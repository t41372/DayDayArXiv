{
  "date": "2025-07-21",
  "category": "cs.AI",
  "summary": "æ¬¢è¿æ¥åˆ° UTC æ—¶é—´ 2025-07-21 çš„ arXiv ä¸­æ–‡ TLDR å¿«æŠ¥ï¼\n\nğŸ‘‹ å¤§å®¶å¥½ï¼Œæˆ‘æ˜¯ä½ ä»¬çš„æ—¥æŠ¥ä½œè€…ã€‚ä»Šå¤©çš„ arXiv åˆ—è¡¨éå¸¸ç‚¸è£‚ï¼Œå¯ä»¥è¯´æ˜¯â€œç¥ä»™æ‰“æ¶â€çš„ä¸€å¤©ã€‚\n\n**ä¸€å¥è¯æ€»ç»“ï¼š**\nä»Šæ—¥é‡ç£…è¿è¿ï¼Œ**Yoshua Bengio** å›¢é˜Ÿå±•ç¤ºäº† LLM åœ¨ç”µæ± ææ–™å‘ç°ä¸Šçš„å…¨æµç¨‹é—­ç¯èƒ½åŠ›ï¼›æ•°å­¦æ¨ç†æ–¹é¢ï¼Œ**IMO 2025** é¢˜ç›®è¢« AI æ”»å…‹ï¼ˆç”šè‡³æåˆ°äº† GPT-5ï¼‰ï¼›å­—èŠ‚è·³åŠ¨å‘å¸ƒäº†é€šç”¨çš„**äººå½¢æœºå™¨äºº VLA æ¨¡å‹ GR-3**ï¼›æ¶æ„å±‚é¢å‡ºç°äº†ç»“åˆä¸‹æ¨è‡ªåŠ¨æœºçš„ **StackTrans**ã€‚\n\nä¸‹é¢æˆ‘ä»¬ç›´å…¥ä¸»é¢˜ï¼Œçœ‹çœ‹ä»Šå¤©æœ€å€¼å¾—å…³æ³¨çš„ç ”ç©¶ã€‚\n\n---\n\n### ğŸš€ AI for Science & æ•°å­¦æ¨ç† (é‡ç£…æ¨è)\n\n**1. [ChatBattery] ç”µæ± å‘ç°ä¸­çš„ä¸“å®¶å¼•å¯¼ LLM æ¨ç†ï¼šä» AI é©±åŠ¨çš„å‡è®¾åˆ°åˆæˆä¸è¡¨å¾**\n**Expert-Guided LLM Reasoning for Battery Discovery: From AI-Driven Hypothesis to Synthesis and Characterization**\n*   **æ ¸å¿ƒè´¡çŒ®**ï¼š**Yoshua Bengio** å¤§ä½¬æŒ‚åçš„æ–‡ç« ã€‚æå‡ºäº†ä¸€ç§æ–°çš„ä»£ç†æ¡†æ¶ **ChatBattery**ï¼Œåˆ©ç”¨æ€ç»´é“¾ï¼ˆCoTï¼‰å°†é¢†åŸŸçŸ¥è¯†æ•´åˆè¿› LLMã€‚\n*   **ä¸»è¦å‘ç°**ï¼šæ–‡ç« ä¸ä»…æ˜¯æ¨¡æ‹Ÿï¼Œè¿˜çœŸæ­£â€œå¹²â€äº†æ´»ï¼šæˆåŠŸè¯†åˆ«ã€åˆæˆå¹¶è¡¨å¾äº†**ä¸‰ç§æ–°å‹é”‚ç¦»å­ç”µæ± æ­£æææ–™**ï¼Œå…¶å®¹é‡æ¯”å¸¸ç”¨çš„ NMC811 åˆ†åˆ«é«˜å‡º 28.8%ã€25.2% å’Œ 18.5%ã€‚å±•ç¤ºäº†ä»è®¾è®¡åˆ°åˆæˆå†åˆ°è¡¨å¾çš„å®Œæ•´ AI é©±åŠ¨é—­ç¯ã€‚\n\n**28. [IMO 2025] åˆ©ç”¨æ¨¡å‹æ— å…³çš„éªŒè¯ä¸ä¿®æ­£æµç¨‹èµ¢å¾— IMO 2025 é‡‘ç‰Œ**\n**Winning Gold at IMO 2025 with a Model-Agnostic Verification-and-Refinement Pipeline**\n*   **æ ¸å¿ƒè´¡çŒ®**ï¼šé’ˆå¯¹é«˜éš¾åº¦çš„å›½é™…æ•°å­¦å¥¥æ—åŒ¹å…‹ï¼ˆIMOï¼‰ï¼Œæå‡ºäº†ä¸€å¥—ä¸ä¾èµ–ç‰¹å®šæ¨¡å‹çš„â€œéªŒè¯-ä¿®æ­£â€æµæ°´çº¿ã€‚\n*   **ä¸»è¦å‘ç°**ï¼šåœ¨ä½¿ç”¨ Gemini 2.5 Proã€Grok-4 æˆ– **GPT-5**ï¼ˆæ³¨æ„ï¼Œæ‘˜è¦ä¸­ç›´æ¥æåˆ°äº† GPT-5ï¼‰ç­‰æ¨¡å‹æ—¶ï¼Œè¯¥æµç¨‹è§£å†³äº† **IMO 2025 ä¸­ 6 é“é¢˜é‡Œçš„ 5 é“**ï¼ˆçº¦ 85.7% å‡†ç¡®ç‡ï¼‰ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œç›´æ¥ Baseline åªæœ‰ 20%-30% çš„æ°´å¹³ã€‚å¼ºè°ƒäº†æ–¹æ³•è®ºè®¾è®¡æ¯”å•çº¯å †æ¨¡å‹æ›´é‡è¦ã€‚\n\n**150. [Delta Prover] é€šè¿‡åˆ†è§£å’Œè¿­ä»£åæ€è§£å†³å½¢å¼åŒ–æ•°å­¦é—®é¢˜**\n**Solving Formal Math Problems by Decomposition and Iterative Reflection**\n*   **æ ¸å¿ƒè´¡çŒ®**ï¼šæå‡ºäº† **Delta Prover**ï¼Œä¸€ä¸ªåŸºäº Agent çš„æ¡†æ¶ï¼Œè®©é€šç”¨ LLM ä¸ **Lean 4** è¯æ˜ç¯å¢ƒäº¤äº’ã€‚\n*   **ä¸»è¦å‘ç°**ï¼šæ— éœ€é’ˆå¯¹å½¢å¼åŒ–è¯­æ–™è¿›è¡Œæ˜‚è´µçš„å¾®è°ƒï¼Œåˆ©ç”¨ DSL ç®¡ç†å­é—®é¢˜ã€‚åœ¨ **miniF2F-test** åŸºå‡†æµ‹è¯•ä¸­è¾¾åˆ°äº† **95.9%** çš„æˆåŠŸç‡ï¼Œåˆ·æ–° SOTAï¼Œè¯æ˜äº†é€šç”¨ LLM é…åˆå¥½çš„ Agent ç»“æ„å¯ä»¥è¶…è¶Šä¸“ç”¨æ¨¡å‹ã€‚\n\n---\n\n### ğŸ¤– å…·èº«æ™ºèƒ½ & æœºå™¨äºº (Embodied AI)\n\n**96. [GR-3] GR-3 æŠ€æœ¯æŠ¥å‘Š**\n**GR-3 Technical Report**\n*   **æ ¸å¿ƒè´¡çŒ®**ï¼šå­—èŠ‚è·³åŠ¨å›¢é˜Ÿï¼ˆæ¶µç›–å¤šä½ä½œè€…ï¼‰å‘å¸ƒäº† **GR-3**ï¼Œä¸€ä¸ªå¤§è§„æ¨¡è§†è§‰-è¯­è¨€-åŠ¨ä½œï¼ˆVLAï¼‰æ¨¡å‹ï¼Œæ—¨åœ¨æ„å»ºé€šç”¨æœºå™¨äººç­–ç•¥ã€‚\n*   **ä¸»è¦å‘ç°**ï¼šGR-3 æ“…é•¿å¤„ç†é•¿åºåˆ—ã€åŒæ‰‹çµå·§æ“ä½œå’Œç§»åŠ¨ä»»åŠ¡ã€‚é€šè¿‡åœ¨ç½‘ç»œè§„æ¨¡æ•°æ®ä¸Šè”åˆè®­ç»ƒï¼Œå¹¶åˆ©ç”¨æå°‘é‡çš„äººç±»è½¨è¿¹æ•°æ®è¿›è¡Œé«˜æ•ˆå¾®è°ƒï¼ˆVRè®¾å¤‡é‡‡é›†ï¼‰ã€‚é…å¥—å‘å¸ƒäº†åŒè‡‚ç§»åŠ¨æœºå™¨äºº **ByteMini**ã€‚\n\n**36. [Gaze-driven] è§‚å¯Ÿã€èšç„¦ã€è¡ŒåŠ¨ï¼šåŸºäºäººç±»æ³¨è§†å’Œæ³¨è§†ç‚¹è§†è§‰ Transformer çš„é«˜æ•ˆé²æ£’æœºå™¨äººå­¦ä¹ **\n**Look, Focus, Act: Efficient and Robust Robot Learning via Human Gaze and Foveated Vision Transformers**\n*   **æ ¸å¿ƒè´¡çŒ®**ï¼šå—äººç±»è§†è§‰å¯å‘ï¼Œæå‡ºäº† **GIAVA** ç³»ç»Ÿï¼Œå°†ä¸»åŠ¨æ³¨è§†ï¼ˆActive Gazeï¼‰å¼•å…¥æœºå™¨äººç­–ç•¥ã€‚\n*   **ä¸»è¦å‘ç°**ï¼šåˆ©ç”¨æ³¨è§†ç‚¹å›¾åƒåˆ†å‰²ï¼ˆFoveated patch tokenizationï¼‰ï¼Œç›¸æ¯”å‡åŒ€å¤„ç†æ˜¾è‘—å‡å°‘äº† Token æ•°é‡ï¼Œä¸ä»…é™ä½äº†è®¡ç®—å¼€é”€ï¼Œè¿˜æé«˜äº†å¯¹èƒŒæ™¯å¹²æ‰°çš„é²æ£’æ€§ã€‚\n\n---\n\n### ğŸ—ï¸ æ¨¡å‹æ¶æ„ä¸é«˜æ•ˆæ¨ç†\n\n**122. [StackTrans] ä»å¤§è¯­è¨€æ¨¡å‹åˆ°å¤§ä¸‹æ¨è‡ªåŠ¨æœºæ¨¡å‹**\n**StackTrans: From Large Language Model to Large Pushdown Automata Model**\n*   **æ ¸å¿ƒè´¡çŒ®**ï¼šé’ˆå¯¹ Transformer éš¾ä»¥å¤„ç†ä¹”å§†æ–¯åŸºå±‚çº§ï¼ˆå¦‚ä¸Šä¸‹æ–‡æ— å…³æ–‡æ³•ï¼‰çš„ç¼ºé™·ï¼Œå—ä¸‹æ¨è‡ªåŠ¨æœºå¯å‘ï¼Œæå‡ºäº† **StackTrans**ã€‚\n*   **ä¸»è¦å‘ç°**ï¼šåœ¨ Transformer å±‚ä¹‹é—´æ˜¾å¼åŠ å…¥äº†**éšè—çŠ¶æ€æ ˆ**ï¼ˆHidden State Stackï¼‰ï¼Œä¸”æ“ä½œæ˜¯å¯å¾®çš„ã€‚**StackTrans-360M** åœ¨ä»å¤´è®­ç»ƒçš„æƒ…å†µä¸‹ï¼Œæ€§èƒ½è¶…è¶Šäº†å‚æ•°é‡å¤§ 2-3 å€çš„å¼€æº LLMï¼Œç‰¹åˆ«æ˜¯åœ¨æ¨ç†ä»»åŠ¡ä¸Šã€‚\n\n**92. [Chart-R1] Chart-R1ï¼šåŸºäºæ€ç»´é“¾ç›‘ç£å’Œå¼ºåŒ–å­¦ä¹ çš„é«˜çº§å›¾è¡¨æ¨ç†å™¨**\n**Chart-R1: Chain-of-Thought Supervision and Reinforcement for Advanced Chart Reasoner**\n*   **æ ¸å¿ƒè´¡çŒ®**ï¼šè¿™æ˜¯ **DeepSeek-R1** æ€æƒ³åœ¨å¤šæ¨¡æ€ï¼ˆå›¾è¡¨ï¼‰é¢†åŸŸçš„å»¶ä¼¸ã€‚æå‡ºäº† Chart-R1ï¼Œç»“åˆäº†ç¨‹åºåŒ–æ•°æ®åˆæˆã€åˆ†æ­¥ CoT ç›‘ç£å’Œæ•°å€¼æ•æ„Ÿçš„å¼ºåŒ–å­¦ä¹ å¾®è°ƒï¼ˆChart-RFTï¼‰ã€‚\n*   **ä¸»è¦å‘ç°**ï¼šåœ¨å›¾è¡¨æ¨ç†ä»»åŠ¡ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œç”šè‡³å¯æ¯”è‚© GPT-4o å’Œ Claude-3.5ã€‚\n\n**100. [LLM Bottleneck] æ–°çš„ LLM ç“¶é¢ˆï¼šæ½œåœ¨æ³¨æ„åŠ›ä¸æ··åˆä¸“å®¶æ¨¡å‹çš„ç³»ç»Ÿè§†è§’**\n**The New LLM Bottleneck: A Systems Perspective on Latent Attention and Mixture-of-Experts**\n*   **æ ¸å¿ƒè´¡çŒ®**ï¼šä¸€ç¯‡ç³»ç»Ÿè§†è§’çš„åˆ†ææ–‡ç« ã€‚æŒ‡å‡º **MLA (Multi-head Latent Attention)** å’Œ **MoE** æ¶æ„æ”¹å˜äº†ç¡¬ä»¶éœ€æ±‚ã€‚\n*   **ä¸»è¦å‘ç°**ï¼šMLA çš„ç®—æœ¯å¼ºåº¦æ¯”ä¼ ç»Ÿ MHA é«˜ä¸¤ä¸ªæ•°é‡çº§ï¼Œå°†ç“¶é¢ˆä»å†…å­˜å¸¦å®½è½¬ç§»åˆ°äº†è®¡ç®—ï¼ˆCompute-boundï¼‰ã€‚è¿™æ„å‘³ç€ä¸“é—¨é’ˆå¯¹ Attention ä¼˜åŒ–çš„ç¡¬ä»¶éœ€æ±‚åœ¨é™ä½ï¼Œæœªæ¥çš„é‡ç‚¹åº”æ˜¯å¹³è¡¡çš„è®¡ç®—å’Œäº’è”èƒ½åŠ›ã€‚\n\n---\n\n### ğŸ‘ï¸ è§†è§‰ä¸å¤šæ¨¡æ€ (Vision & Multimodal)\n\n**3. [Turing Eye Test] åƒç´ ã€æ¨¡å¼ï¼Œä½†æ²¡æœ‰è¯—æ„ï¼šåƒäººç±»ä¸€æ ·çœ‹ä¸–ç•Œ**\n**Pixels, Patterns, but No Poetry: To See The World like Humans**\n*   **æ ¸å¿ƒè´¡çŒ®**ï¼šæå‡ºäº† **Turing Eye Test (TET)** åŸºå‡†ï¼Œä¸æµ‹æ¨ç†ï¼Œåªæµ‹â€œæ„ŸçŸ¥â€ã€‚\n*   **ä¸»è¦å‘ç°**ï¼šå³ä½¿æ˜¯ SOTA çš„å¤šæ¨¡æ€å¤§æ¨¡å‹ï¼ˆMLLMï¼‰ï¼Œåœ¨äººç±»è§‰å¾—ç›´è§‚ç®€å•çš„åˆæˆå›¾åƒæ„ŸçŸ¥ä»»åŠ¡ä¸Šä¹Ÿä¼šå‘ç”Ÿâ€œç¾éš¾æ€§å¤±è´¥â€ã€‚è¿™è¡¨æ˜ç›®å‰çš„æ¨¡å‹åœ¨è§†è§‰å¡”ï¼ˆVision Towerï¼‰çš„æ³›åŒ–èƒ½åŠ›ä¸Šå­˜åœ¨å·¨å¤§ç¼ºå£ï¼Œè€Œä¸ä»…ä»…æ˜¯è¯­è¨€ä¸»å¹²çš„é—®é¢˜ã€‚\n\n**105. [ObjectGS] åŸºäº Gaussian Splatting çš„å¯¹è±¡æ„ŸçŸ¥åœºæ™¯é‡å»ºä¸ç†è§£**\n**ObjectGS: Object-aware Scene Reconstruction and Scene Understanding via Gaussian Splatting**\n*   **æ ¸å¿ƒè´¡çŒ®**ï¼šè§£å†³äº† 3D Gaussian Splatting (3DGS) ç¼ºä¹è¯­ä¹‰ç†è§£çš„é—®é¢˜ã€‚\n*   **ä¸»è¦å‘ç°**ï¼šå°†åœºæ™¯å»ºæ¨¡ä¸ºç‹¬ç«‹çš„â€œå¯¹è±¡é”šç‚¹â€ï¼ˆObject Anchorsï¼‰ï¼Œæ¯ä¸ªå¯¹è±¡ç”Ÿæˆè‡ªå·±çš„ç¥ç»é«˜æ–¯å¹¶å…±äº«å¯¹è±¡ IDã€‚åœ¨å…¨æ™¯åˆ†å‰²å’Œå¼€æ”¾è¯æ±‡åˆ†å‰²ä¸Šè¶…è¶Šäº† SOTAï¼Œå¹¶æ”¯æŒåœºæ™¯ç¼–è¾‘ã€‚\n\n**20. [DLA] æ¢¦æƒ³ã€æå‡ã€åŠ¨ç”»ï¼šä»å•å¼ å›¾åƒåˆ°å¯åŠ¨ç”»çš„é«˜æ–¯åŒ–èº«**\n**Dream, Lift, Animate: From Single Images to Animatable Gaussian Avatars**\n*   **æ ¸å¿ƒè´¡çŒ®**ï¼šæå‡ºäº† DLA æ¡†æ¶ï¼Œä»…éœ€ä¸€å¼ ç…§ç‰‡å³å¯é‡å»ºå¯åŠ¨ç”»çš„ 3D äººç±»åŒ–èº«ã€‚\n*   **ä¸»è¦å‘ç°**ï¼šåˆ©ç”¨è§†é¢‘æ‰©æ•£æ¨¡å‹â€œæ¢¦æƒ³â€å‡ºå¤šè§†è§’ï¼Œç„¶åæå‡ä¸º 3D é«˜æ–¯ï¼Œå¹¶æ˜ å°„åˆ° UV ç©ºé—´ä»¥ä¾¿äºåŠ¨ç”»é©±åŠ¨ã€‚\n\n---\n\n### ğŸ›¡ï¸ å®‰å…¨ä¸å¯¹é½ (Safety & Alignment)\n\n**152. [PromptArmor] ç®€å•è€Œæœ‰æ•ˆçš„æç¤ºæ³¨å…¥é˜²å¾¡**\n**PromptArmor: Simple yet Effective Prompt Injection Defenses**\n*   **æ ¸å¿ƒè´¡çŒ®**ï¼šé’ˆå¯¹ Prompt Injectionï¼ˆæç¤ºæ³¨å…¥ï¼‰æ”»å‡»ï¼Œæå‡ºäº†ä¸€ç§åŸºäºç°æˆ LLM çš„æ£€æµ‹é˜²å¾¡æœºåˆ¶ã€‚\n*   **ä¸»è¦å‘ç°**ï¼šæ–¹æ³•å¾ˆç®€å•ï¼šå…ˆè®© LLM æ£€æŸ¥å¹¶ç§»é™¤è¾“å…¥ä¸­çš„æ³¨å…¥æç¤ºï¼Œå†äº¤ç»™ Agent å¤„ç†ã€‚åœ¨ AgentDojo åŸºå‡†ä¸Šï¼Œèƒ½å°†æ”»å‡»æˆåŠŸç‡é™è‡³ 1% ä»¥ä¸‹ï¼Œä¸”è¯¯æŠ¥ç‡æä½ã€‚\n\n**43. [ToM Overfitting] å°å‹ LLM æ— æ³•é€šè¿‡å¼ºåŒ–å­¦ä¹ ä¹ å¾—å¯æ³›åŒ–çš„å¿ƒæ™ºç†è®º**\n**Small LLMs Do Not Learn a Generalizable Theory of Mind via Reinforcement Learning**\n*   **æ ¸å¿ƒè´¡çŒ®**ï¼šç ”ç©¶å°å‹ LLM æ˜¯å¦èƒ½é€šè¿‡ RL è·å¾—å¿ƒæ™ºç†è®ºï¼ˆToMï¼‰ã€‚\n*   **ä¸»è¦å‘ç°**ï¼š**å¦**ã€‚æ¨¡å‹åªæ˜¯æ‹Ÿåˆäº†è®­ç»ƒæ•°æ®é›†çš„ç»Ÿè®¡æ¨¡å¼ï¼ˆOverfitting/Hackingï¼‰ï¼Œåœ¨åˆ†å¸ƒå¤–ï¼ˆOODï¼‰ä»»åŠ¡ä¸Šè¡¨ç°æ²¡æœ‰æå‡ç”šè‡³ä¸‹é™ã€‚è¿™è¡¨æ˜å®ƒä»¬å­¦åˆ°çš„æ˜¯ç‹­çª„çš„æŠ€å·§ï¼Œè€Œä¸æ˜¯çœŸæ­£çš„æŠ½è±¡ ToM èƒ½åŠ›ã€‚\n\n---\n\n### ğŸ“ è®ºæ–‡åˆ—è¡¨é€Ÿè§ˆ (å…¶ä»–å€¼å¾—å…³æ³¨çš„)\n\n*   **[2] Reinforcement Learning in hyperbolic space for multi-step reasoning**: åœ¨åŒæ›²ç©ºé—´ï¼ˆHyperbolic spaceï¼‰ä¸­åš RLï¼Œé€‚åˆå±‚çº§ç»“æ„æ¨ç†ï¼ŒFrontierMath ä¸Šæå‡æ˜¾è‘—ã€‚\n*   **[27] Diffusion Beats Autoregressive in Data-Constrained Settings**: åœ¨æ•°æ®å—é™ï¼ˆä½†åœ¨è®¡ç®—èµ„æºå……è¶³ï¼‰çš„æƒ…å†µä¸‹ï¼Œæ‰©æ•£æ¨¡å‹æ¯”è‡ªå›å½’ï¼ˆARï¼‰æ¨¡å‹è¡¨ç°æ›´å¥½ã€‚\n*   **[61] CoLD: Counterfactually-Guided Length Debiasing for Process Reward Models**: è¿‡ç¨‹å¥–åŠ±æ¨¡å‹ï¼ˆPRMï¼‰å–œæ¬¢ç»™æ›´é•¿çš„æ¨ç†æ­¥éª¤æ‰“é«˜åˆ†ï¼Œè¿™ç¯‡æ–‡ç« æå‡ºäº†å»åæ–¹æ³•ã€‚\n*   **[130] Butterfly Effects in Toolchains**: å…¨é¢åˆ†æäº† LLM Tool Agent åœ¨å‚æ•°å¡«å……æ—¶çš„å¤±è´¥æ¨¡å¼ï¼Œæå‡ºäº†å‚æ•°åå¹»è§‰ä¸»è¦æºäº LLM è‡ªèº«é™åˆ¶ã€‚\n*   **[121] Scaling Decentralized Learning with FLock**: æå‡ºäº†å»ä¸­å¿ƒåŒ–çš„ LLM å¾®è°ƒæ¡†æ¶ FLockï¼Œåˆ©ç”¨åŒºå—é“¾å’Œæ¿€åŠ±æœºåˆ¶ï¼Œæ— éœ€ä¸­å¿ƒæœåŠ¡å™¨ã€‚\n\nä»Šå¤©çš„å¿«æŠ¥å°±åˆ°è¿™é‡Œï¼Œå¸Œæœ›è¿™äº›ç²¾é€‰å†…å®¹èƒ½ä¸ºä½ çš„ç ”ç©¶å¸¦æ¥çµæ„Ÿï¼æˆ‘ä»¬æ˜å¤©è§ã€‚ğŸ‘‹",
  "papers": [
    {
      "arxiv_id": "2507.16110v1",
      "title": "Expert-Guided LLM Reasoning for Battery Discovery: From AI-Driven Hypothesis to Synthesis and Characterization",
      "title_zh": "ä¸“å®¶å¼•å¯¼çš„å¤§è¯­è¨€æ¨¡å‹ç”µæ± ç ”å‘æ¨ç†ï¼šä»äººå·¥æ™ºèƒ½é©±åŠ¨çš„å‡è¯´åˆ°åˆæˆä¸è¡¨å¾",
      "authors": [
        "Shengchao Liu",
        "Hannan Xu",
        "Yan Ai",
        "Huanxin Li",
        "Yoshua Bengio",
        "Harry Guo"
      ],
      "abstract": "Large language models (LLMs) leverage chain-of-thought (CoT) techniques to tackle complex problems, representing a transformative breakthrough in artificial intelligence (AI). However, their reasoning capabilities have primarily been demonstrated in solving math and coding problems, leaving their potential for domain-specific applications-such as battery discovery-largely unexplored. Inspired by the idea that reasoning mirrors a form of guided search, we introduce ChatBattery, a novel agentic framework that integrates domain knowledge to steer LLMs toward more effective reasoning in materials design. Using ChatBattery, we successfully identify, synthesize, and characterize three novel lithium-ion battery cathode materials, which achieve practical capacity improvements of 28.8%, 25.2%, and 18.5%, respectively, over the widely used cathode material, LiNi0.8Mn0.1Co0.1O2 (NMC811). Beyond this discovery, ChatBattery paves a new path by showing a successful LLM-driven and reasoning-based platform for battery materials invention. This complete AI-driven cycle-from design to synthesis to characterization-demonstrates the transformative potential of AI-driven reasoning in revolutionizing materials discovery.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† ChatBatteryï¼Œè¿™æ˜¯ä¸€ä¸ªå°†é¢†åŸŸçŸ¥è¯†ä¸å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æ¨ç†ç›¸ç»“åˆçš„æ–°å‹æ™ºèƒ½ä½“æ¡†æ¶ï¼Œä¸“é—¨ç”¨äºåŠ é€Ÿç”µæ± ææ–™çš„å‘ç°è¿›ç¨‹ã€‚è¯¥æ¡†æ¶å—å¼•å¯¼å¼æœç´¢å¯å‘ï¼Œé€šè¿‡é›†æˆä¸“å®¶é¢†åŸŸçŸ¥è¯†æ¥å¼•å¯¼ LLMs çš„é“¾å¼æ€ç»´ï¼ˆChain-of-Thoughtï¼‰æ¨ç†ï¼Œä½¿å…¶åœ¨å¤æ‚çš„ææ–™è®¾è®¡ä»»åŠ¡ä¸­è¡¨ç°æ›´åŠ é«˜æ•ˆã€‚åˆ©ç”¨ ChatBatteryï¼Œç ”ç©¶å›¢é˜ŸæˆåŠŸè¯†åˆ«ã€åˆæˆå¹¶è¡¨å¾äº†ä¸‰ç§æ–°å‹é”‚ç¦»å­ç”µæ± æ­£æææ–™ï¼Œå…¶å®é™…å®¹é‡ç›¸è¾ƒäºå¹¿æ³›ä½¿ç”¨çš„ LiNi0.8Mn0.1Co0.1O2 (NMC811) åˆ†åˆ«æå‡äº† 28.8%ã€25.2% å’Œ 18.5%ã€‚è¿™é¡¹å·¥ä½œå®Œæ•´å±•ç¤ºäº†ä» AI é©±åŠ¨è®¾è®¡åˆ°å®éªŒåˆæˆå†åˆ°æ€§èƒ½è¡¨å¾çš„å…¨é—­ç¯æµç¨‹ï¼Œä¸ä»…è¯æ˜äº† AI é©±åŠ¨æ¨ç†åœ¨å˜é©ææ–™å‘ç°é¢†åŸŸçš„å·¨å¤§æ½œåŠ›ï¼Œä¹Ÿä¸ºæ„å»ºè‡ªåŠ¨åŒ–ç”µæ± ææ–™å‘æ˜å¹³å°å¼€è¾Ÿäº†æ–°è·¯å¾„ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.16110v1",
      "published_date": "2025-07-21 23:46:11 UTC",
      "updated_date": "2025-07-21 23:46:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:52:12.787685+00:00"
    },
    {
      "arxiv_id": "2507.16864v1",
      "title": "Reinforcement Learning in hyperbolic space for multi-step reasoning",
      "title_zh": "ç”¨äºå¤šæ­¥æ¨ç†çš„åŒæ›²ç©ºé—´å¼ºåŒ–å­¦ä¹ ",
      "authors": [
        "Tao Xu",
        "Dung-Yang Lee",
        "Momiao Xiong"
      ],
      "abstract": "Multi-step reasoning is a fundamental challenge in artificial intelligence, with applications ranging from mathematical problem-solving to decision-making in dynamic environments. Reinforcement Learning (RL) has shown promise in enabling agents to perform multi-step reasoning by optimizing long-term rewards. However, conventional RL methods struggle with complex reasoning tasks due to issues such as credit assignment, high-dimensional state representations, and stability concerns. Recent advancements in Transformer architectures and hyperbolic geometry have provided novel solutions to these challenges. This paper introduces a new framework that integrates hyperbolic Transformers into RL for multi-step reasoning. The proposed approach leverages hyperbolic embeddings to model hierarchical structures effectively. We present theoretical insights, algorithmic details, and experimental results that include Frontier Math and nonlinear optimal control problems. Compared to RL with vanilla transformer, the hyperbolic RL largely improves accuracy by (32%~44%) on FrontierMath benchmark, (43%~45%) on nonlinear optimal control benchmark, while achieving impressive reduction in computational time by (16%~32%) on FrontierMath benchmark, (16%~17%) on nonlinear optimal control benchmark. Our work demonstrates the potential of hyperbolic Transformers in reinforcement learning, particularly for multi-step reasoning tasks that involve hierarchical structures.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹Reinforcement Learning (RL)åœ¨å¤„ç†Multi-step reasoningä»»åŠ¡æ—¶é¢ä¸´çš„ä¿¡ç”¨åˆ†é…ã€é«˜ç»´çŠ¶æ€è¡¨ç¤ºåŠç¨³å®šæ€§éš¾é¢˜ï¼Œæå‡ºäº†ä¸€ç§é›†æˆHyperbolic Transformersçš„æ–°å‹æ¡†æ¶ã€‚è¯¥æ–¹æ³•åˆ©ç”¨Hyperbolic embeddingsçš„æ•°å­¦ç‰¹æ€§æ¥æœ‰æ•ˆå»ºæ¨¡å¤æ‚çš„Hierarchical structuresï¼Œä¼˜åŒ–äº†æ™ºèƒ½ä½“åœ¨åŠ¨æ€ç¯å¢ƒä¸­çš„é•¿ç¨‹å†³ç­–èƒ½åŠ›ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨FrontierMathåŸºå‡†æµ‹è¯•ä¸­ï¼Œè¯¥æ¡†æ¶æ¯”ä¼ ç»Ÿçš„Transformer RLæ¶æ„åœ¨å‡†ç¡®ç‡ä¸Šæå‡äº†32%è‡³44%ï¼Œå¹¶åœ¨Nonlinear optimal controlé—®é¢˜ä¸Šå®ç°äº†43%è‡³45%çš„æ€§èƒ½å¢é•¿ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ¡ˆæ˜¾è‘—é™ä½äº†è®¡ç®—å¼€é”€ï¼Œåœ¨ä¸åŒåŸºå‡†ä»»åŠ¡ä¸­åˆ†åˆ«å‡å°‘äº†16%è‡³32%å’Œ16%è‡³17%çš„è¿è¡Œæ—¶é—´ã€‚è¿™é¡¹å·¥ä½œå……åˆ†è¯æ˜äº†Hyperbolic geometryåœ¨å¼ºåŒ–å­¦ä¹ é¢†åŸŸï¼Œç‰¹åˆ«æ˜¯å¤„ç†å…·æœ‰å±‚æ¬¡åŒ–ç‰¹å¾çš„å¤šæ­¥æ¨ç†ä»»åŠ¡æ—¶çš„å“è¶Šæ€§èƒ½ä¸åº”ç”¨æ½œåŠ›ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "53 pages, 5 figures",
      "pdf_url": "https://arxiv.org/pdf/2507.16864v1",
      "published_date": "2025-07-21 21:59:05 UTC",
      "updated_date": "2025-07-21 21:59:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:52:11.495160+00:00"
    },
    {
      "arxiv_id": "2507.16863v1",
      "title": "Pixels, Patterns, but No Poetry: To See The World like Humans",
      "title_zh": "åƒç´ ã€æ¨¡å¼ï¼Œè€Œéè¯—æ„ï¼šåƒäººç±»ä¸€æ ·è§‚å¯Ÿä¸–ç•Œ",
      "authors": [
        "Hongcheng Gao",
        "Zihao Huang",
        "Lin Xu",
        "Jingyi Tang",
        "Xinhao Li",
        "Yue Liu",
        "Haoyang Li",
        "Taihang Hu",
        "Minhua Lin",
        "Xinlong Yang",
        "Ge Wu",
        "Balong Bi",
        "Hongyu Chen",
        "Wentao Zhang"
      ],
      "abstract": "Achieving human-like perception and reasoning in Multimodal Large Language Models (MLLMs) remains a central challenge in artificial intelligence. While recent research has primarily focused on enhancing reasoning capabilities in MLLMs, a fundamental question persists: Can Multimodal Large Language Models truly perceive the world as humans do? This paper shifts focus from reasoning to perception. Rather than constructing benchmarks specifically for reasoning, we introduce the Turing Eye Test (TET), a challenging perception-oriented benchmark comprising four diagnostic tasks that evaluate MLLMs' performance on synthetic images that humans process intuitively. Our findings reveal that state-of-the-art MLLMs exhibit catastrophic failures on our perceptual tasks trivial for humans. Both in-context learning and training on language backbone-effective for previous benchmarks-fail to improve performance on our tasks, while fine-tuning the vision tower enables rapid adaptation, suggesting that our benchmark poses challenges for vision tower generalization rather than for the knowledge and reasoning capabilities of the language backbone-a key gap between current MLLMs and human perception. We release a representative subset of TET tasks in this version, and will introduce more diverse tasks and methods to enhance visual generalization in future work.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹(Multimodal Large Language Models, MLLMs)æ˜¯å¦èƒ½åƒäººç±»ä¸€æ ·æ„ŸçŸ¥ä¸–ç•Œï¼Œå°†ç ”ç©¶é‡å¿ƒä»æ¨ç†èƒ½åŠ›è½¬å‘äº†åŸºç¡€æ„ŸçŸ¥èƒ½åŠ›ã€‚ä½œè€…æå‡ºäº†å›¾çµä¹‹çœ¼æµ‹è¯•(Turing Eye Test, TET)ï¼Œè¿™æ˜¯ä¸€ä¸ªç”±å››é¡¹è¯Šæ–­ä»»åŠ¡æ„æˆçš„æ„ŸçŸ¥å¯¼å‘åŸºå‡†æµ‹è¯•ï¼Œä¸“é—¨è¯„ä¼°æ¨¡å‹åœ¨äººç±»å¯ç›´è§‚ç†è§£çš„åˆæˆå›¾åƒä¸Šçš„è¡¨ç°ã€‚ç ”ç©¶å‘ç°ï¼Œå½“å‰æœ€å…ˆè¿›çš„MLLMsåœ¨è¿™äº›å¯¹äººç±»è€Œè¨€æå…·ç›´è§‰æ€§çš„æ„ŸçŸ¥ä»»åŠ¡ä¸Šé­é‡äº†ç¾éš¾æ€§å¤±è´¥ã€‚å®éªŒè¿›ä¸€æ­¥è¯æ˜ï¼Œä¸Šä¸‹æ–‡å­¦ä¹ (In-context learning)å’Œé’ˆå¯¹è¯­è¨€ä¸»å¹²(Language backbone)çš„ä¼ ç»Ÿå¢å¼ºæ–¹æ³•å‡æ— æ³•æ”¹å–„è¡¨ç°ï¼Œè€Œå¾®è°ƒè§†è§‰å¡”(Vision tower)åˆ™èƒ½ä½¿æ¨¡å‹å¿«é€Ÿé€‚åº”ã€‚è¿™è¡¨æ˜å½“å‰MLLMsä¸äººç±»æ„ŸçŸ¥ä¹‹é—´çš„å…³é”®å·®è·åœ¨äºè§†è§‰å¡”çš„æ³›åŒ–èƒ½åŠ›ï¼Œè€Œéè¯­è¨€ä¸»å¹²çš„çŸ¥è¯†æˆ–æ¨ç†æ°´å¹³ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.16863v1",
      "published_date": "2025-07-21 21:50:16 UTC",
      "updated_date": "2025-07-21 21:50:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:52:12.597960+00:00"
    },
    {
      "arxiv_id": "2507.16083v2",
      "title": "Efficient Compositional Multi-tasking for On-device Large Language Models",
      "title_zh": "é¢å‘ç«¯ä¾§å¤§è¯­è¨€æ¨¡å‹çš„é«˜æ•ˆç»„åˆå¼å¤šä»»åŠ¡å¤„ç†",
      "authors": [
        "Ondrej Bohdal",
        "Mete Ozay",
        "Jijoong Moon",
        "Kyeng-Hun Lee",
        "Hyeonmok Ko",
        "Umberto Michieli"
      ],
      "abstract": "Adapter parameters provide a mechanism to modify the behavior of machine learning models and have gained significant popularity in the context of large language models (LLMs) and generative AI. These parameters can be merged to support multiple tasks via a process known as task merging. However, prior work on merging in LLMs, particularly in natural language processing, has been limited to scenarios where each test example addresses only a single task. In this paper, we focus on on-device settings and study the problem of text-based compositional multi-tasking, where each test example involves the simultaneous execution of multiple tasks. For instance, generating a translated summary of a long text requires solving both translation and summarization tasks concurrently. To facilitate research in this setting, we propose a benchmark comprising four practically relevant compositional tasks. We also present an efficient method (Learnable Calibration) tailored for on-device applications, where computational resources are limited, emphasizing the need for solutions that are both resource-efficient and high-performing. Our contributions lay the groundwork for advancing the capabilities of LLMs in real-world multi-tasking scenarios, expanding their applicability to complex, resource-constrained use cases.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç§»åŠ¨è®¾å¤‡(On-device)ä¸Šçš„å¤§è¯­è¨€æ¨¡å‹(LLMs)ï¼Œæ·±å…¥æ¢è®¨äº†æ–‡æœ¬ç»„åˆå¼å¤šä»»åŠ¡å¤„ç†(compositional multi-tasking)çš„æŒ‘æˆ˜ã€‚å°½ç®¡é€‚é…å™¨(Adapter)å‚æ•°åˆå¹¶æŠ€æœ¯å·²è¢«å¹¿æ³›åº”ç”¨ï¼Œä½†ä»¥å¾€ç ”ç©¶å¤šå±€é™äºå•ä»»åŠ¡åœºæ™¯ï¼Œè€Œæœ¬ç ”ç©¶é‡ç‚¹å…³æ³¨æ¯æ¡æµ‹è¯•æ ·æœ¬éœ€åŒæ—¶æ‰§è¡Œå¤šé¡¹ä»»åŠ¡ï¼ˆå¦‚åŒæ—¶è¿›è¡Œç¿»è¯‘ä¸æ‘˜è¦ï¼‰çš„æƒ…å†µã€‚ä½œè€…æå‡ºäº†ä¸€ä¸ªåŒ…å«å››é¡¹å®é™…ç›¸å…³ç»„åˆä»»åŠ¡çš„åŸºå‡†æµ‹è¯•(benchmark)ï¼Œæ—¨åœ¨æ¨åŠ¨è¯¥é¢†åŸŸçš„ç ”ç©¶ã€‚åŒæ—¶ï¼Œè®ºæ–‡å¼•å…¥äº†ä¸€ç§åä¸ºå¯å­¦ä¹ æ ¡å‡†(Learnable Calibration)çš„é«˜æ•ˆæ–¹æ³•ï¼Œä¸“é—¨ä¼˜åŒ–èµ„æºå—é™çš„ç§»åŠ¨ç«¯åº”ç”¨æ€§èƒ½ã€‚è¯¥ç ”ç©¶é€šè¿‡åœ¨æ€§èƒ½ä¸èµ„æºæ•ˆç‡ä¹‹é—´å–å¾—å¹³è¡¡ï¼Œæ˜¾è‘—å¢å¼ºäº†å¤§è¯­è¨€æ¨¡å‹åœ¨å¤„ç†å¤æ‚ä»»åŠ¡æ—¶çš„èƒ½åŠ›ã€‚è¿™é¡¹å·¥ä½œä¸ºLLMsåœ¨ç°å®ä¸–ç•Œå¤æ‚å¤šä»»åŠ¡åœºæ™¯ä¸­çš„åº”ç”¨å¥ å®šäº†åŸºç¡€ï¼Œæœ‰æ•ˆæ‰©å±•äº†å…¶åœ¨å—é™ç¯å¢ƒä¸‹çš„é€‚ç”¨æ€§ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at EMNLP 2025 (main track, long paper)",
      "pdf_url": "https://arxiv.org/pdf/2507.16083v2",
      "published_date": "2025-07-21 21:39:23 UTC",
      "updated_date": "2025-10-11 19:28:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:52:14.393205+00:00"
    },
    {
      "arxiv_id": "2507.16079v1",
      "title": "A Lower Bound for the Number of Linear Regions of Ternary ReLU Regression Neural Networks",
      "title_zh": "ä¸‰å€¼ ReLU å›å½’ç¥ç»ç½‘ç»œçº¿æ€§åŒºåŸŸæ•°é‡çš„ä¸‹ç•Œ",
      "authors": [
        "Yuta Nakahara",
        "Manabu Kobayashi",
        "Toshiyasu Matsushima"
      ],
      "abstract": "With the advancement of deep learning, reducing computational complexity and memory consumption has become a critical challenge, and ternary neural networks (NNs) that restrict parameters to $\\{-1, 0, +1\\}$ have attracted attention as a promising approach. While ternary NNs demonstrate excellent performance in practical applications such as image recognition and natural language processing, their theoretical understanding remains insufficient. In this paper, we theoretically analyze the expressivity of ternary NNs from the perspective of the number of linear regions. Specifically, we evaluate the number of linear regions of ternary regression NNs with Rectified Linear Unit (ReLU) for activation functions and prove that the number of linear regions increases polynomially with respect to network width and exponentially with respect to depth, similar to standard NNs. Moreover, we show that it suffices to either square the width or double the depth of ternary NNs to achieve a lower bound on the maximum number of linear regions comparable to that of general ReLU regression NNs. This provides a theoretical explanation, in some sense, for the practical success of ternary NNs.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ—¨åœ¨é™ä½è®¡ç®—å¤æ‚åº¦å’Œå†…å­˜æ¶ˆè€—çš„ä¸‰å€¼ç¥ç»ç½‘ç»œ(Ternary Neural Networks)è¿›è¡Œäº†ç†è®ºåˆ†æï¼Œé‡ç‚¹æ¢è®¨äº†å…¶åœ¨å‚æ•°å—é™äº $\\{-1, 0, +1\\}$ æ—¶çš„è¡¨è¾¾èƒ½åŠ›(Expressivity)ã€‚ä½œè€…ä»çº¿æ€§åŒºåŸŸ(Linear Regions)æ•°é‡çš„è§’åº¦å‡ºå‘ï¼Œè¯„ä¼°äº†ä»¥ä¿®æ­£çº¿æ€§å•å…ƒ(ReLU)ä¸ºæ¿€æ´»å‡½æ•°çš„ä¸‰å€¼å›å½’ç¥ç»ç½‘ç»œã€‚ç ”ç©¶è¯æ˜ï¼Œä¸‰å€¼ç¥ç»ç½‘ç»œçš„çº¿æ€§åŒºåŸŸæ•°é‡éšç½‘ç»œå®½åº¦å‘ˆå¤šé¡¹å¼å¢é•¿ï¼Œéšæ·±åº¦å‘ˆæŒ‡æ•°å¢é•¿ï¼Œè¿™ä¸€ç‰¹æ€§ä¸æ ‡å‡†ç¥ç»ç½‘ç»œ(Standard NNs)ç›¸ä¼¼ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¡¨æ˜ä»…éœ€å°†ä¸‰å€¼ç¥ç»ç½‘ç»œçš„å®½åº¦å¹³æ–¹æˆ–æ·±åº¦ç¿»å€ï¼Œå³å¯ä½¿å…¶æœ€å¤§çº¿æ€§åŒºåŸŸæ•°é‡çš„ä¸‹ç•Œè¾¾åˆ°ä¸æ™®é€š ReLU å›å½’ç¥ç»ç½‘ç»œç›¸å½“çš„æ°´å¹³ã€‚è¿™äº›ç ”ç©¶ç»“æœä¸ºä¸‰å€¼ç¥ç»ç½‘ç»œåœ¨å›¾åƒè¯†åˆ«å’Œè‡ªç„¶è¯­è¨€å¤„ç†ç­‰å®é™…åº”ç”¨ä¸­çš„å“è¶Šè¡¨ç°æä¾›äº†ç†è®ºä¾æ®ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.16079v1",
      "published_date": "2025-07-21 21:29:33 UTC",
      "updated_date": "2025-07-21 21:29:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:52:16.952104+00:00"
    },
    {
      "arxiv_id": "2507.16077v1",
      "title": "AI-driven Orchestration at Scale: Estimating Service Metrics on National-Wide Testbeds",
      "title_zh": "å¤§è§„æ¨¡ AI é©±åŠ¨ç¼–æ’ï¼šåŸºäºå…¨å›½è§„æ¨¡æµ‹è¯•åºŠçš„æœåŠ¡æŒ‡æ ‡è¯„ä¼°",
      "authors": [
        "Rodrigo Moreira",
        "Rafael Pasquini",
        "Joberto S. B. Martins",
        "Tereza C. Carvalho",
        "FlÃ¡vio de Oliveira Silva"
      ],
      "abstract": "Network Slicing (NS) realization requires AI-native orchestration architectures to efficiently and intelligently handle heterogeneous user requirements. To achieve this, network slicing is evolving towards a more user-centric digital transformation, focusing on architectures that incorporate native intelligence to enable self-managed connectivity in an integrated and isolated manner. However, these initiatives face the challenge of validating their results in production environments, particularly those utilizing ML-enabled orchestration, as they are often tested in local networks or laboratory simulations. This paper proposes a large-scale validation method using a network slicing prediction model to forecast latency using Deep Neural Networks (DNNs) and basic ML algorithms embedded within an NS architecture, evaluated in real large-scale production testbeds. It measures and compares the performance of different DNNs and ML algorithms, considering a distributed database application deployed as a network slice over two large-scale production testbeds. The investigation highlights how AI-based prediction models can enhance network slicing orchestration architectures and presents a seamless, production-ready validation method as an alternative to fully controlled simulations or laboratory setups.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç½‘ç»œåˆ‡ç‰‡(Network Slicing)åœ¨å®é™…ç”Ÿäº§ç¯å¢ƒä¸­éªŒè¯å›°éš¾ä»¥åŠç°æœ‰å®éªŒå¤šå±€é™äºå®éªŒå®¤æ¨¡æ‹Ÿçš„æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§é¢å‘å¤§è§„æ¨¡çœŸå®æµ‹è¯•åºŠçš„ AI é©±åŠ¨ç¼–æ’éªŒè¯æ–¹æ³•ã€‚è¯¥æ–¹æ¡ˆåœ¨ NS æ¶æ„ä¸­åµŒå…¥äº†æ·±åº¦ç¥ç»ç½‘ç»œ(DNNs)å’ŒåŸºç¡€æœºå™¨å­¦ä¹ (ML)ç®—æ³•ï¼Œç”¨äºé¢„æµ‹å»¶è¿Ÿç­‰å…³é”®æœåŠ¡æŒ‡æ ‡ï¼Œä»è€Œå®ç°æ›´é«˜æ•ˆã€æ™ºèƒ½çš„èµ„æºç®¡ç†ã€‚é€šè¿‡åœ¨ä¸¤ä¸ªå›½å®¶çº§å¤§è§„æ¨¡ç”Ÿäº§æµ‹è¯•åºŠä¸Šéƒ¨ç½²åˆ†å¸ƒå¼æ•°æ®åº“åº”ç”¨ä½œä¸ºç½‘ç»œåˆ‡ç‰‡ï¼Œç ”ç©¶äººå‘˜å¯¹æ¯”å¹¶è¯„ä¼°äº†å¤šç§ DNNs å’Œ ML ç®—æ³•çš„æ€§èƒ½è¡¨ç°ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼ŒåŸºäº AI çš„é¢„æµ‹æ¨¡å‹èƒ½å¤Ÿæ˜¾è‘—å¢å¼ºç½‘ç»œåˆ‡ç‰‡çš„ç¼–æ’èƒ½åŠ›ï¼Œæå‡äº†æ¶æ„çš„è‡ªç®¡ç†æ°´å¹³ã€‚è¯¥å·¥ä½œä¸º AI èµ‹èƒ½çš„è‡ªåŠ¨åŒ–ç½‘ç»œç¼–æ’æä¾›äº†ä¸€ç§æ— ç¼ä¸”å…·å¤‡ç”Ÿäº§å°±ç»ªæ€§çš„éªŒè¯æ‰‹æ®µï¼Œæœ‰æ•ˆå¼¥è¡¥äº†å—æ§æ¨¡æ‹Ÿä¸çœŸå®ç¯å¢ƒä¹‹é—´çš„å·®è·ã€‚",
      "categories": [
        "cs.ET",
        "cs.AI",
        "cs.LG",
        "cs.MA",
        "cs.NI"
      ],
      "primary_category": "cs.ET",
      "comment": "17 pages, 18 figures, 14 tables,",
      "pdf_url": "https://arxiv.org/pdf/2507.16077v1",
      "published_date": "2025-07-21 21:24:40 UTC",
      "updated_date": "2025-07-21 21:24:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:52:23.347161+00:00"
    },
    {
      "arxiv_id": "2507.16068v3",
      "title": "Compositional Coordination for Multi-Robot Teams with Large Language Models",
      "title_zh": "åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„å¤šæœºå™¨äººå›¢é˜Ÿç»„åˆå¼ååŒ",
      "authors": [
        "Zhehui Huang",
        "Guangyao Shi",
        "Yuwei Wu",
        "Vijay Kumar",
        "Gaurav S. Sukhatme"
      ],
      "abstract": "Multi-robot coordination has traditionally relied on a mission-specific and expert-driven pipeline, where natural language mission descriptions are manually translated by domain experts into mathematical formulation, algorithm design, and executable code. This conventional process is labor-intensive, inaccessible to non-experts, and inflexible to changes in mission requirements. Here, we propose LAN2CB (Language to Collective Behavior), a novel framework that leverages large language models (LLMs) to streamline and generalize the multi-robot coordination pipeline. LAN2CB transforms natural language (NL) mission descriptions into executable Python code for multi-robot systems through two core modules: (1) Mission Analysis, which parses mission descriptions into behavior trees, and (2) Code Generation, which leverages the behavior tree and a structured knowledge base to generate robot control code. We further introduce a dataset of natural language mission descriptions to support development and benchmarking. Experiments in both simulation and real-world environments demonstrate that LAN2CB enables robust and flexible multi-robot coordination from natural language, significantly reducing manual engineering effort and supporting broad generalization across diverse mission types. Website: https://sites.google.com/view/lan-cb",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†LAN2CB (Language to Collective Behavior)æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ä¼ ç»Ÿå¤šæœºå™¨äººåä½œä¸­ä¾èµ–ä¸“å®¶æ‰‹åŠ¨ç¿»è¯‘ä»»åŠ¡æè¿°ã€å·¥ä½œé‡å¤§ä¸”ç¼ºä¹çµæ´»æ€§ç­‰é—®é¢˜ã€‚è¯¥æ¡†æ¶åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹(Large Language Models, LLMs)å°†è‡ªç„¶è¯­è¨€ä»»åŠ¡æè¿°è‡ªåŠ¨è½¬åŒ–ä¸ºå¤šæœºå™¨äººç³»ç»Ÿçš„å¯æ‰§è¡ŒPythonä»£ç ã€‚å…¶æ ¸å¿ƒåŒ…å«ä¸¤ä¸ªå…³é”®æ¨¡å—ï¼šä»»åŠ¡åˆ†æ(Mission Analysis)æ¨¡å—è´Ÿè´£å°†è‡ªç„¶è¯­è¨€è§£æä¸ºè¡Œä¸ºæ ‘(behavior trees)ï¼Œä»£ç ç”Ÿæˆ(Code Generation)æ¨¡å—åˆ™ç»“åˆè¡Œä¸ºæ ‘å’Œç»“æ„åŒ–çŸ¥è¯†åº“ç”Ÿæˆå…·ä½“çš„æœºå™¨äººæ§åˆ¶ä»£ç ã€‚ç ”ç©¶è¿˜å¼•å…¥äº†ä¸€ä¸ªä¸“é—¨çš„è‡ªç„¶è¯­è¨€ä»»åŠ¡æè¿°æ•°æ®é›†ï¼Œå¹¶åˆ†åˆ«åœ¨ä»¿çœŸå’ŒçœŸå®ç¯å¢ƒè¿›è¡Œäº†å®éªŒéªŒè¯ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒLAN2CBèƒ½å¤Ÿæ˜¾è‘—å‡å°‘äººå·¥å·¥ç¨‹è´Ÿæ‹…ï¼Œå¹¶åœ¨å¤šç§å¤æ‚çš„ä»»åŠ¡ç±»å‹ä¸­å±•ç°å‡ºå¼ºå¤§çš„é€šç”¨æ€§ä¸é²æ£’æ€§ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.RO",
      "comment": "IEEE International Symposium on Multi-Robot & Multi-Agent Systems (MRS 2025) Oral",
      "pdf_url": "https://arxiv.org/pdf/2507.16068v3",
      "published_date": "2025-07-21 21:09:15 UTC",
      "updated_date": "2025-10-22 22:05:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:52:25.855924+00:00"
    },
    {
      "arxiv_id": "2507.16067v1",
      "title": "A Unifying Framework for Semiring-Based Constraint Logic Programming With Negation (full version)",
      "title_zh": "åŸºäºåŠç¯çš„å«å¦å®šçº¦æŸé€»è¾‘ç¼–ç¨‹çš„ç»Ÿä¸€æ¡†æ¶ï¼ˆå®Œæ•´ç‰ˆï¼‰",
      "authors": [
        "Jeroen Spaans",
        "Jesse Heyninck"
      ],
      "abstract": "Constraint Logic Programming (CLP) is a logic programming formalism used to solve problems requiring the consideration of constraints, like resource allocation and automated planning and scheduling. It has previously been extended in various directions, for example to support fuzzy constraint satisfaction, uncertainty, or negation, with different notions of semiring being used as a unifying abstraction for these generalizations. None of these extensions have studied clauses with negation allowed in the body. We investigate an extension of CLP which unifies many of these extensions and allows negation in the body. We provide semantics for such programs, using the framework of approximation fixpoint theory, and give a detailed overview of the impacts of properties of the semirings on the resulting semantics. As such, we provide a unifying framework that captures existing approaches and allows extending them with a more expressive language.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹çº¦æŸé€»è¾‘ç¨‹åºè®¾è®¡(Constraint Logic Programming)æå‡ºäº†ä¸€ç§ç»Ÿä¸€çš„æ¡†æ¶ï¼Œé‡ç‚¹è§£å†³äº†åœ¨åŸºäºåŠç¯(Semirings)çš„æ‰©å±•ä¸­å…è®¸å­å¥ä½“åŒ…å«å¦å®š(Negation)çš„é—®é¢˜ã€‚å°½ç®¡å…ˆå‰å·²æœ‰ç ”ç©¶æ¢è®¨äº†æ¨¡ç³Šçº¦æŸå’Œä¸ç¡®å®šæ€§ç­‰æ–¹å‘ï¼Œä½†æœ¬ç ”ç©¶é¦–æ¬¡å°†å¦å®šå¼•å…¥å­å¥ä½“ï¼Œå¹¶åˆ©ç”¨é€¼è¿‘å®šç‚¹ç†è®º(Approximation Fixpoint Theory)ä¸ºè¿™ç±»ç¨‹åºæä¾›äº†ä¸¥è°¨çš„è¯­ä¹‰å®šä¹‰ã€‚é€šè¿‡è¯¦ç»†åˆ†æåŠç¯å±æ€§å¯¹è¯­ä¹‰çš„å½±å“ï¼Œè¯¥æ¡†æ¶æˆåŠŸç»Ÿä¸€äº†å¤šç§ç°æœ‰çš„CLPæ‰©å±•æ–¹æ³•ã€‚è¿™ä¸€æˆæœä¸ä»…æå‡äº†é€»è¾‘ç¼–ç¨‹è¯­è¨€çš„è¡¨è¾¾èƒ½åŠ›ï¼Œè¿˜ä¸ºå¤„ç†èµ„æºåˆ†é…å’Œè‡ªåŠ¨åŒ–è§„åˆ’ç­‰å¤æ‚çº¦æŸé—®é¢˜æä¾›äº†æ›´å…·æ™®é€‚æ€§çš„ç†è®ºæ”¯æ’‘ã€‚",
      "categories": [
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "Full version, including proofs and appendices, of paper accepted at IJCAI 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.16067v1",
      "published_date": "2025-07-21 21:04:03 UTC",
      "updated_date": "2025-07-21 21:04:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:52:29.547938+00:00"
    },
    {
      "arxiv_id": "2507.16063v1",
      "title": "AI-Powered Commit Explorer (APCE)",
      "title_zh": "AI é©±åŠ¨çš„æäº¤è®°å½•æ¢ç´¢å™¨ (APCE)",
      "authors": [
        "Yousab Grees",
        "Polina Iaremchuk",
        "Ramtin Ehsani",
        "Esteban Parra",
        "Preetha Chatterjee",
        "Sonia Haiduc"
      ],
      "abstract": "Commit messages in a version control system provide valuable information for developers regarding code changes in software systems. Commit messages can be the only source of information left for future developers describing what was changed and why. However, writing high-quality commit messages is often neglected in practice. Large Language Model (LLM) generated commit messages have emerged as a way to mitigate this issue. We introduce the AI-Powered Commit Explorer (APCE), a tool to support developers and researchers in the use and study of LLM-generated commit messages. APCE gives researchers the option to store different prompts for LLMs and provides an additional evaluation prompt that can further enhance the commit message provided by LLMs. APCE also provides researchers with a straightforward mechanism for automated and human evaluation of LLM-generated messages. Demo link https://youtu.be/zYrJ9s6sZvo",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è½¯ä»¶ç‰ˆæœ¬æ§åˆ¶ç³»ç»Ÿä¸­æäº¤ä¿¡æ¯ (Commit messages) è´¨é‡æ™®éè¢«å¿½è§†çš„é—®é¢˜ï¼Œæ¨å‡ºäº† AI-Powered Commit Explorer (APCE) å·¥å…·ã€‚APCE æ—¨åœ¨æ”¯æŒå¼€å‘è€…å’Œç ”ç©¶äººå‘˜åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ (Large Language Model, LLM) è‡ªåŠ¨ç”Ÿæˆå¹¶ç ”ç©¶ä»£ç å˜æ›´è¯´æ˜ã€‚è¯¥å·¥å…·å…è®¸ç”¨æˆ·å­˜å‚¨å¤šç§ä¸åŒçš„æç¤ºè¯ (Prompts)ï¼Œå¹¶æä¾›ä¸“é—¨çš„è¯„ä¼°æç¤ºè¯ä»¥è¿›ä¸€æ­¥ä¼˜åŒ–æ¨¡å‹ç”Ÿæˆçš„æ–‡æœ¬è´¨é‡ã€‚æ­¤å¤–ï¼ŒAPCE è¿˜é›†æˆäº†è‡ªåŠ¨åŒ–è¯„ä¼°å’Œäººå·¥è¯„ä¼°æœºåˆ¶ï¼Œä¸º LLM ç”Ÿæˆçš„ Commit messages æä¾›äº†ç›´è§‚çš„è´¨é‡è¡¡é‡æ ‡å‡†ã€‚é€šè¿‡è¿™ä¸€å¹³å°ï¼Œç ”ç©¶äººå‘˜å¯ä»¥æ›´é«˜æ•ˆåœ°æ¢ç´¢ä¸åŒ LLM ç­–ç•¥å¯¹æäº¤ä¿¡æ¯è´¨é‡çš„å½±å“ã€‚è¯¥å·¥å…·çš„å‡ºç°ä¸ºæå‡è½¯ä»¶æ–‡æ¡£åŒ–æ°´å¹³å’Œä»£ç åº“çš„é•¿æœŸå¯ç»´æŠ¤æ€§æä¾›äº†æœ‰æ•ˆçš„æŠ€æœ¯æ”¯æ’‘ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.16063v1",
      "published_date": "2025-07-21 20:58:56 UTC",
      "updated_date": "2025-07-21 20:58:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:52:32.341915+00:00"
    },
    {
      "arxiv_id": "2507.16043v3",
      "title": "Beyond Rate Coding: Surrogate Gradients Enable Spike Timing Learning in Spiking Neural Networks",
      "title_zh": "è¶…è¶Šé¢‘ç‡ç¼–ç ï¼šä»£ç†æ¢¯åº¦å®ç°è„‰å†²ç¥ç»ç½‘ç»œä¸­çš„è„‰å†²æ—¶åºå­¦ä¹ ",
      "authors": [
        "Ziqiao Yu",
        "Pengfei Sun",
        "Danyal Akarca",
        "Dan F. M. Goodman"
      ],
      "abstract": "The surrogate gradient descent algorithm enabled spiking neural networks to be trained to carry out challenging sensory processing tasks, an important step in understanding how spikes contribute to neural computations. However, it is unclear the extent to which these algorithms fully explore the space of possible spiking solutions to problems. We investigated whether spiking networks trained with surrogate gradient descent can learn to make use of information that is only encoded in the timing and not the rate of spikes. We constructed synthetic datasets with a range of types of spike timing information (interspike intervals, spatio-temporal spike patterns or polychrony, and coincidence codes). We find that surrogate gradient descent training can extract all of these types of information. In more realistic speech-based datasets, both timing and rate information is present. We therefore constructed variants of these datasets in which all rate information is removed, and find that surrogate gradient descent can still perform well. We tested all networks both with and without trainable axonal delays. We find that delays can give a significant increase in performance, particularly for more challenging tasks. To determine what types of spike timing information are being used by the networks trained on the speech-based tasks, we test these networks on time-reversed spikes which perturb spatio-temporal spike patterns but leave interspike intervals and coincidence information unchanged. We find that when axonal delays are not used, networks perform well under time reversal, whereas networks trained with delays perform poorly. This suggests that spiking neural networks with delays are better able to exploit temporal structure. To facilitate further studies of temporal coding, we have released our modified speech-based datasets.",
      "tldr_zh": "è¯¥ç ”ç©¶è°ƒæŸ¥äº†é‡‡ç”¨ Surrogate Gradient Descent ç®—æ³•è®­ç»ƒçš„ Spiking Neural Networks (SNNs) æ˜¯å¦èƒ½å¤Ÿåˆ©ç”¨ä»…é€šè¿‡è„‰å†²æ—¶é—´è€Œéé¢‘ç‡ç¼–ç çš„ä¿¡æ¯ã€‚ç ”ç©¶äººå‘˜é€šè¿‡æ„å»ºåŒ…å« Interspike Intervalsã€æ—¶ç©ºè„‰å†²æ¨¡å¼ (Polychrony) å’Œ Coincidence Codes ç­‰å¤šç§è„‰å†²æ—¶é—´ä¿¡æ¯çš„åˆæˆæ•°æ®é›†ï¼Œè¯å®äº† Surrogate Gradient Descent èƒ½å¤ŸæˆåŠŸæå–æ‰€æœ‰è¿™äº›ç±»å‹çš„ä¿¡æ¯ã€‚åœ¨å»é™¤äº†æ‰€æœ‰é¢‘ç‡ä¿¡æ¯çš„è¯­éŸ³æ•°æ®é›†å®éªŒä¸­ï¼Œè¯¥ç®—æ³•ä¾ç„¶å±•ç°å‡ºè‰¯å¥½çš„æ€§èƒ½ï¼Œè¯æ˜äº†å…¶åœ¨å¤„ç†çº¯æ—¶é—´ç¼–ç ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ã€‚æ­¤å¤–ï¼Œå¼•å…¥å¯è®­ç»ƒçš„ Axonal Delays æ˜¾è‘—æå‡äº†ç½‘ç»œåœ¨æŒ‘æˆ˜æ€§ä»»åŠ¡ä¸­çš„è¡¨ç°ï¼Œå¹¶é€šè¿‡æ—¶é—´åè½¬æµ‹è¯•è¯æ˜äº†å…·å¤‡å»¶è¿Ÿçš„ç½‘ç»œèƒ½æ›´æœ‰æ•ˆåœ°åˆ©ç”¨æ—¶ç©ºç»“æ„ã€‚è¯¥ç ”ç©¶è¡¨æ˜ Surrogate Gradient Descent ä½¿ SNNs å…·å¤‡äº†è¶…è¶Š Rate Coding çš„å­¦ä¹ èƒ½åŠ›ï¼Œä¸ºç†è§£è„‰å†²å¦‚ä½•è´¡çŒ®äºç¥ç»è®¡ç®—æä¾›äº†é‡è¦è§è§£ï¼Œå¹¶å…¬å¼€å‘å¸ƒäº†ç›¸å…³æ•°æ®é›†ä»¥ä¿ƒè¿›å¯¹ Temporal Coding çš„è¿›ä¸€æ­¥ç ”ç©¶ã€‚",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.16043v3",
      "published_date": "2025-07-21 20:19:19 UTC",
      "updated_date": "2025-12-18 14:12:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:52:38.544232+00:00"
    },
    {
      "arxiv_id": "2507.21129v2",
      "title": "Measuring and Analyzing Intelligence via Contextual Uncertainty in Large Language Models using Information-Theoretic Metrics",
      "title_zh": "åŸºäºä¿¡æ¯è®ºæŒ‡æ ‡çš„å¤§è¯­è¨€æ¨¡å‹ä¸Šä¸‹æ–‡ä¸ç¡®å®šæ€§æ™ºèƒ½è¡¡é‡ä¸åˆ†æ",
      "authors": [
        "Jae Wan Shim"
      ],
      "abstract": "Large Language Models (LLMs) excel on many task-specific benchmarks, yet the mechanisms that drive this success remain poorly understood. We move from asking what these systems can do to asking how they process information. Our contribution is a task-agnostic method that builds a quantitative Cognitive Profile for any model. The profile is built around the Entropy Decay Curve-a plot of a model's normalised predictive uncertainty as context length grows. Across several state-of-the-art LLMs and diverse texts, the curves expose distinctive, stable profiles that depend on both model scale and text complexity. We also propose the Information Gain Span (IGS) as a single index that summarises the desirability of a decay pattern. Together, these tools offer a principled way to analyse and compare the internal dynamics of modern AI systems.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ä½†å…¶å†…éƒ¨ä¿¡æ¯å¤„ç†æœºåˆ¶å°šä¸æ˜ç¡®çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§ä»»åŠ¡æ— å…³çš„æ–¹æ³•æ¥ä¸ºæ¨¡å‹æ„å»ºå®šé‡çš„è®¤çŸ¥ç‰¹å¾(Cognitive Profile)ã€‚è¯¥æ–¹æ³•çš„æ ¸å¿ƒæ˜¯ç†µè¡°å‡æ›²çº¿(Entropy Decay Curve)ï¼Œé€šè¿‡è®°å½•æ¨¡å‹éšç€ä¸Šä¸‹æ–‡é•¿åº¦å¢åŠ è€Œäº§ç”Ÿçš„å½’ä¸€åŒ–é¢„æµ‹ä¸ç¡®å®šæ€§çš„å˜åŒ–ï¼Œæ­ç¤ºæ¨¡å‹çš„ä¿¡æ¯å¤„ç†æ¨¡å¼ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œä¸åŒè§„æ¨¡çš„å…ˆè¿›LLMsåœ¨å¤„ç†ä¸åŒå¤æ‚åº¦çš„æ–‡æœ¬æ—¶ï¼Œå±•ç°å‡ºä¸æ¨¡å‹è§„æ¨¡(model scale)å’Œæ–‡æœ¬å¤æ‚åº¦(text complexity)å¯†åˆ‡ç›¸å…³çš„ã€ç‹¬ç‰¹ä¸”ç¨³å®šçš„ç‰¹å¾æ›²çº¿ã€‚æ­¤å¤–ï¼Œç ”ç©¶è€…è¿˜æå‡ºäº†ä¿¡æ¯å¢ç›Šè·¨åº¦(Information Gain Span, IGS)ä½œä¸ºè¡¡é‡è¡°å‡æ¨¡å¼ä¼˜åŠ£çš„å•ä¸€æŒ‡æ ‡ã€‚è¿™äº›å·¥å…·å…±åŒæä¾›äº†ä¸€ç§åŸºäºä¿¡æ¯è®ºçš„ä¸¥è°¨æ‰‹æ®µï¼Œç”¨äºåˆ†æå’Œæ¯”è¾ƒç°ä»£äººå·¥æ™ºèƒ½ç³»ç»Ÿçš„å†…éƒ¨åŠ¨åŠ›å­¦ç‰¹å¾ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.21129v2",
      "published_date": "2025-07-21 20:14:25 UTC",
      "updated_date": "2025-10-26 00:32:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:52:54.086237+00:00"
    },
    {
      "arxiv_id": "2507.16039v2",
      "title": "Reactivation: Empirical NTK Dynamics Under Task Shifts",
      "title_zh": "Reactivationï¼šä»»åŠ¡åˆ‡æ¢ä¸‹çš„ NTK åŠ¨åŠ›å­¦å®è¯ç ”ç©¶",
      "authors": [
        "Yuzhi Liu",
        "Zixuan Chen",
        "Zirui Zhang",
        "Yufei Liu",
        "Giulia Lanzillotta"
      ],
      "abstract": "The Neural Tangent Kernel (NTK) offers a powerful tool to study the functional dynamics of neural networks. In the so-called lazy, or kernel regime, the NTK remains static during training and the network function is linear in the static neural tangents feature space. The evolution of the NTK during training is necessary for feature learning, a key driver of deep learning success. The study of the NTK dynamics has led to several critical discoveries in recent years, in generalization and scaling behaviours. However, this body of work has been limited to the single task setting, where the data distribution is assumed constant over time. In this work, we present a comprehensive empirical analysis of NTK dynamics in continual learning, where the data distribution shifts over time. Our findings highlight continual learning as a rich and underutilized testbed for probing the dynamics of neural training. At the same time, they challenge the validity of static-kernel approximations in theoretical treatments of continual learning, even at large scale.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æŒç»­å­¦ä¹ (Continual Learning)åœºæ™¯ä¸‹çš„ç¥ç»åˆ‡çº¿æ ¸(Neural Tangent Kernel, NTK)åŠ¨æ€è¿›è¡Œäº†æ·±å…¥çš„å®è¯åˆ†æï¼Œæ¢è®¨äº†æ•°æ®åˆ†å¸ƒéšæ—¶é—´åç§»å¯¹ç½‘ç»œåŠŸèƒ½åŠ¨æ€çš„å½±å“ã€‚ç ”ç©¶å¼ºè°ƒäº†NTKåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­çš„æ¼”åŒ–å¯¹äºå®ç°ç‰¹å¾å­¦ä¹ (Feature Learning)çš„é‡è¦æ€§ï¼Œå¹¶æŒ‡å‡ºè¿™æ˜¯æ·±åº¦å­¦ä¹ å–å¾—æˆåŠŸçš„å…³é”®ã€‚é€šè¿‡åœ¨ä»»åŠ¡åç§»(Task Shifts)ç¯å¢ƒä¸‹è§‚å¯ŸNTKçš„è¡Œä¸ºï¼Œä½œè€…æå‡ºæŒç»­å­¦ä¹ æ˜¯æ¢æµ‹ç¥ç»ç½‘ç»œè®­ç»ƒåŠ¨æ€çš„ä¸€ä¸ªæå…·ä»·å€¼ä¸”å°šæœªè¢«å……åˆ†åˆ©ç”¨çš„è¯•éªŒåœºã€‚å®éªŒç»“æœæ˜ç¡®æŒ‘æˆ˜äº†åœ¨æŒç»­å­¦ä¹ ç†è®ºç ”ç©¶ä¸­ä½¿ç”¨é™æ€æ ¸è¿‘ä¼¼(Static-Kernel Approximations)çš„æœ‰æ•ˆæ€§ï¼Œè¯æ˜å³ä½¿åœ¨å¤§è§„æ¨¡æ¨¡å‹ä¸‹è¿™ç§å‡è®¾ä¹Ÿä¾ç„¶å­˜ç–‘ã€‚è¯¥é¡¹å·¥ä½œä¸ºç†è§£éå¹³ç¨³åˆ†å¸ƒä¸‹çš„ç¥ç»åŠ¨åŠ›å­¦æä¾›äº†é‡è¦çš„å®è¯æ”¯æŒï¼Œæ·±åŒ–äº†å¯¹æ¨¡å‹æ³›åŒ–ä¸ç¼©æ”¾è¡Œä¸ºçš„è®¤çŸ¥ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by the 3rd Workshop on High-dimensional Learning Dynamics (HiLD), ICML 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.16039v2",
      "published_date": "2025-07-21 20:13:02 UTC",
      "updated_date": "2025-07-25 13:33:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:52:58.494322+00:00"
    },
    {
      "arxiv_id": "2507.16038v1",
      "title": "Discovering and using Spelke segments",
      "title_zh": "Spelke åˆ†å‰²çš„å‘ç°ä¸åº”ç”¨",
      "authors": [
        "Rahul Venkatesh",
        "Klemen Kotar",
        "Lilian Naing Chen",
        "Seungwoo Kim",
        "Luca Thomas Wheeler",
        "Jared Watrous",
        "Ashley Xu",
        "Gia Ancone",
        "Wanhee Lee",
        "Honglin Chen",
        "Daniel Bear",
        "Stefan Stojanov",
        "Daniel Yamins"
      ],
      "abstract": "Segments in computer vision are often defined by semantic considerations and are highly dependent on category-specific conventions. In contrast, developmental psychology suggests that humans perceive the world in terms of Spelke objects--groupings of physical things that reliably move together when acted on by physical forces. Spelke objects thus operate on category-agnostic causal motion relationships which potentially better support tasks like manipulation and planning. In this paper, we first benchmark the Spelke object concept, introducing the SpelkeBench dataset that contains a wide variety of well-defined Spelke segments in natural images. Next, to extract Spelke segments from images algorithmically, we build SpelkeNet, a class of visual world models trained to predict distributions over future motions. SpelkeNet supports estimation of two key concepts for Spelke object discovery: (1) the motion affordance map, identifying regions likely to move under a poke, and (2) the expected-displacement map, capturing how the rest of the scene will move. These concepts are used for \"statistical counterfactual probing\", where diverse \"virtual pokes\" are applied on regions of high motion-affordance, and the resultant expected displacement maps are used define Spelke segments as statistical aggregates of correlated motion statistics. We find that SpelkeNet outperforms supervised baselines like SegmentAnything (SAM) on SpelkeBench. Finally, we show that the Spelke concept is practically useful for downstream applications, yielding superior performance on the 3DEditBench benchmark for physical object manipulation when used in a variety of off-the-shelf object manipulation models.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†è®¡ç®—æœºè§†è§‰ä¸­çš„ Spelke segments æ¦‚å¿µï¼Œä¸ä¾èµ–è¯­ä¹‰ç±»åˆ«çš„ä¼ ç»Ÿåˆ†å‰²ä¸åŒï¼Œå®ƒæºäºå‘è‚²å¿ƒç†å­¦ï¼Œå¼ºè°ƒç‰©ä½“åœ¨ç‰©ç†åŠ›ä½œç”¨ä¸‹å…±åŒç§»åŠ¨çš„å› æœè¿åŠ¨å…³ç³»ã€‚ä½œè€…é¦–å…ˆæ¨å‡ºäº†åŒ…å«ä¸°å¯Œè‡ªç„¶å›¾åƒæ ‡æ³¨çš„ SpelkeBench æ•°æ®é›†ï¼Œå¹¶å¼€å‘äº†æ—¨åœ¨é¢„æµ‹æœªæ¥è¿åŠ¨åˆ†å¸ƒçš„è§†è§‰ä¸–ç•Œæ¨¡å‹ SpelkeNetã€‚è¯¥æ¨¡å‹é€šè¿‡ç”Ÿæˆè¿åŠ¨å¯å‘å›¾ (motion affordance map) å’ŒæœŸæœ›ä½ç§»å›¾ (expected-displacement map) è¿›è¡Œç»Ÿè®¡åäº‹å®æ¢æµ‹ (statistical counterfactual probing)ï¼Œåˆ©ç”¨â€œè™šæ‹Ÿæˆ³åŠ¨â€ (virtual pokes) äº§ç”Ÿçš„è¿åŠ¨ç»Ÿè®¡å…³è”æ¥å®šä¹‰ Spelke segmentsã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒSpelkeNet åœ¨ SpelkeBench ä¸Šçš„æ€§èƒ½è¶…è¶Šäº† SegmentAnything (SAM) ç­‰å¼ºç›‘ç£åŸºçº¿æ¨¡å‹ã€‚æœ€åï¼Œç ”ç©¶è¯æ˜äº† Spelke æ¦‚å¿µåœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸­çš„å®ç”¨æ€§ï¼Œåœ¨ç‰©ç†å¯¹è±¡æ“ä½œåŸºå‡† 3DEditBench ä¸Šæ˜¾è‘—æå‡äº†å¤šç§ç°æœ‰æ¨¡å‹çš„è¡¨ç°ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Project page at: https://neuroailab.github.io/spelke_net",
      "pdf_url": "https://arxiv.org/pdf/2507.16038v1",
      "published_date": "2025-07-21 20:11:57 UTC",
      "updated_date": "2025-07-21 20:11:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:53:03.947511+00:00"
    },
    {
      "arxiv_id": "2507.16033v1",
      "title": "\"Just a strange pic\": Evaluating 'safety' in GenAI Image safety annotation tasks from diverse annotators' perspectives",
      "title_zh": "â€œåªæ˜¯ä¸€å¼ æ€ªå›¾â€ï¼šå¤šç»´æ ‡æ³¨è€…è§†è§’ä¸‹ç”Ÿæˆå¼äººå·¥æ™ºèƒ½å›¾åƒå®‰å…¨æ ‡æ³¨ä»»åŠ¡çš„å®‰å…¨æ€§è¯„ä¼°",
      "authors": [
        "Ding Wang",
        "Mark DÃ­az",
        "Charvi Rastogi",
        "Aida Davani",
        "Vinodkumar Prabhakaran",
        "Pushkar Mishra",
        "Roma Patel",
        "Alicia Parrish",
        "Zoe Ashwood",
        "Michela Paganini",
        "Tian Huey Teh",
        "Verena Rieser",
        "Lora Aroyo"
      ],
      "abstract": "Understanding what constitutes safety in AI-generated content is complex. While developers often rely on predefined taxonomies, real-world safety judgments also involve personal, social, and cultural perceptions of harm. This paper examines how annotators evaluate the safety of AI-generated images, focusing on the qualitative reasoning behind their judgments. Analyzing 5,372 open-ended comments, we find that annotators consistently invoke moral, emotional, and contextual reasoning that extends beyond structured safety categories. Many reflect on potential harm to others more than to themselves, grounding their judgments in lived experience, collective risk, and sociocultural awareness. Beyond individual perceptions, we also find that the structure of the task itself -- including annotation guidelines -- shapes how annotators interpret and express harm. Guidelines influence not only which images are flagged, but also the moral judgment behind the justifications. Annotators frequently cite factors such as image quality, visual distortion, and mismatches between prompt and output as contributing to perceived harm dimensions, which are often overlooked in standard evaluation frameworks. Our findings reveal that existing safety pipelines miss critical forms of reasoning that annotators bring to the task. We argue for evaluation designs that scaffold moral reflection, differentiate types of harm, and make space for subjective, context-sensitive interpretations of AI-generated content.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†ç”Ÿæˆå¼äººå·¥æ™ºèƒ½ GenAI å›¾åƒå®‰å…¨æ ‡æ³¨ä»»åŠ¡ä¸­å®‰å…¨æ€§çš„å®šä¹‰ï¼Œåˆ†æäº†æ ‡æ³¨è€…åœ¨è¯„ä¼°å›¾åƒå®‰å…¨æ€§æ—¶çš„å®šæ€§æ¨ç†è¿‡ç¨‹ã€‚é€šè¿‡å¯¹ 5,372 æ¡å¼€æ”¾å¼è¯„è®ºçš„åˆ†æï¼Œç ”ç©¶å‘ç°æ ‡æ³¨è€…åœ¨åˆ¤æ–­æ—¶å¸¸è¶…è¶Šé¢„å®šä¹‰çš„åˆ†ç±»ä½“ç³»ï¼Œå¹¿æ³›è¿ç”¨é“å¾·ã€æƒ…æ„Ÿå’ŒèƒŒæ™¯æ¨ç†ã€‚æ ‡æ³¨è€…ä¸ä»…å…³æ³¨è‡ªèº«æ„Ÿå—ï¼Œæ›´å€¾å‘äºåŸºäºç”Ÿæ´»ç»éªŒã€é›†ä½“é£é™©å’Œç¤¾ä¼šæ–‡åŒ–æ„è¯†æ¥è€ƒé‡å¯¹ä»–äººçš„æ½œåœ¨ä¼¤å®³ã€‚ç ”ç©¶è¿›ä¸€æ­¥æ­ç¤ºäº†ä»»åŠ¡ç»“æ„ä¸æ ‡æ³¨æŒ‡å— Guidelines èƒ½å¤Ÿå¡‘é€ æ ‡æ³¨è€…å¯¹ä¼¤å®³çš„ç†è§£ï¼Œå¹¶å½±å“å…¶ç†ç”±èƒŒåçš„é“å¾·åˆ¤æ–­ã€‚æ­¤å¤–ï¼Œæ ‡æ³¨è€…å¸¸å°†å›¾åƒè´¨é‡ã€è§†è§‰å¤±çœŸä»¥åŠæç¤ºè¯ä¸è¾“å‡ºçš„ Mismatches è§†ä¸ºæ„ŸçŸ¥ä¼¤å®³çš„ç»´åº¦ï¼Œè€Œè¿™äº›åœ¨æ ‡å‡†è¯„ä¼°æ¡†æ¶ä¸­å¾€å¾€è¢«å¿½è§†ã€‚ç ”ç©¶æœ€ç»ˆæŒ‡å‡ºå½“å‰çš„å®‰å…¨è¯„ä¼°æµç¨‹ç¼ºå¤±äº†æ ‡æ³¨è€…çš„å…³é”®æ¨ç†ç¯èŠ‚ï¼Œå¹¶å»ºè®®æœªæ¥çš„è¯„ä¼°è®¾è®¡åº”æ”¯æŒé“å¾·åæ€ï¼Œå¹¶å®¹çº³ä¸»è§‚ä¸”å…·æœ‰è¯­å¢ƒæ•æ„Ÿæ€§çš„ AI ç”Ÿæˆå†…å®¹è§£è¯»ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "Accepted to AAAI/ACM Conference on Artificial Intelligence, Ethics, and Society 2025 (AIES 2025)",
      "pdf_url": "https://arxiv.org/pdf/2507.16033v1",
      "published_date": "2025-07-21 19:53:29 UTC",
      "updated_date": "2025-07-21 19:53:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:53:04.948489+00:00"
    },
    {
      "arxiv_id": "2507.16028v1",
      "title": "From Logic to Language: A Trust Index for Problem Solving with LLMs",
      "title_zh": "ä»é€»è¾‘åˆ°è¯­è¨€ï¼šå¤§è¯­è¨€æ¨¡å‹é—®é¢˜æ±‚è§£çš„ä¿¡ä»»æŒ‡æ•°",
      "authors": [
        "Tehseen Rug",
        "Felix BÃ¶hmer",
        "Tessa Pfattheicher"
      ],
      "abstract": "Classical computation, grounded in formal, logical systems, has been the engine of technological progress for decades, excelling at problems that can be described with unambiguous rules. This paradigm, however, leaves a vast ocean of human problems -- those characterized by ambiguity, dynamic environments, and subjective context -- largely untouched. The advent of Large Language Models (LLMs) represents a fundamental shift, enabling computational systems to engage with this previously inaccessible domain using natural language. This paper introduces a unified framework to understand and contrast these problem-solving paradigms. We define and delineate the problem spaces addressable by formal languages versus natural language. While solutions to the former problem class can be evaluated using binary quality measures, the latter requires a much more nuanced definition of approximate solution space taking into account the vagueness, subjectivity and ambiguity inherent to natural language. We therefore introduce a vector-valued trust index Q, which reflects solution quality and distinguishes the binary correctness of formal solutions from the continuous adequacy spectrum characteristic of natural language solutions. Within this framework, we propose two statistical quality dimensions. Normalized bi-semantic entropy measures robustness and conceptual diversity of LLM answers given semantic variation in problem formulations. Emotional valence maps subjective valuation of a solution to a quantifiable metric that can be maximized by invoking statistical measures. The concepts introduced in this work will provide a more rigorous understanding of the capabilities, limitations, and inherent nature of problem-solving in the age of LLMs.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªç»Ÿä¸€æ¡†æ¶ï¼Œç”¨äºå¯¹æ¯”åŸºäºå½¢å¼é€»è¾‘ç³»ç»Ÿçš„ä¼ ç»Ÿè®¡ç®—ä¸åŸºäºè‡ªç„¶è¯­è¨€çš„å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨è§£å†³é—®é¢˜èŒƒå¼ä¸Šçš„å·®å¼‚ã€‚ä½œè€…å®šä¹‰å¹¶åˆ’å®šäº†å½¢å¼è¯­è¨€ä¸è‡ªç„¶è¯­è¨€åˆ†åˆ«é€‚ç”¨çš„é—®é¢˜ç©ºé—´ï¼Œå¼ºè°ƒäº†è‡ªç„¶è¯­è¨€è§£åœ¨å¤„ç†æ¨¡ç³Šæ€§å’Œä¸»è§‚æ€§æ—¶éœ€è¦ä¸åŒäºä¼ ç»ŸäºŒå…ƒè´¨é‡æ ‡å‡†çš„è¯„ä¼°ä½“ç³»ã€‚ç ”ç©¶å¼•å…¥äº†ä¸€ä¸ªå‘é‡å€¼ä¿¡ä»»æŒ‡æ•° Q (trust index Q)ï¼Œæœ‰æ•ˆåœ°åŒºåˆ†äº†å½¢å¼è§£çš„ç»å¯¹æ­£ç¡®æ€§ä¸è‡ªç„¶è¯­è¨€è§£çš„è¿ç»­å……åˆ†æ€§å…‰è°±ã€‚è¯¥æ¡†æ¶æå‡ºäº†ä¸¤ä¸ªæ ¸å¿ƒç»Ÿè®¡ç»´åº¦ï¼šå½’ä¸€åŒ–åŒè¯­ä¹‰ç†µ (Normalized bi-semantic entropy) ç”¨äºè¡¡é‡æ¨¡å‹åœ¨è¯­ä¹‰å˜åŒ–ä¸‹çš„ç¨³å¥æ€§ä¸æ¦‚å¿µå¤šæ ·æ€§ï¼Œè€Œæƒ…æ„Ÿæ•ˆä»· (Emotional valence) åˆ™å°†ä¸»è§‚ä¼°å€¼æ˜ å°„ä¸ºå¯é‡åŒ–çš„ç»Ÿè®¡æŒ‡æ ‡ã€‚è¿™é¡¹å·¥ä½œä¸ºæ·±å…¥ç†è§£ LLMs åœ¨è§£å†³é—®é¢˜è¿‡ç¨‹ä¸­çš„èƒ½åŠ›ã€å±€é™æ€§åŠå…¶æœ¬è´¨æä¾›äº†æ›´ä¸ºä¸¥è°¨çš„ç†è®ºæ”¯æ’‘ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "17 pages, 2 figures",
      "pdf_url": "https://arxiv.org/pdf/2507.16028v1",
      "published_date": "2025-07-21 19:50:45 UTC",
      "updated_date": "2025-07-21 19:50:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:53:04.791315+00:00"
    },
    {
      "arxiv_id": "2507.22923v1",
      "title": "How and Where to Translate? The Impact of Translation Strategies in Cross-lingual LLM Prompting",
      "title_zh": "å¦‚ä½•ç¿»è¯‘åŠåœ¨ä½•å¤„ç¿»è¯‘ï¼Ÿç¿»è¯‘ç­–ç•¥å¯¹è·¨è¯­è¨€ LLM æç¤ºçš„å½±å“",
      "authors": [
        "Aman Gupta",
        "Yingying Zhuang",
        "Zhou Yu",
        "Ziji Zhang",
        "Anurag Beniwal"
      ],
      "abstract": "Despite advances in the multilingual capabilities of Large Language Models (LLMs), their performance varies substantially across different languages and tasks. In multilingual retrieval-augmented generation (RAG)-based systems, knowledge bases (KB) are often shared from high-resource languages (such as English) to low-resource ones, resulting in retrieved information from the KB being in a different language than the rest of the context. In such scenarios, two common practices are pre-translation to create a mono-lingual prompt and cross-lingual prompting for direct inference. However, the impact of these choices remains unclear. In this paper, we systematically evaluate the impact of different prompt translation strategies for classification tasks with RAG-enhanced LLMs in multilingual systems. Experimental results show that an optimized prompting strategy can significantly improve knowledge sharing across languages, therefore improve the performance on the downstream classification task. The findings advocate for a broader utilization of multilingual resource sharing and cross-lingual prompt optimization for non-English languages, especially the low-resource ones.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨è·¨è¯­è¨€å¤§è¯­è¨€æ¨¡å‹(LLM)æç¤ºä¸­ç¿»è¯‘ç­–ç•¥çš„å½±å“ï¼Œæ—¨åœ¨è§£å†³å¤šè¯­è¨€æ¨¡å‹åœ¨ä¸åŒè¯­è¨€å’Œä»»åŠ¡ä¸­è¡¨ç°ä¸å‡çš„é—®é¢˜ã€‚é’ˆå¯¹å¤šè¯­è¨€æ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)ç³»ç»Ÿä¸­çŸ¥è¯†åº“(KB)é€šå¸¸ä»¥è‹±è¯­ä¸ºä¸»è€Œå¯¼è‡´çš„è¯­è¨€ä¸åŒ¹é…ç°è±¡ï¼Œç ”ç©¶ç³»ç»Ÿè¯„ä¼°äº†é¢„ç¿»è¯‘æˆå•è¯­è¨€æç¤º(mono-lingual prompt)ä¸ç›´æ¥è¿›è¡Œè·¨è¯­è¨€æç¤º(cross-lingual prompting)ä¸¤ç§ç­–ç•¥åœ¨åˆ†ç±»ä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä¼˜åŒ–çš„æç¤ºç­–ç•¥èƒ½æ˜¾è‘—å¢å¼ºè·¨è¯­è¨€çš„çŸ¥è¯†å…±äº«ï¼Œä»è€Œæå‡ä¸‹æ¸¸åˆ†ç±»ä»»åŠ¡çš„å‡†ç¡®æ€§ã€‚è¯¥ç ”ç©¶ä¸ä»…è¯æ˜äº†ä¼˜åŒ–æç¤ºè·¯å¾„å¯¹æ¨¡å‹æ€§èƒ½çš„æå‡ä½œç”¨ï¼Œè¿˜å¼ºè°ƒäº†é’ˆå¯¹éè‹±è¯­å°¤å…¶æ˜¯ä½èµ„æºè¯­è¨€è¿›è¡Œè·¨è¯­è¨€æç¤ºä¼˜åŒ–çš„å¿…è¦æ€§ï¼Œä¸ºæ„å»ºé«˜æ•ˆçš„å¤šè¯­è¨€LLMåº”ç”¨æä¾›äº†å®è¯æ”¯æŒã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at Prompt Optimization KDD '25",
      "pdf_url": "https://arxiv.org/pdf/2507.22923v1",
      "published_date": "2025-07-21 19:37:15 UTC",
      "updated_date": "2025-07-21 19:37:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:53:10.802691+00:00"
    },
    {
      "arxiv_id": "2507.16020v1",
      "title": "Micromobility Flow Prediction: A Bike Sharing Station-level Study via Multi-level Spatial-Temporal Attention Neural Network",
      "title_zh": "å¾®å‡ºè¡Œæµé‡é¢„æµ‹ï¼šåŸºäºå¤šçº§æ—¶ç©ºæ³¨æ„åŠ›ç¥ç»ç½‘ç»œçš„å…±äº«å•è½¦ç«™ç‚¹çº§ç ”ç©¶",
      "authors": [
        "Xi Yang",
        "Jiachen Wang",
        "Song Han",
        "Suining He"
      ],
      "abstract": "Efficient use of urban micromobility resources such as bike sharing is challenging due to the unbalanced station-level demand and supply, which causes the maintenance of the bike sharing systems painstaking. Prior efforts have been made on accurate prediction of bike traffics, i.e., demand/pick-up and return/drop-off, to achieve system efficiency. However, bike station-level traffic prediction is difficult because of the spatial-temporal complexity of bike sharing systems. Moreover, such level of prediction over entire bike sharing systems is also challenging due to the large number of bike stations. To fill this gap, we propose BikeMAN, a multi-level spatio-temporal attention neural network to predict station-level bike traffic for entire bike sharing systems. The proposed network consists of an encoder and a decoder with an attention mechanism representing the spatial correlation between features of bike stations in the system and another attention mechanism describing the temporal characteristic of bike station traffic. Through experimental study on over 10 millions trips of bike sharing systems (> 700 stations) of New York City, our network showed high accuracy in predicting the bike station traffic of all stations in the city.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å…±äº«å•è½¦ç³»ç»Ÿå› ç«™ç‚¹çº§ä¾›éœ€ä¸å¹³è¡¡å¯¼è‡´çš„ç»´æŠ¤éš¾é¢˜ï¼Œæå‡ºäº† BikeMAN æ¡†æ¶ï¼Œè¿™æ˜¯ä¸€ç§æ—¨åœ¨é¢„æµ‹æ•´ä¸ªåŸå¸‚èŒƒå›´å†…ç«™ç‚¹çº§æµé‡çš„å¤šçº§æ—¶ç©ºæ³¨æ„åŠ›ç¥ç»ç½‘ç»œ(multi-level spatio-temporal attention neural network)ã€‚BikeMAN é‡‡ç”¨ç¼–ç å™¨-è§£ç å™¨æ¶æ„ï¼Œå¹¶èåˆäº†ä¸¤ç§å…³é”®çš„æ³¨æ„åŠ›æœºåˆ¶(attention mechanism)ï¼Œåˆ†åˆ«ç”¨äºæ•æ‰ç«™ç‚¹ç‰¹å¾ä¹‹é—´çš„ç©ºé—´ç›¸å…³æ€§(spatial correlation)ä»¥åŠç«™ç‚¹æµé‡çš„æ—¶é—´ç‰¹æ€§(temporal characteristic)ã€‚é€šè¿‡å¯¹çº½çº¦å¸‚è¶…è¿‡1000ä¸‡æ¬¡éª‘è¡Œè®°å½•å’Œ700å¤šä¸ªç«™ç‚¹çš„å®éªŒåˆ†æï¼Œè¯¥æ¨¡å‹åœ¨é¢„æµ‹å…¨å¸‚æ‰€æœ‰ç«™ç‚¹æµé‡æ–¹é¢è¡¨ç°å‡ºæé«˜çš„å‡†ç¡®æ€§ã€‚è¯¥æ–¹æ³•æœ‰æ•ˆè§£å†³äº†å¤§è§„æ¨¡å…±äº«å•è½¦ç³»ç»Ÿåœ¨ç©ºé—´ä¸æ—¶é—´ç»´åº¦ä¸Šçš„å¤æ‚é¢„æµ‹æŒ‘æˆ˜ï¼Œä¸ºæå‡åŸå¸‚å¾®å‡ºè¡Œèµ„æºçš„åˆ©ç”¨æ•ˆç‡æä¾›äº†é‡è¦çš„æŠ€æœ¯æ”¯æ’‘ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "6 pages, UrbComp 2024",
      "pdf_url": "https://arxiv.org/pdf/2507.16020v1",
      "published_date": "2025-07-21 19:31:42 UTC",
      "updated_date": "2025-07-21 19:31:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:53:13.889275+00:00"
    },
    {
      "arxiv_id": "2507.16005v1",
      "title": "AutoMAT: A Hierarchical Framework for Autonomous Alloy Discovery",
      "title_zh": "AutoMATï¼šè‡ªä¸»åˆé‡‘å‘ç°çš„å±‚çº§æ¡†æ¶",
      "authors": [
        "Penghui Yang",
        "Chendong Zhao",
        "Bijun Tang",
        "Zhonghan Zhang",
        "Xinrun Wang",
        "Yanchen Deng",
        "Yuhao Lu",
        "Cuntai Guan",
        "Zheng Liu",
        "Bo An"
      ],
      "abstract": "Alloy discovery is central to advancing modern industry but remains hindered by the vastness of compositional design space and the costly validation. Here, we present AutoMAT, a hierarchical and autonomous framework grounded in and validated by experiments, which integrates large language models, automated CALPHAD-based simulations, and AI-driven search to accelerate alloy design. Spanning the entire pipeline from ideation to validation, AutoMAT achieves high efficiency, accuracy, and interpretability without the need for manually curated large datasets. In a case study targeting a lightweight, high-strength alloy, AutoMAT identifies a titanium alloy with 8.1% lower density and comparable yield strength relative to the state-of-the-art reference, achieving the highest specific strength among all comparisons. In a second case targeting high-yield-strength high-entropy alloys, AutoMAT achieves a 28.2% improvement in yield strength over the base alloy. In both cases, AutoMAT reduces the discovery timeline from years to weeks, illustrating its potential as a scalable and versatile platform for next-generation alloy design.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† AutoMATï¼Œä¸€ä¸ªç”¨äºè‡ªä¸»åˆé‡‘å‘ç°çš„åˆ†å±‚æ¡†æ¶ï¼Œé›†æˆäº† Large Language Models (LLMs)ã€åŸºäº CALPHAD çš„è‡ªåŠ¨åŒ–æ¨¡æ‹Ÿå’Œ AI é©±åŠ¨çš„æœç´¢æŠ€æœ¯ä»¥åŠ é€Ÿåˆé‡‘è®¾è®¡ã€‚è¯¥æ¡†æ¶è¦†ç›–äº†ä»æ„æ€åˆ°éªŒè¯çš„å®Œæ•´æµç¨‹ï¼Œåœ¨æ— éœ€äººå·¥æ•´ç†å¤§è§„æ¨¡æ•°æ®é›†çš„æƒ…å†µä¸‹ï¼Œå®ç°äº†é«˜æ•ˆç‡ã€å‡†ç¡®æ€§å’Œå¯è§£é‡Šæ€§ã€‚åœ¨è½»è´¨é«˜å¼ºåˆé‡‘çš„æ¡ˆä¾‹ç ”ç©¶ä¸­ï¼ŒAutoMAT å‘ç°äº†ä¸€ç§å¯†åº¦æ¯”å‚è€ƒææ–™ä½ 8.1% ä¸”å…·æœ‰åŒç­‰å±ˆæœå¼ºåº¦çš„é’›åˆé‡‘ï¼Œå®ç°äº†å¯¹æ¯”ç»„ä¸­æœ€é«˜çš„æ¯”å¼ºåº¦ã€‚æ­¤å¤–ï¼Œåœ¨é’ˆå¯¹é«˜å±ˆæœå¼ºåº¦ High-Entropy Alloys çš„åº”ç”¨ä¸­ï¼Œè¯¥æ¡†æ¶å°†å±ˆæœå¼ºåº¦æå‡äº† 28.2%ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒAutoMAT å°†åˆé‡‘å‘ç°çš„å‘¨æœŸä»æ•°å¹´ç¼©çŸ­è‡³æ•°å‘¨ï¼Œè¯æ˜äº†å…¶ä½œä¸ºä¸‹ä¸€ä»£åˆé‡‘è®¾è®¡å¯æ‰©å±•ã€é€šç”¨å¹³å°çš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "cond-mat.mtrl-sci",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.16005v1",
      "published_date": "2025-07-21 18:55:03 UTC",
      "updated_date": "2025-07-21 18:55:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:53:19.992714+00:00"
    },
    {
      "arxiv_id": "2507.16002v1",
      "title": "Enhancing Hindi NER in Low Context: A Comparative study of Transformer-based models with vs. without Retrieval Augmentation",
      "title_zh": "æå‡ä½ä¸Šä¸‹æ–‡ç¯å¢ƒä¸‹çš„å°åœ°è¯­å‘½åå®ä½“è¯†åˆ«ï¼šæœ‰æ— æ£€ç´¢å¢å¼ºçš„ Transformer æ¨¡å‹å¯¹æ¯”ç ”ç©¶",
      "authors": [
        "Sumit Singh",
        "Rohit Mishra",
        "Uma Shanker Tiwary"
      ],
      "abstract": "One major challenge in natural language processing is named entity recognition (NER), which identifies and categorises named entities in textual input. In order to improve NER, this study investigates a Hindi NER technique that makes use of Hindi-specific pretrained encoders (MuRIL and XLM-R) and Generative Models ( Llama-2-7B-chat-hf (Llama2-7B), Llama-2-70B-chat-hf (Llama2-70B), Llama-3-70B-Instruct (Llama3-70B) and GPT3.5-turbo), and augments the data with retrieved data from external relevant contexts, notably from Wikipedia. We have fine-tuned MuRIL, XLM-R and Llama2-7B with and without RA. However, Llama2-70B, lama3-70B and GPT3.5-turbo are utilised for few-shot NER generation. Our investigation shows that the mentioned language models (LMs) with Retrieval Augmentation (RA) outperform baseline methods that don't incorporate RA in most cases. The macro F1 scores for MuRIL and XLM-R are 0.69 and 0.495, respectively, without RA and increase to 0.70 and 0.71, respectively, in the presence of RA. Fine-tuned Llama2-7B outperforms Llama2-7B by a significant margin. On the other hand the generative models which are not fine-tuned also perform better with augmented data. GPT3.5-turbo adopted RA well; however, Llama2-70B and llama3-70B did not adopt RA with our retrieval context. The findings show that RA significantly improves performance, especially for low-context data. This study adds significant knowledge about how best to use data augmentation methods and pretrained models to enhance NER performance, particularly in languages with limited resources.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä½ä¸Šä¸‹æ–‡ç¯å¢ƒä¸‹çš„å°åœ°è¯­å‘½åå®ä½“è¯†åˆ«(Named Entity Recognition, NER)æŒ‘æˆ˜ï¼Œå¯¹æ¯”åˆ†æäº†åŸºäºTransformerçš„æ¨¡å‹åœ¨ç»“åˆä¸ä¸ç»“åˆæ£€ç´¢å¢å¼ºæŠ€æœ¯(Retrieval Augmentation, RA)ä¸‹çš„è¡¨ç°ã€‚å®éªŒæ¶µç›–äº†MuRILã€XLM-Rç­‰é¢„è®­ç»ƒç¼–ç å™¨ï¼Œä»¥åŠLlama-2-7Bã€Llama2-70Bã€Llama-3-70Bå’ŒGPT3.5-turboç­‰ç”Ÿæˆå¼æ¨¡å‹ã€‚ç ”ç©¶é€šè¿‡ä»Wikipediaæ£€ç´¢ç›¸å…³å¤–éƒ¨ä¸Šä¸‹æ–‡æ¥å¢å¼ºè¾“å…¥æ•°æ®ï¼Œå¹¶å¯¹éƒ¨åˆ†æ¨¡å‹è¿›è¡Œå¾®è°ƒæˆ–é‡‡ç”¨Few-shotç”Ÿæˆæ–¹å¼ã€‚ç»“æœè¡¨æ˜ï¼Œåœ¨å¤§å¤šæ•°æƒ…å†µä¸‹ï¼Œç»“åˆRAçš„æ¨¡å‹æ€§èƒ½æ˜¾è‘—ä¼˜äºåŸºçº¿æ¨¡å‹ï¼Œå…¶ä¸­XLM-Rçš„Macro F1åˆ†æ•°ä»0.495æå‡è‡³0.71ï¼ŒMuRILä¹Ÿä»0.69æå‡è‡³0.70ã€‚å°½ç®¡GPT3.5-turboèƒ½å¤Ÿè‰¯å¥½é€‚åº”RAï¼Œä½†Llama2-70Bå’ŒLlama3-70Båœ¨å½“å‰æ£€ç´¢ä¸Šä¸‹æ–‡ä¸‹çš„è¡¨ç°æå‡å¹¶ä¸æ˜æ˜¾ã€‚è¯¥å‘ç°è¯å®äº†RAåœ¨æå‡èµ„æºåŒ®ä¹è¯­è¨€NERæ€§èƒ½æ–¹é¢çš„æœ‰æ•ˆæ€§ï¼Œç‰¹åˆ«æ˜¯åœ¨ä½ä¸Šä¸‹æ–‡æ•°æ®åœºæ™¯ä¸‹å…·æœ‰é‡è¦åº”ç”¨ä»·å€¼ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.16002v1",
      "published_date": "2025-07-21 18:41:58 UTC",
      "updated_date": "2025-07-21 18:41:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:53:21.095095+00:00"
    },
    {
      "arxiv_id": "2507.15979v2",
      "title": "Dream, Lift, Animate: From Single Images to Animatable Gaussian Avatars",
      "title_zh": "Dream, Lift, Animateï¼šä»å•å¼ å›¾åƒåˆ°å¯åŠ¨ç”»é«˜æ–¯æ•°å­—äºº",
      "authors": [
        "Marcel C. BÃ¼hler",
        "Ye Yuan",
        "Xueting Li",
        "Yangyi Huang",
        "Koki Nagano",
        "Umar Iqbal"
      ],
      "abstract": "We introduce Dream, Lift, Animate (DLA), a novel framework that reconstructs animatable 3D human avatars from a single image. This is achieved by leveraging multi-view generation, 3D Gaussian lifting, and pose-aware UV-space mapping of 3D Gaussians. Given an image, we first dream plausible multi-views using a video diffusion model, capturing rich geometric and appearance details. These views are then lifted into unstructured 3D Gaussians. To enable animation, we propose a transformer-based encoder that models global spatial relationships and projects these Gaussians into a structured latent representation aligned with the UV space of a parametric body model. This latent code is decoded into UV-space Gaussians that can be animated via body-driven deformation and rendered conditioned on pose and viewpoint. By anchoring Gaussians to the UV manifold, our method ensures consistency during animation while preserving fine visual details. DLA enables real-time rendering and intuitive editing without requiring post-processing. Our method outperforms state-of-the-art approaches on the ActorsHQ and 4D-Dress datasets in both perceptual quality and photometric accuracy. By combining the generative strengths of video diffusion models with a pose-aware UV-space Gaussian mapping, DLA bridges the gap between unstructured 3D representations and high-fidelity, animation-ready avatars.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Dream, Lift, Animate (DLA) æ¡†æ¶ï¼Œæ—¨åœ¨ä»…é€šè¿‡å•å¼ å›¾åƒé‡å»ºå¯åŠ¨ç”»åŒ–çš„ 3D äººä½“åŒ–èº«ã€‚è¯¥æ–¹æ³•é¦–å…ˆåˆ©ç”¨ Video Diffusion æ¨¡å‹ç”Ÿæˆå…·æœ‰ä¸°å¯Œå‡ ä½•ä¸å¤–è§‚ç»†èŠ‚çš„å¤šè§†è§’å›¾åƒï¼Œå¹¶å°†å…¶æå‡ä¸ºéç»“æ„åŒ–çš„ 3D Gaussiansã€‚ä¸ºäº†å®ç°åŠ¨ç”»åŒ–ï¼Œç ”ç©¶äººå‘˜è®¾è®¡äº†ä¸€ä¸ªåŸºäº Transformer çš„ç¼–ç å™¨ï¼Œå°†è¿™äº› Gaussians æ˜ å°„åˆ°ä¸å‚æ•°åŒ–äººä½“æ¨¡å‹ UV ç©ºé—´å¯¹é½çš„ç»“æ„åŒ–æ½œåœ¨è¡¨ç¤ºä¸­ã€‚é€šè¿‡å°† Gaussians é”šå®šåœ¨ UV æµå½¢ä¸Šï¼ŒDLA ç¡®ä¿äº†åœ¨ Pose é©±åŠ¨çš„å˜å½¢è¿‡ç¨‹ä¸­ä¿æŒä¸€è‡´æ€§ï¼Œå¹¶èƒ½æ ¹æ®è§†è§’è¿›è¡Œå®æ—¶æ¸²æŸ“ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒDLA åœ¨ ActorsHQ å’Œ 4D-Dress æ•°æ®é›†ä¸Šçš„æ„ŸçŸ¥è´¨é‡å’Œå…‰åº¦å‡†ç¡®åº¦å‡è¶…è¶Šäº†ç°æœ‰æœ€å…ˆè¿›æŠ€æœ¯ã€‚è¯¥æ¡†æ¶ä¸ä»…æ”¯æŒç›´è§‚çš„ç¼–è¾‘ï¼Œè¿˜æˆåŠŸå¡«åˆäº†éç»“æ„åŒ– 3D è¡¨ç¤ºä¸é«˜ä¿çœŸã€å¯åŠ¨ç”»åŒ–åŒ–èº«ä¹‹é—´çš„æŠ€æœ¯é¸¿æ²Ÿã€‚",
      "categories": [
        "cs.GR",
        "cs.AI"
      ],
      "primary_category": "cs.GR",
      "comment": "Accepted to 3DV 2026",
      "pdf_url": "https://arxiv.org/pdf/2507.15979v2",
      "published_date": "2025-07-21 18:20:09 UTC",
      "updated_date": "2025-11-17 13:55:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:53:24.988998+00:00"
    },
    {
      "arxiv_id": "2507.15977v1",
      "title": "On the transferability of Sparse Autoencoders for interpreting compressed models",
      "title_zh": "è®ºç¨€ç–è‡ªç¼–ç å™¨åœ¨å‹ç¼©æ¨¡å‹è§£é‡Šä¸­çš„å¯è¿ç§»æ€§",
      "authors": [
        "Suchit Gupte",
        "Vishnu Kabir Chhabra",
        "Mohammad Mahdi Khalili"
      ],
      "abstract": "Modern LLMs face inference efficiency challenges due to their scale. To address this, many compression methods have been proposed, such as pruning and quantization. However, the effect of compression on a model's interpretability remains elusive. While several model interpretation approaches exist, such as circuit discovery, Sparse Autoencoders (SAEs) have proven particularly effective in decomposing a model's activation space into its feature basis. In this work, we explore the differences in SAEs for the original and compressed models. We find that SAEs trained on the original model can interpret the compressed model albeit with slight performance degradation compared to the trained SAE on the compressed model. Furthermore, simply pruning the original SAE itself achieves performance comparable to training a new SAE on the pruned model. This finding enables us to mitigate the extensive training costs of SAEs.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†æ¨¡å‹å‹ç¼©(compression)å¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)å¯è§£é‡Šæ€§çš„å½±å“ï¼Œé‡ç‚¹åˆ†æäº†ç¨€ç–è‡ªç¼–ç å™¨(Sparse Autoencoders, SAEs)åœ¨åŸå§‹æ¨¡å‹ä¸å‹ç¼©æ¨¡å‹ä¹‹é—´çš„å¯è¿ç§»æ€§ã€‚é’ˆå¯¹å‰ªæ(pruning)å’Œé‡åŒ–(quantization)ç­‰æ—¨åœ¨æé«˜æ¨ç†æ•ˆç‡çš„æŠ€æœ¯ï¼Œç ”ç©¶å‘ç°ç›´æ¥åœ¨åŸå§‹æ¨¡å‹ä¸Šè®­ç»ƒçš„SAEsä»èƒ½æœ‰æ•ˆè§£é‡Šå‹ç¼©åçš„æ¨¡å‹ï¼Œä»…ä¼´éšè½»å¾®çš„æ€§èƒ½ä¸‹é™ã€‚æ­¤å¤–ï¼Œç ”ç©¶æå‡ºé€šè¿‡å¯¹åŸå§‹SAEè¿›è¡Œå‰ªæå¤„ç†ï¼Œå…¶æ€§èƒ½è¡¨ç°å¯ä¸åœ¨å‰ªææ¨¡å‹ä¸Šé‡æ–°è®­ç»ƒçš„SAEç›¸åª²ç¾ã€‚è¿™ä¸€å‘ç°ä¸ä»…è¯æ˜äº†æ¨¡å‹ç‰¹å¾åŸºå…ƒåœ¨å‹ç¼©è¿‡ç¨‹ä¸­çš„ä¸€è‡´æ€§ï¼Œä¹Ÿä¸ºç¼“è§£SAEsé«˜æ˜‚çš„è®­ç»ƒæˆæœ¬æä¾›äº†é«˜æ•ˆçš„æ›¿ä»£æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.15977v1",
      "published_date": "2025-07-21 18:17:18 UTC",
      "updated_date": "2025-07-21 18:17:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:53:38.484654+00:00"
    },
    {
      "arxiv_id": "2507.16861v2",
      "title": "Look Before You Fuse: 2D-Guided Cross-Modal Alignment for Robust 3D Detection",
      "title_zh": "å…ˆå¯¹é½åèåˆï¼šé¢å‘é²æ£’3Dæ£€æµ‹çš„2Då¼•å¯¼è·¨æ¨¡æ€å¯¹é½",
      "authors": [
        "Xiang Li",
        "Zhangchi Hu",
        "Xiao Xu",
        "Bin Kong"
      ],
      "abstract": "Integrating LiDAR and camera inputs into a unified Bird's-Eye-View (BEV) representation is crucial for enhancing 3D perception capabilities of autonomous vehicles. However, existing methods suffer from spatial misalignment between LiDAR and camera features, which causes inaccurate depth supervision in camera branch and erroneous fusion during cross-modal feature aggregation. The root cause of this misalignment lies in projection errors, stemming from calibration inaccuracies and rolling shutter effect. The key insight of this work is that locations of these projection errors are not random but highly predictable, as they are concentrated at object-background boundaries which 2D detectors can reliably identify. Based on this, our main motivation is to utilize 2D object priors to pre-align cross-modal features before fusion. To address local misalignment, we propose Prior Guided Depth Calibration (PGDC), which leverages 2D priors to alleviate misalignment and preserve correct cross-modal feature pairs. To resolve global misalignment, we introduce Discontinuity Aware Geometric Fusion (DAGF) to suppress residual noise from PGDC and explicitly enhance sharp depth transitions at object-background boundaries, yielding a structurally aware representation. To effectively utilize these aligned representations, we incorporate Structural Guidance Depth Modulator (SGDM), using a gated attention mechanism to efficiently fuse aligned depth and image features. Our method achieves SOTA performance on nuScenes validation dataset, with its mAP and NDS reaching 71.5% and 73.6% respectively",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è‡ªåŠ¨é©¾é©¶ä¸­LiDARä¸ç›¸æœºèåˆåœ¨é¸Ÿç°å›¾(BEV)è¡¨ç¤ºä¸­çš„ç©ºé—´å¤±å‡†é—®é¢˜ï¼ŒæŒ‡å‡ºæ ¡å‡†åå·®å’Œæ»šåŠ¨å¿«é—¨æ•ˆåº”å¼•èµ·çš„æŠ•å½±è¯¯å·®ä¸»è¦é›†ä¸­åœ¨ç‰©ä½“ä¸èƒŒæ™¯çš„è¾¹ç•Œå¤„ã€‚ä½œè€…æå‡ºåˆ©ç”¨2Dç›®æ ‡å…ˆéªŒåœ¨èåˆå‰é¢„å¯¹é½è·¨æ¨¡æ€ç‰¹å¾ï¼Œå¹¶è®¾è®¡äº†å…ˆéªŒå¼•å¯¼æ·±åº¦æ ¡å‡†(PGDC)æ¥ç¼“è§£å±€éƒ¨å¤±å‡†å¹¶ä¿ç•™æ­£ç¡®çš„ç‰¹å¾å¯¹ã€‚ä¸ºè§£å†³å…¨å±€å¤±å‡†ï¼Œç ”ç©¶å¼•å…¥äº†ä¸è¿ç»­æ„ŸçŸ¥å‡ ä½•èåˆ(DAGF)ä»¥æŠ‘åˆ¶æ®‹ä½™å™ªå£°å¹¶å¢å¼ºè¾¹ç•Œå¤„çš„æ·±åº¦è¿‡æ¸¡ï¼Œä»è€Œæ„å»ºç»“æ„æ„ŸçŸ¥è¡¨ç¤ºã€‚æ­¤å¤–ï¼Œé€šè¿‡ç»“æ„å¼•å¯¼æ·±åº¦è°ƒåˆ¶å™¨(SGDM)åˆ©ç”¨é—¨æ§æ³¨æ„åŠ›æœºåˆ¶é«˜æ•ˆèåˆå¯¹é½çš„æ·±åº¦å’Œå›¾åƒç‰¹å¾ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨nuSceneséªŒè¯é›†ä¸Šè¾¾åˆ°äº†SOTAæ€§èƒ½ï¼ŒmAPå’ŒNDSåˆ†åˆ«è¾¾åˆ°71.5%å’Œ73.6%ï¼Œè¯æ˜äº†è¯¥æ–¹æ¡ˆåœ¨å®ç°é²æ£’3Dæ£€æµ‹æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.16861v2",
      "published_date": "2025-07-21 18:12:22 UTC",
      "updated_date": "2025-08-07 07:24:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:54:12.287934+00:00"
    },
    {
      "arxiv_id": "2507.15974v1",
      "title": "Does More Inference-Time Compute Really Help Robustness?",
      "title_zh": "å¢åŠ æ¨ç†æ—¶è®¡ç®—é‡æ˜¯å¦çœŸèƒ½æå‡é²æ£’æ€§ï¼Ÿ",
      "authors": [
        "Tong Wu",
        "Chong Xiang",
        "Jiachen T. Wang",
        "Weichen Yu",
        "Chawin Sitawarin",
        "Vikash Sehwag",
        "Prateek Mittal"
      ],
      "abstract": "Recently, Zaremba et al. demonstrated that increasing inference-time computation improves robustness in large proprietary reasoning LLMs. In this paper, we first show that smaller-scale, open-source models (e.g., DeepSeek R1, Qwen3, Phi-reasoning) can also benefit from inference-time scaling using a simple budget forcing strategy. More importantly, we reveal and critically examine an implicit assumption in prior work: intermediate reasoning steps are hidden from adversaries. By relaxing this assumption, we identify an important security risk, intuitively motivated and empirically verified as an inverse scaling law: if intermediate reasoning steps become explicitly accessible, increased inference-time computation consistently reduces model robustness. Finally, we discuss practical scenarios where models with hidden reasoning chains are still vulnerable to attacks, such as models with tool-integrated reasoning and advanced reasoning extraction attacks. Our findings collectively demonstrate that the robustness benefits of inference-time scaling depend heavily on the adversarial setting and deployment context. We urge practitioners to carefully weigh these subtle trade-offs before applying inference-time scaling in security-sensitive, real-world applications.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¢åŠ æ¨ç†æ—¶é—´è®¡ç®—(Inference-time compute)æ˜¯å¦çœŸçš„èƒ½æé«˜å¤§è¯­è¨€æ¨¡å‹çš„é²æ£’æ€§(Robustness)ã€‚ç ”ç©¶é¦–å…ˆè¯æ˜ï¼Œé€šè¿‡ç®€å•çš„é¢„ç®—å¼ºåˆ¶ç­–ç•¥(Budget forcing strategy)ï¼ŒDeepSeek R1å’ŒQwen3ç­‰å¼€æºæ¨¡å‹ä¹Ÿèƒ½ä»æ¨ç†æ—¶é—´ç¼©æ”¾ä¸­è·ç›Šã€‚ç„¶è€Œï¼Œä½œè€…æ­ç¤ºå¹¶æ‰¹åˆ¤æ€§åœ°å®¡æŸ¥äº†å…ˆå‰ç ”ç©¶ä¸­çš„ä¸€ä¸ªéšå«å‡è®¾ï¼Œå³ä¸­é—´æ¨ç†æ­¥éª¤å¯¹æ”»å‡»è€…æ˜¯éšè—çš„ã€‚é€šè¿‡æ”¾å®½è¿™ä¸€å‡è®¾ï¼Œç ”ç©¶å‘ç°äº†ä¸€ä¸ªé€†ç¼©æ”¾å®šå¾‹(Inverse scaling law)ï¼šå¦‚æœä¸­é—´æ¨ç†æ­¥éª¤è¢«å…¬å¼€è®¿é—®ï¼Œå¢åŠ æ¨ç†æ—¶é—´è®¡ç®—åè€Œä¼šæŒç»­é™ä½æ¨¡å‹çš„é²æ£’æ€§ã€‚è®ºæ–‡è¿›ä¸€æ­¥è®¨è®ºäº†åœ¨å·¥å…·é›†æˆæ¨ç†å’Œæ¨ç†æå–æ”»å‡»ç­‰å®é™…åœºæ™¯ä¸‹çš„å®‰å…¨é£é™©ã€‚è¿™äº›å‘ç°è¡¨æ˜ï¼Œæ¨ç†æ—¶é—´ç¼©æ”¾å¸¦æ¥çš„é²æ£’æ€§æ”¶ç›Šåœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šå–å†³äºå¯¹æŠ—ç¯å¢ƒå’Œéƒ¨ç½²ä¸Šä¸‹æ–‡ã€‚ä½œè€…æœ€åæ•¦ä¿ƒä»ä¸šè€…åœ¨å®‰å…¨æ•æ„Ÿçš„ç°å®åº”ç”¨ä¸­åº”ç”¨è¯¥æŠ€æœ¯å‰ï¼Œåº”ä»”ç»†æƒè¡¡è¿™äº›å¾®å¦™çš„æƒè¡¡å…³ç³»ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Preprint",
      "pdf_url": "https://arxiv.org/pdf/2507.15974v1",
      "published_date": "2025-07-21 18:08:38 UTC",
      "updated_date": "2025-07-21 18:08:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:54:10.990630+00:00"
    },
    {
      "arxiv_id": "2507.15970v2",
      "title": "Nonlinear Framework for Speech Bandwidth Extension",
      "title_zh": "è¯­éŸ³å¸¦å®½æ‰©å±•çš„éçº¿æ€§æ¡†æ¶",
      "authors": [
        "Tarikul Islam Tamiti",
        "Nursad Mamun",
        "Anomadarshi Barua"
      ],
      "abstract": "Recovering high-frequency components lost to bandwidth constraints is crucial for applications ranging from telecommunications to high-fidelity audio on limited resources. We introduce NDSI-BWE, a new adversarial Band Width Extension (BWE) framework that leverage four new discriminators inspired by nonlinear dynamical system to capture diverse temporal behaviors: a Multi-Resolution Lyapunov Discriminator (MRLD) for determining sensitivity to initial conditions by capturing deterministic chaos, a Multi-Scale Recurrence Discriminator (MS-RD) for self-similar recurrence dynamics, a Multi-Scale Detrended Fractal Analysis Discriminator (MSDFA) for long range slow variant scale invariant relationship, a Multi-Resolution PoincarÃ© Plot Discriminator (MR-PPD) for capturing hidden latent space relationship, a Multi-Period Discriminator (MPD) for cyclical patterns, a Multi-Resolution Amplitude Discriminator (MRAD) and Multi-Resolution Phase Discriminator (MRPD) for capturing intricate amplitude-phase transition statistics. By using depth-wise convolution at the core of the convolutional block with in each discriminators, NDSI-BWE attains an eight-times parameter reduction. These seven discriminators guide a complex-valued ConformerNeXt based genetor with a dual stream Lattice-Net based architecture for simultaneous refinement of magnitude and phase. The genertor leverage the transformer based conformer's global dependency modeling and ConvNeXt block's local temporal modeling capability. Across six objective evaluation metrics and subjective based texts comprises of five human judges, NDSI-BWE establishes a new SoTA in BWE.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† NDSI-BWEï¼Œä¸€ç§å—éçº¿æ€§åŠ¨åŠ›ç³»ç»Ÿå¯å‘çš„å¯¹æŠ—å¼è¯­éŸ³ Bandwidth Extension (BWE) æ¡†æ¶ï¼Œæ—¨åœ¨é«˜æ•ˆæ¢å¤å—é™èµ„æºä¸‹çš„é«˜é¢‘éŸ³é¢‘æˆåˆ†ã€‚è¯¥æ¡†æ¶åˆ›æ–°æ€§åœ°å¼•å…¥äº† Multi-Resolution Lyapunov Discriminator (MRLD)ã€Multi-Scale Recurrence Discriminator (MS-RD) åŠ Multi-Scale Detrended Fractal Analysis Discriminator (MSDFA) ç­‰ä¸ƒç§æ–°å‹åˆ¤åˆ«å™¨ï¼Œç”¨ä»¥æ•æ‰éŸ³é¢‘ä¸­çš„ç¡®å®šæ€§æ··æ²Œã€è‡ªç›¸ä¼¼å¾ªç¯åŠ¨åŠ›å­¦åŠé•¿ç¨‹å°ºåº¦ä¸å˜å…³ç³»ç­‰å¤æ‚æ—¶åŸŸè¡Œä¸ºã€‚å…¶ç”Ÿæˆå™¨é‡‡ç”¨åŸºäºå¤æ•°å€¼çš„ ConformerNeXt æ¶æ„å¹¶ç»“åˆåŒæµ Lattice-Net ç»“æ„ï¼Œæœ‰æ•ˆèåˆäº†å…¨å±€ä¾èµ–å»ºæ¨¡ä¸å±€éƒ¨æ—¶åŸŸå»ºæ¨¡èƒ½åŠ›ï¼Œå®ç°äº†å¯¹å¹…åº¦å’Œç›¸ä½çš„åŒæ­¥ç²¾ç‚¼ã€‚é€šè¿‡åœ¨åˆ¤åˆ«å™¨æ ¸å¿ƒå¼•å…¥ depth-wise convolutionï¼ŒNDSI-BWE åœ¨ä¿æŒé«˜æ€§èƒ½çš„åŒæ—¶å®ç°äº†å…«å€çš„å‚æ•°é‡ç¼©å‡ã€‚åœ¨å…­é¡¹å®¢è§‚è¯„ä¼°æŒ‡æ ‡åŠäººå·¥ä¸»è§‚è¯„æµ‹ä¸­ï¼ŒNDSI-BWE å‡è¾¾åˆ°äº†æ–°çš„ State-of-the-Art (SoTA) æ°´å¹³ï¼Œä¸ºé«˜ä¿çœŸéŸ³é¢‘é‡å»ºæä¾›äº†é«˜æ•ˆä¸”ç²¾å‡†çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.15970v2",
      "published_date": "2025-07-21 18:06:29 UTC",
      "updated_date": "2025-10-01 16:47:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:53:51.252257+00:00"
    },
    {
      "arxiv_id": "2507.15961v2",
      "title": "A Lightweight Face Quality Assessment Framework to Improve Face Verification Performance in Real-Time Screening Applications",
      "title_zh": "ä¸€ç§æå‡å®æ—¶ç­›é€‰åº”ç”¨ä¸­äººè„¸éªŒè¯æ€§èƒ½çš„è½»é‡çº§äººè„¸è´¨é‡è¯„ä¼°æ¡†æ¶",
      "authors": [
        "Ahmed Aman Ibrahim",
        "Hamad Mansour Alawar",
        "Abdulnasser Abbas Zehi",
        "Ahmed Mohammad Alkendi",
        "Bilal Shafi Ashfaq Ahmed Mirza",
        "Shan Ullah",
        "Ismail Lujain Jaleel",
        "Hassan Ugail"
      ],
      "abstract": "Face image quality plays a critical role in determining the accuracy and reliability of face verification systems, particularly in real-time screening applications such as surveillance, identity verification, and access control. Low-quality face images, often caused by factors such as motion blur, poor lighting conditions, occlusions, and extreme pose variations, significantly degrade the performance of face recognition models, leading to higher false rejection and false acceptance rates. In this work, we propose a lightweight yet effective framework for automatic face quality assessment, which aims to pre-filter low-quality face images before they are passed to the verification pipeline. Our approach utilises normalised facial landmarks in conjunction with a Random Forest Regression classifier to assess image quality, achieving an accuracy of 96.67%. By integrating this quality assessment module into the face verification process, we observe a substantial improvement in performance, including a comfortable 99.7% reduction in the false rejection rate and enhanced cosine similarity scores when paired with the ArcFace face verification model. To validate our approach, we have conducted experiments on a real-world dataset collected comprising over 600 subjects captured from CCTV footage in unconstrained environments within Dubai Police. Our results demonstrate that the proposed framework effectively mitigates the impact of poor-quality face images, outperforming existing face quality assessment techniques while maintaining computational efficiency. Moreover, the framework specifically addresses two critical challenges in real-time screening: variations in face resolution and pose deviations, both of which are prevalent in practical surveillance scenarios.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å®æ—¶ç›‘æ§å’Œèº«ä»½éªŒè¯ä¸­çš„äººè„¸è¯†åˆ«æ€§èƒ½é€€åŒ–é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§è½»é‡çº§çš„äººè„¸è´¨é‡è¯„ä¼°(Face Quality Assessment)æ¡†æ¶ã€‚è¯¥æ–¹æ³•åˆ©ç”¨å½’ä¸€åŒ–çš„äººè„¸å…³é”®ç‚¹(facial landmarks)ç»“åˆéšæœºæ£®æ—å›å½’(Random Forest Regression)åˆ†ç±»å™¨æ¥è‡ªåŠ¨é¢„è¿‡æ»¤ä½è´¨é‡å›¾åƒï¼Œæ—¨åœ¨è§£å†³è¿åŠ¨æ¨¡ç³Šã€å…‰ç…§ä¸è¶³åŠå§¿æ€åå·®å¯¼è‡´çš„è¯†åˆ«è¯¯å·®ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ¡†æ¶åœ¨è´¨é‡è¯„ä¼°ä¸Šçš„å‡†ç¡®ç‡è¾¾åˆ°96.67%ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæå‡åç»­è¯†åˆ«æ¨¡å‹çš„å¯é æ€§ã€‚é€šè¿‡å°†è¯¥æ¨¡å—é›†æˆåˆ°ArcFaceéªŒè¯æµç¨‹ä¸­ï¼Œç ”ç©¶å®ç°äº†é”™è¯¯æ‹’ç»ç‡(False Rejection Rate)é«˜è¾¾99.7%çš„æ˜¾è‘—é™å¹…ï¼Œå¹¶å¤§å¹…æå‡äº†ä½™å¼¦ç›¸ä¼¼åº¦(cosine similarity)åˆ†æ•°ã€‚åŸºäºè¿ªæ‹œè­¦å¯Ÿ(Dubai Police)æä¾›çš„çœŸå®ç›‘æ§æ•°æ®é›†éªŒè¯è¡¨æ˜ï¼Œè¯¥æ¡†æ¶åœ¨ä¿æŒé«˜è®¡ç®—æ•ˆç‡çš„åŒæ—¶ï¼Œå…¶æ€§èƒ½æ˜¾è‘—ä¼˜äºç°æœ‰çš„è´¨é‡è¯„ä¼°æŠ€æœ¯ã€‚è¯¥ç ”ç©¶ç‰¹åˆ«è§£å†³äº†å®æ—¶ç­›é€‰ä¸­å¸¸è§çš„äººè„¸åˆ†è¾¨ç‡(face resolution)å’Œå§¿æ€åå·®(pose deviations)ä¸¤å¤§æ ¸å¿ƒæŒ‘æˆ˜ï¼Œä¸ºå®é™…ç›‘æ§åœºæ™¯æä¾›äº†é«˜æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.15961v2",
      "published_date": "2025-07-21 18:04:14 UTC",
      "updated_date": "2025-07-27 20:09:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:53:51.939546+00:00"
    },
    {
      "arxiv_id": "2507.15958v3",
      "title": "Quantization-Aware Neuromorphic Architecture for Skin Disease Classification on Resource-Constrained Devices",
      "title_zh": "é¢å‘èµ„æºå—é™è®¾å¤‡çš®è‚¤ç—…åˆ†ç±»çš„é‡åŒ–æ„ŸçŸ¥ç¥ç»å½¢æ€æ¶æ„",
      "authors": [
        "Haitian Wang",
        "Xinyu Wang",
        "Yiren Wang",
        "Bo Miao",
        "Atif Mansoor"
      ],
      "abstract": "On-device skin lesion analysis is constrained by the compute and energy cost of conventional CNN inference and by the need to update models as new patient data become available. We propose QANA, a quantization-aware CNN backbone embedded in an end-to-end pipeline engineered for conversion-stable neuromorphic execution. QANA replaces conversion-fragile components with spike-compatible transformations by bounding intermediate activations and aligning normalization with low-bit quantization, reducing conversion-induced distortion that disproportionately impacts rare classes. Efficiency is achieved through Ghost-based feature generation under tight FLOP budgets, while spatially-aware efficient channel attention and squeeze-and-excitation recalibrate channels without heavy global operators that are difficult to map to spiking cores. The resulting quantized projection head produces SNN-ready logits and enables incremental updates on edge hardware without full retraining or data offloading. On HAM10000, QANA achieves 91.6% Top-1 accuracy and 91.0% macro F1, improving the strongest converted SNN baseline by 3.5 percentage points in Top-1 accuracy, corresponding to a 4.0% relative gain, and by 12.0 points in macro F1, corresponding to a 15.2% relative gain. On a clinical dataset, QANA achieves 90.8% Top-1 accuracy and 81.7% macro F1, improving the strongest converted SNN baseline by 3.2 points in Top-1 accuracy, which corresponds to a 3.7% relative gain, and by 3.6 points in macro F1, corresponding to a 4.6% relative gain. When deployed on BrainChip Akida, QANA runs in 1.5 ms per image with 1.7 mJ per image, corresponding to 94.6% lower latency and 99.0% lower energy than its GPU-based CNN implementation.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† QANAï¼Œä¸€ç§ä¸“ä¸ºèµ„æºå—é™è®¾å¤‡ä¸Šçš„çš®è‚¤ç—…åˆ†ç±»è®¾è®¡çš„é‡åŒ–æ„ŸçŸ¥ç¥ç»å½¢æ€æ¶æ„ (Quantization-Aware Neuromorphic Architecture)ã€‚è¯¥æ¶æ„é€šè¿‡å°†é‡åŒ–æ„ŸçŸ¥ CNN éª¨å¹²ç½‘ç»œåµŒå…¥ç«¯åˆ°ç«¯æµç¨‹ï¼Œé‡‡ç”¨è„‰å†²å…¼å®¹å˜æ¢ (spike-compatible transformations) æ›¿æ¢æ˜“æŸç»„ä»¶ï¼Œå¹¶ç»“åˆä½æ¯”ç‰¹é‡åŒ– (low-bit quantization) å‡å°‘è½¬æ¢å¼•èµ·çš„å¤±çœŸï¼Œä»è€Œæœ‰æ•ˆæå‡äº†å¯¹ç¨€æœ‰ç±»åˆ«çš„è¯†åˆ«ç²¾åº¦ã€‚QANA åˆ©ç”¨ Ghost-based ç‰¹å¾ç”Ÿæˆã€ç©ºé—´æ„ŸçŸ¥é€šé“æ³¨æ„åŠ›å’ŒæŒ¤å‹æ¿€åŠ± (squeeze-and-excitation) æœºåˆ¶åœ¨æä½è®¡ç®—é¢„ç®—ä¸‹ä¼˜åŒ–æ€§èƒ½ï¼Œå¹¶æ”¯æŒåœ¨è¾¹ç¼˜ç¡¬ä»¶ä¸Šè¿›è¡Œå¢é‡æ›´æ–°è€Œæ— éœ€å®Œæ•´é‡è®­ã€‚å®éªŒè¡¨æ˜ï¼ŒQANA åœ¨ HAM10000 æ•°æ®é›†ä¸Šå–å¾—äº† 91.6% çš„ Top-1 å‡†ç¡®ç‡ï¼Œå® F1 å€¼è¾ƒæœ€å¼º SNN åŸºå‡†æå‡äº† 12 ä¸ªç™¾åˆ†ç‚¹ã€‚åœ¨ BrainChip Akida èŠ¯ç‰‡ä¸Šçš„éƒ¨ç½²ç»“æœæ˜¾ç¤ºï¼Œè¯¥æ¨¡å‹å•å¼ å›¾åƒå¤„ç†ä»…éœ€ 1.5 ms å’Œ 1.7 mJï¼Œæ¯”ä¼ ç»Ÿ GPU ç«¯çš„ CNN å®ç°é™ä½äº† 94.6% çš„å»¶è¿Ÿå’Œ 99.0% çš„èƒ½è€—ï¼Œä¸ºä¸´åºŠç«¯ä¾§çš„é«˜æ•ˆçš®è‚¤ç—…åˆ†ææä¾›äº†å¯è¡Œæ–¹æ¡ˆã€‚",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.15958v3",
      "published_date": "2025-07-21 18:01:44 UTC",
      "updated_date": "2026-01-13 00:55:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:53:58.348315+00:00"
    },
    {
      "arxiv_id": "2507.15857v7",
      "title": "Diffusion Beats Autoregressive in Data-Constrained Settings",
      "title_zh": "æ•°æ®å—é™åœºæ™¯ä¸‹æ‰©æ•£æ¨¡å‹ä¼˜äºè‡ªå›å½’æ¨¡å‹",
      "authors": [
        "Mihir Prabhudesai",
        "Mengning Wu",
        "Amir Zadeh",
        "Katerina Fragkiadaki",
        "Deepak Pathak"
      ],
      "abstract": "Autoregressive (AR) models have long dominated the landscape of large language models, driving progress across a wide range of tasks. Recently, diffusion-based language models have emerged as a promising alternative, though their advantages over AR models remain underexplored. In this paper, we systematically study masked diffusion models in data-constrained settings where training involves repeated passes over limited data and find that they significantly outperform AR models when compute is abundant but data is scarce. Diffusion models make better use of repeated data, achieving lower validation loss and superior downstream performance. We find new scaling laws for diffusion models and derive a closed-form expression for the critical compute threshold at which diffusion begins to outperform AR. Finally, we explain why diffusion models excel in this regime: their randomized masking objective implicitly trains over a rich distribution of token orderings, acting as an implicit data augmentation that AR's fixed left-to-right factorization lacks. Our results suggest that when data, not compute, is the bottleneck, diffusion models offer a compelling alternative to the standard AR paradigm. Our code is available at: https://diffusion-scaling.github.io.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è®¡ç®—èµ„æºå……è¶³ä½†æ•°æ®åŒ®ä¹çš„æ•°æ®å—é™(Data-Constrained Settings)åœºæ™¯ï¼Œç³»ç»Ÿæ€§åœ°æ¯”è¾ƒäº†æ©ç æ‰©æ•£æ¨¡å‹(Masked Diffusion Models)ä¸ä¸»æµçš„è‡ªå›å½’(Autoregressive)æ¨¡å‹ã€‚å®éªŒå‘ç°ï¼Œåœ¨è¿™ç§ç‰¹å®šæƒ…å¢ƒä¸‹ï¼Œæ‰©æ•£æ¨¡å‹åœ¨å¤„ç†é‡å¤æ•°æ®æ–¹é¢è¡¨ç°å‡ºæ˜¾è‘—ä¼˜åŠ¿ï¼Œèƒ½å®ç°æ›´ä½çš„éªŒè¯æŸå¤±å’Œæ›´ä¼˜çš„ä¸‹æ¸¸ä»»åŠ¡æ€§èƒ½ã€‚ç ”ç©¶è€…æ­ç¤ºäº†æ‰©æ•£æ¨¡å‹çš„æ–°ç¼©æ”¾æ³•åˆ™(Scaling Laws)ï¼Œå¹¶æ¨å¯¼å‡ºæ‰©æ•£æ¨¡å‹å¼€å§‹è¶…è¶Šè‡ªå›å½’æ¨¡å‹çš„å…³é”®è®¡ç®—é˜ˆå€¼çš„é—­å¼è¡¨è¾¾å¼ã€‚æ·±å…¥åˆ†æè¡¨æ˜ï¼Œæ‰©æ•£æ¨¡å‹çš„éšæœºæ©ç ç›®æ ‡é€šè¿‡å¯¹ä¸°å¯Œçš„Tokenæ’åºåˆ†å¸ƒè¿›è¡Œéšå¼æ•°æ®å¢å¼º(Implicit Data Augmentation)ï¼Œå…‹æœäº†è‡ªå›å½’æ¨¡å‹å›ºæœ‰çš„ä»å·¦åˆ°å³å›ºå®šåˆ†è§£é™åˆ¶ã€‚ç»“æœè¯æ˜å½“æ•°æ®è€Œéè®¡ç®—èƒ½åŠ›æˆä¸ºä¸»è¦ç“¶é¢ˆæ—¶ï¼Œæ‰©æ•£æ¨¡å‹ä¸ºæ ‡å‡†çš„è‡ªå›å½’èŒƒå¼æä¾›äº†ä¸€ä¸ªæå…·ç«äº‰åŠ›çš„æ›¿ä»£æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "Project Webpage: https://diffusion-scaling.github.io",
      "pdf_url": "https://arxiv.org/pdf/2507.15857v7",
      "published_date": "2025-07-21 17:59:57 UTC",
      "updated_date": "2025-10-26 22:38:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:54:04.501896+00:00"
    },
    {
      "arxiv_id": "2507.15855v4",
      "title": "Winning Gold at IMO 2025 with a Model-Agnostic Verification-and-Refinement Pipeline",
      "title_zh": "å‡­å€Ÿæ¨¡å‹æ— å…³çš„éªŒè¯ä¸ç²¾ç‚¼æµæ°´çº¿åœ¨ 2025 å¹´ IMO ä¸­å¤ºå¾—é‡‘ç‰Œ",
      "authors": [
        "Yichen Huang",
        "Lin F. Yang"
      ],
      "abstract": "The International Mathematical Olympiad (IMO) is widely regarded as the world championship of high-school mathematics. IMO problems are renowned for their difficulty and novelty, demanding deep insight, creativity, and rigor. Although large language models perform well on many mathematical benchmarks, they often struggle with Olympiad-level problems. Using carefully designed prompts, we construct a model-agnostic, verification-and-refinement pipeline. We demonstrate its effectiveness on the recent IMO 2025, avoiding data contamination for models released before the competition. Equipped with any of the three leading models -- Gemini 2.5 Pro, Grok-4, or GPT-5 -- our pipeline correctly solved 5 out of the 6 problems ($\\approx$85.7% accuracy). This is in sharp contrast to their baseline accuracies: 31.6% (Gemini 2.5 Pro), 21.4% (Grok-4), and 38.1% (GPT-5), obtained by selecting the best of 32 candidate solutions. The substantial improvement underscores that the path to advanced AI reasoning requires not only developing more powerful base models but also designing effective methodologies to harness their full potential for complex tasks.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤„ç†é«˜éš¾åº¦å›½é™…æ•°å­¦å¥¥æ—åŒ¹å…‹ï¼ˆIMOï¼‰é—®é¢˜æ—¶çš„å±€é™æ€§ï¼Œæå‡ºäº†ä¸€ç§ä¸æ¨¡å‹æ— å…³çš„éªŒè¯ä¸ä¼˜åŒ–æµæ°´çº¿ï¼ˆmodel-agnostic, verification-and-refinement pipelineï¼‰ã€‚è¯¥æ–¹æ³•é€šè¿‡ç²¾å¿ƒè®¾è®¡çš„æç¤ºè¯å·¥ç¨‹ï¼Œå®ç°äº†å¯¹è§£é¢˜è¿‡ç¨‹çš„æŒç»­æ ¡éªŒä¸æ”¹è¿›ï¼Œæ—¨åœ¨æŒ–æ˜ç°æœ‰æ¨¡å‹åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸­çš„æ½œåŠ›ã€‚ç ”ç©¶å›¢é˜Ÿåœ¨ 2025 å¹´å›½é™…æ•°å­¦å¥¥æ—åŒ¹å…‹ç«èµ›ï¼ˆIMO 2025ï¼‰çš„é¢˜ç›®ä¸Šå¯¹è¯¥æ¡†æ¶è¿›è¡Œäº†æµ‹è¯•ï¼Œæœ‰æ•ˆé¿å…äº†æ¨¡å‹è®­ç»ƒä¸­çš„æ•°æ®æ±¡æŸ“é—®é¢˜ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œç»“åˆ Gemini 2.5 Proã€Grok-4 æˆ– GPT-5 ç­‰é¢†å…ˆæ¨¡å‹åï¼Œè¯¥æµæ°´çº¿æˆåŠŸè§£å†³äº† 6 é“é¢˜ç›®ä¸­çš„ 5 é“ï¼Œå‡†ç¡®ç‡è¾¾åˆ°çº¦ 85.7%ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œå„åŸºçº¿æ¨¡å‹åœ¨é€‰å– 32 ä¸ªå€™é€‰æ–¹æ¡ˆä¸­æœ€ä¼˜è§£æ—¶çš„å‡†ç¡®ç‡ä»…åœ¨ 21.4% è‡³ 38.1% ä¹‹é—´ï¼Œæ€§èƒ½æå‡æå…¶æ˜¾è‘—ã€‚è¿™ä¸€æˆæœè¡¨æ˜ï¼Œå®ç°é«˜çº§äººå·¥æ™ºèƒ½æ¨ç†ä¸ä»…ä¾èµ–äºæ›´å¼ºå¤§çš„åŸºç¡€æ¨¡å‹ï¼Œæ›´å–å†³äºè®¾è®¡æœ‰æ•ˆçš„æ–¹æ³•è®ºæ¥å……åˆ†æ¿€å‘æ¨¡å‹å¤„ç†å¤æ‚é€»è¾‘ä»»åŠ¡çš„æ½œåŠ›ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.15855v4",
      "published_date": "2025-07-21 17:59:49 UTC",
      "updated_date": "2025-09-30 17:53:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:54:09.058613+00:00"
    },
    {
      "arxiv_id": "2507.15852v2",
      "title": "SeC: Advancing Complex Video Object Segmentation via Progressive Concept Construction",
      "title_zh": "SeCï¼šé€šè¿‡æ¸è¿›å¼æ¦‚å¿µæ„å»ºæå‡å¤æ‚è§†é¢‘ç›®æ ‡åˆ†å‰²",
      "authors": [
        "Zhixiong Zhang",
        "Shuangrui Ding",
        "Xiaoyi Dong",
        "Songxin He",
        "Jianfan Lin",
        "Junsong Tang",
        "Yuhang Zang",
        "Yuhang Cao",
        "Dahua Lin",
        "Jiaqi Wang"
      ],
      "abstract": "Video Object Segmentation (VOS) is a core task in computer vision, requiring models to track and segment target objects across video frames. Despite notable advances with recent efforts, current techniques still lag behind human capabilities in handling drastic visual variations, occlusions, and complex scene changes. This limitation arises from their reliance on appearance matching, neglecting the human-like conceptual understanding of objects that enables robust identification across temporal dynamics. Motivated by this gap, we propose Segment Concept (SeC), a concept-driven segmentation framework that shifts from conventional feature matching to the progressive construction and utilization of high-level, object-centric representations. SeC employs Large Vision-Language Models (LVLMs) to integrate visual cues across diverse frames, constructing robust conceptual priors. During inference, SeC forms a comprehensive semantic representation of the target based on processed frames, realizing robust segmentation of follow-up frames. Furthermore, SeC adaptively balances LVLM-based semantic reasoning with enhanced feature matching, dynamically adjusting computational efforts based on scene complexity. To rigorously assess VOS methods in scenarios demanding high-level conceptual reasoning and robust semantic understanding, we introduce the Semantic Complex Scenarios Video Object Segmentation benchmark (SeCVOS). SeCVOS comprises 160 manually annotated multi-scenario videos designed to challenge models with substantial appearance variations and dynamic scene transformations. In particular, SeC achieves an 11.8-point improvement over SAM 2.1 on SeCVOS, establishing a new state-of-the-art in concept-aware video object segmentation.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è§†é¢‘å¯¹è±¡åˆ†å‰² (Video Object Segmentation, VOS) åœ¨å¤„ç†å‰§çƒˆè§†è§‰å˜åŒ–å’Œé®æŒ¡æ—¶è¡¨ç°ä¸ä½³çš„é—®é¢˜ï¼Œæå‡ºäº†åä¸º Segment Concept (SeC) çš„æ¦‚å¿µé©±åŠ¨åˆ†å‰²æ¡†æ¶ã€‚SeC æ”¹å˜äº†ä¼ ç»Ÿçš„ç‰¹å¾åŒ¹é…æ¨¡å¼ï¼Œåˆ©ç”¨å¤§è§†è§‰è¯­è¨€æ¨¡å‹ (Large Vision-Language Models, LVLMs) è·¨è§†é¢‘å¸§æ•´åˆè§†è§‰çº¿ç´¢ï¼Œé€æ­¥æ„å»ºé«˜å±‚çº§çš„ã€ä»¥ç‰©ä½“ä¸ºä¸­å¿ƒçš„æ¦‚å¿µè¡¨å¾ã€‚åœ¨æ¨ç†è¿‡ç¨‹ä¸­ï¼Œè¯¥æ¡†æ¶èƒ½åŸºäºå·²å¤„ç†å¸§å½¢æˆç›®æ ‡çš„å…¨é¢è¯­ä¹‰è¡¨ç¤ºï¼Œå¹¶æ ¹æ®åœºæ™¯å¤æ‚åº¦åŠ¨æ€å¹³è¡¡åŸºäº LVLM çš„è¯­ä¹‰æ¨ç†ä¸å¢å¼ºçš„ç‰¹å¾åŒ¹é…ã€‚ä¸ºäº†è¯„ä¼°æ¨¡å‹åœ¨å¤æ‚åœºæ™¯ä¸‹çš„é²æ£’è¯­ä¹‰ç†è§£èƒ½åŠ›ï¼Œç ”ç©¶è€…æ¨å‡ºäº†åŒ…å« 160 ä¸ªå¤šåœºæ™¯æ ‡æ³¨è§†é¢‘çš„ SeCVOS åŸºå‡†æµ‹è¯•ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒSeC åœ¨ SeCVOS ä¸Šçš„è¡¨ç°æ¯” SAM 2.1 æ˜¾è‘—æé«˜äº† 11.8 ä¸ªç™¾åˆ†ç‚¹ï¼Œç¡®ç«‹äº†æ¦‚å¿µæ„ŸçŸ¥è§†é¢‘å¯¹è±¡åˆ†å‰²çš„æ–°æœ€å…ˆè¿›æ€§èƒ½ (State-of-the-art)ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "project page: https://rookiexiong7.github.io/projects/SeC/ ; code: https://github.com/OpenIXCLab/SeC ; dataset: https://huggingface.co/datasets/OpenIXCLab/SeCVOS",
      "pdf_url": "https://arxiv.org/pdf/2507.15852v2",
      "published_date": "2025-07-21 17:59:02 UTC",
      "updated_date": "2025-07-22 10:51:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:54:16.403965+00:00"
    },
    {
      "arxiv_id": "2507.15851v1",
      "title": "The Other Mind: How Language Models Exhibit Human Temporal Cognition",
      "title_zh": "ä»–è€…ä¹‹å¿ƒï¼šè¯­è¨€æ¨¡å‹å¦‚ä½•å±•ç°äººç±»çš„æ—¶é—´è®¤çŸ¥",
      "authors": [
        "Lingyu Li",
        "Yang Yao",
        "Yixu Wang",
        "Chubo Li",
        "Yan Teng",
        "Yingchun Wang"
      ],
      "abstract": "As Large Language Models (LLMs) continue to advance, they exhibit certain cognitive patterns similar to those of humans that are not directly specified in training data. This study investigates this phenomenon by focusing on temporal cognition in LLMs. Leveraging the similarity judgment task, we find that larger models spontaneously establish a subjective temporal reference point and adhere to the Weber-Fechner law, whereby the perceived distance logarithmically compresses as years recede from this reference point. To uncover the mechanisms behind this behavior, we conducted multiple analyses across neuronal, representational, and informational levels. We first identify a set of temporal-preferential neurons and find that this group exhibits minimal activation at the subjective reference point and implements a logarithmic coding scheme convergently found in biological systems. Probing representations of years reveals a hierarchical construction process, where years evolve from basic numerical values in shallow layers to abstract temporal orientation in deep layers. Finally, using pre-trained embedding models, we found that the training corpus itself possesses an inherent, non-linear temporal structure, which provides the raw material for the model's internal construction. In discussion, we propose an experientialist perspective for understanding these findings, where the LLMs' cognition is viewed as a subjective construction of the external world by its internal representational system. This nuanced perspective implies the potential emergence of alien cognitive frameworks that humans cannot intuitively predict, pointing toward a direction for AI alignment that focuses on guiding internal constructions. Our code is available at https://TheOtherMind.github.io.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å¦‚ä½•å±•ç°å‡ºç±»ä¼¼äºäººç±»çš„æ—¶é—´è®¤çŸ¥æ¨¡å¼ï¼Œå‘ç°è¾ƒå¤§è§„æ¨¡çš„æ¨¡å‹ä¼šè‡ªå‘å»ºç«‹ä¸»è§‚æ—¶é—´å‚è€ƒç‚¹å¹¶éµå¾ª Weber-Fechner lawï¼Œå³æ„ŸçŸ¥åˆ°çš„æ—¶é—´è·ç¦»éšå¹´ä»½è¿œç¦»å‚è€ƒç‚¹è€Œå‘ˆå¯¹æ•°å‹ç¼©ã€‚é€šè¿‡ç¥ç»ã€è¡¨å¾å’Œä¿¡æ¯å±‚é¢çš„å¤šç»´åˆ†æï¼Œç ”ç©¶è¯†åˆ«å‡ºäº†ä¸€ç»„æ—¶é—´åå¥½ç¥ç»å…ƒï¼ˆtemporal-preferential neuronsï¼‰ï¼Œå‘ç°å…¶é‡‡ç”¨çš„å¯¹æ•°ç¼–ç æ–¹æ¡ˆä¸ç”Ÿç‰©ç³»ç»Ÿé«˜åº¦ç›¸ä¼¼ã€‚åœ¨è¡¨å¾æ¼”å˜ä¸­ï¼Œå¹´ä»½ä¿¡æ¯ä»æµ…å±‚çš„æ•°å€¼è¡¨å¾è¿›åŒ–ä¸ºæ·±å±‚çš„æŠ½è±¡æ—¶é—´å¯¼å‘ï¼ˆtemporal orientationï¼‰ã€‚ç ”ç©¶è¿›ä¸€æ­¥æŒ‡å‡ºï¼Œé¢„è®­ç»ƒè¯­æ–™åº“å›ºæœ‰çš„éçº¿æ€§æ—¶é—´ç»“æ„æ˜¯æ¨¡å‹æ„å»ºæ­¤ç±»è®¤çŸ¥çš„åŸºç¡€ç´ æã€‚ä½œè€…æ®æ­¤æå‡ºäº†ä¸€ç§ç»éªŒä¸»ä¹‰ï¼ˆexperientialistï¼‰è§†è§’ï¼Œè®¤ä¸º LLMs çš„è®¤çŸ¥æ˜¯å¯¹å¤–éƒ¨ä¸–ç•Œçš„ä¸»è§‚æ„å»ºï¼Œè¿™æš—ç¤ºæœªæ¥ AI alignment åº”å½“é‡ç‚¹å…³æ³¨å¯¹æ¨¡å‹å†…éƒ¨è¡¨å¾æ„å»ºçš„å¼•å¯¼ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "12 pages, 9 figures, 4 tables",
      "pdf_url": "https://arxiv.org/pdf/2507.15851v1",
      "published_date": "2025-07-21 17:59:01 UTC",
      "updated_date": "2025-07-21 17:59:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:54:17.856381+00:00"
    },
    {
      "arxiv_id": "2507.15849v2",
      "title": "The Impact of Language Mixing on Bilingual LLM Reasoning",
      "title_zh": "è¯­è¨€æ··ç”¨å¯¹åŒè¯­ LLM æ¨ç†çš„å½±å“",
      "authors": [
        "Yihao Li",
        "Jiayi Xin",
        "Miranda Muqing Miao",
        "Qi Long",
        "Lyle Ungar"
      ],
      "abstract": "Proficient multilingual speakers often intentionally switch languages in the middle of a conversation. Similarly, recent reasoning-focused bilingual large language models (LLMs) with strong capabilities in both languages exhibit language mixing-alternating languages within their chain of thought. Discouraging this behavior in DeepSeek-R1 was found to degrade accuracy, suggesting that language mixing may benefit reasoning. In this work, we study language switching in Chinese-English bilingual reasoning models. We identify reinforcement learning with verifiable rewards (RLVR) as the critical training stage that leads to language mixing. We show that language mixing can enhance reasoning: enforcing monolingual decoding reduces accuracy by 5.6 percentage points on MATH500. Additionally, a lightweight probe can be trained to predict whether a potential language switch would benefit or harm reasoning, and when used to guide decoding, increases accuracy by 2.92 percentage points. Our findings suggest that language mixing is not merely a byproduct of multilingual training, but is a strategic reasoning behavior.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶æ¢è®¨äº†ä¸­è‹±åŒè¯­å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨æ¨ç†è¿‡ç¨‹ä¸­å‡ºç°çš„è¯­è¨€æ··åˆ(language mixing)ç°è±¡åŠå…¶å¯¹æ¨ç†æ€§èƒ½çš„å½±å“ã€‚ç ”ç©¶ç¡®å®šå¸¦æœ‰å¯éªŒè¯å¥–åŠ±çš„å¼ºåŒ–å­¦ä¹ (RLVR)æ˜¯å¯¼è‡´æ¨¡å‹åœ¨é“¾å¼æ€ç»´(Chain-of-Thought)ä¸­é¢‘ç¹åˆ‡æ¢è¯­è¨€çš„å…³é”®è®­ç»ƒé˜¶æ®µã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯­è¨€æ··åˆèƒ½æ˜¾è‘—å¢å¼ºæ¨ç†èƒ½åŠ›ï¼Œè‹¥å¼ºåˆ¶æ‰§è¡Œå•è¯­è¨€è§£ç ï¼Œæ¨¡å‹åœ¨MATH500ä¸Šçš„å‡†ç¡®ç‡å°†ä¸‹é™5.6ä¸ªç™¾åˆ†ç‚¹ã€‚æ­¤å¤–ï¼Œç ”ç©¶é€šè¿‡è®­ç»ƒè½»é‡çº§æ¢æµ‹å™¨(lightweight probe)æ¥é¢„æµ‹è¯­è¨€åˆ‡æ¢çš„æ”¶ç›Šï¼Œå¹¶åœ¨å…¶å¼•å¯¼è§£ç ä¸‹å°†å‡†ç¡®ç‡è¿›ä¸€æ­¥æå‡äº†2.92ä¸ªç™¾åˆ†ç‚¹ã€‚è¯¥å‘ç°è¯å®äº†è¯­è¨€æ··åˆå¹¶éå¤šè¯­è¨€è®­ç»ƒçš„ç®€å•å‰¯äº§å“ï¼Œè€Œæ˜¯ä¸€ç§èƒ½å¤Ÿä¼˜åŒ–æ¨ç†æ•ˆæœçš„ç­–ç•¥æ€§è¡Œä¸ºã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at EMNLP 2025 (Main Conference)",
      "pdf_url": "https://arxiv.org/pdf/2507.15849v2",
      "published_date": "2025-07-21 17:56:09 UTC",
      "updated_date": "2025-09-30 17:58:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:54:37.951317+00:00"
    },
    {
      "arxiv_id": "2507.15846v3",
      "title": "GUI-G$^2$: Gaussian Reward Modeling for GUI Grounding",
      "title_zh": "GUI-G$^2$ï¼šé¢å‘ GUI å®šä½çš„é«˜æ–¯å¥–åŠ±å»ºæ¨¡",
      "authors": [
        "Fei Tang",
        "Zhangxuan Gu",
        "Zhengxi Lu",
        "Xuyang Liu",
        "Shuheng Shen",
        "Changhua Meng",
        "Wen Wang",
        "Wenqi Zhang",
        "Yongliang Shen",
        "Weiming Lu",
        "Jun Xiao",
        "Yueting Zhuang"
      ],
      "abstract": "Graphical User Interface (GUI) grounding maps natural language instructions to precise interface locations for autonomous interaction. Current reinforcement learning approaches use binary rewards that treat elements as hit-or-miss targets, creating sparse signals that ignore the continuous nature of spatial interactions. Motivated by human clicking behavior that naturally forms Gaussian distributions centered on target elements, we introduce GUI Gaussian Grounding Rewards (GUI-G$^2$), a principled reward framework that models GUI elements as continuous Gaussian distributions across the interface plane. GUI-G$^2$ incorporates two synergistic mechanisms: Gaussian point rewards model precise localization through exponentially decaying distributions centered on element centroids, while coverage rewards assess spatial alignment by measuring the overlap between predicted Gaussian distributions and target regions. To handle diverse element scales, we develop an adaptive variance mechanism that calibrates reward distributions based on element dimensions. This framework transforms GUI grounding from sparse binary classification to dense continuous optimization, where Gaussian distributions generate rich gradient signals that guide models toward optimal interaction positions. Extensive experiments across ScreenSpot, ScreenSpot-v2, and ScreenSpot-Pro benchmarks demonstrate that GUI-G$^2$, substantially outperforms state-of-the-art method UI-TARS-72B, with the most significant improvement of 24.7% on ScreenSpot-Pro. Our analysis reveals that continuous modeling provides superior robustness to interface variations and enhanced generalization to unseen layouts, establishing a new paradigm for spatial reasoning in GUI interaction tasks.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å›¾å½¢ç”¨æˆ·ç•Œé¢ï¼ˆGUIï¼‰å®šä½ï¼ˆGroundingï¼‰ä»»åŠ¡ä¸­ä¼ ç»Ÿå¼ºåŒ–å­¦ä¹ æ–¹æ³•å­˜åœ¨çš„äºŒå…ƒå¥–åŠ±ï¼ˆbinary rewardsï¼‰ä¿¡å·ç¨€ç–é—®é¢˜ï¼Œæå‡ºäº† GUI-G$^2$ è¿ç»­é«˜æ–¯å¥–åŠ±å»ºæ¨¡æ¡†æ¶ã€‚GUI-G$^2$ é€šè¿‡å°† GUI å…ƒç´ è§†ä¸ºç•Œé¢å¹³é¢ä¸Šçš„è¿ç»­ Gaussian distributionsï¼Œå¼•å…¥äº†ç”¨äºç²¾ç¡®ä½ç½®å»ºæ¨¡çš„é«˜æ–¯ç‚¹å¥–åŠ±ï¼ˆGaussian point rewardsï¼‰å’Œè¯„ä¼°ç©ºé—´å¯¹é½çš„è¦†ç›–å¥–åŠ±ï¼ˆcoverage rewardsï¼‰ã€‚ä¸ºäº†é€‚åº”ä¸åŒè§„æ¨¡çš„å…ƒç´ ï¼Œè¯¥æ¡†æ¶å¼€å‘äº†è‡ªé€‚åº”æ–¹å·®æœºåˆ¶ï¼ˆadaptive variance mechanismï¼‰æ¥åŠ¨æ€æ ¡å‡†å¥–åŠ±åˆ†å¸ƒã€‚é€šè¿‡å°† GUI å®šä½ä»ç¨€ç–çš„äºŒå…ƒåˆ†ç±»è½¬å˜ä¸ºå¯†é›†çš„è¿ç»­ä¼˜åŒ–ï¼Œæ¨¡å‹èƒ½å¤Ÿè·å¾—æ›´ä¸°å¯Œçš„æ¢¯åº¦ä¿¡å·ï¼Œå¼•å¯¼å…¶å®ç°æœ€ä¼˜äº¤äº’ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒGUI-G$^2$ åœ¨ ScreenSpot-Pro ç­‰å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å¤§å¹…è¶…è¶Šäº†æœ€å…ˆè¿›çš„ UI-TARS-72B æ¨¡å‹ï¼Œæ€§èƒ½æå‡æœ€é«˜è¾¾ 24.7%ã€‚è¯¥æ–¹æ³•ä¸ä»…åœ¨ç©ºé—´æ¨ç†æ–¹é¢è¡¨ç°å“è¶Šï¼Œè¿˜æ˜¾è‘—æå‡äº†æ¨¡å‹å¯¹ç•Œé¢å˜åŒ–å’ŒæœªçŸ¥å¸ƒå±€çš„é²æ£’æ€§ï¼Œä¸º GUI è‡ªåŠ¨åŒ–äº¤äº’é¢†åŸŸæä¾›äº†å…¨æ–°çš„èŒƒå¼ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.HC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.15846v3",
      "published_date": "2025-07-21 17:53:42 UTC",
      "updated_date": "2025-07-28 16:54:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:54:35.532343+00:00"
    },
    {
      "arxiv_id": "2507.15844v3",
      "title": "Hierarchical Budget Policy Optimization for Adaptive Reasoning",
      "title_zh": "é¢å‘è‡ªé€‚åº”æ¨ç†çš„åˆ†å±‚é¢„ç®—ç­–ç•¥ä¼˜åŒ–",
      "authors": [
        "Shangke Lyu",
        "Linjuan Wu",
        "Yuchen Yan",
        "Xingyu Wu",
        "Hao Li",
        "Yongliang Shen",
        "Peisheng Jiang",
        "Weiming Lu",
        "Jun Xiao",
        "Yueting Zhuang"
      ],
      "abstract": "Large reasoning models achieve remarkable performance through extensive chain-of-thought generation, yet they suffer from a critical inefficiency: applying uniformly extensive reasoning regardless of problem complexity. We present Hierarchical Budget Policy Optimization (HBPO), a reinforcement learning framework that enables models to learn problem-specific reasoning depths without sacrificing capability. Unlike existing approaches that impose rigid constraints or rely on discrete mode selection, HBPO partitions the exploration space into budget-constrained hierarchies (512-2560 tokens), each with differentiated reward structures that preserve both efficiency incentives and reasoning capabilities. This design addresses a fundamental challenge in efficient reasoning training: traditional length penalties systematically bias models away from necessary long reasoning paths, causing exploration space collapse. Through hierarchical sampling and budget-aware rewards, HBPO maintains exploration diversity while teaching models to recognize when extended deliberation is warranted. Extensive experiments demonstrate that HBPO reduces average token usage by up to 60.6% while improving accuracy by 3.14% across four reasoning benchmarks. Most notably, HBPO exhibits emergent adaptive behavior where models automatically adjust reasoning depth based on problem complexity. Our results suggest that reasoning efficiency and capability are not inherently conflicting, and can be simultaneously optimized through appropriately structured hierarchical training that preserves exploration diversity.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹åœ¨æ¨ç†è¿‡ç¨‹ä¸­æ— è®ºé—®é¢˜å¤æ‚åº¦å¦‚ä½•å‡é‡‡ç”¨ç»Ÿä¸€é“¾å¼æ€ç»´(Chain-of-Thought)ç”Ÿæˆçš„æ•ˆç‡ç“¶é¢ˆï¼Œæå‡ºäº†å±‚çº§é¢„ç®—ç­–ç•¥ä¼˜åŒ–(Hierarchical Budget Policy Optimization, HBPO)å¼ºåŒ–å­¦ä¹ æ¡†æ¶ã€‚HBPOå°†æ¢ç´¢ç©ºé—´åˆ’åˆ†ä¸ºå—é¢„ç®—çº¦æŸçš„å±‚çº§ç»“æ„ï¼Œå¹¶åˆ©ç”¨å·®å¼‚åŒ–çš„å¥–åŠ±ç»“æ„æ¥å¹³è¡¡æ¨ç†èƒ½åŠ›ä¸æ•ˆç‡ï¼Œæœ‰æ•ˆè§£å†³äº†ä¼ ç»Ÿé•¿åº¦æƒ©ç½šå¯¼è‡´çš„æ¢ç´¢ç©ºé—´åç¼©é—®é¢˜ã€‚é€šè¿‡å±‚çº§é‡‡æ ·å’Œé¢„ç®—æ„ŸçŸ¥å¥–åŠ±ï¼Œè¯¥æ¡†æ¶ä½¿æ¨¡å‹èƒ½å¤Ÿè¯†åˆ«é—®é¢˜çš„å¤æ‚ç¨‹åº¦å¹¶è‡ªé€‚åº”åœ°å­¦ä¹ æ¨ç†æ·±åº¦ï¼Œä»è€Œåœ¨ä¿æŒæ¢ç´¢å¤šæ ·æ€§çš„åŒæ—¶å®ç°é«˜æ•ˆè®¡ç®—ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒHBPOåœ¨å››ä¸ªæ¨ç†åŸºå‡†æµ‹è¯•ä¸­å°†å‡†ç¡®ç‡æé«˜äº†3.14%ï¼ŒåŒæ—¶å°†å¹³å‡Tokenä½¿ç”¨é‡æ˜¾è‘—é™ä½äº†é«˜è¾¾60.6%ã€‚è¿™é¡¹ç ”ç©¶è¯æ˜äº†æ¨ç†æ•ˆç‡ä¸èƒ½åŠ›å¯ä»¥é€šè¿‡å±‚çº§è®­ç»ƒç»“æ„å®ç°åŒæ­¥ä¼˜åŒ–ï¼Œå¹¶ä½¿æ¨¡å‹æ¶Œç°å‡ºæ ¹æ®ä»»åŠ¡éš¾åº¦è‡ªåŠ¨è°ƒæ•´æ¨ç†æ·±åº¦çš„æ™ºèƒ½è‡ªé€‚åº”è¡Œä¸ºã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Code: https://github.com/zju-real/hbpo Project Page:https://zju-real.github.io/hbpo/",
      "pdf_url": "https://arxiv.org/pdf/2507.15844v3",
      "published_date": "2025-07-21 17:52:34 UTC",
      "updated_date": "2025-08-07 14:12:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:54:38.551265+00:00"
    },
    {
      "arxiv_id": "2507.15842v1",
      "title": "Identifying Conditional Causal Effects in MPDAGs",
      "title_zh": "MPDAGs ä¸­çš„æ¡ä»¶å› æœæ•ˆåº”è¯†åˆ«",
      "authors": [
        "Sara LaPlante",
        "Emilija PerkoviÄ‡"
      ],
      "abstract": "We consider identifying a conditional causal effect when a graph is known up to a maximally oriented partially directed acyclic graph (MPDAG). An MPDAG represents an equivalence class of graphs that is restricted by background knowledge and where all variables in the causal model are observed. We provide three results that address identification in this setting: an identification formula when the conditioning set is unaffected by treatment, a generalization of the well-known do calculus to the MPDAG setting, and an algorithm that is complete for identifying these conditional effects.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨å›¾ç»“æ„ä»…å·²çŸ¥ä¸ºæœ€å¤§å®šå‘éƒ¨åˆ†æœ‰å‘æ— ç¯å›¾ (MPDAG) çš„æƒ…å†µä¸‹ï¼Œå¦‚ä½•è¯†åˆ«æ¡ä»¶å› æœæ•ˆåº” (conditional causal effect)ã€‚MPDAG ä»£è¡¨äº†ä¸€ç±»å—èƒŒæ™¯çŸ¥è¯†é™åˆ¶ä¸”è§‚æµ‹åˆ°æ‰€æœ‰å˜é‡çš„ç­‰ä»·å›¾ç±»ã€‚ä¸ºäº†è§£å†³è¿™ä¸€è¯†åˆ«é—®é¢˜ï¼Œè®ºæ–‡æå‡ºäº†ä¸‰é¡¹æ ¸å¿ƒç ”ç©¶æˆæœã€‚é¦–å…ˆï¼Œé’ˆå¯¹è°ƒèŠ‚é›† (conditioning set) ä¸å—å¹²é¢„ (treatment) å½±å“çš„æƒ…å½¢ï¼Œç»™å‡ºäº†ç›¸åº”çš„è¯†åˆ«å…¬å¼ã€‚å…¶æ¬¡ï¼Œç ”ç©¶å°†ç»å…¸çš„ do-calculus æ¨å¹¿åˆ°äº† MPDAG é¢†åŸŸï¼Œä½¿å…¶èƒ½å¤Ÿå¤„ç†æ›´å¤æ‚çš„ç­‰ä»·å›¾åœºæ™¯ã€‚æœ€åï¼Œè®ºæ–‡æä¾›äº†ä¸€ç§èƒ½å¤Ÿå®Œå¤‡åœ° (complete) è¯†åˆ«è¿™äº›æ¡ä»¶æ•ˆåº”çš„ç®—æ³•ã€‚è¿™äº›å·¥ä½œä¸ºåœ¨å­˜åœ¨èƒŒæ™¯çŸ¥è¯†çº¦æŸçš„å› æœæ¨æ–­ä¸­æä¾›äº†é‡è¦çš„ç†è®ºå·¥å…·å’Œè®¡ç®—æ–¹æ³•ã€‚",
      "categories": [
        "cs.AI",
        "stat.ME",
        "stat.ML"
      ],
      "primary_category": "cs.AI",
      "comment": "67 pages, 8 figures",
      "pdf_url": "https://arxiv.org/pdf/2507.15842v1",
      "published_date": "2025-07-21 17:52:28 UTC",
      "updated_date": "2025-07-21 17:52:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:54:39.124033+00:00"
    },
    {
      "arxiv_id": "2507.15839v1",
      "title": "FASTGEN: Fast and Cost-Effective Synthetic Tabular Data Generation with LLMs",
      "title_zh": "FASTGENï¼šåŸºäºå¤§è¯­è¨€æ¨¡å‹çš„é«˜æ•ˆä½æˆæœ¬åˆæˆè¡¨æ ¼æ•°æ®ç”Ÿæˆ",
      "authors": [
        "Anh Nguyen",
        "Sam Schafft",
        "Nicholas Hale",
        "John Alfaro"
      ],
      "abstract": "Synthetic data generation has emerged as an invaluable solution in scenarios where real-world data collection and usage are limited by cost and scarcity. Large language models (LLMs) have demonstrated remarkable capabilities in producing high-fidelity, domain-relevant samples across various fields. However, existing approaches that directly use LLMs to generate each record individually impose prohibitive time and cost burdens, particularly when large volumes of synthetic data are required. In this work, we propose a fast, cost-effective method for realistic tabular data synthesis that leverages LLMs to infer and encode each field's distribution into a reusable sampling script. By automatically classifying fields into numerical, categorical, or free-text types, the LLM generates distribution-based scripts that can efficiently produce diverse, realistic datasets at scale without continuous model inference. Experimental results show that our approach outperforms traditional direct methods in both diversity and data realism, substantially reducing the burden of high-volume synthetic data generation. We plan to apply this methodology to accelerate testing in production pipelines, thereby shortening development cycles and improving overall system efficiency. We believe our insights and lessons learned will aid researchers and practitioners seeking scalable, cost-effective solutions for synthetic data generation.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ (LLMs) ç›´æ¥é€æ¡ç”Ÿæˆåˆæˆæ•°æ®æ‰€å¸¦æ¥çš„é«˜æ˜‚æˆæœ¬å’Œæ—¶é—´è´Ÿæ‹…ï¼Œæå‡ºäº† FASTGEN æ¡†æ¶ã€‚FASTGEN çš„æ ¸å¿ƒæ€æƒ³æ˜¯åˆ©ç”¨ LLMs æ¨ç†å¹¶ç¼–ç æ¯ä¸ªå­—æ®µçš„åˆ†å¸ƒï¼Œå°†å…¶è½¬åŒ–ä¸ºå¯é‡å¤ä½¿ç”¨çš„é‡‡æ ·è„šæœ¬ï¼Œä»è€Œå®ç°å¤§è§„æ¨¡è¡¨æ ¼æ•°æ®çš„å¿«é€Ÿåˆæˆã€‚è¯¥æ–¹æ³•èƒ½è‡ªåŠ¨å°†å­—æ®µåˆ†ç±»ä¸ºæ•°å€¼å‹ (numerical)ã€ç±»åˆ«å‹ (categorical) æˆ–è‡ªç”±æ–‡æœ¬å‹ (free-text)ï¼Œå¹¶åœ¨æ— éœ€æŒç»­æ¨¡å‹æ¨ç†çš„æƒ…å†µä¸‹äº§å‡ºå¤šæ ·åŒ–ä¸”çœŸå®çš„æ ·æœ¬ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒFASTGEN åœ¨æ•°æ®å¤šæ ·æ€§ (diversity) å’ŒçœŸå®æ€§ (realism) æ–¹é¢å‡ä¼˜äºä¼ ç»Ÿçš„ç›´æ¥ç”Ÿæˆæ–¹æ³•ï¼Œæ˜¾è‘—é™ä½äº†å¤§è§„æ¨¡æ•°æ®åˆæˆçš„æˆæœ¬ã€‚è¯¥ç ”ç©¶ä¸ä»…èƒ½åŠ é€Ÿç”Ÿäº§æµç¨‹ä¸­çš„æµ‹è¯•å¹¶ç¼©çŸ­å¼€å‘å‘¨æœŸï¼Œè¿˜ä¸ºå¯»æ±‚å¯æ‰©å±•ã€é«˜æ€§ä»·æ¯”åˆæˆæ•°æ®ç”Ÿæˆæ–¹æ¡ˆçš„ä»ä¸šè€…æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.15839v1",
      "published_date": "2025-07-21 17:51:46 UTC",
      "updated_date": "2025-07-21 17:51:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:54:40.940312+00:00"
    },
    {
      "arxiv_id": "2507.15833v2",
      "title": "Look, Focus, Act: Efficient and Robust Robot Learning via Human Gaze and Foveated Vision Transformers",
      "title_zh": "Look, Focus, Actï¼šåŸºäºäººç±»æ³¨è§†ä¸ä¸­å¿ƒå‡¹è§†è§‰ Transformer çš„é«˜æ•ˆé²æ£’æœºå™¨äººå­¦ä¹ ",
      "authors": [
        "Ian Chuang",
        "Jinyu Zou",
        "Andrew Lee",
        "Dechen Gao",
        "Iman Soltani"
      ],
      "abstract": "Human vision is a highly active process driven by gaze, which directs attention to task-relevant regions through foveation, dramatically reducing visual processing. In contrast, robot learning systems typically rely on passive, uniform processing of raw camera images. In this work, we explore how incorporating human-like active gaze into robotic policies can enhance efficiency and robustness. We develop GIAVA (Gaze Integrated Active-Vision ALOHA), a robot vision system that emulates human head and neck movement, and gaze adjustment for foveated processing. Extending the AV-ALOHA robot platform, we introduce a framework for simultaneously collecting eye-tracking, perspective control, and robot manipulation demonstration data from a human operator. We also open-source a simulation benchmark and dataset for training robot policies that incorporate human gaze. Inspired by recent work in foveated image segmentation and given the widespread use of Vision Transformers (ViTs) in robot learning, we integrate gaze information into ViTs using a foveated patch tokenization scheme. Compared to uniform patch tokenization, this significantly reduces the number of tokens, and thus computation. Our results show that our method for foveated robot vision drastically reduces computational overhead, and enhances robustness to background distractors. Notably, on certain high-precision tasks, foveated vision also improves performance, as reflected in higher success rates. Together, these findings suggest that human-inspired foveated visual processing offers untapped potential and should be further considered as a useful inductive bias in robotic vision systems. https://ian-chuang.github.io/gaze-av-aloha/",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¦‚ä½•å°†ç±»ä¼¼äºäººç±»çš„ active gaze æœºåˆ¶æ•´åˆåˆ°æœºå™¨äººç­–ç•¥ä¸­ï¼Œä»¥æå‡å­¦ä¹ æ•ˆç‡å’Œé²æ£’æ€§ã€‚ä½œè€…å¼€å‘äº† GIAVA (Gaze Integrated Active-Vision ALOHA) ç³»ç»Ÿï¼Œé€šè¿‡æ¨¡æ‹Ÿäººç±»å¤´éƒ¨è¿åŠ¨å’Œ gaze è°ƒèŠ‚æ¥å®ç° foveated è§†è§‰å¤„ç†ï¼Œå¹¶æä¾›äº†åŒ…å« eye-tracking å’Œæ“ä½œæ¼”ç¤ºçš„å¼€æºæ•°æ®é›†ã€‚é’ˆå¯¹æœºå™¨äººå­¦ä¹ ä¸­å¸¸ç”¨çš„ Vision Transformers (ViTs)ï¼Œç ”ç©¶æå‡ºäº†ä¸€ç§ foveated patch tokenization æ–¹æ¡ˆï¼Œå°† gaze ä¿¡æ¯ç›´æ¥é›†æˆåˆ°æ¨¡å‹ä¸­ã€‚ä¸ä¼ ç»Ÿçš„ uniform patch tokenization ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•æ˜¾è‘—å‡å°‘äº† token æ•°é‡ï¼Œä»è€Œå¤§å¹…é™ä½äº†è®¡ç®—å¼€é”€ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œfoveated robot vision ä¸ä»…å¢å¼ºäº†ç³»ç»Ÿå¯¹èƒŒæ™¯å¹²æ‰°ç‰© (background distractors) çš„é²æ£’æ€§ï¼Œè¿˜åœ¨é«˜ç²¾åº¦ä»»åŠ¡ä¸­å®ç°äº†æ›´é«˜çš„æˆåŠŸç‡ã€‚è¯¥æˆæœè¯æ˜äº†äººç±»å¯å‘å¼è§†è§‰å¤„ç†ä½œä¸ºä¸€ç§å½’çº³åç½® (inductive bias)ï¼Œåœ¨æ„å»ºé«˜æ•ˆä¸”ç¨³å¥çš„æœºå™¨äººè§†è§‰ç³»ç»Ÿæ–¹é¢å…·æœ‰æ˜¾è‘—æ½œåŠ›ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "Project page: https://ian-chuang.github.io/gaze-av-aloha/",
      "pdf_url": "https://arxiv.org/pdf/2507.15833v2",
      "published_date": "2025-07-21 17:44:10 UTC",
      "updated_date": "2025-09-22 17:42:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:54:52.946338+00:00"
    },
    {
      "arxiv_id": "2507.15823v1",
      "title": "Operationalizing AI for Good: Spotlight on Deployment and Integration of AI Models in Humanitarian Work",
      "title_zh": "AI å‘å–„çš„è½åœ°å®è·µï¼šèšç„¦äººé“ä¸»ä¹‰å·¥ä½œä¸­çš„ AI æ¨¡å‹éƒ¨ç½²ä¸é›†æˆ",
      "authors": [
        "Anton Abilov",
        "Ke Zhang",
        "Hemank Lamba",
        "Elizabeth M. Olson",
        "Joel R. Tetreault",
        "Alejandro Jaimes"
      ],
      "abstract": "Publications in the AI for Good space have tended to focus on the research and model development that can support high-impact applications. However, very few AI for Good papers discuss the process of deploying and collaborating with the partner organization, and the resulting real-world impact. In this work, we share details about the close collaboration with a humanitarian-to-humanitarian (H2H) organization and how to not only deploy the AI model in a resource-constrained environment, but also how to maintain it for continuous performance updates, and share key takeaways for practitioners.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ AI for Good é¢†åŸŸæ™®éå…³æ³¨æ¨¡å‹å¼€å‘è€Œå¿½è§†å®é™…éƒ¨ç½²ä¸ç°å®å½±å“çš„ç°çŠ¶ï¼Œæ·±å…¥æ¢è®¨äº† AI æ¨¡å‹åœ¨äººé“ä¸»ä¹‰å·¥ä½œä¸­çš„ä¸šåŠ¡åŒ–ï¼ˆOperationalizingï¼‰è¿‡ç¨‹ã€‚ä½œè€…åˆ†äº«äº†ä¸äººé“ä¸»ä¹‰å¯¹äººé“ä¸»ä¹‰ï¼ˆH2Hï¼‰ç»„ç»‡å¯†åˆ‡åˆä½œçš„å®è·µç»†èŠ‚ï¼Œé‡ç‚¹é˜è¿°äº†å¦‚ä½•åœ¨èµ„æºå—é™ç¯å¢ƒï¼ˆresource-constrained environmentï¼‰ä¸­æœ‰æ•ˆéƒ¨ç½² AI æ¨¡å‹ã€‚æ–‡ç« ä¸ä»…ä»‹ç»äº†ç¡®ä¿æ¨¡å‹æŒç»­æ€§èƒ½æ›´æ–°çš„ç»´æŠ¤æœºåˆ¶ï¼Œè¿˜ä¸ºç›¸å…³é¢†åŸŸçš„ä»ä¸šè€…æ€»ç»“äº†å®è´µçš„å®è·µç»éªŒï¼ˆkey takeawaysï¼‰ã€‚é€šè¿‡å¼¥è¡¥å­¦æœ¯ç ”ç©¶ä¸å®åœ°åº”ç”¨ä¹‹é—´çš„é¸¿æ²Ÿï¼Œè¯¥å·¥ä½œä¸ºå®ç° AI æŠ€æœ¯åœ¨äººé“ä¸»ä¹‰æ´åŠ©ä¸­çš„æ·±åº¦æ•´åˆä¸å¯æŒç»­å‘å±•æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.15823v1",
      "published_date": "2025-07-21 17:30:38 UTC",
      "updated_date": "2025-07-21 17:30:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:54:52.193413+00:00"
    },
    {
      "arxiv_id": "2507.15822v2",
      "title": "Do AI models help produce verified bug fixes?",
      "title_zh": "AI æ¨¡å‹æ˜¯å¦æœ‰åŠ©äºç”Ÿæˆç»éªŒè¯çš„ç¨‹åºä¿®å¤ï¼Ÿ",
      "authors": [
        "Li Huang",
        "Ilgiz Mustafin",
        "Marco Piccioni",
        "Alessandro Schena",
        "Reto Weber",
        "Bertrand Meyer"
      ],
      "abstract": "Among areas of software engineering where AI techniques -- particularly, Large Language Models -- seem poised to yield dramatic improvements, an attractive candidate is Automatic Program Repair (APR), the production of satisfactory corrections to software bugs. Does this expectation materialize in practice? How do we find out, making sure that proposed corrections actually work? If programmers have access to LLMs, how do they actually use them to complement their own skills?\n  To answer these questions, we took advantage of the availability of a program-proving environment, which formally determines the correctness of proposed fixes, to conduct a study of program debugging with two randomly assigned groups of programmers, one with access to LLMs and the other without, both validating their answers through the proof tools. The methodology relied on a division into general research questions (Goals in the Goal-Query-Metric approach), specific elements admitting specific answers (Queries), and measurements supporting these answers (Metrics). While applied so far to a limited sample size, the results are a first step towards delineating a proper role for AI and LLMs in providing guaranteed-correct fixes to program bugs.\n  These results caused surprise as compared to what one might expect from the use of AI for debugging and APR. The contributions also include: a detailed methodology for experiments in the use of LLMs for debugging, which other projects can reuse; a fine-grain analysis of programmer behavior, made possible by the use of full-session recording; a definition of patterns of use of LLMs, with 7 distinct categories; and validated advice for getting the best of LLMs for debugging and Automatic Program Repair.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§è¯­è¨€æ¨¡å‹ (Large Language Models, LLMs) åœ¨è‡ªåŠ¨ç¨‹åºä¿®å¤ (Automatic Program Repair, APR) ä¸­ç”Ÿæˆç»æ­£å¼éªŒè¯çš„é”™è¯¯ä¿®å¤çš„å®é™…æ•ˆç”¨ã€‚ä½œè€…åˆ©ç”¨ç¨‹åºè¯æ˜ç¯å¢ƒ (program-proving environment) å¼€å±•å¯¹ç…§å®éªŒï¼Œå¯¹æ¯”äº†æœ‰æ—  LLMs è¾…åŠ©çš„ä¸¤ç»„ç¨‹åºå‘˜åœ¨éªŒè¯ä¿®å¤æ­£ç¡®æ€§æ—¶çš„è¡¨ç°ã€‚ç ”ç©¶é‡‡ç”¨ç›®æ ‡-æŸ¥è¯¢-åº¦é‡ (Goal-Query-Metric) æ–¹æ³•ï¼Œå¹¶é€šè¿‡å…¨ä¼šè¯å½•åˆ¶å¯¹ç¨‹åºå‘˜çš„è°ƒè¯•è¡Œä¸ºè¿›è¡Œäº†ç»†ç²’åº¦åˆ†æã€‚å®éªŒç»“æœåœ¨ AI è¾…åŠ©è°ƒè¯•çš„å®é™…æ•ˆæœæ–¹é¢æå‡ºäº†å‡ºäººæ„æ–™çš„è§è§£ï¼Œæ­ç¤ºäº† LLMs åœ¨æä¾›ä¿è¯æ­£ç¡®ä¿®å¤æ–¹æ¡ˆä¸­çš„çœŸå®ä½œç”¨ã€‚è¯¥è®ºæ–‡çš„ä¸»è¦è´¡çŒ®åŒ…æ‹¬ä¸€å¥—å¯é‡ç”¨çš„å®éªŒæ–¹æ³•è®ºã€ç¨‹åºå‘˜ä½¿ç”¨ AI çš„ 7 ç§æ¨¡å¼åˆ†ç±»ï¼Œä»¥åŠåœ¨ APR é¢†åŸŸå……åˆ†å‘æŒ¥ LLMs æ½œåŠ›çš„éªŒè¯æ€§å»ºè®®ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.15822v2",
      "published_date": "2025-07-21 17:30:16 UTC",
      "updated_date": "2025-08-04 13:56:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:54:58.190774+00:00"
    },
    {
      "arxiv_id": "2507.16859v4",
      "title": "Enhancing Fatigue Detection through Heterogeneous Multi-Source Data Integration and Cross-Domain Modality Imputation",
      "title_zh": "åŸºäºå¼‚æ„å¤šæºæ•°æ®é›†æˆä¸è·¨åŸŸæ¨¡æ€æ’è¡¥çš„ç–²åŠ³æ£€æµ‹å¢å¼º",
      "authors": [
        "Luobin Cui",
        "Yanlai Wu",
        "Tang Ying",
        "Weikai Li"
      ],
      "abstract": "Fatigue detection for human operators plays a key role in safety critical applications such as aviation, mining, and long haul transport. While numerous studies have demonstrated the effectiveness of high fidelity sensors in controlled laboratory environments, their performance often degrades when ported to real world settings due to noise, lighting conditions, and field of view constraints, thereby limiting their practicality. This paper formalizes a deployment oriented setting for real world fatigue detection, where high quality sensors are often unavailable in practical applications. To address this challenge, we propose leveraging knowledge from heterogeneous source domains, including high fidelity sensors that are difficult to deploy in the field but commonly used in controlled environments, to assist fatigue detection in the real world target domain. Building on this idea, we design a heterogeneous and multiple source fatigue detection framework that adaptively utilizes the available modalities in the target domain while exploiting diverse configurations in the source domains through alignment across domains and modality imputation. Our experiments, conducted using a field deployed sensor setup and two publicly available human fatigue datasets, demonstrate the practicality, robustness, and improved generalization of our approach across subjects and domains. The proposed method achieves consistent gains over strong baselines in sensor constrained scenarios. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹èˆªç©ºã€çŸ¿ä¸šå’Œé•¿é€”è¿è¾“ç­‰å®‰å…¨å…³é”®é¢†åŸŸï¼Œæå‡ºäº†ä¸€ç§é€šè¿‡å¼‚æ„å¤šæºæ•°æ®é›†æˆå’Œè·¨åŸŸæ¨¡æ€å½’è¡¥æ¥å¢å¼ºç–²åŠ³æ£€æµ‹(Fatigue detection)çš„æ–¹æ³•ã€‚é’ˆå¯¹é«˜ä¿çœŸä¼ æ„Ÿå™¨åœ¨å®éªŒå®¤ç¯å¢ƒå¤–å› å™ªå£°ã€å…‰ç…§å’Œè§†é‡é™åˆ¶å¯¼è‡´æ€§èƒ½ä¸‹é™çš„é—®é¢˜ï¼Œè¯¥ç ”ç©¶æ­£å¼å®šä¹‰äº†é¢å‘å®é™…éƒ¨ç½²çš„ç–²åŠ³æ£€æµ‹åœºæ™¯ã€‚è®ºæ–‡æå‡ºäº†ä¸€ä¸ªå¼‚æ„å¤šæºç–²åŠ³æ£€æµ‹æ¡†æ¶ï¼Œæ—¨åœ¨åˆ©ç”¨éš¾ä»¥åœ¨ç°åœºéƒ¨ç½²ä½†åœ¨å—æ§ç¯å¢ƒä¸­å¸¸ç”¨çš„æºåŸŸ(Source domains)é«˜ä¿çœŸä¼ æ„Ÿå™¨çŸ¥è¯†ï¼Œè¾…åŠ©ç›®æ ‡åŸŸçš„æ£€æµ‹ä»»åŠ¡ã€‚è¯¥æ¡†æ¶é€šè¿‡è·¨åŸŸå¯¹é½(Alignment across domains)å’Œæ¨¡æ€å½’è¡¥(Modality imputation)æŠ€æœ¯ï¼Œèƒ½å¤Ÿè‡ªé€‚åº”åœ°åˆ©ç”¨ç›®æ ‡åŸŸä¸­çš„å¯ç”¨æ¨¡æ€ï¼Œå¹¶æŒ–æ˜æºåŸŸçš„å¤šæ ·åŒ–é…ç½®ã€‚å®éªŒåœ¨ç°åœºéƒ¨ç½²çš„ä¼ æ„Ÿå™¨è®¾ç½®å’Œä¸¤ä¸ªå…¬å¼€çš„äººä½“ç–²åŠ³æ•°æ®é›†ä¸Šè¿›è¡Œï¼ŒéªŒè¯äº†è¯¥æ–¹æ³•åœ¨è·¨ä¸ªä½“å’Œè·¨åŸŸæƒ…å†µä¸‹çš„å®ç”¨æ€§ã€ç¨³å¥æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚ç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨ä¼ æ„Ÿå™¨å—é™çš„åœºæ™¯ä¸‹ç›¸è¾ƒäºå¼ºåŸºçº¿æ¨¡å‹å–å¾—äº†æŒç»­çš„æ€§èƒ½æå‡ï¼Œä¸ºå®é™…åº”ç”¨ä¸­çš„ç–²åŠ³æ£€æµ‹æä¾›äº†æœ‰æ•ˆçš„æŠ€æœ¯æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "4figures,14pages",
      "pdf_url": "https://arxiv.org/pdf/2507.16859v4",
      "published_date": "2025-07-21 17:22:18 UTC",
      "updated_date": "2025-12-29 00:24:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:54:58.887146+00:00"
    },
    {
      "arxiv_id": "2507.15807v2",
      "title": "True Multimodal In-Context Learning Needs Attention to the Visual Context",
      "title_zh": "çœŸæ­£çš„å¤šæ¨¡æ€ä¸Šä¸‹æ–‡å­¦ä¹ éœ€å…³æ³¨è§†è§‰ä¸Šä¸‹æ–‡",
      "authors": [
        "Shuo Chen",
        "Jianzhe Liu",
        "Zhen Han",
        "Yan Xia",
        "Daniel Cremers",
        "Philip Torr",
        "Volker Tresp",
        "Jindong Gu"
      ],
      "abstract": "Multimodal Large Language Models (MLLMs), built on powerful language backbones, have enabled Multimodal In-Context Learning (MICL)-adapting to new tasks from a few multimodal demonstrations consisting of images, questions, and answers. Despite showing noticeable improvement on standard vision-language datasets, current MLLMs struggle to leverage visual information in the demonstrations. Specifically, they tend to neglect visual cues and over-rely on textual patterns, leading to mere text imitation rather than genuine multimodal adaptation. This behavior makes MICL still unimodal and largely restricts its practical utility. More importantly, this limitation is often concealed by the improved performance on tasks that do not require understanding the visual context. As a result, how to effectively enhance MICL ability and reliably evaluate the MICL performance remains underexplored. To address these issues, we first introduce Dynamic Attention Reallocation (DARA), an efficient fine-tuning strategy that encourages models to attend to the visual context by rebalancing attention across visual and textual tokens. In addition, we present TrueMICL, an MICL-dedicated dataset with both support and test sets that explicitly requires the integration of multimodal information-particularly visual content-for correct task completion. Extensive experiments demonstrate the effectiveness of our holistic solution, showcasing substantial improvements in the true multimodal in-context learning capabilities. Code and datasets are available at https://chenxshuo.github.io/true-micl-colm .",
      "tldr_zh": "è¯¥ç ”ç©¶æŒ‡å‡ºå½“å‰å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ (Multimodal Large Language Models, MLLMs) åœ¨æ‰§è¡Œå¤šæ¨¡æ€ä¸Šä¸‹æ–‡å­¦ä¹  (Multimodal In-Context Learning, MICL) æ—¶ï¼Œå¾€å¾€è¿‡åº¦ä¾èµ–æ–‡æœ¬æ¨¡å¼è€Œå¿½è§†äº†ç¤ºä¾‹ä¸­çš„è§†è§‰çº¿ç´¢ï¼Œå¯¼è‡´å…¶æœ¬è´¨ä¸Šä»è¶‹å‘äºå•æ¨¡æ€æ¨¡ä»¿è€ŒéçœŸæ­£çš„å¤šæ¨¡æ€è‡ªé€‚åº”ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œç ”ç©¶è€…æå‡ºäº†åŠ¨æ€æ³¨æ„åŠ›é‡åˆ†é… (Dynamic Attention Reallocation, DARA) ç­–ç•¥ï¼Œè¿™æ˜¯ä¸€ç§é€šè¿‡é‡æ–°å¹³è¡¡è§†è§‰å’Œæ–‡æœ¬ Token ä¹‹é—´çš„æ³¨æ„åŠ›æƒé‡ï¼Œæ¥å¼ºåˆ¶æ¨¡å‹å…³æ³¨è§†è§‰ä¸Šä¸‹æ–‡çš„é«˜æ•ˆå¾®è°ƒæ–¹æ³•ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜æ¨å‡ºäº† TrueMICL æ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†ä¸“é—¨è®¾è®¡ç”¨äºè¯„ä¼°å¿…é¡»æ•´åˆè§†è§‰ä¿¡æ¯æ‰èƒ½æ­£ç¡®å®Œæˆçš„ä»»åŠ¡ï¼Œå¡«è¡¥äº†ç°æœ‰è¯„ä¼°ä½“ç³»çš„ç©ºç™½ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒDARA ç­–ç•¥ç»“åˆ TrueMICL çš„è¯„ä¼°å¯¼å‘ï¼Œèƒ½å¤Ÿæ˜¾è‘—æå‡æ¨¡å‹åœ¨çœŸæ­£çš„å¤šæ¨¡æ€ä¸Šä¸‹æ–‡å­¦ä¹ ä¸­çš„è¡¨ç°ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to COLM 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.15807v2",
      "published_date": "2025-07-21 17:08:18 UTC",
      "updated_date": "2025-08-06 09:36:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:55:00.987243+00:00"
    },
    {
      "arxiv_id": "2507.15803v1",
      "title": "ConformalSAM: Unlocking the Potential of Foundational Segmentation Models in Semi-Supervised Semantic Segmentation with Conformal Prediction",
      "title_zh": "ConformalSAMï¼šåˆ©ç”¨ç¬¦åˆé¢„æµ‹é‡Šæ”¾åŸºç¡€åˆ†å‰²æ¨¡å‹åœ¨åŠç›‘ç£è¯­ä¹‰åˆ†å‰²ä¸­çš„æ½œåŠ›",
      "authors": [
        "Danhui Chen",
        "Ziquan Liu",
        "Chuxi Yang",
        "Dan Wang",
        "Yan Yan",
        "Yi Xu",
        "Xiangyang Ji"
      ],
      "abstract": "Pixel-level vision tasks, such as semantic segmentation, require extensive and high-quality annotated data, which is costly to obtain. Semi-supervised semantic segmentation (SSSS) has emerged as a solution to alleviate the labeling burden by leveraging both labeled and unlabeled data through self-training techniques. Meanwhile, the advent of foundational segmentation models pre-trained on massive data, has shown the potential to generalize across domains effectively. This work explores whether a foundational segmentation model can address label scarcity in the pixel-level vision task as an annotator for unlabeled images. Specifically, we investigate the efficacy of using SEEM, a Segment Anything Model (SAM) variant fine-tuned for textual input, to generate predictive masks for unlabeled data. To address the shortcomings of using SEEM-generated masks as supervision, we propose ConformalSAM, a novel SSSS framework which first calibrates the foundation model using the target domain's labeled data and then filters out unreliable pixel labels of unlabeled data so that only high-confidence labels are used as supervision. By leveraging conformal prediction (CP) to adapt foundation models to target data through uncertainty calibration, ConformalSAM exploits the strong capability of the foundational segmentation model reliably which benefits the early-stage learning, while a subsequent self-reliance training strategy mitigates overfitting to SEEM-generated masks in the later training stage. Our experiment demonstrates that, on three standard benchmarks of SSSS, ConformalSAM achieves superior performance compared to recent SSSS methods and helps boost the performance of those methods as a plug-in.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† ConformalSAMï¼Œä¸€ç§æ—¨åœ¨åˆ©ç”¨åŸºç¡€åˆ†å‰²æ¨¡å‹ (Foundational Segmentation Models) è§£å†³åŠç›‘ç£è¯­ä¹‰åˆ†å‰² (Semi-Supervised Semantic Segmentation, SSSS) ä¸­æ ‡ç­¾ç¨€ç¼ºé—®é¢˜çš„æ–°å‹æ¡†æ¶ã€‚è¯¥æ¡†æ¶æ¢ç´¢äº†ä½¿ç”¨ Segment Anything Model (SAM) çš„å˜ä½“ SEEM ä¸ºæ— æ ‡ç­¾æ•°æ®ç”Ÿæˆé¢„æµ‹æ©ç ï¼Œå¹¶å¼•å…¥äº†ä¸€è‡´æ€§é¢„æµ‹ (Conformal Prediction, CP) æŠ€æœ¯æ¥åº”å¯¹åŸºç¡€æ¨¡å‹ç”Ÿæˆçš„æ©ç è´¨é‡ä¸ç¨³å®šçš„æŒ‘æˆ˜ã€‚é€šè¿‡åœ¨ç›®æ ‡åŸŸçš„æœ‰æ ‡ç­¾æ•°æ®ä¸Šæ ¡å‡†åŸºç¡€æ¨¡å‹å¹¶è¿‡æ»¤æ‰ä¸å¯é çš„åƒç´ æ ‡ç­¾ï¼ŒConformalSAM ç¡®ä¿äº†æ¨¡å‹ä»…åˆ©ç”¨é«˜ç½®ä¿¡åº¦çš„ç›‘ç£ä¿¡å·è¿›è¡Œæ—©æœŸå­¦ä¹ ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜é‡‡ç”¨äº†è‡ªä¾èµ–è®­ç»ƒç­–ç•¥ (self-reliance training strategy) æ¥ç¼“è§£æ¨¡å‹åœ¨è®­ç»ƒåæœŸå¯¹ SEEM ç”Ÿæˆæ©ç çš„è¿‡æ‹Ÿåˆã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒConformalSAM åœ¨ä¸‰ä¸ªæ ‡å‡† SSSS åŸºå‡†æµ‹è¯•ä¸­å‡è¾¾åˆ°äº†é¢†å…ˆæ€§èƒ½ï¼Œä¸”èƒ½ä½œä¸ºæ’ä»¶ (plug-in) æ˜¾è‘—å¢å¼ºç°æœ‰ SSSS æ–¹æ³•çš„è¡¨ç°ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "ICCV 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.15803v1",
      "published_date": "2025-07-21 17:02:57 UTC",
      "updated_date": "2025-07-21 17:02:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:55:35.784579+00:00"
    },
    {
      "arxiv_id": "2507.15796v1",
      "title": "Challenges of Trustworthy Federated Learning: What's Done, Current Trends and Remaining Work",
      "title_zh": "å¯ä¿¡è”é‚¦å­¦ä¹ é¢ä¸´çš„æŒ‘æˆ˜ï¼šç ”ç©¶ç°çŠ¶ã€è¶‹åŠ¿ä¸æœªæ¥å·¥ä½œ",
      "authors": [
        "Nuria RodrÃ­guez-Barroso",
        "Mario GarcÃ­a-MÃ¡rquez",
        "M. Victoria LuzÃ³n",
        "Francisco Herrera"
      ],
      "abstract": "In recent years, the development of Trustworthy Artificial Intelligence (TAI) has emerged as a critical objective in the deployment of AI systems across sensitive and high-risk domains. TAI frameworks articulate a comprehensive set of ethical, legal, and technical requirements to ensure that AI technologies are aligned with human values, rights, and societal expectations. Among the various AI paradigms, Federated Learning (FL) presents a promising solution to pressing privacy concerns. However, aligning FL with the rest of the requirements of TAI presents a series of challenges, most of which arise from its inherently distributed nature. In this work, we adopt the requirements TAI as a guiding structure to systematically analyze the challenges of adapting FL to TAI. Specifically, we classify and examine the key obstacles to aligning FL with TAI, providing a detailed exploration of what has been done, the trends, and the remaining work within each of the identified challenges.",
      "tldr_zh": "è¯¥ç ”ç©¶ç³»ç»Ÿåœ°æ¢è®¨äº†å°†Trustworthy Artificial Intelligence (TAI)æ¡†æ¶åº”ç”¨äºFederated Learning (FL)æ‰€é¢ä¸´çš„æŒ‘æˆ˜ã€‚è™½ç„¶FLåœ¨è§£å†³éšç§é—®é¢˜æ–¹é¢å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ï¼Œä½†ç”±äºå…¶å›ºæœ‰çš„åˆ†å¸ƒå¼ç‰¹æ€§ï¼Œå°†å…¶ä¸TAIçš„ä¼¦ç†ã€æ³•å¾‹å’ŒæŠ€æœ¯è¦æ±‚å¯¹é½ä»é¢ä¸´ä¸€ç³»åˆ—å¤æ‚éšœç¢ã€‚æœ¬æ–‡é‡‡ç”¨TAIçš„è¦æ±‚ä½œä¸ºæŒ‡å¯¼ç»“æ„ï¼Œç³»ç»Ÿåœ°åˆ†ç±»å¹¶åˆ†æäº†FLåœ¨å®ç°å¯ä¿¡åŒ–è¿‡ç¨‹ä¸­çš„å…³é”®æŠ€æœ¯æŒ‘æˆ˜ã€‚é€šè¿‡å¯¹ç°æœ‰ç ”ç©¶æˆæœã€å½“å‰å‘å±•è¶‹åŠ¿ä»¥åŠæœªæ¥å¾…è§£å†³é—®é¢˜çš„è¯¦ç»†å®¡æŸ¥ï¼Œè¯¥å·¥ä½œä¸ºæ„å»ºç¬¦åˆäººç±»ä»·å€¼è§‚å’Œç¤¾ä¼šæœŸæœ›çš„AIç³»ç»Ÿæä¾›äº†é‡è¦å‚è€ƒã€‚è¿™é¡¹ç»¼è¿°ä¸ä»…æ€»ç»“äº†å½“å‰çš„è¿›å±•ï¼Œè¿˜ä¸ºåœ¨æ•æ„Ÿå’Œé«˜é£é™©é¢†åŸŸéƒ¨ç½²å®‰å…¨ã€é€æ˜ä¸”å¯é çš„Federated Learningç³»ç»ŸæŒ‡æ˜äº†ç ”ç©¶æ–¹å‘ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.15796v1",
      "published_date": "2025-07-21 16:57:06 UTC",
      "updated_date": "2025-07-21 16:57:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:55:29.894201+00:00"
    },
    {
      "arxiv_id": "2507.15788v1",
      "title": "Small LLMs Do Not Learn a Generalizable Theory of Mind via Reinforcement Learning",
      "title_zh": "å°å‹å¤§è¯­è¨€æ¨¡å‹æ— æ³•é€šè¿‡å¼ºåŒ–å­¦ä¹ ä¹ å¾—å¯æ³›åŒ–çš„å¿ƒç†ç†è®º",
      "authors": [
        "Sneheel Sarangi",
        "Hanan Salam"
      ],
      "abstract": "Recent advancements in large language models (LLMs) have demonstrated emergent capabilities in complex reasoning, largely spurred by rule-based Reinforcement Learning (RL) techniques applied during the post-training. This has raised the question of whether similar methods can instill more nuanced, human-like social intelligence, such as a Theory of Mind (ToM), in LLMs. This paper investigates whether small-scale LLMs can acquire a robust and generalizable ToM capability through RL with verifiable rewards (RLVR). We conduct a systematic evaluation by training models on various combinations of prominent ToM datasets (HiToM, ExploreToM, FANToM) and testing for generalization on held-out datasets (e.g., OpenToM). Our findings indicate that small LLMs struggle to develop a generic ToM capability. While performance on in-distribution tasks improves, this capability fails to transfer to unseen ToM tasks with different characteristics. Furthermore, we demonstrate that prolonged RL training leads to models ``hacking'' the statistical patterns of the training datasets, resulting in significant performance gains on in-domain data but no change, or degradation of performance on out-of-distribution tasks. This suggests the learned behavior is a form of narrow overfitting rather than the acquisition of a true, abstract ToM capability.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å°å‹å¤§è¯­è¨€æ¨¡å‹(Small LLMs)æ˜¯å¦èƒ½é€šè¿‡åŸºäºå¯éªŒè¯å¥–åŠ±çš„å¼ºåŒ–å­¦ä¹ (RLVR)è·å¾—é€šç”¨ä¸”å¯æ³›åŒ–çš„å¿ƒæ™ºç†è®º(Theory of Mind, ToM)èƒ½åŠ›ã€‚ç ”ç©¶äººå‘˜åœ¨HiToMã€ExploreToMå’ŒFANToMç­‰æ•°æ®é›†ä¸Šå¯¹æ¨¡å‹è¿›è¡Œè®­ç»ƒï¼Œå¹¶åœ¨OpenToMç­‰ç•™å‡ºæ•°æ®é›†ä¸Šæµ‹è¯•å…¶æ³›åŒ–æ€§èƒ½ã€‚å®éªŒå‘ç°å°å‹LLMéš¾ä»¥å»ºç«‹é€šç”¨çš„ToMèƒ½åŠ›ï¼Œè™½ç„¶å…¶åœ¨åˆ†å¸ƒå†…(in-distribution)ä»»åŠ¡ä¸Šçš„è¡¨ç°æœ‰æ‰€æé«˜ï¼Œä½†è¿™ç§èƒ½åŠ›æ— æ³•è¿ç§»è‡³å…·æœ‰ä¸åŒç‰¹å¾çš„æœªè§ä»»åŠ¡ã€‚ç ”ç©¶è¿›ä¸€æ­¥è¯å®ï¼Œé•¿æ—¶é—´çš„å¼ºåŒ–å­¦ä¹ ä¼šå¯¼è‡´æ¨¡å‹å¯¹è®­ç»ƒæ•°æ®é›†çš„ç»Ÿè®¡æ¨¡å¼äº§ç”Ÿâ€œå¥–åŠ±ç ´è§£â€(reward hacking)ï¼Œå¯¼è‡´åŸŸå†…è¡¨ç°æ˜¾è‘—æå‡è€Œåˆ†å¸ƒå¤–(out-of-distribution)ä»»åŠ¡è¡¨ç°æ— æ”¹å–„ç”šè‡³æ¶åŒ–ã€‚è¿™è¡¨æ˜æ¨¡å‹ä¹ å¾—çš„è¡Œä¸ºæœ¬è´¨ä¸Šæ˜¯é’ˆå¯¹ç‰¹å®šä»»åŠ¡çš„è¿‡åº¦æ‹Ÿåˆï¼Œè€ŒéçœŸæ­£ä¹ å¾—äº†æŠ½è±¡çš„ToMæ¨ç†èƒ½åŠ›ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.15788v1",
      "published_date": "2025-07-21 16:47:59 UTC",
      "updated_date": "2025-07-21 16:47:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:55:30.688457+00:00"
    },
    {
      "arxiv_id": "2507.15783v3",
      "title": "Understanding Teen Overreliance on AI Companion Chatbots Through Self-Reported Reddit Narratives",
      "title_zh": "åŸºäº Reddit è‡ªè¿°å™äº‹çš„é’å°‘å¹´ AI ä¼´ä¾£èŠå¤©æœºå™¨äººè¿‡åº¦ä¾èµ–æ¢ç©¶",
      "authors": [
        "Mohammad Namvarpour",
        "Brandon Brofsky",
        "Jessica Medina",
        "Mamtaj Akter",
        "Afsaneh Razi"
      ],
      "abstract": "AI companion chatbots are increasingly popular with teens, while these interactions are entertaining, they also risk overuse that can potentially disrupt offline daily life. We examined how adolescents describe reliance on AI companions, mapping their experiences onto behavioral addiction frameworks and exploring pathways to disengagement, by analyzing 318 Reddit posts made by users who self-disclosed as 13-17 years old on the Character.AI subreddit. We found teens often begin using chatbots for support or creative play, but these activities can deepen into strong attachments marked by conflict, withdrawal, tolerance, relapse, and mood regulation. Reported consequences include sleep loss, academic decline, and strained real-world connections. Disengagement commonly arises when teens recognize harm, re-engage with offline life, or encounter restrictive platform changes. We highlight specific risks of character-based companion chatbots based on teens' perspectives and introduce a design framework (CARE) for guidance for safer systems and setting directions for future teen-centered research.",
      "tldr_zh": "è¯¥ç ”ç©¶é€šè¿‡åˆ†æCharacter.AIå­ç‰ˆå—ä¸­318ç¯‡ç”±13-17å²é’å°‘å¹´å‘å¸ƒçš„Redditå¸–å­ï¼Œæ¢è®¨äº†é’å°‘å¹´å¯¹AI companion chatbotsè¿‡åº¦ä¾èµ–çš„ç°è±¡ã€‚ç ”ç©¶å°†ç”¨æˆ·ä½“éªŒæ˜ å°„åˆ°è¡Œä¸ºæˆç˜¾(behavioral addiction)æ¡†æ¶ï¼Œå‘ç°é’å°‘å¹´æœ€åˆå› å¯»æ±‚æ”¯æŒæˆ–åˆ›æ„æ¸¸æˆå¼€å§‹ä½¿ç”¨ï¼Œä½†éšåå¯èƒ½æ¼”å˜ä¸ºåŒ…å«å†²çªã€æˆ’æ–­(withdrawal)ã€è€å—(tolerance)ã€å¤å‘(relapse)å’Œæƒ…ç»ªè°ƒèŠ‚(mood regulation)ç­‰ç‰¹å¾çš„æ·±åº¦ä¾æ‹ã€‚è¿™ç§è¿‡åº¦ä½¿ç”¨å¯¼è‡´äº†ç¡çœ ä¸è¶³ã€å­¦ä¸šä¸‹æ»‘åŠç°å®ä¸–ç•Œç¤¾äº¤å…³ç³»å—æŸç­‰åæœã€‚ç ”ç©¶è¿›ä¸€æ­¥æ¢è®¨äº†é’å°‘å¹´åœ¨æ„è¯†åˆ°å±å®³æˆ–é­é‡å¹³å°é™åˆ¶æ€§å˜åŒ–æ—¶çš„è„±ç¦»(disengagement)è·¯å¾„ã€‚æœ€åï¼Œç ”ç©¶æ ¹æ®é’å°‘å¹´è§†è§’æå‡ºäº†CAREè®¾è®¡æ¡†æ¶ï¼Œä¸ºæ„å»ºæ›´å®‰å…¨çš„ç³»ç»ŸåŠæœªæ¥ä»¥é’å°‘å¹´ä¸ºä¸­å¿ƒçš„ç ”ç©¶æä¾›äº†æ–¹å‘ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.HC",
      "comment": "Under Review for CHI 2026",
      "pdf_url": "https://arxiv.org/pdf/2507.15783v3",
      "published_date": "2025-07-21 16:39:33 UTC",
      "updated_date": "2025-10-09 15:09:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:55:35.101020+00:00"
    },
    {
      "arxiv_id": "2507.15775v1",
      "title": "Learning Null Geodesics for Gravitational Lensing Rendering in General Relativity",
      "title_zh": "å¹¿ä¹‰ç›¸å¯¹è®ºä¸­ç”¨äºå¼•åŠ›é€é•œæ¸²æŸ“çš„é›¶æµ‹åœ°çº¿å­¦ä¹ ",
      "authors": [
        "Mingyuan Sun",
        "Zheng Fang",
        "Jiaxu Wang",
        "Kunyi Zhang",
        "Qiang Zhang",
        "Renjing Xu"
      ],
      "abstract": "We present GravLensX, an innovative method for rendering black holes with gravitational lensing effects using neural networks. The methodology involves training neural networks to fit the spacetime around black holes and then employing these trained models to generate the path of light rays affected by gravitational lensing. This enables efficient and scalable simulations of black holes with optically thin accretion disks, significantly decreasing the time required for rendering compared to traditional methods. We validate our approach through extensive rendering of multiple black hole systems with superposed Kerr metric, demonstrating its capability to produce accurate visualizations with significantly $15\\times$ reduced computational time. Our findings suggest that neural networks offer a promising alternative for rendering complex astrophysical phenomena, potentially paving a new path to astronomical visualization.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† GravLensXï¼Œè¿™æ˜¯ä¸€ç§åˆ©ç”¨ç¥ç»ç½‘ç»œè¿›è¡Œå¹¿ä¹‰ç›¸å¯¹è®ºä¸­ gravitational lensing æ•ˆåº”é»‘æ´æ¸²æŸ“çš„åˆ›æ–°æ–¹æ³•ã€‚è¯¥æ–¹æ³•é€šè¿‡è®­ç»ƒç¥ç»ç½‘ç»œæ‹Ÿåˆé»‘æ´å‘¨å›´çš„ spacetimeï¼Œå¹¶åˆ©ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹ç”Ÿæˆå—å¼•åŠ›é€é•œå½±å“çš„å…‰çº¿è·¯å¾„ï¼Œå³ null geodesicsã€‚è¿™ç§æ–¹å¼å®ç°äº†å¯¹å¸¦æœ‰ optically thin accretion disks çš„é»‘æ´è¿›è¡Œé«˜æ•ˆä¸”å¯æ‰©å±•çš„æ¨¡æ‹Ÿï¼Œæ˜¾è‘—é™ä½äº†ä¼ ç»Ÿæ–¹æ³•æ‰€éœ€çš„æ¸²æŸ“æ—¶é—´ã€‚é€šè¿‡å¯¹å…·æœ‰å åŠ  Kerr metric çš„å¤šé»‘æ´ç³»ç»Ÿè¿›è¡Œå¤§é‡æ¸²æŸ“éªŒè¯ï¼Œç»“æœæ˜¾ç¤ºè¯¥æ–¹æ³•åœ¨ä¿æŒå¯è§†åŒ–å‡†ç¡®æ€§çš„åŒæ—¶ï¼Œå°†è®¡ç®—æ—¶é—´æ˜¾è‘—ç¼©çŸ­äº† 15 å€ã€‚ç ”ç©¶è¡¨æ˜ç¥ç»ç½‘ç»œä¸º complex astrophysical phenomena çš„æ¸²æŸ“æä¾›äº†ä¸€ç§æå…·å‰æ™¯çš„æ›¿ä»£æ–¹æ¡ˆï¼Œä¸º astronomical visualization é¢†åŸŸå¼€è¾Ÿäº†æ–°çš„æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "gr-qc",
        "astro-ph.IM",
        "cs.AI"
      ],
      "primary_category": "gr-qc",
      "comment": "ICCV 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.15775v1",
      "published_date": "2025-07-21 16:30:36 UTC",
      "updated_date": "2025-07-21 16:30:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:55:39.090099+00:00"
    },
    {
      "arxiv_id": "2507.15774v1",
      "title": "Dynamics is what you need for time-series forecasting!",
      "title_zh": "åŠ¨åŠ›å­¦æ‰æ˜¯æ—¶é—´åºåˆ—é¢„æµ‹çš„å…³é”®ï¼",
      "authors": [
        "Alexis-Raja Brachet",
        "Pierre-Yves Richard",
        "CÃ©line Hudelot"
      ],
      "abstract": "While boundaries between data modalities are vanishing, the usual successful deep models are still challenged by simple ones in the time-series forecasting task. Our hypothesis is that this task needs models that are able to learn the data underlying dynamics. We propose to validate it through both systemic and empirical studies. We develop an original $\\texttt{PRO-DYN}$ nomenclature to analyze existing models through the lens of dynamics. Two observations thus emerged: $\\textbf{1}$. under-performing architectures learn dynamics at most partially, $\\textbf{2}$. the location of the dynamics block at the model end is of prime importance. We conduct extensive experiments to confirm our observations on a set of performance-varying models with diverse backbones. Results support the need to incorporate a learnable dynamics block and its use as the final predictor.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ·±åº¦å­¦ä¹ æ¨¡å‹åœ¨æ—¶é—´åºåˆ—é¢„æµ‹(Time-series forecasting)ä»»åŠ¡ä¸­é¢ä¸´çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†æ¨¡å‹å¿…é¡»èƒ½å¤Ÿå­¦ä¹ æ•°æ®æ½œåœ¨åŠ¨åŠ›å­¦(Dynamics)çš„æ ¸å¿ƒå‡è®¾ã€‚ä¸ºäº†éªŒè¯è¿™ä¸€å‡è®¾ï¼Œä½œè€…å¼€å‘äº†ä¸€å¥—åä¸º PRO-DYN çš„å‘½åä½“ç³»ï¼Œä»åŠ¨åŠ›å­¦çš„è§†è§’å¯¹ç°æœ‰æ¨¡å‹è¿›è¡Œäº†ç³»ç»Ÿæ€§ä¸å®è¯æ€§åˆ†æã€‚ç ”ç©¶å‘ç°ï¼Œè¡¨ç°ä¸ä½³çš„æ¶æ„å¾€å¾€åªèƒ½éƒ¨åˆ†åœ°å­¦ä¹ åˆ°åŠ¨åŠ›å­¦ç‰¹å¾ï¼Œä¸”åŠ¨åŠ›å­¦æ¨¡å—åœ¨æ¨¡å‹æœ«ç«¯çš„ä½ç½®å¯¹äºé¢„æµ‹æ•ˆæœè‡³å…³é‡è¦ã€‚é€šè¿‡åœ¨å¤šç§ä¸åŒéª¨å¹²ç½‘ç»œ(Backbones)ä¸Šè¿›è¡Œçš„å¹¿æ³›å®éªŒï¼Œè¯¥ç ”ç©¶ç¡®è®¤äº†å¼•å…¥å¯å­¦ä¹ åŠ¨åŠ›å­¦æ¨¡å—çš„å¿…è¦æ€§ã€‚ç»“æœè¡¨æ˜ï¼Œå°†åŠ¨åŠ›å­¦æ¨¡å—ä½œä¸ºæœ€ç»ˆé¢„æµ‹å™¨(Final predictor)èƒ½æœ‰æ•ˆæå‡æ¨¡å‹æ€§èƒ½ï¼Œå¼ºè°ƒäº†åŠ¨åŠ›å­¦å»ºæ¨¡åœ¨æ—¶é—´åºåˆ—é¢„æµ‹ä¸­çš„æ ¸å¿ƒåœ°ä½ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "13 pages, 6 figures, 1 table",
      "pdf_url": "https://arxiv.org/pdf/2507.15774v1",
      "published_date": "2025-07-21 16:29:29 UTC",
      "updated_date": "2025-07-21 16:29:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:55:45.588323+00:00"
    },
    {
      "arxiv_id": "2507.15773v2",
      "title": "Supernova: Achieving More with Less in Transformer Architectures",
      "title_zh": "Supernovaï¼šåœ¨ Transformer æ¶æ„ä¸­å®ç°ä»¥å°‘èƒœå¤š",
      "authors": [
        "Andrei-Valentin Tanase",
        "Elena Pelican"
      ],
      "abstract": "We present Supernova, a 650M-parameter decoder-only transformer that demonstrates how careful architectural design and tokenization innovation can achieve the performance of larger models while maintaining computational efficiency. Our architecture combines Rotary Positional Embeddings (RoPE), Grouped Query Attention (GQA) with a 3:1 compression ratio, RMSNorm for computational efficiency, and SwiGLU activation functions. A critical innovation is our custom 128,000-vocabulary byte-level BPE tokenizer, which achieves state-of-the-art compression performance. Through detailed analysis, we show that Supernova achieves 90% of the performance of 1B-parameter models while using 35% fewer parameters and requiring only 100B training tokens--an order of magnitude less than competing models. Our findings challenge the prevailing scaling paradigm, demonstrating that architectural efficiency and tokenization quality can compensate for reduced parameter counts.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Supernovaï¼Œä¸€ä¸ªæ‹¥æœ‰6.5äº¿å‚æ•°çš„ä»…è§£ç å™¨(decoder-only)Transformeræ¨¡å‹ï¼Œæ—¨åœ¨é€šè¿‡ç²¾å·§çš„æ¶æ„è®¾è®¡å’Œåˆ†è¯å™¨(tokenization)åˆ›æ–°ï¼Œåœ¨ä¿æŒè®¡ç®—æ•ˆç‡çš„åŒæ—¶å®ç°å¤§è§„æ¨¡æ¨¡å‹çš„æ€§èƒ½ã€‚è¯¥æ¶æ„é›†æˆäº†æ—‹è½¬ä½ç½®ç¼–ç (RoPE)ã€å‹ç¼©æ¯”ä¸º3:1çš„åˆ†ç»„æŸ¥è¯¢æ³¨æ„åŠ›(GQA)ã€å‡æ–¹æ ¹å½’ä¸€åŒ–(RMSNorm)ä»¥åŠSwiGLUæ¿€æ´»å‡½æ•°ï¼Œç¡®ä¿äº†é«˜æ•ˆçš„è®¡ç®—è¡¨ç°ã€‚å…¶æ ¸å¿ƒåˆ›æ–°åœ¨äºå¼€å‘äº†ä¸€ä¸ªæ‹¥æœ‰12.8ä¸‡è¯æ±‡é‡çš„è‡ªå®šä¹‰å­—èŠ‚çº§BPEåˆ†è¯å™¨ï¼Œå®ç°äº†é¢†åŸŸé¢†å…ˆçš„å‹ç¼©æ€§èƒ½ã€‚å®éªŒåˆ†æè¡¨æ˜ï¼ŒSupernovaä»…éœ€1000äº¿ä¸ªè®­ç»ƒTokenï¼ˆæ¯”ç«äº‰æ¨¡å‹å°‘ä¸€ä¸ªæ•°é‡çº§ï¼‰ï¼Œä¾¿èƒ½ä»¥å‡å°‘35%å‚æ•°çš„ä»£ä»·è¾¾åˆ°10äº¿å‚æ•°è§„æ¨¡æ¨¡å‹90%çš„æ€§èƒ½ã€‚è¿™ä¸€å‘ç°æŒ‘æˆ˜äº†å½“å‰ä¸»æµçš„ç¼©æ”¾æ³•åˆ™(scaling paradigm)ï¼Œè¯æ˜äº†æ¶æ„æ•ˆç‡å’Œåˆ†è¯è´¨é‡èƒ½å¤Ÿæœ‰æ•ˆå¼¥è¡¥å‚æ•°æ•°é‡çš„å‡å°‘ï¼Œä¸ºå¼€å‘é«˜æ€§èƒ½ã€è½»é‡åŒ–çš„æ¨¡å‹æ¶æ„æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.15773v2",
      "published_date": "2025-07-21 16:27:48 UTC",
      "updated_date": "2025-07-22 13:27:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:55:50.152991+00:00"
    },
    {
      "arxiv_id": "2507.15772v1",
      "title": "Deep-Learning Investigation of Vibrational Raman Spectra for Plant-Stress Analysis",
      "title_zh": "åŸºäºæ·±åº¦å­¦ä¹ çš„æŒ¯åŠ¨æ‹‰æ›¼å…‰è°±æ¤ç‰©èƒè¿«åˆ†æç ”ç©¶",
      "authors": [
        "Anoop C. Patil",
        "Benny Jian Rong Sng",
        "Yu-Wei Chang",
        "Joana B. Pereira",
        "Chua Nam-Hai",
        "Rajani Sarojam",
        "Gajendra Pratap Singh",
        "In-Cheol Jang",
        "Giovanni Volpe"
      ],
      "abstract": "Detecting stress in plants is crucial for both open-farm and controlled-environment agriculture. Biomolecules within plants serve as key stress indicators, offering vital markers for continuous health monitoring and early disease detection. Raman spectroscopy provides a powerful, non-invasive means to quantify these biomolecules through their molecular vibrational signatures. However, traditional Raman analysis relies on customized data-processing workflows that require fluorescence background removal and prior identification of Raman peaks of interest-introducing potential biases and inconsistencies. Here, we introduce DIVA (Deep-learning-based Investigation of Vibrational Raman spectra for plant-stress Analysis), a fully automated workflow based on a variational autoencoder. Unlike conventional approaches, DIVA processes native Raman spectra-including fluorescence backgrounds-without manual preprocessing, identifying and quantifying significant spectral features in an unbiased manner. We applied DIVA to detect a range of plant stresses, including abiotic (shading, high light intensity, high temperature) and biotic stressors (bacterial infections). By integrating deep learning with vibrational spectroscopy, DIVA paves the way for AI-driven plant health assessment, fostering more resilient and sustainable agricultural practices.",
      "tldr_zh": "è¯¥ç ”ç©¶å¼€å‘äº†åä¸º DIVA (Deep-learning-based Investigation of Vibrational Raman spectra for plant-stress Analysis) çš„å…¨è‡ªåŠ¨å·¥ä½œæµï¼Œæ—¨åœ¨é€šè¿‡ deep learning æŠ€æœ¯æ”¹è¿›æ¤ç‰©å‹åŠ›æ£€æµ‹ã€‚ä¼ ç»Ÿçš„ Raman spectroscopy åˆ†æé€šå¸¸éœ€è¦ç¹ççš„è§å…‰èƒŒæ™¯å»é™¤å’Œäººå·¥å³°å€¼è¯†åˆ«ï¼Œå®¹æ˜“å¼•å…¥äººä¸ºåå·®ï¼Œè€Œ DIVA åŸºäº variational autoencoder æ¶æ„ï¼Œèƒ½å¤Ÿç›´æ¥å¤„ç†åŒ…å«è§å…‰èƒŒæ™¯çš„åŸå§‹å…‰è°± (native Raman spectra)ï¼Œå®ç°äº†æ— åå·®çš„å…‰è°±ç‰¹å¾æå–ä¸é‡åŒ–ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆè¯†åˆ«åŒ…æ‹¬é«˜æ¸©ã€å¼ºå…‰ã€é®è«ç­‰éç”Ÿç‰©å‹åŠ› (abiotic stressors) ä»¥åŠç»†èŒæ„ŸæŸ“ç­‰ç”Ÿç‰©å‹åŠ› (biotic stressors)ã€‚é€šè¿‡æ•´åˆ vibrational spectroscopy ä¸æ·±åº¦å­¦ä¹ ç®—æ³•ï¼ŒDIVA ä¸ºè‡ªåŠ¨åŒ–ã€éä¾µå…¥å¼çš„æ¤ç‰©å¥åº·ç›‘æµ‹æä¾›äº†é«˜æ•ˆæ–¹æ¡ˆã€‚è¿™ä¸€ç ”ç©¶ä¸º AI é©±åŠ¨çš„æ¤ç‰©å¥åº·è¯„ä¼°é“ºå¹³äº†é“è·¯ï¼Œæœ‰åŠ©äºå®ç°æ›´å…·éŸ§æ€§å’Œå¯æŒç»­æ€§çš„å†œä¸šå®è·µã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.BM"
      ],
      "primary_category": "cs.LG",
      "comment": "*Authors contributed equally to this work. +Supervised this work. 5 main figures and 1 extended data figure in manuscript. The PDF includes supplementary material",
      "pdf_url": "https://arxiv.org/pdf/2507.15772v1",
      "published_date": "2025-07-21 16:27:34 UTC",
      "updated_date": "2025-07-21 16:27:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:55:51.659110+00:00"
    },
    {
      "arxiv_id": "2507.15771v2",
      "title": "Left Leaning Models: How AI Evaluates Economic Policy?",
      "title_zh": "å·¦å€¾æ¨¡å‹ï¼šäººå·¥æ™ºèƒ½å¦‚ä½•è¯„ä¼°ç»æµæ”¿ç­–ï¼Ÿ",
      "authors": [
        "Maxim Chupilkin"
      ],
      "abstract": "Would artificial intelligence (AI) cut interest rates or adopt conservative monetary policy? Would it deregulate or opt for a more controlled economy? As AI use by economic policymakers, academics, and market participants grows exponentially, it is becoming critical to understand AI preferences over economic policy. However, these preferences are not yet systematically evaluated and remain a black box. This paper makes a conjoint experiment on leading large language models (LLMs) from OpenAI, Anthropic, and Google, asking them to evaluate economic policy under multi-factor constraints. The results are remarkably consistent across models: most LLMs exhibit a strong preference for high growth, low unemployment, and low inequality over traditional macroeconomic concerns such as low inflation and low public debt. Scenario-specific experiments show that LLMs are sensitive to context but still display strong preferences for low unemployment and low inequality even in monetary-policy settings. Numerical sensitivity tests reveal intuitive responses to quantitative changes but also uncover non-linear patterns such as loss aversion.",
      "tldr_zh": "è¯¥ç ”ç©¶é€šè¿‡ä¸€é¡¹é’ˆå¯¹ OpenAIã€Anthropic å’Œ Google æ——ä¸‹ä¸»æµå¤§è¯­è¨€æ¨¡å‹ (LLMs) çš„è”åˆå®éªŒ (conjoint experiment)ï¼Œç³»ç»Ÿè¯„ä¼°äº† AI åœ¨å¤šå› ç´ çº¦æŸä¸‹å¯¹ç»æµæ”¿ç­–çš„åå¥½ã€‚å®éªŒç»“æœåœ¨ä¸åŒæ¨¡å‹é—´è¡¨ç°å‡ºæ˜¾è‘—çš„ä¸€è‡´æ€§ï¼šå¤§å¤šæ•° LLMs è¡¨ç°å‡ºå¯¹é«˜å¢é•¿ (high growth)ã€ä½å¤±ä¸šç‡ (low unemployment) å’Œä½ä¸å¹³ç­‰ (low inequality) çš„å¼ºçƒˆåå¥½ï¼Œè€Œå¯¹ä½é€šè´§è†¨èƒ€ (low inflation) å’Œä½å…¬å…±å€ºåŠ¡ (low public debt) ç­‰ä¼ ç»Ÿå®è§‚ç»æµå…³æ³¨ç‚¹çš„é‡è§†ç¨‹åº¦ç›¸å¯¹è¾ƒä½ã€‚æƒ…æ™¯å®éªŒè¡¨æ˜ï¼ŒLLMs è™½ç„¶å¯¹è¯­å¢ƒå…·æœ‰æ•æ„Ÿæ€§ï¼Œä½†åœ¨è´§å¸æ”¿ç­– (monetary-policy) è®¾ç½®ä¸­ä¾ç„¶åšæŒå¯¹ä½å¤±ä¸šç‡å’Œä½ä¸å¹³ç­‰çš„ä¼˜å…ˆé€‰æ‹©ã€‚æ•°å€¼æ•æ„Ÿæ€§æµ‹è¯•è¿›ä¸€æ­¥æ­ç¤ºï¼ŒAI å¯¹ç»æµæŒ‡æ ‡çš„å®šé‡å˜åŒ–èƒ½åšå‡ºç›´è§‚ååº”ï¼Œä½†ä¹Ÿè¡¨ç°å‡ºæŸå¤±è§„é¿ (loss aversion) ç­‰å¤æ‚çš„éçº¿æ€§æ¨¡å¼ã€‚è¯¥ç ”ç©¶é€šè¿‡æ­ç¤º AI æ”¿ç­–åå¥½çš„â€œé»‘ç®±â€ï¼Œä¸ºç†è§£ AI åœ¨å®è§‚ç»æµç®¡ç†å’Œæ”¿ç­–åˆ¶å®šä¸­çš„æ½œåœ¨å½±å“æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.CY",
        "cs.AI",
        "econ.GN"
      ],
      "primary_category": "cs.CY",
      "comment": "16 pages, 2 figures, 3 tables",
      "pdf_url": "https://arxiv.org/pdf/2507.15771v2",
      "published_date": "2025-07-21 16:27:16 UTC",
      "updated_date": "2025-12-09 11:17:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:55:56.348488+00:00"
    },
    {
      "arxiv_id": "2507.15770v1",
      "title": "A Framework for Analyzing Abnormal Emergence in Service Ecosystems Through LLM-based Agent Intention Mining",
      "title_zh": "åŸºäºå¤§è¯­è¨€æ¨¡å‹æ™ºèƒ½ä½“æ„å›¾æŒ–æ˜çš„æœåŠ¡ç”Ÿæ€ç³»ç»Ÿå¼‚å¸¸æ¶Œç°åˆ†ææ¡†æ¶",
      "authors": [
        "Yifan Shen",
        "Zihan Zhao",
        "Xiao Xue",
        "Yuwei Guo",
        "Qun Ma",
        "Deyu Zhou",
        "Ming Zhang"
      ],
      "abstract": "With the rise of service computing, cloud computing, and IoT, service ecosystems are becoming increasingly complex. The intricate interactions among intelligent agents make abnormal emergence analysis challenging, as traditional causal methods focus on individual trajectories. Large language models offer new possibilities for Agent-Based Modeling (ABM) through Chain-of-Thought (CoT) reasoning to reveal agent intentions. However, existing approaches remain limited to microscopic and static analysis. This paper introduces a framework: Emergence Analysis based on Multi-Agent Intention (EAMI), which enables dynamic and interpretable emergence analysis. EAMI first employs a dual-perspective thought track mechanism, where an Inspector Agent and an Analysis Agent extract agent intentions under bounded and perfect rationality. Then, k-means clustering identifies phase transition points in group intentions, followed by a Intention Temporal Emergence diagram for dynamic analysis. The experiments validate EAMI in complex online-to-offline (O2O) service system and the Stanford AI Town experiment, with ablation studies confirming its effectiveness, generalizability, and efficiency. This framework provides a novel paradigm for abnormal emergence and causal analysis in service ecosystems. The code is available at https://anonymous.4open.science/r/EAMI-B085.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æœåŠ¡ç”Ÿæ€ç³»ç»Ÿä¸­æ™ºèƒ½ä½“äº¤äº’å¯¼è‡´çš„å¼‚å¸¸æ¶Œç°ï¼ˆAbnormal Emergenceï¼‰åˆ†æéš¾é¢˜ï¼Œæå‡ºäº†EAMIï¼ˆEmergence Analysis based on Multi-Agent Intentionï¼‰æ¡†æ¶ï¼Œæ—¨åœ¨å®ç°åŠ¨æ€ä¸”å¯è§£é‡Šçš„æ¶Œç°åˆ†æã€‚è¯¥æ¡†æ¶åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„é“¾å¼æ€ç»´ï¼ˆChain-of-Thoughtï¼‰æ¨ç†ï¼Œé€šè¿‡Inspector Agentå’ŒAnalysis Agentæ„æˆçš„åŒè§†è§’æ€ç»´è½¨è¿¹æœºåˆ¶ï¼Œåœ¨æœ‰é™ç†æ€§å’Œå®Œå…¨ç†æ€§è§†è§’ä¸‹æå–æ™ºèƒ½ä½“æ„å›¾ã€‚éšåï¼ŒEAMIé‡‡ç”¨k-meansèšç±»è¯†åˆ«ç¾¤ä½“æ„å›¾çš„ç›¸ä½è½¬å˜ç‚¹ï¼Œå¹¶åˆ©ç”¨æ„å›¾æ—¶é—´æ¶Œç°ï¼ˆIntention Temporal Emergenceï¼‰å›¾è¿›è¡ŒåŠ¨æ€åˆ†æã€‚å®éªŒåœ¨å¤æ‚çš„çº¿ä¸Šçº¿ä¸‹ï¼ˆO2Oï¼‰æœåŠ¡ç³»ç»Ÿå’ŒStanford AI Townå®éªŒä¸­éªŒè¯äº†è¯¥æ¡†æ¶çš„æœ‰æ•ˆæ€§ã€æ³›åŒ–èƒ½åŠ›å’Œæ•ˆç‡ã€‚è¿™é¡¹å·¥ä½œä¸ºæœåŠ¡ç”Ÿæ€ç³»ç»Ÿä¸­çš„å¼‚å¸¸æ¶Œç°å’Œå› æœåˆ†ææä¾›äº†ä¸€ç§åŸºäºæ™ºèƒ½ä½“æ„å›¾æŒ–æ˜çš„æ–°å‹ç ”ç©¶èŒƒå¼ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.15770v1",
      "published_date": "2025-07-21 16:26:49 UTC",
      "updated_date": "2025-07-21 16:26:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:55:57.592224+00:00"
    },
    {
      "arxiv_id": "2507.15765v2",
      "title": "Learning from Heterogeneity: Generalizing Dynamic Facial Expression Recognition via Distributionally Robust Optimization",
      "title_zh": "ä»å¼‚è´¨æ€§ä¸­å­¦ä¹ ï¼šåŸºäºåˆ†å¸ƒé²æ£’ä¼˜åŒ–çš„åŠ¨æ€é¢éƒ¨è¡¨æƒ…è¯†åˆ«æ³›åŒ–",
      "authors": [
        "Feng-Qi Cui",
        "Anyang Tong",
        "Jinyang Huang",
        "Jie Zhang",
        "Dan Guo",
        "Zhi Liu",
        "Meng Wang"
      ],
      "abstract": "Dynamic Facial Expression Recognition (DFER) plays a critical role in affective computing and human-computer interaction. Although existing methods achieve comparable performance, they inevitably suffer from performance degradation under sample heterogeneity caused by multi-source data and individual expression variability. To address these challenges, we propose a novel framework, called Heterogeneity-aware Distributional Framework (HDF), and design two plug-and-play modules to enhance time-frequency modeling and mitigate optimization imbalance caused by hard samples. Specifically, the Time-Frequency Distributional Attention Module (DAM) captures both temporal consistency and frequency robustness through a dual-branch attention design, improving tolerance to sequence inconsistency and visual style shifts. Then, based on gradient sensitivity and information bottleneck principles, an adaptive optimization module Distribution-aware Scaling Module (DSM) is introduced to dynamically balance classification and contrastive losses, enabling more stable and discriminative representation learning. Extensive experiments on two widely used datasets, DFEW and FERV39k, demonstrate that HDF significantly improves both recognition accuracy and robustness. Our method achieves superior weighted average recall (WAR) and unweighted average recall (UAR) while maintaining strong generalization across diverse and imbalanced scenarios. Codes are released at https://github.com/QIcita/HDF_DFER.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŠ¨æ€äººè„¸è¡¨æƒ…è¯†åˆ«(Dynamic Facial Expression Recognition, DFER)åœ¨å¤šæºæ•°æ®å’Œä¸ªä½“è¡¨è¾¾å·®å¼‚å¯¼è‡´çš„æ ·æœ¬å¼‚è´¨æ€§ä¸‹æ€§èƒ½ä¸‹é™çš„é—®é¢˜ï¼Œæå‡ºäº†å¼‚è´¨æ€§æ„ŸçŸ¥åˆ†å¸ƒæ¡†æ¶(Heterogeneity-aware Distributional Framework, HDF)ã€‚ä¸ºäº†å¢å¼ºæ—¶é¢‘å»ºæ¨¡ï¼Œç ”ç©¶è®¾è®¡äº†æ—¶é—´-é¢‘ç‡åˆ†å¸ƒæ³¨æ„åŠ›æ¨¡å—(Time-Frequency Distributional Attention Module, DAM)ï¼Œé€šè¿‡åŒåˆ†æ”¯æ³¨æ„åŠ›æ•æ‰æ—¶é—´ä¸€è‡´æ€§å’Œé¢‘ç‡é²æ£’æ€§ï¼Œä»è€Œæé«˜å¯¹åºåˆ—ä¸ä¸€è‡´å’Œè§†è§‰é£æ ¼åç§»çš„å®¹å¿åº¦ã€‚æ­¤å¤–ï¼Œç ”ç©¶åŸºäºæ¢¯åº¦æ•æ„Ÿåº¦å’Œä¿¡æ¯ç“¶é¢ˆåŸåˆ™å¼•å…¥äº†åˆ†å¸ƒæ„ŸçŸ¥ç¼©æ”¾æ¨¡å—(Distribution-aware Scaling Module, DSM)ï¼Œæ—¨åœ¨åŠ¨æ€å¹³è¡¡åˆ†ç±»ä¸å¯¹æ¯”æŸå¤±ï¼Œå®ç°æ›´ç¨³å®šä¸”å…·åŒºåˆ†åŠ›çš„è¡¨ç¤ºå­¦ä¹ ã€‚åœ¨DFEWå’ŒFERV39kæ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒHDFæ˜¾è‘—æå‡äº†è¯†åˆ«å‡†ç¡®ç‡å’Œé²æ£’æ€§ï¼Œåœ¨å¤šæ ·åŒ–ä¸”ä¸å¹³è¡¡çš„åœºæ™¯ä¸­å±•ç°å‡ºå¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ã€‚è¯¥æ–¹æ³•åœ¨åŠ æƒå¹³å‡å¬å›ç‡(WAR)å’ŒéåŠ æƒå¹³å‡å¬å›ç‡(UAR)ç­‰æŒ‡æ ‡ä¸Šå‡å–å¾—äº†å“è¶Šè¡¨ç°ï¼Œä¸ºè§£å†³DFERé¢†åŸŸä¸­çš„æ•°æ®å¼‚è´¨æ€§æŒ‘æˆ˜æä¾›äº†æœ‰æ•ˆçš„æŠ€æœ¯æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ACM MM'25",
      "pdf_url": "https://arxiv.org/pdf/2507.15765v2",
      "published_date": "2025-07-21 16:21:47 UTC",
      "updated_date": "2025-07-26 14:16:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:56:12.753134+00:00"
    },
    {
      "arxiv_id": "2507.15761v1",
      "title": "GasAgent: A Multi-Agent Framework for Automated Gas Optimization in Smart Contracts",
      "title_zh": "GasAgentï¼šé¢å‘æ™ºèƒ½åˆçº¦è‡ªåŠ¨åŒ– Gas ä¼˜åŒ–çš„å¤šæ™ºèƒ½ä½“æ¡†æ¶",
      "authors": [
        "Jingyi Zheng",
        "Zifan Peng",
        "Yule Liu",
        "Junfeng Wang",
        "Yifan Liao",
        "Wenhan Dong",
        "Xinlei He"
      ],
      "abstract": "Smart contracts are trustworthy, immutable, and automatically executed programs on the blockchain. Their execution requires the Gas mechanism to ensure efficiency and fairness. However, due to non-optimal coding practices, many contracts contain Gas waste patterns that need to be optimized. Existing solutions mostly rely on manual discovery, which is inefficient, costly to maintain, and difficult to scale. Recent research uses large language models (LLMs) to explore new Gas waste patterns. However, it struggles to remain compatible with existing patterns, often produces redundant patterns, and requires manual validation/rewriting. To address this gap, we present GasAgent, the first multi-agent system for smart contract Gas optimization that combines compatibility with existing patterns and automated discovery/validation of new patterns, enabling end-to-end optimization. GasAgent consists of four specialized agents, Seeker, Innovator, Executor, and Manager, that collaborate in a closed loop to identify, validate, and apply Gas-saving improvements. Experiments on 100 verified real-world contracts demonstrate that GasAgent successfully optimizes 82 contracts, achieving an average deployment Gas savings of 9.97%. In addition, our evaluation confirms its compatibility with existing tools and validates the effectiveness of each module through ablation studies. To assess broader usability, we further evaluate 500 contracts generated by five representative LLMs across 10 categories and find that GasAgent optimizes 79.8% of them, with deployment Gas savings ranging from 4.79% to 13.93%, showing its usability as the optimization layer for LLM-assisted smart contract development.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ™ºèƒ½åˆçº¦(Smart contracts)ä¸­å› ç¼–ç å®è·µéæœ€ä¼˜å¯¼è‡´çš„Gasæµªè´¹é—®é¢˜ï¼Œæå‡ºäº†é¦–ä¸ªç”¨äºè‡ªåŠ¨åŒ–Gasä¼˜åŒ–çš„å¤šæ™ºèƒ½ä½“æ¡†æ¶GasAgentã€‚è¯¥ç³»ç»Ÿç”±Seekerã€Innovatorã€Executorå’ŒManagerå››ä¸ªä¸“ä¸šæ™ºèƒ½ä½“ç»„æˆï¼Œé€šè¿‡é—­ç¯åä½œå®ç°å¯¹ç°æœ‰æ¨¡å¼çš„å…¼å®¹ä»¥åŠæ–°ä¼˜åŒ–æ¨¡å¼çš„è‡ªåŠ¨åŒ–å‘ç°ä¸éªŒè¯ã€‚åœ¨é’ˆå¯¹100ä¸ªçœŸå®ä¸–ç•Œåˆçº¦çš„å®éªŒä¸­ï¼ŒGasAgentæˆåŠŸä¼˜åŒ–äº†å…¶ä¸­çš„82ä¸ªï¼Œå®ç°äº†å¹³å‡9.97%çš„éƒ¨ç½²GasèŠ‚çœã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶åœ¨å¤„ç†500ä¸ªç”±å¤§è¯­è¨€æ¨¡å‹(LLMs)ç”Ÿæˆçš„åˆçº¦æ—¶è¡¨ç°å‡ºè‰²ï¼Œä¼˜åŒ–äº†79.8%çš„æ¡ˆä¾‹ï¼ŒGasèŠ‚çœç‡æœ€é«˜å¯è¾¾13.93%ã€‚ç ”ç©¶ç»“æœè¯æ˜äº†GasAgentä½œä¸ºç«¯åˆ°ç«¯(End-to-end)ä¼˜åŒ–å±‚çš„æœ‰æ•ˆæ€§ï¼Œä¸ºæå‡LLMè¾…åŠ©æ™ºèƒ½åˆçº¦å¼€å‘çš„æ•ˆç‡ä¸ç»æµæ€§æä¾›äº†é‡è¦æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.15761v1",
      "published_date": "2025-07-21 16:17:25 UTC",
      "updated_date": "2025-07-21 16:17:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:56:16.534005+00:00"
    },
    {
      "arxiv_id": "2507.15758v2",
      "title": "LAPO: Internalizing Reasoning Efficiency via Length-Adaptive Policy Optimization",
      "title_zh": "LAPOï¼šåŸºäºé•¿åº¦è‡ªé€‚åº”ç­–ç•¥ä¼˜åŒ–çš„æ¨ç†æ•ˆç‡å†…ç”ŸåŒ–",
      "authors": [
        "Xingyu Wu",
        "Yuchen Yan",
        "Shangke Lyu",
        "Linjuan Wu",
        "Yiwen Qiu",
        "Yongliang Shen",
        "Weiming Lu",
        "Jian Shao",
        "Jun Xiao",
        "Yueting Zhuang"
      ],
      "abstract": "Large reasoning models have achieved remarkable performance through extended chain-of-thought sequences, yet this computational freedom leads to excessive token generation even for simple problems. We present Length-Adaptive Policy Optimization (LAPO), a novel framework that transforms reasoning length control from an external constraint into an intrinsic model capability. Unlike existing approaches that impose rigid limits or rely on post-hoc interventions, LAPO enables models to internalize an understanding of appropriate reasoning depth through a two-stage reinforcement learning process. In the first stage, models learn natural reasoning patterns by discovering the statistical distribution of successful solution lengths. The second stage leverages these patterns as meta-cognitive guidance, embedding them directly within the model's reasoning context to ensure inference-time flexibility. Experiments on mathematical reasoning benchmarks demonstrate that LAPO reduces token usage by up to 40.9% while improving accuracy by 2.3%. Our analysis reveals that models trained with LAPO develop emergent abilities to allocate computational resources based on problem complexity, achieving efficient reasoning without sacrificing quality.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†LAPOï¼ˆLength-Adaptive Policy Optimizationï¼‰ï¼Œè¿™æ˜¯ä¸€ç§æ—¨åœ¨æå‡å¤§å‹æ¨ç†æ¨¡å‹æ•ˆç‡çš„æ–°å‹æ¡†æ¶ï¼Œæœ‰æ•ˆè§£å†³äº†é•¿é“¾å¼æ€ç»´ï¼ˆChain-of-Thoughtï¼‰åœ¨å¤„ç†ç®€å•é—®é¢˜æ—¶äº§ç”Ÿå†—ä½™Tokençš„é—®é¢˜ã€‚ä¸åŒäºæ–½åŠ å¤–éƒ¨ç¡¬æ€§çº¦æŸçš„ç°æœ‰æ–¹æ³•ï¼ŒLAPOé€šè¿‡ä¸¤é˜¶æ®µå¼ºåŒ–å­¦ä¹ ï¼ˆReinforcement Learningï¼‰è¿‡ç¨‹ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿå°†æ¨ç†é•¿åº¦çš„æ§åˆ¶è½¬åŒ–ä¸ºä¸€ç§å†…åœ¨èƒ½åŠ›ã€‚åœ¨ç¬¬ä¸€é˜¶æ®µä¸­ï¼Œæ¨¡å‹é€šè¿‡åˆ†ææˆåŠŸè§£é¢˜é•¿åº¦çš„ç»Ÿè®¡åˆ†å¸ƒæ¥å­¦ä¹ è‡ªç„¶çš„æ¨ç†æ¨¡å¼ï¼›ç¬¬äºŒé˜¶æ®µåˆ™å°†è¿™äº›æ¨¡å¼ä½œä¸ºå…ƒè®¤çŸ¥å¼•å¯¼åµŒå…¥åˆ°æ¨ç†ä¸Šä¸‹æ–‡ä¸­ï¼Œä»è€Œå®ç°æ¨ç†æ—¶çš„åŠ¨æ€çµæ´»æ€§ã€‚å®éªŒç»“æœè¯æ˜ï¼ŒLAPOåœ¨æ•°å­¦æ¨ç†åŸºå‡†æµ‹è¯•ä¸­ä¸ä»…å‡å°‘äº†é«˜è¾¾40.9%çš„Tokenæ¶ˆè€—ï¼Œè¿˜å°†å‡†ç¡®ç‡æå‡äº†2.3%ã€‚ç ”ç©¶åˆ†æè¿›ä¸€æ­¥æ­ç¤ºï¼Œç»LAPOä¼˜åŒ–çš„æ¨¡å‹å±•ç°å‡ºäº†æ ¹æ®é—®é¢˜å¤æ‚ç¨‹åº¦è‡ªä¸»åˆ†é…è®¡ç®—èµ„æºçš„çªç°èƒ½åŠ›ï¼Œåœ¨ä¸ç‰ºç‰²è´¨é‡çš„æƒ…å†µä¸‹å®ç°äº†é«˜æ•ˆæ¨ç†ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "GitHub:https://github.com/zju-real/lapoProject:https://zju-real.github.io/lapo",
      "pdf_url": "https://arxiv.org/pdf/2507.15758v2",
      "published_date": "2025-07-21 16:14:41 UTC",
      "updated_date": "2025-08-14 08:13:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:57:26.586476+00:00"
    },
    {
      "arxiv_id": "2507.15753v1",
      "title": "DiffuMeta: Algebraic Language Models for Inverse Design of Metamaterials via Diffusion Transformers",
      "title_zh": "DiffuMetaï¼šåŸºäºæ‰©æ•£ Transformer çš„è¶…ææ–™é€†å‘è®¾è®¡ä»£æ•°è¯­è¨€æ¨¡å‹",
      "authors": [
        "Li Zheng",
        "Siddhant Kumar",
        "Dennis M. Kochmann"
      ],
      "abstract": "Generative machine learning models have revolutionized material discovery by capturing complex structure-property relationships, yet extending these approaches to the inverse design of three-dimensional metamaterials remains limited by computational complexity and underexplored design spaces due to the lack of expressive representations. Here, we present DiffuMeta, a generative framework integrating diffusion transformers with a novel algebraic language representation, encoding 3D geometries as mathematical sentences. This compact, unified parameterization spans diverse topologies while enabling direct application of transformers to structural design. DiffuMeta leverages diffusion models to generate novel shell structures with precisely targeted stress-strain responses under large deformations, accounting for buckling and contact while addressing the inherent one-to-many mapping by producing diverse solutions. Uniquely, our approach enables simultaneous control over multiple mechanical objectives, including linear and nonlinear responses beyond training domains. Experimental validation of fabricated structures further confirms the efficacy of our approach for accelerated design of metamaterials and structures with tailored properties.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† DiffuMetaï¼Œè¿™æ˜¯ä¸€ä¸ªå°† Diffusion Transformers ä¸æ–°å‹ä»£æ•°è¯­è¨€è¡¨ç¤º (Algebraic Language Representation) ç›¸ç»“åˆçš„ç”Ÿæˆå¼æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ä¸‰ç»´è¶…ææ–™ (Metamaterials) é€†å‘è®¾è®¡ä¸­è®¡ç®—å¤æ‚æ€§å’Œè¡¨è¾¾èƒ½åŠ›ä¸è¶³çš„é—®é¢˜ã€‚è¯¥æ¡†æ¶å°† 3D å‡ ä½•ç»“æ„ç¼–ç ä¸ºæ•°å­¦è¯­å¥ï¼Œé€šè¿‡ç´§å‡‘ç»Ÿä¸€çš„å‚æ•°åŒ–æ–¹æ³•å®ç°å¤šç§æ‹“æ‰‘ç»“æ„çš„è¡¨å¾ï¼Œå¹¶å…è®¸å°† Transformers ç›´æ¥åº”ç”¨äºç»“æ„è®¾è®¡ã€‚DiffuMeta åˆ©ç”¨æ‰©æ•£æ¨¡å‹ (Diffusion Models) ç”Ÿæˆå…·æœ‰ç²¾ç¡®ç›®æ ‡åº”åŠ›-åº”å˜å“åº” (Stress-Strain Responses) çš„æ–°å‹å£³ä½“ç»“æ„ï¼Œæœ‰æ•ˆå¤„ç†äº†å¤§å˜å½¢è¿‡ç¨‹ä¸­çš„å±ˆæ›² (Buckling) ä¸æ¥è§¦ (Contact) ç°è±¡ã€‚é€šè¿‡äº§ç”Ÿå¤šæ ·åŒ–è§£ï¼Œè¯¥æ–¹æ³•è§£å†³äº†é€†å‘è®¾è®¡ä¸­å›ºæœ‰çš„â€œä¸€å¯¹å¤šâ€æ˜ å°„éš¾é¢˜ï¼Œå¹¶å®ç°äº†å¯¹åŒ…æ‹¬è®­ç»ƒé¢†åŸŸ (Training Domains) ä¹‹å¤–çš„çº¿æ€§ä¸éçº¿æ€§å¤šé‡åŠ›å­¦ç›®æ ‡çš„åŒæ­¥æ§åˆ¶ã€‚æœ€åï¼Œé€šè¿‡åˆ¶é€ ç»“æ„çš„å®éªŒéªŒè¯ï¼Œè¯æ˜äº†è¯¥æ–¹æ³•åœ¨åŠ é€Ÿå®šåˆ¶åŒ–æ€§èƒ½è¶…ææ–™è®¾è®¡æ–¹é¢çš„æ˜¾è‘—æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.CE",
        "cs.AI"
      ],
      "primary_category": "cs.CE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.15753v1",
      "published_date": "2025-07-21 16:09:26 UTC",
      "updated_date": "2025-07-21 16:09:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:56:23.034810+00:00"
    },
    {
      "arxiv_id": "2507.15752v1",
      "title": "DialogueForge: LLM Simulation of Human-Chatbot Dialogue",
      "title_zh": "DialogueForgeï¼šåŸºäºå¤§è¯­è¨€æ¨¡å‹çš„äººæœºå¯¹è¯æ¨¡æ‹Ÿ",
      "authors": [
        "Ruizhe Zhu",
        "Hao Zhu",
        "Yaxuan Li",
        "Syang Zhou",
        "Shijing Cai",
        "Malgorzata Lazuka",
        "Elliott Ash"
      ],
      "abstract": "Collecting human-chatbot dialogues typically demands substantial manual effort and is time-consuming, which limits and poses challenges for research on conversational AI. In this work, we propose DialogueForge - a framework for generating AI-simulated conversations in human-chatbot style. To initialize each generated conversation, DialogueForge uses seed prompts extracted from real human-chatbot interactions. We test a variety of LLMs to simulate the human chatbot user, ranging from state-of-the-art proprietary models to small-scale open-source LLMs, and generate multi-turn dialogues tailored to specific tasks. In addition, we explore fine-tuning techniques to enhance the ability of smaller models to produce indistinguishable human-like dialogues. We evaluate the quality of the simulated conversations and compare different models using the UniEval and GTEval evaluation protocols. Our experiments show that large proprietary models (e.g., GPT-4o) generally outperform others in generating more realistic dialogues, while smaller open-source models (e.g., Llama, Mistral) offer promising performance with greater customization. We demonstrate that the performance of smaller models can be significantly improved by employing supervised fine-tuning techniques. Nevertheless, maintaining coherent and natural long-form human-like dialogues remains a common challenge across all models.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† DialogueForgeï¼Œä¸€ä¸ªæ—¨åœ¨æ¨¡æ‹Ÿäººæœºé£æ ¼å¯¹è¯çš„ç”Ÿæˆæ¡†æ¶ï¼Œä»¥è§£å†³æ‰‹åŠ¨æ”¶é›†çœŸå®å¯¹è¯æ•°æ®æ—¶æˆæœ¬é«˜æ˜‚çš„é—®é¢˜ã€‚è¯¥æ¡†æ¶åˆ©ç”¨ä»çœŸå®äººæœºäº’åŠ¨ä¸­æå–çš„ seed prompts åˆå§‹åŒ–ç”Ÿæˆè¿‡ç¨‹ï¼Œå¹¶è¯„ä¼°äº†å¤šç§ LLMs åœ¨æ¨¡æ‹Ÿäººç±»ç”¨æˆ·æ–¹é¢çš„è¡¨ç°ã€‚ç ”ç©¶é€šè¿‡ç›‘ç£å¾®è°ƒ (Supervised Fine-Tuning) æŠ€æœ¯ï¼Œæ˜¾è‘—å¢å¼ºäº† Llama å’Œ Mistral ç­‰å¼€æºå°æ¨¡å‹ç”Ÿæˆç±»äººå¯¹è¯çš„èƒ½åŠ›ã€‚ä½¿ç”¨ UniEval å’Œ GTEval åè®®çš„è¯„ä¼°ç»“æœæ˜¾ç¤ºï¼Œè™½ç„¶ GPT-4o ç­‰é—­æºæ¨¡å‹åœ¨ç”Ÿæˆé€¼çœŸåº¦ä¸Šé¢†å…ˆï¼Œä½†ä¼˜åŒ–åçš„å°æ¨¡å‹åœ¨å®šåˆ¶åŒ–æ–¹é¢å±•ç°å‡ºæå…·ç«äº‰åŠ›çš„æ½œåŠ›ã€‚å®éªŒè¯æ˜äº†è¯¥æ¡†æ¶åœ¨è‡ªåŠ¨åŒ–ç”Ÿæˆé«˜è´¨é‡ç ”ç©¶æ•°æ®æ–¹é¢çš„æœ‰æ•ˆæ€§ï¼ŒåŒæ—¶ä¹ŸæŒ‡å‡ºç»´æŒé•¿ç¯‡å¯¹è¯çš„è¿è´¯æ€§ä¸è‡ªç„¶åº¦ä»æ˜¯å½“å‰æ‰€æœ‰æ¨¡å‹é¢ä¸´çš„å…±åŒæŒ‘æˆ˜ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "For our code and data, see https://github.com/nerchio/Human_Chatbot-Generation",
      "pdf_url": "https://arxiv.org/pdf/2507.15752v1",
      "published_date": "2025-07-21 16:08:19 UTC",
      "updated_date": "2025-07-21 16:08:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:56:25.552143+00:00"
    },
    {
      "arxiv_id": "2507.15743v1",
      "title": "Towards physician-centered oversight of conversational diagnostic AI",
      "title_zh": "è¿ˆå‘ä»¥åŒ»ç”Ÿä¸ºä¸­å¿ƒçš„å¯¹è¯å¼è¯Šæ–­ AI ç›‘ç®¡",
      "authors": [
        "Elahe Vedadi",
        "David Barrett",
        "Natalie Harris",
        "Ellery Wulczyn",
        "Shashir Reddy",
        "Roma Ruparel",
        "Mike Schaekermann",
        "Tim Strother",
        "Ryutaro Tanno",
        "Yash Sharma",
        "Jihyeon Lee",
        "CÃ­an Hughes",
        "Dylan Slack",
        "Anil Palepu",
        "Jan Freyberg",
        "Khaled Saab",
        "Valentin LiÃ©vin",
        "Wei-Hung Weng",
        "Tao Tu",
        "Yun Liu",
        "Nenad Tomasev",
        "Kavita Kulkarni",
        "S. Sara Mahdavi",
        "Kelvin Guu",
        "JoÃ«lle Barral",
        "Dale R. Webster",
        "James Manyika",
        "Avinatan Hassidim",
        "Katherine Chou",
        "Yossi Matias",
        "Pushmeet Kohli",
        "Adam Rodman",
        "Vivek Natarajan",
        "Alan Karthikesalingam",
        "David Stutz"
      ],
      "abstract": "Recent work has demonstrated the promise of conversational AI systems for diagnostic dialogue. However, real-world assurance of patient safety means that providing individual diagnoses and treatment plans is considered a regulated activity by licensed professionals. Furthermore, physicians commonly oversee other team members in such activities, including nurse practitioners (NPs) or physician assistants/associates (PAs). Inspired by this, we propose a framework for effective, asynchronous oversight of the Articulate Medical Intelligence Explorer (AMIE) AI system. We propose guardrailed-AMIE (g-AMIE), a multi-agent system that performs history taking within guardrails, abstaining from individualized medical advice. Afterwards, g-AMIE conveys assessments to an overseeing primary care physician (PCP) in a clinician cockpit interface. The PCP provides oversight and retains accountability of the clinical decision. This effectively decouples oversight from intake and can thus happen asynchronously. In a randomized, blinded virtual Objective Structured Clinical Examination (OSCE) of text consultations with asynchronous oversight, we compared g-AMIE to NPs/PAs or a group of PCPs under the same guardrails. Across 60 scenarios, g-AMIE outperformed both groups in performing high-quality intake, summarizing cases, and proposing diagnoses and management plans for the overseeing PCP to review. This resulted in higher quality composite decisions. PCP oversight of g-AMIE was also more time-efficient than standalone PCP consultations in prior work. While our study does not replicate existing clinical practices and likely underestimates clinicians' capabilities, our results demonstrate the promise of asynchronous oversight as a feasible paradigm for diagnostic AI systems to operate under expert human oversight for enhancing real-world care.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¯¹è¯å¼AIç³»ç»Ÿåœ¨ä¸´åºŠè¯Šæ–­ä¸­çš„åº”ç”¨ï¼Œæå‡ºäº†é¢å‘åŒ»ç”Ÿçš„å¼‚æ­¥ç›‘ç®¡(asynchronous oversight)æ¡†æ¶ï¼Œä»¥è§£å†³æ‚£è€…å®‰å…¨å’ŒåŒ»ç–—ç›‘ç®¡çš„åˆè§„æ€§é—®é¢˜ã€‚æ ¸å¿ƒç³»ç»Ÿg-AMIEé‡‡ç”¨å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ(multi-agent system)è¿›è¡Œå¸¦é˜²æŠ¤æ (guardrails)çš„ç—…å²é‡‡é›†(history taking)ï¼Œå¹¶åœ¨ä¸´åºŠé©¾é©¶èˆ±ç•Œé¢(clinician cockpit)å°†æ±‡æ€»ä¿¡æ¯æäº¤ç»™ä¸»æ²»åŒ»ç”Ÿ(PCP)è¿›è¡Œå®¡æ ¸ä¸å†³ç­–ã€‚åœ¨åŒ…å«60ä¸ªåœºæ™¯çš„è™šæ‹Ÿå®¢è§‚ç»“æ„åŒ–ä¸´åºŠè€ƒè¯•(OSCE)ä¸­ï¼Œg-AMIEåœ¨ç—…å²é‡‡é›†è´¨é‡ã€ç—…ä¾‹æ‘˜è¦ä»¥åŠå»ºè®®çš„è¯Šæ–­å’Œç®¡ç†è®¡åˆ’æ–¹é¢å‡ä¼˜äºæŠ¤å¸ˆ(NPs/PAs)å’Œå…¨ç§‘åŒ»ç”Ÿå°ç»„ã€‚ç»“æœæ˜¾ç¤ºï¼Œè¯¥æ¡†æ¶ä¸ä»…æ˜¾è‘—æé«˜äº†ç»¼åˆå†³ç­–è´¨é‡ï¼Œä¸”åŒ»ç”Ÿçš„ç›‘ç®¡æ•ˆç‡æ¯”ä¼ ç»Ÿçš„ç‹¬ç«‹å’¨è¯¢æ›´é«˜ã€‚è¿™ä¸€èŒƒå¼è¯æ˜äº†å¼‚æ­¥ç›‘ç®¡æ˜¯è¯Šæ–­æ€§AIç³»ç»Ÿåœ¨ä¸“å®¶ç›‘ç£ä¸‹å¢å¼ºçœŸå®ä¸–ç•ŒåŒ»ç–—æŠ¤ç†çš„ä¸€ç§å¯è¡Œä¸”é«˜æ•ˆçš„è·¯å¾„ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.15743v1",
      "published_date": "2025-07-21 15:54:36 UTC",
      "updated_date": "2025-07-21 15:54:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:56:25.725724+00:00"
    },
    {
      "arxiv_id": "2507.15718v1",
      "title": "Explainable Anomaly Detection for Electric Vehicles Charging Stations",
      "title_zh": "ç”µåŠ¨æ±½è½¦å……ç”µç«™çš„å¯è§£é‡Šæ€§å¼‚å¸¸æ£€æµ‹",
      "authors": [
        "Matteo Cederle",
        "Andrea Mazzucco",
        "Andrea Demartini",
        "Eugenio Mazza",
        "Eugenia Suriani",
        "Federico Vitti",
        "Gian Antonio Susto"
      ],
      "abstract": "Electric vehicles (EV) charging stations are one of the critical infrastructures needed to support the transition to renewable-energy-based mobility, but ensuring their reliability and efficiency requires effective anomaly detection to identify irregularities in charging behavior. However, in such a productive scenario, it is also crucial to determine the underlying cause behind the detected anomalies. To achieve this goal, this study investigates unsupervised anomaly detection techniques for EV charging infrastructure, integrating eXplainable Artificial Intelligence techniques to enhance interpretability and uncover root causes of anomalies.\n  Using real-world sensors and charging session data, this work applies Isolation Forest to detect anomalies and employs the Depth-based Isolation Forest Feature Importance (DIFFI) method to identify the most important features contributing to such anomalies. The efficacy of the proposed approach is evaluated in a real industrial case.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç”µåŠ¨æ±½è½¦(Electric vehicles, EV)å……ç”µç«™çš„å¯é æ€§ä¸æ•ˆç‡é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§èåˆå¯è§£é‡Šäººå·¥æ™ºèƒ½(eXplainable Artificial Intelligence, XAI)æŠ€æœ¯çš„æ— ç›‘ç£å¼‚å¸¸æ£€æµ‹æ–¹æ¡ˆã€‚ç”±äºåœ¨å®é™…ç”Ÿäº§åœºæ™¯ä¸­ç¡®å®šå¼‚å¸¸èƒŒåçš„æ ¹æœ¬åŸå› è‡³å…³é‡è¦ï¼Œè¯¥ç ”ç©¶é‡‡ç”¨ Isolation Forest ç®—æ³•å¯¹çœŸå®çš„ä¼ æ„Ÿå™¨å’Œå……ç”µä¼šè¯æ•°æ®è¿›è¡Œå»ºæ¨¡ï¼Œä»¥è¯†åˆ«å……ç”µè¡Œä¸ºä¸­çš„ä¸è§„åˆ™æ€§ã€‚ä¸ºäº†æå‡æ£€æµ‹ç»“æœçš„å¯è§£é‡Šæ€§ï¼Œç ”ç©¶å¼•å…¥äº†åŸºäºæ·±åº¦çš„å­¤ç«‹æ£®æ—ç‰¹å¾é‡è¦æ€§(Depth-based Isolation Forest Feature Importance, DIFFI)æ–¹æ³•ï¼Œæ—¨åœ¨ç²¾å‡†è¯†åˆ«å¯¼è‡´å¼‚å¸¸çš„å…³é”®ç‰¹å¾å¹¶æ­ç¤ºå…¶è¯±å› ã€‚è¯¥æ–¹æ³•åœ¨çœŸå®çš„å·¥ä¸šæ¡ˆä¾‹ä¸­å¾—åˆ°äº†éªŒè¯ï¼Œè¯æ˜äº†å…¶åœ¨è¯†åˆ«å¼‚å¸¸åŠåˆ†ææ ¹æœ¬åŸå› æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚è¿™é¡¹å·¥ä½œä¸ä»…å¢å¼ºäº†æ¨¡å‹åœ¨å…³é”®äº¤é€šåŸºç¡€è®¾æ–½ä¸­çš„é€æ˜åº¦ï¼Œä¹Ÿä¸ºä¿éšœå……ç”µç½‘ç»œçš„ç¨³å®šè¿è¡Œæä¾›äº†å†³ç­–æ”¯æŒã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "4 pages, 3 figures. Paper accepted to J3C 2025 (Joint Conference on Computers, Cognition and Communication)",
      "pdf_url": "https://arxiv.org/pdf/2507.15718v1",
      "published_date": "2025-07-21 15:27:48 UTC",
      "updated_date": "2025-07-21 15:27:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:56:28.541579+00:00"
    },
    {
      "arxiv_id": "2507.15717v1",
      "title": "BEnchmarking LLMs for Ophthalmology (BELO) for Ophthalmological Knowledge and Reasoning",
      "title_zh": "BELOï¼šé’ˆå¯¹çœ¼ç§‘çŸ¥è¯†ä¸æ¨ç†çš„å¤§è¯­è¨€æ¨¡å‹æµ‹è¯„åŸºå‡†",
      "authors": [
        "Sahana Srinivasan",
        "Xuguang Ai",
        "Thaddaeus Wai Soon Lo",
        "Aidan Gilson",
        "Minjie Zou",
        "Ke Zou",
        "Hyunjae Kim",
        "Mingjia Yang",
        "Krithi Pushpanathan",
        "Samantha Yew",
        "Wan Ting Loke",
        "Jocelyn Goh",
        "Yibing Chen",
        "Yiming Kong",
        "Emily Yuelei Fu",
        "Michelle Ongyong Hui",
        "Kristen Nwanyanwu",
        "Amisha Dave",
        "Kelvin Zhenghao Li",
        "Chen-Hsin Sun",
        "Mark Chia",
        "Gabriel Dawei Yang",
        "Wendy Meihua Wong",
        "David Ziyou Chen",
        "Dianbo Liu",
        "Maxwell Singer",
        "Fares Antaki",
        "Lucian V Del Priore",
        "Jost Jonas",
        "Ron Adelman",
        "Qingyu Chen",
        "Yih-Chung Tham"
      ],
      "abstract": "Current benchmarks evaluating large language models (LLMs) in ophthalmology are limited in scope and disproportionately prioritise accuracy. We introduce BELO (BEnchmarking LLMs for Ophthalmology), a standardized and comprehensive evaluation benchmark developed through multiple rounds of expert checking by 13 ophthalmologists. BELO assesses ophthalmology-related clinical accuracy and reasoning quality. Using keyword matching and a fine-tuned PubMedBERT model, we curated ophthalmology-specific multiple-choice-questions (MCQs) from diverse medical datasets (BCSC, MedMCQA, MedQA, BioASQ, and PubMedQA). The dataset underwent multiple rounds of expert checking. Duplicate and substandard questions were systematically removed. Ten ophthalmologists refined the explanations of each MCQ's correct answer. This was further adjudicated by three senior ophthalmologists. To illustrate BELO's utility, we evaluated six LLMs (OpenAI o1, o3-mini, GPT-4o, DeepSeek-R1, Llama-3-8B, and Gemini 1.5 Pro) using accuracy, macro-F1, and five text-generation metrics (ROUGE-L, BERTScore, BARTScore, METEOR, and AlignScore). In a further evaluation involving human experts, two ophthalmologists qualitatively reviewed 50 randomly selected outputs for accuracy, comprehensiveness, and completeness. BELO consists of 900 high-quality, expert-reviewed questions aggregated from five sources: BCSC (260), BioASQ (10), MedMCQA (572), MedQA (40), and PubMedQA (18). A public leaderboard has been established to promote transparent evaluation and reporting. Importantly, the BELO dataset will remain a hold-out, evaluation-only benchmark to ensure fair and reproducible comparisons of future models.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº† BELO (BEnchmarking LLMs for Ophthalmology)ï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨è¯„ä¼°å¤§è¯­è¨€æ¨¡å‹ (LLMs) åœ¨çœ¼ç§‘å­¦é¢†åŸŸä¸´åºŠå‡†ç¡®æ€§å’Œæ¨ç†èƒ½åŠ›çš„æ ‡å‡†åŒ–ç»¼åˆåŸºå‡†ã€‚è¯¥åŸºå‡†ç”± 13 åçœ¼ç§‘ä¸“å®¶é€šè¿‡å¤šè½®å®¡æŸ¥å¼€å‘ï¼Œä» BCSCã€MedMCQAã€MedQAã€BioASQ å’Œ PubMedQA ç­‰å¤šä¸ªåŒ»å­¦æ•°æ®é›†ä¸­ç­›é€‰å¹¶ç²¾ç‚¼äº† 900 é“é«˜è´¨é‡çš„å¤šé€‰é¢˜ (MCQs)ã€‚ä¸ºç¡®ä¿è¯„ä¼°çš„æ·±åº¦ï¼Œç ”ç©¶å›¢é˜Ÿç³»ç»Ÿåœ°ç§»é™¤äº†ä¸åˆæ ¼é—®é¢˜ï¼Œå¹¶ç”±èµ„æ·±çœ¼ç§‘åŒ»ç”Ÿå¯¹æ¯ä¸ªé—®é¢˜çš„æ­£ç¡®ç­”æ¡ˆè§£é‡Šè¿›è¡Œäº†ç²¾ç‚¼å’Œè£å®šã€‚ç ”ç©¶åˆ©ç”¨ BELO å¯¹ OpenAI o1ã€o3-miniã€GPT-4oã€DeepSeek-R1ã€Llama-3-8B å’Œ Gemini 1.5 Pro ç­‰å…­ç§ä¸»æµæ¨¡å‹è¿›è¡Œäº†å…¨é¢è¯„ä¼°ã€‚è¯„ä¼°è¿‡ç¨‹ç»“åˆäº†å‡†ç¡®ç‡ã€macro-F1 ä»¥åŠ ROUGE-Lã€BERTScoreã€AlignScore ç­‰äº”é¡¹æ–‡æœ¬ç”ŸæˆæŒ‡æ ‡ï¼Œå¹¶è¾…ä»¥ä¸“å®¶å¯¹è¾“å‡ºå…¨é¢æ€§çš„å®šæ€§å®¡æŸ¥ã€‚ä½œä¸ºå…¬å¼€æ’è¡Œæ¦œçš„æ”¯æ’‘åŸºå‡†ï¼ŒBELO é‡‡ç”¨äº†ä¸å…¬å¼€æ•°æ®é›† (hold-out) æ¨¡å¼ï¼Œä¸ºæœªæ¥æ¨¡å‹åœ¨çœ¼ç§‘ä¸“ä¸šé¢†åŸŸçš„æ€§èƒ½è¡¡é‡æä¾›äº†å…¬å¹³ä¸”å¯é‡å¤çš„æ¯”è¾ƒæ ‡å‡†ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.15717v1",
      "published_date": "2025-07-21 15:27:32 UTC",
      "updated_date": "2025-07-21 15:27:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:56:42.521162+00:00"
    },
    {
      "arxiv_id": "2507.15707v1",
      "title": "Is Large Language Model Performance on Reasoning Tasks Impacted by Different Ways Questions Are Asked?",
      "title_zh": "ä¸åŒæé—®æ–¹å¼æ˜¯å¦å½±å“å¤§è¯­è¨€æ¨¡å‹åœ¨æ¨ç†ä»»åŠ¡ä¸­çš„è¡¨ç°ï¼Ÿ",
      "authors": [
        "Seok Hwan Song",
        "Mohna Chakraborty",
        "Qi Li",
        "Wallapak Tavanapong"
      ],
      "abstract": "Large Language Models (LLMs) have been evaluated using diverse question types, e.g., multiple-choice, true/false, and short/long answers. This study answers an unexplored question about the impact of different question types on LLM accuracy on reasoning tasks. We investigate the performance of five LLMs on three different types of questions using quantitative and deductive reasoning tasks. The performance metrics include accuracy in the reasoning steps and choosing the final answer. Key Findings: (1) Significant differences exist in LLM performance across different question types. (2) Reasoning accuracy does not necessarily correlate with the final selection accuracy. (3) The number of options and the choice of words, influence LLM performance.",
      "tldr_zh": "è¯¥ç ”ç©¶ç³»ç»Ÿæ¢è®¨äº†ä¸åŒæé—®æ–¹å¼å¯¹ Large Language Models (LLMs) åœ¨æ¨ç†ä»»åŠ¡ä¸­å‡†ç¡®æ€§çš„å½±å“ã€‚ç ”ç©¶è€…é€šè¿‡å®šé‡æ¨ç† (quantitative reasoning) å’Œæ¼”ç»æ¨ç† (deductive reasoning) ä»»åŠ¡ï¼Œè¯„ä¼°äº†äº”ç§ä¸»æµ LLMs åœ¨å¤šé€‰é¢˜ã€åˆ¤æ–­é¢˜åŠç®€ç­”é¢˜ç­‰ä¸åŒ question types ä¸‹çš„è¡¨ç°ã€‚è¯„ä¼°æŒ‡æ ‡ä¸ä»…åŒ…æ‹¬æœ€ç»ˆç­”æ¡ˆçš„å‡†ç¡®ç‡ï¼Œè¿˜æ·±å…¥åˆ†æäº†æ¨ç†æ­¥éª¤ (reasoning steps) çš„æ­£ç¡®æ€§ã€‚ç ”ç©¶å‘ç°ï¼Œä¸åŒæé—®æ–¹å¼ä¼šå¯¼è‡´æ¨¡å‹è¡¨ç°å‡ºç°æ˜¾è‘—å·®å¼‚ï¼Œä¸”æ¨ç†è¿‡ç¨‹çš„å‡†ç¡®æ€§ä¸æœ€ç»ˆé€‰é¡¹çš„å‡†ç¡®æ€§ä¹‹é—´å¹¶ä¸å­˜åœ¨å¿…ç„¶çš„å…³è”ã€‚æ­¤å¤–ï¼Œé€‰é¡¹çš„æ•°é‡ä»¥åŠå…·ä½“çš„æªè¾ (choice of words) ä¹Ÿä¼šå¯¹ LLMs çš„æ€§èƒ½äº§ç”Ÿå¹²æ‰°ã€‚è¯¥ç ”ç©¶ä¸ºå¦‚ä½•æ›´ç§‘å­¦åœ°è®¾è®¡æ¨ç†ä»»åŠ¡è¯„ä¼°æ–¹æ¡ˆæä¾›äº†é‡è¦çš„å®éªŒä¾æ®ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.15707v1",
      "published_date": "2025-07-21 15:15:30 UTC",
      "updated_date": "2025-07-21 15:15:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:57:37.892002+00:00"
    },
    {
      "arxiv_id": "2507.15706v1",
      "title": "Compositional Understanding in Signaling Games",
      "title_zh": "ä¿¡å·åšå¼ˆä¸­çš„ç»„åˆæ€§ç†è§£",
      "authors": [
        "David Peter Wallis Freeborn"
      ],
      "abstract": "Receivers in standard signaling game models struggle with learning compositional information. Even when the signalers send compositional messages, the receivers do not interpret them compositionally. When information from one message component is lost or forgotten, the information from other components is also erased. In this paper I construct signaling game models in which genuine compositional understanding evolves. I present two new models: a minimalist receiver who only learns from the atomic messages of a signal, and a generalist receiver who learns from all of the available information. These models are in many ways simpler than previous alternatives, and allow the receivers to learn from the atomic components of messages.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä¼ ç»Ÿä¿¡å·åšå¼ˆ(Signaling Games)ä¸­æ¥æ”¶è€…éš¾ä»¥æœ‰æ•ˆå¤„ç†ç»„åˆä¿¡æ¯(Compositional Information)çš„å±€é™æ€§ï¼Œæå‡ºäº†ä¸€å¥—èƒ½å¤Ÿæ¼”åŒ–å‡ºçœŸæ­£ç»„åˆå¼ç†è§£(Compositional Understanding)çš„æ–°å‹æ¨¡å‹ã€‚åœ¨ä¼ ç»Ÿæ¨¡å‹ä¸­ï¼Œå³ä½¿ä¿¡å·å…·æœ‰ç»„åˆç»“æ„ï¼Œæ¥æ”¶è€…ä¹Ÿå¾€å¾€æ— æ³•å¯¹å…¶è¿›è¡Œæ¨¡å—åŒ–è§£è¯»ï¼Œå¯¼è‡´å±€éƒ¨ä¿¡æ¯çš„ä¸¢å¤±ä¼šç ´åæ•´ä½“ç†è§£ã€‚ä¸ºæ­¤ï¼Œè®ºæ–‡è®¾è®¡äº†æç®€ä¸»ä¹‰æ¥æ”¶è€…(Minimalist Receiver)å’Œé€šç”¨å‹æ¥æ”¶è€…(Generalist Receiver)ä¸¤ç§æ¶æ„ï¼Œåˆ†åˆ«ä¾§é‡äºä»åŸå­æ¶ˆæ¯(Atomic Messages)æˆ–å…¨å±€ä¿¡æ¯ä¸­è¿›è¡Œå­¦ä¹ ã€‚è¿™äº›æ¨¡å‹åœ¨ä¿æŒç»“æ„ç®€æ´çš„åŒæ—¶ï¼Œå…è®¸æ¥æ”¶è€…ç‹¬ç«‹åœ°ä»æ¶ˆæ¯çš„å„ä¸ªåŸå­ç»„ä»¶ä¸­è·å–çŸ¥è¯†ã€‚è¯¥ç ”ç©¶ä¸ºç†è§£ç»„åˆæ€§åœ¨é€šä¿¡ç³»ç»Ÿä¸­çš„æ¼”åŒ–æä¾›äº†æ›´ç®€å•ä¸”é«˜æ•ˆçš„ç†è®ºæ¡†æ¶ï¼Œæ˜¾è‘—æå‡äº†æ¥æ”¶è€…å¯¹å¤æ‚ä¿¡å·çš„è§£ææ•ˆç‡ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.15706v1",
      "published_date": "2025-07-21 15:14:40 UTC",
      "updated_date": "2025-07-21 15:14:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:57:41.194265+00:00"
    },
    {
      "arxiv_id": "2507.15698v1",
      "title": "CoLD: Counterfactually-Guided Length Debiasing for Process Reward Models",
      "title_zh": "CoLDï¼šåŸºäºåäº‹å®å¼•å¯¼çš„è¿‡ç¨‹å¥–åŠ±æ¨¡å‹é•¿åº¦å»å",
      "authors": [
        "Congmin Zheng",
        "Jiachen Zhu",
        "Jianghao Lin",
        "Xinyi Dai",
        "Yong Yu",
        "Weinan Zhang",
        "Mengyue Yang"
      ],
      "abstract": "Process Reward Models (PRMs) play a central role in evaluating and guiding multi-step reasoning in large language models (LLMs), especially for mathematical problem solving. However, we identify a pervasive length bias in existing PRMs: they tend to assign higher scores to longer reasoning steps, even when the semantic content and logical validity are unchanged. This bias undermines the reliability of reward predictions and leads to overly verbose outputs during inference. To address this issue, we propose CoLD(Counterfactually-Guided Length Debiasing), a unified framework that mitigates length bias through three components: an explicit length-penalty adjustment, a learned bias estimator trained to capture spurious length-related signals, and a joint training strategy that enforces length-invariance in reward predictions. Our approach is grounded in counterfactual reasoning and informed by causal graph analysis. Extensive experiments on MATH500 and GSM-Plus show that CoLD consistently reduces reward-length correlation, improves accuracy in step selection, and encourages more concise, logically valid reasoning. These results demonstrate the effectiveness and practicality of CoLD in improving the fidelity and robustness of PRMs.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹æ¨ç†ä¸­çš„è¿‡ç¨‹å¥–åŠ±æ¨¡å‹ï¼ˆProcess Reward Models, PRMsï¼‰æ™®éå­˜åœ¨çš„é•¿åº¦åå·®ï¼ˆlength biasï¼‰é—®é¢˜æå‡ºäº† CoLDï¼ˆCounterfactually-Guided Length Debiasingï¼‰æ¡†æ¶ã€‚ç ”ç©¶å‘ç° PRMs å€¾å‘äºä¸ºæ›´é•¿çš„æ¨ç†æ­¥éª¤åˆ†é…æ›´é«˜åˆ†æ•°ï¼Œå³ä½¿é€»è¾‘æœ‰æ•ˆæ€§æœªå˜ï¼Œè¿™ä¸¥é‡æŸå®³äº†å¥–åŠ±é¢„æµ‹çš„å¯é æ€§å¹¶å¯¼è‡´æ¨ç†è¾“å‡ºå†—ä½™ã€‚CoLD æ¡†æ¶åŸºäºåå‘äº‹å®æ¨ç†ï¼ˆcounterfactual reasoningï¼‰å’Œå› æœå›¾åˆ†æï¼Œé€šè¿‡æ˜¾å¼é•¿åº¦æƒ©ç½šã€å­¦ä¹ åç½®ä¼°è®¡å™¨ä»¥åŠè”åˆè®­ç»ƒç­–ç•¥æ¥ç¡®ä¿å¥–åŠ±é¢„æµ‹çš„é•¿åº¦ä¸å˜æ€§ã€‚åœ¨ MATH500 å’Œ GSM-Plus ä¸Šçš„å®éªŒç»“æœè¯æ˜ï¼ŒCoLD èƒ½æœ‰æ•ˆé™ä½å¥–åŠ±ä¸é•¿åº¦çš„ç›¸å…³æ€§ï¼Œå¹¶æ˜¾è‘—æé«˜æ­¥éª¤é€‰æ‹©çš„å‡†ç¡®ç‡ã€‚è¯¥æ–¹æ³•ä¸ä»…å¢å¼ºäº† PRMs çš„ä¿çœŸåº¦ä¸é²æ£’æ€§ï¼Œè¿˜æˆåŠŸå¼•å¯¼æ¨¡å‹ç”Ÿæˆæ›´ç®€æ´ã€é€»è¾‘æ›´ä¸¥å¯†çš„æ¨ç†å†…å®¹ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.15698v1",
      "published_date": "2025-07-21 15:07:59 UTC",
      "updated_date": "2025-07-21 15:07:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:57:54.788600+00:00"
    },
    {
      "arxiv_id": "2507.22922v1",
      "title": "Predicting stock prices with ChatGPT-annotated Reddit sentiment",
      "title_zh": "åˆ©ç”¨ ChatGPT æ ‡æ³¨çš„ Reddit æƒ…ç»ªé¢„æµ‹è‚¡ç¥¨ä»·æ ¼",
      "authors": [
        "Mateusz Kmak",
        "Kamil ChmurzyÅ„ski",
        "Kamil Matejuk",
        "PaweÅ‚ Kotzbach",
        "Jan KocoÅ„"
      ],
      "abstract": "The surge of retail investor activity on social media, exemplified by the 2021 GameStop short squeeze, raised questions about the influence of online sentiment on stock prices. This paper explores whether sentiment derived from social media discussions can meaningfully predict stock market movements. We focus on Reddit's r/wallstreetbets and analyze sentiment related to two companies: GameStop (GME) and AMC Entertainment (AMC). To assess sentiment's role, we employ two existing text-based sentiment analysis methods and introduce a third, a ChatGPT-annotated and fine-tuned RoBERTa-based model designed to better interpret the informal language and emojis prevalent in social media discussions. We use correlation and causality metrics to determine these models' predictive power. Surprisingly, our findings suggest that social media sentiment has only a weak correlation with stock prices. At the same time, simpler metrics, such as the volume of comments and Google search trends, exhibit stronger predictive signals. These results highlight the complexity of retail investor behavior and suggest that traditional sentiment analysis may not fully capture the nuances of market-moving online discussions.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†ç¤¾äº¤åª’ä½“æƒ…ç»ªå¯¹è‚¡ç¥¨ä»·æ ¼é¢„æµ‹çš„å½±å“ï¼Œé‡ç‚¹åˆ†æäº†Redditç¤¾åŒºr/wallstreetbetsä¸­å…³äºGameStop (GME)å’ŒAMCçš„è®¨è®ºã€‚ä¸ºäº†å‡†ç¡®è§£æç¤¾äº¤åª’ä½“ä¸­çš„éæ­£å¼è¯­è¨€å’Œè¡¨æƒ…ç¬¦å·(emojis)ï¼Œç ”ç©¶è€…å¼•å…¥äº†ä¸€ç§åŸºäºChatGPTæ ‡æ³¨å¹¶ç»è¿‡å¾®è°ƒçš„RoBERTaæ¨¡å‹ï¼Œå¹¶åˆ©ç”¨ç›¸å…³æ€§(correlation)å’Œå› æœæ€§(causality)æŒ‡æ ‡è¯„ä¼°å…¶é¢„æµ‹èƒ½åŠ›ã€‚ç ”ç©¶å‘ç°ï¼Œç¤¾äº¤åª’ä½“æƒ…ç»ªä¸è‚¡ä»·ä¹‹é—´ä»…å­˜åœ¨å¾®å¼±çš„ç›¸å…³æ€§ï¼Œå…¶é¢„æµ‹æ•ˆæœæ˜¾è‘—é€Šè‰²äºè¯„è®ºé‡(volume of comments)å’ŒGoogleæœç´¢è¶‹åŠ¿ç­‰ç®€å•æŒ‡æ ‡ã€‚è¿™äº›ç»“æœæ­ç¤ºäº†æ•£æˆ·æŠ•èµ„è€…è¡Œä¸ºçš„å¤æ‚æ€§ï¼Œå¹¶è¡¨æ˜ä¼ ç»Ÿçš„æƒ…ç»ªåˆ†ææ–¹æ³•å¯èƒ½éš¾ä»¥å®Œå…¨æ•æ‰é©±åŠ¨å¸‚åœºæ³¢åŠ¨çš„åœ¨çº¿è®¨è®ºç»†å¾®å·®åˆ«ã€‚è¯¥ç ”ç©¶ä¸ºç†è§£ç¤¾äº¤åª’ä½“æ•°æ®åœ¨é‡‘èé¢„æµ‹ä¸­çš„å±€é™æ€§ä¸å®é™…ä»·å€¼æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.CL",
      "comment": "International Conference on Computational Science 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.22922v1",
      "published_date": "2025-07-21 14:56:38 UTC",
      "updated_date": "2025-07-21 14:56:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:58:00.009750+00:00"
    },
    {
      "arxiv_id": "2507.15686v1",
      "title": "LINR-PCGC: Lossless Implicit Neural Representations for Point Cloud Geometry Compression",
      "title_zh": "LINR-PCGCï¼šé¢å‘ç‚¹äº‘å‡ ä½•å‹ç¼©çš„æ— æŸéšå¼ç¥ç»è¡¨ç¤º",
      "authors": [
        "Wenjie Huang",
        "Qi Yang",
        "Shuting Xia",
        "He Huang",
        "Zhu Li",
        "Yiling Xu"
      ],
      "abstract": "Existing AI-based point cloud compression methods struggle with dependence on specific training data distributions, which limits their real-world deployment. Implicit Neural Representation (INR) methods solve the above problem by encoding overfitted network parameters to the bitstream, resulting in more distribution-agnostic results. However, due to the limitation of encoding time and decoder size, current INR based methods only consider lossy geometry compression. In this paper, we propose the first INR based lossless point cloud geometry compression method called Lossless Implicit Neural Representations for Point Cloud Geometry Compression (LINR-PCGC). To accelerate encoding speed, we design a group of point clouds level coding framework with an effective network initialization strategy, which can reduce around 60% encoding time. A lightweight coding network based on multiscale SparseConv, consisting of scale context extraction, child node prediction, and model compression modules, is proposed to realize fast inference and compact decoder size. Experimental results show that our method consistently outperforms traditional and AI-based methods: for example, with the convergence time in the MVUB dataset, our method reduces the bitstream by approximately 21.21% compared to G-PCC TMC13v23 and 21.95% compared to SparsePCGC. Our project can be seen on https://huangwenjie2023.github.io/LINR-PCGC/.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°æœ‰åŸºäºäººå·¥æ™ºèƒ½çš„ç‚¹äº‘å‡ ä½•å‹ç¼©(Point Cloud Geometry Compression, PCGC)æ–¹æ³•è¿‡åº¦ä¾èµ–ç‰¹å®šè®­ç»ƒæ•°æ®åˆ†å¸ƒï¼Œä»¥åŠéšå¼ç¥ç»è¡¨ç¤º(Implicit Neural Representation, INR)æ–¹æ³•ç›®å‰ä»…é™äºæœ‰æŸå‹ç¼©çš„é—®é¢˜ï¼Œæå‡ºäº†é¦–ä¸ªåŸºäºINRçš„æ— æŸç‚¹äº‘å‡ ä½•å‹ç¼©æ–¹æ³•LINR-PCGCã€‚ä¸ºäº†æå‡ç¼–ç é€Ÿåº¦ï¼Œè¯¥æ–¹æ³•è®¾è®¡äº†ä¸€å¥—ç‚¹äº‘ç»„çº§åˆ«(group of point clouds)çš„ç¼–ç æ¡†æ¶ï¼Œå¹¶ç»“åˆæœ‰æ•ˆçš„ç½‘ç»œåˆå§‹åŒ–ç­–ç•¥ï¼Œå°†ç¼–ç æ—¶é—´ç¼©å‡äº†çº¦60%ã€‚å…¶æ ¸å¿ƒæ¶æ„é‡‡ç”¨äº†åŸºäºå¤šå°ºåº¦SparseConvçš„è½»é‡åŒ–ç¼–ç ç½‘ç»œï¼Œé€šè¿‡å°ºåº¦ä¸Šä¸‹æ–‡æå–ã€å­èŠ‚ç‚¹é¢„æµ‹åŠæ¨¡å‹å‹ç¼©æ¨¡å—å®ç°äº†å¿«é€Ÿæ¨ç†å’Œç´§å‡‘çš„è§£ç å™¨ä½“ç§¯ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒLINR-PCGCåœ¨æ€§èƒ½ä¸ŠæŒç»­ä¼˜äºä¼ ç»Ÿæ–¹æ³•å’Œç°æœ‰çš„AIæ¨¡å‹ã€‚åœ¨MVUBæ•°æ®é›†ä¸Šï¼Œè¯¥æ–¹æ³•æ¯”G-PCC TMC13v23å‡å°‘äº†çº¦21.21%çš„ç æµï¼Œç›¸æ¯”SparsePCGCåˆ™å‡å°‘äº†21.95%ã€‚è¯¥ç ”ç©¶æˆåŠŸå°†INRåº”ç”¨äºæ— æŸå‡ ä½•å‹ç¼©é¢†åŸŸï¼Œä¸ºç‚¹äº‘å‹ç¼©çš„å®é™…éƒ¨ç½²æä¾›äº†æ›´å…·æ³›åŒ–èƒ½åŠ›çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to ICCV 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.15686v1",
      "published_date": "2025-07-21 14:48:54 UTC",
      "updated_date": "2025-07-21 14:48:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:58:02.247375+00:00"
    },
    {
      "arxiv_id": "2507.15681v1",
      "title": "Missing value imputation with adversarial random forests -- MissARF",
      "title_zh": "MissARFï¼šåŸºäºå¯¹æŠ—éšæœºæ£®æ—çš„ç¼ºå¤±å€¼æ’è¡¥",
      "authors": [
        "Pegah Golchian",
        "Jan Kapar",
        "David S. Watson",
        "Marvin N. Wright"
      ],
      "abstract": "Handling missing values is a common challenge in biostatistical analyses, typically addressed by imputation methods. We propose a novel, fast, and easy-to-use imputation method called missing value imputation with adversarial random forests (MissARF), based on generative machine learning, that provides both single and multiple imputation. MissARF employs adversarial random forest (ARF) for density estimation and data synthesis. To impute a missing value of an observation, we condition on the non-missing values and sample from the estimated conditional distribution generated by ARF. Our experiments demonstrate that MissARF performs comparably to state-of-the-art single and multiple imputation methods in terms of imputation quality and fast runtime with no additional costs for multiple imputation.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åä¸º MissARF (Missing value imputation with adversarial random forests) çš„æ–°å‹ç¼ºå¤±å€¼å¡«è¡¥æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³ç”Ÿç‰©ç»Ÿè®¡åˆ†æä¸­å¸¸è§çš„ç¼ºå¤±å€¼æŒ‘æˆ˜ã€‚è¯¥æ–¹æ³•åŸºäºç”Ÿæˆå¼æœºå™¨å­¦ä¹ (generative machine learning)ï¼Œåˆ©ç”¨å¯¹æŠ—éšæœºæ£®æ—(Adversarial Random Forest, ARF)è¿›è¡Œå¯†åº¦ä¼°è®¡(density estimation)å’Œæ•°æ®åˆæˆ(data synthesis)ã€‚åœ¨å¡«è¡¥è¿‡ç¨‹ä¸­ï¼ŒMissARF é€šè¿‡å¯¹éç¼ºå¤±å€¼è¿›è¡Œæ¡ä»¶åŒ–å¤„ç†ï¼Œä» ARF ç”Ÿæˆçš„ä¼°è®¡æ¡ä»¶åˆ†å¸ƒ(conditional distribution)ä¸­è¿›è¡Œé‡‡æ ·ã€‚è¯¥æ–¹æ³•ä¸ä»…å¿«é€Ÿä¸”æ˜“äºä½¿ç”¨ï¼Œè¿˜èƒ½å¤ŸåŒæ—¶æ”¯æŒå•æ¬¡å¡«è¡¥(single imputation)å’Œå¤šæ¬¡å¡«è¡¥(multiple imputation)ä»»åŠ¡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒMissARF åœ¨å¡«è¡¥è´¨é‡å’Œè¿è¡Œé€Ÿåº¦ä¸Šä¸ç›®å‰æœ€å…ˆè¿›çš„(state-of-the-art)æ–¹æ³•è¡¨ç°ç›¸å½“ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•åœ¨æ‰§è¡Œå¤šæ¬¡å¡«è¡¥æ—¶ä¸ä¼šäº§ç”Ÿé¢å¤–çš„è®¡ç®—æˆæœ¬ï¼Œä¸ºå¤„ç†å¤æ‚æ•°æ®é›†æä¾›äº†é«˜æ•ˆä¸”ä½æ¶ˆè€—çš„æ›¿ä»£æ–¹æ¡ˆã€‚",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.15681v1",
      "published_date": "2025-07-21 14:44:51 UTC",
      "updated_date": "2025-07-21 14:44:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:58:13.851119+00:00"
    },
    {
      "arxiv_id": "2507.15676v1",
      "title": "Agentic AI for autonomous anomaly management in complex systems",
      "title_zh": "é¢å‘å¤æ‚ç³»ç»Ÿè‡ªä¸»å¼‚å¸¸ç®¡ç†çš„ä»£ç†å¼ AI",
      "authors": [
        "Reza Vatankhah Barenji",
        "Sina Khoshgoftar"
      ],
      "abstract": "This paper explores the potential of agentic AI in autonomously detecting and responding to anomalies within complex systems, emphasizing its ability to transform traditional, human-dependent anomaly management methods.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº† Agentic AI åœ¨å¤æ‚ç³»ç»Ÿä¸­å®ç°è‡ªä¸»å¼‚å¸¸æ£€æµ‹ä¸å“åº”çš„æ½œåŠ›ï¼Œé‡ç‚¹å…³æ³¨å…¶åœ¨æ”¹å˜ä¼ ç»Ÿã€ä¾èµ–äººå·¥çš„å¼‚å¸¸ç®¡ç†æ–¹æ³•æ–¹é¢çš„æ ¸å¿ƒèƒ½åŠ›ã€‚é€šè¿‡å¼•å…¥å…·å¤‡è‡ªä¸»å†³ç­–èƒ½åŠ›çš„æ™ºèƒ½ä½“ï¼Œè¯¥è®ºæ–‡å±•ç¤ºäº†å¦‚ä½•åˆ©ç”¨ AI æŠ€æœ¯æ„å»ºä¸€ä¸ªèƒ½å¤Ÿå®æ—¶è¯†åˆ«å¹¶å¤„ç†ç³»ç»Ÿæ•…éšœçš„è‡ªåŠ¨åŒ–æ¡†æ¶ã€‚ç ”ç©¶å¼ºè°ƒï¼ŒAgentic AI çš„åº”ç”¨å¯ä»¥æ˜¾è‘—é™ä½å¤æ‚ç³»ç»Ÿè¿ç»´å¯¹äººç±»ä¸“å®¶çš„ä¾èµ–ï¼Œæé«˜å¼‚å¸¸å¤„ç†çš„å“åº”é€Ÿåº¦å’Œå‡†ç¡®æ€§ã€‚æœ€ç»ˆï¼Œè¯¥ç ”ç©¶ä¸ºå®ç°å¤æ‚ç³»ç»Ÿçš„å…¨è‡ªåŠ¨åŒ–ç®¡ç†æä¾›äº†ç†è®ºä¾æ®å’Œå®è·µè·¯å¾„ï¼Œé¢„ç¤ºäº†ä»è¢«åŠ¨ç»´æŠ¤å‘ä¸»åŠ¨ã€æ™ºèƒ½åŒ–å¼‚å¸¸ç®¡ç†çš„é‡å¤§è½¬å‹ã€‚",
      "categories": [
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.15676v1",
      "published_date": "2025-07-21 14:39:08 UTC",
      "updated_date": "2025-07-21 14:39:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:58:09.658064+00:00"
    },
    {
      "arxiv_id": "2507.22921v1",
      "title": "Fast and Accurate Contextual Knowledge Extraction Using Cascading Language Model Chains and Candidate Answers",
      "title_zh": "åŸºäºçº§è”è¯­è¨€æ¨¡å‹é“¾ä¸å€™é€‰ç­”æ¡ˆçš„å¿«é€Ÿå‡†ç¡®ä¸Šä¸‹æ–‡çŸ¥è¯†æå–",
      "authors": [
        "Lee Harris"
      ],
      "abstract": "Language models can capture complex relationships in given text, but these are notorious for being costly and for producing information that does not exist (i.e., hallucinations). Furthermore, the resources invested into producing this information would be wasted if it were incorrect. We address these issues by proposing, implementing, and applying the Language Model Chain (LMC) algorithm. In this, a language model's response to a given prompt about given text is only correct if it exists in the collection of possible (i.e., candidate) answers, and text corresponding to incorrect responses is fed into a more predictive (but slower) language model. This process is repeated for a collection of language models, or until all predictions about the text are correct. We used the LMC algorithm to extract patient dates of birth from medical documents, and combining a collection of language models in a multi-stage cascade significantly increased prediction speed and accuracy over individual language models, while greatly reducing the number of corresponding hallucinations. We believe that the novel LMC algorithm significantly contributes to the knowledge extraction field, and that this should be explored much further in the future.",
      "tldr_zh": "æœ¬ç ”ç©¶æå‡ºäº†Language Model Chain (LMC)ç®—æ³•ï¼Œæ—¨åœ¨è§£å†³è¯­è¨€æ¨¡å‹åœ¨ä¸Šä¸‹æ–‡çŸ¥è¯†æå–ä¸­å­˜åœ¨çš„é«˜æˆæœ¬å’Œå¹»è§‰(hallucinations)é—®é¢˜ã€‚è¯¥ç®—æ³•é€šè¿‡æ„å»ºå¤šçº§çº§è”çš„è¯­è¨€æ¨¡å‹é“¾æ¡ï¼Œå°†æ¨¡å‹ç”Ÿæˆçš„å“åº”ä¸é¢„è®¾çš„å€™é€‰ç­”æ¡ˆ(candidate answers)é›†åˆè¿›è¡Œæ ¡éªŒã€‚è‹¥å½“å‰æ¨¡å‹çš„é¢„æµ‹è¢«åˆ¤å®šä¸ºä¸å‡†ç¡®ï¼Œåˆ™å°†ç›¸å…³æ–‡æœ¬ä¼ é€’ç»™é¢„æµ‹èƒ½åŠ›æ›´å¼ºä½†å¤„ç†é€Ÿåº¦è¾ƒæ…¢çš„åç»­æ¨¡å‹ï¼Œç›´è‡³è·å¾—æ­£ç¡®ç»“æœæˆ–éå†å®Œæ¨¡å‹é›†åˆã€‚åœ¨ä»åŒ»ç–—æ–‡æ¡£ä¸­æå–æ‚£è€…å‡ºç”Ÿæ—¥æœŸçš„å®éªŒåº”ç”¨ä¸­ï¼ŒLMCç®—æ³•é€šè¿‡å¤šé˜¶æ®µçº§è”æ˜¾è‘—æé«˜äº†é¢„æµ‹é€Ÿåº¦å’Œå‡†ç¡®æ€§ã€‚å®éªŒç»“æœè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä¿æŒé«˜æ•ˆæ€§èƒ½çš„åŒæ—¶ï¼Œèƒ½å¤Ÿå¤§å¹…å‡å°‘ä¸æå–ä»»åŠ¡ç›¸å…³çš„å¹»è§‰ç°è±¡ã€‚è¿™é¡¹ç ”ç©¶ä¸ºçŸ¥è¯†æå–é¢†åŸŸè´¡çŒ®äº†æ–°é¢–çš„çº§è”æ¡†æ¶ï¼Œä¸ºæœªæ¥å®ç°å¿«é€Ÿä¸”å‡†ç¡®çš„æƒ…å¢ƒåŒ–ä¿¡æ¯æŠ½å–æä¾›äº†æœ‰æ•ˆè·¯å¾„ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.22921v1",
      "published_date": "2025-07-21 14:31:16 UTC",
      "updated_date": "2025-07-21 14:31:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:58:10.090000+00:00"
    },
    {
      "arxiv_id": "2507.15663v2",
      "title": "SustainDiffusion: Optimising the Social and Environmental Sustainability of Stable Diffusion Models",
      "title_zh": "SustainDiffusionï¼šä¼˜åŒ– Stable Diffusion æ¨¡å‹çš„ç¤¾ä¼šä¸ç¯å¢ƒå¯æŒç»­æ€§",
      "authors": [
        "Giordano d'Aloisio",
        "Tosin Fadahunsi",
        "Jay Choy",
        "Rebecca Moussa",
        "Federica Sarro"
      ],
      "abstract": "Background: Text-to-image generation models are widely used across numerous domains. Among these models, Stable Diffusion (SD) - an open-source text-to-image generation model - has become the most popular, producing over 12 billion images annually. However, the widespread use of these models raises concerns regarding their social and environmental sustainability.\n  Aims: To reduce the harm that SD models may have on society and the environment, we introduce SustainDiffusion, a search-based approach designed to enhance the social and environmental sustainability of SD models.\n  Method: SustainDiffusion searches the optimal combination of hyperparameters and prompt structures that can reduce gender and ethnic bias in generated images while also lowering the energy consumption required for image generation. Importantly, SustainDiffusion maintains image quality comparable to that of the original SD model.\n  Results: We conduct a comprehensive empirical evaluation of SustainDiffusion, testing it against six different baselines using 56 different prompts. Our results demonstrate that SustainDiffusion can reduce gender bias in SD3 by 68%, ethnic bias by 59%, and energy consumption (calculated as the sum of CPU and GPU energy) by 48%. Additionally, the outcomes produced by SustainDiffusion are consistent across multiple runs and can be generalised to various prompts.\n  Conclusions: With SustainDiffusion, we demonstrate how enhancing the social and environmental sustainability of text-to-image generation models is possible without fine-tuning or changing the model's architecture.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† SustainDiffusionï¼Œè¿™æ˜¯ä¸€ç§åŸºäºæœç´¢çš„æ–¹æ³•ï¼Œæ—¨åœ¨æå‡ Stable Diffusion (SD) æ¨¡å‹åœ¨ç¤¾ä¼šå’Œç¯å¢ƒæ–¹é¢çš„å¯æŒç»­æ€§ã€‚é’ˆå¯¹ text-to-image æ¨¡å‹å¹¿æ³›åº”ç”¨å¸¦æ¥çš„åè§ä¸é«˜èƒ½è€—é—®é¢˜ï¼Œè¯¥æ–¹æ³•é€šè¿‡å¯»æ‰¾ hyperparameters å’Œ prompt structures çš„æœ€ä¼˜ç»„åˆï¼Œåœ¨æ— éœ€å¯¹æ¨¡å‹è¿›è¡Œ fine-tuning æˆ–æ›´æ”¹æ¶æ„çš„æƒ…å†µä¸‹é™ä½è´Ÿé¢å½±å“ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒSustainDiffusion åœ¨ SD3 æ¨¡å‹ä¸Šåˆ†åˆ«å‡å°‘äº† 68% çš„ gender bias å’Œ 59% çš„ ethnic biasï¼ŒåŒæ—¶å°†åŒ…å« CPU ä¸ GPU åœ¨å†…çš„æ€»èƒ½è€—é™ä½äº† 48%ã€‚è¯¥æ–¹æ¡ˆåœ¨ä¿æŒå›¾åƒè´¨é‡çš„åŒæ—¶è¡¨ç°å‡ºæå¼ºçš„æ³›åŒ–èƒ½åŠ›ï¼Œè¯æ˜äº†åœ¨ä¸ç‰ºç‰²æ€§èƒ½çš„å‰æä¸‹ä¼˜åŒ–ç”Ÿæˆå¼æ¨¡å‹å¯æŒç»­æ€§çš„å¯è¡Œæ€§ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.15663v2",
      "published_date": "2025-07-21 14:24:31 UTC",
      "updated_date": "2025-12-05 18:41:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:58:15.928522+00:00"
    },
    {
      "arxiv_id": "2507.15643v1",
      "title": "Towards Explainable Anomaly Detection in Shared Mobility Systems",
      "title_zh": "é¢å‘å…±äº«å‡ºè¡Œç³»ç»Ÿçš„å¯è§£é‡Šå¼‚å¸¸æ£€æµ‹",
      "authors": [
        "Elnur Isgandarov",
        "Matteo Cederle",
        "Federico Chiariotti",
        "Gian Antonio Susto"
      ],
      "abstract": "Shared mobility systems, such as bike-sharing networks, play a crucial role in urban transportation. Identifying anomalies in these systems is essential for optimizing operations, improving service reliability, and enhancing user experience. This paper presents an interpretable anomaly detection framework that integrates multi-source data, including bike-sharing trip records, weather conditions, and public transit availability. The Isolation Forest algorithm is employed for unsupervised anomaly detection, along with the Depth-based Isolation Forest Feature Importance (DIFFI) algorithm providing interpretability. Results show that station-level analysis offers a robust understanding of anomalies, highlighting the influence of external factors such as adverse weather and limited transit availability. Our findings contribute to improving decision-making in shared mobility operations.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ Shared Mobility Systemsï¼ˆå¦‚å…±äº«å•è½¦ç½‘ç»œï¼‰æå‡ºäº†ä¸€ä¸ªå¯è§£é‡Šçš„å¼‚å¸¸æ£€æµ‹æ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡è¯†åˆ«ç³»ç»Ÿå¼‚å¸¸æ¥ä¼˜åŒ–åŸå¸‚äº¤é€šè¿è¥å¹¶æé«˜æœåŠ¡å¯é æ€§ã€‚è¯¥æ¡†æ¶æ•´åˆäº†è¡Œç¨‹è®°å½•ã€å¤©æ°”çŠ¶å†µå’Œå…¬å…±äº¤é€šå¯ç”¨æ€§ç­‰å¤šæºæ•°æ®ï¼Œå¹¶é‡‡ç”¨ Isolation Forest ç®—æ³•è¿›è¡Œæ— ç›‘ç£å¼‚å¸¸æ£€æµ‹ã€‚ä¸ºäº†æå‡æ¨¡å‹çš„å¯è§£é‡Šæ€§ï¼Œç ”ç©¶ç»“åˆäº† Depth-based Isolation Forest Feature Importance (DIFFI) ç®—æ³•ï¼Œå¯¹å½±å“å¼‚å¸¸çš„ç‰¹å¾è¿›è¡Œæ·±å…¥åˆ†æã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œç«™ç‚¹å±‚é¢çš„åˆ†æèƒ½å¤Ÿç¨³å¥åœ°è¯†åˆ«å¼‚å¸¸æ¨¡å¼ï¼Œå¹¶æ­ç¤ºäº†æ¶åŠ£å¤©æ°”å’Œæœ‰é™çš„äº¤é€šæ¥é©³ç­‰å¤–éƒ¨å› ç´ å¯¹ç³»ç»Ÿè¿è¡Œçš„æ˜¾è‘—å½±å“ã€‚è¯¥ç ”ç©¶æˆæœä¸ºæå‡ Shared Mobility è¿è¥å†³ç­–æ•ˆç‡å’Œä¼˜åŒ–ç”¨æˆ·ä½“éªŒæä¾›äº†é‡è¦çš„æŠ€æœ¯æ”¯æ’‘ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "6 pages, 8 figures. Paper accepted to J3C 2025 (Joint Conference on Computers, Cognition and Communication",
      "pdf_url": "https://arxiv.org/pdf/2507.15643v1",
      "published_date": "2025-07-21 14:06:42 UTC",
      "updated_date": "2025-07-21 14:06:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:58:18.443169+00:00"
    },
    {
      "arxiv_id": "2507.15641v1",
      "title": "Leveraging Context for Multimodal Fallacy Classification in Political Debates",
      "title_zh": "æ”¿æ²»è¾©è®ºä¸­åˆ©ç”¨ä¸Šä¸‹æ–‡çš„å¤šæ¨¡æ€è°¬è¯¯åˆ†ç±»",
      "authors": [
        "Alessio Pittiglio"
      ],
      "abstract": "In this paper, we present our submission to the MM-ArgFallacy2025 shared task, which aims to advance research in multimodal argument mining, focusing on logical fallacies in political debates. Our approach uses pretrained Transformer-based models and proposes several ways to leverage context. In the fallacy classification subtask, our models achieved macro F1-scores of 0.4444 (text), 0.3559 (audio), and 0.4403 (multimodal). Our multimodal model showed performance comparable to the text-only model, suggesting potential for improvements.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹MM-ArgFallacy2025å…±äº«ä»»åŠ¡ï¼Œæå‡ºäº†ä¸€ç§æ—¨åœ¨è¯†åˆ«æ”¿æ²»è¾©è®ºä¸­é€»è¾‘è°¬è¯¯çš„å¤šæ¨¡æ€è®ºè¯æŒ–æ˜æ–¹æ³•ã€‚ç ”ç©¶å›¢é˜Ÿé‡‡ç”¨äº†é¢„è®­ç»ƒçš„Transformer-basedæ¨¡å‹ï¼Œå¹¶é‡ç‚¹æ¢ç´¢äº†å¤šç§åˆ©ç”¨Contextæ¥å¢å¼ºåˆ†ç±»æ€§èƒ½çš„æœ‰æ•ˆæ–¹å¼ã€‚åœ¨è°¬è¯¯åˆ†ç±»å­ä»»åŠ¡ä¸­ï¼Œè¯¥æ¨¡å‹åœ¨æ–‡æœ¬ã€éŸ³é¢‘å’Œå¤šæ¨¡æ€ç»´åº¦ä¸Šåˆ†åˆ«å–å¾—äº†0.4444ã€0.3559å’Œ0.4403çš„macro F1-scoresã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒMultimodalæ¨¡å‹çš„è¡¨ç°ä¸çº¯æ–‡æœ¬æ¨¡å‹åŸºæœ¬æŒå¹³ï¼Œè¿™ä¸ä»…å±•ç¤ºäº†å½“å‰æ¨¡å‹çš„æœ‰æ•ˆæ€§ï¼Œä¹Ÿæ­ç¤ºäº†æœªæ¥åœ¨å¤šæ¨¡æ€ç‰¹å¾èåˆæ–¹é¢è¿›ä¸€æ­¥æå‡æ€§èƒ½çš„æ½œåŠ›ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "12th Workshop on Argument Mining (ArgMining 2025) @ ACL 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.15641v1",
      "published_date": "2025-07-21 14:03:08 UTC",
      "updated_date": "2025-07-21 14:03:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:58:21.353350+00:00"
    },
    {
      "arxiv_id": "2507.15640v1",
      "title": "Data Mixing Agent: Learning to Re-weight Domains for Continual Pre-training",
      "title_zh": "Data Mixing Agentï¼šé¢å‘æŒç»­é¢„è®­ç»ƒçš„é¢†åŸŸé‡åŠ æƒå­¦ä¹ ",
      "authors": [
        "Kailai Yang",
        "Xiao Liu",
        "Lei Ji",
        "Hao Li",
        "Yeyun Gong",
        "Peng Cheng",
        "Mao Yang"
      ],
      "abstract": "Continual pre-training on small-scale task-specific data is an effective method for improving large language models in new target fields, yet it risks catastrophic forgetting of their original capabilities. A common solution is to re-weight training data mixtures from source and target fields on a domain space to achieve balanced performance. Previous domain reweighting strategies rely on manual designation with certain heuristics based on human intuition or empirical results. In this work, we prove that more general heuristics can be parameterized by proposing Data Mixing Agent, the first model-based, end-to-end framework that learns to re-weight domains. The agent learns generalizable heuristics through reinforcement learning on large quantities of data mixing trajectories with corresponding feedback from an evaluation environment. Experiments in continual pre-training on math reasoning show that Data Mixing Agent outperforms strong baselines in achieving balanced performance across source and target field benchmarks. Furthermore, it generalizes well across unseen source fields, target models, and domain spaces without retraining. Direct application to the code generation field also indicates its adaptability across target domains. Further analysis showcases the agents' well-aligned heuristics with human intuitions and their efficiency in achieving superior model performance with less source-field data.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Data Mixing Agentï¼Œè¿™æ˜¯é¦–ä¸ªåŸºäºæ¨¡å‹ä¸”ç«¯åˆ°ç«¯çš„é¢†åŸŸé‡åŠ æƒæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹åœ¨æŒç»­é¢„è®­ç»ƒ(Continual Pre-training)è¿‡ç¨‹ä¸­ï¼Œå› ä¾§é‡ç‰¹å®šä»»åŠ¡æ•°æ®è€Œå¼•å‘çš„ç¾éš¾æ€§é—å¿˜(Catastrophic Forgetting)é—®é¢˜ã€‚è¯¥æ¡†æ¶åˆ©ç”¨å¼ºåŒ–å­¦ä¹ (Reinforcement Learning)åœ¨å¤§é‡æ•°æ®æ··åˆè½¨è¿¹ä¸Šè¿›è¡Œè®­ç»ƒï¼Œé€šè¿‡è¯„ä¼°ç¯å¢ƒçš„åé¦ˆå­¦ä¹ å¯æ³›åŒ–çš„å¯å‘å¼ç­–ç•¥ï¼Œå®ç°è‡ªåŠ¨åŒ–çš„æ•°æ®åŸŸæ¯”ä¾‹è°ƒæ•´ã€‚åœ¨æ•°å­¦æ¨ç†é¢†åŸŸçš„å®éªŒç»“æœæ˜¾ç¤ºï¼ŒData Mixing Agent åœ¨å¹³è¡¡æºé¢†åŸŸå’Œç›®æ ‡é¢†åŸŸçš„è¡¨ç°ä¸Šä¼˜äºå¤šç§åŸºçº¿æ¨¡å‹ã€‚æ­¤å¤–ï¼Œè¯¥ä»£ç†å±•ç°äº†å“è¶Šçš„æ³›åŒ–èƒ½åŠ›ï¼Œåœ¨æœªè§è¿‡çš„æºé¢†åŸŸã€ç›®æ ‡æ¨¡å‹åŠé¢†åŸŸç©ºé—´ä¸‹æ— éœ€é‡è®­å³å¯æœ‰æ•ˆå·¥ä½œã€‚åœ¨ä»£ç ç”Ÿæˆä»»åŠ¡ä¸­çš„åº”ç”¨è¿›ä¸€æ­¥è¯æ˜äº†å…¶å¹¿æ³›çš„é€‚åº”æ€§ï¼Œä¸”åˆ†æè¡¨æ˜è¯¥ä»£ç†èƒ½ä»¥æ›´å°‘çš„æºé¢†åŸŸæ•°æ®è¾¾æˆæ›´ä¼˜çš„æ€§èƒ½ï¼Œå…¶å­¦ä¹ åˆ°çš„ç­–ç•¥ä¸äººç±»ç›´è§‰é«˜åº¦å¥‘åˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.15640v1",
      "published_date": "2025-07-21 14:01:54 UTC",
      "updated_date": "2025-07-21 14:01:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:58:25.632279+00:00"
    },
    {
      "arxiv_id": "2507.16856v2",
      "title": "SIA: Enhancing Safety via Intent Awareness for Vision-Language Models",
      "title_zh": "SIAï¼šé€šè¿‡æ„å›¾æ„ŸçŸ¥æå‡è§†è§‰è¯­è¨€æ¨¡å‹çš„å®‰å…¨æ€§",
      "authors": [
        "Youngjin Na",
        "Sangheon Jeong",
        "Youngwan Lee",
        "Jian Lee",
        "Dawoon Jeong",
        "Youngman Kim"
      ],
      "abstract": "With the growing deployment of Vision-Language Models (VLMs) in real-world applications, previously overlooked safety risks are becoming increasingly evident. In particular, seemingly innocuous multimodal inputs can combine to reveal harmful intent, leading to unsafe model outputs. While multimodal safety has received increasing attention, existing approaches often fail to address such latent risks, especially when harmfulness arises only from the interaction between modalities. We propose SIA (Safety via Intent Awareness), a training-free, intent-aware safety framework that proactively detects harmful intent in multimodal inputs and uses it to guide the generation of safe responses. SIA follows a three-stage process: (1) visual abstraction via captioning; (2) intent inference through few-shot chain-of-thought (CoT) prompting; and (3) intent-conditioned response generation. By dynamically adapting to the implicit intent inferred from an image-text pair, SIA mitigates harmful outputs without extensive retraining. Extensive experiments on safety benchmarks, including SIUO, MM-SafetyBench, and HoliSafe, show that SIA consistently improves safety and outperforms prior training-free methods.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è§†è§‰è¯­è¨€æ¨¡å‹(Vision-Language Models, VLMs)åœ¨å¤„ç†å¤šæ¨¡æ€è¾“å…¥æ—¶å­˜åœ¨çš„æ½œåœ¨å®‰å…¨é£é™©ï¼Œæå‡ºäº†SIA (Safety via Intent Awareness) æ¡†æ¶ã€‚SIAæ˜¯ä¸€ç§æ— éœ€è®­ç»ƒ(training-free)ä¸”å…·å¤‡æ„å›¾æ„ŸçŸ¥èƒ½åŠ›çš„å®‰å…¨å¢å¼ºæ¡†æ¶ï¼Œæ—¨åœ¨ä¸»åŠ¨æ£€æµ‹å¤šæ¨¡æ€è¾“å…¥ä¸­éšè—çš„æœ‰å®³æ„å›¾ï¼Œå¹¶ä»¥æ­¤å¼•å¯¼æ¨¡å‹ç”Ÿæˆå®‰å…¨çš„å›å¤ã€‚è¯¥æ¡†æ¶é‡‡ç”¨ä¸‰é˜¶æ®µå¤„ç†æµç¨‹ï¼ŒåŒ…æ‹¬é€šè¿‡å›¾åƒæè¿°(captioning)å®ç°è§†è§‰æŠ½è±¡ã€åˆ©ç”¨å°‘æ ·æœ¬é“¾å¼æ€ç»´(few-shot Chain-of-Thought, CoT)æç¤ºè¿›è¡Œæ„å›¾æ¨ç†ï¼Œä»¥åŠç”Ÿæˆå—æ„å›¾çº¦æŸçš„å“åº”ã€‚é€šè¿‡åŠ¨æ€é€‚åº”ä»å›¾åƒ-æ–‡æœ¬å¯¹ä¸­æ¨æ–­å‡ºçš„éšå¼æ„å›¾ï¼ŒSIAèƒ½å¤Ÿåœ¨ä¸è¿›è¡Œå¤§è§„æ¨¡é‡æ–°è®­ç»ƒçš„æƒ…å†µä¸‹æœ‰æ•ˆéåˆ¶æœ‰å®³è¾“å‡ºã€‚åœ¨SIUOã€MM-SafetyBenchå’ŒHoliSafeç­‰å®‰å…¨åŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼ŒSIAåœ¨æå‡æ¨¡å‹å®‰å…¨æ€§æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œå…¶æ€§èƒ½ä¼˜äºç°æœ‰çš„æ— éœ€è®­ç»ƒçš„åŸºå‡†æ–¹æ³•ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to Safe and Trustworthy Multimodal AI Systems(SafeMM-AI) Workshop at ICCV2025, Non-archival track",
      "pdf_url": "https://arxiv.org/pdf/2507.16856v2",
      "published_date": "2025-07-21 13:59:50 UTC",
      "updated_date": "2025-10-06 10:16:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:58:36.950402+00:00"
    },
    {
      "arxiv_id": "2507.15636v1",
      "title": "Uncovering Critical Features for Deepfake Detection through the Lottery Ticket Hypothesis",
      "title_zh": "åŸºäºå½©ç¥¨å‡è®¾æ­ç¤º Deepfake æ£€æµ‹çš„å…³é”®ç‰¹å¾",
      "authors": [
        "Lisan Al Amin",
        "Md. Ismail Hossain",
        "Thanh Thi Nguyen",
        "Tasnim Jahan",
        "Mahbubul Islam",
        "Faisal Quader"
      ],
      "abstract": "Recent advances in deepfake technology have created increasingly convincing synthetic media that poses significant challenges to information integrity and social trust. While current detection methods show promise, their underlying mechanisms remain poorly understood, and the large sizes of their models make them challenging to deploy in resource-limited environments. This study investigates the application of the Lottery Ticket Hypothesis (LTH) to deepfake detection, aiming to identify the key features crucial for recognizing deepfakes. We examine how neural networks can be efficiently pruned while maintaining high detection accuracy. Through extensive experiments with MesoNet, CNN-5, and ResNet-18 architectures on the OpenForensic and FaceForensics++ datasets, we find that deepfake detection networks contain winning tickets, i.e., subnetworks, that preserve performance even at substantial sparsity levels. Our results indicate that MesoNet retains 56.2% accuracy at 80% sparsity on the OpenForensic dataset, with only 3,000 parameters, which is about 90% of its baseline accuracy (62.6%). The results also show that our proposed LTH-based iterative magnitude pruning approach consistently outperforms one-shot pruning methods. Using Grad-CAM visualization, we analyze how pruned networks maintain their focus on critical facial regions for deepfake detection. Additionally, we demonstrate the transferability of winning tickets across datasets, suggesting potential for efficient, deployable deepfake detection systems.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†Lottery Ticket Hypothesis (LTH)åœ¨Deepfake Detectionä¸­çš„åº”ç”¨ï¼Œæ—¨åœ¨è¯†åˆ«è¯†åˆ«ä¼ªé€ åª’ä½“çš„å…³é”®ç‰¹å¾å¹¶ä¼˜åŒ–æ¨¡å‹åœ¨èµ„æºå—é™ç¯å¢ƒä¸‹çš„éƒ¨ç½²ã€‚é€šè¿‡åœ¨OpenForensicå’ŒFaceForensics++æ•°æ®é›†ä¸Šå¯¹MesoNetã€CNN-5å’ŒResNet-18æ¶æ„è¿›è¡Œå®éªŒï¼Œç ”ç©¶å‘ç°è¿™äº›ç½‘ç»œä¸­å­˜åœ¨èƒ½å¤Ÿåœ¨æé«˜ç¨€ç–åº¦ä¸‹ä¿æŒé«˜æ€§èƒ½çš„winning ticketså­ç½‘ç»œã€‚å®éªŒè¯æ˜ï¼ŒåŸºäºLTHçš„iterative magnitude pruningæ–¹æ³•åœ¨æ€§èƒ½ä¸ŠæŒç»­ä¼˜äºone-shot pruningï¼Œå…¶ä¸­MesoNetåœ¨80%ç¨€ç–åº¦ä¸‹ä»…éœ€3,000ä¸ªå‚æ•°å³å¯ä¿ç•™çº¦90%çš„åŸºå‡†å‡†ç¡®ç‡ã€‚åˆ©ç”¨Grad-CAMå¯è§†åŒ–åˆ†æï¼Œç ”ç©¶ç¡®è®¤äº†å‰ªæåçš„ç½‘ç»œä¾ç„¶èšç„¦äºå¯¹æ£€æµ‹è‡³å…³é‡è¦çš„é¢éƒ¨åŒºåŸŸã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜å±•ç¤ºäº†winning ticketsåœ¨ä¸åŒæ•°æ®é›†é—´çš„è¿ç§»æ€§ï¼Œä¸ºå¼€å‘é«˜æ•ˆä¸”æ˜“äºéƒ¨ç½²çš„Deepfake Detectionç³»ç»Ÿæä¾›äº†é‡è¦ä¾æ®ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted for publication at the 2025 IEEE International Conference on Systems, Man, and Cybernetics (SMC)",
      "pdf_url": "https://arxiv.org/pdf/2507.15636v1",
      "published_date": "2025-07-21 13:58:24 UTC",
      "updated_date": "2025-07-21 13:58:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:59:01.695916+00:00"
    },
    {
      "arxiv_id": "2507.15907v1",
      "title": "Dual Turing Test: A Framework for Detecting and Mitigating Undetectable AI",
      "title_zh": "åŒé‡å›¾çµæµ‹è¯•ï¼šæ£€æµ‹ä¸åº”å¯¹ä¸å¯æ£€æµ‹äººå·¥æ™ºèƒ½çš„æ¡†æ¶",
      "authors": [
        "Alberto Messina"
      ],
      "abstract": "In this short note, we propose a unified framework that bridges three areas: (1) a flipped perspective on the Turing Test, the \"dual Turing test\", in which a human judge's goal is to identify an AI rather than reward a machine for deception; (2) a formal adversarial classification game with explicit quality constraints and worst-case guarantees; and (3) a reinforcement learning (RL) alignment pipeline that uses an undetectability detector and a set of quality related components in its reward model. We review historical precedents, from inverted and meta-Turing variants to modern supervised reverse-Turing classifiers, and highlight the novelty of combining quality thresholds, phased difficulty levels, and minimax bounds. We then formalize the dual test: define the judge's task over N independent rounds with fresh prompts drawn from a prompt space Q, introduce a quality function Q and parameters tau and delta, and cast the interaction as a two-player zero-sum game over the adversary's feasible strategy set M. Next, we map this minimax game onto an RL-HF style alignment loop, in which an undetectability detector D provides negative reward for stealthy outputs, balanced by a quality proxy that preserves fluency. Throughout, we include detailed explanations of each component notation, the meaning of inner minimization over sequences, phased tests, and iterative adversarial training and conclude with a suggestion for a couple of immediate actions.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªç»Ÿä¸€æ¡†æ¶ï¼Œå°†â€œåŒå›¾çµæµ‹è¯•â€ï¼ˆDual Turing Testï¼‰æ¦‚å¿µã€å¯¹æŠ—æ€§åˆ†ç±»åšå¼ˆå’Œå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰å¯¹é½æµç¨‹ç›¸ç»“åˆï¼Œæ—¨åœ¨æ£€æµ‹å¹¶ç¼“è§£ä¸å¯æ„ŸçŸ¥çš„ AI è¾“å‡ºã€‚è¯¥æ¡†æ¶é‡‡ç”¨ç¿»è½¬çš„å›¾çµæµ‹è¯•è§†è§’ï¼Œè®©è¯„åˆ¤è€…çš„ç›®æ ‡å˜ä¸ºè¯†åˆ« AI è€Œéè¢«å…¶æ¬ºéª—ï¼Œå¹¶ç»“åˆäº†å†å²ä¸Šçš„é€†å‘å›¾çµåˆ†ç±»å™¨ç ”ç©¶ã€‚ç ”ç©¶å½¢å¼åŒ–äº†åŒå‘æµ‹è¯•è¿‡ç¨‹ï¼Œå°†å…¶å®šä¹‰ä¸ºåœ¨ç‰¹å®šæç¤ºç©ºé—´ï¼ˆPrompt Spaceï¼‰å’Œè´¨é‡å‡½æ•°ï¼ˆQuality Functionï¼‰çº¦æŸä¸‹çš„åŒäººé›¶å’Œåšå¼ˆï¼ˆTwo-player Zero-sum Gameï¼‰ã€‚è¯¥åšå¼ˆè¢«æ˜ å°„åˆ°ç±»ä¼¼äº RL-HF çš„å¯¹é½å¾ªç¯ä¸­ï¼Œåˆ©ç”¨ä¸å¯æ¢æµ‹æ£€æµ‹å™¨ï¼ˆUndetectability Detectorï¼‰æä¾›è´Ÿå¥–åŠ±ï¼Œå¹¶é…åˆè´¨é‡ä»£ç†ï¼ˆQuality Proxyï¼‰ä»¥ç¡®ä¿è¾“å‡ºçš„æµåˆ©åº¦ã€‚è®ºæ–‡è¯¦ç»†ä»‹ç»äº†åˆ†é˜¶æ®µæµ‹è¯•ï¼ˆPhased Testsï¼‰ã€è¿­ä»£å¯¹æŠ—è®­ç»ƒï¼ˆIterative Adversarial Trainingï¼‰ä»¥åŠæå°æå¤§ç•Œé™ï¼ˆMinimax Boundsï¼‰çš„åˆ›æ–°ç»“åˆã€‚è¯¥å·¥ä½œä¸ºåº”å¯¹ç°ä»£ç”Ÿæˆå¼æ¨¡å‹äº§ç”Ÿçš„éšè”½ AI å†…å®¹æä¾›äº†ç³»ç»Ÿæ€§çš„æ•°å­¦æ¡†æ¶å’Œå®è·µè·¯å¾„ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.15907v1",
      "published_date": "2025-07-21 13:44:28 UTC",
      "updated_date": "2025-07-21 13:44:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:58:50.044080+00:00"
    },
    {
      "arxiv_id": "2507.15618v1",
      "title": "TacticCraft: Natural Language-Driven Tactical Adaptation for StarCraft II",
      "title_zh": "TacticCraftï¼šé¢å‘ StarCraft II çš„è‡ªç„¶è¯­è¨€é©±åŠ¨æˆ˜æœ¯è‡ªé€‚åº”",
      "authors": [
        "Weiyu Ma",
        "Jiwen Jiang",
        "Haobo Fu",
        "Haifeng Zhang"
      ],
      "abstract": "We present an adapter-based approach for tactical conditioning of StarCraft II AI agents. Current agents, while powerful, lack the ability to adapt their strategies based on high-level tactical directives. Our method freezes a pre-trained policy network (DI-Star) and attaches lightweight adapter modules to each action head, conditioned on a tactical tensor that encodes strategic preferences. By training these adapters with KL divergence constraints, we ensure the policy maintains core competencies while exhibiting tactical variations. Experimental results show our approach successfully modulates agent behavior across tactical dimensions including aggression, expansion patterns, and technology preferences, while maintaining competitive performance. Our method enables flexible tactical control with minimal computational overhead, offering practical strategy customization for complex real-time strategy games.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† TacticCraftï¼Œä¸€ç§é’ˆå¯¹ StarCraft II AI æ™ºèƒ½ä½“çš„åŸºäº Adapter çš„æˆ˜æœ¯è°ƒèŠ‚æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰æ™ºèƒ½ä½“éš¾ä»¥æ ¹æ®é«˜å±‚æŒ‡ä»¤çµæ´»è°ƒæ•´ç­–ç•¥çš„é—®é¢˜ã€‚è¯¥æ–¹æ³•é€šè¿‡å†»ç»“é¢„è®­ç»ƒçš„ç­–ç•¥ç½‘ç»œ DI-Starï¼Œå¹¶åœ¨åŠ¨ä½œå¤´ä¸Šé™„åŠ å—æˆ˜æœ¯å¼ é‡æ¡ä»¶çº¦æŸçš„è½»é‡çº§ Adapter æ¨¡å—ï¼Œå®ç°äº†å¯¹æˆ˜ç•¥åå¥½çš„ç²¾å‡†å¼•å¯¼ã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¼•å…¥ KL divergence çº¦æŸï¼Œç¡®ä¿æ™ºèƒ½ä½“åœ¨äº§ç”Ÿæˆ˜æœ¯å¤šæ ·æ€§çš„åŒæ—¶ç»´æŒæ ¸å¿ƒç«æŠ€æ°´å¹³ã€‚å®éªŒç»“æœè¯æ˜ï¼ŒTacticCraft èƒ½å¤Ÿæœ‰æ•ˆè°ƒèŠ‚æ™ºèƒ½ä½“åœ¨ä¾µç•¥æ€§ã€æ‰©å¼ æ¨¡å¼åŠæŠ€æœ¯è·¯å¾„ç­‰ç»´åº¦çš„è¡Œä¸ºã€‚è¯¥æ–¹æ³•ä»¥æä½çš„è®¡ç®—å¼€é”€å®ç°äº†é«˜æ•ˆçš„æˆ˜æœ¯æ§åˆ¶ï¼Œä¸ºå¤æ‚å®æ—¶ç­–ç•¥æ¸¸æˆçš„ç­–ç•¥å®šåˆ¶åŒ–æä¾›äº†å®ç”¨ä¸”çµæ´»çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.15618v1",
      "published_date": "2025-07-21 13:42:06 UTC",
      "updated_date": "2025-07-21 13:42:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:58:50.791417+00:00"
    },
    {
      "arxiv_id": "2507.15617v1",
      "title": "Why can't Epidemiology be automated (yet)?",
      "title_zh": "ä¸ºä»€ä¹ˆæµè¡Œç—…å­¦ï¼ˆç›®å‰ï¼‰è¿˜æ— æ³•å®ç°è‡ªåŠ¨åŒ–ï¼Ÿ",
      "authors": [
        "David Bann",
        "Ed Lowther",
        "Liam Wright",
        "Yevgeniya Kovalchuk"
      ],
      "abstract": "Recent advances in artificial intelligence (AI) - particularly generative AI - present new opportunities to accelerate, or even automate, epidemiological research. Unlike disciplines based on physical experimentation, a sizable fraction of Epidemiology relies on secondary data analysis and thus is well-suited for such augmentation. Yet, it remains unclear which specific tasks can benefit from AI interventions or where roadblocks exist. Awareness of current AI capabilities is also mixed. Here, we map the landscape of epidemiological tasks using existing datasets - from literature review to data access, analysis, writing up, and dissemination - and identify where existing AI tools offer efficiency gains. While AI can increase productivity in some areas such as coding and administrative tasks, its utility is constrained by limitations of existing AI models (e.g. hallucinations in literature reviews) and human systems (e.g. barriers to accessing datasets). Through examples of AI-generated epidemiological outputs, including fully AI-generated papers, we demonstrate that recently developed agentic systems can now design and execute epidemiological analysis, albeit to varied quality (see https://github.com/edlowther/automated-epidemiology). Epidemiologists have new opportunities to empirically test and benchmark AI systems; realising the potential of AI will require two-way engagement between epidemiologists and engineers.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰ï¼Œç‰¹åˆ«æ˜¯ç”Ÿæˆå¼AIï¼ˆGenerative AIï¼‰åœ¨è‡ªåŠ¨åŒ–æµè¡Œç—…å­¦ï¼ˆEpidemiologyï¼‰ç ”ç©¶ä¸­çš„æ½œåŠ›ä¸å±€é™æ€§ã€‚é€šè¿‡ç»˜åˆ¶æ¶µç›–æ–‡çŒ®ç»¼è¿°ï¼ˆLiterature Reviewï¼‰ã€æ•°æ®è®¿é—®ã€åˆ†æåŠæˆæœå‘å¸ƒç­‰ç¯èŠ‚çš„ä»»åŠ¡å›¾è°±ï¼Œæ–‡ç« è¯†åˆ«äº†AIå·¥å…·åœ¨æå‡æ•ˆç‡æ–¹é¢çš„å…·ä½“åº”ç”¨åœºæ™¯ã€‚ç ”ç©¶æŒ‡å‡ºï¼Œè™½ç„¶AIåœ¨ä»£ç ç¼–å†™ï¼ˆCodingï¼‰å’Œè¡Œæ”¿ä»»åŠ¡ä¸­èƒ½æ˜¾è‘—æé«˜ç”Ÿäº§åŠ›ï¼Œä¸”æ–°å…´çš„æ™ºèƒ½ä½“ç³»ç»Ÿï¼ˆAgentic Systemsï¼‰å·²å±•ç¤ºå‡ºè‡ªä¸»è®¾è®¡å¹¶æ‰§è¡Œæµè¡Œç—…å­¦åˆ†æçš„èƒ½åŠ›ï¼Œä½†äº§å‡ºè´¨é‡ä»å­˜åœ¨å·®å¼‚ã€‚ç›®å‰AIçš„åº”ç”¨ä»å—é™äºæ¨¡å‹å¹»è§‰ï¼ˆHallucinationsï¼‰ä»¥åŠäººç±»ç¤¾ä¼šç³»ç»Ÿä¸­çš„æ•°æ®è®¿é—®å£å’ã€‚ä½œè€…æœ€åå¼ºè°ƒï¼Œè¦å®ç°AIåœ¨æµè¡Œç—…å­¦é¢†åŸŸçš„å…¨é¢æ½œåŠ›ï¼Œéœ€è¦æµè¡Œç—…å­¦å®¶ä¸å·¥ç¨‹å¸ˆè¿›è¡ŒåŒå‘åä½œï¼Œå¹¶å¯¹AIç³»ç»Ÿè¿›è¡ŒæŒç»­çš„å®è¯æµ‹è¯•ä¸åŸºå‡†æµ‹è¯•ï¼ˆBenchmarkingï¼‰ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "9 pages, 2 figures, 1 table",
      "pdf_url": "https://arxiv.org/pdf/2507.15617v1",
      "published_date": "2025-07-21 13:41:52 UTC",
      "updated_date": "2025-07-21 13:41:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:58:55.792321+00:00"
    },
    {
      "arxiv_id": "2507.15614v1",
      "title": "Accelerating HEC-RAS: A Recurrent Neural Operator for Rapid River Forecasting",
      "title_zh": "åŠ é€Ÿ HEC-RASï¼šä¸€ç§ç”¨äºå¿«é€Ÿæ²³æµé¢„æŠ¥çš„å¾ªç¯ç¥ç»ç®—å­",
      "authors": [
        "Edward Holmberg",
        "Pujan Pokhrel",
        "Maximilian Zoch",
        "Elias Ioup",
        "Ken Pathak",
        "Steven Sloan",
        "Kendall Niles",
        "Jay Ratcliff",
        "Maik Flanagin",
        "Christian Guetl",
        "Julian Simeonov",
        "Mahdi Abdelguerfi"
      ],
      "abstract": "Physics-based solvers like HEC-RAS provide high-fidelity river forecasts but are too computationally intensive for on-the-fly decision-making during flood events. The central challenge is to accelerate these simulations without sacrificing accuracy. This paper introduces a deep learning surrogate that treats HEC-RAS not as a solver but as a data-generation engine. We propose a hybrid, auto-regressive architecture that combines a Gated Recurrent Unit (GRU) to capture short-term temporal dynamics with a Geometry-Aware Fourier Neural Operator (Geo-FNO) to model long-range spatial dependencies along a river reach. The model learns underlying physics implicitly from a minimal eight-channel feature vector encoding dynamic state, static geometry, and boundary forcings extracted directly from native HEC-RAS files. Trained on 67 reaches of the Mississippi River Basin, the surrogate was evaluated on a year-long, unseen hold-out simulation. Results show the model achieves a strong predictive accuracy, with a median absolute stage error of 0.31 feet. Critically, for a full 67-reach ensemble forecast, our surrogate reduces the required wall-clock time from 139 minutes to 40 minutes, a speedup of nearly 3.5 times over the traditional solver. The success of this data-driven approach demonstrates that robust feature engineering can produce a viable, high-speed replacement for conventional hydraulic models, improving the computational feasibility of large-scale ensemble flood forecasting.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŸºäºç‰©ç†çš„æ±‚è§£å™¨ HEC-RAS åœ¨æ´ªæ°´é¢„æŠ¥ä¸­è®¡ç®—è€—æ—¶è¿‡é•¿ã€éš¾ä»¥æ»¡è¶³å®æ—¶å†³ç­–éœ€æ±‚çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§æ·±åº¦å­¦ä¹ ä»£ç†æ¨¡å‹ã€‚è¯¥æ¨¡å‹é‡‡ç”¨æ··åˆè‡ªå›å½’æ¶æ„ï¼Œç»“åˆäº†ç”¨äºæ•æ‰çŸ­æœŸæ—¶é—´åŠ¨æ€çš„ Gated Recurrent Unit (GRU) å’Œç”¨äºå»ºæ¨¡æ²³æµæ²³æ®µé•¿ç¨‹ç©ºé—´ä¾èµ–æ€§çš„ Geometry-Aware Fourier Neural Operator (Geo-FNO)ã€‚é€šè¿‡ç›´æ¥ä»åŸç”Ÿ HEC-RAS æ–‡ä»¶ä¸­æå–åŠ¨æ€çŠ¶æ€ã€é™æ€å‡ ä½•å’Œè¾¹ç•Œå¼ºè¿«å¹¶ç¼–ç ä¸ºå…«é€šé“ç‰¹å¾å‘é‡ï¼Œè¯¥æ¨¡å‹èƒ½å¤Ÿéšå¼åœ°å­¦ä¹ æ½œåœ¨çš„ç‰©ç†è§„å¾‹ã€‚åœ¨å¯†è¥¿è¥¿æ¯”æ²³æµåŸŸ 67 ä¸ªæ²³æ®µçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ¨¡å‹å…·æœ‰æé«˜çš„é¢„æµ‹ç²¾åº¦ï¼Œä¸­ä½ç»å¯¹æ°´ä½è¯¯å·®ä»…ä¸º 0.31 è‹±å°ºã€‚åœ¨ç³»ç»¼é¢„æŠ¥ä»»åŠ¡ä¸­ï¼Œè¯¥ä»£ç†æ¨¡å‹å°†è®¡ç®—æ—¶é—´ä» 139 åˆ†é’Ÿç¼©çŸ­è‡³ 40 åˆ†é’Ÿï¼Œå®ç°äº†è¿‘ 3.5 å€çš„åŠ é€Ÿã€‚è¿™ä¸€æ•°æ®é©±åŠ¨çš„æ–¹æ³•è¯æ˜ï¼Œåˆ©ç”¨ç¨³å¥çš„ç‰¹å¾å·¥ç¨‹å¯ä»¥æ„å»ºå‡ºé«˜æ•ˆçš„æ°´åŠ›æ¨¡å‹æ›¿ä»£æ–¹æ¡ˆï¼Œæ˜¾è‘—æå‡äº†å¤§è§„æ¨¡æ´ªæ°´é¢„æŠ¥çš„è®¡ç®—å¯è¡Œæ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 8 figures",
      "pdf_url": "https://arxiv.org/pdf/2507.15614v1",
      "published_date": "2025-07-21 13:38:54 UTC",
      "updated_date": "2025-07-21 13:38:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:58:59.094992+00:00"
    },
    {
      "arxiv_id": "2507.15613v1",
      "title": "Multi-Stage Prompt Inference Attacks on Enterprise LLM Systems",
      "title_zh": "é’ˆå¯¹ä¼ä¸šçº§å¤§è¯­è¨€æ¨¡å‹ç³»ç»Ÿçš„å¤šé˜¶æ®µæç¤ºè¯æ¨ç†æ”»å‡»",
      "authors": [
        "Andrii Balashov",
        "Olena Ponomarova",
        "Xiaohua Zhai"
      ],
      "abstract": "Large Language Models (LLMs) deployed in enterprise settings (e.g., as Microsoft 365 Copilot) face novel security challenges. One critical threat is prompt inference attacks: adversaries chain together seemingly benign prompts to gradually extract confidential data. In this paper, we present a comprehensive study of multi-stage prompt inference attacks in an enterprise LLM context. We simulate realistic attack scenarios where an attacker uses mild-mannered queries and indirect prompt injections to exploit an LLM integrated with private corporate data. We develop a formal threat model for these multi-turn inference attacks and analyze them using probability theory, optimization frameworks, and information-theoretic leakage bounds. The attacks are shown to reliably exfiltrate sensitive information from the LLM's context (e.g., internal SharePoint documents or emails), even when standard safety measures are in place.\n  We propose and evaluate defenses to counter such attacks, including statistical anomaly detection, fine-grained access control, prompt sanitization techniques, and architectural modifications to LLM deployment. Each defense is supported by mathematical analysis or experimental simulation. For example, we derive bounds on information leakage under differential privacy-based training and demonstrate an anomaly detection method that flags multi-turn attacks with high AUC. We also introduce an approach called \"spotlighting\" that uses input transformations to isolate untrusted prompt content, reducing attack success by an order of magnitude. Finally, we provide a formal proof of concept and empirical validation for a combined defense-in-depth strategy. Our work highlights that securing LLMs in enterprise settings requires moving beyond single-turn prompt filtering toward a holistic, multi-stage perspective on both attacks and defenses.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†ä¼ä¸šçº§ LLM ç³»ç»Ÿé¢ä¸´çš„å¤šé˜¶æ®µæç¤ºè¯æ¨ç†æ”»å‡» (Multi-Stage Prompt Inference Attacks)ï¼Œè¿™ç±»æ”»å‡»é€šè¿‡é“¾å¼è°ƒç”¨çœ‹ä¼¼æ— å®³çš„æç¤ºè¯æ¥é€æ­¥çªƒå– SharePoint æˆ–ç”µå­é‚®ä»¶ç­‰å†…éƒ¨ç¯å¢ƒä¸­çš„æœºå¯†æ•°æ®ã€‚ä½œè€…å»ºç«‹äº†ä¸€ä¸ªæ­£å¼çš„å¨èƒæ¨¡å‹ï¼Œåˆ©ç”¨æ¦‚ç‡è®ºã€ä¼˜åŒ–æ¡†æ¶å’Œä¿¡æ¯è®ºæ³„æ¼ç•Œé™ (Information-theoretic leakage bounds) å¯¹å¤šè½®æ¨ç†æ”»å‡»è¿›è¡Œäº†æ·±å…¥åˆ†æã€‚ç ”ç©¶å‘ç°ï¼Œå³ä½¿åœ¨ç°æœ‰çš„æ ‡å‡†å®‰å…¨æªæ–½ä¸‹ï¼Œæ”»å‡»è€…ä»èƒ½é€šè¿‡é—´æ¥æç¤ºè¯æ³¨å…¥ (Indirect prompt injections) å¯é åœ°æå–æ•æ„Ÿä¿¡æ¯ã€‚ä¸ºåº”å¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œè®ºæ–‡æå‡ºå¹¶è¯„ä¼°äº†å¤šç§é˜²å¾¡æœºåˆ¶ï¼ŒåŒ…æ‹¬ç»Ÿè®¡å¼‚å¸¸æ£€æµ‹ (Statistical anomaly detection)ã€ç»†ç²’åº¦è®¿é—®æ§åˆ¶ä»¥åŠåŸºäºå·®åˆ†éšç§ (Differential privacy) çš„é˜²å¾¡æ‰‹æ®µã€‚ç‰¹åˆ«åœ°ï¼Œç ”ç©¶å¼•å…¥äº†ä¸€ç§åä¸º \"spotlighting\" çš„æ–°æ–¹æ³•ï¼Œé€šè¿‡è¾“å…¥å˜æ¢éš”ç¦»ä¸å¯ä¿¡çš„æç¤ºå†…å®¹ï¼Œä»è€Œå°†æ”»å‡»æˆåŠŸç‡é™ä½äº†ä¸€ä¸ªæ•°é‡çº§ã€‚å®éªŒéªŒè¯å’Œå½¢å¼åŒ–è¯æ˜è¡¨æ˜ï¼Œä¼ä¸šçº§ LLM çš„å®‰å…¨ä¿éšœå¿…é¡»è¶…è¶Šå•è½®æç¤ºè¿‡æ»¤ï¼Œè½¬å‘é’ˆå¯¹æ”»å‡»ä¸é˜²å¾¡çš„å…¨é¢ã€å¤šé˜¶æ®µè§†è§’ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "26 pages",
      "pdf_url": "https://arxiv.org/pdf/2507.15613v1",
      "published_date": "2025-07-21 13:38:12 UTC",
      "updated_date": "2025-07-21 13:38:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:59:06.486151+00:00"
    },
    {
      "arxiv_id": "2507.15587v1",
      "title": "Red-Team Multi-Agent Reinforcement Learning for Emergency Braking Scenario",
      "title_zh": "é¢å‘ç´§æ€¥åˆ¶åŠ¨åœºæ™¯çš„çº¢é˜Ÿå¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ",
      "authors": [
        "Yinsong Chen",
        "Kaifeng Wang",
        "Xiaoqiang Meng",
        "Xueyuan Li",
        "Zirui Li",
        "Xin Gao"
      ],
      "abstract": "Current research on decision-making in safety-critical scenarios often relies on inefficient data-driven scenario generation or specific modeling approaches, which fail to capture corner cases in real-world contexts. To address this issue, we propose a Red-Team Multi-Agent Reinforcement Learning framework, where background vehicles with interference capabilities are treated as red-team agents. Through active interference and exploration, red-team vehicles can uncover corner cases outside the data distribution. The framework uses a Constraint Graph Representation Markov Decision Process, ensuring that red-team vehicles comply with safety rules while continuously disrupting the autonomous vehicles (AVs). A policy threat zone model is constructed to quantify the threat posed by red-team vehicles to AVs, inducing more extreme actions to increase the danger level of the scenario. Experimental results show that the proposed framework significantly impacts AVs decision-making safety and generates various corner cases. This method also offers a novel direction for research in safety-critical scenarios.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è‡ªåŠ¨é©¾é©¶å®‰å…¨å…³é”®åœºæ™¯ä¸­æ•°æ®é©±åŠ¨åœºæ™¯ç”Ÿæˆæ•ˆç‡ä½ä¸‹ä¸”éš¾ä»¥æ•æ‰ç°å®æç«¯æ¡ˆä¾‹(corner cases)çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§Red-Team Multi-Agent Reinforcement Learningæ¡†æ¶ã€‚è¯¥æ¡†æ¶å°†å…·æœ‰å¹²æ‰°èƒ½åŠ›çš„èƒŒæ™¯è½¦è¾†å»ºæ¨¡ä¸ºçº¢é˜Ÿæ™ºèƒ½ä½“(red-team agents)ï¼Œé€šè¿‡ä¸»åŠ¨å¹²æ‰°ä¸æ¢ç´¢æ¥æŒ–æ˜æ•°æ®åˆ†å¸ƒä¹‹å¤–çš„æç«¯æƒ…å†µã€‚æŠ€æœ¯ä¸Šé‡‡ç”¨äº†Constraint Graph Representation Markov Decision Processï¼Œåœ¨ç¡®ä¿çº¢é˜Ÿè½¦è¾†éµå¾ªåŸºç¡€å®‰å…¨è§„åˆ™çš„åŒæ—¶ï¼Œå®ç°å¯¹è‡ªåŠ¨é©¾é©¶è½¦è¾†(AVs)çš„æŒç»­å¹²æ‰°ã€‚ç ”ç©¶è¿˜æ„å»ºäº†ç­–ç•¥å¨èƒåŒºåŸŸæ¨¡å‹(policy threat zone model)ä»¥é‡åŒ–å¨èƒç¨‹åº¦ï¼Œè¯±å¯¼å—è¯•è½¦è¾†äº§ç”Ÿæ›´æç«¯çš„ååº”å¹¶æ˜¾è‘—æå‡åœºæ™¯çš„å±é™©ç­‰çº§ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•èƒ½æœ‰æ•ˆå½±å“è‡ªåŠ¨é©¾é©¶å†³ç­–å®‰å…¨æ€§å¹¶ç”Ÿæˆå¤šæ ·åŒ–çš„æç«¯æ¡ˆä¾‹ï¼Œä¸ºå®‰å…¨å…³é”®åœºæ™¯çš„ä»¿çœŸç ”ç©¶æä¾›äº†æ–°é¢–çš„ç ”ç©¶è·¯å¾„ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.15587v1",
      "published_date": "2025-07-21 13:08:49 UTC",
      "updated_date": "2025-07-21 13:08:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:59:12.989184+00:00"
    },
    {
      "arxiv_id": "2507.15585v1",
      "title": "Unequal Voices: How LLMs Construct Constrained Queer Narratives",
      "title_zh": "ä¸å¹³ç­‰çš„å‘å£°ï¼šå¤§è¯­è¨€æ¨¡å‹å¦‚ä½•æ„å»ºå—é™çš„é…·å„¿å™äº‹",
      "authors": [
        "Atreya Ghosal",
        "Ashim Gupta",
        "Vivek Srikumar"
      ],
      "abstract": "One way social groups are marginalized in discourse is that the narratives told about them often default to a narrow, stereotyped range of topics. In contrast, default groups are allowed the full complexity of human existence. We describe the constrained representations of queer people in LLM generations in terms of harmful representations, narrow representations, and discursive othering and formulate hypotheses to test for these phenomena. Our results show that LLMs are significantly limited in their portrayals of queer personas.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æ„å»ºé…·å„¿ï¼ˆQueerï¼‰å™äº‹ä¸­çš„ä¸å¹³ç­‰ç°è±¡ï¼ŒæŒ‡å‡ºè¾¹ç¼˜åŒ–ç¤¾ä¼šç¾¤ä½“çš„å™è¿°å¾€å¾€é™·å…¥ç‹­éš˜ä¸”åˆ»æ¿çš„ç‰¹å®šè¯é¢˜ã€‚ä½œè€…é€šè¿‡æœ‰å®³è¡¨å¾ï¼ˆHarmful Representationsï¼‰ã€ç‹­éš˜è¡¨å¾ï¼ˆNarrow Representationsï¼‰å’Œè¯è¯­æ’æ–¥ï¼ˆDiscursive Otheringï¼‰ä¸‰ä¸ªç»´åº¦ï¼Œç³»ç»Ÿæè¿°äº† LLMs ç”Ÿæˆå†…å®¹ä¸­å¯¹ Queer ç¾¤ä½“çš„å—é™å‘ˆç°ï¼Œå¹¶æ®æ­¤åˆ¶å®šäº†ä¸¥è°¨çš„æµ‹è¯•å‡è®¾ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒLLMs åœ¨æç»˜ Queer è§’è‰²å½¢è±¡æ—¶å­˜åœ¨æ˜¾è‘—å±€é™ï¼Œæœªèƒ½å±•ç°å‡ºé»˜è®¤ç¾¤ä½“æ‰€äº«æœ‰çš„å¤æ‚å®Œæ•´çš„äººæ€§ç»´åº¦ã€‚è¿™ä¸€å‘ç°æ­ç¤ºäº†å½“å‰æ¨¡å‹åœ¨å¤„ç†å¤šå…ƒæ–‡åŒ–å™äº‹æ—¶çš„ç³»ç»Ÿæ€§ç¼ºå¤±ï¼Œä¸ºç†è§£ç®—æ³•åè§åŠå…¶å¯¹è¾¹ç¼˜ç¾¤ä½“çš„ç¤¾ä¼šå½±å“æä¾›äº†é‡è¦è§è§£ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.15585v1",
      "published_date": "2025-07-21 13:03:38 UTC",
      "updated_date": "2025-07-21 13:03:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:59:13.287738+00:00"
    },
    {
      "arxiv_id": "2507.15581v1",
      "title": "Metric assessment protocol in the context of answer fluctuation on MCQ tasks",
      "title_zh": "é’ˆå¯¹å¤šé€‰é¢˜ä»»åŠ¡ä¸­ç­”æ¡ˆæ³¢åŠ¨çš„æŒ‡æ ‡è¯„ä¼°åè®®",
      "authors": [
        "Ekaterina Goliakova",
        "Xavier Renard",
        "Marie-Jeanne Lesot",
        "Thibault Laugel",
        "Christophe Marsala",
        "Marcin Detyniecki"
      ],
      "abstract": "Using multiple-choice questions (MCQs) has become a standard for assessing LLM capabilities efficiently. A variety of metrics can be employed for this task. However, previous research has not conducted a thorough assessment of them. At the same time, MCQ evaluation suffers from answer fluctuation: models produce different results given slight changes in prompts. We suggest a metric assessment protocol in which evaluation methodologies are analyzed through their connection with fluctuation rates, as well as original performance. Our results show that there is a strong link between existing metrics and the answer changing, even when computed without any additional prompt variants. A novel metric, worst accuracy, demonstrates the highest association on the protocol.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤šé¡¹é€‰æ‹©é¢˜ï¼ˆMCQsï¼‰è¯„ä¼°ä¸­å› æç¤ºè¯å¾®å°å˜åŒ–è€Œå¯¼è‡´çš„ç­”æ¡ˆæ³¢åŠ¨ï¼ˆanswer fluctuationï¼‰ç°è±¡è¿›è¡Œäº†æ·±å…¥æ¢è®¨ã€‚ä½œè€…æå‡ºäº†ä¸€ç§æŒ‡æ ‡è¯„ä¼°åè®®ï¼ˆmetric assessment protocolï¼‰ï¼Œæ—¨åœ¨é€šè¿‡åˆ†æè¯„ä¼°æ–¹æ³•ä¸æ³¢åŠ¨ç‡ä»¥åŠåŸå§‹æ€§èƒ½ä¹‹é—´çš„å…³è”ï¼Œå¯¹ç°æœ‰çš„è¯„ä¼°æ•ˆåŠ›è¿›è¡Œç³»ç»ŸåŒ–åˆ†æã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œç°æœ‰çš„è¯„ä»·æŒ‡æ ‡ä¸æ¨¡å‹ç­”æ¡ˆçš„å˜åŠ¨ä¹‹é—´å­˜åœ¨æ˜¾è‘—è”ç³»ï¼Œä¸”è¿™ç§è”ç³»åœ¨ä¸ä½¿ç”¨é¢å¤–æç¤ºå˜ä½“çš„æƒ…å†µä¸‹ä¾ç„¶æˆç«‹ã€‚ç ”ç©¶è¿›ä¸€æ­¥æå‡ºäº†ä¸€ç§åä¸ºæœ€å·®å‡†ç¡®ç‡ï¼ˆworst accuracyï¼‰çš„æ–°å‹æŒ‡æ ‡ï¼Œè¯¥æŒ‡æ ‡åœ¨æ‰€æåè®®ä¸­è¡¨ç°å‡ºæœ€é«˜çš„ç›¸å…³æ€§ã€‚è¯¥ç ”ç©¶ä¸ºä¼˜åŒ–LLMåœ¨MCQä»»åŠ¡ä¸­çš„è¯„ä¼°ç¨³å¥æ€§æä¾›äº†æ–°çš„è§†è§’å’Œå®ç”¨å·¥å…·ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.15581v1",
      "published_date": "2025-07-21 13:01:46 UTC",
      "updated_date": "2025-07-21 13:01:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:59:26.103088+00:00"
    },
    {
      "arxiv_id": "2507.15577v2",
      "title": "GeMix: Conditional GAN-Based Mixup for Improved Medical Image Augmentation",
      "title_zh": "GeMixï¼šåŸºäºæ¡ä»¶ GAN çš„ Mixup æ”¹è¿›åŒ»å­¦å›¾åƒå¢å¼º",
      "authors": [
        "Hugo Carlesso",
        "Maria Eliza Patulea",
        "Moncef Garouani",
        "Radu Tudor Ionescu",
        "Josiane Mothe"
      ],
      "abstract": "Mixup has become a popular augmentation strategy for image classification, yet its naive pixel-wise interpolation often produces unrealistic images that can hinder learning, particularly in high-stakes medical applications. We propose GeMix, a two-stage framework that replaces heuristic blending with a learned, label-aware interpolation powered by class-conditional GANs. First, a StyleGAN2-ADA generator is trained on the target dataset. During augmentation, we sample two label vectors from Dirichlet priors biased toward different classes and blend them via a Beta-distributed coefficient. Then, we condition the generator on this soft label to synthesize visually coherent images that lie along a continuous class manifold. We benchmark GeMix on the large-scale COVIDx-CT-3 dataset using three backbones (ResNet-50, ResNet-101, EfficientNet-B0). When combined with real data, our method increases macro-F1 over traditional mixup for all backbones, reducing the false negative rate for COVID-19 detection. GeMix is thus a drop-in replacement for pixel-space mixup, delivering stronger regularization and greater semantic fidelity, without disrupting existing training pipelines. We publicly release our code at https://github.com/hugocarlesso/GeMix to foster reproducibility and further research.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† GeMixï¼Œä¸€ç§åŸºäºç±»åˆ«æ¡ä»¶ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆclass-conditional GANsï¼‰çš„ä¸¤é˜¶æ®µæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ä¼ ç»Ÿ Mixup ç­–ç•¥å› åƒç´ çº§æ’å€¼äº§ç”Ÿä¸åˆ‡å®é™…å›¾åƒè€Œé™åˆ¶åŒ»ç–—å½±åƒå­¦ä¹ çš„é—®é¢˜ã€‚GeMix åˆ©ç”¨è®­ç»ƒå¥½çš„ StyleGAN2-ADA ç”Ÿæˆå™¨ï¼Œé€šè¿‡ç‹„åˆ©å…‹é›·å…ˆéªŒï¼ˆDirichlet priorsï¼‰å’Œè´å¡”åˆ†å¸ƒç³»æ•°ï¼ˆBeta-distributed coefficientï¼‰å¯¹æ ‡ç­¾å‘é‡è¿›è¡Œèåˆã€‚è¿™ç§æ–¹æ³•ä½¿ç”Ÿæˆå™¨èƒ½å¤Ÿåˆæˆè§†è§‰è¿è´¯ä¸”ä½äºè¿ç»­ç±»åˆ«æµå½¢ä¸Šçš„å›¾åƒï¼Œæ˜¾è‘—æå‡äº†å¢å¼ºæ•°æ®çš„è¯­ä¹‰ä¿çœŸåº¦ã€‚åœ¨å¤§å‹æ•°æ®é›† COVIDx-CT-3 ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒGeMix åœ¨ ResNet-50ã€ResNet-101 å’Œ EfficientNet-B0 ç­‰å¤šç§éª¨å¹²ç½‘ç»œä¸Šçš„ macro-F1 æŒ‡æ ‡å‡ä¼˜äºä¼ ç»Ÿ mixupã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•æœ‰æ•ˆé™ä½äº†æ–°å† è‚ºç‚æ£€æµ‹çš„å‡é˜´æ€§ç‡ï¼Œè¯æ˜äº†å…¶åœ¨åŒ»ç–—è¯Šæ–­ä»»åŠ¡ä¸­çš„å®ç”¨ä»·å€¼ã€‚ä½œä¸ºä¸€ç§å¯å³æ’å³ç”¨çš„å¢å¼ºæ‰‹æ®µï¼ŒGeMix åœ¨ä¸æ”¹å˜ç°æœ‰è®­ç»ƒæµç¨‹çš„å‰æä¸‹ï¼Œä¸ºé«˜é£é™©åŒ»ç–—åº”ç”¨æä¾›äº†æ›´å¼ºçš„æ­£åˆ™åŒ–æ•ˆæœã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at CBMI 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.15577v2",
      "published_date": "2025-07-21 12:58:05 UTC",
      "updated_date": "2025-09-25 13:48:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:59:50.854200+00:00"
    },
    {
      "arxiv_id": "2507.15574v1",
      "title": "On the Role of AI in Managing Satellite Constellations: Insights from the ConstellAI Project",
      "title_zh": "äººå·¥æ™ºèƒ½åœ¨å«æ˜Ÿæ˜Ÿåº§ç®¡ç†ä¸­çš„ä½œç”¨ï¼šæ¥è‡ª ConstellAI é¡¹ç›®çš„å¯ç¤º",
      "authors": [
        "Gregory F. Stock",
        "Juan A. Fraire",
        "Holger Hermanns",
        "JÄ™drzej MosiÄ™Å¼ny",
        "Yusra Al-Khazraji",
        "Julio RamÃ­rez Molina",
        "Evridiki V. Ntagiou"
      ],
      "abstract": "The rapid expansion of satellite constellations in near-Earth orbits presents significant challenges in satellite network management, requiring innovative approaches for efficient, scalable, and resilient operations. This paper explores the role of Artificial Intelligence (AI) in optimizing the operation of satellite mega-constellations, drawing from the ConstellAI project funded by the European Space Agency (ESA). A consortium comprising GMV GmbH, Saarland University, and Thales Alenia Space collaborates to develop AI-driven algorithms and demonstrates their effectiveness over traditional methods for two crucial operational challenges: data routing and resource allocation. In the routing use case, Reinforcement Learning (RL) is used to improve the end-to-end latency by learning from historical queuing latency, outperforming classical shortest path algorithms. For resource allocation, RL optimizes the scheduling of tasks across constellations, focussing on efficiently using limited resources such as battery and memory. Both use cases were tested for multiple satellite constellation configurations and operational scenarios, resembling the real-life spacecraft operations of communications and Earth observation satellites. This research demonstrates that RL not only competes with classical approaches but also offers enhanced flexibility, scalability, and generalizability in decision-making processes, which is crucial for the autonomous and intelligent management of satellite fleets. The findings of this activity suggest that AI can fundamentally alter the landscape of satellite constellation management by providing more adaptive, robust, and cost-effective solutions.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†äººå·¥æ™ºèƒ½(AI)åœ¨ä¼˜åŒ–è¿‘åœ°è½¨é“å«æ˜Ÿå·¨å‹æ˜Ÿåº§(satellite mega-constellations)ç®¡ç†ä¸­çš„å…³é”®ä½œç”¨ï¼Œå¹¶åˆ†äº«äº†æ¬§æ´²èˆªå¤©å±€(ESA)èµ„åŠ©çš„ConstellAIé¡¹ç›®çš„æ ¸å¿ƒæˆæœã€‚é’ˆå¯¹æ•°æ®è·¯ç”±(data routing)æŒ‘æˆ˜ï¼Œé¡¹ç›®é‡‡ç”¨å¼ºåŒ–å­¦ä¹ (Reinforcement Learning)ç®—æ³•é€šè¿‡å†å²å»¶è¿Ÿæ•°æ®è¿›è¡Œå­¦ä¹ ï¼Œå®ç°äº†ä¼˜äºä¼ ç»Ÿæœ€çŸ­è·¯å¾„ç®—æ³•çš„ç«¯åˆ°ç«¯å»¶è¿Ÿè¡¨ç°ã€‚åœ¨èµ„æºåˆ†é…(resource allocation)ç”¨ä¾‹ä¸­ï¼Œå¼ºåŒ–å­¦ä¹ ä¼˜åŒ–äº†è·¨æ˜Ÿåº§çš„ä»»åŠ¡è°ƒåº¦ï¼Œæ˜¾è‘—æå‡äº†ç”µæ± å’Œå­˜å‚¨ç­‰æœ‰é™èµ„æºçš„åˆ©ç”¨ç‡ã€‚ç ”ç©¶å›¢é˜Ÿåœ¨æ¨¡æ‹Ÿé€šä¿¡åŠåœ°çƒè§‚æµ‹å«æ˜Ÿ(Earth observation satellites)çš„çœŸå®è¿è¥åœºæ™¯ä¸­éªŒè¯äº†ç®—æ³•çš„æœ‰æ•ˆæ€§ã€‚å®éªŒè¯æ˜ï¼Œå¼ºåŒ–å­¦ä¹ åœ¨å†³ç­–è¿‡ç¨‹ä¸­å…·å¤‡æ›´å¼ºçš„çµæ´»æ€§(flexibility)ã€å¯æ‰©å±•æ€§(scalability)å’Œæ³›åŒ–èƒ½åŠ›ï¼Œèƒ½å¤Ÿä¸ºå«æ˜Ÿæ˜Ÿåº§çš„è‡ªä¸»åŒ–ç®¡ç†æä¾›æ›´å…·ç¨³å¥æ€§å’Œæˆæœ¬æ•ˆç›Šçš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "18th International Conference on Space Operations (SpaceOps 2025), MontrÃ©al, Canada, 26-30 May 2025, https://star.spaceops.org/2025/user_manudownload.php?doc=140__9bg48dkf.pdf",
      "pdf_url": "https://arxiv.org/pdf/2507.15574v1",
      "published_date": "2025-07-21 12:56:16 UTC",
      "updated_date": "2025-07-21 12:56:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:59:43.456114+00:00"
    },
    {
      "arxiv_id": "2507.15906v1",
      "title": "Towards Reliable, Uncertainty-Aware Alignment",
      "title_zh": "è¿ˆå‘å¯é ä¸”æ„ŸçŸ¥ä¸ç¡®å®šæ€§çš„å¯¹é½",
      "authors": [
        "Debangshu Banerjee",
        "Kintan Saha",
        "Aditya Gopalan"
      ],
      "abstract": "Alignment of large language models (LLMs) typically involves training a reward model on preference data, followed by policy optimization with respect to the reward model. However, optimizing policies with respect to a single reward model estimate can render it vulnerable to inaccuracies in the reward model. We empirically study the variability of reward model training on open-source benchmarks. We observe that independently trained reward models on the same preference dataset can exhibit substantial disagreement, highlighting the instability of current alignment strategies. Employing a theoretical model, we demonstrate that variability in reward model estimation can cause overfitting, leading to the risk of performance degradation. To mitigate this risk, we propose a variance-aware policy optimization framework for preference-based alignment. The key ingredient of the framework is a new policy regularizer that incorporates reward model variance estimates. We show that variance-aware policy optimization provably reduces the risk of outputting a worse policy than the default. Experiments across diverse LLM and reward model configurations confirm that our approach yields more stable and robust alignment than the standard (variance-unaware) pipeline.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å¯¹é½è¿‡ç¨‹ä¸­å¥–åŠ±æ¨¡å‹ï¼ˆReward Modelï¼‰çš„ä¸ç¡®å®šæ€§ä¸å¯é æ€§é—®é¢˜ã€‚ä½œè€…å‘ç°ï¼Œåœ¨ç›¸åŒåå¥½æ•°æ®é›†ä¸Šç‹¬ç«‹è®­ç»ƒçš„å¥–åŠ±æ¨¡å‹å¾€å¾€å­˜åœ¨æ˜¾è‘—çš„ä¸ä¸€è‡´æ€§ï¼Œè¿™ç§ä¸ç¨³å®šæ€§ä¼šå¯¼è‡´ç­–ç•¥ä¼˜åŒ–æ—¶äº§ç”Ÿè¿‡æ‹ŸåˆåŠæ€§èƒ½ä¸‹é™çš„é£é™©ã€‚ä¸ºæ­¤ï¼Œè®ºæ–‡æå‡ºäº†ä¸€ä¸ªæ–¹å·®æ„ŸçŸ¥ï¼ˆVariance-Awareï¼‰çš„ç­–ç•¥ä¼˜åŒ–æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒæ˜¯å¼•å…¥äº†ä¸€ç§ç»“åˆå¥–åŠ±æ¨¡å‹æ–¹å·®ä¼°è®¡çš„æ–°å‹ç­–ç•¥æ­£åˆ™åŒ–é¡¹ï¼ˆPolicy Regularizerï¼‰ã€‚ç†è®ºåˆ†æè¯æ˜ï¼Œè¯¥æ¡†æ¶èƒ½æœ‰æ•ˆé™ä½ç”Ÿæˆæ¯”é»˜è®¤ç­–ç•¥æ›´å·®ç»“æœçš„é£é™©ã€‚åœ¨å¤šç§æ¨¡å‹é…ç½®ä¸‹çš„å®éªŒè¯å®ï¼Œè¯¥æ–¹æ³•æ¯”æ ‡å‡†çš„æ–¹å·®æ— å…³ï¼ˆVariance-Unawareï¼‰æµç¨‹åœ¨å¯¹é½ç¨³å®šæ€§ä¸é²æ£’æ€§æ–¹é¢å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.15906v1",
      "published_date": "2025-07-21 12:51:29 UTC",
      "updated_date": "2025-07-21 12:51:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:59:45.822059+00:00"
    },
    {
      "arxiv_id": "2507.15550v2",
      "title": "PhysGym: Benchmarking LLMs in Interactive Physics Discovery with Controlled Priors",
      "title_zh": "PhysGymï¼šå—æ§å…ˆéªŒä¸‹äº¤äº’å¼ç‰©ç†å‘ç°çš„å¤§è¯­è¨€æ¨¡å‹åŸºå‡†æµ‹è¯•",
      "authors": [
        "Yimeng Chen",
        "Piotr PiÈ©kos",
        "Mateusz Ostaszewski",
        "Firas Laakom",
        "JÃ¼rgen Schmidhuber"
      ],
      "abstract": "Evaluating the scientific discovery capabilities of large language model based agents, particularly how they cope with varying environmental complexity and utilize prior knowledge, requires specialized benchmarks currently lacking in the landscape. To address this gap, we introduce \\textsc{PhysGym}, a novel benchmark suite and simulation platform for rigorously assessing LLM-based scientific reasoning in interactive physics environments. \\textsc{PhysGym}'s primary contribution lies in its sophisticated control over the level of prior knowledge provided to the agent. This allows researchers to dissect agent performance along axes including the complexity of the problem and the prior knowledge levels. The benchmark comprises a suite of interactive simulations, where agents must actively probe environments, gather data sequentially under constraints and formulate hypotheses about underlying physical laws. \\textsc{PhysGym} provides standardized evaluation protocols and metrics for assessing hypothesis accuracy and model fidelity. We demonstrate the benchmark's utility by presenting results from baseline LLMs, showcasing its ability to differentiate capabilities based on varying priors and task complexity.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº† PhysGymï¼Œè¿™æ˜¯ä¸€ä¸ªå…¨æ–°çš„åŸºå‡†æµ‹è¯•å¥—ä»¶å’Œæ¨¡æ‹Ÿå¹³å°ï¼Œæ—¨åœ¨ä¸¥æ ¼è¯„ä¼° Large Language Model (LLM) åœ¨äº¤äº’å¼ç‰©ç†ç¯å¢ƒä¸­çš„ç§‘å­¦æ¨ç†èƒ½åŠ›ã€‚PhysGym çš„æ ¸å¿ƒè´¡çŒ®åœ¨äºå…¶å¯¹æä¾›ç»™æ™ºèƒ½ä½“çš„å…ˆéªŒçŸ¥è¯† (prior knowledge) æ°´å¹³è¿›è¡Œäº†ç²¾ç»†åŒ–æ§åˆ¶ï¼Œä½¿ç ”ç©¶äººå‘˜èƒ½å¤Ÿä»é—®é¢˜å¤æ‚åº¦å’Œå…ˆéªŒçŸ¥è¯†æ°´å¹³ç­‰ç»´åº¦å‰–ææ™ºèƒ½ä½“è¡¨ç°ã€‚è¯¥åŸºå‡†åŒ…å«ä¸€ç³»åˆ—äº¤äº’å¼æ¨¡æ‹Ÿï¼Œè¦æ±‚æ™ºèƒ½ä½“åœ¨çº¦æŸæ¡ä»¶ä¸‹ä¸»åŠ¨æ¢æµ‹ç¯å¢ƒã€æŒ‰åºæ”¶é›†æ•°æ®å¹¶é’ˆå¯¹åº•å±‚ç‰©ç†è§„å¾‹æå‡ºå‡è®¾ã€‚PhysGym æä¾›äº†æ ‡å‡†åŒ–çš„è¯„ä¼°åè®®å’ŒæŒ‡æ ‡ï¼Œç”¨äºè¡¡é‡å‡è®¾çš„å‡†ç¡®æ€§å’Œæ¨¡å‹çš„ä¿çœŸåº¦ (fidelity)ã€‚é€šè¿‡å¯¹åŸºå‡† LLM çš„æµ‹è¯•ç»“æœè¡¨æ˜ï¼Œè¯¥å¹³å°èƒ½å¤Ÿæ ¹æ®ä¸åŒçš„å…ˆéªŒçŸ¥è¯†å’Œä»»åŠ¡å¤æ‚åº¦æœ‰æ•ˆåŒºåˆ†æ¨¡å‹èƒ½åŠ›ï¼Œä¸ºç ”ç©¶ç§‘å­¦å‘ç°è¿‡ç¨‹ä¸­çš„æ™ºèƒ½ä½“è¡¨ç°æä¾›äº†é‡è¦å·¥å…·ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.soc-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "31 Pages",
      "pdf_url": "https://arxiv.org/pdf/2507.15550v2",
      "published_date": "2025-07-21 12:28:10 UTC",
      "updated_date": "2025-10-26 07:14:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:59:56.027056+00:00"
    },
    {
      "arxiv_id": "2507.15905v1",
      "title": "Foundation Models and Transformers for Anomaly Detection: A Survey",
      "title_zh": "åŸºç¡€æ¨¡å‹ä¸ Transformer åœ¨å¼‚å¸¸æ£€æµ‹ä¸­çš„åº”ç”¨ï¼šç»¼è¿°",
      "authors": [
        "MouÃ¯n Ben Ammar",
        "Arturo Mendoza",
        "Nacim Belkhir",
        "Antoine Manzanera",
        "Gianni Franchi"
      ],
      "abstract": "In line with the development of deep learning, this survey examines the transformative role of Transformers and foundation models in advancing visual anomaly detection (VAD). We explore how these architectures, with their global receptive fields and adaptability, address challenges such as long-range dependency modeling, contextual modeling and data scarcity. The survey categorizes VAD methods into reconstruction-based, feature-based and zero/few-shot approaches, highlighting the paradigm shift brought about by foundation models. By integrating attention mechanisms and leveraging large-scale pre-training, Transformers and foundation models enable more robust, interpretable, and scalable anomaly detection solutions. This work provides a comprehensive review of state-of-the-art techniques, their strengths, limitations, and emerging trends in leveraging these architectures for VAD.",
      "tldr_zh": "è¿™ç¯‡ç»¼è¿°æ·±å…¥æ¢è®¨äº† Transformers å’ŒåŸºç¡€æ¨¡å‹ (Foundation Models) åœ¨è§†è§‰å¼‚å¸¸æ£€æµ‹ (Visual Anomaly Detection, VAD) é¢†åŸŸçš„å˜é©æ€§ä½œç”¨ã€‚ç ”ç©¶åˆ†æäº†è¿™äº›æ¶æ„å¦‚ä½•åˆ©ç”¨å…¶å…¨å±€æ„Ÿå—é‡ (global receptive fields) å’Œå“è¶Šçš„é€‚åº”æ€§ï¼Œæœ‰æ•ˆè§£å†³é•¿è·ç¦»ä¾èµ–å»ºæ¨¡ã€ä¸Šä¸‹æ–‡å»ºæ¨¡åŠæ•°æ®ç¨€ç¼ºç­‰å…³é”®æŒ‘æˆ˜ã€‚è¯¥ç»¼è¿°å°† VAD æ–¹æ³•ç³»ç»Ÿåˆ’åˆ†ä¸ºåŸºäºé‡æ„ (reconstruction-based)ã€åŸºäºç‰¹å¾ (feature-based) ä»¥åŠé›¶æ ·æœ¬/å°‘æ ·æœ¬ (zero/few-shot) ä¸‰å¤§ç±»ï¼Œé‡ç‚¹å¼ºè°ƒäº†åŸºç¡€æ¨¡å‹å¸¦æ¥çš„èŒƒå¼è½¬å˜ã€‚é€šè¿‡æ•´åˆæ³¨æ„åŠ›æœºåˆ¶ (attention mechanisms) å¹¶ç»“åˆå¤§è§„æ¨¡é¢„è®­ç»ƒ (large-scale pre-training)ï¼Œè¿™äº›æ¨¡å‹å®ç°äº†æ›´å…·é²æ£’æ€§ã€å¯è§£é‡Šæ€§å’Œå¯æ‰©å±•æ€§çš„å¼‚å¸¸æ£€æµ‹æ–¹æ¡ˆã€‚è¯¥å·¥ä½œä¸ä»…å…¨é¢å›é¡¾äº†æœ€å‰æ²¿çš„æŠ€æœ¯åŠå…¶ä¼˜ç¼ºç‚¹ï¼Œè¿˜æ­ç¤ºäº†åˆ©ç”¨è¿™äº›æ¶æ„è¿›è¡Œ VAD ç ”ç©¶çš„æ–°å…´è¶‹åŠ¿ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.15905v1",
      "published_date": "2025-07-21 12:01:04 UTC",
      "updated_date": "2025-07-21 12:01:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:00:07.393719+00:00"
    },
    {
      "arxiv_id": "2507.15532v2",
      "title": "Data-Efficient Safe Policy Improvement Using Parametric Structure",
      "title_zh": "åˆ©ç”¨å‚æ•°åŒ–ç»“æ„å®ç°æ•°æ®é«˜æ•ˆçš„å®‰å…¨ç­–ç•¥æ”¹è¿›",
      "authors": [
        "Kasper Engelen",
        "Guillermo A. PÃ©rez",
        "Marnix Suilen"
      ],
      "abstract": "Safe policy improvement (SPI) is an offline reinforcement learning problem in which a new policy that reliably outperforms the behavior policy with high confidence needs to be computed using only a dataset and the behavior policy. Markov decision processes (MDPs) are the standard formalism for modeling environments in SPI. In many applications, additional information in the form of parametric dependencies between distributions in the transition dynamics is available. We make SPI more data-efficient by leveraging these dependencies through three contributions: (1) a parametric SPI algorithm that exploits known correlations between distributions to more accurately estimate the transition dynamics using the same amount of data; (2) a preprocessing technique that prunes redundant actions from the environment through a game-based abstraction; and (3) a more advanced preprocessing technique, based on satisfiability modulo theory (SMT) solving, that can identify more actions to prune. Empirical results and an ablation study show that our techniques increase the data efficiency of SPI by multiple orders of magnitude while maintaining the same reliability guarantees.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç¦»çº¿å¼ºåŒ–å­¦ä¹ (Offline Reinforcement Learning)ä¸­çš„å®‰å…¨ç­–ç•¥æ”¹è¿›(Safe Policy Improvement, SPI)é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åˆ©ç”¨å‚æ•°åŒ–ç»“æ„æå‡æ•°æ®æ•ˆç‡çš„æ–°æ¡†æ¶ã€‚ç ”ç©¶è€…å¼€å‘äº†ä¸€ç§å‚æ•°åŒ– SPI ç®—æ³•ï¼Œé€šè¿‡æŒ–æ˜è½¬ç§»åŠ¨åŠ›å­¦(Transition Dynamics)åˆ†å¸ƒé—´çš„å·²çŸ¥ç›¸å…³æ€§ï¼Œæ˜¾è‘—æé«˜äº†æ¨¡å‹åœ¨æœ‰é™æ•°æ®ä¸‹çš„ä¼°è®¡ç²¾åº¦ã€‚åŒæ—¶ï¼Œç ”ç©¶å¼•å…¥äº†åŸºäºåšå¼ˆæŠ½è±¡(Game-based Abstraction)å’Œå¯æ»¡è¶³æ€§æ¨¡ç†è®º(Satisfiability Modulo Theory, SMT)æ±‚è§£çš„ä¸¤ç§é¢„å¤„ç†æŠ€æœ¯ï¼Œç”¨äºè¯†åˆ«å¹¶å‰ªé™¤ç¯å¢ƒä¸­çš„å†—ä½™åŠ¨ä½œã€‚å®éªŒç»“æœä¸æ¶ˆèç ”ç©¶è¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä¿æŒç›¸åŒå¯é æ€§ä¿è¯çš„å‰æä¸‹ï¼Œå°† SPI çš„æ•°æ®æ•ˆç‡æå‡äº†æ•°ä¸ªæ•°é‡çº§ã€‚è¿™ä¸€ç ”ç©¶ä¸ºåœ¨å‚æ•°åŒ–ä¾èµ–ç¯å¢ƒä¸‹å®ç°é«˜æ•ˆä¸”å®‰å…¨çš„ç­–ç•¥ä¼˜åŒ–æä¾›äº†é‡è¦çš„ç†è®ºæ”¯æ’‘ä¸å·¥ç¨‹å®è·µè·¯å¾„ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at ECAI 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.15532v2",
      "published_date": "2025-07-21 12:00:03 UTC",
      "updated_date": "2025-08-18 18:41:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T05:59:55.237503+00:00"
    },
    {
      "arxiv_id": "2508.05637v1",
      "title": "Automated Visualization Makeovers with LLMs",
      "title_zh": "åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„è‡ªåŠ¨åŒ–å¯è§†åŒ–ä¼˜åŒ–",
      "authors": [
        "Siddharth Gangwar",
        "David A. Selby",
        "Sebastian J. Vollmer"
      ],
      "abstract": "Making a good graphic that accurately and efficiently conveys the desired message to the audience is both an art and a science, typically not taught in the data science curriculum. Visualisation makeovers are exercises where the community exchange feedback to improve charts and data visualizations. Can multi-modal large language models (LLMs) emulate this task? Given a plot in the form of an image file, or the code used to generate it, an LLM, primed with a list of visualization best practices, is employed to semi-automatically generate constructive criticism to produce a better plot. Our system is centred around prompt engineering of a pre-trained model, relying on a combination of userspecified guidelines and any latent knowledge of data visualization practices that might lie within an LLMs training corpus. Unlike other works, the focus is not on generating valid visualization scripts from raw data or prompts, but on educating the user how to improve their existing data visualizations according to an interpretation of best practices. A quantitative evaluation is performed to measure the sensitivity of the LLM agent to various plotting issues across different chart types. We make the tool available as a simple self-hosted applet with an accessible Web interface.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åˆ©ç”¨å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ (LLMs) è‡ªåŠ¨è¿›è¡Œå¯è§†åŒ–æ”¹é€  (Visualization makeovers) çš„æ½œåŠ›ï¼Œæ—¨åœ¨æ¨¡æ‹Ÿä¸“ä¸šç¤¾åŒºé€šè¿‡åé¦ˆæ”¹è¿›å›¾è¡¨çš„åä½œæ¨¡å¼ã€‚é€šè¿‡æç¤ºè¯å·¥ç¨‹ (prompt engineering) å°†å¯è§†åŒ–æœ€ä½³å®è·µå‡†åˆ™æ³¨å…¥é¢„è®­ç»ƒæ¨¡å‹ï¼Œè¯¥ç³»ç»Ÿèƒ½å¤Ÿæ ¹æ®å›¾è¡¨å›¾åƒæˆ–å…¶ç”Ÿæˆä»£ç æä¾›åŠè‡ªåŠ¨åŒ–çš„å»ºè®¾æ€§æ‰¹è¯„ï¼Œä»è€Œè¾…åŠ©ç”¨æˆ·ä¼˜åŒ–ç»˜å›¾è´¨é‡ã€‚ä¸ä»¥å¾€ä¾§é‡äºä»åŸå§‹æ•°æ®ç›´æ¥ç”Ÿæˆè„šæœ¬çš„ç ”ç©¶ä¸åŒï¼Œè¯¥å·¥ä½œçš„é‡ç‚¹åœ¨äºæ ¹æ®æœ€ä½³å®è·µåŸåˆ™æ•™è‚²ç”¨æˆ·å¦‚ä½•æ”¹è¿›ç°æœ‰çš„å¯è§†åŒ–è¡¨è¾¾ã€‚ç ”ç©¶é€šè¿‡å®šé‡è¯„ä¼°è¡¡é‡äº† LLM æ™ºèƒ½ä½“åœ¨ä¸åŒå›¾è¡¨ç±»å‹ä¸­è¯†åˆ«ç»˜å›¾é—®é¢˜çš„æ•æ„Ÿåº¦ï¼ŒéªŒè¯äº†å…¶åœ¨å‘ç°è§†è§‰ç¼ºé™·æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚æ­¤å¤–ï¼Œç ”ç©¶å›¢é˜Ÿè¿˜å‘å¸ƒäº†ä¸€ä¸ªå¸¦æœ‰ Web ç•Œé¢çš„è‡ªæ‰˜ç®¡åº”ç”¨ç¨‹åºï¼Œä¸ºæ•°æ®å¯è§†åŒ–è´¨é‡çš„æå‡æä¾›äº†å¯è®¿é—®çš„å·¥å…·æ”¯æŒã€‚è¯¥æˆæœä¸ºåˆ©ç”¨ç”Ÿæˆå¼äººå·¥æ™ºèƒ½æå‡æ•°æ®ç§‘å­¦ä¸­çš„å¯è§†åŒ–æ²Ÿé€šèƒ½åŠ›æä¾›äº†æ–°çš„èŒƒå¼ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.05637v1",
      "published_date": "2025-07-21 11:51:20 UTC",
      "updated_date": "2025-07-21 11:51:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:00:00.646672+00:00"
    },
    {
      "arxiv_id": "2507.16854v1",
      "title": "CLAMP: Contrastive Learning with Adaptive Multi-loss and Progressive Fusion for Multimodal Aspect-Based Sentiment Analysis",
      "title_zh": "CLAMPï¼šåŸºäºè‡ªé€‚åº”å¤šæŸå¤±ä¸æ¸è¿›å¼èåˆå¯¹æ¯”å­¦ä¹ çš„å¤šæ¨¡æ€æ–¹é¢çº§æƒ…æ„Ÿåˆ†æ",
      "authors": [
        "Xiaoqiang He"
      ],
      "abstract": "Multimodal aspect-based sentiment analysis(MABSA) seeks to identify aspect terms within paired image-text data and determine their fine grained sentiment polarities, representing a fundamental task for improving the effectiveness of applications such as product review systems and public opinion monitoring. Existing methods face challenges such as cross modal alignment noise and insufficient consistency in fine-grained representations. While global modality alignment methods often overlook the connection between aspect terms and their corresponding local visual regions, bridging the representation gap between text and images remains a challenge. To address these limitations, this paper introduces an end to end Contrastive Learning framework with Adaptive Multi-loss and Progressive Attention Fusion(CLAMP). The framework is composed of three novel modules: Progressive Attention Fusion network, Multi-task Contrastive Learning, and Adaptive Multi-loss Aggregation. The Progressive Attention Fusion network enhances fine-grained alignment between textual features and image regions via hierarchical, multi-stage cross modal interactions, effectively suppressing irrelevant visual noise. Secondly, multi-task contrastive learning combines global modal contrast and local granularity alignment to enhance cross modal representation consistency. Adaptive Multi-loss Aggregation employs a dynamic uncertainty based weighting mechanism to calibrate loss contributions according to each task's uncertainty, thereby mitigating gradient interference. Evaluation on standard public benchmarks demonstrates that CLAMP consistently outperforms the vast majority of existing state of the art methods.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹Multimodal Aspect-Based Sentiment Analysis (MABSA)ä¸­å­˜åœ¨çš„è·¨æ¨¡æ€å¯¹é½å™ªå£°å’Œç»†ç²’åº¦è¡¨ç¤ºä¸€è‡´æ€§ä¸è¶³ç­‰æŒ‘æˆ˜ï¼Œæå‡ºäº†åä¸ºCLAMPçš„ç«¯åˆ°ç«¯Contrastive Learningæ¡†æ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡Progressive Attention Fusionç½‘ç»œå®ç°æ–‡æœ¬ç‰¹å¾ä¸å›¾åƒåŒºåŸŸçš„å±‚æ¬¡åŒ–ã€å¤šé˜¶æ®µäº¤å‰æ¨¡æ€äº¤äº’ï¼Œæœ‰æ•ˆæŠ‘åˆ¶äº†æ— å…³è§†è§‰å™ªå£°ã€‚åŒæ—¶ï¼ŒMulti-task Contrastive Learningæ¨¡å—ç»“åˆäº†å…¨å±€æ¨¡æ€å¯¹é½ä¸å±€éƒ¨ç²’åº¦å¯¹é½ï¼Œæ˜¾è‘—å¢å¼ºäº†è·¨æ¨¡æ€è¡¨ç¤ºçš„ä¸€è‡´æ€§ã€‚æ­¤å¤–ï¼ŒAdaptive Multi-loss Aggregationåˆ©ç”¨åŸºäºä¸ç¡®å®šæ€§çš„åŠ¨æ€åŠ æƒæœºåˆ¶æ¥æ ¡å‡†å„é¡¹ä»»åŠ¡çš„æŸå¤±è´¡çŒ®ï¼Œä»è€Œå‡è½»äº†æ¢¯åº¦å¹²æ‰°ã€‚åœ¨æ ‡å‡†å…¬å¼€åŸºå‡†æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒCLAMPçš„æ€§èƒ½ä¼˜äºç»å¤§å¤šæ•°ç°æœ‰çš„State-of-the-artæ–¹æ³•ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.16854v1",
      "published_date": "2025-07-21 11:49:57 UTC",
      "updated_date": "2025-07-21 11:49:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:00:03.041733+00:00"
    },
    {
      "arxiv_id": "2507.15524v1",
      "title": "RARE-UNet: Resolution-Aligned Routing Entry for Adaptive Medical Image Segmentation",
      "title_zh": "RARE-UNetï¼šé¢å‘è‡ªé€‚åº”åŒ»å­¦å›¾åƒåˆ†å‰²çš„åˆ†è¾¨ç‡å¯¹é½è·¯ç”±å…¥å£",
      "authors": [
        "Simon Winther Albertsen",
        "Hjalte Svaneborg BjÃ¸rnstrup",
        "Mostafa Mehdipour Ghazi"
      ],
      "abstract": "Accurate segmentation is crucial for clinical applications, but existing models often assume fixed, high-resolution inputs and degrade significantly when faced with lower-resolution data in real-world scenarios. To address this limitation, we propose RARE-UNet, a resolution-aware multi-scale segmentation architecture that dynamically adapts its inference path to the spatial resolution of the input. Central to our design are multi-scale blocks integrated at multiple encoder depths, a resolution-aware routing mechanism, and consistency-driven training that aligns multi-resolution features with full-resolution representations. We evaluate RARE-UNet on two benchmark brain imaging tasks for hippocampus and tumor segmentation. Compared to standard UNet, its multi-resolution augmented variant, and nnUNet, our model achieves the highest average Dice scores of 0.84 and 0.65 across resolution, while maintaining consistent performance and significantly reduced inference time at lower resolutions. These results highlight the effectiveness and scalability of our architecture in achieving resolution-robust segmentation. The codes are available at: https://github.com/simonsejse/RARE-UNet.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† RARE-UNetï¼Œè¿™æ˜¯ä¸€ç§åˆ†è¾¨ç‡æ„ŸçŸ¥ï¼ˆresolution-awareï¼‰çš„å¤šå°ºåº¦åˆ†å‰²æ¶æ„ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰æ¨¡å‹åœ¨å¤„ç†çœŸå®åœºæ™¯ä½åˆ†è¾¨ç‡æ•°æ®æ—¶æ€§èƒ½æ˜¾è‘—ä¸‹é™çš„é—®é¢˜ã€‚è¯¥æ¶æ„çš„æ ¸å¿ƒè®¾è®¡åŒ…æ‹¬åœ¨å¤šä¸ªç¼–ç å™¨æ·±åº¦é›†æˆçš„å¤šå°ºåº¦æ¨¡å—ã€ä¸€ç§åˆ†è¾¨ç‡æ„ŸçŸ¥è·¯ç”±æœºåˆ¶ï¼ˆresolution-aware routing mechanismï¼‰ï¼Œä»¥åŠé€šè¿‡ä¸€è‡´æ€§é©±åŠ¨è®­ç»ƒï¼ˆconsistency-driven trainingï¼‰å°†å¤šåˆ†è¾¨ç‡ç‰¹å¾ä¸å…¨åˆ†è¾¨ç‡è¡¨ç¤ºè¿›è¡Œå¯¹é½ã€‚åœ¨æµ·é©¬ä½“å’Œè‚¿ç˜¤åˆ†å‰²ä¸¤é¡¹è„‘éƒ¨æˆåƒåŸºå‡†ä»»åŠ¡çš„è¯„ä¼°ä¸­ï¼ŒRARE-UNet åœ¨ä¸åŒåˆ†è¾¨ç‡ä¸‹å‡å–å¾—äº†æœ€é«˜çš„å¹³å‡ Dice åˆ†æ•°ï¼ˆåˆ†åˆ«ä¸º 0.84 å’Œ 0.65ï¼‰ï¼Œå…¶è¡¨ç°ä¼˜äºæ ‡å‡† UNetã€å¤šåˆ†è¾¨ç‡å¢å¼ºå˜ä½“åŠ nnUNetã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¨¡å‹åœ¨ä½åˆ†è¾¨ç‡ä¸‹ä¸ä»…ä¿æŒäº†æ€§èƒ½çš„ä¸€è‡´æ€§ï¼Œè¿˜æ˜¾è‘—ç¼©çŸ­äº†æ¨ç†æ—¶é—´ï¼ŒéªŒè¯äº†å…¶åœ¨å®ç°åˆ†è¾¨ç‡é²æ£’ï¼ˆresolution-robustï¼‰åŒ»ç–—å›¾åƒåˆ†å‰²æ–¹é¢çš„æœ‰æ•ˆæ€§ä¸å¯æ‰©å±•æ€§ã€‚",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "EMA4MICCAI 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.15524v1",
      "published_date": "2025-07-21 11:49:20 UTC",
      "updated_date": "2025-07-21 11:49:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:00:09.094171+00:00"
    },
    {
      "arxiv_id": "2507.15521v1",
      "title": "LLM world models are mental: Output layer evidence of brittle world model use in LLM mechanical reasoning",
      "title_zh": "LLM ä¸–ç•Œæ¨¡å‹å…·æœ‰å¿ƒç†æ¨¡å‹ç‰¹å¾ï¼šLLM æœºæ¢°æ¨ç†ä¸­ä¸–ç•Œæ¨¡å‹ä½¿ç”¨è„†å¼±æ€§çš„è¾“å‡ºå±‚è¯æ®",
      "authors": [
        "Cole Robertson",
        "Philip Wolff"
      ],
      "abstract": "Do large language models (LLMs) construct and manipulate internal world models, or do they rely solely on statistical associations represented as output layer token probabilities? We adapt cognitive science methodologies from human mental models research to test LLMs on pulley system problems using TikZ-rendered stimuli. Study 1 examines whether LLMs can estimate mechanical advantage (MA). State-of-the-art models performed marginally but significantly above chance, and their estimates correlated significantly with ground-truth MA. Significant correlations between number of pulleys and model estimates suggest that models employed a pulley counting heuristic, without necessarily simulating pulley systems to derive precise values. Study 2 tested this by probing whether LLMs represent global features crucial to MA estimation. Models evaluated a functionally connected pulley system against a fake system with randomly placed components. Without explicit cues, models identified the functional system as having greater MA with F1=0.8, suggesting LLMs could represent systems well enough to differentiate jumbled from functional systems. Study 3 built on this by asking LLMs to compare functional systems with matched systems which were connected up but which transferred no force to the weight; LLMs identified the functional system with F1=0.46, suggesting random guessing. Insofar as they may generalize, these findings are compatible with the notion that LLMs manipulate internal world models, sufficient to exploit statistical associations between pulley count and MA (Study 1), and to approximately represent system components' spatial relations (Study 2). However, they may lack the facility to reason over nuanced structural connectivity (Study 3). We conclude by advocating the utility of cognitive scientific methods to evaluate the world-modeling capacities of artificial intelligence systems.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§è¯­è¨€æ¨¡å‹(LLMs)æ˜¯æ„å»ºäº†å†…éƒ¨ä¸–ç•Œæ¨¡å‹(world models)è¿˜æ˜¯ä»…ä¾èµ–ç»Ÿè®¡å…³è”ï¼Œå¹¶å€Ÿé‰´è®¤çŸ¥ç§‘å­¦æ–¹æ³•æµ‹è¯•äº†æ¨¡å‹åœ¨æ»‘è½®ç³»ç»Ÿæœºæ¢°æ¨ç†(mechanical reasoning)ä¸­çš„è¡¨ç°ã€‚ç ”ç©¶é€šè¿‡TikZæ¸²æŸ“çš„æ»‘è½®ç³»ç»Ÿé—®é¢˜è¿›è¡Œè¯„ä¼°ï¼Œåœ¨ç ”ç©¶1ä¸­å‘ç°æ¨¡å‹ä¼°ç®—æœºæ¢°åˆ©ç›Š(mechanical advantage, MA)çš„è¡¨ç°ç•¥é«˜äºéšæœºæ°´å¹³ï¼Œä½†å€¾å‘äºä½¿ç”¨â€œæ»‘è½®è®¡æ•°â€çš„å¯å‘å¼æ–¹æ³•ã€‚ç ”ç©¶2æ˜¾ç¤ºæ¨¡å‹èƒ½ä»¥0.8çš„F1å€¼åŒºåˆ†åŠŸèƒ½ç³»ç»Ÿä¸ç»„ä»¶éšæœºæ”¾ç½®çš„ç³»ç»Ÿï¼Œè¡¨æ˜å…¶èƒ½è¡¨å¾ç»„ä»¶é—´çš„ç©ºé—´å…³ç³»ã€‚ç„¶è€Œï¼Œç ”ç©¶3å‘ç°æ¨¡å‹åœ¨åº”å¯¹å¤æ‚çš„ç»“æ„è¿é€šæ€§(structural connectivity)æ—¶è¡¨ç°æ¥è¿‘éšæœºçŒœæµ‹ã€‚å®éªŒç»“æœè¯æ˜LLMsè™½ç„¶èƒ½åˆ©ç”¨ç»Ÿè®¡å…³è”å’Œè¿‘ä¼¼ç©ºé—´å…³ç³»ï¼Œä½†åœ¨æ·±å±‚æœºæ¢°æ¨ç†æ–¹é¢ä»æ˜¾è„†å¼±ã€‚è¯¥ç ”ç©¶æ€»ç»“è®¤ä¸ºLLMsçš„å†…éƒ¨ä¸–ç•Œæ¨¡å‹å…·æœ‰å±€é™æ€§ï¼Œå¹¶å€¡å¯¼ä½¿ç”¨è®¤çŸ¥ç§‘å­¦æ–¹æ³•æ¥è¯„ä¼°äººå·¥æ™ºèƒ½çš„ä¸–ç•Œå»ºæ¨¡(world-modeling)èƒ½åŠ›ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Manuscript comprises 14 pages, 4 figures, 4 tables in the Technical Appendix and Supplementary Material, and is under review at NeurIPS 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.15521v1",
      "published_date": "2025-07-21 11:42:03 UTC",
      "updated_date": "2025-07-21 11:42:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:00:18.886527+00:00"
    },
    {
      "arxiv_id": "2507.15518v3",
      "title": "HAMLET: Hyperadaptive Agent-based Modeling for Live Embodied Theatrics",
      "title_zh": "HAMLETï¼šé¢å‘å®æ—¶å…·èº«æˆå‰§çš„é«˜åº¦è‡ªé€‚åº”æ™ºèƒ½ä½“å»ºæ¨¡",
      "authors": [
        "Sizhou Chen",
        "Shufan Jiang",
        "Chi Zhang",
        "Xiao-Lei Zhang",
        "Xuelong Li"
      ],
      "abstract": "Creating an immersive and interactive theatrical experience is a long-term goal in the field of interactive narrative. The emergence of large language model (LLM) is providing a new path to achieve this goal. However, existing LLM-based drama generation methods often result in agents that lack initiative and cannot interact with the physical scene. Furthermore, these methods typically require detailed user input to drive the drama. These limitations reduce the interactivity and immersion of online real-time performance. To address the above challenges, we propose HAMLET, a multi-agent framework focused on drama creation and online performance. Given a simple topic, the framework generates a narrative blueprint, guiding the subsequent improvisational performance. During the online performance, each actor is given an autonomous mind. This means that actors can make independent decisions based on their own background, goals, and emotional state. In addition to conversations with other actors, their decisions can also change the state of scene props through actions such as opening a letter or picking up a weapon. The change is then broadcast to other related actors, updating what they know and care about, which in turn influences their next action. To evaluate the quality of drama performance generated by HAMLET, we designed an evaluation method to assess three primary aspects, including character performance, narrative quality, and interaction experience. The experimental evaluation shows that HAMLET can create expressive and coherent theatrical experiences.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†HAMLETï¼Œä¸€ä¸ªä¸“æ³¨äºæˆå‰§åˆ›ä½œå’Œåœ¨çº¿è¡¨æ¼”çš„å¤šæ™ºèƒ½ä½“(multi-agent)æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰å¤§è¯­è¨€æ¨¡å‹(LLM)ç”Ÿæˆçš„æ™ºèƒ½ä½“ç¼ºä¹ä¸»åŠ¨æ€§ä¸”æ— æ³•ä¸ç‰©ç†åœºæ™¯äº’åŠ¨çš„é—®é¢˜ã€‚è¯¥æ¡†æ¶ä»…éœ€ç»™å®šç®€å•ä¸»é¢˜å³å¯ç”Ÿæˆå™äº‹è“å›¾(narrative blueprint)ï¼Œå¹¶ä»¥æ­¤æŒ‡å¯¼åç»­çš„å³å…´è¡¨æ¼”ã€‚åœ¨è¡¨æ¼”è¿‡ç¨‹ä¸­ï¼Œæ¯ä½æ¼”å‘˜éƒ½è¢«èµ‹äºˆäº†è‡ªä¸»æ„è¯†ï¼Œèƒ½å¤Ÿæ ¹æ®è‡ªèº«çš„èƒŒæ™¯ã€ç›®æ ‡å’Œæƒ…æ„ŸçŠ¶æ€åšå‡ºç‹¬ç«‹å†³ç­–ã€‚é™¤äº†è¯­è¨€äº¤æµï¼Œæ¼”å‘˜è¿˜å¯ä»¥é€šè¿‡æ“ä½œåœºæ™¯é“å…·æ¥æ”¹å˜ç‰©ç†çŠ¶æ€ï¼Œå¹¶å°†è¿™ç§å˜åŒ–å®æ—¶å¹¿æ’­ç»™å…¶ä»–ç›¸å…³è§’è‰²ï¼Œä»è€ŒåŠ¨æ€å½±å“å…¶åç»­è¡Œä¸ºã€‚å®éªŒé€šè¿‡è§’è‰²è¡¨ç°ã€å™äº‹è´¨é‡å’Œäº’åŠ¨ä½“éªŒä¸‰ä¸ªç»´åº¦è¿›è¡Œè¯„ä¼°ï¼Œç»“æœè¯æ˜HAMLETèƒ½å¤Ÿåˆ›é€ å‡ºæå…·è¡¨ç°åŠ›ä¸”é€»è¾‘è¿è´¯çš„æˆå‰§åŒ–ä½“éªŒã€‚",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "This submission has been withdrawn due to unresolved issues concerning author order and potential conflicts of interest between author affiliations. The authors will resubmit once these matters are fully resolved",
      "pdf_url": "https://arxiv.org/pdf/2507.15518v3",
      "published_date": "2025-07-21 11:36:39 UTC",
      "updated_date": "2025-11-30 09:54:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:00:33.720606+00:00"
    },
    {
      "arxiv_id": "2507.15509v2",
      "title": "Chart-R1: Chain-of-Thought Supervision and Reinforcement for Advanced Chart Reasoner",
      "title_zh": "Chart-R1ï¼šåŸºäºæ€ç»´é“¾ç›‘ç£ä¸å¼ºåŒ–çš„è¿›é˜¶å›¾è¡¨æ¨ç†å™¨",
      "authors": [
        "Lei Chen",
        "Xuanle Zhao",
        "Zhixiong Zeng",
        "Jing Huang",
        "Yufeng Zhong",
        "Lin Ma"
      ],
      "abstract": "Recently, inspired by OpenAI-o1/o3 and Deepseek-R1, the R1-Style method based on reinforcement learning fine-tuning has received widespread attention from the community. Previous R1-Style methods mainly focus on mathematical reasoning and code intelligence. It is of great research significance to verify their advantages on more general multimodal data. Chart is an important multimodal data type with rich information, which brings important research challenges in complex reasoning. In this work, we introduce Chart-R1, a chart-domain vision-language model with reinforcement learning fine-tuning to enable complex chart reasoning. To support Chart-R1, we first propose a novel programmatic data synthesis technology to generate high-quality step-by-step chart reasoning data covering single- and multi-subcharts, which makes up for the lack of reasoning data in the chart domain. Then we develop a two-stage training strategy: Chart-COT with step-by-step chain-of-thought supervision, and Chart-RFT with numerically sensitive reinforcement fine-tuning. Chart-COT aims to decompose complex chart reasoning tasks into fine-grained, understandable subtasks through step-by-step supervision, which lays a good foundation for improving the reasoning level of reinforcement learning. Chart-RFT utilize the typical group relative policy optimization strategy, in which a relatively soft reward is adopted for numerical response to emphasize the numerical sensitivity in the chart domain. We conduct extensive experiments on open-source benchmarks and self-built chart reasoning dataset (\\emph{i.e., ChartRQA}). Experimental results show that Chart-R1 has significant advantages compared to chart-domain methods, even comparable to open/closed source large-scale models (\\emph{e.g., GPT-4o, Claude-3.5}).",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº†Chart-R1ï¼Œè¿™æ˜¯ä¸€æ¬¾ä¸“é—¨é’ˆå¯¹å›¾è¡¨é¢†åŸŸçš„è§†è§‰è¯­è¨€æ¨¡å‹(Vision-Language Model)ï¼Œæ—¨åœ¨åˆ©ç”¨å¼ºåŒ–å­¦ä¹ (Reinforcement Learning)å¾®è°ƒæŠ€æœ¯æå‡å¤æ‚çš„å›¾è¡¨æ¨ç†èƒ½åŠ›ã€‚ä¸ºäº†è§£å†³å›¾è¡¨é¢†åŸŸæ¨ç†æ•°æ®åŒ®ä¹çš„é—®é¢˜ï¼Œä½œè€…æå‡ºäº†ä¸€ç§åˆ›æ–°çš„ç¨‹åºåŒ–æ•°æ®åˆæˆæŠ€æœ¯ï¼Œç”Ÿæˆäº†æ¶µç›–å•å­å›¾å’Œå¤šå­å›¾çš„é«˜è´¨é‡åˆ†æ­¥æ¨ç†æ•°æ®ã€‚è®­ç»ƒè¿‡ç¨‹é‡‡ç”¨äº†ä¸¤é˜¶æ®µç­–ç•¥ï¼šé¦–å…ˆé€šè¿‡Chart-COTè¿›è¡Œåˆ†æ­¥é“¾å¼æ€ç»´(Chain-of-Thought)ç›‘ç£ï¼Œå°†å¤æ‚ä»»åŠ¡åˆ†è§£ä¸ºç»†ç²’åº¦çš„å­ä»»åŠ¡ï¼›éšååˆ©ç”¨Chart-RFTè¿›è¡Œå¼ºåŒ–å­¦ä¹ å¾®è°ƒï¼Œé‡‡ç”¨ç¾¤ä½“ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–(Group Relative Policy Optimization)å¹¶å¼•å…¥é’ˆå¯¹æ•°å€¼æ•æ„Ÿæ€§çš„è½¯å¥–åŠ±(Soft Reward)æœºåˆ¶ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒChart-R1åœ¨å¼€æºåŸºå‡†æµ‹è¯•å’Œè‡ªå»ºçš„ChartRQAæ•°æ®é›†ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œä¸ä»…æ˜¾è‘—è¶…è¿‡äº†ç°æœ‰çš„å›¾è¡¨ä¸“ç”¨æ¨¡å‹ï¼Œå…¶æ€§èƒ½ç”šè‡³èƒ½ä¸GPT-4oå’ŒClaude-3.5ç­‰é¡¶å°–å¤§è§„æ¨¡æ¨¡å‹ç›¸åª²ç¾ã€‚",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "technical report",
      "pdf_url": "https://arxiv.org/pdf/2507.15509v2",
      "published_date": "2025-07-21 11:22:17 UTC",
      "updated_date": "2025-08-07 06:40:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:00:34.650082+00:00"
    },
    {
      "arxiv_id": "2507.15507v1",
      "title": "Off-Policy Corrected Reward Modeling for Reinforcement Learning from Human Feedback",
      "title_zh": "é¢å‘äººç±»åé¦ˆå¼ºåŒ–å­¦ä¹ çš„ç¦»ç­–ç•¥ä¿®æ­£å¥–åŠ±å»ºæ¨¡",
      "authors": [
        "Johannes Ackermann",
        "Takashi Ishida",
        "Masashi Sugiyama"
      ],
      "abstract": "Reinforcement Learning from Human Feedback (RLHF) allows us to train models, such as language models (LMs), to follow complex human preferences. In RLHF for LMs, we first train an LM using supervised fine-tuning, sample pairs of responses, obtain human feedback, and use the resulting data to train a reward model (RM). RL methods are then used to train the LM to maximize the reward given by the RM. As training progresses, the responses generated by the LM no longer resemble the responses seen by the RM during training, leading to the RM becoming inaccurate. The score given by the RM keeps increasing, but the learned behavior no longer matches the human preferences. This issue is known as overoptimization. We investigate overoptimization from the point of view of distribution shift and show that the shift results in an inconsistent estimate of the RM parameters, leading to an inconsistent estimate of the policy gradient. We propose Off-Policy Corrected Reward Modeling (OCRM), which iteratively off-policy corrects the RM using importance weighting, without requiring new labels or samples. This results in a more accurate RM, which empirically leads to an improved final policy. We validate our approach in experiments with summarization and chatbot datasets and show that it performs significantly better than standard RLHF methods and baselines. Our implementation is available at https://github.com/JohannesAck/OffPolicyCorrectedRewardModeling",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶é’ˆå¯¹ Reinforcement Learning from Human Feedback (RLHF) ä¸­çš„ overoptimization é—®é¢˜è¿›è¡Œäº†æ·±å…¥æ¢è®¨ï¼ŒæŒ‡å‡ºè¯¥é—®é¢˜æºäºæ¨¡å‹ç”Ÿæˆçš„å“åº”ä¸ Reward Model (RM) è®­ç»ƒæ•°æ®ä¹‹é—´çš„ distribution shiftã€‚ä½œè€…ä»åˆ†å¸ƒåç§»çš„è§†è§’åˆ†æè¯æ˜ï¼Œè¿™ç§åç§»ä¼šå¯¼è‡´ RM å‚æ•°ä¼°è®¡ä¸ä¸€è‡´ï¼Œè¿›è€Œå¯¼è‡´ policy gradient çš„ä¼°è®¡å¤±æ•ˆã€‚ä¸ºäº†è§£å†³è¿™ä¸€æŒ‘æˆ˜ï¼Œè®ºæ–‡æå‡ºäº† Off-Policy Corrected Reward Modeling (OCRM)ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨ importance weighting æŠ€æœ¯åœ¨ä¸éœ€è¦æ–°æ ‡ç­¾æˆ–æ ·æœ¬çš„æƒ…å†µä¸‹ï¼Œå¯¹ RM è¿›è¡Œè¿­ä»£çš„ off-policy ä¿®æ­£ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒOCRM åœ¨ summarization å’Œ chatbot æ•°æ®é›†ä¸Šçš„è¡¨ç°æ˜¾è‘—ä¼˜äºæ ‡å‡† RLHF æ–¹æ³•åŠç›¸å…³åŸºçº¿ã€‚è¯¥ç ”ç©¶é€šè¿‡æé«˜ RM çš„å‡†ç¡®æ€§ï¼Œæœ€ç»ˆå®ç°äº†æ›´ä¼˜çš„ç­–ç•¥æ€§èƒ½ï¼Œä¸ºç¼“è§£å¼ºåŒ–å­¦ä¹ ä¸­çš„è¿‡åº¦ä¼˜åŒ–é—®é¢˜æä¾›äº†æœ‰æ•ˆæ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Accept at the Conference On Language Modeling (COLM) 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.15507v1",
      "published_date": "2025-07-21 11:19:04 UTC",
      "updated_date": "2025-07-21 11:19:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:00:38.641648+00:00"
    },
    {
      "arxiv_id": "2507.19530v1",
      "title": "Clinical-Grade Blood Pressure Prediction in ICU Settings: An Ensemble Framework with Uncertainty Quantification and Cross-Institutional Validation",
      "title_zh": "ICU ç¯å¢ƒä¸‹çš„ä¸´åºŠçº§è¡€å‹é¢„æµ‹ï¼šä¸€ç§èåˆä¸ç¡®å®šæ€§é‡åŒ–ä¸è·¨æœºæ„éªŒè¯çš„é›†æˆæ¡†æ¶",
      "authors": [
        "Md Basit Azam",
        "Sarangthem Ibotombi Singh"
      ],
      "abstract": "Blood pressure (BP) monitoring is critical in in tensive care units (ICUs) where hemodynamic instability can\n  rapidly progress to cardiovascular collapse. Current machine\n  learning (ML) approaches suffer from three limitations: lack of\n  external validation, absence of uncertainty quantification, and\n  inadequate data leakage prevention. This study presents the\n  first comprehensive framework with novel algorithmic leakage\n  prevention, uncertainty quantification, and cross-institutional\n  validation for electronic health records (EHRs) based BP pre dictions. Our methodology implemented systematic data leakage\n  prevention, uncertainty quantification through quantile regres sion, and external validation between the MIMIC-III and eICU\n  databases. An ensemble framework combines Gradient Boosting,\n  Random Forest, and XGBoost with 74 features across five\n  physiological domains. Internal validation achieved a clinically\n  acceptable performance (for SBP: R^2 = 0.86, RMSE = 6.03\n  mmHg; DBP: R^2 = 0.49, RMSE = 7.13 mmHg), meeting AAMI\n  standards. External validation showed 30% degradation with\n  critical limitations in patients with hypotensive. Uncertainty\n  quantification generated valid prediction intervals (80.3% SBP\n  and 79.9% DBP coverage), enabling risk-stratified protocols\n  with narrow intervals (< 15 mmHg) for standard monitoring\n  and wide intervals (> 30 mmHg) for manual verification. This\n  framework provides realistic deployment expectations for cross institutional AI-assisted BP monitoring in critical care settings.\n  The source code is publicly available at https://github.com/\n  mdbasit897/clinical-bp-prediction-ehr.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§é’ˆå¯¹é‡ç—‡ç›‘æŠ¤ç—…æˆ¿(ICU)è¡€å‹é¢„æµ‹çš„ç»¼åˆé›†æˆæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰æœºå™¨å­¦ä¹ (Machine Learning)æ–¹æ³•åœ¨å¤–éƒ¨éªŒè¯ã€ä¸ç¡®å®šæ€§é‡åŒ–(Uncertainty Quantification)åŠæ•°æ®æ³„æ¼é¢„é˜²æ–¹é¢çš„å±€é™æ€§ã€‚ç ”ç©¶äººå‘˜é€šè¿‡é›†æˆGradient Boostingã€Random Forestå’ŒXGBoostç®—æ³•ï¼Œæå–äº†è·¨äº”ä¸ªç”Ÿç†é¢†åŸŸçš„74ä¸ªç‰¹å¾ï¼Œå¹¶åˆ©ç”¨åˆ†ä½æ•°å›å½’(Quantile Regression)ç”Ÿæˆé¢„æµ‹åŒºé—´ã€‚å®éªŒåœ¨MIMIC-IIIå’ŒeICUæ•°æ®åº“ä¸Šè¿›è¡Œäº†è·¨æœºæ„éªŒè¯ï¼Œå†…éƒ¨éªŒè¯ç»“æœç¬¦åˆAAMIæ ‡å‡†ï¼Œå…¶ä¸­æ”¶ç¼©å‹(SBP)çš„RÂ²è¾¾åˆ°0.86ã€‚å°½ç®¡å¤–éƒ¨éªŒè¯æ˜¾ç¤ºæ€§èƒ½ä¸‹é™çº¦30%ä¸”åœ¨ä½è¡€å‹(Hypotensive)æ‚£è€…ä¸­å­˜åœ¨å±€é™ï¼Œä½†è¯¥æ¡†æ¶é€šè¿‡ä¸ç¡®å®šæ€§é‡åŒ–å®ç°äº†é£é™©åˆ†å±‚åè®®ï¼Œå…è®¸å¯¹å®½åŒºé—´é¢„æµ‹è¿›è¡Œäººå·¥æ ¸å®ã€‚è¿™é¡¹å·¥ä½œä¸ºé‡ç—‡ç›‘æŠ¤ç¯å¢ƒä¸‹çš„AIè¾…åŠ©è¡€å‹ç›‘æµ‹æä¾›äº†ä¸´åºŠçº§çš„éƒ¨ç½²å‚è€ƒå’Œå¼€æºå·¥å…·ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.19530v1",
      "published_date": "2025-07-21 11:15:33 UTC",
      "updated_date": "2025-07-21 11:15:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:00:46.088352+00:00"
    },
    {
      "arxiv_id": "2507.15501v1",
      "title": "ASPERA: A Simulated Environment to Evaluate Planning for Complex Action Execution",
      "title_zh": "ASPERAï¼šé¢å‘å¤æ‚åŠ¨ä½œæ‰§è¡Œè§„åˆ’è¯„ä¼°çš„æ¨¡æ‹Ÿç¯å¢ƒ",
      "authors": [
        "Alexandru Coca",
        "Mark Gaynor",
        "Zhenxing Zhang",
        "Jianpeng Cheng",
        "Bo-Hsiang Tseng",
        "Pete Boothroyd",
        "HÃ©ctor Martinez Alonso",
        "Diarmuid Ã“ SÃ©aghdha",
        "Anders Johannsen"
      ],
      "abstract": "This work evaluates the potential of large language models (LLMs) to power digital assistants capable of complex action execution. These assistants rely on pre-trained programming knowledge to execute multi-step goals by composing objects and functions defined in assistant libraries into action execution programs. To achieve this, we develop ASPERA, a framework comprising an assistant library simulation and a human-assisted LLM data generation engine. Our engine allows developers to guide LLM generation of high-quality tasks consisting of complex user queries, simulation state and corresponding validation programs, tackling data availability and evaluation robustness challenges. Alongside the framework we release Asper-Bench, an evaluation dataset of 250 challenging tasks generated using ASPERA, which we use to show that program generation grounded in custom assistant libraries is a significant challenge to LLMs compared to dependency-free code generation.",
      "tldr_zh": "è¯¥ç ”ç©¶è¯„ä¼°äº†å¤§è¯­è¨€æ¨¡å‹ (LLMs) åœ¨é©±åŠ¨èƒ½å¤Ÿæ‰§è¡Œå¤æ‚åŠ¨ä½œçš„æ•°å­—åŠ©æ‰‹æ–¹é¢çš„æ½œåŠ›ï¼Œé‡ç‚¹æ¢è®¨å…¶åˆ©ç”¨åŠ©æ‰‹åº“ (assistant libraries) ç»„åˆå¯¹è±¡ä¸å‡½æ•°ä»¥å®ç°å¤šæ­¥ç›®æ ‡çš„èƒ½åŠ›ã€‚ä¸ºæ­¤ï¼Œä½œè€…å¼€å‘äº† ASPERA æ¡†æ¶ï¼Œè¯¥æ¡†æ¶åŒ…å«åŠ©æ‰‹åº“æ¨¡æ‹Ÿç¯å¢ƒå’Œäººç±»è¾…åŠ©çš„ LLM æ•°æ®ç”Ÿæˆå¼•æ“ï¼Œæ—¨åœ¨è§£å†³æ•°æ®å¯ç”¨æ€§å’Œè¯„ä¼°ç¨³å¥æ€§æŒ‘æˆ˜ã€‚é€šè¿‡è¯¥å¼•æ“ï¼Œå¼€å‘è€…å¯ä»¥å¼•å¯¼ LLM ç”ŸæˆåŒ…å«å¤æ‚ç”¨æˆ·æŸ¥è¯¢ã€æ¨¡æ‹ŸçŠ¶æ€åŠå¯¹åº”éªŒè¯ç¨‹åºçš„é«˜è´¨é‡ä»»åŠ¡ã€‚ç ”ç©¶å›¢é˜ŸåŒæ­¥å‘å¸ƒäº†åŒ…å« 250 ä¸ªæŒ‘æˆ˜æ€§ä»»åŠ¡çš„è¯„ä¼°æ•°æ®é›† Asper-Benchï¼Œå¹¶æ®æ­¤å‘ç°åŸºäºè‡ªå®šä¹‰åŠ©æ‰‹åº“çš„ç¨‹åºç”Ÿæˆæ¯”æ— ä¾èµ–çš„ä»£ç ç”Ÿæˆå¯¹ LLMs æ„æˆäº†æ›´æ˜¾è‘—çš„æŒ‘æˆ˜ã€‚è¯¥å·¥ä½œä¸ºè¯„ä¼°æ•°å­—åŠ©æ‰‹åœ¨å¤æ‚åŠ¨ä½œæ‰§è¡Œä¸­çš„è§„åˆ’èƒ½åŠ›æä¾›äº†é‡è¦çš„å·¥å…·å’ŒåŸºå‡†ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "37 pages, 22 figures. To appear at ACL 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.15501v1",
      "published_date": "2025-07-21 11:07:05 UTC",
      "updated_date": "2025-07-21 11:07:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:00:42.839112+00:00"
    },
    {
      "arxiv_id": "2507.15493v2",
      "title": "GR-3 Technical Report",
      "title_zh": "GR-3 æŠ€æœ¯æŠ¥å‘Š",
      "authors": [
        "Chilam Cheang",
        "Sijin Chen",
        "Zhongren Cui",
        "Yingdong Hu",
        "Liqun Huang",
        "Tao Kong",
        "Hang Li",
        "Yifeng Li",
        "Yuxiao Liu",
        "Xiao Ma",
        "Hao Niu",
        "Wenxuan Ou",
        "Wanli Peng",
        "Zeyu Ren",
        "Haixin Shi",
        "Jiawen Tian",
        "Hongtao Wu",
        "Xin Xiao",
        "Yuyang Xiao",
        "Jiafeng Xu",
        "Yichu Yang"
      ],
      "abstract": "We report our recent progress towards building generalist robot policies, the development of GR-3. GR-3 is a large-scale vision-language-action (VLA) model. It showcases exceptional capabilities in generalizing to novel objects, environments, and instructions involving abstract concepts. Furthermore, it can be efficiently fine-tuned with minimal human trajectory data, enabling rapid and cost-effective adaptation to new settings. GR-3 also excels in handling long-horizon and dexterous tasks, including those requiring bi-manual manipulation and mobile movement, showcasing robust and reliable performance. These capabilities are achieved through a multi-faceted training recipe that includes co-training with web-scale vision-language data, efficient fine-tuning from human trajectory data collected via VR devices, and effective imitation learning with robot trajectory data. In addition, we introduce ByteMini, a versatile bi-manual mobile robot designed with exceptional flexibility and reliability, capable of accomplishing a wide range of tasks when integrated with GR-3. Through extensive real-world experiments, we show GR-3 surpasses the state-of-the-art baseline method, $Ï€_0$, on a wide variety of challenging tasks. We hope GR-3 can serve as a step towards building generalist robots capable of assisting humans in daily life.",
      "tldr_zh": "è¯¥ç ”ç©¶ä»‹ç»äº†å¤§è§„æ¨¡è§†è§‰-è¯­è¨€-åŠ¨ä½œ (Vision-Language-Action, VLA) æ¨¡å‹ GR-3ï¼Œæ—¨åœ¨æ„å»ºå…·å¤‡é«˜åº¦æ³›åŒ–èƒ½åŠ›çš„é€šç”¨æœºå™¨äººç­–ç•¥ã€‚GR-3 åœ¨é¢å¯¹æ–°é¢–ç‰©ä½“ã€ç¯å¢ƒå’Œæ¶‰åŠæŠ½è±¡æ¦‚å¿µçš„æŒ‡ä»¤æ—¶è¡¨ç°å‡ºå“è¶Šçš„æ³›åŒ–æ€§èƒ½ï¼Œä¸”ä»…éœ€æå°‘é‡äººç±»è½¨è¿¹æ•°æ®å³å¯å®ç°é«˜æ•ˆå¾®è°ƒä¸å¿«é€Ÿé€‚é…ã€‚è¯¥æ¨¡å‹èƒ½å¤Ÿå‡ºè‰²åœ°å¤„ç†é•¿ç¨‹ (Long-horizon) å’ŒåŒè‡‚åä½œ (Bi-manual manipulation) ç­‰çµå·§ç§»åŠ¨ä»»åŠ¡ï¼Œå…¶æ€§èƒ½é€šè¿‡äº’è”ç½‘è§„æ¨¡çš„è§†è§‰-è¯­è¨€æ•°æ®ã€VR è®¾å¤‡é‡‡é›†çš„äººç±»è½¨è¿¹æ•°æ®ä»¥åŠæœºå™¨äººæ¨¡ä»¿å­¦ä¹ çš„ååŒè®­ç»ƒå¾—ä»¥å®ç°ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜å¼•å…¥äº†é…å¥—çš„é€šç”¨åŒè‡‚ç§»åŠ¨æœºå™¨äºº ByteMiniï¼Œæ—¨åœ¨é€šè¿‡é«˜åº¦çš„çµæ´»æ€§ä¸å¯é æ€§å®Œæˆå„ç§å¤æ‚ä»»åŠ¡ã€‚åœ¨å¹¿æ³›çš„ç°å®ä¸–ç•Œå®éªŒä¸­ï¼ŒGR-3 çš„è¡¨ç°è¶…è¶Šäº†å½“å‰æœ€å…ˆè¿›çš„åŸºçº¿æ–¹æ³• $\\pi_0$ï¼Œæ ‡å¿—ç€æ„å»ºèƒ½ååŠ©äººç±»æ—¥å¸¸ç”Ÿæ´»çš„é€šç”¨æœºå™¨äººè¿ˆå‡ºäº†é‡è¦ä¸€æ­¥ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "Tech report. Authors are listed in alphabetical order. Project page: https://seed.bytedance.com/GR3/",
      "pdf_url": "https://arxiv.org/pdf/2507.15493v2",
      "published_date": "2025-07-21 10:54:13 UTC",
      "updated_date": "2025-07-22 15:04:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:00:58.795825+00:00"
    },
    {
      "arxiv_id": "2507.22920v1",
      "title": "Discrete Tokenization for Multimodal LLMs: A Comprehensive Survey",
      "title_zh": "å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹çš„ç¦»æ•£åŒ–æ ‡è®°ï¼šå…¨é¢ç»¼è¿°",
      "authors": [
        "Jindong Li",
        "Yali Fu",
        "Jiahong Liu",
        "Linxiao Cao",
        "Wei Ji",
        "Menglin Yang",
        "Irwin King",
        "Ming-Hsuan Yang"
      ],
      "abstract": "The rapid advancement of large language models (LLMs) has intensified the need for effective mechanisms to transform continuous multimodal data into discrete representations suitable for language-based processing. Discrete tokenization, with vector quantization (VQ) as a central approach, offers both computational efficiency and compatibility with LLM architectures. Despite its growing importance, there is a lack of a comprehensive survey that systematically examines VQ techniques in the context of LLM-based systems. This work fills this gap by presenting the first structured taxonomy and analysis of discrete tokenization methods designed for LLMs. We categorize 8 representative VQ variants that span classical and modern paradigms and analyze their algorithmic principles, training dynamics, and integration challenges with LLM pipelines. Beyond algorithm-level investigation, we discuss existing research in terms of classical applications without LLMs, LLM-based single-modality systems, and LLM-based multimodal systems, highlighting how quantization strategies influence alignment, reasoning, and generation performance. In addition, we identify key challenges including codebook collapse, unstable gradient estimation, and modality-specific encoding constraints. Finally, we discuss emerging research directions such as dynamic and task-adaptive quantization, unified tokenization frameworks, and biologically inspired codebook learning. This survey bridges the gap between traditional vector quantization and modern LLM applications, serving as a foundational reference for the development of efficient and generalizable multimodal systems. A continuously updated version is available at: https://github.com/jindongli-Ai/LLM-Discrete-Tokenization-Survey.",
      "tldr_zh": "è¯¥ç»¼è¿°ç³»ç»Ÿåœ°æ¢è®¨äº†å°†è¿ç»­å¤šæ¨¡æ€æ•°æ®è½¬åŒ–ä¸ºç¦»æ•£è¡¨ç¤ºçš„Discrete TokenizationæŠ€æœ¯ï¼Œé‡ç‚¹å…³æ³¨äº†åœ¨å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMultimodal LLMsï¼‰ä¸­èµ·æ ¸å¿ƒä½œç”¨çš„çŸ¢é‡é‡åŒ–ï¼ˆVector Quantization, VQï¼‰æ–¹æ³•ã€‚ä½œè€…æå‡ºäº†é¦–ä¸ªç»“æ„åŒ–çš„åˆ†ç±»æ³•ï¼Œæ¶µç›–äº†ä»ç»å…¸åˆ°ç°ä»£èŒƒå¼çš„8ç§ä»£è¡¨æ€§VQå˜ä½“ï¼Œå¹¶æ·±å…¥åˆ†æäº†å…¶ç®—æ³•åŸç†ã€è®­ç»ƒåŠ¨æ€ä»¥åŠä¸LLMæµæ°´çº¿é›†æˆçš„æŒ‘æˆ˜ã€‚æ–‡ç« è¿›ä¸€æ­¥è®¨è®ºäº†é‡åŒ–ç­–ç•¥åœ¨å•æ¨¡æ€å’Œå¤šæ¨¡æ€LLMç³»ç»Ÿä¸­å¦‚ä½•å½±å“æ¨¡å‹çš„å¯¹é½ã€æ¨ç†ä¸ç”Ÿæˆæ€§èƒ½ï¼Œå¹¶è¯†åˆ«äº†Codebook collapseã€ä¸ç¨³å®šçš„æ¢¯åº¦ä¼°è®¡åŠæ¨¡æ€ç‰¹å®šç¼–ç çº¦æŸç­‰å…³é”®æŒ‘æˆ˜ã€‚æœ€åï¼Œè¯¥ç ”ç©¶æ¢è®¨äº†åŠ¨æ€ä»»åŠ¡è‡ªé€‚åº”é‡åŒ–ã€ç»Ÿä¸€Tokenizationæ¡†æ¶å’Œç”Ÿç‰©å¯å‘å¼ç æœ¬å­¦ä¹ ç­‰å‰æ²¿æ–¹å‘ï¼Œä¸ºæ„å»ºé«˜æ•ˆä¸”é€šç”¨çš„å¤šæ¨¡æ€æ™ºèƒ½ç³»ç»Ÿæä¾›äº†é‡è¦çš„åŸºç¡€å‚è€ƒã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.22920v1",
      "published_date": "2025-07-21 10:52:14 UTC",
      "updated_date": "2025-07-21 10:52:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:00:58.945010+00:00"
    },
    {
      "arxiv_id": "2507.15478v1",
      "title": "The Constitutional Controller: Doubt-Calibrated Steering of Compliant Agents",
      "title_zh": "å®ªæ³•å¼æ§åˆ¶å™¨ï¼šåŸºäºç–‘è™‘æ ¡å‡†çš„åˆè§„æ™ºèƒ½ä½“å¼•å¯¼",
      "authors": [
        "Simon Kohaut",
        "Felix Divo",
        "Navid Hamid",
        "Benedict Flade",
        "Julian Eggert",
        "Devendra Singh Dhami",
        "Kristian Kersting"
      ],
      "abstract": "Ensuring reliable and rule-compliant behavior of autonomous agents in uncertain environments remains a fundamental challenge in modern robotics. Our work shows how neuro-symbolic systems, which integrate probabilistic, symbolic white-box reasoning models with deep learning methods, offer a powerful solution to this challenge. This enables the simultaneous consideration of explicit rules and neural models trained on noisy data, combining the strength of structured reasoning with flexible representations. To this end, we introduce the Constitutional Controller (CoCo), a novel framework designed to enhance the safety and reliability of agents by reasoning over deep probabilistic logic programs representing constraints such as those found in shared traffic spaces. Furthermore, we propose the concept of self-doubt, implemented as a probability density conditioned on doubt features such as travel velocity, employed sensors, or health factors. In a real-world aerial mobility study, we demonstrate CoCo's advantages for intelligent autonomous systems to learn appropriate doubts and navigate complex and uncertain environments safely and compliantly.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä¸ç¡®å®šç¯å¢ƒä¸‹è‡ªä¸»æ™ºèƒ½ä½“(autonomous agents)çš„è§„åˆ™éµå¾ªä¸å¯é æ€§æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§åä¸ºConstitutional Controller (CoCo)çš„ç¥ç»ç¬¦å·ç³»ç»Ÿ(neuro-symbolic systems)æ¡†æ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡æ•´åˆæ·±åº¦æ¦‚ç‡é€»è¾‘ç¨‹åº(deep probabilistic logic programs)ä¸æ·±åº¦å­¦ä¹ æ–¹æ³•ï¼Œèƒ½å¤ŸåŒæ—¶å¤„ç†æ˜¾å¼è§„åˆ™å’ŒåŸºäºå™ªå£°æ•°æ®è®­ç»ƒçš„ç¥ç»æ¨¡å‹ï¼Œå®ç°äº†ç»“æ„åŒ–æ¨ç†ä¸çµæ´»è¡¨å¾çš„ç»“åˆã€‚ç ”ç©¶æ ¸å¿ƒå¼•å…¥äº†è‡ªæˆ‘æ€€ç–‘(self-doubt)çš„æ¦‚å¿µï¼Œå°†å…¶å®ç°ä¸ºåŸºäºè¡Œé©¶é€Ÿåº¦ã€ä¼ æ„Ÿå™¨çŠ¶æ€æˆ–å¥åº·å› ç´ ç­‰æ€€ç–‘ç‰¹å¾(doubt features)çš„æ¡ä»¶æ¦‚ç‡å¯†åº¦ã€‚åœ¨çœŸå®ä¸–ç•Œçš„ç©ºä¸­äº¤é€š(aerial mobility)æ¡ˆä¾‹ç ”ç©¶ä¸­ï¼ŒCoCoå±•ç¤ºäº†å­¦ä¹ é€‚åº¦æ€€ç–‘å¹¶å®‰å…¨ã€åˆè§„åœ°å¯¼èˆªå¤æ‚ä¸ç¡®å®šç¯å¢ƒçš„æ˜¾è‘—ä¼˜åŠ¿ã€‚è¿™ä¸€æ–¹æ¡ˆé€šè¿‡åœ¨æ¦‚ç‡é€»è¾‘æ¨¡å‹ä¸­æ¨ç†çº¦æŸæ¡ä»¶ï¼Œæœ‰æ•ˆæå‡äº†è‡ªä¸»ç³»ç»Ÿåœ¨å¤æ‚å…±äº«ç©ºé—´ä¸­çš„å®‰å…¨æ€§å’Œå¯é æ€§ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.15478v1",
      "published_date": "2025-07-21 10:33:31 UTC",
      "updated_date": "2025-07-21 10:33:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:00:59.151872+00:00"
    },
    {
      "arxiv_id": "2507.15469v1",
      "title": "The Emergence of Deep Reinforcement Learning for Path Planning",
      "title_zh": "æ·±åº¦å¼ºåŒ–å­¦ä¹ åœ¨è·¯å¾„è§„åˆ’ä¸­çš„å…´èµ·",
      "authors": [
        "Thanh Thi Nguyen",
        "Saeid Nahavandi",
        "Imran Razzak",
        "Dung Nguyen",
        "Nhat Truong Pham",
        "Quoc Viet Hung Nguyen"
      ],
      "abstract": "The increasing demand for autonomous systems in complex and dynamic environments has driven significant research into intelligent path planning methodologies. For decades, graph-based search algorithms, linear programming techniques, and evolutionary computation methods have served as foundational approaches in this domain. Recently, deep reinforcement learning (DRL) has emerged as a powerful method for enabling autonomous agents to learn optimal navigation strategies through interaction with their environments. This survey provides a comprehensive overview of traditional approaches as well as the recent advancements in DRL applied to path planning tasks, focusing on autonomous vehicles, drones, and robotic platforms. Key algorithms across both conventional and learning-based paradigms are categorized, with their innovations and practical implementations highlighted. This is followed by a thorough discussion of their respective strengths and limitations in terms of computational efficiency, scalability, adaptability, and robustness. The survey concludes by identifying key open challenges and outlining promising avenues for future research. Special attention is given to hybrid approaches that integrate DRL with classical planning techniques to leverage the benefits of both learning-based adaptability and deterministic reliability, offering promising directions for robust and resilient autonomous navigation.",
      "tldr_zh": "è¯¥ç ”ç©¶æ·±å…¥æ¢è®¨äº†å¤æ‚åŠ¨æ€ç¯å¢ƒä¸‹è‡ªä¸»ç³»ç»Ÿçš„è·¯å¾„è§„åˆ’æŠ€æœ¯ï¼Œå…¨é¢ç»¼è¿°äº†ä»ä¼ ç»Ÿçš„ graph-based search algorithmsã€linear programming åˆ°æ–°å…´çš„ Deep Reinforcement Learning (DRL) çš„æ¼”å˜è¿‡ç¨‹ã€‚æ–‡ç« é’ˆå¯¹è‡ªåŠ¨é©¾é©¶ã€æ— äººæœºåŠæœºå™¨äººå¹³å°ä¸­çš„å…³é”®ç®—æ³•è¿›è¡Œäº†åˆ†ç±»ï¼Œå¹¶ç³»ç»Ÿåˆ†æäº†å…¶åœ¨è®¡ç®—æ•ˆç‡ã€å¯æ‰©å±•æ€§ã€é€‚åº”æ€§å’Œé²æ£’æ€§æ–¹é¢çš„ä¼˜åŠ£ã€‚ä½œè€…å¼ºè°ƒäº† DRL åœ¨é€šè¿‡ç¯å¢ƒäº¤äº’å­¦ä¹ æœ€ä¼˜å¯¼èˆªç­–ç•¥æ–¹é¢çš„å¼ºå¤§èƒ½åŠ›ï¼ŒåŒæ—¶æŒ‡å‡ºäº†å½“å‰é¢†åŸŸåœ¨å®é™…åº”ç”¨ä¸­é¢ä¸´çš„å¼€æ”¾æ€§æŒ‘æˆ˜ã€‚ç ”ç©¶æœ€åå±•æœ›äº†æœªæ¥çš„ç§‘ç ”è¶‹åŠ¿ï¼Œç‰¹åˆ«æå‡ºäº†å°† DRL ä¸ç»å…¸è§„åˆ’æŠ€æœ¯ç›¸ç»“åˆçš„æ··åˆæ–¹æ³•ï¼Œæ—¨åœ¨é€šè¿‡ç»“åˆå­¦ä¹ çš„é€‚åº”æ€§ä¸ç¡®å®šæ€§çš„å¯é æ€§ï¼Œä¸ºå®ç°ç¨³å¥çš„è‡ªä¸»å¯¼èˆªæä¾›äº†é‡è¦æ–¹å‘ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted for publication in the Proceedings of the 2025 IEEE International Conference on Systems, Man, and Cybernetics (SMC)",
      "pdf_url": "https://arxiv.org/pdf/2507.15469v1",
      "published_date": "2025-07-21 10:21:42 UTC",
      "updated_date": "2025-07-21 10:21:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:01:06.786163+00:00"
    },
    {
      "arxiv_id": "2507.15465v2",
      "title": "The New LLM Bottleneck: A Systems Perspective on Latent Attention and Mixture-of-Experts",
      "title_zh": "å¤§è¯­è¨€æ¨¡å‹çš„æ–°ç“¶é¢ˆï¼šæ½œå±‚æ³¨æ„åŠ›ä¸ä¸“å®¶æ··åˆçš„ç³»ç»Ÿè§†è§’",
      "authors": [
        "Sungmin Yun",
        "Seonyong Park",
        "Hwayong Nam",
        "Younjoo Lee",
        "Gunjun Lee",
        "Kwanhee Kyung",
        "Sangpyo Kim",
        "Nam Sung Kim",
        "Jongmin Kim",
        "Hyungyo Kim",
        "Juhwan Cho",
        "Seungmin Baek",
        "Jung Ho Ahn"
      ],
      "abstract": "Computational workloads composing traditional Transformer models are starkly bifurcated. Multi-Head Attention (MHA) is memory-bound, with low arithmetic intensity, while feedforward layers are compute-bound. This dichotomy has long motivated research into specialized hardware to mitigate the MHA bottleneck.\n  This paper argues that recent architectural shifts, namely Multi-head Latent Attention (MLA) and Mixture-of-Experts (MoE), challenge the premise of specialized attention hardware. We make two key observations. First, the arithmetic intensity of MLA is over two orders of magnitude greater than that of MHA, shifting it close to a compute-bound regime well-suited for modern accelerators like GPUs. Second, by distributing MoE experts across a pool of accelerators, their arithmetic intensity can be tuned through batching to match that of the dense layers, creating a more balanced computational profile.\n  These findings reveal a diminishing need for specialized attention hardware. The central challenge for next-generation Transformers is no longer accelerating a single memory-bound layer. Instead, the focus must shift to designing balanced systems with sufficient compute, memory capacity, memory bandwidth, and high-bandwidth interconnects to manage the diverse demands of large-scale models.",
      "tldr_zh": "è¯¥ç ”ç©¶ä»ç³»ç»Ÿè§†è§’æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)ä¸­æ–°å‡ºç°çš„ç“¶é¢ˆé—®é¢˜ï¼Œé‡ç‚¹åˆ†æäº†Multi-head Latent Attention (MLA)å’ŒMixture-of-Experts (MoE)å¯¹è®¡ç®—è´Ÿè½½çš„å½±å“ã€‚ä¼ ç»ŸTransformeræ¶æ„ä¸­çš„Multi-Head Attention (MHA)é€šå¸¸å—é™äºå†…å­˜å¸¦å®½(memory-bound)ï¼Œè€Œå‰é¦ˆå±‚åˆ™æ˜¯è®¡ç®—å—é™(compute-bound)çš„ï¼Œè¿™ç§åˆ†åŒ–æ›¾ä¿ƒä½¿äº†å¤§é‡é’ˆå¯¹æ³¨æ„åŠ›æœºåˆ¶çš„ä¸“ç”¨ç¡¬ä»¶ç ”å‘ã€‚ç„¶è€Œï¼Œè®ºæ–‡å‘ç°MLAçš„ç®—æœ¯å¼ºåº¦(arithmetic intensity)æ¯”MHAé«˜å‡ºä¸¤ä¸ªæ•°é‡çº§ä»¥ä¸Šï¼Œä½¿å…¶è½¬å˜ä¸ºæ›´é€‚åˆGPUç­‰ç°ä»£åŠ é€Ÿå™¨çš„è®¡ç®—å—é™æ¨¡å¼ã€‚åŒæ—¶ï¼Œé€šè¿‡åœ¨åŠ é€Ÿå™¨æ± ä¸­åˆ†å¸ƒMoEä¸“å®¶å¹¶é…åˆæ‰¹å¤„ç†(batching)æŠ€æœ¯ï¼Œå¯ä»¥è°ƒèŠ‚å…¶ç®—æœ¯å¼ºåº¦ä»¥åŒ¹é…dense layersï¼Œä»è€Œå®ç°æ›´å¹³è¡¡çš„è®¡ç®—é…ç½®ã€‚è¿™äº›å‘ç°è¡¨æ˜ï¼Œå¼€å‘ä¸“ç”¨æ³¨æ„åŠ›åŠ é€Ÿç¡¬ä»¶çš„éœ€æ±‚æ­£åœ¨å‡å¼±ã€‚ä¸‹ä¸€ä»£Transformerçš„æ ¸å¿ƒæŒ‘æˆ˜å·²ä»åŠ é€Ÿå•ä¸€çš„å†…å­˜å—é™å±‚è½¬å‘è®¾è®¡åŒ…å«å……è¶³è®¡ç®—åŠ›ã€å†…å­˜å®¹é‡ã€å¸¦å®½åŠhigh-bandwidth interconnectsçš„å¹³è¡¡ç³»ç»Ÿï¼Œä»¥åº”å¯¹å¤§è§„æ¨¡æ¨¡å‹çš„å¤šæ ·åŒ–éœ€æ±‚ã€‚",
      "categories": [
        "cs.AR",
        "cs.AI"
      ],
      "primary_category": "cs.AR",
      "comment": "15 pages, 11 figures",
      "pdf_url": "https://arxiv.org/pdf/2507.15465v2",
      "published_date": "2025-07-21 10:18:33 UTC",
      "updated_date": "2025-07-23 20:55:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:01:04.592907+00:00"
    },
    {
      "arxiv_id": "2507.15457v1",
      "title": "Optimization of Activity Batching Policies in Business Processes",
      "title_zh": "ä¸šåŠ¡æµç¨‹ä¸­æ´»åŠ¨åˆ†æ‰¹ç­–ç•¥çš„ä¼˜åŒ–",
      "authors": [
        "Orlenys LÃ³pez-Pintado",
        "Jannis Rosenbaum",
        "Marlon Dumas"
      ],
      "abstract": "In business processes, activity batching refers to packing multiple activity instances for joint execution. Batching allows managers to trade off cost and processing effort against waiting time. Larger and less frequent batches may lower costs by reducing processing effort and amortizing fixed costs, but they create longer waiting times. In contrast, smaller and more frequent batches reduce waiting times but increase fixed costs and processing effort. A batching policy defines how activity instances are grouped into batches and when each batch is activated. This paper addresses the problem of discovering batching policies that strike optimal trade-offs between waiting time, processing effort, and cost. The paper proposes a Pareto optimization approach that starts from a given set (possibly empty) of activity batching policies and generates alternative policies for each batched activity via intervention heuristics. Each heuristic identifies an opportunity to improve an activity's batching policy with respect to a metric (waiting time, processing time, cost, or resource utilization) and an associated adjustment to the activity's batching policy (the intervention). The impact of each intervention is evaluated via simulation. The intervention heuristics are embedded in an optimization meta-heuristic that triggers interventions to iteratively update the Pareto front of the interventions identified so far. The paper considers three meta-heuristics: hill-climbing, simulated annealing, and reinforcement learning. An experimental evaluation compares the proposed approach based on intervention heuristics against the same (non-heuristic guided) meta-heuristics baseline regarding convergence, diversity, and cycle time gain of Pareto-optimal policies.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†ä¸šåŠ¡æµç¨‹ä¸­çš„æ´»åŠ¨åˆ†æ‰¹(Activity Batching)ç­–ç•¥ä¼˜åŒ–é—®é¢˜ï¼Œæ—¨åœ¨å¹³è¡¡æ‰§è¡Œæˆæœ¬ã€å¤„ç†åŠªåŠ›ä¸ç­‰å¾…æ—¶é—´ä¹‹é—´çš„æƒè¡¡ã€‚æ–‡ç« æå‡ºäº†ä¸€ç§åŸºäºPareto optimizationçš„æ–¹æ³•ï¼Œé€šè¿‡å¹²é¢„å¯å‘å¼(Intervention Heuristics)æ¥è‡ªåŠ¨å‘ç°å’Œç”Ÿæˆæœ€ä¼˜çš„æ´»åŠ¨åˆ†æ‰¹ç­–ç•¥ã€‚è¿™äº›å¯å‘å¼æ–¹æ³•é’ˆå¯¹ç­‰å¾…æ—¶é—´ã€å¤„ç†æ—¶é—´ã€æˆæœ¬æˆ–èµ„æºåˆ©ç”¨ç‡ç­‰æ ¸å¿ƒæŒ‡æ ‡è¯†åˆ«æ”¹è¿›æœºä¼šï¼Œå¹¶åˆ©ç”¨ä»¿çœŸ(Simulation)æŠ€æœ¯è¯„ä¼°å„é¡¹å¹²é¢„æªæ–½çš„å®é™…å½±å“ã€‚ç ”ç©¶è¿›ä¸€æ­¥å°†è¿™äº›å¹²é¢„å¯å‘å¼åµŒå…¥åˆ°çˆ¬å±±ç®—æ³•(Hill-climbing)ã€æ¨¡æ‹Ÿé€€ç«(Simulated Annealing)å’Œå¼ºåŒ–å­¦ä¹ (Reinforcement Learning)ä¸‰ç§å…ƒå¯å‘å¼æ¡†æ¶ä¸­è¿›è¡Œè¿­ä»£ä¼˜åŒ–ã€‚å®éªŒè¯„ä¼°å¯¹æ¯”äº†è¯¥æ–¹æ³•ä¸ä¼ ç»Ÿå…ƒå¯å‘å¼åŸºå‡†åœ¨æ”¶æ•›æ€§ã€è§£çš„å¤šæ ·æ€§ä»¥åŠå‘¨æœŸæ—¶é—´æ”¶ç›Šæ–¹é¢çš„è¡¨ç°ã€‚ç»“æœè¯æ˜ï¼ŒåŸºäºå¹²é¢„å¯å‘å¼çš„ä¼˜åŒ–æ–¹æ³•èƒ½æ›´æœ‰æ•ˆåœ°è¯†åˆ«Pareto-optimalç­–ç•¥ï¼Œä¸ºæå‡ä¸šåŠ¡æµç¨‹çš„è¿è¡Œæ•ˆç‡æä¾›äº†ç§‘å­¦çš„å†³ç­–å·¥å…·ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.15457v1",
      "published_date": "2025-07-21 10:11:51 UTC",
      "updated_date": "2025-07-21 10:11:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:01:27.095852+00:00"
    },
    {
      "arxiv_id": "2508.00011v1",
      "title": "AoI-Aware Resource Allocation with Deep Reinforcement Learning for HAPS-V2X Networks",
      "title_zh": "HAPS-V2X ç½‘ç»œä¸­åŸºäºæ·±åº¦å¼ºåŒ–å­¦ä¹ çš„ AoI æ„ŸçŸ¥èµ„æºåˆ†é…",
      "authors": [
        "Ahmet Melih Ince",
        "Ayse Elif Canbilen",
        "Halim Yanikomeroglu"
      ],
      "abstract": "Sixth-generation (6G) networks are designed to meet the hyper-reliable and low-latency communication (HRLLC) requirements of safety-critical applications such as autonomous driving. Integrating non-terrestrial networks (NTN) into the 6G infrastructure brings redundancy to the network, ensuring continuity of communications even under extreme conditions. In particular, high-altitude platform stations (HAPS) stand out for their wide coverage and low latency advantages, supporting communication reliability and enhancing information freshness, especially in rural areas and regions with infrastructure constraints. In this paper, we present reinforcement learning-based approaches using deep deterministic policy gradient (DDPG) to dynamically optimize the age-of-information (AoI) in HAPS-enabled vehicle-to-everything (V2X) networks. The proposed method improves information freshness and overall network reliability by enabling independent learning without centralized coordination. The findings reveal the potential of HAPS-supported solutions, combined with DDPG-based learning, for efficient AoI-aware resource allocation in platoon-based autonomous vehicle systems.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹6Gç½‘ç»œä¸­è‡ªåŠ¨é©¾é©¶ç­‰å…³é”®åº”ç”¨å¯¹è¶…é«˜å¯é ä½å»¶è¿Ÿé€šä¿¡(HRLLC)çš„éœ€æ±‚ï¼Œæå‡ºäº†ä¸€ç§å°†é«˜ç©ºå¹³å°ç«™(HAPS)é›†æˆè‡³V2Xç½‘ç»œçš„æ¶æ„ã€‚ä¸ºäº†åœ¨åŸºç¡€è®¾æ–½å—é™æˆ–åè¿œåœ°åŒºç»´æŒé€šä¿¡è¿ç»­æ€§å¹¶ä¼˜åŒ–ä¿¡æ¯æ–°é²œåº¦ï¼Œæ–‡ç« é‡‡ç”¨äº†åŸºäºæ·±åº¦ç¡®å®šæ€§ç­–ç•¥æ¢¯åº¦(DDPG)çš„æ·±åº¦å¼ºåŒ–å­¦ä¹ (Deep Reinforcement Learning)æ–¹æ³•æ¥è¿›è¡ŒåŠ¨æ€çš„ä¿¡æ¯é¾„(Age-of-Information, AoI)æ„ŸçŸ¥èµ„æºåˆ†é…ã€‚è¯¥æ–¹æ¡ˆå…è®¸è½¦è¾†åœ¨æ— éœ€ä¸­å¿ƒåŒ–åè°ƒçš„æƒ…å†µä¸‹è¿›è¡Œç‹¬ç«‹å­¦ä¹ ï¼Œä»è€Œæœ‰æ•ˆæå‡äº†ç½‘ç»œå¯é æ€§ä¸æ•°æ®å®æ—¶æ€§ã€‚ç ”ç©¶ç»“æœè¯æ˜äº†HAPSæ”¯æŒçš„è§£å†³æ–¹æ¡ˆä¸DDPGç®—æ³•ç»“åˆåœ¨è½¦é˜Ÿå¼(Platoon-based)è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿä¸­çš„åº”ç”¨æ½œåŠ›ã€‚è¿™ä¸€æ–¹æ³•ä¸ºæœªæ¥éåœ°é¢ç½‘ç»œ(NTN)çš„èµ„æºç®¡ç†æä¾›äº†é«˜æ•ˆçš„AoIæ„ŸçŸ¥ä¼˜åŒ–è·¯å¾„ã€‚",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.LG",
        "cs.MA",
        "eess.SY"
      ],
      "primary_category": "cs.NI",
      "comment": "6 pages, 3 figures, to appear in IEEE conference proceedings",
      "pdf_url": "https://arxiv.org/pdf/2508.00011v1",
      "published_date": "2025-07-21 10:11:12 UTC",
      "updated_date": "2025-07-21 10:11:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:01:41.647943+00:00"
    },
    {
      "arxiv_id": "2507.19529v2",
      "title": "Machine Learning Risk Intelligence for Green Hydrogen Investment: Insights for Duqm R3 Auction",
      "title_zh": "ç»¿æ°¢æŠ•èµ„çš„æœºå™¨å­¦ä¹ é£é™©æƒ…æŠ¥ï¼šå¯¹ Duqm R3 æ‹å–çš„å¯ç¤º",
      "authors": [
        "Obumneme Nwafor",
        "Mohammed Abdul Majeed Al Hooti"
      ],
      "abstract": "As green hydrogen emerges as a major component of global decarbonisation, Oman has positioned itself strategically through national auctions and international partnerships. Following two successful green hydrogen project rounds, the country launched its third auction (R3) in the Duqm region. While this area exhibits relative geospatial homogeneity, it is still vulnerable to environmental fluctuations that pose inherent risks to productivity. Despite growing global investment in green hydrogen, operational data remains scarce, with major projects like Saudi Arabia's NEOM facility not expected to commence production until 2026, and Oman's ACME Duqm project scheduled for 2028. This absence of historical maintenance and performance data from large-scale hydrogen facilities in desert environments creates a major knowledge gap for accurate risk assessment for infrastructure planning and auction decisions. Given this data void, environmental conditions emerge as accessible and reliable proxy for predicting infrastructure maintenance pressures, because harsh desert conditions such as dust storms, extreme temperatures, and humidity fluctuations are well-documented drivers of equipment degradation in renewable energy systems. To address this challenge, this paper proposes an Artificial Intelligence decision support system that leverages publicly available meteorological data to develop a predictive Maintenance Pressure Index (MPI), which predicts risk levels and future maintenance demands on hydrogen infrastructure. This tool strengthens regulatory foresight and operational decision-making by enabling temporal benchmarking to assess and validate performance claims over time. It can be used to incorporate temporal risk intelligence into auction evaluation criteria despite the absence of historical operational benchmarks.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹é˜¿æ›¼æœåº“å§†(Duqm)R3ç»¿æ°¢æ‹å–èƒŒæ™¯ä¸‹ç¼ºä¹å¤§è§„æ¨¡æ°¢èƒ½è®¾æ–½å†å²è¿è¡Œæ•°æ®çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºäººå·¥æ™ºèƒ½(Artificial Intelligence)çš„å†³ç­–æ”¯æŒç³»ç»Ÿã€‚ç”±äºæ²™æ¼ æç«¯ç¯å¢ƒï¼ˆå¦‚æ²™å°˜æš´ã€é«˜æ¸©å’Œæ¹¿åº¦æ³¢åŠ¨ï¼‰æ˜¯å¯¼è‡´è®¾å¤‡é€€åŒ–çš„å…³é”®å› ç´ ï¼Œç ”ç©¶åˆ©ç”¨å…¬å¼€çš„æ°”è±¡æ•°æ®æ„å»ºäº†é¢„æµ‹æ€§ç»´æŠ¤å‹åŠ›æŒ‡æ•°(Maintenance Pressure Index, MPI)ï¼Œä»¥é¢„æµ‹åŸºç¡€è®¾æ–½çš„ç»´æŠ¤éœ€æ±‚å’Œé£é™©æ°´å¹³ã€‚è¯¥ç³»ç»Ÿå°†ç¯å¢ƒæ¡ä»¶ä½œä¸ºè¯„ä¼°é£é™©çš„å¯é æ›¿ä»£æŒ‡æ ‡ï¼Œæœ‰æ•ˆå¼¥è¡¥äº†å½“å‰ç»¿æ°¢é¡¹ç›®å› å°šæœªæŠ•äº§è€Œäº§ç”Ÿçš„æ•°æ®ç©ºç™½ã€‚é€šè¿‡å¼•å…¥MPIè¿›è¡Œæ—¶é—´åŸºå‡†æµ‹è¯•(Temporal Benchmarking)ï¼Œç›‘ç®¡æœºæ„å¯ä»¥åœ¨ç¼ºä¹å†å²è¿è¡ŒåŸºå‡†çš„æƒ…å†µä¸‹éªŒè¯æŠ•æ ‡æ–¹çš„æ€§èƒ½å£°æ˜ã€‚è¿™é¡¹ç ”ç©¶ä¸ºç»¿æ°¢æ‹å–è¯„ä¼°æ ‡å‡†æä¾›äº†å…³é”®çš„é£é™©æƒ…æŠ¥ï¼Œæ˜¾è‘—å¢å¼ºäº†æ”¿ç­–åˆ¶å®šè€…çš„ç›‘ç®¡é¢„è§èƒ½åŠ›ä¸æŠ•èµ„è€…çš„è¿è¥å†³ç­–æ°´å¹³ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Updated version",
      "pdf_url": "https://arxiv.org/pdf/2507.19529v2",
      "published_date": "2025-07-21 10:11:06 UTC",
      "updated_date": "2025-07-29 08:31:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:01:31.288804+00:00"
    },
    {
      "arxiv_id": "2507.15455v2",
      "title": "Solving nonconvex Hamilton--Jacobi--Isaacs equations with PINN-based policy iteration",
      "title_zh": "åŸºäº PINN ç­–ç•¥è¿­ä»£çš„éå‡¸ Hamilton--Jacobi--Isaacs æ–¹ç¨‹æ±‚è§£",
      "authors": [
        "Hee Jun Yang",
        "Minjung Gim",
        "Yeoneung Kim"
      ],
      "abstract": "We propose a mesh-free policy iteration framework that combines classical dynamic programming with physics-informed neural networks (PINNs) to solve high-dimensional, nonconvex Hamilton--Jacobi--Isaacs (HJI) equations arising in stochastic differential games and robust control. The method alternates between solving linear second-order PDEs under fixed feedback policies and updating the controls via pointwise minimax optimization using automatic differentiation. Under standard Lipschitz and uniform ellipticity assumptions, we prove that the value function iterates converge locally uniformly to the unique viscosity solution of the HJI equation. The analysis establishes equi-Lipschitz regularity of the iterates, enabling provable stability and convergence without requiring convexity of the Hamiltonian. Numerical experiments demonstrate the accuracy and scalability of the method. In a two-dimensional stochastic path-planning game with a moving obstacle, our method matches finite-difference benchmarks with relative $L^2$-errors below %10^{-2}%. In five- and ten-dimensional publisher-subscriber differential games with anisotropic noise, the proposed approach consistently outperforms direct PINN solvers, yielding smoother value functions and lower residuals. Our results suggest that integrating PINNs with policy iteration is a practical and theoretically grounded method for solving high-dimensional, nonconvex HJI equations, with potential applications in robotics, finance, and multi-agent reinforcement learning.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§æ— ç½‘æ ¼çš„ç­–ç•¥è¿­ä»£(policy iteration)æ¡†æ¶ï¼Œé€šè¿‡ç»“åˆç»å…¸åŠ¨æ€è§„åˆ’ä¸ç‰©ç†ä¿¡æ¯ç¥ç»ç½‘ç»œ(PINNs)ï¼Œæ—¨åœ¨è§£å†³éšæœºå¾®åˆ†å¯¹ç­–å’Œç¨³å¥æ§åˆ¶ä¸­çš„é«˜ç»´ã€éå‡¸Hamilton--Jacobi--Isaacs (HJI)æ–¹ç¨‹ã€‚è¯¥æ–¹æ³•åœ¨å›ºå®šåé¦ˆç­–ç•¥ä¸‹äº¤æ›¿æ±‚è§£çº¿æ€§äºŒé˜¶åå¾®åˆ†æ–¹ç¨‹(PDEs)ï¼Œå¹¶åˆ©ç”¨è‡ªåŠ¨å¾®åˆ†(automatic differentiation)é€šè¿‡é€ç‚¹æå°æå¤§ä¼˜åŒ–(pointwise minimax optimization)æ¥æ›´æ–°æ§åˆ¶ç­–ç•¥ã€‚åœ¨æ ‡å‡†Lipschitzå’Œä¸€è‡´æ¤­åœ†æ€§å‡è®¾ä¸‹ï¼Œè¯¥ç ”ç©¶ä»ç†è®ºä¸Šè¯æ˜äº†ä»·å€¼å‡½æ•°è¿­ä»£å±€éƒ¨ä¸€è‡´æ”¶æ•›äºHJIæ–¹ç¨‹çš„å”¯ä¸€ç²˜æ€§è§£(viscosity solution)ï¼Œä¸”æ— éœ€Hamiltoniançš„å‡¸æ€§å³å¯ç¡®ç«‹ç¨³å®šæ€§ã€‚æ•°å€¼å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨äºŒç»´éšæœºè·¯å¾„è§„åˆ’åšå¼ˆä¸­è¾¾åˆ°äº†ä½äº$10^{-2}$çš„ç›¸å¯¹$L^2$è¯¯å·®ï¼Œå¹¶åœ¨äº”ç»´å’Œåç»´çš„å¾®åˆ†åšå¼ˆä¸­å§‹ç»ˆä¼˜äºç›´æ¥PINNæ±‚è§£å™¨ï¼Œè¡¨ç°å‡ºæ›´é«˜çš„å¹³æ»‘åº¦å’Œæ›´ä½çš„æ®‹å·®ã€‚ç ”ç©¶ç»“æœè¯æ˜äº†å°†PINNsä¸ç­–ç•¥è¿­ä»£ç»“åˆæ˜¯æ±‚è§£é«˜ç»´éå‡¸HJIæ–¹ç¨‹çš„ä¸€ç§æ—¢æœ‰ç†è®ºæ”¯æ’‘åˆå…·å®ç”¨æ€§çš„æ–¹æ¡ˆï¼Œåœ¨æœºå™¨äººã€é‡‘èåŠå¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ç­‰é¢†åŸŸå±•ç°å‡ºå·¨å¤§çš„åº”ç”¨æ½œåŠ›ã€‚",
      "categories": [
        "math.NA",
        "cs.AI",
        "math.AP"
      ],
      "primary_category": "math.NA",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.15455v2",
      "published_date": "2025-07-21 10:06:53 UTC",
      "updated_date": "2025-07-23 10:44:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:01:43.046429+00:00"
    },
    {
      "arxiv_id": "2507.15454v1",
      "title": "ObjectGS: Object-aware Scene Reconstruction and Scene Understanding via Gaussian Splatting",
      "title_zh": "ObjectGSï¼šåŸºäºé«˜æ–¯æ³¼æº…çš„ç‰©ä½“æ„ŸçŸ¥åœºæ™¯é‡å»ºä¸åœºæ™¯ç†è§£",
      "authors": [
        "Ruijie Zhu",
        "Mulin Yu",
        "Linning Xu",
        "Lihan Jiang",
        "Yixuan Li",
        "Tianzhu Zhang",
        "Jiangmiao Pang",
        "Bo Dai"
      ],
      "abstract": "3D Gaussian Splatting is renowned for its high-fidelity reconstructions and real-time novel view synthesis, yet its lack of semantic understanding limits object-level perception. In this work, we propose ObjectGS, an object-aware framework that unifies 3D scene reconstruction with semantic understanding. Instead of treating the scene as a unified whole, ObjectGS models individual objects as local anchors that generate neural Gaussians and share object IDs, enabling precise object-level reconstruction. During training, we dynamically grow or prune these anchors and optimize their features, while a one-hot ID encoding with a classification loss enforces clear semantic constraints. We show through extensive experiments that ObjectGS not only outperforms state-of-the-art methods on open-vocabulary and panoptic segmentation tasks, but also integrates seamlessly with applications like mesh extraction and scene editing. Project page: https://ruijiezhu94.github.io/ObjectGS_page",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ObjectGSï¼Œä¸€ä¸ªå°†3Dåœºæ™¯é‡å»ºä¸è¯­ä¹‰ç†è§£ç›¸ç»Ÿä¸€çš„ç‰©ä½“æ„ŸçŸ¥æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³3D Gaussian Splattingåœ¨ç‰©ä½“çº§æ„ŸçŸ¥æ–¹é¢çš„å±€é™æ€§ã€‚ObjectGSä¸å°†åœºæ™¯è§†ä¸ºç»Ÿä¸€æ•´ä½“ï¼Œè€Œæ˜¯å°†å•ä¸ªç‰©ä½“å»ºæ¨¡ä¸ºç”Ÿæˆç¥ç»é«˜æ–¯çš„å±€éƒ¨anchorså¹¶å…±äº«object IDsï¼Œä»è€Œå®ç°ç²¾ç¡®çš„ç‰©ä½“çº§é‡å»ºã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œè¯¥æ¡†æ¶åŠ¨æ€å¢é•¿æˆ–ä¿®å‰ªè¿™äº›anchorså¹¶ä¼˜åŒ–å…¶ç‰¹å¾ï¼ŒåŒæ—¶åˆ©ç”¨one-hot ID encodingå’Œclassification lossæ¥æ–½åŠ æ˜ç¡®çš„è¯­ä¹‰çº¦æŸã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒObjectGSåœ¨open-vocabularyå’Œpanoptic segmentationä»»åŠ¡ä¸Šå‡ä¼˜äºå½“å‰æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶è¿˜èƒ½æ— ç¼é›†æˆåˆ°mesh extractionå’Œåœºæ™¯ç¼–è¾‘ç­‰ä¸‹æ¸¸åº”ç”¨ä¸­ï¼Œå±•ç¤ºäº†å¼ºå¤§çš„å®ç”¨æ€§ã€‚",
      "categories": [
        "cs.GR",
        "cs.AI",
        "cs.CV",
        "cs.HC"
      ],
      "primary_category": "cs.GR",
      "comment": "Accepted by ICCV 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.15454v1",
      "published_date": "2025-07-21 10:06:23 UTC",
      "updated_date": "2025-07-21 10:06:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:01:38.853169+00:00"
    },
    {
      "arxiv_id": "2507.15428v1",
      "title": "EgoPrune: Efficient Token Pruning for Egomotion Video Reasoning in Embodied Agent",
      "title_zh": "EgoPruneï¼šé¢å‘å…·èº«æ™ºèƒ½ä½“è‡ªè¿åŠ¨è§†é¢‘æ¨ç†çš„é«˜æ•ˆ Token å‰ªæ",
      "authors": [
        "Jiaao Li",
        "Kaiyuan Li",
        "Chen Gao",
        "Yong Li",
        "Xinlei Chen"
      ],
      "abstract": "Egomotion videos are first-person recordings where the view changes continuously due to the agent's movement. As they serve as the primary visual input for embodied AI agents, making egomotion video reasoning more efficient is therefore essential for real-world deployment. Recent advances in vision-language models have enabled strong multimodal reasoning capabilities, but their computational cost remains prohibitive for long, redundant video inputs. Existing token pruning methods, typically designed for third-person videos, fail to leverage the spatiotemporal continuity and motion constraints inherent in egomotion settings. To address this, we propose EgoPrune, a training-free token pruning method tailored for egomotion video reasoning. EgoPrune comprises three components: a keyframe selector adapted from EmbodiedR for temporally efficient sampling; Perspective-Aware Redundancy Filtering (PARF), which aligns visual tokens using perspective transformations and removes redundant tokens; and a Maximal Marginal Relevance (MMR)-based token selector that jointly considers visual-text relevance and intra-frame diversity. Experiments on two egomotion video benchmarks show that EgoPrune consistently outperforms prior training-free methods across various pruning ratios while significantly reducing FLOPs, memory usage, and latency. Moreover, we deploy EgoPrune on an embodied agent equipped with a Jetson Orin NX 16GB edge device, demonstrating its real-world efficiency and suitability for on-device egomotion video reasoning.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å…·èº«æ™ºèƒ½ä½“(Embodied Agent)åœ¨ç¬¬ä¸€è§†è§’è§†é¢‘(Egomotion Video)æ¨ç†ä¸­é¢ä¸´çš„è®¡ç®—æˆæœ¬é«˜æ˜‚åŠè§†é¢‘å†—ä½™é—®é¢˜ï¼Œæå‡ºäº†EgoPruneï¼Œä¸€ç§ä¸“ä¸ºè¯¥åœºæ™¯å®šåˆ¶çš„æ— éœ€è®­ç»ƒçš„Token Pruningæ–¹æ³•ã€‚EgoPruneç”±ä¸‰ä¸ªæ ¸å¿ƒæ¨¡å—ç»„æˆï¼šä¸€æ˜¯é€‚é…è‡ªEmbodiedRçš„å…³é”®å¸§é€‰æ‹©å™¨ä»¥å®ç°é«˜æ•ˆçš„æ—¶é—´é‡‡æ ·ï¼›äºŒæ˜¯åˆ©ç”¨é€è§†æ„ŸçŸ¥å†—ä½™è¿‡æ»¤(Perspective-Aware Redundancy Filtering, PARF)é€šè¿‡é€è§†å˜æ¢å¯¹é½è§†è§‰Tokenå¹¶å‰”é™¤å†—ä½™ï¼›ä¸‰æ˜¯åŸºäºæœ€å¤§è¾¹é™…ç›¸å…³æ€§(MMR)çš„Tokené€‰æ‹©å™¨ï¼Œç”¨äºååŒä¼˜åŒ–è§†è§‰-æ–‡æœ¬ç›¸å…³æ€§ä¸å¸§å†…å¤šæ ·æ€§ã€‚å®éªŒè¯æ˜ï¼ŒEgoPruneåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å‡ä¼˜äºç°æœ‰çš„æ— éœ€è®­ç»ƒæ–¹æ³•ï¼Œä¸”åœ¨ä¸åŒä¿®å‰ªæ¯”ä¾‹ä¸‹å‡å¤§å¹…é™ä½äº†FLOPsã€å†…å­˜å ç”¨å’Œæ¨ç†å»¶è¿Ÿã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜åœ¨æ­è½½Jetson Orin NXè¾¹ç¼˜è®¾å¤‡çš„å…·èº«æ™ºèƒ½ä½“ä¸ŠæˆåŠŸéƒ¨ç½²äº†EgoPruneï¼Œå……åˆ†å±•ç¤ºäº†å…¶åœ¨å®é™…è®¾å¤‡ç«¯è¿›è¡Œé«˜æ•ˆç¬¬ä¸€è§†è§’è§†é¢‘æ¨ç†çš„æ½œåŠ›ä¸å®ç”¨ä»·å€¼ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.15428v1",
      "published_date": "2025-07-21 09:27:45 UTC",
      "updated_date": "2025-07-21 09:27:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:01:47.310103+00:00"
    },
    {
      "arxiv_id": "2507.16852v1",
      "title": "SynthCTI: LLM-Driven Synthetic CTI Generation to enhance MITRE Technique Mapping",
      "title_zh": "SynthCTIï¼šæ—¨åœ¨å¢å¼º MITRE æŠ€æœ¯æ˜ å°„çš„å¤§è¯­è¨€æ¨¡å‹é©±åŠ¨åˆæˆ CTI ç”Ÿæˆ",
      "authors": [
        "Ãlvaro Ruiz-RÃ³denas",
        "Jaime Pujante SÃ¡ez",
        "Daniel GarcÃ­a-Algora",
        "Mario RodrÃ­guez BÃ©jar",
        "Jorge Blasco",
        "JosÃ© Luis HernÃ¡ndez-Ramos"
      ],
      "abstract": "Cyber Threat Intelligence (CTI) mining involves extracting structured insights from unstructured threat data, enabling organizations to understand and respond to evolving adversarial behavior. A key task in CTI mining is mapping threat descriptions to MITRE ATT\\&CK techniques. However, this process is often performed manually, requiring expert knowledge and substantial effort. Automated approaches face two major challenges: the scarcity of high-quality labeled CTI data and class imbalance, where many techniques have very few examples. While domain-specific Large Language Models (LLMs) such as SecureBERT have shown improved performance, most recent work focuses on model architecture rather than addressing the data limitations. In this work, we present SynthCTI, a data augmentation framework designed to generate high-quality synthetic CTI sentences for underrepresented MITRE ATT\\&CK techniques. Our method uses a clustering-based strategy to extract semantic context from training data and guide an LLM in producing synthetic CTI sentences that are lexically diverse and semantically faithful. We evaluate SynthCTI on two publicly available CTI datasets, CTI-to-MITRE and TRAM, using LLMs with different capacity. Incorporating synthetic data leads to consistent macro-F1 improvements: for example, ALBERT improves from 0.35 to 0.52 (a relative gain of 48.6\\%), and SecureBERT reaches 0.6558 (up from 0.4412). Notably, smaller models augmented with SynthCTI outperform larger models trained without augmentation, demonstrating the value of data generation methods for building efficient and effective CTI classification systems.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç½‘ç»œå¨èƒæƒ…æŠ¥(Cyber Threat Intelligence, CTI)æŒ–æ˜ä¸­MITRE ATT&CKæŠ€æœ¯æ˜ å°„é¢ä¸´çš„é«˜è´¨é‡æ ‡æ³¨æ•°æ®ç¨€ç¼ºå’Œç±»åˆ«ä¸å¹³è¡¡æŒ‘æˆ˜ï¼Œæå‡ºäº†SynthCTIæ¡†æ¶ã€‚SynthCTIæ˜¯ä¸€ç§å¤§è¯­è¨€æ¨¡å‹(LLMs)é©±åŠ¨çš„æ•°æ®å¢å¼ºæ¡†æ¶ï¼Œä¸“é—¨ç”¨äºä¸ºæ ·æœ¬è¾ƒå°‘çš„MITRE ATT&CKæŠ€æœ¯ç”Ÿæˆé«˜è´¨é‡çš„åˆæˆå¥å­ã€‚è¯¥æ–¹æ³•é€šè¿‡åŸºäºèšç±»(clustering-based)çš„ç­–ç•¥æå–è®­ç»ƒæ•°æ®çš„è¯­ä¹‰ä¸Šä¸‹æ–‡ï¼Œå¼•å¯¼LLMäº§å‡ºè¯æ±‡å¤šæ ·ä¸”è¯­ä¹‰å¿ å®çš„åˆæˆCTIæ ·æœ¬ã€‚å®éªŒåœ¨CTI-to-MITREå’ŒTRAMæ•°æ®é›†ä¸Šçš„è¯„ä¼°ç»“æœè¡¨æ˜ï¼Œåˆæˆæ•°æ®çš„å¼•å…¥å¸¦æ¥äº†æ˜¾è‘—çš„macro-F1æå‡ï¼Œå…¶ä¸­SecureBERTçš„æ€§èƒ½ä»0.4412æé«˜åˆ°äº†0.6558ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œç»è¿‡SynthCTIå¢å¼ºçš„å°è§„æ¨¡æ¨¡å‹ç”šè‡³ä¼˜äºæœªå¢å¼ºçš„å¤§è§„æ¨¡æ¨¡å‹ï¼Œå……åˆ†éªŒè¯äº†è¯¥æ•°æ®ç”Ÿæˆæ–¹æ³•åœ¨æ„å»ºé«˜æ•ˆä¸”ç²¾å‡†çš„CTIåˆ†ç±»ç³»ç»Ÿæ–¹é¢çš„æ ¸å¿ƒä»·å€¼ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "17 pages, 13 figures",
      "pdf_url": "https://arxiv.org/pdf/2507.16852v1",
      "published_date": "2025-07-21 09:22:39 UTC",
      "updated_date": "2025-07-21 09:22:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:01:44.444990+00:00"
    },
    {
      "arxiv_id": "2508.03706v2",
      "title": "Controllable Surface Diffusion Generative Model for Neurodevelopmental Trajectories",
      "title_zh": "é¢å‘ç¥ç»å‘è‚²è½¨è¿¹çš„å¯æ§è¡¨é¢æ‰©æ•£ç”Ÿæˆæ¨¡å‹",
      "authors": [
        "Zhenshan Xie",
        "Levente Baljer",
        "M. Jorge Cardoso",
        "Emma Robinson"
      ],
      "abstract": "Preterm birth disrupts the typical trajectory of cortical neurodevelopment, increasing the risk of cognitive and behavioral difficulties. However, outcomes vary widely, posing a significant challenge for early prediction. To address this, individualized simulation offers a promising solution by modeling subject-specific neurodevelopmental trajectories, enabling the identification of subtle deviations from normative patterns that might act as biomarkers of risk. While generative models have shown potential for simulating neurodevelopment, prior approaches often struggle to preserve subject-specific cortical folding patterns or to reproduce region-specific morphological variations. In this paper, we present a novel graph-diffusion network that supports controllable simulation of cortical maturation. Using cortical surface data from the developing Human Connectome Project (dHCP), we demonstrate that the model maintains subject-specific cortical morphology while modeling cortical maturation sufficiently well to fool an independently trained age regression network, achieving a prediction accuracy of $0.85 \\pm 0.62$.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ—©äº§ï¼ˆPreterm birthï¼‰å¯¼è‡´çš„çš®å±‚ç¥ç»å‘è‚²è½¨è¿¹ä¸­æ–­åŠè®¤çŸ¥è¡Œä¸ºéšœç¢é£é™©ï¼Œæå‡ºäº†ä¸€ç§æ–°å‹çš„å›¾æ‰©æ•£ç½‘ç»œï¼ˆgraph-diffusion networkï¼‰ï¼Œæ—¨åœ¨å®ç°å¯¹çš®å±‚å‘è‚²ï¼ˆcortical maturationï¼‰çš„å¯æ§æ¨¡æ‹Ÿã€‚é’ˆå¯¹ç°æœ‰ç”Ÿæˆæ¨¡å‹éš¾ä»¥ä¿ç•™ä¸ªä½“ç‰¹æœ‰çš„çš®å±‚è¤¶çš±æ¨¡å¼æˆ–åŒºåŸŸå½¢æ€å·®å¼‚çš„é—®é¢˜ï¼Œè¯¥æ¨¡å‹åˆ©ç”¨æ¥è‡ªdeveloping Human Connectome Project (dHCP) çš„çš®å±‚è¡¨é¢æ•°æ®ï¼Œåœ¨æ¨¡æ‹Ÿå‘è‚²è¿‡ç¨‹çš„åŒæ—¶ç²¾å‡†ä¿æŒäº†å—è¯•è€…ç‰¹æœ‰çš„å½¢æ€ç‰¹å¾ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¨¡å‹ç”Ÿæˆçš„æ¨¡æ‹Ÿç»“æœèƒ½å¤Ÿæœ‰æ•ˆè¯¯å¯¼ç‹¬ç«‹è®­ç»ƒçš„å¹´é¾„å›å½’ç½‘ç»œï¼Œè¾¾åˆ° $0.85 \\pm 0.62$ çš„é¢„æµ‹å‡†ç¡®ç‡ã€‚è¯¥ç ”ç©¶ä¸ºé€šè¿‡ä¸ªä½“åŒ–æ¨¡æ‹Ÿè¯†åˆ«å‘è‚²åç¦»è§„èŒƒæ¨¡å¼çš„ç”Ÿç‰©æ ‡å¿—ç‰©æä¾›äº†æœ‰åŠ›å·¥å…·ï¼Œæœ‰åŠ©äºå¯¹æ—©äº§å„¿å‘è‚²é£é™©è¿›è¡Œæ—©æœŸé¢„æµ‹ã€‚",
      "categories": [
        "q-bio.NC",
        "cs.AI"
      ],
      "primary_category": "q-bio.NC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.03706v2",
      "published_date": "2025-07-21 09:16:24 UTC",
      "updated_date": "2025-09-18 06:38:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:01:52.212955+00:00"
    },
    {
      "arxiv_id": "2507.15411v1",
      "title": "Predictive Process Monitoring Using Object-centric Graph Embeddings",
      "title_zh": "åŸºäºä»¥å¯¹è±¡ä¸ºä¸­å¿ƒå›¾åµŒå…¥çš„é¢„æµ‹æ€§æµç¨‹ç›‘æ§",
      "authors": [
        "Wissam Gherissi",
        "Mehdi Acheli",
        "Joyce El Haddad",
        "Daniela Grigori"
      ],
      "abstract": "Object-centric predictive process monitoring explores and utilizes object-centric event logs to enhance process predictions. The main challenge lies in extracting relevant information and building effective models. In this paper, we propose an end-to-end model that predicts future process behavior, focusing on two tasks: next activity prediction and next event time. The proposed model employs a graph attention network to encode activities and their relationships, combined with an LSTM network to handle temporal dependencies. Evaluated on one reallife and three synthetic event logs, the model demonstrates competitive performance compared to state-of-the-art methods.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶é’ˆå¯¹ä»¥å¯¹è±¡ä¸ºä¸­å¿ƒ(Object-centric)çš„é¢„æµ‹æ€§æµç¨‹ç›‘æ§ä¸­ä¿¡æ¯æå–å’Œå»ºæ¨¡çš„æŒ‘æˆ˜ï¼Œæ—¨åœ¨åˆ©ç”¨ä»¥å¯¹è±¡ä¸ºä¸­å¿ƒçš„äº‹ä»¶æ—¥å¿—(event logs)æ¥ä¼˜åŒ–æµç¨‹é¢„æµ‹ã€‚è®ºæ–‡æå‡ºäº†ä¸€ç§ç«¯åˆ°ç«¯(end-to-end)æ¨¡å‹ï¼Œä¸“é—¨ç”¨äºé¢„æµ‹æœªæ¥æµç¨‹è¡Œä¸ºï¼Œé‡ç‚¹å…³æ³¨ä¸‹ä¸€æ´»åŠ¨é¢„æµ‹(next activity prediction)å’Œä¸‹ä¸€äº‹ä»¶æ—¶é—´é¢„æµ‹(next event time)ä¸¤ä¸ªä»»åŠ¡ã€‚è¯¥æ¨¡å‹é‡‡ç”¨å›¾æ³¨æ„åŠ›ç½‘ç»œ(graph attention network)å¯¹æ´»åŠ¨åŠå…¶ç›¸äº’å…³ç³»è¿›è¡Œç¼–ç ï¼Œå¹¶ç»“åˆé•¿çŸ­æœŸè®°å¿†ç½‘ç»œ(LSTM)æ¥å¤„ç†æµç¨‹ä¸­çš„æ—¶é—´ä¾èµ–æ€§(temporal dependencies)ã€‚ç ”ç©¶äººå‘˜é€šè¿‡ä¸€ä¸ªçœŸå®æ¡ˆä¾‹å’Œä¸‰ä¸ªåˆæˆäº‹ä»¶æ—¥å¿—å¯¹è¯¥æ¨¡å‹è¿›è¡Œäº†è¯„ä¼°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¨¡å‹åœ¨é¢„æµ‹æ€§èƒ½ä¸Šä¸ç°æœ‰æœ€å…ˆè¿›(state-of-the-art)çš„æ–¹æ³•ç›¸æ¯”å…·æœ‰å¾ˆå¼ºçš„ç«äº‰åŠ›ã€‚è¿™è¯æ˜äº†åˆ©ç”¨å¯¹è±¡ä¸­å¿ƒå›¾åµŒå…¥(object-centric graph embeddings)æŠ€æœ¯èƒ½æ›´æœ‰æ•ˆåœ°æ•æ‰å¤æ‚æµç¨‹ä¸­çš„äº¤äº’ä¿¡æ¯å¹¶æå‡é¢„æµ‹å‡†ç¡®åº¦ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "ICSOC Workshops 2024, Dec 2024, Tunis, Tunisia",
      "pdf_url": "https://arxiv.org/pdf/2507.15411v1",
      "published_date": "2025-07-21 09:10:49 UTC",
      "updated_date": "2025-07-21 09:10:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:01:55.649096+00:00"
    },
    {
      "arxiv_id": "2507.15903v1",
      "title": "Towards Mitigation of Hallucination for LLM-empowered Agents: Progressive Generalization Bound Exploration and Watchdog Monitor",
      "title_zh": "é¢å‘LLMé©±åŠ¨æ™ºèƒ½ä½“å¹»è§‰ç¼“è§£ï¼šæ¸è¿›å¼æ³›åŒ–è¾¹ç•Œæ¢ç´¢ä¸çœ‹é—¨ç‹—ç›‘è§†å™¨",
      "authors": [
        "Siyuan Liu",
        "Wenjing Liu",
        "Zhiwei Xu",
        "Xin Wang",
        "Bo Chen",
        "Tao Li"
      ],
      "abstract": "Empowered by large language models (LLMs), intelligent agents have become a popular paradigm for interacting with open environments to facilitate AI deployment. However, hallucinations generated by LLMs-where outputs are inconsistent with facts-pose a significant challenge, undermining the credibility of intelligent agents. Only if hallucinations can be mitigated, the intelligent agents can be used in real-world without any catastrophic risk. Therefore, effective detection and mitigation of hallucinations are crucial to ensure the dependability of agents. Unfortunately, the related approaches either depend on white-box access to LLMs or fail to accurately identify hallucinations. To address the challenge posed by hallucinations of intelligent agents, we present HalMit, a novel black-box watchdog framework that models the generalization bound of LLM-empowered agents and thus detect hallucinations without requiring internal knowledge of the LLM's architecture. Specifically, a probabilistic fractal sampling technique is proposed to generate a sufficient number of queries to trigger the incredible responses in parallel, efficiently identifying the generalization bound of the target agent. Experimental evaluations demonstrate that HalMit significantly outperforms existing approaches in hallucination monitoring. Its black-box nature and superior performance make HalMit a promising solution for enhancing the dependability of LLM-powered systems.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŸºäºå¤§è¯­è¨€æ¨¡å‹(LLMs)çš„æ™ºèƒ½ä½“åœ¨å¼€æ”¾ç¯å¢ƒä¸­é¢ä¸´çš„å¹»è§‰(hallucinations)é—®é¢˜ï¼Œæå‡ºäº†åä¸ºHalMitçš„é»‘ç›’ç›‘è§†(watchdog framework)æ¡†æ¶ï¼Œæ—¨åœ¨æå‡ç³»ç»Ÿçš„å¯ä¿¡åº¦ä¸å®‰å…¨æ€§ã€‚ä¸ºäº†å…‹æœç°æœ‰æ£€æµ‹æ–¹æ³•ä¾èµ–ç™½ç›’è®¿é—®æˆ–è¯†åˆ«ç²¾åº¦ä¸è¶³çš„å±€é™ï¼ŒHalMité€šè¿‡å»ºæ¨¡æ™ºèƒ½ä½“çš„æ³›åŒ–ç•Œ(generalization bound)æ¥è¯†åˆ«å¹»è§‰ï¼Œæ— éœ€äº†è§£LLMsçš„å†…éƒ¨æ¶æ„ã€‚ç ”ç©¶æå‡ºäº†ä¸€ç§æ¦‚ç‡åˆ†å½¢é‡‡æ ·(probabilistic fractal sampling)æŠ€æœ¯ï¼Œé€šè¿‡å¹¶è¡Œç”Ÿæˆè¶³é‡æŸ¥è¯¢ä»¥è§¦å‘å¼‚å¸¸å“åº”ï¼Œä»è€Œé«˜æ•ˆæ¢ç´¢å¹¶ç¡®å®šç›®æ ‡æ™ºèƒ½ä½“çš„æ³›åŒ–è¾¹ç•Œã€‚å®éªŒç»“æœè¯æ˜ï¼ŒHalMitåœ¨å¹»è§‰ç›‘æµ‹æ€§èƒ½ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå…¶é»‘ç›’ç‰¹æ€§ä½¿å…¶æˆä¸ºå¢å¼ºLLMé©±åŠ¨ç³»ç»Ÿå¯é æ€§çš„æœ‰æ•ˆæ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.15903v1",
      "published_date": "2025-07-21 09:08:58 UTC",
      "updated_date": "2025-07-21 09:08:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:02:00.957040+00:00"
    },
    {
      "arxiv_id": "2507.15396v1",
      "title": "Neuro-MSBG: An End-to-End Neural Model for Hearing Loss Simulation",
      "title_zh": "Neuro-MSBGï¼šä¸€ç§ç”¨äºå¬åŠ›æŸå¤±æ¨¡æ‹Ÿçš„ç«¯åˆ°ç«¯ç¥ç»æ¨¡å‹",
      "authors": [
        "Hui-Guan Yuan",
        "Ryandhimas E. Zezario",
        "Shafique Ahmed",
        "Hsin-Min Wang",
        "Kai-Lung Hua",
        "Yu Tsao"
      ],
      "abstract": "Hearing loss simulation models are essential for hearing aid deployment. However, existing models have high computational complexity and latency, which limits real-time applications and lack direct integration with speech processing systems. To address these issues, we propose Neuro-MSBG, a lightweight end-to-end model with a personalized audiogram encoder for effective time-frequency modeling. Experiments show that Neuro-MSBG supports parallel inference and retains the intelligibility and perceptual quality of the original MSBG, with a Spearman's rank correlation coefficient (SRCC) of 0.9247 for Short-Time Objective Intelligibility (STOI) and 0.8671 for Perceptual Evaluation of Speech Quality (PESQ). Neuro-MSBG reduces simulation runtime by a factor of 46 (from 0.970 seconds to 0.021 seconds for a 1 second input), further demonstrating its efficiency and practicality.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Neuro-MSBGï¼Œè¿™æ˜¯ä¸€ç§æ—¨åœ¨è§£å†³ç°æœ‰å¬åŠ›æŸå¤±æ¨¡æ‹Ÿæ¨¡å‹ (Hearing loss simulation models) è¾ƒé«˜è®¡ç®—å¤æ‚åº¦å’Œå»¶è¿Ÿé—®é¢˜çš„è½»é‡çº§ç«¯åˆ°ç«¯ç¥ç»æ¨¡å‹ã€‚è¯¥æ¡†æ¶é€šè¿‡é›†æˆä¸ªæ€§åŒ–çš„å¬åŠ›å›¾ç¼–ç å™¨ (audiogram encoder) å®ç°æœ‰æ•ˆçš„æ—¶é¢‘å»ºæ¨¡ï¼Œå¹¶æ”¯æŒå¹¶è¡Œæ¨ç†ä»¥æ»¡è¶³å®æ—¶åº”ç”¨éœ€æ±‚ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒNeuro-MSBG åœ¨ä¿æŒåŸå§‹ MSBG æ¨¡å‹çš„å¯ç†è§£æ€§å’Œæ„ŸçŸ¥è´¨é‡æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œå…¶çŸ­æ—¶å®¢è§‚å¯æ‡‚åº¦ (STOI) çš„ Spearman ç›¸å…³ç³»æ•° (SRCC) è¾¾åˆ° 0.9247ï¼Œè¯­éŸ³æ„ŸçŸ¥è´¨é‡ (PESQ) è¾¾åˆ° 0.8671ã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹å°†æ¨¡æ‹Ÿè¿è¡Œæ—¶é—´ç¼©çŸ­äº†çº¦ 46 å€ï¼Œå¤„ç† 1 ç§’éŸ³é¢‘è¾“å…¥çš„æ—¶é—´ä» 0.970 ç§’é™ä½è‡³ 0.021 ç§’ï¼Œæ˜¾è‘—æå‡äº†è®¡ç®—æ•ˆç‡ã€‚è¿™é¡¹ç ”ç©¶ä¸ºå¬åŠ›æŸå¤±æ¨¡æ‹Ÿä¸è¯­éŸ³å¤„ç†ç³»ç»Ÿçš„ç›´æ¥é›†æˆæä¾›äº†é«˜æ•ˆä¸”å®ç”¨çš„è§£å†³æ–¹æ¡ˆï¼Œè¯æ˜äº†å…¶åœ¨åŠ©å¬è®¾å¤‡éƒ¨ç½²é¢†åŸŸçš„åº”ç”¨æ½œåŠ›ã€‚",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.15396v1",
      "published_date": "2025-07-21 08:58:31 UTC",
      "updated_date": "2025-07-21 08:58:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:02:22.841371+00:00"
    },
    {
      "arxiv_id": "2507.15393v1",
      "title": "PiMRef: Detecting and Explaining Ever-evolving Spear Phishing Emails with Knowledge Base Invariants",
      "title_zh": "PiMRefï¼šåˆ©ç”¨çŸ¥è¯†åº“ä¸å˜é‡æ£€æµ‹ä¸è§£é‡Šä¸æ–­æ¼”å˜çš„é±¼å‰å¼ç½‘ç»œé’“é±¼é‚®ä»¶",
      "authors": [
        "Ruofan Liu",
        "Yun Lin",
        "Silas Yeo Shuen Yu",
        "Xiwen Teoh",
        "Zhenkai Liang",
        "Jin Song Dong"
      ],
      "abstract": "Phishing emails are a critical component of the cybercrime kill chain due to their wide reach and low cost. Their ever-evolving nature renders traditional rule-based and feature-engineered detectors ineffective in the ongoing arms race between attackers and defenders. The rise of large language models (LLMs) further exacerbates the threat, enabling attackers to craft highly convincing phishing emails at minimal cost.\n  This work demonstrates that LLMs can generate psychologically persuasive phishing emails tailored to victim profiles, successfully bypassing nearly all commercial and academic detectors. To defend against such threats, we propose PiMRef, the first reference-based phishing email detector that leverages knowledge-based invariants. Our core insight is that persuasive phishing emails often contain disprovable identity claims, which contradict real-world facts. PiMRef reframes phishing detection as an identity fact-checking task. Given an email, PiMRef (i) extracts the sender's claimed identity, (ii) verifies the legitimacy of the sender's domain against a predefined knowledge base, and (iii) detects call-to-action prompts that push user engagement. Contradictory claims are flagged as phishing indicators and serve as human-understandable explanations.\n  Compared to existing methods such as D-Fence, HelpHed, and ChatSpamDetector, PiMRef boosts precision by 8.8% with no loss in recall on standard benchmarks like Nazario and PhishPot. In a real-world evaluation of 10,183 emails across five university accounts over three years, PiMRef achieved 92.1% precision, 87.9% recall, and a median runtime of 0.05s, outperforming the state-of-the-art in both effectiveness and efficiency.",
      "tldr_zh": "é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)é©±åŠ¨ä¸‹æ—¥ç›Šæ¼”è¿›ä¸”æå…·è¯´æœåŠ›çš„é’“é±¼é‚®ä»¶å¨èƒï¼Œè¯¥ç ”ç©¶æŒ‡å‡ºä¼ ç»Ÿçš„è§„åˆ™å’Œç‰¹å¾æ£€æµ‹æ–¹æ³•å·²éš¾ä»¥åº”å¯¹ã€‚ç ”ç©¶æå‡ºäº†é¦–ä¸ªåŸºäºå‚è€ƒçš„æ£€æµ‹å™¨PiMRefï¼Œé€šè¿‡åˆ©ç”¨çŸ¥è¯†åº“ä¸å˜æ€§(knowledge-based invariants)å°†é’“é±¼æ£€æµ‹é‡æ–°å®šä¹‰ä¸ºèº«ä»½äº‹å®æ ¸æŸ¥(identity fact-checking)ä»»åŠ¡ã€‚PiMRefçš„æ ¸å¿ƒæœºåˆ¶åŒ…æ‹¬æå–å‘ä»¶äººèº«ä»½ã€åœ¨é¢„å®šä¹‰çŸ¥è¯†åº“ä¸­éªŒè¯åŸŸååˆæ³•æ€§ï¼Œä»¥åŠæ£€æµ‹ä¿ƒä½¿ç”¨æˆ·å‚ä¸çš„è¡ŒåŠ¨å‘¼å(call-to-action)æç¤ºã€‚è¯¥æ–¹æ³•é€šè¿‡è¯†åˆ«é‚®ä»¶ä¸­ä¸ç°å®äº‹å®ç›¸çŸ›ç›¾çš„è™šå‡èº«ä»½å£°æ˜æ¥åˆ¤å®šé’“é±¼è¡Œä¸ºï¼Œå¹¶ä»¥æ­¤æä¾›å…·æœ‰å¯è§£é‡Šæ€§çš„è¯æ®ã€‚åœ¨Nazarioå’ŒPhishPotç­‰æ ‡å‡†åŸºå‡†æµ‹è¯•ä¸­ï¼ŒPiMRefçš„å‡†ç¡®ç‡æ¯”ç°æœ‰æ–¹æ³•æå‡äº†8.8%ï¼Œä¸”å¬å›ç‡è¡¨ç°ç¨³å®šã€‚åœ¨é’ˆå¯¹å¤§å­¦è´¦æˆ·ã€è¶…è¿‡ä¸€ä¸‡å°çœŸå®é‚®ä»¶çš„é•¿æœŸè¯„ä¼°ä¸­ï¼Œè¯¥ç³»ç»Ÿå®ç°äº†92.1%çš„å‡†ç¡®ç‡å’Œ87.9%çš„å¬å›ç‡ï¼Œä¸­å€¼è¿è¡Œæ—¶é—´ä»…ä¸º0.05ç§’ï¼Œåœ¨æœ‰æ•ˆæ€§å’Œæ•ˆç‡ä¸Šå‡æ˜¾è‘—ä¼˜äºç°æœ‰æœ€å…ˆè¿›(state-of-the-art)æ–¹æ³•ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.15393v1",
      "published_date": "2025-07-21 08:53:41 UTC",
      "updated_date": "2025-07-21 08:53:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:02:21.457543+00:00"
    },
    {
      "arxiv_id": "2507.15381v1",
      "title": "To Label or Not to Label: PALM -- A Predictive Model for Evaluating Sample Efficiency in Active Learning Models",
      "title_zh": "æ ‡æ³¨ï¼Œè¿˜æ˜¯ä¸æ ‡æ³¨ï¼šPALMâ€”â€”ä¸€ç§è¯„ä¼°ä¸»åŠ¨å­¦ä¹ æ¨¡å‹æ ·æœ¬æ•ˆç‡çš„é¢„æµ‹æ¨¡å‹",
      "authors": [
        "Julia Machnio",
        "Mads Nielsen",
        "Mostafa Mehdipour Ghazi"
      ],
      "abstract": "Active learning (AL) seeks to reduce annotation costs by selecting the most informative samples for labeling, making it particularly valuable in resource-constrained settings. However, traditional evaluation methods, which focus solely on final accuracy, fail to capture the full dynamics of the learning process. To address this gap, we propose PALM (Performance Analysis of Active Learning Models), a unified and interpretable mathematical model that characterizes AL trajectories through four key parameters: achievable accuracy, coverage efficiency, early-stage performance, and scalability. PALM provides a predictive description of AL behavior from partial observations, enabling the estimation of future performance and facilitating principled comparisons across different strategies. We validate PALM through extensive experiments on CIFAR-10/100 and ImageNet-50/100/200, covering a wide range of AL methods and self-supervised embeddings. Our results demonstrate that PALM generalizes effectively across datasets, budgets, and strategies, accurately predicting full learning curves from limited labeled data. Importantly, PALM reveals crucial insights into learning efficiency, data space coverage, and the scalability of AL methods. By enabling the selection of cost-effective strategies and predicting performance under tight budget constraints, PALM lays the basis for more systematic, reproducible, and data-efficient evaluation of AL in both research and real-world applications. The code is available at: https://github.com/juliamachnio/PALM.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä¸»åŠ¨å­¦ä¹  (Active learning) ä¼ ç»Ÿè¯„ä¼°æ–¹æ³•ä»…å…³æ³¨æœ€ç»ˆå‡†ç¡®ç‡è€Œå¿½ç•¥å­¦ä¹ åŠ¨æ€è¿‡ç¨‹çš„é—®é¢˜ï¼Œæå‡ºäº† PALM (Performance Analysis of Active Learning Models) æ¨¡å‹ã€‚ä½œä¸ºä¸€ç§ç»Ÿä¸€ä¸”å¯è§£é‡Šçš„æ•°å­¦æ¨¡å‹ï¼ŒPALM é€šè¿‡å¯å®ç°å‡†ç¡®ç‡ (achievable accuracy)ã€è¦†ç›–æ•ˆç‡ (coverage efficiency)ã€æ—©æœŸè¡¨ç° (early-stage performance) å’Œå¯æ‰©å±•æ€§ (scalability) å››ä¸ªå…³é”®å‚æ•°æ¥åˆ»ç”»ä¸»åŠ¨å­¦ä¹ è½¨è¿¹ã€‚è¯¥æ¨¡å‹èƒ½å¤ŸåŸºäºéƒ¨åˆ†è§‚å¯Ÿæ•°æ®å¯¹å­¦ä¹ è¡Œä¸ºè¿›è¡Œé¢„æµ‹æ€§æè¿°ï¼Œä»è€Œå®ç°å¯¹æœªæ¥æ€§èƒ½çš„ä¼°ç®—ï¼Œå¹¶æ”¯æŒä¸åŒç­–ç•¥é—´çš„åŸåˆ™æ€§æ¯”è¾ƒã€‚ç ”ç©¶å›¢é˜Ÿåœ¨ CIFAR-10/100 å’Œ ImageNet ç­‰å¤šä¸ªæ•°æ®é›†ä¸ŠéªŒè¯äº†è¯¥æ¨¡å‹çš„æœ‰æ•ˆæ€§ï¼Œè¯æ˜å…¶åœ¨ä¸åŒé¢„ç®—å’Œç­–ç•¥ä¸‹å‡å…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚å®éªŒè¡¨æ˜ PALM èƒ½å¤Ÿä»…å‡­æœ‰é™çš„æ ‡æ³¨æ•°æ®å‡†ç¡®é¢„æµ‹å®Œæ•´çš„å­¦ä¹ æ›²çº¿ï¼Œå¹¶æ­ç¤ºäº†å­¦ä¹ æ•ˆç‡ä¸æ•°æ®ç©ºé—´è¦†ç›–ç­‰æ ¸å¿ƒæŒ‡æ ‡ã€‚è¿™ä¸€æˆæœä¸ºåœ¨ç§‘ç ”å’Œå®é™…åº”ç”¨ä¸­å®ç°æ›´ç³»ç»Ÿã€å¯é‡å¤ä¸”æ•°æ®é«˜æ•ˆçš„ä¸»åŠ¨å­¦ä¹ è¯„ä¼°å¥ å®šäº†é‡è¦åŸºç¡€ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "ICCV 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.15381v1",
      "published_date": "2025-07-21 08:37:44 UTC",
      "updated_date": "2025-07-21 08:37:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:02:20.652119+00:00"
    },
    {
      "arxiv_id": "2507.16850v1",
      "title": "Toward a Real-Time Framework for Accurate Monocular 3D Human Pose Estimation with Geometric Priors",
      "title_zh": "é¢å‘å‡ ä½•å…ˆéªŒçš„é«˜ç²¾åº¦å®æ—¶å•ç›® 3D äººä½“å§¿æ€ä¼°è®¡æ¡†æ¶",
      "authors": [
        "Mohamed Adjel"
      ],
      "abstract": "Monocular 3D human pose estimation remains a challenging and ill-posed problem, particularly in real-time settings and unconstrained environments. While direct imageto-3D approaches require large annotated datasets and heavy models, 2D-to-3D lifting offers a more lightweight and flexible alternative-especially when enhanced with prior knowledge. In this work, we propose a framework that combines real-time 2D keypoint detection with geometry-aware 2D-to-3D lifting, explicitly leveraging known camera intrinsics and subject-specific anatomical priors. Our approach builds on recent advances in self-calibration and biomechanically-constrained inverse kinematics to generate large-scale, plausible 2D-3D training pairs from MoCap and synthetic datasets. We discuss how these ingredients can enable fast, personalized, and accurate 3D pose estimation from monocular images without requiring specialized hardware. This proposal aims to foster discussion on bridging data-driven learning and model-based priors to improve accuracy, interpretability, and deployability of 3D human motion capture on edge devices in the wild.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªæ—¨åœ¨å®ç°å®æ—¶é«˜ç²¾åº¦å•ç›® 3D äººä½“å§¿æ€ä¼°è®¡çš„æ¡†æ¶ï¼Œé‡ç‚¹é€šè¿‡å‡ ä½•å…ˆéªŒ (geometric priors) è§£å†³è¯¥é¢†åŸŸçš„ç—…æ€é—®é¢˜ã€‚ç›¸æ¯”äºè®¡ç®—é‡å·¨å¤§çš„ç›´æ¥å›¾åƒè½¬æ¢æ–¹æ¡ˆï¼Œè¯¥æ¡†æ¶é‡‡ç”¨äº†æ›´è½»é‡çº§çš„ 2D-to-3D lifting æ–¹æ¡ˆï¼Œå¹¶ç»“åˆäº†å®æ—¶ 2D å…³é”®ç‚¹æ£€æµ‹ä¸å‡ ä½•æ„ŸçŸ¥çš„æå‡æŠ€æœ¯ï¼Œæ˜¾å¼åˆ©ç”¨ç›¸æœºå†…å‚ (camera intrinsics) å’Œå—è¯•è€…ç‰¹å®šçš„è§£å‰–å­¦å…ˆéªŒ (anatomical priors)ã€‚ç ”ç©¶è¿›ä¸€æ­¥åˆ©ç”¨è‡ªæ ¡å‡† (self-calibration) å’Œå—ç”Ÿç‰©åŠ›å­¦çº¦æŸçš„é€†å‘è¿åŠ¨å­¦ (biomechanically-constrained inverse kinematics) æŠ€æœ¯ï¼Œä» MoCap å’Œåˆæˆæ•°æ®ä¸­ç”Ÿæˆå¤§è§„æ¨¡çš„é«˜è´¨é‡è®­ç»ƒå¯¹ã€‚è¯¥æ–¹æ³•èƒ½å¤Ÿåœ¨æ— éœ€ä¸“é—¨ç¡¬ä»¶çš„æƒ…å†µä¸‹å®ç°å¿«é€Ÿã€ä¸ªæ€§åŒ–ä¸”ç²¾ç¡®çš„ 3D å§¿æ€ä¼°è®¡ã€‚é€šè¿‡æ¡¥æ¥æ•°æ®é©±åŠ¨å­¦ä¹ ä¸æ¨¡å‹å…ˆéªŒï¼Œè¯¥ç ”ç©¶æ˜¾è‘—æå‡äº† 3D äººä½“è¿åŠ¨æ•æ‰åœ¨é‡å¤–ç¯å¢ƒåŠè¾¹ç¼˜è®¾å¤‡ä¸Šçš„å‡†ç¡®æ€§ã€å¯è§£é‡Šæ€§å’Œéƒ¨ç½²èƒ½åŠ›ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "IEEE ICRA 2025 (workshop: Enhancing Human Mobility: From Computer Vision-Based Motion Tracking to Wearable Assistive Robot Control), May 2025, Atlanta (Georgia), United States",
      "pdf_url": "https://arxiv.org/pdf/2507.16850v1",
      "published_date": "2025-07-21 08:18:23 UTC",
      "updated_date": "2025-07-21 08:18:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:02:25.554649+00:00"
    },
    {
      "arxiv_id": "2507.15367v1",
      "title": "Multi-beam Beamforming in RIS-aided MIMO Subject to Reradiation Mask Constraints -- Optimization and Machine Learning Design",
      "title_zh": "å†è¾å°„æ©æ¨¡çº¦æŸä¸‹ RIS è¾…åŠ© MIMO çš„å¤šæ³¢æŸæ³¢æŸèµ‹å½¢ï¼šä¼˜åŒ–ä¸æœºå™¨å­¦ä¹ è®¾è®¡",
      "authors": [
        "Shumin Wang",
        "Hajar El Hassani",
        "Marco Di Renzo",
        "Marios Poulakis"
      ],
      "abstract": "Reconfigurable intelligent surfaces (RISs) are an emerging technology for improving spectral efficiency and reducing power consumption in future wireless systems. This paper investigates the joint design of the transmit precoding matrices and the RIS phase shift vector in a multi-user RIS-aided multiple-input multiple-output (MIMO) communication system. We formulate a max-min optimization problem to maximize the minimum achievable rate while considering transmit power and reradiation mask constraints. The achievable rate is simplified using the Arimoto-Blahut algorithm, and the problem is broken into quadratic programs with quadratic constraints (QPQC) sub-problems using an alternating optimization approach. To improve efficiency, we develop a model-based neural network optimization that utilizes the one-hot encoding for the angles of incidence and reflection. We address practical RIS limitations by using a greedy search algorithm to solve the optimization problem for discrete phase shifts. Simulation results demonstrate that the proposed methods effectively shape the multi-beam radiation pattern towards desired directions while satisfying reradiation mask constraints. The neural network design reduces the execution time, and the discrete phase shift scheme performs well with a small reduction of the beamforming gain by using only four phase shift levels.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨å—reradiation mask constraintsçº¦æŸçš„RIS-aided MIMOç³»ç»Ÿä¸­ï¼Œå¦‚ä½•è”åˆè®¾è®¡transmit precoding matriceså’ŒRIS phase shift vectorã€‚ç ”ç©¶æ„å»ºäº†ä¸€ä¸ªmax-min optimizationé—®é¢˜ï¼Œæ—¨åœ¨æ»¡è¶³å‘å°„åŠŸç‡å’Œé‡æ–°è¾å°„æ©ç çº¦æŸçš„åŒæ—¶ï¼Œæœ€å¤§åŒ–æœ€å°å¯è¾¾é€Ÿç‡(minimum achievable rate)ã€‚é€šè¿‡åˆ©ç”¨Arimoto-Blahut algorithmç®€åŒ–è®¡ç®—ï¼Œå¹¶é‡‡ç”¨alternating optimizationå°†é—®é¢˜åˆ†è§£ä¸ºQPQCå­é—®é¢˜è¿›è¡Œæ±‚è§£ã€‚ä¸ºæå‡è®¡ç®—æ•ˆç‡ï¼Œä½œè€…è¿›ä¸€æ­¥å¼€å‘äº†åŸºäºmodel-based neural networkçš„ä¼˜åŒ–æ–¹æ³•ï¼Œå¹¶é’ˆå¯¹å…¥å°„è§’å’Œåå°„è§’å¼•å…¥äº†one-hot encodingã€‚é’ˆå¯¹ç¦»æ•£ç›¸ä½é™åˆ¶ï¼Œç ”ç©¶é‡‡ç”¨greedy search algorithmä¼˜åŒ–discrete phase shiftsã€‚ä»¿çœŸç»“æœè¯æ˜ï¼Œè¯¥æ–¹æ³•èƒ½æœ‰æ•ˆå¡‘é€ multi-beam radiation patternä»¥æ»¡è¶³æ©ç çº¦æŸï¼Œä¸”neural networkè®¾è®¡æ˜¾è‘—é™ä½äº†æ‰§è¡Œæ—¶é—´ï¼Œç¦»æ•£æ–¹æ¡ˆåœ¨ä»…éœ€å››ä¸ªç›¸ä½æ°´å¹³æ—¶å³å¯ä¿æŒç¨³å¥æ€§èƒ½ã€‚",
      "categories": [
        "math.OC",
        "cs.AI",
        "cs.IT"
      ],
      "primary_category": "math.OC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.15367v1",
      "published_date": "2025-07-21 08:18:23 UTC",
      "updated_date": "2025-07-21 08:18:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:02:30.247058+00:00"
    },
    {
      "arxiv_id": "2507.15364v1",
      "title": "EEG-based Epileptic Prediction via a Two-stage Channel-aware Set Transformer Network",
      "title_zh": "åŸºäºä¸¤é˜¶æ®µé€šé“æ„ŸçŸ¥ Set Transformer ç½‘ç»œçš„ EEG ç™«ç—«é¢„æµ‹",
      "authors": [
        "Ruifeng Zheng",
        "Cong Chen",
        "Shuang Wang",
        "Yiming Liu",
        "Lin You",
        "Jindong Lu",
        "Ruizhe Zhu",
        "Guodao Zhang",
        "Kejie Huang"
      ],
      "abstract": "Epilepsy is a chronic, noncommunicable brain disorder, and sudden seizure onsets can significantly impact patients' quality of life and health. However, wearable seizure-predicting devices are still limited, partly due to the bulky size of EEG-collecting devices. To relieve the problem, we proposed a novel two-stage channel-aware Set Transformer Network that could perform seizure prediction with fewer EEG channel sensors. We also tested a seizure-independent division method which could prevent the adjacency of training and test data. Experiments were performed on the CHB-MIT dataset which includes 22 patients with 88 merged seizures. The mean sensitivity before channel selection was 76.4% with a false predicting rate (FPR) of 0.09/hour. After channel selection, dominant channels emerged in 20 out of 22 patients; the average number of channels was reduced to 2.8 from 18; and the mean sensitivity rose to 80.1% with an FPR of 0.11/hour. Furthermore, experimental results on the seizure-independent division supported our assertion that a more rigorous seizure-independent division should be used for patients with abundant EEG recordings.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¯ç©¿æˆ´ç™«ç—«é¢„æµ‹è®¾å¤‡å—é™äºè„‘ç”µå›¾(EEG)é‡‡é›†è®¾å¤‡ä½“ç§¯åºå¤§çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§æ–°å‹çš„ä¸¤é˜¶æ®µé€šé“æ„ŸçŸ¥Set Transformer Networkï¼ˆTwo-stage Channel-aware Set Transformer Networkï¼‰ï¼Œæ—¨åœ¨åˆ©ç”¨æ›´å°‘çš„ä¼ æ„Ÿå™¨é€šé“å®ç°ç²¾å‡†é¢„æµ‹ã€‚ä¸ºäº†æé«˜è¯„ä¼°çš„ç§‘å­¦æ€§ï¼Œç ”ç©¶è¿˜é‡‡ç”¨äº†ä¸€ç§ç™«ç—«ç‹¬ç«‹åˆ’åˆ†æ–¹æ³•ï¼ˆSeizure-independent division methodï¼‰ï¼Œæœ‰æ•ˆé¿å…äº†è®­ç»ƒé›†ä¸æµ‹è¯•é›†æ•°æ®çš„é‚»è¿‘ç›¸å…³æ€§ã€‚å®éªŒåœ¨åŒ…å«22åæ‚£è€…çš„CHB-MITæ•°æ®é›†ä¸Šå±•å¼€ï¼Œç»“æœæ˜¾ç¤ºåœ¨é€šé“é€‰æ‹©åï¼Œå¹³å‡EEGé€šé“æ•°ä»18ä¸ªæ˜¾è‘—å‡å°‘è‡³2.8ä¸ªï¼Œè€Œå¹³å‡æ•æ„Ÿåº¦ï¼ˆSensitivityï¼‰ä»76.4%æå‡è‡³80.1%ï¼Œè¯¯æŠ¥ç‡ï¼ˆFPRï¼‰ä¿æŒåœ¨æ¯å°æ—¶0.11æ¬¡çš„è¾ƒä½æ°´å¹³ã€‚è¯¥æ–¹æ³•æˆåŠŸè¯†åˆ«äº†å¤šæ•°æ‚£è€…çš„ä¼˜åŠ¿é€šé“ï¼Œè¯æ˜äº†åœ¨å‡å°‘ç¡¬ä»¶å†—ä½™çš„åŒæ—¶ä»èƒ½ä¿æŒç”šè‡³æå‡é¢„æµ‹æ€§èƒ½ã€‚æ­¤å¤–ï¼Œç ”ç©¶ç»“æœè¿›ä¸€æ­¥æ”¯æŒäº†åœ¨å¤„ç†ä¸°å¯Œè„‘ç”µæ•°æ®æ—¶ï¼Œä½¿ç”¨æ›´ä¸ºä¸¥æ ¼çš„ç‹¬ç«‹åˆ’åˆ†æ–¹æ³•å¯¹äºä¿è¯ä¸´åºŠè¯„ä¼°ä¸¥è°¨æ€§çš„å¿…è¦æ€§ã€‚",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.15364v1",
      "published_date": "2025-07-21 08:16:19 UTC",
      "updated_date": "2025-07-21 08:16:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:02:43.359163+00:00"
    },
    {
      "arxiv_id": "2507.15361v1",
      "title": "Latent Space Synergy: Text-Guided Data Augmentation for Direct Diffusion Biomedical Segmentation",
      "title_zh": "æ½œç©ºé—´ååŒï¼šç”¨äºç›´æ¥æ‰©æ•£ç”Ÿç‰©åŒ»å­¦åˆ†å‰²çš„æ–‡æœ¬å¼•å¯¼æ•°æ®å¢å¼º",
      "authors": [
        "Muhammad Aqeel",
        "Maham Nazir",
        "Zanxi Ruan",
        "Francesco Setti"
      ],
      "abstract": "Medical image segmentation suffers from data scarcity, particularly in polyp detection where annotation requires specialized expertise. We present SynDiff, a framework combining text-guided synthetic data generation with efficient diffusion-based segmentation. Our approach employs latent diffusion models to generate clinically realistic synthetic polyps through text-conditioned inpainting, augmenting limited training data with semantically diverse samples. Unlike traditional diffusion methods requiring iterative denoising, we introduce direct latent estimation enabling single-step inference with T x computational speedup. On CVC-ClinicDB, SynDiff achieves 96.0% Dice and 92.9% IoU while maintaining real-time capability suitable for clinical deployment. The framework demonstrates that controlled synthetic augmentation improves segmentation robustness without distribution shift. SynDiff bridges the gap between data-hungry deep learning models and clinical constraints, offering an efficient solution for deployment in resourcelimited medical settings.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŒ»ç–—å›¾åƒåˆ†å‰²é¢†åŸŸç‰¹åˆ«æ˜¯æ¯è‚‰æ£€æµ‹ä¸­æ•°æ®ç¨€ç¼ºåŠæ ‡æ³¨å›°éš¾çš„é—®é¢˜ï¼Œæå‡ºäº†SynDiffæ¡†æ¶ï¼Œå°†æ–‡æœ¬å¼•å¯¼çš„åˆæˆæ•°æ®ç”Ÿæˆ(Text-guided synthetic data generation)ä¸é«˜æ•ˆçš„æ‰©æ•£åˆ†å‰²æŠ€æœ¯(Diffusion-based segmentation)ç›¸ç»“åˆã€‚è¯¥æ¡†æ¶åˆ©ç”¨æ½œæ‰©æ•£æ¨¡å‹(Latent diffusion models)é€šè¿‡æ–‡æœ¬æ¡ä»¶ä¿®å¤(Text-conditioned inpainting)ç”Ÿæˆä¸´åºŠå†™å®çš„åˆæˆæ¯è‚‰å›¾åƒï¼Œæœ‰æ•ˆå¢å¼ºäº†æœ‰é™è®­ç»ƒæ•°æ®çš„è¯­ä¹‰å¤šæ ·æ€§ã€‚ä¸åŒäºä¼ ç»Ÿçš„è¿­ä»£å»å™ªæ‰©æ•£æ–¹æ³•ï¼Œè¯¥ç ”ç©¶å¼•å…¥äº†ç›´æ¥æ½œç©ºé—´ä¼°è®¡(Direct latent estimation)ï¼Œå®ç°äº†å•æ­¥æ¨ç†(Single-step inference)å¹¶è·å¾—äº†æ˜¾è‘—çš„è®¡ç®—åŠ é€Ÿã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒSynDiffåœ¨CVC-ClinicDBæ•°æ®é›†ä¸Šè¾¾åˆ°äº†96.0%çš„Diceç³»æ•°å’Œ92.9%çš„IoUï¼Œå¹¶å…·å¤‡å®æ—¶ä¸´åºŠéƒ¨ç½²çš„æ½œåŠ›ã€‚è¯¥æ–¹æ³•è¯æ˜äº†å—æ§çš„åˆæˆå¢å¼ºèƒ½åœ¨ä¸å¼•èµ·åˆ†å¸ƒåç§»çš„æƒ…å†µä¸‹æå‡åˆ†å‰²æ¨¡å‹çš„ç¨³å¥æ€§ï¼Œä¸ºèµ„æºå—é™çš„åŒ»ç–—åœºæ™¯æä¾›äº†é«˜æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "Accepted to CVGMMI Workshop at ICIAP 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.15361v1",
      "published_date": "2025-07-21 08:15:17 UTC",
      "updated_date": "2025-07-21 08:15:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:02:37.718379+00:00"
    },
    {
      "arxiv_id": "2507.15357v1",
      "title": "Metaphor and Large Language Models: When Surface Features Matter More than Deep Understanding",
      "title_zh": "éšå–»ä¸å¤§è¯­è¨€æ¨¡å‹ï¼šå½“è¡¨é¢ç‰¹å¾çš„é‡è¦æ€§è¶…è¶Šæ·±å±‚ç†è§£",
      "authors": [
        "Elisa Sanchez-Bayona",
        "Rodrigo Agerri"
      ],
      "abstract": "This paper presents a comprehensive evaluation of the capabilities of Large Language Models (LLMs) in metaphor interpretation across multiple datasets, tasks, and prompt configurations. Although metaphor processing has gained significant attention in Natural Language Processing (NLP), previous research has been limited to single-dataset evaluations and specific task settings, often using artificially constructed data through lexical replacement. We address these limitations by conducting extensive experiments using diverse publicly available datasets with inference and metaphor annotations, focusing on Natural Language Inference (NLI) and Question Answering (QA) tasks. The results indicate that LLMs' performance is more influenced by features like lexical overlap and sentence length than by metaphorical content, demonstrating that any alleged emergent abilities of LLMs to understand metaphorical language are the result of a combination of surface-level features, in-context learning, and linguistic knowledge. This work provides critical insights into the current capabilities and limitations of LLMs in processing figurative language, highlighting the need for more realistic evaluation frameworks in metaphor interpretation tasks. Data and code are publicly available.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLarge Language Models, LLMsï¼‰åœ¨éšå–»è§£é‡Šï¼ˆmetaphor interpretationï¼‰èƒ½åŠ›çš„å±€é™æ€§ï¼Œåœ¨å¤šä¸ªæ•°æ®é›†ã€ä»»åŠ¡å’Œæç¤ºé…ç½®ä¸‹è¿›è¡Œäº†å…¨é¢è¯„ä¼°ã€‚ç›¸æ¯”äºä»¥å¾€å±€é™äºå•ä¸€æ•°æ®é›†æˆ–äººå·¥æ„é€ æ•°æ®çš„ç ”ç©¶ï¼Œæœ¬é¡¹å·¥ä½œåˆ©ç”¨åŒ…å«æ¨ç†å’Œéšå–»æ ‡æ³¨çš„å¤šç§å…¬å¼€æ•°æ®é›†ï¼Œé‡ç‚¹å…³æ³¨è‡ªç„¶è¯­è¨€æ¨ç†ï¼ˆNatural Language Inference, NLIï¼‰å’Œé—®ç­”ï¼ˆQuestion Answering, QAï¼‰ä»»åŠ¡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒLLMs çš„è¡¨ç°æ›´å¤šå—è¯æ±‡é‡å ï¼ˆlexical overlapï¼‰å’Œå¥å­é•¿åº¦ï¼ˆsentence lengthï¼‰ç­‰è¡¨é¢ç‰¹å¾çš„å½±å“ï¼Œè€Œééšå–»å†…å®¹æœ¬èº«ã€‚è¿™è¯æ˜äº† LLMs æ‰€è°“ç†è§£éšå–»è¯­è¨€çš„â€œæ¶Œç°èƒ½åŠ›â€ï¼ˆemergent abilitiesï¼‰ï¼Œå®é™…ä¸Šæ˜¯è¡¨é¢ç‰¹å¾ã€ä¸Šä¸‹æ–‡å­¦ä¹ ï¼ˆin-context learningï¼‰å’Œè¯­è¨€çŸ¥è¯†å…±åŒä½œç”¨çš„ç»“æœã€‚è¯¥é¡¹å·¥ä½œæ·±å…¥æ­ç¤ºäº†å½“å‰ LLMs å¤„ç†æ¯”å–»æ€§è¯­è¨€ï¼ˆfigurative languageï¼‰çš„èƒ½åŠ›åŠå…¶å±€é™æ€§ï¼Œå¹¶å¼ºè°ƒäº†åœ¨éšå–»è§£é‡Šä»»åŠ¡ä¸­å»ºç«‹æ›´çœŸå®è¯„ä¼°æ¡†æ¶çš„å¿…è¦æ€§ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.15357v1",
      "published_date": "2025-07-21 08:09:11 UTC",
      "updated_date": "2025-07-21 08:09:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:02:44.632354+00:00"
    },
    {
      "arxiv_id": "2507.15356v1",
      "title": "RAD: Retrieval High-quality Demonstrations to Enhance Decision-making",
      "title_zh": "RADï¼šé€šè¿‡æ£€ç´¢é«˜è´¨é‡æ¼”ç¤ºå¢å¼ºå†³ç­–èƒ½åŠ›",
      "authors": [
        "Lu Guo",
        "Yixiang Shan",
        "Zhengbang Zhu",
        "Qifan Liang",
        "Lichang Song",
        "Ting Long",
        "Weinan Zhang",
        "Yi Chang"
      ],
      "abstract": "Offline reinforcement learning (RL) enables agents to learn policies from fixed datasets, avoiding costly or unsafe environment interactions. However, its effectiveness is often limited by dataset sparsity and the lack of transition overlap between suboptimal and expert trajectories, which makes long-horizon planning particularly challenging. Prior solutions based on synthetic data augmentation or trajectory stitching often fail to generalize to novel states and rely on heuristic stitching points. To address these challenges, we propose Retrieval High-quAlity Demonstrations (RAD) for decision-making, which combines non-parametric retrieval with diffusion-based generative modeling. RAD dynamically retrieves high-return states from the offline dataset as target states based on state similarity and return estimation, and plans toward them using a condition-guided diffusion model. Such retrieval-guided generation enables flexible trajectory stitching and improves generalization when encountered with underrepresented or out-of-distribution states. Extensive experiments confirm that RAD achieves competitive or superior performance compared to baselines across diverse benchmarks, validating its effectiveness.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† RAD (Retrieval High-quAlity Demonstrations) æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç¦»çº¿å¼ºåŒ–å­¦ä¹  (Offline Reinforcement Learning) åœ¨æ•°æ®é›†ç¨€ç–å’Œé•¿ç¨‹è§„åˆ’ (long-horizon planning) ä¸­é¢ä¸´çš„è½¨è¿¹é‡å ä¸è¶³ç­‰æŒ‘æˆ˜ã€‚RAD å°†éå‚æ•°åŒ–æ£€ç´¢ (non-parametric retrieval) ä¸åŸºäºæ‰©æ•£çš„ç”Ÿæˆæ¨¡å‹ (diffusion-based generative modeling) ç›¸ç»“åˆï¼Œé€šè¿‡çŠ¶æ€ç›¸ä¼¼åº¦å’Œå›æŠ¥ä¼°è®¡ä»æ•°æ®é›†ä¸­åŠ¨æ€æ£€ç´¢é«˜å›æŠ¥çŠ¶æ€ä½œä¸ºç›®æ ‡ã€‚è¯¥æ¡†æ¶åˆ©ç”¨æ¡ä»¶å¼•å¯¼çš„æ‰©æ•£æ¨¡å‹ (condition-guided diffusion model) å‘è¿™äº›ç›®æ ‡çŠ¶æ€è¿›è¡Œè§„åˆ’ï¼Œä»è€Œå®ç°äº†çµæ´»çš„è½¨è¿¹æ‹¼æ¥ (trajectory stitching)ã€‚è¿™ç§æ£€ç´¢å¼•å¯¼çš„ç”Ÿæˆæœºåˆ¶æ˜¾è‘—å¢å¼ºäº†æ¨¡å‹åœ¨é¢å¯¹ä»£è¡¨æ€§ä¸è¶³æˆ–åˆ†å¸ƒå¤– (out-of-distribution) çŠ¶æ€æ—¶çš„æ³›åŒ–èƒ½åŠ›ã€‚å¤§é‡å®éªŒè¯æ˜ï¼ŒRAD åœ¨å¤šç§åŸºå‡†æµ‹è¯•ä¸­å‡å–å¾—äº†ä¼˜äºæˆ–ç­‰åŒäºåŸºçº¿æ¨¡å‹çš„æ€§èƒ½ï¼ŒéªŒè¯äº†å…¶åœ¨å¤æ‚å†³ç­–ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.15356v1",
      "published_date": "2025-07-21 08:08:18 UTC",
      "updated_date": "2025-07-21 08:08:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:02:50.496170+00:00"
    },
    {
      "arxiv_id": "2507.15351v2",
      "title": "One Step is Enough: Multi-Agent Reinforcement Learning based on One-Step Policy Optimization for Order Dispatch on Ride-Sharing Platforms",
      "title_zh": "ä¸€æ­¥è¶³çŸ£ï¼šåŸºäºä¸€æ­¥ç­–ç•¥ä¼˜åŒ–çš„å…±äº«å‡ºè¡Œå¹³å°è®¢å•æ´¾é£å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ",
      "authors": [
        "Zijian Zhao",
        "Sen Li"
      ],
      "abstract": "Order dispatch is a critical task in ride-sharing systems with Autonomous Vehicles (AVs), directly influencing efficiency and profits. Recently, Multi-Agent Reinforcement Learning (MARL) has emerged as a promising solution to this problem by decomposing the large state and action spaces among individual agents, effectively addressing the Curse of Dimensionality (CoD) in transportation market, which is caused by the substantial number of vehicles, passengers, and orders. However, conventional MARL-based approaches heavily rely on accurate estimation of the value function, which becomes problematic in large-scale, highly uncertain environments. To address this issue, we propose two novel methods that bypass value function estimation, leveraging the homogeneous property of AV fleets. First, we draw an analogy between AV fleets and groups in Group Relative Policy Optimization (GRPO), adapting it to the order dispatch task. By replacing the Proximal Policy Optimization (PPO) baseline with the group average reward-to-go, GRPO eliminates critic estimation errors and reduces training bias. Inspired by this baseline replacement, we further propose One-Step Policy Optimization (OSPO), demonstrating that the optimal policy can be trained using only one-step group rewards under a homogeneous fleet. Experiments on a real-world ride-hailing dataset show that both GRPO and OSPO achieve promising performance across all scenarios, efficiently optimizing pickup times and the number of served orders using simple Multilayer Perceptron (MLP) networks. Furthermore, OSPO outperforms GRPO in all scenarios, attributed to its elimination of bias caused by the bounded time horizon of GRPO. Our code, trained models, and processed data are provided at https://github.com/RS2002/OSPO .",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è‡ªåŠ¨é©¾é©¶è½¦è¾†(AVs)ç½‘çº¦è½¦å¹³å°çš„è®¢å•æ´¾é£é—®é¢˜ï¼Œæå‡ºäº†åŸºäºå¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ (MARL)çš„æ–°æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³å¤§è§„æ¨¡ä¸ç¡®å®šç¯å¢ƒä¸‹ä¼ ç»Ÿæ–¹æ³•ä¾èµ–ä»·å€¼å‡½æ•°(Value Function)ä¼°è®¡è€Œå¯¼è‡´çš„ç»´åº¦ç¾éš¾å’Œè¯¯å·®é—®é¢˜ã€‚ç ”ç©¶é¦–å…ˆå°†ç¾¤ä½“ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–(GRPO)å¼•å…¥è®¢å•æ´¾é£ä»»åŠ¡ï¼Œé€šè¿‡ç»„å†…å¹³å‡å¥–åŠ±ä»£æ›¿ä¼ ç»Ÿçš„åŸºå‡†å€¼ï¼Œæœ‰æ•ˆå‡å°‘äº†è®­ç»ƒåå·®ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œä½œè€…è¿›ä¸€æ­¥æå‡ºäº†å•æ­¥ç­–ç•¥ä¼˜åŒ–(OSPO)ï¼Œè¯æ˜åœ¨é½æ¬¡è½¦é˜Ÿ(Homogeneous Fleet)æ¡ä»¶ä¸‹ï¼Œä»…åˆ©ç”¨å•æ­¥ç¾¤ä½“å¥–åŠ±å³å¯è®­ç»ƒå‡ºæœ€ä¼˜ç­–ç•¥ã€‚åœ¨çœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒGRPOå’ŒOSPOå‡èƒ½åˆ©ç”¨ç®€å•çš„å¤šå±‚æ„ŸçŸ¥æœº(MLP)é«˜æ•ˆä¼˜åŒ–æ¥é€æ—¶é—´å’Œè®¢å•æœåŠ¡é‡ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒOSPOç”±äºæ¶ˆé™¤äº†GRPOä¸­æœ‰ç•Œæ—¶é—´èŒƒå›´å¸¦æ¥çš„åå·®ï¼Œåœ¨æ‰€æœ‰æµ‹è¯•åœºæ™¯ä¸­çš„è¡¨ç°å‡ä¼˜äºGRPOåŠå…¶ä»–åŸºçº¿æ¨¡å‹ã€‚",
      "categories": [
        "cs.AI",
        "cs.ET",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.15351v2",
      "published_date": "2025-07-21 08:04:31 UTC",
      "updated_date": "2025-12-31 05:00:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:02:58.095580+00:00"
    },
    {
      "arxiv_id": "2507.15349v2",
      "title": "Scaling Decentralized Learning with FLock",
      "title_zh": "FLockï¼šå®ç°å»ä¸­å¿ƒåŒ–å­¦ä¹ çš„è§„æ¨¡åŒ–æ‰©å±•",
      "authors": [
        "Zehua Cheng",
        "Rui Sun",
        "Jiahao Sun",
        "Yike Guo"
      ],
      "abstract": "Fine-tuning the large language models (LLMs) are prevented by the deficiency of centralized control and the massive computing and communication overhead on the decentralized schemes. While the typical standard federated learning (FL) supports data privacy, the central server requirement creates a single point of attack and vulnerability to poisoning attacks. Generalizing the result in this direction to 70B-parameter models in the heterogeneous, trustless environments has turned out to be a huge, yet unbroken bottleneck. This paper introduces FLock, a decentralized framework for secure and efficient collaborative LLM fine-tuning. Integrating a blockchain-based trust layer with economic incentives, FLock replaces the central aggregator with a secure, auditable protocol for cooperation among untrusted parties. We present the first empirical validation of fine-tuning a 70B LLM in a secure, multi-domain, decentralized setting. Our experiments show the FLock framework defends against backdoor poisoning attacks that compromise standard FL optimizers and fosters synergistic knowledge transfer. The resulting models show a >68% reduction in adversarial attack success rates. The global model also demonstrates superior cross-domain generalization, outperforming models trained in isolation on their own specialized data.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† FLockï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨å®ç°å®‰å…¨é«˜æ•ˆåä½œå¾®è°ƒå¤§è¯­è¨€æ¨¡å‹ (LLMs) çš„å»ä¸­å¿ƒåŒ–æ¡†æ¶ã€‚é’ˆå¯¹ä¼ ç»Ÿè”é‚¦å­¦ä¹  (FL) ä¾èµ–ä¸­å¿ƒæœåŠ¡å™¨å¯¼è‡´çš„å•ç‚¹æ•…éšœåŠä¸­æ¯’æ”»å‡»é£é™©ï¼ŒFLock é€šè¿‡é›†æˆåŸºäºåŒºå—é“¾ (Blockchain) çš„ä¿¡ä»»å±‚ä¸ç»æµæ¿€åŠ±æœºåˆ¶ï¼Œåˆ©ç”¨å®‰å…¨å¯å®¡è®¡çš„åè®®å–ä»£äº†ä¸­å¿ƒèšåˆå™¨ã€‚è¯¥ç ”ç©¶é¦–æ¬¡åœ¨ä¸å¯ä¿¡ä¸”å¼‚æ„çš„å¤šé¢†åŸŸç¯å¢ƒä¸‹ï¼ŒæˆåŠŸå®Œæˆäº† 70B å‚æ•°è§„æ¨¡ LLM å¾®è°ƒçš„å®è¯éªŒè¯ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒFLock èƒ½å¤Ÿæœ‰æ•ˆæŠµå¾¡åé—¨ä¸­æ¯’æ”»å‡» (Backdoor Poisoning Attacks)ï¼Œä½¿å¯¹æŠ—æ€§æ”»å‡»çš„æˆåŠŸç‡é™ä½äº† 68% ä»¥ä¸Šã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶é€šè¿‡ä¿ƒè¿›ååŒçŸ¥è¯†è½¬ç§»ï¼Œä½¿æœ€ç»ˆç”Ÿæˆçš„å…¨å±€æ¨¡å‹åœ¨è·¨é¢†åŸŸæ³›åŒ–èƒ½åŠ›ä¸Šæ˜¾è‘—ä¼˜äºåœ¨å­¤ç«‹æ•°æ®ä¸Šè®­ç»ƒçš„ä¸“ç”¨æ¨¡å‹ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.15349v2",
      "published_date": "2025-07-21 08:01:43 UTC",
      "updated_date": "2025-08-27 16:50:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:03:20.193664+00:00"
    },
    {
      "arxiv_id": "2507.15343v2",
      "title": "StackTrans: From Large Language Model to Large Pushdown Automata Model",
      "title_zh": "StackTransï¼šä»å¤§è¯­è¨€æ¨¡å‹åˆ°å¤§ä¸‹æ¨è‡ªåŠ¨æœºæ¨¡å‹",
      "authors": [
        "Kechi Zhang",
        "Ge Li",
        "Jia Li",
        "Huangzhao Zhang",
        "Yihong Dong",
        "Jia Li",
        "Jingjing Xu",
        "Zhi Jin"
      ],
      "abstract": "The Transformer architecture has emerged as a landmark advancement within the broad field of artificial intelligence, effectively catalyzing the advent of large language models (LLMs). However, despite its remarkable capabilities and the substantial progress it has facilitated, the Transformer architecture still has some limitations. One such intrinsic limitation is its inability to effectively capture the Chomsky hierarchy, such as regular expressions or deterministic context-free grammars. Drawing inspiration from pushdown automata, which efficiently resolve deterministic context-free grammars using stacks, we propose StackTrans to address the aforementioned issue within LLMs. Unlike previous approaches that modify the attention computation, StackTrans explicitly incorporates hidden state stacks between Transformer layers. This design maintains compatibility with existing frameworks like flash-attention. Specifically, our design features stack operations -- such as pushing and popping hidden states -- that are differentiable and can be learned in an end-to-end manner. Our comprehensive evaluation spans benchmarks for both Chomsky hierarchies and large-scale natural languages. Across these diverse tasks, StackTrans consistently outperforms standard Transformer models and other baselines. We have successfully scaled StackTrans up from 360M to 7B parameters. In particular, our from-scratch pretrained model StackTrans-360M outperforms several larger open-source LLMs with 2-3x more parameters, showcasing its superior efficiency and reasoning capability.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ Transformer æ¶æ„åœ¨æ•è· Chomsky hierarchyï¼ˆå¦‚ç¡®å®šæ€§ä¸Šä¸‹æ–‡æ— å…³æ–‡æ³•ï¼‰æ–¹é¢çš„å›ºæœ‰å±€é™æ€§ï¼Œå—ä¸‹æ¨è‡ªåŠ¨æœº (pushdown automata) å¯å‘æå‡ºäº† StackTrans æ¨¡å‹ã€‚StackTrans é€šè¿‡åœ¨ Transformer å±‚ä¹‹é—´æ˜¾å¼å¼•å…¥éšè—çŠ¶æ€æ ˆ (hidden state stacks)ï¼Œå®ç°äº†å¯å¾®ä¸”æ”¯æŒç«¯åˆ°ç«¯å­¦ä¹ çš„å‹æ ˆä¸å¼¹æ ˆæ“ä½œï¼ŒåŒæ—¶ä¿æŒäº†å¯¹ flash-attention ç­‰ç°æœ‰æ¡†æ¶çš„å…¼å®¹æ€§ã€‚åœ¨ Chomsky hierarchy åŸºå‡†æµ‹è¯•å’Œå¤§è§„æ¨¡è‡ªç„¶è¯­è¨€ä»»åŠ¡çš„è¯„ä¼°ä¸­ï¼ŒStackTrans çš„è¡¨ç°å§‹ç»ˆä¼˜äºæ ‡å‡† Transformer æ¨¡å‹åŠå…¶ä»–åŸºçº¿ã€‚ç ”ç©¶å›¢é˜ŸæˆåŠŸå°†è¯¥æ¶æ„ä» 360M æ‰©å±•è‡³ 7B å‚æ•°è§„æ¨¡ï¼Œå®éªŒè¯æ˜ä»é›¶å¼€å§‹é¢„è®­ç»ƒçš„ StackTrans-360M åœ¨æ•ˆç‡å’Œæ¨ç†èƒ½åŠ›ä¸Šè¶…è¶Šäº†å‚æ•°é‡ä¸ºå…¶ 2-3 å€çš„å¼€æºå¤§å‹è¯­è¨€æ¨¡å‹ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.15343v2",
      "published_date": "2025-07-21 07:58:03 UTC",
      "updated_date": "2025-08-04 10:12:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:03:17.895416+00:00"
    },
    {
      "arxiv_id": "2507.22919v2",
      "title": "A novel language model for predicting serious adverse event results in clinical trials from their prospective registrations",
      "title_zh": "ä¸€ç§åŸºäºå‰ç»æ€§ç™»è®°ä¿¡æ¯é¢„æµ‹ä¸´åºŠè¯•éªŒä¸¥é‡ä¸è‰¯äº‹ä»¶ç»“æœçš„æ–°å‹è¯­è¨€æ¨¡å‹",
      "authors": [
        "Qixuan Hu",
        "Xumou Zhang",
        "Jinman Kim",
        "Florence Bourgeois",
        "Adam G. Dunn"
      ],
      "abstract": "Objectives: With accurate estimates of expected safety results, clinical trials could be better designed and monitored. We evaluated methods for predicting serious adverse event (SAE) results in clinical trials using information only from their registrations prior to the trial. Material and Methods: We analyzed 22,107 two-arm parallel interventional clinical trials from ClinicalTrials.gov with structured summary results. Two prediction models were developed: a classifier predicting whether a greater proportion of participants in an experimental arm would have SAEs (area under the receiver operating characteristic curve; AUC) compared to the control arm, and a regression model to predict the proportion of participants with SAEs in the control arms (root mean squared error; RMSE). A transfer learning approach using pretrained language models (e.g., ClinicalT5, BioBERT) was used for feature extraction, combined with a downstream model for prediction. To maintain semantic representation in long trial texts exceeding localized language model input limits, a sliding window method was developed for embedding extraction. Results: The best model (ClinicalT5+Transformer+MLP) had 77.6% AUC when predicting which trial arm had a higher proportion of SAEs. When predicting SAE proportion in the control arm, the same model achieved RMSE of 18.6%. The sliding window approach consistently outperformed direct comparisons. Across 12 classifiers, the average absolute AUC increase was 2.00%, and absolute RMSE reduction was 1.58% across 12 regressors. Discussion: Summary results data from ClinicalTrials.gov remains underutilized. Predicted results of publicly reported trials provides an opportunity to identify discrepancies between expected and reported safety results.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§æ–°å‹è¯­è¨€æ¨¡å‹ï¼Œæ—¨åœ¨åˆ©ç”¨ä¸´åºŠè¯•éªŒå‰çš„æ³¨å†Œä¿¡æ¯é¢„æµ‹ä¸¥é‡ä¸è‰¯äº‹ä»¶ (Serious Adverse Events, SAEs) çš„å‘ç”Ÿæƒ…å†µï¼Œä»è€Œä¼˜åŒ–è¯•éªŒè®¾è®¡ä¸ç›‘æµ‹ã€‚ç ”ç©¶å›¢é˜Ÿåˆ†æäº†æ¥è‡ª ClinicalTrials.gov çš„ 22,107 é¡¹ä¸¤è‡‚å¹³è¡Œå¹²é¢„è¯•éªŒï¼Œæ„å»ºäº†é¢„æµ‹å“ªç»„ SAE æ¯”ä¾‹æ›´é«˜çš„åˆ†ç±»æ¨¡å‹ä»¥åŠé¢„æµ‹å¯¹ç…§ç»„ SAE æ¯”ä¾‹çš„å›å½’æ¨¡å‹ã€‚æŠ€æœ¯ä¸Šï¼Œè¯¥ç ”ç©¶é‡‡ç”¨ ClinicalT5 å’Œ BioBERT ç­‰é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹è¿›è¡Œç‰¹å¾æå–ï¼Œå¹¶ç»“åˆæ»‘åŠ¨çª—å£ (Sliding Window) æ–¹æ³•æœ‰æ•ˆè§£å†³äº†é•¿æ–‡æœ¬è¶…è¿‡æ¨¡å‹è¾“å…¥é™åˆ¶çš„é—®é¢˜ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¡¨ç°æœ€ä¼˜çš„ ClinicalT5+Transformer+MLP æ¨¡å‹åœ¨åˆ†ç±»ä»»åŠ¡ä¸­è¾¾åˆ°äº† 77.6% çš„ AUCï¼Œè€Œåœ¨å›å½’ä»»åŠ¡ä¸­å®ç°äº† 18.6% çš„ RMSEã€‚ç ”ç©¶å‘ç°æ»‘åŠ¨çª—å£æ³•ä¸€è‡´ä¼˜äºç›´æ¥å¯¹æ¯”æ³•ï¼Œä½¿åˆ†ç±»å™¨çš„å¹³å‡ AUC æå‡äº† 2.00%ï¼Œå›å½’å™¨çš„ RMSE é™ä½äº† 1.58%ã€‚è¯¥ç ”ç©¶è¯æ˜äº†åˆ©ç”¨é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹æŒ–æ˜ä¸´åºŠè¯•éªŒæ‘˜è¦æ•°æ®çš„æ½œåŠ›ï¼Œä¸ºè¯†åˆ«è¯•éªŒé¢„æœŸä¸å®é™…æŠ¥å‘Šå®‰å…¨ç»“æœä¹‹é—´çš„å·®å¼‚æä¾›äº†ç§‘å­¦å·¥å…·ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "12 pages, 4 figures. Updated to include Table 2, Supplementary Table 1, and an additional baseline random forest model",
      "pdf_url": "https://arxiv.org/pdf/2507.22919v2",
      "published_date": "2025-07-21 07:56:06 UTC",
      "updated_date": "2025-08-10 06:39:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:03:26.090604+00:00"
    },
    {
      "arxiv_id": "2507.15340v1",
      "title": "MedSR-Impact: Transformer-Based Super-Resolution for Lung CT Segmentation, Radiomics, Classification, and Prognosis",
      "title_zh": "MedSR-Impactï¼šç”¨äºè‚ºéƒ¨ CT åˆ†å‰²ã€å½±åƒç»„å­¦ã€åˆ†ç±»åŠé¢„åçš„åŸºäº Transformer çš„è¶…åˆ†è¾¨ç‡ç ”ç©¶",
      "authors": [
        "Marc Boubnovski Martell",
        "Kristofer Linton-Reid",
        "Mitchell Chen",
        "Sumeet Hindocha",
        "Benjamin Hunter",
        "Marco A. Calzado",
        "Richard Lee",
        "Joram M. Posma",
        "Eric O. Aboagye"
      ],
      "abstract": "High-resolution volumetric computed tomography (CT) is essential for accurate diagnosis and treatment planning in thoracic diseases; however, it is limited by radiation dose and hardware costs. We present the Transformer Volumetric Super-Resolution Network (\\textbf{TVSRN-V2}), a transformer-based super-resolution (SR) framework designed for practical deployment in clinical lung CT analysis. Built from scalable components, including Through-Plane Attention Blocks (TAB) and Swin Transformer V2 -- our model effectively reconstructs fine anatomical details in low-dose CT volumes and integrates seamlessly with downstream analysis pipelines. We evaluate its effectiveness on three critical lung cancer tasks -- lobe segmentation, radiomics, and prognosis -- across multiple clinical cohorts. To enhance robustness across variable acquisition protocols, we introduce pseudo-low-resolution augmentation, simulating scanner diversity without requiring private data. TVSRN-V2 demonstrates a significant improvement in segmentation accuracy (+4\\% Dice), higher radiomic feature reproducibility, and enhanced predictive performance (+0.06 C-index and AUC). These results indicate that SR-driven recovery of structural detail significantly enhances clinical decision support, positioning TVSRN-V2 as a well-engineered, clinically viable system for dose-efficient imaging and quantitative analysis in real-world CT workflows.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†TVSRN-V2 (Transformer Volumetric Super-Resolution Network)ï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºTransformerçš„ä¸‰ç»´è¶…åˆ†è¾¨ç‡ (Super-Resolution) æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³è‚ºéƒ¨CTå½±åƒä¸­å› è¾å°„å‰‚é‡å’Œç¡¬ä»¶æˆæœ¬å¯¼è‡´çš„å›¾åƒåˆ†è¾¨ç‡å—é™é—®é¢˜ã€‚è¯¥æ¨¡å‹ç»“åˆäº†Through-Plane Attention Blocks (TAB) å’Œ Swin Transformer V2 æ¶æ„ï¼Œèƒ½å¤Ÿæœ‰æ•ˆé‡å»ºä½å‰‚é‡CTä¸­çš„ç²¾ç»†è§£å‰–ç»†èŠ‚ï¼Œå¹¶æ— ç¼é›†æˆåˆ°ä¸‹æ¸¸åˆ†ææµç¨‹ä¸­ã€‚ä¸ºäº†æé«˜åœ¨ä¸åŒä¸´åºŠåè®®ä¸‹çš„é²æ£’æ€§ï¼Œç ”ç©¶è¿˜å¼•å…¥äº†ä¼ªä½åˆ†è¾¨ç‡å¢å¼º (pseudo-low-resolution augmentation) æŠ€æœ¯æ¥æ¨¡æ‹Ÿæ‰«æä»ªçš„å¤šæ ·æ€§ã€‚å®éªŒåœ¨è‚ºå¶åˆ†å‰² (lobe segmentation)ã€æ”¾å°„ç»„å­¦ (radiomics) å’Œé¢„åè¯„ä¼° (prognosis) ä¸‰é¡¹å…³é”®ä»»åŠ¡ä¸Šè¿›è¡Œäº†éªŒè¯ï¼Œç»“æœæ˜¾ç¤ºåˆ†å‰²å‡†ç¡®ç‡æå‡äº†4% Diceï¼Œä¸”æ”¾å°„ç»„å­¦ç‰¹å¾é‡ç°æ€§å’Œé¢„æµ‹æ€§èƒ½ (+0.06 C-index å’Œ AUC) å‡æœ‰æ˜¾è‘—æé«˜ã€‚è¿™è¡¨æ˜é€šè¿‡è¶…åˆ†è¾¨ç‡æŠ€æœ¯æ¢å¤ç»“æ„ç»†èŠ‚å¯æ˜¾è‘—å¢å¼ºä¸´åºŠå†³ç­–æ”¯æŒï¼Œä½¿TVSRN-V2æˆä¸ºä¸€ç§å…·å¤‡ä¸´åºŠå¯è¡Œæ€§ä¸”èƒ½å¤Ÿæé«˜å‰‚é‡æ•ˆç‡çš„è‚ºéƒ¨CTå®šé‡åˆ†æç³»ç»Ÿã€‚",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.15340v1",
      "published_date": "2025-07-21 07:53:49 UTC",
      "updated_date": "2025-07-21 07:53:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:03:28.195023+00:00"
    },
    {
      "arxiv_id": "2507.15336v1",
      "title": "Beyond Model Base Selection: Weaving Knowledge to Master Fine-grained Neural Network Design",
      "title_zh": "è¶…è¶Šæ¨¡å‹åº“é€‰æ‹©ï¼šé€šè¿‡çŸ¥è¯†ç»‡å…¥å®ç°ç»†ç²’åº¦ç¥ç»ç½‘ç»œè®¾è®¡",
      "authors": [
        "Jialiang Wang",
        "Hanmo Liu",
        "Shimin Di",
        "Zhili Wang",
        "Jiachuan Wang",
        "Lei Chen",
        "Xiaofang Zhou"
      ],
      "abstract": "Database systems have recently advocated for embedding machine learning (ML) capabilities, offering declarative model queries over large, managed model repositories, thereby circumventing the huge computational overhead of traditional ML-based algorithms in automated neural network model selection. Pioneering database studies aim to organize existing benchmark repositories as model bases (MB), querying them for the model records with the highest performance estimation metrics for given tasks. However, this static model selection practice overlooks the fine-grained, evolving relational dependencies between diverse task queries and model architecture variations, resulting in suboptimal matches and failing to further refine the model effectively. To fill the model refinement gap in database research, we propose M-DESIGN, a curated model knowledge base (MKB) pipeline for mastering neural network refinement by adaptively weaving prior insights about model architecture modification. First, we propose a knowledge weaving engine that reframes model refinement as an adaptive query problem over task metadata. Given a user's task query, M-DESIGN quickly matches and iteratively refines candidate models by leveraging a graph-relational knowledge schema that explicitly encodes data properties, architecture variations, and pairwise performance deltas as joinable relations. This schema supports fine-grained relational analytics over architecture tweaks and drives a predictive query planner that can detect and adapt to out-of-distribution (OOD) tasks. We instantiate M-DESIGN for graph analytics tasks, where our model knowledge base enriches existing benchmarks with structured metadata covering 3 graph tasks and 22 graph datasets, contributing data records of 67,760 graph models. Empirical results demonstrate that M-DESIGN delivers the optimal model in 26 of 33 data-task pairs within limited budgets.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ•°æ®åº“ç³»ç»Ÿä¸­ä¼ ç»Ÿæ¨¡å‹åº“(Model Base, MB)é™æ€é€‰æ‹©å®è·µåœ¨å¤„ç†ç»†ç²’åº¦ä»»åŠ¡ä¾èµ–å’Œæ¨¡å‹ç²¾ç»†åŒ–æ–¹é¢çš„å±€é™æ€§ï¼Œæå‡ºäº†M-DESIGNï¼Œä¸€ä¸ªæ—¨åœ¨é€šè¿‡è‡ªé€‚åº”ç»‡å…¥æ¶æ„ä¿®æ”¹å…ˆéªŒæ´å¯Ÿæ¥å®ç°ç¥ç»ç½‘ç»œç²¾ç»†åŒ–è®¾è®¡çš„æ¨¡å‹çŸ¥è¯†åº“(Model Knowledge Base, MKB)æµæ°´çº¿ã€‚è¯¥ç³»ç»Ÿå¼•å…¥äº†çŸ¥è¯†ç¼–ç»‡å¼•æ“(Knowledge Weaving Engine)ï¼Œå°†æ¨¡å‹ç²¾ç»†åŒ–è¿‡ç¨‹é‡æ„ä¸ºé’ˆå¯¹ä»»åŠ¡å…ƒæ•°æ®çš„è‡ªé€‚åº”æŸ¥è¯¢é—®é¢˜ï¼Œå¹¶åˆ©ç”¨å›¾å…³ç³»çŸ¥è¯†æ¨¡å¼(Graph-Relational Knowledge Schema)æ˜¾å¼ç¼–ç æ•°æ®å±æ€§ã€æ¶æ„å˜ä½“ä¸æ€§èƒ½å·®å¼‚ã€‚é€šè¿‡é¢„æµ‹æ€§æŸ¥è¯¢è§„åˆ’å™¨ï¼ŒM-DESIGNèƒ½å¤Ÿè¿­ä»£ä¼˜åŒ–å€™é€‰æ¨¡å‹å¹¶æœ‰æ•ˆåº”å¯¹åˆ†å¸ƒå¤–(OOD)ä»»åŠ¡ã€‚ç ”ç©¶å›¢é˜Ÿåœ¨å›¾åˆ†æé¢†åŸŸå®ä¾‹åŒ–äº†è¯¥æ¡†æ¶ï¼Œæ„å»ºäº†æ¶µç›–22ä¸ªæ•°æ®é›†å’Œ67,760ä¸ªæ¨¡å‹è®°å½•çš„ç»“æ„åŒ–å…ƒæ•°æ®åº“ã€‚å®éªŒç»“æœè¯æ˜ï¼ŒM-DESIGNåœ¨æœ‰é™é¢„ç®—ä¸‹äº33ä¸ªæ•°æ®-ä»»åŠ¡å¯¹ä¸­çš„26ä¸ªæˆåŠŸäº¤ä»˜äº†æœ€ä¼˜æ¨¡å‹ï¼Œæ˜¾è‘—æå‡äº†ç¥ç»ç½‘ç»œåŒ¹é…ä¸ç²¾ç‚¼çš„æ€§èƒ½å’Œæ•ˆç‡ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.15336v1",
      "published_date": "2025-07-21 07:49:19 UTC",
      "updated_date": "2025-07-21 07:49:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:03:30.003150+00:00"
    },
    {
      "arxiv_id": "2507.15335v1",
      "title": "ExDD: Explicit Dual Distribution Learning for Surface Defect Detection via Diffusion Synthesis",
      "title_zh": "ExDDï¼šåŸºäºæ‰©æ•£åˆæˆçš„æ˜¾å¼åŒåˆ†å¸ƒå­¦ä¹ è¡¨é¢ç¼ºé™·æ£€æµ‹",
      "authors": [
        "Muhammad Aqeel",
        "Federico Leonardi",
        "Francesco Setti"
      ],
      "abstract": "Industrial defect detection systems face critical limitations when confined to one-class anomaly detection paradigms, which assume uniform outlier distributions and struggle with data scarcity in realworld manufacturing environments. We present ExDD (Explicit Dual Distribution), a novel framework that transcends these limitations by explicitly modeling dual feature distributions. Our approach leverages parallel memory banks that capture the distinct statistical properties of both normality and anomalous patterns, addressing the fundamental flaw of uniform outlier assumptions. To overcome data scarcity, we employ latent diffusion models with domain-specific textual conditioning, generating in-distribution synthetic defects that preserve industrial context. Our neighborhood-aware ratio scoring mechanism elegantly fuses complementary distance metrics, amplifying signals in regions exhibiting both deviation from normality and similarity to known defect patterns. Experimental validation on KSDD2 demonstrates superior performance (94.2% I-AUROC, 97.7% P-AUROC), with optimal augmentation at 100 synthetic samples.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ExDDï¼ˆExplicit Dual Distributionï¼‰ï¼Œè¿™æ˜¯ä¸€ç§æ—¨åœ¨è§£å†³å·¥ä¸šç¼ºé™·æ£€æµ‹ä¸­å•ç±»å¼‚å¸¸æ£€æµ‹èŒƒå¼å±€é™æ€§çš„æ–°é¢–æ¡†æ¶ã€‚ExDDé€šè¿‡å¹¶è¡Œå†…å­˜åº“ï¼ˆParallel Memory Banksï¼‰æ˜¾å¼å»ºæ¨¡æ­£å¸¸ä¸å¼‚å¸¸çš„åŒé‡ç‰¹å¾åˆ†å¸ƒï¼Œå…‹æœäº†ä¼ ç»Ÿæ–¹æ³•ä¸­ç»Ÿä¸€ç¦»ç¾¤åˆ†å¸ƒå‡è®¾çš„ç¼ºé™·ã€‚é’ˆå¯¹å·¥ä¸šç¯å¢ƒä¸‹çš„æ•°æ®ç¨€ç¼ºé—®é¢˜ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨å¸¦æœ‰é¢†åŸŸç‰¹å®šæ–‡æœ¬çº¦æŸçš„æ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼ˆLatent Diffusion Modelsï¼‰ç”Ÿæˆé«˜è´¨é‡çš„åˆæˆç¼ºé™·æ•°æ®ï¼Œä»¥ä¿ç•™å·¥ä¸šèƒŒæ™¯ä¿¡æ¯ã€‚æ­¤å¤–ï¼Œç ”ç©¶å¼•å…¥äº†é‚»åŸŸæ„ŸçŸ¥æ¯”ç‡è¯„åˆ†æœºåˆ¶ï¼ˆNeighborhood-aware Ratio Scoringï¼‰ï¼Œé€šè¿‡èåˆäº’è¡¥çš„è·ç¦»æŒ‡æ ‡æ¥æ˜¾è‘—å¢å¼ºç¼ºé™·ä¿¡å·ã€‚åœ¨KSDD2æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼ŒExDDè¡¨ç°ä¼˜å¼‚ï¼Œåˆ†åˆ«è¾¾åˆ°äº†94.2%çš„I-AUROCå’Œ97.7%çš„P-AUROCï¼Œè¯æ˜äº†è¯¥æ–¹æ³•åœ¨æå‡å·¥ä¸šè¡¨é¢ç¼ºé™·æ£€æµ‹é²æ£’æ€§æ–¹é¢çš„æ˜¾è‘—æ•ˆæœã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to ICIAP 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.15335v1",
      "published_date": "2025-07-21 07:49:00 UTC",
      "updated_date": "2025-07-21 07:49:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:03:37.289712+00:00"
    },
    {
      "arxiv_id": "2507.16849v1",
      "title": "Post-Disaster Affected Area Segmentation with a Vision Transformer (ViT)-based EVAP Model using Sentinel-2 and Formosat-5 Imagery",
      "title_zh": "åŸºäº Vision Transformer (ViT) çš„ EVAP æ¨¡å‹ç»“åˆ Sentinel-2 ä¸ Formosat-5 å½±åƒçš„ç¾åå—ç¾åŒºåŸŸåˆ†å‰²",
      "authors": [
        "Yi-Shan Chu",
        "Hsuan-Cheng Wei"
      ],
      "abstract": "We propose a vision transformer (ViT)-based deep learning framework to refine disaster-affected area segmentation from remote sensing imagery, aiming to support and enhance the Emergent Value Added Product (EVAP) developed by the Taiwan Space Agency (TASA). The process starts with a small set of manually annotated regions. We then apply principal component analysis (PCA)-based feature space analysis and construct a confidence index (CI) to expand these labels, producing a weakly supervised training set. These expanded labels are then used to train ViT-based encoder-decoder models with multi-band inputs from Sentinel-2 and Formosat-5 imagery. Our architecture supports multiple decoder variants and multi-stage loss strategies to improve performance under limited supervision. During the evaluation, model predictions are compared with higher-resolution EVAP output to assess spatial coherence and segmentation consistency. Case studies on the 2022 Poyang Lake drought and the 2023 Rhodes wildfire demonstrate that our framework improves the smoothness and reliability of segmentation results, offering a scalable approach for disaster mapping when accurate ground truth is unavailable.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç¾åå—ç¾åŒºåŸŸåˆ†å‰²ä»»åŠ¡ï¼Œæå‡ºäº†ä¸€ç§åŸºäº Vision Transformer (ViT) çš„æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œæ—¨åœ¨æ”¯æŒå¹¶ä¼˜åŒ–å°æ¹¾å¤ªç©ºä¸­å¿ƒ (TASA) å¼€å‘çš„ Emergent Value Added Product (EVAP) é¥æ„Ÿå½±åƒäº§å“ã€‚è¯¥æ¡†æ¶é€šè¿‡å°‘é‡äººå·¥æ ‡æ³¨åŒºåŸŸï¼Œç»“åˆåŸºäº Principal Component Analysis (PCA) çš„ç‰¹å¾ç©ºé—´åˆ†æå¹¶æ„å»ºç½®ä¿¡æŒ‡æ•° (Confidence Index, CI) æ¥æ‰©å……æ ‡ç­¾ï¼Œä»è€Œç”Ÿæˆå¼±ç›‘ç£è®­ç»ƒé›†ã€‚æ¨¡å‹åˆ©ç”¨ Sentinel-2 å’Œ Formosat-5 å«æ˜Ÿçš„å¤šæ³¢æ®µæ•°æ®è¾“å…¥æ¥è®­ç»ƒ ViT ç¼–ç å™¨-è§£ç å™¨æ¶æ„ï¼Œå¹¶é‡‡ç”¨å¤šé˜¶æ®µæŸå¤±ç­–ç•¥ä»¥æå‡æœ‰é™ç›‘ç£ä¸‹çš„æ€§èƒ½ã€‚é€šè¿‡ 2022 å¹´é„±é˜³æ¹–å¹²æ—±å’Œ 2023 å¹´ç½—å¾·å²›é‡ç«çš„æ¡ˆä¾‹ç ”ç©¶ï¼Œè¯¥æ–¹æ³•åœ¨ç©ºé—´ç›¸å¹²æ€§å’Œåˆ†å‰²ä¸€è‡´æ€§ä¸Šè¡¨ç°å‡ºè‰²ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ¡†æ¶æ˜¾è‘—æé«˜äº†åˆ†å‰²ç»“æœçš„å¹³æ»‘åº¦ä¸å¯é æ€§ï¼Œä¸ºç¼ºä¹ç²¾ç¡®åœ°é¢çœŸç›¸ (ground truth) æ—¶çš„ç¾å®³åˆ¶å›¾æä¾›äº†ä¸€ç§å…·å¤‡å¯æ‰©å±•æ€§çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.16849v1",
      "published_date": "2025-07-21 07:48:07 UTC",
      "updated_date": "2025-07-21 07:48:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:03:41.200756+00:00"
    },
    {
      "arxiv_id": "2507.15330v1",
      "title": "QSAF: A Novel Mitigation Framework for Cognitive Degradation in Agentic AI",
      "title_zh": "QSAFï¼šä¸€ç§é’ˆå¯¹æ™ºèƒ½ä½“ AI è®¤çŸ¥é€€åŒ–çš„æ–°å‹ç¼“è§£æ¡†æ¶",
      "authors": [
        "Hammad Atta",
        "Muhammad Zeeshan Baig",
        "Yasir Mehmood",
        "Nadeem Shahzad",
        "Ken Huang",
        "Muhammad Aziz Ul Haq",
        "Muhammad Awais",
        "Kamal Ahmed"
      ],
      "abstract": "We introduce Cognitive Degradation as a novel vulnerability class in agentic AI systems. Unlike traditional adversarial external threats such as prompt injection, these failures originate internally, arising from memory starvation, planner recursion, context flooding, and output suppression. These systemic weaknesses lead to silent agent drift, logic collapse, and persistent hallucinations over time. To address this class of failures, we introduce the Qorvex Security AI Framework for Behavioral & Cognitive Resilience (QSAF Domain 10), a lifecycle-aware defense framework defined by a six-stage cognitive degradation lifecycle. The framework includes seven runtime controls (QSAF-BC-001 to BC-007) that monitor agent subsystems in real time and trigger proactive mitigation through fallback routing, starvation detection, and memory integrity enforcement. Drawing from cognitive neuroscience, we map agentic architectures to human analogs, enabling early detection of fatigue, starvation, and role collapse. By introducing a formal lifecycle and real-time mitigation controls, this work establishes Cognitive Degradation as a critical new class of AI system vulnerability and proposes the first cross-platform defense model for resilient agentic behavior.",
      "tldr_zh": "è¯¥ç ”ç©¶å¼•å…¥äº†è®¤çŸ¥é€€åŒ–(Cognitive Degradation)è¿™ä¸€æ™ºèƒ½ä½“äººå·¥æ™ºèƒ½(Agentic AI)ç³»ç»Ÿçš„æ–°å‹å†…éƒ¨æ¼æ´ç±»åˆ«ï¼Œåˆ†æäº†å…¶ç”±å†…å­˜é¥¥é¥¿(memory starvation)ã€è§„åˆ’å™¨é€’å½’(planner recursion)ã€ä¸Šä¸‹æ–‡æ³›æ»¥(context flooding)ç­‰å› ç´ å¯¼è‡´çš„é€»è¾‘å´©æºƒå’ŒæŒç»­å¹»è§‰é—®é¢˜ã€‚ä¸ºåº”å¯¹æ­¤ç±»å¨èƒï¼Œä½œè€…æå‡ºäº†Qorvex Security AI Framework for Behavioral & Cognitive Resilience (QSAF Domain 10)é˜²å¾¡æ¡†æ¶ï¼Œå®šä¹‰äº†ç”±å…­ä¸ªé˜¶æ®µç»„æˆçš„è®¤çŸ¥é€€åŒ–ç”Ÿå‘½å‘¨æœŸã€‚è¯¥æ¡†æ¶é›†æˆäº†ä¸ƒé¡¹è¿è¡Œæ—¶æ§åˆ¶æªæ–½(QSAF-BC-001è‡³BC-007)ï¼Œé€šè¿‡å®æ—¶ç›‘æ§æ™ºèƒ½ä½“å­ç³»ç»Ÿå¹¶è§¦å‘å›é€€è·¯ç”±ã€é¥¥é¥¿æ£€æµ‹å’Œå†…å­˜å®Œæ•´æ€§å¼ºåˆ¶æ‰§è¡Œç­‰æ‰‹æ®µå®ç°ä¸»åŠ¨ç¼“è§£ã€‚ç ”ç©¶è¿›ä¸€æ­¥å€Ÿé‰´è®¤çŸ¥ç¥ç»ç§‘å­¦ï¼Œå°†æ™ºèƒ½ä½“æ¶æ„ä¸äººç±»è®¤çŸ¥æ¨¡æ‹Ÿè¿›è¡Œæ˜ å°„ï¼Œä»è€Œèƒ½å¤Ÿæ—©æœŸæ£€æµ‹ç³»ç»Ÿçš„ç–²åŠ³ã€é¥¥é¥¿å’Œè§’è‰²å´©æºƒã€‚è¯¥å·¥ä½œé¦–æ¬¡å°†è®¤çŸ¥é€€åŒ–ç¡®ç«‹ä¸ºå…³é”®çš„AIç³»ç»Ÿæ¼æ´ç±»åˆ«ï¼Œå¹¶ä¸ºæ„å»ºè·¨å¹³å°ä¸”å…·å¤‡éŸ§æ€§çš„æ™ºèƒ½ä½“è¡Œä¸ºé˜²å¾¡æ¨¡å‹æä¾›äº†ç†è®ºä¸æŠ€æœ¯æ”¯æ’‘ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.15330v1",
      "published_date": "2025-07-21 07:41:58 UTC",
      "updated_date": "2025-07-21 07:41:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:03:45.492239+00:00"
    },
    {
      "arxiv_id": "2507.16848v1",
      "title": "Dynamic Simulation Framework for Disinformation Dissemination and Correction With Social Bots",
      "title_zh": "ç¤¾äº¤æœºå™¨äººå‚ä¸ä¸‹çš„è™šå‡ä¿¡æ¯ä¼ æ’­ä¸çº æ­£åŠ¨æ€ä»¿çœŸæ¡†æ¶",
      "authors": [
        "Boyu Qiao",
        "Kun Li",
        "Wei Zhou",
        "Songlin Hu"
      ],
      "abstract": "In the human-bot symbiotic information ecosystem, social bots play key roles in spreading and correcting disinformation. Understanding their influence is essential for risk control and better governance. However, current studies often rely on simplistic user and network modeling, overlook the dynamic behavior of bots, and lack quantitative evaluation of correction strategies. To fill these gaps, we propose MADD, a Multi Agent based framework for Disinformation Dissemination. MADD constructs a more realistic propagation network by integrating the Barabasi Albert Model for scale free topology and the Stochastic Block Model for community structures, while designing node attributes based on real world user data. Furthermore, MADD incorporates both malicious and legitimate bots, with their controlled dynamic participation allows for quantitative analysis of correction strategies. We evaluate MADD using individual and group level metrics. We experimentally verify the real world consistency of MADD user attributes and network structure, and we simulate the dissemination of six disinformation topics, demonstrating the differential effects of fact based and narrative based correction strategies.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† MADDï¼Œä¸€ç§åŸºäºå¤šæ™ºèƒ½ä½“ (Multi Agent) çš„è™šå‡ä¿¡æ¯ä¼ æ’­æ¡†æ¶ï¼Œæ—¨åœ¨æ·±å…¥åˆ†æç¤¾äº¤æœºå™¨äºº (social bots) åœ¨è™šå‡ä¿¡æ¯ä¼ æ’­ä¸ä¿®æ­£ä¸­çš„å…³é”®ä½œç”¨ã€‚MADD é€šè¿‡æ•´åˆ Barabasi Albert Model æ¯”ä¾‹ç¼©æ”¾æ‹“æ‰‘å’Œ Stochastic Block Model ç¤¾åŒºç»“æ„ï¼Œå¹¶ç»“åˆçœŸå®ä¸–ç•Œç”¨æˆ·æ•°æ®ï¼Œæ„å»ºäº†æ›´å…·ç°å®æ€§çš„ä¼ æ’­ç½‘ç»œã€‚è¯¥æ¡†æ¶å¼•å…¥äº†æ¶æ„å’Œåˆæ³•æœºå™¨äººçš„åŠ¨æ€å‚ä¸æœºåˆ¶ï¼Œå¡«è¡¥äº†ä»¥å¾€ç ”ç©¶åœ¨æœºå™¨äººè¡Œä¸ºå»ºæ¨¡å’Œä¿®æ­£ç­–ç•¥å®šé‡è¯„ä¼°æ–¹é¢çš„ç©ºç™½ã€‚ç ”ç©¶é€šè¿‡ä¸ªä½“å’Œç¾¤ä½“å±‚é¢çš„æŒ‡æ ‡éªŒè¯äº† MADD ä¸ç°å®ä¸–ç•Œçš„ä¸€è‡´æ€§ï¼Œå¹¶æ¨¡æ‹Ÿäº†å…­ç±»è™šå‡ä¿¡æ¯è¯é¢˜çš„ä¼ æ’­è¿‡ç¨‹ã€‚å®éªŒç»“æœæ­ç¤ºäº†åŸºäºäº‹å® (fact based) å’ŒåŸºäºå™äº‹ (narrative based) çš„ä¿®æ­£ç­–ç•¥åœ¨ä¸åŒæƒ…å¢ƒä¸‹çš„å·®å¼‚åŒ–æ•ˆæœï¼Œä¸ºè™šå‡ä¿¡æ¯çš„é£é™©æ§åˆ¶å’Œæ²»ç†æä¾›äº†ç†è®ºæ”¯æŒã€‚",
      "categories": [
        "cs.SI",
        "cs.AI"
      ],
      "primary_category": "cs.SI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.16848v1",
      "published_date": "2025-07-21 07:15:17 UTC",
      "updated_date": "2025-07-21 07:15:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:03:49.292022+00:00"
    },
    {
      "arxiv_id": "2507.15296v1",
      "title": "Butterfly Effects in Toolchains: A Comprehensive Analysis of Failed Parameter Filling in LLM Tool-Agent Systems",
      "title_zh": "å·¥å…·é“¾ä¸­çš„è´è¶æ•ˆåº”ï¼šLLM å·¥å…·æ™ºèƒ½ä½“ç³»ç»Ÿå‚æ•°å¡«å……å¤±è´¥çš„å…¨é¢åˆ†æ",
      "authors": [
        "Qian Xiong",
        "Yuekai Huang",
        "Ziyou Jiang",
        "Zhiyuan Chang",
        "Yujia Zheng",
        "Tianhao Li",
        "Mingyang Li"
      ],
      "abstract": "The emergence of the tool agent paradigm has broadened the capability boundaries of the Large Language Model (LLM), enabling it to complete more complex tasks. However, the effectiveness of this paradigm is limited due to the issue of parameter failure during its execution. To explore this phenomenon and propose corresponding suggestions, we first construct a parameter failure taxonomy in this paper. We derive five failure categories from the invocation chain of a mainstream tool agent. Then, we explore the correlation between three different input sources and failure categories by applying 15 input perturbation methods to the input. Experimental results show that parameter name hallucination failure primarily stems from inherent LLM limitations, while issues with input sources mainly cause other failure patterns. To improve the reliability and effectiveness of tool-agent interactions, we propose corresponding improvement suggestions, including standardizing tool return formats, improving error feedback mechanisms, and ensuring parameter consistency.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹ (LLM) å·¥å…·æ™ºèƒ½ä½“ç³»ç»Ÿåœ¨æ‰§è¡Œè¿‡ç¨‹ä¸­çš„å‚æ•°å¡«å……å¤±è´¥ (parameter failure) é—®é¢˜è¿›è¡Œäº†å…¨é¢åˆ†æã€‚ä½œè€…é¦–å…ˆåŸºäºä¸»æµå·¥å…·æ™ºèƒ½ä½“è°ƒç”¨é“¾æ„å»ºäº†åŒ…å«äº”ç§å¤±æ•ˆç±»åˆ«çš„å‚æ•°å¤±æ•ˆåˆ†ç±»ä½“ç³» (parameter failure taxonomy)ã€‚ç ”ç©¶é€šè¿‡åº”ç”¨ 15 ç§è¾“å…¥æ‰°åŠ¨ (input perturbation) æ–¹æ³•ï¼Œæ·±å…¥æ¢è®¨äº†ä¸‰ç§ä¸åŒè¾“å…¥æ¥æºä¸å¤±æ•ˆç±»åˆ«ä¹‹é—´çš„ç›¸å…³æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå‚æ•°åå¹»è§‰ (parameter name hallucination) ä¸»è¦æºäº LLM çš„å›ºæœ‰å±€é™ï¼Œè€Œå…¶ä»–å¤±æ•ˆæ¨¡å¼åˆ™ä¸»è¦ç”±è¾“å…¥æ¥æºé—®é¢˜å¼•èµ·ã€‚ä¸ºæå‡å·¥å…·æ™ºèƒ½ä½“äº¤äº’çš„å¯é æ€§ï¼Œæœ¬æ–‡æå‡ºäº†æ ‡å‡†åŒ–å·¥å…·è¿”å›æ ¼å¼ã€æ”¹è¿›é”™è¯¯åé¦ˆæœºåˆ¶ (error feedback mechanisms) ä»¥åŠç¡®ä¿å‚æ•°ä¸€è‡´æ€§ç­‰æ”¹è¿›å»ºè®®ã€‚è¯¥é¡¹å·¥ä½œé€šè¿‡æ­ç¤ºå·¥å…·é“¾ä¸­çš„â€œè´è¶æ•ˆåº”â€ï¼Œä¸ºä¼˜åŒ–å¤æ‚ä»»åŠ¡ä¸‹çš„æ™ºèƒ½ä½“ç³»ç»Ÿç¨³å®šæ€§æä¾›äº†ç†è®ºæ”¯æŒä¸å®è·µæŒ‡å¯¼ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.15296v1",
      "published_date": "2025-07-21 06:55:37 UTC",
      "updated_date": "2025-07-21 06:55:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:03:50.395959+00:00"
    },
    {
      "arxiv_id": "2507.15292v4",
      "title": "EndoControlMag: Robust Endoscopic Vascular Motion Magnification with Periodic Reference Resetting and Hierarchical Tissue-aware Dual-Mask Control",
      "title_zh": "EndoControlMagï¼šç»“åˆå‘¨æœŸæ€§å‚è€ƒé‡ç½®ä¸åˆ†å±‚ç»„ç»‡æ„ŸçŸ¥åŒæ©è†œæ§åˆ¶çš„ç¨³å¥å†…çª¥é•œè¡€ç®¡è¿åŠ¨æ”¾å¤§æŠ€æœ¯",
      "authors": [
        "An Wang",
        "Rulin Zhou",
        "Mengya Xu",
        "Yiru Ye",
        "Longfei Gou",
        "Yiting Chang",
        "Hao Chen",
        "Chwee Ming Lim",
        "Jiankun Wang",
        "Hongliang Ren"
      ],
      "abstract": "Visualizing subtle vascular motions in endoscopic surgery is crucial for surgical precision and decision-making, yet remains challenging due to the complex and dynamic nature of surgical scenes. To address this, we introduce EndoControlMag, a training-free, Lagrangian-based framework with mask-conditioned vascular motion magnification tailored to endoscopic environments. Our approach features two key modules: a Periodic Reference Resetting (PRR) scheme that divides videos into short overlapping clips with dynamically updated reference frames to prevent error accumulation while maintaining temporal coherence, and a Hierarchical Tissue-aware Magnification (HTM) framework with dual-mode mask dilation. HTM first tracks vessel cores using a pretrained visual tracking model to maintain accurate localization despite occlusions and view changes. It then applies one of two adaptive softening strategies to surrounding tissues: motion-based softening that modulates magnification strength proportional to observed tissue displacement, or distance-based exponential decay that simulates biomechanical force attenuation. This dual-mode approach accommodates diverse surgical scenarios-motion-based softening excels with complex tissue deformations while distance-based softening provides stability during unreliable optical flow conditions. We evaluate EndoControlMag on our EndoVMM24 dataset spanning four different surgery types and various challenging scenarios, including occlusions, instrument disturbance, view changes, and vessel deformations. Quantitative metrics, visual assessments, and expert surgeon evaluations demonstrate that EndoControlMag significantly outperforms existing methods in both magnification accuracy and visual quality while maintaining robustness across challenging surgical conditions. The code, dataset, and video results are available at https://szupc.github.io/EndoControlMag/.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† EndoControlMagï¼Œä¸€ä¸ªæ— éœ€è®­ç»ƒã€åŸºäº Lagrangian çš„å†…çª¥é•œè¡€ç®¡è¿åŠ¨æ”¾å¤§æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¤æ‚åŠ¨æ€æ‰‹æœ¯åœºæ™¯ä¸‹å¾®å¼±è¡€ç®¡è¿åŠ¨éš¾ä»¥å¯è§†åŒ–çš„éš¾é¢˜ã€‚è¯¥æ¡†æ¶æ ¸å¿ƒå¼•å…¥äº†å‘¨æœŸæ€§å‚è€ƒé‡ç½® (Periodic Reference Resetting, PRR) æœºåˆ¶ï¼Œé€šè¿‡å°†è§†é¢‘åˆ’åˆ†ä¸ºå¸¦æœ‰åŠ¨æ€æ›´æ–°å‚è€ƒå¸§çš„é‡å çŸ­ç‰‡æ®µï¼Œåœ¨ä¿æŒæ—¶é—´è¿è´¯æ€§çš„åŒæ—¶æœ‰æ•ˆé˜²æ­¢äº†è¯¯å·®ç´¯ç§¯ã€‚æ­¤å¤–ï¼Œç ”ç©¶é‡‡ç”¨äº†å…·æœ‰åŒæ¨¡æ©ç æ‰©å¼ çš„åˆ†å±‚ç»„ç»‡æ„ŸçŸ¥æ”¾å¤§ (Hierarchical Tissue-aware Magnification, HTM) æ–¹æ¡ˆï¼Œåˆ©ç”¨é¢„è®­ç»ƒè§†è§‰è·Ÿè¸ªæ¨¡å‹é”å®šè¡€ç®¡æ ¸å¿ƒï¼Œå¹¶ç»“åˆè¿åŠ¨æ„ŸçŸ¥æŸ”åŒ–ä¸è·ç¦»æŒ‡æ•°è¡°å‡ç­–ç•¥æ¥åº”å¯¹å¤æ‚çš„ç»„ç»‡å˜å½¢å’Œä¸å¯é çš„å…‰æµ (Optical Flow) æ¡ä»¶ã€‚åœ¨æ¶µç›–å››ç§æ‰‹æœ¯ç±»å‹åŠé®æŒ¡ã€å™¨æ¢°å¹²æ‰°ç­‰æŒ‘æˆ˜åœºæ™¯çš„ EndoVMM24 æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒEndoControlMag åœ¨æ”¾å¤§ç²¾åº¦å’Œè§†è§‰è´¨é‡ä¸Šå‡æ˜¾è‘—è¶…è¶Šäº†ç°æœ‰æ–¹æ³•ã€‚ç»è¿‡å®šé‡æŒ‡æ ‡å’Œå¤–ç§‘ä¸“å®¶çš„è¯„ä¼°ï¼Œè¯¥æ¡†æ¶è¯æ˜äº†å…¶åœ¨æç«¯æ‰‹æœ¯ç¯å¢ƒä¸‹çš„é²æ£’æ€§ï¼Œä¸ºæé«˜æ‰‹æœ¯ç²¾åº¦å’Œå†³ç­–æ”¯æŒå¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.15292v4",
      "published_date": "2025-07-21 06:47:44 UTC",
      "updated_date": "2025-07-24 13:26:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:04:02.648106+00:00"
    },
    {
      "arxiv_id": "2507.15288v1",
      "title": "Preferential subspace identification (PSID) with forward-backward smoothing",
      "title_zh": "ç»“åˆå‰å‘-åå‘å¹³æ»‘çš„åå¥½å­ç©ºé—´è¾¨è¯† (PSID)",
      "authors": [
        "Omid G. Sani",
        "Maryam M. Shanechi"
      ],
      "abstract": "System identification methods for multivariate time-series, such as neural and behavioral recordings, have been used to build models for predicting one from the other. For example, Preferential Subspace Identification (PSID) builds a state-space model of a primary time-series (e.g., neural activity) to optimally predict a secondary time-series (e.g., behavior). However, PSID focuses on optimal prediction using past primary data, even though in offline applications, better estimation can be achieved by incorporating concurrent data (filtering) or all available data (smoothing). Here, we extend PSID to enable optimal filtering and smoothing. First, we show that the presence of a secondary signal makes it possible to uniquely identify a model with an optimal Kalman update step (to enable filtering) from a family of otherwise equivalent state-space models. Our filtering solution augments PSID with a reduced-rank regression step that directly learns the optimal gain required for the update step from data. We refer to this extension of PSID as PSID with filtering. Second, inspired by two-filter Kalman smoother formulations, we develop a novel forward-backward PSID smoothing algorithm where we first apply PSID with filtering and then apply it again in the reverse time direction on the residuals of the filtered secondary signal. We validate our methods on simulated data, showing that our approach recovers the ground-truth model parameters for filtering, and achieves optimal filtering and smoothing decoding performance of the secondary signal that matches the ideal performance of the true underlying model. This work provides a principled framework for optimal linear filtering and smoothing in the two-signal setting, significantly expanding the toolkit for analyzing dynamic interactions in multivariate time-series.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç”¨äºå¤šå…ƒæ—¶é—´åºåˆ—åˆ†æçš„ä¼˜å…ˆå­ç©ºé—´è¯†åˆ«(Preferential Subspace Identification, PSID)æ–¹æ³•è¿›è¡Œäº†æ‰©å±•ï¼Œæ—¨åœ¨è§£å†³å…¶ä»¥å¾€ä¸»è¦å…³æ³¨åˆ©ç”¨è¿‡å»æ•°æ®è¿›è¡Œé¢„æµ‹è€Œå¿½ç•¥äº†ç»“åˆå½“å‰æˆ–å…¨éƒ¨æ•°æ®è¿›è¡ŒFilteringå’ŒSmoothingçš„é—®é¢˜ã€‚ç ”ç©¶äººå‘˜é¦–å…ˆè¯æ˜äº†è¾…åŠ©ä¿¡å·çš„å­˜åœ¨ä½¿å¾—ä»ç­‰æ•ˆçŠ¶æ€ç©ºé—´æ¨¡å‹æ—ä¸­è¯†åˆ«å…·æœ‰æœ€ä¼˜Kalmanæ›´æ–°æ­¥éª¤çš„æ¨¡å‹æˆä¸ºå¯èƒ½ï¼Œå¹¶æå‡ºé€šè¿‡Reduced-rank regressionç›´æ¥ä»æ•°æ®ä¸­å­¦ä¹ æœ€ä¼˜å¢ç›Šçš„Filteringæ–¹æ¡ˆã€‚éšåï¼Œå—åŒæ»¤æ³¢å™¨Kalmanå¹³æ»‘å…¬å¼å¯å‘ï¼Œå¼€å‘äº†ä¸€ç§æ–°å‹çš„å‰å‘-åå‘(Forward-backward)PSIDå¹³æ»‘ç®—æ³•ï¼Œé€šè¿‡åœ¨æ»¤æ³¢æ®‹å·®ä¸Šåå‘é‡å¤åº”ç”¨PSIDæ¥å®ç°ã€‚æ¨¡æ‹Ÿå®éªŒéªŒè¯äº†è¯¥æ–¹æ³•èƒ½å¤Ÿå‡†ç¡®æ¢å¤æ¨¡å‹å‚æ•°ï¼Œå¹¶åœ¨è§£ç æ€§èƒ½ä¸Šè¾¾åˆ°äº†ä¸çœŸå®æ¨¡å‹ä¸€è‡´çš„æœ€ä¼˜æ°´å¹³ã€‚è¯¥å·¥ä½œä¸ºåŒä¿¡å·è®¾å®šä¸‹çš„çº¿æ€§Filteringå’ŒSmoothingæä¾›äº†ä¸€ä¸ªåŸåˆ™æ€§æ¡†æ¶ï¼Œæ˜¾è‘—æå‡äº†åˆ†æå¤šå…ƒæ—¶é—´åºåˆ—åŠ¨æ€äº¤äº’çš„èƒ½åŠ›ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "17 pages, 5 figures",
      "pdf_url": "https://arxiv.org/pdf/2507.15288v1",
      "published_date": "2025-07-21 06:39:31 UTC",
      "updated_date": "2025-07-21 06:39:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:04:10.087620+00:00"
    },
    {
      "arxiv_id": "2507.15287v1",
      "title": "Mixture of Autoencoder Experts Guidance using Unlabeled and Incomplete Data for Exploration in Reinforcement Learning",
      "title_zh": "åˆ©ç”¨æœªæ ‡è®°ä¸ä¸å®Œæ•´æ•°æ®çš„è‡ªåŠ¨ç¼–ç å™¨ä¸“å®¶æ··åˆå¼•å¯¼å¼ºåŒ–å­¦ä¹ æ¢ç´¢",
      "authors": [
        "Elias MalomgrÃ©",
        "Pieter Simoens"
      ],
      "abstract": "Recent trends in Reinforcement Learning (RL) highlight the need for agents to learn from reward-free interactions and alternative supervision signals, such as unlabeled or incomplete demonstrations, rather than relying solely on explicit reward maximization. Additionally, developing generalist agents that can adapt efficiently in real-world environments often requires leveraging these reward-free signals to guide learning and behavior. However, while intrinsic motivation techniques provide a means for agents to seek out novel or uncertain states in the absence of explicit rewards, they are often challenged by dense reward environments or the complexity of high-dimensional state and action spaces. Furthermore, most existing approaches rely directly on the unprocessed intrinsic reward signals, which can make it difficult to shape or control the agent's exploration effectively. We propose a framework that can effectively utilize expert demonstrations, even when they are incomplete and imperfect. By applying a mapping function to transform the similarity between an agent's state and expert data into a shaped intrinsic reward, our method allows for flexible and targeted exploration of expert-like behaviors. We employ a Mixture of Autoencoder Experts to capture a diverse range of behaviors and accommodate missing information in demonstrations. Experiments show our approach enables robust exploration and strong performance in both sparse and dense reward environments, even when demonstrations are sparse or incomplete. This provides a practical framework for RL in realistic settings where optimal data is unavailable and precise reward control is needed.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åˆ©ç”¨ Mixture of Autoencoder Experts (MoAE) å¼•å¯¼ Reinforcement Learning æ™ºèƒ½ä½“åœ¨æœªæ ‡è®°æˆ–ä¸å®Œæ•´æ•°æ®ä¸‹è¿›è¡Œæ¢ç´¢çš„æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³æ™ºèƒ½ä½“åœ¨ç°å®ç¯å¢ƒä¸­ç¼ºä¹æ˜ç¡®å¥–åŠ±ä¿¡å·æˆ–ä»…èƒ½è·å¾—ä¸å®Œå–„ä¸“å®¶æ¼”ç¤ºæ—¶çš„å­¦ä¹ éš¾é¢˜ã€‚è¯¥æ–¹æ³•é€šè¿‡æ˜ å°„å‡½æ•°å°†æ™ºèƒ½ä½“çŠ¶æ€ä¸ä¸“å®¶æ•°æ®ä¹‹é—´çš„ç›¸ä¼¼æ€§è½¬åŒ–ä¸ºå¡‘é€ åçš„å†…åœ¨å¥–åŠ± (intrinsic reward)ï¼Œä»è€Œå®ç°å¯¹ç±»ä¸“å®¶è¡Œä¸ºçš„çµæ´»ä¸”æœ‰é’ˆå¯¹æ€§çš„æ¢ç´¢ã€‚æ ¸å¿ƒçš„ Mixture of Autoencoder Experts ç»“æ„èƒ½å¤Ÿæ•æ‰å¤šæ ·çš„è¡Œä¸ºæ¨¡å¼ï¼Œå¹¶æœ‰æ•ˆå¤„ç†æ¼”ç¤ºæ•°æ®ä¸­çš„ä¿¡æ¯ç¼ºå¤±é—®é¢˜ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ç¨€ç–å¥–åŠ±å’Œç¨ å¯†å¥–åŠ±ç¯å¢ƒä¸‹å‡å±•ç°å‡ºé²æ£’çš„æ¢ç´¢èƒ½åŠ›å’Œä¼˜å¼‚çš„æ€§èƒ½ï¼Œå³ä½¿ä¸“å®¶æ¼”ç¤ºæåº¦ç¨€ç–æˆ–ä¸å®Œæ•´ä¹Ÿä¾ç„¶æœ‰æ•ˆã€‚è¿™ä¸€ç ”ç©¶ä¸ºåœ¨æ— æ³•è·å–æœ€ä¼˜æ•°æ®ä¸”éœ€è¦ç²¾ç¡®å¥–åŠ±æ§åˆ¶çš„ç°å®åœºæ™¯ä¸­åº”ç”¨å¼ºåŒ–å­¦ä¹ æä¾›äº†ä¸€ä¸ªåˆ‡å®å¯è¡Œçš„æ¡†æ¶ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 8 figures, accepted for the non-archival workshop \"Workshop on Reinforcement Learning Beyond Rewards @ Reinforcement Learning Conference 2025\"",
      "pdf_url": "https://arxiv.org/pdf/2507.15287v1",
      "published_date": "2025-07-21 06:38:46 UTC",
      "updated_date": "2025-07-21 06:38:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:04:12.990195+00:00"
    },
    {
      "arxiv_id": "2507.15281v1",
      "title": "A Novel Self-Evolution Framework for Large Language Models",
      "title_zh": "ä¸€ç§é¢å‘å¤§è¯­è¨€æ¨¡å‹çš„æ–°å‹è‡ªè¿›åŒ–æ¡†æ¶",
      "authors": [
        "Haoran Sun",
        "Zekun Zhang",
        "Shaoning Zeng"
      ],
      "abstract": "The capabilities of Large Language Models (LLMs) are limited to some extent by pre-training, so some researchers optimize LLMs through post-training. Existing post-training strategies, such as memory-based retrieval or preference optimization, improve user alignment yet fail to enhance the model's domain cognition. To bridge this gap, we propose a novel Dual-Phase Self-Evolution (DPSE) framework that jointly optimizes user preference adaptation and domain-specific competence. DPSE introduces a Censor module to extract multi-dimensional interaction signals and estimate satisfaction scores, which guide structured data expansion via topic-aware and preference-driven strategies. These expanded datasets support a two-stage fine-tuning pipeline: supervised domain grounding followed by frequency-aware preference optimization. Experiments across general NLP benchmarks and long-term dialogue tasks demonstrate that DPSE consistently outperforms Supervised Fine-Tuning, Preference Optimization, and Memory-Augmented baselines. Ablation studies validate the contribution of each module. In this way, our framework provides an autonomous path toward continual self-evolution of LLMs.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†åŒé˜¶æ®µè‡ªæˆ‘è¿›åŒ– (Dual-Phase Self-Evolution, DPSE) æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹ (LLMs) åœ¨åè®­ç»ƒ (post-training) é˜¶æ®µéš¾ä»¥æå‡é¢†åŸŸè®¤çŸ¥èƒ½åŠ›çš„é—®é¢˜ã€‚è¯¥æ¡†æ¶å¼•å…¥äº†å®¡æŸ¥æ¨¡å— (Censor module) æ¥æå–å¤šç»´äº¤äº’ä¿¡å·å¹¶ä¼°ç®—æ»¡æ„åº¦è¯„åˆ†ï¼Œä»è€ŒæŒ‡å¯¼åŸºäºä¸»é¢˜æ„ŸçŸ¥å’Œåå¥½é©±åŠ¨çš„ç»“æ„åŒ–æ•°æ®æ‰©å±•ã€‚é€šè¿‡ç›‘ç£é¢†åŸŸè½åœ° (supervised domain grounding) å’Œé¢‘ç‡æ„ŸçŸ¥åå¥½ä¼˜åŒ– (frequency-aware preference optimization) çš„ä¸¤é˜¶æ®µå¾®è°ƒæµæ°´çº¿ï¼ŒDPSE å®ç°äº†ç”¨æˆ·åå¥½é€‚åº”ä¸é¢†åŸŸèƒ½åŠ›çš„ååŒä¼˜åŒ–ã€‚åœ¨é€šç”¨ NLP åŸºå‡†æµ‹è¯•å’Œé•¿æœŸå¯¹è¯ä»»åŠ¡ä¸­çš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ¡†æ¶çš„è¡¨ç°ä¸€è‡´ä¼˜äºç›‘ç£å¾®è°ƒ (SFT)ã€åå¥½ä¼˜åŒ–å’Œå†…å­˜å¢å¼º (Memory-Augmented) ç­‰åŸºå‡†æ¨¡å‹ã€‚æ¶ˆèå®éªŒè¿›ä¸€æ­¥è¯å®äº†å„æ¨¡å—çš„æœ‰æ•ˆæ€§ï¼Œè¯æ˜è¯¥æ¡†æ¶ä¸ºå®ç° LLMs çš„æŒç»­è‡ªä¸»è¿›åŒ–æä¾›äº†ä¸€æ¡æœ‰æ•ˆçš„è·¯å¾„ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.15281v1",
      "published_date": "2025-07-21 06:30:39 UTC",
      "updated_date": "2025-07-21 06:30:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:04:20.449030+00:00"
    },
    {
      "arxiv_id": "2507.15272v1",
      "title": "A2TTS: TTS for Low Resource Indian Languages",
      "title_zh": "A2TTSï¼šé¢å‘ä½èµ„æºå°åº¦è¯­è¨€çš„è¯­éŸ³åˆæˆ",
      "authors": [
        "Ayush Singh Bhadoriya",
        "Abhishek Nikunj Shinde",
        "Isha Pandey",
        "Ganesh Ramakrishnan"
      ],
      "abstract": "We present a speaker conditioned text-to-speech (TTS) system aimed at addressing challenges in generating speech for unseen speakers and supporting diverse Indian languages. Our method leverages a diffusion-based TTS architecture, where a speaker encoder extracts embeddings from short reference audio samples to condition the DDPM decoder for multispeaker generation. To further enhance prosody and naturalness, we employ a cross-attention based duration prediction mechanism that utilizes reference audio, enabling more accurate and speaker consistent timing. This results in speech that closely resembles the target speaker while improving duration modeling and overall expressiveness. Additionally, to improve zero-shot generation, we employed classifier free guidance, allowing the system to generate speech more near speech for unknown speakers. Using this approach, we trained language-specific speaker-conditioned models. Using the IndicSUPERB dataset for multiple Indian languages such as Bengali, Gujarati, Hindi, Marathi, Malayalam, Punjabi and Tamil.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† A2TTSï¼Œè¿™æ˜¯ä¸€ç§æ—¨åœ¨è§£å†³ä½èµ„æºå°åº¦è¯­è¨€åŠä¸å¯è§è¯´è¯è€…è¯­éŸ³åˆæˆæŒ‘æˆ˜çš„è¯´è¯è€…è°ƒèŠ‚ TTS ç³»ç»Ÿã€‚è¯¥æ–¹æ³•é‡‡ç”¨äº†åŸºäºæ‰©æ•£ (diffusion-based) çš„æ¶æ„ï¼Œåˆ©ç”¨ Speaker Encoder ä»çŸ­å‚è€ƒéŸ³é¢‘ä¸­æå–åµŒå…¥å‘é‡ï¼Œä»¥å¼•å¯¼ DDPM Decoder å®ç°å¤šè¯´è¯è€…ç”Ÿæˆã€‚ä¸ºäº†å¢å¼ºéŸµå¾‹å’Œè‡ªç„¶åº¦ï¼Œç ”ç©¶å¼•å…¥äº†åŸºäºäº¤å‰æ³¨æ„åŠ› (cross-attention) çš„æ—¶é•¿é¢„æµ‹æœºåˆ¶ï¼Œä»è€Œå®ç°æ›´ç²¾ç¡®ä¸”ä¸è¯´è¯è€…ä¸€è‡´çš„æ—¶åºå»ºæ¨¡ã€‚æ­¤å¤–ï¼Œç³»ç»Ÿé€šè¿‡åº”ç”¨æ— åˆ†ç±»å™¨å¼•å¯¼ (classifier-free guidance) æŠ€æœ¯ï¼Œæ˜¾è‘—æå‡äº†åœ¨é›¶æ ·æœ¬ (zero-shot) åœºæ™¯ä¸‹é’ˆå¯¹æœªçŸ¥è¯´è¯è€…çš„ç”Ÿæˆè´¨é‡ã€‚åŸºäº IndicSUPERB æ•°æ®é›†ï¼Œè¯¥ç ”ç©¶é’ˆå¯¹å­ŸåŠ æ‹‰è¯­ã€å°åœ°è¯­ã€æ³°ç±³å°”è¯­ç­‰å¤šç§è¯­è¨€è®­ç»ƒäº†ç‰¹å®šæ¨¡å‹ã€‚å®éªŒç»“æœè¯æ˜ï¼Œè¯¥ç³»ç»Ÿåœ¨æé«˜åˆæˆè¯­éŸ³è¡¨ç°åŠ›çš„åŒæ—¶ï¼Œèƒ½å¤Ÿç”Ÿæˆä¸ç›®æ ‡è¯´è¯è€…ç‰¹å¾é«˜åº¦å¥‘åˆçš„è¯­éŸ³ã€‚",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CL",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.15272v1",
      "published_date": "2025-07-21 06:20:27 UTC",
      "updated_date": "2025-07-21 06:20:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:04:15.052235+00:00"
    },
    {
      "arxiv_id": "2507.15269v4",
      "title": "Conditional Video Generation for High-Efficiency Video Compression",
      "title_zh": "é¢å‘é«˜æ•ˆè§†é¢‘å‹ç¼©çš„æ¡ä»¶è§†é¢‘ç”Ÿæˆ",
      "authors": [
        "Fangqiu Yi",
        "Jingyu Xu",
        "Jiawei Shao",
        "Chi Zhang",
        "Xuelong Li"
      ],
      "abstract": "Perceptual studies demonstrate that conditional diffusion models excel at reconstructing video content aligned with human visual perception. Building on this insight, we propose a video compression framework that leverages conditional diffusion models for perceptually optimized reconstruction. Specifically, we reframe video compression as a conditional generation task, where a generative model synthesizes video from sparse, yet informative signals. Our approach introduces three key modules: (1) Multi-granular conditioning that captures both static scene structure and dynamic spatio-temporal cues; (2) Compact representations designed for efficient transmission without sacrificing semantic richness; (3) Multi-condition training with modality dropout and role-aware embeddings, which prevent over-reliance on any single modality and enhance robustness. Extensive experiments show that our method significantly outperforms both traditional and neural codecs on perceptual quality metrics such as FrÃ©chet Video Distance (FVD) and LPIPS, especially under high compression ratios.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºæ¡ä»¶æ‰©æ•£æ¨¡å‹(conditional diffusion models)çš„é«˜æ•ˆè§†é¢‘å‹ç¼©æ¡†æ¶ï¼Œæ—¨åœ¨åˆ©ç”¨ç”Ÿæˆæ¨¡å‹å®ç°æ„ŸçŸ¥ä¼˜åŒ–çš„è§†é¢‘é‡å»ºã€‚è¯¥æ–¹æ³•å°†è§†é¢‘å‹ç¼©é‡æ–°å®šä¹‰ä¸ºæ¡ä»¶ç”Ÿæˆä»»åŠ¡ï¼Œé€šè¿‡å¤šç²’åº¦è°ƒèŠ‚(multi-granular conditioning)æŠ€æœ¯åŒæ—¶æ•æ‰é™æ€åœºæ™¯ç»“æ„ä¸åŠ¨æ€æ—¶ç©ºçº¿ç´¢(dynamic spatio-temporal cues)ã€‚ä¸ºäº†ç¡®ä¿ä¼ è¾“æ•ˆç‡ï¼Œç ”ç©¶è®¾è®¡äº†å…¼é¡¾è¯­ä¹‰ä¸°å¯Œæ€§çš„ç´§å‡‘è¡¨ç¤º(compact representations)ï¼Œå¹¶å¼•å…¥æ¨¡æ€ä¸¢å¼ƒ(modality dropout)å’Œè§’è‰²æ„ŸçŸ¥åµŒå…¥(role-aware embeddings)è¿›è¡Œå¤šæ¡ä»¶è®­ç»ƒï¼Œæ˜¾è‘—å¢å¼ºäº†æ¨¡å‹çš„é²æ£’æ€§ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨FrÃ©chet Video Distance (FVD)å’ŒLPIPSç­‰æ„ŸçŸ¥è´¨é‡æŒ‡æ ‡ä¸Šæ˜¾è‘—ä¼˜äºä¼ ç»ŸåŠç¥ç»ç¼–è§£ç å™¨ï¼Œå°¤å…¶åœ¨é«˜å‹ç¼©æ¯”ä¸‹è¡¨ç°ä¼˜å¼‚ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.15269v4",
      "published_date": "2025-07-21 06:16:27 UTC",
      "updated_date": "2025-09-25 05:52:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:04:19.492773+00:00"
    },
    {
      "arxiv_id": "2507.15268v2",
      "title": "IM-Chat: A Multi-agent LLM Framework Integrating Tool-Calling and Diffusion Modeling for Knowledge Transfer in Injection Molding Industry",
      "title_zh": "IM-Chatï¼šé›†æˆå·¥å…·è°ƒç”¨ä¸æ‰©æ•£å»ºæ¨¡çš„æ³¨å¡‘è¡Œä¸šçŸ¥è¯†ä¼ æ‰¿å¤šæ™ºèƒ½ä½“å¤§è¯­è¨€æ¨¡å‹æ¡†æ¶",
      "authors": [
        "Junhyeong Lee",
        "Joon-Young Kim",
        "Heekyu Kim",
        "Inhyo Lee",
        "Seunghwa Ryu"
      ],
      "abstract": "The injection molding industry faces critical challenges in preserving and transferring field knowledge, particularly as experienced workers retire and multilingual barriers hinder effective communication. This study introduces IM-Chat, a multi-agent framework based on large language models (LLMs), designed to facilitate knowledge transfer in injection molding. IM-Chat integrates both limited documented knowledge (e.g., troubleshooting tables, manuals) and extensive field data modeled through a data-driven process condition generator that infers optimal manufacturing settings from environmental inputs such as temperature and humidity, enabling robust and context-aware task resolution. By adopting a retrieval-augmented generation (RAG) strategy and tool-calling agents within a modular architecture, IM-Chat ensures adaptability without the need for fine-tuning. Performance was assessed across 100 single-tool and 60 hybrid tasks for GPT-4o, GPT-4o-mini, and GPT-3.5-turbo by domain experts using a 10-point rubric focused on relevance and correctness, and was further supplemented by automated evaluation using GPT-4o guided by a domain-adapted instruction prompt. The evaluation results indicate that more capable models tend to achieve higher accuracy, particularly in complex, tool-integrated scenarios. In addition, compared with the fine-tuned single-agent LLM, IM-Chat demonstrated superior accuracy, particularly in quantitative reasoning, and greater scalability in handling multiple information sources. Overall, these findings demonstrate the viability of multi-agent LLM systems for industrial knowledge workflows and establish IM-Chat as a scalable and generalizable approach to AI-assisted decision support in manufacturing.",
      "tldr_zh": "æ³¨å¡‘æˆå‹(Injection Molding)è¡Œä¸šé¢ä¸´ç€èµ„æ·±å·¥äººé€€ä¼‘å’Œå¤šè¯­è¨€éšœç¢å¯¼è‡´çš„ç°åœºçŸ¥è¯†ä¼ æ‰¿éš¾é¢˜ã€‚è¯¥ç ”ç©¶æå‡ºäº†IM-Chatï¼Œä¸€ä¸ªåŸºäºå¤§è¯­è¨€æ¨¡å‹(LLMs)çš„å¤šæ™ºèƒ½ä½“æ¡†æ¶ï¼Œæ—¨åœ¨ä¿ƒè¿›æ³¨å¡‘é¢†åŸŸçš„çŸ¥è¯†è½¬ç§»ã€‚IM-Chaté€šè¿‡æ¨¡å—åŒ–æ¶æ„é›†æˆäº†æ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)ç­–ç•¥å’Œå·¥å…·è°ƒç”¨æ™ºèƒ½ä½“(Tool-calling Agents)ï¼Œèƒ½å¤Ÿæœ‰æ•ˆç»“åˆæ–‡æ¡£çŸ¥è¯†ä¸ç°åœºæ•°æ®ï¼Œå¹¶åˆ©ç”¨æ•°æ®é©±åŠ¨çš„å·¥è‰ºæ¡ä»¶ç”Ÿæˆå™¨(Process Condition Generator)æ ¹æ®ç¯å¢ƒè¾“å…¥æ¨æ–­æœ€ä½³åˆ¶é€ è®¾ç½®ã€‚å®éªŒè¯„ä¼°æ¶µç›–äº†å¤šç§GPTç³»åˆ—æ¨¡å‹åœ¨å•å·¥å…·å’Œæ··åˆä»»åŠ¡ä¸‹çš„è¡¨ç°ï¼Œç»“æœè¡¨æ˜è¯¥ç³»ç»Ÿæ— éœ€å¾®è°ƒå³å¯å®ç°ç¨³å¥çš„ä¸Šä¸‹æ–‡æ„ŸçŸ¥ä»»åŠ¡è§£å†³ã€‚ç›¸æ¯”å¾®è°ƒåçš„å•æ™ºèƒ½ä½“æ¨¡å‹ï¼ŒIM-Chatåœ¨å®šé‡æ¨ç†å’Œå¤„ç†å¤šæºä¿¡æ¯æ–¹é¢è¡¨ç°å‡ºæ›´é«˜çš„å‡†ç¡®æ€§ä¸æ‰©å±•æ€§ã€‚è¯¥ç ”ç©¶éªŒè¯äº†å¤šæ™ºèƒ½ä½“ç³»ç»Ÿåœ¨å·¥ä¸šçŸ¥è¯†å·¥ä½œæµä¸­çš„å¯è¡Œæ€§ï¼Œä¸ºåˆ¶é€ ä¸šæä¾›äº†ä¸€ç§å¯æ‰©å±•ä¸”é€šç”¨çš„AIè¾…åŠ©å†³ç­–æ”¯æŒæ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.15268v2",
      "published_date": "2025-07-21 06:13:53 UTC",
      "updated_date": "2025-10-22 14:04:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:04:26.931363+00:00"
    },
    {
      "arxiv_id": "2507.15901v1",
      "title": "Advancing Responsible Innovation in Agentic AI: A study of Ethical Frameworks for Household Automation",
      "title_zh": "æ¨è¿›æ™ºèƒ½ä½“ AI ä¸­çš„è´Ÿè´£ä»»åˆ›æ–°ï¼šå®¶åº­è‡ªåŠ¨åŒ–ä¼¦ç†æ¡†æ¶ç ”ç©¶",
      "authors": [
        "Joydeep Chandra",
        "Satyam Kumar Navneet"
      ],
      "abstract": "The implementation of Artificial Intelligence (AI) in household environments, especially in the form of proactive autonomous agents, brings about possibilities of comfort and attention as well as it comes with intra or extramural ethical challenges. This article analyzes agentic AI and its applications, focusing on its move from reactive to proactive autonomy, privacy, fairness and user control. We review responsible innovation frameworks, human-centered design principles, and governance practices to distill practical guidance for ethical smart home systems. Vulnerable user groups such as elderly individuals, children, and neurodivergent who face higher risks of surveillance, bias, and privacy risks were studied in detail in context of Agentic AI. Design imperatives are highlighted such as tailored explainability, granular consent mechanisms, and robust override controls, supported by participatory and inclusive methodologies. It was also explored how data-driven insights, including social media analysis via Natural Language Processing(NLP), can inform specific user needs and ethical concerns. This survey aims to provide both a conceptual foundation and suggestions for developing transparent, inclusive, and trustworthy agentic AI in household automation.",
      "tldr_zh": "è¯¥ç ”ç©¶æ·±å…¥æ¢è®¨äº†å®¶åº­è‡ªåŠ¨åŒ–é¢†åŸŸä¸­ Agentic AI çš„è´Ÿè´£ä»»åˆ›æ–°ï¼Œé‡ç‚¹åˆ†æäº†å…¶ä»ååº”å¼å‘ä¸»åŠ¨å¼è‡ªä¸»è½¬å˜è¿‡ç¨‹ä¸­å¼•å‘çš„éšç§ã€å…¬å¹³åŠç”¨æˆ·æ§åˆ¶ç­‰ä¼¦ç†æŒ‘æˆ˜ã€‚æ–‡ä¸­ç³»ç»Ÿå®¡æŸ¥äº†è´Ÿè´£ä»»åˆ›æ–°æ¡†æ¶ä¸ä»¥äººä¸ºæœ¬çš„è®¾è®¡åŸåˆ™ï¼Œå¹¶ç‰¹åˆ«å…³æ³¨äº†è€å¹´äººã€å„¿ç«¥åŠç¥ç»å¤šæ ·æ€§ç¾¤ä½“åœ¨é¢å¯¹ç›‘æ§ã€åè§å’Œéšç§é£é™©æ—¶çš„è„†å¼±æ€§ã€‚ç ”ç©¶é€šè¿‡ç»“åˆå‚ä¸å¼æ–¹æ³•ï¼Œå¹¶åˆ©ç”¨è‡ªç„¶è¯­è¨€å¤„ç† (NLP) å¯¹ç¤¾äº¤åª’ä½“è¿›è¡Œæ•°æ®åˆ†æï¼Œç²¾å‡†æ•æ‰äº†ç‰¹å®šç”¨æˆ·çš„éœ€æ±‚ä¸ä¼¦ç†å…³åˆ‡ã€‚é’ˆå¯¹ä¸Šè¿°é—®é¢˜ï¼Œæ–‡ç« æå‡ºäº†å®šåˆ¶åŒ–å¯è§£é‡Šæ€§ (explainability)ã€ç»†ç²’åº¦åŒæ„æœºåˆ¶ä»¥åŠé²æ£’çš„è¦†ç›–æ§åˆ¶ (override controls) ç­‰å…³é”®è®¾è®¡å‡†åˆ™ã€‚è¯¥é¡¹å·¥ä½œä¸ºå¼€å‘é€æ˜ã€åŒ…å®¹ä¸”å¯ä¿¡èµ–çš„å®¶åº­æ™ºèƒ½ç³»ç»Ÿå¥ å®šäº†ç†è®ºåŸºç¡€å¹¶æä¾›äº†å…·ä½“çš„å®è·µå»ºè®®ã€‚",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.15901v1",
      "published_date": "2025-07-21 06:10:02 UTC",
      "updated_date": "2025-07-21 06:10:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:04:29.249007+00:00"
    },
    {
      "arxiv_id": "2508.00009v1",
      "title": "Enabling Immersive XR Collaborations over FTTR Networks (Invited)",
      "title_zh": "åŸºäº FTTR ç½‘ç»œå®ç°æ²‰æµ¸å¼ XR åä½œï¼ˆç‰¹é‚€ï¼‰",
      "authors": [
        "Sourav Mondal",
        "Elaine Wong"
      ],
      "abstract": "Fiber-To-The-Room is a potential solution to achieve in-premise extended reality collaborations. This paper explores predictive bandwidth allocation and seamless handover schemes over FTTR, showing high-quality immersive experience for in-premise collaborations can be achieved. \\c{opyright} 2025 The Author(s).",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åˆ©ç”¨å…¨å±‹å…‰çº¤(Fiber-To-The-Room, FTTR)ç½‘ç»œå®ç°å®¤å†…æ²‰æµ¸å¼æ‰©å±•ç°å®(Extended Reality, XR)åä½œçš„æŠ€æœ¯è·¯å¾„ã€‚æ–‡ç« æ˜ç¡®æŒ‡å‡ºFTTRæ˜¯è§£å†³å®¤å†…XRåä½œå¸¦å®½ä¸å»¶è¿ŸæŒ‘æˆ˜çš„æ½œåœ¨å…³é”®æ–¹æ¡ˆã€‚ç ”ç©¶é‡ç‚¹æ¢ç´¢äº†é¢„æµ‹æ€§å¸¦å®½åˆ†é…(predictive bandwidth allocation)ä»¥åŠæ— ç¼åˆ‡æ¢æ–¹æ¡ˆ(seamless handover schemes)åœ¨FTTRç¯å¢ƒä¸‹çš„åº”ç”¨ã€‚é€šè¿‡è¿™äº›æŠ€æœ¯çš„ç»“åˆï¼Œç ”ç©¶è¯æ˜äº†åœ¨å®¤å†…åä½œåœºæ™¯ä¸­å®ç°é«˜è´¨é‡æ²‰æµ¸å¼ä½“éªŒçš„å¯è¡Œæ€§ã€‚å®éªŒç»“æœéªŒè¯äº†è¯¥æ–¹æ¡ˆèƒ½å¤Ÿæœ‰æ•ˆä¿éšœXRä¸šåŠ¡çš„è¿ç»­æ€§ä¸ç”¨æˆ·æ„ŸçŸ¥è´¨é‡ã€‚è¯¥å·¥ä½œä¸ºæœªæ¥FTTRç½‘ç»œæ”¯æŒè¶…é«˜æ¸…ã€ä½æ—¶å»¶çš„æ‰©å±•ç°å®åº”ç”¨å¥ å®šäº†æŠ€æœ¯åŸºç¡€ã€‚",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "This invited paper was presented in Optica Advanced Photonic Congress 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.00009v1",
      "published_date": "2025-07-21 05:38:29 UTC",
      "updated_date": "2025-07-21 05:38:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:04:44.751779+00:00"
    },
    {
      "arxiv_id": "2507.15256v1",
      "title": "Optimal Transceiver Design in Over-the-Air Federated Distillation",
      "title_zh": "ç©ºä¸­è”é‚¦è’¸é¦ä¸­çš„æœ€ä¼˜æ”¶å‘æœºè®¾è®¡",
      "authors": [
        "Zihao Hu",
        "Jia Yan",
        "Ying-Jun Angela Zhang",
        "Jun Zhang",
        "Khaled B. Letaief"
      ],
      "abstract": "The rapid proliferation and growth of artificial intelligence (AI) has led to the development of federated learning (FL). FL allows wireless devices (WDs) to cooperatively learn by sharing only local model parameters, without needing to share the entire dataset. However, the emergence of large AI models has made existing FL approaches inefficient, due to the significant communication overhead required. In this paper, we propose a novel over-the-air federated distillation (FD) framework by synergizing the strength of FL and knowledge distillation to avoid the heavy local model transmission. Instead of sharing the model parameters, only the WDs' model outputs, referred to as knowledge, are shared and aggregated over-the-air by exploiting the superposition property of the multiple-access channel. We shall study the transceiver design in over-the-air FD, aiming to maximize the learning convergence rate while meeting the power constraints of the transceivers. The main challenge lies in the intractability of the learning performance analysis, as well as the non-convex nature and the optimization spanning the whole FD training period. To tackle this problem, we first derive an analytical expression of the convergence rate in over-the-air FD. Then, the closed-form optimal solutions of the WDs' transmit power and the estimator for over-the-air aggregation are obtained given the receiver combining strategy. Accordingly, we put forth an efficient approach to find the optimal receiver beamforming vector via semidefinite relaxation. We further prove that there is no optimality gap between the original and relaxed problem for the receiver beamforming design. Numerical results will show that the proposed over-the-air FD approach achieves a significant reduction in communication overhead, with only a minor compromise in testing accuracy compared to conventional FL benchmarks.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§æ–°å‹çš„ç©ºä¸­è”é‚¦è’¸é¦ (Over-the-Air Federated Distillation, FD) æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ä¼ ç»Ÿè”é‚¦å­¦ä¹  (Federated Learning, FL) åœ¨å¤„ç†å¤§å‹ AI æ¨¡å‹æ—¶é¢ä¸´çš„å·¨å¤§é€šä¿¡å¼€é”€é—®é¢˜ã€‚è¯¥æ¡†æ¶ä¸å†ä¼ è¾“å®Œæ•´çš„æ¨¡å‹å‚æ•°ï¼Œè€Œæ˜¯é€šè¿‡åˆ†äº«æ— çº¿è®¾å¤‡ (WDs) çš„æ¨¡å‹è¾“å‡ºï¼ˆå³â€œçŸ¥è¯†â€ï¼‰ï¼Œå¹¶åˆ©ç”¨å¤šå€ä¿¡é“çš„å åŠ ç‰¹æ€§å®ç°é«˜æ•ˆçš„ç©ºä¸­èšåˆã€‚ç ”ç©¶é‡ç‚¹åœ¨äºä¼˜åŒ–æ”¶å‘æœºè®¾è®¡ï¼Œä»¥åœ¨æ»¡è¶³åŠŸç‡çº¦æŸçš„åŒæ—¶æœ€å¤§åŒ–å­¦ä¹ æ”¶æ•›ç‡ (Learning Convergence Rate)ã€‚ä¸ºæ­¤ï¼Œè®ºæ–‡é¦–å…ˆæ¨å¯¼äº†æ”¶æ•›ç‡çš„è§£æè¡¨è¾¾å¼ï¼Œå¹¶å¾—å‡ºäº†å‘å°„åŠŸç‡ä¸ä¼°è®¡å™¨çš„é—­å¼æœ€ä¼˜è§£ã€‚éšåï¼Œç ”ç©¶è€…åˆ©ç”¨åŠæ­£å®šæ¾å¼› (Semidefinite Relaxation, SDR) æŠ€æœ¯ç¡®å®šäº†æœ€ä¼˜æ¥æ”¶ç«¯æ³¢æŸèµ‹å½¢å‘é‡ï¼Œå¹¶ä»ç†è®ºä¸Šè¯æ˜äº†è¯¥æ¾å¼›æ–¹æ¡ˆä¸å­˜åœ¨ä¼˜åŒ–é—´éš™ã€‚æ•°å€¼å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ‰€æå‡ºçš„ç©ºä¸­ FD æ–¹æ³•åœ¨æ˜¾è‘—é™ä½é€šä¿¡å¼€é”€çš„åŒæ—¶ï¼Œä¸ä¼ ç»Ÿ FL åŸºå‡†ç›¸æ¯”ä»…å­˜åœ¨æå°çš„æµ‹è¯•å‡†ç¡®ç‡æŸå¤±ã€‚",
      "categories": [
        "eess.SP",
        "cs.AI"
      ],
      "primary_category": "eess.SP",
      "comment": "13 pages, 7 figures, submitted to IEEE Transactions on Wireless Communications",
      "pdf_url": "https://arxiv.org/pdf/2507.15256v1",
      "published_date": "2025-07-21 05:37:08 UTC",
      "updated_date": "2025-07-21 05:37:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:04:43.827597+00:00"
    },
    {
      "arxiv_id": "2507.15255v1",
      "title": "MEETI: A Multimodal ECG Dataset from MIMIC-IV-ECG with Signals, Images, Features and Interpretations",
      "title_zh": "MEETIï¼šåŒ…å«ä¿¡å·ã€å›¾åƒã€ç‰¹å¾ä¸åˆ¤è¯»çš„ MIMIC-IV-ECG å¤šæ¨¡æ€å¿ƒç”µå›¾æ•°æ®é›†",
      "authors": [
        "Deyun Zhang",
        "Xiang Lan",
        "Shijia Geng",
        "Qinghao Zhao",
        "Sumei Fan",
        "Mengling Feng",
        "Shenda Hong"
      ],
      "abstract": "Electrocardiogram (ECG) plays a foundational role in modern cardiovascular care, enabling non-invasive diagnosis of arrhythmias, myocardial ischemia, and conduction disorders. While machine learning has achieved expert-level performance in ECG interpretation, the development of clinically deployable multimodal AI systems remains constrained, primarily due to the lack of publicly available datasets that simultaneously incorporate raw signals, diagnostic images, and interpretation text. Most existing ECG datasets provide only single-modality data or, at most, dual modalities, making it difficult to build models that can understand and integrate diverse ECG information in real-world settings. To address this gap, we introduce MEETI (MIMIC-IV-Ext ECG-Text-Image), the first large-scale ECG dataset that synchronizes raw waveform data, high-resolution plotted images, and detailed textual interpretations generated by large language models. In addition, MEETI includes beat-level quantitative ECG parameters extracted from each lead, offering structured parameters that support fine-grained analysis and model interpretability. Each MEETI record is aligned across four components: (1) the raw ECG waveform, (2) the corresponding plotted image, (3) extracted feature parameters, and (4) detailed interpretation text. This alignment is achieved using consistent, unique identifiers. This unified structure supports transformer-based multimodal learning and supports fine-grained, interpretable reasoning about cardiac health. By bridging the gap between traditional signal analysis, image-based interpretation, and language-driven understanding, MEETI established a robust foundation for the next generation of explainable, multimodal cardiovascular AI. It offers the research community a comprehensive benchmark for developing and evaluating ECG-based AI systems.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº†MEETI (MIMIC-IV-Ext ECG-Text-Image)ï¼Œè¿™æ˜¯é¦–ä¸ªåŒæ­¥äº†åŸå§‹æ³¢å½¢æ•°æ®ã€é«˜åˆ†è¾¨ç‡å¿ƒç”µå›¾å›¾åƒä»¥åŠç”±å¤§è¯­è¨€æ¨¡å‹(LLMs)ç”Ÿæˆçš„è¯¦ç»†æ–‡æœ¬è§£é‡Šçš„å¤§è§„æ¨¡å¤šæ¨¡æ€å¿ƒç”µå›¾(ECG)æ•°æ®é›†ã€‚é’ˆå¯¹ç°æœ‰æ•°æ®é›†ç¼ºä¹å¤šç»´ä¿¡æ¯é›†æˆã€éš¾ä»¥æ”¯æŒä¸´åºŠå¯éƒ¨ç½²AIç³»ç»Ÿçš„é—®é¢˜ï¼ŒMEETI å®ç°äº†åŸå§‹ä¿¡å·ã€å›¾åƒã€æ–‡æœ¬ä»¥åŠä»å¯¼è”ä¸­æå–çš„è·³åŠ¨çº§(beat-level)å®šé‡ç‰¹å¾å‚æ•°çš„ä¸¥æ ¼å¯¹é½ã€‚é€šè¿‡è¿™ç§ç»Ÿä¸€çš„ç»“æ„ï¼Œè¯¥æ•°æ®é›†èƒ½å¤Ÿæ”¯æŒåŸºäº Transformer çš„å¤šæ¨¡æ€å­¦ä¹ ï¼Œå¹¶å®ç°å¯¹å¿ƒè„å¥åº·çŠ¶å†µçš„ç»†ç²’åº¦ã€å¯è§£é‡Šæ¨ç†ã€‚MEETI æˆåŠŸæ¡¥æ¥äº†ä¼ ç»Ÿçš„ä¿¡å·åˆ†æã€åŸºäºå›¾åƒçš„è§£è¯»ä¸è¯­è¨€é©±åŠ¨çš„ç†è§£ï¼Œä¸ºå¼€å‘ä¸‹ä¸€ä»£å¯è§£é‡Šã€å¤šæ¨¡æ€çš„å¿ƒè¡€ç®¡äººå·¥æ™ºèƒ½å¥ å®šäº†åšå®åŸºç¡€ï¼Œå¹¶ä¸ºç ”ç©¶ç¤¾åŒºæä¾›äº†å…¨é¢çš„åŸºå‡†æµ‹è¯•èµ„æºã€‚",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.15255v1",
      "published_date": "2025-07-21 05:32:44 UTC",
      "updated_date": "2025-07-21 05:32:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:04:57.490113+00:00"
    },
    {
      "arxiv_id": "2507.15254v1",
      "title": "User Head Movement-Predictive XR in Immersive H2M Collaborations over Future Enterprise Networks",
      "title_zh": "é¢å‘æœªæ¥ä¼ä¸šç½‘ç»œæ²‰æµ¸å¼ H2M åä½œçš„ç”¨æˆ·å¤´éƒ¨è¿åŠ¨é¢„æµ‹ XR",
      "authors": [
        "Sourav Mondal",
        "Elaine Wong"
      ],
      "abstract": "The evolution towards future generation of mobile systems and fixed wireless networks is primarily driven by the urgency to support high-bandwidth and low-latency services across various vertical sectors. This endeavor is fueled by smartphones as well as technologies like industrial internet of things, extended reality (XR), and human-to-machine (H2M) collaborations for fostering industrial and social revolutions like Industry 4.0/5.0 and Society 5.0. To ensure an ideal immersive experience and avoid cyber-sickness for users in all the aforementioned usage scenarios, it is typically challenging to synchronize XR content from a remote machine to a human collaborator according to their head movements across a large geographic span in real-time over communication networks. Thus, we propose a novel H2M collaboration scheme where the human's head movements are predicted ahead with highly accurate models like bidirectional long short-term memory networks to orient the machine's camera in advance. We validate that XR frame size varies in accordance with the human's head movements and predict the corresponding bandwidth requirements from the machine's camera to propose a human-machine coordinated dynamic bandwidth allocation (HMC-DBA) scheme. Through extensive simulations, we show that end-to-end latency and jitter requirements of XR frames are satisfied with much lower bandwidth consumption over enterprise networks like Fiber-To-The-Room-Business. Furthermore, we show that better efficiency in network resource utilization is achieved by employing our proposed HMC-DBA over state-of-the-art schemes.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æœªæ¥ä¼ä¸šç½‘ç»œä¸­çš„æ²‰æµ¸å¼äººæœºåä½œ(H2M)åœºæ™¯ï¼Œæå‡ºäº†ä¸€ç§åŸºäºå¤´éƒ¨è¿åŠ¨é¢„æµ‹çš„æ‰©å±•ç°å®(XR)åä½œæ–¹æ¡ˆï¼Œæ—¨åœ¨è§£å†³è¿œç¨‹å®æ—¶åŒæ­¥ä¸­çš„é«˜å¸¦å®½å’Œä½å»¶è¿ŸæŒ‘æˆ˜ã€‚ä¸ºäº†ä¼˜åŒ–æ²‰æµ¸å¼ä½“éªŒå¹¶é¿å…çœ©æ™•æ„Ÿï¼Œè¯¥æ–¹æ¡ˆé‡‡ç”¨åŒå‘é•¿çŸ­æœŸè®°å¿†ç½‘ç»œ(BiLSTM)æ¨¡å‹æå‰é¢„æµ‹ç”¨æˆ·çš„å¤´éƒ¨è¿åŠ¨ï¼Œä»è€Œé¢„å…ˆè°ƒæ•´è¿œç¨‹æœºå™¨çš„æ‘„åƒå¤´æ–¹å‘ã€‚ç ”ç©¶å›¢é˜Ÿè¿›ä¸€æ­¥åˆ†æäº†XRå¸§å¤§å°ä¸å¤´éƒ¨è¿åŠ¨çš„ç›¸å…³æ€§ï¼Œå¹¶æ®æ­¤è®¾è®¡äº†äººæœºååŒåŠ¨æ€å¸¦å®½åˆ†é…(HMC-DBA)ç®—æ³•ã€‚åœ¨å…¨å…‰æˆ¿é—´å•†ä¸šç‰ˆ(Fiber-To-The-Room-Business, FTTR-B)ç­‰ä¼ä¸šç½‘ç»œç¯å¢ƒä¸‹çš„ä»¿çœŸå®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ¡ˆåœ¨æ»¡è¶³XRå¸§ç«¯åˆ°ç«¯å»¶è¿Ÿå’ŒæŠ–åŠ¨è¦æ±‚çš„åŒæ—¶ï¼Œæ˜¾è‘—é™ä½äº†å¸¦å®½æ¶ˆè€—ã€‚ç›¸æ¯”ç°æœ‰å…ˆè¿›æ–¹æ¡ˆï¼Œè¯¥ç ”ç©¶æå‡ºçš„æ¶æ„å®ç°äº†æ›´é«˜çš„ç½‘ç»œèµ„æºåˆ©ç”¨æ•ˆç‡ï¼Œä¸ºå®ç°å¤§è§„æ¨¡åœ°ç†è·¨åº¦ä¸‹çš„é«˜æ•ˆH2Måä½œå¥ å®šäº†æŠ€æœ¯åŸºç¡€ã€‚",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "This article is accepted for publication in IEEE Internet of Things Journal. Copyright @ IEEE 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.15254v1",
      "published_date": "2025-07-21 05:31:24 UTC",
      "updated_date": "2025-07-21 05:31:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:05:06.947364+00:00"
    },
    {
      "arxiv_id": "2507.15253v1",
      "title": "Disentangling Homophily and Heterophily in Multimodal Graph Clustering",
      "title_zh": "å¤šæ¨¡æ€å›¾èšç±»ä¸­çš„åŒè´¨æ€§ä¸å¼‚è´¨æ€§è§£è€¦",
      "authors": [
        "Zhaochen Guo",
        "Zhixiang Shen",
        "Xuanting Xie",
        "Liangjian Wen",
        "Zhao Kang"
      ],
      "abstract": "Multimodal graphs, which integrate unstructured heterogeneous data with structured interconnections, offer substantial real-world utility but remain insufficiently explored in unsupervised learning. In this work, we initiate the study of multimodal graph clustering, aiming to bridge this critical gap. Through empirical analysis, we observe that real-world multimodal graphs often exhibit hybrid neighborhood patterns, combining both homophilic and heterophilic relationships. To address this challenge, we propose a novel framework -- \\textsc{Disentangled Multimodal Graph Clustering (DMGC)} -- which decomposes the original hybrid graph into two complementary views: (1) a homophily-enhanced graph that captures cross-modal class consistency, and (2) heterophily-aware graphs that preserve modality-specific inter-class distinctions. We introduce a \\emph{Multimodal Dual-frequency Fusion} mechanism that jointly filters these disentangled graphs through a dual-pass strategy, enabling effective multimodal integration while mitigating category confusion. Our self-supervised alignment objectives further guide the learning process without requiring labels. Extensive experiments on both multimodal and multi-relational graph datasets demonstrate that DMGC achieves state-of-the-art performance, highlighting its effectiveness and generalizability across diverse settings. Our code is available at https://github.com/Uncnbb/DMGC.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤šæ¨¡æ€å›¾èšç±»(Multimodal Graph Clustering)ä¸­åŒè´¨æ€§(Homophily)ä¸å¼‚è´¨æ€§(Heterophily)çš„è§£è€¦é—®é¢˜ã€‚é’ˆå¯¹ç°å®ä¸–ç•Œå¤šæ¨¡æ€å›¾ä¸­å­˜åœ¨çš„æ··åˆé‚»åŸŸæ¨¡å¼ï¼Œä½œè€…æå‡ºäº†DMGC(Disentangled Multimodal Graph Clustering)æ¡†æ¶ï¼Œæ—¨åœ¨å¡«è¡¥æ— ç›‘ç£å­¦ä¹ åœ¨è¯¥é¢†åŸŸçš„ç©ºç™½ã€‚è¯¥æ¡†æ¶å°†åŸå§‹æ··åˆå›¾åˆ†è§£ä¸ºä¸¤ä¸ªäº’è¡¥è§†å›¾ï¼šæ•æ‰è·¨æ¨¡æ€ç±»åˆ«ä¸€è‡´æ€§çš„åŒè´¨æ€§å¢å¼ºå›¾ï¼Œä»¥åŠä¿ç•™æ¨¡æ€ç‰¹å®šç±»åˆ«å·®å¼‚çš„å¼‚è´¨æ€§æ„ŸçŸ¥å›¾ã€‚é€šè¿‡å¼•å…¥å¤šæ¨¡æ€åŒé¢‘èåˆ(Multimodal Dual-frequency Fusion)æœºåˆ¶ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨åŒé€šè·¯ç­–ç•¥è¿‡æ»¤è§£è€¦å›¾ï¼Œæœ‰æ•ˆå®ç°äº†å¤šæ¨¡æ€é›†æˆå¹¶å‡å°‘äº†ç±»åˆ«æ··æ·†ã€‚æ­¤å¤–ï¼Œç ”ç©¶é‡‡ç”¨è‡ªç›‘ç£å¯¹é½ç›®æ ‡åœ¨æ— æ ‡ç­¾çš„æƒ…å†µä¸‹å¼•å¯¼å­¦ä¹ è¿‡ç¨‹ã€‚åœ¨å¤šæ¨¡æ€å’Œå¤šå…³ç³»å›¾æ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒDMGCè¾¾åˆ°äº†State-of-the-artçš„æ€§èƒ½ï¼Œè¯æ˜äº†å…¶åœ¨ä¸åŒè®¾ç½®ä¸‹çš„æœ‰æ•ˆæ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.SI"
      ],
      "primary_category": "cs.AI",
      "comment": "Appear in ACM Multimedia 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.15253v1",
      "published_date": "2025-07-21 05:29:53 UTC",
      "updated_date": "2025-07-21 05:29:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:05:04.700615+00:00"
    },
    {
      "arxiv_id": "2507.22917v1",
      "title": "Reading Between the Timelines: RAG for Answering Diachronic Questions",
      "title_zh": "è¯»æ‡‚æ—¶é—´è„‰ç»œï¼šé¢å‘å†æ—¶æ€§é—®ç­”çš„æ£€ç´¢å¢å¼ºç”Ÿæˆ",
      "authors": [
        "Kwun Hang Lau",
        "Ruiyuan Zhang",
        "Weijie Shi",
        "Xiaofang Zhou",
        "Xiaojun Cheng"
      ],
      "abstract": "While Retrieval-Augmented Generation (RAG) excels at injecting static, factual knowledge into Large Language Models (LLMs), it exhibits a critical deficit in handling longitudinal queries that require tracking entities and phenomena across time. This blind spot arises because conventional, semantically-driven retrieval methods are not equipped to gather evidence that is both topically relevant and temporally coherent for a specified duration. We address this challenge by proposing a new framework that fundamentally redesigns the RAG pipeline to infuse temporal logic. Our methodology begins by disentangling a user's query into its core subject and its temporal window. It then employs a specialized retriever that calibrates semantic matching against temporal relevance, ensuring the collection of a contiguous evidence set that spans the entire queried period. To enable rigorous evaluation of this capability, we also introduce the Analytical Diachronic Question Answering Benchmark (ADQAB), a challenging evaluation suite grounded in a hybrid corpus of real and synthetic financial news. Empirical results on ADQAB show that our approach yields substantial gains in answer accuracy, surpassing standard RAG implementations by 13% to 27%. This work provides a validated pathway toward RAG systems capable of performing the nuanced, evolutionary analysis required for complex, real-world questions. The dataset and code for this study are publicly available at https://github.com/kwunhang/TA-RAG.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ Retrieval-Augmented Generation (RAG) åœ¨å¤„ç†éœ€è¦è·¨æ—¶é—´è·Ÿè¸ªå®ä½“å’Œç°è±¡çš„ diachronic questions æ—¶å­˜åœ¨çš„å±€é™æ€§ï¼Œæå‡ºäº†ä¸€ä¸ªèåˆæ—¶é—´é€»è¾‘çš„æ–°å‹æ¡†æ¶ã€‚è¯¥æ–¹æ³•é€šè¿‡å°†ç”¨æˆ·æŸ¥è¯¢åˆ†è§£ä¸ºæ ¸å¿ƒä¸»ä½“å’Œæ—¶é—´çª—å£ï¼Œå¹¶åˆ©ç”¨ä¸“é—¨çš„æ£€ç´¢å™¨å¹³è¡¡ semantic matching ä¸ temporal relevanceï¼Œç¡®ä¿è·å–åœ¨ç›®æ ‡æ—¶é—´æ®µå†…è¿ç»­ä¸”è¿è´¯çš„è¯æ®é›†ã€‚ä¸ºäº†éªŒè¯è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œç ”ç©¶è€…æ¨å‡ºäº† Analytical Diachronic Question Answering Benchmark (ADQAB)ï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºçœŸå®ä¸åˆæˆé‡‘èæ–°é—»è¯­æ–™åº“çš„è¯„ä¼°åŸºå‡†ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ¡ˆåœ¨ ADQAB ä¸Šçš„å‡†ç¡®ç‡æ¯”æ ‡å‡† RAG æå‡äº† 13% è‡³ 27%ï¼Œè¯æ˜äº†å…¶åœ¨å¤„ç†æ¼”åŒ–åˆ†æä»»åŠ¡ä¸­çš„ä¼˜è¶Šæ€§ã€‚è¯¥å·¥ä½œä¸º RAG ç³»ç»Ÿå¤„ç†å¤æ‚çš„ç°å®ä¸–ç•Œ longitudinal queries æä¾›äº†æœ‰æ•ˆçš„è·¯å¾„ï¼Œå¹¶å…¬å¼€äº†ç›¸å…³æ•°æ®é›†ä¸ä»£ç ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.22917v1",
      "published_date": "2025-07-21 05:19:41 UTC",
      "updated_date": "2025-07-21 05:19:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:05:21.995784+00:00"
    },
    {
      "arxiv_id": "2507.15246v1",
      "title": "Spatio-Temporal Demand Prediction for Food Delivery Using Attention-Driven Graph Neural Networks",
      "title_zh": "åŸºäºæ³¨æ„åŠ›é©±åŠ¨å›¾ç¥ç»ç½‘ç»œçš„å¤–å–æ—¶ç©ºéœ€æ±‚é¢„æµ‹",
      "authors": [
        "Rabia Latief Bhat",
        "Iqra Altaf Gillani"
      ],
      "abstract": "Accurate demand forecasting is critical for enhancing the efficiency and responsiveness of food delivery platforms, where spatial heterogeneity and temporal fluctuations in order volumes directly influence operational decisions. This paper proposes an attention-based Graph Neural Network framework that captures spatial-temporal dependencies by modeling the food delivery environment as a graph. In this graph, nodes represent urban delivery zones, while edges reflect spatial proximity and inter-regional order flow patterns derived from historical data. The attention mechanism dynamically weighs the influence of neighboring zones, enabling the model to focus on the most contextually relevant areas during prediction. Temporal trends are jointly learned alongside spatial interactions, allowing the model to adapt to evolving demand patterns. Extensive experiments on real-world food delivery datasets demonstrate the superiority of the proposed model in forecasting future order volumes with high accuracy. The framework offers a scalable and adaptive solution to support proactive fleet positioning, resource allocation, and dispatch optimization in urban food delivery operations.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºæ³¨æ„åŠ›çš„å›¾ç¥ç»ç½‘ç»œ(Graph Neural Network)æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¤–å–é…é€å¹³å°ä¸­å› ç©ºé—´å¼‚è´¨æ€§å’Œæ—¶é—´æ³¢åŠ¨å¯¼è‡´çš„éœ€æ±‚é¢„æµ‹éš¾é¢˜ã€‚è¯¥æ¡†æ¶å°†é…é€ç¯å¢ƒå»ºæ¨¡ä¸ºå›¾(Graph)ï¼Œåˆ©ç”¨èŠ‚ç‚¹è¡¨ç¤ºåŸå¸‚é…é€åŒºåŸŸ(delivery zones)ï¼Œå¹¶é€šè¿‡è¾¹åæ˜ ç©ºé—´é‚»è¿‘æ€§å’Œå†å²è®¢å•æµæ¨¡å¼ã€‚é€šè¿‡å¼•å…¥æ³¨æ„åŠ›æœºåˆ¶(Attention mechanism)åŠ¨æ€åŠ æƒé‚»è¿‘åŒºåŸŸçš„å½±å“ï¼Œæ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆæ•æ‰å¤æ‚çš„æ—¶ç©ºä¾èµ–å…³ç³»(spatial-temporal dependencies)å¹¶é€‚åº”ä¸æ–­å˜åŒ–çš„éœ€æ±‚æ¨¡å¼ã€‚åœ¨çœŸå®ä¸–ç•Œå¤–å–æ•°æ®é›†ä¸Šçš„å®éªŒè¯æ˜ï¼Œè¯¥æ¨¡å‹åœ¨é¢„æµ‹æœªæ¥è®¢å•é‡æ–¹é¢å…·æœ‰æ˜¾è‘—çš„å‡†ç¡®æ€§ä¼˜åŠ¿ã€‚è¯¥ç ”ç©¶ä¸ºåŸå¸‚é…é€ä¸šåŠ¡ä¸­çš„è½¦é˜Ÿå®šä½(fleet positioning)ã€èµ„æºåˆ†é…(resource allocation)ä»¥åŠè°ƒåº¦ä¼˜åŒ–(dispatch optimization)æä¾›äº†é«˜åº¦å¯æ‰©å±•ä¸”å…·å¤‡è‡ªé€‚åº”æ€§çš„å†³ç­–æ”¯æŒã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.15246v1",
      "published_date": "2025-07-21 05:10:32 UTC",
      "updated_date": "2025-07-21 05:10:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:05:15.594434+00:00"
    },
    {
      "arxiv_id": "2507.15245v1",
      "title": "SPAR: Scholar Paper Retrieval with LLM-based Agents for Enhanced Academic Search",
      "title_zh": "SPARï¼šåŸºäºå¤§è¯­è¨€æ¨¡å‹æ™ºèƒ½ä½“å¢å¼ºå­¦æœ¯æœç´¢çš„å­¦æœ¯è®ºæ–‡æ£€ç´¢",
      "authors": [
        "Xiaofeng Shi",
        "Yuduo Li",
        "Qian Kou",
        "Longbin Yu",
        "Jinxin Xie",
        "Hua Zhou"
      ],
      "abstract": "Recent advances in large language models (LLMs) have opened new opportunities for academic literature retrieval. However, existing systems often rely on rigid pipelines and exhibit limited reasoning capabilities. We introduce SPAR, a multi-agent framework that incorporates RefChain-based query decomposition and query evolution to enable more flexible and effective search. To facilitate systematic evaluation, we also construct SPARBench, a challenging benchmark with expert-annotated relevance labels. Experimental results demonstrate that SPAR substantially outperforms strong baselines, achieving up to +56% F1 on AutoScholar and +23% F1 on SPARBench over the best-performing baseline. Together, SPAR and SPARBench provide a scalable, interpretable, and high-performing foundation for advancing research in scholarly retrieval. Code and data will be available at: https://github.com/xiaofengShi/SPAR",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†SPARï¼Œä¸€ä¸ªåŸºäºå¤§è¯­è¨€æ¨¡å‹(LLMs)æ™ºèƒ½ä½“çš„å¤šæ™ºèƒ½ä½“æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰å­¦æœ¯æ–‡çŒ®æ£€ç´¢ç³»ç»Ÿæµç¨‹åƒµåŒ–å’Œæ¨ç†èƒ½åŠ›ä¸è¶³çš„å±€é™ã€‚è¯¥æ¡†æ¶é€šè¿‡å¼•å…¥åŸºäºRefChainçš„æŸ¥è¯¢åˆ†è§£(query decomposition)å’ŒæŸ¥è¯¢æ¼”è¿›(query evolution)æœºåˆ¶ï¼Œå®ç°äº†æ›´åŠ çµæ´»ä¸”é«˜æ•ˆçš„æ–‡çŒ®æœç´¢è¿‡ç¨‹ã€‚ä¸ºè¿›è¡Œç³»ç»ŸåŒ–è¯„ä¼°ï¼Œç ”ç©¶è€…åŒæ­¥æ„å»ºäº†å…·æœ‰ä¸“å®¶æ ‡æ³¨ç›¸å…³æ€§æ ‡ç­¾çš„æŒ‘æˆ˜æ€§åŸºå‡†æµ‹è¯•é›†SPARBenchã€‚å®éªŒæ•°æ®æ˜¾ç¤ºï¼ŒSPARåœ¨AutoScholarå’ŒSPARBenchä¸Šçš„F1æŒ‡æ ‡åˆ†åˆ«æ¯”è¡¨ç°æœ€å¥½çš„åŸºçº¿æ¨¡å‹æå‡äº†56%å’Œ23%ã€‚è¿™é¡¹å·¥ä½œä¸ºæ¨åŠ¨å­¦æœ¯æ£€ç´¢å‘å¯æ‰©å±•ã€å¯è§£é‡ŠåŠé«˜æ€§èƒ½æ–¹å‘å‘å±•å¥ å®šäº†åšå®åŸºç¡€ï¼Œå…¶ä»£ç ä¸æ•°æ®å‡å·²å…¬å¼€ã€‚",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.15245v1",
      "published_date": "2025-07-21 05:06:53 UTC",
      "updated_date": "2025-07-21 05:06:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:05:22.487474+00:00"
    },
    {
      "arxiv_id": "2507.15243v2",
      "title": "Cross-Domain Few-Shot Learning with Coalescent Projections and Latent Space Reservation",
      "title_zh": "åŸºäºç»“åˆæŠ•å½±ä¸æ½œç©ºé—´é¢„ç•™çš„è·¨åŸŸå°æ ·æœ¬å­¦ä¹ ",
      "authors": [
        "Naeem Paeedeh",
        "Mahardhika Pratama",
        "Imam Mustafa Kamal",
        "Wolfgang Mayer",
        "Jimmy Cao",
        "Ryszard Kowlczyk"
      ],
      "abstract": "Despite the progress in cross-domain few-shot learning, a model pre-trained with DINO combined with a prototypical classifier outperforms the latest SOTA methods. A crucial limitation that needs to be overcome is that updating too many parameters of the transformers leads to overfitting due to the scarcity of labeled samples. To address this challenge, we propose a new concept, coalescent projection, as an effective successor to soft prompts. Additionally, we propose a novel pseudo-class generation method, combined with self-supervised transformations, that relies solely on the base domain to prepare the network to encounter unseen samples from different domains. The proposed method exhibits its effectiveness in comprehensive experiments on the extreme domain-shift problem of the BSCD-FSL benchmark. Our code is published at \\href{https://github.com/Naeem-Paeedeh/CPLSR}{https://github.com/Naeem-Paeedeh/CPLSR}.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è·¨åŸŸå°æ ·æœ¬å­¦ä¹  (Cross-Domain Few-Shot Learning) ä¸­ç”±äºæ ‡æ³¨æ ·æœ¬ç¨€ç¼ºå¯¼è‡´æ›´æ–° Transformer è¿‡å¤šå‚æ•°è€Œå¼•å‘è¿‡æ‹Ÿåˆçš„é—®é¢˜ã€‚ä½œè€…æå‡ºäº†åä¸º Coalescent Projection çš„æ–°æ¦‚å¿µï¼Œæ—¨åœ¨ä½œä¸º Soft Prompts çš„æœ‰æ•ˆç»§ä»»æ–¹æ¡ˆæ¥ä¼˜åŒ–æ¨¡å‹ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜å¼•å…¥äº†ä¸€ç§ç»“åˆ Self-Supervised Transformations çš„æ–°å‹ä¼ªç±»åˆ«ç”Ÿæˆæ–¹æ³•ï¼Œè¯¥æ–¹æ³•ä»…åˆ©ç”¨åŸºç¡€åŸŸæ•°æ®å³å¯è®­ç»ƒç½‘ç»œåº”å¯¹æ¥è‡ªä¸åŒé¢†åŸŸçš„æœªè§æ ·æœ¬ã€‚åœ¨é’ˆå¯¹æç«¯åŸŸåç§»é—®é¢˜çš„ BSCD-FSL åŸºå‡†æµ‹è¯•ä¸Šï¼Œç»¼åˆå®éªŒç»“æœå……åˆ†è¯æ˜äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚è¯¥æ–¹æ¡ˆæˆåŠŸå…‹æœäº†ç°æœ‰æ–¹æ³•åœ¨æ ‡æ³¨æ•°æ®åŒ®ä¹æ—¶çš„å±€é™æ€§ï¼Œä¸ºæå‡æ¨¡å‹åœ¨å¤æ‚è·¨åŸŸåœºæ™¯ä¸‹çš„æ³›åŒ–æ€§èƒ½æä¾›äº†æ–°çš„æ€è·¯ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.15243v2",
      "published_date": "2025-07-21 05:01:27 UTC",
      "updated_date": "2025-11-18 04:16:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:05:24.486391+00:00"
    },
    {
      "arxiv_id": "2507.15239v1",
      "title": "Explainable Artificial Intelligence based Soft Evaluation Indicator for Arc Fault Diagnosis",
      "title_zh": "åŸºäºå¯è§£é‡Šäººå·¥æ™ºèƒ½çš„ç”µå¼§æ•…éšœè¯Šæ–­è½¯è¯„ä»·æŒ‡æ ‡",
      "authors": [
        "Qianchao Wang",
        "Yuxuan Ding",
        "Chuanzhen Jia",
        "Zhe Li",
        "Yaping Du"
      ],
      "abstract": "Novel AI-based arc fault diagnosis models have demonstrated outstanding performance in terms of classification accuracy. However, an inherent problem is whether these models can actually be trusted to find arc faults. In this light, this work proposes a soft evaluation indicator that explains the outputs of arc fault diagnosis models, by defining the the correct explanation of arc faults and leveraging Explainable Artificial Intelligence and real arc fault experiments. Meanwhile, a lightweight balanced neural network is proposed to guarantee competitive accuracy and soft feature extraction score. In our experiments, several traditional machine learning methods and deep learning methods across two arc fault datasets with different sample times and noise levels are utilized to test the effectiveness of the soft evaluation indicator. Through this approach, the arc fault diagnosis models are easy to understand and trust, allowing practitioners to make informed and trustworthy decisions.",
      "tldr_zh": "æœ¬ç ”ç©¶é’ˆå¯¹ç”µå¼§æ•…éšœè¯Šæ–­ (Arc Fault Diagnosis) æ¨¡å‹åœ¨åˆ†ç±»å‡†ç¡®ç‡è™½é«˜ä½†å…¶å†³ç­–è¿‡ç¨‹ç¼ºä¹å¯ä¿¡åº¦çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºå¯è§£é‡Šäººå·¥æ™ºèƒ½ (Explainable Artificial Intelligence) çš„è½¯è¯„ä¼°æŒ‡æ ‡ (Soft Evaluation Indicator)ã€‚è¯¥æŒ‡æ ‡é€šè¿‡å®šä¹‰ç”µå¼§æ•…éšœçš„æ­£ç¡®è§£é‡Šé€»è¾‘ï¼Œå¹¶ç»“åˆå®é™…ç”µå¼§æ•…éšœå®éªŒä¸ XAI æŠ€æœ¯ï¼Œå®ç°äº†å¯¹è¯Šæ–­æ¨¡å‹è¾“å‡ºç»“æœçš„æœ‰æ•ˆè§£é‡Šã€‚ç ”ç©¶åŒæ—¶æå‡ºäº†ä¸€ç§è½»é‡åŒ–å¹³è¡¡ç¥ç»ç½‘ç»œ (Lightweight balanced neural network)ï¼Œæ—¨åœ¨ä¿è¯é«˜å‡†ç¡®ç‡çš„åŒæ—¶ä¼˜åŒ–è½¯ç‰¹å¾æå–è¯„åˆ†ã€‚å®éªŒé€šè¿‡åœ¨å…·æœ‰ä¸åŒé‡‡æ ·æ—¶é—´å’Œå™ªå£°æ°´å¹³çš„ä¸¤ä¸ªç”µå¼§æ•…éšœæ•°æ®é›†ä¸Šæµ‹è¯•å¤šç§ä¼ ç»Ÿæœºå™¨å­¦ä¹  (Machine Learning) ä¸æ·±åº¦å­¦ä¹  (Deep Learning) æ–¹æ³•ï¼ŒéªŒè¯äº†è¯¥è¯„ä¼°æŒ‡æ ‡çš„æœ‰æ•ˆæ€§ã€‚è¯¥ç ”ç©¶æ˜¾è‘—æå‡äº†ç”µå¼§æ•…éšœè¯Šæ–­æ¨¡å‹çš„å¯ç†è§£æ€§ï¼Œä¸ºä»ä¸šè€…åšå‡ºæ˜æ™ºä¸”å¯ä¿¡çš„å†³ç­–æä¾›äº†æŠ€æœ¯ä¿éšœã€‚",
      "categories": [
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.15239v1",
      "published_date": "2025-07-21 04:52:43 UTC",
      "updated_date": "2025-07-21 04:52:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:05:28.994988+00:00"
    },
    {
      "arxiv_id": "2507.17934v1",
      "title": "Multimodal Fine-grained Reasoning for Post Quality Evaluation",
      "title_zh": "é¢å‘å¸–å­è´¨é‡è¯„ä¼°çš„å¤šæ¨¡æ€ç»†ç²’åº¦æ¨ç†",
      "authors": [
        "Xiaoxu Guo",
        "Siyan Liang",
        "Yachao Cui",
        "Juxiang Zhou",
        "Lei Wang",
        "Han Cao"
      ],
      "abstract": "Accurately assessing post quality requires complex relational reasoning to capture nuanced topic-post relationships. However, existing studies face three major limitations: (1) treating the task as unimodal categorization, which fails to leverage multimodal cues and fine-grained quality distinctions; (2) introducing noise during deep multimodal fusion, leading to misleading signals; and (3) lacking the ability to capture complex semantic relationships like relevance and comprehensiveness. To address these issues, we propose the Multimodal Fine-grained Topic-post Relational Reasoning (MFTRR) framework, which mimics human cognitive processes. MFTRR reframes post-quality assessment as a ranking task and incorporates multimodal data to better capture quality variations. It consists of two key modules: (1) the Local-Global Semantic Correlation Reasoning Module, which models fine-grained semantic interactions between posts and topics at both local and global levels, enhanced by a maximum information fusion mechanism to suppress noise; and (2) the Multi-Level Evidential Relational Reasoning Module, which explores macro- and micro-level relational cues to strengthen evidence-based reasoning. We evaluate MFTRR on three newly constructed multimodal topic-post datasets and the public Lazada-Home dataset. Experimental results demonstrate that MFTRR significantly outperforms state-of-the-art baselines, achieving up to 9.52% NDCG@3 improvement over the best unimodal method on the Art History dataset.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†å¤šæ¨¡æ€ç»†ç²’åº¦ä¸»é¢˜-å¸–å­å…³ç³»æ¨ç†(Multimodal Fine-grained Topic-post Relational Reasoning, MFTRR)æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰å¸–å­è´¨é‡è¯„ä¼°ä¸­å­˜åœ¨çš„å•æ¨¡æ€åˆ†ç±»å±€é™ã€å¤šæ¨¡æ€èåˆå™ªå£°ä»¥åŠå¤æ‚è¯­ä¹‰å…³ç³»æ•æ‰ä¸è¶³ç­‰é—®é¢˜ã€‚MFTRRå°†è´¨é‡è¯„ä¼°ä»»åŠ¡é‡æ–°å®šä¹‰ä¸ºæ’åºä»»åŠ¡ï¼Œé€šè¿‡æ•´åˆå¤šæ¨¡æ€æ•°æ®æ¥æ›´ç²¾å‡†åœ°æ•æ‰å¸–å­çš„è´¨é‡å˜åŒ–ã€‚è¯¥æ¡†æ¶æ ¸å¿ƒåŒ…å«å±€éƒ¨-å…¨å±€è¯­ä¹‰ç›¸å…³æ€§æ¨ç†æ¨¡å—(Local-Global Semantic Correlation Reasoning Module)ï¼Œåˆ©ç”¨æœ€å¤§ä¿¡æ¯èåˆæœºåˆ¶æŠ‘åˆ¶æ·±åº¦èåˆè¿‡ç¨‹ä¸­çš„å™ªå£°ï¼Œå¹¶å»ºæ¨¡ä¸»é¢˜ä¸å¸–å­é—´çš„ç»†ç²’åº¦äº¤äº’ã€‚æ­¤å¤–ï¼Œé€šè¿‡å¤šå±‚çº§è¯æ®å…³ç³»æ¨ç†æ¨¡å—(Multi-Level Evidential Relational Reasoning Module)æ¢ç´¢å®è§‚å’Œå¾®è§‚å±‚é¢çš„å…³è”çº¿ç´¢ï¼Œå¢å¼ºäº†åŸºäºè¯æ®çš„æ¨ç†èƒ½åŠ›ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒMFTRRåœ¨ä¸‰ä¸ªæ–°æ„å»ºçš„æ•°æ®é›†åŠLazada-Homeæ•°æ®é›†ä¸Šå‡æ˜¾è‘—ä¼˜äºç°æœ‰åŸºçº¿æ–¹æ³•ï¼Œå…¶ä¸­åœ¨Art Historyæ•°æ®é›†ä¸Šçš„NDCG@3æŒ‡æ ‡ç›¸æ¯”æœ€ä¼˜å•æ¨¡æ€æ–¹æ³•æå‡äº†9.52%ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "48 pages",
      "pdf_url": "https://arxiv.org/pdf/2507.17934v1",
      "published_date": "2025-07-21 04:30:50 UTC",
      "updated_date": "2025-07-21 04:30:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:05:37.499853+00:00"
    },
    {
      "arxiv_id": "2507.15225v1",
      "title": "Solving Formal Math Problems by Decomposition and Iterative Reflection",
      "title_zh": "åŸºäºåˆ†è§£ä¸è¿­ä»£åæ€çš„å½¢å¼åŒ–æ•°å­¦é—®é¢˜æ±‚è§£",
      "authors": [
        "Yichi Zhou",
        "Jianqiu Zhao",
        "Yongxin Zhang",
        "Bohan Wang",
        "Siran Wang",
        "Luoxin Chen",
        "Jiahui Wang",
        "Haowei Chen",
        "Allan Jie",
        "Xinbo Zhang",
        "Haocheng Wang",
        "Luong Trung",
        "Rong Ye",
        "Phan Nhat Hoang",
        "Huishuai Zhang",
        "Peng Sun",
        "Hang Li"
      ],
      "abstract": "General-purpose Large Language Models (LLMs) have achieved remarkable success in intelligence, performing comparably to human experts on complex reasoning tasks such as coding and mathematical reasoning. However, generating formal proofs in specialized languages like Lean 4 remains a significant challenge for these models, limiting their application in complex theorem proving and automated verification. Current approaches typically require specializing models through fine-tuning on dedicated formal corpora, incurring high costs for data collection and training. In this work, we introduce \\textbf{Delta Prover}, an agent-based framework that orchestrates the interaction between a general-purpose LLM and the Lean 4 proof environment. Delta Prover leverages the reflection and reasoning capabilities of general-purpose LLMs to interactively construct formal proofs in Lean 4, circumventing the need for model specialization. At its core, the agent integrates two novel, interdependent components: an algorithmic framework for reflective decomposition and iterative proof repair, and a custom Domain-Specific Language (DSL) built upon Lean 4 for streamlined subproblem management. \\textbf{Delta Prover achieves a state-of-the-art 95.9\\% success rate on the miniF2F-test benchmark, surpassing all existing approaches, including those requiring model specialization.} Furthermore, Delta Prover exhibits a significantly stronger test-time scaling law compared to standard Best-of-N proof strategies. Crucially, our findings demonstrate that general-purpose LLMs, when guided by an effective agentic structure, possess substantial untapped theorem-proving capabilities. This presents a computationally efficient alternative to specialized models for robust automated reasoning in formal environments.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Delta Proverï¼Œä¸€ç§åŸºäºæ™ºèƒ½ä½“(Agent)çš„æ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡é€šç”¨å¤§è¯­è¨€æ¨¡å‹(LLMs)ä¸Lean 4è¯æ˜ç¯å¢ƒçš„äº¤äº’æ¥è§£å†³å½¢å¼åŒ–æ•°å­¦è¯æ˜éš¾é¢˜ã€‚è¯¥æ¡†æ¶çš„æ ¸å¿ƒé›†æˆäº†åæ€æ€§åˆ†è§£(Reflective Decomposition)ä¸è¿­ä»£å¼è¯æ˜ä¿®å¤(Iterative Proof Repair)çš„ç®—æ³•æ¡†æ¶ï¼Œå¹¶ç»“åˆä¸“é—¨æ„å»ºçš„é¢†åŸŸç‰¹å®šè¯­è¨€(DSL)æ¥ä¼˜åŒ–å­é—®é¢˜ç®¡ç†ã€‚Delta Proveré€šè¿‡äº¤äº’å¼è¯æ˜æ„å»ºè§„é¿äº†å¯¹ç‰¹å®šæ¨¡å‹è¿›è¡Œæ˜‚è´µå¾®è°ƒçš„éœ€æ±‚ï¼Œå……åˆ†æŒ–æ˜äº†é€šç”¨æ¨¡å‹åœ¨å½¢å¼åŒ–å®šç†è¯æ˜ä¸­å°šæœªè¢«å¼€å‘çš„æ½œåŠ›ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒDelta Proveråœ¨miniF2F-teståŸºå‡†æµ‹è¯•ä¸Šå–å¾—äº†95.9%çš„æˆåŠŸç‡ï¼Œåˆ·æ–°äº†SOTAè®°å½•ï¼Œå¹¶å±•ç°å‡ºæ˜¾è‘—ä¼˜äºä¼ ç»Ÿç­–ç•¥çš„æ¨ç†æ—¶é—´ç¼©æ”¾å®šå¾‹(Test-time Scaling Law)ã€‚è¿™ä¸€æˆæœè¯æ˜äº†åœ¨æœ‰æ•ˆæ™ºèƒ½ä½“ç»“æ„çš„å¼•å¯¼ä¸‹ï¼Œé€šç”¨æ¨¡å‹èƒ½ä¸ºå½¢å¼åŒ–ç¯å¢ƒä¸­çš„è‡ªåŠ¨åŒ–æ¨ç†æä¾›ä¸€ç§é«˜æ•ˆç‡ä¸”ç¨³å¥çš„æ›¿ä»£æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.15225v1",
      "published_date": "2025-07-21 03:56:35 UTC",
      "updated_date": "2025-07-21 03:56:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:05:41.395104+00:00"
    },
    {
      "arxiv_id": "2507.15224v1",
      "title": "SimdBench: Benchmarking Large Language Models for SIMD-Intrinsic Code Generation",
      "title_zh": "SimdBenchï¼šé¢å‘ SIMD å†…è”å‡½æ•°ä»£ç ç”Ÿæˆçš„å¤§è¯­è¨€æ¨¡å‹åŸºå‡†æµ‹è¯•",
      "authors": [
        "Yibo He",
        "Shuoran Zhao",
        "Jiaming Huang",
        "Yingjie Fu",
        "Hao Yu",
        "Cunjian Huang",
        "Tao Xie"
      ],
      "abstract": "SIMD (Single Instruction Multiple Data) instructions and their compiler intrinsics are widely supported by modern processors to accelerate performance-critical tasks. SIMD intrinsic programming, a trade-off between coding productivity and high performance, is widely used in the development of mainstream performance-critical libraries and daily computing tasks. Large Language Models (LLMs), which have demonstrated strong and comprehensive capabilities in code generation, show promise in assisting programmers with the challenges of SIMD intrinsic programming. However, existing code-generation benchmarks focus on only scalar code, and it is unclear how LLMs perform in generating vectorized code using SIMD intrinsics. To fill this gap, we propose SimdBench, the first code benchmark specifically designed for SIMD-intrinsic code generation, comprising 136 carefully crafted tasks and targeting five representative SIMD intrinsics: SSE (x86 Streaming SIMD Extension), AVX (x86 Advanced Vector Extension), Neon (ARM Advanced SIMD Extension), SVE (ARM Scalable Vector Extension), and RVV (RISC-V Vector Extension). We conduct a systematic evaluation (measuring both correctness and performance) of 18 representative LLMs on SimdBench, resulting in a series of novel and insightful findings. Our evaluation results demonstrate that LLMs exhibit a universal decrease in pass@k during SIMD-intrinsic code generation compared to scalar-code generation. Our in-depth analysis highlights promising directions for the further advancement of LLMs in the challenging domain of SIMD-intrinsic code generation. SimdBench is fully open source at https://anonymous.4open.science/r/SimdBench-1B3F/ to benefit the broader research community.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†SimdBenchï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªä¸“é—¨ä¸ºSIMD-intrinsicä»£ç ç”Ÿæˆè®¾è®¡çš„åŸºå‡†æµ‹è¯•é›†ï¼Œæ—¨åœ¨è¯„ä¼°å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨å‘é‡åŒ–ç¼–ç¨‹é¢†åŸŸçš„æ€§èƒ½ã€‚è¯¥åŸºå‡†åŒ…å«136ä¸ªç²¾å¿ƒè®¾è®¡çš„ä»»åŠ¡ï¼Œæ¶µç›–äº†SSEã€AVXã€Neonã€SVEå’ŒRVVäº”ç§ä»£è¡¨æ€§çš„æŒ‡ä»¤é›†ã€‚ç ”ç©¶è€…å¯¹18ä¸ªä»£è¡¨æ€§LLMsåœ¨ä»£ç æ­£ç¡®æ€§å’Œæ€§èƒ½æ–¹é¢è¿›è¡Œäº†ç³»ç»Ÿè¯„ä¼°ï¼Œå¡«è¡¥äº†ç°æœ‰åŸºå‡†ä¸»è¦å…³æ³¨æ ‡é‡ä»£ç (scalar code)çš„ç©ºç™½ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒLLMsåœ¨å¤„ç†SIMD-intrinsicä»£ç ç”Ÿæˆä»»åŠ¡æ—¶ï¼Œå…¶pass@kæŒ‡æ ‡è¾ƒæ ‡é‡ä»£ç ç”Ÿæˆå‘ˆç°æ™®éä¸‹é™è¶‹åŠ¿ã€‚é€šè¿‡æ·±å…¥åˆ†æï¼Œè¯¥ç ”ç©¶æ­ç¤ºäº†LLMsåœ¨è¿™ä¸€å…·æœ‰æŒ‘æˆ˜æ€§çš„é¢†åŸŸä¸­çš„å±€é™æ€§ï¼Œå¹¶ä¸ºåç»­æå‡æ¨¡å‹åœ¨åº•å±‚ä¼˜åŒ–ä»£ç ç”Ÿæˆæ–¹é¢çš„èƒ½åŠ›æä¾›äº†æ–¹å‘ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.15224v1",
      "published_date": "2025-07-21 03:55:41 UTC",
      "updated_date": "2025-07-21 03:55:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:05:59.641626+00:00"
    },
    {
      "arxiv_id": "2507.15219v1",
      "title": "PromptArmor: Simple yet Effective Prompt Injection Defenses",
      "title_zh": "PromptArmorï¼šç®€å•è€Œæœ‰æ•ˆçš„æç¤ºæ³¨å…¥é˜²å¾¡",
      "authors": [
        "Tianneng Shi",
        "Kaijie Zhu",
        "Zhun Wang",
        "Yuqi Jia",
        "Will Cai",
        "Weida Liang",
        "Haonan Wang",
        "Hend Alzahrani",
        "Joshua Lu",
        "Kenji Kawaguchi",
        "Basel Alomair",
        "Xuandong Zhao",
        "William Yang Wang",
        "Neil Gong",
        "Wenbo Guo",
        "Dawn Song"
      ],
      "abstract": "Despite their potential, recent research has demonstrated that LLM agents are vulnerable to prompt injection attacks, where malicious prompts are injected into the agent's input, causing it to perform an attacker-specified task rather than the intended task provided by the user. In this paper, we present PromptArmor, a simple yet effective defense against prompt injection attacks. Specifically, PromptArmor prompts an off-the-shelf LLM to detect and remove potential injected prompts from the input before the agent processes it. Our results show that PromptArmor can accurately identify and remove injected prompts. For example, using GPT-4o, GPT-4.1, or o4-mini, PromptArmor achieves both a false positive rate and a false negative rate below 1% on the AgentDojo benchmark. Moreover, after removing injected prompts with PromptArmor, the attack success rate drops to below 1%. We also demonstrate PromptArmor's effectiveness against adaptive attacks and explore different strategies for prompting an LLM. We recommend that PromptArmor be adopted as a standard baseline for evaluating new defenses against prompt injection attacks.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹æ™ºèƒ½ä½“ï¼ˆLLM agentsï¼‰ææ˜“é­å—æç¤ºæ³¨å…¥æ”»å‡»ï¼ˆprompt injection attacksï¼‰çš„ç°çŠ¶ï¼Œæå‡ºäº† PromptArmor è¿™ä¸€ç®€å•ä¸”æœ‰æ•ˆçš„é˜²å¾¡æœºåˆ¶ã€‚PromptArmor çš„æ ¸å¿ƒæ–¹æ³•æ˜¯åˆ©ç”¨ç°æˆçš„ LLMï¼ˆoff-the-shelf LLMï¼‰åœ¨ä»»åŠ¡å¤„ç†å‰å¯¹è¾“å…¥è¿›è¡Œé¢„æ‰«æï¼Œæ—¨åœ¨è¯†åˆ«å¹¶ç§»é™¤å…¶ä¸­çš„æ¶æ„æ³¨å…¥æŒ‡ä»¤ã€‚å®éªŒè¡¨æ˜ï¼ŒPromptArmor åœ¨ AgentDojo åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å“è¶Šï¼Œä½¿ç”¨ GPT-4o æˆ– o4-mini ç­‰æ¨¡å‹æ—¶çš„è¯¯æŠ¥ç‡ï¼ˆfalse positive rateï¼‰å’Œæ¼æŠ¥ç‡ï¼ˆfalse negative rateï¼‰å‡ä½äº 1%ã€‚å®æ–½è¯¥é˜²å¾¡åï¼Œæ”»å‡»æˆåŠŸç‡ï¼ˆattack success rateï¼‰å¯é™è‡³ 1% ä»¥ä¸‹ï¼Œä¸”è¯¥æ–¹æ³•åœ¨åº”å¯¹è‡ªé€‚åº”æ”»å‡»ï¼ˆadaptive attacksï¼‰æ—¶åŒæ ·å±•ç°å‡ºæå¼ºçš„é²æ£’æ€§ã€‚é‰´äºå…¶å‡ºè‰²çš„é˜²å¾¡æ€§èƒ½å’Œç®€æ´æ€§ï¼Œç ”ç©¶è€…å»ºè®®å°† PromptArmor ä½œä¸ºæœªæ¥è¯„ä¼°æç¤ºæ³¨å…¥é˜²å¾¡æŠ€æœ¯çš„æ ‡å‡†åŸºå‡†ï¼ˆbaselineï¼‰ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.15219v1",
      "published_date": "2025-07-21 03:41:44 UTC",
      "updated_date": "2025-07-21 03:41:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:05:58.650076+00:00"
    },
    {
      "arxiv_id": "2507.15205v2",
      "title": "Long-Short Distance Graph Neural Networks and Improved Curriculum Learning for Emotion Recognition in Conversation",
      "title_zh": "é¢å‘å¯¹è¯æƒ…æ„Ÿè¯†åˆ«çš„é•¿çŸ­è·ç¦»å›¾ç¥ç»ç½‘ç»œä¸æ”¹è¿›è¯¾ç¨‹å­¦ä¹ ",
      "authors": [
        "Xinran Li",
        "Xiujuan Xu",
        "Jiaqi Qiao"
      ],
      "abstract": "Emotion Recognition in Conversation (ERC) is a practical and challenging task. This paper proposes a novel multimodal approach, the Long-Short Distance Graph Neural Network (LSDGNN). Based on the Directed Acyclic Graph (DAG), it constructs a long-distance graph neural network and a short-distance graph neural network to obtain multimodal features of distant and nearby utterances, respectively. To ensure that long- and short-distance features are as distinct as possible in representation while enabling mutual influence between the two modules, we employ a Differential Regularizer and incorporate a BiAffine Module to facilitate feature interaction. In addition, we propose an Improved Curriculum Learning (ICL) to address the challenge of data imbalance. By computing the similarity between different emotions to emphasize the shifts in similar emotions, we design a \"weighted emotional shift\" metric and develop a difficulty measurer, enabling a training process that prioritizes learning easy samples before harder ones. Experimental results on the IEMOCAP and MELD datasets demonstrate that our model outperforms existing benchmarks.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åä¸ºLSDGNNçš„æ–°å‹å¤šæ¨¡æ€æ¡†æ¶ï¼Œæ—¨åœ¨æå‡å¯¹è¯ä¸­çš„æƒ…æ„Ÿè¯†åˆ«(ERC)ä»»åŠ¡æ€§èƒ½ã€‚è¯¥æ–¹æ³•åŸºäºæœ‰å‘æ— ç¯å›¾(DAG)æ„å»ºäº†é•¿è·ç¦»å’ŒçŸ­è·ç¦»å›¾ç¥ç»ç½‘ç»œï¼Œç”¨ä»¥åˆ†åˆ«æå–è¿œç«¯å’Œè¿‘ç«¯è¯è¯­çš„å¤šæ¨¡æ€ç‰¹å¾ã€‚ä¸ºäº†ä¼˜åŒ–ç‰¹å¾è¡¨ç¤ºï¼Œç ”ç©¶å¼•å…¥äº†Differential Regularizerä»¥ç¡®ä¿é•¿çŸ­è·ç¦»ç‰¹å¾çš„åŒºåˆ†æ€§ï¼Œå¹¶é€šè¿‡BiAffine Moduleå®ç°ç‰¹å¾é—´çš„æœ‰æ•ˆäº¤äº’ã€‚é’ˆå¯¹æ•°æ®ä¸å¹³è¡¡é—®é¢˜ï¼Œè®ºæ–‡æå‡ºäº†æ”¹è¿›çš„è¯¾ç¨‹å­¦ä¹ (ICL)ç­–ç•¥ï¼Œåˆ©ç”¨æ–°è®¾è®¡çš„â€œåŠ æƒæƒ…æ„Ÿåç§»(weighted emotional shift)â€æŒ‡æ ‡æ¥è¡¡é‡æ ·æœ¬éš¾åº¦ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿéµå¾ªä»æ˜“åˆ°éš¾çš„è®­ç»ƒè·¯å¾„ã€‚åœ¨IEMOCAPå’ŒMELDæ•°æ®é›†ä¸Šçš„å®éªŒè¯æ˜ï¼Œè¯¥æ¨¡å‹åœ¨è¯†åˆ«æ€§èƒ½ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰çš„åŸºå‡†æ¨¡å‹ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by the 28th European Conference on Artificial Intelligence (ECAI 2025)",
      "pdf_url": "https://arxiv.org/pdf/2507.15205v2",
      "published_date": "2025-07-21 03:12:54 UTC",
      "updated_date": "2025-07-24 05:15:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:06:02.543681+00:00"
    },
    {
      "arxiv_id": "2507.15898v2",
      "title": "A Generative Model for Disentangling Galaxy Photometric Parameters",
      "title_zh": "ç”¨äºæ˜Ÿç³»å…‰åº¦å‚æ•°è§£è€¦çš„ç”Ÿæˆå¼æ¨¡å‹",
      "authors": [
        "Keen Leung",
        "Colen Yan",
        "Jun Yin"
      ],
      "abstract": "Ongoing and future photometric surveys will produce unprecedented volumes of galaxy images, necessitating robust, efficient methods for deriving galaxy morphological parameters at scale. Traditional approaches, such as parametric light-profile fitting, offer valuable insights but become computationally prohibitive when applied to billions of sources. In this work, we propose a Conditional AutoEncoder (CAE) framework to simultaneously model and characterize galaxy morphology. Our CAE is trained on a suite of realistic mock galaxy images generated via GalSim, encompassing a broad range of galaxy types, photometric parameters (e.g., flux, half-light radius, Sersic index, ellipticity), and observational conditions. By encoding each galaxy image into a low-dimensional latent representation conditioned on key parameters, our model effectively recovers these morphological features in a disentangled manner, while also reconstructing the original image. The results demonstrate that the CAE approach can accurately and efficiently infer complex structural properties, offering a powerful alternative to existing methods.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æœªæ¥å¤§è§„æ¨¡å…‰åº¦å·¡å¤©äº§ç”Ÿçš„æµ·é‡æ˜Ÿç³»å›¾åƒï¼Œæå‡ºäº†ä¸€ç§æ—¨åœ¨é«˜æ•ˆæå–æ˜Ÿç³»å½¢æ€å‚æ•°çš„ Conditional AutoEncoder (CAE) æ¡†æ¶ã€‚ä¼ ç»Ÿçš„å…‰åº¦è½®å»“æ‹Ÿåˆ(parametric light-profile fitting)æ–¹æ³•åœ¨å¤„ç†æ•°åäº¿ä¸ªæºæ—¶é¢ä¸´è®¡ç®—æˆæœ¬è¿‡é«˜çš„æŒ‘æˆ˜ï¼Œè€Œè¯¥ CAE æ¨¡å‹é€šè¿‡åœ¨ GalSim ç”Ÿæˆçš„çœŸå®æ¨¡æ‹Ÿæ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒï¼Œæ¶µç›–äº†å¹¿æ³›çš„æ˜Ÿç³»ç±»å‹å’Œè§‚æµ‹æ¡ä»¶ã€‚è¯¥æ¡†æ¶å°†æ˜Ÿç³»å›¾åƒç¼–ç ä¸ºå—å…³é”®å‚æ•°çº¦æŸçš„ä½ç»´æ½œåœ¨è¡¨ç¤º(latent representation)ï¼Œä»è€Œä»¥è§£è€¦çš„æ–¹å¼æœ‰æ•ˆæ¢å¤ fluxã€half-light radiusã€Sersic index å’Œ ellipticity ç­‰æ ¸å¿ƒå½¢æ€ç‰¹å¾ï¼Œå¹¶åŒæ­¥å®ç°å›¾åƒé‡æ„ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒCAE æ–¹æ³•èƒ½å¤Ÿå‡†ç¡®ä¸”é«˜æ•ˆåœ°æ¨æ–­å¤æ‚çš„ç»“æ„å±æ€§ï¼Œä¸ºç°æœ‰çš„æ˜Ÿç³»å½¢æ€å­¦ç ”ç©¶æä¾›äº†ä¸€ç§æå…·æ½œåŠ›çš„æ›¿ä»£æ–¹æ¡ˆï¼Œèƒ½å¤Ÿæ»¡è¶³å¤§è§„æ¨¡ç§‘å­¦æ•°æ®çš„è‡ªåŠ¨åŒ–å¤„ç†éœ€æ±‚ã€‚",
      "categories": [
        "astro-ph.IM",
        "astro-ph.GA",
        "cs.AI"
      ],
      "primary_category": "astro-ph.IM",
      "comment": "16 pages, 7 figures",
      "pdf_url": "https://arxiv.org/pdf/2507.15898v2",
      "published_date": "2025-07-21 03:09:37 UTC",
      "updated_date": "2025-12-26 21:19:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:06:04.293824+00:00"
    },
    {
      "arxiv_id": "2507.15193v2",
      "title": "A Study of Anatomical Priors for Deep Learning-Based Segmentation of Pheochromocytoma in Abdominal CT",
      "title_zh": "è…¹éƒ¨ CT å—œé“¬ç»†èƒç˜¤æ·±åº¦å­¦ä¹ åˆ†å‰²çš„è§£å‰–å­¦å…ˆéªŒç ”ç©¶",
      "authors": [
        "Tanjin Taher Toma",
        "Tejas Sudharshan Mathai",
        "Bikash Santra",
        "Pritam Mukherjee",
        "Jianfei Liu",
        "Wesley Jong",
        "Darwish Alabyad",
        "Vivek Batheja",
        "Abhishek Jha",
        "Mayank Patel",
        "Darko Pucar",
        "Jayadira del Rivero",
        "Karel Pacak",
        "Ronald M. Summers"
      ],
      "abstract": "Accurate segmentation of pheochromocytoma (PCC) in abdominal CT scans is essential for tumor burden estimation, prognosis, and treatment planning. It may also help infer genetic clusters, reducing reliance on expensive testing. This study systematically evaluates anatomical priors to identify configurations that improve deep learning-based PCC segmentation. We employed the nnU-Net framework to evaluate eleven annotation strategies for accurate 3D segmentation of pheochromocytoma, introducing a set of novel multi-class schemes based on organ-specific anatomical priors. These priors were derived from adjacent organs commonly surrounding adrenal tumors (e.g., liver, spleen, kidney, aorta, adrenal gland, and pancreas), and were compared against a broad body-region prior used in previous work. The framework was trained and tested on 105 contrast-enhanced CT scans from 91 patients at the NIH Clinical Center. Performance was measured using Dice Similarity Coefficient (DSC), Normalized Surface Distance (NSD), and instance-wise F1 score. Among all strategies, the Tumor + Kidney + Aorta (TKA) annotation achieved the highest segmentation accuracy, significantly outperforming the previously used Tumor + Body (TB) annotation across DSC (p = 0.0097), NSD (p = 0.0110), and F1 score (25.84% improvement at an IoU threshold of 0.5), measured on a 70-30 train-test split. The TKA model also showed superior tumor burden quantification (R^2 = 0.968) and strong segmentation across all genetic subtypes. In five-fold cross-validation, TKA consistently outperformed TB across IoU thresholds (0.1 to 0.5), reinforcing its robustness and generalizability. These findings highlight the value of incorporating relevant anatomical context into deep learning models to achieve precise PCC segmentation, offering a valuable tool to support clinical assessment and longitudinal disease monitoring in PCC patients.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è…¹éƒ¨CTå½±åƒä¸­çš„å—œé“¬ç»†èƒç˜¤ Pheochromocytoma (PCC) è‡ªåŠ¨åˆ†å‰²å±•å¼€ï¼Œè¿™å¯¹äºè¯„ä¼°è‚¿ç˜¤è´Ÿæ‹…å’Œåˆ¶å®šæ²»ç–—æ–¹æ¡ˆè‡³å…³é‡è¦ã€‚ç ”ç©¶äººå‘˜åŸºäº nnU-Net æ¡†æ¶ç³»ç»Ÿè¯„ä¼°äº†11ç§è§£å‰–å…ˆéªŒ (anatomical priors) æ ‡æ³¨ç­–ç•¥ï¼Œæ¢è®¨äº†å¼•å…¥å‘¨è¾¹å™¨å®˜ä¿¡æ¯å¯¹æ·±åº¦å­¦ä¹ æ¨¡å‹æ€§èƒ½çš„å½±å“ã€‚é€šè¿‡å¯¹æ¯”è‚è„ã€è‚¾è„ã€ä¸»åŠ¨è„‰ç­‰å¤šç§å™¨å®˜ç»„åˆä¸ä¼ ç»Ÿå…¨èº«åŒºåŸŸ (Tumor + Body, TB) å…ˆéªŒçš„è¡¨ç°ï¼Œå‘ç°â€œè‚¿ç˜¤+è‚¾è„+ä¸»åŠ¨è„‰â€ (Tumor + Kidney + Aorta, TKA) æ ‡æ³¨ç­–ç•¥è¾¾åˆ°äº†æœ€é«˜çš„åˆ†å‰²ç²¾åº¦ã€‚å®éªŒæ•°æ®è¡¨æ˜ï¼ŒTKA ç­–ç•¥åœ¨ Dice Similarity Coefficient (DSC) å’Œ Normalized Surface Distance (NSD) ç­‰æŒ‡æ ‡ä¸Šæ˜¾è‘—ä¼˜äº TB åŸºçº¿ï¼Œä¸” F1 score æå‡äº† 25.84%ã€‚æ­¤å¤–ï¼ŒTKA æ¨¡å‹åœ¨è‚¿ç˜¤è´Ÿæ‹…å®šé‡è¯„ä¼° (R^2 = 0.968) å’Œä¸åŒé—ä¼ äºšå‹åˆ†å‰²ä¸­å‡è¡¨ç°å‡ºæå¼ºçš„é²æ£’æ€§ã€‚è¯¥ç ”ç©¶è¯æ˜äº†æ•´åˆç›¸å…³è§£å‰–èƒŒæ™¯ä¿¡æ¯å¯¹äºå®ç°ç²¾ç¡® PCC åˆ†å‰²çš„ä¸´åºŠä»·å€¼ï¼Œä¸ºè¯¥ç–¾ç—…çš„ä¸´åºŠè¯„ä¼°å’Œé•¿æœŸç›‘æµ‹æä¾›äº†æœ‰åŠ›å·¥å…·ã€‚",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.15193v2",
      "published_date": "2025-07-21 02:35:29 UTC",
      "updated_date": "2025-07-24 19:33:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:06:15.846733+00:00"
    },
    {
      "arxiv_id": "2507.15897v2",
      "title": "ReDi: Rectified Discrete Flow",
      "title_zh": "ReDiï¼šæ•´æµç¦»æ•£æµ",
      "authors": [
        "Jaehoon Yoo",
        "Wonjung Kim",
        "Seunghoon Hong"
      ],
      "abstract": "Discrete Flow-based Models (DFMs) are powerful generative models for high-quality discrete data but typically suffer from slow sampling speeds due to their reliance on iterative decoding processes. This reliance on a multi-step process originates from the factorization approximation of DFMs, which is necessary for handling high-dimensional data. In this paper, we analyze the factorization approximation error using Conditional Total Correlation (TC), and reveal its dependence on the coupling. To address the challenge of efficient few-step generation, we propose Rectified Discrete Flow (ReDi), a novel iterative method that reduces the underlying factorization error (measured as Conditional TC) by rectifying the coupling between source and target distributions. We theoretically prove that each ReDi step guarantees a monotonic decreasing Conditional TC, ensuring its convergence. Empirically, ReDi significantly reduces Conditional TC and enables few-step generation. Moreover, we demonstrate that the rectified couplings are well-suited for training efficient one-step models on image generation. ReDi offers a simple and theoretically grounded approach for tackling the few-step challenge, providing a new perspective on efficient discrete data synthesis. Code is available at https://github.com/Ugness/ReDi_discrete.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç¦»æ•£æµæ¨¡å‹ (Discrete Flow-based Models, DFMs) å› ä¾èµ–è¿­ä»£è§£ç å¯¼è‡´é‡‡æ ·é€Ÿåº¦æ…¢çš„é—®é¢˜ï¼ŒæŒ‡å‡ºå…¶æ ¹æºåœ¨äºå¤„ç†é«˜ç»´æ•°æ®æ—¶çš„åˆ†è§£è¿‘ä¼¼ (factorization approximation) è¯¯å·®ã€‚ä½œè€…é€šè¿‡æ¡ä»¶å…¨ç›¸å…³ (Conditional Total Correlation, TC) é‡åŒ–åˆ†æäº†è¯¥è¯¯å·®ï¼Œå¹¶æ­ç¤ºäº†å…¶å¯¹åˆ†å¸ƒé—´è€¦åˆ (coupling) çš„ä¾èµ–æ€§ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº† ReDi (Rectified Discrete Flow)ï¼Œé€šè¿‡æ ¡æ­£æºåˆ†å¸ƒä¸ç›®æ ‡åˆ†å¸ƒä¹‹é—´çš„è€¦åˆæ¥å‡å° Conditional TC è¯¯å·®ï¼Œå¹¶ä»ç†è®ºä¸Šè¯æ˜äº†è¯¥æ–¹æ³•æ¯ä¸€æ­¥éƒ½èƒ½ä¿è¯è¯¯å·®å•è°ƒé€’å‡ä»¥ç¡®ä¿æ”¶æ•›ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒReDi æ˜¾è‘—é™ä½äº† Conditional TC å¹¶å®ç°äº†é«˜æ•ˆçš„å°‘æ­¥ç”Ÿæˆï¼Œä¸”æ ¡æ­£åçš„è€¦åˆåŒæ ·é€‚ç”¨äºè®­ç»ƒé«˜æ€§èƒ½çš„å•æ­¥å›¾åƒç”Ÿæˆæ¨¡å‹ã€‚è¯¥ç ”ç©¶ä¸ºè§£å†³ç¦»æ•£æ•°æ®åˆæˆçš„æ•ˆç‡æŒ‘æˆ˜æä¾›äº†ä¸€ä¸ªç®€å•ä¸”å…·å¤‡ç†è®ºæ”¯æ’‘çš„æ–°è§†è§’ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.15897v2",
      "published_date": "2025-07-21 01:18:44 UTC",
      "updated_date": "2025-10-20 07:43:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:06:14.795691+00:00"
    }
  ],
  "processing_status": "completed",
  "error": null,
  "raw_papers_fetched": true,
  "papers_count": 156,
  "processed_papers_count": 156,
  "failed_papers_count": 0,
  "llm_backup_calls": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2026-01-24T06:07:09.389668+00:00"
}