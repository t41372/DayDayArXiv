[
  {
    "arxiv_id": "2501.04014v1",
    "title": "AICat: An AI Cataloguing Approach to Support the EU AI Act",
    "authors": [
      "Delaram Golpayegani",
      "Harshvardhan J. Pandit",
      "Dave Lewis"
    ],
    "abstract": "The European Union's Artificial Intelligence Act (AI Act) requires providers\nand deployers of high-risk AI applications to register their systems into the\nEU database, wherein the information should be represented and maintained in an\neasily-navigable and machine-readable manner. Given the uptake of open data and\nSemantic Web-based approaches for other EU repositories, in particular the use\nof the Data Catalogue vocabulary Application Profile (DCAT-AP), a similar\nsolution for managing the EU database of high-risk AI systems is needed. This\npaper introduces AICat - an extension of DCAT for representing catalogues of AI\nsystems that provides consistency, machine-readability, searchability, and\ninteroperability in managing open metadata regarding AI systems. This open\napproach to cataloguing ensures transparency, traceability, and accountability\nin AI application markets beyond the immediate needs of high-risk AI compliance\nin the EU. AICat is available online at https://w3id.org/aicat under the\nCC-BY-4.0 license.",
    "categories": [
      "cs.DL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.DL",
    "comment": "Presented at 37th International Conference on Legal Knowledge and\n  Information Systems (JURIX) 2024",
    "pdf_url": "http://arxiv.org/pdf/2501.04014v1",
    "published_date": "2024-12-19 23:48:20 UTC",
    "updated_date": "2024-12-19 23:48:20 UTC"
  },
  {
    "arxiv_id": "2412.15462v1",
    "title": "TalkWithMachines: Enhancing Human-Robot Interaction for Interpretable Industrial Robotics Through Large/Vision Language Models",
    "authors": [
      "Ammar N. Abbas",
      "Csaba Beleznai"
    ],
    "abstract": "TalkWithMachines aims to enhance human-robot interaction by contributing to\ninterpretable industrial robotic systems, especially for safety-critical\napplications. The presented paper investigates recent advancements in Large\nLanguage Models (LLMs) and Vision Language Models (VLMs), in combination with\nrobotic perception and control. This integration allows robots to understand\nand execute commands given in natural language and to perceive their\nenvironment through visual and/or descriptive inputs. Moreover, translating the\nLLM's internal states and reasoning into text that humans can easily understand\nensures that operators gain a clearer insight into the robot's current state\nand intentions, which is essential for effective and safe operation. Our paper\noutlines four LLM-assisted simulated robotic control workflows, which explore\n(i) low-level control, (ii) the generation of language-based feedback that\ndescribes the robot's internal states, (iii) the use of visual information as\nadditional input, and (iv) the use of robot structure information for\ngenerating task plans and feedback, taking the robot's physical capabilities\nand limitations into account. The proposed concepts are presented in a set of\nexperiments, along with a brief discussion. Project description, videos, and\nsupplementary materials will be available on the project website:\nhttps://talk-machines.github.io.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CL",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "This paper has been accepted for publication in the proceedings of\n  the 2024 Eighth IEEE International Conference on Robotic Computing (IRC)",
    "pdf_url": "http://arxiv.org/pdf/2412.15462v1",
    "published_date": "2024-12-19 23:43:40 UTC",
    "updated_date": "2024-12-19 23:43:40 UTC"
  },
  {
    "arxiv_id": "2412.17854v1",
    "title": "Active Geospatial Search for Efficient Tenant Eviction Outreach",
    "authors": [
      "Anindya Sarkar",
      "Alex DiChristofano",
      "Sanmay Das",
      "Patrick J. Fowler",
      "Nathan Jacobs",
      "Yevgeniy Vorobeychik"
    ],
    "abstract": "Tenant evictions threaten housing stability and are a major concern for many\ncities. An open question concerns whether data-driven methods enhance outreach\nprograms that target at-risk tenants to mitigate their risk of eviction. We\npropose a novel active geospatial search (AGS) modeling framework for this\nproblem. AGS integrates property-level information in a search policy that\nidentifies a sequence of rental units to canvas to both determine their\neviction risk and provide support if needed. We propose a hierarchical\nreinforcement learning approach to learn a search policy for AGS that scales to\nlarge urban areas containing thousands of parcels, balancing exploration and\nexploitation and accounting for travel costs and a budget constraint.\nCrucially, the search policy adapts online to newly discovered information\nabout evictions. Evaluation using eviction data for a large urban area\ndemonstrates that the proposed framework and algorithmic approach are\nconsiderably more effective at sequentially identifying eviction cases than\nbaseline methods.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to AAAI 2025 (AI for Social Impact Track)",
    "pdf_url": "http://arxiv.org/pdf/2412.17854v1",
    "published_date": "2024-12-19 23:40:36 UTC",
    "updated_date": "2024-12-19 23:40:36 UTC"
  },
  {
    "arxiv_id": "2412.15453v1",
    "title": "Northeastern Uni at Multilingual Counterspeech Generation: Enhancing Counter Speech Generation with LLM Alignment through Direct Preference Optimization",
    "authors": [
      "Sahil Wadhwa",
      "Chengtian Xu",
      "Haoming Chen",
      "Aakash Mahalingam",
      "Akankshya Kar",
      "Divya Chaudhary"
    ],
    "abstract": "The automatic generation of counter-speech (CS) is a critical strategy for\naddressing hate speech by providing constructive and informed responses.\nHowever, existing methods often fail to generate high-quality, impactful, and\nscalable CS, particularly across diverse linguistic contexts. In this paper, we\npropose a novel methodology to enhance CS generation by aligning Large Language\nModels (LLMs) using Supervised Fine-Tuning (SFT) and Direct Preference\nOptimization (DPO). Our approach leverages DPO to align LLM outputs with human\npreferences, ensuring contextually appropriate and linguistically adaptable\nresponses. Additionally, we incorporate knowledge grounding to enhance the\nfactual accuracy and relevance of generated CS. Experimental results\ndemonstrate that DPO-aligned models significantly outperform SFT baselines on\nCS benchmarks while scaling effectively to multiple languages. These findings\nhighlight the potential of preference-based alignment techniques to advance CS\ngeneration across varied linguistic settings. The model supervision and\nalignment is done in English and the same model is used for reporting metrics\nacross other languages like Basque, Italian, and Spanish.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "10 pages, 6 tables, 1 figure, The First Workshop on Multilingual\n  Counterspeech Generation (MCG) at The 31st International Conference on\n  Computational Linguistics (COLING 2025)",
    "pdf_url": "http://arxiv.org/pdf/2412.15453v1",
    "published_date": "2024-12-19 23:22:11 UTC",
    "updated_date": "2024-12-19 23:22:11 UTC"
  },
  {
    "arxiv_id": "2412.15444v1",
    "title": "AI-Enhanced Sensemaking: Exploring the Design of a Generative AI-Based Assistant to Support Genetic Professionals",
    "authors": [
      "Angela Mastrianni",
      "Hope Twede",
      "Aleksandra Sarcevic",
      "Jeremiah Wander",
      "Christina Austin-Tse",
      "Scott Saponas",
      "Heidi Rehm",
      "Ashley Mae Conard",
      "Amanda K. Hall"
    ],
    "abstract": "Generative AI has the potential to transform knowledge work, but further\nresearch is needed to understand how knowledge workers envision using and\ninteracting with generative AI. We investigate the development of generative AI\ntools to support domain experts in knowledge work, examining task delegation\nand the design of human-AI interactions. Our research focused on designing a\ngenerative AI assistant to aid genetic professionals in analyzing whole genome\nsequences (WGS) and other clinical data for rare disease diagnosis. Through\ninterviews with 17 genetics professionals, we identified current challenges in\nWGS analysis. We then conducted co-design sessions with six genetics\nprofessionals to determine tasks that could be supported by an AI assistant and\nconsiderations for designing interactions with the AI assistant. From our\nfindings, we identified sensemaking as both a current challenge in WGS analysis\nand a process that could be supported by AI. We contribute an understanding of\nhow domain experts envision interacting with generative AI in their knowledge\nwork, a detailed empirical study of WGS analysis, and three design\nconsiderations for using generative AI to support domain experts in sensemaking\nduring knowledge work.\n  CCS CONCEPTS: Human-centered computing, Human-computer interaction, Empirical\nstudies in HCI\n  Additional Keywords and Phrases: whole genome sequencing, generative AI,\nlarge language models, knowledge work, sensemaking, co-design, rare disease\n  Contact Author: Angela Mastrianni (This work was done during the author's\ninternship at Microsoft Research)\n  Ashley Mae Conard and Amanda K. Hall contributed equally",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "22 pages, 8 figures, 1 table, 3 appendices",
    "pdf_url": "http://arxiv.org/pdf/2412.15444v1",
    "published_date": "2024-12-19 22:54:49 UTC",
    "updated_date": "2024-12-19 22:54:49 UTC"
  },
  {
    "arxiv_id": "2412.15441v1",
    "title": "Energy consumption of code small language models serving with runtime engines and execution providers",
    "authors": [
      "Francisco Durán",
      "Matias Martinez",
      "Patricia Lago",
      "Silverio Martínez-Fernández"
    ],
    "abstract": "Background. The rapid growth of Language Models (LMs), particularly in code\ngeneration, requires substantial computational resources, raising concerns\nabout energy consumption and environmental impact. Optimizing LMs inference for\nenergy efficiency is crucial, and Small Language Models (SLMs) offer a\npromising solution to reduce resource demands.\n  Aim. Our goal is to analyze the impact of deep learning runtime engines and\nexecution providers on energy consumption, execution time, and\ncomputing-resource utilization from the point of view of software engineers\nconducting inference in the context of code SLMs.\n  Method. We conducted a technology-oriented, multi-stage experimental pipeline\nusing twelve code generation SLMs to investigate energy consumption, execution\ntime, and computing-resource utilization across the configurations.\n  Results. Significant differences emerged across configurations. CUDA\nexecution provider configurations outperformed CPU execution provider\nconfigurations in both energy consumption and execution time. Among the\nconfigurations, TORCH paired with CUDA demonstrated the greatest energy\nefficiency, achieving energy savings from 37.99% up to 89.16% compared to other\nserving configurations. Similarly, optimized runtime engines like ONNX with the\nCPU execution provider achieved from 8.98% up to 72.04% energy savings within\nCPU-based configurations. Also, TORCH paired with CUDA exhibited efficient\ncomputing-resource utilization.\n  Conclusions. Serving configuration choice significantly impacts energy\nefficiency. While further research is needed, we recommend the above\nconfigurations best suited to software engineers' requirements for enhancing\nserving efficiency in energy and performance.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.SE",
    "comment": "26 pages, submitted to journal",
    "pdf_url": "http://arxiv.org/pdf/2412.15441v1",
    "published_date": "2024-12-19 22:44:02 UTC",
    "updated_date": "2024-12-19 22:44:02 UTC"
  },
  {
    "arxiv_id": "2412.15438v1",
    "title": "Efficient Neural Network Encoding for 3D Color Lookup Tables",
    "authors": [
      "Vahid Zehtab",
      "David B. Lindell",
      "Marcus A. Brubaker",
      "Michael S. Brown"
    ],
    "abstract": "3D color lookup tables (LUTs) enable precise color manipulation by mapping\ninput RGB values to specific output RGB values. 3D LUTs are instrumental in\nvarious applications, including video editing, in-camera processing,\nphotographic filters, computer graphics, and color processing for displays.\nWhile an individual LUT does not incur a high memory overhead, software and\ndevices may need to store dozens to hundreds of LUTs that can take over 100 MB.\nThis work aims to develop a neural network architecture that can encode\nhundreds of LUTs in a single compact representation. To this end, we propose a\nmodel with a memory footprint of less than 0.25 MB that can reconstruct 512\nLUTs with only minor color distortion ($\\bar{\\Delta}E_M$ $\\leq$ 2.0) over the\nentire color gamut. We also show that our network can weight colors to provide\nfurther quality gains on natural image colors ($\\bar{\\Delta}{E}_M$ $\\leq$ 1.0).\nFinally, we show that minor modifications to the network architecture enable a\nbijective encoding that produces LUTs that are invertible, allowing for reverse\ncolor processing. Our code is available at https://github.com/vahidzee/ennelut.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "eess.IV",
      "I.4.0; I.4.2; I.5.0; I.5.1; I.5.4; I.2.0; I.2.6; I.2.10"
    ],
    "primary_category": "cs.CV",
    "comment": "14 pages, 13 figures; extended version; to appear in AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.15438v1",
    "published_date": "2024-12-19 22:41:26 UTC",
    "updated_date": "2024-12-19 22:41:26 UTC"
  },
  {
    "arxiv_id": "2412.19830v1",
    "title": "A Unified Framework for Context-Aware IoT Management and State-of-the-Art IoT Traffic Anomaly Detection",
    "authors": [
      "Daniel Adu Worae",
      "Athar Sheikh",
      "Spyridon Mastorakis"
    ],
    "abstract": "The rapid expansion of Internet of Things (IoT) ecosystems has introduced\ngrowing complexities in device management and network security. To address\nthese challenges, we present a unified framework that combines context-driven\nlarge language models (LLMs) for IoT administrative tasks with a fine-tuned\nanomaly detection module for network traffic analysis. The framework\nstreamlines administrative processes such as device management,\ntroubleshooting, and security enforcement by harnessing contextual knowledge\nfrom IoT manuals and operational data. The anomaly detection model achieves\nstate-of-the-art performance in identifying irregularities and threats within\nIoT traffic, leveraging fine-tuning to deliver exceptional accuracy.\nEvaluations demonstrate that incorporating relevant contextual information\nsignificantly enhances the precision and reliability of LLM-based responses for\ndiverse IoT administrative tasks. Additionally, resource usage metrics such as\nexecution time, memory consumption, and response efficiency demonstrate the\nframework's scalability and suitability for real-world IoT deployments.",
    "categories": [
      "cs.NI",
      "cs.AI"
    ],
    "primary_category": "cs.NI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.19830v1",
    "published_date": "2024-12-19 22:38:41 UTC",
    "updated_date": "2024-12-19 22:38:41 UTC"
  },
  {
    "arxiv_id": "2412.15433v1",
    "title": "Quantifying detection rates for dangerous capabilities: a theoretical model of dangerous capability evaluations",
    "authors": [
      "Paolo Bova",
      "Alessandro Di Stefano",
      "The Anh Han"
    ],
    "abstract": "We present a quantitative model for tracking dangerous AI capabilities over\ntime. Our goal is to help the policy and research community visualise how\ndangerous capability testing can give us an early warning about approaching AI\nrisks. We first use the model to provide a novel introduction to dangerous\ncapability testing and how this testing can directly inform policy. Decision\nmakers in AI labs and government often set policy that is sensitive to the\nestimated danger of AI systems, and may wish to set policies that condition on\nthe crossing of a set threshold for danger. The model helps us to reason about\nthese policy choices. We then run simulations to illustrate how we might fail\nto test for dangerous capabilities. To summarise, failures in dangerous\ncapability testing may manifest in two ways: higher bias in our estimates of AI\ndanger, or larger lags in threshold monitoring. We highlight two drivers of\nthese failure modes: uncertainty around dynamics in AI capabilities and\ncompetition between frontier AI labs. Effective AI policy demands that we\naddress these failure modes and their drivers. Even if the optimal targeting of\nresources is challenging, we show how delays in testing can harm AI policy. We\noffer preliminary recommendations for building an effective testing ecosystem\nfor dangerous capabilities and advise on a research agenda.",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.MA",
      "econ.GN",
      "q-fin.EC",
      "stat.AP"
    ],
    "primary_category": "cs.AI",
    "comment": "26 pages, 15 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.15433v1",
    "published_date": "2024-12-19 22:31:34 UTC",
    "updated_date": "2024-12-19 22:31:34 UTC"
  },
  {
    "arxiv_id": "2412.15429v5",
    "title": "Offline Safe Reinforcement Learning Using Trajectory Classification",
    "authors": [
      "Ze Gong",
      "Akshat Kumar",
      "Pradeep Varakantham"
    ],
    "abstract": "Offline safe reinforcement learning (RL) has emerged as a promising approach\nfor learning safe behaviors without engaging in risky online interactions with\nthe environment. Most existing methods in offline safe RL rely on cost\nconstraints at each time step (derived from global cost constraints) and this\ncan result in either overly conservative policies or violation of safety\nconstraints. In this paper, we propose to learn a policy that generates\ndesirable trajectories and avoids undesirable trajectories. To be specific, we\nfirst partition the pre-collected dataset of state-action trajectories into\ndesirable and undesirable subsets. Intuitively, the desirable set contains high\nreward and safe trajectories, and undesirable set contains unsafe trajectories\nand low-reward safe trajectories. Second, we learn a policy that generates\ndesirable trajectories and avoids undesirable trajectories, where\n(un)desirability scores are provided by a classifier learnt from the dataset of\ndesirable and undesirable trajectories. This approach bypasses the\ncomputational complexity and stability issues of a min-max objective that is\nemployed in existing methods. Theoretically, we also show our approach's strong\nconnections to existing learning paradigms involving human feedback. Finally,\nwe extensively evaluate our method using the DSRL benchmark for offline safe\nRL. Empirically, our method outperforms competitive baselines, achieving higher\nrewards and better constraint satisfaction across a wide variety of benchmark\ntasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "AAAI 2025. Updated results",
    "pdf_url": "http://arxiv.org/pdf/2412.15429v5",
    "published_date": "2024-12-19 22:29:03 UTC",
    "updated_date": "2025-04-19 01:50:15 UTC"
  },
  {
    "arxiv_id": "2412.15404v1",
    "title": "A Retrieval-Augmented Generation Framework for Academic Literature Navigation in Data Science",
    "authors": [
      "Ahmet Yasin Aytar",
      "Kemal Kilic",
      "Kamer Kaya"
    ],
    "abstract": "In the rapidly evolving field of data science, efficiently navigating the\nexpansive body of academic literature is crucial for informed decision-making\nand innovation. This paper presents an enhanced Retrieval-Augmented Generation\n(RAG) application, an artificial intelligence (AI)-based system designed to\nassist data scientists in accessing precise and contextually relevant academic\nresources. The AI-powered application integrates advanced techniques, including\nthe GeneRation Of BIbliographic Data (GROBID) technique for extracting\nbibliographic information, fine-tuned embedding models, semantic chunking, and\nan abstract-first retrieval method, to significantly improve the relevance and\naccuracy of the retrieved information. This implementation of AI specifically\naddresses the challenge of academic literature navigation. A comprehensive\nevaluation using the Retrieval-Augmented Generation Assessment System (RAGAS)\nframework demonstrates substantial improvements in key metrics, particularly\nContext Relevance, underscoring the system's effectiveness in reducing\ninformation overload and enhancing decision-making processes. Our findings\nhighlight the potential of this enhanced Retrieval-Augmented Generation system\nto transform academic exploration within data science, ultimately advancing the\nworkflow of research and innovation in the field.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.15404v1",
    "published_date": "2024-12-19 21:14:54 UTC",
    "updated_date": "2024-12-19 21:14:54 UTC"
  },
  {
    "arxiv_id": "2412.16244v2",
    "title": "The impact of behavioral diversity in multi-agent reinforcement learning",
    "authors": [
      "Matteo Bettini",
      "Ryan Kortvelesy",
      "Amanda Prorok"
    ],
    "abstract": "Many of the world's most pressing issues, such as climate change and global\npeace, require complex collective problem-solving skills. Recent studies\nindicate that diversity in individuals' behaviors is key to developing such\nskills and increasing collective performance. Yet behavioral diversity in\ncollective artificial learning is understudied, with today's machine learning\nparadigms commonly favoring homogeneous agent strategies over heterogeneous\nones, mainly due to computational considerations. In this work, we employ\ndiversity measurement and control paradigms to study the impact of behavioral\nheterogeneity in several facets of multi-agent reinforcement learning. Through\nexperiments in team play and other cooperative tasks, we show the emergence of\nunbiased behavioral roles that improve team outcomes; how behavioral diversity\nsynergizes with morphological diversity; how diverse agents are more effective\nat finding cooperative solutions in sparse reward settings; and how\nbehaviorally heterogeneous teams learn and retain latent skills to overcome\nrepeated disruptions. Overall, our results indicate that, by controlling\ndiversity, we can obtain non-trivial benefits over homogeneous training\nparadigms, demonstrating that diversity is a fundamental component of\ncollective artificial learning, an insight thus far overlooked.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.16244v2",
    "published_date": "2024-12-19 21:13:32 UTC",
    "updated_date": "2025-01-29 09:53:58 UTC"
  },
  {
    "arxiv_id": "2412.15396v2",
    "title": "Learning Visual Composition through Improved Semantic Guidance",
    "authors": [
      "Austin Stone",
      "Hagen Soltau",
      "Robert Geirhos",
      "Xi Yi",
      "Ye Xia",
      "Bingyi Cao",
      "Kaifeng Chen",
      "Abhijit Ogale",
      "Jonathon Shlens"
    ],
    "abstract": "Visual imagery does not consist of solitary objects, but instead reflects the\ncomposition of a multitude of fluid concepts. While there have been great\nadvances in visual representation learning, such advances have focused on\nbuilding better representations for a small number of discrete objects bereft\nof an understanding of how these objects are interacting. One can observe this\nlimitation in representations learned through captions or contrastive learning\n-- where the learned model treats an image essentially as a bag of words.\nSeveral works have attempted to address this limitation through the development\nof bespoke learned architectures to directly address the shortcomings in\ncompositional learning. In this work, we focus on simple, and scalable\napproaches. In particular, we demonstrate that by substantially improving\nweakly labeled data, i.e. captions, we can vastly improve the performance of\nstandard contrastive learning approaches. Previous CLIP models achieved near\nchance rate on challenging tasks probing compositional learning. However, our\nsimple approach boosts performance of CLIP substantially and surpasses all\nbespoke architectures. Furthermore, we showcase our results on a relatively new\ncaptioning benchmark derived from DOCCI. We demonstrate through a series of\nablations that a standard CLIP model trained with enhanced data may demonstrate\nimpressive performance on image retrieval tasks.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.IR"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.15396v2",
    "published_date": "2024-12-19 20:58:26 UTC",
    "updated_date": "2025-04-04 00:14:26 UTC"
  },
  {
    "arxiv_id": "2412.15388v1",
    "title": "Investigating Relational State Abstraction in Collaborative MARL",
    "authors": [
      "Sharlin Utke",
      "Jeremie Houssineau",
      "Giovanni Montana"
    ],
    "abstract": "This paper explores the impact of relational state abstraction on sample\nefficiency and performance in collaborative Multi-Agent Reinforcement Learning.\nThe proposed abstraction is based on spatial relationships in environments\nwhere direct communication between agents is not allowed, leveraging the\nubiquity of spatial reasoning in real-world multi-agent scenarios. We introduce\nMARC (Multi-Agent Relational Critic), a simple yet effective critic\narchitecture incorporating spatial relational inductive biases by transforming\nthe state into a spatial graph and processing it through a relational graph\nneural network. The performance of MARC is evaluated across six collaborative\ntasks, including a novel environment with heterogeneous agents. We conduct a\ncomprehensive empirical analysis, comparing MARC against state-of-the-art MARL\nbaselines, demonstrating improvements in both sample efficiency and asymptotic\nperformance, as well as its potential for generalization. Our findings suggest\nthat a minimal integration of spatial relational inductive biases as\nabstraction can yield substantial benefits without requiring complex designs or\ntask-specific engineering. This work provides insights into the potential of\nrelational state abstraction to address sample efficiency, a key challenge in\nMARL, offering a promising direction for developing more efficient algorithms\nin spatially complex environments.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.15388v1",
    "published_date": "2024-12-19 20:34:00 UTC",
    "updated_date": "2024-12-19 20:34:00 UTC"
  },
  {
    "arxiv_id": "2412.15386v1",
    "title": "Systematic Evaluation of Long-Context LLMs on Financial Concepts",
    "authors": [
      "Lavanya Gupta",
      "Saket Sharma",
      "Yiyun Zhao"
    ],
    "abstract": "Long-context large language models (LC LLMs) promise to increase reliability\nof LLMs in real-world tasks requiring processing and understanding of long\ninput documents. However, this ability of LC LLMs to reliably utilize their\ngrowing context windows remains under investigation. In this work, we evaluate\nthe performance of state-of-the-art GPT-4 suite of LC LLMs in solving a series\nof progressively challenging tasks, as a function of factors such as context\nlength, task difficulty, and position of key information by creating a real\nworld financial news dataset. Our findings indicate that LC LLMs exhibit\nbrittleness at longer context lengths even for simple tasks, with performance\ndeteriorating sharply as task complexity increases. At longer context lengths,\nthese state-of-the-art models experience catastrophic failures in instruction\nfollowing resulting in degenerate outputs. Our prompt ablations also reveal\nunfortunate continued sensitivity to both the placement of the task instruction\nin the context window as well as minor markdown formatting. Finally, we\nadvocate for more rigorous evaluation of LC LLMs by employing holistic metrics\nsuch as F1 (rather than recall) and reporting confidence intervals, thereby\nensuring robust and conclusive findings.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at EMNLP 2024",
    "pdf_url": "http://arxiv.org/pdf/2412.15386v1",
    "published_date": "2024-12-19 20:26:55 UTC",
    "updated_date": "2024-12-19 20:26:55 UTC"
  },
  {
    "arxiv_id": "2412.15374v1",
    "title": "Automated Root Cause Analysis System for Complex Data Products",
    "authors": [
      "Mathieu Demarne",
      "Miso Cilimdzic",
      "Tom Falkowski",
      "Timothy Johnson",
      "Jim Gramling",
      "Wei Kuang",
      "Hoobie Hou",
      "Amjad Aryan",
      "Gayatri Subramaniam",
      "Kenny Lee",
      "Manuel Mejia",
      "Lisa Liu",
      "Divya Vermareddy"
    ],
    "abstract": "We present ARCAS (Automated Root Cause Analysis System), a diagnostic\nplatform based on a Domain Specific Language (DSL) built for fast diagnostic\nimplementation and low learning curve. Arcas is composed of a constellation of\nautomated troubleshooting guides (Auto-TSGs) that can execute in parallel to\ndetect issues using product telemetry and apply mitigation in near-real-time.\nThe DSL is tailored specifically to ensure that subject matter experts can\ndeliver highly curated and relevant Auto-TSGs in a short time without having to\nunderstand how they will interact with the rest of the diagnostic platform,\nthus reducing time-to-mitigate and saving crucial engineering cycles when they\nmatter most. This contrasts with platforms like Datadog and New Relic, which\nprimarily focus on monitoring and require manual intervention for mitigation.\nARCAS uses a Large Language Model (LLM) to prioritize Auto-TSGs outputs and\ntake appropriate actions, thus suppressing the costly requirement of\nunderstanding the general behavior of the system. We explain the key concepts\nbehind ARCAS and demonstrate how it has been successfully used for multiple\nproducts across Azure Synapse Analytics and Microsoft Fabric Synapse Data\nWarehouse.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "13 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.15374v1",
    "published_date": "2024-12-19 20:10:54 UTC",
    "updated_date": "2024-12-19 20:10:54 UTC"
  },
  {
    "arxiv_id": "2412.15373v1",
    "title": "Granger Causality Detection with Kolmogorov-Arnold Networks",
    "authors": [
      "Hongyu Lin",
      "Mohan Ren",
      "Paolo Barucca",
      "Tomaso Aste"
    ],
    "abstract": "Discovering causal relationships in time series data is central in many\nscientific areas, ranging from economics to climate science. Granger causality\nis a powerful tool for causality detection. However, its original formulation\nis limited by its linear form and only recently nonlinear machine-learning\ngeneralizations have been introduced. This study contributes to the definition\nof neural Granger causality models by investigating the application of\nKolmogorov-Arnold networks (KANs) in Granger causality detection and comparing\ntheir capabilities against multilayer perceptrons (MLP). In this work, we\ndevelop a framework called Granger Causality KAN (GC-KAN) along with a tailored\ntraining approach designed specifically for Granger causality detection. We\ntest this framework on both Vector Autoregressive (VAR) models and chaotic\nLorenz-96 systems, analysing the ability of KANs to sparsify input features by\nidentifying Granger causal relationships, providing a concise yet accurate\nmodel for Granger causality detection. Our findings show the potential of KANs\nto outperform MLPs in discerning interpretable Granger causal relationships,\nparticularly for the ability of identifying sparse Granger causality patterns\nin high-dimensional settings, and more generally, the potential of AI in\ncausality discovery for the dynamical laws in physical systems.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "8 pages, 2 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2412.15373v1",
    "published_date": "2024-12-19 20:10:34 UTC",
    "updated_date": "2024-12-19 20:10:34 UTC"
  },
  {
    "arxiv_id": "2412.15363v1",
    "title": "Making Transparency Advocates: An Educational Approach Towards Better Algorithmic Transparency in Practice",
    "authors": [
      "Andrew Bell",
      "Julia Stoyanovich"
    ],
    "abstract": "Concerns about the risks and harms posed by artificial intelligence (AI) have\nresulted in significant study into algorithmic transparency, giving rise to a\nsub-field known as Explainable AI (XAI). Unfortunately, despite a decade of\ndevelopment in XAI, an existential challenge remains: progress in research has\nnot been fully translated into the actual implementation of algorithmic\ntransparency by organizations. In this work, we test an approach for addressing\nthe challenge by creating transparency advocates, or motivated individuals\nwithin organizations who drive a ground-up cultural shift towards improved\nalgorithmic transparency.\n  Over several years, we created an open-source educational workshop on\nalgorithmic transparency and advocacy. We delivered the workshop to\nprofessionals across two separate domains to improve their algorithmic\ntransparency literacy and willingness to advocate for change. In the weeks\nfollowing the workshop, participants applied what they learned, such as\nspeaking up for algorithmic transparency at an organization-wide AI strategy\nmeeting. We also make two broader observations: first, advocacy is not a\nmonolith and can be broken down into different levels. Second, individuals'\nwillingness for advocacy is affected by their professional field. For example,\nnews and media professionals may be more likely to advocate for algorithmic\ntransparency than those working at technology start-ups.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.15363v1",
    "published_date": "2024-12-19 19:49:59 UTC",
    "updated_date": "2024-12-19 19:49:59 UTC"
  },
  {
    "arxiv_id": "2412.15353v1",
    "title": "GeoPro-Net: Learning Interpretable Spatiotemporal Prediction Models through Statistically-Guided Geo-Prototyping",
    "authors": [
      "Bang An",
      "Xun Zhou",
      "Zirui Zhou",
      "Ronilo Ragodos",
      "Zenglin Xu",
      "Jun Luo"
    ],
    "abstract": "The problem of forecasting spatiotemporal events such as crimes and accidents\nis crucial to public safety and city management. Besides accuracy,\ninterpretability is also a key requirement for spatiotemporal forecasting\nmodels to justify the decisions. Interpretation of the spatiotemporal\nforecasting mechanism is, however, challenging due to the complexity of\nmulti-source spatiotemporal features, the non-intuitive nature of\nspatiotemporal patterns for non-expert users, and the presence of spatial\nheterogeneity in the data. Currently, no existing deep learning model\nintrinsically interprets the complex predictive process learned from\nmulti-source spatiotemporal features. To bridge the gap, we propose GeoPro-Net,\nan intrinsically interpretable spatiotemporal model for spatiotemporal event\nforecasting problems. GeoPro-Net introduces a novel Geo-concept convolution\noperation, which employs statistical tests to extract predictive patterns in\nthe input as Geo-concepts, and condenses the Geo-concept-encoded input through\ninterpretable channel fusion and geographic-based pooling. In addition,\nGeoPro-Net learns different sets of prototypes of concepts inherently, and\nprojects them to real-world cases for interpretation. Comprehensive experiments\nand case studies on four real-world datasets demonstrate that GeoPro-Net\nprovides better interpretability while still achieving competitive prediction\nperformance compared with state-of-the-art baselines.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.15353v1",
    "published_date": "2024-12-19 19:39:16 UTC",
    "updated_date": "2024-12-19 19:39:16 UTC"
  },
  {
    "arxiv_id": "2412.15347v1",
    "title": "Exploring Machine Learning Engineering for Object Detection and Tracking by Unmanned Aerial Vehicle (UAV)",
    "authors": [
      "Aneesha Guna",
      "Parth Ganeriwala",
      "Siddhartha Bhattacharyya"
    ],
    "abstract": "With the advancement of deep learning methods it is imperative that\nautonomous systems will increasingly become intelligent with the inclusion of\nadvanced machine learning algorithms to execute a variety of autonomous\noperations. One such task involves the design and evaluation for a subsystem of\nthe perception system for object detection and tracking. The challenge in the\ncreation of software to solve the task is in discovering the need for a\ndataset, annotation of the dataset, selection of features, integration and\nrefinement of existing algorithms, while evaluating performance metrics through\ntraining and testing. This research effort focuses on the development of a\nmachine learning pipeline emphasizing the inclusion of assurance methods with\nincreasing automation. In the process, a new dataset was created by collecting\nvideos of moving object such as Roomba vacuum cleaner, emulating search and\nrescue (SAR) for indoor environment. Individual frames were extracted from the\nvideos and labeled using a combination of manual and automated techniques. This\nannotated dataset was refined for accuracy by initially training it on YOLOv4.\nAfter the refinement of the dataset it was trained on a second YOLOv4 and a\nMask R-CNN model, which is deployed on a Parrot Mambo drone to perform\nreal-time object detection and tracking. Experimental results demonstrate the\neffectiveness of the models in accurately detecting and tracking the Roomba\nacross multiple trials, achieving an average loss of 0.1942 and 96% accuracy.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at ICMLA '24",
    "pdf_url": "http://arxiv.org/pdf/2412.15347v1",
    "published_date": "2024-12-19 19:27:31 UTC",
    "updated_date": "2024-12-19 19:27:31 UTC"
  },
  {
    "arxiv_id": "2412.15212v1",
    "title": "Scaling 4D Representations",
    "authors": [
      "João Carreira",
      "Dilara Gokay",
      "Michael King",
      "Chuhan Zhang",
      "Ignacio Rocco",
      "Aravindh Mahendran",
      "Thomas Albert Keck",
      "Joseph Heyward",
      "Skanda Koppula",
      "Etienne Pot",
      "Goker Erdogan",
      "Yana Hasson",
      "Yi Yang",
      "Klaus Greff",
      "Guillaume Le Moing",
      "Sjoerd van Steenkiste",
      "Daniel Zoran",
      "Drew A. Hudson",
      "Pedro Vélez",
      "Luisa Polanía",
      "Luke Friedman",
      "Chris Duvarney",
      "Ross Goroshin",
      "Kelsey Allen",
      "Jacob Walker",
      "Rishabh Kabra",
      "Eric Aboussouan",
      "Jennifer Sun",
      "Thomas Kipf",
      "Carl Doersch",
      "Viorica Pătrăucean",
      "Dima Damen",
      "Pauline Luc",
      "Mehdi S. M. Sajjadi",
      "Andrew Zisserman"
    ],
    "abstract": "Scaling has not yet been convincingly demonstrated for pure self-supervised\nlearning from video. However, prior work has focused evaluations on\nsemantic-related tasks $\\unicode{x2013}$ action classification, ImageNet\nclassification, etc. In this paper we focus on evaluating self-supervised\nlearning on non-semantic vision tasks that are more spatial (3D) and temporal\n(+1D = 4D), such as camera pose estimation, point and object tracking, and\ndepth estimation. We show that by learning from very large video datasets,\nmasked auto-encoding (MAE) with transformer video models actually scales,\nconsistently improving performance on these 4D tasks, as model size increases\nfrom 20M all the way to the largest by far reported self-supervised video model\n$\\unicode{x2013}$ 22B parameters. Rigorous apples-to-apples comparison with\nmany recent image and video models demonstrates the benefits of scaling 4D\nrepresentations.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.15212v1",
    "published_date": "2024-12-19 18:59:51 UTC",
    "updated_date": "2024-12-19 18:59:51 UTC"
  },
  {
    "arxiv_id": "2412.15209v1",
    "title": "PRIMA: Multi-Image Vision-Language Models for Reasoning Segmentation",
    "authors": [
      "Muntasir Wahed",
      "Kiet A. Nguyen",
      "Adheesh Sunil Juvekar",
      "Xinzhuo Li",
      "Xiaona Zhou",
      "Vedant Shah",
      "Tianjiao Yu",
      "Pinar Yanardag",
      "Ismini Lourentzou"
    ],
    "abstract": "Despite significant advancements in Large Vision-Language Models (LVLMs),\nexisting pixel-grounding models operate on single-image settings, limiting\ntheir ability to perform detailed, fine-grained comparisons across multiple\nimages. Conversely, current multi-image understanding models lack pixel-level\ngrounding. Our work addresses this gap by introducing the task of multi-image\npixel-grounded reasoning segmentation, and PRIMA, a novel LVLM that integrates\npixel-level grounding with robust multi-image reasoning capabilities to produce\ncontextually rich, pixel-grounded explanations. Central to PRIMA is an\nefficient vision module that queries fine-grained visual representations across\nmultiple images, reducing TFLOPs by $25.3\\%$. To support training and\nevaluation, we curate $M^4Seg$, a new reasoning segmentation benchmark\nconsisting of $\\sim$224K question-answer pairs that require fine-grained visual\nunderstanding across multiple images. Experimental results demonstrate PRIMA\noutperforms state-of-the-art baselines.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Project page: https://plan-lab.github.io/prima",
    "pdf_url": "http://arxiv.org/pdf/2412.15209v1",
    "published_date": "2024-12-19 18:59:44 UTC",
    "updated_date": "2024-12-19 18:59:44 UTC"
  },
  {
    "arxiv_id": "2412.15204v2",
    "title": "LongBench v2: Towards Deeper Understanding and Reasoning on Realistic Long-context Multitasks",
    "authors": [
      "Yushi Bai",
      "Shangqing Tu",
      "Jiajie Zhang",
      "Hao Peng",
      "Xiaozhi Wang",
      "Xin Lv",
      "Shulin Cao",
      "Jiazheng Xu",
      "Lei Hou",
      "Yuxiao Dong",
      "Jie Tang",
      "Juanzi Li"
    ],
    "abstract": "This paper introduces LongBench v2, a benchmark designed to assess the\nability of LLMs to handle long-context problems requiring deep understanding\nand reasoning across real-world multitasks. LongBench v2 consists of 503\nchallenging multiple-choice questions, with contexts ranging from 8k to 2M\nwords, across six major task categories: single-document QA, multi-document QA,\nlong in-context learning, long-dialogue history understanding, code repository\nunderstanding, and long structured data understanding. To ensure the breadth\nand the practicality, we collect data from nearly 100 highly educated\nindividuals with diverse professional backgrounds. We employ both automated and\nmanual review processes to maintain high quality and difficulty, resulting in\nhuman experts achieving only 53.7% accuracy under a 15-minute time constraint.\nOur evaluation reveals that the best-performing model, when directly answers\nthe questions, achieves only 50.1% accuracy. In contrast, the o1-preview model,\nwhich includes longer reasoning, achieves 57.7%, surpassing the human baseline\nby 4%. These results highlight the importance of enhanced reasoning ability and\nscaling inference-time compute to tackle the long-context challenges in\nLongBench v2. The project is available at https://longbench2.github.io.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "26 pages, 13 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.15204v2",
    "published_date": "2024-12-19 18:59:17 UTC",
    "updated_date": "2025-01-03 11:44:51 UTC"
  },
  {
    "arxiv_id": "2412.15200v1",
    "title": "DI-PCG: Diffusion-based Efficient Inverse Procedural Content Generation for High-quality 3D Asset Creation",
    "authors": [
      "Wang Zhao",
      "Yan-Pei Cao",
      "Jiale Xu",
      "Yuejiang Dong",
      "Ying Shan"
    ],
    "abstract": "Procedural Content Generation (PCG) is powerful in creating high-quality 3D\ncontents, yet controlling it to produce desired shapes is difficult and often\nrequires extensive parameter tuning. Inverse Procedural Content Generation aims\nto automatically find the best parameters under the input condition. However,\nexisting sampling-based and neural network-based methods still suffer from\nnumerous sample iterations or limited controllability. In this work, we present\nDI-PCG, a novel and efficient method for Inverse PCG from general image\nconditions. At its core is a lightweight diffusion transformer model, where PCG\nparameters are directly treated as the denoising target and the observed images\nas conditions to control parameter generation. DI-PCG is efficient and\neffective. With only 7.6M network parameters and 30 GPU hours to train, it\ndemonstrates superior performance in recovering parameters accurately, and\ngeneralizing well to in-the-wild images. Quantitative and qualitative\nexperiment results validate the effectiveness of DI-PCG in inverse PCG and\nimage-to-3D generation tasks. DI-PCG offers a promising approach for efficient\ninverse PCG and represents a valuable exploration step towards a 3D generation\npath that models how to construct a 3D asset using parametric models.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR"
    ],
    "primary_category": "cs.CV",
    "comment": "Project page: https://thuzhaowang.github.io/projects/DI-PCG/",
    "pdf_url": "http://arxiv.org/pdf/2412.15200v1",
    "published_date": "2024-12-19 18:58:46 UTC",
    "updated_date": "2024-12-19 18:58:46 UTC"
  },
  {
    "arxiv_id": "2412.15188v4",
    "title": "LMFusion: Adapting Pretrained Language Models for Multimodal Generation",
    "authors": [
      "Weijia Shi",
      "Xiaochuang Han",
      "Chunting Zhou",
      "Weixin Liang",
      "Xi Victoria Lin",
      "Luke Zettlemoyer",
      "Lili Yu"
    ],
    "abstract": "We present LMFusion, a framework for empowering pretrained text-only large\nlanguage models (LLMs) with multimodal generative capabilities, enabling them\nto understand and generate both text and images in arbitrary sequences.\nLMFusion leverages existing Llama-3's weights for processing texts\nautoregressively while introducing additional and parallel transformer modules\nfor processing images with diffusion. During training, the data from each\nmodality is routed to its dedicated modules: modality-specific feedforward\nlayers, query-key-value projections, and normalization layers process each\nmodality independently, while the shared self-attention layers allow\ninteractions across text and image features. By freezing the text-specific\nmodules and only training the image-specific modules, LMFusion preserves the\nlanguage capabilities of text-only LLMs while developing strong visual\nunderstanding and generation abilities. Compared to methods that pretrain\nmultimodal generative models from scratch, our experiments demonstrate that,\nLMFusion improves image understanding by 20% and image generation by 3.6% using\nonly 50% of the FLOPs while maintaining Llama-3's language capabilities. We\nalso demonstrate that this framework can adapt existing vision-language models\nwith multimodal generation ability. Overall, this framework not only leverages\nexisting computational investments in text-only LLMs but also enables the\nparallel development of language and vision capabilities, presenting a\npromising direction for efficient multimodal model development.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Name change: LlamaFusion to LMFusion",
    "pdf_url": "http://arxiv.org/pdf/2412.15188v4",
    "published_date": "2024-12-19 18:56:24 UTC",
    "updated_date": "2025-02-05 02:26:38 UTC"
  },
  {
    "arxiv_id": "2412.15177v1",
    "title": "Critical-Questions-of-Thought: Steering LLM reasoning with Argumentative Querying",
    "authors": [
      "Federico Castagna",
      "Isabel Sassoon",
      "Simon Parsons"
    ],
    "abstract": "Studies have underscored how, regardless of the recent breakthrough and swift\nadvances in AI research, even state-of-the-art Large Language models (LLMs)\ncontinue to struggle when performing logical and mathematical reasoning. The\nresults seem to suggest that LLMs still work as (highly advanced) data pattern\nidentifiers, scoring poorly when attempting to generalise and solve reasoning\nproblems the models have never previously seen or that are not close to samples\npresented in their training data. To address this compelling concern, this\npaper makes use of the notion of critical questions from the literature on\nargumentation theory, focusing in particular on Toulmin's model of\nargumentation. We show that employing these critical questions can improve the\nreasoning capabilities of LLMs. By probing the rationale behind the models'\nreasoning process, the LLM can assess whether some logical mistake is occurring\nand correct it before providing the final reply to the user prompt. The\nunderlying idea is drawn from the gold standard of any valid argumentative\nprocedure: the conclusion is valid if it is entailed by accepted premises. Or,\nto paraphrase such Aristotelian principle in a real-world approximation,\ncharacterised by incomplete information and presumptive logic, the conclusion\nis valid if not proved otherwise. This approach successfully steers the models'\noutput through a reasoning pipeline, resulting in better performance against\nthe baseline and its Chain-of-Thought (CoT) implementation. To this end, an\nextensive evaluation of the proposed approach on the MT-Bench Reasoning and\nMath tasks across a range of LLMs is provided.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.15177v1",
    "published_date": "2024-12-19 18:51:30 UTC",
    "updated_date": "2024-12-19 18:51:30 UTC"
  },
  {
    "arxiv_id": "2412.15166v1",
    "title": "Human-Humanoid Robots Cross-Embodiment Behavior-Skill Transfer Using Decomposed Adversarial Learning from Demonstration",
    "authors": [
      "Junjia Liu",
      "Zhuo Li",
      "Minghao Yu",
      "Zhipeng Dong",
      "Sylvain Calinon",
      "Darwin Caldwell",
      "Fei Chen"
    ],
    "abstract": "Humanoid robots are envisioned as embodied intelligent agents capable of\nperforming a wide range of human-level loco-manipulation tasks, particularly in\nscenarios requiring strenuous and repetitive labor. However, learning these\nskills is challenging due to the high degrees of freedom of humanoid robots,\nand collecting sufficient training data for humanoid is a laborious process.\nGiven the rapid introduction of new humanoid platforms, a cross-embodiment\nframework that allows generalizable skill transfer is becoming increasingly\ncritical. To address this, we propose a transferable framework that reduces the\ndata bottleneck by using a unified digital human model as a common prototype\nand bypassing the need for re-training on every new robot platform. The model\nlearns behavior primitives from human demonstrations through adversarial\nimitation, and the complex robot structures are decomposed into functional\ncomponents, each trained independently and dynamically coordinated. Task\ngeneralization is achieved through a human-object interaction graph, and skills\nare transferred to different robots via embodiment-specific kinematic motion\nretargeting and dynamic fine-tuning. Our framework is validated on five\nhumanoid robots with diverse configurations, demonstrating stable\nloco-manipulation and highlighting its effectiveness in reducing data\nrequirements and increasing the efficiency of skill transfer across platforms.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "9 pages, 8 figures. Accepted by IEEE Robotics and Automation Magazine",
    "pdf_url": "http://arxiv.org/pdf/2412.15166v1",
    "published_date": "2024-12-19 18:41:45 UTC",
    "updated_date": "2024-12-19 18:41:45 UTC"
  },
  {
    "arxiv_id": "2412.15163v1",
    "title": "Operationalising Rawlsian Ethics for Fairness in Norm-Learning Agents",
    "authors": [
      "Jessica Woodgate",
      "Paul Marshall",
      "Nirav Ajmeri"
    ],
    "abstract": "Social norms are standards of behaviour common in a society. However, when\nagents make decisions without considering how others are impacted, norms can\nemerge that lead to the subjugation of certain agents. We present RAWL-E, a\nmethod to create ethical norm-learning agents. RAWL-E agents operationalise\nmaximin, a fairness principle from Rawlsian ethics, in their decision-making\nprocesses to promote ethical norms by balancing societal well-being with\nindividual goals. We evaluate RAWL-E agents in simulated harvesting scenarios.\nWe find that norms emerging in RAWL-E agent societies enhance social welfare,\nfairness, and robustness, and yield higher minimum experience compared to those\nthat emerge in agent societies that do not implement Rawlsian ethics.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.MA",
    "comment": "14 pages, 7 figures, 8 tables (and supplementary material with\n  reproducibility and additional results), accepted at AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.15163v1",
    "published_date": "2024-12-19 18:38:13 UTC",
    "updated_date": "2024-12-19 18:38:13 UTC"
  },
  {
    "arxiv_id": "2412.15151v3",
    "title": "Language Models as Continuous Self-Evolving Data Engineers",
    "authors": [
      "Peidong Wang",
      "Ming Wang",
      "Zhiming Ma",
      "Xiaocui Yang",
      "Shi Feng",
      "Daling Wang",
      "Yifei Zhang",
      "Kaisong Song"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities on\nvarious tasks, while the further evolvement is limited to the lack of\nhigh-quality training data. In addition, traditional training approaches rely\ntoo much on expert-labeled data, setting a ceiling on the performance of LLMs.\nTo address this issue, we propose a novel paradigm named LANCE (LANguage models\nas Continuous self-Evolving data engineers) that enables LLMs to train\nthemselves by autonomously generating, cleaning, reviewing, and annotating data\nwith preference information. Our approach demonstrates that LLMs can serve as\ncontinuous self-evolving data engineers, significantly reducing the time and\ncost of the post-training data construction. Through iterative fine-tuning on\nQwen2 series models, we validate the effectiveness of LANCE across various\ntasks, showing that it can maintain high-quality data generation and\ncontinuously improve model performance. Across multiple benchmark dimensions,\nLANCE results in an average score enhancement of 3.64 for Qwen2-7B and 1.75 for\nQwen2-7B-Instruct. This training paradigm with autonomous data construction not\nonly reduces the reliance on human experts or external models but also ensures\nthat the data aligns with human preferences, paving the way for the development\nof future superintelligent systems that can exceed human capabilities. Codes\nare available at: https://github.com/Control-derek/LANCE.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.15151v3",
    "published_date": "2024-12-19 18:28:41 UTC",
    "updated_date": "2025-02-13 11:37:45 UTC"
  },
  {
    "arxiv_id": "2412.15150v1",
    "title": "Leveraging Color Channel Independence for Improved Unsupervised Object Detection",
    "authors": [
      "Bastian Jäckl",
      "Yannick Metz",
      "Udo Schlegel",
      "Daniel A. Keim",
      "Maximilian T. Fischer"
    ],
    "abstract": "Object-centric architectures can learn to extract distinct object\nrepresentations from visual scenes, enabling downstream applications on the\nobject level. Similarly to autoencoder-based image models, object-centric\napproaches have been trained on the unsupervised reconstruction loss of images\nencoded by RGB color spaces. In our work, we challenge the common assumption\nthat RGB images are the optimal color space for unsupervised learning in\ncomputer vision. We discuss conceptually and empirically that other color\nspaces, such as HSV, bear essential characteristics for object-centric\nrepresentation learning, like robustness to lighting conditions. We further\nshow that models improve when requiring them to predict additional color\nchannels. Specifically, we propose to transform the predicted targets to the\nRGB-S space, which extends RGB with HSV's saturation component and leads to\nmarkedly better reconstruction and disentanglement for five common evaluation\ndatasets. The use of composite color spaces can be implemented with basically\nno computational overhead, is agnostic of the models' architecture, and is\nuniversally applicable across a wide range of visual computing tasks and\ntraining types. The findings of our approach encourage additional\ninvestigations in computer vision tasks beyond object-centric learning.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "I.4.8; I.2.10"
    ],
    "primary_category": "cs.CV",
    "comment": "38 pages incl. references, 16 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.15150v1",
    "published_date": "2024-12-19 18:28:37 UTC",
    "updated_date": "2024-12-19 18:28:37 UTC"
  },
  {
    "arxiv_id": "2412.15135v3",
    "title": "Probabilistic Strategy Logic with Degrees of Observability",
    "authors": [
      "Chunyan Mu",
      "Nima Motamed",
      "Natasha Alechina",
      "Brian Logan"
    ],
    "abstract": "There has been considerable work on reasoning about the strategic ability of\nagents under imperfect information. However, existing logics such as\nProbabilistic Strategy Logic are unable to express properties relating to\ninformation transparency. Information transparency concerns the extent to which\nagents' actions and behaviours are observable by other agents. Reasoning about\ninformation transparency is useful in many domains including security, privacy,\nand decision-making. In this paper, we present a formal framework for reasoning\nabout information transparency properties in stochastic multi-agent systems. We\nextend Probabilistic Strategy Logic with new observability operators that\ncapture the degree of observability of temporal properties by agents. We show\nthat the model checking problem for the resulting logic is decidable.",
    "categories": [
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.15135v3",
    "published_date": "2024-12-19 18:17:04 UTC",
    "updated_date": "2025-01-06 03:35:50 UTC"
  },
  {
    "arxiv_id": "2412.15129v1",
    "title": "Jet: A Modern Transformer-Based Normalizing Flow",
    "authors": [
      "Alexander Kolesnikov",
      "André Susano Pinto",
      "Michael Tschannen"
    ],
    "abstract": "In the past, normalizing generative flows have emerged as a promising class\nof generative models for natural images. This type of model has many modeling\nadvantages: the ability to efficiently compute log-likelihood of the input\ndata, fast generation and simple overall structure. Normalizing flows remained\na topic of active research but later fell out of favor, as visual quality of\nthe samples was not competitive with other model classes, such as GANs,\nVQ-VAE-based approaches or diffusion models. In this paper we revisit the\ndesign of the coupling-based normalizing flow models by carefully ablating\nprior design choices and using computational blocks based on the Vision\nTransformer architecture, not convolutional neural networks. As a result, we\nachieve state-of-the-art quantitative and qualitative performance with a much\nsimpler architecture. While the overall visual quality is still behind the\ncurrent state-of-the-art models, we argue that strong normalizing flow models\ncan help advancing research frontier by serving as building components of more\npowerful generative models.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.15129v1",
    "published_date": "2024-12-19 18:09:42 UTC",
    "updated_date": "2024-12-19 18:09:42 UTC"
  },
  {
    "arxiv_id": "2412.15127v1",
    "title": "Adaptive Pruning for Large Language Models with Structural Importance Awareness",
    "authors": [
      "Haotian Zheng",
      "Jinke Ren",
      "Yushan Sun",
      "Ruichen Zhang",
      "Wenbo Zhang",
      "Zhen Li",
      "Dusit Niyato",
      "Shuguang Cui",
      "Yatong Han"
    ],
    "abstract": "The recent advancements in large language models (LLMs) have significantly\nimproved language understanding and generation capabilities. However, it is\ndifficult to deploy LLMs on resource-constrained edge devices due to their high\ncomputational and storage resource demands. To address this issue, we propose a\nnovel LLM model pruning method, namely structurally-aware adaptive pruning\n(SAAP), to significantly reduce the computational and memory costs while\nmaintaining model performance. We first define an adaptive importance fusion\nmetric to evaluate the importance of all coupled structures in LLMs by\nconsidering their homoscedastic uncertainty. Then, we rank the importance of\nall modules to determine the specific layers that should be pruned to meet\nparticular performance requirements. Furthermore, we develop a new group\nfine-tuning strategy to improve the inference efficiency of LLMs. Finally, we\nevaluate the proposed SAAP method on multiple LLMs across two common tasks,\ni.e., zero-shot classification and text generation. Experimental results show\nthat our SAAP method outperforms several state-of-the-art baseline methods,\nachieving 2.17%, 2.37%, and 2.39% accuracy gains on LLaMA-7B, Vicuna-7B, and\nLLaMA-13B. Additionally, SAAP improves the token generation speed by 5%,\nshowcasing its practical advantages in resource-constrained scenarios.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "12 pages, 6 figures, 12 tables",
    "pdf_url": "http://arxiv.org/pdf/2412.15127v1",
    "published_date": "2024-12-19 18:08:04 UTC",
    "updated_date": "2024-12-19 18:08:04 UTC"
  },
  {
    "arxiv_id": "2412.15118v1",
    "title": "Outcome-Refining Process Supervision for Code Generation",
    "authors": [
      "Zhuohao Yu",
      "Weizheng Gu",
      "Yidong Wang",
      "Zhengran Zeng",
      "Jindong Wang",
      "Wei Ye",
      "Shikun Zhang"
    ],
    "abstract": "Large Language Models have demonstrated remarkable capabilities in code\ngeneration, yet they often struggle with complex programming tasks that require\ndeep algorithmic reasoning. While process supervision through learned reward\nmodels shows promise in guiding reasoning steps, it requires expensive training\ndata and suffers from unreliable evaluation. We propose Outcome-Refining\nProcess Supervision, a novel paradigm that treats outcome refinement itself as\nthe process to be supervised. Our framework leverages concrete execution\nsignals to ground the supervision of reasoning steps, while using\ntree-structured exploration to maintain multiple solution trajectories\nsimultaneously. Experiments demonstrate that our approach enables even smaller\nmodels to achieve high success accuracy and performance metrics on competitive\nprogramming tasks, creates more reliable verification than traditional reward\nmodels without requiring training PRMs. Our approach achieves significant\nimprovements across 5 models and 3 datasets: an average of 26.9% increase in\ncorrectness and 42.2% in efficiency. The results suggest that providing\nstructured reasoning space with concrete verification signals is crucial for\nsolving complex programming tasks. We open-source all our code and data at:\nhttps://github.com/zhuohaoyu/ORPS",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.SE"
    ],
    "primary_category": "cs.CL",
    "comment": "18 pages, 5 figures, Code: https://github.com/zhuohaoyu/ORPS",
    "pdf_url": "http://arxiv.org/pdf/2412.15118v1",
    "published_date": "2024-12-19 17:59:42 UTC",
    "updated_date": "2024-12-19 17:59:42 UTC"
  },
  {
    "arxiv_id": "2412.15114v1",
    "title": "Towards Friendly AI: A Comprehensive Review and New Perspectives on Human-AI Alignment",
    "authors": [
      "Qiyang Sun",
      "Yupei Li",
      "Emran Alturki",
      "Sunil Munthumoduku Krishna Murthy",
      "Björn W. Schuller"
    ],
    "abstract": "As Artificial Intelligence (AI) continues to advance rapidly, Friendly AI\n(FAI) has been proposed to advocate for more equitable and fair development of\nAI. Despite its importance, there is a lack of comprehensive reviews examining\nFAI from an ethical perspective, as well as limited discussion on its potential\napplications and future directions. This paper addresses these gaps by\nproviding a thorough review of FAI, focusing on theoretical perspectives both\nfor and against its development, and presenting a formal definition in a clear\nand accessible format. Key applications are discussed from the perspectives of\neXplainable AI (XAI), privacy, fairness and affective computing (AC).\nAdditionally, the paper identifies challenges in current technological\nadvancements and explores future research avenues. The findings emphasise the\nsignificance of developing FAI and advocate for its continued advancement to\nensure ethical and beneficial AI development.",
    "categories": [
      "cs.AI",
      "cs.CY",
      "I.2.0; K.4.0"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.15114v1",
    "published_date": "2024-12-19 17:56:08 UTC",
    "updated_date": "2024-12-19 17:56:08 UTC"
  },
  {
    "arxiv_id": "2412.15113v1",
    "title": "Associative memory inspires improvements for in-context learning using a novel attention residual stream architecture",
    "authors": [
      "Thomas F Burns",
      "Tomoki Fukai",
      "Christopher J Earls"
    ],
    "abstract": "Large language models (LLMs) demonstrate an impressive ability to utilise\ninformation within the context of their input sequences to appropriately\nrespond to data unseen by the LLM during its training procedure. This ability\nis known as in-context learning (ICL). Humans and non-human animals demonstrate\nsimilar abilities, however their neural architectures differ substantially from\nLLMs. Despite this, a critical component within LLMs, the attention mechanism,\nresembles modern associative memory models, widely used in and influenced by\nthe computational neuroscience community to model biological memory systems.\nUsing this connection, we introduce an associative memory model capable of\nperforming ICL. We use this as inspiration for a novel residual stream\narchitecture which allows information to directly flow between attention heads.\nWe test this architecture during training within a two-layer Transformer and\nshow its ICL abilities manifest more quickly than without this modification. We\nthen apply our architecture in small language models with 8 million parameters,\nfocusing on attention head values, with results also indicating improved ICL\nperformance at this larger and more naturalistic scale.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.CL",
      "92B20, 68T01, 68T37, 68T50",
      "I.2; I.5; I.7; J.2; J.3"
    ],
    "primary_category": "cs.NE",
    "comment": "18 pages, 6 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2412.15113v1",
    "published_date": "2024-12-19 17:55:42 UTC",
    "updated_date": "2024-12-19 17:55:42 UTC"
  },
  {
    "arxiv_id": "2412.15105v1",
    "title": "Exploiting sparse structures and synergy designs to advance situational awareness of electrical power grid",
    "authors": [
      "Shimiao Li"
    ],
    "abstract": "The growing threats of uncertainties, anomalies, and cyberattacks on power\ngrids are driving a critical need to advance situational awareness which allows\nsystem operators to form a complete and accurate picture of the present and\nfuture state. Simulation and estimation are foundational tools in this process.\nHowever, existing tools lack the robustness and efficiency required to achieve\nthe level of situational awareness needed for the ever-evolving threat\nlandscape. Industry-standard (steady-state) simulators are not robust to\nblackouts, often leading to non-converging or non-actionable results.\nEstimation tools lack robustness to anomalous data, returning erroneous system\nstates. Efficiency is the other major concern as nonlinearities and scalability\nissues make large systems slow to converge.\n  This thesis addresses robustness and efficiency gaps through a dual-fold\ncontribution. We first address the inherent limitations in the existing\nphysics-based and data-driven worlds; and then transcend the boundaries of\nconventional algorithmic design in the direction of a new paradigm --\nPhysics-ML Synergy -- which integrates the strengths of the two worlds. Our\napproaches are built on circuit formulation which provides a unified framework\nthat applies to both transmission and distribution. Sparse optimization acts as\nthe key enabler to make these tools intrinsically robust and immune to random\nthreats, pinpointing dominant sources of (random) blackouts and data errors.\nFurther, we explore sparsity-exploiting optimizations to develop lightweight ML\nmodels whose prediction and detection capabilities are a complement to\nphysics-based tools; and whose lightweight designs advance generalization and\nscalability. Finally, Physics-ML Synergy brings robustness and efficiency\nfurther against targeted cyberthreats, by interconnecting our physics-based\ntools with lightweight ML.",
    "categories": [
      "eess.SP",
      "cs.AI"
    ],
    "primary_category": "eess.SP",
    "comment": "PhD thesis",
    "pdf_url": "http://arxiv.org/pdf/2412.15105v1",
    "published_date": "2024-12-19 17:51:43 UTC",
    "updated_date": "2024-12-19 17:51:43 UTC"
  },
  {
    "arxiv_id": "2501.10390v1",
    "title": "Towards an Environmental Ethics of Artificial Intelligence",
    "authors": [
      "Nynke van Uffelen",
      "Lode Lauwaert",
      "Mark Coeckelbergh",
      "Olya Kudina"
    ],
    "abstract": "In recent years, much research has been dedicated to uncovering the\nenvironmental impact of Artificial Intelligence (AI), showing that training and\ndeploying AI systems require large amounts of energy and resources, and the\noutcomes of AI may lead to decisions and actions that may negatively impact the\nenvironment. This new knowledge raises new ethical questions, such as: When is\nit (un)justifiable to develop an AI system, and how to make design choices,\nconsidering its environmental impact? However, so far, the environmental impact\nof AI has largely escaped ethical scrutiny, as AI ethics tends to focus\nstrongly on themes such as transparency, privacy, safety, responsibility, and\nbias. Considering the environmental impact of AI from an ethical perspective\nexpands the scope of AI ethics beyond an anthropocentric focus towards\nincluding more-than-human actors such as animals and ecosystems. This paper\nexplores the ethical implications of the environmental impact of AI for\ndesigning AI systems by drawing on environmental justice literature, in which\nthree categories of justice are distinguished, referring to three elements that\ncan be unjust: the distribution of benefits and burdens (distributive justice),\ndecision-making procedures (procedural justice), and institutionalized social\nnorms (justice as recognition). Based on these tenets of justice, we outline\ncriteria for developing environmentally just AI systems, given their ecological\nimpact.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.10390v1",
    "published_date": "2024-12-19 17:48:54 UTC",
    "updated_date": "2024-12-19 17:48:54 UTC"
  },
  {
    "arxiv_id": "2412.15098v1",
    "title": "A Cross-Domain Study of the Use of Persuasion Techniques in Online Disinformation",
    "authors": [
      "João A. Leite",
      "Olesya Razuvayevskaya",
      "Carolina Scarton",
      "Kalina Bontcheva"
    ],
    "abstract": "Disinformation, irrespective of domain or language, aims to deceive or\nmanipulate public opinion, typically through employing advanced persuasion\ntechniques. Qualitative and quantitative research on the weaponisation of\npersuasion techniques in disinformation has been mostly topic-specific (e.g.,\nCOVID-19) with limited cross-domain studies, resulting in a lack of\ncomprehensive understanding of these strategies. This study employs a\nstate-of-the-art persuasion technique classifier to conduct a large-scale,\nmulti-domain analysis of the role of 16 persuasion techniques in disinformation\nnarratives. It shows how different persuasion techniques are employed\ndisproportionately in different disinformation domains. We also include a\ndetailed case study on climate change disinformation, highlighting how\nlinguistic, psychological, and cultural factors shape the adaptation of\npersuasion strategies to fit unique thematic contexts.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.15098v1",
    "published_date": "2024-12-19 17:46:13 UTC",
    "updated_date": "2024-12-19 17:46:13 UTC"
  },
  {
    "arxiv_id": "2412.15095v1",
    "title": "A Full Transformer-based Framework for Automatic Pain Estimation using Videos",
    "authors": [
      "Stefanos Gkikas",
      "Manolis Tsiknakis"
    ],
    "abstract": "The automatic estimation of pain is essential in designing an optimal pain\nmanagement system offering reliable assessment and reducing the suffering of\npatients. In this study, we present a novel full transformer-based framework\nconsisting of a Transformer in Transformer (TNT) model and a Transformer\nleveraging cross-attention and self-attention blocks. Elaborating on videos\nfrom the BioVid database, we demonstrate state-of-the-art performances, showing\nthe efficacy, efficiency, and generalization capability across all the primary\npain estimation tasks.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.15095v1",
    "published_date": "2024-12-19 17:45:08 UTC",
    "updated_date": "2024-12-19 17:45:08 UTC"
  },
  {
    "arxiv_id": "2412.15086v1",
    "title": "Learning Disentangled Equivariant Representation for Explicitly Controllable 3D Molecule Generation",
    "authors": [
      "Haoran Liu",
      "Youzhi Luo",
      "Tianxiao Li",
      "James Caverlee",
      "Martin Renqiang Min"
    ],
    "abstract": "We consider the conditional generation of 3D drug-like molecules with\n\\textit{explicit control} over molecular properties such as drug-like\nproperties (e.g., Quantitative Estimate of Druglikeness or Synthetic\nAccessibility score) and effectively binding to specific protein sites. To\ntackle this problem, we propose an E(3)-equivariant Wasserstein autoencoder and\nfactorize the latent space of our generative model into two disentangled\naspects: molecular properties and the remaining structural context of 3D\nmolecules. Our model ensures explicit control over these molecular attributes\nwhile maintaining equivariance of coordinate representation and invariance of\ndata likelihood. Furthermore, we introduce a novel alignment-based coordinate\nloss to adapt equivariant networks for auto-regressive de-novo 3D molecule\ngeneration from scratch. Extensive experiments validate our model's\neffectiveness on property-guided and context-guided molecule generation, both\nfor de-novo 3D molecule design and structure-based drug discovery against\nprotein targets.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.15086v1",
    "published_date": "2024-12-19 17:33:56 UTC",
    "updated_date": "2024-12-19 17:33:56 UTC"
  },
  {
    "arxiv_id": "2412.15084v2",
    "title": "AceMath: Advancing Frontier Math Reasoning with Post-Training and Reward Modeling",
    "authors": [
      "Zihan Liu",
      "Yang Chen",
      "Mohammad Shoeybi",
      "Bryan Catanzaro",
      "Wei Ping"
    ],
    "abstract": "In this paper, we introduce AceMath, a suite of frontier math models that\nexcel in solving complex math problems, along with highly effective reward\nmodels capable of evaluating generated solutions and reliably identifying the\ncorrect ones. To develop the instruction-tuned math models, we propose a\nsupervised fine-tuning (SFT) process that first achieves competitive\nperformance across general domains, followed by targeted fine-tuning for the\nmath domain using a carefully curated set of prompts and synthetically\ngenerated responses. The resulting model, AceMath-72B-Instruct greatly\noutperforms Qwen2.5-Math-72B-Instruct, GPT-4o and Claude-3.5 Sonnet. To develop\nmath-specialized reward model, we first construct AceMath-RewardBench, a\ncomprehensive and robust benchmark for evaluating math reward models across\ndiverse problems and difficulty levels. After that, we present a systematic\napproach to build our math reward models. The resulting model, AceMath-72B-RM,\nconsistently outperforms state-of-the-art reward models. Furthermore, when\ncombining AceMath-72B-Instruct with AceMath-72B-RM, we achieve the highest\naverage rm@8 score across the math reasoning benchmarks. We release model\nweights, training data, and evaluation benchmarks at:\nhttps://research.nvidia.com/labs/adlr/acemath",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.15084v2",
    "published_date": "2024-12-19 17:29:44 UTC",
    "updated_date": "2025-01-17 07:12:55 UTC"
  },
  {
    "arxiv_id": "2412.15314v1",
    "title": "Eliciting Causal Abilities in Large Language Models for Reasoning Tasks",
    "authors": [
      "Yajing Wang",
      "Zongwei Luo",
      "Jingzhe Wang",
      "Zhanke Zhou",
      "Yongqiang Chen",
      "Bo Han"
    ],
    "abstract": "Prompt optimization automatically refines prompting expressions, unlocking\nthe full potential of LLMs in downstream tasks. However, current prompt\noptimization methods are costly to train and lack sufficient interpretability.\nThis paper proposes enhancing LLMs' reasoning performance by eliciting their\ncausal inference ability from prompting instructions to correct answers.\nSpecifically, we introduce the Self-Causal Instruction Enhancement (SCIE)\nmethod, which enables LLMs to generate high-quality, low-quantity observational\ndata, then estimates the causal effect based on these data, and ultimately\ngenerates instructions with the optimized causal effect. In SCIE, the\ninstructions are treated as the treatment, and textual features are used to\nprocess natural language, establishing causal relationships through treatments\nbetween instructions and downstream tasks. Additionally, we propose applying\nObject-Relational (OR) principles, where the uncovered causal relationships are\ntreated as the inheritable class across task objects, ensuring low-cost\nreusability. Extensive experiments demonstrate that our method effectively\ngenerates instructions that enhance reasoning performance with reduced training\ncost of prompts, leveraging interpretable textual features to provide\nactionable insights.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.15314v1",
    "published_date": "2024-12-19 17:03:02 UTC",
    "updated_date": "2024-12-19 17:03:02 UTC"
  },
  {
    "arxiv_id": "2412.15054v1",
    "title": "GIRAFE: Glottal Imaging Dataset for Advanced Segmentation, Analysis, and Facilitative Playbacks Evaluation",
    "authors": [
      "G. Andrade-Miranda",
      "K. Chatzipapas",
      "J. D. Arias-Londoño",
      "J. I. Godino-Llorente"
    ],
    "abstract": "The advances in the development of Facilitative Playbacks extracted from\nHigh-Speed videoendoscopic sequences of the vocal folds are hindered by a\nnotable lack of publicly available datasets annotated with the semantic\nsegmentations corresponding to the area of the glottal gap. This fact also\nlimits the reproducibility and further exploration of existing research in this\nfield.\n  To address this gap, GIRAFE is a data repository designed to facilitate the\ndevelopment of advanced techniques for the semantic segmentation, analysis, and\nfast evaluation of High-Speed videoendoscopic sequences of the vocal folds. The\nrepository includes 65 high-speed videoendoscopic recordings from a cohort of\n50 patients (30 female, 20 male). The dataset comprises 15 recordings from\nhealthy controls, 26 from patients with diagnosed voice disorders, and 24 with\nan unknown health condition. All of them were manually annotated by an expert,\nincluding the masks corresponding to the semantic segmentation of the glottal\ngap. The repository is also complemented with the automatic segmentation of the\nglottal area using different state-of-the-art approaches.\n  This data set has already supported several studies, which demonstrates its\nusefulness for the development of new glottal gap segmentation algorithms from\nHigh-Speed-Videoendoscopic sequences to improve or create new Facilitative\nPlaybacks. Despite these advances and others in the field, the broader\nchallenge of performing an accurate and completely automatic semantic\nsegmentation method of the glottal area remains open.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CV",
    "comment": "18 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.15054v1",
    "published_date": "2024-12-19 17:02:03 UTC",
    "updated_date": "2024-12-19 17:02:03 UTC"
  },
  {
    "arxiv_id": "2412.16241v1",
    "title": "Agents Are Not Enough",
    "authors": [
      "Chirag Shah",
      "Ryen W. White"
    ],
    "abstract": "In the midst of the growing integration of Artificial Intelligence (AI) into\nvarious aspects of our lives, agents are experiencing a resurgence. These\nautonomous programs that act on behalf of humans are neither new nor exclusive\nto the mainstream AI movement. By exploring past incarnations of agents, we can\nunderstand what has been done previously, what worked, and more importantly,\nwhat did not pan out and why. This understanding lets us to examine what\ndistinguishes the current focus on agents. While generative AI is appealing,\nthis technology alone is insufficient to make new generations of agents more\nsuccessful. To make the current wave of agents effective and sustainable, we\nenvision an ecosystem that includes not only agents but also Sims, which\nrepresent user preferences and behaviors, as well as Assistants, which directly\ninteract with the user and coordinate the execution of user tasks with the help\nof the agents.",
    "categories": [
      "cs.AI",
      "cs.HC",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.16241v1",
    "published_date": "2024-12-19 16:54:17 UTC",
    "updated_date": "2024-12-19 16:54:17 UTC"
  },
  {
    "arxiv_id": "2412.15047v1",
    "title": "Measuring, Modeling, and Helping People Account for Privacy Risks in Online Self-Disclosures with AI",
    "authors": [
      "Isadora Krsek",
      "Anubha Kabra",
      "Yao Dou",
      "Tarek Naous",
      "Laura A. Dabbish",
      "Alan Ritter",
      "Wei Xu",
      "Sauvik Das"
    ],
    "abstract": "In pseudonymous online fora like Reddit, the benefits of self-disclosure are\noften apparent to users (e.g., I can vent about my in-laws to understanding\nstrangers), but the privacy risks are more abstract (e.g., will my partner be\nable to tell that this is me?). Prior work has sought to develop natural\nlanguage processing (NLP) tools that help users identify potentially risky\nself-disclosures in their text, but none have been designed for or evaluated\nwith the users they hope to protect. Absent this assessment, these tools will\nbe limited by the social-technical gap: users need assistive tools that help\nthem make informed decisions, not paternalistic tools that tell them to avoid\nself-disclosure altogether. To bridge this gap, we conducted a study with N =\n21 Reddit users; we had them use a state-of-the-art NLP disclosure detection\nmodel on two of their authored posts and asked them questions to understand if\nand how the model helped, where it fell short, and how it could be improved to\nhelp them make more informed decisions. Despite its imperfections, users\nresponded positively to the model and highlighted its use as a tool that can\nhelp them catch mistakes, inform them of risks they were unaware of, and\nencourage self-reflection. However, our work also shows how, to be useful and\nusable, AI for supporting privacy decision-making must account for posting\ncontext, disclosure norms, and users' lived threat models, and provide\nexplanations that help contextualize detected risks.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "31 pages, 5 figues, Accepted for publication at CSCW 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.15047v1",
    "published_date": "2024-12-19 16:53:40 UTC",
    "updated_date": "2024-12-19 16:53:40 UTC"
  },
  {
    "arxiv_id": "2412.15004v3",
    "title": "From Vulnerabilities to Remediation: A Systematic Literature Review of LLMs in Code Security",
    "authors": [
      "Enna Basic",
      "Alberto Giaretta"
    ],
    "abstract": "Large Language Models (LLMs) have emerged as powerful tools for automating\nvarious programming tasks, including security-related ones, such as detecting\nand fixing vulnerabilities. Despite their promising capabilities, when required\nto produce or modify pre-existing code, LLMs could introduce vulnerabilities\nunbeknown to the programmer. When analyzing code, they could miss clear\nvulnerabilities or signal nonexistent ones. In this Systematic Literature\nReview (SLR), we aim to investigate both the security benefits and potential\ndrawbacks of using LLMs for a variety of code-related tasks. In particular,\nfirst we focus on the types of vulnerabilities that could be introduced by\nLLMs, when used for producing code. Second, we analyze the capabilities of LLMs\nto detect and fix vulnerabilities, in any given code, and how the prompting\nstrategy of choice impacts their performance in these two tasks. Last, we\nprovide an in-depth analysis on how data poisoning attacks on LLMs can impact\nperformance in the aforementioned tasks.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.15004v3",
    "published_date": "2024-12-19 16:20:22 UTC",
    "updated_date": "2025-04-14 10:36:33 UTC"
  },
  {
    "arxiv_id": "2412.14995v1",
    "title": "HSEvo: Elevating Automatic Heuristic Design with Diversity-Driven Harmony Search and Genetic Algorithm Using LLMs",
    "authors": [
      "Pham Vu Tuan Dat",
      "Long Doan",
      "Huynh Thi Thanh Binh"
    ],
    "abstract": "Automatic Heuristic Design (AHD) is an active research area due to its\nutility in solving complex search and NP-hard combinatorial optimization\nproblems in the real world. The recent advancements in Large Language Models\n(LLMs) introduce new possibilities by coupling LLMs with evolutionary\ncomputation to automatically generate heuristics, known as LLM-based\nEvolutionary Program Search (LLM-EPS). While previous LLM-EPS studies obtained\ngreat performance on various tasks, there is still a gap in understanding the\nproperties of heuristic search spaces and achieving a balance between\nexploration and exploitation, which is a critical factor in large heuristic\nsearch spaces. In this study, we address this gap by proposing two diversity\nmeasurement metrics and perform an analysis on previous LLM-EPS approaches,\nincluding FunSearch, EoH, and ReEvo. Results on black-box AHD problems reveal\nthat while EoH demonstrates higher diversity than FunSearch and ReEvo, its\nobjective score is unstable. Conversely, ReEvo's reflection mechanism yields\ngood objective scores but fails to optimize diversity effectively. With this\nfinding in mind, we introduce HSEvo, an adaptive LLM-EPS framework that\nmaintains a balance between diversity and convergence with a harmony search\nalgorithm. Through experimentation, we find that HSEvo achieved high diversity\nindices and good objective scores while remaining cost-effective. These results\nunderscore the importance of balancing exploration and exploitation and\nunderstanding heuristic search spaces in designing frameworks in LLM-EPS.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "18 pages, 12 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.14995v1",
    "published_date": "2024-12-19 16:07:00 UTC",
    "updated_date": "2024-12-19 16:07:00 UTC"
  },
  {
    "arxiv_id": "2412.14965v2",
    "title": "Movie2Story: A framework for understanding videos and telling stories in the form of novel text",
    "authors": [
      "Kangning Li",
      "Zheyang Jia",
      "Anyu Ying"
    ],
    "abstract": "In recent years, large-scale models have achieved significant advancements,\naccompanied by the emergence of numerous high-quality benchmarks for evaluating\nvarious aspects of their comprehension abilities. However, most existing\nbenchmarks primarily focus on spatial understanding in static image tasks.\nWhile some benchmarks extend evaluations to temporal tasks, they fall short in\nassessing text generation under complex contexts involving long videos and rich\nauxiliary information. To address this limitation, we propose a novel\nbenchmark: the Multi-modal Story Generation Benchmark (MSBench), designed to\nevaluate text generation capabilities in scenarios enriched with auxiliary\ninformation. Our work introduces an innovative automatic dataset generation\nmethod to ensure the availability of accurate auxiliary information. On one\nhand, we leverage existing datasets and apply automated processes to generate\nnew evaluation datasets, significantly reducing manual efforts. On the other\nhand, we refine auxiliary data through systematic filtering and utilize\nstate-of-the-art models to ensure the fairness and accuracy of the ground-truth\ndatasets. Our experiments reveal that current Multi-modal Large Language Models\n(MLLMs) perform suboptimally under the proposed evaluation metrics,\nhighlighting significant gaps in their capabilities. To address these\nchallenges, we propose a novel model architecture and methodology to better\nhandle the overall process, demonstrating improvements on our benchmark.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.14965v2",
    "published_date": "2024-12-19 15:44:04 UTC",
    "updated_date": "2025-01-11 14:08:22 UTC"
  },
  {
    "arxiv_id": "2412.14950v1",
    "title": "Generalizing Constraint Models in Constraint Acquisition",
    "authors": [
      "Dimos Tsouros",
      "Senne Berden",
      "Steven Prestwich",
      "Tias Guns"
    ],
    "abstract": "Constraint Acquisition (CA) aims to widen the use of constraint programming\nby assisting users in the modeling process. However, most CA methods suffer\nfrom a significant drawback: they learn a single set of individual constraints\nfor a specific problem instance, but cannot generalize these constraints to the\nparameterized constraint specifications of the problem. In this paper, we\naddress this limitation by proposing GenCon, a novel approach to learn\nparameterized constraint models capable of modeling varying instances of the\nsame problem. To achieve this generalization, we make use of statistical\nlearning techniques at the level of individual constraints. Specifically, we\npropose to train a classifier to predict, for any possible constraint and\nparameterization, whether the constraint belongs to the problem. We then show\nhow, for some classes of classifiers, we can extract decision rules to\nconstruct interpretable constraint specifications. This enables the generation\nof ground constraints for any parameter instantiation. Additionally, we present\na generate-and-test approach that can be used with any classifier, to generate\nthe ground constraints on the fly. Our empirical results demonstrate that our\napproach achieves high accuracy and is robust to noise in the input instances.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.14950v1",
    "published_date": "2024-12-19 15:31:29 UTC",
    "updated_date": "2024-12-19 15:31:29 UTC"
  },
  {
    "arxiv_id": "2412.14933v1",
    "title": "Cirbo: A New Tool for Boolean Circuit Analysis and Synthesis",
    "authors": [
      "Daniil Averkov",
      "Tatiana Belova",
      "Gregory Emdin",
      "Mikhail Goncharov",
      "Viktoriia Krivogornitsyna",
      "Alexander S. Kulikov",
      "Fedor Kurmazov",
      "Daniil Levtsov",
      "Georgie Levtsov",
      "Vsevolod Vaskin",
      "Aleksey Vorobiev"
    ],
    "abstract": "We present an open-source tool for manipulating Boolean circuits. It\nimplements efficient algorithms, both existing and novel, for a rich variety of\nfrequently used circuit tasks such as satisfiability, synthesis, and\nminimization. We tested the tool on a wide range of practically relevant\ncircuits (computing, in particular, symmetric and arithmetic functions) that\nhave been optimized intensively by the community for the last three years. The\ntool helped us to win the IWLS 2024 Programming Contest. In 2023, it was Google\nDeepMind who took the first place in the competition. We were able to reduce\nthe size of the best circuits from 2023 by 12\\% on average, whereas for some\nindividual circuits, our size reduction was as large as 83\\%.",
    "categories": [
      "cs.LO",
      "cs.AI"
    ],
    "primary_category": "cs.LO",
    "comment": "To appear in AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.14933v1",
    "published_date": "2024-12-19 15:10:31 UTC",
    "updated_date": "2024-12-19 15:10:31 UTC"
  },
  {
    "arxiv_id": "2412.15310v1",
    "title": "MRWeb: An Exploration of Generating Multi-Page Resource-Aware Web Code from UI Designs",
    "authors": [
      "Yuxuan Wan",
      "Yi Dong",
      "Jingyu Xiao",
      "Yintong Huo",
      "Wenxuan Wang",
      "Michael R. Lyu"
    ],
    "abstract": "Multi-page websites dominate modern web development. However, existing\ndesign-to-code methods rely on simplified assumptions, limiting to single-page,\nself-contained webpages without external resource connection. To address this\ngap, we introduce the Multi-Page Resource-Aware Webpage (MRWeb) generation\ntask, which transforms UI designs into multi-page, functional web UIs with\ninternal/external navigation, image loading, and backend routing. We propose a\nnovel resource list data structure to track resources, links, and design\ncomponents. Our study applies existing methods to the MRWeb problem using a\nnewly curated dataset of 500 websites (300 synthetic, 200 real-world).\nSpecifically, we identify the best metric to evaluate the similarity of the web\nUI, assess the impact of the resource list on MRWeb generation, analyze MLLM\nlimitations, and evaluate the effectiveness of the MRWeb tool in real-world\nworkflows. The results show that resource lists boost navigation functionality\nfrom 0% to 66%-80% while facilitating visual similarity. Our proposed metrics\nand evaluation framework provide new insights into MLLM performance on MRWeb\ntasks. We release the MRWeb tool, dataset, and evaluation framework to promote\nfurther research.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.15310v1",
    "published_date": "2024-12-19 15:02:33 UTC",
    "updated_date": "2024-12-19 15:02:33 UTC"
  },
  {
    "arxiv_id": "2412.14922v1",
    "title": "RobustFT: Robust Supervised Fine-tuning for Large Language Models under Noisy Response",
    "authors": [
      "Junyu Luo",
      "Xiao Luo",
      "Kaize Ding",
      "Jingyang Yuan",
      "Zhiping Xiao",
      "Ming Zhang"
    ],
    "abstract": "Supervised fine-tuning (SFT) plays a crucial role in adapting large language\nmodels (LLMs) to specific domains or tasks. However, as demonstrated by\nempirical experiments, the collected data inevitably contains noise in\npractical applications, which poses significant challenges to model performance\non downstream tasks. Therefore, there is an urgent need for a noise-robust SFT\nframework to enhance model capabilities in downstream tasks. To address this\nchallenge, we introduce a robust SFT framework (RobustFT) that performs noise\ndetection and relabeling on downstream task data. For noise identification, our\napproach employs a multi-expert collaborative system with inference-enhanced\nmodels to achieve superior noise detection. In the denoising phase, we utilize\na context-enhanced strategy, which incorporates the most relevant and confident\nknowledge followed by careful assessment to generate reliable annotations.\nAdditionally, we introduce an effective data selection mechanism based on\nresponse entropy, ensuring only high-quality samples are retained for\nfine-tuning. Extensive experiments conducted on multiple LLMs across five\ndatasets demonstrate RobustFT's exceptional performance in noisy scenarios.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.14922v1",
    "published_date": "2024-12-19 15:00:18 UTC",
    "updated_date": "2024-12-19 15:00:18 UTC"
  },
  {
    "arxiv_id": "2501.01435v1",
    "title": "Fundamental Risks in the Current Deployment of General-Purpose AI Models: What Have We (Not) Learnt From Cybersecurity?",
    "authors": [
      "Mario Fritz"
    ],
    "abstract": "General Purpose AI - such as Large Language Models (LLMs) - have seen rapid\ndeployment in a wide range of use cases. Most surprisingly, they have have made\ntheir way from plain language models, to chat-bots, all the way to an almost\n``operating system''-like status that can control decisions and logic of an\napplication. Tool-use, Microsoft co-pilot/office integration, and OpenAIs\nAltera are just a few examples of increased autonomy, data access, and\nexecution capabilities. These methods come with a range of cybersecurity\nchallenges. We highlight some of the work we have done in terms of evaluation\nas well as outline future opportunities and challenges.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.01435v1",
    "published_date": "2024-12-19 14:44:41 UTC",
    "updated_date": "2024-12-19 14:44:41 UTC"
  },
  {
    "arxiv_id": "2412.14905v1",
    "title": "Dehallucinating Parallel Context Extension for Retrieval-Augmented Generation",
    "authors": [
      "Zexiong Ma",
      "Shengnan An",
      "Zeqi Lin",
      "Yanzhen Zou",
      "Jian-Guang Lou",
      "Bing Xie"
    ],
    "abstract": "Large language models (LLMs) are susceptible to generating hallucinated\ninformation, despite the integration of retrieval-augmented generation (RAG).\nParallel context extension (PCE) is a line of research attempting to\neffectively integrating parallel (unordered) contexts, while it still suffers\nfrom hallucinations when adapted to RAG scenarios. In this paper, we propose\nDePaC (Dehallucinating Parallel Context Extension), which alleviates the\nhallucination problem with context-aware negative training and\ninformation-calibrated aggregation. DePaC is designed to alleviate two types of\nin-context hallucination: fact fabrication (i.e., LLMs present claims that are\nnot supported by the contexts) and fact omission (i.e., LLMs fail to present\nclaims that can be supported by the contexts). Specifically, (1) for fact\nfabrication, we apply the context-aware negative training that fine-tunes the\nLLMs with negative supervisions, thus explicitly guiding the LLMs to refuse to\nanswer when contexts are not related to questions; (2) for fact omission, we\npropose the information-calibrated aggregation which prioritizes context\nwindows with higher information increment from their contexts. The experimental\nresults on nine RAG tasks demonstrate that DePaC significantly alleviates the\ntwo types of hallucination and consistently achieves better performances on\nthese tasks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.14905v1",
    "published_date": "2024-12-19 14:37:11 UTC",
    "updated_date": "2024-12-19 14:37:11 UTC"
  },
  {
    "arxiv_id": "2412.14869v1",
    "title": "AI-Powered Intracranial Hemorrhage Detection: A Co-Scale Convolutional Attention Model with Uncertainty-Based Fuzzy Integral Operator and Feature Screening",
    "authors": [
      "Mehdi Hosseini Chagahi",
      "Md. Jalil Piran",
      "Niloufar Delfan",
      "Behzad Moshiri",
      "Jaber Hatam Parikhan"
    ],
    "abstract": "Intracranial hemorrhage (ICH) refers to the leakage or accumulation of blood\nwithin the skull, which occurs due to the rupture of blood vessels in or around\nthe brain. If this condition is not diagnosed in a timely manner and\nappropriately treated, it can lead to serious complications such as decreased\nconsciousness, permanent neurological disabilities, or even death.The primary\naim of this study is to detect the occurrence or non-occurrence of ICH,\nfollowed by determining the type of subdural hemorrhage (SDH). These tasks are\nframed as two separate binary classification problems. By adding two layers to\nthe co-scale convolutional attention (CCA) classifier architecture, we\nintroduce a novel approach for ICH detection. In the first layer, after\nextracting features from different slices of computed tomography (CT) scan\nimages, we combine these features and select the 50 components that capture the\nhighest variance in the data, considering them as informative features. We then\nassess the discriminative power of these features using the bootstrap forest\nalgorithm, discarding those that lack sufficient discriminative ability between\ndifferent classes. This algorithm explicitly determines the contribution of\neach feature to the final prediction, assisting us in developing an explainable\nAI model. The features feed into a boosting neural network as a latent feature\nspace. In the second layer, we introduce a novel uncertainty-based fuzzy\nintegral operator to fuse information from different CT scan slices. This\noperator, by accounting for the dependencies between consecutive slices,\nsignificantly improves detection accuracy.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.14869v1",
    "published_date": "2024-12-19 14:06:44 UTC",
    "updated_date": "2024-12-19 14:06:44 UTC"
  },
  {
    "arxiv_id": "2412.15309v1",
    "title": "Conceptual In-Context Learning and Chain of Concepts: Solving Complex Conceptual Problems Using Large Language Models",
    "authors": [
      "Nishtha N. Vaidya",
      "Thomas Runkler",
      "Thomas Hubauer",
      "Veronika Haderlein-Hoegberg",
      "Maja Mlicic Brandt"
    ],
    "abstract": "Science and engineering problems fall in the category of complex conceptual\nproblems that require specific conceptual information (CI) like math/logic\n-related know-how, process information, or engineering guidelines to solve\nthem. Large Language Models (LLMs) are promising agents to solve such complex\nconceptual problems due to their implications in advancing engineering and\nscience tasks like assisted problem-solving. But vanilla LLMs, trained on\nopen-world data, lack the necessary CI. In this work, we specifically explore\nshallow customization methods (SCMs) of LLMs for solving complex conceptual\nproblems. We propose two novel SCM algorithms for LLM, to augment LLMs with CI\nand enable LLMs to solve complex conceptual problems: Conceptual In-Context\nLearning (C-ICL) and Chain of Concepts (CoC). The problem tackled in this paper\nis generation of proprietary data models in the engineering/industry domain\nbased on conceptual information in data modelling guidelines. We evaluate our\nalgorithms on varied sizes of the OpenAI LLMs against four evaluation metrics\nrelated to syntactic and semantic correctness, time and cost incurred. The\nproposed algorithms perform better than currently popular LLM SCMs like\nIn-context Learning (ICL) and Chain of Thoughts (CoT). It was observed that as\ncompared to CoT, response correctness increased by 30.6% and 29.88% for the new\nSCMs C-ICL and CoC respectively. Qualitative analysis suggests that the\nproposed new SCMs activate emergent capabilities in LLMs, previously unobserved\nin the existing SCMs. They make problem-solving processes more transparent and\nreduce hallucinations and the tendency of model responses to copy examples from\nprompts (parroting).",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to 2025 IEEE Symposium on Computational Intelligence in\n  Natural Language Processing and Social Media",
    "pdf_url": "http://arxiv.org/pdf/2412.15309v1",
    "published_date": "2024-12-19 13:54:33 UTC",
    "updated_date": "2024-12-19 13:54:33 UTC"
  },
  {
    "arxiv_id": "2412.14847v2",
    "title": "A Survey of RWKV",
    "authors": [
      "Zhiyuan Li",
      "Tingyu Xia",
      "Yi Chang",
      "Yuan Wu"
    ],
    "abstract": "The Receptance Weighted Key Value (RWKV) model offers a novel alternative to\nthe Transformer architecture, merging the benefits of recurrent and\nattention-based systems. Unlike conventional Transformers, which depend heavily\non self-attention, RWKV adeptly captures long-range dependencies with minimal\ncomputational demands. By utilizing a recurrent framework, RWKV addresses some\ncomputational inefficiencies found in Transformers, particularly in tasks with\nlong sequences. RWKV has recently drawn considerable attention for its robust\nperformance across multiple domains. Despite its growing popularity, no\nsystematic review of the RWKV model exists. This paper seeks to fill this gap\nas the first comprehensive review of the RWKV architecture, its core\nprinciples, and its varied applications, such as natural language generation,\nnatural language understanding, and computer vision. We assess how RWKV\ncompares to traditional Transformer models, highlighting its capability to\nmanage long sequences efficiently and lower computational costs. Furthermore,\nwe explore the challenges RWKV encounters and propose potential directions for\nfuture research and advancement. We consistently maintain the related\nopen-source materials at: https://github.com/MLGroupJLU/RWKV-Survey.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "19 pages",
    "pdf_url": "http://arxiv.org/pdf/2412.14847v2",
    "published_date": "2024-12-19 13:39:24 UTC",
    "updated_date": "2025-01-05 13:54:06 UTC"
  },
  {
    "arxiv_id": "2412.14846v2",
    "title": "Head and Neck Tumor Segmentation of MRI from Pre- and Mid-radiotherapy with Pre-training, Data Augmentation and Dual Flow UNet",
    "authors": [
      "Litingyu Wang",
      "Wenjun Liao",
      "Shichuan Zhang",
      "Guotai Wang"
    ],
    "abstract": "Head and neck tumors and metastatic lymph nodes are crucial for treatment\nplanning and prognostic analysis. Accurate segmentation and quantitative\nanalysis of these structures require pixel-level annotation, making automated\nsegmentation techniques essential for the diagnosis and treatment of head and\nneck cancer. In this study, we investigated the effects of multiple strategies\non the segmentation of pre-radiotherapy (pre-RT) and mid-radiotherapy (mid-RT)\nimages. For the segmentation of pre-RT images, we utilized: 1) a fully\nsupervised learning approach, and 2) the same approach enhanced with\npre-trained weights and the MixUp data augmentation technique. For mid-RT\nimages, we introduced a novel computational-friendly network architecture that\nfeatures separate encoders for mid-RT images and registered pre-RT images with\ntheir labels. The mid-RT encoder branch integrates information from pre-RT\nimages and labels progressively during the forward propagation. We selected the\nhighest-performing model from each fold and used their predictions to create an\nensemble average for inference. In the final test, our models achieved a\nsegmentation performance of 82.38% for pre-RT and 72.53% for mid-RT on\naggregated Dice Similarity Coefficient (DSC) as HiLab. Our code is available at\nhttps://github.com/WltyBY/HNTS-MRG2024_train_code.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.14846v2",
    "published_date": "2024-12-19 13:38:20 UTC",
    "updated_date": "2025-03-31 03:02:07 UTC"
  },
  {
    "arxiv_id": "2412.14843v3",
    "title": "Mapping and Influencing the Political Ideology of Large Language Models using Synthetic Personas",
    "authors": [
      "Pietro Bernardelle",
      "Leon Fröhling",
      "Stefano Civelli",
      "Riccardo Lunardi",
      "Kevin Roitero",
      "Gianluca Demartini"
    ],
    "abstract": "The analysis of political biases in large language models (LLMs) has\nprimarily examined these systems as single entities with fixed viewpoints.\nWhile various methods exist for measuring such biases, the impact of\npersona-based prompting on LLMs' political orientation remains unexplored. In\nthis work we leverage PersonaHub, a collection of synthetic persona\ndescriptions, to map the political distribution of persona-based prompted LLMs\nusing the Political Compass Test (PCT). We then examine whether these initial\ncompass distributions can be manipulated through explicit ideological prompting\ntowards diametrically opposed political orientations: right-authoritarian and\nleft-libertarian. Our experiments reveal that synthetic personas predominantly\ncluster in the left-libertarian quadrant, with models demonstrating varying\ndegrees of responsiveness when prompted with explicit ideological descriptors.\nWhile all models demonstrate significant shifts towards right-authoritarian\npositions, they exhibit more limited shifts towards left-libertarian positions,\nsuggesting an asymmetric response to ideological manipulation that may reflect\ninherent biases in model training.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Companion Proceedings of the ACM Web Conference 2025 (WWW\n  Companion'25)",
    "pdf_url": "http://arxiv.org/pdf/2412.14843v3",
    "published_date": "2024-12-19 13:36:18 UTC",
    "updated_date": "2025-02-26 03:24:32 UTC"
  },
  {
    "arxiv_id": "2412.14841v2",
    "title": "Helping LLMs Improve Code Generation Using Feedback from Testing and Static Analysis",
    "authors": [
      "Greta Dolcetti",
      "Vincenzo Arceri",
      "Eleonora Iotti",
      "Sergio Maffeis",
      "Agostino Cortesi",
      "Enea Zaffanella"
    ],
    "abstract": "Large Language Models (LLMs) are one of the most promising developments in\nthe field of artificial intelligence, and the software engineering community\nhas readily noticed their potential role in the software development\nlife-cycle. Developers routinely ask LLMs to generate code snippets, increasing\nproductivity but also potentially introducing ownership, privacy, correctness,\nand security issues. Previous work highlighted how code generated by mainstream\ncommercial LLMs is often not safe, containing vulnerabilities, bugs, and code\nsmells. In this paper, we present a framework that leverages testing and static\nanalysis to assess the quality, and guide the self-improvement, of code\ngenerated by general-purpose, open-source LLMs.\n  First, we ask LLMs to generate C code to solve a number of programming tasks.\nThen we employ ground-truth tests to assess the (in)correctness of the\ngenerated code, and a static analysis tool to detect potential safety\nvulnerabilities. Next, we assess the models ability to evaluate the generated\ncode, by asking them to detect errors and vulnerabilities. Finally, we test the\nmodels ability to fix the generated code, providing the reports produced during\nthe static analysis and incorrectness evaluation phases as feedback.\n  Our results show that models often produce incorrect code, and that the\ngenerated code can include safety issues. Moreover, they perform very poorly at\ndetecting either issue. On the positive side, we observe a substantial ability\nto fix flawed code when provided with information about failed tests or\npotential vulnerabilities, indicating a promising avenue for improving the\nsafety of LLM-based code generation tools.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.14841v2",
    "published_date": "2024-12-19 13:34:14 UTC",
    "updated_date": "2025-01-07 15:30:56 UTC"
  },
  {
    "arxiv_id": "2412.14835v1",
    "title": "Progressive Multimodal Reasoning via Active Retrieval",
    "authors": [
      "Guanting Dong",
      "Chenghao Zhang",
      "Mengjie Deng",
      "Yutao Zhu",
      "Zhicheng Dou",
      "Ji-Rong Wen"
    ],
    "abstract": "Multi-step multimodal reasoning tasks pose significant challenges for\nmultimodal large language models (MLLMs), and finding effective ways to enhance\ntheir performance in such scenarios remains an unresolved issue. In this paper,\nwe propose AR-MCTS, a universal framework designed to progressively improve the\nreasoning capabilities of MLLMs through Active Retrieval (AR) and Monte Carlo\nTree Search (MCTS). Our approach begins with the development of a unified\nretrieval module that retrieves key supporting insights for solving complex\nreasoning problems from a hybrid-modal retrieval corpus. To bridge the gap in\nautomated multimodal reasoning verification, we employ the MCTS algorithm\ncombined with an active retrieval mechanism, which enables the automatic\ngeneration of step-wise annotations. This strategy dynamically retrieves key\ninsights for each reasoning step, moving beyond traditional beam search\nsampling to improve the diversity and reliability of the reasoning space.\nAdditionally, we introduce a process reward model that aligns progressively to\nsupport the automatic verification of multimodal reasoning tasks. Experimental\nresults across three complex multimodal reasoning benchmarks confirm the\neffectiveness of the AR-MCTS framework in enhancing the performance of various\nmultimodal models. Further analysis demonstrates that AR-MCTS can optimize\nsampling diversity and accuracy, yielding reliable multimodal reasoning.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "Working in progress",
    "pdf_url": "http://arxiv.org/pdf/2412.14835v1",
    "published_date": "2024-12-19 13:25:39 UTC",
    "updated_date": "2024-12-19 13:25:39 UTC"
  },
  {
    "arxiv_id": "2412.14814v1",
    "title": "Answer Set Networks: Casting Answer Set Programming into Deep Learning",
    "authors": [
      "Arseny Skryagin",
      "Daniel Ochs",
      "Phillip Deibert",
      "Simon Kohaut",
      "Devendra Singh Dhami",
      "Kristian Kersting"
    ],
    "abstract": "Although Answer Set Programming (ASP) allows constraining neural-symbolic\n(NeSy) systems, its employment is hindered by the prohibitive costs of\ncomputing stable models and the CPU-bound nature of state-of-the-art solvers.\nTo this end, we propose Answer Set Networks (ASN), a NeSy solver. Based on\nGraph Neural Networks (GNN), ASNs are a scalable approach to ASP-based Deep\nProbabilistic Logic Programming (DPPL). Specifically, we show how to translate\nASPs into ASNs and demonstrate how ASNs can efficiently solve the encoded\nproblem by leveraging GPU's batching and parallelization capabilities. Our\nexperimental evaluations demonstrate that ASNs outperform state-of-the-art\nCPU-bound NeSy systems on multiple tasks. Simultaneously, we make the following\ntwo contributions based on the strengths of ASNs. Namely, we are the first to\nshow the finetuning of Large Language Models (LLM) with DPPLs, employing ASNs\nto guide the training with logic. Further, we show the \"constitutional\nnavigation\" of drones, i.e., encoding public aviation laws in an ASN for\nrouting Unmanned Aerial Vehicles in uncertain environments.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.SC",
      "68T37, 68T30, 68T27",
      "I.2.4; I.2.5"
    ],
    "primary_category": "cs.AI",
    "comment": "16 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.14814v1",
    "published_date": "2024-12-19 13:09:06 UTC",
    "updated_date": "2024-12-19 13:09:06 UTC"
  },
  {
    "arxiv_id": "2412.16238v2",
    "title": "Algebraic Evaluation Theorems",
    "authors": [
      "Andrés Corrada-Emmanuel"
    ],
    "abstract": "Majority voting (MV) is the prototypical ``wisdom of the crowd'' algorithm.\nTheorems considering when MV is optimal for group decisions date back to\nCondorcet's 1785 jury \\emph{decision} theorem. The same error independence\nassumption underlying the theorem can be used to prove a jury \\emph{evaluation}\ntheorem that does purely algebraic evaluation (AE) of juror performance based\non a batch of their decisions. Three or more binary jurors are enough to obtain\nthe only two possible statistics of their correctness on a test they took. AE\nis superior to MV in three ways. First, its empirical assumptions are looser\nand can handle jurors less than 50\\% accurate in making decisions. Second, it\nhas point-like precision in evaluating them given its assumption of error\nindependence. This precision enables a multi-accuracy approach that has higher\nlabeling accuracy than MV and comes with empirical uncertainty bounds. And,\nthird, it is self-alarming about the failure of its error independence\nassumption. Experiments using demographic data from the American Community\nSurvey confirm the practical utility of AE over MV. Two implications of the\ntheorem for AI safety are discussed - a principled way to terminate infinite\nmonitoring chains (who grades the graders?) and the super-alignment problem\n(how do we evaluate agents doing tasks we do not understand?).",
    "categories": [
      "cs.AI",
      "cs.LG",
      "I.2.6"
    ],
    "primary_category": "cs.AI",
    "comment": "28 pages",
    "pdf_url": "http://arxiv.org/pdf/2412.16238v2",
    "published_date": "2024-12-19 13:01:21 UTC",
    "updated_date": "2025-03-12 16:31:39 UTC"
  },
  {
    "arxiv_id": "2412.14810v2",
    "title": "MARIA: a Multimodal Transformer Model for Incomplete Healthcare Data",
    "authors": [
      "Camillo Maria Caruso",
      "Paolo Soda",
      "Valerio Guarrasi"
    ],
    "abstract": "In healthcare, the integration of multimodal data is pivotal for developing\ncomprehensive diagnostic and predictive models. However, managing missing data\nremains a significant challenge in real-world applications. We introduce MARIA\n(Multimodal Attention Resilient to Incomplete datA), a novel transformer-based\ndeep learning model designed to address these challenges through an\nintermediate fusion strategy. Unlike conventional approaches that depend on\nimputation, MARIA utilizes a masked self-attention mechanism, which processes\nonly the available data without generating synthetic values. This approach\nenables it to effectively handle incomplete datasets, enhancing robustness and\nminimizing biases introduced by imputation methods. We evaluated MARIA against\n10 state-of-the-art machine learning and deep learning models across 8\ndiagnostic and prognostic tasks. The results demonstrate that MARIA outperforms\nexisting methods in terms of performance and resilience to varying levels of\ndata incompleteness, underscoring its potential for critical healthcare\napplications.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.14810v2",
    "published_date": "2024-12-19 13:00:03 UTC",
    "updated_date": "2025-04-30 12:32:27 UTC"
  },
  {
    "arxiv_id": "2412.14802v1",
    "title": "Stack Trace Deduplication: Faster, More Accurately, and in More Realistic Scenarios",
    "authors": [
      "Egor Shibaev",
      "Denis Sushentsev",
      "Yaroslav Golubev",
      "Aleksandr Khvorov"
    ],
    "abstract": "In large-scale software systems, there are often no fully-fledged bug reports\nwith human-written descriptions when an error occurs. In this case, developers\nrely on stack traces, i.e., series of function calls that led to the error.\nSince there can be tens and hundreds of thousands of them describing the same\nissue from different users, automatic deduplication into categories is\nnecessary to allow for processing. Recent works have proposed powerful deep\nlearning-based approaches for this, but they are evaluated and compared in\nisolation from real-life workflows, and it is not clear whether they will\nactually work well at scale.\n  To overcome this gap, this work presents three main contributions: a novel\nmodel, an industry-based dataset, and a multi-faceted evaluation. Our model\nconsists of two parts - (1) an embedding model with byte-pair encoding and\napproximate nearest neighbor search to quickly find the most relevant stack\ntraces to the incoming one, and (2) a reranker that re-ranks the most fitting\nstack traces, taking into account the repeated frames between them. To\ncomplement the existing datasets collected from open-source projects, we share\nwith the community SlowOps - a dataset of stack traces from IntelliJ-based\nproducts developed by JetBrains, which has an order of magnitude more stack\ntraces per category. Finally, we carry out an evaluation that strives to be\nrealistic: measuring not only the accuracy of categorization, but also the\noperation time and the ability to create new categories. The evaluation shows\nthat our model strikes a good balance - it outperforms other models on both\nopen-source datasets and SlowOps, while also being faster on time than most. We\nrelease all of our code and data, and hope that our work can pave the way to\nfurther practice-oriented research in the area.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.SE",
    "comment": "Published at SANER'25. 11 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.14802v1",
    "published_date": "2024-12-19 12:48:17 UTC",
    "updated_date": "2024-12-19 12:48:17 UTC"
  },
  {
    "arxiv_id": "2412.15305v1",
    "title": "Tree-of-Code: A Tree-Structured Exploring Framework for End-to-End Code Generation and Execution in Complex Task Handling",
    "authors": [
      "Ziyi Ni",
      "Yifan Li",
      "Ning Yang",
      "Dou Shen",
      "Pin Lv",
      "Daxiang Dong"
    ],
    "abstract": "Solving complex reasoning tasks is a key real-world application of agents.\nThanks to the pretraining of Large Language Models (LLMs) on code data, recent\napproaches like CodeAct successfully use code as LLM agents' action, achieving\ngood results. However, CodeAct greedily generates the next action's code block\nby relying on fragmented thoughts, resulting in inconsistency and instability.\nMoreover, CodeAct lacks action-related ground-truth (GT), making its\nsupervision signals and termination conditions questionable in multi-turn\ninteractions. To address these issues, we first introduce a simple yet\neffective end-to-end code generation paradigm, CodeProgram, which leverages\ncode's systematic logic to align with global reasoning and enable cohesive\nproblem-solving. Then, we propose Tree-of-Code (ToC), which self-grows\nCodeProgram nodes based on the executable nature of the code and enables\nself-supervision in a GT-free scenario. Experimental results on two datasets\nusing ten popular zero-shot LLMs show ToC remarkably boosts accuracy by nearly\n20% over CodeAct with less than 1/4 turns. Several LLMs even perform better on\none-turn CodeProgram than on multi-turn CodeAct. To further investigate the\ntrade-off between efficacy and efficiency, we test different ToC tree sizes and\nexploration mechanisms. We also highlight the potential of ToC's end-to-end\ndata generation for supervised and reinforced fine-tuning.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "This idea was first submitted to the NeuralPS Workshop \"System 2\n  Reasoning At Scale\" in September 2024. Its OpenReview:\n  https://openreview.net/forum?id=8NKAL8Ngxk&noteId=8NKAL8Ngxk. It was then\n  submitted to the NAACL 2025 in October 2024, which is recorded in:\n  https://openreview.net/forum?id=S0ZUWD3Vy5&noteId=S0ZUWD3Vy5. This work\n  predates many existing works",
    "pdf_url": "http://arxiv.org/pdf/2412.15305v1",
    "published_date": "2024-12-19 12:31:22 UTC",
    "updated_date": "2024-12-19 12:31:22 UTC"
  },
  {
    "arxiv_id": "2502.07786v1",
    "title": "Counterexample Guided Program Repair Using Zero-Shot Learning and MaxSAT-based Fault Localization",
    "authors": [
      "Pedro Orvalho",
      "Mikoláš Janota",
      "Vasco Manquinho"
    ],
    "abstract": "Automated Program Repair (APR) for introductory programming assignments\n(IPAs) is motivated by the large number of student enrollments in programming\ncourses each year. Since providing feedback on IPAs requires substantial time\nand effort from faculty, personalized feedback often involves suggesting fixes\nto students' programs. Formal Methods (FM)-based semantic repair approaches,\ncheck a program's execution against a test suite or reference solution, are\neffective but limited. These tools excel at identifying buggy parts but can\nonly fix programs if the correct implementation and the faulty one share the\nsame control flow graph. Conversely, Large Language Models (LLMs) are used for\nAPR but often make extensive instead of minimal rewrites. This leads to more\ninvasive fixes, making it harder for students to learn from their mistakes. In\nsummary, LLMs excel at completing strings, while FM-based fault localization\nexcel at identifying buggy parts of a program. In this paper, we propose a\nnovel approach that combines the strengths of both FM-based fault localization\nand LLMs, via zero-shot learning, to enhance APR for IPAs. Our method uses\nMaxSAT-based fault localization to identify buggy parts of a program, then\npresents the LLM with a program sketch devoid of these buggy statements. This\nhybrid approach follows a CEGIS loop to iteratively refine the program. We ask\nthe LLM to synthesize the missing parts, which are then checked against a test\nsuite. If the suggested program is incorrect, a counterexample from the test\nsuite is fed back to the LLM. Our experiments show that our counterexample\nguided approach, using MaxSAT-based bug-free program sketches, significantly\nimproves the repair capabilities of all six evaluated LLMs. This method allows\nLLMs to repair more programs with smaller fixes, outperforming other\nconfigurations and state-of-the-art symbolic program repair tools.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "Accepted at AAAI 2025. 11 pages, 4 listings, 2 figures and 5 tables",
    "pdf_url": "http://arxiv.org/pdf/2502.07786v1",
    "published_date": "2024-12-19 12:08:44 UTC",
    "updated_date": "2024-12-19 12:08:44 UTC"
  },
  {
    "arxiv_id": "2412.14779v1",
    "title": "Agent-Temporal Credit Assignment for Optimal Policy Preservation in Sparse Multi-Agent Reinforcement Learning",
    "authors": [
      "Aditya Kapoor",
      "Sushant Swamy",
      "Kale-ab Tessera",
      "Mayank Baranwal",
      "Mingfei Sun",
      "Harshad Khadilkar",
      "Stefano V. Albrecht"
    ],
    "abstract": "In multi-agent environments, agents often struggle to learn optimal policies\ndue to sparse or delayed global rewards, particularly in long-horizon tasks\nwhere it is challenging to evaluate actions at intermediate time steps. We\nintroduce Temporal-Agent Reward Redistribution (TAR$^2$), a novel approach\ndesigned to address the agent-temporal credit assignment problem by\nredistributing sparse rewards both temporally and across agents. TAR$^2$\ndecomposes sparse global rewards into time-step-specific rewards and calculates\nagent-specific contributions to these rewards. We theoretically prove that\nTAR$^2$ is equivalent to potential-based reward shaping, ensuring that the\noptimal policy remains unchanged. Empirical results demonstrate that TAR$^2$\nstabilizes and accelerates the learning process. Additionally, we show that\nwhen TAR$^2$ is integrated with single-agent reinforcement learning algorithms,\nit performs as well as or better than traditional multi-agent reinforcement\nlearning methods.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.GT",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.MA",
    "comment": "12 pages, 1 figure",
    "pdf_url": "http://arxiv.org/pdf/2412.14779v1",
    "published_date": "2024-12-19 12:05:13 UTC",
    "updated_date": "2024-12-19 12:05:13 UTC"
  },
  {
    "arxiv_id": "2412.14775v1",
    "title": "Energy and polarization based on-line interference mitigation in radio interferometry",
    "authors": [
      "Sarod Yatawatta",
      "Albert-Jan Boonstra",
      "Chris P. Broekema"
    ],
    "abstract": "Radio frequency interference (RFI) is a persistent contaminant in terrestrial\nradio astronomy. While new radio interferometers are becoming operational,\nnovel sources of RFI are also emerging. In order to strengthen the mitigation\nof RFI in modern radio interferometers, we propose an on-line RFI mitigation\nscheme that can be run in the correlator of such interferometers. We combine\nstatistics based on the energy as well as the polarization alignment of the\ncorrelated signal to develop an on-line RFI mitigation scheme that can be\napplied to a data stream produced by the correlator in real-time, especially\ntargeted at low duty-cycle or transient RFI detection. In order to improve the\ncomputational efficiency, we explore the use of both single precision and half\nprecision floating point operations in implementing the RFI mitigation\nalgorithm. This ideally suits its deployment in accelerator computing devices\nsuch as graphics processing units (GPUs) as used by the LOFAR correlator. We\nprovide results based on real data to demonstrate the efficacy of the proposed\nmethod.",
    "categories": [
      "astro-ph.IM",
      "cs.AI"
    ],
    "primary_category": "astro-ph.IM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.14775v1",
    "published_date": "2024-12-19 11:59:17 UTC",
    "updated_date": "2024-12-19 11:59:17 UTC"
  },
  {
    "arxiv_id": "2412.14771v1",
    "title": "ALKAFI-LLAMA3: Fine-Tuning LLMs for Precise Legal Understanding in Palestine",
    "authors": [
      "Rabee Qasem",
      "Mohannad Hendi",
      "Banan Tantour"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable potential in\ndiverse domains, yet their application in the legal sector, particularly in\nlow-resource contexts, remains limited. This study addresses the challenges of\nadapting LLMs to the Palestinian legal domain, where political instability,\nfragmented legal frameworks, and limited AI resources hinder effective\nmachine-learning applications. We present a fine-tuned model based on a\nquantized version of Llama-3.2-1B-Instruct, trained on a synthetic data set\nderived from Palestinian legal texts. Using smaller-scale models and\nstrategically generated question-answer pairs, we achieve a cost-effective,\nlocally sustainable solution that provides accurate and contextually relevant\nlegal guidance. Our experiments demonstrate promising performance on various\nquery types, ranging from yes/no questions and narrative explanations to\ncomplex legal differentiations, while highlighting areas for improvement, such\nas handling calculation-based inquiries and structured list formatting. This\nwork provides a pathway for the deployment of AI-driven legal assistance tools\ntailored to the needs of resource-constrained environments.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.14771v1",
    "published_date": "2024-12-19 11:55:51 UTC",
    "updated_date": "2024-12-19 11:55:51 UTC"
  },
  {
    "arxiv_id": "2412.14764v1",
    "title": "CodeRepoQA: A Large-scale Benchmark for Software Engineering Question Answering",
    "authors": [
      "Ruida Hu",
      "Chao Peng",
      "Jingyi Ren",
      "Bo Jiang",
      "Xiangxin Meng",
      "Qinyun Wu",
      "Pengfei Gao",
      "Xinchen Wang",
      "Cuiyun Gao"
    ],
    "abstract": "In this work, we introduce CodeRepoQA, a large-scale benchmark specifically\ndesigned for evaluating repository-level question-answering capabilities in the\nfield of software engineering. CodeRepoQA encompasses five programming\nlanguages and covers a wide range of scenarios, enabling comprehensive\nevaluation of language models. To construct this dataset, we crawl data from 30\nwell-known repositories in GitHub, the largest platform for hosting and\ncollaborating on code, and carefully filter raw data. In total, CodeRepoQA is a\nmulti-turn question-answering benchmark with 585,687 entries, covering a\ndiverse array of software engineering scenarios, with an average of 6.62\ndialogue turns per entry.\n  We evaluate ten popular large language models on our dataset and provide\nin-depth analysis. We find that LLMs still have limitations in\nquestion-answering capabilities in the field of software engineering, and\nmedium-length contexts are more conducive to LLMs' performance. The entire\nbenchmark is publicly available at\nhttps://github.com/kinesiatricssxilm14/CodeRepoQA.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.14764v1",
    "published_date": "2024-12-19 11:48:01 UTC",
    "updated_date": "2024-12-19 11:48:01 UTC"
  },
  {
    "arxiv_id": "2412.14736v1",
    "title": "Advances in Artificial Intelligence forDiabetes Prediction: Insights from a Systematic Literature Review",
    "authors": [
      "Pir Bakhsh Khokhar",
      "Carmine Gravino",
      "Fabio Palomba"
    ],
    "abstract": "This systematic review explores the use of machine learning (ML) in\npredicting diabetes, focusing on datasets, algorithms, training methods, and\nevaluation metrics. It examines datasets like the Singapore National Diabetic\nRetinopathy Screening program, REPLACE-BG, National Health and Nutrition\nExamination Survey, and Pima Indians Diabetes Database. The review assesses the\nperformance of ML algorithms like CNN, SVM, Logistic Regression, and XGBoost in\npredicting diabetes outcomes. The study emphasizes the importance of\ninterdisciplinary collaboration and ethical considerations in ML-based diabetes\nprediction models.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.14736v1",
    "published_date": "2024-12-19 11:09:10 UTC",
    "updated_date": "2024-12-19 11:09:10 UTC"
  },
  {
    "arxiv_id": "2412.14732v1",
    "title": "Beyond the Hype: A Comprehensive Review of Current Trends in Generative AI Research, Teaching Practices, and Tools",
    "authors": [
      "James Prather",
      "Juho Leinonen",
      "Natalie Kiesler",
      "Jamie Gorson Benario",
      "Sam Lau",
      "Stephen MacNeil",
      "Narges Norouzi",
      "Simone Opel",
      "Vee Pettit",
      "Leo Porter",
      "Brent N. Reeves",
      "Jaromir Savelka",
      "David H. Smith IV",
      "Sven Strickroth",
      "Daniel Zingaro"
    ],
    "abstract": "Generative AI (GenAI) is advancing rapidly, and the literature in computing\neducation is expanding almost as quickly. Initial responses to GenAI tools were\nmixed between panic and utopian optimism. Many were fast to point out the\nopportunities and challenges of GenAI. Researchers reported that these new\ntools are capable of solving most introductory programming tasks and are\ncausing disruptions throughout the curriculum. These tools can write and\nexplain code, enhance error messages, create resources for instructors, and\neven provide feedback and help for students like a traditional teaching\nassistant. In 2024, new research started to emerge on the effects of GenAI\nusage in the computing classroom. These new data involve the use of GenAI to\nsupport classroom instruction at scale and to teach students how to code with\nGenAI. In support of the former, a new class of tools is emerging that can\nprovide personalized feedback to students on their programming assignments or\nteach both programming and prompting skills at the same time. With the\nliterature expanding so rapidly, this report aims to summarize and explain what\nis happening on the ground in computing classrooms. We provide a systematic\nliterature review; a survey of educators and industry professionals; and\ninterviews with educators using GenAI in their courses, educators studying\nGenAI, and researchers who create GenAI tools to support computing education.\nThe triangulation of these methods and data sources expands the understanding\nof GenAI usage and perceptions at this critical moment for our community.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC",
      "cs.SE"
    ],
    "primary_category": "cs.CY",
    "comment": "39 pages, 10 figures, 16 tables. To be published in the Proceedings\n  of the 2024 Working Group Reports on Innovation and Technology in Computer\n  Science Education (ITiCSE-WGR 2024)",
    "pdf_url": "http://arxiv.org/pdf/2412.14732v1",
    "published_date": "2024-12-19 11:01:11 UTC",
    "updated_date": "2024-12-19 11:01:11 UTC"
  },
  {
    "arxiv_id": "2412.14728v1",
    "title": "LTLf Synthesis Under Unreliable Input",
    "authors": [
      "Christian Hagemeier",
      "Giuseppe de Giacomo",
      "Moshe Y. Vardi"
    ],
    "abstract": "We study the problem of realizing strategies for an LTLf goal specification\nwhile ensuring that at least an LTLf backup specification is satisfied in case\nof unreliability of certain input variables. We formally define the problem and\ncharacterize its worst-case complexity as 2EXPTIME-complete, like standard LTLf\nsynthesis. Then we devise three different solution techniques: one based on\ndirect automata manipulation, which is 2EXPTIME, one disregarding unreliable\ninput variables by adopting a belief construction, which is 3EXPTIME, and one\nleveraging second-order quantified LTLf (QLTLf), which is 2EXPTIME and allows\nfor a direct encoding into monadic second-order logic, which in turn is\nworst-case nonelementary. We prove their correctness and evaluate them against\neach other empirically. Interestingly, theoretical worst-case bounds do not\ntranslate into observed performance; the MSO technique performs best, followed\nby belief construction and direct automata manipulation. As a byproduct of our\nstudy, we provide a general synthesis procedure for arbitrary QLTLf\nspecifications.",
    "categories": [
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "8 pages, to appear at AAAI2025",
    "pdf_url": "http://arxiv.org/pdf/2412.14728v1",
    "published_date": "2024-12-19 10:54:17 UTC",
    "updated_date": "2024-12-19 10:54:17 UTC"
  },
  {
    "arxiv_id": "2412.15298v1",
    "title": "A Comparative Study of DSPy Teleprompter Algorithms for Aligning Large Language Models Evaluation Metrics to Human Evaluation",
    "authors": [
      "Bhaskarjit Sarmah",
      "Kriti Dutta",
      "Anna Grigoryan",
      "Sachin Tiwari",
      "Stefano Pasquali",
      "Dhagash Mehta"
    ],
    "abstract": "We argue that the Declarative Self-improving Python (DSPy) optimizers are a\nway to align the large language model (LLM) prompts and their evaluations to\nthe human annotations. We present a comparative analysis of five teleprompter\nalgorithms, namely, Cooperative Prompt Optimization (COPRO), Multi-Stage\nInstruction Prompt Optimization (MIPRO), BootstrapFewShot, BootstrapFewShot\nwith Optuna, and K-Nearest Neighbor Few Shot, within the DSPy framework with\nrespect to their ability to align with human evaluations. As a concrete\nexample, we focus on optimizing the prompt to align hallucination detection\n(using LLM as a judge) to human annotated ground truth labels for a publicly\navailable benchmark dataset. Our experiments demonstrate that optimized prompts\ncan outperform various benchmark methods to detect hallucination, and certain\ntelemprompters outperform the others in at least these experiments.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "q-fin.ST",
      "stat.ME"
    ],
    "primary_category": "cs.CL",
    "comment": "7 pages, 10 tables, two-column format",
    "pdf_url": "http://arxiv.org/pdf/2412.15298v1",
    "published_date": "2024-12-19 10:38:46 UTC",
    "updated_date": "2024-12-19 10:38:46 UTC"
  },
  {
    "arxiv_id": "2412.14708v1",
    "title": "Creation of AI-driven Smart Spaces for Enhanced Indoor Environments -- A Survey",
    "authors": [
      "Aygün Varol",
      "Naser Hossein Motlagh",
      "Mirka Leino",
      "Sasu Tarkoma",
      "Johanna Virkki"
    ],
    "abstract": "Smart spaces are ubiquitous computing environments that integrate diverse\nsensing and communication technologies to enhance space functionality, optimize\nenergy utilization, and improve user comfort and well-being. The integration of\nemerging AI methodologies into these environments facilitates the formation of\nAI-driven smart spaces, which further enhance functionalities of the spaces by\nenabling advanced applications such as personalized comfort settings,\ninteractive living spaces, and automatization of the space systems, all\nresulting in enhanced indoor experiences of the users. In this paper, we\npresent a systematic survey of existing research on the foundational components\nof AI-driven smart spaces, including sensor technologies, data communication\nprotocols, sensor network management and maintenance strategies, as well as the\ndata collection, processing and analytics. Given the pivotal role of AI in\nestablishing AI-powered smart spaces, we explore the opportunities and\nchallenges associated with traditional machine learning (ML) approaches, such\nas deep learning (DL), and emerging methodologies including large language\nmodels (LLMs). Finally, we provide key insights necessary for the development\nof AI-driven smart spaces, propose future research directions, and sheds light\non the path forward.",
    "categories": [
      "cs.AI",
      "cs.DC",
      "cs.ET",
      "cs.HC",
      "I.2; C.0; I.0"
    ],
    "primary_category": "cs.AI",
    "comment": "39 pages, 3 figures, 1 table, journal",
    "pdf_url": "http://arxiv.org/pdf/2412.14708v1",
    "published_date": "2024-12-19 10:20:34 UTC",
    "updated_date": "2024-12-19 10:20:34 UTC"
  },
  {
    "arxiv_id": "2412.14689v1",
    "title": "How to Synthesize Text Data without Model Collapse?",
    "authors": [
      "Xuekai Zhu",
      "Daixuan Cheng",
      "Hengli Li",
      "Kaiyan Zhang",
      "Ermo Hua",
      "Xingtai Lv",
      "Ning Ding",
      "Zhouhan Lin",
      "Zilong Zheng",
      "Bowen Zhou"
    ],
    "abstract": "Model collapse in synthetic data indicates that iterative training on\nself-generated data leads to a gradual decline in performance. With the\nproliferation of AI models, synthetic data will fundamentally reshape the web\ndata ecosystem. Future GPT-$\\{n\\}$ models will inevitably be trained on a blend\nof synthetic and human-produced data. In this paper, we focus on two questions:\nwhat is the impact of synthetic data on language model training, and how to\nsynthesize data without model collapse? We first pre-train language models\nacross different proportions of synthetic data, revealing a negative\ncorrelation between the proportion of synthetic data and model performance. We\nfurther conduct statistical analysis on synthetic data to uncover\ndistributional shift phenomenon and over-concentration of n-gram features.\nInspired by the above findings, we propose token editing on human-produced data\nto obtain semi-synthetic data. As a proof of concept, we theoretically\ndemonstrate that token-level editing can prevent model collapse, as the test\nerror is constrained by a finite upper bound. We conduct extensive experiments\non pre-training from scratch, continual pre-training, and supervised\nfine-tuning. The results validate our theoretical proof that token-level\nediting improves data quality and enhances model performance.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.14689v1",
    "published_date": "2024-12-19 09:43:39 UTC",
    "updated_date": "2024-12-19 09:43:39 UTC"
  },
  {
    "arxiv_id": "2501.10388v2",
    "title": "Beyond the Sum: Unlocking AI Agents Potential Through Market Forces",
    "authors": [
      "Jordi Montes Sanabria",
      "Pol Alvarez Vecino"
    ],
    "abstract": "The emergence of Large Language Models has fundamentally transformed the\ncapabilities of AI agents, enabling a new class of autonomous agents capable of\ninteracting with their environment through dynamic code generation and\nexecution. These agents possess the theoretical capacity to operate as\nindependent economic actors within digital markets, offering unprecedented\npotential for value creation through their distinct advantages in operational\ncontinuity, perfect replication, and distributed learning capabilities.\nHowever, contemporary digital infrastructure, architected primarily for human\ninteraction, presents significant barriers to their participation.\n  This work presents a systematic analysis of the infrastructure requirements\nnecessary for AI agents to function as autonomous participants in digital\nmarkets. We examine four key areas - identity and authorization, service\ndiscovery, interfaces, and payment systems - to show how existing\ninfrastructure actively impedes agent participation. We argue that addressing\nthese infrastructure challenges represents more than a technical imperative; it\nconstitutes a fundamental step toward enabling new forms of economic\norganization. Much as traditional markets enable human intelligence to\ncoordinate complex activities beyond individual capability, markets\nincorporating AI agents could dramatically enhance economic efficiency through\ncontinuous operation, perfect information sharing, and rapid adaptation to\nchanging conditions. The infrastructure challenges identified in this work\nrepresent key barriers to realizing this potential.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL",
      "cs.GT",
      "cs.MA",
      "I.2.2; I.2.7; I.2.11; J.4; K.4.4"
    ],
    "primary_category": "cs.CY",
    "comment": "20 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.10388v2",
    "published_date": "2024-12-19 09:40:40 UTC",
    "updated_date": "2025-01-23 22:53:04 UTC"
  },
  {
    "arxiv_id": "2412.14686v1",
    "title": "Each Fake News is Fake in its Own Way: An Attribution Multi-Granularity Benchmark for Multimodal Fake News Detection",
    "authors": [
      "Hao Guo",
      "Zihan Ma",
      "Zhi Zeng",
      "Minnan Luo",
      "Weixin Zeng",
      "Jiuyang Tang",
      "Xiang Zhao"
    ],
    "abstract": "Social platforms, while facilitating access to information, have also become\nsaturated with a plethora of fake news, resulting in negative consequences.\nAutomatic multimodal fake news detection is a worthwhile pursuit. Existing\nmultimodal fake news datasets only provide binary labels of real or fake.\nHowever, real news is alike, while each fake news is fake in its own way. These\ndatasets fail to reflect the mixed nature of various types of multimodal fake\nnews. To bridge the gap, we construct an attributing multi-granularity\nmultimodal fake news detection dataset \\amg, revealing the inherent fake\npattern. Furthermore, we propose a multi-granularity clue alignment model \\our\nto achieve multimodal fake news detection and attribution. Experimental results\ndemonstrate that \\amg is a challenging dataset, and its attribution setting\nopens up new avenues for future research.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.14686v1",
    "published_date": "2024-12-19 09:40:17 UTC",
    "updated_date": "2024-12-19 09:40:17 UTC"
  },
  {
    "arxiv_id": "2412.14684v1",
    "title": "Bel Esprit: Multi-Agent Framework for Building AI Model Pipelines",
    "authors": [
      "Yunsu Kim",
      "AhmedElmogtaba Abdelaziz",
      "Thiago Castro Ferreira",
      "Mohamed Al-Badrashiny",
      "Hassan Sawaf"
    ],
    "abstract": "As the demand for artificial intelligence (AI) grows to address complex\nreal-world tasks, single models are often insufficient, requiring the\nintegration of multiple models into pipelines. This paper introduces Bel\nEsprit, a conversational agent designed to construct AI model pipelines based\non user-defined requirements. Bel Esprit employs a multi-agent framework where\nsubagents collaborate to clarify requirements, build, validate, and populate\npipelines with appropriate models. We demonstrate the effectiveness of this\nframework in generating pipelines from ambiguous user queries, using both\nhuman-curated and synthetic data. A detailed error analysis highlights ongoing\nchallenges in pipeline construction. Bel Esprit is available for a free trial\nat https://belesprit.aixplain.com.",
    "categories": [
      "cs.AI",
      "cs.HC",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.14684v1",
    "published_date": "2024-12-19 09:36:33 UTC",
    "updated_date": "2024-12-19 09:36:33 UTC"
  },
  {
    "arxiv_id": "2412.14680v2",
    "title": "A Light-Weight Framework for Open-Set Object Detection with Decoupled Feature Alignment in Joint Space",
    "authors": [
      "Yonghao He",
      "Hu Su",
      "Haiyong Yu",
      "Cong Yang",
      "Wei Sui",
      "Cong Wang",
      "Song Liu"
    ],
    "abstract": "Open-set object detection (OSOD) is highly desirable for robotic manipulation\nin unstructured environments. However, existing OSOD methods often fail to meet\nthe requirements of robotic applications due to their high computational burden\nand complex deployment. To address this issue, this paper proposes a\nlight-weight framework called Decoupled OSOD (DOSOD), which is a practical and\nhighly efficient solution to support real-time OSOD tasks in robotic systems.\nSpecifically, DOSOD builds upon the YOLO-World pipeline by integrating a\nvision-language model (VLM) with a detector. A Multilayer Perceptron (MLP)\nadaptor is developed to transform text embeddings extracted by the VLM into a\njoint space, within which the detector learns the region representations of\nclass-agnostic proposals. Cross-modality features are directly aligned in the\njoint space, avoiding the complex feature interactions and thereby improving\ncomputational efficiency. DOSOD operates like a traditional closed-set detector\nduring the testing phase, effectively bridging the gap between closed-set and\nopen-set detection. Compared to the baseline YOLO-World, the proposed DOSOD\nsignificantly enhances real-time performance while maintaining comparable\naccuracy. The slight DOSOD-S model achieves a Fixed AP of $26.7\\%$, compared to\n$26.2\\%$ for YOLO-World-v1-S and $22.7\\%$ for YOLO-World-v2-S, using similar\nbackbones on the LVIS minival dataset. Meanwhile, the FPS of DOSOD-S is\n$57.1\\%$ higher than YOLO-World-v1-S and $29.6\\%$ higher than YOLO-World-v2-S.\nMeanwhile, we demonstrate that the DOSOD model facilitates the deployment of\nedge devices. The codes and models are publicly available at\nhttps://github.com/D-Robotics-AI-Lab/DOSOD.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.14680v2",
    "published_date": "2024-12-19 09:32:53 UTC",
    "updated_date": "2024-12-25 12:22:27 UTC"
  },
  {
    "arxiv_id": "2412.14672v2",
    "title": "FiVL: A Framework for Improved Vision-Language Alignment through the Lens of Training, Evaluation and Explainability",
    "authors": [
      "Estelle Aflalo",
      "Gabriela Ben Melech Stan",
      "Tiep Le",
      "Man Luo",
      "Shachar Rosenman",
      "Sayak Paul",
      "Shao-Yen Tseng",
      "Vasudev Lal"
    ],
    "abstract": "Large Vision Language Models (LVLMs) have achieved significant progress in\nintegrating visual and textual inputs for multimodal reasoning. However, a\nrecurring challenge is ensuring these models utilize visual information as\neffectively as linguistic content when both modalities are necessary to\nformulate an accurate answer. We hypothesize that hallucinations arise due to\nthe lack of effective visual grounding in current LVLMs. Furthermore, current\nvision-language benchmarks are not specifically measuring the degree to which\nthe answer require the visual input. This limitation makes it challenging to\nconfirm that the image is truly necessary, particularly in tasks like visual\nquestion answering. In this work, we introduce FiVL, a novel method for\nconstructing datasets designed to train LVLMs for enhanced visual grounding and\nalso evaluate their effectiveness in achieving it. We demonstrate the value of\nour datasets through three approaches. First, we introduce a novel training\ntask based on our augmented training dataset, resulting in better performance\nthan the baseline. Second, we present benchmarks to assess the model's ability\nto use image as substantive evidence, rather than relying solely on linguistic\npriors. Finally, we identify attention heads with the strongest vision-language\nalignment, enabling explainability on visual-driven hallucinations. The code is\navailable at https://github.com/IntelLabs/fivl.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.14672v2",
    "published_date": "2024-12-19 09:24:10 UTC",
    "updated_date": "2025-03-19 12:04:30 UTC"
  },
  {
    "arxiv_id": "2412.14670v1",
    "title": "Analysis and Visualization of Linguistic Structures in Large Language Models: Neural Representations of Verb-Particle Constructions in BERT",
    "authors": [
      "Hassane Kissane",
      "Achim Schilling",
      "Patrick Krauss"
    ],
    "abstract": "This study investigates the internal representations of verb-particle\ncombinations within transformer-based large language models (LLMs),\nspecifically examining how these models capture lexical and syntactic nuances\nat different neural network layers. Employing the BERT architecture, we analyse\nthe representational efficacy of its layers for various verb-particle\nconstructions such as 'agree on', 'come back', and 'give up'. Our methodology\nincludes a detailed dataset preparation from the British National Corpus,\nfollowed by extensive model training and output analysis through techniques\nlike multi-dimensional scaling (MDS) and generalized discrimination value (GDV)\ncalculations. Results show that BERT's middle layers most effectively capture\nsyntactic structures, with significant variability in representational accuracy\nacross different verb categories. These findings challenge the conventional\nuniformity assumed in neural network processing of linguistic elements and\nsuggest a complex interplay between network architecture and linguistic\nrepresentation. Our research contributes to a better understanding of how deep\nlearning models comprehend and process language, offering insights into the\npotential and limitations of current neural approaches to linguistic analysis.\nThis study not only advances our knowledge in computational linguistics but\nalso prompts further research into optimizing neural architectures for enhanced\nlinguistic precision.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.14670v1",
    "published_date": "2024-12-19 09:21:39 UTC",
    "updated_date": "2024-12-19 09:21:39 UTC"
  },
  {
    "arxiv_id": "2412.14668v2",
    "title": "LoLaFL: Low-Latency Federated Learning via Forward-only Propagation",
    "authors": [
      "Jierui Zhang",
      "Jianhao Huang",
      "Kaibin Huang"
    ],
    "abstract": "Federated learning (FL) has emerged as a widely adopted paradigm for enabling\nedge learning with distributed data while ensuring data privacy. However, the\ntraditional FL with deep neural networks trained via backpropagation can hardly\nmeet the low-latency learning requirements in the sixth generation (6G) mobile\nnetworks. This challenge mainly arises from the high-dimensional model\nparameters to be transmitted and the numerous rounds of communication required\nfor convergence due to the inherent randomness of the training process. To\naddress this issue, we adopt the state-of-the-art principle of maximal coding\nrate reduction to learn linear discriminative features and extend the resultant\nwhite-box neural network into FL, yielding the novel framework of Low-Latency\nFederated Learning (LoLaFL) via forward-only propagation. LoLaFL enables\nlayer-wise transmissions and aggregation with significantly fewer communication\nrounds, thereby considerably reducing latency. Additionally, we propose two\n\\emph{nonlinear} aggregation schemes for LoLaFL. The first scheme is based on\nthe proof that the optimal NN parameter aggregation in LoLaFL should be\nharmonic-mean-like. The second scheme further exploits the low-rank structures\nof the features and transmits the low-rank-approximated covariance matrices of\nfeatures to achieve additional latency reduction. Theoretic analysis and\nexperiments are conducted to evaluate the performance of LoLaFL. In comparison\nwith traditional FL, the two nonlinear aggregation schemes for LoLaFL can\nachieve reductions in latency of over 91\\% and 98\\%, respectively, while\nmaintaining comparable accuracies.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NI"
    ],
    "primary_category": "cs.LG",
    "comment": "14 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.14668v2",
    "published_date": "2024-12-19 09:20:27 UTC",
    "updated_date": "2024-12-20 08:51:06 UTC"
  },
  {
    "arxiv_id": "2412.14663v2",
    "title": "IOHunter: Graph Foundation Model to Uncover Online Information Operations",
    "authors": [
      "Marco Minici",
      "Luca Luceri",
      "Francesco Fabbri",
      "Emilio Ferrara"
    ],
    "abstract": "Social media platforms have become vital spaces for public discourse, serving\nas modern agor\\`as where a wide range of voices influence societal narratives.\nHowever, their open nature also makes them vulnerable to exploitation by\nmalicious actors, including state-sponsored entities, who can conduct\ninformation operations (IOs) to manipulate public opinion. The spread of\nmisinformation, false news, and misleading claims threatens democratic\nprocesses and societal cohesion, making it crucial to develop methods for the\ntimely detection of inauthentic activity to protect the integrity of online\ndiscourse. In this work, we introduce a methodology designed to identify users\norchestrating information operations, a.k.a. IO drivers, across various\ninfluence campaigns. Our framework, named IOHunter, leverages the combined\nstrengths of Language Models and Graph Neural Networks to improve\ngeneralization in supervised, scarcely-supervised, and cross-IO contexts. Our\napproach achieves state-of-the-art performance across multiple sets of IOs\noriginating from six countries, significantly surpassing existing approaches.\nThis research marks a step toward developing Graph Foundation Models\nspecifically tailored for the task of IO detection on social media platforms.",
    "categories": [
      "cs.SI",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.SI",
    "comment": "Accepted at AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.14663v2",
    "published_date": "2024-12-19 09:14:24 UTC",
    "updated_date": "2025-03-03 15:32:17 UTC"
  },
  {
    "arxiv_id": "2412.14660v2",
    "title": "Unveiling Uncertainty: A Deep Dive into Calibration and Performance of Multimodal Large Language Models",
    "authors": [
      "Zijun Chen",
      "Wenbo Hu",
      "Guande He",
      "Zhijie Deng",
      "Zheng Zhang",
      "Richang Hong"
    ],
    "abstract": "Multimodal large language models (MLLMs) combine visual and textual data for\ntasks such as image captioning and visual question answering. Proper\nuncertainty calibration is crucial, yet challenging, for reliable use in areas\nlike healthcare and autonomous driving. This paper investigates representative\nMLLMs, focusing on their calibration across various scenarios, including before\nand after visual fine-tuning, as well as before and after multimodal training\nof the base LLMs. We observed miscalibration in their performance, and at the\nsame time, no significant differences in calibration across these scenarios. We\nalso highlight how uncertainty differs between text and images and how their\nintegration affects overall uncertainty. To better understand MLLMs'\nmiscalibration and their ability to self-assess uncertainty, we construct the\nIDK (I don't know) dataset, which is key to evaluating how they handle\nunknowns. Our findings reveal that MLLMs tend to give answers rather than admit\nuncertainty, but this self-assessment improves with proper prompt adjustments.\nFinally, to calibrate MLLMs and enhance model reliability, we propose\ntechniques such as temperature scaling and iterative prompt optimization. Our\nresults provide insights into improving MLLMs for effective and responsible\ndeployment in multimodal applications. Code and IDK dataset:\nhttps://github.com/hfutml/Calibration-MLLM.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to COLING 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.14660v2",
    "published_date": "2024-12-19 09:10:07 UTC",
    "updated_date": "2024-12-25 06:05:36 UTC"
  },
  {
    "arxiv_id": "2412.14640v2",
    "title": "Adaptive Prompt Tuning: Vision Guided Prompt Tuning with Cross-Attention for Fine-Grained Few-Shot Learning",
    "authors": [
      "Eric Brouwer",
      "Jan Erik van Woerden",
      "Gertjan Burghouts",
      "Matias Valdenegro-Toro",
      "Marco Zullich"
    ],
    "abstract": "Few-shot, fine-grained classification in computer vision poses significant\nchallenges due to the need to differentiate subtle class distinctions with\nlimited data. This paper presents a novel method that enhances the Contrastive\nLanguage-Image Pre-Training (CLIP) model through adaptive prompt tuning, guided\nby real-time visual inputs. Unlike existing techniques such as Context\nOptimization (CoOp) and Visual Prompt Tuning (VPT), which are constrained by\nstatic prompts or visual token reliance, the proposed approach leverages a\ncross-attention mechanism to dynamically refine text prompts for the image at\nhand. This enables an image-specific alignment of textual features with image\npatches extracted from the Vision Transformer, making the model more effective\nfor datasets with high intra-class variance and low inter-class differences.\nThe method is evaluated on several datasets, including CUBirds, Oxford Flowers,\nand FGVC Aircraft, showing significant performance gains over static prompt\ntuning approaches. To ensure these performance gains translate into trustworthy\npredictions, we integrate Monte-Carlo Dropout in our approach to improve the\nreliability of the model predictions and uncertainty estimates. This\nintegration provides valuable insights into the model's predictive confidence,\nhelping to identify when predictions can be trusted and when additional\nverification is necessary. This dynamic approach offers a robust solution,\nadvancing the state-of-the-art for few-shot fine-grained classification.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.14640v2",
    "published_date": "2024-12-19 08:51:01 UTC",
    "updated_date": "2025-01-01 18:00:00 UTC"
  },
  {
    "arxiv_id": "2412.14639v2",
    "title": "A Shapley Value Estimation Speedup for Efficient Explainable Quantum AI",
    "authors": [
      "Iain Burge",
      "Michel Barbeau",
      "Joaquin Garcia-Alfaro"
    ],
    "abstract": "This work focuses on developing efficient post-hoc explanations for quantum\nAI algorithms. In classical contexts, the cooperative game theory concept of\nthe Shapley value adapts naturally to post-hoc explanations, where it can be\nused to identify which factors are important in an AI's decision-making\nprocess. An interesting question is how to translate Shapley values to the\nquantum setting and whether quantum effects could be used to accelerate their\ncalculation. We propose quantum algorithms that can extract Shapley values\nwithin some confidence interval. Our method is capable of quadratically\noutperforming classical Monte Carlo approaches to approximating Shapley values\nup to polylogarithmic factors in various circumstances. We demonstrate the\nvalidity of our approach empirically with specific voting games and provide\nrigorous proofs of performance for general cooperative games.",
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "quant-ph",
    "comment": "34 pages, 4 figures, 4 tables, 45 citations",
    "pdf_url": "http://arxiv.org/pdf/2412.14639v2",
    "published_date": "2024-12-19 08:50:46 UTC",
    "updated_date": "2025-04-17 07:00:56 UTC"
  },
  {
    "arxiv_id": "2412.14633v1",
    "title": "Progressive Fine-to-Coarse Reconstruction for Accurate Low-Bit Post-Training Quantization in Vision Transformers",
    "authors": [
      "Rui Ding",
      "Liang Yong",
      "Sihuan Zhao",
      "Jing Nie",
      "Lihui Chen",
      "Haijun Liu",
      "Xichuan Zhou"
    ],
    "abstract": "Due to its efficiency, Post-Training Quantization (PTQ) has been widely\nadopted for compressing Vision Transformers (ViTs). However, when quantized\ninto low-bit representations, there is often a significant performance drop\ncompared to their full-precision counterparts. To address this issue,\nreconstruction methods have been incorporated into the PTQ framework to improve\nperformance in low-bit quantization settings. Nevertheless, existing related\nmethods predefine the reconstruction granularity and seldom explore the\nprogressive relationships between different reconstruction granularities, which\nleads to sub-optimal quantization results in ViTs. To this end, in this paper,\nwe propose a Progressive Fine-to-Coarse Reconstruction (PFCR) method for\naccurate PTQ, which significantly improves the performance of low-bit quantized\nvision transformers. Specifically, we define multi-head self-attention and\nmulti-layer perceptron modules along with their shortcuts as the finest\nreconstruction units. After reconstructing these two fine-grained units, we\ncombine them to form coarser blocks and reconstruct them at a coarser\ngranularity level. We iteratively perform this combination and reconstruction\nprocess, achieving progressive fine-to-coarse reconstruction. Additionally, we\nintroduce a Progressive Optimization Strategy (POS) for PFCR to alleviate the\ndifficulty of training, thereby further enhancing model performance.\nExperimental results on the ImageNet dataset demonstrate that our proposed\nmethod achieves the best Top-1 accuracy among state-of-the-art methods,\nparticularly attaining 75.61% for 3-bit quantized ViT-B in PTQ. Besides,\nquantization results on the COCO dataset reveal the effectiveness and\ngeneralization of our proposed method on other computer vision tasks like\nobject detection and instance segmentation.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.14633v1",
    "published_date": "2024-12-19 08:38:59 UTC",
    "updated_date": "2024-12-19 08:38:59 UTC"
  },
  {
    "arxiv_id": "2412.14626v1",
    "title": "Learning to Generate Research Idea with Dynamic Control",
    "authors": [
      "Ruochen Li",
      "Liqiang Jing",
      "Chi Han",
      "Jiawei Zhou",
      "Xinya Du"
    ],
    "abstract": "The rapid advancements in large language models (LLMs) have demonstrated\ntheir potential to accelerate scientific discovery, particularly in automating\nthe process of research ideation. LLM-based systems have shown promise in\ngenerating hypotheses and research ideas. However, current approaches\npredominantly rely on prompting-based pre-trained models, limiting their\nability to optimize generated content effectively. Moreover, they also lack the\ncapability to deal with the complex interdependence and inherent restrictions\namong novelty, feasibility, and effectiveness, which remains challenging due to\nthe inherent trade-offs among these dimensions, such as the\ninnovation-feasibility conflict. To address these limitations, we for the first\ntime propose fine-tuning LLMs to be better idea proposers and introduce a novel\nframework that employs a two-stage approach combining Supervised Fine-Tuning\n(SFT) and controllable Reinforcement Learning (RL). In the SFT stage, the model\nlearns foundational patterns from pairs of research papers and follow-up ideas.\nIn the RL stage, multi-dimensional reward modeling, guided by fine-grained\nfeedback, evaluates and optimizes the generated ideas across key metrics.\nDimensional controllers enable dynamic adjustment of generation, while a\nsentence-level decoder ensures context-aware emphasis during inference. Our\nframework provides a balanced approach to research ideation, achieving\nhigh-quality outcomes by dynamically navigating the trade-offs among novelty,\nfeasibility, and effectiveness.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.14626v1",
    "published_date": "2024-12-19 08:28:18 UTC",
    "updated_date": "2024-12-19 08:28:18 UTC"
  },
  {
    "arxiv_id": "2412.14619v1",
    "title": "Pitfalls of topology-aware image segmentation",
    "authors": [
      "Alexander H. Berger",
      "Laurin Lux",
      "Alexander Weers",
      "Martin Menten",
      "Daniel Rueckert",
      "Johannes C. Paetzold"
    ],
    "abstract": "Topological correctness, i.e., the preservation of structural integrity and\nspecific characteristics of shape, is a fundamental requirement for medical\nimaging tasks, such as neuron or vessel segmentation. Despite the recent surge\nin topology-aware methods addressing this challenge, their real-world\napplicability is hindered by flawed benchmarking practices. In this paper, we\nidentify critical pitfalls in model evaluation that include inadequate\nconnectivity choices, overlooked topological artifacts in ground truth\nannotations, and inappropriate use of evaluation metrics. Through detailed\nempirical analysis, we uncover these issues' profound impact on the evaluation\nand ranking of segmentation methods. Drawing from our findings, we propose a\nset of actionable recommendations to establish fair and robust evaluation\nstandards for topology-aware medical image segmentation methods.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Code is available at\n  https://github.com/AlexanderHBerger/topo-pitfalls",
    "pdf_url": "http://arxiv.org/pdf/2412.14619v1",
    "published_date": "2024-12-19 08:11:42 UTC",
    "updated_date": "2024-12-19 08:11:42 UTC"
  },
  {
    "arxiv_id": "2412.14617v1",
    "title": "How good is GPT at writing political speeches for the White House?",
    "authors": [
      "Jacques Savoy"
    ],
    "abstract": "Using large language models (LLMs), computers are able to generate a written\ntext in response to a us er request. As this pervasive technology can be\napplied in numerous contexts, this study analyses the written style of one LLM\ncalled GPT by comparing its generated speeches with those of the recent US\npresidents. To achieve this objective, the State of the Union (SOTU) addresses\nwritten by Reagan to Biden are contrasted to those produced by both GPT-3.5 and\nGPT-4.o versions. Compared to US presidents, GPT tends to overuse the lemma\n\"we\" and produce shorter messages with, on average, longer sentences. Moreover,\nGPT opts for an optimistic tone, opting more often for political (e.g.,\npresident, Congress), symbolic (e.g., freedom), and abstract terms (e.g.,\nfreedom). Even when imposing an author's style to GPT, the resulting speech\nremains distinct from addresses written by the target author. Finally, the two\nGPT versions present distinct characteristics, but both appear overall\ndissimilar to true presidential messages.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.14617v1",
    "published_date": "2024-12-19 08:06:09 UTC",
    "updated_date": "2024-12-19 08:06:09 UTC"
  },
  {
    "arxiv_id": "2412.14613v2",
    "title": "Multi-modal, Multi-task, Multi-criteria Automatic Evaluation with Vision Language Models",
    "authors": [
      "Masanari Ohi",
      "Masahiro Kaneko",
      "Naoaki Okazaki",
      "Nakamasa Inoue"
    ],
    "abstract": "Vision-language models (VLMs) have shown impressive abilities across a range\nof multi-modal tasks. However, existing metrics for evaluating the quality of\ntext generated by VLMs typically focus on an overall evaluation for a specific\ntask, such as image captioning. While the overall evaluation is essential for\nany task, the criteria prioritized can differ depending on the task, making it\nchallenging for current metrics to adapt to multi-task scenarios. To address\nthis limitation, we propose HarmonicEval, a reference-free comprehensive\nevaluation metric that aggregates criterion-wise scores to produce the overall\nscore in a bottom-up manner. Furthermore, we construct the Multi-task\nMulti-criteria Human Evaluation (MMHE) dataset, which comprises 18,000 expert\nhuman judgments across four multi-modal tasks. Our experiments demonstrate that\nHarmonicEval achieves higher correlations with human judgments than\nconventional metrics while providing numerical scores for each criterion.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.14613v2",
    "published_date": "2024-12-19 08:03:16 UTC",
    "updated_date": "2025-02-28 03:04:05 UTC"
  },
  {
    "arxiv_id": "2412.14602v2",
    "title": "Towards Scalable and Deep Graph Neural Networks via Noise Masking",
    "authors": [
      "Yuxuan Liang",
      "Wentao Zhang",
      "Zeang Sheng",
      "Ling Yang",
      "Quanqing Xu",
      "Jiawei Jiang",
      "Yunhai Tong",
      "Bin Cui"
    ],
    "abstract": "In recent years, Graph Neural Networks (GNNs) have achieved remarkable\nsuccess in many graph mining tasks. However, scaling them to large graphs is\nchallenging due to the high computational and storage costs of repeated feature\npropagation and non-linear transformation during training. One commonly\nemployed approach to address this challenge is model-simplification, which only\nexecutes the Propagation (P) once in the pre-processing, and Combine (C) these\nreceptive fields in different ways and then feed them into a simple model for\nbetter performance. Despite their high predictive performance and scalability,\nthese methods still face two limitations. First, existing approaches mainly\nfocus on exploring different C methods from the model perspective, neglecting\nthe crucial problem of performance degradation with increasing P depth from the\ndata-centric perspective, known as the over-smoothing problem. Second,\npre-processing overhead takes up most of the end-to-end processing time,\nespecially for large-scale graphs. To address these limitations, we present\nrandom walk with noise masking (RMask), a plug-and-play module compatible with\nthe existing model-simplification works. This module enables the exploration of\ndeeper GNNs while preserving their scalability. Unlike the previous\nmodel-simplification works, we focus on continuous P and found that the noise\nexisting inside each P is the cause of the over-smoothing issue, and use the\nefficient masking mechanism to eliminate them. Experimental results on six\nreal-world datasets demonstrate that model-simplification works equipped with\nRMask yield superior performance compared to their original version and can\nmake a good trade-off between accuracy and efficiency.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.14602v2",
    "published_date": "2024-12-19 07:48:14 UTC",
    "updated_date": "2025-04-10 02:16:19 UTC"
  },
  {
    "arxiv_id": "2412.15294v1",
    "title": "A Universal Model for Human Mobility Prediction",
    "authors": [
      "Qingyue Long",
      "Yuan Yuan",
      "Yong Li"
    ],
    "abstract": "Predicting human mobility is crucial for urban planning, traffic control, and\nemergency response. Mobility behaviors can be categorized into individual and\ncollective, and these behaviors are recorded by diverse mobility data, such as\nindividual trajectory and crowd flow. As different modalities of mobility data,\nindividual trajectory and crowd flow have a close coupling relationship. Crowd\nflows originate from the bottom-up aggregation of individual trajectories,\nwhile the constraints imposed by crowd flows shape these individual\ntrajectories. Existing mobility prediction methods are limited to single tasks\ndue to modal gaps between individual trajectory and crowd flow. In this work,\nwe aim to unify mobility prediction to break through the limitations of\ntask-specific models. We propose a universal human mobility prediction model\n(named UniMob), which can be applied to both individual trajectory and crowd\nflow. UniMob leverages a multi-view mobility tokenizer that transforms both\ntrajectory and flow data into spatiotemporal tokens, facilitating unified\nsequential modeling through a diffusion transformer architecture. To bridge the\ngap between the different characteristics of these two data modalities, we\nimplement a novel bidirectional individual and collective alignment mechanism.\nThis mechanism enables learning common spatiotemporal patterns from different\nmobility data, facilitating mutual enhancement of both trajectory and flow\npredictions. Extensive experiments on real-world datasets validate the\nsuperiority of our model over state-of-the-art baselines in trajectory and flow\nprediction. Especially in noisy and scarce data scenarios, our model achieves\nthe highest performance improvement of more than 14% and 25% in MAPE and\nAccuracy@5.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.15294v1",
    "published_date": "2024-12-19 07:38:13 UTC",
    "updated_date": "2024-12-19 07:38:13 UTC"
  },
  {
    "arxiv_id": "2412.15292v1",
    "title": "Deep reinforcement learning with time-scale invariant memory",
    "authors": [
      "Md Rysul Kabir",
      "James Mochizuki-Freeman",
      "Zoran Tiganj"
    ],
    "abstract": "The ability to estimate temporal relationships is critical for both animals\nand artificial agents. Cognitive science and neuroscience provide remarkable\ninsights into behavioral and neural aspects of temporal credit assignment. In\nparticular, scale invariance of learning dynamics, observed in behavior and\nsupported by neural data, is one of the key principles that governs animal\nperception: proportional rescaling of temporal relationships does not alter the\noverall learning efficiency. Here we integrate a computational neuroscience\nmodel of scale invariant memory into deep reinforcement learning (RL) agents.\nWe first provide a theoretical analysis and then demonstrate through\nexperiments that such agents can learn robustly across a wide range of temporal\nscales, unlike agents built with commonly used recurrent memory architectures\nsuch as LSTM. This result illustrates that incorporating computational\nprinciples from neuroscience and cognitive science into deep neural networks\ncan enhance adaptability to complex temporal dynamics, mirroring some of the\ncore properties of human learning.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.15292v1",
    "published_date": "2024-12-19 07:20:03 UTC",
    "updated_date": "2024-12-19 07:20:03 UTC"
  },
  {
    "arxiv_id": "2412.14587v1",
    "title": "Spike2Former: Efficient Spiking Transformer for High-performance Image Segmentation",
    "authors": [
      "Zhenxin Lei",
      "Man Yao",
      "Jiakui Hu",
      "Xinhao Luo",
      "Yanye Lu",
      "Bo Xu",
      "Guoqi Li"
    ],
    "abstract": "Spiking Neural Networks (SNNs) have a low-power advantage but perform poorly\nin image segmentation tasks. The reason is that directly converting neural\nnetworks with complex architectural designs for segmentation tasks into spiking\nversions leads to performance degradation and non-convergence. To address this\nchallenge, we first identify the modules in the architecture design that lead\nto the severe reduction in spike firing, make targeted improvements, and\npropose Spike2Former architecture. Second, we propose normalized integer\nspiking neurons to solve the training stability problem of SNNs with complex\narchitectures. We set a new state-of-the-art for SNNs in various semantic\nsegmentation datasets, with a significant improvement of +12.7% mIoU and 5.0\nefficiency on ADE20K, +14.3% mIoU and 5.2 efficiency on VOC2012, and +9.1% mIoU\nand 6.6 efficiency on CityScapes.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.CV",
    "comment": "This work has been accepted on Association for the Advancement of\n  Artificial Intelligence 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.14587v1",
    "published_date": "2024-12-19 07:13:15 UTC",
    "updated_date": "2024-12-19 07:13:15 UTC"
  },
  {
    "arxiv_id": "2412.14579v1",
    "title": "GSRender: Deduplicated Occupancy Prediction via Weakly Supervised 3D Gaussian Splatting",
    "authors": [
      "Qianpu Sun",
      "Changyong Shu",
      "Sifan Zhou",
      "Zichen Yu",
      "Yan Chen",
      "Dawei Yang",
      "Yuan Chun"
    ],
    "abstract": "3D occupancy perception is gaining increasing attention due to its capability\nto offer detailed and precise environment representations. Previous\nweakly-supervised NeRF methods balance efficiency and accuracy, with mIoU\nvarying by 5-10 points due to sampling count along camera rays. Recently,\nreal-time Gaussian splatting has gained widespread popularity in 3D\nreconstruction, and the occupancy prediction task can also be viewed as a\nreconstruction task. Consequently, we propose GSRender, which naturally employs\n3D Gaussian Splatting for occupancy prediction, simplifying the sampling\nprocess. In addition, the limitations of 2D supervision result in duplicate\npredictions along the same camera ray. We implemented the Ray Compensation (RC)\nmodule, which mitigates this issue by compensating for features from adjacent\nframes. Finally, we redesigned the loss to eliminate the impact of dynamic\nobjects from adjacent frames. Extensive experiments demonstrate that our\napproach achieves SOTA (state-of-the-art) results in RayIoU (+6.0), while\nnarrowing the gap with 3D supervision methods. Our code will be released soon.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.14579v1",
    "published_date": "2024-12-19 06:57:37 UTC",
    "updated_date": "2024-12-19 06:57:37 UTC"
  },
  {
    "arxiv_id": "2412.14571v1",
    "title": "SCKD: Semi-Supervised Cross-Modality Knowledge Distillation for 4D Radar Object Detection",
    "authors": [
      "Ruoyu Xu",
      "Zhiyu Xiang",
      "Chenwei Zhang",
      "Hanzhi Zhong",
      "Xijun Zhao",
      "Ruina Dang",
      "Peng Xu",
      "Tianyu Pu",
      "Eryun Liu"
    ],
    "abstract": "3D object detection is one of the fundamental perception tasks for autonomous\nvehicles. Fulfilling such a task with a 4D millimeter-wave radar is very\nattractive since the sensor is able to acquire 3D point clouds similar to Lidar\nwhile maintaining robust measurements under adverse weather. However, due to\nthe high sparsity and noise associated with the radar point clouds, the\nperformance of the existing methods is still much lower than expected. In this\npaper, we propose a novel Semi-supervised Cross-modality Knowledge Distillation\n(SCKD) method for 4D radar-based 3D object detection. It characterizes the\ncapability of learning the feature from a Lidar-radar-fused teacher network\nwith semi-supervised distillation. We first propose an adaptive fusion module\nin the teacher network to boost its performance. Then, two feature distillation\nmodules are designed to facilitate the cross-modality knowledge transfer.\nFinally, a semi-supervised output distillation is proposed to increase the\neffectiveness and flexibility of the distillation framework. With the same\nnetwork structure, our radar-only student trained by SCKD boosts the mAP by\n10.38% over the baseline and outperforms the state-of-the-art works on the VoD\ndataset. The experiment on ZJUODset also shows 5.12% mAP improvements on the\nmoderate difficulty level over the baseline when extra unlabeled data are\navailable. Code is available at https://github.com/Ruoyu-Xu/SCKD.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.14571v1",
    "published_date": "2024-12-19 06:42:25 UTC",
    "updated_date": "2024-12-19 06:42:25 UTC"
  },
  {
    "arxiv_id": "2412.14570v2",
    "title": "Characterising Simulation-Based Program Equilibria",
    "authors": [
      "Emery Cooper",
      "Caspar Oesterheld",
      "Vincent Conitzer"
    ],
    "abstract": "In Tennenholtz's program equilibrium, players of a game submit programs to\nplay on their behalf. Each program receives the other programs' source code and\noutputs an action. This can model interactions involving AI agents, mutually\ntransparent institutions, or commitments. Tennenholtz (2004) proves a folk\ntheorem for program games, but the equilibria constructed are very brittle. We\ntherefore consider simulation-based programs -- i.e., programs that work by\nrunning opponents' programs. These are relatively robust (in particular, two\nprograms that act the same are treated the same) and are more practical than\nproof-based approaches. Oesterheld's (2019) $\\epsilon$Grounded$\\pi$Bot is such\nan approach. Unfortunately, it is not generally applicable to games of three or\nmore players, and only allows for a limited range of equilibria in two player\ngames. In this paper, we propose a generalisation to Oesterheld's (2019)\n$\\epsilon$Grounded$\\pi$Bot. We prove a folk theorem for our programs in a\nsetting with access to a shared source of randomness. We then characterise\ntheir equilibria in a setting without shared randomness. Both with and without\nshared randomness, we achieve a much wider range of equilibria than\nOesterheld's (2019) $\\epsilon$Grounded$\\pi$Bot. Finally, we explore the limits\nof simulation-based program equilibrium, showing that the Tennenholtz folk\ntheorem cannot be attained by simulation-based programs without access to\nshared randomness.",
    "categories": [
      "cs.GT",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.GT",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.14570v2",
    "published_date": "2024-12-19 06:41:06 UTC",
    "updated_date": "2025-01-20 23:37:35 UTC"
  },
  {
    "arxiv_id": "2412.14569v1",
    "title": "Global Spatio-Temporal Fusion-based Traffic Prediction Algorithm with Anomaly Aware",
    "authors": [
      "Chaoqun Liu",
      "Xuanpeng Li",
      "Chen Gong",
      "Guangyu Li"
    ],
    "abstract": "Traffic prediction is an indispensable component of urban planning and\ntraffic management. Achieving accurate traffic prediction hinges on the ability\nto capture the potential spatio-temporal relationships among road sensors.\nHowever, the majority of existing works focus on local short-term\nspatio-temporal correlations, failing to fully consider the interactions of\ndifferent sensors in the long-term state. In addition, these works do not\nanalyze the influences of anomalous factors, or have insufficient ability to\nextract personalized features of anomalous factors, which make them\nineffectively capture their spatio-temporal influences on traffic prediction.\nTo address the aforementioned issues, We propose a global spatio-temporal\nfusion-based traffic prediction algorithm that incorporates anomaly awareness.\nInitially, based on the designed anomaly detection network, we construct an\nefficient anomalous factors impacting module (AFIM), to evaluate the\nspatio-temporal impact of unexpected external events on traffic prediction.\nFurthermore, we propose a multi-scale spatio-temporal feature fusion module\n(MTSFFL) based on the transformer architecture, to obtain all possible both\nlong and short term correlations among different sensors in a wide-area traffic\nenvironment for accurate prediction of traffic flow. Finally, experiments are\nimplemented based on real-scenario public transportation datasets (PEMS04 and\nPEMS08) to demonstrate that our approach can achieve state-of-the-art\nperformance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.14569v1",
    "published_date": "2024-12-19 06:40:21 UTC",
    "updated_date": "2024-12-19 06:40:21 UTC"
  },
  {
    "arxiv_id": "2412.14566v3",
    "title": "AIArena: A Blockchain-Based Decentralized AI Training Platform",
    "authors": [
      "Zhipeng Wang",
      "Rui Sun",
      "Elizabeth Lui",
      "Tuo Zhou",
      "Yizhe Wen",
      "Jiahao Sun"
    ],
    "abstract": "The rapid advancement of AI has underscored critical challenges in its\ndevelopment and implementation, largely due to centralized control by a few\nmajor corporations. This concentration of power intensifies biases within AI\nmodels, resulting from inadequate governance and oversight mechanisms.\nAdditionally, it limits public involvement and heightens concerns about the\nintegrity of model generation. Such monopolistic control over data and AI\noutputs threatens both innovation and fair data usage, as users inadvertently\ncontribute data that primarily benefits these corporations. In this work, we\npropose AIArena, a blockchain-based decentralized AI training platform designed\nto democratize AI development and alignment through on-chain incentive\nmechanisms. AIArena fosters an open and collaborative environment where\nparticipants can contribute models and computing resources. Its on-chain\nconsensus mechanism ensures fair rewards for participants based on their\ncontributions. We instantiate and implement AIArena on the public Base\nblockchain Sepolia testnet, and the evaluation results demonstrate the\nfeasibility of AIArena in real-world applications.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.DC",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "Camera ready version. Accepted by the ACM Web Conference (WWW) Short\n  Paper Track, 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.14566v3",
    "published_date": "2024-12-19 06:35:54 UTC",
    "updated_date": "2025-04-11 08:10:03 UTC"
  },
  {
    "arxiv_id": "2412.15289v2",
    "title": "SATA: A Paradigm for LLM Jailbreak via Simple Assistive Task Linkage",
    "authors": [
      "Xiaoning Dong",
      "Wenbo Hu",
      "Wei Xu",
      "Tianxing He"
    ],
    "abstract": "Large language models (LLMs) have made significant advancements across\nvarious tasks, but their safety alignment remain a major concern. Exploring\njailbreak prompts can expose LLMs' vulnerabilities and guide efforts to secure\nthem. Existing methods primarily design sophisticated instructions for the LLM\nto follow, or rely on multiple iterations, which could hinder the performance\nand efficiency of jailbreaks. In this work, we propose a novel jailbreak\nparadigm, Simple Assistive Task Linkage (SATA), which can effectively\ncircumvent LLM safeguards and elicit harmful responses. Specifically, SATA\nfirst masks harmful keywords within a malicious query to generate a relatively\nbenign query containing one or multiple [MASK] special tokens. It then employs\na simple assistive task such as a masked language model task or an element\nlookup by position task to encode the semantics of the masked keywords.\nFinally, SATA links the assistive task with the masked query to jointly perform\nthe jailbreak. Extensive experiments show that SATA achieves state-of-the-art\nperformance and outperforms baselines by a large margin. Specifically, on\nAdvBench dataset, with mask language model (MLM) assistive task, SATA achieves\nan overall attack success rate (ASR) of 85% and harmful score (HS) of 4.57, and\nwith element lookup by position (ELP) assistive task, SATA attains an overall\nASR of 76% and HS of 4.43.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.15289v2",
    "published_date": "2024-12-19 05:57:37 UTC",
    "updated_date": "2025-03-21 13:00:44 UTC"
  },
  {
    "arxiv_id": "2412.14545v1",
    "title": "Summary of Point Transformer with Federated Learning for Predicting Breast Cancer HER2 Status from Hematoxylin and Eosin-Stained Whole Slide Images",
    "authors": [
      "Kamorudeen A. Amuda",
      "Almustapha A. Wakili"
    ],
    "abstract": "This study introduces a federated learning-based approach to predict HER2\nstatus from hematoxylin and eosin (HE)-stained whole slide images (WSIs),\nreducing costs and speeding up treatment decisions. To address label imbalance\nand feature representation challenges in multisite datasets, a point\ntransformer is proposed, incorporating dynamic label distribution, an auxiliary\nclassifier, and farthest cosine sampling. Extensive experiments demonstrate\nstate-of-the-art performance across four sites (2687 WSIs) and strong\ngeneralization to two unseen sites (229 WSIs).",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.14545v1",
    "published_date": "2024-12-19 05:51:46 UTC",
    "updated_date": "2024-12-19 05:51:46 UTC"
  },
  {
    "arxiv_id": "2412.14538v4",
    "title": "Overview of AI and Communication for 6G Network: Fundamentals, Challenges, and Future Research Opportunities",
    "authors": [
      "Qimei Cui",
      "Xiaohu You",
      "Ni Wei",
      "Guoshun Nan",
      "Xuefei Zhang",
      "Jianhua Zhang",
      "Xinchen Lyu",
      "Ming Ai",
      "Xiaofeng Tao",
      "Zhiyong Feng",
      "Ping Zhang",
      "Qingqing Wu",
      "Meixia Tao",
      "Yongming Huang",
      "Chongwen Huang",
      "Guangyi Liu",
      "Chenghui Peng",
      "Zhiwen Pan",
      "Tao Sun",
      "Dusit Niyato",
      "Tao Chen",
      "Muhammad Khurram Khan",
      "Abbas Jamalipour",
      "Mohsen Guizani",
      "Chau Yuen"
    ],
    "abstract": "With the growing demand for seamless connectivity and intelligent\ncommunication, the integration of artificial intelligence (AI) and\nsixth-generation (6G) communication networks has emerged as a transformative\nparadigm. By embedding AI capabilities across various network layers, this\nintegration enables optimized resource allocation, improved efficiency, and\nenhanced system robust performance, particularly in intricate and dynamic\nenvironments. This paper presents a comprehensive overview of AI and\ncommunication for 6G networks, with a focus on emphasizing their foundational\nprinciples, inherent challenges, and future research opportunities. We first\nreview the integration of AI and communications in the context of 6G, exploring\nthe driving factors behind incorporating AI into wireless communications, as\nwell as the vision for the convergence of AI and 6G. The discourse then\ntransitions to a detailed exposition of the envisioned integration of AI within\n6G networks, delineated across three progressive developmental stages. The\nfirst stage, AI for Network, focuses on employing AI to augment network\nperformance, optimize efficiency, and enhance user service experiences. The\nsecond stage, Network for AI, highlights the role of the network in\nfacilitating and buttressing AI operations and presents key enabling\ntechnologies, such as digital twins for AI and semantic communication. In the\nfinal stage, AI as a Service, it is anticipated that future 6G networks will\ninnately provide AI functions as services, supporting application scenarios\nlike immersive communication and intelligent industrial robots. In addition, we\nconduct an in-depth analysis of the critical challenges faced by the\nintegration of AI and communications in 6G. Finally, we outline promising\nfuture research opportunities that are expected to drive the development and\nrefinement of AI and 6G communications.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.NI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.14538v4",
    "published_date": "2024-12-19 05:36:34 UTC",
    "updated_date": "2025-02-13 07:40:46 UTC"
  },
  {
    "arxiv_id": "2412.14522v2",
    "title": "CwA-T: A Channelwise AutoEncoder with Transformer for EEG Abnormality Detection",
    "authors": [
      "Youshen Zhao",
      "Keiji Iramina"
    ],
    "abstract": "Electroencephalogram (EEG) signals are critical for detecting abnormal brain\nactivity, but their high dimensionality and complexity pose significant\nchallenges for effective analysis. In this paper, we propose CwA-T, a novel\nframework that combines a channelwise CNN-based autoencoder with a single-head\ntransformer classifier for efficient EEG abnormality detection. The channelwise\nautoencoder compresses raw EEG signals while preserving channel independence,\nreducing computational costs and retaining biologically meaningful features.\nThe compressed representations are then fed into the transformer-based\nclassifier, which efficiently models long-term dependencies to distinguish\nbetween normal and abnormal signals. Evaluated on the TUH Abnormal EEG Corpus,\nthe proposed model achieves 85.0% accuracy, 76.2% sensitivity, and 91.2%\nspecificity at the per-case level, outperforming baseline models such as\nEEGNet, Deep4Conv, and FusionCNN. Furthermore, CwA-T requires only 202M FLOPs\nand 2.9M parameters, making it significantly more efficient than\ntransformer-based alternatives. The framework retains interpretability through\nits channelwise design, demonstrating great potential for future applications\nin neuroscience research and clinical practice. The source code is available at\nhttps://github.com/YossiZhao/CAE-T.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE",
      "eess.SP",
      "I.2"
    ],
    "primary_category": "cs.LG",
    "comment": "The manuscript consists of 10 pages, including 5 figures. The\n  experimental results are based on evaluations using the TUH Abnormal EEG\n  Corpus",
    "pdf_url": "http://arxiv.org/pdf/2412.14522v2",
    "published_date": "2024-12-19 04:38:34 UTC",
    "updated_date": "2024-12-24 00:56:06 UTC"
  },
  {
    "arxiv_id": "2412.14515v1",
    "title": "Relational Programming with Foundation Models",
    "authors": [
      "Ziyang Li",
      "Jiani Huang",
      "Jason Liu",
      "Felix Zhu",
      "Eric Zhao",
      "William Dodds",
      "Neelay Velingker",
      "Rajeev Alur",
      "Mayur Naik"
    ],
    "abstract": "Foundation models have vast potential to enable diverse AI applications. The\npowerful yet incomplete nature of these models has spurred a wide range of\nmechanisms to augment them with capabilities such as in-context learning,\ninformation retrieval, and code interpreting. We propose Vieira, a declarative\nframework that unifies these mechanisms in a general solution for programming\nwith foundation models. Vieira follows a probabilistic relational paradigm and\ntreats foundation models as stateless functions with relational inputs and\noutputs. It supports neuro-symbolic applications by enabling the seamless\ncombination of such models with logic programs, as well as complex, multi-modal\napplications by streamlining the composition of diverse sub-models. We\nimplement Vieira by extending the Scallop compiler with a foreign interface\nthat supports foundation models as plugins. We implement plugins for 12\nfoundation models including GPT, CLIP, and SAM. We evaluate Vieira on 9\nchallenging tasks that span language, vision, and structured and vector\ndatabases. Our evaluation shows that programs in Vieira are concise, can\nincorporate modern foundation models, and have comparable or better accuracy\nthan competitive baselines.",
    "categories": [
      "cs.AI",
      "cs.PL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.14515v1",
    "published_date": "2024-12-19 04:26:45 UTC",
    "updated_date": "2024-12-19 04:26:45 UTC"
  },
  {
    "arxiv_id": "2412.14510v1",
    "title": "PA-RAG: RAG Alignment via Multi-Perspective Preference Optimization",
    "authors": [
      "Jiayi Wu",
      "Hengyi Cai",
      "Lingyong Yan",
      "Hao Sun",
      "Xiang Li",
      "Shuaiqiang Wang",
      "Dawei Yin",
      "Ming Gao"
    ],
    "abstract": "The emergence of Retrieval-augmented generation (RAG) has alleviated the\nissues of outdated and hallucinatory content in the generation of large\nlanguage models (LLMs), yet it still reveals numerous limitations. When a\ngeneral-purpose LLM serves as the RAG generator, it often suffers from\ninadequate response informativeness, response robustness, and citation quality.\nPast approaches to tackle these limitations, either by incorporating additional\nsteps beyond generating responses or optimizing the generator through\nsupervised fine-tuning (SFT), still failed to align with the RAG requirement\nthoroughly. Consequently, optimizing the RAG generator from multiple preference\nperspectives while maintaining its end-to-end LLM form remains a challenge. To\nbridge this gap, we propose Multiple Perspective Preference Alignment for\nRetrieval-Augmented Generation (PA-RAG), a method for optimizing the generator\nof RAG systems to align with RAG requirements comprehensively. Specifically, we\nconstruct high-quality instruction fine-tuning data and multi-perspective\npreference data by sampling varied quality responses from the generator across\ndifferent prompt documents quality scenarios. Subsequently, we optimize the\ngenerator using SFT and Direct Preference Optimization (DPO). Extensive\nexperiments conducted on four question-answer datasets across three LLMs\ndemonstrate that PA-RAG can significantly enhance the performance of RAG\ngenerators. Our code and datasets are available at\nhttps://github.com/wujwyi/PA-RAG.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.14510v1",
    "published_date": "2024-12-19 04:18:51 UTC",
    "updated_date": "2024-12-19 04:18:51 UTC"
  },
  {
    "arxiv_id": "2412.14500v2",
    "title": "The Digital Ecosystem of Beliefs: does evolution favour AI over humans?",
    "authors": [
      "David M. Bossens",
      "Shanshan Feng",
      "Yew-Soon Ong"
    ],
    "abstract": "As AI systems are integrated into social networks, there are AI safety\nconcerns that AI-generated content may dominate the web, e.g. in popularity or\nimpact on beliefs. To understand such questions, this paper proposes the\nDigital Ecosystem of Beliefs (Digico), the first evolutionary framework for\ncontrolled experimentation with multi-population interactions in simulated\nsocial networks. The framework models a population of agents which change their\nmessaging strategies due to evolutionary updates following a Universal\nDarwinism approach, interact via messages, influence each other's beliefs\nthrough dynamics based on a contagion model, and maintain their beliefs through\ncognitive Lamarckian inheritance. Initial experiments with an abstract\nimplementation of Digico show that: a) when AIs have faster messaging,\nevolution, and more influence in the recommendation algorithm, they get 80% to\n95% of the views, depending on the size of the influence benefit; b) AIs\ndesigned for propaganda can typically convince 50% of humans to adopt extreme\nbeliefs, and up to 85% when agents believe only a limited number of channels;\nc) a penalty for content that violates agents' beliefs reduces propaganda\neffectiveness by up to 8%. We further discuss implications for control (e.g.\nlegislation) and Digico as a means of studying evolutionary principles.",
    "categories": [
      "cs.AI",
      "cs.MA",
      "cs.NE"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.14500v2",
    "published_date": "2024-12-19 03:48:23 UTC",
    "updated_date": "2025-01-08 06:52:05 UTC"
  },
  {
    "arxiv_id": "2412.14497v2",
    "title": "Disentangled Graph Autoencoder for Treatment Effect Estimation",
    "authors": [
      "Di Fan",
      "Renlei Jiang",
      "Yunhao Wen",
      "Chuanhou Gao"
    ],
    "abstract": "Treatment effect estimation from observational data has attracted significant\nattention across various research fields. However, many widely used methods\nrely on the unconfoundedness assumption, which is often unrealistic due to the\ninability to observe all confounders, thereby overlooking the influence of\nlatent confounders. To address this limitation, recent approaches have utilized\nauxiliary network information to infer latent confounders, relaxing this\nassumption. However, these methods often treat observed variables and networks\nas proxies only for latent confounders, which can result in inaccuracies when\ncertain variables influence treatment without affecting outcomes, or vice\nversa. This conflation of distinct latent factors undermines the precision of\ntreatment effect estimation. To overcome this challenge, we propose a novel\ndisentangled variational graph autoencoder for treatment effect estimation on\nnetworked observational data. Our graph encoder disentangles latent factors\ninto instrumental, confounding, adjustment, and noisy factors, while enforcing\nfactor independence using the Hilbert-Schmidt Independence Criterion. Extensive\nexperiments on multiple networked datasets demonstrate that our method\noutperforms state-of-the-art approaches.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "22 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.14497v2",
    "published_date": "2024-12-19 03:44:49 UTC",
    "updated_date": "2025-02-20 11:43:15 UTC"
  },
  {
    "arxiv_id": "2412.14492v1",
    "title": "FaultExplainer: Leveraging Large Language Models for Interpretable Fault Detection and Diagnosis",
    "authors": [
      "Abdullah Khan",
      "Rahul Nahar",
      "Hao Chen",
      "Gonzalo E. Constante Flores",
      "Can Li"
    ],
    "abstract": "Machine learning algorithms are increasingly being applied to fault detection\nand diagnosis (FDD) in chemical processes. However, existing data-driven FDD\nplatforms often lack interpretability for process operators and struggle to\nidentify root causes of previously unseen faults. This paper presents\nFaultExplainer, an interactive tool designed to improve fault detection,\ndiagnosis, and explanation in the Tennessee Eastman Process (TEP).\nFaultExplainer integrates real-time sensor data visualization, Principal\nComponent Analysis (PCA)-based fault detection, and identification of top\ncontributing variables within an interactive user interface powered by large\nlanguage models (LLMs). We evaluate the LLMs' reasoning capabilities in two\nscenarios: one where historical root causes are provided, and one where they\nare not to mimic the challenge of previously unseen faults. Experimental\nresults using GPT-4o and o1-preview models demonstrate the system's strengths\nin generating plausible and actionable explanations, while also highlighting\nits limitations, including reliance on PCA-selected features and occasional\nhallucinations.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.14492v1",
    "published_date": "2024-12-19 03:35:06 UTC",
    "updated_date": "2024-12-19 03:35:06 UTC"
  },
  {
    "arxiv_id": "2412.14491v1",
    "title": "Mediation Analysis for Probabilities of Causation",
    "authors": [
      "Yuta Kawakami",
      "Jin Tian"
    ],
    "abstract": "Probabilities of causation (PoC) offer valuable insights for informed\ndecision-making. This paper introduces novel variants of PoC-controlled direct,\nnatural direct, and natural indirect probability of necessity and sufficiency\n(PNS). These metrics quantify the necessity and sufficiency of a treatment for\nproducing an outcome, accounting for different causal pathways. We develop\nidentification theorems for these new PoC measures, allowing for their\nestimation from observational data. We demonstrate the practical application of\nour results through an analysis of a real-world psychology dataset.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.14491v1",
    "published_date": "2024-12-19 03:28:13 UTC",
    "updated_date": "2024-12-19 03:28:13 UTC"
  },
  {
    "arxiv_id": "2412.14488v4",
    "title": "A stochastic first-order method with multi-extrapolated momentum for highly smooth unconstrained optimization",
    "authors": [
      "Chuan He"
    ],
    "abstract": "In this paper, we consider an unconstrained stochastic optimization problem\nwhere the objective function exhibits high-order smoothness. Specifically, we\npropose a new stochastic first-order method (SFOM) with multi-extrapolated\nmomentum, in which multiple extrapolations are performed in each iteration,\nfollowed by a momentum update based on these extrapolations. We demonstrate\nthat the proposed SFOM can accelerate optimization by exploiting the high-order\nsmoothness of the objective function $f$. Assuming that the $p$th-order\nderivative of $f$ is Lipschitz continuous for some $p\\ge2$, and under\nadditional mild assumptions, we establish that our method achieves a sample\ncomplexity of $\\widetilde{\\mathcal{O}}(\\epsilon^{-(3p+1)/p})$ for finding a\npoint $x$ such that $\\mathbb{E}[\\|\\nabla f(x)\\|]\\le\\epsilon$. To the best of\nour knowledge, this is the first SFOM to leverage arbitrary-order smoothness of\nthe objective function for acceleration, resulting in a sample complexity that\nimproves upon the best-known results without assuming the mean-squared\nsmoothness condition. Preliminary numerical experiments validate the practical\nperformance of our method and support our theoretical findings.",
    "categories": [
      "math.OC",
      "cs.AI",
      "cs.LG",
      "49M05, 49M37, 90C25, 90C30"
    ],
    "primary_category": "math.OC",
    "comment": "An example is provided to illustrate the gap between the smoothness\n  of the objective function itself and the mean-squared smoothness of the\n  stochastic gradient estimator",
    "pdf_url": "http://arxiv.org/pdf/2412.14488v4",
    "published_date": "2024-12-19 03:22:47 UTC",
    "updated_date": "2025-04-08 16:04:37 UTC"
  },
  {
    "arxiv_id": "2412.14485v2",
    "title": "Towards Projected and Incremental Pseudo-Boolean Model Counting",
    "authors": [
      "Suwei Yang",
      "Kuldeep S. Meel"
    ],
    "abstract": "Model counting is a fundamental task that involves determining the number of\nsatisfying assignments to a logical formula, typically in conjunctive normal\nform (CNF). While CNF model counting has received extensive attention over\nrecent decades, interest in Pseudo-Boolean (PB) model counting is just emerging\npartly due to the greater flexibility of PB formulas. As such, we observed\nfeature gaps in existing PB counters such as a lack of support for projected\nand incremental settings, which could hinder adoption. In this work, our main\ncontribution is the introduction of the PB model counter PBCount2, the first\nexact PB model counter with support for projected and incremental model\ncounting. Our counter, PBCount2, uses our Least Occurrence Weighted Min Degree\n(LOW-MD) computation ordering heuristic to support projected model counting and\na cache mechanism to enable incremental model counting. In our evaluations,\nPBCount2 completed at least 1.40x the number of benchmarks of competing methods\nfor projected model counting and at least 1.18x of competing methods in\nincremental model counting.",
    "categories": [
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "To appear in AAAI25",
    "pdf_url": "http://arxiv.org/pdf/2412.14485v2",
    "published_date": "2024-12-19 03:11:33 UTC",
    "updated_date": "2024-12-20 15:18:44 UTC"
  },
  {
    "arxiv_id": "2412.16233v2",
    "title": "WiFi CSI Based Temporal Activity Detection via Dual Pyramid Network",
    "authors": [
      "Zhendong Liu",
      "Le Zhang",
      "Bing Li",
      "Yingjie Zhou",
      "Zhenghua Chen",
      "Ce Zhu"
    ],
    "abstract": "We address the challenge of WiFi-based temporal activity detection and\npropose an efficient Dual Pyramid Network that integrates Temporal Signal\nSemantic Encoders and Local Sensitive Response Encoders. The Temporal Signal\nSemantic Encoder splits feature learning into high and low-frequency\ncomponents, using a novel Signed Mask-Attention mechanism to emphasize\nimportant areas and downplay unimportant ones, with the features fused using\nContraNorm. The Local Sensitive Response Encoder captures fluctuations without\nlearning. These feature pyramids are then combined using a new cross-attention\nfusion mechanism. We also introduce a dataset with over 2,114 activity segments\nacross 553 WiFi CSI samples, each lasting around 85 seconds. Extensive\nexperiments show our method outperforms challenging baselines.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.NI"
    ],
    "primary_category": "cs.CV",
    "comment": "9 pages, 4 figures, AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.16233v2",
    "published_date": "2024-12-19 03:00:45 UTC",
    "updated_date": "2025-01-26 15:22:07 UTC"
  },
  {
    "arxiv_id": "2412.16232v3",
    "title": "Defeasible Visual Entailment: Benchmark, Evaluator, and Reward-Driven Optimization",
    "authors": [
      "Yue Zhang",
      "Liqiang Jing",
      "Vibhav Gogate"
    ],
    "abstract": "We introduce a new task called Defeasible Visual Entailment (DVE), where the\ngoal is to allow the modification of the entailment relationship between an\nimage premise and a text hypothesis based on an additional update. While this\nconcept is well-established in Natural Language Inference, it remains\nunexplored in visual entailment. At a high level, DVE enables models to refine\ntheir initial interpretations, leading to improved accuracy and reliability in\nvarious applications such as detecting misleading information in images,\nenhancing visual question answering, and refining decision-making processes in\nautonomous systems. Existing metrics do not adequately capture the change in\nthe entailment relationship brought by updates. To address this, we propose a\nnovel inference-aware evaluator designed to capture changes in entailment\nstrength induced by updates, using pairwise contrastive learning and\ncategorical information learning. Additionally, we introduce a reward-driven\nupdate optimization method to further enhance the quality of updates generated\nby multimodal models. Experimental results demonstrate the effectiveness of our\nproposed evaluator and optimization method.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.16232v3",
    "published_date": "2024-12-19 02:38:31 UTC",
    "updated_date": "2025-02-08 22:04:37 UTC"
  },
  {
    "arxiv_id": "2412.14468v1",
    "title": "HashAttention: Semantic Sparsity for Faster Inference",
    "authors": [
      "Aditya Desai",
      "Shuo Yang",
      "Alejandro Cuadron",
      "Ana Klimovic",
      "Matei Zaharia",
      "Joseph E. Gonzalez",
      "Ion Stoica"
    ],
    "abstract": "Utilizing longer contexts is increasingly essential to power better AI\nsystems. However, the cost of attending to long contexts is high due to the\ninvolved softmax computation. While the scaled dot-product attention (SDPA)\nexhibits token sparsity, with only a few pivotal tokens significantly\ncontributing to attention, leveraging this sparsity effectively remains an open\nchallenge. Previous methods either suffer from model degradation or require\nconsiderable additional resources. We propose HashAttention --a principled\napproach casting pivotal token identification as a recommendation problem.\nGiven a query, HashAttention encodes keys and queries in Hamming space\ncapturing the required semantic similarity using learned mapping functions.\nHashAttention efficiently identifies pivotal tokens for a given query in this\nHamming space using bitwise operations, and only these pivotal tokens are used\nfor attention computation, significantly improving overall attention\nefficiency. HashAttention can reduce the number of tokens used by a factor of\n$1/32\\times$ for the Llama-3.1-8B model with LongBench, keeping average quality\nloss within 0.6 points, while using only 32 bits per token auxiliary memory. At\n$32\\times$ sparsity, HashAttention is $3{-}6\\times$ faster than LightLLM and\n$2.5{-}4.5\\times$ faster than gpt-fast on Nvidia-L4 GPU.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.14468v1",
    "published_date": "2024-12-19 02:34:15 UTC",
    "updated_date": "2024-12-19 02:34:15 UTC"
  },
  {
    "arxiv_id": "2412.14451v1",
    "title": "CLDG: Contrastive Learning on Dynamic Graphs",
    "authors": [
      "Yiming Xu",
      "Bin Shi",
      "Teng Ma",
      "Bo Dong",
      "Haoyi Zhou",
      "Qinghua Zheng"
    ],
    "abstract": "The graph with complex annotations is the most potent data type, whose\nconstantly evolving motivates further exploration of the unsupervised dynamic\ngraph representation. One of the representative paradigms is graph contrastive\nlearning. It constructs self-supervised signals by maximizing the mutual\ninformation between the statistic graph's augmentation views. However, the\nsemantics and labels may change within the augmentation process, causing a\nsignificant performance drop in downstream tasks. This drawback becomes greatly\nmagnified on dynamic graphs. To address this problem, we designed a simple yet\neffective framework named CLDG. Firstly, we elaborate that dynamic graphs have\ntemporal translation invariance at different levels. Then, we proposed a\nsampling layer to extract the temporally-persistent signals. It will encourage\nthe node to maintain consistent local and global representations, i.e.,\ntemporal translation invariance under the timespan views. The extensive\nexperiments demonstrate the effectiveness and efficiency of the method on seven\ndatasets by outperforming eight unsupervised state-of-the-art baselines and\nshowing competitiveness against four semi-supervised methods. Compared with the\nexisting dynamic graph method, the number of model parameters and training time\nis reduced by an average of 2,001.86 times and 130.31 times on seven datasets,\nrespectively.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by ICDE2023",
    "pdf_url": "http://arxiv.org/pdf/2412.14451v1",
    "published_date": "2024-12-19 01:59:24 UTC",
    "updated_date": "2024-12-19 01:59:24 UTC"
  },
  {
    "arxiv_id": "2412.14444v1",
    "title": "GenHMR: Generative Human Mesh Recovery",
    "authors": [
      "Muhammad Usama Saleem",
      "Ekkasit Pinyoanuntapong",
      "Pu Wang",
      "Hongfei Xue",
      "Srijan Das",
      "Chen Chen"
    ],
    "abstract": "Human mesh recovery (HMR) is crucial in many computer vision applications;\nfrom health to arts and entertainment. HMR from monocular images has\npredominantly been addressed by deterministic methods that output a single\nprediction for a given 2D image. However, HMR from a single image is an\nill-posed problem due to depth ambiguity and occlusions. Probabilistic methods\nhave attempted to address this by generating and fusing multiple plausible 3D\nreconstructions, but their performance has often lagged behind deterministic\napproaches. In this paper, we introduce GenHMR, a novel generative framework\nthat reformulates monocular HMR as an image-conditioned generative task,\nexplicitly modeling and mitigating uncertainties in the 2D-to-3D mapping\nprocess. GenHMR comprises two key components: (1) a pose tokenizer to convert\n3D human poses into a sequence of discrete tokens in a latent space, and (2) an\nimage-conditional masked transformer to learn the probabilistic distributions\nof the pose tokens, conditioned on the input image prompt along with randomly\nmasked token sequence. During inference, the model samples from the learned\nconditional distribution to iteratively decode high-confidence pose tokens,\nthereby reducing 3D reconstruction uncertainties. To further refine the\nreconstruction, a 2D pose-guided refinement technique is proposed to directly\nfine-tune the decoded pose tokens in the latent space, which forces the\nprojected 3D body mesh to align with the 2D pose clues. Experiments on\nbenchmark datasets demonstrate that GenHMR significantly outperforms\nstate-of-the-art methods. Project website can be found at\nhttps://m-usamasaleem.github.io/publication/GenHMR/GenHMR.html",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.14444v1",
    "published_date": "2024-12-19 01:45:58 UTC",
    "updated_date": "2024-12-19 01:45:58 UTC"
  },
  {
    "arxiv_id": "2412.14436v1",
    "title": "ORBIT: Cost-Effective Dataset Curation for Large Language Model Domain Adaptation with an Astronomy Case Study",
    "authors": [
      "Eric Modesitt",
      "Ke Yang",
      "Spencer Hulsey",
      "Chengxiang Zhai",
      "Volodymyr Kindratenko"
    ],
    "abstract": "Recent advances in language modeling demonstrate the need for high-quality\ndomain-specific training data, especially for tasks that require specialized\nknowledge. General-purpose models, while versatile, often lack the depth needed\nfor expert-level tasks because of limited domain-specific information. Domain\nadaptation training can enhance these models, but it demands substantial,\nhigh-quality data. To address this, we propose ORBIT, a cost-efficient\nmethodology for curating massive, high-quality domain-specific datasets from\nnoisy web sources, tailored for training specialist large language models.\nUsing astronomy as a primary case study, we refined the 1.3T-token FineWeb-Edu\ndataset into a high-quality, 10B-token subset focused on astronomy. Fine-tuning\n\\textsc{LLaMA-3-8B} on a 1B-token astronomy subset improved performance on the\nMMLU astronomy benchmark from 69\\% to 76\\% and achieved top results on\nAstroBench, an astronomy-specific benchmark. Moreover, our model (Orbit-LLaMA)\noutperformed \\textsc{LLaMA-3-8B-base}, with GPT-4o evaluations preferring it in\n73\\% of cases across 1000 astronomy-specific questions. Additionally, we\nvalidated ORBIT's generalizability by applying it to law and medicine,\nachieving a significant improvement of data quality compared to an unfiltered\nbaseline. We open-source the ORBIT methodology, including the curated datasets,\nthe codebase, and the resulting model at\n\\href{https://github.com/ModeEric/ORBIT-Llama}{https://github.com/ModeEric/ORBIT-Llama}.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.14436v1",
    "published_date": "2024-12-19 01:35:47 UTC",
    "updated_date": "2024-12-19 01:35:47 UTC"
  },
  {
    "arxiv_id": "2412.14435v1",
    "title": "Cherry-Picking in Time Series Forecasting: How to Select Datasets to Make Your Model Shine",
    "authors": [
      "Luis Roque",
      "Carlos Soares",
      "Vitor Cerqueira",
      "Luis Torgo"
    ],
    "abstract": "The importance of time series forecasting drives continuous research and the\ndevelopment of new approaches to tackle this problem. Typically, these methods\nare introduced through empirical studies that frequently claim superior\naccuracy for the proposed approaches. Nevertheless, concerns are rising about\nthe reliability and generalizability of these results due to limitations in\nexperimental setups. This paper addresses a critical limitation: the number and\nrepresentativeness of the datasets used. We investigate the impact of dataset\nselection bias, particularly the practice of cherry-picking datasets, on the\nperformance evaluation of forecasting methods. Through empirical analysis with\na diverse set of benchmark datasets, our findings reveal that cherry-picking\ndatasets can significantly distort the perceived performance of methods, often\nexaggerating their effectiveness. Furthermore, our results demonstrate that by\nselectively choosing just four datasets - what most studies report - 46% of\nmethods could be deemed best in class, and 77% could rank within the top three.\nAdditionally, recent deep learning-based approaches show high sensitivity to\ndataset selection, whereas classical methods exhibit greater robustness.\nFinally, our results indicate that, when empirically validating forecasting\nalgorithms on a subset of the benchmarks, increasing the number of datasets\ntested from 3 to 6 reduces the risk of incorrectly identifying an algorithm as\nthe best one by approximately 40%. Our study highlights the critical need for\ncomprehensive evaluation frameworks that more accurately reflect real-world\nscenarios. Adopting such frameworks will ensure the development of robust and\nreliable forecasting methods.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "68T01",
      "I.5.1; G.3; H.2.8; I.2.1"
    ],
    "primary_category": "cs.LG",
    "comment": "Proceedings of the 39th AAAI Conference on Artificial Intelligence\n  (AAAI-25), February 25-March 4, 2025, Philadelphia, Pennsylvania, USA",
    "pdf_url": "http://arxiv.org/pdf/2412.14435v1",
    "published_date": "2024-12-19 01:34:17 UTC",
    "updated_date": "2024-12-19 01:34:17 UTC"
  },
  {
    "arxiv_id": "2412.17847v2",
    "title": "Bridging the Data Provenance Gap Across Text, Speech and Video",
    "authors": [
      "Shayne Longpre",
      "Nikhil Singh",
      "Manuel Cherep",
      "Kushagra Tiwary",
      "Joanna Materzynska",
      "William Brannon",
      "Robert Mahari",
      "Naana Obeng-Marnu",
      "Manan Dey",
      "Mohammed Hamdy",
      "Nayan Saxena",
      "Ahmad Mustafa Anis",
      "Emad A. Alghamdi",
      "Vu Minh Chien",
      "Da Yin",
      "Kun Qian",
      "Yizhi Li",
      "Minnie Liang",
      "An Dinh",
      "Shrestha Mohanty",
      "Deividas Mataciunas",
      "Tobin South",
      "Jianguo Zhang",
      "Ariel N. Lee",
      "Campbell S. Lund",
      "Christopher Klamm",
      "Damien Sileo",
      "Diganta Misra",
      "Enrico Shippole",
      "Kevin Klyman",
      "Lester JV Miranda",
      "Niklas Muennighoff",
      "Seonghyeon Ye",
      "Seungone Kim",
      "Vipul Gupta",
      "Vivek Sharma",
      "Xuhui Zhou",
      "Caiming Xiong",
      "Luis Villa",
      "Stella Biderman",
      "Alex Pentland",
      "Sara Hooker",
      "Jad Kabbara"
    ],
    "abstract": "Progress in AI is driven largely by the scale and quality of training data.\nDespite this, there is a deficit of empirical analysis examining the attributes\nof well-established datasets beyond text. In this work we conduct the largest\nand first-of-its-kind longitudinal audit across modalities--popular text,\nspeech, and video datasets--from their detailed sourcing trends and use\nrestrictions to their geographical and linguistic representation. Our manual\nanalysis covers nearly 4000 public datasets between 1990-2024, spanning 608\nlanguages, 798 sources, 659 organizations, and 67 countries. We find that\nmultimodal machine learning applications have overwhelmingly turned to\nweb-crawled, synthetic, and social media platforms, such as YouTube, for their\ntraining sets, eclipsing all other sources since 2019. Secondly, tracing the\nchain of dataset derivations we find that while less than 33% of datasets are\nrestrictively licensed, over 80% of the source content in widely-used text,\nspeech, and video datasets, carry non-commercial restrictions. Finally, counter\nto the rising number of languages and geographies represented in public AI\ntraining datasets, our audit demonstrates measures of relative geographical and\nmultilingual representation have failed to significantly improve their coverage\nsince 2013. We believe the breadth of our audit enables us to empirically\nexamine trends in data sourcing, restrictions, and Western-centricity at an\necosystem-level, and that visibility into these questions are essential to\nprogress in responsible AI. As a contribution to ongoing improvements in\ndataset transparency and responsible use, we release our entire multimodal\naudit, allowing practitioners to trace data provenance across text, speech, and\nvideo.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CY",
      "cs.LG",
      "cs.MM"
    ],
    "primary_category": "cs.AI",
    "comment": "ICLR 2025. 10 pages, 5 figures (main paper)",
    "pdf_url": "http://arxiv.org/pdf/2412.17847v2",
    "published_date": "2024-12-19 01:30:19 UTC",
    "updated_date": "2025-02-19 03:05:56 UTC"
  },
  {
    "arxiv_id": "2412.16231v1",
    "title": "A Proposal for Extending the Common Model of Cognition to Emotion",
    "authors": [
      "Paul S. Rosenbloom",
      "John E. Laird",
      "Christian Lebiere",
      "Andrea Stocco",
      "Richard H. Granger",
      "Christian Huyck"
    ],
    "abstract": "Cognition and emotion must be partnered in any complete model of a humanlike\nmind. This article proposes an extension to the Common Model of Cognition -- a\ndeveloping consensus concerning what is required in such a mind -- for emotion\nthat includes a linked pair of modules for emotion and metacognitive\nassessment, plus pervasive connections between these two new modules and the\nCommon Model's existing modules and links.",
    "categories": [
      "cs.AI",
      "q-bio.NC"
    ],
    "primary_category": "cs.AI",
    "comment": "A version of this article was published in Proceedings of the 22nd\n  International Conference on Cognitive Modeling (2024)",
    "pdf_url": "http://arxiv.org/pdf/2412.16231v1",
    "published_date": "2024-12-19 00:54:32 UTC",
    "updated_date": "2024-12-19 00:54:32 UTC"
  },
  {
    "arxiv_id": "2412.14426v2",
    "title": "All-in-One Tuning and Structural Pruning for Domain-Specific LLMs",
    "authors": [
      "Lei Lu",
      "Zhepeng Wang",
      "Runxue Bao",
      "Mengbing Wang",
      "Fangyi Li",
      "Yawen Wu",
      "Weiwen Jiang",
      "Jie Xu",
      "Yanzhi Wang",
      "Shangqian Gao"
    ],
    "abstract": "Existing pruning techniques for large language models (LLMs) targeting\ndomain-specific applications typically follow a two-stage process: pruning the\npretrained general-purpose LLMs and then fine-tuning the pruned LLMs on\nspecific domains. However, the pruning decisions, derived from the pretrained\nweights, remain unchanged during fine-tuning, even if the weights have been\nupdated. Therefore, such a combination of the pruning decisions and the\nfinetuned weights may be suboptimal, leading to non-negligible performance\ndegradation. To address these limitations, we propose ATP: All-in-One Tuning\nand Structural Pruning, a unified one-stage structural pruning and fine-tuning\napproach that dynamically identifies the current optimal substructure\nthroughout the fine-tuning phase via a trainable pruning decision generator.\nMoreover, given the limited available data for domain-specific applications,\nLow-Rank Adaptation (LoRA) becomes a common technique to fine-tune the LLMs. In\nATP, we introduce LoRA-aware forward and sparsity regularization to ensure that\nthe substructures corresponding to the learned pruning decisions can be\ndirectly removed after the ATP process. ATP outperforms the state-of-the-art\ntwo-stage pruning methods on tasks in the legal and healthcare domains. More\nspecifically, ATP recovers up to 88% and 91% performance of the dense model\nwhen pruning 40% parameters of LLaMA2-7B and LLaMA3-8B models, respectively.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Updated a typo in the author list;",
    "pdf_url": "http://arxiv.org/pdf/2412.14426v2",
    "published_date": "2024-12-19 00:41:40 UTC",
    "updated_date": "2024-12-20 15:57:10 UTC"
  },
  {
    "arxiv_id": "2412.14424v1",
    "title": "FedPIA -- Permuting and Integrating Adapters leveraging Wasserstein Barycenters for Finetuning Foundation Models in Multi-Modal Federated Learning",
    "authors": [
      "Pramit Saha",
      "Divyanshu Mishra",
      "Felix Wagner",
      "Konstantinos Kamnitsas",
      "J. Alison Noble"
    ],
    "abstract": "Large Vision-Language Models typically require large text and image datasets\nfor effective fine-tuning. However, collecting data from various sites,\nespecially in healthcare, is challenging due to strict privacy regulations. An\nalternative is to fine-tune these models on end-user devices, such as in\nmedical clinics, without sending data to a server. These local clients\ntypically have limited computing power and small datasets, which are not enough\nfor fully fine-tuning large VLMs on their own. A naive solution to these\nscenarios is to leverage parameter-efficient fine-tuning (PEFT) strategies and\napply federated learning (FL) algorithms to combine the learned adapter\nweights, thereby respecting the resource limitations and data privacy. However,\nthis approach does not fully leverage the knowledge from multiple adapters\ntrained on diverse data distributions and for diverse tasks. The adapters are\nadversely impacted by data heterogeneity and task heterogeneity across clients\nresulting in suboptimal convergence. To this end, we propose a novel framework\ncalled FedPIA that improves upon the naive combinations of FL and PEFT by\nintroducing Permutation and Integration of the local Adapters in the server and\nglobal Adapters in the clients exploiting Wasserstein barycenters for improved\nblending of client-specific and client-agnostic knowledge. This layerwise\npermutation helps to bridge the gap in the parameter space of local and global\nadapters before integration. We conduct over 2000 client-level experiments\nutilizing 48 medical image datasets across five different medical\nvision-language FL task settings encompassing visual question answering as well\nas image and report-based multi-label disease detection. Our experiments\ninvolving diverse client settings, ten different modalities, and two VLM\nbackbones demonstrate that FedPIA consistently outperforms the state-of-the-art\nPEFT-FL baselines.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted for publication in AAAI 2025 (Main Track)",
    "pdf_url": "http://arxiv.org/pdf/2412.14424v1",
    "published_date": "2024-12-19 00:24:00 UTC",
    "updated_date": "2024-12-19 00:24:00 UTC"
  },
  {
    "arxiv_id": "2412.14422v1",
    "title": "Enhancing Diffusion Models for High-Quality Image Generation",
    "authors": [
      "Jaineet Shah",
      "Michael Gromis",
      "Rickston Pinto"
    ],
    "abstract": "This report presents the comprehensive implementation, evaluation, and\noptimization of Denoising Diffusion Probabilistic Models (DDPMs) and Denoising\nDiffusion Implicit Models (DDIMs), which are state-of-the-art generative\nmodels. During inference, these models take random noise as input and\niteratively generate high-quality images as output. The study focuses on\nenhancing their generative capabilities by incorporating advanced techniques\nsuch as Classifier-Free Guidance (CFG), Latent Diffusion Models with\nVariational Autoencoders (VAE), and alternative noise scheduling strategies.\nThe motivation behind this work is the growing demand for efficient and\nscalable generative AI models that can produce realistic images across diverse\ndatasets, addressing challenges in applications such as art creation, image\nsynthesis, and data augmentation. Evaluations were conducted on datasets\nincluding CIFAR-10 and ImageNet-100, with a focus on improving inference speed,\ncomputational efficiency, and image quality metrics like Frechet Inception\nDistance (FID). Results demonstrate that DDIM + CFG achieves faster inference\nand superior image quality. Challenges with VAE and noise scheduling are also\nhighlighted, suggesting opportunities for future optimization. This work lays\nthe groundwork for developing scalable, efficient, and high-quality generative\nAI systems to benefit industries ranging from entertainment to robotics.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.14422v1",
    "published_date": "2024-12-19 00:23:15 UTC",
    "updated_date": "2024-12-19 00:23:15 UTC"
  },
  {
    "arxiv_id": "2412.14415v3",
    "title": "DriveGPT: Scaling Autoregressive Behavior Models for Driving",
    "authors": [
      "Xin Huang",
      "Eric M. Wolff",
      "Paul Vernaza",
      "Tung Phan-Minh",
      "Hongge Chen",
      "David S. Hayden",
      "Mark Edmonds",
      "Brian Pierce",
      "Xinxin Chen",
      "Pratik Elias Jacob",
      "Xiaobai Chen",
      "Chingiz Tairbekov",
      "Pratik Agarwal",
      "Tianshi Gao",
      "Yuning Chai",
      "Siddhartha Srinivasa"
    ],
    "abstract": "We present DriveGPT, a scalable behavior model for autonomous driving. We\nmodel driving as a sequential decision-making task, and learn a transformer\nmodel to predict future agent states as tokens in an autoregressive fashion. We\nscale up our model parameters and training data by multiple orders of\nmagnitude, enabling us to explore the scaling properties in terms of dataset\nsize, model parameters, and compute. We evaluate DriveGPT across different\nscales in a planning task, through both quantitative metrics and qualitative\nexamples, including closed-loop driving in complex real-world scenarios. In a\nseparate prediction task, DriveGPT outperforms state-of-the-art baselines and\nexhibits improved performance by pretraining on a large-scale dataset, further\nvalidating the benefits of data scaling.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "ICML 2025. 14 pages, 17 figures, 8 tables, and 1 video link",
    "pdf_url": "http://arxiv.org/pdf/2412.14415v3",
    "published_date": "2024-12-19 00:06:09 UTC",
    "updated_date": "2025-05-02 01:02:47 UTC"
  }
]