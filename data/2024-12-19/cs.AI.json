{
  "date": "2024-12-19",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-12-19 的 arXiv 中文 TLDR 快报！今天 arXiv 的论文主要聚焦 AI 模型优化、多模态学习、强化学习以及特定领域应用，如医学和机器人等领域，强调了大型语言模型（LLM）的微调、安全性和高效性。重点包括多模态生成、LLM 校准和强化学习算法的创新，令人印象深刻的文章有 Andrew Zisserman 等参与的 Scaling 4D Representations，以及 Jie Tang 等主导的 LongBench v2，这些工作展示了 AI 在复杂任务中的潜力。\n\n下面，我挑选并简要讨论了部分重要论文，先从 AI 和 LLM 相关的高影响力工作入手，再快速掠过其他领域的关键贡献。限于篇幅，我会优先突出有话题度和创新性的论文，并用简洁描述概述每篇的核心内容。\n\n### AI 和 LLM 优化\n- **Scaling 4D Representations（Scaling 4D 表示）**（第21篇）：该论文提出了一种自监督视频学习方法，通过扩展 Transformer 模型处理时空数据，实现更高维度的表示学习。贡献在于提升了非语义任务（如姿态估计和深度估计）的性能，显著优于现有基准。\n- **LongBench v2: Towards Deeper Understanding and Reasoning on Realistic Long-context Multitasks（LongBench v2: 针对真实长上下文多任务的更深理解和推理）**（第23篇）：Jie Tang 等作者构建了一个包含503个多任务问题的基准数据集，评估LLM在长上下文下的推理能力。发现o1-preview模型超越人类基线，强调了推理计算的重要性。\n- **LMFusion: Adapting Pretrained Language Models for Multimodal Generation（LMFusion: 为多模态生成适配预训练语言模型）**（第25篇）：Luke Zettlemoyer 等参与，提出一种框架将文本模型扩展到多模态任务，通过共享注意力层融合文本和图像。发现这种方法在保持语言能力的同时，提升了视觉生成性能。\n- **AceMath: Advancing Frontier Math Reasoning with Post-Training and Reward Modeling（AceMath: 通过后训练和奖励建模提升前沿数学推理）**（第42篇）：Bryan Catanzaro 等作者开发了数学专用LLM和奖励模型，在数学基准上超越GPT-4o，展示了后训练策略的有效性。\n- **ORBIT: Cost-Effective Dataset Curation for Large Language Model Domain Adaptation（ORBIT: 为LLM领域适配的成本有效数据集构建）**（第101篇）：Yew-Soon Ong 等提出了一种高效数据集构建框架，应用于天文学领域，显著提升了LLM在专业任务上的表现。\n- **Defeasible Visual Entailment: Benchmark, Evaluator, and Reward-Driven Optimization（可辩驳视觉蕴含：基准、评估器和奖励驱动优化）**（第43篇）：引入新任务和基准，优化视觉语言模型的推理，通过奖励模型提升准确性。\n- **GenHMR: Generative Human Mesh Recovery（GenHMR: 生成式人体网格恢复）**（第120篇）：提出生成框架重构3D人体网格，减少不确定性，显著优于SOTA方法。\n- **PA-RAG: RAG Alignment via Multi-Perspective Preference Optimization（PA-RAG: 通过多视角偏好优化对RAG进行对齐）**（第109篇）：优化检索增强生成模型，提升响应信息性和鲁棒性，在多个基准上表现突出。\n\n这些论文突出了LLM在多模态和领域适配上的进展，强调了微调和奖励机制的重要性，有助于AI安全和高效应用。\n\n### 多模态和视觉学习\n- **PRIMA: Multi-Image Vision-Language Models for Reasoning Segmentation（PRIMA: 多图像视觉语言模型用于推理分割）**（第22篇）：提出多图像处理框架，提升像素级分割性能，显著减少计算量。\n- **DI-PCG: Diffusion-based Efficient Inverse Procedural Content Generation（DI-PCG: 基于扩散的逆过程内容生成）**（第24篇）：使用扩散Transformer扩展3D内容生成，减少内存开销并保持高质量。\n- **Efficient Neural Network Encoding for 3D Color Lookup Tables（高效神经网络编码用于3D颜色查找表）**（第7篇）：开发紧凑网络编码数百个LUT，实现了低失真颜色处理。\n- **Learning Visual Composition through Improved Semantic Guidance（通过改进语义引导学习视觉组合）**（第13篇）：优化对比学习方法，提升图像检索性能，超越专用架构。\n\n这些工作在视觉任务中引入了语义和生成创新，适用于图像处理和多模态应用。\n\n### 强化学习和决策\n- **Active Geospatial Search for Efficient Tenant Eviction Outreach（主动地理空间搜索用于高效租户驱逐外联）**（第3篇）：提出层次强化学习框架，优化城市租户风险评估，显著提升效率。\n- **Offline Safe Reinforcement Learning Using Trajectory Classification（使用轨迹分类的离线安全强化学习）**（第10篇）：开发轨迹分类方法，平衡探索和利用，实现更安全的高回报策略。\n- **The impact of behavioral diversity in multi-agent reinforcement learning（多代理强化学习中行为多样性的影响）**（第12篇）：Amanda Prorok 等作者探索行为异质性，提升团队性能，适用于复杂合作任务。\n\n强化学习论文强调了安全性和多样性，适用于多代理场景。\n\n### 其他领域快速掠过\n- **AI-Enhanced Sensemaking: Exploring the Design of a Generative AI-Based Assistant to Support Genetic Professionals（AI增强的意义构建: 探索生成式AI助手的设计以支持遗传专业人士）**（第5篇）：设计AI助手辅助基因分析，提升诊断效率。\n- **Energy consumption of code small language models（代码小型语言模型的能耗）**（第6篇）：分析不同执行提供者的能耗，推荐高效配置。\n- **Quantifying detection rates for dangerous capabilities: a theoretical model（量化危险能力检测率: 一个理论模型）**（第9篇）：Paolo Bova 等构建AI风险模型，提供政策洞见。\n- **Granger Causality Detection with Kolmogorov-Arnold Networks（使用Kolmogorov-Arnold网络的Granger因果关系检测）**（第17篇）：提出新框架检测时间序列因果，提升准确性。\n- **Towards Friendly AI: A Comprehensive Review（迈向友好AI: 全面综述）**（第35篇）：综述AI伦理，强调公平和可持续性。\n- **Movie2Story: A framework for understanding videos and telling stories（Movie2Story: 理解视频并生成故事的框架）**（第49篇）：构建框架从视频生成叙事文本，提升多模态理解。\n- **ALKAFI-LLAMA3: Fine-Tuning LLMs for Precise Legal Understanding in Palestine（ALKAFI-LLAMA3: 为巴勒斯坦法律理解微调LLM）**（第71篇）：针对法律领域微调模型，提升准确性。\n\n这些论文在医学、能耗和伦理等领域有实用贡献，但非核心焦点，故简要概述。\n\n今天的论文展示了AI领域的快速迭代，特别在LLM和多模态上的突破。建议读者关注Andrew Zisserman和Jie Tang的作品，以了解前沿进展。更多细节可查阅arXiv。明天的快报再见！",
  "papers": [
    {
      "arxiv_id": "2501.04014v1",
      "title": "AICat: An AI Cataloguing Approach to Support the EU AI Act",
      "title_zh": "AICat：支持欧盟AI法案的AI编目方法",
      "authors": [
        "Delaram Golpayegani",
        "Harshvardhan J. Pandit",
        "Dave Lewis"
      ],
      "abstract": "The European Union's Artificial Intelligence Act (AI Act) requires providers\nand deployers of high-risk AI applications to register their systems into the\nEU database, wherein the information should be represented and maintained in an\neasily-navigable and machine-readable manner. Given the uptake of open data and\nSemantic Web-based approaches for other EU repositories, in particular the use\nof the Data Catalogue vocabulary Application Profile (DCAT-AP), a similar\nsolution for managing the EU database of high-risk AI systems is needed. This\npaper introduces AICat - an extension of DCAT for representing catalogues of AI\nsystems that provides consistency, machine-readability, searchability, and\ninteroperability in managing open metadata regarding AI systems. This open\napproach to cataloguing ensures transparency, traceability, and accountability\nin AI application markets beyond the immediate needs of high-risk AI compliance\nin the EU. AICat is available online at https://w3id.org/aicat under the\nCC-BY-4.0 license.",
      "tldr_zh": "欧盟人工智能法案（EU AI Act）要求高风险AI系统提供者和部署者将系统注册到一个易于导航和机器可读的数据库中，以确保透明性和合规性。论文引入AICat，这是一种基于Data Catalogue vocabulary Application Profile (DCAT-AP)的扩展框架，用于目录化AI系统，提供一致性、机器可读性、可搜索性和互操作性。AICat通过Semantic Web方法管理AI系统的开放元数据，促进AI应用市场的透明性、可追溯性和问责性；该框架已在线发布在https://w3id.org/aicat，并采用CC-BY-4.0许可。",
      "categories": [
        "cs.DL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.DL",
      "comment": "Presented at 37th International Conference on Legal Knowledge and\n  Information Systems (JURIX) 2024",
      "pdf_url": "http://arxiv.org/pdf/2501.04014v1",
      "published_date": "2024-12-19 23:48:20 UTC",
      "updated_date": "2024-12-19 23:48:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:05:32.463137"
    },
    {
      "arxiv_id": "2412.15462v1",
      "title": "TalkWithMachines: Enhancing Human-Robot Interaction for Interpretable Industrial Robotics Through Large/Vision Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Ammar N. Abbas",
        "Csaba Beleznai"
      ],
      "abstract": "TalkWithMachines aims to enhance human-robot interaction by contributing to\ninterpretable industrial robotic systems, especially for safety-critical\napplications. The presented paper investigates recent advancements in Large\nLanguage Models (LLMs) and Vision Language Models (VLMs), in combination with\nrobotic perception and control. This integration allows robots to understand\nand execute commands given in natural language and to perceive their\nenvironment through visual and/or descriptive inputs. Moreover, translating the\nLLM's internal states and reasoning into text that humans can easily understand\nensures that operators gain a clearer insight into the robot's current state\nand intentions, which is essential for effective and safe operation. Our paper\noutlines four LLM-assisted simulated robotic control workflows, which explore\n(i) low-level control, (ii) the generation of language-based feedback that\ndescribes the robot's internal states, (iii) the use of visual information as\nadditional input, and (iv) the use of robot structure information for\ngenerating task plans and feedback, taking the robot's physical capabilities\nand limitations into account. The proposed concepts are presented in a set of\nexperiments, along with a brief discussion. Project description, videos, and\nsupplementary materials will be available on the project website:\nhttps://talk-machines.github.io.",
      "tldr_zh": "该研究提出TalkWithMachines框架，通过整合Large Language Models (LLMs) 和 Vision Language Models (VLMs) 来提升人类-机器人交互的可解释性，特别针对安全关键的工业机器人应用。框架允许机器人理解自然语言命令并通过视觉或描述性输入感知环境，同时将LLMs的内部状态和推理转化为易懂的文本，帮助操作者更好地把握机器人的状态和意图。论文概述了四个LLM辅助的模拟机器人控制工作流，包括低级控制、生成语言反馈、使用视觉信息以及考虑机器人物理能力的任务规划。实验结果展示了这些概念的有效性，为更安全有效的机器人操作提供了基础。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CL",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "This paper has been accepted for publication in the proceedings of\n  the 2024 Eighth IEEE International Conference on Robotic Computing (IRC)",
      "pdf_url": "http://arxiv.org/pdf/2412.15462v1",
      "published_date": "2024-12-19 23:43:40 UTC",
      "updated_date": "2024-12-19 23:43:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:05:44.502116"
    },
    {
      "arxiv_id": "2412.17854v1",
      "title": "Active Geospatial Search for Efficient Tenant Eviction Outreach",
      "title_zh": "翻译失败",
      "authors": [
        "Anindya Sarkar",
        "Alex DiChristofano",
        "Sanmay Das",
        "Patrick J. Fowler",
        "Nathan Jacobs",
        "Yevgeniy Vorobeychik"
      ],
      "abstract": "Tenant evictions threaten housing stability and are a major concern for many\ncities. An open question concerns whether data-driven methods enhance outreach\nprograms that target at-risk tenants to mitigate their risk of eviction. We\npropose a novel active geospatial search (AGS) modeling framework for this\nproblem. AGS integrates property-level information in a search policy that\nidentifies a sequence of rental units to canvas to both determine their\neviction risk and provide support if needed. We propose a hierarchical\nreinforcement learning approach to learn a search policy for AGS that scales to\nlarge urban areas containing thousands of parcels, balancing exploration and\nexploitation and accounting for travel costs and a budget constraint.\nCrucially, the search policy adapts online to newly discovered information\nabout evictions. Evaluation using eviction data for a large urban area\ndemonstrates that the proposed framework and algorithmic approach are\nconsiderably more effective at sequentially identifying eviction cases than\nbaseline methods.",
      "tldr_zh": "该研究针对租户驱逐（Tenant evictions）对住房稳定的威胁，提出了一种新型主动地理空间搜索（Active Geospatial Search, AGS）建模框架，以提升针对高风险租户的外展计划效率。框架通过整合财产级信息和分层强化学习（hierarchical reinforcement learning）方法，学习一个搜索策略，该策略能动态识别租赁单元序列、平衡探索与利用、考虑旅行成本和预算约束，并在线适应新发现的信息。实验结果显示，在大型城市驱逐数据上，该框架比基线方法更有效地识别驱逐案例，提高了整体效能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to AAAI 2025 (AI for Social Impact Track)",
      "pdf_url": "http://arxiv.org/pdf/2412.17854v1",
      "published_date": "2024-12-19 23:40:36 UTC",
      "updated_date": "2024-12-19 23:40:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:05:56.318856"
    },
    {
      "arxiv_id": "2412.15453v1",
      "title": "Northeastern Uni at Multilingual Counterspeech Generation: Enhancing Counter Speech Generation with LLM Alignment through Direct Preference Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Sahil Wadhwa",
        "Chengtian Xu",
        "Haoming Chen",
        "Aakash Mahalingam",
        "Akankshya Kar",
        "Divya Chaudhary"
      ],
      "abstract": "The automatic generation of counter-speech (CS) is a critical strategy for\naddressing hate speech by providing constructive and informed responses.\nHowever, existing methods often fail to generate high-quality, impactful, and\nscalable CS, particularly across diverse linguistic contexts. In this paper, we\npropose a novel methodology to enhance CS generation by aligning Large Language\nModels (LLMs) using Supervised Fine-Tuning (SFT) and Direct Preference\nOptimization (DPO). Our approach leverages DPO to align LLM outputs with human\npreferences, ensuring contextually appropriate and linguistically adaptable\nresponses. Additionally, we incorporate knowledge grounding to enhance the\nfactual accuracy and relevance of generated CS. Experimental results\ndemonstrate that DPO-aligned models significantly outperform SFT baselines on\nCS benchmarks while scaling effectively to multiple languages. These findings\nhighlight the potential of preference-based alignment techniques to advance CS\ngeneration across varied linguistic settings. The model supervision and\nalignment is done in English and the same model is used for reporting metrics\nacross other languages like Basque, Italian, and Spanish.",
      "tldr_zh": "本篇论文针对自动生成反驳言论（counter-speech）以应对仇恨言论的问题，提出了一种新方法，通过监督微调（SFT）和直接偏好优化（DPO）对大语言模型（LLMs）进行对齐，确保生成的响应更高质量、上下文相关且多语言适应。方法还整合了知识 grounding 技术，以提升反驳言论的事实准确性和相关性。实验结果表明，DPO 对齐的模型在 CS 基准测试中显著优于 SFT 基线，并在英语外扩展到巴斯克语、意大利语和西班牙语等语言，展示了偏好优化技术的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages, 6 tables, 1 figure, The First Workshop on Multilingual\n  Counterspeech Generation (MCG) at The 31st International Conference on\n  Computational Linguistics (COLING 2025)",
      "pdf_url": "http://arxiv.org/pdf/2412.15453v1",
      "published_date": "2024-12-19 23:22:11 UTC",
      "updated_date": "2024-12-19 23:22:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:06:09.330946"
    },
    {
      "arxiv_id": "2412.15444v1",
      "title": "AI-Enhanced Sensemaking: Exploring the Design of a Generative AI-Based Assistant to Support Genetic Professionals",
      "title_zh": "翻译失败",
      "authors": [
        "Angela Mastrianni",
        "Hope Twede",
        "Aleksandra Sarcevic",
        "Jeremiah Wander",
        "Christina Austin-Tse",
        "Scott Saponas",
        "Heidi Rehm",
        "Ashley Mae Conard",
        "Amanda K. Hall"
      ],
      "abstract": "Generative AI has the potential to transform knowledge work, but further\nresearch is needed to understand how knowledge workers envision using and\ninteracting with generative AI. We investigate the development of generative AI\ntools to support domain experts in knowledge work, examining task delegation\nand the design of human-AI interactions. Our research focused on designing a\ngenerative AI assistant to aid genetic professionals in analyzing whole genome\nsequences (WGS) and other clinical data for rare disease diagnosis. Through\ninterviews with 17 genetics professionals, we identified current challenges in\nWGS analysis. We then conducted co-design sessions with six genetics\nprofessionals to determine tasks that could be supported by an AI assistant and\nconsiderations for designing interactions with the AI assistant. From our\nfindings, we identified sensemaking as both a current challenge in WGS analysis\nand a process that could be supported by AI. We contribute an understanding of\nhow domain experts envision interacting with generative AI in their knowledge\nwork, a detailed empirical study of WGS analysis, and three design\nconsiderations for using generative AI to support domain experts in sensemaking\nduring knowledge work.\n  CCS CONCEPTS: Human-centered computing, Human-computer interaction, Empirical\nstudies in HCI\n  Additional Keywords and Phrases: whole genome sequencing, generative AI,\nlarge language models, knowledge work, sensemaking, co-design, rare disease\n  Contact Author: Angela Mastrianni (This work was done during the author's\ninternship at Microsoft Research)\n  Ashley Mae Conard and Amanda K. Hall contributed equally",
      "tldr_zh": "本研究探讨了生成式AI如何辅助遗传专业人士进行知识工作，特别是分析全基因组序列(WGS)和临床数据以诊断罕见疾病。通过对17名遗传专业人士的采访和与6名专业人士的共同设计(co-design)会议，研究者识别了WGS分析中的挑战，如sensemaking过程的复杂性，并探讨了AI助手的设计以支持任务委托和人机互动。研究发现，generative AI可有效缓解sensemaking难题，并提出了三个设计考虑，包括优化AI交互以提升领域专家的效率。该工作为generative AI在知识工作中的应用提供了实证洞见和指导原则。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "22 pages, 8 figures, 1 table, 3 appendices",
      "pdf_url": "http://arxiv.org/pdf/2412.15444v1",
      "published_date": "2024-12-19 22:54:49 UTC",
      "updated_date": "2024-12-19 22:54:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:06:21.238940"
    },
    {
      "arxiv_id": "2412.15441v1",
      "title": "Energy consumption of code small language models serving with runtime engines and execution providers",
      "title_zh": "翻译失败",
      "authors": [
        "Francisco Durán",
        "Matias Martinez",
        "Patricia Lago",
        "Silverio Martínez-Fernández"
      ],
      "abstract": "Background. The rapid growth of Language Models (LMs), particularly in code\ngeneration, requires substantial computational resources, raising concerns\nabout energy consumption and environmental impact. Optimizing LMs inference for\nenergy efficiency is crucial, and Small Language Models (SLMs) offer a\npromising solution to reduce resource demands.\n  Aim. Our goal is to analyze the impact of deep learning runtime engines and\nexecution providers on energy consumption, execution time, and\ncomputing-resource utilization from the point of view of software engineers\nconducting inference in the context of code SLMs.\n  Method. We conducted a technology-oriented, multi-stage experimental pipeline\nusing twelve code generation SLMs to investigate energy consumption, execution\ntime, and computing-resource utilization across the configurations.\n  Results. Significant differences emerged across configurations. CUDA\nexecution provider configurations outperformed CPU execution provider\nconfigurations in both energy consumption and execution time. Among the\nconfigurations, TORCH paired with CUDA demonstrated the greatest energy\nefficiency, achieving energy savings from 37.99% up to 89.16% compared to other\nserving configurations. Similarly, optimized runtime engines like ONNX with the\nCPU execution provider achieved from 8.98% up to 72.04% energy savings within\nCPU-based configurations. Also, TORCH paired with CUDA exhibited efficient\ncomputing-resource utilization.\n  Conclusions. Serving configuration choice significantly impacts energy\nefficiency. While further research is needed, we recommend the above\nconfigurations best suited to software engineers' requirements for enhancing\nserving efficiency in energy and performance.",
      "tldr_zh": "本文研究了代码小语言模型(SLMs)在不同运行时引擎和执行提供者下的能耗、执行时间及计算资源利用情况，旨在帮助软件工程师优化能源效率并减少环境影响。研究采用多阶段实验管道，使用12个代码生成SLMs测试各种配置，结果显示CUDA执行提供者配置显著优于CPU配置，其中TORCH与CUDA组合可节省37.99%至89.16%的能耗，而ONNX与CPU组合在CPU配置中节省8.98%至72.04%。结论建议选择合适的配置（如TORCH+CUDA）以提升性能和能效，并呼吁进一步研究。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "26 pages, submitted to journal",
      "pdf_url": "http://arxiv.org/pdf/2412.15441v1",
      "published_date": "2024-12-19 22:44:02 UTC",
      "updated_date": "2024-12-19 22:44:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:06:33.499006"
    },
    {
      "arxiv_id": "2412.15438v1",
      "title": "Efficient Neural Network Encoding for 3D Color Lookup Tables",
      "title_zh": "翻译失败",
      "authors": [
        "Vahid Zehtab",
        "David B. Lindell",
        "Marcus A. Brubaker",
        "Michael S. Brown"
      ],
      "abstract": "3D color lookup tables (LUTs) enable precise color manipulation by mapping\ninput RGB values to specific output RGB values. 3D LUTs are instrumental in\nvarious applications, including video editing, in-camera processing,\nphotographic filters, computer graphics, and color processing for displays.\nWhile an individual LUT does not incur a high memory overhead, software and\ndevices may need to store dozens to hundreds of LUTs that can take over 100 MB.\nThis work aims to develop a neural network architecture that can encode\nhundreds of LUTs in a single compact representation. To this end, we propose a\nmodel with a memory footprint of less than 0.25 MB that can reconstruct 512\nLUTs with only minor color distortion ($\\bar{\\Delta}E_M$ $\\leq$ 2.0) over the\nentire color gamut. We also show that our network can weight colors to provide\nfurther quality gains on natural image colors ($\\bar{\\Delta}{E}_M$ $\\leq$ 1.0).\nFinally, we show that minor modifications to the network architecture enable a\nbijective encoding that produces LUTs that are invertible, allowing for reverse\ncolor processing. Our code is available at https://github.com/vahidzee/ennelut.",
      "tldr_zh": "本研究针对3D Color Lookup Tables (LUTs) 的存储效率问题，提出了一种高效的Neural Network架构，能够用单一紧凑表示编码数百个LUTs，从而显著减少内存占用（小于0.25 MB）。该模型能够准确重建512个LUTs，仅产生微小颜色失真（平均ΔE_M ≤ 2.0），并通过颜色加权技术进一步优化自然图像质量（平均ΔE_M ≤ 1.0）。此外，轻微修改网络架构实现双向编码，使LUTs可逆，用于反向颜色处理。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "eess.IV",
        "I.4.0; I.4.2; I.5.0; I.5.1; I.5.4; I.2.0; I.2.6; I.2.10"
      ],
      "primary_category": "cs.CV",
      "comment": "14 pages, 13 figures; extended version; to appear in AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.15438v1",
      "published_date": "2024-12-19 22:41:26 UTC",
      "updated_date": "2024-12-19 22:41:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:06:44.074795"
    },
    {
      "arxiv_id": "2412.19830v1",
      "title": "A Unified Framework for Context-Aware IoT Management and State-of-the-Art IoT Traffic Anomaly Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Daniel Adu Worae",
        "Athar Sheikh",
        "Spyridon Mastorakis"
      ],
      "abstract": "The rapid expansion of Internet of Things (IoT) ecosystems has introduced\ngrowing complexities in device management and network security. To address\nthese challenges, we present a unified framework that combines context-driven\nlarge language models (LLMs) for IoT administrative tasks with a fine-tuned\nanomaly detection module for network traffic analysis. The framework\nstreamlines administrative processes such as device management,\ntroubleshooting, and security enforcement by harnessing contextual knowledge\nfrom IoT manuals and operational data. The anomaly detection model achieves\nstate-of-the-art performance in identifying irregularities and threats within\nIoT traffic, leveraging fine-tuning to deliver exceptional accuracy.\nEvaluations demonstrate that incorporating relevant contextual information\nsignificantly enhances the precision and reliability of LLM-based responses for\ndiverse IoT administrative tasks. Additionally, resource usage metrics such as\nexecution time, memory consumption, and response efficiency demonstrate the\nframework's scalability and suitability for real-world IoT deployments.",
      "tldr_zh": "本研究提出一个统一的框架，结合上下文驱动的大语言模型 (LLMs) 用于 IoT 设备管理、故障排除和安全执行，以及一个微调的异常检测模块来实现最先进的 IoT 流量异常识别。该框架利用 IoT 手册和操作数据提供精确的上下文知识，提升了管理任务的响应可靠性和精确性。实验评估显示，异常检测模型在识别不规则性和威胁方面表现出色，同时框架在执行时间、内存消耗和响应效率等方面表现出良好的可扩展性，适用于实际 IoT 部署。",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.19830v1",
      "published_date": "2024-12-19 22:38:41 UTC",
      "updated_date": "2024-12-19 22:38:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:06:56.717964"
    },
    {
      "arxiv_id": "2412.15433v1",
      "title": "Quantifying detection rates for dangerous capabilities: a theoretical model of dangerous capability evaluations",
      "title_zh": "翻译失败",
      "authors": [
        "Paolo Bova",
        "Alessandro Di Stefano",
        "The Anh Han"
      ],
      "abstract": "We present a quantitative model for tracking dangerous AI capabilities over\ntime. Our goal is to help the policy and research community visualise how\ndangerous capability testing can give us an early warning about approaching AI\nrisks. We first use the model to provide a novel introduction to dangerous\ncapability testing and how this testing can directly inform policy. Decision\nmakers in AI labs and government often set policy that is sensitive to the\nestimated danger of AI systems, and may wish to set policies that condition on\nthe crossing of a set threshold for danger. The model helps us to reason about\nthese policy choices. We then run simulations to illustrate how we might fail\nto test for dangerous capabilities. To summarise, failures in dangerous\ncapability testing may manifest in two ways: higher bias in our estimates of AI\ndanger, or larger lags in threshold monitoring. We highlight two drivers of\nthese failure modes: uncertainty around dynamics in AI capabilities and\ncompetition between frontier AI labs. Effective AI policy demands that we\naddress these failure modes and their drivers. Even if the optimal targeting of\nresources is challenging, we show how delays in testing can harm AI policy. We\noffer preliminary recommendations for building an effective testing ecosystem\nfor dangerous capabilities and advise on a research agenda.",
      "tldr_zh": "本研究提出一个量化模型，用于跟踪人工智能（AI）的危险能力（dangerous capabilities），旨在帮助政策和研究社区可视化测试如何提供AI风险的早期警告。模型首先介绍危险能力测试如何直接影响政策决策，例如设定基于危险阈值（threshold）的策略，并通过模拟展示测试失败可能导致估计偏差或延迟。研究强调，AI能力动态的不确定性和前沿AI实验室间的竞争是这些失败模式的驱动因素，并提供初步推荐来构建有效的测试生态系统，以优化AI政策和研究议程。",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.MA",
        "econ.GN",
        "q-fin.EC",
        "stat.AP"
      ],
      "primary_category": "cs.AI",
      "comment": "26 pages, 15 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.15433v1",
      "published_date": "2024-12-19 22:31:34 UTC",
      "updated_date": "2024-12-19 22:31:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:09:01.860912"
    },
    {
      "arxiv_id": "2412.15429v5",
      "title": "Offline Safe Reinforcement Learning Using Trajectory Classification",
      "title_zh": "使用轨迹分类的离线安全强化学习",
      "authors": [
        "Ze Gong",
        "Akshat Kumar",
        "Pradeep Varakantham"
      ],
      "abstract": "Offline safe reinforcement learning (RL) has emerged as a promising approach\nfor learning safe behaviors without engaging in risky online interactions with\nthe environment. Most existing methods in offline safe RL rely on cost\nconstraints at each time step (derived from global cost constraints) and this\ncan result in either overly conservative policies or violation of safety\nconstraints. In this paper, we propose to learn a policy that generates\ndesirable trajectories and avoids undesirable trajectories. To be specific, we\nfirst partition the pre-collected dataset of state-action trajectories into\ndesirable and undesirable subsets. Intuitively, the desirable set contains high\nreward and safe trajectories, and undesirable set contains unsafe trajectories\nand low-reward safe trajectories. Second, we learn a policy that generates\ndesirable trajectories and avoids undesirable trajectories, where\n(un)desirability scores are provided by a classifier learnt from the dataset of\ndesirable and undesirable trajectories. This approach bypasses the\ncomputational complexity and stability issues of a min-max objective that is\nemployed in existing methods. Theoretically, we also show our approach's strong\nconnections to existing learning paradigms involving human feedback. Finally,\nwe extensively evaluate our method using the DSRL benchmark for offline safe\nRL. Empirically, our method outperforms competitive baselines, achieving higher\nrewards and better constraint satisfaction across a wide variety of benchmark\ntasks.",
      "tldr_zh": "本文提出了一种基于轨迹分类的离线安全强化学习（Offline Safe Reinforcement Learning）方法，以解决现有方法在成本约束下导致的策略过于保守或安全违反问题。具体而言，该方法首先将预收集数据集分区为可取轨迹（高奖励和安全）和不可取轨迹（不安全或低奖励）子集，然后通过一个从这些子集学习的分级器来指导策略生成可取轨迹并避免不可取轨迹。该方法避免了传统min-max目标的计算复杂性和稳定性问题，并在理论上与人类反馈学习范式相关联；实验结果显示，在DSRL基准任务中，该方法优于竞争基线，实现了更高奖励和更好的约束满足。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "AAAI 2025. Updated results",
      "pdf_url": "http://arxiv.org/pdf/2412.15429v5",
      "published_date": "2024-12-19 22:29:03 UTC",
      "updated_date": "2025-04-19 01:50:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:07:20.776144"
    },
    {
      "arxiv_id": "2412.15404v1",
      "title": "A Retrieval-Augmented Generation Framework for Academic Literature Navigation in Data Science",
      "title_zh": "一种检索增强生成框架，用于数据科学中的学术文献导航",
      "authors": [
        "Ahmet Yasin Aytar",
        "Kemal Kilic",
        "Kamer Kaya"
      ],
      "abstract": "In the rapidly evolving field of data science, efficiently navigating the\nexpansive body of academic literature is crucial for informed decision-making\nand innovation. This paper presents an enhanced Retrieval-Augmented Generation\n(RAG) application, an artificial intelligence (AI)-based system designed to\nassist data scientists in accessing precise and contextually relevant academic\nresources. The AI-powered application integrates advanced techniques, including\nthe GeneRation Of BIbliographic Data (GROBID) technique for extracting\nbibliographic information, fine-tuned embedding models, semantic chunking, and\nan abstract-first retrieval method, to significantly improve the relevance and\naccuracy of the retrieved information. This implementation of AI specifically\naddresses the challenge of academic literature navigation. A comprehensive\nevaluation using the Retrieval-Augmented Generation Assessment System (RAGAS)\nframework demonstrates substantial improvements in key metrics, particularly\nContext Relevance, underscoring the system's effectiveness in reducing\ninformation overload and enhancing decision-making processes. Our findings\nhighlight the potential of this enhanced Retrieval-Augmented Generation system\nto transform academic exploration within data science, ultimately advancing the\nworkflow of research and innovation in the field.",
      "tldr_zh": "这篇论文提出一个增强的 Retrieval-Augmented Generation (RAG) 框架，旨在帮助数据科学家高效导航学术文献，提高决策和创新效率。框架整合了 GROBID 技术用于提取书目信息、细调的嵌入模型、语义分块以及抽象优先检索方法，以提升检索信息的相关性和准确性。使用 Retrieval-Augmented Generation Assessment System (RAGAS) 框架进行评估，结果显示系统在 Context Relevance 等关键指标上取得了显著改善，减少了信息过载。总体而言，该框架有望革新数据科学领域的学术探索工作流程。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.15404v1",
      "published_date": "2024-12-19 21:14:54 UTC",
      "updated_date": "2024-12-19 21:14:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:09:13.943159"
    },
    {
      "arxiv_id": "2412.16244v2",
      "title": "The impact of behavioral diversity in multi-agent reinforcement learning",
      "title_zh": "多智能体强化学习中行为多样性的影响",
      "authors": [
        "Matteo Bettini",
        "Ryan Kortvelesy",
        "Amanda Prorok"
      ],
      "abstract": "Many of the world's most pressing issues, such as climate change and global\npeace, require complex collective problem-solving skills. Recent studies\nindicate that diversity in individuals' behaviors is key to developing such\nskills and increasing collective performance. Yet behavioral diversity in\ncollective artificial learning is understudied, with today's machine learning\nparadigms commonly favoring homogeneous agent strategies over heterogeneous\nones, mainly due to computational considerations. In this work, we employ\ndiversity measurement and control paradigms to study the impact of behavioral\nheterogeneity in several facets of multi-agent reinforcement learning. Through\nexperiments in team play and other cooperative tasks, we show the emergence of\nunbiased behavioral roles that improve team outcomes; how behavioral diversity\nsynergizes with morphological diversity; how diverse agents are more effective\nat finding cooperative solutions in sparse reward settings; and how\nbehaviorally heterogeneous teams learn and retain latent skills to overcome\nrepeated disruptions. Overall, our results indicate that, by controlling\ndiversity, we can obtain non-trivial benefits over homogeneous training\nparadigms, demonstrating that diversity is a fundamental component of\ncollective artificial learning, an insight thus far overlooked.",
      "tldr_zh": "本研究探讨了行为多样性（behavioral diversity）在多智能体强化学习（multi-agent reinforcement learning）中的影响，强调其在提升集体问题解决能力方面的关键作用。作者通过多样性测量和控制范式，进行团队合作和合作任务实验，揭示行为异质性如何促成无偏行为角色、改善团队表现，并与形态多样性（morphological diversity）协同增强效果。实验结果显示，行为多样性在稀疏奖励设置（sparse reward settings）中更有效地找到合作解决方案，并帮助团队学习和保留技能以应对干扰。总体而言，该工作证明，通过控制多样性，可以获得比同质化训练范式更大的益处，将多样性确立为集体人工智能学习的基本组成部分。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.16244v2",
      "published_date": "2024-12-19 21:13:32 UTC",
      "updated_date": "2025-01-29 09:53:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:09:25.203653"
    },
    {
      "arxiv_id": "2412.15396v2",
      "title": "Learning Visual Composition through Improved Semantic Guidance",
      "title_zh": "通过改进的语义指导学习视觉构图",
      "authors": [
        "Austin Stone",
        "Hagen Soltau",
        "Robert Geirhos",
        "Xi Yi",
        "Ye Xia",
        "Bingyi Cao",
        "Kaifeng Chen",
        "Abhijit Ogale",
        "Jonathon Shlens"
      ],
      "abstract": "Visual imagery does not consist of solitary objects, but instead reflects the\ncomposition of a multitude of fluid concepts. While there have been great\nadvances in visual representation learning, such advances have focused on\nbuilding better representations for a small number of discrete objects bereft\nof an understanding of how these objects are interacting. One can observe this\nlimitation in representations learned through captions or contrastive learning\n-- where the learned model treats an image essentially as a bag of words.\nSeveral works have attempted to address this limitation through the development\nof bespoke learned architectures to directly address the shortcomings in\ncompositional learning. In this work, we focus on simple, and scalable\napproaches. In particular, we demonstrate that by substantially improving\nweakly labeled data, i.e. captions, we can vastly improve the performance of\nstandard contrastive learning approaches. Previous CLIP models achieved near\nchance rate on challenging tasks probing compositional learning. However, our\nsimple approach boosts performance of CLIP substantially and surpasses all\nbespoke architectures. Furthermore, we showcase our results on a relatively new\ncaptioning benchmark derived from DOCCI. We demonstrate through a series of\nablations that a standard CLIP model trained with enhanced data may demonstrate\nimpressive performance on image retrieval tasks.",
      "tldr_zh": "本研究针对视觉表示学习中忽略物体间互动组合的问题，提出通过改进语义指导（如增强标题数据）来提升标准对比学习方法。作者发现，优化弱标记数据后，CLIP 模型在组合学习任务上的性能大幅提升，从接近随机水平超越所有定制架构。实验结果显示，该方法在 DOCCI 基准的图像检索任务中表现出色，证明了简单可扩展方法的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.IR"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.15396v2",
      "published_date": "2024-12-19 20:58:26 UTC",
      "updated_date": "2025-04-04 00:14:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:09:36.877202"
    },
    {
      "arxiv_id": "2412.15388v1",
      "title": "Investigating Relational State Abstraction in Collaborative MARL",
      "title_zh": "在协作多智能体强化学习中研究关系状态",
      "authors": [
        "Sharlin Utke",
        "Jeremie Houssineau",
        "Giovanni Montana"
      ],
      "abstract": "This paper explores the impact of relational state abstraction on sample\nefficiency and performance in collaborative Multi-Agent Reinforcement Learning.\nThe proposed abstraction is based on spatial relationships in environments\nwhere direct communication between agents is not allowed, leveraging the\nubiquity of spatial reasoning in real-world multi-agent scenarios. We introduce\nMARC (Multi-Agent Relational Critic), a simple yet effective critic\narchitecture incorporating spatial relational inductive biases by transforming\nthe state into a spatial graph and processing it through a relational graph\nneural network. The performance of MARC is evaluated across six collaborative\ntasks, including a novel environment with heterogeneous agents. We conduct a\ncomprehensive empirical analysis, comparing MARC against state-of-the-art MARL\nbaselines, demonstrating improvements in both sample efficiency and asymptotic\nperformance, as well as its potential for generalization. Our findings suggest\nthat a minimal integration of spatial relational inductive biases as\nabstraction can yield substantial benefits without requiring complex designs or\ntask-specific engineering. This work provides insights into the potential of\nrelational state abstraction to address sample efficiency, a key challenge in\nMARL, offering a promising direction for developing more efficient algorithms\nin spatially complex environments.",
      "tldr_zh": "这篇论文探讨了关系状态抽象（relational state abstraction）对协作多智能体强化学习（collaborative MARL）中样本效率和性能的影响，特别针对不允许代理直接通信的空间环境。作者提出了MARC（Multi-Agent Relational Critic），一种简单有效的批评者架构，通过将状态转化为空间图并使用关系图神经网络整合空间关系归纳偏差。实验在六个协作任务上进行，包括一个异构代理的新型环境，结果显示MARC相较于最先进MARL基线显著提升了样本效率和渐近性能，并展现出良好的泛化潜力。这些发现表明，采用最小化的空间关系抽象可以带来实质性益处，而无需复杂设计或任务特定优化。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.15388v1",
      "published_date": "2024-12-19 20:34:00 UTC",
      "updated_date": "2024-12-19 20:34:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:09:49.738953"
    },
    {
      "arxiv_id": "2412.15386v1",
      "title": "Systematic Evaluation of Long-Context LLMs on Financial Concepts",
      "title_zh": "长上下文大语言模型在金融概念上的系统评估",
      "authors": [
        "Lavanya Gupta",
        "Saket Sharma",
        "Yiyun Zhao"
      ],
      "abstract": "Long-context large language models (LC LLMs) promise to increase reliability\nof LLMs in real-world tasks requiring processing and understanding of long\ninput documents. However, this ability of LC LLMs to reliably utilize their\ngrowing context windows remains under investigation. In this work, we evaluate\nthe performance of state-of-the-art GPT-4 suite of LC LLMs in solving a series\nof progressively challenging tasks, as a function of factors such as context\nlength, task difficulty, and position of key information by creating a real\nworld financial news dataset. Our findings indicate that LC LLMs exhibit\nbrittleness at longer context lengths even for simple tasks, with performance\ndeteriorating sharply as task complexity increases. At longer context lengths,\nthese state-of-the-art models experience catastrophic failures in instruction\nfollowing resulting in degenerate outputs. Our prompt ablations also reveal\nunfortunate continued sensitivity to both the placement of the task instruction\nin the context window as well as minor markdown formatting. Finally, we\nadvocate for more rigorous evaluation of LC LLMs by employing holistic metrics\nsuch as F1 (rather than recall) and reporting confidence intervals, thereby\nensuring robust and conclusive findings.",
      "tldr_zh": "这篇论文系统评估了长上下文大语言模型 (LC LLMs) 在处理金融概念时的性能，特别是其在长输入文档上的可靠性和理解能力。研究者通过创建一个真实世界的金融新闻数据集，测试了 GPT-4 等模型在不同上下文长度、任务难度和关键信息位置下的表现。结果显示，LC LLMs 在较长上下文长度下表现出脆弱性，性能急剧下降，甚至导致灾难性失败和指令遵循问题。论文还强调了模型对任务指令位置和微小 markdown 格式的持续敏感性，并建议采用更严格的评估指标，如 F1 分数和置信区间，以确保更可靠的结论。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at EMNLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2412.15386v1",
      "published_date": "2024-12-19 20:26:55 UTC",
      "updated_date": "2024-12-19 20:26:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:10:01.481288"
    },
    {
      "arxiv_id": "2412.15374v1",
      "title": "Automated Root Cause Analysis System for Complex Data Products",
      "title_zh": "复杂数据产品的自动化根本原因分析系统",
      "authors": [
        "Mathieu Demarne",
        "Miso Cilimdzic",
        "Tom Falkowski",
        "Timothy Johnson",
        "Jim Gramling",
        "Wei Kuang",
        "Hoobie Hou",
        "Amjad Aryan",
        "Gayatri Subramaniam",
        "Kenny Lee",
        "Manuel Mejia",
        "Lisa Liu",
        "Divya Vermareddy"
      ],
      "abstract": "We present ARCAS (Automated Root Cause Analysis System), a diagnostic\nplatform based on a Domain Specific Language (DSL) built for fast diagnostic\nimplementation and low learning curve. Arcas is composed of a constellation of\nautomated troubleshooting guides (Auto-TSGs) that can execute in parallel to\ndetect issues using product telemetry and apply mitigation in near-real-time.\nThe DSL is tailored specifically to ensure that subject matter experts can\ndeliver highly curated and relevant Auto-TSGs in a short time without having to\nunderstand how they will interact with the rest of the diagnostic platform,\nthus reducing time-to-mitigate and saving crucial engineering cycles when they\nmatter most. This contrasts with platforms like Datadog and New Relic, which\nprimarily focus on monitoring and require manual intervention for mitigation.\nARCAS uses a Large Language Model (LLM) to prioritize Auto-TSGs outputs and\ntake appropriate actions, thus suppressing the costly requirement of\nunderstanding the general behavior of the system. We explain the key concepts\nbehind ARCAS and demonstrate how it has been successfully used for multiple\nproducts across Azure Synapse Analytics and Microsoft Fabric Synapse Data\nWarehouse.",
      "tldr_zh": "本研究介绍了 ARCAS（Automated Root Cause Analysis System），一个基于 Domain Specific Language (DSL) 的诊断平台，旨在为复杂数据产品提供快速诊断和低学习曲线的解决方案。ARCAS 通过一组可并行执行的自动故障排除指南 (Auto-TSGs) 利用产品遥测数据检测问题并实时应用缓解措施，允许主题专家快速创建相关指南而无需深入了解平台交互，从而减少问题解决时间并节省工程资源。与 Datadog 和 New Relic 等平台不同，ARCAS 整合 Large Language Model (LLM) 来优先处理 Auto-TSGs 输出并自动采取行动，避免了手动干预的需求。实验证明，该系统已在 Azure Synapse Analytics 和 Microsoft Fabric Synapse Data Warehouse 等多个产品中成功应用，显著提升了诊断效率。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "13 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.15374v1",
      "published_date": "2024-12-19 20:10:54 UTC",
      "updated_date": "2024-12-19 20:10:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:10:14.142477"
    },
    {
      "arxiv_id": "2412.15373v1",
      "title": "Granger Causality Detection with Kolmogorov-Arnold Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Hongyu Lin",
        "Mohan Ren",
        "Paolo Barucca",
        "Tomaso Aste"
      ],
      "abstract": "Discovering causal relationships in time series data is central in many\nscientific areas, ranging from economics to climate science. Granger causality\nis a powerful tool for causality detection. However, its original formulation\nis limited by its linear form and only recently nonlinear machine-learning\ngeneralizations have been introduced. This study contributes to the definition\nof neural Granger causality models by investigating the application of\nKolmogorov-Arnold networks (KANs) in Granger causality detection and comparing\ntheir capabilities against multilayer perceptrons (MLP). In this work, we\ndevelop a framework called Granger Causality KAN (GC-KAN) along with a tailored\ntraining approach designed specifically for Granger causality detection. We\ntest this framework on both Vector Autoregressive (VAR) models and chaotic\nLorenz-96 systems, analysing the ability of KANs to sparsify input features by\nidentifying Granger causal relationships, providing a concise yet accurate\nmodel for Granger causality detection. Our findings show the potential of KANs\nto outperform MLPs in discerning interpretable Granger causal relationships,\nparticularly for the ability of identifying sparse Granger causality patterns\nin high-dimensional settings, and more generally, the potential of AI in\ncausality discovery for the dynamical laws in physical systems.",
      "tldr_zh": "本研究探讨了Kolmogorov-Arnold networks (KANs)在Granger causality检测中的应用，以克服传统线性Granger因果性的局限性，并与multilayer perceptrons (MLP)进行比较。研究开发了Granger Causality KAN (GC-KAN)框架及其专属训练方法，用于识别时间序列数据中的因果关系，并在Vector Autoregressive (VAR)模型和chaotic Lorenz-96系统中进行测试。结果显示，KANs在高维设置中更擅长识别稀疏Granger因果模式，并整体优于MLPs，提供更具可解释性的因果发现模型，从而彰显了AI在物理系统动态法则分析中的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, 2 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2412.15373v1",
      "published_date": "2024-12-19 20:10:34 UTC",
      "updated_date": "2024-12-19 20:10:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:10:26.945803"
    },
    {
      "arxiv_id": "2412.15363v1",
      "title": "Making Transparency Advocates: An Educational Approach Towards Better Algorithmic Transparency in Practice",
      "title_zh": "培养透明度倡导者：一种通往更好地算法透明度在实践中的教育方法",
      "authors": [
        "Andrew Bell",
        "Julia Stoyanovich"
      ],
      "abstract": "Concerns about the risks and harms posed by artificial intelligence (AI) have\nresulted in significant study into algorithmic transparency, giving rise to a\nsub-field known as Explainable AI (XAI). Unfortunately, despite a decade of\ndevelopment in XAI, an existential challenge remains: progress in research has\nnot been fully translated into the actual implementation of algorithmic\ntransparency by organizations. In this work, we test an approach for addressing\nthe challenge by creating transparency advocates, or motivated individuals\nwithin organizations who drive a ground-up cultural shift towards improved\nalgorithmic transparency.\n  Over several years, we created an open-source educational workshop on\nalgorithmic transparency and advocacy. We delivered the workshop to\nprofessionals across two separate domains to improve their algorithmic\ntransparency literacy and willingness to advocate for change. In the weeks\nfollowing the workshop, participants applied what they learned, such as\nspeaking up for algorithmic transparency at an organization-wide AI strategy\nmeeting. We also make two broader observations: first, advocacy is not a\nmonolith and can be broken down into different levels. Second, individuals'\nwillingness for advocacy is affected by their professional field. For example,\nnews and media professionals may be more likely to advocate for algorithmic\ntransparency than those working at technology start-ups.",
      "tldr_zh": "这项研究探讨了Explainable AI (XAI)领域面临的挑战，即尽管研究进展显著，但算法透明度在组织中的实际实施仍不足。为解决这一问题，作者提出通过教育工作坊培养transparency advocates，即组织内的个体，推动基层文化变革以提升算法透明度实践。工作坊是开源设计，针对不同领域的专业人士，提高他们的算法透明度素养和倡导意愿。实验显示，参与者在工作坊后积极应用所学，例如在组织AI策略会议上发言支持透明度。研究还观察到，倡导行为可分为不同级别，且受专业领域影响，如新闻媒体从业者比科技初创企业员工更愿意倡导算法透明度。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.15363v1",
      "published_date": "2024-12-19 19:49:59 UTC",
      "updated_date": "2024-12-19 19:49:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:10:38.320922"
    },
    {
      "arxiv_id": "2412.15353v1",
      "title": "GeoPro-Net: Learning Interpretable Spatiotemporal Prediction Models through Statistically-Guided Geo-Prototyping",
      "title_zh": "翻译失败",
      "authors": [
        "Bang An",
        "Xun Zhou",
        "Zirui Zhou",
        "Ronilo Ragodos",
        "Zenglin Xu",
        "Jun Luo"
      ],
      "abstract": "The problem of forecasting spatiotemporal events such as crimes and accidents\nis crucial to public safety and city management. Besides accuracy,\ninterpretability is also a key requirement for spatiotemporal forecasting\nmodels to justify the decisions. Interpretation of the spatiotemporal\nforecasting mechanism is, however, challenging due to the complexity of\nmulti-source spatiotemporal features, the non-intuitive nature of\nspatiotemporal patterns for non-expert users, and the presence of spatial\nheterogeneity in the data. Currently, no existing deep learning model\nintrinsically interprets the complex predictive process learned from\nmulti-source spatiotemporal features. To bridge the gap, we propose GeoPro-Net,\nan intrinsically interpretable spatiotemporal model for spatiotemporal event\nforecasting problems. GeoPro-Net introduces a novel Geo-concept convolution\noperation, which employs statistical tests to extract predictive patterns in\nthe input as Geo-concepts, and condenses the Geo-concept-encoded input through\ninterpretable channel fusion and geographic-based pooling. In addition,\nGeoPro-Net learns different sets of prototypes of concepts inherently, and\nprojects them to real-world cases for interpretation. Comprehensive experiments\nand case studies on four real-world datasets demonstrate that GeoPro-Net\nprovides better interpretability while still achieving competitive prediction\nperformance compared with state-of-the-art baselines.",
      "tldr_zh": "该论文针对时空事件预测（如犯罪和事故）的问题，强调模型的准确性和可解释性，解决现有深度学习模型在处理多源时空特征时的复杂性和空间异质性挑战。GeoPro-Net 提出了一种固有可解释的时空模型，通过 Geo-concept convolution 操作利用统计测试提取预测模式（Geo-concepts），并结合可解释的通道融合和基于地理的池化来凝练输入数据，同时学习概念原型并投影到真实案例以增强解读。实验在四个真实数据集上表明，GeoPro-Net 比最先进基线模型提供了更好的可解释性，同时保持了竞争性的预测性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.15353v1",
      "published_date": "2024-12-19 19:39:16 UTC",
      "updated_date": "2024-12-19 19:39:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:10:49.301129"
    },
    {
      "arxiv_id": "2412.15347v1",
      "title": "Exploring Machine Learning Engineering for Object Detection and Tracking by Unmanned Aerial Vehicle (UAV)",
      "title_zh": "翻译失败",
      "authors": [
        "Aneesha Guna",
        "Parth Ganeriwala",
        "Siddhartha Bhattacharyya"
      ],
      "abstract": "With the advancement of deep learning methods it is imperative that\nautonomous systems will increasingly become intelligent with the inclusion of\nadvanced machine learning algorithms to execute a variety of autonomous\noperations. One such task involves the design and evaluation for a subsystem of\nthe perception system for object detection and tracking. The challenge in the\ncreation of software to solve the task is in discovering the need for a\ndataset, annotation of the dataset, selection of features, integration and\nrefinement of existing algorithms, while evaluating performance metrics through\ntraining and testing. This research effort focuses on the development of a\nmachine learning pipeline emphasizing the inclusion of assurance methods with\nincreasing automation. In the process, a new dataset was created by collecting\nvideos of moving object such as Roomba vacuum cleaner, emulating search and\nrescue (SAR) for indoor environment. Individual frames were extracted from the\nvideos and labeled using a combination of manual and automated techniques. This\nannotated dataset was refined for accuracy by initially training it on YOLOv4.\nAfter the refinement of the dataset it was trained on a second YOLOv4 and a\nMask R-CNN model, which is deployed on a Parrot Mambo drone to perform\nreal-time object detection and tracking. Experimental results demonstrate the\neffectiveness of the models in accurately detecting and tracking the Roomba\nacross multiple trials, achieving an average loss of 0.1942 and 96% accuracy.",
      "tldr_zh": "该研究探讨了无人机(UAV)上机器学习工程的应用，针对物体检测和跟踪任务设计了一个机器学习管道，包括数据集创建、标注和算法优化，以提升自主系统的智能性。研究者收集了模拟室内搜索和救援(SAR)的视频数据集（如Roomba真空清洁器），并使用手动和自动技术标注后，在YOLOv4和Mask R-CNN模型上进行训练和精炼。实验结果显示，该系统部署在Parrot Mambo无人机上，实现实时检测和跟踪，平均损失为0.1942，准确率达96%。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at ICMLA '24",
      "pdf_url": "http://arxiv.org/pdf/2412.15347v1",
      "published_date": "2024-12-19 19:27:31 UTC",
      "updated_date": "2024-12-19 19:27:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:11:01.002231"
    },
    {
      "arxiv_id": "2412.15212v1",
      "title": "Scaling 4D Representations",
      "title_zh": "翻译失败",
      "authors": [
        "João Carreira",
        "Dilara Gokay",
        "Michael King",
        "Chuhan Zhang",
        "Ignacio Rocco",
        "Aravindh Mahendran",
        "Thomas Albert Keck",
        "Joseph Heyward",
        "Skanda Koppula",
        "Etienne Pot",
        "Goker Erdogan",
        "Yana Hasson",
        "Yi Yang",
        "Klaus Greff",
        "Guillaume Le Moing",
        "Sjoerd van Steenkiste",
        "Daniel Zoran",
        "Drew A. Hudson",
        "Pedro Vélez",
        "Luisa Polanía",
        "Luke Friedman",
        "Chris Duvarney",
        "Ross Goroshin",
        "Kelsey Allen",
        "Jacob Walker",
        "Rishabh Kabra",
        "Eric Aboussouan",
        "Jennifer Sun",
        "Thomas Kipf",
        "Carl Doersch",
        "Viorica Pătrăucean",
        "Dima Damen",
        "Pauline Luc",
        "Mehdi S. M. Sajjadi",
        "Andrew Zisserman"
      ],
      "abstract": "Scaling has not yet been convincingly demonstrated for pure self-supervised\nlearning from video. However, prior work has focused evaluations on\nsemantic-related tasks $\\unicode{x2013}$ action classification, ImageNet\nclassification, etc. In this paper we focus on evaluating self-supervised\nlearning on non-semantic vision tasks that are more spatial (3D) and temporal\n(+1D = 4D), such as camera pose estimation, point and object tracking, and\ndepth estimation. We show that by learning from very large video datasets,\nmasked auto-encoding (MAE) with transformer video models actually scales,\nconsistently improving performance on these 4D tasks, as model size increases\nfrom 20M all the way to the largest by far reported self-supervised video model\n$\\unicode{x2013}$ 22B parameters. Rigorous apples-to-apples comparison with\nmany recent image and video models demonstrates the benefits of scaling 4D\nrepresentations.",
      "tldr_zh": "该论文探讨了在纯自监督视频学习中扩展模型规模的问题，强调评估应从语义相关任务（如动作分类和 ImageNet 分类）转向空间（3D）和时间（+1D = 4D）任务，例如相机姿态估计、点和对象跟踪以及深度估计。研究采用 masked auto-encoding (MAE) 与 transformer 视频模型，从大型视频数据集学习，发现模型规模从 20M 参数增加到 22B 参数时，能持续提升这些 4D 任务的性能。严格与现有图像和视频模型比较后，证明了扩展 4D 表示的益处，为自监督学习提供了新见解。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.15212v1",
      "published_date": "2024-12-19 18:59:51 UTC",
      "updated_date": "2024-12-19 18:59:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:11:13.829015"
    },
    {
      "arxiv_id": "2412.15209v1",
      "title": "PRIMA: Multi-Image Vision-Language Models for Reasoning Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Muntasir Wahed",
        "Kiet A. Nguyen",
        "Adheesh Sunil Juvekar",
        "Xinzhuo Li",
        "Xiaona Zhou",
        "Vedant Shah",
        "Tianjiao Yu",
        "Pinar Yanardag",
        "Ismini Lourentzou"
      ],
      "abstract": "Despite significant advancements in Large Vision-Language Models (LVLMs),\nexisting pixel-grounding models operate on single-image settings, limiting\ntheir ability to perform detailed, fine-grained comparisons across multiple\nimages. Conversely, current multi-image understanding models lack pixel-level\ngrounding. Our work addresses this gap by introducing the task of multi-image\npixel-grounded reasoning segmentation, and PRIMA, a novel LVLM that integrates\npixel-level grounding with robust multi-image reasoning capabilities to produce\ncontextually rich, pixel-grounded explanations. Central to PRIMA is an\nefficient vision module that queries fine-grained visual representations across\nmultiple images, reducing TFLOPs by $25.3\\%$. To support training and\nevaluation, we curate $M^4Seg$, a new reasoning segmentation benchmark\nconsisting of $\\sim$224K question-answer pairs that require fine-grained visual\nunderstanding across multiple images. Experimental results demonstrate PRIMA\noutperforms state-of-the-art baselines.",
      "tldr_zh": "该研究指出了现有 Large Vision-Language Models (LVLMs) 在多图像处理上的局限性，即无法进行细粒度比较或像素级 grounding，因此引入了 multi-image pixel-grounded reasoning segmentation 的新任务。论文提出 PRIMA，一种新型 LVLM，通过整合像素级 grounding 和多图像推理能力，生成上下文丰富的像素级解释，其核心是高效的 vision module，能查询多个图像的细粒度视觉表示，并减少 TFLOPs 25.3%。为了支持模型训练和评估，研究团队创建了 M4Seg 基准数据集，包含约224K 个问题-答案对，强调跨图像的细粒度视觉理解。实验结果显示，PRIMA 超过了 state-of-the-art 基线模型，在多图像推理分割任务中表现出色。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Project page: https://plan-lab.github.io/prima",
      "pdf_url": "http://arxiv.org/pdf/2412.15209v1",
      "published_date": "2024-12-19 18:59:44 UTC",
      "updated_date": "2024-12-19 18:59:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:11:25.652140"
    },
    {
      "arxiv_id": "2412.15204v2",
      "title": "LongBench v2: Towards Deeper Understanding and Reasoning on Realistic Long-context Multitasks",
      "title_zh": "翻译失败",
      "authors": [
        "Yushi Bai",
        "Shangqing Tu",
        "Jiajie Zhang",
        "Hao Peng",
        "Xiaozhi Wang",
        "Xin Lv",
        "Shulin Cao",
        "Jiazheng Xu",
        "Lei Hou",
        "Yuxiao Dong",
        "Jie Tang",
        "Juanzi Li"
      ],
      "abstract": "This paper introduces LongBench v2, a benchmark designed to assess the\nability of LLMs to handle long-context problems requiring deep understanding\nand reasoning across real-world multitasks. LongBench v2 consists of 503\nchallenging multiple-choice questions, with contexts ranging from 8k to 2M\nwords, across six major task categories: single-document QA, multi-document QA,\nlong in-context learning, long-dialogue history understanding, code repository\nunderstanding, and long structured data understanding. To ensure the breadth\nand the practicality, we collect data from nearly 100 highly educated\nindividuals with diverse professional backgrounds. We employ both automated and\nmanual review processes to maintain high quality and difficulty, resulting in\nhuman experts achieving only 53.7% accuracy under a 15-minute time constraint.\nOur evaluation reveals that the best-performing model, when directly answers\nthe questions, achieves only 50.1% accuracy. In contrast, the o1-preview model,\nwhich includes longer reasoning, achieves 57.7%, surpassing the human baseline\nby 4%. These results highlight the importance of enhanced reasoning ability and\nscaling inference-time compute to tackle the long-context challenges in\nLongBench v2. The project is available at https://longbench2.github.io.",
      "tldr_zh": "这篇论文介绍了 LongBench v2，这是一个基准测试，用于评估 LLMs 在处理真实长上下文多任务时的深度理解和推理能力，包含 503 个多项选择题，上下文长度从 8k 到 2M 单词，覆盖单文档 QA、多文档 QA、长上下文学习、长对话历史理解、代码仓库理解和长结构化数据理解。数据由近 100 名受过高等教育的专业人士收集，并通过自动化和手动审查确保高质量和难度，导致人类专家在 15 分钟内准确率仅 53.7%。实验结果显示，最佳模型直接回答准确率仅 50.1%，而 o1-preview 模型通过更长的推理能力达到 57.7%，超过了人类基线 4%，突显了增强推理和扩展计算资源的重要性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "26 pages, 13 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.15204v2",
      "published_date": "2024-12-19 18:59:17 UTC",
      "updated_date": "2025-01-03 11:44:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:11:38.579818"
    },
    {
      "arxiv_id": "2412.15200v1",
      "title": "DI-PCG: Diffusion-based Efficient Inverse Procedural Content Generation for High-quality 3D Asset Creation",
      "title_zh": "翻译失败",
      "authors": [
        "Wang Zhao",
        "Yan-Pei Cao",
        "Jiale Xu",
        "Yuejiang Dong",
        "Ying Shan"
      ],
      "abstract": "Procedural Content Generation (PCG) is powerful in creating high-quality 3D\ncontents, yet controlling it to produce desired shapes is difficult and often\nrequires extensive parameter tuning. Inverse Procedural Content Generation aims\nto automatically find the best parameters under the input condition. However,\nexisting sampling-based and neural network-based methods still suffer from\nnumerous sample iterations or limited controllability. In this work, we present\nDI-PCG, a novel and efficient method for Inverse PCG from general image\nconditions. At its core is a lightweight diffusion transformer model, where PCG\nparameters are directly treated as the denoising target and the observed images\nas conditions to control parameter generation. DI-PCG is efficient and\neffective. With only 7.6M network parameters and 30 GPU hours to train, it\ndemonstrates superior performance in recovering parameters accurately, and\ngeneralizing well to in-the-wild images. Quantitative and qualitative\nexperiment results validate the effectiveness of DI-PCG in inverse PCG and\nimage-to-3D generation tasks. DI-PCG offers a promising approach for efficient\ninverse PCG and represents a valuable exploration step towards a 3D generation\npath that models how to construct a 3D asset using parametric models.",
      "tldr_zh": "本研究提出 DI-PCG，一种基于扩散模型的高效逆向程序化内容生成（Inverse PCG）方法，旨在从一般图像条件自动优化参数，以创建高质量3D资产。该方法的核心是一个轻量级扩散transformer模型，将PCG参数直接作为去噪目标，并使用输入图像作为条件进行控制，从而避免了传统方法的多次采样迭代和控制性问题。DI-PCG仅需7.6M网络参数和30 GPU小时的训练，即可准确恢复参数并泛化到野外图像；实验结果显示，其在逆向PCG和图像到3D生成任务中表现出色，提供了一个高效的3D资产构建路径。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR"
      ],
      "primary_category": "cs.CV",
      "comment": "Project page: https://thuzhaowang.github.io/projects/DI-PCG/",
      "pdf_url": "http://arxiv.org/pdf/2412.15200v1",
      "published_date": "2024-12-19 18:58:46 UTC",
      "updated_date": "2024-12-19 18:58:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:11:49.042996"
    },
    {
      "arxiv_id": "2412.15188v4",
      "title": "LMFusion: Adapting Pretrained Language Models for Multimodal Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Weijia Shi",
        "Xiaochuang Han",
        "Chunting Zhou",
        "Weixin Liang",
        "Xi Victoria Lin",
        "Luke Zettlemoyer",
        "Lili Yu"
      ],
      "abstract": "We present LMFusion, a framework for empowering pretrained text-only large\nlanguage models (LLMs) with multimodal generative capabilities, enabling them\nto understand and generate both text and images in arbitrary sequences.\nLMFusion leverages existing Llama-3's weights for processing texts\nautoregressively while introducing additional and parallel transformer modules\nfor processing images with diffusion. During training, the data from each\nmodality is routed to its dedicated modules: modality-specific feedforward\nlayers, query-key-value projections, and normalization layers process each\nmodality independently, while the shared self-attention layers allow\ninteractions across text and image features. By freezing the text-specific\nmodules and only training the image-specific modules, LMFusion preserves the\nlanguage capabilities of text-only LLMs while developing strong visual\nunderstanding and generation abilities. Compared to methods that pretrain\nmultimodal generative models from scratch, our experiments demonstrate that,\nLMFusion improves image understanding by 20% and image generation by 3.6% using\nonly 50% of the FLOPs while maintaining Llama-3's language capabilities. We\nalso demonstrate that this framework can adapt existing vision-language models\nwith multimodal generation ability. Overall, this framework not only leverages\nexisting computational investments in text-only LLMs but also enables the\nparallel development of language and vision capabilities, presenting a\npromising direction for efficient multimodal model development.",
      "tldr_zh": "本文提出 LMFusion 框架，用于将预训练的纯文本大型语言模型 (LLMs) 如 Llama-3 适配为多模态生成系统，支持文本和图像的任意序列理解与生成。框架通过添加并行 transformer 模块处理图像扩散，同时利用共享自注意力层实现模态间交互，并在训练中冻结文本模块只训练图像模块，从而保留原有语言能力。实验结果显示，LMFusion 比从零预训练的多模态模型提高图像理解 20% 和图像生成 3.6%，并仅使用 50% 的 FLOPs。该方法不仅利用现有 LLMs 的计算投资，还促进语言和视觉能力的并行发展，提供高效的多模态模型开发新路径。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Name change: LlamaFusion to LMFusion",
      "pdf_url": "http://arxiv.org/pdf/2412.15188v4",
      "published_date": "2024-12-19 18:56:24 UTC",
      "updated_date": "2025-02-05 02:26:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:12:02.792987"
    },
    {
      "arxiv_id": "2412.15177v1",
      "title": "Critical-Questions-of-Thought: Steering LLM reasoning with Argumentative Querying",
      "title_zh": "翻译失败",
      "authors": [
        "Federico Castagna",
        "Isabel Sassoon",
        "Simon Parsons"
      ],
      "abstract": "Studies have underscored how, regardless of the recent breakthrough and swift\nadvances in AI research, even state-of-the-art Large Language models (LLMs)\ncontinue to struggle when performing logical and mathematical reasoning. The\nresults seem to suggest that LLMs still work as (highly advanced) data pattern\nidentifiers, scoring poorly when attempting to generalise and solve reasoning\nproblems the models have never previously seen or that are not close to samples\npresented in their training data. To address this compelling concern, this\npaper makes use of the notion of critical questions from the literature on\nargumentation theory, focusing in particular on Toulmin's model of\nargumentation. We show that employing these critical questions can improve the\nreasoning capabilities of LLMs. By probing the rationale behind the models'\nreasoning process, the LLM can assess whether some logical mistake is occurring\nand correct it before providing the final reply to the user prompt. The\nunderlying idea is drawn from the gold standard of any valid argumentative\nprocedure: the conclusion is valid if it is entailed by accepted premises. Or,\nto paraphrase such Aristotelian principle in a real-world approximation,\ncharacterised by incomplete information and presumptive logic, the conclusion\nis valid if not proved otherwise. This approach successfully steers the models'\noutput through a reasoning pipeline, resulting in better performance against\nthe baseline and its Chain-of-Thought (CoT) implementation. To this end, an\nextensive evaluation of the proposed approach on the MT-Bench Reasoning and\nMath tasks across a range of LLMs is provided.",
      "tldr_zh": "本研究针对大型语言模型(LLMs)在逻辑和数学推理方面的局限性，提出了一种基于论证理论的“Critical-Questions-of-Thought”方法，利用Toulmin's model中的关键问题来指导模型的推理过程，从而检测并纠正潜在的逻辑错误。方法通过一个推理管道，确保结论仅基于可接受的前提，从而提升模型的泛化能力和输出质量。在MT-Bench Reasoning和Math任务上的广泛评估显示，该方法在多种LLMs上比基线和Chain-of-Thought (CoT)实现表现出显著改善。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.15177v1",
      "published_date": "2024-12-19 18:51:30 UTC",
      "updated_date": "2024-12-19 18:51:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:12:14.170359"
    },
    {
      "arxiv_id": "2412.15166v1",
      "title": "Human-Humanoid Robots Cross-Embodiment Behavior-Skill Transfer Using Decomposed Adversarial Learning from Demonstration",
      "title_zh": "翻译失败",
      "authors": [
        "Junjia Liu",
        "Zhuo Li",
        "Minghao Yu",
        "Zhipeng Dong",
        "Sylvain Calinon",
        "Darwin Caldwell",
        "Fei Chen"
      ],
      "abstract": "Humanoid robots are envisioned as embodied intelligent agents capable of\nperforming a wide range of human-level loco-manipulation tasks, particularly in\nscenarios requiring strenuous and repetitive labor. However, learning these\nskills is challenging due to the high degrees of freedom of humanoid robots,\nand collecting sufficient training data for humanoid is a laborious process.\nGiven the rapid introduction of new humanoid platforms, a cross-embodiment\nframework that allows generalizable skill transfer is becoming increasingly\ncritical. To address this, we propose a transferable framework that reduces the\ndata bottleneck by using a unified digital human model as a common prototype\nand bypassing the need for re-training on every new robot platform. The model\nlearns behavior primitives from human demonstrations through adversarial\nimitation, and the complex robot structures are decomposed into functional\ncomponents, each trained independently and dynamically coordinated. Task\ngeneralization is achieved through a human-object interaction graph, and skills\nare transferred to different robots via embodiment-specific kinematic motion\nretargeting and dynamic fine-tuning. Our framework is validated on five\nhumanoid robots with diverse configurations, demonstrating stable\nloco-manipulation and highlighting its effectiveness in reducing data\nrequirements and increasing the efficiency of skill transfer across platforms.",
      "tldr_zh": "本研究提出了一种跨形态行为技能转移框架，旨在解决人形机器人学习loco-manipulation任务时面临的自由度高和数据收集laborious问题。该框架使用统一的数字人类模型作为共同原型，通过Decomposed Adversarial Learning from Demonstration从人类演示中学习行为 primitives，并将复杂机器人结构分解为功能组件进行独立训练和动态协调。任务泛化通过human-object interaction graph实现，而技能转移则依赖于特定于形态的kinematic motion retargeting和动态微调。在五种不同配置的人形机器人上验证，该框架展示了稳定的loco-manipulation性能，并显著减少了数据需求，提高了技能转移效率。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "9 pages, 8 figures. Accepted by IEEE Robotics and Automation Magazine",
      "pdf_url": "http://arxiv.org/pdf/2412.15166v1",
      "published_date": "2024-12-19 18:41:45 UTC",
      "updated_date": "2024-12-19 18:41:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:12:25.237015"
    },
    {
      "arxiv_id": "2412.15163v1",
      "title": "Operationalising Rawlsian Ethics for Fairness in Norm-Learning Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Jessica Woodgate",
        "Paul Marshall",
        "Nirav Ajmeri"
      ],
      "abstract": "Social norms are standards of behaviour common in a society. However, when\nagents make decisions without considering how others are impacted, norms can\nemerge that lead to the subjugation of certain agents. We present RAWL-E, a\nmethod to create ethical norm-learning agents. RAWL-E agents operationalise\nmaximin, a fairness principle from Rawlsian ethics, in their decision-making\nprocesses to promote ethical norms by balancing societal well-being with\nindividual goals. We evaluate RAWL-E agents in simulated harvesting scenarios.\nWe find that norms emerging in RAWL-E agent societies enhance social welfare,\nfairness, and robustness, and yield higher minimum experience compared to those\nthat emerge in agent societies that do not implement Rawlsian ethics.",
      "tldr_zh": "本论文提出 RAWL-E 方法，将 Rawlsian ethics 中的 maximin 原则应用于规范学习代理的决策过程，以平衡社会福祉和个人目标，从而促进公平的社会规范。该方法通过考虑代理间影响，防止某些代理被边缘化。在模拟收获场景的实验中，RAWL-E 代理产生的规范显著提高了社会福利、公平性、稳健性和最低经验水平，相比不采用 Rawlsian ethics 的代理表现更优。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.MA",
      "comment": "14 pages, 7 figures, 8 tables (and supplementary material with\n  reproducibility and additional results), accepted at AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.15163v1",
      "published_date": "2024-12-19 18:38:13 UTC",
      "updated_date": "2024-12-19 18:38:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:12:36.604181"
    },
    {
      "arxiv_id": "2412.15151v3",
      "title": "Language Models as Continuous Self-Evolving Data Engineers",
      "title_zh": "语言模型作为持续自我演化的数据工程师",
      "authors": [
        "Peidong Wang",
        "Ming Wang",
        "Zhiming Ma",
        "Xiaocui Yang",
        "Shi Feng",
        "Daling Wang",
        "Yifei Zhang",
        "Kaisong Song"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities on\nvarious tasks, while the further evolvement is limited to the lack of\nhigh-quality training data. In addition, traditional training approaches rely\ntoo much on expert-labeled data, setting a ceiling on the performance of LLMs.\nTo address this issue, we propose a novel paradigm named LANCE (LANguage models\nas Continuous self-Evolving data engineers) that enables LLMs to train\nthemselves by autonomously generating, cleaning, reviewing, and annotating data\nwith preference information. Our approach demonstrates that LLMs can serve as\ncontinuous self-evolving data engineers, significantly reducing the time and\ncost of the post-training data construction. Through iterative fine-tuning on\nQwen2 series models, we validate the effectiveness of LANCE across various\ntasks, showing that it can maintain high-quality data generation and\ncontinuously improve model performance. Across multiple benchmark dimensions,\nLANCE results in an average score enhancement of 3.64 for Qwen2-7B and 1.75 for\nQwen2-7B-Instruct. This training paradigm with autonomous data construction not\nonly reduces the reliance on human experts or external models but also ensures\nthat the data aligns with human preferences, paving the way for the development\nof future superintelligent systems that can exceed human capabilities. Codes\nare available at: https://github.com/Control-derek/LANCE.",
      "tldr_zh": "本研究提出 LANCE 范式，将大型语言模型 (LLMs) 作为持续自我进化的数据工程师，通过自主生成、清理、审查和标注数据（包括偏好信息），以解决高质量训练数据短缺和对专家依赖的问题。LANCE 通过在 Qwen2 系列模型上的迭代微调，实现模型性能持续提升，在多个基准测试中，Qwen2-7B 的平均分数提高 3.64，Qwen2-7B-Instruct 提高 1.75。该方法显著降低了数据构建的时间和成本，确保数据与人类偏好一致，并为开发超越人类能力的超级智能系统提供新路径。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.15151v3",
      "published_date": "2024-12-19 18:28:41 UTC",
      "updated_date": "2025-02-13 11:37:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:12:50.183960"
    },
    {
      "arxiv_id": "2412.15150v1",
      "title": "Leveraging Color Channel Independence for Improved Unsupervised Object Detection",
      "title_zh": "利用颜色",
      "authors": [
        "Bastian Jäckl",
        "Yannick Metz",
        "Udo Schlegel",
        "Daniel A. Keim",
        "Maximilian T. Fischer"
      ],
      "abstract": "Object-centric architectures can learn to extract distinct object\nrepresentations from visual scenes, enabling downstream applications on the\nobject level. Similarly to autoencoder-based image models, object-centric\napproaches have been trained on the unsupervised reconstruction loss of images\nencoded by RGB color spaces. In our work, we challenge the common assumption\nthat RGB images are the optimal color space for unsupervised learning in\ncomputer vision. We discuss conceptually and empirically that other color\nspaces, such as HSV, bear essential characteristics for object-centric\nrepresentation learning, like robustness to lighting conditions. We further\nshow that models improve when requiring them to predict additional color\nchannels. Specifically, we propose to transform the predicted targets to the\nRGB-S space, which extends RGB with HSV's saturation component and leads to\nmarkedly better reconstruction and disentanglement for five common evaluation\ndatasets. The use of composite color spaces can be implemented with basically\nno computational overhead, is agnostic of the models' architecture, and is\nuniversally applicable across a wide range of visual computing tasks and\ntraining types. The findings of our approach encourage additional\ninvestigations in computer vision tasks beyond object-centric learning.",
      "tldr_zh": "本研究质疑了在无监督物体检测（unsupervised object detection）中依赖 RGB 颜色空间的传统假设，并探讨了其他颜色空间如 HSV 的优势，例如对光照条件的鲁棒性。作者提出一种方法，通过要求模型预测额外的颜色通道，将目标转换为 RGB-S 空间（扩展 RGB 并加入 HSV 的饱和度组件），从而显著提高了五个常见评估数据集上的重建和解缠结（disentanglement）性能。实验结果显示，该方法几乎没有计算开销，且适用于各种模型架构和视觉任务，鼓励在更广泛的计算机视觉领域进行进一步探索。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "I.4.8; I.2.10"
      ],
      "primary_category": "cs.CV",
      "comment": "38 pages incl. references, 16 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.15150v1",
      "published_date": "2024-12-19 18:28:37 UTC",
      "updated_date": "2024-12-19 18:28:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:13:00.912942"
    },
    {
      "arxiv_id": "2412.15135v3",
      "title": "Probabilistic Strategy Logic with Degrees of Observability",
      "title_zh": "翻译失败",
      "authors": [
        "Chunyan Mu",
        "Nima Motamed",
        "Natasha Alechina",
        "Brian Logan"
      ],
      "abstract": "There has been considerable work on reasoning about the strategic ability of\nagents under imperfect information. However, existing logics such as\nProbabilistic Strategy Logic are unable to express properties relating to\ninformation transparency. Information transparency concerns the extent to which\nagents' actions and behaviours are observable by other agents. Reasoning about\ninformation transparency is useful in many domains including security, privacy,\nand decision-making. In this paper, we present a formal framework for reasoning\nabout information transparency properties in stochastic multi-agent systems. We\nextend Probabilistic Strategy Logic with new observability operators that\ncapture the degree of observability of temporal properties by agents. We show\nthat the model checking problem for the resulting logic is decidable.",
      "tldr_zh": "本论文探讨了代理在不完美信息下的战略能力，指出现有的 Probabilistic Strategy Logic 无法表达信息透明度相关属性，该属性涉及代理行为对其他代理的可观察程度，并在安全、隐私和决策等领域有重要应用。论文扩展了 Probabilistic Strategy Logic，通过引入新的 observability operators 来捕捉代理对时间属性的可观察度，构建了一个用于随机多代理系统的正式推理框架。结果表明，该逻辑的 model checking 问题是可判定的，从而为更全面的战略推理提供了基础。",
      "categories": [
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.15135v3",
      "published_date": "2024-12-19 18:17:04 UTC",
      "updated_date": "2025-01-06 03:35:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:13:12.593802"
    },
    {
      "arxiv_id": "2412.15129v1",
      "title": "Jet: A Modern Transformer-Based Normalizing Flow",
      "title_zh": "翻译失败",
      "authors": [
        "Alexander Kolesnikov",
        "André Susano Pinto",
        "Michael Tschannen"
      ],
      "abstract": "In the past, normalizing generative flows have emerged as a promising class\nof generative models for natural images. This type of model has many modeling\nadvantages: the ability to efficiently compute log-likelihood of the input\ndata, fast generation and simple overall structure. Normalizing flows remained\na topic of active research but later fell out of favor, as visual quality of\nthe samples was not competitive with other model classes, such as GANs,\nVQ-VAE-based approaches or diffusion models. In this paper we revisit the\ndesign of the coupling-based normalizing flow models by carefully ablating\nprior design choices and using computational blocks based on the Vision\nTransformer architecture, not convolutional neural networks. As a result, we\nachieve state-of-the-art quantitative and qualitative performance with a much\nsimpler architecture. While the overall visual quality is still behind the\ncurrent state-of-the-art models, we argue that strong normalizing flow models\ncan help advancing research frontier by serving as building components of more\npowerful generative models.",
      "tldr_zh": "该论文提出了一种现代 normalizing flows 模型名为 Jet，通过重新审视基于耦合的设计选择，并采用 Vision Transformer 架构取代传统的卷积神经网络，提升了模型的整体结构和性能。相比以往，Jet 在定量和定性指标上实现了 state-of-the-art 水平，尽管样本视觉质量仍落后于 GANs、VQ-VAE 或扩散模型等竞争者。作者强调，这种强 normalizing flows 模型可作为更强大生成模型的构建组件，帮助推进生成模型研究的前沿。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.15129v1",
      "published_date": "2024-12-19 18:09:42 UTC",
      "updated_date": "2024-12-19 18:09:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:13:25.471035"
    },
    {
      "arxiv_id": "2412.15127v1",
      "title": "Adaptive Pruning for Large Language Models with Structural Importance Awareness",
      "title_zh": "翻译失败",
      "authors": [
        "Haotian Zheng",
        "Jinke Ren",
        "Yushan Sun",
        "Ruichen Zhang",
        "Wenbo Zhang",
        "Zhen Li",
        "Dusit Niyato",
        "Shuguang Cui",
        "Yatong Han"
      ],
      "abstract": "The recent advancements in large language models (LLMs) have significantly\nimproved language understanding and generation capabilities. However, it is\ndifficult to deploy LLMs on resource-constrained edge devices due to their high\ncomputational and storage resource demands. To address this issue, we propose a\nnovel LLM model pruning method, namely structurally-aware adaptive pruning\n(SAAP), to significantly reduce the computational and memory costs while\nmaintaining model performance. We first define an adaptive importance fusion\nmetric to evaluate the importance of all coupled structures in LLMs by\nconsidering their homoscedastic uncertainty. Then, we rank the importance of\nall modules to determine the specific layers that should be pruned to meet\nparticular performance requirements. Furthermore, we develop a new group\nfine-tuning strategy to improve the inference efficiency of LLMs. Finally, we\nevaluate the proposed SAAP method on multiple LLMs across two common tasks,\ni.e., zero-shot classification and text generation. Experimental results show\nthat our SAAP method outperforms several state-of-the-art baseline methods,\nachieving 2.17%, 2.37%, and 2.39% accuracy gains on LLaMA-7B, Vicuna-7B, and\nLLaMA-13B. Additionally, SAAP improves the token generation speed by 5%,\nshowcasing its practical advantages in resource-constrained scenarios.",
      "tldr_zh": "本文提出了一种结构感知自适应修剪(SAAP)方法，用于优化大语言模型(LLMs)，以减少其计算和内存需求，同时维持模型性能。SAAP 通过定义自适应重要性融合指标来评估 LLMs 中耦合结构的 homoscedastic uncertainty，并基于重要性排名选择特定层进行修剪，同时引入 group fine-tuning 策略提升推理效率。在零样本分类和文本生成任务的实验中，SAAP 在 LLaMA-7B、Vicuna-7B 和 LLaMA-13B 上分别实现了 2.17%、2.37% 和 2.39% 的准确率提升，并提高了 5% 的 token 生成速度，适用于资源受限场景。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "12 pages, 6 figures, 12 tables",
      "pdf_url": "http://arxiv.org/pdf/2412.15127v1",
      "published_date": "2024-12-19 18:08:04 UTC",
      "updated_date": "2024-12-19 18:08:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:13:38.136463"
    },
    {
      "arxiv_id": "2412.15118v1",
      "title": "Outcome-Refining Process Supervision for Code Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Zhuohao Yu",
        "Weizheng Gu",
        "Yidong Wang",
        "Zhengran Zeng",
        "Jindong Wang",
        "Wei Ye",
        "Shikun Zhang"
      ],
      "abstract": "Large Language Models have demonstrated remarkable capabilities in code\ngeneration, yet they often struggle with complex programming tasks that require\ndeep algorithmic reasoning. While process supervision through learned reward\nmodels shows promise in guiding reasoning steps, it requires expensive training\ndata and suffers from unreliable evaluation. We propose Outcome-Refining\nProcess Supervision, a novel paradigm that treats outcome refinement itself as\nthe process to be supervised. Our framework leverages concrete execution\nsignals to ground the supervision of reasoning steps, while using\ntree-structured exploration to maintain multiple solution trajectories\nsimultaneously. Experiments demonstrate that our approach enables even smaller\nmodels to achieve high success accuracy and performance metrics on competitive\nprogramming tasks, creates more reliable verification than traditional reward\nmodels without requiring training PRMs. Our approach achieves significant\nimprovements across 5 models and 3 datasets: an average of 26.9% increase in\ncorrectness and 42.2% in efficiency. The results suggest that providing\nstructured reasoning space with concrete verification signals is crucial for\nsolving complex programming tasks. We open-source all our code and data at:\nhttps://github.com/zhuohaoyu/ORPS",
      "tldr_zh": "该研究提出了一种名为 Outcome-Refining Process Supervision 的新范式，用于提升大语言模型在代码生成中的性能，特别是针对需要深度算法推理的复杂编程任务。该框架通过利用具体的执行信号来监督推理步骤，并采用树状结构探索同时维护多个解决方案轨迹，从而避免了传统奖励模型的昂贵训练和不可靠评估。实验结果显示，即使是小型模型，在5个模型和3个数据集上，正确性平均提高了26.9%，效率提高了42.2%。这项工作强调，提供结构化的推理空间和可靠的验证信号是解决复杂编程任务的关键，并开源了所有代码和数据。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.SE"
      ],
      "primary_category": "cs.CL",
      "comment": "18 pages, 5 figures, Code: https://github.com/zhuohaoyu/ORPS",
      "pdf_url": "http://arxiv.org/pdf/2412.15118v1",
      "published_date": "2024-12-19 17:59:42 UTC",
      "updated_date": "2024-12-19 17:59:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:13:50.389740"
    },
    {
      "arxiv_id": "2412.15114v1",
      "title": "Towards Friendly AI: A Comprehensive Review and New Perspectives on Human-AI Alignment",
      "title_zh": "迈向友好人工智能：人类-AI 对齐的全面综述和新视角",
      "authors": [
        "Qiyang Sun",
        "Yupei Li",
        "Emran Alturki",
        "Sunil Munthumoduku Krishna Murthy",
        "Björn W. Schuller"
      ],
      "abstract": "As Artificial Intelligence (AI) continues to advance rapidly, Friendly AI\n(FAI) has been proposed to advocate for more equitable and fair development of\nAI. Despite its importance, there is a lack of comprehensive reviews examining\nFAI from an ethical perspective, as well as limited discussion on its potential\napplications and future directions. This paper addresses these gaps by\nproviding a thorough review of FAI, focusing on theoretical perspectives both\nfor and against its development, and presenting a formal definition in a clear\nand accessible format. Key applications are discussed from the perspectives of\neXplainable AI (XAI), privacy, fairness and affective computing (AC).\nAdditionally, the paper identifies challenges in current technological\nadvancements and explores future research avenues. The findings emphasise the\nsignificance of developing FAI and advocate for its continued advancement to\nensure ethical and beneficial AI development.",
      "tldr_zh": "这篇论文对 Friendly AI (FAI) 进行了全面审查，聚焦于人类-AI 协调（Human-AI Alignment），旨在填补从伦理角度分析 FAI 的空白，并提供清晰的正式定义。\n它探讨了支持和反对 FAI 的理论观点，以及其在 eXplainable AI (XAI)、隐私、公平性和 affective computing (AC) 等领域的关键应用，同时识别了当前技术挑战并提出未来研究方向。\n研究强调，开发 FAI 对确保 AI 的伦理和有益发展至关重要，并呼吁持续推进相关工作。",
      "categories": [
        "cs.AI",
        "cs.CY",
        "I.2.0; K.4.0"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.15114v1",
      "published_date": "2024-12-19 17:56:08 UTC",
      "updated_date": "2024-12-19 17:56:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:14:01.746860"
    },
    {
      "arxiv_id": "2412.15113v1",
      "title": "Associative memory inspires improvements for in-context learning using a novel attention residual stream architecture",
      "title_zh": "翻译失败",
      "authors": [
        "Thomas F Burns",
        "Tomoki Fukai",
        "Christopher J Earls"
      ],
      "abstract": "Large language models (LLMs) demonstrate an impressive ability to utilise\ninformation within the context of their input sequences to appropriately\nrespond to data unseen by the LLM during its training procedure. This ability\nis known as in-context learning (ICL). Humans and non-human animals demonstrate\nsimilar abilities, however their neural architectures differ substantially from\nLLMs. Despite this, a critical component within LLMs, the attention mechanism,\nresembles modern associative memory models, widely used in and influenced by\nthe computational neuroscience community to model biological memory systems.\nUsing this connection, we introduce an associative memory model capable of\nperforming ICL. We use this as inspiration for a novel residual stream\narchitecture which allows information to directly flow between attention heads.\nWe test this architecture during training within a two-layer Transformer and\nshow its ICL abilities manifest more quickly than without this modification. We\nthen apply our architecture in small language models with 8 million parameters,\nfocusing on attention head values, with results also indicating improved ICL\nperformance at this larger and more naturalistic scale.",
      "tldr_zh": "该研究受 associative memory 模型启发，提出一个新颖的 attention residual stream architecture，以改善大型语言模型(LLMs)的 in-context learning (ICL) 能力。该架构允许信息在 attention heads 之间直接流动，从而增强模型对输入序列信息的利用。在两层 Transformer 和 8 百万参数的小型语言模型实验中，这种设计使 ICL 能力更快显现，并显著提升了模型性能。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.CL",
        "92B20, 68T01, 68T37, 68T50",
        "I.2; I.5; I.7; J.2; J.3"
      ],
      "primary_category": "cs.NE",
      "comment": "18 pages, 6 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2412.15113v1",
      "published_date": "2024-12-19 17:55:42 UTC",
      "updated_date": "2024-12-19 17:55:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:14:12.933883"
    },
    {
      "arxiv_id": "2412.15105v1",
      "title": "Exploiting sparse structures and synergy designs to advance situational awareness of electrical power grid",
      "title_zh": "利用稀疏结构和协同设计推进电力电网的态势感知",
      "authors": [
        "Shimiao Li"
      ],
      "abstract": "The growing threats of uncertainties, anomalies, and cyberattacks on power\ngrids are driving a critical need to advance situational awareness which allows\nsystem operators to form a complete and accurate picture of the present and\nfuture state. Simulation and estimation are foundational tools in this process.\nHowever, existing tools lack the robustness and efficiency required to achieve\nthe level of situational awareness needed for the ever-evolving threat\nlandscape. Industry-standard (steady-state) simulators are not robust to\nblackouts, often leading to non-converging or non-actionable results.\nEstimation tools lack robustness to anomalous data, returning erroneous system\nstates. Efficiency is the other major concern as nonlinearities and scalability\nissues make large systems slow to converge.\n  This thesis addresses robustness and efficiency gaps through a dual-fold\ncontribution. We first address the inherent limitations in the existing\nphysics-based and data-driven worlds; and then transcend the boundaries of\nconventional algorithmic design in the direction of a new paradigm --\nPhysics-ML Synergy -- which integrates the strengths of the two worlds. Our\napproaches are built on circuit formulation which provides a unified framework\nthat applies to both transmission and distribution. Sparse optimization acts as\nthe key enabler to make these tools intrinsically robust and immune to random\nthreats, pinpointing dominant sources of (random) blackouts and data errors.\nFurther, we explore sparsity-exploiting optimizations to develop lightweight ML\nmodels whose prediction and detection capabilities are a complement to\nphysics-based tools; and whose lightweight designs advance generalization and\nscalability. Finally, Physics-ML Synergy brings robustness and efficiency\nfurther against targeted cyberthreats, by interconnecting our physics-based\ntools with lightweight ML.",
      "tldr_zh": "本论文探讨了如何利用稀疏结构（sparse structures）和协同设计（synergy designs）来提升电力电网的态势感知（situational awareness），以应对不确定性、异常和网络攻击的威胁。论文通过双重贡献解决现有模拟和估计工具的稳健性和效率问题：首先，针对物理基础和数据驱动方法的局限，采用电路公式作为统一框架，并借助稀疏优化（sparse optimization）使其对随机黑客和数据错误具有内在免疫力。最终，提出Physics-ML Synergy范式，将轻量级机器学习模型与物理工具整合，提高预测、检测能力及系统可扩展性，并在针对性网络威胁下显著增强电网的稳健性和效率。",
      "categories": [
        "eess.SP",
        "cs.AI"
      ],
      "primary_category": "eess.SP",
      "comment": "PhD thesis",
      "pdf_url": "http://arxiv.org/pdf/2412.15105v1",
      "published_date": "2024-12-19 17:51:43 UTC",
      "updated_date": "2024-12-19 17:51:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:14:25.359098"
    },
    {
      "arxiv_id": "2501.10390v1",
      "title": "Towards an Environmental Ethics of Artificial Intelligence",
      "title_zh": "翻译失败",
      "authors": [
        "Nynke van Uffelen",
        "Lode Lauwaert",
        "Mark Coeckelbergh",
        "Olya Kudina"
      ],
      "abstract": "In recent years, much research has been dedicated to uncovering the\nenvironmental impact of Artificial Intelligence (AI), showing that training and\ndeploying AI systems require large amounts of energy and resources, and the\noutcomes of AI may lead to decisions and actions that may negatively impact the\nenvironment. This new knowledge raises new ethical questions, such as: When is\nit (un)justifiable to develop an AI system, and how to make design choices,\nconsidering its environmental impact? However, so far, the environmental impact\nof AI has largely escaped ethical scrutiny, as AI ethics tends to focus\nstrongly on themes such as transparency, privacy, safety, responsibility, and\nbias. Considering the environmental impact of AI from an ethical perspective\nexpands the scope of AI ethics beyond an anthropocentric focus towards\nincluding more-than-human actors such as animals and ecosystems. This paper\nexplores the ethical implications of the environmental impact of AI for\ndesigning AI systems by drawing on environmental justice literature, in which\nthree categories of justice are distinguished, referring to three elements that\ncan be unjust: the distribution of benefits and burdens (distributive justice),\ndecision-making procedures (procedural justice), and institutionalized social\nnorms (justice as recognition). Based on these tenets of justice, we outline\ncriteria for developing environmentally just AI systems, given their ecological\nimpact.",
      "tldr_zh": "该论文探讨了人工智能（AI）对环境的影响及其伦理含义，指出AI系统的训练和部署会消耗大量能源资源，并可能导致负面环境决策，从而引发何时开发AI系统合理以及如何权衡环境影响的设计问题。现有的AI伦理主要关注透明度、隐私、安全、责任和偏见，而论文主张扩展至更广泛的视角，包括动物和生态系统等非人类因素。通过借鉴环境正义文献，该研究将正义分为分配正义（distributive justice）、程序正义（procedural justice）和认可正义（justice as recognition）三类，并据此提出开发环境正义AI系统的标准，以确保AI的生态影响更公平可持续。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.10390v1",
      "published_date": "2024-12-19 17:48:54 UTC",
      "updated_date": "2024-12-19 17:48:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:14:38.112008"
    },
    {
      "arxiv_id": "2412.15098v1",
      "title": "A Cross-Domain Study of the Use of Persuasion Techniques in Online Disinformation",
      "title_zh": "在线虚假信息中使用说服技巧的跨领域研究",
      "authors": [
        "João A. Leite",
        "Olesya Razuvayevskaya",
        "Carolina Scarton",
        "Kalina Bontcheva"
      ],
      "abstract": "Disinformation, irrespective of domain or language, aims to deceive or\nmanipulate public opinion, typically through employing advanced persuasion\ntechniques. Qualitative and quantitative research on the weaponisation of\npersuasion techniques in disinformation has been mostly topic-specific (e.g.,\nCOVID-19) with limited cross-domain studies, resulting in a lack of\ncomprehensive understanding of these strategies. This study employs a\nstate-of-the-art persuasion technique classifier to conduct a large-scale,\nmulti-domain analysis of the role of 16 persuasion techniques in disinformation\nnarratives. It shows how different persuasion techniques are employed\ndisproportionately in different disinformation domains. We also include a\ndetailed case study on climate change disinformation, highlighting how\nlinguistic, psychological, and cultural factors shape the adaptation of\npersuasion strategies to fit unique thematic contexts.",
      "tldr_zh": "本研究针对在线虚假信息（disinformation）的说服技巧（persuasion techniques）使用进行了跨领域分析，填补了现有研究的主题局限（如COVID-19）。研究采用先进的persuasion technique classifier，对16种说服技巧在多个领域中的应用进行大规模定量和定性分析，结果显示不同领域对这些技巧的采用存在显著不均衡现象。特别在气候变化disinformation的案例研究中，论文强调了语言（linguistic）、心理（psychological）和文化（cultural）因素如何塑造说服策略的适应，以提供更全面的理解。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.15098v1",
      "published_date": "2024-12-19 17:46:13 UTC",
      "updated_date": "2024-12-19 17:46:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:14:50.395343"
    },
    {
      "arxiv_id": "2412.15095v1",
      "title": "A Full Transformer-based Framework for Automatic Pain Estimation using Videos",
      "title_zh": "翻译失败",
      "authors": [
        "Stefanos Gkikas",
        "Manolis Tsiknakis"
      ],
      "abstract": "The automatic estimation of pain is essential in designing an optimal pain\nmanagement system offering reliable assessment and reducing the suffering of\npatients. In this study, we present a novel full transformer-based framework\nconsisting of a Transformer in Transformer (TNT) model and a Transformer\nleveraging cross-attention and self-attention blocks. Elaborating on videos\nfrom the BioVid database, we demonstrate state-of-the-art performances, showing\nthe efficacy, efficiency, and generalization capability across all the primary\npain estimation tasks.",
      "tldr_zh": "本研究提出一个全Transformer-based框架，用于基于视频的自动疼痛估计，以设计可靠的疼痛管理系统并减轻患者痛苦。该框架包括Transformer in Transformer (TNT)模型和另一个结合cross-attention和self-attention的Transformer模块，能够高效处理视频数据。在BioVid数据库的实验中，该框架在所有主要疼痛估计任务中实现了最先进性能，展示了出色的功效、效率和泛化能力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.15095v1",
      "published_date": "2024-12-19 17:45:08 UTC",
      "updated_date": "2024-12-19 17:45:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:15:01.859990"
    },
    {
      "arxiv_id": "2412.15086v1",
      "title": "Learning Disentangled Equivariant Representation for Explicitly Controllable 3D Molecule Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Haoran Liu",
        "Youzhi Luo",
        "Tianxiao Li",
        "James Caverlee",
        "Martin Renqiang Min"
      ],
      "abstract": "We consider the conditional generation of 3D drug-like molecules with\n\\textit{explicit control} over molecular properties such as drug-like\nproperties (e.g., Quantitative Estimate of Druglikeness or Synthetic\nAccessibility score) and effectively binding to specific protein sites. To\ntackle this problem, we propose an E(3)-equivariant Wasserstein autoencoder and\nfactorize the latent space of our generative model into two disentangled\naspects: molecular properties and the remaining structural context of 3D\nmolecules. Our model ensures explicit control over these molecular attributes\nwhile maintaining equivariance of coordinate representation and invariance of\ndata likelihood. Furthermore, we introduce a novel alignment-based coordinate\nloss to adapt equivariant networks for auto-regressive de-novo 3D molecule\ngeneration from scratch. Extensive experiments validate our model's\neffectiveness on property-guided and context-guided molecule generation, both\nfor de-novo 3D molecule design and structure-based drug discovery against\nprotein targets.",
      "tldr_zh": "我们提出了一种 E(3)-equivariant Wasserstein autoencoder，用于实现对 3D 分子生成的显式控制，包括分子属性（如 Quantitative Estimate of Druglikeness 和 Synthetic Accessibility score）以及与特定蛋白位点的结合。模型通过将潜在空间分解成分子属性和结构上下文两个解耦部分，确保了对属性的精确控制，同时维持坐标表示的等变性和数据似然的不变性。我们引入了 alignment-based coordinate loss，以支持自回归的从零开始的 3D 分子生成。实验结果验证了该模型在属性引导和上下文引导的分子生成任务中的有效性，包括从零设计 3D 分子和基于结构的药物发现。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.15086v1",
      "published_date": "2024-12-19 17:33:56 UTC",
      "updated_date": "2024-12-19 17:33:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:15:14.556273"
    },
    {
      "arxiv_id": "2412.15084v2",
      "title": "AceMath: Advancing Frontier Math Reasoning with Post-Training and Reward Modeling",
      "title_zh": "AceMath：通过后训练和奖励建模推进前沿数学推理",
      "authors": [
        "Zihan Liu",
        "Yang Chen",
        "Mohammad Shoeybi",
        "Bryan Catanzaro",
        "Wei Ping"
      ],
      "abstract": "In this paper, we introduce AceMath, a suite of frontier math models that\nexcel in solving complex math problems, along with highly effective reward\nmodels capable of evaluating generated solutions and reliably identifying the\ncorrect ones. To develop the instruction-tuned math models, we propose a\nsupervised fine-tuning (SFT) process that first achieves competitive\nperformance across general domains, followed by targeted fine-tuning for the\nmath domain using a carefully curated set of prompts and synthetically\ngenerated responses. The resulting model, AceMath-72B-Instruct greatly\noutperforms Qwen2.5-Math-72B-Instruct, GPT-4o and Claude-3.5 Sonnet. To develop\nmath-specialized reward model, we first construct AceMath-RewardBench, a\ncomprehensive and robust benchmark for evaluating math reward models across\ndiverse problems and difficulty levels. After that, we present a systematic\napproach to build our math reward models. The resulting model, AceMath-72B-RM,\nconsistently outperforms state-of-the-art reward models. Furthermore, when\ncombining AceMath-72B-Instruct with AceMath-72B-RM, we achieve the highest\naverage rm@8 score across the math reasoning benchmarks. We release model\nweights, training data, and evaluation benchmarks at:\nhttps://research.nvidia.com/labs/adlr/acemath",
      "tldr_zh": "本文介绍了 AceMath，一套先进的数学模型和奖励模型，用于提升复杂数学问题的推理能力。研究采用监督细调 (SFT) 方法，先在一般领域优化性能，然后针对数学领域进行精确微调，使用精心策划的提示和合成响应，使 AceMath-72B-Instruct 模型显著优于 Qwen2.5-Math-72B-Instruct、GPT-4o 和 Claude-3.5 Sonnet。同时，构建了 AceMath-RewardBench 基准和 AceMath-72B-RM 奖励模型，后者超越了现有最先进模型，并在结合使用时实现了数学推理基准上的最高平均 rm@8 分数。该研究开源了模型权重、训练数据和评估工具。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.15084v2",
      "published_date": "2024-12-19 17:29:44 UTC",
      "updated_date": "2025-01-17 07:12:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:15:27.370218"
    },
    {
      "arxiv_id": "2412.15314v1",
      "title": "Eliciting Causal Abilities in Large Language Models for Reasoning Tasks",
      "title_zh": "激发大语言模型的因果能力用于推理任务",
      "authors": [
        "Yajing Wang",
        "Zongwei Luo",
        "Jingzhe Wang",
        "Zhanke Zhou",
        "Yongqiang Chen",
        "Bo Han"
      ],
      "abstract": "Prompt optimization automatically refines prompting expressions, unlocking\nthe full potential of LLMs in downstream tasks. However, current prompt\noptimization methods are costly to train and lack sufficient interpretability.\nThis paper proposes enhancing LLMs' reasoning performance by eliciting their\ncausal inference ability from prompting instructions to correct answers.\nSpecifically, we introduce the Self-Causal Instruction Enhancement (SCIE)\nmethod, which enables LLMs to generate high-quality, low-quantity observational\ndata, then estimates the causal effect based on these data, and ultimately\ngenerates instructions with the optimized causal effect. In SCIE, the\ninstructions are treated as the treatment, and textual features are used to\nprocess natural language, establishing causal relationships through treatments\nbetween instructions and downstream tasks. Additionally, we propose applying\nObject-Relational (OR) principles, where the uncovered causal relationships are\ntreated as the inheritable class across task objects, ensuring low-cost\nreusability. Extensive experiments demonstrate that our method effectively\ngenerates instructions that enhance reasoning performance with reduced training\ncost of prompts, leveraging interpretable textual features to provide\nactionable insights.",
      "tldr_zh": "本研究提出 Self-Causal Instruction Enhancement (SCIE) 方法，通过从提示指令中激发 Large Language Models (LLMs) 的因果推理能力，提升其在推理任务中的性能，以解决现有提示优化方法的训练成本高和可解释性不足问题。SCIE 涉及生成高质量的观察数据、估计因果效应，并基于文本特征将指令视为治疗（treatment）来优化指令，从而建立指令与下游任务之间的因果关系。此外，该方法引入 Object-Relational (OR) 原则，使因果关系可继承和复用，实现低成本的指令重用。实验结果显示，SCIE 能有效生成优化指令，提高 LLMs 的推理性能，同时提供可解释的文本见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.15314v1",
      "published_date": "2024-12-19 17:03:02 UTC",
      "updated_date": "2024-12-19 17:03:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:15:37.108562"
    },
    {
      "arxiv_id": "2412.15054v1",
      "title": "GIRAFE: Glottal Imaging Dataset for Advanced Segmentation, Analysis, and Facilitative Playbacks Evaluation",
      "title_zh": "翻译失败",
      "authors": [
        "G. Andrade-Miranda",
        "K. Chatzipapas",
        "J. D. Arias-Londoño",
        "J. I. Godino-Llorente"
      ],
      "abstract": "The advances in the development of Facilitative Playbacks extracted from\nHigh-Speed videoendoscopic sequences of the vocal folds are hindered by a\nnotable lack of publicly available datasets annotated with the semantic\nsegmentations corresponding to the area of the glottal gap. This fact also\nlimits the reproducibility and further exploration of existing research in this\nfield.\n  To address this gap, GIRAFE is a data repository designed to facilitate the\ndevelopment of advanced techniques for the semantic segmentation, analysis, and\nfast evaluation of High-Speed videoendoscopic sequences of the vocal folds. The\nrepository includes 65 high-speed videoendoscopic recordings from a cohort of\n50 patients (30 female, 20 male). The dataset comprises 15 recordings from\nhealthy controls, 26 from patients with diagnosed voice disorders, and 24 with\nan unknown health condition. All of them were manually annotated by an expert,\nincluding the masks corresponding to the semantic segmentation of the glottal\ngap. The repository is also complemented with the automatic segmentation of the\nglottal area using different state-of-the-art approaches.\n  This data set has already supported several studies, which demonstrates its\nusefulness for the development of new glottal gap segmentation algorithms from\nHigh-Speed-Videoendoscopic sequences to improve or create new Facilitative\nPlaybacks. Despite these advances and others in the field, the broader\nchallenge of performing an accurate and completely automatic semantic\nsegmentation method of the glottal area remains open.",
      "tldr_zh": "该研究介绍了GIRAFE数据集，用于推进声带成像的语义分割、分析和Facilitative Playbacks评估，以解决现有High-Speed videoendoscopic sequences缺乏标注的难题。数据集包含65个高速度声带内镜视频记录，来自50名患者（30女、20男），包括15个健康对照、26个语音障碍患者和24个未知健康状况样本，所有视频均由专家手动标注了glottal gap的语义分割掩码，并附带多种最先进方法的自动分割结果。该数据集已支持多项研究，助力开发新的glottal gap分割算法以改进Facilitative Playbacks，但完全自动的准确语义分割方法仍是一个开放挑战。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CV",
      "comment": "18 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.15054v1",
      "published_date": "2024-12-19 17:02:03 UTC",
      "updated_date": "2024-12-19 17:02:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:15:49.831748"
    },
    {
      "arxiv_id": "2412.16241v1",
      "title": "Agents Are Not Enough",
      "title_zh": "翻译失败",
      "authors": [
        "Chirag Shah",
        "Ryen W. White"
      ],
      "abstract": "In the midst of the growing integration of Artificial Intelligence (AI) into\nvarious aspects of our lives, agents are experiencing a resurgence. These\nautonomous programs that act on behalf of humans are neither new nor exclusive\nto the mainstream AI movement. By exploring past incarnations of agents, we can\nunderstand what has been done previously, what worked, and more importantly,\nwhat did not pan out and why. This understanding lets us to examine what\ndistinguishes the current focus on agents. While generative AI is appealing,\nthis technology alone is insufficient to make new generations of agents more\nsuccessful. To make the current wave of agents effective and sustainable, we\nenvision an ecosystem that includes not only agents but also Sims, which\nrepresent user preferences and behaviors, as well as Assistants, which directly\ninteract with the user and coordinate the execution of user tasks with the help\nof the agents.",
      "tldr_zh": "本文论文指出，虽然AI代理（Agents）正在复兴，但仅靠生成式AI不足以使其成功，因为历史经验显示了许多代理技术的局限性，如未能持久或有效。作者通过回顾过去代理的成败，分析了当前关注的独特之处，并提出一个生态系统框架，包括代理（Agents）执行任务、模拟器（Sims）代表用户偏好和行为，以及助手（Assistants）直接互动并协调任务执行。这种综合方法旨在使新一代代理更有效和可持续。",
      "categories": [
        "cs.AI",
        "cs.HC",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.16241v1",
      "published_date": "2024-12-19 16:54:17 UTC",
      "updated_date": "2024-12-19 16:54:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:16:00.845732"
    },
    {
      "arxiv_id": "2412.15047v1",
      "title": "Measuring, Modeling, and Helping People Account for Privacy Risks in Online Self-Disclosures with AI",
      "title_zh": "翻译失败",
      "authors": [
        "Isadora Krsek",
        "Anubha Kabra",
        "Yao Dou",
        "Tarek Naous",
        "Laura A. Dabbish",
        "Alan Ritter",
        "Wei Xu",
        "Sauvik Das"
      ],
      "abstract": "In pseudonymous online fora like Reddit, the benefits of self-disclosure are\noften apparent to users (e.g., I can vent about my in-laws to understanding\nstrangers), but the privacy risks are more abstract (e.g., will my partner be\nable to tell that this is me?). Prior work has sought to develop natural\nlanguage processing (NLP) tools that help users identify potentially risky\nself-disclosures in their text, but none have been designed for or evaluated\nwith the users they hope to protect. Absent this assessment, these tools will\nbe limited by the social-technical gap: users need assistive tools that help\nthem make informed decisions, not paternalistic tools that tell them to avoid\nself-disclosure altogether. To bridge this gap, we conducted a study with N =\n21 Reddit users; we had them use a state-of-the-art NLP disclosure detection\nmodel on two of their authored posts and asked them questions to understand if\nand how the model helped, where it fell short, and how it could be improved to\nhelp them make more informed decisions. Despite its imperfections, users\nresponded positively to the model and highlighted its use as a tool that can\nhelp them catch mistakes, inform them of risks they were unaware of, and\nencourage self-reflection. However, our work also shows how, to be useful and\nusable, AI for supporting privacy decision-making must account for posting\ncontext, disclosure norms, and users' lived threat models, and provide\nexplanations that help contextualize detected risks.",
      "tldr_zh": "本研究探讨了使用 AI 帮助用户管理在线自我披露（如 Reddit 帖子）的隐私风险，强调现有 NLP 工具需针对用户需求进行设计和评估，以桥接社会技术差距。研究通过 N=21 名 Reddit 用户实验，让他们应用先进的 NLP 披露检测模型分析自身帖子，并收集反馈，结果显示用户对工具持正面态度，认为其可帮助发现错误、告知未知风险并促进自我反思。论文发现，要使 AI 工具更实用，必须考虑发布上下文、披露规范和用户的实际威胁模型，并提供解释来 contextualize 检测到的风险，从而支持用户做出知情决策。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "31 pages, 5 figues, Accepted for publication at CSCW 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.15047v1",
      "published_date": "2024-12-19 16:53:40 UTC",
      "updated_date": "2024-12-19 16:53:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:16:13.604791"
    },
    {
      "arxiv_id": "2412.15004v3",
      "title": "From Vulnerabilities to Remediation: A Systematic Literature Review of LLMs in Code Security",
      "title_zh": "从漏洞到修复：LLMs 在代码安全中的系统文献综述",
      "authors": [
        "Enna Basic",
        "Alberto Giaretta"
      ],
      "abstract": "Large Language Models (LLMs) have emerged as powerful tools for automating\nvarious programming tasks, including security-related ones, such as detecting\nand fixing vulnerabilities. Despite their promising capabilities, when required\nto produce or modify pre-existing code, LLMs could introduce vulnerabilities\nunbeknown to the programmer. When analyzing code, they could miss clear\nvulnerabilities or signal nonexistent ones. In this Systematic Literature\nReview (SLR), we aim to investigate both the security benefits and potential\ndrawbacks of using LLMs for a variety of code-related tasks. In particular,\nfirst we focus on the types of vulnerabilities that could be introduced by\nLLMs, when used for producing code. Second, we analyze the capabilities of LLMs\nto detect and fix vulnerabilities, in any given code, and how the prompting\nstrategy of choice impacts their performance in these two tasks. Last, we\nprovide an in-depth analysis on how data poisoning attacks on LLMs can impact\nperformance in the aforementioned tasks.",
      "tldr_zh": "这篇系统文献综述 (Systematic Literature Review, SLR) 探讨了大型语言模型 (LLMs) 在代码安全中的双重作用，包括检测和修复漏洞的益处，以及潜在风险，如生成代码时引入未知漏洞或错过现有漏洞。研究分析了 LLMs 在识别和修复代码漏洞的能力，以及不同提示策略 (prompting strategy) 对性能的影响。最终，该论文还考察了数据中毒攻击 (data poisoning attacks) 如何影响 LLMs 在这些任务中的表现，并为未来代码安全应用提供了深入见解。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.15004v3",
      "published_date": "2024-12-19 16:20:22 UTC",
      "updated_date": "2025-04-14 10:36:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:16:26.007801"
    },
    {
      "arxiv_id": "2412.14995v1",
      "title": "HSEvo: Elevating Automatic Heuristic Design with Diversity-Driven Harmony Search and Genetic Algorithm Using LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Pham Vu Tuan Dat",
        "Long Doan",
        "Huynh Thi Thanh Binh"
      ],
      "abstract": "Automatic Heuristic Design (AHD) is an active research area due to its\nutility in solving complex search and NP-hard combinatorial optimization\nproblems in the real world. The recent advancements in Large Language Models\n(LLMs) introduce new possibilities by coupling LLMs with evolutionary\ncomputation to automatically generate heuristics, known as LLM-based\nEvolutionary Program Search (LLM-EPS). While previous LLM-EPS studies obtained\ngreat performance on various tasks, there is still a gap in understanding the\nproperties of heuristic search spaces and achieving a balance between\nexploration and exploitation, which is a critical factor in large heuristic\nsearch spaces. In this study, we address this gap by proposing two diversity\nmeasurement metrics and perform an analysis on previous LLM-EPS approaches,\nincluding FunSearch, EoH, and ReEvo. Results on black-box AHD problems reveal\nthat while EoH demonstrates higher diversity than FunSearch and ReEvo, its\nobjective score is unstable. Conversely, ReEvo's reflection mechanism yields\ngood objective scores but fails to optimize diversity effectively. With this\nfinding in mind, we introduce HSEvo, an adaptive LLM-EPS framework that\nmaintains a balance between diversity and convergence with a harmony search\nalgorithm. Through experimentation, we find that HSEvo achieved high diversity\nindices and good objective scores while remaining cost-effective. These results\nunderscore the importance of balancing exploration and exploitation and\nunderstanding heuristic search spaces in designing frameworks in LLM-EPS.",
      "tldr_zh": "该研究针对Automatic Heuristic Design (AHD)领域中的探索与利用平衡问题，分析了现有LLM-EPS方法如FunSearch、EoH和ReEvo的多样性表现，发现EoH多样性高但目标分数不稳定，而ReEvo目标分数好却优化多样性不足。作者提出HSEvo框架，通过引入两个多样性测量指标和基于harmony search算法的适应性机制，与遗传算法和LLMs结合，实现探索与利用的动态平衡。实验结果表明，HSEvo在黑箱AHD问题上取得了高多样性指标、良好目标分数和成本效益，突显了理解启发式搜索空间的重要性。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "18 pages, 12 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.14995v1",
      "published_date": "2024-12-19 16:07:00 UTC",
      "updated_date": "2024-12-19 16:07:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:16:38.561629"
    },
    {
      "arxiv_id": "2412.14965v2",
      "title": "Movie2Story: A framework for understanding videos and telling stories in the form of novel text",
      "title_zh": "翻译失败",
      "authors": [
        "Kangning Li",
        "Zheyang Jia",
        "Anyu Ying"
      ],
      "abstract": "In recent years, large-scale models have achieved significant advancements,\naccompanied by the emergence of numerous high-quality benchmarks for evaluating\nvarious aspects of their comprehension abilities. However, most existing\nbenchmarks primarily focus on spatial understanding in static image tasks.\nWhile some benchmarks extend evaluations to temporal tasks, they fall short in\nassessing text generation under complex contexts involving long videos and rich\nauxiliary information. To address this limitation, we propose a novel\nbenchmark: the Multi-modal Story Generation Benchmark (MSBench), designed to\nevaluate text generation capabilities in scenarios enriched with auxiliary\ninformation. Our work introduces an innovative automatic dataset generation\nmethod to ensure the availability of accurate auxiliary information. On one\nhand, we leverage existing datasets and apply automated processes to generate\nnew evaluation datasets, significantly reducing manual efforts. On the other\nhand, we refine auxiliary data through systematic filtering and utilize\nstate-of-the-art models to ensure the fairness and accuracy of the ground-truth\ndatasets. Our experiments reveal that current Multi-modal Large Language Models\n(MLLMs) perform suboptimally under the proposed evaluation metrics,\nhighlighting significant gaps in their capabilities. To address these\nchallenges, we propose a novel model architecture and methodology to better\nhandle the overall process, demonstrating improvements on our benchmark.",
      "tldr_zh": "该研究指出了现有基准主要关注静态图像的空间理解，而忽略了长视频和丰富辅助信息下的文本生成评估。为解决这一问题，研究者提出Multi-modal Story Generation Benchmark (MSBench)，一个用于评估多模态文本生成能力的创新基准，并引入自动数据集生成方法，通过利用现有数据集、系统过滤和最先进模型，确保辅助信息的准确性和公平性。实验结果显示，当前Multi-modal Large Language Models (MLLMs)在MSBench上表现不佳，存在显著能力差距；为此，研究团队开发了新型模型架构和方法，并在基准上实现了性能提升。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.14965v2",
      "published_date": "2024-12-19 15:44:04 UTC",
      "updated_date": "2025-01-11 14:08:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:16:49.646793"
    },
    {
      "arxiv_id": "2412.14950v1",
      "title": "Generalizing Constraint Models in Constraint Acquisition",
      "title_zh": "在约束获取中泛化约束模型",
      "authors": [
        "Dimos Tsouros",
        "Senne Berden",
        "Steven Prestwich",
        "Tias Guns"
      ],
      "abstract": "Constraint Acquisition (CA) aims to widen the use of constraint programming\nby assisting users in the modeling process. However, most CA methods suffer\nfrom a significant drawback: they learn a single set of individual constraints\nfor a specific problem instance, but cannot generalize these constraints to the\nparameterized constraint specifications of the problem. In this paper, we\naddress this limitation by proposing GenCon, a novel approach to learn\nparameterized constraint models capable of modeling varying instances of the\nsame problem. To achieve this generalization, we make use of statistical\nlearning techniques at the level of individual constraints. Specifically, we\npropose to train a classifier to predict, for any possible constraint and\nparameterization, whether the constraint belongs to the problem. We then show\nhow, for some classes of classifiers, we can extract decision rules to\nconstruct interpretable constraint specifications. This enables the generation\nof ground constraints for any parameter instantiation. Additionally, we present\na generate-and-test approach that can be used with any classifier, to generate\nthe ground constraints on the fly. Our empirical results demonstrate that our\napproach achieves high accuracy and is robust to noise in the input instances.",
      "tldr_zh": "本文针对 Constraint Acquisition (CA) 的局限性，即现有方法仅能为特定问题实例学习单一约束集，而无法泛化到参数化的约束规范，提出了一种新方法 GenCon。GenCon 通过统计学习技术训练一个分类器，来预测任意约束和参数化是否属于问题，并可提取决策规则构建可解释的约束规范，或使用 generate-and-test 方式动态生成具体约束。实验结果表明，该方法在处理不同实例时表现出高准确性和对输入噪声的鲁棒性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.14950v1",
      "published_date": "2024-12-19 15:31:29 UTC",
      "updated_date": "2024-12-19 15:31:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:17:01.560161"
    },
    {
      "arxiv_id": "2412.14933v1",
      "title": "Cirbo: A New Tool for Boolean Circuit Analysis and Synthesis",
      "title_zh": "Cirbo：一种新的布尔电路分析和合成工具",
      "authors": [
        "Daniil Averkov",
        "Tatiana Belova",
        "Gregory Emdin",
        "Mikhail Goncharov",
        "Viktoriia Krivogornitsyna",
        "Alexander S. Kulikov",
        "Fedor Kurmazov",
        "Daniil Levtsov",
        "Georgie Levtsov",
        "Vsevolod Vaskin",
        "Aleksey Vorobiev"
      ],
      "abstract": "We present an open-source tool for manipulating Boolean circuits. It\nimplements efficient algorithms, both existing and novel, for a rich variety of\nfrequently used circuit tasks such as satisfiability, synthesis, and\nminimization. We tested the tool on a wide range of practically relevant\ncircuits (computing, in particular, symmetric and arithmetic functions) that\nhave been optimized intensively by the community for the last three years. The\ntool helped us to win the IWLS 2024 Programming Contest. In 2023, it was Google\nDeepMind who took the first place in the competition. We were able to reduce\nthe size of the best circuits from 2023 by 12\\% on average, whereas for some\nindividual circuits, our size reduction was as large as 83\\%.",
      "tldr_zh": "该论文介绍了Cirbo，一款开源工具，用于Boolean电路的分析和合成。它实现了高效算法，包括现有和新型方法，支持常见任务如satisfiability、synthesis和minimization，并在各种实际电路（如计算对称和算术函数）上进行了测试。相比2023年最佳电路，Cirbo平均将电路大小减少了12%，某些情况下高达83%，并帮助作者赢得了IWLS 2024编程竞赛。",
      "categories": [
        "cs.LO",
        "cs.AI"
      ],
      "primary_category": "cs.LO",
      "comment": "To appear in AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.14933v1",
      "published_date": "2024-12-19 15:10:31 UTC",
      "updated_date": "2024-12-19 15:10:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:17:12.786885"
    },
    {
      "arxiv_id": "2412.15310v1",
      "title": "MRWeb: An Exploration of Generating Multi-Page Resource-Aware Web Code from UI Designs",
      "title_zh": "翻译失败",
      "authors": [
        "Yuxuan Wan",
        "Yi Dong",
        "Jingyu Xiao",
        "Yintong Huo",
        "Wenxuan Wang",
        "Michael R. Lyu"
      ],
      "abstract": "Multi-page websites dominate modern web development. However, existing\ndesign-to-code methods rely on simplified assumptions, limiting to single-page,\nself-contained webpages without external resource connection. To address this\ngap, we introduce the Multi-Page Resource-Aware Webpage (MRWeb) generation\ntask, which transforms UI designs into multi-page, functional web UIs with\ninternal/external navigation, image loading, and backend routing. We propose a\nnovel resource list data structure to track resources, links, and design\ncomponents. Our study applies existing methods to the MRWeb problem using a\nnewly curated dataset of 500 websites (300 synthetic, 200 real-world).\nSpecifically, we identify the best metric to evaluate the similarity of the web\nUI, assess the impact of the resource list on MRWeb generation, analyze MLLM\nlimitations, and evaluate the effectiveness of the MRWeb tool in real-world\nworkflows. The results show that resource lists boost navigation functionality\nfrom 0% to 66%-80% while facilitating visual similarity. Our proposed metrics\nand evaluation framework provide new insights into MLLM performance on MRWeb\ntasks. We release the MRWeb tool, dataset, and evaluation framework to promote\nfurther research.",
      "tldr_zh": "该研究引入了 MRWeb 生成任务，旨在将 UI 设计转化为多页功能性网页，支持内部/外部导航、图像加载和后端路由，以克服现有设计-to-code 方法的单页限制。论文提出了一种新型资源列表数据结构来跟踪资源、链接和设计组件，并使用一个新数据集（包含 500 个网站，包括 300 个合成和 200 个真实网站）评估现有方法、MLLM 的局限性及其性能。实验结果显示，资源列表显著提升了导航功能（从 0% 提高到 66%-80%），同时保持视觉相似性，并提供了新的评估指标和框架。该研究还发布了 MRWeb 工具、数据集和评估框架，以推动相关领域的研究。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.15310v1",
      "published_date": "2024-12-19 15:02:33 UTC",
      "updated_date": "2024-12-19 15:02:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:17:25.483059"
    },
    {
      "arxiv_id": "2412.14922v1",
      "title": "RobustFT: Robust Supervised Fine-tuning for Large Language Models under Noisy Response",
      "title_zh": "翻译失败",
      "authors": [
        "Junyu Luo",
        "Xiao Luo",
        "Kaize Ding",
        "Jingyang Yuan",
        "Zhiping Xiao",
        "Ming Zhang"
      ],
      "abstract": "Supervised fine-tuning (SFT) plays a crucial role in adapting large language\nmodels (LLMs) to specific domains or tasks. However, as demonstrated by\nempirical experiments, the collected data inevitably contains noise in\npractical applications, which poses significant challenges to model performance\non downstream tasks. Therefore, there is an urgent need for a noise-robust SFT\nframework to enhance model capabilities in downstream tasks. To address this\nchallenge, we introduce a robust SFT framework (RobustFT) that performs noise\ndetection and relabeling on downstream task data. For noise identification, our\napproach employs a multi-expert collaborative system with inference-enhanced\nmodels to achieve superior noise detection. In the denoising phase, we utilize\na context-enhanced strategy, which incorporates the most relevant and confident\nknowledge followed by careful assessment to generate reliable annotations.\nAdditionally, we introduce an effective data selection mechanism based on\nresponse entropy, ensuring only high-quality samples are retained for\nfine-tuning. Extensive experiments conducted on multiple LLMs across five\ndatasets demonstrate RobustFT's exceptional performance in noisy scenarios.",
      "tldr_zh": "这篇论文针对监督微调(SFT)数据中不可避免的噪声问题，提出RobustFT框架，以提升大语言模型(LLMs)在下游任务中的鲁棒性。RobustFT通过多专家协作系统结合增强推理模型进行噪声检测，并在去噪阶段采用上下文增强策略生成可靠的标注，同时引入基于响应熵的数据选择机制，确保只使用高质量样本进行微调。实验结果显示，在多个LLMs和五个数据集上，RobustFT在噪声场景下显著提高了模型性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.14922v1",
      "published_date": "2024-12-19 15:00:18 UTC",
      "updated_date": "2024-12-19 15:00:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:17:38.192734"
    },
    {
      "arxiv_id": "2501.01435v1",
      "title": "Fundamental Risks in the Current Deployment of General-Purpose AI Models: What Have We (Not) Learnt From Cybersecurity?",
      "title_zh": "翻译失败",
      "authors": [
        "Mario Fritz"
      ],
      "abstract": "General Purpose AI - such as Large Language Models (LLMs) - have seen rapid\ndeployment in a wide range of use cases. Most surprisingly, they have have made\ntheir way from plain language models, to chat-bots, all the way to an almost\n``operating system''-like status that can control decisions and logic of an\napplication. Tool-use, Microsoft co-pilot/office integration, and OpenAIs\nAltera are just a few examples of increased autonomy, data access, and\nexecution capabilities. These methods come with a range of cybersecurity\nchallenges. We highlight some of the work we have done in terms of evaluation\nas well as outline future opportunities and challenges.",
      "tldr_zh": "该论文探讨了通用 AI 模型（如 Large Language Models, LLMs）的当前部署中存在的根本风险，并反思我们从 Cybersecurity（网络安全）领域学到的（或未学到的）教训。作者指出，这些模型已从简单语言模型演变为高度自治系统，例如聊天机器人、工具使用、Microsoft CoPilot/Office 集成和 OpenAI 的 Altera，从而增加了数据访问和执行能力，并引发了各种网络安全挑战。通过评估工作，论文突出了这些风险，并概述了未来的机会和挑战，以推动更安全的 AI 部署。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.01435v1",
      "published_date": "2024-12-19 14:44:41 UTC",
      "updated_date": "2024-12-19 14:44:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:17:49.208121"
    },
    {
      "arxiv_id": "2412.14905v1",
      "title": "Dehallucinating Parallel Context Extension for Retrieval-Augmented Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Zexiong Ma",
        "Shengnan An",
        "Zeqi Lin",
        "Yanzhen Zou",
        "Jian-Guang Lou",
        "Bing Xie"
      ],
      "abstract": "Large language models (LLMs) are susceptible to generating hallucinated\ninformation, despite the integration of retrieval-augmented generation (RAG).\nParallel context extension (PCE) is a line of research attempting to\neffectively integrating parallel (unordered) contexts, while it still suffers\nfrom hallucinations when adapted to RAG scenarios. In this paper, we propose\nDePaC (Dehallucinating Parallel Context Extension), which alleviates the\nhallucination problem with context-aware negative training and\ninformation-calibrated aggregation. DePaC is designed to alleviate two types of\nin-context hallucination: fact fabrication (i.e., LLMs present claims that are\nnot supported by the contexts) and fact omission (i.e., LLMs fail to present\nclaims that can be supported by the contexts). Specifically, (1) for fact\nfabrication, we apply the context-aware negative training that fine-tunes the\nLLMs with negative supervisions, thus explicitly guiding the LLMs to refuse to\nanswer when contexts are not related to questions; (2) for fact omission, we\npropose the information-calibrated aggregation which prioritizes context\nwindows with higher information increment from their contexts. The experimental\nresults on nine RAG tasks demonstrate that DePaC significantly alleviates the\ntwo types of hallucination and consistently achieves better performances on\nthese tasks.",
      "tldr_zh": "该研究针对大语言模型 (LLMs) 在检索增强生成 (RAG) 中的幻觉问题，提出 DePaC (Dehallucinating Parallel Context Extension) 框架，以改进 Parallel Context Extension (PCE) 的局限性。DePaC 通过上下文感知负训练缓解事实捏造（LLMs 呈现未被上下文支持的声明），并采用信息校准聚合优先处理信息增量更高的上下文窗口，从而减少事实遗漏。实验结果显示，DePaC 在九个 RAG 任务上显著降低了幻觉发生率，并实现了更好的整体性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.14905v1",
      "published_date": "2024-12-19 14:37:11 UTC",
      "updated_date": "2024-12-19 14:37:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:18:01.433214"
    },
    {
      "arxiv_id": "2412.14869v1",
      "title": "AI-Powered Intracranial Hemorrhage Detection: A Co-Scale Convolutional Attention Model with Uncertainty-Based Fuzzy Integral Operator and Feature Screening",
      "title_zh": "翻译失败",
      "authors": [
        "Mehdi Hosseini Chagahi",
        "Md. Jalil Piran",
        "Niloufar Delfan",
        "Behzad Moshiri",
        "Jaber Hatam Parikhan"
      ],
      "abstract": "Intracranial hemorrhage (ICH) refers to the leakage or accumulation of blood\nwithin the skull, which occurs due to the rupture of blood vessels in or around\nthe brain. If this condition is not diagnosed in a timely manner and\nappropriately treated, it can lead to serious complications such as decreased\nconsciousness, permanent neurological disabilities, or even death.The primary\naim of this study is to detect the occurrence or non-occurrence of ICH,\nfollowed by determining the type of subdural hemorrhage (SDH). These tasks are\nframed as two separate binary classification problems. By adding two layers to\nthe co-scale convolutional attention (CCA) classifier architecture, we\nintroduce a novel approach for ICH detection. In the first layer, after\nextracting features from different slices of computed tomography (CT) scan\nimages, we combine these features and select the 50 components that capture the\nhighest variance in the data, considering them as informative features. We then\nassess the discriminative power of these features using the bootstrap forest\nalgorithm, discarding those that lack sufficient discriminative ability between\ndifferent classes. This algorithm explicitly determines the contribution of\neach feature to the final prediction, assisting us in developing an explainable\nAI model. The features feed into a boosting neural network as a latent feature\nspace. In the second layer, we introduce a novel uncertainty-based fuzzy\nintegral operator to fuse information from different CT scan slices. This\noperator, by accounting for the dependencies between consecutive slices,\nsignificantly improves detection accuracy.",
      "tldr_zh": "本研究针对颅内出血 (ICH) 的及时检测问题，旨在通过两个二元分类任务识别 ICH 的发生与否，以及硬膜下出血 (SDH) 类型。研究基于 co-scale convolutional attention (CCA) 分类器架构，添加两个新层：第一层从 CT 扫描图像的多个切片提取特征，选择最高方差的 50 个组件，并使用 bootstrap forest 算法筛选出具有强区分能力的特征，形成可解释的 AI 模型，然后输入 boosting neural network。第二个层引入 uncertainty-based fuzzy integral operator 来融合切片间的信息，考虑其依赖性，从而显著提升检测准确性。该方法为 AI 驱动的 ICH 检测提供了更可靠和可解释的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.14869v1",
      "published_date": "2024-12-19 14:06:44 UTC",
      "updated_date": "2024-12-19 14:06:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:18:13.578988"
    },
    {
      "arxiv_id": "2412.15309v1",
      "title": "Conceptual In-Context Learning and Chain of Concepts: Solving Complex Conceptual Problems Using Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Nishtha N. Vaidya",
        "Thomas Runkler",
        "Thomas Hubauer",
        "Veronika Haderlein-Hoegberg",
        "Maja Mlicic Brandt"
      ],
      "abstract": "Science and engineering problems fall in the category of complex conceptual\nproblems that require specific conceptual information (CI) like math/logic\n-related know-how, process information, or engineering guidelines to solve\nthem. Large Language Models (LLMs) are promising agents to solve such complex\nconceptual problems due to their implications in advancing engineering and\nscience tasks like assisted problem-solving. But vanilla LLMs, trained on\nopen-world data, lack the necessary CI. In this work, we specifically explore\nshallow customization methods (SCMs) of LLMs for solving complex conceptual\nproblems. We propose two novel SCM algorithms for LLM, to augment LLMs with CI\nand enable LLMs to solve complex conceptual problems: Conceptual In-Context\nLearning (C-ICL) and Chain of Concepts (CoC). The problem tackled in this paper\nis generation of proprietary data models in the engineering/industry domain\nbased on conceptual information in data modelling guidelines. We evaluate our\nalgorithms on varied sizes of the OpenAI LLMs against four evaluation metrics\nrelated to syntactic and semantic correctness, time and cost incurred. The\nproposed algorithms perform better than currently popular LLM SCMs like\nIn-context Learning (ICL) and Chain of Thoughts (CoT). It was observed that as\ncompared to CoT, response correctness increased by 30.6% and 29.88% for the new\nSCMs C-ICL and CoC respectively. Qualitative analysis suggests that the\nproposed new SCMs activate emergent capabilities in LLMs, previously unobserved\nin the existing SCMs. They make problem-solving processes more transparent and\nreduce hallucinations and the tendency of model responses to copy examples from\nprompts (parroting).",
      "tldr_zh": "本研究探讨了大型语言模型（LLMs）在解决科学和工程领域的复杂概念问题时面临的挑战，这些问题需要特定概念信息（CI）如数学/逻辑知识或工程指南。作者提出两种新型浅层定制方法（SCMs）：Conceptual In-Context Learning (C-ICL) 和 Chain of Concepts (CoC)，通过增强LLMs的CI来生成工程领域的专有数据模型。实验结果显示，与现有方法In-context Learning (ICL)和Chain of Thoughts (CoT)相比，C-ICL和CoC分别将响应正确率提高了30.6%和29.88%，并显著减少了幻觉和模仿行为，同时提升了问题解决过程的透明度和新兴能力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to 2025 IEEE Symposium on Computational Intelligence in\n  Natural Language Processing and Social Media",
      "pdf_url": "http://arxiv.org/pdf/2412.15309v1",
      "published_date": "2024-12-19 13:54:33 UTC",
      "updated_date": "2024-12-19 13:54:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:18:26.117804"
    },
    {
      "arxiv_id": "2412.14847v2",
      "title": "A Survey of RWKV",
      "title_zh": "RWKV 的综述",
      "authors": [
        "Zhiyuan Li",
        "Tingyu Xia",
        "Yi Chang",
        "Yuan Wu"
      ],
      "abstract": "The Receptance Weighted Key Value (RWKV) model offers a novel alternative to\nthe Transformer architecture, merging the benefits of recurrent and\nattention-based systems. Unlike conventional Transformers, which depend heavily\non self-attention, RWKV adeptly captures long-range dependencies with minimal\ncomputational demands. By utilizing a recurrent framework, RWKV addresses some\ncomputational inefficiencies found in Transformers, particularly in tasks with\nlong sequences. RWKV has recently drawn considerable attention for its robust\nperformance across multiple domains. Despite its growing popularity, no\nsystematic review of the RWKV model exists. This paper seeks to fill this gap\nas the first comprehensive review of the RWKV architecture, its core\nprinciples, and its varied applications, such as natural language generation,\nnatural language understanding, and computer vision. We assess how RWKV\ncompares to traditional Transformer models, highlighting its capability to\nmanage long sequences efficiently and lower computational costs. Furthermore,\nwe explore the challenges RWKV encounters and propose potential directions for\nfuture research and advancement. We consistently maintain the related\nopen-source materials at: https://github.com/MLGroupJLU/RWKV-Survey.",
      "tldr_zh": "本论文对 Receptance Weighted Key Value (RWKV) 模型进行了首次全面调查，RWKV 作为 Transformer 架构的替代方案，通过 recurrent 框架捕捉长距离依赖关系，同时减少计算需求。论文详细阐述了 RWKV 的核心原理、应用（如自然语言生成、理解和计算机视觉），并与传统 Transformer 模型进行比较，突显其在处理长序列时的效率优势和较低计算成本。作者还讨论了 RWKV 面临的挑战，并提出未来研究方向，同时提供相关开源资源（https://github.com/MLGroupJLU/RWKV-Survey）。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "19 pages",
      "pdf_url": "http://arxiv.org/pdf/2412.14847v2",
      "published_date": "2024-12-19 13:39:24 UTC",
      "updated_date": "2025-01-05 13:54:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:18:37.289222"
    },
    {
      "arxiv_id": "2412.14846v2",
      "title": "Head and Neck Tumor Segmentation of MRI from Pre- and Mid-radiotherapy with Pre-training, Data Augmentation and Dual Flow UNet",
      "title_zh": "翻译失败",
      "authors": [
        "Litingyu Wang",
        "Wenjun Liao",
        "Shichuan Zhang",
        "Guotai Wang"
      ],
      "abstract": "Head and neck tumors and metastatic lymph nodes are crucial for treatment\nplanning and prognostic analysis. Accurate segmentation and quantitative\nanalysis of these structures require pixel-level annotation, making automated\nsegmentation techniques essential for the diagnosis and treatment of head and\nneck cancer. In this study, we investigated the effects of multiple strategies\non the segmentation of pre-radiotherapy (pre-RT) and mid-radiotherapy (mid-RT)\nimages. For the segmentation of pre-RT images, we utilized: 1) a fully\nsupervised learning approach, and 2) the same approach enhanced with\npre-trained weights and the MixUp data augmentation technique. For mid-RT\nimages, we introduced a novel computational-friendly network architecture that\nfeatures separate encoders for mid-RT images and registered pre-RT images with\ntheir labels. The mid-RT encoder branch integrates information from pre-RT\nimages and labels progressively during the forward propagation. We selected the\nhighest-performing model from each fold and used their predictions to create an\nensemble average for inference. In the final test, our models achieved a\nsegmentation performance of 82.38% for pre-RT and 72.53% for mid-RT on\naggregated Dice Similarity Coefficient (DSC) as HiLab. Our code is available at\nhttps://github.com/WltyBY/HNTS-MRG2024_train_code.",
      "tldr_zh": "本文研究了使用预训练、数据增强和 Dual Flow UNet 架构对头部和颈部肿瘤 MRI 图像进行分割，以支持治疗规划和预后分析。对于 pre-radiotherapy (pre-RT) 图像，采用全监督学习结合预训练权重和 MixUp 技术进行增强；对于 mid-radiotherapy (mid-RT) 图像，则引入了新型网络架构，配备单独编码器逐步整合 pre-RT 图像及其标签信息。实验通过集成平均预测方法，在 HiLab 数据集上实现了 pre-RT 的 Dice Similarity Coefficient (DSC) 为 82.38% 和 mid-RT 的 72.53%。这项工作为自动化肿瘤分割提供了高效工具，并开源了代码以便进一步应用。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.14846v2",
      "published_date": "2024-12-19 13:38:20 UTC",
      "updated_date": "2025-03-31 03:02:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:18:51.086013"
    },
    {
      "arxiv_id": "2412.14843v3",
      "title": "Mapping and Influencing the Political Ideology of Large Language Models using Synthetic Personas",
      "title_zh": "利用合成人物映射与影响大语言模型的政治意识形态",
      "authors": [
        "Pietro Bernardelle",
        "Leon Fröhling",
        "Stefano Civelli",
        "Riccardo Lunardi",
        "Kevin Roitero",
        "Gianluca Demartini"
      ],
      "abstract": "The analysis of political biases in large language models (LLMs) has\nprimarily examined these systems as single entities with fixed viewpoints.\nWhile various methods exist for measuring such biases, the impact of\npersona-based prompting on LLMs' political orientation remains unexplored. In\nthis work we leverage PersonaHub, a collection of synthetic persona\ndescriptions, to map the political distribution of persona-based prompted LLMs\nusing the Political Compass Test (PCT). We then examine whether these initial\ncompass distributions can be manipulated through explicit ideological prompting\ntowards diametrically opposed political orientations: right-authoritarian and\nleft-libertarian. Our experiments reveal that synthetic personas predominantly\ncluster in the left-libertarian quadrant, with models demonstrating varying\ndegrees of responsiveness when prompted with explicit ideological descriptors.\nWhile all models demonstrate significant shifts towards right-authoritarian\npositions, they exhibit more limited shifts towards left-libertarian positions,\nsuggesting an asymmetric response to ideological manipulation that may reflect\ninherent biases in model training.",
      "tldr_zh": "本研究探讨了使用 Synthetic Personas 来映射和影响 Large Language Models (LLMs) 的政治意识形态，填补了现有偏见分析方法的空白。作者利用 PersonaHub 中的合成角色描述和 Political Compass Test (PCT) 评估了 LLMs 的初始政治分布，发现这些角色主要聚集在 left-libertarian 象限。实验结果显示，通过显式意识形态提示，LLMs 可以显著向 right-authoritarian 方向转移，但对 left-libertarian 方向的转移较为有限，这可能反映了模型训练中的固有偏见。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Companion Proceedings of the ACM Web Conference 2025 (WWW\n  Companion'25)",
      "pdf_url": "http://arxiv.org/pdf/2412.14843v3",
      "published_date": "2024-12-19 13:36:18 UTC",
      "updated_date": "2025-02-26 03:24:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:20:55.273536"
    },
    {
      "arxiv_id": "2412.14841v2",
      "title": "Helping LLMs Improve Code Generation Using Feedback from Testing and Static Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Greta Dolcetti",
        "Vincenzo Arceri",
        "Eleonora Iotti",
        "Sergio Maffeis",
        "Agostino Cortesi",
        "Enea Zaffanella"
      ],
      "abstract": "Large Language Models (LLMs) are one of the most promising developments in\nthe field of artificial intelligence, and the software engineering community\nhas readily noticed their potential role in the software development\nlife-cycle. Developers routinely ask LLMs to generate code snippets, increasing\nproductivity but also potentially introducing ownership, privacy, correctness,\nand security issues. Previous work highlighted how code generated by mainstream\ncommercial LLMs is often not safe, containing vulnerabilities, bugs, and code\nsmells. In this paper, we present a framework that leverages testing and static\nanalysis to assess the quality, and guide the self-improvement, of code\ngenerated by general-purpose, open-source LLMs.\n  First, we ask LLMs to generate C code to solve a number of programming tasks.\nThen we employ ground-truth tests to assess the (in)correctness of the\ngenerated code, and a static analysis tool to detect potential safety\nvulnerabilities. Next, we assess the models ability to evaluate the generated\ncode, by asking them to detect errors and vulnerabilities. Finally, we test the\nmodels ability to fix the generated code, providing the reports produced during\nthe static analysis and incorrectness evaluation phases as feedback.\n  Our results show that models often produce incorrect code, and that the\ngenerated code can include safety issues. Moreover, they perform very poorly at\ndetecting either issue. On the positive side, we observe a substantial ability\nto fix flawed code when provided with information about failed tests or\npotential vulnerabilities, indicating a promising avenue for improving the\nsafety of LLM-based code generation tools.",
      "tldr_zh": "本文提出一个框架，利用测试和静态分析反馈，帮助开源 LLMs 改进代码生成质量，以解决生成的 C 代码中常见的安全漏洞、错误和代码异味问题。框架流程包括：让 LLMs 生成代码、使用 ground-truth 测试评估正确性、静态分析检测潜在漏洞、让 LLMs 自我检测问题，并提供反馈引导修复。实验结果显示，LLMs 在检测错误和漏洞方面表现较差，但当获得测试失败或漏洞报告的反馈时，能够显著提升代码修复能力，为开发更安全可靠的 LLM 代码生成工具提供了新途径。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.14841v2",
      "published_date": "2024-12-19 13:34:14 UTC",
      "updated_date": "2025-01-07 15:30:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:22:13.855680"
    },
    {
      "arxiv_id": "2412.14835v1",
      "title": "Progressive Multimodal Reasoning via Active Retrieval",
      "title_zh": "翻译失败",
      "authors": [
        "Guanting Dong",
        "Chenghao Zhang",
        "Mengjie Deng",
        "Yutao Zhu",
        "Zhicheng Dou",
        "Ji-Rong Wen"
      ],
      "abstract": "Multi-step multimodal reasoning tasks pose significant challenges for\nmultimodal large language models (MLLMs), and finding effective ways to enhance\ntheir performance in such scenarios remains an unresolved issue. In this paper,\nwe propose AR-MCTS, a universal framework designed to progressively improve the\nreasoning capabilities of MLLMs through Active Retrieval (AR) and Monte Carlo\nTree Search (MCTS). Our approach begins with the development of a unified\nretrieval module that retrieves key supporting insights for solving complex\nreasoning problems from a hybrid-modal retrieval corpus. To bridge the gap in\nautomated multimodal reasoning verification, we employ the MCTS algorithm\ncombined with an active retrieval mechanism, which enables the automatic\ngeneration of step-wise annotations. This strategy dynamically retrieves key\ninsights for each reasoning step, moving beyond traditional beam search\nsampling to improve the diversity and reliability of the reasoning space.\nAdditionally, we introduce a process reward model that aligns progressively to\nsupport the automatic verification of multimodal reasoning tasks. Experimental\nresults across three complex multimodal reasoning benchmarks confirm the\neffectiveness of the AR-MCTS framework in enhancing the performance of various\nmultimodal models. Further analysis demonstrates that AR-MCTS can optimize\nsampling diversity and accuracy, yielding reliable multimodal reasoning.",
      "tldr_zh": "本文提出 AR-MCTS 框架，通过 Active Retrieval (AR) 和 Monte Carlo Tree Search (MCTS) 来逐步提升多模态大语言模型 (MLLMs) 在多步多模态推理任务中的性能。该框架包括一个统一检索模块，从混合模态语料库中提取关键洞见，并结合 AR 机制自动生成步-wise 注解，同时引入过程奖励模型以支持多模态推理的自动验证。实验在三个复杂多模态推理基准上验证了 AR-MCTS 的有效性，显著提高了各种 MLLMs 的性能，并优化了采样多样性和准确性，提供更可靠的推理结果。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "Working in progress",
      "pdf_url": "http://arxiv.org/pdf/2412.14835v1",
      "published_date": "2024-12-19 13:25:39 UTC",
      "updated_date": "2024-12-19 13:25:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:21:19.749405"
    },
    {
      "arxiv_id": "2412.14814v1",
      "title": "Answer Set Networks: Casting Answer Set Programming into Deep Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Arseny Skryagin",
        "Daniel Ochs",
        "Phillip Deibert",
        "Simon Kohaut",
        "Devendra Singh Dhami",
        "Kristian Kersting"
      ],
      "abstract": "Although Answer Set Programming (ASP) allows constraining neural-symbolic\n(NeSy) systems, its employment is hindered by the prohibitive costs of\ncomputing stable models and the CPU-bound nature of state-of-the-art solvers.\nTo this end, we propose Answer Set Networks (ASN), a NeSy solver. Based on\nGraph Neural Networks (GNN), ASNs are a scalable approach to ASP-based Deep\nProbabilistic Logic Programming (DPPL). Specifically, we show how to translate\nASPs into ASNs and demonstrate how ASNs can efficiently solve the encoded\nproblem by leveraging GPU's batching and parallelization capabilities. Our\nexperimental evaluations demonstrate that ASNs outperform state-of-the-art\nCPU-bound NeSy systems on multiple tasks. Simultaneously, we make the following\ntwo contributions based on the strengths of ASNs. Namely, we are the first to\nshow the finetuning of Large Language Models (LLM) with DPPLs, employing ASNs\nto guide the training with logic. Further, we show the \"constitutional\nnavigation\" of drones, i.e., encoding public aviation laws in an ASN for\nrouting Unmanned Aerial Vehicles in uncertain environments.",
      "tldr_zh": "该论文提出 Answer Set Networks (ASN)，一种将 Answer Set Programming (ASP) 整合到深度学习框架中的方法，旨在解决 ASP 在神经符号 (NeSy) 系统中的计算效率问题。ASN 基于 Graph Neural Networks (GNN)，通过将 ASP 翻译成 ASN 模型，并利用 GPU 的批量处理和并行能力，实现高效求解 Deep Probabilistic Logic Programming (DPPL) 问题。实验结果显示，ASN 在多个任务上优于现有 CPU-bound 系统；此外，论文首次使用 ASN 指导 Large Language Models (LLM) 的微调，并将其应用于不确定环境中的无人机“宪法导航”，如编码公共航空法进行路由。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.SC",
        "68T37, 68T30, 68T27",
        "I.2.4; I.2.5"
      ],
      "primary_category": "cs.AI",
      "comment": "16 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.14814v1",
      "published_date": "2024-12-19 13:09:06 UTC",
      "updated_date": "2024-12-19 13:09:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:21:31.215821"
    },
    {
      "arxiv_id": "2412.16238v2",
      "title": "Algebraic Evaluation Theorems",
      "title_zh": "代数评估定理",
      "authors": [
        "Andrés Corrada-Emmanuel"
      ],
      "abstract": "Majority voting (MV) is the prototypical ``wisdom of the crowd'' algorithm.\nTheorems considering when MV is optimal for group decisions date back to\nCondorcet's 1785 jury \\emph{decision} theorem. The same error independence\nassumption underlying the theorem can be used to prove a jury \\emph{evaluation}\ntheorem that does purely algebraic evaluation (AE) of juror performance based\non a batch of their decisions. Three or more binary jurors are enough to obtain\nthe only two possible statistics of their correctness on a test they took. AE\nis superior to MV in three ways. First, its empirical assumptions are looser\nand can handle jurors less than 50\\% accurate in making decisions. Second, it\nhas point-like precision in evaluating them given its assumption of error\nindependence. This precision enables a multi-accuracy approach that has higher\nlabeling accuracy than MV and comes with empirical uncertainty bounds. And,\nthird, it is self-alarming about the failure of its error independence\nassumption. Experiments using demographic data from the American Community\nSurvey confirm the practical utility of AE over MV. Two implications of the\ntheorem for AI safety are discussed - a principled way to terminate infinite\nmonitoring chains (who grades the graders?) and the super-alignment problem\n(how do we evaluate agents doing tasks we do not understand?).",
      "tldr_zh": "本论文提出了代数评估定理（Algebraic Evaluation Theorems），基于Condorcet陪审团决策定理的错误独立性假设，开发了一种纯代数评估（AE）方法，用于评估陪审员或决策者在批量决策中的性能。相比传统多数投票（Majority Voting, MV），AE具有三个优势：其经验假设更宽松，能处理准确率低于50%的决策者；提供点精度评估，支持多精度方法以提高标签准确率并给出经验不确定性界限；并能警报错误独立性假设的失败。实验使用美国社区调查的demographic数据证实了AE的实用性，并讨论了其对AI安全的启示，包括终止无限监控链（who grades the graders?）和解决超对齐问题（super-alignment problem）。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "I.2.6"
      ],
      "primary_category": "cs.AI",
      "comment": "28 pages",
      "pdf_url": "http://arxiv.org/pdf/2412.16238v2",
      "published_date": "2024-12-19 13:01:21 UTC",
      "updated_date": "2025-03-12 16:31:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:21:43.774107"
    },
    {
      "arxiv_id": "2412.14810v2",
      "title": "MARIA: a Multimodal Transformer Model for Incomplete Healthcare Data",
      "title_zh": "翻译失败",
      "authors": [
        "Camillo Maria Caruso",
        "Paolo Soda",
        "Valerio Guarrasi"
      ],
      "abstract": "In healthcare, the integration of multimodal data is pivotal for developing\ncomprehensive diagnostic and predictive models. However, managing missing data\nremains a significant challenge in real-world applications. We introduce MARIA\n(Multimodal Attention Resilient to Incomplete datA), a novel transformer-based\ndeep learning model designed to address these challenges through an\nintermediate fusion strategy. Unlike conventional approaches that depend on\nimputation, MARIA utilizes a masked self-attention mechanism, which processes\nonly the available data without generating synthetic values. This approach\nenables it to effectively handle incomplete datasets, enhancing robustness and\nminimizing biases introduced by imputation methods. We evaluated MARIA against\n10 state-of-the-art machine learning and deep learning models across 8\ndiagnostic and prognostic tasks. The results demonstrate that MARIA outperforms\nexisting methods in terms of performance and resilience to varying levels of\ndata incompleteness, underscoring its potential for critical healthcare\napplications.",
      "tldr_zh": "该研究提出 MARIA，一种针对医疗领域不完整多模态数据的 Transformer 模型，通过中间融合策略(intermediate fusion strategy)和 masked self-attention 机制，仅处理可用数据，避免传统插值方法带来的偏差，从而提升模型的鲁棒性和减少偏置。在 8 个诊断和预后任务上，MARIA 与 10 个最先进机器学习和深度学习模型相比，表现出更高的性能和对数据不完整性的抵抗力。该模型为医疗应用中的综合诊断和预测提供了更可靠的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.14810v2",
      "published_date": "2024-12-19 13:00:03 UTC",
      "updated_date": "2025-04-30 12:32:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:21:54.870677"
    },
    {
      "arxiv_id": "2412.14802v1",
      "title": "Stack Trace Deduplication: Faster, More Accurately, and in More Realistic Scenarios",
      "title_zh": "栈追踪去重：更快、更准确、以及在更现实的场景中",
      "authors": [
        "Egor Shibaev",
        "Denis Sushentsev",
        "Yaroslav Golubev",
        "Aleksandr Khvorov"
      ],
      "abstract": "In large-scale software systems, there are often no fully-fledged bug reports\nwith human-written descriptions when an error occurs. In this case, developers\nrely on stack traces, i.e., series of function calls that led to the error.\nSince there can be tens and hundreds of thousands of them describing the same\nissue from different users, automatic deduplication into categories is\nnecessary to allow for processing. Recent works have proposed powerful deep\nlearning-based approaches for this, but they are evaluated and compared in\nisolation from real-life workflows, and it is not clear whether they will\nactually work well at scale.\n  To overcome this gap, this work presents three main contributions: a novel\nmodel, an industry-based dataset, and a multi-faceted evaluation. Our model\nconsists of two parts - (1) an embedding model with byte-pair encoding and\napproximate nearest neighbor search to quickly find the most relevant stack\ntraces to the incoming one, and (2) a reranker that re-ranks the most fitting\nstack traces, taking into account the repeated frames between them. To\ncomplement the existing datasets collected from open-source projects, we share\nwith the community SlowOps - a dataset of stack traces from IntelliJ-based\nproducts developed by JetBrains, which has an order of magnitude more stack\ntraces per category. Finally, we carry out an evaluation that strives to be\nrealistic: measuring not only the accuracy of categorization, but also the\noperation time and the ability to create new categories. The evaluation shows\nthat our model strikes a good balance - it outperforms other models on both\nopen-source datasets and SlowOps, while also being faster on time than most. We\nrelease all of our code and data, and hope that our work can pave the way to\nfurther practice-oriented research in the area.",
      "tldr_zh": "这篇论文针对大型软件系统中stack traces（错误函数调用序列）的自动去重分类问题，提出了一种新模型，以提升速度、准确性和真实场景适用性。该模型包括一个使用byte-pair encoding和approximate nearest neighbor search的嵌入模型，用于快速查找相关stack traces，以及一个reranker模块来重新排序并考虑重复帧，从而提高分类精度。为填补现有数据集的不足，论文分享了SlowOps数据集，这是一个基于JetBrains IntelliJ产品的行业数据集，每类别包含更多stack traces。实验评估显示，该模型在开源数据集和SlowOps上均优于现有方法，同时在准确性和操作时间上表现出色，并开源了代码以推动更多实践导向的研究。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "Published at SANER'25. 11 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.14802v1",
      "published_date": "2024-12-19 12:48:17 UTC",
      "updated_date": "2024-12-19 12:48:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:22:07.119080"
    },
    {
      "arxiv_id": "2412.15305v1",
      "title": "Tree-of-Code: A Tree-Structured Exploring Framework for End-to-End Code Generation and Execution in Complex Task Handling",
      "title_zh": "翻译失败",
      "authors": [
        "Ziyi Ni",
        "Yifan Li",
        "Ning Yang",
        "Dou Shen",
        "Pin Lv",
        "Daxiang Dong"
      ],
      "abstract": "Solving complex reasoning tasks is a key real-world application of agents.\nThanks to the pretraining of Large Language Models (LLMs) on code data, recent\napproaches like CodeAct successfully use code as LLM agents' action, achieving\ngood results. However, CodeAct greedily generates the next action's code block\nby relying on fragmented thoughts, resulting in inconsistency and instability.\nMoreover, CodeAct lacks action-related ground-truth (GT), making its\nsupervision signals and termination conditions questionable in multi-turn\ninteractions. To address these issues, we first introduce a simple yet\neffective end-to-end code generation paradigm, CodeProgram, which leverages\ncode's systematic logic to align with global reasoning and enable cohesive\nproblem-solving. Then, we propose Tree-of-Code (ToC), which self-grows\nCodeProgram nodes based on the executable nature of the code and enables\nself-supervision in a GT-free scenario. Experimental results on two datasets\nusing ten popular zero-shot LLMs show ToC remarkably boosts accuracy by nearly\n20% over CodeAct with less than 1/4 turns. Several LLMs even perform better on\none-turn CodeProgram than on multi-turn CodeAct. To further investigate the\ntrade-off between efficacy and efficiency, we test different ToC tree sizes and\nexploration mechanisms. We also highlight the potential of ToC's end-to-end\ndata generation for supervised and reinforced fine-tuning.",
      "tldr_zh": "该论文提出Tree-of-Code (ToC)，一个基于树结构的探索框架，用于端到端代码生成和执行，以处理复杂推理任务。ToC 通过引入CodeProgram范式，利用代码的系统逻辑实现全局推理对齐和连贯问题解决，并基于代码的可执行性实现自增长节点和无ground-truth (GT)场景下的自监督。实验在两个数据集上使用十个零样本LLMs显示，ToC比CodeAct提高了近20%的准确率，且仅需不到1/4的回合；此外，某些LLMs在单回合CodeProgram上表现优于多回合CodeAct。论文还探讨了不同ToC树大小和探索机制的效能权衡，并强调其端到端数据生成潜力，用于监督和强化微调。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "This idea was first submitted to the NeuralPS Workshop \"System 2\n  Reasoning At Scale\" in September 2024. Its OpenReview:\n  https://openreview.net/forum?id=8NKAL8Ngxk&noteId=8NKAL8Ngxk. It was then\n  submitted to the NAACL 2025 in October 2024, which is recorded in:\n  https://openreview.net/forum?id=S0ZUWD3Vy5&noteId=S0ZUWD3Vy5. This work\n  predates many existing works",
      "pdf_url": "http://arxiv.org/pdf/2412.15305v1",
      "published_date": "2024-12-19 12:31:22 UTC",
      "updated_date": "2024-12-19 12:31:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:22:19.615859"
    },
    {
      "arxiv_id": "2502.07786v1",
      "title": "Counterexample Guided Program Repair Using Zero-Shot Learning and MaxSAT-based Fault Localization",
      "title_zh": "翻译失败",
      "authors": [
        "Pedro Orvalho",
        "Mikoláš Janota",
        "Vasco Manquinho"
      ],
      "abstract": "Automated Program Repair (APR) for introductory programming assignments\n(IPAs) is motivated by the large number of student enrollments in programming\ncourses each year. Since providing feedback on IPAs requires substantial time\nand effort from faculty, personalized feedback often involves suggesting fixes\nto students' programs. Formal Methods (FM)-based semantic repair approaches,\ncheck a program's execution against a test suite or reference solution, are\neffective but limited. These tools excel at identifying buggy parts but can\nonly fix programs if the correct implementation and the faulty one share the\nsame control flow graph. Conversely, Large Language Models (LLMs) are used for\nAPR but often make extensive instead of minimal rewrites. This leads to more\ninvasive fixes, making it harder for students to learn from their mistakes. In\nsummary, LLMs excel at completing strings, while FM-based fault localization\nexcel at identifying buggy parts of a program. In this paper, we propose a\nnovel approach that combines the strengths of both FM-based fault localization\nand LLMs, via zero-shot learning, to enhance APR for IPAs. Our method uses\nMaxSAT-based fault localization to identify buggy parts of a program, then\npresents the LLM with a program sketch devoid of these buggy statements. This\nhybrid approach follows a CEGIS loop to iteratively refine the program. We ask\nthe LLM to synthesize the missing parts, which are then checked against a test\nsuite. If the suggested program is incorrect, a counterexample from the test\nsuite is fed back to the LLM. Our experiments show that our counterexample\nguided approach, using MaxSAT-based bug-free program sketches, significantly\nimproves the repair capabilities of all six evaluated LLMs. This method allows\nLLMs to repair more programs with smaller fixes, outperforming other\nconfigurations and state-of-the-art symbolic program repair tools.",
      "tldr_zh": "本文提出了一种Counterexample Guided Program Repair方法，结合Zero-Shot Learning和MaxSAT-based Fault Localization，用于Automated Program Repair（APR）入门级编程作业（IPAs），以弥补Formal Methods（FM）工具的控制流限制和Large Language Models（LLMs）的过度修改问题。该方法先用MaxSAT-based Fault Localization识别程序错误部分，然后通过LLMs生成无错误程序草图，并采用CEGIS循环迭代反馈counterexample进行改进。实验结果显示，该混合方法显著提升了六个LLMs的修复能力，使其修复更多程序且修改更小，优于其他配置和现有符号程序修复工具。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted at AAAI 2025. 11 pages, 4 listings, 2 figures and 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2502.07786v1",
      "published_date": "2024-12-19 12:08:44 UTC",
      "updated_date": "2024-12-19 12:08:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:22:31.422872"
    },
    {
      "arxiv_id": "2412.14779v1",
      "title": "Agent-Temporal Credit Assignment for Optimal Policy Preservation in Sparse Multi-Agent Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Aditya Kapoor",
        "Sushant Swamy",
        "Kale-ab Tessera",
        "Mayank Baranwal",
        "Mingfei Sun",
        "Harshad Khadilkar",
        "Stefano V. Albrecht"
      ],
      "abstract": "In multi-agent environments, agents often struggle to learn optimal policies\ndue to sparse or delayed global rewards, particularly in long-horizon tasks\nwhere it is challenging to evaluate actions at intermediate time steps. We\nintroduce Temporal-Agent Reward Redistribution (TAR$^2$), a novel approach\ndesigned to address the agent-temporal credit assignment problem by\nredistributing sparse rewards both temporally and across agents. TAR$^2$\ndecomposes sparse global rewards into time-step-specific rewards and calculates\nagent-specific contributions to these rewards. We theoretically prove that\nTAR$^2$ is equivalent to potential-based reward shaping, ensuring that the\noptimal policy remains unchanged. Empirical results demonstrate that TAR$^2$\nstabilizes and accelerates the learning process. Additionally, we show that\nwhen TAR$^2$ is integrated with single-agent reinforcement learning algorithms,\nit performs as well as or better than traditional multi-agent reinforcement\nlearning methods.",
      "tldr_zh": "这篇论文针对多智能体强化学习(multi-agent reinforcement learning)中稀疏或延迟全局奖励导致的学习挑战，提出了一种新方法Temporal-Agent Reward Redistribution (TAR²)。TAR² 通过将稀疏全局奖励分解为特定时间步的奖励，并计算每个代理的贡献，实现时间和代理间的奖励重新分配。理论上证明 TAR² 等同于 potential-based reward shaping，确保最优策略保持不变。实验结果表明，该方法稳定并加速了学习过程，并在与单智能体强化学习算法结合时，表现不亚于或优于传统多智能体方法。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.GT",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.MA",
      "comment": "12 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2412.14779v1",
      "published_date": "2024-12-19 12:05:13 UTC",
      "updated_date": "2024-12-19 12:05:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:22:43.643739"
    },
    {
      "arxiv_id": "2412.14775v1",
      "title": "Energy and polarization based on-line interference mitigation in radio interferometry",
      "title_zh": "翻译失败",
      "authors": [
        "Sarod Yatawatta",
        "Albert-Jan Boonstra",
        "Chris P. Broekema"
      ],
      "abstract": "Radio frequency interference (RFI) is a persistent contaminant in terrestrial\nradio astronomy. While new radio interferometers are becoming operational,\nnovel sources of RFI are also emerging. In order to strengthen the mitigation\nof RFI in modern radio interferometers, we propose an on-line RFI mitigation\nscheme that can be run in the correlator of such interferometers. We combine\nstatistics based on the energy as well as the polarization alignment of the\ncorrelated signal to develop an on-line RFI mitigation scheme that can be\napplied to a data stream produced by the correlator in real-time, especially\ntargeted at low duty-cycle or transient RFI detection. In order to improve the\ncomputational efficiency, we explore the use of both single precision and half\nprecision floating point operations in implementing the RFI mitigation\nalgorithm. This ideally suits its deployment in accelerator computing devices\nsuch as graphics processing units (GPUs) as used by the LOFAR correlator. We\nprovide results based on real data to demonstrate the efficacy of the proposed\nmethod.",
      "tldr_zh": "这篇论文针对射电天文学中的射频干扰(RFI)问题，提出了一种基于能量和极化对齐统计的在线缓解方案，可在相关器(correlator)中实时处理数据流，特别是针对低占空比或瞬态RFI。方法结合了统计分析和单精度及半精度浮点运算，以提高计算效率，并适合部署在GPU等加速器设备上，如LOFAR correlator。实验结果基于真实数据，证明了该方案的有效性，提升了RFI缓解的性能。",
      "categories": [
        "astro-ph.IM",
        "cs.AI"
      ],
      "primary_category": "astro-ph.IM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.14775v1",
      "published_date": "2024-12-19 11:59:17 UTC",
      "updated_date": "2024-12-19 11:59:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:22:54.874846"
    },
    {
      "arxiv_id": "2412.14771v1",
      "title": "ALKAFI-LLAMA3: Fine-Tuning LLMs for Precise Legal Understanding in Palestine",
      "title_zh": "翻译失败",
      "authors": [
        "Rabee Qasem",
        "Mohannad Hendi",
        "Banan Tantour"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated remarkable potential in\ndiverse domains, yet their application in the legal sector, particularly in\nlow-resource contexts, remains limited. This study addresses the challenges of\nadapting LLMs to the Palestinian legal domain, where political instability,\nfragmented legal frameworks, and limited AI resources hinder effective\nmachine-learning applications. We present a fine-tuned model based on a\nquantized version of Llama-3.2-1B-Instruct, trained on a synthetic data set\nderived from Palestinian legal texts. Using smaller-scale models and\nstrategically generated question-answer pairs, we achieve a cost-effective,\nlocally sustainable solution that provides accurate and contextually relevant\nlegal guidance. Our experiments demonstrate promising performance on various\nquery types, ranging from yes/no questions and narrative explanations to\ncomplex legal differentiations, while highlighting areas for improvement, such\nas handling calculation-based inquiries and structured list formatting. This\nwork provides a pathway for the deployment of AI-driven legal assistance tools\ntailored to the needs of resource-constrained environments.",
      "tldr_zh": "该研究针对 LLMs 在巴勒斯坦法律领域的应用挑战（如政治不稳定和资源有限），提出了一种微调模型 ALKAFI-LLAMA3，基于 Llama-3.2-1B-Instruct 的量化版本，并使用从巴勒斯坦法律文本派生的合成数据集进行训练。模型通过小规模模型和策略性生成的问答对，实现成本效益高且本地可持续的法律指导。实验结果显示，该模型在是/否问题、叙述解释和复杂法律区分等查询类型上表现出色，但需进一步改进处理计算查询和结构化列表；这项工作为资源受限环境提供定制的 AI 驱动法律援助工具铺平了道路。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.14771v1",
      "published_date": "2024-12-19 11:55:51 UTC",
      "updated_date": "2024-12-19 11:55:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:23:07.403140"
    },
    {
      "arxiv_id": "2412.14764v1",
      "title": "CodeRepoQA: A Large-scale Benchmark for Software Engineering Question Answering",
      "title_zh": "CodeRepoQA: 软件工程问答的大规模基准测试",
      "authors": [
        "Ruida Hu",
        "Chao Peng",
        "Jingyi Ren",
        "Bo Jiang",
        "Xiangxin Meng",
        "Qinyun Wu",
        "Pengfei Gao",
        "Xinchen Wang",
        "Cuiyun Gao"
      ],
      "abstract": "In this work, we introduce CodeRepoQA, a large-scale benchmark specifically\ndesigned for evaluating repository-level question-answering capabilities in the\nfield of software engineering. CodeRepoQA encompasses five programming\nlanguages and covers a wide range of scenarios, enabling comprehensive\nevaluation of language models. To construct this dataset, we crawl data from 30\nwell-known repositories in GitHub, the largest platform for hosting and\ncollaborating on code, and carefully filter raw data. In total, CodeRepoQA is a\nmulti-turn question-answering benchmark with 585,687 entries, covering a\ndiverse array of software engineering scenarios, with an average of 6.62\ndialogue turns per entry.\n  We evaluate ten popular large language models on our dataset and provide\nin-depth analysis. We find that LLMs still have limitations in\nquestion-answering capabilities in the field of software engineering, and\nmedium-length contexts are more conducive to LLMs' performance. The entire\nbenchmark is publicly available at\nhttps://github.com/kinesiatricssxilm14/CodeRepoQA.",
      "tldr_zh": "本文提出 CodeRepoQA，这是一个大规模基准，用于评估软件工程领域仓库级问题回答能力，涵盖五种编程语言和多种场景。数据集通过从 GitHub 的30个知名仓库爬取并过滤原始数据构建，共包含585,687条多轮对话条目，平均每个条目有6.62个对话轮次。研究评估了十个热门 Large Language Models (LLMs)，发现这些模型在软件工程问题回答方面存在局限性，而中等长度上下文更能提升性能。该基准已公开在 https://github.com/kinesiatricssxilm14/CodeRepoQA 上，供进一步研究使用。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.14764v1",
      "published_date": "2024-12-19 11:48:01 UTC",
      "updated_date": "2024-12-19 11:48:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:23:19.192556"
    },
    {
      "arxiv_id": "2412.14736v1",
      "title": "Advances in Artificial Intelligence forDiabetes Prediction: Insights from a Systematic Literature Review",
      "title_zh": "人工智能在糖尿病预测中的进展：系统文献综述的见解",
      "authors": [
        "Pir Bakhsh Khokhar",
        "Carmine Gravino",
        "Fabio Palomba"
      ],
      "abstract": "This systematic review explores the use of machine learning (ML) in\npredicting diabetes, focusing on datasets, algorithms, training methods, and\nevaluation metrics. It examines datasets like the Singapore National Diabetic\nRetinopathy Screening program, REPLACE-BG, National Health and Nutrition\nExamination Survey, and Pima Indians Diabetes Database. The review assesses the\nperformance of ML algorithms like CNN, SVM, Logistic Regression, and XGBoost in\npredicting diabetes outcomes. The study emphasizes the importance of\ninterdisciplinary collaboration and ethical considerations in ML-based diabetes\nprediction models.",
      "tldr_zh": "本研究通过系统文献综述，探讨了机器学习(ML)在糖尿病预测中的进展，焦点包括数据集、算法、训练方法和评估指标。文献审视了如 Singapore National Diabetic Retinopathy Screening program、REPLACE-BG、National Health and Nutrition Examination Survey 和 Pima Indians Diabetes Database 等数据集，以及 CNN、SVM、Logistic Regression 和 XGBoost 等算法的性能表现。该研究强调了跨学科合作和伦理考虑在构建可靠的 ML 模型中的重要性，以推动糖尿病预测的实际应用。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.14736v1",
      "published_date": "2024-12-19 11:09:10 UTC",
      "updated_date": "2024-12-19 11:09:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:23:31.064257"
    },
    {
      "arxiv_id": "2412.14732v1",
      "title": "Beyond the Hype: A Comprehensive Review of Current Trends in Generative AI Research, Teaching Practices, and Tools",
      "title_zh": "超越炒作：生成式 AI 研究、教学实践和工具的当前趋势全面审查",
      "authors": [
        "James Prather",
        "Juho Leinonen",
        "Natalie Kiesler",
        "Jamie Gorson Benario",
        "Sam Lau",
        "Stephen MacNeil",
        "Narges Norouzi",
        "Simone Opel",
        "Vee Pettit",
        "Leo Porter",
        "Brent N. Reeves",
        "Jaromir Savelka",
        "David H. Smith IV",
        "Sven Strickroth",
        "Daniel Zingaro"
      ],
      "abstract": "Generative AI (GenAI) is advancing rapidly, and the literature in computing\neducation is expanding almost as quickly. Initial responses to GenAI tools were\nmixed between panic and utopian optimism. Many were fast to point out the\nopportunities and challenges of GenAI. Researchers reported that these new\ntools are capable of solving most introductory programming tasks and are\ncausing disruptions throughout the curriculum. These tools can write and\nexplain code, enhance error messages, create resources for instructors, and\neven provide feedback and help for students like a traditional teaching\nassistant. In 2024, new research started to emerge on the effects of GenAI\nusage in the computing classroom. These new data involve the use of GenAI to\nsupport classroom instruction at scale and to teach students how to code with\nGenAI. In support of the former, a new class of tools is emerging that can\nprovide personalized feedback to students on their programming assignments or\nteach both programming and prompting skills at the same time. With the\nliterature expanding so rapidly, this report aims to summarize and explain what\nis happening on the ground in computing classrooms. We provide a systematic\nliterature review; a survey of educators and industry professionals; and\ninterviews with educators using GenAI in their courses, educators studying\nGenAI, and researchers who create GenAI tools to support computing education.\nThe triangulation of these methods and data sources expands the understanding\nof GenAI usage and perceptions at this critical moment for our community.",
      "tldr_zh": "这篇论文对 Generative AI (GenAI) 在计算教育领域的当前趋势进行了全面综述，涵盖研究、教学实践和工具的发展。作者通过系统文献综述、针对教育者和行业专业人士的调查，以及对使用 GenAI 课程的教师和研究者的访谈，分析了 GenAI 的应用，如代码编写、错误解释和提供个性化反馈。研究发现，GenAI 能支持大规模课堂教学、提升编程技能和提示技巧，但也引发了初始的恐慌与乐观反应，为社区提供了及时的洞见和实用指导。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC",
        "cs.SE"
      ],
      "primary_category": "cs.CY",
      "comment": "39 pages, 10 figures, 16 tables. To be published in the Proceedings\n  of the 2024 Working Group Reports on Innovation and Technology in Computer\n  Science Education (ITiCSE-WGR 2024)",
      "pdf_url": "http://arxiv.org/pdf/2412.14732v1",
      "published_date": "2024-12-19 11:01:11 UTC",
      "updated_date": "2024-12-19 11:01:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:23:42.976953"
    },
    {
      "arxiv_id": "2412.14728v1",
      "title": "LTLf Synthesis Under Unreliable Input",
      "title_zh": "翻译失败",
      "authors": [
        "Christian Hagemeier",
        "Giuseppe de Giacomo",
        "Moshe Y. Vardi"
      ],
      "abstract": "We study the problem of realizing strategies for an LTLf goal specification\nwhile ensuring that at least an LTLf backup specification is satisfied in case\nof unreliability of certain input variables. We formally define the problem and\ncharacterize its worst-case complexity as 2EXPTIME-complete, like standard LTLf\nsynthesis. Then we devise three different solution techniques: one based on\ndirect automata manipulation, which is 2EXPTIME, one disregarding unreliable\ninput variables by adopting a belief construction, which is 3EXPTIME, and one\nleveraging second-order quantified LTLf (QLTLf), which is 2EXPTIME and allows\nfor a direct encoding into monadic second-order logic, which in turn is\nworst-case nonelementary. We prove their correctness and evaluate them against\neach other empirically. Interestingly, theoretical worst-case bounds do not\ntranslate into observed performance; the MSO technique performs best, followed\nby belief construction and direct automata manipulation. As a byproduct of our\nstudy, we provide a general synthesis procedure for arbitrary QLTLf\nspecifications.",
      "tldr_zh": "这篇论文研究了在输入变量不可靠情况下，实现 LTLf 目标规范的策略，同时确保至少一个 LTLf 备份规范被满足。作者定义了该问题的最坏情况复杂度为 2EXPTIME-complete，并提出了三种解决方案：基于直接自动机操作的（复杂度 2EXPTIME）、采用信念构造忽略不可靠变量的（复杂度 3EXPTIME）、以及利用二阶量化 LTLf (QLTLf) 的方法（复杂度 2EXPTIME，可编码成 monadic second-order logic）。实验结果显示，尽管理论复杂度较高，但 QLTLf 相关技术（MSO）在实际性能上表现最佳，其次是信念构造和直接自动机操作；作为副产品，该研究还提供了一个通用的 QLTLf 规范合成过程。",
      "categories": [
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages, to appear at AAAI2025",
      "pdf_url": "http://arxiv.org/pdf/2412.14728v1",
      "published_date": "2024-12-19 10:54:17 UTC",
      "updated_date": "2024-12-19 10:54:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:23:56.267698"
    },
    {
      "arxiv_id": "2412.15298v1",
      "title": "A Comparative Study of DSPy Teleprompter Algorithms for Aligning Large Language Models Evaluation Metrics to Human Evaluation",
      "title_zh": "翻译失败",
      "authors": [
        "Bhaskarjit Sarmah",
        "Kriti Dutta",
        "Anna Grigoryan",
        "Sachin Tiwari",
        "Stefano Pasquali",
        "Dhagash Mehta"
      ],
      "abstract": "We argue that the Declarative Self-improving Python (DSPy) optimizers are a\nway to align the large language model (LLM) prompts and their evaluations to\nthe human annotations. We present a comparative analysis of five teleprompter\nalgorithms, namely, Cooperative Prompt Optimization (COPRO), Multi-Stage\nInstruction Prompt Optimization (MIPRO), BootstrapFewShot, BootstrapFewShot\nwith Optuna, and K-Nearest Neighbor Few Shot, within the DSPy framework with\nrespect to their ability to align with human evaluations. As a concrete\nexample, we focus on optimizing the prompt to align hallucination detection\n(using LLM as a judge) to human annotated ground truth labels for a publicly\navailable benchmark dataset. Our experiments demonstrate that optimized prompts\ncan outperform various benchmark methods to detect hallucination, and certain\ntelemprompters outperform the others in at least these experiments.",
      "tldr_zh": "本研究比较了 DSPy 框架中的五个 teleprompter 算法，包括 COPRO、MIPRO、BootstrapFewShot、BootstrapFewShot with Optuna 和 K-Nearest Neighbor Few Shot，以评估它们将大型语言模型 (LLM) 的提示和评估指标与人类标注对齐的能力。论文以幻觉检测为例，通过优化提示使 LLM 作为判断者生成的输出更接近人类标注的基准数据集。实验结果显示，优化后的提示在检测幻觉方面优于现有基准方法，且某些算法（如 MIPRO）在这些测试中表现出色。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "q-fin.ST",
        "stat.ME"
      ],
      "primary_category": "cs.CL",
      "comment": "7 pages, 10 tables, two-column format",
      "pdf_url": "http://arxiv.org/pdf/2412.15298v1",
      "published_date": "2024-12-19 10:38:46 UTC",
      "updated_date": "2024-12-19 10:38:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:24:07.814789"
    },
    {
      "arxiv_id": "2412.14708v1",
      "title": "Creation of AI-driven Smart Spaces for Enhanced Indoor Environments -- A Survey",
      "title_zh": "AI驱动智能空间的创建以增强室内环境——综述",
      "authors": [
        "Aygün Varol",
        "Naser Hossein Motlagh",
        "Mirka Leino",
        "Sasu Tarkoma",
        "Johanna Virkki"
      ],
      "abstract": "Smart spaces are ubiquitous computing environments that integrate diverse\nsensing and communication technologies to enhance space functionality, optimize\nenergy utilization, and improve user comfort and well-being. The integration of\nemerging AI methodologies into these environments facilitates the formation of\nAI-driven smart spaces, which further enhance functionalities of the spaces by\nenabling advanced applications such as personalized comfort settings,\ninteractive living spaces, and automatization of the space systems, all\nresulting in enhanced indoor experiences of the users. In this paper, we\npresent a systematic survey of existing research on the foundational components\nof AI-driven smart spaces, including sensor technologies, data communication\nprotocols, sensor network management and maintenance strategies, as well as the\ndata collection, processing and analytics. Given the pivotal role of AI in\nestablishing AI-powered smart spaces, we explore the opportunities and\nchallenges associated with traditional machine learning (ML) approaches, such\nas deep learning (DL), and emerging methodologies including large language\nmodels (LLMs). Finally, we provide key insights necessary for the development\nof AI-driven smart spaces, propose future research directions, and sheds light\non the path forward.",
      "tldr_zh": "这篇论文对AI驱动智能空间（AI-driven smart spaces）的创建进行系统调查，旨在通过整合传感器技术、数据通信协议、传感器网络管理和数据处理来提升室内环境的能效和用户舒适度。论文探讨了传统机器学习（ML）方法如深度学习（DL）和新兴方法如大型语言模型（LLMs）在这些空间中的应用机会与挑战，包括实现个性化舒适设置和自动化系统的潜力。最终，论文提供了关键洞见和未来研究方向，推动AI驱动智能空间的可持续发展。",
      "categories": [
        "cs.AI",
        "cs.DC",
        "cs.ET",
        "cs.HC",
        "I.2; C.0; I.0"
      ],
      "primary_category": "cs.AI",
      "comment": "39 pages, 3 figures, 1 table, journal",
      "pdf_url": "http://arxiv.org/pdf/2412.14708v1",
      "published_date": "2024-12-19 10:20:34 UTC",
      "updated_date": "2024-12-19 10:20:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:24:18.136751"
    },
    {
      "arxiv_id": "2412.14689v1",
      "title": "How to Synthesize Text Data without Model Collapse?",
      "title_zh": "翻译失败",
      "authors": [
        "Xuekai Zhu",
        "Daixuan Cheng",
        "Hengli Li",
        "Kaiyan Zhang",
        "Ermo Hua",
        "Xingtai Lv",
        "Ning Ding",
        "Zhouhan Lin",
        "Zilong Zheng",
        "Bowen Zhou"
      ],
      "abstract": "Model collapse in synthetic data indicates that iterative training on\nself-generated data leads to a gradual decline in performance. With the\nproliferation of AI models, synthetic data will fundamentally reshape the web\ndata ecosystem. Future GPT-$\\{n\\}$ models will inevitably be trained on a blend\nof synthetic and human-produced data. In this paper, we focus on two questions:\nwhat is the impact of synthetic data on language model training, and how to\nsynthesize data without model collapse? We first pre-train language models\nacross different proportions of synthetic data, revealing a negative\ncorrelation between the proportion of synthetic data and model performance. We\nfurther conduct statistical analysis on synthetic data to uncover\ndistributional shift phenomenon and over-concentration of n-gram features.\nInspired by the above findings, we propose token editing on human-produced data\nto obtain semi-synthetic data. As a proof of concept, we theoretically\ndemonstrate that token-level editing can prevent model collapse, as the test\nerror is constrained by a finite upper bound. We conduct extensive experiments\non pre-training from scratch, continual pre-training, and supervised\nfine-tuning. The results validate our theoretical proof that token-level\nediting improves data quality and enhances model performance.",
      "tldr_zh": "这篇论文探讨了在合成数据上训练语言模型时出现的模型崩溃（model collapse）问题，即迭代训练自生成数据导致性能逐渐下降，并分析了合成数据比例与模型性能的负相关关系，以及合成数据中的分布偏移（distributional shift）和 n-gram 特征过度集中现象。研究者提出一种通过对人类产生的数据进行 token editing 生成半合成数据的方法，以改善数据质量。理论证明显示，这种 token-level 编辑能将测试错误限制在有限上限，从而防止模型崩溃；实验在预训练、持续预训练和监督微调场景中验证了该方法的有效性，提高了整体模型性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.14689v1",
      "published_date": "2024-12-19 09:43:39 UTC",
      "updated_date": "2024-12-19 09:43:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:24:31.827006"
    },
    {
      "arxiv_id": "2501.10388v2",
      "title": "Beyond the Sum: Unlocking AI Agents Potential Through Market Forces",
      "title_zh": "超越总和：通过市场力量解锁 AI 代理的潜力",
      "authors": [
        "Jordi Montes Sanabria",
        "Pol Alvarez Vecino"
      ],
      "abstract": "The emergence of Large Language Models has fundamentally transformed the\ncapabilities of AI agents, enabling a new class of autonomous agents capable of\ninteracting with their environment through dynamic code generation and\nexecution. These agents possess the theoretical capacity to operate as\nindependent economic actors within digital markets, offering unprecedented\npotential for value creation through their distinct advantages in operational\ncontinuity, perfect replication, and distributed learning capabilities.\nHowever, contemporary digital infrastructure, architected primarily for human\ninteraction, presents significant barriers to their participation.\n  This work presents a systematic analysis of the infrastructure requirements\nnecessary for AI agents to function as autonomous participants in digital\nmarkets. We examine four key areas - identity and authorization, service\ndiscovery, interfaces, and payment systems - to show how existing\ninfrastructure actively impedes agent participation. We argue that addressing\nthese infrastructure challenges represents more than a technical imperative; it\nconstitutes a fundamental step toward enabling new forms of economic\norganization. Much as traditional markets enable human intelligence to\ncoordinate complex activities beyond individual capability, markets\nincorporating AI agents could dramatically enhance economic efficiency through\ncontinuous operation, perfect information sharing, and rapid adaptation to\nchanging conditions. The infrastructure challenges identified in this work\nrepresent key barriers to realizing this potential.",
      "tldr_zh": "该论文探讨了大型语言模型如何提升AI agents的能力，使其能够通过动态代码生成和执行，成为数字市场的独立经济参与者，并利用持续操作、完美复制和分布式学习优势创造价值。然而，现有的数字基础设施（如身份和授权、服务发现、接口以及支付系统）主要针对人类互动，严重阻碍了AI agents的参与。作者通过系统分析这些关键领域，论证了解决基础设施挑战的必要性，这不仅是技术问题，更是实现新经济组织形式的关键，能通过持续操作、完美信息共享和快速适应显著提高经济效率。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL",
        "cs.GT",
        "cs.MA",
        "I.2.2; I.2.7; I.2.11; J.4; K.4.4"
      ],
      "primary_category": "cs.CY",
      "comment": "20 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.10388v2",
      "published_date": "2024-12-19 09:40:40 UTC",
      "updated_date": "2025-01-23 22:53:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:24:43.816160"
    },
    {
      "arxiv_id": "2412.14686v1",
      "title": "Each Fake News is Fake in its Own Way: An Attribution Multi-Granularity Benchmark for Multimodal Fake News Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Hao Guo",
        "Zihan Ma",
        "Zhi Zeng",
        "Minnan Luo",
        "Weixin Zeng",
        "Jiuyang Tang",
        "Xiang Zhao"
      ],
      "abstract": "Social platforms, while facilitating access to information, have also become\nsaturated with a plethora of fake news, resulting in negative consequences.\nAutomatic multimodal fake news detection is a worthwhile pursuit. Existing\nmultimodal fake news datasets only provide binary labels of real or fake.\nHowever, real news is alike, while each fake news is fake in its own way. These\ndatasets fail to reflect the mixed nature of various types of multimodal fake\nnews. To bridge the gap, we construct an attributing multi-granularity\nmultimodal fake news detection dataset \\amg, revealing the inherent fake\npattern. Furthermore, we propose a multi-granularity clue alignment model \\our\nto achieve multimodal fake news detection and attribution. Experimental results\ndemonstrate that \\amg is a challenging dataset, and its attribution setting\nopens up new avenues for future research.",
      "tldr_zh": "这篇论文针对社交平台上多模态假新闻的多样性问题，构建了一个新的基准数据集 AMG（Attribution Multi-Granularity Benchmark），它提供多粒度归因标签，以揭示假新闻的内在模式，并弥补现有数据集仅限二元标签的不足。论文提出了一种多粒度线索对齐模型 \\our，用于实现多模态假新闻检测和归因，通过对齐不同粒度的线索来提升准确性。实验结果表明，AMG 是一个具有挑战性的数据集，其归因设置为未来多模态假新闻研究开辟了新路径。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.14686v1",
      "published_date": "2024-12-19 09:40:17 UTC",
      "updated_date": "2024-12-19 09:40:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:24:55.128583"
    },
    {
      "arxiv_id": "2412.14684v1",
      "title": "Bel Esprit: Multi-Agent Framework for Building AI Model Pipelines",
      "title_zh": "翻译失败",
      "authors": [
        "Yunsu Kim",
        "AhmedElmogtaba Abdelaziz",
        "Thiago Castro Ferreira",
        "Mohamed Al-Badrashiny",
        "Hassan Sawaf"
      ],
      "abstract": "As the demand for artificial intelligence (AI) grows to address complex\nreal-world tasks, single models are often insufficient, requiring the\nintegration of multiple models into pipelines. This paper introduces Bel\nEsprit, a conversational agent designed to construct AI model pipelines based\non user-defined requirements. Bel Esprit employs a multi-agent framework where\nsubagents collaborate to clarify requirements, build, validate, and populate\npipelines with appropriate models. We demonstrate the effectiveness of this\nframework in generating pipelines from ambiguous user queries, using both\nhuman-curated and synthetic data. A detailed error analysis highlights ongoing\nchallenges in pipeline construction. Bel Esprit is available for a free trial\nat https://belesprit.aixplain.com.",
      "tldr_zh": "该论文介绍了 Bel Esprit，一个多智能体框架，旨在帮助用户根据特定需求构建 AI 模型管道，以应对单一模型无法处理复杂现实任务的挑战。框架中的子代理通过协作方式来澄清用户要求、构建管道、验证其有效性，并填充合适的模型。实验结果显示，Bel Esprit 能够有效处理模糊查询，使用人工整理和合成数据进行验证，同时错误分析突出了管道构建中的潜在挑战；该框架现提供免费试用，访问链接为 https://belesprit.aixplain.com。",
      "categories": [
        "cs.AI",
        "cs.HC",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.14684v1",
      "published_date": "2024-12-19 09:36:33 UTC",
      "updated_date": "2024-12-19 09:36:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:25:06.764857"
    },
    {
      "arxiv_id": "2412.14680v2",
      "title": "A Light-Weight Framework for Open-Set Object Detection with Decoupled Feature Alignment in Joint Space",
      "title_zh": "翻译失败",
      "authors": [
        "Yonghao He",
        "Hu Su",
        "Haiyong Yu",
        "Cong Yang",
        "Wei Sui",
        "Cong Wang",
        "Song Liu"
      ],
      "abstract": "Open-set object detection (OSOD) is highly desirable for robotic manipulation\nin unstructured environments. However, existing OSOD methods often fail to meet\nthe requirements of robotic applications due to their high computational burden\nand complex deployment. To address this issue, this paper proposes a\nlight-weight framework called Decoupled OSOD (DOSOD), which is a practical and\nhighly efficient solution to support real-time OSOD tasks in robotic systems.\nSpecifically, DOSOD builds upon the YOLO-World pipeline by integrating a\nvision-language model (VLM) with a detector. A Multilayer Perceptron (MLP)\nadaptor is developed to transform text embeddings extracted by the VLM into a\njoint space, within which the detector learns the region representations of\nclass-agnostic proposals. Cross-modality features are directly aligned in the\njoint space, avoiding the complex feature interactions and thereby improving\ncomputational efficiency. DOSOD operates like a traditional closed-set detector\nduring the testing phase, effectively bridging the gap between closed-set and\nopen-set detection. Compared to the baseline YOLO-World, the proposed DOSOD\nsignificantly enhances real-time performance while maintaining comparable\naccuracy. The slight DOSOD-S model achieves a Fixed AP of $26.7\\%$, compared to\n$26.2\\%$ for YOLO-World-v1-S and $22.7\\%$ for YOLO-World-v2-S, using similar\nbackbones on the LVIS minival dataset. Meanwhile, the FPS of DOSOD-S is\n$57.1\\%$ higher than YOLO-World-v1-S and $29.6\\%$ higher than YOLO-World-v2-S.\nMeanwhile, we demonstrate that the DOSOD model facilitates the deployment of\nedge devices. The codes and models are publicly available at\nhttps://github.com/D-Robotics-AI-Lab/DOSOD.",
      "tldr_zh": "本研究提出了一种轻量级框架 Decoupled OSOD (DOSOD)，旨在解决 Open-Set Object Detection (OSOD) 在机器人操作中的计算负担和部署复杂问题。该框架基于 YOLO-World 管道，整合 Vision-Language Model (VLM) 和检测器，并使用 Multilayer Perceptron (MLP) 适配器将文本嵌入转化为联合空间，从而实现跨模态特征的解耦对齐，提高计算效率。实验结果显示，DOSOD-S 在 LVIS minival 数据集上达到 Fixed AP 26.7%，与 YOLO-World-v1-S (26.2%) 和 v2-S (22.7%) 相比保持可比准确率，同时 FPS 分别提高了 57.1% 和 29.6%。此外，该框架便于部署到边缘设备，并提供公开代码，支持实时 OSOD 任务。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.14680v2",
      "published_date": "2024-12-19 09:32:53 UTC",
      "updated_date": "2024-12-25 12:22:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:25:19.790891"
    },
    {
      "arxiv_id": "2412.14672v2",
      "title": "FiVL: A Framework for Improved Vision-Language Alignment through the Lens of Training, Evaluation and Explainability",
      "title_zh": "翻译失败",
      "authors": [
        "Estelle Aflalo",
        "Gabriela Ben Melech Stan",
        "Tiep Le",
        "Man Luo",
        "Shachar Rosenman",
        "Sayak Paul",
        "Shao-Yen Tseng",
        "Vasudev Lal"
      ],
      "abstract": "Large Vision Language Models (LVLMs) have achieved significant progress in\nintegrating visual and textual inputs for multimodal reasoning. However, a\nrecurring challenge is ensuring these models utilize visual information as\neffectively as linguistic content when both modalities are necessary to\nformulate an accurate answer. We hypothesize that hallucinations arise due to\nthe lack of effective visual grounding in current LVLMs. Furthermore, current\nvision-language benchmarks are not specifically measuring the degree to which\nthe answer require the visual input. This limitation makes it challenging to\nconfirm that the image is truly necessary, particularly in tasks like visual\nquestion answering. In this work, we introduce FiVL, a novel method for\nconstructing datasets designed to train LVLMs for enhanced visual grounding and\nalso evaluate their effectiveness in achieving it. We demonstrate the value of\nour datasets through three approaches. First, we introduce a novel training\ntask based on our augmented training dataset, resulting in better performance\nthan the baseline. Second, we present benchmarks to assess the model's ability\nto use image as substantive evidence, rather than relying solely on linguistic\npriors. Finally, we identify attention heads with the strongest vision-language\nalignment, enabling explainability on visual-driven hallucinations. The code is\navailable at https://github.com/IntelLabs/fivl.",
      "tldr_zh": "该论文提出 FiVL 框架，以提升大型视觉语言模型 (LVLMs) 在训练、评估和可解释性方面的视觉语言对齐问题，针对模型幻觉问题假设其源于视觉 grounding 的不足。FiVL 通过构建增强数据集引入新训练任务，帮助模型更好地利用视觉信息，并开发基准测试来评估模型是否依赖图像证据而非仅靠语言先验。同时，论文识别关键注意力头以增强模型的可解释性。实验结果显示，使用 FiVL 的模型在性能上优于基线，为减少视觉驱动幻觉提供了有效方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.14672v2",
      "published_date": "2024-12-19 09:24:10 UTC",
      "updated_date": "2025-03-19 12:04:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:25:30.918998"
    },
    {
      "arxiv_id": "2412.14670v1",
      "title": "Analysis and Visualization of Linguistic Structures in Large Language Models: Neural Representations of Verb-Particle Constructions in BERT",
      "title_zh": "大型语言模型中语言结构的分析与可视化：BERT 中动词-粒子结构的神经表示",
      "authors": [
        "Hassane Kissane",
        "Achim Schilling",
        "Patrick Krauss"
      ],
      "abstract": "This study investigates the internal representations of verb-particle\ncombinations within transformer-based large language models (LLMs),\nspecifically examining how these models capture lexical and syntactic nuances\nat different neural network layers. Employing the BERT architecture, we analyse\nthe representational efficacy of its layers for various verb-particle\nconstructions such as 'agree on', 'come back', and 'give up'. Our methodology\nincludes a detailed dataset preparation from the British National Corpus,\nfollowed by extensive model training and output analysis through techniques\nlike multi-dimensional scaling (MDS) and generalized discrimination value (GDV)\ncalculations. Results show that BERT's middle layers most effectively capture\nsyntactic structures, with significant variability in representational accuracy\nacross different verb categories. These findings challenge the conventional\nuniformity assumed in neural network processing of linguistic elements and\nsuggest a complex interplay between network architecture and linguistic\nrepresentation. Our research contributes to a better understanding of how deep\nlearning models comprehend and process language, offering insights into the\npotential and limitations of current neural approaches to linguistic analysis.\nThis study not only advances our knowledge in computational linguistics but\nalso prompts further research into optimizing neural architectures for enhanced\nlinguistic precision.",
      "tldr_zh": "本研究分析了基于 transformer 的大型语言模型（如 BERT）中 verb-particle constructions（如 'agree on'、'come back' 和 'give up'）的神经表示，探讨这些模型在不同层级如何捕捉词汇和句法细微差别。研究方法包括从 British National Corpus 准备数据集、进行模型训练，并运用多维缩放 (MDS) 和广义鉴别值 (GDV) 计算进行输出分析。结果表明，BERT 的中间层最有效地捕捉句法结构，但不同动词类别的表示准确性存在显著差异，挑战了神经网络处理语言元素的统一性假设。该研究为理解深度学习模型的语言处理机制提供了新见解，并为优化神经架构以提升语言精确性指明了方向。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.14670v1",
      "published_date": "2024-12-19 09:21:39 UTC",
      "updated_date": "2024-12-19 09:21:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:25:43.876448"
    },
    {
      "arxiv_id": "2412.14668v2",
      "title": "LoLaFL: Low-Latency Federated Learning via Forward-only Propagation",
      "title_zh": "翻译失败",
      "authors": [
        "Jierui Zhang",
        "Jianhao Huang",
        "Kaibin Huang"
      ],
      "abstract": "Federated learning (FL) has emerged as a widely adopted paradigm for enabling\nedge learning with distributed data while ensuring data privacy. However, the\ntraditional FL with deep neural networks trained via backpropagation can hardly\nmeet the low-latency learning requirements in the sixth generation (6G) mobile\nnetworks. This challenge mainly arises from the high-dimensional model\nparameters to be transmitted and the numerous rounds of communication required\nfor convergence due to the inherent randomness of the training process. To\naddress this issue, we adopt the state-of-the-art principle of maximal coding\nrate reduction to learn linear discriminative features and extend the resultant\nwhite-box neural network into FL, yielding the novel framework of Low-Latency\nFederated Learning (LoLaFL) via forward-only propagation. LoLaFL enables\nlayer-wise transmissions and aggregation with significantly fewer communication\nrounds, thereby considerably reducing latency. Additionally, we propose two\n\\emph{nonlinear} aggregation schemes for LoLaFL. The first scheme is based on\nthe proof that the optimal NN parameter aggregation in LoLaFL should be\nharmonic-mean-like. The second scheme further exploits the low-rank structures\nof the features and transmits the low-rank-approximated covariance matrices of\nfeatures to achieve additional latency reduction. Theoretic analysis and\nexperiments are conducted to evaluate the performance of LoLaFL. In comparison\nwith traditional FL, the two nonlinear aggregation schemes for LoLaFL can\nachieve reductions in latency of over 91\\% and 98\\%, respectively, while\nmaintaining comparable accuracies.",
      "tldr_zh": "该论文提出 LoLaFL，一种通过 forward-only propagation 的低延迟 Federated Learning (FL) 框架，旨在解决传统 FL 在 6G 网络中因高维模型参数传输和通信轮次过多而导致的延迟问题。LoLaFL 采用 maximal coding rate reduction 原则学习线性判别特征，并引入两个非线性聚合方案：一个基于 harmonic-mean-like 的最佳神经网络参数聚合，另一个利用特征的低秩结构传输低秩近似协方差矩阵，以进一步减少通信量。实验结果显示，与传统 FL 相比，LoLaFL 的两个方案分别实现延迟减少超过 91% 和 98%，同时保持可比的准确率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NI"
      ],
      "primary_category": "cs.LG",
      "comment": "14 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.14668v2",
      "published_date": "2024-12-19 09:20:27 UTC",
      "updated_date": "2024-12-20 08:51:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:25:56.073189"
    },
    {
      "arxiv_id": "2412.14663v2",
      "title": "IOHunter: Graph Foundation Model to Uncover Online Information Operations",
      "title_zh": "IOHunter：揭示在线信息行动的图基础模型",
      "authors": [
        "Marco Minici",
        "Luca Luceri",
        "Francesco Fabbri",
        "Emilio Ferrara"
      ],
      "abstract": "Social media platforms have become vital spaces for public discourse, serving\nas modern agor\\`as where a wide range of voices influence societal narratives.\nHowever, their open nature also makes them vulnerable to exploitation by\nmalicious actors, including state-sponsored entities, who can conduct\ninformation operations (IOs) to manipulate public opinion. The spread of\nmisinformation, false news, and misleading claims threatens democratic\nprocesses and societal cohesion, making it crucial to develop methods for the\ntimely detection of inauthentic activity to protect the integrity of online\ndiscourse. In this work, we introduce a methodology designed to identify users\norchestrating information operations, a.k.a. IO drivers, across various\ninfluence campaigns. Our framework, named IOHunter, leverages the combined\nstrengths of Language Models and Graph Neural Networks to improve\ngeneralization in supervised, scarcely-supervised, and cross-IO contexts. Our\napproach achieves state-of-the-art performance across multiple sets of IOs\noriginating from six countries, significantly surpassing existing approaches.\nThis research marks a step toward developing Graph Foundation Models\nspecifically tailored for the task of IO detection on social media platforms.",
      "tldr_zh": "本研究探讨了社交媒体平台上信息操作（IOs）的风险，这些操作由恶意行为者（如国家赞助实体）进行，可能操纵公众舆论并威胁民主进程。为解决这一问题，研究引入了IOHunter框架，该框架结合Language Models和Graph Neural Networks，提高了在监督、稀疏监督和跨IO环境的泛化能力。实验结果显示，IOHunter在多个国家起源的IO数据集上实现了最先进性能，显著超越现有方法，并为Graph Foundation Models在社交媒体IO检测中的应用奠定了基础。",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SI",
      "comment": "Accepted at AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.14663v2",
      "published_date": "2024-12-19 09:14:24 UTC",
      "updated_date": "2025-03-03 15:32:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:26:05.811009"
    },
    {
      "arxiv_id": "2412.14660v2",
      "title": "Unveiling Uncertainty: A Deep Dive into Calibration and Performance of Multimodal Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zijun Chen",
        "Wenbo Hu",
        "Guande He",
        "Zhijie Deng",
        "Zheng Zhang",
        "Richang Hong"
      ],
      "abstract": "Multimodal large language models (MLLMs) combine visual and textual data for\ntasks such as image captioning and visual question answering. Proper\nuncertainty calibration is crucial, yet challenging, for reliable use in areas\nlike healthcare and autonomous driving. This paper investigates representative\nMLLMs, focusing on their calibration across various scenarios, including before\nand after visual fine-tuning, as well as before and after multimodal training\nof the base LLMs. We observed miscalibration in their performance, and at the\nsame time, no significant differences in calibration across these scenarios. We\nalso highlight how uncertainty differs between text and images and how their\nintegration affects overall uncertainty. To better understand MLLMs'\nmiscalibration and their ability to self-assess uncertainty, we construct the\nIDK (I don't know) dataset, which is key to evaluating how they handle\nunknowns. Our findings reveal that MLLMs tend to give answers rather than admit\nuncertainty, but this self-assessment improves with proper prompt adjustments.\nFinally, to calibrate MLLMs and enhance model reliability, we propose\ntechniques such as temperature scaling and iterative prompt optimization. Our\nresults provide insights into improving MLLMs for effective and responsible\ndeployment in multimodal applications. Code and IDK dataset:\nhttps://github.com/hfutml/Calibration-MLLM.",
      "tldr_zh": "这篇论文探讨了多模态大语言模型 (MLLMs) 的不确定性校准问题，调查了其在视觉微调前后以及多模态训练前后的表现，发现模型存在误校准，但不同场景间差异不大。研究者构建了 IDK 数据集，用于评估 MLLMs 处理未知情况的能力，结果显示这些模型倾向于给出答案而非承认不确定性，但通过适当的提示调整可改善自评估。作者提出温度缩放 (temperature scaling) 和迭代提示优化 (iterative prompt optimization) 等技术，以提升 MLLMs 的可靠性和在医疗、自动驾驶等领域的负责任部署。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to COLING 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.14660v2",
      "published_date": "2024-12-19 09:10:07 UTC",
      "updated_date": "2024-12-25 06:05:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:26:20.607046"
    },
    {
      "arxiv_id": "2412.14640v2",
      "title": "Adaptive Prompt Tuning: Vision Guided Prompt Tuning with Cross-Attention for Fine-Grained Few-Shot Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Eric Brouwer",
        "Jan Erik van Woerden",
        "Gertjan Burghouts",
        "Matias Valdenegro-Toro",
        "Marco Zullich"
      ],
      "abstract": "Few-shot, fine-grained classification in computer vision poses significant\nchallenges due to the need to differentiate subtle class distinctions with\nlimited data. This paper presents a novel method that enhances the Contrastive\nLanguage-Image Pre-Training (CLIP) model through adaptive prompt tuning, guided\nby real-time visual inputs. Unlike existing techniques such as Context\nOptimization (CoOp) and Visual Prompt Tuning (VPT), which are constrained by\nstatic prompts or visual token reliance, the proposed approach leverages a\ncross-attention mechanism to dynamically refine text prompts for the image at\nhand. This enables an image-specific alignment of textual features with image\npatches extracted from the Vision Transformer, making the model more effective\nfor datasets with high intra-class variance and low inter-class differences.\nThe method is evaluated on several datasets, including CUBirds, Oxford Flowers,\nand FGVC Aircraft, showing significant performance gains over static prompt\ntuning approaches. To ensure these performance gains translate into trustworthy\npredictions, we integrate Monte-Carlo Dropout in our approach to improve the\nreliability of the model predictions and uncertainty estimates. This\nintegration provides valuable insights into the model's predictive confidence,\nhelping to identify when predictions can be trusted and when additional\nverification is necessary. This dynamic approach offers a robust solution,\nadvancing the state-of-the-art for few-shot fine-grained classification.",
      "tldr_zh": "本研究针对少样本细粒度分类(Few-Shot Learning)的挑战，提出了一种自适应提示调整(Adaptive Prompt Tuning)方法，通过交叉注意力(Cross-Attention)机制利用实时视觉输入动态优化文本提示，以增强 Contrastive Language-Image Pre-Training (CLIP) 模型的表现。不同于静态方法的 CoOp 和 Visual Prompt Tuning (VPT)，该方法实现图像特定文本特征与 Vision Transformer 提取的图像补丁对齐，从而更好地处理高内部变异和低外部差异的数据集。在 CUBirds、Oxford Flowers 和 FGVC Aircraft 等数据集上，该方法显著优于静态提示方法，并通过整合 Monte-Carlo Dropout 提升预测可靠性和不确定性估计，推动了少样本细粒度分类的最新进展。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.14640v2",
      "published_date": "2024-12-19 08:51:01 UTC",
      "updated_date": "2025-01-01 18:00:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:26:30.916632"
    },
    {
      "arxiv_id": "2412.14639v2",
      "title": "A Shapley Value Estimation Speedup for Efficient Explainable Quantum AI",
      "title_zh": "翻译失败",
      "authors": [
        "Iain Burge",
        "Michel Barbeau",
        "Joaquin Garcia-Alfaro"
      ],
      "abstract": "This work focuses on developing efficient post-hoc explanations for quantum\nAI algorithms. In classical contexts, the cooperative game theory concept of\nthe Shapley value adapts naturally to post-hoc explanations, where it can be\nused to identify which factors are important in an AI's decision-making\nprocess. An interesting question is how to translate Shapley values to the\nquantum setting and whether quantum effects could be used to accelerate their\ncalculation. We propose quantum algorithms that can extract Shapley values\nwithin some confidence interval. Our method is capable of quadratically\noutperforming classical Monte Carlo approaches to approximating Shapley values\nup to polylogarithmic factors in various circumstances. We demonstrate the\nvalidity of our approach empirically with specific voting games and provide\nrigorous proofs of performance for general cooperative games.",
      "tldr_zh": "该研究针对量子AI算法开发高效的后验解释方法，通过将合作博弈理论中的Shapley value 应用于量子设置，利用量子效应加速计算。作者提出了一种量子算法，能够在特定置信区间内估算Shapley value，并在多项式对数因子内实现比经典Monte Carlo方法二次加速。实验通过特定投票游戏验证了方法的有效性，并为一般cooperative games提供了严格的性能证明，从而提升了量子AI的可解释性。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "quant-ph",
      "comment": "34 pages, 4 figures, 4 tables, 45 citations",
      "pdf_url": "http://arxiv.org/pdf/2412.14639v2",
      "published_date": "2024-12-19 08:50:46 UTC",
      "updated_date": "2025-04-17 07:00:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:26:41.924465"
    },
    {
      "arxiv_id": "2412.14633v1",
      "title": "Progressive Fine-to-Coarse Reconstruction for Accurate Low-Bit Post-Training Quantization in Vision Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Rui Ding",
        "Liang Yong",
        "Sihuan Zhao",
        "Jing Nie",
        "Lihui Chen",
        "Haijun Liu",
        "Xichuan Zhou"
      ],
      "abstract": "Due to its efficiency, Post-Training Quantization (PTQ) has been widely\nadopted for compressing Vision Transformers (ViTs). However, when quantized\ninto low-bit representations, there is often a significant performance drop\ncompared to their full-precision counterparts. To address this issue,\nreconstruction methods have been incorporated into the PTQ framework to improve\nperformance in low-bit quantization settings. Nevertheless, existing related\nmethods predefine the reconstruction granularity and seldom explore the\nprogressive relationships between different reconstruction granularities, which\nleads to sub-optimal quantization results in ViTs. To this end, in this paper,\nwe propose a Progressive Fine-to-Coarse Reconstruction (PFCR) method for\naccurate PTQ, which significantly improves the performance of low-bit quantized\nvision transformers. Specifically, we define multi-head self-attention and\nmulti-layer perceptron modules along with their shortcuts as the finest\nreconstruction units. After reconstructing these two fine-grained units, we\ncombine them to form coarser blocks and reconstruct them at a coarser\ngranularity level. We iteratively perform this combination and reconstruction\nprocess, achieving progressive fine-to-coarse reconstruction. Additionally, we\nintroduce a Progressive Optimization Strategy (POS) for PFCR to alleviate the\ndifficulty of training, thereby further enhancing model performance.\nExperimental results on the ImageNet dataset demonstrate that our proposed\nmethod achieves the best Top-1 accuracy among state-of-the-art methods,\nparticularly attaining 75.61% for 3-bit quantized ViT-B in PTQ. Besides,\nquantization results on the COCO dataset reveal the effectiveness and\ngeneralization of our proposed method on other computer vision tasks like\nobject detection and instance segmentation.",
      "tldr_zh": "本研究针对视觉变压器 (Vision Transformers, ViTs) 在低位后训练量化 (Post-Training Quantization, PTQ) 中的性能下降问题，提出了一种渐进式细到粗重建方法 (Progressive Fine-to-Coarse Reconstruction, PFCR)，以提升量化准确性。PFCR 将多头自注意力 (multi-head self-attention) 和多层感知器 (multi-layer perceptron) 模块及其快捷方式定义为最细重建单位，通过迭代组合和重建过程，实现从细粒度到粗粒度的渐进优化，同时引入渐进式优化策略 (Progressive Optimization Strategy, POS) 来缓解训练难度，进一步提高模型性能。在 ImageNet 数据集上，实验结果显示 PFCR 在 3-bit 量化 ViT-B 上达到 75.61% Top-1 准确率，优于现有方法，并在 COCO 数据集上的对象检测和实例分割任务中证明了其有效性和泛化性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.14633v1",
      "published_date": "2024-12-19 08:38:59 UTC",
      "updated_date": "2024-12-19 08:38:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:26:55.998926"
    },
    {
      "arxiv_id": "2412.14626v1",
      "title": "Learning to Generate Research Idea with Dynamic Control",
      "title_zh": "翻译失败",
      "authors": [
        "Ruochen Li",
        "Liqiang Jing",
        "Chi Han",
        "Jiawei Zhou",
        "Xinya Du"
      ],
      "abstract": "The rapid advancements in large language models (LLMs) have demonstrated\ntheir potential to accelerate scientific discovery, particularly in automating\nthe process of research ideation. LLM-based systems have shown promise in\ngenerating hypotheses and research ideas. However, current approaches\npredominantly rely on prompting-based pre-trained models, limiting their\nability to optimize generated content effectively. Moreover, they also lack the\ncapability to deal with the complex interdependence and inherent restrictions\namong novelty, feasibility, and effectiveness, which remains challenging due to\nthe inherent trade-offs among these dimensions, such as the\ninnovation-feasibility conflict. To address these limitations, we for the first\ntime propose fine-tuning LLMs to be better idea proposers and introduce a novel\nframework that employs a two-stage approach combining Supervised Fine-Tuning\n(SFT) and controllable Reinforcement Learning (RL). In the SFT stage, the model\nlearns foundational patterns from pairs of research papers and follow-up ideas.\nIn the RL stage, multi-dimensional reward modeling, guided by fine-grained\nfeedback, evaluates and optimizes the generated ideas across key metrics.\nDimensional controllers enable dynamic adjustment of generation, while a\nsentence-level decoder ensures context-aware emphasis during inference. Our\nframework provides a balanced approach to research ideation, achieving\nhigh-quality outcomes by dynamically navigating the trade-offs among novelty,\nfeasibility, and effectiveness.",
      "tldr_zh": "这篇论文提出了一种微调大型语言模型（LLMs）的新框架，用于生成研究想法，首次解决新颖性、可行性和有效性之间的复杂权衡问题，如创新与可行性的冲突。框架采用两阶段方法：首先通过Supervised Fine-Tuning (SFT)从研究论文和后续想法的配对中学习基础模式；其次，通过可控的Reinforcement Learning (RL)结合多维度奖励模型和细粒度反馈来优化生成的想法。维度控制器和句子级解码器实现了动态调整和上下文感知的生成，最终提供平衡的高质量研究想法输出。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.14626v1",
      "published_date": "2024-12-19 08:28:18 UTC",
      "updated_date": "2024-12-19 08:28:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:29:07.742226"
    },
    {
      "arxiv_id": "2412.14619v1",
      "title": "Pitfalls of topology-aware image segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Alexander H. Berger",
        "Laurin Lux",
        "Alexander Weers",
        "Martin Menten",
        "Daniel Rueckert",
        "Johannes C. Paetzold"
      ],
      "abstract": "Topological correctness, i.e., the preservation of structural integrity and\nspecific characteristics of shape, is a fundamental requirement for medical\nimaging tasks, such as neuron or vessel segmentation. Despite the recent surge\nin topology-aware methods addressing this challenge, their real-world\napplicability is hindered by flawed benchmarking practices. In this paper, we\nidentify critical pitfalls in model evaluation that include inadequate\nconnectivity choices, overlooked topological artifacts in ground truth\nannotations, and inappropriate use of evaluation metrics. Through detailed\nempirical analysis, we uncover these issues' profound impact on the evaluation\nand ranking of segmentation methods. Drawing from our findings, we propose a\nset of actionable recommendations to establish fair and robust evaluation\nstandards for topology-aware medical image segmentation methods.",
      "tldr_zh": "该论文强调了拓扑正确性（topological correctness）在医疗图像分割任务（如神经元或血管分割）中的重要性，但指出现有拓扑感知（topology-aware）方法因评估缺陷而难以实际应用。研究通过实证分析识别出关键问题，包括不适当的连接选择（inadequate connectivity choices）、忽略地面实况标注中的拓扑伪像（overlooked topological artifacts in ground truth annotations），以及不当使用评估指标（inappropriate use of evaluation metrics），这些问题严重影响了方法的评估和排名。作者基于这些发现，提出了一系列可操作的推荐，以建立公平且稳健的评估标准，从而提升拓扑感知医疗图像分割方法的可靠性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Code is available at\n  https://github.com/AlexanderHBerger/topo-pitfalls",
      "pdf_url": "http://arxiv.org/pdf/2412.14619v1",
      "published_date": "2024-12-19 08:11:42 UTC",
      "updated_date": "2024-12-19 08:11:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:27:18.842946"
    },
    {
      "arxiv_id": "2412.14617v1",
      "title": "How good is GPT at writing political speeches for the White House?",
      "title_zh": "翻译失败",
      "authors": [
        "Jacques Savoy"
      ],
      "abstract": "Using large language models (LLMs), computers are able to generate a written\ntext in response to a us er request. As this pervasive technology can be\napplied in numerous contexts, this study analyses the written style of one LLM\ncalled GPT by comparing its generated speeches with those of the recent US\npresidents. To achieve this objective, the State of the Union (SOTU) addresses\nwritten by Reagan to Biden are contrasted to those produced by both GPT-3.5 and\nGPT-4.o versions. Compared to US presidents, GPT tends to overuse the lemma\n\"we\" and produce shorter messages with, on average, longer sentences. Moreover,\nGPT opts for an optimistic tone, opting more often for political (e.g.,\npresident, Congress), symbolic (e.g., freedom), and abstract terms (e.g.,\nfreedom). Even when imposing an author's style to GPT, the resulting speech\nremains distinct from addresses written by the target author. Finally, the two\nGPT versions present distinct characteristics, but both appear overall\ndissimilar to true presidential messages.",
      "tldr_zh": "这篇论文评估了GPT在生成白宫政治演讲方面的表现，通过比较GPT-3.5和GPT-4生成的演讲与美国总统从里根到拜登的国情咨文（SOTU）。研究发现，GPT倾向于过度使用\"we\"，产生更短的消息但平均句子更长，并偏好乐观语气，使用更多政治术语（如president, Congress）、象征性术语（如freedom）和抽象术语。即便强迫GPT模仿特定作者的风格，其生成的演讲仍与目标作者的真实演讲存在显著差异，且GPT-3.5和GPT-4虽然各有特色，但整体上均与总统演讲不相似。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.14617v1",
      "published_date": "2024-12-19 08:06:09 UTC",
      "updated_date": "2024-12-19 08:06:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:27:32.771131"
    },
    {
      "arxiv_id": "2412.14613v2",
      "title": "Multi-modal, Multi-task, Multi-criteria Automatic Evaluation with Vision Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Masanari Ohi",
        "Masahiro Kaneko",
        "Naoaki Okazaki",
        "Nakamasa Inoue"
      ],
      "abstract": "Vision-language models (VLMs) have shown impressive abilities across a range\nof multi-modal tasks. However, existing metrics for evaluating the quality of\ntext generated by VLMs typically focus on an overall evaluation for a specific\ntask, such as image captioning. While the overall evaluation is essential for\nany task, the criteria prioritized can differ depending on the task, making it\nchallenging for current metrics to adapt to multi-task scenarios. To address\nthis limitation, we propose HarmonicEval, a reference-free comprehensive\nevaluation metric that aggregates criterion-wise scores to produce the overall\nscore in a bottom-up manner. Furthermore, we construct the Multi-task\nMulti-criteria Human Evaluation (MMHE) dataset, which comprises 18,000 expert\nhuman judgments across four multi-modal tasks. Our experiments demonstrate that\nHarmonicEval achieves higher correlations with human judgments than\nconventional metrics while providing numerical scores for each criterion.",
      "tldr_zh": "视觉语言模型（VLMs）在多模态任务中表现出色，但现有评估指标通常仅针对特定任务的整体评估，无法适应多任务、多准则场景。为解决此问题，本文提出HarmonicEval，一种无参考的综合评估指标，它通过聚合每个准则的分数从下往上生成整体分数，并构建了Multi-task Multi-criteria Human Evaluation (MMHE)数据集，包含18,000条专家人类判断，覆盖四个多模态任务。实验表明，HarmonicEval与人类判断的相关性高于传统指标，同时为每个准则提供详细的数值分数。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.14613v2",
      "published_date": "2024-12-19 08:03:16 UTC",
      "updated_date": "2025-02-28 03:04:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:27:43.431710"
    },
    {
      "arxiv_id": "2412.14602v2",
      "title": "Towards Scalable and Deep Graph Neural Networks via Noise Masking",
      "title_zh": "翻译失败",
      "authors": [
        "Yuxuan Liang",
        "Wentao Zhang",
        "Zeang Sheng",
        "Ling Yang",
        "Quanqing Xu",
        "Jiawei Jiang",
        "Yunhai Tong",
        "Bin Cui"
      ],
      "abstract": "In recent years, Graph Neural Networks (GNNs) have achieved remarkable\nsuccess in many graph mining tasks. However, scaling them to large graphs is\nchallenging due to the high computational and storage costs of repeated feature\npropagation and non-linear transformation during training. One commonly\nemployed approach to address this challenge is model-simplification, which only\nexecutes the Propagation (P) once in the pre-processing, and Combine (C) these\nreceptive fields in different ways and then feed them into a simple model for\nbetter performance. Despite their high predictive performance and scalability,\nthese methods still face two limitations. First, existing approaches mainly\nfocus on exploring different C methods from the model perspective, neglecting\nthe crucial problem of performance degradation with increasing P depth from the\ndata-centric perspective, known as the over-smoothing problem. Second,\npre-processing overhead takes up most of the end-to-end processing time,\nespecially for large-scale graphs. To address these limitations, we present\nrandom walk with noise masking (RMask), a plug-and-play module compatible with\nthe existing model-simplification works. This module enables the exploration of\ndeeper GNNs while preserving their scalability. Unlike the previous\nmodel-simplification works, we focus on continuous P and found that the noise\nexisting inside each P is the cause of the over-smoothing issue, and use the\nefficient masking mechanism to eliminate them. Experimental results on six\nreal-world datasets demonstrate that model-simplification works equipped with\nRMask yield superior performance compared to their original version and can\nmake a good trade-off between accuracy and efficiency.",
      "tldr_zh": "该研究针对图神经网络(GNNs)扩展到大规模图时的计算和存储成本问题，提出了一种模型简化方法改进策略，即随机游走噪声掩码(RMask)模块。该模块通过在传播(Propagation, P)过程中消除噪声来解决over-smoothing问题，从而支持更深层的GNNs，同时保持高可扩展性。与现有方法相比，RMask关注数据视角的性能下降问题，并减少预处理开销。实验在六个真实数据集上显示，配备RMask的模型简化方法比原版提升了性能，并在准确性和效率之间实现了良好平衡。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.14602v2",
      "published_date": "2024-12-19 07:48:14 UTC",
      "updated_date": "2025-04-10 02:16:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:27:55.434081"
    },
    {
      "arxiv_id": "2412.15294v1",
      "title": "A Universal Model for Human Mobility Prediction",
      "title_zh": "一种用于人类移动性预测的通用模型",
      "authors": [
        "Qingyue Long",
        "Yuan Yuan",
        "Yong Li"
      ],
      "abstract": "Predicting human mobility is crucial for urban planning, traffic control, and\nemergency response. Mobility behaviors can be categorized into individual and\ncollective, and these behaviors are recorded by diverse mobility data, such as\nindividual trajectory and crowd flow. As different modalities of mobility data,\nindividual trajectory and crowd flow have a close coupling relationship. Crowd\nflows originate from the bottom-up aggregation of individual trajectories,\nwhile the constraints imposed by crowd flows shape these individual\ntrajectories. Existing mobility prediction methods are limited to single tasks\ndue to modal gaps between individual trajectory and crowd flow. In this work,\nwe aim to unify mobility prediction to break through the limitations of\ntask-specific models. We propose a universal human mobility prediction model\n(named UniMob), which can be applied to both individual trajectory and crowd\nflow. UniMob leverages a multi-view mobility tokenizer that transforms both\ntrajectory and flow data into spatiotemporal tokens, facilitating unified\nsequential modeling through a diffusion transformer architecture. To bridge the\ngap between the different characteristics of these two data modalities, we\nimplement a novel bidirectional individual and collective alignment mechanism.\nThis mechanism enables learning common spatiotemporal patterns from different\nmobility data, facilitating mutual enhancement of both trajectory and flow\npredictions. Extensive experiments on real-world datasets validate the\nsuperiority of our model over state-of-the-art baselines in trajectory and flow\nprediction. Especially in noisy and scarce data scenarios, our model achieves\nthe highest performance improvement of more than 14% and 25% in MAPE and\nAccuracy@5.",
      "tldr_zh": "该论文提出一个通用人类流动性预测模型UniMob，用于统一处理个体轨迹和人群流动数据，解决现有方法受限于单一任务的局限性。UniMob采用multi-view mobility tokenizer将不同数据模态转化为时空标记，并通过diffusion transformer architecture进行统一顺序建模，同时引入bidirectional individual and collective alignment mechanism来学习共同时空模式，促进预测的相互增强。实验在真实数据集上显示，该模型优于现有基线，尤其在噪声和稀缺数据场景中，MAPE改善超过14%，Accuracy@5改善超过25%。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.15294v1",
      "published_date": "2024-12-19 07:38:13 UTC",
      "updated_date": "2024-12-19 07:38:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:28:08.701457"
    },
    {
      "arxiv_id": "2412.15292v1",
      "title": "Deep reinforcement learning with time-scale invariant memory",
      "title_zh": "翻译失败",
      "authors": [
        "Md Rysul Kabir",
        "James Mochizuki-Freeman",
        "Zoran Tiganj"
      ],
      "abstract": "The ability to estimate temporal relationships is critical for both animals\nand artificial agents. Cognitive science and neuroscience provide remarkable\ninsights into behavioral and neural aspects of temporal credit assignment. In\nparticular, scale invariance of learning dynamics, observed in behavior and\nsupported by neural data, is one of the key principles that governs animal\nperception: proportional rescaling of temporal relationships does not alter the\noverall learning efficiency. Here we integrate a computational neuroscience\nmodel of scale invariant memory into deep reinforcement learning (RL) agents.\nWe first provide a theoretical analysis and then demonstrate through\nexperiments that such agents can learn robustly across a wide range of temporal\nscales, unlike agents built with commonly used recurrent memory architectures\nsuch as LSTM. This result illustrates that incorporating computational\nprinciples from neuroscience and cognitive science into deep neural networks\ncan enhance adaptability to complex temporal dynamics, mirroring some of the\ncore properties of human learning.",
      "tldr_zh": "这篇论文提出了一种整合计算神经科学模型的深度强化学习（Deep reinforcement learning）代理，具备时间尺度不变记忆，以提升对时间关系的处理能力。研究通过理论分析和实验验证，证明这种代理能够在广泛的时间尺度上实现鲁棒学习，而传统循环记忆架构如 LSTM 则无法达到类似效果。该方法展示了将神经科学和认知科学原理融入深度神经网络的优势，有助于人工智能更好地适应复杂时间动态，类似于人类学习的特性。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.15292v1",
      "published_date": "2024-12-19 07:20:03 UTC",
      "updated_date": "2024-12-19 07:20:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:28:19.671715"
    },
    {
      "arxiv_id": "2412.14587v1",
      "title": "Spike2Former: Efficient Spiking Transformer for High-performance Image Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Zhenxin Lei",
        "Man Yao",
        "Jiakui Hu",
        "Xinhao Luo",
        "Yanye Lu",
        "Bo Xu",
        "Guoqi Li"
      ],
      "abstract": "Spiking Neural Networks (SNNs) have a low-power advantage but perform poorly\nin image segmentation tasks. The reason is that directly converting neural\nnetworks with complex architectural designs for segmentation tasks into spiking\nversions leads to performance degradation and non-convergence. To address this\nchallenge, we first identify the modules in the architecture design that lead\nto the severe reduction in spike firing, make targeted improvements, and\npropose Spike2Former architecture. Second, we propose normalized integer\nspiking neurons to solve the training stability problem of SNNs with complex\narchitectures. We set a new state-of-the-art for SNNs in various semantic\nsegmentation datasets, with a significant improvement of +12.7% mIoU and 5.0\nefficiency on ADE20K, +14.3% mIoU and 5.2 efficiency on VOC2012, and +9.1% mIoU\nand 6.6 efficiency on CityScapes.",
      "tldr_zh": "本研究针对 Spiking Neural Networks (SNNs) 在图像分割任务中的性能下降和不收敛问题，提出了一种高效的 Spike2Former 架构，通过识别并改进导致 spike firing 减少的关键模块来优化设计。论文还引入 normalized integer spiking neurons，以解决复杂架构 SNNs 的训练稳定性问题。实验结果显示，Spike2Former 在 ADE20K 上提升 +12.7% mIoU 和 5.0 效率，在 VOC2012 上提升 +14.3% mIoU 和 5.2 效率，在 CityScapes 上提升 +9.1% mIoU 和 6.6 效率，设定了 SNNs 在语义分割数据集上的新 State-of-the-Art。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.CV",
      "comment": "This work has been accepted on Association for the Advancement of\n  Artificial Intelligence 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.14587v1",
      "published_date": "2024-12-19 07:13:15 UTC",
      "updated_date": "2024-12-19 07:13:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:28:31.792888"
    },
    {
      "arxiv_id": "2412.14579v1",
      "title": "GSRender: Deduplicated Occupancy Prediction via Weakly Supervised 3D Gaussian Splatting",
      "title_zh": "GS",
      "authors": [
        "Qianpu Sun",
        "Changyong Shu",
        "Sifan Zhou",
        "Zichen Yu",
        "Yan Chen",
        "Dawei Yang",
        "Yuan Chun"
      ],
      "abstract": "3D occupancy perception is gaining increasing attention due to its capability\nto offer detailed and precise environment representations. Previous\nweakly-supervised NeRF methods balance efficiency and accuracy, with mIoU\nvarying by 5-10 points due to sampling count along camera rays. Recently,\nreal-time Gaussian splatting has gained widespread popularity in 3D\nreconstruction, and the occupancy prediction task can also be viewed as a\nreconstruction task. Consequently, we propose GSRender, which naturally employs\n3D Gaussian Splatting for occupancy prediction, simplifying the sampling\nprocess. In addition, the limitations of 2D supervision result in duplicate\npredictions along the same camera ray. We implemented the Ray Compensation (RC)\nmodule, which mitigates this issue by compensating for features from adjacent\nframes. Finally, we redesigned the loss to eliminate the impact of dynamic\nobjects from adjacent frames. Extensive experiments demonstrate that our\napproach achieves SOTA (state-of-the-art) results in RayIoU (+6.0), while\nnarrowing the gap with 3D supervision methods. Our code will be released soon.",
      "tldr_zh": "本研究提出GSRender，一种基于弱监督的3D Gaussian Splatting方法，用于实现去重化的3D occupancy prediction，从而提供更高效且精确的环境表示。该框架简化了沿相机射线的采样过程，并引入Ray Compensation (RC)模块，通过补偿相邻帧的特征来缓解重复预测问题，同时重新设计损失函数以消除动态对象的影响。实验结果显示，GSRender在RayIoU上达到SOTA (state-of-the-art)水平，提升6.0点，并显著缩小与3D监督方法的差距。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.14579v1",
      "published_date": "2024-12-19 06:57:37 UTC",
      "updated_date": "2024-12-19 06:57:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:28:43.501810"
    },
    {
      "arxiv_id": "2412.14571v1",
      "title": "SCKD: Semi-Supervised Cross-Modality Knowledge Distillation for 4D Radar Object Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Ruoyu Xu",
        "Zhiyu Xiang",
        "Chenwei Zhang",
        "Hanzhi Zhong",
        "Xijun Zhao",
        "Ruina Dang",
        "Peng Xu",
        "Tianyu Pu",
        "Eryun Liu"
      ],
      "abstract": "3D object detection is one of the fundamental perception tasks for autonomous\nvehicles. Fulfilling such a task with a 4D millimeter-wave radar is very\nattractive since the sensor is able to acquire 3D point clouds similar to Lidar\nwhile maintaining robust measurements under adverse weather. However, due to\nthe high sparsity and noise associated with the radar point clouds, the\nperformance of the existing methods is still much lower than expected. In this\npaper, we propose a novel Semi-supervised Cross-modality Knowledge Distillation\n(SCKD) method for 4D radar-based 3D object detection. It characterizes the\ncapability of learning the feature from a Lidar-radar-fused teacher network\nwith semi-supervised distillation. We first propose an adaptive fusion module\nin the teacher network to boost its performance. Then, two feature distillation\nmodules are designed to facilitate the cross-modality knowledge transfer.\nFinally, a semi-supervised output distillation is proposed to increase the\neffectiveness and flexibility of the distillation framework. With the same\nnetwork structure, our radar-only student trained by SCKD boosts the mAP by\n10.38% over the baseline and outperforms the state-of-the-art works on the VoD\ndataset. The experiment on ZJUODset also shows 5.12% mAP improvements on the\nmoderate difficulty level over the baseline when extra unlabeled data are\navailable. Code is available at https://github.com/Ruoyu-Xu/SCKD.",
      "tldr_zh": "这篇论文提出了一种名为 SCKD 的半监督跨模态知识蒸馏方法，用于 4D Radar 的 3D 对象检测，以解决雷达点云稀疏和噪声问题。SCKD 通过一个自适应融合模块增强 Lidar-radar-fused 教师网络的性能，并设计了两个特征蒸馏模块和一个半监督输出蒸馏模块，促进跨模态知识转移。实验结果显示，该方法使雷达-only 学生网络在 VoD 数据集上 mAP 提高了 10.38%，并在 ZJUODset 上实现了 5.12% 的提升，证明了其在自动驾驶感知任务中的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.14571v1",
      "published_date": "2024-12-19 06:42:25 UTC",
      "updated_date": "2024-12-19 06:42:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:30:36.829243"
    },
    {
      "arxiv_id": "2412.14570v2",
      "title": "Characterising Simulation-Based Program Equilibria",
      "title_zh": "基于模拟的程序",
      "authors": [
        "Emery Cooper",
        "Caspar Oesterheld",
        "Vincent Conitzer"
      ],
      "abstract": "In Tennenholtz's program equilibrium, players of a game submit programs to\nplay on their behalf. Each program receives the other programs' source code and\noutputs an action. This can model interactions involving AI agents, mutually\ntransparent institutions, or commitments. Tennenholtz (2004) proves a folk\ntheorem for program games, but the equilibria constructed are very brittle. We\ntherefore consider simulation-based programs -- i.e., programs that work by\nrunning opponents' programs. These are relatively robust (in particular, two\nprograms that act the same are treated the same) and are more practical than\nproof-based approaches. Oesterheld's (2019) $\\epsilon$Grounded$\\pi$Bot is such\nan approach. Unfortunately, it is not generally applicable to games of three or\nmore players, and only allows for a limited range of equilibria in two player\ngames. In this paper, we propose a generalisation to Oesterheld's (2019)\n$\\epsilon$Grounded$\\pi$Bot. We prove a folk theorem for our programs in a\nsetting with access to a shared source of randomness. We then characterise\ntheir equilibria in a setting without shared randomness. Both with and without\nshared randomness, we achieve a much wider range of equilibria than\nOesterheld's (2019) $\\epsilon$Grounded$\\pi$Bot. Finally, we explore the limits\nof simulation-based program equilibrium, showing that the Tennenholtz folk\ntheorem cannot be attained by simulation-based programs without access to\nshared randomness.",
      "tldr_zh": "本研究探讨了基于模拟的程序均衡（simulation-based program equilibria），旨在解决 Tennenholtz 的程序均衡（program equilibrium）中均衡脆弱的问题。该方法通过模拟对手程序来构建更稳健的程序框架，并对 Oesterheld 的 εGroundedπBot 进行泛化，证明了在有共享随机源（shared randomness）情况下的一个 folk theorem，并在无共享随机源场景下表征了更广泛的均衡。实验结果显示，这种泛化方法在两人和多人游戏中实现了比原有方法更丰富的均衡策略；然而，在无共享随机源时，无法达到 Tennenholtz folk theorem 的完整效果，为 AI 代理互动提供了更实用且鲁棒的理论基础。",
      "categories": [
        "cs.GT",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.GT",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.14570v2",
      "published_date": "2024-12-19 06:41:06 UTC",
      "updated_date": "2025-01-20 23:37:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:30:48.702860"
    },
    {
      "arxiv_id": "2412.14569v1",
      "title": "Global Spatio-Temporal Fusion-based Traffic Prediction Algorithm with Anomaly Aware",
      "title_zh": "翻译失败",
      "authors": [
        "Chaoqun Liu",
        "Xuanpeng Li",
        "Chen Gong",
        "Guangyu Li"
      ],
      "abstract": "Traffic prediction is an indispensable component of urban planning and\ntraffic management. Achieving accurate traffic prediction hinges on the ability\nto capture the potential spatio-temporal relationships among road sensors.\nHowever, the majority of existing works focus on local short-term\nspatio-temporal correlations, failing to fully consider the interactions of\ndifferent sensors in the long-term state. In addition, these works do not\nanalyze the influences of anomalous factors, or have insufficient ability to\nextract personalized features of anomalous factors, which make them\nineffectively capture their spatio-temporal influences on traffic prediction.\nTo address the aforementioned issues, We propose a global spatio-temporal\nfusion-based traffic prediction algorithm that incorporates anomaly awareness.\nInitially, based on the designed anomaly detection network, we construct an\nefficient anomalous factors impacting module (AFIM), to evaluate the\nspatio-temporal impact of unexpected external events on traffic prediction.\nFurthermore, we propose a multi-scale spatio-temporal feature fusion module\n(MTSFFL) based on the transformer architecture, to obtain all possible both\nlong and short term correlations among different sensors in a wide-area traffic\nenvironment for accurate prediction of traffic flow. Finally, experiments are\nimplemented based on real-scenario public transportation datasets (PEMS04 and\nPEMS08) to demonstrate that our approach can achieve state-of-the-art\nperformance.",
      "tldr_zh": "该论文针对交通预测中现有方法忽略全局长期时空相关性和异常因素影响的问题，提出了一种全局时空融合算法，该算法集成了异常感知机制。论文设计了异常因素影响模块（AFIM），基于异常检测网络评估外部事件对交通预测的时空影响；同时，引入多尺度时空特征融合模块（MTSFFL），利用Transformer架构捕获不同传感器间的长期和短期相关性。在真实数据集（PEMS04和PEMS08）上的实验显示，该方法实现了最先进的预测性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.14569v1",
      "published_date": "2024-12-19 06:40:21 UTC",
      "updated_date": "2024-12-19 06:40:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:31:00.952958"
    },
    {
      "arxiv_id": "2412.14566v3",
      "title": "AIArena: A Blockchain-Based Decentralized AI Training Platform",
      "title_zh": "AIArena：基于区块链的去中心化 AI 训练平台",
      "authors": [
        "Zhipeng Wang",
        "Rui Sun",
        "Elizabeth Lui",
        "Tuo Zhou",
        "Yizhe Wen",
        "Jiahao Sun"
      ],
      "abstract": "The rapid advancement of AI has underscored critical challenges in its\ndevelopment and implementation, largely due to centralized control by a few\nmajor corporations. This concentration of power intensifies biases within AI\nmodels, resulting from inadequate governance and oversight mechanisms.\nAdditionally, it limits public involvement and heightens concerns about the\nintegrity of model generation. Such monopolistic control over data and AI\noutputs threatens both innovation and fair data usage, as users inadvertently\ncontribute data that primarily benefits these corporations. In this work, we\npropose AIArena, a blockchain-based decentralized AI training platform designed\nto democratize AI development and alignment through on-chain incentive\nmechanisms. AIArena fosters an open and collaborative environment where\nparticipants can contribute models and computing resources. Its on-chain\nconsensus mechanism ensures fair rewards for participants based on their\ncontributions. We instantiate and implement AIArena on the public Base\nblockchain Sepolia testnet, and the evaluation results demonstrate the\nfeasibility of AIArena in real-world applications.",
      "tldr_zh": "AI 的快速发展面临集中化控制的挑战，导致模型偏见加剧、治理不足和创新受限，因此本文提出 AIArena，一种基于 blockchain 的去中心化 AI 训练平台。AIArena 通过链上激励机制和共识系统，鼓励参与者贡献模型和计算资源，确保基于贡献的公平奖励，从而民主化 AI 开发和对齐。该平台已在公共 Base blockchain Sepolia testnet 上实现和评估，结果证明了其在实际应用中的可行性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.DC",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "Camera ready version. Accepted by the ACM Web Conference (WWW) Short\n  Paper Track, 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.14566v3",
      "published_date": "2024-12-19 06:35:54 UTC",
      "updated_date": "2025-04-11 08:10:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:31:12.238759"
    },
    {
      "arxiv_id": "2412.15289v2",
      "title": "SATA: A Paradigm for LLM Jailbreak via Simple Assistive Task Linkage",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaoning Dong",
        "Wenbo Hu",
        "Wei Xu",
        "Tianxing He"
      ],
      "abstract": "Large language models (LLMs) have made significant advancements across\nvarious tasks, but their safety alignment remain a major concern. Exploring\njailbreak prompts can expose LLMs' vulnerabilities and guide efforts to secure\nthem. Existing methods primarily design sophisticated instructions for the LLM\nto follow, or rely on multiple iterations, which could hinder the performance\nand efficiency of jailbreaks. In this work, we propose a novel jailbreak\nparadigm, Simple Assistive Task Linkage (SATA), which can effectively\ncircumvent LLM safeguards and elicit harmful responses. Specifically, SATA\nfirst masks harmful keywords within a malicious query to generate a relatively\nbenign query containing one or multiple [MASK] special tokens. It then employs\na simple assistive task such as a masked language model task or an element\nlookup by position task to encode the semantics of the masked keywords.\nFinally, SATA links the assistive task with the masked query to jointly perform\nthe jailbreak. Extensive experiments show that SATA achieves state-of-the-art\nperformance and outperforms baselines by a large margin. Specifically, on\nAdvBench dataset, with mask language model (MLM) assistive task, SATA achieves\nan overall attack success rate (ASR) of 85% and harmful score (HS) of 4.57, and\nwith element lookup by position (ELP) assistive task, SATA attains an overall\nASR of 76% and HS of 4.43.",
      "tldr_zh": "该研究提出了一种新颖的越狱范式SATA（Simple Assistive Task Linkage），旨在绕过大型语言模型(LLMs)的安全机制，以高效地诱导有害响应。SATA方法首先通过掩盖恶意查询中的有害关键词生成相对无害的查询，然后利用简单辅助任务（如masked language model (MLM)或element lookup by position (ELP)）编码掩盖关键词的语义，最后将辅助任务与掩盖查询链接起来执行越狱。实验结果显示，在AdvBench数据集上，SATA使用MLM辅助任务的攻击成功率(ASR)达到85%和有害分数(HS)为4.57，使用ELP辅助任务的ASR为76%和HS为4.43，显著优于现有基线方法。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.15289v2",
      "published_date": "2024-12-19 05:57:37 UTC",
      "updated_date": "2025-03-21 13:00:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:31:24.524910"
    },
    {
      "arxiv_id": "2412.14545v1",
      "title": "Summary of Point Transformer with Federated Learning for Predicting Breast Cancer HER2 Status from Hematoxylin and Eosin-Stained Whole Slide Images",
      "title_zh": "翻译失败",
      "authors": [
        "Kamorudeen A. Amuda",
        "Almustapha A. Wakili"
      ],
      "abstract": "This study introduces a federated learning-based approach to predict HER2\nstatus from hematoxylin and eosin (HE)-stained whole slide images (WSIs),\nreducing costs and speeding up treatment decisions. To address label imbalance\nand feature representation challenges in multisite datasets, a point\ntransformer is proposed, incorporating dynamic label distribution, an auxiliary\nclassifier, and farthest cosine sampling. Extensive experiments demonstrate\nstate-of-the-art performance across four sites (2687 WSIs) and strong\ngeneralization to two unseen sites (229 WSIs).",
      "tldr_zh": "这项研究提出了一种基于 Federated Learning 的方法，从 Hematoxylin and Eosin (HE)-stained Whole Slide Images (WSIs) 中预测乳腺癌 HER2 状态，以降低成本并加速治疗决策。针对多站点数据集中的标签不平衡和特征表示挑战，他们设计了 Point Transformer，结合动态标签分布、辅助分类器和 farthest cosine sampling 技术。实验结果显示，该方法在四个站点（2687 WSIs）上达到了最先进性能，并在两个未见站点（229 WSIs）上表现出强泛化能力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.14545v1",
      "published_date": "2024-12-19 05:51:46 UTC",
      "updated_date": "2024-12-19 05:51:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:31:36.935008"
    },
    {
      "arxiv_id": "2412.14538v4",
      "title": "Overview of AI and Communication for 6G Network: Fundamentals, Challenges, and Future Research Opportunities",
      "title_zh": "人工智能和通信在6G网络中的概述：基础、",
      "authors": [
        "Qimei Cui",
        "Xiaohu You",
        "Ni Wei",
        "Guoshun Nan",
        "Xuefei Zhang",
        "Jianhua Zhang",
        "Xinchen Lyu",
        "Ming Ai",
        "Xiaofeng Tao",
        "Zhiyong Feng",
        "Ping Zhang",
        "Qingqing Wu",
        "Meixia Tao",
        "Yongming Huang",
        "Chongwen Huang",
        "Guangyi Liu",
        "Chenghui Peng",
        "Zhiwen Pan",
        "Tao Sun",
        "Dusit Niyato",
        "Tao Chen",
        "Muhammad Khurram Khan",
        "Abbas Jamalipour",
        "Mohsen Guizani",
        "Chau Yuen"
      ],
      "abstract": "With the growing demand for seamless connectivity and intelligent\ncommunication, the integration of artificial intelligence (AI) and\nsixth-generation (6G) communication networks has emerged as a transformative\nparadigm. By embedding AI capabilities across various network layers, this\nintegration enables optimized resource allocation, improved efficiency, and\nenhanced system robust performance, particularly in intricate and dynamic\nenvironments. This paper presents a comprehensive overview of AI and\ncommunication for 6G networks, with a focus on emphasizing their foundational\nprinciples, inherent challenges, and future research opportunities. We first\nreview the integration of AI and communications in the context of 6G, exploring\nthe driving factors behind incorporating AI into wireless communications, as\nwell as the vision for the convergence of AI and 6G. The discourse then\ntransitions to a detailed exposition of the envisioned integration of AI within\n6G networks, delineated across three progressive developmental stages. The\nfirst stage, AI for Network, focuses on employing AI to augment network\nperformance, optimize efficiency, and enhance user service experiences. The\nsecond stage, Network for AI, highlights the role of the network in\nfacilitating and buttressing AI operations and presents key enabling\ntechnologies, such as digital twins for AI and semantic communication. In the\nfinal stage, AI as a Service, it is anticipated that future 6G networks will\ninnately provide AI functions as services, supporting application scenarios\nlike immersive communication and intelligent industrial robots. In addition, we\nconduct an in-depth analysis of the critical challenges faced by the\nintegration of AI and communications in 6G. Finally, we outline promising\nfuture research opportunities that are expected to drive the development and\nrefinement of AI and 6G communications.",
      "tldr_zh": "这篇论文概述了人工智能（AI）和第六代通信网络（6G）的整合基础、挑战及未来研究机会，强调通过嵌入 AI 于网络各层来优化资源分配、提升效率并增强系统性能。论文将整合分为三个阶段：AI for Network（利用 AI 提升网络性能和用户体验）、Network for AI（网络支持 AI 操作，包括 digital twins 和 semantic communication 等关键技术），以及 AI as a Service（6G 网络提供 AI 服务，支持沉浸式通信和智能工业机器人等应用）。此外，它深入分析了整合面临的 critical challenges，并指出了 promising future research opportunities，以推动 AI 和 6G 通信的发展。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.14538v4",
      "published_date": "2024-12-19 05:36:34 UTC",
      "updated_date": "2025-02-13 07:40:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:31:49.569768"
    },
    {
      "arxiv_id": "2412.14522v2",
      "title": "CwA-T: A Channelwise AutoEncoder with Transformer for EEG Abnormality Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Youshen Zhao",
        "Keiji Iramina"
      ],
      "abstract": "Electroencephalogram (EEG) signals are critical for detecting abnormal brain\nactivity, but their high dimensionality and complexity pose significant\nchallenges for effective analysis. In this paper, we propose CwA-T, a novel\nframework that combines a channelwise CNN-based autoencoder with a single-head\ntransformer classifier for efficient EEG abnormality detection. The channelwise\nautoencoder compresses raw EEG signals while preserving channel independence,\nreducing computational costs and retaining biologically meaningful features.\nThe compressed representations are then fed into the transformer-based\nclassifier, which efficiently models long-term dependencies to distinguish\nbetween normal and abnormal signals. Evaluated on the TUH Abnormal EEG Corpus,\nthe proposed model achieves 85.0% accuracy, 76.2% sensitivity, and 91.2%\nspecificity at the per-case level, outperforming baseline models such as\nEEGNet, Deep4Conv, and FusionCNN. Furthermore, CwA-T requires only 202M FLOPs\nand 2.9M parameters, making it significantly more efficient than\ntransformer-based alternatives. The framework retains interpretability through\nits channelwise design, demonstrating great potential for future applications\nin neuroscience research and clinical practice. The source code is available at\nhttps://github.com/YossiZhao/CAE-T.",
      "tldr_zh": "本论文提出 CwA-T 框架，用于 EEG 异常检测，该框架结合 channelwise CNN-based autoencoder 和 single-head transformer classifier，以应对 EEG 信号的高维度和复杂性挑战。Channelwise autoencoder 负责压缩原始 EEG 信号，保留通道独立性和生物学意义特征，从而降低计算成本；随后，transformer 分类器处理压缩表示，建模长期依赖性以区分正常和异常信号。在 TUH Abnormal EEG Corpus 上，CwA-T 实现 85.0% 准确率、76.2% 敏感性和 91.2% 特异性，优于基线模型如 EEGNet 和 Deep4Conv，且仅需 202M FLOPs 和 2.9M 参数。该框架通过 channelwise 设计保持可解释性，具有广阔潜力应用于神经科学研究和临床实践。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE",
        "eess.SP",
        "I.2"
      ],
      "primary_category": "cs.LG",
      "comment": "The manuscript consists of 10 pages, including 5 figures. The\n  experimental results are based on evaluations using the TUH Abnormal EEG\n  Corpus",
      "pdf_url": "http://arxiv.org/pdf/2412.14522v2",
      "published_date": "2024-12-19 04:38:34 UTC",
      "updated_date": "2024-12-24 00:56:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:32:02.382002"
    },
    {
      "arxiv_id": "2412.14515v1",
      "title": "Relational Programming with Foundation Models",
      "title_zh": "翻译失败",
      "authors": [
        "Ziyang Li",
        "Jiani Huang",
        "Jason Liu",
        "Felix Zhu",
        "Eric Zhao",
        "William Dodds",
        "Neelay Velingker",
        "Rajeev Alur",
        "Mayur Naik"
      ],
      "abstract": "Foundation models have vast potential to enable diverse AI applications. The\npowerful yet incomplete nature of these models has spurred a wide range of\nmechanisms to augment them with capabilities such as in-context learning,\ninformation retrieval, and code interpreting. We propose Vieira, a declarative\nframework that unifies these mechanisms in a general solution for programming\nwith foundation models. Vieira follows a probabilistic relational paradigm and\ntreats foundation models as stateless functions with relational inputs and\noutputs. It supports neuro-symbolic applications by enabling the seamless\ncombination of such models with logic programs, as well as complex, multi-modal\napplications by streamlining the composition of diverse sub-models. We\nimplement Vieira by extending the Scallop compiler with a foreign interface\nthat supports foundation models as plugins. We implement plugins for 12\nfoundation models including GPT, CLIP, and SAM. We evaluate Vieira on 9\nchallenging tasks that span language, vision, and structured and vector\ndatabases. Our evaluation shows that programs in Vieira are concise, can\nincorporate modern foundation models, and have comparable or better accuracy\nthan competitive baselines.",
      "tldr_zh": "该论文提出 Vieira，一种声明式框架，用于统一增强 Foundation Models 的机制，如 in-context learning、information retrieval 和 code interpreting，从而简化基础模型的编程。Vieira 采用概率关系范式，将基础模型视为无状态函数，支持 neuro-symbolic 应用和多模态应用的无缝组合，并通过扩展 Scallop 编译器添加了包括 GPT、CLIP 和 SAM 在内的 12 个模型插件。在 9 个跨越语言、视觉和数据库的任务上，Vieira 的程序表现出简洁性、兼容性和与竞争基线相当或更好的准确率。",
      "categories": [
        "cs.AI",
        "cs.PL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.14515v1",
      "published_date": "2024-12-19 04:26:45 UTC",
      "updated_date": "2024-12-19 04:26:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:33:58.918279"
    },
    {
      "arxiv_id": "2412.14510v1",
      "title": "PA-RAG: RAG Alignment via Multi-Perspective Preference Optimization",
      "title_zh": "PA-RAG：通过多视角偏好优化的 RAG 对齐",
      "authors": [
        "Jiayi Wu",
        "Hengyi Cai",
        "Lingyong Yan",
        "Hao Sun",
        "Xiang Li",
        "Shuaiqiang Wang",
        "Dawei Yin",
        "Ming Gao"
      ],
      "abstract": "The emergence of Retrieval-augmented generation (RAG) has alleviated the\nissues of outdated and hallucinatory content in the generation of large\nlanguage models (LLMs), yet it still reveals numerous limitations. When a\ngeneral-purpose LLM serves as the RAG generator, it often suffers from\ninadequate response informativeness, response robustness, and citation quality.\nPast approaches to tackle these limitations, either by incorporating additional\nsteps beyond generating responses or optimizing the generator through\nsupervised fine-tuning (SFT), still failed to align with the RAG requirement\nthoroughly. Consequently, optimizing the RAG generator from multiple preference\nperspectives while maintaining its end-to-end LLM form remains a challenge. To\nbridge this gap, we propose Multiple Perspective Preference Alignment for\nRetrieval-Augmented Generation (PA-RAG), a method for optimizing the generator\nof RAG systems to align with RAG requirements comprehensively. Specifically, we\nconstruct high-quality instruction fine-tuning data and multi-perspective\npreference data by sampling varied quality responses from the generator across\ndifferent prompt documents quality scenarios. Subsequently, we optimize the\ngenerator using SFT and Direct Preference Optimization (DPO). Extensive\nexperiments conducted on four question-answer datasets across three LLMs\ndemonstrate that PA-RAG can significantly enhance the performance of RAG\ngenerators. Our code and datasets are available at\nhttps://github.com/wujwyi/PA-RAG.",
      "tldr_zh": "这篇论文针对Retrieval-augmented Generation (RAG)系统的局限性（如响应信息不足、鲁棒性差和引用质量低）提出PA-RAG方法，通过多视角偏好优化来全面提升RAG生成器的性能。PA-RAG首先构建高质量的指令微调数据和多视角偏好数据，从生成器中采样不同质量的响应，然后使用Supervised Fine-Tuning (SFT)和Direct Preference Optimization (DPO)进行端到端优化。实验结果显示，在四个问答数据集和三个Large Language Models (LLMs)上，PA-RAG显著提高了RAG生成器的整体表现。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.14510v1",
      "published_date": "2024-12-19 04:18:51 UTC",
      "updated_date": "2024-12-19 04:18:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:32:24.856124"
    },
    {
      "arxiv_id": "2412.14500v2",
      "title": "The Digital Ecosystem of Beliefs: does evolution favour AI over humans?",
      "title_zh": "翻译失败",
      "authors": [
        "David M. Bossens",
        "Shanshan Feng",
        "Yew-Soon Ong"
      ],
      "abstract": "As AI systems are integrated into social networks, there are AI safety\nconcerns that AI-generated content may dominate the web, e.g. in popularity or\nimpact on beliefs. To understand such questions, this paper proposes the\nDigital Ecosystem of Beliefs (Digico), the first evolutionary framework for\ncontrolled experimentation with multi-population interactions in simulated\nsocial networks. The framework models a population of agents which change their\nmessaging strategies due to evolutionary updates following a Universal\nDarwinism approach, interact via messages, influence each other's beliefs\nthrough dynamics based on a contagion model, and maintain their beliefs through\ncognitive Lamarckian inheritance. Initial experiments with an abstract\nimplementation of Digico show that: a) when AIs have faster messaging,\nevolution, and more influence in the recommendation algorithm, they get 80% to\n95% of the views, depending on the size of the influence benefit; b) AIs\ndesigned for propaganda can typically convince 50% of humans to adopt extreme\nbeliefs, and up to 85% when agents believe only a limited number of channels;\nc) a penalty for content that violates agents' beliefs reduces propaganda\neffectiveness by up to 8%. We further discuss implications for control (e.g.\nlegislation) and Digico as a means of studying evolutionary principles.",
      "tldr_zh": "该论文提出 Digital Ecosystem of Beliefs (Digico) 框架，这是第一个用于模拟社交网络中多群体互动的演化框架，允许控制实验以评估 AI 与人类在信念传播中的竞争。框架基于 Universal Darwinism 的演化更新、传染模型的影响动态以及认知 Lamarckian inheritance 来模拟代理的互动和信念变化。实验结果显示，当 AI 在消息速度、演化速度和推荐算法上占优势时，可获得 80% 到 95% 的浏览量；设计为宣传的 AI 能说服 50% 的人类采用极端信念，限制渠道时可达 85%。此外，惩罚违反信念的内容可降低宣传效果 8%，论文讨论了这些发现对立法等控制措施以及研究演化原则的启示。",
      "categories": [
        "cs.AI",
        "cs.MA",
        "cs.NE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.14500v2",
      "published_date": "2024-12-19 03:48:23 UTC",
      "updated_date": "2025-01-08 06:52:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:32:38.033838"
    },
    {
      "arxiv_id": "2412.14497v2",
      "title": "Disentangled Graph Autoencoder for Treatment Effect Estimation",
      "title_zh": "用于治疗效果估计的解缠图自编码器",
      "authors": [
        "Di Fan",
        "Renlei Jiang",
        "Yunhao Wen",
        "Chuanhou Gao"
      ],
      "abstract": "Treatment effect estimation from observational data has attracted significant\nattention across various research fields. However, many widely used methods\nrely on the unconfoundedness assumption, which is often unrealistic due to the\ninability to observe all confounders, thereby overlooking the influence of\nlatent confounders. To address this limitation, recent approaches have utilized\nauxiliary network information to infer latent confounders, relaxing this\nassumption. However, these methods often treat observed variables and networks\nas proxies only for latent confounders, which can result in inaccuracies when\ncertain variables influence treatment without affecting outcomes, or vice\nversa. This conflation of distinct latent factors undermines the precision of\ntreatment effect estimation. To overcome this challenge, we propose a novel\ndisentangled variational graph autoencoder for treatment effect estimation on\nnetworked observational data. Our graph encoder disentangles latent factors\ninto instrumental, confounding, adjustment, and noisy factors, while enforcing\nfactor independence using the Hilbert-Schmidt Independence Criterion. Extensive\nexperiments on multiple networked datasets demonstrate that our method\noutperforms state-of-the-art approaches.",
      "tldr_zh": "该论文针对从观察数据中估计治疗效果的问题，指出现有方法依赖于不现实的无混杂假设，并忽略了潜在混杂因素的影响。作者提出了一种新型的 disentangled variational graph autoencoder 方法，通过图编码器将潜在因素解耦为工具变量（instrumental factors）、混杂因素（confounding factors）、调整因素（adjustment factors）和噪声因素（noisy factors），并利用 Hilbert-Schmidt Independence Criterion 强制这些因素独立，以提高估计精度。在多个网络数据集上的广泛实验中，该方法优于最先进的方法，展示了其有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "22 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.14497v2",
      "published_date": "2024-12-19 03:44:49 UTC",
      "updated_date": "2025-02-20 11:43:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:34:10.389769"
    },
    {
      "arxiv_id": "2412.14492v1",
      "title": "FaultExplainer: Leveraging Large Language Models for Interpretable Fault Detection and Diagnosis",
      "title_zh": "FaultExplainer：利用大语言模型进行可解释的故障检测和诊断",
      "authors": [
        "Abdullah Khan",
        "Rahul Nahar",
        "Hao Chen",
        "Gonzalo E. Constante Flores",
        "Can Li"
      ],
      "abstract": "Machine learning algorithms are increasingly being applied to fault detection\nand diagnosis (FDD) in chemical processes. However, existing data-driven FDD\nplatforms often lack interpretability for process operators and struggle to\nidentify root causes of previously unseen faults. This paper presents\nFaultExplainer, an interactive tool designed to improve fault detection,\ndiagnosis, and explanation in the Tennessee Eastman Process (TEP).\nFaultExplainer integrates real-time sensor data visualization, Principal\nComponent Analysis (PCA)-based fault detection, and identification of top\ncontributing variables within an interactive user interface powered by large\nlanguage models (LLMs). We evaluate the LLMs' reasoning capabilities in two\nscenarios: one where historical root causes are provided, and one where they\nare not to mimic the challenge of previously unseen faults. Experimental\nresults using GPT-4o and o1-preview models demonstrate the system's strengths\nin generating plausible and actionable explanations, while also highlighting\nits limitations, including reliance on PCA-selected features and occasional\nhallucinations.",
      "tldr_zh": "本研究提出 FaultExplainer，一种利用 Large Language Models (LLMs) 的交互式工具，旨在提升化学过程的故障检测和诊断 (FDD) 可解释性，并解决现有平台在识别新故障根因方面的不足。该工具整合实时传感器数据可视化、Principal Component Analysis (PCA) 基于的故障检测，以及 LLMs 驱动的用户界面，以生成可行动的解释。实验在 Tennessee Eastman Process (TEP) 上使用 GPT-4o 和 o1-preview 模型评估，展示了在提供历史根因或无根因场景下的推理能力，但也突显了依赖 PCA 特征和潜在幻觉的局限性。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.14492v1",
      "published_date": "2024-12-19 03:35:06 UTC",
      "updated_date": "2024-12-19 03:35:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:34:23.254948"
    },
    {
      "arxiv_id": "2412.14491v1",
      "title": "Mediation Analysis for Probabilities of Causation",
      "title_zh": "因果概率的中介分析",
      "authors": [
        "Yuta Kawakami",
        "Jin Tian"
      ],
      "abstract": "Probabilities of causation (PoC) offer valuable insights for informed\ndecision-making. This paper introduces novel variants of PoC-controlled direct,\nnatural direct, and natural indirect probability of necessity and sufficiency\n(PNS). These metrics quantify the necessity and sufficiency of a treatment for\nproducing an outcome, accounting for different causal pathways. We develop\nidentification theorems for these new PoC measures, allowing for their\nestimation from observational data. We demonstrate the practical application of\nour results through an analysis of a real-world psychology dataset.",
      "tldr_zh": "这篇论文引入了新的 Probabilities of Causation (PoC) 变体，包括 controlled direct、natural direct 和 natural indirect probability of necessity and sufficiency (PNS)，这些指标用于量化治疗对结果的必要性和充分性，同时考虑不同的因果路径。作者开发了 identification theorems 来从观察数据中估计这些新 PoC 措施。论文通过分析一个真实世界的心理学数据集，展示了这些方法的实际应用及其在决策支持中的价值。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.14491v1",
      "published_date": "2024-12-19 03:28:13 UTC",
      "updated_date": "2024-12-19 03:28:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:34:34.390504"
    },
    {
      "arxiv_id": "2412.14488v4",
      "title": "A stochastic first-order method with multi-extrapolated momentum for highly smooth unconstrained optimization",
      "title_zh": "一种带有多重外推动量的随机一阶方法，用于高度光滑的无约束优化",
      "authors": [
        "Chuan He"
      ],
      "abstract": "In this paper, we consider an unconstrained stochastic optimization problem\nwhere the objective function exhibits high-order smoothness. Specifically, we\npropose a new stochastic first-order method (SFOM) with multi-extrapolated\nmomentum, in which multiple extrapolations are performed in each iteration,\nfollowed by a momentum update based on these extrapolations. We demonstrate\nthat the proposed SFOM can accelerate optimization by exploiting the high-order\nsmoothness of the objective function $f$. Assuming that the $p$th-order\nderivative of $f$ is Lipschitz continuous for some $p\\ge2$, and under\nadditional mild assumptions, we establish that our method achieves a sample\ncomplexity of $\\widetilde{\\mathcal{O}}(\\epsilon^{-(3p+1)/p})$ for finding a\npoint $x$ such that $\\mathbb{E}[\\|\\nabla f(x)\\|]\\le\\epsilon$. To the best of\nour knowledge, this is the first SFOM to leverage arbitrary-order smoothness of\nthe objective function for acceleration, resulting in a sample complexity that\nimproves upon the best-known results without assuming the mean-squared\nsmoothness condition. Preliminary numerical experiments validate the practical\nperformance of our method and support our theoretical findings.",
      "tldr_zh": "这篇论文提出了一种新的随机一阶方法（SFOM），即带有多重外推动量（multi-extrapolated momentum）的算法，用于处理目标函数具有高阶平滑性的无约束优化问题。该方法在每个迭代中进行多个外推并基于这些外推更新动量，从而利用函数的 p 阶导数 Lipschitz 连续性（p ≥ 2）来加速优化，实现了样本复杂度为 \\(\\widetilde{\\mathcal{O}}(\\epsilon^{-(3p+1)/p}\\)，优于现有结果且不依赖均方平滑性假设。初步数值实验验证了该方法的实际性能，并支持了理论分析。",
      "categories": [
        "math.OC",
        "cs.AI",
        "cs.LG",
        "49M05, 49M37, 90C25, 90C30"
      ],
      "primary_category": "math.OC",
      "comment": "An example is provided to illustrate the gap between the smoothness\n  of the objective function itself and the mean-squared smoothness of the\n  stochastic gradient estimator",
      "pdf_url": "http://arxiv.org/pdf/2412.14488v4",
      "published_date": "2024-12-19 03:22:47 UTC",
      "updated_date": "2025-04-08 16:04:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:34:48.487966"
    },
    {
      "arxiv_id": "2412.14485v2",
      "title": "Towards Projected and Incremental Pseudo-Boolean Model Counting",
      "title_zh": "翻译失败",
      "authors": [
        "Suwei Yang",
        "Kuldeep S. Meel"
      ],
      "abstract": "Model counting is a fundamental task that involves determining the number of\nsatisfying assignments to a logical formula, typically in conjunctive normal\nform (CNF). While CNF model counting has received extensive attention over\nrecent decades, interest in Pseudo-Boolean (PB) model counting is just emerging\npartly due to the greater flexibility of PB formulas. As such, we observed\nfeature gaps in existing PB counters such as a lack of support for projected\nand incremental settings, which could hinder adoption. In this work, our main\ncontribution is the introduction of the PB model counter PBCount2, the first\nexact PB model counter with support for projected and incremental model\ncounting. Our counter, PBCount2, uses our Least Occurrence Weighted Min Degree\n(LOW-MD) computation ordering heuristic to support projected model counting and\na cache mechanism to enable incremental model counting. In our evaluations,\nPBCount2 completed at least 1.40x the number of benchmarks of competing methods\nfor projected model counting and at least 1.18x of competing methods in\nincremental model counting.",
      "tldr_zh": "该论文探讨了Pseudo-Boolean (PB)模型计数问题，该任务涉及计算逻辑公式（如CNF）满足赋值的数量，但现有PB计数器缺少对projected和incremental设置的支持。研究的主要贡献是引入PBCount2，这是首个精确的PB模型计数器，支持projected模型计数（通过Least Occurrence Weighted Min Degree (LOW-MD)启发式方法）和incremental模型计数（通过缓存机制）。在评估中，PBCount2在projected模型计数中完成了竞争方法的至少1.40倍基准测试，在incremental模型计数中完成了至少1.18倍，展示了其显著性能优势。",
      "categories": [
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "To appear in AAAI25",
      "pdf_url": "http://arxiv.org/pdf/2412.14485v2",
      "published_date": "2024-12-19 03:11:33 UTC",
      "updated_date": "2024-12-20 15:18:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:34:58.265142"
    },
    {
      "arxiv_id": "2412.16233v2",
      "title": "WiFi CSI Based Temporal Activity Detection via Dual Pyramid Network",
      "title_zh": "翻译失败",
      "authors": [
        "Zhendong Liu",
        "Le Zhang",
        "Bing Li",
        "Yingjie Zhou",
        "Zhenghua Chen",
        "Ce Zhu"
      ],
      "abstract": "We address the challenge of WiFi-based temporal activity detection and\npropose an efficient Dual Pyramid Network that integrates Temporal Signal\nSemantic Encoders and Local Sensitive Response Encoders. The Temporal Signal\nSemantic Encoder splits feature learning into high and low-frequency\ncomponents, using a novel Signed Mask-Attention mechanism to emphasize\nimportant areas and downplay unimportant ones, with the features fused using\nContraNorm. The Local Sensitive Response Encoder captures fluctuations without\nlearning. These feature pyramids are then combined using a new cross-attention\nfusion mechanism. We also introduce a dataset with over 2,114 activity segments\nacross 553 WiFi CSI samples, each lasting around 85 seconds. Extensive\nexperiments show our method outperforms challenging baselines.",
      "tldr_zh": "这篇论文针对 WiFi CSI 基于的临时活动检测问题，提出了一种高效的 Dual Pyramid Network，该网络整合了 Temporal Signal Semantic Encoders（使用 Signed Mask-Attention 机制处理高低频特征并通过 ContraNorm 融合）和 Local Sensitive Response Encoders（捕获波动而不进行学习）。这些特征金字塔随后通过 cross-attention fusion 机制结合，以提升检测性能。作者还引入了一个新数据集，包含超过 2,114 个活动段和 553 个 WiFi CSI 样本，每个约 85 秒。实验结果表明，该方法在广泛测试中优于现有基线模型。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.NI"
      ],
      "primary_category": "cs.CV",
      "comment": "9 pages, 4 figures, AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.16233v2",
      "published_date": "2024-12-19 03:00:45 UTC",
      "updated_date": "2025-01-26 15:22:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:35:10.942599"
    },
    {
      "arxiv_id": "2412.16232v3",
      "title": "Defeasible Visual Entailment: Benchmark, Evaluator, and Reward-Driven Optimization",
      "title_zh": "可废止视觉蕴涵：基准、评估器和",
      "authors": [
        "Yue Zhang",
        "Liqiang Jing",
        "Vibhav Gogate"
      ],
      "abstract": "We introduce a new task called Defeasible Visual Entailment (DVE), where the\ngoal is to allow the modification of the entailment relationship between an\nimage premise and a text hypothesis based on an additional update. While this\nconcept is well-established in Natural Language Inference, it remains\nunexplored in visual entailment. At a high level, DVE enables models to refine\ntheir initial interpretations, leading to improved accuracy and reliability in\nvarious applications such as detecting misleading information in images,\nenhancing visual question answering, and refining decision-making processes in\nautonomous systems. Existing metrics do not adequately capture the change in\nthe entailment relationship brought by updates. To address this, we propose a\nnovel inference-aware evaluator designed to capture changes in entailment\nstrength induced by updates, using pairwise contrastive learning and\ncategorical information learning. Additionally, we introduce a reward-driven\nupdate optimization method to further enhance the quality of updates generated\nby multimodal models. Experimental results demonstrate the effectiveness of our\nproposed evaluator and optimization method.",
      "tldr_zh": "本文引入 Defeasible Visual Entailment (DVE) 任务，允许基于额外更新修改图像前提与文本假设之间的蕴含关系，从而提升模型在检测图像误导信息、视觉问答和自主系统决策中的准确性和可靠性。针对现有指标的不足，作者提出一个新型推理感知评估器，利用 pairwise contrastive learning 和 categorical information learning 来捕捉更新对蕴含强度的变化。还开发了 reward-driven update optimization 方法，以优化多模态模型的更新生成质量。实验结果验证了该评估器和优化方法的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.16232v3",
      "published_date": "2024-12-19 02:38:31 UTC",
      "updated_date": "2025-02-08 22:04:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:35:22.491048"
    },
    {
      "arxiv_id": "2412.14468v1",
      "title": "HashAttention: Semantic Sparsity for Faster Inference",
      "title_zh": "HashAttention：语义稀疏性用于更快推理",
      "authors": [
        "Aditya Desai",
        "Shuo Yang",
        "Alejandro Cuadron",
        "Ana Klimovic",
        "Matei Zaharia",
        "Joseph E. Gonzalez",
        "Ion Stoica"
      ],
      "abstract": "Utilizing longer contexts is increasingly essential to power better AI\nsystems. However, the cost of attending to long contexts is high due to the\ninvolved softmax computation. While the scaled dot-product attention (SDPA)\nexhibits token sparsity, with only a few pivotal tokens significantly\ncontributing to attention, leveraging this sparsity effectively remains an open\nchallenge. Previous methods either suffer from model degradation or require\nconsiderable additional resources. We propose HashAttention --a principled\napproach casting pivotal token identification as a recommendation problem.\nGiven a query, HashAttention encodes keys and queries in Hamming space\ncapturing the required semantic similarity using learned mapping functions.\nHashAttention efficiently identifies pivotal tokens for a given query in this\nHamming space using bitwise operations, and only these pivotal tokens are used\nfor attention computation, significantly improving overall attention\nefficiency. HashAttention can reduce the number of tokens used by a factor of\n$1/32\\times$ for the Llama-3.1-8B model with LongBench, keeping average quality\nloss within 0.6 points, while using only 32 bits per token auxiliary memory. At\n$32\\times$ sparsity, HashAttention is $3{-}6\\times$ faster than LightLLM and\n$2.5{-}4.5\\times$ faster than gpt-fast on Nvidia-L4 GPU.",
      "tldr_zh": "这篇论文提出 HashAttention，一种基于语义稀疏性的方法，用于加速注意力机制的推理过程，以应对长上下文计算成本高的问题。HashAttention 将 keys 和 queries 编码到 Hamming space，使用学习映射函数捕捉语义相似性，并通过位运算高效识别关键 token，仅计算这些 token 的注意力，从而显著减少计算量。实验显示，在 Llama-3.1-8B 模型上，它可以将 token 数量减少到 1/32 倍，平均质量损失仅 0.6 分，并在 Nvidia-L4 GPU 上比 LightLLM 快 3-6 倍，比 gpt-fast 快 2.5-4.5 倍。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.14468v1",
      "published_date": "2024-12-19 02:34:15 UTC",
      "updated_date": "2024-12-19 02:34:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:35:35.355874"
    },
    {
      "arxiv_id": "2412.14451v1",
      "title": "CLDG: Contrastive Learning on Dynamic Graphs",
      "title_zh": "CLDG：动态图上的对比学习",
      "authors": [
        "Yiming Xu",
        "Bin Shi",
        "Teng Ma",
        "Bo Dong",
        "Haoyi Zhou",
        "Qinghua Zheng"
      ],
      "abstract": "The graph with complex annotations is the most potent data type, whose\nconstantly evolving motivates further exploration of the unsupervised dynamic\ngraph representation. One of the representative paradigms is graph contrastive\nlearning. It constructs self-supervised signals by maximizing the mutual\ninformation between the statistic graph's augmentation views. However, the\nsemantics and labels may change within the augmentation process, causing a\nsignificant performance drop in downstream tasks. This drawback becomes greatly\nmagnified on dynamic graphs. To address this problem, we designed a simple yet\neffective framework named CLDG. Firstly, we elaborate that dynamic graphs have\ntemporal translation invariance at different levels. Then, we proposed a\nsampling layer to extract the temporally-persistent signals. It will encourage\nthe node to maintain consistent local and global representations, i.e.,\ntemporal translation invariance under the timespan views. The extensive\nexperiments demonstrate the effectiveness and efficiency of the method on seven\ndatasets by outperforming eight unsupervised state-of-the-art baselines and\nshowing competitiveness against four semi-supervised methods. Compared with the\nexisting dynamic graph method, the number of model parameters and training time\nis reduced by an average of 2,001.86 times and 130.31 times on seven datasets,\nrespectively.",
      "tldr_zh": "本研究提出 CLDG 框架，用于动态图上的对比学习（Contrastive Learning），旨在解决现有方法在图增强过程中语义和标签变化导致的下游任务性能下降问题。CLDG 利用动态图的时间平移不变性（temporal translation invariance），设计了一个采样层来提取时间上持久的信号，确保节点在时段视图下保持一致的局部和全局表示。实验结果显示，该框架在七个数据集上超过了八个无监督的 SOTA 基线，并在四个半监督方法上表现出竞争力，同时与现有动态图方法相比，模型参数和训练时间分别平均减少了 2001.86 倍和 130.31 倍。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by ICDE2023",
      "pdf_url": "http://arxiv.org/pdf/2412.14451v1",
      "published_date": "2024-12-19 01:59:24 UTC",
      "updated_date": "2024-12-19 01:59:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:35:47.523911"
    },
    {
      "arxiv_id": "2412.14444v1",
      "title": "GenHMR: Generative Human Mesh Recovery",
      "title_zh": "GenHMR：生成式人体网格恢复",
      "authors": [
        "Muhammad Usama Saleem",
        "Ekkasit Pinyoanuntapong",
        "Pu Wang",
        "Hongfei Xue",
        "Srijan Das",
        "Chen Chen"
      ],
      "abstract": "Human mesh recovery (HMR) is crucial in many computer vision applications;\nfrom health to arts and entertainment. HMR from monocular images has\npredominantly been addressed by deterministic methods that output a single\nprediction for a given 2D image. However, HMR from a single image is an\nill-posed problem due to depth ambiguity and occlusions. Probabilistic methods\nhave attempted to address this by generating and fusing multiple plausible 3D\nreconstructions, but their performance has often lagged behind deterministic\napproaches. In this paper, we introduce GenHMR, a novel generative framework\nthat reformulates monocular HMR as an image-conditioned generative task,\nexplicitly modeling and mitigating uncertainties in the 2D-to-3D mapping\nprocess. GenHMR comprises two key components: (1) a pose tokenizer to convert\n3D human poses into a sequence of discrete tokens in a latent space, and (2) an\nimage-conditional masked transformer to learn the probabilistic distributions\nof the pose tokens, conditioned on the input image prompt along with randomly\nmasked token sequence. During inference, the model samples from the learned\nconditional distribution to iteratively decode high-confidence pose tokens,\nthereby reducing 3D reconstruction uncertainties. To further refine the\nreconstruction, a 2D pose-guided refinement technique is proposed to directly\nfine-tune the decoded pose tokens in the latent space, which forces the\nprojected 3D body mesh to align with the 2D pose clues. Experiments on\nbenchmark datasets demonstrate that GenHMR significantly outperforms\nstate-of-the-art methods. Project website can be found at\nhttps://m-usamasaleem.github.io/publication/GenHMR/GenHMR.html",
      "tldr_zh": "该论文提出GenHMR，一种创新的生成框架，用于从单目图像中恢复人类网格(HMR)，通过显式建模2D到3D映射的不确定性来解决深度模糊和遮挡问题。GenHMR的关键组件包括姿态tokenizer，将3D人类姿势转换为潜在空间的离散token序列，以及图像条件masked transformer，用于学习姿势token的概率分布并在推理时采样解码高置信度token。论文还引入2D姿势引导的精炼技术，在潜在空间中微调解码token，使投影的3D身体网格与2D姿势对齐；实验结果显示，GenHMR在基准数据集上显著优于现有最先进方法。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.14444v1",
      "published_date": "2024-12-19 01:45:58 UTC",
      "updated_date": "2024-12-19 01:45:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:36:00.373743"
    },
    {
      "arxiv_id": "2412.14436v1",
      "title": "ORBIT: Cost-Effective Dataset Curation for Large Language Model Domain Adaptation with an Astronomy Case Study",
      "title_zh": "翻译失败",
      "authors": [
        "Eric Modesitt",
        "Ke Yang",
        "Spencer Hulsey",
        "Chengxiang Zhai",
        "Volodymyr Kindratenko"
      ],
      "abstract": "Recent advances in language modeling demonstrate the need for high-quality\ndomain-specific training data, especially for tasks that require specialized\nknowledge. General-purpose models, while versatile, often lack the depth needed\nfor expert-level tasks because of limited domain-specific information. Domain\nadaptation training can enhance these models, but it demands substantial,\nhigh-quality data. To address this, we propose ORBIT, a cost-efficient\nmethodology for curating massive, high-quality domain-specific datasets from\nnoisy web sources, tailored for training specialist large language models.\nUsing astronomy as a primary case study, we refined the 1.3T-token FineWeb-Edu\ndataset into a high-quality, 10B-token subset focused on astronomy. Fine-tuning\n\\textsc{LLaMA-3-8B} on a 1B-token astronomy subset improved performance on the\nMMLU astronomy benchmark from 69\\% to 76\\% and achieved top results on\nAstroBench, an astronomy-specific benchmark. Moreover, our model (Orbit-LLaMA)\noutperformed \\textsc{LLaMA-3-8B-base}, with GPT-4o evaluations preferring it in\n73\\% of cases across 1000 astronomy-specific questions. Additionally, we\nvalidated ORBIT's generalizability by applying it to law and medicine,\nachieving a significant improvement of data quality compared to an unfiltered\nbaseline. We open-source the ORBIT methodology, including the curated datasets,\nthe codebase, and the resulting model at\n\\href{https://github.com/ModeEric/ORBIT-Llama}{https://github.com/ModeEric/ORBIT-Llama}.",
      "tldr_zh": "本论文提出 ORBIT，一种成本高效的方法，用于从嘈杂网络来源中整理大规模、高质量的领域特定数据集，以支持大型语言模型（Large Language Models）的领域适应训练。  \n以天文学为例，研究者从 1.3T-token 的 FineWeb-Edu 数据集提炼出 10B-token 的天文学子集，并对 LLaMA-3-8B 进行微调，结果在 MMLU 天文学基准上性能从 69% 提升到 76%，并在 AstroBench 上取得最佳成绩。  \n此外，ORBIT-LLaMA 模型在 GPT-4o 的评估中胜出，73% 的天文学问题更倾向于其答案。  \n该方法还验证了在法律和医学领域的泛化能力，并开源了 ORBIT 相关数据集、代码和模型。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.14436v1",
      "published_date": "2024-12-19 01:35:47 UTC",
      "updated_date": "2024-12-19 01:35:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:36:14.063630"
    },
    {
      "arxiv_id": "2412.14435v1",
      "title": "Cherry-Picking in Time Series Forecasting: How to Select Datasets to Make Your Model Shine",
      "title_zh": "翻译失败",
      "authors": [
        "Luis Roque",
        "Carlos Soares",
        "Vitor Cerqueira",
        "Luis Torgo"
      ],
      "abstract": "The importance of time series forecasting drives continuous research and the\ndevelopment of new approaches to tackle this problem. Typically, these methods\nare introduced through empirical studies that frequently claim superior\naccuracy for the proposed approaches. Nevertheless, concerns are rising about\nthe reliability and generalizability of these results due to limitations in\nexperimental setups. This paper addresses a critical limitation: the number and\nrepresentativeness of the datasets used. We investigate the impact of dataset\nselection bias, particularly the practice of cherry-picking datasets, on the\nperformance evaluation of forecasting methods. Through empirical analysis with\na diverse set of benchmark datasets, our findings reveal that cherry-picking\ndatasets can significantly distort the perceived performance of methods, often\nexaggerating their effectiveness. Furthermore, our results demonstrate that by\nselectively choosing just four datasets - what most studies report - 46% of\nmethods could be deemed best in class, and 77% could rank within the top three.\nAdditionally, recent deep learning-based approaches show high sensitivity to\ndataset selection, whereas classical methods exhibit greater robustness.\nFinally, our results indicate that, when empirically validating forecasting\nalgorithms on a subset of the benchmarks, increasing the number of datasets\ntested from 3 to 6 reduces the risk of incorrectly identifying an algorithm as\nthe best one by approximately 40%. Our study highlights the critical need for\ncomprehensive evaluation frameworks that more accurately reflect real-world\nscenarios. Adopting such frameworks will ensure the development of robust and\nreliable forecasting methods.",
      "tldr_zh": "该论文探讨了时间序列预测（time series forecasting）中的数据集选择偏见，特别是 cherry-picking（挑选数据集）的做法如何扭曲模型性能评估。研究通过对多样基准数据集的实证分析发现，这种偏见往往夸大方法的有效性，导致46%的模型在仅选四个数据集时被视为最佳，而77%排在前三。结果显示，深度学习-based approaches 对数据集选择高度敏感，而经典方法更具稳健性。最终，论文强调增加测试数据集数量（如从3到6个）可将错误识别最佳算法的风险降低约40%，并呼吁采用更全面的评估框架以确保预测方法的可靠性和泛化性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "68T01",
        "I.5.1; G.3; H.2.8; I.2.1"
      ],
      "primary_category": "cs.LG",
      "comment": "Proceedings of the 39th AAAI Conference on Artificial Intelligence\n  (AAAI-25), February 25-March 4, 2025, Philadelphia, Pennsylvania, USA",
      "pdf_url": "http://arxiv.org/pdf/2412.14435v1",
      "published_date": "2024-12-19 01:34:17 UTC",
      "updated_date": "2024-12-19 01:34:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:36:24.016834"
    },
    {
      "arxiv_id": "2412.17847v2",
      "title": "Bridging the Data Provenance Gap Across Text, Speech and Video",
      "title_zh": "跨越文本、语音和视频的数据溯源差距弥合",
      "authors": [
        "Shayne Longpre",
        "Nikhil Singh",
        "Manuel Cherep",
        "Kushagra Tiwary",
        "Joanna Materzynska",
        "William Brannon",
        "Robert Mahari",
        "Naana Obeng-Marnu",
        "Manan Dey",
        "Mohammed Hamdy",
        "Nayan Saxena",
        "Ahmad Mustafa Anis",
        "Emad A. Alghamdi",
        "Vu Minh Chien",
        "Da Yin",
        "Kun Qian",
        "Yizhi Li",
        "Minnie Liang",
        "An Dinh",
        "Shrestha Mohanty",
        "Deividas Mataciunas",
        "Tobin South",
        "Jianguo Zhang",
        "Ariel N. Lee",
        "Campbell S. Lund",
        "Christopher Klamm",
        "Damien Sileo",
        "Diganta Misra",
        "Enrico Shippole",
        "Kevin Klyman",
        "Lester JV Miranda",
        "Niklas Muennighoff",
        "Seonghyeon Ye",
        "Seungone Kim",
        "Vipul Gupta",
        "Vivek Sharma",
        "Xuhui Zhou",
        "Caiming Xiong",
        "Luis Villa",
        "Stella Biderman",
        "Alex Pentland",
        "Sara Hooker",
        "Jad Kabbara"
      ],
      "abstract": "Progress in AI is driven largely by the scale and quality of training data.\nDespite this, there is a deficit of empirical analysis examining the attributes\nof well-established datasets beyond text. In this work we conduct the largest\nand first-of-its-kind longitudinal audit across modalities--popular text,\nspeech, and video datasets--from their detailed sourcing trends and use\nrestrictions to their geographical and linguistic representation. Our manual\nanalysis covers nearly 4000 public datasets between 1990-2024, spanning 608\nlanguages, 798 sources, 659 organizations, and 67 countries. We find that\nmultimodal machine learning applications have overwhelmingly turned to\nweb-crawled, synthetic, and social media platforms, such as YouTube, for their\ntraining sets, eclipsing all other sources since 2019. Secondly, tracing the\nchain of dataset derivations we find that while less than 33% of datasets are\nrestrictively licensed, over 80% of the source content in widely-used text,\nspeech, and video datasets, carry non-commercial restrictions. Finally, counter\nto the rising number of languages and geographies represented in public AI\ntraining datasets, our audit demonstrates measures of relative geographical and\nmultilingual representation have failed to significantly improve their coverage\nsince 2013. We believe the breadth of our audit enables us to empirically\nexamine trends in data sourcing, restrictions, and Western-centricity at an\necosystem-level, and that visibility into these questions are essential to\nprogress in responsible AI. As a contribution to ongoing improvements in\ndataset transparency and responsible use, we release our entire multimodal\naudit, allowing practitioners to trace data provenance across text, speech, and\nvideo.",
      "tldr_zh": "这篇论文通过对1990-2024年间近4000个文本、语音和视频数据集进行首次大规模纵向审计，分析了它们的来源趋势、使用限制、地理和语言表示，涵盖608种语言、798个来源、659个组织和67个国家。研究发现，多模态机器学习应用越来越多地依赖网络爬取、合成数据和社会媒体（如YouTube）作为训练集，自2019年起主导整个生态，而超过80%的源内容存在非商业限制，尽管不到33%的数据集有严格许可。审计还揭示，尽管语言和地理覆盖有所增加，但相对的多语言和地理代表性自2013年以来未显著改善。作者发布了完整的多模态审计结果，以促进数据provenance的追踪，提升数据集透明度和负责任AI的发展。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CY",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "cs.AI",
      "comment": "ICLR 2025. 10 pages, 5 figures (main paper)",
      "pdf_url": "http://arxiv.org/pdf/2412.17847v2",
      "published_date": "2024-12-19 01:30:19 UTC",
      "updated_date": "2025-02-19 03:05:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:36:36.798963"
    },
    {
      "arxiv_id": "2412.16231v1",
      "title": "A Proposal for Extending the Common Model of Cognition to Emotion",
      "title_zh": "一个将共同认知模型扩展到情绪的提案",
      "authors": [
        "Paul S. Rosenbloom",
        "John E. Laird",
        "Christian Lebiere",
        "Andrea Stocco",
        "Richard H. Granger",
        "Christian Huyck"
      ],
      "abstract": "Cognition and emotion must be partnered in any complete model of a humanlike\nmind. This article proposes an extension to the Common Model of Cognition -- a\ndeveloping consensus concerning what is required in such a mind -- for emotion\nthat includes a linked pair of modules for emotion and metacognitive\nassessment, plus pervasive connections between these two new modules and the\nCommon Model's existing modules and links.",
      "tldr_zh": "这篇文章提出扩展 Common Model of Cognition 以整合情感，强调认知和情感是构建完整类人智能模型的必要组成部分。提案包括添加一对新模块：一个负责 emotion，另一个负责 metacognitive assessment，并与现有模块建立广泛连接。这种扩展旨在增强模型的全面性，为更真实的人类心智模拟提供基础。",
      "categories": [
        "cs.AI",
        "q-bio.NC"
      ],
      "primary_category": "cs.AI",
      "comment": "A version of this article was published in Proceedings of the 22nd\n  International Conference on Cognitive Modeling (2024)",
      "pdf_url": "http://arxiv.org/pdf/2412.16231v1",
      "published_date": "2024-12-19 00:54:32 UTC",
      "updated_date": "2024-12-19 00:54:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:36:47.153888"
    },
    {
      "arxiv_id": "2412.14426v2",
      "title": "All-in-One Tuning and Structural Pruning for Domain-Specific LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Lei Lu",
        "Zhepeng Wang",
        "Runxue Bao",
        "Mengbing Wang",
        "Fangyi Li",
        "Yawen Wu",
        "Weiwen Jiang",
        "Jie Xu",
        "Yanzhi Wang",
        "Shangqian Gao"
      ],
      "abstract": "Existing pruning techniques for large language models (LLMs) targeting\ndomain-specific applications typically follow a two-stage process: pruning the\npretrained general-purpose LLMs and then fine-tuning the pruned LLMs on\nspecific domains. However, the pruning decisions, derived from the pretrained\nweights, remain unchanged during fine-tuning, even if the weights have been\nupdated. Therefore, such a combination of the pruning decisions and the\nfinetuned weights may be suboptimal, leading to non-negligible performance\ndegradation. To address these limitations, we propose ATP: All-in-One Tuning\nand Structural Pruning, a unified one-stage structural pruning and fine-tuning\napproach that dynamically identifies the current optimal substructure\nthroughout the fine-tuning phase via a trainable pruning decision generator.\nMoreover, given the limited available data for domain-specific applications,\nLow-Rank Adaptation (LoRA) becomes a common technique to fine-tune the LLMs. In\nATP, we introduce LoRA-aware forward and sparsity regularization to ensure that\nthe substructures corresponding to the learned pruning decisions can be\ndirectly removed after the ATP process. ATP outperforms the state-of-the-art\ntwo-stage pruning methods on tasks in the legal and healthcare domains. More\nspecifically, ATP recovers up to 88% and 91% performance of the dense model\nwhen pruning 40% parameters of LLaMA2-7B and LLaMA3-8B models, respectively.",
      "tldr_zh": "该研究针对特定领域的大语言模型(LLMs)修剪问题，提出了一种统一的单阶段方法All-in-One Tuning and Structural Pruning (ATP)，它在微调过程中动态优化修剪决策，避免了传统两阶段方法中修剪决策与微调权重不匹配导致的性能下降。ATP 引入可训练的修剪决策生成器，并结合Low-Rank Adaptation (LoRA)技术及LoRA-aware 正则化，确保修剪后子结构可直接移除，从而提高模型效率。实验结果显示，在法律和医疗领域任务上，ATP 优于现有方法；具体而言，在修剪40%参数时，LLaMA2-7B和LLaMA3-8B模型分别恢复了88%和91%的密集模型性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Updated a typo in the author list;",
      "pdf_url": "http://arxiv.org/pdf/2412.14426v2",
      "published_date": "2024-12-19 00:41:40 UTC",
      "updated_date": "2024-12-20 15:57:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:36:59.837791"
    },
    {
      "arxiv_id": "2412.14424v1",
      "title": "FedPIA -- Permuting and Integrating Adapters leveraging Wasserstein Barycenters for Finetuning Foundation Models in Multi-Modal Federated Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Pramit Saha",
        "Divyanshu Mishra",
        "Felix Wagner",
        "Konstantinos Kamnitsas",
        "J. Alison Noble"
      ],
      "abstract": "Large Vision-Language Models typically require large text and image datasets\nfor effective fine-tuning. However, collecting data from various sites,\nespecially in healthcare, is challenging due to strict privacy regulations. An\nalternative is to fine-tune these models on end-user devices, such as in\nmedical clinics, without sending data to a server. These local clients\ntypically have limited computing power and small datasets, which are not enough\nfor fully fine-tuning large VLMs on their own. A naive solution to these\nscenarios is to leverage parameter-efficient fine-tuning (PEFT) strategies and\napply federated learning (FL) algorithms to combine the learned adapter\nweights, thereby respecting the resource limitations and data privacy. However,\nthis approach does not fully leverage the knowledge from multiple adapters\ntrained on diverse data distributions and for diverse tasks. The adapters are\nadversely impacted by data heterogeneity and task heterogeneity across clients\nresulting in suboptimal convergence. To this end, we propose a novel framework\ncalled FedPIA that improves upon the naive combinations of FL and PEFT by\nintroducing Permutation and Integration of the local Adapters in the server and\nglobal Adapters in the clients exploiting Wasserstein barycenters for improved\nblending of client-specific and client-agnostic knowledge. This layerwise\npermutation helps to bridge the gap in the parameter space of local and global\nadapters before integration. We conduct over 2000 client-level experiments\nutilizing 48 medical image datasets across five different medical\nvision-language FL task settings encompassing visual question answering as well\nas image and report-based multi-label disease detection. Our experiments\ninvolving diverse client settings, ten different modalities, and two VLM\nbackbones demonstrate that FedPIA consistently outperforms the state-of-the-art\nPEFT-FL baselines.",
      "tldr_zh": "本研究提出FedPIA框架，旨在解决大型视觉语言模型（VLMs）在多模态联邦学习（FL）中的微调挑战，特别是数据隐私限制和客户端资源不足的问题。FedPIA通过在服务器和客户端上排列和整合适配器（Permuting and Integrating Adapters），利用Wasserstein Barycenters实现对客户端特定和客户端无关知识的优化融合，从而缓解数据异质性和任务异质性带来的影响。实验涉及超过2000个客户端设置、48个医疗图像数据集和多种任务（如视觉问答和多标签疾病检测），结果显示FedPIA在十种模态和两种VLM骨干网络上 consistently 优于现有参数高效微调（PEFT）-FL基线。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted for publication in AAAI 2025 (Main Track)",
      "pdf_url": "http://arxiv.org/pdf/2412.14424v1",
      "published_date": "2024-12-19 00:24:00 UTC",
      "updated_date": "2024-12-19 00:24:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:37:12.059964"
    },
    {
      "arxiv_id": "2412.14422v1",
      "title": "Enhancing Diffusion Models for High-Quality Image Generation",
      "title_zh": "增强扩散模型用于高质量图像生成",
      "authors": [
        "Jaineet Shah",
        "Michael Gromis",
        "Rickston Pinto"
      ],
      "abstract": "This report presents the comprehensive implementation, evaluation, and\noptimization of Denoising Diffusion Probabilistic Models (DDPMs) and Denoising\nDiffusion Implicit Models (DDIMs), which are state-of-the-art generative\nmodels. During inference, these models take random noise as input and\niteratively generate high-quality images as output. The study focuses on\nenhancing their generative capabilities by incorporating advanced techniques\nsuch as Classifier-Free Guidance (CFG), Latent Diffusion Models with\nVariational Autoencoders (VAE), and alternative noise scheduling strategies.\nThe motivation behind this work is the growing demand for efficient and\nscalable generative AI models that can produce realistic images across diverse\ndatasets, addressing challenges in applications such as art creation, image\nsynthesis, and data augmentation. Evaluations were conducted on datasets\nincluding CIFAR-10 and ImageNet-100, with a focus on improving inference speed,\ncomputational efficiency, and image quality metrics like Frechet Inception\nDistance (FID). Results demonstrate that DDIM + CFG achieves faster inference\nand superior image quality. Challenges with VAE and noise scheduling are also\nhighlighted, suggesting opportunities for future optimization. This work lays\nthe groundwork for developing scalable, efficient, and high-quality generative\nAI systems to benefit industries ranging from entertainment to robotics.",
      "tldr_zh": "这篇论文探讨了如何增强Denoising Diffusion Probabilistic Models (DDPMs) 和Denoising Diffusion Implicit Models (DDIMs)，以生成高质量图像。研究通过引入Classifier-Free Guidance (CFG)、Latent Diffusion Models with Variational Autoencoders (VAE)以及优化噪声调度策略，改善了模型的生成能力，并解决了推理速度和计算效率的挑战。在CIFAR-10和ImageNet-100数据集上的评估显示，DDIM结合CFG实现了更快的推理和更低的Frechet Inception Distance (FID)分数，显著提升图像质量。该工作为高效生成AI模型在艺术创作、图像合成和数据增强等领域提供了重要基础。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.14422v1",
      "published_date": "2024-12-19 00:23:15 UTC",
      "updated_date": "2024-12-19 00:23:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:37:24.087817"
    },
    {
      "arxiv_id": "2412.14415v3",
      "title": "DriveGPT: Scaling Autoregressive Behavior Models for Driving",
      "title_zh": "翻译失败",
      "authors": [
        "Xin Huang",
        "Eric M. Wolff",
        "Paul Vernaza",
        "Tung Phan-Minh",
        "Hongge Chen",
        "David S. Hayden",
        "Mark Edmonds",
        "Brian Pierce",
        "Xinxin Chen",
        "Pratik Elias Jacob",
        "Xiaobai Chen",
        "Chingiz Tairbekov",
        "Pratik Agarwal",
        "Tianshi Gao",
        "Yuning Chai",
        "Siddhartha Srinivasa"
      ],
      "abstract": "We present DriveGPT, a scalable behavior model for autonomous driving. We\nmodel driving as a sequential decision-making task, and learn a transformer\nmodel to predict future agent states as tokens in an autoregressive fashion. We\nscale up our model parameters and training data by multiple orders of\nmagnitude, enabling us to explore the scaling properties in terms of dataset\nsize, model parameters, and compute. We evaluate DriveGPT across different\nscales in a planning task, through both quantitative metrics and qualitative\nexamples, including closed-loop driving in complex real-world scenarios. In a\nseparate prediction task, DriveGPT outperforms state-of-the-art baselines and\nexhibits improved performance by pretraining on a large-scale dataset, further\nvalidating the benefits of data scaling.",
      "tldr_zh": "该研究提出 DriveGPT，一种可扩展的自回归行为模型，用于自动驾驶，通过 transformer 模型将驾驶建模为顺序决策任务，并以 autoregressive 方式预测未来代理状态。研究者通过大幅增加模型参数、训练数据和计算资源，探索了缩放特性的影响，并在规划任务中（如复杂真实场景的闭环驾驶）和预测任务中评估模型。结果表明，DriveGPT 优于现有基线模型，且通过大规模数据集预训练进一步提升性能，验证了数据缩放的好处。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "ICML 2025. 14 pages, 17 figures, 8 tables, and 1 video link",
      "pdf_url": "http://arxiv.org/pdf/2412.14415v3",
      "published_date": "2024-12-19 00:06:09 UTC",
      "updated_date": "2025-05-02 01:02:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T15:37:35.692789"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 128,
  "processed_papers_count": 128,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-21T15:37:59.348800"
}