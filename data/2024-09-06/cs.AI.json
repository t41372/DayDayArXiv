{
  "date": "2024-09-06",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-09-06 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文主要聚焦于 AI 模型优化、LLM 在医疗和科学领域的创新应用、强化学习算法改进以及量子计算安全等主题，其中最令人印象深刻的是关于 LLM 生成研究想法的实验性工作，以及 Shankar Sastry 等著名学者在多智能体强化学习的贡献，这些论文展示了 AI 在实际应用中的潜力。\n\n下面，我将挑选并讨论几篇重要的、话题度高的论文，先从 LLM 相关和 AI 优化入手，再聊医疗与科学应用，最后快速掠过其他次要论文。每个条目会简要列出论文标题（中文 + 英文）和核心贡献。\n\n### LLM 和 AI 优化领域\n- **The emergence of Large Language Models (LLM) as a tool in literature reviews（大型语言模型在文献综述中的应用）**  \n  这篇论文通过系统综述探讨了 LLM 在文献综述中的自动化潜力，核心贡献是分析 LLM 在搜索和数据提取阶段的性能，实验显示 GPT-基于模型在精度和召回率上表现出色，为科研文献处理提供高效工具。\n\n- **Beyond Following: Mixing Active Initiative into Computational Creativity（超越跟随：将主动性融入计算创意）**  \n  作者探索了 LLM 在混合主动学习中的作用，主要发现是，通过强化学习增强 LLM 的主动性，能显著提高用户在故事创作中的满意度，实验结果显示学习型代理提升了 74% 的交互体验。\n\n- **Convergence of Decentralized Actor-Critic Algorithm in General-sum Markov Games（去中心化 Actor-Critic 算法在广义和博弈中的收敛）**  \n  作者包括著名学者 Shankar Sastry，这篇论文的关键贡献是引入 Markov Near-Potential Function 作为近似 Lyapunov 函数，证明了去中心化算法在复杂多智能体环境中的收敛性，为强化学习提供了更强的理论基础。\n\n- **Efficient Training of Large Vision Models via Advanced Automated Progressive Learning（通过高级自动渐进学习高效训练大型视觉模型）**  \n  这篇论文提出 AutoProg 框架，用于优化视觉模型训练，核心发现是它能加速 ViT 和扩散模型的训练，同时保持性能，实验显示在 ImageNet 上提速高达 1.85 倍，具有实际应用价值。\n\n### 医疗和科学应用\n- **Evaluating the Impact of a Specialized LLM on Physician Experience in Clinical Decision Support（评估专用 LLM 对医生经验的影响）**  \n  论文比较了专用 LLM（如 Ask Avo）和 ChatGPT-4 在临床决策中的表现，主要贡献是证明专用 LLM 在可信度和相关性上显著优于通用模型，实验结果显示 Ask Avo 在多个指标上提升 20% 以上，提升了医疗辅助系统的实用性。\n\n- **Question-Answering Dense Video Events（基于问题回答的密集视频事件处理）**  \n  作者开发了 DeVE-QA 数据集和 DeVi 模型，核心发现是新模型在处理长视频的多事件推理时优于现有 MLLM，提升了视频理解的准确性，适用于医疗和监控场景。\n\n- **Enhancing Quantum Security over Federated Learning via Post-Quantum Cryptography（通过后量子密码增强联邦学习的量子安全）**  \n  这篇论文测试了后量子密码算法在联邦学习中的影响，主要贡献是证明 Dilithium 算法是最有效的选项，能保护模型更新免受量子攻击，为隐私保护型 AI 提供了新方向。\n\n其他论文如量子机器学习训练方法（Training quantum machine learning models on cloud without uploading the data）和多机器人任务分配模拟器（SPACE）等，也值得一提，它们分别解决了数据隐私和模拟效率问题，但细节较技术化，我这里快速掠过。同样，涉及图像生成、边检测和表格语义的论文（如 UI-JEPA 和 CPD-Net）虽有创新，但影响力较小，仅补充说它们在视觉任务中提升了精度和泛化能力。\n\n总之，今天的论文突出了 AI 模型在实际应用中的进步，尤其是 LLM 的多领域潜力。如果你对 LLM 在科研或医疗的创新感兴趣，不妨关注前述几篇！下次快报见。",
  "papers": [
    {
      "arxiv_id": "2409.04653v1",
      "title": "Solving Stochastic Orienteering Problems with Chance Constraints Using a GNN Powered Monte Carlo Tree Search",
      "title_zh": "使用基于 GNN 的蒙特卡洛树搜索解决带有机会约束的随机定向问题",
      "authors": [
        "Marcos Abel Zuzuárregui",
        "Stefano Carpin"
      ],
      "abstract": "Leveraging the power of a graph neural network (GNN) with message passing, we\npresent a Monte Carlo Tree Search (MCTS) method to solve stochastic\norienteering problems with chance constraints. While adhering to an assigned\ntravel budget the algorithm seeks to maximize collected reward while incurring\nstochastic travel costs. In this context, the acceptable probability of\nexceeding the assigned budget is expressed as a chance constraint. Our MCTS\nsolution is an online and anytime algorithm alternating planning and execution\nthat determines the next vertex to visit by continuously monitoring the\nremaining travel budget. The novelty of our work is that the rollout phase in\nthe MCTS framework is implemented using a message passing GNN, predicting both\nthe utility and failure probability of each available action. This allows to\nenormously expedite the search process. Our experimental evaluation shows that\nwith the proposed method and architecture we manage to efficiently solve\ncomplex problem instances while incurring in moderate losses in terms of\ncollected reward. Moreover, we demonstrate how the approach is capable of\ngeneralizing beyond the characteristics of the training dataset. The paper's\nwebsite, open-source code, and supplementary documentation can be found at\nucmercedrobotics.github.io/gnn-sop.",
      "tldr_zh": "本文提出了一种结合图神经网络 (GNN) 和 Monte Carlo Tree Search (MCTS) 的方法，用于解决带概率约束的随机定向问题 (stochastic orienteering problems)，旨在在遵守旅行预算的前提下最大化奖励收集，同时处理随机旅行成本。创新点在于，使用消息传递 GNN 在 MCTS 的 rollout 阶段预测每个动作的效用和失败概率，从而显著加速搜索过程。实验结果表明，该方法能高效解决复杂问题实例，具有良好的泛化能力，尽管在奖励收集方面存在适度损失，并提供了开源代码以供进一步应用。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "8 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.04653v1",
      "published_date": "2024-09-06 23:31:01 UTC",
      "updated_date": "2024-09-06 23:31:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:47:20.426955"
    },
    {
      "arxiv_id": "2409.04641v1",
      "title": "Stacked Universal Successor Feature Approximators for Safety in Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Ian Cannon",
        "Washington Garcia",
        "Thomas Gresavage",
        "Joseph Saurine",
        "Ian Leong",
        "Jared Culbertson"
      ],
      "abstract": "Real-world problems often involve complex objective structures that resist\ndistillation into reinforcement learning environments with a single objective.\nOperation costs must be balanced with multi-dimensional task performance and\nend-states' effects on future availability, all while ensuring safety for other\nagents in the environment and the reinforcement learning agent itself. System\nredundancy through secondary backup controllers has proven to be an effective\nmethod to ensure safety in real-world applications where the risk of violating\nconstraints is extremely high. In this work, we investigate the utility of a\nstacked, continuous-control variation of universal successor feature\napproximation (USFA) adapted for soft actor-critic (SAC) and coupled with a\nsuite of secondary safety controllers, which we call stacked USFA for safety\n(SUSFAS). Our method improves performance on secondary objectives compared to\nSAC baselines using an intervening secondary controller such as a runtime\nassurance (RTA) controller.",
      "tldr_zh": "该研究针对强化学习中复杂目标结构的挑战（如平衡操作成本、多维任务性能和安全性），提出了一种堆叠的通用后继特征逼近器（Stacked Universal Successor Feature Approximators for Safety，SUSFAS）。SUSFAS 基于 Universal Successor Feature Approximation (USFA) 的连续控制变体，适配 Soft Actor-Critic (SAC) 算法，并结合次要安全控制器（如 Runtime Assurance 控制器），以确保系统冗余和约束安全。实验结果显示，SUSFAS 在次要目标上比 SAC 基线性能有所提升，为真实世界强化学习应用中的安全性和多目标优化提供了有效方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "13 pages",
      "pdf_url": "http://arxiv.org/pdf/2409.04641v1",
      "published_date": "2024-09-06 22:20:07 UTC",
      "updated_date": "2024-09-06 22:20:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:47:30.883731"
    },
    {
      "arxiv_id": "2409.04637v1",
      "title": "Enhancing Quantum Security over Federated Learning via Post-Quantum Cryptography",
      "title_zh": "翻译失败",
      "authors": [
        "Pingzhi Li",
        "Tianlong Chen",
        "Junyu Liu"
      ],
      "abstract": "Federated learning (FL) has become one of the standard approaches for\ndeploying machine learning models on edge devices, where private training data\nare distributed across clients, and a shared model is learned by aggregating\nlocally computed updates from each client. While this paradigm enhances\ncommunication efficiency by only requiring updates at the end of each training\nepoch, the transmitted model updates remain vulnerable to malicious tampering,\nposing risks to the integrity of the global model. Although current digital\nsignature algorithms can protect these communicated model updates, they fail to\nensure quantum security in the era of large-scale quantum computing.\nFortunately, various post-quantum cryptography algorithms have been developed\nto address this vulnerability, especially the three NIST-standardized\nalgorithms - Dilithium, FALCON, and SPHINCS+. In this work, we empirically\ninvestigate the impact of these three NIST-standardized PQC algorithms for\ndigital signatures within the FL procedure, covering a wide range of models,\ntasks, and FL settings. Our results indicate that Dilithium stands out as the\nmost efficient PQC algorithm for digital signature in federated learning.\nAdditionally, we offer an in-depth discussion of the implications of our\nfindings and potential directions for future research.",
      "tldr_zh": "该研究探讨了在联邦学习（Federated Learning）中通过后量子密码学（Post-Quantum Cryptography）提升量子安全性的方法，以保护模型更新免受恶意篡改。作者评估了NIST标准化的三款数字签名算法——Dilithium、FALCON和SPHINCS+——在各种模型、任务和FL设置下的性能。结果显示，Dilithium是最有效的算法，能够显著提高通信效率。该工作还讨论了这些发现的潜在影响，并提出了未来研究的可能方向。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.CR",
        "cs.LG"
      ],
      "primary_category": "quant-ph",
      "comment": "Submission for IEEE 2024 IEEE Workshop on Quantum IntelLigence,\n  Learning & Security (QUILLS), https://sites.google.com/pitt.edu/quills/home",
      "pdf_url": "http://arxiv.org/pdf/2409.04637v1",
      "published_date": "2024-09-06 22:02:08 UTC",
      "updated_date": "2024-09-06 22:02:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:47:43.025646"
    },
    {
      "arxiv_id": "2409.04631v2",
      "title": "Zero-Shot Whole Slide Image Retrieval in Histopathology Using Embeddings of Foundation Models",
      "title_zh": "翻译失败",
      "authors": [
        "Saghir Alfasly",
        "Ghazal Alabtah",
        "Sobhan Hemati",
        "Krishna Rani Kalari",
        "H. R. Tizhoosh"
      ],
      "abstract": "We have tested recently published foundation models for histopathology for\nimage retrieval. We report macro average of F1 score for top-1 retrieval,\nmajority of top-3 retrievals, and majority of top-5 retrievals. We perform\nzero-shot retrievals, i.e., we do not alter embeddings and we do not train any\nclassifier. As test data, we used diagnostic slides of TCGA, The Cancer Genome\nAtlas, consisting of 23 organs and 117 cancer subtypes. As a search platform we\nused Yottixel that enabled us to perform WSI search using patches. Achieved F1\nscores show low performance, e.g., for top-5 retrievals, 27% +/- 13%\n(Yottixel-DenseNet), 42% +/- 14% (Yottixel-UNI), 40%+/-13% (Yottixel-Virchow),\n41%+/-13% (Yottixel-GigaPath), and 41%+/-14% (GigaPath WSI).",
      "tldr_zh": "这篇论文评估了基础模型的嵌入在病理学领域的零-shot 全滑片图像（Whole Slide Image, WSI）检索性能，而不进行任何模型微调或分类器训练。研究使用 TCGA（The Cancer Genome Atlas）数据集，包括 23 个器官和 117 个癌症亚型，作为测试数据，并通过 Yottixel 平台基于 patches 进行检索。结果显示性能较低，例如 top-5 检索的 F1 score 宏观平均值为 27% +/- 13%（Yottixel-DenseNet）、42% +/- 14%（Yottixel-UNI）等，这突出了现有基础模型在零-shot 检索任务中的局限性，并为未来改进提供了参考。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "This paper will be updated with more results",
      "pdf_url": "http://arxiv.org/pdf/2409.04631v2",
      "published_date": "2024-09-06 21:43:00 UTC",
      "updated_date": "2024-09-12 15:37:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:47:57.500898"
    },
    {
      "arxiv_id": "2409.04615v1",
      "title": "A Short Survey on Set-Based Aggregation Techniques for Single-Vector WSI Representation in Digital Pathology",
      "title_zh": "翻译失败",
      "authors": [
        "S. Hemati",
        "Krishna R. Kalari",
        "H. R. Tizhoosh"
      ],
      "abstract": "Digital pathology is revolutionizing the field of pathology by enabling the\ndigitization, storage, and analysis of tissue samples as whole slide images\n(WSIs). WSIs are gigapixel files that capture the intricate details of tissue\nsamples, providing a rich source of information for diagnostic and research\npurposes. However, due to their enormous size, representing these images as one\ncompact vector is essential for many computational pathology tasks, such as\nsearch and retrieval, to ensure efficiency and scalability. Most current\nmethods are \"patch-oriented,\" meaning they divide WSIs into smaller patches for\nprocessing, which prevents a holistic analysis of the entire slide.\nAdditionally, the necessity for compact representation is driven by the\nexpensive high-performance storage required for WSIs. Not all hospitals have\naccess to such extensive storage solutions, leading to potential disparities in\nhealthcare quality and accessibility. This paper provides an overview of\nexisting set-based approaches to single-vector WSI representation, highlighting\nthe innovations that allow for more efficient and effective use of these\ncomplex images in digital pathology, thus addressing both computational\nchallenges and storage limitations.",
      "tldr_zh": "该论文概述了数字病理学中基于集合的聚合技术（Set-Based Aggregation Techniques），用于将巨像素全滑微图像（Whole Slide Images, WSIs）表示为单一紧凑向量，以提升计算效率和可扩展性。现有方法多采用“patch-oriented”策略，即将WSIs分割成小块处理，这导致无法进行整体分析，并加剧了存储成本问题，可能造成医疗资源不均。论文强调这些创新技术通过集合聚合方法解决了计算挑战和存储限制，促进WSIs在诊断和研究中的高效应用，从而改善医疗公平性和可访问性。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.04615v1",
      "published_date": "2024-09-06 20:56:25 UTC",
      "updated_date": "2024-09-06 20:56:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:48:06.597761"
    },
    {
      "arxiv_id": "2409.04613v5",
      "title": "Convergence of Decentralized Actor-Critic Algorithm in General-sum Markov Games",
      "title_zh": "翻译失败",
      "authors": [
        "Chinmay Maheshwari",
        "Manxi Wu",
        "Shankar Sastry"
      ],
      "abstract": "Markov games provide a powerful framework for modeling strategic multi-agent\ninteractions in dynamic environments. Traditionally, convergence properties of\ndecentralized learning algorithms in these settings have been established only\nfor special cases, such as Markov zero-sum and potential games, which do not\nfully capture real-world interactions. In this paper, we address this gap by\nstudying the asymptotic properties of learning algorithms in general-sum Markov\ngames. In particular, we focus on a decentralized algorithm where each agent\nadopts an actor-critic learning dynamic with asynchronous step sizes. This\ndecentralized approach enables agents to operate independently, without\nrequiring knowledge of others' strategies or payoffs. We introduce the concept\nof a Markov Near-Potential Function (MNPF) and demonstrate that it serves as an\napproximate Lyapunov function for the policy updates in the decentralized\nlearning dynamics, which allows us to characterize the convergent set of\nstrategies. We further strengthen our result under specific regularity\nconditions and with finite Nash equilibria.",
      "tldr_zh": "本文研究了在一般和游戏（general-sum Markov games）中去中心化 actor-critic 算法的收敛性，填补了传统研究仅限于特殊情况（如零和游戏或势函数游戏）的空白。算法允许每个代理采用异步步长的 actor-critic 学习动态，独立操作而不需知道其他代理的策略或收益。作者引入 Markov Near-Potential Function (MNPF) 作为近似 Lyapunov 函数，证明了策略更新的收敛集，并在特定条件和有限 Nash equilibria 下强化了这一结果。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.GT",
        "cs.SY",
        "eess.SY",
        "math.OC",
        "91A06, 91A10, 91A14, 91A15, 91A20, 91A40, 91A50, 93E03, 37N40"
      ],
      "primary_category": "cs.MA",
      "comment": "18 pages, 3 figure",
      "pdf_url": "http://arxiv.org/pdf/2409.04613v5",
      "published_date": "2024-09-06 20:49:11 UTC",
      "updated_date": "2025-04-01 00:36:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:48:18.792735"
    },
    {
      "arxiv_id": "2409.04609v1",
      "title": "Detection of False Data Injection Attacks (FDIA) on Power Dynamical Systems With a State Prediction Method",
      "title_zh": "翻译失败",
      "authors": [
        "Abhijeet Sahu",
        "Truc Nguyen",
        "Kejun Chen",
        "Xiangyu Zhang",
        "Malik Hassanaly"
      ],
      "abstract": "With the deeper penetration of inverter-based resources in power systems,\nfalse data injection attacks (FDIA) are a growing cyber-security concern. They\nhave the potential to disrupt the system's stability like frequency stability,\nthereby leading to catastrophic failures. Therefore, an FDIA detection method\nwould be valuable to protect power systems. FDIAs typically induce a\ndiscrepancy between the desired and the effective behavior of the power system\ndynamics. A suitable detection method can leverage power dynamics predictions\nto identify whether such a discrepancy was induced by an FDIA. This work\ninvestigates the efficacy of temporal and spatio-temporal state prediction\nmodels, such as Long Short-Term Memory (LSTM) and a combination of Graph Neural\nNetworks (GNN) with LSTM, for predicting frequency dynamics in the absence of\nan FDIA but with noisy measurements, and thereby identify FDIA events. For\ndemonstration purposes, the IEEE 39 New England Kron-reduced model simulated\nwith a swing equation is considered. It is shown that the proposed state\nprediction models can be used as a building block for developing an effective\nFDIA detection method that can maintain high detection accuracy across various\nattack and deployment settings. It is also shown how the FDIA detection should\nbe deployed to limit its exposure to detection inaccuracies and mitigate its\ncomputational burden.",
      "tldr_zh": "该研究针对电力系统中的假数据注入攻击（FDIA），提出了一种基于状态预测的方法，以应对攻击对系统稳定性的威胁，如频率稳定性。方法利用Long Short-Term Memory (LSTM) 和Graph Neural Networks (GNN) 与 LSTM 的组合模型，对系统频率动态进行时空预测，从而在噪声测量环境下检测FDIA。实验基于IEEE 39 New England Kron-reduced 模型显示，该方法在各种攻击场景下保持高检测准确率，并提供了优化部署策略以减少计算负担和检测误差。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "Under review",
      "pdf_url": "http://arxiv.org/pdf/2409.04609v1",
      "published_date": "2024-09-06 20:47:21 UTC",
      "updated_date": "2024-09-06 20:47:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:48:30.100528"
    },
    {
      "arxiv_id": "2409.04602v2",
      "title": "Training quantum machine learning models on cloud without uploading the data",
      "title_zh": "在云端训练量子机器学习模型而不上传数据",
      "authors": [
        "Guang Ping He"
      ],
      "abstract": "Based on the linearity of quantum unitary operations, we propose a method\nthat runs the parameterized quantum circuits before encoding the input data.\nThis enables a dataset owner to train machine learning models on quantum cloud\ncomputation platforms, without the risk of leaking the information about the\ndata. It is also capable of encoding a vast amount of data effectively at a\nlater time using classical computations, thus saving runtime on quantum\ncomputation devices. The trained quantum machine learning models can be run\ncompletely on classical computers, meaning the dataset owner does not need to\nhave any quantum hardware, nor even quantum simulators. Moreover, our method\nmitigates the encoding bottleneck by reducing the required circuit depth from\n$O(2^{n})$ to $O(n)$, and relax the tolerance on the precision of the quantum\ngates for the encoding. These results demonstrate yet another advantage of\nquantum and quantum-inspired machine learning models over existing classical\nneural networks, and broaden the approaches to data security.",
      "tldr_zh": "本研究提出了一种基于量子单元操作线性性的方法，通过在编码输入数据前运行参数化量子电路（parameterized quantum circuits），使数据所有者能够在量子云平台上训练量子机器学习模型，而无需上传数据，从而避免信息泄露。该方法还允许后期使用经典计算高效编码大量数据，节省量子计算资源，并将所需电路深度从 O(2^n) 减少到 O(n)，同时放宽对量子门精度的要求。结果显示，训练后的模型可在完全经典计算机上运行，这不仅提升了数据安全性，还展示了量子和量子灵感机器学习模型相对于经典神经网络的显著优势。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.CR",
        "cs.LG"
      ],
      "primary_category": "quant-ph",
      "comment": "Added experimental results and the flow chart of our method",
      "pdf_url": "http://arxiv.org/pdf/2409.04602v2",
      "published_date": "2024-09-06 20:14:52 UTC",
      "updated_date": "2024-10-07 20:19:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:48:42.836621"
    },
    {
      "arxiv_id": "2409.04600v1",
      "title": "The emergence of Large Language Models (LLM) as a tool in literature reviews: an LLM automated systematic review",
      "title_zh": "翻译失败",
      "authors": [
        "Dmitry Scherbakov",
        "Nina Hubig",
        "Vinita Jansari",
        "Alexander Bakumenko",
        "Leslie A. Lenert"
      ],
      "abstract": "Objective: This study aims to summarize the usage of Large Language Models\n(LLMs) in the process of creating a scientific review. We look at the range of\nstages in a review that can be automated and assess the current\nstate-of-the-art research projects in the field. Materials and Methods: The\nsearch was conducted in June 2024 in PubMed, Scopus, Dimensions, and Google\nScholar databases by human reviewers. Screening and extraction process took\nplace in Covidence with the help of LLM add-on which uses OpenAI gpt-4o model.\nChatGPT was used to clean extracted data and generate code for figures in this\nmanuscript, ChatGPT and Scite.ai were used in drafting all components of the\nmanuscript, except the methods and discussion sections. Results: 3,788 articles\nwere retrieved, and 172 studies were deemed eligible for the final review.\nChatGPT and GPT-based LLM emerged as the most dominant architecture for review\nautomation (n=126, 73.2%). A significant number of review automation projects\nwere found, but only a limited number of papers (n=26, 15.1%) were actual\nreviews that used LLM during their creation. Most citations focused on\nautomation of a particular stage of review, such as Searching for publications\n(n=60, 34.9%), and Data extraction (n=54, 31.4%). When comparing pooled\nperformance of GPT-based and BERT-based models, the former were better in data\nextraction with mean precision 83.0% (SD=10.4), and recall 86.0% (SD=9.8),\nwhile being slightly less accurate in title and abstract screening stage\n(Maccuracy=77.3%, SD=13.0). Discussion/Conclusion: Our LLM-assisted systematic\nreview revealed a significant number of research projects related to review\nautomation using LLMs. The results looked promising, and we anticipate that\nLLMs will change in the near future the way the scientific reviews are\nconducted.",
      "tldr_zh": "本研究旨在总结 Large Language Models (LLMs) 在科学文献综述中的应用，并评估其自动化各个阶段的潜力，通过在 2024 年 6 月的人工搜索和 LLM 辅助工具（如 OpenAI gpt-4o 和 ChatGPT）进行文献检索、筛选和数据提取。结果显示，从 3,788 篇检索文章中筛选出 172 篇符合标准，GPT-based 模型（如 ChatGPT）在数据提取任务中表现出色（精确率 83.0%，召回率 86.0%），但在标题和摘要筛选阶段的准确率较低（77.3%），而自动化主要集中在搜索出版物（34.9%）和数据提取（31.4%）等环节。总体而言，该研究证明 LLMs 已显示出显著潜力，并预示着未来文献综述过程将发生重大变革。",
      "categories": [
        "cs.DL",
        "cs.AI"
      ],
      "primary_category": "cs.DL",
      "comment": "18 main pages with 5 figures and 1 table, references, followed by\n  supplementary materials",
      "pdf_url": "http://arxiv.org/pdf/2409.04600v1",
      "published_date": "2024-09-06 20:12:57 UTC",
      "updated_date": "2024-09-06 20:12:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:48:57.000944"
    },
    {
      "arxiv_id": "2409.04585v2",
      "title": "CubicML: Automated ML for Large ML Systems Co-design with ML Prediction of Performance",
      "title_zh": "翻译失败",
      "authors": [
        "Wei Wen",
        "Quanyu Zhu",
        "Weiwei Chu",
        "Wen-Yen Chen",
        "Jiyan Yang"
      ],
      "abstract": "Scaling up deep learning models has been proven effective to improve\nintelligence of machine learning (ML) models, especially for industry\nrecommendation models and large language models. The co-design of large\ndistributed ML systems and algorithms (to maximize training performance) plays\na pivotal role for its success. As it scales, the number of co-design\nhyper-parameters grows rapidly which brings challenges to feasibly find the\noptimal setup for system performance maximization. In this paper, we propose\nCubicML which uses ML to automatically optimize training performance of large\ndistributed ML systems. In CubicML, we use an ML model as a proxy to predict\nthe training performance for search efficiency and performance modeling\nflexibility. We proved that CubicML can effectively optimize training speed of\nin-house ads recommendation models with 73 billion parameters and large\nlanguage models up to 405 billion parameters at Meta.",
      "tldr_zh": "这篇论文提出了 CubicML，一种自动化 ML 方法，用于优化大型分布式 ML 系统的协同设计（co-design），以最大化训练性能。CubicML 通过使用 ML 模型作为代理（proxy）来预测训练性能，从而提高搜索效率和性能建模灵活性，避免手动调整海量超参数。实验结果显示，该方法在 Meta 的内部广告推荐模型（73 亿参数）和大型语言模型（405 亿参数）上显著提升了训练速度，为大规模 ML 系统的优化提供了有效解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.04585v2",
      "published_date": "2024-09-06 19:55:21 UTC",
      "updated_date": "2024-09-21 05:55:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:49:07.457863"
    },
    {
      "arxiv_id": "2409.04576v1",
      "title": "ActionFlow: Equivariant, Accurate, and Efficient Policies with Spatially Symmetric Flow Matching",
      "title_zh": "翻译失败",
      "authors": [
        "Niklas Funk",
        "Julen Urain",
        "Joao Carvalho",
        "Vignesh Prasad",
        "Georgia Chalvatzaki",
        "Jan Peters"
      ],
      "abstract": "Spatial understanding is a critical aspect of most robotic tasks,\nparticularly when generalization is important. Despite the impressive results\nof deep generative models in complex manipulation tasks, the absence of a\nrepresentation that encodes intricate spatial relationships between\nobservations and actions often limits spatial generalization, necessitating\nlarge amounts of demonstrations. To tackle this problem, we introduce a novel\npolicy class, ActionFlow. ActionFlow integrates spatial symmetry inductive\nbiases while generating expressive action sequences. On the representation\nlevel, ActionFlow introduces an SE(3) Invariant Transformer architecture, which\nenables informed spatial reasoning based on the relative SE(3) poses between\nobservations and actions. For action generation, ActionFlow leverages Flow\nMatching, a state-of-the-art deep generative model known for generating\nhigh-quality samples with fast inference - an essential property for feedback\ncontrol. In combination, ActionFlow policies exhibit strong spatial and\nlocality biases and SE(3)-equivariant action generation. Our experiments\ndemonstrate the effectiveness of ActionFlow and its two main components on\nseveral simulated and real-world robotic manipulation tasks and confirm that we\ncan obtain equivariant, accurate, and efficient policies with spatially\nsymmetric flow matching. Project website: https://flowbasedpolicies.github.io/",
      "tldr_zh": "该研究针对机器人任务中的空间理解和泛化问题，提出了一种新型策略类ActionFlow，以解决现有深度生成模型在编码观察与动作间复杂空间关系方面的不足。ActionFlow 整合了SE(3) Invariant Transformer 架构，用于基于相对SE(3) 位姿进行空间推理，以及Flow Matching 生成模型，以实现高品质动作序列生成和快速推理。实验结果显示，ActionFlow 在多个模拟和真实世界机器人操作任务中表现出色，实现了等变(SE(3)-equivariant)、准确且高效的政策，显著提升了空间泛化能力。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.04576v1",
      "published_date": "2024-09-06 19:30:36 UTC",
      "updated_date": "2024-09-06 19:30:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:49:20.758351"
    },
    {
      "arxiv_id": "2409.04572v1",
      "title": "Neurosymbolic Methods for Dynamic Knowledge Graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Mehwish Alam",
        "Genet Asefa Gesese",
        "Pierre-Henri Paris"
      ],
      "abstract": "Knowledge graphs (KGs) have recently been used for many tools and\napplications, making them rich resources in structured format. However, in the\nreal world, KGs grow due to the additions of new knowledge in the form of\nentities and relations, making these KGs dynamic. This chapter formally defines\nseveral types of dynamic KGs and summarizes how these KGs can be represented.\nAdditionally, many neurosymbolic methods have been proposed for learning\nrepresentations over static KGs for several tasks such as KG completion and\nentity alignment. This chapter further focuses on neurosymbolic methods for\ndynamic KGs with or without temporal information. More specifically, it\nprovides an insight into neurosymbolic methods for dynamic (temporal or\nnon-temporal) KG completion and entity alignment tasks. It further discusses\nthe challenges of current approaches and provides some future directions.",
      "tldr_zh": "本章论文探讨了动态知识图谱（Knowledge Graphs）的概念和应用，正式定义了其多种类型（如基于实体和关系增长的动态KGs），并总结了它们的表示方法。论文聚焦于神经符号方法（neurosymbolic methods）在动态KGs上的应用，包括有或无时间信息的KG完成和实体对齐任务，提供相关方法的洞见和总结。最终，它讨论了当前方法的挑战，如处理动态数据的不确定性，并提出未来研究方向以提升这些技术的鲁棒性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.04572v1",
      "published_date": "2024-09-06 19:24:29 UTC",
      "updated_date": "2024-09-06 19:24:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:49:32.180951"
    },
    {
      "arxiv_id": "2409.16291v1",
      "title": "Beyond Following: Mixing Active Initiative into Computational Creativity",
      "title_zh": "超越跟随：将主动举措融入计算创造性",
      "authors": [
        "Zhiyu Lin",
        "Upol Ehsan",
        "Rohan Agarwal",
        "Samihan Dani",
        "Vidushi Vashishth",
        "Mark Riedl"
      ],
      "abstract": "Generative Artificial Intelligence (AI) encounters limitations in efficiency\nand fairness within the realm of Procedural Content Generation (PCG) when human\ncreators solely drive and bear responsibility for the generative process.\nAlternative setups, such as Mixed-Initiative Co-Creative (MI-CC) systems,\nexhibited their promise. Still, the potential of an active mixed initiative,\nwhere AI takes a role beyond following, is understudied. This work investigates\nthe influence of the adaptive ability of an active and learning AI agent on\ncreators' expectancy of creative responsibilities in an MI-CC setting. We built\nand studied a system that employs reinforcement learning (RL) methods to learn\nthe creative responsibility preferences of a human user during online\ninteractions. Situated in story co-creation, we develop a Multi-armed-bandit\nagent that learns from the human creator, updates its collaborative\ndecision-making belief, and switches between its capabilities during an MI-CC\nexperience. With 39 participants joining a human subject study, Our developed\nsystem's learning capabilities are well recognized compared to the non-learning\nablation, corresponding to a significant increase in overall satisfaction with\nthe MI-CC experience. These findings indicate a robust association between\neffective MI-CC collaborative interactions, particularly the implementation of\nproactive AI initiatives, and deepened understanding among all participants.",
      "tldr_zh": "这篇论文探讨了在Procedural Content Generation (PCG) 中，生成式AI的被动角色导致效率和公平性问题，并提出让AI通过主动参与（active mixed initiative）提升Mixed-Initiative Co-Creative (MI-CC) 系统。研究开发了一个基于reinforcement learning (RL) 的Multi-armed-bandit 代理，该代理在故事共同创作场景中学习人类用户的创意责任偏好，并实时更新决策信念以切换能力。实验结果显示，与非学习版本相比，该系统在39名参与者中显著提高了整体满意度，并强化了协作互动和参与者理解。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "11 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.16291v1",
      "published_date": "2024-09-06 18:56:08 UTC",
      "updated_date": "2024-09-06 18:56:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:49:46.495793"
    },
    {
      "arxiv_id": "2409.13711v2",
      "title": "WebQuest: A Benchmark for Multimodal QA on Web Page Sequences",
      "title_zh": "翻译失败",
      "authors": [
        "Maria Wang",
        "Srinivas Sunkara",
        "Gilles Baechler",
        "Jason Lin",
        "Yun Zhu",
        "Fedir Zubach",
        "Lei Shu",
        "Jindong Chen"
      ],
      "abstract": "The rise of powerful multimodal LLMs has enhanced the viability of building\nweb agents which can, with increasing levels of autonomy, assist users to\nretrieve information and complete tasks on various human-computer interfaces.\nIt is hence necessary to build challenging benchmarks that span a wide-variety\nof use cases reflecting real-world usage. In this work, we present WebQuest, a\nmulti-page question-answering dataset that requires reasoning across multiple\nrelated web pages. In contrast to existing UI benchmarks that focus on\nmulti-step web navigation and task completion, our dataset evaluates\ninformation extraction, multimodal retrieval and composition of information\nfrom many web pages. WebQuest includes three question categories: single-screen\nQA, multi-screen QA, and QA based on navigation traces. We evaluate leading\nproprietary multimodal models like GPT-4V, Gemini Flash, Claude 3, and open\nsource models like InstructBLIP, PaliGemma on our dataset, revealing a\nsignificant gap between single-screen and multi-screen reasoning. Finally, we\ninvestigate inference time techniques like Chain-of-Thought prompting to\nimprove model capabilities on multi-screen reasoning.",
      "tldr_zh": "本文提出WebQuest，这是一个用于多模态QA（Multimodal QA）的基准数据集，旨在评估模型在多网页序列上的信息提取、多模态检索和信息合成能力。数据集包含三种问题类别：单屏QA、多屏QA和基于导航轨迹的QA，以模拟真实网页使用场景。评估结果显示，模型如GPT-4V、Gemini Flash和Claude 3在单屏和多屏推理之间存在显著性能差距。最终，研究探讨了Chain-of-Thought prompting等推理技术，以提升模型的多屏推理表现。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.13711v2",
      "published_date": "2024-09-06 18:44:25 UTC",
      "updated_date": "2024-09-24 18:38:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:49:57.115930"
    },
    {
      "arxiv_id": "2409.04559v2",
      "title": "Thinking Outside the BBox: Unconstrained Generative Object Compositing",
      "title_zh": "翻译失败",
      "authors": [
        "Gemma Canet Tarrés",
        "Zhe Lin",
        "Zhifei Zhang",
        "Jianming Zhang",
        "Yizhi Song",
        "Dan Ruta",
        "Andrew Gilbert",
        "John Collomosse",
        "Soo Ye Kim"
      ],
      "abstract": "Compositing an object into an image involves multiple non-trivial sub-tasks\nsuch as object placement and scaling, color/lighting harmonization,\nviewpoint/geometry adjustment, and shadow/reflection generation. Recent\ngenerative image compositing methods leverage diffusion models to handle\nmultiple sub-tasks at once. However, existing models face limitations due to\ntheir reliance on masking the original object during training, which constrains\ntheir generation to the input mask. Furthermore, obtaining an accurate input\nmask specifying the location and scale of the object in a new image can be\nhighly challenging. To overcome such limitations, we define a novel problem of\nunconstrained generative object compositing, i.e., the generation is not\nbounded by the mask, and train a diffusion-based model on a synthesized paired\ndataset. Our first-of-its-kind model is able to generate object effects such as\nshadows and reflections that go beyond the mask, enhancing image realism.\nAdditionally, if an empty mask is provided, our model automatically places the\nobject in diverse natural locations and scales, accelerating the compositing\nworkflow. Our model outperforms existing object placement and compositing\nmodels in various quality metrics and user studies.",
      "tldr_zh": "本文提出了一种不受掩码约束的生成式物体合成方法（unconstrained generative object compositing），旨在解决传统扩散模型（diffusion models）在物体合成任务中的局限性，如依赖输入掩码导致的生成范围受限和掩码获取困难。研究团队训练了一个基于扩散模型的模型，使用合成的配对数据集，使其能够生成超出掩码的物体效果，例如阴影和反射，从而提升图像真实性。如果提供空掩码，该模型还能自动在多样化的自然位置和缩放下放置物体，加速合成工作流。在各种质量指标和用户研究中，该模型优于现有物体放置和合成模型，展示了显著的性能提升。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.04559v2",
      "published_date": "2024-09-06 18:42:30 UTC",
      "updated_date": "2024-09-11 11:05:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:50:08.711971"
    },
    {
      "arxiv_id": "2409.04519v1",
      "title": "The role of data embedding in quantum autoencoders for improved anomaly detection",
      "title_zh": "翻译失败",
      "authors": [
        "Jack Y. Araz",
        "Michael Spannowsky"
      ],
      "abstract": "The performance of Quantum Autoencoders (QAEs) in anomaly detection tasks is\ncritically dependent on the choice of data embedding and ansatz design. This\nstudy explores the effects of three data embedding techniques, data\nre-uploading, parallel embedding, and alternate embedding, on the\nrepresentability and effectiveness of QAEs in detecting anomalies. Our findings\nreveal that even with relatively simple variational circuits, enhanced data\nembedding strategies can substantially improve anomaly detection accuracy and\nthe representability of underlying data across different datasets. Starting\nwith toy examples featuring low-dimensional data, we visually demonstrate the\neffect of different embedding techniques on the representability of the model.\nWe then extend our analysis to complex, higher-dimensional datasets,\nhighlighting the significant impact of embedding methods on QAE performance.",
      "tldr_zh": "本文研究了数据嵌入技术在量子自动编码器 (QAEs) 中的作用，以提升异常检测性能。作者比较了三种数据嵌入方法：data re-uploading、parallel embedding 和 alternate embedding，并发现这些策略即使在简单变分电路下也能显著提高检测准确性和数据表示能力。实验从低维玩具数据集的视觉演示扩展到高维复杂数据集，证明了嵌入方法的显著影响。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.LG",
        "physics.data-an"
      ],
      "primary_category": "quant-ph",
      "comment": "8 pages, 5 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2409.04519v1",
      "published_date": "2024-09-06 18:00:01 UTC",
      "updated_date": "2024-09-06 18:00:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:50:20.587979"
    },
    {
      "arxiv_id": "2409.04434v3",
      "title": "Accelerating Training with Neuron Interaction and Nowcasting Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Boris Knyazev",
        "Abhinav Moudgil",
        "Guillaume Lajoie",
        "Eugene Belilovsky",
        "Simon Lacoste-Julien"
      ],
      "abstract": "Neural network training can be accelerated when a learnable update rule is\nused in lieu of classic adaptive optimizers (e.g. Adam). However, learnable\nupdate rules can be costly and unstable to train and use. Recently, Jang et al.\n(2023) proposed a simpler approach to accelerate training based on weight\nnowcaster networks (WNNs). In their approach, Adam is used for most of the\noptimization steps and periodically, only every few steps, a WNN nowcasts\n(predicts near future) parameters. We improve WNNs by proposing neuron\ninteraction and nowcasting (NiNo) networks. In contrast to WNNs, NiNo leverages\nneuron connectivity and graph neural networks to more accurately nowcast\nparameters. We further show that in some networks, such as Transformers,\nmodeling neuron connectivity accurately is challenging. We address this and\nother limitations, which allows NiNo to accelerate Adam training by up to 50%\nin vision and language tasks.",
      "tldr_zh": "本研究提出 NiNo（Neuron Interaction and Nowcasting Networks），一种改进的权重预报网络（WNNs），旨在通过利用神经元连接性和图神经网络（Graph Neural Networks）来更准确地预报参数，从而加速神经网络训练。NiNo 解决了传统方法在某些网络（如 Transformers）中的挑战，例如建模神经元连接的困难，并作为辅助优化器与 Adam 结合使用。实验结果显示，NiNo 在视觉和语言任务上可以将 Adam 训练速度提高高达 50%。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "ICLR 2025, code is https://github.com/SamsungSAILMontreal/nino",
      "pdf_url": "http://arxiv.org/pdf/2409.04434v3",
      "published_date": "2024-09-06 17:55:49 UTC",
      "updated_date": "2025-02-27 19:52:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:50:32.488132"
    },
    {
      "arxiv_id": "2409.04432v2",
      "title": "A Survey on Knowledge Organization Systems of Research Fields: Resources and Challenges",
      "title_zh": "研究领域知识组织系统的调查：",
      "authors": [
        "Angelo Salatino",
        "Tanay Aggarwal",
        "Andrea Mannocci",
        "Francesco Osborne",
        "Enrico Motta"
      ],
      "abstract": "Knowledge Organization Systems (KOSs), such as term lists, thesauri,\ntaxonomies, and ontologies, play a fundamental role in categorising, managing,\nand retrieving information. In the academic domain, KOSs are often adopted for\nrepresenting research areas and their relationships, primarily aiming to\nclassify research articles, academic courses, patents, books, scientific\nvenues, domain experts, grants, software, experiment materials, and several\nother relevant products and agents. These structured representations of\nresearch areas, widely embraced by many academic fields, have proven effective\nin empowering AI-based systems to i) enhance retrievability of relevant\ndocuments, ii) enable advanced analytic solutions to quantify the impact of\nacademic research, and iii) analyse and forecast research dynamics. This paper\naims to present a comprehensive survey of the current KOS for academic\ndisciplines. We analysed and compared 45 KOSs according to five main\ndimensions: scope, structure, curation, usage, and links to other KOSs. Our\nresults reveal a very heterogeneous scenario in terms of scope, scale, quality,\nand usage, highlighting the need for more integrated solutions for representing\nresearch knowledge across academic fields. We conclude by discussing the main\nchallenges and the most promising future directions.",
      "tldr_zh": "这篇论文对学术领域的Knowledge Organization Systems (KOSs)进行了全面调查，包括术语列表、thesauri、taxonomies和ontologies等系统，用于分类和管理研究文章、课程、专利等。作者分析了45个KOSs，从scope、structure、curation、usage和links to other KOSs五个维度进行比较，结果显示这些系统在范围、规模、质量和使用上高度异质。调查强调了需要更集成的解决方案来统一研究知识表示，以提升AI系统的检索、分析和预测能力。论文最后讨论了主要挑战和未来方向，如促进跨领域整合。",
      "categories": [
        "cs.DL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.DL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.04432v2",
      "published_date": "2024-09-06 17:54:43 UTC",
      "updated_date": "2025-01-27 18:03:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:50:45.123165"
    },
    {
      "arxiv_id": "2409.15326v1",
      "title": "Evaluating the Impact of a Specialized LLM on Physician Experience in Clinical Decision Support: A Comparison of Ask Avo and ChatGPT-4",
      "title_zh": "翻译失败",
      "authors": [
        "Daniel Jung",
        "Alex Butler",
        "Joongheum Park",
        "Yair Saperstein"
      ],
      "abstract": "The use of Large language models (LLMs) to augment clinical decision support\nsystems is a topic with rapidly growing interest, but current shortcomings such\nas hallucinations and lack of clear source citations make them unreliable for\nuse in the clinical environment. This study evaluates Ask Avo, an LLM-derived\nsoftware by AvoMD that incorporates a proprietary Language Model Augmented\nRetrieval (LMAR) system, in-built visual citation cues, and prompt engineering\ndesigned for interactions with physicians, against ChatGPT-4 in end-user\nexperience for physicians in a simulated clinical scenario environment. Eight\nclinical questions derived from medical guideline documents in various\nspecialties were prompted to both models by 62 study participants, with each\nresponse rated on trustworthiness, actionability, relevancy, comprehensiveness,\nand friendly format from 1 to 5. Ask Avo significantly outperformed ChatGPT-4\nin all criteria: trustworthiness (4.52 vs. 3.34, p<0.001), actionability (4.41\nvs. 3.19, p<0.001), relevancy (4.55 vs. 3.49, p<0.001), comprehensiveness (4.50\nvs. 3.37, p<0.001), and friendly format (4.52 vs. 3.60, p<0.001). Our findings\nsuggest that specialized LLMs designed with the needs of clinicians in mind can\noffer substantial improvements in user experience over general-purpose LLMs.\nAsk Avo's evidence-based approach tailored to clinician needs shows promise in\nthe adoption of LLM-augmented clinical decision support software.",
      "tldr_zh": "本研究评估了专化大型语言模型(LLM) Ask Avo 与通用模型 ChatGPT-4 在临床决策支持中的用户体验影响，Ask Avo 采用了专有的 Language Model Augmented Retrieval (LMAR) 系统、内置视觉引用提示和针对医生的提示工程。研究中，62 名参与者针对 8 个来自医疗指南的临床问题向两个模型提问，并对响应在 trustworthiness（可信度）、actionability（可操作性）、relevancy（相关性）、comprehensiveness（全面性）和 friendly format（友好格式）等方面进行 1-5 分评分。结果显示，Ask Avo 在所有标准上显著优于 ChatGPT-4，例如 trustworthiness（4.52 vs. 3.34, p<0.001）。这些发现表明，专为临床医生设计的 LLM 可显著提升用户体验，并为 LLM 增强临床决策支持软件的采用提供潜力。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "8 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2409.15326v1",
      "published_date": "2024-09-06 17:53:29 UTC",
      "updated_date": "2024-09-06 17:53:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:50:58.984315"
    },
    {
      "arxiv_id": "2409.04428v2",
      "title": "Hybrid Spiking Neural Networks for Low-Power Intra-Cortical Brain-Machine Interfaces",
      "title_zh": "用于低功耗皮层内脑机接口的混合脉冲神经网络",
      "authors": [
        "Alexandru Vasilache",
        "Jann Krausse",
        "Klaus Knobloch",
        "Juergen Becker"
      ],
      "abstract": "Intra-cortical brain-machine interfaces (iBMIs) have the potential to\ndramatically improve the lives of people with paraplegia by restoring their\nability to perform daily activities. However, current iBMIs suffer from\nscalability and mobility limitations due to bulky hardware and wiring. Wireless\niBMIs offer a solution but are constrained by a limited data rate. To overcome\nthis challenge, we are investigating hybrid spiking neural networks for\nembedded neural decoding in wireless iBMIs. The networks consist of a temporal\nconvolution-based compression followed by recurrent processing and a final\ninterpolation back to the original sequence length. As recurrent units, we\nexplore gated recurrent units (GRUs), leaky integrate-and-fire (LIF) neurons,\nand a combination of both - spiking GRUs (sGRUs) and analyze their differences\nin terms of accuracy, footprint, and activation sparsity. To that end, we train\ndecoders on the \"Nonhuman Primate Reaching with Multichannel Sensorimotor\nCortex Electrophysiology\" dataset and evaluate it using the NeuroBench\nframework, targeting both tracks of the IEEE BioCAS Grand Challenge on Neural\nDecoding. Our approach achieves high accuracy in predicting velocities of\nprimate reaching movements from multichannel primary motor cortex recordings\nwhile maintaining a low number of synaptic operations, surpassing the current\nbaseline models in the NeuroBench framework. This work highlights the potential\nof hybrid neural networks to facilitate wireless iBMIs with high decoding\nprecision and a substantial increase in the number of monitored neurons, paving\nthe way toward more advanced neuroprosthetic technologies.",
      "tldr_zh": "本研究针对脑机接口(iBMIs)的可扩展性和移动性问题，提出了一种混合脉冲神经网络，用于低功耗无线iBMIs的嵌入式神经解码。该网络包括时间卷积压缩、循环处理（如gated recurrent units (GRUs)、leaky integrate-and-fire (LIF)神经元和spiking GRUs (sGRUs)）以及序列插值，以优化准确性和激活稀疏性。实验使用“Nonhuman Primate Reaching”数据集和NeuroBench框架进行评估，结果显示该方法在预测灵长类动物到达运动速度方面准确性高，且突触操作数量显著降低，超过了现有基线模型。该创新有望提升无线iBMIs的解码精度，并增加可监控神经元数量，推动神经假肢技术的发展。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.NC"
      ],
      "primary_category": "cs.LG",
      "comment": "This work has been accepted at the 2024 IEEE Biomedical Circuits and\n  Systems Conference",
      "pdf_url": "http://arxiv.org/pdf/2409.04428v2",
      "published_date": "2024-09-06 17:48:44 UTC",
      "updated_date": "2024-09-26 07:53:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:51:09.985840"
    },
    {
      "arxiv_id": "2409.04421v2",
      "title": "RLPF: Reinforcement Learning from Prediction Feedback for User Summarization with LLMs",
      "title_zh": "RLPF：基于预测反馈的强化学习，用于使用LLMs的用户总结",
      "authors": [
        "Jiaxing Wu",
        "Lin Ning",
        "Luyang Liu",
        "Harrison Lee",
        "Neo Wu",
        "Chao Wang",
        "Sushant Prakash",
        "Shawn O'Banion",
        "Bradley Green",
        "Jun Xie"
      ],
      "abstract": "LLM-powered personalization agent systems employ Large Language Models (LLMs)\nto predict users' behavior from their past activities. However, their\neffectiveness often hinges on the ability to effectively leverage extensive,\nlong user historical data due to its inherent noise and length of such data.\nExisting pretrained LLMs may generate summaries that are concise but lack the\nnecessary context for downstream tasks, hindering their utility in\npersonalization systems. To address these challenges, we introduce\nReinforcement Learning from Prediction Feedback (RLPF). RLPF fine-tunes LLMs to\ngenerate concise, human-readable user summaries that are optimized for\ndownstream task performance. By maximizing the usefulness of the generated\nsummaries, RLPF effectively distills extensive user history data while\npreserving essential information for downstream tasks. Our empirical evaluation\ndemonstrates significant improvements in both extrinsic downstream task utility\nand intrinsic summary quality, surpassing baseline methods by up to 22% on\ndownstream task performance and achieving an up to 84.59% win rate on\nFactuality, Abstractiveness, and Readability. RLPF also achieves a remarkable\n74% reduction in context length while improving performance on 16 out of 19\nunseen tasks and/or datasets, showcasing its generalizability. This approach\noffers a promising solution for enhancing LLM personalization by effectively\ntransforming long, noisy user histories into informative and human-readable\nrepresentations.",
      "tldr_zh": "这篇论文提出RLPF（Reinforcement Learning from Prediction Feedback），一种基于强化学习的方法，用于微调LLMs（Large Language Models），以生成简洁、人可读的用户摘要，这些摘要针对下游任务性能进行优化，从而有效处理用户历史数据的噪声和长度问题。RLPF通过最大化摘要的usefulness来提炼关键信息，显著提升了个性化系统的实用性。实验结果显示，RLPF在下游任务性能上比基线方法提高了多达22%，在Factuality、Abstractiveness和Readability方面胜率达84.59%，并减少了74%的上下文长度，同时在19个任务/数据集中的16个上实现了性能提升，展示了其泛化性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2409.04421v2",
      "published_date": "2024-09-06 17:30:45 UTC",
      "updated_date": "2025-01-17 01:11:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:51:23.792147"
    },
    {
      "arxiv_id": "2409.04415v1",
      "title": "Improved Parallel Algorithm for Non-Monotone Submodular Maximization under Knapsack Constraint",
      "title_zh": "翻译失败",
      "authors": [
        "Tan D. Tran",
        "Canh V. Pham",
        "Dung T. K. Ha",
        "Phuong N. H. Pham"
      ],
      "abstract": "This work proposes an efficient parallel algorithm for non-monotone\nsubmodular maximization under a knapsack constraint problem over the ground set\nof size $n$. Our algorithm improves the best approximation factor of the\nexisting parallel one from $8+\\epsilon$ to $7+\\epsilon$ with $O(\\log n)$\nadaptive complexity.\n  The key idea of our approach is to create a new alternate threshold\nalgorithmic framework. This strategy alternately constructs two disjoint\ncandidate solutions within a constant number of sequence rounds. Then, the\nalgorithm boosts solution quality without sacrificing the adaptive complexity.\nExtensive experimental studies on three applications, Revenue Maximization,\nImage Summarization, and Maximum Weighted Cut, show that our algorithm not only\nsignificantly increases solution quality but also requires comparative\nadaptivity to state-of-the-art algorithms.",
      "tldr_zh": "本研究提出了一种改进的并行算法，用于非单调子模函数最大化（non-monotone submodular maximization）问题下的背包约束（knapsack constraint），将现有算法的近似因子（approximation factor）从 8 + ε 提升至 7 + ε，同时保持自适应复杂度（adaptive complexity）为 O(log n)。关键方法是采用新的交替阈值算法框架（alternate threshold algorithmic framework），该框架在恒定数量的顺序轮次内交替构建两个不相交的候选解决方案，从而在不增加复杂度的前提下提升解决方案质量。在三个应用场景（Revenue Maximization、Image Summarization 和 Maximum Weighted Cut）的广泛实验中，该算法显著提高了解决方案质量，并与最先进算法具有可比的自适应性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "In Proceedings of the Thirty-Third International Joint Conference on\n  Artificial Intelligence (IJCAI), Main Track",
      "pdf_url": "http://arxiv.org/pdf/2409.04415v1",
      "published_date": "2024-09-06 17:17:52 UTC",
      "updated_date": "2024-09-06 17:17:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:51:35.566111"
    },
    {
      "arxiv_id": "2409.04410v3",
      "title": "Open-MAGVIT2: An Open-Source Project Toward Democratizing Auto-regressive Visual Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Zhuoyan Luo",
        "Fengyuan Shi",
        "Yixiao Ge",
        "Yujiu Yang",
        "Limin Wang",
        "Ying Shan"
      ],
      "abstract": "The Open-MAGVIT2 project produces an open-source replication of Google's\nMAGVIT-v2 tokenizer, a tokenizer with a super-large codebook (i.e., $2^{18}$\ncodes), and achieves the state-of-the-art reconstruction performance on\nImageNet and UCF benchmarks. We also provide a tokenizer pre-trained on\nlarge-scale data, significantly outperforming Cosmos on zero-shot benchmarks\n(1.93 vs. 0.78 rFID on ImageNet original resolution). Furthermore, we explore\nits application in plain auto-regressive models to validate scalability\nproperties, producing a family of auto-regressive image generation models\nranging from 300M to 1.5B. To assist auto-regressive models in predicting with\na super-large vocabulary, we factorize it into two sub-vocabulary of different\nsizes by asymmetric token factorization, and further introduce ``next sub-token\nprediction'' to enhance sub-token interaction for better generation quality. We\nrelease all models and codes to foster innovation and creativity in the field\nof auto-regressive visual generation.",
      "tldr_zh": "Open-MAGVIT2 是一个开源项目，旨在民主化自回归视觉生成，通过复制 Google's MAGVIT-v2 tokenizer 并采用超大代码书（2^{18} codes），在 ImageNet 和 UCF 基准上实现了最先进的图像重建性能。该项目提供了一个在大规模数据上预训练的 tokenizer，其零样本性能显著优于 Cosmos（ImageNet 上 rFID 1.93 vs. 0.78），并探索了其在自回归模型中的应用，通过不对称标记因子化（asymmetric token factorization）和 next sub-token prediction 增强子标记交互，开发出一系列从 300M 到 1.5B 参数的图像生成模型。所有模型和代码已开源，以推动自回归视觉生成领域的创新和发展。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.04410v3",
      "published_date": "2024-09-06 17:14:53 UTC",
      "updated_date": "2025-02-09 08:59:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:51:51.062398"
    },
    {
      "arxiv_id": "2409.04398v3",
      "title": "HiSC4D: Human-centered interaction and 4D Scene Capture in Large-scale Space Using Wearable IMUs and LiDAR",
      "title_zh": "翻译失败",
      "authors": [
        "Yudi Dai",
        "Zhiyong Wang",
        "Xiping Lin",
        "Chenglu Wen",
        "Lan Xu",
        "Siqi Shen",
        "Yuexin Ma",
        "Cheng Wang"
      ],
      "abstract": "We introduce HiSC4D, a novel Human-centered interaction and 4D Scene Capture\nmethod, aimed at accurately and efficiently creating a dynamic digital world,\ncontaining large-scale indoor-outdoor scenes, diverse human motions, rich\nhuman-human interactions, and human-environment interactions. By utilizing\nbody-mounted IMUs and a head-mounted LiDAR, HiSC4D can capture egocentric human\nmotions in unconstrained space without the need for external devices and\npre-built maps. This affords great flexibility and accessibility for\nhuman-centered interaction and 4D scene capturing in various environments.\nTaking into account that IMUs can capture human spatially unrestricted poses\nbut are prone to drifting for long-period using, and while LiDAR is stable for\nglobal localization but rough for local positions and orientations, HiSC4D\nemploys a joint optimization method, harmonizing all sensors and utilizing\nenvironment cues, yielding promising results for long-term capture in large\nscenes. To promote research of egocentric human interaction in large scenes and\nfacilitate downstream tasks, we also present a dataset, containing 8 sequences\nin 4 large scenes (200 to 5,000 $m^2$), providing 36k frames of accurate 4D\nhuman motions with SMPL annotations and dynamic scenes, 31k frames of cropped\nhuman point clouds, and scene mesh of the environment. A variety of scenarios,\nsuch as the basketball gym and commercial street, alongside challenging human\nmotions, such as daily greeting, one-on-one basketball playing, and tour\nguiding, demonstrate the effectiveness and the generalization ability of\nHiSC4D. The dataset and code will be publicated on\nwww.lidarhumanmotion.net/hisc4d available for research purposes.",
      "tldr_zh": "本研究引入了 HiSC4D，一种以人为中心的人机互动和 4D 场景捕获方法，使用可穿戴 IMUs 和头戴 LiDAR，在大规模室内外空间中精确捕获动态场景、人体动作以及人类互动。\n该方法通过联合优化整合 IMUs 的空间自由度与 LiDAR 的全局稳定，结合环境线索，解决了传感器漂移和局部定位问题，实现高效的长期捕获。\n研究提供了一个数据集，包含 8 个序列和 4 个大型场景（200 至 5000 m²），包括 36k 帧的 4D 人体动作（带 SMPL 注释）和动态点云，实验在各种场景如篮球馆和商业街中验证了 HiSC4D 的有效性和泛化能力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "17 pages, 10 figures, Jornal",
      "pdf_url": "http://arxiv.org/pdf/2409.04398v3",
      "published_date": "2024-09-06 16:43:04 UTC",
      "updated_date": "2024-09-14 15:48:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:52:01.827958"
    },
    {
      "arxiv_id": "2409.04388v5",
      "title": "Question-Answering Dense Video Events",
      "title_zh": "翻译失败",
      "authors": [
        "Hangyu Qin",
        "Junbin Xiao",
        "Angela Yao"
      ],
      "abstract": "This paper presents question-answering on dense video events, a novel task\nthat answers and grounds dense-event questions in long videos, thus challenging\nMLLMs to faithfully comprehend and reason about multiple events over extended\nperiods of time. To facilitate the study, we construct DeVE-QA -- a dataset\nfeaturing 78K questions about 26K events on 10.6K long videos. Our benchmarking\nshows that state-of-the-art MLLMs struggle on DeVE-QA. For improvement, we\npropose DeVi, a novel training-free MLLM approach that highlights a\nhierarchical captioning module, a temporal event memory module, and a\nself-consistency checking module to respectively detect, contextualize and\nmemorize, and ground dense-events in long videos for question answering.\nExtensive experiments show that DeVi is superior at answering dense-event\nquestions and grounding relevant video moments. Compared with existing MLLMs,\nit achieves a notable increase of 4.8% and 2.1% for G(round)QA accuracy on\nDeVE-QA and NExT-GQA, respectively. Data and code are available at\nhttps://github.com/QHUni/DeVE-QA.",
      "tldr_zh": "本论文提出了一种新任务，即在长视频中回答和定位密集事件（Question-Answering on Dense Video Events），挑战多模态大型语言模型（MLLMs）对多个事件的理解和推理能力。为此，构建了 DeVE-QA 数据集，包含 78K 个问题和 26K 事件基于 10.6K 长视频，并发现现有 MLLMs 在此数据集上表现不佳。论文引入了无训练方法 DeVi，包括 hierarchical captioning module 用于检测事件、temporal event memory module 用于上下文化和记忆，以及 self-consistency checking module 用于定位和验证，从而显著提升问答性能，在 DeVE-QA 和 NExT-GQA 上分别提高了 4.8% 和 2.1% 的 GQA 准确率。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to SIGIR'25",
      "pdf_url": "http://arxiv.org/pdf/2409.04388v5",
      "published_date": "2024-09-06 16:27:52 UTC",
      "updated_date": "2025-05-16 08:24:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:52:15.720865"
    },
    {
      "arxiv_id": "2410.00350v1",
      "title": "Efficient Training of Large Vision Models via Advanced Automated Progressive Learning",
      "title_zh": "高级自动渐进学习用于大型视觉模型的高效训练",
      "authors": [
        "Changlin Li",
        "Jiawei Zhang",
        "Sihao Lin",
        "Zongxin Yang",
        "Junwei Liang",
        "Xiaodan Liang",
        "Xiaojun Chang"
      ],
      "abstract": "The rapid advancements in Large Vision Models (LVMs), such as Vision\nTransformers (ViTs) and diffusion models, have led to an increasing demand for\ncomputational resources, resulting in substantial financial and environmental\ncosts. This growing challenge highlights the necessity of developing efficient\ntraining methods for LVMs. Progressive learning, a training strategy in which\nmodel capacity gradually increases during training, has shown potential in\naddressing these challenges. In this paper, we present an advanced automated\nprogressive learning (AutoProg) framework for efficient training of LVMs. We\nbegin by focusing on the pre-training of LVMs, using ViTs as a case study, and\npropose AutoProg-One, an AutoProg scheme featuring momentum growth (MoGrow) and\na one-shot growth schedule search. Beyond pre-training, we extend our approach\nto tackle transfer learning and fine-tuning of LVMs. We expand the scope of\nAutoProg to cover a wider range of LVMs, including diffusion models. First, we\nintroduce AutoProg-Zero, by enhancing the AutoProg framework with a novel\nzero-shot unfreezing schedule search, eliminating the need for one-shot\nsupernet training. Second, we introduce a novel Unique Stage Identifier (SID)\nscheme to bridge the gap during network growth. These innovations, integrated\nwith the core principles of AutoProg, offer a comprehensive solution for\nefficient training across various LVM scenarios. Extensive experiments show\nthat AutoProg accelerates ViT pre-training by up to 1.85x on ImageNet and\naccelerates fine-tuning of diffusion models by up to 2.86x, with comparable or\neven higher performance. This work provides a robust and scalable approach to\nefficient training of LVMs, with potential applications in a wide range of\nvision tasks. Code: https://github.com/changlin31/AutoProg-Zero",
      "tldr_zh": "本研究针对 Large Vision Models (LVMs) 如 Vision Transformers (ViTs) 和扩散模型的训练效率问题，提出了一种先进的自动渐进学习框架 AutoProg，以减少计算资源消耗。AutoProg 包括 AutoProg-One（用于 ViTs 预训练，结合 momentum growth (MoGrow) 和 one-shot growth schedule search）和 AutoProg-Zero（扩展到转移学习和微调，引入 zero-shot unfreezing schedule search 和 Unique Stage Identifier (SID) 方案），从而实现模型容量渐进增长和高效优化。实验结果显示，AutoProg 可将 ViTs 在 ImageNet 的预训练加速高达 1.85 倍，并将扩散模型的微调加速高达 2.86 倍，同时保持或提升性能，为 LVMs 的高效训练提供可扩展解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Code: https://github.com/changlin31/AutoProg-Zero. arXiv admin note:\n  substantial text overlap with arXiv:2203.14509",
      "pdf_url": "http://arxiv.org/pdf/2410.00350v1",
      "published_date": "2024-09-06 16:24:24 UTC",
      "updated_date": "2024-09-06 16:24:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:52:23.430750"
    },
    {
      "arxiv_id": "2409.09069v1",
      "title": "Temporal Many-valued Conditional Logics: a Preliminary Report",
      "title_zh": "翻译失败",
      "authors": [
        "Mario Alviano",
        "Laura Giordano",
        "Daniele Theseider Dupré"
      ],
      "abstract": "In this paper we propose a many-valued temporal conditional logic. We start\nfrom a many-valued logic with typicality, and extend it with the temporal\noperators of the Linear Time Temporal Logic (LTL), thus providing a formalism\nwhich is able to capture the dynamics of a system, trough strict and defeasible\ntemporal properties. We also consider an instantiation of the formalism for\ngradual argumentation.",
      "tldr_zh": "本论文提出了一种多值时间条件逻辑（Temporal Many-valued Conditional Logics），旨在通过扩展多值逻辑（with typicality）来整合线性时间时态逻辑（LTL）的时态运算符，从而捕捉系统的动态，包括严格和 defeasible 时间属性。该形式主义能够处理系统演变的典型性和不确定性，并探讨了其在 gradual argumentation 中的具体实例化。作为初步报告，这为多值逻辑在动态系统建模中的应用提供了新框架。",
      "categories": [
        "cs.LO",
        "cs.AI",
        "68T27",
        "I.2.4"
      ],
      "primary_category": "cs.LO",
      "comment": "8 pages",
      "pdf_url": "http://arxiv.org/pdf/2409.09069v1",
      "published_date": "2024-09-06 16:23:31 UTC",
      "updated_date": "2024-09-06 16:23:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:52:34.512816"
    },
    {
      "arxiv_id": "2409.04368v2",
      "title": "The Impact of Scanner Domain Shift on Deep Learning Performance in Medical Imaging: an Experimental Study",
      "title_zh": "扫描仪域移对医疗成像中深度学习性能的影响：一项实验研究",
      "authors": [
        "Brian Guo",
        "Darui Lu",
        "Gregory Szumel",
        "Rongze Gui",
        "Tingyu Wang",
        "Nicholas Konz",
        "Maciej A. Mazurowski"
      ],
      "abstract": "Purpose: Medical images acquired using different scanners and protocols can\ndiffer substantially in their appearance. This phenomenon, scanner domain\nshift, can result in a drop in the performance of deep neural networks which\nare trained on data acquired by one scanner and tested on another. This\nsignificant practical issue is well-acknowledged, however, no systematic study\nof the issue is available across different modalities and diagnostic tasks.\nMaterials and Methods: In this paper, we present a broad experimental study\nevaluating the impact of scanner domain shift on convolutional neural network\nperformance for different automated diagnostic tasks. We evaluate this\nphenomenon in common radiological modalities, including X-ray, CT, and MRI.\nResults: We find that network performance on data from a different scanner is\nalmost always worse than on same-scanner data, and we quantify the degree of\nperformance drop across different datasets. Notably, we find that this drop is\nmost severe for MRI, moderate for X-ray, and quite small for CT, on average,\nwhich we attribute to the standardized nature of CT acquisition systems which\nis not present in MRI or X-ray. We also study how injecting varying amounts of\ntarget domain data into the training set, as well as adding noise to the\ntraining data, helps with generalization. Conclusion: Our results provide\nextensive experimental evidence and quantification of the extent of performance\ndrop caused by scanner domain shift in deep learning across different\nmodalities, with the goal of guiding the future development of robust deep\nlearning models for medical image analysis.",
      "tldr_zh": "本研究系统探讨了扫描仪领域偏移(scanner domain shift)对深度学习在医疗图像分析中的性能影响，特别是在不同扫描仪和协议下图像外观差异导致的神经网络性能下降。研究通过实验评估卷积神经网络(CNN)在X-ray、CT和MRI等放射学模式下的自动化诊断任务表现。结果显示，不同扫描仪数据上的性能几乎总是低于相同扫描仪数据，且下降程度以MRI最严重、X-ray中等、CT最小，归因于CT获取系统的标准化。进一步实验表明，在训练集中加入目标领域数据或添加噪声有助于提升模型的泛化能力。该研究提供了量化证据，指导未来开发更鲁棒的深度学习模型。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.04368v2",
      "published_date": "2024-09-06 15:59:30 UTC",
      "updated_date": "2024-10-02 13:51:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:52:48.838065"
    },
    {
      "arxiv_id": "2409.04367v3",
      "title": "Algorithm Configuration for Structured Pfaffian Settings",
      "title_zh": "针对结构化 Pfaffian 设置的算法配置",
      "authors": [
        "Maria-Florina Balcan",
        "Anh Tuan Nguyen",
        "Dravyansh Sharma"
      ],
      "abstract": "Data-driven algorithm design automatically adapts algorithms to specific\napplication domains, achieving better performance. In the context of\nparameterized algorithms, this approach involves tuning the algorithm's\nhyperparameters using problem instances drawn from the problem distribution of\nthe target application domain. This can be achieved by maximizing empirical\nutilities that measure the algorithms' performance as a function of their\nhyperparameters, using problem instances. While empirical evidence supports the\neffectiveness of data-driven algorithm design, providing theoretical guarantees\nfor several parameterized families remains challenging. This is due to the\nintricate behaviors of their corresponding utility functions, which typically\nadmit piecewise discontinuous structures. In this work, we present refined\nframeworks for providing learning guarantees for parameterized data-driven\nalgorithm design problems in both distributional and online learning settings.\nFor the distributional learning setting, we introduce the \\textit{Pfaffian GJ\nframework}, an extension of the classical \\textit{GJ framework}, that is\ncapable of providing learning guarantees for function classes for which the\ncomputation involves Pfaffian functions. Unlike the GJ framework, which is\nlimited to function classes with computation characterized by rational\nfunctions, our proposed framework can deal with function classes involving\nPfaffian functions, which are much more general and widely applicable. We then\nshow that for many parameterized algorithms of interest, their utility function\npossesses a \\textit{refined piecewise structure}, which automatically\ntranslates to learning guarantees using our proposed framework.",
      "tldr_zh": "本研究探讨了数据驱动算法设计（data-driven algorithm design）在参数化算法（parameterized algorithms）中的应用，通过优化超参数来提升针对特定领域的性能，但面临理论保证的挑战，如效用函数的复杂分段不连续结构。作者提出了一种扩展框架——Pfaffian GJ framework，作为经典GJ framework的改进，能够处理更广泛的Pfaffian functions，从而为分布学习（distributional learning）和在线学习（online learning）设置提供学习保证。该框架适用于许多参数化算法的精炼分段结构（refined piecewise structure），从而自动转化为可靠的学习保障。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.04367v3",
      "published_date": "2024-09-06 15:58:20 UTC",
      "updated_date": "2024-11-12 22:53:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:52:59.102915"
    },
    {
      "arxiv_id": "2409.05907v3",
      "title": "Programming Refusal with Conditional Activation Steering",
      "title_zh": "翻译失败",
      "authors": [
        "Bruce W. Lee",
        "Inkit Padhi",
        "Karthikeyan Natesan Ramamurthy",
        "Erik Miehling",
        "Pierre Dognin",
        "Manish Nagireddy",
        "Amit Dhurandhar"
      ],
      "abstract": "LLMs have shown remarkable capabilities, but precisely controlling their\nresponse behavior remains challenging. Existing activation steering methods\nalter LLM behavior indiscriminately, limiting their practical applicability in\nsettings where selective responses are essential, such as content moderation or\ndomain-specific assistants. In this paper, we propose Conditional Activation\nSteering (CAST), which analyzes LLM activation patterns during inference to\nselectively apply or withhold activation steering based on the input context.\nOur method is based on the observation that different categories of prompts\nactivate distinct patterns in the model's hidden states. Using CAST, one can\nsystematically control LLM behavior with rules like \"if input is about hate\nspeech or adult content, then refuse\" or \"if input is not about legal advice,\nthen refuse.\" This allows for selective modification of responses to specific\ncontent while maintaining normal responses to other content, all without\nrequiring weight optimization. We release an open-source implementation of our\nframework at github.com/IBM/activation-steering .",
      "tldr_zh": "该论文提出 Conditional Activation Steering (CAST) 方法，用于精确控制大型语言模型 (LLMs) 的响应行为，解决现有激活导向方法无法选择性应用的问题。CAST 通过分析模型在推理过程中的隐藏状态激活模式，根据输入上下文决定是否应用导向，从而实现针对特定内容的响应控制，例如拒绝仇恨言论、成人内容或非相关查询。用户可以自定义规则，如“如果输入涉及非法建议，则拒绝”，而保持其他正常响应，且无需优化模型权重。实验验证了 CAST 的有效性，并开源了框架实现于 github.com/IBM/activation-steering。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "ICLR 2025, Spotlight",
      "pdf_url": "http://arxiv.org/pdf/2409.05907v3",
      "published_date": "2024-09-06 15:47:40 UTC",
      "updated_date": "2025-02-17 20:23:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:53:11.537282"
    },
    {
      "arxiv_id": "2409.04360v1",
      "title": "Connectivity-Inspired Network for Context-Aware Recognition",
      "title_zh": "基于连接性启发的上下文感知识别网络",
      "authors": [
        "Gianluca Carloni",
        "Sara Colantonio"
      ],
      "abstract": "The aim of this paper is threefold. We inform the AI practitioner about the\nhuman visual system with an extensive literature review; we propose a novel\nbiologically motivated neural network for image classification; and, finally,\nwe present a new plug-and-play module to model context awareness. We focus on\nthe effect of incorporating circuit motifs found in biological brains to\naddress visual recognition. Our convolutional architecture is inspired by the\nconnectivity of human cortical and subcortical streams, and we implement\nbottom-up and top-down modulations that mimic the extensive afferent and\nefferent connections between visual and cognitive areas. Our Contextual\nAttention Block is simple and effective and can be integrated with any\nfeed-forward neural network. It infers weights that multiply the feature maps\naccording to their causal influence on the scene, modeling the co-occurrence of\ndifferent objects in the image. We place our module at different bottlenecks to\ninfuse a hierarchical context awareness into the model. We validated our\nproposals through image classification experiments on benchmark data and found\na consistent improvement in performance and the robustness of the produced\nexplanations via class activation. Our code is available at\nhttps://github.com/gianlucarloni/CoCoReco.",
      "tldr_zh": "本论文旨在综述人类视觉系统、提出一种新型生物启发神经网络用于图像分类，并引入一个可插拔模块来实现上下文感知。受人类皮层和皮层下流连接启发的卷积架构，模拟了视觉和认知区域之间的自下而上及自上而下调节，同时通过Contextual Attention Block推断特征图的因果影响，建模图像中对象的共现关系。实验结果显示，该网络在基准数据集上的图像分类任务中，显著提升了性能和解释的鲁棒性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV",
        "I.2; I.4; I.5; J.3; J.6"
      ],
      "primary_category": "cs.CV",
      "comment": "ECCV 2024 - HCV Workshop, Accepted for presentation, Submitted\n  Manuscript Version (adapted to include author names, Acknowledgements, and\n  reference DOIs): the version of the manuscript improved after peer review\n  will appear in the Proceedings later",
      "pdf_url": "http://arxiv.org/pdf/2409.04360v1",
      "published_date": "2024-09-06 15:42:10 UTC",
      "updated_date": "2024-09-06 15:42:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:53:25.073282"
    },
    {
      "arxiv_id": "2409.04341v1",
      "title": "Towards Fine-Grained Webpage Fingerprinting at Scale",
      "title_zh": "翻译失败",
      "authors": [
        "Xiyuan Zhao",
        "Xinhao Deng",
        "Qi Li",
        "Yunpeng Liu",
        "Zhuotao Liu",
        "Kun Sun",
        "Ke Xu"
      ],
      "abstract": "Website Fingerprinting (WF) attacks can effectively identify the websites\nvisited by Tor clients via analyzing encrypted traffic patterns. Existing\nattacks focus on identifying different websites, but their accuracy\ndramatically decreases when applied to identify fine-grained webpages,\nespecially when distinguishing among different subpages of the same website.\nWebPage Fingerprinting (WPF) attacks face the challenges of highly similar\ntraffic patterns and a much larger scale of webpages. Furthermore, clients\noften visit multiple webpages concurrently, increasing the difficulty of\nextracting the traffic patterns of each webpage from the obfuscated traffic. In\nthis paper, we propose Oscar, a WPF attack based on multi-label metric learning\nthat identifies different webpages from obfuscated traffic by transforming the\nfeature space. Oscar can extract the subtle differences among various webpages,\neven those with similar traffic patterns. In particular, Oscar combines\nproxy-based and sample-based metric learning losses to extract webpage features\nfrom obfuscated traffic and identify multiple webpages. We prototype Oscar and\nevaluate its performance using traffic collected from 1,000 monitored webpages\nand over 9,000 unmonitored webpages in the real world. Oscar demonstrates an\n88.6% improvement in the multi-label metric Recall@5 compared to the\nstate-of-the-art attacks.",
      "tldr_zh": "本文探讨了 Website Fingerprinting (WF) 攻击在识别细粒度网页时的挑战，特别是区分同一网站的子页面，以及处理并发访问导致的流量混淆问题。论文提出 Oscar，一种基于 multi-label metric learning 的 WebPage Fingerprinting (WPF) 攻击框架，通过转换特征空间并结合 proxy-based 和 sample-based 度量学习损失，从混淆流量中提取网页的细微差异，以识别多个网页。实验结果显示，Oscar 在真实世界流量数据集上，将 multi-label metric Recall@5 比现有攻击提高了 88.6%，显著提升了网页识别的准确性和规模适应性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "To appear in the Proceedings of The ACM Conference on Computer and\n  Communications Security (CCS), 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.04341v1",
      "published_date": "2024-09-06 15:21:00 UTC",
      "updated_date": "2024-09-06 15:21:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:53:38.227824"
    },
    {
      "arxiv_id": "2409.04340v1",
      "title": "AGR: Age Group fairness Reward for Bias Mitigation in LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Shuirong Cao",
        "Ruoxi Cheng",
        "Zhiqiang Wang"
      ],
      "abstract": "LLMs can exhibit age biases, resulting in unequal treatment of individuals\nacross age groups. While much research has addressed racial and gender biases,\nage bias remains little explored. The scarcity of instruction-tuning and\npreference datasets for age bias hampers its detection and measurement, and\nexisting fine-tuning methods seldom address age-related fairness. In this\npaper, we construct age bias preference datasets and instruction-tuning\ndatasets for RLHF. We introduce ARG, an age fairness reward to reduce\ndifferences in the response quality of LLMs across different age groups.\nExtensive experiments demonstrate that this reward significantly improves\nresponse accuracy and reduces performance disparities across age groups. Our\nsource code and datasets are available at the anonymous\n\\href{https://anonymous.4open.science/r/FairRLHF-D445/readme.md}{link}.",
      "tldr_zh": "本研究探讨了大型语言模型（LLMs）中的年龄偏见问题，指出现有工作多关注种族和性别偏见，而年龄相关公平性鲜有探讨，并为此构建了专门的偏好数据集和指令微调数据集，以支持强化学习从人类反馈（RLHF）。他们引入了 AGR（Age Group fairness Reward）机制，作为一种奖励函数，用于减少 LLMs 在不同年龄组间的响应质量差异。实验结果显示，AGR 显著提升了模型的响应准确性和公平性，缩小了性能差距，并公开了源代码和数据集以促进进一步研究。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "The first two authors contributed equally to this work. Corresponding\n  to Zhiqiang Wang. ACKNOWLEDGMENT: we would like to thank the computing\n  resources support from the State Key Laboratory of New Computer Software\n  Technologies at Nanjing University",
      "pdf_url": "http://arxiv.org/pdf/2409.04340v1",
      "published_date": "2024-09-06 15:18:12 UTC",
      "updated_date": "2024-09-06 15:18:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:53:50.030582"
    },
    {
      "arxiv_id": "2409.04495v1",
      "title": "Learning to Solve Combinatorial Optimization under Positive Linear Constraints via Non-Autoregressive Neural Networks",
      "title_zh": "通过非自回归神经网络学习解决正线性约束下的组合优化问题",
      "authors": [
        "Runzhong Wang",
        "Yang Li",
        "Junchi Yan",
        "Xiaokang Yang"
      ],
      "abstract": "Combinatorial optimization (CO) is the fundamental problem at the\nintersection of computer science, applied mathematics, etc. The inherent\nhardness in CO problems brings up challenge for solving CO exactly, making\ndeep-neural-network-based solvers a research frontier. In this paper, we design\na family of non-autoregressive neural networks to solve CO problems under\npositive linear constraints with the following merits. First, the positive\nlinear constraint covers a wide range of CO problems, indicating that our\napproach breaks the generality bottleneck of existing non-autoregressive\nnetworks. Second, compared to existing autoregressive neural network solvers,\nour non-autoregressive networks have the advantages of higher efficiency and\npreserving permutation invariance. Third, our offline unsupervised learning has\nlower demand on high-quality labels, getting rid of the demand of optimal\nlabels in supervised learning. Fourth, our online differentiable search method\nsignificantly improves the generalizability of our neural network solver to\nunseen problems. We validate the effectiveness of this framework in solving\nrepresentative CO problems including facility location, max-set covering, and\ntraveling salesman problem. Our non-autoregressive neural solvers are\ncompetitive to and can be even superior to state-of-the-art solvers such as\nSCIP and Gurobi, especially when both efficiency and efficacy are considered.\nCode is available at https://github.com/Thinklab-SJTU/NAR-CO-Solver",
      "tldr_zh": "该论文提出了一种使用非自回归 neural networks 来解决受 positive linear constraints 的组合优化 (CO) 问题的方法，扩展了现有框架的适用范围。相比自回归网络，该方法具有更高的效率、保持 permutation invariance，以及通过离线无监督学习和在线可微搜索降低标签需求并提升泛化能力。在 facility location、max-set covering 和 traveling salesman problem 等典型 CO 问题上，实验结果显示，该神经求解器在效率和效能方面与 SCIP 和 Gurobi 等最先进求解器相当或更优。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "English version of the same paper published on Scientia Sinica\n  Informationis",
      "pdf_url": "http://arxiv.org/pdf/2409.04495v1",
      "published_date": "2024-09-06 14:58:31 UTC",
      "updated_date": "2024-09-06 14:58:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:54:03.100711"
    },
    {
      "arxiv_id": "2409.13709v1",
      "title": "Column Vocabulary Association (CVA): semantic interpretation of dataless tables",
      "title_zh": "列词汇关联 (CVA)：无数据表的语义解释",
      "authors": [
        "Margherita Martorana",
        "Xueli Pan",
        "Benno Kruit",
        "Tobias Kuhn",
        "Jacco van Ossenbruggen"
      ],
      "abstract": "Traditional Semantic Table Interpretation (STI) methods rely primarily on the\nunderlying table data to create semantic annotations. This year's SemTab\nchallenge introduced the ``Metadata to KG'' track, which focuses on performing\nSTI by using only metadata information, without access to the underlying data.\nIn response to this new challenge, we introduce a new term: Column Vocabulary\nAssociation (CVA). This term refers to the task of semantic annotation of\ncolumn headers solely based on metadata information. In this study, we evaluate\nthe performance of various methods in executing the CVA task, including a Large\nLanguage Models (LLMs) and Retrieval Augmented Generation (RAG) approach, as\nwell as a more traditional similarity approach with SemanticBERT. Our\nmethodology uses a zero-shot setting, with no pretraining or examples passed to\nthe Large Language Models (LLMs), as we aim to avoid a domain-specific setting.\n  We investigate a total of 7 different LLMs, of which three commercial GPT\nmodels (i.e. gpt-3.5-turbo-0.125, gpt-4o and gpt-4-turbo) and four open source\nmodels (i.e. llama3-80b, llama3-7b, gemma-7b and mixtral-8x7b). We integrate\nthis models with RAG systems, and we explore how variations in temperature\nsettings affect performances. Moreover, we continue our investigation by\nperforming the CVA task utilizing SemanticBERT, analyzing how various metadata\ninformation influence its performance.\n  Initial findings indicate that LLMs generally perform well at temperatures\nbelow 1.0, achieving an accuracy of 100\\% in certain cases. Nevertheless, our\ninvestigation also reveal that the nature of the data significantly influences\nCVA task outcomes. In fact, in cases where the input data and glossary are\nrelated (for example by being created by the same organizations) traditional\nmethods appear to surpass the performance of LLMs.",
      "tldr_zh": "这篇论文引入了 Column Vocabulary Association (CVA)，一种仅基于元数据信息对列头进行语义注解的任务，针对无底层数据的 Semantic Table Interpretation (STI) 挑战。研究评估了多种方法，包括 Large Language Models (LLMs) 与 Retrieval Augmented Generation (RAG) 的结合，以及传统的 SemanticBERT 相似性方法，所有实验均采用 zero-shot 设置，并测试了 7 个 LLMs（如 gpt-3.5-turbo-0.125、gpt-4o 和开源模型 llama3-80b 等）。初步发现显示，LLMs 在温度设置低于 1.0 时表现出色，有时达到 100% 准确率，但当输入数据和词汇表相关时，传统方法可能超越 LLMs 的性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.13709v1",
      "published_date": "2024-09-06 14:58:30 UTC",
      "updated_date": "2024-09-06 14:58:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:54:15.902121"
    },
    {
      "arxiv_id": "2409.04318v2",
      "title": "Learning vs Retrieval: The Role of In-Context Examples in Regression with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Aliakbar Nafar",
        "Kristen Brent Venable",
        "Parisa Kordjamshidi"
      ],
      "abstract": "Generative Large Language Models (LLMs) are capable of being in-context\nlearners. However, the underlying mechanism of in-context learning (ICL) is\nstill a major research question, and experimental research results about how\nmodels exploit ICL are not always consistent. In this work, we propose a\nframework for evaluating in-context learning mechanisms, which we claim are a\ncombination of retrieving internal knowledge and learning from in-context\nexamples by focusing on regression tasks. First, we show that LLMs can solve\nreal-world regression problems and then design experiments to measure the\nextent to which the LLM retrieves its internal knowledge versus learning from\nin-context examples. We argue that this process lies on a spectrum between\nthese two extremes. We provide an in-depth analysis of the degrees to which\nthese mechanisms are triggered depending on various factors, such as prior\nknowledge about the tasks and the type and richness of the information provided\nby the in-context examples. We employ three LLMs and utilize multiple datasets\nto corroborate the robustness of our findings. Our results shed light on how to\nengineer prompts to leverage meta-learning from in-context examples and foster\nknowledge retrieval depending on the problem being addressed.",
      "tldr_zh": "该研究探讨了大型语言模型（LLMs）在回归任务中通过in-context learning (ICL)机制的运作，具体比较了模型从内部知识检索与从in-context例子中学习的相对作用。作者提出一个评估框架，通过实验设计测量这些机制的程度，分析因素如任务的先验知识和in-context例子的类型与丰富度对机制的影响。结果显示，ICL过程位于一个光谱上，使用三个LLMs和多个数据集验证了这一发现，并为优化提示工程以利用meta-learning和知识检索提供了指导。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.04318v2",
      "published_date": "2024-09-06 14:46:37 UTC",
      "updated_date": "2025-02-09 22:47:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:54:24.890247"
    },
    {
      "arxiv_id": "2409.04306v1",
      "title": "Safe and Efficient Path Planning under Uncertainty via Deep Collision Probability Fields",
      "title_zh": "在不确定性下通过深度碰撞概率场实现安全且高效的路径规划",
      "authors": [
        "Felix Herrmann",
        "Sebastian Zach",
        "Jacopo Banfi",
        "Jan Peters",
        "Georgia Chalvatzaki",
        "Davide Tateo"
      ],
      "abstract": "Estimating collision probabilities between robots and environmental obstacles\nor other moving agents is crucial to ensure safety during path planning. This\nis an important building block of modern planning algorithms in many\napplication scenarios such as autonomous driving, where noisy sensors perceive\nobstacles. While many approaches exist, they either provide too conservative\nestimates of the collision probabilities or are computationally intensive due\nto their sampling-based nature. To deal with these issues, we introduce Deep\nCollision Probability Fields, a neural-based approach for computing collision\nprobabilities of arbitrary objects with arbitrary unimodal uncertainty\ndistributions. Our approach relegates the computationally intensive estimation\nof collision probabilities via sampling at the training step, allowing for fast\nneural network inference of the constraints during planning. In extensive\nexperiments, we show that Deep Collision Probability Fields can produce\nreasonably accurate collision probabilities (up to 10^{-3}) for planning and\nthat our approach can be easily plugged into standard path planning approaches\nto plan safe paths on 2-D maps containing uncertain static and dynamic\nobstacles. Additional material, code, and videos are available at\nhttps://sites.google.com/view/ral-dcpf.",
      "tldr_zh": "该论文提出了一种名为 Deep Collision Probability Fields 的神经网络方法，用于在不确定环境下进行安全高效的路径规划。该方法通过在训练阶段使用采样估计算法来计算任意物体与任意单峰不确定性分布的碰撞概率，从而在规划阶段实现快速神经网络推理，避免了现有方法的保守估计或计算密集问题。实验结果显示，该方法能提供高精度（精确到 10^{-3}）的碰撞概率，并轻松集成到标准路径规划算法中，在 2-D 地图上成功处理不确定静态和动态障碍物，从而提升了机器人路径规划的安全性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Preprint version of a paper accepted to the IEEE Robotics and\n  Automation Letters",
      "pdf_url": "http://arxiv.org/pdf/2409.04306v1",
      "published_date": "2024-09-06 14:28:41 UTC",
      "updated_date": "2024-09-06 14:28:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:54:36.079385"
    },
    {
      "arxiv_id": "2409.13708v2",
      "title": "Towards Safe Multilingual Frontier AI",
      "title_zh": "翻译失败",
      "authors": [
        "Artūrs Kanepajs",
        "Vladimir Ivanov",
        "Richard Moulange"
      ],
      "abstract": "Linguistically inclusive LLMs -- which maintain good performance regardless\nof the language with which they are prompted -- are necessary for the diffusion\nof AI benefits around the world. Multilingual jailbreaks that rely on language\ntranslation to evade safety measures undermine the safe and inclusive\ndeployment of AI systems. We provide policy recommendations to enhance the\nmultilingual capabilities of AI while mitigating the risks of multilingual\njailbreaks. We examine how a language's level of resourcing relates to how\nvulnerable LLMs are to multilingual jailbreaks in that language. We do this by\ntesting five advanced AI models across 24 official languages of the EU.\nBuilding on prior research, we propose policy actions that align with the EU\nlegal landscape and institutional framework to address multilingual jailbreaks,\nwhile promoting linguistic inclusivity. These include mandatory assessments of\nmultilingual capabilities and vulnerabilities, public opinion research, and\nstate support for multilingual AI development. The measures aim to improve AI\nsafety and functionality through EU policy initiatives, guiding the\nimplementation of the EU AI Act and informing regulatory efforts of the\nEuropean AI Office.",
      "tldr_zh": "该论文探讨了多语言大型语言模型（LLMs）的安全性和包容性问题，强调了防范多语言越狱攻击（multilingual jailbreaks）的重要性，以确保AI系统在全球范围内安全部署。研究者测试了5个高级AI模型在24种欧盟官方语言中的表现，分析了语言资源水平与模型易受攻击的相关性，发现资源较少的语言更易出现漏洞。最终，他们提出政策推荐，包括强制评估多语言能力和漏洞、开展公众意见研究以及国家支持多语言AI开发，以指导欧盟AI法案（EU AI Act）和欧洲AI办公室的监管努力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "23 pages; 1 figure and 10 supplementary figures; Accepted (spotlight\n  presentation) at NeurIPS 2024 SoLaR workshop",
      "pdf_url": "http://arxiv.org/pdf/2409.13708v2",
      "published_date": "2024-09-06 14:26:18 UTC",
      "updated_date": "2024-10-29 11:14:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:54:48.552188"
    },
    {
      "arxiv_id": "2409.04290v1",
      "title": "CoxKAN: Kolmogorov-Arnold Networks for Interpretable, High-Performance Survival Analysis",
      "title_zh": "CoxKAN：Kol",
      "authors": [
        "William Knottenbelt",
        "Zeyu Gao",
        "Rebecca Wray",
        "Woody Zhidong Zhang",
        "Jiashuai Liu",
        "Mireia Crispin-Ortuzar"
      ],
      "abstract": "Survival analysis is a branch of statistics used for modeling the time until\na specific event occurs and is widely used in medicine, engineering, finance,\nand many other fields. When choosing survival models, there is typically a\ntrade-off between performance and interpretability, where the highest\nperformance is achieved by black-box models based on deep learning. This is a\nmajor problem in fields such as medicine where practitioners are reluctant to\nblindly trust black-box models to make important patient decisions.\nKolmogorov-Arnold Networks (KANs) were recently proposed as an interpretable\nand accurate alternative to multi-layer perceptrons (MLPs). We introduce\nCoxKAN, a Cox proportional hazards Kolmogorov-Arnold Network for interpretable,\nhigh-performance survival analysis. We evaluate the proposed CoxKAN on 4\nsynthetic datasets and 9 real medical datasets. The synthetic experiments\ndemonstrate that CoxKAN accurately recovers interpretable symbolic formulae for\nthe hazard function, and effectively performs automatic feature selection.\nEvaluation on the 9 real datasets show that CoxKAN consistently outperforms the\nCox proportional hazards model and achieves performance that is superior or\ncomparable to that of tuned MLPs. Furthermore, we find that CoxKAN identifies\ncomplex interactions between predictor variables that would be extremely\ndifficult to recognise using existing survival methods, and automatically finds\nsymbolic formulae which uncover the precise effect of important biomarkers on\npatient risk.",
      "tldr_zh": "本研究针对生存分析（Survival Analysis）中性能与可解释性的权衡问题，提出 CoxKAN，一种基于 Kolmogorov-Arnold Networks (KANs) 的 Cox 比例风险模型，旨在提供高性能且易于解释的解决方案。CoxKAN 能够准确恢复风险函数的符号公式、实现自动特征选择，并识别预测变量之间的复杂交互，从而揭示生物标记物对患者风险的精确影响。在4个合成数据集和9个真实医疗数据集上的实验表明，CoxKAN 优于传统 Cox 比例风险模型，并与调优的多层感知器 (MLPs) 性能相当或更佳。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.04290v1",
      "published_date": "2024-09-06 13:59:58 UTC",
      "updated_date": "2024-09-06 13:59:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:55:02.330150"
    },
    {
      "arxiv_id": "2409.04286v2",
      "title": "Using Large Language Models to Generate Authentic Multi-agent Knowledge Work Datasets",
      "title_zh": "翻译失败",
      "authors": [
        "Desiree Heim",
        "Christian Jilek",
        "Adrian Ulges",
        "Andreas Dengel"
      ],
      "abstract": "Current publicly available knowledge work data collections lack diversity,\nextensive annotations, and contextual information about the users and their\ndocuments. These issues hinder objective and comparable data-driven evaluations\nand optimizations of knowledge work assistance systems. Due to the considerable\nresources needed to collect such data in real-life settings and the necessity\nof data censorship, collecting such a dataset appears nearly impossible. For\nthis reason, we propose a configurable, multi-agent knowledge work dataset\ngenerator. This system simulates collaborative knowledge work among agents\nproducing Large Language Model-generated documents and accompanying data\ntraces. Additionally, the generator captures all background information, given\nin its configuration or created during the simulation process, in a knowledge\ngraph. Finally, the resulting dataset can be utilized and shared without\nprivacy or confidentiality concerns.\n  This paper introduces our approach's design and vision and focuses on\ngenerating authentic knowledge work documents using Large Language Models. Our\nstudy involving human raters who assessed 53% of the generated and 74% of the\nreal documents as realistic demonstrates the potential of our approach.\nFurthermore, we analyze the authenticity criteria mentioned in the\nparticipants' comments and elaborate on potential improvements for identified\ncommon issues.",
      "tldr_zh": "该研究针对现有知识工作数据集缺乏多样性、广泛注解和上下文信息的问题，提出了一种使用 Large Language Models (LLMs) 的可配置多智能体生成器。该系统模拟代理间的协作知识工作，生成真实文档、数据跟踪，并将背景信息捕获在知识图谱中，从而避免隐私和保密问题。实验结果显示，人类评估者认为53%的生成文档和74%的真实文档具有真实性，并分析了真实性标准及潜在改进方向，为数据驱动的知识工作辅助系统优化提供了新途径。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted and published (INFORMATIK Festival, Wiesbaden, 2024)",
      "pdf_url": "http://arxiv.org/pdf/2409.04286v2",
      "published_date": "2024-09-06 13:53:28 UTC",
      "updated_date": "2024-10-24 08:32:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:55:12.752765"
    },
    {
      "arxiv_id": "2409.04272v2",
      "title": "Cycle Pixel Difference Network for Crisp Edge Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Changsong Liu",
        "Wei Zhang",
        "Yanyan Liu",
        "Mingyang Li",
        "Wenlin Li",
        "Yimeng Fan",
        "Xiangnan Bai",
        "Liang Zhang"
      ],
      "abstract": "Edge detection, as a fundamental task in computer vision, has garnered\nincreasing attention. The advent of deep learning has significantly advanced\nthis field. However, recent deep learning-based methods generally face two\nsignificant issues: 1) reliance on large-scale pre-trained weights, and 2)\ngeneration of thick edges. We construct a U-shape encoder-decoder model named\nCPD-Net that successfully addresses these two issues simultaneously. In\nresponse to issue 1), we propose a novel cycle pixel difference convolution\n(CPDC), which effectively integrates edge prior knowledge with modern\nconvolution operations, consequently successfully eliminating the dependence on\nlarge-scale pre-trained weights. As for issue 2), we construct a multi-scale\ninformation enhancement module (MSEM) and a dual residual connection-based\n(DRC) decoder to enhance the edge location ability of the model, thereby\ngenerating crisp and clean contour maps. Comprehensive experiments conducted on\nfour standard benchmarks demonstrate that our method achieves competitive\nperformance on the BSDS500 dataset (ODS=0.813 and AC=0.352), NYUD-V2 (ODS=0.760\nand AC=0.223), BIPED dataset (ODS=0.898 and AC=0.426), and CID (ODS=0.59). Our\napproach provides a novel perspective for addressing these challenges in edge\ndetection.",
      "tldr_zh": "本研究针对边缘检测领域的两个主要问题——依赖大规模预训练权重和生成厚边缘——提出了一种名为 Cycle Pixel Difference Network (CPD-Net) 的 U-shape 编码器-解码器模型。CPD-Net 引入了 cycle pixel difference convolution (CPDC) 模块来整合边缘先验知识，从而消除对预训练权重的需求；同时，通过 multi-scale information enhancement module (MSEM) 和 dual residual connection-based (DRC) 解码器，提升模型的边缘定位能力，以生成清晰的轮廓图。在四个标准基准上进行的全面实验显示，该方法在 BSDS500 数据集上达到 ODS=0.813 和 AC=0.352，在 NYUD-V2、BIPED 和 CID 数据集上也取得了竞争性性能，为边缘检测提供了一个新颖的解决视角。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.04272v2",
      "published_date": "2024-09-06 13:28:05 UTC",
      "updated_date": "2024-12-19 15:02:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:55:27.571979"
    },
    {
      "arxiv_id": "2409.04267v1",
      "title": "An overview of domain-specific foundation model: key technologies, applications and challenges",
      "title_zh": "领域特定基础模型的概述：关键技术、应用和挑战",
      "authors": [
        "Haolong Chen",
        "Hanzhi Chen",
        "Zijian Zhao",
        "Kaifeng Han",
        "Guangxu Zhu",
        "Yichen Zhao",
        "Ying Du",
        "Wei Xu",
        "Qingjiang Shi"
      ],
      "abstract": "The impressive performance of ChatGPT and other foundation-model-based\nproducts in human language understanding has prompted both academia and\nindustry to explore how these models can be tailored for specific industries\nand application scenarios. This process, known as the customization of\ndomain-specific foundation models, addresses the limitations of general-purpose\nmodels, which may not fully capture the unique patterns and requirements of\ndomain-specific data. Despite its importance, there is a notable lack of\ncomprehensive overview papers on building domain-specific foundation models,\nwhile numerous resources exist for general-purpose models. To bridge this gap,\nthis article provides a timely and thorough overview of the methodology for\ncustomizing domain-specific foundation models. It introduces basic concepts,\noutlines the general architecture, and surveys key methods for constructing\ndomain-specific models. Furthermore, the article discusses various domains that\ncan benefit from these specialized models and highlights the challenges ahead.\nThrough this overview, we aim to offer valuable guidance and reference for\nresearchers and practitioners from diverse fields to develop their own\ncustomized foundation models.",
      "tldr_zh": "这篇综述论文探讨了领域特定基础模型（domain-specific foundation models）的定制化方法，以克服通用模型在特定行业应用中的局限性。论文介绍了基础概念、总体架构以及关键技术，如模型构建和适应策略，并调研了这些模型在各种领域的潜在应用。最终，它突出了面临的挑战，并为研究者和从业者提供宝贵指导，以开发自定义的foundation models。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.04267v1",
      "published_date": "2024-09-06 13:24:22 UTC",
      "updated_date": "2024-09-06 13:24:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:55:36.777447"
    },
    {
      "arxiv_id": "2409.13707v1",
      "title": "Retrieval Augmented Generation-Based Incident Resolution Recommendation System for IT Support",
      "title_zh": "基于检索增强生成的 IT 支持事件解决推荐系统",
      "authors": [
        "Paulina Toro Isaza",
        "Michael Nidd",
        "Noah Zheutlin",
        "Jae-wook Ahn",
        "Chidansh Amitkumar Bhatt",
        "Yu Deng",
        "Ruchi Mahindru",
        "Martin Franz",
        "Hans Florian",
        "Salim Roukos"
      ],
      "abstract": "Clients wishing to implement generative AI in the domain of IT Support and\nAIOps face two critical issues: domain coverage and model size constraints due\nto model choice limitations. Clients might choose to not use larger proprietary\nmodels such as GPT-4 due to cost and privacy concerns and so are limited to\nsmaller models with potentially less domain coverage that do not generalize to\nthe client's domain. Retrieval augmented generation is a common solution that\naddresses both of these issues: a retrieval system first retrieves the\nnecessary domain knowledge which a smaller generative model leverages as\ncontext for generation. We present a system developed for a client in the IT\nSupport domain for support case solution recommendation that combines retrieval\naugmented generation (RAG) for answer generation with an encoder-only model for\nclassification and a generative large language model for query generation. We\ncover architecture details, data collection and annotation, development journey\nand preliminary validations, expected final deployment process and evaluation\nplans, and finally lessons learned.",
      "tldr_zh": "该研究针对 IT 支持和 AIOps 领域中生成式 AI 的领域覆盖不足和模型大小限制问题，提出了一种基于 Retrieval Augmented Generation (RAG) 的故障解决推荐系统。该系统结合 RAG 用于生成答案、encoder-only 模型进行分类，以及生成式大语言模型生成查询，从而帮助较小模型在特定领域提供更准确的解决方案。研究详细阐述了系统架构、数据收集与标注、开发过程、初步验证、部署计划和评估策略，并总结了宝贵的经验教训，以提升 IT 支持的效率和泛化能力。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "7 pages, 3 figures, 6 tables",
      "pdf_url": "http://arxiv.org/pdf/2409.13707v1",
      "published_date": "2024-09-06 13:06:29 UTC",
      "updated_date": "2024-09-06 13:06:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:55:50.228920"
    },
    {
      "arxiv_id": "2409.04249v2",
      "title": "Hermes: Memory-Efficient Pipeline Inference for Large Models on Edge Devices",
      "title_zh": "翻译失败",
      "authors": [
        "Xueyuan Han",
        "Zinuo Cai",
        "Yichu Zhang",
        "Chongxin Fan",
        "Junhan Liu",
        "Ruhui Ma",
        "Rajkumar Buyya"
      ],
      "abstract": "The application of Transformer-based large models has achieved numerous\nsuccess in recent years. However, the exponential growth in the parameters of\nlarge models introduces formidable memory challenge for edge deployment. Prior\nworks to address this challenge mainly focus on optimizing the model structure\nand adopting memory swapping methods. However, the former reduces the inference\naccuracy, and the latter raises the inference latency. This paper introduces\nPIPELOAD, a novel memory-efficient pipeline execution mechanism. It reduces\nmemory usage by incorporating dynamic memory management and minimizes inference\nlatency by employing parallel model loading. Based on PIPELOAD mechanism, we\npresent Hermes, a framework optimized for large model inference on edge\ndevices. We evaluate Hermes on Transformer-based models of different sizes. Our\nexperiments illustrate that Hermes achieves up to 4.24 X increase in inference\nspeed and 86.7% lower memory consumption than the state-of-the-art pipeline\nmechanism for BERT and ViT models, 2.58 X increase in inference speed and 90.3%\nlower memory consumption for GPT-style models.",
      "tldr_zh": "该论文针对 Transformer-based 大模型在边缘设备部署时的内存挑战，提出 PIPELOAD 机制，通过动态内存管理和并行模型加载来减少内存使用并最小化推理延迟。基于 PIPELOAD，作者开发了 Hermes 框架，用于优化大模型的管道推理。实验结果显示，Hermes 在 BERT 和 ViT 模型上实现了高达 4.24 倍的推理速度提升和 86.7% 的内存消耗降低，在 GPT-style 模型上则提升 2.58 倍并降低 90.3%。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.DC",
      "comment": "Accepted by the 42nd IEEE International Conference on Computer Design\n  (ICCD 2024)",
      "pdf_url": "http://arxiv.org/pdf/2409.04249v2",
      "published_date": "2024-09-06 12:55:49 UTC",
      "updated_date": "2024-09-09 18:25:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:56:02.154275"
    },
    {
      "arxiv_id": "2409.04244v1",
      "title": "WarpAdam: A new Adam optimizer based on Meta-Learning approach",
      "title_zh": "WarpAdam: 一种基于元学习方法的新的 Adam 优化器",
      "authors": [
        "Chengxi Pan",
        "Junshang Chen",
        "Jingrui Ye"
      ],
      "abstract": "Optimal selection of optimization algorithms is crucial for training deep\nlearning models. The Adam optimizer has gained significant attention due to its\nefficiency and wide applicability. However, to enhance the adaptability of\noptimizers across diverse datasets, we propose an innovative optimization\nstrategy by integrating the 'warped gradient descend'concept from Meta Learning\ninto the Adam optimizer. In the conventional Adam optimizer, gradients are\nutilized to compute estimates of gradient mean and variance, subsequently\nupdating model parameters. Our approach introduces a learnable distortion\nmatrix, denoted as P, which is employed for linearly transforming gradients.\nThis transformation slightly adjusts gradients during each iteration, enabling\nthe optimizer to better adapt to distinct dataset characteristics. By learning\nan appropriate distortion matrix P, our method aims to adaptively adjust\ngradient information across different data distributions, thereby enhancing\noptimization performance. Our research showcases the potential of this novel\napproach through theoretical insights and empirical evaluations. Experimental\nresults across various tasks and datasets validate the superiority of our\noptimizer that integrates the 'warped gradient descend' concept in terms of\nadaptability. Furthermore, we explore effective strategies for training the\nadaptation matrix P and identify scenarios where this method can yield optimal\nresults. In summary, this study introduces an innovative approach that merges\nthe 'warped gradient descend' concept from Meta Learning with the Adam\noptimizer. By introducing a learnable distortion matrix P within the optimizer,\nwe aim to enhance the model's generalization capability across diverse data\ndistributions, thus opening up new possibilities in the field of deep learning\noptimization.",
      "tldr_zh": "本文提出WarpAdam优化器，将Meta Learning中的warped gradient descend概念整合到Adam optimizer中，以提升其对不同数据集的适应性。通过引入一个可学习的扭曲矩阵P，对梯度进行线性变换，该方法能动态调整梯度信息，提高优化性能。实验结果显示，WarpAdam在各种任务和数据集上表现出色，增强了模型的泛化能力，并探讨了训练P的有效策略。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.04244v1",
      "published_date": "2024-09-06 12:51:10 UTC",
      "updated_date": "2024-09-06 12:51:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:56:13.183857"
    },
    {
      "arxiv_id": "2409.15324v1",
      "title": "Cognitive phantoms in LLMs through the lens of latent variables",
      "title_zh": "通过潜变量的视角审视大型语言模型中的认知幻影",
      "authors": [
        "Sanne Peereboom",
        "Inga Schwabe",
        "Bennett Kleinberg"
      ],
      "abstract": "Large language models (LLMs) increasingly reach real-world applications,\nnecessitating a better understanding of their behaviour. Their size and\ncomplexity complicate traditional assessment methods, causing the emergence of\nalternative approaches inspired by the field of psychology. Recent studies\nadministering psychometric questionnaires to LLMs report human-like traits in\nLLMs, potentially influencing LLM behaviour. However, this approach suffers\nfrom a validity problem: it presupposes that these traits exist in LLMs and\nthat they are measurable with tools designed for humans. Typical procedures\nrarely acknowledge the validity problem in LLMs, comparing and interpreting\naverage LLM scores. This study investigates this problem by comparing latent\nstructures of personality between humans and three LLMs using two validated\npersonality questionnaires. Findings suggest that questionnaires designed for\nhumans do not validly measure similar constructs in LLMs, and that these\nconstructs may not exist in LLMs at all, highlighting the need for psychometric\nanalyses of LLM responses to avoid chasing cognitive phantoms.\n  Keywords: large language models, psychometrics, machine behaviour, latent\nvariable modeling, validity",
      "tldr_zh": "该研究探讨了大型语言模型（LLMs）中“认知幻影”（cognitive phantoms）的概念，质疑使用心理测量工具（如人格问卷）来评估 LLMs 是否具有人类般的特质的有效性问题。研究者通过比较人类和三个 LLMs 的个性潜在结构（latent variables），利用两个经过验证的人格问卷进行分析，发现这些工具无法在 LLMs 中有效测量类似结构，表明这些认知特质可能在 LLMs 中不存在。最终，该论文强调需要对 LLMs 的响应进行心理测量（psychometrics）分析，以避免追逐虚幻的认知特征，并为更准确的机器行为（machine behaviour）评估提供指导。",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.15324v1",
      "published_date": "2024-09-06 12:42:35 UTC",
      "updated_date": "2024-09-06 12:42:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:56:26.886729"
    },
    {
      "arxiv_id": "2409.04230v1",
      "title": "SPACE: A Python-based Simulator for Evaluating Decentralized Multi-Robot Task Allocation Algorithms",
      "title_zh": "翻译失败",
      "authors": [
        "Inmo Jang"
      ],
      "abstract": "Swarm robotics explores the coordination of multiple robots to achieve\ncollective goals, with collective decision-making being a central focus. This\nprocess involves decentralized robots autonomously making local decisions and\ncommunicating them, which influences the overall emergent behavior. Testing\nsuch decentralized algorithms in real-world scenarios with hundreds or more\nrobots is often impractical, underscoring the need for effective simulation\ntools. We propose SPACE (Swarm Planning and Control Evaluation), a Python-based\nsimulator designed to support the research, evaluation, and comparison of\ndecentralized Multi-Robot Task Allocation (MRTA) algorithms. SPACE streamlines\ncore algorithmic development by allowing users to implement decision-making\nalgorithms as Python plug-ins, easily construct agent behavior trees via an\nintuitive GUI, and leverage built-in support for inter-agent communication and\nlocal task awareness. To demonstrate its practical utility, we implement and\nevaluate CBBA and GRAPE within the simulator, comparing their performance\nacross different metrics, particularly in scenarios with dynamically introduced\ntasks. This evaluation shows the usefulness of SPACE in conducting rigorous and\nstandardized comparisons of MRTA algorithms, helping to support future research\nin the field.",
      "tldr_zh": "本研究提出 SPACE，一种基于 Python 的模拟器，用于评估分散式多机器人任务分配（Multi-Robot Task Allocation, MRTA）算法，旨在解决群机器人（swarm robotics）集体决策的测试挑战。SPACE 允许用户通过 Python 插件实现决策算法、利用直观 GUI 构建代理行为树，并提供内置支持如代理间通信和本地任务感知，从而简化算法开发和评估。研究者在模拟器中实现了 CBBA 和 GRAPE 算法，并在动态任务场景下比较其性能，展示了 SPACE 在进行标准化比较方面的实用性。该工具有助于推进 MRTA 算法的未来研究，提供高效的实验平台。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.04230v1",
      "published_date": "2024-09-06 12:38:24 UTC",
      "updated_date": "2024-09-06 12:38:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:56:37.825970"
    },
    {
      "arxiv_id": "2409.15323v1",
      "title": "Introducing ELLIPS: An Ethics-Centered Approach to Research on LLM-Based Inference of Psychiatric Conditions",
      "title_zh": "翻译失败",
      "authors": [
        "Roberta Rocca",
        "Giada Pistilli",
        "Kritika Maheshwari",
        "Riccardo Fusaroli"
      ],
      "abstract": "As mental health care systems worldwide struggle to meet demand, there is\nincreasing focus on using language models to infer neuropsychiatric conditions\nor psychopathological traits from language production. Yet, so far, this\nresearch has only delivered solutions with limited clinical applicability, due\nto insufficient consideration of ethical questions crucial to ensuring the\nsynergy between possible applications and model design. To accelerate progress\ntowards clinically applicable models, our paper charts the ethical landscape of\nresearch on language-based inference of psychopathology and provides a\npractical tool for researchers to navigate it. We identify seven core ethical\nprinciples that should guide model development and deployment in this domain,\ntranslate them into ELLIPS, an ethical toolkit operationalizing these\nprinciples into questions that can guide researchers' choices with respect to\ndata selection, architectures, evaluation, and model deployment, and provide a\ncase study exemplifying its use. With this, we aim to facilitate the emergence\nof model technology with concrete potential for real-world applicability.",
      "tldr_zh": "该论文探讨了使用大型语言模型(LLM)从语言生产中推断神经精神疾病或心理病理特征的研究，但强调现有工作因忽略关键伦理问题而导致临床适用性有限。为解决这一问题，研究者引入了ELLIPS，这是一个以伦理为中心的工具包，基于七个核心伦理原则，将其转化为具体问题，以指导研究者在数据选择、模型架构、评估和部署等方面做出决策。通过一个案例研究，论文展示了ELLIPS的使用方式，旨在促进LLM技术向现实世界应用的进展。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.15323v1",
      "published_date": "2024-09-06 12:27:38 UTC",
      "updated_date": "2024-09-06 12:27:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:56:49.431492"
    },
    {
      "arxiv_id": "2409.04224v1",
      "title": "Advancing Multi-Organ Disease Care: A Hierarchical Multi-Agent Reinforcement Learning Framework",
      "title_zh": "翻译失败",
      "authors": [
        "Daniel J. Tan",
        "Qianyi Xu",
        "Kay Choong See",
        "Dilruk Perera",
        "Mengling Feng"
      ],
      "abstract": "Multi-organ diseases present significant challenges due to their simultaneous\nimpact on multiple organ systems, necessitating complex and adaptive treatment\nstrategies. Despite recent advancements in AI-powered healthcare decision\nsupport systems, existing solutions are limited to individual organ systems.\nThey often ignore the intricate dependencies between organ system and thereby\nfails to provide holistic treatment recommendations that are useful in\npractice. We propose a novel hierarchical multi-agent reinforcement learning\n(HMARL) framework to address these challenges. This framework uses dedicated\nagents for each organ system, and model dynamic through explicit inter-agent\ncommunication channels, enabling coordinated treatment strategies across\norgans. Furthermore, we introduce a dual-layer state representation technique\nto contextualize patient conditions at various hierarchical levels, enhancing\nthe treatment accuracy and relevance. Through extensive qualitative and\nquantitative evaluations in managing sepsis (a complex multi-organ disease),\nour approach demonstrates its ability to learn effective treatment policies\nthat significantly improve patient survival rates. This framework marks a\nsubstantial advancement in clinical decision support systems, pioneering a\ncomprehensive approach for multi-organ treatment recommendations.",
      "tldr_zh": "该研究针对多器官疾病的复杂挑战，提出了一种层次化多智能体强化学习（HMARL）框架，以解决现有AI决策支持系统仅限于单一器官系统的局限性。该框架通过为每个器官系统分配专属智能体，并利用显式智能体间通信渠道来建模器官间动态依赖，实现跨器官协调治疗策略。此外，引入双层状态表示技术来增强患者条件在不同层次的上下文化。实验在败血症（sepsis）管理中显示，该方法显著提高了患者生存率，为多器官疾病的综合临床决策支持系统提供了创新途径。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.04224v1",
      "published_date": "2024-09-06 12:26:47 UTC",
      "updated_date": "2024-09-06 12:26:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:57:01.736925"
    },
    {
      "arxiv_id": "2409.04196v2",
      "title": "GST: Precise 3D Human Body from a Single Image with Gaussian Splatting Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Lorenza Prospero",
        "Abdullah Hamdi",
        "Joao F. Henriques",
        "Christian Rupprecht"
      ],
      "abstract": "Reconstructing posed 3D human models from monocular images has important\napplications in the sports industry, including performance tracking, injury\nprevention and virtual training. In this work, we combine 3D human pose and\nshape estimation with 3D Gaussian Splatting (3DGS), a representation of the\nscene composed of a mixture of Gaussians. This allows training or fine-tuning a\nhuman model predictor on multi-view images alone, without 3D ground truth.\nPredicting such mixtures for a human from a single input image is challenging\ndue to self-occlusions and dependence on articulations, while also needing to\nretain enough flexibility to accommodate a variety of clothes and poses. Our\nkey observation is that the vertices of standardized human meshes (such as\nSMPL) can provide an adequate spatial density and approximate initial position\nfor the Gaussians. We can then train a transformer model to jointly predict\ncomparatively small adjustments to these positions, as well as the other 3DGS\nattributes and the SMPL parameters. We show empirically that this combination\n(using only multi-view supervision) can achieve near real-time inference of 3D\nhuman models from a single image without expensive diffusion models or 3D\npoints supervision, thus making it ideal for the sport industry at any level.\nMore importantly, rendering is an effective auxiliary objective to refine 3D\npose estimation by accounting for clothes and other geometric variations. The\ncode is available at https://github.com/prosperolo/GST.",
      "tldr_zh": "本研究提出 GST 方法，通过结合 3D 人体姿势和形状估计与 3D Gaussian Splatting (3DGS)，从单张图像精确重建姿势 3D 人体模型，适用于体育行业的性能跟踪、伤病预防和虚拟训练。方法利用 SMPL 网格的顶点作为高斯初始位置，并训练 Transformer 模型来预测位置调整、其他 3DGS 属性以及 SMPL 参数，仅需多视图图像监督而无需 3D 地面真实数据。实验结果显示，该方法实现近实时推断，并通过渲染作为辅助目标来改进 3D 姿势估计，考虑衣服和几何变化，提供高效的解决方案。代码已在 GitHub 开源。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Camera ready for CVSports workshop at CVPR 2025",
      "pdf_url": "http://arxiv.org/pdf/2409.04196v2",
      "published_date": "2024-09-06 11:34:24 UTC",
      "updated_date": "2025-04-16 14:37:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:57:14.151303"
    },
    {
      "arxiv_id": "2409.04194v2",
      "title": "Towards Privacy-Preserving Relational Data Synthesis via Probabilistic Relational Models",
      "title_zh": "翻译失败",
      "authors": [
        "Malte Luttermann",
        "Ralf Möller",
        "Mattis Hartwig"
      ],
      "abstract": "Probabilistic relational models provide a well-established formalism to\ncombine first-order logic and probabilistic models, thereby allowing to\nrepresent relationships between objects in a relational domain. At the same\ntime, the field of artificial intelligence requires increasingly large amounts\nof relational training data for various machine learning tasks. Collecting\nreal-world data, however, is often challenging due to privacy concerns, data\nprotection regulations, high costs, and so on. To mitigate these challenges,\nthe generation of synthetic data is a promising approach. In this paper, we\nsolve the problem of generating synthetic relational data via probabilistic\nrelational models. In particular, we propose a fully-fledged pipeline to go\nfrom relational database to probabilistic relational model, which can then be\nused to sample new synthetic relational data points from its underlying\nprobability distribution. As part of our proposed pipeline, we introduce a\nlearning algorithm to construct a probabilistic relational model from a given\nrelational database.",
      "tldr_zh": "该论文针对人工智能领域中关系数据获取的隐私和法规挑战，提出使用Probabilistic Relational Models来生成合成关系数据，以替代真实数据。研究者设计了一个完整管道，从关系数据库构建Probabilistic Relational Models，并引入一个学习算法来实现这一转换。最终，该模型可从其概率分布中采样生成新的合成数据点，从而实现隐私保护的数据合成。",
      "categories": [
        "cs.AI",
        "cs.DB",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to the Proceedings of the 47th German Conference on\n  Artificial Intelligence (KI 2024)",
      "pdf_url": "http://arxiv.org/pdf/2409.04194v2",
      "published_date": "2024-09-06 11:24:25 UTC",
      "updated_date": "2024-10-02 17:01:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:57:26.834822"
    },
    {
      "arxiv_id": "2409.04183v1",
      "title": "GALLa: Graph Aligned Large Language Models for Improved Source Code Understanding",
      "title_zh": "GALLa：图对齐的大型语言模型，用于改进源代码理解",
      "authors": [
        "Ziyin Zhang",
        "Hang Yu",
        "Shijie Li",
        "Peng Di",
        "Jianguo Li",
        "Rui Wang"
      ],
      "abstract": "Programming languages possess rich semantic information such as data flow\nthat is represented by graphs and not available from the surface form of source\ncode. Recent code language models have scaled to billions of parameters, but\nmodel source code solely as text tokens while ignoring any other structural\ninformation. Conversely, models that do encode structural information of code\nmake modifications to the Transformer architecture, limiting their scale and\ncompatibility with pretrained LLMs. In this work, we take the best of both\nworlds with GALLa - Graph Aligned Large Language Model. GALLa utilizes graph\nneural networks and cross-modal alignment technologies to inject the structural\ninformation of code into LLMs as an auxiliary task during finetuning. This\nframework is both model-agnostic and task-agnostic, as it can be applied to any\ncode LLM for any code downstream task, and requires the structural graph data\nonly at training time from a corpus unrelated to the finetuning data, while\nincurring no cost at inference time over the baseline LLM. Experiments on five\ncode tasks with four different baseline LLMs ranging in size from 350M to 8B\nvalidate the effectiveness of GALLa, demonstrating consistent improvement over\nthe baseline, even for powerful models such as LLaMA3.",
      "tldr_zh": "该论文提出 GALLa 框架，利用图神经网络（Graph Neural Networks）和跨模态对齐技术（Cross-modal Alignment），在大型语言模型（LLMs）的微调过程中注入源代码的结构信息（如数据流图），从而提升代码理解能力。GALLa 的设计是模型无关和任务无关的，仅需在训练时使用与微调数据无关的结构图数据，在推理时不增加基线模型的成本。实验在五个代码任务上验证了其有效性，使用从 350M 到 8B 参数的四个基线 LLM（如 LLaMA3），GALLa  consistently 改善了性能，甚至在强大模型上也表现出显著提升。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.04183v1",
      "published_date": "2024-09-06 10:57:34 UTC",
      "updated_date": "2024-09-06 10:57:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:57:39.977306"
    },
    {
      "arxiv_id": "2409.04180v2",
      "title": "The Prevalence of Neural Collapse in Neural Multivariate Regression",
      "title_zh": "翻译失败",
      "authors": [
        "George Andriopoulos",
        "Zixuan Dong",
        "Li Guo",
        "Zifan Zhao",
        "Keith Ross"
      ],
      "abstract": "Recently it has been observed that neural networks exhibit Neural Collapse\n(NC) during the final stage of training for the classification problem. We\nempirically show that multivariate regression, as employed in imitation\nlearning and other applications, exhibits Neural Regression Collapse (NRC), a\nnew form of neural collapse: (NRC1) The last-layer feature vectors collapse to\nthe subspace spanned by the $n$ principal components of the feature vectors,\nwhere $n$ is the dimension of the targets (for univariate regression, $n=1$);\n(NRC2) The last-layer feature vectors also collapse to the subspace spanned by\nthe last-layer weight vectors; (NRC3) The Gram matrix for the weight vectors\nconverges to a specific functional form that depends on the covariance matrix\nof the targets. After empirically establishing the prevalence of (NRC1)-(NRC3)\nfor a variety of datasets and network architectures, we provide an explanation\nof these phenomena by modeling the regression task in the context of the\nUnconstrained Feature Model (UFM), in which the last layer feature vectors are\ntreated as free variables when minimizing the loss function. We show that when\nthe regularization parameters in the UFM model are strictly positive, then\n(NRC1)-(NRC3) also emerge as solutions in the UFM optimization problem. We also\nshow that if the regularization parameters are equal to zero, then there is no\ncollapse. To our knowledge, this is the first empirical and theoretical study\nof neural collapse in the context of regression. This extension is significant\nnot only because it broadens the applicability of neural collapse to a new\ncategory of problems but also because it suggests that the phenomena of neural\ncollapse could be a universal behavior in deep learning.",
      "tldr_zh": "该论文研究了神经网络在多变量回归中的 Neural Collapse 现象，引入了 Neural Regression Collapse (NRC) 概念，观察到训练后期会出现三个关键特征：(NRC1) 最后一层特征向量崩溃到目标维度 n 的主成分子空间；(NRC2) 特征向量也崩溃到最后一层权重向量的子空间；(NRC3) 权重向量的 Gram 矩阵收敛到一个依赖目标协方差矩阵的特定形式。\n\n通过在多种数据集和网络架构上的实验，论文证明了 NRC 的普遍性，并使用 Unconstrained Feature Model (UFM) 模型进行理论解释，显示正则化参数大于零时 NRC 会出现，而为零时则不会。\n\n这项工作首次将 Neural Collapse 扩展到回归问题，不仅拓宽了其适用范围，还暗示这可能是深度学习中的普遍行为。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Published at NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.04180v2",
      "published_date": "2024-09-06 10:45:58 UTC",
      "updated_date": "2024-10-30 02:32:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:57:52.556812"
    },
    {
      "arxiv_id": "2409.04168v2",
      "title": "From Calculation to Adjudication: Examining LLM judges on Mathematical Reasoning Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Andreas Stephan",
        "Dawei Zhu",
        "Matthias Aßenmacher",
        "Xiaoyu Shen",
        "Benjamin Roth"
      ],
      "abstract": "To reduce the need for human annotations, large language models (LLMs) have\nbeen proposed as judges of the quality of other candidate models. The\nperformance of LLM judges is typically evaluated by measuring the correlation\nwith human judgments on generative tasks such as summarization or machine\ntranslation. In contrast, we study LLM judges on mathematical reasoning tasks.\nThese tasks require multi-step reasoning, and the correctness of their\nsolutions is verifiable, enabling a more objective evaluation. We perform a\ndetailed performance analysis and find that easy samples are easy to judge, and\ndifficult samples are difficult to judge. Our analysis uncovers a strong\ncorrelation between judgment performance and the candidate model task\nperformance, indicating that judges tend to favor higher-quality models even if\ntheir answer is incorrect. As a consequence, we test whether we can predict the\nbehavior of LLM judges using simple features such as part-of-speech tags and\nfind that we can correctly predict 70%-75% of judgments. We conclude this study\nby analyzing practical use cases, showing that LLM judges consistently detect\nthe on-average better model but largely fail if we use them to improve task\nperformance.",
      "tldr_zh": "这篇论文探讨了大型语言模型(LLMs)作为裁判者在数学推理任务中的表现，这些任务涉及多步推理且答案可验证。研究发现，LLMs判断性能与样本难度相关，即容易样本易判断，而困难样本判断较差，且裁判者倾向于偏好任务性能更高的候选模型，即使其答案不正确。通过分析简单特征如词性标签，研究者能准确预测70%-75%的判断结果。最终，LLMs裁判者能识别平均表现更好的模型，但无法有效用于提升任务性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.04168v2",
      "published_date": "2024-09-06 10:09:41 UTC",
      "updated_date": "2025-05-12 19:41:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:58:03.527827"
    },
    {
      "arxiv_id": "2409.04142v1",
      "title": "Context is the Key: Backdoor Attacks for In-Context Learning with Vision Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Gorka Abad",
        "Stjepan Picek",
        "Lorenzo Cavallaro",
        "Aitor Urbieta"
      ],
      "abstract": "Due to the high cost of training, large model (LM) practitioners commonly use\npretrained models downloaded from untrusted sources, which could lead to owning\ncompromised models. In-context learning is the ability of LMs to perform\nmultiple tasks depending on the prompt or context. This can enable new attacks,\nsuch as backdoor attacks with dynamic behavior depending on how models are\nprompted.\n  In this paper, we leverage the ability of vision transformers (ViTs) to\nperform different tasks depending on the prompts. Then, through data poisoning,\nwe investigate two new threats: i) task-specific backdoors where the attacker\nchooses a target task to attack, and only the selected task is compromised at\ntest time under the presence of the trigger. At the same time, any other task\nis not affected, even if prompted with the trigger. We succeeded in attacking\nevery tested model, achieving up to 89.90\\% degradation on the target task. ii)\nWe generalize the attack, allowing the backdoor to affect \\emph{any} task, even\ntasks unseen during the training phase. Our attack was successful on every\ntested model, achieving a maximum of $13\\times$ degradation. Finally, we\ninvestigate the robustness of prompts and fine-tuning as techniques for\nremoving the backdoors from the model. We found that these methods fall short\nand, in the best case, reduce the degradation from 89.90\\% to 73.46\\%.",
      "tldr_zh": "本研究探讨了视觉变压器 (Vision Transformers, ViTs) 在 in-context learning 中的安全风险，提出通过数据投毒 (data poisoning) 实现后门攻击 (backdoor attacks)。攻击包括任务特定后门，仅在触发器出现时影响目标任务，导致目标任务性能下降高达 89.90%，而其他任务不受影响；以及泛化后门，可攻击任何任务（甚至训练中未见的任务），实现最大 13 倍的性能退化。实验证明，这些攻击在所有测试模型上成功，但使用提示或微调等方法移除后门的尝试效果有限，最多仅将性能下降从 89.90% 减至 73.46%。这揭示了预训练模型潜在威胁，并强调了需要更有效的防御策略。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.04142v1",
      "published_date": "2024-09-06 09:16:39 UTC",
      "updated_date": "2024-09-06 09:16:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:58:15.654597"
    },
    {
      "arxiv_id": "2409.04117v1",
      "title": "Confidence-Aware Document OCR Error Detection",
      "title_zh": "置信度感知的文档 OCR 错误检测",
      "authors": [
        "Arthur Hemmer",
        "Mickaël Coustaty",
        "Nicola Bartolo",
        "Jean-Marc Ogier"
      ],
      "abstract": "Optical Character Recognition (OCR) continues to face accuracy challenges\nthat impact subsequent applications. To address these errors, we explore the\nutility of OCR confidence scores for enhancing post-OCR error detection. Our\nstudy involves analyzing the correlation between confidence scores and error\nrates across different OCR systems. We develop ConfBERT, a BERT-based model\nthat incorporates OCR confidence scores into token embeddings and offers an\noptional pre-training phase for noise adjustment. Our experimental results\ndemonstrate that integrating OCR confidence scores can enhance error detection\ncapabilities. This work underscores the importance of OCR confidence scores in\nimproving detection accuracy and reveals substantial disparities in performance\nbetween commercial and open-source OCR technologies.",
      "tldr_zh": "本研究探讨了光学字符识别(OCR)准确性问题，并通过分析OCR置信度分数与错误率的相关性，来提升后续错误检测能力。研究开发了ConfBERT，一种基于BERT的模型，将OCR置信度分数整合到token embeddings中，并提供可选的预训练阶段以调整噪声。实验结果显示，这种方法显著提高了错误检测性能，并突出了商业OCR与开源OCR技术在表现上的显著差异。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.04117v1",
      "published_date": "2024-09-06 08:35:28 UTC",
      "updated_date": "2024-09-06 08:35:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:58:27.200908"
    },
    {
      "arxiv_id": "2409.04114v1",
      "title": "Multi-Programming Language Ensemble for Code Generation in Large Language Model",
      "title_zh": "翻译失败",
      "authors": [
        "Tengfei Xue",
        "Xuefeng Li",
        "Tahir Azim",
        "Roman Smirnov",
        "Jianhui Yu",
        "Arash Sadrieh",
        "Babak Pahlavan"
      ],
      "abstract": "Large language models (LLMs) have significantly improved code generation,\nparticularly in one-pass code generation. However, most existing approaches\nfocus solely on generating code in a single programming language, overlooking\nthe potential of leveraging the multi-language capabilities of LLMs. LLMs have\nvarying patterns of errors across different languages, suggesting that a more\nrobust approach could be developed by leveraging these multi-language outputs.\nIn this study, we propose Multi-Programming Language Ensemble (MPLE), a novel\nensemble-based method that utilizes code generation across multiple programming\nlanguages to enhance overall performance. By treating each language-specific\ncode generation process as an individual \"weak expert\" and effectively\nintegrating their outputs, our method mitigates language-specific errors and\nbiases. This multi-language ensemble strategy leverages the complementary\nstrengths of different programming languages, enabling the model to produce\nmore accurate and robust code. Our approach can be seamlessly integrated with\ncommonly used techniques such as the reflection algorithm and Monte Carlo tree\nsearch to improve code generation quality further. Experimental results show\nthat our framework consistently enhances baseline performance by up to 17.92%\non existing benchmarks (HumanEval and HumanEval-plus), with a standout result\nof 96.25% accuracy on the HumanEval benchmark, achieving new state-of-the-art\nresults across various LLM models. The code will be released at\nhttps://github.com/NinjaTech-AI/MPLE",
      "tldr_zh": "该研究提出 Multi-Programming Language Ensemble (MPLE)，一种新型集成方法，利用大型语言模型(LLMs)在多编程语言中生成代码，以缓解单一语言的错误模式和偏差。MPLE 将每个语言的代码生成视为“弱专家”，通过整合它们的输出并结合反射算法和 Monte Carlo 树搜索，增强代码的准确性和鲁棒性。实验结果显示，该框架在 HumanEval 和 HumanEval-plus 基准上提升基线性能高达 17.92%，HumanEval 准确率达到 96.25%，实现了新的最先进水平。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Code available at https://github.com/NinjaTech-AI/MPLE",
      "pdf_url": "http://arxiv.org/pdf/2409.04114v1",
      "published_date": "2024-09-06 08:31:18 UTC",
      "updated_date": "2024-09-06 08:31:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:58:40.080833"
    },
    {
      "arxiv_id": "2409.04109v1",
      "title": "Can LLMs Generate Novel Research Ideas? A Large-Scale Human Study with 100+ NLP Researchers",
      "title_zh": "翻译失败",
      "authors": [
        "Chenglei Si",
        "Diyi Yang",
        "Tatsunori Hashimoto"
      ],
      "abstract": "Recent advancements in large language models (LLMs) have sparked optimism\nabout their potential to accelerate scientific discovery, with a growing number\nof works proposing research agents that autonomously generate and validate new\nideas. Despite this, no evaluations have shown that LLM systems can take the\nvery first step of producing novel, expert-level ideas, let alone perform the\nentire research process. We address this by establishing an experimental design\nthat evaluates research idea generation while controlling for confounders and\nperforms the first head-to-head comparison between expert NLP researchers and\nan LLM ideation agent. By recruiting over 100 NLP researchers to write novel\nideas and blind reviews of both LLM and human ideas, we obtain the first\nstatistically significant conclusion on current LLM capabilities for research\nideation: we find LLM-generated ideas are judged as more novel (p < 0.05) than\nhuman expert ideas while being judged slightly weaker on feasibility. Studying\nour agent baselines closely, we identify open problems in building and\nevaluating research agents, including failures of LLM self-evaluation and their\nlack of diversity in generation. Finally, we acknowledge that human judgements\nof novelty can be difficult, even by experts, and propose an end-to-end study\ndesign which recruits researchers to execute these ideas into full projects,\nenabling us to study whether these novelty and feasibility judgements result in\nmeaningful differences in research outcome.",
      "tldr_zh": "这篇论文通过一个大规模人类研究，评估了大型语言模型 (LLMs) 是否能生成新颖的研究想法，招募了 100 多名 NLP 研究者进行想法生成和盲审对比。结果显示，LLM 生成的想法在新颖性上被评为高于人类专家 (p < 0.05)，但在可行性上略逊色。研究还识别了 LLM 在自我评估和生成多样性方面的不足问题，并提出未来端到端研究设计，让研究者执行这些想法，以检验新颖性和可行性对实际研究成果的影响。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "main paper is 20 pages",
      "pdf_url": "http://arxiv.org/pdf/2409.04109v1",
      "published_date": "2024-09-06 08:25:03 UTC",
      "updated_date": "2024-09-06 08:25:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:58:51.838040"
    },
    {
      "arxiv_id": "2409.04104v1",
      "title": "MixNet: Joining Force of Classical and Modern Approaches Toward the Comprehensive Pipeline in Motor Imagery EEG Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Phairot Autthasan",
        "Rattanaphon Chaisaen",
        "Huy Phan",
        "Maarten De Vos",
        "Theerawit Wilaiprasitporn"
      ],
      "abstract": "Recent advances in deep learning (DL) have significantly impacted motor\nimagery (MI)-based brain-computer interface (BCI) systems, enhancing the\ndecoding of electroencephalography (EEG) signals. However, most studies\nstruggle to identify discriminative patterns across subjects during MI tasks,\nlimiting MI classification performance. In this article, we propose MixNet, a\nnovel classification framework designed to overcome this limitation by\nutilizing spectral-spatial signals from MI data, along with a multitask\nlearning architecture named MIN2Net, for classification. Here, the\nspectral-spatial signals are generated using the filter-bank common spatial\npatterns (FBCSPs) method on MI data. Since the multitask learning architecture\nis used for the classification task, the learning in each task may exhibit\ndifferent generalization rates and potential overfitting across tasks. To\naddress this issue, we implement adaptive gradient blending, simultaneously\nregulating multiple loss weights and adjusting the learning pace for each task\nbased on its generalization/overfitting tendencies. Experimental results on six\nbenchmark data sets of different data sizes demonstrate that MixNet\nconsistently outperforms all state-of-the-art algorithms in subject-dependent\nand -independent settings. Finally, the low-density EEG MI classification\nresults show that MixNet outperforms all state-of-the-art algorithms, offering\npromising implications for Internet of Thing (IoT) applications, such as\nlightweight and portable EEG wearable devices based on low-density montages.",
      "tldr_zh": "这篇论文提出了 MixNet，一种结合经典和现代方法的综合框架，旨在提升运动想象 (MI) 基于脑机接口 (BCI) 的 EEG 信号分类性能，通过 filter-bank common spatial patterns (FBCSPs) 方法生成谱-空间信号，并采用 multitask learning 架构 MIN2Net 进行分类。针对多任务学习中可能出现的泛化率差异和过拟合问题，MixNet 引入 adaptive gradient blending 技术来动态调节损失权重和学习步伐。在六个基准数据集上的实验结果显示，MixNet 在受试者相关和无关设置中均优于现有算法，尤其在低密度 EEG 分类中表现出色，为 Internet of Things (IoT) 应用（如便携式 EEG 设备）提供了重要潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.HC",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "Supplementary materials and source codes are available on-line at\n  https://github.com/Max-Phairot-A/MixNet",
      "pdf_url": "http://arxiv.org/pdf/2409.04104v1",
      "published_date": "2024-09-06 08:14:58 UTC",
      "updated_date": "2024-09-06 08:14:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:59:05.476659"
    },
    {
      "arxiv_id": "2409.04103v1",
      "title": "The Role of Graph Topology in the Performance of Biomedical Knowledge Graph Completion Models",
      "title_zh": "图拓扑在生物医学知识图谱补全模型性能中的作用",
      "authors": [
        "Alberto Cattaneo",
        "Stephen Bonner",
        "Thomas Martynec",
        "Carlo Luschi",
        "Ian P Barrett",
        "Daniel Justus"
      ],
      "abstract": "Knowledge Graph Completion has been increasingly adopted as a useful method\nfor several tasks in biomedical research, like drug repurposing or drug-target\nidentification. To that end, a variety of datasets and Knowledge Graph\nEmbedding models has been proposed over the years. However, little is known\nabout the properties that render a dataset useful for a given task and, even\nthough theoretical properties of Knowledge Graph Embedding models are well\nunderstood, their practical utility in this field remains controversial. We\nconduct a comprehensive investigation into the topological properties of\npublicly available biomedical Knowledge Graphs and establish links to the\naccuracy observed in real-world applications. By releasing all model\npredictions and a new suite of analysis tools we invite the community to build\nupon our work and continue improving the understanding of these crucial\napplications.",
      "tldr_zh": "这篇论文探讨了图拓扑(Graph Topology)在生物医学知识图谱完成(Knowledge Graph Completion)模型性能中的作用，针对生物医学研究任务如药物再利用或药物靶点识别。作者通过全面调查公开可用的生物医学知识图谱(Biomedical Knowledge Graphs)的拓扑属性，建立了这些属性与实际应用准确性的联系。最终，他们发布了模型预测和一套新的分析工具，邀请社区基于此工作进一步提升对这些应用的理解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.QM"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.04103v1",
      "published_date": "2024-09-06 08:09:15 UTC",
      "updated_date": "2024-09-06 08:09:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:59:15.191176"
    },
    {
      "arxiv_id": "2409.04102v2",
      "title": "Intelligent tutoring systems by Bayesian nets with noisy gates",
      "title_zh": "翻译失败",
      "authors": [
        "Alessandro Antonucci",
        "Francesca Mangili",
        "Claudio Bonesana",
        "Giorgia Adorni"
      ],
      "abstract": "Directed graphical models such as Bayesian nets are often used to implement\nintelligent tutoring systems able to interact in real-time with learners in a\npurely automatic way. When coping with such models, keeping a bound on the\nnumber of parameters might be important for multiple reasons. First, as these\nmodels are typically based on expert knowledge, a huge number of parameters to\nelicit might discourage practitioners from adopting them. Moreover, the number\nof model parameters affects the complexity of the inferences, while a fast\ncomputation of the queries is needed for real-time feedback. We advocate\nlogical gates with uncertainty for a compact parametrization of the conditional\nprobability tables in the underlying Bayesian net used by tutoring systems. We\ndiscuss the semantics of the model parameters to elicit and the assumptions\nrequired to apply such approach in this domain. We also derive a dedicated\ninference scheme to speed up computations.",
      "tldr_zh": "该论文提出了一种基于带有噪声门的 Bayesian nets 构建智能辅导系统的方法，以减少模型参数数量并支持实时互动。传统 Bayesian nets 在智能辅导系统中面临参数过多的问题，这会增加专家知识获取难度和推理复杂度；为此，作者引入 logical gates with uncertainty 来紧凑地参数化条件概率表（conditional probability tables）。论文讨论了这些模型参数的语义、所需假设，并设计了一个专属的 inference scheme 以加速计算，从而使系统更易于实际应用。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.04102v2",
      "published_date": "2024-09-06 08:08:55 UTC",
      "updated_date": "2024-09-09 08:55:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:59:28.056300"
    },
    {
      "arxiv_id": "2409.04082v1",
      "title": "SDformerFlow: Spatiotemporal swin spikeformer for event-based optical flow estimation",
      "title_zh": "翻译失败",
      "authors": [
        "Yi Tian",
        "Juan Andrade-Cetto"
      ],
      "abstract": "Event cameras generate asynchronous and sparse event streams capturing\nchanges in light intensity. They offer significant advantages over conventional\nframe-based cameras, such as a higher dynamic range and an extremely faster\ndata rate, making them particularly useful in scenarios involving fast motion\nor challenging lighting conditions. Spiking neural networks (SNNs) share\nsimilar asynchronous and sparse characteristics and are well-suited for\nprocessing data from event cameras. Inspired by the potential of transformers\nand spike-driven transformers (spikeformers) in other computer vision tasks, we\npropose two solutions for fast and robust optical flow estimation for event\ncameras: STTFlowNet and SDformerFlow. STTFlowNet adopts a U-shaped artificial\nneural network (ANN) architecture with spatiotemporal shifted window\nself-attention (swin) transformer encoders, while SDformerFlow presents its\nfully spiking counterpart, incorporating swin spikeformer encoders.\nFurthermore, we present two variants of the spiking version with different\nneuron models. Our work is the first to make use of spikeformers for dense\noptical flow estimation. We conduct end-to-end training for all models using\nsupervised learning. Our results yield state-of-the-art performance among\nSNN-based event optical flow methods on both the DSEC and MVSEC datasets, and\nshow significant reduction in power consumption compared to the equivalent\nANNs.",
      "tldr_zh": "该论文提出两种基于事件相机的光流估计方法：STTFlowNet 和 SDformerFlow，以处理事件流的异步和稀疏特性。STTFlowNet 采用 U-shaped 人工神经网络 (ANN) 架构，结合时空移窗自注意力 (swin) transformer 编码器，而 SDformerFlow 是其完全脉冲神经网络 (SNN) 版本，使用 swin spikeformer 编码器，并探索了不同神经元模型的变体，这是首次将 spikeformers 应用于密集光流估计。实验结果显示，在 DSEC 和 MVSEC 数据集上，这些模型在 SNN-based 方法中达到最先进性能，同时显著降低了与等效 ANN 相比的功耗。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Under Review",
      "pdf_url": "http://arxiv.org/pdf/2409.04082v1",
      "published_date": "2024-09-06 07:48:18 UTC",
      "updated_date": "2024-09-06 07:48:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:59:41.036788"
    },
    {
      "arxiv_id": "2409.04081v3",
      "title": "UI-JEPA: Towards Active Perception of User Intent through Onscreen User Activity",
      "title_zh": "翻译失败",
      "authors": [
        "Yicheng Fu",
        "Raviteja Anantha",
        "Prabal Vashisht",
        "Jianpeng Cheng",
        "Etai Littwin"
      ],
      "abstract": "Generating user intent from a sequence of user interface (UI) actions is a\ncore challenge in comprehensive UI understanding. Recent advancements in\nmultimodal large language models (MLLMs) have led to substantial progress in\nthis area, but their demands for extensive model parameters, computing power,\nand high latency makes them impractical for scenarios requiring lightweight,\non-device solutions with low latency or heightened privacy. Additionally, the\nlack of high-quality datasets has hindered the development of such lightweight\nmodels. To address these challenges, we propose UI-JEPA, a novel framework that\nemploys masking strategies to learn abstract UI embeddings from unlabeled data\nthrough self-supervised learning, combined with an LLM decoder fine-tuned for\nuser intent prediction. We also introduce two new UI-grounded multimodal\ndatasets, \"Intent in the Wild\" (IIW) and \"Intent in the Tame\" (IIT), designed\nfor few-shot and zero-shot UI understanding tasks. IIW consists of 1.7K videos\nacross 219 intent categories, while IIT contains 914 videos across 10\ncategories. We establish the first baselines for these datasets, showing that\nrepresentations learned using a JEPA-style objective, combined with an LLM\ndecoder, can achieve user intent predictions that match the performance of\nstate-of-the-art large MLLMs, but with significantly reduced annotation and\ndeployment resources. Measured by intent similarity scores, UI-JEPA outperforms\nGPT-4 Turbo and Claude 3.5 Sonnet by 10.0% and 7.2% respectively, averaged\nacross two datasets. Notably, UI-JEPA accomplishes the performance with a 50.5x\nreduction in computational cost and a 6.6x improvement in latency in the IIW\ndataset. These results underscore the effectiveness of UI-JEPA, highlighting\nits potential for lightweight, high-performance UI understanding.",
      "tldr_zh": "该研究针对从用户界面(UI)动作序列中生成用户意图的核心挑战，提出UI-JEPA框架，该框架通过masking策略进行自监督学习，从无标签数据中学习抽象UI embeddings，并结合fine-tuned的LLM decoder实现高效的用户意图预测。研究还引入了两个新数据集：“Intent in the Wild”(IIW)包含1.7K视频和219意图类别，以及“Intent in the Tame”(IIT)包含914视频和10意图类别，用于few-shot和zero-shot UI理解任务。实验结果显示，UI-JEPA在意图相似性得分上平均超过GPT-4 Turbo和Claude 3.5 Sonnet 10.0%和7.2%，同时实现了计算成本减少50.5倍和延迟改善6.6倍，证明了其在轻量级、高性能UI理解中的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.04081v3",
      "published_date": "2024-09-06 07:44:44 UTC",
      "updated_date": "2024-10-02 05:00:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:59:54.204583"
    },
    {
      "arxiv_id": "2409.04073v2",
      "title": "AnyMatch -- Efficient Zero-Shot Entity Matching with a Small Language Model",
      "title_zh": "翻译失败",
      "authors": [
        "Zeyu Zhang",
        "Paul Groth",
        "Iacer Calixto",
        "Sebastian Schelter"
      ],
      "abstract": "Entity matching (EM) is the problem of determining whether two records refer\nto same real-world entity, which is crucial in data integration, e.g., for\nproduct catalogs or address databases. A major drawback of many EM approaches\nis their dependence on labelled examples. We thus focus on the challenging\nsetting of zero-shot entity matching where no labelled examples are available\nfor an unseen target dataset. Recently, large language models (LLMs) have shown\npromising results for zero-shot EM, but their low throughput and high\ndeployment cost limit their applicability and scalability.\n  We revisit the zero-shot EM problem with AnyMatch, a small language model\nfine-tuned in a transfer learning setup. We propose several novel data\nselection techniques to generate fine-tuning data for our model, e.g., by\nselecting difficult pairs to match via an AutoML filter, by generating\nadditional attribute-level examples, and by controlling label imbalance in the\ndata.\n  We conduct an extensive evaluation of the prediction quality and deployment\ncost of our model, in a comparison to thirteen baselines on nine benchmark\ndatasets. We find that AnyMatch provides competitive prediction quality despite\nits small parameter size: it achieves the second-highest F1 score overall, and\noutperforms several other approaches that employ models with hundreds of\nbillions of parameters. Furthermore, our approach exhibits major cost benefits:\nthe average prediction quality of AnyMatch is within 4.4% of the\nstate-of-the-art method MatchGPT with the proprietary trillion-parameter model\nGPT-4, yet AnyMatch requires four orders of magnitude less parameters and\nincurs a 3,899 times lower inference cost (in dollars per 1,000 tokens).",
      "tldr_zh": "本文提出 AnyMatch，一种基于小语言模型的零-shot Entity Matching 方法，通过转移学习和新型数据选择技术（如使用 AutoML 过滤器选择困难配对、生成属性级示例以及控制标签不平衡）来解决无标记数据的实体匹配挑战。实验在九个基准数据集上与十三种基线模型比较显示，AnyMatch 尽管参数量小，仍取得了第二高的 F1 score，并超越了部分数百亿参数模型。相比最先进方法 MatchGPT（基于 GPT-4），AnyMatch 的预测质量仅低 4.4%，但参数减少四个数量级，推理成本降低 3899 倍，提供显著的部署效率优势。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.CL",
      "comment": "12 pages excluding references, 3 figures, and 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2409.04073v2",
      "published_date": "2024-09-06 07:29:01 UTC",
      "updated_date": "2024-09-09 11:33:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:00:05.973886"
    },
    {
      "arxiv_id": "2409.04065v1",
      "title": "An Argumentative Approach for Explaining Preemption in Soft-Constraint Based Norms",
      "title_zh": "翻译失败",
      "authors": [
        "Wachara Fungwacharakorn",
        "Kanae Tsushima",
        "Hiroshi Hosobe",
        "Hideaki Takeda",
        "Ken Satoh"
      ],
      "abstract": "Although various aspects of soft-constraint based norms have been explored,\nit is still challenging to understand preemption. Preemption is a situation\nwhere higher-level norms override lower-level norms when new information\nemerges. To address this, we propose a derivation state argumentation framework\n(DSA-framework). DSA-framework incorporates derivation states to explain how\npreemption arises based on evolving situational knowledge. Based on\nDSA-framework, we present an argumentative approach for explaining preemption.\nWe formally prove that, under local optimality, DSA-framework can provide\nexplanations why one consequence is obligatory or forbidden by soft-constraint\nbased norms represented as logical constraint hierarchies.",
      "tldr_zh": "该研究针对软-constraint based norms 中的 preemption（抢占）问题提出了一种 argumentation framework，即 derivation state argumentation framework（DSA-framework）。DSA-framework 通过整合推导状态，解释 preemption 如何基于演变的 situational knowledge 产生，从而帮助理解高层规范如何覆盖低层规范。研究进一步证明，在局部最优条件下，该框架能提供解释，阐明为什么某些后果在逻辑约束层次中被视为强制或禁止，为软约束规范的解释性分析奠定了基础。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "submitted to VECOMP/AICOM 2024 associated with 27th European\n  Conference on Artificial Intelligence (ECAI2024)",
      "pdf_url": "http://arxiv.org/pdf/2409.04065v1",
      "published_date": "2024-09-06 07:14:32 UTC",
      "updated_date": "2024-09-06 07:14:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:00:15.289909"
    },
    {
      "arxiv_id": "2409.04060v1",
      "title": "D4: Text-guided diffusion model-based domain adaptive data augmentation for vineyard shoot detection",
      "title_zh": "翻译失败",
      "authors": [
        "Kentaro Hirahara",
        "Chikahito Nakane",
        "Hajime Ebisawa",
        "Tsuyoshi Kuroda",
        "Yohei Iwaki",
        "Tomoyoshi Utsumi",
        "Yuichiro Nomura",
        "Makoto Koike",
        "Hiroshi Mineno"
      ],
      "abstract": "In an agricultural field, plant phenotyping using object detection models is\ngaining attention. However, collecting the training data necessary to create\ngeneric and high-precision models is extremely challenging due to the\ndifficulty of annotation and the diversity of domains. Furthermore, it is\ndifficult to transfer training data across different crops, and although\nmachine learning models effective for specific environments, conditions, or\ncrops have been developed, they cannot be widely applied in actual fields. In\nthis study, we propose a generative data augmentation method (D4) for vineyard\nshoot detection. D4 uses a pre-trained text-guided diffusion model based on a\nlarge number of original images culled from video data collected by unmanned\nground vehicles or other means, and a small number of annotated datasets. The\nproposed method generates new annotated images with background information\nadapted to the target domain while retaining annotation information necessary\nfor object detection. In addition, D4 overcomes the lack of training data in\nagriculture, including the difficulty of annotation and diversity of domains.\nWe confirmed that this generative data augmentation method improved the mean\naverage precision by up to 28.65% for the BBox detection task and the average\nprecision by up to 13.73% for the keypoint detection task for vineyard shoot\ndetection. Our generative data augmentation method D4 is expected to\nsimultaneously solve the cost and domain diversity issues of training data\ngeneration in agriculture and improve the generalization performance of\ndetection models.",
      "tldr_zh": "本文提出 D4 方法，一种基于文本-guided diffusion model 的领域自适应数据增强技术，用于改善葡萄园枝条检测。该方法利用大量原始图像和少量标注数据集生成新图像，同时保留物体检测所需的标注信息并适应目标领域背景，从而克服农业训练数据的标注困难和领域多样性问题。实验结果显示，D4 显著提升了检测性能，使 BBox 检测任务的 mean average precision (mAP) 提高至 28.65%，关键点检测任务的 average precision (AP) 提高至 13.73%。总体而言，该方法有助于降低农业训练数据成本并增强检测模型的泛化性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.04060v1",
      "published_date": "2024-09-06 07:04:27 UTC",
      "updated_date": "2024-09-06 07:04:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:00:30.109839"
    },
    {
      "arxiv_id": "2409.04056v1",
      "title": "Refining Wikidata Taxonomy using Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yiwen Peng",
        "Thomas Bonald",
        "Mehwish Alam"
      ],
      "abstract": "Due to its collaborative nature, Wikidata is known to have a complex\ntaxonomy, with recurrent issues like the ambiguity between instances and\nclasses, the inaccuracy of some taxonomic paths, the presence of cycles, and\nthe high level of redundancy across classes. Manual efforts to clean up this\ntaxonomy are time-consuming and prone to errors or subjective decisions. We\npresent WiKC, a new version of Wikidata taxonomy cleaned automatically using a\ncombination of Large Language Models (LLMs) and graph mining techniques.\nOperations on the taxonomy, such as cutting links or merging classes, are\nperformed with the help of zero-shot prompting on an open-source LLM. The\nquality of the refined taxonomy is evaluated from both intrinsic and extrinsic\nperspectives, on a task of entity typing for the latter, showing the practical\ninterest of WiKC.",
      "tldr_zh": "这篇论文针对 Wikidata 分类系统的复杂问题，如实例与类别的模糊性、分类路径不准确、循环存在和高冗余，提出了 WiKC，这是一个使用 Large Language Models (LLMs) 和图挖掘技术自动清理的改进版本。\n方法包括通过零-shot prompting 在开源 LLM 上执行操作，如切割链接或合并类，以提升分类系统的准确性。\n评估结果显示，WiKC 在内在质量和外在任务（如实体分类）上表现出色，证明了其实际应用价值。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.IR"
      ],
      "primary_category": "cs.AI",
      "comment": "ACM International Conference on Information and Knowledge Management,\n  Oct 2024, Boise, Idaho, United States",
      "pdf_url": "http://arxiv.org/pdf/2409.04056v1",
      "published_date": "2024-09-06 06:53:45 UTC",
      "updated_date": "2024-09-06 06:53:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:00:40.999808"
    },
    {
      "arxiv_id": "2409.04053v2",
      "title": "COLUMBUS: Evaluating COgnitive Lateral Understanding through Multiple-choice reBUSes",
      "title_zh": "翻译失败",
      "authors": [
        "Koen Kraaijveld",
        "Yifan Jiang",
        "Kaixin Ma",
        "Filip Ilievski"
      ],
      "abstract": "While visual question-answering (VQA) benchmarks have catalyzed the\ndevelopment of reasoning techniques, they have focused on vertical thinking.\nEffective problem-solving also necessitates lateral thinking, which remains\nunderstudied in AI and has not been used to test visual perception systems. To\nbridge this gap, we formulate visual lateral thinking as a multiple-choice\nquestion-answering task and describe a three-step taxonomy-driven methodology\nfor instantiating task examples. Then, we develop COLUMBUS, a synthetic\nbenchmark that applies the task pipeline to create QA sets with text and icon\nrebus puzzles based on publicly available collections of compounds and common\nphrases. COLUMBUS comprises over 1,000 puzzles, each with four answer\ncandidates. While the SotA vision-language models (VLMs) achieve decent\nperformance, our evaluation demonstrates a substantial gap between humans and\nmodels. VLMs benefit from human-curated descriptions but struggle to\nself-generate such representations at the right level of abstraction.",
      "tldr_zh": "该论文指出，现有的视觉问答（VQA）基准主要关注垂直思考，而忽略了横向思考（lateral thinking），因此提出将视觉横向思考制定为多选问答任务，并开发了一个基于三步分类驱动方法来创建任务示例。研究构建了COLUMBUS基准，这是一个合成数据集，包含超过1,000个基于文本和图标rebus puzzles的QA集，每个谜语附有四个答案选项。实验结果显示，虽然SotA视觉语言模型（VLMs）在该基准上表现出色，但与人类相比仍有显著差距，且VLMs依赖人类描述而难以自行生成适当抽象水平的表示。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "15 pages, 10 figures, accepted to AAAI-25",
      "pdf_url": "http://arxiv.org/pdf/2409.04053v2",
      "published_date": "2024-09-06 06:49:55 UTC",
      "updated_date": "2024-12-20 12:14:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:00:53.724047"
    },
    {
      "arxiv_id": "2409.04040v1",
      "title": "A First Look At Efficient And Secure On-Device LLM Inference Against KV Leakage",
      "title_zh": "翻译失败",
      "authors": [
        "Huan Yang",
        "Deyu Zhang",
        "Yudong Zhao",
        "Yuanchun Li",
        "Yunxin Liu"
      ],
      "abstract": "Running LLMs on end devices has garnered significant attention recently due\nto their advantages in privacy preservation. With the advent of lightweight LLM\nmodels and specially designed GPUs, on-device LLM inference has achieved the\nnecessary accuracy and performance metrics. However, we have identified that\nLLM inference on GPUs can leak privacy-sensitive intermediate information,\nspecifically the KV pairs. An attacker could exploit these KV pairs to\nreconstruct the entire user conversation, leading to significant\nvulnerabilities. Existing solutions, such as Fully Homomorphic Encryption (FHE)\nand Trusted Execution Environments (TEE), are either too computation-intensive\nor resource-limited. To address these issues, we designed KV-Shield, which\noperates in two phases. In the initialization phase, it permutes the weight\nmatrices so that all KV pairs are correspondingly permuted. During the runtime\nphase, the attention vector is inversely permuted to ensure the correctness of\nthe layer output. All permutation-related operations are executed within the\nTEE, ensuring that insecure GPUs cannot access the original KV pairs, thus\npreventing conversation reconstruction. Finally, we theoretically analyze the\ncorrectness of KV-Shield, along with its advantages and overhead.",
      "tldr_zh": "该研究首次探讨了端设备上运行LLM推理的安全性问题，指出GPU上的推理可能泄露隐私敏感的KV pairs，导致用户对话重建。针对现有方案如Fully Homomorphic Encryption (FHE)和Trusted Execution Environments (TEE)的局限性，作者提出KV-Shield框架，通过初始化阶段的权重矩阵置换和运行时阶段的注意力向量逆置换，确保KV pairs在TEE中处理，从而防止泄露。理论分析显示，KV-Shield维持了推理正确性，同时提高了效率并降低了开销，为安全的on-device LLM推理提供了新途径。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.04040v1",
      "published_date": "2024-09-06 06:16:55 UTC",
      "updated_date": "2024-09-06 06:16:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:01:05.309706"
    },
    {
      "arxiv_id": "2409.04025v2",
      "title": "BFA-YOLO: A balanced multiscale object detection network for building façade attachments detection",
      "title_zh": "BFA-YOLO：一种平衡的多尺度目标检测网络，用于建筑立面附件检测",
      "authors": [
        "Yangguang Chen",
        "Tong Wang",
        "Guanzhou Chen",
        "Kun Zhu",
        "Xiaoliang Tan",
        "Jiaqi Wang",
        "Wenchao Guo",
        "Qing Wang",
        "Xiaolong Luo",
        "Xiaodong Zhang"
      ],
      "abstract": "The detection of fa\\c{c}ade elements on buildings, such as doors, windows,\nbalconies, air conditioning units, billboards, and glass curtain walls, is a\ncritical step in automating the creation of Building Information Modeling\n(BIM). Yet, this field faces significant challenges, including the uneven\ndistribution of fa\\c{c}ade elements, the presence of small objects, and\nsubstantial background noise, which hamper detection accuracy. To address these\nissues, we develop the BFA-YOLO model and the BFA-3D dataset in this study. The\nBFA-YOLO model is an advanced architecture designed specifically for analyzing\nmulti-view images of fa\\c{c}ade attachments. It integrates three novel\ncomponents: the Feature Balanced Spindle Module (FBSM) that tackles the issue\nof uneven object distribution; the Target Dynamic Alignment Task Detection Head\n(TDATH) that enhances the detection of small objects; and the Position Memory\nEnhanced Self-Attention Mechanism (PMESA), aimed at reducing the impact of\nbackground noise. These elements collectively enable BFA-YOLO to effectively\naddress each challenge, thereby improving model robustness and detection\nprecision. The BFA-3D dataset, offers multi-view images with precise\nannotations across a wide range of fa\\c{c}ade attachment categories. This\ndataset is developed to address the limitations present in existing fa\\c{c}ade\ndetection datasets, which often feature a single perspective and insufficient\ncategory coverage. Through comparative analysis, BFA-YOLO demonstrated\nimprovements of 1.8\\% and 2.9\\% in mAP$_{50}$ on the BFA-3D dataset and the\npublic Fa\\c{c}ade-WHU dataset, respectively, when compared to the baseline\nYOLOv8 model. These results highlight the superior performance of BFA-YOLO in\nfa\\c{c}ade element detection and the advancement of intelligent BIM\ntechnologies.",
      "tldr_zh": "本研究针对建筑立面附件（如门、窗、阳台、空调和广告牌）的检测问题，开发了 BFA-YOLO 模型，以提升自动化创建 Building Information Modeling (BIM) 的准确性。模型引入了三个创新组件：Feature Balanced Spindle Module (FBSM) 处理物体分布不均、Target Dynamic Alignment Task Detection Head (TDATH) 增强小物体检测，以及 Position Memory Enhanced Self-Attention Mechanism (PMESA) 减少背景噪声影响。研究同时构建了 BFA-3D 数据集，提供多视图图像和精确标注，以弥补现有数据集的视角和类别覆盖不足。在实验对比中，BFA-YOLO 相比 YOLOv8 基线模型，在 BFA-3D 和 Façade-WHU 数据集上分别提高了 1.8% 和 2.9% 的 mAP50，显著推进了智能 BIM 技术的发展。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "21 pages",
      "pdf_url": "http://arxiv.org/pdf/2409.04025v2",
      "published_date": "2024-09-06 04:44:52 UTC",
      "updated_date": "2024-11-11 06:23:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:01:21.355180"
    },
    {
      "arxiv_id": "2409.04007v1",
      "title": "Searching for Effective Preprocessing Method and CNN-based Architecture with Efficient Channel Attention on Speech Emotion Recognition",
      "title_zh": "在语音情感识别中搜索有效的预处理方法和带有高效通道注意力的基于 CNN 的架构",
      "authors": [
        "Byunggun Kim",
        "Younghun Kwon"
      ],
      "abstract": "Speech emotion recognition (SER) classifies human emotions in speech with a\ncomputer model. Recently, performance in SER has steadily increased as deep\nlearning techniques have adapted. However, unlike many domains that use speech\ndata, data for training in the SER model is insufficient. This causes\noverfitting of training of the neural network, resulting in performance\ndegradation. In fact, successful emotion recognition requires an effective\npreprocessing method and a model structure that efficiently uses the number of\nweight parameters. In this study, we propose using eight dataset versions with\ndifferent frequency-time resolutions to search for an effective emotional\nspeech preprocessing method. We propose a 6-layer convolutional neural network\n(CNN) model with efficient channel attention (ECA) to pursue an efficient model\nstructure. In particular, the well-positioned ECA blocks can improve channel\nfeature representation with only a few parameters. With the interactive\nemotional dyadic motion capture (IEMOCAP) dataset, increasing the frequency\nresolution in preprocessing emotional speech can improve emotion recognition\nperformance. Also, ECA after the deep convolution layer can effectively\nincrease channel feature representation. Consequently, the best result (79.37UA\n79.68WA) can be obtained, exceeding the performance of previous SER models.\nFurthermore, to compensate for the lack of emotional speech data, we experiment\nwith multiple preprocessing data methods that augment trainable data\npreprocessed with all different settings from one sample. In the experiment, we\ncan achieve the highest result (80.28UA 80.46WA).",
      "tldr_zh": "本研究针对语音情感识别(Speech Emotion Recognition, SER)中数据不足导致的过拟合问题，提出了一种有效的预处理方法和基于CNN的架构优化。具体而言，研究者探索了八种不同频率-时间分辨率的数据集版本，并设计了一个6层卷积神经网络(CNN)模型，融入Efficient Channel Attention (ECA)模块，以高效提升通道特征表示。实验在IEMOCAP数据集上显示，增加频率分辨率能显著改善情感识别性能，而在深层卷积后添加ECA进一步优化了模型。最终，结果达到79.37% UA和79.68% WA，优于现有模型，通过数据增强方法进一步提升至80.28% UA和80.46% WA，为SER提供了更高效的解决方案。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.04007v1",
      "published_date": "2024-09-06 03:17:25 UTC",
      "updated_date": "2024-09-06 03:17:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:01:35.545163"
    },
    {
      "arxiv_id": "2409.03992v4",
      "title": "Confidential Computing on NVIDIA Hopper GPUs: A Performance Benchmark Study",
      "title_zh": "翻译失败",
      "authors": [
        "Jianwei Zhu",
        "Hang Yin",
        "Peng Deng",
        "Aline Almeida",
        "Shunfan Zhou"
      ],
      "abstract": "This report evaluates the performance impact of enabling Trusted Execution\nEnvironments (TEE) on NVIDIA Hopper GPUs for large language model (LLM)\ninference tasks. We benchmark the overhead introduced by TEE mode across\nvarious LLMs and token lengths, with a particular focus on the bottleneck\ncaused by CPU-GPU data transfers via PCIe. Our results indicate that while\nthere is minimal computational overhead within the GPU, the overall performance\npenalty is primarily attributable to data transfer. For the majority of typical\nLLM queries, the overhead remains below 7%, with larger models and longer\nsequences experiencing nearly zero overhead.",
      "tldr_zh": "这篇报告评估了在 NVIDIA Hopper GPUs 上启用 Trusted Execution Environments (TEE) 对大型语言模型 (LLM) 推理任务的性能影响。研究通过基准测试分析了 TEE 模式引入的开销，重点关注 CPU-GPU 数据传输 via PCIe 作为主要瓶颈。结果显示，GPU 内部计算开销最小，而整体性能损失主要源于数据传输，大多数 LLM 查询的开销低于 7%，尤其在更大模型和更长序列中几乎无影响。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.PF"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.03992v4",
      "published_date": "2024-09-06 02:44:27 UTC",
      "updated_date": "2024-11-05 16:57:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:01:47.311254"
    },
    {
      "arxiv_id": "2409.04481v1",
      "title": "Large Language Models in Drug Discovery and Development: From Disease Mechanisms to Clinical Trials",
      "title_zh": "大语言模型在药物发现和开发中：从疾病机制到临床试验",
      "authors": [
        "Yizhen Zheng",
        "Huan Yee Koh",
        "Maddie Yang",
        "Li Li",
        "Lauren T. May",
        "Geoffrey I. Webb",
        "Shirui Pan",
        "George Church"
      ],
      "abstract": "The integration of Large Language Models (LLMs) into the drug discovery and\ndevelopment field marks a significant paradigm shift, offering novel\nmethodologies for understanding disease mechanisms, facilitating drug\ndiscovery, and optimizing clinical trial processes. This review highlights the\nexpanding role of LLMs in revolutionizing various stages of the drug\ndevelopment pipeline. We investigate how these advanced computational models\ncan uncover target-disease linkage, interpret complex biomedical data, enhance\ndrug molecule design, predict drug efficacy and safety profiles, and facilitate\nclinical trial processes. Our paper aims to provide a comprehensive overview\nfor researchers and practitioners in computational biology, pharmacology, and\nAI4Science by offering insights into the potential transformative impact of\nLLMs on drug discovery and development.",
      "tldr_zh": "这篇综述探讨了Large Language Models (LLMs)在药物发现和开发领域的整合及其变革性影响，从理解疾病机制到优化临床试验过程。论文详细分析了LLMs如何揭示目标-疾病联系、解释复杂生物医学数据、增强药物分子设计、预测药物功效和安全性，以及促进临床试验流程。总体而言，该研究为计算生物学、药理学和AI4Science的从业者提供全面概述，强调LLMs在加速药物开发管道中的潜在转型作用。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.QM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.04481v1",
      "published_date": "2024-09-06 02:03:38 UTC",
      "updated_date": "2024-09-06 02:03:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:01:58.371097"
    },
    {
      "arxiv_id": "2409.03947v1",
      "title": "FODA-PG for Enhanced Medical Imaging Narrative Generation: Adaptive Differentiation of Normal and Abnormal Attributes",
      "title_zh": "FODA-PG 用于增强医学影像叙述生成：正常和异常属性的自",
      "authors": [
        "Kai Shu",
        "Yuzhuo Jia",
        "Ziyang Zhang",
        "Jiechao Gao"
      ],
      "abstract": "Automatic Medical Imaging Narrative generation aims to alleviate the workload\nof radiologists by producing accurate clinical descriptions directly from\nradiological images. However, the subtle visual nuances and domain-specific\nterminology in medical images pose significant challenges compared to generic\nimage captioning tasks. Existing approaches often neglect the vital distinction\nbetween normal and abnormal findings, leading to suboptimal performance. In\nthis work, we propose FODA-PG, a novel Fine-grained Organ-Disease Adaptive\nPartitioning Graph framework that addresses these limitations through\ndomain-adaptive learning. FODA-PG constructs a granular graphical\nrepresentation of radiological findings by separating disease-related\nattributes into distinct \"disease-specific\" and \"disease-free\" categories based\non their clinical significance and location. This adaptive partitioning enables\nour model to capture the nuanced differences between normal and pathological\nstates, mitigating the impact of data biases. By integrating this fine-grained\nsemantic knowledge into a powerful transformer-based architecture and providing\nrigorous mathematical justifications for its effectiveness, FODA-PG generates\nprecise and clinically coherent reports with enhanced generalization\ncapabilities. Extensive experiments on the IU-Xray and MIMIC-CXR benchmarks\ndemonstrate the superiority of our approach over state-of-the-art methods,\nhighlighting the importance of domain adaptation in medical report generation.",
      "tldr_zh": "该论文提出FODA-PG框架，用于提升医疗影像叙述生成，通过Fine-grained Organ-Disease Adaptive Partitioning Graph实现对正常和异常属性的适应性区分，解决现有方法忽略关键差异的问题。FODA-PG构建细粒度的图形表示，将疾病相关属性分为“disease-specific”和“disease-free”类别，并整合domain-adaptive learning到transformer-based架构中，以捕捉微妙视觉细微差别并提供数学证明。实验结果显示，在IU-Xray和MIMIC-CXR基准上，该方法优于最先进技术，提高了报告的精确性、临床连贯性和泛化能力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.03947v1",
      "published_date": "2024-09-06 00:04:35 UTC",
      "updated_date": "2024-09-06 00:04:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T22:02:12.181819"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 74,
  "processed_papers_count": 74,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-19T22:02:34.182586"
}