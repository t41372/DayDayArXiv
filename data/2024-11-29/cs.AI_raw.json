[
  {
    "arxiv_id": "2412.00281v1",
    "title": "Streamlining the review process: AI-generated annotations in research manuscripts",
    "authors": [
      "Oscar Díaz",
      "Xabier Garmendia",
      "Juanan Pereira"
    ],
    "abstract": "The increasing volume of research paper submissions poses a significant\nchallenge to the traditional academic peer-review system, leading to an\noverwhelming workload for reviewers. This study explores the potential of\nintegrating Large Language Models (LLMs) into the peer-review process to\nenhance efficiency without compromising effectiveness. We focus on manuscript\nannotations, particularly excerpt highlights, as a potential area for AI-human\ncollaboration. While LLMs excel in certain tasks like aspect coverage and\ninformativeness, they often lack high-level analysis and critical thinking,\nmaking them unsuitable for replacing human reviewers entirely. Our approach\ninvolves using LLMs to assist with specific aspects of the review process. This\npaper introduces AnnotateGPT, a platform that utilizes GPT-4 for manuscript\nreview, aiming to improve reviewers' comprehension and focus. We evaluate\nAnnotateGPT using a Technology Acceptance Model (TAM) questionnaire with nine\nparticipants and generalize the findings. Our work highlights annotation as a\nviable middle ground for AI-human collaboration in academic review, offering\ninsights into integrating LLMs into the review process and tuning traditional\nannotation tools for LLM incorporation.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.00281v1",
    "published_date": "2024-11-29 23:26:34 UTC",
    "updated_date": "2024-11-29 23:26:34 UTC"
  },
  {
    "arxiv_id": "2412.00278v1",
    "title": "Average-Over-Time Spiking Neural Networks for Uncertainty Estimation in Regression",
    "authors": [
      "Tao Sun",
      "Sander Bohté"
    ],
    "abstract": "Uncertainty estimation is a standard tool to quantify the reliability of\nmodern deep learning models, and crucial for many real-world applications.\nHowever, efficient uncertainty estimation methods for spiking neural networks,\nparticularly for regression models, have been lacking. Here, we introduce two\nmethods that adapt the Average-Over-Time Spiking Neural Network (AOT-SNN)\nframework to regression tasks, enhancing uncertainty estimation in event-driven\nmodels. The first method uses the heteroscedastic Gaussian approach, where SNNs\npredict both the mean and variance at each time step, thereby generating a\nconditional probability distribution of the target variable. The second method\nleverages the Regression-as-Classification (RAC) approach, reformulating\nregression as a classification problem to facilitate uncertainty estimation. We\nevaluate our approaches on both a toy dataset and several benchmark datasets,\ndemonstrating that the proposed AOT-SNN models achieve performance comparable\nto or better than state-of-the-art deep neural network methods, particularly in\nuncertainty estimation. Our findings highlight the potential of SNNs for\nuncertainty estimation in regression tasks, providing an efficient and\nbiologically inspired alternative for applications requiring both accuracy and\nenergy efficiency.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.00278v1",
    "published_date": "2024-11-29 23:13:52 UTC",
    "updated_date": "2024-11-29 23:13:52 UTC"
  },
  {
    "arxiv_id": "2412.00261v1",
    "title": "Attribute-Enhanced Similarity Ranking for Sparse Link Prediction",
    "authors": [
      "João Mattos",
      "Zexi Huang",
      "Mert Kosan",
      "Ambuj Singh",
      "Arlei Silva"
    ],
    "abstract": "Link prediction is a fundamental problem in graph data. In its most realistic\nsetting, the problem consists of predicting missing or future links between\nrandom pairs of nodes from the set of disconnected pairs. Graph Neural Networks\n(GNNs) have become the predominant framework for link prediction. GNN-based\nmethods treat link prediction as a binary classification problem and handle the\nextreme class imbalance -- real graphs are very sparse -- by sampling\n(uniformly at random) a balanced number of disconnected pairs not only for\ntraining but also for evaluation. However, we show that the reported\nperformance of GNNs for link prediction in the balanced setting does not\ntranslate to the more realistic imbalanced setting and that simpler\ntopology-based approaches are often better at handling sparsity. These findings\nmotivate Gelato, a similarity-based link-prediction method that applies (1)\ngraph learning based on node attributes to enhance a topological heuristic, (2)\na ranking loss for addressing class imbalance, and (3) a negative sampling\nscheme that efficiently selects hard training pairs via graph partitioning.\nExperiments show that Gelato outperforms existing GNN-based alternatives.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SI"
    ],
    "primary_category": "cs.LG",
    "comment": "To appear at the 31st SIGKDD Conference on Knowledge Discovery and\n  Data Mining - Research Track (August 2024 Deadline)",
    "pdf_url": "http://arxiv.org/pdf/2412.00261v1",
    "published_date": "2024-11-29 21:22:35 UTC",
    "updated_date": "2024-11-29 21:22:35 UTC"
  },
  {
    "arxiv_id": "2412.00251v1",
    "title": "Fine Tuning Large Language Models to Deliver CBT for Depression",
    "authors": [
      "Talha Tahir"
    ],
    "abstract": "Cognitive Behavioral Therapy (CBT) is a well-established, evidence-based\ntreatment for Major Depressive Disorder. Unfortunately, there exist significant\nbarriers to individuals accessing CBT, including cost, scarcity of therapists\nand stigma. This study explores the feasibility of fine-tuning small open\nweight large language models (LLMs) to deliver CBT for depression. Using 58\nsets of synthetic CBT transcripts generated by the Nous Research fine-tune of\nLlama 3.1 405b, we fine-tuned three models: Mistral 7b v0.3, Qwen 2.5 7b, and\nLlama 3.1 8b. CBT fidelity was evaluated through a modified Cognitive Therapy\nRating Scale (CTRS). All fine-tuned models were compared against each other, as\nwell as their instruct-tuned variants. Simulated patient transcripts were\ngenerated for the purpose of evaluating model performance, with the instruct\nand CBT-tuned models acting as the therapist and DeepSeek-V2.5 acting as the\npatient. These simulated transcripts were evaluated on a modified CTRS by\nGemini 1.5 Pro-002. Our findings demonstrated that the CBT-tuned models\nsignificantly outperformed their instruct-tuned counterparts, with an average\nimprovement of 11.33 points (p < 0.001) on total CTRS score. Llama 3.1 8b had\nthe strongest performance (mean CTRS score 67.86 +/- 7.24), followed by Qwen\n2.5 7b (64.28 +/- 9.55) and Mistral 7b v0.3 (64.17 +/- 9.79), with these\ndifferences between models being statistically significant. The CBT-tuned\nmodels were competent in implementing core CBT techniques and providing\nempathetic responses, however, there were limitations observed in agenda\nadherence, exploration depth and long-context coherence. This study establishes\nthat CBT specific fine-tuning can effectively encode therapeutic competencies\nin small LLMs, though significant technical and ethical considerations must be\nresolved prior to clinical deployment.",
    "categories": [
      "cs.AI",
      "cs.HC",
      "I.2.7; J.3"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.00251v1",
    "published_date": "2024-11-29 20:48:08 UTC",
    "updated_date": "2024-11-29 20:48:08 UTC"
  },
  {
    "arxiv_id": "2412.00245v1",
    "title": "Integrating Social Determinants of Health into Knowledge Graphs: Evaluating Prediction Bias and Fairness in Healthcare",
    "authors": [
      "Tianqi Shang",
      "Weiqing He",
      "Tianlong Chen",
      "Ying Ding",
      "Huanmei Wu",
      "Kaixiong Zhou",
      "Li Shen"
    ],
    "abstract": "Social determinants of health (SDoH) play a crucial role in patient health\noutcomes, yet their integration into biomedical knowledge graphs remains\nunderexplored. This study addresses this gap by constructing an SDoH-enriched\nknowledge graph using the MIMIC-III dataset and PrimeKG. We introduce a novel\nfairness formulation for graph embeddings, focusing on invariance with respect\nto sensitive SDoH information. Via employing a heterogeneous-GCN model for\ndrug-disease link prediction, we detect biases related to various SDoH factors.\nTo mitigate these biases, we propose a post-processing method that\nstrategically reweights edges connected to SDoHs, balancing their influence on\ngraph representations. This approach represents one of the first comprehensive\ninvestigations into fairness issues within biomedical knowledge graphs\nincorporating SDoH. Our work not only highlights the importance of considering\nSDoH in medical informatics but also provides a concrete method for reducing\nSDoH-related biases in link prediction tasks, paving the way for more equitable\nhealthcare recommendations. Our code is available at\n\\url{https://github.com/hwq0726/SDoH-KG}.",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.00245v1",
    "published_date": "2024-11-29 20:35:01 UTC",
    "updated_date": "2024-11-29 20:35:01 UTC"
  },
  {
    "arxiv_id": "2412.00243v1",
    "title": "Realistic Corner Case Generation for Autonomous Vehicles with Multimodal Large Language Model",
    "authors": [
      "Qiujing Lu",
      "Meng Ma",
      "Ximiao Dai",
      "Xuanhan Wang",
      "Shuo Feng"
    ],
    "abstract": "To guarantee the safety and reliability of autonomous vehicle (AV) systems,\ncorner cases play a crucial role in exploring the system's behavior under rare\nand challenging conditions within simulation environments. However, current\napproaches often fall short in meeting diverse testing needs and struggle to\ngeneralize to novel, high-risk scenarios that closely mirror real-world\nconditions. To tackle this challenge, we present AutoScenario, a multimodal\nLarge Language Model (LLM)-based framework for realistic corner case\ngeneration. It converts safety-critical real-world data from multiple sources\ninto textual representations, enabling the generalization of key risk factors\nwhile leveraging the extensive world knowledge and advanced reasoning\ncapabilities of LLMs.Furthermore, it integrates tools from the Simulation of\nUrban Mobility (SUMO) and CARLA simulators to simplify and execute the code\ngenerated by LLMs. Our experiments demonstrate that AutoScenario can generate\nrealistic and challenging test scenarios, precisely tailored to specific\ntesting requirements or textual descriptions. Additionally, we validated its\nability to produce diverse and novel scenarios derived from multimodal\nreal-world data involving risky situations, harnessing the powerful\ngeneralization capabilities of LLMs to effectively simulate a wide range of\ncorner cases.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.00243v1",
    "published_date": "2024-11-29 20:23:28 UTC",
    "updated_date": "2024-11-29 20:23:28 UTC"
  },
  {
    "arxiv_id": "2412.00239v1",
    "title": "Generating a Low-code Complete Workflow via Task Decomposition and RAG",
    "authors": [
      "Orlando Marquez Ayala",
      "Patrice Béchard"
    ],
    "abstract": "AI technologies are moving rapidly from research to production. With the\npopularity of Foundation Models (FMs) that generate text, images, and video,\nAI-based systems are increasing their complexity. Compared to traditional\nAI-based software, systems employing FMs, or GenAI-based systems, are more\ndifficult to design due to their scale and versatility. This makes it necessary\nto document best practices, known as design patterns in software engineering,\nthat can be used across GenAI applications. Our first contribution is to\nformalize two techniques, Task Decomposition and Retrieval-Augmented Generation\n(RAG), as design patterns for GenAI-based systems. We discuss their trade-offs\nin terms of software quality attributes and comment on alternative approaches.\nWe recommend to AI practitioners to consider these techniques not only from a\nscientific perspective but also from the standpoint of desired engineering\nproperties such as flexibility, maintainability, safety, and security. As a\nsecond contribution, we describe our industry experience applying Task\nDecomposition and RAG to build a complex real-world GenAI application for\nenterprise users: Workflow Generation. The task of generating workflows entails\ngenerating a specific plan using data from the system environment, taking as\ninput a user requirement. As these two patterns affect the entire AI\ndevelopment cycle, we explain how they impacted the dataset creation, model\ntraining, model evaluation, and deployment phases.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "Under review; 12 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.00239v1",
    "published_date": "2024-11-29 20:13:56 UTC",
    "updated_date": "2024-11-29 20:13:56 UTC"
  },
  {
    "arxiv_id": "2412.00238v1",
    "title": "Twisted Convolutional Networks (TCNs): Enhancing Feature Interactions for Non-Spatial Data Classification",
    "authors": [
      "Junbo Jacob Lian"
    ],
    "abstract": "Twisted Convolutional Networks (TCNs) are introduced as a novel neural\nnetwork architecture designed to effectively process one-dimensional data with\narbitrary feature order and minimal spatial relationships. Unlike traditional\nConvolutional Neural Networks (CNNs), which excel at handling structured\ntwo-dimensional data like images, TCNs reduce dependency on feature order by\ncombining input features in innovative ways to create new representations. By\nexplicitly enhancing feature interactions and employing diverse feature\ncombinations, TCNs generate richer and more informative representations, making\nthem especially effective for classification tasks on datasets with arbitrary\nfeature arrangements. This paper details the TCN architecture and its feature\ncombination strategy, providing a comprehensive comparison with traditional\nCNNs, DeepSets, Transformers, and Graph Neural Networks (GNNs). Extensive\nexperiments on benchmark datasets demonstrate that TCNs achieve superior\nperformance, particularly in classification scenarios involving one-dimensional\ndata.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "The source code for the TCNs can be accessed at\n  https://github.com/junbolian/Twisted-Convolutional-Networks",
    "pdf_url": "http://arxiv.org/pdf/2412.00238v1",
    "published_date": "2024-11-29 20:12:24 UTC",
    "updated_date": "2024-11-29 20:12:24 UTC"
  },
  {
    "arxiv_id": "2412.00224v1",
    "title": "An AI-Driven Data Mesh Architecture Enhancing Decision-Making in Infrastructure Construction and Public Procurement",
    "authors": [
      "Saurabh Mishra",
      "Mahendra Shinde",
      "Aniket Yadav",
      "Bilal Ayyub",
      "Anand Rao"
    ],
    "abstract": "Infrastructure construction, often dubbed an \"industry of industries,\" is\nclosely linked with government spending and public procurement, offering\nsignificant opportunities for improved efficiency and productivity through\nbetter transparency and information access. By leveraging these opportunities,\nwe can achieve notable gains in productivity, cost savings, and broader\neconomic benefits. Our approach introduces an integrated software ecosystem\nutilizing Data Mesh and Service Mesh architectures. This system includes the\nlargest training dataset for infrastructure and procurement, encompassing over\n100 billion tokens, scientific publications, activities, and risk data, all\nstructured by a systematic AI framework. Supported by a Knowledge Graph linked\nto domain-specific multi-agent tasks and Q&A capabilities, our platform\nstandardizes and ingests diverse data sources, transforming them into\nstructured knowledge. Leveraging large language models (LLMs) and automation,\nour system revolutionizes data structuring and knowledge creation, aiding\ndecision-making in early-stage project planning, detailed research, market\ntrend analysis, and qualitative assessments. Its web-scalable architecture\ndelivers domain-curated information, enabling AI agents to facilitate reasoning\nand manage uncertainties, while preparing for future expansions with\nspecialized agents targeting particular challenges. This integration of AI with\ndomain expertise not only boosts efficiency and decision-making in construction\nand infrastructure but also establishes a framework for enhancing government\nefficiency and accelerating the transition of traditional industries to digital\nworkflows. This work is poised to significantly influence AI-driven initiatives\nin this sector and guide best practices in AI Operations.",
    "categories": [
      "cs.AI",
      "cs.DB",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.00224v1",
    "published_date": "2024-11-29 19:33:51 UTC",
    "updated_date": "2024-11-29 19:33:51 UTC"
  },
  {
    "arxiv_id": "2412.00209v1",
    "title": "Digital Twin in Industries: A Comprehensive Survey",
    "authors": [
      "Md Bokhtiar Al Zami",
      "Shaba Shaon",
      "Vu Khanh Quy",
      "Dinh C. Nguyen"
    ],
    "abstract": "Industrial networks are undergoing rapid transformation driven by the\nconvergence of emerging technologies that are revolutionizing conventional\nworkflows, enhancing operational efficiency, and fundamentally redefining the\nindustrial landscape across diverse sectors. Amidst this revolution, Digital\nTwin (DT) emerges as a transformative innovation that seamlessly integrates\nreal-world systems with their virtual counterparts, bridging the physical and\ndigital realms. In this article, we present a comprehensive survey of the\nemerging DT-enabled services and applications across industries, beginning with\nan overview of DT fundamentals and its components to a discussion of key\nenabling technologies for DT. Different from literature works, we investigate\nand analyze the capabilities of DT across a wide range of industrial services,\nincluding data sharing, data offloading, integrated sensing and communication,\ncontent caching, resource allocation, wireless networking, and metaverse. In\nparticular, we present an in-depth technical discussion of the roles of DT in\nindustrial applications across various domains, including manufacturing,\nhealthcare, transportation, energy, agriculture, space, oil and gas, as well as\nrobotics. Throughout the technical analysis, we delve into real-time data\ncommunications between physical and virtual platforms to enable industrial DT\nnetworking. Subsequently, we extensively explore and analyze a wide range of\nmajor privacy and security issues in DT-based industry. Taxonomy tables and the\nkey research findings from the survey are also given, emphasizing important\ninsights into the significance of DT in industries. Finally, we point out\nfuture research directions to spur further research in this promising area.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.00209v1",
    "published_date": "2024-11-29 19:14:45 UTC",
    "updated_date": "2024-11-29 19:14:45 UTC"
  },
  {
    "arxiv_id": "2412.00206v1",
    "title": "Towards the Ultimate Programming Language: Trust and Benevolence in the Age of Artificial Intelligence",
    "authors": [
      "Bartosz Sawicki",
      "Michał Śmiałek",
      "Bartłomiej Skowron"
    ],
    "abstract": "This article explores the evolving role of programming languages in the\ncontext of artificial intelligence. It highlights the need for programming\nlanguages to ensure human understanding while eliminating unnecessary\nimplementation details and suggests that future programs should be designed to\nrecognize and actively support user interests. The vision includes a\nthree-level process: using natural language for requirements, translating it\ninto a precise system definition language, and finally optimizing the code for\nperformance. The concept of an \"Ultimate Programming Language\" is introduced,\nemphasizing its role in maintaining human control over machines. Trust,\nreliability, and benevolence are identified as key elements that will enhance\ncooperation between humans and AI systems.",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.HC",
      "cs.PL",
      "cs.SE"
    ],
    "primary_category": "cs.AI",
    "comment": "submitted to proceedings of \"Ethics and AI\" conference",
    "pdf_url": "http://arxiv.org/pdf/2412.00206v1",
    "published_date": "2024-11-29 19:02:25 UTC",
    "updated_date": "2024-11-29 19:02:25 UTC"
  },
  {
    "arxiv_id": "2411.19946v1",
    "title": "DELT: A Simple Diversity-driven EarlyLate Training for Dataset Distillation",
    "authors": [
      "Zhiqiang Shen",
      "Ammar Sherif",
      "Zeyuan Yin",
      "Shitong Shao"
    ],
    "abstract": "Recent advances in dataset distillation have led to solutions in two main\ndirections. The conventional batch-to-batch matching mechanism is ideal for\nsmall-scale datasets and includes bi-level optimization methods on models and\nsyntheses, such as FRePo, RCIG, and RaT-BPTT, as well as other methods like\ndistribution matching, gradient matching, and weight trajectory matching.\nConversely, batch-to-global matching typifies decoupled methods, which are\nparticularly advantageous for large-scale datasets. This approach has garnered\nsubstantial interest within the community, as seen in SRe$^2$L, G-VBSM, WMDD,\nand CDA. A primary challenge with the second approach is the lack of diversity\namong syntheses within each class since samples are optimized independently and\nthe same global supervision signals are reused across different synthetic\nimages. In this study, we propose a new Diversity-driven EarlyLate Training\n(DELT) scheme to enhance the diversity of images in batch-to-global matching\nwith less computation. Our approach is conceptually simple yet effective, it\npartitions predefined IPC samples into smaller subtasks and employs local\noptimizations to distill each subset into distributions from distinct phases,\nreducing the uniformity induced by the unified optimization process. These\ndistilled images from the subtasks demonstrate effective generalization when\napplied to the entire task. We conduct extensive experiments on CIFAR,\nTiny-ImageNet, ImageNet-1K, and its sub-datasets. Our approach outperforms the\nprevious state-of-the-art by 2$\\sim$5% on average across different datasets and\nIPCs (images per class), increasing diversity per class by more than 5% while\nreducing synthesis time by up to 39.3% for enhancing the training efficiency.\nCode is available at: https://github.com/VILA-Lab/DELT.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.19946v1",
    "published_date": "2024-11-29 18:59:46 UTC",
    "updated_date": "2024-11-29 18:59:46 UTC"
  },
  {
    "arxiv_id": "2411.19943v3",
    "title": "Critical Tokens Matter: Token-Level Contrastive Estimation Enhances LLM's Reasoning Capability",
    "authors": [
      "Zicheng Lin",
      "Tian Liang",
      "Jiahao Xu",
      "Qiuzhi Lin",
      "Xing Wang",
      "Ruilin Luo",
      "Chufan Shi",
      "Siheng Li",
      "Yujiu Yang",
      "Zhaopeng Tu"
    ],
    "abstract": "Mathematical reasoning tasks pose significant challenges for large language\nmodels (LLMs) because they require precise logical deduction and sequence\nanalysis. In this work, we introduce the concept of critical tokens -- elements\nwithin reasoning trajectories that significantly influence incorrect outcomes.\nWe present a novel framework for identifying these tokens through rollout\nsampling and demonstrate their substantial divergence from traditional error\ntokens. Through extensive experiments on datasets such as GSM8K and MATH500, we\nshow that identifying and replacing critical tokens significantly improves\nmodel accuracy. We propose an efficient methodology for pinpointing these\ntokens in large-scale datasets using contrastive estimation and extend this\nframework to enhance model training processes with direct preference\noptimization (DPO). Experimental results on GSM8K and MATH500 benchmarks with\nthe widely used models Llama-3 (8B and 70B) and Deepseek-math (7B) demonstrate\nthe effectiveness of the proposed approach, cDPO. Our results underscore the\npotential of leveraging critical tokens to reduce errors in reasoning tasks,\nadvancing the development of AI systems capable of robust logical deduction.\nOur code, annotated datasets, and trained models are available at\nhttps://github.com/chenzhiling9954/Critical-Tokens-Matter to support and\nencourage future research in this promising field.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Work in progress",
    "pdf_url": "http://arxiv.org/pdf/2411.19943v3",
    "published_date": "2024-11-29 18:58:22 UTC",
    "updated_date": "2025-01-13 06:53:56 UTC"
  },
  {
    "arxiv_id": "2412.12108v3",
    "title": "Responsible AI Governance: A Response to UN Interim Report on Governing AI for Humanity",
    "authors": [
      "Sarah Kiden",
      "Bernd Stahl",
      "Beverley Townsend",
      "Carsten Maple",
      "Charles Vincent",
      "Fraser Sampson",
      "Geoff Gilbert",
      "Helen Smith",
      "Jayati Deshmukh",
      "Jen Ross",
      "Jennifer Williams",
      "Jesus Martinez del Rincon",
      "Justyna Lisinska",
      "Karen O'Shea",
      "Márjory Da Costa Abreu",
      "Nelly Bencomo",
      "Oishi Deb",
      "Peter Winter",
      "Phoebe Li",
      "Philip Torr",
      "Pin Lean Lau",
      "Raquel Iniesta",
      "Gopal Ramchurn",
      "Sebastian Stein",
      "Vahid Yazdanpanah"
    ],
    "abstract": "This report presents a comprehensive response to the United Nation's Interim\nReport on Governing Artificial Intelligence (AI) for Humanity. It emphasizes\nthe transformative potential of AI in achieving the Sustainable Development\nGoals (SDGs) while acknowledging the need for robust governance to mitigate\nassociated risks. The response highlights opportunities for promoting\nequitable, secure, and inclusive AI ecosystems, which should be supported by\ninvestments in infrastructure and multi-stakeholder collaborations across\njurisdictions. It also underscores challenges, including societal inequalities\nexacerbated by AI, ethical concerns, and environmental impacts. Recommendations\nadvocate for legally binding norms, transparency, and multi-layered data\ngovernance models, alongside fostering AI literacy and capacity-building\ninitiatives. Internationally, the report calls for harmonising AI governance\nframeworks with established laws, human rights standards, and regulatory\napproaches. The report concludes with actionable principles for fostering\nresponsible AI governance through collaboration among governments, industry,\nacademia, and civil society, ensuring the development of AI aligns with\nuniversal human values and the public good.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "Submitted to United Nations. 23 pages. All the Authors Contributed\n  Equally",
    "pdf_url": "http://arxiv.org/pdf/2412.12108v3",
    "published_date": "2024-11-29 18:57:24 UTC",
    "updated_date": "2024-12-31 18:52:58 UTC"
  },
  {
    "arxiv_id": "2411.19939v3",
    "title": "VLSBench: Unveiling Visual Leakage in Multimodal Safety",
    "authors": [
      "Xuhao Hu",
      "Dongrui Liu",
      "Hao Li",
      "Xuanjing Huang",
      "Jing Shao"
    ],
    "abstract": "Safety concerns of Multimodal large language models (MLLMs) have gradually\nbecome an important problem in various applications. Surprisingly, previous\nworks indicate a counterintuitive phenomenon that using textual unlearning to\nalign MLLMs achieves comparable safety performances with MLLMs aligned with\nimage text pairs. To explain such a phenomenon, we discover a Visual Safety\nInformation Leakage (VSIL) problem in existing multimodal safety benchmarks,\ni.e., the potentially risky content in the image has been revealed in the\ntextual query. Thus, MLLMs can easily refuse these sensitive image-text pairs\naccording to textual queries only, leading to unreliable cross-modality safety\nevaluation of MLLMs. We also conduct a further comparison experiment between\ntextual alignment and multimodal alignment to highlight this drawback. To this\nend, we construct multimodal Visual Leakless Safety Bench (VLSBench) with 2.2k\nimage-text pairs through an automated data pipeline. Experimental results\nindicate that VLSBench poses a significant challenge to both open-source and\nclose-source MLLMs, e.g., LLaVA, Qwen2-VL and GPT-4o. Besides, we empirically\ncompare textual and multimodal alignment methods on VLSBench and find that\ntextual alignment is effective enough for multimodal safety scenarios with\nVSIL, while multimodal alignment is preferable for safety scenarios without\nVSIL. Code and data are released under https://github.com/AI45Lab/VLSBench",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.CR",
    "comment": "ACL2025 Main",
    "pdf_url": "http://arxiv.org/pdf/2411.19939v3",
    "published_date": "2024-11-29 18:56:37 UTC",
    "updated_date": "2025-05-17 15:14:14 UTC"
  },
  {
    "arxiv_id": "2412.00174v1",
    "title": "SOLAMI: Social Vision-Language-Action Modeling for Immersive Interaction with 3D Autonomous Characters",
    "authors": [
      "Jianping Jiang",
      "Weiye Xiao",
      "Zhengyu Lin",
      "Huaizhong Zhang",
      "Tianxiang Ren",
      "Yang Gao",
      "Zhiqian Lin",
      "Zhongang Cai",
      "Lei Yang",
      "Ziwei Liu"
    ],
    "abstract": "Human beings are social animals. How to equip 3D autonomous characters with\nsimilar social intelligence that can perceive, understand and interact with\nhumans remains an open yet foundamental problem. In this paper, we introduce\nSOLAMI, the first end-to-end Social vision-Language-Action (VLA) Modeling\nframework for Immersive interaction with 3D autonomous characters.\nSpecifically, SOLAMI builds 3D autonomous characters from three aspects: (1)\nSocial VLA Architecture: We propose a unified social VLA framework to generate\nmultimodal response (speech and motion) based on the user's multimodal input to\ndrive the character for social interaction. (2) Interactive Multimodal Data: We\npresent SynMSI, a synthetic multimodal social interaction dataset generated by\nan automatic pipeline using only existing motion datasets to address the issue\nof data scarcity. (3) Immersive VR Interface: We develop a VR interface that\nenables users to immersively interact with these characters driven by various\narchitectures. Extensive quantitative experiments and user studies demonstrate\nthat our framework leads to more precise and natural character responses (in\nboth speech and motion) that align with user expectations with lower latency.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.00174v1",
    "published_date": "2024-11-29 18:53:40 UTC",
    "updated_date": "2024-11-29 18:53:40 UTC"
  },
  {
    "arxiv_id": "2411.19922v1",
    "title": "Dynamic EEG-fMRI mapping: Revealing the relationship between brain connectivity and cognitive state",
    "authors": [
      "Guiran Liu",
      "Binrong Zhu"
    ],
    "abstract": "This study investigated the dynamic connectivity patterns between EEG and\nfMRI modalities, contributing to our understanding of brain network\ninteractions. By employing a comprehensive approach that integrated static and\ndynamic analyses of EEG-fMRI data, we were able to uncover distinct\nconnectivity states and characterize their temporal fluctuations. The results\nrevealed modular organization within the intrinsic connectivity networks (ICNs)\nof the brain, highlighting the significant roles of sensory systems and the\ndefault mode network. The use of a sliding window technique allowed us to\nassess how functional connectivity varies over time, further elucidating the\ntransient nature of brain connectivity. Additionally, our findings align with\nprevious literature, reinforcing the notion that cognitive states can be\neffectively identified through short-duration data, specifically within the\n30-60 second timeframe. The established relationships between connectivity\nstrength and cognitive processes, particularly during different visual states,\nunderscore the relevance of our approach for future research into brain\ndynamics. Overall, this study not only enhances our understanding of the\ninterplay between EEG and fMRI signals but also paves the way for further\nexploration into the neural correlates of cognitive functions and their\nimplications in clinical settings. Future research should focus on refining\nthese methodologies and exploring their applications in various cognitive and\nclinical contexts.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "15 pages, Subjects: Machine Learning (cs.LG); Human-Computer\n  Interaction (cs.HC); Signal Processing (eess.SP)",
    "pdf_url": "http://arxiv.org/pdf/2411.19922v1",
    "published_date": "2024-11-29 18:36:58 UTC",
    "updated_date": "2024-11-29 18:36:58 UTC"
  },
  {
    "arxiv_id": "2411.19921v2",
    "title": "SIMS: Simulating Stylized Human-Scene Interactions with Retrieval-Augmented Script Generation",
    "authors": [
      "Wenjia Wang",
      "Liang Pan",
      "Zhiyang Dou",
      "Jidong Mei",
      "Zhouyingcheng Liao",
      "Yuke Lou",
      "Yifan Wu",
      "Lei Yang",
      "Jingbo Wang",
      "Taku Komura"
    ],
    "abstract": "Simulating stylized human-scene interactions (HSI) in physical environments\nis a challenging yet fascinating task. Prior works emphasize long-term\nexecution but fall short in achieving both diverse style and physical\nplausibility. To tackle this challenge, we introduce a novel hierarchical\nframework named SIMS that seamlessly bridges highlevel script-driven intent\nwith a low-level control policy, enabling more expressive and diverse\nhuman-scene interactions. Specifically, we employ Large Language Models with\nRetrieval-Augmented Generation (RAG) to generate coherent and diverse long-form\nscripts, providing a rich foundation for motion planning. A versatile\nmulticondition physics-based control policy is also developed, which leverages\ntext embeddings from the generated scripts to encode stylistic cues,\nsimultaneously perceiving environmental geometries and accomplishing task\ngoals. By integrating the retrieval-augmented script generation with the\nmulti-condition controller, our approach provides a unified solution for\ngenerating stylized HSI motions. We further introduce a comprehensive planning\ndataset produced by RAG and a stylized motion dataset featuring diverse\nlocomotions and interactions. Extensive experiments demonstrate SIMS's\neffectiveness in executing various tasks and generalizing across different\nscenarios, significantly outperforming previous methods.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.GR"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.19921v2",
    "published_date": "2024-11-29 18:36:15 UTC",
    "updated_date": "2025-03-16 04:09:27 UTC"
  },
  {
    "arxiv_id": "2411.19918v1",
    "title": "Handling irresolvable conflicts in the Semantic Web: an RDF-based conflict-tolerant version of the Deontic Traditional Scheme",
    "authors": [
      "Livio Robaldo",
      "Gianluca Pozzato"
    ],
    "abstract": "This paper presents a new ontology that implements the well-known Deontic\nTraditional Scheme in RDFs and SPARQL, fit to handle irresolvable conflicts,\ni.e., situations in which two or more statements prescribe conflicting\nobligations, prohibitions, or permissions, with none of them being \"stronger\"\nthan the other one(s). In our view, this paper marks a significant advancement\nin standard theoretical research in formal Deontic Logic. Most contemporary\napproaches in this field are confined to the propositional level, mainly focus\non the notion of obligation, and lack implementations. The proposed framework\nis encoded in RDF, which is not only a first-order language but also the most\nwidely used knowledge representation language, as it forms the foundation of\nthe Semantic Web. Moreover, the proposed computational ontology formalizes all\ndeontic modalities defined in the Deontic Traditional Scheme, without\nspecifically focusing on obligations, and offers constructs to model and reason\nwith various types of irresolvable conflicts, violations, and the interaction\nbetween deontic modalities and contextual constraints in a given state of\naffairs. To the best of our knowledge, no existing approach in the literature\naddresses all these aspects within a unified integrated framework. All examples\npresented and discussed in this paper, together with Java code and clear\ninstructions to re-execute them locally, are available at\nhttps://github.com/liviorobaldo/conflict-tolerantDeonticTraditionalScheme",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.19918v1",
    "published_date": "2024-11-29 18:33:28 UTC",
    "updated_date": "2024-11-29 18:33:28 UTC"
  },
  {
    "arxiv_id": "2411.19913v1",
    "title": "Quantifying the synthetic and real domain gap in aerial scene understanding",
    "authors": [
      "Alina Marcu"
    ],
    "abstract": "Quantifying the gap between synthetic and real-world imagery is essential for\nimproving both transformer-based models - that rely on large volumes of data -\nand datasets, especially in underexplored domains like aerial scene\nunderstanding where the potential impact is significant. This paper introduces\na novel methodology for scene complexity assessment using Multi-Model Consensus\nMetric (MMCM) and depth-based structural metrics, enabling a robust evaluation\nof perceptual and structural disparities between domains. Our experimental\nanalysis, utilizing real-world (Dronescapes) and synthetic (Skyscenes)\ndatasets, demonstrates that real-world scenes generally exhibit higher\nconsensus among state-of-the-art vision transformers, while synthetic scenes\nshow greater variability and challenge model adaptability. The results\nunderline the inherent complexities and domain gaps, emphasizing the need for\nenhanced simulation fidelity and model generalization. This work provides\ncritical insights into the interplay between domain characteristics and model\nperformance, offering a pathway for improved domain adaptation strategies in\naerial scene understanding.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "17 pages (including references), 5 figures, 2 tables. Accepted for\n  publication in the \"Scientific Bulletin\", Series C, Electrical Engineering\n  and Computer Science, ISSN 2286-3540",
    "pdf_url": "http://arxiv.org/pdf/2411.19913v1",
    "published_date": "2024-11-29 18:18:26 UTC",
    "updated_date": "2024-11-29 18:18:26 UTC"
  },
  {
    "arxiv_id": "2411.19886v1",
    "title": "PDDLFuse: A Tool for Generating Diverse Planning Domains",
    "authors": [
      "Vedant Khandelwal",
      "Amit Sheth",
      "Forest Agostinelli"
    ],
    "abstract": "Various real-world challenges require planning algorithms that can adapt to a\nbroad range of domains. Traditionally, the creation of planning domains has\nrelied heavily on human implementation, which limits the scale and diversity of\navailable domains. While recent advancements have leveraged generative AI\ntechnologies such as large language models (LLMs) for domain creation, these\nefforts have predominantly focused on translating existing domains from natural\nlanguage descriptions rather than generating novel ones. In contrast, the\nconcept of domain randomization, which has been highly effective in\nreinforcement learning, enhances performance and generalizability by training\non a diverse array of randomized new domains. Inspired by this success, our\ntool, PDDLFuse, aims to bridge this gap in Planning Domain Definition Language\n(PDDL). PDDLFuse is designed to generate new, diverse planning domains that can\nbe used to validate new planners or test foundational planning models. We have\ndeveloped methods to adjust the domain generators parameters to modulate the\ndifficulty of the domains it generates. This adaptability is crucial as\nexisting domain-independent planners often struggle with more complex problems.\nInitial tests indicate that PDDLFuse efficiently creates intricate and varied\ndomains, representing a significant advancement over traditional domain\ngeneration methods and making a contribution towards planning research.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "218 Tables, 3 Figures, 4 Algorithms",
    "pdf_url": "http://arxiv.org/pdf/2411.19886v1",
    "published_date": "2024-11-29 17:52:39 UTC",
    "updated_date": "2024-11-29 17:52:39 UTC"
  },
  {
    "arxiv_id": "2411.19876v3",
    "title": "LUMIA: Linear probing for Unimodal and MultiModal Membership Inference Attacks leveraging internal LLM states",
    "authors": [
      "Luis Ibanez-Lissen",
      "Lorena Gonzalez-Manzano",
      "Jose Maria de Fuentes",
      "Nicolas Anciaux",
      "Joaquin Garcia-Alfaro"
    ],
    "abstract": "Large Language Models (LLMs) are increasingly used in a variety of\napplications, but concerns around membership inference have grown in parallel.\nPrevious efforts focus on black-to-grey-box models, thus neglecting the\npotential benefit from internal LLM information. To address this, we propose\nthe use of Linear Probes (LPs) as a method to detect Membership Inference\nAttacks (MIAs) by examining internal activations of LLMs. Our approach, dubbed\nLUMIA, applies LPs layer-by-layer to get fine-grained data on the model inner\nworkings. We test this method across several model architectures, sizes and\ndatasets, including unimodal and multimodal tasks. In unimodal MIA, LUMIA\nachieves an average gain of 15.71 % in Area Under the Curve (AUC) over previous\ntechniques. Remarkably, LUMIA reaches AUC>60% in 65.33% of cases -- an\nincrement of 46.80% against the state of the art. Furthermore, our approach\nreveals key insights, such as the model layers where MIAs are most detectable.\nIn multimodal models, LPs indicate that visual inputs can significantly\ncontribute to detect MIAs -- AUC>60% is reached in 85.90% of experiments.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.19876v3",
    "published_date": "2024-11-29 17:38:56 UTC",
    "updated_date": "2025-01-10 15:08:44 UTC"
  },
  {
    "arxiv_id": "2411.19875v1",
    "title": "Enhanced anomaly detection in well log data through the application of ensemble GANs",
    "authors": [
      "Abdulrahman Al-Fakih",
      "A. Koeshidayatullah",
      "Tapan Mukerji",
      "SanLinn I. Kaka"
    ],
    "abstract": "Although generative adversarial networks (GANs) have shown significant\nsuccess in modeling data distributions for image datasets, their application to\nstructured or tabular data, such as well logs, remains relatively\nunderexplored. This study extends the ensemble GANs (EGANs) framework to\ncapture the distribution of well log data and detect anomalies that fall\noutside of these distributions. The proposed approach compares the performance\nof traditional methods, such as Gaussian mixture models (GMMs), with EGANs in\ndetecting anomalies outside the expected data distributions. For the gamma ray\n(GR) dataset, EGANs achieved a precision of 0.62 and F1 score of 0.76,\noutperforming GMM's precision of 0.38 and F1 score of 0.54. Similarly, for\ntravel time (DT), EGANs achieved a precision of 0.70 and F1 score of 0.79,\nsurpassing GMM 0.56 and 0.71. In the neutron porosity (NPHI) dataset, EGANs\nrecorded a precision of 0.53 and F1 score of 0.68, outshining GMM 0.47 and\n0.61. For the bulk density (RHOB) dataset, EGANs achieved a precision of 0.52\nand an F1 score of 0.67, slightly outperforming GMM, which yielded a precision\nof 0.50 and an F1 score of 0.65. This work's novelty lies in applying EGANs for\nwell log data analysis, showcasing their ability to learn data patterns and\nidentify anomalies that deviate from them. This approach offers more reliable\nanomaly detection compared to traditional methods like GMM. The findings\nhighlight the potential of EGANs in enhancing anomaly detection for well log\ndata, delivering significant implications for optimizing drilling strategies\nand reservoir management through more accurate, data-driven insights into\nsubsurface characterization.",
    "categories": [
      "physics.geo-ph",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "physics.geo-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.19875v1",
    "published_date": "2024-11-29 17:36:31 UTC",
    "updated_date": "2024-11-29 17:36:31 UTC"
  },
  {
    "arxiv_id": "2411.19870v1",
    "title": "DeMo: Decoupled Momentum Optimization",
    "authors": [
      "Bowen Peng",
      "Jeffrey Quesnelle",
      "Diederik P. Kingma"
    ],
    "abstract": "Training large neural networks typically requires sharing gradients between\naccelerators through specialized high-speed interconnects. Drawing from the\nsignal processing principles of frequency decomposition and energy compaction,\nwe demonstrate that synchronizing full optimizer states and model parameters\nduring training is unnecessary. By decoupling momentum updates and allowing\ncontrolled divergence in optimizer states across accelerators, we achieve\nimproved convergence compared to state-of-the-art optimizers. We introduce\n{\\textbf{De}}coupled {\\textbf{Mo}}mentum (DeMo), a fused optimizer and data\nparallel algorithm that reduces inter-accelerator communication requirements by\nseveral orders of magnitude. This enables training of large neural networks\neven with limited network bandwidth and heterogeneous hardware. Our method is\ntopology-agnostic and architecture-independent and supports scalable\nclock-synchronous distributed training with negligible compute and memory\noverhead. Empirical results show that models trained with DeMo match or exceed\nthe performance of equivalent models trained with AdamW, while eliminating the\nneed for high-speed interconnects when pre-training large scale foundation\nmodels. An open source reference PyTorch implementation is published on GitHub\nat https://github.com/bloc97/DeMo",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.19870v1",
    "published_date": "2024-11-29 17:31:47 UTC",
    "updated_date": "2024-11-29 17:31:47 UTC"
  },
  {
    "arxiv_id": "2411.19865v2",
    "title": "Reverse Thinking Makes LLMs Stronger Reasoners",
    "authors": [
      "Justin Chih-Yao Chen",
      "Zifeng Wang",
      "Hamid Palangi",
      "Rujun Han",
      "Sayna Ebrahimi",
      "Long Le",
      "Vincent Perot",
      "Swaroop Mishra",
      "Mohit Bansal",
      "Chen-Yu Lee",
      "Tomas Pfister"
    ],
    "abstract": "Reverse thinking plays a crucial role in human reasoning. Humans can reason\nnot only from a problem to a solution but also in reverse, i.e., start from the\nsolution and reason towards the problem. This often enhances overall reasoning\nperformance as it enables consistency checks between their forward and backward\nthinking. To enable Large Language Models (LLMs) to perform reverse thinking,\nwe introduce Reverse-Enhanced Thinking (RevThink), a framework composed of data\naugmentation and learning objectives. In RevThink, we augment the dataset by\ncollecting structured forward-backward reasoning from a teacher model,\nconsisting of: (1) the original question, (2) forward reasoning, (3) backward\nquestion, and (4) backward reasoning. We then employ three objectives to train\na smaller student model in a multi-task learning fashion: (a) generate forward\nreasoning from a question, (b) generate a backward question from a question,\nand (c) generate backward reasoning from the backward question. Experiments\nacross 12 datasets covering commonsense, math, and logical reasoning show an\naverage 13.53% improvement over the student model's zero-shot performance and a\n6.84% improvement over the strongest knowledge distillation baselines.\nMoreover, our method demonstrates sample efficiency -- using only 10% of the\ncorrect forward reasoning from the training data, it outperforms a standard\nfine-tuning method trained on 10x more forward reasoning. RevThink also\nexhibits strong generalization to out-of-distribution held-out datasets.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to NAACL 2025",
    "pdf_url": "http://arxiv.org/pdf/2411.19865v2",
    "published_date": "2024-11-29 17:27:05 UTC",
    "updated_date": "2025-03-07 20:33:35 UTC"
  },
  {
    "arxiv_id": "2411.19842v1",
    "title": "Scaling Transformers for Low-Bitrate High-Quality Speech Coding",
    "authors": [
      "Julian D Parker",
      "Anton Smirnov",
      "Jordi Pons",
      "CJ Carr",
      "Zack Zukowski",
      "Zach Evans",
      "Xubo Liu"
    ],
    "abstract": "The tokenization of speech with neural audio codec models is a vital part of\nmodern AI pipelines for the generation or understanding of speech, alone or in\na multimodal context. Traditionally such tokenization models have concentrated\non low parameter-count architectures using only components with strong\ninductive biases. In this work we show that by scaling a transformer\narchitecture with large parameter count to this problem, and applying a\nflexible Finite Scalar Quantization (FSQ) based bottleneck, it is possible to\nreach state-of-the-art speech quality at extremely low bit-rates of $400$ or\n$700$ bits-per-second. The trained models strongly out-perform existing\nbaselines in both objective and subjective tests.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.LG",
      "cs.SD",
      "eess.SP"
    ],
    "primary_category": "eess.AS",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.19842v1",
    "published_date": "2024-11-29 16:58:02 UTC",
    "updated_date": "2024-11-29 16:58:02 UTC"
  },
  {
    "arxiv_id": "2411.19809v1",
    "title": "Q-learning-based Model-free Safety Filter",
    "authors": [
      "Guo Ning Sue",
      "Yogita Choudhary",
      "Richard Desatnik",
      "Carmel Majidi",
      "John Dolan",
      "Guanya Shi"
    ],
    "abstract": "Ensuring safety via safety filters in real-world robotics presents\nsignificant challenges, particularly when the system dynamics is complex or\nunavailable. To handle this issue, learning-based safety filters recently\ngained popularity, which can be classified as model-based and model-free\nmethods. Existing model-based approaches requires various assumptions on system\nmodel (e.g., control-affine), which limits their application in complex\nsystems, and existing model-free approaches need substantial modifications to\nstandard RL algorithms and lack versatility. This paper proposes a simple,\nplugin-and-play, and effective model-free safety filter learning framework. We\nintroduce a novel reward formulation and use Q-learning to learn Q-value\nfunctions to safeguard arbitrary task specific nominal policies via filtering\nout their potentially unsafe actions. The threshold used in the filtering\nprocess is supported by our theoretical analysis. Due to its model-free nature\nand simplicity, our framework can be seamlessly integrated with various RL\nalgorithms. We validate the proposed approach through simulations on double\nintegrator and Dubin's car systems and demonstrate its effectiveness in\nreal-world experiments with a soft robotic limb.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO",
    "comment": "*Denotes equal contribution",
    "pdf_url": "http://arxiv.org/pdf/2411.19809v1",
    "published_date": "2024-11-29 16:16:59 UTC",
    "updated_date": "2024-11-29 16:16:59 UTC"
  },
  {
    "arxiv_id": "2411.19806v2",
    "title": "Zero-shot Musical Stem Retrieval with Joint-Embedding Predictive Architectures",
    "authors": [
      "Alain Riou",
      "Antonin Gagneré",
      "Gaëtan Hadjeres",
      "Stefan Lattner",
      "Geoffroy Peeters"
    ],
    "abstract": "In this paper, we tackle the task of musical stem retrieval. Given a musical\nmix, it consists in retrieving a stem that would fit with it, i.e., that would\nsound pleasant if played together. To do so, we introduce a new method based on\nJoint-Embedding Predictive Architectures, where an encoder and a predictor are\njointly trained to produce latent representations of a context and predict\nlatent representations of a target. In particular, we design our predictor to\nbe conditioned on arbitrary instruments, enabling our model to perform\nzero-shot stem retrieval. In addition, we discover that pretraining the encoder\nusing contrastive learning drastically improves the model's performance.\n  We validate the retrieval performances of our model using the MUSDB18 and\nMoisesDB datasets. We show that it significantly outperforms previous baselines\non both datasets, showcasing its ability to support more or less precise (and\npossibly unseen) conditioning. We also evaluate the learned embeddings on a\nbeat tracking task, demonstrating that they retain temporal structure and local\ninformation.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Accepted to the IEEE International Conference on Acoustics, Speech\n  and Signal Processing (ICASSP 2025)",
    "pdf_url": "http://arxiv.org/pdf/2411.19806v2",
    "published_date": "2024-11-29 16:11:47 UTC",
    "updated_date": "2025-02-24 17:10:01 UTC"
  },
  {
    "arxiv_id": "2411.19804v1",
    "title": "Advanced System Integration: Analyzing OpenAPI Chunking for Retrieval-Augmented Generation",
    "authors": [
      "Robin D. Pesl",
      "Jerin G. Mathew",
      "Massimo Mecella",
      "Marco Aiello"
    ],
    "abstract": "Integrating multiple (sub-)systems is essential to create advanced\nInformation Systems (ISs). Difficulties mainly arise when integrating dynamic\nenvironments across the IS lifecycle. A traditional approach is a registry that\nprovides the API documentation of the systems' endpoints. Large Language Models\n(LLMs) have shown to be capable of automatically creating system integrations\n(e.g., as service composition) based on this documentation but require concise\ninput due to input token limitations, especially regarding comprehensive API\ndescriptions. Currently, it is unknown how best to preprocess these API\ndescriptions. Within this work, we (i) analyze the usage of Retrieval Augmented\nGeneration (RAG) for endpoint discovery and the chunking, i.e., preprocessing,\nof OpenAPIs to reduce the input token length while preserving the most relevant\ninformation. To further reduce the input token length for the composition\nprompt and improve endpoint retrieval, we propose (ii) a Discovery Agent that\nonly receives a summary of the most relevant endpoints and retrieves details on\ndemand. We evaluate RAG for endpoint discovery using the RestBench benchmark,\nfirst, for the different chunking possibilities and parameters measuring the\nendpoint retrieval recall, precision, and F1 score. Then, we assess the\nDiscovery Agent using the same test set. With our prototype, we demonstrate how\nto successfully employ RAG for endpoint discovery to reduce the token count.\nWhile revealing high values for recall, precision, and F1, further research is\nnecessary to retrieve all requisite endpoints. Our experiments show that for\npreprocessing, LLM-based and format-specific approaches outperform na\\\"ive\nchunking methods. Relying on an agent further enhances these results as the\nagent splits the tasks into multiple fine granular subtasks, improving the\noverall RAG performance in the token count, precision, and F1 score.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.19804v1",
    "published_date": "2024-11-29 16:09:43 UTC",
    "updated_date": "2024-11-29 16:09:43 UTC"
  },
  {
    "arxiv_id": "2411.19787v1",
    "title": "CAREL: Instruction-guided reinforcement learning with cross-modal auxiliary objectives",
    "authors": [
      "Armin Saghafian",
      "Amirmohammad Izadi",
      "Negin Hashemi Dijujin",
      "Mahdieh Soleymani Baghshah"
    ],
    "abstract": "Grounding the instruction in the environment is a key step in solving\nlanguage-guided goal-reaching reinforcement learning problems. In automated\nreinforcement learning, a key concern is to enhance the model's ability to\ngeneralize across various tasks and environments. In goal-reaching scenarios,\nthe agent must comprehend the different parts of the instructions within the\nenvironmental context in order to complete the overall task successfully. In\nthis work, we propose CAREL (Cross-modal Auxiliary REinforcement Learning) as a\nnew framework to solve this problem using auxiliary loss functions inspired by\nvideo-text retrieval literature and a novel method called instruction tracking,\nwhich automatically keeps track of progress in an environment. The results of\nour experiments suggest superior sample efficiency and systematic\ngeneralization for this framework in multi-modal reinforcement learning\nproblems. Our code base is available here.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.19787v1",
    "published_date": "2024-11-29 15:49:06 UTC",
    "updated_date": "2024-11-29 15:49:06 UTC"
  },
  {
    "arxiv_id": "2412.00167v1",
    "title": "Origin-Destination Demand Prediction: An Urban Radiation and Attraction Perspective",
    "authors": [
      "Xuan Ma",
      "Zepeng Bao",
      "Ming Zhong",
      "Yuanyuan Zhu",
      "Chenliang Li",
      "Jiawei Jiang",
      "Qing Li",
      "Tieyun Qian"
    ],
    "abstract": "In recent years, origin-destination (OD) demand prediction has gained\nsignificant attention for its profound implications in urban development.\nExisting data-driven deep learning methods primarily focus on the spatial or\ntemporal dependency between regions yet neglecting regions' fundamental\nfunctional difference. Though knowledge-driven physical methods have\ncharacterised regions' functions by their radiation and attraction capacities,\nthese functions are defined on numerical factors like population without\nconsidering regions' intrinsic nominal attributes, e.g., a region is a\nresidential or industrial district. Moreover, the complicated relationships\nbetween two types of capacities, e.g., the radiation capacity of a residential\ndistrict in the morning will be transformed into the attraction capacity in the\nevening, are totally missing from physical methods.\n  In this paper, we not only generalize the physical radiation and attraction\ncapacities into the deep learning framework with the extended capability to\nfulfil regions' functions, but also present a new model that captures the\nrelationships between two types of capacities. Specifically, we first model\nregions' radiation and attraction capacities using a bilateral branch network,\neach equipped with regions' attribute representations. We then describe the\ntransformation relationship of different capacities of the same region using a\nhypergraph-based parameter generation method. We finally unveil the competition\nrelationship of different regions with the same attraction capacity through\ncluster-based adversarial learning. Extensive experiments on two datasets\ndemonstrate the consistent improvements of our method over the state-of-the-art\nbaselines, as well as the good explainability of regions' functions using their\nnominal attributes.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.00167v1",
    "published_date": "2024-11-29 15:35:17 UTC",
    "updated_date": "2024-11-29 15:35:17 UTC"
  },
  {
    "arxiv_id": "2412.09000v1",
    "title": "The AI Interface: Designing for the Ideal Machine-Human Experience (Editorial)",
    "authors": [
      "Aparna Sundar",
      "Tony Russell-Rose",
      "Udo Kruschwitz",
      "Karen Machleit"
    ],
    "abstract": "As artificial intelligence (AI) becomes increasingly embedded in daily life,\ndesigning intuitive, trustworthy, and emotionally resonant AI-human interfaces\nhas emerged as a critical challenge. This editorial introduces a Special Issue\nthat explores the psychology of AI experience design, focusing on how\ninterfaces can foster seamless collaboration between humans and machines.\nDrawing on insights from diverse fields (healthcare, consumer technology,\nworkplace dynamics, and cultural sector), the papers in this collection\nhighlight the complexities of trust, transparency, and emotional sensitivity in\nhuman-AI interaction. Key themes include designing AI systems that align with\nuser perceptions and expectations, overcoming resistance through transparency\nand trust, and framing AI capabilities to reduce user anxiety. By synthesizing\nfindings from eight diverse studies, this editorial underscores the need for AI\ninterfaces to balance efficiency with empathy, addressing both functional and\nemotional dimensions of user experience. Ultimately, it calls for actionable\nframeworks to bridge research and practice, ensuring that AI systems enhance\nhuman lives through thoughtful, human-centered design.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "H.5.2"
    ],
    "primary_category": "cs.HC",
    "comment": "8 pages",
    "pdf_url": "http://arxiv.org/pdf/2412.09000v1",
    "published_date": "2024-11-29 15:17:32 UTC",
    "updated_date": "2024-11-29 15:17:32 UTC"
  },
  {
    "arxiv_id": "2411.19766v1",
    "title": "Stock Price Prediction using Multi-Faceted Information based on Deep Recurrent Neural Networks",
    "authors": [
      "Lida Shahbandari",
      "Elahe Moradi",
      "Mohammad Manthouri"
    ],
    "abstract": "Accurate prediction of stock market trends is crucial for informed investment\ndecisions and effective portfolio management, ultimately leading to enhanced\nwealth creation and risk mitigation. This study proposes a novel approach for\npredicting stock prices in the stock market by integrating Convolutional Neural\nNetworks (CNN) and Long Short-Term Memory (LSTM) networks, using sentiment\nanalysis of social network data and candlestick data (price). The proposed\nmethodology consists of two primary components: sentiment analysis of social\nnetwork and candlestick data. By amalgamating candlestick data with insights\ngleaned from Twitter, this approach facilitates a more detailed and accurate\nexamination of market trends and patterns, ultimately leading to more effective\nstock price predictions. Additionally, a Random Forest algorithm is used to\nclassify tweets as either positive or negative, allowing for a more subtle and\ninformed assessment of market sentiment. This study uses CNN and LSTM networks\nto predict stock prices. The CNN extracts short-term features, while the LSTM\nmodels long-term dependencies. The integration of both networks enables a more\ncomprehensive analysis of market trends and patterns, leading to more accurate\nstock price predictions.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.19766v1",
    "published_date": "2024-11-29 15:12:48 UTC",
    "updated_date": "2024-11-29 15:12:48 UTC"
  },
  {
    "arxiv_id": "2411.19763v1",
    "title": "Forecasting Foreign Exchange Market Prices Using Technical Indicators with Deep Learning and Attention Mechanism",
    "authors": [
      "Sahabeh Saadati",
      "Mohammad Manthouri"
    ],
    "abstract": "Accurate prediction of price behavior in the foreign exchange market is\ncrucial. This paper proposes a novel approach that leverages technical\nindicators and deep neural networks. The proposed architecture consists of a\nLong Short-Term Memory (LSTM) and Convolutional Neural Network (CNN), and\nattention mechanism. Initially, trend and oscillation technical indicators are\nemployed to extract statistical features from Forex currency pair data,\nproviding insights into price trends, market volatility, relative price\nstrength, and overbought and oversold conditions. Subsequently, the LSTM and\nCNN networks are utilized in parallel to predict future price movements,\nleveraging the strengths of both recurrent and convolutional architectures. The\nLSTM network captures long-term dependencies and temporal patterns in the data,\nwhile the CNN network extracts local patterns. The outputs of the parallel LSTM\nand CNN networks are then fed into an attention mechanism, which learns to\nweigh the importance of each feature and temporal dependency, generating a\ncontext-aware representation of the input data. The attention-weighted output\nis then used to predict future price movements, enabling the model to focus on\nthe most relevant features and temporal dependencies. Through a comprehensive\nevaluation of the proposed approach on multiple Forex currency pairs, we\ndemonstrate its effectiveness in predicting price behavior and outperforming\nbenchmark models.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.19763v1",
    "published_date": "2024-11-29 15:07:44 UTC",
    "updated_date": "2024-11-29 15:07:44 UTC"
  },
  {
    "arxiv_id": "2411.19758v1",
    "title": "LaVIDE: A Language-Vision Discriminator for Detecting Changes in Satellite Image with Map References",
    "authors": [
      "Shuguo Jiang",
      "Fang Xu",
      "Sen Jia",
      "Gui-Song Xia"
    ],
    "abstract": "Change detection, which typically relies on the comparison of bi-temporal\nimages, is significantly hindered when only a single image is available.\nComparing a single image with an existing map, such as OpenStreetMap, which is\ncontinuously updated through crowd-sourcing, offers a viable solution to this\nchallenge. Unlike images that carry low-level visual details of ground objects,\nmaps convey high-level categorical information. This discrepancy in abstraction\nlevels complicates the alignment and comparison of the two data types. In this\npaper, we propose a \\textbf{La}nguage-\\textbf{VI}sion \\textbf{D}iscriminator\nfor d\\textbf{E}tecting changes in satellite image with map references, namely\n\\ours{}, which leverages language to bridge the information gap between maps\nand images. Specifically, \\ours{} formulates change detection as the problem of\n``{\\textit Does the pixel belong to [class]?}'', aligning maps and images\nwithin the feature space of the language-vision model to associate high-level\nmap categories with low-level image details. Moreover, we build a\nmixture-of-experts discriminative module, which compares linguistic features\nfrom maps with visual features from images across various semantic\nperspectives, achieving comprehensive semantic comparison for change detection.\nExtensive evaluation on four benchmark datasets demonstrates that \\ours{} can\neffectively detect changes in satellite image with map references,\noutperforming state-of-the-art change detection algorithms, e.g., with gains of\nabout $13.8$\\% on the DynamicEarthNet dataset and $4.3$\\% on the SECOND\ndataset.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.19758v1",
    "published_date": "2024-11-29 15:04:40 UTC",
    "updated_date": "2024-11-29 15:04:40 UTC"
  },
  {
    "arxiv_id": "2412.12107v1",
    "title": "Generative AI Literacy: Twelve Defining Competencies",
    "authors": [
      "Ravinithesh Annapureddy",
      "Alessandro Fornaroli",
      "Daniel Gatica-Perez"
    ],
    "abstract": "This paper introduces a competency-based model for generative artificial\nintelligence (AI) literacy covering essential skills and knowledge areas\nnecessary to interact with generative AI. The competencies range from\nfoundational AI literacy to prompt engineering and programming skills,\nincluding ethical and legal considerations. These twelve competencies offer a\nframework for individuals, policymakers, government officials, and educators\nlooking to navigate and take advantage of the potential of generative AI\nresponsibly. Embedding these competencies into educational programs and\nprofessional training initiatives can equip individuals to become responsible\nand informed users and creators of generative AI. The competencies follow a\nlogical progression and serve as a roadmap for individuals seeking to get\nfamiliar with generative AI and for researchers and policymakers to develop\nassessments, educational programs, guidelines, and regulations.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.12107v1",
    "published_date": "2024-11-29 14:55:15 UTC",
    "updated_date": "2024-11-29 14:55:15 UTC"
  },
  {
    "arxiv_id": "2411.19747v1",
    "title": "A Multi-Loss Strategy for Vehicle Trajectory Prediction: Combining Off-Road, Diversity, and Directional Consistency Losses",
    "authors": [
      "Ahmad Rahimi",
      "Alexandre Alahi"
    ],
    "abstract": "Trajectory prediction is essential for the safety and efficiency of planning\nin autonomous vehicles. However, current models often fail to fully capture\ncomplex traffic rules and the complete range of potential vehicle movements.\nAddressing these limitations, this study introduces three novel loss functions:\nOffroad Loss, Direction Consistency Error, and Diversity Loss. These functions\nare designed to keep predicted paths within driving area boundaries, aligned\nwith traffic directions, and cover a wider variety of plausible driving\nscenarios. As all prediction modes should adhere to road rules and conditions,\nthis work overcomes the shortcomings of traditional \"winner takes all\" training\nmethods by applying the loss functions to all prediction modes. These loss\nfunctions not only improve model training but can also serve as metrics for\nevaluating the realism and diversity of trajectory predictions. Extensive\nvalidation on the nuScenes and Argoverse 2 datasets with leading baseline\nmodels demonstrates that our approach not only maintains accuracy but\nsignificantly improves safety and robustness, reducing offroad errors on\naverage by 47% on original and by 37% on attacked scenes. This work sets a new\nbenchmark for trajectory prediction in autonomous driving, offering substantial\nimprovements in navigating complex environments. Our code is available at\nhttps://github.com/vita-epfl/stay-on-track .",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.MA",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "Preprint, 7 pages, 4 figures and 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2411.19747v1",
    "published_date": "2024-11-29 14:47:08 UTC",
    "updated_date": "2024-11-29 14:47:08 UTC"
  },
  {
    "arxiv_id": "2411.19746v1",
    "title": "HVAC-DPT: A Decision Pretrained Transformer for HVAC Control",
    "authors": [
      "Anaïs Berkes"
    ],
    "abstract": "Building operations consume approximately 40% of global energy, with Heating,\nVentilation, and Air Conditioning (HVAC) systems responsible for up to 50% of\nthis consumption. As HVAC energy demands are expected to rise, optimising\nsystem efficiency is crucial for reducing future energy use and mitigating\nclimate change. Existing control strategies lack generalisation and require\nextensive training and data, limiting their rapid deployment across diverse\nbuildings. This paper introduces HVAC-DPT, a Decision-Pretrained Transformer\nusing in-context Reinforcement Learning (RL) for multi-zone HVAC control.\nHVAC-DPT frames HVAC control as a sequential prediction task, training a causal\ntransformer on interaction histories generated by diverse RL agents. This\napproach enables HVAC-DPT to refine its policy in-context, without modifying\nnetwork parameters, allowing for deployment across different buildings without\nthe need for additional training or data collection. HVAC-DPT reduces energy\nconsumption in unseen buildings by 45% compared to the baseline controller,\noffering a scalable and effective approach to mitigating the increasing\nenvironmental impact of HVAC systems.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.LG",
    "comment": "7 pages, 3 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2411.19746v1",
    "published_date": "2024-11-29 14:46:37 UTC",
    "updated_date": "2024-11-29 14:46:37 UTC"
  },
  {
    "arxiv_id": "2412.00166v1",
    "title": "To Ensemble or Not: Assessing Majority Voting Strategies for Phishing Detection with Large Language Models",
    "authors": [
      "Fouad Trad",
      "Ali Chehab"
    ],
    "abstract": "The effectiveness of Large Language Models (LLMs) significantly relies on the\nquality of the prompts they receive. However, even when processing identical\nprompts, LLMs can yield varying outcomes due to differences in their training\nprocesses. To leverage the collective intelligence of multiple LLMs and enhance\ntheir performance, this study investigates three majority voting strategies for\ntext classification, focusing on phishing URL detection. The strategies are:\n(1) a prompt-based ensemble, which utilizes majority voting across the\nresponses generated by a single LLM to various prompts; (2) a model-based\nensemble, which entails aggregating responses from multiple LLMs to a single\nprompt; and (3) a hybrid ensemble, which combines the two methods by sending\ndifferent prompts to multiple LLMs and then aggregating their responses. Our\nanalysis shows that ensemble strategies are most suited in cases where\nindividual components exhibit equivalent performance levels. However, when\nthere is a significant discrepancy in individual performance, the effectiveness\nof the ensemble method may not exceed that of the highest-performing single LLM\nor prompt. In such instances, opting for ensemble techniques is not\nrecommended.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted in 4th International Conference on Intelligent Systems and\n  Pattern Recognition (ISPR24)",
    "pdf_url": "http://arxiv.org/pdf/2412.00166v1",
    "published_date": "2024-11-29 14:42:23 UTC",
    "updated_date": "2024-11-29 14:42:23 UTC"
  },
  {
    "arxiv_id": "2411.19744v1",
    "title": "Amplifying human performance in combinatorial competitive programming",
    "authors": [
      "Petar Veličković",
      "Alex Vitvitskyi",
      "Larisa Markeeva",
      "Borja Ibarz",
      "Lars Buesing",
      "Matej Balog",
      "Alexander Novikov"
    ],
    "abstract": "Recent years have seen a significant surge in complex AI systems for\ncompetitive programming, capable of performing at admirable levels against\nhuman competitors. While steady progress has been made, the highest percentiles\nstill remain out of reach for these methods on standard competition platforms\nsuch as Codeforces. Here we instead focus on combinatorial competitive\nprogramming, where the target is to find as-good-as-possible solutions to\notherwise computationally intractable problems, over specific given inputs. We\nhypothesise that this scenario offers a unique testbed for human-AI synergy, as\nhuman programmers can write a backbone of a heuristic solution, after which AI\ncan be used to optimise the scoring function used by the heuristic. We deploy\nour approach on previous iterations of Hash Code, a global team programming\ncompetition inspired by NP-hard software engineering problems at Google, and we\nleverage FunSearch to evolve our scoring functions. Our evolved solutions\nsignificantly improve the attained scores from their baseline, successfully\nbreaking into the top percentile on all previous Hash Code online qualification\nrounds, and outperforming the top human teams on several. Our method is also\nperformant on an optimisation problem that featured in a recent held-out\nAtCoder contest.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE",
      "cs.PL"
    ],
    "primary_category": "cs.LG",
    "comment": "Technical report. 18 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.19744v1",
    "published_date": "2024-11-29 14:40:36 UTC",
    "updated_date": "2024-11-29 14:40:36 UTC"
  },
  {
    "arxiv_id": "2411.19742v1",
    "title": "Graph Neural Networks for Heart Failure Prediction on an EHR-Based Patient Similarity Graph",
    "authors": [
      "Heloisa Oss Boll",
      "Ali Amirahmadi",
      "Amira Soliman",
      "Stefan Byttner",
      "Mariana Recamonde-Mendoza"
    ],
    "abstract": "Objective: In modern healthcare, accurately predicting diseases is a crucial\nmatter. This study introduces a novel approach using graph neural networks\n(GNNs) and a Graph Transformer (GT) to predict the incidence of heart failure\n(HF) on a patient similarity graph at the next hospital visit. Materials and\nMethods: We used electronic health records (EHR) from the MIMIC-III dataset and\napplied the K-Nearest Neighbors (KNN) algorithm to create a patient similarity\ngraph using embeddings from diagnoses, procedures, and medications. Three\nmodels - GraphSAGE, Graph Attention Network (GAT), and Graph Transformer (GT) -\nwere implemented to predict HF incidence. Model performance was evaluated using\nF1 score, AUROC, and AUPRC metrics, and results were compared against baseline\nalgorithms. An interpretability analysis was performed to understand the\nmodel's decision-making process. Results: The GT model demonstrated the best\nperformance (F1 score: 0.5361, AUROC: 0.7925, AUPRC: 0.5168). Although the\nRandom Forest (RF) baseline achieved a similar AUPRC value, the GT model\noffered enhanced interpretability due to the use of patient relationships in\nthe graph structure. A joint analysis of attention weights, graph connectivity,\nand clinical features provided insight into model predictions across different\nclassification groups. Discussion and Conclusion: Graph-based approaches such\nas GNNs provide an effective framework for predicting HF. By leveraging a\npatient similarity graph, GNNs can capture complex relationships in EHR data,\npotentially improving prediction accuracy and clinical interpretability.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.19742v1",
    "published_date": "2024-11-29 14:40:19 UTC",
    "updated_date": "2024-11-29 14:40:19 UTC"
  },
  {
    "arxiv_id": "2411.19732v1",
    "title": "Improving generalization of robot locomotion policies via Sharpness-Aware Reinforcement Learning",
    "authors": [
      "Severin Bochem",
      "Eduardo Gonzalez-Sanchez",
      "Yves Bicker",
      "Gabriele Fadini"
    ],
    "abstract": "Reinforcement learning often requires extensive training data.\nSimulation-to-real transfer offers a promising approach to address this\nchallenge in robotics. While differentiable simulators offer improved sample\nefficiency through exact gradients, they can be unstable in contact-rich\nenvironments and may lead to poor generalization. This paper introduces a novel\napproach integrating sharpness-aware optimization into gradient-based\nreinforcement learning algorithms. Our simulation results demonstrate that our\nmethod, tested on contact-rich environments, significantly enhances policy\nrobustness to environmental variations and action perturbations while\nmaintaining the sample efficiency of first-order methods. Specifically, our\napproach improves action noise tolerance compared to standard first-order\nmethods and achieves generalization comparable to zeroth-order methods. This\nimprovement stems from finding flatter minima in the loss landscape, associated\nwith better generalization. Our work offers a promising solution to balance\nefficient learning and robust sim-to-real transfer in robotics, potentially\nbridging the gap between simulation and real-world performance.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "9 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.19732v1",
    "published_date": "2024-11-29 14:25:54 UTC",
    "updated_date": "2024-11-29 14:25:54 UTC"
  },
  {
    "arxiv_id": "2411.19722v2",
    "title": "JetFormer: An Autoregressive Generative Model of Raw Images and Text",
    "authors": [
      "Michael Tschannen",
      "André Susano Pinto",
      "Alexander Kolesnikov"
    ],
    "abstract": "Removing modeling constraints and unifying architectures across domains has\nbeen a key driver of the recent progress in training large multimodal models.\nHowever, most of these models still rely on many separately trained components\nsuch as modality-specific encoders and decoders. In this work, we further\nstreamline joint generative modeling of images and text. We propose an\nautoregressive decoder-only transformer - JetFormer - which is trained to\ndirectly maximize the likelihood of raw data, without relying on any separately\npretrained components, and can understand and generate both text and images.\nSpecifically, we leverage a normalizing flow model to obtain a soft-token image\nrepresentation that is jointly trained with an autoregressive multimodal\ntransformer. The normalizing flow model serves as both an image encoder for\nperception tasks and an image decoder for image generation tasks during\ninference. JetFormer achieves text-to-image generation quality competitive with\nrecent VQ-VAE- and VAE-based baselines. These baselines rely on pretrained\nimage autoencoders, which are trained with a complex mixture of losses,\nincluding perceptual ones. At the same time, JetFormer demonstrates robust\nimage understanding capabilities. To the best of our knowledge, JetFormer is\nthe first model that is capable of generating high-fidelity images and\nproducing strong log-likelihood bounds.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "ICLR 2025. Code available at\n  https://github.com/google-research/big_vision",
    "pdf_url": "http://arxiv.org/pdf/2411.19722v2",
    "published_date": "2024-11-29 14:14:59 UTC",
    "updated_date": "2025-05-19 15:26:21 UTC"
  },
  {
    "arxiv_id": "2411.19717v1",
    "title": "MonoPP: Metric-Scaled Self-Supervised Monocular Depth Estimation by Planar-Parallax Geometry in Automotive Applications",
    "authors": [
      "Gasser Elazab",
      "Torben Gräber",
      "Michael Unterreiner",
      "Olaf Hellwich"
    ],
    "abstract": "Self-supervised monocular depth estimation (MDE) has gained popularity for\nobtaining depth predictions directly from videos. However, these methods often\nproduce scale invariant results, unless additional training signals are\nprovided. Addressing this challenge, we introduce a novel self-supervised\nmetric-scaled MDE model that requires only monocular video data and the\ncamera's mounting position, both of which are readily available in modern\nvehicles. Our approach leverages planar-parallax geometry to reconstruct scene\nstructure. The full pipeline consists of three main networks, a multi-frame\nnetwork, a singleframe network, and a pose network. The multi-frame network\nprocesses sequential frames to estimate the structure of the static scene using\nplanar-parallax geometry and the camera mounting position. Based on this\nreconstruction, it acts as a teacher, distilling knowledge such as scale\ninformation, masked drivable area, metric-scale depth for the static scene, and\ndynamic object mask to the singleframe network. It also aids the pose network\nin predicting a metric-scaled relative pose between two subsequent images. Our\nmethod achieved state-of-the-art results for the driving benchmark KITTI for\nmetric-scaled depth prediction. Notably, it is one of the first methods to\nproduce self-supervised metric-scaled depth prediction for the challenging\nCityscapes dataset, demonstrating its effectiveness and versatility.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at WACV 25, project page: https://mono-pp.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2411.19717v1",
    "published_date": "2024-11-29 14:06:58 UTC",
    "updated_date": "2024-11-29 14:06:58 UTC"
  },
  {
    "arxiv_id": "2411.19713v3",
    "title": "CantorNet: A Sandbox for Testing Geometrical and Topological Complexity Measures",
    "authors": [
      "Michal Lewandowski",
      "Hamid Eghbalzadeh",
      "Bernhard A. Moser"
    ],
    "abstract": "Many natural phenomena are characterized by self-similarity, for example the\nsymmetry of human faces, or a repetitive motif of a song. Studying of such\nsymmetries will allow us to gain deeper insights into the underlying mechanisms\nof complex systems. Recognizing the importance of understanding these patterns,\nwe propose a geometrically inspired framework to study such phenomena in\nartificial neural networks. To this end, we introduce \\emph{CantorNet},\ninspired by the triadic construction of the Cantor set, which was introduced by\nGeorg Cantor in the $19^\\text{th}$ century. In mathematics, the Cantor set is a\nset of points lying on a single line that is self-similar and has a counter\nintuitive property of being an uncountably infinite null set. Similarly, we\nintroduce CantorNet as a sandbox for studying self-similarity by means of novel\ntopological and geometrical complexity measures. CantorNet constitutes a family\nof ReLU neural networks that spans the whole spectrum of possible Kolmogorov\ncomplexities, including the two opposite descriptions (linear and exponential\nas measured by the description length). CantorNet's decision boundaries can be\narbitrarily ragged, yet are analytically known. Besides serving as a testing\nground for complexity measures, our work may serve to illustrate potential\npitfalls in geometry-ignorant data augmentation techniques and adversarial\nattacks.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.NE",
    "comment": "Accepted at the NeurIPS Workshop on Symmetry and Geometry in Neural\n  Representations, 2024",
    "pdf_url": "http://arxiv.org/pdf/2411.19713v3",
    "published_date": "2024-11-29 14:01:34 UTC",
    "updated_date": "2025-01-28 11:19:56 UTC"
  },
  {
    "arxiv_id": "2411.19668v1",
    "title": "ChineseWebText 2.0: Large-Scale High-quality Chinese Web Text with Multi-dimensional and fine-grained information",
    "authors": [
      "Wanyue Zhang",
      "Ziyong Li",
      "Wen Yang",
      "Chunlin Leng",
      "Yinan Bai",
      "Qianlong Du",
      "Chengqing Zong",
      "Jiajun Zhang"
    ],
    "abstract": "During the development of large language models (LLMs), pre-training data\nplay a critical role in shaping LLMs' capabilities. In recent years several\nlarge-scale and high-quality pre-training datasets have been released to\naccelerate the research of LLMs, including ChineseWebText1.0, C4, Pile,\nWanJuan, MAPCC and others. However, as LLMs continue to evolve, focus has\nincreasingly shifted to domain-specific capabilities and safety concerns,\nmaking those previous coarse-grained texts insufficient for meeting training\nrequirements. Furthermore, fine-grained information, such as quality, domain\nand toxicity, is becoming increasingly important in building powerful and\nreliable LLMs for various scenarios. To address these challenges, in this paper\nwe propose a new tool-chain called MDFG-tool for constructing large-scale and\nhigh-quality Chinese datasets with multi-dimensional and fine-grained\ninformation. First, we employ manually crafted rules to discard explicit noisy\ntexts from raw contents. Second, the quality evaluation model, domain\nclassifier, and toxicity evaluation model are well-designed to assess the\nremaining cleaned data respectively. Finally, we integrate these three types of\nfine-grained information for each text. With this approach, we release the\nlargest, high-quality and fine-grained Chinese text ChineseWebText2.0, which\nconsists of 3.8TB and each text is associated with a quality score, domain\nlabels, a toxicity label and a toxicity score, facilitating the LLM researchers\nto select data based on various types of fine-grained information. The data,\ncodes and the tool-chain are available on this website\nhttps://github.com/CASIA-LM/ChineseWebText-2.0",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "ChineseWebTex2.0 dataset is available at\n  https://github.com/CASIA-LM/ChineseWebText-2.0",
    "pdf_url": "http://arxiv.org/pdf/2411.19668v1",
    "published_date": "2024-11-29 12:48:49 UTC",
    "updated_date": "2024-11-29 12:48:49 UTC"
  },
  {
    "arxiv_id": "2411.19666v1",
    "title": "Multimodal Whole Slide Foundation Model for Pathology",
    "authors": [
      "Tong Ding",
      "Sophia J. Wagner",
      "Andrew H. Song",
      "Richard J. Chen",
      "Ming Y. Lu",
      "Andrew Zhang",
      "Anurag J. Vaidya",
      "Guillaume Jaume",
      "Muhammad Shaban",
      "Ahrong Kim",
      "Drew F. K. Williamson",
      "Bowen Chen",
      "Cristina Almagro-Perez",
      "Paul Doucet",
      "Sharifa Sahai",
      "Chengkuan Chen",
      "Daisuke Komura",
      "Akihiro Kawabe",
      "Shumpei Ishikawa",
      "Georg Gerber",
      "Tingying Peng",
      "Long Phi Le",
      "Faisal Mahmood"
    ],
    "abstract": "The field of computational pathology has been transformed with recent\nadvances in foundation models that encode histopathology region-of-interests\n(ROIs) into versatile and transferable feature representations via\nself-supervised learning (SSL). However, translating these advancements to\naddress complex clinical challenges at the patient and slide level remains\nconstrained by limited clinical data in disease-specific cohorts, especially\nfor rare clinical conditions. We propose TITAN, a multimodal whole slide\nfoundation model pretrained using 335,645 WSIs via visual self-supervised\nlearning and vision-language alignment with corresponding pathology reports and\n423,122 synthetic captions generated from a multimodal generative AI copilot\nfor pathology. Without any finetuning or requiring clinical labels, TITAN can\nextract general-purpose slide representations and generate pathology reports\nthat generalize to resource-limited clinical scenarios such as rare disease\nretrieval and cancer prognosis. We evaluate TITAN on diverse clinical tasks and\nfind that TITAN outperforms both ROI and slide foundation models across machine\nlearning settings such as linear probing, few-shot and zero-shot\nclassification, rare cancer retrieval and cross-modal retrieval, and pathology\nreport generation.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "stat.AP"
    ],
    "primary_category": "eess.IV",
    "comment": "The code is accessible at https://github.com/mahmoodlab/TITAN",
    "pdf_url": "http://arxiv.org/pdf/2411.19666v1",
    "published_date": "2024-11-29 12:39:57 UTC",
    "updated_date": "2024-11-29 12:39:57 UTC"
  },
  {
    "arxiv_id": "2411.19652v1",
    "title": "Uniform Attention Maps: Boosting Image Fidelity in Reconstruction and Editing",
    "authors": [
      "Wenyi Mo",
      "Tianyu Zhang",
      "Yalong Bai",
      "Bing Su",
      "Ji-Rong Wen"
    ],
    "abstract": "Text-guided image generation and editing using diffusion models have achieved\nremarkable advancements. Among these, tuning-free methods have gained attention\nfor their ability to perform edits without extensive model adjustments,\noffering simplicity and efficiency. However, existing tuning-free approaches\noften struggle with balancing fidelity and editing precision. Reconstruction\nerrors in DDIM Inversion are partly attributed to the cross-attention mechanism\nin U-Net, which introduces misalignments during the inversion and\nreconstruction process. To address this, we analyze reconstruction from a\nstructural perspective and propose a novel approach that replaces traditional\ncross-attention with uniform attention maps, significantly enhancing image\nreconstruction fidelity. Our method effectively minimizes distortions caused by\nvarying text conditions during noise prediction. To complement this\nimprovement, we introduce an adaptive mask-guided editing technique that\nintegrates seamlessly with our reconstruction approach, ensuring consistency\nand accuracy in editing tasks. Experimental results demonstrate that our\napproach not only excels in achieving high-fidelity image reconstruction but\nalso performs robustly in real image composition and editing scenarios. This\nstudy underscores the potential of uniform attention maps to enhance the\nfidelity and versatility of diffusion-based image processing methods. Code is\navailable at https://github.com/Mowenyii/Uniform-Attention-Maps.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to WACV 2025",
    "pdf_url": "http://arxiv.org/pdf/2411.19652v1",
    "published_date": "2024-11-29 12:11:28 UTC",
    "updated_date": "2024-11-29 12:11:28 UTC"
  },
  {
    "arxiv_id": "2411.19650v1",
    "title": "CogACT: A Foundational Vision-Language-Action Model for Synergizing Cognition and Action in Robotic Manipulation",
    "authors": [
      "Qixiu Li",
      "Yaobo Liang",
      "Zeyu Wang",
      "Lin Luo",
      "Xi Chen",
      "Mozheng Liao",
      "Fangyun Wei",
      "Yu Deng",
      "Sicheng Xu",
      "Yizhong Zhang",
      "Xiaofan Wang",
      "Bei Liu",
      "Jianlong Fu",
      "Jianmin Bao",
      "Dong Chen",
      "Yuanchun Shi",
      "Jiaolong Yang",
      "Baining Guo"
    ],
    "abstract": "The advancement of large Vision-Language-Action (VLA) models has\nsignificantly improved robotic manipulation in terms of language-guided task\nexecution and generalization to unseen scenarios. While existing VLAs adapted\nfrom pretrained large Vision-Language-Models (VLM) have demonstrated promising\ngeneralizability, their task performance is still unsatisfactory as indicated\nby the low tasks success rates in different environments. In this paper, we\npresent a new advanced VLA architecture derived from VLM. Unlike previous works\nthat directly repurpose VLM for action prediction by simple action\nquantization, we propose a omponentized VLA architecture that has a specialized\naction module conditioned on VLM output. We systematically study the design of\nthe action module and demonstrates the strong performance enhancement with\ndiffusion action transformers for action sequence modeling, as well as their\nfavorable scaling behaviors. We also conduct comprehensive experiments and\nablation studies to evaluate the efficacy of our models with varied designs.\nThe evaluation on 5 robot embodiments in simulation and real work shows that\nour model not only significantly surpasses existing VLAs in task performance\nand but also exhibits remarkable adaptation to new robots and generalization to\nunseen objects and backgrounds. It exceeds the average success rates of OpenVLA\nwhich has similar model size (7B) with ours by over 35% in simulated evaluation\nand 55% in real robot experiments. It also outperforms the large RT-2-X model\n(55B) by 18% absolute success rates in simulation. Code and models can be found\non our project page (https://cogact.github.io/).",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "Project Webpage: https://cogact.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2411.19650v1",
    "published_date": "2024-11-29 12:06:03 UTC",
    "updated_date": "2024-11-29 12:06:03 UTC"
  },
  {
    "arxiv_id": "2411.19647v1",
    "title": "CAdam: Confidence-Based Optimization for Online Learning",
    "authors": [
      "Shaowen Wang",
      "Anan Liu",
      "Jian Xiao",
      "Huan Liu",
      "Yuekui Yang",
      "Cong Xu",
      "Qianqian Pu",
      "Suncong Zheng",
      "Wei Zhang",
      "Jian Li"
    ],
    "abstract": "Modern recommendation systems frequently employ online learning to\ndynamically update their models with freshly collected data. The most commonly\nused optimizer for updating neural networks in these contexts is the Adam\noptimizer, which integrates momentum ($m_t$) and adaptive learning rate\n($v_t$). However, the volatile nature of online learning data, characterized by\nits frequent distribution shifts and presence of noises, poses significant\nchallenges to Adam's standard optimization process: (1) Adam may use outdated\nmomentum and the average of squared gradients, resulting in slower adaptation\nto distribution changes, and (2) Adam's performance is adversely affected by\ndata noise. To mitigate these issues, we introduce CAdam, a confidence-based\noptimization strategy that assesses the consistence between the momentum and\nthe gradient for each parameter dimension before deciding on updates. If\nmomentum and gradient are in sync, CAdam proceeds with parameter updates\naccording to Adam's original formulation; if not, it temporarily withholds\nupdates and monitors potential shifts in data distribution in subsequent\niterations. This method allows CAdam to distinguish between the true\ndistributional shifts and mere noise, and adapt more quickly to new data\ndistributions. Our experiments with both synthetic and real-world datasets\ndemonstrate that CAdam surpasses other well-known optimizers, including the\noriginal Adam, in efficiency and noise robustness. Furthermore, in large-scale\nA/B testing within a live recommendation system, CAdam significantly enhances\nmodel performance compared to Adam, leading to substantial increases in the\nsystem's gross merchandise volume (GMV).",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.19647v1",
    "published_date": "2024-11-29 12:00:27 UTC",
    "updated_date": "2024-11-29 12:00:27 UTC"
  },
  {
    "arxiv_id": "2411.19626v2",
    "title": "GREAT: Geometry-Intention Collaborative Inference for Open-Vocabulary 3D Object Affordance Grounding",
    "authors": [
      "Yawen Shao",
      "Wei Zhai",
      "Yuhang Yang",
      "Hongchen Luo",
      "Yang Cao",
      "Zheng-Jun Zha"
    ],
    "abstract": "Open-Vocabulary 3D object affordance grounding aims to anticipate ``action\npossibilities'' regions on 3D objects with arbitrary instructions, which is\ncrucial for robots to generically perceive real scenarios and respond to\noperational changes. Existing methods focus on combining images or languages\nthat depict interactions with 3D geometries to introduce external interaction\npriors. However, they are still vulnerable to a limited semantic space by\nfailing to leverage implied invariant geometries and potential interaction\nintentions. Normally, humans address complex tasks through multi-step reasoning\nand respond to diverse situations by leveraging associative and analogical\nthinking. In light of this, we propose GREAT (GeometRy-intEntion collAboraTive\ninference) for Open-Vocabulary 3D Object Affordance Grounding, a novel\nframework that mines the object invariant geometry attributes and performs\nanalogically reason in potential interaction scenarios to form affordance\nknowledge, fully combining the knowledge with both geometries and visual\ncontents to ground 3D object affordance. Besides, we introduce the Point Image\nAffordance Dataset v2 (PIADv2), the largest 3D object affordance dataset at\npresent to support the task. Extensive experiments demonstrate the\neffectiveness and superiority of GREAT. The code and dataset are available at\nhttps://yawen-shao.github.io/GREAT/.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "CVPR 2025. Project page: https://yawen-shao.github.io/GREAT/ Code:\n  https://github.com/yawen-shao/GREAT_code",
    "pdf_url": "http://arxiv.org/pdf/2411.19626v2",
    "published_date": "2024-11-29 11:23:15 UTC",
    "updated_date": "2025-03-29 03:46:58 UTC"
  },
  {
    "arxiv_id": "2411.19623v1",
    "title": "FairDD: Fair Dataset Distillation via Synchronized Matching",
    "authors": [
      "Qihang Zhou",
      "Shenhao Fang",
      "Shibo He",
      "Wenchao Meng",
      "Jiming Chen"
    ],
    "abstract": "Condensing large datasets into smaller synthetic counterparts has\ndemonstrated its promise for image classification. However, previous research\nhas overlooked a crucial concern in image recognition: ensuring that models\ntrained on condensed datasets are unbiased towards protected attributes (PA),\nsuch as gender and race. Our investigation reveals that dataset distillation\n(DD) fails to alleviate the unfairness towards minority groups within original\ndatasets. Moreover, this bias typically worsens in the condensed datasets due\nto their smaller size. To bridge the research gap, we propose a novel fair\ndataset distillation (FDD) framework, namely FairDD, which can be seamlessly\napplied to diverse matching-based DD approaches, requiring no modifications to\ntheir original architectures. The key innovation of FairDD lies in\nsynchronously matching synthetic datasets to PA-wise groups of original\ndatasets, rather than indiscriminate alignment to the whole distributions in\nvanilla DDs, dominated by majority groups. This synchronized matching allows\nsynthetic datasets to avoid collapsing into majority groups and bootstrap their\nbalanced generation to all PA groups. Consequently, FairDD could effectively\nregularize vanilla DDs to favor biased generation toward minority groups while\nmaintaining the accuracy of target attributes. Theoretical analyses and\nextensive experimental evaluations demonstrate that FairDD significantly\nimproves fairness compared to vanilla DD methods, without sacrificing\nclassification accuracy. Its consistent superiority across diverse DDs,\nspanning Distribution and Gradient Matching, establishes it as a versatile FDD\napproach.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.19623v1",
    "published_date": "2024-11-29 11:22:20 UTC",
    "updated_date": "2024-11-29 11:22:20 UTC"
  },
  {
    "arxiv_id": "2411.19583v1",
    "title": "Solving Rubik's Cube Without Tricky Sampling",
    "authors": [
      "Yicheng Lin",
      "Siyu Liang"
    ],
    "abstract": "The Rubiks Cube, with its vast state space and sparse reward structure,\npresents a significant challenge for reinforcement learning (RL) due to the\ndifficulty of reaching rewarded states. Previous research addressed this by\npropagating cost-to-go estimates from the solved state and incorporating search\ntechniques. These approaches differ from human strategies that start from fully\nscrambled cubes, which can be tricky for solving a general sparse-reward\nproblem. In this paper, we introduce a novel RL algorithm using policy gradient\nmethods to solve the Rubiks Cube without relying on near solved-state sampling.\nOur approach employs a neural network to predict cost patterns between states,\nallowing the agent to learn directly from scrambled states. Our method was\ntested on the 2x2x2 Rubiks Cube, where the cube was scrambled 50,000 times, and\nthe model successfully solved it in over 99.4% of cases. Notably, this result\nwas achieved using only the policy network without relying on tree search as in\nprevious methods, demonstrating its effectiveness and potential for broader\napplications in sparse-reward problems.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.19583v1",
    "published_date": "2024-11-29 09:56:40 UTC",
    "updated_date": "2024-11-29 09:56:40 UTC"
  },
  {
    "arxiv_id": "2411.19557v2",
    "title": "Initialization using Update Approximation is a Silver Bullet for Extremely Efficient Low-Rank Fine-Tuning",
    "authors": [
      "Kaustubh Ponkshe",
      "Raghav Singhal",
      "Eduard Gorbunov",
      "Alexey Tumanov",
      "Samuel Horvath",
      "Praneeth Vepakomma"
    ],
    "abstract": "Low-rank adapters have become standard for efficiently fine-tuning large\nlanguage models (LLMs), but they often fall short of achieving the performance\nof full fine-tuning. We propose a method, LoRA Silver Bullet or LoRA-SB, that\napproximates full fine-tuning within low-rank subspaces using a carefully\ndesigned initialization strategy. We theoretically demonstrate that the\narchitecture of LoRA-XS, which inserts a learnable (r x r) matrix between B and\nA while keeping other matrices fixed, provides the precise conditions needed\nfor this approximation. We leverage its constrained update space to achieve\noptimal scaling for high-rank gradient updates while removing the need for\nhyperparameter tuning. We prove that our initialization offers an optimal\nlow-rank approximation of the initial gradient and preserves update directions\nthroughout training. Extensive experiments across mathematical reasoning,\ncommonsense reasoning, and language understanding tasks demonstrate that our\napproach exceeds the performance of standard LoRA while using \\textbf{27-90}\ntimes fewer learnable parameters, and comprehensively outperforms LoRA-XS. Our\nfindings establish that it is possible to simulate full fine-tuning in low-rank\nsubspaces, and achieve significant efficiency gains without sacrificing\nperformance. Our code is publicly available at\nhttps://github.com/RaghavSinghal10/lora-sb.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Kaustubh Ponkshe and Raghav Singhal contributed equally to this work",
    "pdf_url": "http://arxiv.org/pdf/2411.19557v2",
    "published_date": "2024-11-29 09:10:30 UTC",
    "updated_date": "2025-02-07 19:50:29 UTC"
  },
  {
    "arxiv_id": "2411.19554v1",
    "title": "Unimib Assistant: designing a student-friendly RAG-based chatbot for all their needs",
    "authors": [
      "Chiara Antico",
      "Stefano Giordano",
      "Cansu Koyuturk",
      "Dimitri Ognibene"
    ],
    "abstract": "Natural language processing skills of Large Language Models (LLMs) are\nunprecedented, having wide diffusion and application in different tasks. This\npilot study focuses on specializing ChatGPT behavior through a\nRetrieval-Augmented Generation (RAG) system using the OpenAI custom GPTs\nfeature. The purpose of our chatbot, called Unimib Assistant, is to provide\ninformation and solutions to the specific needs of University of Milano-Bicocca\n(Unimib) students through a question-answering approach. We provided the system\nwith a prompt highlighting its specific purpose and behavior, as well as\nuniversity-related documents and links obtained from an initial need-finding\nphase, interviewing six students. After a preliminary customization phase, a\nqualitative usability test was conducted with six other students to identify\nthe strengths and weaknesses of the chatbot, with the goal of improving it in a\nsubsequent redesign phase. While the chatbot was appreciated for its\nuser-friendly experience, perceived general reliability, well-structured\nresponses, and conversational tone, several significant technical and\nfunctional limitations emerged. In particular, the satisfaction and overall\nexperience of the users was impaired by the system's inability to always\nprovide fully accurate information. Moreover, it would often neglect to report\nrelevant information even if present in the materials uploaded and prompt\ngiven. Furthermore, it sometimes generated unclickable links, undermining its\ntrustworthiness, since providing the source of information was an important\naspect for our users. Further in-depth studies and feedback from other users as\nwell as implementation iterations are planned to refine our Unimib Assistant.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.HC",
    "comment": "Accepted for Italian Workshop on Artificial Intelligence for Human\n  Machine Interaction (AIxHMI 2024), November 26, 2024, Bolzano, Italy",
    "pdf_url": "http://arxiv.org/pdf/2411.19554v1",
    "published_date": "2024-11-29 09:07:21 UTC",
    "updated_date": "2024-11-29 09:07:21 UTC"
  },
  {
    "arxiv_id": "2411.19548v1",
    "title": "ReconDreamer: Crafting World Models for Driving Scene Reconstruction via Online Restoration",
    "authors": [
      "Chaojun Ni",
      "Guosheng Zhao",
      "Xiaofeng Wang",
      "Zheng Zhu",
      "Wenkang Qin",
      "Guan Huang",
      "Chen Liu",
      "Yuyin Chen",
      "Yida Wang",
      "Xueyang Zhang",
      "Yifei Zhan",
      "Kun Zhan",
      "Peng Jia",
      "Xianpeng Lang",
      "Xingang Wang",
      "Wenjun Mei"
    ],
    "abstract": "Closed-loop simulation is crucial for end-to-end autonomous driving. Existing\nsensor simulation methods (e.g., NeRF and 3DGS) reconstruct driving scenes\nbased on conditions that closely mirror training data distributions. However,\nthese methods struggle with rendering novel trajectories, such as lane changes.\nRecent works have demonstrated that integrating world model knowledge\nalleviates these issues. Despite their efficiency, these approaches still\nencounter difficulties in the accurate representation of more complex\nmaneuvers, with multi-lane shifts being a notable example. Therefore, we\nintroduce ReconDreamer, which enhances driving scene reconstruction through\nincremental integration of world model knowledge. Specifically, DriveRestorer\nis proposed to mitigate artifacts via online restoration. This is complemented\nby a progressive data update strategy designed to ensure high-quality rendering\nfor more complex maneuvers. To the best of our knowledge, ReconDreamer is the\nfirst method to effectively render in large maneuvers. Experimental results\ndemonstrate that ReconDreamer outperforms Street Gaussians in the NTA-IoU,\nNTL-IoU, and FID, with relative improvements by 24.87%, 6.72%, and 29.97%.\nFurthermore, ReconDreamer surpasses DriveDreamer4D with PVG during large\nmaneuver rendering, as verified by a relative improvement of 195.87% in the\nNTA-IoU metric and a comprehensive user study.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "Project Page: https://recondreamer.github.io",
    "pdf_url": "http://arxiv.org/pdf/2411.19548v1",
    "published_date": "2024-11-29 08:47:46 UTC",
    "updated_date": "2024-11-29 08:47:46 UTC"
  },
  {
    "arxiv_id": "2411.19547v1",
    "title": "Training Agents with Weakly Supervised Feedback from Large Language Models",
    "authors": [
      "Dihong Gong",
      "Pu Lu",
      "Zelong Wang",
      "Meng Zhou",
      "Xiuqiang He"
    ],
    "abstract": "Large Language Models (LLMs) offer a promising basis for creating agents that\ncan tackle complex tasks through iterative environmental interaction. Existing\nmethods either require these agents to mimic expert-provided trajectories or\nrely on definitive environmental feedback for reinforcement learning which\nlimits their application to specific scenarios like gaming or code generation.\nThis paper introduces a novel training method for LLM-based agents using weakly\nsupervised signals from a critic LLM, bypassing the need for expert\ntrajectories or definitive feedback. Our agents are trained in iterative\nmanner, where they initially generate trajectories through environmental\ninteraction. Subsequently, a critic LLM selects a subset of good trajectories,\nwhich are then used to update the agents, enabling them to generate improved\ntrajectories in the next iteration. Extensive tests on the API-bank dataset\nshow consistent improvement in our agents' capabilities and comparable\nperformance to GPT-4, despite using open-source models with much fewer\nparameters.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.19547v1",
    "published_date": "2024-11-29 08:47:04 UTC",
    "updated_date": "2024-11-29 08:47:04 UTC"
  },
  {
    "arxiv_id": "2411.19544v1",
    "title": "SkelMamba: A State Space Model for Efficient Skeleton Action Recognition of Neurological Disorders",
    "authors": [
      "Niki Martinel",
      "Mariano Serrao",
      "Christian Micheloni"
    ],
    "abstract": "We introduce a novel state-space model (SSM)-based framework for\nskeleton-based human action recognition, with an anatomically-guided\narchitecture that improves state-of-the-art performance in both clinical\ndiagnostics and general action recognition tasks. Our approach decomposes\nskeletal motion analysis into spatial, temporal, and spatio-temporal streams,\nusing channel partitioning to capture distinct movement characteristics\nefficiently. By implementing a structured, multi-directional scanning strategy\nwithin SSMs, our model captures local joint interactions and global motion\npatterns across multiple anatomical body parts. This anatomically-aware\ndecomposition enhances the ability to identify subtle motion patterns critical\nin medical diagnosis, such as gait anomalies associated with neurological\nconditions. On public action recognition benchmarks, i.e., NTU RGB+D, NTU RGB+D\n120, and NW-UCLA, our model outperforms current state-of-the-art methods,\nachieving accuracy improvements up to $3.2\\%$ with lower computational\ncomplexity than previous leading transformer-based models. We also introduce a\nnovel medical dataset for motion-based patient neurological disorder analysis\nto validate our method's potential in automated disease diagnosis.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.19544v1",
    "published_date": "2024-11-29 08:43:52 UTC",
    "updated_date": "2024-11-29 08:43:52 UTC"
  },
  {
    "arxiv_id": "2411.19539v1",
    "title": "Knowledge Management for Automobile Failure Analysis Using Graph RAG",
    "authors": [
      "Yuta Ojima",
      "Hiroki Sakaji",
      "Tadashi Nakamura",
      "Hiroaki Sakata",
      "Kazuya Seki",
      "Yuu Teshigawara",
      "Masami Yamashita",
      "Kazuhiro Aoyama"
    ],
    "abstract": "This paper presents a knowledge management system for automobile failure\nanalysis using retrieval-augmented generation (RAG) with large language models\n(LLMs) and knowledge graphs (KGs). In the automotive industry, there is a\ngrowing demand for knowledge transfer of failure analysis from experienced\nengineers to young engineers. However, failure events are phenomena that occur\nin a chain reaction, making them difficult for beginners to analyze them. While\nknowledge graphs, which can describe semantic relationships and structure\ninformation is effective in representing failure events, due to their\ncapability of representing the relationships between components, there is much\ninformation in KGs, so it is challenging for young engineers to extract and\nunderstand sub-graphs from the KG. On the other hand, there is increasing\ninterest in the use of Graph RAG, a type of RAG that combines LLMs and KGs for\nknowledge management. However, when using the current Graph RAG framework with\nan existing knowledge graph for automobile failures, several issues arise\nbecause it is difficult to generate executable queries for a knowledge graph\ndatabase which is not constructed by LLMs. To address this, we focused on\noptimizing the Graph RAG pipeline for existing knowledge graphs. Using an\noriginal Q&A dataset, the ROUGE F1 score of the sentences generated by the\nproposed method showed an average improvement of 157.6% compared to the current\nmethod. This highlights the effectiveness of the proposed method for automobile\nfailure analysis.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.IR"
    ],
    "primary_category": "cs.AI",
    "comment": "7 pages, 6 figures, to be published in 2024 IEEE International\n  Conference on Bid Data (BigData)",
    "pdf_url": "http://arxiv.org/pdf/2411.19539v1",
    "published_date": "2024-11-29 08:34:07 UTC",
    "updated_date": "2024-11-29 08:34:07 UTC"
  },
  {
    "arxiv_id": "2411.19537v1",
    "title": "Deepfake Media Generation and Detection in the Generative AI Era: A Survey and Outlook",
    "authors": [
      "Florinel-Alin Croitoru",
      "Andrei-Iulian Hiji",
      "Vlad Hondru",
      "Nicolae Catalin Ristea",
      "Paul Irofti",
      "Marius Popescu",
      "Cristian Rusu",
      "Radu Tudor Ionescu",
      "Fahad Shahbaz Khan",
      "Mubarak Shah"
    ],
    "abstract": "With the recent advancements in generative modeling, the realism of deepfake\ncontent has been increasing at a steady pace, even reaching the point where\npeople often fail to detect manipulated media content online, thus being\ndeceived into various kinds of scams. In this paper, we survey deepfake\ngeneration and detection techniques, including the most recent developments in\nthe field, such as diffusion models and Neural Radiance Fields. Our literature\nreview covers all deepfake media types, comprising image, video, audio and\nmultimodal (audio-visual) content. We identify various kinds of deepfakes,\naccording to the procedure used to alter or generate the fake content. We\nfurther construct a taxonomy of deepfake generation and detection methods,\nillustrating the important groups of methods and the domains where these\nmethods are applied. Next, we gather datasets used for deepfake detection and\nprovide updated rankings of the best performing deepfake detectors on the most\npopular datasets. In addition, we develop a novel multimodal benchmark to\nevaluate deepfake detectors on out-of-distribution content. The results\nindicate that state-of-the-art detectors fail to generalize to deepfake content\ngenerated by unseen deepfake generators. Finally, we propose future directions\nto obtain robust and powerful deepfake detectors. Our project page and new\nbenchmark are available at https://github.com/CroitoruAlin/biodeep.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.MM",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.19537v1",
    "published_date": "2024-11-29 08:29:25 UTC",
    "updated_date": "2024-11-29 08:29:25 UTC"
  },
  {
    "arxiv_id": "2412.01787v2",
    "title": "Pretrained Reversible Generation as Unsupervised Visual Representation Learning",
    "authors": [
      "Rongkun Xue",
      "Jinouwen Zhang",
      "Yazhe Niu",
      "Dazhong Shen",
      "Bingqi Ma",
      "Yu Liu",
      "Jing Yang"
    ],
    "abstract": "Recent generative models based on score matching and flow matching have\nsignificantly advanced generation tasks, but their potential in discriminative\ntasks remains underexplored. Previous approaches, such as generative\nclassifiers, have not fully leveraged the capabilities of these models for\ndiscriminative tasks due to their intricate designs. We propose Pretrained\nReversible Generation (PRG), which extracts unsupervised representations by\nreversing the generative process of a pretrained continuous generation model.\nPRG effectively reuses unsupervised generative models, leveraging their high\ncapacity to serve as robust and generalizable feature extractors for downstream\ntasks. This framework enables the flexible selection of feature hierarchies\ntailored to specific downstream tasks. Our method consistently outperforms\nprior approaches across multiple benchmarks, achieving state-of-the-art\nperformance among generative model based methods, including 78% top-1 accuracy\non ImageNet at a resolution of 64. Extensive ablation studies, including\nout-of-distribution evaluations, further validate the effectiveness of our\napproach.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.01787v2",
    "published_date": "2024-11-29 08:24:49 UTC",
    "updated_date": "2025-03-08 14:13:46 UTC"
  },
  {
    "arxiv_id": "2412.00156v4",
    "title": "VISION-XL: High Definition Video Inverse Problem Solver using Latent Image Diffusion Models",
    "authors": [
      "Taesung Kwon",
      "Jong Chul Ye"
    ],
    "abstract": "In this paper, we propose a novel framework for solving high-definition video\ninverse problems using latent image diffusion models. Building on recent\nadvancements in spatio-temporal optimization for video inverse problems using\nimage diffusion models, our approach leverages latent-space diffusion models to\nachieve enhanced video quality and resolution. To address the high\ncomputational demands of processing high-resolution frames, we introduce a\npseudo-batch consistent sampling strategy, allowing efficient operation on a\nsingle GPU. Additionally, to improve temporal consistency, we present\npseudo-batch inversion, an initialization technique that incorporates\ninformative latents from the measurement. By integrating with SDXL, our\nframework achieves state-of-the-art video reconstruction across a wide range of\nspatio-temporal inverse problems, including complex combinations of frame\naveraging and various spatial degradations, such as deblurring,\nsuper-resolution, and inpainting. Unlike previous methods, our approach\nsupports multiple aspect ratios (landscape, vertical, and square) and delivers\nHD-resolution reconstructions (exceeding 1280x720) in under 6 seconds per frame\non a single NVIDIA 4090 GPU.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.CV",
    "comment": "Project page: https://vision-xl.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2412.00156v4",
    "published_date": "2024-11-29 08:10:49 UTC",
    "updated_date": "2025-03-07 02:43:19 UTC"
  },
  {
    "arxiv_id": "2411.19530v1",
    "title": "Quantized Delta Weight Is Safety Keeper",
    "authors": [
      "Yule Liu",
      "Zhen Sun",
      "Xinlei He",
      "Xinyi Huang"
    ],
    "abstract": "Recent advancements in fine-tuning proprietary language models enable\ncustomized applications across various domains but also introduce two major\nchallenges: high resource demands and security risks. Regarding resource\ndemands, recent work proposes novel partial compression, such as BitDelta, to\nquantize the delta weights between the fine-tuned model and base model.\nRegarding the security risks, user-defined fine-tuning can introduce security\nvulnerabilities, such as alignment issues, backdoor attacks, and\nhallucinations. However, most of the current efforts in security assessment\nfocus on the full-precision or full-compression models, it is not\nwell-discussed how the partial compression methods affect security concerns. To\nbridge this gap, we evaluate the robustness of delta-weight quantization\nagainst these security threats. In this paper, we uncover a \"free lunch\"\nphenomenon: partial compression can enhance model security against\nfine-tuning-based attacks with bearable utility loss. Using Llama-2-7b-chat as\na case study, we show that, with under 10% utility degradation, the partial\ncompression mitigates alignment-breaking risks by up to 66.17%, harmful\nbackdoor vulnerabilities by 64.46%, and targeted output manipulation risks by\nup to 90.53%. We further apply LogitLens to visualize internal state\ntransformations during forward passes, suggesting mechanisms for both security\nfailure and recovery in standard versus compressed fine-tuning. This work\noffers new insights into selecting effective delta compression methods for\nsecure, resource-efficient multi-tenant services.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.19530v1",
    "published_date": "2024-11-29 08:05:50 UTC",
    "updated_date": "2024-11-29 08:05:50 UTC"
  },
  {
    "arxiv_id": "2411.19528v1",
    "title": "RAGDiffusion: Faithful Cloth Generation via External Knowledge Assimilation",
    "authors": [
      "Xianfeng Tan",
      "Yuhan Li",
      "Wenxiang Shang",
      "Yubo Wu",
      "Jian Wang",
      "Xuanhong Chen",
      "Yi Zhang",
      "Ran Lin",
      "Bingbing Ni"
    ],
    "abstract": "Standard clothing asset generation involves creating forward-facing flat-lay\ngarment images displayed on a clear background by extracting clothing\ninformation from diverse real-world contexts, which presents significant\nchallenges due to highly standardized sampling distributions and precise\nstructural requirements in the generated images. Existing models have limited\nspatial perception and often exhibit structural hallucinations in this\nhigh-specification generative task. To address this issue, we propose a novel\nRetrieval-Augmented Generation (RAG) framework, termed RAGDiffusion, to enhance\nstructure determinacy and mitigate hallucinations by assimilating external\nknowledge from LLM and databases. RAGDiffusion consists of two core processes:\n(1) Retrieval-based structure aggregation, which employs contrastive learning\nand a Structure Locally Linear Embedding (SLLE) to derive global structure and\nspatial landmarks, providing both soft and hard guidance to counteract\nstructural ambiguities; and (2) Omni-level faithful garment generation, which\nintroduces a three-level alignment that ensures fidelity in structural,\npattern, and decoding components within the diffusing. Extensive experiments on\nchallenging real-world datasets demonstrate that RAGDiffusion synthesizes\nstructurally and detail-faithful clothing assets with significant performance\nimprovements, representing a pioneering effort in high-specification faithful\ngeneration with RAG to confront intrinsic hallucinations and enhance fidelity.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Project website: https://colorful-liyu.github.io/RAGDiffusion-page/",
    "pdf_url": "http://arxiv.org/pdf/2411.19528v1",
    "published_date": "2024-11-29 07:57:32 UTC",
    "updated_date": "2024-11-29 07:57:32 UTC"
  },
  {
    "arxiv_id": "2411.19527v3",
    "title": "DisCoRD: Discrete Tokens to Continuous Motion via Rectified Flow Decoding",
    "authors": [
      "Jungbin Cho",
      "Junwan Kim",
      "Jisoo Kim",
      "Minseo Kim",
      "Mingu Kang",
      "Sungeun Hong",
      "Tae-Hyun Oh",
      "Youngjae Yu"
    ],
    "abstract": "Human motion is inherently continuous and dynamic, posing significant\nchallenges for generative models. While discrete generation methods are widely\nused, they suffer from limited expressiveness and frame-wise noise artifacts.\nIn contrast, continuous approaches produce smoother, more natural motion but\noften struggle to adhere to conditioning signals due to high-dimensional\ncomplexity and limited training data. To resolve this discord between discrete\nand continuous representations, we introduce DisCoRD: Discrete Tokens to\nContinuous Motion via Rectified Flow Decoding, a novel method that leverages\nrectified flow to decode discrete motion tokens in the continuous, raw motion\nspace. Our core idea is to frame token decoding as a conditional generation\ntask, ensuring that DisCoRD captures fine-grained dynamics and achieves\nsmoother, more natural motions. Compatible with any discrete-based framework,\nour method enhances naturalness without compromising faithfulness to the\nconditioning signals on diverse settings. Extensive evaluations Our project\npage is available at: https://whwjdqls.github.io/discord.github.io/.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "11 pages",
    "pdf_url": "http://arxiv.org/pdf/2411.19527v3",
    "published_date": "2024-11-29 07:54:56 UTC",
    "updated_date": "2025-04-18 08:49:08 UTC"
  },
  {
    "arxiv_id": "2411.19526v1",
    "title": "A Local Information Aggregation based Multi-Agent Reinforcement Learning for Robot Swarm Dynamic Task Allocation",
    "authors": [
      "Yang Lv",
      "Jinlong Lei",
      "Peng Yi"
    ],
    "abstract": "In this paper, we explore how to optimize task allocation for robot swarms in\ndynamic environments, emphasizing the necessity of formulating robust,\nflexible, and scalable strategies for robot cooperation. We introduce a novel\nframework using a decentralized partially observable Markov decision process\n(Dec_POMDP), specifically designed for distributed robot swarm networks. At the\ncore of our methodology is the Local Information Aggregation Multi-Agent Deep\nDeterministic Policy Gradient (LIA_MADDPG) algorithm, which merges centralized\ntraining with distributed execution (CTDE). During the centralized training\nphase, a local information aggregation (LIA) module is meticulously designed to\ngather critical data from neighboring robots, enhancing decision-making\nefficiency. In the distributed execution phase, a strategy improvement method\nis proposed to dynamically adjust task allocation based on changing and\npartially observable environmental conditions. Our empirical evaluations show\nthat the LIA module can be seamlessly integrated into various CTDE-based MARL\nmethods, significantly enhancing their performance. Additionally, by comparing\nLIA_MADDPG with six conventional reinforcement learning algorithms and a\nheuristic algorithm, we demonstrate its superior scalability, rapid adaptation\nto environmental changes, and ability to maintain both stability and\nconvergence speed. These results underscore LIA_MADDPG's outstanding\nperformance and its potential to significantly improve dynamic task allocation\nin robot swarms through enhanced local collaboration and adaptive strategy\nexecution.",
    "categories": [
      "cs.AI",
      "cs.MA",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.19526v1",
    "published_date": "2024-11-29 07:53:05 UTC",
    "updated_date": "2024-11-29 07:53:05 UTC"
  },
  {
    "arxiv_id": "2411.19523v2",
    "title": "Density-Calibrated Conformal Quantile Regression",
    "authors": [
      "Yuan Lu"
    ],
    "abstract": "This paper introduces the Density-Calibrated Conformal Quantile Regression\n(CQR-d) method, a novel approach for constructing prediction intervals that\nadapts to varying uncertainty across the feature space. Building upon conformal\nquantile regression, CQR-d incorporates local information through a weighted\ncombination of local and global conformity scores, where the weights are\ndetermined by local data density. We prove that CQR-d provides valid marginal\ncoverage at level $1 - \\alpha - \\epsilon$, where $\\epsilon$ represents a small\ntolerance from numerical optimization. Through extensive simulation studies and\nan application to the a heteroscedastic dataset available in R, we demonstrate\nthat CQR-d maintains the desired coverage while producing substantially\nnarrower prediction intervals compared to standard conformal quantile\nregression (CQR). The method's effectiveness is particularly pronounced in\nsettings with clear local uncertainty patterns, making it a valuable tool for\nprediction tasks in heterogeneous data environments.",
    "categories": [
      "stat.ME",
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "stat.ME",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.19523v2",
    "published_date": "2024-11-29 07:41:20 UTC",
    "updated_date": "2024-12-02 20:33:09 UTC"
  },
  {
    "arxiv_id": "2411.19517v4",
    "title": "RL-MILP Solver: A Reinforcement Learning Approach for Solving Mixed-Integer Linear Programs with Graph Neural Networks",
    "authors": [
      "Tae-Hoon Lee",
      "Min-Soo Kim"
    ],
    "abstract": "Mixed-integer linear programming (MILP) is a widely used optimization\ntechnique across various fields. Existing $\\textit{end-to-end learning}$\nmethods for MILP generate values for a subset of decision variables and\ndelegate the remaining problem to traditional MILP solvers. However, this\napproach often fails to guarantee solution feasibility (i.e., satisfying all\nconstraints) due to inaccurate predictions and primarily focuses on binary\ndecision variables. Satisfying all constraints is a prerequisite for obtaining\nthe optimal solution, and the feasibility issue becomes even more critical with\nnon-binary integer (integer, for short) variables. Thus, addressing the\nfeasibility of MILP involving integer variables is crucial. To address these\nchallenges, we propose a novel reinforcement learning (RL)-based solver that\nnot only finds the first feasible solution but also incrementally discovers\nbetter feasible solutions without delegating the remainder to off-the-shelf\nsolvers. Our experimental results demonstrate that the proposed method achieves\n(near-)optimal solutions.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Extended version (17 pages, 8 figures). Accepted at the 2025 AAAI\n  Workshop on AI to Accelerate Science and Engineering (AI2ASE)",
    "pdf_url": "http://arxiv.org/pdf/2411.19517v4",
    "published_date": "2024-11-29 07:23:34 UTC",
    "updated_date": "2025-03-11 08:21:06 UTC"
  },
  {
    "arxiv_id": "2412.00154v2",
    "title": "o1-Coder: an o1 Replication for Coding",
    "authors": [
      "Yuxiang Zhang",
      "Shangxi Wu",
      "Yuqi Yang",
      "Jiangming Shu",
      "Jinlin Xiao",
      "Chao Kong",
      "Jitao Sang"
    ],
    "abstract": "The technical report introduces O1-CODER, an attempt to replicate OpenAI's o1\nmodel with a focus on coding tasks. It integrates reinforcement learning (RL)\nand Monte Carlo Tree Search (MCTS) to enhance the model's System-2 thinking\ncapabilities. The framework includes training a Test Case Generator (TCG) for\nstandardized code testing, using MCTS to generate code data with reasoning\nprocesses, and iteratively fine-tuning the policy model to initially produce\npseudocode and then generate the full code. The report also addresses the\nopportunities and challenges in deploying o1-like models in real-world\napplications, suggesting transitioning to the System-2 paradigm and\nhighlighting the imperative for world model construction. Updated model\nprogress and experimental results will be reported in subsequent versions. All\nsource code, curated datasets, as well as the derived models are disclosed at\nhttps://github.com/ADaM-BJTU/O1-CODER .",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.00154v2",
    "published_date": "2024-11-29 07:19:56 UTC",
    "updated_date": "2024-12-10 04:39:25 UTC"
  },
  {
    "arxiv_id": "2411.19504v1",
    "title": "TQA-Bench: Evaluating LLMs for Multi-Table Question Answering with Scalable Context and Symbolic Extension",
    "authors": [
      "Zipeng Qiu",
      "You Peng",
      "Guangxin He",
      "Binhang Yuan",
      "Chen Wang"
    ],
    "abstract": "The advent of large language models (LLMs) has unlocked great opportunities\nin complex data management tasks, particularly in question answering (QA) over\ncomplicated multi-table relational data. Despite significant progress,\nsystematically evaluating LLMs on multi-table QA remains a critical challenge\ndue to the inherent complexity of analyzing heterogeneous table structures and\npotential large scale of serialized relational data. Existing benchmarks\nprimarily focus on single-table QA, failing to capture the intricacies of\nreasoning across multiple relational tables, as required in real-world domains\nsuch as finance, healthcare, and e-commerce. To address this gap, we present\nTQA-Bench, a new multi-table QA benchmark designed to evaluate the capabilities\nof LLMs in tackling complex QA tasks over relational data. Our benchmark\nincorporates diverse relational database instances sourced from real-world\npublic datasets and introduces a flexible sampling mechanism to create tasks\nwith varying multi-table context lengths, ranging from 8K to 64K tokens. To\nensure robustness and reliability, we integrate symbolic extensions into the\nevaluation framework, enabling the assessment of LLM reasoning capabilities\nbeyond simple data retrieval or probabilistic pattern matching. We\nsystematically evaluate a range of LLMs, both open-source and closed-source,\nspanning model scales from 7 billion to 70 billion parameters. Our extensive\nexperiments reveal critical insights into the performance of LLMs in\nmulti-table QA, highlighting both challenges and opportunities for advancing\ntheir application in complex, data-driven environments. Our benchmark\nimplementation and results are available at\nhttps://github.com/Relaxed-System-Lab/TQA-Bench.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.IR"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.19504v1",
    "published_date": "2024-11-29 06:48:13 UTC",
    "updated_date": "2024-11-29 06:48:13 UTC"
  },
  {
    "arxiv_id": "2411.19502v1",
    "title": "Knowledge-Data Fusion Based Source-Free Semi-Supervised Domain Adaptation for Seizure Subtype Classification",
    "authors": [
      "Ruimin Peng",
      "Jiayu An",
      "Dongrui Wu"
    ],
    "abstract": "Electroencephalogram (EEG)-based seizure subtype classification enhances\nclinical diagnosis efficiency. Source-free semi-supervised domain adaptation\n(SF-SSDA), which transfers a pre-trained model to a new dataset with no source\ndata and limited labeled target data, can be used for privacy-preserving\nseizure subtype classification. This paper considers two challenges in SF-SSDA\nfor EEG-based seizure subtype classification: 1) How to effectively fuse both\nraw EEG data and expert knowledge in classifier design? 2) How to align the\nsource and target domain distributions for SF-SSDA? We propose a Knowledge-Data\nFusion based SF-SSDA approach, KDF-MutualSHOT, for EEG-based seizure subtype\nclassification. In source model training, KDF uses Jensen-Shannon Divergence to\nfacilitate mutual learning between a feature-driven Decision Tree-based model\nand a data-driven Transformer-based model. To adapt KDF to a new target\ndataset, an SF-SSDA algorithm, MutualSHOT, is developed, which features a\nconsistency-based pseudo-label selection strategy. Experiments on the public\nTUSZ and CHSZ datasets demonstrated that KDF-MutualSHOT outperformed other\nsupervised and source-free domain adaptation approaches in cross-subject\nseizure subtype classification.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.19502v1",
    "published_date": "2024-11-29 06:40:45 UTC",
    "updated_date": "2024-11-29 06:40:45 UTC"
  },
  {
    "arxiv_id": "2412.00152v1",
    "title": "Dynamic Neural Curiosity Enhances Learning Flexibility for Autonomous Goal Discovery",
    "authors": [
      "Quentin Houbre",
      "Roel Pieters"
    ],
    "abstract": "The autonomous learning of new goals in robotics remains a complex issue to\naddress. Here, we propose a model where curiosity influence learning\nflexibility. To do so, this paper proposes to root curiosity and attention\ntogether by taking inspiration from the Locus Coeruleus-Norepinephrine system\nalong with various cognitive processes such as cognitive persistence and visual\nhabituation. We apply our approach by experimenting with a simulated robotic\narm on a set of objects with varying difficulty. The robot first discovers new\ngoals via bottom-up attention through motor babbling with an inhibition of\nreturn mechanism, then engage to the learning of goals due to neural activity\narising within the curiosity mechanism. The architecture is modelled with\ndynamic neural fields and the learning of goals such as pushing the objects in\ndiverse directions is supported by the use of forward and inverse models\nimplemented by multi-layer perceptrons. The adoption of dynamic neural fields\nto model curiosity, habituation and persistence allows the robot to demonstrate\nvarious learning trajectories depending on the object. In addition, the\napproach exhibits interesting properties regarding the learning of similar\ngoals as well as the continuous switch between exploration and exploitation.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.00152v1",
    "published_date": "2024-11-29 06:37:23 UTC",
    "updated_date": "2024-11-29 06:37:23 UTC"
  },
  {
    "arxiv_id": "2411.19500v1",
    "title": "COLD: Causal reasOning in cLosed Daily activities",
    "authors": [
      "Abhinav Joshi",
      "Areeb Ahmad",
      "Ashutosh Modi"
    ],
    "abstract": "Large Language Models (LLMs) have shown state-of-the-art performance in a\nvariety of tasks, including arithmetic and reasoning; however, to gauge the\nintellectual capabilities of LLMs, causal reasoning has become a reliable proxy\nfor validating a general understanding of the mechanics and intricacies of the\nworld similar to humans. Previous works in natural language processing (NLP)\nhave either focused on open-ended causal reasoning via causal commonsense\nreasoning (CCR) or framed a symbolic representation-based question answering\nfor theoretically backed-up analysis via a causal inference engine. The former\nadds an advantage of real-world grounding but lacks theoretically backed-up\nanalysis/validation, whereas the latter is far from real-world grounding. In\nthis work, we bridge this gap by proposing the COLD (Causal reasOning in cLosed\nDaily activities) framework, which is built upon human understanding of daily\nreal-world activities to reason about the causal nature of events. We show that\nthe proposed framework facilitates the creation of enormous causal queries (~ 9\nmillion) and comes close to the mini-turing test, simulating causal reasoning\nto evaluate the understanding of a daily real-world task. We evaluate multiple\nLLMs on the created causal queries and find that causal reasoning is\nchallenging even for activities trivial to humans. We further explore (the\ncausal reasoning abilities of LLMs) using the backdoor criterion to determine\nthe causal strength between events.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Paper accepted at NeurIPS 2024; Total 37 Pages",
    "pdf_url": "http://arxiv.org/pdf/2411.19500v1",
    "published_date": "2024-11-29 06:37:13 UTC",
    "updated_date": "2024-11-29 06:37:13 UTC"
  },
  {
    "arxiv_id": "2411.19498v1",
    "title": "Protecting Multiple Types of Privacy Simultaneously in EEG-based Brain-Computer Interfaces",
    "authors": [
      "Lubin Meng",
      "Xue Jiang",
      "Tianwang Jia",
      "Dongrui Wu"
    ],
    "abstract": "A brain-computer interface (BCI) enables direct communication between the\nbrain and an external device. Electroencephalogram (EEG) is the preferred input\nsignal in non-invasive BCIs, due to its convenience and low cost. EEG-based\nBCIs have been successfully used in many applications, such as neurological\nrehabilitation, text input, games, and so on. However, EEG signals inherently\ncarry rich personal information, necessitating privacy protection. This paper\ndemonstrates that multiple types of private information (user identity, gender,\nand BCI-experience) can be easily inferred from EEG data, imposing a serious\nprivacy threat to BCIs. To address this issue, we design perturbations to\nconvert the original EEG data into privacy-protected EEG data, which conceal\nthe private information while maintaining the primary BCI task performance.\nExperimental results demonstrated that the privacy-protected EEG data can\nsignificantly reduce the classification accuracy of user identity, gender and\nBCI-experience, but almost do not affect at all the classification accuracy of\nthe primary BCI task, enabling user privacy protection in EEG-based BCIs.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.19498v1",
    "published_date": "2024-11-29 06:33:31 UTC",
    "updated_date": "2024-11-29 06:33:31 UTC"
  },
  {
    "arxiv_id": "2412.00151v1",
    "title": "DLaVA: Document Language and Vision Assistant for Answer Localization with Enhanced Interpretability and Trustworthiness",
    "authors": [
      "Ahmad Mohammadshirazi",
      "Pinaki Prasad Guha Neogi",
      "Ser-Nam Lim",
      "Rajiv Ramnath"
    ],
    "abstract": "Document Visual Question Answering (VQA) requires models to interpret textual\ninformation within complex visual layouts and comprehend spatial relationships\nto answer questions based on document images. Existing approaches often lack\ninterpretability and fail to precisely localize answers within the document,\nhindering users' ability to verify responses and understand the reasoning\nprocess. Moreover, standard metrics like Average Normalized Levenshtein\nSimilarity (ANLS) focus on text accuracy but overlook spatial correctness. We\nintroduce DLaVA, a novel method that enhances Multimodal Large Language Models\n(MLLMs) with answer localization capabilities for Document VQA. Our approach\nintegrates image annotation directly into the MLLM pipeline, improving\ninterpretability by enabling users to trace the model's reasoning. We present\nboth OCR-dependent and OCR-free architectures, with the OCR-free approach\neliminating the need for separate text recognition components, thus reducing\ncomplexity. To the best of our knowledge, DLaVA is the first approach to\nintroduce answer localization within multimodal QA, marking a significant step\nforward in enhancing user trust and reducing the risk of AI hallucinations. Our\ncontributions include enhancing interpretability and reliability by grounding\nresponses in spatially annotated visual content, introducing answer\nlocalization in MLLMs, proposing a streamlined pipeline that combines an MLLM\nwith a text detection module, and conducting comprehensive evaluations using\nboth textual and spatial accuracy metrics, including Intersection over Union\n(IoU). Experimental results on standard datasets demonstrate that DLaVA\nachieves SOTA performance, significantly enhancing model transparency and\nreliability. Our approach sets a new benchmark for Document VQA, highlighting\nthe critical importance of precise answer localization and model\ninterpretability.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.00151v1",
    "published_date": "2024-11-29 06:17:11 UTC",
    "updated_date": "2024-11-29 06:17:11 UTC"
  },
  {
    "arxiv_id": "2411.19488v2",
    "title": "Interleaved-Modal Chain-of-Thought",
    "authors": [
      "Jun Gao",
      "Yongqi Li",
      "Ziqiang Cao",
      "Wenjie Li"
    ],
    "abstract": "Chain-of-Thought (CoT) prompting elicits large language models (LLMs) to\nproduce a series of intermediate reasoning steps before arriving at the final\nanswer. However, when transitioning to vision-language models (VLMs), their\ntext-only rationales struggle to express the fine-grained associations with the\noriginal image. In this paper, we propose an image-incorporated multimodal\nChain-of-Thought, named \\textbf{Interleaved-modal Chain-of-Thought (ICoT)},\nwhich generates sequential reasoning steps consisting of paired visual and\ntextual rationales to infer the final answer. Intuitively, the novel ICoT\nrequires VLMs to enable the generation of fine-grained interleaved-modal\ncontent, which is hard for current VLMs to fulfill. Considering that the\nrequired visual information is usually part of the input image, we propose\n\\textbf{Attention-driven Selection (ADS)} to realize ICoT over existing VLMs.\nADS intelligently inserts regions of the input image to generate the\ninterleaved-modal reasoning steps with ignorable additional latency. ADS relies\nsolely on the attention map of VLMs without the need for parameterization, and\ntherefore it is a plug-and-play strategy that can be generalized to a spectrum\nof VLMs. We apply ADS to realize ICoT on two popular VLMs of different\narchitectures. Extensive evaluations of three benchmarks have shown that ICoT\nprompting achieves substantial performance (up to 14\\%) and interpretability\nimprovements compared to existing multimodal CoT prompting methods.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "CVPR 2025 Main Conference",
    "pdf_url": "http://arxiv.org/pdf/2411.19488v2",
    "published_date": "2024-11-29 06:06:35 UTC",
    "updated_date": "2025-03-17 09:01:38 UTC"
  },
  {
    "arxiv_id": "2412.03594v2",
    "title": "BatchLLM: Optimizing Large Batched LLM Inference with Global Prefix Sharing and Throughput-oriented Token Batching",
    "authors": [
      "Zhen Zheng",
      "Xin Ji",
      "Taosong Fang",
      "Fanghao Zhou",
      "Chuanjie Liu",
      "Gang Peng"
    ],
    "abstract": "Large language models (LLMs) increasingly play an important role in a wide\nrange of information processing and management tasks. Many of these tasks are\nperformed in large batches or even offline, and the performance indictor for\nwhich is throughput. These tasks usually show the characteristic of prefix\nsharing, where different prompt input can partially show the common prefix.\nHowever, the existing LLM inference engines tend to optimize the streaming\nrequests and show limitations of supporting the large batched tasks with the\nprefix sharing characteristic. The existing solutions use the LRU-based cache\nto reuse the KV context of common prefix between requests. The KV context that\nare about to be reused may prematurely evicted with the implicit cache\nmanagement. Besides, the streaming oriented systems do not leverage the\nrequest-batch information and can not mix the decoding tokens with the prefill\nchunks to the best for the batched scenarios, and thus fails to saturate the\nGPU. We propose BatchLLM to address the above problems. BatchLLM explicitly\nidentifies the common prefixes globally. The requests sharing the same prefix\nwill be scheduled together to reuse the KV context the best. BatchLLM reorders\nthe requests and schedules the requests with larger ratio of decoding first to\nbetter mix the decoding tokens with the latter prefill chunks, and applies\nmemory-centric token batching to enlarge the token-batch sizes, which helps to\nincrease the GPU utilization. Finally, BatchLLM optimizes the prefix-shared\nAttention kernel with horizontal fusion to reduce tail effect and kernel launch\noverhead. Extensive evaluation shows that BatchLLM outperforms vLLM and SGLang\nby 1.3$\\times$ to 10.8$\\times$ on a set of microbenchmarks and a typical\nindustry workload under different hardware environments.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.DC",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.03594v2",
    "published_date": "2024-11-29 05:57:37 UTC",
    "updated_date": "2025-01-17 09:37:36 UTC"
  },
  {
    "arxiv_id": "2411.19485v1",
    "title": "Action Engine: An LLM-based Framework for Automatic FaaS Workflow Generation",
    "authors": [
      "Akiharu Esashi",
      "Pawissanutt Lertpongrujikorn",
      "Mohsen Amini Salehi"
    ],
    "abstract": "Function as a Service (FaaS) is poised to become the foundation of the next\ngeneration of cloud systems due to its inherent advantages in scalability,\ncost-efficiency, and ease of use. However, challenges such as the need for\nspecialized knowledge and difficulties in building function workflows persist\nfor cloud-native application developers. To overcome these challenges and\nmitigate the burden of developing FaaS-based applications, in this paper, we\npropose a mechanism called Action Engine, that makes use of Tool-Augmented\nLarge Language Models (LLMs) at its kernel to interpret human language queries\nand automates FaaS workflow generation, thereby, reducing the need for\nspecialized expertise and manual design. Action Engine includes modules to\nidentify relevant functions from the FaaS repository and seamlessly manage the\ndata dependency between them, ensuring that the developer's query is processed\nand resolved. Beyond that, Action Engine can execute the generated workflow by\nfeeding the user-provided parameters. Our evaluations show that Action Engine\ncan generate workflows with up to 20\\% higher correctness without developer\ninvolvement. We notice that Action Engine can unlock FaaS workflow generation\nfor non-cloud-savvy developers and expedite the development cycles of\ncloud-native applications.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.LG",
      "cs.SE"
    ],
    "primary_category": "cs.DC",
    "comment": "Accepted at Utility Cloud Computing (UCC '24) conference",
    "pdf_url": "http://arxiv.org/pdf/2411.19485v1",
    "published_date": "2024-11-29 05:54:41 UTC",
    "updated_date": "2024-11-29 05:54:41 UTC"
  },
  {
    "arxiv_id": "2411.19479v1",
    "title": "FLARE: Towards Universal Dataset Purification against Backdoor Attacks",
    "authors": [
      "Linshan Hou",
      "Wei Luo",
      "Zhongyun Hua",
      "Songhua Chen",
      "Leo Yu Zhang",
      "Yiming Li"
    ],
    "abstract": "Deep neural networks (DNNs) are susceptible to backdoor attacks, where\nadversaries poison datasets with adversary-specified triggers to implant hidden\nbackdoors, enabling malicious manipulation of model predictions. Dataset\npurification serves as a proactive defense by removing malicious training\nsamples to prevent backdoor injection at its source. We first reveal that the\ncurrent advanced purification methods rely on a latent assumption that the\nbackdoor connections between triggers and target labels in backdoor attacks are\nsimpler to learn than the benign features. We demonstrate that this assumption,\nhowever, does not always hold, especially in all-to-all (A2A) and untargeted\n(UT) attacks. As a result, purification methods that analyze the separation\nbetween the poisoned and benign samples in the input-output space or the final\nhidden layer space are less effective. We observe that this separability is not\nconfined to a single layer but varies across different hidden layers. Motivated\nby this understanding, we propose FLARE, a universal purification method to\ncounter various backdoor attacks. FLARE aggregates abnormal activations from\nall hidden layers to construct representations for clustering. To enhance\nseparation, FLARE develops an adaptive subspace selection algorithm to isolate\nthe optimal space for dividing an entire dataset into two clusters. FLARE\nassesses the stability of each cluster and identifies the cluster with higher\nstability as poisoned. Extensive evaluations on benchmark datasets demonstrate\nthe effectiveness of FLARE against 22 representative backdoor attacks,\nincluding all-to-one (A2O), all-to-all (A2A), and untargeted (UT) attacks, and\nits robustness to adaptive attacks.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "13 pages",
    "pdf_url": "http://arxiv.org/pdf/2411.19479v1",
    "published_date": "2024-11-29 05:34:21 UTC",
    "updated_date": "2024-11-29 05:34:21 UTC"
  },
  {
    "arxiv_id": "2411.19477v4",
    "title": "Simple and Provable Scaling Laws for the Test-Time Compute of Large Language Models",
    "authors": [
      "Yanxi Chen",
      "Xuchen Pan",
      "Yaliang Li",
      "Bolin Ding",
      "Jingren Zhou"
    ],
    "abstract": "We propose two simple, principled and practical algorithms that enjoy\nprovable scaling laws for the test-time compute of large language models\n(LLMs). The first one is a two-stage knockout-style algorithm: given an input\nproblem, it first generates multiple candidate solutions, and then aggregate\nthem via a knockout tournament for the final output. Assuming that the LLM can\ngenerate a correct solution with non-zero probability and do better than a\nrandom guess in comparing a pair of correct and incorrect solutions, we prove\ntheoretically that the failure probability of this algorithm decays to zero\nexponentially or by a power law (depending on the specific way of scaling) as\nits test-time compute grows. The second one is a two-stage league-style\nalgorithm, where each candidate is evaluated by its average win rate against\nmultiple opponents, rather than eliminated upon loss to a single opponent.\nUnder analogous but more robust assumptions, we prove that its failure\nprobability also decays to zero exponentially with more test-time compute. Both\nalgorithms require a black-box LLM and nothing else (e.g., no verifier or\nreward model) for a minimalistic implementation, which makes them appealing for\npractical applications and easy to adapt for different tasks. Through extensive\nexperiments with diverse models and datasets, we validate the proposed theories\nand demonstrate the outstanding scaling properties of both algorithms.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.19477v4",
    "published_date": "2024-11-29 05:29:47 UTC",
    "updated_date": "2025-05-19 12:12:00 UTC"
  },
  {
    "arxiv_id": "2411.19475v1",
    "title": "Effective Fine-Tuning of Vision-Language Models for Accurate Galaxy Morphology Analysis",
    "authors": [
      "Ruoqi Wang",
      "Haitao Wang",
      "Qiong Luo"
    ],
    "abstract": "Galaxy morphology analysis involves classifying galaxies by their shapes and\nstructures. For this task, directly training domain-specific models on large,\nannotated astronomical datasets is effective but costly. In contrast,\nfine-tuning vision foundation models on a smaller set of astronomical images is\nmore resource-efficient but generally results in lower accuracy. To harness the\nbenefits of both approaches and address their shortcomings, we propose\nGalaxAlign, a novel method that fine-tunes pre-trained foundation models to\nachieve high accuracy on astronomical tasks. Specifically, our method extends a\ncontrastive learning architecture to align three types of data in fine-tuning:\n(1) a set of schematic symbols representing galaxy shapes and structures, (2)\ntextual labels of these symbols, and (3) galaxy images. This way, GalaxAlign\nnot only eliminates the need for expensive pretraining but also enhances the\neffectiveness of fine-tuning. Extensive experiments on galaxy classification\nand similarity search demonstrate that our method effectively fine-tunes\ngeneral pre-trained models for astronomical tasks by incorporating\ndomain-specific multi-modal knowledge.",
    "categories": [
      "cs.CV",
      "astro-ph.GA",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.19475v1",
    "published_date": "2024-11-29 05:10:47 UTC",
    "updated_date": "2024-11-29 05:10:47 UTC"
  },
  {
    "arxiv_id": "2411.19463v1",
    "title": "Towards Understanding Retrieval Accuracy and Prompt Quality in RAG Systems",
    "authors": [
      "Shengming Zhao",
      "Yuheng Huang",
      "Jiayang Song",
      "Zhijie Wang",
      "Chengcheng Wan",
      "Lei Ma"
    ],
    "abstract": "Retrieval-Augmented Generation (RAG) is a pivotal technique for enhancing the\ncapability of large language models (LLMs) and has demonstrated promising\nefficacy across a diverse spectrum of tasks. While LLM-driven RAG systems show\nsuperior performance, they face unique challenges in stability and reliability.\nTheir complexity hinders developers' efforts to design, maintain, and optimize\neffective RAG systems. Therefore, it is crucial to understand how RAG's\nperformance is impacted by its design. In this work, we conduct an early\nexploratory study toward a better understanding of the mechanism of RAG\nsystems, covering three code datasets, three QA datasets, and two LLMs. We\nfocus on four design factors: retrieval document type, retrieval recall,\ndocument selection, and prompt techniques. Our study uncovers how each factor\nimpacts system correctness and confidence, providing valuable insights for\ndeveloping an accurate and reliable RAG system. Based on these findings, we\npresent nine actionable guidelines for detecting defects and optimizing the\nperformance of RAG systems. We hope our early exploration can inspire further\nadvancements in engineering, improving and maintaining LLM-driven intelligent\nsoftware systems for greater efficiency and reliability.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.19463v1",
    "published_date": "2024-11-29 04:25:31 UTC",
    "updated_date": "2024-11-29 04:25:31 UTC"
  },
  {
    "arxiv_id": "2411.19460v1",
    "title": "Look Every Frame All at Once: Video-Ma$^2$mba for Efficient Long-form Video Understanding with Multi-Axis Gradient Checkpointing",
    "authors": [
      "Hosu Lee",
      "Junho Kim",
      "Hyunjun Kim",
      "Yong Man Ro"
    ],
    "abstract": "With the growing scale and complexity of video data, efficiently processing\nlong video sequences poses significant challenges due to the quadratic increase\nin memory and computational demands associated with existing transformer-based\nLarge Multi-modal Models (LMMs). To address these issues, we introduce\nVideo-Ma$^2$mba, a novel architecture that incorporates State Space Models\n(SSMs) within the Mamba-2 framework, replacing the attention mechanisms. This\nallows the LMMs to scale linearly in terms of time and memory requirements,\nmaking it feasible to handle long-duration video content. Furthermore, we\nenhance the memory efficiency introducing the Multi-Axis Gradient Checkpointing\n(MA-GC) method, which strategically manages memory by retaining only essential\nactivations across multiple computational axes. Our approach significantly\nreduces the memory footprint compared to standard gradient checkpointing.\nEmpirical analyses show that Video-Ma$^2$mba can process extensive video\nsequences-equivalent to millions of tokens or over two hours of continuous\nsequences at 1 FPS-on a single GPU. By maintaining a detailed capture of\ntemporal dynamics, our model improves the accuracy and relevance of responses\nin long video understanding tasks, demonstrating substantial advantages over\nexisting frameworks.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Project page: https://ivy-lvlm.github.io/Video-MA2MBA/",
    "pdf_url": "http://arxiv.org/pdf/2411.19460v1",
    "published_date": "2024-11-29 04:12:13 UTC",
    "updated_date": "2024-11-29 04:12:13 UTC"
  },
  {
    "arxiv_id": "2411.19456v1",
    "title": "Beyond Surface Structure: A Causal Assessment of LLMs' Comprehension Ability",
    "authors": [
      "Yujin Han",
      "Lei Xu",
      "Sirui Chen",
      "Difan Zou",
      "Chaochao Lu"
    ],
    "abstract": "Large language models (LLMs) have shown remarkable capability in natural\nlanguage tasks, yet debate persists on whether they truly comprehend deep\nstructure (i.e., core semantics) or merely rely on surface structure (e.g.,\npresentation format). Prior studies observe that LLMs' performance declines\nwhen intervening on surface structure, arguing their success relies on surface\nstructure recognition. However, surface structure sensitivity does not prevent\ndeep structure comprehension. Rigorously evaluating LLMs' capability requires\nanalyzing both, yet deep structure is often overlooked. To this end, we assess\nLLMs' comprehension ability using causal mediation analysis, aiming to fully\ndiscover the capability of using both deep and surface structures.\nSpecifically, we formulate the comprehension of deep structure as direct causal\neffect (DCE) and that of surface structure as indirect causal effect (ICE),\nrespectively. To address the non-estimability of original DCE and ICE --\nstemming from the infeasibility of isolating mutual influences of deep and\nsurface structures, we develop the corresponding quantifiable surrogates,\nincluding approximated DCE (ADCE) and approximated ICE (AICE). We further apply\nthe ADCE to evaluate a series of mainstream LLMs, showing that most of them\nexhibit deep structure comprehension ability, which grows along with the\nprediction accuracy. Comparing ADCE and AICE demonstrates closed-source LLMs\nrely more on deep structure, while open-source LLMs are more surface-sensitive,\nwhich decreases with model scale. Theoretically, ADCE is a bidirectional\nevaluation, which measures both the sufficiency and necessity of deep structure\nchanges in causing output variations, thus offering a more comprehensive\nassessment than accuracy, a common evaluation in LLMs. Our work provides new\ninsights into LLMs' deep structure comprehension and offers novel methods for\nLLMs evaluation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "28 pages, 14 figures, 10 tables",
    "pdf_url": "http://arxiv.org/pdf/2411.19456v1",
    "published_date": "2024-11-29 03:57:26 UTC",
    "updated_date": "2024-11-29 03:57:26 UTC"
  },
  {
    "arxiv_id": "2411.19451v1",
    "title": "Learning Visual Abstract Reasoning through Dual-Stream Networks",
    "authors": [
      "Kai Zhao",
      "Chang Xu",
      "Bailu Si"
    ],
    "abstract": "Visual abstract reasoning tasks present challenges for deep neural networks,\nexposing limitations in their capabilities. In this work, we present a neural\nnetwork model that addresses the challenges posed by Raven's Progressive\nMatrices (RPM). Inspired by the two-stream hypothesis of visual processing, we\nintroduce the Dual-stream Reasoning Network (DRNet), which utilizes two\nparallel branches to capture image features. On top of the two streams, a\nreasoning module first learns to merge the high-level features of the same\nimage. Then, it employs a rule extractor to handle combinations involving the\neight context images and each candidate image, extracting discrete abstract\nrules and utilizing an multilayer perceptron (MLP) to make predictions.\nEmpirical results demonstrate that the proposed DRNet achieves state-of-the-art\naverage performance across multiple RPM benchmarks. Furthermore, DRNet\ndemonstrates robust generalization capabilities, even extending to various\nout-of-distribution scenarios. The dual streams within DRNet serve distinct\nfunctions by addressing local or spatial information. They are then integrated\ninto the reasoning module, leveraging abstract rules to facilitate the\nexecution of visual reasoning tasks. These findings indicate that the\ndual-stream architecture could play a crucial role in visual abstract\nreasoning.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "10 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.19451v1",
    "published_date": "2024-11-29 03:25:32 UTC",
    "updated_date": "2024-11-29 03:25:32 UTC"
  },
  {
    "arxiv_id": "2411.19447v1",
    "title": "Adaptive Interactive Segmentation for Multimodal Medical Imaging via Selection Engine",
    "authors": [
      "Zhi Li",
      "Kai Zhao",
      "Yaqi Wang",
      "Shuai Wang"
    ],
    "abstract": "In medical image analysis, achieving fast, efficient, and accurate\nsegmentation is essential for automated diagnosis and treatment. Although\nrecent advancements in deep learning have significantly improved segmentation\naccuracy, current models often face challenges in adaptability and\ngeneralization, particularly when processing multi-modal medical imaging data.\nThese limitations stem from the substantial variations between imaging\nmodalities and the inherent complexity of medical data. To address these\nchallenges, we propose the Strategy-driven Interactive Segmentation Model\n(SISeg), built on SAM2, which enhances segmentation performance across various\nmedical imaging modalities by integrating a selection engine. To mitigate\nmemory bottlenecks and optimize prompt frame selection during the inference of\n2D image sequences, we developed an automated system, the Adaptive Frame\nSelection Engine (AFSE). This system dynamically selects the optimal prompt\nframes without requiring extensive prior medical knowledge and enhances the\ninterpretability of the model's inference process through an interactive\nfeedback mechanism. We conducted extensive experiments on 10 datasets covering\n7 representative medical imaging modalities, demonstrating the SISeg model's\nrobust adaptability and generalization in multi-modal tasks. The project page\nand code will be available at: [URL].",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.19447v1",
    "published_date": "2024-11-29 03:08:28 UTC",
    "updated_date": "2024-11-29 03:08:28 UTC"
  },
  {
    "arxiv_id": "2411.19440v1",
    "title": "Gradient Inversion Attack on Graph Neural Networks",
    "authors": [
      "Divya Anand Sinha",
      "Yezi Liu",
      "Ruijie Du",
      "Yanning Shen"
    ],
    "abstract": "Graph federated learning is of essential importance for training over large\ngraph datasets while protecting data privacy, where each client stores a subset\nof local graph data, while the server collects the local gradients and\nbroadcasts only the aggregated gradients. Recent studies reveal that a\nmalicious attacker can steal private image data from gradient exchanging of\nneural networks during federated learning. However, none of the existing works\nhave studied the vulnerability of graph data and graph neural networks under\nsuch attack. To answer this question, the present paper studies the problem of\nwhether private data can be recovered from leaked gradients in both node\nclassification and graph classification tasks and { proposes a novel attack\nnamed Graph Leakage from Gradients (GLG)}. Two widely-used GNN frameworks are\nanalyzed, namely GCN and GraphSAGE. The effects of different model settings on\nrecovery are extensively discussed. Through theoretical analysis and empirical\nvalidation, it is shown that parts of the graph data can be leaked from the\ngradients.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.19440v1",
    "published_date": "2024-11-29 02:42:17 UTC",
    "updated_date": "2024-11-29 02:42:17 UTC"
  },
  {
    "arxiv_id": "2411.19418v2",
    "title": "Proto Successor Measure: Representing the Behavior Space of an RL Agent",
    "authors": [
      "Siddhant Agarwal",
      "Harshit Sikchi",
      "Peter Stone",
      "Amy Zhang"
    ],
    "abstract": "Having explored an environment, intelligent agents should be able to transfer\ntheir knowledge to most downstream tasks within that environment without\nadditional interactions. Referred to as \"zero-shot learning\", this ability\nremains elusive for general-purpose reinforcement learning algorithms. While\nrecent works have attempted to produce zero-shot RL agents, they make\nassumptions about the nature of the tasks or the structure of the MDP. We\npresent Proto Successor Measure: the basis set for all possible behaviors of a\nReinforcement Learning Agent in a dynamical system. We prove that any possible\nbehavior (represented using visitation distributions) can be represented using\nan affine combination of these policy-independent basis functions. Given a\nreward function at test time, we simply need to find the right set of linear\nweights to combine these bases corresponding to the optimal policy. We derive a\npractical algorithm to learn these basis functions using reward-free\ninteraction data from the environment and show that our approach can produce\nthe optimal policy at test time for any given reward function without\nadditional environmental interactions. Project page:\nhttps://agarwalsiddhant10.github.io/projects/psm.html.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Under submission, 20 pages",
    "pdf_url": "http://arxiv.org/pdf/2411.19418v2",
    "published_date": "2024-11-29 00:09:39 UTC",
    "updated_date": "2025-03-11 17:41:54 UTC"
  }
]