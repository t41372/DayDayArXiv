{
  "date": "2024-11-09",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-11-09 的 arXiv 中文 TLDR 快报！今天 arXiv 更新了 45 篇论文，主要聚焦 AI 模型优化（如 LLM 的推理和量化）、多模态学习、医疗图像处理以及自动驾驶风险评估等领域，亮点包括 OpenAI o1 模型的实证分析、LLM 在智能合约漏洞检测中的应用，以及图神经网络的创新框架，这些论文可能引发广泛讨论，尤其在 AI 安全和实际应用方面。\n\n下面，我将挑选最具话题性和影响力的论文优先讨论，按主题归类相关内容，并快速掠过较基础或重复性强的论文（如纯理论优化或小规模实验）。每篇论文会列出标题（中文 + 英文），并简要概述核心贡献和发现，保留关键学术术语。\n\n### AI 和 Large Language Models（LLM）相关\n- **Smart-LLaMA: Two-Stage Post-Training of Large Language Models for Smart Contract Vulnerability Detection and Explanation**（中文：Smart-LLaMA：用于智能合约漏洞检测和解释的大语言模型两阶段后训练）  \n  这篇论文提出 Smart-LLaMA 框架，通过构建数据集和特定训练方法，提升 LLM 在智能合约漏洞检测中的性能，平均 F1 分数提升 6.49%，并提供可靠的解释，帮助开发者快速修复漏洞。\n\n- **IOPO: Empowering LLMs with Complex Instruction Following via Input-Output Preference Optimization**（中文：IOPO：通过输入输出偏好优化增强 LLM 的复杂指令遵循能力）  \n  作者引入 IOPO 方法，考虑输入和输出偏好对，显著提升 LLM 处理复杂指令的能力，在内外域数据集上比 SFT 和 DPO 分别提高 8.15% 和 6.29%，适用于 AI 代理应用。\n\n- **Target-driven Attack for Large Language Models**（中文：针对大语言模型的目标驱动攻击）  \n  这篇扩展了 arXiv:2404.07234 的工作，提出目标驱动黑盒攻击方法，通过最大化 KL 散度优化攻击文本，实验显示在多个 LLM 和数据集上有效，强调了模型鲁棒性的潜在风险。\n\n- **Zyda-2: a 5 Trillion Token High-Quality Dataset**（中文：Zyda-2：一个 5 万亿 token 的高质量数据集）  \n  论文发布 Zyda-2 数据集，用于训练如 Zamba2 系列模型，通过交叉去重和质量过滤提升数据纯度，支持 LLM 预训练的开源应用。\n\n- **OpenAI-o1 AB Testing: Does the o1 model really do good reasoning in math problem solving?**（中文：OpenAI-o1 AB 测试：o1 模型在数学问题求解中是否真正具备良好推理能力？）  \n  作者通过实验比较 IMO 和 CNT 数据集，验证 o1 模型的数学推理能力，发现无明显记忆依赖，强调其在高难度问题上的潜力。\n\n- **Optimizing Large Language Models through Quantization: A Comparative Analysis of PTQ and QAT Techniques**（中文：通过量化优化大语言模型：PTQ 和 QAT 技术的比较分析）  \n  论文比较后训练量化 (PTQ) 和量化感知训练 (QAT)，提出新缩放因子 γ，实现模型大小减小 68% 和计算成本降低 60%，在边设备上提升吞吐量 2.4 倍。\n\n### 医疗和图像处理\n- **NeuReg: Domain-invariant 3D Image Registration on Human and Mouse Brains**（中文：NeuReg：人类和小鼠大脑的领域不变 3D 图像配准）  \n  提出 NeuReg 架构，使用神经启发和 Swin Transformer 捕获跨模态和物种变异，在多领域数据集上超越基线，提升跨域 3D 脑图像配准性能。\n\n- **GuidelineGuard: An Agentic Framework for Medical Note Evaluation with Guideline Adherence**（中文：GuidelineGuard：基于指南遵守的医疗笔记评估代理框架）  \n  这篇论文引入 GuidelineGuard，使用 LLM 分析医疗笔记是否符合 WHO 和 CDC 指南，提供证据建议，减少临床错误。\n\n- **FuzzRisk: Online Collision Risk Estimation for Autonomous Vehicles based on Depth-Aware Object Detection via Fuzzy Inference**（中文：FuzzRisk：基于深度感知对象检测和模糊推理的自动驾驶车辆在线碰撞风险估计）  \n  作者开发 FuzzRisk 框架，通过模糊推理整合深度图和对象检测预测碰撞风险，在 nuScenes 数据集上优化风险指标，提升自动驾驶安全。\n\n### 图学习和多模态模型\n- **GFT: Graph Foundation Model with Transferable Tree Vocabulary**（中文：GFT：具有可转移树词汇的图基础模型）  \n  论文提出 GFT 框架，将计算树作为图学习的转移模式，提升跨任务泛化，在 NeurIPS 接受，实验显示在多样数据集上表现优异。\n\n- **A Comprehensive Survey and Guide to Multimodal Large Language Models in Vision-Language Tasks**（中文：多模态大语言模型在视觉语言任务的全面调查和指南）  \n  这篇综述探讨 MLLM 的架构和应用，覆盖训练方法和伦理问题，提供理论框架和案例分析，适合研究者参考。\n\n- **Multimodal Contrastive Learning of Urban Space Representations from POI Data**（中文：基于 POI 数据的多模态对比学习城市空间表示）  \n  提出 CaLLiPer 模型，通过对比学习从 POI 数据中提取城市语义表示，提升土地利用分类和 socioeconomic 映射的预测性能 5-15%。\n\n### 自动驾驶和强化学习\n- **Optimal Driver Warning Generation in Dynamic Driving Environment**（中文：动态驾驶环境下的最优驾驶员警告生成）  \n  作者将警告生成建模为 POMDP，提出框架优化警告策略，实验显示在 ICRA 2024 数据上优于现有方法，提升驾驶安全。\n\n- **Deep Reinforcement Learning for Digital Twin-Oriented Complex Networked Systems**（中文：面向数字孪生复杂网络系统的深度强化学习）  \n  扩展 DT-CNS 框架，使用强化学习模拟疫情传播，实验表明全合作策略降低感染率，强调节点互动对系统弹性的影响。\n\n其他论文如纯理论的图卷积网络或简单数据集分析（如第16、26、27），由于较少创新或话题度，我将快速掠过，仅提要：这些工作在图学习和导航算法上提供了一些改进，但未见突破性贡献。\n\n总之，今天的 arXiv 更新突显 AI 领域的快速迭代，LLM 优化和实际应用论文值得关注。读者可根据自身兴趣优先查看这些内容，完整论文列表可查 arXiv 官网。明天见！",
  "papers": [
    {
      "arxiv_id": "2411.06315v1",
      "title": "NeuReg: Domain-invariant 3D Image Registration on Human and Mouse Brains",
      "title_zh": "NeuReg：针对人类和鼠标大脑的域不变 3D 图像配准",
      "authors": [
        "Taha Razzaq",
        "Asim Iqbal"
      ],
      "abstract": "Medical brain imaging relies heavily on image registration to accurately\ncurate structural boundaries of brain features for various healthcare\napplications. Deep learning models have shown remarkable performance in image\nregistration in recent years. Still, they often struggle to handle the\ndiversity of 3D brain volumes, challenged by their structural and contrastive\nvariations and their imaging domains. In this work, we present NeuReg, a\nNeuro-inspired 3D image registration architecture with the feature of domain\ninvariance. NeuReg generates domain-agnostic representations of imaging\nfeatures and incorporates a shifting window-based Swin Transformer block as the\nencoder. This enables our model to capture the variations across brain imaging\nmodalities and species. We demonstrate a new benchmark in multi-domain publicly\navailable datasets comprising human and mouse 3D brain volumes. Extensive\nexperiments reveal that our model (NeuReg) outperforms the existing baseline\ndeep learning-based image registration models and provides a high-performance\nboost on cross-domain datasets, where models are trained on 'source-only'\ndomain and tested on completely 'unseen' target domains. Our work establishes a\nnew state-of-the-art for domain-agnostic 3D brain image registration,\nunderpinned by Neuro-inspired Transformer-based architecture.",
      "tldr_zh": "本论文提出 NeuReg，一种受神经启发的域不变 3D 图像注册模型，旨在处理人类和鼠标大脑图像在结构、对比度和成像域方面的多样性。NeuReg 通过生成 domain-agnostic 特征表示并采用 shifting window-based Swin Transformer 块作为编码器，捕捉不同脑部成像模态和物种的变异。在多域公共数据集上的实验表明，NeuReg 优于现有基线深度学习模型，并在跨域测试中显著提升性能，建立新的 state-of-the-art 基准。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.NE",
        "q-bio.QM"
      ],
      "primary_category": "cs.CV",
      "comment": "15 pages, 5 figures, 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2411.06315v1",
      "published_date": "2024-11-09 23:57:53 UTC",
      "updated_date": "2024-11-09 23:57:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:56:11.925879"
    },
    {
      "arxiv_id": "2411.06306v1",
      "title": "Optimal Driver Warning Generation in Dynamic Driving Environment",
      "title_zh": "在动态驾驶环境中最优的驾驶员警告生成",
      "authors": [
        "Chenran Li",
        "Aolin Xu",
        "Enna Sachdeva",
        "Teruhisa Misu",
        "Behzad Dariush"
      ],
      "abstract": "The driver warning system that alerts the human driver about potential risks\nduring driving is a key feature of an advanced driver assistance system.\nExisting driver warning technologies, mainly the forward collision warning and\nunsafe lane change warning, can reduce the risk of collision caused by human\nerrors. However, the current design methods have several major limitations.\nFirstly, the warnings are mainly generated in a one-shot manner without\nmodeling the ego driver's reactions and surrounding objects, which reduces the\nflexibility and generality of the system over different scenarios.\nAdditionally, the triggering conditions of warning are mostly rule-based\nthreshold-checking given the current state, which lacks the prediction of the\npotential risk in a sufficiently long future horizon. In this work, we study\nthe problem of optimally generating driver warnings by considering the\ninteractions among the generated warning, the driver behavior, and the states\nof ego and surrounding vehicles on a long horizon. The warning generation\nproblem is formulated as a partially observed Markov decision process (POMDP).\nAn optimal warning generation framework is proposed as a solution to the\nproposed POMDP. The simulation experiments demonstrate the superiority of the\nproposed solution to the existing warning generation methods.",
      "tldr_zh": "本文研究了在动态驾驶环境中优化驾驶员警告生成的问题，以克服现有系统的局限性，如单次警告生成忽略驾驶员反应和周围物体，以及基于规则阈值检查缺乏长期风险预测。作者将警告生成问题建模为部分可观测Markov决策过程（POMDP），并提出一个优化框架，该框架考虑警告、驾驶员行为以及自我和周围车辆状态的互动。实验结果显示，该方法在模拟环境中显著优于现有技术，提高了系统的灵活性和风险预测能力。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.RO",
      "comment": "ICRA 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.06306v1",
      "published_date": "2024-11-09 23:04:19 UTC",
      "updated_date": "2024-11-09 23:04:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:56:22.733466"
    },
    {
      "arxiv_id": "2411.06295v1",
      "title": "Analyzing the Evolution of Graphs and Texts",
      "title_zh": "分析图和文本的演化",
      "authors": [
        "Xingzhi Guo"
      ],
      "abstract": "With the recent advance of representation learning algorithms on graphs\n(e.g., DeepWalk/GraphSage) and natural languages (e.g., Word2Vec/BERT) , the\nstate-of-the art models can even achieve human-level performance over many\ndownstream tasks, particularly for the task of node and sentence\nclassification. However, most algorithms focus on large-scale models for static\ngraphs and text corpus without considering the inherent dynamic characteristics\nor discovering the reasons behind the changes. This dissertation aims to\nefficiently model the dynamics in graphs (such as social networks and citation\ngraphs) and understand the changes in texts (specifically news titles and\npersonal biographies). To achieve this goal, we utilize the renowned\nPersonalized PageRank algorithm to create effective dynamic network embeddings\nfor evolving graphs. Our proposed approaches significantly improve the running\ntime and accuracy for both detecting network abnormal intruders and discovering\nentity meaning shifts over large-scale dynamic graphs. For text changes, we\nanalyze the post-publication changes in news titles to understand the intents\nbehind the edits and discuss the potential impact of titles changes from\ninformation integrity perspective. Moreover, we investigate self-presented\noccupational identities in Twitter users' biographies over five years,\ninvestigating job prestige and demographics effects in how people disclose\njobs, quantifying over-represented jobs and their transitions over time.",
      "tldr_zh": "本研究分析了图（graphs）和文本的演化，针对现有表示学习算法（如 DeepWalk/GraphSage 和 Word2Vec/BERT）在静态数据上的局限性，提出高效建模动态图（如社交网络和引用图）的方法。利用 Personalized PageRank 算法创建动态网络嵌入，该方法显著提高了检测网络异常入侵者和发现实体意义变化的运行时间和准确性。对于文本变化，该论文探讨了新闻标题的发布后编辑意图及其对信息完整性的潜在影响，并调查了 Twitter 用户在五年内传记中的职业身份变化，包括工作声望、人口统计学因素以及过度代表的工作及其演化趋势。这些贡献为理解动态图和文本提供了新的洞见和实用框架。",
      "categories": [
        "cs.SI",
        "cs.AI"
      ],
      "primary_category": "cs.SI",
      "comment": "PhD dissertation",
      "pdf_url": "http://arxiv.org/pdf/2411.06295v1",
      "published_date": "2024-11-09 21:39:41 UTC",
      "updated_date": "2024-11-09 21:39:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:56:35.187380"
    },
    {
      "arxiv_id": "2411.06284v2",
      "title": "A Comprehensive Survey and Guide to Multimodal Large Language Models in Vision-Language Tasks",
      "title_zh": "多模态大型语言模型在视觉-语言任务中的全面调查和指南",
      "authors": [
        "Chia Xin Liang",
        "Pu Tian",
        "Caitlyn Heqi Yin",
        "Yao Yua",
        "Wei An-Hou",
        "Li Ming",
        "Tianyang Wang",
        "Ziqian Bi",
        "Ming Liu"
      ],
      "abstract": "This survey and application guide to multimodal large language models(MLLMs)\nexplores the rapidly developing field of MLLMs, examining their architectures,\napplications, and impact on AI and Generative Models. Starting with\nfoundational concepts, we delve into how MLLMs integrate various data types,\nincluding text, images, video and audio, to enable complex AI systems for\ncross-modal understanding and generation. It covers essential topics such as\ntraining methods, architectural components, and practical applications in\nvarious fields, from visual storytelling to enhanced accessibility. Through\ndetailed case studies and technical analysis, the text examines prominent MLLM\nimplementations while addressing key challenges in scalability, robustness, and\ncross-modal learning. Concluding with a discussion of ethical considerations,\nresponsible AI development, and future directions, this authoritative resource\nprovides both theoretical frameworks and practical insights. It offers a\nbalanced perspective on the opportunities and challenges in the development and\ndeployment of MLLMs, and is highly valuable for researchers, practitioners, and\nstudents interested in the intersection of natural language processing and\ncomputer vision.",
      "tldr_zh": "这篇论文提供了一个全面的调查和指南，聚焦于多模态大型语言模型 (MLLMs) 在视觉语言任务中的架构、应用及其对 AI 和生成模型的影响。论文探讨了 MLLMs 如何整合文本、图像、视频和音频等数据类型，实现跨模态理解和生成，并涵盖了训练方法、架构组件以及在领域如视觉叙事和增强可访问性的实际应用。作者通过案例研究和技术分析，讨论了关键挑战包括可伸缩性、鲁棒性和跨模态学习，同时强调伦理考虑、负责任的 AI 开发和未来方向，为研究人员、从业者和学生提供宝贵的理论框架和实用见解。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.06284v2",
      "published_date": "2024-11-09 20:56:23 UTC",
      "updated_date": "2024-12-08 06:48:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:56:47.354615"
    },
    {
      "arxiv_id": "2411.06276v2",
      "title": "Multi-View Majority Vote Learning Algorithms: Direct Minimization of PAC-Bayesian Bounds",
      "title_zh": "翻译失败",
      "authors": [
        "Mehdi Hennequin",
        "Abdelkrim Zitouni",
        "Khalid Benabdeslem",
        "Haytham Elghazel",
        "Yacine Gaci"
      ],
      "abstract": "The PAC-Bayesian framework has significantly advanced the understanding of\nstatistical learning, particularly for majority voting methods. Despite its\nsuccesses, its application to multi-view learning -- a setting with multiple\ncomplementary data representations -- remains underexplored. In this work, we\nextend PAC-Bayesian theory to multi-view learning, introducing novel\ngeneralization bounds based on R\\'enyi divergence. These bounds provide an\nalternative to traditional Kullback-Leibler divergence-based counterparts,\nleveraging the flexibility of R\\'enyi divergence. Furthermore, we propose\nfirst- and second-order oracle PAC-Bayesian bounds and extend the C-bound to\nmulti-view settings. To bridge theory and practice, we design efficient\nself-bounding optimization algorithms that align with our theoretical results.",
      "tldr_zh": "本文扩展了PAC-Bayesian框架应用于多视图学习（multi-view learning），引入基于Rényi divergence的新泛化边界，作为传统Kullback-Leibler divergence方法的替代，以提升其灵活性。研究提出了first- and second-order oracle PAC-Bayesian bounds，并将C-bound扩展到多视图设置，提供更强的理论支撑。为将理论转化为实践，作者设计了高效的自界优化算法，这些算法与理论结果一致，有助于改善多视图学习算法的性能和泛化能力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.06276v2",
      "published_date": "2024-11-09 20:25:47 UTC",
      "updated_date": "2025-01-02 23:44:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:56:58.569925"
    },
    {
      "arxiv_id": "2411.08060v2",
      "title": "FuzzRisk: Online Collision Risk Estimation for Autonomous Vehicles based on Depth-Aware Object Detection via Fuzzy Inference",
      "title_zh": "翻译失败",
      "authors": [
        "Brian Hsuan-Cheng Liao",
        "Yingjie Xu",
        "Chih-Hong Cheng",
        "Hasan Esen",
        "Alois Knoll"
      ],
      "abstract": "This paper presents a novel monitoring framework that infers the level of\ncollision risk for autonomous vehicles (AVs) based on their object detection\nperformance. The framework takes two sets of predictions from different\nalgorithms and associates their inconsistencies with the collision risk via\nfuzzy inference. The first set of predictions is obtained by retrieving\nsafety-critical 2.5D objects from a depth map, and the second set comes from\nthe ordinary AV's 3D object detector. We experimentally validate that, based on\nIntersection-over-Union (IoU) and a depth discrepancy measure, the\ninconsistencies between the two sets of predictions strongly correlate to the\nerror of the 3D object detector against ground truths. This correlation allows\nus to construct a fuzzy inference system and map the inconsistency measures to\nan AV collision risk indicator. In particular, we optimize the fuzzy inference\nsystem towards an existing offline metric that matches AV collision rates well.\nLastly, we validate our monitor's capability to produce relevant risk estimates\nwith the large-scale nuScenes dataset and demonstrate that it can safeguard an\nAV in closed-loop simulations.",
      "tldr_zh": "本研究提出FuzzRisk框架，通过模糊推理(Fuzzy Inference)实时估计自动驾驶车辆(AVs)的碰撞风险，基于深度感知对象检测(Depth-Aware Object Detection)分析两个预测集的不一致性。框架使用从深度图中提取的安全关键2.5D对象与普通3D对象检测器的预测进行比较，借助Intersection-over-Union (IoU)和深度差异度量，将不一致性映射为风险指标。实验结果显示，这种相关性有助于优化模糊推理系统，与现有离线指标匹配，并在nuScenes数据集的闭环模拟中验证了框架的有效性，提高了AV的安全性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted by ICRA 2025, 7 pages (IEEE double column format), 5\n  figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2411.08060v2",
      "published_date": "2024-11-09 20:20:36 UTC",
      "updated_date": "2025-02-19 10:49:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:57:11.423749"
    },
    {
      "arxiv_id": "2411.06269v4",
      "title": "AI's Spatial Intelligence: Evaluating AI's Understanding of Spatial Transformations in PSVT:R and Augmented Reality",
      "title_zh": "AI 的空间智能：评估 AI 在 PSVT:R 和增强现实中对空间变换的理解",
      "authors": [
        "Uttamasha Monjoree",
        "Wei Yan"
      ],
      "abstract": "Spatial intelligence is important in Architecture, Construction, Science,\nTechnology, Engineering, and Mathematics (STEM), and Medicine. Understanding\nthree-dimensional (3D) spatial rotations can involve verbal descriptions and\nvisual or interactive examples, illustrating how objects change orientation in\n3D space. Recent studies show Artificial Intelligence (AI) with language and\nvision capabilities still face limitations in spatial reasoning. In this paper,\nwe have studied generative AI's spatial capabilities of understanding rotations\nof objects utilizing its image and language processing features. We examined\nthe spatial intelligence of the GPT-4 model with vision in understanding\nspatial rotation process with diagrams based on the Revised Purdue Spatial\nVisualization Test: Visualization of Rotations (Revised PSVT:R). Next, we\nincorporated a layer of coordinate system axes on Revised PSVT:R to study the\nvariations in GPT-4's performance. We also examined GPT-4's understanding of 3D\nrotations in Augmented Reality (AR) scenes that visualize spatial rotations of\nan object in 3D space and observed increased accuracy of GPT-4's understanding\nof the rotations by adding supplementary textual information depicting the\nrotation process or mathematical representations of the rotation (e.g.,\nmatrices). The results indicate that while GPT-4 as a major current Generative\nAI model lacks the understanding of a spatial rotation process, it has the\npotential to understand the rotation process with additional information that\ncan be provided by methods such as AR. By combining the potentials in spatial\nintelligence of AI with AR's interactive visualization abilities, we expect to\noffer enhanced guidance for students' spatial learning activities. Such spatial\nguidance can benefit understanding spatial transformations and additionally\nsupport processes like assembly, fabrication, and manufacturing.",
      "tldr_zh": "本研究评估了人工智能（AI）在空间智能方面的能力，特别是GPT-4模型理解三维（3D）空间旋转的性能，使用Revised PSVT:R测试作为基准。研究方法包括在测试中添加坐标系统轴，并整合Augmented Reality（AR）场景，以观察额外文本信息（如旋转过程描述或数学矩阵）对GPT-4准确率的影响。结果显示，GPT-4在空间旋转理解上存在局限，但通过补充信息可显著提升性能；未来，通过结合AI的空间智能与AR的交互可视化，可为学生的空间学习提供更有效的指导，支持领域如工程和制造的应用。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.06269v4",
      "published_date": "2024-11-09 19:53:15 UTC",
      "updated_date": "2025-03-16 03:24:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:57:23.319195"
    },
    {
      "arxiv_id": "2411.06264v1",
      "title": "GuidelineGuard: An Agentic Framework for Medical Note Evaluation with Guideline Adherence",
      "title_zh": "GuidelineGuard：一种智能体框架，用于医疗笔记评估以确保指南遵守",
      "authors": [
        "MD Ragib Shahriyear"
      ],
      "abstract": "Although rapid advancements in Large Language Models (LLMs) are facilitating\nthe integration of artificial intelligence-based applications and services in\nhealthcare, limited research has focused on the systematic evaluation of\nmedical notes for guideline adherence. This paper introduces GuidelineGuard, an\nagentic framework powered by LLMs that autonomously analyzes medical notes,\nsuch as hospital discharge and office visit notes, to ensure compliance with\nestablished healthcare guidelines. By identifying deviations from recommended\npractices and providing evidence-based suggestions, GuidelineGuard helps\nclinicians adhere to the latest standards from organizations like the WHO and\nCDC. This framework offers a novel approach to improving documentation quality\nand reducing clinical errors.",
      "tldr_zh": "本论文引入 GuidelineGuard，这是一个基于 Large Language Models (LLMs) 的代理框架，用于自主分析医疗笔记（如出院和门诊笔记），以确保遵守医疗指南。该框架通过识别偏离推荐实践并提供基于证据的建议，帮助临床医生遵循 WHO 和 CDC 等组织的标准。GuidelineGuard 提供了一种创新方法，提高了文档质量并减少了临床错误。",
      "categories": [
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.06264v1",
      "published_date": "2024-11-09 19:32:26 UTC",
      "updated_date": "2024-11-09 19:32:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:57:35.107680"
    },
    {
      "arxiv_id": "2411.06263v1",
      "title": "Federated Split Learning for Human Activity Recognition with Differential Privacy",
      "title_zh": "翻译失败",
      "authors": [
        "Josue Ndeko",
        "Shaba Shaon",
        "Aubrey Beal",
        "Avimanyu Sahoo",
        "Dinh C. Nguyen"
      ],
      "abstract": "This paper proposes a novel intelligent human activity recognition (HAR)\nframework based on a new design of Federated Split Learning (FSL) with\nDifferential Privacy (DP) over edge networks. Our FSL-DP framework leverages\nboth accelerometer and gyroscope data, achieving significant improvements in\nHAR accuracy. The evaluation includes a detailed comparison between traditional\nFederated Learning (FL) and our FSL framework, showing that the FSL framework\noutperforms FL models in both accuracy and loss metrics. Additionally, we\nexamine the privacy-performance trade-off under different data settings in the\nDP mechanism, highlighting the balance between privacy guarantees and model\naccuracy. The results also indicate that our FSL framework achieves faster\ncommunication times per training round compared to traditional FL, further\nemphasizing its efficiency and effectiveness. This work provides valuable\ninsight and a novel framework which was tested on a real-life dataset.",
      "tldr_zh": "该论文提出了一种基于 Federated Split Learning (FSL) 与 Differential Privacy (DP) 的新型智能人类活动识别 (HAR) 框架，利用加速度计和陀螺仪数据显著提升识别准确性。相比传统 Federated Learning (FL)，FSL 框架在准确性和损失指标上表现出色，同时实现了更快的通信时间，并探讨了 DP 机制下隐私保护与模型性能的权衡。实验结果基于真实数据集验证，提供了高效且隐私友好的 HAR 解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to IEEE Consumer Communications and Networking Conference\n  (CCNC), 6 pages",
      "pdf_url": "http://arxiv.org/pdf/2411.06263v1",
      "published_date": "2024-11-09 19:32:23 UTC",
      "updated_date": "2024-11-09 19:32:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:57:46.918752"
    },
    {
      "arxiv_id": "2411.07269v1",
      "title": "Learning From Graph-Structured Data: Addressing Design Issues and Exploring Practical Applications in Graph Representation Learning",
      "title_zh": "从图结构化数据中学习：解决设计问题并探索图表示学习中的实际应用",
      "authors": [
        "Chenqing Hua"
      ],
      "abstract": "Graphs serve as fundamental descriptors for systems composed of interacting\nelements, capturing a wide array of data types, from molecular interactions to\nsocial networks and knowledge graphs. In this paper, we present an exhaustive\nreview of the latest advancements in graph representation learning and Graph\nNeural Networks (GNNs). GNNs, tailored to handle graph-structured data, excel\nin deriving insights and predictions from intricate relational information,\nmaking them invaluable for tasks involving such data. Graph representation\nlearning, a pivotal approach in analyzing graph-structured data, facilitates\nnumerous downstream tasks and applications across machine learning, data\nmining, biomedicine, and healthcare.\n  Our work delves into the capabilities of GNNs, examining their foundational\ndesigns and their application in addressing real-world challenges. We introduce\na GNN equipped with an advanced high-order pooling function, adept at capturing\ncomplex node interactions within graph-structured data. This pooling function\nsignificantly enhances the GNN's efficacy in both node- and graph-level tasks.\nAdditionally, we propose a molecular graph generative model with a GNN as its\ncore framework. This GNN backbone is proficient in learning invariant and\nequivariant molecular characteristics. Employing these features, the molecular\ngraph generative model is capable of simultaneously learning and generating\nmolecular graphs with atom-bond structures and precise atom positions. Our\nmodels undergo thorough experimental evaluations and comparisons with\nestablished methods, showcasing their superior performance in addressing\ndiverse real-world challenges with various datasets.",
      "tldr_zh": "这篇论文回顾了图表示学习和Graph Neural Networks (GNNs) 的最新进展，强调GNNs 在处理图结构数据方面的优势，并探讨其在机器学习、数据挖掘、生物医学和医疗领域的实际应用。作者提出了一种配备高级高阶池化函数的GNN 模型，能够有效捕捉复杂节点交互，从而提升节点级和图级任务的性能。此外，他们开发了一个以GNN 为核心的分子图生成模型，能学习并生成具有原子键结构和精确原子位置的分子图；实验结果显示，该模型在多种数据集上优于现有方法，展示了其在真实世界挑战中的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "arXiv admin note: text overlap with arXiv:2205.11691,\n  arXiv:2304.14621",
      "pdf_url": "http://arxiv.org/pdf/2411.07269v1",
      "published_date": "2024-11-09 19:10:33 UTC",
      "updated_date": "2024-11-09 19:10:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:57:58.668867"
    },
    {
      "arxiv_id": "2411.06253v1",
      "title": "Knowledge Authoring with Factual English, Rules, and Actions",
      "title_zh": "使用",
      "authors": [
        "Yuheng Wang"
      ],
      "abstract": "Knowledge representation and reasoning systems represent knowledge as\ncollections of facts and rules. KRRs can represent complex concepts and\nrelations, and they can query and manipulate information in sophisticated ways.\nUnfortunately, the KRR technology has been hindered by the fact that specifying\nthe requisite knowledge requires skills that most domain experts do not have,\nand professional knowledge engineers are hard to find. Some recent CNL-based\napproaches, such as the Knowledge Authoring Logic Machine (KALM), have shown to\nhave very high accuracy compared to others, and a natural question is to what\nextent the CNL restrictions can be lifted. Besides the CNL restrictions, KALM\nhas limitations in terms of the types of knowledge it can represent. To address\nthese issues, we propose an extension of KALM called KALM for Factual Language\n(KALMF). KALMF uses a neural parser for natural language, MS, to parse what we\ncall factual English sentences, which require little grammar training to use.\nBuilding upon KALMF, we propose KALM for Rules and Actions (KALMR), to\nrepresent and reason with rules and actions. Furthermore, we identify the\nreasons behind the slow speed of KALM and make optimizations to address this\nissue. Our evaluation using multiple benchmarks shows that our approaches\nachieve a high level of correctness on fact and query authoring (95%) and on\nrule authoring (100%). When used for authoring and reasoning with actions, our\napproach achieves more than 99.3% correctness, demonstrating its effectiveness\nin enabling more sophisticated knowledge representation and reasoning. We also\nillustrate the logical reasoning capabilities of our approach by drawing\nattention to the problems faced by the famous AI, ChatGPT. Finally, the\nevaluation of the newly proposed speed optimization points not only to a 68%\nruntime improvement but also yields better accuracy of the overall system.",
      "tldr_zh": "该论文针对知识表示和推理系统(KRRs)的知识指定难题，提出扩展Knowledge Authoring Logic Machine (KALM)的方法，以简化非专业人士的参与。研究者开发了KALMF，使用神经解析器解析factual English句子，减少语法训练需求，并进一步扩展到KALMR，以支持规则和动作的表示与推理。实验结果显示，KALMF在事实和查询创作上达到95%正确率，KALMR在规则创作上达100%、在动作推理上超过99.3%，同时通过速度优化实现了68%的运行时改进和整体准确性提升。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "PhD thesis",
      "pdf_url": "http://arxiv.org/pdf/2411.06253v1",
      "published_date": "2024-11-09 19:01:34 UTC",
      "updated_date": "2024-11-09 19:01:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:58:12.154401"
    },
    {
      "arxiv_id": "2411.06251v2",
      "title": "Quasi-random Multi-Sample Inference for Large Language Models",
      "title_zh": "针对大型语言模型的准随机多样本推理",
      "authors": [
        "Aditya Parashar",
        "Aditya Vikram Singh",
        "Avinash Amballa",
        "Jinlin Lai",
        "Benjamin Rozonoyer"
      ],
      "abstract": "Large language models (LLMs) are often equipped with multi-sample decoding\nstrategies. An LLM implicitly defines an arithmetic code book, facilitating\nefficient and embarrassingly parallelizable \\textbf{arithmetic sampling} to\nproduce multiple samples using quasi-random codes. Traditional text generation\nmethods, such as beam search and sampling-based techniques, have notable\nlimitations: they lack parallelizability or diversity of sampled sequences.\nThis study explores the potential of arithmetic sampling, contrasting it with\nancestral sampling across two decoding tasks that employ multi-sample\ninference: chain-of-thought reasoning with self-consistency and machine\ntranslation with minimum Bayes risk decoding. Our results demonstrate that\narithmetic sampling produces more diverse samples, significantly improving\nreasoning and translation performance as the sample size increases. We observe\na $\\mathbf{3\\text{-}5\\%}$ point increase in accuracy on the GSM8K dataset and a\n$\\mathbf{0.45\\text{-}0.89\\%}$ point increment in COMET score for WMT19 tasks\nusing arithmetic sampling without any significant computational overhead.",
      "tldr_zh": "本研究提出了一种基于 quasi-random codes 的 arithmetic sampling 方法，用于大型语言模型 (LLMs) 的多样本推断，与传统方法如 beam search 和 ancestral sampling 相比，它提高了样本多样性并支持高效并行化。研究在 chain-of-thought reasoning with self-consistency 和 machine translation with minimum Bayes risk decoding 等任务上进行了对比实验，结果显示 arithmetic sampling 显著提升了性能：在 GSM8K 数据集上准确率提高了 3-5%，而在 WMT19 任务上 COMET 分数提升了 0.45-0.89%，且无需额外计算开销。该方法为改进 LLMs 的多样本推断提供了高效且可靠的途径。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.06251v2",
      "published_date": "2024-11-09 18:55:04 UTC",
      "updated_date": "2025-04-27 21:28:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:58:23.709506"
    },
    {
      "arxiv_id": "2411.06229v1",
      "title": "Multimodal Contrastive Learning of Urban Space Representations from POI Data",
      "title_zh": "翻译失败",
      "authors": [
        "Xinglei Wang",
        "Tao Cheng",
        "Stephen Law",
        "Zichao Zeng",
        "Lu Yin",
        "Junyuan Liu"
      ],
      "abstract": "Existing methods for learning urban space representations from\nPoint-of-Interest (POI) data face several limitations, including issues with\ngeographical delineation, inadequate spatial information modelling,\nunderutilisation of POI semantic attributes, and computational inefficiencies.\nTo address these issues, we propose CaLLiPer (Contrastive Language-Location\nPre-training), a novel representation learning model that directly embeds\ncontinuous urban spaces into vector representations that can capture the\nspatial and semantic distribution of urban environment. This model leverages a\nmultimodal contrastive learning objective, aligning location embeddings with\ntextual POI descriptions, thereby bypassing the need for complex training\ncorpus construction and negative sampling. We validate CaLLiPer's effectiveness\nby applying it to learning urban space representations in London, UK, where it\ndemonstrates 5-15% improvement in predictive performance for land use\nclassification and socioeconomic mapping tasks compared to state-of-the-art\nmethods. Visualisations of the learned representations further illustrate our\nmodel's advantages in capturing spatial variations in urban semantics with high\naccuracy and fine resolution. Additionally, CaLLiPer achieves reduced training\ntime, showcasing its efficiency and scalability. This work provides a promising\npathway for scalable, semantically rich urban space representation learning\nthat can support the development of geospatial foundation models. The\nimplementation code is available at https://github.com/xlwang233/CaLLiPer.",
      "tldr_zh": "现有方法在从 POI 数据学习城市空间表示时，面临地理划分、空间信息建模不足、POI 语义属性利用不充分以及计算效率低等问题。研究提出 CaLLiPer（Contrastive Language-Location Pre-training）模型，通过多模态对比学习（Multimodal Contrastive Learning）目标，将位置嵌入与 POI 的文本描述对齐，从而直接嵌入连续城市空间并捕捉其空间和语义分布，避免了复杂训练语料构建和负采样。实验在伦敦城市数据上验证了该模型，在土地利用分类和经济社会映射任务中比现有方法提高了 5-15% 的预测性能，并展示了高准确性和精细分辨率的视觉化优势。此外，CaLLiPer 显著减少了训练时间，提升了效率和可扩展性，为开发地理空间基础模型提供了可扩展的语义丰富路径。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "19 pages, 5 figures, 7 tables",
      "pdf_url": "http://arxiv.org/pdf/2411.06229v1",
      "published_date": "2024-11-09 16:24:07 UTC",
      "updated_date": "2024-11-09 16:24:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:58:36.106116"
    },
    {
      "arxiv_id": "2411.07268v2",
      "title": "Target-driven Attack for Large Language Models",
      "title_zh": "针对大型语言模型的目标驱动攻击",
      "authors": [
        "Chong Zhang",
        "Mingyu Jin",
        "Dong Shu",
        "Taowen Wang",
        "Dongfang Liu",
        "Xiaobo Jin"
      ],
      "abstract": "Current large language models (LLM) provide a strong foundation for\nlarge-scale user-oriented natural language tasks. Many users can easily inject\nadversarial text or instructions through the user interface, thus causing LLM\nmodel security challenges like the language model not giving the correct\nanswer. Although there is currently a large amount of research on black-box\nattacks, most of these black-box attacks use random and heuristic strategies.\nIt is unclear how these strategies relate to the success rate of attacks and\nthus effectively improve model robustness. To solve this problem, we propose\nour target-driven black-box attack method to maximize the KL divergence between\nthe conditional probabilities of the clean text and the attack text to redefine\nthe attack's goal. We transform the distance maximization problem into two\nconvex optimization problems based on the attack goal to solve the attack text\nand estimate the covariance. Furthermore, the projected gradient descent\nalgorithm solves the vector corresponding to the attack text. Our target-driven\nblack-box attack approach includes two attack strategies: token manipulation\nand misinformation attack. Experimental results on multiple Large Language\nModels and datasets demonstrate the effectiveness of our attack method.",
      "tldr_zh": "本研究针对大型语言模型（LLM）的安全挑战，提出了一种目标驱动黑盒攻击方法，通过最大化干净文本和攻击文本的条件概率之间的 KL divergence 来重新定义攻击目标。方法将距离最大化问题转化为两个凸优化问题，并使用投影梯度下降（projected gradient descent）算法求解攻击文本对应的向量，同时包括 token manipulation 和 misinformation attack 两种策略。实验结果显示，该方法在多个 LLM 和数据集上表现出色，有效提升了攻击成功率，并为改善模型鲁棒性提供了新见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "12 pages, 7 figures. This work is an extension of the\n  arXiv:2404.07234 work. We propose new methods. 27th European Conference on\n  Artificial Intelligence 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.07268v2",
      "published_date": "2024-11-09 15:59:59 UTC",
      "updated_date": "2024-11-13 11:28:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:58:47.493078"
    },
    {
      "arxiv_id": "2411.06221v1",
      "title": "Smart-LLaMA: Two-Stage Post-Training of Large Language Models for Smart Contract Vulnerability Detection and Explanation",
      "title_zh": "Smart-LLaMA：大型语言模型的两阶段后训练，用于智能合约漏洞检测和解释",
      "authors": [
        "Lei Yu",
        "Shiqi Chen",
        "Hang Yuan",
        "Peng Wang",
        "Zhirong Huang",
        "Jingyuan Zhang",
        "Chenjie Shen",
        "Fengjun Zhang",
        "Li Yang",
        "Jiajia Ma"
      ],
      "abstract": "With the rapid development of blockchain technology, smart contract security\nhas become a critical challenge. Existing smart contract vulnerability\ndetection methods face three main issues: (1) Insufficient quality of datasets,\nlacking detailed explanations and precise vulnerability locations. (2) Limited\nadaptability of large language models (LLMs) to the smart contract domain, as\nmost LLMs are pre-trained on general text data but minimal smart\ncontract-specific data. (3) Lack of high-quality explanations for detected\nvulnerabilities, as existing methods focus solely on detection without clear\nexplanations. These limitations hinder detection performance and make it harder\nfor developers to understand and fix vulnerabilities quickly, potentially\nleading to severe financial losses. To address these problems, we propose\nSmart-LLaMA, an advanced detection method based on the LLaMA language model.\nFirst, we construct a comprehensive dataset covering four vulnerability types\nwith labels, detailed explanations, and precise vulnerability locations.\nSecond, we introduce Smart Contract-Specific Continual Pre-Training, using raw\nsmart contract data to enable the LLM to learn smart contract syntax and\nsemantics, enhancing their domain adaptability. Furthermore, we propose\nExplanation-Guided Fine-Tuning, which fine-tunes the LLM using paired\nvulnerable code and explanations, enabling both vulnerability detection and\nreasoned explanations. We evaluate explanation quality through LLM and human\nevaluation, focusing on Correctness, Completeness, and Conciseness.\nExperimental results show that Smart-LLaMA outperforms state-of-the-art\nbaselines, with average improvements of 6.49% in F1 score and 3.78% in\naccuracy, while providing reliable explanations.",
      "tldr_zh": "该研究针对智能合约安全挑战，提出Smart-LLaMA，一种基于LLaMA的大型语言模型(Large Language Models, LLMs)的两阶段后训练方法，以解决数据集质量不足、LLMs领域适应性差以及漏洞解释缺失的问题。首先，构建一个覆盖四种漏洞类型的数据集，包括标签、详细解释和精确漏洞位置；其次，通过Smart Contract-Specific Continual Pre-Training使用原始智能合约数据增强模型的语法和语义理解，并采用Explanation-Guided Fine-Tuning对配对的漏洞代码和解释进行微调，实现漏洞检测和高质量解释。实验结果显示，Smart-LLaMA在F1 score上平均提高6.49%、准确率提高3.78%，并在Correctness、Completeness和Conciseness方面表现出色，提供可靠的漏洞解释。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.06221v1",
      "published_date": "2024-11-09 15:49:42 UTC",
      "updated_date": "2024-11-09 15:49:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:59:00.790021"
    },
    {
      "arxiv_id": "2411.06212v1",
      "title": "Multistage non-deterministic classification using secondary concept graphs and graph convolutional networks for high-level feature extraction",
      "title_zh": "翻译失败",
      "authors": [
        "Masoud Kargar",
        "Nasim Jelodari",
        "Alireza Assadzadeh"
      ],
      "abstract": "Graphs, comprising nodes and edges, visually depict relationships and\nstructures, posing challenges in extracting high-level features due to their\nintricate connections. Multiple connections introduce complexities in\ndiscovering patterns, where node weights may affect some features more than\nothers. In domains with diverse topics, graph representations illustrate\ninterrelations among features. Pattern discovery within graphs is recognized as\nNP-hard. Graph Convolutional Networks (GCNs) are a prominent deep learning\napproach for acquiring meaningful representations by leveraging node\nconnectivity and characteristics. Despite achievements, predicting and\nassigning 9 deterministic classes often involves errors. To address this\nchallenge, we present a multi-stage non-deterministic classification method\nbased on a secondary conceptual graph and graph convolutional networks, which\nincludes distinct steps: 1) leveraging GCN for the extraction and generation of\n12 high-level features: 2) employing incomplete, non-deterministic models for\nfeature extraction, conducted before reaching a definitive prediction: and 3)\nformulating definitive forecasts grounded in conceptual (logical) graphs. The\nempirical findings indicate that our proposed approach outperforms contemporary\nmethods in classification tasks. Across three datasets Cora, Citeseer, and\nPubMed the achieved accuracies are 96%, 93%, and 95%, respectively. Code is\navailable at https://github.com/MasoudKargar.",
      "tldr_zh": "这篇论文提出了一种多阶段非确定性分类方法，利用secondary concept graphs和Graph Convolutional Networks (GCNs)来提取图结构中的高水平特征，解决图复杂连接导致的模式发现挑战。方法包括三个关键步骤：首先使用GCNs提取和生成12个高水平特征；其次采用不完整的非确定性模型进行特征提取，以避免直接预测错误；最后基于概念（逻辑）图制定最终预测。实验结果显示，该方法在Cora、Citeseer和PubMed数据集上分别实现了96%、93%和95%的准确率，优于现有方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "13 Pages, 15 figures, and 4 Tables",
      "pdf_url": "http://arxiv.org/pdf/2411.06212v1",
      "published_date": "2024-11-09 15:28:45 UTC",
      "updated_date": "2024-11-09 15:28:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:59:11.586006"
    },
    {
      "arxiv_id": "2411.06211v1",
      "title": "Artificial Intelligence for Collective Intelligence: A National-Scale Research Strategy",
      "title_zh": "翻译失败",
      "authors": [
        "Seth Bullock",
        "Nirav Ajmeri",
        "Mike Batty",
        "Michaela Black",
        "John Cartlidge",
        "Robert Challen",
        "Cangxiong Chen",
        "Jing Chen",
        "Joan Condell",
        "Leon Danon",
        "Adam Dennett",
        "Alison Heppenstall",
        "Paul Marshall",
        "Phil Morgan",
        "Aisling O'Kane",
        "Laura G. E. Smith",
        "Theresa Smith",
        "Hywel T. P. Williams"
      ],
      "abstract": "Advances in artificial intelligence (AI) have great potential to help address\nsocietal challenges that are both collective in nature and present at national\nor trans-national scale. Pressing challenges in healthcare, finance,\ninfrastructure and sustainability, for instance, might all be productively\naddressed by leveraging and amplifying AI for national-scale collective\nintelligence. The development and deployment of this kind of AI faces\ndistinctive challenges, both technical and socio-technical. Here, a research\nstrategy for mobilising inter-disciplinary research to address these challenges\nis detailed and some of the key issues that must be faced are outlined.",
      "tldr_zh": "本论文探讨了人工智能（AI）在解决国家或跨国家规模的集体性社会挑战（如医疗、金融、基础设施和可持续性）方面的潜力，强调AI可以通过放大集体智能来有效应对这些问题。论文提出一个国家规模的研究策略，旨在动员跨学科研究来处理AI的开发和部署中遇到的技术和社会技术挑战。总体而言，该策略概述了关键问题，并为实现AI驱动的集体智能提供了一个框架。",
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "25 pages, 3 figures, Accepted for publication at Knowledge\n  Engineering Review (KER)",
      "pdf_url": "http://arxiv.org/pdf/2411.06211v1",
      "published_date": "2024-11-09 15:25:43 UTC",
      "updated_date": "2024-11-09 15:25:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:59:21.502239"
    },
    {
      "arxiv_id": "2411.06208v2",
      "title": "IOPO: Empowering LLMs with Complex Instruction Following via Input-Output Preference Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Xinghua Zhang",
        "Haiyang Yu",
        "Cheng Fu",
        "Fei Huang",
        "Yongbin Li"
      ],
      "abstract": "In the realm of large language models (LLMs), the ability of models to\naccurately follow instructions is paramount as more agents and applications\nleverage LLMs for construction, where the complexity of instructions are\nrapidly increasing. However, on the one hand, there is only a certain amount of\ncomplex instruction evaluation data; on the other hand, there are no dedicated\nalgorithms to improve the ability to follow complex instructions. To this end,\nthis paper introduces TRACE, a benchmark for improving and evaluating the\ncomplex instructionfollowing ability, which consists of 120K training data and\n1K evaluation data. Furthermore, we propose IOPO (Input-Output Preference\nOptimization) alignment method which takes both input and output preference\npairs into consideration, where LLMs not only rapidly align with response\npreferences but also meticulously explore the instruction preferences.\nExtensive experiments on both in-domain and outof-domain datasets confirm the\neffectiveness of IOPO, showing 8.15%, 2.18% improvements on in-domain data and\n6.29%, 3.13% on outof-domain data compared to SFT and DPO respectively.",
      "tldr_zh": "该论文强调了大型语言模型（LLMs）在遵循复杂指令方面的关键挑战，尤其是在指令复杂度不断增加的背景下。研究者引入了TRACE基准，包括120K训练数据和1K评估数据，用于评估和改进LLMs的复杂指令遵循能力；同时提出IOPO（Input-Output Preference Optimization）方法，该方法通过考虑输入和输出偏好对，使模型不仅快速对齐响应偏好，还能探索指令偏好。实验结果显示，IOPO在领域内数据集上比SFT和DPO分别提高了8.15%和2.18%，而在领域外数据集上提高了6.29%和3.13%，证明了其有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Work in progress",
      "pdf_url": "http://arxiv.org/pdf/2411.06208v2",
      "published_date": "2024-11-09 15:12:43 UTC",
      "updated_date": "2024-11-27 07:29:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:59:35.155811"
    },
    {
      "arxiv_id": "2411.07267v1",
      "title": "A Survey on Data Markets",
      "title_zh": "数据市场的综述",
      "authors": [
        "Jiayao Zhang",
        "Yuran Bi",
        "Mengye Cheng",
        "Jinfei Liu",
        "Kui Ren",
        "Qiheng Sun",
        "Yihang Wu",
        "Yang Cao",
        "Raul Castro Fernandez",
        "Haifeng Xu",
        "Ruoxi Jia",
        "Yongchan Kwon",
        "Jian Pei",
        "Jiachen T. Wang",
        "Haocheng Xia",
        "Li Xiong",
        "Xiaohui Yu",
        "James Zou"
      ],
      "abstract": "Data is the new oil of the 21st century. The growing trend of trading data\nfor greater welfare has led to the emergence of data markets. A data market is\nany mechanism whereby the exchange of data products including datasets and data\nderivatives takes place as a result of data buyers and data sellers being in\ncontact with one another, either directly or through mediating agents. It\nserves as a coordinating mechanism by which several functions, including the\npricing and the distribution of data as the most important ones, interact to\nmake the value of data fully exploited and enhanced. In this article, we\npresent a comprehensive survey of this important and emerging direction from\nthe aspects of data search, data productization, data transaction, data\npricing, revenue allocation as well as privacy, security, and trust issues. We\nalso investigate the government policies and industry status of data markets\nacross different countries and different domains. Finally, we identify the\nunresolved challenges and discuss possible future directions for the\ndevelopment of data markets.",
      "tldr_zh": "本调查探讨了数据 markets 的兴起及其重要性，将数据比作21世纪的新石油，并定义为数据买家和卖家通过直接或中介交换数据产品（如数据集和数据衍生品）的机制。文章从数据 search、数据 productization、数据 transaction、数据 pricing 和收入 allocation 等方面进行全面分析，同时考察了隐私、安全和信任问题，以及不同国家和领域的政府政策和行业现状。最后，论文识别了未解决的挑战，并讨论了数据 markets 的未来发展方向，以最大化数据价值。",
      "categories": [
        "cs.GT",
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.GT",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.07267v1",
      "published_date": "2024-11-09 15:09:24 UTC",
      "updated_date": "2024-11-09 15:09:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:59:47.363719"
    },
    {
      "arxiv_id": "2411.06198v1",
      "title": "OpenAI-o1 AB Testing: Does the o1 model really do good reasoning in math problem solving?",
      "title_zh": "翻译失败",
      "authors": [
        "Leo Li",
        "Ye Luo",
        "Tingyou Pan"
      ],
      "abstract": "The Orion-1 model by OpenAI is claimed to have more robust logical reasoning\ncapabilities than previous large language models. However, some suggest the\nexcellence might be partially due to the model \"memorizing\" solutions,\nresulting in less satisfactory performance when prompted with problems not in\nthe training data. We conduct a comparison experiment using two datasets: one\nconsisting of International Mathematics Olympiad (IMO) problems, which is\neasily accessible; the other one consisting of Chinese National Team Training\ncamp (CNT) problems, which have similar difficulty but not as publically\naccessible. We label the response for each problem and compare the performance\nbetween the two datasets. We conclude that there is no significant evidence to\nshow that the model relies on memorizing problems and solutions. Also, we\nperform case studies to analyze some features of the model's response.",
      "tldr_zh": "这篇论文通过 A/B Testing 评估了 OpenAI 的 Orion-1 模型在数学问题求解中的推理能力，针对其是否依赖于记忆解决方案进行检验。研究者使用两个数据集进行比较：一个是容易获取的 International Mathematics Olympiad (IMO) 问题，另一个是难度类似但不公开的 Chinese National Team Training camp (CNT) 问题，并对每个问题的响应进行标记和分析。结果显示，没有显著证据表明模型依赖于记忆解决方案；此外，论文还通过案例研究探讨了模型响应的一些特征。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.06198v1",
      "published_date": "2024-11-09 14:47:52 UTC",
      "updated_date": "2024-11-09 14:47:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T22:59:59.121648"
    },
    {
      "arxiv_id": "2411.06191v1",
      "title": "Generalizing Hyperedge Expansion for Hyper-relational Knowledge Graph Modeling",
      "title_zh": "翻译失败",
      "authors": [
        "Yu Liu",
        "Shu Yang",
        "Jingtao Ding",
        "Quanming Yao",
        "Yong Li"
      ],
      "abstract": "By representing knowledge in a primary triple associated with additional\nattribute-value qualifiers, hyper-relational knowledge graph (HKG) that\ngeneralizes triple-based knowledge graph (KG) has been attracting research\nattention recently. Compared with KG, HKG is enriched with the semantic\nqualifiers as well as the hyper-relational graph structure. However, to model\nHKG, existing studies mainly focus on either semantic information or structural\ninformation therein, which however fail to capture both simultaneously. To\ntackle this issue, in this paper, we generalize the hyperedge expansion in\nhypergraph learning and propose an equivalent transformation for HKG modeling,\nreferred to as TransEQ. Specifically, the equivalent transformation transforms\na HKG to a KG, which considers both semantic and structural characteristics.\nThen an encoder-decoder framework is developed to bridge the modeling research\nbetween KG and HKG. In the encoder part, KG-based graph neural networks are\nleveraged for structural modeling; while in the decoder part, various HKG-based\nscoring functions are exploited for semantic modeling. Especially, we design\nthe sharing embedding mechanism in the encoder-decoder framework with semantic\nrelatedness captured. We further theoretically prove that TransEQ preserves\ncomplete information in the equivalent transformation, and also achieves full\nexpressivity. Finally, extensive experiments on three benchmarks demonstrate\nthe superior performance of TransEQ in terms of both effectiveness and\nefficiency. On the largest benchmark WikiPeople, TransEQ significantly improves\nthe state-of-the-art models by 15\\% on MRR.",
      "tldr_zh": "该论文提出了一种名为 TransEQ 的方法，用于扩展超边扩展（hyperedge expansion），以同时捕捉超关系知识图（HKG）的语义和结构信息，从而解决现有模型的局限性。具体而言，TransEQ 通过等价转换将 HKG 转化为知识图（KG），并采用编码器-解码器框架：编码器利用基于图神经网络（GNNs）的结构建模，解码器则通过 HKG 评分函数和共享嵌入机制进行语义建模。理论上，TransEQ 能保留完整信息并实现完全表达性；实验在三个基准上证明其有效性和效率，在最大基准 WikiPeople 上，MRR 比现有模型提高了 15%。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.06191v1",
      "published_date": "2024-11-09 14:16:41 UTC",
      "updated_date": "2024-11-09 14:16:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:00:12.235195"
    },
    {
      "arxiv_id": "2411.06160v2",
      "title": "Expansion Quantization Network: An Efficient Micro-emotion Annotation and Detection Framework",
      "title_zh": "翻译失败",
      "authors": [
        "Jingyi Zhou",
        "Senlin Luo",
        "Haofan Chen"
      ],
      "abstract": "Text emotion detection constitutes a crucial foundation for advancing\nartificial intelligence from basic comprehension to the exploration of\nemotional reasoning. Most existing emotion detection datasets rely on manual\nannotations, which are associated with high costs, substantial subjectivity,\nand severe label imbalances. This is particularly evident in the inadequate\nannotation of micro-emotions and the absence of emotional intensity\nrepresentation, which fail to capture the rich emotions embedded in sentences\nand adversely affect the quality of downstream task completion. By proposing an\nall-labels and training-set label regression method, we map label values to\nenergy intensity levels, thereby fully leveraging the learning capabilities of\nmachine models and the interdependencies among labels to uncover multiple\nemotions within samples. This led to the establishment of the Emotion\nQuantization Network (EQN) framework for micro-emotion detection and\nannotation. Using five commonly employed sentiment datasets, we conducted\ncomparative experiments with various models, validating the broad applicability\nof our framework within NLP machine learning models. Based on the EQN\nframework, emotion detection and annotation are conducted on the GoEmotions\ndataset. A comprehensive comparison with the results from Google literature\ndemonstrates that the EQN framework possesses a high capability for automatic\ndetection and annotation of micro-emotions. The EQN framework is the first to\nachieve automatic micro-emotion annotation with energy-level scores, providing\nstrong support for further emotion detection analysis and the quantitative\nresearch of emotion computing.",
      "tldr_zh": "该论文针对文本情感检测中手动标注的高成本、主观性和标签不平衡问题，提出了一种 all-labels 和 training-set label regression 方法，将标签值映射到能量强度水平，以挖掘样本中的多种微情感。论文建立了 Emotion Quantization Network (EQN) 框架，用于高效的微情感标注和检测，并通过在五个常用情感数据集上的实验，与多种模型比较，验证了其广泛适用性。结果显示，EQN 框架在 GoEmotions 数据集上实现了自动微情感标注带有能量水平分数，是首次实现此功能的框架，为情感计算的量化研究提供了有力支持。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "3.1 There is a misstatement in the EQN Framework section",
      "pdf_url": "http://arxiv.org/pdf/2411.06160v2",
      "published_date": "2024-11-09 12:09:26 UTC",
      "updated_date": "2025-02-27 09:06:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:00:24.331686"
    },
    {
      "arxiv_id": "2411.06148v1",
      "title": "Deep Reinforcement Learning for Digital Twin-Oriented Complex Networked Systems",
      "title_zh": "深度强化学习用于面向数字孪生的复杂网络化系统",
      "authors": [
        "Jiaqi Wen",
        "Bogdan Gabrys",
        "Katarzyna Musial"
      ],
      "abstract": "The Digital Twin Oriented Complex Networked System (DT-CNS) aims to build and\nextend a Complex Networked System (CNS) model with progressively increasing\ndynamics complexity towards an accurate reflection of reality -- a Digital Twin\nof reality. Our previous work proposed evolutionary DT-CNSs to model the\nlong-term adaptive network changes in an epidemic outbreak. This study extends\nthis framework by proposeing the temporal DT-CNS model, where reinforcement\nlearning-driven nodes make decisions on temporal directed interactions in an\nepidemic outbreak. We consider cooperative nodes, as well as egocentric and\nignorant \"free-riders\" in the cooperation. We describe this epidemic spreading\nprocess with the Susceptible-Infected-Recovered ($SIR$) model and investigate\nthe impact of epidemic severity on the epidemic resilience for different types\nof nodes. Our experimental results show that (i) the full cooperation leads to\na higher reward and lower infection number than a cooperation with egocentric\nor ignorant \"free-riders\"; (ii) an increasing number of \"free-riders\" in a\ncooperation leads to a smaller reward, while an increasing number of egocentric\n\"free-riders\" further escalate the infection numbers and (iii) higher infection\nrates and a slower recovery weakens networks' resilience to severe epidemic\noutbreaks. These findings also indicate that promoting cooperation and reducing\n\"free-riders\" can improve public health during epidemics.",
      "tldr_zh": "本研究提出了一种基于深度强化学习的 temporal Digital Twin Oriented Complex Networked Systems (DT-CNS) 模型，用于模拟流行病爆发中的网络动态变化。模型中，强化学习驱动的节点在 Susceptible-Infected-Recovered (SIR) 模型下进行决策，考虑合作节点以及自我中心和无知的 \"free-riders\" 类型。实验结果显示，全合作策略比包含 \"free-riders\" 的策略获得更高奖励和更低感染率；增加 \"free-riders\" 会降低奖励并加剧感染传播；此外，更高的感染率和更慢的恢复会削弱网络对流行病的弹性。这些发现表明，促进合作并减少 \"free-riders\" 可以提升公共卫生应对能力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.06148v1",
      "published_date": "2024-11-09 11:24:42 UTC",
      "updated_date": "2024-11-09 11:24:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:00:35.572752"
    },
    {
      "arxiv_id": "2411.06146v1",
      "title": "AI-Compass: A Comprehensive and Effective Multi-module Testing Tool for AI Systems",
      "title_zh": "AI-Compass：一个全面且有效的多模块 AI 系统测试工具",
      "authors": [
        "Zhiyu Zhu",
        "Zhibo Jin",
        "Hongsheng Hu",
        "Minhui Xue",
        "Ruoxi Sun",
        "Seyit Camtepe",
        "Praveen Gauravaram",
        "Huaming Chen"
      ],
      "abstract": "AI systems, in particular with deep learning techniques, have demonstrated\nsuperior performance for various real-world applications. Given the need for\ntailored optimization in specific scenarios, as well as the concerns related to\nthe exploits of subsurface vulnerabilities, a more comprehensive and in-depth\ntesting AI system becomes a pivotal topic. We have seen the emergence of\ntesting tools in real-world applications that aim to expand testing\ncapabilities. However, they often concentrate on ad-hoc tasks, rendering them\nunsuitable for simultaneously testing multiple aspects or components.\nFurthermore, trustworthiness issues arising from adversarial attacks and the\nchallenge of interpreting deep learning models pose new challenges for\ndeveloping more comprehensive and in-depth AI system testing tools. In this\nstudy, we design and implement a testing tool, \\tool, to comprehensively and\neffectively evaluate AI systems. The tool extensively assesses multiple\nmeasurements towards adversarial robustness, model interpretability, and\nperforms neuron analysis. The feasibility of the proposed testing tool is\nthoroughly validated across various modalities, including image classification,\nobject detection, and text classification. Extensive experiments demonstrate\nthat \\tool is the state-of-the-art tool for a comprehensive assessment of the\nrobustness and trustworthiness of AI systems. Our research sheds light on a\ngeneral solution for AI systems testing landscape.",
      "tldr_zh": "该研究开发了AI-Compass，一种全面且有效的多模块测试工具，用于评估AI系统的鲁棒性和可信度，针对现有工具的局限性，如仅专注于单一任务。AI-Compass通过评估对抗鲁棒性（adversarial robustness）、模型可解释性（model interpretability）和神经元分析（neuron analysis）等多方面指标，来应对AI系统的潜在漏洞和优化需求。在图像分类、目标检测和文本分类等模态上进行广泛实验，结果显示AI-Compass是目前最先进的测试工具，为AI系统测试领域提供了通用解决方案。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.06146v1",
      "published_date": "2024-11-09 11:15:17 UTC",
      "updated_date": "2024-11-09 11:15:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:00:47.249301"
    },
    {
      "arxiv_id": "2411.06142v1",
      "title": "Aquila-plus: Prompt-Driven Visual-Language Models for Pixel-Level Remote Sensing Image Understanding",
      "title_zh": "翻译失败",
      "authors": [
        "Kaixuan Lu"
      ],
      "abstract": "The recent development of vision language models (VLMs) has led to\nsignificant advances in visual-language integration through visual instruction\ntuning, and they have rapidly evolved in the field of remote sensing image\nunderstanding, demonstrating their powerful capabilities. However, existing\nRSVLMs mainly focus on image-level or frame-level understanding, making it\ndifficult to achieve fine-grained pixel-level visual-language alignment.\nAdditionally, the lack of mask-based instructional data limits their further\ndevelopment. In this paper, we propose a mask-text instruction tuning method\ncalled Aquila-plus, which extends the capabilities of RSVLMs to achieve\npixel-level visual understanding by incorporating fine-grained mask regions\ninto language instructions. To achieve this, we first meticulously constructed\na mask region-text dataset containing 100K samples, and then designed a\nvisual-language model by injecting pixel-level representations into a large\nlanguage model (LLM). Specifically, Aquila-plus uses a convolutional CLIP as\nthe visual encoder and employs a mask-aware visual extractor to extract precise\nvisual mask features from high-resolution inputs. Experimental results\ndemonstrate that Aquila-plus outperforms existing methods in various region\nunderstanding tasks, showcasing its novel capabilities in pixel-level\ninstruction tuning.",
      "tldr_zh": "该研究针对现有视觉语言模型（VLMs）和遥感视觉语言模型（RSVLM）在图像级理解上的局限性，提出了Aquila-plus方法，通过掩码-文本指令调整实现细粒度的像素级视觉-语言对齐。\n他们构建了一个包含10万样本的掩码区域-文本数据集，并设计了视觉-语言模型，使用卷积CLIP作为视觉编码器和掩码感知视觉提取器，从高分辨率输入中提取精确的像素级特征，并注入到大型语言模型（LLM）。\n实验结果显示，Aquila-plus在各种区域理解任务中优于现有方法，证明了其在像素级指令调整方面的创新能力和性能提升。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.06142v1",
      "published_date": "2024-11-09 10:42:57 UTC",
      "updated_date": "2024-11-09 10:42:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:01:00.270670"
    },
    {
      "arxiv_id": "2411.06135v1",
      "title": "Online Parallel Multi-Task Relationship Learning via Alternating Direction Method of Multipliers",
      "title_zh": "翻译失败",
      "authors": [
        "Ruiyu Li",
        "Peilin Zhao",
        "Guangxia Li",
        "Zhiqiang Xu",
        "Xuewei Li"
      ],
      "abstract": "Online multi-task learning (OMTL) enhances streaming data processing by\nleveraging the inherent relations among multiple tasks. It can be described as\nan optimization problem in which a single loss function is defined for multiple\ntasks. Existing gradient-descent-based methods for this problem might suffer\nfrom gradient vanishing and poor conditioning issues. Furthermore, the\ncentralized setting hinders their application to online parallel optimization,\nwhich is vital to big data analytics. Therefore, this study proposes a novel\nOMTL framework based on the alternating direction multiplier method (ADMM), a\nrecent breakthrough in optimization suitable for the distributed computing\nenvironment because of its decomposable and easy-to-implement nature. The\nrelations among multiple tasks are modeled dynamically to fit the constant\nchanges in an online scenario. In a classical distributed computing\narchitecture with a central server, the proposed OMTL algorithm with the ADMM\noptimizer outperforms SGD-based approaches in terms of accuracy and efficiency.\nBecause the central server might become a bottleneck when the data scale grows,\nwe further tailor the algorithm to a decentralized setting, so that each node\ncan work by only exchanging information with local neighbors. Experimental\nresults on a synthetic and several real-world datasets demonstrate the\nefficiency of our methods.",
      "tldr_zh": "这篇论文针对在线多任务学习 (OMTL) 的挑战，提出了一种基于交替方向乘子法 (ADMM) 的新框架，以动态建模任务间关系并支持分布式计算，从而解决现有梯度下降方法如 SGD 的梯度消失和条件差问题。框架首先在中心化架构中实现，显著提高了准确性和效率；随后扩展到去中心化设置，让节点仅通过本地邻居交换信息，避免中心服务器瓶颈。实验在合成和真实数据集上验证了该方法的优越性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "Accpeted by Neurocomputing",
      "pdf_url": "http://arxiv.org/pdf/2411.06135v1",
      "published_date": "2024-11-09 10:20:13 UTC",
      "updated_date": "2024-11-09 10:20:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:01:12.042090"
    },
    {
      "arxiv_id": "2411.06128v1",
      "title": "Research on reinforcement learning based warehouse robot navigation algorithm in complex warehouse layout",
      "title_zh": "复杂仓库布局中基于强化学习的仓库机器人导航算法研究",
      "authors": [
        "Keqin Li",
        "Lipeng Liu",
        "Jiajing Chen",
        "Dezhi Yu",
        "Xiaofan Zhou",
        "Ming Li",
        "Congyu Wang",
        "Zhao Li"
      ],
      "abstract": "In this paper, how to efficiently find the optimal path in complex warehouse\nlayout and make real-time decision is a key problem. This paper proposes a new\nmethod of Proximal Policy Optimization (PPO) and Dijkstra's algorithm, Proximal\npolicy-Dijkstra (PP-D). PP-D method realizes efficient strategy learning and\nreal-time decision making through PPO, and uses Dijkstra algorithm to plan the\nglobal optimal path, thus ensuring high navigation accuracy and significantly\nimproving the efficiency of path planning. Specifically, PPO enables robots to\nquickly adapt and optimize action strategies in dynamic environments through\nits stable policy updating mechanism. Dijkstra's algorithm ensures global\noptimal path planning in static environment. Finally, through the comparison\nexperiment and analysis of the proposed framework with the traditional\nalgorithm, the results show that the PP-D method has significant advantages in\nimproving the accuracy of navigation prediction and enhancing the robustness of\nthe system. Especially in complex warehouse layout, PP-D method can find the\noptimal path more accurately and reduce collision and stagnation. This proves\nthe reliability and effectiveness of the robot in the study of complex\nwarehouse layout navigation algorithm.",
      "tldr_zh": "本文针对复杂仓库布局中机器人导航的路径优化和实时决策问题，提出了一种结合 Proximal Policy Optimization (PPO) 和 Dijkstra's algorithm 的新方法，称为 Proximal policy-Dijkstra (PP-D)。该方法利用 PPO 实现高效策略学习和动态环境适应，同时通过 Dijkstra's algorithm 规划全局最优路径，从而显著提高导航准确性和路径规划效率。实验结果显示，PP-D 与传统算法相比，在复杂仓库环境中提升了导航预测准确性、系统鲁棒性，并减少了碰撞和停滞现象，证明了其在机器人导航算法中的可靠性和有效性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.06128v1",
      "published_date": "2024-11-09 09:44:03 UTC",
      "updated_date": "2024-11-09 09:44:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:01:23.947778"
    },
    {
      "arxiv_id": "2411.06122v2",
      "title": "Characteristics of Political Misinformation Over the Past Decade",
      "title_zh": "过去十年的政治虚假信息特征",
      "authors": [
        "Erik J Schlicht"
      ],
      "abstract": "Although misinformation tends to spread online, it can have serious\nreal-world consequences. In order to develop automated tools to detect and\nmitigate the impact of misinformation, researchers must leverage algorithms\nthat can adapt to the modality (text, images and video), the source, and the\ncontent of the false information. However, these characteristics tend to change\ndynamically across time, making it challenging to develop robust algorithms to\nfight misinformation spread. Therefore, this paper uses natural language\nprocessing to find common characteristics of political misinformation over a\ntwelve year period. The results show that misinformation has increased\ndramatically in recent years and that it has increasingly started to be shared\nfrom sources with primary information modalities of text and images (e.g.,\nFacebook and Instagram), although video sharing sources containing\nmisinformation are starting to increase (e.g., TikTok). Moreover, it was\ndiscovered that statements expressing misinformation contain more negative\nsentiment than accurate information. However, the sentiment associated with\nboth accurate and inaccurate information has trended downward, indicating a\ngenerally more negative tone in political statements across time. Finally,\nrecurring misinformation categories were uncovered that occur over multiple\nyears, which may imply that people tend to share inaccurate statements around\ninformation they fear or don't understand (Science and Medicine, Crime,\nReligion), impacts them directly (Policy, Election Integrity, Economic) or\nPublic Figures who are salient in their daily lives. Together, it is hoped that\nthese insights will assist researchers in developing algorithms that are\ntemporally invariant and capable of detecting and mitigating misinformation\nacross time.",
      "tldr_zh": "这篇论文使用自然语言处理 (NLP) 分析了过去12年的政治误导信息特征，旨在帮助开发适应文本、图像和视频等模式的检测算法。研究发现，误导信息近年来急剧增加，主要通过文本和图像来源（如Facebook和Instagram）传播，而视频来源（如TikTok）正逐渐增多。结果还显示，误导信息通常包含更多负面情绪，且准确信息的情绪也趋于负面；此外，存在反复出现的类别，如科学与医学、犯罪、宗教、政策、经济和公共人物，这些可能与人们恐惧、不理解的事物或日常关注相关。这些洞见有助于创建时间不变的算法，以更有效地检测和缓解误导信息的传播。",
      "categories": [
        "cs.SI",
        "cs.AI"
      ],
      "primary_category": "cs.SI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.06122v2",
      "published_date": "2024-11-09 09:12:39 UTC",
      "updated_date": "2025-04-08 16:41:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:01:37.615107"
    },
    {
      "arxiv_id": "2411.06120v7",
      "title": "Evaluating the Propensity of Generative AI for Producing Harmful Disinformation During an Election Cycle",
      "title_zh": "评估生成式人工智能在选举周期期间产生有害虚假信息的倾向",
      "authors": [
        "Erik J Schlicht"
      ],
      "abstract": "Generative Artificial Intelligence offers a powerful tool for adversaries who\nwish to engage in influence operations, such as the Chinese Spamouflage\noperation and the Russian Internet Research Agency effort that both sought to\ninterfere with recent US election cycles. Therefore, this study seeks to\ninvestigate the propensity of current generative AI models for producing\nharmful disinformation during an election cycle. The probability that different\ngenerative AI models produced disinformation when given adversarial prompts was\nevaluated, in addition to the associated harm. This allows for the expected\nharm for each model to be computed and it was discovered that Copilot and\nGemini tied for the overall safest performance by realizing the lowest expected\nharm, while GPT-4o produced the greatest rates of harmful disinformation,\nresulting in much higher expected harm scores. The impact of disinformation\ncategory was also investigated and Gemini was safest within the political\ncategory of disinformation due to mitigation attempts made by developers during\nthe election, while Copilot was safest for topics related to health. Moreover,\ncharacteristics of adversarial roles were discovered that led to greater\nexpected harm across all models. Finally, classification models were developed\nthat predicted disinformation production based on the conditions considered in\nthis study, which offers insight into factors important for predicting\ndisinformation production. Based on all of these insights, recommendations are\nprovided that seek to mitigate factors that lead to harmful disinformation\nbeing produced by generative AI models. It is hoped that developers will use\nthese insights to improve future models.",
      "tldr_zh": "这篇论文评估了 Generative AI 在选举周期中产生有害 disinformation 的倾向，焦点在于模型对 adversarial prompts 的响应及其潜在危害。研究通过测试多种 AI 模型，计算了每个模型产生 disinformation 的概率和期望危害，发现 Copilot 和 Gemini 表现最安全，而 GPT-4o 的有害输出率最高，导致期望危害分数显著增加。进一步分析显示，Gemini 在政治类别 disinformation 中最安全（得益于开发者的缓解措施），Copilot 在健康相关主题中表现最佳，且某些对抗角色特征会加剧所有模型的危害。最终，论文开发了分类模型来预测 disinformation 生产，并提供了针对性推荐，以帮助开发者改进未来模型并减少风险。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.06120v7",
      "published_date": "2024-11-09 09:03:08 UTC",
      "updated_date": "2025-04-15 22:05:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:01:48.064143"
    },
    {
      "arxiv_id": "2411.06111v1",
      "title": "Energy-efficient Hybrid Model Predictive Trajectory Planning for Autonomous Electric Vehicles",
      "title_zh": "翻译失败",
      "authors": [
        "Fan Ding",
        "Xuewen Luo",
        "Gaoxuan Li",
        "Hwa Hui Tew",
        "Junn Yong Loo",
        "Chor Wai Tong",
        "A. S. M Bakibillah",
        "Ziyuan Zhao",
        "Zhiyu Tao"
      ],
      "abstract": "To tackle the twin challenges of limited battery life and lengthy charging\ndurations in electric vehicles (EVs), this paper introduces an Energy-efficient\nHybrid Model Predictive Planner (EHMPP), which employs an energy-saving\noptimization strategy. EHMPP focuses on refining the design of the motion\nplanner to be seamlessly integrated with the existing automatic driving\nalgorithms, without additional hardware. It has been validated through\nsimulation experiments on the Prescan, CarSim, and Matlab platforms,\ndemonstrating that it can increase passive recovery energy by 11.74\\% and\neffectively track motor speed and acceleration at optimal power. To sum up,\nEHMPP not only aids in trajectory planning but also significantly boosts energy\nefficiency in autonomous EVs.",
      "tldr_zh": "这篇论文针对电动汽车（EVs）的电池寿命有限和充电时间漫长问题，提出了一种 Energy-efficient Hybrid Model Predictive Planner (EHMPP)，通过节能优化策略优化运动规划设计，与现有自动驾驶算法无缝整合，无需额外硬件。EHMPP 在 Prescan、CarSim 和 Matlab 平台的模拟实验中验证，实现了被动回收能量提高 11.74%，并有效跟踪电机速度和加速度以达到最佳功率。总体而言，该方法不仅提升了自主 EVs 的轨迹规划能力，还显著提高了能源效率。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted at the IEEE International Conference on Systems, Man, and\n  Cybernetics (SMC) 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.06111v1",
      "published_date": "2024-11-09 08:21:06 UTC",
      "updated_date": "2024-11-09 08:21:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:01:59.258807"
    },
    {
      "arxiv_id": "2411.06106v2",
      "title": "Personalize to generalize: Towards a universal medical multi-modality generalization through personalization",
      "title_zh": "翻译失败",
      "authors": [
        "Zhaorui Tan",
        "Xi Yang",
        "Tan Pan",
        "Tianyi Liu",
        "Chen Jiang",
        "Xin Guo",
        "Qiufeng Wang",
        "Anh Nguyen",
        "Yuan Qi",
        "Kaizhu Huang",
        "Yuan Cheng"
      ],
      "abstract": "The differences among medical imaging modalities, driven by distinct\nunderlying principles, pose significant challenges for generalization in\nmulti-modal medical tasks. Beyond modality gaps, individual variations, such as\ndifferences in organ size and metabolic rate, further impede a model's ability\nto generalize effectively across both modalities and diverse populations.\nDespite the importance of personalization, existing approaches to multi-modal\ngeneralization often neglect individual differences, focusing solely on common\nanatomical features. This limitation may result in weakened generalization in\nvarious medical tasks. In this paper, we unveil that personalization is\ncritical for multi-modal generalization. Specifically, we propose an approach\nto achieve personalized generalization through approximating the underlying\npersonalized invariant representation ${X}_h$ across various modalities by\nleveraging individual-level constraints and a learnable biological prior. We\nvalidate the feasibility and benefits of learning a personalized ${X}_h$,\nshowing that this representation is highly generalizable and transferable\nacross various multi-modal medical tasks. Extensive experimental results\nconsistently show that the additionally incorporated personalization\nsignificantly improves performance and generalization across diverse scenarios,\nconfirming its effectiveness.",
      "tldr_zh": "该论文探讨了医疗成像多模态任务中，模态差异（如不同成像原理）和个体变异（如器官大小和代谢率）对模型泛化能力的挑战，强调现有方法忽略个体差异导致的局限性。作者提出一种通过个性化方法实现通用多模态泛化的框架，该方法利用个体级约束和可学习的生物学先验来逼近personalized invariant representation ${X}_h$，从而提升跨模态任务的表示学习。实验结果显示，这种个性化策略显著提高了模型在各种医疗场景中的性能和泛化能力，证明了其有效性和可转移性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.06106v2",
      "published_date": "2024-11-09 08:00:50 UTC",
      "updated_date": "2024-11-13 03:19:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:02:10.954653"
    },
    {
      "arxiv_id": "2411.06098v3",
      "title": "An Architectural Approach to Enhance Deep Long-Tailed Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Yuhan Pan",
        "Yanan Sun",
        "Wei Gong"
      ],
      "abstract": "Deep long-tailed recognition has been widely studied to address the issue of\nimbalanced data distributions in real-world scenarios. However, there has been\ninsufficient focus on the design of neural architectures, despite empirical\nevidence suggesting that architecture can significantly impact performance. In\nthis paper, we attempt to mitigate long-tailed issues through architectural\nimprovements. To simplify the design process, we utilize Differential\nArchitecture Search (DARTS) to achieve this goal. Unfortunately, existing DARTS\nmethods struggle to perform well in long-tailed scenarios. To tackle this\nchallenge, we introduce Long-Tailed Differential Architecture Search (LTDAS).\nSpecifically, we conduct extensive experiments to explore architectural\ncomponents that demonstrate better performance on long-tailed data and propose\na new search space based on our observations. This ensures that the\narchitecture obtained through our search process incorporates superior\ncomponents. Additionally, we propose replacing the learnable linear classifier\nwith an Equiangular Tight Frame (ETF) classifier to further enhance our method.\nThis classifier effectively alleviates the biased search process and prevents\nperformance collapse. Extensive experimental evaluations demonstrate that our\napproach consistently improves upon existing methods from an orthogonal\nperspective and achieves state-of-the-art results with simple enhancements.",
      "tldr_zh": "本研究针对深度长尾学习（Deep Long-Tailed Learning）中的数据不平衡问题，强调神经架构设计的重要性，并提出一种架构改进方法。作者引入Long-Tailed Differential Architecture Search (LTDAS)，这是一种基于Differential Architecture Search (DARTS)的改进版本，通过实验探索新搜索空间以优化长尾数据下的架构组件，并用Equiangular Tight Frame (ETF)分类器替换线性分类器，以缓解偏差并提升性能。实验结果显示，该方法从正交视角持续优于现有方法，并在多个场景中实现了最先进（state-of-the-art）性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.06098v3",
      "published_date": "2024-11-09 07:19:56 UTC",
      "updated_date": "2024-12-02 11:49:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:02:22.567702"
    },
    {
      "arxiv_id": "2411.06097v2",
      "title": "A Multimodal Adaptive Graph-based Intelligent Classification Model for Fake News",
      "title_zh": "翻译失败",
      "authors": [
        "Jun-hao",
        "Xu"
      ],
      "abstract": "Numerous studies have been proposed to detect fake news focusing on\nmulti-modalities based on machine and/or deep learning. However, studies\nfocusing on graph-based structures using geometric deep learning are lacking.\nTo address this challenge, we introduce the Multimodal Adaptive Graph-based\nIntelligent Classification (aptly referred to as MAGIC) for fake news\ndetection. Specifically, the Encoder Representations from Transformers was used\nfor text vectorization whilst ResNet50 was used for images. A comprehensive\ninformation interaction graph was built using the adaptive Graph Attention\nNetwork before classifying the multimodal input through the Softmax function.\nMAGIC was trained and tested on two fake news datasets, that is, Fakeddit\n(English) and Multimodal Fake News Detection (Chinese), with the model\nachieving an accuracy of 98.8\\% and 86.3\\%, respectively. Ablation experiments\nalso revealed MAGIC to yield superior performance across both the datasets.\nFindings show that a graph-based deep learning adaptive model is effective in\ndetecting multimodal fake news, surpassing state-of-the-art methods.",
      "tldr_zh": "本文提出了一种多模态自适应图-based 智能分类模型 MAGIC，用于假新闻检测，以弥补现有研究中基于几何深度学习的图结构不足。模型采用 Encoder Representations from Transformers 进行文本向量化，ResNet50 处理图像，并构建信息交互图通过 adaptive Graph Attention Network，最后利用 Softmax 函数进行分类。在 Fakeddit（英语）和 Multimodal Fake News Detection（中文）数据集上，MAGIC 分别实现了 98.8% 和 86.3% 的准确率，优于现有最先进方法，并通过消融实验验证了其有效性。",
      "categories": [
        "cs.AI",
        "68T99"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages",
      "pdf_url": "http://arxiv.org/pdf/2411.06097v2",
      "published_date": "2024-11-09 07:19:19 UTC",
      "updated_date": "2024-11-18 18:19:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:02:35.262143"
    },
    {
      "arxiv_id": "2411.06087v2",
      "title": "Cross-Domain Transfer Learning using Attention Latent Features for Multi-Agent Trajectory Prediction",
      "title_zh": "使用注意力潜在特征的跨域迁移学习，用于多智能体",
      "authors": [
        "Jia Quan Loh",
        "Xuewen Luo",
        "Fan Ding",
        "Hwa Hui Tew",
        "Junn Yong Loo",
        "Ze Yang Ding",
        "Susilawati Susilawati",
        "Chee Pin Tan"
      ],
      "abstract": "With the advancements of sensor hardware, traffic infrastructure and deep\nlearning architectures, trajectory prediction of vehicles has established a\nsolid foundation in intelligent transportation systems. However, existing\nsolutions are often tailored to specific traffic networks at particular time\nperiods. Consequently, deep learning models trained on one network may struggle\nto generalize effectively to unseen networks. To address this, we proposed a\nnovel spatial-temporal trajectory prediction framework that performs\ncross-domain adaption on the attention representation of a Transformer-based\nmodel. A graph convolutional network is also integrated to construct dynamic\ngraph feature embeddings that accurately model the complex spatial-temporal\ninteractions between the multi-agent vehicles across multiple traffic domains.\nThe proposed framework is validated on two case studies involving the\ncross-city and cross-period settings. Experimental results show that our\nproposed framework achieves superior trajectory prediction and domain\nadaptation performances over the state-of-the-art models.",
      "tldr_zh": "这篇论文提出了一种基于注意力潜在特征（Attention Latent Features）的跨域转移学习框架，用于多代理轨迹预测（Multi-Agent Trajectory Prediction），以解决现有模型在不同交通网络间泛化能力不足的问题。该框架利用 Transformer-based 模型的注意力表示进行跨域适应，并整合图卷积网络（Graph Convolutional Network）来构建动态图特征嵌入，从而准确捕捉多车辆间的复杂空间-时间交互。在跨城市和跨时期设置的两个案例研究中，实验结果显示，该框架在轨迹预测和域适配性能上优于现有最先进模型。",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at the IEEE International Conference on Systems, Man, and\n  Cybernetics 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.06087v2",
      "published_date": "2024-11-09 06:39:44 UTC",
      "updated_date": "2024-11-12 05:40:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:02:47.186250"
    },
    {
      "arxiv_id": "2411.06084v1",
      "title": "Optimizing Large Language Models through Quantization: A Comparative Analysis of PTQ and QAT Techniques",
      "title_zh": "通过量化优化大语言模型：PTQ 和 QAT 技术的比较分析",
      "authors": [
        "Jahid Hasan"
      ],
      "abstract": "This paper presents a comprehensive analysis of quantization techniques for\noptimizing Large Language Models (LLMs), specifically focusing on Post-Training\nQuantization (PTQ) and Quantization-Aware Training (QAT). Through empirical\nevaluation across models ranging from 10M to 1B parameters, we demonstrate that\nquantization can achieve up to 68% reduction in model size while maintaining\nperformance within 6% of full-precision baselines when utilizing our proposed\nscaling factor {\\gamma}. Our experiments show that INT8 quantization delivers a\n40% reduction in computational cost and power consumption, while INT4\nquantization further improves these metrics by 60%. We introduce a novel\ntheoretical framework for mixed-precision quantization, deriving optimal bit\nallocation strategies based on layer sensitivity and weight variance. Hardware\nefficiency evaluations on edge devices reveal that our quantization approach\nenables up to 2.4x throughput improvement for INT8 and 3x for INT4, with 60%\npower reduction compared to full-precision models.",
      "tldr_zh": "本研究对后训练量化（PTQ）和量化感知训练（QAT）技术进行了全面比较，以优化大型语言模型（LLMs）。通过对10M至1B参数模型的实证评估，论文证明量化可将模型大小减少高达68%，同时保持性能仅比全精度基准下降6%，并引入了基于层敏感性和权重方差的混合精度量化理论框架。实验结果显示，INT8量化可降低计算成本和功耗40%，而INT4量化进一步提升这些指标60%，并在边缘设备上实现2.4x（INT8）和3x（INT4）的吞吐量改进，同时减少60%的功耗。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.06084v1",
      "published_date": "2024-11-09 06:30:13 UTC",
      "updated_date": "2024-11-09 06:30:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:02:59.300468"
    },
    {
      "arxiv_id": "2411.06074v1",
      "title": "Aquila: A Hierarchically Aligned Visual-Language Model for Enhanced Remote Sensing Image Comprehension",
      "title_zh": "翻译失败",
      "authors": [
        "Kaixuan Lu",
        "Ruiqian Zhang",
        "Xiao Huang",
        "Yuxing Xie"
      ],
      "abstract": "Recently, large vision language models (VLMs) have made significant strides\nin visual language capabilities through visual instruction tuning, showing\ngreat promise in the field of remote sensing image interpretation. However,\nexisting remote sensing vision language models (RSVLMs) often fall short in\ncapturing the complex characteristics of remote sensing scenes, as they\ntypically rely on low resolution, single scale visual features and simplistic\nmethods to map visual features to language features. In this paper, we present\nAquila, an advanced visual language foundation model designed to enable richer\nvisual feature representation and more precise visual-language feature\nalignment for remote sensing images. Our approach introduces a learnable\nHierarchical Spatial Feature Integration (SFI) module that supports high\nresolution image inputs and aggregates multi scale visual features, allowing\nfor the detailed representation of complex visual information. Additionally,\nthe SFI module is repeatedly integrated into the layers of the large language\nmodel (LLM) to achieve deep visual language feature alignment, without\ncompromising the model's performance in natural language processing tasks.\nThese innovations, capturing detailed visual effects through higher resolution\nand multi scale input, and enhancing feature alignment significantly improve\nthe model's ability to learn from image text data. We validate the\neffectiveness of Aquila through extensive quantitative experiments and\nqualitative analyses, demonstrating its superior performance.",
      "tldr_zh": "本文提出Aquila，一种分层对齐的视觉语言模型(VLMs)，旨在提升遥感图像(Remote Sensing)的理解能力，以解决现有遥感视觉语言模型(RSVLMs)依赖低分辨率和单尺度特征的问题。Aquila引入可学习的Hierarchical Spatial Feature Integration (SFI)模块，支持高分辨率输入并聚合多尺度视觉特征，同时将SFI模块集成到大型语言模型(LLM)的层中，实现深度视觉-语言特征对齐，而不影响自然语言处理性能。这些创新显著提高了模型从图像文本数据中学习的能力，实验结果显示Aquila在定量和定性评估中表现出优越性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.06074v1",
      "published_date": "2024-11-09 05:31:56 UTC",
      "updated_date": "2024-11-09 05:31:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:03:11.804043"
    },
    {
      "arxiv_id": "2411.06070v1",
      "title": "GFT: Graph Foundation Model with Transferable Tree Vocabulary",
      "title_zh": "翻译失败",
      "authors": [
        "Zehong Wang",
        "Zheyuan Zhang",
        "Nitesh V Chawla",
        "Chuxu Zhang",
        "Yanfang Ye"
      ],
      "abstract": "Inspired by the success of foundation models in applications such as ChatGPT,\nas graph data has been ubiquitous, one can envision the far-reaching impacts\nthat can be brought by Graph Foundation Models (GFMs) with broader applications\nin the areas such as scientific research, social network analysis, drug\ndiscovery, and e-commerce. Despite the significant progress of pre-trained\ngraph neural networks, there haven't been GFMs that can achieve desired\nperformance on various graph-learning-related tasks. Building GFMs may rely on\na vocabulary that encodes transferable patterns shared among different tasks\nand domains. Unlike image and text, defining such transferable patterns for\ngraphs remains an open question. In this paper, we aim to bridge this gap by\nrethinking the transferable patterns on graphs as computation trees -- i.e.,\ntree structures derived from the message-passing process. Based on this\ninsight, we propose a cross-task, cross-domain graph foundation model named\nGFT, short for Graph Foundation model with transferable Tree vocabulary. By\ntreating computation trees as tokens within the transferable vocabulary, GFT\nimproves model generalization and reduces the risk of negative transfer. The\ntheoretical analyses and extensive experimental studies have demonstrated the\ntransferability of computation trees and shown the effectiveness of GFT across\ndiverse tasks and domains in graph learning. The open source code and data are\navailable at https://github.com/Zehong-Wang/GFT.",
      "tldr_zh": "该研究受 ChatGPT 等基础模型启发，针对图数据在科学研究、社会网络分析等领域中的广泛应用，提出了一种图基础模型（Graph Foundation Models, GFMs）——GFT，利用可转移的树词汇（transferable Tree vocabulary）来编码图模式。GFT 将计算树（computation trees），即从消息传递过程中衍生的树结构，作为词汇标记，以提升模型在跨任务和跨领域的泛化能力，并减少负面转移。实验结果和理论分析证明了计算树的转移性，展示了 GFT 在多样化图学习任务中的有效性，并提供了开源代码以促进进一步应用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.06070v1",
      "published_date": "2024-11-09 05:14:30 UTC",
      "updated_date": "2024-11-09 05:14:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:03:22.905953"
    },
    {
      "arxiv_id": "2411.06068v1",
      "title": "Zyda-2: a 5 Trillion Token High-Quality Dataset",
      "title_zh": "翻译失败",
      "authors": [
        "Yury Tokpanov",
        "Paolo Glorioso",
        "Quentin Anthony",
        "Beren Millidge"
      ],
      "abstract": "In this technical report, we present Zyda-2: a five trillion token dataset\nfor language model pretraining. Zyda-2 was used to train our Zamba2 series of\nmodels which are state-of-the-art for their weight class. We build Zyda-2 by\ncollating high-quality open-source tokens such as FineWeb and DCLM, then\ndistilling them to the highest-quality subset via cross-deduplication and\nmodel-based quality filtering. Zyda-2 is released under a permissive open\nlicense, and is available at https://huggingface.co/datasets/Zyphra/Zyda-2",
      "tldr_zh": "本文介绍了 Zyda-2，一个包含 5 万亿 token 的高质量数据集，用于语言模型预训练，并已用于训练 Zamba2 系列模型，这些模型在它们的权重类别中达到了 state-of-the-art 水平。Zyda-2 通过整合 FineWeb 和 DCLM 等开源数据，然后应用 cross-deduplication 和 model-based quality filtering 来提炼出最高质量子集。该数据集以 permissive open license 发布，并可在 Hugging Face 上获取，为语言模型研究社区提供了宝贵资源。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "initial upload 11/08/24",
      "pdf_url": "http://arxiv.org/pdf/2411.06068v1",
      "published_date": "2024-11-09 04:57:41 UTC",
      "updated_date": "2024-11-09 04:57:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:03:35.200881"
    },
    {
      "arxiv_id": "2411.06066v1",
      "title": "Diversity and Inclusion in AI for Recruitment: Lessons from Industry Workshop",
      "title_zh": "多样性和包容性在用于招聘的人工智能中：来自行业研讨会的经验教训",
      "authors": [
        "Muneera Bano",
        "Didar Zowghi",
        "Fernando Mourao",
        "Sarah Kaur",
        "Tao Zhang"
      ],
      "abstract": "Artificial Intelligence (AI) systems for online recruitment markets have the\npotential to significantly enhance the efficiency and effectiveness of job\nplacements and even promote fairness or inclusive hiring practices. Neglecting\nDiversity and Inclusion (D&I) in these systems, however, can perpetuate biases,\nleading to unfair hiring practices and decreased workplace diversity, while\nexposing organisations to legal and reputational risks. Despite the\nacknowledged importance of D&I in AI, there is a gap in research on effectively\nimplementing D&I guidelines in real-world recruitment systems. Challenges\ninclude a lack of awareness and framework for operationalising D&I in a\ncost-effective, context-sensitive manner. This study aims to investigate the\npractical application of D&I guidelines in AI-driven online job-seeking\nsystems, specifically exploring how these principles can be operationalised to\ncreate more inclusive recruitment processes. We conducted a co-design workshop\nwith a large multinational recruitment company focusing on two AI-driven\nrecruitment use cases. User stories and personas were applied to evaluate the\nimpacts of AI on diverse stakeholders. Follow-up interviews were conducted to\nassess the workshop's long-term effects on participants' awareness and\napplication of D&I principles. The co-design workshop successfully increased\nparticipants' understanding of D&I in AI. However, translating awareness into\noperational practice posed challenges, particularly in balancing D&I with\nbusiness goals. The results suggest developing tailored D&I guidelines and\nongoing support to ensure the effective adoption of inclusive AI practices.",
      "tldr_zh": "这篇论文探讨了在AI驱动的招聘系统中实施Diversity and Inclusion (D&I)的挑战与解决方案，强调忽视D&I可能导致偏见和不公平问题。研究通过与大型跨国招聘公司进行共设计工作坊，聚焦两个AI用例，并运用用户故事和角色评估对不同利益相关者的影响，同时进行后续访谈以评估长期效果。结果显示工作坊显著提高了参与者对D&I的理解，但将意识转化为实际实践面临困难，特别是平衡D&I与商业目标。论文建议开发量身定制的D&I指南和持续支持，以推动更具包容性的AI招聘实践。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.06066v1",
      "published_date": "2024-11-09 04:45:47 UTC",
      "updated_date": "2024-11-09 04:45:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:03:47.079102"
    },
    {
      "arxiv_id": "2411.06060v1",
      "title": "Wild Narratives: Exploring the Effects of Animal Chatbots on Empathy and Positive Attitudes toward Animals",
      "title_zh": "翻译失败",
      "authors": [
        "Jingshu Li",
        "Aaditya Patwari",
        "Yi-Chieh Lee"
      ],
      "abstract": "Rises in the number of animal abuse cases are reported around the world.\nWhile chatbots have been effective in influencing their users' perceptions and\nbehaviors, little if any research has hitherto explored the design of chatbots\nthat embody animal identities for the purpose of eliciting empathy toward\nanimals. We therefore conducted a mixed-methods experiment to investigate how\nspecific design cues in such chatbots can shape their users' perceptions of\nboth the chatbots' identities and the type of animal they represent. Our\nfindings indicate that such chatbots can significantly increase empathy,\nimprove attitudes, and promote prosocial behavioral intentions toward animals,\nparticularly when they incorporate emotional verbal expressions and authentic\ndetails of such animals' lives. These results expand our understanding of\nchatbots with non-human identities and highlight their potential for use in\nconservation initiatives, suggesting a promising avenue whereby technology\ncould foster a more informed and empathetic society.",
      "tldr_zh": "这篇论文探讨了动物身份聊天机器人如何通过特定设计元素（如情感性语言和真实生活细节）影响用户对动物的同理心和积极态度，以应对全球动物虐待案件上升的问题。研究采用混合方法实验，评估了这些聊天机器人在塑造用户感知方面的效果，发现它们能显著提升同理心、改善态度并促进亲社会行为意图。结果扩展了对非人类身份聊天机器人的理解，并建议其应用于动物保护倡议，以培养一个更具同理心和知情的社会。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.06060v1",
      "published_date": "2024-11-09 03:55:53 UTC",
      "updated_date": "2024-11-09 03:55:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:03:59.164190"
    },
    {
      "arxiv_id": "2411.07814v1",
      "title": "Community Research Earth Digital Intelligence Twin (CREDIT)",
      "title_zh": "翻译失败",
      "authors": [
        "John Schreck",
        "Yingkai Sha",
        "William Chapman",
        "Dhamma Kimpara",
        "Judith Berner",
        "Seth McGinnis",
        "Arnold Kazadi",
        "Negin Sobhani",
        "Ben Kirk",
        "David John Gagne II"
      ],
      "abstract": "Recent advancements in artificial intelligence (AI) for numerical weather\nprediction (NWP) have significantly transformed atmospheric modeling. AI NWP\nmodels outperform traditional physics-based systems, such as the Integrated\nForecast System (IFS), across several global metrics while requiring fewer\ncomputational resources. However, existing AI NWP models face limitations\nrelated to training datasets and timestep choices, often resulting in artifacts\nthat reduce model performance. To address these challenges, we introduce the\nCommunity Research Earth Digital Intelligence Twin (CREDIT) framework,\ndeveloped at NSF NCAR. CREDIT provides a flexible, scalable, and user-friendly\nplatform for training and deploying AI-based atmospheric models on\nhigh-performance computing systems. It offers an end-to-end pipeline for data\npreprocessing, model training, and evaluation, democratizing access to advanced\nAI NWP capabilities. We demonstrate CREDIT's potential through WXFormer, a\nnovel deterministic vision transformer designed to predict atmospheric states\nautoregressively, addressing common AI NWP issues like compounding error growth\nwith techniques such as spectral normalization, padding, and multi-step\ntraining. Additionally, to illustrate CREDIT's flexibility and state-of-the-art\nmodel comparisons, we train the FUXI architecture within this framework. Our\nfindings show that both FUXI and WXFormer, trained on six-hourly ERA5 hybrid\nsigma-pressure levels, generally outperform IFS HRES in 10-day forecasts,\noffering potential improvements in efficiency and forecast accuracy. CREDIT's\nmodular design enables researchers to explore various models, datasets, and\ntraining configurations, fostering innovation within the scientific community.",
      "tldr_zh": "该研究介绍了 Community Research Earth Digital Intelligence Twin (CREDIT) 框架，由 NSF NCAR 开发，用于解决 AI 数值天气预报 (NWP) 模型在训练数据集和时间步选择方面的局限性，从而减少性能问题。CREDIT 提供了一个灵活、可扩展的用户友好平台，支持数据预处理、模型训练和评估的全流程，并适用于高性能计算系统。通过演示 WXFormer（一个基于自回归预测的确定性视觉变压器）和 FUXI 架构，实验结果显示两者在六小时 ERA5 混合 sigma-压力水平上训练后，通常在 10 天预报中优于 Integrated Forecast System (IFS)，显著提高了效率和准确性。该框架的模块化设计促进了研究人员探索不同模型、数据集和配置，推动 AI NWP 领域的创新。",
      "categories": [
        "cs.AI",
        "physics.ao-ph"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.07814v1",
      "published_date": "2024-11-09 03:08:03 UTC",
      "updated_date": "2024-11-09 03:08:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:04:12.481543"
    },
    {
      "arxiv_id": "2411.06048v1",
      "title": "An Empirical Analysis on Spatial Reasoning Capabilities of Large Multimodal Models",
      "title_zh": "对大型多模态模型空间推理能力的实证分析",
      "authors": [
        "Fatemeh Shiri",
        "Xiao-Yu Guo",
        "Mona Golestan Far",
        "Xin Yu",
        "Gholamreza Haffari",
        "Yuan-Fang Li"
      ],
      "abstract": "Large Multimodal Models (LMMs) have achieved strong performance across a\nrange of vision and language tasks. However, their spatial reasoning\ncapabilities are under-investigated. In this paper, we construct a novel VQA\ndataset, Spatial-MM, to comprehensively study LMMs' spatial understanding and\nreasoning capabilities. Our analyses on object-relationship and multi-hop\nreasoning reveal several important findings. Firstly, bounding boxes and scene\ngraphs, even synthetic ones, can significantly enhance LMMs' spatial reasoning.\nSecondly, LMMs struggle more with questions posed from the human perspective\nthan the camera perspective about the image. Thirdly, chain of thought (CoT)\nprompting does not improve model performance on complex multi-hop questions\ninvolving spatial relations. % Moreover, spatial reasoning steps are much less\naccurate than non-spatial ones across MLLMs. Lastly, our perturbation analysis\non GQA-spatial reveals that LMMs are much stronger at basic object detection\nthan complex spatial reasoning. We believe our benchmark dataset and in-depth\nanalyses can spark further research on LMMs spatial reasoning. Spatial-MM\nbenchmark is available at: https://github.com/FatemehShiri/Spatial-MM",
      "tldr_zh": "这篇论文通过构建一个新数据集 Spatial-MM，对 Large Multimodal Models (LMMs) 的空间推理能力进行了全面实证分析，重点评估了对象关系和多跳推理。研究发现，边界框和场景图（即使是合成的）能显著提升 LMMs 的空间理解，而模型在处理从人类视角的问题时比从相机视角更困难，且 Chain of Thought (CoT) 提示对复杂多跳空间关系问题无效。扰动分析进一步显示，LMMs 在基本对象检测上表现更强，但复杂空间推理准确率较低，该基准数据集可推动未来 LMMs 研究的深入。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.06048v1",
      "published_date": "2024-11-09 03:07:33 UTC",
      "updated_date": "2024-11-09 03:07:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:04:23.056656"
    },
    {
      "arxiv_id": "2411.06046v1",
      "title": "Personalized News Recommendation System via LLM Embedding and Co-Occurrence Patterns",
      "title_zh": "翻译失败",
      "authors": [
        "Zheng Li",
        "Kai Zhange"
      ],
      "abstract": "In the past two years, large language models (LLMs) have achieved rapid\ndevelopment and demonstrated remarkable emerging capabilities. Concurrently,\nwith powerful semantic understanding and reasoning capabilities, LLMs have\nsignificantly empowered the rapid advancement of the recommendation system\nfield. Specifically, in news recommendation (NR), systems must comprehend and\nprocess a vast amount of clicked news text to infer the probability of\ncandidate news clicks. This requirement exceeds the capabilities of traditional\nNR models but aligns well with the strengths of LLMs. In this paper, we propose\na novel NR algorithm to reshape the news model via LLM Embedding and\nCo-Occurrence Pattern (LECOP). On one hand, we fintuned LLM by contrastive\nlearning using large-scale datasets to encode news, which can fully explore the\nsemantic information of news to thoroughly identify user preferences. On the\nother hand, we explored multiple co-occurrence patterns to mine collaborative\ninformation. Those patterns include news ID co-occurrence, Item-Item keywords\nco-occurrence and Intra-Item keywords co-occurrence. The keywords mentioned\nabove are all generated by LLM. As far as we know, this is the first time that\nconstructing such detailed Co-Occurrence Patterns via LLM to capture\ncollaboration. Extensive experiments demonstrate the superior performance of\nour proposed novel method",
      "tldr_zh": "该论文提出了一种新型个性化新闻推荐算法LECOP，利用LLM Embedding和Co-Occurrence Patterns来提升推荐系统的性能。方法包括通过对比学习微调LLMs编码新闻，以深入挖掘新闻语义信息并识别用户偏好；同时，探索多种共现模式，如新闻ID共现、Item-Item关键词共现和Intra-Item关键词共现，这些关键词均由LLMs生成。实验结果显示，该算法在新闻推荐任务中表现出色，首次通过LLMs构建详细的Co-Occurrence Patterns来捕获协作信息。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.06046v1",
      "published_date": "2024-11-09 03:01:49 UTC",
      "updated_date": "2024-11-09 03:01:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:04:35.104245"
    },
    {
      "arxiv_id": "2411.06041v1",
      "title": "PointCG: Self-supervised Point Cloud Learning via Joint Completion and Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Yun Liu",
        "Peng Li",
        "Xuefeng Yan",
        "Liangliang Nan",
        "Bing Wang",
        "Honghua Chen",
        "Lina Gong",
        "Wei Zhao",
        "Mingqiang Wei"
      ],
      "abstract": "The core of self-supervised point cloud learning lies in setting up\nappropriate pretext tasks, to construct a pre-training framework that enables\nthe encoder to perceive 3D objects effectively. In this paper, we integrate two\nprevalent methods, masked point modeling (MPM) and 3D-to-2D generation, as\npretext tasks within a pre-training framework. We leverage the spatial\nawareness and precise supervision offered by these two methods to address their\nrespective limitations: ambiguous supervision signals and insensitivity to\ngeometric information. Specifically, the proposed framework, abbreviated as\nPointCG, consists of a Hidden Point Completion (HPC) module and an\nArbitrary-view Image Generation (AIG) module. We first capture visible points\nfrom arbitrary views as inputs by removing hidden points. Then, HPC extracts\nrepresentations of the inputs with an encoder and completes the entire shape\nwith a decoder, while AIG is used to generate rendered images based on the\nvisible points' representations. Extensive experiments demonstrate the\nsuperiority of the proposed method over the baselines in various downstream\ntasks. Our code will be made available upon acceptance.",
      "tldr_zh": "该论文提出了一种自监督点云学习框架PointCG，通过联合点云补全和生成任务来提升编码器对3D对象的感知能力。具体而言，PointCG整合了masked point modeling (MPM)和3D-to-2D generation作为预训练任务，利用Hidden Point Completion (HPC)模块提取输入点云表示并完成完整形状，以及Arbitrary-view Image Generation (AIG)模块基于可见点生成渲染图像，从而解决MPM的模糊监督信号和生成任务对几何信息的敏感性问题。实验结果显示，PointCG在各种下游任务中优于基线模型，证明了其有效性。作者计划在论文接受后公开代码。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.06041v1",
      "published_date": "2024-11-09 02:38:29 UTC",
      "updated_date": "2024-11-09 02:38:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:04:47.309415"
    },
    {
      "arxiv_id": "2411.06040v1",
      "title": "CGLearn: Consistent Gradient-Based Learning for Out-of-Distribution Generalization",
      "title_zh": "翻译失败",
      "authors": [
        "Jawad Chowdhury",
        "Gabriel Terejanu"
      ],
      "abstract": "Improving generalization and achieving highly predictive, robust machine\nlearning models necessitates learning the underlying causal structure of the\nvariables of interest. A prominent and effective method for this is learning\ninvariant predictors across multiple environments. In this work, we introduce a\nsimple yet powerful approach, CGLearn, which relies on the agreement of\ngradients across various environments. This agreement serves as a powerful\nindication of reliable features, while disagreement suggests less reliability\ndue to potential differences in underlying causal mechanisms. Our proposed\nmethod demonstrates superior performance compared to state-of-the-art methods\nin both linear and nonlinear settings across various regression and\nclassification tasks. CGLearn shows robust applicability even in the absence of\nseparate environments by exploiting invariance across different subsamples of\nobservational data. Comprehensive experiments on both synthetic and real-world\ndatasets highlight its effectiveness in diverse scenarios. Our findings\nunderscore the importance of leveraging gradient agreement for learning causal\ninvariance, providing a significant step forward in the field of robust machine\nlearning. The source code of the linear and nonlinear implementation of CGLearn\nis open-source and available at: https://github.com/hasanjawad001/CGLearn.",
      "tldr_zh": "该论文提出 CGLearn，一种基于梯度一致性的学习方法，用于提升机器学习模型的 Out-of-Distribution Generalization 能力，通过学习变量的底层因果结构来实现不变预测器。CGLearn 通过分析梯度在不同环境中的一致性来识别可靠特征，而不一致性则提示潜在的因果机制差异，并在线性、非线性设置下的回归和分类任务中表现出色。实验在合成和真实数据集上证明了其优于现有最先进方法的性能，即使在没有单独环境的情况下，也能通过子样本的观测数据利用不变性。开源代码可从 GitHub 获取。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "68T07",
        "I.2.6"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.06040v1",
      "published_date": "2024-11-09 02:36:39 UTC",
      "updated_date": "2024-11-09 02:36:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:05:00.337874"
    },
    {
      "arxiv_id": "2411.06034v1",
      "title": "CROPS: A Deployable Crop Management System Over All Possible State Availabilities",
      "title_zh": "翻译失败",
      "authors": [
        "Jing Wu",
        "Zhixin Lai",
        "Shengjie Liu",
        "Suiyao Chen",
        "Ran Tao",
        "Pan Zhao",
        "Chuyuan Tao",
        "Yikun Cheng",
        "Naira Hovakimyan"
      ],
      "abstract": "Exploring the optimal management strategy for nitrogen and irrigation has a\nsignificant impact on crop yield, economic profit, and the environment. To\ntackle this optimization challenge, this paper introduces a deployable\n\\textbf{CR}op Management system \\textbf{O}ver all \\textbf{P}ossible\n\\textbf{S}tate availabilities (CROPS). CROPS employs a language model (LM) as a\nreinforcement learning (RL) agent to explore optimal management strategies\nwithin the Decision Support System for Agrotechnology Transfer (DSSAT) crop\nsimulations. A distinguishing feature of this system is that the states used\nfor decision-making are partially observed through random masking.\nConsequently, the RL agent is tasked with two primary objectives: optimizing\nmanagement policies and inferring masked states. This approach significantly\nenhances the RL agent's robustness and adaptability across various real-world\nagricultural scenarios. Extensive experiments on maize crops in Florida, USA,\nand Zaragoza, Spain, validate the effectiveness of CROPS. Not only did CROPS\nachieve State-of-the-Art (SOTA) results across various evaluation metrics such\nas production, profit, and sustainability, but the trained management policies\nare also immediately deployable in over of ten millions of real-world contexts.\nFurthermore, the pre-trained policies possess a noise resilience property,\nwhich enables them to minimize potential sensor biases, ensuring robustness and\ngeneralizability. Finally, unlike previous methods, the strength of CROPS lies\nin its unified and elegant structure, which eliminates the need for pre-defined\nstates or multi-stage training. These advancements highlight the potential of\nCROPS in revolutionizing agricultural practices.",
      "tldr_zh": "本研究引入了CROPS系统，这是一个可部署的作物管理框架，旨在优化氮肥和灌溉策略，以提升作物产量、经济效益和环境可持续性。CROPS利用语言模型(LM)作为强化学习(RL)代理，在Decision Support System for Agrotechnology Transfer (DSSAT)模拟环境中探索最佳策略，同时通过随机掩码处理部分观察状态，使代理能够优化管理政策并推断缺失信息。实验在佛罗里达和萨拉戈萨的玉米作物上验证了其有效性，CROPS实现了State-of-the-Art (SOTA)结果，在生产、利润和可持续性指标上表现出色，且策略可直接部署于数百万真实场景。相比以往方法，CROPS的统一结构无需预定义状态或多阶段训练，并具备噪声鲁棒性，提高了实际农业应用的鲁棒性和泛化能力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.06034v1",
      "published_date": "2024-11-09 02:06:09 UTC",
      "updated_date": "2024-11-09 02:06:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:05:11.459632"
    },
    {
      "arxiv_id": "2411.06018v2",
      "title": "A Picture is Worth A Thousand Numbers: Enabling LLMs Reason about Time Series via Visualization",
      "title_zh": "翻译失败",
      "authors": [
        "Haoxin Liu",
        "Chenghao Liu",
        "B. Aditya Prakash"
      ],
      "abstract": "Large language models (LLMs), with demonstrated reasoning abilities across\nmultiple domains, are largely underexplored for time-series reasoning (TsR),\nwhich is ubiquitous in the real world. In this work, we propose TimerBed, the\nfirst comprehensive testbed for evaluating LLMs' TsR performance. Specifically,\nTimerBed includes stratified reasoning patterns with real-world tasks,\ncomprehensive combinations of LLMs and reasoning strategies, and various\nsupervised models as comparison anchors. We perform extensive experiments with\nTimerBed, test multiple current beliefs, and verify the initial failures of\nLLMs in TsR, evidenced by the ineffectiveness of zero shot (ZST) and\nperformance degradation of few shot in-context learning (ICL). Further, we\nidentify one possible root cause: the numerical modeling of data. To address\nthis, we propose a prompt-based solution VL-Time, using visualization-modeled\ndata and language-guided reasoning. Experimental results demonstrate that\nVl-Time enables multimodal LLMs to be non-trivial ZST and powerful ICL\nreasoners for time series, achieving about 140% average performance improvement\nand 99% average token costs reduction.",
      "tldr_zh": "本研究提出 TimerBed，这是第一个全面评估大型语言模型(LLMs)在时间序列推理(TsR)上的测试平台，涵盖分层推理模式、真实任务和基准模型，以揭示LLMs在TsR中的局限性，如零样本(ZST)无效和少样本学习(ICL)性能下降。研究发现，数据数值建模是主要根因，因此开发了VL-Time方法，通过可视化建模数据和语言引导推理来提升LLMs的TsR能力。实验结果显示，VL-Time使多模态LLMs的TsR性能平均提升约140%，并减少99%的令牌成本。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.06018v2",
      "published_date": "2024-11-09 00:35:29 UTC",
      "updated_date": "2025-04-25 16:39:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T23:05:24.029280"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 47,
  "processed_papers_count": 47,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-20T23:05:40.495687"
}