[
  {
    "arxiv_id": "2411.06315v1",
    "title": "NeuReg: Domain-invariant 3D Image Registration on Human and Mouse Brains",
    "authors": [
      "Taha Razzaq",
      "Asim Iqbal"
    ],
    "abstract": "Medical brain imaging relies heavily on image registration to accurately\ncurate structural boundaries of brain features for various healthcare\napplications. Deep learning models have shown remarkable performance in image\nregistration in recent years. Still, they often struggle to handle the\ndiversity of 3D brain volumes, challenged by their structural and contrastive\nvariations and their imaging domains. In this work, we present NeuReg, a\nNeuro-inspired 3D image registration architecture with the feature of domain\ninvariance. NeuReg generates domain-agnostic representations of imaging\nfeatures and incorporates a shifting window-based Swin Transformer block as the\nencoder. This enables our model to capture the variations across brain imaging\nmodalities and species. We demonstrate a new benchmark in multi-domain publicly\navailable datasets comprising human and mouse 3D brain volumes. Extensive\nexperiments reveal that our model (NeuReg) outperforms the existing baseline\ndeep learning-based image registration models and provides a high-performance\nboost on cross-domain datasets, where models are trained on 'source-only'\ndomain and tested on completely 'unseen' target domains. Our work establishes a\nnew state-of-the-art for domain-agnostic 3D brain image registration,\nunderpinned by Neuro-inspired Transformer-based architecture.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.NE",
      "q-bio.QM"
    ],
    "primary_category": "cs.CV",
    "comment": "15 pages, 5 figures, 5 tables",
    "pdf_url": "http://arxiv.org/pdf/2411.06315v1",
    "published_date": "2024-11-09 23:57:53 UTC",
    "updated_date": "2024-11-09 23:57:53 UTC"
  },
  {
    "arxiv_id": "2411.06306v1",
    "title": "Optimal Driver Warning Generation in Dynamic Driving Environment",
    "authors": [
      "Chenran Li",
      "Aolin Xu",
      "Enna Sachdeva",
      "Teruhisa Misu",
      "Behzad Dariush"
    ],
    "abstract": "The driver warning system that alerts the human driver about potential risks\nduring driving is a key feature of an advanced driver assistance system.\nExisting driver warning technologies, mainly the forward collision warning and\nunsafe lane change warning, can reduce the risk of collision caused by human\nerrors. However, the current design methods have several major limitations.\nFirstly, the warnings are mainly generated in a one-shot manner without\nmodeling the ego driver's reactions and surrounding objects, which reduces the\nflexibility and generality of the system over different scenarios.\nAdditionally, the triggering conditions of warning are mostly rule-based\nthreshold-checking given the current state, which lacks the prediction of the\npotential risk in a sufficiently long future horizon. In this work, we study\nthe problem of optimally generating driver warnings by considering the\ninteractions among the generated warning, the driver behavior, and the states\nof ego and surrounding vehicles on a long horizon. The warning generation\nproblem is formulated as a partially observed Markov decision process (POMDP).\nAn optimal warning generation framework is proposed as a solution to the\nproposed POMDP. The simulation experiments demonstrate the superiority of the\nproposed solution to the existing warning generation methods.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.RO",
    "comment": "ICRA 2024",
    "pdf_url": "http://arxiv.org/pdf/2411.06306v1",
    "published_date": "2024-11-09 23:04:19 UTC",
    "updated_date": "2024-11-09 23:04:19 UTC"
  },
  {
    "arxiv_id": "2411.06295v1",
    "title": "Analyzing the Evolution of Graphs and Texts",
    "authors": [
      "Xingzhi Guo"
    ],
    "abstract": "With the recent advance of representation learning algorithms on graphs\n(e.g., DeepWalk/GraphSage) and natural languages (e.g., Word2Vec/BERT) , the\nstate-of-the art models can even achieve human-level performance over many\ndownstream tasks, particularly for the task of node and sentence\nclassification. However, most algorithms focus on large-scale models for static\ngraphs and text corpus without considering the inherent dynamic characteristics\nor discovering the reasons behind the changes. This dissertation aims to\nefficiently model the dynamics in graphs (such as social networks and citation\ngraphs) and understand the changes in texts (specifically news titles and\npersonal biographies). To achieve this goal, we utilize the renowned\nPersonalized PageRank algorithm to create effective dynamic network embeddings\nfor evolving graphs. Our proposed approaches significantly improve the running\ntime and accuracy for both detecting network abnormal intruders and discovering\nentity meaning shifts over large-scale dynamic graphs. For text changes, we\nanalyze the post-publication changes in news titles to understand the intents\nbehind the edits and discuss the potential impact of titles changes from\ninformation integrity perspective. Moreover, we investigate self-presented\noccupational identities in Twitter users' biographies over five years,\ninvestigating job prestige and demographics effects in how people disclose\njobs, quantifying over-represented jobs and their transitions over time.",
    "categories": [
      "cs.SI",
      "cs.AI"
    ],
    "primary_category": "cs.SI",
    "comment": "PhD dissertation",
    "pdf_url": "http://arxiv.org/pdf/2411.06295v1",
    "published_date": "2024-11-09 21:39:41 UTC",
    "updated_date": "2024-11-09 21:39:41 UTC"
  },
  {
    "arxiv_id": "2411.06284v2",
    "title": "A Comprehensive Survey and Guide to Multimodal Large Language Models in Vision-Language Tasks",
    "authors": [
      "Chia Xin Liang",
      "Pu Tian",
      "Caitlyn Heqi Yin",
      "Yao Yua",
      "Wei An-Hou",
      "Li Ming",
      "Tianyang Wang",
      "Ziqian Bi",
      "Ming Liu"
    ],
    "abstract": "This survey and application guide to multimodal large language models(MLLMs)\nexplores the rapidly developing field of MLLMs, examining their architectures,\napplications, and impact on AI and Generative Models. Starting with\nfoundational concepts, we delve into how MLLMs integrate various data types,\nincluding text, images, video and audio, to enable complex AI systems for\ncross-modal understanding and generation. It covers essential topics such as\ntraining methods, architectural components, and practical applications in\nvarious fields, from visual storytelling to enhanced accessibility. Through\ndetailed case studies and technical analysis, the text examines prominent MLLM\nimplementations while addressing key challenges in scalability, robustness, and\ncross-modal learning. Concluding with a discussion of ethical considerations,\nresponsible AI development, and future directions, this authoritative resource\nprovides both theoretical frameworks and practical insights. It offers a\nbalanced perspective on the opportunities and challenges in the development and\ndeployment of MLLMs, and is highly valuable for researchers, practitioners, and\nstudents interested in the intersection of natural language processing and\ncomputer vision.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.06284v2",
    "published_date": "2024-11-09 20:56:23 UTC",
    "updated_date": "2024-12-08 06:48:30 UTC"
  },
  {
    "arxiv_id": "2411.06276v2",
    "title": "Multi-View Majority Vote Learning Algorithms: Direct Minimization of PAC-Bayesian Bounds",
    "authors": [
      "Mehdi Hennequin",
      "Abdelkrim Zitouni",
      "Khalid Benabdeslem",
      "Haytham Elghazel",
      "Yacine Gaci"
    ],
    "abstract": "The PAC-Bayesian framework has significantly advanced the understanding of\nstatistical learning, particularly for majority voting methods. Despite its\nsuccesses, its application to multi-view learning -- a setting with multiple\ncomplementary data representations -- remains underexplored. In this work, we\nextend PAC-Bayesian theory to multi-view learning, introducing novel\ngeneralization bounds based on R\\'enyi divergence. These bounds provide an\nalternative to traditional Kullback-Leibler divergence-based counterparts,\nleveraging the flexibility of R\\'enyi divergence. Furthermore, we propose\nfirst- and second-order oracle PAC-Bayesian bounds and extend the C-bound to\nmulti-view settings. To bridge theory and practice, we design efficient\nself-bounding optimization algorithms that align with our theoretical results.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.06276v2",
    "published_date": "2024-11-09 20:25:47 UTC",
    "updated_date": "2025-01-02 23:44:44 UTC"
  },
  {
    "arxiv_id": "2411.08060v2",
    "title": "FuzzRisk: Online Collision Risk Estimation for Autonomous Vehicles based on Depth-Aware Object Detection via Fuzzy Inference",
    "authors": [
      "Brian Hsuan-Cheng Liao",
      "Yingjie Xu",
      "Chih-Hong Cheng",
      "Hasan Esen",
      "Alois Knoll"
    ],
    "abstract": "This paper presents a novel monitoring framework that infers the level of\ncollision risk for autonomous vehicles (AVs) based on their object detection\nperformance. The framework takes two sets of predictions from different\nalgorithms and associates their inconsistencies with the collision risk via\nfuzzy inference. The first set of predictions is obtained by retrieving\nsafety-critical 2.5D objects from a depth map, and the second set comes from\nthe ordinary AV's 3D object detector. We experimentally validate that, based on\nIntersection-over-Union (IoU) and a depth discrepancy measure, the\ninconsistencies between the two sets of predictions strongly correlate to the\nerror of the 3D object detector against ground truths. This correlation allows\nus to construct a fuzzy inference system and map the inconsistency measures to\nan AV collision risk indicator. In particular, we optimize the fuzzy inference\nsystem towards an existing offline metric that matches AV collision rates well.\nLastly, we validate our monitor's capability to produce relevant risk estimates\nwith the large-scale nuScenes dataset and demonstrate that it can safeguard an\nAV in closed-loop simulations.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted by ICRA 2025, 7 pages (IEEE double column format), 5\n  figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2411.08060v2",
    "published_date": "2024-11-09 20:20:36 UTC",
    "updated_date": "2025-02-19 10:49:11 UTC"
  },
  {
    "arxiv_id": "2411.06269v4",
    "title": "AI's Spatial Intelligence: Evaluating AI's Understanding of Spatial Transformations in PSVT:R and Augmented Reality",
    "authors": [
      "Uttamasha Monjoree",
      "Wei Yan"
    ],
    "abstract": "Spatial intelligence is important in Architecture, Construction, Science,\nTechnology, Engineering, and Mathematics (STEM), and Medicine. Understanding\nthree-dimensional (3D) spatial rotations can involve verbal descriptions and\nvisual or interactive examples, illustrating how objects change orientation in\n3D space. Recent studies show Artificial Intelligence (AI) with language and\nvision capabilities still face limitations in spatial reasoning. In this paper,\nwe have studied generative AI's spatial capabilities of understanding rotations\nof objects utilizing its image and language processing features. We examined\nthe spatial intelligence of the GPT-4 model with vision in understanding\nspatial rotation process with diagrams based on the Revised Purdue Spatial\nVisualization Test: Visualization of Rotations (Revised PSVT:R). Next, we\nincorporated a layer of coordinate system axes on Revised PSVT:R to study the\nvariations in GPT-4's performance. We also examined GPT-4's understanding of 3D\nrotations in Augmented Reality (AR) scenes that visualize spatial rotations of\nan object in 3D space and observed increased accuracy of GPT-4's understanding\nof the rotations by adding supplementary textual information depicting the\nrotation process or mathematical representations of the rotation (e.g.,\nmatrices). The results indicate that while GPT-4 as a major current Generative\nAI model lacks the understanding of a spatial rotation process, it has the\npotential to understand the rotation process with additional information that\ncan be provided by methods such as AR. By combining the potentials in spatial\nintelligence of AI with AR's interactive visualization abilities, we expect to\noffer enhanced guidance for students' spatial learning activities. Such spatial\nguidance can benefit understanding spatial transformations and additionally\nsupport processes like assembly, fabrication, and manufacturing.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.06269v4",
    "published_date": "2024-11-09 19:53:15 UTC",
    "updated_date": "2025-03-16 03:24:05 UTC"
  },
  {
    "arxiv_id": "2411.06264v1",
    "title": "GuidelineGuard: An Agentic Framework for Medical Note Evaluation with Guideline Adherence",
    "authors": [
      "MD Ragib Shahriyear"
    ],
    "abstract": "Although rapid advancements in Large Language Models (LLMs) are facilitating\nthe integration of artificial intelligence-based applications and services in\nhealthcare, limited research has focused on the systematic evaluation of\nmedical notes for guideline adherence. This paper introduces GuidelineGuard, an\nagentic framework powered by LLMs that autonomously analyzes medical notes,\nsuch as hospital discharge and office visit notes, to ensure compliance with\nestablished healthcare guidelines. By identifying deviations from recommended\npractices and providing evidence-based suggestions, GuidelineGuard helps\nclinicians adhere to the latest standards from organizations like the WHO and\nCDC. This framework offers a novel approach to improving documentation quality\nand reducing clinical errors.",
    "categories": [
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.06264v1",
    "published_date": "2024-11-09 19:32:26 UTC",
    "updated_date": "2024-11-09 19:32:26 UTC"
  },
  {
    "arxiv_id": "2411.06263v1",
    "title": "Federated Split Learning for Human Activity Recognition with Differential Privacy",
    "authors": [
      "Josue Ndeko",
      "Shaba Shaon",
      "Aubrey Beal",
      "Avimanyu Sahoo",
      "Dinh C. Nguyen"
    ],
    "abstract": "This paper proposes a novel intelligent human activity recognition (HAR)\nframework based on a new design of Federated Split Learning (FSL) with\nDifferential Privacy (DP) over edge networks. Our FSL-DP framework leverages\nboth accelerometer and gyroscope data, achieving significant improvements in\nHAR accuracy. The evaluation includes a detailed comparison between traditional\nFederated Learning (FL) and our FSL framework, showing that the FSL framework\noutperforms FL models in both accuracy and loss metrics. Additionally, we\nexamine the privacy-performance trade-off under different data settings in the\nDP mechanism, highlighting the balance between privacy guarantees and model\naccuracy. The results also indicate that our FSL framework achieves faster\ncommunication times per training round compared to traditional FL, further\nemphasizing its efficiency and effectiveness. This work provides valuable\ninsight and a novel framework which was tested on a real-life dataset.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to IEEE Consumer Communications and Networking Conference\n  (CCNC), 6 pages",
    "pdf_url": "http://arxiv.org/pdf/2411.06263v1",
    "published_date": "2024-11-09 19:32:23 UTC",
    "updated_date": "2024-11-09 19:32:23 UTC"
  },
  {
    "arxiv_id": "2411.07269v1",
    "title": "Learning From Graph-Structured Data: Addressing Design Issues and Exploring Practical Applications in Graph Representation Learning",
    "authors": [
      "Chenqing Hua"
    ],
    "abstract": "Graphs serve as fundamental descriptors for systems composed of interacting\nelements, capturing a wide array of data types, from molecular interactions to\nsocial networks and knowledge graphs. In this paper, we present an exhaustive\nreview of the latest advancements in graph representation learning and Graph\nNeural Networks (GNNs). GNNs, tailored to handle graph-structured data, excel\nin deriving insights and predictions from intricate relational information,\nmaking them invaluable for tasks involving such data. Graph representation\nlearning, a pivotal approach in analyzing graph-structured data, facilitates\nnumerous downstream tasks and applications across machine learning, data\nmining, biomedicine, and healthcare.\n  Our work delves into the capabilities of GNNs, examining their foundational\ndesigns and their application in addressing real-world challenges. We introduce\na GNN equipped with an advanced high-order pooling function, adept at capturing\ncomplex node interactions within graph-structured data. This pooling function\nsignificantly enhances the GNN's efficacy in both node- and graph-level tasks.\nAdditionally, we propose a molecular graph generative model with a GNN as its\ncore framework. This GNN backbone is proficient in learning invariant and\nequivariant molecular characteristics. Employing these features, the molecular\ngraph generative model is capable of simultaneously learning and generating\nmolecular graphs with atom-bond structures and precise atom positions. Our\nmodels undergo thorough experimental evaluations and comparisons with\nestablished methods, showcasing their superior performance in addressing\ndiverse real-world challenges with various datasets.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "arXiv admin note: text overlap with arXiv:2205.11691,\n  arXiv:2304.14621",
    "pdf_url": "http://arxiv.org/pdf/2411.07269v1",
    "published_date": "2024-11-09 19:10:33 UTC",
    "updated_date": "2024-11-09 19:10:33 UTC"
  },
  {
    "arxiv_id": "2411.06253v1",
    "title": "Knowledge Authoring with Factual English, Rules, and Actions",
    "authors": [
      "Yuheng Wang"
    ],
    "abstract": "Knowledge representation and reasoning systems represent knowledge as\ncollections of facts and rules. KRRs can represent complex concepts and\nrelations, and they can query and manipulate information in sophisticated ways.\nUnfortunately, the KRR technology has been hindered by the fact that specifying\nthe requisite knowledge requires skills that most domain experts do not have,\nand professional knowledge engineers are hard to find. Some recent CNL-based\napproaches, such as the Knowledge Authoring Logic Machine (KALM), have shown to\nhave very high accuracy compared to others, and a natural question is to what\nextent the CNL restrictions can be lifted. Besides the CNL restrictions, KALM\nhas limitations in terms of the types of knowledge it can represent. To address\nthese issues, we propose an extension of KALM called KALM for Factual Language\n(KALMF). KALMF uses a neural parser for natural language, MS, to parse what we\ncall factual English sentences, which require little grammar training to use.\nBuilding upon KALMF, we propose KALM for Rules and Actions (KALMR), to\nrepresent and reason with rules and actions. Furthermore, we identify the\nreasons behind the slow speed of KALM and make optimizations to address this\nissue. Our evaluation using multiple benchmarks shows that our approaches\nachieve a high level of correctness on fact and query authoring (95%) and on\nrule authoring (100%). When used for authoring and reasoning with actions, our\napproach achieves more than 99.3% correctness, demonstrating its effectiveness\nin enabling more sophisticated knowledge representation and reasoning. We also\nillustrate the logical reasoning capabilities of our approach by drawing\nattention to the problems faced by the famous AI, ChatGPT. Finally, the\nevaluation of the newly proposed speed optimization points not only to a 68%\nruntime improvement but also yields better accuracy of the overall system.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "PhD thesis",
    "pdf_url": "http://arxiv.org/pdf/2411.06253v1",
    "published_date": "2024-11-09 19:01:34 UTC",
    "updated_date": "2024-11-09 19:01:34 UTC"
  },
  {
    "arxiv_id": "2411.06251v2",
    "title": "Quasi-random Multi-Sample Inference for Large Language Models",
    "authors": [
      "Aditya Parashar",
      "Aditya Vikram Singh",
      "Avinash Amballa",
      "Jinlin Lai",
      "Benjamin Rozonoyer"
    ],
    "abstract": "Large language models (LLMs) are often equipped with multi-sample decoding\nstrategies. An LLM implicitly defines an arithmetic code book, facilitating\nefficient and embarrassingly parallelizable \\textbf{arithmetic sampling} to\nproduce multiple samples using quasi-random codes. Traditional text generation\nmethods, such as beam search and sampling-based techniques, have notable\nlimitations: they lack parallelizability or diversity of sampled sequences.\nThis study explores the potential of arithmetic sampling, contrasting it with\nancestral sampling across two decoding tasks that employ multi-sample\ninference: chain-of-thought reasoning with self-consistency and machine\ntranslation with minimum Bayes risk decoding. Our results demonstrate that\narithmetic sampling produces more diverse samples, significantly improving\nreasoning and translation performance as the sample size increases. We observe\na $\\mathbf{3\\text{-}5\\%}$ point increase in accuracy on the GSM8K dataset and a\n$\\mathbf{0.45\\text{-}0.89\\%}$ point increment in COMET score for WMT19 tasks\nusing arithmetic sampling without any significant computational overhead.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.06251v2",
    "published_date": "2024-11-09 18:55:04 UTC",
    "updated_date": "2025-04-27 21:28:16 UTC"
  },
  {
    "arxiv_id": "2411.06229v1",
    "title": "Multimodal Contrastive Learning of Urban Space Representations from POI Data",
    "authors": [
      "Xinglei Wang",
      "Tao Cheng",
      "Stephen Law",
      "Zichao Zeng",
      "Lu Yin",
      "Junyuan Liu"
    ],
    "abstract": "Existing methods for learning urban space representations from\nPoint-of-Interest (POI) data face several limitations, including issues with\ngeographical delineation, inadequate spatial information modelling,\nunderutilisation of POI semantic attributes, and computational inefficiencies.\nTo address these issues, we propose CaLLiPer (Contrastive Language-Location\nPre-training), a novel representation learning model that directly embeds\ncontinuous urban spaces into vector representations that can capture the\nspatial and semantic distribution of urban environment. This model leverages a\nmultimodal contrastive learning objective, aligning location embeddings with\ntextual POI descriptions, thereby bypassing the need for complex training\ncorpus construction and negative sampling. We validate CaLLiPer's effectiveness\nby applying it to learning urban space representations in London, UK, where it\ndemonstrates 5-15% improvement in predictive performance for land use\nclassification and socioeconomic mapping tasks compared to state-of-the-art\nmethods. Visualisations of the learned representations further illustrate our\nmodel's advantages in capturing spatial variations in urban semantics with high\naccuracy and fine resolution. Additionally, CaLLiPer achieves reduced training\ntime, showcasing its efficiency and scalability. This work provides a promising\npathway for scalable, semantically rich urban space representation learning\nthat can support the development of geospatial foundation models. The\nimplementation code is available at https://github.com/xlwang233/CaLLiPer.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "19 pages, 5 figures, 7 tables",
    "pdf_url": "http://arxiv.org/pdf/2411.06229v1",
    "published_date": "2024-11-09 16:24:07 UTC",
    "updated_date": "2024-11-09 16:24:07 UTC"
  },
  {
    "arxiv_id": "2411.07268v2",
    "title": "Target-driven Attack for Large Language Models",
    "authors": [
      "Chong Zhang",
      "Mingyu Jin",
      "Dong Shu",
      "Taowen Wang",
      "Dongfang Liu",
      "Xiaobo Jin"
    ],
    "abstract": "Current large language models (LLM) provide a strong foundation for\nlarge-scale user-oriented natural language tasks. Many users can easily inject\nadversarial text or instructions through the user interface, thus causing LLM\nmodel security challenges like the language model not giving the correct\nanswer. Although there is currently a large amount of research on black-box\nattacks, most of these black-box attacks use random and heuristic strategies.\nIt is unclear how these strategies relate to the success rate of attacks and\nthus effectively improve model robustness. To solve this problem, we propose\nour target-driven black-box attack method to maximize the KL divergence between\nthe conditional probabilities of the clean text and the attack text to redefine\nthe attack's goal. We transform the distance maximization problem into two\nconvex optimization problems based on the attack goal to solve the attack text\nand estimate the covariance. Furthermore, the projected gradient descent\nalgorithm solves the vector corresponding to the attack text. Our target-driven\nblack-box attack approach includes two attack strategies: token manipulation\nand misinformation attack. Experimental results on multiple Large Language\nModels and datasets demonstrate the effectiveness of our attack method.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "12 pages, 7 figures. This work is an extension of the\n  arXiv:2404.07234 work. We propose new methods. 27th European Conference on\n  Artificial Intelligence 2024",
    "pdf_url": "http://arxiv.org/pdf/2411.07268v2",
    "published_date": "2024-11-09 15:59:59 UTC",
    "updated_date": "2024-11-13 11:28:07 UTC"
  },
  {
    "arxiv_id": "2411.06221v1",
    "title": "Smart-LLaMA: Two-Stage Post-Training of Large Language Models for Smart Contract Vulnerability Detection and Explanation",
    "authors": [
      "Lei Yu",
      "Shiqi Chen",
      "Hang Yuan",
      "Peng Wang",
      "Zhirong Huang",
      "Jingyuan Zhang",
      "Chenjie Shen",
      "Fengjun Zhang",
      "Li Yang",
      "Jiajia Ma"
    ],
    "abstract": "With the rapid development of blockchain technology, smart contract security\nhas become a critical challenge. Existing smart contract vulnerability\ndetection methods face three main issues: (1) Insufficient quality of datasets,\nlacking detailed explanations and precise vulnerability locations. (2) Limited\nadaptability of large language models (LLMs) to the smart contract domain, as\nmost LLMs are pre-trained on general text data but minimal smart\ncontract-specific data. (3) Lack of high-quality explanations for detected\nvulnerabilities, as existing methods focus solely on detection without clear\nexplanations. These limitations hinder detection performance and make it harder\nfor developers to understand and fix vulnerabilities quickly, potentially\nleading to severe financial losses. To address these problems, we propose\nSmart-LLaMA, an advanced detection method based on the LLaMA language model.\nFirst, we construct a comprehensive dataset covering four vulnerability types\nwith labels, detailed explanations, and precise vulnerability locations.\nSecond, we introduce Smart Contract-Specific Continual Pre-Training, using raw\nsmart contract data to enable the LLM to learn smart contract syntax and\nsemantics, enhancing their domain adaptability. Furthermore, we propose\nExplanation-Guided Fine-Tuning, which fine-tunes the LLM using paired\nvulnerable code and explanations, enabling both vulnerability detection and\nreasoned explanations. We evaluate explanation quality through LLM and human\nevaluation, focusing on Correctness, Completeness, and Conciseness.\nExperimental results show that Smart-LLaMA outperforms state-of-the-art\nbaselines, with average improvements of 6.49% in F1 score and 3.78% in\naccuracy, while providing reliable explanations.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.06221v1",
    "published_date": "2024-11-09 15:49:42 UTC",
    "updated_date": "2024-11-09 15:49:42 UTC"
  },
  {
    "arxiv_id": "2411.06212v1",
    "title": "Multistage non-deterministic classification using secondary concept graphs and graph convolutional networks for high-level feature extraction",
    "authors": [
      "Masoud Kargar",
      "Nasim Jelodari",
      "Alireza Assadzadeh"
    ],
    "abstract": "Graphs, comprising nodes and edges, visually depict relationships and\nstructures, posing challenges in extracting high-level features due to their\nintricate connections. Multiple connections introduce complexities in\ndiscovering patterns, where node weights may affect some features more than\nothers. In domains with diverse topics, graph representations illustrate\ninterrelations among features. Pattern discovery within graphs is recognized as\nNP-hard. Graph Convolutional Networks (GCNs) are a prominent deep learning\napproach for acquiring meaningful representations by leveraging node\nconnectivity and characteristics. Despite achievements, predicting and\nassigning 9 deterministic classes often involves errors. To address this\nchallenge, we present a multi-stage non-deterministic classification method\nbased on a secondary conceptual graph and graph convolutional networks, which\nincludes distinct steps: 1) leveraging GCN for the extraction and generation of\n12 high-level features: 2) employing incomplete, non-deterministic models for\nfeature extraction, conducted before reaching a definitive prediction: and 3)\nformulating definitive forecasts grounded in conceptual (logical) graphs. The\nempirical findings indicate that our proposed approach outperforms contemporary\nmethods in classification tasks. Across three datasets Cora, Citeseer, and\nPubMed the achieved accuracies are 96%, 93%, and 95%, respectively. Code is\navailable at https://github.com/MasoudKargar.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "13 Pages, 15 figures, and 4 Tables",
    "pdf_url": "http://arxiv.org/pdf/2411.06212v1",
    "published_date": "2024-11-09 15:28:45 UTC",
    "updated_date": "2024-11-09 15:28:45 UTC"
  },
  {
    "arxiv_id": "2411.06211v1",
    "title": "Artificial Intelligence for Collective Intelligence: A National-Scale Research Strategy",
    "authors": [
      "Seth Bullock",
      "Nirav Ajmeri",
      "Mike Batty",
      "Michaela Black",
      "John Cartlidge",
      "Robert Challen",
      "Cangxiong Chen",
      "Jing Chen",
      "Joan Condell",
      "Leon Danon",
      "Adam Dennett",
      "Alison Heppenstall",
      "Paul Marshall",
      "Phil Morgan",
      "Aisling O'Kane",
      "Laura G. E. Smith",
      "Theresa Smith",
      "Hywel T. P. Williams"
    ],
    "abstract": "Advances in artificial intelligence (AI) have great potential to help address\nsocietal challenges that are both collective in nature and present at national\nor trans-national scale. Pressing challenges in healthcare, finance,\ninfrastructure and sustainability, for instance, might all be productively\naddressed by leveraging and amplifying AI for national-scale collective\nintelligence. The development and deployment of this kind of AI faces\ndistinctive challenges, both technical and socio-technical. Here, a research\nstrategy for mobilising inter-disciplinary research to address these challenges\nis detailed and some of the key issues that must be faced are outlined.",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "25 pages, 3 figures, Accepted for publication at Knowledge\n  Engineering Review (KER)",
    "pdf_url": "http://arxiv.org/pdf/2411.06211v1",
    "published_date": "2024-11-09 15:25:43 UTC",
    "updated_date": "2024-11-09 15:25:43 UTC"
  },
  {
    "arxiv_id": "2411.06208v2",
    "title": "IOPO: Empowering LLMs with Complex Instruction Following via Input-Output Preference Optimization",
    "authors": [
      "Xinghua Zhang",
      "Haiyang Yu",
      "Cheng Fu",
      "Fei Huang",
      "Yongbin Li"
    ],
    "abstract": "In the realm of large language models (LLMs), the ability of models to\naccurately follow instructions is paramount as more agents and applications\nleverage LLMs for construction, where the complexity of instructions are\nrapidly increasing. However, on the one hand, there is only a certain amount of\ncomplex instruction evaluation data; on the other hand, there are no dedicated\nalgorithms to improve the ability to follow complex instructions. To this end,\nthis paper introduces TRACE, a benchmark for improving and evaluating the\ncomplex instructionfollowing ability, which consists of 120K training data and\n1K evaluation data. Furthermore, we propose IOPO (Input-Output Preference\nOptimization) alignment method which takes both input and output preference\npairs into consideration, where LLMs not only rapidly align with response\npreferences but also meticulously explore the instruction preferences.\nExtensive experiments on both in-domain and outof-domain datasets confirm the\neffectiveness of IOPO, showing 8.15%, 2.18% improvements on in-domain data and\n6.29%, 3.13% on outof-domain data compared to SFT and DPO respectively.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Work in progress",
    "pdf_url": "http://arxiv.org/pdf/2411.06208v2",
    "published_date": "2024-11-09 15:12:43 UTC",
    "updated_date": "2024-11-27 07:29:59 UTC"
  },
  {
    "arxiv_id": "2411.07267v1",
    "title": "A Survey on Data Markets",
    "authors": [
      "Jiayao Zhang",
      "Yuran Bi",
      "Mengye Cheng",
      "Jinfei Liu",
      "Kui Ren",
      "Qiheng Sun",
      "Yihang Wu",
      "Yang Cao",
      "Raul Castro Fernandez",
      "Haifeng Xu",
      "Ruoxi Jia",
      "Yongchan Kwon",
      "Jian Pei",
      "Jiachen T. Wang",
      "Haocheng Xia",
      "Li Xiong",
      "Xiaohui Yu",
      "James Zou"
    ],
    "abstract": "Data is the new oil of the 21st century. The growing trend of trading data\nfor greater welfare has led to the emergence of data markets. A data market is\nany mechanism whereby the exchange of data products including datasets and data\nderivatives takes place as a result of data buyers and data sellers being in\ncontact with one another, either directly or through mediating agents. It\nserves as a coordinating mechanism by which several functions, including the\npricing and the distribution of data as the most important ones, interact to\nmake the value of data fully exploited and enhanced. In this article, we\npresent a comprehensive survey of this important and emerging direction from\nthe aspects of data search, data productization, data transaction, data\npricing, revenue allocation as well as privacy, security, and trust issues. We\nalso investigate the government policies and industry status of data markets\nacross different countries and different domains. Finally, we identify the\nunresolved challenges and discuss possible future directions for the\ndevelopment of data markets.",
    "categories": [
      "cs.GT",
      "cs.AI",
      "cs.DB"
    ],
    "primary_category": "cs.GT",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.07267v1",
    "published_date": "2024-11-09 15:09:24 UTC",
    "updated_date": "2024-11-09 15:09:24 UTC"
  },
  {
    "arxiv_id": "2411.06198v1",
    "title": "OpenAI-o1 AB Testing: Does the o1 model really do good reasoning in math problem solving?",
    "authors": [
      "Leo Li",
      "Ye Luo",
      "Tingyou Pan"
    ],
    "abstract": "The Orion-1 model by OpenAI is claimed to have more robust logical reasoning\ncapabilities than previous large language models. However, some suggest the\nexcellence might be partially due to the model \"memorizing\" solutions,\nresulting in less satisfactory performance when prompted with problems not in\nthe training data. We conduct a comparison experiment using two datasets: one\nconsisting of International Mathematics Olympiad (IMO) problems, which is\neasily accessible; the other one consisting of Chinese National Team Training\ncamp (CNT) problems, which have similar difficulty but not as publically\naccessible. We label the response for each problem and compare the performance\nbetween the two datasets. We conclude that there is no significant evidence to\nshow that the model relies on memorizing problems and solutions. Also, we\nperform case studies to analyze some features of the model's response.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.06198v1",
    "published_date": "2024-11-09 14:47:52 UTC",
    "updated_date": "2024-11-09 14:47:52 UTC"
  },
  {
    "arxiv_id": "2411.06191v1",
    "title": "Generalizing Hyperedge Expansion for Hyper-relational Knowledge Graph Modeling",
    "authors": [
      "Yu Liu",
      "Shu Yang",
      "Jingtao Ding",
      "Quanming Yao",
      "Yong Li"
    ],
    "abstract": "By representing knowledge in a primary triple associated with additional\nattribute-value qualifiers, hyper-relational knowledge graph (HKG) that\ngeneralizes triple-based knowledge graph (KG) has been attracting research\nattention recently. Compared with KG, HKG is enriched with the semantic\nqualifiers as well as the hyper-relational graph structure. However, to model\nHKG, existing studies mainly focus on either semantic information or structural\ninformation therein, which however fail to capture both simultaneously. To\ntackle this issue, in this paper, we generalize the hyperedge expansion in\nhypergraph learning and propose an equivalent transformation for HKG modeling,\nreferred to as TransEQ. Specifically, the equivalent transformation transforms\na HKG to a KG, which considers both semantic and structural characteristics.\nThen an encoder-decoder framework is developed to bridge the modeling research\nbetween KG and HKG. In the encoder part, KG-based graph neural networks are\nleveraged for structural modeling; while in the decoder part, various HKG-based\nscoring functions are exploited for semantic modeling. Especially, we design\nthe sharing embedding mechanism in the encoder-decoder framework with semantic\nrelatedness captured. We further theoretically prove that TransEQ preserves\ncomplete information in the equivalent transformation, and also achieves full\nexpressivity. Finally, extensive experiments on three benchmarks demonstrate\nthe superior performance of TransEQ in terms of both effectiveness and\nefficiency. On the largest benchmark WikiPeople, TransEQ significantly improves\nthe state-of-the-art models by 15\\% on MRR.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.06191v1",
    "published_date": "2024-11-09 14:16:41 UTC",
    "updated_date": "2024-11-09 14:16:41 UTC"
  },
  {
    "arxiv_id": "2411.06160v2",
    "title": "Expansion Quantization Network: An Efficient Micro-emotion Annotation and Detection Framework",
    "authors": [
      "Jingyi Zhou",
      "Senlin Luo",
      "Haofan Chen"
    ],
    "abstract": "Text emotion detection constitutes a crucial foundation for advancing\nartificial intelligence from basic comprehension to the exploration of\nemotional reasoning. Most existing emotion detection datasets rely on manual\nannotations, which are associated with high costs, substantial subjectivity,\nand severe label imbalances. This is particularly evident in the inadequate\nannotation of micro-emotions and the absence of emotional intensity\nrepresentation, which fail to capture the rich emotions embedded in sentences\nand adversely affect the quality of downstream task completion. By proposing an\nall-labels and training-set label regression method, we map label values to\nenergy intensity levels, thereby fully leveraging the learning capabilities of\nmachine models and the interdependencies among labels to uncover multiple\nemotions within samples. This led to the establishment of the Emotion\nQuantization Network (EQN) framework for micro-emotion detection and\nannotation. Using five commonly employed sentiment datasets, we conducted\ncomparative experiments with various models, validating the broad applicability\nof our framework within NLP machine learning models. Based on the EQN\nframework, emotion detection and annotation are conducted on the GoEmotions\ndataset. A comprehensive comparison with the results from Google literature\ndemonstrates that the EQN framework possesses a high capability for automatic\ndetection and annotation of micro-emotions. The EQN framework is the first to\nachieve automatic micro-emotion annotation with energy-level scores, providing\nstrong support for further emotion detection analysis and the quantitative\nresearch of emotion computing.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "3.1 There is a misstatement in the EQN Framework section",
    "pdf_url": "http://arxiv.org/pdf/2411.06160v2",
    "published_date": "2024-11-09 12:09:26 UTC",
    "updated_date": "2025-02-27 09:06:45 UTC"
  },
  {
    "arxiv_id": "2411.06148v1",
    "title": "Deep Reinforcement Learning for Digital Twin-Oriented Complex Networked Systems",
    "authors": [
      "Jiaqi Wen",
      "Bogdan Gabrys",
      "Katarzyna Musial"
    ],
    "abstract": "The Digital Twin Oriented Complex Networked System (DT-CNS) aims to build and\nextend a Complex Networked System (CNS) model with progressively increasing\ndynamics complexity towards an accurate reflection of reality -- a Digital Twin\nof reality. Our previous work proposed evolutionary DT-CNSs to model the\nlong-term adaptive network changes in an epidemic outbreak. This study extends\nthis framework by proposeing the temporal DT-CNS model, where reinforcement\nlearning-driven nodes make decisions on temporal directed interactions in an\nepidemic outbreak. We consider cooperative nodes, as well as egocentric and\nignorant \"free-riders\" in the cooperation. We describe this epidemic spreading\nprocess with the Susceptible-Infected-Recovered ($SIR$) model and investigate\nthe impact of epidemic severity on the epidemic resilience for different types\nof nodes. Our experimental results show that (i) the full cooperation leads to\na higher reward and lower infection number than a cooperation with egocentric\nor ignorant \"free-riders\"; (ii) an increasing number of \"free-riders\" in a\ncooperation leads to a smaller reward, while an increasing number of egocentric\n\"free-riders\" further escalate the infection numbers and (iii) higher infection\nrates and a slower recovery weakens networks' resilience to severe epidemic\noutbreaks. These findings also indicate that promoting cooperation and reducing\n\"free-riders\" can improve public health during epidemics.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.06148v1",
    "published_date": "2024-11-09 11:24:42 UTC",
    "updated_date": "2024-11-09 11:24:42 UTC"
  },
  {
    "arxiv_id": "2411.06146v1",
    "title": "AI-Compass: A Comprehensive and Effective Multi-module Testing Tool for AI Systems",
    "authors": [
      "Zhiyu Zhu",
      "Zhibo Jin",
      "Hongsheng Hu",
      "Minhui Xue",
      "Ruoxi Sun",
      "Seyit Camtepe",
      "Praveen Gauravaram",
      "Huaming Chen"
    ],
    "abstract": "AI systems, in particular with deep learning techniques, have demonstrated\nsuperior performance for various real-world applications. Given the need for\ntailored optimization in specific scenarios, as well as the concerns related to\nthe exploits of subsurface vulnerabilities, a more comprehensive and in-depth\ntesting AI system becomes a pivotal topic. We have seen the emergence of\ntesting tools in real-world applications that aim to expand testing\ncapabilities. However, they often concentrate on ad-hoc tasks, rendering them\nunsuitable for simultaneously testing multiple aspects or components.\nFurthermore, trustworthiness issues arising from adversarial attacks and the\nchallenge of interpreting deep learning models pose new challenges for\ndeveloping more comprehensive and in-depth AI system testing tools. In this\nstudy, we design and implement a testing tool, \\tool, to comprehensively and\neffectively evaluate AI systems. The tool extensively assesses multiple\nmeasurements towards adversarial robustness, model interpretability, and\nperforms neuron analysis. The feasibility of the proposed testing tool is\nthoroughly validated across various modalities, including image classification,\nobject detection, and text classification. Extensive experiments demonstrate\nthat \\tool is the state-of-the-art tool for a comprehensive assessment of the\nrobustness and trustworthiness of AI systems. Our research sheds light on a\ngeneral solution for AI systems testing landscape.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.06146v1",
    "published_date": "2024-11-09 11:15:17 UTC",
    "updated_date": "2024-11-09 11:15:17 UTC"
  },
  {
    "arxiv_id": "2411.06142v1",
    "title": "Aquila-plus: Prompt-Driven Visual-Language Models for Pixel-Level Remote Sensing Image Understanding",
    "authors": [
      "Kaixuan Lu"
    ],
    "abstract": "The recent development of vision language models (VLMs) has led to\nsignificant advances in visual-language integration through visual instruction\ntuning, and they have rapidly evolved in the field of remote sensing image\nunderstanding, demonstrating their powerful capabilities. However, existing\nRSVLMs mainly focus on image-level or frame-level understanding, making it\ndifficult to achieve fine-grained pixel-level visual-language alignment.\nAdditionally, the lack of mask-based instructional data limits their further\ndevelopment. In this paper, we propose a mask-text instruction tuning method\ncalled Aquila-plus, which extends the capabilities of RSVLMs to achieve\npixel-level visual understanding by incorporating fine-grained mask regions\ninto language instructions. To achieve this, we first meticulously constructed\na mask region-text dataset containing 100K samples, and then designed a\nvisual-language model by injecting pixel-level representations into a large\nlanguage model (LLM). Specifically, Aquila-plus uses a convolutional CLIP as\nthe visual encoder and employs a mask-aware visual extractor to extract precise\nvisual mask features from high-resolution inputs. Experimental results\ndemonstrate that Aquila-plus outperforms existing methods in various region\nunderstanding tasks, showcasing its novel capabilities in pixel-level\ninstruction tuning.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.06142v1",
    "published_date": "2024-11-09 10:42:57 UTC",
    "updated_date": "2024-11-09 10:42:57 UTC"
  },
  {
    "arxiv_id": "2411.06135v1",
    "title": "Online Parallel Multi-Task Relationship Learning via Alternating Direction Method of Multipliers",
    "authors": [
      "Ruiyu Li",
      "Peilin Zhao",
      "Guangxia Li",
      "Zhiqiang Xu",
      "Xuewei Li"
    ],
    "abstract": "Online multi-task learning (OMTL) enhances streaming data processing by\nleveraging the inherent relations among multiple tasks. It can be described as\nan optimization problem in which a single loss function is defined for multiple\ntasks. Existing gradient-descent-based methods for this problem might suffer\nfrom gradient vanishing and poor conditioning issues. Furthermore, the\ncentralized setting hinders their application to online parallel optimization,\nwhich is vital to big data analytics. Therefore, this study proposes a novel\nOMTL framework based on the alternating direction multiplier method (ADMM), a\nrecent breakthrough in optimization suitable for the distributed computing\nenvironment because of its decomposable and easy-to-implement nature. The\nrelations among multiple tasks are modeled dynamically to fit the constant\nchanges in an online scenario. In a classical distributed computing\narchitecture with a central server, the proposed OMTL algorithm with the ADMM\noptimizer outperforms SGD-based approaches in terms of accuracy and efficiency.\nBecause the central server might become a bottleneck when the data scale grows,\nwe further tailor the algorithm to a decentralized setting, so that each node\ncan work by only exchanging information with local neighbors. Experimental\nresults on a synthetic and several real-world datasets demonstrate the\nefficiency of our methods.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "Accpeted by Neurocomputing",
    "pdf_url": "http://arxiv.org/pdf/2411.06135v1",
    "published_date": "2024-11-09 10:20:13 UTC",
    "updated_date": "2024-11-09 10:20:13 UTC"
  },
  {
    "arxiv_id": "2411.06128v1",
    "title": "Research on reinforcement learning based warehouse robot navigation algorithm in complex warehouse layout",
    "authors": [
      "Keqin Li",
      "Lipeng Liu",
      "Jiajing Chen",
      "Dezhi Yu",
      "Xiaofan Zhou",
      "Ming Li",
      "Congyu Wang",
      "Zhao Li"
    ],
    "abstract": "In this paper, how to efficiently find the optimal path in complex warehouse\nlayout and make real-time decision is a key problem. This paper proposes a new\nmethod of Proximal Policy Optimization (PPO) and Dijkstra's algorithm, Proximal\npolicy-Dijkstra (PP-D). PP-D method realizes efficient strategy learning and\nreal-time decision making through PPO, and uses Dijkstra algorithm to plan the\nglobal optimal path, thus ensuring high navigation accuracy and significantly\nimproving the efficiency of path planning. Specifically, PPO enables robots to\nquickly adapt and optimize action strategies in dynamic environments through\nits stable policy updating mechanism. Dijkstra's algorithm ensures global\noptimal path planning in static environment. Finally, through the comparison\nexperiment and analysis of the proposed framework with the traditional\nalgorithm, the results show that the PP-D method has significant advantages in\nimproving the accuracy of navigation prediction and enhancing the robustness of\nthe system. Especially in complex warehouse layout, PP-D method can find the\noptimal path more accurately and reduce collision and stagnation. This proves\nthe reliability and effectiveness of the robot in the study of complex\nwarehouse layout navigation algorithm.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.06128v1",
    "published_date": "2024-11-09 09:44:03 UTC",
    "updated_date": "2024-11-09 09:44:03 UTC"
  },
  {
    "arxiv_id": "2411.06122v2",
    "title": "Characteristics of Political Misinformation Over the Past Decade",
    "authors": [
      "Erik J Schlicht"
    ],
    "abstract": "Although misinformation tends to spread online, it can have serious\nreal-world consequences. In order to develop automated tools to detect and\nmitigate the impact of misinformation, researchers must leverage algorithms\nthat can adapt to the modality (text, images and video), the source, and the\ncontent of the false information. However, these characteristics tend to change\ndynamically across time, making it challenging to develop robust algorithms to\nfight misinformation spread. Therefore, this paper uses natural language\nprocessing to find common characteristics of political misinformation over a\ntwelve year period. The results show that misinformation has increased\ndramatically in recent years and that it has increasingly started to be shared\nfrom sources with primary information modalities of text and images (e.g.,\nFacebook and Instagram), although video sharing sources containing\nmisinformation are starting to increase (e.g., TikTok). Moreover, it was\ndiscovered that statements expressing misinformation contain more negative\nsentiment than accurate information. However, the sentiment associated with\nboth accurate and inaccurate information has trended downward, indicating a\ngenerally more negative tone in political statements across time. Finally,\nrecurring misinformation categories were uncovered that occur over multiple\nyears, which may imply that people tend to share inaccurate statements around\ninformation they fear or don't understand (Science and Medicine, Crime,\nReligion), impacts them directly (Policy, Election Integrity, Economic) or\nPublic Figures who are salient in their daily lives. Together, it is hoped that\nthese insights will assist researchers in developing algorithms that are\ntemporally invariant and capable of detecting and mitigating misinformation\nacross time.",
    "categories": [
      "cs.SI",
      "cs.AI"
    ],
    "primary_category": "cs.SI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.06122v2",
    "published_date": "2024-11-09 09:12:39 UTC",
    "updated_date": "2025-04-08 16:41:24 UTC"
  },
  {
    "arxiv_id": "2411.06120v7",
    "title": "Evaluating the Propensity of Generative AI for Producing Harmful Disinformation During an Election Cycle",
    "authors": [
      "Erik J Schlicht"
    ],
    "abstract": "Generative Artificial Intelligence offers a powerful tool for adversaries who\nwish to engage in influence operations, such as the Chinese Spamouflage\noperation and the Russian Internet Research Agency effort that both sought to\ninterfere with recent US election cycles. Therefore, this study seeks to\ninvestigate the propensity of current generative AI models for producing\nharmful disinformation during an election cycle. The probability that different\ngenerative AI models produced disinformation when given adversarial prompts was\nevaluated, in addition to the associated harm. This allows for the expected\nharm for each model to be computed and it was discovered that Copilot and\nGemini tied for the overall safest performance by realizing the lowest expected\nharm, while GPT-4o produced the greatest rates of harmful disinformation,\nresulting in much higher expected harm scores. The impact of disinformation\ncategory was also investigated and Gemini was safest within the political\ncategory of disinformation due to mitigation attempts made by developers during\nthe election, while Copilot was safest for topics related to health. Moreover,\ncharacteristics of adversarial roles were discovered that led to greater\nexpected harm across all models. Finally, classification models were developed\nthat predicted disinformation production based on the conditions considered in\nthis study, which offers insight into factors important for predicting\ndisinformation production. Based on all of these insights, recommendations are\nprovided that seek to mitigate factors that lead to harmful disinformation\nbeing produced by generative AI models. It is hoped that developers will use\nthese insights to improve future models.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.06120v7",
    "published_date": "2024-11-09 09:03:08 UTC",
    "updated_date": "2025-04-15 22:05:39 UTC"
  },
  {
    "arxiv_id": "2411.06111v1",
    "title": "Energy-efficient Hybrid Model Predictive Trajectory Planning for Autonomous Electric Vehicles",
    "authors": [
      "Fan Ding",
      "Xuewen Luo",
      "Gaoxuan Li",
      "Hwa Hui Tew",
      "Junn Yong Loo",
      "Chor Wai Tong",
      "A. S. M Bakibillah",
      "Ziyuan Zhao",
      "Zhiyu Tao"
    ],
    "abstract": "To tackle the twin challenges of limited battery life and lengthy charging\ndurations in electric vehicles (EVs), this paper introduces an Energy-efficient\nHybrid Model Predictive Planner (EHMPP), which employs an energy-saving\noptimization strategy. EHMPP focuses on refining the design of the motion\nplanner to be seamlessly integrated with the existing automatic driving\nalgorithms, without additional hardware. It has been validated through\nsimulation experiments on the Prescan, CarSim, and Matlab platforms,\ndemonstrating that it can increase passive recovery energy by 11.74\\% and\neffectively track motor speed and acceleration at optimal power. To sum up,\nEHMPP not only aids in trajectory planning but also significantly boosts energy\nefficiency in autonomous EVs.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted at the IEEE International Conference on Systems, Man, and\n  Cybernetics (SMC) 2024",
    "pdf_url": "http://arxiv.org/pdf/2411.06111v1",
    "published_date": "2024-11-09 08:21:06 UTC",
    "updated_date": "2024-11-09 08:21:06 UTC"
  },
  {
    "arxiv_id": "2411.06106v2",
    "title": "Personalize to generalize: Towards a universal medical multi-modality generalization through personalization",
    "authors": [
      "Zhaorui Tan",
      "Xi Yang",
      "Tan Pan",
      "Tianyi Liu",
      "Chen Jiang",
      "Xin Guo",
      "Qiufeng Wang",
      "Anh Nguyen",
      "Yuan Qi",
      "Kaizhu Huang",
      "Yuan Cheng"
    ],
    "abstract": "The differences among medical imaging modalities, driven by distinct\nunderlying principles, pose significant challenges for generalization in\nmulti-modal medical tasks. Beyond modality gaps, individual variations, such as\ndifferences in organ size and metabolic rate, further impede a model's ability\nto generalize effectively across both modalities and diverse populations.\nDespite the importance of personalization, existing approaches to multi-modal\ngeneralization often neglect individual differences, focusing solely on common\nanatomical features. This limitation may result in weakened generalization in\nvarious medical tasks. In this paper, we unveil that personalization is\ncritical for multi-modal generalization. Specifically, we propose an approach\nto achieve personalized generalization through approximating the underlying\npersonalized invariant representation ${X}_h$ across various modalities by\nleveraging individual-level constraints and a learnable biological prior. We\nvalidate the feasibility and benefits of learning a personalized ${X}_h$,\nshowing that this representation is highly generalizable and transferable\nacross various multi-modal medical tasks. Extensive experimental results\nconsistently show that the additionally incorporated personalization\nsignificantly improves performance and generalization across diverse scenarios,\nconfirming its effectiveness.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.06106v2",
    "published_date": "2024-11-09 08:00:50 UTC",
    "updated_date": "2024-11-13 03:19:47 UTC"
  },
  {
    "arxiv_id": "2411.06098v3",
    "title": "An Architectural Approach to Enhance Deep Long-Tailed Learning",
    "authors": [
      "Yuhan Pan",
      "Yanan Sun",
      "Wei Gong"
    ],
    "abstract": "Deep long-tailed recognition has been widely studied to address the issue of\nimbalanced data distributions in real-world scenarios. However, there has been\ninsufficient focus on the design of neural architectures, despite empirical\nevidence suggesting that architecture can significantly impact performance. In\nthis paper, we attempt to mitigate long-tailed issues through architectural\nimprovements. To simplify the design process, we utilize Differential\nArchitecture Search (DARTS) to achieve this goal. Unfortunately, existing DARTS\nmethods struggle to perform well in long-tailed scenarios. To tackle this\nchallenge, we introduce Long-Tailed Differential Architecture Search (LTDAS).\nSpecifically, we conduct extensive experiments to explore architectural\ncomponents that demonstrate better performance on long-tailed data and propose\na new search space based on our observations. This ensures that the\narchitecture obtained through our search process incorporates superior\ncomponents. Additionally, we propose replacing the learnable linear classifier\nwith an Equiangular Tight Frame (ETF) classifier to further enhance our method.\nThis classifier effectively alleviates the biased search process and prevents\nperformance collapse. Extensive experimental evaluations demonstrate that our\napproach consistently improves upon existing methods from an orthogonal\nperspective and achieves state-of-the-art results with simple enhancements.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.06098v3",
    "published_date": "2024-11-09 07:19:56 UTC",
    "updated_date": "2024-12-02 11:49:05 UTC"
  },
  {
    "arxiv_id": "2411.06097v2",
    "title": "A Multimodal Adaptive Graph-based Intelligent Classification Model for Fake News",
    "authors": [
      "Jun-hao",
      "Xu"
    ],
    "abstract": "Numerous studies have been proposed to detect fake news focusing on\nmulti-modalities based on machine and/or deep learning. However, studies\nfocusing on graph-based structures using geometric deep learning are lacking.\nTo address this challenge, we introduce the Multimodal Adaptive Graph-based\nIntelligent Classification (aptly referred to as MAGIC) for fake news\ndetection. Specifically, the Encoder Representations from Transformers was used\nfor text vectorization whilst ResNet50 was used for images. A comprehensive\ninformation interaction graph was built using the adaptive Graph Attention\nNetwork before classifying the multimodal input through the Softmax function.\nMAGIC was trained and tested on two fake news datasets, that is, Fakeddit\n(English) and Multimodal Fake News Detection (Chinese), with the model\nachieving an accuracy of 98.8\\% and 86.3\\%, respectively. Ablation experiments\nalso revealed MAGIC to yield superior performance across both the datasets.\nFindings show that a graph-based deep learning adaptive model is effective in\ndetecting multimodal fake news, surpassing state-of-the-art methods.",
    "categories": [
      "cs.AI",
      "68T99"
    ],
    "primary_category": "cs.AI",
    "comment": "8 pages",
    "pdf_url": "http://arxiv.org/pdf/2411.06097v2",
    "published_date": "2024-11-09 07:19:19 UTC",
    "updated_date": "2024-11-18 18:19:34 UTC"
  },
  {
    "arxiv_id": "2411.06087v2",
    "title": "Cross-Domain Transfer Learning using Attention Latent Features for Multi-Agent Trajectory Prediction",
    "authors": [
      "Jia Quan Loh",
      "Xuewen Luo",
      "Fan Ding",
      "Hwa Hui Tew",
      "Junn Yong Loo",
      "Ze Yang Ding",
      "Susilawati Susilawati",
      "Chee Pin Tan"
    ],
    "abstract": "With the advancements of sensor hardware, traffic infrastructure and deep\nlearning architectures, trajectory prediction of vehicles has established a\nsolid foundation in intelligent transportation systems. However, existing\nsolutions are often tailored to specific traffic networks at particular time\nperiods. Consequently, deep learning models trained on one network may struggle\nto generalize effectively to unseen networks. To address this, we proposed a\nnovel spatial-temporal trajectory prediction framework that performs\ncross-domain adaption on the attention representation of a Transformer-based\nmodel. A graph convolutional network is also integrated to construct dynamic\ngraph feature embeddings that accurately model the complex spatial-temporal\ninteractions between the multi-agent vehicles across multiple traffic domains.\nThe proposed framework is validated on two case studies involving the\ncross-city and cross-period settings. Experimental results show that our\nproposed framework achieves superior trajectory prediction and domain\nadaptation performances over the state-of-the-art models.",
    "categories": [
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted at the IEEE International Conference on Systems, Man, and\n  Cybernetics 2024",
    "pdf_url": "http://arxiv.org/pdf/2411.06087v2",
    "published_date": "2024-11-09 06:39:44 UTC",
    "updated_date": "2024-11-12 05:40:38 UTC"
  },
  {
    "arxiv_id": "2411.06084v1",
    "title": "Optimizing Large Language Models through Quantization: A Comparative Analysis of PTQ and QAT Techniques",
    "authors": [
      "Jahid Hasan"
    ],
    "abstract": "This paper presents a comprehensive analysis of quantization techniques for\noptimizing Large Language Models (LLMs), specifically focusing on Post-Training\nQuantization (PTQ) and Quantization-Aware Training (QAT). Through empirical\nevaluation across models ranging from 10M to 1B parameters, we demonstrate that\nquantization can achieve up to 68% reduction in model size while maintaining\nperformance within 6% of full-precision baselines when utilizing our proposed\nscaling factor {\\gamma}. Our experiments show that INT8 quantization delivers a\n40% reduction in computational cost and power consumption, while INT4\nquantization further improves these metrics by 60%. We introduce a novel\ntheoretical framework for mixed-precision quantization, deriving optimal bit\nallocation strategies based on layer sensitivity and weight variance. Hardware\nefficiency evaluations on edge devices reveal that our quantization approach\nenables up to 2.4x throughput improvement for INT8 and 3x for INT4, with 60%\npower reduction compared to full-precision models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "9 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.06084v1",
    "published_date": "2024-11-09 06:30:13 UTC",
    "updated_date": "2024-11-09 06:30:13 UTC"
  },
  {
    "arxiv_id": "2411.06074v1",
    "title": "Aquila: A Hierarchically Aligned Visual-Language Model for Enhanced Remote Sensing Image Comprehension",
    "authors": [
      "Kaixuan Lu",
      "Ruiqian Zhang",
      "Xiao Huang",
      "Yuxing Xie"
    ],
    "abstract": "Recently, large vision language models (VLMs) have made significant strides\nin visual language capabilities through visual instruction tuning, showing\ngreat promise in the field of remote sensing image interpretation. However,\nexisting remote sensing vision language models (RSVLMs) often fall short in\ncapturing the complex characteristics of remote sensing scenes, as they\ntypically rely on low resolution, single scale visual features and simplistic\nmethods to map visual features to language features. In this paper, we present\nAquila, an advanced visual language foundation model designed to enable richer\nvisual feature representation and more precise visual-language feature\nalignment for remote sensing images. Our approach introduces a learnable\nHierarchical Spatial Feature Integration (SFI) module that supports high\nresolution image inputs and aggregates multi scale visual features, allowing\nfor the detailed representation of complex visual information. Additionally,\nthe SFI module is repeatedly integrated into the layers of the large language\nmodel (LLM) to achieve deep visual language feature alignment, without\ncompromising the model's performance in natural language processing tasks.\nThese innovations, capturing detailed visual effects through higher resolution\nand multi scale input, and enhancing feature alignment significantly improve\nthe model's ability to learn from image text data. We validate the\neffectiveness of Aquila through extensive quantitative experiments and\nqualitative analyses, demonstrating its superior performance.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.06074v1",
    "published_date": "2024-11-09 05:31:56 UTC",
    "updated_date": "2024-11-09 05:31:56 UTC"
  },
  {
    "arxiv_id": "2411.06070v1",
    "title": "GFT: Graph Foundation Model with Transferable Tree Vocabulary",
    "authors": [
      "Zehong Wang",
      "Zheyuan Zhang",
      "Nitesh V Chawla",
      "Chuxu Zhang",
      "Yanfang Ye"
    ],
    "abstract": "Inspired by the success of foundation models in applications such as ChatGPT,\nas graph data has been ubiquitous, one can envision the far-reaching impacts\nthat can be brought by Graph Foundation Models (GFMs) with broader applications\nin the areas such as scientific research, social network analysis, drug\ndiscovery, and e-commerce. Despite the significant progress of pre-trained\ngraph neural networks, there haven't been GFMs that can achieve desired\nperformance on various graph-learning-related tasks. Building GFMs may rely on\na vocabulary that encodes transferable patterns shared among different tasks\nand domains. Unlike image and text, defining such transferable patterns for\ngraphs remains an open question. In this paper, we aim to bridge this gap by\nrethinking the transferable patterns on graphs as computation trees -- i.e.,\ntree structures derived from the message-passing process. Based on this\ninsight, we propose a cross-task, cross-domain graph foundation model named\nGFT, short for Graph Foundation model with transferable Tree vocabulary. By\ntreating computation trees as tokens within the transferable vocabulary, GFT\nimproves model generalization and reduces the risk of negative transfer. The\ntheoretical analyses and extensive experimental studies have demonstrated the\ntransferability of computation trees and shown the effectiveness of GFT across\ndiverse tasks and domains in graph learning. The open source code and data are\navailable at https://github.com/Zehong-Wang/GFT.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2411.06070v1",
    "published_date": "2024-11-09 05:14:30 UTC",
    "updated_date": "2024-11-09 05:14:30 UTC"
  },
  {
    "arxiv_id": "2411.06068v1",
    "title": "Zyda-2: a 5 Trillion Token High-Quality Dataset",
    "authors": [
      "Yury Tokpanov",
      "Paolo Glorioso",
      "Quentin Anthony",
      "Beren Millidge"
    ],
    "abstract": "In this technical report, we present Zyda-2: a five trillion token dataset\nfor language model pretraining. Zyda-2 was used to train our Zamba2 series of\nmodels which are state-of-the-art for their weight class. We build Zyda-2 by\ncollating high-quality open-source tokens such as FineWeb and DCLM, then\ndistilling them to the highest-quality subset via cross-deduplication and\nmodel-based quality filtering. Zyda-2 is released under a permissive open\nlicense, and is available at https://huggingface.co/datasets/Zyphra/Zyda-2",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "initial upload 11/08/24",
    "pdf_url": "http://arxiv.org/pdf/2411.06068v1",
    "published_date": "2024-11-09 04:57:41 UTC",
    "updated_date": "2024-11-09 04:57:41 UTC"
  },
  {
    "arxiv_id": "2411.06066v1",
    "title": "Diversity and Inclusion in AI for Recruitment: Lessons from Industry Workshop",
    "authors": [
      "Muneera Bano",
      "Didar Zowghi",
      "Fernando Mourao",
      "Sarah Kaur",
      "Tao Zhang"
    ],
    "abstract": "Artificial Intelligence (AI) systems for online recruitment markets have the\npotential to significantly enhance the efficiency and effectiveness of job\nplacements and even promote fairness or inclusive hiring practices. Neglecting\nDiversity and Inclusion (D&I) in these systems, however, can perpetuate biases,\nleading to unfair hiring practices and decreased workplace diversity, while\nexposing organisations to legal and reputational risks. Despite the\nacknowledged importance of D&I in AI, there is a gap in research on effectively\nimplementing D&I guidelines in real-world recruitment systems. Challenges\ninclude a lack of awareness and framework for operationalising D&I in a\ncost-effective, context-sensitive manner. This study aims to investigate the\npractical application of D&I guidelines in AI-driven online job-seeking\nsystems, specifically exploring how these principles can be operationalised to\ncreate more inclusive recruitment processes. We conducted a co-design workshop\nwith a large multinational recruitment company focusing on two AI-driven\nrecruitment use cases. User stories and personas were applied to evaluate the\nimpacts of AI on diverse stakeholders. Follow-up interviews were conducted to\nassess the workshop's long-term effects on participants' awareness and\napplication of D&I principles. The co-design workshop successfully increased\nparticipants' understanding of D&I in AI. However, translating awareness into\noperational practice posed challenges, particularly in balancing D&I with\nbusiness goals. The results suggest developing tailored D&I guidelines and\nongoing support to ensure the effective adoption of inclusive AI practices.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.06066v1",
    "published_date": "2024-11-09 04:45:47 UTC",
    "updated_date": "2024-11-09 04:45:47 UTC"
  },
  {
    "arxiv_id": "2411.06060v1",
    "title": "Wild Narratives: Exploring the Effects of Animal Chatbots on Empathy and Positive Attitudes toward Animals",
    "authors": [
      "Jingshu Li",
      "Aaditya Patwari",
      "Yi-Chieh Lee"
    ],
    "abstract": "Rises in the number of animal abuse cases are reported around the world.\nWhile chatbots have been effective in influencing their users' perceptions and\nbehaviors, little if any research has hitherto explored the design of chatbots\nthat embody animal identities for the purpose of eliciting empathy toward\nanimals. We therefore conducted a mixed-methods experiment to investigate how\nspecific design cues in such chatbots can shape their users' perceptions of\nboth the chatbots' identities and the type of animal they represent. Our\nfindings indicate that such chatbots can significantly increase empathy,\nimprove attitudes, and promote prosocial behavioral intentions toward animals,\nparticularly when they incorporate emotional verbal expressions and authentic\ndetails of such animals' lives. These results expand our understanding of\nchatbots with non-human identities and highlight their potential for use in\nconservation initiatives, suggesting a promising avenue whereby technology\ncould foster a more informed and empathetic society.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.06060v1",
    "published_date": "2024-11-09 03:55:53 UTC",
    "updated_date": "2024-11-09 03:55:53 UTC"
  },
  {
    "arxiv_id": "2411.07814v1",
    "title": "Community Research Earth Digital Intelligence Twin (CREDIT)",
    "authors": [
      "John Schreck",
      "Yingkai Sha",
      "William Chapman",
      "Dhamma Kimpara",
      "Judith Berner",
      "Seth McGinnis",
      "Arnold Kazadi",
      "Negin Sobhani",
      "Ben Kirk",
      "David John Gagne II"
    ],
    "abstract": "Recent advancements in artificial intelligence (AI) for numerical weather\nprediction (NWP) have significantly transformed atmospheric modeling. AI NWP\nmodels outperform traditional physics-based systems, such as the Integrated\nForecast System (IFS), across several global metrics while requiring fewer\ncomputational resources. However, existing AI NWP models face limitations\nrelated to training datasets and timestep choices, often resulting in artifacts\nthat reduce model performance. To address these challenges, we introduce the\nCommunity Research Earth Digital Intelligence Twin (CREDIT) framework,\ndeveloped at NSF NCAR. CREDIT provides a flexible, scalable, and user-friendly\nplatform for training and deploying AI-based atmospheric models on\nhigh-performance computing systems. It offers an end-to-end pipeline for data\npreprocessing, model training, and evaluation, democratizing access to advanced\nAI NWP capabilities. We demonstrate CREDIT's potential through WXFormer, a\nnovel deterministic vision transformer designed to predict atmospheric states\nautoregressively, addressing common AI NWP issues like compounding error growth\nwith techniques such as spectral normalization, padding, and multi-step\ntraining. Additionally, to illustrate CREDIT's flexibility and state-of-the-art\nmodel comparisons, we train the FUXI architecture within this framework. Our\nfindings show that both FUXI and WXFormer, trained on six-hourly ERA5 hybrid\nsigma-pressure levels, generally outperform IFS HRES in 10-day forecasts,\noffering potential improvements in efficiency and forecast accuracy. CREDIT's\nmodular design enables researchers to explore various models, datasets, and\ntraining configurations, fostering innovation within the scientific community.",
    "categories": [
      "cs.AI",
      "physics.ao-ph"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.07814v1",
    "published_date": "2024-11-09 03:08:03 UTC",
    "updated_date": "2024-11-09 03:08:03 UTC"
  },
  {
    "arxiv_id": "2411.06048v1",
    "title": "An Empirical Analysis on Spatial Reasoning Capabilities of Large Multimodal Models",
    "authors": [
      "Fatemeh Shiri",
      "Xiao-Yu Guo",
      "Mona Golestan Far",
      "Xin Yu",
      "Gholamreza Haffari",
      "Yuan-Fang Li"
    ],
    "abstract": "Large Multimodal Models (LMMs) have achieved strong performance across a\nrange of vision and language tasks. However, their spatial reasoning\ncapabilities are under-investigated. In this paper, we construct a novel VQA\ndataset, Spatial-MM, to comprehensively study LMMs' spatial understanding and\nreasoning capabilities. Our analyses on object-relationship and multi-hop\nreasoning reveal several important findings. Firstly, bounding boxes and scene\ngraphs, even synthetic ones, can significantly enhance LMMs' spatial reasoning.\nSecondly, LMMs struggle more with questions posed from the human perspective\nthan the camera perspective about the image. Thirdly, chain of thought (CoT)\nprompting does not improve model performance on complex multi-hop questions\ninvolving spatial relations. % Moreover, spatial reasoning steps are much less\naccurate than non-spatial ones across MLLMs. Lastly, our perturbation analysis\non GQA-spatial reveals that LMMs are much stronger at basic object detection\nthan complex spatial reasoning. We believe our benchmark dataset and in-depth\nanalyses can spark further research on LMMs spatial reasoning. Spatial-MM\nbenchmark is available at: https://github.com/FatemehShiri/Spatial-MM",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.06048v1",
    "published_date": "2024-11-09 03:07:33 UTC",
    "updated_date": "2024-11-09 03:07:33 UTC"
  },
  {
    "arxiv_id": "2411.06046v1",
    "title": "Personalized News Recommendation System via LLM Embedding and Co-Occurrence Patterns",
    "authors": [
      "Zheng Li",
      "Kai Zhange"
    ],
    "abstract": "In the past two years, large language models (LLMs) have achieved rapid\ndevelopment and demonstrated remarkable emerging capabilities. Concurrently,\nwith powerful semantic understanding and reasoning capabilities, LLMs have\nsignificantly empowered the rapid advancement of the recommendation system\nfield. Specifically, in news recommendation (NR), systems must comprehend and\nprocess a vast amount of clicked news text to infer the probability of\ncandidate news clicks. This requirement exceeds the capabilities of traditional\nNR models but aligns well with the strengths of LLMs. In this paper, we propose\na novel NR algorithm to reshape the news model via LLM Embedding and\nCo-Occurrence Pattern (LECOP). On one hand, we fintuned LLM by contrastive\nlearning using large-scale datasets to encode news, which can fully explore the\nsemantic information of news to thoroughly identify user preferences. On the\nother hand, we explored multiple co-occurrence patterns to mine collaborative\ninformation. Those patterns include news ID co-occurrence, Item-Item keywords\nco-occurrence and Intra-Item keywords co-occurrence. The keywords mentioned\nabove are all generated by LLM. As far as we know, this is the first time that\nconstructing such detailed Co-Occurrence Patterns via LLM to capture\ncollaboration. Extensive experiments demonstrate the superior performance of\nour proposed novel method",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.06046v1",
    "published_date": "2024-11-09 03:01:49 UTC",
    "updated_date": "2024-11-09 03:01:49 UTC"
  },
  {
    "arxiv_id": "2411.06041v1",
    "title": "PointCG: Self-supervised Point Cloud Learning via Joint Completion and Generation",
    "authors": [
      "Yun Liu",
      "Peng Li",
      "Xuefeng Yan",
      "Liangliang Nan",
      "Bing Wang",
      "Honghua Chen",
      "Lina Gong",
      "Wei Zhao",
      "Mingqiang Wei"
    ],
    "abstract": "The core of self-supervised point cloud learning lies in setting up\nappropriate pretext tasks, to construct a pre-training framework that enables\nthe encoder to perceive 3D objects effectively. In this paper, we integrate two\nprevalent methods, masked point modeling (MPM) and 3D-to-2D generation, as\npretext tasks within a pre-training framework. We leverage the spatial\nawareness and precise supervision offered by these two methods to address their\nrespective limitations: ambiguous supervision signals and insensitivity to\ngeometric information. Specifically, the proposed framework, abbreviated as\nPointCG, consists of a Hidden Point Completion (HPC) module and an\nArbitrary-view Image Generation (AIG) module. We first capture visible points\nfrom arbitrary views as inputs by removing hidden points. Then, HPC extracts\nrepresentations of the inputs with an encoder and completes the entire shape\nwith a decoder, while AIG is used to generate rendered images based on the\nvisible points' representations. Extensive experiments demonstrate the\nsuperiority of the proposed method over the baselines in various downstream\ntasks. Our code will be made available upon acceptance.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.06041v1",
    "published_date": "2024-11-09 02:38:29 UTC",
    "updated_date": "2024-11-09 02:38:29 UTC"
  },
  {
    "arxiv_id": "2411.06040v1",
    "title": "CGLearn: Consistent Gradient-Based Learning for Out-of-Distribution Generalization",
    "authors": [
      "Jawad Chowdhury",
      "Gabriel Terejanu"
    ],
    "abstract": "Improving generalization and achieving highly predictive, robust machine\nlearning models necessitates learning the underlying causal structure of the\nvariables of interest. A prominent and effective method for this is learning\ninvariant predictors across multiple environments. In this work, we introduce a\nsimple yet powerful approach, CGLearn, which relies on the agreement of\ngradients across various environments. This agreement serves as a powerful\nindication of reliable features, while disagreement suggests less reliability\ndue to potential differences in underlying causal mechanisms. Our proposed\nmethod demonstrates superior performance compared to state-of-the-art methods\nin both linear and nonlinear settings across various regression and\nclassification tasks. CGLearn shows robust applicability even in the absence of\nseparate environments by exploiting invariance across different subsamples of\nobservational data. Comprehensive experiments on both synthetic and real-world\ndatasets highlight its effectiveness in diverse scenarios. Our findings\nunderscore the importance of leveraging gradient agreement for learning causal\ninvariance, providing a significant step forward in the field of robust machine\nlearning. The source code of the linear and nonlinear implementation of CGLearn\nis open-source and available at: https://github.com/hasanjawad001/CGLearn.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "68T07",
      "I.2.6"
    ],
    "primary_category": "cs.LG",
    "comment": "9 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.06040v1",
    "published_date": "2024-11-09 02:36:39 UTC",
    "updated_date": "2024-11-09 02:36:39 UTC"
  },
  {
    "arxiv_id": "2411.06034v1",
    "title": "CROPS: A Deployable Crop Management System Over All Possible State Availabilities",
    "authors": [
      "Jing Wu",
      "Zhixin Lai",
      "Shengjie Liu",
      "Suiyao Chen",
      "Ran Tao",
      "Pan Zhao",
      "Chuyuan Tao",
      "Yikun Cheng",
      "Naira Hovakimyan"
    ],
    "abstract": "Exploring the optimal management strategy for nitrogen and irrigation has a\nsignificant impact on crop yield, economic profit, and the environment. To\ntackle this optimization challenge, this paper introduces a deployable\n\\textbf{CR}op Management system \\textbf{O}ver all \\textbf{P}ossible\n\\textbf{S}tate availabilities (CROPS). CROPS employs a language model (LM) as a\nreinforcement learning (RL) agent to explore optimal management strategies\nwithin the Decision Support System for Agrotechnology Transfer (DSSAT) crop\nsimulations. A distinguishing feature of this system is that the states used\nfor decision-making are partially observed through random masking.\nConsequently, the RL agent is tasked with two primary objectives: optimizing\nmanagement policies and inferring masked states. This approach significantly\nenhances the RL agent's robustness and adaptability across various real-world\nagricultural scenarios. Extensive experiments on maize crops in Florida, USA,\nand Zaragoza, Spain, validate the effectiveness of CROPS. Not only did CROPS\nachieve State-of-the-Art (SOTA) results across various evaluation metrics such\nas production, profit, and sustainability, but the trained management policies\nare also immediately deployable in over of ten millions of real-world contexts.\nFurthermore, the pre-trained policies possess a noise resilience property,\nwhich enables them to minimize potential sensor biases, ensuring robustness and\ngeneralizability. Finally, unlike previous methods, the strength of CROPS lies\nin its unified and elegant structure, which eliminates the need for pre-defined\nstates or multi-stage training. These advancements highlight the potential of\nCROPS in revolutionizing agricultural practices.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.06034v1",
    "published_date": "2024-11-09 02:06:09 UTC",
    "updated_date": "2024-11-09 02:06:09 UTC"
  },
  {
    "arxiv_id": "2411.06018v2",
    "title": "A Picture is Worth A Thousand Numbers: Enabling LLMs Reason about Time Series via Visualization",
    "authors": [
      "Haoxin Liu",
      "Chenghao Liu",
      "B. Aditya Prakash"
    ],
    "abstract": "Large language models (LLMs), with demonstrated reasoning abilities across\nmultiple domains, are largely underexplored for time-series reasoning (TsR),\nwhich is ubiquitous in the real world. In this work, we propose TimerBed, the\nfirst comprehensive testbed for evaluating LLMs' TsR performance. Specifically,\nTimerBed includes stratified reasoning patterns with real-world tasks,\ncomprehensive combinations of LLMs and reasoning strategies, and various\nsupervised models as comparison anchors. We perform extensive experiments with\nTimerBed, test multiple current beliefs, and verify the initial failures of\nLLMs in TsR, evidenced by the ineffectiveness of zero shot (ZST) and\nperformance degradation of few shot in-context learning (ICL). Further, we\nidentify one possible root cause: the numerical modeling of data. To address\nthis, we propose a prompt-based solution VL-Time, using visualization-modeled\ndata and language-guided reasoning. Experimental results demonstrate that\nVl-Time enables multimodal LLMs to be non-trivial ZST and powerful ICL\nreasoners for time series, achieving about 140% average performance improvement\nand 99% average token costs reduction.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.06018v2",
    "published_date": "2024-11-09 00:35:29 UTC",
    "updated_date": "2025-04-25 16:39:41 UTC"
  }
]