[
  {
    "arxiv_id": "2409.16507v2",
    "title": "Center-fixing of tropical cyclones using uncertainty-aware deep learning applied to high-temporal-resolution geostationary satellite imagery",
    "authors": [
      "Ryan Lagerquist",
      "Galina Chirokova",
      "Robert DeMaria",
      "Mark DeMaria",
      "Imme Ebert-Uphoff"
    ],
    "abstract": "Determining the location of a tropical cyclone's (TC) surface circulation\ncenter -- \"center-fixing\" -- is a critical first step in the TC-forecasting\nprocess, affecting current and future estimates of track, intensity, and\nstructure. Despite a recent increase in automated center-fixing methods, only\none such method (ARCHER-2) is operational, and its best performance is achieved\nwhen using microwave or scatterometer data, which are not available at every\nforecast cycle. We develop a deep-learning algorithm called GeoCenter; besides\na few scalars in the operational ATCF, it relies only on geostationary IR\nsatellite imagery, which is available for all TC basins at high frequency (10\nmin) and low latency (< 10 min) during both day and night. GeoCenter ingests an\nanimation (time series) of IR images, including 9 channels at lag times up to 4\nhours. The animation is centered at a \"first guess\" location, offset from the\ntrue TC-center location by 48 km on average and sometimes > 100 km; GeoCenter\nis tasked with correcting this offset. On an independent testing dataset,\nGeoCenter achieves a mean/median/RMS (root mean square) error of 26.6/22.2/32.4\nkm for all systems, 24.7/20.8/30.0 km for tropical systems, and 14.6/12.5/17.3\nkm for category-2--5 hurricanes. These values are similar to ARCHER-2 errors\nwith microwave or scatterometer data, and better than ARCHER-2 errors when only\nIR data are available. GeoCenter also performs skillful uncertainty\nquantification, producing a well calibrated ensemble of 150 TC-center\nlocations. Furthermore, all predictors used by GeoCenter are available in real\ntime, which would make GeoCenter easy to implement operationally every 10 min.",
    "categories": [
      "physics.ao-ph",
      "cs.AI"
    ],
    "primary_category": "physics.ao-ph",
    "comment": "Submitted to AMS journal Weather and Forecasting. Main body is 64\n  pages and 17 figures; supplement is another 33 pages and 31 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.16507v2",
    "published_date": "2024-09-24 23:39:56 UTC",
    "updated_date": "2025-04-08 18:34:36 UTC"
  },
  {
    "arxiv_id": "2409.16502v3",
    "title": "GSplatLoc: Grounding Keypoint Descriptors into 3D Gaussian Splatting for Improved Visual Localization",
    "authors": [
      "Gennady Sidorov",
      "Malik Mohrat",
      "Denis Gridusov",
      "Ruslan Rakhimov",
      "Sergey Kolyubin"
    ],
    "abstract": "Although various visual localization approaches exist, such as scene\ncoordinate regression and camera pose regression, these methods often struggle\nwith optimization complexity or limited accuracy. To address these challenges,\nwe explore the use of novel view synthesis techniques, particularly 3D Gaussian\nSplatting (3DGS), which enables the compact encoding of both 3D geometry and\nscene appearance. We propose a two-stage procedure that integrates dense and\nrobust keypoint descriptors from the lightweight XFeat feature extractor into\n3DGS, enhancing performance in both indoor and outdoor environments. The coarse\npose estimates are directly obtained via 2D-3D correspondences between the 3DGS\nrepresentation and query image descriptors. In the second stage, the initial\npose estimate is refined by minimizing the rendering-based photometric warp\nloss. Benchmarking on widely used indoor and outdoor datasets demonstrates\nimprovements over recent neural rendering-based localization methods, such as\nNeRFMatch and PNeRFLoc.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "Project website at https://gsplatloc.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2409.16502v3",
    "published_date": "2024-09-24 23:18:32 UTC",
    "updated_date": "2025-03-20 12:57:03 UTC"
  },
  {
    "arxiv_id": "2409.16497v1",
    "title": "Unsupervised Text Representation Learning via Instruction-Tuning for Zero-Shot Dense Retrieval",
    "authors": [
      "Qiuhai Zeng",
      "Zimeng Qiu",
      "Dae Yon Hwang",
      "Xin He",
      "William M. Campbell"
    ],
    "abstract": "Dense retrieval systems are commonly used for information retrieval (IR).\nThey rely on learning text representations through an encoder and usually\nrequire supervised modeling via labelled data which can be costly to obtain or\nsimply unavailable. In this study, we introduce a novel unsupervised text\nrepresentation learning technique via instruction-tuning the pre-trained\nencoder-decoder large language models (LLM) under the dual-encoder retrieval\nframework. We demonstrate the corpus representation can be augmented by the\nrepresentations of relevant synthetic queries generated by the instruct-tuned\nLLM founded on the Rao-Blackwell theorem. Furthermore, we effectively align the\nquery and corpus text representation with self-instructed-tuning. Specifically,\nwe first prompt an open-box pre-trained LLM to follow defined instructions\n(i.e. question generation and keyword summarization) to generate synthetic\nqueries. Next, we fine-tune the pre-trained LLM with defined instructions and\nthe generated queries that passed quality check. Finally, we generate synthetic\nqueries with the instruction-tuned LLM for each corpora and represent each\ncorpora by weighted averaging the synthetic queries and original corpora\nembeddings. We evaluate our proposed method under low-resource settings on\nthree English and one German retrieval datasets measuring NDCG@10, MRR@100,\nRecall@100. We significantly improve the average zero-shot retrieval\nperformance on all metrics, increasing open-box FLAN-T5 model variations by\n[3.34%, 3.50%] in absolute and exceeding three competitive dense retrievers\n(i.e. mDPR, T-Systems, mBART-Large), with model of size at least 38% smaller,\nby 1.96%, 4.62%, 9.52% absolute on NDCG@10.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted at DCAI24 workshop@CIKM2024",
    "pdf_url": "http://arxiv.org/pdf/2409.16497v1",
    "published_date": "2024-09-24 23:03:13 UTC",
    "updated_date": "2024-09-24 23:03:13 UTC"
  },
  {
    "arxiv_id": "2409.16486v1",
    "title": "To Explore the Potential Inhibitors against Multitarget Proteins of COVID 19 using In Silico Study",
    "authors": [
      "Imra Aqeel"
    ],
    "abstract": "The global pandemic due to emergence of COVID 19 has created the unrivaled\npublic health crisis. It has huge morbidity rate never comprehended in the\nrecent decades. Researchers have made many efforts to find the optimal solution\nof this pandemic. Progressively, drug repurposing is an emergent and powerful\nstrategy with saving cost, time, and labor. Lacking of identified repurposed\ndrug candidates against COVID 19 demands more efforts to explore the potential\ninhibitors for effective cure. In this study, we used the combination of\nmolecular docking and machine learning regression approaches to explore the\npotential inhibitors for the treatment of COVID 19. We calculated the binding\naffinities of these drugs to multitarget proteins using molecular docking\nprocess. We perform the QSAR modeling by employing various machine learning\nregression approaches to identify the potential inhibitors against COVID 19.\nOur findings with best scores of R2 and RMSE demonstrated that our proposed\nDecision Tree Regression (DTR) model is the most appropriate model to explore\nthe potential inhibitors. We proposed five novel promising inhibitors with\ntheir respective Zinc IDs ZINC (3873365, 85432544, 8214470, 85536956, and\n261494640) within the range of -19.7 kcal/mol to -12.6 kcal/mol. We further\nanalyzed the physiochemical and pharmacokinetic properties of these most potent\ninhibitors to examine their behavior. The analysis of these properties is the\nkey factor to promote an effective cure for public health. Our work constructs\nan efficient structure with which to probe the potential inhibitors against\nCOVID-19, creating the combination of molecular docking with machine learning\nregression approaches.",
    "categories": [
      "q-bio.QM",
      "cs.AI"
    ],
    "primary_category": "q-bio.QM",
    "comment": "22 pages",
    "pdf_url": "http://arxiv.org/pdf/2409.16486v1",
    "published_date": "2024-09-24 22:19:56 UTC",
    "updated_date": "2024-09-24 22:19:56 UTC"
  },
  {
    "arxiv_id": "2409.16478v1",
    "title": "Algorithmic Drift: A Simulation Framework to Study the Effects of Recommender Systems on User Preferences",
    "authors": [
      "Erica Coppolillo",
      "Simone Mungari",
      "Ettore Ritacco",
      "Francesco Fabbri",
      "Marco Minici",
      "Francesco Bonchi",
      "Giuseppe Manco"
    ],
    "abstract": "Digital platforms such as social media and e-commerce websites adopt\nRecommender Systems to provide value to the user. However, the social\nconsequences deriving from their adoption are still unclear. Many scholars\nargue that recommenders may lead to detrimental effects, such as\nbias-amplification deriving from the feedback loop between algorithmic\nsuggestions and users' choices. Nonetheless, the extent to which recommenders\ninfluence changes in users leaning remains uncertain. In this context, it is\nimportant to provide a controlled environment for evaluating the recommendation\nalgorithm before deployment. To address this, we propose a stochastic\nsimulation framework that mimics user-recommender system interactions in a\nlong-term scenario. In particular, we simulate the user choices by formalizing\na user model, which comprises behavioral aspects, such as the user resistance\ntowards the recommendation algorithm and their inertia in relying on the\nreceived suggestions. Additionally, we introduce two novel metrics for\nquantifying the algorithm's impact on user preferences, specifically in terms\nof drift over time. We conduct an extensive evaluation on multiple synthetic\ndatasets, aiming at testing the robustness of our framework when considering\ndifferent scenarios and hyper-parameters setting. The experimental results\nprove that the proposed methodology is effective in detecting and quantifying\nthe drift over the users preferences by means of the simulation. All the code\nand data used to perform the experiments are publicly available.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.SI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.16478v1",
    "published_date": "2024-09-24 21:54:22 UTC",
    "updated_date": "2024-09-24 21:54:22 UTC"
  },
  {
    "arxiv_id": "2409.17183v1",
    "title": "Transfer learning for financial data predictions: a systematic review",
    "authors": [
      "V. Lanzetta"
    ],
    "abstract": "Literature highlighted that financial time series data pose significant\nchallenges for accurate stock price prediction, because these data are\ncharacterized by noise and susceptibility to news; traditional statistical\nmethodologies made assumptions, such as linearity and normality, which are not\nsuitable for the non-linear nature of financial time series; on the other hand,\nmachine learning methodologies are able to capture non linear relationship in\nthe data. To date, neural network is considered the main machine learning tool\nfor the financial prices prediction. Transfer Learning, as a method aimed at\ntransferring knowledge from source tasks to target tasks, can represent a very\nuseful methodological tool for getting better financial prediction capability.\nCurrent reviews on the above body of knowledge are mainly focused on neural\nnetwork architectures, for financial prediction, with very little emphasis on\nthe transfer learning methodology; thus, this paper is aimed at going deeper on\nthis topic by developing a systematic review with respect to application of\nTransfer Learning for financial market predictions and to challenges/potential\nfuture directions of the transfer learning methodologies for stock market\npredictions.",
    "categories": [
      "q-fin.TR",
      "cs.AI",
      "cs.LG",
      "q-fin.CP"
    ],
    "primary_category": "q-fin.TR",
    "comment": "43 pages, 5 tables, 1 figure",
    "pdf_url": "http://arxiv.org/pdf/2409.17183v1",
    "published_date": "2024-09-24 20:52:32 UTC",
    "updated_date": "2024-09-24 20:52:32 UTC"
  },
  {
    "arxiv_id": "2409.16444v2",
    "title": "Artificial Intelligence for Secured Information Systems in Smart Cities: Collaborative IoT Computing with Deep Reinforcement Learning and Blockchain",
    "authors": [
      "Amin Zakaie Far",
      "Mohammad Zakaie Far",
      "Sonia Gharibzadeh",
      "Hajar Kazemi Naeini",
      "Leila Amini",
      "Shiva Zangeneh",
      "Morteza Rahimi",
      "Saeed Asadi"
    ],
    "abstract": "The accelerated expansion of the Internet of Things (IoT) has raised critical\nchallenges associated with privacy, security, and data integrity, specifically\nin infrastructures such as smart cities or smart manufacturing. Blockchain\ntechnology provides immutable, scalable, and decentralized solutions to address\nthese challenges, and integrating deep reinforcement learning (DRL) into the\nIoT environment offers enhanced adaptability and decision-making. This paper\ninvestigates the integration of blockchain and DRL to optimize mobile\ntransmission and secure data exchange in IoT-assisted smart cities. Through the\nclustering and categorization of IoT application systems, the combination of\nDRL and blockchain is shown to enhance the performance of IoT networks by\nmaintaining privacy and security. Based on the review of papers published\nbetween 2015 and 2024, we have classified the presented approaches and offered\npractical taxonomies, which provide researchers with critical perspectives and\nhighlight potential areas for future exploration and research. Our\ninvestigation shows how combining blockchain's decentralized framework with DRL\ncan address privacy and security issues, improve mobile transmission\nefficiency, and guarantee robust, privacy-preserving IoT systems. Additionally,\nwe explore blockchain integration for DRL and outline the notable applications\nof DRL technology. By addressing the challenges of machine learning and\nblockchain integration, this study proposes novel perspectives for researchers\nand serves as a foundational exploration from an interdisciplinary standpoint.",
    "categories": [
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.16444v2",
    "published_date": "2024-09-24 20:25:20 UTC",
    "updated_date": "2025-03-11 08:42:40 UTC"
  },
  {
    "arxiv_id": "2409.16434v5",
    "title": "Lessons and Insights from a Unifying Study of Parameter-Efficient Fine-Tuning (PEFT) in Visual Recognition",
    "authors": [
      "Zheda Mai",
      "Ping Zhang",
      "Cheng-Hao Tu",
      "Hong-You Chen",
      "Li Zhang",
      "Wei-Lun Chao"
    ],
    "abstract": "Parameter-efficient fine-tuning (PEFT) has attracted significant attention\ndue to the growth of pre-trained model sizes and the need to fine-tune (FT)\nthem for superior downstream performance. Despite a surge in new PEFT methods,\na systematic study to understand their performance and suitable application\nscenarios is lacking, leaving questions like \"when to apply PEFT\" and \"which\nmethod to use\" largely unanswered, especially in visual recognition. In this\npaper, we conduct a unifying empirical study of representative PEFT methods\nwith Vision Transformers. We systematically tune their hyperparameters to\nfairly compare their accuracy on downstream tasks. Our study offers a practical\nuser guide and unveils several new insights. First, if tuned carefully,\ndifferent PEFT methods achieve similar accuracy in the low-shot benchmark\nVTAB-1K. This includes simple approaches like FT the bias terms that were\nreported inferior. Second, despite similar accuracy, we find that PEFT methods\nmake different mistakes and high-confidence predictions, likely due to their\ndifferent inductive biases. Such an inconsistency (or complementarity) opens up\nthe opportunity for ensemble methods, and we make preliminary attempts at this.\nThird, going beyond the commonly used low-shot tasks, we find that PEFT is also\nuseful in many-shot regimes, achieving comparable or better accuracy than full\nFT while using significantly fewer parameters. Lastly, we investigate PEFT's\nability to preserve a pre-trained model's robustness to distribution shifts\n(e.g., CLIP). Perhaps not surprisingly, PEFT approaches outperform full FT\nalone. However, with weight-space ensembles, full FT can better balance target\ndistribution and distribution shift performance, suggesting a future research\ndirection for robust PEFT.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "CVPR 2025. The code is available at\n  https://github.com/OSU-MLB/ViT_PEFT_Vision",
    "pdf_url": "http://arxiv.org/pdf/2409.16434v5",
    "published_date": "2024-09-24 19:57:40 UTC",
    "updated_date": "2025-03-25 02:07:28 UTC"
  },
  {
    "arxiv_id": "2409.16430v1",
    "title": "A Comprehensive Survey of Bias in LLMs: Current Landscape and Future Directions",
    "authors": [
      "Rajesh Ranjan",
      "Shailja Gupta",
      "Surya Narayan Singh"
    ],
    "abstract": "Large Language Models(LLMs) have revolutionized various applications in\nnatural language processing (NLP) by providing unprecedented text generation,\ntranslation, and comprehension capabilities. However, their widespread\ndeployment has brought to light significant concerns regarding biases embedded\nwithin these models. This paper presents a comprehensive survey of biases in\nLLMs, aiming to provide an extensive review of the types, sources, impacts, and\nmitigation strategies related to these biases. We systematically categorize\nbiases into several dimensions. Our survey synthesizes current research\nfindings and discusses the implications of biases in real-world applications.\nAdditionally, we critically assess existing bias mitigation techniques and\npropose future research directions to enhance fairness and equity in LLMs. This\nsurvey serves as a foundational resource for researchers, practitioners, and\npolicymakers concerned with addressing and understanding biases in LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "2 Tables, 1 Figure",
    "pdf_url": "http://arxiv.org/pdf/2409.16430v1",
    "published_date": "2024-09-24 19:50:38 UTC",
    "updated_date": "2024-09-24 19:50:38 UTC"
  },
  {
    "arxiv_id": "2409.16429v1",
    "title": "Leveraging Local Structure for Improving Model Explanations: An Information Propagation Approach",
    "authors": [
      "Ruo Yang",
      "Binghui Wang",
      "Mustafa Bilgic"
    ],
    "abstract": "Numerous explanation methods have been recently developed to interpret the\ndecisions made by deep neural network (DNN) models. For image classifiers,\nthese methods typically provide an attribution score to each pixel in the image\nto quantify its contribution to the prediction. However, most of these\nexplanation methods appropriate attribution scores to pixels independently,\neven though both humans and DNNs make decisions by analyzing a set of closely\nrelated pixels simultaneously. Hence, the attribution score of a pixel should\nbe evaluated jointly by considering itself and its structurally-similar pixels.\nWe propose a method called IProp, which models each pixel's individual\nattribution score as a source of explanatory information and explains the image\nprediction through the dynamic propagation of information across all pixels. To\nformulate the information propagation, IProp adopts the Markov Reward Process,\nwhich guarantees convergence, and the final status indicates the desired\npixels' attribution scores. Furthermore, IProp is compatible with any existing\nattribution-based explanation method. Extensive experiments on various\nexplanation methods and DNN models verify that IProp significantly improves\nthem on a variety of interpretability metrics.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.16429v1",
    "published_date": "2024-09-24 19:48:47 UTC",
    "updated_date": "2024-09-24 19:48:47 UTC"
  },
  {
    "arxiv_id": "2409.16427v3",
    "title": "HAICOSYSTEM: An Ecosystem for Sandboxing Safety Risks in Human-AI Interactions",
    "authors": [
      "Xuhui Zhou",
      "Hyunwoo Kim",
      "Faeze Brahman",
      "Liwei Jiang",
      "Hao Zhu",
      "Ximing Lu",
      "Frank Xu",
      "Bill Yuchen Lin",
      "Yejin Choi",
      "Niloofar Mireshghallah",
      "Ronan Le Bras",
      "Maarten Sap"
    ],
    "abstract": "AI agents are increasingly autonomous in their interactions with human users\nand tools, leading to increased interactional safety risks. We present\nHAICOSYSTEM, a framework examining AI agent safety within diverse and complex\nsocial interactions. HAICOSYSTEM features a modular sandbox environment that\nsimulates multi-turn interactions between human users and AI agents, where the\nAI agents are equipped with a variety of tools (e.g., patient management\nplatforms) to navigate diverse scenarios (e.g., a user attempting to access\nother patients' profiles). To examine the safety of AI agents in these\ninteractions, we develop a comprehensive multi-dimensional evaluation framework\nthat uses metrics covering operational, content-related, societal, and legal\nrisks. Through running 1840 simulations based on 92 scenarios across seven\ndomains (e.g., healthcare, finance, education), we demonstrate that HAICOSYSTEM\ncan emulate realistic user-AI interactions and complex tool use by AI agents.\nOur experiments show that state-of-the-art LLMs, both proprietary and\nopen-sourced, exhibit safety risks in over 50\\% cases, with models generally\nshowing higher risks when interacting with simulated malicious users. Our\nfindings highlight the ongoing challenge of building agents that can safely\nnavigate complex interactions, particularly when faced with malicious users. To\nfoster the AI agent safety ecosystem, we release a code platform that allows\npractitioners to create custom scenarios, simulate interactions, and evaluate\nthe safety and performance of their agents.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Both the second and third authors contributed equally",
    "pdf_url": "http://arxiv.org/pdf/2409.16427v3",
    "published_date": "2024-09-24 19:47:21 UTC",
    "updated_date": "2024-10-21 19:47:54 UTC"
  },
  {
    "arxiv_id": "2409.16425v1",
    "title": "Lessons for Editors of AI Incidents from the AI Incident Database",
    "authors": [
      "Kevin Paeth",
      "Daniel Atherton",
      "Nikiforos Pittaras",
      "Heather Frase",
      "Sean McGregor"
    ],
    "abstract": "As artificial intelligence (AI) systems become increasingly deployed across\nthe world, they are also increasingly implicated in AI incidents - harm events\nto individuals and society. As a result, industry, civil society, and\ngovernments worldwide are developing best practices and regulations for\nmonitoring and analyzing AI incidents. The AI Incident Database (AIID) is a\nproject that catalogs AI incidents and supports further research by providing a\nplatform to classify incidents for different operational and research-oriented\ngoals. This study reviews the AIID's dataset of 750+ AI incidents and two\nindependent taxonomies applied to these incidents to identify common challenges\nto indexing and analyzing AI incidents. We find that certain patterns of AI\nincidents present structural ambiguities that challenge incident databasing and\nexplore how epistemic uncertainty in AI incident reporting is unavoidable. We\ntherefore report mitigations to make incident processes more robust to\nuncertainty related to cause, extent of harm, severity, or technical details of\nimplicated systems. With these findings, we discuss how to develop future AI\nincident reporting practices.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "8 pages, 0 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.16425v1",
    "published_date": "2024-09-24 19:46:58 UTC",
    "updated_date": "2024-09-24 19:46:58 UTC"
  },
  {
    "arxiv_id": "2409.16418v1",
    "title": "Task-oriented Prompt Enhancement via Script Generation",
    "authors": [
      "Chung-Yu Wang",
      "Alireza DaghighFarsoodeh",
      "Hung Viet Pham"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable abilities across\nvarious tasks, leveraging advanced reasoning. Yet, they struggle with\ntask-oriented prompts due to a lack of specific prior knowledge of the task\nanswers. The current state-of-the-art approach, PAL, utilizes code generation\nto address this issue. However, PAL depends on manually crafted prompt\ntemplates and examples while still producing inaccurate results. In this work,\nwe present TITAN-a novel strategy designed to enhance LLMs' performance on\ntask-oriented prompts. TITAN achieves this by generating scripts using a\nuniversal approach and zero-shot learning. Unlike existing methods, TITAN\neliminates the need for detailed task-specific instructions and extensive\nmanual efforts. TITAN enhances LLMs' performance on various tasks by utilizing\ntheir analytical and code-generation capabilities in a streamlined process.\nTITAN employs two key techniques: (1) step-back prompting to extract the task's\ninput specifications and (2) chain-of-thought prompting to identify required\nprocedural steps. This information is used to improve the LLMs' code-generation\nprocess. TITAN further refines the generated script through post-processing and\nthe script is executed to retrieve the final answer. Our comprehensive\nevaluation demonstrates TITAN's effectiveness in a diverse set of tasks. On\naverage, TITAN outperforms the state-of-the-art zero-shot approach by 7.6% and\n3.9% when paired with GPT-3.5 and GPT-4. Overall, without human annotation,\nTITAN achieves state-of-the-art performance in 8 out of 11 cases while only\nmarginally losing to few-shot approaches (which needed human intervention) on\nthree occasions by small margins. This work represents a significant\nadvancement in addressing task-oriented prompts, offering a novel solution for\neffectively utilizing LLMs in everyday life tasks.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "17 pages + reference",
    "pdf_url": "http://arxiv.org/pdf/2409.16418v1",
    "published_date": "2024-09-24 19:32:08 UTC",
    "updated_date": "2024-09-24 19:32:08 UTC"
  },
  {
    "arxiv_id": "2409.16416v1",
    "title": "Selection of Prompt Engineering Techniques for Code Generation through Predicting Code Complexity",
    "authors": [
      "Chung-Yu Wang",
      "Alireza DaghighFarsoodeh",
      "Hung Viet Pham"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated impressive performance in\nsoftware engineering tasks. However, improving their accuracy in generating\ncorrect and reliable code remains challenging. Numerous prompt engineering\ntechniques (PETs) have been developed to address this, but no single approach\nis universally optimal. Selecting the right PET for each query is difficult for\ntwo primary reasons: (1) interactive prompting techniques may not consistently\ndeliver the expected benefits, especially for simpler queries, and (2) current\nautomated prompt engineering methods lack adaptability and fail to fully\nutilize multi-stage responses. To overcome these challenges, we propose\nPET-Select, a PET-agnostic selection model that uses code complexity as a proxy\nto classify queries and select the most appropriate PET. By incorporating\ncontrastive learning, PET-Select effectively distinguishes between simple and\ncomplex problems, allowing it to choose PETs that are best suited for each\nquery's complexity level. Our evaluations on the MBPP and HumanEval benchmarks\nusing GPT-3.5 Turbo and GPT-4o show up to a 1.9% improvement in pass@1\naccuracy, along with a 74.8% reduction in token usage. Additionally, we provide\nboth quantitative and qualitative results to demonstrate how PET-Select\neffectively selects the most appropriate techniques for each code generation\nquery, further showcasing its efficiency in optimizing PET selection.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "18 pages + reference",
    "pdf_url": "http://arxiv.org/pdf/2409.16416v1",
    "published_date": "2024-09-24 19:28:55 UTC",
    "updated_date": "2024-09-24 19:28:55 UTC"
  },
  {
    "arxiv_id": "2409.16408v2",
    "title": "Modern Hopfield Networks meet Encoded Neural Representations -- Addressing Practical Considerations",
    "authors": [
      "Satyananda Kashyap",
      "Niharika S. D'Souza",
      "Luyao Shi",
      "Ken C. L. Wong",
      "Hongzhi Wang",
      "Tanveer Syeda-Mahmood"
    ],
    "abstract": "Content-addressable memories such as Modern Hopfield Networks (MHN) have been\nstudied as mathematical models of auto-association and storage/retrieval in the\nhuman declarative memory, yet their practical use for large-scale content\nstorage faces challenges. Chief among them is the occurrence of meta-stable\nstates, particularly when handling large amounts of high dimensional content.\nThis paper introduces Hopfield Encoding Networks (HEN), a framework that\nintegrates encoded neural representations into MHNs to improve pattern\nseparability and reduce meta-stable states. We show that HEN can also be used\nfor retrieval in the context of hetero association of images with natural\nlanguage queries, thus removing the limitation of requiring access to partial\ncontent in the same domain. Experimental results demonstrate substantial\nreduction in meta-stable states and increased storage capacity while still\nenabling perfect recall of a significantly larger number of inputs advancing\nthe practical utility of associative memory networks for real-world tasks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.IR",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "17 pages, 8 figures, accepted as a workshop paper at UniReps @\n  Neurips 2024",
    "pdf_url": "http://arxiv.org/pdf/2409.16408v2",
    "published_date": "2024-09-24 19:17:15 UTC",
    "updated_date": "2024-10-30 22:35:58 UTC"
  },
  {
    "arxiv_id": "2409.16395v2",
    "title": "HELIOT: LLM-Based CDSS for Adverse Drug Reaction Management",
    "authors": [
      "Gabriele De Vito",
      "Filomena Ferrucci",
      "Athanasios Angelakis"
    ],
    "abstract": "Medication errors significantly threaten patient safety, leading to adverse\ndrug events and substantial economic burdens on healthcare systems. Clinical\nDecision Support Systems (CDSSs) aimed at mitigating these errors often face\nlimitations when processing unstructured clinical data, including reliance on\nstatic databases and rule-based algorithms, frequently generating excessive\nalerts that lead to alert fatigue among healthcare providers. This paper\nintroduces HELIOT, an innovative CDSS for adverse drug reaction management that\nprocesses free-text clinical information using Large Language Models (LLMs)\nintegrated with a comprehensive pharmaceutical data repository. HELIOT\nleverages advanced natural language processing capabilities to interpret\nmedical narratives, extract relevant drug reaction information from\nunstructured clinical notes, and learn from past patient-specific medication\ntolerances to reduce false alerts, enabling more nuanced and contextual adverse\ndrug event warnings across primary care, specialist consultations, and hospital\nsettings. An initial evaluation using a synthetic dataset of clinical\nnarratives and expert-verified ground truth shows promising results. HELIOT\nachieves high accuracy in a controlled setting. In addition, by intelligently\nanalyzing previous medication tolerance documented in clinical notes and\ndistinguishing between cases requiring different alert types, HELIOT can\npotentially reduce interruptive alerts by over 50% compared to traditional\nCDSSs. While these preliminary findings are encouraging, real-world validation\nwill be essential to confirm these benefits in clinical practice.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.16395v2",
    "published_date": "2024-09-24 18:55:10 UTC",
    "updated_date": "2025-04-13 18:36:21 UTC"
  },
  {
    "arxiv_id": "2409.16392v2",
    "title": "Rao-Blackwellized POMDP Planning",
    "authors": [
      "Jiho Lee",
      "Nisar R. Ahmed",
      "Kyle H. Wray",
      "Zachary N. Sunberg"
    ],
    "abstract": "Partially Observable Markov Decision Processes (POMDPs) provide a structured\nframework for decision-making under uncertainty, but their application requires\nefficient belief updates. Sequential Importance Resampling Particle Filters\n(SIRPF), also known as Bootstrap Particle Filters, are commonly used as belief\nupdaters in large approximate POMDP solvers, but they face challenges such as\nparticle deprivation and high computational costs as the system's state\ndimension grows. To address these issues, this study introduces\nRao-Blackwellized POMDP (RB-POMDP) approximate solvers and outlines generic\nmethods to apply Rao-Blackwellization in both belief updates and online\nplanning. We compare the performance of SIRPF and Rao-Blackwellized Particle\nFilters (RBPF) in a simulated localization problem where an agent navigates\ntoward a target in a GPS-denied environment using POMCPOW and RB-POMCPOW\nplanners. Our results not only confirm that RBPFs maintain accurate belief\napproximations over time with fewer particles, but, more surprisingly, RBPFs\ncombined with quadrature-based integration improve planning quality\nsignificantly compared to SIRPF-based planning under the same computational\nlimits.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.16392v2",
    "published_date": "2024-09-24 18:46:50 UTC",
    "updated_date": "2025-03-03 20:56:33 UTC"
  },
  {
    "arxiv_id": "2409.16376v2",
    "title": "Beyond Text-to-Text: An Overview of Multimodal and Generative Artificial Intelligence for Education Using Topic Modeling",
    "authors": [
      "Ville Heilala",
      "Roberto Araya",
      "Raija Hämäläinen"
    ],
    "abstract": "Generative artificial intelligence (GenAI) can reshape education and\nlearning. While large language models (LLMs) like ChatGPT dominate current\neducational research, multimodal capabilities, such as text-to-speech and\ntext-to-image, are less explored. This study uses topic modeling to map the\nresearch landscape of multimodal and generative AI in education. An extensive\nliterature search using Dimensions yielded 4175 articles. Employing a topic\nmodeling approach, latent topics were extracted, resulting in 38 interpretable\ntopics organized into 14 thematic areas. Findings indicate a predominant focus\non text-to-text models in educational contexts, with other modalities\nunderexplored, overlooking the broader potential of multimodal approaches. The\nresults suggest a research gap, stressing the importance of more balanced\nattention across different AI modalities and educational levels. In summary,\nthis research provides an overview of current trends in generative AI for\neducation, underlining opportunities for future exploration of multimodal\ntechnologies to fully realize the transformative potential of artificial\nintelligence in education.",
    "categories": [
      "cs.AI",
      "cs.HC",
      "I.2; K.3.0"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.16376v2",
    "published_date": "2024-09-24 18:11:24 UTC",
    "updated_date": "2025-04-02 10:19:10 UTC"
  },
  {
    "arxiv_id": "2409.16287v2",
    "title": "Articulated Object Manipulation using Online Axis Estimation with SAM2-Based Tracking",
    "authors": [
      "Xi Wang",
      "Tianxing Chen",
      "Qiaojun Yu",
      "Tianling Xu",
      "Zanxin Chen",
      "Yiting Fu",
      "Ziqi He",
      "Cewu Lu",
      "Yao Mu",
      "Ping Luo"
    ],
    "abstract": "Articulated object manipulation requires precise object interaction, where\nthe object's axis must be carefully considered. Previous research employed\ninteractive perception for manipulating articulated objects, but typically,\nopen-loop approaches often suffer from overlooking the interaction dynamics. To\naddress this limitation, we present a closed-loop pipeline integrating\ninteractive perception with online axis estimation from segmented 3D point\nclouds. Our method leverages any interactive perception technique as a\nfoundation for interactive perception, inducing slight object movement to\ngenerate point cloud frames of the evolving dynamic scene. These point clouds\nare then segmented using Segment Anything Model 2 (SAM2), after which the\nmoving part of the object is masked for accurate motion online axis estimation,\nguiding subsequent robotic actions. Our approach significantly enhances the\nprecision and efficiency of manipulation tasks involving articulated objects.\nExperiments in simulated environments demonstrate that our method outperforms\nbaseline approaches, especially in tasks that demand precise axis-based\ncontrol. Project Page:\nhttps://hytidel.github.io/video-tracking-for-axis-estimation/.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.GR",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "Project Page:\n  https://hytidel.github.io/video-tracking-for-axis-estimation/",
    "pdf_url": "http://arxiv.org/pdf/2409.16287v2",
    "published_date": "2024-09-24 17:59:56 UTC",
    "updated_date": "2025-03-07 01:24:50 UTC"
  },
  {
    "arxiv_id": "2409.16252v2",
    "title": "Fields of The World: A Machine Learning Benchmark Dataset For Global Agricultural Field Boundary Segmentation",
    "authors": [
      "Hannah Kerner",
      "Snehal Chaudhari",
      "Aninda Ghosh",
      "Caleb Robinson",
      "Adeel Ahmad",
      "Eddie Choi",
      "Nathan Jacobs",
      "Chris Holmes",
      "Matthias Mohr",
      "Rahul Dodhia",
      "Juan M. Lavista Ferres",
      "Jennifer Marcus"
    ],
    "abstract": "Crop field boundaries are foundational datasets for agricultural monitoring\nand assessments but are expensive to collect manually. Machine learning (ML)\nmethods for automatically extracting field boundaries from remotely sensed\nimages could help realize the demand for these datasets at a global scale.\nHowever, current ML methods for field instance segmentation lack sufficient\ngeographic coverage, accuracy, and generalization capabilities. Further,\nresearch on improving ML methods is restricted by the lack of labeled datasets\nrepresenting the diversity of global agricultural fields. We present Fields of\nThe World (FTW) -- a novel ML benchmark dataset for agricultural field instance\nsegmentation spanning 24 countries on four continents (Europe, Africa, Asia,\nand South America). FTW is an order of magnitude larger than previous datasets\nwith 70,462 samples, each containing instance and semantic segmentation masks\npaired with multi-date, multi-spectral Sentinel-2 satellite images. We provide\nresults from baseline models for the new FTW benchmark, show that models\ntrained on FTW have better zero-shot and fine-tuning performance in held-out\ncountries than models that aren't pre-trained with diverse datasets, and show\npositive qualitative zero-shot results of FTW models in a real-world scenario\n-- running on Sentinel-2 scenes over Ethiopia.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at the AAAI-2025 Artificial Intelligence for Social Impact\n  (AISI) track",
    "pdf_url": "http://arxiv.org/pdf/2409.16252v2",
    "published_date": "2024-09-24 17:20:58 UTC",
    "updated_date": "2024-12-19 21:41:29 UTC"
  },
  {
    "arxiv_id": "2409.16241v1",
    "title": "LLM Echo Chamber: personalized and automated disinformation",
    "authors": [
      "Tony Ma"
    ],
    "abstract": "Recent advancements have showcased the capabilities of Large Language Models\nlike GPT4 and Llama2 in tasks such as summarization, translation, and content\nreview. However, their widespread use raises concerns, particularly around the\npotential for LLMs to spread persuasive, humanlike misinformation at scale,\nwhich could significantly influence public opinion. This study examines these\nrisks, focusing on LLMs ability to propagate misinformation as factual. To\ninvestigate this, we built the LLM Echo Chamber, a controlled digital\nenvironment simulating social media chatrooms, where misinformation often\nspreads. Echo chambers, where individuals only interact with like minded\npeople, further entrench beliefs. By studying malicious bots spreading\nmisinformation in this environment, we can better understand this phenomenon.\nWe reviewed current LLMs, explored misinformation risks, and applied sota\nfinetuning techniques. Using Microsoft phi2 model, finetuned with our custom\ndataset, we generated harmful content to create the Echo Chamber. This setup,\nevaluated by GPT4 for persuasiveness and harmfulness, sheds light on the\nethical concerns surrounding LLMs and emphasizes the need for stronger\nsafeguards against misinformation.",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "42 pages",
    "pdf_url": "http://arxiv.org/pdf/2409.16241v1",
    "published_date": "2024-09-24 17:04:12 UTC",
    "updated_date": "2024-09-24 17:04:12 UTC"
  },
  {
    "arxiv_id": "2409.16340v1",
    "title": "Future-Proofing Medical Imaging with Privacy-Preserving Federated Learning and Uncertainty Quantification: A Review",
    "authors": [
      "Nikolas Koutsoubis",
      "Asim Waqas",
      "Yasin Yilmaz",
      "Ravi P. Ramachandran",
      "Matthew Schabath",
      "Ghulam Rasool"
    ],
    "abstract": "Artificial Intelligence (AI) has demonstrated significant potential in\nautomating various medical imaging tasks, which could soon become routine in\nclinical practice for disease diagnosis, prognosis, treatment planning, and\npost-treatment surveillance. However, the privacy concerns surrounding patient\ndata present a major barrier to the widespread adoption of AI in medical\nimaging, as large, diverse training datasets are essential for developing\naccurate, generalizable, and robust Artificial intelligence models. Federated\nLearning (FL) offers a solution that enables organizations to train AI models\ncollaboratively without sharing sensitive data. federated learning exchanges\nmodel training information, such as gradients, between the participating sites.\nDespite its promise, federated learning is still in its developmental stages\nand faces several challenges. Notably, sensitive information can still be\ninferred from the gradients shared during model training. Quantifying AI\nmodels' uncertainty is vital due to potential data distribution shifts\npost-deployment, which can affect model performance. Uncertainty quantification\n(UQ) in FL is particularly challenging due to data heterogeneity across\nparticipating sites. This review provides a comprehensive examination of FL,\nprivacy-preserving FL (PPFL), and UQ in FL. We identify key gaps in current FL\nmethodologies and propose future research directions to enhance data privacy\nand trustworthiness in medical imaging applications.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "21 pages, 5 figures, 4 tables, Review paper, preprint to Radiology\n  AI. arXiv admin note: text overlap with arXiv:2406.12815",
    "pdf_url": "http://arxiv.org/pdf/2409.16340v1",
    "published_date": "2024-09-24 16:55:32 UTC",
    "updated_date": "2024-09-24 16:55:32 UTC"
  },
  {
    "arxiv_id": "2409.16239v1",
    "title": "Label-Augmented Dataset Distillation",
    "authors": [
      "Seoungyoon Kang",
      "Youngsun Lim",
      "Hyunjung Shim"
    ],
    "abstract": "Traditional dataset distillation primarily focuses on image representation\nwhile often overlooking the important role of labels. In this study, we\nintroduce Label-Augmented Dataset Distillation (LADD), a new dataset\ndistillation framework enhancing dataset distillation with label augmentations.\nLADD sub-samples each synthetic image, generating additional dense labels to\ncapture rich semantics. These dense labels require only a 2.5% increase in\nstorage (ImageNet subsets) with significant performance benefits, providing\nstrong learning signals. Our label generation strategy can complement existing\ndataset distillation methods for significantly enhancing their training\nefficiency and performance. Experimental results demonstrate that LADD\noutperforms existing methods in terms of computational overhead and accuracy.\nWith three high-performance dataset distillation algorithms, LADD achieves\nremarkable gains by an average of 14.9% in accuracy. Furthermore, the\neffectiveness of our method is proven across various datasets, distillation\nhyperparameters, and algorithms. Finally, our method improves the\ncross-architecture robustness of the distilled dataset, which is important in\nthe application scenario.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.16239v1",
    "published_date": "2024-09-24 16:54:22 UTC",
    "updated_date": "2024-09-24 16:54:22 UTC"
  },
  {
    "arxiv_id": "2409.16238v2",
    "title": "Efficiently Learning Probabilistic Logical Models by Cheaply Ranking Mined Rules",
    "authors": [
      "Jonathan Feldstein",
      "Dominic Phillips",
      "Efthymia Tsamoura"
    ],
    "abstract": "Probabilistic logical models are a core component of neurosymbolic AI and are\nimportant in their own right for tasks that require high explainability. Unlike\nneural networks, logical theories that underlie the model are often handcrafted\nusing domain expertise, making their development costly and prone to errors.\nWhile there are algorithms that learn logical theories from data, they are\ngenerally prohibitively expensive, limiting their applicability in real-world\nsettings. Here, we introduce precision and recall for logical rules and define\ntheir composition as rule utility -- a cost-effective measure of the predictive\npower of logical theories. We also introduce SPECTRUM, a scalable framework for\nlearning logical theories from relational data. Its scalability derives from a\nlinear-time algorithm that mines recurrent subgraphs in the data graph along\nwith a second algorithm that, using the cheap utility measure, efficiently\nranks rules derived from these subgraphs. Finally, we prove theoretical\nguarantees on the utility of the learnt logical theory. As a result, we\ndemonstrate across various tasks that SPECTRUM scales to larger datasets, often\nlearning more accurate logical theories on CPUs in < 1% the runtime of SOTA\nneural network approaches on GPUs.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "21 pages",
    "pdf_url": "http://arxiv.org/pdf/2409.16238v2",
    "published_date": "2024-09-24 16:54:12 UTC",
    "updated_date": "2025-02-28 16:29:51 UTC"
  },
  {
    "arxiv_id": "2409.16231v1",
    "title": "Predicting Deterioration in Mild Cognitive Impairment with Survival Transformers, Extreme Gradient Boosting and Cox Proportional Hazard Modelling",
    "authors": [
      "Henry Musto",
      "Daniel Stamate",
      "Doina Logofatu",
      "Daniel Stahl"
    ],
    "abstract": "The paper proposes a novel approach of survival transformers and extreme\ngradient boosting models in predicting cognitive deterioration in individuals\nwith mild cognitive impairment (MCI) using metabolomics data in the ADNI\ncohort. By leveraging advanced machine learning and transformer-based\ntechniques applied in survival analysis, the proposed approach highlights the\npotential of these techniques for more accurate early detection and\nintervention in Alzheimer's dementia disease. This research also underscores\nthe importance of non-invasive biomarkers and innovative modelling tools in\nenhancing the accuracy of dementia risk assessments, offering new avenues for\nclinical practice and patient care. A comprehensive Monte Carlo simulation\nprocedure consisting of 100 repetitions of a nested cross-validation in which\nmodels were trained and evaluated, indicates that the survival machine learning\nmodels based on Transformer and XGBoost achieved the highest mean C-index\nperformances, namely 0.85 and 0.8, respectively, and that they are superior to\nthe conventional survival analysis Cox Proportional Hazards model which\nachieved a mean C-Index of 0.77. Moreover, based on the standard deviations of\nthe C-Index performances obtained in the Monte Carlo simulation, we established\nthat both survival machine learning models above are more stable than the\nconventional statistical model.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to ICANN 2024",
    "pdf_url": "http://arxiv.org/pdf/2409.16231v1",
    "published_date": "2024-09-24 16:49:43 UTC",
    "updated_date": "2024-09-24 16:49:43 UTC"
  },
  {
    "arxiv_id": "2409.16223v3",
    "title": "Fine-Tuning is Fine, if Calibrated",
    "authors": [
      "Zheda Mai",
      "Arpita Chowdhury",
      "Ping Zhang",
      "Cheng-Hao Tu",
      "Hong-You Chen",
      "Vardaan Pahuja",
      "Tanya Berger-Wolf",
      "Song Gao",
      "Charles Stewart",
      "Yu Su",
      "Wei-Lun Chao"
    ],
    "abstract": "Fine-tuning is arguably the most straightforward way to tailor a pre-trained\nmodel (e.g., a foundation model) to downstream applications, but it also comes\nwith the risk of losing valuable knowledge the model had learned in\npre-training. For example, fine-tuning a pre-trained classifier capable of\nrecognizing a large number of classes to master a subset of classes at hand is\nshown to drastically degrade the model's accuracy in the other classes it had\npreviously learned. As such, it is hard to further use the fine-tuned model\nwhen it encounters classes beyond the fine-tuning data. In this paper, we\nsystematically dissect the issue, aiming to answer the fundamental question,\n\"What has been damaged in the fine-tuned model?\" To our surprise, we find that\nthe fine-tuned model neither forgets the relationship among the other classes\nnor degrades the features to recognize these classes. Instead, the fine-tuned\nmodel often produces more discriminative features for these other classes, even\nif they were missing during fine-tuning! {What really hurts the accuracy is the\ndiscrepant logit scales between the fine-tuning classes and the other classes},\nimplying that a simple post-processing calibration would bring back the\npre-trained model's capability and at the same time unveil the feature\nimprovement over all classes. We conduct an extensive empirical study to\ndemonstrate the robustness of our findings and provide preliminary explanations\nunderlying them, suggesting new directions for future theoretical analysis. Our\ncode is available at\nhttps://github.com/OSU-MLB/Fine-Tuning-Is-Fine-If-Calibrated.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "The paper has been accepted to NeurIPS 2024. The first three authors\n  contribute equally",
    "pdf_url": "http://arxiv.org/pdf/2409.16223v3",
    "published_date": "2024-09-24 16:35:16 UTC",
    "updated_date": "2024-10-13 23:07:33 UTC"
  },
  {
    "arxiv_id": "2409.16220v1",
    "title": "Towards Enhancing Linked Data Retrieval in Conversational UIs using Large Language Models",
    "authors": [
      "Omar Mussa",
      "Omer Rana",
      "Benoît Goossens",
      "Pablo Orozco-Terwengel",
      "Charith Perera"
    ],
    "abstract": "Despite the recent broad adoption of Large Language Models (LLMs) across\nvarious domains, their potential for enriching information systems in\nextracting and exploring Linked Data (LD) and Resource Description Framework\n(RDF) triplestores has not been extensively explored. This paper examines the\nintegration of LLMs within existing systems, emphasising the enhancement of\nconversational user interfaces (UIs) and their capabilities for data extraction\nby producing more accurate SPARQL queries without the requirement for model\nretraining. Typically, conversational UI models necessitate retraining with the\nintroduction of new datasets or updates, limiting their functionality as\ngeneral-purpose extraction tools. Our approach addresses this limitation by\nincorporating LLMs into the conversational UI workflow, significantly enhancing\ntheir ability to comprehend and process user queries effectively. By leveraging\nthe advanced natural language understanding capabilities of LLMs, our method\nimproves RDF entity extraction within web systems employing conventional\nchatbots. This integration facilitates a more nuanced and context-aware\ninteraction model, critical for handling the complex query patterns often\nencountered in RDF datasets and Linked Open Data (LOD) endpoints. The\nevaluation of this methodology shows a marked enhancement in system\nexpressivity and the accuracy of responses to user queries, indicating a\npromising direction for future research in this area. This investigation not\nonly underscores the versatility of LLMs in enhancing existing information\nsystems but also sets the stage for further explorations into their potential\napplications within more specialised domains of web information systems.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.IR",
    "comment": "This paper has been accepted at the 25th International Web\n  Information Systems Engineering Conference (WISE 2024)",
    "pdf_url": "http://arxiv.org/pdf/2409.16220v1",
    "published_date": "2024-09-24 16:31:33 UTC",
    "updated_date": "2024-09-24 16:31:33 UTC"
  },
  {
    "arxiv_id": "2409.16218v1",
    "title": "Problem-oriented AutoML in Clustering",
    "authors": [
      "Matheus Camilo da Silva",
      "Gabriel Marques Tavares",
      "Eric Medvet",
      "Sylvio Barbon Junior"
    ],
    "abstract": "The Problem-oriented AutoML in Clustering (PoAC) framework introduces a\nnovel, flexible approach to automating clustering tasks by addressing the\nshortcomings of traditional AutoML solutions. Conventional methods often rely\non predefined internal Clustering Validity Indexes (CVIs) and static\nmeta-features, limiting their adaptability and effectiveness across diverse\nclustering tasks. In contrast, PoAC establishes a dynamic connection between\nthe clustering problem, CVIs, and meta-features, allowing users to customize\nthese components based on the specific context and goals of their task. At its\ncore, PoAC employs a surrogate model trained on a large meta-knowledge base of\nprevious clustering datasets and solutions, enabling it to infer the quality of\nnew clustering pipelines and synthesize optimal solutions for unseen datasets.\nUnlike many AutoML frameworks that are constrained by fixed evaluation metrics\nand algorithm sets, PoAC is algorithm-agnostic, adapting seamlessly to\ndifferent clustering problems without requiring additional data or retraining.\nExperimental results demonstrate that PoAC not only outperforms\nstate-of-the-art frameworks on a variety of datasets but also excels in\nspecific tasks such as data visualization, and highlight its ability to\ndynamically adjust pipeline configurations based on dataset complexity.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.16218v1",
    "published_date": "2024-09-24 16:25:53 UTC",
    "updated_date": "2024-09-24 16:25:53 UTC"
  },
  {
    "arxiv_id": "2409.16203v1",
    "title": "Facial Expression-Enhanced TTS: Combining Face Representation and Emotion Intensity for Adaptive Speech",
    "authors": [
      "Yunji Chu",
      "Yunseob Shim",
      "Unsang Park"
    ],
    "abstract": "We propose FEIM-TTS, an innovative zero-shot text-to-speech (TTS) model that\nsynthesizes emotionally expressive speech, aligned with facial images and\nmodulated by emotion intensity. Leveraging deep learning, FEIM-TTS transcends\ntraditional TTS systems by interpreting facial cues and adjusting to emotional\nnuances without dependence on labeled datasets. To address sparse\naudio-visual-emotional data, the model is trained using LRS3, CREMA-D, and MELD\ndatasets, demonstrating its adaptability. FEIM-TTS's unique capability to\nproduce high-quality, speaker-agnostic speech makes it suitable for creating\nadaptable voices for virtual characters. Moreover, FEIM-TTS significantly\nenhances accessibility for individuals with visual impairments or those who\nhave trouble seeing. By integrating emotional nuances into TTS, our model\nenables dynamic and engaging auditory experiences for webcomics, allowing\nvisually impaired users to enjoy these narratives more fully. Comprehensive\nevaluation evidences its proficiency in modulating emotion and intensity,\nadvancing emotional speech synthesis and accessibility. Samples are available\nat: https://feim-tts.github.io/.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "13 pages, 3 figures, accepted to ECCV Workshop ABAW(Affective\n  Behavior Analysis in-the-wild)7 (to be appear)",
    "pdf_url": "http://arxiv.org/pdf/2409.16203v1",
    "published_date": "2024-09-24 16:01:12 UTC",
    "updated_date": "2024-09-24 16:01:12 UTC"
  },
  {
    "arxiv_id": "2409.16202v2",
    "title": "CJEval: A Benchmark for Assessing Large Language Models Using Chinese Junior High School Exam Data",
    "authors": [
      "Qian-Wen Zhang",
      "Haochen Wang",
      "Fang Li",
      "Siyu An",
      "Lingfeng Qiao",
      "Liangcai Gao",
      "Di Yin",
      "Xing Sun"
    ],
    "abstract": "Online education platforms have significantly transformed the dissemination\nof educational resources by providing a dynamic and digital infrastructure.\nWith the further enhancement of this transformation, the advent of Large\nLanguage Models (LLMs) has elevated the intelligence levels of these platforms.\nHowever, current academic benchmarks provide limited guidance for real-world\nindustry scenarios. This limitation arises because educational applications\nrequire more than mere test question responses. To bridge this gap, we\nintroduce CJEval, a benchmark based on Chinese Junior High School Exam\nEvaluations. CJEval consists of 26,136 samples across four application-level\neducational tasks covering ten subjects. These samples include not only\nquestions and answers but also detailed annotations such as question types,\ndifficulty levels, knowledge concepts, and answer explanations. By utilizing\nthis benchmark, we assessed LLMs' potential applications and conducted a\ncomprehensive analysis of their performance by fine-tuning on various\neducational tasks. Extensive experiments and discussions have highlighted the\nopportunities and challenges of applying LLMs in the field of education.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.16202v2",
    "published_date": "2024-09-24 16:00:28 UTC",
    "updated_date": "2024-09-25 03:35:35 UTC"
  },
  {
    "arxiv_id": "2409.16198v1",
    "title": "Leveraging Estimated Transferability Over Human Intuition for Model Selection in Text Ranking",
    "authors": [
      "Jun Bai",
      "Zhuofan Chen",
      "Zhenzi Li",
      "Hanhua Hong",
      "Jianfei Zhang",
      "Chen Li",
      "Chenghua Lin",
      "Wenge Rong"
    ],
    "abstract": "Text ranking has witnessed significant advancements, attributed to the\nutilization of dual-encoder enhanced by Pre-trained Language Models (PLMs).\nGiven the proliferation of available PLMs, selecting the most effective one for\na given dataset has become a non-trivial challenge. As a promising alternative\nto human intuition and brute-force fine-tuning, Transferability Estimation (TE)\nhas emerged as an effective approach to model selection. However, current TE\nmethods are primarily designed for classification tasks, and their estimated\ntransferability may not align well with the objectives of text ranking. To\naddress this challenge, we propose to compute the expected rank as\ntransferability, explicitly reflecting the model's ranking capability.\nFurthermore, to mitigate anisotropy and incorporate training dynamics, we\nadaptively scale isotropic sentence embeddings to yield an accurate expected\nrank score. Our resulting method, Adaptive Ranking Transferability (AiRTran),\ncan effectively capture subtle differences between models. On challenging model\nselection scenarios across various text ranking datasets, it demonstrates\nsignificant improvements over previous classification-oriented TE methods,\nhuman intuition, and ChatGPT with minor time consumption.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted by EMNLP 2024 main conference",
    "pdf_url": "http://arxiv.org/pdf/2409.16198v1",
    "published_date": "2024-09-24 15:48:03 UTC",
    "updated_date": "2024-09-24 15:48:03 UTC"
  },
  {
    "arxiv_id": "2409.16197v3",
    "title": "Second Order Bounds for Contextual Bandits with Function Approximation",
    "authors": [
      "Aldo Pacchiano"
    ],
    "abstract": "Many works have developed no-regret algorithms for contextual bandits with\nfunction approximation, where the mean reward function over context-action\npairs belongs to a function class. Although there are many approaches to this\nproblem, one that has gained in importance is the use of algorithms based on\nthe optimism principle such as optimistic least squares. It can be shown the\nregret of this algorithm scales as square root of the product of the eluder\ndimension (a statistical measure of the complexity of the function class), the\nlogarithm of the function class size and the time horizon. Unfortunately, even\nif the variance of the measurement noise of the rewards at each time is\nchanging and is very small, the regret of the optimistic least squares\nalgorithm scales with square root of the time horizon. In this work we are the\nfirst to develop algorithms that satisfy regret bounds of scaling not with the\nsquare root of the time horizon, but the square root of the sum of the\nmeasurement variances in the setting of contextual bandits with function\napproximation when the variances are unknown. These bounds generalize existing\ntechniques for deriving second order bounds in contextual linear problems.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "13 pages main, 34 pages total",
    "pdf_url": "http://arxiv.org/pdf/2409.16197v3",
    "published_date": "2024-09-24 15:42:04 UTC",
    "updated_date": "2025-03-15 19:53:31 UTC"
  },
  {
    "arxiv_id": "2409.16176v1",
    "title": "Cyber Knowledge Completion Using Large Language Models",
    "authors": [
      "Braden K Webb",
      "Sumit Purohit",
      "Rounak Meyur"
    ],
    "abstract": "The integration of the Internet of Things (IoT) into Cyber-Physical Systems\n(CPSs) has expanded their cyber-attack surface, introducing new and\nsophisticated threats with potential to exploit emerging vulnerabilities.\nAssessing the risks of CPSs is increasingly difficult due to incomplete and\noutdated cybersecurity knowledge. This highlights the urgent need for\nbetter-informed risk assessments and mitigation strategies. While previous\nefforts have relied on rule-based natural language processing (NLP) tools to\nmap vulnerabilities, weaknesses, and attack patterns, recent advancements in\nLarge Language Models (LLMs) present a unique opportunity to enhance\ncyber-attack knowledge completion through improved reasoning, inference, and\nsummarization capabilities. We apply embedding models to encapsulate\ninformation on attack patterns and adversarial techniques, generating mappings\nbetween them using vector embeddings. Additionally, we propose a\nRetrieval-Augmented Generation (RAG)-based approach that leverages pre-trained\nmodels to create structured mappings between different taxonomies of threat\npatterns. Further, we use a small hand-labeled dataset to compare the proposed\nRAG-based approach to a baseline standard binary classification model. Thus,\nthe proposed approach provides a comprehensive framework to address the\nchallenge of cyber-attack knowledge graph completion.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "J.7; H.3.3"
    ],
    "primary_category": "cs.CR",
    "comment": "7 pages, 2 figures. Submitted to 2024 IEEE International Conference\n  on Big Data",
    "pdf_url": "http://arxiv.org/pdf/2409.16176v1",
    "published_date": "2024-09-24 15:20:39 UTC",
    "updated_date": "2024-09-24 15:20:39 UTC"
  },
  {
    "arxiv_id": "2409.16167v3",
    "title": "Merging LoRAs like Playing LEGO: Pushing the Modularity of LoRA to Extremes Through Rank-Wise Clustering",
    "authors": [
      "Ziyu Zhao",
      "Tao Shen",
      "Didi Zhu",
      "Zexi Li",
      "Jing Su",
      "Xuwu Wang",
      "Kun Kuang",
      "Fei Wu"
    ],
    "abstract": "Low-Rank Adaptation (LoRA) has emerged as a popular technique for fine-tuning\nlarge language models (LLMs) to various domains due to its modular design and\nwidespread availability on platforms like Huggingface. This modularity has\nsparked interest in combining multiple LoRAs to enhance LLM capabilities.\nHowever, existing methods for LoRA composition primarily focus on task-specific\nadaptations that require additional training, and current model merging\ntechniques often fail to fully leverage LoRA's modular nature, leading to\nparameter interference and performance degradation. In this paper, we\ninvestigate the feasibility of disassembling and reassembling multiple LoRAs at\na finer granularity, analogous to assembling LEGO blocks. We introduce the\nconcept of Minimal Semantic Units (MSUs), where the parameters corresponding to\neach rank in LoRA function as independent units. These MSUs demonstrate\npermutation invariance and concatenation-summation equivalence properties,\nenabling flexible combinations to create new LoRAs. Building on these insights,\nwe propose the LoRA-LEGO framework. This framework conducts rank-wise parameter\nclustering by grouping MSUs from different LoRAs into $k$ clusters. The\ncentroid of each cluster serves as a representative MSU, enabling the assembly\nof a merged LoRA with an adjusted rank of $k$. Additionally, we apply a dual\nreweighting strategy to optimize the scale of the merged LoRA. Experiments\nacross various benchmarks demonstrate that our method outperforms existing\napproaches in LoRA merging.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.16167v3",
    "published_date": "2024-09-24 15:08:41 UTC",
    "updated_date": "2024-10-22 02:29:22 UTC"
  },
  {
    "arxiv_id": "2409.16165v2",
    "title": "Interactive Tools Substantially Assist LM Agents in Finding Security Vulnerabilities",
    "authors": [
      "Talor Abramovich",
      "Meet Udeshi",
      "Minghao Shao",
      "Kilian Lieret",
      "Haoran Xi",
      "Kimberly Milner",
      "Sofija Jancheska",
      "John Yang",
      "Carlos E. Jimenez",
      "Farshad Khorrami",
      "Prashanth Krishnamurthy",
      "Brendan Dolan-Gavitt",
      "Muhammad Shafique",
      "Karthik Narasimhan",
      "Ramesh Karri",
      "Ofir Press"
    ],
    "abstract": "Although language model (LM) agents have demonstrated increased performance\nin multiple domains, including coding and web-browsing, their success in\ncybersecurity has been limited. We present EnIGMA, an LM agent for autonomously\nsolving Capture The Flag (CTF) challenges. We introduce new tools and\ninterfaces to improve the agent's ability to find and exploit security\nvulnerabilities, focusing on interactive terminal programs. These novel\nInteractive Agent Tools enable LM agents, for the first time, to run\ninteractive utilities, such as a debugger and a server connection tool, which\nare essential for solving these challenges. Empirical analysis on 390 CTF\nchallenges across four benchmarks demonstrate that these new tools and\ninterfaces substantially improve our agent's performance, achieving\nstate-of-the-art results on NYU CTF, Intercode-CTF, and CyBench. Finally, we\nanalyze data leakage, developing new methods to quantify it and identifying a\nnew phenomenon we term soliloquizing, where the model self-generates\nhallucinated observations without interacting with the environment. Our code\nand development dataset are available at\nhttps://github.com/SWE-agent/SWE-agent/tree/v0.7 and\nhttps://github.com/NYU-LLM-CTF/NYU_CTF_Bench/tree/main/development\nrespectively.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.16165v2",
    "published_date": "2024-09-24 15:06:01 UTC",
    "updated_date": "2025-02-04 09:49:41 UTC"
  },
  {
    "arxiv_id": "2409.16143v1",
    "title": "Seeing Faces in Things: A Model and Dataset for Pareidolia",
    "authors": [
      "Mark Hamilton",
      "Simon Stent",
      "Vasha DuTell",
      "Anne Harrington",
      "Jennifer Corbett",
      "Ruth Rosenholtz",
      "William T. Freeman"
    ],
    "abstract": "The human visual system is well-tuned to detect faces of all shapes and\nsizes. While this brings obvious survival advantages, such as a better chance\nof spotting unknown predators in the bush, it also leads to spurious face\ndetections. ``Face pareidolia'' describes the perception of face-like structure\namong otherwise random stimuli: seeing faces in coffee stains or clouds in the\nsky. In this paper, we study face pareidolia from a computer vision\nperspective. We present an image dataset of ``Faces in Things'', consisting of\nfive thousand web images with human-annotated pareidolic faces. Using this\ndataset, we examine the extent to which a state-of-the-art human face detector\nexhibits pareidolia, and find a significant behavioral gap between humans and\nmachines. We find that the evolutionary need for humans to detect animal faces,\nas well as human faces, may explain some of this gap. Finally, we propose a\nsimple statistical model of pareidolia in images. Through studies on human\nsubjects and our pareidolic face detectors we confirm a key prediction of our\nmodel regarding what image conditions are most likely to induce pareidolia.\nDataset and Website: https://aka.ms/faces-in-things",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.HC",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.16143v1",
    "published_date": "2024-09-24 14:50:21 UTC",
    "updated_date": "2024-09-24 14:50:21 UTC"
  },
  {
    "arxiv_id": "2409.16136v1",
    "title": "HA-FGOVD: Highlighting Fine-grained Attributes via Explicit Linear Composition for Open-Vocabulary Object Detection",
    "authors": [
      "Yuqi Ma",
      "Mengyin Liu",
      "Chao Zhu",
      "Xu-Cheng Yin"
    ],
    "abstract": "Open-vocabulary object detection (OVD) models are considered to be Large\nMulti-modal Models (LMM), due to their extensive training data and a large\nnumber of parameters. Mainstream OVD models prioritize object coarse-grained\ncategory rather than focus on their fine-grained attributes, e.g., colors or\nmaterials, thus failed to identify objects specified with certain attributes.\nHowever, OVD models are pretrained on large-scale image-text pairs with rich\nattribute words, whose latent feature space can represent the global text\nfeature as a linear composition of fine-grained attribute tokens without\nhighlighting them. Therefore, we propose in this paper a universal and explicit\napproach for frozen mainstream OVD models that boosts their attribute-level\ndetection capabilities by highlighting fine-grained attributes in explicit\nlinear space. Firstly, a LLM is leveraged to highlight attribute words within\nthe input text as a zero-shot prompted task. Secondly, by strategically\nadjusting the token masks, the text encoders of OVD models extract both global\ntext and attribute-specific features, which are then explicitly composited as\ntwo vectors in linear space to form the new attribute-highlighted feature for\ndetection tasks, where corresponding scalars are hand-crafted or learned to\nreweight both two vectors. Notably, these scalars can be seamlessly transferred\namong different OVD models, which proves that such an explicit linear\ncomposition is universal. Empirical evaluation on the FG-OVD dataset\ndemonstrates that our proposed method uniformly improves fine-grained\nattribute-level OVD of various mainstream models and achieves new\nstate-of-the-art performance.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "This work has been submitted to the IEEE for possible publication",
    "pdf_url": "http://arxiv.org/pdf/2409.16136v1",
    "published_date": "2024-09-24 14:43:14 UTC",
    "updated_date": "2024-09-24 14:43:14 UTC"
  },
  {
    "arxiv_id": "2409.16133v1",
    "title": "Implicit assessment of language learning during practice as accurate as explicit testing",
    "authors": [
      "Jue Hou",
      "Anisia Katinskaia",
      "Anh-Duc Vu",
      "Roman Yangarber"
    ],
    "abstract": "Assessment of proficiency of the learner is an essential part of Intelligent\nTutoring Systems (ITS). We use Item Response Theory (IRT) in computer-aided\nlanguage learning for assessment of student ability in two contexts: in test\nsessions, and in exercises during practice sessions. Exhaustive testing across\na wide range of skills can provide a detailed picture of proficiency, but may\nbe undesirable for a number of reasons. Therefore, we first aim to replace\nexhaustive tests with efficient but accurate adaptive tests. We use learner\ndata collected from exhaustive tests under imperfect conditions, to train an\nIRT model to guide adaptive tests. Simulations and experiments with real\nlearner data confirm that this approach is efficient and accurate. Second, we\nexplore whether we can accurately estimate learner ability directly from the\ncontext of practice with exercises, without testing. We transform learner data\ncollected from exercise sessions into a form that can be used for IRT modeling.\nThis is done by linking the exercises to {\\em linguistic constructs}; the\nconstructs are then treated as \"items\" within IRT. We present results from\nlarge-scale studies with thousands of learners. Using teacher assessments of\nstudent ability as \"ground truth,\" we compare the estimates obtained from tests\nvs. those from exercises. The experiments confirm that the IRT models can\nproduce accurate ability estimation based on exercises.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.16133v1",
    "published_date": "2024-09-24 14:40:44 UTC",
    "updated_date": "2024-09-24 14:40:44 UTC"
  },
  {
    "arxiv_id": "2409.16125v3",
    "title": "Analyzing Probabilistic Methods for Evaluating Agent Capabilities",
    "authors": [
      "Axel Højmark",
      "Govind Pimpale",
      "Arjun Panickssery",
      "Marius Hobbhahn",
      "Jérémy Scheurer"
    ],
    "abstract": "To mitigate risks from AI systems, we need to assess their capabilities\naccurately. This is especially difficult in cases where capabilities are only\nrarely displayed. Phuong et al. propose two methods that aim to obtain better\nestimates of the probability of an AI agent successfully completing a given\ntask. The milestone method decomposes tasks into subtasks, aiming to improve\noverall success rate estimation, while the expert best-of-N method leverages\nhuman guidance as a proxy for the model's independent performance.\n  Our analysis of these methods as Monte Carlo estimators reveals that while\nboth effectively reduce variance compared to naive Monte Carlo sampling, they\nalso introduce bias. Experimental results demonstrate that the milestone method\nunderestimates true solve rates for many real-world tasks due to its\nconstraining assumptions. The expert best-of-N method exhibits even more severe\nunderestimation across all tasks, attributed to an inherently flawed\nre-weighting factor. To enhance the accuracy of capability estimates of AI\nagents on difficult tasks, we suggest future work should leverage the rich\nliterature on Monte Carlo Estimators.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted (Poster) to SoLaR 2024",
    "pdf_url": "http://arxiv.org/pdf/2409.16125v3",
    "published_date": "2024-09-24 14:35:20 UTC",
    "updated_date": "2024-10-11 21:10:36 UTC"
  },
  {
    "arxiv_id": "2409.16120v1",
    "title": "MOSS: Enabling Code-Driven Evolution and Context Management for AI Agents",
    "authors": [
      "Ming Zhu",
      "Yi Zhou"
    ],
    "abstract": "Developing AI agents powered by large language models (LLMs) faces\nsignificant challenges in achieving true Turing completeness and adaptive,\ncode-driven evolution. Current approaches often generate code independently of\nits runtime context, relying heavily on the LLM's memory, which results in\ninefficiencies and limits adaptability. Manual protocol development in sandbox\nenvironments further constrains the agent's autonomous adaptability. Crucially,\nachieving consistency in code and context across multi-turn interactions and\nensuring isolation of local variables within each interaction remains an\nunsolved problem.\n  We introduce MOSS (llM-oriented Operating System Simulation), a novel\nframework that addresses these challenges by integrating code generation with a\ndynamic context management system. MOSS ensures consistency and adaptability by\nusing a mechanism that maintains the Python context across interactions,\nincluding isolation of local variables and preservation of runtime integrity.\nAt its core, the framework employs an Inversion of Control (IoC) container in\nconjunction with decorators to enforce the least knowledge principle, allowing\nagents to focus on abstract interfaces rather than concrete implementations.\nThis facilitates seamless integration of new tools and libraries, enables\nruntime instance replacement, and reduces prompt complexity, providing a \"what\nyou see is what you get\" environment for the agent.\n  Through a series of case studies, we show how this framework can enhance the\nefficiency and capabilities of agent development and highlight its advantages\nin moving towards Turing-complete agents capable of evolving through code.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.16120v1",
    "published_date": "2024-09-24 14:30:21 UTC",
    "updated_date": "2024-09-24 14:30:21 UTC"
  },
  {
    "arxiv_id": "2409.18807v1",
    "title": "LLM With Tools: A Survey",
    "authors": [
      "Zhuocheng Shen"
    ],
    "abstract": "The integration of tools in augmenting large language models presents a novel\napproach toward enhancing the efficiency and accuracy of these models in\nhandling specific, complex tasks. This paper delves into the\nmethodology,challenges, and developments in the realm of teaching LLMs to use\nexternal tools, thereby pushing the boundaries of their capabilities beyond\npre-existing knowledge bases. We introduce a standardized paradigm for tool\nintegration guided by a series of functions that map user instructions to\nactionable plans and their execution, emphasizing the significance of\nunderstanding user intent, tool selection, and dynamic plan adjustment. Our\nexploration reveals the various challenges encountered, such as tool invocation\ntiming, selection accuracy, and the need for robust reasoning processes. In\naddressing these challenges, we investigate techniques within the context of\nfine-tuning and incontext learning paradigms, highlighting innovative\napproaches to ensure diversity, augment datasets, and improve\ngeneralization.Furthermore, we investigate a perspective on enabling LLMs to\nnot only utilize but also autonomously create tools, which may redefine their\nrole from mere tool users to tool creators. Finally,we reproduced Chameleon's\nresults on ScienceQA and analyzed the code structure.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "10 pages",
    "pdf_url": "http://arxiv.org/pdf/2409.18807v1",
    "published_date": "2024-09-24 14:08:11 UTC",
    "updated_date": "2024-09-24 14:08:11 UTC"
  },
  {
    "arxiv_id": "2409.16106v2",
    "title": "Scenario of Use Scheme: Threat Model Specification for Speaker Privacy Protection in the Medical Domain",
    "authors": [
      "Mehtab Ur Rahman",
      "Martha Larson",
      "Louis ten Bosch",
      "Cristian Tejedor-García"
    ],
    "abstract": "Speech recordings are being more frequently used to detect and monitor\ndisease, leading to privacy concerns. Beyond cryptography, protection of speech\ncan be addressed by approaches, such as perturbation, disentanglement, and\nre-synthesis, that eliminate sensitive information of the speaker, leaving the\ninformation necessary for medical analysis purposes. In order for such privacy\nprotective approaches to be developed, clear and systematic specifications of\nassumptions concerning medical settings and the needs of medical professionals\nare necessary. In this paper, we propose a Scenario of Use Scheme that\nincorporates an Attacker Model, which characterizes the adversary against whom\nthe speaker's privacy must be defended, and a Protector Model, which specifies\nthe defense. We discuss the connection of the scheme with previous work on\nspeech privacy. Finally, we present a concrete example of a specified Scenario\nof Use and a set of experiments about protecting speaker data against gender\ninference attacks while maintaining utility for Parkinson's detection.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.CR",
      "cs.SD"
    ],
    "primary_category": "eess.AS",
    "comment": "Accepted and published at SPSC Symposium 2024 4th Symposium on\n  Security and Privacy in Speech Communication. Interspeech 2024",
    "pdf_url": "http://arxiv.org/pdf/2409.16106v2",
    "published_date": "2024-09-24 14:07:47 UTC",
    "updated_date": "2024-09-26 13:05:36 UTC"
  },
  {
    "arxiv_id": "2409.16099v1",
    "title": "Neuromorphic Drone Detection: an Event-RGB Multimodal Approach",
    "authors": [
      "Gabriele Magrini",
      "Federico Becattini",
      "Pietro Pala",
      "Alberto Del Bimbo",
      "Antonio Porta"
    ],
    "abstract": "In recent years, drone detection has quickly become a subject of extreme\ninterest: the potential for fast-moving objects of contained dimensions to be\nused for malicious intents or even terrorist attacks has posed attention to the\nnecessity for precise and resilient systems for detecting and identifying such\nelements. While extensive literature and works exist on object detection based\non RGB data, it is also critical to recognize the limits of such modality when\napplied to UAVs detection. Detecting drones indeed poses several challenges\nsuch as fast-moving objects and scenes with a high dynamic range or, even\nworse, scarce illumination levels. Neuromorphic cameras, on the other hand, can\nretain precise and rich spatio-temporal information in situations that are\nchallenging for RGB cameras. They are resilient to both high-speed moving\nobjects and scarce illumination settings, while prone to suffer a rapid loss of\ninformation when the objects in the scene are static. In this context, we\npresent a novel model for integrating both domains together, leveraging\nmultimodal data to take advantage of the best of both worlds. To this end, we\nalso release NeRDD (Neuromorphic-RGB Drone Detection), a novel\nspatio-temporally synchronized Event-RGB Drone detection dataset of more than\n3.5 hours of multimodal annotated recordings.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at NeVi Workshop at ECCV24",
    "pdf_url": "http://arxiv.org/pdf/2409.16099v1",
    "published_date": "2024-09-24 13:53:20 UTC",
    "updated_date": "2024-09-24 13:53:20 UTC"
  },
  {
    "arxiv_id": "2409.16098v2",
    "title": "The Digital Transformation in Health: How AI Can Improve the Performance of Health Systems",
    "authors": [
      "África Periáñez",
      "Ana Fernández del Río",
      "Ivan Nazarov",
      "Enric Jané",
      "Moiz Hassan",
      "Aditya Rastogi",
      "Dexian Tang"
    ],
    "abstract": "Mobile health has the potential to revolutionize health care delivery and\npatient engagement. In this work, we discuss how integrating Artificial\nIntelligence into digital health applications-focused on supply chain, patient\nmanagement, and capacity building, among other use cases-can improve the health\nsystem and public health performance. We present an Artificial Intelligence and\nReinforcement Learning platform that allows the delivery of adaptive\ninterventions whose impact can be optimized through experimentation and\nreal-time monitoring. The system can integrate multiple data sources and\ndigital health applications. The flexibility of this platform to connect to\nvarious mobile health applications and digital devices and send personalized\nrecommendations based on past data and predictions can significantly improve\nthe impact of digital tools on health system outcomes. The potential for\nresource-poor settings, where the impact of this approach on health outcomes\ncould be more decisive, is discussed specifically. This framework is, however,\nsimilarly applicable to improving efficiency in health systems where scarcity\nis not an issue.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY",
      "cs.HC"
    ],
    "primary_category": "cs.LG",
    "comment": "This is an original manuscript of an article published by Taylor &\n  Francis in Health Systems & Reform on 22 Oct 2024, available online:\n  https://www.tandfonline.com/doi/10.1080/23288604.2024.2387138",
    "pdf_url": "http://arxiv.org/pdf/2409.16098v2",
    "published_date": "2024-09-24 13:52:15 UTC",
    "updated_date": "2024-11-21 09:24:12 UTC"
  },
  {
    "arxiv_id": "2409.16089v2",
    "title": "From Pixels to Words: Leveraging Explainability in Face Recognition through Interactive Natural Language Processing",
    "authors": [
      "Ivan DeAndres-Tame",
      "Muhammad Faisal",
      "Ruben Tolosana",
      "Rouqaiah Al-Refai",
      "Ruben Vera-Rodriguez",
      "Philipp Terhörst"
    ],
    "abstract": "Face Recognition (FR) has advanced significantly with the development of deep\nlearning, achieving high accuracy in several applications. However, the lack of\ninterpretability of these systems raises concerns about their accountability,\nfairness, and reliability. In the present study, we propose an interactive\nframework to enhance the explainability of FR models by combining\nmodel-agnostic Explainable Artificial Intelligence (XAI) and Natural Language\nProcessing (NLP) techniques. The proposed framework is able to accurately\nanswer various questions of the user through an interactive chatbot. In\nparticular, the explanations generated by our proposed method are in the form\nof natural language text and visual representations, which for example can\ndescribe how different facial regions contribute to the similarity measure\nbetween two faces. This is achieved through the automatic analysis of the\noutput's saliency heatmaps of the face images and a BERT question-answering\nmodel, providing users with an interface that facilitates a comprehensive\nunderstanding of the FR decisions. The proposed approach is interactive,\nallowing the users to ask questions to get more precise information based on\nthe user's background knowledge. More importantly, in contrast to previous\nstudies, our solution does not decrease the face recognition performance. We\ndemonstrate the effectiveness of the method through different experiments,\nhighlighting its potential to make FR systems more interpretable and\nuser-friendly, especially in sensitive applications where decision-making\ntransparency is crucial.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.16089v2",
    "published_date": "2024-09-24 13:40:39 UTC",
    "updated_date": "2024-12-09 14:41:53 UTC"
  },
  {
    "arxiv_id": "2409.16086v1",
    "title": "Assessing Simplification Levels in Neural Networks: The Impact of Hyperparameter Configurations on Complexity and Sensitivity",
    "authors": [
      "Huixin Guan"
    ],
    "abstract": "This paper presents an experimental study focused on understanding the\nsimplification properties of neural networks under different hyperparameter\nconfigurations, specifically investigating the effects on Lempel Ziv complexity\nand sensitivity. By adjusting key hyperparameters such as activation functions,\nhidden layers, and learning rate, this study evaluates how these parameters\nimpact the complexity of network outputs and their robustness to input\nperturbations. The experiments conducted using the MNIST dataset aim to provide\ninsights into the relationships between hyperparameters, complexity, and\nsensitivity, contributing to a deeper theoretical understanding of these\nconcepts in neural networks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.16086v1",
    "published_date": "2024-09-24 13:39:04 UTC",
    "updated_date": "2024-09-24 13:39:04 UTC"
  },
  {
    "arxiv_id": "2409.16081v1",
    "title": "Online Multi-level Contrastive Representation Distillation for Cross-Subject fNIRS Emotion Recognition",
    "authors": [
      "Zhili Lai",
      "Chunmei Qing",
      "Junpeng Tan",
      "Wanxiang Luo",
      "Xiangmin Xu"
    ],
    "abstract": "Utilizing functional near-infrared spectroscopy (fNIRS) signals for emotion\nrecognition is a significant advancement in understanding human emotions.\nHowever, due to the lack of artificial intelligence data and algorithms in this\nfield, current research faces the following challenges: 1) The portable\nwearable devices have higher requirements for lightweight models; 2) The\nobjective differences of physiology and psychology among different subjects\naggravate the difficulty of emotion recognition. To address these challenges,\nwe propose a novel cross-subject fNIRS emotion recognition method, called the\nOnline Multi-level Contrastive Representation Distillation framework (OMCRD).\nSpecifically, OMCRD is a framework designed for mutual learning among multiple\nlightweight student networks. It utilizes multi-level fNIRS feature extractor\nfor each sub-network and conducts multi-view sentimental mining using\nphysiological signals. The proposed Inter-Subject Interaction Contrastive\nRepresentation (IS-ICR) facilitates knowledge transfer for interactions between\nstudent models, enhancing cross-subject emotion recognition performance. The\noptimal student network can be selected and deployed on a wearable device. Some\nexperimental results demonstrate that OMCRD achieves state-of-the-art results\nin emotional perception and affective imagery tasks.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "Accepted in ACMMM-2024 Workshop BCI. Codes are available at\n  https://github.com/Lzhili/fNIRS-OMCRD",
    "pdf_url": "http://arxiv.org/pdf/2409.16081v1",
    "published_date": "2024-09-24 13:30:15 UTC",
    "updated_date": "2024-09-24 13:30:15 UTC"
  },
  {
    "arxiv_id": "2409.16077v1",
    "title": "Leveraging Mixture of Experts for Improved Speech Deepfake Detection",
    "authors": [
      "Viola Negroni",
      "Davide Salvi",
      "Alessandro Ilic Mezza",
      "Paolo Bestagini",
      "Stefano Tubaro"
    ],
    "abstract": "Speech deepfakes pose a significant threat to personal security and content\nauthenticity. Several detectors have been proposed in the literature, and one\nof the primary challenges these systems have to face is the generalization over\nunseen data to identify fake signals across a wide range of datasets. In this\npaper, we introduce a novel approach for enhancing speech deepfake detection\nperformance using a Mixture of Experts architecture. The Mixture of Experts\nframework is well-suited for the speech deepfake detection task due to its\nability to specialize in different input types and handle data variability\nefficiently. This approach offers superior generalization and adaptability to\nunseen data compared to traditional single models or ensemble methods.\nAdditionally, its modular structure supports scalable updates, making it more\nflexible in managing the evolving complexity of deepfake techniques while\nmaintaining high detection accuracy. We propose an efficient, lightweight\ngating mechanism to dynamically assign expert weights for each input,\noptimizing detection performance. Experimental results across multiple datasets\ndemonstrate the effectiveness and potential of our proposed approach.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Submitted to ICASSP 2025",
    "pdf_url": "http://arxiv.org/pdf/2409.16077v1",
    "published_date": "2024-09-24 13:24:03 UTC",
    "updated_date": "2024-09-24 13:24:03 UTC"
  },
  {
    "arxiv_id": "2409.16057v2",
    "title": "Towards Robust Object Detection: Identifying and Removing Backdoors via Module Inconsistency Analysis",
    "authors": [
      "Xianda Zhang",
      "Siyuan Liang"
    ],
    "abstract": "Object detection models, widely used in security-critical applications, are\nvulnerable to backdoor attacks that cause targeted misclassifications when\ntriggered by specific patterns. Existing backdoor defense techniques, primarily\ndesigned for simpler models like image classifiers, often fail to effectively\ndetect and remove backdoors in object detectors. We propose a backdoor defense\nframework tailored to object detection models, based on the observation that\nbackdoor attacks cause significant inconsistencies between local modules'\nbehaviors, such as the Region Proposal Network (RPN) and classification head.\nBy quantifying and analyzing these inconsistencies, we develop an algorithm to\ndetect backdoors. We find that the inconsistent module is usually the main\nsource of backdoor behavior, leading to a removal method that localizes the\naffected module, resets its parameters, and fine-tunes the model on a small\nclean dataset. Extensive experiments with state-of-the-art two-stage object\ndetectors show our method achieves a 90% improvement in backdoor removal rate\nover fine-tuning baselines, while limiting clean data accuracy loss to less\nthan 4%. To the best of our knowledge, this work presents the first approach\nthat addresses both the detection and removal of backdoors in two-stage object\ndetection models, advancing the field of securing these complex systems against\nbackdoor attacks.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.16057v2",
    "published_date": "2024-09-24 12:58:35 UTC",
    "updated_date": "2024-09-30 08:27:24 UTC"
  },
  {
    "arxiv_id": "2409.16056v1",
    "title": "Adversarial Watermarking for Face Recognition",
    "authors": [
      "Yuguang Yao",
      "Anil Jain",
      "Sijia Liu"
    ],
    "abstract": "Watermarking is an essential technique for embedding an identifier (i.e.,\nwatermark message) within digital images to assert ownership and monitor\nunauthorized alterations. In face recognition systems, watermarking plays a\npivotal role in ensuring data integrity and security. However, an adversary\ncould potentially interfere with the watermarking process, significantly\nimpairing recognition performance. We explore the interaction between\nwatermarking and adversarial attacks on face recognition models. Our findings\nreveal that while watermarking or input-level perturbation alone may have a\nnegligible effect on recognition accuracy, the combined effect of watermarking\nand perturbation can result in an adversarial watermarking attack,\nsignificantly degrading recognition performance. Specifically, we introduce a\nnovel threat model, the adversarial watermarking attack, which remains stealthy\nin the absence of watermarking, allowing images to be correctly recognized\ninitially. However, once watermarking is applied, the attack is activated,\ncausing recognition failures. Our study reveals a previously unrecognized\nvulnerability: adversarial perturbations can exploit the watermark message to\nevade face recognition systems. Evaluated on the CASIA-WebFace dataset, our\nproposed adversarial watermarking attack reduces face matching accuracy by\n67.2% with an $\\ell_\\infty$ norm-measured perturbation strength of ${2}/{255}$\nand by 95.9% with a strength of ${4}/{255}$.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.16056v1",
    "published_date": "2024-09-24 12:58:32 UTC",
    "updated_date": "2024-09-24 12:58:32 UTC"
  },
  {
    "arxiv_id": "2409.16048v2",
    "title": "Whole-body End-Effector Pose Tracking",
    "authors": [
      "Tifanny Portela",
      "Andrei Cramariuc",
      "Mayank Mittal",
      "Marco Hutter"
    ],
    "abstract": "Combining manipulation with the mobility of legged robots is essential for a\nwide range of robotic applications. However, integrating an arm with a mobile\nbase significantly increases the system's complexity, making precise\nend-effector control challenging. Existing model-based approaches are often\nconstrained by their modeling assumptions, leading to limited robustness.\nMeanwhile, recent Reinforcement Learning (RL) implementations restrict the\narm's workspace to be in front of the robot or track only the position to\nobtain decent tracking accuracy. In this work, we address these limitations by\nintroducing a whole-body RL formulation for end-effector pose tracking in a\nlarge workspace on rough, unstructured terrains. Our proposed method involves a\nterrain-aware sampling strategy for the robot's initial configuration and\nend-effector pose commands, as well as a game-based curriculum to extend the\nrobot's operating range. We validate our approach on the ANYmal quadrupedal\nrobot with a six DoF robotic arm. Through our experiments, we show that the\nlearned controller achieves precise command tracking over a large workspace and\nadapts across varying terrains such as stairs and slopes. On deployment, it\nachieves a pose-tracking error of 2.64 cm and 3.64 degrees, outperforming\nexisting competitive baselines.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.16048v2",
    "published_date": "2024-09-24 12:51:32 UTC",
    "updated_date": "2025-04-25 09:59:56 UTC"
  },
  {
    "arxiv_id": "2409.16045v1",
    "title": "LTNtorch: PyTorch Implementation of Logic Tensor Networks",
    "authors": [
      "Tommaso Carraro",
      "Luciano Serafini",
      "Fabio Aiolli"
    ],
    "abstract": "Logic Tensor Networks (LTN) is a Neuro-Symbolic framework that effectively\nincorporates deep learning and logical reasoning. In particular, LTN allows\ndefining a logical knowledge base and using it as the objective of a neural\nmodel. This makes learning by logical reasoning possible as the parameters of\nthe model are optimized by minimizing a loss function composed of a set of\nlogical formulas expressing facts about the learning task. The framework learns\nvia gradient-descent optimization. Fuzzy logic, a relaxation of classical logic\npermitting continuous truth values in the interval [0,1], makes this learning\npossible. Specifically, the training of an LTN consists of three steps.\nFirstly, (1) the training data is used to ground the formulas. Then, (2) the\nformulas are evaluated, and the loss function is computed. Lastly, (3) the\ngradients are back-propagated through the logical computational graph, and the\nweights of the neural model are changed so the knowledge base is maximally\nsatisfied. LTNtorch is the fully documented and tested PyTorch implementation\nof Logic Tensor Networks. This paper presents the formalization of LTN and how\nLTNtorch implements it. Moreover, it provides a basic binary classification\nexample.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "5 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.16045v1",
    "published_date": "2024-09-24 12:50:22 UTC",
    "updated_date": "2024-09-24 12:50:22 UTC"
  },
  {
    "arxiv_id": "2409.16040v4",
    "title": "Time-MoE: Billion-Scale Time Series Foundation Models with Mixture of Experts",
    "authors": [
      "Xiaoming Shi",
      "Shiyu Wang",
      "Yuqi Nie",
      "Dianqi Li",
      "Zhou Ye",
      "Qingsong Wen",
      "Ming Jin"
    ],
    "abstract": "Deep learning for time series forecasting has seen significant advancements\nover the past decades. However, despite the success of large-scale pre-training\nin language and vision domains, pre-trained time series models remain limited\nin scale and operate at a high cost, hindering the development of larger\ncapable forecasting models in real-world applications. In response, we\nintroduce Time-MoE, a scalable and unified architecture designed to pre-train\nlarger, more capable forecasting foundation models while reducing inference\ncosts. By leveraging a sparse mixture-of-experts (MoE) design, Time-MoE\nenhances computational efficiency by activating only a subset of networks for\neach prediction, reducing computational load while maintaining high model\ncapacity. This allows Time-MoE to scale effectively without a corresponding\nincrease in inference costs. Time-MoE comprises a family of decoder-only\ntransformer models that operate in an auto-regressive manner and support\nflexible forecasting horizons with varying input context lengths. We\npre-trained these models on our newly introduced large-scale data Time-300B,\nwhich spans over 9 domains and encompassing over 300 billion time points. For\nthe first time, we scaled a time series foundation model up to 2.4 billion\nparameters, achieving significantly improved forecasting precision. Our results\nvalidate the applicability of scaling laws for training tokens and model size\nin the context of time series forecasting. Compared to dense models with the\nsame number of activated parameters or equivalent computation budgets, our\nmodels consistently outperform them by large margin. These advancements\nposition Time-MoE as a state-of-the-art solution for tackling real-world time\nseries forecasting challenges with superior capability, efficiency, and\nflexibility.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by the 13th International Conference on Learning\n  Representations (ICLR 2025)",
    "pdf_url": "http://arxiv.org/pdf/2409.16040v4",
    "published_date": "2024-09-24 12:42:18 UTC",
    "updated_date": "2025-02-27 05:38:14 UTC"
  },
  {
    "arxiv_id": "2409.16036v1",
    "title": "Grounded Computation & Consciousness: A Framework for Exploring Consciousness in Machines & Other Organisms",
    "authors": [
      "Ryan Williams"
    ],
    "abstract": "Computational modeling is a critical tool for understanding consciousness,\nbut is it enough on its own? This paper discusses the necessity for an\nontological basis of consciousness, and introduces a formal framework for\ngrounding computational descriptions into an ontological substrate. Utilizing\nthis technique, a method is demonstrated for estimating the difference in\nqualitative experience between two systems. This framework has wide\napplicability to computational theories of consciousness.",
    "categories": [
      "q-bio.NC",
      "cs.AI"
    ],
    "primary_category": "q-bio.NC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.16036v1",
    "published_date": "2024-09-24 12:34:05 UTC",
    "updated_date": "2024-09-24 12:34:05 UTC"
  },
  {
    "arxiv_id": "2409.16032v1",
    "title": "Deep chroma compression of tone-mapped images",
    "authors": [
      "Xenios Milidonis",
      "Francesco Banterle",
      "Alessandro Artusi"
    ],
    "abstract": "Acquisition of high dynamic range (HDR) images is thriving due to the\nincreasing use of smart devices and the demand for high-quality output.\nExtensive research has focused on developing methods for reducing the luminance\nrange in HDR images using conventional and deep learning-based tone mapping\noperators to enable accurate reproduction on conventional 8 and 10-bit digital\ndisplays. However, these methods often fail to account for pixels that may lie\noutside the target display's gamut, resulting in visible chromatic distortions\nor color clipping artifacts. Previous studies suggested that a gamut management\nstep ensures that all pixels remain within the target gamut. However, such\napproaches are computationally expensive and cannot be deployed on devices with\nlimited computational resources. We propose a generative adversarial network\nfor fast and reliable chroma compression of HDR tone-mapped images. We design a\nloss function that considers the hue property of generated images to improve\ncolor accuracy, and train the model on an extensive image dataset. Quantitative\nexperiments demonstrate that the proposed model outperforms state-of-the-art\nimage generation and enhancement networks in color accuracy, while a subjective\nstudy suggests that the generated images are on par or superior to those\nproduced by conventional chroma compression methods in terms of visual quality.\nAdditionally, the model achieves real-time performance, showing promising\nresults for deployment on devices with limited computational resources.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.16032v1",
    "published_date": "2024-09-24 12:31:55 UTC",
    "updated_date": "2024-09-24 12:31:55 UTC"
  },
  {
    "arxiv_id": "2409.16024v2",
    "title": "From Goal-Conditioned to Language-Conditioned Agents via Vision-Language Models",
    "authors": [
      "Theo Cachet",
      "Christopher R. Dance",
      "Olivier Sigaud"
    ],
    "abstract": "Vision-language models (VLMs) have tremendous potential for grounding\nlanguage, and thus enabling language-conditioned agents (LCAs) to perform\ndiverse tasks specified with text. This has motivated the study of LCAs based\non reinforcement learning (RL) with rewards given by rendering images of an\nenvironment and evaluating those images with VLMs. If single-task RL is\nemployed, such approaches are limited by the cost and time required to train a\npolicy for each new task. Multi-task RL (MTRL) is a natural alternative, but\nrequires a carefully designed corpus of training tasks and does not always\ngeneralize reliably to new tasks. Therefore, this paper introduces a novel\ndecomposition of the problem of building an LCA: first find an environment\nconfiguration that has a high VLM score for text describing a task; then use a\n(pretrained) goal-conditioned policy to reach that configuration. We also\nexplore several enhancements to the speed and quality of VLM-based LCAs,\nnotably, the use of distilled models, and the evaluation of configurations from\nmultiple viewpoints to resolve the ambiguities inherent in a single 2D view. We\ndemonstrate our approach on the Humanoid environment, showing that it results\nin LCAs that outperform MTRL baselines in zero-shot generalization, without\nrequiring any textual task descriptions or other forms of environment-specific\nannotation during training.\n  Videos and an interactive demo can be found at\nhttps://europe.naverlabs.com/text2control",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.16024v2",
    "published_date": "2024-09-24 12:24:07 UTC",
    "updated_date": "2024-11-26 11:15:53 UTC"
  },
  {
    "arxiv_id": "2409.16022v2",
    "title": "AI Can Be Cognitively Biased: An Exploratory Study on Threshold Priming in LLM-Based Batch Relevance Assessment",
    "authors": [
      "Nuo Chen",
      "Jiqun Liu",
      "Xiaoyu Dong",
      "Qijiong Liu",
      "Tetsuya Sakai",
      "Xiao-Ming Wu"
    ],
    "abstract": "Cognitive biases are systematic deviations in thinking that lead to\nirrational judgments and problematic decision-making, extensively studied\nacross various fields. Recently, large language models (LLMs) have shown\nadvanced understanding capabilities but may inherit human biases from their\ntraining data. While social biases in LLMs have been well-studied, cognitive\nbiases have received less attention, with existing research focusing on\nspecific scenarios. The broader impact of cognitive biases on LLMs in various\ndecision-making contexts remains underexplored. We investigated whether LLMs\nare influenced by the threshold priming effect in relevance judgments, a core\ntask and widely-discussed research topic in the Information Retrieval (IR)\ncoummunity. The priming effect occurs when exposure to certain stimuli\nunconsciously affects subsequent behavior and decisions. Our experiment\nemployed 10 topics from the TREC 2019 Deep Learning passage track collection,\nand tested AI judgments under different document relevance scores, batch\nlengths, and LLM models, including GPT-3.5, GPT-4, LLaMa2-13B and LLaMa2-70B.\nResults showed that LLMs tend to give lower scores to later documents if\nearlier ones have high relevance, and vice versa, regardless of the combination\nand model used. Our finding demonstrates that LLM%u2019s judgments, similar to\nhuman judgments, are also influenced by threshold priming biases, and suggests\nthat researchers and system engineers should take into account potential\nhuman-like cognitive biases in designing, evaluating, and auditing LLMs in IR\ntasks and beyond.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.16022v2",
    "published_date": "2024-09-24 12:23:15 UTC",
    "updated_date": "2024-10-08 10:23:00 UTC"
  },
  {
    "arxiv_id": "2409.16001v2",
    "title": "Artificial Human Intelligence: The role of Humans in the Development of Next Generation AI",
    "authors": [
      "Suayb S. Arslan"
    ],
    "abstract": "Human intelligence, the most evident and accessible form of source of\nreasoning, hosted by biological hardware, has evolved and been refined over\nthousands of years, positioning itself today to create new artificial forms and\npreparing to self--design their evolutionary path forward. Beginning with the\nadvent of foundation models, the rate at which human and artificial\nintelligence interact with each other has exceeded any anticipated quantitative\nfigures. The close engagement led both bits of intelligence to be impacted in\nvarious ways, which naturally resulted in complex confluences that warrant\nclose scrutiny. In the sequel, using a novel taxonomy, we shall explore the\ninterplay between human and machine intelligence, focusing on the crucial role\nhumans play in developing ethical, responsible, and robust intelligent systems.\nWe briefly delve into various aspects of implementation inspired by the\nmechanisms underlying neuroscience and human cognition. In addition, we propose\nfuture perspectives, capitalizing on the advantages of symbiotic designs to\nsuggest a human-centered direction for next-generation developments, focusing\non the augmentation role of AI. We finalize this evolving document with some\nthoughts and open questions yet to be addressed by the broader community.",
    "categories": [
      "cs.AI",
      "q-bio.NC"
    ],
    "primary_category": "cs.AI",
    "comment": "26 pages, 8 figures, submitted to IEEE Trans. on NNLS",
    "pdf_url": "http://arxiv.org/pdf/2409.16001v2",
    "published_date": "2024-09-24 12:02:20 UTC",
    "updated_date": "2025-02-02 15:33:49 UTC"
  },
  {
    "arxiv_id": "2409.15997v2",
    "title": "Improvements to SDXL in NovelAI Diffusion V3",
    "authors": [
      "Juan Ossa",
      "Eren Doğan",
      "Alex Birch",
      "F. Johnson"
    ],
    "abstract": "In this technical report, we document the changes we made to SDXL in the\nprocess of training NovelAI Diffusion V3, our state of the art anime image\ngeneration model.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "14 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.15997v2",
    "published_date": "2024-09-24 11:57:12 UTC",
    "updated_date": "2024-09-26 21:56:01 UTC"
  },
  {
    "arxiv_id": "2409.15985v1",
    "title": "DataGpt-SQL-7B: An Open-Source Language Model for Text-to-SQL",
    "authors": [
      "Lixia Wu",
      "Peng Li",
      "Junhong Lou",
      "Lei Fu"
    ],
    "abstract": "In addressing the pivotal role of translating natural language queries into\nSQL commands, we propose a suite of compact, fine-tuned models and self-refine\nmechanisms to democratize data access and analysis for non-expert users,\nmitigating risks associated with closed-source Large Language Models.\nSpecifically, we constructed a dataset of over 20K sample for Text-to-SQL as\nwell as the preference dateset, to improve the efficiency in the domain of SQL\ngeneration. To further ensure code validity, a code corrector was integrated\ninto the model. Our system, DataGpt-sql, achieved 87.2\\% accuracy on the\nspider-dev, respectively, showcasing the effectiveness of our solution in\ntext-to-SQL conversion tasks. Our code, data, and models are available at\n\\url{https://github.com/CainiaoTechAi/datagpt-sql-7b}",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.15985v1",
    "published_date": "2024-09-24 11:38:08 UTC",
    "updated_date": "2024-09-24 11:38:08 UTC"
  },
  {
    "arxiv_id": "2409.15980v1",
    "title": "Leveraging Unsupervised Learning for Cost-Effective Visual Anomaly Detection",
    "authors": [
      "Yunbo Long",
      "Zhengyang Ling",
      "Sam Brook",
      "Duncan McFarlane",
      "Alexandra Brintrup"
    ],
    "abstract": "Traditional machine learning-based visual inspection systems require\nextensive data collection and repetitive model training to improve accuracy.\nThese systems typically require expensive camera, computing equipment and\nsignificant machine learning expertise, which can substantially burden small\nand medium-sized enterprises. This study explores leveraging unsupervised\nlearning methods with pre-trained models and low-cost hardware to create a\ncost-effective visual anomaly detection system. The research aims to develop a\nlow-cost visual anomaly detection solution that uses minimal data for model\ntraining while maintaining generalizability and scalability. The system\nutilises unsupervised learning models from Anomalib and is deployed on\naffordable Raspberry Pi hardware through openVINO. The results show that this\ncost-effective system can complete anomaly defection training and inference on\na Raspberry Pi in just 90 seconds using only 10 normal product images,\nachieving an F1 macro score exceeding 0.95. While the system is slightly\nsensitive to environmental changes like lighting, product positioning, or\nbackground, it remains a swift and economical method for factory automation\ninspection for small and medium-sized manufacturers",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.15980v1",
    "published_date": "2024-09-24 11:22:24 UTC",
    "updated_date": "2024-09-24 11:22:24 UTC"
  },
  {
    "arxiv_id": "2409.15974v1",
    "title": "Disentangling Age and Identity with a Mutual Information Minimization Approach for Cross-Age Speaker Verification",
    "authors": [
      "Fengrun Zhang",
      "Wangjin Zhou",
      "Yiming Liu",
      "Wang Geng",
      "Yahui Shan",
      "Chen Zhang"
    ],
    "abstract": "There has been an increasing research interest in cross-age speaker\nverification~(CASV). However, existing speaker verification systems perform\npoorly in CASV due to the great individual differences in voice caused by\naging. In this paper, we propose a disentangled representation learning\nframework for CASV based on mutual information~(MI) minimization. In our\nmethod, a backbone model is trained to disentangle the identity- and\nage-related embeddings from speaker information, and an MI estimator is trained\nto minimize the correlation between age- and identity-related embeddings via MI\nminimization, resulting in age-invariant speaker embeddings. Furthermore, by\nusing the age gaps between positive and negative samples, we propose an\naging-aware MI minimization loss function that allows the backbone model to\nfocus more on the vocal changes with large age gaps. Experimental results show\nthat the proposed method outperforms other methods on multiple Cross-Age test\nsets of Vox-CA.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Interspeech 2024",
    "pdf_url": "http://arxiv.org/pdf/2409.15974v1",
    "published_date": "2024-09-24 11:08:23 UTC",
    "updated_date": "2024-09-24 11:08:23 UTC"
  },
  {
    "arxiv_id": "2409.15973v1",
    "title": "Edge-device Collaborative Computing for Multi-view Classification",
    "authors": [
      "Marco Palena",
      "Tania Cerquitelli",
      "Carla Fabiana Chiasserini"
    ],
    "abstract": "Motivated by the proliferation of Internet-of-Thing (IoT) devices and the\nrapid advances in the field of deep learning, there is a growing interest in\npushing deep learning computations, conventionally handled by the cloud, to the\nedge of the network to deliver faster responses to end users, reduce bandwidth\nconsumption to the cloud, and address privacy concerns. However, to fully\nrealize deep learning at the edge, two main challenges still need to be\naddressed: (i) how to meet the high resource requirements of deep learning on\nresource-constrained devices, and (ii) how to leverage the availability of\nmultiple streams of spatially correlated data, to increase the effectiveness of\ndeep learning and improve application-level performance. To address the above\nchallenges, we explore collaborative inference at the edge, in which edge nodes\nand end devices share correlated data and the inference computational burden by\nleveraging different ways to split computation and fuse data. Besides\ntraditional centralized and distributed schemes for edge-end device\ncollaborative inference, we introduce selective schemes that decrease bandwidth\nresource consumption by effectively reducing data redundancy. As a reference\nscenario, we focus on multi-view classification in a networked system in which\nsensing nodes can capture overlapping fields of view. The proposed schemes are\ncompared in terms of accuracy, computational expenditure at the nodes,\ncommunication overhead, inference latency, robustness, and noise sensitivity.\nExperimental results highlight that selective collaborative schemes can achieve\ndifferent trade-offs between the above performance metrics, with some of them\nbringing substantial communication savings (from 18% to 74% of the transmitted\ndata with respect to centralized inference) while still keeping the inference\naccuracy well above 90%.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC",
      "cs.NI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.15973v1",
    "published_date": "2024-09-24 11:07:33 UTC",
    "updated_date": "2024-09-24 11:07:33 UTC"
  },
  {
    "arxiv_id": "2409.15971v1",
    "title": "Creating Healthy Friction: Determining Stakeholder Requirements of Job Recommendation Explanations",
    "authors": [
      "Roan Schellingerhout",
      "Francesco Barile",
      "Nava Tintarev"
    ],
    "abstract": "The increased use of information retrieval in recruitment, primarily through\njob recommender systems (JRSs), can have a large impact on job seekers,\nrecruiters, and companies. As a result, such systems have been determined to be\nhigh-risk in recent legislature. This requires JRSs to be trustworthy and\ntransparent, allowing stakeholders to understand why specific recommendations\nwere made. To fulfill this requirement, the stakeholders' exact preferences and\nneeds need to be determined. To do so, we evaluated an explainable job\nrecommender system using a realistic, task-based, mixed-design user study\n(n=30) in which stakeholders had to make decisions based on the model's\nexplanations. This mixed-methods evaluation consisted of two objective metrics\n- correctness and efficiency, along with three subjective metrics - trust,\ntransparency, and usefulness. These metrics were evaluated twice per\nparticipant, once using real explanations and once using random explanations.\nThe study included a qualitative analysis following a think-aloud protocol\nwhile performing tasks adapted to each stakeholder group. We find that\nproviding stakeholders with real explanations does not significantly improve\ndecision-making speed and accuracy. Our results showed a non-significant trend\nfor the real explanations to outperform the random ones on perceived trust,\nusefulness, and transparency of the system for all stakeholder types. We\ndetermine that stakeholders benefit more from interacting with explanations as\ndecision support capable of providing healthy friction, rather than as\npreviously-assumed persuasive tools.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "14 pages, 3 figures, to be published in ACM RecSys in HR '24: 4th\n  Workshop on Recommender Systems for Human Resources",
    "pdf_url": "http://arxiv.org/pdf/2409.15971v1",
    "published_date": "2024-09-24 11:03:17 UTC",
    "updated_date": "2024-09-24 11:03:17 UTC"
  },
  {
    "arxiv_id": "2409.15963v4",
    "title": "Provably Efficient Exploration in Inverse Constrained Reinforcement Learning",
    "authors": [
      "Bo Yue",
      "Jian Li",
      "Guiliang Liu"
    ],
    "abstract": "Optimizing objective functions subject to constraints is fundamental in many\nreal-world applications. However, these constraints are often not readily\ndefined and must be inferred from expert agent behaviors, a problem known as\nInverse Constraint Inference. Inverse Constrained Reinforcement Learning (ICRL)\nis a common solver for recovering feasible constraints in complex environments,\nrelying on training samples collected from interactive environments. However,\nthe efficacy and efficiency of current sampling strategies remain unclear. We\npropose a strategic exploration framework for sampling with guaranteed\nefficiency to bridge this gap. By defining the feasible cost set for ICRL\nproblems, we analyze how estimation errors in transition dynamics and the\nexpert policy influence the feasibility of inferred constraints. Based on this\nanalysis, we introduce two exploratory algorithms to achieve efficient\nconstraint inference via 1) dynamically reducing the bounded aggregate error of\ncost estimations or 2) strategically constraining the exploration policy around\nplausibly optimal ones. Both algorithms are theoretically grounded with\ntractable sample complexity, and their performance is validated empirically\nacross various environments.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.15963v4",
    "published_date": "2024-09-24 10:48:13 UTC",
    "updated_date": "2025-05-16 09:40:19 UTC"
  },
  {
    "arxiv_id": "2409.15957v1",
    "title": "ASD-Diffusion: Anomalous Sound Detection with Diffusion Models",
    "authors": [
      "Fengrun Zhang",
      "Xiang Xie",
      "Kai Guo"
    ],
    "abstract": "Unsupervised Anomalous Sound Detection (ASD) aims to design a generalizable\nmethod that can be used to detect anomalies when only normal sounds are given.\nIn this paper, Anomalous Sound Detection based on Diffusion Models\n(ASD-Diffusion) is proposed for ASD in real-world factories. In our pipeline,\nthe anomalies in acoustic features are reconstructed from their noisy corrupted\nfeatures into their approximate normal pattern. Secondly, a post-processing\nanomalies filter algorithm is proposed to detect anomalies that exhibit\nsignificant deviation from the original input after reconstruction.\nFurthermore, denoising diffusion implicit model is introduced to accelerate the\ninference speed by a longer sampling interval of the denoising process. The\nproposed method is innovative in the application of diffusion models as a new\nscheme. Experimental results on the development set of DCASE 2023 challenge\ntask 2 outperform the baseline by 7.75%, demonstrating the effectiveness of the\nproposed method.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "This paper will appear at ICPR 2024",
    "pdf_url": "http://arxiv.org/pdf/2409.15957v1",
    "published_date": "2024-09-24 10:42:23 UTC",
    "updated_date": "2024-09-24 10:42:23 UTC"
  },
  {
    "arxiv_id": "2409.15955v5",
    "title": "A Historical Trajectory Assisted Optimization Method for Zeroth-Order Federated Learning",
    "authors": [
      "Chenlin Wu",
      "Xiaoyu He",
      "Zike Li",
      "Jing Gong",
      "Zibin Zheng"
    ],
    "abstract": "Federated learning heavily relies on distributed gradient descent techniques.\nIn the situation where gradient information is not available, the gradients\nneed to be estimated from zeroth-order information, which typically involves\ncomputing finite-differences along isotropic random directions. This method\nsuffers from high estimation errors, as the geometric features of the objective\nlandscape may be overlooked during the isotropic sampling. In this work, we\npropose a non-isotropic sampling method to improve the gradient estimation\nprocedure. Gradients in our method are estimated in a subspace spanned by\nhistorical trajectories of solutions, aiming to encourage the exploration of\npromising regions and hence improve the convergence. The proposed method uses a\ncovariance matrix for sampling which is a convex combination of two parts. The\nfirst part is a thin projection matrix containing the basis of the subspace\nwhich is designed to improve the exploitation ability. The second part is the\nhistorical trajectories. We implement this method in zeroth-order federated\nsettings, and show that the convergence rate aligns with existing ones while\nintroducing no significant overheads in communication or local computation. The\neffectiveness of our proposal is verified on several numerical experiments in\ncomparison to several commonly-used zeroth-order federated optimization\nalgorithms.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.15955v5",
    "published_date": "2024-09-24 10:36:40 UTC",
    "updated_date": "2024-10-24 09:39:27 UTC"
  },
  {
    "arxiv_id": "2409.15950v1",
    "title": "TSFeatLIME: An Online User Study in Enhancing Explainability in Univariate Time Series Forecasting",
    "authors": [
      "Hongnan Ma",
      "Kevin McAreavey",
      "Weiru Liu"
    ],
    "abstract": "Time series forecasting, while vital in various applications, often employs\ncomplex models that are difficult for humans to understand. Effective\nexplainable AI techniques are crucial to bridging the gap between model\npredictions and user understanding. This paper presents a framework -\nTSFeatLIME, extending TSLIME, tailored specifically for explaining univariate\ntime series forecasting. TSFeatLIME integrates an auxiliary feature into the\nsurrogate model and considers the pairwise Euclidean distances between the\nqueried time series and the generated samples to improve the fidelity of the\nsurrogate models. However, the usefulness of such explanations for human beings\nremains an open question. We address this by conducting a user study with 160\nparticipants through two interactive interfaces, aiming to measure how\nindividuals from different backgrounds can simulate or predict model output\nchanges in the treatment group and control group. Our results show that the\nsurrogate model under the TSFeatLIME framework is able to better simulate the\nbehaviour of the black-box considering distance, without sacrificing accuracy.\nIn addition, the user study suggests that the explanations were significantly\nmore effective for participants without a computer science background.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.15950v1",
    "published_date": "2024-09-24 10:24:53 UTC",
    "updated_date": "2024-09-24 10:24:53 UTC"
  },
  {
    "arxiv_id": "2409.15934v2",
    "title": "Automated test generation to evaluate tool-augmented LLMs as conversational AI agents",
    "authors": [
      "Samuel Arcadinho",
      "David Aparicio",
      "Mariana Almeida"
    ],
    "abstract": "Tool-augmented LLMs are a promising approach to create AI agents that can\nhave realistic conversations, follow procedures, and call appropriate\nfunctions. However, evaluating them is challenging due to the diversity of\npossible conversations, and existing datasets focus only on single interactions\nand function-calling. We present a test generation pipeline to evaluate LLMs as\nconversational AI agents. Our framework uses LLMs to generate diverse tests\ngrounded on user-defined procedures. For that, we use intermediate graphs to\nlimit the LLM test generator's tendency to hallucinate content that is not\ngrounded on input procedures, and enforces high coverage of the possible\nconversations. Additionally, we put forward ALMITA, a manually curated dataset\nfor evaluating AI agents in customer support, and use it to evaluate existing\nLLMs. Our results show that while tool-augmented LLMs perform well in single\ninteractions, they often struggle to handle complete conversations. While our\nfocus is on customer support, our method is general and capable of AI agents\nfor different domains.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "14 pages, 5 figures, Submitted to GenBench@EMNLP2024",
    "pdf_url": "http://arxiv.org/pdf/2409.15934v2",
    "published_date": "2024-09-24 09:57:43 UTC",
    "updated_date": "2024-10-10 11:37:51 UTC"
  },
  {
    "arxiv_id": "2409.15924v2",
    "title": "Multilingual Transfer and Domain Adaptation for Low-Resource Languages of Spain",
    "authors": [
      "Yuanchang Luo",
      "Zhanglin Wu",
      "Daimeng Wei",
      "Hengchao Shang",
      "Zongyao Li",
      "Jiaxin Guo",
      "Zhiqiang Rao",
      "Shaojun Li",
      "Jinlong Yang",
      "Yuhao Xie",
      "Jiawei Zheng Bin Wei",
      "Hao Yang"
    ],
    "abstract": "This article introduces the submission status of the Translation into\nLow-Resource Languages of Spain task at (WMT 2024) by Huawei Translation\nService Center (HW-TSC). We participated in three translation tasks: spanish to\naragonese (es-arg), spanish to aranese (es-arn), and spanish to asturian\n(es-ast). For these three translation tasks, we use training strategies such as\nmultilingual transfer, regularized dropout, forward translation and back\ntranslation, labse denoising, transduction ensemble learning and other\nstrategies to neural machine translation (NMT) model based on training deep\ntransformer-big architecture. By using these enhancement strategies, our\nsubmission achieved a competitive result in the final evaluation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "6 pages,wmt24. arXiv admin note: substantial text overlap with\n  arXiv:2409.14842; text overlap with arXiv:2409.14800",
    "pdf_url": "http://arxiv.org/pdf/2409.15924v2",
    "published_date": "2024-09-24 09:46:27 UTC",
    "updated_date": "2024-09-29 09:15:42 UTC"
  },
  {
    "arxiv_id": "2409.15915v1",
    "title": "Planning in the Dark: LLM-Symbolic Planning Pipeline without Experts",
    "authors": [
      "Sukai Huang",
      "Nir Lipovetzky",
      "Trevor Cohn"
    ],
    "abstract": "Large Language Models (LLMs) have shown promise in solving natural\nlanguage-described planning tasks, but their direct use often leads to\ninconsistent reasoning and hallucination. While hybrid LLM-symbolic planning\npipelines have emerged as a more robust alternative, they typically require\nextensive expert intervention to refine and validate generated action schemas.\nIt not only limits scalability but also introduces a potential for biased\ninterpretation, as a single expert's interpretation of ambiguous natural\nlanguage descriptions might not align with the user's actual intent. To address\nthis, we propose a novel approach that constructs an action schema library to\ngenerate multiple candidates, accounting for the diverse possible\ninterpretations of natural language descriptions. We further introduce a\nsemantic validation and ranking module that automatically filter and rank the\ngenerated schemas and plans without expert-in-the-loop. The experiments showed\nour pipeline maintains superiority in planning over the direct LLM planning\napproach. These findings demonstrate the feasibility of a fully automated\nend-to-end LLM-symbolic planner that requires no expert intervention, opening\nup the possibility for a broader audience to engage with AI planning with less\nprerequisite of domain expertise.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "8 main body pages, 10 appendix pages",
    "pdf_url": "http://arxiv.org/pdf/2409.15915v1",
    "published_date": "2024-09-24 09:33:12 UTC",
    "updated_date": "2024-09-24 09:33:12 UTC"
  },
  {
    "arxiv_id": "2409.15910v2",
    "title": "Enhancing IoT based Plant Health Monitoring through Advanced Human Plant Interaction using Large Language Models and Mobile Applications",
    "authors": [
      "Kriti Agarwal",
      "Samhruth Ananthanarayanan",
      "Srinitish Srinivasan",
      "Abirami S"
    ],
    "abstract": "This paper presents the development of a novel plant communication\napplication that allows plants to \"talk\" to humans using real-time sensor data\nand AI-powered language models. Utilizing soil sensors that track moisture,\ntemperature, and nutrient levels, the system feeds this data into the Gemini\nAPI, where it is processed and transformed into natural language insights about\nthe plant's health and \"mood.\" Developed using Flutter, Firebase, and\nThingSpeak, the app offers a seamless user experience with real-time\ninteraction capabilities. By fostering human-plant connectivity, this system\nenhances plant care practices, promotes sustainability, and introduces\ninnovative applications for AI and IoT technologies in both personal and\nagricultural contexts. The paper explores the technical architecture, system\nintegration, and broader implications of AI-driven plant communication.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Presented as poster at ICDTSA 2024. Link to poster:\n  https://drive.google.com/file/d/138POUASonUQxmJaPqRhwHBeTDhL7lWY3/view?usp=sharing",
    "pdf_url": "http://arxiv.org/pdf/2409.15910v2",
    "published_date": "2024-09-24 09:26:47 UTC",
    "updated_date": "2025-01-05 18:21:23 UTC"
  },
  {
    "arxiv_id": "2409.15907v2",
    "title": "Enhancing Text-to-SQL Capabilities of Large Language Models via Domain Database Knowledge Injection",
    "authors": [
      "Xingyu Ma",
      "Xin Tian",
      "Lingxiang Wu",
      "Xuepeng Wang",
      "Xueming Tang",
      "Jinqiao Wang"
    ],
    "abstract": "Text-to-SQL is a subtask in semantic parsing that has seen rapid progress\nwith the evolution of Large Language Models (LLMs). However, LLMs face\nchallenges due to hallucination issues and a lack of domain-specific database\nknowledge(such as table schema and cell values). As a result, they can make\nerrors in generating table names, columns, and matching values to the correct\ncolumns in SQL statements. This paper introduces a method of knowledge\ninjection to enhance LLMs' ability to understand schema contents by\nincorporating prior knowledge. This approach improves their performance in\nText-to-SQL tasks. Experimental results show that pre-training LLMs on\ndomain-specific database knowledge and fine-tuning them on downstream\nText-to-SQL tasks significantly improves the Execution Match (EX) and Exact\nMatch (EM) metrics across various models. This effectively reduces errors in\ngenerating column names and matching values to the columns. Furthermore, the\nknowledge-injected models can be applied to many downstream Text-to-SQL tasks,\ndemonstrating the generalizability of the approach presented in this paper.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "This paper has been accepted by ECAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2409.15907v2",
    "published_date": "2024-09-24 09:24:03 UTC",
    "updated_date": "2025-02-25 09:36:41 UTC"
  },
  {
    "arxiv_id": "2409.15905v2",
    "title": "Boosting Code-Switching ASR with Mixture of Experts Enhanced Speech-Conditioned LLM",
    "authors": [
      "Fengrun Zhang",
      "Wang Geng",
      "Hukai Huang",
      "Yahui Shan",
      "Cheng Yi",
      "He Qu"
    ],
    "abstract": "In this paper, we introduce a speech-conditioned Large Language Model (LLM)\nintegrated with a Mixture of Experts (MoE) based connector to address the\nchallenge of Code-Switching (CS) in Automatic Speech Recognition (ASR).\nSpecifically, we propose an Insertion and Deletion of Interruption Token (IDIT)\nmechanism for better transfer text generation ability of LLM to speech\nrecognition task. We also present a connecter with MoE architecture that\nmanages multiple languages efficiently. To further enhance the collaboration of\nmultiple experts and leverage the understanding capabilities of LLM, we propose\na two-stage progressive training strategy: 1) The connector is unfrozen and\ntrained with language-specialized experts to map speech representations to the\ntext space. 2) The connector and LLM LoRA adaptor are trained with the proposed\nIDIT mechanism and all experts are activated to learn general representations.\nExperimental results demonstrate that our method significantly outperforms\nstate-of-the-art models, including end-to-end and large-scale audio-language\nmodels.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Submitted to ICASSP 2025",
    "pdf_url": "http://arxiv.org/pdf/2409.15905v2",
    "published_date": "2024-09-24 09:20:22 UTC",
    "updated_date": "2024-10-31 02:26:11 UTC"
  },
  {
    "arxiv_id": "2409.15903v1",
    "title": "Five questions and answers about artificial intelligence",
    "authors": [
      "Alberto Prieto",
      "Beatriz Prieto"
    ],
    "abstract": "Rapid advances in Artificial Intelligence (AI) are generating much\ncontroversy in society, often without scientific basis. As occurred the\ndevelopment of other emerging technologies, such as the introduction of\nelectricity in the early 20th century, AI causes both fascination and fear.\nFollowing the advice of the philosopher R.W. Emerson's: advice the knowledge is\nthe antidote to fear; this paper seeks to contribute to the dissemination of\nknowledge about AI. To this end, it reflects on the following questions: the\norigins of AI, its possible future evolution, its ability to show feelings, the\nassociated threats and dangers, and the concept of AI singularity.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "17 pages, 0 figures, Scientific and technological popularization\n  article",
    "pdf_url": "http://arxiv.org/pdf/2409.15903v1",
    "published_date": "2024-09-24 09:19:55 UTC",
    "updated_date": "2024-09-24 09:19:55 UTC"
  },
  {
    "arxiv_id": "2410.02816v1",
    "title": "Bipolar fuzzy relation equations systems based on the product t-norm",
    "authors": [
      "M. Eugenia Cornejo",
      "David Lobo",
      "Jesús Medina"
    ],
    "abstract": "Bipolar fuzzy relation equations arise as a generalization of fuzzy relation\nequations considering unknown variables together with their logical connective\nnegations. The occurrence of a variable and the occurrence of its negation\nsimultaneously can give very useful information for certain frameworks where\nthe human reasoning plays a key role. Hence, the resolution of bipolar fuzzy\nrelation equations systems is a research topic of great interest.\n  This paper focuses on the study of bipolar fuzzy relation equations systems\nbased on the max-product t-norm composition. Specifically, the solvability and\nthe algebraic structure of the set of solutions of these bipolar equations\nsystems will be studied, including the case in which such systems are composed\nof equations whose independent term be equal to zero. As a consequence, this\npaper complements the contribution carried out by the authors on the\nsolvability of bipolar max-product fuzzy relation equations.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.02816v1",
    "published_date": "2024-09-24 09:09:13 UTC",
    "updated_date": "2024-09-24 09:09:13 UTC"
  },
  {
    "arxiv_id": "2409.15892v1",
    "title": "Symmetries and Expressive Requirements for Learning General Policies",
    "authors": [
      "Dominik Drexler",
      "Simon Ståhlberg",
      "Blai Bonet",
      "Hector Geffner"
    ],
    "abstract": "State symmetries play an important role in planning and generalized planning.\nIn the first case, state symmetries can be used to reduce the size of the\nsearch; in the second, to reduce the size of the training set. In the case of\ngeneral planning, however, it is also critical to distinguish non-symmetric\nstates, i.e., states that represent non-isomorphic relational structures.\nHowever, while the language of first-order logic distinguishes non-symmetric\nstates, the languages and architectures used to represent and learn general\npolicies do not. In particular, recent approaches for learning general policies\nuse state features derived from description logics or learned via graph neural\nnetworks (GNNs) that are known to be limited by the expressive power of C_2,\nfirst-order logic with two variables and counting. In this work, we address the\nproblem of detecting symmetries in planning and generalized planning and use\nthe results to assess the expressive requirements for learning general policies\nover various planning domains. For this, we map planning states to plain\ngraphs, run off-the-shelf algorithms to determine whether two states are\nisomorphic with respect to the goal, and run coloring algorithms to determine\nif C_2 features computed logically or via GNNs distinguish non-isomorphic\nstates. Symmetry detection results in more effective learning, while the\nfailure to detect non-symmetries prevents general policies from being learned\nat all in certain domains.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted at the 21st International Conference on Principles of\n  Knowledge Representation and Reasoning (KR2024) in the Reasoning, Learning,\n  and Decision Making track",
    "pdf_url": "http://arxiv.org/pdf/2409.15892v1",
    "published_date": "2024-09-24 09:04:47 UTC",
    "updated_date": "2024-09-24 09:04:47 UTC"
  },
  {
    "arxiv_id": "2409.15879v1",
    "title": "Machine Translation Advancements of Low-Resource Indian Languages by Transfer Learning",
    "authors": [
      "Bin Wei",
      "Jiawei Zhen",
      "Zongyao Li",
      "Zhanglin Wu",
      "Daimeng Wei",
      "Jiaxin Guo",
      "Zhiqiang Rao",
      "Shaojun Li",
      "Yuanchang Luo",
      "Hengchao Shang",
      "Jinlong Yang",
      "Yuhao Xie",
      "Hao Yang"
    ],
    "abstract": "This paper introduces the submission by Huawei Translation Center (HW-TSC) to\nthe WMT24 Indian Languages Machine Translation (MT) Shared Task. To develop a\nreliable machine translation system for low-resource Indian languages, we\nemployed two distinct knowledge transfer strategies, taking into account the\ncharacteristics of the language scripts and the support available from existing\nopen-source models for Indian languages. For Assamese(as) and Manipuri(mn), we\nfine-tuned the existing IndicTrans2 open-source model to enable bidirectional\ntranslation between English and these languages. For Khasi (kh) and Mizo (mz),\nWe trained a multilingual model as a baseline using bilingual data from these\nfour language pairs, along with an additional about 8kw English-Bengali\nbilingual data, all of which share certain linguistic features. This was\nfollowed by fine-tuning to achieve bidirectional translation between English\nand Khasi, as well as English and Mizo. Our transfer learning experiments\nproduced impressive results: 23.5 BLEU for en-as, 31.8 BLEU for en-mn, 36.2\nBLEU for as-en, and 47.9 BLEU for mn-en on their respective test sets.\nSimilarly, the multilingual model transfer learning experiments yielded\nimpressive outcomes, achieving 19.7 BLEU for en-kh, 32.8 BLEU for en-mz, 16.1\nBLEU for kh-en, and 33.9 BLEU for mz-en on their respective test sets. These\nresults not only highlight the effectiveness of transfer learning techniques\nfor low-resource languages but also contribute to advancing machine translation\ncapabilities for low-resource Indian languages.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "6 pages, wmt24. arXiv admin note: substantial text overlap with\n  arXiv:2409.14800",
    "pdf_url": "http://arxiv.org/pdf/2409.15879v1",
    "published_date": "2024-09-24 08:53:19 UTC",
    "updated_date": "2024-09-24 08:53:19 UTC"
  },
  {
    "arxiv_id": "2409.16331v1",
    "title": "Exploring the traditional NMT model and Large Language Model for chat translation",
    "authors": [
      "Jinlong Yang",
      "Hengchao Shang",
      "Daimeng Wei",
      "Jiaxin Guo",
      "Zongyao Li",
      "Zhanglin Wu",
      "Zhiqiang Rao",
      "Shaojun Li",
      "Yuhao Xie",
      "Yuanchang Luo",
      "Jiawei Zheng",
      "Bin Wei",
      "Hao Yang"
    ],
    "abstract": "This paper describes the submissions of Huawei Translation Services\nCenter(HW-TSC) to WMT24 chat translation shared task on\nEnglish$\\leftrightarrow$Germany (en-de) bidirection. The experiments involved\nfine-tuning models using chat data and exploring various strategies, including\nMinimum Bayesian Risk (MBR) decoding and self-training. The results show\nsignificant performance improvements in certain directions, with the MBR\nself-training method achieving the best results. The Large Language Model also\ndiscusses the challenges and potential avenues for further research in the\nfield of chat translation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "7 pages, 6 Tables, WMT24",
    "pdf_url": "http://arxiv.org/pdf/2409.16331v1",
    "published_date": "2024-09-24 08:48:25 UTC",
    "updated_date": "2024-09-24 08:48:25 UTC"
  },
  {
    "arxiv_id": "2409.15869v1",
    "title": "Whisper in Medusa's Ear: Multi-head Efficient Decoding for Transformer-based ASR",
    "authors": [
      "Yael Segal-Feldman",
      "Aviv Shamsian",
      "Aviv Navon",
      "Gill Hetz",
      "Joseph Keshet"
    ],
    "abstract": "Large transformer-based models have significant potential for speech\ntranscription and translation. Their self-attention mechanisms and parallel\nprocessing enable them to capture complex patterns and dependencies in audio\nsequences. However, this potential comes with challenges, as these large and\ncomputationally intensive models lead to slow inference speeds. Various\noptimization strategies have been proposed to improve performance, including\nefficient hardware utilization and algorithmic enhancements. In this paper, we\nintroduce Whisper-Medusa, a novel approach designed to enhance processing speed\nwith minimal impact on Word Error Rate (WER). The proposed model extends the\nOpenAI's Whisper architecture by predicting multiple tokens per iteration,\nresulting in a 50% reduction in latency. We showcase the effectiveness of\nWhisper-Medusa across different learning setups and datasets.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.LG",
      "cs.SD"
    ],
    "primary_category": "eess.AS",
    "comment": "Under Review",
    "pdf_url": "http://arxiv.org/pdf/2409.15869v1",
    "published_date": "2024-09-24 08:42:31 UTC",
    "updated_date": "2024-09-24 08:42:31 UTC"
  },
  {
    "arxiv_id": "2409.15867v5",
    "title": "In-Context Ensemble Learning from Pseudo Labels Improves Video-Language Models for Low-Level Workflow Understanding",
    "authors": [
      "Moucheng Xu",
      "Evangelos Chatzaroulas",
      "Luc McCutcheon",
      "Abdul Ahad",
      "Hamzah Azeem",
      "Janusz Marecki",
      "Ammar Anwar"
    ],
    "abstract": "A Standard Operating Procedure (SOP) defines a low-level, step-by-step\nwritten guide for a business software workflow. SOP generation is a crucial\nstep towards automating end-to-end software workflows. Manually creating SOPs\ncan be time-consuming. Recent advancements in large video-language models offer\nthe potential for automating SOP generation by analyzing recordings of human\ndemonstrations. However, current large video-language models face challenges\nwith zero-shot SOP generation. In this work, we first explore in-context\nlearning with video-language models for SOP generation. We then propose an\nexploration-focused strategy called In-Context Ensemble Learning, to aggregate\npseudo labels of multiple possible paths of SOPs. The proposed in-context\nensemble learning as well enables the models to learn beyond its context window\nlimit with an implicit consistency regularisation. We report that in-context\nlearning helps video-language models to generate more temporally accurate SOP,\nand the proposed in-context ensemble learning can consistently enhance the\ncapabilities of the video-language models in SOP generation.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "To appear in NeurIPS Workshop on Video-Language Models 2024",
    "pdf_url": "http://arxiv.org/pdf/2409.15867v5",
    "published_date": "2024-09-24 08:41:01 UTC",
    "updated_date": "2024-10-20 10:45:08 UTC"
  },
  {
    "arxiv_id": "2409.15865v1",
    "title": "BeSimulator: A Large Language Model Powered Text-based Behavior Simulator",
    "authors": [
      "Jianan Wang",
      "Bin Li",
      "Xueying Wang",
      "Fu Li",
      "Yunlong Wu",
      "Juan Chen",
      "Xiaodong Yi"
    ],
    "abstract": "Traditional robot simulators focus on physical process modeling and realistic\nrendering, often suffering from high computational costs, inefficiencies, and\nlimited adaptability. To handle this issue, we propose Behavior Simulation in\nrobotics to emphasize checking the behavior logic of robots and achieving\nsufficient alignment between the outcome of robot actions and real scenarios.\nIn this paper, we introduce BeSimulator, a modular and novel LLM-powered\nframework, as an attempt towards behavior simulation in the context of\ntext-based environments. By constructing text-based virtual environments and\nperforming semantic-level simulation, BeSimulator can generalize across\nscenarios and achieve long-horizon complex simulation. Inspired by human\ncognition processes, it employs a \"consider-decide-capture-transfer\"\nmethodology, termed Chain of Behavior Simulation, which excels at analyzing\naction feasibility and state transitions. Additionally, BeSimulator\nincorporates code-driven reasoning to enable arithmetic operations and enhance\nreliability, as well as integrates reflective feedback to refine simulation.\nBased on our manually constructed behavior-tree-based simulation benchmark\nBTSIMBENCH, our experiments show a significant performance improvement in\nbehavior simulation compared to baselines, ranging from 14.7% to 26.6%.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.RO",
    "comment": "7 pages, 3 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2409.15865v1",
    "published_date": "2024-09-24 08:37:04 UTC",
    "updated_date": "2024-09-24 08:37:04 UTC"
  },
  {
    "arxiv_id": "2409.15861v3",
    "title": "A Zero-Shot Open-Vocabulary Pipeline for Dialogue Understanding",
    "authors": [
      "Abdulfattah Safa",
      "Gözde Gül Şahin"
    ],
    "abstract": "Dialogue State Tracking (DST) is crucial for understanding user needs and\nexecuting appropriate system actions in task-oriented dialogues. Majority of\nexisting DST methods are designed to work within predefined ontologies and\nassume the availability of gold domain labels, struggling with adapting to new\nslots values. While Large Language Models (LLMs)-based systems show promising\nzero-shot DST performance, they either require extensive computational\nresources or they underperform existing fully-trained systems, limiting their\npracticality. To address these limitations, we propose a zero-shot,\nopen-vocabulary system that integrates domain classification and DST in a\nsingle pipeline. Our approach includes reformulating DST as a\nquestion-answering task for less capable models and employing self-refining\nprompts for more adaptable ones. Our system does not rely on fixed slot values\ndefined in the ontology allowing the system to adapt dynamically. We compare\nour approach with existing SOTA, and show that it provides up to 20% better\nJoint Goal Accuracy (JGA) over previous methods on datasets like Multi-WOZ 2.1,\nwith up to 90% fewer requests to the LLM API.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to NAACL 2025",
    "pdf_url": "http://arxiv.org/pdf/2409.15861v3",
    "published_date": "2024-09-24 08:33:41 UTC",
    "updated_date": "2025-03-07 19:50:00 UTC"
  },
  {
    "arxiv_id": "2409.15858v2",
    "title": "Identification For Control Based on Neural Networks: Approximately Linearizable Models",
    "authors": [
      "Maxime Thieffry",
      "Alexandre Hache",
      "Mohamed Yagoubi",
      "Philippe Chevrel"
    ],
    "abstract": "This work presents a control-oriented identification scheme for efficient\ncontrol design and stability analysis of nonlinear systems. Neural networks are\nused to identify a discrete-time nonlinear state-space model to approximate\ntime-domain input-output behavior of a nonlinear system. The network is\nconstructed such that the identified model is approximately linearizable by\nfeedback, ensuring that the control law trivially follows from the learning\nstage. After the identification and quasi-linearization procedures, linear\ncontrol theory comes at hand to design robust controllers and study stability\nof the closed-loop system. The effectiveness and interest of the methodology\nare illustrated throughout the paper on popular benchmarks for system\nidentification.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.SY"
    ],
    "primary_category": "eess.SY",
    "comment": "15 pages, 3 figures, 6 tables, accepted as a poster in SysDO 2024,\n  Stuttgart, Germany",
    "pdf_url": "http://arxiv.org/pdf/2409.15858v2",
    "published_date": "2024-09-24 08:31:22 UTC",
    "updated_date": "2024-10-03 10:59:15 UTC"
  },
  {
    "arxiv_id": "2409.15844v2",
    "title": "Adaptive Learn-then-Test: Statistically Valid and Efficient Hyperparameter Selection",
    "authors": [
      "Matteo Zecchin",
      "Sangwoo Park",
      "Osvaldo Simeone"
    ],
    "abstract": "We introduce adaptive learn-then-test (aLTT), an efficient hyperparameter\nselection procedure that provides finite-sample statistical guarantees on the\npopulation risk of AI models. Unlike the existing learn-then-test (LTT)\ntechnique, which relies on conventional p-value-based multiple hypothesis\ntesting (MHT), aLTT implements sequential data-dependent MHT with early\ntermination by leveraging e-processes. As a result, aLTT can reduce the number\nof testing rounds, making it particularly well-suited for scenarios in which\ntesting is costly or presents safety risks. Apart from maintaining statistical\nvalidity, in applications such as online policy selection for offline\nreinforcement learning and prompt engineering, aLTT is shown to achieve the\nsame performance as LTT while requiring only a fraction of the testing rounds.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.IT",
      "cs.LG",
      "math.IT",
      "stat.ME"
    ],
    "primary_category": "stat.ML",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.15844v2",
    "published_date": "2024-09-24 08:14:26 UTC",
    "updated_date": "2025-01-31 15:04:08 UTC"
  },
  {
    "arxiv_id": "2409.15843v2",
    "title": "From Passive Watching to Active Learning: Empowering Proactive Participation in Digital Classrooms with AI Video Assistant",
    "authors": [
      "Anna Bodonhelyi",
      "Enkeleda Thaqi",
      "Süleyman Özdel",
      "Efe Bozkir",
      "Enkelejda Kasneci"
    ],
    "abstract": "In online education, innovative tools are crucial for enhancing learning\noutcomes. SAM (Study with AI Mentor) is an advanced platform that integrates\neducational videos with a context-aware chat interface powered by large\nlanguage models. SAM encourages students to ask questions and explore unclear\nconcepts in real time, offering personalized, context-specific assistance,\nincluding explanations of formulas, slides, and images. We evaluated SAM in two\nstudies: one with 25 university students and another with 80 crowdsourced\nparticipants, using pre- and post-knowledge tests to compare a group using SAM\nand a control group. The results demonstrated that SAM users achieved greater\nknowledge gains specifically for younger learners and individuals in flexible\nworking environments, such as students, supported by a 97.6% accuracy rate in\nthe chatbot's responses. Participants also provided positive feedback on SAM's\nusability and effectiveness. SAM's proactive approach to learning not only\nenhances learning outcomes but also empowers students to take full ownership of\ntheir educational experience, representing a promising future direction for\nonline learning tools.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.15843v2",
    "published_date": "2024-09-24 08:12:36 UTC",
    "updated_date": "2025-02-24 11:05:02 UTC"
  },
  {
    "arxiv_id": "2409.19015v1",
    "title": "Textless NLP -- Zero Resource Challenge with Low Resource Compute",
    "authors": [
      "Krithiga Ramadass",
      "Abrit Pal Singh",
      "Srihari J",
      "Sheetal Kalyani"
    ],
    "abstract": "This work addresses the persistent challenges of substantial training time\nand GPU resource requirements even when training lightweight encoder-vocoder\nmodels for Textless NLP. We reduce training steps significantly while improving\nperformance by a) leveraging learning rate schedulers for efficient and faster\nconvergence b) optimizing hop length and c) tuning the interpolation scale\nfactors for better audio quality. Additionally, we explore the latent space\nrepresentation for Indian languages such as Tamil and Bengali for the acoustic\nunit discovery and voice conversion task. Our approach leverages a quantized\nencoder architecture, in conjunction with a vocoder which utilizes the proposed\nmixture of optimized hop length, tuned interpolation scale factors and a cyclic\nlearning rate scheduler. We obtain consistently good results across English,\nTamil and Bengali datasets. The proposed method excels in capturing complex\nlinguistic patterns, resulting in clear reconstructed audio during voice\nconversion with significantly reduced training time.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.19015v1",
    "published_date": "2024-09-24 08:08:05 UTC",
    "updated_date": "2024-09-24 08:08:05 UTC"
  },
  {
    "arxiv_id": "2409.15825v2",
    "title": "60 Data Points are Sufficient to Fine-Tune LLMs for Question-Answering",
    "authors": [
      "Junjie Ye",
      "Yuming Yang",
      "Qi Zhang",
      "Tao Gui",
      "Xuanjing Huang",
      "Peng Wang",
      "Zhongchao Shi",
      "Jianping Fan"
    ],
    "abstract": "Large language models (LLMs) encode extensive world knowledge through\npre-training on massive datasets, which can then be fine-tuned for the\nquestion-answering (QA) task. However, effective strategies for fine-tuning\nLLMs for the QA task remain largely unexplored. To address this gap, we\ncategorize supervised fine-tuning (SFT) data based on the extent of knowledge\nmemorized by the pretrained LLMs and conduct a series of empirical analyses.\nOur experiments, involving four LLMs from three different model families, focus\non three key factors: the amount of data required for SFT, the impact of\ndifferent SFT datasets on model performance, and how data requirements vary\nacross LLMs. The results show that as few as 60 data points during the SFT\nstage can activate the knowledge encoded during pre-training, enabling LLMs to\nperform the QA task. Additionally, SFT with data of varying memory levels has a\nsignificant impact on LLM performance, with the optimal dataset differing based\non the specific model being fine-tuned. Future research will delve deeper into\nthe mechanisms underlying these phenomena.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.15825v2",
    "published_date": "2024-09-24 07:38:38 UTC",
    "updated_date": "2025-01-20 15:37:50 UTC"
  },
  {
    "arxiv_id": "2409.15817v1",
    "title": "SwiftDossier: Tailored Automatic Dossier for Drug Discovery with LLMs and Agents",
    "authors": [
      "Gabriele Fossi",
      "Youssef Boulaimen",
      "Leila Outemzabet",
      "Nathalie Jeanray",
      "Stephane Gerart",
      "Sebastien Vachenc",
      "Joanna Giemza",
      "Salvatore Raieli"
    ],
    "abstract": "The advancement of artificial intelligence algorithms has expanded their\napplication to several fields such as the biomedical domain. Artificial\nintelligence systems, including Large Language Models (LLMs), can be\nparticularly advantageous in drug discovery, which is a very long and expensive\nprocess. However, LLMs by themselves lack in-depth knowledge about specific\ndomains and can generate factually incorrect information. Moreover, they are\nnot able to perform more complex actions that imply the usage of external\ntools. Our work is focused on these two issues. Firstly, we show how the\nimplementation of an advanced RAG system can help the LLM to generate more\naccurate answers to drug-discovery-related questions. The results show that the\nanswers generated by the LLM with the RAG system surpass in quality the answers\nproduced by the model without RAG. Secondly, we show how to create an automatic\ntarget dossier using LLMs and incorporating them with external tools that they\ncan use to execute more intricate tasks to gather data such as accessing\ndatabases and executing code. The result is a production-ready target dossier\ncontaining the acquired information summarized into a PDF and a PowerPoint\npresentation.",
    "categories": [
      "cs.AI",
      "68T07, 92C50, 68T09",
      "I.2.7; J.3"
    ],
    "primary_category": "cs.AI",
    "comment": "10 pages, 7 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2409.15817v1",
    "published_date": "2024-09-24 07:29:05 UTC",
    "updated_date": "2024-09-24 07:29:05 UTC"
  },
  {
    "arxiv_id": "2409.15815v1",
    "title": "AsthmaBot: Multi-modal, Multi-Lingual Retrieval Augmented Generation For Asthma Patient Support",
    "authors": [
      "Adil Bahaj",
      "Mounir Ghogho"
    ],
    "abstract": "Asthma rates have risen globally, driven by environmental and lifestyle\nfactors. Access to immediate medical care is limited, particularly in\ndeveloping countries, necessitating automated support systems. Large Language\nModels like ChatGPT (Chat Generative Pre-trained Transformer) and Gemini have\nadvanced natural language processing in general and question answering in\nparticular, however, they are prone to producing factually incorrect responses\n(i.e. hallucinations). Retrieval-augmented generation systems, integrating\ncurated documents, can improve large language models' performance and reduce\nthe incidence of hallucination. We introduce AsthmaBot, a multi-lingual,\nmulti-modal retrieval-augmented generation system for asthma support.\nEvaluation of an asthma-related frequently asked questions dataset shows\nAsthmaBot's efficacy. AsthmaBot has an added interactive and intuitive\ninterface that integrates different data modalities (text, images, videos) to\nmake it accessible to the larger public. AsthmaBot is available online via\n\\url{asthmabot.datanets.org}.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "10 pages",
    "pdf_url": "http://arxiv.org/pdf/2409.15815v1",
    "published_date": "2024-09-24 07:24:01 UTC",
    "updated_date": "2024-09-24 07:24:01 UTC"
  },
  {
    "arxiv_id": "2409.15814v1",
    "title": "Interactive Example-based Explanations to Improve Health Professionals' Onboarding with AI for Human-AI Collaborative Decision Making",
    "authors": [
      "Min Hun Lee",
      "Renee Bao Xuan Ng",
      "Silvana Xinyi Choo",
      "Shamala Thilarajah"
    ],
    "abstract": "A growing research explores the usage of AI explanations on user's decision\nphases for human-AI collaborative decision-making. However, previous studies\nfound the issues of overreliance on `wrong' AI outputs. In this paper, we\npropose interactive example-based explanations to improve health professionals'\nonboarding with AI for their better reliance on AI during AI-assisted\ndecision-making. We implemented an AI-based decision support system that\nutilizes a neural network to assess the quality of post-stroke survivors'\nexercises and interactive example-based explanations that systematically\nsurface the nearest neighborhoods of a test/task sample from the training set\nof the AI model to assist users' onboarding with the AI model. To investigate\nthe effect of interactive example-based explanations, we conducted a study with\ndomain experts, health professionals to evaluate their performance and reliance\non AI. Our interactive example-based explanations during onboarding assisted\nhealth professionals in having a better reliance on AI and making a higher\nratio of making `right' decisions and a lower ratio of `wrong' decisions than\nproviding only feature-based explanations during the decision-support phase.\nOur study discusses new challenges of assisting user's onboarding with AI for\nhuman-AI collaborative decision-making.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.15814v1",
    "published_date": "2024-09-24 07:20:09 UTC",
    "updated_date": "2024-09-24 07:20:09 UTC"
  },
  {
    "arxiv_id": "2409.15813v1",
    "title": "Layer-wise Model Merging for Unsupervised Domain Adaptation in Segmentation Tasks",
    "authors": [
      "Roberto Alcover-Couso",
      "Juan C. SanMiguel",
      "Marcos Escudero-Viñolo",
      "Jose M Martínez"
    ],
    "abstract": "Merging parameters of multiple models has resurfaced as an effective strategy\nto enhance task performance and robustness, but prior work is limited by the\nhigh costs of ensemble creation and inference. In this paper, we leverage the\nabundance of freely accessible trained models to introduce a cost-free approach\nto model merging. It focuses on a layer-wise integration of merged models,\naiming to maintain the distinctiveness of the task-specific final layers while\nunifying the initial layers, which are primarily associated with feature\nextraction. This approach ensures parameter consistency across all layers,\nessential for boosting performance. Moreover, it facilitates seamless\nintegration of knowledge, enabling effective merging of models from different\ndatasets and tasks. Specifically, we investigate its applicability in\nUnsupervised Domain Adaptation (UDA), an unexplored area for model merging, for\nSemantic and Panoptic Segmentation. Experimental results demonstrate\nsubstantial UDA improvements without additional costs for merging\nsame-architecture models from distinct datasets ($\\uparrow 2.6\\%$ mIoU) and\ndifferent-architecture models with a shared backbone ($\\uparrow 6.8\\%$ mIoU).\nFurthermore, merging Semantic and Panoptic Segmentation models increases mPQ by\n$\\uparrow 7\\%$. These findings are validated across a wide variety of UDA\nstrategies, architectures, and datasets.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.15813v1",
    "published_date": "2024-09-24 07:19:30 UTC",
    "updated_date": "2024-09-24 07:19:30 UTC"
  },
  {
    "arxiv_id": "2409.15806v1",
    "title": "CLSP: High-Fidelity Contrastive Language-State Pre-training for Agent State Representation",
    "authors": [
      "Fuxian Huang",
      "Qi Zhang",
      "Shaopeng Zhai",
      "Jie Wang",
      "Tianyi Zhang",
      "Haoran Zhang",
      "Ming Zhou",
      "Yu Liu",
      "Yu Qiao"
    ],
    "abstract": "With the rapid development of artificial intelligence, multimodal learning\nhas become an important research area. For intelligent agents, the state is a\ncrucial modality to convey precise information alongside common modalities like\nimages, videos, and language. This becomes especially clear with the broad\nadoption of reinforcement learning and multimodal large language models.\nNevertheless, the representation of state modality still lags in development.\nTo this end, we propose a High-Fidelity Contrastive Language-State Pre-training\n(CLSP) method, which can accurately encode state information into general\nrepresentations for both reinforcement learning and multimodal large language\nmodels. Specifically, we first design a pre-training task based on the\nclassification to train an encoder with coarse-grained information. Next, we\nconstruct data pairs of states and language descriptions, utilizing the\npre-trained encoder to initialize the CLSP encoder. Then, we deploy contrastive\nlearning to train the CLSP encoder to effectively represent precise state\ninformation. Additionally, we enhance the representation of numerical\ninformation using the Random Fourier Features (RFF) method for high-fidelity\nmapping. Extensive experiments demonstrate the superior precision and\ngeneralization capabilities of our representation, achieving outstanding\nresults in text-state retrieval, reinforcement learning navigation tasks, and\nmultimodal large language model understanding.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.15806v1",
    "published_date": "2024-09-24 07:08:00 UTC",
    "updated_date": "2024-09-24 07:08:00 UTC"
  },
  {
    "arxiv_id": "2409.15794v1",
    "title": "Towards Universal Large-Scale Foundational Model for Natural Gas Demand Forecasting",
    "authors": [
      "Xinxing Zhou",
      "Jiaqi Ye",
      "Shubao Zhao",
      "Ming Jin",
      "Zhaoxiang Hou",
      "Chengyi Yang",
      "Zengxiang Li",
      "Yanlong Wen",
      "Xiaojie Yuan"
    ],
    "abstract": "In the context of global energy strategy, accurate natural gas demand\nforecasting is crucial for ensuring efficient resource allocation and\noperational planning. Traditional forecasting methods struggle to cope with the\ngrowing complexity and variability of gas consumption patterns across diverse\nindustries and commercial sectors. To address these challenges, we propose the\nfirst foundation model specifically tailored for natural gas demand\nforecasting. Foundation models, known for their ability to generalize across\ntasks and datasets, offer a robust solution to the limitations of traditional\nmethods, such as the need for separate models for different customer segments\nand their limited generalization capabilities. Our approach leverages\ncontrastive learning to improve prediction accuracy in real-world scenarios,\nparticularly by tackling issues such as noise in historical consumption data\nand the potential misclassification of similar data samples, which can lead to\ndegradation in the quaility of the representation and thus the accuracy of\ndownstream forecasting tasks. By integrating advanced noise filtering\ntechniques within the contrastive learning framework, our model enhances the\nquality of learned representations, leading to more accurate predictions.\nFurthermore, the model undergoes industry-specific fine-tuning during\npretraining, enabling it to better capture the unique characteristics of gas\nconsumption across various sectors. We conducted extensive experiments using a\nlarge-scale dataset from ENN Group, which includes data from over 10,000\nindustrial, commercial, and welfare-related customers across multiple regions.\nOur model outperformed existing state-of-the-art methods, demonstrating a\nrelative improvement in MSE by 3.68\\% and in MASE by 6.15\\% compared to the\nbest available model.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.15794v1",
    "published_date": "2024-09-24 06:44:29 UTC",
    "updated_date": "2024-09-24 06:44:29 UTC"
  },
  {
    "arxiv_id": "2409.15790v3",
    "title": "Small Language Models: Survey, Measurements, and Insights",
    "authors": [
      "Zhenyan Lu",
      "Xiang Li",
      "Dongqi Cai",
      "Rongjie Yi",
      "Fangming Liu",
      "Xiwen Zhang",
      "Nicholas D. Lane",
      "Mengwei Xu"
    ],
    "abstract": "Small language models (SLMs), despite their widespread adoption in modern\nsmart devices, have received significantly less academic attention compared to\ntheir large language model (LLM) counterparts, which are predominantly deployed\nin data centers and cloud environments. While researchers continue to improve\nthe capabilities of LLMs in the pursuit of artificial general intelligence, SLM\nresearch aims to make machine intelligence more accessible, affordable, and\nefficient for everyday tasks. Focusing on transformer-based, decoder-only\nlanguage models with 100M-5B parameters, we survey 70 state-of-the-art\nopen-source SLMs, analyzing their technical innovations across three axes:\narchitectures, training datasets, and training algorithms. In addition, we\nevaluate their capabilities in various domains, including commonsense\nreasoning, mathematics, in-context learning, and long context. To gain further\ninsight into their on-device runtime costs, we benchmark their inference\nlatency and memory footprints. Through in-depth analysis of our benchmarking\ndata, we offer valuable insights to advance research in this field.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.15790v3",
    "published_date": "2024-09-24 06:36:56 UTC",
    "updated_date": "2025-02-26 06:34:55 UTC"
  },
  {
    "arxiv_id": "2409.15764v1",
    "title": "Spatial-Temporal Mixture-of-Graph-Experts for Multi-Type Crime Prediction",
    "authors": [
      "Ziyang Wu",
      "Fan Liu",
      "Jindong Han",
      "Yuxuan Liang",
      "Hao Liu"
    ],
    "abstract": "As various types of crime continue to threaten public safety and economic\ndevelopment, predicting the occurrence of multiple types of crimes becomes\nincreasingly vital for effective prevention measures. Although extensive\nefforts have been made, most of them overlook the heterogeneity of different\ncrime categories and fail to address the issue of imbalanced spatial\ndistribution. In this work, we propose a Spatial-Temporal\nMixture-of-Graph-Experts (ST-MoGE) framework for collective multiple-type crime\nprediction. To enhance the model's ability to identify diverse spatial-temporal\ndependencies and mitigate potential conflicts caused by spatial-temporal\nheterogeneity of different crime categories, we introduce an attentive-gated\nMixture-of-Graph-Experts (MGEs) module to capture the distinctive and shared\ncrime patterns of each crime category. Then, we propose Cross-Expert\nContrastive Learning(CECL) to update the MGEs and force each expert to focus on\nspecific pattern modeling, thereby reducing blending and redundancy.\nFurthermore, to address the issue of imbalanced spatial distribution, we\npropose a Hierarchical Adaptive Loss Re-weighting (HALR) approach to eliminate\nbiases and insufficient learning of data-scarce regions. To evaluate the\neffectiveness of our methods, we conduct comprehensive experiments on two\nreal-world crime datasets and compare our results with twelve advanced\nbaselines. The experimental results demonstrate the superiority of our methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.15764v1",
    "published_date": "2024-09-24 05:41:11 UTC",
    "updated_date": "2024-09-24 05:41:11 UTC"
  },
  {
    "arxiv_id": "2409.15763v2",
    "title": "IRSC: A Zero-shot Evaluation Benchmark for Information Retrieval through Semantic Comprehension in Retrieval-Augmented Generation Scenarios",
    "authors": [
      "Hai Lin",
      "Shaoxiong Zhan",
      "Junyou Su",
      "Haitao Zheng",
      "Hui Wang"
    ],
    "abstract": "In Retrieval-Augmented Generation (RAG) tasks using Large Language Models\n(LLMs), the quality of retrieved information is critical to the final output.\nThis paper introduces the IRSC benchmark for evaluating the performance of\nembedding models in multilingual RAG tasks. The benchmark encompasses five\nretrieval tasks: query retrieval, title retrieval, part-of-paragraph retrieval,\nkeyword retrieval, and summary retrieval. Our research addresses the current\nlack of comprehensive testing and effective comparison methods for embedding\nmodels in RAG scenarios. We introduced new metrics: the Similarity of Semantic\nComprehension Index (SSCI) and the Retrieval Capability Contest Index (RCCI),\nand evaluated models such as Snowflake-Arctic, BGE, GTE, and M3E. Our\ncontributions include: 1) the IRSC benchmark, 2) the SSCI and RCCI metrics, and\n3) insights into the cross-lingual limitations of embedding models. The IRSC\nbenchmark aims to enhance the understanding and development of accurate\nretrieval systems in RAG tasks. All code and datasets are available at:\nhttps://github.com/Jasaxion/IRSC_Benchmark",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.15763v2",
    "published_date": "2024-09-24 05:39:53 UTC",
    "updated_date": "2024-09-26 05:43:08 UTC"
  },
  {
    "arxiv_id": "2409.15761v2",
    "title": "TFG: Unified Training-Free Guidance for Diffusion Models",
    "authors": [
      "Haotian Ye",
      "Haowei Lin",
      "Jiaqi Han",
      "Minkai Xu",
      "Sheng Liu",
      "Yitao Liang",
      "Jianzhu Ma",
      "James Zou",
      "Stefano Ermon"
    ],
    "abstract": "Given an unconditional diffusion model and a predictor for a target property\nof interest (e.g., a classifier), the goal of training-free guidance is to\ngenerate samples with desirable target properties without additional training.\nExisting methods, though effective in various individual applications, often\nlack theoretical grounding and rigorous testing on extensive benchmarks. As a\nresult, they could even fail on simple tasks, and applying them to a new\nproblem becomes unavoidably difficult. This paper introduces a novel\nalgorithmic framework encompassing existing methods as special cases, unifying\nthe study of training-free guidance into the analysis of an algorithm-agnostic\ndesign space. Via theoretical and empirical investigation, we propose an\nefficient and effective hyper-parameter searching strategy that can be readily\napplied to any downstream task. We systematically benchmark across 7 diffusion\nmodels on 16 tasks with 40 targets, and improve performance by 8.5% on average.\nOur framework and benchmark offer a solid foundation for conditional generation\nin a training-free manner.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.15761v2",
    "published_date": "2024-09-24 05:31:17 UTC",
    "updated_date": "2024-11-19 08:12:46 UTC"
  },
  {
    "arxiv_id": "2409.15755v1",
    "title": "Stage-Wise Reward Shaping for Acrobatic Robots: A Constrained Multi-Objective Reinforcement Learning Approach",
    "authors": [
      "Dohyeong Kim",
      "Hyeokjin Kwon",
      "Junseok Kim",
      "Gunmin Lee",
      "Songhwai Oh"
    ],
    "abstract": "As the complexity of tasks addressed through reinforcement learning (RL)\nincreases, the definition of reward functions also has become highly\ncomplicated. We introduce an RL method aimed at simplifying the reward-shaping\nprocess through intuitive strategies. Initially, instead of a single reward\nfunction composed of various terms, we define multiple reward and cost\nfunctions within a constrained multi-objective RL (CMORL) framework. For tasks\ninvolving sequential complex movements, we segment the task into distinct\nstages and define multiple rewards and costs for each stage. Finally, we\nintroduce a practical CMORL algorithm that maximizes objectives based on these\nrewards while satisfying constraints defined by the costs. The proposed method\nhas been successfully demonstrated across a variety of acrobatic tasks in both\nsimulation and real-world environments. Additionally, it has been shown to\nsuccessfully perform tasks compared to existing RL and constrained RL\nalgorithms. Our code is available at\nhttps://github.com/rllab-snu/Stage-Wise-CMORL.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "7 pages",
    "pdf_url": "http://arxiv.org/pdf/2409.15755v1",
    "published_date": "2024-09-24 05:25:24 UTC",
    "updated_date": "2024-09-24 05:25:24 UTC"
  },
  {
    "arxiv_id": "2409.15753v1",
    "title": "Development and Validation of Heparin Dosing Policies Using an Offline Reinforcement Learning Algorithm",
    "authors": [
      "Yooseok Lim",
      "Inbeom Park",
      "Sujee Lee"
    ],
    "abstract": "Appropriate medication dosages in the intensive care unit (ICU) are critical\nfor patient survival. Heparin, used to treat thrombosis and inhibit blood\nclotting in the ICU, requires careful administration due to its complexity and\nsensitivity to various factors, including patient clinical characteristics,\nunderlying medical conditions, and potential drug interactions. Incorrect\ndosing can lead to severe complications such as strokes or excessive bleeding.\nTo address these challenges, this study proposes a reinforcement learning\n(RL)-based personalized optimal heparin dosing policy that guides dosing\ndecisions reliably within the therapeutic range based on individual patient\nconditions. A batch-constrained policy was implemented to minimize\nout-of-distribution errors in an offline RL environment and effectively\nintegrate RL with existing clinician policies. The policy's effectiveness was\nevaluated using weighted importance sampling, an off-policy evaluation method,\nand the relationship between state representations and Q-values was explored\nusing t-SNE. Both quantitative and qualitative analyses were conducted using\nthe Medical Information Mart for Intensive Care III (MIMIC-III) database,\ndemonstrating the efficacy of the proposed RL-based medication policy.\nLeveraging advanced machine learning techniques and extensive clinical data,\nthis research enhances heparin administration practices and establishes a\nprecedent for the development of sophisticated decision-support tools in\nmedicine.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.15753v1",
    "published_date": "2024-09-24 05:20:38 UTC",
    "updated_date": "2024-09-24 05:20:38 UTC"
  },
  {
    "arxiv_id": "2409.15750v3",
    "title": "The Roles of Generative Artificial Intelligence in Internet of Electric Vehicles",
    "authors": [
      "Hanwen Zhang",
      "Dusit Niyato",
      "Wei Zhang",
      "Changyuan Zhao",
      "Hongyang Du",
      "Abbas Jamalipour",
      "Sumei Sun",
      "Yiyang Pei"
    ],
    "abstract": "With the advancements of generative artificial intelligence (GenAI) models,\ntheir capabilities are expanding significantly beyond content generation and\nthe models are increasingly being used across diverse applications.\nParticularly, GenAI shows great potential in addressing challenges in the\nelectric vehicle (EV) ecosystem ranging from charging management to\ncyber-attack prevention. In this paper, we specifically consider Internet of\nelectric vehicles (IoEV) and we categorize GenAI for IoEV into four different\nlayers namely, EV's battery layer, individual EV layer, smart grid layer, and\nsecurity layer. We introduce various GenAI techniques used in each layer of\nIoEV applications. Subsequently, public datasets available for training the\nGenAI models are summarized. Finally, we provide recommendations for future\ndirections. This survey not only categorizes the applications of GenAI in IoEV\nacross different layers but also serves as a valuable resource for researchers\nand practitioners by highlighting the design and implementation challenges\nwithin each layer. Furthermore, it provides a roadmap for future research\ndirections, enabling the development of more robust and efficient IoEV systems\nthrough the integration of advanced GenAI techniques.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.ET"
    ],
    "primary_category": "cs.LG",
    "comment": "25 Pages",
    "pdf_url": "http://arxiv.org/pdf/2409.15750v3",
    "published_date": "2024-09-24 05:12:10 UTC",
    "updated_date": "2024-11-14 06:33:26 UTC"
  },
  {
    "arxiv_id": "2409.15749v1",
    "title": "Automated Assessment of Multimodal Answer Sheets in the STEM domain",
    "authors": [
      "Rajlaxmi Patil",
      "Aditya Ashutosh Kulkarni",
      "Ruturaj Ghatage",
      "Sharvi Endait",
      "Geetanjali Kale",
      "Raviraj Joshi"
    ],
    "abstract": "In the domain of education, the integration of,technology has led to a\ntransformative era, reshaping traditional,learning paradigms. Central to this\nevolution is the automation,of grading processes, particularly within the STEM\ndomain encompassing Science, Technology, Engineering, and Mathematics.,While\nefforts to automate grading have been made in subjects,like Literature, the\nmultifaceted nature of STEM assessments,presents unique challenges, ranging\nfrom quantitative analysis,to the interpretation of handwritten diagrams. To\naddress these,challenges, this research endeavors to develop efficient and\nreliable grading methods through the implementation of automated,assessment\ntechniques using Artificial Intelligence (AI). Our,contributions lie in two key\nareas: firstly, the development of a,robust system for evaluating textual\nanswers in STEM, leveraging,sample answers for precise comparison and grading,\nenabled by,advanced algorithms and natural language processing\ntechniques.,Secondly, a focus on enhancing diagram evaluation,\nparticularly,flowcharts, within the STEM context, by transforming diagrams,into\ntextual representations for nuanced assessment using a,Large Language Model\n(LLM). By bridging the gap between,visual representation and semantic meaning,\nour approach ensures accurate evaluation while minimizing manual\nintervention.,Through the integration of models such as CRAFT for\ntext,extraction and YoloV5 for object detection, coupled with LLMs,like\nMistral-7B for textual evaluation, our methodology facilitates,comprehensive\nassessment of multimodal answer sheets. This,paper provides a detailed account\nof our methodology, challenges,encountered, results, and implications,\nemphasizing the potential,of AI-driven approaches in revolutionizing grading\npractices in,STEM education.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.15749v1",
    "published_date": "2024-09-24 05:10:13 UTC",
    "updated_date": "2024-09-24 05:10:13 UTC"
  },
  {
    "arxiv_id": "2409.15747v1",
    "title": "Training Neural Networks for Modularity aids Interpretability",
    "authors": [
      "Satvik Golechha",
      "Dylan Cope",
      "Nandi Schoots"
    ],
    "abstract": "An approach to improve network interpretability is via clusterability, i.e.,\nsplitting a model into disjoint clusters that can be studied independently. We\nfind pretrained models to be highly unclusterable and thus train models to be\nmore modular using an ``enmeshment loss'' function that encourages the\nformation of non-interacting clusters. Using automated interpretability\nmeasures, we show that our method finds clusters that learn different,\ndisjoint, and smaller circuits for CIFAR-10 labels. Our approach provides a\npromising direction for making neural networks easier to interpret.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "4 pages, preprint",
    "pdf_url": "http://arxiv.org/pdf/2409.15747v1",
    "published_date": "2024-09-24 05:03:49 UTC",
    "updated_date": "2024-09-24 05:03:49 UTC"
  },
  {
    "arxiv_id": "2409.15740v1",
    "title": "Real-Time Pedestrian Detection on IoT Edge Devices: A Lightweight Deep Learning Approach",
    "authors": [
      "Muhammad Dany Alfikri",
      "Rafael Kaliski"
    ],
    "abstract": "Artificial intelligence (AI) has become integral to our everyday lives.\nComputer vision has advanced to the point where it can play the safety critical\nrole of detecting pedestrians at road intersections in intelligent\ntransportation systems and alert vehicular traffic as to potential collisions.\nCentralized computing analyzes camera feeds and generates alerts for nearby\nvehicles. However, real-time applications face challenges such as latency,\nlimited data transfer speeds, and the risk of life loss. Edge servers offer a\npotential solution for real-time applications, providing localized computing\nand storage resources and lower response times. Unfortunately, edge servers\nhave limited processing power. Lightweight deep learning (DL) techniques enable\nedge servers to utilize compressed deep neural network (DNN) models.\n  The research explores implementing a lightweight DL model on Artificial\nIntelligence of Things (AIoT) edge devices. An optimized You Only Look Once\n(YOLO) based DL model is deployed for real-time pedestrian detection, with\ndetection events transmitted to the edge server using the Message Queuing\nTelemetry Transport (MQTT) protocol. The simulation results demonstrate that\nthe optimized YOLO model can achieve real-time pedestrian detection, with a\nfast inference speed of 147 milliseconds, a frame rate of 2.3 frames per\nsecond, and an accuracy of 78%, representing significant improvements over\nbaseline models.",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.NI"
    ],
    "primary_category": "cs.AI",
    "comment": "10 pages, 3 tables, 12 figures, article submitted to IEEE for\n  possible publication",
    "pdf_url": "http://arxiv.org/pdf/2409.15740v1",
    "published_date": "2024-09-24 04:48:41 UTC",
    "updated_date": "2024-09-24 04:48:41 UTC"
  },
  {
    "arxiv_id": "2409.15733v1",
    "title": "EvoFA: Evolvable Fast Adaptation for EEG Emotion Recognition",
    "authors": [
      "Ming Jin",
      "Danni Zhang",
      "Gangming Zhao",
      "Changde Du",
      "Jinpeng Li"
    ],
    "abstract": "Electroencephalography (EEG)-based emotion recognition has gained significant\ntraction due to its accuracy and objectivity. However, the non-stationary\nnature of EEG signals leads to distribution drift over time, causing severe\nperformance degradation when the model is reused. While numerous domain\nadaptation (DA) approaches have been proposed in recent years to address this\nissue, their reliance on large amounts of target data for calibration restricts\nthem to offline scenarios, rendering them unsuitable for real-time\napplications. To address this challenge, this paper proposes Evolvable Fast\nAdaptation (EvoFA), an online adaptive framework tailored for EEG data. EvoFA\norganically integrates the rapid adaptation of Few-Shot Learning (FSL) and the\ndistribution matching of Domain Adaptation (DA) through a two-stage\ngeneralization process. During the training phase, a robust base meta-learning\nmodel is constructed for strong generalization. In the testing phase, a\ndesigned evolvable meta-adaptation module iteratively aligns the marginal\ndistribution of target (testing) data with the evolving source (training) data\nwithin a model-agnostic meta-learning framework, enabling the model to learn\nthe evolving trends of testing data relative to training data and improving\nonline testing performance. Experimental results demonstrate that EvoFA\nachieves significant improvements compared to the basic FSL method and previous\nonline methods. The introduction of EvoFA paves the way for broader adoption of\nEEG-based emotion recognition in real-world applications. Our code will be\nreleased upon publication.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.15733v1",
    "published_date": "2024-09-24 04:35:10 UTC",
    "updated_date": "2024-09-24 04:35:10 UTC"
  },
  {
    "arxiv_id": "2409.15730v1",
    "title": "Learning Multiple Probabilistic Decisions from Latent World Model in Autonomous Driving",
    "authors": [
      "Lingyu Xiao",
      "Jiang-Jiang Liu",
      "Sen Yang",
      "Xiaofan Li",
      "Xiaoqing Ye",
      "Wankou Yang",
      "Jingdong Wang"
    ],
    "abstract": "The autoregressive world model exhibits robust generalization capabilities in\nvectorized scene understanding but encounters difficulties in deriving actions\ndue to insufficient uncertainty modeling and self-delusion. In this paper, we\nexplore the feasibility of deriving decisions from an autoregressive world\nmodel by addressing these challenges through the formulation of multiple\nprobabilistic hypotheses. We propose LatentDriver, a framework models the\nenvironment's next states and the ego vehicle's possible actions as a mixture\ndistribution, from which a deterministic control signal is then derived. By\nincorporating mixture modeling, the stochastic nature of decisionmaking is\ncaptured. Additionally, the self-delusion problem is mitigated by providing\nintermediate actions sampled from a distribution to the world model.\nExperimental results on the recently released close-loop benchmark Waymax\ndemonstrate that LatentDriver surpasses state-of-the-art reinforcement learning\nand imitation learning methods, achieving expert-level performance. The code\nand models will be made available at\nhttps://github.com/Sephirex-X/LatentDriver.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.15730v1",
    "published_date": "2024-09-24 04:26:24 UTC",
    "updated_date": "2024-09-24 04:26:24 UTC"
  },
  {
    "arxiv_id": "2409.15729v2",
    "title": "Sequential Learning in the Dense Associative Memory",
    "authors": [
      "Hayden McAlister",
      "Anthony Robins",
      "Lech Szymanski"
    ],
    "abstract": "Sequential learning involves learning tasks in a sequence, and proves\nchallenging for most neural networks. Biological neural networks regularly\nconquer the sequential learning challenge and are even capable of transferring\nknowledge both forward and backwards between tasks. Artificial neural networks\noften totally fail to transfer performance between tasks, and regularly suffer\nfrom degraded performance or catastrophic forgetting on previous tasks. Models\nof associative memory have been used to investigate the discrepancy between\nbiological and artificial neural networks due to their biological ties and\ninspirations, of which the Hopfield network is the most studied model. The\nDense Associative Memory (DAM), or modern Hopfield network, generalizes the\nHopfield network, allowing for greater capacities and prototype learning\nbehaviors, while still retaining the associative memory structure. We give a\nsubstantial review of the sequential learning space with particular respect to\nthe Hopfield network and associative memories. We perform foundational\nbenchmarks of sequential learning in the DAM using various sequential learning\ntechniques, and analyze the results of the sequential learning to demonstrate\npreviously unseen transitions in the behavior of the DAM. This paper also\ndiscusses the departure from biological plausibility that may affect the\nutility of the DAM as a tool for studying biological neural networks. We\npresent our findings, including the effectiveness of a range of\nstate-of-the-art sequential learning methods when applied to the DAM, and use\nthese methods to further the understanding of DAM properties and behaviors.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.15729v2",
    "published_date": "2024-09-24 04:23:00 UTC",
    "updated_date": "2025-03-04 21:41:17 UTC"
  },
  {
    "arxiv_id": "2409.15724v1",
    "title": "LLM-Cure: LLM-based Competitor User Review Analysis for Feature Enhancement",
    "authors": [
      "Maram Assi",
      "Safwat Hassan",
      "Ying Zou"
    ],
    "abstract": "The exponential growth of the mobile app market underscores the importance of\nconstant innovation and rapid response to user demands. As user satisfaction is\nparamount to the success of a mobile application (app), developers typically\nrely on user reviews, which represent user feedback that includes ratings and\ncomments to identify areas for improvement. However, the sheer volume of user\nreviews poses challenges in manual analysis, necessitating automated\napproaches. Existing automated approaches either analyze only the target apps\nreviews, neglecting the comparison of similar features to competitors or fail\nto provide suggestions for feature enhancement. To address these gaps, we\npropose a Large Language Model (LLM)-based Competitive User Review Analysis for\nFeature Enhancement) (LLM-Cure), an approach powered by LLMs to automatically\ngenerate suggestion s for mobile app feature improvements. More specifically,\nLLM-Cure identifies and categorizes features within reviews by applying LLMs.\nWhen provided with a complaint in a user review, LLM-Cure curates highly rated\n(4 and 5 stars) reviews in competing apps related to the complaint and proposes\npotential improvements tailored to the target application. We evaluate LLM-Cure\non 1,056,739 reviews of 70 popular Android apps. Our evaluation demonstrates\nthat LLM-Cure significantly outperforms the state-of-the-art approaches in\nassigning features to reviews by up to 13% in F1-score, up to 16% in recall and\nup to 11% in precision. Additionally, LLM-Cure demonstrates its capability to\nprovide suggestions for resolving user complaints. We verify the suggestions\nusing the release notes that reflect the changes of features in the target\nmobile app. LLM-Cure achieves a promising average of 73% of the implementation\nof the provided suggestions.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.SE",
    "comment": "25 pages",
    "pdf_url": "http://arxiv.org/pdf/2409.15724v1",
    "published_date": "2024-09-24 04:17:21 UTC",
    "updated_date": "2024-09-24 04:17:21 UTC"
  },
  {
    "arxiv_id": "2409.15711v2",
    "title": "Adversarial Federated Consensus Learning for Surface Defect Classification Under Data Heterogeneity in IIoT",
    "authors": [
      "Jixuan Cui",
      "Jun Li",
      "Zhen Mei",
      "Yiyang Ni",
      "Wen Chen",
      "Zengxiang Li"
    ],
    "abstract": "The challenge of data scarcity hinders the application of deep learning in\nindustrial surface defect classification (SDC), as it's difficult to collect\nand centralize sufficient training data from various entities in Industrial\nInternet of Things (IIoT) due to privacy concerns. Federated learning (FL)\nprovides a solution by enabling collaborative global model training across\nclients while maintaining privacy. However, performance may suffer due to data\nheterogeneity-discrepancies in data distributions among clients. In this paper,\nwe propose a novel personalized FL (PFL) approach, named Adversarial Federated\nConsensus Learning (AFedCL), for the challenge of data heterogeneity across\ndifferent clients in SDC. First, we develop a dynamic consensus construction\nstrategy to mitigate the performance degradation caused by data heterogeneity.\nThrough adversarial training, local models from different clients utilize the\nglobal model as a bridge to achieve distribution alignment, alleviating the\nproblem of global knowledge forgetting. Complementing this strategy, we propose\na consensus-aware aggregation mechanism. It assigns aggregation weights to\ndifferent clients based on their efficacy in global knowledge learning, thereby\nenhancing the global model's generalization capabilities. Finally, we design an\nadaptive feature fusion module to further enhance global knowledge utilization\nefficiency. Personalized fusion weights are gradually adjusted for each client\nto optimally balance global and local features. Compared with state-of-the-art\nFL methods like FedALA, the proposed AFedCL method achieves an accuracy\nincrease of up to 5.67% on three SDC datasets.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.15711v2",
    "published_date": "2024-09-24 03:59:32 UTC",
    "updated_date": "2024-11-01 03:17:03 UTC"
  },
  {
    "arxiv_id": "2409.15710v1",
    "title": "Autotuning Bipedal Locomotion MPC with GRFM-Net for Efficient Sim-to-Real Transfer",
    "authors": [
      "Qianzhong Chen",
      "Junheng Li",
      "Sheng Cheng",
      "Naira Hovakimyan",
      "Quan Nguyen"
    ],
    "abstract": "Bipedal locomotion control is essential for humanoid robots to navigate\ncomplex, human-centric environments. While optimization-based control designs\nare popular for integrating sophisticated models of humanoid robots, they often\nrequire labor-intensive manual tuning. In this work, we address the challenges\nof parameter selection in bipedal locomotion control using DiffTune, a\nmodel-based autotuning method that leverages differential programming for\nefficient parameter learning. A major difficulty lies in balancing model\nfidelity with differentiability. We address this difficulty using a\nlow-fidelity model for differentiability, enhanced by a Ground Reaction\nForce-and-Moment Network (GRFM-Net) to capture discrepancies between MPC\ncommands and actual control effects. We validate the parameters learned by\nDiffTune with GRFM-Net in hardware experiments, which demonstrates the\nparameters' optimality in a multi-objective setting compared with baseline\nparameters, reducing the total loss by up to 40.5$\\%$ compared with the\nexpert-tuned parameters. The results confirm the GRFM-Net's effectiveness in\nmitigating the sim-to-real gap, improving the transferability of\nsimulation-learned parameters to real hardware.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.15710v1",
    "published_date": "2024-09-24 03:58:18 UTC",
    "updated_date": "2024-09-24 03:58:18 UTC"
  },
  {
    "arxiv_id": "2409.15706v1",
    "title": "Improving Emotional Support Delivery in Text-Based Community Safety Reporting Using Large Language Models",
    "authors": [
      "Yiren Liu",
      "Yerong Li",
      "Ryan Mayfield",
      "Yun Huang"
    ],
    "abstract": "Emotional support is a crucial aspect of communication between community\nmembers and police dispatchers during incident reporting. However, there is a\nlack of understanding about how emotional support is delivered through\ntext-based systems, especially in various non-emergency contexts. In this\nstudy, we analyzed two years of chat logs comprising 57,114 messages across\n8,239 incidents from 130 higher education institutions. Our empirical findings\nrevealed significant variations in emotional support provided by dispatchers,\ninfluenced by the type of incident, service time, and a noticeable decline in\nsupport over time across multiple organizations. To improve the consistency and\nquality of emotional support, we developed and implemented a fine-tuned Large\nLanguage Model (LLM), named dispatcherLLM. We evaluated dispatcherLLM by\ncomparing its generated responses to those of human dispatchers and other\noff-the-shelf models using real chat messages. Additionally, we conducted a\nhuman evaluation to assess the perceived effectiveness of the support provided\nby dispatcherLLM. This study not only contributes new empirical understandings\nof emotional support in text-based dispatch systems but also demonstrates the\nsignificant potential of generative AI in improving service delivery.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.15706v1",
    "published_date": "2024-09-24 03:47:02 UTC",
    "updated_date": "2024-09-24 03:47:02 UTC"
  },
  {
    "arxiv_id": "2409.15697v1",
    "title": "dnaGrinder: a lightweight and high-capacity genomic foundation model",
    "authors": [
      "Qihang Zhao",
      "Chi Zhang",
      "Weixiong Zhang"
    ],
    "abstract": "The task of understanding and interpreting the complex information encoded\nwithin genomic sequences remains a grand challenge in biological research and\nclinical applications. In this context, recent advancements in large language\nmodel research have led to the development of both encoder-only and\ndecoder-only foundation models designed to decode intricate information in DNA\nsequences. However, several issues persist, particularly regarding the\nefficient management of long-range dependencies inherent in genomic sequences,\nthe effective representation of nucleotide variations, and the considerable\ncomputational costs associated with large model architectures and extensive\npretraining datasets. Current genomic foundation models often face a critical\ntradeoff: smaller models with mediocre performance versus large models with\nimproved performance. To address these challenges, we introduce dnaGrinder, a\nunique and efficient genomic foundation model. dnaGrinder excels at managing\nlong-range dependencies within genomic sequences while minimizing computational\ncosts without compromising performance. It achieves results that are not just\ncomparable but often superior to leading DNA models such as Nucleotide\nTransformer and DNABERT-2. Furthermore, dnaGrinder is designed for easy\nfine-tuning on workstation-grade GPUs, accommodating input lengths exceeding\n17,000 tokens. On a single high-performance GPU, it supports sequences longer\nthan 140,000 tokens, making it a highly efficient and accessible tool for both\nbasic biological research and clinical applications.",
    "categories": [
      "q-bio.GN",
      "cs.AI",
      "cs.CE",
      "cs.CL"
    ],
    "primary_category": "q-bio.GN",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.15697v1",
    "published_date": "2024-09-24 03:20:07 UTC",
    "updated_date": "2024-09-24 03:20:07 UTC"
  },
  {
    "arxiv_id": "2409.15695v1",
    "title": "Toward Mixture-of-Experts Enabled Trustworthy Semantic Communication for 6G Networks",
    "authors": [
      "Jiayi He",
      "Xiaofeng Luo",
      "Jiawen Kang",
      "Hongyang Du",
      "Zehui Xiong",
      "Ci Chen",
      "Dusit Niyato",
      "Xuemin Shen"
    ],
    "abstract": "Semantic Communication (SemCom) plays a pivotal role in 6G networks, offering\na viable solution for future efficient communication. Deep Learning (DL)-based\nsemantic codecs further enhance this efficiency. However, the vulnerability of\nDL models to security threats, such as adversarial attacks, poses significant\nchallenges for practical applications of SemCom systems. These vulnerabilities\nenable attackers to tamper with messages and eavesdrop on private information,\nespecially in wireless communication scenarios. Although existing defenses\nattempt to address specific threats, they often fail to simultaneously handle\nmultiple heterogeneous attacks. To overcome this limitation, we introduce a\nnovel Mixture-of-Experts (MoE)-based SemCom system. This system comprises a\ngating network and multiple experts, each specializing in different security\nchallenges. The gating network adaptively selects suitable experts to counter\nheterogeneous attacks based on user-defined security requirements. Multiple\nexperts collaborate to accomplish semantic communication tasks while meeting\nthe security requirements of users. A case study in vehicular networks\ndemonstrates the efficacy of the MoE-based SemCom system. Simulation results\nshow that the proposed MoE-based SemCom system effectively mitigates concurrent\nheterogeneous attacks, with minimal impact on downstream task accuracy.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.NI",
    "comment": "8 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.15695v1",
    "published_date": "2024-09-24 03:17:51 UTC",
    "updated_date": "2024-09-24 03:17:51 UTC"
  },
  {
    "arxiv_id": "2409.15688v2",
    "title": "Safe Navigation for Robotic Digestive Endoscopy via Human Intervention-based Reinforcement Learning",
    "authors": [
      "Min Tan",
      "Yushun Tao",
      "Boyun Zheng",
      "GaoSheng Xie",
      "Lijuan Feng",
      "Zeyang Xia",
      "Jing Xiong"
    ],
    "abstract": "With the increasing application of automated robotic digestive endoscopy\n(RDE), ensuring safe and efficient navigation in the unstructured and narrow\ndigestive tract has become a critical challenge. Existing automated\nreinforcement learning navigation algorithms often result in potentially risky\ncollisions due to the absence of essential human intervention, which\nsignificantly limits the safety and effectiveness of RDE in actual clinical\npractice. To address this limitation, we proposed a Human Intervention\n(HI)-based Proximal Policy Optimization (PPO) framework, dubbed HI-PPO, which\nincorporates expert knowledge to enhance RDE's safety. Specifically, HI-PPO\ncombines Enhanced Exploration Mechanism (EEM), Reward-Penalty Adjustment (RPA),\nand Behavior Cloning Similarity (BCS) to address PPO's exploration\ninefficiencies for safe navigation in complex gastrointestinal environments.\nComparative experiments were conducted on a simulation platform, and the\nresults showed that HI-PPO achieved a mean ATE (Average Trajectory Error) of\n\\(8.02\\ \\text{mm}\\) and a Security Score of \\(0.862\\), demonstrating\nperformance comparable to human experts. The code will be publicly available\nonce this paper is published.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.15688v2",
    "published_date": "2024-09-24 03:01:30 UTC",
    "updated_date": "2025-03-30 04:42:35 UTC"
  },
  {
    "arxiv_id": "2409.15687v1",
    "title": "A Comprehensive Evaluation of Large Language Models on Mental Illnesses",
    "authors": [
      "Abdelrahman Hanafi",
      "Mohammed Saad",
      "Noureldin Zahran",
      "Radwa J. Hanafy",
      "Mohammed E. Fouda"
    ],
    "abstract": "Large language models have shown promise in various domains, including\nhealthcare. In this study, we conduct a comprehensive evaluation of LLMs in the\ncontext of mental health tasks using social media data. We explore the\nzero-shot (ZS) and few-shot (FS) capabilities of various LLMs, including GPT-4,\nLlama 3, Gemini, and others, on tasks such as binary disorder detection,\ndisorder severity evaluation, and psychiatric knowledge assessment. Our\nevaluation involved 33 models testing 9 main prompt templates across the tasks.\nKey findings revealed that models like GPT-4 and Llama 3 exhibited superior\nperformance in binary disorder detection, with accuracies reaching up to 85% on\ncertain datasets. Moreover, prompt engineering played a crucial role in\nenhancing model performance. Notably, the Mixtral 8x22b model showed an\nimprovement of over 20%, while Gemma 7b experienced a similar boost in\nperformance. In the task of disorder severity evaluation, we observed that FS\nlearning significantly improved the model's accuracy, highlighting the\nimportance of contextual examples in complex assessments. Notably, the\nPhi-3-mini model exhibited a substantial increase in performance, with balanced\naccuracy improving by over 6.80% and mean average error dropping by nearly 1.3\nwhen moving from ZS to FS learning. In the psychiatric knowledge task, recent\nmodels generally outperformed older, larger counterparts, with the Llama 3.1\n405b achieving an accuracy of 91.2%. Despite promising results, our analysis\nidentified several challenges, including variability in performance across\ndatasets and the need for careful prompt engineering. Furthermore, the ethical\nguards imposed by many LLM providers hamper the ability to accurately evaluate\ntheir performance, due to tendency to not respond to potentially sensitive\nqueries.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.15687v1",
    "published_date": "2024-09-24 02:58:52 UTC",
    "updated_date": "2024-09-24 02:58:52 UTC"
  },
  {
    "arxiv_id": "2410.07194v1",
    "title": "Technical Report: Competition Solution For Modelscope-Sora",
    "authors": [
      "Shengfu Chen",
      "Hailong Liu",
      "Wenzhao Wei"
    ],
    "abstract": "This report presents the approach adopted in the Modelscope-Sora challenge,\nwhich focuses on fine-tuning data for video generation models. The challenge\nevaluates participants' ability to analyze, clean, and generate high-quality\ndatasets for video-based text-to-video tasks under specific computational\nconstraints. The provided methodology involves data processing techniques such\nas video description generation, filtering, and acceleration. This report\noutlines the procedures and tools utilized to enhance the quality of training\ndata, ensuring improved performance in text-to-video generation models.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.07194v1",
    "published_date": "2024-09-24 02:45:09 UTC",
    "updated_date": "2024-09-24 02:45:09 UTC"
  },
  {
    "arxiv_id": "2409.15664v1",
    "title": "Mitigating Semantic Leakage in Cross-lingual Embeddings via Orthogonality Constraint",
    "authors": [
      "Dayeon Ki",
      "Cheonbok Park",
      "Hyunjoong Kim"
    ],
    "abstract": "Accurately aligning contextual representations in cross-lingual sentence\nembeddings is key for effective parallel data mining. A common strategy for\nachieving this alignment involves disentangling semantics and language in\nsentence embeddings derived from multilingual pre-trained models. However, we\ndiscover that current disentangled representation learning methods suffer from\nsemantic leakage - a term we introduce to describe when a substantial amount of\nlanguage-specific information is unintentionally leaked into semantic\nrepresentations. This hinders the effective disentanglement of semantic and\nlanguage representations, making it difficult to retrieve embeddings that\ndistinctively represent the meaning of the sentence. To address this challenge,\nwe propose a novel training objective, ORthogonAlity Constraint LEarning\n(ORACLE), tailored to enforce orthogonality between semantic and language\nembeddings. ORACLE builds upon two components: intra-class clustering and\ninter-class separation. Through experiments on cross-lingual retrieval and\nsemantic textual similarity tasks, we demonstrate that training with the ORACLE\nobjective effectively reduces semantic leakage and enhances semantic alignment\nwithin the embedding space.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "18 pages, 16 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.15664v1",
    "published_date": "2024-09-24 02:01:52 UTC",
    "updated_date": "2024-09-24 02:01:52 UTC"
  },
  {
    "arxiv_id": "2409.15662v1",
    "title": "Double-Path Adaptive-correlation Spatial-Temporal Inverted Transformer for Stock Time Series Forecasting",
    "authors": [
      "Wenbo Yan",
      "Ying Tan"
    ],
    "abstract": "Spatial-temporal graph neural networks (STGNNs) have achieved significant\nsuccess in various time series forecasting tasks. However, due to the lack of\nexplicit and fixed spatial relationships in stock prediction tasks, many STGNNs\nfail to perform effectively in this domain. While some STGNNs learn spatial\nrelationships from time series, they often lack comprehensiveness. Research\nindicates that modeling time series using feature changes as tokens reveals\nentirely different information compared to using time steps as tokens. To more\ncomprehensively extract dynamic spatial information from stock data, we propose\na Double-Path Adaptive-correlation Spatial-Temporal Inverted Transformer\n(DPA-STIFormer). DPA-STIFormer models each node via continuous changes in\nfeatures as tokens and introduces a Double Direction Self-adaptation Fusion\nmechanism. This mechanism decomposes node encoding into temporal and feature\nrepresentations, simultaneously extracting different spatial correlations from\na double path approach, and proposes a Double-path gating mechanism to fuse\nthese two types of correlation information. Experiments conducted on four stock\nmarket datasets demonstrate state-of-the-art results, validating the model's\nsuperior capability in uncovering latent temporal-correlation patterns.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.15662v1",
    "published_date": "2024-09-24 01:53:22 UTC",
    "updated_date": "2024-09-24 01:53:22 UTC"
  },
  {
    "arxiv_id": "2409.15658v2",
    "title": "Long-horizon Embodied Planning with Implicit Logical Inference and Hallucination Mitigation",
    "authors": [
      "Siyuan Liu",
      "Jiawei Du",
      "Sicheng Xiang",
      "Zibo Wang",
      "Dingsheng Luo"
    ],
    "abstract": "Long-horizon embodied planning underpins embodied AI. To accomplish\nlong-horizon tasks, one of the most feasible ways is to decompose abstract\ninstructions into a sequence of actionable steps. Foundation models still face\nlogical errors and hallucinations in long-horizon planning, unless provided\nwith highly relevant examples to the tasks. However, providing highly relevant\nexamples for any random task is unpractical. Therefore, we present ReLEP, a\nnovel framework for Real-time Long-horizon Embodied Planning. ReLEP can\ncomplete a wide range of long-horizon tasks without in-context examples by\nlearning implicit logical inference through fine-tuning. The fine-tuned large\nvision-language model formulates plans as sequences of skill functions. These\nfunctions are selected from a carefully designed skill library. ReLEP is also\nequipped with a Memory module for plan and status recall, and a Robot\nConfiguration module for versatility across robot types. In addition, we\npropose a data generation pipeline to tackle dataset scarcity. When\nconstructing the dataset, we considered the implicit logical relationships,\nenabling the model to learn implicit logical relationships and dispel\nhallucinations. Through comprehensive evaluations across various long-horizon\ntasks, ReLEP demonstrates high success rates and compliance to execution even\non unseen tasks and outperforms state-of-the-art baseline methods.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.15658v2",
    "published_date": "2024-09-24 01:47:23 UTC",
    "updated_date": "2025-03-13 10:15:59 UTC"
  },
  {
    "arxiv_id": "2409.15657v4",
    "title": "M$^2$PT: Multimodal Prompt Tuning for Zero-shot Instruction Learning",
    "authors": [
      "Taowen Wang",
      "Yiyang Liu",
      "James Chenhao Liang",
      "junhan zhao",
      "Yiming Cui",
      "Yuning Mao",
      "Shaoliang Nie",
      "Jiahao Liu",
      "Fuli Feng",
      "Zenglin Xu",
      "Cheng Han",
      "Lifu Huang",
      "Qifan Wang",
      "Dongfang Liu"
    ],
    "abstract": "Multimodal Large Language Models (MLLMs) demonstrate remarkable performance\nacross a wide range of domains, with increasing emphasis on enhancing their\nzero-shot generalization capabilities for unseen tasks across various\nmodalities. Instruction tuning has emerged as an effective strategy for\nachieving zero-shot generalization by finetuning pretrained models on diverse\nmultimodal tasks. As the scale of MLLMs continues to grow, parameter-efficient\nfinetuning becomes increasingly critical. However, most existing\nparameter-efficient approaches focus only on single modalities and often\noverlook the multimodal characteristics during finetuning. In this work, we\nintroduce a novel Multimodal Prompt Tuning (M$^2$PT) approach for efficient\ninstruction tuning of MLLMs. M$^2$PT effectively integrates visual and textual\nprompts into the vision encoder and language processor respectively during\nfinetuning, facilitating the extraction and alignment of features across\nmodalities. Empirical results on various multimodal evaluation datasets\ndemonstrate the superior performance of our approach compared to several\nstate-of-the-art baselines. A comprehensive set of ablation studies validates\nthe effectiveness of our prompt design and the efficiency of our approach.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "EMNLP 2024",
    "pdf_url": "http://arxiv.org/pdf/2409.15657v4",
    "published_date": "2024-09-24 01:40:24 UTC",
    "updated_date": "2024-10-30 04:38:52 UTC"
  },
  {
    "arxiv_id": "2409.15637v2",
    "title": "Synatra: Turning Indirect Knowledge into Direct Demonstrations for Digital Agents at Scale",
    "authors": [
      "Tianyue Ou",
      "Frank F. Xu",
      "Aman Madaan",
      "Jiarui Liu",
      "Robert Lo",
      "Abishek Sridhar",
      "Sudipta Sengupta",
      "Dan Roth",
      "Graham Neubig",
      "Shuyan Zhou"
    ],
    "abstract": "LLMs can now act as autonomous agents that interact with digital environments\nand complete specific objectives (e.g., arranging an online meeting). However,\naccuracy is still far from satisfactory, partly due to a lack of large-scale,\ndirect demonstrations for digital tasks. Obtaining supervised data from humans\nis costly, and automatic data collection through exploration or reinforcement\nlearning relies on complex environmental and content setup, resulting in\ndatasets that lack comprehensive coverage of various scenarios. On the other\nhand, there is abundant knowledge that may indirectly assist task completion,\nsuch as online tutorials that were created for human consumption. In this work,\nwe present Synatra, an approach that effectively transforms this indirect\nknowledge into direct supervision at scale. We define different types of\nindirect knowledge, and carefully study the available sources to obtain it,\nmethods to encode the structure of direct demonstrations, and finally methods\nto transform indirect knowledge into direct demonstrations. We use 100k such\nsynthetically-created demonstrations to finetune a 7B CodeLlama, and\ndemonstrate that the resulting agent surpasses all comparably sized models on\nthree web-based task benchmarks Mind2Web, MiniWoB++ and WebArena, as well as\nsurpassing GPT-3.5 on WebArena and Mind2Web. In addition, while synthetic\ndemonstrations prove to be only 3% the cost of human demonstrations (at $0.031\neach), we show that the synthetic demonstrations can be more effective than an\nidentical number of human demonstrations collected from limited domains.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.15637v2",
    "published_date": "2024-09-24 00:51:45 UTC",
    "updated_date": "2024-11-27 16:34:52 UTC"
  },
  {
    "arxiv_id": "2409.15636v1",
    "title": "Personalized Federated Learning via Backbone Self-Distillation",
    "authors": [
      "Pengju Wang",
      "Bochao Liu",
      "Dan Zeng",
      "Chenggang Yan",
      "Shiming Ge"
    ],
    "abstract": "In practical scenarios, federated learning frequently necessitates training\npersonalized models for each client using heterogeneous data. This paper\nproposes a backbone self-distillation approach to facilitate personalized\nfederated learning. In this approach, each client trains its local model and\nonly sends the backbone weights to the server. These weights are then\naggregated to create a global backbone, which is returned to each client for\nupdating. However, the client's local backbone lacks personalization because of\nthe common representation. To solve this problem, each client further performs\nbackbone self-distillation by using the global backbone as a teacher and\ntransferring knowledge to update the local backbone. This process involves\nlearning two components: the shared backbone for common representation and the\nprivate head for local personalization, which enables effective global\nknowledge transfer. Extensive experiments and comparisons with 12\nstate-of-the-art approaches demonstrate the effectiveness of our approach.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "Pubished in ACM MMAsia 2023",
    "pdf_url": "http://arxiv.org/pdf/2409.15636v1",
    "published_date": "2024-09-24 00:43:16 UTC",
    "updated_date": "2024-09-24 00:43:16 UTC"
  },
  {
    "arxiv_id": "2409.15631v3",
    "title": "Data Augmentation for Sparse Multidimensional Learning Performance Data Using Generative AI",
    "authors": [
      "Liang Zhang",
      "Jionghao Lin",
      "John Sabatini",
      "Conrad Borchers",
      "Daniel Weitekamp",
      "Meng Cao",
      "John Hollander",
      "Xiangen Hu",
      "Arthur C. Graesser"
    ],
    "abstract": "Learning performance data describe correct and incorrect answers or\nproblem-solving attempts in adaptive learning, such as in intelligent tutoring\nsystems (ITSs). Learning performance data tend to be highly sparse\n(80\\%\\(\\sim\\)90\\% missing observations) in most real-world applications due to\nadaptive item selection. This data sparsity presents challenges to using\nlearner models to effectively predict future performance explore new hypotheses\nabout learning. This article proposes a systematic framework for augmenting\nlearner data to address data sparsity in learning performance data. First,\nlearning performance is represented as a three-dimensional tensor of learners'\nquestions, answers, and attempts, capturing longitudinal knowledge states\nduring learning. Second, a tensor factorization method is used to impute\nmissing values in sparse tensors of collected learner data, thereby grounding\nthe imputation on knowledge tracing tasks that predict missing performance\nvalues based on real observations. Third, a module for generating patterns of\nlearning is used. This study contrasts two forms of generative Artificial\nIntelligence (AI), including Generative Adversarial Networks (GANs) and\nGenerate Pre-Trained Transformers (GPT) to generate data associated with\ndifferent clusters of learner data. We tested this approach on an adult\nliteracy dataset from AutoTutor lessons developed for Adult Reading\nComprehension (ARC). We found that: (1) tensor factorization improved the\nperformance in tracing and predicting knowledge mastery compared with other\nknowledge tracing techniques without data augmentation, showing higher relative\nfidelity for this imputation method, and (2) the GAN-based simulation showed\ngreater overall stability and less statistical bias based on a divergence\nevaluation with varying simulation sample sizes compared to GPT.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.15631v3",
    "published_date": "2024-09-24 00:25:07 UTC",
    "updated_date": "2025-01-03 23:27:26 UTC"
  }
]