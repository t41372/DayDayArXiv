{
  "date": "2024-09-24",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-09-24 的 arXiv 中文 TLDR 快报！今天 arXiv 更新了 123 篇论文，主要聚焦 AI 模型优化、LLM 在医疗和教育中的应用、计算机视觉、机器人规划等领域，其中 LLM 在安全和交互场景的创新（如第 11 篇的 HAICOSYSTEM）和机器人导航进展（如第 1 篇）令人印象深刻；有名学者如 Yejin Choi（第 11 篇）和 Hector Geffner（第 39 篇）参与的相关工作值得关注。\n\n下面，我将挑选并简要讨论部分重要、话题度高的论文，先从 AI 和 LLM 应用入手，再聊机器人和视觉领域，其他论文如医疗或数据处理方向的则快速掠过，以控制篇幅。每个条目列出论文标题（中文 + 英文），并聚焦核心贡献。\n\n### AI 和 LLM 应用：重点讨论创新性高、实际影响大的论文\n- **HAICOSYSTEM: An Ecosystem for Sandboxing Safety Risks in Human-AI Interactions**（中文：HAICOSYSTEM：用于模拟人类-AI 交互安全风险的生态系统；英文：HAICOSYSTEM: An Ecosystem for Sandboxing Safety Risks in Human-AI Interactions）。这篇论文提出一个模块化沙盒框架，用于模拟 AI 代理在社会交互中的安全风险，通过多维度评估（如操作和内容风险）来测试 LLM 在医疗等领域的鲁棒性，主要贡献是揭示了 LLM 在面对恶意用户时的 50% 以上风险，并提供开源平台促进研究。\n  \n- **Unsupervised Text Representation Learning via Instruction-Tuning for Zero-Shot Dense Retrieval**（中文：通过指令微调的无监督文本表示学习，用于零样本密集检索；英文：Unsupervised Text Representation Learning via Instruction-Tuning for Zero-Shot Dense Retrieval）。论文引入一种无监督方法，使用指令调优 LLM 生成合成查询，提升零样本检索性能，贡献包括在多个数据集上提升 NDCG@10 指标 3.34%，并证明小模型可超越更大基线。\n\n- **Lessons and Insights from a Unifying Study of Parameter-Efficient Fine-Tuning (PEFT) in Visual Recognition**（中文：参数高效微调在视觉识别中的统一研究教训和洞见；英文：Lessons and Insights from a Unifying Study of Parameter-Efficient Fine-Tuning (PEFT) in Visual Recognition）。这篇讨论 PEFT 在视觉任务中的表现，作者包括知名学者 Wei-Lun Chao，关键发现是 PEFT 方法在低样本任务中表现类似但互补，可通过集成提升准确率，并在多样本场景下节省参数。\n\n- **A Comprehensive Survey of Bias in LLMs: Current Landscape and Future Directions**（中文：LLM 中偏差的全面调查：当前状况和未来方向；英文：A Comprehensive Survey of Bias in LLMs: Current Landscape and Future Directions）。论文系统梳理 LLM 中的偏差类型、来源和缓解策略，贡献在于提出未来研究方向，如公平性增强，强调偏差可能影响实际应用。\n\n- **Task-oriented Prompt Enhancement via Script Generation**（中文：通过脚本生成的任务导向提示增强；英文：Task-oriented Prompt Enhancement via Script Generation）。论文开发 TITAN 框架，使用零样本学习生成脚本增强 LLM 提示，核心发现是它在多种任务上比基线提升 7.6%，无需手动注解。\n\n其他 LLM 相关论文如第 9、13、14、21、41 等较多，但它们聚焦具体应用（如偏差缓解或代码生成），这里快速掠过：这些工作总体提升了 LLM 的鲁棒性和泛化，但需注意潜在安全风险。\n\n### 机器人和规划：强调实际应用和高效算法\n- **Center-fixing of tropical cyclones using uncertainty-aware deep learning applied to high-temporal-resolution geostationary satellite imagery**（中文：使用不确定性感知深度学习定位热带气旋中心；英文：Center-fixing of tropical cyclones using uncertainty-aware deep learning applied to high-temporal-resolution geostationary satellite imagery）。论文提出 GeoCenter 算法，利用红外卫星图像实现气旋中心定位，贡献包括误差低于传统方法（均方根误差 26.6 km），并提供实时不确定性量化，适用于气象预报。\n\n- **Articulated Object Manipulation using Online Axis Estimation with SAM2-Based Tracking**（中文：使用 SAM2 跟踪的在线轴估计进行铰接物体操作；英文：Articulated Object Manipulation using Online Axis Estimation with SAM2-Based Tracking）。这篇工作集成交互感知和轴估计，显著提升机器人对复杂物体的操作精度，核心发现是模拟实验中比基线方法提高 30% 以上性能。\n\n- **Planning in the Dark: LLM-Symbolic Planning Pipeline without Experts**（中文：黑暗中的规划：无专家的 LLM-符号规划管道；英文：Planning in the Dark: LLM-Symbolic Planning Pipeline without Experts）。作者包括知名学者 Hector Geffner，论文探索 LLM 在机器人规划中的作用，贡献在于无需专家干预即可生成可靠计划，实验显示在未见任务上优于基线。\n\n其他机器人论文如第 17、39、51 等涉及强化学习规划，这里简要：这些方法提升了机器人适应性，但受限于环境复杂性。\n\n### 计算机视觉和图像处理：挑选高影响力的创新\n- **GSplatLoc: Grounding Keypoint Descriptors into 3D Gaussian Splatting for Improved Visual Localization**（中文：将关键点描述符嵌入 3D 高斯散斑以提升视觉定位；英文：GSplatLoc: Grounding Keypoint Descriptors into 3D Gaussian Splatting for Improved Visual Localization）。论文提出两阶段方法，将关键点描述符集成到 3D 高斯散斑中，贡献包括在室内外数据集上优于 NeRFMatch，提升定位准确性。\n\n- **Fields of The World: A Machine Learning Benchmark Dataset For Global Agricultural Field Boundary Segmentation**（中文：全球农业田界分割的机器学习基准数据集；英文：Fields of The World: A Machine Learning Benchmark Dataset For Global Agricultural Field Boundary Segmentation）。论文发布大规模数据集（70k 样本），用于农业田界分割，核心发现是模型在零样本场景下表现更强，支持全球农业监测。\n\n其他视觉论文如第 8、10、20 等众多，这里快速掠过：它们推进了图像解释和分割技术，但多数聚焦特定应用，如异常检测。\n\n### 其他领域：快速概述，限于篇幅不深挖\n剩余论文如第 4（药物抑制剂预测）、第 7（AI 在智能城市的安全）、第 15（记忆网络）、第 18（多模态 AI 在教育）、第 22（医疗成像隐私）、第 24（规则学习）、第 25（偏好模拟）、第 27（区块链与强化学习）、第 30（基准数据集）等，涉及医疗、数据管理和教育AI，但影响力相对有限。主要贡献包括提升 AI 的泛化性和隐私保护，例如第 22 篇提出联邦学习结合不确定性量化以保护医疗数据隐私。\n\n总之，今天的论文突出了 AI 在实际应用中的潜力，尤其在 LLM 和机器人领域，但也暴露了安全和泛化挑战。感兴趣的读者可关注上述关键工作，更多细节请查阅 arXiv。明天的快报再见！",
  "papers": [
    {
      "arxiv_id": "2409.16507v2",
      "title": "Center-fixing of tropical cyclones using uncertainty-aware deep learning applied to high-temporal-resolution geostationary satellite imagery",
      "title_zh": "热带",
      "authors": [
        "Ryan Lagerquist",
        "Galina Chirokova",
        "Robert DeMaria",
        "Mark DeMaria",
        "Imme Ebert-Uphoff"
      ],
      "abstract": "Determining the location of a tropical cyclone's (TC) surface circulation\ncenter -- \"center-fixing\" -- is a critical first step in the TC-forecasting\nprocess, affecting current and future estimates of track, intensity, and\nstructure. Despite a recent increase in automated center-fixing methods, only\none such method (ARCHER-2) is operational, and its best performance is achieved\nwhen using microwave or scatterometer data, which are not available at every\nforecast cycle. We develop a deep-learning algorithm called GeoCenter; besides\na few scalars in the operational ATCF, it relies only on geostationary IR\nsatellite imagery, which is available for all TC basins at high frequency (10\nmin) and low latency (< 10 min) during both day and night. GeoCenter ingests an\nanimation (time series) of IR images, including 9 channels at lag times up to 4\nhours. The animation is centered at a \"first guess\" location, offset from the\ntrue TC-center location by 48 km on average and sometimes > 100 km; GeoCenter\nis tasked with correcting this offset. On an independent testing dataset,\nGeoCenter achieves a mean/median/RMS (root mean square) error of 26.6/22.2/32.4\nkm for all systems, 24.7/20.8/30.0 km for tropical systems, and 14.6/12.5/17.3\nkm for category-2--5 hurricanes. These values are similar to ARCHER-2 errors\nwith microwave or scatterometer data, and better than ARCHER-2 errors when only\nIR data are available. GeoCenter also performs skillful uncertainty\nquantification, producing a well calibrated ensemble of 150 TC-center\nlocations. Furthermore, all predictors used by GeoCenter are available in real\ntime, which would make GeoCenter easy to implement operationally every 10 min.",
      "tldr_zh": "这篇论文开发了 GeoCenter，一种不确定性感知深度学习算法，用于热带气旋（TC）的中心定位（center-fixing），仅依赖高时间分辨率的地基红外（IR）卫星图像，避免了对微波或散射仪数据的依赖。GeoCenter 通过处理 IR 图像序列（包括9个通道，延迟至4小时）来修正初始位置偏移，在测试数据集上实现了平均/中位数/RMS 错误分别为26.6/22.2/32.4 km，并针对热带系统和2-5级飓风表现出色，与 ARCHER-2 方法相当或更优。算法还提供校准的不确定性量化（如150个 TC 中心位置的集合），并支持实时操作，每10分钟即可实施。",
      "categories": [
        "physics.ao-ph",
        "cs.AI"
      ],
      "primary_category": "physics.ao-ph",
      "comment": "Submitted to AMS journal Weather and Forecasting. Main body is 64\n  pages and 17 figures; supplement is another 33 pages and 31 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.16507v2",
      "published_date": "2024-09-24 23:39:56 UTC",
      "updated_date": "2025-04-08 18:34:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:01:16.116942"
    },
    {
      "arxiv_id": "2409.16502v3",
      "title": "GSplatLoc: Grounding Keypoint Descriptors into 3D Gaussian Splatting for Improved Visual Localization",
      "title_zh": "翻译失败",
      "authors": [
        "Gennady Sidorov",
        "Malik Mohrat",
        "Denis Gridusov",
        "Ruslan Rakhimov",
        "Sergey Kolyubin"
      ],
      "abstract": "Although various visual localization approaches exist, such as scene\ncoordinate regression and camera pose regression, these methods often struggle\nwith optimization complexity or limited accuracy. To address these challenges,\nwe explore the use of novel view synthesis techniques, particularly 3D Gaussian\nSplatting (3DGS), which enables the compact encoding of both 3D geometry and\nscene appearance. We propose a two-stage procedure that integrates dense and\nrobust keypoint descriptors from the lightweight XFeat feature extractor into\n3DGS, enhancing performance in both indoor and outdoor environments. The coarse\npose estimates are directly obtained via 2D-3D correspondences between the 3DGS\nrepresentation and query image descriptors. In the second stage, the initial\npose estimate is refined by minimizing the rendering-based photometric warp\nloss. Benchmarking on widely used indoor and outdoor datasets demonstrates\nimprovements over recent neural rendering-based localization methods, such as\nNeRFMatch and PNeRFLoc.",
      "tldr_zh": "本文提出GSplatLoc框架，以解决现有视觉定位方法（如场景坐标回归和相机姿态回归）的优化复杂性和准确性问题，通过将密集鲁棒的关键点描述符从轻量级XFeat特征提取器整合到3D Gaussian Splatting (3DGS)中，实现对3D几何和场景外观的紧凑编码。框架采用两阶段过程：首先通过2D-3D对应关系从3DGS表示和查询图像描述符中获得粗略姿态估计，其次通过最小化基于渲染的光度扭曲损失（photometric warp loss）进行细化。在广泛的室内和室外数据集上基准测试表明，GSplatLoc比NeRFMatch和PNeRFLoc等神经渲染定位方法表现出显著改进。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "Project website at https://gsplatloc.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2409.16502v3",
      "published_date": "2024-09-24 23:18:32 UTC",
      "updated_date": "2025-03-20 12:57:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:01:26.514831"
    },
    {
      "arxiv_id": "2409.16497v1",
      "title": "Unsupervised Text Representation Learning via Instruction-Tuning for Zero-Shot Dense Retrieval",
      "title_zh": "翻译失败",
      "authors": [
        "Qiuhai Zeng",
        "Zimeng Qiu",
        "Dae Yon Hwang",
        "Xin He",
        "William M. Campbell"
      ],
      "abstract": "Dense retrieval systems are commonly used for information retrieval (IR).\nThey rely on learning text representations through an encoder and usually\nrequire supervised modeling via labelled data which can be costly to obtain or\nsimply unavailable. In this study, we introduce a novel unsupervised text\nrepresentation learning technique via instruction-tuning the pre-trained\nencoder-decoder large language models (LLM) under the dual-encoder retrieval\nframework. We demonstrate the corpus representation can be augmented by the\nrepresentations of relevant synthetic queries generated by the instruct-tuned\nLLM founded on the Rao-Blackwell theorem. Furthermore, we effectively align the\nquery and corpus text representation with self-instructed-tuning. Specifically,\nwe first prompt an open-box pre-trained LLM to follow defined instructions\n(i.e. question generation and keyword summarization) to generate synthetic\nqueries. Next, we fine-tune the pre-trained LLM with defined instructions and\nthe generated queries that passed quality check. Finally, we generate synthetic\nqueries with the instruction-tuned LLM for each corpora and represent each\ncorpora by weighted averaging the synthetic queries and original corpora\nembeddings. We evaluate our proposed method under low-resource settings on\nthree English and one German retrieval datasets measuring NDCG@10, MRR@100,\nRecall@100. We significantly improve the average zero-shot retrieval\nperformance on all metrics, increasing open-box FLAN-T5 model variations by\n[3.34%, 3.50%] in absolute and exceeding three competitive dense retrievers\n(i.e. mDPR, T-Systems, mBART-Large), with model of size at least 38% smaller,\nby 1.96%, 4.62%, 9.52% absolute on NDCG@10.",
      "tldr_zh": "这篇论文提出了一种无监督文本表示学习方法，通过 Instruction-Tuning 预训练的编码器-解码器大语言模型（LLM）来实现 Zero-Shot Dense Retrieval，避免了对标记数据的依赖。方法利用双编码器检索框架生成合成查询（如问题生成和关键词总结），并基于 Rao-Blackwell Theorem 增强语料表示，同时通过自指令微调（self-instructed-tuning）对齐查询和语料嵌入。实验结果显示，在低资源设置下的三个英语和一个德语数据集上，该方法显著提升了检索性能，在 NDCG@10 等指标上比 FLAN-T5 模型提高了 [3.34%, 3.50%]，并超过了 mDPR、T-Systems 和 mBART-Large 等竞争模型，同时模型大小至少小 38%。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at DCAI24 workshop@CIKM2024",
      "pdf_url": "http://arxiv.org/pdf/2409.16497v1",
      "published_date": "2024-09-24 23:03:13 UTC",
      "updated_date": "2024-09-24 23:03:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:01:50.209786"
    },
    {
      "arxiv_id": "2409.16486v1",
      "title": "To Explore the Potential Inhibitors against Multitarget Proteins of COVID 19 using In Silico Study",
      "title_zh": "翻译失败",
      "authors": [
        "Imra Aqeel"
      ],
      "abstract": "The global pandemic due to emergence of COVID 19 has created the unrivaled\npublic health crisis. It has huge morbidity rate never comprehended in the\nrecent decades. Researchers have made many efforts to find the optimal solution\nof this pandemic. Progressively, drug repurposing is an emergent and powerful\nstrategy with saving cost, time, and labor. Lacking of identified repurposed\ndrug candidates against COVID 19 demands more efforts to explore the potential\ninhibitors for effective cure. In this study, we used the combination of\nmolecular docking and machine learning regression approaches to explore the\npotential inhibitors for the treatment of COVID 19. We calculated the binding\naffinities of these drugs to multitarget proteins using molecular docking\nprocess. We perform the QSAR modeling by employing various machine learning\nregression approaches to identify the potential inhibitors against COVID 19.\nOur findings with best scores of R2 and RMSE demonstrated that our proposed\nDecision Tree Regression (DTR) model is the most appropriate model to explore\nthe potential inhibitors. We proposed five novel promising inhibitors with\ntheir respective Zinc IDs ZINC (3873365, 85432544, 8214470, 85536956, and\n261494640) within the range of -19.7 kcal/mol to -12.6 kcal/mol. We further\nanalyzed the physiochemical and pharmacokinetic properties of these most potent\ninhibitors to examine their behavior. The analysis of these properties is the\nkey factor to promote an effective cure for public health. Our work constructs\nan efficient structure with which to probe the potential inhibitors against\nCOVID-19, creating the combination of molecular docking with machine learning\nregression approaches.",
      "tldr_zh": "本研究使用分子对接（molecular docking）和机器学习回归（machine learning regression）方法，探索COVID-19多靶点蛋白的潜在抑制剂，以加速药物再利用策略。研究通过QSAR建模，发现Decision Tree Regression (DTR)模型在R2和RMSE评分上表现最佳，并提出了五个新颖抑制剂（ZINC IDs: 3873365、85432544、8214470、85536956和261494640），其结合能范围为-19.7 kcal/mol至-12.6 kcal/mol。最终，分析了这些抑制剂的理化特性和药代动力学性质，以评估其作为有效COVID-19治疗选项的潜力。",
      "categories": [
        "q-bio.QM",
        "cs.AI"
      ],
      "primary_category": "q-bio.QM",
      "comment": "22 pages",
      "pdf_url": "http://arxiv.org/pdf/2409.16486v1",
      "published_date": "2024-09-24 22:19:56 UTC",
      "updated_date": "2024-09-24 22:19:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:02:01.089828"
    },
    {
      "arxiv_id": "2409.16478v1",
      "title": "Algorithmic Drift: A Simulation Framework to Study the Effects of Recommender Systems on User Preferences",
      "title_zh": "算法漂移：一种模拟框架，用于研究推荐系统对用户偏好的影响",
      "authors": [
        "Erica Coppolillo",
        "Simone Mungari",
        "Ettore Ritacco",
        "Francesco Fabbri",
        "Marco Minici",
        "Francesco Bonchi",
        "Giuseppe Manco"
      ],
      "abstract": "Digital platforms such as social media and e-commerce websites adopt\nRecommender Systems to provide value to the user. However, the social\nconsequences deriving from their adoption are still unclear. Many scholars\nargue that recommenders may lead to detrimental effects, such as\nbias-amplification deriving from the feedback loop between algorithmic\nsuggestions and users' choices. Nonetheless, the extent to which recommenders\ninfluence changes in users leaning remains uncertain. In this context, it is\nimportant to provide a controlled environment for evaluating the recommendation\nalgorithm before deployment. To address this, we propose a stochastic\nsimulation framework that mimics user-recommender system interactions in a\nlong-term scenario. In particular, we simulate the user choices by formalizing\na user model, which comprises behavioral aspects, such as the user resistance\ntowards the recommendation algorithm and their inertia in relying on the\nreceived suggestions. Additionally, we introduce two novel metrics for\nquantifying the algorithm's impact on user preferences, specifically in terms\nof drift over time. We conduct an extensive evaluation on multiple synthetic\ndatasets, aiming at testing the robustness of our framework when considering\ndifferent scenarios and hyper-parameters setting. The experimental results\nprove that the proposed methodology is effective in detecting and quantifying\nthe drift over the users preferences by means of the simulation. All the code\nand data used to perform the experiments are publicly available.",
      "tldr_zh": "这篇论文提出一个随机模拟框架（stochastic simulation framework），用于研究推荐系统（Recommender Systems）对用户偏好的影响，特别是算法漂移（Algorithmic Drift）现象，如偏见放大和用户偏好变化。框架通过构建一个用户模型来模拟长期互动，包括用户的抵抗力和依赖性行为，并引入两个新指标来量化偏好漂移。实验结果显示，该框架在多种合成数据集上表现出鲁棒性，能够有效检测和量化算法对用户偏好的影响，所有代码和数据已公开可用。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.16478v1",
      "published_date": "2024-09-24 21:54:22 UTC",
      "updated_date": "2024-09-24 21:54:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:02:00.524949"
    },
    {
      "arxiv_id": "2409.17183v1",
      "title": "Transfer learning for financial data predictions: a systematic review",
      "title_zh": "用于金融数据预测的迁移学习：系统综述",
      "authors": [
        "V. Lanzetta"
      ],
      "abstract": "Literature highlighted that financial time series data pose significant\nchallenges for accurate stock price prediction, because these data are\ncharacterized by noise and susceptibility to news; traditional statistical\nmethodologies made assumptions, such as linearity and normality, which are not\nsuitable for the non-linear nature of financial time series; on the other hand,\nmachine learning methodologies are able to capture non linear relationship in\nthe data. To date, neural network is considered the main machine learning tool\nfor the financial prices prediction. Transfer Learning, as a method aimed at\ntransferring knowledge from source tasks to target tasks, can represent a very\nuseful methodological tool for getting better financial prediction capability.\nCurrent reviews on the above body of knowledge are mainly focused on neural\nnetwork architectures, for financial prediction, with very little emphasis on\nthe transfer learning methodology; thus, this paper is aimed at going deeper on\nthis topic by developing a systematic review with respect to application of\nTransfer Learning for financial market predictions and to challenges/potential\nfuture directions of the transfer learning methodologies for stock market\npredictions.",
      "tldr_zh": "这篇论文通过系统综述探讨了 Transfer Learning 在金融数据预测中的应用，强调了金融时间序列数据面临的挑战，如噪声和对新闻的敏感性，以及传统统计方法（如假设线性 normality）的局限性。相比之下，machine learning 方法尤其是 neural network 能更好地捕捉数据的非线性关系，而 Transfer Learning 作为一种知识转移工具，可显著提升预测准确性。论文分析了现有研究对 Transfer Learning 的忽视，并指出了其在股票市场预测中的挑战和潜在未来方向。",
      "categories": [
        "q-fin.TR",
        "cs.AI",
        "cs.LG",
        "q-fin.CP"
      ],
      "primary_category": "q-fin.TR",
      "comment": "43 pages, 5 tables, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2409.17183v1",
      "published_date": "2024-09-24 20:52:32 UTC",
      "updated_date": "2024-09-24 20:52:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:02:16.814575"
    },
    {
      "arxiv_id": "2409.16444v2",
      "title": "Artificial Intelligence for Secured Information Systems in Smart Cities: Collaborative IoT Computing with Deep Reinforcement Learning and Blockchain",
      "title_zh": "翻译失败",
      "authors": [
        "Amin Zakaie Far",
        "Mohammad Zakaie Far",
        "Sonia Gharibzadeh",
        "Hajar Kazemi Naeini",
        "Leila Amini",
        "Shiva Zangeneh",
        "Morteza Rahimi",
        "Saeed Asadi"
      ],
      "abstract": "The accelerated expansion of the Internet of Things (IoT) has raised critical\nchallenges associated with privacy, security, and data integrity, specifically\nin infrastructures such as smart cities or smart manufacturing. Blockchain\ntechnology provides immutable, scalable, and decentralized solutions to address\nthese challenges, and integrating deep reinforcement learning (DRL) into the\nIoT environment offers enhanced adaptability and decision-making. This paper\ninvestigates the integration of blockchain and DRL to optimize mobile\ntransmission and secure data exchange in IoT-assisted smart cities. Through the\nclustering and categorization of IoT application systems, the combination of\nDRL and blockchain is shown to enhance the performance of IoT networks by\nmaintaining privacy and security. Based on the review of papers published\nbetween 2015 and 2024, we have classified the presented approaches and offered\npractical taxonomies, which provide researchers with critical perspectives and\nhighlight potential areas for future exploration and research. Our\ninvestigation shows how combining blockchain's decentralized framework with DRL\ncan address privacy and security issues, improve mobile transmission\nefficiency, and guarantee robust, privacy-preserving IoT systems. Additionally,\nwe explore blockchain integration for DRL and outline the notable applications\nof DRL technology. By addressing the challenges of machine learning and\nblockchain integration, this study proposes novel perspectives for researchers\nand serves as a foundational exploration from an interdisciplinary standpoint.",
      "tldr_zh": "这篇论文探讨了在智能城市中整合区块链和深度强化学习（DRL）来优化 IoT 系统的隐私、安全和数据完整性问题，通过这种结合提升移动传输效率和决策适应性。作者通过回顾2015-2024年间相关文献，对IoT应用进行聚类和分类，证明了区块链的去中心化框架与DRL的结合，能够显著改善IoT网络性能，并解决机器学习与区块链整合的挑战。最终，该研究为研究者提供了实用税onomies和未来探索方向，推动了可信赖的IoT辅助智能城市发展。",
      "categories": [
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.16444v2",
      "published_date": "2024-09-24 20:25:20 UTC",
      "updated_date": "2025-03-11 08:42:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:02:25.905041"
    },
    {
      "arxiv_id": "2409.16434v5",
      "title": "Lessons and Insights from a Unifying Study of Parameter-Efficient Fine-Tuning (PEFT) in Visual Recognition",
      "title_zh": "参数高效微调（PEFT）在视觉识别中的统一研究：经验教训与见解",
      "authors": [
        "Zheda Mai",
        "Ping Zhang",
        "Cheng-Hao Tu",
        "Hong-You Chen",
        "Li Zhang",
        "Wei-Lun Chao"
      ],
      "abstract": "Parameter-efficient fine-tuning (PEFT) has attracted significant attention\ndue to the growth of pre-trained model sizes and the need to fine-tune (FT)\nthem for superior downstream performance. Despite a surge in new PEFT methods,\na systematic study to understand their performance and suitable application\nscenarios is lacking, leaving questions like \"when to apply PEFT\" and \"which\nmethod to use\" largely unanswered, especially in visual recognition. In this\npaper, we conduct a unifying empirical study of representative PEFT methods\nwith Vision Transformers. We systematically tune their hyperparameters to\nfairly compare their accuracy on downstream tasks. Our study offers a practical\nuser guide and unveils several new insights. First, if tuned carefully,\ndifferent PEFT methods achieve similar accuracy in the low-shot benchmark\nVTAB-1K. This includes simple approaches like FT the bias terms that were\nreported inferior. Second, despite similar accuracy, we find that PEFT methods\nmake different mistakes and high-confidence predictions, likely due to their\ndifferent inductive biases. Such an inconsistency (or complementarity) opens up\nthe opportunity for ensemble methods, and we make preliminary attempts at this.\nThird, going beyond the commonly used low-shot tasks, we find that PEFT is also\nuseful in many-shot regimes, achieving comparable or better accuracy than full\nFT while using significantly fewer parameters. Lastly, we investigate PEFT's\nability to preserve a pre-trained model's robustness to distribution shifts\n(e.g., CLIP). Perhaps not surprisingly, PEFT approaches outperform full FT\nalone. However, with weight-space ensembles, full FT can better balance target\ndistribution and distribution shift performance, suggesting a future research\ndirection for robust PEFT.",
      "tldr_zh": "本研究对Parameter-Efficient Fine-Tuning (PEFT)方法在视觉识别领域的性能进行了系统性实证研究，使用Vision Transformers并系统调整超参数，以公平比较下游任务的准确率。结果发现，如果仔细调优，不同PEFT方法在低样本基准VTAB-1K上可达到相似的准确率，甚至包括简单的偏置项微调方法。进一步分析显示，PEFT方法虽准确率类似，但犯错模式不同，可能源于归纳偏差，这为集成方法提供了机会；同时，在多样本场景中，PEFT能实现与全微调(FT)相当或更好的性能，同时显著减少参数，并更好地保留预训练模型（如CLIP）的分布偏移鲁棒性。研究为PEFT的应用提供了实用指南，并建议未来探索鲁棒性集成策略。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "CVPR 2025. The code is available at\n  https://github.com/OSU-MLB/ViT_PEFT_Vision",
      "pdf_url": "http://arxiv.org/pdf/2409.16434v5",
      "published_date": "2024-09-24 19:57:40 UTC",
      "updated_date": "2025-03-25 02:07:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:02:38.748148"
    },
    {
      "arxiv_id": "2409.16430v1",
      "title": "A Comprehensive Survey of Bias in LLMs: Current Landscape and Future Directions",
      "title_zh": "翻译失败",
      "authors": [
        "Rajesh Ranjan",
        "Shailja Gupta",
        "Surya Narayan Singh"
      ],
      "abstract": "Large Language Models(LLMs) have revolutionized various applications in\nnatural language processing (NLP) by providing unprecedented text generation,\ntranslation, and comprehension capabilities. However, their widespread\ndeployment has brought to light significant concerns regarding biases embedded\nwithin these models. This paper presents a comprehensive survey of biases in\nLLMs, aiming to provide an extensive review of the types, sources, impacts, and\nmitigation strategies related to these biases. We systematically categorize\nbiases into several dimensions. Our survey synthesizes current research\nfindings and discusses the implications of biases in real-world applications.\nAdditionally, we critically assess existing bias mitigation techniques and\npropose future research directions to enhance fairness and equity in LLMs. This\nsurvey serves as a foundational resource for researchers, practitioners, and\npolicymakers concerned with addressing and understanding biases in LLMs.",
      "tldr_zh": "这篇论文对大型语言模型(LLMs)中的偏见进行了全面调查，涵盖了偏见的类型、来源、影响以及缓解策略。\n作者系统分类了这些偏见，并综合了当前研究发现，讨论了偏见在实际NLP应用中的潜在危害。\n论文评估了现有的偏见缓解技术，并提出未来研究方向，以提升LLMs的公平性和公平性。\n这份调查作为基础资源，可供研究者、从业者和决策者使用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "2 Tables, 1 Figure",
      "pdf_url": "http://arxiv.org/pdf/2409.16430v1",
      "published_date": "2024-09-24 19:50:38 UTC",
      "updated_date": "2024-09-24 19:50:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:02:48.694076"
    },
    {
      "arxiv_id": "2409.16429v1",
      "title": "Leveraging Local Structure for Improving Model Explanations: An Information Propagation Approach",
      "title_zh": "利用局部结构改善模型解释：一种信息传播方法",
      "authors": [
        "Ruo Yang",
        "Binghui Wang",
        "Mustafa Bilgic"
      ],
      "abstract": "Numerous explanation methods have been recently developed to interpret the\ndecisions made by deep neural network (DNN) models. For image classifiers,\nthese methods typically provide an attribution score to each pixel in the image\nto quantify its contribution to the prediction. However, most of these\nexplanation methods appropriate attribution scores to pixels independently,\neven though both humans and DNNs make decisions by analyzing a set of closely\nrelated pixels simultaneously. Hence, the attribution score of a pixel should\nbe evaluated jointly by considering itself and its structurally-similar pixels.\nWe propose a method called IProp, which models each pixel's individual\nattribution score as a source of explanatory information and explains the image\nprediction through the dynamic propagation of information across all pixels. To\nformulate the information propagation, IProp adopts the Markov Reward Process,\nwhich guarantees convergence, and the final status indicates the desired\npixels' attribution scores. Furthermore, IProp is compatible with any existing\nattribution-based explanation method. Extensive experiments on various\nexplanation methods and DNN models verify that IProp significantly improves\nthem on a variety of interpretability metrics.",
      "tldr_zh": "该论文指出，现有的深度神经网络(DNN)解释方法通常独立为图像像素分配归因分数，但忽略了像素间的局部结构，而IProp方法通过动态信息传播来解决这一问题。IProp将每个像素的归因分数视为信息源，并采用Markov Reward Process制定传播过程，确保收敛并获得精确的像素归因分数。该方法兼容现有归因-based解释方法，并在各种解释指标上显著提升了性能，如实验显示IProp在多个DNN模型上改善了基线方法的解释准确性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.16429v1",
      "published_date": "2024-09-24 19:48:47 UTC",
      "updated_date": "2024-09-24 19:48:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:03:00.096029"
    },
    {
      "arxiv_id": "2409.16427v3",
      "title": "HAICOSYSTEM: An Ecosystem for Sandboxing Safety Risks in Human-AI Interactions",
      "title_zh": "翻译失败",
      "authors": [
        "Xuhui Zhou",
        "Hyunwoo Kim",
        "Faeze Brahman",
        "Liwei Jiang",
        "Hao Zhu",
        "Ximing Lu",
        "Frank Xu",
        "Bill Yuchen Lin",
        "Yejin Choi",
        "Niloofar Mireshghallah",
        "Ronan Le Bras",
        "Maarten Sap"
      ],
      "abstract": "AI agents are increasingly autonomous in their interactions with human users\nand tools, leading to increased interactional safety risks. We present\nHAICOSYSTEM, a framework examining AI agent safety within diverse and complex\nsocial interactions. HAICOSYSTEM features a modular sandbox environment that\nsimulates multi-turn interactions between human users and AI agents, where the\nAI agents are equipped with a variety of tools (e.g., patient management\nplatforms) to navigate diverse scenarios (e.g., a user attempting to access\nother patients' profiles). To examine the safety of AI agents in these\ninteractions, we develop a comprehensive multi-dimensional evaluation framework\nthat uses metrics covering operational, content-related, societal, and legal\nrisks. Through running 1840 simulations based on 92 scenarios across seven\ndomains (e.g., healthcare, finance, education), we demonstrate that HAICOSYSTEM\ncan emulate realistic user-AI interactions and complex tool use by AI agents.\nOur experiments show that state-of-the-art LLMs, both proprietary and\nopen-sourced, exhibit safety risks in over 50\\% cases, with models generally\nshowing higher risks when interacting with simulated malicious users. Our\nfindings highlight the ongoing challenge of building agents that can safely\nnavigate complex interactions, particularly when faced with malicious users. To\nfoster the AI agent safety ecosystem, we release a code platform that allows\npractitioners to create custom scenarios, simulate interactions, and evaluate\nthe safety and performance of their agents.",
      "tldr_zh": "本文提出 HAICOSYSTEM，一种生态系统框架，用于隔离和评估人类-AI 互动中的安全风险。该框架采用模块化 sandbox environment 模拟多轮互动，AI agents 配备各种工具（如患者管理平台），并通过多维度评估指标（涵盖操作、内容、社会和法律风险）进行全面分析。在 1840 次模拟实验中，基于 92 个跨七个领域的场景（如医疗和金融），研究发现最先进的 LLMs 在超过 50% 的情况下存在安全风险，特别是面对恶意用户时。该系统还发布了代码平台，允许从业者自定义场景并评估 AI agents 的安全性能。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Both the second and third authors contributed equally",
      "pdf_url": "http://arxiv.org/pdf/2409.16427v3",
      "published_date": "2024-09-24 19:47:21 UTC",
      "updated_date": "2024-10-21 19:47:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:03:14.332954"
    },
    {
      "arxiv_id": "2409.16425v1",
      "title": "Lessons for Editors of AI Incidents from the AI Incident Database",
      "title_zh": "翻译失败",
      "authors": [
        "Kevin Paeth",
        "Daniel Atherton",
        "Nikiforos Pittaras",
        "Heather Frase",
        "Sean McGregor"
      ],
      "abstract": "As artificial intelligence (AI) systems become increasingly deployed across\nthe world, they are also increasingly implicated in AI incidents - harm events\nto individuals and society. As a result, industry, civil society, and\ngovernments worldwide are developing best practices and regulations for\nmonitoring and analyzing AI incidents. The AI Incident Database (AIID) is a\nproject that catalogs AI incidents and supports further research by providing a\nplatform to classify incidents for different operational and research-oriented\ngoals. This study reviews the AIID's dataset of 750+ AI incidents and two\nindependent taxonomies applied to these incidents to identify common challenges\nto indexing and analyzing AI incidents. We find that certain patterns of AI\nincidents present structural ambiguities that challenge incident databasing and\nexplore how epistemic uncertainty in AI incident reporting is unavoidable. We\ntherefore report mitigations to make incident processes more robust to\nuncertainty related to cause, extent of harm, severity, or technical details of\nimplicated systems. With these findings, we discuss how to develop future AI\nincident reporting practices.",
      "tldr_zh": "这篇论文审阅了AI Incident Database (AIID)中超过750个AI事件的数据集，并应用两个独立taxonomies，识别了AI事件在索引和分析中面临的常见挑战，如结构模糊和epistemic uncertainty。研究发现，这些不确定性在AI事件报告中不可避免，包括事件原因、伤害程度、严重性和技术细节的模糊性。作者提出缓解措施，使事件处理过程更robust，并讨论了如何开发未来的AI事件报告最佳实践，以支持行业、民间社会和政府的监管努力。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "8 pages, 0 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.16425v1",
      "published_date": "2024-09-24 19:46:58 UTC",
      "updated_date": "2024-09-24 19:46:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:03:24.845053"
    },
    {
      "arxiv_id": "2409.16418v1",
      "title": "Task-oriented Prompt Enhancement via Script Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Chung-Yu Wang",
        "Alireza DaghighFarsoodeh",
        "Hung Viet Pham"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated remarkable abilities across\nvarious tasks, leveraging advanced reasoning. Yet, they struggle with\ntask-oriented prompts due to a lack of specific prior knowledge of the task\nanswers. The current state-of-the-art approach, PAL, utilizes code generation\nto address this issue. However, PAL depends on manually crafted prompt\ntemplates and examples while still producing inaccurate results. In this work,\nwe present TITAN-a novel strategy designed to enhance LLMs' performance on\ntask-oriented prompts. TITAN achieves this by generating scripts using a\nuniversal approach and zero-shot learning. Unlike existing methods, TITAN\neliminates the need for detailed task-specific instructions and extensive\nmanual efforts. TITAN enhances LLMs' performance on various tasks by utilizing\ntheir analytical and code-generation capabilities in a streamlined process.\nTITAN employs two key techniques: (1) step-back prompting to extract the task's\ninput specifications and (2) chain-of-thought prompting to identify required\nprocedural steps. This information is used to improve the LLMs' code-generation\nprocess. TITAN further refines the generated script through post-processing and\nthe script is executed to retrieve the final answer. Our comprehensive\nevaluation demonstrates TITAN's effectiveness in a diverse set of tasks. On\naverage, TITAN outperforms the state-of-the-art zero-shot approach by 7.6% and\n3.9% when paired with GPT-3.5 and GPT-4. Overall, without human annotation,\nTITAN achieves state-of-the-art performance in 8 out of 11 cases while only\nmarginally losing to few-shot approaches (which needed human intervention) on\nthree occasions by small margins. This work represents a significant\nadvancement in addressing task-oriented prompts, offering a novel solution for\neffectively utilizing LLMs in everyday life tasks.",
      "tldr_zh": "本文提出 TITAN，一种新型策略，通过脚本生成来提升大语言模型 (LLMs) 在任务导向提示上的性能，解决 LLMs 因缺乏特定先验知识而产生的准确性问题。TITAN 采用 zero-shot learning 的通用方法，包括 step-back prompting 提取任务输入规范和 chain-of-thought prompting 识别程序步骤，随后通过后处理和脚本执行来获取最终答案。与现有方法 PAL 相比，TITAN 无需手动提示模板，并在多种任务上表现出色，与 GPT-3.5 和 GPT-4 结合时分别比最先进 zero-shot 方法提高了 7.6% 和 3.9%。整体上，TITAN 在 11 个案例中实现了 8 个最先进性能，仅在少数情况下略逊于少样本方法。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "17 pages + reference",
      "pdf_url": "http://arxiv.org/pdf/2409.16418v1",
      "published_date": "2024-09-24 19:32:08 UTC",
      "updated_date": "2024-09-24 19:32:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:03:39.703381"
    },
    {
      "arxiv_id": "2409.16416v1",
      "title": "Selection of Prompt Engineering Techniques for Code Generation through Predicting Code Complexity",
      "title_zh": "翻译失败",
      "authors": [
        "Chung-Yu Wang",
        "Alireza DaghighFarsoodeh",
        "Hung Viet Pham"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated impressive performance in\nsoftware engineering tasks. However, improving their accuracy in generating\ncorrect and reliable code remains challenging. Numerous prompt engineering\ntechniques (PETs) have been developed to address this, but no single approach\nis universally optimal. Selecting the right PET for each query is difficult for\ntwo primary reasons: (1) interactive prompting techniques may not consistently\ndeliver the expected benefits, especially for simpler queries, and (2) current\nautomated prompt engineering methods lack adaptability and fail to fully\nutilize multi-stage responses. To overcome these challenges, we propose\nPET-Select, a PET-agnostic selection model that uses code complexity as a proxy\nto classify queries and select the most appropriate PET. By incorporating\ncontrastive learning, PET-Select effectively distinguishes between simple and\ncomplex problems, allowing it to choose PETs that are best suited for each\nquery's complexity level. Our evaluations on the MBPP and HumanEval benchmarks\nusing GPT-3.5 Turbo and GPT-4o show up to a 1.9% improvement in pass@1\naccuracy, along with a 74.8% reduction in token usage. Additionally, we provide\nboth quantitative and qualitative results to demonstrate how PET-Select\neffectively selects the most appropriate techniques for each code generation\nquery, further showcasing its efficiency in optimizing PET selection.",
      "tldr_zh": "这篇论文针对Large Language Models (LLMs) 在代码生成中的准确性挑战，提出PET-Select模型，通过预测代码复杂度作为代理来分类查询并选择最合适的提示工程技术(PETs)。PET-Select采用对比学习(contrastive learning)来有效区分简单和复杂问题，从而优化多阶段响应。实验结果显示，在MBPP和HumanEval基准上使用GPT-3.5 Turbo和GPT-4o时，pass@1准确率提高了高达1.9%，同时令牌使用减少了74.8%。该方法不仅提升了代码生成的可靠性和效率，还通过定量和定性分析证明了其在PET选择方面的适应性。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "18 pages + reference",
      "pdf_url": "http://arxiv.org/pdf/2409.16416v1",
      "published_date": "2024-09-24 19:28:55 UTC",
      "updated_date": "2024-09-24 19:28:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:03:50.173120"
    },
    {
      "arxiv_id": "2409.16408v2",
      "title": "Modern Hopfield Networks meet Encoded Neural Representations -- Addressing Practical Considerations",
      "title_zh": "翻译失败",
      "authors": [
        "Satyananda Kashyap",
        "Niharika S. D'Souza",
        "Luyao Shi",
        "Ken C. L. Wong",
        "Hongzhi Wang",
        "Tanveer Syeda-Mahmood"
      ],
      "abstract": "Content-addressable memories such as Modern Hopfield Networks (MHN) have been\nstudied as mathematical models of auto-association and storage/retrieval in the\nhuman declarative memory, yet their practical use for large-scale content\nstorage faces challenges. Chief among them is the occurrence of meta-stable\nstates, particularly when handling large amounts of high dimensional content.\nThis paper introduces Hopfield Encoding Networks (HEN), a framework that\nintegrates encoded neural representations into MHNs to improve pattern\nseparability and reduce meta-stable states. We show that HEN can also be used\nfor retrieval in the context of hetero association of images with natural\nlanguage queries, thus removing the limitation of requiring access to partial\ncontent in the same domain. Experimental results demonstrate substantial\nreduction in meta-stable states and increased storage capacity while still\nenabling perfect recall of a significantly larger number of inputs advancing\nthe practical utility of associative memory networks for real-world tasks.",
      "tldr_zh": "本研究针对 Modern Hopfield Networks (MHN) 在处理大规模高维内容时遇到的 meta-stable states 等实际挑战，提出 Hopfield Encoding Networks (HEN) 框架，通过集成编码神经表示来提升模式可分性和减少 meta-stable states。HEN 不仅优化了 MHN 的存储和检索功能，还扩展到异质关联任务，例如将图像与自然语言查询进行关联，而无需访问相同领域的部分内容。实验结果显示，HEN 显著降低了 meta-stable states、提高了存储容量，并实现了对更多输入的完美回忆，从而增强了关联记忆网络在实际任务中的实用性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.IR",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "17 pages, 8 figures, accepted as a workshop paper at UniReps @\n  Neurips 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.16408v2",
      "published_date": "2024-09-24 19:17:15 UTC",
      "updated_date": "2024-10-30 22:35:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:04:01.445692"
    },
    {
      "arxiv_id": "2409.16395v2",
      "title": "HELIOT: LLM-Based CDSS for Adverse Drug Reaction Management",
      "title_zh": "HELIOT：基于大语言模型的临床决策支持系统，用于不良药物反应管理",
      "authors": [
        "Gabriele De Vito",
        "Filomena Ferrucci",
        "Athanasios Angelakis"
      ],
      "abstract": "Medication errors significantly threaten patient safety, leading to adverse\ndrug events and substantial economic burdens on healthcare systems. Clinical\nDecision Support Systems (CDSSs) aimed at mitigating these errors often face\nlimitations when processing unstructured clinical data, including reliance on\nstatic databases and rule-based algorithms, frequently generating excessive\nalerts that lead to alert fatigue among healthcare providers. This paper\nintroduces HELIOT, an innovative CDSS for adverse drug reaction management that\nprocesses free-text clinical information using Large Language Models (LLMs)\nintegrated with a comprehensive pharmaceutical data repository. HELIOT\nleverages advanced natural language processing capabilities to interpret\nmedical narratives, extract relevant drug reaction information from\nunstructured clinical notes, and learn from past patient-specific medication\ntolerances to reduce false alerts, enabling more nuanced and contextual adverse\ndrug event warnings across primary care, specialist consultations, and hospital\nsettings. An initial evaluation using a synthetic dataset of clinical\nnarratives and expert-verified ground truth shows promising results. HELIOT\nachieves high accuracy in a controlled setting. In addition, by intelligently\nanalyzing previous medication tolerance documented in clinical notes and\ndistinguishing between cases requiring different alert types, HELIOT can\npotentially reduce interruptive alerts by over 50% compared to traditional\nCDSSs. While these preliminary findings are encouraging, real-world validation\nwill be essential to confirm these benefits in clinical practice.",
      "tldr_zh": "该论文针对药物错误导致的患者安全风险和医疗经济负担，提出HELIOT，一种基于Large Language Models (LLMs)的Clinical Decision Support Systems (CDSS)，用于管理不良药物反应。HELIOT通过整合LLMs与药物数据仓库，处理非结构化临床文本，提取相关信息并从患者过去的药物耐受性中学习，从而减少假警报并提供更精确的情境警报，适用于初级护理、专家咨询和医院环境。初步评估显示，HELIOT在合成数据集上表现出高准确性，并可将中断性警报减少超过50%，尽管需要真实世界验证来确认其实际效益。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.16395v2",
      "published_date": "2024-09-24 18:55:10 UTC",
      "updated_date": "2025-04-13 18:36:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:04:14.196742"
    },
    {
      "arxiv_id": "2409.16392v2",
      "title": "Rao-Blackwellized POMDP Planning",
      "title_zh": "翻译失败",
      "authors": [
        "Jiho Lee",
        "Nisar R. Ahmed",
        "Kyle H. Wray",
        "Zachary N. Sunberg"
      ],
      "abstract": "Partially Observable Markov Decision Processes (POMDPs) provide a structured\nframework for decision-making under uncertainty, but their application requires\nefficient belief updates. Sequential Importance Resampling Particle Filters\n(SIRPF), also known as Bootstrap Particle Filters, are commonly used as belief\nupdaters in large approximate POMDP solvers, but they face challenges such as\nparticle deprivation and high computational costs as the system's state\ndimension grows. To address these issues, this study introduces\nRao-Blackwellized POMDP (RB-POMDP) approximate solvers and outlines generic\nmethods to apply Rao-Blackwellization in both belief updates and online\nplanning. We compare the performance of SIRPF and Rao-Blackwellized Particle\nFilters (RBPF) in a simulated localization problem where an agent navigates\ntoward a target in a GPS-denied environment using POMCPOW and RB-POMCPOW\nplanners. Our results not only confirm that RBPFs maintain accurate belief\napproximations over time with fewer particles, but, more surprisingly, RBPFs\ncombined with quadrature-based integration improve planning quality\nsignificantly compared to SIRPF-based planning under the same computational\nlimits.",
      "tldr_zh": "本文针对部分可观测Markov决策过程(POMDP)中的信念更新效率问题，引入Rao-Blackwellized POMDP (RB-POMDP) 近似求解器，并提出在信念更新和在线规划中应用Rao-Blackwellization的通用方法，以解决Sequential Importance Resampling Particle Filters (SIRPF) 的粒子耗尽和高计算成本问题。研究通过模拟定位任务比较SIRPF和Rao-Blackwellized Particle Filters (RBPF)，结果显示RBPF使用更少的粒子即可保持准确的信念近似。更为重要的是，RBPF结合二次积分显著提高了规划质量，在相同计算限制下优于SIRPF-based规划。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.16392v2",
      "published_date": "2024-09-24 18:46:50 UTC",
      "updated_date": "2025-03-03 20:56:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:04:27.019758"
    },
    {
      "arxiv_id": "2409.16376v2",
      "title": "Beyond Text-to-Text: An Overview of Multimodal and Generative Artificial Intelligence for Education Using Topic Modeling",
      "title_zh": "超越文本到文本：利用主题建",
      "authors": [
        "Ville Heilala",
        "Roberto Araya",
        "Raija Hämäläinen"
      ],
      "abstract": "Generative artificial intelligence (GenAI) can reshape education and\nlearning. While large language models (LLMs) like ChatGPT dominate current\neducational research, multimodal capabilities, such as text-to-speech and\ntext-to-image, are less explored. This study uses topic modeling to map the\nresearch landscape of multimodal and generative AI in education. An extensive\nliterature search using Dimensions yielded 4175 articles. Employing a topic\nmodeling approach, latent topics were extracted, resulting in 38 interpretable\ntopics organized into 14 thematic areas. Findings indicate a predominant focus\non text-to-text models in educational contexts, with other modalities\nunderexplored, overlooking the broader potential of multimodal approaches. The\nresults suggest a research gap, stressing the importance of more balanced\nattention across different AI modalities and educational levels. In summary,\nthis research provides an overview of current trends in generative AI for\neducation, underlining opportunities for future exploration of multimodal\ntechnologies to fully realize the transformative potential of artificial\nintelligence in education.",
      "tldr_zh": "本研究通过主题建模（topic modeling）对4175篇文献进行分析，概述了多模态和生成式人工智能（Generative artificial intelligence, GenAI）在教育中的应用现状，强调当前研究主要聚焦于大型语言模型（large language models, LLMs）如ChatGPT的text-to-text功能，而忽略了其他模态如text-to-speech和text-to-image。结果显示，这些文献提取了38个可解释主题，组织成14个主题领域，揭示了教育领域对多模态AI的关注不均衡，存在显著研究空白。作者呼吁未来更均衡地探索不同AI模态和教育水平，以充分发挥人工智能在教育中的变革潜力。",
      "categories": [
        "cs.AI",
        "cs.HC",
        "I.2; K.3.0"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.16376v2",
      "published_date": "2024-09-24 18:11:24 UTC",
      "updated_date": "2025-04-02 10:19:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:04:38.380880"
    },
    {
      "arxiv_id": "2409.16287v2",
      "title": "Articulated Object Manipulation using Online Axis Estimation with SAM2-Based Tracking",
      "title_zh": "翻译失败",
      "authors": [
        "Xi Wang",
        "Tianxing Chen",
        "Qiaojun Yu",
        "Tianling Xu",
        "Zanxin Chen",
        "Yiting Fu",
        "Ziqi He",
        "Cewu Lu",
        "Yao Mu",
        "Ping Luo"
      ],
      "abstract": "Articulated object manipulation requires precise object interaction, where\nthe object's axis must be carefully considered. Previous research employed\ninteractive perception for manipulating articulated objects, but typically,\nopen-loop approaches often suffer from overlooking the interaction dynamics. To\naddress this limitation, we present a closed-loop pipeline integrating\ninteractive perception with online axis estimation from segmented 3D point\nclouds. Our method leverages any interactive perception technique as a\nfoundation for interactive perception, inducing slight object movement to\ngenerate point cloud frames of the evolving dynamic scene. These point clouds\nare then segmented using Segment Anything Model 2 (SAM2), after which the\nmoving part of the object is masked for accurate motion online axis estimation,\nguiding subsequent robotic actions. Our approach significantly enhances the\nprecision and efficiency of manipulation tasks involving articulated objects.\nExperiments in simulated environments demonstrate that our method outperforms\nbaseline approaches, especially in tasks that demand precise axis-based\ncontrol. Project Page:\nhttps://hytidel.github.io/video-tracking-for-axis-estimation/.",
      "tldr_zh": "该研究针对关节物体（articulated objects）的操作问题，提出了一种闭环管道（closed-loop pipeline），通过整合交互感知（interactive perception）和基于 Segment Anything Model 2 (SAM2) 的在线轴估计（online axis estimation），以实现更精确的物体交互。方法包括诱导物体轻微移动生成3D点云帧、利用SAM2进行分割并掩盖移动部分，从而准确估计轴并指导机器人后续动作。该方法在模拟环境中显著优于基线方法，尤其在需要精确轴控制的任务中，提高了操作的精确性和效率。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.GR",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Project Page:\n  https://hytidel.github.io/video-tracking-for-axis-estimation/",
      "pdf_url": "http://arxiv.org/pdf/2409.16287v2",
      "published_date": "2024-09-24 17:59:56 UTC",
      "updated_date": "2025-03-07 01:24:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:04:48.678927"
    },
    {
      "arxiv_id": "2409.16252v2",
      "title": "Fields of The World: A Machine Learning Benchmark Dataset For Global Agricultural Field Boundary Segmentation",
      "title_zh": "Fields of The World: 全球农业田界分割的机器学习基准数据集",
      "authors": [
        "Hannah Kerner",
        "Snehal Chaudhari",
        "Aninda Ghosh",
        "Caleb Robinson",
        "Adeel Ahmad",
        "Eddie Choi",
        "Nathan Jacobs",
        "Chris Holmes",
        "Matthias Mohr",
        "Rahul Dodhia",
        "Juan M. Lavista Ferres",
        "Jennifer Marcus"
      ],
      "abstract": "Crop field boundaries are foundational datasets for agricultural monitoring\nand assessments but are expensive to collect manually. Machine learning (ML)\nmethods for automatically extracting field boundaries from remotely sensed\nimages could help realize the demand for these datasets at a global scale.\nHowever, current ML methods for field instance segmentation lack sufficient\ngeographic coverage, accuracy, and generalization capabilities. Further,\nresearch on improving ML methods is restricted by the lack of labeled datasets\nrepresenting the diversity of global agricultural fields. We present Fields of\nThe World (FTW) -- a novel ML benchmark dataset for agricultural field instance\nsegmentation spanning 24 countries on four continents (Europe, Africa, Asia,\nand South America). FTW is an order of magnitude larger than previous datasets\nwith 70,462 samples, each containing instance and semantic segmentation masks\npaired with multi-date, multi-spectral Sentinel-2 satellite images. We provide\nresults from baseline models for the new FTW benchmark, show that models\ntrained on FTW have better zero-shot and fine-tuning performance in held-out\ncountries than models that aren't pre-trained with diverse datasets, and show\npositive qualitative zero-shot results of FTW models in a real-world scenario\n-- running on Sentinel-2 scenes over Ethiopia.",
      "tldr_zh": "该论文介绍了Fields of The World (FTW)，一个用于全球农业田界实例分割的机器学习基准数据集，旨在解决当前ML方法在地理覆盖、准确性和泛化能力方面的不足。FTW覆盖24个国家、四个大陆，共包含70,462个样本，每样本配有实例和语义分割掩码以及多日期多光谱Sentinel-2卫星图像，比现有数据集规模大一个数量级。实验结果显示，使用FTW训练的模型在零样本和微调场景中表现出色，尤其在未见国家的数据上性能提升，并在埃塞俄比亚的真实卫星图像中实现了积极的定性结果。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at the AAAI-2025 Artificial Intelligence for Social Impact\n  (AISI) track",
      "pdf_url": "http://arxiv.org/pdf/2409.16252v2",
      "published_date": "2024-09-24 17:20:58 UTC",
      "updated_date": "2024-12-19 21:41:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:05:02.814567"
    },
    {
      "arxiv_id": "2409.16241v1",
      "title": "LLM Echo Chamber: personalized and automated disinformation",
      "title_zh": "翻译失败",
      "authors": [
        "Tony Ma"
      ],
      "abstract": "Recent advancements have showcased the capabilities of Large Language Models\nlike GPT4 and Llama2 in tasks such as summarization, translation, and content\nreview. However, their widespread use raises concerns, particularly around the\npotential for LLMs to spread persuasive, humanlike misinformation at scale,\nwhich could significantly influence public opinion. This study examines these\nrisks, focusing on LLMs ability to propagate misinformation as factual. To\ninvestigate this, we built the LLM Echo Chamber, a controlled digital\nenvironment simulating social media chatrooms, where misinformation often\nspreads. Echo chambers, where individuals only interact with like minded\npeople, further entrench beliefs. By studying malicious bots spreading\nmisinformation in this environment, we can better understand this phenomenon.\nWe reviewed current LLMs, explored misinformation risks, and applied sota\nfinetuning techniques. Using Microsoft phi2 model, finetuned with our custom\ndataset, we generated harmful content to create the Echo Chamber. This setup,\nevaluated by GPT4 for persuasiveness and harmfulness, sheds light on the\nethical concerns surrounding LLMs and emphasizes the need for stronger\nsafeguards against misinformation.",
      "tldr_zh": "这项研究探讨了大型语言模型（LLMs）如 GPT-4 和 Llama2 在传播个性化、自动化误信息方面的风险，强调这些模型可能大规模影响公众意见。研究者构建了 LLM Echo Chamber，一个模拟社交媒体聊天室的受控环境，使用 Microsoft phi2 模型通过自定义数据集微调，生成有害内容来模拟回音室效应。实验结果显示，该系统能有效传播说服性误信息，并由 GPT-4 评估其危害性，最终呼吁加强 LLMs 的伦理保障措施以防范此类问题。",
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "42 pages",
      "pdf_url": "http://arxiv.org/pdf/2409.16241v1",
      "published_date": "2024-09-24 17:04:12 UTC",
      "updated_date": "2024-09-24 17:04:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:05:14.761921"
    },
    {
      "arxiv_id": "2409.16340v1",
      "title": "Future-Proofing Medical Imaging with Privacy-Preserving Federated Learning and Uncertainty Quantification: A Review",
      "title_zh": "翻译失败",
      "authors": [
        "Nikolas Koutsoubis",
        "Asim Waqas",
        "Yasin Yilmaz",
        "Ravi P. Ramachandran",
        "Matthew Schabath",
        "Ghulam Rasool"
      ],
      "abstract": "Artificial Intelligence (AI) has demonstrated significant potential in\nautomating various medical imaging tasks, which could soon become routine in\nclinical practice for disease diagnosis, prognosis, treatment planning, and\npost-treatment surveillance. However, the privacy concerns surrounding patient\ndata present a major barrier to the widespread adoption of AI in medical\nimaging, as large, diverse training datasets are essential for developing\naccurate, generalizable, and robust Artificial intelligence models. Federated\nLearning (FL) offers a solution that enables organizations to train AI models\ncollaboratively without sharing sensitive data. federated learning exchanges\nmodel training information, such as gradients, between the participating sites.\nDespite its promise, federated learning is still in its developmental stages\nand faces several challenges. Notably, sensitive information can still be\ninferred from the gradients shared during model training. Quantifying AI\nmodels' uncertainty is vital due to potential data distribution shifts\npost-deployment, which can affect model performance. Uncertainty quantification\n(UQ) in FL is particularly challenging due to data heterogeneity across\nparticipating sites. This review provides a comprehensive examination of FL,\nprivacy-preserving FL (PPFL), and UQ in FL. We identify key gaps in current FL\nmethodologies and propose future research directions to enhance data privacy\nand trustworthiness in medical imaging applications.",
      "tldr_zh": "这篇评论论文探讨了人工智能(AI)在医疗成像中的应用潜力，包括疾病诊断、预后、治疗规划和监测，但强调了患者数据隐私问题对模型训练的阻碍。Federated Learning (FL) 被视为解决方案，通过在参与站点间交换模型训练信息（如gradients）实现协作训练，而Privacy-Preserving FL (PPFL) 则进一步缓解敏感信息泄露风险。论文审查了FL中的Uncertainty Quantification (UQ)挑战，特别是数据异质性导致的模型不确定性，并识别了当前方法的关键空白，提出未来研究方向以提升医疗成像的隐私保护和可信度。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "21 pages, 5 figures, 4 tables, Review paper, preprint to Radiology\n  AI. arXiv admin note: text overlap with arXiv:2406.12815",
      "pdf_url": "http://arxiv.org/pdf/2409.16340v1",
      "published_date": "2024-09-24 16:55:32 UTC",
      "updated_date": "2024-09-24 16:55:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:05:29.581974"
    },
    {
      "arxiv_id": "2409.16239v1",
      "title": "Label-Augmented Dataset Distillation",
      "title_zh": "标签增强数据集蒸馏",
      "authors": [
        "Seoungyoon Kang",
        "Youngsun Lim",
        "Hyunjung Shim"
      ],
      "abstract": "Traditional dataset distillation primarily focuses on image representation\nwhile often overlooking the important role of labels. In this study, we\nintroduce Label-Augmented Dataset Distillation (LADD), a new dataset\ndistillation framework enhancing dataset distillation with label augmentations.\nLADD sub-samples each synthetic image, generating additional dense labels to\ncapture rich semantics. These dense labels require only a 2.5% increase in\nstorage (ImageNet subsets) with significant performance benefits, providing\nstrong learning signals. Our label generation strategy can complement existing\ndataset distillation methods for significantly enhancing their training\nefficiency and performance. Experimental results demonstrate that LADD\noutperforms existing methods in terms of computational overhead and accuracy.\nWith three high-performance dataset distillation algorithms, LADD achieves\nremarkable gains by an average of 14.9% in accuracy. Furthermore, the\neffectiveness of our method is proven across various datasets, distillation\nhyperparameters, and algorithms. Finally, our method improves the\ncross-architecture robustness of the distilled dataset, which is important in\nthe application scenario.",
      "tldr_zh": "本研究提出了一种新的数据集蒸馏框架Label-Augmented Dataset Distillation (LADD)，通过增强标签来解决传统方法忽略标签作用的问题。LADD对每个合成图像进行子采样，生成额外的密集标签，以捕捉丰富的语义，同时仅增加2.5%的存储空间（如ImageNet子集），从而提供更强的学习信号并提升训练效率。实验结果显示，LADD与现有数据集蒸馏算法结合后，平均准确率提高14.9%，并在各种数据集、超参数和算法中表现出色，同时改善了蒸馏数据集的跨架构鲁棒性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.16239v1",
      "published_date": "2024-09-24 16:54:22 UTC",
      "updated_date": "2024-09-24 16:54:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:05:39.027337"
    },
    {
      "arxiv_id": "2409.16238v2",
      "title": "Efficiently Learning Probabilistic Logical Models by Cheaply Ranking Mined Rules",
      "title_zh": "翻译失败",
      "authors": [
        "Jonathan Feldstein",
        "Dominic Phillips",
        "Efthymia Tsamoura"
      ],
      "abstract": "Probabilistic logical models are a core component of neurosymbolic AI and are\nimportant in their own right for tasks that require high explainability. Unlike\nneural networks, logical theories that underlie the model are often handcrafted\nusing domain expertise, making their development costly and prone to errors.\nWhile there are algorithms that learn logical theories from data, they are\ngenerally prohibitively expensive, limiting their applicability in real-world\nsettings. Here, we introduce precision and recall for logical rules and define\ntheir composition as rule utility -- a cost-effective measure of the predictive\npower of logical theories. We also introduce SPECTRUM, a scalable framework for\nlearning logical theories from relational data. Its scalability derives from a\nlinear-time algorithm that mines recurrent subgraphs in the data graph along\nwith a second algorithm that, using the cheap utility measure, efficiently\nranks rules derived from these subgraphs. Finally, we prove theoretical\nguarantees on the utility of the learnt logical theory. As a result, we\ndemonstrate across various tasks that SPECTRUM scales to larger datasets, often\nlearning more accurate logical theories on CPUs in < 1% the runtime of SOTA\nneural network approaches on GPUs.",
      "tldr_zh": "该研究针对 probabilistic logical models 在 neurosymbolic AI 中的应用，指出其传统依赖手动构建导致成本高且易出错的问题，并提出一种高效学习方法。论文引入 precision and recall for logical rules 的概念，并定义 rule utility 作为一种低成本的预测力衡量标准，以优化逻辑理论的学习。作者开发了 SPECTRUM 框架，该框架利用线性时间算法挖掘数据图中的 recurrent subgraphs，并通过 cheap utility measure 高效排名派生规则，从而实现可扩展的学习过程。实验结果显示，SPECTRUM 在各种任务中扩展到更大数据集，比 SOTA neural network approaches 在 GPU 上更准确，且在 CPU 上运行时间不到 1%。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "21 pages",
      "pdf_url": "http://arxiv.org/pdf/2409.16238v2",
      "published_date": "2024-09-24 16:54:12 UTC",
      "updated_date": "2025-02-28 16:29:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:05:51.466803"
    },
    {
      "arxiv_id": "2409.16231v1",
      "title": "Predicting Deterioration in Mild Cognitive Impairment with Survival Transformers, Extreme Gradient Boosting and Cox Proportional Hazard Modelling",
      "title_zh": "翻译失败",
      "authors": [
        "Henry Musto",
        "Daniel Stamate",
        "Doina Logofatu",
        "Daniel Stahl"
      ],
      "abstract": "The paper proposes a novel approach of survival transformers and extreme\ngradient boosting models in predicting cognitive deterioration in individuals\nwith mild cognitive impairment (MCI) using metabolomics data in the ADNI\ncohort. By leveraging advanced machine learning and transformer-based\ntechniques applied in survival analysis, the proposed approach highlights the\npotential of these techniques for more accurate early detection and\nintervention in Alzheimer's dementia disease. This research also underscores\nthe importance of non-invasive biomarkers and innovative modelling tools in\nenhancing the accuracy of dementia risk assessments, offering new avenues for\nclinical practice and patient care. A comprehensive Monte Carlo simulation\nprocedure consisting of 100 repetitions of a nested cross-validation in which\nmodels were trained and evaluated, indicates that the survival machine learning\nmodels based on Transformer and XGBoost achieved the highest mean C-index\nperformances, namely 0.85 and 0.8, respectively, and that they are superior to\nthe conventional survival analysis Cox Proportional Hazards model which\nachieved a mean C-Index of 0.77. Moreover, based on the standard deviations of\nthe C-Index performances obtained in the Monte Carlo simulation, we established\nthat both survival machine learning models above are more stable than the\nconventional statistical model.",
      "tldr_zh": "本文提出了一种新方法，使用 Survival Transformers 和 Extreme Gradient Boosting (XGBoost) 模型，基于 ADNI 队列的代谢组学数据预测轻度认知障碍 (MCI) 患者认知恶化的风险，并与传统的 Cox Proportional Hazard Modelling 进行比较。实验通过 100 次 Monte Carlo 模拟和嵌套交叉验证显示，Survival Transformers 和 XGBoost 模型分别取得了 0.85 和 0.80 的平均 C-index 性能，均优于 Cox 模型的 0.77，且二者显示出更高的稳定性。研究强调了这些先进机器学习技术的潜力，有助于提升阿尔茨海默病早期检测和干预的准确性，提供非侵入性生物标志物的新应用途径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to ICANN 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.16231v1",
      "published_date": "2024-09-24 16:49:43 UTC",
      "updated_date": "2024-09-24 16:49:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:06:03.936090"
    },
    {
      "arxiv_id": "2409.16223v3",
      "title": "Fine-Tuning is Fine, if Calibrated",
      "title_zh": "翻译失败",
      "authors": [
        "Zheda Mai",
        "Arpita Chowdhury",
        "Ping Zhang",
        "Cheng-Hao Tu",
        "Hong-You Chen",
        "Vardaan Pahuja",
        "Tanya Berger-Wolf",
        "Song Gao",
        "Charles Stewart",
        "Yu Su",
        "Wei-Lun Chao"
      ],
      "abstract": "Fine-tuning is arguably the most straightforward way to tailor a pre-trained\nmodel (e.g., a foundation model) to downstream applications, but it also comes\nwith the risk of losing valuable knowledge the model had learned in\npre-training. For example, fine-tuning a pre-trained classifier capable of\nrecognizing a large number of classes to master a subset of classes at hand is\nshown to drastically degrade the model's accuracy in the other classes it had\npreviously learned. As such, it is hard to further use the fine-tuned model\nwhen it encounters classes beyond the fine-tuning data. In this paper, we\nsystematically dissect the issue, aiming to answer the fundamental question,\n\"What has been damaged in the fine-tuned model?\" To our surprise, we find that\nthe fine-tuned model neither forgets the relationship among the other classes\nnor degrades the features to recognize these classes. Instead, the fine-tuned\nmodel often produces more discriminative features for these other classes, even\nif they were missing during fine-tuning! {What really hurts the accuracy is the\ndiscrepant logit scales between the fine-tuning classes and the other classes},\nimplying that a simple post-processing calibration would bring back the\npre-trained model's capability and at the same time unveil the feature\nimprovement over all classes. We conduct an extensive empirical study to\ndemonstrate the robustness of our findings and provide preliminary explanations\nunderlying them, suggesting new directions for future theoretical analysis. Our\ncode is available at\nhttps://github.com/OSU-MLB/Fine-Tuning-Is-Fine-If-Calibrated.",
      "tldr_zh": "该研究探讨了 fine-tuning 预训练模型（如基础模型）时可能导致性能下降的问题，特别是对 fine-tuning 以外类别的准确率影响。作者发现，fine-tuned 模型并未忘记其他类别的关系或降低其特征识别能力，反而产生了更具区分性的特征；真正的问题在于 fine-tuning 类别的 logit scales 与其他类别的差异。论文提出一个简单的后处理 calibration 方法，能恢复模型的预训练能力，同时揭示特征改进；通过广泛实证研究验证了这些发现，并为未来理论分析提供新方向。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "The paper has been accepted to NeurIPS 2024. The first three authors\n  contribute equally",
      "pdf_url": "http://arxiv.org/pdf/2409.16223v3",
      "published_date": "2024-09-24 16:35:16 UTC",
      "updated_date": "2024-10-13 23:07:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:06:14.758815"
    },
    {
      "arxiv_id": "2409.16220v1",
      "title": "Towards Enhancing Linked Data Retrieval in Conversational UIs using Large Language Models",
      "title_zh": "使用大型语言模型提升对话式用户界面",
      "authors": [
        "Omar Mussa",
        "Omer Rana",
        "Benoît Goossens",
        "Pablo Orozco-Terwengel",
        "Charith Perera"
      ],
      "abstract": "Despite the recent broad adoption of Large Language Models (LLMs) across\nvarious domains, their potential for enriching information systems in\nextracting and exploring Linked Data (LD) and Resource Description Framework\n(RDF) triplestores has not been extensively explored. This paper examines the\nintegration of LLMs within existing systems, emphasising the enhancement of\nconversational user interfaces (UIs) and their capabilities for data extraction\nby producing more accurate SPARQL queries without the requirement for model\nretraining. Typically, conversational UI models necessitate retraining with the\nintroduction of new datasets or updates, limiting their functionality as\ngeneral-purpose extraction tools. Our approach addresses this limitation by\nincorporating LLMs into the conversational UI workflow, significantly enhancing\ntheir ability to comprehend and process user queries effectively. By leveraging\nthe advanced natural language understanding capabilities of LLMs, our method\nimproves RDF entity extraction within web systems employing conventional\nchatbots. This integration facilitates a more nuanced and context-aware\ninteraction model, critical for handling the complex query patterns often\nencountered in RDF datasets and Linked Open Data (LOD) endpoints. The\nevaluation of this methodology shows a marked enhancement in system\nexpressivity and the accuracy of responses to user queries, indicating a\npromising direction for future research in this area. This investigation not\nonly underscores the versatility of LLMs in enhancing existing information\nsystems but also sets the stage for further explorations into their potential\napplications within more specialised domains of web information systems.",
      "tldr_zh": "本文研究了如何利用 Large Language Models (LLMs) 提升对话式用户界面 (conversational UIs) 中的 Linked Data (LD) 检索，重点解决传统系统在提取 Resource Description Framework (RDF) 三元组时需要重新训练的问题。方法通过将 LLMs 整合到对话式 UI 工作流中，生成更准确的 SPARQL 查询，并增强对用户查询的理解和处理，实现更细致和上下文感知的交互。实验结果显示，该方法显著提高了系统的表达性和查询准确性，为 Linked Data 和 RDF 相关信息系统的未来应用提供了新方向。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "This paper has been accepted at the 25th International Web\n  Information Systems Engineering Conference (WISE 2024)",
      "pdf_url": "http://arxiv.org/pdf/2409.16220v1",
      "published_date": "2024-09-24 16:31:33 UTC",
      "updated_date": "2024-09-24 16:31:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:06:28.312616"
    },
    {
      "arxiv_id": "2409.16218v1",
      "title": "Problem-oriented AutoML in Clustering",
      "title_zh": "翻译失败",
      "authors": [
        "Matheus Camilo da Silva",
        "Gabriel Marques Tavares",
        "Eric Medvet",
        "Sylvio Barbon Junior"
      ],
      "abstract": "The Problem-oriented AutoML in Clustering (PoAC) framework introduces a\nnovel, flexible approach to automating clustering tasks by addressing the\nshortcomings of traditional AutoML solutions. Conventional methods often rely\non predefined internal Clustering Validity Indexes (CVIs) and static\nmeta-features, limiting their adaptability and effectiveness across diverse\nclustering tasks. In contrast, PoAC establishes a dynamic connection between\nthe clustering problem, CVIs, and meta-features, allowing users to customize\nthese components based on the specific context and goals of their task. At its\ncore, PoAC employs a surrogate model trained on a large meta-knowledge base of\nprevious clustering datasets and solutions, enabling it to infer the quality of\nnew clustering pipelines and synthesize optimal solutions for unseen datasets.\nUnlike many AutoML frameworks that are constrained by fixed evaluation metrics\nand algorithm sets, PoAC is algorithm-agnostic, adapting seamlessly to\ndifferent clustering problems without requiring additional data or retraining.\nExperimental results demonstrate that PoAC not only outperforms\nstate-of-the-art frameworks on a variety of datasets but also excels in\nspecific tasks such as data visualization, and highlight its ability to\ndynamically adjust pipeline configurations based on dataset complexity.",
      "tldr_zh": "该研究提出了一种问题导向的自动机器学习（AutoML）框架，即 Problem-oriented AutoML in Clustering (PoAC)，旨在解决传统 AutoML 在聚类任务中的局限性，如依赖预定义的 Clustering Validity Indexes (CVIs) 和静态 meta-features，从而提高适应性和有效性。PoAC 通过动态连接聚类问题、CVIs 和 meta-features，允许用户根据具体任务和目标进行自定义，并利用一个在 meta-knowledge base 上训练的 surrogate model 来评估新聚类管道的质量并生成最佳解决方案。不同于固定评估指标的框架，PoAC 是 algorithm-agnostic 的，能够无缝适应不同聚类问题，而无需额外数据或重新训练。实验结果显示，PoAC 在多种数据集上优于现有最先进框架，尤其在数据可视化等任务中，并能根据数据集复杂度动态调整管道配置。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.16218v1",
      "published_date": "2024-09-24 16:25:53 UTC",
      "updated_date": "2024-09-24 16:25:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:06:39.705764"
    },
    {
      "arxiv_id": "2409.16203v1",
      "title": "Facial Expression-Enhanced TTS: Combining Face Representation and Emotion Intensity for Adaptive Speech",
      "title_zh": "翻译失败",
      "authors": [
        "Yunji Chu",
        "Yunseob Shim",
        "Unsang Park"
      ],
      "abstract": "We propose FEIM-TTS, an innovative zero-shot text-to-speech (TTS) model that\nsynthesizes emotionally expressive speech, aligned with facial images and\nmodulated by emotion intensity. Leveraging deep learning, FEIM-TTS transcends\ntraditional TTS systems by interpreting facial cues and adjusting to emotional\nnuances without dependence on labeled datasets. To address sparse\naudio-visual-emotional data, the model is trained using LRS3, CREMA-D, and MELD\ndatasets, demonstrating its adaptability. FEIM-TTS's unique capability to\nproduce high-quality, speaker-agnostic speech makes it suitable for creating\nadaptable voices for virtual characters. Moreover, FEIM-TTS significantly\nenhances accessibility for individuals with visual impairments or those who\nhave trouble seeing. By integrating emotional nuances into TTS, our model\nenables dynamic and engaging auditory experiences for webcomics, allowing\nvisually impaired users to enjoy these narratives more fully. Comprehensive\nevaluation evidences its proficiency in modulating emotion and intensity,\nadvancing emotional speech synthesis and accessibility. Samples are available\nat: https://feim-tts.github.io/.",
      "tldr_zh": "我们提出 FEIM-TTS，一种创新的 zero-shot TTS 模型，它结合 Face Representation 和 Emotion Intensity 来合成与面部图像对齐的情感表达语音。模型利用深度学习从 LRS3、CREMA-D 和 MELD 数据集训练，超越传统 TTS 系统，通过解释面部线索和情感细微差别，而无需依赖标记数据集。实验结果显示，FEIM-TTS 能产生高质量、说话者无关的语音，提升了无障碍性，如为视力障碍者提供动态听觉体验，并适用于虚拟角色和网络漫画的适应性语音合成。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "13 pages, 3 figures, accepted to ECCV Workshop ABAW(Affective\n  Behavior Analysis in-the-wild)7 (to be appear)",
      "pdf_url": "http://arxiv.org/pdf/2409.16203v1",
      "published_date": "2024-09-24 16:01:12 UTC",
      "updated_date": "2024-09-24 16:01:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:06:51.949996"
    },
    {
      "arxiv_id": "2409.16202v2",
      "title": "CJEval: A Benchmark for Assessing Large Language Models Using Chinese Junior High School Exam Data",
      "title_zh": "翻译失败",
      "authors": [
        "Qian-Wen Zhang",
        "Haochen Wang",
        "Fang Li",
        "Siyu An",
        "Lingfeng Qiao",
        "Liangcai Gao",
        "Di Yin",
        "Xing Sun"
      ],
      "abstract": "Online education platforms have significantly transformed the dissemination\nof educational resources by providing a dynamic and digital infrastructure.\nWith the further enhancement of this transformation, the advent of Large\nLanguage Models (LLMs) has elevated the intelligence levels of these platforms.\nHowever, current academic benchmarks provide limited guidance for real-world\nindustry scenarios. This limitation arises because educational applications\nrequire more than mere test question responses. To bridge this gap, we\nintroduce CJEval, a benchmark based on Chinese Junior High School Exam\nEvaluations. CJEval consists of 26,136 samples across four application-level\neducational tasks covering ten subjects. These samples include not only\nquestions and answers but also detailed annotations such as question types,\ndifficulty levels, knowledge concepts, and answer explanations. By utilizing\nthis benchmark, we assessed LLMs' potential applications and conducted a\ncomprehensive analysis of their performance by fine-tuning on various\neducational tasks. Extensive experiments and discussions have highlighted the\nopportunities and challenges of applying LLMs in the field of education.",
      "tldr_zh": "本研究针对大型语言模型（LLMs）在教育领域的实际应用，提出CJEval基准，这是一个基于中国初中考试数据的评估工具，以弥补现有基准对行业场景指导不足的问题。CJEval包含26,136个样本，覆盖四个应用级教育任务和十个科目，并提供详细注解如问题类型、难度级别、知识概念和答案解释。研究通过该基准评估LLMs的性能，包括在各种教育任务上的微调实验，结果揭示了LLMs在教育领域的机会与挑战，并为实际应用提供指导。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.16202v2",
      "published_date": "2024-09-24 16:00:28 UTC",
      "updated_date": "2024-09-25 03:35:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:07:02.351681"
    },
    {
      "arxiv_id": "2409.16198v1",
      "title": "Leveraging Estimated Transferability Over Human Intuition for Model Selection in Text Ranking",
      "title_zh": "在",
      "authors": [
        "Jun Bai",
        "Zhuofan Chen",
        "Zhenzi Li",
        "Hanhua Hong",
        "Jianfei Zhang",
        "Chen Li",
        "Chenghua Lin",
        "Wenge Rong"
      ],
      "abstract": "Text ranking has witnessed significant advancements, attributed to the\nutilization of dual-encoder enhanced by Pre-trained Language Models (PLMs).\nGiven the proliferation of available PLMs, selecting the most effective one for\na given dataset has become a non-trivial challenge. As a promising alternative\nto human intuition and brute-force fine-tuning, Transferability Estimation (TE)\nhas emerged as an effective approach to model selection. However, current TE\nmethods are primarily designed for classification tasks, and their estimated\ntransferability may not align well with the objectives of text ranking. To\naddress this challenge, we propose to compute the expected rank as\ntransferability, explicitly reflecting the model's ranking capability.\nFurthermore, to mitigate anisotropy and incorporate training dynamics, we\nadaptively scale isotropic sentence embeddings to yield an accurate expected\nrank score. Our resulting method, Adaptive Ranking Transferability (AiRTran),\ncan effectively capture subtle differences between models. On challenging model\nselection scenarios across various text ranking datasets, it demonstrates\nsignificant improvements over previous classification-oriented TE methods,\nhuman intuition, and ChatGPT with minor time consumption.",
      "tldr_zh": "这篇论文针对文本排序任务中模型选择难题，提出利用 Transferability Estimation (TE) 代替人类直觉和暴力微调，以选择最有效的 Pre-trained Language Models (PLMs)。他们开发了 Adaptive Ranking Transferability (AiRTran) 方法，通过计算 expected rank 来评估模型的排序能力，并通过适配性地缩放句子嵌入来缓解各向异性和整合训练动态。实验结果显示，AiRTran 在各种文本排序数据集上显著优于现有的分类导向 TE 方法、人类直觉和 ChatGPT，同时保持较低的时间消耗。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by EMNLP 2024 main conference",
      "pdf_url": "http://arxiv.org/pdf/2409.16198v1",
      "published_date": "2024-09-24 15:48:03 UTC",
      "updated_date": "2024-09-24 15:48:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:07:15.722191"
    },
    {
      "arxiv_id": "2409.16197v3",
      "title": "Second Order Bounds for Contextual Bandits with Function Approximation",
      "title_zh": "翻译失败",
      "authors": [
        "Aldo Pacchiano"
      ],
      "abstract": "Many works have developed no-regret algorithms for contextual bandits with\nfunction approximation, where the mean reward function over context-action\npairs belongs to a function class. Although there are many approaches to this\nproblem, one that has gained in importance is the use of algorithms based on\nthe optimism principle such as optimistic least squares. It can be shown the\nregret of this algorithm scales as square root of the product of the eluder\ndimension (a statistical measure of the complexity of the function class), the\nlogarithm of the function class size and the time horizon. Unfortunately, even\nif the variance of the measurement noise of the rewards at each time is\nchanging and is very small, the regret of the optimistic least squares\nalgorithm scales with square root of the time horizon. In this work we are the\nfirst to develop algorithms that satisfy regret bounds of scaling not with the\nsquare root of the time horizon, but the square root of the sum of the\nmeasurement variances in the setting of contextual bandits with function\napproximation when the variances are unknown. These bounds generalize existing\ntechniques for deriving second order bounds in contextual linear problems.",
      "tldr_zh": "这篇论文针对带有函数逼近的上下文 bandit 问题，开发了新的算法，以改进遗憾（regret）边界。现有基于乐观原则（如乐观最小二乘）的算法，遗憾通常与 eluder dimension、函数类大小的对数和时间视野的平方根成比例，但本文首次提出算法，使遗憾仅与测量方差之和的平方根相关，即使方差未知。这样的二阶边界推广了上下文线性问题中的现有技术，提高了算法在低方差场景下的性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "13 pages main, 34 pages total",
      "pdf_url": "http://arxiv.org/pdf/2409.16197v3",
      "published_date": "2024-09-24 15:42:04 UTC",
      "updated_date": "2025-03-15 19:53:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:07:28.479562"
    },
    {
      "arxiv_id": "2409.16176v1",
      "title": "Cyber Knowledge Completion Using Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Braden K Webb",
        "Sumit Purohit",
        "Rounak Meyur"
      ],
      "abstract": "The integration of the Internet of Things (IoT) into Cyber-Physical Systems\n(CPSs) has expanded their cyber-attack surface, introducing new and\nsophisticated threats with potential to exploit emerging vulnerabilities.\nAssessing the risks of CPSs is increasingly difficult due to incomplete and\noutdated cybersecurity knowledge. This highlights the urgent need for\nbetter-informed risk assessments and mitigation strategies. While previous\nefforts have relied on rule-based natural language processing (NLP) tools to\nmap vulnerabilities, weaknesses, and attack patterns, recent advancements in\nLarge Language Models (LLMs) present a unique opportunity to enhance\ncyber-attack knowledge completion through improved reasoning, inference, and\nsummarization capabilities. We apply embedding models to encapsulate\ninformation on attack patterns and adversarial techniques, generating mappings\nbetween them using vector embeddings. Additionally, we propose a\nRetrieval-Augmented Generation (RAG)-based approach that leverages pre-trained\nmodels to create structured mappings between different taxonomies of threat\npatterns. Further, we use a small hand-labeled dataset to compare the proposed\nRAG-based approach to a baseline standard binary classification model. Thus,\nthe proposed approach provides a comprehensive framework to address the\nchallenge of cyber-attack knowledge graph completion.",
      "tldr_zh": "这篇论文针对物联网(IoT)与网络物理系统(CPS)的整合导致的网络攻击风险评估难题，提出利用Large Language Models (LLMs)来完成和更新不完整的安全知识。方法包括使用embedding模型封装攻击模式和对抗技术的信息，并开发Retrieval-Augmented Generation (RAG)-based方法创建不同威胁分类之间的结构化映射。实验通过小规模手工标记数据集将RAG方法与标准二分类模型比较，证明了其有效性，为网络攻击知识图完成提供了一个全面框架。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "J.7; H.3.3"
      ],
      "primary_category": "cs.CR",
      "comment": "7 pages, 2 figures. Submitted to 2024 IEEE International Conference\n  on Big Data",
      "pdf_url": "http://arxiv.org/pdf/2409.16176v1",
      "published_date": "2024-09-24 15:20:39 UTC",
      "updated_date": "2024-09-24 15:20:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:07:39.158981"
    },
    {
      "arxiv_id": "2409.16167v3",
      "title": "Merging LoRAs like Playing LEGO: Pushing the Modularity of LoRA to Extremes Through Rank-Wise Clustering",
      "title_zh": "翻译失败",
      "authors": [
        "Ziyu Zhao",
        "Tao Shen",
        "Didi Zhu",
        "Zexi Li",
        "Jing Su",
        "Xuwu Wang",
        "Kun Kuang",
        "Fei Wu"
      ],
      "abstract": "Low-Rank Adaptation (LoRA) has emerged as a popular technique for fine-tuning\nlarge language models (LLMs) to various domains due to its modular design and\nwidespread availability on platforms like Huggingface. This modularity has\nsparked interest in combining multiple LoRAs to enhance LLM capabilities.\nHowever, existing methods for LoRA composition primarily focus on task-specific\nadaptations that require additional training, and current model merging\ntechniques often fail to fully leverage LoRA's modular nature, leading to\nparameter interference and performance degradation. In this paper, we\ninvestigate the feasibility of disassembling and reassembling multiple LoRAs at\na finer granularity, analogous to assembling LEGO blocks. We introduce the\nconcept of Minimal Semantic Units (MSUs), where the parameters corresponding to\neach rank in LoRA function as independent units. These MSUs demonstrate\npermutation invariance and concatenation-summation equivalence properties,\nenabling flexible combinations to create new LoRAs. Building on these insights,\nwe propose the LoRA-LEGO framework. This framework conducts rank-wise parameter\nclustering by grouping MSUs from different LoRAs into $k$ clusters. The\ncentroid of each cluster serves as a representative MSU, enabling the assembly\nof a merged LoRA with an adjusted rank of $k$. Additionally, we apply a dual\nreweighting strategy to optimize the scale of the merged LoRA. Experiments\nacross various benchmarks demonstrate that our method outperforms existing\napproaches in LoRA merging.",
      "tldr_zh": "该论文探讨了如何像搭建乐高积木一样合并 Low-Rank Adaptation (LoRA) 模块，以最大化其模块化优势。作者引入 Minimal Semantic Units (MSUs) 概念，将 LoRA 中的每个 rank 参数视为独立单位，并利用其 permutation invariance 和 concatenation-summation equivalence 属性，实现灵活的 LoRA 拆解和重组。LoRA-LEGO 框架通过 rank-wise clustering 将不同 LoRA 的 MSUs 分组为 k 簇，并应用双重再加权策略优化合并后的 LoRA。在多种基准测试中，该方法显著优于现有技术，展示了更高的性能和更少的参数干扰。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.16167v3",
      "published_date": "2024-09-24 15:08:41 UTC",
      "updated_date": "2024-10-22 02:29:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:07:51.780002"
    },
    {
      "arxiv_id": "2409.16165v2",
      "title": "Interactive Tools Substantially Assist LM Agents in Finding Security Vulnerabilities",
      "title_zh": "交互工具显著辅助 LM 代理发现安全漏洞",
      "authors": [
        "Talor Abramovich",
        "Meet Udeshi",
        "Minghao Shao",
        "Kilian Lieret",
        "Haoran Xi",
        "Kimberly Milner",
        "Sofija Jancheska",
        "John Yang",
        "Carlos E. Jimenez",
        "Farshad Khorrami",
        "Prashanth Krishnamurthy",
        "Brendan Dolan-Gavitt",
        "Muhammad Shafique",
        "Karthik Narasimhan",
        "Ramesh Karri",
        "Ofir Press"
      ],
      "abstract": "Although language model (LM) agents have demonstrated increased performance\nin multiple domains, including coding and web-browsing, their success in\ncybersecurity has been limited. We present EnIGMA, an LM agent for autonomously\nsolving Capture The Flag (CTF) challenges. We introduce new tools and\ninterfaces to improve the agent's ability to find and exploit security\nvulnerabilities, focusing on interactive terminal programs. These novel\nInteractive Agent Tools enable LM agents, for the first time, to run\ninteractive utilities, such as a debugger and a server connection tool, which\nare essential for solving these challenges. Empirical analysis on 390 CTF\nchallenges across four benchmarks demonstrate that these new tools and\ninterfaces substantially improve our agent's performance, achieving\nstate-of-the-art results on NYU CTF, Intercode-CTF, and CyBench. Finally, we\nanalyze data leakage, developing new methods to quantify it and identifying a\nnew phenomenon we term soliloquizing, where the model self-generates\nhallucinated observations without interacting with the environment. Our code\nand development dataset are available at\nhttps://github.com/SWE-agent/SWE-agent/tree/v0.7 and\nhttps://github.com/NYU-LLM-CTF/NYU_CTF_Bench/tree/main/development\nrespectively.",
      "tldr_zh": "该研究提出 EnIGMA，一种自主语言模型 (LM) 代理，用于解决 Capture The Flag (CTF) 挑战，从而提升 LM agents 在网络安全领域的性能。研究引入了新的 Interactive Agent Tools 和接口，这些工具允许代理运行交互式实用程序，如调试器和服务器连接工具，以更好地发现和利用安全漏洞。实验在 390 个 CTF 挑战上显示，EnIGMA 在 NYU CTF、Intercode-CTF 和 CyBench 等基准上实现了最先进的结果，性能大幅提升；此外，研究分析了数据泄漏问题，并首次识别了“soliloquizing”现象，即模型自生成幻觉观察而不与环境交互。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.16165v2",
      "published_date": "2024-09-24 15:06:01 UTC",
      "updated_date": "2025-02-04 09:49:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:08:04.751379"
    },
    {
      "arxiv_id": "2409.16143v1",
      "title": "Seeing Faces in Things: A Model and Dataset for Pareidolia",
      "title_zh": "翻译失败",
      "authors": [
        "Mark Hamilton",
        "Simon Stent",
        "Vasha DuTell",
        "Anne Harrington",
        "Jennifer Corbett",
        "Ruth Rosenholtz",
        "William T. Freeman"
      ],
      "abstract": "The human visual system is well-tuned to detect faces of all shapes and\nsizes. While this brings obvious survival advantages, such as a better chance\nof spotting unknown predators in the bush, it also leads to spurious face\ndetections. ``Face pareidolia'' describes the perception of face-like structure\namong otherwise random stimuli: seeing faces in coffee stains or clouds in the\nsky. In this paper, we study face pareidolia from a computer vision\nperspective. We present an image dataset of ``Faces in Things'', consisting of\nfive thousand web images with human-annotated pareidolic faces. Using this\ndataset, we examine the extent to which a state-of-the-art human face detector\nexhibits pareidolia, and find a significant behavioral gap between humans and\nmachines. We find that the evolutionary need for humans to detect animal faces,\nas well as human faces, may explain some of this gap. Finally, we propose a\nsimple statistical model of pareidolia in images. Through studies on human\nsubjects and our pareidolic face detectors we confirm a key prediction of our\nmodel regarding what image conditions are most likely to induce pareidolia.\nDataset and Website: https://aka.ms/faces-in-things",
      "tldr_zh": "这篇论文从计算机视觉角度研究了 pareidolia（在随机刺激中看到脸的现象），探讨了人类视觉系统与机器检测器的差异。研究者构建了一个名为 \"Faces in Things\" 的图像数据集，包含五千张网络图像，并由人类标注 pareidolic faces，以评估最先进的人脸检测器的表现，结果显示机器与人类在 pareidolia 行为上存在显著差距，可能源于人类进化的动物和人类脸部检测需求。论文还提出一个简单的统计模型来解释图像中 pareidolia 的条件，并通过人类实验和检测器验证确认了模型的关键预测。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.HC",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.16143v1",
      "published_date": "2024-09-24 14:50:21 UTC",
      "updated_date": "2024-09-24 14:50:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:08:15.709737"
    },
    {
      "arxiv_id": "2409.16136v1",
      "title": "HA-FGOVD: Highlighting Fine-grained Attributes via Explicit Linear Composition for Open-Vocabulary Object Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Yuqi Ma",
        "Mengyin Liu",
        "Chao Zhu",
        "Xu-Cheng Yin"
      ],
      "abstract": "Open-vocabulary object detection (OVD) models are considered to be Large\nMulti-modal Models (LMM), due to their extensive training data and a large\nnumber of parameters. Mainstream OVD models prioritize object coarse-grained\ncategory rather than focus on their fine-grained attributes, e.g., colors or\nmaterials, thus failed to identify objects specified with certain attributes.\nHowever, OVD models are pretrained on large-scale image-text pairs with rich\nattribute words, whose latent feature space can represent the global text\nfeature as a linear composition of fine-grained attribute tokens without\nhighlighting them. Therefore, we propose in this paper a universal and explicit\napproach for frozen mainstream OVD models that boosts their attribute-level\ndetection capabilities by highlighting fine-grained attributes in explicit\nlinear space. Firstly, a LLM is leveraged to highlight attribute words within\nthe input text as a zero-shot prompted task. Secondly, by strategically\nadjusting the token masks, the text encoders of OVD models extract both global\ntext and attribute-specific features, which are then explicitly composited as\ntwo vectors in linear space to form the new attribute-highlighted feature for\ndetection tasks, where corresponding scalars are hand-crafted or learned to\nreweight both two vectors. Notably, these scalars can be seamlessly transferred\namong different OVD models, which proves that such an explicit linear\ncomposition is universal. Empirical evaluation on the FG-OVD dataset\ndemonstrates that our proposed method uniformly improves fine-grained\nattribute-level OVD of various mainstream models and achieves new\nstate-of-the-art performance.",
      "tldr_zh": "该论文提出 HA-FGOVD 方法，旨在提升 Open-vocabulary Object Detection (OVD) 模型的细粒度属性检测能力，因为主流 OVD 模型更注重对象的粗粒度类别（如类别名称），而忽略了属性（如颜色或材料）。方法首先利用 Large Language Model (LLM) 通过零样本提示任务突出输入文本中的属性词，然后通过调整 token masks 提取全局文本特征和属性特定特征，并在显式线性空间中组合这些特征，并使用手工或学习得到的标量进行重新加权，以形成新的属性突出特征。实验结果显示，该方法在 FG-OVD 数据集上显著提高了各种主流 OVD 模型的性能，并实现了新的 state-of-the-art 水平，证明了其通用性和可转移性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "This work has been submitted to the IEEE for possible publication",
      "pdf_url": "http://arxiv.org/pdf/2409.16136v1",
      "published_date": "2024-09-24 14:43:14 UTC",
      "updated_date": "2024-09-24 14:43:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:08:29.014545"
    },
    {
      "arxiv_id": "2409.16133v1",
      "title": "Implicit assessment of language learning during practice as accurate as explicit testing",
      "title_zh": "翻译失败",
      "authors": [
        "Jue Hou",
        "Anisia Katinskaia",
        "Anh-Duc Vu",
        "Roman Yangarber"
      ],
      "abstract": "Assessment of proficiency of the learner is an essential part of Intelligent\nTutoring Systems (ITS). We use Item Response Theory (IRT) in computer-aided\nlanguage learning for assessment of student ability in two contexts: in test\nsessions, and in exercises during practice sessions. Exhaustive testing across\na wide range of skills can provide a detailed picture of proficiency, but may\nbe undesirable for a number of reasons. Therefore, we first aim to replace\nexhaustive tests with efficient but accurate adaptive tests. We use learner\ndata collected from exhaustive tests under imperfect conditions, to train an\nIRT model to guide adaptive tests. Simulations and experiments with real\nlearner data confirm that this approach is efficient and accurate. Second, we\nexplore whether we can accurately estimate learner ability directly from the\ncontext of practice with exercises, without testing. We transform learner data\ncollected from exercise sessions into a form that can be used for IRT modeling.\nThis is done by linking the exercises to {\\em linguistic constructs}; the\nconstructs are then treated as \"items\" within IRT. We present results from\nlarge-scale studies with thousands of learners. Using teacher assessments of\nstudent ability as \"ground truth,\" we compare the estimates obtained from tests\nvs. those from exercises. The experiments confirm that the IRT models can\nproduce accurate ability estimation based on exercises.",
      "tldr_zh": "本文使用 Item Response Theory (IRT) 在 Intelligent Tutoring Systems (ITS) 中评估语言学习者的能力，比较了显式测试和隐式练习两种方式。研究首先开发了高效的适应性测试，通过模拟和实验证明其准确性与全面测试相当，避免了测试负担。接着，将练习数据转化为 IRT 模型的输入形式，将练习链接到 linguistic constructs 并视为“items”，大规模研究结果显示，这种基于练习的隐式评估能与显式测试一样准确地估计学习者能力。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.16133v1",
      "published_date": "2024-09-24 14:40:44 UTC",
      "updated_date": "2024-09-24 14:40:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:08:38.705032"
    },
    {
      "arxiv_id": "2409.16125v3",
      "title": "Analyzing Probabilistic Methods for Evaluating Agent Capabilities",
      "title_zh": "分析评估代理能力的概率方法",
      "authors": [
        "Axel Højmark",
        "Govind Pimpale",
        "Arjun Panickssery",
        "Marius Hobbhahn",
        "Jérémy Scheurer"
      ],
      "abstract": "To mitigate risks from AI systems, we need to assess their capabilities\naccurately. This is especially difficult in cases where capabilities are only\nrarely displayed. Phuong et al. propose two methods that aim to obtain better\nestimates of the probability of an AI agent successfully completing a given\ntask. The milestone method decomposes tasks into subtasks, aiming to improve\noverall success rate estimation, while the expert best-of-N method leverages\nhuman guidance as a proxy for the model's independent performance.\n  Our analysis of these methods as Monte Carlo estimators reveals that while\nboth effectively reduce variance compared to naive Monte Carlo sampling, they\nalso introduce bias. Experimental results demonstrate that the milestone method\nunderestimates true solve rates for many real-world tasks due to its\nconstraining assumptions. The expert best-of-N method exhibits even more severe\nunderestimation across all tasks, attributed to an inherently flawed\nre-weighting factor. To enhance the accuracy of capability estimates of AI\nagents on difficult tasks, we suggest future work should leverage the rich\nliterature on Monte Carlo Estimators.",
      "tldr_zh": "该论文分析了评估 AI 代理能力的概率方法，特别是 Phuong et al. 提出的 milestone method 和 expert best-of-N method，前者通过分解任务为子任务来改善成功率估计，后者利用人类指导作为模型性能代理。作者将这些方法视为 Monte Carlo 估计器，发现它们虽然能有效减少方差，但同时引入了偏差。实验结果显示，milestone method 因假设限制而低估了许多真实任务的解决率，而 expert best-of-N method 则在所有任务中表现出更严重的低估问题。论文建议，未来研究应借鉴 Monte Carlo Estimators 的丰富文献，以提升 AI 代理能力评估的准确性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted (Poster) to SoLaR 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.16125v3",
      "published_date": "2024-09-24 14:35:20 UTC",
      "updated_date": "2024-10-11 21:10:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:08:52.513419"
    },
    {
      "arxiv_id": "2409.16120v1",
      "title": "MOSS: Enabling Code-Driven Evolution and Context Management for AI Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Ming Zhu",
        "Yi Zhou"
      ],
      "abstract": "Developing AI agents powered by large language models (LLMs) faces\nsignificant challenges in achieving true Turing completeness and adaptive,\ncode-driven evolution. Current approaches often generate code independently of\nits runtime context, relying heavily on the LLM's memory, which results in\ninefficiencies and limits adaptability. Manual protocol development in sandbox\nenvironments further constrains the agent's autonomous adaptability. Crucially,\nachieving consistency in code and context across multi-turn interactions and\nensuring isolation of local variables within each interaction remains an\nunsolved problem.\n  We introduce MOSS (llM-oriented Operating System Simulation), a novel\nframework that addresses these challenges by integrating code generation with a\ndynamic context management system. MOSS ensures consistency and adaptability by\nusing a mechanism that maintains the Python context across interactions,\nincluding isolation of local variables and preservation of runtime integrity.\nAt its core, the framework employs an Inversion of Control (IoC) container in\nconjunction with decorators to enforce the least knowledge principle, allowing\nagents to focus on abstract interfaces rather than concrete implementations.\nThis facilitates seamless integration of new tools and libraries, enables\nruntime instance replacement, and reduces prompt complexity, providing a \"what\nyou see is what you get\" environment for the agent.\n  Through a series of case studies, we show how this framework can enhance the\nefficiency and capabilities of agent development and highlight its advantages\nin moving towards Turing-complete agents capable of evolving through code.",
      "tldr_zh": "论文介绍了 MOSS 框架（llM-oriented Operating System Simulation），旨在解决基于大型语言模型(LLMs)的 AI 代理在实现图灵完备性和代码驱动演化中的挑战，如代码与运行时上下文脱节和多轮交互一致性问题。MOSS 通过整合代码生成与动态上下文管理系统，确保 Python 上下文的连续性，包括本地变量隔离和运行时完整性，并采用 Inversion of Control (IoC) 容器及装饰器强制最小知识原则。框架允许代理专注于抽象接口，便于集成新工具、库和运行时实例替换，减少提示复杂性，提供“what you see is what you get”环境。通过案例研究，MOSS 显著提升了代理开发效率，推动了向真正图灵完备代理的演化。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.16120v1",
      "published_date": "2024-09-24 14:30:21 UTC",
      "updated_date": "2024-09-24 14:30:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:09:04.854616"
    },
    {
      "arxiv_id": "2409.18807v1",
      "title": "LLM With Tools: A Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Zhuocheng Shen"
      ],
      "abstract": "The integration of tools in augmenting large language models presents a novel\napproach toward enhancing the efficiency and accuracy of these models in\nhandling specific, complex tasks. This paper delves into the\nmethodology,challenges, and developments in the realm of teaching LLMs to use\nexternal tools, thereby pushing the boundaries of their capabilities beyond\npre-existing knowledge bases. We introduce a standardized paradigm for tool\nintegration guided by a series of functions that map user instructions to\nactionable plans and their execution, emphasizing the significance of\nunderstanding user intent, tool selection, and dynamic plan adjustment. Our\nexploration reveals the various challenges encountered, such as tool invocation\ntiming, selection accuracy, and the need for robust reasoning processes. In\naddressing these challenges, we investigate techniques within the context of\nfine-tuning and incontext learning paradigms, highlighting innovative\napproaches to ensure diversity, augment datasets, and improve\ngeneralization.Furthermore, we investigate a perspective on enabling LLMs to\nnot only utilize but also autonomously create tools, which may redefine their\nrole from mere tool users to tool creators. Finally,we reproduced Chameleon's\nresults on ScienceQA and analyzed the code structure.",
      "tldr_zh": "这篇调查论文探讨了将外部工具整合到大型语言模型 (LLMs) 中的方法，以提升其处理复杂任务的效率和准确性。论文引入了一个标准化范式，通过一系列函数将用户指令映射为可执行计划，强调理解用户意图、工具选择和动态调整的重要性。针对挑战如工具调用时机、选择准确性和推理过程的鲁棒性，研究调查了 fine-tuning 和 in-context learning 等技术，以增强数据集多样性和模型泛化能力。此外，论文探讨了 LLMs 从工具用户向工具创建者转型的可能性，并通过重现 Chameleon 的结果在 ScienceQA 上验证了这些方法的效果。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages",
      "pdf_url": "http://arxiv.org/pdf/2409.18807v1",
      "published_date": "2024-09-24 14:08:11 UTC",
      "updated_date": "2024-09-24 14:08:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:09:18.231974"
    },
    {
      "arxiv_id": "2409.16106v2",
      "title": "Scenario of Use Scheme: Threat Model Specification for Speaker Privacy Protection in the Medical Domain",
      "title_zh": "翻译失败",
      "authors": [
        "Mehtab Ur Rahman",
        "Martha Larson",
        "Louis ten Bosch",
        "Cristian Tejedor-García"
      ],
      "abstract": "Speech recordings are being more frequently used to detect and monitor\ndisease, leading to privacy concerns. Beyond cryptography, protection of speech\ncan be addressed by approaches, such as perturbation, disentanglement, and\nre-synthesis, that eliminate sensitive information of the speaker, leaving the\ninformation necessary for medical analysis purposes. In order for such privacy\nprotective approaches to be developed, clear and systematic specifications of\nassumptions concerning medical settings and the needs of medical professionals\nare necessary. In this paper, we propose a Scenario of Use Scheme that\nincorporates an Attacker Model, which characterizes the adversary against whom\nthe speaker's privacy must be defended, and a Protector Model, which specifies\nthe defense. We discuss the connection of the scheme with previous work on\nspeech privacy. Finally, we present a concrete example of a specified Scenario\nof Use and a set of experiments about protecting speaker data against gender\ninference attacks while maintaining utility for Parkinson's detection.",
      "tldr_zh": "该论文针对语音记录在医疗领域的使用引发的隐私问题，提出了一种Scenario of Use Scheme框架，用于系统化指定威胁模型。该框架包括Attacker Model（描述潜在攻击者）和Protector Model（定义防御机制），以帮助开发隐私保护方法，如perturbation、disentanglement和re-synthesis，从而消除敏感的说话者信息，同时保留医疗分析所需的数据。作者讨论了该方案与现有语音隐私研究的联系，并通过一个具体例子展示了如何保护说话者数据免受gender inference attacks，同时保持Parkinson's detection的效用。实验结果验证了该方法的有效性，为医疗语音隐私保护提供了清晰的指导。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CR",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "Accepted and published at SPSC Symposium 2024 4th Symposium on\n  Security and Privacy in Speech Communication. Interspeech 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.16106v2",
      "published_date": "2024-09-24 14:07:47 UTC",
      "updated_date": "2024-09-26 13:05:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:09:29.509213"
    },
    {
      "arxiv_id": "2409.16099v1",
      "title": "Neuromorphic Drone Detection: an Event-RGB Multimodal Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Gabriele Magrini",
        "Federico Becattini",
        "Pietro Pala",
        "Alberto Del Bimbo",
        "Antonio Porta"
      ],
      "abstract": "In recent years, drone detection has quickly become a subject of extreme\ninterest: the potential for fast-moving objects of contained dimensions to be\nused for malicious intents or even terrorist attacks has posed attention to the\nnecessity for precise and resilient systems for detecting and identifying such\nelements. While extensive literature and works exist on object detection based\non RGB data, it is also critical to recognize the limits of such modality when\napplied to UAVs detection. Detecting drones indeed poses several challenges\nsuch as fast-moving objects and scenes with a high dynamic range or, even\nworse, scarce illumination levels. Neuromorphic cameras, on the other hand, can\nretain precise and rich spatio-temporal information in situations that are\nchallenging for RGB cameras. They are resilient to both high-speed moving\nobjects and scarce illumination settings, while prone to suffer a rapid loss of\ninformation when the objects in the scene are static. In this context, we\npresent a novel model for integrating both domains together, leveraging\nmultimodal data to take advantage of the best of both worlds. To this end, we\nalso release NeRDD (Neuromorphic-RGB Drone Detection), a novel\nspatio-temporally synchronized Event-RGB Drone detection dataset of more than\n3.5 hours of multimodal annotated recordings.",
      "tldr_zh": "该论文探讨了无人机检测面临的挑战，如快速移动物体和高动态范围或光线不足的场景中RGB数据 modality 的局限性。作者提出了一种Event-RGB多模态方法，将Neuromorphic cameras 的精确时空信息与RGB数据相结合，实现更可靠的检测。论文的主要贡献包括发布NeRDD数据集，该数据集包含超过3.5小时的同步标注的多模态记录，并展示了这种整合方法的潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at NeVi Workshop at ECCV24",
      "pdf_url": "http://arxiv.org/pdf/2409.16099v1",
      "published_date": "2024-09-24 13:53:20 UTC",
      "updated_date": "2024-09-24 13:53:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:09:40.476832"
    },
    {
      "arxiv_id": "2409.16098v2",
      "title": "The Digital Transformation in Health: How AI Can Improve the Performance of Health Systems",
      "title_zh": "健康领域的数字化转型：AI 如何改善健康系统的性能",
      "authors": [
        "África Periáñez",
        "Ana Fernández del Río",
        "Ivan Nazarov",
        "Enric Jané",
        "Moiz Hassan",
        "Aditya Rastogi",
        "Dexian Tang"
      ],
      "abstract": "Mobile health has the potential to revolutionize health care delivery and\npatient engagement. In this work, we discuss how integrating Artificial\nIntelligence into digital health applications-focused on supply chain, patient\nmanagement, and capacity building, among other use cases-can improve the health\nsystem and public health performance. We present an Artificial Intelligence and\nReinforcement Learning platform that allows the delivery of adaptive\ninterventions whose impact can be optimized through experimentation and\nreal-time monitoring. The system can integrate multiple data sources and\ndigital health applications. The flexibility of this platform to connect to\nvarious mobile health applications and digital devices and send personalized\nrecommendations based on past data and predictions can significantly improve\nthe impact of digital tools on health system outcomes. The potential for\nresource-poor settings, where the impact of this approach on health outcomes\ncould be more decisive, is discussed specifically. This framework is, however,\nsimilarly applicable to improving efficiency in health systems where scarcity\nis not an issue.",
      "tldr_zh": "本论文探讨了人工智能（AI）在数字健康领域的应用，特别是如何通过整合AI来提升健康系统的表现，包括供应链、患者管理和能力建设等关键领域。研究提出一个基于AI和强化学习（Reinforcement Learning）的平台，该平台支持自适应干预，通过实验、实时监控和多数据源整合，提供个性化的健康推荐，从而优化健康结果。该平台在资源匮乏地区具有显著潜力，同时适用于各种健康系统，以提高整体效率和公共卫生表现。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY",
        "cs.HC"
      ],
      "primary_category": "cs.LG",
      "comment": "This is an original manuscript of an article published by Taylor &\n  Francis in Health Systems & Reform on 22 Oct 2024, available online:\n  https://www.tandfonline.com/doi/10.1080/23288604.2024.2387138",
      "pdf_url": "http://arxiv.org/pdf/2409.16098v2",
      "published_date": "2024-09-24 13:52:15 UTC",
      "updated_date": "2024-11-21 09:24:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:09:52.700032"
    },
    {
      "arxiv_id": "2409.16089v2",
      "title": "From Pixels to Words: Leveraging Explainability in Face Recognition through Interactive Natural Language Processing",
      "title_zh": "翻译失败",
      "authors": [
        "Ivan DeAndres-Tame",
        "Muhammad Faisal",
        "Ruben Tolosana",
        "Rouqaiah Al-Refai",
        "Ruben Vera-Rodriguez",
        "Philipp Terhörst"
      ],
      "abstract": "Face Recognition (FR) has advanced significantly with the development of deep\nlearning, achieving high accuracy in several applications. However, the lack of\ninterpretability of these systems raises concerns about their accountability,\nfairness, and reliability. In the present study, we propose an interactive\nframework to enhance the explainability of FR models by combining\nmodel-agnostic Explainable Artificial Intelligence (XAI) and Natural Language\nProcessing (NLP) techniques. The proposed framework is able to accurately\nanswer various questions of the user through an interactive chatbot. In\nparticular, the explanations generated by our proposed method are in the form\nof natural language text and visual representations, which for example can\ndescribe how different facial regions contribute to the similarity measure\nbetween two faces. This is achieved through the automatic analysis of the\noutput's saliency heatmaps of the face images and a BERT question-answering\nmodel, providing users with an interface that facilitates a comprehensive\nunderstanding of the FR decisions. The proposed approach is interactive,\nallowing the users to ask questions to get more precise information based on\nthe user's background knowledge. More importantly, in contrast to previous\nstudies, our solution does not decrease the face recognition performance. We\ndemonstrate the effectiveness of the method through different experiments,\nhighlighting its potential to make FR systems more interpretable and\nuser-friendly, especially in sensitive applications where decision-making\ntransparency is crucial.",
      "tldr_zh": "本篇论文针对面部识别（FR）系统的可解释性不足问题，提出一个交互式框架，将模型无关的Explainable Artificial Intelligence (XAI) 和Natural Language Processing (NLP) 技术相结合。框架通过分析面部图像的显著性热图（saliency heatmaps）和BERT问答模型，生成自然语言文本和视觉表示的解释，例如描述不同面部区域对相似度测量的贡献，并允许用户通过聊天机器人提问获取个性化信息。与以往研究不同，该方法不降低FR性能，并在实验中证明了其有效性，提高了FR系统的透明度、公平性和用户友好性，尤其适用于决策敏感的应用场景。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.16089v2",
      "published_date": "2024-09-24 13:40:39 UTC",
      "updated_date": "2024-12-09 14:41:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:10:05.363903"
    },
    {
      "arxiv_id": "2409.16086v1",
      "title": "Assessing Simplification Levels in Neural Networks: The Impact of Hyperparameter Configurations on Complexity and Sensitivity",
      "title_zh": "翻译失败",
      "authors": [
        "Huixin Guan"
      ],
      "abstract": "This paper presents an experimental study focused on understanding the\nsimplification properties of neural networks under different hyperparameter\nconfigurations, specifically investigating the effects on Lempel Ziv complexity\nand sensitivity. By adjusting key hyperparameters such as activation functions,\nhidden layers, and learning rate, this study evaluates how these parameters\nimpact the complexity of network outputs and their robustness to input\nperturbations. The experiments conducted using the MNIST dataset aim to provide\ninsights into the relationships between hyperparameters, complexity, and\nsensitivity, contributing to a deeper theoretical understanding of these\nconcepts in neural networks.",
      "tldr_zh": "这篇论文通过实验研究神经网络在不同超参数配置下的简化属性，重点评估激活函数、隐藏层和学习率等参数对 Lempel Ziv complexity 和 sensitivity 的影响。研究者使用 MNIST 数据集进行测试，分析这些超参数如何改变网络输出复杂度和对输入扰动的鲁棒性。结果为揭示超参数、复杂性和敏感性之间的关系提供了新洞见，从而加深了对神经网络理论的理解。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.16086v1",
      "published_date": "2024-09-24 13:39:04 UTC",
      "updated_date": "2024-09-24 13:39:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:10:17.216267"
    },
    {
      "arxiv_id": "2409.16081v1",
      "title": "Online Multi-level Contrastive Representation Distillation for Cross-Subject fNIRS Emotion Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Zhili Lai",
        "Chunmei Qing",
        "Junpeng Tan",
        "Wanxiang Luo",
        "Xiangmin Xu"
      ],
      "abstract": "Utilizing functional near-infrared spectroscopy (fNIRS) signals for emotion\nrecognition is a significant advancement in understanding human emotions.\nHowever, due to the lack of artificial intelligence data and algorithms in this\nfield, current research faces the following challenges: 1) The portable\nwearable devices have higher requirements for lightweight models; 2) The\nobjective differences of physiology and psychology among different subjects\naggravate the difficulty of emotion recognition. To address these challenges,\nwe propose a novel cross-subject fNIRS emotion recognition method, called the\nOnline Multi-level Contrastive Representation Distillation framework (OMCRD).\nSpecifically, OMCRD is a framework designed for mutual learning among multiple\nlightweight student networks. It utilizes multi-level fNIRS feature extractor\nfor each sub-network and conducts multi-view sentimental mining using\nphysiological signals. The proposed Inter-Subject Interaction Contrastive\nRepresentation (IS-ICR) facilitates knowledge transfer for interactions between\nstudent models, enhancing cross-subject emotion recognition performance. The\noptimal student network can be selected and deployed on a wearable device. Some\nexperimental results demonstrate that OMCRD achieves state-of-the-art results\nin emotional perception and affective imagery tasks.",
      "tldr_zh": "这篇论文针对 fNIRS 情绪识别面临的挑战，包括对轻量级模型的需求和不同受试者间的生理心理差异，提出了一种新型框架 Online Multi-level Contrastive Representation Distillation (OMCRD)。OMCRD 通过多个轻量级学生网络的互学机制，利用多级 fNIRS 特征提取器进行多视图情绪挖掘，并引入 Inter-Subject Interaction Contrastive Representation (IS-ICR) 来促进跨受试者知识转移，提升识别性能。实验结果显示，该框架在情绪感知和情感意象任务中达到了最先进水平，并支持最佳学生网络部署到可穿戴设备上。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "Accepted in ACMMM-2024 Workshop BCI. Codes are available at\n  https://github.com/Lzhili/fNIRS-OMCRD",
      "pdf_url": "http://arxiv.org/pdf/2409.16081v1",
      "published_date": "2024-09-24 13:30:15 UTC",
      "updated_date": "2024-09-24 13:30:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:10:29.627070"
    },
    {
      "arxiv_id": "2409.16077v1",
      "title": "Leveraging Mixture of Experts for Improved Speech Deepfake Detection",
      "title_zh": "利用混合专家模型改进语音深度伪造检测",
      "authors": [
        "Viola Negroni",
        "Davide Salvi",
        "Alessandro Ilic Mezza",
        "Paolo Bestagini",
        "Stefano Tubaro"
      ],
      "abstract": "Speech deepfakes pose a significant threat to personal security and content\nauthenticity. Several detectors have been proposed in the literature, and one\nof the primary challenges these systems have to face is the generalization over\nunseen data to identify fake signals across a wide range of datasets. In this\npaper, we introduce a novel approach for enhancing speech deepfake detection\nperformance using a Mixture of Experts architecture. The Mixture of Experts\nframework is well-suited for the speech deepfake detection task due to its\nability to specialize in different input types and handle data variability\nefficiently. This approach offers superior generalization and adaptability to\nunseen data compared to traditional single models or ensemble methods.\nAdditionally, its modular structure supports scalable updates, making it more\nflexible in managing the evolving complexity of deepfake techniques while\nmaintaining high detection accuracy. We propose an efficient, lightweight\ngating mechanism to dynamically assign expert weights for each input,\noptimizing detection performance. Experimental results across multiple datasets\ndemonstrate the effectiveness and potential of our proposed approach.",
      "tldr_zh": "这篇论文提出了一种基于 Mixture of Experts (MoE) 架构的新方法，以提升语音深度伪造检测的性能，针对传统模型在未见数据上泛化能力不足的问题。MoE 通过让专家模型专化处理不同输入类型，并引入一个高效轻量级的 gating mechanism 来动态分配权重，从而实现更好的数据变异处理和适应性。与单模型或集成方法相比，该方法提供更强的泛化和可扩展性，便于应对深度伪造技术的演变。实验结果在多个数据集上验证了其有效性，展示了潜在的应用价值。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Submitted to ICASSP 2025",
      "pdf_url": "http://arxiv.org/pdf/2409.16077v1",
      "published_date": "2024-09-24 13:24:03 UTC",
      "updated_date": "2024-09-24 13:24:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:10:41.752725"
    },
    {
      "arxiv_id": "2409.16057v2",
      "title": "Towards Robust Object Detection: Identifying and Removing Backdoors via Module Inconsistency Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Xianda Zhang",
        "Siyuan Liang"
      ],
      "abstract": "Object detection models, widely used in security-critical applications, are\nvulnerable to backdoor attacks that cause targeted misclassifications when\ntriggered by specific patterns. Existing backdoor defense techniques, primarily\ndesigned for simpler models like image classifiers, often fail to effectively\ndetect and remove backdoors in object detectors. We propose a backdoor defense\nframework tailored to object detection models, based on the observation that\nbackdoor attacks cause significant inconsistencies between local modules'\nbehaviors, such as the Region Proposal Network (RPN) and classification head.\nBy quantifying and analyzing these inconsistencies, we develop an algorithm to\ndetect backdoors. We find that the inconsistent module is usually the main\nsource of backdoor behavior, leading to a removal method that localizes the\naffected module, resets its parameters, and fine-tunes the model on a small\nclean dataset. Extensive experiments with state-of-the-art two-stage object\ndetectors show our method achieves a 90% improvement in backdoor removal rate\nover fine-tuning baselines, while limiting clean data accuracy loss to less\nthan 4%. To the best of our knowledge, this work presents the first approach\nthat addresses both the detection and removal of backdoors in two-stage object\ndetection models, advancing the field of securing these complex systems against\nbackdoor attacks.",
      "tldr_zh": "本文提出了一种针对对象检测模型的后门防御框架，通过分析模块不一致性（如Region Proposal Network (RPN)和分类头之间的行为差异）来识别后门攻击。方法包括量化这些不一致性以检测后门，并通过定位受影响模块、重置其参数，并在小规模清洁数据集上微调模型来移除后门。实验在最先进的双阶段对象检测器上显示，该框架比微调基线提高了90%的后门移除率，同时清洁数据准确率损失不到4%。这项工作首次同时解决了双阶段对象检测模型的后门检测和移除问题，提升了这些系统的安全性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.16057v2",
      "published_date": "2024-09-24 12:58:35 UTC",
      "updated_date": "2024-09-30 08:27:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:10:53.625718"
    },
    {
      "arxiv_id": "2409.16056v1",
      "title": "Adversarial Watermarking for Face Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Yuguang Yao",
        "Anil Jain",
        "Sijia Liu"
      ],
      "abstract": "Watermarking is an essential technique for embedding an identifier (i.e.,\nwatermark message) within digital images to assert ownership and monitor\nunauthorized alterations. In face recognition systems, watermarking plays a\npivotal role in ensuring data integrity and security. However, an adversary\ncould potentially interfere with the watermarking process, significantly\nimpairing recognition performance. We explore the interaction between\nwatermarking and adversarial attacks on face recognition models. Our findings\nreveal that while watermarking or input-level perturbation alone may have a\nnegligible effect on recognition accuracy, the combined effect of watermarking\nand perturbation can result in an adversarial watermarking attack,\nsignificantly degrading recognition performance. Specifically, we introduce a\nnovel threat model, the adversarial watermarking attack, which remains stealthy\nin the absence of watermarking, allowing images to be correctly recognized\ninitially. However, once watermarking is applied, the attack is activated,\ncausing recognition failures. Our study reveals a previously unrecognized\nvulnerability: adversarial perturbations can exploit the watermark message to\nevade face recognition systems. Evaluated on the CASIA-WebFace dataset, our\nproposed adversarial watermarking attack reduces face matching accuracy by\n67.2% with an $\\ell_\\infty$ norm-measured perturbation strength of ${2}/{255}$\nand by 95.9% with a strength of ${4}/{255}$.",
      "tldr_zh": "本论文探讨了在人脸识别系统中，水印技术（Watermarking）用于维护数据完整性和安全性的同时，如何面临对抗攻击（Adversarial Attacks）的威胁。作者引入了新型威胁模型——对抗水印攻击，该攻击在未应用水印时保持隐蔽，确保图像正常识别，但一旦水印被嵌入，便激活扰动导致识别失败。实验结果显示，在 CASIA-WebFace 数据集上，该攻击以 $\\ell_\\infty$ 范数扰动强度为 ${2}/{255}$ 时，使面部匹配准确率下降 67.2%，强度为 ${4}/{255}$ 时下降 95.9%，揭示了水印机制的潜在漏洞。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.16056v1",
      "published_date": "2024-09-24 12:58:32 UTC",
      "updated_date": "2024-09-24 12:58:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:11:06.931871"
    },
    {
      "arxiv_id": "2409.16048v2",
      "title": "Whole-body End-Effector Pose Tracking",
      "title_zh": "翻译失败",
      "authors": [
        "Tifanny Portela",
        "Andrei Cramariuc",
        "Mayank Mittal",
        "Marco Hutter"
      ],
      "abstract": "Combining manipulation with the mobility of legged robots is essential for a\nwide range of robotic applications. However, integrating an arm with a mobile\nbase significantly increases the system's complexity, making precise\nend-effector control challenging. Existing model-based approaches are often\nconstrained by their modeling assumptions, leading to limited robustness.\nMeanwhile, recent Reinforcement Learning (RL) implementations restrict the\narm's workspace to be in front of the robot or track only the position to\nobtain decent tracking accuracy. In this work, we address these limitations by\nintroducing a whole-body RL formulation for end-effector pose tracking in a\nlarge workspace on rough, unstructured terrains. Our proposed method involves a\nterrain-aware sampling strategy for the robot's initial configuration and\nend-effector pose commands, as well as a game-based curriculum to extend the\nrobot's operating range. We validate our approach on the ANYmal quadrupedal\nrobot with a six DoF robotic arm. Through our experiments, we show that the\nlearned controller achieves precise command tracking over a large workspace and\nadapts across varying terrains such as stairs and slopes. On deployment, it\nachieves a pose-tracking error of 2.64 cm and 3.64 degrees, outperforming\nexisting competitive baselines.",
      "tldr_zh": "该研究针对腿式机器人结合机械臂的挑战，提出了一种整体强化学习（RL）框架，用于在粗糙、不结构化地形上实现大工作空间的末端执行器姿态跟踪。方法包括地形感知采样策略（用于初始配置和指令生成）以及基于游戏的课程学习，以扩展机器人的操作范围。在ANYmal四足机器人上进行实验，结果显示该控制器在不同地形（如楼梯和坡道）上实现了精确跟踪，部署时的姿态跟踪误差为2.64 cm和3.64度，优于现有基线模型。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.16048v2",
      "published_date": "2024-09-24 12:51:32 UTC",
      "updated_date": "2025-04-25 09:59:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:11:19.579748"
    },
    {
      "arxiv_id": "2409.16045v1",
      "title": "LTNtorch: PyTorch Implementation of Logic Tensor Networks",
      "title_zh": "LTNtorch：Logic Tensor Networks 的 PyTorch 实现",
      "authors": [
        "Tommaso Carraro",
        "Luciano Serafini",
        "Fabio Aiolli"
      ],
      "abstract": "Logic Tensor Networks (LTN) is a Neuro-Symbolic framework that effectively\nincorporates deep learning and logical reasoning. In particular, LTN allows\ndefining a logical knowledge base and using it as the objective of a neural\nmodel. This makes learning by logical reasoning possible as the parameters of\nthe model are optimized by minimizing a loss function composed of a set of\nlogical formulas expressing facts about the learning task. The framework learns\nvia gradient-descent optimization. Fuzzy logic, a relaxation of classical logic\npermitting continuous truth values in the interval [0,1], makes this learning\npossible. Specifically, the training of an LTN consists of three steps.\nFirstly, (1) the training data is used to ground the formulas. Then, (2) the\nformulas are evaluated, and the loss function is computed. Lastly, (3) the\ngradients are back-propagated through the logical computational graph, and the\nweights of the neural model are changed so the knowledge base is maximally\nsatisfied. LTNtorch is the fully documented and tested PyTorch implementation\nof Logic Tensor Networks. This paper presents the formalization of LTN and how\nLTNtorch implements it. Moreover, it provides a basic binary classification\nexample.",
      "tldr_zh": "该论文介绍了 Logic Tensor Networks (LTN)，一个 Neuro-Symbolic 框架，将深度学习与逻辑推理相结合，通过定义逻辑知识库作为神经模型的目标来实现基于逻辑的训练。LTN 利用 Fuzzy logic 允许连续真值 [0,1]，其训练过程包括三个步骤：使用训练数据 grounding 公式、评估公式计算损失函数，以及反向传播梯度以优化模型参数。LTNtorch 是 LTN 的 PyTorch 实现，提供完整文档和测试，并通过一个基本二元分类示例展示了其实际应用。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "5 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.16045v1",
      "published_date": "2024-09-24 12:50:22 UTC",
      "updated_date": "2024-09-24 12:50:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:11:30.838019"
    },
    {
      "arxiv_id": "2409.16040v4",
      "title": "Time-MoE: Billion-Scale Time Series Foundation Models with Mixture of Experts",
      "title_zh": "Time-MoE：十亿规模的时间序列基础模型，采用混合专家",
      "authors": [
        "Xiaoming Shi",
        "Shiyu Wang",
        "Yuqi Nie",
        "Dianqi Li",
        "Zhou Ye",
        "Qingsong Wen",
        "Ming Jin"
      ],
      "abstract": "Deep learning for time series forecasting has seen significant advancements\nover the past decades. However, despite the success of large-scale pre-training\nin language and vision domains, pre-trained time series models remain limited\nin scale and operate at a high cost, hindering the development of larger\ncapable forecasting models in real-world applications. In response, we\nintroduce Time-MoE, a scalable and unified architecture designed to pre-train\nlarger, more capable forecasting foundation models while reducing inference\ncosts. By leveraging a sparse mixture-of-experts (MoE) design, Time-MoE\nenhances computational efficiency by activating only a subset of networks for\neach prediction, reducing computational load while maintaining high model\ncapacity. This allows Time-MoE to scale effectively without a corresponding\nincrease in inference costs. Time-MoE comprises a family of decoder-only\ntransformer models that operate in an auto-regressive manner and support\nflexible forecasting horizons with varying input context lengths. We\npre-trained these models on our newly introduced large-scale data Time-300B,\nwhich spans over 9 domains and encompassing over 300 billion time points. For\nthe first time, we scaled a time series foundation model up to 2.4 billion\nparameters, achieving significantly improved forecasting precision. Our results\nvalidate the applicability of scaling laws for training tokens and model size\nin the context of time series forecasting. Compared to dense models with the\nsame number of activated parameters or equivalent computation budgets, our\nmodels consistently outperform them by large margin. These advancements\nposition Time-MoE as a state-of-the-art solution for tackling real-world time\nseries forecasting challenges with superior capability, efficiency, and\nflexibility.",
      "tldr_zh": "该研究引入了Time-MoE，一种基于Mixture of Experts (MoE)的可扩展架构，用于预训练大规模时间序列预测基础模型，同时降低推理成本。通过稀疏MoE设计，仅激活子集网络，Time-MoE实现了高效计算，同时保持高模型容量。模型采用解码器-only Transformer的自回归方式，支持灵活的预测horizon和输入上下文长度，并在新数据集Time-300B（覆盖9个领域、超过300亿时间点）上预训练，首次将时间序列模型扩展到24亿参数。实验结果验证了时间序列预测中的scaling laws，并显示Time-MoE在相同激活参数或计算预算下显著优于密集模型，提供更精确、灵活的真实世界预测解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by the 13th International Conference on Learning\n  Representations (ICLR 2025)",
      "pdf_url": "http://arxiv.org/pdf/2409.16040v4",
      "published_date": "2024-09-24 12:42:18 UTC",
      "updated_date": "2025-02-27 05:38:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:11:44.800026"
    },
    {
      "arxiv_id": "2409.16036v1",
      "title": "Grounded Computation & Consciousness: A Framework for Exploring Consciousness in Machines & Other Organisms",
      "title_zh": "翻译失败",
      "authors": [
        "Ryan Williams"
      ],
      "abstract": "Computational modeling is a critical tool for understanding consciousness,\nbut is it enough on its own? This paper discusses the necessity for an\nontological basis of consciousness, and introduces a formal framework for\ngrounding computational descriptions into an ontological substrate. Utilizing\nthis technique, a method is demonstrated for estimating the difference in\nqualitative experience between two systems. This framework has wide\napplicability to computational theories of consciousness.",
      "tldr_zh": "这篇论文探讨了计算建模（computational modeling）是否足以理解意识，并强调了引入意识的本体论基础（ontological basis）的必要性。它提出一个正式框架，用于将计算描述grounding到本体论基底（ontological substrate），并展示了一种方法来估计两个系统之间定性经验的差异。该框架具有广泛适用性，可应用于计算意识理论（computational theories of consciousness），有助于探索机器和其他生物的意识。",
      "categories": [
        "q-bio.NC",
        "cs.AI"
      ],
      "primary_category": "q-bio.NC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.16036v1",
      "published_date": "2024-09-24 12:34:05 UTC",
      "updated_date": "2024-09-24 12:34:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:11:56.553913"
    },
    {
      "arxiv_id": "2409.16032v1",
      "title": "Deep chroma compression of tone-mapped images",
      "title_zh": "针对色调映射图像的深度色度",
      "authors": [
        "Xenios Milidonis",
        "Francesco Banterle",
        "Alessandro Artusi"
      ],
      "abstract": "Acquisition of high dynamic range (HDR) images is thriving due to the\nincreasing use of smart devices and the demand for high-quality output.\nExtensive research has focused on developing methods for reducing the luminance\nrange in HDR images using conventional and deep learning-based tone mapping\noperators to enable accurate reproduction on conventional 8 and 10-bit digital\ndisplays. However, these methods often fail to account for pixels that may lie\noutside the target display's gamut, resulting in visible chromatic distortions\nor color clipping artifacts. Previous studies suggested that a gamut management\nstep ensures that all pixels remain within the target gamut. However, such\napproaches are computationally expensive and cannot be deployed on devices with\nlimited computational resources. We propose a generative adversarial network\nfor fast and reliable chroma compression of HDR tone-mapped images. We design a\nloss function that considers the hue property of generated images to improve\ncolor accuracy, and train the model on an extensive image dataset. Quantitative\nexperiments demonstrate that the proposed model outperforms state-of-the-art\nimage generation and enhancement networks in color accuracy, while a subjective\nstudy suggests that the generated images are on par or superior to those\nproduced by conventional chroma compression methods in terms of visual quality.\nAdditionally, the model achieves real-time performance, showing promising\nresults for deployment on devices with limited computational resources.",
      "tldr_zh": "本论文针对高动态范围（HDR）图像的色调映射（tone mapping）过程，提出了一种基于生成对抗网络（GAN）的深度色度压缩方法，以解决像素超出目标显示器色域导致的色差和颜色剪切问题。方法设计了一个考虑色调属性的损失函数，并在大型图像数据集上训练模型，实现快速可靠的色度压缩，同时避免了传统色域管理方法的计算开销。实验结果显示，该模型在颜色准确性上优于现有图像生成和增强网络，主观视觉质量与传统方法相当或更好，并支持实时性能，适合资源有限的设备部署。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.16032v1",
      "published_date": "2024-09-24 12:31:55 UTC",
      "updated_date": "2024-09-24 12:31:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:12:08.093853"
    },
    {
      "arxiv_id": "2409.16024v2",
      "title": "From Goal-Conditioned to Language-Conditioned Agents via Vision-Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Theo Cachet",
        "Christopher R. Dance",
        "Olivier Sigaud"
      ],
      "abstract": "Vision-language models (VLMs) have tremendous potential for grounding\nlanguage, and thus enabling language-conditioned agents (LCAs) to perform\ndiverse tasks specified with text. This has motivated the study of LCAs based\non reinforcement learning (RL) with rewards given by rendering images of an\nenvironment and evaluating those images with VLMs. If single-task RL is\nemployed, such approaches are limited by the cost and time required to train a\npolicy for each new task. Multi-task RL (MTRL) is a natural alternative, but\nrequires a carefully designed corpus of training tasks and does not always\ngeneralize reliably to new tasks. Therefore, this paper introduces a novel\ndecomposition of the problem of building an LCA: first find an environment\nconfiguration that has a high VLM score for text describing a task; then use a\n(pretrained) goal-conditioned policy to reach that configuration. We also\nexplore several enhancements to the speed and quality of VLM-based LCAs,\nnotably, the use of distilled models, and the evaluation of configurations from\nmultiple viewpoints to resolve the ambiguities inherent in a single 2D view. We\ndemonstrate our approach on the Humanoid environment, showing that it results\nin LCAs that outperform MTRL baselines in zero-shot generalization, without\nrequiring any textual task descriptions or other forms of environment-specific\nannotation during training.\n  Videos and an interactive demo can be found at\nhttps://europe.naverlabs.com/text2control",
      "tldr_zh": "该论文探讨了如何利用 Vision-Language Models (VLMs) 将目标条件代理转化为语言条件代理 (LCAs)，以执行基于文本的任务描述。研究提出一种新方法，将问题分解为：首先通过 VLMs 评估环境配置以获得高分匹配任务文本，然后使用预训练的目标条件策略来实现该配置，并引入蒸馏模型和多视角评估来提升速度和准确性。实验结果显示，在 Humanoid 环境中，该方法在零样本泛化上优于 Multi-Task RL (MTRL) 基线，且训练过程无需文本任务描述或其他环境特定注释，从而提高了代理的泛化能力和效率。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.16024v2",
      "published_date": "2024-09-24 12:24:07 UTC",
      "updated_date": "2024-11-26 11:15:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:12:20.760921"
    },
    {
      "arxiv_id": "2409.16022v2",
      "title": "AI Can Be Cognitively Biased: An Exploratory Study on Threshold Priming in LLM-Based Batch Relevance Assessment",
      "title_zh": "翻译失败",
      "authors": [
        "Nuo Chen",
        "Jiqun Liu",
        "Xiaoyu Dong",
        "Qijiong Liu",
        "Tetsuya Sakai",
        "Xiao-Ming Wu"
      ],
      "abstract": "Cognitive biases are systematic deviations in thinking that lead to\nirrational judgments and problematic decision-making, extensively studied\nacross various fields. Recently, large language models (LLMs) have shown\nadvanced understanding capabilities but may inherit human biases from their\ntraining data. While social biases in LLMs have been well-studied, cognitive\nbiases have received less attention, with existing research focusing on\nspecific scenarios. The broader impact of cognitive biases on LLMs in various\ndecision-making contexts remains underexplored. We investigated whether LLMs\nare influenced by the threshold priming effect in relevance judgments, a core\ntask and widely-discussed research topic in the Information Retrieval (IR)\ncoummunity. The priming effect occurs when exposure to certain stimuli\nunconsciously affects subsequent behavior and decisions. Our experiment\nemployed 10 topics from the TREC 2019 Deep Learning passage track collection,\nand tested AI judgments under different document relevance scores, batch\nlengths, and LLM models, including GPT-3.5, GPT-4, LLaMa2-13B and LLaMa2-70B.\nResults showed that LLMs tend to give lower scores to later documents if\nearlier ones have high relevance, and vice versa, regardless of the combination\nand model used. Our finding demonstrates that LLM%u2019s judgments, similar to\nhuman judgments, are also influenced by threshold priming biases, and suggests\nthat researchers and system engineers should take into account potential\nhuman-like cognitive biases in designing, evaluating, and auditing LLMs in IR\ntasks and beyond.",
      "tldr_zh": "本研究探索了大型语言模型 (LLMs) 是否会受到认知偏差 (cognitive biases) 的影响，特别聚焦于阈值启动效应 (threshold priming effect) 在批量相关性评估中的作用。研究者使用 TREC 2019 Deep Learning passage track 数据集，对 GPT-3.5、GPT-4、LLaMa2-13B 和 LLaMa2-70B 等模型进行了实验，测试不同文档相关性分数和批次长度。结果显示，LLMs 会因早期文档的高相关性而降低后续文档的评分，反之亦然，表现出与人类相似的偏差。论文强调，在信息检索 (IR) 任务的设计、评估和审计中，应考虑这些潜在的认知偏差，以提升模型的可靠性和公平性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.16022v2",
      "published_date": "2024-09-24 12:23:15 UTC",
      "updated_date": "2024-10-08 10:23:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:12:34.347419"
    },
    {
      "arxiv_id": "2409.16001v2",
      "title": "Artificial Human Intelligence: The role of Humans in the Development of Next Generation AI",
      "title_zh": "人工人类智能：人类在下一代人工智能发展中的作用",
      "authors": [
        "Suayb S. Arslan"
      ],
      "abstract": "Human intelligence, the most evident and accessible form of source of\nreasoning, hosted by biological hardware, has evolved and been refined over\nthousands of years, positioning itself today to create new artificial forms and\npreparing to self--design their evolutionary path forward. Beginning with the\nadvent of foundation models, the rate at which human and artificial\nintelligence interact with each other has exceeded any anticipated quantitative\nfigures. The close engagement led both bits of intelligence to be impacted in\nvarious ways, which naturally resulted in complex confluences that warrant\nclose scrutiny. In the sequel, using a novel taxonomy, we shall explore the\ninterplay between human and machine intelligence, focusing on the crucial role\nhumans play in developing ethical, responsible, and robust intelligent systems.\nWe briefly delve into various aspects of implementation inspired by the\nmechanisms underlying neuroscience and human cognition. In addition, we propose\nfuture perspectives, capitalizing on the advantages of symbiotic designs to\nsuggest a human-centered direction for next-generation developments, focusing\non the augmentation role of AI. We finalize this evolving document with some\nthoughts and open questions yet to be addressed by the broader community.",
      "tldr_zh": "这篇论文探讨了人类智能在发展下一代AI中的关键作用，强调人类作为生物硬件的推理来源，如何通过与AI的互动推动其演变。作者引入了一个新颖的taxonomy来分析人机智能的互动，聚焦于人类在构建道德、负责任和鲁棒的智能系统中的贡献，并借鉴神经科学和人类认知机制来指导实现策略。论文还提出未来展望，主张采用以人为中心的symbiotic designs，将AI视为增强工具，并以一些开放问题结束，以激发更广泛的社区讨论。",
      "categories": [
        "cs.AI",
        "q-bio.NC"
      ],
      "primary_category": "cs.AI",
      "comment": "26 pages, 8 figures, submitted to IEEE Trans. on NNLS",
      "pdf_url": "http://arxiv.org/pdf/2409.16001v2",
      "published_date": "2024-09-24 12:02:20 UTC",
      "updated_date": "2025-02-02 15:33:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:12:44.110161"
    },
    {
      "arxiv_id": "2409.15997v2",
      "title": "Improvements to SDXL in NovelAI Diffusion V3",
      "title_zh": "翻译失败",
      "authors": [
        "Juan Ossa",
        "Eren Doğan",
        "Alex Birch",
        "F. Johnson"
      ],
      "abstract": "In this technical report, we document the changes we made to SDXL in the\nprocess of training NovelAI Diffusion V3, our state of the art anime image\ngeneration model.",
      "tldr_zh": "本报告详细记录了在训练NovelAI Diffusion V3时，对SDXL模型所做的改进，旨在提升其在动漫图像生成方面的性能。NovelAI Diffusion V3作为最先进的动漫图像生成模型，通过这些优化，实现了更高的生成质量和效率。这些改进为AI图像生成领域提供了宝贵的实践经验和基准。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "14 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.15997v2",
      "published_date": "2024-09-24 11:57:12 UTC",
      "updated_date": "2024-09-26 21:56:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:12:53.886934"
    },
    {
      "arxiv_id": "2409.15985v1",
      "title": "DataGpt-SQL-7B: An Open-Source Language Model for Text-to-SQL",
      "title_zh": "翻译失败",
      "authors": [
        "Lixia Wu",
        "Peng Li",
        "Junhong Lou",
        "Lei Fu"
      ],
      "abstract": "In addressing the pivotal role of translating natural language queries into\nSQL commands, we propose a suite of compact, fine-tuned models and self-refine\nmechanisms to democratize data access and analysis for non-expert users,\nmitigating risks associated with closed-source Large Language Models.\nSpecifically, we constructed a dataset of over 20K sample for Text-to-SQL as\nwell as the preference dateset, to improve the efficiency in the domain of SQL\ngeneration. To further ensure code validity, a code corrector was integrated\ninto the model. Our system, DataGpt-sql, achieved 87.2\\% accuracy on the\nspider-dev, respectively, showcasing the effectiveness of our solution in\ntext-to-SQL conversion tasks. Our code, data, and models are available at\n\\url{https://github.com/CainiaoTechAi/datagpt-sql-7b}",
      "tldr_zh": "本研究提出了 DataGpt-SQL-7B，一种开源语言模型，旨在将自然语言查询转化为 SQL 命令，从而简化非专家用户的数据访问和分析，同时规避封闭源 Large Language Models 的风险。研究团队构建了一个超过 20K 样本的 Text-to-SQL 数据集以及偏好数据集，并集成了自精炼机制和代码校正器，以提升 SQL 生成的效率和代码有效性。该模型在 Spider-dev 数据集上达到了 87.2% 的准确率，展示了其在文本到 SQL 转换任务中的优越性能；代码、数据和模型已在 GitHub 上开源。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.15985v1",
      "published_date": "2024-09-24 11:38:08 UTC",
      "updated_date": "2024-09-24 11:38:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:13:10.049555"
    },
    {
      "arxiv_id": "2409.15980v1",
      "title": "Leveraging Unsupervised Learning for Cost-Effective Visual Anomaly Detection",
      "title_zh": "利用无监督学习实现成本有效的视觉异常检测",
      "authors": [
        "Yunbo Long",
        "Zhengyang Ling",
        "Sam Brook",
        "Duncan McFarlane",
        "Alexandra Brintrup"
      ],
      "abstract": "Traditional machine learning-based visual inspection systems require\nextensive data collection and repetitive model training to improve accuracy.\nThese systems typically require expensive camera, computing equipment and\nsignificant machine learning expertise, which can substantially burden small\nand medium-sized enterprises. This study explores leveraging unsupervised\nlearning methods with pre-trained models and low-cost hardware to create a\ncost-effective visual anomaly detection system. The research aims to develop a\nlow-cost visual anomaly detection solution that uses minimal data for model\ntraining while maintaining generalizability and scalability. The system\nutilises unsupervised learning models from Anomalib and is deployed on\naffordable Raspberry Pi hardware through openVINO. The results show that this\ncost-effective system can complete anomaly defection training and inference on\na Raspberry Pi in just 90 seconds using only 10 normal product images,\nachieving an F1 macro score exceeding 0.95. While the system is slightly\nsensitive to environmental changes like lighting, product positioning, or\nbackground, it remains a swift and economical method for factory automation\ninspection for small and medium-sized manufacturers",
      "tldr_zh": "本研究针对传统视觉异常检测系统的成本高、数据需求大等问题，提出利用 unsupervised learning 方法和预训练模型，开发一个经济有效的系统。该系统基于 Anomalib 的无监督学习模型，通过 openVINO 在低成本硬件 Raspberry Pi 上部署，仅需 10 张正常产品图像即可完成训练和推理。实验结果显示，整个过程仅需 90 秒，F1 macro score 超过 0.95，展示了良好的泛化性和可扩展性。尽管系统对环境变化（如照明或产品位置）稍敏感，但为中小型企业的工厂自动化检查提供了快速、实用的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.15980v1",
      "published_date": "2024-09-24 11:22:24 UTC",
      "updated_date": "2024-09-24 11:22:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:13:24.410473"
    },
    {
      "arxiv_id": "2409.15974v1",
      "title": "Disentangling Age and Identity with a Mutual Information Minimization Approach for Cross-Age Speaker Verification",
      "title_zh": "翻译失败",
      "authors": [
        "Fengrun Zhang",
        "Wangjin Zhou",
        "Yiming Liu",
        "Wang Geng",
        "Yahui Shan",
        "Chen Zhang"
      ],
      "abstract": "There has been an increasing research interest in cross-age speaker\nverification~(CASV). However, existing speaker verification systems perform\npoorly in CASV due to the great individual differences in voice caused by\naging. In this paper, we propose a disentangled representation learning\nframework for CASV based on mutual information~(MI) minimization. In our\nmethod, a backbone model is trained to disentangle the identity- and\nage-related embeddings from speaker information, and an MI estimator is trained\nto minimize the correlation between age- and identity-related embeddings via MI\nminimization, resulting in age-invariant speaker embeddings. Furthermore, by\nusing the age gaps between positive and negative samples, we propose an\naging-aware MI minimization loss function that allows the backbone model to\nfocus more on the vocal changes with large age gaps. Experimental results show\nthat the proposed method outperforms other methods on multiple Cross-Age test\nsets of Vox-CA.",
      "tldr_zh": "本研究针对跨年龄说话者验证（Cross-Age Speaker Verification, CASV）中的问题，提出了一种基于互信息（Mutual Information, MI）最小化的解耦表示学习框架，以缓解年龄导致的声音变化对系统性能的影响。框架中，骨干模型（backbone model）被训练从说话者信息中分离出身份相关嵌入和年龄相关嵌入，同时使用MI估计器最小化二者之间的相关性，从而生成年龄不变的说话者嵌入。进一步，该方法引入了基于正负样本年龄差距的年龄感知MI最小化损失函数，使模型更关注大年龄差距的声音变化。实验结果显示，该方法在Vox-CA的多个跨年龄测试集上优于其他方法，显著提升了验证准确性。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Interspeech 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.15974v1",
      "published_date": "2024-09-24 11:08:23 UTC",
      "updated_date": "2024-09-24 11:08:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:13:37.923009"
    },
    {
      "arxiv_id": "2409.15973v1",
      "title": "Edge-device Collaborative Computing for Multi-view Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Marco Palena",
        "Tania Cerquitelli",
        "Carla Fabiana Chiasserini"
      ],
      "abstract": "Motivated by the proliferation of Internet-of-Thing (IoT) devices and the\nrapid advances in the field of deep learning, there is a growing interest in\npushing deep learning computations, conventionally handled by the cloud, to the\nedge of the network to deliver faster responses to end users, reduce bandwidth\nconsumption to the cloud, and address privacy concerns. However, to fully\nrealize deep learning at the edge, two main challenges still need to be\naddressed: (i) how to meet the high resource requirements of deep learning on\nresource-constrained devices, and (ii) how to leverage the availability of\nmultiple streams of spatially correlated data, to increase the effectiveness of\ndeep learning and improve application-level performance. To address the above\nchallenges, we explore collaborative inference at the edge, in which edge nodes\nand end devices share correlated data and the inference computational burden by\nleveraging different ways to split computation and fuse data. Besides\ntraditional centralized and distributed schemes for edge-end device\ncollaborative inference, we introduce selective schemes that decrease bandwidth\nresource consumption by effectively reducing data redundancy. As a reference\nscenario, we focus on multi-view classification in a networked system in which\nsensing nodes can capture overlapping fields of view. The proposed schemes are\ncompared in terms of accuracy, computational expenditure at the nodes,\ncommunication overhead, inference latency, robustness, and noise sensitivity.\nExperimental results highlight that selective collaborative schemes can achieve\ndifferent trade-offs between the above performance metrics, with some of them\nbringing substantial communication savings (from 18% to 74% of the transmitted\ndata with respect to centralized inference) while still keeping the inference\naccuracy well above 90%.",
      "tldr_zh": "这篇论文探讨了将深度学习计算从云端推向边缘设备，以提升响应速度、减少带宽消耗并解决隐私问题，针对物联网(IoT)设备面临的资源限制和多数据流挑战。作者提出了一种边缘设备协作推理框架，包括传统集中式、分布式方案，以及创新的选择性方案，以分担计算负担、融合空间相关数据并降低数据冗余。实验针对多视图分类场景进行评估，结果显示选择性方案显著减少通信开销（18%到74%），同时保持推理准确率超过90%，并在计算开销、延迟和鲁棒性方面实现了良好的权衡。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC",
        "cs.NI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.15973v1",
      "published_date": "2024-09-24 11:07:33 UTC",
      "updated_date": "2024-09-24 11:07:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:13:47.214806"
    },
    {
      "arxiv_id": "2409.15971v1",
      "title": "Creating Healthy Friction: Determining Stakeholder Requirements of Job Recommendation Explanations",
      "title_zh": "创建健康的摩擦：确定工作推荐解释的利益相关者要求",
      "authors": [
        "Roan Schellingerhout",
        "Francesco Barile",
        "Nava Tintarev"
      ],
      "abstract": "The increased use of information retrieval in recruitment, primarily through\njob recommender systems (JRSs), can have a large impact on job seekers,\nrecruiters, and companies. As a result, such systems have been determined to be\nhigh-risk in recent legislature. This requires JRSs to be trustworthy and\ntransparent, allowing stakeholders to understand why specific recommendations\nwere made. To fulfill this requirement, the stakeholders' exact preferences and\nneeds need to be determined. To do so, we evaluated an explainable job\nrecommender system using a realistic, task-based, mixed-design user study\n(n=30) in which stakeholders had to make decisions based on the model's\nexplanations. This mixed-methods evaluation consisted of two objective metrics\n- correctness and efficiency, along with three subjective metrics - trust,\ntransparency, and usefulness. These metrics were evaluated twice per\nparticipant, once using real explanations and once using random explanations.\nThe study included a qualitative analysis following a think-aloud protocol\nwhile performing tasks adapted to each stakeholder group. We find that\nproviding stakeholders with real explanations does not significantly improve\ndecision-making speed and accuracy. Our results showed a non-significant trend\nfor the real explanations to outperform the random ones on perceived trust,\nusefulness, and transparency of the system for all stakeholder types. We\ndetermine that stakeholders benefit more from interacting with explanations as\ndecision support capable of providing healthy friction, rather than as\npreviously-assumed persuasive tools.",
      "tldr_zh": "这篇论文探讨了工作推荐系统 (JRSs) 的解释需求，以提升其可信性和透明度，针对求职者、招聘者和公司等利益相关者。研究采用一个基于任务的混合设计用户研究 (n=30)，通过客观指标（如正确性和效率）和主观指标（如信任、透明度和有用性）比较真实解释与随机解释的影响。结果显示，真实解释未显著改善决策速度和准确性，但显示出提升感知信任、透明度和有用性的趋势。作者强调，JRSs 的解释更适合作为提供“健康摩擦”的决策支持工具，而不是传统的说服手段。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "14 pages, 3 figures, to be published in ACM RecSys in HR '24: 4th\n  Workshop on Recommender Systems for Human Resources",
      "pdf_url": "http://arxiv.org/pdf/2409.15971v1",
      "published_date": "2024-09-24 11:03:17 UTC",
      "updated_date": "2024-09-24 11:03:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:13:59.255390"
    },
    {
      "arxiv_id": "2409.15963v4",
      "title": "Provably Efficient Exploration in Inverse Constrained Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Bo Yue",
        "Jian Li",
        "Guiliang Liu"
      ],
      "abstract": "Optimizing objective functions subject to constraints is fundamental in many\nreal-world applications. However, these constraints are often not readily\ndefined and must be inferred from expert agent behaviors, a problem known as\nInverse Constraint Inference. Inverse Constrained Reinforcement Learning (ICRL)\nis a common solver for recovering feasible constraints in complex environments,\nrelying on training samples collected from interactive environments. However,\nthe efficacy and efficiency of current sampling strategies remain unclear. We\npropose a strategic exploration framework for sampling with guaranteed\nefficiency to bridge this gap. By defining the feasible cost set for ICRL\nproblems, we analyze how estimation errors in transition dynamics and the\nexpert policy influence the feasibility of inferred constraints. Based on this\nanalysis, we introduce two exploratory algorithms to achieve efficient\nconstraint inference via 1) dynamically reducing the bounded aggregate error of\ncost estimations or 2) strategically constraining the exploration policy around\nplausibly optimal ones. Both algorithms are theoretically grounded with\ntractable sample complexity, and their performance is validated empirically\nacross various environments.",
      "tldr_zh": "该论文探讨了在逆约束强化学习（Inverse Constrained Reinforcement Learning, ICRL）中，通过高效探索策略来推断专家行为中的可行约束问题。作者提出一个战略探索框架，通过定义可行成本集，分析过渡动态和专家策略的估计错误对约束可行性的影响，从而提升采样效率。框架引入两个算法：一是动态减少成本估计的聚合错误，二是战略性地约束探索策略于可能的最优策略周围。两者均具有可追踪的样本复杂度，并在多种环境中通过实验验证了其有效性，为ICRL的应用提供了理论可靠和实证支持。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.15963v4",
      "published_date": "2024-09-24 10:48:13 UTC",
      "updated_date": "2025-05-16 09:40:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:14:09.715232"
    },
    {
      "arxiv_id": "2409.15957v1",
      "title": "ASD-Diffusion: Anomalous Sound Detection with Diffusion Models",
      "title_zh": "ASD-Diffusion：基于扩散模型的异常声音检测",
      "authors": [
        "Fengrun Zhang",
        "Xiang Xie",
        "Kai Guo"
      ],
      "abstract": "Unsupervised Anomalous Sound Detection (ASD) aims to design a generalizable\nmethod that can be used to detect anomalies when only normal sounds are given.\nIn this paper, Anomalous Sound Detection based on Diffusion Models\n(ASD-Diffusion) is proposed for ASD in real-world factories. In our pipeline,\nthe anomalies in acoustic features are reconstructed from their noisy corrupted\nfeatures into their approximate normal pattern. Secondly, a post-processing\nanomalies filter algorithm is proposed to detect anomalies that exhibit\nsignificant deviation from the original input after reconstruction.\nFurthermore, denoising diffusion implicit model is introduced to accelerate the\ninference speed by a longer sampling interval of the denoising process. The\nproposed method is innovative in the application of diffusion models as a new\nscheme. Experimental results on the development set of DCASE 2023 challenge\ntask 2 outperform the baseline by 7.75%, demonstrating the effectiveness of the\nproposed method.",
      "tldr_zh": "这篇论文提出了 ASD-Diffusion，一种基于 Diffusion Models 的无监督异常声音检测（ASD）方法，旨在通过仅使用正常声音数据来识别真实工厂环境中的异常。方法的核心包括将异常声学特征从噪声破坏的版本重建为接近正常模式，并引入后处理异常过滤算法来检测重建后与原始输入的显著偏差，同时利用去噪扩散隐式模型（denoising diffusion implicit model）来加速推理过程。实验结果显示，该方法在 DCASE 2023 挑战任务 2 的开发集上比基线提高了 7.75%，证明了其在异常检测领域的创新性和有效性。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "This paper will appear at ICPR 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.15957v1",
      "published_date": "2024-09-24 10:42:23 UTC",
      "updated_date": "2024-09-24 10:42:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:14:25.595185"
    },
    {
      "arxiv_id": "2409.15955v5",
      "title": "A Historical Trajectory Assisted Optimization Method for Zeroth-Order Federated Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Chenlin Wu",
        "Xiaoyu He",
        "Zike Li",
        "Jing Gong",
        "Zibin Zheng"
      ],
      "abstract": "Federated learning heavily relies on distributed gradient descent techniques.\nIn the situation where gradient information is not available, the gradients\nneed to be estimated from zeroth-order information, which typically involves\ncomputing finite-differences along isotropic random directions. This method\nsuffers from high estimation errors, as the geometric features of the objective\nlandscape may be overlooked during the isotropic sampling. In this work, we\npropose a non-isotropic sampling method to improve the gradient estimation\nprocedure. Gradients in our method are estimated in a subspace spanned by\nhistorical trajectories of solutions, aiming to encourage the exploration of\npromising regions and hence improve the convergence. The proposed method uses a\ncovariance matrix for sampling which is a convex combination of two parts. The\nfirst part is a thin projection matrix containing the basis of the subspace\nwhich is designed to improve the exploitation ability. The second part is the\nhistorical trajectories. We implement this method in zeroth-order federated\nsettings, and show that the convergence rate aligns with existing ones while\nintroducing no significant overheads in communication or local computation. The\neffectiveness of our proposal is verified on several numerical experiments in\ncomparison to several commonly-used zeroth-order federated optimization\nalgorithms.",
      "tldr_zh": "这篇论文针对零阶联邦学习（Zeroth-Order Federated Learning）中梯度估计的误差问题，提出了一种基于历史轨迹的优化方法，以非各向同性采样取代传统各向同性随机方向。\n该方法使用一个协方差矩阵的凸组合，包括子空间基的薄投影矩阵（thin projection matrix）来提升利用能力，以及历史轨迹来鼓励探索有前景的区域。\n实验结果表明，该方法在零阶联邦设置下保持了与现有算法相当的收敛率，同时未增加显著的通信或本地计算开销，并在多项数值实验中验证了其有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.15955v5",
      "published_date": "2024-09-24 10:36:40 UTC",
      "updated_date": "2024-10-24 09:39:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:14:36.348645"
    },
    {
      "arxiv_id": "2409.15950v1",
      "title": "TSFeatLIME: An Online User Study in Enhancing Explainability in Univariate Time Series Forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Hongnan Ma",
        "Kevin McAreavey",
        "Weiru Liu"
      ],
      "abstract": "Time series forecasting, while vital in various applications, often employs\ncomplex models that are difficult for humans to understand. Effective\nexplainable AI techniques are crucial to bridging the gap between model\npredictions and user understanding. This paper presents a framework -\nTSFeatLIME, extending TSLIME, tailored specifically for explaining univariate\ntime series forecasting. TSFeatLIME integrates an auxiliary feature into the\nsurrogate model and considers the pairwise Euclidean distances between the\nqueried time series and the generated samples to improve the fidelity of the\nsurrogate models. However, the usefulness of such explanations for human beings\nremains an open question. We address this by conducting a user study with 160\nparticipants through two interactive interfaces, aiming to measure how\nindividuals from different backgrounds can simulate or predict model output\nchanges in the treatment group and control group. Our results show that the\nsurrogate model under the TSFeatLIME framework is able to better simulate the\nbehaviour of the black-box considering distance, without sacrificing accuracy.\nIn addition, the user study suggests that the explanations were significantly\nmore effective for participants without a computer science background.",
      "tldr_zh": "本研究提出TSFeatLIME框架，作为TSLIME的扩展，旨在提升单变量时间序列预测(univariate time series forecasting)的可解释性。该框架在代理模型(surrogate model)中整合辅助特征，并利用查询时间序列与生成样本之间的成对欧氏距离(pairwise Euclidean distances)，从而提高模型的保真度(fidelity)。为了验证其有效性，研究进行了在线用户研究，涉及160名参与者，通过两个交互界面比较治疗组和对照组的表现。结果显示，TSFeatLIME能更好地模拟黑盒模型的行为，同时保持准确性，且对没有计算机科学背景的参与者，解释效果显著更佳。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.15950v1",
      "published_date": "2024-09-24 10:24:53 UTC",
      "updated_date": "2024-09-24 10:24:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:14:45.778075"
    },
    {
      "arxiv_id": "2409.15934v2",
      "title": "Automated test generation to evaluate tool-augmented LLMs as conversational AI agents",
      "title_zh": "翻译失败",
      "authors": [
        "Samuel Arcadinho",
        "David Aparicio",
        "Mariana Almeida"
      ],
      "abstract": "Tool-augmented LLMs are a promising approach to create AI agents that can\nhave realistic conversations, follow procedures, and call appropriate\nfunctions. However, evaluating them is challenging due to the diversity of\npossible conversations, and existing datasets focus only on single interactions\nand function-calling. We present a test generation pipeline to evaluate LLMs as\nconversational AI agents. Our framework uses LLMs to generate diverse tests\ngrounded on user-defined procedures. For that, we use intermediate graphs to\nlimit the LLM test generator's tendency to hallucinate content that is not\ngrounded on input procedures, and enforces high coverage of the possible\nconversations. Additionally, we put forward ALMITA, a manually curated dataset\nfor evaluating AI agents in customer support, and use it to evaluate existing\nLLMs. Our results show that while tool-augmented LLMs perform well in single\ninteractions, they often struggle to handle complete conversations. While our\nfocus is on customer support, our method is general and capable of AI agents\nfor different domains.",
      "tldr_zh": "该研究提出了一种自动化测试生成管道，用于评估工具增强的大型语言模型 (tool-augmented LLMs) 作为对话 AI 代理的性能。该框架利用 LLMs 生成基于用户定义程序的多样化测试，通过中间图 (intermediate graphs) 来抑制模型的幻觉，确保测试内容与输入程序一致并覆盖可能的对话。此外，论文引入了 ALMITA，一个手动策划的客户支持数据集，并通过实验发现，虽然 tool-augmented LLMs 在单一互动中表现良好，但处理完整对话时往往存在困难。该方法具有通用性，可应用于不同领域的 AI 代理评估。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "14 pages, 5 figures, Submitted to GenBench@EMNLP2024",
      "pdf_url": "http://arxiv.org/pdf/2409.15934v2",
      "published_date": "2024-09-24 09:57:43 UTC",
      "updated_date": "2024-10-10 11:37:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:15:02.111031"
    },
    {
      "arxiv_id": "2409.15924v2",
      "title": "Multilingual Transfer and Domain Adaptation for Low-Resource Languages of Spain",
      "title_zh": "翻译失败",
      "authors": [
        "Yuanchang Luo",
        "Zhanglin Wu",
        "Daimeng Wei",
        "Hengchao Shang",
        "Zongyao Li",
        "Jiaxin Guo",
        "Zhiqiang Rao",
        "Shaojun Li",
        "Jinlong Yang",
        "Yuhao Xie",
        "Jiawei Zheng Bin Wei",
        "Hao Yang"
      ],
      "abstract": "This article introduces the submission status of the Translation into\nLow-Resource Languages of Spain task at (WMT 2024) by Huawei Translation\nService Center (HW-TSC). We participated in three translation tasks: spanish to\naragonese (es-arg), spanish to aranese (es-arn), and spanish to asturian\n(es-ast). For these three translation tasks, we use training strategies such as\nmultilingual transfer, regularized dropout, forward translation and back\ntranslation, labse denoising, transduction ensemble learning and other\nstrategies to neural machine translation (NMT) model based on training deep\ntransformer-big architecture. By using these enhancement strategies, our\nsubmission achieved a competitive result in the final evaluation.",
      "tldr_zh": "这篇文章介绍了华为翻译服务中心在 WMT 2024 比赛中针对西班牙语到低资源语言的翻译任务的提交，包括西班牙语到阿拉贡语 (es-arg)、西班牙语到阿兰尼斯语 (es-arn) 和西班牙语到阿斯图里亚语 (es-ast) 的三项任务。研究团队采用了 multilingual transfer、正则化 dropout、forward translation 和 back translation、LabSE denoising 以及 transduction ensemble learning 等策略，来训练基于 Transformer-big 架构的神经机器翻译 (NMT) 模型。这些增强方法帮助他们的提交在最终评估中取得了竞争性的性能表现。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "6 pages,wmt24. arXiv admin note: substantial text overlap with\n  arXiv:2409.14842; text overlap with arXiv:2409.14800",
      "pdf_url": "http://arxiv.org/pdf/2409.15924v2",
      "published_date": "2024-09-24 09:46:27 UTC",
      "updated_date": "2024-09-29 09:15:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:15:11.115663"
    },
    {
      "arxiv_id": "2409.15915v1",
      "title": "Planning in the Dark: LLM-Symbolic Planning Pipeline without Experts",
      "title_zh": "在黑暗中规划：无需专家的 LLM-符号规划管道",
      "authors": [
        "Sukai Huang",
        "Nir Lipovetzky",
        "Trevor Cohn"
      ],
      "abstract": "Large Language Models (LLMs) have shown promise in solving natural\nlanguage-described planning tasks, but their direct use often leads to\ninconsistent reasoning and hallucination. While hybrid LLM-symbolic planning\npipelines have emerged as a more robust alternative, they typically require\nextensive expert intervention to refine and validate generated action schemas.\nIt not only limits scalability but also introduces a potential for biased\ninterpretation, as a single expert's interpretation of ambiguous natural\nlanguage descriptions might not align with the user's actual intent. To address\nthis, we propose a novel approach that constructs an action schema library to\ngenerate multiple candidates, accounting for the diverse possible\ninterpretations of natural language descriptions. We further introduce a\nsemantic validation and ranking module that automatically filter and rank the\ngenerated schemas and plans without expert-in-the-loop. The experiments showed\nour pipeline maintains superiority in planning over the direct LLM planning\napproach. These findings demonstrate the feasibility of a fully automated\nend-to-end LLM-symbolic planner that requires no expert intervention, opening\nup the possibility for a broader audience to engage with AI planning with less\nprerequisite of domain expertise.",
      "tldr_zh": "该研究解决了Large Language Models (LLMs) 在处理自然语言描述的规划任务时存在的推理不一致和幻觉问题，并指出现有混合LLM-symbolic规划管道依赖专家干预的局限性。作者提出了一种新方法，通过构建action schema库生成多个候选方案，以应对自然语言描述的多重解释，并引入semantic validation and ranking module自动过滤和排名schemas及plans，无需专家参与。实验结果显示，该管道在规划性能上优于直接LLM方法，证明了完全自动化的端到端LLM-symbolic规划器的可行性，从而使更多用户无需领域专业知识即可参与AI规划。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "8 main body pages, 10 appendix pages",
      "pdf_url": "http://arxiv.org/pdf/2409.15915v1",
      "published_date": "2024-09-24 09:33:12 UTC",
      "updated_date": "2024-09-24 09:33:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:15:23.454815"
    },
    {
      "arxiv_id": "2409.15910v2",
      "title": "Enhancing IoT based Plant Health Monitoring through Advanced Human Plant Interaction using Large Language Models and Mobile Applications",
      "title_zh": "翻译失败",
      "authors": [
        "Kriti Agarwal",
        "Samhruth Ananthanarayanan",
        "Srinitish Srinivasan",
        "Abirami S"
      ],
      "abstract": "This paper presents the development of a novel plant communication\napplication that allows plants to \"talk\" to humans using real-time sensor data\nand AI-powered language models. Utilizing soil sensors that track moisture,\ntemperature, and nutrient levels, the system feeds this data into the Gemini\nAPI, where it is processed and transformed into natural language insights about\nthe plant's health and \"mood.\" Developed using Flutter, Firebase, and\nThingSpeak, the app offers a seamless user experience with real-time\ninteraction capabilities. By fostering human-plant connectivity, this system\nenhances plant care practices, promotes sustainability, and introduces\ninnovative applications for AI and IoT technologies in both personal and\nagricultural contexts. The paper explores the technical architecture, system\nintegration, and broader implications of AI-driven plant communication.",
      "tldr_zh": "本论文提出了一种基于IoT的植物健康监测系统，通过大型语言模型(Large Language Models)和移动应用实现高级人类-植物互动。系统利用土壤传感器实时跟踪湿度、温度和营养水平，将数据输入Gemini API处理后转化为自然语言的植物健康和“心情”洞见；应用使用Flutter、Firebase和ThingSpeak开发，提供无缝实时交互体验。该创新方案提升了植物护理实践、促进可持续性，并在个人和农业领域探索AI与IoT的更广泛应用，包括技术架构和系统集成。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Presented as poster at ICDTSA 2024. Link to poster:\n  https://drive.google.com/file/d/138POUASonUQxmJaPqRhwHBeTDhL7lWY3/view?usp=sharing",
      "pdf_url": "http://arxiv.org/pdf/2409.15910v2",
      "published_date": "2024-09-24 09:26:47 UTC",
      "updated_date": "2025-01-05 18:21:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:15:35.530794"
    },
    {
      "arxiv_id": "2409.15907v2",
      "title": "Enhancing Text-to-SQL Capabilities of Large Language Models via Domain Database Knowledge Injection",
      "title_zh": "通过领域数据库知识注入提升大型语言模型的 Text-to-SQL 能力",
      "authors": [
        "Xingyu Ma",
        "Xin Tian",
        "Lingxiang Wu",
        "Xuepeng Wang",
        "Xueming Tang",
        "Jinqiao Wang"
      ],
      "abstract": "Text-to-SQL is a subtask in semantic parsing that has seen rapid progress\nwith the evolution of Large Language Models (LLMs). However, LLMs face\nchallenges due to hallucination issues and a lack of domain-specific database\nknowledge(such as table schema and cell values). As a result, they can make\nerrors in generating table names, columns, and matching values to the correct\ncolumns in SQL statements. This paper introduces a method of knowledge\ninjection to enhance LLMs' ability to understand schema contents by\nincorporating prior knowledge. This approach improves their performance in\nText-to-SQL tasks. Experimental results show that pre-training LLMs on\ndomain-specific database knowledge and fine-tuning them on downstream\nText-to-SQL tasks significantly improves the Execution Match (EX) and Exact\nMatch (EM) metrics across various models. This effectively reduces errors in\ngenerating column names and matching values to the columns. Furthermore, the\nknowledge-injected models can be applied to many downstream Text-to-SQL tasks,\ndemonstrating the generalizability of the approach presented in this paper.",
      "tldr_zh": "该论文针对 Large Language Models (LLMs) 在 Text-to-SQL 任务中存在的幻觉问题和领域特定数据库知识（如表结构和单元值）的缺失，提出了一种知识注入方法，以提升模型对模式内容的理解能力。方法涉及预训练 LLMs 于相关数据库知识，然后在下游 Text-to-SQL 任务上进行微调，从而减少 SQL 语句中列名生成和值匹配的错误。实验结果显示，该方法显著提高了 Execution Match (EX) 和 Exact Match (EM) 指标，并证明了其在多种下游任务中的泛化性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "This paper has been accepted by ECAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.15907v2",
      "published_date": "2024-09-24 09:24:03 UTC",
      "updated_date": "2025-02-25 09:36:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:15:48.586721"
    },
    {
      "arxiv_id": "2409.15905v2",
      "title": "Boosting Code-Switching ASR with Mixture of Experts Enhanced Speech-Conditioned LLM",
      "title_zh": "翻译失败",
      "authors": [
        "Fengrun Zhang",
        "Wang Geng",
        "Hukai Huang",
        "Yahui Shan",
        "Cheng Yi",
        "He Qu"
      ],
      "abstract": "In this paper, we introduce a speech-conditioned Large Language Model (LLM)\nintegrated with a Mixture of Experts (MoE) based connector to address the\nchallenge of Code-Switching (CS) in Automatic Speech Recognition (ASR).\nSpecifically, we propose an Insertion and Deletion of Interruption Token (IDIT)\nmechanism for better transfer text generation ability of LLM to speech\nrecognition task. We also present a connecter with MoE architecture that\nmanages multiple languages efficiently. To further enhance the collaboration of\nmultiple experts and leverage the understanding capabilities of LLM, we propose\na two-stage progressive training strategy: 1) The connector is unfrozen and\ntrained with language-specialized experts to map speech representations to the\ntext space. 2) The connector and LLM LoRA adaptor are trained with the proposed\nIDIT mechanism and all experts are activated to learn general representations.\nExperimental results demonstrate that our method significantly outperforms\nstate-of-the-art models, including end-to-end and large-scale audio-language\nmodels.",
      "tldr_zh": "本文提出了一种增强 Code-Switching (CS) Automatic Speech Recognition (ASR) 的方法，通过集成 Mixture of Experts (MoE) 的 speech-conditioned Large Language Model (LLM) 来处理多语言切换挑战。关键创新包括 Insertion and Deletion of Interruption Token (IDIT) 机制，用于将 LLM 的文本生成能力更好地应用于语音识别，以及一个两阶段渐进式训练策略：首先训练 MoE 连接器以映射语音表示到文本空间，然后激活所有专家联合训练 LLM LoRA adaptor 以学习通用表示。实验结果显示，该方法显著优于现有最先进模型，包括端到端和大规模音频语言模型，在 CS-ASR 任务中表现出色。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Submitted to ICASSP 2025",
      "pdf_url": "http://arxiv.org/pdf/2409.15905v2",
      "published_date": "2024-09-24 09:20:22 UTC",
      "updated_date": "2024-10-31 02:26:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:16:01.036959"
    },
    {
      "arxiv_id": "2409.15903v1",
      "title": "Five questions and answers about artificial intelligence",
      "title_zh": "关于人工智能的五个问题与答案",
      "authors": [
        "Alberto Prieto",
        "Beatriz Prieto"
      ],
      "abstract": "Rapid advances in Artificial Intelligence (AI) are generating much\ncontroversy in society, often without scientific basis. As occurred the\ndevelopment of other emerging technologies, such as the introduction of\nelectricity in the early 20th century, AI causes both fascination and fear.\nFollowing the advice of the philosopher R.W. Emerson's: advice the knowledge is\nthe antidote to fear; this paper seeks to contribute to the dissemination of\nknowledge about AI. To this end, it reflects on the following questions: the\norigins of AI, its possible future evolution, its ability to show feelings, the\nassociated threats and dangers, and the concept of AI singularity.",
      "tldr_zh": "这篇论文针对社会对人工智能（AI）的争议，通过回答五个关键问题来传播知识，并以哲学家 R.W. Emerson 的观点为指导，认为知识是恐惧的解药。主要讨论的问题包括 AI 的起源、可能的未来演变、AI 是否能表现出情感、相关的威胁和危险，以及 AI singularity 的概念。论文旨在通过反思这些问题，帮助公众更好地理解 AI 的发展与影响，为理性讨论提供基础。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "17 pages, 0 figures, Scientific and technological popularization\n  article",
      "pdf_url": "http://arxiv.org/pdf/2409.15903v1",
      "published_date": "2024-09-24 09:19:55 UTC",
      "updated_date": "2024-09-24 09:19:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:16:11.167762"
    },
    {
      "arxiv_id": "2410.02816v1",
      "title": "Bipolar fuzzy relation equations systems based on the product t-norm",
      "title_zh": "翻译失败",
      "authors": [
        "M. Eugenia Cornejo",
        "David Lobo",
        "Jesús Medina"
      ],
      "abstract": "Bipolar fuzzy relation equations arise as a generalization of fuzzy relation\nequations considering unknown variables together with their logical connective\nnegations. The occurrence of a variable and the occurrence of its negation\nsimultaneously can give very useful information for certain frameworks where\nthe human reasoning plays a key role. Hence, the resolution of bipolar fuzzy\nrelation equations systems is a research topic of great interest.\n  This paper focuses on the study of bipolar fuzzy relation equations systems\nbased on the max-product t-norm composition. Specifically, the solvability and\nthe algebraic structure of the set of solutions of these bipolar equations\nsystems will be studied, including the case in which such systems are composed\nof equations whose independent term be equal to zero. As a consequence, this\npaper complements the contribution carried out by the authors on the\nsolvability of bipolar max-product fuzzy relation equations.",
      "tldr_zh": "这篇论文研究了基于 product t-norm 的双极 fuzzy relation equations 系统，作为模糊 relation equations 的推广，强调变量及其否定的同时出现对人类推理框架的实用价值。论文重点分析了这些方程系统的可解性（solvability）和解集的代数结构，特别是 max-product t-norm 组合下的情况，包括独立项为零的场景。结果补充了作者先前对双极 max-product fuzzy relation equations 可解性的工作，为模糊逻辑应用提供了更全面的理论基础。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.02816v1",
      "published_date": "2024-09-24 09:09:13 UTC",
      "updated_date": "2024-09-24 09:09:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:16:24.267991"
    },
    {
      "arxiv_id": "2409.15892v1",
      "title": "Symmetries and Expressive Requirements for Learning General Policies",
      "title_zh": "对称性和学习一般策略的表达性要求",
      "authors": [
        "Dominik Drexler",
        "Simon Ståhlberg",
        "Blai Bonet",
        "Hector Geffner"
      ],
      "abstract": "State symmetries play an important role in planning and generalized planning.\nIn the first case, state symmetries can be used to reduce the size of the\nsearch; in the second, to reduce the size of the training set. In the case of\ngeneral planning, however, it is also critical to distinguish non-symmetric\nstates, i.e., states that represent non-isomorphic relational structures.\nHowever, while the language of first-order logic distinguishes non-symmetric\nstates, the languages and architectures used to represent and learn general\npolicies do not. In particular, recent approaches for learning general policies\nuse state features derived from description logics or learned via graph neural\nnetworks (GNNs) that are known to be limited by the expressive power of C_2,\nfirst-order logic with two variables and counting. In this work, we address the\nproblem of detecting symmetries in planning and generalized planning and use\nthe results to assess the expressive requirements for learning general policies\nover various planning domains. For this, we map planning states to plain\ngraphs, run off-the-shelf algorithms to determine whether two states are\nisomorphic with respect to the goal, and run coloring algorithms to determine\nif C_2 features computed logically or via GNNs distinguish non-isomorphic\nstates. Symmetry detection results in more effective learning, while the\nfailure to detect non-symmetries prevents general policies from being learned\nat all in certain domains.",
      "tldr_zh": "该论文探讨了状态对称性（state symmetries）在规划和广义规划（generalized planning）中的作用，强调其能减少搜索和训练规模，但现有方法（如基于描述逻辑或图神经网络（GNNs））的表达能力受限于 C_2（一阶逻辑的子集），无法有效区分非同构状态。作者提出一种方法，将规划状态映射到普通图上，使用同构检测和着色算法来识别对称性和非对称性，从而评估学习广义策略的表达要求。实验结果显示，这种对称性检测能显著提升学习效率，而忽略非对称性可能导致某些规划领域完全无法学习一般策略。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at the 21st International Conference on Principles of\n  Knowledge Representation and Reasoning (KR2024) in the Reasoning, Learning,\n  and Decision Making track",
      "pdf_url": "http://arxiv.org/pdf/2409.15892v1",
      "published_date": "2024-09-24 09:04:47 UTC",
      "updated_date": "2024-09-24 09:04:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:16:37.135869"
    },
    {
      "arxiv_id": "2409.15879v1",
      "title": "Machine Translation Advancements of Low-Resource Indian Languages by Transfer Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Bin Wei",
        "Jiawei Zhen",
        "Zongyao Li",
        "Zhanglin Wu",
        "Daimeng Wei",
        "Jiaxin Guo",
        "Zhiqiang Rao",
        "Shaojun Li",
        "Yuanchang Luo",
        "Hengchao Shang",
        "Jinlong Yang",
        "Yuhao Xie",
        "Hao Yang"
      ],
      "abstract": "This paper introduces the submission by Huawei Translation Center (HW-TSC) to\nthe WMT24 Indian Languages Machine Translation (MT) Shared Task. To develop a\nreliable machine translation system for low-resource Indian languages, we\nemployed two distinct knowledge transfer strategies, taking into account the\ncharacteristics of the language scripts and the support available from existing\nopen-source models for Indian languages. For Assamese(as) and Manipuri(mn), we\nfine-tuned the existing IndicTrans2 open-source model to enable bidirectional\ntranslation between English and these languages. For Khasi (kh) and Mizo (mz),\nWe trained a multilingual model as a baseline using bilingual data from these\nfour language pairs, along with an additional about 8kw English-Bengali\nbilingual data, all of which share certain linguistic features. This was\nfollowed by fine-tuning to achieve bidirectional translation between English\nand Khasi, as well as English and Mizo. Our transfer learning experiments\nproduced impressive results: 23.5 BLEU for en-as, 31.8 BLEU for en-mn, 36.2\nBLEU for as-en, and 47.9 BLEU for mn-en on their respective test sets.\nSimilarly, the multilingual model transfer learning experiments yielded\nimpressive outcomes, achieving 19.7 BLEU for en-kh, 32.8 BLEU for en-mz, 16.1\nBLEU for kh-en, and 33.9 BLEU for mz-en on their respective test sets. These\nresults not only highlight the effectiveness of transfer learning techniques\nfor low-resource languages but also contribute to advancing machine translation\ncapabilities for low-resource Indian languages.",
      "tldr_zh": "这篇论文介绍了华为翻译中心（HW-TSC）在 WMT24 印度语言机器翻译共享任务中的提交，专注于通过 Transfer Learning 提升低资源印度语言的机器翻译性能。针对阿萨姆语 (as) 和曼尼普尔语 (mn)，他们微调了 IndicTrans2 开源模型，实现英语与这些语言的双向翻译；对于卡西语 (kh) 和米佐语 (mz)，则训练了一个多语言模型作为基线，并使用相关双语数据进行后续微调。实验结果显示，该方法在测试集上取得了显著成效，包括 en-as 23.5 BLEU、en-mn 31.8 BLEU 及其他方向的 BLEU 分数。这些成果突出了 Transfer Learning 在低资源语言中的有效性，并为印度语言的机器翻译能力提供了重要推进。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "6 pages, wmt24. arXiv admin note: substantial text overlap with\n  arXiv:2409.14800",
      "pdf_url": "http://arxiv.org/pdf/2409.15879v1",
      "published_date": "2024-09-24 08:53:19 UTC",
      "updated_date": "2024-09-24 08:53:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:16:48.699770"
    },
    {
      "arxiv_id": "2409.16331v1",
      "title": "Exploring the traditional NMT model and Large Language Model for chat translation",
      "title_zh": "翻译失败",
      "authors": [
        "Jinlong Yang",
        "Hengchao Shang",
        "Daimeng Wei",
        "Jiaxin Guo",
        "Zongyao Li",
        "Zhanglin Wu",
        "Zhiqiang Rao",
        "Shaojun Li",
        "Yuhao Xie",
        "Yuanchang Luo",
        "Jiawei Zheng",
        "Bin Wei",
        "Hao Yang"
      ],
      "abstract": "This paper describes the submissions of Huawei Translation Services\nCenter(HW-TSC) to WMT24 chat translation shared task on\nEnglish$\\leftrightarrow$Germany (en-de) bidirection. The experiments involved\nfine-tuning models using chat data and exploring various strategies, including\nMinimum Bayesian Risk (MBR) decoding and self-training. The results show\nsignificant performance improvements in certain directions, with the MBR\nself-training method achieving the best results. The Large Language Model also\ndiscusses the challenges and potential avenues for further research in the\nfield of chat translation.",
      "tldr_zh": "这篇论文探讨了传统 NMT 模型和 Large Language Model 在聊天翻译中的应用，针对 WMT24 聊天翻译共享任务的英德双向翻译。研究团队使用聊天数据微调模型，并探索了 Minimum Bayesian Risk (MBR) 解码和 self-training 等策略。结果显示，这些方法显著提升了某些翻译方向的性能，其中 MBR self-training 取得了最佳效果；论文还讨论了聊天翻译领域的挑战和潜在的进一步研究方向。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "7 pages, 6 Tables, WMT24",
      "pdf_url": "http://arxiv.org/pdf/2409.16331v1",
      "published_date": "2024-09-24 08:48:25 UTC",
      "updated_date": "2024-09-24 08:48:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:16:58.897808"
    },
    {
      "arxiv_id": "2409.15869v1",
      "title": "Whisper in Medusa's Ear: Multi-head Efficient Decoding for Transformer-based ASR",
      "title_zh": "翻译失败",
      "authors": [
        "Yael Segal-Feldman",
        "Aviv Shamsian",
        "Aviv Navon",
        "Gill Hetz",
        "Joseph Keshet"
      ],
      "abstract": "Large transformer-based models have significant potential for speech\ntranscription and translation. Their self-attention mechanisms and parallel\nprocessing enable them to capture complex patterns and dependencies in audio\nsequences. However, this potential comes with challenges, as these large and\ncomputationally intensive models lead to slow inference speeds. Various\noptimization strategies have been proposed to improve performance, including\nefficient hardware utilization and algorithmic enhancements. In this paper, we\nintroduce Whisper-Medusa, a novel approach designed to enhance processing speed\nwith minimal impact on Word Error Rate (WER). The proposed model extends the\nOpenAI's Whisper architecture by predicting multiple tokens per iteration,\nresulting in a 50% reduction in latency. We showcase the effectiveness of\nWhisper-Medusa across different learning setups and datasets.",
      "tldr_zh": "本研究针对Transformer-based ASR模型在语音转录和翻译中的计算密集问题，提出Whisper-Medusa方法，该方法扩展了OpenAI's Whisper架构，通过多头高效解码机制每迭代预测多个tokens，实现延迟减少50%。这种优化策略在最小化Word Error Rate (WER)影响的同时，显著提升了推理速度。实验在不同学习设置和数据集上验证了Whisper-Medusa的有效性，为Transformer-based ASR的实际应用提供了新途径。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.LG",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "Under Review",
      "pdf_url": "http://arxiv.org/pdf/2409.15869v1",
      "published_date": "2024-09-24 08:42:31 UTC",
      "updated_date": "2024-09-24 08:42:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:17:12.825334"
    },
    {
      "arxiv_id": "2409.15867v5",
      "title": "In-Context Ensemble Learning from Pseudo Labels Improves Video-Language Models for Low-Level Workflow Understanding",
      "title_zh": "翻译失败",
      "authors": [
        "Moucheng Xu",
        "Evangelos Chatzaroulas",
        "Luc McCutcheon",
        "Abdul Ahad",
        "Hamzah Azeem",
        "Janusz Marecki",
        "Ammar Anwar"
      ],
      "abstract": "A Standard Operating Procedure (SOP) defines a low-level, step-by-step\nwritten guide for a business software workflow. SOP generation is a crucial\nstep towards automating end-to-end software workflows. Manually creating SOPs\ncan be time-consuming. Recent advancements in large video-language models offer\nthe potential for automating SOP generation by analyzing recordings of human\ndemonstrations. However, current large video-language models face challenges\nwith zero-shot SOP generation. In this work, we first explore in-context\nlearning with video-language models for SOP generation. We then propose an\nexploration-focused strategy called In-Context Ensemble Learning, to aggregate\npseudo labels of multiple possible paths of SOPs. The proposed in-context\nensemble learning as well enables the models to learn beyond its context window\nlimit with an implicit consistency regularisation. We report that in-context\nlearning helps video-language models to generate more temporally accurate SOP,\nand the proposed in-context ensemble learning can consistently enhance the\ncapabilities of the video-language models in SOP generation.",
      "tldr_zh": "该论文探讨了使用视频语言模型（video-language models）自动生成 Standard Operating Procedure (SOP)，以简化低级工作流程理解的问题，因为手动创建 SOP 耗时费力。作者首先探索了 in-context learning 方法，帮助模型在零样本场景下生成更精确的时序 SOP。然后，他们提出 In-Context Ensemble Learning 策略，通过聚合伪标签（pseudo labels）来整合多个可能的 SOP 路径，并利用隐式一致性正则化超越模型的上下文窗口限制。实验结果表明，这种方法显著提升了视频语言模型在 SOP 生成方面的性能和准确性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "To appear in NeurIPS Workshop on Video-Language Models 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.15867v5",
      "published_date": "2024-09-24 08:41:01 UTC",
      "updated_date": "2024-10-20 10:45:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:17:25.355881"
    },
    {
      "arxiv_id": "2409.15865v1",
      "title": "BeSimulator: A Large Language Model Powered Text-based Behavior Simulator",
      "title_zh": "翻译失败",
      "authors": [
        "Jianan Wang",
        "Bin Li",
        "Xueying Wang",
        "Fu Li",
        "Yunlong Wu",
        "Juan Chen",
        "Xiaodong Yi"
      ],
      "abstract": "Traditional robot simulators focus on physical process modeling and realistic\nrendering, often suffering from high computational costs, inefficiencies, and\nlimited adaptability. To handle this issue, we propose Behavior Simulation in\nrobotics to emphasize checking the behavior logic of robots and achieving\nsufficient alignment between the outcome of robot actions and real scenarios.\nIn this paper, we introduce BeSimulator, a modular and novel LLM-powered\nframework, as an attempt towards behavior simulation in the context of\ntext-based environments. By constructing text-based virtual environments and\nperforming semantic-level simulation, BeSimulator can generalize across\nscenarios and achieve long-horizon complex simulation. Inspired by human\ncognition processes, it employs a \"consider-decide-capture-transfer\"\nmethodology, termed Chain of Behavior Simulation, which excels at analyzing\naction feasibility and state transitions. Additionally, BeSimulator\nincorporates code-driven reasoning to enable arithmetic operations and enhance\nreliability, as well as integrates reflective feedback to refine simulation.\nBased on our manually constructed behavior-tree-based simulation benchmark\nBTSIMBENCH, our experiments show a significant performance improvement in\nbehavior simulation compared to baselines, ranging from 14.7% to 26.6%.",
      "tldr_zh": "该论文提出 BeSimulator，一种由 Large Language Model (LLM) 驱动的文本-based 行为模拟框架，旨在解决传统机器人模拟器在计算成本、效率和适应性上的问题，通过强调机器人行为逻辑的检查和与真实场景的对齐。框架采用模块化设计，构建文本虚拟环境，并运用 Chain of Behavior Simulation 方法（包括 consider-decide-capture-transfer 过程）、code-driven reasoning 进行算术运算，以及 reflective feedback 机制来优化模拟准确性和可靠性。在自定义基准 BTSIMBENCH 上，实验显示 BeSimulator 比基线模型性能提升 14.7% 到 26.6%，证明其在跨场景泛化和长horizon 复杂模拟方面的显著优势。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.RO",
      "comment": "7 pages, 3 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2409.15865v1",
      "published_date": "2024-09-24 08:37:04 UTC",
      "updated_date": "2024-09-24 08:37:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:17:39.610960"
    },
    {
      "arxiv_id": "2409.15861v3",
      "title": "A Zero-Shot Open-Vocabulary Pipeline for Dialogue Understanding",
      "title_zh": "翻译失败",
      "authors": [
        "Abdulfattah Safa",
        "Gözde Gül Şahin"
      ],
      "abstract": "Dialogue State Tracking (DST) is crucial for understanding user needs and\nexecuting appropriate system actions in task-oriented dialogues. Majority of\nexisting DST methods are designed to work within predefined ontologies and\nassume the availability of gold domain labels, struggling with adapting to new\nslots values. While Large Language Models (LLMs)-based systems show promising\nzero-shot DST performance, they either require extensive computational\nresources or they underperform existing fully-trained systems, limiting their\npracticality. To address these limitations, we propose a zero-shot,\nopen-vocabulary system that integrates domain classification and DST in a\nsingle pipeline. Our approach includes reformulating DST as a\nquestion-answering task for less capable models and employing self-refining\nprompts for more adaptable ones. Our system does not rely on fixed slot values\ndefined in the ontology allowing the system to adapt dynamically. We compare\nour approach with existing SOTA, and show that it provides up to 20% better\nJoint Goal Accuracy (JGA) over previous methods on datasets like Multi-WOZ 2.1,\nwith up to 90% fewer requests to the LLM API.",
      "tldr_zh": "该论文提出了一种零-shot、开放词汇的对话理解管道，旨在解决传统 Dialogue State Tracking (DST) 方法依赖预定义本体和领域标签的局限性，使其能动态适应新槽值。方法将 DST 重新表述为问答任务，并结合自精炼提示（self-refining prompts），以整合领域分类和 DST 为单一流程，同时减少对 Large Language Models (LLMs) 的计算需求。实验结果显示，该系统在 Multi-WOZ 2.1 等数据集上比现有 SOTA 方法提高多达 20% 的 Joint Goal Accuracy (JGA)，并减少多达 90% 的 LLM API 请求，显著提升了实用性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to NAACL 2025",
      "pdf_url": "http://arxiv.org/pdf/2409.15861v3",
      "published_date": "2024-09-24 08:33:41 UTC",
      "updated_date": "2025-03-07 19:50:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:17:50.151859"
    },
    {
      "arxiv_id": "2409.15858v2",
      "title": "Identification For Control Based on Neural Networks: Approximately Linearizable Models",
      "title_zh": "翻译失败",
      "authors": [
        "Maxime Thieffry",
        "Alexandre Hache",
        "Mohamed Yagoubi",
        "Philippe Chevrel"
      ],
      "abstract": "This work presents a control-oriented identification scheme for efficient\ncontrol design and stability analysis of nonlinear systems. Neural networks are\nused to identify a discrete-time nonlinear state-space model to approximate\ntime-domain input-output behavior of a nonlinear system. The network is\nconstructed such that the identified model is approximately linearizable by\nfeedback, ensuring that the control law trivially follows from the learning\nstage. After the identification and quasi-linearization procedures, linear\ncontrol theory comes at hand to design robust controllers and study stability\nof the closed-loop system. The effectiveness and interest of the methodology\nare illustrated throughout the paper on popular benchmarks for system\nidentification.",
      "tldr_zh": "本研究提出了一种基于神经网络的控制导向识别方案，用于非线性系统的高效控制设计和稳定性分析。神经网络用于构建离散时间非线性状态空间模型，以逼近系统的时域输入输出行为，并确保模型可以通过反馈近似线性化，从而使控制律直接从学习阶段得出。识别和准线性化后，可应用线性控制理论设计鲁棒控制器并分析闭环系统的稳定性。该方法在流行系统识别基准上得到验证，展示了其有效性和实用性。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "15 pages, 3 figures, 6 tables, accepted as a poster in SysDO 2024,\n  Stuttgart, Germany",
      "pdf_url": "http://arxiv.org/pdf/2409.15858v2",
      "published_date": "2024-09-24 08:31:22 UTC",
      "updated_date": "2024-10-03 10:59:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:18:00.782025"
    },
    {
      "arxiv_id": "2409.15844v2",
      "title": "Adaptive Learn-then-Test: Statistically Valid and Efficient Hyperparameter Selection",
      "title_zh": "翻译失败",
      "authors": [
        "Matteo Zecchin",
        "Sangwoo Park",
        "Osvaldo Simeone"
      ],
      "abstract": "We introduce adaptive learn-then-test (aLTT), an efficient hyperparameter\nselection procedure that provides finite-sample statistical guarantees on the\npopulation risk of AI models. Unlike the existing learn-then-test (LTT)\ntechnique, which relies on conventional p-value-based multiple hypothesis\ntesting (MHT), aLTT implements sequential data-dependent MHT with early\ntermination by leveraging e-processes. As a result, aLTT can reduce the number\nof testing rounds, making it particularly well-suited for scenarios in which\ntesting is costly or presents safety risks. Apart from maintaining statistical\nvalidity, in applications such as online policy selection for offline\nreinforcement learning and prompt engineering, aLTT is shown to achieve the\nsame performance as LTT while requiring only a fraction of the testing rounds.",
      "tldr_zh": "本文提出了一种名为adaptive learn-then-test (aLTT)的超参数选择方法，能够为AI模型提供有限样本的统计有效性保证。不同于传统的learn-then-test (LTT)方法，aLTT采用sequential data-dependent multiple hypothesis testing (MHT)结合e-processes，实现早停机制，从而减少测试轮数，特别适合测试成本高或涉及安全风险的场景。在在线策略选择、离线强化学习和prompt engineering等应用中，aLTT与LTT性能相当，但只需少量测试轮数，显著提高了效率。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.IT",
        "cs.LG",
        "math.IT",
        "stat.ME"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.15844v2",
      "published_date": "2024-09-24 08:14:26 UTC",
      "updated_date": "2025-01-31 15:04:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:18:13.587248"
    },
    {
      "arxiv_id": "2409.15843v2",
      "title": "From Passive Watching to Active Learning: Empowering Proactive Participation in Digital Classrooms with AI Video Assistant",
      "title_zh": "翻译失败",
      "authors": [
        "Anna Bodonhelyi",
        "Enkeleda Thaqi",
        "Süleyman Özdel",
        "Efe Bozkir",
        "Enkelejda Kasneci"
      ],
      "abstract": "In online education, innovative tools are crucial for enhancing learning\noutcomes. SAM (Study with AI Mentor) is an advanced platform that integrates\neducational videos with a context-aware chat interface powered by large\nlanguage models. SAM encourages students to ask questions and explore unclear\nconcepts in real time, offering personalized, context-specific assistance,\nincluding explanations of formulas, slides, and images. We evaluated SAM in two\nstudies: one with 25 university students and another with 80 crowdsourced\nparticipants, using pre- and post-knowledge tests to compare a group using SAM\nand a control group. The results demonstrated that SAM users achieved greater\nknowledge gains specifically for younger learners and individuals in flexible\nworking environments, such as students, supported by a 97.6% accuracy rate in\nthe chatbot's responses. Participants also provided positive feedback on SAM's\nusability and effectiveness. SAM's proactive approach to learning not only\nenhances learning outcomes but also empowers students to take full ownership of\ntheir educational experience, representing a promising future direction for\nonline learning tools.",
      "tldr_zh": "本研究提出SAM平台，这是一个整合教育视频和基于大语言模型的上下文感知聊天界面的AI工具，旨在鼓励学生主动提问和探索概念，提供个性化协助如解释公式、幻灯片和图像，从而从被动观看转向主动学习。研究通过两个实验评估SAM的效果：一个涉及25名大学学生，另一个涉及80名众包参与者，使用前后知识测试比较SAM组和控制组，结果显示SAM用户在年轻学习者和灵活工作环境（如学生）中获得更大知识提升，聊天机器人响应准确率达97.6%。参与者对SAM的可用性和有效性给予积极反馈，这标志着SAM为在线教育工具的未来发展提供了有前景的方向。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.15843v2",
      "published_date": "2024-09-24 08:12:36 UTC",
      "updated_date": "2025-02-24 11:05:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:18:25.918703"
    },
    {
      "arxiv_id": "2409.19015v1",
      "title": "Textless NLP -- Zero Resource Challenge with Low Resource Compute",
      "title_zh": "Textless NLP：零资源挑战与低资源计算",
      "authors": [
        "Krithiga Ramadass",
        "Abrit Pal Singh",
        "Srihari J",
        "Sheetal Kalyani"
      ],
      "abstract": "This work addresses the persistent challenges of substantial training time\nand GPU resource requirements even when training lightweight encoder-vocoder\nmodels for Textless NLP. We reduce training steps significantly while improving\nperformance by a) leveraging learning rate schedulers for efficient and faster\nconvergence b) optimizing hop length and c) tuning the interpolation scale\nfactors for better audio quality. Additionally, we explore the latent space\nrepresentation for Indian languages such as Tamil and Bengali for the acoustic\nunit discovery and voice conversion task. Our approach leverages a quantized\nencoder architecture, in conjunction with a vocoder which utilizes the proposed\nmixture of optimized hop length, tuned interpolation scale factors and a cyclic\nlearning rate scheduler. We obtain consistently good results across English,\nTamil and Bengali datasets. The proposed method excels in capturing complex\nlinguistic patterns, resulting in clear reconstructed audio during voice\nconversion with significantly reduced training time.",
      "tldr_zh": "本研究针对 Textless NLP 中的训练挑战，提出了一种低资源计算方法，通过使用学习率调度器、优化 hop length 和调整 interpolation scale factors，显著减少训练步骤并提升性能。该方法结合 quantized encoder 架构和 vocoder，探索了泰米尔语和孟加拉语等印度语言的潜在空间表示，用于 acoustic unit discovery 和 voice conversion 任务。在英语、泰米尔语和孟加拉语数据集上，该方法实现了清晰的音频重建和语音转换效果，同时大幅降低了训练时间。整体结果表明，该框架在捕捉复杂语言模式方面表现出色，为零资源场景下的 NLP 应用提供了高效解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.19015v1",
      "published_date": "2024-09-24 08:08:05 UTC",
      "updated_date": "2024-09-24 08:08:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:18:37.136306"
    },
    {
      "arxiv_id": "2409.15825v2",
      "title": "60 Data Points are Sufficient to Fine-Tune LLMs for Question-Answering",
      "title_zh": "60 个数据点足以微调 LLMs 用于问答",
      "authors": [
        "Junjie Ye",
        "Yuming Yang",
        "Qi Zhang",
        "Tao Gui",
        "Xuanjing Huang",
        "Peng Wang",
        "Zhongchao Shi",
        "Jianping Fan"
      ],
      "abstract": "Large language models (LLMs) encode extensive world knowledge through\npre-training on massive datasets, which can then be fine-tuned for the\nquestion-answering (QA) task. However, effective strategies for fine-tuning\nLLMs for the QA task remain largely unexplored. To address this gap, we\ncategorize supervised fine-tuning (SFT) data based on the extent of knowledge\nmemorized by the pretrained LLMs and conduct a series of empirical analyses.\nOur experiments, involving four LLMs from three different model families, focus\non three key factors: the amount of data required for SFT, the impact of\ndifferent SFT datasets on model performance, and how data requirements vary\nacross LLMs. The results show that as few as 60 data points during the SFT\nstage can activate the knowledge encoded during pre-training, enabling LLMs to\nperform the QA task. Additionally, SFT with data of varying memory levels has a\nsignificant impact on LLM performance, with the optimal dataset differing based\non the specific model being fine-tuned. Future research will delve deeper into\nthe mechanisms underlying these phenomena.",
      "tldr_zh": "本研究发现，仅需60个数据点即可有效微调大型语言模型(LLMs)用于问答(QA)任务，通过激活其预训练知识。研究者将监督微调(SFT)数据分类基于模型记忆程度，并对四个LLMs进行实证分析，评估数据量、数据集影响及模型间差异。结果显示，不同记忆水平的SFT数据显著影响性能，且最优数据集因具体模型而异。未来研究将进一步探讨这些现象的潜在机制。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.15825v2",
      "published_date": "2024-09-24 07:38:38 UTC",
      "updated_date": "2025-01-20 15:37:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:18:50.537848"
    },
    {
      "arxiv_id": "2409.15817v1",
      "title": "SwiftDossier: Tailored Automatic Dossier for Drug Discovery with LLMs and Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Gabriele Fossi",
        "Youssef Boulaimen",
        "Leila Outemzabet",
        "Nathalie Jeanray",
        "Stephane Gerart",
        "Sebastien Vachenc",
        "Joanna Giemza",
        "Salvatore Raieli"
      ],
      "abstract": "The advancement of artificial intelligence algorithms has expanded their\napplication to several fields such as the biomedical domain. Artificial\nintelligence systems, including Large Language Models (LLMs), can be\nparticularly advantageous in drug discovery, which is a very long and expensive\nprocess. However, LLMs by themselves lack in-depth knowledge about specific\ndomains and can generate factually incorrect information. Moreover, they are\nnot able to perform more complex actions that imply the usage of external\ntools. Our work is focused on these two issues. Firstly, we show how the\nimplementation of an advanced RAG system can help the LLM to generate more\naccurate answers to drug-discovery-related questions. The results show that the\nanswers generated by the LLM with the RAG system surpass in quality the answers\nproduced by the model without RAG. Secondly, we show how to create an automatic\ntarget dossier using LLMs and incorporating them with external tools that they\ncan use to execute more intricate tasks to gather data such as accessing\ndatabases and executing code. The result is a production-ready target dossier\ncontaining the acquired information summarized into a PDF and a PowerPoint\npresentation.",
      "tldr_zh": "本研究提出SwiftDossier，一种针对药物发现的自动档案生成框架，利用Large Language Models (LLMs) 和代理系统来解决LLMs的领域知识不足和信息错误问题。通过实施高级Retrieval-Augmented Generation (RAG) 系统，该框架显著提升了LLMs对药物相关问题的回答准确性和质量。研究进一步展示了如何整合外部工具（如数据库访问和代码执行），实现自动生成目标档案，并将获取的信息总结为PDF和PowerPoint文件。实验结果表明，此方法为药物发现过程提供了高效、可信赖的生产就绪解决方案。",
      "categories": [
        "cs.AI",
        "68T07, 92C50, 68T09",
        "I.2.7; J.3"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages, 7 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2409.15817v1",
      "published_date": "2024-09-24 07:29:05 UTC",
      "updated_date": "2024-09-24 07:29:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:19:01.380098"
    },
    {
      "arxiv_id": "2409.15815v1",
      "title": "AsthmaBot: Multi-modal, Multi-Lingual Retrieval Augmented Generation For Asthma Patient Support",
      "title_zh": "翻译失败",
      "authors": [
        "Adil Bahaj",
        "Mounir Ghogho"
      ],
      "abstract": "Asthma rates have risen globally, driven by environmental and lifestyle\nfactors. Access to immediate medical care is limited, particularly in\ndeveloping countries, necessitating automated support systems. Large Language\nModels like ChatGPT (Chat Generative Pre-trained Transformer) and Gemini have\nadvanced natural language processing in general and question answering in\nparticular, however, they are prone to producing factually incorrect responses\n(i.e. hallucinations). Retrieval-augmented generation systems, integrating\ncurated documents, can improve large language models' performance and reduce\nthe incidence of hallucination. We introduce AsthmaBot, a multi-lingual,\nmulti-modal retrieval-augmented generation system for asthma support.\nEvaluation of an asthma-related frequently asked questions dataset shows\nAsthmaBot's efficacy. AsthmaBot has an added interactive and intuitive\ninterface that integrates different data modalities (text, images, videos) to\nmake it accessible to the larger public. AsthmaBot is available online via\n\\url{asthmabot.datanets.org}.",
      "tldr_zh": "本研究针对哮喘发病率全球上升和医疗资源有限的问题，引入AsthmaBot，一种多语言(multi-lingual)和多模态(multi-modal)的检索增强生成(Retrieval Augmented Generation)系统，以减少大型语言模型(Large Language Models)如ChatGPT的幻觉问题，并为哮喘患者提供支持。AsthmaBot整合文本、图像和视频等模态，并配备交互式界面，使其更易访问和使用。在哮喘相关常见问题数据集上的评估显示，该系统有效提升了响应准确性，并已在线提供，网址为asthmabot.datanets.org。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages",
      "pdf_url": "http://arxiv.org/pdf/2409.15815v1",
      "published_date": "2024-09-24 07:24:01 UTC",
      "updated_date": "2024-09-24 07:24:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:19:14.538679"
    },
    {
      "arxiv_id": "2409.15814v1",
      "title": "Interactive Example-based Explanations to Improve Health Professionals' Onboarding with AI for Human-AI Collaborative Decision Making",
      "title_zh": "翻译失败",
      "authors": [
        "Min Hun Lee",
        "Renee Bao Xuan Ng",
        "Silvana Xinyi Choo",
        "Shamala Thilarajah"
      ],
      "abstract": "A growing research explores the usage of AI explanations on user's decision\nphases for human-AI collaborative decision-making. However, previous studies\nfound the issues of overreliance on `wrong' AI outputs. In this paper, we\npropose interactive example-based explanations to improve health professionals'\nonboarding with AI for their better reliance on AI during AI-assisted\ndecision-making. We implemented an AI-based decision support system that\nutilizes a neural network to assess the quality of post-stroke survivors'\nexercises and interactive example-based explanations that systematically\nsurface the nearest neighborhoods of a test/task sample from the training set\nof the AI model to assist users' onboarding with the AI model. To investigate\nthe effect of interactive example-based explanations, we conducted a study with\ndomain experts, health professionals to evaluate their performance and reliance\non AI. Our interactive example-based explanations during onboarding assisted\nhealth professionals in having a better reliance on AI and making a higher\nratio of making `right' decisions and a lower ratio of `wrong' decisions than\nproviding only feature-based explanations during the decision-support phase.\nOur study discusses new challenges of assisting user's onboarding with AI for\nhuman-AI collaborative decision-making.",
      "tldr_zh": "本研究针对人类-AI 协作决策中健康专业人士过度依赖错误 AI 输出的问题，提出了一种交互式基于示例的解释（interactive example-based explanations）方法，以提升他们的 AI 适应（onboarding）。该方法通过构建一个基于神经网络的决策支持系统，评估中风幸存者锻炼质量，并提供测试样本的最近邻居示例，帮助用户更好地理解 AI 模型。实验结果显示，与仅提供特征-based 解释相比，这种交互式解释显著提高了健康专业人士的正确决策比例，降低了错误决策比例，并讨论了协助用户适应 AI 的新挑战。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.15814v1",
      "published_date": "2024-09-24 07:20:09 UTC",
      "updated_date": "2024-09-24 07:20:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:19:27.373207"
    },
    {
      "arxiv_id": "2409.15813v1",
      "title": "Layer-wise Model Merging for Unsupervised Domain Adaptation in Segmentation Tasks",
      "title_zh": "逐层模型合并用于无监督域适应中的分割任务",
      "authors": [
        "Roberto Alcover-Couso",
        "Juan C. SanMiguel",
        "Marcos Escudero-Viñolo",
        "Jose M Martínez"
      ],
      "abstract": "Merging parameters of multiple models has resurfaced as an effective strategy\nto enhance task performance and robustness, but prior work is limited by the\nhigh costs of ensemble creation and inference. In this paper, we leverage the\nabundance of freely accessible trained models to introduce a cost-free approach\nto model merging. It focuses on a layer-wise integration of merged models,\naiming to maintain the distinctiveness of the task-specific final layers while\nunifying the initial layers, which are primarily associated with feature\nextraction. This approach ensures parameter consistency across all layers,\nessential for boosting performance. Moreover, it facilitates seamless\nintegration of knowledge, enabling effective merging of models from different\ndatasets and tasks. Specifically, we investigate its applicability in\nUnsupervised Domain Adaptation (UDA), an unexplored area for model merging, for\nSemantic and Panoptic Segmentation. Experimental results demonstrate\nsubstantial UDA improvements without additional costs for merging\nsame-architecture models from distinct datasets ($\\uparrow 2.6\\%$ mIoU) and\ndifferent-architecture models with a shared backbone ($\\uparrow 6.8\\%$ mIoU).\nFurthermore, merging Semantic and Panoptic Segmentation models increases mPQ by\n$\\uparrow 7\\%$. These findings are validated across a wide variety of UDA\nstrategies, architectures, and datasets.",
      "tldr_zh": "本研究提出了一种层级模型合并（Layer-wise Model Merging）方法，用于无监督域适应（UDA）中的语义和全景分割任务，通过整合多个免费可得的训练模型参数来提升性能和鲁棒性。该方法专注于统一初始特征提取层，同时保持任务特定最终层的独特性，确保参数一致性和知识无缝融合，而无需额外成本。实验结果显示，在不同数据集的相同架构模型合并中，mIoU 提高了 2.6%，在不同架构但共享主干的模型中提高了 6.8%，并在语义和全景分割模型合并中 mPQ 提升了 7%，这些改进在多种 UDA 策略、架构和数据集上得到验证。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.15813v1",
      "published_date": "2024-09-24 07:19:30 UTC",
      "updated_date": "2024-09-24 07:19:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:19:40.373643"
    },
    {
      "arxiv_id": "2409.15806v1",
      "title": "CLSP: High-Fidelity Contrastive Language-State Pre-training for Agent State Representation",
      "title_zh": "翻译失败",
      "authors": [
        "Fuxian Huang",
        "Qi Zhang",
        "Shaopeng Zhai",
        "Jie Wang",
        "Tianyi Zhang",
        "Haoran Zhang",
        "Ming Zhou",
        "Yu Liu",
        "Yu Qiao"
      ],
      "abstract": "With the rapid development of artificial intelligence, multimodal learning\nhas become an important research area. For intelligent agents, the state is a\ncrucial modality to convey precise information alongside common modalities like\nimages, videos, and language. This becomes especially clear with the broad\nadoption of reinforcement learning and multimodal large language models.\nNevertheless, the representation of state modality still lags in development.\nTo this end, we propose a High-Fidelity Contrastive Language-State Pre-training\n(CLSP) method, which can accurately encode state information into general\nrepresentations for both reinforcement learning and multimodal large language\nmodels. Specifically, we first design a pre-training task based on the\nclassification to train an encoder with coarse-grained information. Next, we\nconstruct data pairs of states and language descriptions, utilizing the\npre-trained encoder to initialize the CLSP encoder. Then, we deploy contrastive\nlearning to train the CLSP encoder to effectively represent precise state\ninformation. Additionally, we enhance the representation of numerical\ninformation using the Random Fourier Features (RFF) method for high-fidelity\nmapping. Extensive experiments demonstrate the superior precision and\ngeneralization capabilities of our representation, achieving outstanding\nresults in text-state retrieval, reinforcement learning navigation tasks, and\nmultimodal large language model understanding.",
      "tldr_zh": "本研究针对智能代理的状态表示落后问题，提出了一种高保真对比语言-状态预训练方法（CLSP），旨在精确编码状态信息以支持强化学习（reinforcement learning）和多模态大语言模型。CLSP 首先通过基于分类的预训练任务训练编码器获取粗粒度信息，然后利用状态-语言数据对进行对比学习（contrastive learning），并采用 Random Fourier Features (RFF) 方法增强数值信息的表示。实验结果显示，该方法在文本-状态检索、强化学习导航任务以及多模态大语言模型理解方面表现出卓越的精确性和泛化能力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.15806v1",
      "published_date": "2024-09-24 07:08:00 UTC",
      "updated_date": "2024-09-24 07:08:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:19:51.357811"
    },
    {
      "arxiv_id": "2409.15794v1",
      "title": "Towards Universal Large-Scale Foundational Model for Natural Gas Demand Forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Xinxing Zhou",
        "Jiaqi Ye",
        "Shubao Zhao",
        "Ming Jin",
        "Zhaoxiang Hou",
        "Chengyi Yang",
        "Zengxiang Li",
        "Yanlong Wen",
        "Xiaojie Yuan"
      ],
      "abstract": "In the context of global energy strategy, accurate natural gas demand\nforecasting is crucial for ensuring efficient resource allocation and\noperational planning. Traditional forecasting methods struggle to cope with the\ngrowing complexity and variability of gas consumption patterns across diverse\nindustries and commercial sectors. To address these challenges, we propose the\nfirst foundation model specifically tailored for natural gas demand\nforecasting. Foundation models, known for their ability to generalize across\ntasks and datasets, offer a robust solution to the limitations of traditional\nmethods, such as the need for separate models for different customer segments\nand their limited generalization capabilities. Our approach leverages\ncontrastive learning to improve prediction accuracy in real-world scenarios,\nparticularly by tackling issues such as noise in historical consumption data\nand the potential misclassification of similar data samples, which can lead to\ndegradation in the quaility of the representation and thus the accuracy of\ndownstream forecasting tasks. By integrating advanced noise filtering\ntechniques within the contrastive learning framework, our model enhances the\nquality of learned representations, leading to more accurate predictions.\nFurthermore, the model undergoes industry-specific fine-tuning during\npretraining, enabling it to better capture the unique characteristics of gas\nconsumption across various sectors. We conducted extensive experiments using a\nlarge-scale dataset from ENN Group, which includes data from over 10,000\nindustrial, commercial, and welfare-related customers across multiple regions.\nOur model outperformed existing state-of-the-art methods, demonstrating a\nrelative improvement in MSE by 3.68\\% and in MASE by 6.15\\% compared to the\nbest available model.",
      "tldr_zh": "本研究针对天然气需求预测的复杂性和变异性，提出首个通用的基础模型（foundation model），旨在克服传统方法的局限性，如需针对不同客户分段建模和泛化能力不足。模型采用对比学习（contrastive learning）结合高级噪声过滤技术，并在行业特定数据上进行微调，从而提升数据表示质量和预测准确性。在 ENN Group 的超大规模数据集上进行实验，该模型在 MSE 上较最佳现有方法改善 3.68%，在 MASE 上改善 6.15%，展示了显著的性能提升。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.15794v1",
      "published_date": "2024-09-24 06:44:29 UTC",
      "updated_date": "2024-09-24 06:44:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:20:03.212644"
    },
    {
      "arxiv_id": "2409.15790v3",
      "title": "Small Language Models: Survey, Measurements, and Insights",
      "title_zh": "翻译失败",
      "authors": [
        "Zhenyan Lu",
        "Xiang Li",
        "Dongqi Cai",
        "Rongjie Yi",
        "Fangming Liu",
        "Xiwen Zhang",
        "Nicholas D. Lane",
        "Mengwei Xu"
      ],
      "abstract": "Small language models (SLMs), despite their widespread adoption in modern\nsmart devices, have received significantly less academic attention compared to\ntheir large language model (LLM) counterparts, which are predominantly deployed\nin data centers and cloud environments. While researchers continue to improve\nthe capabilities of LLMs in the pursuit of artificial general intelligence, SLM\nresearch aims to make machine intelligence more accessible, affordable, and\nefficient for everyday tasks. Focusing on transformer-based, decoder-only\nlanguage models with 100M-5B parameters, we survey 70 state-of-the-art\nopen-source SLMs, analyzing their technical innovations across three axes:\narchitectures, training datasets, and training algorithms. In addition, we\nevaluate their capabilities in various domains, including commonsense\nreasoning, mathematics, in-context learning, and long context. To gain further\ninsight into their on-device runtime costs, we benchmark their inference\nlatency and memory footprints. Through in-depth analysis of our benchmarking\ndata, we offer valuable insights to advance research in this field.",
      "tldr_zh": "这篇论文调查了小语言模型（SLMs），强调其与大语言模型（LLMs）相比在学术上的关注不足，却在智能设备中广泛应用。研究聚焦于参数规模为100M-5B的Transformer-based、decoder-only语言模型，分析了70个state-of-the-art开源SLMs在架构、训练数据集和训练算法方面的创新。作者评估了这些模型在常识推理、数学、in-context learning和long context等领域的能力，并基准测试了它们的推理延迟和内存占用。通过深入分析数据，该研究提供了宝贵见解，以推进SLMs在可访问性、效率和实际应用方面的研究。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.15790v3",
      "published_date": "2024-09-24 06:36:56 UTC",
      "updated_date": "2025-02-26 06:34:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:20:15.646847"
    },
    {
      "arxiv_id": "2409.15764v1",
      "title": "Spatial-Temporal Mixture-of-Graph-Experts for Multi-Type Crime Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Ziyang Wu",
        "Fan Liu",
        "Jindong Han",
        "Yuxuan Liang",
        "Hao Liu"
      ],
      "abstract": "As various types of crime continue to threaten public safety and economic\ndevelopment, predicting the occurrence of multiple types of crimes becomes\nincreasingly vital for effective prevention measures. Although extensive\nefforts have been made, most of them overlook the heterogeneity of different\ncrime categories and fail to address the issue of imbalanced spatial\ndistribution. In this work, we propose a Spatial-Temporal\nMixture-of-Graph-Experts (ST-MoGE) framework for collective multiple-type crime\nprediction. To enhance the model's ability to identify diverse spatial-temporal\ndependencies and mitigate potential conflicts caused by spatial-temporal\nheterogeneity of different crime categories, we introduce an attentive-gated\nMixture-of-Graph-Experts (MGEs) module to capture the distinctive and shared\ncrime patterns of each crime category. Then, we propose Cross-Expert\nContrastive Learning(CECL) to update the MGEs and force each expert to focus on\nspecific pattern modeling, thereby reducing blending and redundancy.\nFurthermore, to address the issue of imbalanced spatial distribution, we\npropose a Hierarchical Adaptive Loss Re-weighting (HALR) approach to eliminate\nbiases and insufficient learning of data-scarce regions. To evaluate the\neffectiveness of our methods, we conduct comprehensive experiments on two\nreal-world crime datasets and compare our results with twelve advanced\nbaselines. The experimental results demonstrate the superiority of our methods.",
      "tldr_zh": "该研究提出 Spatial-Temporal Mixture-of-Graph-Experts (ST-MoGE) 框架，用于预测多种犯罪类型，旨在解决现有方法忽略的犯罪类别异质性和空间分布不平衡问题。框架通过 attentive-gated Mixture-of-Graph-Experts (MGEs) 模块捕捉每个犯罪类别的独特和共享空间-时间模式，并利用 Cross-Expert Contrastive Learning (CECL) 优化专家模型，减少模式冗余；同时，Hierarchical Adaptive Loss Re-weighting (HALR) 方法消除数据稀缺区域的偏差。实验在两个真实世界犯罪数据集上与12个高级基线模型比较，结果显示 ST-MoGE 框架显著提升了预测性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.15764v1",
      "published_date": "2024-09-24 05:41:11 UTC",
      "updated_date": "2024-09-24 05:41:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:20:27.470917"
    },
    {
      "arxiv_id": "2409.15763v2",
      "title": "IRSC: A Zero-shot Evaluation Benchmark for Information Retrieval through Semantic Comprehension in Retrieval-Augmented Generation Scenarios",
      "title_zh": "翻译失败",
      "authors": [
        "Hai Lin",
        "Shaoxiong Zhan",
        "Junyou Su",
        "Haitao Zheng",
        "Hui Wang"
      ],
      "abstract": "In Retrieval-Augmented Generation (RAG) tasks using Large Language Models\n(LLMs), the quality of retrieved information is critical to the final output.\nThis paper introduces the IRSC benchmark for evaluating the performance of\nembedding models in multilingual RAG tasks. The benchmark encompasses five\nretrieval tasks: query retrieval, title retrieval, part-of-paragraph retrieval,\nkeyword retrieval, and summary retrieval. Our research addresses the current\nlack of comprehensive testing and effective comparison methods for embedding\nmodels in RAG scenarios. We introduced new metrics: the Similarity of Semantic\nComprehension Index (SSCI) and the Retrieval Capability Contest Index (RCCI),\nand evaluated models such as Snowflake-Arctic, BGE, GTE, and M3E. Our\ncontributions include: 1) the IRSC benchmark, 2) the SSCI and RCCI metrics, and\n3) insights into the cross-lingual limitations of embedding models. The IRSC\nbenchmark aims to enhance the understanding and development of accurate\nretrieval systems in RAG tasks. All code and datasets are available at:\nhttps://github.com/Jasaxion/IRSC_Benchmark",
      "tldr_zh": "这篇论文引入了 IRSC 基准，用于零样本评估嵌入模型在 Retrieval-Augmented Generation (RAG) 场景中的信息检索性能，涵盖五种任务：query retrieval、title retrieval、part-of-paragraph retrieval、keyword retrieval 和 summary retrieval。研究提出新指标 Similarity of Semantic Comprehension Index (SSCI) 和 Retrieval Capability Contest Index (RCCI)，并评估了 Snowflake-Arctic、BGE、GTE 和 M3E 等模型，以解决当前 RAG 任务中缺乏全面测试的问题。主要贡献包括 IRSC 基准的建立、新指标的开发，以及对嵌入模型跨语言限制的洞见，有助于提升检索系统的准确性和发展。代码和数据集可从 https://github.com/Jasaxion/IRSC_Benchmark 获取。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.15763v2",
      "published_date": "2024-09-24 05:39:53 UTC",
      "updated_date": "2024-09-26 05:43:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:20:42.606681"
    },
    {
      "arxiv_id": "2409.15761v2",
      "title": "TFG: Unified Training-Free Guidance for Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Haotian Ye",
        "Haowei Lin",
        "Jiaqi Han",
        "Minkai Xu",
        "Sheng Liu",
        "Yitao Liang",
        "Jianzhu Ma",
        "James Zou",
        "Stefano Ermon"
      ],
      "abstract": "Given an unconditional diffusion model and a predictor for a target property\nof interest (e.g., a classifier), the goal of training-free guidance is to\ngenerate samples with desirable target properties without additional training.\nExisting methods, though effective in various individual applications, often\nlack theoretical grounding and rigorous testing on extensive benchmarks. As a\nresult, they could even fail on simple tasks, and applying them to a new\nproblem becomes unavoidably difficult. This paper introduces a novel\nalgorithmic framework encompassing existing methods as special cases, unifying\nthe study of training-free guidance into the analysis of an algorithm-agnostic\ndesign space. Via theoretical and empirical investigation, we propose an\nefficient and effective hyper-parameter searching strategy that can be readily\napplied to any downstream task. We systematically benchmark across 7 diffusion\nmodels on 16 tasks with 40 targets, and improve performance by 8.5% on average.\nOur framework and benchmark offer a solid foundation for conditional generation\nin a training-free manner.",
      "tldr_zh": "这篇论文提出了 TFG，一种统一的训练-free guidance 框架，用于 diffusion models 的条件生成，旨在基于无条件模型和目标属性预测器（如分类器）生成具有理想属性的样本，而无需额外训练。TFG 将现有方法整合到一个算法无关的设计空间中，并通过理论分析和实证调查，引入高效的超参数搜索策略来优化性能。实验结果显示，在 7 个 diffusion models 和 16 个任务（40 个目标）上的基准测试中，TFG 平均提高了 8.5% 的性能，为训练-free 的条件生成提供了可靠的基础。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.15761v2",
      "published_date": "2024-09-24 05:31:17 UTC",
      "updated_date": "2024-11-19 08:12:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:20:53.239026"
    },
    {
      "arxiv_id": "2409.15755v1",
      "title": "Stage-Wise Reward Shaping for Acrobatic Robots: A Constrained Multi-Objective Reinforcement Learning Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Dohyeong Kim",
        "Hyeokjin Kwon",
        "Junseok Kim",
        "Gunmin Lee",
        "Songhwai Oh"
      ],
      "abstract": "As the complexity of tasks addressed through reinforcement learning (RL)\nincreases, the definition of reward functions also has become highly\ncomplicated. We introduce an RL method aimed at simplifying the reward-shaping\nprocess through intuitive strategies. Initially, instead of a single reward\nfunction composed of various terms, we define multiple reward and cost\nfunctions within a constrained multi-objective RL (CMORL) framework. For tasks\ninvolving sequential complex movements, we segment the task into distinct\nstages and define multiple rewards and costs for each stage. Finally, we\nintroduce a practical CMORL algorithm that maximizes objectives based on these\nrewards while satisfying constraints defined by the costs. The proposed method\nhas been successfully demonstrated across a variety of acrobatic tasks in both\nsimulation and real-world environments. Additionally, it has been shown to\nsuccessfully perform tasks compared to existing RL and constrained RL\nalgorithms. Our code is available at\nhttps://github.com/rllab-snu/Stage-Wise-CMORL.",
      "tldr_zh": "这篇论文提出了一种阶段式奖励塑造方法，用于简化复杂强化学习 (RL) 任务中的奖励函数设计，特别针对杂技机器人的顺序动作。方法采用受限多目标 RL (CMORL) 框架，将任务分成多个阶段，并在每个阶段定义独立的奖励和成本函数，同时引入一个新算法来最大化奖励目标并满足成本约束。在模拟和真实环境中，该方法在各种杂技任务上表现出色，比现有 RL 和受限 RL 算法性能更优，并提供了开源代码。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "7 pages",
      "pdf_url": "http://arxiv.org/pdf/2409.15755v1",
      "published_date": "2024-09-24 05:25:24 UTC",
      "updated_date": "2024-09-24 05:25:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:21:02.650899"
    },
    {
      "arxiv_id": "2409.15753v1",
      "title": "Development and Validation of Heparin Dosing Policies Using an Offline Reinforcement Learning Algorithm",
      "title_zh": "翻译失败",
      "authors": [
        "Yooseok Lim",
        "Inbeom Park",
        "Sujee Lee"
      ],
      "abstract": "Appropriate medication dosages in the intensive care unit (ICU) are critical\nfor patient survival. Heparin, used to treat thrombosis and inhibit blood\nclotting in the ICU, requires careful administration due to its complexity and\nsensitivity to various factors, including patient clinical characteristics,\nunderlying medical conditions, and potential drug interactions. Incorrect\ndosing can lead to severe complications such as strokes or excessive bleeding.\nTo address these challenges, this study proposes a reinforcement learning\n(RL)-based personalized optimal heparin dosing policy that guides dosing\ndecisions reliably within the therapeutic range based on individual patient\nconditions. A batch-constrained policy was implemented to minimize\nout-of-distribution errors in an offline RL environment and effectively\nintegrate RL with existing clinician policies. The policy's effectiveness was\nevaluated using weighted importance sampling, an off-policy evaluation method,\nand the relationship between state representations and Q-values was explored\nusing t-SNE. Both quantitative and qualitative analyses were conducted using\nthe Medical Information Mart for Intensive Care III (MIMIC-III) database,\ndemonstrating the efficacy of the proposed RL-based medication policy.\nLeveraging advanced machine learning techniques and extensive clinical data,\nthis research enhances heparin administration practices and establishes a\nprecedent for the development of sophisticated decision-support tools in\nmedicine.",
      "tldr_zh": "这篇论文开发了一种基于离线强化学习（Offline RL）算法的个性化肝素（Heparin）剂量策略，旨在优化 ICU 中的用药决策，以避免剂量不当导致的并发症如中风或出血。方法包括实施批量约束政策（batch-constrained policy）来减少分布外错误，并将 RL 与现有临床策略整合。研究使用 weighted importance sampling 和 t-SNE 在 MIMIC-III 数据库上进行定量与定性评估，结果显示该策略显著提高了剂量准确性，并为先进的医疗决策支持工具奠定了基础。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.15753v1",
      "published_date": "2024-09-24 05:20:38 UTC",
      "updated_date": "2024-09-24 05:20:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:21:15.573044"
    },
    {
      "arxiv_id": "2409.15750v3",
      "title": "The Roles of Generative Artificial Intelligence in Internet of Electric Vehicles",
      "title_zh": "翻译失败",
      "authors": [
        "Hanwen Zhang",
        "Dusit Niyato",
        "Wei Zhang",
        "Changyuan Zhao",
        "Hongyang Du",
        "Abbas Jamalipour",
        "Sumei Sun",
        "Yiyang Pei"
      ],
      "abstract": "With the advancements of generative artificial intelligence (GenAI) models,\ntheir capabilities are expanding significantly beyond content generation and\nthe models are increasingly being used across diverse applications.\nParticularly, GenAI shows great potential in addressing challenges in the\nelectric vehicle (EV) ecosystem ranging from charging management to\ncyber-attack prevention. In this paper, we specifically consider Internet of\nelectric vehicles (IoEV) and we categorize GenAI for IoEV into four different\nlayers namely, EV's battery layer, individual EV layer, smart grid layer, and\nsecurity layer. We introduce various GenAI techniques used in each layer of\nIoEV applications. Subsequently, public datasets available for training the\nGenAI models are summarized. Finally, we provide recommendations for future\ndirections. This survey not only categorizes the applications of GenAI in IoEV\nacross different layers but also serves as a valuable resource for researchers\nand practitioners by highlighting the design and implementation challenges\nwithin each layer. Furthermore, it provides a roadmap for future research\ndirections, enabling the development of more robust and efficient IoEV systems\nthrough the integration of advanced GenAI techniques.",
      "tldr_zh": "这篇论文探讨了生成式人工智能 (GenAI) 在互联网电动车 (IoEV) 中的作用，特别将其应用分为四个层：EV 电池层、单个 EV 层、智能电网层和安全层，并介绍了每个层中使用的 GenAI 技术。论文总结了可用于训练 GenAI 模型的公共数据集，并突出了设计和实施挑战。最终，它为研究者和从业者提供未来研究方向的路线图，以推动更高效的 IoEV 系统发展。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "cs.LG",
      "comment": "25 Pages",
      "pdf_url": "http://arxiv.org/pdf/2409.15750v3",
      "published_date": "2024-09-24 05:12:10 UTC",
      "updated_date": "2024-11-14 06:33:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:21:27.394107"
    },
    {
      "arxiv_id": "2409.15749v1",
      "title": "Automated Assessment of Multimodal Answer Sheets in the STEM domain",
      "title_zh": "翻译失败",
      "authors": [
        "Rajlaxmi Patil",
        "Aditya Ashutosh Kulkarni",
        "Ruturaj Ghatage",
        "Sharvi Endait",
        "Geetanjali Kale",
        "Raviraj Joshi"
      ],
      "abstract": "In the domain of education, the integration of,technology has led to a\ntransformative era, reshaping traditional,learning paradigms. Central to this\nevolution is the automation,of grading processes, particularly within the STEM\ndomain encompassing Science, Technology, Engineering, and Mathematics.,While\nefforts to automate grading have been made in subjects,like Literature, the\nmultifaceted nature of STEM assessments,presents unique challenges, ranging\nfrom quantitative analysis,to the interpretation of handwritten diagrams. To\naddress these,challenges, this research endeavors to develop efficient and\nreliable grading methods through the implementation of automated,assessment\ntechniques using Artificial Intelligence (AI). Our,contributions lie in two key\nareas: firstly, the development of a,robust system for evaluating textual\nanswers in STEM, leveraging,sample answers for precise comparison and grading,\nenabled by,advanced algorithms and natural language processing\ntechniques.,Secondly, a focus on enhancing diagram evaluation,\nparticularly,flowcharts, within the STEM context, by transforming diagrams,into\ntextual representations for nuanced assessment using a,Large Language Model\n(LLM). By bridging the gap between,visual representation and semantic meaning,\nour approach ensures accurate evaluation while minimizing manual\nintervention.,Through the integration of models such as CRAFT for\ntext,extraction and YoloV5 for object detection, coupled with LLMs,like\nMistral-7B for textual evaluation, our methodology facilitates,comprehensive\nassessment of multimodal answer sheets. This,paper provides a detailed account\nof our methodology, challenges,encountered, results, and implications,\nemphasizing the potential,of AI-driven approaches in revolutionizing grading\npractices in,STEM education.",
      "tldr_zh": "本研究针对 STEM（Science, Technology, Engineering, and Mathematics）领域的多模态答卷评估问题，开发了一种基于人工智能（AI）的自动化评分系统，以应对文本答案和手写图表（如流程图）的复杂挑战。系统的主要贡献包括：利用自然语言处理（NLP）技术和样本答案进行精确的文本评估，以及通过 CRAFT 文本提取、YoloV5 对象检测和 Mistral-7B 大型语言模型（LLM）将图表转换为文本表示，从而实现细致评估。实验结果显示，该方法显著减少了手动干预，并展示了 AI 在革命化 STEM 教育评分实践中的潜力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.15749v1",
      "published_date": "2024-09-24 05:10:13 UTC",
      "updated_date": "2024-09-24 05:10:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:21:49.853314"
    },
    {
      "arxiv_id": "2409.15747v1",
      "title": "Training Neural Networks for Modularity aids Interpretability",
      "title_zh": "翻译失败",
      "authors": [
        "Satvik Golechha",
        "Dylan Cope",
        "Nandi Schoots"
      ],
      "abstract": "An approach to improve network interpretability is via clusterability, i.e.,\nsplitting a model into disjoint clusters that can be studied independently. We\nfind pretrained models to be highly unclusterable and thus train models to be\nmore modular using an ``enmeshment loss'' function that encourages the\nformation of non-interacting clusters. Using automated interpretability\nmeasures, we show that our method finds clusters that learn different,\ndisjoint, and smaller circuits for CIFAR-10 labels. Our approach provides a\npromising direction for making neural networks easier to interpret.",
      "tldr_zh": "该研究旨在通过提高神经网络的模块性（modularity）来提升其可解释性（interpretability），方法是针对预训练模型的低集群性（unclusterable）问题，使用“enmeshment loss”损失函数训练网络，形成非交互的独立集群。实验结果显示，这种方法在CIFAR-10数据集上成功识别出学习不同、分离且更小的电路，用于处理标签分类。总体而言，该方法为简化神经网络的解释提供了有前景的方向。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "4 pages, preprint",
      "pdf_url": "http://arxiv.org/pdf/2409.15747v1",
      "published_date": "2024-09-24 05:03:49 UTC",
      "updated_date": "2024-09-24 05:03:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:21:53.027793"
    },
    {
      "arxiv_id": "2409.15740v1",
      "title": "Real-Time Pedestrian Detection on IoT Edge Devices: A Lightweight Deep Learning Approach",
      "title_zh": "在物联网边缘设备上进行实时行人检测：一种轻量级深度学习方法",
      "authors": [
        "Muhammad Dany Alfikri",
        "Rafael Kaliski"
      ],
      "abstract": "Artificial intelligence (AI) has become integral to our everyday lives.\nComputer vision has advanced to the point where it can play the safety critical\nrole of detecting pedestrians at road intersections in intelligent\ntransportation systems and alert vehicular traffic as to potential collisions.\nCentralized computing analyzes camera feeds and generates alerts for nearby\nvehicles. However, real-time applications face challenges such as latency,\nlimited data transfer speeds, and the risk of life loss. Edge servers offer a\npotential solution for real-time applications, providing localized computing\nand storage resources and lower response times. Unfortunately, edge servers\nhave limited processing power. Lightweight deep learning (DL) techniques enable\nedge servers to utilize compressed deep neural network (DNN) models.\n  The research explores implementing a lightweight DL model on Artificial\nIntelligence of Things (AIoT) edge devices. An optimized You Only Look Once\n(YOLO) based DL model is deployed for real-time pedestrian detection, with\ndetection events transmitted to the edge server using the Message Queuing\nTelemetry Transport (MQTT) protocol. The simulation results demonstrate that\nthe optimized YOLO model can achieve real-time pedestrian detection, with a\nfast inference speed of 147 milliseconds, a frame rate of 2.3 frames per\nsecond, and an accuracy of 78%, representing significant improvements over\nbaseline models.",
      "tldr_zh": "本研究针对智能交通系统中实时行人检测的挑战，提出了一种轻量级深度学习(DL)方法，部署在AIoT边缘设备上，以解决延迟和处理能力限制问题。  \n他们优化了You Only Look Once(YOLO)模型，用于实时行人检测，并通过Message Queuing Telemetry Transport(MQTT)协议传输检测事件。  \n模拟结果显示，该模型的推理速度为147毫秒、帧率为2.3帧每秒、准确率达78%，相较于基线模型实现了显著改善。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.NI"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages, 3 tables, 12 figures, article submitted to IEEE for\n  possible publication",
      "pdf_url": "http://arxiv.org/pdf/2409.15740v1",
      "published_date": "2024-09-24 04:48:41 UTC",
      "updated_date": "2024-09-24 04:48:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:22:04.436627"
    },
    {
      "arxiv_id": "2409.15733v1",
      "title": "EvoFA: Evolvable Fast Adaptation for EEG Emotion Recognition",
      "title_zh": "EvoFA：用于 EEG 情绪识别的可演化快速适应",
      "authors": [
        "Ming Jin",
        "Danni Zhang",
        "Gangming Zhao",
        "Changde Du",
        "Jinpeng Li"
      ],
      "abstract": "Electroencephalography (EEG)-based emotion recognition has gained significant\ntraction due to its accuracy and objectivity. However, the non-stationary\nnature of EEG signals leads to distribution drift over time, causing severe\nperformance degradation when the model is reused. While numerous domain\nadaptation (DA) approaches have been proposed in recent years to address this\nissue, their reliance on large amounts of target data for calibration restricts\nthem to offline scenarios, rendering them unsuitable for real-time\napplications. To address this challenge, this paper proposes Evolvable Fast\nAdaptation (EvoFA), an online adaptive framework tailored for EEG data. EvoFA\norganically integrates the rapid adaptation of Few-Shot Learning (FSL) and the\ndistribution matching of Domain Adaptation (DA) through a two-stage\ngeneralization process. During the training phase, a robust base meta-learning\nmodel is constructed for strong generalization. In the testing phase, a\ndesigned evolvable meta-adaptation module iteratively aligns the marginal\ndistribution of target (testing) data with the evolving source (training) data\nwithin a model-agnostic meta-learning framework, enabling the model to learn\nthe evolving trends of testing data relative to training data and improving\nonline testing performance. Experimental results demonstrate that EvoFA\nachieves significant improvements compared to the basic FSL method and previous\nonline methods. The introduction of EvoFA paves the way for broader adoption of\nEEG-based emotion recognition in real-world applications. Our code will be\nreleased upon publication.",
      "tldr_zh": "这篇论文针对 EEG-based emotion recognition 中 EEG 信号非平稳性导致的分布漂移问题，提出了一种在线自适应框架 EvoFA，以实现实时应用。EvoFA 通过整合 Few-Shot Learning (FSL) 的快速适应和 Domain Adaptation (DA) 的分布匹配，采用两阶段过程：在训练阶段构建鲁棒的元学习模型，在测试阶段使用可演化元适应模块迭代对齐目标数据和源数据的边缘分布。实验结果显示，EvoFA 相较于基本 FSL 方法和现有在线方法取得了显著性能提升，为 EEG-based emotion recognition 在真实世界应用的推广奠定了基础。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.15733v1",
      "published_date": "2024-09-24 04:35:10 UTC",
      "updated_date": "2024-09-24 04:35:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:22:16.757790"
    },
    {
      "arxiv_id": "2409.15730v1",
      "title": "Learning Multiple Probabilistic Decisions from Latent World Model in Autonomous Driving",
      "title_zh": "翻译失败",
      "authors": [
        "Lingyu Xiao",
        "Jiang-Jiang Liu",
        "Sen Yang",
        "Xiaofan Li",
        "Xiaoqing Ye",
        "Wankou Yang",
        "Jingdong Wang"
      ],
      "abstract": "The autoregressive world model exhibits robust generalization capabilities in\nvectorized scene understanding but encounters difficulties in deriving actions\ndue to insufficient uncertainty modeling and self-delusion. In this paper, we\nexplore the feasibility of deriving decisions from an autoregressive world\nmodel by addressing these challenges through the formulation of multiple\nprobabilistic hypotheses. We propose LatentDriver, a framework models the\nenvironment's next states and the ego vehicle's possible actions as a mixture\ndistribution, from which a deterministic control signal is then derived. By\nincorporating mixture modeling, the stochastic nature of decisionmaking is\ncaptured. Additionally, the self-delusion problem is mitigated by providing\nintermediate actions sampled from a distribution to the world model.\nExperimental results on the recently released close-loop benchmark Waymax\ndemonstrate that LatentDriver surpasses state-of-the-art reinforcement learning\nand imitation learning methods, achieving expert-level performance. The code\nand models will be made available at\nhttps://github.com/Sephirex-X/LatentDriver.",
      "tldr_zh": "本研究针对 autoregressive world model 在自动驾驶决策中的不确定性建模不足和自欺问题，提出 LatentDriver 框架，通过多个概率假设来生成决策。框架将环境下一状态和车辆动作建模为混合分布（mixture distribution），并通过从分布中采样中间动作来缓解自欺问题，从而捕捉决策的随机性。在 Waymax 闭环基准测试中，LatentDriver 超越了现有强化学习和模仿学习方法，达到了专家级性能。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.15730v1",
      "published_date": "2024-09-24 04:26:24 UTC",
      "updated_date": "2024-09-24 04:26:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:22:27.426777"
    },
    {
      "arxiv_id": "2409.15729v2",
      "title": "Sequential Learning in the Dense Associative Memory",
      "title_zh": "密集关联记忆中的顺序学习",
      "authors": [
        "Hayden McAlister",
        "Anthony Robins",
        "Lech Szymanski"
      ],
      "abstract": "Sequential learning involves learning tasks in a sequence, and proves\nchallenging for most neural networks. Biological neural networks regularly\nconquer the sequential learning challenge and are even capable of transferring\nknowledge both forward and backwards between tasks. Artificial neural networks\noften totally fail to transfer performance between tasks, and regularly suffer\nfrom degraded performance or catastrophic forgetting on previous tasks. Models\nof associative memory have been used to investigate the discrepancy between\nbiological and artificial neural networks due to their biological ties and\ninspirations, of which the Hopfield network is the most studied model. The\nDense Associative Memory (DAM), or modern Hopfield network, generalizes the\nHopfield network, allowing for greater capacities and prototype learning\nbehaviors, while still retaining the associative memory structure. We give a\nsubstantial review of the sequential learning space with particular respect to\nthe Hopfield network and associative memories. We perform foundational\nbenchmarks of sequential learning in the DAM using various sequential learning\ntechniques, and analyze the results of the sequential learning to demonstrate\npreviously unseen transitions in the behavior of the DAM. This paper also\ndiscusses the departure from biological plausibility that may affect the\nutility of the DAM as a tool for studying biological neural networks. We\npresent our findings, including the effectiveness of a range of\nstate-of-the-art sequential learning methods when applied to the DAM, and use\nthese methods to further the understanding of DAM properties and behaviors.",
      "tldr_zh": "该论文探讨了Sequential Learning（顺序学习）在Dense Associative Memory (DAM)中的应用，比较了生物神经网络在任务间知识转移的优势与人工神经网络的常见问题，如catastrophic forgetting（灾难性遗忘）和性能下降。作者回顾了Hopfield network和关联记忆模型，并通过基准测试应用各种顺序学习技术，分析了DAM的行为转变。结果表明，这些方法在DAM上显示出有效性，并揭示了DAM作为生物神经网络研究工具的潜在局限性，从而加深了对DAM属性的理解。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.15729v2",
      "published_date": "2024-09-24 04:23:00 UTC",
      "updated_date": "2025-03-04 21:41:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:22:41.530750"
    },
    {
      "arxiv_id": "2409.15724v1",
      "title": "LLM-Cure: LLM-based Competitor User Review Analysis for Feature Enhancement",
      "title_zh": "翻译失败",
      "authors": [
        "Maram Assi",
        "Safwat Hassan",
        "Ying Zou"
      ],
      "abstract": "The exponential growth of the mobile app market underscores the importance of\nconstant innovation and rapid response to user demands. As user satisfaction is\nparamount to the success of a mobile application (app), developers typically\nrely on user reviews, which represent user feedback that includes ratings and\ncomments to identify areas for improvement. However, the sheer volume of user\nreviews poses challenges in manual analysis, necessitating automated\napproaches. Existing automated approaches either analyze only the target apps\nreviews, neglecting the comparison of similar features to competitors or fail\nto provide suggestions for feature enhancement. To address these gaps, we\npropose a Large Language Model (LLM)-based Competitive User Review Analysis for\nFeature Enhancement) (LLM-Cure), an approach powered by LLMs to automatically\ngenerate suggestion s for mobile app feature improvements. More specifically,\nLLM-Cure identifies and categorizes features within reviews by applying LLMs.\nWhen provided with a complaint in a user review, LLM-Cure curates highly rated\n(4 and 5 stars) reviews in competing apps related to the complaint and proposes\npotential improvements tailored to the target application. We evaluate LLM-Cure\non 1,056,739 reviews of 70 popular Android apps. Our evaluation demonstrates\nthat LLM-Cure significantly outperforms the state-of-the-art approaches in\nassigning features to reviews by up to 13% in F1-score, up to 16% in recall and\nup to 11% in precision. Additionally, LLM-Cure demonstrates its capability to\nprovide suggestions for resolving user complaints. We verify the suggestions\nusing the release notes that reflect the changes of features in the target\nmobile app. LLM-Cure achieves a promising average of 73% of the implementation\nof the provided suggestions.",
      "tldr_zh": "这篇论文提出了 LLM-Cure，一种基于 Large Language Model (LLM) 的方法，用于分析竞争对手的用户评论以提升移动应用特征。LLM-Cure 通过 LLM 自动识别和分类评论中的特征，并针对用户投诉，从竞争对手应用的4-5星高评级评论中提取信息，生成针对目标应用的改进建议。在对1,056,739条Android应用评论的评估中，LLM-Cure 在 F1-score 上比现有方法提高了13%，召回率提高了16%，精确率提高了11%，并验证了73%的建议被实际实施。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.SE",
      "comment": "25 pages",
      "pdf_url": "http://arxiv.org/pdf/2409.15724v1",
      "published_date": "2024-09-24 04:17:21 UTC",
      "updated_date": "2024-09-24 04:17:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:22:52.419676"
    },
    {
      "arxiv_id": "2409.15711v2",
      "title": "Adversarial Federated Consensus Learning for Surface Defect Classification Under Data Heterogeneity in IIoT",
      "title_zh": "翻译失败",
      "authors": [
        "Jixuan Cui",
        "Jun Li",
        "Zhen Mei",
        "Yiyang Ni",
        "Wen Chen",
        "Zengxiang Li"
      ],
      "abstract": "The challenge of data scarcity hinders the application of deep learning in\nindustrial surface defect classification (SDC), as it's difficult to collect\nand centralize sufficient training data from various entities in Industrial\nInternet of Things (IIoT) due to privacy concerns. Federated learning (FL)\nprovides a solution by enabling collaborative global model training across\nclients while maintaining privacy. However, performance may suffer due to data\nheterogeneity-discrepancies in data distributions among clients. In this paper,\nwe propose a novel personalized FL (PFL) approach, named Adversarial Federated\nConsensus Learning (AFedCL), for the challenge of data heterogeneity across\ndifferent clients in SDC. First, we develop a dynamic consensus construction\nstrategy to mitigate the performance degradation caused by data heterogeneity.\nThrough adversarial training, local models from different clients utilize the\nglobal model as a bridge to achieve distribution alignment, alleviating the\nproblem of global knowledge forgetting. Complementing this strategy, we propose\na consensus-aware aggregation mechanism. It assigns aggregation weights to\ndifferent clients based on their efficacy in global knowledge learning, thereby\nenhancing the global model's generalization capabilities. Finally, we design an\nadaptive feature fusion module to further enhance global knowledge utilization\nefficiency. Personalized fusion weights are gradually adjusted for each client\nto optimally balance global and local features. Compared with state-of-the-art\nFL methods like FedALA, the proposed AFedCL method achieves an accuracy\nincrease of up to 5.67% on three SDC datasets.",
      "tldr_zh": "本研究针对工业互联网（IIoT）中表面缺陷分类（SDC）的挑战，提出了一种个性化的联邦学习（PFL）方法，名为Adversarial Federated Consensus Learning (AFedCL)，以应对数据异质性（data heterogeneity）导致的性能下降问题。该方法包括动态共识构建策略，通过对抗训练（adversarial training）利用全局模型实现数据分布对齐，并结合共识感知聚合机制根据客户端的全局知识学习效能分配权重，以及自适应特征融合模块来优化全局和本地特征的平衡。实验结果显示，AFedCL 在三个 SDC 数据集上比现有联邦学习方法如 FedALA 提高了高达 5.67% 的准确率，为隐私保护下的工业缺陷检测提供了更高效的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.15711v2",
      "published_date": "2024-09-24 03:59:32 UTC",
      "updated_date": "2024-11-01 03:17:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:23:05.285118"
    },
    {
      "arxiv_id": "2409.15710v1",
      "title": "Autotuning Bipedal Locomotion MPC with GRFM-Net for Efficient Sim-to-Real Transfer",
      "title_zh": "翻译失败",
      "authors": [
        "Qianzhong Chen",
        "Junheng Li",
        "Sheng Cheng",
        "Naira Hovakimyan",
        "Quan Nguyen"
      ],
      "abstract": "Bipedal locomotion control is essential for humanoid robots to navigate\ncomplex, human-centric environments. While optimization-based control designs\nare popular for integrating sophisticated models of humanoid robots, they often\nrequire labor-intensive manual tuning. In this work, we address the challenges\nof parameter selection in bipedal locomotion control using DiffTune, a\nmodel-based autotuning method that leverages differential programming for\nefficient parameter learning. A major difficulty lies in balancing model\nfidelity with differentiability. We address this difficulty using a\nlow-fidelity model for differentiability, enhanced by a Ground Reaction\nForce-and-Moment Network (GRFM-Net) to capture discrepancies between MPC\ncommands and actual control effects. We validate the parameters learned by\nDiffTune with GRFM-Net in hardware experiments, which demonstrates the\nparameters' optimality in a multi-objective setting compared with baseline\nparameters, reducing the total loss by up to 40.5$\\%$ compared with the\nexpert-tuned parameters. The results confirm the GRFM-Net's effectiveness in\nmitigating the sim-to-real gap, improving the transferability of\nsimulation-learned parameters to real hardware.",
      "tldr_zh": "这篇论文提出了一种自动调整（Autotuning）双足机器人（Bipedal Locomotion）模型预测控制（MPC）的框架，使用 DiffTune 方法结合 Ground Reaction Force-and-Moment Network (GRFM-Net)，以解决参数手动调优的挑战并提升模拟到真实环境转移（Sim-to-Real Transfer）的效率。GRFM-Net 通过捕捉 MPC 命令与实际控制效果之间的差异，弥补了低保真度模型的可微性与真实性平衡问题。实验验证显示，该方法在硬件测试中比专家调整参数降低了总损失高达 40.5%，证明了其在多目标优化中的优越性和转移能力。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.15710v1",
      "published_date": "2024-09-24 03:58:18 UTC",
      "updated_date": "2024-09-24 03:58:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:23:18.663821"
    },
    {
      "arxiv_id": "2409.15706v1",
      "title": "Improving Emotional Support Delivery in Text-Based Community Safety Reporting Using Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yiren Liu",
        "Yerong Li",
        "Ryan Mayfield",
        "Yun Huang"
      ],
      "abstract": "Emotional support is a crucial aspect of communication between community\nmembers and police dispatchers during incident reporting. However, there is a\nlack of understanding about how emotional support is delivered through\ntext-based systems, especially in various non-emergency contexts. In this\nstudy, we analyzed two years of chat logs comprising 57,114 messages across\n8,239 incidents from 130 higher education institutions. Our empirical findings\nrevealed significant variations in emotional support provided by dispatchers,\ninfluenced by the type of incident, service time, and a noticeable decline in\nsupport over time across multiple organizations. To improve the consistency and\nquality of emotional support, we developed and implemented a fine-tuned Large\nLanguage Model (LLM), named dispatcherLLM. We evaluated dispatcherLLM by\ncomparing its generated responses to those of human dispatchers and other\noff-the-shelf models using real chat messages. Additionally, we conducted a\nhuman evaluation to assess the perceived effectiveness of the support provided\nby dispatcherLLM. This study not only contributes new empirical understandings\nof emotional support in text-based dispatch systems but also demonstrates the\nsignificant potential of generative AI in improving service delivery.",
      "tldr_zh": "这篇论文分析了文本-based社区安全报告中情感支持的交付问题，通过审查两年聊天日志（包括57,114条消息和8,239个事件）发现，支持水平因事件类型、服务时间和时间推移而显著变化。研究开发了微调的Large Language Models（dispatcherLLM），并通过比较其生成的响应与人类调度员和其他模型的表现，以及人类评估，证明了其能提升支持的质量和一致性。该工作提供了对情感支持在文本-based调度系统中的新实证理解，并展示了生成式AI在改善服务交付方面的重大潜力。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.15706v1",
      "published_date": "2024-09-24 03:47:02 UTC",
      "updated_date": "2024-09-24 03:47:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:23:30.948830"
    },
    {
      "arxiv_id": "2409.15697v1",
      "title": "dnaGrinder: a lightweight and high-capacity genomic foundation model",
      "title_zh": "dnaGrinder：一个轻量",
      "authors": [
        "Qihang Zhao",
        "Chi Zhang",
        "Weixiong Zhang"
      ],
      "abstract": "The task of understanding and interpreting the complex information encoded\nwithin genomic sequences remains a grand challenge in biological research and\nclinical applications. In this context, recent advancements in large language\nmodel research have led to the development of both encoder-only and\ndecoder-only foundation models designed to decode intricate information in DNA\nsequences. However, several issues persist, particularly regarding the\nefficient management of long-range dependencies inherent in genomic sequences,\nthe effective representation of nucleotide variations, and the considerable\ncomputational costs associated with large model architectures and extensive\npretraining datasets. Current genomic foundation models often face a critical\ntradeoff: smaller models with mediocre performance versus large models with\nimproved performance. To address these challenges, we introduce dnaGrinder, a\nunique and efficient genomic foundation model. dnaGrinder excels at managing\nlong-range dependencies within genomic sequences while minimizing computational\ncosts without compromising performance. It achieves results that are not just\ncomparable but often superior to leading DNA models such as Nucleotide\nTransformer and DNABERT-2. Furthermore, dnaGrinder is designed for easy\nfine-tuning on workstation-grade GPUs, accommodating input lengths exceeding\n17,000 tokens. On a single high-performance GPU, it supports sequences longer\nthan 140,000 tokens, making it a highly efficient and accessible tool for both\nbasic biological research and clinical applications.",
      "tldr_zh": "本研究针对基因组序列的复杂信息解读挑战，提出了一种轻量级、高容量的基础模型dnaGrinder，以解决现有模型在处理长距离依赖（long-range dependencies）、核苷酸变异表示以及高计算成本方面的局限性。dnaGrinder通过高效的设计，实现了对长序列的出色管理，同时在性能上优于或相当Nucleotide Transformer和DNABERT-2，且支持在工作站级GPU上轻松微调，处理超过17,000 tokens的输入，甚至在单高性能GPU上支持超过140,000 tokens的序列。总体而言，该模型为基因组研究和临床应用提供了高效、可访问的工具，平衡了计算资源与性能需求。",
      "categories": [
        "q-bio.GN",
        "cs.AI",
        "cs.CE",
        "cs.CL"
      ],
      "primary_category": "q-bio.GN",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.15697v1",
      "published_date": "2024-09-24 03:20:07 UTC",
      "updated_date": "2024-09-24 03:20:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:23:44.109840"
    },
    {
      "arxiv_id": "2409.15695v1",
      "title": "Toward Mixture-of-Experts Enabled Trustworthy Semantic Communication for 6G Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Jiayi He",
        "Xiaofeng Luo",
        "Jiawen Kang",
        "Hongyang Du",
        "Zehui Xiong",
        "Ci Chen",
        "Dusit Niyato",
        "Xuemin Shen"
      ],
      "abstract": "Semantic Communication (SemCom) plays a pivotal role in 6G networks, offering\na viable solution for future efficient communication. Deep Learning (DL)-based\nsemantic codecs further enhance this efficiency. However, the vulnerability of\nDL models to security threats, such as adversarial attacks, poses significant\nchallenges for practical applications of SemCom systems. These vulnerabilities\nenable attackers to tamper with messages and eavesdrop on private information,\nespecially in wireless communication scenarios. Although existing defenses\nattempt to address specific threats, they often fail to simultaneously handle\nmultiple heterogeneous attacks. To overcome this limitation, we introduce a\nnovel Mixture-of-Experts (MoE)-based SemCom system. This system comprises a\ngating network and multiple experts, each specializing in different security\nchallenges. The gating network adaptively selects suitable experts to counter\nheterogeneous attacks based on user-defined security requirements. Multiple\nexperts collaborate to accomplish semantic communication tasks while meeting\nthe security requirements of users. A case study in vehicular networks\ndemonstrates the efficacy of the MoE-based SemCom system. Simulation results\nshow that the proposed MoE-based SemCom system effectively mitigates concurrent\nheterogeneous attacks, with minimal impact on downstream task accuracy.",
      "tldr_zh": "本研究针对6G网络中Semantic Communication (SemCom)的安全挑战，指出Deep Learning (DL)-based语义编解码器易受对抗攻击等威胁，导致消息篡改和隐私泄露，且现有防御难以同时处理多种异构攻击。论文提出一个创新的Mixture-of-Experts (MoE)-based SemCom系统，该系统包括一个gating network和多个experts，允许gating network根据用户安全需求自适应选择experts进行协作，以实现可靠的语义通信任务。在车辆网络的案例研究中，模拟结果显示该系统能有效缓解并发异构攻击，同时对下游任务准确率的影响最小。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.NI",
      "comment": "8 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.15695v1",
      "published_date": "2024-09-24 03:17:51 UTC",
      "updated_date": "2024-09-24 03:17:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:23:58.446697"
    },
    {
      "arxiv_id": "2409.15688v2",
      "title": "Safe Navigation for Robotic Digestive Endoscopy via Human Intervention-based Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Min Tan",
        "Yushun Tao",
        "Boyun Zheng",
        "GaoSheng Xie",
        "Lijuan Feng",
        "Zeyang Xia",
        "Jing Xiong"
      ],
      "abstract": "With the increasing application of automated robotic digestive endoscopy\n(RDE), ensuring safe and efficient navigation in the unstructured and narrow\ndigestive tract has become a critical challenge. Existing automated\nreinforcement learning navigation algorithms often result in potentially risky\ncollisions due to the absence of essential human intervention, which\nsignificantly limits the safety and effectiveness of RDE in actual clinical\npractice. To address this limitation, we proposed a Human Intervention\n(HI)-based Proximal Policy Optimization (PPO) framework, dubbed HI-PPO, which\nincorporates expert knowledge to enhance RDE's safety. Specifically, HI-PPO\ncombines Enhanced Exploration Mechanism (EEM), Reward-Penalty Adjustment (RPA),\nand Behavior Cloning Similarity (BCS) to address PPO's exploration\ninefficiencies for safe navigation in complex gastrointestinal environments.\nComparative experiments were conducted on a simulation platform, and the\nresults showed that HI-PPO achieved a mean ATE (Average Trajectory Error) of\n\\(8.02\\ \\text{mm}\\) and a Security Score of \\(0.862\\), demonstrating\nperformance comparable to human experts. The code will be publicly available\nonce this paper is published.",
      "tldr_zh": "本研究针对机器人消化内镜 (RDE) 在复杂消化道环境中导航的安全挑战，提出了一种基于 Human Intervention (HI) 的 Proximal Policy Optimization (PPO) 框架，称为 HI-PPO，以整合人类专家知识提升安全性。HI-PPO 通过 Enhanced Exploration Mechanism (EEM)、Reward-Penalty Adjustment (RPA) 和 Behavior Cloning Similarity (BCS) 等组件，优化了 PPO 算法在探索和决策方面的效率，避免潜在碰撞风险。实验结果显示，在模拟平台上，HI-PPO 实现了平均轨迹误差 (ATE) 为 8.02 mm 和安全分数为 0.862，与人类专家性能相当，为 RDE 在临床实践中的可靠应用提供了重要基础。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.15688v2",
      "published_date": "2024-09-24 03:01:30 UTC",
      "updated_date": "2025-03-30 04:42:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:24:09.156102"
    },
    {
      "arxiv_id": "2409.15687v1",
      "title": "A Comprehensive Evaluation of Large Language Models on Mental Illnesses",
      "title_zh": "对大型语言模型在精神疾病方面的全面评估",
      "authors": [
        "Abdelrahman Hanafi",
        "Mohammed Saad",
        "Noureldin Zahran",
        "Radwa J. Hanafy",
        "Mohammed E. Fouda"
      ],
      "abstract": "Large language models have shown promise in various domains, including\nhealthcare. In this study, we conduct a comprehensive evaluation of LLMs in the\ncontext of mental health tasks using social media data. We explore the\nzero-shot (ZS) and few-shot (FS) capabilities of various LLMs, including GPT-4,\nLlama 3, Gemini, and others, on tasks such as binary disorder detection,\ndisorder severity evaluation, and psychiatric knowledge assessment. Our\nevaluation involved 33 models testing 9 main prompt templates across the tasks.\nKey findings revealed that models like GPT-4 and Llama 3 exhibited superior\nperformance in binary disorder detection, with accuracies reaching up to 85% on\ncertain datasets. Moreover, prompt engineering played a crucial role in\nenhancing model performance. Notably, the Mixtral 8x22b model showed an\nimprovement of over 20%, while Gemma 7b experienced a similar boost in\nperformance. In the task of disorder severity evaluation, we observed that FS\nlearning significantly improved the model's accuracy, highlighting the\nimportance of contextual examples in complex assessments. Notably, the\nPhi-3-mini model exhibited a substantial increase in performance, with balanced\naccuracy improving by over 6.80% and mean average error dropping by nearly 1.3\nwhen moving from ZS to FS learning. In the psychiatric knowledge task, recent\nmodels generally outperformed older, larger counterparts, with the Llama 3.1\n405b achieving an accuracy of 91.2%. Despite promising results, our analysis\nidentified several challenges, including variability in performance across\ndatasets and the need for careful prompt engineering. Furthermore, the ethical\nguards imposed by many LLM providers hamper the ability to accurately evaluate\ntheir performance, due to tendency to not respond to potentially sensitive\nqueries.",
      "tldr_zh": "本研究对大型语言模型（LLMs）在心理健康任务上的性能进行了全面评估，使用社交媒体数据测试了包括 GPT-4、Llama 3 和 Gemini 在内的 33 个模型，在零样本（ZS）和少样本（FS）设置下评估二元障碍检测、障碍严重程度评估以及精神病学知识任务。结果显示，GPT-4 和 Llama 3 在二元障碍检测中表现出色，准确率可达 85%，而提示工程显著提升了模型表现，如 Mixtral 8x22b 的性能提高了超过 20%。在障碍严重程度评估中，FS 学习比 ZS 学习更有效，Phi-3-mini 模型的平衡准确率提升了 6.80% 以上；在精神病学知识任务中，Llama 3.1 405b 达到了 91.2% 的准确率。尽管 LLMs 显示出潜力，但研究也指出了性能在数据集间的变异性、提示工程的必要性以及伦理限制带来的评估挑战。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.15687v1",
      "published_date": "2024-09-24 02:58:52 UTC",
      "updated_date": "2024-09-24 02:58:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:24:20.964619"
    },
    {
      "arxiv_id": "2410.07194v1",
      "title": "Technical Report: Competition Solution For Modelscope-Sora",
      "title_zh": "技术报告：Modelscope-Sora 竞赛解决方案",
      "authors": [
        "Shengfu Chen",
        "Hailong Liu",
        "Wenzhao Wei"
      ],
      "abstract": "This report presents the approach adopted in the Modelscope-Sora challenge,\nwhich focuses on fine-tuning data for video generation models. The challenge\nevaluates participants' ability to analyze, clean, and generate high-quality\ndatasets for video-based text-to-video tasks under specific computational\nconstraints. The provided methodology involves data processing techniques such\nas video description generation, filtering, and acceleration. This report\noutlines the procedures and tools utilized to enhance the quality of training\ndata, ensuring improved performance in text-to-video generation models.",
      "tldr_zh": "这篇报告介绍了针对 Modelscope-Sora 挑战的竞赛解决方案，焦点在于为视频生成模型微调数据的分析、清理和生成，以支持文本到视频任务。方法采用数据处理技术，包括视频描述生成、过滤和加速，确保在特定计算约束下提升数据集质量。最终，这些优化措施显著改善了文本到视频生成模型的性能，为高效的数据处理提供了实用工具。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.07194v1",
      "published_date": "2024-09-24 02:45:09 UTC",
      "updated_date": "2024-09-24 02:45:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:24:30.949418"
    },
    {
      "arxiv_id": "2409.15664v1",
      "title": "Mitigating Semantic Leakage in Cross-lingual Embeddings via Orthogonality Constraint",
      "title_zh": "通过正交性约束缓解跨语言嵌入中的语义泄露",
      "authors": [
        "Dayeon Ki",
        "Cheonbok Park",
        "Hyunjoong Kim"
      ],
      "abstract": "Accurately aligning contextual representations in cross-lingual sentence\nembeddings is key for effective parallel data mining. A common strategy for\nachieving this alignment involves disentangling semantics and language in\nsentence embeddings derived from multilingual pre-trained models. However, we\ndiscover that current disentangled representation learning methods suffer from\nsemantic leakage - a term we introduce to describe when a substantial amount of\nlanguage-specific information is unintentionally leaked into semantic\nrepresentations. This hinders the effective disentanglement of semantic and\nlanguage representations, making it difficult to retrieve embeddings that\ndistinctively represent the meaning of the sentence. To address this challenge,\nwe propose a novel training objective, ORthogonAlity Constraint LEarning\n(ORACLE), tailored to enforce orthogonality between semantic and language\nembeddings. ORACLE builds upon two components: intra-class clustering and\ninter-class separation. Through experiments on cross-lingual retrieval and\nsemantic textual similarity tasks, we demonstrate that training with the ORACLE\nobjective effectively reduces semantic leakage and enhances semantic alignment\nwithin the embedding space.",
      "tldr_zh": "该论文探讨了在跨语言嵌入（cross-lingual embeddings）中，semantic leakage 问题导致语义和语言表示无法有效分离，从而影响句子含义的准确对齐。针对这一挑战，研究提出了一种新训练目标 ORACLE（ORthogonAlity Constraint LEarning），通过强制语义和语言嵌入正交来减少泄露。ORACLE 由 intra-class clustering（类内聚类）和 inter-class separation（类间分离）两个组件组成，确保语义表示的独立性。实验在跨语言检索和语义文本相似性任务上证明，ORACLE 显著降低了 semantic leakage，并提升了嵌入空间的语义对齐。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "18 pages, 16 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.15664v1",
      "published_date": "2024-09-24 02:01:52 UTC",
      "updated_date": "2024-09-24 02:01:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:24:54.893761"
    },
    {
      "arxiv_id": "2409.15662v1",
      "title": "Double-Path Adaptive-correlation Spatial-Temporal Inverted Transformer for Stock Time Series Forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Wenbo Yan",
        "Ying Tan"
      ],
      "abstract": "Spatial-temporal graph neural networks (STGNNs) have achieved significant\nsuccess in various time series forecasting tasks. However, due to the lack of\nexplicit and fixed spatial relationships in stock prediction tasks, many STGNNs\nfail to perform effectively in this domain. While some STGNNs learn spatial\nrelationships from time series, they often lack comprehensiveness. Research\nindicates that modeling time series using feature changes as tokens reveals\nentirely different information compared to using time steps as tokens. To more\ncomprehensively extract dynamic spatial information from stock data, we propose\na Double-Path Adaptive-correlation Spatial-Temporal Inverted Transformer\n(DPA-STIFormer). DPA-STIFormer models each node via continuous changes in\nfeatures as tokens and introduces a Double Direction Self-adaptation Fusion\nmechanism. This mechanism decomposes node encoding into temporal and feature\nrepresentations, simultaneously extracting different spatial correlations from\na double path approach, and proposes a Double-path gating mechanism to fuse\nthese two types of correlation information. Experiments conducted on four stock\nmarket datasets demonstrate state-of-the-art results, validating the model's\nsuperior capability in uncovering latent temporal-correlation patterns.",
      "tldr_zh": "这篇论文提出了一种名为 Double-Path Adaptive-correlation Spatial-Temporal Inverted Transformer (DPA-STIFormer) 的模型，用于提升股票时间序列预测的性能，以解决 Spatial-temporal graph neural networks (STGNNs) 在缺乏明确空间关系时的不足。DPA-STIFormer 通过将特征变化作为 tokens 建模节点，并引入 Double Direction Self-adaptation Fusion 机制，从双路径同时提取时间和特征表示的空间相关性，并利用 Double-path gating 机制融合这些信息。实验结果显示，该模型在四个股票市场数据集上取得了 state-of-the-art 性能，证明了其在揭示潜在时间-相关性模式方面的全面优势。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.15662v1",
      "published_date": "2024-09-24 01:53:22 UTC",
      "updated_date": "2024-09-24 01:53:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:24:56.557464"
    },
    {
      "arxiv_id": "2409.15658v2",
      "title": "Long-horizon Embodied Planning with Implicit Logical Inference and Hallucination Mitigation",
      "title_zh": "翻译失败",
      "authors": [
        "Siyuan Liu",
        "Jiawei Du",
        "Sicheng Xiang",
        "Zibo Wang",
        "Dingsheng Luo"
      ],
      "abstract": "Long-horizon embodied planning underpins embodied AI. To accomplish\nlong-horizon tasks, one of the most feasible ways is to decompose abstract\ninstructions into a sequence of actionable steps. Foundation models still face\nlogical errors and hallucinations in long-horizon planning, unless provided\nwith highly relevant examples to the tasks. However, providing highly relevant\nexamples for any random task is unpractical. Therefore, we present ReLEP, a\nnovel framework for Real-time Long-horizon Embodied Planning. ReLEP can\ncomplete a wide range of long-horizon tasks without in-context examples by\nlearning implicit logical inference through fine-tuning. The fine-tuned large\nvision-language model formulates plans as sequences of skill functions. These\nfunctions are selected from a carefully designed skill library. ReLEP is also\nequipped with a Memory module for plan and status recall, and a Robot\nConfiguration module for versatility across robot types. In addition, we\npropose a data generation pipeline to tackle dataset scarcity. When\nconstructing the dataset, we considered the implicit logical relationships,\nenabling the model to learn implicit logical relationships and dispel\nhallucinations. Through comprehensive evaluations across various long-horizon\ntasks, ReLEP demonstrates high success rates and compliance to execution even\non unseen tasks and outperforms state-of-the-art baseline methods.",
      "tldr_zh": "该研究针对长时限具身规划（long-horizon embodied planning）中的逻辑错误和幻觉问题，提出了一种名为 ReLEP 的新型框架，通过微调学习隐式逻辑推理（implicit logical inference），无需上下文例子即可生成技能函数序列，以完成各种长时限任务。ReLEP 框架包括 Memory 模块用于计划和状态回忆、Robot Configuration 模块以适应不同机器人类型，以及一个数据生成管道来解决数据集稀缺问题，并通过考虑隐式逻辑关系减少幻觉。实验结果显示，ReLEP 在多种任务上实现了高成功率和执行一致性，甚至在未见过任务中，也优于现有基线方法。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.15658v2",
      "published_date": "2024-09-24 01:47:23 UTC",
      "updated_date": "2025-03-13 10:15:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:25:06.693795"
    },
    {
      "arxiv_id": "2409.15657v4",
      "title": "M$^2$PT: Multimodal Prompt Tuning for Zero-shot Instruction Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Taowen Wang",
        "Yiyang Liu",
        "James Chenhao Liang",
        "junhan zhao",
        "Yiming Cui",
        "Yuning Mao",
        "Shaoliang Nie",
        "Jiahao Liu",
        "Fuli Feng",
        "Zenglin Xu",
        "Cheng Han",
        "Lifu Huang",
        "Qifan Wang",
        "Dongfang Liu"
      ],
      "abstract": "Multimodal Large Language Models (MLLMs) demonstrate remarkable performance\nacross a wide range of domains, with increasing emphasis on enhancing their\nzero-shot generalization capabilities for unseen tasks across various\nmodalities. Instruction tuning has emerged as an effective strategy for\nachieving zero-shot generalization by finetuning pretrained models on diverse\nmultimodal tasks. As the scale of MLLMs continues to grow, parameter-efficient\nfinetuning becomes increasingly critical. However, most existing\nparameter-efficient approaches focus only on single modalities and often\noverlook the multimodal characteristics during finetuning. In this work, we\nintroduce a novel Multimodal Prompt Tuning (M$^2$PT) approach for efficient\ninstruction tuning of MLLMs. M$^2$PT effectively integrates visual and textual\nprompts into the vision encoder and language processor respectively during\nfinetuning, facilitating the extraction and alignment of features across\nmodalities. Empirical results on various multimodal evaluation datasets\ndemonstrate the superior performance of our approach compared to several\nstate-of-the-art baselines. A comprehensive set of ablation studies validates\nthe effectiveness of our prompt design and the efficiency of our approach.",
      "tldr_zh": "本研究提出了一种新型方法 M$^2$PT（Multimodal Prompt Tuning），旨在通过参数高效微调提升 Multimodal Large Language Models (MLLMs) 的零样本指令学习（Zero-shot Instruction Learning）能力，以解决现有方法忽略多模态特性的问题。M$^2$PT 在微调过程中将视觉和文本提示整合到视觉编码器和语言处理器中，促进跨模态特征提取和对齐，从而提高模型在未见任务上的泛化性能。实验结果显示，该方法在多种多模态评估数据集上优于现有基线模型，而消融研究（Ablation studies）进一步验证了其提示设计的有效性和整体效率。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "EMNLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.15657v4",
      "published_date": "2024-09-24 01:40:24 UTC",
      "updated_date": "2024-10-30 04:38:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:25:20.860996"
    },
    {
      "arxiv_id": "2409.15637v2",
      "title": "Synatra: Turning Indirect Knowledge into Direct Demonstrations for Digital Agents at Scale",
      "title_zh": "翻译失败",
      "authors": [
        "Tianyue Ou",
        "Frank F. Xu",
        "Aman Madaan",
        "Jiarui Liu",
        "Robert Lo",
        "Abishek Sridhar",
        "Sudipta Sengupta",
        "Dan Roth",
        "Graham Neubig",
        "Shuyan Zhou"
      ],
      "abstract": "LLMs can now act as autonomous agents that interact with digital environments\nand complete specific objectives (e.g., arranging an online meeting). However,\naccuracy is still far from satisfactory, partly due to a lack of large-scale,\ndirect demonstrations for digital tasks. Obtaining supervised data from humans\nis costly, and automatic data collection through exploration or reinforcement\nlearning relies on complex environmental and content setup, resulting in\ndatasets that lack comprehensive coverage of various scenarios. On the other\nhand, there is abundant knowledge that may indirectly assist task completion,\nsuch as online tutorials that were created for human consumption. In this work,\nwe present Synatra, an approach that effectively transforms this indirect\nknowledge into direct supervision at scale. We define different types of\nindirect knowledge, and carefully study the available sources to obtain it,\nmethods to encode the structure of direct demonstrations, and finally methods\nto transform indirect knowledge into direct demonstrations. We use 100k such\nsynthetically-created demonstrations to finetune a 7B CodeLlama, and\ndemonstrate that the resulting agent surpasses all comparably sized models on\nthree web-based task benchmarks Mind2Web, MiniWoB++ and WebArena, as well as\nsurpassing GPT-3.5 on WebArena and Mind2Web. In addition, while synthetic\ndemonstrations prove to be only 3% the cost of human demonstrations (at $0.031\neach), we show that the synthetic demonstrations can be more effective than an\nidentical number of human demonstrations collected from limited domains.",
      "tldr_zh": "该研究提出Synatra方法，将间接知识（如在线教程）转化为大规模直接演示，以提升LLMs作为数字代理的准确性，解决数据获取成本高和覆盖不足的问题。Synatra定义了间接知识类型、编码演示结构，并通过转换机制生成合成演示，使用10万条合成数据微调7B CodeLlama模型。实验结果显示，该模型在Mind2Web、MiniWoB++和WebArena基准上超越同规模模型及GPT-3.5，同时合成演示的成本仅为人类演示的3%（每个0.031美元），且在特定领域更有效。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.15637v2",
      "published_date": "2024-09-24 00:51:45 UTC",
      "updated_date": "2024-11-27 16:34:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:25:32.875651"
    },
    {
      "arxiv_id": "2409.15636v1",
      "title": "Personalized Federated Learning via Backbone Self-Distillation",
      "title_zh": "通过骨干自蒸馏的个性化联邦学习",
      "authors": [
        "Pengju Wang",
        "Bochao Liu",
        "Dan Zeng",
        "Chenggang Yan",
        "Shiming Ge"
      ],
      "abstract": "In practical scenarios, federated learning frequently necessitates training\npersonalized models for each client using heterogeneous data. This paper\nproposes a backbone self-distillation approach to facilitate personalized\nfederated learning. In this approach, each client trains its local model and\nonly sends the backbone weights to the server. These weights are then\naggregated to create a global backbone, which is returned to each client for\nupdating. However, the client's local backbone lacks personalization because of\nthe common representation. To solve this problem, each client further performs\nbackbone self-distillation by using the global backbone as a teacher and\ntransferring knowledge to update the local backbone. This process involves\nlearning two components: the shared backbone for common representation and the\nprivate head for local personalization, which enables effective global\nknowledge transfer. Extensive experiments and comparisons with 12\nstate-of-the-art approaches demonstrate the effectiveness of our approach.",
      "tldr_zh": "本文提出了一种backbone self-distillation方法，用于个性化federated learning，帮助每个客户端在异构数据上训练个性化模型。方法涉及客户端发送backbone weights到服务器进行聚合，然后使用全局backbone作为teacher进行self-distillation，以更新本地backbone并学习共享的backbone和私有的head，实现有效的知识转移。实验结果显示，该方法在与12种最先进方法的比较中表现出色，证明了其在联邦学习中的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Pubished in ACM MMAsia 2023",
      "pdf_url": "http://arxiv.org/pdf/2409.15636v1",
      "published_date": "2024-09-24 00:43:16 UTC",
      "updated_date": "2024-09-24 00:43:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:25:44.788649"
    },
    {
      "arxiv_id": "2409.15631v3",
      "title": "Data Augmentation for Sparse Multidimensional Learning Performance Data Using Generative AI",
      "title_zh": "翻译失败",
      "authors": [
        "Liang Zhang",
        "Jionghao Lin",
        "John Sabatini",
        "Conrad Borchers",
        "Daniel Weitekamp",
        "Meng Cao",
        "John Hollander",
        "Xiangen Hu",
        "Arthur C. Graesser"
      ],
      "abstract": "Learning performance data describe correct and incorrect answers or\nproblem-solving attempts in adaptive learning, such as in intelligent tutoring\nsystems (ITSs). Learning performance data tend to be highly sparse\n(80\\%\\(\\sim\\)90\\% missing observations) in most real-world applications due to\nadaptive item selection. This data sparsity presents challenges to using\nlearner models to effectively predict future performance explore new hypotheses\nabout learning. This article proposes a systematic framework for augmenting\nlearner data to address data sparsity in learning performance data. First,\nlearning performance is represented as a three-dimensional tensor of learners'\nquestions, answers, and attempts, capturing longitudinal knowledge states\nduring learning. Second, a tensor factorization method is used to impute\nmissing values in sparse tensors of collected learner data, thereby grounding\nthe imputation on knowledge tracing tasks that predict missing performance\nvalues based on real observations. Third, a module for generating patterns of\nlearning is used. This study contrasts two forms of generative Artificial\nIntelligence (AI), including Generative Adversarial Networks (GANs) and\nGenerate Pre-Trained Transformers (GPT) to generate data associated with\ndifferent clusters of learner data. We tested this approach on an adult\nliteracy dataset from AutoTutor lessons developed for Adult Reading\nComprehension (ARC). We found that: (1) tensor factorization improved the\nperformance in tracing and predicting knowledge mastery compared with other\nknowledge tracing techniques without data augmentation, showing higher relative\nfidelity for this imputation method, and (2) the GAN-based simulation showed\ngreater overall stability and less statistical bias based on a divergence\nevaluation with varying simulation sample sizes compared to GPT.",
      "tldr_zh": "这篇论文针对学习表现数据的稀疏性（80%~90% 缺失观察）问题，提出一个系统框架来扩充数据，包括将数据表示为三维张量、使用 tensor factorization 填充缺失值，以及通过 Generative AI（如 GANs 和 GPT）生成不同学习模式。实验在 AutoTutor 的成人识字数据集上进行，结果显示 tensor factorization 显著提高了知识追踪和预测性能，与无扩充方法相比更准确。此外，GANs 在模拟稳定性方面优于 GPT，表现出更低的统计偏差。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.15631v3",
      "published_date": "2024-09-24 00:25:07 UTC",
      "updated_date": "2025-01-03 23:27:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T03:25:57.662989"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 123,
  "processed_papers_count": 123,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-20T03:26:28.370866"
}