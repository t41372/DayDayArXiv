[
  {
    "arxiv_id": "2504.14423v1",
    "title": "Adversarial Attack for RGB-Event based Visual Object Tracking",
    "authors": [
      "Qiang Chen",
      "Xiao Wang",
      "Haowen Wang",
      "Bo Jiang",
      "Lin Zhu",
      "Dawei Zhang",
      "Yonghong Tian",
      "Jin Tang"
    ],
    "abstract": "Visual object tracking is a crucial research topic in the fields of computer\nvision and multi-modal fusion. Among various approaches, robust visual tracking\nthat combines RGB frames with Event streams has attracted increasing attention\nfrom researchers. While striving for high accuracy and efficiency in tracking,\nit is also important to explore how to effectively conduct adversarial attacks\nand defenses on RGB-Event stream tracking algorithms, yet research in this area\nremains relatively scarce. To bridge this gap, in this paper, we propose a\ncross-modal adversarial attack algorithm for RGB-Event visual tracking. Because\nof the diverse representations of Event streams, and given that Event voxels\nand frames are more commonly used, this paper will focus on these two\nrepresentations for an in-depth study. Specifically, for the RGB-Event voxel,\nwe first optimize the perturbation by adversarial loss to generate RGB frame\nadversarial examples. For discrete Event voxel representations, we propose a\ntwo-step attack strategy, more in detail, we first inject Event voxels into the\ntarget region as initialized adversarial examples, then, conduct a\ngradient-guided optimization by perturbing the spatial location of the Event\nvoxels. For the RGB-Event frame based tracking, we optimize the cross-modal\nuniversal perturbation by integrating the gradient information from multimodal\ndata. We evaluate the proposed approach against attacks on three widely used\nRGB-Event Tracking datasets, i.e., COESOT, FE108, and VisEvent. Extensive\nexperiments show that our method significantly reduces the performance of the\ntracker across numerous datasets in both unimodal and multimodal scenarios. The\nsource code will be released on\nhttps://github.com/Event-AHU/Adversarial_Attack_Defense",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.14423v1",
    "published_date": "2025-04-19 23:35:19 UTC",
    "updated_date": "2025-04-19 23:35:19 UTC"
  },
  {
    "arxiv_id": "2504.14411v3",
    "title": "Planet as a Brain: Towards Internet of AgentSites based on AIOS Server",
    "authors": [
      "Xiang Zhang",
      "Yongfeng Zhang"
    ],
    "abstract": "The internet is undergoing a historical transformation from the \"Internet of\nWebsites\" to the \"Internet of AgentSites.\" While traditional Websites served as\nthe foundation for information hosting and dissemination, a new frontier is\nemerging where AgentSites serve as the hubs of the internet, where each\nAgentSite hosts one or more AI agents that receive tasks, address them, and\ndeliver actionable solutions, marking a significant shift in the digital\nlandscape and representing the next generation of online ecosystems. Under this\nvision, AIOS, the AI Agent Operating System, serves as the server for the\ndevelopment, deployment and execution of AI agents, which is a fundamental\ninfrastructure for the Internet of Agentsites.\n  In this paper, we introduce AIOS Server, a runtime framework to host agents\nand enable global-scale collaboration among decentralized agents. AIOS Server\nprovides a communication protocol leveraging the Model Context Protocol (MCP)\nand JSON-RPC to enable agent-agent or human-agent interactions. Each AIOS node\noperates as a server to host and execute agents, while supporting peer-to-peer\ncoordination without reliance on centralized orchestration. Based on AIOS\nServer, we further present the world's first practically deployed Internet of\nAgentsites (AIOS-IoA), including AgentHub for agent registration and discovery\nand AgentChat for interactive communication, at https://planet.aios.foundation.\nThe agent discovery mechanism based on Distributed Hash Tables (DHT) and a\nGossip protocol serves as the search engine for the internet of agentsites.\nThis work provides a practical foundation for building the Internet of\nAgentsites-a new paradigm where autonomous agents become first-class citizens\nof the web. The implementation is available at\nhttps://github.com/agiresearch/AIOS.Server and is integrated into the AIOS main\nbranch at https://github.com/agiresearch/AIOS.",
    "categories": [
      "cs.NI",
      "cs.AI"
    ],
    "primary_category": "cs.NI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.14411v3",
    "published_date": "2025-04-19 21:58:00 UTC",
    "updated_date": "2025-05-09 14:35:17 UTC"
  },
  {
    "arxiv_id": "2504.14409v1",
    "title": "Data Augmentation Using Neural Acoustic Fields With Retrieval-Augmented Pre-training",
    "authors": [
      "Christopher Ick",
      "Gordon Wichern",
      "Yoshiki Masuyama",
      "Fran√ßois G. Germain",
      "Jonathan Le Roux"
    ],
    "abstract": "This report details MERL's system for room impulse response (RIR) estimation\nsubmitted to the Generative Data Augmentation Workshop at ICASSP 2025 for\nAugmenting RIR Data (Task 1) and Improving Speaker Distance Estimation (Task\n2). We first pre-train a neural acoustic field conditioned by room geometry on\nan external large-scale dataset in which pairs of RIRs and the geometries are\nprovided. The neural acoustic field is then adapted to each target room by\nusing the enrollment data, where we leverage either the provided room\ngeometries or geometries retrieved from the external dataset, depending on\navailability. Lastly, we predict the RIRs for each pair of source and receiver\nlocations specified by Task 1, and use these RIRs to train the speaker distance\nestimation model in Task 2.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "cs.SD"
    ],
    "primary_category": "eess.AS",
    "comment": "Presented at ICASSP 2025 GenDA Workshop",
    "pdf_url": "http://arxiv.org/pdf/2504.14409v1",
    "published_date": "2025-04-19 21:43:56 UTC",
    "updated_date": "2025-04-19 21:43:56 UTC"
  },
  {
    "arxiv_id": "2504.14406v2",
    "title": "ScholarMate: A Mixed-Initiative Tool for Qualitative Knowledge Work and Information Sensemaking",
    "authors": [
      "Runlong Ye",
      "Patrick Yung Kang Lee",
      "Matthew Varona",
      "Oliver Huang",
      "Carolina Nobre"
    ],
    "abstract": "Synthesizing knowledge from large document collections is a critical yet\nincreasingly complex aspect of qualitative research and knowledge work. While\nAI offers automation potential, effectively integrating it into human-centric\nsensemaking workflows remains challenging. We present ScholarMate, an\ninteractive system designed to augment qualitative analysis by unifying AI\nassistance with human oversight. ScholarMate enables researchers to dynamically\narrange and interact with text snippets on a non-linear canvas, leveraging AI\nfor theme suggestions, multi-level summarization, and evidence-based theme\nnaming, while ensuring transparency through traceability to source documents.\nInitial pilot studies indicated that users value this mixed-initiative\napproach, finding the balance between AI suggestions and direct manipulation\ncrucial for maintaining interpretability and trust. We further demonstrate the\nsystem's capability through a case study analyzing 24 papers. By balancing\nautomation with human control, ScholarMate enhances efficiency and supports\ninterpretability, offering a valuable approach for productive human-AI\ncollaboration in demanding sensemaking tasks common in knowledge work.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "accepted at CHIWORK '25",
    "pdf_url": "http://arxiv.org/pdf/2504.14406v2",
    "published_date": "2025-04-19 21:11:40 UTC",
    "updated_date": "2025-05-16 17:13:48 UTC"
  },
  {
    "arxiv_id": "2504.16122v1",
    "title": "SOTOPIA-S4: a user-friendly system for flexible, customizable, and large-scale social simulation",
    "authors": [
      "Xuhui Zhou",
      "Zhe Su",
      "Sophie Feng",
      "Jiaxu Zhou",
      "Jen-tse Huang",
      "Hsien-Te Kao",
      "Spencer Lynch",
      "Svitlana Volkova",
      "Tongshuang Sherry Wu",
      "Anita Woolley",
      "Hao Zhu",
      "Maarten Sap"
    ],
    "abstract": "Social simulation through large language model (LLM) agents is a promising\napproach to explore and validate hypotheses related to social science questions\nand LLM agents behavior. We present SOTOPIA-S4, a fast, flexible, and scalable\nsocial simulation system that addresses the technical barriers of current\nframeworks while enabling practitioners to generate multi-turn and multi-party\nLLM-based interactions with customizable evaluation metrics for hypothesis\ntesting. SOTOPIA-S4 comes as a pip package that contains a simulation engine,\nan API server with flexible RESTful APIs for simulation management, and a web\ninterface that enables both technical and non-technical users to design, run,\nand analyze simulations without programming. We demonstrate the usefulness of\nSOTOPIA-S4 with two use cases involving dyadic hiring negotiation and\nmulti-party planning scenarios.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "The first author and the second author contributed equally",
    "pdf_url": "http://arxiv.org/pdf/2504.16122v1",
    "published_date": "2025-04-19 20:02:59 UTC",
    "updated_date": "2025-04-19 20:02:59 UTC"
  },
  {
    "arxiv_id": "2504.14395v1",
    "title": "Hydra: An Agentic Reasoning Approach for Enhancing Adversarial Robustness and Mitigating Hallucinations in Vision-Language Models",
    "authors": [
      "Chung-En",
      "Yu",
      "Hsuan-Chih",
      "Chen",
      "Brian Jalaian",
      "Nathaniel D. Bastian"
    ],
    "abstract": "To develop trustworthy Vision-Language Models (VLMs), it is essential to\naddress adversarial robustness and hallucination mitigation, both of which\nimpact factual accuracy in high-stakes applications such as defense and\nhealthcare. Existing methods primarily focus on either adversarial defense or\nhallucination post-hoc correction, leaving a gap in unified robustness\nstrategies. We introduce \\textbf{Hydra}, an adaptive agentic framework that\nenhances plug-in VLMs through iterative reasoning, structured critiques, and\ncross-model verification, improving both resilience to adversarial\nperturbations and intrinsic model errors. Hydra employs an Action-Critique\nLoop, where it retrieves and critiques visual information, leveraging\nChain-of-Thought (CoT) and In-Context Learning (ICL) techniques to refine\noutputs dynamically. Unlike static post-hoc correction methods, Hydra adapts to\nboth adversarial manipulations and intrinsic model errors, making it robust to\nmalicious perturbations and hallucination-related inaccuracies. We evaluate\nHydra on four VLMs, three hallucination benchmarks, two adversarial attack\nstrategies, and two adversarial defense methods, assessing performance on both\nclean and adversarial inputs. Results show that Hydra surpasses plug-in VLMs\nand state-of-the-art (SOTA) dehallucination methods, even without explicit\nadversarial defenses, demonstrating enhanced robustness and factual\nconsistency. By bridging adversarial resistance and hallucination mitigation,\nHydra provides a scalable, training-free solution for improving the reliability\nof VLMs in real-world applications.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.14395v1",
    "published_date": "2025-04-19 19:51:20 UTC",
    "updated_date": "2025-04-19 19:51:20 UTC"
  },
  {
    "arxiv_id": "2504.14386v1",
    "title": "LOOPE: Learnable Optimal Patch Order in Positional Embeddings for Vision Transformers",
    "authors": [
      "Md Abtahi Majeed Chowdhury",
      "Md Rifat Ur Rahman",
      "Akil Ahmad Taki"
    ],
    "abstract": "Positional embeddings (PE) play a crucial role in Vision Transformers (ViTs)\nby providing spatial information otherwise lost due to the permutation\ninvariant nature of self attention. While absolute positional embeddings (APE)\nhave shown theoretical advantages over relative positional embeddings (RPE),\nparticularly due to the ability of sinusoidal functions to preserve spatial\ninductive biases like monotonicity and shift invariance, a fundamental\nchallenge arises when mapping a 2D grid to a 1D sequence. Existing methods have\nmostly overlooked or never explored the impact of patch ordering in positional\nembeddings. To address this, we propose LOOPE, a learnable patch-ordering\nmethod that optimizes spatial representation for a given set of frequencies,\nproviding a principled approach to patch order optimization. Empirical results\nshow that our PE significantly improves classification accuracy across various\nViT architectures. To rigorously evaluate the effectiveness of positional\nembeddings, we introduce the \"Three Cell Experiment\", a novel benchmarking\nframework that assesses the ability of PEs to retain relative and absolute\npositional information across different ViT architectures. Unlike standard\nevaluations, which typically report a performance gap of 4 to 6% between models\nwith and without PE, our method reveals a striking 30 to 35% difference,\noffering a more sensitive diagnostic tool to measure the efficacy of PEs. Our\nexperimental analysis confirms that the proposed LOOPE demonstrates enhanced\neffectiveness in retaining both relative and absolute positional information.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.14386v1",
    "published_date": "2025-04-19 19:20:47 UTC",
    "updated_date": "2025-04-19 19:20:47 UTC"
  },
  {
    "arxiv_id": "2504.14379v2",
    "title": "The Geometry of Self-Verification in a Task-Specific Reasoning Model",
    "authors": [
      "Andrew Lee",
      "Lihao Sun",
      "Chris Wendler",
      "Fernanda Vi√©gas",
      "Martin Wattenberg"
    ],
    "abstract": "How do reasoning models verify their own answers? We study this question by\ntraining a model using DeepSeek R1's recipe on the CountDown task. We leverage\nthe fact that preference tuning leads to mode collapse, yielding a model that\nalways produces highly structured chain-of-thought sequences. With this setup,\nwe do top-down and bottom-up analyses to reverse-engineer how the model\nverifies its outputs. Top-down, we find Gated Linear Unit (GLU) weights\nencoding verification-related tokens, such as ``success'' or ``incorrect''.\nBottom-up, we find that ``previous-token heads'' are mainly responsible for\nself-verification in our setup. Our analyses meet in the middle: drawing\ninspiration from inter-layer communication channels, we use the identified GLU\nweights to localize as few as three attention heads that can disable\nself-verification, pointing to a necessary component of a potentially larger\nverification circuit. Finally, we verify that similar verification components\nexist in our base model and a general reasoning DeepSeek-R1 model.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.14379v2",
    "published_date": "2025-04-19 18:40:51 UTC",
    "updated_date": "2025-05-11 04:15:06 UTC"
  },
  {
    "arxiv_id": "2504.14372v1",
    "title": "Learning Enhanced Structural Representations with Block-Based Uncertainties for Ocean Floor Mapping",
    "authors": [
      "Jose Marie Antonio Minoza"
    ],
    "abstract": "Accurate ocean modeling and coastal hazard prediction depend on\nhigh-resolution bathymetric data; yet, current worldwide datasets are too\ncoarse for exact numerical simulations. While recent deep learning advances\nhave improved earth observation data resolution, existing methods struggle with\nthe unique challenges of producing detailed ocean floor maps, especially in\nmaintaining physical structure consistency and quantifying uncertainties. This\nwork presents a novel uncertainty-aware mechanism using spatial blocks to\nefficiently capture local bathymetric complexity based on block-based conformal\nprediction. Using the Vector Quantized Variational Autoencoder (VQ-VAE)\narchitecture, the integration of this uncertainty quantification framework\nyields spatially adaptive confidence estimates while preserving topographical\nfeatures via discrete latent representations. With smaller uncertainty widths\nin well-characterized areas and appropriately larger bounds in areas of complex\nseafloor structures, the block-based design adapts uncertainty estimates to\nlocal bathymetric complexity. Compared to conventional techniques, experimental\nresults over several ocean regions show notable increases in both\nreconstruction quality and uncertainty estimation reliability. This framework\nincreases the reliability of bathymetric reconstructions by preserving\nstructural integrity while offering spatially adaptive uncertainty estimates,\nso opening the path for more solid climate modeling and coastal hazard\nassessment.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.14372v1",
    "published_date": "2025-04-19 18:20:08 UTC",
    "updated_date": "2025-04-19 18:20:08 UTC"
  },
  {
    "arxiv_id": "2504.14367v1",
    "title": "Diverse Prompts: Illuminating the Prompt Space of Large Language Models with MAP-Elites",
    "authors": [
      "Gabriel Machado Santos",
      "Rita Maria da Silva Julia",
      "Marcelo Zanchetta do Nascimento"
    ],
    "abstract": "Prompt engineering is essential for optimizing large language models (LLMs),\nyet the link between prompt structures and task performance remains\nunderexplored. This work introduces an evolutionary approach that combines\ncontext-free grammar (CFG) with the MAP-Elites algorithm to systematically\nexplore the prompt space. Our method prioritizes quality and diversity,\ngenerating high-performing and structurally varied prompts while analyzing\ntheir alignment with diverse tasks by varying traits such as the number of\nexamples (shots) and reasoning depth. By systematically mapping the phenotypic\nspace, we reveal how structural variations influence LLM performance, offering\nactionable insights for task-specific and adaptable prompt design. Evaluated on\nseven BigBench Lite tasks across multiple LLMs, our results underscore the\ncritical interplay of quality and diversity, advancing the effectiveness and\nversatility of LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "8 pages Accepted for publication in IEEE CEC 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.14367v1",
    "published_date": "2025-04-19 17:50:34 UTC",
    "updated_date": "2025-04-19 17:50:34 UTC"
  },
  {
    "arxiv_id": "2504.14366v1",
    "title": "Empirical Evaluation of Knowledge Distillation from Transformers to Subquadratic Language Models",
    "authors": [
      "Patrick Haller",
      "Jonas Golde",
      "Alan Akbik"
    ],
    "abstract": "Knowledge distillation is a widely used technique for compressing large\nlanguage models (LLMs) by training a smaller student model to mimic a larger\nteacher model. Typically, both the teacher and student are Transformer-based\narchitectures, leveraging softmax attention for sequence modeling. However, the\nquadratic complexity of self-attention at inference time remains a significant\nbottleneck, motivating the exploration of subquadratic alternatives such as\nstructured state-space models (SSMs), linear attention, and recurrent\narchitectures. In this work, we systematically evaluate the transferability of\nknowledge distillation from a Transformer teacher to nine subquadratic student\narchitectures. Our study aims to determine which subquadratic model best aligns\nwith the teacher's learned representations and how different architectural\nconstraints influence the distillation process. We also investigate the impact\nof intelligent initialization strategies, including matrix mixing and\nquery-key-value (QKV) copying, on the adaptation process. Our empirical results\non multiple NLP benchmarks provide insights into the trade-offs between\nefficiency and performance, highlighting key factors for successful knowledge\ntransfer to subquadratic architectures.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.14366v1",
    "published_date": "2025-04-19 17:49:52 UTC",
    "updated_date": "2025-04-19 17:49:52 UTC"
  },
  {
    "arxiv_id": "2504.14365v1",
    "title": "Accelerating LLM Inference with Flexible N:M Sparsity via A Fully Digital Compute-in-Memory Accelerator",
    "authors": [
      "Akshat Ramachandran",
      "Souvik Kundu",
      "Arnab Raha",
      "Shamik Kundu",
      "Deepak K. Mathaikutty",
      "Tushar Krishna"
    ],
    "abstract": "Large language model (LLM) pruning with fixed N:M structured sparsity\nsignificantly limits the expressivity of the sparse model, yielding sub-optimal\nperformance. In contrast, supporting multiple N:M patterns to provide sparse\nrepresentational freedom introduces costly overhead in hardware. To address\nthese challenges for LLMs, we first present a flexible layer-wise\noutlier-density-aware N:M sparsity (FLOW) selection method. FLOW enables the\nidentification of optimal layer-wise N and M values (from a given range) by\nsimultaneously accounting for the presence and distribution of outliers,\nallowing a higher degree of representational freedom. To deploy sparse models\nwith such N:M flexibility, we then introduce a flexible, low-overhead digital\ncompute-in-memory architecture (FlexCiM). FlexCiM supports diverse sparsity\npatterns by partitioning a digital CiM (DCiM) macro into smaller sub-macros,\nwhich are adaptively aggregated and disaggregated through distribution and\nmerging mechanisms for different N and M values. Extensive experiments on both\ntransformer-based and recurrence-based state space foundation models (SSMs)\ndemonstrate that FLOW outperforms existing alternatives with an accuracy\nimprovement of up to 36%, while FlexCiM achieves up to 1.75x lower inference\nlatency and 1.5x lower energy consumption compared to existing sparse\naccelerators. Code is available at: https://github.com/FLOW-open-project/FLOW",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.AR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.14365v1",
    "published_date": "2025-04-19 17:47:01 UTC",
    "updated_date": "2025-04-19 17:47:01 UTC"
  },
  {
    "arxiv_id": "2504.14359v1",
    "title": "A Multimodal Recaptioning Framework to Account for Perceptual Diversity in Multilingual Vision-Language Modeling",
    "authors": [
      "Kyle Buettner",
      "Jacob Emmerson",
      "Adriana Kovashka"
    ],
    "abstract": "There are many ways to describe, name, and group objects when captioning an\nimage. Differences are evident when speakers come from diverse cultures due to\nthe unique experiences that shape perception. Machine translation of captions\nhas pushed multilingual capabilities in vision-language models (VLMs), but data\ncomes mainly from English speakers, indicating a perceptual bias and lack of\nmodel flexibility. In this work, we address this challenge and outline a\ndata-efficient framework to instill multilingual VLMs with greater\nunderstanding of perceptual diversity. We specifically propose an LLM-based,\nmultimodal recaptioning strategy that alters the object descriptions of English\ncaptions before translation. The greatest benefits are demonstrated in a\ntargeted multimodal mechanism guided by native speaker data. By adding produced\nrewrites as augmentations in training, we improve on German and Japanese\ntext-image retrieval cases studies (up to +3.5 mean recall overall, +4.7 on\nnon-native error cases). We further propose a mechanism to analyze the specific\nobject description differences across datasets, and we offer insights into\ncross-dataset and cross-language generalization.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.14359v1",
    "published_date": "2025-04-19 17:23:12 UTC",
    "updated_date": "2025-04-19 17:23:12 UTC"
  },
  {
    "arxiv_id": "2504.14356v1",
    "title": "Mathematical Programming Models for Exact and Interpretable Formulation of Neural Networks",
    "authors": [
      "Masoud Ataei",
      "Edrin Hasaj",
      "Jacob Gipp",
      "Sepideh Forouzi"
    ],
    "abstract": "This paper presents a unified mixed-integer programming framework for\ntraining sparse and interpretable neural networks. We develop exact\nformulations for both fully connected and convolutional architectures by\nmodeling nonlinearities such as ReLU activations through binary variables and\nencoding structural sparsity via filter- and layer-level pruning constraints.\nThe resulting models integrate parameter learning, architecture selection, and\nstructural regularization within a single optimization problem, yielding\nglobally optimal solutions with respect to a composite objective that balances\nprediction accuracy, weight sparsity, and architectural compactness. The\nmixed-integer programming formulation accommodates piecewise-linear operations,\nincluding max pooling and activation gating, and permits precise enforcement of\nlogic-based or domain-specific constraints. By incorporating considerations of\ninterpretability, sparsity, and verifiability directly into the training\nprocess, the proposed framework bridges a range of research areas including\nexplainable artificial intelligence, symbolic reasoning, and formal\nverification.",
    "categories": [
      "cs.AI",
      "math.OC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.14356v1",
    "published_date": "2025-04-19 16:50:17 UTC",
    "updated_date": "2025-04-19 16:50:17 UTC"
  },
  {
    "arxiv_id": "2504.14350v3",
    "title": "An Empirical Study of LLM Reasoning Ability Under Strict Output Length Constraint",
    "authors": [
      "Yi Sun",
      "Han Wang",
      "Jiaqiang Li",
      "Jiacheng Liu",
      "Xiangyu Li",
      "Hao Wen",
      "Yizhen Yuan",
      "Huiwen Zheng",
      "Yan Liang",
      "Yuanchun Li",
      "Yunxin Liu"
    ],
    "abstract": "Recent work has demonstrated the remarkable potential of Large Language\nModels (LLMs) in test-time scaling. By making models think before answering,\nthey are able to achieve much higher accuracy with extra inference computation.\nHowever, in many real-world scenarios, models are used under time constraints,\nwhere an answer should be given within a certain output length. It is unclear\nwhether and how the reasoning ability of different LLMs remain effective under\nstrict constraints. We take a first look at this problem by conducting an\nin-depth empirical study. Specifically, we test 30 LLMs on common reasoning\ndatasets under a wide range of output length budgets, and we analyze the\ncorrelation between the inference accuracy and various properties including\nmodel type, model size, prompt style, etc. We also consider the mappings\nbetween token budgets and actual on-device latency budgets. The results have\ndemonstrated several interesting findings regarding the budget-aware LLM\nreasoning ability that differ from the unconstrained situation, e.g. the\noptimal choices of either model size or prompt style change under different\nbudgets. These findings offer timely evaluation to this area and practical\nguidance for users to deploy LLMs under real-world latency constraints.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.14350v3",
    "published_date": "2025-04-19 16:32:28 UTC",
    "updated_date": "2025-05-21 09:05:29 UTC"
  },
  {
    "arxiv_id": "2504.14345v1",
    "title": "Integrating LLM-Generated Views into Mean-Variance Optimization Using the Black-Litterman Model",
    "authors": [
      "Youngbin Lee",
      "Yejin Kim",
      "Suin Kim",
      "Yongjae Lee"
    ],
    "abstract": "Portfolio optimization faces challenges due to the sensitivity in traditional\nmean-variance models. The Black-Litterman model mitigates this by integrating\ninvestor views, but defining these views remains difficult. This study explores\nthe integration of large language models (LLMs) generated views into portfolio\noptimization using the Black-Litterman framework. Our method leverages LLMs to\nestimate expected stock returns from historical prices and company metadata,\nincorporating uncertainty through the variance in predictions. We conduct a\nbacktest of the LLM-optimized portfolios from June 2024 to February 2025,\nrebalancing biweekly using the previous two weeks of price data. As baselines,\nwe compare against the S&P 500, an equal-weighted portfolio, and a traditional\nmean-variance optimized portfolio constructed using the same set of stocks.\nEmpirical results suggest that different LLMs exhibit varying levels of\npredictive optimism and confidence stability, which impact portfolio\nperformance. The source code and data are available at\nhttps://github.com/youngandbin/LLM-MVO-BLM.",
    "categories": [
      "q-fin.PM",
      "cs.AI"
    ],
    "primary_category": "q-fin.PM",
    "comment": "Presented at the ICLR 2025 Workshop on Financial AI\n  (https://sites.google.com/view/financialaiiclr25/home)",
    "pdf_url": "http://arxiv.org/pdf/2504.14345v1",
    "published_date": "2025-04-19 16:26:14 UTC",
    "updated_date": "2025-04-19 16:26:14 UTC"
  },
  {
    "arxiv_id": "2504.18560v1",
    "title": "Mind the Language Gap: Automated and Augmented Evaluation of Bias in LLMs for High- and Low-Resource Languages",
    "authors": [
      "Alessio Buscemi",
      "C√©dric Lothritz",
      "Sergio Morales",
      "Marcos Gomez-Vazquez",
      "Robert Claris√≥",
      "Jordi Cabot",
      "German Castignani"
    ],
    "abstract": "Large Language Models (LLMs) have exhibited impressive natural language\nprocessing capabilities but often perpetuate social biases inherent in their\ntraining data. To address this, we introduce MultiLingual Augmented Bias\nTesting (MLA-BiTe), a framework that improves prior bias evaluation methods by\nenabling systematic multilingual bias testing. MLA-BiTe leverages automated\ntranslation and paraphrasing techniques to support comprehensive assessments\nacross diverse linguistic settings. In this study, we evaluate the\neffectiveness of MLA-BiTe by testing four state-of-the-art LLMs in six\nlanguages -- including two low-resource languages -- focusing on seven\nsensitive categories of discrimination.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.18560v1",
    "published_date": "2025-04-19 16:18:22 UTC",
    "updated_date": "2025-04-19 16:18:22 UTC"
  },
  {
    "arxiv_id": "2504.14335v1",
    "title": "Visual Prompting for One-shot Controllable Video Editing without Inversion",
    "authors": [
      "Zhengbo Zhang",
      "Yuxi Zhou",
      "Duo Peng",
      "Joo-Hwee Lim",
      "Zhigang Tu",
      "De Wen Soh",
      "Lin Geng Foo"
    ],
    "abstract": "One-shot controllable video editing (OCVE) is an important yet challenging\ntask, aiming to propagate user edits that are made -- using any image editing\ntool -- on the first frame of a video to all subsequent frames, while ensuring\ncontent consistency between edited frames and source frames. To achieve this,\nprior methods employ DDIM inversion to transform source frames into latent\nnoise, which is then fed into a pre-trained diffusion model, conditioned on the\nuser-edited first frame, to generate the edited video. However, the DDIM\ninversion process accumulates errors, which hinder the latent noise from\naccurately reconstructing the source frames, ultimately compromising content\nconsistency in the generated edited frames. To overcome it, our method\neliminates the need for DDIM inversion by performing OCVE through a novel\nperspective based on visual prompting. Furthermore, inspired by consistency\nmodels that can perform multi-step consistency sampling to generate a sequence\nof content-consistent images, we propose a content consistency sampling (CCS)\nto ensure content consistency between the generated edited frames and the\nsource frames. Moreover, we introduce a temporal-content consistency sampling\n(TCS) based on Stein Variational Gradient Descent to ensure temporal\nconsistency across the edited frames. Extensive experiments validate the\neffectiveness of our approach.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "accepted by cvpr2025",
    "pdf_url": "http://arxiv.org/pdf/2504.14335v1",
    "published_date": "2025-04-19 16:00:47 UTC",
    "updated_date": "2025-04-19 16:00:47 UTC"
  },
  {
    "arxiv_id": "2504.14325v2",
    "title": "FAIRGAME: a Framework for AI Agents Bias Recognition using Game Theory",
    "authors": [
      "Alessio Buscemi",
      "Daniele Proverbio",
      "Alessandro Di Stefano",
      "The Anh Han",
      "German Castignani",
      "Pietro Li√≤"
    ],
    "abstract": "Letting AI agents interact in multi-agent applications adds a layer of\ncomplexity to the interpretability and prediction of AI outcomes, with profound\nimplications for their trustworthy adoption in research and society. Game\ntheory offers powerful models to capture and interpret strategic interaction\namong agents, but requires the support of reproducible, standardized and\nuser-friendly IT frameworks to enable comparison and interpretation of results.\nTo this end, we present FAIRGAME, a Framework for AI Agents Bias Recognition\nusing Game Theory. We describe its implementation and usage, and we employ it\nto uncover biased outcomes in popular games among AI agents, depending on the\nemployed Large Language Model (LLM) and used language, as well as on the\npersonality trait or strategic knowledge of the agents. Overall, FAIRGAME\nallows users to reliably and easily simulate their desired games and scenarios\nand compare the results across simulation campaigns and with game-theoretic\npredictions, enabling the systematic discovery of biases, the anticipation of\nemerging behavior out of strategic interplays, and empowering further research\ninto strategic decision-making using LLM agents.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.14325v2",
    "published_date": "2025-04-19 15:29:04 UTC",
    "updated_date": "2025-04-22 11:56:45 UTC"
  },
  {
    "arxiv_id": "2504.15311v1",
    "title": "RINN: One Sample Radio Frequency Imaging based on Physics Informed Neural Network",
    "authors": [
      "Fei Shang",
      "Haohua Du",
      "Dawei Yan",
      "Panlong Yang",
      "Xiang-Yang Li"
    ],
    "abstract": "Due to its ability to work in non-line-of-sight and low-light environments,\nradio frequency (RF) imaging technology is expected to bring new possibilities\nfor embodied intelligence and multimodal sensing. However, widely used RF\ndevices (such as Wi-Fi) often struggle to provide high-precision\nelectromagnetic measurements and large-scale datasets, hindering the\napplication of RF imaging technology. In this paper, we combine the ideas of\nPINN to design the RINN network, using physical constraints instead of true\nvalue comparison constraints and adapting it with the characteristics of\nubiquitous RF signals, allowing the RINN network to achieve RF imaging using\nonly one sample without phase and with amplitude noise. Our numerical\nevaluation results show that compared with 5 classic algorithms based on phase\ndata for imaging results, RINN's imaging results based on phaseless data are\ngood, with indicators such as RRMSE (0.11) performing similarly well. RINN\nprovides new possibilities for the universal development of radio frequency\nimaging technology.",
    "categories": [
      "eess.IV",
      "cs.AI"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15311v1",
    "published_date": "2025-04-19 15:19:12 UTC",
    "updated_date": "2025-04-19 15:19:12 UTC"
  },
  {
    "arxiv_id": "2504.14320v2",
    "title": "Expanding the Generative AI Design Space through Structured Prompting and Multimodal Interfaces",
    "authors": [
      "Nimisha Karnatak",
      "Adrien Baranes",
      "Rob Marchant",
      "Huinan Zeng",
      "Tr√≠ona Butler",
      "Kristen Olson"
    ],
    "abstract": "Text-based prompting remains the predominant interaction paradigm in\ngenerative AI, yet it often introduces friction for novice users such as small\nbusiness owners (SBOs), who struggle to articulate creative goals in\ndomain-specific contexts like advertising. Through a formative study with six\nSBOs in the United Kingdom, we identify three key challenges: difficulties in\nexpressing brand intuition through prompts, limited opportunities for\nfine-grained adjustment and refinement during and after content generation, and\nthe frequent production of generic content that lacks brand specificity. In\nresponse, we present ACAI (AI Co-Creation for Advertising and Inspiration), a\nmultimodal generative AI tool designed to support novice designers by moving\nbeyond traditional prompt interfaces. ACAI features a structured input system\ncomposed of three panels: Branding, Audience and Goals, and the Inspiration\nBoard. These inputs allow users to convey brand-relevant context and visual\npreferences. This work contributes to HCI research on generative systems by\nshowing how structured interfaces can foreground user-defined context, improve\nalignment, and enhance co-creative control in novice creative workflows.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "Accepted at CHI'25 Workshop on Designing and Developing User\n  Interfaces with AI",
    "pdf_url": "http://arxiv.org/pdf/2504.14320v2",
    "published_date": "2025-04-19 14:57:32 UTC",
    "updated_date": "2025-04-22 17:59:41 UTC"
  },
  {
    "arxiv_id": "2504.14302v1",
    "title": "Learning to Score",
    "authors": [
      "Yogev Kriger",
      "Shai Fine"
    ],
    "abstract": "Common machine learning settings range from supervised tasks, where\naccurately labeled data is accessible, through semi-supervised and\nweakly-supervised tasks, where target labels are scant or noisy, to\nunsupervised tasks where labels are unobtainable. In this paper we study a\nscenario where the target labels are not available but additional related\ninformation is at hand. This information, referred to as Side Information, is\neither correlated with the unknown labels or imposes constraints on the feature\nspace. We formulate the problem as an ensemble of three semantic components:\nrepresentation learning, side information and metric learning. The proposed\nscoring model is advantageous for multiple use-cases. For example, in the\nhealthcare domain it can be used to create a severity score for diseases where\nthe symptoms are known but the criteria for the disease progression are not\nwell defined. We demonstrate the utility of the suggested scoring system on\nwell-known benchmark data-sets and bio-medical patient records.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.14302v1",
    "published_date": "2025-04-19 13:53:38 UTC",
    "updated_date": "2025-04-19 13:53:38 UTC"
  },
  {
    "arxiv_id": "2504.14301v1",
    "title": "Balancing Privacy and Action Performance: A Penalty-Driven Approach to Image Anonymization",
    "authors": [
      "Nazia Aslam",
      "Kamal Nasrollahi"
    ],
    "abstract": "The rapid development of video surveillance systems for object detection,\ntracking, activity recognition, and anomaly detection has revolutionized our\nday-to-day lives while setting alarms for privacy concerns. It isn't easy to\nstrike a balance between visual privacy and action recognition performance in\nmost computer vision models. Is it possible to safeguard privacy without\nsacrificing performance? It poses a formidable challenge, as even minor privacy\nenhancements can lead to substantial performance degradation. To address this\nchallenge, we propose a privacy-preserving image anonymization technique that\noptimizes the anonymizer using penalties from the utility branch, ensuring\nimproved action recognition performance while minimally affecting privacy\nleakage. This approach addresses the trade-off between minimizing privacy\nleakage and maintaining high action performance. The proposed approach is\nprimarily designed to align with the regulatory standards of the EU AI Act and\nGDPR, ensuring the protection of personally identifiable information while\nmaintaining action performance. To the best of our knowledge, we are the first\nto introduce a feature-based penalty scheme that exclusively controls the\naction features, allowing freedom to anonymize private attributes. Extensive\nexperiments were conducted to validate the effectiveness of the proposed\nmethod. The results demonstrate that applying a penalty to anonymizer from\nutility branch enhances action performance while maintaining nearly consistent\nprivacy leakage across different penalty settings.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to CVPRW 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.14301v1",
    "published_date": "2025-04-19 13:52:33 UTC",
    "updated_date": "2025-04-19 13:52:33 UTC"
  },
  {
    "arxiv_id": "2504.14300v2",
    "title": "Learning and Generating Diverse Residential Load Patterns Using GAN with Weakly-Supervised Training and Weight Selection",
    "authors": [
      "Xinyu Liang",
      "Hao Wang"
    ],
    "abstract": "The scarcity of high-quality residential load data can pose obstacles for\ndecarbonizing the residential sector as well as effective grid planning and\noperation. The above challenges have motivated research into generating\nsynthetic load data, but existing methods faced limitations in terms of\nscalability, diversity, and similarity. This paper proposes a Generative\nAdversarial Network-based Synthetic Residential Load Pattern (RLP-GAN)\ngeneration model, a novel weakly-supervised GAN framework, leveraging an\nover-complete autoencoder to capture dependencies within complex and diverse\nload patterns and learn household-level data distribution at scale. We\nincorporate a model weight selection method to address the mode collapse\nproblem and generate load patterns with high diversity. We develop a holistic\nevaluation method to validate the effectiveness of RLP-GAN using real-world\ndata of 417 households. The results demonstrate that RLP-GAN outperforms\nstate-of-the-art models in capturing temporal dependencies and generating load\npatterns with higher similarity to real data. Furthermore, we have publicly\nreleased the RLP-GAN generated synthetic dataset, which comprises one million\nsynthetic residential load pattern profiles.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "12 pages",
    "pdf_url": "http://arxiv.org/pdf/2504.14300v2",
    "published_date": "2025-04-19 13:50:49 UTC",
    "updated_date": "2025-04-25 05:01:08 UTC"
  },
  {
    "arxiv_id": "2504.14298v3",
    "title": "RadioDiff-Inverse: Diffusion Enhanced Bayesian Inverse Estimation for ISAC Radio Map Construction",
    "authors": [
      "Xiucheng Wang",
      "Zhongsheng Fang",
      "Nan Cheng",
      "Ruijin Sun",
      "Zan Li",
      "Xuemin",
      "Shen"
    ],
    "abstract": "Radio maps (RMs) are essential for environment-aware communication and\nsensing, providing location-specific wireless channel information. Existing RM\nconstruction methods often rely on precise environmental data and base station\n(BS) locations, which are not always available in dynamic or privacy-sensitive\nenvironments. While sparse measurement techniques reduce data collection, the\nimpact of noise in sparse data on RM accuracy is not well understood. This\npaper addresses these challenges by formulating RM construction as a Bayesian\ninverse problem under coarse environmental knowledge and noisy sparse\nmeasurements. Although maximum a posteriori (MAP) filtering offers an optimal\nsolution, it requires a precise prior distribution of the RM, which is\ntypically unavailable. To solve this, we propose RadioDiff-Inverse, a\ndiffusion-enhanced Bayesian inverse estimation framework that uses an\nunconditional generative diffusion model to learn the RM prior. This approach\nnot only reconstructs the spatial distribution of wireless channel features but\nalso enables environmental structure perception, such as building outlines, and\nlocation of BS just relay on pathloss, through integrated sensing and\ncommunication (ISAC). Remarkably, RadioDiff-Inverse is training-free,\nleveraging a pre-trained model from Imagenet without task-specific fine-tuning,\nwhich significantly reduces the training cost of using generative large model\nin wireless networks. Experimental results demonstrate that RadioDiff-Inverse\nachieves state-of-the-art performance in accuracy of RM construction and\nenvironmental reconstruction, and robustness against noisy sparse sampling.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "This work has been submitted to the IEEE for possible publication",
    "pdf_url": "http://arxiv.org/pdf/2504.14298v3",
    "published_date": "2025-04-19 13:49:59 UTC",
    "updated_date": "2025-05-21 03:11:40 UTC"
  },
  {
    "arxiv_id": "2504.15310v1",
    "title": "Power Transformer Health Index and Life Span Assessment: A Comprehensive Review of Conventional and Machine Learning based Approaches",
    "authors": [
      "Syeda Tahreem Zahra",
      "Syed Kashif Imdad",
      "Sohail Khan",
      "Sohail Khalid",
      "Nauman Anwar Baig"
    ],
    "abstract": "Power transformers play a critical role within the electrical power system,\nmaking their health assessment and the prediction of their remaining lifespan\nparamount for the purpose of ensuring efficient operation and facilitating\neffective maintenance planning. This paper undertakes a comprehensive\nexamination of existent literature, with a primary focus on both conventional\nand cutting-edge techniques employed within this domain. The merits and\ndemerits of recent methodologies and techniques are subjected to meticulous\nscrutiny and explication. Furthermore, this paper expounds upon intelligent\nfault diagnosis methodologies and delves into the most widely utilized\nintelligent algorithms for the assessment of transformer conditions. Diverse\nArtificial Intelligence (AI) approaches, including Artificial Neural Networks\n(ANN) and Convolutional Neural Network (CNN), Support Vector Machine (SVM),\nRandom Forest (RF), Genetic Algorithm (GA), and Particle Swarm Optimization\n(PSO), are elucidated offering pragmatic solutions for enhancing the\nperformance of transformer fault diagnosis. The amalgamation of multiple AI\nmethodologies and the exploration of timeseries analysis further contribute to\nthe augmentation of diagnostic precision and the early detection of faults in\ntransformers. By furnishing a comprehensive panorama of AI applications in the\nfield of transformer fault diagnosis, this study lays the groundwork for future\nresearch endeavors and the progression of this critical area of study.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15310v1",
    "published_date": "2025-04-19 13:48:05 UTC",
    "updated_date": "2025-04-19 13:48:05 UTC"
  },
  {
    "arxiv_id": "2505.03756v1",
    "title": "Improving the Serving Performance of Multi-LoRA Large Language Models via Efficient LoRA and KV Cache Management",
    "authors": [
      "Hang Zhang",
      "Jiuchen Shi",
      "Yixiao Wang",
      "Quan Chen",
      "Yizhou Shan",
      "Minyi Guo"
    ],
    "abstract": "Multiple Low-Rank Adapters (Multi-LoRAs) are gaining popularity for\ntask-specific Large Language Model (LLM) applications. For multi-LoRA serving,\ncaching hot KV caches and LoRA adapters in high bandwidth memory of\naccelerations can improve inference performance. However, existing Multi-LoRA\ninference systems fail to optimize serving performance like Time-To-First-Toke\n(TTFT), neglecting usage dependencies when caching LoRAs and KVs. We therefore\npropose FASTLIBRA, a Multi-LoRA caching system to optimize the serving\nperformance. FASTLIBRA comprises a dependency-aware cache manager and a\nperformance-driven cache swapper. The cache manager maintains the usage\ndependencies between LoRAs and KV caches during the inference with a unified\ncaching pool. The cache swapper determines the swap-in or out of LoRAs and KV\ncaches based on a unified cost model, when the HBM is idle or busy,\nrespectively. Experimental results show that ELORA reduces the TTFT by 63.4% on\naverage, compared to state-of-the-art works.",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.LG",
      "cs.PF"
    ],
    "primary_category": "cs.AR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.03756v1",
    "published_date": "2025-04-19 13:17:34 UTC",
    "updated_date": "2025-04-19 13:17:34 UTC"
  },
  {
    "arxiv_id": "2504.14282v1",
    "title": "CHAINSFORMER: Numerical Reasoning on Knowledge Graphs from a Chain Perspective",
    "authors": [
      "Ze Zhao",
      "Bin Lu",
      "Xiaoying Gan",
      "Gu Tang",
      "Luoyi Fu",
      "Xinbing Wang"
    ],
    "abstract": "Reasoning over Knowledge Graphs (KGs) plays a pivotal role in knowledge graph\ncompletion or question answering systems, providing richer and more accurate\ntriples and attributes. As numerical attributes become increasingly essential\nin characterizing entities and relations in KGs, the ability to reason over\nthese attributes has gained significant importance. Existing graph-based\nmethods such as Graph Neural Networks (GNNs) and Knowledge Graph Embeddings\n(KGEs), primarily focus on aggregating homogeneous local neighbors and\nimplicitly embedding diverse triples. However, these approaches often fail to\nfully leverage the potential of logical paths within the graph, limiting their\neffectiveness in exploiting the reasoning process. To address these\nlimitations, we propose ChainsFormer, a novel chain-based framework designed to\nsupport numerical reasoning. Chainsformer not only explicitly constructs\nlogical chains but also expands the reasoning depth to multiple hops.\nSpecially, we introduces Relation-Attribute Chains (RA-Chains), a specialized\nlogic chain, to model sequential reasoning patterns. ChainsFormer captures the\nstep-by-step nature of multi-hop reasoning along RA-Chains by employing\nsequential in-context learning. To mitigate the impact of noisy chains, we\npropose a hyperbolic affinity scoring mechanism that selects relevant logic\nchains in a variable-resolution space. Furthermore, ChainsFormer incorporates\nan attention-based numerical reasoner to identify critical reasoning paths,\nenhancing both reasoning accuracy and transparency. Experimental results\ndemonstrate that ChainsFormer significantly outperforms state-of-the-art\nmethods, achieving up to a 20.0% improvement in performance. The\nimplementations are available at\nhttps://github.com/zhaodazhuang2333/ChainsFormer.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted to ICDE 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.14282v1",
    "published_date": "2025-04-19 12:47:44 UTC",
    "updated_date": "2025-04-19 12:47:44 UTC"
  },
  {
    "arxiv_id": "2505.14843v1",
    "title": "Leveraging Generative AI Models to Explore Human Identity",
    "authors": [
      "Yunha Yeo",
      "Daeho Um"
    ],
    "abstract": "This paper attempts to explore human identity by utilizing neural networks in\nan indirect manner. For this exploration, we adopt diffusion models,\nstate-of-the-art AI generative models trained to create human face images. By\nrelating the generated human face to human identity, we establish a\ncorrespondence between the face image generation process of the diffusion model\nand the process of human identity formation. Through experiments with the\ndiffusion model, we observe that changes in its external input result in\nsignificant changes in the generated face image. Based on the correspondence,\nwe indirectly confirm the dependence of human identity on external factors in\nthe process of human identity formation. Furthermore, we introduce\n\\textit{Fluidity of Human Identity}, a video artwork that expresses the fluid\nnature of human identity affected by varying external factors. The video is\navailable at\nhttps://www.behance.net/gallery/219958453/Fluidity-of-Human-Identity?.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to ISEA 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.14843v1",
    "published_date": "2025-04-19 12:35:07 UTC",
    "updated_date": "2025-04-19 12:35:07 UTC"
  },
  {
    "arxiv_id": "2504.14274v1",
    "title": "ProtPainter: Draw or Drag Protein via Topology-guided Diffusion",
    "authors": [
      "Zhengxi Lu",
      "Shizhuo Cheng",
      "Yuru Jiang",
      "Yan Zhang",
      "Min Zhang"
    ],
    "abstract": "Recent advances in protein backbone generation have achieved promising\nresults under structural, functional, or physical constraints. However,\nexisting methods lack the flexibility for precise topology control, limiting\nnavigation of the backbone space. We present ProtPainter, a diffusion-based\napproach for generating protein backbones conditioned on 3D curves. ProtPainter\nfollows a two-stage process: curve-based sketching and sketch-guided backbone\ngeneration. For the first stage, we propose CurveEncoder, which predicts\nsecondary structure annotations from a curve to parametrize sketch generation.\nFor the second stage, the sketch guides the generative process in Denoising\nDiffusion Probabilistic Modeling (DDPM) to generate backbones. During this\nprocess, we further introduce a fusion scheduling scheme, Helix-Gating, to\ncontrol the scaling factors. To evaluate, we propose the first benchmark for\ntopology-conditioned protein generation, introducing Protein Restoration Task\nand a new metric, self-consistency Topology Fitness (scTF). Experiments\ndemonstrate ProtPainter's ability to generate topology-fit (scTF > 0.8) and\ndesignable (scTM > 0.5) backbones, with drawing and dragging tasks showcasing\nits flexibility and versatility.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Published as a conference paper at ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.14274v1",
    "published_date": "2025-04-19 11:59:48 UTC",
    "updated_date": "2025-04-19 11:59:48 UTC"
  },
  {
    "arxiv_id": "2504.14259v1",
    "title": "Experience-based Refinement of Task Planning Knowledge in Autonomous Robots",
    "authors": [
      "Hadeel Jazzaa",
      "Thomas McCluskey",
      "David Peebles"
    ],
    "abstract": "The requirement for autonomous robots to exhibit higher-level cognitive\nskills by planning and adapting in an ever-changing environment is indeed a\ngreat challenge for the AI community. Progress has been made in the automated\nplanning community on refinement and repair of an agent's symbolic knowledge to\ndo task planning in an incomplete or changing environmental model, but these\nadvances up to now have not been transferred to real physical robots. This\npaper demonstrates how a physical robot can be capable of adapting its symbolic\nknowledge of the environment, by using experiences in robot action execution to\ndrive knowledge refinement and hence to improve the success rate of the task\nplans the robot creates. To implement more robust planning systems, we propose\na method for refining domain knowledge to improve the knowledge on which\nintelligent robot behavior is based. This architecture has been implemented and\nevaluated using a NAO robot. The refined knowledge leads to the future\nsynthesis of task plans which demonstrate decreasing rates of failure over time\nas faulty knowledge is removed or adjusted.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.14259v1",
    "published_date": "2025-04-19 10:43:33 UTC",
    "updated_date": "2025-04-19 10:43:33 UTC"
  },
  {
    "arxiv_id": "2504.14248v1",
    "title": "Rethinking Traffic Flow Forecasting: From Transition to Generatation",
    "authors": [
      "Li Shijiao",
      "Ma Zhipeng",
      "He Huajun",
      "Chen Haiyue"
    ],
    "abstract": "Traffic flow prediction plays an important role in Intelligent Transportation\nSystems in traffic management and urban planning. There have been extensive\nsuccessful works in this area. However, these approaches focus only on\nmodelling the flow transition and ignore the flow generation process, which\nmanifests itself in two ways: (i) The models are based on Markovian\nassumptions, ignoring the multi-periodicity of the flow generation in nodes.\n(ii) The same structure is designed to encode both the transition and\ngeneration processes, ignoring the differences between them. To address these\nproblems, we propose an Effective Multi-Branch Similarity Transformer for\nTraffic Flow Prediction, namely EMBSFormer. Through data analysis, we find that\nthe factors affecting traffic flow include node-level traffic generation and\ngraph-level traffic transition, which describe the multi-periodicity and\ninteraction pattern of nodes, respectively. Specifically, to capture traffic\ngeneration patterns, we propose a similarity analysis module that supports\nmulti-branch encoding to dynamically expand significant cycles. For traffic\ntransition, we employ a temporal and spatial self-attention mechanism to\nmaintain global node interactions, and use GNN and time conv to model local\nnode interactions, respectively. Model performance is evaluated on three\nreal-world datasets on both long-term and short-term prediction tasks.\nExperimental results show that EMBSFormer outperforms baselines on both tasks.\nMoreover, compared to models based on flow transition modelling (e.g. GMAN,\n513k), the variant of EMBSFormer(93K) only uses 18\\% of the parameters,\nachieving the same performance.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.14248v1",
    "published_date": "2025-04-19 09:52:39 UTC",
    "updated_date": "2025-04-19 09:52:39 UTC"
  },
  {
    "arxiv_id": "2504.14241v1",
    "title": "A Knowledge-Informed Deep Learning Paradigm for Generalizable and Stability-Optimized Car-Following Models",
    "authors": [
      "Chengming Wang",
      "Dongyao Jia",
      "Wei Wang",
      "Dong Ngoduy",
      "Bei Peng",
      "Jianping Wang"
    ],
    "abstract": "Car-following models (CFMs) are fundamental to traffic flow analysis and\nautonomous driving. Although calibrated physics-based and trained data-driven\nCFMs can replicate human driving behavior, their reliance on specific datasets\nlimits generalization across diverse scenarios and reduces reliability in\nreal-world deployment. Moreover, these models typically focus on behavioral\nfidelity and do not support the explicit optimization of local and string\nstability, which are increasingly important for the safe and efficient\noperation of autonomous vehicles (AVs). To address these limitations, we\npropose a Knowledge-Informed Deep Learning (KIDL) paradigm that distills the\ngeneralization capabilities of pre-trained Large Language Models (LLMs) into a\nlightweight and stability-aware neural architecture. LLMs are used to extract\nfundamental car-following knowledge beyond dataset-specific patterns, and this\nknowledge is transferred to a reliable, tractable, and computationally\nefficient model through knowledge distillation. KIDL also incorporates\nstability constraints directly into its training objective, ensuring that the\nresulting model not only emulates human-like behavior but also satisfies the\nlocal and string stability requirements essential for real-world AV deployment.\nWe evaluate KIDL on the real-world NGSIM and HighD datasets, comparing its\nperformance with representative physics-based, data-driven, and hybrid CFMs.\nBoth empirical and theoretical results consistently demonstrate KIDL's superior\nbehavioral generalization and traffic flow stability, offering a robust and\nscalable solution for next-generation traffic systems.",
    "categories": [
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.14241v1",
    "published_date": "2025-04-19 09:33:02 UTC",
    "updated_date": "2025-04-19 09:33:02 UTC"
  },
  {
    "arxiv_id": "2504.14239v1",
    "title": "InfiGUI-R1: Advancing Multimodal GUI Agents from Reactive Actors to Deliberative Reasoners",
    "authors": [
      "Yuhang Liu",
      "Pengxiang Li",
      "Congkai Xie",
      "Xavier Hu",
      "Xiaotian Han",
      "Shengyu Zhang",
      "Hongxia Yang",
      "Fei Wu"
    ],
    "abstract": "Multimodal Large Language Models (MLLMs) have powered Graphical User\nInterface (GUI) Agents, showing promise in automating tasks on computing\ndevices. Recent works have begun exploring reasoning in GUI tasks with\nencouraging results. However, many current approaches rely on manually designed\nreasoning templates, which may result in reasoning that is not sufficiently\nrobust and adaptive for complex GUI environments. Meanwhile, some existing\nagents continue to operate as Reactive Actors, relying primarily on implicit\nreasoning that may lack sufficient depth for GUI tasks demanding planning and\nerror recovery. We argue that advancing these agents requires a shift from\nreactive acting towards acting based on deliberate reasoning. To facilitate\nthis transformation, we introduce InfiGUI-R1, an MLLM-based GUI agent developed\nthrough our Actor2Reasoner framework, a reasoning-centric, two-stage training\napproach designed to progressively evolve agents from Reactive Actors to\nDeliberative Reasoners. The first stage, Reasoning Injection, focuses on\nestablishing a basic reasoner. We employ Spatial Reasoning Distillation to\ntransfer cross-modal spatial reasoning capabilities from teacher models to\nMLLMs through trajectories with explicit reasoning steps, enabling models to\nintegrate GUI visual-spatial information with logical reasoning before action\ngeneration. The second stage, Deliberation Enhancement, refines the basic\nreasoner into a deliberative one using Reinforcement Learning. This stage\nintroduces two approaches: Sub-goal Guidance, which rewards models for\ngenerating accurate intermediate sub-goals, and Error Recovery Scenario\nConstruction, which creates failure-and-recovery training scenarios from\nidentified prone-to-error steps. Experimental results show InfiGUI-R1 achieves\nstrong performance in GUI grounding and trajectory tasks. Resources at\nhttps://github.com/Reallm-Labs/InfiGUI-R1.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "10 pages, 3 figures, work in progress",
    "pdf_url": "http://arxiv.org/pdf/2504.14239v1",
    "published_date": "2025-04-19 09:25:55 UTC",
    "updated_date": "2025-04-19 09:25:55 UTC"
  },
  {
    "arxiv_id": "2504.21013v1",
    "title": "Analyzing Feedback Mechanisms in AI-Generated MCQs: Insights into Readability, Lexical Properties, and Levels of Challenge",
    "authors": [
      "Antoun Yaacoub",
      "Zainab Assaghir",
      "Lionel Prevost",
      "J√©r√¥me Da-Rugna"
    ],
    "abstract": "Artificial Intelligence (AI)-generated feedback in educational settings has\ngarnered considerable attention due to its potential to enhance learning\noutcomes. However, a comprehensive understanding of the linguistic\ncharacteristics of AI-generated feedback, including readability, lexical\nrichness, and adaptability across varying challenge levels, remains limited.\nThis study delves into the linguistic and structural attributes of feedback\ngenerated by Google's Gemini 1.5-flash text model for computer science\nmultiple-choice questions (MCQs). A dataset of over 1,200 MCQs was analyzed,\nconsidering three difficulty levels (easy, medium, hard) and three feedback\ntones (supportive, neutral, challenging). Key linguistic metrics, such as\nlength, readability scores (Flesch-Kincaid Grade Level), vocabulary richness,\nand lexical density, were computed and examined. A fine-tuned RoBERTa-based\nmulti-task learning (MTL) model was trained to predict these linguistic\nproperties, achieving a Mean Absolute Error (MAE) of 2.0 for readability and\n0.03 for vocabulary richness. The findings reveal significant interaction\neffects between feedback tone and question difficulty, demonstrating the\ndynamic adaptation of AI-generated feedback within diverse educational\ncontexts. These insights contribute to the development of more personalized and\neffective AI-driven feedback mechanisms, highlighting the potential for\nimproved learning outcomes while underscoring the importance of ethical\nconsiderations in their design and deployment.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "This paper will be presented in the 9th Int. Conf. on Computer,\n  Software and Modeling (ICCSM 2025), Roma, Italy, 2025, July 3-5",
    "pdf_url": "http://arxiv.org/pdf/2504.21013v1",
    "published_date": "2025-04-19 09:20:52 UTC",
    "updated_date": "2025-04-19 09:20:52 UTC"
  },
  {
    "arxiv_id": "2504.14232v1",
    "title": "Assessing AI-Generated Questions' Alignment with Cognitive Frameworks in Educational Assessment",
    "authors": [
      "Antoun Yaacoub",
      "J√©r√¥me Da-Rugna",
      "Zainab Assaghir"
    ],
    "abstract": "This study evaluates the integration of Bloom's Taxonomy into OneClickQuiz,\nan Artificial Intelligence (AI) driven plugin for automating Multiple-Choice\nQuestion (MCQ) generation in Moodle. Bloom's Taxonomy provides a structured\nframework for categorizing educational objectives into hierarchical cognitive\nlevels. Our research investigates whether incorporating this taxonomy can\nimprove the alignment of AI-generated questions with specific cognitive\nobjectives. We developed a dataset of 3691 questions categorized according to\nBloom's levels and employed various classification models-Multinomial Logistic\nRegression, Naive Bayes, Linear Support Vector Classification (SVC), and a\nTransformer-based model (DistilBERT)-to evaluate their effectiveness in\ncategorizing questions. Our results indicate that higher Bloom's levels\ngenerally correlate with increased question length, Flesch-Kincaid Grade Level\n(FKGL), and Lexical Density (LD), reflecting the increased complexity of higher\ncognitive demands. Multinomial Logistic Regression showed varying accuracy\nacross Bloom's levels, performing best for \"Knowledge\" and less accurately for\nhigher-order levels. Merging higher-level categories improved accuracy for\ncomplex cognitive tasks. Naive Bayes and Linear SVC also demonstrated effective\nclassification for lower levels but struggled with higher-order tasks.\nDistilBERT achieved the highest performance, significantly improving\nclassification of both lower and higher-order cognitive levels, achieving an\noverall validation accuracy of 91%. This study highlights the potential of\nintegrating Bloom's Taxonomy into AI-driven assessment tools and underscores\nthe advantages of advanced models like DistilBERT for enhancing educational\ncontent generation.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "This paper was presented in the 17th Int. Conf. on Computer Science\n  and Information Technology (ICCSIT 2024), Dubai, United Arab Emirates, 2024,\n  Oct. 23-25. IT's now in production to be published in the International\n  Journal of Computer Theory and Engineering",
    "pdf_url": "http://arxiv.org/pdf/2504.14232v1",
    "published_date": "2025-04-19 09:03:39 UTC",
    "updated_date": "2025-04-19 09:03:39 UTC"
  },
  {
    "arxiv_id": "2504.14223v1",
    "title": "SimplifyMyText: An LLM-Based System for Inclusive Plain Language Text Simplification",
    "authors": [
      "Michael F√§rber",
      "Parisa Aghdam",
      "Kyuri Im",
      "Mario Tawfelis",
      "Hardik Ghoshal"
    ],
    "abstract": "Text simplification is essential for making complex content accessible to\ndiverse audiences who face comprehension challenges. Yet, the limited\navailability of simplified materials creates significant barriers to personal\nand professional growth and hinders social inclusion. Although researchers have\nexplored various methods for automatic text simplification, none fully leverage\nlarge language models (LLMs) to offer tailored customization for different\ntarget groups and varying levels of simplicity. Moreover, despite its proven\nbenefits for both consumers and organizations, the well-established practice of\nplain language remains underutilized. In this paper, we\nhttps://simplifymytext.org, the first system designed to produce plain language\ncontent from multiple input formats, including typed text and file uploads,\nwith flexible customization options for diverse audiences. We employ GPT-4 and\nLlama-3 and evaluate outputs across multiple metrics. Overall, our work\ncontributes to research on automatic text simplification and highlights the\nimportance of tailored communication in promoting inclusivity.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "accepted at ECIR 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.14223v1",
    "published_date": "2025-04-19 08:07:53 UTC",
    "updated_date": "2025-04-19 08:07:53 UTC"
  },
  {
    "arxiv_id": "2504.14209v2",
    "title": "Pets: General Pattern Assisted Architecture For Time Series Analysis",
    "authors": [
      "Xiangkai Ma",
      "Xiaobin Hong",
      "Wenzhong Li",
      "Sanglu Lu"
    ],
    "abstract": "Time series analysis has found widespread applications in areas such as\nweather forecasting, anomaly detection, and healthcare. However, real-world\nsequential data often exhibit a superimposed state of various fluctuation\npatterns, including hourly, daily, and monthly frequencies. Traditional\ndecomposition techniques struggle to effectively disentangle these multiple\nfluctuation patterns from the seasonal components, making time series analysis\nchallenging. Surpassing the existing multi-period decoupling paradigms, this\npaper introduces a novel perspective based on energy distribution within the\ntemporal-spectrum space. By adaptively quantifying observed sequences into\ncontinuous frequency band intervals, the proposed approach reconstructs\nfluctuation patterns across diverse periods without relying on domain-specific\nprior knowledge. Building upon this innovative strategy, we propose Pets, an\nenhanced architecture that is adaptable to arbitrary model structures. Pets\nintegrates a Fluctuation Pattern Assisted (FPA) module and a Context-Guided\nMixture of Predictors (MoP). The FPA module facilitates information fusion\namong diverse fluctuation patterns by capturing their dependencies and\nprogressively modeling these patterns as latent representations at each layer.\nMeanwhile, the MoP module leverages these compound pattern representations to\nguide and regulate the reconstruction of distinct fluctuations hierarchically.\nPets achieves state-of-the-art performance across various tasks, including\nforecasting, imputation, anomaly detection, and classification, while\ndemonstrating strong generalization and robustness.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.14209v2",
    "published_date": "2025-04-19 07:12:57 UTC",
    "updated_date": "2025-04-25 04:23:48 UTC"
  },
  {
    "arxiv_id": "2504.14206v1",
    "title": "Decomposition-based multi-scale transformer framework for time series anomaly detection",
    "authors": [
      "Wenxin Zhang",
      "Cuicui Luo"
    ],
    "abstract": "Time series anomaly detection is crucial for maintaining stable systems.\nExisting methods face two main challenges. First, it is difficult to directly\nmodel the dependencies of diverse and complex patterns within the sequences.\nSecond, many methods that optimize parameters using mean squared error struggle\nwith noise in the time series, leading to performance deterioration. To address\nthese challenges, we propose a transformer-based framework built on\ndecomposition (TransDe) for multivariate time series anomaly detection. The key\nidea is to combine the strengths of time series decomposition and transformers\nto effectively learn the complex patterns in normal time series data. A\nmulti-scale patch-based transformer architecture is proposed to exploit the\nrepresentative dependencies of each decomposed component of the time series.\nFurthermore, a contrastive learn paradigm based on patch operation is proposed,\nwhich leverages KL divergence to align the positive pairs, namely the pure\nrepresentations of normal patterns between different patch-level views. A novel\nasynchronous loss function with a stop-gradient strategy is further introduced\nto enhance the performance of TransDe effectively. It can avoid time-consuming\nand labor-intensive computation costs in the optimization process. Extensive\nexperiments on five public datasets are conducted and TransDe shows superiority\ncompared with twelve baselines in terms of F1 score. Our code is available at\nhttps://github.com/shaieesss/TransDe.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.14206v1",
    "published_date": "2025-04-19 06:47:38 UTC",
    "updated_date": "2025-04-19 06:47:38 UTC"
  },
  {
    "arxiv_id": "2504.14205v2",
    "title": "Dual-channel Heterophilic Message Passing for Graph Fraud Detection",
    "authors": [
      "Wenxin Zhang",
      "Jingxing Zhong",
      "Guangzhen Yao",
      "Renda Han",
      "Xiaojian Lin",
      "Zeyu Zhang",
      "Cuicui Luo"
    ],
    "abstract": "Fraudulent activities have significantly increased across various domains,\nsuch as e-commerce, online review platforms, and social networks, making fraud\ndetection a critical task. Spatial Graph Neural Networks (GNNs) have been\nsuccessfully applied to fraud detection tasks due to their strong inductive\nlearning capabilities. However, existing spatial GNN-based methods often\nenhance the graph structure by excluding heterophilic neighbors during message\npassing to align with the homophilic bias of GNNs. Unfortunately, this approach\ncan disrupt the original graph topology and increase uncertainty in\npredictions. To address these limitations, this paper proposes a novel\nframework, Dual-channel Heterophilic Message Passing (DHMP), for fraud\ndetection. DHMP leverages a heterophily separation module to divide the graph\ninto homophilic and heterophilic subgraphs, mitigating the low-pass inductive\nbias of traditional GNNs. It then applies shared weights to capture signals at\ndifferent frequencies independently and incorporates a customized sampling\nstrategy for training. This allows nodes to adaptively balance the\ncontributions of various signals based on their labels. Extensive experiments\non three real-world datasets demonstrate that DHMP outperforms existing\nmethods, highlighting the importance of separating signals with different\nfrequencies for improved fraud detection. The code is available at\nhttps://github.com/shaieesss/DHMP.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.14205v2",
    "published_date": "2025-04-19 06:41:24 UTC",
    "updated_date": "2025-04-26 08:03:12 UTC"
  },
  {
    "arxiv_id": "2504.14204v2",
    "title": "DConAD: A Differencing-based Contrastive Representation Learning Framework for Time Series Anomaly Detection",
    "authors": [
      "Wenxin Zhang",
      "Xiaojian Lin",
      "Wenjun Yu",
      "Guangzhen Yao",
      "jingxiang Zhong",
      "Yu Li",
      "Renda Han",
      "Songcheng Xu",
      "Hao Shi",
      "Cuicui Luo"
    ],
    "abstract": "Time series anomaly detection holds notable importance for risk\nidentification and fault detection across diverse application domains.\nUnsupervised learning methods have become popular because they have no\nrequirement for labels. However, due to the challenges posed by the\nmultiplicity of abnormal patterns, the sparsity of anomalies, and the growth of\ndata scale and complexity, these methods often fail to capture robust and\nrepresentative dependencies within the time series for identifying anomalies.\nTo enhance the ability of models to capture normal patterns of time series and\navoid the retrogression of modeling ability triggered by the dependencies on\nhigh-quality prior knowledge, we propose a differencing-based contrastive\nrepresentation learning framework for time series anomaly detection (DConAD).\nSpecifically, DConAD generates differential data to provide additional\ninformation about time series and utilizes transformer-based architecture to\ncapture spatiotemporal dependencies, which enhances the robustness of unbiased\nrepresentation learning ability. Furthermore, DConAD implements a novel KL\ndivergence-based contrastive learning paradigm that only uses positive samples\nto avoid deviation from reconstruction and deploys the stop-gradient strategy\nto compel convergence. Extensive experiments on five public datasets show the\nsuperiority and effectiveness of DConAD compared with nine baselines. The code\nis available at https://github.com/shaieesss/DConAD.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.14204v2",
    "published_date": "2025-04-19 06:35:06 UTC",
    "updated_date": "2025-05-02 10:25:23 UTC"
  },
  {
    "arxiv_id": "2504.14202v3",
    "title": "Learning Joint ID-Textual Representation for ID-Preserving Image Synthesis",
    "authors": [
      "Zichuan Liu",
      "Liming Jiang",
      "Qing Yan",
      "Yumin Jia",
      "Hao Kang",
      "Xin Lu"
    ],
    "abstract": "We propose a novel framework for ID-preserving generation using a multi-modal\nencoding strategy rather than injecting identity features via adapters into\npre-trained models. Our method treats identity and text as a unified\nconditioning input. To achieve this, we introduce FaceCLIP, a multi-modal\nencoder that learns a joint embedding space for both identity and textual\nsemantics. Given a reference face and a text prompt, FaceCLIP produces a\nunified representation that encodes both identity and text, which conditions a\nbase diffusion model to generate images that are identity-consistent and\ntext-aligned. We also present a multi-modal alignment algorithm to train\nFaceCLIP, using a loss that aligns its joint representation with face, text,\nand image embedding spaces. We then build FaceCLIP-SDXL, an ID-preserving image\nsynthesis pipeline by integrating FaceCLIP with Stable Diffusion XL (SDXL).\nCompared to prior methods, FaceCLIP-SDXL enables photorealistic portrait\ngeneration with better identity preservation and textual relevance. Extensive\nexperiments demonstrate its quantitative and qualitative superiority.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.14202v3",
    "published_date": "2025-04-19 06:31:07 UTC",
    "updated_date": "2025-05-21 19:56:33 UTC"
  },
  {
    "arxiv_id": "2504.14200v1",
    "title": "Enhancing Multimodal In-Context Learning for Image Classification through Coreset Optimization",
    "authors": [
      "Huiyi Chen",
      "Jiawei Peng",
      "Kaihua Tang",
      "Xin Geng",
      "Xu Yang"
    ],
    "abstract": "In-context learning (ICL) enables Large Vision-Language Models (LVLMs) to\nadapt to new tasks without parameter updates, using a few demonstrations from a\nlarge support set. However, selecting informative demonstrations leads to high\ncomputational and memory costs. While some methods explore selecting a small\nand representative coreset in the text classification, evaluating all support\nset samples remains costly, and discarded samples lead to unnecessary\ninformation loss. These methods may also be less effective for image\nclassification due to differences in feature spaces. Given these limitations,\nwe propose Key-based Coreset Optimization (KeCO), a novel framework that\nleverages untapped data to construct a compact and informative coreset. We\nintroduce visual features as keys within the coreset, which serve as the anchor\nfor identifying samples to be updated through different selection strategies.\nBy leveraging untapped samples from the support set, we update the keys of\nselected coreset samples, enabling the randomly initialized coreset to evolve\ninto a more informative coreset under low computational cost. Through extensive\nexperiments on coarse-grained and fine-grained image classification benchmarks,\nwe demonstrate that KeCO effectively enhances ICL performance for image\nclassification task, achieving an average improvement of more than 20\\%.\nNotably, we evaluate KeCO under a simulated online scenario, and the strong\nperformance in this scenario highlights the practical value of our framework\nfor resource-constrained real-world scenarios.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "11 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.14200v1",
    "published_date": "2025-04-19 06:26:23 UTC",
    "updated_date": "2025-04-19 06:26:23 UTC"
  },
  {
    "arxiv_id": "2504.14191v2",
    "title": "AI Idea Bench 2025: AI Research Idea Generation Benchmark",
    "authors": [
      "Yansheng Qiu",
      "Haoquan Zhang",
      "Zhaopan Xu",
      "Ming Li",
      "Diping Song",
      "Zheng Wang",
      "Kaipeng Zhang"
    ],
    "abstract": "Large-scale Language Models (LLMs) have revolutionized human-AI interaction\nand achieved significant success in the generation of novel ideas. However,\ncurrent assessments of idea generation overlook crucial factors such as\nknowledge leakage in LLMs, the absence of open-ended benchmarks with grounded\ntruth, and the limited scope of feasibility analysis constrained by prompt\ndesign. These limitations hinder the potential of uncovering groundbreaking\nresearch ideas. In this paper, we present AI Idea Bench 2025, a framework\ndesigned to quantitatively evaluate and compare the ideas generated by LLMs\nwithin the domain of AI research from diverse perspectives. The framework\ncomprises a comprehensive dataset of 3,495 AI papers and their associated\ninspired works, along with a robust evaluation methodology. This evaluation\nsystem gauges idea quality in two dimensions: alignment with the ground-truth\ncontent of the original papers and judgment based on general reference\nmaterial. AI Idea Bench 2025's benchmarking system stands to be an invaluable\nresource for assessing and comparing idea-generation techniques, thereby\nfacilitating the automation of scientific discovery.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.14191v2",
    "published_date": "2025-04-19 05:35:45 UTC",
    "updated_date": "2025-05-16 11:37:51 UTC"
  },
  {
    "arxiv_id": "2504.16120v1",
    "title": "A Data-Centric Approach for Safe and Secure Large Language Models against Threatening and Toxic Content",
    "authors": [
      "Chaima Njeh",
      "Ha√Øfa Nakouri",
      "Fehmi Jaafar"
    ],
    "abstract": "Large Language Models (LLM) have made remarkable progress, but concerns about\npotential biases and harmful content persist. To address these apprehensions,\nwe introduce a practical solution for ensuring LLM's safe and ethical use. Our\nnovel approach focuses on a post-generation correction mechanism, the\nBART-Corrective Model, which adjusts generated content to ensure safety and\nsecurity. Unlike relying solely on model fine-tuning or prompt engineering, our\nmethod provides a robust data-centric alternative for mitigating harmful\ncontent. We demonstrate the effectiveness of our approach through experiments\non multiple toxic datasets, which show a significant reduction in mean toxicity\nand jail-breaking scores after integration. Specifically, our results show a\nreduction of 15% and 21% in mean toxicity and jail-breaking scores with GPT-4,\na substantial reduction of 28% and 5% with PaLM2, a reduction of approximately\n26% and 23% with Mistral-7B, and a reduction of 11.1% and 19% with Gemma-2b-it.\nThese results demonstrate the potential of our approach to improve the safety\nand security of LLM, making them more suitable for real-world applications.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "This paper is under revision in the International Journal of\n  Information Security",
    "pdf_url": "http://arxiv.org/pdf/2504.16120v1",
    "published_date": "2025-04-19 04:57:05 UTC",
    "updated_date": "2025-04-19 04:57:05 UTC"
  },
  {
    "arxiv_id": "2504.14177v1",
    "title": "Direct Advantage Regression: Aligning LLMs with Online AI Reward",
    "authors": [
      "Li He",
      "He Zhao",
      "Stephen Wan",
      "Dadong Wang",
      "Lina Yao",
      "Tongliang Liu"
    ],
    "abstract": "Online AI Feedback (OAIF) presents a promising alternative to Reinforcement\nLearning from Human Feedback (RLHF) by utilizing online AI preference in\naligning language models (LLMs). However, the straightforward replacement of\nhumans with AI deprives LLMs from learning more fine-grained AI supervision\nbeyond binary signals. In this paper, we propose Direct Advantage Regression\n(DAR), a simple alignment algorithm using online AI reward to optimize policy\nimprovement through weighted supervised fine-tuning. As an RL-free approach,\nDAR maintains theoretical consistency with online RLHF pipelines while\nsignificantly reducing implementation complexity and improving learning\nefficiency. Our empirical results underscore that AI reward is a better form of\nAI supervision consistently achieving higher human-AI agreement as opposed to\nAI preference. Additionally, evaluations using GPT-4-Turbo and MT-bench show\nthat DAR outperforms both OAIF and online RLHF baselines.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.14177v1",
    "published_date": "2025-04-19 04:44:32 UTC",
    "updated_date": "2025-04-19 04:44:32 UTC"
  },
  {
    "arxiv_id": "2504.14174v1",
    "title": "A Physics-guided Multimodal Transformer Path to Weather and Climate Sciences",
    "authors": [
      "Jing Han",
      "Hanting Chen",
      "Kai Han",
      "Xiaomeng Huang",
      "Yongyun Hu",
      "Wenjun Xu",
      "Dacheng Tao",
      "Ping Zhang"
    ],
    "abstract": "With the rapid development of machine learning in recent years, many problems\nin meteorology can now be addressed using AI models. In particular, data-driven\nalgorithms have significantly improved accuracy compared to traditional\nmethods. Meteorological data is often transformed into 2D images or 3D videos,\nwhich are then fed into AI models for learning. Additionally, these models\noften incorporate physical signals, such as temperature, pressure, and wind\nspeed, to further enhance accuracy and interpretability. In this paper, we\nreview several representative AI + Weather/Climate algorithms and propose a new\nparadigm where observational data from different perspectives, each with\ndistinct physical meanings, are treated as multimodal data and integrated via\ntransformers. Furthermore, key weather and climate knowledge can be\nincorporated through regularization techniques to further strengthen the\nmodel's capabilities. This new paradigm is versatile and can address a variety\nof tasks, offering strong generalizability. We also discuss future directions\nfor improving model accuracy and interpretability.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Perspective article",
    "pdf_url": "http://arxiv.org/pdf/2504.14174v1",
    "published_date": "2025-04-19 04:31:35 UTC",
    "updated_date": "2025-04-19 04:31:35 UTC"
  },
  {
    "arxiv_id": "2504.14171v1",
    "title": "Adaptation Method for Misinformation Identification",
    "authors": [
      "Yangping Chen",
      "Weijie Shi",
      "Mengze Li",
      "Yue Cui",
      "Hao Chen",
      "Jia Zhu",
      "Jiajie Xu"
    ],
    "abstract": "Multimodal fake news detection plays a crucial role in combating online\nmisinformation. Unfortunately, effective detection methods rely on annotated\nlabels and encounter significant performance degradation when domain shifts\nexist between training (source) and test (target) data. To address the\nproblems, we propose ADOSE, an Active Domain Adaptation (ADA) framework for\nmultimodal fake news detection which actively annotates a small subset of\ntarget samples to improve detection performance. To identify various deceptive\npatterns in cross-domain settings, we design multiple expert classifiers to\nlearn dependencies across different modalities. These classifiers specifically\ntarget the distinct deception patterns exhibited in fake news, where two\nunimodal classifiers capture knowledge errors within individual modalities\nwhile one cross-modal classifier identifies semantic inconsistencies between\ntext and images. To reduce annotation costs from the target domain, we propose\na least-disagree uncertainty selector with a diversity calculator for selecting\nthe most informative samples. The selector leverages prediction disagreement\nbefore and after perturbations by multiple classifiers as an indicator of\nuncertain samples, whose deceptive patterns deviate most from source domains.\nIt further incorporates diversity scores derived from multi-view features to\nensure the chosen samples achieve maximal coverage of target domain features.\nThe extensive experiments on multiple datasets show that ADOSE outperforms\nexisting ADA methods by 2.72\\% $\\sim$ 14.02\\%, indicating the superiority of\nour model.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.14171v1",
    "published_date": "2025-04-19 04:18:32 UTC",
    "updated_date": "2025-04-19 04:18:32 UTC"
  },
  {
    "arxiv_id": "2504.14156v1",
    "title": "Breaking the Diffraction Barrier for Passive Sources: Parameter-Decoupled Superresolution Assisted by Physics-Informed Machine Learning",
    "authors": [
      "Abdelali Sajia",
      "Bilal Benzimoun",
      "Pawan Khatiwada",
      "Guogan Zhao",
      "Xiao-Feng Qian"
    ],
    "abstract": "We present a parameter-decoupled superresolution framework for estimating\nsub-wavelength separations of passive two-point sources without requiring prior\nknowledge or control of the source. Our theoretical foundation circumvents the\nneed to estimate multiple challenging parameters such as partial coherence,\nbrightness imbalance, random relative phase, and photon statistics. A\nphysics-informed machine learning (ML) model (trained with a standard desktop\nworkstation), synergistically integrating this theory, further addresses\npractical imperfections including background noise, photon loss, and\ncentroid/orientation misalignment. The integrated parameter-decoupling\nsuperresolution method achieves resolution 14 and more times below the\ndiffraction limit (corresponding to ~ 13.5 nm in optical microscopy) on\nexperimentally generated realistic images with >82% fidelity, performance\nrivaling state-of-the-art techniques for actively controllable sources.\nCritically, our method's robustness against source parameter variability and\nsource-independent noises enables potential applications in realistic scenarios\nwhere source control is infeasible, such as astrophysical imaging, live-cell\nmicroscopy, and quantum metrology. This work bridges a critical gap between\ntheoretical superresolution limits and practical implementations for passive\nsystems.",
    "categories": [
      "physics.optics",
      "cs.AI",
      "quant-ph"
    ],
    "primary_category": "physics.optics",
    "comment": "12 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.14156v1",
    "published_date": "2025-04-19 03:03:42 UTC",
    "updated_date": "2025-04-19 03:03:42 UTC"
  },
  {
    "arxiv_id": "2504.14154v1",
    "title": "SConU: Selective Conformal Uncertainty in Large Language Models",
    "authors": [
      "Zhiyuan Wang",
      "Qingni Wang",
      "Yue Zhang",
      "Tianlong Chen",
      "Xiaofeng Zhu",
      "Xiaoshuang Shi",
      "Kaidi Xu"
    ],
    "abstract": "As large language models are increasingly utilized in real-world\napplications, guarantees of task-specific metrics are essential for their\nreliable deployment. Previous studies have introduced various criteria of\nconformal uncertainty grounded in split conformal prediction, which offer\nuser-specified correctness coverage. However, existing frameworks often fail to\nidentify uncertainty data outliers that violate the exchangeability assumption,\nleading to unbounded miscoverage rates and unactionable prediction sets. In\nthis paper, we propose a novel approach termed Selective Conformal Uncertainty\n(SConU), which, for the first time, implements significance tests, by\ndeveloping two conformal p-values that are instrumental in determining whether\na given sample deviates from the uncertainty distribution of the calibration\nset at a specific manageable risk level. Our approach not only facilitates\nrigorous management of miscoverage rates across both single-domain and\ninterdisciplinary contexts, but also enhances the efficiency of predictions.\nFurthermore, we comprehensively analyze the components of the conformal\nprocedures, aiming to approximate conditional coverage, particularly in\nhigh-stakes question-answering tasks.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.14154v1",
    "published_date": "2025-04-19 03:01:45 UTC",
    "updated_date": "2025-04-19 03:01:45 UTC"
  },
  {
    "arxiv_id": "2504.14151v1",
    "title": "Locate 3D: Real-World Object Localization via Self-Supervised Learning in 3D",
    "authors": [
      "Sergio Arnaud",
      "Paul McVay",
      "Ada Martin",
      "Arjun Majumdar",
      "Krishna Murthy Jatavallabhula",
      "Phillip Thomas",
      "Ruslan Partsey",
      "Daniel Dugas",
      "Abha Gejji",
      "Alexander Sax",
      "Vincent-Pierre Berges",
      "Mikael Henaff",
      "Ayush Jain",
      "Ang Cao",
      "Ishita Prasad",
      "Mrinal Kalakrishnan",
      "Michael Rabbat",
      "Nicolas Ballas",
      "Mido Assran",
      "Oleksandr Maksymets",
      "Aravind Rajeswaran",
      "Franziska Meier"
    ],
    "abstract": "We present LOCATE 3D, a model for localizing objects in 3D scenes from\nreferring expressions like \"the small coffee table between the sofa and the\nlamp.\" LOCATE 3D sets a new state-of-the-art on standard referential grounding\nbenchmarks and showcases robust generalization capabilities. Notably, LOCATE 3D\noperates directly on sensor observation streams (posed RGB-D frames), enabling\nreal-world deployment on robots and AR devices. Key to our approach is 3D-JEPA,\na novel self-supervised learning (SSL) algorithm applicable to sensor point\nclouds. It takes as input a 3D pointcloud featurized using 2D foundation models\n(CLIP, DINO). Subsequently, masked prediction in latent space is employed as a\npretext task to aid the self-supervised learning of contextualized pointcloud\nfeatures. Once trained, the 3D-JEPA encoder is finetuned alongside a\nlanguage-conditioned decoder to jointly predict 3D masks and bounding boxes.\nAdditionally, we introduce LOCATE 3D DATASET, a new dataset for 3D referential\ngrounding, spanning multiple capture setups with over 130K annotations. This\nenables a systematic study of generalization capabilities as well as a stronger\nmodel.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO",
      "I.2.10; I.2.6; I.2.9; I.3.7; I.4.6; I.4.8"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.14151v1",
    "published_date": "2025-04-19 02:51:24 UTC",
    "updated_date": "2025-04-19 02:51:24 UTC"
  },
  {
    "arxiv_id": "2504.14150v2",
    "title": "Walk the Talk? Measuring the Faithfulness of Large Language Model Explanations",
    "authors": [
      "Katie Matton",
      "Robert Osazuwa Ness",
      "John Guttag",
      "Emre Kƒ±cƒ±man"
    ],
    "abstract": "Large language models (LLMs) are capable of generating plausible explanations\nof how they arrived at an answer to a question. However, these explanations can\nmisrepresent the model's \"reasoning\" process, i.e., they can be unfaithful.\nThis, in turn, can lead to over-trust and misuse. We introduce a new approach\nfor measuring the faithfulness of LLM explanations. First, we provide a\nrigorous definition of faithfulness. Since LLM explanations mimic human\nexplanations, they often reference high-level concepts in the input question\nthat purportedly influenced the model. We define faithfulness in terms of the\ndifference between the set of concepts that LLM explanations imply are\ninfluential and the set that truly are. Second, we present a novel method for\nestimating faithfulness that is based on: (1) using an auxiliary LLM to modify\nthe values of concepts within model inputs to create realistic counterfactuals,\nand (2) using a Bayesian hierarchical model to quantify the causal effects of\nconcepts at both the example- and dataset-level. Our experiments show that our\nmethod can be used to quantify and discover interpretable patterns of\nunfaithfulness. On a social bias task, we uncover cases where LLM explanations\nhide the influence of social bias. On a medical question answering task, we\nuncover cases where LLM explanations provide misleading claims about which\npieces of evidence influenced the model's decisions.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.CL",
    "comment": "66 pages, 14 figures, 40 tables; ICLR 2025 (spotlight) camera ready",
    "pdf_url": "http://arxiv.org/pdf/2504.14150v2",
    "published_date": "2025-04-19 02:51:20 UTC",
    "updated_date": "2025-05-20 14:36:36 UTC"
  },
  {
    "arxiv_id": "2504.14147v1",
    "title": "HF4Rec: Human-Like Feedback-Driven Optimization Framework for Explainable Recommendation",
    "authors": [
      "Jiakai Tang",
      "Jingsen Zhang",
      "Zihang Tian",
      "Xueyang Feng",
      "Lei Wang",
      "Xu Chen"
    ],
    "abstract": "Recent advancements in explainable recommendation have greatly bolstered user\nexperience by elucidating the decision-making rationale. However, the existing\nmethods actually fail to provide effective feedback signals for potentially\nbetter or worse generated explanations due to their reliance on traditional\nsupervised learning paradigms in sparse interaction data. To address these\nissues, we propose a novel human-like feedback-driven optimization framework.\nThis framework employs a dynamic interactive optimization mechanism for\nachieving human-centered explainable requirements without incurring high labor\ncosts. Specifically, we propose to utilize large language models (LLMs) as\nhuman simulators to predict human-like feedback for guiding the learning\nprocess. To enable the LLMs to deeply understand the task essence and meet\nuser's diverse personalized requirements, we introduce a human-induced\ncustomized reward scoring method, which helps stimulate the language\nunderstanding and logical reasoning capabilities of LLMs. Furthermore,\nconsidering the potential conflicts between different perspectives of\nexplanation quality, we introduce a principled Pareto optimization that\ntransforms the multi-perspective quality enhancement task into a\nmulti-objective optimization problem for improving explanation performance. At\nlast, to achieve efficient model training, we design an off-policy optimization\npipeline. By incorporating a replay buffer and addressing the data distribution\nbiases, we can effectively improve data utilization and enhance model\ngenerality. Extensive experiments on four datasets demonstrate the superiority\nof our approach.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.14147v1",
    "published_date": "2025-04-19 02:46:10 UTC",
    "updated_date": "2025-04-19 02:46:10 UTC"
  },
  {
    "arxiv_id": "2504.14145v1",
    "title": "PipeWeaver: Addressing Data Dynamicity in Large Multimodal Model Training with Dynamic Interleaved Pipeline",
    "authors": [
      "Zhenliang Xue",
      "Hanpeng Hu",
      "Xing Chen",
      "Yimin Jiang",
      "Yixin Song",
      "Zeyu Mi",
      "Yibo Zhu",
      "Daxin Jiang",
      "Yubin Xia",
      "Haibo Chen"
    ],
    "abstract": "Large multimodal models (LMMs) have demonstrated excellent capabilities in\nboth understanding and generation tasks with various modalities. While these\nmodels can accept flexible combinations of input data, their training\nefficiency suffers from two major issues: pipeline stage imbalance caused by\nheterogeneous model architectures, and training data dynamicity stemming from\nthe diversity of multimodal data.\n  In this paper, we present PipeWeaver, a dynamic pipeline scheduling framework\ndesigned for LMM training. The core of PipeWeaver is dynamic interleaved\npipeline, which searches for pipeline schedules dynamically tailored to current\ntraining batches. PipeWeaver addresses issues of LMM training with two\ntechniques: adaptive modality-aware partitioning and efficient pipeline\nschedule search within a hierarchical schedule space. Meanwhile, PipeWeaver\nutilizes SEMU (Step Emulator), a training simulator for multimodal models, for\naccurate performance estimations, accelerated by spatial-temporal subgraph\nreuse to improve search efficiency. Experiments show that PipeWeaver can\nenhance LMM training efficiency by up to 97.3% compared to state-of-the-art\nsystems, and demonstrate excellent adaptivity to LMM training's data\ndynamicity.",
    "categories": [
      "cs.DC",
      "cs.AI"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.14145v1",
    "published_date": "2025-04-19 02:30:11 UTC",
    "updated_date": "2025-04-19 02:30:11 UTC"
  },
  {
    "arxiv_id": "2504.14139v2",
    "title": "ThyroidEffi 1.0: A Cost-Effective System for High-Performance Multi-Class Thyroid Carcinoma Classification",
    "authors": [
      "Hai Pham-Ngoc",
      "De Nguyen-Van",
      "Dung Vu-Tien",
      "Phuong Le-Hong"
    ],
    "abstract": "Background: Automated classification of thyroid Fine Needle Aspiration Biopsy\n(FNAB) images faces challenges in limited data, inter-observer variability, and\ncomputational cost. Efficient, interpretable models are crucial for clinical\nsupport.\n  Objective: To develop and externally validate a deep learning system for\nmulti-class thyroid FNAB image classification into three key categories\ndirectly guiding post-biopsy treatment in Vietnam: Benign (Bethesda II),\nIndeterminate/Suspicious (BI, III, IV, V), and Malignant (BVI), achieving high\ndiagnostic accuracy with low computational overhead.\n  Methods: Our pipeline features: (1) YOLOv10 cell cluster detection for\ninformative sub-region extraction/noise reduction; (2) curriculum learning\nsequencing localized crops to full images for multi-scale capture; (3) adaptive\nlightweight EfficientNetB0 (4M parameters) balancing performance/efficiency;\nand (4) a Transformer-inspired module for multi-scale/multi-region analysis.\nExternal validation used 1,015 independent FNAB images.\n  Results: ThyroidEffi Basic achieved macro F1 of 89.19% and AUCs of 0.98\n(Benign), 0.95 (Indeterminate/Suspicious), 0.96 (Malignant) on the internal\ntest set. External validation yielded AUCs of 0.9495 (Benign), 0.7436\n(Indeterminate/Suspicious), 0.8396 (Malignant). ThyroidEffi Premium improved\nmacro F1 to 89.77%. Grad-CAM highlighted key diagnostic regions, confirming\ninterpretability. The system processed 1000 cases in 30 seconds, demonstrating\nfeasibility on widely accessible hardware.\n  Conclusions: This work demonstrates that high-accuracy, interpretable thyroid\nFNAB image classification is achievable with minimal computational demands.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Preprint",
    "pdf_url": "http://arxiv.org/pdf/2504.14139v2",
    "published_date": "2025-04-19 02:13:07 UTC",
    "updated_date": "2025-04-27 11:38:59 UTC"
  },
  {
    "arxiv_id": "2504.14130v1",
    "title": "Personalized News Recommendation with Multi-granularity Candidate-aware User Modeling",
    "authors": [
      "Qiang Li",
      "Xinze Lin",
      "Shenghao Lv",
      "Faliang Huang",
      "Xiangju Li"
    ],
    "abstract": "Matching candidate news with user interests is crucial for personalized news\nrecommendations. Most existing methods can represent a user's reading interests\nthrough a single profile based on clicked news, which may not fully capture the\ndiversity of user interests. Although some approaches incorporate candidate\nnews or topic information, they remain insufficient because they neglect the\nmulti-granularity relatedness between candidate news and user interests. To\naddress this, this study proposed a multi-granularity candidate-aware user\nmodeling framework that integrated user interest features across various levels\nof granularity. It consisted of two main components: candidate news encoding\nand user modeling. A news textual information extractor and a\nknowledge-enhanced entity information extractor can capture candidate news\nfeatures, and word-level, entity-level, and news-level candidate-aware\nmechanisms can provide a comprehensive representation of user interests.\nExtensive experiments on a real-world dataset demonstrated that the proposed\nmodel could significantly outperform baseline models.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.14130v1",
    "published_date": "2025-04-19 01:14:55 UTC",
    "updated_date": "2025-04-19 01:14:55 UTC"
  },
  {
    "arxiv_id": "2504.14128v4",
    "title": "TALES: Text Adventure Learning Environment Suite",
    "authors": [
      "Christopher Zhang Cui",
      "Xingdi Yuan",
      "Ziang Xiao",
      "Prithviraj Ammanabrolu",
      "Marc-Alexandre C√¥t√©"
    ],
    "abstract": "Reasoning is an essential skill to enable Large Language Models (LLMs) to\ninteract with the world. As tasks become more complex, they demand increasingly\nsophisticated and diverse reasoning capabilities for sequential\ndecision-making, requiring structured reasoning over the context history to\ndetermine the next best action. We introduce TALES, a diverse collection of\nsynthetic and human-written text-adventure games designed to challenge and\nevaluate diverse reasoning capabilities. We present results over a range of\nLLMs, open- and closed-weights, performing a qualitative analysis on the top\nperforming models. Despite an impressive showing on synthetic games, even the\ntop LLM-driven agents fail to achieve 15% on games designed for human\nenjoyment. Code and visualization of the experiments can be found at\nhttps://microsoft.github.io/tale-suite.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.14128v4",
    "published_date": "2025-04-19 01:02:42 UTC",
    "updated_date": "2025-04-24 02:50:28 UTC"
  },
  {
    "arxiv_id": "2504.14126v1",
    "title": "Large Language Model Enhanced Particle Swarm Optimization for Hyperparameter Tuning for Deep Learning Models",
    "authors": [
      "Saad Hameed",
      "Basheer Qolomany",
      "Samir Brahim Belhaouari",
      "Mohamed Abdallah",
      "Junaid Qadir",
      "Ala Al-Fuqaha"
    ],
    "abstract": "Determining the ideal architecture for deep learning models, such as the\nnumber of layers and neurons, is a difficult and resource-intensive process\nthat frequently relies on human tuning or computationally costly optimization\napproaches. While Particle Swarm Optimization (PSO) and Large Language Models\n(LLMs) have been individually applied in optimization and deep learning, their\ncombined use for enhancing convergence in numerical optimization tasks remains\nunderexplored. Our work addresses this gap by integrating LLMs into PSO to\nreduce model evaluations and improve convergence for deep learning\nhyperparameter tuning. The proposed LLM-enhanced PSO method addresses the\ndifficulties of efficiency and convergence by using LLMs (particularly\nChatGPT-3.5 and Llama3) to improve PSO performance, allowing for faster\nachievement of target objectives. Our method speeds up search space exploration\nby substituting underperforming particle placements with best suggestions\noffered by LLMs. Comprehensive experiments across three scenarios -- (1)\noptimizing the Rastrigin function, (2) using Long Short-Term Memory (LSTM)\nnetworks for time series regression, and (3) using Convolutional Neural\nNetworks (CNNs) for material classification -- show that the method\nsignificantly improves convergence rates and lowers computational costs.\nDepending on the application, computational complexity is lowered by 20% to 60%\ncompared to traditional PSO methods. Llama3 achieved a 20% to 40% reduction in\nmodel calls for regression tasks, whereas ChatGPT-3.5 reduced model calls by\n60% for both regression and classification tasks, all while preserving accuracy\nand error rates. This groundbreaking methodology offers a very efficient and\neffective solution for optimizing deep learning models, leading to substantial\ncomputational performance improvements across a wide range of applications.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.14126v1",
    "published_date": "2025-04-19 00:54:59 UTC",
    "updated_date": "2025-04-19 00:54:59 UTC"
  },
  {
    "arxiv_id": "2504.14125v1",
    "title": "Exploring Language Patterns of Prompts in Text-to-Image Generation and Their Impact on Visual Diversity",
    "authors": [
      "Maria-Teresa De Rosa Palmini",
      "Eva Cetinic"
    ],
    "abstract": "Following the initial excitement, Text-to-Image (TTI) models are now being\nexamined more critically. While much of the discourse has focused on biases and\nstereotypes embedded in large-scale training datasets, the sociotechnical\ndynamics of user interactions with these models remain underexplored. This\nstudy examines the linguistic and semantic choices users make when crafting\nprompts and how these choices influence the diversity of generated outputs.\nAnalyzing over six million prompts from the Civiverse dataset on the CivitAI\nplatform across seven months, we categorize users into three groups based on\ntheir levels of linguistic experimentation: consistent repeaters, occasional\nrepeaters, and non-repeaters. Our findings reveal that as user participation\ngrows over time, prompt language becomes increasingly homogenized through the\nadoption of popular community tags and descriptors, with repeated prompts\ncomprising 40-50% of submissions. At the same time, semantic similarity and\ntopic preferences remain relatively stable, emphasizing common subjects and\nsurface aesthetics. Using Vendi scores to quantify visual diversity, we\ndemonstrate a clear correlation between lexical similarity in prompts and the\nvisual similarity of generated images, showing that linguistic repetition\nreinforces less diverse representations. These findings highlight the\nsignificant role of user-driven factors in shaping AI-generated imagery, beyond\ninherent model biases, and underscore the need for tools and practices that\nencourage greater linguistic and thematic experimentation within TTI systems to\nfoster more inclusive and diverse AI-generated content.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.14125v1",
    "published_date": "2025-04-19 00:51:38 UTC",
    "updated_date": "2025-04-19 00:51:38 UTC"
  },
  {
    "arxiv_id": "2504.14123v1",
    "title": "Bayesian Principles Improve Prompt Learning In Vision-Language Models",
    "authors": [
      "Mingyu Kim",
      "Jongwoo Ko",
      "Mijung Park"
    ],
    "abstract": "Prompt learning is a popular fine-tuning method for vision-language models\ndue to its efficiency. It requires a small number of additional learnable\nparameters while significantly enhancing performance on target tasks. However,\nmost existing methods suffer from overfitting to fine-tuning data, yielding\npoor generalizability. To address this, we propose a new training objective\nfunction based on a Bayesian learning principle to balance adaptability and\ngeneralizability. We derive a prior over the logits, where the mean function is\nparameterized by the pre-trained model, while the posterior corresponds to the\nfine-tuned model. This objective establishes a balance by allowing the\nfine-tuned model to adapt to downstream tasks while remaining close to the\npre-trained model.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "AISTATS2025",
    "pdf_url": "http://arxiv.org/pdf/2504.14123v1",
    "published_date": "2025-04-19 00:48:09 UTC",
    "updated_date": "2025-04-19 00:48:09 UTC"
  },
  {
    "arxiv_id": "2504.14119v1",
    "title": "CODECRASH: Stress Testing LLM Reasoning under Structural and Semantic Perturbations",
    "authors": [
      "Man Ho Lam",
      "Chaozheng Wang",
      "Jen-tse Huang",
      "Michael R. Lyu"
    ],
    "abstract": "Large Language Models (LLMs) have recently showcased strong capabilities in\ncode-related tasks, yet their robustness in code comprehension and reasoning\nremains underexplored. In this paper, we present CodeCrash, a unified benchmark\nthat evaluates LLM robustness under code structural and textual distraction\nperturbations, applied to two established benchmarks -- CRUXEval and\nLiveCodeBench -- across both input and output prediction tasks. We evaluate\nseventeen LLMs using direct and Chain-of-Thought inference to systematically\nanalyze their robustness, identify primary reasons for performance degradation,\nand highlight failure modes. Our findings reveal the fragility of LLMs under\nstructural noise and the inherent reliance on natural language cues,\nhighlighting critical robustness issues of LLMs in code execution and\nunderstanding. Additionally, we examine three Large Reasoning Models (LRMs) and\ndiscover the severe vulnerability of self-reflective reasoning mechanisms that\nlead to reasoning collapse. CodeCrash provides a principled framework for\nstress-testing LLMs in code understanding, offering actionable directions for\nfuture evaluation and benchmarking. The code of CodeCrash and the robustness\nleaderboard are publicly available at https://donaldlamnl.github.io/CodeCrash/ .",
    "categories": [
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.14119v1",
    "published_date": "2025-04-19 00:40:28 UTC",
    "updated_date": "2025-04-19 00:40:28 UTC"
  },
  {
    "arxiv_id": "2504.14112v1",
    "title": "Longitudinal Study on Social and Emotional Use of AI Conversational Agent",
    "authors": [
      "Mohit Chandra",
      "Javier Hernandez",
      "Gonzalo Ramos",
      "Mahsa Ershadi",
      "Ananya Bhattacharjee",
      "Judith Amores",
      "Ebele Okoli",
      "Ann Paradiso",
      "Shahed Warreth",
      "Jina Suh"
    ],
    "abstract": "Development in digital technologies has continuously reshaped how individuals\nseek and receive social and emotional support. While online platforms and\ncommunities have long served this need, the increased integration of\ngeneral-purpose conversational AI into daily lives has introduced new dynamics\nin how support is provided and experienced. Existing research has highlighted\nboth benefits (e.g., wider access to well-being resources) and potential risks\n(e.g., over-reliance) of using AI for support seeking. In this five-week,\nexploratory study, we recruited 149 participants divided into two usage groups:\na baseline usage group (BU, n=60) that used the internet and AI as usual, and\nan active usage group (AU, n=89) encouraged to use one of four commercially\navailable AI tools (Microsoft Copilot, Google Gemini, PI AI, ChatGPT) for\nsocial and emotional interactions. Our analysis revealed significant increases\nin perceived attachment towards AI (32.99 percentage points), perceived AI\nempathy (25.8 p.p.), and motivation to use AI for entertainment (22.90 p.p.)\namong the AU group. We also observed that individual differences (e.g., gender\nidentity, prior AI usage) influenced perceptions of AI empathy and attachment.\nLastly, the AU group expressed higher comfort in seeking personal help,\nmanaging stress, obtaining social support, and talking about health with AI,\nindicating potential for broader emotional support while highlighting the need\nfor safeguards against problematic usage. Overall, our exploratory findings\nunderscore the importance of developing consumer-facing AI tools that support\nemotional well-being responsibly, while empowering users to understand the\nlimitations of these tools.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.HC",
    "comment": "16 pages, 5 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2504.14112v1",
    "published_date": "2025-04-19 00:03:48 UTC",
    "updated_date": "2025-04-19 00:03:48 UTC"
  }
]