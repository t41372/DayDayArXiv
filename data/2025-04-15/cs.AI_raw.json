[
  {
    "arxiv_id": "2504.11456v1",
    "title": "DeepMath-103K: A Large-Scale, Challenging, Decontaminated, and Verifiable Mathematical Dataset for Advancing Reasoning",
    "authors": [
      "Zhiwei He",
      "Tian Liang",
      "Jiahao Xu",
      "Qiuzhi Liu",
      "Xingyu Chen",
      "Yue Wang",
      "Linfeng Song",
      "Dian Yu",
      "Zhenwen Liang",
      "Wenxuan Wang",
      "Zhuosheng Zhang",
      "Rui Wang",
      "Zhaopeng Tu",
      "Haitao Mi",
      "Dong Yu"
    ],
    "abstract": "The capacity for complex mathematical reasoning is a key benchmark for\nartificial intelligence. While reinforcement learning (RL) applied to LLMs\nshows promise, progress is significantly hindered by the lack of large-scale\ntraining data that is sufficiently challenging, possesses verifiable answer\nformats suitable for RL, and is free from contamination with evaluation\nbenchmarks. To address these limitations, we introduce DeepMath-103K, a new,\nlarge-scale dataset comprising approximately 103K mathematical problems,\nspecifically designed to train advanced reasoning models via RL. DeepMath-103K\nis curated through a rigorous pipeline involving source analysis, stringent\ndecontamination against numerous benchmarks, and filtering for high difficulty\n(primarily Levels 5-9), significantly exceeding existing open resources in\nchallenge. Each problem includes a verifiable final answer, enabling rule-based\nRL, and three distinct R1-generated solutions suitable for diverse training\nparadigms like supervised fine-tuning or distillation. Spanning a wide range of\nmathematical topics, DeepMath-103K promotes the development of generalizable\nreasoning. We demonstrate that models trained on DeepMath-103K achieve\nsignificant improvements on challenging mathematical benchmarks, validating its\neffectiveness. We release DeepMath-103K publicly to facilitate community\nprogress in building more capable AI reasoning systems:\nhttps://github.com/zwhe99/DeepMath.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "WIP",
    "pdf_url": "http://arxiv.org/pdf/2504.11456v1",
    "published_date": "2025-04-15 17:59:51 UTC",
    "updated_date": "2025-04-15 17:59:51 UTC"
  },
  {
    "arxiv_id": "2504.11454v2",
    "title": "Elucidating the Design Space of Multimodal Protein Language Models",
    "authors": [
      "Cheng-Yen Hsieh",
      "Xinyou Wang",
      "Daiheng Zhang",
      "Dongyu Xue",
      "Fei Ye",
      "Shujian Huang",
      "Zaixiang Zheng",
      "Quanquan Gu"
    ],
    "abstract": "Multimodal protein language models (PLMs) integrate sequence and token-based\nstructural information, serving as a powerful foundation for protein modeling,\ngeneration, and design. However, the reliance on tokenizing 3D structures into\ndiscrete tokens causes substantial loss of fidelity about fine-grained\nstructural details and correlations. In this paper, we systematically elucidate\nthe design space of multimodal PLMs to overcome their limitations. We identify\ntokenization loss and inaccurate structure token predictions by the PLMs as\nmajor bottlenecks. To address these, our proposed design space covers improved\ngenerative modeling, structure-aware architectures and representation learning,\nand data exploration. Our advancements approach finer-grained supervision,\ndemonstrating that token-based multimodal PLMs can achieve robust structural\nmodeling. The effective design methods dramatically improve the structure\ngeneration diversity, and notably, folding abilities of our 650M model by\nreducing the RMSD from 5.52 to 2.36 on PDB testset, even outperforming 3B\nbaselines and on par with the specialized folding models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.QM"
    ],
    "primary_category": "cs.LG",
    "comment": "Project Page: https://bytedance.github.io/dplm/dplm-2.1/",
    "pdf_url": "http://arxiv.org/pdf/2504.11454v2",
    "published_date": "2025-04-15 17:59:43 UTC",
    "updated_date": "2025-04-16 02:35:11 UTC"
  },
  {
    "arxiv_id": "2504.11453v1",
    "title": "A Clean Slate for Offline Reinforcement Learning",
    "authors": [
      "Matthew Thomas Jackson",
      "Uljad Berdica",
      "Jarek Liesen",
      "Shimon Whiteson",
      "Jakob Nicolaus Foerster"
    ],
    "abstract": "Progress in offline reinforcement learning (RL) has been impeded by ambiguous\nproblem definitions and entangled algorithmic designs, resulting in\ninconsistent implementations, insufficient ablations, and unfair evaluations.\nAlthough offline RL explicitly avoids environment interaction, prior methods\nfrequently employ extensive, undocumented online evaluation for hyperparameter\ntuning, complicating method comparisons. Moreover, existing reference\nimplementations differ significantly in boilerplate code, obscuring their core\nalgorithmic contributions. We address these challenges by first introducing a\nrigorous taxonomy and a transparent evaluation protocol that explicitly\nquantifies online tuning budgets. To resolve opaque algorithmic design, we\nprovide clean, minimalistic, single-file implementations of various model-free\nand model-based offline RL methods, significantly enhancing clarity and\nachieving substantial speed-ups. Leveraging these streamlined implementations,\nwe propose Unifloral, a unified algorithm that encapsulates diverse prior\napproaches within a single, comprehensive hyperparameter space, enabling\nalgorithm development in a shared hyperparameter space. Using Unifloral with\nour rigorous evaluation protocol, we develop two novel algorithms - TD3-AWR\n(model-free) and MoBRAC (model-based) - which substantially outperform\nestablished baselines. Our implementation is publicly available at\nhttps://github.com/EmptyJackson/unifloral.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.11453v1",
    "published_date": "2025-04-15 17:59:05 UTC",
    "updated_date": "2025-04-15 17:59:05 UTC"
  },
  {
    "arxiv_id": "2504.11442v1",
    "title": "TextArena",
    "authors": [
      "Leon Guertler",
      "Bobby Cheng",
      "Simon Yu",
      "Bo Liu",
      "Leshem Choshen",
      "Cheston Tan"
    ],
    "abstract": "TextArena is an open-source collection of competitive text-based games for\ntraining and evaluation of agentic behavior in Large Language Models (LLMs). It\nspans 57+ unique environments (including single-player, two-player, and\nmulti-player setups) and allows for easy evaluation of model capabilities via\nan online-play system (against humans and other submitted models) with\nreal-time TrueSkill scores. Traditional benchmarks rarely assess dynamic social\nskills such as negotiation, theory of mind, and deception, creating a gap that\nTextArena addresses. Designed with research, community and extensibility in\nmind, TextArena emphasizes ease of adding new games, adapting the framework,\ntesting models, playing against the models, and training models. Detailed\ndocumentation of environments, games, leaderboard, and examples are available\non https://github.com/LeonGuertler/TextArena and https://www.textarena.ai/.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.CL",
    "comment": "work in progress; 5 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.11442v1",
    "published_date": "2025-04-15 17:55:20 UTC",
    "updated_date": "2025-04-15 17:55:20 UTC"
  },
  {
    "arxiv_id": "2504.11440v1",
    "title": "Greedy Restart Schedules: A Baseline for Dynamic Algorithm Selection on Numerical Black-box Optimization Problems",
    "authors": [
      "Lennart Sch√§permeier"
    ],
    "abstract": "In many optimization domains, there are multiple different solvers that\ncontribute to the overall state-of-the-art, each performing better on some, and\nworse on other types of problem instances. Meta-algorithmic approaches, such as\ninstance-based algorithm selection, configuration and scheduling, aim to close\nthis gap by extracting the most performance possible from a set of\n(configurable) optimizers. In this context, the best performing individual\nalgorithms are often hand-crafted hybrid heuristics which perform many restarts\nof fast local optimization approaches. However, data-driven techniques to\ncreate optimized restart schedules have not yet been extensively studied.\n  Here, we present a simple scheduling approach that iteratively selects the\nalgorithm performing best on the distribution of unsolved training problems at\ntime of selection, resulting in a problem-independent solver schedule. We\ndemonstrate our approach using well-known optimizers from numerical black-box\noptimization on the BBOB testbed, bridging much of the gap between single and\nvirtual best solver from the original portfolio across various evaluation\nprotocols. Our greedy restart schedule presents a powerful baseline for more\ncomplex dynamic algorithm selection models.",
    "categories": [
      "math.OC",
      "cs.AI"
    ],
    "primary_category": "math.OC",
    "comment": "Author version. Accepted as full paper to be presented at the GECCO\n  2025 conference, July 14-18, M\\'alaga, Spain. (DOI 10.1145/3712256.3726408)",
    "pdf_url": "http://arxiv.org/pdf/2504.11440v1",
    "published_date": "2025-04-15 17:54:21 UTC",
    "updated_date": "2025-04-15 17:54:21 UTC"
  },
  {
    "arxiv_id": "2504.11431v1",
    "title": "Masculine Defaults via Gendered Discourse in Podcasts and Large Language Models",
    "authors": [
      "Maria Teleki",
      "Xiangjue Dong",
      "Haoran Liu",
      "James Caverlee"
    ],
    "abstract": "Masculine defaults are widely recognized as a significant type of gender\nbias, but they are often unseen as they are under-researched. Masculine\ndefaults involve three key parts: (i) the cultural context, (ii) the masculine\ncharacteristics or behaviors, and (iii) the reward for, or simply acceptance\nof, those masculine characteristics or behaviors. In this work, we study\ndiscourse-based masculine defaults, and propose a twofold framework for (i) the\nlarge-scale discovery and analysis of gendered discourse words in spoken\ncontent via our Gendered Discourse Correlation Framework (GDCF); and (ii) the\nmeasurement of the gender bias associated with these gendered discourse words\nin LLMs via our Discourse Word-Embedding Association Test (D-WEAT). We focus\nour study on podcasts, a popular and growing form of social media, analyzing\n15,117 podcast episodes. We analyze correlations between gender and discourse\nwords -- discovered via LDA and BERTopic -- to automatically form gendered\ndiscourse word lists. We then study the prevalence of these gendered discourse\nwords in domain-specific contexts, and find that gendered discourse-based\nmasculine defaults exist in the domains of business, technology/politics, and\nvideo games. Next, we study the representation of these gendered discourse\nwords from a state-of-the-art LLM embedding model from OpenAI, and find that\nthe masculine discourse words have a more stable and robust representation than\nthe feminine discourse words, which may result in better system performance on\ndownstream tasks for men. Hence, men are rewarded for their discourse patterns\nwith better system performance by one of the state-of-the-art language models\n-- and this embedding disparity is a representational harm and a masculine\ndefault.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.LG",
      "cs.SI"
    ],
    "primary_category": "cs.CL",
    "comment": "To appear in ICWSM 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.11431v1",
    "published_date": "2025-04-15 17:41:54 UTC",
    "updated_date": "2025-04-15 17:41:54 UTC"
  },
  {
    "arxiv_id": "2504.11426v1",
    "title": "A Dual-Space Framework for General Knowledge Distillation of Large Language Models",
    "authors": [
      "Xue Zhang",
      "Songming Zhang",
      "Yunlong Liang",
      "Fandong Meng",
      "Yufeng Chen",
      "Jinan Xu",
      "Jie Zhou"
    ],
    "abstract": "Knowledge distillation (KD) is a promising solution to compress large\nlanguage models (LLMs) by transferring their knowledge to smaller models.\nDuring this process, white-box KD methods usually minimize the distance between\nthe output distributions of the teacher model and the student model to transfer\nmore information. However, we reveal that the current white-box KD framework\nexhibits two limitations: a) bridging probability distributions from different\noutput spaces will limit the similarity between the teacher model and the\nstudent model; b) this framework cannot be applied to LLMs with different\nvocabularies. One of the root causes for these limitations is that the\ndistributions from the teacher and the student for KD are output by different\nprediction heads, which yield distributions in different output spaces and\ndimensions. Therefore, in this paper, we propose a dual-space knowledge\ndistillation (DSKD) framework that unifies the prediction heads of the teacher\nand the student models for KD. Specifically, we first introduce two projectors\nwith ideal initialization to project the teacher/student hidden states into the\nstudent/teacher representation spaces. After this, the hidden states from\ndifferent models can share the same head and unify the output spaces of the\ndistributions. Furthermore, we develop an exact token alignment (ETA) algorithm\nto align the same tokens in two differently-tokenized sequences. Based on the\nabove, our DSKD framework is a general KD framework that supports both\noff-policy and on-policy KD, and KD between any two LLMs regardless of their\nvocabularies. Extensive experiments on instruction-following, mathematical\nreasoning, and code generation benchmarks show that DSKD significantly\noutperforms existing methods based on the current white-box KD framework and\nsurpasses other cross-tokenizer KD methods for LLMs with different\nvocabularies.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "19 pages, 9 figures, 11 tables, under review. Code is available at:\n  https://github.com/songmzhang/DSKDv2. arXiv admin note: text overlap with\n  arXiv:2406.17328",
    "pdf_url": "http://arxiv.org/pdf/2504.11426v1",
    "published_date": "2025-04-15 17:38:47 UTC",
    "updated_date": "2025-04-15 17:38:47 UTC"
  },
  {
    "arxiv_id": "2504.11423v1",
    "title": "ADT: Tuning Diffusion Models with Adversarial Supervision",
    "authors": [
      "Dazhong Shen",
      "Guanglu Song",
      "Yi Zhang",
      "Bingqi Ma",
      "Lujundong Li",
      "Dongzhi Jiang",
      "Zhuofan Zong",
      "Yu Liu"
    ],
    "abstract": "Diffusion models have achieved outstanding image generation by reversing a\nforward noising process to approximate true data distributions. During\ntraining, these models predict diffusion scores from noised versions of true\nsamples in a single forward pass, while inference requires iterative denoising\nstarting from white noise. This training-inference divergences hinder the\nalignment between inference and training data distributions, due to potential\nprediction biases and cumulative error accumulation. To address this problem,\nwe propose an intuitive but effective fine-tuning framework, called Adversarial\nDiffusion Tuning (ADT), by stimulating the inference process during\noptimization and aligning the final outputs with training data by adversarial\nsupervision. Specifically, to achieve robust adversarial training, ADT features\na siamese-network discriminator with a fixed pre-trained backbone and\nlightweight trainable parameters, incorporates an image-to-image sampling\nstrategy to smooth discriminative difficulties, and preserves the original\ndiffusion loss to prevent discriminator hacking. In addition, we carefully\nconstrain the backward-flowing path for back-propagating gradients along the\ninference path without incurring memory overload or gradient explosion.\nFinally, extensive experiments on Stable Diffusion models (v1.5, XL, and v3),\ndemonstrate that ADT significantly improves both distribution alignment and\nimage quality.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.11423v1",
    "published_date": "2025-04-15 17:37:50 UTC",
    "updated_date": "2025-04-15 17:37:50 UTC"
  },
  {
    "arxiv_id": "2504.11419v1",
    "title": "Embodied World Models Emerge from Navigational Task in Open-Ended Environments",
    "authors": [
      "Li Jin",
      "Liu Jia"
    ],
    "abstract": "Understanding how artificial systems can develop spatial awareness and\nreasoning has long been a challenge in AI research. Traditional models often\nrely on passive observation, but embodied cognition theory suggests that deeper\nunderstanding emerges from active interaction with the environment. This study\ninvestigates whether neural networks can autonomously internalize spatial\nconcepts through interaction, focusing on planar navigation tasks. Using Gated\nRecurrent Units (GRUs) combined with Meta-Reinforcement Learning (Meta-RL), we\nshow that agents can learn to encode spatial properties like direction,\ndistance, and obstacle avoidance. We introduce Hybrid Dynamical Systems (HDS)\nto model the agent-environment interaction as a closed dynamical system,\nrevealing stable limit cycles that correspond to optimal navigation strategies.\nRidge Representation allows us to map navigation paths into a fixed-dimensional\nbehavioral space, enabling comparison with neural states. Canonical Correlation\nAnalysis (CCA) confirms strong alignment between these representations,\nsuggesting that the agent's neural states actively encode spatial knowledge.\nIntervention experiments further show that specific neural dimensions are\ncausally linked to navigation performance. This work provides an approach to\nbridging the gap between action and perception in AI, offering new insights\ninto building adaptive, interpretable models that can generalize across complex\nenvironments. The causal validation of neural representations also opens new\navenues for understanding and controlling the internal mechanisms of AI\nsystems, pushing the boundaries of how machines learn and reason in dynamic,\nreal-world scenarios.",
    "categories": [
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.AI",
    "comment": "Research on explainable meta-reinforcement learning AI",
    "pdf_url": "http://arxiv.org/pdf/2504.11419v1",
    "published_date": "2025-04-15 17:35:13 UTC",
    "updated_date": "2025-04-15 17:35:13 UTC"
  },
  {
    "arxiv_id": "2504.11412v1",
    "title": "Measures of Variability for Risk-averse Policy Gradient",
    "authors": [
      "Yudong Luo",
      "Yangchen Pan",
      "Jiaqi Tan",
      "Pascal Poupart"
    ],
    "abstract": "Risk-averse reinforcement learning (RARL) is critical for decision-making\nunder uncertainty, which is especially valuable in high-stake applications.\nHowever, most existing works focus on risk measures, e.g., conditional\nvalue-at-risk (CVaR), while measures of variability remain underexplored. In\nthis paper, we comprehensively study nine common measures of variability,\nnamely Variance, Gini Deviation, Mean Deviation, Mean-Median Deviation,\nStandard Deviation, Inter-Quantile Range, CVaR Deviation, Semi_Variance, and\nSemi_Standard Deviation. Among them, four metrics have not been previously\nstudied in RARL. We derive policy gradient formulas for these unstudied\nmetrics, improve gradient estimation for Gini Deviation, analyze their gradient\nproperties, and incorporate them with the REINFORCE and PPO frameworks to\npenalize the dispersion of returns.\n  Our empirical study reveals that variance-based metrics lead to unstable\npolicy updates. In contrast, CVaR Deviation and Gini Deviation show consistent\nperformance across different randomness and evaluation domains, achieving high\nreturns while effectively learning risk-averse policies. Mean Deviation and\nSemi_Standard Deviation are also competitive across different scenarios. This\nwork provides a comprehensive overview of variability measures in RARL,\noffering practical insights for risk-aware decision-making and guiding future\nresearch on risk metrics and RARL algorithms.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.11412v1",
    "published_date": "2025-04-15 17:28:15 UTC",
    "updated_date": "2025-04-15 17:28:15 UTC"
  },
  {
    "arxiv_id": "2504.11406v1",
    "title": "Multi-level Cellular Automata for FLIM networks",
    "authors": [
      "Felipe Crispim Salvagnini",
      "Jancarlo F. Gomes",
      "Cid A. N. Santos",
      "Silvio Jamil F. Guimar√£es",
      "Alexandre X. Falc√£o"
    ],
    "abstract": "The necessity of abundant annotated data and complex network architectures\npresents a significant challenge in deep-learning Salient Object Detection\n(deep SOD) and across the broader deep-learning landscape. This challenge is\nparticularly acute in medical applications in developing countries with limited\ncomputational resources. Combining modern and classical techniques offers a\npath to maintaining competitive performance while enabling practical\napplications. Feature Learning from Image Markers (FLIM) methodology empowers\nexperts to design convolutional encoders through user-drawn markers, with\nfilters learned directly from these annotations. Recent findings demonstrate\nthat coupling a FLIM encoder with an adaptive decoder creates a flyweight\nnetwork suitable for SOD, requiring significantly fewer parameters than\nlightweight models and eliminating the need for backpropagation. Cellular\nAutomata (CA) methods have proven successful in data-scarce scenarios but\nrequire proper initialization -- typically through user input, priors, or\nrandomness. We propose a practical intersection of these approaches: using FLIM\nnetworks to initialize CA states with expert knowledge without requiring user\ninteraction for each image. By decoding features from each level of a FLIM\nnetwork, we can initialize multiple CAs simultaneously, creating a multi-level\nframework. Our method leverages the hierarchical knowledge encoded across\ndifferent network layers, merging multiple saliency maps into a high-quality\nfinal output that functions as a CA ensemble. Benchmarks across two challenging\nmedical datasets demonstrate the competitiveness of our multi-level CA approach\ncompared to established models in the deep SOD literature.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.11406v1",
    "published_date": "2025-04-15 17:22:24 UTC",
    "updated_date": "2025-04-15 17:22:24 UTC"
  },
  {
    "arxiv_id": "2504.11389v1",
    "title": "VideoPanda: Video Panoramic Diffusion with Multi-view Attention",
    "authors": [
      "Kevin Xie",
      "Amirmojtaba Sabour",
      "Jiahui Huang",
      "Despoina Paschalidou",
      "Greg Klar",
      "Umar Iqbal",
      "Sanja Fidler",
      "Xiaohui Zeng"
    ],
    "abstract": "High resolution panoramic video content is paramount for immersive\nexperiences in Virtual Reality, but is non-trivial to collect as it requires\nspecialized equipment and intricate camera setups. In this work, we introduce\nVideoPanda, a novel approach for synthesizing 360$^\\circ$ videos conditioned on\ntext or single-view video data. VideoPanda leverages multi-view attention\nlayers to augment a video diffusion model, enabling it to generate consistent\nmulti-view videos that can be combined into immersive panoramic content.\nVideoPanda is trained jointly using two conditions: text-only and single-view\nvideo, and supports autoregressive generation of long-videos. To overcome the\ncomputational burden of multi-view video generation, we randomly subsample the\nduration and camera views used during training and show that the model is able\nto gracefully generalize to generating more frames during inference. Extensive\nevaluations on both real-world and synthetic video datasets demonstrate that\nVideoPanda generates more realistic and coherent 360$^\\circ$ panoramas across\nall input conditions compared to existing methods. Visit the project website at\nhttps://research-staging.nvidia.com/labs/toronto-ai/VideoPanda/ for results.",
    "categories": [
      "cs.GR",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.GR",
    "comment": "Project website at\n  https://research-staging.nvidia.com/labs/toronto-ai/VideoPanda/",
    "pdf_url": "http://arxiv.org/pdf/2504.11389v1",
    "published_date": "2025-04-15 16:58:15 UTC",
    "updated_date": "2025-04-15 16:58:15 UTC"
  },
  {
    "arxiv_id": "2504.11386v1",
    "title": "Trajectory Encoding Temporal Graph Networks",
    "authors": [
      "Jiafeng Xiong",
      "Rizos Sakellariou"
    ],
    "abstract": "Temporal Graph Networks (TGNs) have demonstrated significant success in\ndynamic graph tasks such as link prediction and node classification. Both tasks\ncomprise transductive settings, where the model predicts links among known\nnodes, and in inductive settings, where it generalises learned patterns to\npreviously unseen nodes. Existing TGN designs face a dilemma under these dual\nscenarios. Anonymous TGNs, which rely solely on temporal and structural\ninformation, offer strong inductive generalisation but struggle to distinguish\nknown nodes. In contrast, non-anonymous TGNs leverage node features to excel in\ntransductive tasks yet fail to adapt to new nodes. To address this challenge,\nwe propose Trajectory Encoding TGN (TETGN). Our approach introduces\nautomatically expandable node identifiers (IDs) as learnable temporal\npositional features and performs message passing over these IDs to capture each\nnode's historical context. By integrating this trajectory-aware module with a\nstandard TGN using multi-head attention, TETGN effectively balances\ntransductive accuracy with inductive generalisation. Experimental results on\nthree real-world datasets show that TETGN significantly outperforms strong\nbaselines on both link prediction and node classification tasks, demonstrating\nits ability to unify the advantages of anonymous and non-anonymous models for\ndynamic graph learning.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.11386v1",
    "published_date": "2025-04-15 16:57:09 UTC",
    "updated_date": "2025-04-15 16:57:09 UTC"
  },
  {
    "arxiv_id": "2504.11374v1",
    "title": "A Winner-Takes-All Mechanism for Event Generation",
    "authors": [
      "Yongkang Huo",
      "Fuvio Forni",
      "Rodolphe Sepulchre"
    ],
    "abstract": "We present a novel framework for central pattern generator design that\nleverages the intrinsic rebound excitability of neurons in combination with\nwinner-takes-all computation. Our approach unifies decision-making and rhythmic\npattern generation within a simple yet powerful network architecture that\nemploys all-to-all inhibitory connections enhanced by designable excitatory\ninteractions. This design offers significant advantages regarding ease of\nimplementation, adaptability, and robustness. We demonstrate its efficacy\nthrough a ring oscillator model, which exhibits adaptive phase and frequency\nmodulation, making the framework particularly promising for applications in\nneuromorphic systems and robotics.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.SY"
    ],
    "primary_category": "eess.SY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.11374v1",
    "published_date": "2025-04-15 16:40:37 UTC",
    "updated_date": "2025-04-15 16:40:37 UTC"
  },
  {
    "arxiv_id": "2504.11369v1",
    "title": "OpenTuringBench: An Open-Model-based Benchmark and Framework for Machine-Generated Text Detection and Attribution",
    "authors": [
      "Lucio La Cava",
      "Andrea Tagarelli"
    ],
    "abstract": "Open Large Language Models (OLLMs) are increasingly leveraged in generative\nAI applications, posing new challenges for detecting their outputs. We propose\nOpenTuringBench, a new benchmark based on OLLMs, designed to train and evaluate\nmachine-generated text detectors on the Turing Test and Authorship Attribution\nproblems. OpenTuringBench focuses on a representative set of OLLMs, and\nfeatures a number of challenging evaluation tasks, including\nhuman/machine-manipulated texts, out-of-domain texts, and texts from previously\nunseen models. We also provide OTBDetector, a contrastive learning framework to\ndetect and attribute OLLM-based machine-generated texts. Results highlight the\nrelevance and varying degrees of difficulty of the OpenTuringBench tasks, with\nour detector achieving remarkable capabilities across the various tasks and\noutperforming most existing detectors. Resources are available on the\nOpenTuringBench Hugging Face repository at\nhttps://huggingface.co/datasets/MLNTeam-Unical/OpenTuringBench",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.HC",
      "physics.soc-ph"
    ],
    "primary_category": "cs.CL",
    "comment": "Under review with ARR",
    "pdf_url": "http://arxiv.org/pdf/2504.11369v1",
    "published_date": "2025-04-15 16:36:14 UTC",
    "updated_date": "2025-04-15 16:36:14 UTC"
  },
  {
    "arxiv_id": "2504.11364v1",
    "title": "Teaching Large Language Models to Reason through Learning and Forgetting",
    "authors": [
      "Tianwei Ni",
      "Allen Nie",
      "Sapana Chaudhary",
      "Yao Liu",
      "Huzefa Rangwala",
      "Rasool Fakoor"
    ],
    "abstract": "Leveraging inference-time search in large language models has proven\neffective in further enhancing a trained model's capability to solve complex\nmathematical and reasoning problems. However, this approach significantly\nincreases computational costs and inference time, as the model must generate\nand evaluate multiple candidate solutions to identify a viable reasoning path.\nTo address this, we propose an effective approach that integrates search\ncapabilities directly into the model by fine-tuning it using both successful\n(learning) and failed reasoning paths (forgetting) derived from diverse search\nmethods. While fine-tuning the model with these data might seem\nstraightforward, we identify a critical issue: the model's search capability\ntends to degrade rapidly if fine-tuning is performed naively. We show that this\ndegradation can be substantially mitigated by employing a smaller learning\nrate. Extensive experiments on the challenging Game-of-24 and Countdown\nmathematical reasoning benchmarks show that our approach not only outperforms\nboth standard fine-tuning and inference-time search baselines but also\nsignificantly reduces inference time by 180$\\times$.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.11364v1",
    "published_date": "2025-04-15 16:30:02 UTC",
    "updated_date": "2025-04-15 16:30:02 UTC"
  },
  {
    "arxiv_id": "2504.11358v1",
    "title": "DataSentinel: A Game-Theoretic Detection of Prompt Injection Attacks",
    "authors": [
      "Yupei Liu",
      "Yuqi Jia",
      "Jinyuan Jia",
      "Dawn Song",
      "Neil Zhenqiang Gong"
    ],
    "abstract": "LLM-integrated applications and agents are vulnerable to prompt injection\nattacks, where an attacker injects prompts into their inputs to induce\nattacker-desired outputs. A detection method aims to determine whether a given\ninput is contaminated by an injected prompt. However, existing detection\nmethods have limited effectiveness against state-of-the-art attacks, let alone\nadaptive ones. In this work, we propose DataSentinel, a game-theoretic method\nto detect prompt injection attacks. Specifically, DataSentinel fine-tunes an\nLLM to detect inputs contaminated with injected prompts that are strategically\nadapted to evade detection. We formulate this as a minimax optimization\nproblem, with the objective of fine-tuning the LLM to detect strong adaptive\nattacks. Furthermore, we propose a gradient-based method to solve the minimax\noptimization problem by alternating between the inner max and outer min\nproblems. Our evaluation results on multiple benchmark datasets and LLMs show\nthat DataSentinel effectively detects both existing and adaptive prompt\ninjection attacks.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "To appear in IEEE Symposium on Security and Privacy, 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.11358v1",
    "published_date": "2025-04-15 16:26:21 UTC",
    "updated_date": "2025-04-15 16:26:21 UTC"
  },
  {
    "arxiv_id": "2504.11355v1",
    "title": "Neural Networks for on-chip Model Predictive Control: a Method to Build Optimized Training Datasets and its application to Type-1 Diabetes",
    "authors": [
      "Alberto Castillo",
      "Elliot Pryor",
      "Anas El Fathi",
      "Boris Kovatchev",
      "Marc Breton"
    ],
    "abstract": "Training Neural Networks (NNs) to behave as Model Predictive Control (MPC)\nalgorithms is an effective way to implement them in constrained embedded\ndevices. By collecting large amounts of input-output data, where inputs\nrepresent system states and outputs are MPC-generated control actions, NNs can\nbe trained to replicate MPC behavior at a fraction of the computational cost.\nHowever, although the composition of the training data critically influences\nthe final NN accuracy, methods for systematically optimizing it remain\nunderexplored. In this paper, we introduce the concept of Optimally-Sampled\nDatasets (OSDs) as ideal training sets and present an efficient algorithm for\ngenerating them. An OSD is a parametrized subset of all the available data that\n(i) preserves existing MPC information up to a certain numerical resolution,\n(ii) avoids duplicate or near-duplicate states, and (iii) becomes saturated or\ncomplete. We demonstrate the effectiveness of OSDs by training NNs to replicate\nthe University of Virginia's MPC algorithm for automated insulin delivery in\nType-1 Diabetes, achieving a four-fold improvement in final accuracy. Notably,\ntwo OSD-trained NNs received regulatory clearance for clinical testing as the\nfirst NN-based control algorithm for direct human insulin dosing. This\nmethodology opens new pathways for implementing advanced optimizations on\nresource-constrained embedded platforms, potentially revolutionizing how\ncomplex algorithms are deployed.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.SY"
    ],
    "primary_category": "eess.SY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.11355v1",
    "published_date": "2025-04-15 16:25:06 UTC",
    "updated_date": "2025-04-15 16:25:06 UTC"
  },
  {
    "arxiv_id": "2504.11354v1",
    "title": "Kimina-Prover Preview: Towards Large Formal Reasoning Models with Reinforcement Learning",
    "authors": [
      "Haiming Wang",
      "Mert Unsal",
      "Xiaohan Lin",
      "Mantas Baksys",
      "Junqi Liu",
      "Marco Dos Santos",
      "Flood Sung",
      "Marina Vinyes",
      "Zhenzhe Ying",
      "Zekai Zhu",
      "Jianqiao Lu",
      "Hugues de Saxc√©",
      "Bolton Bailey",
      "Chendong Song",
      "Chenjun Xiao",
      "Dehao Zhang",
      "Ebony Zhang",
      "Frederick Pu",
      "Han Zhu",
      "Jiawei Liu",
      "Jonas Bayer",
      "Julien Michel",
      "Longhui Yu",
      "L√©o Dreyfus-Schmidt",
      "Lewis Tunstall",
      "Luigi Pagani",
      "Moreira Machado",
      "Pauline Bourigault",
      "Ran Wang",
      "Stanislas Polu",
      "Thibaut Barroyer",
      "Wen-Ding Li",
      "Yazhe Niu",
      "Yann Fleureau",
      "Yangyang Hu",
      "Zhouliang Yu",
      "Zihan Wang",
      "Zhilin Yang",
      "Zhengying Liu",
      "Jia Li"
    ],
    "abstract": "We introduce Kimina-Prover Preview, a large language model that pioneers a\nnovel reasoning-driven exploration paradigm for formal theorem proving, as\nshowcased in this preview release. Trained with a large-scale reinforcement\nlearning pipeline from Qwen2.5-72B, Kimina-Prover demonstrates strong\nperformance in Lean 4 proof generation by employing a structured reasoning\npattern we term \\textit{formal reasoning pattern}. This approach allows the\nmodel to emulate human problem-solving strategies in Lean, iteratively\ngenerating and refining proof steps. Kimina-Prover sets a new state-of-the-art\non the miniF2F benchmark, reaching 80.7% with pass@8192. Beyond improved\nbenchmark performance, our work yields several key insights: (1) Kimina-Prover\nexhibits high sample efficiency, delivering strong results even with minimal\nsampling (pass@1) and scaling effectively with computational budget, stemming\nfrom its unique reasoning pattern and RL training; (2) we demonstrate clear\nperformance scaling with model size, a trend previously unobserved for neural\ntheorem provers in formal mathematics; (3) the learned reasoning style,\ndistinct from traditional search algorithms, shows potential to bridge the gap\nbetween formal verification and informal mathematical intuition. We open source\ndistilled versions with 1.5B and 7B parameters of Kimina-Prover",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "22 pages",
    "pdf_url": "http://arxiv.org/pdf/2504.11354v1",
    "published_date": "2025-04-15 16:23:44 UTC",
    "updated_date": "2025-04-15 16:23:44 UTC"
  },
  {
    "arxiv_id": "2504.11349v1",
    "title": "Explicit and Implicit Representations in AI-based 3D Reconstruction for Radiology: A systematic literature review",
    "authors": [
      "Yuezhe Yang",
      "Boyu Yang",
      "Yaqian Wang",
      "Yang He",
      "Xingbo Dong",
      "Zhe Jin"
    ],
    "abstract": "The demand for high-quality medical imaging in clinical practice and assisted\ndiagnosis has made 3D reconstruction in radiological imaging a key research\nfocus. Artificial intelligence (AI) has emerged as a promising approach to\nenhancing reconstruction accuracy while reducing acquisition and processing\ntime, thereby minimizing patient radiation exposure and discomfort and\nultimately benefiting clinical diagnosis. This review explores state-of-the-art\nAI-based 3D reconstruction algorithms in radiological imaging, categorizing\nthem into explicit and implicit approaches based on their underlying\nprinciples. Explicit methods include point-based, volume-based, and Gaussian\nrepresentations, while implicit methods encompass implicit prior embedding and\nneural radiance fields. Additionally, we examine commonly used evaluation\nmetrics and benchmark datasets. Finally, we discuss the current state of\ndevelopment, key challenges, and future research directions in this evolving\nfield. Our project available on: https://github.com/Bean-Young/AI4Med.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR",
      "68T45",
      "I.4.5"
    ],
    "primary_category": "cs.CV",
    "comment": "43 pages, 5 figures, submit to Medical Image Analysis",
    "pdf_url": "http://arxiv.org/pdf/2504.11349v1",
    "published_date": "2025-04-15 16:21:47 UTC",
    "updated_date": "2025-04-15 16:21:47 UTC"
  },
  {
    "arxiv_id": "2504.11344v1",
    "title": "Interpretable Hybrid-Rule Temporal Point Processes",
    "authors": [
      "Yunyang Cao",
      "Juekai Lin",
      "Hongye Wang",
      "Wenhao Li",
      "Bo Jin"
    ],
    "abstract": "Temporal Point Processes (TPPs) are widely used for modeling event sequences\nin various medical domains, such as disease onset prediction, progression\nanalysis, and clinical decision support. Although TPPs effectively capture\ntemporal dynamics, their lack of interpretability remains a critical challenge.\nRecent advancements have introduced interpretable TPPs. However, these methods\nfail to incorporate numerical features, thereby limiting their ability to\ngenerate precise predictions. To address this issue, we propose Hybrid-Rule\nTemporal Point Processes (HRTPP), a novel framework that integrates temporal\nlogic rules with numerical features, improving both interpretability and\npredictive accuracy in event modeling. HRTPP comprises three key components:\nbasic intensity for intrinsic event likelihood, rule-based intensity for\nstructured temporal dependencies, and numerical feature intensity for dynamic\nprobability modulation. To effectively discover valid rules, we introduce a\ntwo-phase rule mining strategy with Bayesian optimization. To evaluate our\nmethod, we establish a multi-criteria assessment framework, incorporating rule\nvalidity, model fitting, and temporal predictive accuracy. Experimental results\non real-world medical datasets demonstrate that HRTPP outperforms\nstate-of-the-art interpretable TPPs in terms of predictive performance and\nclinical interpretability. In case studies, the rules extracted by HRTPP\nexplain the disease progression, offering valuable contributions to medical\ndiagnosis.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.11344v1",
    "published_date": "2025-04-15 16:15:16 UTC",
    "updated_date": "2025-04-15 16:15:16 UTC"
  },
  {
    "arxiv_id": "2504.11343v1",
    "title": "A Minimalist Approach to LLM Reasoning: from Rejection Sampling to Reinforce",
    "authors": [
      "Wei Xiong",
      "Jiarui Yao",
      "Yuhui Xu",
      "Bo Pang",
      "Lei Wang",
      "Doyen Sahoo",
      "Junnan Li",
      "Nan Jiang",
      "Tong Zhang",
      "Caiming Xiong",
      "Hanze Dong"
    ],
    "abstract": "Reinforcement learning (RL) has become a prevailing approach for fine-tuning\nlarge language models (LLMs) on complex reasoning tasks. Among recent methods,\nGRPO stands out for its empirical success in training models such as\nDeepSeek-R1, yet the sources of its effectiveness remain poorly understood. In\nthis work, we revisit GRPO from a reinforce-like algorithm perspective and\nanalyze its core components. Surprisingly, we find that a simple rejection\nsampling baseline, RAFT, which trains only on positively rewarded samples,\nyields competitive performance than GRPO and PPO. Our ablation studies reveal\nthat GRPO's main advantage arises from discarding prompts with entirely\nincorrect responses, rather than from its reward normalization. Motivated by\nthis insight, we propose Reinforce-Rej, a minimal extension of policy gradient\nthat filters both entirely incorrect and entirely correct samples.\nReinforce-Rej improves KL efficiency and stability, serving as a lightweight\nyet effective alternative to more complex RL algorithms. We advocate RAFT as a\nrobust and interpretable baseline, and suggest that future advances should\nfocus on more principled designs for incorporating negative samples, rather\nthan relying on them indiscriminately. Our findings provide guidance for future\nwork in reward-based LLM post-training.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "12 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.11343v1",
    "published_date": "2025-04-15 16:15:02 UTC",
    "updated_date": "2025-04-15 16:15:02 UTC"
  },
  {
    "arxiv_id": "2504.11338v1",
    "title": "Transformer-Based Model for Cold Start Mitigation in FaaS Architecture",
    "authors": [
      "Alexandre Savi Fayam Mbala Mouen",
      "Jerry Lacmou Zeutouo",
      "Vianney Kengne Tchendji"
    ],
    "abstract": "Serverless architectures, particularly the Function as a Service (FaaS)\nmodel, have become a cornerstone of modern cloud computing due to their ability\nto simplify resource management and enhance application deployment agility.\nHowever, a significant challenge remains: the cold start problem. This\nphenomenon occurs when an idle FaaS function is invoked, requiring a full\ninitialization process, which increases latency and degrades user experience.\nExisting solutions for cold start mitigation are limited in terms of invocation\npattern generalization and implementation complexity. In this study, we propose\nan innovative approach leveraging Transformer models to mitigate the impact of\ncold starts in FaaS architectures. Our solution excels in accurately modeling\nfunction initialization delays and optimizing serverless system performance.\nExperimental evaluation using a public dataset provided by Azure demonstrates a\nsignificant reduction in cold start times, reaching up to 79\\% compared to\nconventional methods.",
    "categories": [
      "cs.DC",
      "cs.AI"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.11338v1",
    "published_date": "2025-04-15 16:12:07 UTC",
    "updated_date": "2025-04-15 16:12:07 UTC"
  },
  {
    "arxiv_id": "2504.11336v1",
    "title": "Looking beyond the next token",
    "authors": [
      "Abitha Thankaraj",
      "Yiding Jiang",
      "J. Zico Kolter",
      "Yonatan Bisk"
    ],
    "abstract": "The structure of causal language model training assumes that each token can\nbe accurately predicted from the previous context. This contrasts with humans'\nnatural writing and reasoning process, where goals are typically known before\nthe exact argument or phrasings. While this mismatch has been well studied in\nthe literature, the working assumption has been that architectural changes are\nneeded to address this mismatch. We argue that rearranging and processing the\ntraining data sequences can allow models to more accurately imitate the true\ndata-generating process, and does not require any other changes to the\narchitecture or training infrastructure. We demonstrate that this technique,\nTrelawney, and the inference algorithms derived from it allow us to improve\nperformance on several key benchmarks that span planning, algorithmic\nreasoning, and story generation tasks. Finally, our method naturally enables\nthe generation of long-term goals at no additional cost. We investigate how\nusing the model's goal-generation capability can further improve planning and\nreasoning. Additionally, we believe Trelawney could potentially open doors to\nnew capabilities beyond the current language modeling paradigm.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.11336v1",
    "published_date": "2025-04-15 16:09:06 UTC",
    "updated_date": "2025-04-15 16:09:06 UTC"
  },
  {
    "arxiv_id": "2504.11335v1",
    "title": "Code Reborn AI-Driven Legacy Systems Modernization from COBOL to Java",
    "authors": [
      "Gopichand Bandarupalli"
    ],
    "abstract": "This study investigates AI-driven modernization of legacy COBOL code into\nJava, addressing a critical challenge in aging software systems. Leveraging the\nLegacy COBOL 2024 Corpus -- 50,000 COBOL files from public and enterprise\nsources -- Java parses the code, AI suggests upgrades, and React visualizes\ngains. Achieving 93% accuracy, complexity drops 35% (from 18 to 11.7) and\ncoupling 33% (from 8 to 5.4), surpassing manual efforts (75%) and rule-based\ntools (82%). The approach offers a scalable path to rejuvenate COBOL systems,\nvital for industries like banking and insurance.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.11335v1",
    "published_date": "2025-04-15 16:07:54 UTC",
    "updated_date": "2025-04-15 16:07:54 UTC"
  },
  {
    "arxiv_id": "2504.11320v1",
    "title": "Optimizing LLM Inference: Fluid-Guided Online Scheduling with Memory Constraints",
    "authors": [
      "Ruicheng Ao",
      "Gan Luo",
      "David Simchi-Levi",
      "Xinshang Wang"
    ],
    "abstract": "Large Language Models (LLMs) are indispensable in today's applications, but\ntheir inference procedure -- generating responses by processing text in\nsegments and using a memory-heavy Key-Value (KV) cache -- demands significant\ncomputational resources, particularly under memory constraints. This paper\nformulates LLM inference optimization as a multi-stage online scheduling\nproblem where sequential prompt arrivals and KV cache growth render\nconventional scheduling ineffective. We develop a fluid dynamics approximation\nto provide a tractable benchmark that guides algorithm design. Building on\nthis, we propose the Waiting for Accumulated Inference Threshold (WAIT)\nalgorithm, which uses multiple thresholds to schedule incoming prompts\noptimally when output lengths are known, and extend it to Nested WAIT for cases\nwith unknown output lengths. Theoretical analysis shows that both algorithms\nachieve near-optimal performance against the fluid benchmark in heavy traffic\nconditions, balancing throughput, latency, and Time to First Token (TTFT).\nExperiments with the Llama-7B model on an A100 GPU using both synthetic and\nreal-world datasets demonstrate improved throughput and reduced latency\nrelative to established baselines like vLLM and Sarathi. This work bridges\noperations research and machine learning, offering a rigorous framework for the\nefficient deployment of LLMs under memory constraints.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC",
      "math.OC",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "42 pages, 18 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.11320v1",
    "published_date": "2025-04-15 16:00:21 UTC",
    "updated_date": "2025-04-15 16:00:21 UTC"
  },
  {
    "arxiv_id": "2504.11305v1",
    "title": "CFIS-YOLO: A Lightweight Multi-Scale Fusion Network for Edge-Deployable Wood Defect Detection",
    "authors": [
      "Jincheng Kang",
      "Yi Cen",
      "Yigang Cen",
      "Ke Wang",
      "Yuhan Liu"
    ],
    "abstract": "Wood defect detection is critical for ensuring quality control in the wood\nprocessing industry. However, current industrial applications face two major\nchallenges: traditional methods are costly, subjective, and labor-intensive,\nwhile mainstream deep learning models often struggle to balance detection\naccuracy and computational efficiency for edge deployment. To address these\nissues, this study proposes CFIS-YOLO, a lightweight object detection model\noptimized for edge devices. The model introduces an enhanced C2f structure, a\ndynamic feature recombination module, and a novel loss function that\nincorporates auxiliary bounding boxes and angular constraints. These\ninnovations improve multi-scale feature fusion and small object localization\nwhile significantly reducing computational overhead. Evaluated on a public wood\ndefect dataset, CFIS-YOLO achieves a mean Average Precision (mAP@0.5) of\n77.5\\%, outperforming the baseline YOLOv10s by 4 percentage points. On SOPHON\nBM1684X edge devices, CFIS-YOLO delivers 135 FPS, reduces power consumption to\n17.3\\% of the original implementation, and incurs only a 0.5 percentage point\ndrop in mAP. These results demonstrate that CFIS-YOLO is a practical and\neffective solution for real-world wood defect detection in resource-constrained\nenvironments.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "10 pages, 11 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.11305v1",
    "published_date": "2025-04-15 15:45:59 UTC",
    "updated_date": "2025-04-15 15:45:59 UTC"
  },
  {
    "arxiv_id": "2504.11301v1",
    "title": "Learning to Be A Doctor: Searching for Effective Medical Agent Architectures",
    "authors": [
      "Yangyang Zhuang",
      "Wenjia Jiang",
      "Jiayu Zhang",
      "Ze Yang",
      "Joey Tianyi Zhou",
      "Chi Zhang"
    ],
    "abstract": "Large Language Model (LLM)-based agents have demonstrated strong capabilities\nacross a wide range of tasks, and their application in the medical domain holds\nparticular promise due to the demand for high generalizability and reliance on\ninterdisciplinary knowledge. However, existing medical agent systems often rely\non static, manually crafted workflows that lack the flexibility to accommodate\ndiverse diagnostic requirements and adapt to emerging clinical scenarios.\nMotivated by the success of automated machine learning (AutoML), this paper\nintroduces a novel framework for the automated design of medical agent\narchitectures. Specifically, we define a hierarchical and expressive agent\nsearch space that enables dynamic workflow adaptation through structured\nmodifications at the node, structural, and framework levels. Our framework\nconceptualizes medical agents as graph-based architectures composed of diverse,\nfunctional node types and supports iterative self-improvement guided by\ndiagnostic feedback. Experimental results on skin disease diagnosis tasks\ndemonstrate that the proposed method effectively evolves workflow structures\nand significantly enhances diagnostic accuracy over time. This work represents\nthe first fully automated framework for medical agent architecture design and\noffers a scalable, adaptable foundation for deploying intelligent agents in\nreal-world clinical environments.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.11301v1",
    "published_date": "2025-04-15 15:44:21 UTC",
    "updated_date": "2025-04-15 15:44:21 UTC"
  },
  {
    "arxiv_id": "2504.11284v1",
    "title": "Bipartite Ranking From Multiple Labels: On Loss Versus Label Aggregation",
    "authors": [
      "Michal Lukasik",
      "Lin Chen",
      "Harikrishna Narasimhan",
      "Aditya Krishna Menon",
      "Wittawat Jitkrittum",
      "Felix X. Yu",
      "Sashank J. Reddi",
      "Gang Fu",
      "Mohammadhossein Bateni",
      "Sanjiv Kumar"
    ],
    "abstract": "Bipartite ranking is a fundamental supervised learning problem, with the goal\nof learning a ranking over instances with maximal area under the ROC curve\n(AUC) against a single binary target label. However, one may often observe\nmultiple binary target labels, e.g., from distinct human annotators. How can\none synthesize such labels into a single coherent ranking? In this work, we\nformally analyze two approaches to this problem -- loss aggregation and label\naggregation -- by characterizing their Bayes-optimal solutions. Based on this,\nwe show that while both methods can yield Pareto-optimal solutions, loss\naggregation can exhibit label dictatorship: one can inadvertently (and\nundesirably) favor one label over others. This suggests that label aggregation\ncan be preferable to loss aggregation, which we empirically verify.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IR",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.11284v1",
    "published_date": "2025-04-15 15:25:27 UTC",
    "updated_date": "2025-04-15 15:25:27 UTC"
  },
  {
    "arxiv_id": "2504.11268v1",
    "title": "Single-Input Multi-Output Model Merging: Leveraging Foundation Models for Dense Multi-Task Learning",
    "authors": [
      "Juan Garcia Giraldo",
      "Nikolaos Dimitriadis",
      "Ke Wang",
      "Pascal Frossard"
    ],
    "abstract": "Model merging is a flexible and computationally tractable approach to merge\nsingle-task checkpoints into a multi-task model. Prior work has solely focused\non constrained multi-task settings where there is a one-to-one mapping between\na sample and a task, overlooking the paradigm where multiple tasks may operate\non the same sample, e.g., scene understanding. In this paper, we focus on the\nmulti-task setting with single-input-multiple-outputs (SIMO) and show that it\nqualitatively differs from the single-input-single-output model merging\nsettings studied in the literature due to the existence of task-specific\ndecoders and diverse loss objectives. We identify that existing model merging\nmethods lead to significant performance degradation, primarily due to\nrepresentation misalignment between the merged encoder and task-specific\ndecoders. We propose two simple and efficient fixes for the SIMO setting to\nre-align the feature representation after merging. Compared to joint\nfine-tuning, our approach is computationally effective and flexible, and sheds\nlight into identifying task relationships in an offline manner. Experiments on\nNYUv2, Cityscapes, and a subset of the Taskonomy dataset demonstrate: (1) task\narithmetic suffices to enable multi-task capabilities; however, the\nrepresentations generated by the merged encoder has to be re-aligned with the\ntask-specific heads; (2) the proposed architecture rivals traditional\nmulti-task learning in performance but requires fewer samples and training\nsteps by leveraging the existence of task-specific models.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "22 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.11268v1",
    "published_date": "2025-04-15 15:10:46 UTC",
    "updated_date": "2025-04-15 15:10:46 UTC"
  },
  {
    "arxiv_id": "2504.11264v1",
    "title": "DeepSelective: Feature Gating and Representation Matching for Interpretable Clinical Prediction",
    "authors": [
      "Ruochi Zhang",
      "Qian Yang",
      "Xiaoyang Wang",
      "Haoran Wu",
      "Qiong Zhou",
      "Yu Wang",
      "Kewei Li",
      "Yueying Wang",
      "Yusi Fan",
      "Jiale Zhang",
      "Lan Huang",
      "Chang Liu",
      "Fengfeng Zhou"
    ],
    "abstract": "The rapid accumulation of Electronic Health Records (EHRs) has transformed\nhealthcare by providing valuable data that enhance clinical predictions and\ndiagnoses. While conventional machine learning models have proven effective,\nthey often lack robust representation learning and depend heavily on\nexpert-crafted features. Although deep learning offers powerful solutions, it\nis often criticized for its lack of interpretability. To address these\nchallenges, we propose DeepSelective, a novel end to end deep learning\nframework for predicting patient prognosis using EHR data, with a strong\nemphasis on enhancing model interpretability. DeepSelective combines data\ncompression techniques with an innovative feature selection approach,\nintegrating custom-designed modules that work together to improve both accuracy\nand interpretability. Our experiments demonstrate that DeepSelective not only\nenhances predictive accuracy but also significantly improves interpretability,\nmaking it a valuable tool for clinical decision-making. The source code is\nfreely available at http://www.healthinformaticslab.org/supp/resources.php .",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.11264v1",
    "published_date": "2025-04-15 15:04:39 UTC",
    "updated_date": "2025-04-15 15:04:39 UTC"
  },
  {
    "arxiv_id": "2504.11250v1",
    "title": "A Rollout-Based Algorithm and Reward Function for Efficient Resource Allocation in Business Processes",
    "authors": [
      "Jeroen Middelhuis",
      "Zaharah Bukhsh",
      "Ivo Adan",
      "Remco Dijkman"
    ],
    "abstract": "Resource allocation plays a critical role in minimizing cycle time and\nimproving the efficiency of business processes. Recently, Deep Reinforcement\nLearning (DRL) has emerged as a powerful tool to optimize resource allocation\npolicies in business processes. In the DRL framework, an agent learns a policy\nthrough interaction with the environment, guided solely by reward signals that\nindicate the quality of its decisions. However, existing algorithms are not\nsuitable for dynamic environments such as business processes. Furthermore,\nexisting DRL-based methods rely on engineered reward functions that approximate\nthe desired objective, but a misalignment between reward and objective can lead\nto undesired decisions or suboptimal policies. To address these issues, we\npropose a rollout-based DRL algorithm and a reward function to optimize the\nobjective directly. Our algorithm iteratively improves the policy by evaluating\nexecution trajectories following different actions. Our reward function\ndirectly decomposes the objective function of minimizing the mean cycle time.\nMaximizing our reward function guarantees that the objective function is\nminimized without requiring extensive reward engineering. The results show that\nour method consistently learns the optimal policy in all six evaluated business\nprocesses, outperforming the state-of-the-art algorithm that can only learn the\noptimal policy in two of the evaluated processes.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Pre-print submitted to the 23rd International Conference on Business\n  Process Management",
    "pdf_url": "http://arxiv.org/pdf/2504.11250v1",
    "published_date": "2025-04-15 14:46:58 UTC",
    "updated_date": "2025-04-15 14:46:58 UTC"
  },
  {
    "arxiv_id": "2504.11246v1",
    "title": "Respiratory Inhaler Sound Event Classification Using Self-Supervised Learning",
    "authors": [
      "Davoud Shariat Panah",
      "Alessandro N Franciosi",
      "Cormac McCarthy",
      "Andrew Hines"
    ],
    "abstract": "Asthma is a chronic respiratory condition that affects millions of people\nworldwide. While this condition can be managed by administering controller\nmedications through handheld inhalers, clinical studies have shown low\nadherence to the correct inhaler usage technique. Consequently, many patients\nmay not receive the full benefit of their medication. Automated classification\nof inhaler sounds has recently been studied to assess medication adherence.\nHowever, the existing classification models were typically trained using data\nfrom specific inhaler types, and their ability to generalize to sounds from\ndifferent inhalers remains unexplored. In this study, we adapted the wav2vec\n2.0 self-supervised learning model for inhaler sound classification by\npre-training and fine-tuning this model on inhaler sounds. The proposed model\nshows a balanced accuracy of 98% on a dataset collected using a dry powder\ninhaler and smartwatch device. The results also demonstrate that re-finetuning\nthis model on minimal data from a target inhaler is a promising approach to\nadapting a generic inhaler sound classification model to a different inhaler\ndevice and audio capture hardware. This is the first study in the field to\ndemonstrate the potential of smartwatches as assistive technologies for the\npersonalized monitoring of inhaler adherence using machine learning models.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.AS",
    "comment": "Accepted at the IEEE EMBC 2025 Conference",
    "pdf_url": "http://arxiv.org/pdf/2504.11246v1",
    "published_date": "2025-04-15 14:44:47 UTC",
    "updated_date": "2025-04-15 14:44:47 UTC"
  },
  {
    "arxiv_id": "2504.11245v1",
    "title": "Influence Maximization in Temporal Social Networks with a Cold-Start Problem: A Supervised Approach",
    "authors": [
      "Laixin Xie",
      "Ying Zhang",
      "Xiyuan Wang",
      "Shiyi Liu",
      "Shenghan Gao",
      "Xingxing Xing",
      "Wei Wan",
      "Haipeng Zhang",
      "Quan Li"
    ],
    "abstract": "Influence Maximization (IM) in temporal graphs focuses on identifying\ninfluential \"seeds\" that are pivotal for maximizing network expansion. We\nadvocate defining these seeds through Influence Propagation Paths (IPPs), which\nis essential for scaling up the network. Our focus lies in efficiently labeling\nIPPs and accurately predicting these seeds, while addressing the\noften-overlooked cold-start issue prevalent in temporal networks. Our strategy\nintroduces a motif-based labeling method and a tensorized Temporal Graph\nNetwork (TGN) tailored for multi-relational temporal graphs, bolstering\nprediction accuracy and computational efficiency. Moreover, we augment\ncold-start nodes with new neighbors from historical data sharing similar IPPs.\nThe recommendation system within an online team-based gaming environment\npresents subtle impact on the social network, forming multi-relational (i.e.,\nweak and strong) temporal graphs for our empirical IM study. We conduct offline\nexperiments to assess prediction accuracy and model training efficiency,\ncomplemented by online A/B testing to validate practical network growth and the\neffectiveness in addressing the cold-start issue.",
    "categories": [
      "cs.SI",
      "cs.AI"
    ],
    "primary_category": "cs.SI",
    "comment": "Accepted by ICWSM 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.11245v1",
    "published_date": "2025-04-15 14:44:30 UTC",
    "updated_date": "2025-04-15 14:44:30 UTC"
  },
  {
    "arxiv_id": "2504.11243v1",
    "title": "Towards Automated Safety Requirements Derivation Using Agent-based RAG",
    "authors": [
      "Balahari Vignesh Balu",
      "Florian Geissler",
      "Francesco Carella",
      "Joao-Vitor Zacchi",
      "Josef Jiru",
      "Nuria Mata",
      "Reinhard Stolle"
    ],
    "abstract": "We study the automated derivation of safety requirements in a self-driving\nvehicle use case, leveraging LLMs in combination with agent-based\nretrieval-augmented generation. Conventional approaches that utilise\npre-trained LLMs to assist in safety analyses typically lack domain-specific\nknowledge. Existing RAG approaches address this issue, yet their performance\ndeteriorates when handling complex queries and it becomes increasingly harder\nto retrieve the most relevant information. This is particularly relevant for\nsafety-relevant applications. In this paper, we propose the use of agent-based\nRAG to derive safety requirements and show that the retrieved information is\nmore relevant to the queries. We implement an agent-based approach on a\ndocument pool of automotive standards and the Apollo case study, as a\nrepresentative example of an automated driving perception system. Our solution\nis tested on a data set of safety requirement questions and answers, extracted\nfrom the Apollo data. Evaluating a set of selected RAG metrics, we present and\ndiscuss advantages of a agent-based approach compared to default RAG methods.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "9 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.11243v1",
    "published_date": "2025-04-15 14:43:19 UTC",
    "updated_date": "2025-04-15 14:43:19 UTC"
  },
  {
    "arxiv_id": "2504.11239v1",
    "title": "Nondeterministic Polynomial-time Problem Challenge: An Ever-Scaling Reasoning Benchmark for LLMs",
    "authors": [
      "Chang Yang",
      "Ruiyu Wang",
      "Junzhe Jiang",
      "Qi Jiang",
      "Qinggang Zhang",
      "Yanchen Deng",
      "Shuxin Li",
      "Shuyue Hu",
      "Bo Li",
      "Florian T. Pokorny",
      "Xiao Huang",
      "Xinrun Wang"
    ],
    "abstract": "Reasoning is the fundamental capability of large language models (LLMs). Due\nto the rapid progress of LLMs, there are two main issues of current benchmarks:\ni) these benchmarks can be crushed in a short time (less than 1 year), and ii)\nthese benchmarks may be easily hacked. To handle these issues, we propose the\never-scalingness for building the benchmarks which are uncrushable, unhackable,\nauto-verifiable and general. This paper presents Nondeterministic\nPolynomial-time Problem Challenge (NPPC), an ever-scaling reasoning benchmark\nfor LLMs. Specifically, the NPPC has three main modules: i) npgym, which\nprovides a unified interface of 25 well-known NP-complete problems and can\ngenerate any number of instances with any levels of complexities, ii) npsolver:\nwhich provides a unified interface to evaluate the problem instances with both\nonline and offline models via APIs and local deployments, respectively, and\niii) npeval: which provides the comprehensive and ready-to-use tools to analyze\nthe performances of LLMs over different problems, the number of tokens, the aha\nmoments, the reasoning errors and the solution errors. Extensive experiments\nover widely-used LLMs demonstrate: i) NPPC can successfully decrease the\nperformances of advanced LLMs' performances to below 10%, demonstrating that\nNPPC is uncrushable, ii) DeepSeek-R1, Claude-3.7-Sonnet, and o1/o3-mini are the\nmost powerful LLMs, where DeepSeek-R1 outperforms Claude-3.7-Sonnet and\no1/o3-mini in most NP-complete problems considered, and iii) the numbers of\ntokens, aha moments in the advanced LLMs, e.g., Claude-3.7-Sonnet and\nDeepSeek-R1, are observed first to increase and then decrease when the problem\ninstances become more and more difficult. We believe that NPPC is the first\never-scaling reasoning benchmark, serving as the uncrushable and unhackable\ntestbed for LLMs toward artificial general intelligence (AGI).",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "Preliminary work, 10 pages for main text",
    "pdf_url": "http://arxiv.org/pdf/2504.11239v1",
    "published_date": "2025-04-15 14:40:29 UTC",
    "updated_date": "2025-04-15 14:40:29 UTC"
  },
  {
    "arxiv_id": "2504.11216v1",
    "title": "Diversity-Driven Learning: Tackling Spurious Correlations and Data Heterogeneity in Federated Models",
    "authors": [
      "Gergely D. N√©meth",
      "Eros Fan√¨",
      "Yeat Jeng Ng",
      "Barbara Caputo",
      "Miguel √Ångel Lozano",
      "Nuria Oliver",
      "Novi Quadrianto"
    ],
    "abstract": "Federated Learning (FL) enables decentralized training of machine learning\nmodels on distributed data while preserving privacy. However, in real-world FL\nsettings, client data is often non-identically distributed and imbalanced,\nresulting in statistical data heterogeneity which impacts the generalization\ncapabilities of the server's model across clients, slows convergence and\nreduces performance. In this paper, we address this challenge by first\nproposing a characterization of statistical data heterogeneity by means of 6\nmetrics of global and client attribute imbalance, class imbalance, and spurious\ncorrelations. Next, we create and share 7 computer vision datasets for binary\nand multiclass image classification tasks in Federated Learning that cover a\nbroad range of statistical data heterogeneity and hence simulate real-world\nsituations. Finally, we propose FedDiverse, a novel client selection algorithm\nin FL which is designed to manage and leverage data heterogeneity across\nclients by promoting collaboration between clients with complementary data\ndistributions. Experiments on the seven proposed FL datasets demonstrate\nFedDiverse's effectiveness in enhancing the performance and robustness of a\nvariety of FL methods while having low communication and computational\noverhead.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.11216v1",
    "published_date": "2025-04-15 14:20:42 UTC",
    "updated_date": "2025-04-15 14:20:42 UTC"
  },
  {
    "arxiv_id": "2504.11200v1",
    "title": "Mutual Understanding between People and Systems via Neurosymbolic AI and Knowledge Graphs",
    "authors": [
      "Irene Celino",
      "Mario Scrocca",
      "Agnese Chiatti"
    ],
    "abstract": "This chapter investigates the concept of mutual understanding between humans\nand systems, positing that Neuro-symbolic Artificial Intelligence (NeSy AI)\nmethods can significantly enhance this mutual understanding by leveraging\nexplicit symbolic knowledge representations with data-driven learning models.\nWe start by introducing three critical dimensions to characterize mutual\nunderstanding: sharing knowledge, exchanging knowledge, and governing\nknowledge. Sharing knowledge involves aligning the conceptual models of\ndifferent agents to enable a shared understanding of the domain of interest.\nExchanging knowledge relates to ensuring the effective and accurate\ncommunication between agents. Governing knowledge concerns establishing rules\nand processes to regulate the interaction between agents. Then, we present\nseveral different use case scenarios that demonstrate the application of NeSy\nAI and Knowledge Graphs to aid meaningful exchanges between human, artificial,\nand robotic agents. These scenarios highlight both the potential and the\nchallenges of combining top-down symbolic reasoning with bottom-up neural\nlearning, guiding the discussion of the coverage provided by current solutions\nalong the dimensions of sharing, exchanging, and governing knowledge.\nConcurrently, this analysis facilitates the identification of gaps and less\ndeveloped aspects in mutual understanding to address in future research.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "26 pages, 13 figures, 1 table; pre-print version of book chapter",
    "pdf_url": "http://arxiv.org/pdf/2504.11200v1",
    "published_date": "2025-04-15 13:57:09 UTC",
    "updated_date": "2025-04-15 13:57:09 UTC"
  },
  {
    "arxiv_id": "2504.11197v2",
    "title": "Efficient Distributed Retrieval-Augmented Generation for Enhancing Language Model Performance",
    "authors": [
      "Shangyu Liu",
      "Zhenzhe Zheng",
      "Xiaoyao Huang",
      "Fan Wu",
      "Guihai Chen",
      "Jie Wu"
    ],
    "abstract": "Small language models (SLMs) support efficient deployments on\nresource-constrained edge devices, but their limited capacity compromises\ninference performance. Retrieval-augmented generation (RAG) is a promising\nsolution to enhance model performance by integrating external databases,\nwithout requiring intensive on-device model retraining. However, large-scale\npublic databases and user-specific private contextual documents are typically\nlocated on the cloud and the device separately, while existing RAG\nimplementations are primarily centralized. To bridge this gap, we propose\nDRAGON, a distributed RAG framework to enhance on-device SLMs through both\ngeneral and personal knowledge without the risk of leaking document privacy.\nSpecifically, DRAGON decomposes multi-document RAG into multiple parallel token\ngeneration processes performed independently and locally on the cloud and the\ndevice, and employs a newly designed Speculative Aggregation, a dual-side\nspeculative algorithm to avoid frequent output synchronization between the\ncloud and device. A new scheduling algorithm is further introduced to identify\nthe optimal aggregation side based on real-time network conditions. Evaluations\non real-world hardware testbed demonstrate a significant performance\nimprovement of DRAGON-up to 1.9x greater gains over standalone SLM compared to\nthe centralized RAG, substantial reduction in per-token latency, and negligible\nTime to First Token (TTFT) overhead.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC",
      "cs.IR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.11197v2",
    "published_date": "2025-04-15 13:53:08 UTC",
    "updated_date": "2025-04-16 03:32:23 UTC"
  },
  {
    "arxiv_id": "2504.11190v1",
    "title": "Enhancing multimodal analogical reasoning with Logic Augmented Generation",
    "authors": [
      "Anna Sofia Lippolis",
      "Andrea Giovanni Nuzzolese",
      "Aldo Gangemi"
    ],
    "abstract": "Recent advances in Large Language Models have demonstrated their capabilities\nacross a variety of tasks. However, automatically extracting implicit knowledge\nfrom natural language remains a significant challenge, as machines lack active\nexperience with the physical world. Given this scenario, semantic knowledge\ngraphs can serve as conceptual spaces that guide the automated text generation\nreasoning process to achieve more efficient and explainable results. In this\npaper, we apply a logic-augmented generation (LAG) framework that leverages the\nexplicit representation of a text through a semantic knowledge graph and\napplies it in combination with prompt heuristics to elicit implicit analogical\nconnections. This method generates extended knowledge graph triples\nrepresenting implicit meaning, enabling systems to reason on unlabeled\nmultimodal data regardless of the domain. We validate our work through three\nmetaphor detection and understanding tasks across four datasets, as they\nrequire deep analogical reasoning capabilities. The results show that this\nintegrated approach surpasses current baselines, performs better than humans in\nunderstanding visual metaphors, and enables more explainable reasoning\nprocesses, though still has inherent limitations in metaphor understanding,\nespecially for domain-specific metaphors. Furthermore, we propose a thorough\nerror analysis, discussing issues with metaphorical annotations and current\nevaluation methods.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.11190v1",
    "published_date": "2025-04-15 13:47:55 UTC",
    "updated_date": "2025-04-15 13:47:55 UTC"
  },
  {
    "arxiv_id": "2504.11186v1",
    "title": "Benchmarking Next-Generation Reasoning-Focused Large Language Models in Ophthalmology: A Head-to-Head Evaluation on 5,888 Items",
    "authors": [
      "Minjie Zou",
      "Sahana Srinivasan",
      "Thaddaeus Wai Soon Lo",
      "Ke Zou",
      "Gabriel Dawei Yang",
      "Xuguang Ai",
      "Hyunjae Kim",
      "Maxwell Singer",
      "Fares Antaki",
      "Kelvin Li",
      "Robert Chang",
      "Marcus Tan",
      "David Ziyou Chen",
      "Dianbo Liu",
      "Qingyu Chen",
      "Yih Chung Tham"
    ],
    "abstract": "Recent advances in reasoning-focused large language models (LLMs) mark a\nshift from general LLMs toward models designed for complex decision-making, a\ncrucial aspect in medicine. However, their performance in specialized domains\nlike ophthalmology remains underexplored. This study comprehensively evaluated\nand compared the accuracy and reasoning capabilities of four newly developed\nreasoning-focused LLMs, namely DeepSeek-R1, OpenAI o1, o3-mini, and Gemini 2.0\nFlash-Thinking. Each model was assessed using 5,888 multiple-choice\nophthalmology exam questions from the MedMCQA dataset in zero-shot setting.\nQuantitative evaluation included accuracy, Macro-F1, and five text-generation\nmetrics (ROUGE-L, METEOR, BERTScore, BARTScore, and AlignScore), computed\nagainst ground-truth reasonings. Average inference time was recorded for a\nsubset of 100 randomly selected questions. Additionally, two board-certified\nophthalmologists qualitatively assessed clarity, completeness, and reasoning\nstructure of responses to differential diagnosis questions.O1 (0.902) and\nDeepSeek-R1 (0.888) achieved the highest accuracy, with o1 also leading in\nMacro-F1 (0.900). The performance of models across the text-generation metrics\nvaried: O3-mini excelled in ROUGE-L (0.151), o1 in METEOR (0.232), DeepSeek-R1\nand o3-mini tied for BERTScore (0.673), DeepSeek-R1 (-4.105) and Gemini 2.0\nFlash-Thinking (-4.127) performed best in BARTScore, while o3-mini (0.181) and\no1 (0.176) led AlignScore. Inference time across the models varied, with\nDeepSeek-R1 being slowest (40.4 seconds) and Gemini 2.0 Flash-Thinking fastest\n(6.7 seconds). Qualitative evaluation revealed that DeepSeek-R1 and Gemini 2.0\nFlash-Thinking tended to provide detailed and comprehensive intermediate\nreasoning, whereas o1 and o3-mini displayed concise and summarized\njustifications.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "83 pages, 6 figures, 3 tables, 9 supplementary figures, 7\n  supplementary tables",
    "pdf_url": "http://arxiv.org/pdf/2504.11186v1",
    "published_date": "2025-04-15 13:42:34 UTC",
    "updated_date": "2025-04-15 13:42:34 UTC"
  },
  {
    "arxiv_id": "2504.11182v1",
    "title": "Exploring Backdoor Attack and Defense for LLM-empowered Recommendations",
    "authors": [
      "Liangbo Ning",
      "Wenqi Fan",
      "Qing Li"
    ],
    "abstract": "The fusion of Large Language Models (LLMs) with recommender systems (RecSys)\nhas dramatically advanced personalized recommendations and drawn extensive\nattention. Despite the impressive progress, the safety of LLM-based RecSys\nagainst backdoor attacks remains largely under-explored. In this paper, we\nraise a new problem: Can a backdoor with a specific trigger be injected into\nLLM-based Recsys, leading to the manipulation of the recommendation responses\nwhen the backdoor trigger is appended to an item's title? To investigate the\nvulnerabilities of LLM-based RecSys under backdoor attacks, we propose a new\nattack framework termed Backdoor Injection Poisoning for RecSys (BadRec).\nBadRec perturbs the items' titles with triggers and employs several fake users\nto interact with these items, effectively poisoning the training set and\ninjecting backdoors into LLM-based RecSys. Comprehensive experiments reveal\nthat poisoning just 1% of the training data with adversarial examples is\nsufficient to successfully implant backdoors, enabling manipulation of\nrecommendations. To further mitigate such a security threat, we propose a\nuniversal defense strategy called Poison Scanner (P-Scanner). Specifically, we\nintroduce an LLM-based poison scanner to detect the poisoned items by\nleveraging the powerful language understanding and rich knowledge of LLMs. A\ntrigger augmentation agent is employed to generate diverse synthetic triggers\nto guide the poison scanner in learning domain-specific knowledge of the\npoisoned item detection task. Extensive experiments on three real-world\ndatasets validate the effectiveness of the proposed P-Scanner.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.11182v1",
    "published_date": "2025-04-15 13:37:38 UTC",
    "updated_date": "2025-04-15 13:37:38 UTC"
  },
  {
    "arxiv_id": "2504.11171v1",
    "title": "TerraMind: Large-Scale Generative Multimodality for Earth Observation",
    "authors": [
      "Johannes Jakubik",
      "Felix Yang",
      "Benedikt Blumenstiel",
      "Erik Scheurer",
      "Rocco Sedona",
      "Stefano Maurogiovanni",
      "Jente Bosmans",
      "Nikolaos Dionelis",
      "Valerio Marsocci",
      "Niklas Kopp",
      "Rahul Ramachandran",
      "Paolo Fraccaro",
      "Thomas Brunschwiler",
      "Gabriele Cavallaro",
      "Juan Bernabe-Moreno",
      "Nicolas Long√©p√©"
    ],
    "abstract": "We present TerraMind, the first any-to-any generative, multimodal foundation\nmodel for Earth observation (EO). Unlike other multimodal models, TerraMind is\npretrained on dual-scale representations combining both token-level and\npixel-level data across modalities. On a token level, TerraMind encodes\nhigh-level contextual information to learn cross-modal relationships, while on\na pixel level, TerraMind leverages fine-grained representations to capture\ncritical spatial nuances. We pretrained TerraMind on nine geospatial modalities\nof a global, large-scale dataset. In this paper, we demonstrate that (i)\nTerraMind's dual-scale early fusion approach unlocks a range of zero-shot and\nfew-shot applications for Earth observation, (ii) TerraMind introduces\n\"Thinking-in-Modalities\" (TiM) -- the capability of generating additional\nartificial data during finetuning and inference to improve the model output --\nand (iii) TerraMind achieves beyond state-of-the-art performance in\ncommunity-standard benchmarks for EO like PANGAEA. The pretraining dataset, the\nmodel weights, and our code is open-sourced under a permissive license.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.11171v1",
    "published_date": "2025-04-15 13:17:39 UTC",
    "updated_date": "2025-04-15 13:17:39 UTC"
  },
  {
    "arxiv_id": "2504.11169v1",
    "title": "MuSeD: A Multimodal Spanish Dataset for Sexism Detection in Social Media Videos",
    "authors": [
      "Laura De Grazia",
      "Pol Pastells",
      "Mauro V√°zquez Chas",
      "Desmond Elliott",
      "Danae S√°nchez Villegas",
      "Mireia Farr√∫s",
      "Mariona Taul√©"
    ],
    "abstract": "Sexism is generally defined as prejudice and discrimination based on sex or\ngender, affecting every sector of society, from social institutions to\nrelationships and individual behavior. Social media platforms amplify the\nimpact of sexism by conveying discriminatory content not only through text but\nalso across multiple modalities, highlighting the critical need for a\nmultimodal approach to the analysis of sexism online. With the rise of social\nmedia platforms where users share short videos, sexism is increasingly\nspreading through video content. Automatically detecting sexism in videos is a\nchallenging task, as it requires analyzing the combination of verbal, audio,\nand visual elements to identify sexist content. In this study, (1) we introduce\nMuSeD, a new Multimodal Spanish dataset for Sexism Detection consisting of\n$\\approx$ 11 hours of videos extracted from TikTok and BitChute; (2) we propose\nan innovative annotation framework for analyzing the contribution of textual\nand multimodal labels in the classification of sexist and non-sexist content;\nand (3) we evaluate a range of large language models (LLMs) and multimodal LLMs\non the task of sexism detection. We find that visual information plays a key\nrole in labeling sexist content for both humans and models. Models effectively\ndetect explicit sexism; however, they struggle with implicit cases, such as\nstereotypes, instances where annotators also show low agreement. This\nhighlights the inherent difficulty of the task, as identifying implicit sexism\ndepends on the social and cultural context.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.11169v1",
    "published_date": "2025-04-15 13:16:46 UTC",
    "updated_date": "2025-04-15 13:16:46 UTC"
  },
  {
    "arxiv_id": "2504.11168v2",
    "title": "Bypassing Prompt Injection and Jailbreak Detection in LLM Guardrails",
    "authors": [
      "William Hackett",
      "Lewis Birch",
      "Stefan Trawicki",
      "Neeraj Suri",
      "Peter Garraghan"
    ],
    "abstract": "Large Language Models (LLMs) guardrail systems are designed to protect\nagainst prompt injection and jailbreak attacks. However, they remain vulnerable\nto evasion techniques. We demonstrate two approaches for bypassing LLM prompt\ninjection and jailbreak detection systems via traditional character injection\nmethods and algorithmic Adversarial Machine Learning (AML) evasion techniques.\nThrough testing against six prominent protection systems, including Microsoft's\nAzure Prompt Shield and Meta's Prompt Guard, we show that both methods can be\nused to evade detection while maintaining adversarial utility achieving in some\ninstances up to 100% evasion success. Furthermore, we demonstrate that\nadversaries can enhance Attack Success Rates (ASR) against black-box targets by\nleveraging word importance ranking computed by offline white-box models. Our\nfindings reveal vulnerabilities within current LLM protection mechanisms and\nhighlight the need for more robust guardrail systems.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG",
      "I.2.7"
    ],
    "primary_category": "cs.CR",
    "comment": "12 pages, 5 figures, 6 tables",
    "pdf_url": "http://arxiv.org/pdf/2504.11168v2",
    "published_date": "2025-04-15 13:16:02 UTC",
    "updated_date": "2025-04-16 15:33:06 UTC"
  },
  {
    "arxiv_id": "2504.11160v1",
    "title": "DMAGaze: Gaze Estimation Based on Feature Disentanglement and Multi-Scale Attention",
    "authors": [
      "Haohan Chen",
      "Hongjia Liu",
      "Shiyong Lan",
      "Wenwu Wang",
      "Yixin Qiao",
      "Yao Li",
      "Guonan Deng"
    ],
    "abstract": "Gaze estimation, which predicts gaze direction, commonly faces the challenge\nof interference from complex gaze-irrelevant information in face images. In\nthis work, we propose DMAGaze, a novel gaze estimation framework that exploits\ninformation from facial images in three aspects: gaze-relevant global features\n(disentangled from facial image), local eye features (extracted from cropped\neye patch), and head pose estimation features, to improve overall performance.\nFirstly, we design a new continuous mask-based Disentangler to accurately\ndisentangle gaze-relevant and gaze-irrelevant information in facial images by\nachieving the dual-branch disentanglement goal through separately\nreconstructing the eye and non-eye regions. Furthermore, we introduce a new\ncascaded attention module named Multi-Scale Global Local Attention Module\n(MS-GLAM). Through a customized cascaded attention structure, it effectively\nfocuses on global and local information at multiple scales, further enhancing\nthe information from the Disentangler. Finally, the global gaze-relevant\nfeatures disentangled by the upper face branch, combined with head pose and\nlocal eye features, are passed through the detection head for high-precision\ngaze estimation. Our proposed DMAGaze has been extensively validated on two\nmainstream public datasets, achieving state-of-the-art performance.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.11160v1",
    "published_date": "2025-04-15 13:08:43 UTC",
    "updated_date": "2025-04-15 13:08:43 UTC"
  },
  {
    "arxiv_id": "2504.11159v1",
    "title": "C-SHAP for time series: An approach to high-level temporal explanations",
    "authors": [
      "Annemarie Jutte",
      "Faizan Ahmed",
      "Jeroen Linssen",
      "Maurice van Keulen"
    ],
    "abstract": "Time series are ubiquitous in domains such as energy forecasting, healthcare,\nand industry. Using AI systems, some tasks within these domains can be\nefficiently handled. Explainable AI (XAI) aims to increase the reliability of\nAI solutions by explaining model reasoning. For time series, many XAI methods\nprovide point- or sequence-based attribution maps. These methods explain model\nreasoning in terms of low-level patterns. However, they do not capture\nhigh-level patterns that may also influence model reasoning. We propose a\nconcept-based method to provide explanations in terms of these high-level\npatterns. In this paper, we present C-SHAP for time series, an approach which\ndetermines the contribution of concepts to a model outcome. We provide a\ngeneral definition of C-SHAP and present an example implementation using time\nseries decomposition. Additionally, we demonstrate the effectiveness of the\nmethodology through a use case from the energy domain.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "10 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.11159v1",
    "published_date": "2025-04-15 13:06:32 UTC",
    "updated_date": "2025-04-15 13:06:32 UTC"
  },
  {
    "arxiv_id": "2504.11130v1",
    "title": "Divergence of Empirical Neural Tangent Kernel in Classification Problems",
    "authors": [
      "Zixiong Yu",
      "Songtao Tian",
      "Guhan Chen"
    ],
    "abstract": "This paper demonstrates that in classification problems, fully connected\nneural networks (FCNs) and residual neural networks (ResNets) cannot be\napproximated by kernel logistic regression based on the Neural Tangent Kernel\n(NTK) under overtraining (i.e., when training time approaches infinity).\nSpecifically, when using the cross-entropy loss, regardless of how large the\nnetwork width is (as long as it is finite), the empirical NTK diverges from the\nNTK on the training samples as training time increases. To establish this\nresult, we first demonstrate the strictly positive definiteness of the NTKs for\nmulti-layer FCNs and ResNets. Then, we prove that during training, % with the\ncross-entropy loss, the neural network parameters diverge if the smallest\neigenvalue of the empirical NTK matrix (Gram matrix) with respect to training\nsamples is bounded below by a positive constant. This behavior contrasts\nsharply with the lazy training regime commonly observed in regression problems.\nConsequently, using a proof by contradiction, we show that the empirical NTK\ndoes not uniformly converge to the NTK across all times on the training samples\nas the network width increases. We validate our theoretical results through\nexperiments on both synthetic data and the MNIST classification task. This\nfinding implies that NTK theory is not applicable in this context, with\nsignificant theoretical implications for understanding neural networks in\nclassification problems.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.11130v1",
    "published_date": "2025-04-15 12:30:21 UTC",
    "updated_date": "2025-04-15 12:30:21 UTC"
  },
  {
    "arxiv_id": "2504.11109v1",
    "title": "Fine-Tuning Large Language Models on Quantum Optimization Problems for Circuit Generation",
    "authors": [
      "Linus Jern",
      "Valter Uotila",
      "Cong Yu",
      "Bo Zhao"
    ],
    "abstract": "Large language models (LLM) have achieved remarkable outcomes in addressing\ncomplex problems, including math, coding, and analyzing large amounts of\nscientific reports. Yet few works have explored the potential of LLM in quantum\ncomputing. The most challenging problem is how to leverage LLMs to\nautomatically generate quantum circuits at a large scale. In this paper, we\naddress such a challenge by fine-tuning LLMs and injecting the domain-specific\nknowledge of quantum computing. In particular, we investigate the mechanisms to\ngenerate training data sets and construct the end-to-end pipeline to fine-tune\npre-trained LLMs that produce parameterized quantum circuits for optimization\nproblems. We have prepared 14,000 quantum circuits covering a substantial part\nof the quantum optimization landscape: 12 optimization problem instances and\ntheir optimized QAOA, VQE, and adaptive VQE circuits. The fine-tuned LLMs can\nconstruct syntactically correct parametrized quantum circuits in the most\nrecent OpenQASM 3.0. We have evaluated the quality of the parameters by\ncomparing them to the optimized expectation values and distributions. Our\nevaluation shows that the fine-tuned LLM outperforms state-of-the-art models\nand that the parameters are better than random. The LLM-generated parametrized\ncircuits and initial parameters can be used as a starting point for further\noptimization, \\emph{e.g.,} templates in quantum machine learning and the\nbenchmark for compilers and hardware.",
    "categories": [
      "quant-ph",
      "cs.AI"
    ],
    "primary_category": "quant-ph",
    "comment": "12 pages, 8 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2504.11109v1",
    "published_date": "2025-04-15 11:56:54 UTC",
    "updated_date": "2025-04-15 11:56:54 UTC"
  },
  {
    "arxiv_id": "2504.11091v1",
    "title": "AI-guided Antibiotic Discovery Pipeline from Target Selection to Compound Identification",
    "authors": [
      "Maximilian G. Schuh",
      "Joshua Hesse",
      "Stephan A. Sieber"
    ],
    "abstract": "Antibiotic resistance presents a growing global health crisis, demanding new\ntherapeutic strategies that target novel bacterial mechanisms. Recent advances\nin protein structure prediction and machine learning-driven molecule generation\noffer a promising opportunity to accelerate drug discovery. However, practical\nguidance on selecting and integrating these models into real-world pipelines\nremains limited. In this study, we develop an end-to-end, artificial\nintelligence-guided antibiotic discovery pipeline that spans target\nidentification to compound realization. We leverage structure-based clustering\nacross predicted proteomes of multiple pathogens to identify conserved,\nessential, and non-human-homologous targets. We then systematically evaluate\nsix leading 3D-structure-aware generative models$\\unicode{x2014}$spanning\ndiffusion, autoregressive, graph neural network, and language model\narchitectures$\\unicode{x2014}$on their usability, chemical validity, and\nbiological relevance. Rigorous post-processing filters and commercial analogue\nsearches reduce over 100 000 generated compounds to a focused, synthesizable\nset. Our results highlight DeepBlock and TamGen as top performers across\ndiverse criteria, while also revealing critical trade-offs between model\ncomplexity, usability, and output quality. This work provides a comparative\nbenchmark and blueprint for deploying artificial intelligence in early-stage\nantibiotic development.",
    "categories": [
      "q-bio.BM",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.BM",
    "comment": "12 pages, preprint",
    "pdf_url": "http://arxiv.org/pdf/2504.11091v1",
    "published_date": "2025-04-15 11:36:27 UTC",
    "updated_date": "2025-04-15 11:36:27 UTC"
  },
  {
    "arxiv_id": "2504.11083v1",
    "title": "QAMA: Quantum annealing multi-head attention operator with classical deep learning framework",
    "authors": [
      "Peng Du",
      "Shuolei Wang",
      "Shicheng Li",
      "Jinjing Shi"
    ],
    "abstract": "As large language models scale up, the conventional attention mechanism faces\ncritical challenges of exponential growth in memory consumption and energy\ncosts. Quantum annealing computing, with its inherent advantages in\ncomputational efficiency and low energy consumption, offers an innovative\ndirection for constructing novel deep learning architectures. This study\nproposes the first Quantum Annealing-based Multi-head Attention (QAMA)\nmechanism, achieving seamless compatibility with classical attention\narchitectures through quadratic unconstrained binary optimization (QUBO)\nmodeling of forward propagation and energy-based backpropagation. The method\ninnovatively leverages the quantum bit interaction characteristics of Ising\nmodels to optimize the conventional $O(n^2)$ spatiotemporal complexity into\nlinear resource consumption. Integrated with the optical computing advantages\nof coherent Ising machines (CIM), the system maintains millisecond-level\nreal-time responsiveness while significantly reducing energy consumption. Our\nkey contributions include: Theoretical proofs establish QAMA mathematical\nequivalence to classical attention mechanisms; Dual optimization of multi-head\nspecificity and long-range information capture via QUBO constraints; Explicit\ngradient proofs for the Ising energy equation are utilized to implement\ngradient conduction as the only path in the computational graph as a layer;\nProposed soft selection mechanism overcoming traditional binary attention\nlimitations to approximate continuous weights. Experiments on QBoson CPQC\nquantum computer show QAMA achieves comparable accuracy to classical operators\nwhile reducing inference time to millisecond level and improving solution\nquality. This work pioneers architectural-level integration of quantum\ncomputing and deep learning, applicable to any attention-based model, driving\nparadigm innovation in AI foundational computing.",
    "categories": [
      "quant-ph",
      "cs.AI"
    ],
    "primary_category": "quant-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.11083v1",
    "published_date": "2025-04-15 11:29:09 UTC",
    "updated_date": "2025-04-15 11:29:09 UTC"
  },
  {
    "arxiv_id": "2504.11082v1",
    "title": "DeepMLF: Multimodal language model with learnable tokens for deep fusion in sentiment analysis",
    "authors": [
      "Efthymios Georgiou",
      "Vassilis Katsouros",
      "Yannis Avrithis",
      "Alexandros Potamianos"
    ],
    "abstract": "While multimodal fusion has been extensively studied in Multimodal Sentiment\nAnalysis (MSA), the role of fusion depth and multimodal capacity allocation\nremains underexplored. In this work, we position fusion depth, scalability, and\ndedicated multimodal capacity as primary factors for effective fusion. We\nintroduce DeepMLF, a novel multimodal language model (LM) with learnable tokens\ntailored toward deep fusion. DeepMLF leverages an audiovisual encoder and a\npretrained decoder LM augmented with multimodal information across its layers.\nWe append learnable tokens to the LM that: 1) capture modality interactions in\na controlled fashion and 2) preserve independent information flow for each\nmodality. These fusion tokens gather linguistic information via causal\nself-attention in LM Blocks and integrate with audiovisual information through\ncross-attention MM Blocks. Serving as dedicated multimodal capacity, this\ndesign enables progressive fusion across multiple layers, providing depth in\nthe fusion process. Our training recipe combines modality-specific losses and\nlanguage modelling loss, with the decoder LM tasked to predict ground truth\npolarity. Across three MSA benchmarks with varying dataset characteristics,\nDeepMLF achieves state-of-the-art performance. Our results confirm that deeper\nfusion leads to better performance, with optimal fusion depths (5-7) exceeding\nthose of existing approaches. Additionally, our analysis on the number of\nfusion tokens reveals that small token sets ($\\sim$20) achieve optimal\nperformance. We examine the importance of representation learning order (fusion\ncurriculum) through audiovisual encoder initialization experiments. Our\nablation studies demonstrate the superiority of the proposed fusion design and\ngating while providing a holistic examination of DeepMLF's scalability to LLMs,\nand the impact of each training objective and embedding regularization.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Preprint",
    "pdf_url": "http://arxiv.org/pdf/2504.11082v1",
    "published_date": "2025-04-15 11:28:02 UTC",
    "updated_date": "2025-04-15 11:28:02 UTC"
  },
  {
    "arxiv_id": "2504.11075v1",
    "title": "Emergence of Goal-Directed Behaviors via Active Inference with Self-Prior",
    "authors": [
      "Dongmin Kim",
      "Hoshinori Kanazawa",
      "Naoto Yoshida",
      "Yasuo Kuniyoshi"
    ],
    "abstract": "Infants often exhibit goal-directed behaviors, such as reaching for a sensory\nstimulus, even when no external reward criterion is provided. These\nintrinsically motivated behaviors facilitate spontaneous exploration and\nlearning of the body and environment during early developmental stages.\nAlthough computational modeling can offer insight into the mechanisms\nunderlying such behaviors, many existing studies on intrinsic motivation focus\nprimarily on how exploration contributes to acquiring external rewards. In this\npaper, we propose a novel density model for an agent's own multimodal sensory\nexperiences, called the \"self-prior,\" and investigate whether it can\nautonomously induce goal-directed behavior. Integrated within an active\ninference framework based on the free energy principle, the self-prior\ngenerates behavioral references purely from an intrinsic process that minimizes\nmismatches between average past sensory experiences and current observations.\nThis mechanism is also analogous to the acquisition and utilization of a body\nschema through continuous interaction with the environment. We examine this\napproach in a simulated environment and confirm that the agent spontaneously\nreaches toward a tactile stimulus. Our study implements intrinsically motivated\nbehavior shaped by the agent's own sensory experiences, demonstrating the\nspontaneous emergence of intentional behavior during early development.",
    "categories": [
      "cs.AI",
      "68T05, 68T40, 68T42",
      "I.2.0; I.2.6; I.2.9"
    ],
    "primary_category": "cs.AI",
    "comment": "20 pages, Code is available at\n  https://github.com/kim135797531/self-prior",
    "pdf_url": "http://arxiv.org/pdf/2504.11075v1",
    "published_date": "2025-04-15 11:16:27 UTC",
    "updated_date": "2025-04-15 11:16:27 UTC"
  },
  {
    "arxiv_id": "2504.11074v2",
    "title": "Dynamical errors in machine learning forecasts",
    "authors": [
      "Zhou Fang",
      "Gianmarco Mengaldo"
    ],
    "abstract": "In machine learning forecasting, standard error metrics such as mean absolute\nerror (MAE) and mean squared error (MSE) quantify discrepancies between\npredictions and target values. However, these metrics do not directly evaluate\nthe physical and/or dynamical consistency of forecasts, an increasingly\ncritical concern in scientific and engineering applications.\n  Indeed, a fundamental yet often overlooked question is whether machine\nlearning forecasts preserve the dynamical behavior of the underlying system.\nAddressing this issue is essential for assessing the fidelity of machine\nlearning models and identifying potential failure modes, particularly in\napplications where maintaining correct dynamical behavior is crucial.\n  In this work, we investigate the relationship between standard forecasting\nerror metrics, such as MAE and MSE, and the dynamical properties of the\nunderlying system. To achieve this goal, we use two recently developed\ndynamical indices: the instantaneous dimension ($d$), and the inverse\npersistence ($\\theta$). Our results indicate that larger forecast errors --\ne.g., higher MSE -- tend to occur in states with higher $d$ (higher complexity)\nand higher $\\theta$ (lower persistence). To further assess dynamical\nconsistency, we propose error metrics based on the dynamical indices that\nmeasure the discrepancy of the forecasted $d$ and $\\theta$ versus their correct\nvalues. Leveraging these dynamical indices-based metrics, we analyze direct and\nrecursive forecasting strategies for three canonical datasets -- Lorenz,\nKuramoto-Sivashinsky equation, and Kolmogorov flow -- as well as a real-world\nweather forecasting task. Our findings reveal substantial distortions in\ndynamical properties in ML forecasts, especially for long forecast lead times\nor long recursive simulations, providing complementary information on ML\nforecast fidelity that can be used to improve ML models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.comp-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.11074v2",
    "published_date": "2025-04-15 11:16:13 UTC",
    "updated_date": "2025-04-16 08:48:34 UTC"
  },
  {
    "arxiv_id": "2504.11045v1",
    "title": "Neural Control Barrier Functions from Physics Informed Neural Networks",
    "authors": [
      "Shreenabh Agrawal",
      "Manan Tayal",
      "Aditya Singh",
      "Shishir Kolathaya"
    ],
    "abstract": "As autonomous systems become increasingly prevalent in daily life, ensuring\ntheir safety is paramount. Control Barrier Functions (CBFs) have emerged as an\neffective tool for guaranteeing safety; however, manually designing them for\nspecific applications remains a significant challenge. With the advent of deep\nlearning techniques, recent research has explored synthesizing CBFs using\nneural networks-commonly referred to as neural CBFs. This paper introduces a\nnovel class of neural CBFs that leverages a physics-inspired neural network\nframework by incorporating Zubov's Partial Differential Equation (PDE) within\nthe context of safety. This approach provides a scalable methodology for\nsynthesizing neural CBFs applicable to high-dimensional systems. Furthermore,\nby utilizing reciprocal CBFs instead of zeroing CBFs, the proposed framework\nallows for the specification of flexible, user-defined safe regions. To\nvalidate the effectiveness of the approach, we present case studies on three\ndifferent systems: an inverted pendulum, autonomous ground navigation, and\naerial navigation in obstacle-laden environments.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO",
    "comment": "8 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.11045v1",
    "published_date": "2025-04-15 10:13:30 UTC",
    "updated_date": "2025-04-15 10:13:30 UTC"
  },
  {
    "arxiv_id": "2504.11038v1",
    "title": "QAVA: Query-Agnostic Visual Attack to Large Vision-Language Models",
    "authors": [
      "Yudong Zhang",
      "Ruobing Xie",
      "Jiansheng Chen",
      "Xingwu Sun",
      "Zhanhui Kang",
      "Yu Wang"
    ],
    "abstract": "In typical multimodal tasks, such as Visual Question Answering (VQA),\nadversarial attacks targeting a specific image and question can lead large\nvision-language models (LVLMs) to provide incorrect answers. However, it is\ncommon for a single image to be associated with multiple questions, and LVLMs\nmay still answer other questions correctly even for an adversarial image\nattacked by a specific question. To address this, we introduce the\nquery-agnostic visual attack (QAVA), which aims to create robust adversarial\nexamples that generate incorrect responses to unspecified and unknown\nquestions. Compared to traditional adversarial attacks focused on specific\nimages and questions, QAVA significantly enhances the effectiveness and\nefficiency of attacks on images when the question is unknown, achieving\nperformance comparable to attacks on known target questions. Our research\nbroadens the scope of visual adversarial attacks on LVLMs in practical\nsettings, uncovering previously overlooked vulnerabilities, particularly in the\ncontext of visual adversarial threats. The code is available at\nhttps://github.com/btzyd/qava.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by NAACL 2025 main",
    "pdf_url": "http://arxiv.org/pdf/2504.11038v1",
    "published_date": "2025-04-15 10:00:01 UTC",
    "updated_date": "2025-04-15 10:00:01 UTC"
  },
  {
    "arxiv_id": "2504.11020v1",
    "title": "\"Even explanations will not help in trusting [this] fundamentally biased system\": A Predictive Policing Case-Study",
    "authors": [
      "Siddharth Mehrotra",
      "Ujwal Gadiraju",
      "Eva Bittner",
      "Folkert van Delden",
      "Catholijn M. Jonker",
      "Myrthe L. Tielman"
    ],
    "abstract": "In today's society, where Artificial Intelligence (AI) has gained a vital\nrole, concerns regarding user's trust have garnered significant attention. The\nuse of AI systems in high-risk domains have often led users to either\nunder-trust it, potentially causing inadequate reliance or over-trust it,\nresulting in over-compliance. Therefore, users must maintain an appropriate\nlevel of trust. Past research has indicated that explanations provided by AI\nsystems can enhance user understanding of when to trust or not trust the\nsystem. However, the utility of presentation of different explanations forms\nstill remains to be explored especially in high-risk domains. Therefore, this\nstudy explores the impact of different explanation types (text, visual, and\nhybrid) and user expertise (retired police officers and lay users) on\nestablishing appropriate trust in AI-based predictive policing. While we\nobserved that the hybrid form of explanations increased the subjective trust in\nAI for expert users, it did not led to better decision-making. Furthermore, no\nform of explanations helped build appropriate trust. The findings of our study\nemphasize the importance of re-evaluating the use of explanations to build\n[appropriate] trust in AI based systems especially when the system's use is\nquestionable. Finally, we synthesize potential challenges and policy\nrecommendations based on our results to design for appropriate trust in\nhigh-risk based AI-based systems.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "33rd ACM Conference on User Modeling, Adaptation and Personalization\n  (UMAP '25), June 16--19, 2025, New York City, NY, USA",
    "pdf_url": "http://arxiv.org/pdf/2504.11020v1",
    "published_date": "2025-04-15 09:43:48 UTC",
    "updated_date": "2025-04-15 09:43:48 UTC"
  },
  {
    "arxiv_id": "2504.11014v2",
    "title": "GATE3D: Generalized Attention-based Task-synergized Estimation in 3D*",
    "authors": [
      "Eunsoo Im",
      "Jung Kwon Lee",
      "Changhyun Jee"
    ],
    "abstract": "The emerging trend in computer vision emphasizes developing universal models\ncapable of simultaneously addressing multiple diverse tasks. Such universality\ntypically requires joint training across multi-domain datasets to ensure\neffective generalization. However, monocular 3D object detection presents\nunique challenges in multi-domain training due to the scarcity of datasets\nannotated with accurate 3D ground-truth labels, especially beyond typical\nroad-based autonomous driving contexts. To address this challenge, we introduce\na novel weakly supervised framework leveraging pseudo-labels. Current\npretrained models often struggle to accurately detect pedestrians in non-road\nenvironments due to inherent dataset biases. Unlike generalized image-based 2D\nobject detection models, achieving similar generalization in monocular 3D\ndetection remains largely unexplored. In this paper, we propose GATE3D, a novel\nframework designed specifically for generalized monocular 3D object detection\nvia weak supervision. GATE3D effectively bridges domain gaps by employing\nconsistency losses between 2D and 3D predictions. Remarkably, our model\nachieves competitive performance on the KITTI benchmark as well as on an\nindoor-office dataset collected by us to evaluate the generalization\ncapabilities of our framework. Our results demonstrate that GATE3D\nsignificantly accelerates learning from limited annotated data through\neffective pre-training strategies, highlighting substantial potential for\nbroader impacts in robotics, augmented reality, and virtual reality\napplications. Project page: https://ies0411.github.io/GATE3D/",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "9pages, 1 supple",
    "pdf_url": "http://arxiv.org/pdf/2504.11014v2",
    "published_date": "2025-04-15 09:37:54 UTC",
    "updated_date": "2025-04-16 01:38:27 UTC"
  },
  {
    "arxiv_id": "2504.11011v1",
    "title": "Document Quality Scoring for Web Crawling",
    "authors": [
      "Francesca Pezzuti",
      "Ariane Mueller",
      "Sean MacAvaney",
      "Nicola Tonellotto"
    ],
    "abstract": "The internet contains large amounts of low-quality content, yet users expect\nweb search engines to deliver high-quality, relevant results. The abundant\npresence of low-quality pages can negatively impact retrieval and crawling\nprocesses by wasting resources on these documents. Therefore, search engines\ncan greatly benefit from techniques that leverage efficient quality estimation\nmethods to mitigate these negative impacts. Quality scoring methods for web\npages are useful for many processes typical for web search systems, including\nstatic index pruning, index tiering, and crawling. Building on work by Chang et\nal.~\\cite{chang2024neural}, who proposed using neural estimators of semantic\nquality for static index pruning, we extend their approach and apply their\nneural quality scorers to assess the semantic quality of web pages in crawling\nprioritisation tasks. In our experimental analysis, we found that prioritising\nsemantically high-quality pages over low-quality ones can improve downstream\nsearch effectiveness. Our software contribution consists of a Docker container\nthat computes an effective quality score for a given web page, allowing the\nquality scorer to be easily included and used in other components of web search\nsystems.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "Presented at WOWS2025",
    "pdf_url": "http://arxiv.org/pdf/2504.11011v1",
    "published_date": "2025-04-15 09:32:57 UTC",
    "updated_date": "2025-04-15 09:32:57 UTC"
  },
  {
    "arxiv_id": "2504.11008v1",
    "title": "MediSee: Reasoning-based Pixel-level Perception in Medical Images",
    "authors": [
      "Qinyue Tong",
      "Ziqian Lu",
      "Jun Liu",
      "Yangming Zheng",
      "Zheming Lu"
    ],
    "abstract": "Despite remarkable advancements in pixel-level medical image perception,\nexisting methods are either limited to specific tasks or heavily rely on\naccurate bounding boxes or text labels as input prompts. However, the medical\nknowledge required for input is a huge obstacle for general public, which\ngreatly reduces the universality of these methods. Compared with these\ndomain-specialized auxiliary information, general users tend to rely on oral\nqueries that require logical reasoning. In this paper, we introduce a novel\nmedical vision task: Medical Reasoning Segmentation and Detection (MedSD),\nwhich aims to comprehend implicit queries about medical images and generate the\ncorresponding segmentation mask and bounding box for the target object. To\naccomplish this task, we first introduce a Multi-perspective, Logic-driven\nMedical Reasoning Segmentation and Detection (MLMR-SD) dataset, which\nencompasses a substantial collection of medical entity targets along with their\ncorresponding reasoning. Furthermore, we propose MediSee, an effective baseline\nmodel designed for medical reasoning segmentation and detection. The\nexperimental results indicate that the proposed method can effectively address\nMedSD with implicit colloquial queries and outperform traditional medical\nreferring segmentation methods.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "10 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.11008v1",
    "published_date": "2025-04-15 09:28:53 UTC",
    "updated_date": "2025-04-15 09:28:53 UTC"
  },
  {
    "arxiv_id": "2504.11004v1",
    "title": "Dynamic Compressing Prompts for Efficient Inference of Large Language Models",
    "authors": [
      "Jinwu Hu",
      "Wei Zhang",
      "Yufeng Wang",
      "Yu Hu",
      "Bin Xiao",
      "Mingkui Tan",
      "Qing Du"
    ],
    "abstract": "Large Language Models (LLMs) have shown outstanding performance across a\nvariety of tasks, partly due to advanced prompting techniques. However, these\ntechniques often require lengthy prompts, which increase computational costs\nand can hinder performance because of the limited context windows of LLMs.\nWhile prompt compression is a straightforward solution, existing methods\nconfront the challenges of retaining essential information, adapting to context\nchanges, and remaining effective across different tasks. To tackle these\nissues, we propose a task-agnostic method called Dynamic Compressing Prompts\n(LLM-DCP). Our method reduces the number of prompt tokens while aiming to\npreserve the performance as much as possible. We model prompt compression as a\nMarkov Decision Process (MDP), enabling the DCP-Agent to sequentially remove\nredundant tokens by adapting to dynamic contexts and retaining crucial content.\nWe develop a reward function for training the DCP-Agent that balances the\ncompression rate, the quality of the LLM output, and the retention of key\ninformation. This allows for prompt token reduction without needing an external\nblack-box LLM. Inspired by the progressive difficulty adjustment in curriculum\nlearning, we introduce a Hierarchical Prompt Compression (HPC) training\nstrategy that gradually increases the compression difficulty, enabling the\nDCP-Agent to learn an effective compression method that maintains information\nintegrity. Experiments demonstrate that our method outperforms state-of-the-art\ntechniques, especially at higher compression rates. The code for our approach\nwill be available at https://github.com/Fhujinwu/DCP.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Under review (submited in 2024.11)",
    "pdf_url": "http://arxiv.org/pdf/2504.11004v1",
    "published_date": "2025-04-15 09:20:45 UTC",
    "updated_date": "2025-04-15 09:20:45 UTC"
  },
  {
    "arxiv_id": "2504.10995v1",
    "title": "TMCIR: Token Merge Benefits Composed Image Retrieval",
    "authors": [
      "Chaoyang Wang",
      "Zeyu Zhang",
      "Long Teng",
      "Zijun Li",
      "Shichao Kan"
    ],
    "abstract": "Composed Image Retrieval (CIR) retrieves target images using a multi-modal\nquery that combines a reference image with text describing desired\nmodifications. The primary challenge is effectively fusing this visual and\ntextual information. Current cross-modal feature fusion approaches for CIR\nexhibit an inherent bias in intention interpretation. These methods tend to\ndisproportionately emphasize either the reference image features\n(visual-dominant fusion) or the textual modification intent (text-dominant\nfusion through image-to-text conversion). Such an imbalanced representation\noften fails to accurately capture and reflect the actual search intent of the\nuser in the retrieval results. To address this challenge, we propose TMCIR, a\nnovel framework that advances composed image retrieval through two key\ninnovations: 1) Intent-Aware Cross-Modal Alignment. We first fine-tune CLIP\nencoders contrastively using intent-reflecting pseudo-target images,\nsynthesized from reference images and textual descriptions via a diffusion\nmodel. This step enhances the encoder ability of text to capture nuanced\nintents in textual descriptions. 2) Adaptive Token Fusion. We further fine-tune\nall encoders contrastively by comparing adaptive token-fusion features with the\ntarget image. This mechanism dynamically balances visual and textual\nrepresentations within the contrastive learning pipeline, optimizing the\ncomposed feature for retrieval. Extensive experiments on Fashion-IQ and CIRR\ndatasets demonstrate that TMCIR significantly outperforms state-of-the-art\nmethods, particularly in capturing nuanced user intent.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "arXiv admin note: text overlap with arXiv:2310.05473 by other authors",
    "pdf_url": "http://arxiv.org/pdf/2504.10995v1",
    "published_date": "2025-04-15 09:14:04 UTC",
    "updated_date": "2025-04-15 09:14:04 UTC"
  },
  {
    "arxiv_id": "2504.10983v1",
    "title": "ProtFlow: Fast Protein Sequence Design via Flow Matching on Compressed Protein Language Model Embeddings",
    "authors": [
      "Zitai Kong",
      "Yiheng Zhu",
      "Yinlong Xu",
      "Hanjing Zhou",
      "Mingzhe Yin",
      "Jialu Wu",
      "Hongxia Xu",
      "Chang-Yu Hsieh",
      "Tingjun Hou",
      "Jian Wu"
    ],
    "abstract": "The design of protein sequences with desired functionalities is a fundamental\ntask in protein engineering. Deep generative methods, such as autoregressive\nmodels and diffusion models, have greatly accelerated the discovery of novel\nprotein sequences. However, these methods mainly focus on local or shallow\nresidual semantics and suffer from low inference efficiency, large modeling\nspace and high training cost. To address these challenges, we introduce\nProtFlow, a fast flow matching-based protein sequence design framework that\noperates on embeddings derived from semantically meaningful latent space of\nprotein language models. By compressing and smoothing the latent space,\nProtFlow enhances performance while training on limited computational\nresources. Leveraging reflow techniques, ProtFlow enables high-quality\nsingle-step sequence generation. Additionally, we develop a joint design\npipeline for the design scene of multichain proteins. We evaluate ProtFlow\nacross diverse protein design tasks, including general peptides and long-chain\nproteins, antimicrobial peptides, and antibodies. Experimental results\ndemonstrate that ProtFlow outperforms task-specific methods in these\napplications, underscoring its potential and broad applicability in\ncomputational protein sequence design and analysis.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.BM"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.10983v1",
    "published_date": "2025-04-15 08:46:53 UTC",
    "updated_date": "2025-04-15 08:46:53 UTC"
  },
  {
    "arxiv_id": "2504.10982v2",
    "title": "Exploring the Role of Knowledge Graph-Based RAG in Japanese Medical Question Answering with Small-Scale LLMs",
    "authors": [
      "Yingjian Chen",
      "Feiyang Li",
      "Xingyu Song",
      "Tianxiao Li",
      "Issey Sukeda",
      "Irene Li"
    ],
    "abstract": "Large language models (LLMs) perform well in medical QA, but their\neffectiveness in Japanese contexts is limited due to privacy constraints that\nprevent the use of commercial models like GPT-4 in clinical settings. As a\nresult, recent efforts focus on instruction-tuning open-source LLMs, though the\npotential of combining them with retrieval-augmented generation (RAG) remains\nunderexplored. To bridge this gap, we are the first to explore a knowledge\ngraph-based (KG) RAG framework for Japanese medical QA small-scale open-source\nLLMs. Experimental results show that KG-based RAG has only a limited impact on\nJapanese medical QA using small-scale open-source LLMs. Further case studies\nreveal that the effectiveness of the RAG is sensitive to the quality and\nrelevance of the external retrieved content. These findings offer valuable\ninsights into the challenges and potential of applying RAG in Japanese medical\nQA, while also serving as a reference for other low-resource languages.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "10 pages",
    "pdf_url": "http://arxiv.org/pdf/2504.10982v2",
    "published_date": "2025-04-15 08:46:39 UTC",
    "updated_date": "2025-04-16 01:42:26 UTC"
  },
  {
    "arxiv_id": "2504.10961v1",
    "title": "Evaluating Trust in AI, Human, and Co-produced Feedback Among Undergraduate Students",
    "authors": [
      "Audrey Zhang",
      "Yifei Gao",
      "Wannapon Suraworachet",
      "Tanya Nazaretsky",
      "Mutlu Cukurova"
    ],
    "abstract": "As generative AI transforms educational feedback practices, understanding\nstudents' perceptions of different feedback providers becomes crucial for\neffective implementation. This study addresses a critical gap by comparing\nundergraduate students' trust in AI-generated, human-created, and human-AI\nco-produced feedback, informing how institutions can adapt feedback practices\nin this new era. Through a within-subject experiment with 91 participants, we\ninvestigated factors predicting students' ability to distinguish between\nfeedback types, perception of feedback quality, and potential biases to AI\ninvolvement. Findings revealed that students generally preferred AI and\nco-produced feedback over human feedback in terms of perceived usefulness and\nobjectivity. Only AI feedback suffered a decline in perceived genuineness when\nfeedback sources were revealed, while co-produced feedback maintained its\npositive perception. Educational AI experience improved students' ability to\nidentify AI feedback and increased their trust in all feedback types, while\ngeneral AI experience decreased perceived usefulness and credibility. Male\nstudents consistently rated all feedback types as less valuable than their\nfemale and non-binary counterparts. These insights inform evidence-based\nguidelines for integrating AI into higher education feedback systems while\naddressing trust concerns and fostering AI literacy among students.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "35 pages, 6 figures. Under review at Assessment and Evaluation in\n  Higher Education",
    "pdf_url": "http://arxiv.org/pdf/2504.10961v1",
    "published_date": "2025-04-15 08:06:36 UTC",
    "updated_date": "2025-04-15 08:06:36 UTC"
  },
  {
    "arxiv_id": "2504.10948v1",
    "title": "BEACON: A Benchmark for Efficient and Accurate Counting of Subgraphs",
    "authors": [
      "Mohammad Matin Najafi",
      "Xianju Zhu",
      "Chrysanthi Kosyfaki",
      "Laks V. S. Lakshmanan",
      "Reynold Cheng"
    ],
    "abstract": "Subgraph counting the task of determining the number of instances of a query\npattern within a large graph lies at the heart of many critical applications,\nfrom analyzing financial networks and transportation systems to understanding\nbiological interactions. Despite decades of work yielding efficient algorithmic\n(AL) solutions and, more recently, machine learning (ML) approaches, a clear\ncomparative understanding is elusive. This gap stems from the absence of a\nunified evaluation framework, standardized datasets, and accessible ground\ntruths, all of which hinder systematic analysis and fair benchmarking. To\novercome these barriers, we introduce BEACON: a comprehensive benchmark\ndesigned to rigorously evaluate both AL and ML-based subgraph counting methods.\nBEACON provides a standardized dataset with verified ground truths, an\nintegrated evaluation environment, and a public leaderboard, enabling\nreproducible and transparent comparisons across diverse approaches. Our\nextensive experiments reveal that while AL methods excel in efficiently\ncounting subgraphs on very large graphs, they struggle with complex patterns\n(e.g., those exceeding six nodes). In contrast, ML methods are capable of\nhandling larger patterns but demand massive graph data inputs and often yield\nsuboptimal accuracy on small, dense graphs. These insights not only highlight\nthe unique strengths and limitations of each approach but also pave the way for\nfuture advancements in subgraph counting techniques. Overall, BEACON represents\na significant step towards unifying and accelerating research in subgraph\ncounting, encouraging innovative solutions and fostering a deeper understanding\nof the trade-offs between algorithmic and machine learning paradigms.",
    "categories": [
      "cs.DS",
      "cs.AI",
      "cs.DB",
      "cs.SI"
    ],
    "primary_category": "cs.DS",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.10948v1",
    "published_date": "2025-04-15 07:53:47 UTC",
    "updated_date": "2025-04-15 07:53:47 UTC"
  },
  {
    "arxiv_id": "2504.10936v1",
    "title": "Can LLMs Leverage Observational Data? Towards Data-Driven Causal Discovery with LLMs",
    "authors": [
      "Yuni Susanti",
      "Michael F√§rber"
    ],
    "abstract": "Causal discovery traditionally relies on statistical methods applied to\nobservational data, often requiring large datasets and assumptions about\nunderlying causal structures. Recent advancements in Large Language Models\n(LLMs) have introduced new possibilities for causal discovery by providing\ndomain expert knowledge. However, it remains unclear whether LLMs can\neffectively process observational data for causal discovery. In this work, we\nexplore the potential of LLMs for data-driven causal discovery by integrating\nobservational data for LLM-based reasoning. Specifically, we examine whether\nLLMs can effectively utilize observational data through two prompting\nstrategies: pairwise prompting and breadth first search (BFS)-based prompting.\nIn both approaches, we incorporate the observational data directly into the\nprompt to assess LLMs' ability to infer causal relationships from such data.\nExperiments on benchmark datasets show that incorporating observational data\nenhances causal discovery, boosting F1 scores by up to 0.11 point using both\npairwise and BFS LLM-based prompting, while outperforming traditional\nstatistical causal discovery baseline by up to 0.52 points. Our findings\nhighlight the potential and limitations of LLMs for data-driven causal\ndiscovery, demonstrating their ability to move beyond textual metadata and\neffectively interpret and utilize observational data for more informed causal\nreasoning. Our studies lays the groundwork for future advancements toward fully\nLLM-driven causal discovery.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.10936v1",
    "published_date": "2025-04-15 07:32:35 UTC",
    "updated_date": "2025-04-15 07:32:35 UTC"
  },
  {
    "arxiv_id": "2504.10925v1",
    "title": "Transfer Learning for Temporal Link Prediction",
    "authors": [
      "Ayan Chatterjee",
      "Barbara Ikica",
      "Babak Ravandi",
      "John Palowitch"
    ],
    "abstract": "Link prediction on graphs has applications spanning from recommender systems\nto drug discovery. Temporal link prediction (TLP) refers to predicting future\nlinks in a temporally evolving graph and adds additional complexity related to\nthe dynamic nature of graphs. State-of-the-art TLP models incorporate memory\nmodules alongside graph neural networks to learn both the temporal mechanisms\nof incoming nodes and the evolving graph topology. However, memory modules only\nstore information about nodes seen at train time, and hence such models cannot\nbe directly transferred to entirely new graphs at test time and deployment. In\nthis work, we study a new transfer learning task for temporal link prediction,\nand develop transfer-effective methods for memory-laden models. Specifically,\nmotivated by work showing the informativeness of structural signals for the TLP\ntask, we augment a structural mapping module to the existing TLP model\narchitectures, which learns a mapping from graph structural (topological)\nfeatures to memory embeddings. Our work paves the way for a memory-free\nfoundation model for TLP.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "14 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.10925v1",
    "published_date": "2025-04-15 07:12:00 UTC",
    "updated_date": "2025-04-15 07:12:00 UTC"
  },
  {
    "arxiv_id": "2504.10917v1",
    "title": "Towards A Universal Graph Structural Encoder",
    "authors": [
      "Jialin Chen",
      "Haolan Zuo",
      "Haoyu Peter Wang",
      "Siqi Miao",
      "Pan Li",
      "Rex Ying"
    ],
    "abstract": "Recent advancements in large-scale pre-training have shown the potential to\nlearn generalizable representations for downstream tasks. In the graph domain,\nhowever, capturing and transferring structural information across different\ngraph domains remains challenging, primarily due to the inherent differences in\ntopological patterns across various contexts. Additionally, most existing\nmodels struggle to capture the complexity of rich graph structures, leading to\ninadequate exploration of the embedding space. To address these challenges, we\npropose GFSE, a universal graph structural encoder designed to capture\ntransferable structural patterns across diverse domains such as molecular\ngraphs, social networks, and citation networks. GFSE is the first cross-domain\ngraph structural encoder pre-trained with multiple self-supervised learning\nobjectives. Built on a Graph Transformer, GFSE incorporates attention\nmechanisms informed by graph inductive bias, enabling it to encode intricate\nmulti-level and fine-grained topological features. The pre-trained GFSE\nproduces generic and theoretically expressive positional and structural\nencoding for graphs, which can be seamlessly integrated with various downstream\ngraph feature encoders, including graph neural networks for vectorized features\nand Large Language Models for text-attributed graphs. Comprehensive experiments\non synthetic and real-world datasets demonstrate GFSE's capability to\nsignificantly enhance the model's performance while requiring substantially\nless task-specific fine-tuning. Notably, GFSE achieves state-of-the-art\nperformance in 81.6% evaluated cases, spanning diverse graph models and\ndatasets, highlighting its potential as a powerful and versatile encoder for\ngraph-structured data.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.10917v1",
    "published_date": "2025-04-15 06:57:26 UTC",
    "updated_date": "2025-04-15 06:57:26 UTC"
  },
  {
    "arxiv_id": "2504.10915v1",
    "title": "LOKA Protocol: A Decentralized Framework for Trustworthy and Ethical AI Agent Ecosystems",
    "authors": [
      "Rajesh Ranjan",
      "Shailja Gupta",
      "Surya Narayan Singh"
    ],
    "abstract": "The rise of autonomous AI agents, capable of perceiving, reasoning, and\nacting independently, signals a profound shift in how digital ecosystems\noperate, govern, and evolve. As these agents proliferate beyond centralized\ninfrastructures, they expose foundational gaps in identity, accountability, and\nethical alignment. Three critical questions emerge: Identity: Who or what is\nthe agent? Accountability: Can its actions be verified, audited, and trusted?\nEthical Consensus: Can autonomous systems reliably align with human values and\nprevent harmful emergent behaviors? We present the novel LOKA Protocol (Layered\nOrchestration for Knowledgeful Agents), a unified, systems-level architecture\nfor building ethically governed, interoperable AI agent ecosystems. LOKA\nintroduces a proposed Universal Agent Identity Layer (UAIL) for decentralized,\nverifiable identity; intent-centric communication protocols for semantic\ncoordination across diverse agents; and a Decentralized Ethical Consensus\nProtocol (DECP) that enables agents to make context-aware decisions grounded in\nshared ethical baselines. Anchored in emerging standards such as Decentralized\nIdentifiers (DIDs), Verifiable Credentials (VCs), and post-quantum\ncryptography, LOKA offers a scalable, future-resilient blueprint for\nmulti-agent AI governance. By embedding identity, trust, and ethics into the\nprotocol layer itself, LOKA establishes the foundation for a new era of\nresponsible, transparent, and autonomous AI ecosystems operating across digital\nand physical domains.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.MA",
    "comment": "4 Figures, 1 Table",
    "pdf_url": "http://arxiv.org/pdf/2504.10915v1",
    "published_date": "2025-04-15 06:51:35 UTC",
    "updated_date": "2025-04-15 06:51:35 UTC"
  },
  {
    "arxiv_id": "2504.10903v1",
    "title": "Efficient Reasoning Models: A Survey",
    "authors": [
      "Sicheng Feng",
      "Gongfan Fang",
      "Xinyin Ma",
      "Xinchao Wang"
    ],
    "abstract": "Reasoning models have demonstrated remarkable progress in solving complex and\nlogic-intensive tasks by generating extended Chain-of-Thoughts (CoTs) prior to\narriving at a final answer. Yet, the emergence of this \"slow-thinking\"\nparadigm, with numerous tokens generated in sequence, inevitably introduces\nsubstantial computational overhead. To this end, it highlights an urgent need\nfor effective acceleration. This survey aims to provide a comprehensive\noverview of recent advances in efficient reasoning. It categorizes existing\nworks into three key directions: (1) shorter - compressing lengthy CoTs into\nconcise yet effective reasoning chains; (2) smaller - developing compact\nlanguage models with strong reasoning capabilities through techniques such as\nknowledge distillation, other model compression techniques, and reinforcement\nlearning; and (3) faster - designing efficient decoding strategies to\naccelerate inference. A curated collection of papers discussed in this survey\nis available in our GitHub repository.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.10903v1",
    "published_date": "2025-04-15 06:28:00 UTC",
    "updated_date": "2025-04-15 06:28:00 UTC"
  },
  {
    "arxiv_id": "2504.10900v1",
    "title": "Bridging Distribution Gaps in Time Series Foundation Model Pretraining with Prototype-Guided Normalization",
    "authors": [
      "Peiliang Gong",
      "Emadeldeen Eldele",
      "Min Wu",
      "Zhenghua Chen",
      "Xiaoli Li",
      "Daoqiang Zhang"
    ],
    "abstract": "Foundation models have achieved remarkable success across diverse\nmachine-learning domains through large-scale pretraining on large, diverse\ndatasets. However, pretraining on such datasets introduces significant\nchallenges due to substantial mismatches in data distributions, a problem\nparticularly pronounced with time series data. In this paper, we tackle this\nissue by proposing a domain-aware adaptive normalization strategy within the\nTransformer architecture. Specifically, we replace the traditional LayerNorm\nwith a prototype-guided dynamic normalization mechanism (ProtoNorm), where\nlearned prototypes encapsulate distinct data distributions, and\nsample-to-prototype affinity determines the appropriate normalization layer.\nThis mechanism effectively captures the heterogeneity of time series\ncharacteristics, aligning pretrained representations with downstream tasks.\nThrough comprehensive empirical evaluation, we demonstrate that our method\nsignificantly outperforms conventional pretraining techniques across both\nclassification and forecasting tasks, while effectively mitigating the adverse\neffects of distribution shifts during pretraining. Incorporating ProtoNorm is\nas simple as replacing a single line of code. Extensive experiments on diverse\nreal-world time series benchmarks validate the robustness and generalizability\nof our approach, advancing the development of more versatile time series\nfoundation models.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.10900v1",
    "published_date": "2025-04-15 06:23:00 UTC",
    "updated_date": "2025-04-15 06:23:00 UTC"
  },
  {
    "arxiv_id": "2504.10898v1",
    "title": "Xpose: Bi-directional Engineering for Hidden Query Extraction",
    "authors": [
      "Ahana Pradhan",
      "Jayant Haritsa"
    ],
    "abstract": "Query reverse engineering (QRE) aims to synthesize a SQL query to connect a\ngiven database and result instance. A recent variation of QRE is where an\nadditional input, an opaque executable containing a ground-truth query, is\nprovided, and the goal is to non-invasively extract this specific query through\nonly input-output examples. This variant, called Hidden Query Extraction (HQE),\nhas a spectrum of industrial use-cases including query recovery, database\nsecurity, and vendor migration. The reverse engineering (RE) tools developed\nfor HQE, which are based on database mutation and generation techniques, can\nonly extract flat queries with key-based equi joins and conjunctive arithmetic\nfilter predicates, making them limited wrt both query structure and query\noperators. In this paper, we present Xpose, a HQE solution that elevates the\nextraction scope to realistic complex queries, such as those found in the TPCH\nbenchmark. A two-pronged approach is taken: (1) The existing RE scope is\nsubstantially extended to incorporate union connectors, algebraic filter\npredicates, and disjunctions for both values and predicates. (2) The predictive\npower of LLMs is leveraged to convert business descriptions of the opaque\napplication into extraction guidance, representing ``forward engineering\" (FE).\nThe FE module recognizes common constructs, such as nesting of sub-queries,\nouter joins, and scalar functions. In essence, FE establishes the broad query\ncontours, while RE fleshes out the fine-grained details. We have evaluated\nXpose on (a) E-TPCH, a query suite comprising the complete TPCH benchmark\nextended with queries featuring unions, diverse join types, and sub-queries;\nand (b) the real-world STACK benchmark. The experimental results demonstrate\nthat its bi-directional engineering approach accurately extracts these complex\nqueries, representing a significant step forward with regard to HQE coverage.",
    "categories": [
      "cs.DB",
      "cs.AI",
      "H.2.8"
    ],
    "primary_category": "cs.DB",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.10898v1",
    "published_date": "2025-04-15 06:17:58 UTC",
    "updated_date": "2025-04-15 06:17:58 UTC"
  },
  {
    "arxiv_id": "2504.10893v1",
    "title": "ARise: Towards Knowledge-Augmented Reasoning via Risk-Adaptive Search",
    "authors": [
      "Yize Zhang",
      "Tianshu Wang",
      "Sirui Chen",
      "Kun Wang",
      "Xingyu Zeng",
      "Hongyu Lin",
      "Xianpei Han",
      "Le Sun",
      "Chaochao Lu"
    ],
    "abstract": "Large language models (LLMs) have demonstrated impressive capabilities and\nare receiving increasing attention to enhance their reasoning through scaling\ntest--time compute. However, their application in open--ended,\nknowledge--intensive, complex reasoning scenarios is still limited.\nReasoning--oriented methods struggle to generalize to open--ended scenarios due\nto implicit assumptions of complete world knowledge. Meanwhile,\nknowledge--augmented reasoning (KAR) methods fail to address two core\nchallenges: 1) error propagation, where errors in early steps cascade through\nthe chain, and 2) verification bottleneck, where the explore--exploit tradeoff\narises in multi--branch decision processes. To overcome these limitations, we\nintroduce ARise, a novel framework that integrates risk assessment of\nintermediate reasoning states with dynamic retrieval--augmented generation\n(RAG) within a Monte Carlo tree search paradigm. This approach enables\neffective construction and optimization of reasoning plans across multiple\nmaintained hypothesis branches. Experimental results show that ARise\nsignificantly outperforms the state--of--the--art KAR methods by up to 23.10%,\nand the latest RAG-equipped large reasoning models by up to 25.37%.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "Project homepage: https://opencausalab.github.io/ARise",
    "pdf_url": "http://arxiv.org/pdf/2504.10893v1",
    "published_date": "2025-04-15 06:06:50 UTC",
    "updated_date": "2025-04-15 06:06:50 UTC"
  },
  {
    "arxiv_id": "2504.10888v1",
    "title": "CDUPatch: Color-Driven Universal Adversarial Patch Attack for Dual-Modal Visible-Infrared Detectors",
    "authors": [
      "Jiahuan Long",
      "Wen Yao",
      "Tingsong Jiang",
      "Chao Ma"
    ],
    "abstract": "Adversarial patches are widely used to evaluate the robustness of object\ndetection systems in real-world scenarios. These patches were initially\ndesigned to deceive single-modal detectors (e.g., visible or infrared) and have\nrecently been extended to target visible-infrared dual-modal detectors.\nHowever, existing dual-modal adversarial patch attacks have limited attack\neffectiveness across diverse physical scenarios. To address this, we propose\nCDUPatch, a universal cross-modal patch attack against visible-infrared object\ndetectors across scales, views, and scenarios. Specifically, we observe that\ncolor variations lead to different levels of thermal absorption, resulting in\ntemperature differences in infrared imaging. Leveraging this property, we\npropose an RGB-to-infrared adapter that maps RGB patches to infrared patches,\nenabling unified optimization of cross-modal patches. By learning an optimal\ncolor distribution on the adversarial patch, we can manipulate its thermal\nresponse and generate an adversarial infrared texture. Additionally, we\nintroduce a multi-scale clipping strategy and construct a new visible-infrared\ndataset, MSDrone, which contains aerial vehicle images in varying scales and\nperspectives. These data augmentation strategies enhance the robustness of our\npatch in real-world conditions. Experiments on four benchmark datasets (e.g.,\nDroneVehicle, LLVIP, VisDrone, MSDrone) show that our method outperforms\nexisting patch attacks in the digital domain. Extensive physical tests further\nconfirm strong transferability across scales, views, and scenarios.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.10888v1",
    "published_date": "2025-04-15 05:46:00 UTC",
    "updated_date": "2025-04-15 05:46:00 UTC"
  },
  {
    "arxiv_id": "2504.10886v1",
    "title": "Exploring Persona-dependent LLM Alignment for the Moral Machine Experiment",
    "authors": [
      "Jiseon Kim",
      "Jea Kwon",
      "Luiz Felipe Vecchietti",
      "Alice Oh",
      "Meeyoung Cha"
    ],
    "abstract": "Deploying large language models (LLMs) with agency in real-world applications\nraises critical questions about how these models will behave. In particular,\nhow will their decisions align with humans when faced with moral dilemmas? This\nstudy examines the alignment between LLM-driven decisions and human judgment in\nvarious contexts of the moral machine experiment, including personas reflecting\ndifferent sociodemographics. We find that the moral decisions of LLMs vary\nsubstantially by persona, showing greater shifts in moral decisions for\ncritical tasks than humans. Our data also indicate an interesting partisan\nsorting phenomenon, where political persona predominates the direction and\ndegree of LLM decisions. We discuss the ethical implications and risks\nassociated with deploying these models in applications that involve moral\ndecisions.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CY",
    "comment": "Accepted to ICLR 2025 Workshop - BiAlign (Bidirectional Human-AI\n  Alignment)",
    "pdf_url": "http://arxiv.org/pdf/2504.10886v1",
    "published_date": "2025-04-15 05:29:51 UTC",
    "updated_date": "2025-04-15 05:29:51 UTC"
  },
  {
    "arxiv_id": "2504.10885v1",
    "title": "PuzzleBench: A Fully Dynamic Evaluation Framework for Large Multimodal Models on Puzzle Solving",
    "authors": [
      "Zeyu Zhang",
      "Zijian Chen",
      "Zicheng Zhang",
      "Yuze Sun",
      "Yuan Tian",
      "Ziheng Jia",
      "Chunyi Li",
      "Xiaohong Liu",
      "Xiongkuo Min",
      "Guangtao Zhai"
    ],
    "abstract": "Large Multimodal Models (LMMs) have demonstrated impressive capabilities\nacross a wide range of multimodal tasks, achieving ever-increasing performance\non various evaluation benchmarks. However, existing benchmarks are typically\nstatic and often overlap with pre-training datasets, leading to fixed\ncomplexity constraints and substantial data contamination issues. Meanwhile,\nmanually annotated datasets are labor-intensive, time-consuming, and subject to\nhuman bias and inconsistency, leading to reliability and reproducibility\nissues. To address these problems, we propose a fully dynamic multimodal\nevaluation framework, named Open-ended Visual Puzzle Generation (OVPG), which\naims to generate fresh, diverse, and verifiable evaluation data automatically\nin puzzle-solving tasks. Specifically, the OVPG pipeline consists of a raw\nmaterial sampling module, a visual content generation module, and a puzzle rule\ndesign module, which ensures that each evaluation instance is primitive, highly\nrandomized, and uniquely solvable, enabling continual adaptation to the\nevolving capabilities of LMMs. Built upon OVPG, we construct PuzzleBench, a\ndynamic and scalable benchmark comprising 11,840 VQA samples. It features six\ncarefully designed puzzle tasks targeting three core LMM competencies, visual\nrecognition, logical reasoning, and context understanding. PuzzleBench differs\nfrom static benchmarks that quickly become outdated. It enables ongoing dataset\nrefreshing through OVPG and a rich set of open-ended puzzle designs, allowing\nseamless adaptation to the evolving capabilities of LMMs.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.10885v1",
    "published_date": "2025-04-15 05:29:31 UTC",
    "updated_date": "2025-04-15 05:29:31 UTC"
  },
  {
    "arxiv_id": "2504.10883v1",
    "title": "Bringing together invertible UNets with invertible attention modules for memory-efficient diffusion models",
    "authors": [
      "Karan Jain",
      "Mohammad Nayeem Teli"
    ],
    "abstract": "Diffusion models have recently gained state of the art performance on many\nimage generation tasks. However, most models require significant computational\nresources to achieve this. This becomes apparent in the application of medical\nimage synthesis due to the 3D nature of medical datasets like CT-scans, MRIs,\nelectron microscope, etc. In this paper we propose a novel architecture for a\nsingle GPU memory-efficient training for diffusion models for high dimensional\nmedical datasets. The proposed model is built by using an invertible UNet\narchitecture with invertible attention modules. This leads to the following two\ncontributions: 1. denoising diffusion models and thus enabling memory usage to\nbe independent of the dimensionality of the dataset, and 2. reducing the energy\nusage during training. While this new model can be applied to a multitude of\nimage generation tasks, we showcase its memory-efficiency on the 3D BraTS2020\ndataset leading to up to 15\\% decrease in peak memory consumption during\ntraining with comparable results to SOTA while maintaining the image quality.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.10883v1",
    "published_date": "2025-04-15 05:26:42 UTC",
    "updated_date": "2025-04-15 05:26:42 UTC"
  },
  {
    "arxiv_id": "2504.10878v1",
    "title": "Large Language Model-Informed Feature Discovery Improves Prediction and Interpretation of Credibility Perceptions of Visual Content",
    "authors": [
      "Yilang Peng",
      "Sijia Qian",
      "Yingdan Lu",
      "Cuihua Shen"
    ],
    "abstract": "In today's visually dominated social media landscape, predicting the\nperceived credibility of visual content and understanding what drives human\njudgment are crucial for countering misinformation. However, these tasks are\nchallenging due to the diversity and richness of visual features. We introduce\na Large Language Model (LLM)-informed feature discovery framework that\nleverages multimodal LLMs, such as GPT-4o, to evaluate content credibility and\nexplain its reasoning. We extract and quantify interpretable features using\ntargeted prompts and integrate them into machine learning models to improve\ncredibility predictions. We tested this approach on 4,191 visual social media\nposts across eight topics in science, health, and politics, using credibility\nratings from 5,355 crowdsourced workers. Our method outperformed zero-shot\nGPT-based predictions by 13 percent in R2, and revealed key features like\ninformation concreteness and image format. We discuss the implications for\nmisinformation mitigation, visual credibility, and the role of LLMs in social\nscience.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "I.4.9; J.4"
    ],
    "primary_category": "cs.CV",
    "comment": "26 pages",
    "pdf_url": "http://arxiv.org/pdf/2504.10878v1",
    "published_date": "2025-04-15 05:11:40 UTC",
    "updated_date": "2025-04-15 05:11:40 UTC"
  },
  {
    "arxiv_id": "2504.10873v1",
    "title": "Can Vision-Language Models Understand and Interpret Dynamic Gestures from Pedestrians? Pilot Datasets and Exploration Towards Instructive Nonverbal Commands for Cooperative Autonomous Vehicles",
    "authors": [
      "Tonko E. W. Bossen",
      "Andreas M√∏gelmose",
      "Ross Greer"
    ],
    "abstract": "In autonomous driving, it is crucial to correctly interpret traffic gestures\n(TGs), such as those of an authority figure providing orders or instructions,\nor a pedestrian signaling the driver, to ensure a safe and pleasant traffic\nenvironment for all road users. This study investigates the capabilities of\nstate-of-the-art vision-language models (VLMs) in zero-shot interpretation,\nfocusing on their ability to caption and classify human gestures in traffic\ncontexts. We create and publicly share two custom datasets with varying formal\nand informal TGs, such as 'Stop', 'Reverse', 'Hail', etc. The datasets are\n\"Acted TG (ATG)\" and \"Instructive TG In-The-Wild (ITGI)\". They are annotated\nwith natural language, describing the pedestrian's body position and gesture.\nWe evaluate models using three methods utilizing expert-generated captions as\nbaseline and control: (1) caption similarity, (2) gesture classification, and\n(3) pose sequence reconstruction similarity. Results show that current VLMs\nstruggle with gesture understanding: sentence similarity averages below 0.59,\nand classification F1 scores reach only 0.14-0.39, well below the expert\nbaseline of 0.70. While pose reconstruction shows potential, it requires more\ndata and refined metrics to be reliable. Our findings reveal that although some\nSOTA VLMs can interpret zero-shot human traffic gestures, none are accurate and\nrobust enough to be trustworthy, emphasizing the need for further research in\nthis domain.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.10873v1",
    "published_date": "2025-04-15 05:04:25 UTC",
    "updated_date": "2025-04-15 05:04:25 UTC"
  },
  {
    "arxiv_id": "2504.10865v1",
    "title": "Understanding the theoretical properties of projected Bellman equation, linear Q-learning, and approximate value iteration",
    "authors": [
      "Han-Dong Lim",
      "Donghwan Lee"
    ],
    "abstract": "In this paper, we study the theoretical properties of the projected Bellman\nequation (PBE) and two algorithms to solve this equation: linear Q-learning and\napproximate value iteration (AVI). We consider two sufficient conditions for\nthe existence of a solution to PBE : strictly negatively row dominating\ndiagonal (SNRDD) assumption and a condition motivated by the convergence of\nAVI. The SNRDD assumption also ensures the convergence of linear Q-learning,\nand its relationship with the convergence of AVI is examined. Lastly, several\ninteresting observations on the solution of PBE are provided when using\n$\\epsilon$-greedy policy.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Initial submission",
    "pdf_url": "http://arxiv.org/pdf/2504.10865v1",
    "published_date": "2025-04-15 04:56:33 UTC",
    "updated_date": "2025-04-15 04:56:33 UTC"
  },
  {
    "arxiv_id": "2504.10845v1",
    "title": "Moving Beyond Next-Token Prediction: Transformers are Context-Sensitive Language Generators",
    "authors": [
      "Phill Kyu Rhee"
    ],
    "abstract": "Large Language Models (LLMs), powered by Transformers, have demonstrated\nhuman-like intelligence capabilities, yet their underlying mechanisms remain\npoorly understood. This paper presents a novel framework for interpreting LLMs\nas probabilistic left context-sensitive languages (CSLs) generators. We\nhypothesize that Transformers can be effectively decomposed into three\nfundamental components: context windows, attention mechanisms, and\nautoregressive generation frameworks. This decomposition allows for the\ndevelopment of more flexible and interpretable computational models, moving\nbeyond the traditional view of attention and autoregression as inseparable\nprocesses. We argue that next-token predictions can be understood as\nprobabilistic, dynamic approximations of left CSL production rules, providing\nan intuitive explanation for how simple token predictions can yield human-like\nintelligence outputs. Given that all CSLs are left context-sensitive\n(Penttonen, 1974), we conclude that Transformers stochastically approximate\nCSLs, which are widely recognized as models of human-like intelligence. This\ninterpretation bridges the gap between Formal Language Theory and the observed\ngenerative power of Transformers, laying a foundation for future advancements\nin generative AI theory and applications. Our novel perspective on Transformer\narchitectures will foster a deeper understanding of LLMs and their future\npotentials.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "11 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.10845v1",
    "published_date": "2025-04-15 04:06:27 UTC",
    "updated_date": "2025-04-15 04:06:27 UTC"
  },
  {
    "arxiv_id": "2504.10839v1",
    "title": "Rethinking Theory of Mind Benchmarks for LLMs: Towards A User-Centered Perspective",
    "authors": [
      "Qiaosi Wang",
      "Xuhui Zhou",
      "Maarten Sap",
      "Jodi Forlizzi",
      "Hong Shen"
    ],
    "abstract": "The last couple of years have witnessed emerging research that appropriates\nTheory-of-Mind (ToM) tasks designed for humans to benchmark LLM's ToM\ncapabilities as an indication of LLM's social intelligence. However, this\napproach has a number of limitations. Drawing on existing psychology and AI\nliterature, we summarize the theoretical, methodological, and evaluation\nlimitations by pointing out that certain issues are inherently present in the\noriginal ToM tasks used to evaluate human's ToM, which continues to persist and\nexacerbated when appropriated to benchmark LLM's ToM. Taking a human-computer\ninteraction (HCI) perspective, these limitations prompt us to rethink the\ndefinition and criteria of ToM in ToM benchmarks in a more dynamic,\ninteractional approach that accounts for user preferences, needs, and\nexperiences with LLMs in such evaluations. We conclude by outlining potential\nopportunities and challenges towards this direction.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "7 pages, 1 figure, accepted to the HEAL@CHI 2025 Workshop",
    "pdf_url": "http://arxiv.org/pdf/2504.10839v1",
    "published_date": "2025-04-15 03:44:43 UTC",
    "updated_date": "2025-04-15 03:44:43 UTC"
  },
  {
    "arxiv_id": "2504.10836v1",
    "title": "Uplink Assisted Joint Channel Estimation and CSI Feedback: An Approach Based on Deep Joint Source-Channel Coding",
    "authors": [
      "Yiran Guo",
      "Wei Chen",
      "Bo Ai"
    ],
    "abstract": "In frequency division duplex (FDD) multiple-input multiple-output (MIMO)\nwireless communication systems, the acquisition of downlink channel state\ninformation (CSI) is essential for maximizing spatial resource utilization and\nimproving system spectral efficiency. The separate design of modules in\nAI-based CSI feedback architectures under traditional modular communication\nframeworks, including channel estimation (CE), CSI compression and feedback,\nleads to sub-optimal performance. In this paper, we propose an uplink assisted\njoint CE and and CSI feedback approach via deep learning for downlink CSI\nacquisition, which mitigates performance degradation caused by distribution\nbias across separately trained modules in traditional modular communication\nframeworks. The proposed network adopts a deep joint source-channel coding\n(DJSCC) architecture to mitigate the cliff effect encountered in the\nconventional separate source-channel coding. Furthermore, we exploit the uplink\nCSI as auxiliary information to enhance CSI reconstruction accuracy by\nleveraging the partial reciprocity between the uplink and downlink channels in\nFDD systems, without introducing additional overhead. The effectiveness of\nuplink CSI as assisted information and the necessity of an end-toend\nmulti-module joint training architecture is validated through comprehensive\nablation and scalability experiments.",
    "categories": [
      "eess.SP",
      "cs.AI"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.10836v1",
    "published_date": "2025-04-15 03:29:24 UTC",
    "updated_date": "2025-04-15 03:29:24 UTC"
  },
  {
    "arxiv_id": "2504.10833v1",
    "title": "Towards Spatially-Aware and Optimally Faithful Concept-Based Explanations",
    "authors": [
      "Shubham Kumar",
      "Dwip Dalal",
      "Narendra Ahuja"
    ],
    "abstract": "Post-hoc, unsupervised concept-based explanation methods (U-CBEMs) are a\npromising tool for generating semantic explanations of the decision-making\nprocesses in deep neural networks, having applications in both model\nimprovement and understanding. It is vital that the explanation is accurate, or\nfaithful, to the model, yet we identify several limitations of prior\nfaithfulness metrics that inhibit an accurate evaluation; most notably, prior\nmetrics involve only the set of concepts present, ignoring how they may be\nspatially distributed. We address these limitations with Surrogate Faithfulness\n(SF), an evaluation method that introduces a spatially-aware surrogate and two\nnovel faithfulness metrics. Using SF, we produce Optimally Faithful (OF)\nexplanations, where concepts are found that maximize faithfulness. Our\nexperiments show that (1) adding spatial-awareness to prior U-CBEMs increases\nfaithfulness in all cases; (2) OF produces significantly more faithful\nexplanations than prior U-CBEMs (30% or higher improvement in error); (3) OF's\nlearned concepts generalize well to out-of-domain data and are more robust to\nadversarial examples, where prior U-CBEMs struggle.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.10833v1",
    "published_date": "2025-04-15 03:24:13 UTC",
    "updated_date": "2025-04-15 03:24:13 UTC"
  },
  {
    "arxiv_id": "2504.10831v1",
    "title": "Hallucination-Aware Generative Pretrained Transformer for Cooperative Aerial Mobility Control",
    "authors": [
      "Hyojun Ahn",
      "Seungcheol Oh",
      "Gyu Seon Kim",
      "Soyi Jung",
      "Soohyun Park",
      "Joongheon Kim"
    ],
    "abstract": "This paper proposes SafeGPT, a two-tiered framework that integrates\ngenerative pretrained transformers (GPTs) with reinforcement learning (RL) for\nefficient and reliable unmanned aerial vehicle (UAV) last-mile deliveries. In\nthe proposed design, a Global GPT module assigns high-level tasks such as\nsector allocation, while an On-Device GPT manages real-time local route\nplanning. An RL-based safety filter monitors each GPT decision and overrides\nunsafe actions that could lead to battery depletion or duplicate visits,\neffectively mitigating hallucinations. Furthermore, a dual replay buffer\nmechanism helps both the GPT modules and the RL agent refine their strategies\nover time. Simulation results demonstrate that SafeGPT achieves higher delivery\nsuccess rates compared to a GPT-only baseline, while substantially reducing\nbattery consumption and travel distance. These findings validate the efficacy\nof combining GPT-based semantic reasoning with formal safety guarantees,\ncontributing a viable solution for robust and energy-efficient UAV logistics.",
    "categories": [
      "cs.AI",
      "cs.RO",
      "68T05"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.10831v1",
    "published_date": "2025-04-15 03:21:08 UTC",
    "updated_date": "2025-04-15 03:21:08 UTC"
  },
  {
    "arxiv_id": "2504.10823v1",
    "title": "CLASH: Evaluating Language Models on Judging High-Stakes Dilemmas from Multiple Perspectives",
    "authors": [
      "Ayoung Lee",
      "Ryan Sungmo Kwon",
      "Peter Railton",
      "Lu Wang"
    ],
    "abstract": "Navigating high-stakes dilemmas involving conflicting values is challenging\neven for humans, let alone for AI. Yet prior work in evaluating the reasoning\ncapabilities of large language models (LLMs) in such situations has been\nlimited to everyday scenarios. To close this gap, this work first introduces\nCLASH (Character perspective-based LLM Assessments in Situations with\nHigh-stakes), a meticulously curated dataset consisting of 345 high-impact\ndilemmas along with 3,795 individual perspectives of diverse values. In\nparticular, we design CLASH in a way to support the study of critical aspects\nof value-based decision-making processes which are missing from prior work,\nincluding understanding decision ambivalence and psychological discomfort as\nwell as capturing the temporal shifts of values in characters' perspectives. By\nbenchmarking 10 open and closed frontier models, we uncover several key\nfindings. (1) Even the strongest models, such as GPT-4o and Claude-Sonnet,\nachieve less than 50% accuracy in identifying situations where the decision\nshould be ambivalent, while they perform significantly better in clear-cut\nscenarios. (2) While LLMs reasonably predict psychological discomfort as marked\nby human, they inadequately comprehend perspectives involving value shifts,\nindicating a need for LLMs to reason over complex values. (3) Our experiments\nalso reveal a significant correlation between LLMs' value preferences and their\nsteerability towards a given value. (4) Finally, LLMs exhibit greater\nsteerability when engaged in value reasoning from a third-party perspective,\ncompared to a first-person setup, though certain value pairs benefit uniquely\nfrom the first-person framing.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.10823v1",
    "published_date": "2025-04-15 02:54:16 UTC",
    "updated_date": "2025-04-15 02:54:16 UTC"
  },
  {
    "arxiv_id": "2504.10821v1",
    "title": "Progressive Rock Music Classification",
    "authors": [
      "Arpan Nagar",
      "Joseph Bensabat",
      "Jokent Gaza",
      "Moinak Dey"
    ],
    "abstract": "This study investigates the classification of progressive rock music, a genre\ncharacterized by complex compositions and diverse instrumentation, distinct\nfrom other musical styles. Addressing this Music Information Retrieval (MIR)\ntask, we extracted comprehensive audio features, including spectrograms,\nMel-Frequency Cepstral Coefficients (MFCCs), chromagrams, and beat positions\nfrom song snippets using the Librosa library. A winner-take-all voting strategy\nwas employed to aggregate snippet-level predictions into final song\nclassifications. We conducted a comparative analysis of various machine\nlearning techniques. Ensemble methods, encompassing Bagging (Random Forest,\nExtraTrees, Bagging Classifier) and Boosting (XGBoost, Gradient Boosting), were\nexplored, utilizing Principal Component Analysis (PCA) for dimensionality\nreduction to manage computational constraints with high-dimensional feature\nsets. Additionally, deep learning approaches were investigated, including the\ndevelopment of custom 1D Convolutional Neural Network (1D CNN) architectures\n(named \"Zuck\" and \"Satya\") featuring specific layer configurations,\nnormalization, and activation functions. Furthermore, we fine-tuned a\nstate-of-the-art Audio Spectrogram Transformer (AST) model, leveraging its\nattention-based mechanisms for audio classification. Performance evaluation on\nvalidation and test sets revealed varying effectiveness across models, with\nensemble methods like Extra Trees achieving test accuracies up to 76.38%. This\nresearch provides insights into the application and relative performance of\ndiverse machine learning paradigms for the nuanced task of progressive rock\ngenre classification.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "20 pages",
    "pdf_url": "http://arxiv.org/pdf/2504.10821v1",
    "published_date": "2025-04-15 02:48:52 UTC",
    "updated_date": "2025-04-15 02:48:52 UTC"
  },
  {
    "arxiv_id": "2504.10817v1",
    "title": "FHBench: Towards Efficient and Personalized Federated Learning for Multimodal Healthcare",
    "authors": [
      "Penghao Wang",
      "Qian Chen",
      "Teng Zhang",
      "Yingwei Zhang",
      "Wang Lu",
      "Yiqiang Chen"
    ],
    "abstract": "Federated Learning (FL) has emerged as an effective solution for\nmulti-institutional collaborations without sharing patient data, offering a\nrange of methods tailored for diverse applications. However, real-world medical\ndatasets are often multimodal, and computational resources are limited, posing\nsignificant challenges for existing FL approaches. Recognizing these\nlimitations, we developed the Federated Healthcare Benchmark(FHBench), a\nbenchmark specifically designed from datasets derived from real-world\nhealthcare applications. FHBench encompasses critical diagnostic tasks across\ndomains such as the nervous, cardiovascular, and respiratory systems and\ngeneral pathology, providing comprehensive support for multimodal healthcare\nevaluations and filling a significant gap in existing benchmarks. Building on\nFHBench, we introduced Efficient Personalized Federated Learning with Adaptive\nLoRA(EPFL), a personalized FL framework that demonstrates superior efficiency\nand effectiveness across various healthcare modalities. Our results highlight\nthe robustness of FHBench as a benchmarking tool and the potential of EPFL as\nan innovative approach to advancing healthcare-focused FL, addressing key\nlimitations of existing methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.10817v1",
    "published_date": "2025-04-15 02:38:00 UTC",
    "updated_date": "2025-04-15 02:38:00 UTC"
  },
  {
    "arxiv_id": "2504.10812v1",
    "title": "E2E Parking Dataset: An Open Benchmark for End-to-End Autonomous Parking",
    "authors": [
      "Kejia Gao",
      "Liguo Zhou",
      "Mingjun Liu",
      "Alois Knoll"
    ],
    "abstract": "End-to-end learning has shown great potential in autonomous parking, yet the\nlack of publicly available datasets limits reproducibility and benchmarking.\nWhile prior work introduced a visual-based parking model and a pipeline for\ndata generation, training, and close-loop test, the dataset itself was not\nreleased. To bridge this gap, we create and open-source a high-quality dataset\nfor end-to-end autonomous parking. Using the original model, we achieve an\noverall success rate of 85.16% with lower average position and orientation\nerrors (0.24 meters and 0.34 degrees).",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.10812v1",
    "published_date": "2025-04-15 02:21:09 UTC",
    "updated_date": "2025-04-15 02:21:09 UTC"
  },
  {
    "arxiv_id": "2504.10810v1",
    "title": "PatrolVision: Automated License Plate Recognition in the wild",
    "authors": [
      "Anmol Singhal Navya Singhal"
    ],
    "abstract": "Adoption of AI driven techniques in public services remains low due to\nchallenges related to accuracy and speed of information at population scale.\nComputer vision techniques for traffic monitoring have not gained much\npopularity despite their relative strength in areas such as autonomous driving.\nDespite large number of academic methods for Automatic License Plate\nRecognition (ALPR) systems, very few provide an end to end solution for\npatrolling in the city. This paper presents a novel prototype for a low power\nGPU based patrolling system to be deployed in an urban environment on\nsurveillance vehicles for automated vehicle detection, recognition and\ntracking. In this work, we propose a complete ALPR system for Singapore license\nplates having both single and double line creating our own YOLO based network.\nWe focus on unconstrained capture scenarios as would be the case in real world\napplication, where the license plate (LP) might be considerably distorted due\nto oblique views. In this work, we first detect the license plate from the full\nimage using RFB-Net and rectify multiple distorted license plates in a single\nimage. After that, the detected license plate image is fed to our network for\ncharacter recognition. We evaluate the performance of our proposed system on a\nnewly built dataset covering more than 16,000 images. The system was able to\ncorrectly detect license plates with 86\\% precision and recognize characters of\na license plate in 67\\% of the test set, and 89\\% accuracy with one incorrect\ncharacter (partial match). We also test latency of our system and achieve 64FPS\non Tesla P4 GPU",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted in IEEE Southeast Con 2025. To be published in IEEEXplore",
    "pdf_url": "http://arxiv.org/pdf/2504.10810v1",
    "published_date": "2025-04-15 02:10:43 UTC",
    "updated_date": "2025-04-15 02:10:43 UTC"
  },
  {
    "arxiv_id": "2504.10797v1",
    "title": "Name of Thrones: Evaluating How LLMs Rank Student Names, Race, and Gender in Status Hierarchies",
    "authors": [
      "Annabella Sakunkoo",
      "Jonathan Sakunkoo"
    ],
    "abstract": "Across cultures, names tell a lot about their bearers as they carry deep\npersonal and cultural significance. Names also serve as powerful signals of\ngender, race, and status in the social hierarchy - a pecking order in which\nindividual positions shape others' expectations on their perceived competence\nand worth. With the widespread adoption of LLMs and as names are often an input\nfor LLMs, it is crucial to evaluate whether LLMs may sort people into status\npositions based on first and last names and, if so, whether it is in an unfair,\nbiased fashion. While prior work has primarily investigated biases in first\nnames, little attention has been paid to last names and even less to the\ncombined effects of first and last names. In this study, we conduct a\nlarge-scale analysis of name variations across 5 ethnicities to examine how AI\nexhibits name biases. Our study investigates three key characteristics of\ninequality and finds that LLMs reflect and reinforce status hierarchies based\non names that signal gender and ethnicity as they encode differential\nexpectations of competence, leadership, and economic potential. Contrary to the\ncommon assumption that AI tends to favor Whites, we show that East and, in some\ncontexts, South Asian names receive higher rankings. We also disaggregate\nAsians, a population projected to be the largest immigrant group in the U.S. by\n2055. Our results challenge the monolithic Asian model minority assumption,\nillustrating a more complex and stratified model of bias. Gender moderates\nbiases, with girls facing unfair disadvantages in certain racial groups.\nAdditionally, spanning cultural categories by adopting Western first names\nimproves AI-perceived status for East and Southeast Asian students,\nparticularly for girls. Our findings underscore the importance of\nintersectional and more nuanced understandings of race, gender, and mixed\nidentities in the evaluation of LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC",
      "H.5; J.4"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.10797v1",
    "published_date": "2025-04-15 01:47:39 UTC",
    "updated_date": "2025-04-15 01:47:39 UTC"
  },
  {
    "arxiv_id": "2504.10786v2",
    "title": "Visual Language Models show widespread visual deficits on neuropsychological tests",
    "authors": [
      "Gene Tangtartharakul",
      "Katherine R. Storrs"
    ],
    "abstract": "Visual Language Models (VLMs) show remarkable performance in visual reasoning\ntasks, successfully tackling college-level challenges that require high-level\nunderstanding of images. However, some recent reports of VLMs struggling to\nreason about elemental visual concepts like orientation, position, continuity,\nand occlusion suggest a potential gulf between human and VLM vision. Here we\nuse the toolkit of neuropsychology to systematically assess the capabilities of\nthree state-of-the-art VLMs across visual domains. Using 51 tests drawn from\nsix clinical and experimental batteries, we characterise the visual abilities\nof leading VLMs relative to normative performance in healthy adults. While the\nmodels excel in straightforward object recognition tasks, we find widespread\ndeficits in low- and mid-level visual abilities that would be considered\nclinically significant in humans. These selective deficits, profiled through\nvalidated test batteries, suggest that an artificial system can achieve complex\nobject recognition without developing foundational visual concepts that in\nhumans require no explicit training.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "I.2.0; I.2.10"
    ],
    "primary_category": "cs.CV",
    "comment": "31 pages, 3 figures, 1 supplementary document with 1 figure and 51\n  sample images; corrected typo in Fig 1",
    "pdf_url": "http://arxiv.org/pdf/2504.10786v2",
    "published_date": "2025-04-15 01:04:56 UTC",
    "updated_date": "2025-04-16 01:27:42 UTC"
  },
  {
    "arxiv_id": "2504.10784v1",
    "title": "ATLASv2: LLM-Guided Adaptive Landmark Acquisition and Navigation on the Edge",
    "authors": [
      "Mikolaj Walczak",
      "Uttej Kallakuri",
      "Tinoosh Mohsenin"
    ],
    "abstract": "Autonomous systems deployed on edge devices face significant challenges,\nincluding resource constraints, real-time processing demands, and adapting to\ndynamic environments. This work introduces ATLASv2, a novel system that\nintegrates a fine-tuned TinyLLM, real-time object detection, and efficient path\nplanning to enable hierarchical, multi-task navigation and manipulation all on\nthe edge device, Jetson Nano. ATLASv2 dynamically expands its navigable\nlandmarks by detecting and localizing objects in the environment which are\nsaved to its internal knowledge base to be used for future task execution. We\nevaluate ATLASv2 in real-world environments, including a handcrafted home and\noffice setting constructed with diverse objects and landmarks. Results show\nthat ATLASv2 effectively interprets natural language instructions, decomposes\nthem into low-level actions, and executes tasks with high success rates. By\nleveraging generative AI in a fully on-board framework, ATLASv2 achieves\noptimized resource utilization with minimal prompting latency and power\nconsumption, bridging the gap between simulated environments and real-world\napplications.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.10784v1",
    "published_date": "2025-04-15 00:55:57 UTC",
    "updated_date": "2025-04-15 00:55:57 UTC"
  },
  {
    "arxiv_id": "2504.10781v1",
    "title": "Neural Network Emulation of the Classical Limit in Quantum Systems via Learned Observable Mappings",
    "authors": [
      "Kamran Majid"
    ],
    "abstract": "The classical limit of quantum mechanics, formally investigated through\nframeworks like strict deformation quantization, remains a profound area of\ninquiry in the philosophy of physics. This paper explores a computational\napproach employing a neural network to emulate the emergence of classical\nbehavior from the quantum harmonic oscillator as Planck's constant $\\hbar$\napproaches zero. We develop and train a neural network architecture to learn\nthe mapping from initial expectation values and $\\hbar$ to the time evolution\nof the expectation value of position. By analyzing the network's predictions\nacross different regimes of hbar, we aim to provide computational insights into\nthe nature of the quantum-classical transition. This work demonstrates the\npotential of machine learning as a complementary tool for exploring\nfoundational questions in quantum mechanics and its classical limit.",
    "categories": [
      "quant-ph",
      "cs.AI"
    ],
    "primary_category": "quant-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.10781v1",
    "published_date": "2025-04-15 00:48:36 UTC",
    "updated_date": "2025-04-15 00:48:36 UTC"
  },
  {
    "arxiv_id": "2504.10768v1",
    "title": "The Art of Audience Engagement: LLM-Based Thin-Slicing of Scientific Talks",
    "authors": [
      "Ralf Schm√§lzle",
      "Sue Lim",
      "Yuetong Du",
      "Gary Bente"
    ],
    "abstract": "This paper examines the thin-slicing approach - the ability to make accurate\njudgments based on minimal information - in the context of scientific\npresentations. Drawing on research from nonverbal communication and personality\npsychology, we show that brief excerpts (thin slices) reliably predict overall\npresentation quality. Using a novel corpus of over one hundred real-life\nscience talks, we employ Large Language Models (LLMs) to evaluate transcripts\nof full presentations and their thin slices. By correlating LLM-based\nevaluations of short excerpts with full-talk assessments, we determine how much\ninformation is needed for accurate predictions. Our results demonstrate that\nLLM-based evaluations align closely with human ratings, proving their validity,\nreliability, and efficiency. Critically, even very short excerpts (less than 10\npercent of a talk) strongly predict overall evaluations. This suggests that the\nfirst moments of a presentation convey relevant information that is used in\nquality evaluations and can shape lasting impressions. The findings are robust\nacross different LLMs and prompting strategies. This work extends thin-slicing\nresearch to public speaking and connects theories of impression formation to\nLLMs and current research on AI communication. We discuss implications for\ncommunication and social cognition research on message reception. Lastly, we\nsuggest an LLM-based thin-slicing framework as a scalable feedback tool to\nenhance human communication.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.ET",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.10768v1",
    "published_date": "2025-04-15 00:08:13 UTC",
    "updated_date": "2025-04-15 00:08:13 UTC"
  }
]