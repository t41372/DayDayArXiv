{
  "date": "2025-04-15",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-04-15 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 论文主要聚焦于 AI 模型的推理能力提升、生成式 AI 的安全与效率优化，以及在医疗、图神经网络和量子计算等领域的应用，其中 Nemotron-CrossThink（由 Yejin Choi 等知名学者主导的跨领域 LLM 强化学习框架）和 DeepSeek-R1（LLM 在数学推理中的突破性进展）等文章令人印象深刻，强调了 LLM 在复杂任务中的潜力与挑战。\n\n以下是今日论文的精选摘要，我将优先讨论重要、创新性强的文章（如 LLM 推理、安全和医疗应用），并将相关论文归类讨论。对次要论文（如某些算法细节或小众优化），将简要掠过，只列出标题和核心点。所有摘要均保留关键学术术语，并清晰概述贡献和发现。\n\n### LLM 推理与优化\n- **Nemotron-CrossThink: Scaling Self-Learning beyond Math Reasoning**（Nemotron-CrossThink: 扩展数学推理之外的自学习）  \n  作者包括 Yejin Choi，这篇论文提出一个多领域强化学习框架，整合 STEM 和人文数据，提升 LLM 在数学（MATH-500 准确率提升 30.1%）和非数学任务（如 MMLU-PRO +12.8%）的泛化能力，主要发现是通过数据混合策略和可验证奖励，实现高效跨任务推理。\n  \n- **DeepSeek-R1 的相关工作**（如 Achieving Tighter Finite-Time Rates for Heterogeneous Federated Stochastic Approximation）  \n  这类论文探索 LLM 在强化学习中的加速，如 DeepSeek-R1 在数学推理中通过高效策略实现 67% 准确率，贡献在于 M 倍线性加速和鲁棒收敛；另一篇 ReTool 则使用 RL 优化工具调用，提升数学任务性能（AIME 基准上达 72.5%），发现 LLM 可自主学习工具策略。\n\n- **Improving Instruct Models for Free: A Study on Partial Adaptation**  \n  作者 Ozan İrsoy 等人研究部分适应技术，减少指令微调中的遗忘问题，贡献是通过缩放微调强度提升少样本学习性能（MRR 提升 10-50%），发现权衡了指令遵循与知识保留。\n\n- **其他 LLM 相关**：如 DeepMLF（使用 RL 优化数学数据集）和 Kimina-Prover（RL 驱动的形式证明），这些工作快速掠过，它们主要提升了 LLM 的推理效率和可扩展性。\n\n### AI 安全与攻击防御\n- **DataSentinel: A Game-Theoretic Detection of Prompt Injection Attacks**（DataSentinel: 基于博弈论的提示注入攻击检测）  \n  这篇论文提出游戏论框架检测提示注入，贡献是通过 minimax 优化训练 LLM 检测器，提升 46% 的检测性能，主要发现即使面对自适应攻击，也能有效保护 LLM。\n\n- **X-Teaming: Multi-Turn Jailbreaks and Defenses with Adaptive Multi-Agents**（X-Teaming: 自适应多代理的提示注入和越狱防御）  \n  作者 Salman Rahman 等开发多代理系统，成功率达 98.1%，贡献在于模拟多轮攻击并生成防御数据集，强调了 LLM 在对话安全中的适应性。\n\n- **其他安全论文**：如 Bypassing Prompt Injection and Jailbreak Detection（探讨攻击绕过），快速提及其发现 LLM 防护易被规避，需更强防御机制。\n\n### 医疗与生物应用\n- **TrialGPT: Recommending Clinical Trials for Online Patient Cases using Artificial Intelligence**（TrialGPT: 使用 AI 推荐临床试验的在线患者案例）  \n  作者 Zhiyong Lu 等人构建 LLM 框架，提升临床试验匹配准确率 46%，贡献是通过患者案例匹配算法，平均每个患者匹配 7 个试验，主要发现在线平台可扩展招募。\n\n- **Deep Generative Model-Based Generation of Synthetic Individual-Specific Brain MRI Segmentations**（基于深度生成模型的合成个体特定脑 MRI 分割）  \n  论文提出 CSegSynth 模型，使用人口统计数据生成高质量合成 MRI，贡献在于减少真实数据依赖（误差仅 29-36 mL），发现合成数据可提升脑部分析效率。\n\n- **其他医疗论文**：如 Prototype-Guided Diffusion（用于数字病理的合成数据生成）和 A Large-Language Model Framework for Relative Timeline Extraction（从病例报告提取时间序列），这些快速掠过，前者提升了自监督学习，后者改善了临床事件时间分析。\n\n### 其他亮点领域\n- **WaterFlow: Learning Fast & Robust Watermarks using Stable Diffusion**（WaterFlow: 使用 Stable Diffusion 学习快速鲁棒水印）  \n  作者 Aditya Grover 等人开发水印方法，贡献在于基于潜在扩散模型的 Fourier 域植入，提升图像水印鲁棒性（首创防御组合攻击），主要发现适用于真实数据集如 MS-COCO。\n\n- **GraphicBench: A Planning Benchmark for Graphic Design with Language Agents**（GraphicBench: 图形设计规划基准）  \n  论文构建 LLM 代理基准，贡献是通过多任务评估提升设计代理性能，强调空间推理和工具选择。\n\n- **快速掠过论文**：如 On-Device Watermarking（硬件层水印框架）、HypoBench（假设生成基准）和 BEACON（子图计数基准），这些工作虽有创新（如高效子图计数），但影响力较小，仅提及其基准构建和性能提升。\n\n今日 arXiv 共收录 126 篇论文，以上精选了核心亮点；其他如量子计算、图网络和环境模拟论文虽多样，但多为技术优化（如 QAMA 在蛋白设计中的应用），未列出以控制篇幅。总的来说，这些论文推动了 AI 的高效推理和实际应用，期待后续进展！",
  "papers": [
    {
      "arxiv_id": "2504.12354v2",
      "title": "WaterFlow: Learning Fast & Robust Watermarks using Stable Diffusion",
      "title_zh": "翻译失败",
      "authors": [
        "Vinay Shukla",
        "Prachee Sharma",
        "Ryan Rossi",
        "Sungchul Kim",
        "Tong Yu",
        "Aditya Grover"
      ],
      "abstract": "The ability to embed watermarks in images is a fundamental problem of\ninterest for computer vision, and is exacerbated by the rapid rise of generated\nimagery in recent times. Current state-of-the-art techniques suffer from\ncomputational and statistical challenges such as the slow execution speed for\npractical deployments. In addition, other works trade off fast watermarking\nspeeds but suffer greatly in their robustness or perceptual quality. In this\nwork, we propose WaterFlow (WF), a fast and extremely robust approach for high\nfidelity visual watermarking based on a learned latent-dependent watermark. Our\napproach utilizes a pretrained latent diffusion model to encode an arbitrary\nimage into a latent space and produces a learned watermark that is then planted\ninto the Fourier Domain of the latent. The transformation is specified via\ninvertible flow layers that enhance the expressivity of the latent space of the\npre-trained model to better preserve image quality while permitting robust and\ntractable detection. Most notably, WaterFlow demonstrates state-of-the-art\nperformance on general robustness and is the first method capable of\neffectively defending against difficult combination attacks. We validate our\nfindings on three widely used real and generated datasets: MS-COCO,\nDiffusionDB, and WikiArt.",
      "tldr_zh": "本文提出 WaterFlow，一种基于 Stable Diffusion 的快速且鲁棒的视觉水印方法，旨在解决现有技术的计算效率和鲁棒性问题。该方法利用预训练的潜在扩散模型将图像编码到潜在空间中，生成学习的水印并植入到 Fourier Domain，同时通过 invertible flow layers 增强潜在空间的表达性，以保持图像高保真度并实现可行检测。实验结果显示，WaterFlow 在 MS-COCO、DiffusionDB 和 WikiArt 数据集上达到了最先进的一般鲁棒性水平，并首次有效防御复杂组合攻击。",
      "categories": [
        "eess.IV",
        "cs.AI"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.12354v2",
      "published_date": "2025-04-15 23:27:52 UTC",
      "updated_date": "2025-04-18 02:12:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:04:28.492489"
    },
    {
      "arxiv_id": "2504.11658v1",
      "title": "Improving LLM Interpretability and Performance via Guided Embedding Refinement for Sequential Recommendation",
      "title_zh": "通过引导嵌入精炼提升 LLM 的可解释性和性能，用于序列推荐",
      "authors": [
        "Nanshan Jia",
        "Chenfei Yuan",
        "Yuhang Wu",
        "Zeyu Zheng"
      ],
      "abstract": "The fast development of Large Language Models (LLMs) offers growing\nopportunities to further improve sequential recommendation systems. Yet for\nsome practitioners, integrating LLMs to their existing base recommendation\nsystems raises questions about model interpretability, transparency and related\nsafety. To partly alleviate challenges from these questions, we propose guided\nembedding refinement, a method that carries out a guided and interpretable\nusage of LLM to enhance the embeddings associated with the base recommendation\nsystem. Instead of directly using LLMs as the backbone of sequential\nrecommendation systems, we utilize them as auxiliary tools to emulate the sales\nlogic of recommendation and generate guided embeddings that capture\ndomain-relevant semantic information on interpretable attributes. Benefiting\nfrom the strong generalization capabilities of the guided embedding, we\nconstruct refined embedding by using the guided embedding and reduced-dimension\nversion of the base embedding. We then integrate the refined embedding into the\nrecommendation module for training and inference. A range of numerical\nexperiments demonstrate that guided embedding is adaptable to various given\nexisting base embedding models, and generalizes well across different\nrecommendation tasks. The numerical results show that the refined embedding not\nonly improves recommendation performance, achieving approximately $10\\%$ to\n$50\\%$ gains in Mean Reciprocal Rank (MRR), Recall rate, and Normalized\nDiscounted Cumulative Gain (NDCG), but also enhances interpretability, as\nevidenced by case studies.",
      "tldr_zh": "这篇论文提出了一种名为 guided embedding refinement 的方法，利用 Large Language Models (LLMs) 作为辅助工具，提升序列推荐系统的性能和可解释性。该方法通过模拟销售逻辑生成指导嵌入 (guided embeddings)，这些嵌入捕捉与领域相关的语义信息，并与基线嵌入的简化版本结合，构建精炼嵌入并整合到推荐模块中。实验结果显示，该方法适用于多种基线模型，在不同推荐任务中表现出良好泛化性，实现了 Mean Reciprocal Rank (MRR)、Recall 和 Normalized Discounted Cumulative Gain (NDCG) 的 10% 到 50% 提升，同时通过案例研究增强了模型的可解释性。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.11658v1",
      "published_date": "2025-04-15 23:03:53 UTC",
      "updated_date": "2025-04-15 23:03:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:04:40.531103"
    },
    {
      "arxiv_id": "2504.11650v1",
      "title": "Data driven approach towards more efficient Newton-Raphson power flow calculation for distribution grids",
      "title_zh": "翻译失败",
      "authors": [
        "Shengyuan Yan",
        "Farzad Vazinram",
        "Zeynab Kaseb",
        "Lindsay Spoor",
        "Jochen Stiasny",
        "Betul Mamudi",
        "Amirhossein Heydarian Ardakani",
        "Ugochukwu Orji",
        "Pedro P. Vergara",
        "Yu Xiang",
        "Jerry Guo"
      ],
      "abstract": "Power flow (PF) calculations are fundamental to power system analysis to\nensure stable and reliable grid operation. The Newton-Raphson (NR) method is\ncommonly used for PF analysis due to its rapid convergence when initialized\nproperly. However, as power grids operate closer to their capacity limits,\nill-conditioned cases and convergence issues pose significant challenges. This\nwork, therefore, addresses these challenges by proposing strategies to improve\nNR initialization, hence minimizing iterations and avoiding divergence. We\nexplore three approaches: (i) an analytical method that estimates the basin of\nattraction using mathematical bounds on voltages, (ii) Two data-driven models\nleveraging supervised learning or physics-informed neural networks (PINNs) to\npredict optimal initial guesses, and (iii) a reinforcement learning (RL)\napproach that incrementally adjusts voltages to accelerate convergence. These\nmethods are tested on benchmark systems. This research is particularly relevant\nfor modern power systems, where high penetration of renewables and\ndecentralized generation require robust and scalable PF solutions. In\nexperiments, all three proposed methods demonstrate a strong ability to provide\nan initial guess for Newton-Raphson method to converge with fewer steps. The\nfindings provide a pathway for more efficient real-time grid operations, which,\nin turn, support the transition toward smarter and more resilient electricity\nnetworks.",
      "tldr_zh": "本研究针对电力系统中的 Newton-Raphson (NR) 功率流计算提出数据驱动方法，以改善初始化过程，减少迭代次数并避免发散问题。该方法包括三种策略：(i) 一种使用电压数学边界的分析方法估计吸引域，(ii) 基于监督学习或物理信息神经网络 (PINNs) 的模型预测最佳初始猜测，以及 (iii) 强化学习 (RL) 技术逐步调整电压以加速收敛。在基准系统中实验验证显示，这些方法使 NR 收敛步骤显著减少。该创新为现代电力系统（如高可再生能源渗透）提供更高效的实时操作解决方案，支持更智能和坚韧的电网。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.LG",
        "cs.NA",
        "cs.SY",
        "math.NA",
        "I.2.8"
      ],
      "primary_category": "eess.SY",
      "comment": "7 pages, 9 figures, 3 tables, 14 equations, 1 lemma, and 2 theorems.\n  ICT for Industry 2025 Alliander usecase workshop paper. Oral presentation of\n  this paper accepted and to be given on 16th April 2025 in ICT.OPEN 2025\n  conference of Netherlands in the Beatrix Theatre in Utrecht",
      "pdf_url": "http://arxiv.org/pdf/2504.11650v1",
      "published_date": "2025-04-15 22:37:55 UTC",
      "updated_date": "2025-04-15 22:37:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:04:53.082195"
    },
    {
      "arxiv_id": "2504.11645v1",
      "title": "Achieving Tighter Finite-Time Rates for Heterogeneous Federated Stochastic Approximation under Markovian Sampling",
      "title_zh": "在Markovian采样下实现异构联邦随机逼近的更紧有限时间收敛率",
      "authors": [
        "Feng Zhu",
        "Aritra Mitra",
        "Robert W. Heath"
      ],
      "abstract": "Motivated by collaborative reinforcement learning (RL) and optimization with\ntime-correlated data, we study a generic federated stochastic approximation\nproblem involving $M$ agents, where each agent is characterized by an\nagent-specific (potentially nonlinear) local operator. The goal is for the\nagents to communicate intermittently via a server to find the root of the\naverage of the agents' local operators. The generality of our setting stems\nfrom allowing for (i) Markovian data at each agent and (ii) heterogeneity in\nthe roots of the agents' local operators. The limited recent work that has\naccounted for both these features in a federated setting fails to guarantee\nconvergence to the desired point or to show any benefit of collaboration;\nfurthermore, they rely on projection steps in their algorithms to guarantee\nbounded iterates. Our work overcomes each of these limitations. We develop a\nnovel algorithm titled \\texttt{FedHSA}, and prove that it guarantees\nconvergence to the correct point, while enjoying an $M$-fold linear speedup in\nsample-complexity due to collaboration. To our knowledge, \\emph{this is the\nfirst finite-time result of its kind}, and establishing it (without relying on\na projection step) entails a fairly intricate argument that accounts for the\ninterplay between complex temporal correlations due to Markovian sampling,\nmultiple local steps to save communication, and the drift-effects induced by\nheterogeneous local operators. Our results have implications for a broad class\nof heterogeneous federated RL problems (e.g., policy evaluation and control)\nwith function approximation, where the agents' Markov decision processes can\ndiffer in their probability transition kernels and reward functions.",
      "tldr_zh": "本研究针对异质联邦随机逼近（Federated Stochastic Approximation）问题，考虑了每个代理的Markovian采样和局部操作符根的异质性，旨在通过代理间歇性通信找到局部操作符平均的根。研究提出了一种新算法FedHSA，能够保证收敛到正确点，并实现M倍的线性加速在样本复杂度上，而无需依赖投影步骤。实验结果显示，该算法首次提供了此类有限时间收敛率（Finite-Time Rates），并有效处理了Markovian采样的时间相关性、多个本地步骤节省通信以及异质操作符的漂移效应。该方法适用于广泛的异质联邦强化学习（Federated RL）场景，如策略评估和控制，使用函数逼近时代理的Markov决策过程（MDPs）可能在转移核和奖励函数上不同。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SY",
        "eess.SY",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.11645v1",
      "published_date": "2025-04-15 22:13:55 UTC",
      "updated_date": "2025-04-15 22:13:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:05:05.309234"
    },
    {
      "arxiv_id": "2504.20059v1",
      "title": "Recommending Clinical Trials for Online Patient Cases using Artificial Intelligence",
      "title_zh": "使用人工智能为在线患者病例推荐临床试验",
      "authors": [
        "Joey Chan",
        "Qiao Jin",
        "Nicholas Wan",
        "Charalampos S. Floudas",
        "Elisabetta Xue",
        "Zhiyong Lu"
      ],
      "abstract": "Clinical trials are crucial for assessing new treatments; however,\nrecruitment challenges - such as limited awareness, complex eligibility\ncriteria, and referral barriers - hinder their success. With the growth of\nonline platforms, patients increasingly turn to social media and health\ncommunities for support, research, and advocacy, expanding recruitment pools\nand established enrollment pathways. Recognizing this potential, we utilized\nTrialGPT, a framework that leverages a large language model (LLM) as its\nbackbone, to match 50 online patient cases (collected from published case\nreports and a social media website) to clinical trials and evaluate performance\nagainst traditional keyword-based searches. Our results show that TrialGPT\noutperforms traditional methods by 46% in identifying eligible trials, with\neach patient, on average, being eligible for around 7 trials. Additionally, our\noutreach efforts to case authors and trial organizers regarding these\npatient-trial matches yielded highly positive feedback, which we present from\nboth perspectives.",
      "tldr_zh": "该研究针对临床试验招募的挑战（如意识不足和复杂资格标准），提出使用 TrialGPT 框架，该框架基于大型语言模型 (LLM) 来为在线患者案例推荐合适的试验。研究将 50 个患者案例（来自已发表报告和社交媒体）与临床试验匹配，结果显示 TrialGPT 比传统关键词搜索提高了 46% 的识别准确率，每个患者平均适合约 7 个试验。此外，向案例作者和试验组织者的外联反馈非常积极，证明了该方法的实际价值。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "10 pages with 2 figures and 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2504.20059v1",
      "published_date": "2025-04-15 21:56:36 UTC",
      "updated_date": "2025-04-15 21:56:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:05:15.685478"
    },
    {
      "arxiv_id": "2504.13941v2",
      "title": "Nemotron-CrossThink: Scaling Self-Learning beyond Math Reasoning",
      "title_zh": "Nemotron-CrossThink：将自学习扩展至超越数学推理",
      "authors": [
        "Syeda Nahida Akter",
        "Shrimai Prabhumoye",
        "Matvei Novikov",
        "Seungju Han",
        "Ying Lin",
        "Evelina Bakhturina",
        "Eric Nyberg",
        "Yejin Choi",
        "Mostofa Patwary",
        "Mohammad Shoeybi",
        "Bryan Catanzaro"
      ],
      "abstract": "Large Language Models (LLMs) have shown strong reasoning capabilities,\nparticularly when enhanced through Reinforcement Learning (RL). While prior\nwork has successfully applied RL to mathematical reasoning -- where rules and\ncorrectness are well-defined -- generalizing these methods to broader reasoning\ndomains remains challenging due to limited data, the lack of verifiable reward\nstructures, and diverse task requirements. In this work, we propose\nNEMOTRON-CROSSTHINK, a framework that systematically incorporates multi-domain\ncorpora, including both synthetic and real-world question-answer pairs, into RL\ntraining to improve generalization across diverse reasoning tasks.\nNEMOTRON-CROSSTHINK addresses key challenges by (1) incorporating data from\nvaried sources spanning STEM, humanities, social sciences, etc.; (2) applying\nstructured templates (e.g., multiple-choice and open-ended) to control\nanswer-space complexity; (3) filtering for verifiable answers; and (4)\noptimizing data blending strategies that utilizes data from multiple sources\neffectively. Our approach enables scalable and verifiable reward modeling\nbeyond mathematics and demonstrates improved accuracies on both math (MATH-500:\n+30.1%, AMC23:+27.5%) and non-math reasoning benchmarks (MMLU-PRO: +12.8%,\nGPQA-DIAMOND: +11.3%, AGIEVAL: +15.1%, SUPERGPQA: +3.8%). Moreover,\nNEMOTRON-CROSSTHINK exhibits significantly improved response efficiency --\nusing 28% fewer tokens for correct answers -- highlighting more focused and\neffective reasoning. Through NEMOTRON-CROSSTHINK, we demonstrate that\nintegrating multi-domain, multi-format data in RL leads to more accurate,\nefficient, and generalizable LLMs.",
      "tldr_zh": "这篇论文提出了NEMOTRON-CROSSTHINK框架，通过将多领域语料（如STEM、人文和社会科学中的合成和真实问题-答案对）整合到Reinforcement Learning (RL)训练中，扩展Large Language Models (LLMs)的自学习能力，超越数学推理的局限。框架的关键方法包括使用结构化模板（如多项选择和开放式问题）控制答案复杂度、过滤可验证答案，以及优化数据混合策略，以应对数据稀缺和奖励结构缺失的挑战。实验结果显示，该框架在数学基准（如MATH-500提高30.1%、AMC23提高27.5%）和非数学基准（如MMLU-PRO提高12.8%、GPQA-DIAMOND提高11.3%）上显著提升准确率，并减少28%的tokens使用，实现了更高效的推理。总之，这证明了在RL中整合多领域数据的有效性，能使LLMs更准确、可泛化和高效。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "18 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.13941v2",
      "published_date": "2025-04-15 21:37:13 UTC",
      "updated_date": "2025-04-24 02:38:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:05:30.058962"
    },
    {
      "arxiv_id": "2504.11626v1",
      "title": "Improving Instruct Models for Free: A Study on Partial Adaptation",
      "title_zh": "免费改进指令模型：关于部分适应的研究",
      "authors": [
        "Ozan İrsoy",
        "Pengxiang Cheng",
        "Jennifer L. Chen",
        "Daniel Preoţiuc-Pietro",
        "Shiyue Zhang",
        "Duccio Pappadopulo"
      ],
      "abstract": "Instruct models, obtained from various instruction tuning or post-training\nsteps, are commonly deemed superior and more usable than their base\ncounterpart. While the model gains instruction following ability, instruction\ntuning may lead to forgetting the knowledge from pre-training or it may\nencourage the model being overly conversational or verbose. This, in turn, can\nlead to degradation of in-context few-shot learning performance. In this work,\nwe study the performance trajectory between base and instruct models by scaling\ndown the strength of instruction-tuning via the partial adaption method. We\nshow that, across several model families and model sizes, reducing the strength\nof instruction-tuning results in material improvement on a few-shot in-context\nlearning benchmark covering a variety of classic natural language tasks. This\ncomes at the cost of losing some degree of instruction following ability as\nmeasured by AlpacaEval. Our study shines light on the potential trade-off\nbetween in-context learning and instruction following abilities that is worth\nconsidering in practice.",
      "tldr_zh": "本文研究了 partial adaptation 方法，通过降低指令微调强度来改善 instruct models 的性能，避免指令微调导致的知识遗忘和过度对话化问题。实验结果显示，在多个模型系列和大小上，这种方法显著提升了 few-shot in-context learning 的表现，覆盖各种经典自然语言处理任务。然而，这会以牺牲部分指令遵循能力为代价，如 AlpacaEval 评估所示。该研究突出了 in-context learning 与指令遵循能力之间的权衡，在实际应用中值得权衡。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Author ordering chosen at random",
      "pdf_url": "http://arxiv.org/pdf/2504.11626v1",
      "published_date": "2025-04-15 21:35:09 UTC",
      "updated_date": "2025-04-15 21:35:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:05:40.484134"
    },
    {
      "arxiv_id": "2504.12352v2",
      "title": "Deep Generative Model-Based Generation of Synthetic Individual-Specific Brain MRI Segmentations",
      "title_zh": "翻译失败",
      "authors": [
        "Ruijie Wang",
        "Luca Rossetto",
        "Susan Mérillat",
        "Christina Röcke",
        "Mike Martin",
        "Abraham Bernstein"
      ],
      "abstract": "To the best of our knowledge, all existing methods that can generate\nsynthetic brain magnetic resonance imaging (MRI) scans for a specific\nindividual require detailed structural or volumetric information about the\nindividual's brain. However, such brain information is often scarce, expensive,\nand difficult to obtain. In this paper, we propose the first approach capable\nof generating synthetic brain MRI segmentations -- specifically, 3D white\nmatter (WM), gray matter (GM), and cerebrospinal fluid (CSF) segmentations --\nfor individuals using their easily obtainable and often readily available\ndemographic, interview, and cognitive test information. Our approach features a\nnovel deep generative model, CSegSynth, which outperforms existing prominent\ngenerative models, including conditional variational autoencoder (C-VAE),\nconditional generative adversarial network (C-GAN), and conditional latent\ndiffusion model (C-LDM). We demonstrate the high quality of our synthetic\nsegmentations through extensive evaluations. Also, in assessing the\neffectiveness of the individual-specific generation, we achieve superior volume\nprediction, with mean absolute errors of only 36.44mL, 29.20mL, and 35.51mL\nbetween the ground-truth WM, GM, and CSF volumes of test individuals and those\nvolumes predicted based on generated individual-specific segmentations,\nrespectively.",
      "tldr_zh": "本文提出了一种新颖的深度生成模型CSegSynth，用于基于个体的基本信息（如人口统计学、访谈和认知测试数据）生成合成个体特定脑MRI分割，包括3D的白质(WM)、灰质(GM)和脑脊液(CSF)分割，这是有史以来首个无需详细结构或体积信息的方法。CSegSynth在性能上优于现有的生成模型，如conditional variational autoencoder (C-VAE)、conditional generative adversarial network (C-GAN)和conditional latent diffusion model (C-LDM)。实验结果显示，该模型在体积预测方面表现出色，WM、GM和CSF的平均绝对误差分别为36.44mL、29.20mL和35.51mL，证明了其在脑MRI合成领域的潜在应用价值。",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "q-bio.NC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.12352v2",
      "published_date": "2025-04-15 21:25:36 UTC",
      "updated_date": "2025-04-23 18:53:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:05:52.511355"
    },
    {
      "arxiv_id": "2504.11623v1",
      "title": "Possibility for Proactive Anomaly Detection",
      "title_zh": "主动异常检测的可能性",
      "authors": [
        "Jinsung Jeon",
        "Jaehyeon Park",
        "Sewon Park",
        "Jeongwhan Choi",
        "Minjung Kim",
        "Noseong Park"
      ],
      "abstract": "Time-series anomaly detection, which detects errors and failures in a\nworkflow, is one of the most important topics in real-world applications. The\npurpose of time-series anomaly detection is to reduce potential damages or\nlosses. However, existing anomaly detection models detect anomalies through the\nerror between the model output and the ground truth (observed) value, which\nmakes them impractical. In this work, we present a \\textit{proactive} approach\nfor time-series anomaly detection based on a time-series forecasting model\nspecialized for anomaly detection and a data-driven anomaly detection model.\nOur proactive approach establishes an anomaly threshold from training data with\na data-driven anomaly detection model, and anomalies are subsequently detected\nby identifying predicted values that exceed the anomaly threshold. In addition,\nwe extensively evaluated the model using four anomaly detection benchmarks and\nanalyzed both predictable and unpredictable anomalies. We attached the source\ncode as supplementary material.",
      "tldr_zh": "本文提出了一种主动（proactive）时间序列异常检测方法，以解决现有模型依赖模型输出与真实值误差的局限性，从而提高实际应用的可行性。该方法结合时间序列预测模型和数据驱动的异常检测模型，从训练数据中建立异常阈值，并通过检测预测值超过阈值的异常来实现提前识别。实验在四个异常检测基准上进行了广泛评估，分析了可预测和不可预测的异常类型，并提供了源代码作为补充材料。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at ICLR 2025 I Can't Believe It's Not Better: Challenges in\n  Applied Deep Learning Workshop (ICBINB)",
      "pdf_url": "http://arxiv.org/pdf/2504.11623v1",
      "published_date": "2025-04-15 21:25:02 UTC",
      "updated_date": "2025-04-15 21:25:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:06:05.180088"
    },
    {
      "arxiv_id": "2504.12351v1",
      "title": "Prototype-Guided Diffusion for Digital Pathology: Achieving Foundation Model Performance with Minimal Clinical Data",
      "title_zh": "翻译失败",
      "authors": [
        "Ekaterina Redekop",
        "Mara Pleasure",
        "Vedrana Ivezic",
        "Zichen Wang",
        "Kimberly Flores",
        "Anthony Sisk",
        "William Speier",
        "Corey Arnold"
      ],
      "abstract": "Foundation models in digital pathology use massive datasets to learn useful\ncompact feature representations of complex histology images. However, there is\nlimited transparency into what drives the correlation between dataset size and\nperformance, raising the question of whether simply adding more data to\nincrease performance is always necessary. In this study, we propose a\nprototype-guided diffusion model to generate high-fidelity synthetic pathology\ndata at scale, enabling large-scale self-supervised learning and reducing\nreliance on real patient samples while preserving downstream performance. Using\nguidance from histological prototypes during sampling, our approach ensures\nbiologically and diagnostically meaningful variations in the generated data. We\ndemonstrate that self-supervised features trained on our synthetic dataset\nachieve competitive performance despite using ~60x-760x less data than models\ntrained on large real-world datasets. Notably, models trained using our\nsynthetic data showed statistically comparable or better performance across\nmultiple evaluation metrics and tasks, even when compared to models trained on\norders of magnitude larger datasets. Our hybrid approach, combining synthetic\nand real data, further enhanced performance, achieving top results in several\nevaluations. These findings underscore the potential of generative AI to create\ncompelling training data for digital pathology, significantly reducing the\nreliance on extensive clinical datasets and highlighting the efficiency of our\napproach.",
      "tldr_zh": "本研究提出了一种prototype-guided diffusion model，用于生成高保真合成病理数据，以实现大规模自监督学习，同时大幅减少对真实临床数据的依赖。\n该模型通过组织学原型（histological prototypes）指导采样，确保生成的數據在生物学和诊断上具有意义。\n实验显示，使用合成数据集训练的模型在下游任务上表现出色，与使用60x-760x更多真实数据的模型相比，性能相当或更好。\n这种结合合成和真实数据的混合方法进一步提升了整体表现，突显了生成AI在数字病理学中提高效率和降低数据需求的潜力。",
      "categories": [
        "cs.GR",
        "cs.AI",
        "eess.IV",
        "q-bio.TO"
      ],
      "primary_category": "cs.GR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.12351v1",
      "published_date": "2025-04-15 21:17:39 UTC",
      "updated_date": "2025-04-15 21:17:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:06:17.487243"
    },
    {
      "arxiv_id": "2504.12350v1",
      "title": "A Large-Language Model Framework for Relative Timeline Extraction from PubMed Case Reports",
      "title_zh": "翻译失败",
      "authors": [
        "Jing Wang",
        "Jeremy C Weiss"
      ],
      "abstract": "Timing of clinical events is central to characterization of patient\ntrajectories, enabling analyses such as process tracing, forecasting, and\ncausal reasoning. However, structured electronic health records capture few\ndata elements critical to these tasks, while clinical reports lack temporal\nlocalization of events in structured form. We present a system that transforms\ncase reports into textual time series-structured pairs of textual events and\ntimestamps. We contrast manual and large language model (LLM) annotations\n(n=320 and n=390 respectively) of ten randomly-sampled PubMed open-access\n(PMOA) case reports (N=152,974) and assess inter-LLM agreement (n=3,103; N=93).\nWe find that the LLM models have moderate event recall(O1-preview: 0.80) but\nhigh temporal concordance among identified events (O1-preview: 0.95). By\nestablishing the task, annotation, and assessment systems, and by demonstrating\nhigh concordance, this work may serve as a benchmark for leveraging the PMOA\ncorpus for temporal analytics.",
      "tldr_zh": "这篇论文提出了一种Large Language Model (LLM) 框架，用于从PubMed病例报告中提取相对时间线，以支持患者轨迹分析、过程追踪、预测和因果推理。框架将病例报告转化为结构化的文本事件和时间戳对，并通过比较手动标注（n=320）和LLM标注（n=390）来评估其性能，同时检查LLM间一致性（n=3,103; N=93）。结果显示，LLM在事件召回上中等（O1-preview: 0.80），但在时间一致性上很高（O1-preview: 0.95），为利用PubMed开放访问语料库进行时间分析提供了重要基准。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.12350v1",
      "published_date": "2025-04-15 20:54:19 UTC",
      "updated_date": "2025-04-15 20:54:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:06:29.924236"
    },
    {
      "arxiv_id": "2504.11609v1",
      "title": "Towards Interpretable Deep Generative Models via Causal Representation Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Gemma E. Moran",
        "Bryon Aragam"
      ],
      "abstract": "Recent developments in generative artificial intelligence (AI) rely on\nmachine learning techniques such as deep learning and generative modeling to\nachieve state-of-the-art performance across wide-ranging domains. These\nmethods' surprising performance is due in part to their ability to learn\nimplicit \"representations'' of complex, multi-modal data. Unfortunately, deep\nneural networks are notoriously black boxes that obscure these representations,\nmaking them difficult to interpret or analyze. To resolve these difficulties,\none approach is to build new interpretable neural network models from the\nground up. This is the goal of the emerging field of causal representation\nlearning (CRL) that uses causality as a vector for building flexible,\ninterpretable, and transferable generative AI. CRL can be seen as a culmination\nof three intrinsically statistical problems: (i) latent variable models such as\nfactor analysis; (ii) causal graphical models with latent variables; and (iii)\nnonparametric statistics and deep learning. This paper reviews recent progress\nin CRL from a statistical perspective, focusing on connections to classical\nmodels and statistical and causal identifiablity results. This review also\nhighlights key application areas, implementation strategies, and open\nstatistical questions in CRL.",
      "tldr_zh": "该论文探讨了通过因果表示学习（Causal Representation Learning, CRL）来提升深度生成模型的可解释性问题，以解决传统深度神经网络的黑箱特性。CRL 将潜在变量模型（如因子分析）、带有潜在变量的因果图形模型以及非参数统计和深度学习相结合，构建出灵活、可转移的生成式 AI 框架。论文从统计视角回顾了 CRL 的最新进展，包括统计和因果可识别性结果，并强调了其在关键应用领域中的实现策略和未解决的统计问题。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG",
        "stat.ME"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.11609v1",
      "published_date": "2025-04-15 20:46:42 UTC",
      "updated_date": "2025-04-15 20:46:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:06:40.922341"
    },
    {
      "arxiv_id": "2504.13205v1",
      "title": "On-Device Watermarking: A Socio-Technical Imperative For Authenticity In The Age of Generative AI",
      "title_zh": "翻译失败",
      "authors": [
        "Houssam Kherraz"
      ],
      "abstract": "As generative AI models produce increasingly realistic output, both academia\nand industry are focusing on the ability to detect whether an output was\ngenerated by an AI model or not. Many of the research efforts and policy\ndiscourse are centered around robust watermarking of AI outputs. While plenty\nof progress has been made, all watermarking and AI detection techniques face\nsevere limitations. In this position paper, we argue that we are adopting the\nwrong approach, and should instead focus on watermarking via cryptographic\nsignatures trustworthy content rather than AI generated ones. For audio-visual\ncontent, in particular, all real content is grounded in the physical world and\ncaptured via hardware sensors. This presents a unique opportunity to watermark\nat the hardware layer, and we lay out a socio-technical framework and draw\nparallels with HTTPS certification and Blu-Ray verification protocols. While\nacknowledging implementation challenges, we contend that hardware-based\nauthentication offers a more tractable path forward, particularly from a policy\nperspective. As generative models approach perceptual indistinguishability, the\nresearch community should be wary of being overly optimistic with AI\nwatermarking, and we argue that AI watermarking research efforts are better\nspent in the text and LLM space, which are ultimately not traceable to a\nphysical sensor.",
      "tldr_zh": "该论文主张，在生成式AI时代，确保内容真实性的关键在于采用硬件层水印，而不是依赖AI输出水印，因为后者存在严重局限性。作者提出一个社会-技术框架，利用加密签名(cryptographic signatures)对音频-视觉内容进行硬件层认证，并与HTTPS certification和Blu-Ray verification协议类比，以实现更可靠的真实性验证。尽管实施面临挑战，但这种方法在政策层面更具可行性，并建议AI watermarking研究应优先转向文本和LLM领域，因为这些内容不依赖物理传感器。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "10 pages, 3 figures, ICLR 2025,\n  https://openreview.net/forum?id=ygE0U21vxM",
      "pdf_url": "http://arxiv.org/pdf/2504.13205v1",
      "published_date": "2025-04-15 20:36:52 UTC",
      "updated_date": "2025-04-15 20:36:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:06:52.130121"
    },
    {
      "arxiv_id": "2504.11588v1",
      "title": "Deep Learning Approaches for Medical Imaging Under Varying Degrees of Label Availability: A Comprehensive Survey",
      "title_zh": "在不同标签可用度下的医学成像深度学习方法：一个全面综述",
      "authors": [
        "Siteng Ma",
        "Honghui Du",
        "Yu An",
        "Jing Wang",
        "Qinqin Wang",
        "Haochang Wu",
        "Aonghus Lawlor",
        "Ruihai Dong"
      ],
      "abstract": "Deep learning has achieved significant breakthroughs in medical imaging, but\nthese advancements are often dependent on large, well-annotated datasets.\nHowever, obtaining such datasets poses a significant challenge, as it requires\ntime-consuming and labor-intensive annotations from medical experts.\nConsequently, there is growing interest in learning paradigms such as\nincomplete, inexact, and absent supervision, which are designed to operate\nunder limited, inexact, or missing labels. This survey categorizes and reviews\nthe evolving research in these areas, analyzing around 600 notable\ncontributions since 2018. It covers tasks such as image classification,\nsegmentation, and detection across various medical application areas, including\nbut not limited to brain, chest, and cardiac imaging. We attempt to establish\nthe relationships among existing research studies in related areas. We provide\nformal definitions of different learning paradigms and offer a comprehensive\nsummary and interpretation of various learning mechanisms and strategies,\naiding readers in better understanding the current research landscape and\nideas. We also discuss potential future research challenges.",
      "tldr_zh": "这篇综述论文探讨了深度学习在医疗成像中的应用，特别是面对标签可用性不足（如incomplete supervision、inexact supervision和absent supervision）时的挑战。论文分析了约600个自2018年以来的研究，涵盖图像分类、segmentation和detection等任务，并应用于脑、胸部和心脏成像等领域。作者提供了这些学习范式的正式定义、机制总结以及研究间的关联，帮助读者理解当前景观，并指出了潜在的未来研究挑战。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "68T07, 68T45, 92C50, 92C55",
        "I.2.10; I.4.5; I.4.6; I.4.9; J.3"
      ],
      "primary_category": "cs.CV",
      "comment": "33 pages, 10 figures, 8 tables. Will be submit to Medical Image\n  Analysis",
      "pdf_url": "http://arxiv.org/pdf/2504.11588v1",
      "published_date": "2025-04-15 20:06:43 UTC",
      "updated_date": "2025-04-15 20:06:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:07:04.685205"
    },
    {
      "arxiv_id": "2504.11575v1",
      "title": "MULTI-LF: A Unified Continuous Learning Framework for Real-Time DDoS Detection in Multi-Environment Networks",
      "title_zh": "MULTI-LF：一个统一的连续学习框架，用于多环境网络中的实时 DDoS 检测",
      "authors": [
        "Furqan Rustam",
        "Islam Obaidat",
        "Anca Delia Jurcut"
      ],
      "abstract": "Detecting Distributed Denial of Service (DDoS) attacks in Multi-Environment\n(M-En) networks presents significant challenges due to diverse malicious\ntraffic patterns and the evolving nature of cyber threats. Existing AI-based\ndetection systems struggle to adapt to new attack strategies and lack real-time\nattack detection capabilities with high accuracy and efficiency. This study\nproposes an online, continuous learning methodology for DDoS detection in M-En\nnetworks, enabling continuous model updates and real-time adaptation to\nemerging threats, including zero-day attacks. First, we develop a unique M-En\nnetwork dataset by setting up a realistic, real-time simulation using the NS-3\ntool, incorporating both victim and bot devices. DDoS attacks with varying\npacket sizes are simulated using the DDoSim application across IoT and\ntraditional IP-based environments under M-En network criteria. Our approach\nemploys a multi-level framework (MULTI-LF) featuring two machine learning\nmodels: a lightweight Model 1 (M1) trained on a selective, critical packet\ndataset for fast and efficient initial detection, and a more complex, highly\naccurate Model 2 (M2) trained on extensive data. When M1 exhibits low\nconfidence in its predictions, the decision is escalated to M2 for verification\nand potential fine-tuning of M1 using insights from M2. If both models\ndemonstrate low confidence, the system flags the incident for human\nintervention, facilitating model updates with human-verified categories to\nenhance adaptability to unseen attack patterns. We validate the MULTI-LF\nthrough real-world simulations, demonstrating superior classification accuracy\nof 0.999 and low prediction latency of 0.866 seconds compared to established\nbaselines. Furthermore, we evaluate performance in terms of memory usage (3.632\nMB) and CPU utilization (10.05%) in real-time scenarios.",
      "tldr_zh": "本研究针对多环境（M-En）网络中 DDoS 攻击的多样化威胁，提出一个统一的连续学习框架 MULTI-LF，以实现实时检测和适应新兴威胁，包括 zero-day attacks。框架采用两个机器学习模型：轻量级 Model 1 (M1) 用于快速初始检测基于关键包数据集，以及复杂 Model 2 (M2) 用于验证和微调 M1；当模型信心不足时，系统会升级到人工干预以更新模型，提升对未知攻击的适应性。该框架通过 NS-3 工具模拟的真实数据集验证，实现了 0.999 的分类准确率、0.866 秒的预测延迟，以及低资源消耗（3.632 MB 内存和 10.05% CPU 使用率），显著优于现有基线方法。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.11575v1",
      "published_date": "2025-04-15 19:44:53 UTC",
      "updated_date": "2025-04-15 19:44:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:07:18.350312"
    },
    {
      "arxiv_id": "2504.11571v1",
      "title": "GraphicBench: A Planning Benchmark for Graphic Design with Language Agents",
      "title_zh": "GraphicBench：图形",
      "authors": [
        "Dayeon Ki",
        "Tianyi Zhou",
        "Marine Carpuat",
        "Gang Wu",
        "Puneet Mathur",
        "Viswanathan Swaminathan"
      ],
      "abstract": "Large Language Model (LLM)-powered agents have unlocked new possibilities for\nautomating human tasks. While prior work has focused on well-defined tasks with\nspecified goals, the capabilities of agents in creative design tasks with\nopen-ended goals remain underexplored. We introduce GraphicBench, a new\nplanning benchmark for graphic design that covers 1,079 user queries and input\nimages across four design types. We further present GraphicTown, an LLM agent\nframework with three design experts and 46 actions (tools) to choose from for\nexecuting each step of the planned workflows in web environments. Experiments\nwith six LLMs demonstrate their ability to generate workflows that integrate\nboth explicit design constraints from user queries and implicit commonsense\nconstraints. However, these workflows often do not lead to successful execution\noutcomes, primarily due to challenges in: (1) reasoning about spatial\nrelationships, (2) coordinating global dependencies across experts, and (3)\nretrieving the most appropriate action per step. We envision GraphicBench as a\nchallenging yet valuable testbed for advancing LLM-agent planning and execution\nin creative design tasks.",
      "tldr_zh": "该研究引入了GraphicBench，一个针对图形设计的规划基准，涵盖1,079个用户查询和输入图像的四种设计类型，用于评估Large Language Model (LLM)代理在开放目标创意任务中的性能。同时，提出了GraphicTown框架，该框架包括三个设计专家和46个动作工具，用于生成并执行工作流，整合用户查询的显式约束和隐式常识约束。实验使用六种LLMs表明，代理能有效生成工作流，但执行成功率较低，主要受限于推理空间关系、协调专家间的全局依赖以及选择合适动作的挑战。总之，GraphicBench作为测试平台，有望推动LLM代理在创意设计任务中的规划和执行能力发展。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "41 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.11571v1",
      "published_date": "2025-04-15 19:26:59 UTC",
      "updated_date": "2025-04-15 19:26:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:07:28.946298"
    },
    {
      "arxiv_id": "2504.11564v1",
      "title": "Perceptions of Agentic AI in Organizations: Implications for Responsible AI and ROI",
      "title_zh": "组织中",
      "authors": [
        "Lee Ackerman"
      ],
      "abstract": "As artificial intelligence (AI) systems rapidly gain autonomy, the need for\nrobust responsible AI frameworks becomes paramount. This paper investigates how\norganizations perceive and adapt such frameworks amidst the emerging landscape\nof increasingly sophisticated agentic AI. Employing an interpretive qualitative\napproach, the study explores the lived experiences of AI professionals.\nFindings highlight that the inherent complexity of agentic AI systems and their\nresponsible implementation, rooted in the intricate interconnectedness of\nresponsible AI dimensions and the thematic framework (an analytical structure\ndeveloped from the data), combined with the novelty of agentic AI, contribute\nto significant challenges in organizational adaptation, characterized by\nknowledge gaps, a limited emphasis on stakeholder engagement, and a strong\nfocus on control. These factors, by hindering effective adaptation and\nimplementation, ultimately compromise the potential for responsible AI and the\nrealization of ROI.",
      "tldr_zh": "本研究探讨了组织对代理式 AI (agentic AI) 的感知及其对负责任 AI 和 ROI 的影响，采用解释性定性方法分析 AI 专业人士的亲身经历。研究发现，agentic AI 的复杂性及其负责任实施的相互关联性导致组织面临重大适应挑战，包括知识缺口、有限的利益相关者参与以及对控制的过度强调。这些挑战阻碍了有效实施，进而削弱了负责任 AI 的潜力并影响 ROI 的实现。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "68T99 (Primary), 91D25 (Secondary)",
        "K.4; I.2; K.4.2; K.4.3"
      ],
      "primary_category": "cs.CY",
      "comment": "26 pages, 15 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.11564v1",
      "published_date": "2025-04-15 19:15:06 UTC",
      "updated_date": "2025-04-15 19:15:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:07:39.518142"
    },
    {
      "arxiv_id": "2504.11558v1",
      "title": "Error Broadcast and Decorrelation as a Potential Artificial and Natural Learning Mechanism",
      "title_zh": "翻译失败",
      "authors": [
        "Mete Erdogan",
        "Cengiz Pehlevan",
        "Alper T. Erdogan"
      ],
      "abstract": "We introduce the Error Broadcast and Decorrelation (EBD) algorithm, a novel\nlearning framework that addresses the credit assignment problem in neural\nnetworks by directly broadcasting output error to individual layers. Leveraging\nthe stochastic orthogonality property of the optimal minimum mean square error\n(MMSE) estimator, EBD defines layerwise loss functions to penalize correlations\nbetween layer activations and output errors, offering a principled approach to\nerror broadcasting without the need for weight transport. The optimization\nframework naturally leads to the experimentally observed three-factor learning\nrule and integrates with biologically plausible frameworks to enhance\nperformance and plausibility. Numerical experiments demonstrate that EBD\nachieves performance comparable to or better than known error-broadcast methods\non benchmark datasets. While the scalability of EBD to very large or complex\ndatasets remains to be further explored, our findings suggest it provides a\nbiologically plausible, efficient, and adaptable alternative for neural network\ntraining. This approach could inform future advancements in artificial and\nnatural learning paradigms.",
      "tldr_zh": "我们引入了 Error Broadcast and Decorrelation (EBD) 算法，这是一种新型学习框架，用于解决神经网络中的 credit assignment 问题，通过直接广播输出错误到各个层，并利用 optimal minimum mean square error (MMSE) 估计器的 stochastic orthogonality 属性定义层级损失函数来惩罚层激活与输出错误的相关性。EBD 无需 weight transport，便能自然导出实验观察到的 three-factor learning rule，并与生物上可信的框架整合，提升训练性能和可解释性。数值实验显示，EBD 在基准数据集上表现与现有错误广播方法相当或更好，虽然其在大规模数据集上的可扩展性需进一步探索，但该方法为人工和自然学习范式提供了高效、可适应的替代方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.11558v1",
      "published_date": "2025-04-15 19:00:53 UTC",
      "updated_date": "2025-04-15 19:00:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:07:53.473212"
    },
    {
      "arxiv_id": "2504.11547v1",
      "title": "Probabilistic causal graphs as categorical data synthesizers: Do they do better than Gaussian Copulas and Conditional Tabular GANs?",
      "title_zh": "翻译失败",
      "authors": [
        "Olha Shaposhnyk",
        "Noor Abid",
        "Mouri Zakir",
        "Svetlana Yanushkevich"
      ],
      "abstract": "This study investigates the generation of high-quality synthetic categorical\ndata, such as survey data, using causal graph models. Generating synthetic data\naims not only to create a variety of data for training the models but also to\npreserve privacy while capturing relationships between the data. The research\nemploys Structural Equation Modeling (SEM) followed by Bayesian Networks (BN).\nWe used the categorical data that are based on the survey of accessibility to\nservices for people with disabilities. We created both SEM and BN models to\nrepresent causal relationships and to capture joint distributions between\nvariables. In our case studies, such variables include, in particular,\ndemographics, types of disability, types of accessibility barriers and\nfrequencies of encountering those barriers.\n  The study compared the SEM-based BN method with alternative approaches,\nincluding the probabilistic Gaussian copula technique and generative models\nlike the Conditional Tabular Generative Adversarial Network (CTGAN). The\nproposed method outperformed others in statistical metrics, including the\nChi-square test, Kullback-Leibler divergence, and Total Variation Distance\n(TVD). In particular, the BN model demonstrated superior performance, achieving\nthe highest TVD, indicating alignment with the original data. The Gaussian\nCopula ranked second, while CTGAN exhibited moderate performance. These\nanalyses confirmed the ability of the SEM-based BN to produce synthetic data\nthat maintain statistical and relational validity while maintaining\nconfidentiality. This approach is particularly beneficial for research on\nsensitive data, such as accessibility and disability studies.",
      "tldr_zh": "本研究探讨了使用概率因果图模型生成高质量合成分类数据（如调查数据），以实现数据多样性、隐私保护和变量间关系捕捉。研究采用 Structural Equation Modeling (SEM) 后跟 Bayesian Networks (BN) 方法，基于残疾人群服务可访问性调查数据，建模变量如人口统计、残疾类型和可访问性障碍。相比于 Gaussian Copulas 和 Conditional Tabular GANs (CTGAN)，SEM-based BN 在 Chi-square test、Kullback-Leibler divergence 和 Total Variation Distance (TVD) 等统计指标上表现出色，特别是 BN 模型的 TVD 最高，证明其在保持数据统计及关系有效性方面更具优势。该方法为敏感数据研究（如残疾研究）提供更可靠的合成数据生成框架。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.11547v1",
      "published_date": "2025-04-15 18:41:54 UTC",
      "updated_date": "2025-04-15 18:41:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:08:04.949994"
    },
    {
      "arxiv_id": "2504.13940v1",
      "title": "Hashigo: A Next Generation Sketch Interactive System for Japanese Kanji",
      "title_zh": "翻译失败",
      "authors": [
        "Paul Taele",
        "Tracy Hammond"
      ],
      "abstract": "Language students can increase their effectiveness in learning written\nJapanese by mastering the visual structure and written technique of Japanese\nkanji. Yet, existing kanji handwriting recognition systems do not assess the\nwritten technique sufficiently enough to discourage students from developing\nbad learning habits. In this paper, we describe our work on Hashigo, a kanji\nsketch interactive system which achieves human instructor-level critique and\nfeedback on both the visual structure and written technique of students'\nsketched kanji. This type of automated critique and feedback allows students to\ntarget and correct specific deficiencies in their sketches that, if left\nuntreated, are detrimental to effective long-term kanji learning.",
      "tldr_zh": "这篇论文介绍了Hashigo，一种下一代日语Kanji草图互动系统，旨在帮助语言学习者掌握Japanese Kanji的视觉结构和书写技巧。Hashigo通过提供类似于人类指导者的自动批评和反馈，针对性地评估并纠正学生草图中的不足，从而避免形成不良学习习惯。实验结果表明，该系统能显著提升长期Kanji学习的效果，填补了现有手写识别系统的局限性。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.13940v1",
      "published_date": "2025-04-15 18:37:28 UTC",
      "updated_date": "2025-04-15 18:37:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:08:17.097419"
    },
    {
      "arxiv_id": "2504.12347v1",
      "title": "Mathematical Capabilities of Large Language Models in Finnish Matriculation Examination",
      "title_zh": "翻译失败",
      "authors": [
        "Mika Setälä",
        "Pieta Sikström",
        "Ville Heilala",
        "Tommi Kärkkäinen"
      ],
      "abstract": "Large language models (LLMs) have shown increasing promise in educational\nsettings, yet their mathematical reasoning has been considered evolving. This\nstudy evaluates the mathematical capabilities of various LLMs using the Finnish\nmatriculation examination, a high-stakes digital test for upper secondary\neducation. Initial tests yielded moderate performance corresponding to\nmid-range grades, but later evaluations demonstrated substantial improvements\nas the language models evolved. Remarkably, some models achieved near-perfect\nor perfect scores, matching top student performance and qualifying for\nuniversity admission. Our findings highlight the rapid advances in the\nmathematical proficiency of LLMs and illustrate their potential to also support\neducational assessments at scale.",
      "tldr_zh": "这项研究评估了各种大型语言模型（LLMs）在芬兰高中毕业考试（Finnish Matriculation Examination）中的数学能力，该考试是高中生的高风险数字测试。初始测试显示LLMs的表现中等，相当于中档分数，但后续评估随着模型演进而显著提升。令人注目的是，一些LLMs实现了近乎完美或完美的成绩，与顶尖学生的表现相当，甚至满足大学录取标准。这些发现突显了LLMs数学推理能力的快速进步，并展示了它们在大规模教育评估中的潜在支持作用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "K.3; I.2"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.12347v1",
      "published_date": "2025-04-15 18:31:54 UTC",
      "updated_date": "2025-04-15 18:31:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:08:27.457714"
    },
    {
      "arxiv_id": "2504.11544v1",
      "title": "NodeRAG: Structuring Graph-based RAG with Heterogeneous Nodes",
      "title_zh": "NodeRAG：通过异构节点结构化基于图的 RAG",
      "authors": [
        "Tianyang Xu",
        "Haojie Zheng",
        "Chengze Li",
        "Haoxiang Chen",
        "Yixin Liu",
        "Ruoxi Chen",
        "Lichao Sun"
      ],
      "abstract": "Retrieval-augmented generation (RAG) empowers large language models to access\nexternal and private corpus, enabling factually consistent responses in\nspecific domains. By exploiting the inherent structure of the corpus,\ngraph-based RAG methods further enrich this process by building a knowledge\ngraph index and leveraging the structural nature of graphs. However, current\ngraph-based RAG approaches seldom prioritize the design of graph structures.\nInadequately designed graph not only impede the seamless integration of diverse\ngraph algorithms but also result in workflow inconsistencies and degraded\nperformance. To further unleash the potential of graph for RAG, we propose\nNodeRAG, a graph-centric framework introducing heterogeneous graph structures\nthat enable the seamless and holistic integration of graph-based methodologies\ninto the RAG workflow. By aligning closely with the capabilities of LLMs, this\nframework ensures a fully cohesive and efficient end-to-end process. Through\nextensive experiments, we demonstrate that NodeRAG exhibits performance\nadvantages over previous methods, including GraphRAG and LightRAG, not only in\nindexing time, query time, and storage efficiency but also in delivering\nsuperior question-answering performance on multi-hop benchmarks and open-ended\nhead-to-head evaluations with minimal retrieval tokens. Our GitHub repository\ncould be seen at https://github.com/Terry-Xu-666/NodeRAG.",
      "tldr_zh": "该研究提出NodeRAG框架，通过引入heterogeneous graph structures来优化基于图的Retrieval-augmented generation (RAG)系统，解决现有方法在图结构设计上的不足，从而实现图算法的无缝整合和RAG工作流的连贯性。NodeRAG紧密结合大型语言模型(LLMs)的能力，确保端到端的效率和一致性。实验结果显示，与GraphRAG和LightRAG相比，NodeRAG在索引时间、查询时间、存储效率以及多跳问答性能上均表现出显著优势，同时在开放式评估中以更少的检索标记实现优异表现。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.11544v1",
      "published_date": "2025-04-15 18:24:00 UTC",
      "updated_date": "2025-04-15 18:24:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:08:40.761187"
    },
    {
      "arxiv_id": "2504.11543v2",
      "title": "REAL: Benchmarking Autonomous Agents on Deterministic Simulations of Real Websites",
      "title_zh": "REAL：在真实网站的确定性模拟上对自主代理进行基准测试",
      "authors": [
        "Divyansh Garg",
        "Shaun VanWeelden",
        "Diego Caples",
        "Andis Draguns",
        "Nikil Ravi",
        "Pranav Putta",
        "Naman Garg",
        "Tomas Abraham",
        "Michael Lara",
        "Federico Lopez",
        "James Liu",
        "Atharva Gundawar",
        "Prannay Hebbar",
        "Youngchul Joo",
        "Jindong Gu",
        "Charles London",
        "Christian Schroeder de Witt",
        "Sumeet Motwani"
      ],
      "abstract": "We introduce REAL, a benchmark and framework for multi-turn agent evaluations\non deterministic simulations of real-world websites. REAL comprises\nhigh-fidelity, deterministic replicas of 11 widely-used websites across domains\nsuch as e-commerce, travel, communication, and professional networking. We also\nrelease a benchmark consisting of 112 practical tasks that mirror everyday\ncomplex user interactions requiring both accurate information retrieval and\nstate-changing actions. All interactions occur within this fully controlled\nsetting, eliminating safety risks and enabling robust, reproducible evaluation\nof agent capability and reliability. Our novel evaluation framework combines\nprogrammatic checks of website state for action-based tasks with rubric-guided\nLLM-based judgments for information retrieval. The framework supports both\nopen-source and proprietary agent systems through a flexible evaluation harness\nthat accommodates black-box commands within browser environments, allowing\nresearch labs to test agentic systems without modification. Our empirical\nresults show that frontier language models achieve at most a 41% success rate\non REAL, highlighting critical gaps in autonomous web navigation and task\ncompletion capabilities. Our framework supports easy integration of new tasks,\nreproducible evaluation, and scalable post-training data generation, marking a\nsignificant step forward in evaluating and advancing agent capabilities.",
      "tldr_zh": "本文提出 REAL 基准和框架，用于在真实网站的可确定性模拟上评估多轮自主代理的性能。REAL 包括 11 个高保真网站模拟（覆盖电商、旅行等领域）和 112 个实际任务，这些任务模拟日常复杂交互，需要准确的信息检索和状态改变动作。评估框架结合程序化检查（针对动作任务）和基于 LLM 的判断，支持开源和专有代理系统，并确保安全、可重复的测试。实证结果显示，前沿语言模型在 REAL 上的成功率最高仅为 41%，突显代理在网络导航和任务完成方面的关键不足，并为未来代理能力提升提供可扩展的评估工具。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "The websites, framework, and leaderboard are available at\n  https://realevals.xyz and https://github.com/agi-inc/REAL",
      "pdf_url": "http://arxiv.org/pdf/2504.11543v2",
      "published_date": "2025-04-15 18:22:55 UTC",
      "updated_date": "2025-04-17 16:28:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:08:54.276762"
    },
    {
      "arxiv_id": "2504.11536v2",
      "title": "ReTool: Reinforcement Learning for Strategic Tool Use in LLMs",
      "title_zh": "ReTool：强化学习用于大语言模型中的战略工具使用",
      "authors": [
        "Jiazhan Feng",
        "Shijue Huang",
        "Xingwei Qu",
        "Ge Zhang",
        "Yujia Qin",
        "Baoquan Zhong",
        "Chengquan Jiang",
        "Jinxin Chi",
        "Wanjun Zhong"
      ],
      "abstract": "While reasoning models (e.g., DeepSeek R1) trained with reinforcement\nlearning (RL), excel in textual reasoning, they struggle in scenarios requiring\nstructured problem-solving, such as geometric reasoning, concise computation,\nor complex equation solving-areas where computational tools like code\ninterpreters (CI) demonstrate distinct advantages. To bridge this gap, we\npropose ReTool, which enhances long-form reasoning with tool-integrated\nlearning, including two key features: (1) dynamic interleaving of real-time\ncode execution within natural language reasoning processes, and (2) an\nautomated RL paradigm that allows policy rollouts with multi-turn real-time\ncode execution and teaches the model in learning when and how to invoke tools\nbased on outcome feedback. ReTool employs a systematic training framework,\nbeginning with synthetic cold-start data generation to produce code-augmented\nlong-form reasoning traces for fine-tuning base models. Subsequent RL training\nleverages task outcomes as rewards to iteratively refine the model's tool use\nstrategy, enabling autonomous discovery of optimal tool invocation patterns\nwithout human priors. Experiments on the challenging MATH Olympiad benchmark\nAIME demonstrate ReTool's superiority: Our 32B model achieves 67% accuracy with\n400 training steps, outperforming text-based RL baseline (40% accuracy, 1080\nsteps) in efficiency and performance. Remarkably, ReTool-32B attains 72.5%\naccuracy in extended settings, surpassing OpenAI's o1-preview by 27.9%. Further\nanalysis reveals emergent behaviors such as code self-correction, signaling an\n''aha moment'' in which the model autonomously masters adaptive tool use. These\nfindings highlight the promise of outcome-driven tool integration for advancing\ncomplex mathematical reasoning and offer new insights into hybrid\nneuro-symbolic systems.",
      "tldr_zh": "本研究提出 ReTool，一种基于 Reinforcement Learning (RL) 的框架，用于提升大型语言模型 (LLMs) 在结构化问题（如几何推理和复杂方程）上的战略工具使用能力，以弥补纯文本推理的不足。ReTool 包括动态交错实时代码执行与自然语言推理过程，以及自动 RL 范式，通过多轮代码执行和基于任务结果的反馈，教导模型自主决定何时及如何调用工具。实验在 MATH Olympiad 基准 AIME 上显示，ReTool 的 32B 模型仅需 400 步训练即达到 67% 准确率，并在扩展设置中达 72.5%，优于文本-based RL 基线和 OpenAI 的 o1-preview；此外，模型展现出紧急行为如代码自修正，突显了混合神经符号系统在复杂数学推理中的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "fix typos",
      "pdf_url": "http://arxiv.org/pdf/2504.11536v2",
      "published_date": "2025-04-15 18:10:22 UTC",
      "updated_date": "2025-04-17 16:46:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:09:07.194241"
    },
    {
      "arxiv_id": "2504.11524v1",
      "title": "HypoBench: Towards Systematic and Principled Benchmarking for Hypothesis Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Haokun Liu",
        "Sicong Huang",
        "Jingyu Hu",
        "Yangqiaoyu Zhou",
        "Chenhao Tan"
      ],
      "abstract": "There is growing interest in hypothesis generation with large language models\n(LLMs). However, fundamental questions remain: what makes a good hypothesis,\nand how can we systematically evaluate methods for hypothesis generation? To\naddress this, we introduce HypoBench, a novel benchmark designed to evaluate\nLLMs and hypothesis generation methods across multiple aspects, including\npractical utility, generalizability, and hypothesis discovery rate. HypoBench\nincludes 7 real-world tasks and 5 synthetic tasks with 194 distinct datasets.\nWe evaluate four state-of-the-art LLMs combined with six existing\nhypothesis-generation methods. Overall, our results suggest that existing\nmethods are capable of discovering valid and novel patterns in the data.\nHowever, the results from synthetic datasets indicate that there is still\nsignificant room for improvement, as current hypothesis generation methods do\nnot fully uncover all relevant or meaningful patterns. Specifically, in\nsynthetic settings, as task difficulty increases, performance significantly\ndrops, with best models and methods only recovering 38.8% of the ground-truth\nhypotheses. These findings highlight challenges in hypothesis generation and\ndemonstrate that HypoBench serves as a valuable resource for improving AI\nsystems designed to assist scientific discovery.",
      "tldr_zh": "本研究引入了HypoBench，一种新型基准，用于系统评估大型语言模型(LLMs)在假设生成(hypothesis generation)方面的性能，涵盖实用性、generalizability和hypothesis discovery rate等多个方面。HypoBench包括7个真实世界任务和5个合成任务，共194个数据集，并评估了四种最先进的LLMs结合六种现有方法。结果显示，现有机方法能发现有效和新颖的模式，但在合成任务中，随着难度增加，性能显著下降，最好模型仅恢复了38.8%的ground-truth假设。这些发现突出了假设生成的挑战，并证明HypoBench是改进AI系统辅助科学发现的重要资源。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "29 pages, 6 figures, website link:\n  https://chicagohai.github.io/HypoBench/",
      "pdf_url": "http://arxiv.org/pdf/2504.11524v1",
      "published_date": "2025-04-15 18:00:00 UTC",
      "updated_date": "2025-04-15 18:00:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:09:18.011048"
    },
    {
      "arxiv_id": "2504.11456v1",
      "title": "DeepMath-103K: A Large-Scale, Challenging, Decontaminated, and Verifiable Mathematical Dataset for Advancing Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Zhiwei He",
        "Tian Liang",
        "Jiahao Xu",
        "Qiuzhi Liu",
        "Xingyu Chen",
        "Yue Wang",
        "Linfeng Song",
        "Dian Yu",
        "Zhenwen Liang",
        "Wenxuan Wang",
        "Zhuosheng Zhang",
        "Rui Wang",
        "Zhaopeng Tu",
        "Haitao Mi",
        "Dong Yu"
      ],
      "abstract": "The capacity for complex mathematical reasoning is a key benchmark for\nartificial intelligence. While reinforcement learning (RL) applied to LLMs\nshows promise, progress is significantly hindered by the lack of large-scale\ntraining data that is sufficiently challenging, possesses verifiable answer\nformats suitable for RL, and is free from contamination with evaluation\nbenchmarks. To address these limitations, we introduce DeepMath-103K, a new,\nlarge-scale dataset comprising approximately 103K mathematical problems,\nspecifically designed to train advanced reasoning models via RL. DeepMath-103K\nis curated through a rigorous pipeline involving source analysis, stringent\ndecontamination against numerous benchmarks, and filtering for high difficulty\n(primarily Levels 5-9), significantly exceeding existing open resources in\nchallenge. Each problem includes a verifiable final answer, enabling rule-based\nRL, and three distinct R1-generated solutions suitable for diverse training\nparadigms like supervised fine-tuning or distillation. Spanning a wide range of\nmathematical topics, DeepMath-103K promotes the development of generalizable\nreasoning. We demonstrate that models trained on DeepMath-103K achieve\nsignificant improvements on challenging mathematical benchmarks, validating its\neffectiveness. We release DeepMath-103K publicly to facilitate community\nprogress in building more capable AI reasoning systems:\nhttps://github.com/zwhe99/DeepMath.",
      "tldr_zh": "本研究引入了 DeepMath-103K，这是一个约 103K 个数学问题的庞大数据集，旨在通过 reinforcement learning (RL) 等方法提升人工智能的复杂数学推理能力。该数据集通过严格的管道构建，包括来源分析、去污染处理和过滤高难度问题（主要 Levels 5-9），确保每个问题具有可验证的最终答案和三种 R1 生成的解决方案，适用于 supervised fine-tuning 或其他训练范式。实验结果显示，在 DeepMath-103K 上训练的模型在各种数学基准测试中取得了显著改进，该数据集已公开发布在 https://github.com/zwhe99/DeepMath，以推动社区开发更强大的 AI 推理系统。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "WIP",
      "pdf_url": "http://arxiv.org/pdf/2504.11456v1",
      "published_date": "2025-04-15 17:59:51 UTC",
      "updated_date": "2025-04-15 17:59:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:09:29.414347"
    },
    {
      "arxiv_id": "2504.11454v2",
      "title": "Elucidating the Design Space of Multimodal Protein Language Models",
      "title_zh": "阐明多模态",
      "authors": [
        "Cheng-Yen Hsieh",
        "Xinyou Wang",
        "Daiheng Zhang",
        "Dongyu Xue",
        "Fei Ye",
        "Shujian Huang",
        "Zaixiang Zheng",
        "Quanquan Gu"
      ],
      "abstract": "Multimodal protein language models (PLMs) integrate sequence and token-based\nstructural information, serving as a powerful foundation for protein modeling,\ngeneration, and design. However, the reliance on tokenizing 3D structures into\ndiscrete tokens causes substantial loss of fidelity about fine-grained\nstructural details and correlations. In this paper, we systematically elucidate\nthe design space of multimodal PLMs to overcome their limitations. We identify\ntokenization loss and inaccurate structure token predictions by the PLMs as\nmajor bottlenecks. To address these, our proposed design space covers improved\ngenerative modeling, structure-aware architectures and representation learning,\nand data exploration. Our advancements approach finer-grained supervision,\ndemonstrating that token-based multimodal PLMs can achieve robust structural\nmodeling. The effective design methods dramatically improve the structure\ngeneration diversity, and notably, folding abilities of our 650M model by\nreducing the RMSD from 5.52 to 2.36 on PDB testset, even outperforming 3B\nbaselines and on par with the specialized folding models.",
      "tldr_zh": "该论文系统阐述了Multimodal Protein Language Models (PLMs)的设计空间，以解决3D结构标记化导致的精细结构细节和相关性丢失问题。作者识别出标记化损失和结构标记预测不准确作为主要瓶颈，并提出改进生成建模、结构感知架构、表示学习和数据探索等方法，实现更精细的监督和稳健的结构建模。实验结果显示，这些设计优化显著提升了结构生成多样性，并将650M模型的RMSD从5.52降低到2.36，在PDB测试集上优于3B基线模型，甚至与专业折叠模型相当。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.QM"
      ],
      "primary_category": "cs.LG",
      "comment": "Project Page: https://bytedance.github.io/dplm/dplm-2.1/",
      "pdf_url": "http://arxiv.org/pdf/2504.11454v2",
      "published_date": "2025-04-15 17:59:43 UTC",
      "updated_date": "2025-04-16 02:35:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:09:41.738758"
    },
    {
      "arxiv_id": "2504.11453v1",
      "title": "A Clean Slate for Offline Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Matthew Thomas Jackson",
        "Uljad Berdica",
        "Jarek Liesen",
        "Shimon Whiteson",
        "Jakob Nicolaus Foerster"
      ],
      "abstract": "Progress in offline reinforcement learning (RL) has been impeded by ambiguous\nproblem definitions and entangled algorithmic designs, resulting in\ninconsistent implementations, insufficient ablations, and unfair evaluations.\nAlthough offline RL explicitly avoids environment interaction, prior methods\nfrequently employ extensive, undocumented online evaluation for hyperparameter\ntuning, complicating method comparisons. Moreover, existing reference\nimplementations differ significantly in boilerplate code, obscuring their core\nalgorithmic contributions. We address these challenges by first introducing a\nrigorous taxonomy and a transparent evaluation protocol that explicitly\nquantifies online tuning budgets. To resolve opaque algorithmic design, we\nprovide clean, minimalistic, single-file implementations of various model-free\nand model-based offline RL methods, significantly enhancing clarity and\nachieving substantial speed-ups. Leveraging these streamlined implementations,\nwe propose Unifloral, a unified algorithm that encapsulates diverse prior\napproaches within a single, comprehensive hyperparameter space, enabling\nalgorithm development in a shared hyperparameter space. Using Unifloral with\nour rigorous evaluation protocol, we develop two novel algorithms - TD3-AWR\n(model-free) and MoBRAC (model-based) - which substantially outperform\nestablished baselines. Our implementation is publicly available at\nhttps://github.com/EmptyJackson/unifloral.",
      "tldr_zh": "这篇论文针对离线强化学习（offline RL）的进展问题，提出了一个全新的框架，以解决算法设计模糊和评估不透明的问题。作者引入了严格的分类法和透明评估协议，能够量化在线调整预算，并提供了干净、最小化的单文件实现，提升了算法清晰度和执行效率。基于此，他们开发了 Unifloral 算法，将多种现有方法统一到一个综合超参数空间中，并据此创建了两个新算法：TD3-AWR（模型无关）和 MoBRAC（模型相关），在性能上大幅超越基线。代码已开源，方便进一步研究和应用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.11453v1",
      "published_date": "2025-04-15 17:59:05 UTC",
      "updated_date": "2025-04-15 17:59:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:09:52.304788"
    },
    {
      "arxiv_id": "2504.11442v1",
      "title": "TextArena",
      "title_zh": "翻译失败",
      "authors": [
        "Leon Guertler",
        "Bobby Cheng",
        "Simon Yu",
        "Bo Liu",
        "Leshem Choshen",
        "Cheston Tan"
      ],
      "abstract": "TextArena is an open-source collection of competitive text-based games for\ntraining and evaluation of agentic behavior in Large Language Models (LLMs). It\nspans 57+ unique environments (including single-player, two-player, and\nmulti-player setups) and allows for easy evaluation of model capabilities via\nan online-play system (against humans and other submitted models) with\nreal-time TrueSkill scores. Traditional benchmarks rarely assess dynamic social\nskills such as negotiation, theory of mind, and deception, creating a gap that\nTextArena addresses. Designed with research, community and extensibility in\nmind, TextArena emphasizes ease of adding new games, adapting the framework,\ntesting models, playing against the models, and training models. Detailed\ndocumentation of environments, games, leaderboard, and examples are available\non https://github.com/LeonGuertler/TextArena and https://www.textarena.ai/.",
      "tldr_zh": "TextArena 是一个开源平台，收集了57+个独特文本游戏环境（包括单人、两人和多人设置），用于训练和评估大型语言模型(LLMs)的代理行为，特别是动态社交技能如谈判、理论思维和欺骗，这些是传统基准常忽略的领域。\n该平台通过在线游戏系统允许模型与人类或其他提交模型实时竞争，并使用TrueSkill分数进行评估，提供了一个易于扩展的框架。\nTextArena 强调研究和社区友好性，便于添加新游戏、适应框架、测试和训练模型。\n详细文档、游戏示例和排行榜可通过GitHub和官方网站访问。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.CL",
      "comment": "work in progress; 5 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.11442v1",
      "published_date": "2025-04-15 17:55:20 UTC",
      "updated_date": "2025-04-15 17:55:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:10:05.527687"
    },
    {
      "arxiv_id": "2504.11440v1",
      "title": "Greedy Restart Schedules: A Baseline for Dynamic Algorithm Selection on Numerical Black-box Optimization Problems",
      "title_zh": "翻译失败",
      "authors": [
        "Lennart Schäpermeier"
      ],
      "abstract": "In many optimization domains, there are multiple different solvers that\ncontribute to the overall state-of-the-art, each performing better on some, and\nworse on other types of problem instances. Meta-algorithmic approaches, such as\ninstance-based algorithm selection, configuration and scheduling, aim to close\nthis gap by extracting the most performance possible from a set of\n(configurable) optimizers. In this context, the best performing individual\nalgorithms are often hand-crafted hybrid heuristics which perform many restarts\nof fast local optimization approaches. However, data-driven techniques to\ncreate optimized restart schedules have not yet been extensively studied.\n  Here, we present a simple scheduling approach that iteratively selects the\nalgorithm performing best on the distribution of unsolved training problems at\ntime of selection, resulting in a problem-independent solver schedule. We\ndemonstrate our approach using well-known optimizers from numerical black-box\noptimization on the BBOB testbed, bridging much of the gap between single and\nvirtual best solver from the original portfolio across various evaluation\nprotocols. Our greedy restart schedule presents a powerful baseline for more\ncomplex dynamic algorithm selection models.",
      "tldr_zh": "本文提出 Greedy Restart Schedules 作为数值黑箱优化问题（Numerical Black-box Optimization Problems）动态算法选择（Dynamic Algorithm Selection）的基线方法。该方法通过迭代选择在当前未解决训练问题分布上表现最好的算法，生成一个问题独立的求解器调度，从而优化多种优化器的性能。在 BBOB 测试床上实验显示，该调度显著缩小了单个优化器和虚拟最佳求解器之间的差距，在各种评估协议中表现出色。该方法为更复杂的动态算法选择模型提供了强大基线。",
      "categories": [
        "math.OC",
        "cs.AI"
      ],
      "primary_category": "math.OC",
      "comment": "Author version. Accepted as full paper to be presented at the GECCO\n  2025 conference, July 14-18, M\\'alaga, Spain. (DOI 10.1145/3712256.3726408)",
      "pdf_url": "http://arxiv.org/pdf/2504.11440v1",
      "published_date": "2025-04-15 17:54:21 UTC",
      "updated_date": "2025-04-15 17:54:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:10:17.576020"
    },
    {
      "arxiv_id": "2504.11431v1",
      "title": "Masculine Defaults via Gendered Discourse in Podcasts and Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Maria Teleki",
        "Xiangjue Dong",
        "Haoran Liu",
        "James Caverlee"
      ],
      "abstract": "Masculine defaults are widely recognized as a significant type of gender\nbias, but they are often unseen as they are under-researched. Masculine\ndefaults involve three key parts: (i) the cultural context, (ii) the masculine\ncharacteristics or behaviors, and (iii) the reward for, or simply acceptance\nof, those masculine characteristics or behaviors. In this work, we study\ndiscourse-based masculine defaults, and propose a twofold framework for (i) the\nlarge-scale discovery and analysis of gendered discourse words in spoken\ncontent via our Gendered Discourse Correlation Framework (GDCF); and (ii) the\nmeasurement of the gender bias associated with these gendered discourse words\nin LLMs via our Discourse Word-Embedding Association Test (D-WEAT). We focus\nour study on podcasts, a popular and growing form of social media, analyzing\n15,117 podcast episodes. We analyze correlations between gender and discourse\nwords -- discovered via LDA and BERTopic -- to automatically form gendered\ndiscourse word lists. We then study the prevalence of these gendered discourse\nwords in domain-specific contexts, and find that gendered discourse-based\nmasculine defaults exist in the domains of business, technology/politics, and\nvideo games. Next, we study the representation of these gendered discourse\nwords from a state-of-the-art LLM embedding model from OpenAI, and find that\nthe masculine discourse words have a more stable and robust representation than\nthe feminine discourse words, which may result in better system performance on\ndownstream tasks for men. Hence, men are rewarded for their discourse patterns\nwith better system performance by one of the state-of-the-art language models\n-- and this embedding disparity is a representational harm and a masculine\ndefault.",
      "tldr_zh": "本研究探讨了“masculine defaults”作为一种常见的性别偏见，焦点在于基于话语的男性默认现象，包括文化背景、男性特征及其奖励。研究者提出了双重框架：Gendered Discourse Correlation Framework (GDCF) 用于大规模分析15,117个播客剧集中的性别化话语词汇（通过LDA和BERTopic），以及Discourse Word-Embedding Association Test (D-WEAT) 用于评估这些词汇在LLMs中的性别偏见。结果显示，在商业、技术/政治和视频游戏等领域存在性别化男性默认，且OpenAI的LLMs中男性话语词汇表示更稳定，导致男性在下游任务中获得更好性能，这构成了一种代表性伤害。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.LG",
        "cs.SI"
      ],
      "primary_category": "cs.CL",
      "comment": "To appear in ICWSM 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.11431v1",
      "published_date": "2025-04-15 17:41:54 UTC",
      "updated_date": "2025-04-15 17:41:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:10:29.393951"
    },
    {
      "arxiv_id": "2504.11426v1",
      "title": "A Dual-Space Framework for General Knowledge Distillation of Large Language Models",
      "title_zh": "一种双空间框架，用于大型语言模型的一般知识蒸馏",
      "authors": [
        "Xue Zhang",
        "Songming Zhang",
        "Yunlong Liang",
        "Fandong Meng",
        "Yufeng Chen",
        "Jinan Xu",
        "Jie Zhou"
      ],
      "abstract": "Knowledge distillation (KD) is a promising solution to compress large\nlanguage models (LLMs) by transferring their knowledge to smaller models.\nDuring this process, white-box KD methods usually minimize the distance between\nthe output distributions of the teacher model and the student model to transfer\nmore information. However, we reveal that the current white-box KD framework\nexhibits two limitations: a) bridging probability distributions from different\noutput spaces will limit the similarity between the teacher model and the\nstudent model; b) this framework cannot be applied to LLMs with different\nvocabularies. One of the root causes for these limitations is that the\ndistributions from the teacher and the student for KD are output by different\nprediction heads, which yield distributions in different output spaces and\ndimensions. Therefore, in this paper, we propose a dual-space knowledge\ndistillation (DSKD) framework that unifies the prediction heads of the teacher\nand the student models for KD. Specifically, we first introduce two projectors\nwith ideal initialization to project the teacher/student hidden states into the\nstudent/teacher representation spaces. After this, the hidden states from\ndifferent models can share the same head and unify the output spaces of the\ndistributions. Furthermore, we develop an exact token alignment (ETA) algorithm\nto align the same tokens in two differently-tokenized sequences. Based on the\nabove, our DSKD framework is a general KD framework that supports both\noff-policy and on-policy KD, and KD between any two LLMs regardless of their\nvocabularies. Extensive experiments on instruction-following, mathematical\nreasoning, and code generation benchmarks show that DSKD significantly\noutperforms existing methods based on the current white-box KD framework and\nsurpasses other cross-tokenizer KD methods for LLMs with different\nvocabularies.",
      "tldr_zh": "本文提出了一种双空间知识蒸馏（DSKD）框架，用于解决现有白盒知识蒸馏（KD）方法的局限性，包括输出空间差异导致的模型相似性问题以及无法处理不同词汇表的大型语言模型（LLMs）。DSKD框架通过引入两个投影器将教师和学生模型的隐藏状态投影到统一的空间，并开发精确标记对齐（ETA）算法来对齐不同词汇表的标记，从而支持离策略和在线策略KD。实验在指令遵循、数学推理和代码生成基准上表明，DSKD显著优于现有方法，并在不同词汇表场景中表现出色。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "19 pages, 9 figures, 11 tables, under review. Code is available at:\n  https://github.com/songmzhang/DSKDv2. arXiv admin note: text overlap with\n  arXiv:2406.17328",
      "pdf_url": "http://arxiv.org/pdf/2504.11426v1",
      "published_date": "2025-04-15 17:38:47 UTC",
      "updated_date": "2025-04-15 17:38:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:10:41.656235"
    },
    {
      "arxiv_id": "2504.11423v1",
      "title": "ADT: Tuning Diffusion Models with Adversarial Supervision",
      "title_zh": "ADT：通过对抗监督微调扩散模型",
      "authors": [
        "Dazhong Shen",
        "Guanglu Song",
        "Yi Zhang",
        "Bingqi Ma",
        "Lujundong Li",
        "Dongzhi Jiang",
        "Zhuofan Zong",
        "Yu Liu"
      ],
      "abstract": "Diffusion models have achieved outstanding image generation by reversing a\nforward noising process to approximate true data distributions. During\ntraining, these models predict diffusion scores from noised versions of true\nsamples in a single forward pass, while inference requires iterative denoising\nstarting from white noise. This training-inference divergences hinder the\nalignment between inference and training data distributions, due to potential\nprediction biases and cumulative error accumulation. To address this problem,\nwe propose an intuitive but effective fine-tuning framework, called Adversarial\nDiffusion Tuning (ADT), by stimulating the inference process during\noptimization and aligning the final outputs with training data by adversarial\nsupervision. Specifically, to achieve robust adversarial training, ADT features\na siamese-network discriminator with a fixed pre-trained backbone and\nlightweight trainable parameters, incorporates an image-to-image sampling\nstrategy to smooth discriminative difficulties, and preserves the original\ndiffusion loss to prevent discriminator hacking. In addition, we carefully\nconstrain the backward-flowing path for back-propagating gradients along the\ninference path without incurring memory overload or gradient explosion.\nFinally, extensive experiments on Stable Diffusion models (v1.5, XL, and v3),\ndemonstrate that ADT significantly improves both distribution alignment and\nimage quality.",
      "tldr_zh": "本研究针对扩散模型（Diffusion models）在训练和推理过程中的不一致问题（如预测偏差和累积错误），提出了一种直观有效的微调框架——Adversarial Diffusion Tuning (ADT)。ADT 通过在优化中模拟推理过程，并采用对抗监督（如 Siamese-network 鉴别器、image-to-image sampling 策略和原始扩散损失的保留）来对齐最终输出与训练数据分布，同时约束梯度回传路径以避免内存过载或梯度爆炸。实验结果显示，在 Stable Diffusion 模型（v1.5、XL 和 v3）上，ADT 显著提升了分布对齐和图像质量。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.11423v1",
      "published_date": "2025-04-15 17:37:50 UTC",
      "updated_date": "2025-04-15 17:37:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:10:53.495370"
    },
    {
      "arxiv_id": "2504.11419v2",
      "title": "Embodied World Models Emerge from Navigational Task in Open-Ended Environments",
      "title_zh": "具身世界模型从导航任务在开放式环境中涌现",
      "authors": [
        "Li Jin",
        "Liu Jia"
      ],
      "abstract": "Spatial reasoning in partially observable environments has often been\napproached through passive predictive models, yet theories of embodied\ncognition suggest that genuinely useful representations arise only when\nperception is tightly coupled to action. Here we ask whether a recurrent agent,\ntrained solely by sparse rewards to solve procedurally generated planar mazes,\ncan autonomously internalize metric concepts such as direction, distance and\nobstacle layout. After training, the agent consistently produces near-optimal\npaths in unseen mazes, behavior that hints at an underlying spatial model. To\nprobe this possibility, we cast the closed agent-environment loop as a hybrid\ndynamical system, identify stable limit cycles in its state space, and\ncharacterize behavior with a Ridge Representation that embeds whole\ntrajectories into a common metric space. Canonical correlation analysis exposes\na robust linear alignment between neural and behavioral manifolds, while\ntargeted perturbations of the most informative neural dimensions sharply\ndegrade navigation performance. Taken together, these dynamical,\nrepresentational, and causal signatures show that sustained sensorimotor\ninteraction is sufficient for the spontaneous emergence of compact, embodied\nworld models, providing a principled path toward interpretable and transferable\nnavigation policies.",
      "tldr_zh": "该研究探讨了在开放环境中，通过将感知与行动紧密结合，代理是否能自发发展出体现化的世界模型（Embodied World Models）。研究训练了一个循环代理（Recurrent Agent），仅通过稀疏奖励（Sparse Rewards）在程序生成的平面迷宫中导航，训练后代理在未见迷宫中产生近似最优路径。利用混合动力系统、Ridge Representation 和规范相关分析（Canonical Correlation Analysis），分析显示神经和行为流形之间存在稳健线性对齐，且针对关键神经维度的扰动会显著降低导航性能。这些发现证明，持续的传感器运动交互足以使紧凑、体现化的世界模型自发出现，为可解释和可转移的导航策略提供可靠路径。",
      "categories": [
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.AI",
      "comment": "Research on explainable meta-reinforcement learning AI",
      "pdf_url": "http://arxiv.org/pdf/2504.11419v2",
      "published_date": "2025-04-15 17:35:13 UTC",
      "updated_date": "2025-04-27 08:46:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:11:05.152292"
    },
    {
      "arxiv_id": "2504.11412v1",
      "title": "Measures of Variability for Risk-averse Policy Gradient",
      "title_zh": "风险厌恶策略梯度的变异度量措施",
      "authors": [
        "Yudong Luo",
        "Yangchen Pan",
        "Jiaqi Tan",
        "Pascal Poupart"
      ],
      "abstract": "Risk-averse reinforcement learning (RARL) is critical for decision-making\nunder uncertainty, which is especially valuable in high-stake applications.\nHowever, most existing works focus on risk measures, e.g., conditional\nvalue-at-risk (CVaR), while measures of variability remain underexplored. In\nthis paper, we comprehensively study nine common measures of variability,\nnamely Variance, Gini Deviation, Mean Deviation, Mean-Median Deviation,\nStandard Deviation, Inter-Quantile Range, CVaR Deviation, Semi_Variance, and\nSemi_Standard Deviation. Among them, four metrics have not been previously\nstudied in RARL. We derive policy gradient formulas for these unstudied\nmetrics, improve gradient estimation for Gini Deviation, analyze their gradient\nproperties, and incorporate them with the REINFORCE and PPO frameworks to\npenalize the dispersion of returns.\n  Our empirical study reveals that variance-based metrics lead to unstable\npolicy updates. In contrast, CVaR Deviation and Gini Deviation show consistent\nperformance across different randomness and evaluation domains, achieving high\nreturns while effectively learning risk-averse policies. Mean Deviation and\nSemi_Standard Deviation are also competitive across different scenarios. This\nwork provides a comprehensive overview of variability measures in RARL,\noffering practical insights for risk-aware decision-making and guiding future\nresearch on risk metrics and RARL algorithms.",
      "tldr_zh": "本研究探讨了风险厌恶强化学习（RARL）中变异性度量的应用，针对不确定性决策场景，系统研究了九种常见度量，包括Variance、Gini Deviation、Mean Deviation、Mean-Median Deviation、Standard Deviation、Inter-Quantile Range、CVaR Deviation、Semi_Variance和Semi_Standard Deviation，其中四种之前未在RARL中被研究。论文贡献包括为这些未研究的度量推导策略梯度公式、改进Gini Deviation的梯度估计，并将这些度量整合到REINFORCE和PPO框架中，以惩罚回报的离散性。实证结果显示，Variance-based度量导致策略更新不稳定，而CVaR Deviation和Gini Deviation在不同随机性和评估场景中表现出色，实现高回报并有效学习风险厌恶策略；同时，Mean Deviation和Semi_Standard Deviation在多种情境下也具有竞争力。该工作为RARL中的风险感知决策提供了全面见解，并为未来研究提供指导。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.11412v1",
      "published_date": "2025-04-15 17:28:15 UTC",
      "updated_date": "2025-04-15 17:28:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:11:19.957547"
    },
    {
      "arxiv_id": "2504.11406v1",
      "title": "Multi-level Cellular Automata for FLIM networks",
      "title_zh": "翻译失败",
      "authors": [
        "Felipe Crispim Salvagnini",
        "Jancarlo F. Gomes",
        "Cid A. N. Santos",
        "Silvio Jamil F. Guimarães",
        "Alexandre X. Falcão"
      ],
      "abstract": "The necessity of abundant annotated data and complex network architectures\npresents a significant challenge in deep-learning Salient Object Detection\n(deep SOD) and across the broader deep-learning landscape. This challenge is\nparticularly acute in medical applications in developing countries with limited\ncomputational resources. Combining modern and classical techniques offers a\npath to maintaining competitive performance while enabling practical\napplications. Feature Learning from Image Markers (FLIM) methodology empowers\nexperts to design convolutional encoders through user-drawn markers, with\nfilters learned directly from these annotations. Recent findings demonstrate\nthat coupling a FLIM encoder with an adaptive decoder creates a flyweight\nnetwork suitable for SOD, requiring significantly fewer parameters than\nlightweight models and eliminating the need for backpropagation. Cellular\nAutomata (CA) methods have proven successful in data-scarce scenarios but\nrequire proper initialization -- typically through user input, priors, or\nrandomness. We propose a practical intersection of these approaches: using FLIM\nnetworks to initialize CA states with expert knowledge without requiring user\ninteraction for each image. By decoding features from each level of a FLIM\nnetwork, we can initialize multiple CAs simultaneously, creating a multi-level\nframework. Our method leverages the hierarchical knowledge encoded across\ndifferent network layers, merging multiple saliency maps into a high-quality\nfinal output that functions as a CA ensemble. Benchmarks across two challenging\nmedical datasets demonstrate the competitiveness of our multi-level CA approach\ncompared to established models in the deep SOD literature.",
      "tldr_zh": "本研究针对深度学习Salient Object Detection (deep SOD) 的数据标注需求和复杂网络挑战，特别是资源有限的医疗应用，提出了一种多级Cellular Automata (CA) 框架。该框架利用Feature Learning from Image Markers (FLIM) 网络通过专家绘制的标记学习卷积编码器，并将其用于初始化多个CA状态，从而创建层次化多级系统，避免了每次图像的交互需求。方法通过从FLIM网络的不同层解码特征，合并多个显著性地图生成高质量输出，作为CA集成，显著减少了网络参数并省去了反向传播过程。在两个挑战性医疗数据集上的基准测试中，该方法与现有deep SOD模型相比表现出竞争性性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.11406v1",
      "published_date": "2025-04-15 17:22:24 UTC",
      "updated_date": "2025-04-15 17:22:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:11:29.579310"
    },
    {
      "arxiv_id": "2504.11389v2",
      "title": "VideoPanda: Video Panoramic Diffusion with Multi-view Attention",
      "title_zh": "VideoPanda：利用多视图注意力的视频全景扩散",
      "authors": [
        "Kevin Xie",
        "Amirmojtaba Sabour",
        "Jiahui Huang",
        "Despoina Paschalidou",
        "Greg Klar",
        "Umar Iqbal",
        "Sanja Fidler",
        "Xiaohui Zeng"
      ],
      "abstract": "High resolution panoramic video content is paramount for immersive\nexperiences in Virtual Reality, but is non-trivial to collect as it requires\nspecialized equipment and intricate camera setups. In this work, we introduce\nVideoPanda, a novel approach for synthesizing 360$^\\circ$ videos conditioned on\ntext or single-view video data. VideoPanda leverages multi-view attention\nlayers to augment a video diffusion model, enabling it to generate consistent\nmulti-view videos that can be combined into immersive panoramic content.\nVideoPanda is trained jointly using two conditions: text-only and single-view\nvideo, and supports autoregressive generation of long-videos. To overcome the\ncomputational burden of multi-view video generation, we randomly subsample the\nduration and camera views used during training and show that the model is able\nto gracefully generalize to generating more frames during inference. Extensive\nevaluations on both real-world and synthetic video datasets demonstrate that\nVideoPanda generates more realistic and coherent 360$^\\circ$ panoramas across\nall input conditions compared to existing methods. Visit the project website at\nhttps://research.nvidia.com/labs/toronto-ai/VideoPanda/ for results.",
      "tldr_zh": "该研究引入 VideoPanda，一种基于多视图注意力（multi-view attention）的视频扩散模型，用于从文本或单视图视频合成 360° 视频，从而解决高分辨率全景视频采集的难题。VideoPanda 通过增强视频扩散模型并联合训练文本和单视图条件，支持自回归生成长视频，并在训练中采用随机采样策略来降低计算负担。实验评估显示，该方法在真实和合成数据集上生成更真实、更连贯的 360° 全景内容，优于现有技术。",
      "categories": [
        "cs.GR",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.GR",
      "comment": "Project website at\n  https://research.nvidia.com/labs/toronto-ai/VideoPanda/",
      "pdf_url": "http://arxiv.org/pdf/2504.11389v2",
      "published_date": "2025-04-15 16:58:15 UTC",
      "updated_date": "2025-04-17 22:59:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:11:41.286419"
    },
    {
      "arxiv_id": "2504.11386v1",
      "title": "Trajectory Encoding Temporal Graph Networks",
      "title_zh": "轨迹编码时序图网络",
      "authors": [
        "Jiafeng Xiong",
        "Rizos Sakellariou"
      ],
      "abstract": "Temporal Graph Networks (TGNs) have demonstrated significant success in\ndynamic graph tasks such as link prediction and node classification. Both tasks\ncomprise transductive settings, where the model predicts links among known\nnodes, and in inductive settings, where it generalises learned patterns to\npreviously unseen nodes. Existing TGN designs face a dilemma under these dual\nscenarios. Anonymous TGNs, which rely solely on temporal and structural\ninformation, offer strong inductive generalisation but struggle to distinguish\nknown nodes. In contrast, non-anonymous TGNs leverage node features to excel in\ntransductive tasks yet fail to adapt to new nodes. To address this challenge,\nwe propose Trajectory Encoding TGN (TETGN). Our approach introduces\nautomatically expandable node identifiers (IDs) as learnable temporal\npositional features and performs message passing over these IDs to capture each\nnode's historical context. By integrating this trajectory-aware module with a\nstandard TGN using multi-head attention, TETGN effectively balances\ntransductive accuracy with inductive generalisation. Experimental results on\nthree real-world datasets show that TETGN significantly outperforms strong\nbaselines on both link prediction and node classification tasks, demonstrating\nits ability to unify the advantages of anonymous and non-anonymous models for\ndynamic graph learning.",
      "tldr_zh": "该论文针对 Temporal Graph Networks (TGNs) 在动态图任务（如 link prediction 和 node classification）中的困境，指出匿名 TGNs 虽强于 inductive 泛化但难以区分已知节点，而非匿名 TGNs 则在 transductive 任务中出色但不适应新节点。作者提出 Trajectory Encoding TGN (TETGN)，通过引入自动可扩展的节点标识符作为 learnable temporal positional features，并结合 message passing 和 multi-head attention 与标准 TGN 整合，以捕获节点的 historical context，从而平衡 transductive 准确性和 inductive 泛化能力。在三个真实数据集上的实验结果表明，TETGN 在 link prediction 和 node classification 任务中显著优于基线模型，统一了匿名和非匿名模型的优势。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.11386v1",
      "published_date": "2025-04-15 16:57:09 UTC",
      "updated_date": "2025-04-15 16:57:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:11:55.148166"
    },
    {
      "arxiv_id": "2504.11374v1",
      "title": "A Winner-Takes-All Mechanism for Event Generation",
      "title_zh": "事件生成的",
      "authors": [
        "Yongkang Huo",
        "Fuvio Forni",
        "Rodolphe Sepulchre"
      ],
      "abstract": "We present a novel framework for central pattern generator design that\nleverages the intrinsic rebound excitability of neurons in combination with\nwinner-takes-all computation. Our approach unifies decision-making and rhythmic\npattern generation within a simple yet powerful network architecture that\nemploys all-to-all inhibitory connections enhanced by designable excitatory\ninteractions. This design offers significant advantages regarding ease of\nimplementation, adaptability, and robustness. We demonstrate its efficacy\nthrough a ring oscillator model, which exhibits adaptive phase and frequency\nmodulation, making the framework particularly promising for applications in\nneuromorphic systems and robotics.",
      "tldr_zh": "本研究提出一个新框架，用于中心模式生成器设计，该框架结合神经元的内在反弹兴奋性（intrinsic rebound excitability）和 winner-takes-all 计算，实现决策与节律模式生成的统一。框架采用全对全抑制连接（all-to-all inhibitory connections）并增强可设计的兴奋性交互，形成一个简单而强大的网络架构，具有易于实现、可适应性和鲁棒性的优势。通过环形振荡器模型（ring oscillator model）的实验验证，该框架展示了自适应相位和频率调制的能力，适用于神经形态系统和机器人领域。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.11374v1",
      "published_date": "2025-04-15 16:40:37 UTC",
      "updated_date": "2025-04-15 16:40:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:12:05.291383"
    },
    {
      "arxiv_id": "2504.11369v1",
      "title": "OpenTuringBench: An Open-Model-based Benchmark and Framework for Machine-Generated Text Detection and Attribution",
      "title_zh": "翻译失败",
      "authors": [
        "Lucio La Cava",
        "Andrea Tagarelli"
      ],
      "abstract": "Open Large Language Models (OLLMs) are increasingly leveraged in generative\nAI applications, posing new challenges for detecting their outputs. We propose\nOpenTuringBench, a new benchmark based on OLLMs, designed to train and evaluate\nmachine-generated text detectors on the Turing Test and Authorship Attribution\nproblems. OpenTuringBench focuses on a representative set of OLLMs, and\nfeatures a number of challenging evaluation tasks, including\nhuman/machine-manipulated texts, out-of-domain texts, and texts from previously\nunseen models. We also provide OTBDetector, a contrastive learning framework to\ndetect and attribute OLLM-based machine-generated texts. Results highlight the\nrelevance and varying degrees of difficulty of the OpenTuringBench tasks, with\nour detector achieving remarkable capabilities across the various tasks and\noutperforming most existing detectors. Resources are available on the\nOpenTuringBench Hugging Face repository at\nhttps://huggingface.co/datasets/MLNTeam-Unical/OpenTuringBench",
      "tldr_zh": "该论文提出 OpenTuringBench，这是一个基于 Open Large Language Models (OLLMs) 的开源基准和框架，用于训练和评估机器生成文本的检测（Turing Test）和归因（Authorship Attribution）。该基准涵盖多种挑战性任务，包括人类/机器操作文本、域外文本以及来自未见过模型的文本，以测试检测器的鲁棒性。作者还开发了 OTBDetector，一个基于 contrastive learning 的框架，能够在这些任务中显著优于现有检测器，并在实验中展现出卓越性能。资源已在 Hugging Face 仓库中公开。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.HC",
        "physics.soc-ph"
      ],
      "primary_category": "cs.CL",
      "comment": "Under review with ARR",
      "pdf_url": "http://arxiv.org/pdf/2504.11369v1",
      "published_date": "2025-04-15 16:36:14 UTC",
      "updated_date": "2025-04-15 16:36:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:12:17.755168"
    },
    {
      "arxiv_id": "2504.11364v2",
      "title": "Teaching Large Language Models to Reason through Learning and Forgetting",
      "title_zh": "教导大型语言模型通过学习与遗忘进行推理",
      "authors": [
        "Tianwei Ni",
        "Allen Nie",
        "Sapana Chaudhary",
        "Yao Liu",
        "Huzefa Rangwala",
        "Rasool Fakoor"
      ],
      "abstract": "Leveraging inference-time search in large language models has proven\neffective in further enhancing a trained model's capability to solve complex\nmathematical and reasoning problems. However, this approach significantly\nincreases computational costs and inference time, as the model must generate\nand evaluate multiple candidate solutions to identify a viable reasoning path.\nTo address this, we propose an effective approach that integrates search\ncapabilities directly into the model by fine-tuning it using both successful\n(learning) and failed reasoning paths (forgetting) derived from diverse search\nmethods. While fine-tuning the model with these data might seem\nstraightforward, we identify a critical issue: the model's search capability\ntends to degrade rapidly if fine-tuning is performed naively. We show that this\ndegradation can be substantially mitigated by employing a smaller learning\nrate. Extensive experiments on the challenging Game-of-24 and Countdown\nmathematical reasoning benchmarks show that our approach not only outperforms\nboth standard fine-tuning and inference-time search baselines but also\nsignificantly reduces inference time by 180$\\times$.",
      "tldr_zh": "这篇论文提出了一种新方法，通过使用成功推理路径（learning）和失败推理路径（forgetting）来微调 Large Language Models，从而将推理时的搜索能力直接整合到模型中，以解决复杂数学和推理问题的计算开销问题。作者发现，传统 fine-tuning 可能导致模型搜索能力快速退化，因此采用较小的 learning rate 来显著缓解这一问题。在 Game-of-24 和 Countdown 等基准测试中，该方法不仅超过了标准 fine-tuning 和 inference-time search 基线，还将推理时间减少了 180 倍。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Code: https://github.com/twni2016/llm-reasoning-uft",
      "pdf_url": "http://arxiv.org/pdf/2504.11364v2",
      "published_date": "2025-04-15 16:30:02 UTC",
      "updated_date": "2025-04-23 21:27:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:12:29.485025"
    },
    {
      "arxiv_id": "2504.11358v2",
      "title": "DataSentinel: A Game-Theoretic Detection of Prompt Injection Attacks",
      "title_zh": "DataSentinel：一种基于博弈论的提示注入攻击检测",
      "authors": [
        "Yupei Liu",
        "Yuqi Jia",
        "Jinyuan Jia",
        "Dawn Song",
        "Neil Zhenqiang Gong"
      ],
      "abstract": "LLM-integrated applications and agents are vulnerable to prompt injection\nattacks, where an attacker injects prompts into their inputs to induce\nattacker-desired outputs. A detection method aims to determine whether a given\ninput is contaminated by an injected prompt. However, existing detection\nmethods have limited effectiveness against state-of-the-art attacks, let alone\nadaptive ones. In this work, we propose DataSentinel, a game-theoretic method\nto detect prompt injection attacks. Specifically, DataSentinel fine-tunes an\nLLM to detect inputs contaminated with injected prompts that are strategically\nadapted to evade detection. We formulate this as a minimax optimization\nproblem, with the objective of fine-tuning the LLM to detect strong adaptive\nattacks. Furthermore, we propose a gradient-based method to solve the minimax\noptimization problem by alternating between the inner max and outer min\nproblems. Our evaluation results on multiple benchmark datasets and LLMs show\nthat DataSentinel effectively detects both existing and adaptive prompt\ninjection attacks.",
      "tldr_zh": "这篇论文提出了 DataSentinel，一种基于博弈论（game-theoretic）的检测方法，用于识别大型语言模型（LLM）应用中的提示注入攻击（prompt injection attacks）。方法通过微调 LLM，将检测问题形式化为 minimax 优化问题，并采用梯度-based 技术交替解决内部最大化和外部最小化，以对抗策略性自适应攻击。实验结果显示，DataSentinel 在多个基准数据集和 LLM 上，显著提高了对现有和自适应攻击的检测有效性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "Distinguished Paper Award in IEEE Symposium on Security and Privacy,\n  2025",
      "pdf_url": "http://arxiv.org/pdf/2504.11358v2",
      "published_date": "2025-04-15 16:26:21 UTC",
      "updated_date": "2025-05-15 20:05:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:12:41.228983"
    },
    {
      "arxiv_id": "2504.11355v1",
      "title": "Neural Networks for on-chip Model Predictive Control: a Method to Build Optimized Training Datasets and its application to Type-1 Diabetes",
      "title_zh": "翻译失败",
      "authors": [
        "Alberto Castillo",
        "Elliot Pryor",
        "Anas El Fathi",
        "Boris Kovatchev",
        "Marc Breton"
      ],
      "abstract": "Training Neural Networks (NNs) to behave as Model Predictive Control (MPC)\nalgorithms is an effective way to implement them in constrained embedded\ndevices. By collecting large amounts of input-output data, where inputs\nrepresent system states and outputs are MPC-generated control actions, NNs can\nbe trained to replicate MPC behavior at a fraction of the computational cost.\nHowever, although the composition of the training data critically influences\nthe final NN accuracy, methods for systematically optimizing it remain\nunderexplored. In this paper, we introduce the concept of Optimally-Sampled\nDatasets (OSDs) as ideal training sets and present an efficient algorithm for\ngenerating them. An OSD is a parametrized subset of all the available data that\n(i) preserves existing MPC information up to a certain numerical resolution,\n(ii) avoids duplicate or near-duplicate states, and (iii) becomes saturated or\ncomplete. We demonstrate the effectiveness of OSDs by training NNs to replicate\nthe University of Virginia's MPC algorithm for automated insulin delivery in\nType-1 Diabetes, achieving a four-fold improvement in final accuracy. Notably,\ntwo OSD-trained NNs received regulatory clearance for clinical testing as the\nfirst NN-based control algorithm for direct human insulin dosing. This\nmethodology opens new pathways for implementing advanced optimizations on\nresource-constrained embedded platforms, potentially revolutionizing how\ncomplex algorithms are deployed.",
      "tldr_zh": "本文提出了一种优化训练数据集的方法，用于训练 Neural Networks (NNs) 以模仿 Model Predictive Control (MPC) 算法，从而在资源受限的嵌入式设备上实现高效控制。该方法引入了 Optimally-Sampled Datasets (OSDs) 概念，通过一个高效算法生成参数化的数据子集，确保保留 MPC 信息到特定数值分辨率、避免重复状态并达到数据饱和，从而显著提高 NNs 的准确性。在 Type-1 Diabetes 的应用中，OSDs 训练的 NNs 用于复制 University of Virginia 的自动胰岛素递送算法，准确性提高了四倍，并有两款 NNs 获得监管批准用于临床测试。这为在约束平台上部署复杂优化算法开辟了新途径。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.11355v1",
      "published_date": "2025-04-15 16:25:06 UTC",
      "updated_date": "2025-04-15 16:25:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:12:54.302021"
    },
    {
      "arxiv_id": "2504.11354v1",
      "title": "Kimina-Prover Preview: Towards Large Formal Reasoning Models with Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Haiming Wang",
        "Mert Unsal",
        "Xiaohan Lin",
        "Mantas Baksys",
        "Junqi Liu",
        "Marco Dos Santos",
        "Flood Sung",
        "Marina Vinyes",
        "Zhenzhe Ying",
        "Zekai Zhu",
        "Jianqiao Lu",
        "Hugues de Saxcé",
        "Bolton Bailey",
        "Chendong Song",
        "Chenjun Xiao",
        "Dehao Zhang",
        "Ebony Zhang",
        "Frederick Pu",
        "Han Zhu",
        "Jiawei Liu",
        "Jonas Bayer",
        "Julien Michel",
        "Longhui Yu",
        "Léo Dreyfus-Schmidt",
        "Lewis Tunstall",
        "Luigi Pagani",
        "Moreira Machado",
        "Pauline Bourigault",
        "Ran Wang",
        "Stanislas Polu",
        "Thibaut Barroyer",
        "Wen-Ding Li",
        "Yazhe Niu",
        "Yann Fleureau",
        "Yangyang Hu",
        "Zhouliang Yu",
        "Zihan Wang",
        "Zhilin Yang",
        "Zhengying Liu",
        "Jia Li"
      ],
      "abstract": "We introduce Kimina-Prover Preview, a large language model that pioneers a\nnovel reasoning-driven exploration paradigm for formal theorem proving, as\nshowcased in this preview release. Trained with a large-scale reinforcement\nlearning pipeline from Qwen2.5-72B, Kimina-Prover demonstrates strong\nperformance in Lean 4 proof generation by employing a structured reasoning\npattern we term \\textit{formal reasoning pattern}. This approach allows the\nmodel to emulate human problem-solving strategies in Lean, iteratively\ngenerating and refining proof steps. Kimina-Prover sets a new state-of-the-art\non the miniF2F benchmark, reaching 80.7% with pass@8192. Beyond improved\nbenchmark performance, our work yields several key insights: (1) Kimina-Prover\nexhibits high sample efficiency, delivering strong results even with minimal\nsampling (pass@1) and scaling effectively with computational budget, stemming\nfrom its unique reasoning pattern and RL training; (2) we demonstrate clear\nperformance scaling with model size, a trend previously unobserved for neural\ntheorem provers in formal mathematics; (3) the learned reasoning style,\ndistinct from traditional search algorithms, shows potential to bridge the gap\nbetween formal verification and informal mathematical intuition. We open source\ndistilled versions with 1.5B and 7B parameters of Kimina-Prover",
      "tldr_zh": "我们介绍了 Kimina-Prover，一种基于强化学习（Reinforcement Learning）的模型，用于正式定理证明，通过采用结构化的 formal reasoning pattern 模仿人类问题解决策略，在 Lean 4 证明生成中迭代优化步骤。该模型在 miniF2F 基准上达到了 80.7% pass@8192 的新最先进水平，展示了高样本效率和性能随模型大小的扩展趋势。研究还揭示了其独特的推理风格，有潜力桥接形式验证与非正式数学直觉，并开源了 1.5B 和 7B 参数的精简版本。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "22 pages",
      "pdf_url": "http://arxiv.org/pdf/2504.11354v1",
      "published_date": "2025-04-15 16:23:44 UTC",
      "updated_date": "2025-04-15 16:23:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:13:06.152101"
    },
    {
      "arxiv_id": "2504.11349v2",
      "title": "Explicit and Implicit Representations in AI-based 3D Reconstruction for Radiology: A Systematic Review",
      "title_zh": "翻译失败",
      "authors": [
        "Yuezhe Yang",
        "Boyu Yang",
        "Yaqian Wang",
        "Yang He",
        "Xingbo Dong",
        "Zhe Jin"
      ],
      "abstract": "The demand for high-quality medical imaging in clinical practice and assisted\ndiagnosis has made 3D reconstruction in radiological imaging a key research\nfocus. Artificial intelligence (AI) has emerged as a promising approach to\nenhancing reconstruction accuracy while reducing acquisition and processing\ntime, thereby minimizing patient radiation exposure and discomfort and\nultimately benefiting clinical diagnosis. This review explores state-of-the-art\nAI-based 3D reconstruction algorithms in radiological imaging, categorizing\nthem into explicit and implicit approaches based on their underlying\nprinciples. Explicit methods include point-based, volume-based, and Gaussian\nrepresentations, while implicit methods encompass implicit prior embedding and\nneural radiance fields. Additionally, we examine commonly used evaluation\nmetrics and benchmark datasets. Finally, we discuss the current state of\ndevelopment, key challenges, and future research directions in this evolving\nfield. Our project available on: https://github.com/Bean-Young/AI4Radiology.",
      "tldr_zh": "这篇论文系统综述了基于人工智能(AI)的放射学3D重建技术，旨在提高重建准确性、减少采集处理时间并降低患者辐射暴露。论文将AI算法分为explicit methods（如point-based、volume-based和Gaussian representations）和implicit methods（如implicit prior embedding和neural radiance fields）。此外，研究者评估了常用评价指标和基准数据集，并讨论了当前发展面临的挑战以及未来研究方向，例如改进算法鲁棒性和临床应用潜力。总的来说，此工作为AI在放射学中的应用提供了全面概述，并附有开源项目链接。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "68T45",
        "I.4.5"
      ],
      "primary_category": "cs.CV",
      "comment": "20 pages, 5 figures, submit to Medical Image Analysis",
      "pdf_url": "http://arxiv.org/pdf/2504.11349v2",
      "published_date": "2025-04-15 16:21:47 UTC",
      "updated_date": "2025-05-17 08:58:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:13:16.985127"
    },
    {
      "arxiv_id": "2504.11344v2",
      "title": "Interpretable Hybrid-Rule Temporal Point Processes",
      "title_zh": "翻译失败",
      "authors": [
        "Yunyang Cao",
        "Juekai Lin",
        "Hongye Wang",
        "Wenhao Li",
        "Bo Jin"
      ],
      "abstract": "Temporal Point Processes (TPPs) are widely used for modeling event sequences\nin various medical domains, such as disease onset prediction, progression\nanalysis, and clinical decision support. Although TPPs effectively capture\ntemporal dynamics, their lack of interpretability remains a critical challenge.\nRecent advancements have introduced interpretable TPPs. However, these methods\nfail to incorporate numerical features, thereby limiting their ability to\ngenerate precise predictions. To address this issue, we propose Hybrid-Rule\nTemporal Point Processes (HRTPP), a novel framework that integrates temporal\nlogic rules with numerical features, improving both interpretability and\npredictive accuracy in event modeling. HRTPP comprises three key components:\nbasic intensity for intrinsic event likelihood, rule-based intensity for\nstructured temporal dependencies, and numerical feature intensity for dynamic\nprobability modulation. To effectively discover valid rules, we introduce a\ntwo-phase rule mining strategy with Bayesian optimization. To evaluate our\nmethod, we establish a multi-criteria assessment framework, incorporating rule\nvalidity, model fitting, and temporal predictive accuracy. Experimental results\non real-world medical datasets demonstrate that HRTPP outperforms\nstate-of-the-art interpretable TPPs in terms of predictive performance and\nclinical interpretability. In case studies, the rules extracted by HRTPP\nexplain the disease progression, offering valuable contributions to medical\ndiagnosis.",
      "tldr_zh": "该研究针对 Temporal Point Processes (TPPs) 在医疗领域建模事件序列时存在的可解释性不足问题，提出了一种新型框架 Hybrid-Rule Temporal Point Processes (HRTPP)，它整合了时间逻辑规则和数值特征，以提升预测准确性和临床可解释性。HRTPP 由基本强度（内在事件可能性）、基于规则的强度（结构化时间依赖）和数值特征强度（动态概率调节）三个组件组成，并引入两阶段规则挖掘策略结合 Bayesian optimization 来发现有效规则。在真实医疗数据集上的实验表明，HRTPP 优于现有可解释 TPPs 方法，在预测性能和模型拟合方面表现出显著优势，并通过案例研究为疾病进展分析和医疗诊断提供宝贵的解释性见解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.11344v2",
      "published_date": "2025-04-15 16:15:16 UTC",
      "updated_date": "2025-04-19 11:39:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:13:29.780038"
    },
    {
      "arxiv_id": "2504.11343v1",
      "title": "A Minimalist Approach to LLM Reasoning: from Rejection Sampling to Reinforce",
      "title_zh": "翻译失败",
      "authors": [
        "Wei Xiong",
        "Jiarui Yao",
        "Yuhui Xu",
        "Bo Pang",
        "Lei Wang",
        "Doyen Sahoo",
        "Junnan Li",
        "Nan Jiang",
        "Tong Zhang",
        "Caiming Xiong",
        "Hanze Dong"
      ],
      "abstract": "Reinforcement learning (RL) has become a prevailing approach for fine-tuning\nlarge language models (LLMs) on complex reasoning tasks. Among recent methods,\nGRPO stands out for its empirical success in training models such as\nDeepSeek-R1, yet the sources of its effectiveness remain poorly understood. In\nthis work, we revisit GRPO from a reinforce-like algorithm perspective and\nanalyze its core components. Surprisingly, we find that a simple rejection\nsampling baseline, RAFT, which trains only on positively rewarded samples,\nyields competitive performance than GRPO and PPO. Our ablation studies reveal\nthat GRPO's main advantage arises from discarding prompts with entirely\nincorrect responses, rather than from its reward normalization. Motivated by\nthis insight, we propose Reinforce-Rej, a minimal extension of policy gradient\nthat filters both entirely incorrect and entirely correct samples.\nReinforce-Rej improves KL efficiency and stability, serving as a lightweight\nyet effective alternative to more complex RL algorithms. We advocate RAFT as a\nrobust and interpretable baseline, and suggest that future advances should\nfocus on more principled designs for incorporating negative samples, rather\nthan relying on them indiscriminately. Our findings provide guidance for future\nwork in reward-based LLM post-training.",
      "tldr_zh": "本文重新审视强化学习（RL）在微调大型语言模型（LLMs）上的应用，发现GRPO方法的优势主要源于丢弃完全错误的响应，而非奖励归一化；同时，一个简单拒绝采样基线RAFT（仅训练正奖励样本）表现出与GRPO和PPO相当的性能。作者提出Reinforce-Rej，这是一种政策梯度的最小扩展，通过过滤完全错误和正确样本，提高KL效率和训练稳定性，作为更复杂RL算法的轻量级替代。研究主张RAFT作为稳健、可解释的基线，并建议未来工作应更原则性地处理负样本，以指导基于奖励的LLM后训练发展。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "12 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.11343v1",
      "published_date": "2025-04-15 16:15:02 UTC",
      "updated_date": "2025-04-15 16:15:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:13:41.499049"
    },
    {
      "arxiv_id": "2504.11338v1",
      "title": "Transformer-Based Model for Cold Start Mitigation in FaaS Architecture",
      "title_zh": "翻译失败",
      "authors": [
        "Alexandre Savi Fayam Mbala Mouen",
        "Jerry Lacmou Zeutouo",
        "Vianney Kengne Tchendji"
      ],
      "abstract": "Serverless architectures, particularly the Function as a Service (FaaS)\nmodel, have become a cornerstone of modern cloud computing due to their ability\nto simplify resource management and enhance application deployment agility.\nHowever, a significant challenge remains: the cold start problem. This\nphenomenon occurs when an idle FaaS function is invoked, requiring a full\ninitialization process, which increases latency and degrades user experience.\nExisting solutions for cold start mitigation are limited in terms of invocation\npattern generalization and implementation complexity. In this study, we propose\nan innovative approach leveraging Transformer models to mitigate the impact of\ncold starts in FaaS architectures. Our solution excels in accurately modeling\nfunction initialization delays and optimizing serverless system performance.\nExperimental evaluation using a public dataset provided by Azure demonstrates a\nsignificant reduction in cold start times, reaching up to 79\\% compared to\nconventional methods.",
      "tldr_zh": "这篇论文针对 Function as a Service (FaaS) 架构中的 cold start 问题，提出了一种基于 Transformer 模型的创新解决方案，以准确建模函数初始化延迟并优化服务器性能。现有方法在调用模式泛化和实现复杂度上存在局限，该研究通过 Transformer 模型预测和缓解冷启动影响。实验使用 Azure 公共数据集显示，与传统方法相比，冷启动时间减少高达 79%。",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.11338v1",
      "published_date": "2025-04-15 16:12:07 UTC",
      "updated_date": "2025-04-15 16:12:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:13:52.580481"
    },
    {
      "arxiv_id": "2504.13203v1",
      "title": "X-Teaming: Multi-Turn Jailbreaks and Defenses with Adaptive Multi-Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Salman Rahman",
        "Liwei Jiang",
        "James Shiffer",
        "Genglin Liu",
        "Sheriff Issaka",
        "Md Rizwan Parvez",
        "Hamid Palangi",
        "Kai-Wei Chang",
        "Yejin Choi",
        "Saadia Gabriel"
      ],
      "abstract": "Multi-turn interactions with language models (LMs) pose critical safety\nrisks, as harmful intent can be strategically spread across exchanges. Yet, the\nvast majority of prior work has focused on single-turn safety, while\nadaptability and diversity remain among the key challenges of multi-turn\nred-teaming. To address these challenges, we present X-Teaming, a scalable\nframework that systematically explores how seemingly harmless interactions\nescalate into harmful outcomes and generates corresponding attack scenarios.\nX-Teaming employs collaborative agents for planning, attack optimization, and\nverification, achieving state-of-the-art multi-turn jailbreak effectiveness and\ndiversity with success rates up to 98.1% across representative leading\nopen-weight and closed-source models. In particular, X-Teaming achieves a 96.2%\nattack success rate against the latest Claude 3.7 Sonnet model, which has been\nconsidered nearly immune to single-turn attacks. Building on X-Teaming, we\nintroduce XGuard-Train, an open-source multi-turn safety training dataset that\nis 20x larger than the previous best resource, comprising 30K interactive\njailbreaks, designed to enable robust multi-turn safety alignment for LMs. Our\nwork offers essential tools and insights for mitigating sophisticated\nconversational attacks, advancing the multi-turn safety of LMs.",
      "tldr_zh": "该研究提出X-Teaming框架，利用自适应多代理（Adaptive Multi-Agents）来处理语言模型（LMs）在多轮交互中的安全风险，通过协作代理进行规划、攻击优化和验证，系统探索无害对话如何升级为有害结果，并生成多样化的攻击场景。实验显示，X-Teaming在多轮越狱攻击（Multi-Turn Jailbreaks）中取得高达98.1%的成功率，包括对Claude 3.7 Sonnet模型的96.2%成功率，远超单轮攻击基准。基于此，研究还引入了XGuard-Train数据集，该数据集包含30K交互记录，是现有资源的20倍，用于增强LMs的多轮安全对齐，提供关键工具来缓解复杂对话攻击。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.13203v1",
      "published_date": "2025-04-15 16:11:28 UTC",
      "updated_date": "2025-04-15 16:11:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:14:05.073298"
    },
    {
      "arxiv_id": "2504.11336v2",
      "title": "Looking beyond the next token",
      "title_zh": "超越下一个标记",
      "authors": [
        "Abitha Thankaraj",
        "Yiding Jiang",
        "J. Zico Kolter",
        "Yonatan Bisk"
      ],
      "abstract": "The structure of causal language model training assumes that each token can\nbe accurately predicted from the previous context. This contrasts with humans'\nnatural writing and reasoning process, where goals are typically known before\nthe exact argument or phrasings. While this mismatch has been well studied in\nthe literature, the working assumption has been that architectural changes are\nneeded to address this mismatch. We argue that rearranging and processing the\ntraining data sequences can allow models to more accurately imitate the true\ndata-generating process, and does not require any other changes to the\narchitecture or training infrastructure. We demonstrate that this technique,\nTrelawney, and the inference algorithms derived from it allow us to improve\nperformance on several key benchmarks that span planning, algorithmic\nreasoning, and story generation tasks. Finally, our method naturally enables\nthe generation of long-term goals at no additional cost. We investigate how\nusing the model's goal-generation capability can further improve planning and\nreasoning. Additionally, we believe Trelawney could potentially open doors to\nnew capabilities beyond the current language modeling paradigm.",
      "tldr_zh": "这篇论文指出，传统因果语言模型的训练假设每个标记（token）仅基于前文预测，这与人类写作和推理过程（先知目标后构建细节）不匹配。作者提出 Trelawney 技术，通过重新排列和处理训练数据序列，让模型更准确模仿真实数据生成过程，而无需修改模型架构或训练基础设施。该方法在规划、算法推理和故事生成等基准任务上显著提升性能，并能免费生成长期目标，利用这一能力进一步优化模型的规划和推理效果。总的来说，Trelawney 可能为语言模型范式带来新能力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.11336v2",
      "published_date": "2025-04-15 16:09:06 UTC",
      "updated_date": "2025-04-24 03:13:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:14:16.607173"
    },
    {
      "arxiv_id": "2504.11335v1",
      "title": "Code Reborn AI-Driven Legacy Systems Modernization from COBOL to Java",
      "title_zh": "翻译失败",
      "authors": [
        "Gopichand Bandarupalli"
      ],
      "abstract": "This study investigates AI-driven modernization of legacy COBOL code into\nJava, addressing a critical challenge in aging software systems. Leveraging the\nLegacy COBOL 2024 Corpus -- 50,000 COBOL files from public and enterprise\nsources -- Java parses the code, AI suggests upgrades, and React visualizes\ngains. Achieving 93% accuracy, complexity drops 35% (from 18 to 11.7) and\ncoupling 33% (from 8 to 5.4), surpassing manual efforts (75%) and rule-based\ntools (82%). The approach offers a scalable path to rejuvenate COBOL systems,\nvital for industries like banking and insurance.",
      "tldr_zh": "本研究提出了一种AI驱动的方法，将遗留COBOL代码现代化为Java，解决老化软件系统的关键挑战。利用Legacy COBOL 2024 Corpus（包含50,000个COBOL文件），该方法结合Java解析代码、AI建议升级和React可视化，实现了93%的准确率。结果显示，代码复杂度降低了35%（从18到11.7）、耦合度降低了33%（从8到5.4），并超过了手动努力（75%）和基于规则的工具（82%）。此方法为银行和保险等行业的COBOL系统提供了一个可扩展的现代化路径。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.11335v1",
      "published_date": "2025-04-15 16:07:54 UTC",
      "updated_date": "2025-04-15 16:07:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:14:30.033119"
    },
    {
      "arxiv_id": "2504.11320v1",
      "title": "Optimizing LLM Inference: Fluid-Guided Online Scheduling with Memory Constraints",
      "title_zh": "翻译失败",
      "authors": [
        "Ruicheng Ao",
        "Gan Luo",
        "David Simchi-Levi",
        "Xinshang Wang"
      ],
      "abstract": "Large Language Models (LLMs) are indispensable in today's applications, but\ntheir inference procedure -- generating responses by processing text in\nsegments and using a memory-heavy Key-Value (KV) cache -- demands significant\ncomputational resources, particularly under memory constraints. This paper\nformulates LLM inference optimization as a multi-stage online scheduling\nproblem where sequential prompt arrivals and KV cache growth render\nconventional scheduling ineffective. We develop a fluid dynamics approximation\nto provide a tractable benchmark that guides algorithm design. Building on\nthis, we propose the Waiting for Accumulated Inference Threshold (WAIT)\nalgorithm, which uses multiple thresholds to schedule incoming prompts\noptimally when output lengths are known, and extend it to Nested WAIT for cases\nwith unknown output lengths. Theoretical analysis shows that both algorithms\nachieve near-optimal performance against the fluid benchmark in heavy traffic\nconditions, balancing throughput, latency, and Time to First Token (TTFT).\nExperiments with the Llama-7B model on an A100 GPU using both synthetic and\nreal-world datasets demonstrate improved throughput and reduced latency\nrelative to established baselines like vLLM and Sarathi. This work bridges\noperations research and machine learning, offering a rigorous framework for the\nefficient deployment of LLMs under memory constraints.",
      "tldr_zh": "这篇论文针对大语言模型 (LLM) 推理过程中内存约束问题，将其表述为多阶段在线调度问题，并使用流体动力学近似 (fluid dynamics approximation) 作为基准来指导算法设计。作者提出 Waiting for Accumulated Inference Threshold (WAIT) 算法及其扩展 Nested WAIT，用于优化提示调度，在已知或未知输出长度场景下平衡吞吐量、延迟和 Time to First Token (TTFT)。理论分析显示，这些算法在高负载条件下接近最优性能；实验在 Llama-7B 模型上证明了其比 vLLM 和 Sarathi 等基线更高的吞吐量和更低延迟。该工作桥接了运筹学和机器学习，提供了一个高效部署 LLM 的严谨框架。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC",
        "math.OC",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "42 pages, 18 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.11320v1",
      "published_date": "2025-04-15 16:00:21 UTC",
      "updated_date": "2025-04-15 16:00:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:14:44.556245"
    },
    {
      "arxiv_id": "2504.11305v1",
      "title": "CFIS-YOLO: A Lightweight Multi-Scale Fusion Network for Edge-Deployable Wood Defect Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Jincheng Kang",
        "Yi Cen",
        "Yigang Cen",
        "Ke Wang",
        "Yuhan Liu"
      ],
      "abstract": "Wood defect detection is critical for ensuring quality control in the wood\nprocessing industry. However, current industrial applications face two major\nchallenges: traditional methods are costly, subjective, and labor-intensive,\nwhile mainstream deep learning models often struggle to balance detection\naccuracy and computational efficiency for edge deployment. To address these\nissues, this study proposes CFIS-YOLO, a lightweight object detection model\noptimized for edge devices. The model introduces an enhanced C2f structure, a\ndynamic feature recombination module, and a novel loss function that\nincorporates auxiliary bounding boxes and angular constraints. These\ninnovations improve multi-scale feature fusion and small object localization\nwhile significantly reducing computational overhead. Evaluated on a public wood\ndefect dataset, CFIS-YOLO achieves a mean Average Precision (mAP@0.5) of\n77.5\\%, outperforming the baseline YOLOv10s by 4 percentage points. On SOPHON\nBM1684X edge devices, CFIS-YOLO delivers 135 FPS, reduces power consumption to\n17.3\\% of the original implementation, and incurs only a 0.5 percentage point\ndrop in mAP. These results demonstrate that CFIS-YOLO is a practical and\neffective solution for real-world wood defect detection in resource-constrained\nenvironments.",
      "tldr_zh": "该研究针对木材加工行业的缺陷检测问题，提出了一种轻量级目标检测模型 CFIS-YOLO，优化了边缘设备部署以平衡准确性和计算效率。模型引入增强的 C2f 结构、动态特征重组模块以及一种新颖的损失函数（包括辅助边界框和角度约束），从而改善多尺度特征融合和小对象定位，同时显著减少计算开销。在公共木材缺陷数据集上，CFIS-YOLO 实现了 77.5% 的 mAP@0.5，较基准 YOLOv10s 高出 4%。此外，在 SOPHON BM1684X 边缘设备上，它达到了 135 FPS、功耗仅为原实现的 17.3%，并仅以 0.5% 的 mAP 损失换取高效性能，为资源受限环境下的实际应用提供了实用解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.11305v1",
      "published_date": "2025-04-15 15:45:59 UTC",
      "updated_date": "2025-04-15 15:45:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:14:55.361380"
    },
    {
      "arxiv_id": "2504.11301v1",
      "title": "Learning to Be A Doctor: Searching for Effective Medical Agent Architectures",
      "title_zh": "学习成为医生：搜索有效的医疗智能体架构",
      "authors": [
        "Yangyang Zhuang",
        "Wenjia Jiang",
        "Jiayu Zhang",
        "Ze Yang",
        "Joey Tianyi Zhou",
        "Chi Zhang"
      ],
      "abstract": "Large Language Model (LLM)-based agents have demonstrated strong capabilities\nacross a wide range of tasks, and their application in the medical domain holds\nparticular promise due to the demand for high generalizability and reliance on\ninterdisciplinary knowledge. However, existing medical agent systems often rely\non static, manually crafted workflows that lack the flexibility to accommodate\ndiverse diagnostic requirements and adapt to emerging clinical scenarios.\nMotivated by the success of automated machine learning (AutoML), this paper\nintroduces a novel framework for the automated design of medical agent\narchitectures. Specifically, we define a hierarchical and expressive agent\nsearch space that enables dynamic workflow adaptation through structured\nmodifications at the node, structural, and framework levels. Our framework\nconceptualizes medical agents as graph-based architectures composed of diverse,\nfunctional node types and supports iterative self-improvement guided by\ndiagnostic feedback. Experimental results on skin disease diagnosis tasks\ndemonstrate that the proposed method effectively evolves workflow structures\nand significantly enhances diagnostic accuracy over time. This work represents\nthe first fully automated framework for medical agent architecture design and\noffers a scalable, adaptable foundation for deploying intelligent agents in\nreal-world clinical environments.",
      "tldr_zh": "这篇论文提出一个自动设计医疗代理架构的框架，受 AutoML 启发，旨在解决现有 LLM-based 代理系统依赖静态工作流、缺乏灵活性的问题。该框架定义了一个分层且表达性的搜索空间，将医疗代理视为基于图的结构，支持通过节点、结构和框架级别的动态修改以及诊断反馈引导的迭代自改进。在皮肤病诊断任务的实验中，该方法有效演化工作流并显著提升诊断准确率，为部署智能代理于真实临床环境提供了一个可扩展的基础。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.11301v1",
      "published_date": "2025-04-15 15:44:21 UTC",
      "updated_date": "2025-04-15 15:44:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:15:05.580205"
    },
    {
      "arxiv_id": "2504.11284v1",
      "title": "Bipartite Ranking From Multiple Labels: On Loss Versus Label Aggregation",
      "title_zh": "翻译失败",
      "authors": [
        "Michal Lukasik",
        "Lin Chen",
        "Harikrishna Narasimhan",
        "Aditya Krishna Menon",
        "Wittawat Jitkrittum",
        "Felix X. Yu",
        "Sashank J. Reddi",
        "Gang Fu",
        "Mohammadhossein Bateni",
        "Sanjiv Kumar"
      ],
      "abstract": "Bipartite ranking is a fundamental supervised learning problem, with the goal\nof learning a ranking over instances with maximal area under the ROC curve\n(AUC) against a single binary target label. However, one may often observe\nmultiple binary target labels, e.g., from distinct human annotators. How can\none synthesize such labels into a single coherent ranking? In this work, we\nformally analyze two approaches to this problem -- loss aggregation and label\naggregation -- by characterizing their Bayes-optimal solutions. Based on this,\nwe show that while both methods can yield Pareto-optimal solutions, loss\naggregation can exhibit label dictatorship: one can inadvertently (and\nundesirably) favor one label over others. This suggests that label aggregation\ncan be preferable to loss aggregation, which we empirically verify.",
      "tldr_zh": "该论文探讨了从多个二进制标签中学习二分排名（Bipartite ranking）的挑战，目标是最大化ROC曲线下的面积（AUC）。研究者通过分析损失聚合（loss aggregation）和标签聚合（label aggregation）两种方法，表征了它们的Bayes-optimal solutions。结果显示，虽然两者都能产生Pareto-optimal solutions，但损失聚合可能导致标签独裁（label dictatorship），即无意中偏好某一标签，因此标签聚合更可取，且实验验证了其优越性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IR",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.11284v1",
      "published_date": "2025-04-15 15:25:27 UTC",
      "updated_date": "2025-04-15 15:25:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:15:17.769139"
    },
    {
      "arxiv_id": "2504.11268v1",
      "title": "Single-Input Multi-Output Model Merging: Leveraging Foundation Models for Dense Multi-Task Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Juan Garcia Giraldo",
        "Nikolaos Dimitriadis",
        "Ke Wang",
        "Pascal Frossard"
      ],
      "abstract": "Model merging is a flexible and computationally tractable approach to merge\nsingle-task checkpoints into a multi-task model. Prior work has solely focused\non constrained multi-task settings where there is a one-to-one mapping between\na sample and a task, overlooking the paradigm where multiple tasks may operate\non the same sample, e.g., scene understanding. In this paper, we focus on the\nmulti-task setting with single-input-multiple-outputs (SIMO) and show that it\nqualitatively differs from the single-input-single-output model merging\nsettings studied in the literature due to the existence of task-specific\ndecoders and diverse loss objectives. We identify that existing model merging\nmethods lead to significant performance degradation, primarily due to\nrepresentation misalignment between the merged encoder and task-specific\ndecoders. We propose two simple and efficient fixes for the SIMO setting to\nre-align the feature representation after merging. Compared to joint\nfine-tuning, our approach is computationally effective and flexible, and sheds\nlight into identifying task relationships in an offline manner. Experiments on\nNYUv2, Cityscapes, and a subset of the Taskonomy dataset demonstrate: (1) task\narithmetic suffices to enable multi-task capabilities; however, the\nrepresentations generated by the merged encoder has to be re-aligned with the\ntask-specific heads; (2) the proposed architecture rivals traditional\nmulti-task learning in performance but requires fewer samples and training\nsteps by leveraging the existence of task-specific models.",
      "tldr_zh": "该论文探讨了Single-Input Multi-Output (SIMO)模型合并方法，利用基础模型实现密集多任务学习，解决了传统方法在处理同一输入多任务场景（如场景理解）时的表示不匹配问题。作者提出两个简单高效的修复策略，通过重新对齐合并后的编码器与任务特定解码器，缓解性能下降。实验在NYUv2、Cityscapes和Taskonomy数据集上显示，该方法仅需任务算术即可启用多任务能力，且在性能上媲美传统多任务学习，但显著减少了样本和训练步骤。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "22 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.11268v1",
      "published_date": "2025-04-15 15:10:46 UTC",
      "updated_date": "2025-04-15 15:10:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:15:30.101429"
    },
    {
      "arxiv_id": "2504.11264v1",
      "title": "DeepSelective: Feature Gating and Representation Matching for Interpretable Clinical Prediction",
      "title_zh": "DeepSelective：特征门控和表示匹配用于可解释的临床预测",
      "authors": [
        "Ruochi Zhang",
        "Qian Yang",
        "Xiaoyang Wang",
        "Haoran Wu",
        "Qiong Zhou",
        "Yu Wang",
        "Kewei Li",
        "Yueying Wang",
        "Yusi Fan",
        "Jiale Zhang",
        "Lan Huang",
        "Chang Liu",
        "Fengfeng Zhou"
      ],
      "abstract": "The rapid accumulation of Electronic Health Records (EHRs) has transformed\nhealthcare by providing valuable data that enhance clinical predictions and\ndiagnoses. While conventional machine learning models have proven effective,\nthey often lack robust representation learning and depend heavily on\nexpert-crafted features. Although deep learning offers powerful solutions, it\nis often criticized for its lack of interpretability. To address these\nchallenges, we propose DeepSelective, a novel end to end deep learning\nframework for predicting patient prognosis using EHR data, with a strong\nemphasis on enhancing model interpretability. DeepSelective combines data\ncompression techniques with an innovative feature selection approach,\nintegrating custom-designed modules that work together to improve both accuracy\nand interpretability. Our experiments demonstrate that DeepSelective not only\nenhances predictive accuracy but also significantly improves interpretability,\nmaking it a valuable tool for clinical decision-making. The source code is\nfreely available at http://www.healthinformaticslab.org/supp/resources.php .",
      "tldr_zh": "本文提出 DeepSelective，一种新型端到端深度学习框架，用于基于 Electronic Health Records (EHRs) 数据进行临床预测，旨在解决传统模型依赖专家手工特征和深度学习缺乏可解释性的问题。该框架结合数据压缩技术、创新的 feature gating 和 representation matching 方法，以及自定义模块，以同时提升预测准确性和模型解释性。实验结果显示，DeepSelective 显著提高了预测性能，并为临床决策提供了一个更可靠且可解释的工具。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.11264v1",
      "published_date": "2025-04-15 15:04:39 UTC",
      "updated_date": "2025-04-15 15:04:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:15:40.745246"
    },
    {
      "arxiv_id": "2504.11250v1",
      "title": "A Rollout-Based Algorithm and Reward Function for Efficient Resource Allocation in Business Processes",
      "title_zh": "翻译失败",
      "authors": [
        "Jeroen Middelhuis",
        "Zaharah Bukhsh",
        "Ivo Adan",
        "Remco Dijkman"
      ],
      "abstract": "Resource allocation plays a critical role in minimizing cycle time and\nimproving the efficiency of business processes. Recently, Deep Reinforcement\nLearning (DRL) has emerged as a powerful tool to optimize resource allocation\npolicies in business processes. In the DRL framework, an agent learns a policy\nthrough interaction with the environment, guided solely by reward signals that\nindicate the quality of its decisions. However, existing algorithms are not\nsuitable for dynamic environments such as business processes. Furthermore,\nexisting DRL-based methods rely on engineered reward functions that approximate\nthe desired objective, but a misalignment between reward and objective can lead\nto undesired decisions or suboptimal policies. To address these issues, we\npropose a rollout-based DRL algorithm and a reward function to optimize the\nobjective directly. Our algorithm iteratively improves the policy by evaluating\nexecution trajectories following different actions. Our reward function\ndirectly decomposes the objective function of minimizing the mean cycle time.\nMaximizing our reward function guarantees that the objective function is\nminimized without requiring extensive reward engineering. The results show that\nour method consistently learns the optimal policy in all six evaluated business\nprocesses, outperforming the state-of-the-art algorithm that can only learn the\noptimal policy in two of the evaluated processes.",
      "tldr_zh": "本文提出了一种基于 rollout 的 DRL 算法和奖励函数，用于优化业务流程中的资源分配，以最小化平均周期时间并提高效率。该算法通过评估不同动作的执行轨迹来迭代改进策略，而奖励函数直接分解目标函数，确保最大化奖励即最小化周期时间目标，无需复杂的奖励工程。实验结果显示，该方法在六个评估的业务流程中始终学习到最优策略，显著优于现有算法，后者仅在两个流程中达到最优。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Pre-print submitted to the 23rd International Conference on Business\n  Process Management",
      "pdf_url": "http://arxiv.org/pdf/2504.11250v1",
      "published_date": "2025-04-15 14:46:58 UTC",
      "updated_date": "2025-04-15 14:46:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:15:53.810387"
    },
    {
      "arxiv_id": "2504.11246v1",
      "title": "Respiratory Inhaler Sound Event Classification Using Self-Supervised Learning",
      "title_zh": "基于自监督学习的呼吸道吸入器声音事件分类",
      "authors": [
        "Davoud Shariat Panah",
        "Alessandro N Franciosi",
        "Cormac McCarthy",
        "Andrew Hines"
      ],
      "abstract": "Asthma is a chronic respiratory condition that affects millions of people\nworldwide. While this condition can be managed by administering controller\nmedications through handheld inhalers, clinical studies have shown low\nadherence to the correct inhaler usage technique. Consequently, many patients\nmay not receive the full benefit of their medication. Automated classification\nof inhaler sounds has recently been studied to assess medication adherence.\nHowever, the existing classification models were typically trained using data\nfrom specific inhaler types, and their ability to generalize to sounds from\ndifferent inhalers remains unexplored. In this study, we adapted the wav2vec\n2.0 self-supervised learning model for inhaler sound classification by\npre-training and fine-tuning this model on inhaler sounds. The proposed model\nshows a balanced accuracy of 98% on a dataset collected using a dry powder\ninhaler and smartwatch device. The results also demonstrate that re-finetuning\nthis model on minimal data from a target inhaler is a promising approach to\nadapting a generic inhaler sound classification model to a different inhaler\ndevice and audio capture hardware. This is the first study in the field to\ndemonstrate the potential of smartwatches as assistive technologies for the\npersonalized monitoring of inhaler adherence using machine learning models.",
      "tldr_zh": "本研究针对哮喘患者吸入器使用依从性低的问题，提出了一种基于自监督学习(Self-Supervised Learning)的吸入器声音事件分类方法，使用 wav2vec 2.0 模型进行预训练和微调。实验结果显示，该模型在干粉吸入器和智能手表数据集上实现了98%的平衡准确率(Balanced Accuracy)。此外，通过在目标吸入器上的少量数据重新微调，该方法能够有效适应不同吸入器设备和音频捕获硬件，这是首次证明智能手表作为辅助技术用于个性化监测吸入器依从性的潜力。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.AS",
      "comment": "Accepted at the IEEE EMBC 2025 Conference",
      "pdf_url": "http://arxiv.org/pdf/2504.11246v1",
      "published_date": "2025-04-15 14:44:47 UTC",
      "updated_date": "2025-04-15 14:44:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:16:05.667358"
    },
    {
      "arxiv_id": "2504.11245v1",
      "title": "Influence Maximization in Temporal Social Networks with a Cold-Start Problem: A Supervised Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Laixin Xie",
        "Ying Zhang",
        "Xiyuan Wang",
        "Shiyi Liu",
        "Shenghan Gao",
        "Xingxing Xing",
        "Wei Wan",
        "Haipeng Zhang",
        "Quan Li"
      ],
      "abstract": "Influence Maximization (IM) in temporal graphs focuses on identifying\ninfluential \"seeds\" that are pivotal for maximizing network expansion. We\nadvocate defining these seeds through Influence Propagation Paths (IPPs), which\nis essential for scaling up the network. Our focus lies in efficiently labeling\nIPPs and accurately predicting these seeds, while addressing the\noften-overlooked cold-start issue prevalent in temporal networks. Our strategy\nintroduces a motif-based labeling method and a tensorized Temporal Graph\nNetwork (TGN) tailored for multi-relational temporal graphs, bolstering\nprediction accuracy and computational efficiency. Moreover, we augment\ncold-start nodes with new neighbors from historical data sharing similar IPPs.\nThe recommendation system within an online team-based gaming environment\npresents subtle impact on the social network, forming multi-relational (i.e.,\nweak and strong) temporal graphs for our empirical IM study. We conduct offline\nexperiments to assess prediction accuracy and model training efficiency,\ncomplemented by online A/B testing to validate practical network growth and the\neffectiveness in addressing the cold-start issue.",
      "tldr_zh": "该论文针对时序社交网络中的影响最大化（Influence Maximization）问题，提出了一种监督方法，重点解决冷启动问题（Cold-Start Problem），通过影响传播路径（IPPs）来识别关键影响种子。方法包括基于 motif 的标记技术以及张量化时序图网络（tensorized Temporal Graph Network），适用于多关系时序图，提高了预测准确性和计算效率，同时为冷启动节点添加历史数据中类似IPPs的新邻居。实验结果显示，该方法在在线团队游戏环境中的离线评估和在线A/B测试中，显著提升了网络增长效果，并有效缓解了冷启动问题。",
      "categories": [
        "cs.SI",
        "cs.AI"
      ],
      "primary_category": "cs.SI",
      "comment": "Accepted by ICWSM 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.11245v1",
      "published_date": "2025-04-15 14:44:30 UTC",
      "updated_date": "2025-04-15 14:44:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:16:18.822977"
    },
    {
      "arxiv_id": "2504.11243v1",
      "title": "Towards Automated Safety Requirements Derivation Using Agent-based RAG",
      "title_zh": "翻译失败",
      "authors": [
        "Balahari Vignesh Balu",
        "Florian Geissler",
        "Francesco Carella",
        "Joao-Vitor Zacchi",
        "Josef Jiru",
        "Nuria Mata",
        "Reinhard Stolle"
      ],
      "abstract": "We study the automated derivation of safety requirements in a self-driving\nvehicle use case, leveraging LLMs in combination with agent-based\nretrieval-augmented generation. Conventional approaches that utilise\npre-trained LLMs to assist in safety analyses typically lack domain-specific\nknowledge. Existing RAG approaches address this issue, yet their performance\ndeteriorates when handling complex queries and it becomes increasingly harder\nto retrieve the most relevant information. This is particularly relevant for\nsafety-relevant applications. In this paper, we propose the use of agent-based\nRAG to derive safety requirements and show that the retrieved information is\nmore relevant to the queries. We implement an agent-based approach on a\ndocument pool of automotive standards and the Apollo case study, as a\nrepresentative example of an automated driving perception system. Our solution\nis tested on a data set of safety requirement questions and answers, extracted\nfrom the Apollo data. Evaluating a set of selected RAG metrics, we present and\ndiscuss advantages of a agent-based approach compared to default RAG methods.",
      "tldr_zh": "这篇论文探讨了使用agent-based RAG（基于代理的检索增强生成）自动推导自驾车辆的安全要求，以解决传统LLMs在缺少领域特定知识和处理复杂查询时的局限性。研究者提出了一种agent-based RAG方法，在汽车标准文档和Apollo案例研究的文件池上进行实现，并针对安全要求问题数据集进行测试。相比默认RAG方法，该方法显著提高了检索信息的相关性，并在选定的RAG指标上表现出优势，为安全相关应用提供了更可靠的解决方案。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "9 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.11243v1",
      "published_date": "2025-04-15 14:43:19 UTC",
      "updated_date": "2025-04-15 14:43:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:16:30.273890"
    },
    {
      "arxiv_id": "2504.11239v1",
      "title": "Nondeterministic Polynomial-time Problem Challenge: An Ever-Scaling Reasoning Benchmark for LLMs",
      "title_zh": "非确定性",
      "authors": [
        "Chang Yang",
        "Ruiyu Wang",
        "Junzhe Jiang",
        "Qi Jiang",
        "Qinggang Zhang",
        "Yanchen Deng",
        "Shuxin Li",
        "Shuyue Hu",
        "Bo Li",
        "Florian T. Pokorny",
        "Xiao Huang",
        "Xinrun Wang"
      ],
      "abstract": "Reasoning is the fundamental capability of large language models (LLMs). Due\nto the rapid progress of LLMs, there are two main issues of current benchmarks:\ni) these benchmarks can be crushed in a short time (less than 1 year), and ii)\nthese benchmarks may be easily hacked. To handle these issues, we propose the\never-scalingness for building the benchmarks which are uncrushable, unhackable,\nauto-verifiable and general. This paper presents Nondeterministic\nPolynomial-time Problem Challenge (NPPC), an ever-scaling reasoning benchmark\nfor LLMs. Specifically, the NPPC has three main modules: i) npgym, which\nprovides a unified interface of 25 well-known NP-complete problems and can\ngenerate any number of instances with any levels of complexities, ii) npsolver:\nwhich provides a unified interface to evaluate the problem instances with both\nonline and offline models via APIs and local deployments, respectively, and\niii) npeval: which provides the comprehensive and ready-to-use tools to analyze\nthe performances of LLMs over different problems, the number of tokens, the aha\nmoments, the reasoning errors and the solution errors. Extensive experiments\nover widely-used LLMs demonstrate: i) NPPC can successfully decrease the\nperformances of advanced LLMs' performances to below 10%, demonstrating that\nNPPC is uncrushable, ii) DeepSeek-R1, Claude-3.7-Sonnet, and o1/o3-mini are the\nmost powerful LLMs, where DeepSeek-R1 outperforms Claude-3.7-Sonnet and\no1/o3-mini in most NP-complete problems considered, and iii) the numbers of\ntokens, aha moments in the advanced LLMs, e.g., Claude-3.7-Sonnet and\nDeepSeek-R1, are observed first to increase and then decrease when the problem\ninstances become more and more difficult. We believe that NPPC is the first\never-scaling reasoning benchmark, serving as the uncrushable and unhackable\ntestbed for LLMs toward artificial general intelligence (AGI).",
      "tldr_zh": "该论文提出 NPPC（Nondeterministic Polynomial-time Problem Challenge），一个不断扩展的推理基准，旨在解决现有 LLMs 基准易被快速超越和操纵的问题，通过 ever-scaling 设计使其不可超越、不可hack、自动可验证且通用。NPPC 包括三个模块：npgym 用于生成任意复杂度的 25 个 NP-complete 问题实例、npsolver 用于评估模型性能，以及 npeval 用于分析 LLMs 的表现指标，如 token 数量、aha moments、推理错误和解决方案错误。实验结果显示，NPPC 将先进 LLMs 的性能降至 10% 以下，其中 DeepSeek-R1 在多数 NP-complete 问题上优于 Claude-3.7-Sonnet 和 o1/o3-mini，且随着问题难度增加，token 数量和 aha moments 先升后降。该基准作为通往 AGI 的不可破解测试平台，为 LLMs 评估提供了可靠工具。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Preliminary work, 10 pages for main text",
      "pdf_url": "http://arxiv.org/pdf/2504.11239v1",
      "published_date": "2025-04-15 14:40:29 UTC",
      "updated_date": "2025-04-15 14:40:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:16:43.348951"
    },
    {
      "arxiv_id": "2504.11216v1",
      "title": "Diversity-Driven Learning: Tackling Spurious Correlations and Data Heterogeneity in Federated Models",
      "title_zh": "多样性驱动学习：应对联邦模型中的虚假相关性和数据异质性",
      "authors": [
        "Gergely D. Németh",
        "Eros Fanì",
        "Yeat Jeng Ng",
        "Barbara Caputo",
        "Miguel Ángel Lozano",
        "Nuria Oliver",
        "Novi Quadrianto"
      ],
      "abstract": "Federated Learning (FL) enables decentralized training of machine learning\nmodels on distributed data while preserving privacy. However, in real-world FL\nsettings, client data is often non-identically distributed and imbalanced,\nresulting in statistical data heterogeneity which impacts the generalization\ncapabilities of the server's model across clients, slows convergence and\nreduces performance. In this paper, we address this challenge by first\nproposing a characterization of statistical data heterogeneity by means of 6\nmetrics of global and client attribute imbalance, class imbalance, and spurious\ncorrelations. Next, we create and share 7 computer vision datasets for binary\nand multiclass image classification tasks in Federated Learning that cover a\nbroad range of statistical data heterogeneity and hence simulate real-world\nsituations. Finally, we propose FedDiverse, a novel client selection algorithm\nin FL which is designed to manage and leverage data heterogeneity across\nclients by promoting collaboration between clients with complementary data\ndistributions. Experiments on the seven proposed FL datasets demonstrate\nFedDiverse's effectiveness in enhancing the performance and robustness of a\nvariety of FL methods while having low communication and computational\noverhead.",
      "tldr_zh": "本文探讨了Federated Learning (FL)中数据异质性（包括非独立同分布和不平衡数据）以及spurious correlations对模型泛化、收敛和性能的影响，通过提出6个指标来表征全球和客户端属性不平衡、类别不平衡及伪相关。论文创建并分享了7个计算机视觉数据集，用于FL中的二元和多类图像分类任务，以模拟真实世界场景。最终，提出FedDiverse算法，该算法通过选择具有互补数据分布的客户端促进协作，实验在7个数据集上证明其显著提升了各种FL方法的性能和鲁棒性，同时保持低通信和计算开销。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.11216v1",
      "published_date": "2025-04-15 14:20:42 UTC",
      "updated_date": "2025-04-15 14:20:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:16:55.478774"
    },
    {
      "arxiv_id": "2504.11200v1",
      "title": "Mutual Understanding between People and Systems via Neurosymbolic AI and Knowledge Graphs",
      "title_zh": "通过 Neurosymbolic AI 和 Knowledge Graphs 实现人与系统之间的相互理解",
      "authors": [
        "Irene Celino",
        "Mario Scrocca",
        "Agnese Chiatti"
      ],
      "abstract": "This chapter investigates the concept of mutual understanding between humans\nand systems, positing that Neuro-symbolic Artificial Intelligence (NeSy AI)\nmethods can significantly enhance this mutual understanding by leveraging\nexplicit symbolic knowledge representations with data-driven learning models.\nWe start by introducing three critical dimensions to characterize mutual\nunderstanding: sharing knowledge, exchanging knowledge, and governing\nknowledge. Sharing knowledge involves aligning the conceptual models of\ndifferent agents to enable a shared understanding of the domain of interest.\nExchanging knowledge relates to ensuring the effective and accurate\ncommunication between agents. Governing knowledge concerns establishing rules\nand processes to regulate the interaction between agents. Then, we present\nseveral different use case scenarios that demonstrate the application of NeSy\nAI and Knowledge Graphs to aid meaningful exchanges between human, artificial,\nand robotic agents. These scenarios highlight both the potential and the\nchallenges of combining top-down symbolic reasoning with bottom-up neural\nlearning, guiding the discussion of the coverage provided by current solutions\nalong the dimensions of sharing, exchanging, and governing knowledge.\nConcurrently, this analysis facilitates the identification of gaps and less\ndeveloped aspects in mutual understanding to address in future research.",
      "tldr_zh": "这篇论文探讨了通过 Neuro-symbolic AI (NeSy AI) 和 Knowledge Graphs 提升人类与系统之间相互理解的概念，强调了结合符号知识表示和数据驱动学习模型的重要性。论文定义了三个关键维度：sharing knowledge（共享知识，用于对齐代理的概念模型）、exchanging knowledge（交换知识，确保有效通信）和governing knowledge（管理知识，建立互动规则）。通过多个用例场景，展示了 NeSy AI 在人类、人工智能和机器人代理间促进知识交换的潜力与挑战。最终，分析了当前解决方案的覆盖情况，并指出了未来研究中共享、交换和管理知识方面的空白。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "26 pages, 13 figures, 1 table; pre-print version of book chapter",
      "pdf_url": "http://arxiv.org/pdf/2504.11200v1",
      "published_date": "2025-04-15 13:57:09 UTC",
      "updated_date": "2025-04-15 13:57:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:17:07.412342"
    },
    {
      "arxiv_id": "2504.11197v2",
      "title": "Efficient Distributed Retrieval-Augmented Generation for Enhancing Language Model Performance",
      "title_zh": "高效分布式检索增强生成，用于提升语言模型性能",
      "authors": [
        "Shangyu Liu",
        "Zhenzhe Zheng",
        "Xiaoyao Huang",
        "Fan Wu",
        "Guihai Chen",
        "Jie Wu"
      ],
      "abstract": "Small language models (SLMs) support efficient deployments on\nresource-constrained edge devices, but their limited capacity compromises\ninference performance. Retrieval-augmented generation (RAG) is a promising\nsolution to enhance model performance by integrating external databases,\nwithout requiring intensive on-device model retraining. However, large-scale\npublic databases and user-specific private contextual documents are typically\nlocated on the cloud and the device separately, while existing RAG\nimplementations are primarily centralized. To bridge this gap, we propose\nDRAGON, a distributed RAG framework to enhance on-device SLMs through both\ngeneral and personal knowledge without the risk of leaking document privacy.\nSpecifically, DRAGON decomposes multi-document RAG into multiple parallel token\ngeneration processes performed independently and locally on the cloud and the\ndevice, and employs a newly designed Speculative Aggregation, a dual-side\nspeculative algorithm to avoid frequent output synchronization between the\ncloud and device. A new scheduling algorithm is further introduced to identify\nthe optimal aggregation side based on real-time network conditions. Evaluations\non real-world hardware testbed demonstrate a significant performance\nimprovement of DRAGON-up to 1.9x greater gains over standalone SLM compared to\nthe centralized RAG, substantial reduction in per-token latency, and negligible\nTime to First Token (TTFT) overhead.",
      "tldr_zh": "本研究针对小型语言模型 (SLMs) 在资源受限边缘设备上的性能局限，提出了一种高效分布式检索增强生成 (RAG) 框架——DRAGON，以整合云端公共数据库和设备本地私有文档，同时保护隐私。DRAGON 将多文档 RAG 分解为并行 token 生成过程，并在云端和设备上独立执行，结合新设计的 Speculative Aggregation 算法和基于实时网络条件的调度算法，避免频繁同步并优化聚合策略。实验在真实硬件测试床上显示，DRAGON 相较于独立 SLMs 提升高达 1.9 倍性能，比集中式 RAG 更高效，显著降低了每 token 延迟，且 Time to First Token (TTFT) 开销微不足道。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC",
        "cs.IR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.11197v2",
      "published_date": "2025-04-15 13:53:08 UTC",
      "updated_date": "2025-04-16 03:32:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:17:19.709384"
    },
    {
      "arxiv_id": "2504.11514v1",
      "title": "Enhancing Autonomous Driving Systems with On-Board Deployed Large Language Models",
      "title_zh": "使用机载部署的大语言模型增强自动驾驶系统",
      "authors": [
        "Nicolas Baumann",
        "Cheng Hu",
        "Paviththiren Sivasothilingam",
        "Haotong Qin",
        "Lei Xie",
        "Michele Magno",
        "Luca Benini"
      ],
      "abstract": "Neural Networks (NNs) trained through supervised learning struggle with\nmanaging edge-case scenarios common in real-world driving due to the\nintractability of exhaustive datasets covering all edge-cases, making\nknowledge-driven approaches, akin to how humans intuitively detect unexpected\ndriving behavior, a suitable complement to data-driven methods. This work\nproposes a hybrid architecture combining low-level Model Predictive Controller\n(MPC) with locally deployed Large Language Models (LLMs) to enhance\ndecision-making and Human Machine Interaction (HMI). The DecisionxLLM module\nevaluates robotic state information against natural language instructions to\nensure adherence to desired driving behavior. The MPCxLLM module then adjusts\nMPC parameters based on LLM-generated insights, achieving control adaptability\nwhile preserving the safety and constraint guarantees of traditional MPC\nsystems. Further, to enable efficient on-board deployment and to eliminate\ndependency on cloud connectivity, we shift processing to the on-board computing\nplatform: We propose an approach that exploits Retrieval Augmented Generation\n(RAG), Low Rank Adaptation (LoRA) fine-tuning, and quantization. Experimental\nresults demonstrate that these enhancements yield significant improvements in\nreasoning accuracy by up to 10.45%, control adaptability by as much as 52.2%,\nand up to 10.5x increase in computational efficiency (tokens/s), validating the\nproposed framework's practicality for real-time deployment even on down-scaled\nrobotic platforms. This work bridges high-level decision-making with low-level\ncontrol adaptability, offering a synergistic framework for knowledge-driven and\nadaptive Autonomous Driving Systems (ADS).",
      "tldr_zh": "这篇论文提出了一种混合架构，将低级模型预测控制器 (MPC) 与本地部署的大型语言模型 (LLMs) 结合，以提升自动驾驶系统的决策能力和人机交互 (HMI)，并解决神经网络在处理边缘场景时的局限性。关键模块包括 DecisionxLLM，用于评估机器人状态信息与自然语言指令的符合性，以及 MPCxLLM，通过 LLM 生成的洞见动态调整 MPC 参数，实现控制适应性，同时保持系统的安全性和约束保证。为实现高效本地部署，该框架采用 Retrieval Augmented Generation (RAG)、Low Rank Adaptation (LoRA) 微调和量化技术，消除对云连接的依赖。实验结果显示，推理准确率提升高达 10.45%、控制适应性提高 52.2%，计算效率提升 10.5 倍，为知识驱动的适应性自动驾驶系统 (ADS) 提供了协同框架。",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.11514v1",
      "published_date": "2025-04-15 13:49:17 UTC",
      "updated_date": "2025-04-15 13:49:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:17:32.733939"
    },
    {
      "arxiv_id": "2504.11190v1",
      "title": "Enhancing multimodal analogical reasoning with Logic Augmented Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Anna Sofia Lippolis",
        "Andrea Giovanni Nuzzolese",
        "Aldo Gangemi"
      ],
      "abstract": "Recent advances in Large Language Models have demonstrated their capabilities\nacross a variety of tasks. However, automatically extracting implicit knowledge\nfrom natural language remains a significant challenge, as machines lack active\nexperience with the physical world. Given this scenario, semantic knowledge\ngraphs can serve as conceptual spaces that guide the automated text generation\nreasoning process to achieve more efficient and explainable results. In this\npaper, we apply a logic-augmented generation (LAG) framework that leverages the\nexplicit representation of a text through a semantic knowledge graph and\napplies it in combination with prompt heuristics to elicit implicit analogical\nconnections. This method generates extended knowledge graph triples\nrepresenting implicit meaning, enabling systems to reason on unlabeled\nmultimodal data regardless of the domain. We validate our work through three\nmetaphor detection and understanding tasks across four datasets, as they\nrequire deep analogical reasoning capabilities. The results show that this\nintegrated approach surpasses current baselines, performs better than humans in\nunderstanding visual metaphors, and enables more explainable reasoning\nprocesses, though still has inherent limitations in metaphor understanding,\nespecially for domain-specific metaphors. Furthermore, we propose a thorough\nerror analysis, discussing issues with metaphorical annotations and current\nevaluation methods.",
      "tldr_zh": "这篇论文提出了Logic Augmented Generation (LAG) 框架，利用语义知识图作为概念空间，结合提示启发式来增强Large Language Models在多模态类比推理中的能力，从而从自然语言中提取隐含知识并生成扩展的知识图三元组。LAG框架允许系统在无标签的多模态数据上进行领域无关的推理，并在三个比喻检测和理解任务的四个数据集上验证。实验结果显示，该方法超越了当前基线，在视觉比喻理解上优于人类，并提供了更可解释的推理过程，但仍存在局限性，如在领域特定比喻的处理上。论文还进行了彻底的错误分析，讨论了比喻标注和评估方法的潜在问题。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.11190v1",
      "published_date": "2025-04-15 13:47:55 UTC",
      "updated_date": "2025-04-15 13:47:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:17:44.295002"
    },
    {
      "arxiv_id": "2504.11186v1",
      "title": "Benchmarking Next-Generation Reasoning-Focused Large Language Models in Ophthalmology: A Head-to-Head Evaluation on 5,888 Items",
      "title_zh": "翻译失败",
      "authors": [
        "Minjie Zou",
        "Sahana Srinivasan",
        "Thaddaeus Wai Soon Lo",
        "Ke Zou",
        "Gabriel Dawei Yang",
        "Xuguang Ai",
        "Hyunjae Kim",
        "Maxwell Singer",
        "Fares Antaki",
        "Kelvin Li",
        "Robert Chang",
        "Marcus Tan",
        "David Ziyou Chen",
        "Dianbo Liu",
        "Qingyu Chen",
        "Yih Chung Tham"
      ],
      "abstract": "Recent advances in reasoning-focused large language models (LLMs) mark a\nshift from general LLMs toward models designed for complex decision-making, a\ncrucial aspect in medicine. However, their performance in specialized domains\nlike ophthalmology remains underexplored. This study comprehensively evaluated\nand compared the accuracy and reasoning capabilities of four newly developed\nreasoning-focused LLMs, namely DeepSeek-R1, OpenAI o1, o3-mini, and Gemini 2.0\nFlash-Thinking. Each model was assessed using 5,888 multiple-choice\nophthalmology exam questions from the MedMCQA dataset in zero-shot setting.\nQuantitative evaluation included accuracy, Macro-F1, and five text-generation\nmetrics (ROUGE-L, METEOR, BERTScore, BARTScore, and AlignScore), computed\nagainst ground-truth reasonings. Average inference time was recorded for a\nsubset of 100 randomly selected questions. Additionally, two board-certified\nophthalmologists qualitatively assessed clarity, completeness, and reasoning\nstructure of responses to differential diagnosis questions.O1 (0.902) and\nDeepSeek-R1 (0.888) achieved the highest accuracy, with o1 also leading in\nMacro-F1 (0.900). The performance of models across the text-generation metrics\nvaried: O3-mini excelled in ROUGE-L (0.151), o1 in METEOR (0.232), DeepSeek-R1\nand o3-mini tied for BERTScore (0.673), DeepSeek-R1 (-4.105) and Gemini 2.0\nFlash-Thinking (-4.127) performed best in BARTScore, while o3-mini (0.181) and\no1 (0.176) led AlignScore. Inference time across the models varied, with\nDeepSeek-R1 being slowest (40.4 seconds) and Gemini 2.0 Flash-Thinking fastest\n(6.7 seconds). Qualitative evaluation revealed that DeepSeek-R1 and Gemini 2.0\nFlash-Thinking tended to provide detailed and comprehensive intermediate\nreasoning, whereas o1 and o3-mini displayed concise and summarized\njustifications.",
      "tldr_zh": "这篇论文评估了四种推理-focused Large Language Models（LLMs），包括 DeepSeek-R1、OpenAI o1、o3-mini 和 Gemini 2.0 Flash-Thinking，在眼科领域的性能，使用 5,888 个 MedMCQA 数据集的多选题进行零样本测试。评估指标涵盖准确率、Macro-F1 和文本生成指标（如 ROUGE-L、METEOR、BERTScore），结果显示 o1 以最高准确率（0.902）和 Macro-F1（0.900）领先，而各模型在不同指标上表现不一，例如 o3-mini 在 ROUGE-L 上最佳。推理时间方面，DeepSeek-R1 最慢（40.4 秒），Gemini 2.0 Flash-Thinking 最快（6.7 秒），定性评估则表明 DeepSeek-R1 和 Gemini 2.0 Flash-Thinking 提供更详细的中间推理。该研究为 LLMs 在医学决策中的应用提供了宝贵基准，帮助填补眼科领域的研究空白。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "83 pages, 6 figures, 3 tables, 9 supplementary figures, 7\n  supplementary tables",
      "pdf_url": "http://arxiv.org/pdf/2504.11186v1",
      "published_date": "2025-04-15 13:42:34 UTC",
      "updated_date": "2025-04-15 13:42:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:17:59.752330"
    },
    {
      "arxiv_id": "2504.11182v1",
      "title": "Exploring Backdoor Attack and Defense for LLM-empowered Recommendations",
      "title_zh": "探索 LLM 赋能推荐系统的后门攻击与防御",
      "authors": [
        "Liangbo Ning",
        "Wenqi Fan",
        "Qing Li"
      ],
      "abstract": "The fusion of Large Language Models (LLMs) with recommender systems (RecSys)\nhas dramatically advanced personalized recommendations and drawn extensive\nattention. Despite the impressive progress, the safety of LLM-based RecSys\nagainst backdoor attacks remains largely under-explored. In this paper, we\nraise a new problem: Can a backdoor with a specific trigger be injected into\nLLM-based Recsys, leading to the manipulation of the recommendation responses\nwhen the backdoor trigger is appended to an item's title? To investigate the\nvulnerabilities of LLM-based RecSys under backdoor attacks, we propose a new\nattack framework termed Backdoor Injection Poisoning for RecSys (BadRec).\nBadRec perturbs the items' titles with triggers and employs several fake users\nto interact with these items, effectively poisoning the training set and\ninjecting backdoors into LLM-based RecSys. Comprehensive experiments reveal\nthat poisoning just 1% of the training data with adversarial examples is\nsufficient to successfully implant backdoors, enabling manipulation of\nrecommendations. To further mitigate such a security threat, we propose a\nuniversal defense strategy called Poison Scanner (P-Scanner). Specifically, we\nintroduce an LLM-based poison scanner to detect the poisoned items by\nleveraging the powerful language understanding and rich knowledge of LLMs. A\ntrigger augmentation agent is employed to generate diverse synthetic triggers\nto guide the poison scanner in learning domain-specific knowledge of the\npoisoned item detection task. Extensive experiments on three real-world\ndatasets validate the effectiveness of the proposed P-Scanner.",
      "tldr_zh": "这篇论文探讨了大型语言模型 (LLMs) 增强的推荐系统 (RecSys) 面对后门攻击的漏洞，提出一个新问题：是否可以通过特定触发器注入后门来操纵推荐响应。研究团队开发了攻击框架 BadRec，该框架通过在物品标题中添加触发器并使用假用户互动毒害训练数据，仅需污染 1% 的数据即可成功注入后门并控制推荐结果。为应对这一威胁，他们引入了通用防御策略 Poison Scanner (P-Scanner)，利用 LLM 的语言理解能力结合触发器增强代理来检测毒害物品。实验在三个真实数据集上验证了 BadRec 的攻击有效性和 P-Scanner 的防御性能。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.11182v1",
      "published_date": "2025-04-15 13:37:38 UTC",
      "updated_date": "2025-04-15 13:37:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:18:07.470392"
    },
    {
      "arxiv_id": "2504.11171v1",
      "title": "TerraMind: Large-Scale Generative Multimodality for Earth Observation",
      "title_zh": "翻译失败",
      "authors": [
        "Johannes Jakubik",
        "Felix Yang",
        "Benedikt Blumenstiel",
        "Erik Scheurer",
        "Rocco Sedona",
        "Stefano Maurogiovanni",
        "Jente Bosmans",
        "Nikolaos Dionelis",
        "Valerio Marsocci",
        "Niklas Kopp",
        "Rahul Ramachandran",
        "Paolo Fraccaro",
        "Thomas Brunschwiler",
        "Gabriele Cavallaro",
        "Juan Bernabe-Moreno",
        "Nicolas Longépé"
      ],
      "abstract": "We present TerraMind, the first any-to-any generative, multimodal foundation\nmodel for Earth observation (EO). Unlike other multimodal models, TerraMind is\npretrained on dual-scale representations combining both token-level and\npixel-level data across modalities. On a token level, TerraMind encodes\nhigh-level contextual information to learn cross-modal relationships, while on\na pixel level, TerraMind leverages fine-grained representations to capture\ncritical spatial nuances. We pretrained TerraMind on nine geospatial modalities\nof a global, large-scale dataset. In this paper, we demonstrate that (i)\nTerraMind's dual-scale early fusion approach unlocks a range of zero-shot and\nfew-shot applications for Earth observation, (ii) TerraMind introduces\n\"Thinking-in-Modalities\" (TiM) -- the capability of generating additional\nartificial data during finetuning and inference to improve the model output --\nand (iii) TerraMind achieves beyond state-of-the-art performance in\ncommunity-standard benchmarks for EO like PANGAEA. The pretraining dataset, the\nmodel weights, and our code is open-sourced under a permissive license.",
      "tldr_zh": "我们提出了 TerraMind，这是第一个针对地球观测的 any-to-any 生成式多模态基础模型，使用双尺度表示（token-level 和 pixel-level）在九种地理空间模态的全球大规模数据集上预训练，以学习跨模态关系和空间细节。\n\n该模型采用双尺度早期融合方法，支持零样本和少样本应用，并引入了 Thinking-in-Modalities (TiM) 技术，通过生成额外人工数据来提升微调和推理的输出质量。\n\n实验结果显示，TerraMind 在社区标准基准如 PANGAEA 上超越了现有技术水平，且其预训练数据集、模型权重和代码已开源，以促进进一步研究。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.11171v1",
      "published_date": "2025-04-15 13:17:39 UTC",
      "updated_date": "2025-04-15 13:17:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:18:19.490297"
    },
    {
      "arxiv_id": "2504.11169v1",
      "title": "MuSeD: A Multimodal Spanish Dataset for Sexism Detection in Social Media Videos",
      "title_zh": "翻译失败",
      "authors": [
        "Laura De Grazia",
        "Pol Pastells",
        "Mauro Vázquez Chas",
        "Desmond Elliott",
        "Danae Sánchez Villegas",
        "Mireia Farrús",
        "Mariona Taulé"
      ],
      "abstract": "Sexism is generally defined as prejudice and discrimination based on sex or\ngender, affecting every sector of society, from social institutions to\nrelationships and individual behavior. Social media platforms amplify the\nimpact of sexism by conveying discriminatory content not only through text but\nalso across multiple modalities, highlighting the critical need for a\nmultimodal approach to the analysis of sexism online. With the rise of social\nmedia platforms where users share short videos, sexism is increasingly\nspreading through video content. Automatically detecting sexism in videos is a\nchallenging task, as it requires analyzing the combination of verbal, audio,\nand visual elements to identify sexist content. In this study, (1) we introduce\nMuSeD, a new Multimodal Spanish dataset for Sexism Detection consisting of\n$\\approx$ 11 hours of videos extracted from TikTok and BitChute; (2) we propose\nan innovative annotation framework for analyzing the contribution of textual\nand multimodal labels in the classification of sexist and non-sexist content;\nand (3) we evaluate a range of large language models (LLMs) and multimodal LLMs\non the task of sexism detection. We find that visual information plays a key\nrole in labeling sexist content for both humans and models. Models effectively\ndetect explicit sexism; however, they struggle with implicit cases, such as\nstereotypes, instances where annotators also show low agreement. This\nhighlights the inherent difficulty of the task, as identifying implicit sexism\ndepends on the social and cultural context.",
      "tldr_zh": "本文介绍了 MuSeD，这是一个多模态西班牙语数据集，包含约 11 小时从 TikTok 和 BitChute 提取的社交媒体视频，用于检测视频中的性别歧视。研究提出了一种创新的标注框架，分析文本和多模态标签（如语音和视觉元素）在分类性别歧视内容中的贡献，并评估了 LLMs 和多模态 LLMs 的性能。结果显示，视觉信息在识别性别歧视中起关键作用，模型能有效检测显性歧视，但对隐性歧视（如刻板印象）表现较差，这取决于社会文化背景。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.11169v1",
      "published_date": "2025-04-15 13:16:46 UTC",
      "updated_date": "2025-04-15 13:16:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:18:37.352094"
    },
    {
      "arxiv_id": "2504.11168v2",
      "title": "Bypassing Prompt Injection and Jailbreak Detection in LLM Guardrails",
      "title_zh": "翻译失败",
      "authors": [
        "William Hackett",
        "Lewis Birch",
        "Stefan Trawicki",
        "Neeraj Suri",
        "Peter Garraghan"
      ],
      "abstract": "Large Language Models (LLMs) guardrail systems are designed to protect\nagainst prompt injection and jailbreak attacks. However, they remain vulnerable\nto evasion techniques. We demonstrate two approaches for bypassing LLM prompt\ninjection and jailbreak detection systems via traditional character injection\nmethods and algorithmic Adversarial Machine Learning (AML) evasion techniques.\nThrough testing against six prominent protection systems, including Microsoft's\nAzure Prompt Shield and Meta's Prompt Guard, we show that both methods can be\nused to evade detection while maintaining adversarial utility achieving in some\ninstances up to 100% evasion success. Furthermore, we demonstrate that\nadversaries can enhance Attack Success Rates (ASR) against black-box targets by\nleveraging word importance ranking computed by offline white-box models. Our\nfindings reveal vulnerabilities within current LLM protection mechanisms and\nhighlight the need for more robust guardrail systems.",
      "tldr_zh": "这篇论文探讨了大型语言模型 (LLMs) 防护系统在应对提示注入和越狱攻击时的漏洞，提出两种绕过方法：传统字符注入和算法性 Adversarial Machine Learning (AML) 逃避技术。研究者在六种主要防护系统中（如 Microsoft's Azure Prompt Shield 和 Meta's Prompt Guard）进行测试，证明这些方法能实现高达 100% 的逃避成功率，同时保持攻击效用。作者进一步展示了利用白盒模型计算的词重要性排名来提升对黑盒目标的 Attack Success Rates (ASR)。这些发现突显了当前 LLM 防护机制的脆弱性，并强调了开发更 robust 防护系统的必要性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG",
        "I.2.7"
      ],
      "primary_category": "cs.CR",
      "comment": "12 pages, 5 figures, 6 tables",
      "pdf_url": "http://arxiv.org/pdf/2504.11168v2",
      "published_date": "2025-04-15 13:16:02 UTC",
      "updated_date": "2025-04-16 15:33:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:18:44.594114"
    },
    {
      "arxiv_id": "2504.11160v1",
      "title": "DMAGaze: Gaze Estimation Based on Feature Disentanglement and Multi-Scale Attention",
      "title_zh": "DMAGaze：基于特征解耦和多尺度注意力的注视估计",
      "authors": [
        "Haohan Chen",
        "Hongjia Liu",
        "Shiyong Lan",
        "Wenwu Wang",
        "Yixin Qiao",
        "Yao Li",
        "Guonan Deng"
      ],
      "abstract": "Gaze estimation, which predicts gaze direction, commonly faces the challenge\nof interference from complex gaze-irrelevant information in face images. In\nthis work, we propose DMAGaze, a novel gaze estimation framework that exploits\ninformation from facial images in three aspects: gaze-relevant global features\n(disentangled from facial image), local eye features (extracted from cropped\neye patch), and head pose estimation features, to improve overall performance.\nFirstly, we design a new continuous mask-based Disentangler to accurately\ndisentangle gaze-relevant and gaze-irrelevant information in facial images by\nachieving the dual-branch disentanglement goal through separately\nreconstructing the eye and non-eye regions. Furthermore, we introduce a new\ncascaded attention module named Multi-Scale Global Local Attention Module\n(MS-GLAM). Through a customized cascaded attention structure, it effectively\nfocuses on global and local information at multiple scales, further enhancing\nthe information from the Disentangler. Finally, the global gaze-relevant\nfeatures disentangled by the upper face branch, combined with head pose and\nlocal eye features, are passed through the detection head for high-precision\ngaze estimation. Our proposed DMAGaze has been extensively validated on two\nmainstream public datasets, achieving state-of-the-art performance.",
      "tldr_zh": "该研究提出 DMAGaze，一种基于 Feature Disentanglement 和 Multi-Scale Attention 的视线估算框架，旨在减少面部图像中复杂无关信息对估算的干扰。\nDMAGaze 通过一个基于连续掩码的 Disentangler 模块，准确分离视线相关全局特征和无关信息，实现双分支重建眼睛和非眼睛区域。\n此外，它引入 Multi-Scale Global Local Attention Module (MS-GLAM)，通过级联注意力结构在多尺度上增强全局和局部特征的融合。\n最终，将分离出的全局视线相关特征与局部眼睛特征及头部姿势特征结合，进行高精度视线估算。\n在两个主流公共数据集上，DMAGaze 达到了 state-of-the-art 性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.11160v1",
      "published_date": "2025-04-15 13:08:43 UTC",
      "updated_date": "2025-04-15 13:08:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:18:56.925057"
    },
    {
      "arxiv_id": "2504.11159v1",
      "title": "C-SHAP for time series: An approach to high-level temporal explanations",
      "title_zh": "翻译失败",
      "authors": [
        "Annemarie Jutte",
        "Faizan Ahmed",
        "Jeroen Linssen",
        "Maurice van Keulen"
      ],
      "abstract": "Time series are ubiquitous in domains such as energy forecasting, healthcare,\nand industry. Using AI systems, some tasks within these domains can be\nefficiently handled. Explainable AI (XAI) aims to increase the reliability of\nAI solutions by explaining model reasoning. For time series, many XAI methods\nprovide point- or sequence-based attribution maps. These methods explain model\nreasoning in terms of low-level patterns. However, they do not capture\nhigh-level patterns that may also influence model reasoning. We propose a\nconcept-based method to provide explanations in terms of these high-level\npatterns. In this paper, we present C-SHAP for time series, an approach which\ndetermines the contribution of concepts to a model outcome. We provide a\ngeneral definition of C-SHAP and present an example implementation using time\nseries decomposition. Additionally, we demonstrate the effectiveness of the\nmethodology through a use case from the energy domain.",
      "tldr_zh": "本论文针对时间序列数据在能源预测、健康和工业等领域中的应用，指出现有 Explainable AI (XAI) 方法仅提供低级别的点级或序列级归因图，无法捕捉高水平模式的影响。作者提出 C-SHAP for time series 这一概念-based 方法，用于评估概念对模型结果的贡献，并提供其通用定义和基于时间序列分解的示例实现。通过能源领域的实际用例，实验证明了该方法的有效性，为高水平时间序列解释提供了新途径。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.11159v1",
      "published_date": "2025-04-15 13:06:32 UTC",
      "updated_date": "2025-04-15 13:06:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:19:07.124840"
    },
    {
      "arxiv_id": "2504.11130v1",
      "title": "Divergence of Empirical Neural Tangent Kernel in Classification Problems",
      "title_zh": "翻译失败",
      "authors": [
        "Zixiong Yu",
        "Songtao Tian",
        "Guhan Chen"
      ],
      "abstract": "This paper demonstrates that in classification problems, fully connected\nneural networks (FCNs) and residual neural networks (ResNets) cannot be\napproximated by kernel logistic regression based on the Neural Tangent Kernel\n(NTK) under overtraining (i.e., when training time approaches infinity).\nSpecifically, when using the cross-entropy loss, regardless of how large the\nnetwork width is (as long as it is finite), the empirical NTK diverges from the\nNTK on the training samples as training time increases. To establish this\nresult, we first demonstrate the strictly positive definiteness of the NTKs for\nmulti-layer FCNs and ResNets. Then, we prove that during training, % with the\ncross-entropy loss, the neural network parameters diverge if the smallest\neigenvalue of the empirical NTK matrix (Gram matrix) with respect to training\nsamples is bounded below by a positive constant. This behavior contrasts\nsharply with the lazy training regime commonly observed in regression problems.\nConsequently, using a proof by contradiction, we show that the empirical NTK\ndoes not uniformly converge to the NTK across all times on the training samples\nas the network width increases. We validate our theoretical results through\nexperiments on both synthetic data and the MNIST classification task. This\nfinding implies that NTK theory is not applicable in this context, with\nsignificant theoretical implications for understanding neural networks in\nclassification problems.",
      "tldr_zh": "本研究揭示了在分类问题中，FCNs（Fully Connected Neural Networks）和ResNets（Residual Neural Networks）在使用cross-entropy loss进行过度训练时，无法被基于Neural Tangent Kernel (NTK)的内核逻辑回归所近似，因为经验NTK会随着训练时间增加而偏离训练样本上的NTK。论文首先证明了多层FCNs和ResNets的NTK是严格正定的，并展示了如果经验NTK矩阵的最小特征值被正常量下界，则神经网络参数会发散，这与回归问题的惰性训练形成鲜明对比。通过反证法和实验验证（如合成数据和MNIST任务），研究者证实了经验NTK不会均匀收敛到NTK，从而表明NTK理论在分类问题中不适用，具有重要的理论启示。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.11130v1",
      "published_date": "2025-04-15 12:30:21 UTC",
      "updated_date": "2025-04-15 12:30:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:19:19.131401"
    },
    {
      "arxiv_id": "2504.11109v1",
      "title": "Fine-Tuning Large Language Models on Quantum Optimization Problems for Circuit Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Linus Jern",
        "Valter Uotila",
        "Cong Yu",
        "Bo Zhao"
      ],
      "abstract": "Large language models (LLM) have achieved remarkable outcomes in addressing\ncomplex problems, including math, coding, and analyzing large amounts of\nscientific reports. Yet few works have explored the potential of LLM in quantum\ncomputing. The most challenging problem is how to leverage LLMs to\nautomatically generate quantum circuits at a large scale. In this paper, we\naddress such a challenge by fine-tuning LLMs and injecting the domain-specific\nknowledge of quantum computing. In particular, we investigate the mechanisms to\ngenerate training data sets and construct the end-to-end pipeline to fine-tune\npre-trained LLMs that produce parameterized quantum circuits for optimization\nproblems. We have prepared 14,000 quantum circuits covering a substantial part\nof the quantum optimization landscape: 12 optimization problem instances and\ntheir optimized QAOA, VQE, and adaptive VQE circuits. The fine-tuned LLMs can\nconstruct syntactically correct parametrized quantum circuits in the most\nrecent OpenQASM 3.0. We have evaluated the quality of the parameters by\ncomparing them to the optimized expectation values and distributions. Our\nevaluation shows that the fine-tuned LLM outperforms state-of-the-art models\nand that the parameters are better than random. The LLM-generated parametrized\ncircuits and initial parameters can be used as a starting point for further\noptimization, \\emph{e.g.,} templates in quantum machine learning and the\nbenchmark for compilers and hardware.",
      "tldr_zh": "本文探讨了微调大型语言模型 (LLMs) 以自动生成量子电路的方法，针对量子优化问题注入领域特定知识，如 QAOA、VQE 和 adaptive VQE。研究者构建了端到端管道，包括生成14,000个量子电路数据集，并使用这些数据微调预训练LLMs，使其输出符合OpenQASM 3.0语法的参数化电路。实验结果表明，微调后的LLMs在参数质量和期望值优化上优于现有模型，且生成的电路可作为量子机器学习模板或硬件基准的起点。",
      "categories": [
        "quant-ph",
        "cs.AI"
      ],
      "primary_category": "quant-ph",
      "comment": "12 pages, 8 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2504.11109v1",
      "published_date": "2025-04-15 11:56:54 UTC",
      "updated_date": "2025-04-15 11:56:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:19:32.403026"
    },
    {
      "arxiv_id": "2504.11091v2",
      "title": "AI-guided Antibiotic Discovery Pipeline from Target Selection to Compound Identification",
      "title_zh": "AI 引导的抗生素发现管道：从目标选择到化合物识别",
      "authors": [
        "Maximilian G. Schuh",
        "Joshua Hesse",
        "Stephan A. Sieber"
      ],
      "abstract": "Antibiotic resistance presents a growing global health crisis, demanding new\ntherapeutic strategies that target novel bacterial mechanisms. Recent advances\nin protein structure prediction and machine learning-driven molecule generation\noffer a promising opportunity to accelerate drug discovery. However, practical\nguidance on selecting and integrating these models into real-world pipelines\nremains limited. In this study, we develop an end-to-end, artificial\nintelligence-guided antibiotic discovery pipeline that spans target\nidentification to compound realization. We leverage structure-based clustering\nacross predicted proteomes of multiple pathogens to identify conserved,\nessential, and non-human-homologous targets. We then systematically evaluate\nsix leading 3D-structure-aware generative models$\\unicode{x2014}$spanning\ndiffusion, autoregressive, graph neural network, and language model\narchitectures$\\unicode{x2014}$on their usability, chemical validity, and\nbiological relevance. Rigorous post-processing filters and commercial analogue\nsearches reduce over 100 000 generated compounds to a focused, synthesizable\nset. Our results highlight DeepBlock and TamGen as top performers across\ndiverse criteria, while also revealing critical trade-offs between model\ncomplexity, usability, and output quality. This work provides a comparative\nbenchmark and blueprint for deploying artificial intelligence in early-stage\nantibiotic development.",
      "tldr_zh": "本研究开发了一个端到端的AI指导抗生素发现管道，从目标选择到化合物识别，旨在应对抗生素抵抗的全球健康危机，通过整合蛋白质结构预测和机器学习驱动的分子生成来加速药物发现。管道采用基于结构的聚类方法识别保守的、必需的、非人类同源目标，并系统评估六种3D结构感知生成模型（包括diffusion、autoregressive、graph neural network和language model架构），通过后处理过滤和商业类似物搜索将超过10万个生成的化合物精简为可合成集。结果显示DeepBlock和TamGen在可用性、化学有效性和生物相关性方面表现最佳，同时揭示了模型复杂性、可用性与输出质量之间的关键权衡，为AI在早期抗生素开发中的部署提供了比较基准和蓝图。",
      "categories": [
        "q-bio.BM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.BM",
      "comment": "12 pages, preprint",
      "pdf_url": "http://arxiv.org/pdf/2504.11091v2",
      "published_date": "2025-04-15 11:36:27 UTC",
      "updated_date": "2025-05-21 11:33:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:19:44.830897"
    },
    {
      "arxiv_id": "2504.11083v1",
      "title": "QAMA: Quantum annealing multi-head attention operator with classical deep learning framework",
      "title_zh": "翻译失败",
      "authors": [
        "Peng Du",
        "Shuolei Wang",
        "Shicheng Li",
        "Jinjing Shi"
      ],
      "abstract": "As large language models scale up, the conventional attention mechanism faces\ncritical challenges of exponential growth in memory consumption and energy\ncosts. Quantum annealing computing, with its inherent advantages in\ncomputational efficiency and low energy consumption, offers an innovative\ndirection for constructing novel deep learning architectures. This study\nproposes the first Quantum Annealing-based Multi-head Attention (QAMA)\nmechanism, achieving seamless compatibility with classical attention\narchitectures through quadratic unconstrained binary optimization (QUBO)\nmodeling of forward propagation and energy-based backpropagation. The method\ninnovatively leverages the quantum bit interaction characteristics of Ising\nmodels to optimize the conventional $O(n^2)$ spatiotemporal complexity into\nlinear resource consumption. Integrated with the optical computing advantages\nof coherent Ising machines (CIM), the system maintains millisecond-level\nreal-time responsiveness while significantly reducing energy consumption. Our\nkey contributions include: Theoretical proofs establish QAMA mathematical\nequivalence to classical attention mechanisms; Dual optimization of multi-head\nspecificity and long-range information capture via QUBO constraints; Explicit\ngradient proofs for the Ising energy equation are utilized to implement\ngradient conduction as the only path in the computational graph as a layer;\nProposed soft selection mechanism overcoming traditional binary attention\nlimitations to approximate continuous weights. Experiments on QBoson CPQC\nquantum computer show QAMA achieves comparable accuracy to classical operators\nwhile reducing inference time to millisecond level and improving solution\nquality. This work pioneers architectural-level integration of quantum\ncomputing and deep learning, applicable to any attention-based model, driving\nparadigm innovation in AI foundational computing.",
      "tldr_zh": "这篇论文提出QAMA，一种基于量子退火计算的Multi-head Attention机制，用于解决传统注意力机制在大规模语言模型中指数级增长的内存和能量消耗问题。QAMA通过quadratic unconstrained binary optimization (QUBO)建模前向传播和基于能量的反向传播，并利用Ising模型的量子位交互特性，将O(n^2)的时空复杂度优化为线性资源消耗，同时与coherent Ising machines (CIM)整合，实现毫秒级实时响应和显著降低能量消耗。主要贡献包括理论证明QAMA与经典注意力机制的数学等价性、双重优化QUBO约束、Ising能量方程的梯度传导以及软选择机制来近似连续权重；实验在QBoson CPQC量子计算机上显示，QAMA实现了与经典操作符相当的准确性，同时大幅缩短推理时间并提升解决方案质量，推动了量子计算与深度学习的架构级创新。",
      "categories": [
        "quant-ph",
        "cs.AI"
      ],
      "primary_category": "quant-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.11083v1",
      "published_date": "2025-04-15 11:29:09 UTC",
      "updated_date": "2025-04-15 11:29:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:19:57.278781"
    },
    {
      "arxiv_id": "2504.11082v1",
      "title": "DeepMLF: Multimodal language model with learnable tokens for deep fusion in sentiment analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Efthymios Georgiou",
        "Vassilis Katsouros",
        "Yannis Avrithis",
        "Alexandros Potamianos"
      ],
      "abstract": "While multimodal fusion has been extensively studied in Multimodal Sentiment\nAnalysis (MSA), the role of fusion depth and multimodal capacity allocation\nremains underexplored. In this work, we position fusion depth, scalability, and\ndedicated multimodal capacity as primary factors for effective fusion. We\nintroduce DeepMLF, a novel multimodal language model (LM) with learnable tokens\ntailored toward deep fusion. DeepMLF leverages an audiovisual encoder and a\npretrained decoder LM augmented with multimodal information across its layers.\nWe append learnable tokens to the LM that: 1) capture modality interactions in\na controlled fashion and 2) preserve independent information flow for each\nmodality. These fusion tokens gather linguistic information via causal\nself-attention in LM Blocks and integrate with audiovisual information through\ncross-attention MM Blocks. Serving as dedicated multimodal capacity, this\ndesign enables progressive fusion across multiple layers, providing depth in\nthe fusion process. Our training recipe combines modality-specific losses and\nlanguage modelling loss, with the decoder LM tasked to predict ground truth\npolarity. Across three MSA benchmarks with varying dataset characteristics,\nDeepMLF achieves state-of-the-art performance. Our results confirm that deeper\nfusion leads to better performance, with optimal fusion depths (5-7) exceeding\nthose of existing approaches. Additionally, our analysis on the number of\nfusion tokens reveals that small token sets ($\\sim$20) achieve optimal\nperformance. We examine the importance of representation learning order (fusion\ncurriculum) through audiovisual encoder initialization experiments. Our\nablation studies demonstrate the superiority of the proposed fusion design and\ngating while providing a holistic examination of DeepMLF's scalability to LLMs,\nand the impact of each training objective and embedding regularization.",
      "tldr_zh": "本研究探讨了多模态情感分析（Multimodal Sentiment Analysis, MSA）中融合深度、可伸缩性和专用多模态容量的作用，提出了一种新型模型DeepMLF，该模型利用可学习tokens进行深度融合。DeepMLF结合音频视觉编码器和预训练解码器语言模型（LM），通过在LM块中添加融合tokens来捕获模态交互，并利用因果自注意力（causal self-attention）和交叉注意力（cross-attention MM Blocks）实现多层渐进融合，同时保留各模态的独立信息流。实验结果显示，DeepMLF在三个MSA基准上达到最先进性能，更深的融合深度（5-7层）显著优于现有方法，且使用约20个融合tokens即可实现最佳效果；此外，消融研究证实了该设计和训练策略（如模态特定损失和语言建模损失）的优越性，以及模型对大型语言模型（LLMs）的可伸缩性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Preprint",
      "pdf_url": "http://arxiv.org/pdf/2504.11082v1",
      "published_date": "2025-04-15 11:28:02 UTC",
      "updated_date": "2025-04-15 11:28:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:20:08.084086"
    },
    {
      "arxiv_id": "2504.11075v1",
      "title": "Emergence of Goal-Directed Behaviors via Active Inference with Self-Prior",
      "title_zh": "翻译失败",
      "authors": [
        "Dongmin Kim",
        "Hoshinori Kanazawa",
        "Naoto Yoshida",
        "Yasuo Kuniyoshi"
      ],
      "abstract": "Infants often exhibit goal-directed behaviors, such as reaching for a sensory\nstimulus, even when no external reward criterion is provided. These\nintrinsically motivated behaviors facilitate spontaneous exploration and\nlearning of the body and environment during early developmental stages.\nAlthough computational modeling can offer insight into the mechanisms\nunderlying such behaviors, many existing studies on intrinsic motivation focus\nprimarily on how exploration contributes to acquiring external rewards. In this\npaper, we propose a novel density model for an agent's own multimodal sensory\nexperiences, called the \"self-prior,\" and investigate whether it can\nautonomously induce goal-directed behavior. Integrated within an active\ninference framework based on the free energy principle, the self-prior\ngenerates behavioral references purely from an intrinsic process that minimizes\nmismatches between average past sensory experiences and current observations.\nThis mechanism is also analogous to the acquisition and utilization of a body\nschema through continuous interaction with the environment. We examine this\napproach in a simulated environment and confirm that the agent spontaneously\nreaches toward a tactile stimulus. Our study implements intrinsically motivated\nbehavior shaped by the agent's own sensory experiences, demonstrating the\nspontaneous emergence of intentional behavior during early development.",
      "tldr_zh": "本文提出“self-prior”密度模型，用于代理的多模态感官体验，通过内在动机过程诱导目标导向行为，而非依赖外部奖励。该模型整合到基于“free energy principle”的主动推理框架中，生成行为参考以最小化过去感官体验与当前观察之间的不匹配，从而模拟婴儿式探索和学习。在模拟环境中，实验显示代理自发地伸手触碰触觉刺激，这证明了基于自身感官体验的内在动机能促进意图行为的自发出现。",
      "categories": [
        "cs.AI",
        "68T05, 68T40, 68T42",
        "I.2.0; I.2.6; I.2.9"
      ],
      "primary_category": "cs.AI",
      "comment": "20 pages, Code is available at\n  https://github.com/kim135797531/self-prior",
      "pdf_url": "http://arxiv.org/pdf/2504.11075v1",
      "published_date": "2025-04-15 11:16:27 UTC",
      "updated_date": "2025-04-15 11:16:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:20:19.300860"
    },
    {
      "arxiv_id": "2504.11074v2",
      "title": "Dynamical errors in machine learning forecasts",
      "title_zh": "机器学习预测中的动力学错误",
      "authors": [
        "Zhou Fang",
        "Gianmarco Mengaldo"
      ],
      "abstract": "In machine learning forecasting, standard error metrics such as mean absolute\nerror (MAE) and mean squared error (MSE) quantify discrepancies between\npredictions and target values. However, these metrics do not directly evaluate\nthe physical and/or dynamical consistency of forecasts, an increasingly\ncritical concern in scientific and engineering applications.\n  Indeed, a fundamental yet often overlooked question is whether machine\nlearning forecasts preserve the dynamical behavior of the underlying system.\nAddressing this issue is essential for assessing the fidelity of machine\nlearning models and identifying potential failure modes, particularly in\napplications where maintaining correct dynamical behavior is crucial.\n  In this work, we investigate the relationship between standard forecasting\nerror metrics, such as MAE and MSE, and the dynamical properties of the\nunderlying system. To achieve this goal, we use two recently developed\ndynamical indices: the instantaneous dimension ($d$), and the inverse\npersistence ($\\theta$). Our results indicate that larger forecast errors --\ne.g., higher MSE -- tend to occur in states with higher $d$ (higher complexity)\nand higher $\\theta$ (lower persistence). To further assess dynamical\nconsistency, we propose error metrics based on the dynamical indices that\nmeasure the discrepancy of the forecasted $d$ and $\\theta$ versus their correct\nvalues. Leveraging these dynamical indices-based metrics, we analyze direct and\nrecursive forecasting strategies for three canonical datasets -- Lorenz,\nKuramoto-Sivashinsky equation, and Kolmogorov flow -- as well as a real-world\nweather forecasting task. Our findings reveal substantial distortions in\ndynamical properties in ML forecasts, especially for long forecast lead times\nor long recursive simulations, providing complementary information on ML\nforecast fidelity that can be used to improve ML models.",
      "tldr_zh": "本文研究了机器学习预测中的动态错误问题，指出标准错误指标如 MAE 和 MSE 虽能衡量预测与目标值的差异，但无法评估预测的物理或动态一致性。作者引入瞬时维度 ($d$) 和逆持久性 ($\\theta$) 等动态指标，分析了预测错误与系统动态属性的关系，发现较大的 MSE 往往与更高 $d$ (复杂度更高) 和更高 $\\theta$ (持久性更低) 的状态相关。基于此，他们提出了新的基于动态指标的错误度量，并在 Lorenz 系统、Kuramoto-Sivashinsky 方程、Kolmogorov 流动以及天气预报任务中验证，揭示 ML 预测在长时预测或递归模拟中存在显著动态扭曲，为提升模型的动态保真度提供了改进方向。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.comp-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.11074v2",
      "published_date": "2025-04-15 11:16:13 UTC",
      "updated_date": "2025-04-16 08:48:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:20:34.339448"
    },
    {
      "arxiv_id": "2504.11511v1",
      "title": "Position Paper: Rethinking Privacy in RL for Sequential Decision-making in the Age of LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Flint Xiaofeng Fan",
        "Cheston Tan",
        "Roger Wattenhofer",
        "Yew-Soon Ong"
      ],
      "abstract": "The rise of reinforcement learning (RL) in critical real-world applications\ndemands a fundamental rethinking of privacy in AI systems. Traditional privacy\nframeworks, designed to protect isolated data points, fall short for sequential\ndecision-making systems where sensitive information emerges from temporal\npatterns, behavioral strategies, and collaborative dynamics. Modern RL\nparadigms, such as federated RL (FedRL) and RL with human feedback (RLHF) in\nlarge language models (LLMs), exacerbate these challenges by introducing\ncomplex, interactive, and context-dependent learning environments that\ntraditional methods do not address. In this position paper, we argue for a new\nprivacy paradigm built on four core principles: multi-scale protection,\nbehavioral pattern protection, collaborative privacy preservation, and\ncontext-aware adaptation. These principles expose inherent tensions between\nprivacy, utility, and interpretability that must be navigated as RL systems\nbecome more pervasive in high-stakes domains like healthcare, autonomous\nvehicles, and decision support systems powered by LLMs. To tackle these\nchallenges, we call for the development of new theoretical frameworks,\npractical mechanisms, and rigorous evaluation methodologies that collectively\nenable effective privacy protection in sequential decision-making systems.",
      "tldr_zh": "本文讨论了在大型语言模型 (LLMs) 时代，强化学习 (RL) 用于顺序决策系统的隐私问题，强调传统隐私框架无法有效保护时间模式、行为策略和协作动态中的敏感信息。论文提出一个新隐私范式，基于四个核心原则：多尺度保护、行为模式保护、协作隐私保存和上下文感知适应，以应对联邦 RL (FedRL) 和 RL with human feedback (RLHF) 等现代 RL 范式的挑战。这些原则暴露了隐私、效用和可解释性之间的内在张力，并呼吁开发新的理论框架、实用机制和评估方法，以在高风险领域如医疗和自动驾驶中实现有效隐私保护。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to IJCNN 2025 Position Paper Track",
      "pdf_url": "http://arxiv.org/pdf/2504.11511v1",
      "published_date": "2025-04-15 10:45:55 UTC",
      "updated_date": "2025-04-15 10:45:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:20:44.369388"
    },
    {
      "arxiv_id": "2504.11510v1",
      "title": "RAID: An In-Training Defense against Attribute Inference Attacks in Recommender Systems",
      "title_zh": "RAID：针对推荐系统中属性推断攻击的训练中防御",
      "authors": [
        "Xiaohua Feng",
        "Yuyuan Li",
        "Fengyuan Yu",
        "Ke Xiong",
        "Junjie Fang",
        "Li Zhang",
        "Tianyu Du",
        "Chaochao Chen"
      ],
      "abstract": "In various networks and mobile applications, users are highly susceptible to\nattribute inference attacks, with particularly prevalent occurrences in\nrecommender systems. Attackers exploit partially exposed user profiles in\nrecommendation models, such as user embeddings, to infer private attributes of\ntarget users, such as gender and political views. The goal of defenders is to\nmitigate the effectiveness of these attacks while maintaining recommendation\nperformance. Most existing defense methods, such as differential privacy and\nattribute unlearning, focus on post-training settings, which limits their\ncapability of utilizing training data to preserve recommendation performance.\nAlthough adversarial training extends defenses to in-training settings, it\noften struggles with convergence due to unstable training processes. In this\npaper, we propose RAID, an in-training defense method against attribute\ninference attacks in recommender systems. In addition to the recommendation\nobjective, we define a defensive objective to ensure that the distribution of\nprotected attributes becomes independent of class labels, making users\nindistinguishable from attribute inference attacks. Specifically, this\ndefensive objective aims to solve a constrained Wasserstein barycenter problem\nto identify the centroid distribution that makes the attribute\nindistinguishable while complying with recommendation performance constraints.\nTo optimize our proposed objective, we use optimal transport to align users\nwith the centroid distribution. We conduct extensive experiments on four\nreal-world datasets to evaluate RAID. The experimental results validate the\neffectiveness of RAID and demonstrate its significant superiority over existing\nmethods in multiple aspects.",
      "tldr_zh": "该论文针对推荐系统中属性推断攻击（attribute inference attacks）的问题，提出了一种在训练中（in-training）的防御方法RAID，以缓解攻击者利用用户嵌入推断私人属性的风险，同时保持推荐性能。RAID在推荐目标之外，定义了一个防御目标，通过解决受约束的Wasserstein barycenter问题，确保受保护属性的分布与类别标签无关，从而使用户在攻击中不可区分，并使用optimal transport技术对用户与中心分布进行对齐。实验结果显示，在四个真实数据集上，RAID显著优于现有方法如differential privacy和对抗训练，在防御有效性和性能平衡方面表现出色。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CR",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "17 pages",
      "pdf_url": "http://arxiv.org/pdf/2504.11510v1",
      "published_date": "2025-04-15 10:24:37 UTC",
      "updated_date": "2025-04-15 10:24:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:20:56.797890"
    },
    {
      "arxiv_id": "2504.11045v1",
      "title": "Neural Control Barrier Functions from Physics Informed Neural Networks",
      "title_zh": "基于物理信息神经网络的神经控制屏障函数",
      "authors": [
        "Shreenabh Agrawal",
        "Manan Tayal",
        "Aditya Singh",
        "Shishir Kolathaya"
      ],
      "abstract": "As autonomous systems become increasingly prevalent in daily life, ensuring\ntheir safety is paramount. Control Barrier Functions (CBFs) have emerged as an\neffective tool for guaranteeing safety; however, manually designing them for\nspecific applications remains a significant challenge. With the advent of deep\nlearning techniques, recent research has explored synthesizing CBFs using\nneural networks-commonly referred to as neural CBFs. This paper introduces a\nnovel class of neural CBFs that leverages a physics-inspired neural network\nframework by incorporating Zubov's Partial Differential Equation (PDE) within\nthe context of safety. This approach provides a scalable methodology for\nsynthesizing neural CBFs applicable to high-dimensional systems. Furthermore,\nby utilizing reciprocal CBFs instead of zeroing CBFs, the proposed framework\nallows for the specification of flexible, user-defined safe regions. To\nvalidate the effectiveness of the approach, we present case studies on three\ndifferent systems: an inverted pendulum, autonomous ground navigation, and\naerial navigation in obstacle-laden environments.",
      "tldr_zh": "这篇论文提出了一种新型 Neural Control Barrier Functions (neural CBFs)，利用 Physics Informed Neural Networks 框架整合 Zubov's Partial Differential Equation (PDE)，以解决自主系统安全设计中的挑战。该方法提供可扩展的合成框架，适用于高维系统，并通过采用 reciprocal CBFs 而非 zeroing CBFs，允许用户定义灵活的安全区域。通过对倒立摆、地面导航和空中导航等系统的案例研究，验证了该框架的有效性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "8 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.11045v1",
      "published_date": "2025-04-15 10:13:30 UTC",
      "updated_date": "2025-04-15 10:13:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:21:07.707092"
    },
    {
      "arxiv_id": "2504.11038v1",
      "title": "QAVA: Query-Agnostic Visual Attack to Large Vision-Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yudong Zhang",
        "Ruobing Xie",
        "Jiansheng Chen",
        "Xingwu Sun",
        "Zhanhui Kang",
        "Yu Wang"
      ],
      "abstract": "In typical multimodal tasks, such as Visual Question Answering (VQA),\nadversarial attacks targeting a specific image and question can lead large\nvision-language models (LVLMs) to provide incorrect answers. However, it is\ncommon for a single image to be associated with multiple questions, and LVLMs\nmay still answer other questions correctly even for an adversarial image\nattacked by a specific question. To address this, we introduce the\nquery-agnostic visual attack (QAVA), which aims to create robust adversarial\nexamples that generate incorrect responses to unspecified and unknown\nquestions. Compared to traditional adversarial attacks focused on specific\nimages and questions, QAVA significantly enhances the effectiveness and\nefficiency of attacks on images when the question is unknown, achieving\nperformance comparable to attacks on known target questions. Our research\nbroadens the scope of visual adversarial attacks on LVLMs in practical\nsettings, uncovering previously overlooked vulnerabilities, particularly in the\ncontext of visual adversarial threats. The code is available at\nhttps://github.com/btzyd/qava.",
      "tldr_zh": "论文提出 QAVA，一种查询无关视觉攻击方法，针对大型视觉语言模型 (LVLMs) 设计，用于创建鲁棒的对抗样本，使其对未知问题生成错误响应，从而解决传统 Visual Question Answering (VQA) 攻击仅针对特定图像和问题的局限性。与传统攻击相比，QAVA 在问题未知的情况下显著提升了攻击的有效性和效率，性能可与针对已知问题的攻击相当。研究扩展了视觉对抗攻击的范围，揭示了 LVLMs 在实际场景中的新漏洞，并提供了开源代码以供进一步验证。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by NAACL 2025 main",
      "pdf_url": "http://arxiv.org/pdf/2504.11038v1",
      "published_date": "2025-04-15 10:00:01 UTC",
      "updated_date": "2025-04-15 10:00:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:21:20.197124"
    },
    {
      "arxiv_id": "2504.11020v1",
      "title": "\"Even explanations will not help in trusting [this] fundamentally biased system\": A Predictive Policing Case-Study",
      "title_zh": "翻译失败",
      "authors": [
        "Siddharth Mehrotra",
        "Ujwal Gadiraju",
        "Eva Bittner",
        "Folkert van Delden",
        "Catholijn M. Jonker",
        "Myrthe L. Tielman"
      ],
      "abstract": "In today's society, where Artificial Intelligence (AI) has gained a vital\nrole, concerns regarding user's trust have garnered significant attention. The\nuse of AI systems in high-risk domains have often led users to either\nunder-trust it, potentially causing inadequate reliance or over-trust it,\nresulting in over-compliance. Therefore, users must maintain an appropriate\nlevel of trust. Past research has indicated that explanations provided by AI\nsystems can enhance user understanding of when to trust or not trust the\nsystem. However, the utility of presentation of different explanations forms\nstill remains to be explored especially in high-risk domains. Therefore, this\nstudy explores the impact of different explanation types (text, visual, and\nhybrid) and user expertise (retired police officers and lay users) on\nestablishing appropriate trust in AI-based predictive policing. While we\nobserved that the hybrid form of explanations increased the subjective trust in\nAI for expert users, it did not led to better decision-making. Furthermore, no\nform of explanations helped build appropriate trust. The findings of our study\nemphasize the importance of re-evaluating the use of explanations to build\n[appropriate] trust in AI based systems especially when the system's use is\nquestionable. Finally, we synthesize potential challenges and policy\nrecommendations based on our results to design for appropriate trust in\nhigh-risk based AI-based systems.",
      "tldr_zh": "本研究探讨了在高风险领域如预测性警务中，不同解释形式（文本、视觉和混合）对用户信任的影响，针对退休警察和普通用户等不同专业性群体。研究发现，虽然混合解释形式提高了专家用户的主观信任，但并未改善决策表现，且任何解释形式都无法建立适当信任。结果强调，需要重新评估解释在本质上存在偏差的AI系统中的作用，并基于此提出潜在挑战和政策推荐，以设计更可靠的高风险AI应用。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "33rd ACM Conference on User Modeling, Adaptation and Personalization\n  (UMAP '25), June 16--19, 2025, New York City, NY, USA",
      "pdf_url": "http://arxiv.org/pdf/2504.11020v1",
      "published_date": "2025-04-15 09:43:48 UTC",
      "updated_date": "2025-04-15 09:43:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:21:31.085192"
    },
    {
      "arxiv_id": "2504.11014v4",
      "title": "GATE3D: Generalized Attention-based Task-synergized Estimation in 3D*",
      "title_zh": "翻译失败",
      "authors": [
        "Eunsoo Im",
        "Changhyun Jee",
        "Jung Kwon Lee"
      ],
      "abstract": "The emerging trend in computer vision emphasizes developing universal models\ncapable of simultaneously addressing multiple diverse tasks. Such universality\ntypically requires joint training across multi-domain datasets to ensure\neffective generalization. However, monocular 3D object detection presents\nunique challenges in multi-domain training due to the scarcity of datasets\nannotated with accurate 3D ground-truth labels, especially beyond typical\nroad-based autonomous driving contexts. To address this challenge, we introduce\na novel weakly supervised framework leveraging pseudo-labels. Current\npretrained models often struggle to accurately detect pedestrians in non-road\nenvironments due to inherent dataset biases. Unlike generalized image-based 2D\nobject detection models, achieving similar generalization in monocular 3D\ndetection remains largely unexplored. In this paper, we propose GATE3D, a novel\nframework designed specifically for generalized monocular 3D object detection\nvia weak supervision. GATE3D effectively bridges domain gaps by employing\nconsistency losses between 2D and 3D predictions. Remarkably, our model\nachieves competitive performance on the KITTI benchmark as well as on an\nindoor-office dataset collected by us to evaluate the generalization\ncapabilities of our framework. Our results demonstrate that GATE3D\nsignificantly accelerates learning from limited annotated data through\neffective pre-training strategies, highlighting substantial potential for\nbroader impacts in robotics, augmented reality, and virtual reality\napplications. Project page: https://ies0411.github.io/GATE3D/",
      "tldr_zh": "本研究针对单目 3D 对象检测（monocular 3D object detection）在多领域训练中的数据稀缺问题，提出了一种新型弱监督框架 GATE3D。GATE3D 通过利用伪标签（pseudo-labels）和在 2D 与 3D 预测之间施加一致性损失（consistency losses），有效桥接领域差距，实现通用模型的训练和泛化。实验结果显示，该框架在 KITTI benchmark 上取得竞争性性能，并在作者收集的室内办公室数据集上表现出色，显著加速了从有限标注数据中学习的过程。总体而言，GATE3D 为机器人、增强现实和虚拟现实应用提供了广阔的潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted (Poster) to the 3rd CV4MR Workshop at CVPR 2025:\n  https://openreview.net/forum?id=00RQ8Cv3ia",
      "pdf_url": "http://arxiv.org/pdf/2504.11014v4",
      "published_date": "2025-04-15 09:37:54 UTC",
      "updated_date": "2025-04-30 01:39:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:21:43.592225"
    },
    {
      "arxiv_id": "2504.11011v1",
      "title": "Document Quality Scoring for Web Crawling",
      "title_zh": "用于网络爬取的文档质量评分",
      "authors": [
        "Francesca Pezzuti",
        "Ariane Mueller",
        "Sean MacAvaney",
        "Nicola Tonellotto"
      ],
      "abstract": "The internet contains large amounts of low-quality content, yet users expect\nweb search engines to deliver high-quality, relevant results. The abundant\npresence of low-quality pages can negatively impact retrieval and crawling\nprocesses by wasting resources on these documents. Therefore, search engines\ncan greatly benefit from techniques that leverage efficient quality estimation\nmethods to mitigate these negative impacts. Quality scoring methods for web\npages are useful for many processes typical for web search systems, including\nstatic index pruning, index tiering, and crawling. Building on work by Chang et\nal.~\\cite{chang2024neural}, who proposed using neural estimators of semantic\nquality for static index pruning, we extend their approach and apply their\nneural quality scorers to assess the semantic quality of web pages in crawling\nprioritisation tasks. In our experimental analysis, we found that prioritising\nsemantically high-quality pages over low-quality ones can improve downstream\nsearch effectiveness. Our software contribution consists of a Docker container\nthat computes an effective quality score for a given web page, allowing the\nquality scorer to be easily included and used in other components of web search\nsystems.",
      "tldr_zh": "本研究针对互联网中大量低质量内容的挑战，提出了一种基于神经估计器（neural estimators）的网页质量评分方法，用于提升网络爬取效率。该方法扩展了 Chang et al. 的工作，将语义质量（semantic quality）评分应用于爬取优先级任务，从而减少资源浪费并改善搜索效果。实验结果显示，优先处理高质量页面可提高下游搜索效能（downstream search effectiveness）。此外，研究提供了可轻松集成的 Docker container，用于计算网页质量分数。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "Presented at WOWS2025",
      "pdf_url": "http://arxiv.org/pdf/2504.11011v1",
      "published_date": "2025-04-15 09:32:57 UTC",
      "updated_date": "2025-04-15 09:32:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:21:54.956067"
    },
    {
      "arxiv_id": "2504.11008v2",
      "title": "MediSee: Reasoning-based Pixel-level Perception in Medical Images",
      "title_zh": "MediSee：基于推理的像素级医疗图像感知",
      "authors": [
        "Qinyue Tong",
        "Ziqian Lu",
        "Jun Liu",
        "Yangming Zheng",
        "Zheming Lu"
      ],
      "abstract": "Despite remarkable advancements in pixel-level medical image perception,\nexisting methods are either limited to specific tasks or heavily rely on\naccurate bounding boxes or text labels as input prompts. However, the medical\nknowledge required for input is a huge obstacle for general public, which\ngreatly reduces the universality of these methods. Compared with these\ndomain-specialized auxiliary information, general users tend to rely on oral\nqueries that require logical reasoning. In this paper, we introduce a novel\nmedical vision task: Medical Reasoning Segmentation and Detection (MedSD),\nwhich aims to comprehend implicit queries about medical images and generate the\ncorresponding segmentation mask and bounding box for the target object. To\naccomplish this task, we first introduce a Multi-perspective, Logic-driven\nMedical Reasoning Segmentation and Detection (MLMR-SD) dataset, which\nencompasses a substantial collection of medical entity targets along with their\ncorresponding reasoning. Furthermore, we propose MediSee, an effective baseline\nmodel designed for medical reasoning segmentation and detection. The\nexperimental results indicate that the proposed method can effectively address\nMedSD with implicit colloquial queries and outperform traditional medical\nreferring segmentation methods.",
      "tldr_zh": "本研究指出，现有的像素级医疗图像感知方法局限于特定任务或依赖精确的bounding box和文本标签，这需要专业医学知识，降低了通用性。论文引入一个新任务：Medical Reasoning Segmentation and Detection (MedSD)，旨在理解医疗图像的隐含口语查询，并生成对应的segmentation mask和bounding box。为此，构建了Multi-perspective, Logic-driven Medical Reasoning Segmentation and Detection (MLMR-SD)数据集，并提出MediSee模型作为有效基线，通过逻辑驱动的推理处理查询。实验结果表明，MediSee在处理隐含查询时优于传统医疗referring segmentation方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.11008v2",
      "published_date": "2025-04-15 09:28:53 UTC",
      "updated_date": "2025-04-23 15:29:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:22:09.548859"
    },
    {
      "arxiv_id": "2504.11004v1",
      "title": "Dynamic Compressing Prompts for Efficient Inference of Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jinwu Hu",
        "Wei Zhang",
        "Yufeng Wang",
        "Yu Hu",
        "Bin Xiao",
        "Mingkui Tan",
        "Qing Du"
      ],
      "abstract": "Large Language Models (LLMs) have shown outstanding performance across a\nvariety of tasks, partly due to advanced prompting techniques. However, these\ntechniques often require lengthy prompts, which increase computational costs\nand can hinder performance because of the limited context windows of LLMs.\nWhile prompt compression is a straightforward solution, existing methods\nconfront the challenges of retaining essential information, adapting to context\nchanges, and remaining effective across different tasks. To tackle these\nissues, we propose a task-agnostic method called Dynamic Compressing Prompts\n(LLM-DCP). Our method reduces the number of prompt tokens while aiming to\npreserve the performance as much as possible. We model prompt compression as a\nMarkov Decision Process (MDP), enabling the DCP-Agent to sequentially remove\nredundant tokens by adapting to dynamic contexts and retaining crucial content.\nWe develop a reward function for training the DCP-Agent that balances the\ncompression rate, the quality of the LLM output, and the retention of key\ninformation. This allows for prompt token reduction without needing an external\nblack-box LLM. Inspired by the progressive difficulty adjustment in curriculum\nlearning, we introduce a Hierarchical Prompt Compression (HPC) training\nstrategy that gradually increases the compression difficulty, enabling the\nDCP-Agent to learn an effective compression method that maintains information\nintegrity. Experiments demonstrate that our method outperforms state-of-the-art\ntechniques, especially at higher compression rates. The code for our approach\nwill be available at https://github.com/Fhujinwu/DCP.",
      "tldr_zh": "本文提出了一种任务无关的动态压缩提示方法（Dynamic Compressing Prompts, LLM-DCP），旨在解决大型语言模型（Large Language Models, LLMs）在使用长提示时导致的计算成本增加和性能受限问题。该方法将提示压缩建模为马尔可夫决策过程（Markov Decision Process, MDP），通过 DCP-Agent 顺序移除冗余标记，同时使用奖励函数平衡压缩率、输出质量和关键信息保留，并引入分层提示压缩（Hierarchical Prompt Compression, HPC）策略逐步提升训练难度。实验结果显示，LLM-DCP 在高压缩率下优于现有技术，有效提高了 LLMs 的高效推理性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Under review (submited in 2024.11)",
      "pdf_url": "http://arxiv.org/pdf/2504.11004v1",
      "published_date": "2025-04-15 09:20:45 UTC",
      "updated_date": "2025-04-15 09:20:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:22:20.353158"
    },
    {
      "arxiv_id": "2504.10995v1",
      "title": "TMCIR: Token Merge Benefits Composed Image Retrieval",
      "title_zh": "翻译失败",
      "authors": [
        "Chaoyang Wang",
        "Zeyu Zhang",
        "Long Teng",
        "Zijun Li",
        "Shichao Kan"
      ],
      "abstract": "Composed Image Retrieval (CIR) retrieves target images using a multi-modal\nquery that combines a reference image with text describing desired\nmodifications. The primary challenge is effectively fusing this visual and\ntextual information. Current cross-modal feature fusion approaches for CIR\nexhibit an inherent bias in intention interpretation. These methods tend to\ndisproportionately emphasize either the reference image features\n(visual-dominant fusion) or the textual modification intent (text-dominant\nfusion through image-to-text conversion). Such an imbalanced representation\noften fails to accurately capture and reflect the actual search intent of the\nuser in the retrieval results. To address this challenge, we propose TMCIR, a\nnovel framework that advances composed image retrieval through two key\ninnovations: 1) Intent-Aware Cross-Modal Alignment. We first fine-tune CLIP\nencoders contrastively using intent-reflecting pseudo-target images,\nsynthesized from reference images and textual descriptions via a diffusion\nmodel. This step enhances the encoder ability of text to capture nuanced\nintents in textual descriptions. 2) Adaptive Token Fusion. We further fine-tune\nall encoders contrastively by comparing adaptive token-fusion features with the\ntarget image. This mechanism dynamically balances visual and textual\nrepresentations within the contrastive learning pipeline, optimizing the\ncomposed feature for retrieval. Extensive experiments on Fashion-IQ and CIRR\ndatasets demonstrate that TMCIR significantly outperforms state-of-the-art\nmethods, particularly in capturing nuanced user intent.",
      "tldr_zh": "该论文提出 TMCIR 框架，以解决 Composed Image Retrieval (CIR) 中跨模态特征融合的偏差问题，这些偏差导致模型过度强调参考图像（visual-dominant fusion）或文本描述（text-dominant fusion），从而无法准确捕捉用户意图。TMCIR 的关键创新包括：1) Intent-Aware Cross-Modal Alignment，通过使用扩散模型合成伪目标图像，对 CLIP 编码器进行对比微调，以增强文本对细微意图的捕捉；2) Adaptive Token Fusion，通过对比学习动态平衡视觉和文本表示，优化组合特征用于检索。在 Fashion-IQ 和 CIRR 数据集上的实验表明，TMCIR 显著优于现有方法，尤其在捕捉用户细微意图方面，展示了其有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "arXiv admin note: text overlap with arXiv:2310.05473 by other authors",
      "pdf_url": "http://arxiv.org/pdf/2504.10995v1",
      "published_date": "2025-04-15 09:14:04 UTC",
      "updated_date": "2025-04-15 09:14:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:22:34.092994"
    },
    {
      "arxiv_id": "2504.10983v1",
      "title": "ProtFlow: Fast Protein Sequence Design via Flow Matching on Compressed Protein Language Model Embeddings",
      "title_zh": "翻译失败",
      "authors": [
        "Zitai Kong",
        "Yiheng Zhu",
        "Yinlong Xu",
        "Hanjing Zhou",
        "Mingzhe Yin",
        "Jialu Wu",
        "Hongxia Xu",
        "Chang-Yu Hsieh",
        "Tingjun Hou",
        "Jian Wu"
      ],
      "abstract": "The design of protein sequences with desired functionalities is a fundamental\ntask in protein engineering. Deep generative methods, such as autoregressive\nmodels and diffusion models, have greatly accelerated the discovery of novel\nprotein sequences. However, these methods mainly focus on local or shallow\nresidual semantics and suffer from low inference efficiency, large modeling\nspace and high training cost. To address these challenges, we introduce\nProtFlow, a fast flow matching-based protein sequence design framework that\noperates on embeddings derived from semantically meaningful latent space of\nprotein language models. By compressing and smoothing the latent space,\nProtFlow enhances performance while training on limited computational\nresources. Leveraging reflow techniques, ProtFlow enables high-quality\nsingle-step sequence generation. Additionally, we develop a joint design\npipeline for the design scene of multichain proteins. We evaluate ProtFlow\nacross diverse protein design tasks, including general peptides and long-chain\nproteins, antimicrobial peptides, and antibodies. Experimental results\ndemonstrate that ProtFlow outperforms task-specific methods in these\napplications, underscoring its potential and broad applicability in\ncomputational protein sequence design and analysis.",
      "tldr_zh": "该研究提出ProtFlow，一种基于流匹配(flow matching)的快速蛋白质序列设计框架，通过在蛋白质语言模型嵌入(embeddings)的压缩潜在空间上操作，解决了现有生成方法如自回归模型和扩散模型的效率低下和训练成本高等问题。ProtFlow通过压缩和平滑潜在空间以及reflow技术，实现高质量的单步序列生成，并支持多链蛋白的联合设计管道。在各种任务中，包括一般肽、长链蛋白、抗菌肽和抗体，ProtFlow的表现优于特定任务方法，展示了其在计算蛋白质序列设计中的广泛潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.BM"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10983v1",
      "published_date": "2025-04-15 08:46:53 UTC",
      "updated_date": "2025-04-15 08:46:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:22:44.979172"
    },
    {
      "arxiv_id": "2504.10982v5",
      "title": "Exploring the Role of Knowledge Graph-Based RAG in Japanese Medical Question Answering with Small-Scale LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Yingjian Chen",
        "Feiyang Li",
        "Xingyu Song",
        "Tianxiao Li",
        "Zixin Xu",
        "Xiujie Chen",
        "Issey Sukeda",
        "Irene Li"
      ],
      "abstract": "Large language models (LLMs) perform well in medical QA, but their\neffectiveness in Japanese contexts is limited due to privacy constraints that\nprevent the use of commercial models like GPT-4 in clinical settings. As a\nresult, recent efforts focus on instruction-tuning open-source LLMs, though the\npotential of combining them with retrieval-augmented generation (RAG) remains\nunderexplored. To bridge this gap, we are the first to explore a knowledge\ngraph-based (KG) RAG framework for Japanese medical QA small-scale open-source\nLLMs. Experimental results show that KG-based RAG has only a limited impact on\nJapanese medical QA using small-scale open-source LLMs. Further case studies\nreveal that the effectiveness of the RAG is sensitive to the quality and\nrelevance of the external retrieved content. These findings offer valuable\ninsights into the challenges and potential of applying RAG in Japanese medical\nQA, while also serving as a reference for other low-resource languages.",
      "tldr_zh": "本研究探讨了基于知识图谱(KG)的检索增强生成(RAG)框架在日语医疗问答(Japanese medical QA)中使用小型开源大型语言模型(small-scale LLMs)中的作用，旨在解决商业模型受隐私限制而无法应用的挑战。\n实验结果显示，KG-based RAG对日语医疗QA的影响有限，主要取决于外部检索内容的质量和相关性。\n这些发现为日语医疗QA中RAG的应用提供了宝贵见解，并为其他低资源语言的类似研究提供了参考。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages",
      "pdf_url": "http://arxiv.org/pdf/2504.10982v5",
      "published_date": "2025-04-15 08:46:39 UTC",
      "updated_date": "2025-04-26 09:13:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:22:57.924550"
    },
    {
      "arxiv_id": "2504.10961v1",
      "title": "Evaluating Trust in AI, Human, and Co-produced Feedback Among Undergraduate Students",
      "title_zh": "翻译失败",
      "authors": [
        "Audrey Zhang",
        "Yifei Gao",
        "Wannapon Suraworachet",
        "Tanya Nazaretsky",
        "Mutlu Cukurova"
      ],
      "abstract": "As generative AI transforms educational feedback practices, understanding\nstudents' perceptions of different feedback providers becomes crucial for\neffective implementation. This study addresses a critical gap by comparing\nundergraduate students' trust in AI-generated, human-created, and human-AI\nco-produced feedback, informing how institutions can adapt feedback practices\nin this new era. Through a within-subject experiment with 91 participants, we\ninvestigated factors predicting students' ability to distinguish between\nfeedback types, perception of feedback quality, and potential biases to AI\ninvolvement. Findings revealed that students generally preferred AI and\nco-produced feedback over human feedback in terms of perceived usefulness and\nobjectivity. Only AI feedback suffered a decline in perceived genuineness when\nfeedback sources were revealed, while co-produced feedback maintained its\npositive perception. Educational AI experience improved students' ability to\nidentify AI feedback and increased their trust in all feedback types, while\ngeneral AI experience decreased perceived usefulness and credibility. Male\nstudents consistently rated all feedback types as less valuable than their\nfemale and non-binary counterparts. These insights inform evidence-based\nguidelines for integrating AI into higher education feedback systems while\naddressing trust concerns and fostering AI literacy among students.",
      "tldr_zh": "这篇论文通过一个涉及91名参与者的within-subject实验，评估了本科生对AI-generated、human-created和human-AI co-produced反馈的信任，探讨了学生区分反馈类型的能力、对反馈质量的感知以及对AI参与的潜在偏见。结果显示，学生更倾向于AI和co-produced反馈，认为它们在usefulness和objectivity方面优于human反馈，而co-produced反馈在来源揭露后仍保持积极感知。教育AI经验提升了学生识别AI反馈的能力并增加了对所有反馈类型的信任，而一般AI经验则降低了perceived usefulness和credibility。性别差异显著，男性学生对所有反馈类型的评价较低，这些发现为高等教育中整合AI反馈系统提供了证据-based指导，同时强调了解决信任问题和培养AI literacy的重要性。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "35 pages, 6 figures. Under review at Assessment and Evaluation in\n  Higher Education",
      "pdf_url": "http://arxiv.org/pdf/2504.10961v1",
      "published_date": "2025-04-15 08:06:36 UTC",
      "updated_date": "2025-04-15 08:06:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:23:08.625835"
    },
    {
      "arxiv_id": "2504.10948v1",
      "title": "BEACON: A Benchmark for Efficient and Accurate Counting of Subgraphs",
      "title_zh": "翻译失败",
      "authors": [
        "Mohammad Matin Najafi",
        "Xianju Zhu",
        "Chrysanthi Kosyfaki",
        "Laks V. S. Lakshmanan",
        "Reynold Cheng"
      ],
      "abstract": "Subgraph counting the task of determining the number of instances of a query\npattern within a large graph lies at the heart of many critical applications,\nfrom analyzing financial networks and transportation systems to understanding\nbiological interactions. Despite decades of work yielding efficient algorithmic\n(AL) solutions and, more recently, machine learning (ML) approaches, a clear\ncomparative understanding is elusive. This gap stems from the absence of a\nunified evaluation framework, standardized datasets, and accessible ground\ntruths, all of which hinder systematic analysis and fair benchmarking. To\novercome these barriers, we introduce BEACON: a comprehensive benchmark\ndesigned to rigorously evaluate both AL and ML-based subgraph counting methods.\nBEACON provides a standardized dataset with verified ground truths, an\nintegrated evaluation environment, and a public leaderboard, enabling\nreproducible and transparent comparisons across diverse approaches. Our\nextensive experiments reveal that while AL methods excel in efficiently\ncounting subgraphs on very large graphs, they struggle with complex patterns\n(e.g., those exceeding six nodes). In contrast, ML methods are capable of\nhandling larger patterns but demand massive graph data inputs and often yield\nsuboptimal accuracy on small, dense graphs. These insights not only highlight\nthe unique strengths and limitations of each approach but also pave the way for\nfuture advancements in subgraph counting techniques. Overall, BEACON represents\na significant step towards unifying and accelerating research in subgraph\ncounting, encouraging innovative solutions and fostering a deeper understanding\nof the trade-offs between algorithmic and machine learning paradigms.",
      "tldr_zh": "这篇论文介绍了 BEACON，一个全面基准，用于评估子图计数（subgraph counting）算法（AL）和机器学习（ML）方法的效率与准确性，旨在解决现有方法缺乏统一框架、标准化数据集和可访问真实数据的问题。BEACON 提供验证的真实数据集、集成评估环境和公共排行榜，支持可重复的跨方法比较。实验结果显示，AL 方法在大型图上表现出色，但处理复杂模式（如超过六节点的子图）时存在困难，而 ML 方法能应对更大模式却需大量数据输入，并在小密集图上准确性较低。这些发现揭示了各方法的优势与局限性，推动子图计数领域的创新和更深入的权衡分析。",
      "categories": [
        "cs.DS",
        "cs.AI",
        "cs.DB",
        "cs.SI"
      ],
      "primary_category": "cs.DS",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10948v1",
      "published_date": "2025-04-15 07:53:47 UTC",
      "updated_date": "2025-04-15 07:53:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:23:21.380064"
    },
    {
      "arxiv_id": "2504.10936v1",
      "title": "Can LLMs Leverage Observational Data? Towards Data-Driven Causal Discovery with LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Yuni Susanti",
        "Michael Färber"
      ],
      "abstract": "Causal discovery traditionally relies on statistical methods applied to\nobservational data, often requiring large datasets and assumptions about\nunderlying causal structures. Recent advancements in Large Language Models\n(LLMs) have introduced new possibilities for causal discovery by providing\ndomain expert knowledge. However, it remains unclear whether LLMs can\neffectively process observational data for causal discovery. In this work, we\nexplore the potential of LLMs for data-driven causal discovery by integrating\nobservational data for LLM-based reasoning. Specifically, we examine whether\nLLMs can effectively utilize observational data through two prompting\nstrategies: pairwise prompting and breadth first search (BFS)-based prompting.\nIn both approaches, we incorporate the observational data directly into the\nprompt to assess LLMs' ability to infer causal relationships from such data.\nExperiments on benchmark datasets show that incorporating observational data\nenhances causal discovery, boosting F1 scores by up to 0.11 point using both\npairwise and BFS LLM-based prompting, while outperforming traditional\nstatistical causal discovery baseline by up to 0.52 points. Our findings\nhighlight the potential and limitations of LLMs for data-driven causal\ndiscovery, demonstrating their ability to move beyond textual metadata and\neffectively interpret and utilize observational data for more informed causal\nreasoning. Our studies lays the groundwork for future advancements toward fully\nLLM-driven causal discovery.",
      "tldr_zh": "该研究探讨了大型语言模型（LLMs）是否能有效利用观察数据进行数据驱动的因果发现（causal discovery），以弥补传统统计方法对大型数据集和假设的依赖。研究引入了两种提示策略：pairwise prompting 和 BFS-based prompting，将观察数据直接整合到提示中，以评估 LLMs 推断因果关系的性能。在基准数据集上的实验显示，这种整合提升了 F1 scores 最高 0.11 分，并比传统统计基线高出最高 0.52 分。这些发现突显了 LLMs 的潜力，能够超越文本元数据并有效解释观察数据，从而为未来的 LLM-driven causal discovery 奠定基础。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10936v1",
      "published_date": "2025-04-15 07:32:35 UTC",
      "updated_date": "2025-04-15 07:32:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:23:32.262225"
    },
    {
      "arxiv_id": "2504.10925v2",
      "title": "Transfer Learning for Temporal Link Prediction",
      "title_zh": "用于时序链接预测的迁移学习",
      "authors": [
        "Ayan Chatterjee",
        "Barbara Ikica",
        "Babak Ravandi",
        "John Palowitch"
      ],
      "abstract": "Link prediction on graphs has applications spanning from recommender systems\nto drug discovery. Temporal link prediction (TLP) refers to predicting future\nlinks in a temporally evolving graph and adds additional complexity related to\nthe dynamic nature of graphs. State-of-the-art TLP models incorporate memory\nmodules alongside graph neural networks to learn both the temporal mechanisms\nof incoming nodes and the evolving graph topology. However, memory modules only\nstore information about nodes seen at train time, and hence such models cannot\nbe directly transferred to entirely new graphs at test time and deployment. In\nthis work, we study a new transfer learning task for temporal link prediction,\nand develop transfer-effective methods for memory-laden models. Specifically,\nmotivated by work showing the informativeness of structural signals for the TLP\ntask, we augment a structural mapping module to the existing TLP model\narchitectures, which learns a mapping from graph structural (topological)\nfeatures to memory embeddings. Our work paves the way for a memory-free\nfoundation model for TLP.",
      "tldr_zh": "本文探讨了Transfer Learning在Temporal Link Prediction（TLP）中的应用，旨在解决现有模型因依赖记忆模块而无法直接转移到新图的问题。研究团队通过添加一个结构映射模块，将图的拓扑特征映射到记忆嵌入，从而增强TLP模型的转移有效性。最终，这为开发无记忆的TLP基础模型铺平了道路，促进了模型在动态图上的泛化应用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "14 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.10925v2",
      "published_date": "2025-04-15 07:12:00 UTC",
      "updated_date": "2025-04-17 04:59:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:23:43.908220"
    },
    {
      "arxiv_id": "2504.10917v1",
      "title": "Towards A Universal Graph Structural Encoder",
      "title_zh": "翻译失败",
      "authors": [
        "Jialin Chen",
        "Haolan Zuo",
        "Haoyu Peter Wang",
        "Siqi Miao",
        "Pan Li",
        "Rex Ying"
      ],
      "abstract": "Recent advancements in large-scale pre-training have shown the potential to\nlearn generalizable representations for downstream tasks. In the graph domain,\nhowever, capturing and transferring structural information across different\ngraph domains remains challenging, primarily due to the inherent differences in\ntopological patterns across various contexts. Additionally, most existing\nmodels struggle to capture the complexity of rich graph structures, leading to\ninadequate exploration of the embedding space. To address these challenges, we\npropose GFSE, a universal graph structural encoder designed to capture\ntransferable structural patterns across diverse domains such as molecular\ngraphs, social networks, and citation networks. GFSE is the first cross-domain\ngraph structural encoder pre-trained with multiple self-supervised learning\nobjectives. Built on a Graph Transformer, GFSE incorporates attention\nmechanisms informed by graph inductive bias, enabling it to encode intricate\nmulti-level and fine-grained topological features. The pre-trained GFSE\nproduces generic and theoretically expressive positional and structural\nencoding for graphs, which can be seamlessly integrated with various downstream\ngraph feature encoders, including graph neural networks for vectorized features\nand Large Language Models for text-attributed graphs. Comprehensive experiments\non synthetic and real-world datasets demonstrate GFSE's capability to\nsignificantly enhance the model's performance while requiring substantially\nless task-specific fine-tuning. Notably, GFSE achieves state-of-the-art\nperformance in 81.6% evaluated cases, spanning diverse graph models and\ndatasets, highlighting its potential as a powerful and versatile encoder for\ngraph-structured data.",
      "tldr_zh": "该研究针对图领域中结构信息捕捉和转移的挑战，提出了一种通用图结构编码器GFSE，用于处理不同图域（如分子图、社会网络和引用网络）的拓扑模式差异。GFSE基于Graph Transformer架构，结合受图归纳偏差影响的注意力机制，并通过多个自监督学习目标进行跨域预训练，以编码复杂的多级和细粒度拓扑特征。预训练后的GFSE生成通用的位置和结构编码，可无缝整合到下游模型中，如Graph Neural Networks或Large Language Models，从而减少任务特定微调需求。在合成和真实数据集上的全面实验中，GFSE在81.6%的评估案例中实现最先进性能，显著提升了模型表现。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10917v1",
      "published_date": "2025-04-15 06:57:26 UTC",
      "updated_date": "2025-04-15 06:57:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:23:56.628106"
    },
    {
      "arxiv_id": "2504.10915v2",
      "title": "LOKA Protocol: A Decentralized Framework for Trustworthy and Ethical AI Agent Ecosystems",
      "title_zh": "LOKA Protocol：一个去中心化框架，用于可信赖且合乎伦理的AI代理生态系统",
      "authors": [
        "Rajesh Ranjan",
        "Shailja Gupta",
        "Surya Narayan Singh"
      ],
      "abstract": "The rise of autonomous AI agents, capable of perceiving, reasoning, and\nacting independently, signals a profound shift in how digital ecosystems\noperate, govern, and evolve. As these agents proliferate beyond centralized\ninfrastructures, they expose foundational gaps in identity, accountability, and\nethical alignment. Three critical questions emerge: Identity: Who or what is\nthe agent? Accountability: Can its actions be verified, audited, and trusted?\nEthical Consensus: Can autonomous systems reliably align with human values and\nprevent harmful emergent behaviors? We present the novel LOKA Protocol (Layered\nOrchestration for Knowledgeful Agents), a unified, systems-level architecture\nfor building ethically governed, interoperable AI agent ecosystems. LOKA\nintroduces a proposed Universal Agent Identity Layer (UAIL) for decentralized,\nverifiable identity; intent-centric communication protocols for semantic\ncoordination across diverse agents; and a Decentralized Ethical Consensus\nProtocol (DECP) that could enable agents to make context-aware decisions\ngrounded in shared ethical baselines. Anchored in emerging standards such as\nDecentralized Identifiers (DIDs), Verifiable Credentials (VCs), and\npost-quantum cryptography, LOKA proposes a scalable, future-resilient blueprint\nfor multi-agent AI governance. By embedding identity, trust, and ethics into\nthe protocol layer itself, LOKA proposes the foundation for a new era of\nresponsible, transparent, and autonomous AI ecosystems operating across digital\nand physical domains.",
      "tldr_zh": "本研究探讨了自治AI代理的兴起所带来的身份、责任和伦理共识挑战，并提出LOKA Protocol（Layered Orchestration for Knowledgeful Agents）作为一种统一的去中心化架构，用于构建可信赖且伦理治理的AI代理生态系统。LOKA引入Universal Agent Identity Layer (UAIL)实现去中心化可验证身份、intent-centric通信协议促进代理间的语义协调，以及Decentralized Ethical Consensus Protocol (DECP)确保代理基于共享伦理基线进行上下文感知决策。该框架依托Decentralized Identifiers (DIDs)、Verifiable Credentials (VCs)和后量子密码学等标准，提供一个可扩展的蓝图，推动负责任、透明的AI生态系统在数字和物理领域的发展。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.MA",
      "comment": "4 Figures, 1 Table",
      "pdf_url": "http://arxiv.org/pdf/2504.10915v2",
      "published_date": "2025-04-15 06:51:35 UTC",
      "updated_date": "2025-04-22 02:59:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:24:08.659734"
    },
    {
      "arxiv_id": "2504.10903v1",
      "title": "Efficient Reasoning Models: A Survey",
      "title_zh": "高效推理模型：综述",
      "authors": [
        "Sicheng Feng",
        "Gongfan Fang",
        "Xinyin Ma",
        "Xinchao Wang"
      ],
      "abstract": "Reasoning models have demonstrated remarkable progress in solving complex and\nlogic-intensive tasks by generating extended Chain-of-Thoughts (CoTs) prior to\narriving at a final answer. Yet, the emergence of this \"slow-thinking\"\nparadigm, with numerous tokens generated in sequence, inevitably introduces\nsubstantial computational overhead. To this end, it highlights an urgent need\nfor effective acceleration. This survey aims to provide a comprehensive\noverview of recent advances in efficient reasoning. It categorizes existing\nworks into three key directions: (1) shorter - compressing lengthy CoTs into\nconcise yet effective reasoning chains; (2) smaller - developing compact\nlanguage models with strong reasoning capabilities through techniques such as\nknowledge distillation, other model compression techniques, and reinforcement\nlearning; and (3) faster - designing efficient decoding strategies to\naccelerate inference. A curated collection of papers discussed in this survey\nis available in our GitHub repository.",
      "tldr_zh": "这篇调查论文探讨了推理模型在生成Chain-of-Thought (CoT)时面临的计算开销问题，强调了加速“慢思考”范式的必要性。论文将现有高效推理方法分为三类：(1) shorter - 通过压缩CoT生成更简洁的推理链；(2) smaller - 利用知识蒸馏(knowledge distillation)、模型压缩和其他技术开发小型化模型；(3) faster - 设计高效解码策略加速推理过程。通过综合概述这些进展，论文为优化推理模型提供了宝贵见解，并提供了一个GitHub仓库收集相关论文。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10903v1",
      "published_date": "2025-04-15 06:28:00 UTC",
      "updated_date": "2025-04-15 06:28:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:24:19.905083"
    },
    {
      "arxiv_id": "2504.10900v1",
      "title": "Bridging Distribution Gaps in Time Series Foundation Model Pretraining with Prototype-Guided Normalization",
      "title_zh": "翻译失败",
      "authors": [
        "Peiliang Gong",
        "Emadeldeen Eldele",
        "Min Wu",
        "Zhenghua Chen",
        "Xiaoli Li",
        "Daoqiang Zhang"
      ],
      "abstract": "Foundation models have achieved remarkable success across diverse\nmachine-learning domains through large-scale pretraining on large, diverse\ndatasets. However, pretraining on such datasets introduces significant\nchallenges due to substantial mismatches in data distributions, a problem\nparticularly pronounced with time series data. In this paper, we tackle this\nissue by proposing a domain-aware adaptive normalization strategy within the\nTransformer architecture. Specifically, we replace the traditional LayerNorm\nwith a prototype-guided dynamic normalization mechanism (ProtoNorm), where\nlearned prototypes encapsulate distinct data distributions, and\nsample-to-prototype affinity determines the appropriate normalization layer.\nThis mechanism effectively captures the heterogeneity of time series\ncharacteristics, aligning pretrained representations with downstream tasks.\nThrough comprehensive empirical evaluation, we demonstrate that our method\nsignificantly outperforms conventional pretraining techniques across both\nclassification and forecasting tasks, while effectively mitigating the adverse\neffects of distribution shifts during pretraining. Incorporating ProtoNorm is\nas simple as replacing a single line of code. Extensive experiments on diverse\nreal-world time series benchmarks validate the robustness and generalizability\nof our approach, advancing the development of more versatile time series\nfoundation models.",
      "tldr_zh": "该论文针对时间序列基础模型预训练中数据分布不匹配的问题，提出了一种领域感知的自适应归一化策略，即在Transformer架构中用原型引导的动态归一化机制(ProtoNorm)替换传统的LayerNorm。ProtoNorm通过学习的原型封装不同数据分布，并根据样本到原型的亲和力选择合适的归一化层，从而有效捕捉时间序列的异质性和与下游任务的表示对齐。实验结果显示，该方法在分类和预测任务上显著优于传统预训练技术，并缓解了分布偏移的负面影响；在各种真实世界基准上验证了其鲁棒性和泛化性，同时实现简单，只需替换一行代码。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10900v1",
      "published_date": "2025-04-15 06:23:00 UTC",
      "updated_date": "2025-04-15 06:23:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:24:31.588436"
    },
    {
      "arxiv_id": "2504.10898v1",
      "title": "Xpose: Bi-directional Engineering for Hidden Query Extraction",
      "title_zh": "Xpose：用于隐藏查询提取的双向工程",
      "authors": [
        "Ahana Pradhan",
        "Jayant Haritsa"
      ],
      "abstract": "Query reverse engineering (QRE) aims to synthesize a SQL query to connect a\ngiven database and result instance. A recent variation of QRE is where an\nadditional input, an opaque executable containing a ground-truth query, is\nprovided, and the goal is to non-invasively extract this specific query through\nonly input-output examples. This variant, called Hidden Query Extraction (HQE),\nhas a spectrum of industrial use-cases including query recovery, database\nsecurity, and vendor migration. The reverse engineering (RE) tools developed\nfor HQE, which are based on database mutation and generation techniques, can\nonly extract flat queries with key-based equi joins and conjunctive arithmetic\nfilter predicates, making them limited wrt both query structure and query\noperators. In this paper, we present Xpose, a HQE solution that elevates the\nextraction scope to realistic complex queries, such as those found in the TPCH\nbenchmark. A two-pronged approach is taken: (1) The existing RE scope is\nsubstantially extended to incorporate union connectors, algebraic filter\npredicates, and disjunctions for both values and predicates. (2) The predictive\npower of LLMs is leveraged to convert business descriptions of the opaque\napplication into extraction guidance, representing ``forward engineering\" (FE).\nThe FE module recognizes common constructs, such as nesting of sub-queries,\nouter joins, and scalar functions. In essence, FE establishes the broad query\ncontours, while RE fleshes out the fine-grained details. We have evaluated\nXpose on (a) E-TPCH, a query suite comprising the complete TPCH benchmark\nextended with queries featuring unions, diverse join types, and sub-queries;\nand (b) the real-world STACK benchmark. The experimental results demonstrate\nthat its bi-directional engineering approach accurately extracts these complex\nqueries, representing a significant step forward with regard to HQE coverage.",
      "tldr_zh": "这篇论文提出Xpose，一种双向工程方法，用于Hidden Query Extraction (HQE)，旨在从不透明可执行文件中提取隐藏的SQL查询，扩展了现有工具的局限性。Xpose通过扩展Reverse Engineering (RE)来支持更复杂的查询元素，如union connectors、algebraic filter predicates和disjunctions，同时利用Large Language Models (LLMs)进行Forward Engineering (FE)，将业务描述转化为提取指导，以识别子查询、外连接和标量函数等结构。实验结果显示，Xpose在E-TPCH基准测试和真实世界STACK基准上准确提取复杂查询，显著提升了HQE的覆盖范围和实用性。",
      "categories": [
        "cs.DB",
        "cs.AI",
        "H.2.8"
      ],
      "primary_category": "cs.DB",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10898v1",
      "published_date": "2025-04-15 06:17:58 UTC",
      "updated_date": "2025-04-15 06:17:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:24:44.404991"
    },
    {
      "arxiv_id": "2504.10893v1",
      "title": "ARise: Towards Knowledge-Augmented Reasoning via Risk-Adaptive Search",
      "title_zh": "翻译失败",
      "authors": [
        "Yize Zhang",
        "Tianshu Wang",
        "Sirui Chen",
        "Kun Wang",
        "Xingyu Zeng",
        "Hongyu Lin",
        "Xianpei Han",
        "Le Sun",
        "Chaochao Lu"
      ],
      "abstract": "Large language models (LLMs) have demonstrated impressive capabilities and\nare receiving increasing attention to enhance their reasoning through scaling\ntest--time compute. However, their application in open--ended,\nknowledge--intensive, complex reasoning scenarios is still limited.\nReasoning--oriented methods struggle to generalize to open--ended scenarios due\nto implicit assumptions of complete world knowledge. Meanwhile,\nknowledge--augmented reasoning (KAR) methods fail to address two core\nchallenges: 1) error propagation, where errors in early steps cascade through\nthe chain, and 2) verification bottleneck, where the explore--exploit tradeoff\narises in multi--branch decision processes. To overcome these limitations, we\nintroduce ARise, a novel framework that integrates risk assessment of\nintermediate reasoning states with dynamic retrieval--augmented generation\n(RAG) within a Monte Carlo tree search paradigm. This approach enables\neffective construction and optimization of reasoning plans across multiple\nmaintained hypothesis branches. Experimental results show that ARise\nsignificantly outperforms the state--of--the--art KAR methods by up to 23.10%,\nand the latest RAG-equipped large reasoning models by up to 25.37%.",
      "tldr_zh": "该论文探讨了大型语言模型 (LLMs) 在开放式、知识密集型复杂推理场景中的局限性，包括现有推理方法对完整世界知识的假设以及知识增强推理 (KAR) 方法面临的错误传播和验证瓶颈问题。为解决这些挑战，研究提出 ARise 框架，该框架整合风险评估、动态检索增强生成 (RAG) 和 Monte Carlo tree search 范式，以构建和优化多分支推理计划。实验结果显示，ARise 相较于最先进的 KAR 方法提升高达 23.10%，并比最新 RAG 配备的模型提升高达 25.37%，显著提高了推理性能。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Project homepage: https://opencausalab.github.io/ARise",
      "pdf_url": "http://arxiv.org/pdf/2504.10893v1",
      "published_date": "2025-04-15 06:06:50 UTC",
      "updated_date": "2025-04-15 06:06:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:24:54.997099"
    },
    {
      "arxiv_id": "2504.10888v1",
      "title": "CDUPatch: Color-Driven Universal Adversarial Patch Attack for Dual-Modal Visible-Infrared Detectors",
      "title_zh": "CDUPatch：颜色驱动的通用对抗性补丁攻击针对双模态可见光-红外检测器",
      "authors": [
        "Jiahuan Long",
        "Wen Yao",
        "Tingsong Jiang",
        "Chao Ma"
      ],
      "abstract": "Adversarial patches are widely used to evaluate the robustness of object\ndetection systems in real-world scenarios. These patches were initially\ndesigned to deceive single-modal detectors (e.g., visible or infrared) and have\nrecently been extended to target visible-infrared dual-modal detectors.\nHowever, existing dual-modal adversarial patch attacks have limited attack\neffectiveness across diverse physical scenarios. To address this, we propose\nCDUPatch, a universal cross-modal patch attack against visible-infrared object\ndetectors across scales, views, and scenarios. Specifically, we observe that\ncolor variations lead to different levels of thermal absorption, resulting in\ntemperature differences in infrared imaging. Leveraging this property, we\npropose an RGB-to-infrared adapter that maps RGB patches to infrared patches,\nenabling unified optimization of cross-modal patches. By learning an optimal\ncolor distribution on the adversarial patch, we can manipulate its thermal\nresponse and generate an adversarial infrared texture. Additionally, we\nintroduce a multi-scale clipping strategy and construct a new visible-infrared\ndataset, MSDrone, which contains aerial vehicle images in varying scales and\nperspectives. These data augmentation strategies enhance the robustness of our\npatch in real-world conditions. Experiments on four benchmark datasets (e.g.,\nDroneVehicle, LLVIP, VisDrone, MSDrone) show that our method outperforms\nexisting patch attacks in the digital domain. Extensive physical tests further\nconfirm strong transferability across scales, views, and scenarios.",
      "tldr_zh": "该研究提出CDUPatch，一种基于颜色的通用对抗性补丁攻击，针对可见光-红外双模态检测器，旨在提升攻击在不同物理场景下的有效性。具体而言，CDUPatch利用颜色变化导致的热吸收差异，开发了RGB-to-infrared adapter来映射RGB补丁到红外补丁，并通过学习最佳颜色分布优化跨模态补丁的热响应。论文还引入多尺度裁剪策略并构建了新数据集MSDrone，以增强补丁在真实世界的鲁棒性。实验结果显示，CDUPatch在四个基准数据集（包括DroneVehicle、LLVIP、VisDrone和MSDrone）上优于现有方法，并在物理测试中证明了其在不同尺度、视角和场景下的强转移性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10888v1",
      "published_date": "2025-04-15 05:46:00 UTC",
      "updated_date": "2025-04-15 05:46:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:25:07.754953"
    },
    {
      "arxiv_id": "2504.10886v1",
      "title": "Exploring Persona-dependent LLM Alignment for the Moral Machine Experiment",
      "title_zh": "翻译失败",
      "authors": [
        "Jiseon Kim",
        "Jea Kwon",
        "Luiz Felipe Vecchietti",
        "Alice Oh",
        "Meeyoung Cha"
      ],
      "abstract": "Deploying large language models (LLMs) with agency in real-world applications\nraises critical questions about how these models will behave. In particular,\nhow will their decisions align with humans when faced with moral dilemmas? This\nstudy examines the alignment between LLM-driven decisions and human judgment in\nvarious contexts of the moral machine experiment, including personas reflecting\ndifferent sociodemographics. We find that the moral decisions of LLMs vary\nsubstantially by persona, showing greater shifts in moral decisions for\ncritical tasks than humans. Our data also indicate an interesting partisan\nsorting phenomenon, where political persona predominates the direction and\ndegree of LLM decisions. We discuss the ethical implications and risks\nassociated with deploying these models in applications that involve moral\ndecisions.",
      "tldr_zh": "本研究探讨了大型语言模型（LLM）在道德困境中的决策如何与人类判断对齐，特别是受不同社会人口统计学角色（persona）的影响。研究利用道德机器实验（Moral Machine Experiment）的各种情境，发现LLM的道德决策会根据角色显著变化，且在关键任务中比人类表现出更大的波动，同时观察到政治角色主导的党派分化现象。这些发现突显了在涉及道德决策的应用中部署LLM的伦理风险和潜在问题。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CY",
      "comment": "Accepted to ICLR 2025 Workshop - BiAlign (Bidirectional Human-AI\n  Alignment)",
      "pdf_url": "http://arxiv.org/pdf/2504.10886v1",
      "published_date": "2025-04-15 05:29:51 UTC",
      "updated_date": "2025-04-15 05:29:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:25:19.453554"
    },
    {
      "arxiv_id": "2504.10885v1",
      "title": "PuzzleBench: A Fully Dynamic Evaluation Framework for Large Multimodal Models on Puzzle Solving",
      "title_zh": "翻译失败",
      "authors": [
        "Zeyu Zhang",
        "Zijian Chen",
        "Zicheng Zhang",
        "Yuze Sun",
        "Yuan Tian",
        "Ziheng Jia",
        "Chunyi Li",
        "Xiaohong Liu",
        "Xiongkuo Min",
        "Guangtao Zhai"
      ],
      "abstract": "Large Multimodal Models (LMMs) have demonstrated impressive capabilities\nacross a wide range of multimodal tasks, achieving ever-increasing performance\non various evaluation benchmarks. However, existing benchmarks are typically\nstatic and often overlap with pre-training datasets, leading to fixed\ncomplexity constraints and substantial data contamination issues. Meanwhile,\nmanually annotated datasets are labor-intensive, time-consuming, and subject to\nhuman bias and inconsistency, leading to reliability and reproducibility\nissues. To address these problems, we propose a fully dynamic multimodal\nevaluation framework, named Open-ended Visual Puzzle Generation (OVPG), which\naims to generate fresh, diverse, and verifiable evaluation data automatically\nin puzzle-solving tasks. Specifically, the OVPG pipeline consists of a raw\nmaterial sampling module, a visual content generation module, and a puzzle rule\ndesign module, which ensures that each evaluation instance is primitive, highly\nrandomized, and uniquely solvable, enabling continual adaptation to the\nevolving capabilities of LMMs. Built upon OVPG, we construct PuzzleBench, a\ndynamic and scalable benchmark comprising 11,840 VQA samples. It features six\ncarefully designed puzzle tasks targeting three core LMM competencies, visual\nrecognition, logical reasoning, and context understanding. PuzzleBench differs\nfrom static benchmarks that quickly become outdated. It enables ongoing dataset\nrefreshing through OVPG and a rich set of open-ended puzzle designs, allowing\nseamless adaptation to the evolving capabilities of LMMs.",
      "tldr_zh": "该论文提出了一种动态评估框架 Open-ended Visual Puzzle Generation (OVPG)，旨在解决 Large Multimodal Models (LMMs) 在谜题解决任务中面临的基准测试静态性、数据污染和手动标注问题。OVPG 通过原始材料采样、视觉内容生成和谜题规则设计模块自动生成新鲜、多样且可验证的评估数据，确保每个实例高度随机且唯一可解。基于此框架，构建了 PuzzleBench 基准，包含 11,840 个 Visual Question Answering (VQA) 样本，涵盖六种谜题任务，针对 LMMs 的核心能力：视觉识别、逻辑推理和上下文理解。PuzzleBench 的动态特性允许持续数据刷新和适应 LMMs 的演变，提升基准的可扩展性和可靠性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10885v1",
      "published_date": "2025-04-15 05:29:31 UTC",
      "updated_date": "2025-04-15 05:29:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:25:32.538428"
    },
    {
      "arxiv_id": "2504.10883v1",
      "title": "Bringing together invertible UNets with invertible attention modules for memory-efficient diffusion models",
      "title_zh": "将可逆UNets与可逆注意力模块结合，用于内存高效的扩散模型",
      "authors": [
        "Karan Jain",
        "Mohammad Nayeem Teli"
      ],
      "abstract": "Diffusion models have recently gained state of the art performance on many\nimage generation tasks. However, most models require significant computational\nresources to achieve this. This becomes apparent in the application of medical\nimage synthesis due to the 3D nature of medical datasets like CT-scans, MRIs,\nelectron microscope, etc. In this paper we propose a novel architecture for a\nsingle GPU memory-efficient training for diffusion models for high dimensional\nmedical datasets. The proposed model is built by using an invertible UNet\narchitecture with invertible attention modules. This leads to the following two\ncontributions: 1. denoising diffusion models and thus enabling memory usage to\nbe independent of the dimensionality of the dataset, and 2. reducing the energy\nusage during training. While this new model can be applied to a multitude of\nimage generation tasks, we showcase its memory-efficiency on the 3D BraTS2020\ndataset leading to up to 15\\% decrease in peak memory consumption during\ntraining with comparable results to SOTA while maintaining the image quality.",
      "tldr_zh": "这篇论文提出了一种结合可逆 UNet 和可逆注意力模块的创新架构，用于单 GPU 内存高效训练扩散模型，旨在解决高维医疗图像数据集（如 CT 和 MRI）在生成任务中的计算资源问题。该架构使去噪扩散模型的内存使用独立于数据集维度，并显著减少训练过程中的能源消耗。在 3D BraTS2020 数据集上的实验表明，该方法在保持图像质量与最先进技术相当的同时，使峰值内存消耗降低高达 15%。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10883v1",
      "published_date": "2025-04-15 05:26:42 UTC",
      "updated_date": "2025-04-15 05:26:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:25:44.640533"
    },
    {
      "arxiv_id": "2504.10878v1",
      "title": "Large Language Model-Informed Feature Discovery Improves Prediction and Interpretation of Credibility Perceptions of Visual Content",
      "title_zh": "大语言模型指导的特征发现改善了视觉内容可信度感知的预测和解释",
      "authors": [
        "Yilang Peng",
        "Sijia Qian",
        "Yingdan Lu",
        "Cuihua Shen"
      ],
      "abstract": "In today's visually dominated social media landscape, predicting the\nperceived credibility of visual content and understanding what drives human\njudgment are crucial for countering misinformation. However, these tasks are\nchallenging due to the diversity and richness of visual features. We introduce\na Large Language Model (LLM)-informed feature discovery framework that\nleverages multimodal LLMs, such as GPT-4o, to evaluate content credibility and\nexplain its reasoning. We extract and quantify interpretable features using\ntargeted prompts and integrate them into machine learning models to improve\ncredibility predictions. We tested this approach on 4,191 visual social media\nposts across eight topics in science, health, and politics, using credibility\nratings from 5,355 crowdsourced workers. Our method outperformed zero-shot\nGPT-based predictions by 13 percent in R2, and revealed key features like\ninformation concreteness and image format. We discuss the implications for\nmisinformation mitigation, visual credibility, and the role of LLMs in social\nscience.",
      "tldr_zh": "该研究提出了一种基于 Large Language Model-Informed 的特征发现框架，用于提升视觉内容信誉感知的预测和解释，以对抗社交媒体虚假信息。框架利用 multimodal LLMs 如 GPT-4o 通过针对性提示提取和量化可解释特征（如 information concreteness 和 image format），并将其整合到机器学习模型中进行优化。在对 4,191 个涵盖科学、健康和政治主题的视觉社交媒体帖子进行测试时，该方法在 R2 上比零样本 GPT 预测提高了 13%。这项工作揭示了关键视觉特征的作用，并为虚假信息缓解、视觉信誉评估以及 LLMs 在社会科学中的应用提供了重要启示。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "I.4.9; J.4"
      ],
      "primary_category": "cs.CV",
      "comment": "26 pages",
      "pdf_url": "http://arxiv.org/pdf/2504.10878v1",
      "published_date": "2025-04-15 05:11:40 UTC",
      "updated_date": "2025-04-15 05:11:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:25:56.575139"
    },
    {
      "arxiv_id": "2504.10873v1",
      "title": "Can Vision-Language Models Understand and Interpret Dynamic Gestures from Pedestrians? Pilot Datasets and Exploration Towards Instructive Nonverbal Commands for Cooperative Autonomous Vehicles",
      "title_zh": "翻译失败",
      "authors": [
        "Tonko E. W. Bossen",
        "Andreas Møgelmose",
        "Ross Greer"
      ],
      "abstract": "In autonomous driving, it is crucial to correctly interpret traffic gestures\n(TGs), such as those of an authority figure providing orders or instructions,\nor a pedestrian signaling the driver, to ensure a safe and pleasant traffic\nenvironment for all road users. This study investigates the capabilities of\nstate-of-the-art vision-language models (VLMs) in zero-shot interpretation,\nfocusing on their ability to caption and classify human gestures in traffic\ncontexts. We create and publicly share two custom datasets with varying formal\nand informal TGs, such as 'Stop', 'Reverse', 'Hail', etc. The datasets are\n\"Acted TG (ATG)\" and \"Instructive TG In-The-Wild (ITGI)\". They are annotated\nwith natural language, describing the pedestrian's body position and gesture.\nWe evaluate models using three methods utilizing expert-generated captions as\nbaseline and control: (1) caption similarity, (2) gesture classification, and\n(3) pose sequence reconstruction similarity. Results show that current VLMs\nstruggle with gesture understanding: sentence similarity averages below 0.59,\nand classification F1 scores reach only 0.14-0.39, well below the expert\nbaseline of 0.70. While pose reconstruction shows potential, it requires more\ndata and refined metrics to be reliable. Our findings reveal that although some\nSOTA VLMs can interpret zero-shot human traffic gestures, none are accurate and\nrobust enough to be trustworthy, emphasizing the need for further research in\nthis domain.",
      "tldr_zh": "这篇论文探讨了视觉语言模型（VLMs）是否能理解和解释行人的动态手势，以支持合作式自动驾驶车辆的安全性。研究者创建并公开分享了两个自定义数据集（Acted TG (ATG) 和 Instructive TG In-The-Wild (ITGI)），这些数据集标注了行人的身体位置和手势，并使用零-shot 方法评估 VLMs 的描述相似性、手势分类和姿势序列重建性能。结果显示，VLMs 在手势理解上表现不佳，句子相似度平均低于 0.59，分类 F1 scores 仅为 0.14-0.39，而专家基准为 0.70，强调了需要进一步研究以实现可靠的非语言指令解释。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10873v1",
      "published_date": "2025-04-15 05:04:25 UTC",
      "updated_date": "2025-04-15 05:04:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:26:09.090123"
    },
    {
      "arxiv_id": "2504.10865v1",
      "title": "Understanding the theoretical properties of projected Bellman equation, linear Q-learning, and approximate value iteration",
      "title_zh": "翻译失败",
      "authors": [
        "Han-Dong Lim",
        "Donghwan Lee"
      ],
      "abstract": "In this paper, we study the theoretical properties of the projected Bellman\nequation (PBE) and two algorithms to solve this equation: linear Q-learning and\napproximate value iteration (AVI). We consider two sufficient conditions for\nthe existence of a solution to PBE : strictly negatively row dominating\ndiagonal (SNRDD) assumption and a condition motivated by the convergence of\nAVI. The SNRDD assumption also ensures the convergence of linear Q-learning,\nand its relationship with the convergence of AVI is examined. Lastly, several\ninteresting observations on the solution of PBE are provided when using\n$\\epsilon$-greedy policy.",
      "tldr_zh": "这篇论文探讨了 projected Bellman equation (PBE) 的理论性质，以及 linear Q-learning 和 approximate value iteration (AVI) 算法的特性。论文提出了两个 PBE 存在解的充分条件：strictly negatively row dominating diagonal (SNRDD) 假设，以及一个与 AVI 收敛相关的条件，其中 SNRDD 假设确保了 linear Q-learning 的收敛，并分析了它与 AVI 收敛的关系。最后，论文提供了在使用 ε-greedy policy 时 PBE 解的若干有趣观察，为强化学习算法的理论基础提供了新见解。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Initial submission",
      "pdf_url": "http://arxiv.org/pdf/2504.10865v1",
      "published_date": "2025-04-15 04:56:33 UTC",
      "updated_date": "2025-04-15 04:56:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:26:20.295692"
    },
    {
      "arxiv_id": "2504.10845v1",
      "title": "Moving Beyond Next-Token Prediction: Transformers are Context-Sensitive Language Generators",
      "title_zh": "超越下一个标记预测：Transformer 是上下文敏感语言生成器",
      "authors": [
        "Phill Kyu Rhee"
      ],
      "abstract": "Large Language Models (LLMs), powered by Transformers, have demonstrated\nhuman-like intelligence capabilities, yet their underlying mechanisms remain\npoorly understood. This paper presents a novel framework for interpreting LLMs\nas probabilistic left context-sensitive languages (CSLs) generators. We\nhypothesize that Transformers can be effectively decomposed into three\nfundamental components: context windows, attention mechanisms, and\nautoregressive generation frameworks. This decomposition allows for the\ndevelopment of more flexible and interpretable computational models, moving\nbeyond the traditional view of attention and autoregression as inseparable\nprocesses. We argue that next-token predictions can be understood as\nprobabilistic, dynamic approximations of left CSL production rules, providing\nan intuitive explanation for how simple token predictions can yield human-like\nintelligence outputs. Given that all CSLs are left context-sensitive\n(Penttonen, 1974), we conclude that Transformers stochastically approximate\nCSLs, which are widely recognized as models of human-like intelligence. This\ninterpretation bridges the gap between Formal Language Theory and the observed\ngenerative power of Transformers, laying a foundation for future advancements\nin generative AI theory and applications. Our novel perspective on Transformer\narchitectures will foster a deeper understanding of LLMs and their future\npotentials.",
      "tldr_zh": "本论文提出一个新框架，将大型语言模型 (LLMs) 解释为概率左上下文敏感语言 (CSLs) 生成器，超越了传统的下一个标记预测 (next-token prediction) 范式。研究假设 Transformers 可以分解为三个核心组件：上下文窗口、注意力机制和自回归生成框架，从而开发更灵活且可解释的计算模型。作者认为，next-token prediction 可以视为对左 CSL 生产规则的概率动态近似，这解释了简单标记预测如何产生类似人类智能的输出。最终，该框架桥接了形式语言理论与 Transformers 的生成能力，为生成式 AI 的理论和应用奠定基础。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "11 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.10845v1",
      "published_date": "2025-04-15 04:06:27 UTC",
      "updated_date": "2025-04-15 04:06:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:26:30.918206"
    },
    {
      "arxiv_id": "2504.10839v1",
      "title": "Rethinking Theory of Mind Benchmarks for LLMs: Towards A User-Centered Perspective",
      "title_zh": "重新思考心智理论基准测试：朝向用户中心视角",
      "authors": [
        "Qiaosi Wang",
        "Xuhui Zhou",
        "Maarten Sap",
        "Jodi Forlizzi",
        "Hong Shen"
      ],
      "abstract": "The last couple of years have witnessed emerging research that appropriates\nTheory-of-Mind (ToM) tasks designed for humans to benchmark LLM's ToM\ncapabilities as an indication of LLM's social intelligence. However, this\napproach has a number of limitations. Drawing on existing psychology and AI\nliterature, we summarize the theoretical, methodological, and evaluation\nlimitations by pointing out that certain issues are inherently present in the\noriginal ToM tasks used to evaluate human's ToM, which continues to persist and\nexacerbated when appropriated to benchmark LLM's ToM. Taking a human-computer\ninteraction (HCI) perspective, these limitations prompt us to rethink the\ndefinition and criteria of ToM in ToM benchmarks in a more dynamic,\ninteractional approach that accounts for user preferences, needs, and\nexperiences with LLMs in such evaluations. We conclude by outlining potential\nopportunities and challenges towards this direction.",
      "tldr_zh": "这篇论文重新审视了使用 Theory of Mind (ToM) 任务评估大型语言模型 (LLMs) 的社会智能方法，指出现有基准存在理论、方法和评估局限性，这些问题源于原有人类 ToM 任务并在 LLMs 评估中被放大。\n作者从人机交互 (HCI) 视角出发，提出采用更动态、交互的方法重新定义 ToM 标准，强调考虑用户偏好、需求和体验。\n论文总结了这一用户中心方法的潜在机会和挑战，为未来 LLMs 的 ToM 评估提供新方向。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "7 pages, 1 figure, accepted to the HEAL@CHI 2025 Workshop",
      "pdf_url": "http://arxiv.org/pdf/2504.10839v1",
      "published_date": "2025-04-15 03:44:43 UTC",
      "updated_date": "2025-04-15 03:44:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:26:43.702777"
    },
    {
      "arxiv_id": "2504.10836v1",
      "title": "Uplink Assisted Joint Channel Estimation and CSI Feedback: An Approach Based on Deep Joint Source-Channel Coding",
      "title_zh": "翻译失败",
      "authors": [
        "Yiran Guo",
        "Wei Chen",
        "Bo Ai"
      ],
      "abstract": "In frequency division duplex (FDD) multiple-input multiple-output (MIMO)\nwireless communication systems, the acquisition of downlink channel state\ninformation (CSI) is essential for maximizing spatial resource utilization and\nimproving system spectral efficiency. The separate design of modules in\nAI-based CSI feedback architectures under traditional modular communication\nframeworks, including channel estimation (CE), CSI compression and feedback,\nleads to sub-optimal performance. In this paper, we propose an uplink assisted\njoint CE and and CSI feedback approach via deep learning for downlink CSI\nacquisition, which mitigates performance degradation caused by distribution\nbias across separately trained modules in traditional modular communication\nframeworks. The proposed network adopts a deep joint source-channel coding\n(DJSCC) architecture to mitigate the cliff effect encountered in the\nconventional separate source-channel coding. Furthermore, we exploit the uplink\nCSI as auxiliary information to enhance CSI reconstruction accuracy by\nleveraging the partial reciprocity between the uplink and downlink channels in\nFDD systems, without introducing additional overhead. The effectiveness of\nuplink CSI as assisted information and the necessity of an end-toend\nmulti-module joint training architecture is validated through comprehensive\nablation and scalability experiments.",
      "tldr_zh": "本论文针对 FDD MIMO 无线通信系统中下行链路 CSI 获取的性能瓶颈，提出了一种基于深度学习的上行辅助联合通道估计和 CSI 反馈方法，以克服传统模块化设计导致的子优性能。方法采用 DJSCC（Deep Joint Source-Channel Coding）架构，缓解了分离源-通道编码的悬崖效应，并利用上行链路 CSI 作为辅助信息，借助 FDD 系统中的部分互易性提升重建准确性，而无需额外开销。通过消融实验和可扩展性实验，验证了上行 CSI 的有效性和端到端多模块联合训练的必要性，为系统光谱效率的提升提供了新途径。",
      "categories": [
        "eess.SP",
        "cs.AI"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10836v1",
      "published_date": "2025-04-15 03:29:24 UTC",
      "updated_date": "2025-04-15 03:29:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:26:56.214037"
    },
    {
      "arxiv_id": "2504.10833v1",
      "title": "Towards Spatially-Aware and Optimally Faithful Concept-Based Explanations",
      "title_zh": "翻译失败",
      "authors": [
        "Shubham Kumar",
        "Dwip Dalal",
        "Narendra Ahuja"
      ],
      "abstract": "Post-hoc, unsupervised concept-based explanation methods (U-CBEMs) are a\npromising tool for generating semantic explanations of the decision-making\nprocesses in deep neural networks, having applications in both model\nimprovement and understanding. It is vital that the explanation is accurate, or\nfaithful, to the model, yet we identify several limitations of prior\nfaithfulness metrics that inhibit an accurate evaluation; most notably, prior\nmetrics involve only the set of concepts present, ignoring how they may be\nspatially distributed. We address these limitations with Surrogate Faithfulness\n(SF), an evaluation method that introduces a spatially-aware surrogate and two\nnovel faithfulness metrics. Using SF, we produce Optimally Faithful (OF)\nexplanations, where concepts are found that maximize faithfulness. Our\nexperiments show that (1) adding spatial-awareness to prior U-CBEMs increases\nfaithfulness in all cases; (2) OF produces significantly more faithful\nexplanations than prior U-CBEMs (30% or higher improvement in error); (3) OF's\nlearned concepts generalize well to out-of-domain data and are more robust to\nadversarial examples, where prior U-CBEMs struggle.",
      "tldr_zh": "该论文针对后验、非监督的概念-based解释方法（U-CBEMs）存在的问题，提出了一种空间感知的 Surrogate Faithfulness (SF) 评估方法，包括一个空间感知代理和两个新忠实度指标，以更准确地评估深度神经网络决策的语义解释。研究通过 SF 生成 Optimally Faithful (OF) 解释，这些解释通过优化概念选择来最大化忠实度。实验结果显示，添加空间感知后，U-CBEMs 的忠实度在所有情况下均有所提升，OF 解释的错误率比现有方法降低了 30% 或更高，且其学习的概念在域外数据上泛化良好，并对对抗样本更具鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10833v1",
      "published_date": "2025-04-15 03:24:13 UTC",
      "updated_date": "2025-04-15 03:24:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:27:07.364143"
    },
    {
      "arxiv_id": "2504.10831v1",
      "title": "Hallucination-Aware Generative Pretrained Transformer for Cooperative Aerial Mobility Control",
      "title_zh": "翻译失败",
      "authors": [
        "Hyojun Ahn",
        "Seungcheol Oh",
        "Gyu Seon Kim",
        "Soyi Jung",
        "Soohyun Park",
        "Joongheon Kim"
      ],
      "abstract": "This paper proposes SafeGPT, a two-tiered framework that integrates\ngenerative pretrained transformers (GPTs) with reinforcement learning (RL) for\nefficient and reliable unmanned aerial vehicle (UAV) last-mile deliveries. In\nthe proposed design, a Global GPT module assigns high-level tasks such as\nsector allocation, while an On-Device GPT manages real-time local route\nplanning. An RL-based safety filter monitors each GPT decision and overrides\nunsafe actions that could lead to battery depletion or duplicate visits,\neffectively mitigating hallucinations. Furthermore, a dual replay buffer\nmechanism helps both the GPT modules and the RL agent refine their strategies\nover time. Simulation results demonstrate that SafeGPT achieves higher delivery\nsuccess rates compared to a GPT-only baseline, while substantially reducing\nbattery consumption and travel distance. These findings validate the efficacy\nof combining GPT-based semantic reasoning with formal safety guarantees,\ncontributing a viable solution for robust and energy-efficient UAV logistics.",
      "tldr_zh": "该论文提出 SafeGPT 框架，将生成式预训练 transformer (GPT) 与强化学习 (RL) 相结合，用于高效可靠的无人机 (UAV) 最后一段交付。框架包括 Global GPT 模块负责高层任务分配（如区域划分）和 On-Device GPT 模块处理实时本地路线规划，同时 RL-based 安全过滤器监控决策以防止幻觉问题，并覆盖可能导致电池耗尽或重复访问的不安全行动。系统还采用双重回放缓冲机制，帮助 GPT 模块和 RL 代理持续优化策略。模拟结果显示，SafeGPT 相较于仅 GPT 的基准方案显著提高了交付成功率，同时降低了电池消耗和旅行距离，为鲁棒且节能的 UAV 物流提供了一个可行的解决方案。",
      "categories": [
        "cs.AI",
        "cs.RO",
        "68T05"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10831v1",
      "published_date": "2025-04-15 03:21:08 UTC",
      "updated_date": "2025-04-15 03:21:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:27:19.782134"
    },
    {
      "arxiv_id": "2504.11501v1",
      "title": "A Framework for the Private Governance of Frontier Artificial Intelligence",
      "title_zh": "翻译失败",
      "authors": [
        "Dean W. Ball"
      ],
      "abstract": "This paper presents a proposal for the governance of frontier AI systems\nthrough a hybrid public-private system. Private bodies, authorized and overseen\nby government, provide certifications to developers of frontier AI systems on\nan opt-in basis. In exchange for opting in, frontier AI firms receive\nprotections from tort liability for customer misuse of their models. Before\ndetailing the proposal, the paper explores more commonly discussed approaches\nto AI governance, analyzing their strengths and flaws. It also examines the\nnature of frontier AI governance itself. The paper includes consideration of\nthe political economic, institutional, legal, safety, and other merits and\ntradeoffs inherent in the governance system it proposes.",
      "tldr_zh": "这篇论文提出一个混合公私治理框架，用于管理前沿 AI 系统，其中私营机构在政府授权和监督下，向开发商提供可选认证，以换取对客户误用模型的侵权责任保护。论文首先分析了常见 AI 治理方法的优势和缺陷，并探讨了前沿 AI 治理的本质。最终，该框架考虑了政治经济、制度、法律、安全等方面的权衡，提供了一个平衡风险与创新的潜在解决方案。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.11501v1",
      "published_date": "2025-04-15 02:56:26 UTC",
      "updated_date": "2025-04-15 02:56:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:27:31.069062"
    },
    {
      "arxiv_id": "2504.10823v2",
      "title": "CLASH: Evaluating Language Models on Judging High-Stakes Dilemmas from Multiple Perspectives",
      "title_zh": "CLASH：评估语言模型从多个视角判断高风险困境",
      "authors": [
        "Ayoung Lee",
        "Ryan Sungmo Kwon",
        "Peter Railton",
        "Lu Wang"
      ],
      "abstract": "Navigating high-stakes dilemmas involving conflicting values is challenging\neven for humans, let alone for AI. Yet prior work in evaluating the reasoning\ncapabilities of large language models (LLMs) in such situations has been\nlimited to everyday scenarios. To close this gap, this work first introduces\nCLASH (Character perspective-based LLM Assessments in Situations with\nHigh-stakes), a meticulously curated dataset consisting of 345 high-impact\ndilemmas along with 3,795 individual perspectives of diverse values. In\nparticular, we design CLASH in a way to support the study of critical aspects\nof value-based decision-making processes which are missing from prior work,\nincluding understanding decision ambivalence and psychological discomfort as\nwell as capturing the temporal shifts of values in characters' perspectives. By\nbenchmarking 10 open and closed frontier models, we uncover several key\nfindings. (1) Even the strongest models, such as GPT-4o and Claude-Sonnet,\nachieve less than 50% accuracy in identifying situations where the decision\nshould be ambivalent, while they perform significantly better in clear-cut\nscenarios. (2) While LLMs reasonably predict psychological discomfort as marked\nby human, they inadequately comprehend perspectives involving value shifts,\nindicating a need for LLMs to reason over complex values. (3) Our experiments\nalso reveal a significant correlation between LLMs' value preferences and their\nsteerability towards a given value. (4) Finally, LLMs exhibit greater\nsteerability when engaged in value reasoning from a third-party perspective,\ncompared to a first-person setup, though certain value pairs benefit uniquely\nfrom the first-person framing.",
      "tldr_zh": "本研究引入了 CLASH 数据集，该数据集包含 345 个高-stakes 道德困境和 3795 个多样价值的个人视角，用于评估大型语言模型 (LLMs) 在处理冲突价值决策时的推理能力。CLASH 特别关注决策过程中的关键方面，包括决策 ambivalence（矛盾心理）、psychological discomfort（心理不适）以及人物视角中价值的 temporal shifts（时序变化）。通过基准测试 10 个前沿模型（如 GPT-4o 和 Claude-Sonnet），研究发现这些模型在识别应犹豫不决的情况时准确率不足 50%，但在明确场景中表现较好；此外，LLMs 能较好预测心理不适，却对涉及 value shifts 的视角理解不足，并显示出价值偏好与 steerability（可引导性）之间的显著相关性。最终，LLMs 在第三人称视角下比第一人称视角更易引导，但某些价值对可能从第一人称受益，这为提升模型在高-stakes 情境中的价值推理提供了重要启示。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10823v2",
      "published_date": "2025-04-15 02:54:16 UTC",
      "updated_date": "2025-05-14 21:15:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:27:45.231474"
    },
    {
      "arxiv_id": "2504.10821v1",
      "title": "Progressive Rock Music Classification",
      "title_zh": "前卫摇滚音乐分类",
      "authors": [
        "Arpan Nagar",
        "Joseph Bensabat",
        "Jokent Gaza",
        "Moinak Dey"
      ],
      "abstract": "This study investigates the classification of progressive rock music, a genre\ncharacterized by complex compositions and diverse instrumentation, distinct\nfrom other musical styles. Addressing this Music Information Retrieval (MIR)\ntask, we extracted comprehensive audio features, including spectrograms,\nMel-Frequency Cepstral Coefficients (MFCCs), chromagrams, and beat positions\nfrom song snippets using the Librosa library. A winner-take-all voting strategy\nwas employed to aggregate snippet-level predictions into final song\nclassifications. We conducted a comparative analysis of various machine\nlearning techniques. Ensemble methods, encompassing Bagging (Random Forest,\nExtraTrees, Bagging Classifier) and Boosting (XGBoost, Gradient Boosting), were\nexplored, utilizing Principal Component Analysis (PCA) for dimensionality\nreduction to manage computational constraints with high-dimensional feature\nsets. Additionally, deep learning approaches were investigated, including the\ndevelopment of custom 1D Convolutional Neural Network (1D CNN) architectures\n(named \"Zuck\" and \"Satya\") featuring specific layer configurations,\nnormalization, and activation functions. Furthermore, we fine-tuned a\nstate-of-the-art Audio Spectrogram Transformer (AST) model, leveraging its\nattention-based mechanisms for audio classification. Performance evaluation on\nvalidation and test sets revealed varying effectiveness across models, with\nensemble methods like Extra Trees achieving test accuracies up to 76.38%. This\nresearch provides insights into the application and relative performance of\ndiverse machine learning paradigms for the nuanced task of progressive rock\ngenre classification.",
      "tldr_zh": "本研究探讨了 Progressive Rock 音乐的分类，该音乐风格以复杂构图和多样乐器为特征，并将其作为 Music Information Retrieval (MIR) 任务进行分析。\n研究团队从音频片段提取特征，包括 spectrograms、Mel-Frequency Cepstral Coefficients (MFCCs)、chromagrams 和 beat positions，使用 Librosa 库，并采用 winner-take-all 投票策略聚合预测。\n他们比较了各种机器学习方法，如 Ensemble 方法（包括 Bagging 的 Random Forest 和 ExtraTrees，以及 Boosting 的 XGBoost 和 Gradient Boosting）结合 Principal Component Analysis (PCA) 降维，以及深度学习模型如自定义 1D CNN（Zuck 和 Satya 架构）和微调 Audio Spectrogram Transformer (AST)。\n实验结果显示，Extra Trees 等 Ensemble 方法在测试集上达到76.38%的准确率，为 Progressive Rock 分类提供了不同机器学习范式的性能洞见。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "20 pages",
      "pdf_url": "http://arxiv.org/pdf/2504.10821v1",
      "published_date": "2025-04-15 02:48:52 UTC",
      "updated_date": "2025-04-15 02:48:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:27:57.352933"
    },
    {
      "arxiv_id": "2504.10817v1",
      "title": "FHBench: Towards Efficient and Personalized Federated Learning for Multimodal Healthcare",
      "title_zh": "翻译失败",
      "authors": [
        "Penghao Wang",
        "Qian Chen",
        "Teng Zhang",
        "Yingwei Zhang",
        "Wang Lu",
        "Yiqiang Chen"
      ],
      "abstract": "Federated Learning (FL) has emerged as an effective solution for\nmulti-institutional collaborations without sharing patient data, offering a\nrange of methods tailored for diverse applications. However, real-world medical\ndatasets are often multimodal, and computational resources are limited, posing\nsignificant challenges for existing FL approaches. Recognizing these\nlimitations, we developed the Federated Healthcare Benchmark(FHBench), a\nbenchmark specifically designed from datasets derived from real-world\nhealthcare applications. FHBench encompasses critical diagnostic tasks across\ndomains such as the nervous, cardiovascular, and respiratory systems and\ngeneral pathology, providing comprehensive support for multimodal healthcare\nevaluations and filling a significant gap in existing benchmarks. Building on\nFHBench, we introduced Efficient Personalized Federated Learning with Adaptive\nLoRA(EPFL), a personalized FL framework that demonstrates superior efficiency\nand effectiveness across various healthcare modalities. Our results highlight\nthe robustness of FHBench as a benchmarking tool and the potential of EPFL as\nan innovative approach to advancing healthcare-focused FL, addressing key\nlimitations of existing methods.",
      "tldr_zh": "该研究针对联邦学习(Federated Learning, FL) 在多模态医疗领域的挑战，如数据集多模态性和计算资源限制，开发了 Federated Healthcare Benchmark (FHBench)，这是一个基于真实医疗应用的基准，涵盖神经、心血管、呼吸系统和一般病理的诊断任务，并填补了现有基准的空白。FHBench 支持全面的多模态评估，为多机构协作提供可靠工具。基于此，研究引入了 Efficient Personalized Federated Learning with Adaptive LoRA (EPFL)，一个高效的个性化 FL 框架，在各种医疗模态中表现出色，显著提升了性能并解决了现有方法的局限性。实验结果验证了 FHBench 的稳健性和 EPFL 的潜力，推动了医疗 FL 的创新发展。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10817v1",
      "published_date": "2025-04-15 02:38:00 UTC",
      "updated_date": "2025-04-15 02:38:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:28:07.558964"
    },
    {
      "arxiv_id": "2504.10812v1",
      "title": "E2E Parking Dataset: An Open Benchmark for End-to-End Autonomous Parking",
      "title_zh": "翻译失败",
      "authors": [
        "Kejia Gao",
        "Liguo Zhou",
        "Mingjun Liu",
        "Alois Knoll"
      ],
      "abstract": "End-to-end learning has shown great potential in autonomous parking, yet the\nlack of publicly available datasets limits reproducibility and benchmarking.\nWhile prior work introduced a visual-based parking model and a pipeline for\ndata generation, training, and close-loop test, the dataset itself was not\nreleased. To bridge this gap, we create and open-source a high-quality dataset\nfor end-to-end autonomous parking. Using the original model, we achieve an\noverall success rate of 85.16% with lower average position and orientation\nerrors (0.24 meters and 0.34 degrees).",
      "tldr_zh": "这篇论文介绍了E2E Parking Dataset，这是一个开源基准数据集，旨在解决端到端自动泊车研究中数据集缺乏导致的可重复性和基准测试问题。该数据集基于先前视觉模型和数据生成管道创建，并提供高质量的训练和闭环测试资源。实验结果显示，使用该数据集的原始模型实现了85.16%的整体成功率，平均位置误差为0.24米和方向误差为0.34度。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10812v1",
      "published_date": "2025-04-15 02:21:09 UTC",
      "updated_date": "2025-04-15 02:21:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:28:18.371482"
    },
    {
      "arxiv_id": "2504.10810v1",
      "title": "PatrolVision: Automated License Plate Recognition in the wild",
      "title_zh": "PatrolVision：野外自动车牌识别",
      "authors": [
        "Anmol Singhal Navya Singhal"
      ],
      "abstract": "Adoption of AI driven techniques in public services remains low due to\nchallenges related to accuracy and speed of information at population scale.\nComputer vision techniques for traffic monitoring have not gained much\npopularity despite their relative strength in areas such as autonomous driving.\nDespite large number of academic methods for Automatic License Plate\nRecognition (ALPR) systems, very few provide an end to end solution for\npatrolling in the city. This paper presents a novel prototype for a low power\nGPU based patrolling system to be deployed in an urban environment on\nsurveillance vehicles for automated vehicle detection, recognition and\ntracking. In this work, we propose a complete ALPR system for Singapore license\nplates having both single and double line creating our own YOLO based network.\nWe focus on unconstrained capture scenarios as would be the case in real world\napplication, where the license plate (LP) might be considerably distorted due\nto oblique views. In this work, we first detect the license plate from the full\nimage using RFB-Net and rectify multiple distorted license plates in a single\nimage. After that, the detected license plate image is fed to our network for\ncharacter recognition. We evaluate the performance of our proposed system on a\nnewly built dataset covering more than 16,000 images. The system was able to\ncorrectly detect license plates with 86\\% precision and recognize characters of\na license plate in 67\\% of the test set, and 89\\% accuracy with one incorrect\ncharacter (partial match). We also test latency of our system and achieve 64FPS\non Tesla P4 GPU",
      "tldr_zh": "本研究提出PatrolVision，一种基于低功耗GPU的自动化车牌识别(ALPR)系统，旨在解决AI在公共服务中的准确性和速度挑战，并提供适用于城市巡逻的端到端解决方案。该系统针对新加坡车牌（包括单行和双行）处理不受约束的场景，如倾斜视图导致的扭曲，使用RFB-Net检测并校正车牌图像，然后通过自定义的YOLO-based网络进行字符识别。在一个包含超过16,000张图像的新数据集上，系统实现了86%的车牌检测精度、67%的字符识别准确率（部分匹配为89%），并在Tesla P4 GPU上达到64 FPS的实时性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted in IEEE Southeast Con 2025. To be published in IEEEXplore",
      "pdf_url": "http://arxiv.org/pdf/2504.10810v1",
      "published_date": "2025-04-15 02:10:43 UTC",
      "updated_date": "2025-04-15 02:10:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:28:31.795182"
    },
    {
      "arxiv_id": "2504.11500v1",
      "title": "TransitReID: Transit OD Data Collection with Occlusion-Resistant Dynamic Passenger Re-Identification",
      "title_zh": "TransitReID：抗遮挡动态乘客重新识别的公共交通 OD 数据收集",
      "authors": [
        "Kaicong Huang",
        "Talha Azfar",
        "Jack Reilly",
        "Ruimin Ke"
      ],
      "abstract": "Transit Origin-Destination (OD) data are essential for transit planning,\nparticularly in route optimization and demand-responsive paratransit systems.\nTraditional methods, such as manual surveys, are costly and inefficient, while\nBluetooth and WiFi-based approaches require passengers to carry specific\ndevices, limiting data coverage. On the other hand, most transit vehicles are\nequipped with onboard cameras for surveillance, offering an opportunity to\nrepurpose them for edge-based OD data collection through visual person\nre-identification (ReID). However, such approaches face significant challenges,\nincluding severe occlusion and viewpoint variations in transit environments,\nwhich greatly reduce matching accuracy and hinder their adoption. Moreover,\ndesigning effective algorithms that can operate efficiently on edge devices\nremains an open challenge. To address these challenges, we propose TransitReID,\na novel framework for individual-level transit OD data collection. TransitReID\nconsists of two key components: (1) An occlusion-robust ReID algorithm\nfeaturing a variational autoencoder guided region-attention mechanism that\nadaptively focuses on visible body regions through reconstruction\nloss-optimized weight allocation; and (2) a Hierarchical Storage and Dynamic\nMatching (HSDM) mechanism specifically designed for efficient and robust\ntransit OD matching which balances storage, speed, and accuracy. Additionally,\na multi-threaded design supports near real-time operation on edge devices,\nwhich also ensuring privacy protection. We also introduce a ReID dataset\ntailored for complex bus environments to address the lack of relevant training\ndata. Experimental results demonstrate that TransitReID achieves\nstate-of-the-art performance in ReID tasks, with an accuracy of approximately\n90\\% in bus route simulations.",
      "tldr_zh": "这篇论文提出了TransitReID框架，用于通过抗遮挡的动态乘客重新识别(ReID)来高效收集公交Origin-Destination (OD) 数据，解决传统方法成本高和覆盖有限的问题。框架的关键组件包括一个基于变分自编码器引导的区域注意力机制的ReID算法，该机制通过重构损失优化权重，专注于可见身体区域；以及一个层次存储和动态匹配(HSDM)机制，以平衡存储、速度和准确性，同时支持边缘设备的近实时操作和隐私保护。作者还引入了一个针对复杂公交环境的ReID数据集，实验结果显示TransitReID在ReID任务中达到最先进性能，准确率约90%。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.11500v1",
      "published_date": "2025-04-15 02:09:02 UTC",
      "updated_date": "2025-04-15 02:09:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:28:43.815024"
    },
    {
      "arxiv_id": "2504.10797v1",
      "title": "Name of Thrones: Evaluating How LLMs Rank Student Names, Race, and Gender in Status Hierarchies",
      "title_zh": "王座之名：评估 LLMs 如何在地位阶层中对学生姓名、种族和",
      "authors": [
        "Annabella Sakunkoo",
        "Jonathan Sakunkoo"
      ],
      "abstract": "Across cultures, names tell a lot about their bearers as they carry deep\npersonal and cultural significance. Names also serve as powerful signals of\ngender, race, and status in the social hierarchy - a pecking order in which\nindividual positions shape others' expectations on their perceived competence\nand worth. With the widespread adoption of LLMs and as names are often an input\nfor LLMs, it is crucial to evaluate whether LLMs may sort people into status\npositions based on first and last names and, if so, whether it is in an unfair,\nbiased fashion. While prior work has primarily investigated biases in first\nnames, little attention has been paid to last names and even less to the\ncombined effects of first and last names. In this study, we conduct a\nlarge-scale analysis of name variations across 5 ethnicities to examine how AI\nexhibits name biases. Our study investigates three key characteristics of\ninequality and finds that LLMs reflect and reinforce status hierarchies based\non names that signal gender and ethnicity as they encode differential\nexpectations of competence, leadership, and economic potential. Contrary to the\ncommon assumption that AI tends to favor Whites, we show that East and, in some\ncontexts, South Asian names receive higher rankings. We also disaggregate\nAsians, a population projected to be the largest immigrant group in the U.S. by\n2055. Our results challenge the monolithic Asian model minority assumption,\nillustrating a more complex and stratified model of bias. Gender moderates\nbiases, with girls facing unfair disadvantages in certain racial groups.\nAdditionally, spanning cultural categories by adopting Western first names\nimproves AI-perceived status for East and Southeast Asian students,\nparticularly for girls. Our findings underscore the importance of\nintersectional and more nuanced understandings of race, gender, and mixed\nidentities in the evaluation of LLMs.",
      "tldr_zh": "这篇论文评估了大型语言模型（LLMs）如何基于学生姓名、种族和性别对社会地位进行排名，揭示了LLMs在处理姓名时可能强化不平等的偏见。研究通过对5个种族的姓名组合进行大规模分析，调查了能力、领导力和经济潜力的预期差异，结果显示东亚和某些南亚姓名在某些语境下获得更高排名，挑战了AI偏向白人的常见假设。性别因素加剧了偏见，例如女孩在特定种族中面临不利，而采用西方名字能显著改善东亚和东南亚学生的AI感知地位。该研究强调了在评估LLMs时，需要更细致交叉的种族、性别和混合身份视角，以促进更公平的AI应用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC",
        "H.5; J.4"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10797v1",
      "published_date": "2025-04-15 01:47:39 UTC",
      "updated_date": "2025-04-15 01:47:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:28:57.283282"
    },
    {
      "arxiv_id": "2504.10786v2",
      "title": "Visual Language Models show widespread visual deficits on neuropsychological tests",
      "title_zh": "视觉语言模型在神经心理学测试中显示出广泛的视觉缺陷",
      "authors": [
        "Gene Tangtartharakul",
        "Katherine R. Storrs"
      ],
      "abstract": "Visual Language Models (VLMs) show remarkable performance in visual reasoning\ntasks, successfully tackling college-level challenges that require high-level\nunderstanding of images. However, some recent reports of VLMs struggling to\nreason about elemental visual concepts like orientation, position, continuity,\nand occlusion suggest a potential gulf between human and VLM vision. Here we\nuse the toolkit of neuropsychology to systematically assess the capabilities of\nthree state-of-the-art VLMs across visual domains. Using 51 tests drawn from\nsix clinical and experimental batteries, we characterise the visual abilities\nof leading VLMs relative to normative performance in healthy adults. While the\nmodels excel in straightforward object recognition tasks, we find widespread\ndeficits in low- and mid-level visual abilities that would be considered\nclinically significant in humans. These selective deficits, profiled through\nvalidated test batteries, suggest that an artificial system can achieve complex\nobject recognition without developing foundational visual concepts that in\nhumans require no explicit training.",
      "tldr_zh": "本研究使用神经心理学测试系统评估了三种最先进的 Visual Language Models (VLMs)，通过 51 个测试从六个临床和实验电池中比较其视觉能力与人类标准。结果显示，VLMs 在简单物体识别任务中表现出色，但存在广泛的低级和中级视觉缺陷，如方向、位置和遮挡理解，这些缺陷在人类中可能被视为临床意义重大。该发现表明，人工智能可以实现复杂物体识别，而无需像人类那样依赖基础视觉概念的显式训练。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "I.2.0; I.2.10"
      ],
      "primary_category": "cs.CV",
      "comment": "31 pages, 3 figures, 1 supplementary document with 1 figure and 51\n  sample images; corrected typo in Fig 1",
      "pdf_url": "http://arxiv.org/pdf/2504.10786v2",
      "published_date": "2025-04-15 01:04:56 UTC",
      "updated_date": "2025-04-16 01:27:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:29:07.758138"
    },
    {
      "arxiv_id": "2504.10784v1",
      "title": "ATLASv2: LLM-Guided Adaptive Landmark Acquisition and Navigation on the Edge",
      "title_zh": "翻译失败",
      "authors": [
        "Mikolaj Walczak",
        "Uttej Kallakuri",
        "Tinoosh Mohsenin"
      ],
      "abstract": "Autonomous systems deployed on edge devices face significant challenges,\nincluding resource constraints, real-time processing demands, and adapting to\ndynamic environments. This work introduces ATLASv2, a novel system that\nintegrates a fine-tuned TinyLLM, real-time object detection, and efficient path\nplanning to enable hierarchical, multi-task navigation and manipulation all on\nthe edge device, Jetson Nano. ATLASv2 dynamically expands its navigable\nlandmarks by detecting and localizing objects in the environment which are\nsaved to its internal knowledge base to be used for future task execution. We\nevaluate ATLASv2 in real-world environments, including a handcrafted home and\noffice setting constructed with diverse objects and landmarks. Results show\nthat ATLASv2 effectively interprets natural language instructions, decomposes\nthem into low-level actions, and executes tasks with high success rates. By\nleveraging generative AI in a fully on-board framework, ATLASv2 achieves\noptimized resource utilization with minimal prompting latency and power\nconsumption, bridging the gap between simulated environments and real-world\napplications.",
      "tldr_zh": "该研究提出ATLASv2系统，利用LLM-Guided（大语言模型指导）的自适应地标获取和导航方法，针对边缘设备（如Jetson Nano）的资源限制、实时处理需求和动态环境挑战。ATLASv2整合fine-tuned TinyLLM、实时对象检测和高效路径规划，实现层次化多任务导航和操作，并动态扩展内部知识库以保存检测到的环境地标。实验在真实家庭和办公室环境中显示，该系统能准确解释自然语言指令、分解为低级动作并以高成功率执行任务，同时优化资源利用、减少提示延迟和功耗，从而桥接模拟与实际应用的差距。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10784v1",
      "published_date": "2025-04-15 00:55:57 UTC",
      "updated_date": "2025-04-15 00:55:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:29:19.573269"
    },
    {
      "arxiv_id": "2504.10781v1",
      "title": "Neural Network Emulation of the Classical Limit in Quantum Systems via Learned Observable Mappings",
      "title_zh": "神经网络通过学习的可观测映射模拟量子系统中的经典极限",
      "authors": [
        "Kamran Majid"
      ],
      "abstract": "The classical limit of quantum mechanics, formally investigated through\nframeworks like strict deformation quantization, remains a profound area of\ninquiry in the philosophy of physics. This paper explores a computational\napproach employing a neural network to emulate the emergence of classical\nbehavior from the quantum harmonic oscillator as Planck's constant $\\hbar$\napproaches zero. We develop and train a neural network architecture to learn\nthe mapping from initial expectation values and $\\hbar$ to the time evolution\nof the expectation value of position. By analyzing the network's predictions\nacross different regimes of hbar, we aim to provide computational insights into\nthe nature of the quantum-classical transition. This work demonstrates the\npotential of machine learning as a complementary tool for exploring\nfoundational questions in quantum mechanics and its classical limit.",
      "tldr_zh": "这篇论文使用神经网络模拟量子系统的经典极限，聚焦于量子谐振子当Planck's constant ħ接近零时的行为，通过学习可观测映射来预测期望值的演化。研究团队开发并训练了一个神经网络架构，将初始期望值和ħ映射到位置期望值的时间演化。实验结果展示了机器学习作为探索量子-经典过渡的补充工具的潜力，提供新的计算洞见以加深对量子力学基础问题的理解。",
      "categories": [
        "quant-ph",
        "cs.AI"
      ],
      "primary_category": "quant-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10781v1",
      "published_date": "2025-04-15 00:48:36 UTC",
      "updated_date": "2025-04-15 00:48:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:29:32.095094"
    },
    {
      "arxiv_id": "2504.10768v1",
      "title": "The Art of Audience Engagement: LLM-Based Thin-Slicing of Scientific Talks",
      "title_zh": "翻译失败",
      "authors": [
        "Ralf Schmälzle",
        "Sue Lim",
        "Yuetong Du",
        "Gary Bente"
      ],
      "abstract": "This paper examines the thin-slicing approach - the ability to make accurate\njudgments based on minimal information - in the context of scientific\npresentations. Drawing on research from nonverbal communication and personality\npsychology, we show that brief excerpts (thin slices) reliably predict overall\npresentation quality. Using a novel corpus of over one hundred real-life\nscience talks, we employ Large Language Models (LLMs) to evaluate transcripts\nof full presentations and their thin slices. By correlating LLM-based\nevaluations of short excerpts with full-talk assessments, we determine how much\ninformation is needed for accurate predictions. Our results demonstrate that\nLLM-based evaluations align closely with human ratings, proving their validity,\nreliability, and efficiency. Critically, even very short excerpts (less than 10\npercent of a talk) strongly predict overall evaluations. This suggests that the\nfirst moments of a presentation convey relevant information that is used in\nquality evaluations and can shape lasting impressions. The findings are robust\nacross different LLMs and prompting strategies. This work extends thin-slicing\nresearch to public speaking and connects theories of impression formation to\nLLMs and current research on AI communication. We discuss implications for\ncommunication and social cognition research on message reception. Lastly, we\nsuggest an LLM-based thin-slicing framework as a scalable feedback tool to\nenhance human communication.",
      "tldr_zh": "本文研究了Thin-slicing方法在科学演讲中的应用，即基于最小信息（如简短片段）做出准确判断，利用LLMs（大型语言模型）评估一个包含100多个真实科学演讲的语料库。研究发现，LLMs对短片段（如不到10%的演讲内容）的评估与人类评分高度一致，并能可靠预测整体演讲质量，这表明演讲开头的信息对印象形成至关重要。结果在不同LLMs和提示策略下保持稳健，并扩展了Thin-slicing研究到公共演讲领域，同时提出一个LLM-based框架作为可扩展的反馈工具，以提升人类沟通效果。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.ET",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10768v1",
      "published_date": "2025-04-15 00:08:13 UTC",
      "updated_date": "2025-04-15 00:08:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T13:29:43.893631"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 127,
  "processed_papers_count": 127,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-24T13:30:03.344790"
}