{
  "date": "2025-04-15",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间2025-04-15的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文热点集中在大型语言模型（LLM）的**推理能力提升、安全性、效率优化以及多模态应用**。特别值得关注的是用于提升数学推理的大规模数据集 **DeepMath-103K** 的发布，以及利用强化学习进行形式化定理证明的 **Kimina-Prover**。此外，**离线强化学习**、**多模态模型**（如蛋白质语言模型、全景视频生成、地球观测）以及 **AI 在科学发现和工程应用**（如抗生素发现、控制系统）中的探索也占据了重要位置。LLM 的安全问题，特别是**提示注入攻击及其防御**，以及 **AI 伦理和偏见**问题也得到了深入探讨。\n\n以下是今天值得关注的论文：\n\n---\n\n**1. DeepMath-103K: 用于推进推理的大规模、高难度、去污染、可验证的数学数据集 (DeepMath-103K: A Large-Scale, Challenging, Decontaminated, and Verifiable Mathematical Dataset for Advancing Reasoning)**\n\n*   **问题:** 现有数学推理数据集在规模、难度、答案可验证性（用于RL）和基准污染方面存在不足，阻碍了通过强化学习（RL）训练高级推理模型。\n*   **贡献:** 提出了 DeepMath-103K 数据集，包含约10.3万个高难度（主要为5-9级）数学问题，经过严格去污染处理，提供可验证答案和多种 R1 生成的解法，适用于不同训练范式（SFT, RL, 蒸馏）。\n*   **发现:** 在 DeepMath-103K 上训练的模型在挑战性数学基准上取得了显著提升。\n*   **意义:** 为社区提供了高质量、大规模的数学推理训练资源，有望推动 AI 推理能力的发展。\n\n**2. Kimina-Prover 预览版: 迈向基于强化学习的大型形式化推理模型 (Kimina-Prover Preview: Towards Large Formal Reasoning Models with Reinforcement Learning)**\n\n*   **问题:** 如何利用大型语言模型进行高效、可靠的形式化定理证明。\n*   **贡献:** 提出了 Kimina-Prover Preview，一个基于 Qwen2.5-72B 并通过大规模强化学习训练的大模型。它采用了一种称为“形式化推理模式”的结构化推理方法，在 Lean 4 证明生成中模拟人类解决问题的策略。\n*   **发现:** Kimina-Prover 在 miniF2F 基准上达到 80.7% (pass@8192)，创下新纪录。模型展现出高样本效率，并随模型规模增大性能提升。其学习到的推理风格不同于传统搜索算法。\n*   **意义:** 展示了 RL 在训练大型形式化推理模型方面的潜力，并开源了 1.5B 和 7B 参数的蒸馏版本，可能弥合形式化验证与非形式化数学直觉之间的鸿沟。\n\n**3. 通过学习与遗忘教大型语言模型推理 (Teaching Large Language Models to Reason through Learning and Forgetting)**\n\n*   **问题:** 推理时搜索（Inference-time search）能提升 LLM 推理能力，但计算成本高昂。直接用搜索路径微调模型效果不佳，模型搜索能力会快速退化。\n*   **贡献:** 提出一种方法，通过微调模型学习成功（learning）和失败（forgetting）的推理路径来整合搜索能力。发现使用较小的学习率可以显著缓解微调过程中的能力退化问题。\n*   **发现:** 该方法在 Game-of-24 和 Countdown 数学推理基准上优于标准微调和推理时搜索基线，并将推理时间大幅缩短 180 倍。\n*   **意义:** 提供了一种将搜索能力内化到 LLM 中的有效方法，提高了推理效率。\n\n**4. LLM 推理的极简方法：从拒绝采样到 REINFORCE (A Minimalist Approach to LLM Reasoning: from Rejection Sampling to Reinforce)**\n\n*   **问题:** 现有基于强化学习（RL）微调 LLM 进行复杂推理的方法（如 GRPO）效果好但原理不清。\n*   **贡献:** 本文重新审视了 GRPO，发现其核心优势在于丢弃完全错误的样本，而非奖励归一化。基于此，提出了一个简单的拒绝采样基线 RAFT（只用正奖励样本训练）和一个最小扩展 Reinforce-Rej（过滤掉完全错误和完全正确的样本）。\n*   **发现:** RAFT 性能与 GRPO 和 PPO 相当。Reinforce-Rej 提高了 KL 效率和稳定性，是复杂 RL 算法的轻量级有效替代方案。\n*   **意义:** 倡导使用 RAFT 作为健壮且可解释的基线，并建议未来研究应更注重有原则地利用负样本，而非不加区分地使用。为基于奖励的 LLM 后训练提供了指导。\n\n**5. DataSentinel: 基于博弈论的提示注入攻击检测 (DataSentinel: A Game-Theoretic Detection of Prompt Injection Attacks)**\n\n*   **问题:** LLM 集成应用易受提示注入攻击，现有检测方法对高级或自适应攻击效果有限。\n*   **贡献:** 提出了 DataSentinel，一种基于博弈论的提示注入攻击检测方法。通过将检测问题建模为 Minimax 优化问题，微调 LLM 以检测能策略性适应以规避检测的注入提示。提出了基于梯度的方法来解决此优化问题。\n*   **发现:** 在多个基准数据集和 LLM 上的评估表明，DataSentinel 能有效检测现有及自适应的提示注入攻击。\n*   **意义:** 提出了一种更强大的提示注入攻击防御机制，提高了 LLM 应用的安全性。\n\n**6. 绕过 LLM 护栏中的提示注入和越狱检测 (Bypassing Prompt Injection and Jailbreak Detection in LLM Guardrails)**\n\n*   **问题:** LLM 护栏系统旨在防御提示注入和越狱攻击，但仍易被规避技术绕过。\n*   **贡献:** 展示了两种绕过 LLM 提示注入和越狱检测系统的方法：传统字符注入和算法性对抗机器学习（AML）规避技术。\n*   **发现:** 对六个主流防护系统（包括微软 Azure Prompt Shield 和 Meta Prompt Guard）的测试表明，这两种方法都能在保持攻击效用的同时规避检测，某些情况下成功率高达 100%。利用离线白盒模型计算的词重要性排名可以提高对黑盒目标的攻击成功率。\n*   **意义:** 揭示了当前 LLM 保护机制的漏洞，强调了需要更强大的护栏系统。\n\n**7. TerraMind: 用于地球观测的大规模生成式多模态模型 (TerraMind: Large-Scale Generative Multimodality for Earth Observation)**\n\n*   **问题:** 如何构建一个能够处理多种地球观测（EO）模态数据并进行生成任务的基础模型。\n*   **贡献:** 提出了 TerraMind，第一个用于 EO 的 any-to-any 生成式多模态基础模型。它在预训练中结合了 token 级（高层上下文）和 pixel 级（细粒度空间细节）的双尺度表示。\n*   **发现:** TerraMind 的双尺度早期融合方法支持多种零样本和少样本 EO 应用。引入了 \"Thinking-in-Modalities\" (TiM) 能力，即在微调和推理时生成额外人工数据以改善模型输出。在 PANGAEA 等 EO 基准上达到 SOTA 性能。\n*   **意义:** 为地球观测领域提供了一个强大的多模态基础模型，并开源了数据集、模型权重和代码。\n\n**8. VideoPanda: 具有多视图注意力的视频全景扩散模型 (VideoPanda: Video Panoramic Diffusion with Multi-view Attention)**\n\n*   **问题:** 生成高质量的 360° 全景视频通常需要专业设备，难以获取。如何利用 AI 生成此类内容？\n*   **贡献:** 提出了 VideoPanda，一种新方法，可根据文本或单视图视频生成 360° 视频。它通过多视图注意力层增强视频扩散模型，使其能生成一致的多视图视频，组合成全景内容。\n*   **发现:** VideoPanda 支持文本和单视图视频两种条件输入，并能自回归生成长视频。通过训练时随机子采样时长和视角，模型能在推理时泛化生成更多帧。在真实和合成数据集上的评估表明，VideoPanda 生成的全景视频比现有方法更真实、连贯。\n*   **意义:** 为 VR 等沉浸式体验提供了生成高质量全景视频内容的新途径。\n\n**9. 阐明多模态蛋白质语言模型的设计空间 (Elucidating the Design Space of Multimodal Protein Language Models)**\n\n*   **问题:** 多模态蛋白质语言模型（PLM）将序列和基于 token 的结构信息结合，但在将 3D 结构 token 化时会丢失细粒度细节。\n*   **贡献:** 系统性地阐明了多模态 PLM 的设计空间，识别出 token 化损失和结构 token 预测不准确是主要瓶颈。提出了覆盖改进生成建模、结构感知架构和表示学习以及数据探索的设计空间。\n*   **发现:** 提出的设计方法显著提高了结构生成多样性和折叠能力，使 650M 模型在 PDB 测试集上的 RMSD 从 5.52 降至 2.36，优于 3B 基线，与专门的折叠模型相当。\n*   **意义:** 为构建更强大的多模态蛋白质模型提供了设计指导，推动了蛋白质建模、生成和设计领域的发展。\n\n**10. 离线强化学习的新起点 (A Clean Slate for Offline Reinforcement Learning)**\n\n*   **问题:** 离线强化学习（Offline RL）的进展受到模糊问题定义、纠缠算法设计、不一致实现、不充分消融和不公平评估的阻碍。许多方法依赖未记录的在线评估进行超参数调整。\n*   **贡献:** 提出了严格的分类法和透明的评估协议（量化在线调整预算）。提供了多种 model-free 和 model-based 离线 RL 方法的简洁、最小化、单文件实现。提出了统一算法 Unifloral，将多种先前方法纳入单一超参数空间。\n*   **发现:** 基于 Unifloral 和严格评估协议，开发了两种新算法 TD3-AWR (model-free) 和 MoBRAC (model-based)，显著优于现有基线。\n*   **意义:** 通过提供清晰的实现、严格的评估框架和统一的算法空间，为离线 RL 研究奠定了更坚实的基础。\n\n**11. 面向 LLM 的非确定性多项式时间问题挑战：一个永恒扩展的推理基准 (Nondeterministic Polynomial-time Problem Challenge: An Ever-Scaling Reasoning Benchmark for LLMs)**\n\n*   **问题:** 当前 LLM 推理基准容易被快速攻克（<1年）且可能被轻易破解（hacked）。\n*   **贡献:** 提出了“永恒扩展性”（ever-scalingness）概念，并构建了 NPPC 基准，包含 25 个 NP 完全问题，可生成任意数量和复杂度的实例，并提供统一的评估接口和分析工具。\n*   **发现:** NPPC 成功将高级 LLM 的性能降低到 10% 以下，证明其“不可攻克性”。DeepSeek-R1, Claude-3.7-Sonnet, o1/o3-mini 表现最强。随着问题难度增加，高级 LLM 的 token 数、aha 时刻先增后减。\n*   **意义:** 提供了首个永恒扩展的推理基准，为迈向 AGI 的 LLM 提供了一个难以攻克和破解的测试平台。\n\n**12. 面向医疗保健的高效个性化联邦学习基准 (FHBench: Towards Efficient and Personalized Federated Learning for Multimodal Healthcare)**\n\n*   **问题:** 现实世界医疗数据通常是多模态的，且计算资源有限，给联邦学习（FL）带来挑战。现有 FL 基准缺乏对多模态和效率的关注。\n*   **贡献:** 开发了 FHBench，一个专为多模态医疗应用设计的 FL 基准，涵盖神经、心血管、呼吸系统和病理学等领域的诊断任务。提出了 EPFL，一个基于 FHBench 的高效个性化 FL 框架，使用自适应 LoRA。\n*   **发现:** FHBench 作为基准工具表现稳健，EPFL 在各种医疗模态上展现出优越的效率和效果。\n*   **意义:** 填补了现有医疗 FL 基准的空白，并提出了一种高效的个性化 FL 方法，推动了医疗 FL 的发展。\n\n**13. 用于边缘部署的轻量级多尺度融合网络 CFIS-YOLO 进行木材缺陷检测 (CFIS-YOLO: A Lightweight Multi-Scale Fusion Network for Edge-Deployable Wood Defect Detection)**\n\n*   **贡献:** 提出了 CFIS-YOLO，一个为边缘设备优化的轻量级木材缺陷检测模型。引入了增强的 C2f 结构、动态特征重组模块和结合辅助边界框及角度约束的新损失函数。\n*   **发现:** 在公共木材缺陷数据集上，mAP@0.5 达到 77.5%，优于 YOLOv10s。在 SOPHON BM1684X 边缘设备上，达到 135 FPS，功耗降低至 17.3%，mAP 仅下降 0.5%。\n*   **意义:** 为资源受限环境下的实时木材缺陷检测提供了实用有效的解决方案。\n\n**14. 探索面向道德机器实验的依赖于角色的 LLM 对齐 (Exploring Persona-dependent LLM Alignment for the Moral Machine Experiment)**\n\n*   **问题:** 具有代理能力的 LLM 在现实世界应用中面临道德困境时，其决策如何与人类判断对齐？\n*   **贡献:** 研究了在道德机器实验的不同情境下（包括反映不同社会人口统计特征的角色），LLM 驱动的决策与人类判断的对齐情况。\n*   **发现:** LLM 的道德决策因角色而异，在关键任务上比人类表现出更大的决策转变。政治角色主导了 LLM 决策的方向和程度。\n*   **意义:** 讨论了在涉及道德决策的应用中部署这些模型的伦理影响和风险。\n\n**15. 超越下一个 Token 预测：Transformer 是上下文敏感语言生成器 (Moving Beyond Next-Token Prediction: Transformers are Context-Sensitive Language Generators)**\n\n*   **贡献:** 提出一个新框架，将 LLM (Transformer) 解释为概率性左上下文敏感语言 (CSL) 生成器。假设 Transformer 可分解为上下文窗口、注意力机制和自回归生成框架。\n*   **论点:** 下一个 token 预测可理解为对左 CSL 产生式规则的概率性、动态近似。由于所有 CSL 都是左上下文敏感的，Transformer 随机近似了 CSL，这为简单的 token 预测如何产生类人智能输出提供了直观解释。\n*   **意义:** 桥接了形式语言理论与 Transformer 的生成能力，为生成式 AI 理论和应用的未来发展奠定基础。\n\n---\n\n**其他简讯:**\n\n*   **多模态蛋白质语言模型 (2):** 探索了设计空间，通过改进生成建模、结构感知架构等克服 token 化损失，显著提升结构生成和折叠能力。\n*   **TextArena (4):** 发布了一个开源的、包含 57+ 竞争性文本游戏的集合，用于训练和评估 LLM 的智能体行为，特别是谈判、心智理论等社交技能。\n*   **播客和 LLM 中的男性默认 (6):** 提出框架分析播客中的性别化话语，发现商业、科技/政治、游戏领域存在基于话语的男性默认偏见，且 LLM 嵌入对男性话语表示更稳定。\n*   **大型语言模型通用知识蒸馏的双空间框架 (7):** 提出 DSKD 框架，通过统一教师和学生模型的预测头进行知识蒸馏，解决了输出空间不匹配和词汇表不同的问题。\n*   **ADT: 用对抗监督微调扩散模型 (8):** 提出 Adversarial Diffusion Tuning (ADT) 框架，在优化过程中模拟推理过程，通过对抗监督对齐输出与训练数据，提升 Stable Diffusion 等模型的图像质量。\n*   **具身世界模型 (9):** 通过在开放环境中进行导航任务，展示了结合 GRU 和 Meta-RL 的智能体可以自主内化方向、距离等空间概念，形成具身世界模型。\n*   **风险规避策略梯度的变异性度量 (10):** 研究了 9 种变异性度量（如方差、基尼偏差、CVaR 偏差等）在风险规避 RL 中的应用，推导了未研究度量的策略梯度，发现 CVaR 偏差和基尼偏差表现稳健。\n*   **用于 FLIM 网络的多级元胞自动机 (11):** 提出使用 FLIM 网络初始化元胞自动机（CA）状态，创建多级 CA 框架，在医学显著目标检测中表现出竞争力。\n*   **轨迹编码时序图网络 (13):** 提出 TETGN，通过引入可扩展节点 ID 作为可学习时序位置特征，并进行消息传递，有效平衡了时序图网络在直推式和归纳式任务上的性能。\n*   **用于事件生成的赢者通吃机制 (14):** 提出一种基于神经元反跳兴奋性和赢者通吃计算的中枢模式发生器（CPG）设计框架。\n*   **OpenTuringBench (15):** 提出了一个基于开源 LLM 的基准和框架，用于机器生成文本的检测（图灵测试）和归因，并提供了一个基于对比学习的检测器 OTBDetector。\n*   **神经辐射场在放射学 3D 重建中的显式与隐式表示 (20):** 对 AI 在放射学 3D 重建中的应用进行了系统性综述，分类讨论了显式（点、体、高斯）和隐式（先验嵌入、NeRF）方法。\n*   **可解释混合规则时序点过程 (21):** 提出 HRTPP 框架，将时序逻辑规则与数值特征结合，提高了时序点过程（TPP）在医学事件建模中的可解释性和预测准确性。\n*   **优化 LLM 推理 (26):** 将 LLM 推理优化建模为多阶段在线调度问题，提出基于流体近似的 WAIT 和 Nested WAIT 算法，在内存约束下平衡吞吐量、延迟和 TTFT。\n*   **学习成为医生 (28):** 提出自动化设计医疗智能体架构的框架，定义了分层表达性搜索空间，通过 AutoML 自动进化工作流结构，提升诊断准确率。\n*   **单输入多输出模型合并 (30):** 研究了单输入多输出（SIMO）场景下的模型合并，发现现有方法存在表示未对齐问题，并提出两种简单修复方法，有效利用预训练模型进行密集多任务学习。\n*   **DeepSelective (31):** 提出用于 EHR 数据临床预测的可解释深度学习框架，结合数据压缩和特征选择，提高预测准确性和模型可解释性。\n*   **基于 Rollout 的算法和奖励函数用于业务流程资源分配 (32):** 提出一种基于 Rollout 的 DRL 算法和直接优化平均循环时间目标的奖励函数，用于业务流程资源分配。\n*   **呼吸吸入器声音事件分类 (33):** 使用 wav2vec 2.0 自监督学习模型对吸入器声音进行分类，证明了其有效性，并探索了模型对不同吸入器类型的泛化能力。\n*   **时序社交网络中的影响最大化与冷启动问题 (34):** 提出一种监督方法解决时序图中的影响最大化（IM）问题，特别是冷启动场景，使用基于 motif 的标记和张量化 TGN。\n*   **基于智能体的 RAG 实现自动化安全需求推导 (35):** 提出使用基于智能体的 RAG 从汽车标准和案例研究（Apollo）中自动推导安全需求，提高了检索信息的相关性。\n*   **多样性驱动学习 (37):** 提出 FedDiverse 客户端选择算法，通过促进数据分布互补的客户端协作，解决联邦学习中的伪相关和数据异质性问题。\n*   **通过神经符号 AI 和知识图谱实现人与系统间的相互理解 (38):** 探讨了利用神经符号 AI 和知识图谱增强人与系统（包括机器人）之间相互理解的三个维度：共享、交换和治理知识。\n*   **高效分布式 RAG (39):** 提出 DRAGON 框架，通过分布式 RAG 增强端侧小模型（SLM）性能，利用云端通用知识和设备端个人知识，同时保护隐私。\n*   **使用逻辑增强生成增强多模态类比推理 (40):** 应用 LAG 框架，利用知识图谱引导文本生成，以激发隐式类比联系，在多模态隐喻检测和理解任务上超越基线。\n*   **眼科领域下一代推理型 LLM 基准测试 (41):** 对四种新推理型 LLM（DeepSeek-R1, o1, o3-mini, Gemini 2.0 Flash-Thinking）在 5888 个眼科选择题上进行了准确性和推理能力评估。\n*   **探索 LLM 赋能推荐中的后门攻击与防御 (42):** 提出 BadRec 攻击框架，通过在物品标题中注入触发器并毒化训练集来植入后门。提出 P-Scanner 防御策略，利用 LLM 检测毒化物品。\n*   **MuSeD: 用于社交媒体视频中性别歧视检测的多模态西班牙语数据集 (44):** 发布了 MuSeD 数据集，包含约 11 小时 TikTok 和 BitChute 视频，用于多模态性别歧视检测研究。\n*   **DMAGaze: 基于特征解耦和多尺度注意力的视线估计 (46):** 提出 DMAGaze 框架，通过掩码解耦器分离视线相关/无关信息，并用多尺度全局局部注意力模块（MS-GLAM）融合全局、局部眼部和头部姿态特征。\n*   **C-SHAP for time series (47):** 提出 C-SHAP for time series，一种基于概念的方法，用于解释时间序列模型预测中高层模式（如趋势、季节性）的贡献。\n*   **分类问题中经验神经正切核的发散性 (48):** 理论证明在交叉熵损失下，全连接和残差网络的经验 NTK 在训练时间趋于无穷时会发散，表明 NTK 理论在此场景下不适用。\n*   **基于量子优化问题微调 LLM 生成量子电路 (49):** 通过微调 LLM 并注入量子计算知识，使其能够为优化问题（QAOA, VQE 等）生成 OpenQASM 3.0 格式的参数化量子电路。\n*   **从目标选择到化合物识别的 AI 引导抗生素发现流程 (50):** 开发了一个端到端的 AI 引导流程，利用结构预测和生成模型识别保守、必需、非人同源的靶点，并生成、筛选候选化合物。\n*   **QAMA: 具有经典深度学习框架的量子退火多头注意力算子 (51):** 提出首个基于量子退火的多头注意力机制 QAMA，通过 QUBO 建模和基于能量的反向传播实现与经典注意力的兼容，降低时空复杂度。\n*   **DeepMLF: 用于情感分析深度融合的带可学习 Token 的多模态语言模型 (52):** 提出 DeepMLF，通过在 LM 解码器中引入跨层融合的可学习 token，实现视听和语言信息的深度、渐进式融合。\n*   **通过带自先验的主动推理实现目标导向行为的涌现 (53):** 提出 \"self-prior\" 密度模型，捕捉智能体自身多模态感觉经验，在主动推理框架下，通过最小化历史经验与当前观察的差异，自主诱导目标导向行为（如触碰刺激）。\n*   **机器学习预测中的动力学误差 (54):** 研究了标准预测误差（MAE, MSE）与系统动力学特性（瞬时维度 d, 逆持续性 θ）的关系，发现高误差倾向于发生在 d 和 θ 较高的状态，并提出基于 d 和 θ 的误差度量来评估预测的动力学一致性。\n*   **来自物理信息神经网络的神经控制屏障函数 (55):** 提出一类新的神经 CBF，利用物理启发神经网络框架，将 Zubov 偏微分方程（PDE）纳入安全背景，用于合成高维系统的 CBF。\n*   **QAVA: 对大型视觉语言模型的查询无关视觉攻击 (56):** 提出 QAVA 攻击，旨在生成对未知查询也有效的鲁棒视觉对抗样本，攻击 LVLM 的视觉部分，使其对后续任意问题都给出错误回答。\n*   **GATE3D: 3D 中基于广义注意力的任务协同估计 (58):** 提出 GATE3D 框架，通过弱监督（伪标签和 2D/3D 一致性损失）实现通用的单目 3D 目标检测，有效弥合领域差距。\n*   **用于网络爬行的文档质量评分 (59):** 将神经语义质量评分器应用于网络爬行优先级排序任务，发现优先爬取高质量页面可以提高下游搜索效果。\n*   **MediSee: 医学图像中基于推理的像素级感知 (60):** 提出 MedSD 任务（医学推理分割与检测），旨在理解关于医学图像的隐式口语查询并生成目标分割掩码/边界框。发布了 MLMR-SD 数据集和基线模型 MediSee。\n*   **动态压缩提示以实现 LLM 高效推理 (61):** 提出 LLM-DCP 方法，将提示压缩建模为马尔可夫决策过程（MDP），训练 DCP-Agent 动态移除冗余 token，并使用分层提示压缩（HPC）策略进行训练。\n*   **TMCIR: Token 合并有益于组合图像检索 (62):** 提出 TMCIR 框架，通过意图感知的跨模态对齐（使用伪目标图像微调 CLIP）和自适应 Token 融合（对比学习优化组合特征）来改进组合图像检索（CIR）。\n*   **ProtFlow: 基于压缩蛋白质语言模型嵌入的流匹配实现快速蛋白质序列设计 (63):** 提出 ProtFlow 框架，在蛋白质语言模型的压缩潜空间上使用流匹配进行蛋白质序列设计，并通过 reflow 技术实现高质量单步生成。\n*   **探索基于知识图谱的 RAG 在小型 LLM 日语医疗问答中的作用 (64):** 首次探索了 KG-RAG 框架在小型开源 LLM 上的日语医疗问答效果，发现效果有限，且对检索内容的质量和相关性敏感。\n*   **评估本科生对 AI、人类和共同生成反馈的信任度 (65):** 通过实验比较学生对 AI、人类和人机协作反馈的信任度，发现学生通常更偏好 AI 和协作反馈的有用性和客观性，但 AI 反馈在来源揭示后真实感下降。\n*   **BEACON: 高效准确子图计数基准 (66):** 推出 BEACON 基准，提供标准化数据集、验证真值和评估环境，用于严格评估算法（AL）和机器学习（ML）子图计数方法。\n*   **LLM 能否利用观测数据？(67):** 探索 LLM 进行数据驱动因果发现的潜力，通过将观测数据纳入提示（成对提示和 BFS 提示），发现 LLM 能有效利用数据增强因果推断。\n*   **时序链接预测的迁移学习 (68):** 研究时序链接预测（TLP）的迁移学习任务，提出通过增加结构映射模块，将图结构特征映射到记忆嵌入，使基于记忆的 TLP 模型能够迁移到新图。\n*   **迈向通用图结构编码器 (69):** 提出 GFSE，一个通用的、跨领域的图结构编码器，通过在图 Transformer 上结合多种自监督学习目标进行预训练，生成可迁移的图结构表示。\n*   **LOKA 协议 (70):** 提出 LOKA 协议，一个用于构建可信、符合伦理的 AI 智能体生态系统的去中心化框架，包含通用智能体身份层、意图中心通信协议和去中心化伦理共识协议。\n*   **高效推理模型：综述 (71):** 对近期高效推理模型进展进行综述，分为更短（压缩 CoT）、更小（紧凑模型）和更快（高效解码）三个方向。\n*   **用原型引导归一化弥合时间序列基础模型预训练中的分布差距 (72):** 提出 ProtoNorm，用原型引导的动态归一化取代 LayerNorm，解决时间序列基础模型预训练中数据分布差异大的问题。\n*   **Xpose: 用于隐藏查询提取的双向工程 (73):** 提出 Xpose，结合反向工程（数据库变异和生成）和正向工程（利用 LLM 将业务描述转为提取指导），从不透明可执行文件中提取复杂的 SQL 查询。\n*   **ARise: 通过风险自适应搜索实现知识增强推理 (74):** 提出 ARise 框架，将中间推理状态的风险评估与动态 RAG 集成到蒙特卡洛树搜索中，用于开放域、知识密集型复杂推理。\n*   **CDUPatch: 针对双模态可见光-红外探测器的颜色驱动通用对抗补丁攻击 (75):** 提出 CDUPatch，利用颜色变化导致的热吸收差异，通过 RGB 到红外适配器统一优化跨模态补丁，攻击可见光-红外融合探测器。\n*   **PuzzleBench: 用于 LMM 解谜能力的全动态评估框架 (77):** 提出 OVPG 框架自动生成新鲜、多样、可验证的视觉谜题数据，并构建了 PuzzleBench 基准评估 LMM 的视觉识别、逻辑推理和上下文理解能力。\n*   **结合可逆 UNet 与可逆注意力模块构建内存高效的扩散模型 (78):** 提出使用可逆 UNet 架构和可逆注意力模块构建扩散模型，实现内存使用与数据维度无关，降低训练能耗，特别适用于 3D 医学图像。\n*   **LLM 驱动的特征发现改进视觉内容可信度感知的预测和解释 (79):** 提出 LLM 知情的特征发现框架，利用 GPT-4o 等多模态 LLM 评估内容可信度并解释原因，提取可解释特征以改进预测模型。\n*   **视觉语言模型能否理解和解释行人的动态手势？(80):** 创建并共享了两个包含正式和非正式交通手势的数据集（ATG, ITGI），评估了 VLM 在零样本手势理解（字幕生成、分类）方面的能力，发现现有模型能力有限。\n*   **理解投影贝尔曼方程、线性 Q 学习和近似值迭代的理论性质 (81):** 研究了 PBE 的理论性质及其求解算法（线性 Q 学习、AVI）的收敛条件，探讨了 SNRDD 假设与 AVI 收敛性的关系。\n*   **重新思考 LLM 的心智理论基准 (83):** 从人机交互角度出发，指出当前用人类 ToM 任务评估 LLM 的局限性，提倡采用更动态、交互式的方法，考虑用户偏好和体验。\n*   **用于协同空中移动控制的幻觉感知 GPT (86):** 提出 SafeGPT 框架，结合 GPT 进行高层任务分配和局部路径规划，并用 RL 安全过滤器监控和纠正不安全决策（缓解幻觉），用于无人机送货。\n*   **CLASH: 评估 LLM 从多角度判断高风险困境 (87):** 引入 CLASH 数据集，包含 345 个高风险困境和 3795 个不同价值观的角色视角，用于评估 LLM 在价值冲突决策中的能力，包括理解决策矛盾、心理不适和价值转变。\n*   **渐进式摇滚音乐分类 (88):** 使用多种音频特征（频谱图、MFCC 等）和机器学习方法（集成学习、1D CNN、微调 AST）对渐进式摇滚音乐进行分类。\n*   **E2E 停车数据集 (90):** 创建并开源了一个用于端到端自动泊车的高质量数据集，以促进该领域的可复现性和基准测试。\n*   **PatrolVision: 野外自动车牌识别 (91):** 提出一个基于低功耗 GPU 的巡逻系统原型，用于城市环境中的车辆检测、识别和跟踪，特别针对新加坡车牌和畸变校正。\n*   **权力的游戏之名：评估 LLM 如何根据姓名、种族和性别对学生进行地位排序 (92):** 大规模分析了 LLM 如何基于姓名（名字+姓氏）所暗示的性别和种族（特别是亚裔细分）来排序学生的地位（能力、领导力、经济潜力），发现存在偏见和分层现象。\n*   **视觉语言模型在神经心理学测试中表现出广泛的视觉缺陷 (93):** 使用 51 项神经心理学测试评估了三个 SOTA VLM，发现虽然物体识别能力强，但在低级和中级视觉能力（如方向、位置、连续性）方面存在显著缺陷。\n*   **ATLASv2: 边缘设备上 LLM 引导的自适应地标获取与导航 (94):** 提出 ATLASv2 系统，在 Jetson Nano 上集成微调的 TinyLLM、实时目标检测和路径规划，实现分层、多任务导航和操作，能动态识别并利用环境中的物体作为新地标。\n*   **通过学习可观测映射实现量子系统经典极限的神经网络仿真 (95):** 使用神经网络学习从初始期望值和普朗克常数到位置期望值时间演化的映射，以计算方式模拟量子谐振子在普朗克常数趋于零时的经典行为涌现。\n*   **观众参与的艺术：基于 LLM 的科学演讲薄片撷取 (96):** 应用“薄片撷取”（thin-slicing）理论，使用 LLM 评估科学演讲的完整记录稿和短片段（薄片），发现即使是很短的片段（<10%）也能高度预测整体评价，验证了 LLM 在此任务上的有效性。",
  "papers": [
    {
      "arxiv_id": "2504.11456v1",
      "title": "DeepMath-103K: A Large-Scale, Challenging, Decontaminated, and Verifiable Mathematical Dataset for Advancing Reasoning",
      "title_zh": "DeepMath-103K：用于推进推理的大规模、具挑战性、已净化且可验证的数学数据集\n",
      "authors": [
        "Zhiwei He",
        "Tian Liang",
        "Jiahao Xu",
        "Qiuzhi Liu",
        "Xingyu Chen",
        "Yue Wang",
        "Linfeng Song",
        "Dian Yu",
        "Zhenwen Liang",
        "Wenxuan Wang",
        "Zhuosheng Zhang",
        "Rui Wang",
        "Zhaopeng Tu",
        "Haitao Mi",
        "Dong Yu"
      ],
      "abstract": "The capacity for complex mathematical reasoning is a key benchmark for\nartificial intelligence. While reinforcement learning (RL) applied to LLMs\nshows promise, progress is significantly hindered by the lack of large-scale\ntraining data that is sufficiently challenging, possesses verifiable answer\nformats suitable for RL, and is free from contamination with evaluation\nbenchmarks. To address these limitations, we introduce DeepMath-103K, a new,\nlarge-scale dataset comprising approximately 103K mathematical problems,\nspecifically designed to train advanced reasoning models via RL. DeepMath-103K\nis curated through a rigorous pipeline involving source analysis, stringent\ndecontamination against numerous benchmarks, and filtering for high difficulty\n(primarily Levels 5-9), significantly exceeding existing open resources in\nchallenge. Each problem includes a verifiable final answer, enabling rule-based\nRL, and three distinct R1-generated solutions suitable for diverse training\nparadigms like supervised fine-tuning or distillation. Spanning a wide range of\nmathematical topics, DeepMath-103K promotes the development of generalizable\nreasoning. We demonstrate that models trained on DeepMath-103K achieve\nsignificant improvements on challenging mathematical benchmarks, validating its\neffectiveness. We release DeepMath-103K publicly to facilitate community\nprogress in building more capable AI reasoning systems:\nhttps://github.com/zwhe99/DeepMath.",
      "tldr_zh": "该论文介绍了DeepMath-103K，一个包含约103K数学问题的大规模数据集，旨在推动AI在数学推理方面的进展。该数据集专为通过强化学习(RL)训练高级推理模型而设计，具有挑战性高（难度等级主要为5-9）、答案可验证以及经过严格的反污染处理等特点。每个问题都包含一个可验证的最终答案和三个不同的R1生成的解决方案，适用于监督微调或知识蒸馏等多种训练范式。实验表明，在DeepMath-103K上训练的模型在具有挑战性的数学基准测试中取得了显著改进，验证了其有效性。该数据集已公开发布，以促进社区在构建更强大的AI推理系统方面的进展。\n",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "WIP",
      "pdf_url": "http://arxiv.org/pdf/2504.11456v1",
      "published_date": "2025-04-15 17:59:51 UTC",
      "updated_date": "2025-04-15 17:59:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:09:59.821502"
    },
    {
      "arxiv_id": "2504.11454v2",
      "title": "Elucidating the Design Space of Multimodal Protein Language Models",
      "title_zh": "解析多模态蛋白质语言模型的设计空间\n",
      "authors": [
        "Cheng-Yen Hsieh",
        "Xinyou Wang",
        "Daiheng Zhang",
        "Dongyu Xue",
        "Fei Ye",
        "Shujian Huang",
        "Zaixiang Zheng",
        "Quanquan Gu"
      ],
      "abstract": "Multimodal protein language models (PLMs) integrate sequence and token-based\nstructural information, serving as a powerful foundation for protein modeling,\ngeneration, and design. However, the reliance on tokenizing 3D structures into\ndiscrete tokens causes substantial loss of fidelity about fine-grained\nstructural details and correlations. In this paper, we systematically elucidate\nthe design space of multimodal PLMs to overcome their limitations. We identify\ntokenization loss and inaccurate structure token predictions by the PLMs as\nmajor bottlenecks. To address these, our proposed design space covers improved\ngenerative modeling, structure-aware architectures and representation learning,\nand data exploration. Our advancements approach finer-grained supervision,\ndemonstrating that token-based multimodal PLMs can achieve robust structural\nmodeling. The effective design methods dramatically improve the structure\ngeneration diversity, and notably, folding abilities of our 650M model by\nreducing the RMSD from 5.52 to 2.36 on PDB testset, even outperforming 3B\nbaselines and on par with the specialized folding models.",
      "tldr_zh": "本文深入研究了多模态蛋白质语言模型(PLMs)的设计空间，旨在克服其将3D结构离散化为token所造成的精度损失。研究指出，token化损失和PLMs对结构token的不准确预测是主要瓶颈。为了解决这些问题，论文提出了改进的生成建模、结构感知架构和表示学习以及数据探索等设计方向。实验表明，这些改进方法能够实现更精细的监督，显著提高结构生成的diversity和folding能力。具体而言，一个650M参数的模型在PDB测试集上的RMSD从5.52降低到2.36，甚至优于3B参数的基线模型，与专门的folding模型相当。\n",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.QM"
      ],
      "primary_category": "cs.LG",
      "comment": "Project Page: https://bytedance.github.io/dplm/dplm-2.1/",
      "pdf_url": "http://arxiv.org/pdf/2504.11454v2",
      "published_date": "2025-04-15 17:59:43 UTC",
      "updated_date": "2025-04-16 02:35:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:10:11.777384"
    },
    {
      "arxiv_id": "2504.11453v1",
      "title": "A Clean Slate for Offline Reinforcement Learning",
      "title_zh": "离线强化学习的全新开始\n",
      "authors": [
        "Matthew Thomas Jackson",
        "Uljad Berdica",
        "Jarek Liesen",
        "Shimon Whiteson",
        "Jakob Nicolaus Foerster"
      ],
      "abstract": "Progress in offline reinforcement learning (RL) has been impeded by ambiguous\nproblem definitions and entangled algorithmic designs, resulting in\ninconsistent implementations, insufficient ablations, and unfair evaluations.\nAlthough offline RL explicitly avoids environment interaction, prior methods\nfrequently employ extensive, undocumented online evaluation for hyperparameter\ntuning, complicating method comparisons. Moreover, existing reference\nimplementations differ significantly in boilerplate code, obscuring their core\nalgorithmic contributions. We address these challenges by first introducing a\nrigorous taxonomy and a transparent evaluation protocol that explicitly\nquantifies online tuning budgets. To resolve opaque algorithmic design, we\nprovide clean, minimalistic, single-file implementations of various model-free\nand model-based offline RL methods, significantly enhancing clarity and\nachieving substantial speed-ups. Leveraging these streamlined implementations,\nwe propose Unifloral, a unified algorithm that encapsulates diverse prior\napproaches within a single, comprehensive hyperparameter space, enabling\nalgorithm development in a shared hyperparameter space. Using Unifloral with\nour rigorous evaluation protocol, we develop two novel algorithms - TD3-AWR\n(model-free) and MoBRAC (model-based) - which substantially outperform\nestablished baselines. Our implementation is publicly available at\nhttps://github.com/EmptyJackson/unifloral.",
      "tldr_zh": "现有离线强化学习(Offline RL)研究存在问题定义模糊、算法设计复杂、实现不一致以及评估不公平等问题。该论文通过引入严格的分类体系和透明的评估协议来量化在线调参预算，解决了这些挑战。同时，论文提供了各种无模型和基于模型的离线RL方法的简洁、最小化的单文件实现，显著提高了清晰度并实现了加速。在此基础上，论文提出了Unifloral，一个统一的算法框架，它将不同的现有方法封装在一个共享的超参数空间中，从而促进算法开发。利用Unifloral和严格的评估协议，论文开发了两种新的算法——TD3-AWR (无模型) 和 MoBRAC (基于模型)，它们显著优于已有的基线方法。\n",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.11453v1",
      "published_date": "2025-04-15 17:59:05 UTC",
      "updated_date": "2025-04-15 17:59:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:10:23.711568"
    },
    {
      "arxiv_id": "2504.11442v1",
      "title": "TextArena",
      "title_zh": "TextArena\n",
      "authors": [
        "Leon Guertler",
        "Bobby Cheng",
        "Simon Yu",
        "Bo Liu",
        "Leshem Choshen",
        "Cheston Tan"
      ],
      "abstract": "TextArena is an open-source collection of competitive text-based games for\ntraining and evaluation of agentic behavior in Large Language Models (LLMs). It\nspans 57+ unique environments (including single-player, two-player, and\nmulti-player setups) and allows for easy evaluation of model capabilities via\nan online-play system (against humans and other submitted models) with\nreal-time TrueSkill scores. Traditional benchmarks rarely assess dynamic social\nskills such as negotiation, theory of mind, and deception, creating a gap that\nTextArena addresses. Designed with research, community and extensibility in\nmind, TextArena emphasizes ease of adding new games, adapting the framework,\ntesting models, playing against the models, and training models. Detailed\ndocumentation of environments, games, leaderboard, and examples are available\non https://github.com/LeonGuertler/TextArena and https://www.textarena.ai/.",
      "tldr_zh": "TextArena是一个开源的、基于文本的竞技游戏集合，旨在训练和评估大型语言模型(LLMs)中的智能体行为。它包含57+个独特环境（包括单人、双人和多人设置），并通过在线游戏系统（与人类和其他模型对抗）和实时TrueSkill评分，方便地评估模型能力。TextArena弥补了传统基准测试在评估谈判、心智理论和欺骗等动态社交技能方面的不足。该平台注重研究、社区和可扩展性，方便添加新游戏、调整框架、测试模型、与模型对战以及训练模型。\n",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.CL",
      "comment": "work in progress; 5 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.11442v1",
      "published_date": "2025-04-15 17:55:20 UTC",
      "updated_date": "2025-04-15 17:55:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:10:35.516333"
    },
    {
      "arxiv_id": "2504.11440v1",
      "title": "Greedy Restart Schedules: A Baseline for Dynamic Algorithm Selection on Numerical Black-box Optimization Problems",
      "title_zh": "贪婪重启调度：数值黑盒优化问题动态算法选择的基准\n",
      "authors": [
        "Lennart Schäpermeier"
      ],
      "abstract": "In many optimization domains, there are multiple different solvers that\ncontribute to the overall state-of-the-art, each performing better on some, and\nworse on other types of problem instances. Meta-algorithmic approaches, such as\ninstance-based algorithm selection, configuration and scheduling, aim to close\nthis gap by extracting the most performance possible from a set of\n(configurable) optimizers. In this context, the best performing individual\nalgorithms are often hand-crafted hybrid heuristics which perform many restarts\nof fast local optimization approaches. However, data-driven techniques to\ncreate optimized restart schedules have not yet been extensively studied.\n  Here, we present a simple scheduling approach that iteratively selects the\nalgorithm performing best on the distribution of unsolved training problems at\ntime of selection, resulting in a problem-independent solver schedule. We\ndemonstrate our approach using well-known optimizers from numerical black-box\noptimization on the BBOB testbed, bridging much of the gap between single and\nvirtual best solver from the original portfolio across various evaluation\nprotocols. Our greedy restart schedule presents a powerful baseline for more\ncomplex dynamic algorithm selection models.",
      "tldr_zh": "该论文提出了一种简单的贪婪重启调度方法，用于解决数值黑盒优化问题中的动态算法选择问题。该方法通过迭代选择在未解决的训练问题分布上表现最佳的算法，从而生成与问题无关的求解器调度。在BBOB测试集上，使用数值黑盒优化中常用的优化器进行实验，结果表明该方法在各种评估协议下，弥合了单一求解器和虚拟最佳求解器之间的差距。该贪婪重启调度为更复杂的动态算法选择模型提供了一个强大的基线。\n",
      "categories": [
        "math.OC",
        "cs.AI"
      ],
      "primary_category": "math.OC",
      "comment": "Author version. Accepted as full paper to be presented at the GECCO\n  2025 conference, July 14-18, M\\'alaga, Spain. (DOI 10.1145/3712256.3726408)",
      "pdf_url": "http://arxiv.org/pdf/2504.11440v1",
      "published_date": "2025-04-15 17:54:21 UTC",
      "updated_date": "2025-04-15 17:54:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:10:47.413480"
    },
    {
      "arxiv_id": "2504.11431v1",
      "title": "Masculine Defaults via Gendered Discourse in Podcasts and Large Language Models",
      "title_zh": "播客和大型语言模型中通过性别化话语体现的男性预设\n",
      "authors": [
        "Maria Teleki",
        "Xiangjue Dong",
        "Haoran Liu",
        "James Caverlee"
      ],
      "abstract": "Masculine defaults are widely recognized as a significant type of gender\nbias, but they are often unseen as they are under-researched. Masculine\ndefaults involve three key parts: (i) the cultural context, (ii) the masculine\ncharacteristics or behaviors, and (iii) the reward for, or simply acceptance\nof, those masculine characteristics or behaviors. In this work, we study\ndiscourse-based masculine defaults, and propose a twofold framework for (i) the\nlarge-scale discovery and analysis of gendered discourse words in spoken\ncontent via our Gendered Discourse Correlation Framework (GDCF); and (ii) the\nmeasurement of the gender bias associated with these gendered discourse words\nin LLMs via our Discourse Word-Embedding Association Test (D-WEAT). We focus\nour study on podcasts, a popular and growing form of social media, analyzing\n15,117 podcast episodes. We analyze correlations between gender and discourse\nwords -- discovered via LDA and BERTopic -- to automatically form gendered\ndiscourse word lists. We then study the prevalence of these gendered discourse\nwords in domain-specific contexts, and find that gendered discourse-based\nmasculine defaults exist in the domains of business, technology/politics, and\nvideo games. Next, we study the representation of these gendered discourse\nwords from a state-of-the-art LLM embedding model from OpenAI, and find that\nthe masculine discourse words have a more stable and robust representation than\nthe feminine discourse words, which may result in better system performance on\ndownstream tasks for men. Hence, men are rewarded for their discourse patterns\nwith better system performance by one of the state-of-the-art language models\n-- and this embedding disparity is a representational harm and a masculine\ndefault.",
      "tldr_zh": "该研究关注性别偏见中一种未被充分研究的形式：男性默认设置(Masculine Defaults)。论文提出了一个双重框架，用于大规模发现和分析语音内容中的性别化语篇词汇。该框架包含性别化语篇关联框架(GDCF)和语篇词嵌入关联测试(D-WEAT)。研究分析了15117集播客节目，发现商业、科技/政治和视频游戏领域存在基于性别化语篇的男性默认设置。通过分析OpenAI的LLM嵌入模型，发现男性语篇词汇比女性语篇词汇具有更稳定和鲁棒的表示，这可能导致男性在下游任务中获得更好的系统性能，从而强化了男性默认设置。\n",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.LG",
        "cs.SI"
      ],
      "primary_category": "cs.CL",
      "comment": "To appear in ICWSM 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.11431v1",
      "published_date": "2025-04-15 17:41:54 UTC",
      "updated_date": "2025-04-15 17:41:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:10:59.781094"
    },
    {
      "arxiv_id": "2504.11426v1",
      "title": "A Dual-Space Framework for General Knowledge Distillation of Large Language Models",
      "title_zh": "一种用于大语言模型通用知识蒸馏的双空间框架\n",
      "authors": [
        "Xue Zhang",
        "Songming Zhang",
        "Yunlong Liang",
        "Fandong Meng",
        "Yufeng Chen",
        "Jinan Xu",
        "Jie Zhou"
      ],
      "abstract": "Knowledge distillation (KD) is a promising solution to compress large\nlanguage models (LLMs) by transferring their knowledge to smaller models.\nDuring this process, white-box KD methods usually minimize the distance between\nthe output distributions of the teacher model and the student model to transfer\nmore information. However, we reveal that the current white-box KD framework\nexhibits two limitations: a) bridging probability distributions from different\noutput spaces will limit the similarity between the teacher model and the\nstudent model; b) this framework cannot be applied to LLMs with different\nvocabularies. One of the root causes for these limitations is that the\ndistributions from the teacher and the student for KD are output by different\nprediction heads, which yield distributions in different output spaces and\ndimensions. Therefore, in this paper, we propose a dual-space knowledge\ndistillation (DSKD) framework that unifies the prediction heads of the teacher\nand the student models for KD. Specifically, we first introduce two projectors\nwith ideal initialization to project the teacher/student hidden states into the\nstudent/teacher representation spaces. After this, the hidden states from\ndifferent models can share the same head and unify the output spaces of the\ndistributions. Furthermore, we develop an exact token alignment (ETA) algorithm\nto align the same tokens in two differently-tokenized sequences. Based on the\nabove, our DSKD framework is a general KD framework that supports both\noff-policy and on-policy KD, and KD between any two LLMs regardless of their\nvocabularies. Extensive experiments on instruction-following, mathematical\nreasoning, and code generation benchmarks show that DSKD significantly\noutperforms existing methods based on the current white-box KD framework and\nsurpasses other cross-tokenizer KD methods for LLMs with different\nvocabularies.",
      "tldr_zh": "该论文提出了一种双空间知识蒸馏（DSKD）框架，旨在解决现有知识蒸馏方法在压缩大型语言模型（LLMs）时存在的局限性，即不同输出空间概率分布的桥接限制了teacher和student模型的相似性，且无法应用于具有不同词汇表的LLMs。DSKD框架通过引入投影器将teacher和student模型的隐藏状态投影到student/teacher表示空间，从而统一预测头和输出空间。此外，论文还开发了一种精确token对齐（ETA）算法，用于对齐不同分词序列中的相同token。实验结果表明，DSKD在指令跟随、数学推理和代码生成基准测试中显著优于现有方法，并超越了其他跨分词器KD方法。该框架支持off-policy和on-policy KD，以及任意两个LLMs之间的KD，不受词汇表限制。\n",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "19 pages, 9 figures, 11 tables, under review. Code is available at:\n  https://github.com/songmzhang/DSKDv2. arXiv admin note: text overlap with\n  arXiv:2406.17328",
      "pdf_url": "http://arxiv.org/pdf/2504.11426v1",
      "published_date": "2025-04-15 17:38:47 UTC",
      "updated_date": "2025-04-15 17:38:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:11:11.832559"
    },
    {
      "arxiv_id": "2504.11423v1",
      "title": "ADT: Tuning Diffusion Models with Adversarial Supervision",
      "title_zh": "ADT：使用对抗监督调整扩散模型\n",
      "authors": [
        "Dazhong Shen",
        "Guanglu Song",
        "Yi Zhang",
        "Bingqi Ma",
        "Lujundong Li",
        "Dongzhi Jiang",
        "Zhuofan Zong",
        "Yu Liu"
      ],
      "abstract": "Diffusion models have achieved outstanding image generation by reversing a\nforward noising process to approximate true data distributions. During\ntraining, these models predict diffusion scores from noised versions of true\nsamples in a single forward pass, while inference requires iterative denoising\nstarting from white noise. This training-inference divergences hinder the\nalignment between inference and training data distributions, due to potential\nprediction biases and cumulative error accumulation. To address this problem,\nwe propose an intuitive but effective fine-tuning framework, called Adversarial\nDiffusion Tuning (ADT), by stimulating the inference process during\noptimization and aligning the final outputs with training data by adversarial\nsupervision. Specifically, to achieve robust adversarial training, ADT features\na siamese-network discriminator with a fixed pre-trained backbone and\nlightweight trainable parameters, incorporates an image-to-image sampling\nstrategy to smooth discriminative difficulties, and preserves the original\ndiffusion loss to prevent discriminator hacking. In addition, we carefully\nconstrain the backward-flowing path for back-propagating gradients along the\ninference path without incurring memory overload or gradient explosion.\nFinally, extensive experiments on Stable Diffusion models (v1.5, XL, and v3),\ndemonstrate that ADT significantly improves both distribution alignment and\nimage quality.",
      "tldr_zh": "该论文提出了对抗扩散调整(ADT)框架，旨在解决扩散模型训练和推理过程中的差异性问题。ADT通过在优化过程中模拟推理过程，并利用对抗监督将最终输出与训练数据对齐。具体来说，ADT采用 Siamese 网络判别器，结合图像到图像的采样策略，并保留原始扩散损失，以实现鲁棒的对抗训练。此外，论文还精心设计了反向传播路径，避免了内存过载或梯度爆炸。在 Stable Diffusion 模型上的实验结果表明，ADT 显著提高了分布对齐和图像质量。\n",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.11423v1",
      "published_date": "2025-04-15 17:37:50 UTC",
      "updated_date": "2025-04-15 17:37:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:11:23.557788"
    },
    {
      "arxiv_id": "2504.11419v1",
      "title": "Embodied World Models Emerge from Navigational Task in Open-Ended Environments",
      "title_zh": "具身世界模型从开放环境中导航任务涌现\n",
      "authors": [
        "Li Jin",
        "Liu Jia"
      ],
      "abstract": "Understanding how artificial systems can develop spatial awareness and\nreasoning has long been a challenge in AI research. Traditional models often\nrely on passive observation, but embodied cognition theory suggests that deeper\nunderstanding emerges from active interaction with the environment. This study\ninvestigates whether neural networks can autonomously internalize spatial\nconcepts through interaction, focusing on planar navigation tasks. Using Gated\nRecurrent Units (GRUs) combined with Meta-Reinforcement Learning (Meta-RL), we\nshow that agents can learn to encode spatial properties like direction,\ndistance, and obstacle avoidance. We introduce Hybrid Dynamical Systems (HDS)\nto model the agent-environment interaction as a closed dynamical system,\nrevealing stable limit cycles that correspond to optimal navigation strategies.\nRidge Representation allows us to map navigation paths into a fixed-dimensional\nbehavioral space, enabling comparison with neural states. Canonical Correlation\nAnalysis (CCA) confirms strong alignment between these representations,\nsuggesting that the agent's neural states actively encode spatial knowledge.\nIntervention experiments further show that specific neural dimensions are\ncausally linked to navigation performance. This work provides an approach to\nbridging the gap between action and perception in AI, offering new insights\ninto building adaptive, interpretable models that can generalize across complex\nenvironments. The causal validation of neural representations also opens new\navenues for understanding and controlling the internal mechanisms of AI\nsystems, pushing the boundaries of how machines learn and reason in dynamic,\nreal-world scenarios.",
      "tldr_zh": "该研究探索了人工智能系统如何在开放环境中通过导航任务自主发展空间感知和推理能力。研究人员使用GRU和元强化学习(Meta-RL)训练智能体，使其学习编码方向、距离和避障等空间属性。他们引入混合动力系统(HDS)将智能体与环境的交互建模为闭环动力系统，并使用Ridge Representation将导航路径映射到固定维度的行为空间。通过典型相关分析(CCA)发现，智能体的神经状态与行为空间之间存在强烈的对应关系，表明智能体的神经状态主动编码了空间知识。干预实验进一步证实了特定神经维度与导航性能之间存在因果关系。该研究为构建自适应、可解释的模型提供了新思路，并为理解和控制人工智能系统的内部机制开辟了新途径。\n",
      "categories": [
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.AI",
      "comment": "Research on explainable meta-reinforcement learning AI",
      "pdf_url": "http://arxiv.org/pdf/2504.11419v1",
      "published_date": "2025-04-15 17:35:13 UTC",
      "updated_date": "2025-04-15 17:35:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:11:35.862346"
    },
    {
      "arxiv_id": "2504.11412v1",
      "title": "Measures of Variability for Risk-averse Policy Gradient",
      "title_zh": "风险规避策略梯度的变异性度量\n",
      "authors": [
        "Yudong Luo",
        "Yangchen Pan",
        "Jiaqi Tan",
        "Pascal Poupart"
      ],
      "abstract": "Risk-averse reinforcement learning (RARL) is critical for decision-making\nunder uncertainty, which is especially valuable in high-stake applications.\nHowever, most existing works focus on risk measures, e.g., conditional\nvalue-at-risk (CVaR), while measures of variability remain underexplored. In\nthis paper, we comprehensively study nine common measures of variability,\nnamely Variance, Gini Deviation, Mean Deviation, Mean-Median Deviation,\nStandard Deviation, Inter-Quantile Range, CVaR Deviation, Semi_Variance, and\nSemi_Standard Deviation. Among them, four metrics have not been previously\nstudied in RARL. We derive policy gradient formulas for these unstudied\nmetrics, improve gradient estimation for Gini Deviation, analyze their gradient\nproperties, and incorporate them with the REINFORCE and PPO frameworks to\npenalize the dispersion of returns.\n  Our empirical study reveals that variance-based metrics lead to unstable\npolicy updates. In contrast, CVaR Deviation and Gini Deviation show consistent\nperformance across different randomness and evaluation domains, achieving high\nreturns while effectively learning risk-averse policies. Mean Deviation and\nSemi_Standard Deviation are also competitive across different scenarios. This\nwork provides a comprehensive overview of variability measures in RARL,\noffering practical insights for risk-aware decision-making and guiding future\nresearch on risk metrics and RARL algorithms.",
      "tldr_zh": "该论文深入研究了风险规避强化学习(RARL)中九种常见的变异性度量，包括方差、Gini偏差、平均偏差等，其中四种度量是首次在RARL中进行研究。论文推导了这些新度量的策略梯度公式，改进了Gini偏差的梯度估计，分析了它们的梯度特性，并将它们与REINFORCE和PPO框架结合，以惩罚回报的分散性。实验结果表明，基于方差的度量导致不稳定的策略更新，而CVaR偏差和Gini偏差在不同随机性和评估领域表现稳定，在实现高回报的同时有效地学习风险规避策略。该研究为RARL中的变异性度量提供了一个全面的概述，为风险感知决策提供了实践见解，并为风险度量和RARL算法的未来研究提供了指导。\n",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.11412v1",
      "published_date": "2025-04-15 17:28:15 UTC",
      "updated_date": "2025-04-15 17:28:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:11:47.964320"
    },
    {
      "arxiv_id": "2504.11406v1",
      "title": "Multi-level Cellular Automata for FLIM networks",
      "title_zh": "用于 FLIM 网络的多层细胞自动机\n",
      "authors": [
        "Felipe Crispim Salvagnini",
        "Jancarlo F. Gomes",
        "Cid A. N. Santos",
        "Silvio Jamil F. Guimarães",
        "Alexandre X. Falcão"
      ],
      "abstract": "The necessity of abundant annotated data and complex network architectures\npresents a significant challenge in deep-learning Salient Object Detection\n(deep SOD) and across the broader deep-learning landscape. This challenge is\nparticularly acute in medical applications in developing countries with limited\ncomputational resources. Combining modern and classical techniques offers a\npath to maintaining competitive performance while enabling practical\napplications. Feature Learning from Image Markers (FLIM) methodology empowers\nexperts to design convolutional encoders through user-drawn markers, with\nfilters learned directly from these annotations. Recent findings demonstrate\nthat coupling a FLIM encoder with an adaptive decoder creates a flyweight\nnetwork suitable for SOD, requiring significantly fewer parameters than\nlightweight models and eliminating the need for backpropagation. Cellular\nAutomata (CA) methods have proven successful in data-scarce scenarios but\nrequire proper initialization -- typically through user input, priors, or\nrandomness. We propose a practical intersection of these approaches: using FLIM\nnetworks to initialize CA states with expert knowledge without requiring user\ninteraction for each image. By decoding features from each level of a FLIM\nnetwork, we can initialize multiple CAs simultaneously, creating a multi-level\nframework. Our method leverages the hierarchical knowledge encoded across\ndifferent network layers, merging multiple saliency maps into a high-quality\nfinal output that functions as a CA ensemble. Benchmarks across two challenging\nmedical datasets demonstrate the competitiveness of our multi-level CA approach\ncompared to established models in the deep SOD literature.",
      "tldr_zh": "这篇论文提出了一种用于显著目标检测（SOD）的多层细胞自动机（CA）方法，旨在解决深度学习SOD中对大量标注数据和复杂网络架构的依赖问题，尤其是在计算资源有限的医学应用中。该方法利用图像标记特征学习（FLIM）网络，通过专家设计的标记学习卷积编码器，并从FLIM网络的每一层解码特征来初始化多个CA，构建一个多层框架。该框架能够融合不同网络层级的层次化知识，将多个显著性图合并成一个高质量的最终输出，相当于一个CA集成。在两个具有挑战性的医学数据集上的基准测试表明，该多层CA方法与深度SOD文献中已建立的模型相比具有竞争力。\n",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.11406v1",
      "published_date": "2025-04-15 17:22:24 UTC",
      "updated_date": "2025-04-15 17:22:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:11:59.833578"
    },
    {
      "arxiv_id": "2504.11389v1",
      "title": "VideoPanda: Video Panoramic Diffusion with Multi-view Attention",
      "title_zh": "VideoPanda：基于多视角注意力的视频全景扩散模型\n",
      "authors": [
        "Kevin Xie",
        "Amirmojtaba Sabour",
        "Jiahui Huang",
        "Despoina Paschalidou",
        "Greg Klar",
        "Umar Iqbal",
        "Sanja Fidler",
        "Xiaohui Zeng"
      ],
      "abstract": "High resolution panoramic video content is paramount for immersive\nexperiences in Virtual Reality, but is non-trivial to collect as it requires\nspecialized equipment and intricate camera setups. In this work, we introduce\nVideoPanda, a novel approach for synthesizing 360$^\\circ$ videos conditioned on\ntext or single-view video data. VideoPanda leverages multi-view attention\nlayers to augment a video diffusion model, enabling it to generate consistent\nmulti-view videos that can be combined into immersive panoramic content.\nVideoPanda is trained jointly using two conditions: text-only and single-view\nvideo, and supports autoregressive generation of long-videos. To overcome the\ncomputational burden of multi-view video generation, we randomly subsample the\nduration and camera views used during training and show that the model is able\nto gracefully generalize to generating more frames during inference. Extensive\nevaluations on both real-world and synthetic video datasets demonstrate that\nVideoPanda generates more realistic and coherent 360$^\\circ$ panoramas across\nall input conditions compared to existing methods. Visit the project website at\nhttps://research-staging.nvidia.com/labs/toronto-ai/VideoPanda/ for results.",
      "tldr_zh": "VideoPanda 是一种新颖的360°视频合成方法，它以文本或单视角视频数据为条件，利用多视角注意力层增强视频扩散模型，从而生成一致的多视角视频，并可组合成沉浸式全景内容。该模型采用文本和单视角视频两种条件进行联合训练，并支持长视频的自回归生成。为了克服多视角视频生成中的计算负担，VideoPanda 在训练过程中随机抽取时间和相机视角，并展示了模型在推理过程中能够很好地泛化到生成更多帧。在真实和合成视频数据集上的大量评估表明，与现有方法相比，VideoPanda 能够生成更逼真和连贯的360°全景视频。\n",
      "categories": [
        "cs.GR",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.GR",
      "comment": "Project website at\n  https://research-staging.nvidia.com/labs/toronto-ai/VideoPanda/",
      "pdf_url": "http://arxiv.org/pdf/2504.11389v1",
      "published_date": "2025-04-15 16:58:15 UTC",
      "updated_date": "2025-04-15 16:58:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:12:11.694964"
    },
    {
      "arxiv_id": "2504.11386v1",
      "title": "Trajectory Encoding Temporal Graph Networks",
      "title_zh": "轨迹编码时序图网络\n",
      "authors": [
        "Jiafeng Xiong",
        "Rizos Sakellariou"
      ],
      "abstract": "Temporal Graph Networks (TGNs) have demonstrated significant success in\ndynamic graph tasks such as link prediction and node classification. Both tasks\ncomprise transductive settings, where the model predicts links among known\nnodes, and in inductive settings, where it generalises learned patterns to\npreviously unseen nodes. Existing TGN designs face a dilemma under these dual\nscenarios. Anonymous TGNs, which rely solely on temporal and structural\ninformation, offer strong inductive generalisation but struggle to distinguish\nknown nodes. In contrast, non-anonymous TGNs leverage node features to excel in\ntransductive tasks yet fail to adapt to new nodes. To address this challenge,\nwe propose Trajectory Encoding TGN (TETGN). Our approach introduces\nautomatically expandable node identifiers (IDs) as learnable temporal\npositional features and performs message passing over these IDs to capture each\nnode's historical context. By integrating this trajectory-aware module with a\nstandard TGN using multi-head attention, TETGN effectively balances\ntransductive accuracy with inductive generalisation. Experimental results on\nthree real-world datasets show that TETGN significantly outperforms strong\nbaselines on both link prediction and node classification tasks, demonstrating\nits ability to unify the advantages of anonymous and non-anonymous models for\ndynamic graph learning.",
      "tldr_zh": "本文提出了Trajectory Encoding Temporal Graph Networks (TETGN)，旨在解决现有TGNs在动态图任务中，transductive和inductive场景下的两难问题。TETGN引入了自动扩展的节点标识符(IDs)作为可学习的时间位置特征，并通过在这些IDs上进行消息传递来捕获每个节点的历史上下文。通过将这种轨迹感知模块与使用多头注意力的标准TGN集成，TETGN有效地平衡了transductive准确性和inductive泛化能力。在三个真实世界数据集上的实验结果表明，TETGN在链接预测和节点分类任务上显著优于强大的基线模型，证明了其统一匿名和非匿名模型优势的能力，适用于动态图学习。\n",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.11386v1",
      "published_date": "2025-04-15 16:57:09 UTC",
      "updated_date": "2025-04-15 16:57:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:12:23.700071"
    },
    {
      "arxiv_id": "2504.11374v1",
      "title": "A Winner-Takes-All Mechanism for Event Generation",
      "title_zh": "一种用于事件生成的胜者全得机制\n",
      "authors": [
        "Yongkang Huo",
        "Fuvio Forni",
        "Rodolphe Sepulchre"
      ],
      "abstract": "We present a novel framework for central pattern generator design that\nleverages the intrinsic rebound excitability of neurons in combination with\nwinner-takes-all computation. Our approach unifies decision-making and rhythmic\npattern generation within a simple yet powerful network architecture that\nemploys all-to-all inhibitory connections enhanced by designable excitatory\ninteractions. This design offers significant advantages regarding ease of\nimplementation, adaptability, and robustness. We demonstrate its efficacy\nthrough a ring oscillator model, which exhibits adaptive phase and frequency\nmodulation, making the framework particularly promising for applications in\nneuromorphic systems and robotics.",
      "tldr_zh": "本文提出了一种新颖的中央模式发生器(central pattern generator)设计框架，该框架利用神经元的内在反弹兴奋性(rebound excitability)与胜者全得(winner-takes-all)计算相结合。该方法在一个简单而强大的网络架构中统一了决策制定和节律模式生成，该架构采用全连接抑制连接，并通过可设计的兴奋性相互作用增强。这种设计在易于实现、适应性和鲁棒性方面具有显著优势。通过环形振荡器模型验证了其有效性，该模型表现出适应性相位和频率调制，使该框架在神经形态系统和机器人技术应用中具有广阔的应用前景。\n",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.11374v1",
      "published_date": "2025-04-15 16:40:37 UTC",
      "updated_date": "2025-04-15 16:40:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:12:35.811531"
    },
    {
      "arxiv_id": "2504.11369v1",
      "title": "OpenTuringBench: An Open-Model-based Benchmark and Framework for Machine-Generated Text Detection and Attribution",
      "title_zh": "OpenTuringBench：一个用于机器生成文本检测和归因的基于开放模型的基准和框架\n",
      "authors": [
        "Lucio La Cava",
        "Andrea Tagarelli"
      ],
      "abstract": "Open Large Language Models (OLLMs) are increasingly leveraged in generative\nAI applications, posing new challenges for detecting their outputs. We propose\nOpenTuringBench, a new benchmark based on OLLMs, designed to train and evaluate\nmachine-generated text detectors on the Turing Test and Authorship Attribution\nproblems. OpenTuringBench focuses on a representative set of OLLMs, and\nfeatures a number of challenging evaluation tasks, including\nhuman/machine-manipulated texts, out-of-domain texts, and texts from previously\nunseen models. We also provide OTBDetector, a contrastive learning framework to\ndetect and attribute OLLM-based machine-generated texts. Results highlight the\nrelevance and varying degrees of difficulty of the OpenTuringBench tasks, with\nour detector achieving remarkable capabilities across the various tasks and\noutperforming most existing detectors. Resources are available on the\nOpenTuringBench Hugging Face repository at\nhttps://huggingface.co/datasets/MLNTeam-Unical/OpenTuringBench",
      "tldr_zh": "OpenTuringBench是一个新的基准测试，旨在评估和训练用于检测机器生成文本的检测器，特别是基于开放大语言模型(OLLMs)生成的文本。该基准测试涵盖了图灵测试和作者身份归属问题，并包含了一系列具有挑战性的评估任务，例如人工/机器修改的文本、领域外文本和来自先前未见模型的文本。此外，论文还提出了OTBDetector，一个基于对比学习的框架，用于检测和归属基于OLLM的机器生成文本。实验结果表明，OTBDetector在各种任务中表现出色，优于现有的大多数检测器。该资源可在Hugging Face仓库中获取。\n",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.HC",
        "physics.soc-ph"
      ],
      "primary_category": "cs.CL",
      "comment": "Under review with ARR",
      "pdf_url": "http://arxiv.org/pdf/2504.11369v1",
      "published_date": "2025-04-15 16:36:14 UTC",
      "updated_date": "2025-04-15 16:36:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:12:47.919654"
    },
    {
      "arxiv_id": "2504.11364v1",
      "title": "Teaching Large Language Models to Reason through Learning and Forgetting",
      "title_zh": "通过学习与遗忘来教导大型语言模型进行推理\n",
      "authors": [
        "Tianwei Ni",
        "Allen Nie",
        "Sapana Chaudhary",
        "Yao Liu",
        "Huzefa Rangwala",
        "Rasool Fakoor"
      ],
      "abstract": "Leveraging inference-time search in large language models has proven\neffective in further enhancing a trained model's capability to solve complex\nmathematical and reasoning problems. However, this approach significantly\nincreases computational costs and inference time, as the model must generate\nand evaluate multiple candidate solutions to identify a viable reasoning path.\nTo address this, we propose an effective approach that integrates search\ncapabilities directly into the model by fine-tuning it using both successful\n(learning) and failed reasoning paths (forgetting) derived from diverse search\nmethods. While fine-tuning the model with these data might seem\nstraightforward, we identify a critical issue: the model's search capability\ntends to degrade rapidly if fine-tuning is performed naively. We show that this\ndegradation can be substantially mitigated by employing a smaller learning\nrate. Extensive experiments on the challenging Game-of-24 and Countdown\nmathematical reasoning benchmarks show that our approach not only outperforms\nboth standard fine-tuning and inference-time search baselines but also\nsignificantly reduces inference time by 180$\\times$.",
      "tldr_zh": "这篇论文提出了一种通过学习和遗忘来教导大型语言模型(LLMs)进行推理的方法，旨在将推理时搜索的能力直接集成到模型中，以解决推理时搜索计算成本高的问题。该方法通过使用从不同搜索方法中获得的成功和失败的推理路径对模型进行微调。研究发现，直接微调会导致模型搜索能力下降，通过采用较小的学习率可以有效缓解这个问题。在Game-of-24和Countdown数学推理基准测试上的实验表明，该方法优于标准微调和推理时搜索基线，并将推理时间减少了180倍。\n",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.11364v1",
      "published_date": "2025-04-15 16:30:02 UTC",
      "updated_date": "2025-04-15 16:30:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:12:59.768825"
    },
    {
      "arxiv_id": "2504.11358v1",
      "title": "DataSentinel: A Game-Theoretic Detection of Prompt Injection Attacks",
      "title_zh": "DataSentinel：一种基于博弈论的提示注入攻击检测方法\n",
      "authors": [
        "Yupei Liu",
        "Yuqi Jia",
        "Jinyuan Jia",
        "Dawn Song",
        "Neil Zhenqiang Gong"
      ],
      "abstract": "LLM-integrated applications and agents are vulnerable to prompt injection\nattacks, where an attacker injects prompts into their inputs to induce\nattacker-desired outputs. A detection method aims to determine whether a given\ninput is contaminated by an injected prompt. However, existing detection\nmethods have limited effectiveness against state-of-the-art attacks, let alone\nadaptive ones. In this work, we propose DataSentinel, a game-theoretic method\nto detect prompt injection attacks. Specifically, DataSentinel fine-tunes an\nLLM to detect inputs contaminated with injected prompts that are strategically\nadapted to evade detection. We formulate this as a minimax optimization\nproblem, with the objective of fine-tuning the LLM to detect strong adaptive\nattacks. Furthermore, we propose a gradient-based method to solve the minimax\noptimization problem by alternating between the inner max and outer min\nproblems. Our evaluation results on multiple benchmark datasets and LLMs show\nthat DataSentinel effectively detects both existing and adaptive prompt\ninjection attacks.",
      "tldr_zh": "该论文提出了DataSentinel，一种基于博弈论的方法，用于检测提示注入攻击。DataSentinel通过微调LLM来检测被注入提示污染的输入，这些注入提示经过策略性调整以逃避检测。该方法将检测问题建模为一个minimax优化问题，旨在微调LLM以检测强大的自适应攻击。通过梯度方法交替求解内部最大化和外部最小化问题。在多个基准数据集和LLM上的评估结果表明，DataSentinel能够有效地检测现有和自适应的提示注入攻击。\n",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "To appear in IEEE Symposium on Security and Privacy, 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.11358v1",
      "published_date": "2025-04-15 16:26:21 UTC",
      "updated_date": "2025-04-15 16:26:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:13:11.584390"
    },
    {
      "arxiv_id": "2504.11355v1",
      "title": "Neural Networks for on-chip Model Predictive Control: a Method to Build Optimized Training Datasets and its application to Type-1 Diabetes",
      "title_zh": "用于片上模型预测控制的神经网络：构建优化训练数据集的方法及其在 1 型糖尿病中的应用\n",
      "authors": [
        "Alberto Castillo",
        "Elliot Pryor",
        "Anas El Fathi",
        "Boris Kovatchev",
        "Marc Breton"
      ],
      "abstract": "Training Neural Networks (NNs) to behave as Model Predictive Control (MPC)\nalgorithms is an effective way to implement them in constrained embedded\ndevices. By collecting large amounts of input-output data, where inputs\nrepresent system states and outputs are MPC-generated control actions, NNs can\nbe trained to replicate MPC behavior at a fraction of the computational cost.\nHowever, although the composition of the training data critically influences\nthe final NN accuracy, methods for systematically optimizing it remain\nunderexplored. In this paper, we introduce the concept of Optimally-Sampled\nDatasets (OSDs) as ideal training sets and present an efficient algorithm for\ngenerating them. An OSD is a parametrized subset of all the available data that\n(i) preserves existing MPC information up to a certain numerical resolution,\n(ii) avoids duplicate or near-duplicate states, and (iii) becomes saturated or\ncomplete. We demonstrate the effectiveness of OSDs by training NNs to replicate\nthe University of Virginia's MPC algorithm for automated insulin delivery in\nType-1 Diabetes, achieving a four-fold improvement in final accuracy. Notably,\ntwo OSD-trained NNs received regulatory clearance for clinical testing as the\nfirst NN-based control algorithm for direct human insulin dosing. This\nmethodology opens new pathways for implementing advanced optimizations on\nresource-constrained embedded platforms, potentially revolutionizing how\ncomplex algorithms are deployed.",
      "tldr_zh": "该论文提出了一种利用神经网络(NNs)在片上实现模型预测控制(MPC)的方法，重点在于构建优化的训练数据集。核心思想是通过训练NNs来模仿MPC算法的行为，从而在资源受限的嵌入式设备上以更低的计算成本实现MPC。论文引入了最优采样数据集(Optimally-Sampled Datasets, OSDs)的概念，并提出了一种高效的OSD生成算法，该算法能够保留MPC信息、避免重复状态并达到饱和。通过在1型糖尿病的自动胰岛素递送MPC算法上进行实验，证明了OSD的有效性，最终精度提高了四倍。该方法为在资源受限平台上部署高级优化算法开辟了新途径。\n",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.11355v1",
      "published_date": "2025-04-15 16:25:06 UTC",
      "updated_date": "2025-04-15 16:25:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:13:23.858767"
    },
    {
      "arxiv_id": "2504.11354v1",
      "title": "Kimina-Prover Preview: Towards Large Formal Reasoning Models with Reinforcement Learning",
      "title_zh": "Kimina-Prover Preview：迈向基于强化学习的大型形式化推理模型\n",
      "authors": [
        "Haiming Wang",
        "Mert Unsal",
        "Xiaohan Lin",
        "Mantas Baksys",
        "Junqi Liu",
        "Marco Dos Santos",
        "Flood Sung",
        "Marina Vinyes",
        "Zhenzhe Ying",
        "Zekai Zhu",
        "Jianqiao Lu",
        "Hugues de Saxcé",
        "Bolton Bailey",
        "Chendong Song",
        "Chenjun Xiao",
        "Dehao Zhang",
        "Ebony Zhang",
        "Frederick Pu",
        "Han Zhu",
        "Jiawei Liu",
        "Jonas Bayer",
        "Julien Michel",
        "Longhui Yu",
        "Léo Dreyfus-Schmidt",
        "Lewis Tunstall",
        "Luigi Pagani",
        "Moreira Machado",
        "Pauline Bourigault",
        "Ran Wang",
        "Stanislas Polu",
        "Thibaut Barroyer",
        "Wen-Ding Li",
        "Yazhe Niu",
        "Yann Fleureau",
        "Yangyang Hu",
        "Zhouliang Yu",
        "Zihan Wang",
        "Zhilin Yang",
        "Zhengying Liu",
        "Jia Li"
      ],
      "abstract": "We introduce Kimina-Prover Preview, a large language model that pioneers a\nnovel reasoning-driven exploration paradigm for formal theorem proving, as\nshowcased in this preview release. Trained with a large-scale reinforcement\nlearning pipeline from Qwen2.5-72B, Kimina-Prover demonstrates strong\nperformance in Lean 4 proof generation by employing a structured reasoning\npattern we term \\textit{formal reasoning pattern}. This approach allows the\nmodel to emulate human problem-solving strategies in Lean, iteratively\ngenerating and refining proof steps. Kimina-Prover sets a new state-of-the-art\non the miniF2F benchmark, reaching 80.7% with pass@8192. Beyond improved\nbenchmark performance, our work yields several key insights: (1) Kimina-Prover\nexhibits high sample efficiency, delivering strong results even with minimal\nsampling (pass@1) and scaling effectively with computational budget, stemming\nfrom its unique reasoning pattern and RL training; (2) we demonstrate clear\nperformance scaling with model size, a trend previously unobserved for neural\ntheorem provers in formal mathematics; (3) the learned reasoning style,\ndistinct from traditional search algorithms, shows potential to bridge the gap\nbetween formal verification and informal mathematical intuition. We open source\ndistilled versions with 1.5B and 7B parameters of Kimina-Prover",
      "tldr_zh": "该论文介绍了Kimina-Prover Preview，一个基于Qwen2.5-72B训练的大型语言模型，它采用了一种新颖的推理驱动探索范式来进行形式化定理证明。Kimina-Prover使用强化学习训练，并运用一种称为“形式化推理模式”(formal reasoning pattern)的结构化推理模式，在Lean 4证明生成方面表现出色，模拟了人类在Lean中的问题解决策略，迭代地生成和改进证明步骤。在miniF2F基准测试中，Kimina-Prover达到了80.7% (pass@8192) 的新SOTA。研究表明，Kimina-Prover具有高采样效率，性能随模型规模扩展而提升，并且其学习到的推理风格有潜力弥合形式验证和非形式数学直觉之间的差距。论文开源了Kimina-Prover的1.5B和7B参数的精简版本。\n",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "22 pages",
      "pdf_url": "http://arxiv.org/pdf/2504.11354v1",
      "published_date": "2025-04-15 16:23:44 UTC",
      "updated_date": "2025-04-15 16:23:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:13:36.171937"
    },
    {
      "arxiv_id": "2504.11349v1",
      "title": "Explicit and Implicit Representations in AI-based 3D Reconstruction for Radiology: A systematic literature review",
      "title_zh": "人工智能放射学三维重建中的显式和隐式表示：系统性文献综述\n",
      "authors": [
        "Yuezhe Yang",
        "Boyu Yang",
        "Yaqian Wang",
        "Yang He",
        "Xingbo Dong",
        "Zhe Jin"
      ],
      "abstract": "The demand for high-quality medical imaging in clinical practice and assisted\ndiagnosis has made 3D reconstruction in radiological imaging a key research\nfocus. Artificial intelligence (AI) has emerged as a promising approach to\nenhancing reconstruction accuracy while reducing acquisition and processing\ntime, thereby minimizing patient radiation exposure and discomfort and\nultimately benefiting clinical diagnosis. This review explores state-of-the-art\nAI-based 3D reconstruction algorithms in radiological imaging, categorizing\nthem into explicit and implicit approaches based on their underlying\nprinciples. Explicit methods include point-based, volume-based, and Gaussian\nrepresentations, while implicit methods encompass implicit prior embedding and\nneural radiance fields. Additionally, we examine commonly used evaluation\nmetrics and benchmark datasets. Finally, we discuss the current state of\ndevelopment, key challenges, and future research directions in this evolving\nfield. Our project available on: https://github.com/Bean-Young/AI4Med.",
      "tldr_zh": "这篇综述系统地回顾了基于人工智能(AI)的放射学3D重建算法，并根据其底层原理将其分为显式和隐式方法。显式方法包括基于点、基于体积和基于高斯的表示，而隐式方法包括隐式先验嵌入和神经辐射场(neural radiance fields)。文章还考察了常用的评估指标和基准数据集，并讨论了该领域目前的发展状况、关键挑战和未来研究方向。该综述旨在为临床实践和辅助诊断中对高质量医学影像的需求提供参考，并促进AI在减少患者辐射暴露和不适方面的应用。项目代码已开源。\n",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "68T45",
        "I.4.5"
      ],
      "primary_category": "cs.CV",
      "comment": "43 pages, 5 figures, submit to Medical Image Analysis",
      "pdf_url": "http://arxiv.org/pdf/2504.11349v1",
      "published_date": "2025-04-15 16:21:47 UTC",
      "updated_date": "2025-04-15 16:21:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:13:47.793439"
    },
    {
      "arxiv_id": "2504.11344v1",
      "title": "Interpretable Hybrid-Rule Temporal Point Processes",
      "title_zh": "可解释的混合规则时序点过程\n",
      "authors": [
        "Yunyang Cao",
        "Juekai Lin",
        "Hongye Wang",
        "Wenhao Li",
        "Bo Jin"
      ],
      "abstract": "Temporal Point Processes (TPPs) are widely used for modeling event sequences\nin various medical domains, such as disease onset prediction, progression\nanalysis, and clinical decision support. Although TPPs effectively capture\ntemporal dynamics, their lack of interpretability remains a critical challenge.\nRecent advancements have introduced interpretable TPPs. However, these methods\nfail to incorporate numerical features, thereby limiting their ability to\ngenerate precise predictions. To address this issue, we propose Hybrid-Rule\nTemporal Point Processes (HRTPP), a novel framework that integrates temporal\nlogic rules with numerical features, improving both interpretability and\npredictive accuracy in event modeling. HRTPP comprises three key components:\nbasic intensity for intrinsic event likelihood, rule-based intensity for\nstructured temporal dependencies, and numerical feature intensity for dynamic\nprobability modulation. To effectively discover valid rules, we introduce a\ntwo-phase rule mining strategy with Bayesian optimization. To evaluate our\nmethod, we establish a multi-criteria assessment framework, incorporating rule\nvalidity, model fitting, and temporal predictive accuracy. Experimental results\non real-world medical datasets demonstrate that HRTPP outperforms\nstate-of-the-art interpretable TPPs in terms of predictive performance and\nclinical interpretability. In case studies, the rules extracted by HRTPP\nexplain the disease progression, offering valuable contributions to medical\ndiagnosis.",
      "tldr_zh": "本文提出了一种可解释的混合规则时间点过程(HRTPP)框架，旨在提升时间点过程(TPPs)在医疗领域事件序列建模中的可解释性和预测精度。HRTPP结合了时间逻辑规则和数值特征，通过基本强度、基于规则的强度以及数值特征强度三个关键组件，捕捉事件的内在可能性、结构化时间依赖性和动态概率调制。为了有效挖掘有效规则，研究引入了基于贝叶斯优化的两阶段规则挖掘策略。实验结果表明，HRTPP在真实医疗数据集上优于现有的可解释TPPs，并在预测性能和临床可解释性方面表现出色，提取的规则能够解释疾病进展，为医疗诊断提供有价值的参考。\n",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.11344v1",
      "published_date": "2025-04-15 16:15:16 UTC",
      "updated_date": "2025-04-15 16:15:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:13:59.859070"
    },
    {
      "arxiv_id": "2504.11343v1",
      "title": "A Minimalist Approach to LLM Reasoning: from Rejection Sampling to Reinforce",
      "title_zh": "LLM 推理的极简方法：从拒绝采样到强化学习\n",
      "authors": [
        "Wei Xiong",
        "Jiarui Yao",
        "Yuhui Xu",
        "Bo Pang",
        "Lei Wang",
        "Doyen Sahoo",
        "Junnan Li",
        "Nan Jiang",
        "Tong Zhang",
        "Caiming Xiong",
        "Hanze Dong"
      ],
      "abstract": "Reinforcement learning (RL) has become a prevailing approach for fine-tuning\nlarge language models (LLMs) on complex reasoning tasks. Among recent methods,\nGRPO stands out for its empirical success in training models such as\nDeepSeek-R1, yet the sources of its effectiveness remain poorly understood. In\nthis work, we revisit GRPO from a reinforce-like algorithm perspective and\nanalyze its core components. Surprisingly, we find that a simple rejection\nsampling baseline, RAFT, which trains only on positively rewarded samples,\nyields competitive performance than GRPO and PPO. Our ablation studies reveal\nthat GRPO's main advantage arises from discarding prompts with entirely\nincorrect responses, rather than from its reward normalization. Motivated by\nthis insight, we propose Reinforce-Rej, a minimal extension of policy gradient\nthat filters both entirely incorrect and entirely correct samples.\nReinforce-Rej improves KL efficiency and stability, serving as a lightweight\nyet effective alternative to more complex RL algorithms. We advocate RAFT as a\nrobust and interpretable baseline, and suggest that future advances should\nfocus on more principled designs for incorporating negative samples, rather\nthan relying on them indiscriminately. Our findings provide guidance for future\nwork in reward-based LLM post-training.",
      "tldr_zh": "该论文研究了使用强化学习(RL)微调大型语言模型(LLMs)以解决复杂推理任务的方法，特别是GRPO算法。研究发现，一个简单的拒绝采样基线方法RAFT，仅使用正向奖励样本进行训练，就能达到与GRPO和PPO相当的性能。通过消融研究表明，GRPO的主要优势在于丢弃了完全错误响应的提示，而不是奖励归一化。基于此，作者提出了Reinforce-Rej，一种策略梯度的最小扩展，过滤掉完全错误和完全正确的样本，提高了KL效率和稳定性，成为一种轻量级但有效的替代方案。该研究提倡使用RAFT作为稳健且可解释的基线，并建议未来的研究应侧重于更合理地设计负样本的结合方式。\n",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "12 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.11343v1",
      "published_date": "2025-04-15 16:15:02 UTC",
      "updated_date": "2025-04-15 16:15:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:14:12.191408"
    },
    {
      "arxiv_id": "2504.11338v1",
      "title": "Transformer-Based Model for Cold Start Mitigation in FaaS Architecture",
      "title_zh": "基于 Transformer 的 FaaS 架构冷启动缓解模型\n",
      "authors": [
        "Alexandre Savi Fayam Mbala Mouen",
        "Jerry Lacmou Zeutouo",
        "Vianney Kengne Tchendji"
      ],
      "abstract": "Serverless architectures, particularly the Function as a Service (FaaS)\nmodel, have become a cornerstone of modern cloud computing due to their ability\nto simplify resource management and enhance application deployment agility.\nHowever, a significant challenge remains: the cold start problem. This\nphenomenon occurs when an idle FaaS function is invoked, requiring a full\ninitialization process, which increases latency and degrades user experience.\nExisting solutions for cold start mitigation are limited in terms of invocation\npattern generalization and implementation complexity. In this study, we propose\nan innovative approach leveraging Transformer models to mitigate the impact of\ncold starts in FaaS architectures. Our solution excels in accurately modeling\nfunction initialization delays and optimizing serverless system performance.\nExperimental evaluation using a public dataset provided by Azure demonstrates a\nsignificant reduction in cold start times, reaching up to 79\\% compared to\nconventional methods.",
      "tldr_zh": "该论文提出了一种基于Transformer模型的创新方法，用于缓解FaaS架构中的冷启动问题。通过Transformer模型精确建模函数初始化延迟，并优化serverless系统性能。实验结果表明，使用Azure提供的公共数据集进行评估，该方法能够显著减少冷启动时间，与传统方法相比，降幅高达79%。该研究为提升serverless架构的性能和用户体验提供了有效方案。\n",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.11338v1",
      "published_date": "2025-04-15 16:12:07 UTC",
      "updated_date": "2025-04-15 16:12:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:14:23.536846"
    },
    {
      "arxiv_id": "2504.11336v1",
      "title": "Looking beyond the next token",
      "title_zh": "超越下一个 token 的视野\n",
      "authors": [
        "Abitha Thankaraj",
        "Yiding Jiang",
        "J. Zico Kolter",
        "Yonatan Bisk"
      ],
      "abstract": "The structure of causal language model training assumes that each token can\nbe accurately predicted from the previous context. This contrasts with humans'\nnatural writing and reasoning process, where goals are typically known before\nthe exact argument or phrasings. While this mismatch has been well studied in\nthe literature, the working assumption has been that architectural changes are\nneeded to address this mismatch. We argue that rearranging and processing the\ntraining data sequences can allow models to more accurately imitate the true\ndata-generating process, and does not require any other changes to the\narchitecture or training infrastructure. We demonstrate that this technique,\nTrelawney, and the inference algorithms derived from it allow us to improve\nperformance on several key benchmarks that span planning, algorithmic\nreasoning, and story generation tasks. Finally, our method naturally enables\nthe generation of long-term goals at no additional cost. We investigate how\nusing the model's goal-generation capability can further improve planning and\nreasoning. Additionally, we believe Trelawney could potentially open doors to\nnew capabilities beyond the current language modeling paradigm.",
      "tldr_zh": "本文提出了一种名为Trelawney的新技术，通过重排和处理训练数据序列，使语言模型能够更好地模拟真实的数据生成过程，而无需改变模型架构或训练基础设施。Trelawney 允许模型在预测下一个 token 之前，先“看到”未来的信息，从而更好地进行规划、算法推理和故事生成。实验证明，该方法在多个关键 benchmark 上取得了性能提升，并且能够以零成本生成长期目标。研究进一步探索了利用模型的目标生成能力来改进规划和推理的方法，并认为 Trelawney 有潜力开启超越当前语言建模范式的新能力。\n",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.11336v1",
      "published_date": "2025-04-15 16:09:06 UTC",
      "updated_date": "2025-04-15 16:09:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:14:35.841902"
    },
    {
      "arxiv_id": "2504.11335v1",
      "title": "Code Reborn AI-Driven Legacy Systems Modernization from COBOL to Java",
      "title_zh": "代码重生：AI驱动的从COBOL到Java的遗留系统现代化改造\n",
      "authors": [
        "Gopichand Bandarupalli"
      ],
      "abstract": "This study investigates AI-driven modernization of legacy COBOL code into\nJava, addressing a critical challenge in aging software systems. Leveraging the\nLegacy COBOL 2024 Corpus -- 50,000 COBOL files from public and enterprise\nsources -- Java parses the code, AI suggests upgrades, and React visualizes\ngains. Achieving 93% accuracy, complexity drops 35% (from 18 to 11.7) and\ncoupling 33% (from 8 to 5.4), surpassing manual efforts (75%) and rule-based\ntools (82%). The approach offers a scalable path to rejuvenate COBOL systems,\nvital for industries like banking and insurance.",
      "tldr_zh": "该研究探索了利用AI驱动的COBOL代码向Java的现代化迁移方法，旨在解决遗留系统升级的关键挑战。研究人员使用Legacy COBOL 2024语料库（包含来自公共和企业来源的50,000个COBOL文件），通过Java解析代码，AI提供升级建议，并使用React可视化改进效果。实验结果表明，该方法达到了93%的准确率，代码复杂度降低了35%（从18降至11.7），耦合度降低了33%（从8降至5.4），优于人工迁移（75%）和基于规则的工具（82%）。该方法为COBOL系统的现代化改造提供了一条可扩展的路径，对银行和保险等行业至关重要。\n",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.11335v1",
      "published_date": "2025-04-15 16:07:54 UTC",
      "updated_date": "2025-04-15 16:07:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:14:48.027081"
    },
    {
      "arxiv_id": "2504.11320v1",
      "title": "Optimizing LLM Inference: Fluid-Guided Online Scheduling with Memory Constraints",
      "title_zh": "优化LLM推理：基于流体引导的在线调度与内存约束\n",
      "authors": [
        "Ruicheng Ao",
        "Gan Luo",
        "David Simchi-Levi",
        "Xinshang Wang"
      ],
      "abstract": "Large Language Models (LLMs) are indispensable in today's applications, but\ntheir inference procedure -- generating responses by processing text in\nsegments and using a memory-heavy Key-Value (KV) cache -- demands significant\ncomputational resources, particularly under memory constraints. This paper\nformulates LLM inference optimization as a multi-stage online scheduling\nproblem where sequential prompt arrivals and KV cache growth render\nconventional scheduling ineffective. We develop a fluid dynamics approximation\nto provide a tractable benchmark that guides algorithm design. Building on\nthis, we propose the Waiting for Accumulated Inference Threshold (WAIT)\nalgorithm, which uses multiple thresholds to schedule incoming prompts\noptimally when output lengths are known, and extend it to Nested WAIT for cases\nwith unknown output lengths. Theoretical analysis shows that both algorithms\nachieve near-optimal performance against the fluid benchmark in heavy traffic\nconditions, balancing throughput, latency, and Time to First Token (TTFT).\nExperiments with the Llama-7B model on an A100 GPU using both synthetic and\nreal-world datasets demonstrate improved throughput and reduced latency\nrelative to established baselines like vLLM and Sarathi. This work bridges\noperations research and machine learning, offering a rigorous framework for the\nefficient deployment of LLMs under memory constraints.",
      "tldr_zh": "本文将LLM推理优化问题建模为一个多阶段在线调度问题，重点关注内存约束下的效率。针对传统调度方法在处理连续prompt到达和KV缓存增长时的不足，研究提出了一种基于流体动力学近似的基准方法，并在此基础上设计了Waiting for Accumulated Inference Threshold (WAIT)算法及其扩展Nested WAIT，分别用于已知和未知输出长度的情况。理论分析表明，这些算法在重负载条件下能实现接近最优的性能，平衡吞吐量、延迟和首个token生成时间(TTFT)。实验结果表明，相较于vLLM和Sarathi等基线模型，WAIT算法在使用Llama-7B模型和A100 GPU时，在合成和真实数据集上均能显著提高吞吐量并降低延迟。该研究为在内存约束下高效部署LLM提供了一个严谨的框架。\n",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC",
        "math.OC",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "42 pages, 18 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.11320v1",
      "published_date": "2025-04-15 16:00:21 UTC",
      "updated_date": "2025-04-15 16:00:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:15:00.152717"
    },
    {
      "arxiv_id": "2504.11305v1",
      "title": "CFIS-YOLO: A Lightweight Multi-Scale Fusion Network for Edge-Deployable Wood Defect Detection",
      "title_zh": "CFIS-YOLO：一种用于边缘可部署木材缺陷检测的轻量级多尺度融合网络\n",
      "authors": [
        "Jincheng Kang",
        "Yi Cen",
        "Yigang Cen",
        "Ke Wang",
        "Yuhan Liu"
      ],
      "abstract": "Wood defect detection is critical for ensuring quality control in the wood\nprocessing industry. However, current industrial applications face two major\nchallenges: traditional methods are costly, subjective, and labor-intensive,\nwhile mainstream deep learning models often struggle to balance detection\naccuracy and computational efficiency for edge deployment. To address these\nissues, this study proposes CFIS-YOLO, a lightweight object detection model\noptimized for edge devices. The model introduces an enhanced C2f structure, a\ndynamic feature recombination module, and a novel loss function that\nincorporates auxiliary bounding boxes and angular constraints. These\ninnovations improve multi-scale feature fusion and small object localization\nwhile significantly reducing computational overhead. Evaluated on a public wood\ndefect dataset, CFIS-YOLO achieves a mean Average Precision (mAP@0.5) of\n77.5\\%, outperforming the baseline YOLOv10s by 4 percentage points. On SOPHON\nBM1684X edge devices, CFIS-YOLO delivers 135 FPS, reduces power consumption to\n17.3\\% of the original implementation, and incurs only a 0.5 percentage point\ndrop in mAP. These results demonstrate that CFIS-YOLO is a practical and\neffective solution for real-world wood defect detection in resource-constrained\nenvironments.",
      "tldr_zh": "该研究提出了CFIS-YOLO，一种轻量级的多尺度融合网络，专为边缘设备上的木材缺陷检测而设计。CFIS-YOLO通过引入增强的C2f结构、动态特征重组模块以及包含辅助边界框和角度约束的新型损失函数，改进了多尺度特征融合和小目标定位，同时显著降低了计算开销。在公开木材缺陷数据集上的评估显示，CFIS-YOLO实现了77.5%的mAP@0.5，优于基线YOLOv10s 4个百分点。在SOPHON BM1684X边缘设备上，CFIS-YOLO达到135 FPS，功耗降低到原始实现的17.3%，且mAP仅下降0.5个百分点。实验结果表明，CFIS-YOLO是资源受限环境下木材缺陷检测的实用有效解决方案。\n",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.11305v1",
      "published_date": "2025-04-15 15:45:59 UTC",
      "updated_date": "2025-04-15 15:45:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:15:12.030177"
    },
    {
      "arxiv_id": "2504.11301v1",
      "title": "Learning to Be A Doctor: Searching for Effective Medical Agent Architectures",
      "title_zh": "学习成为一名医生：探索有效的医疗 Agent 架构\n",
      "authors": [
        "Yangyang Zhuang",
        "Wenjia Jiang",
        "Jiayu Zhang",
        "Ze Yang",
        "Joey Tianyi Zhou",
        "Chi Zhang"
      ],
      "abstract": "Large Language Model (LLM)-based agents have demonstrated strong capabilities\nacross a wide range of tasks, and their application in the medical domain holds\nparticular promise due to the demand for high generalizability and reliance on\ninterdisciplinary knowledge. However, existing medical agent systems often rely\non static, manually crafted workflows that lack the flexibility to accommodate\ndiverse diagnostic requirements and adapt to emerging clinical scenarios.\nMotivated by the success of automated machine learning (AutoML), this paper\nintroduces a novel framework for the automated design of medical agent\narchitectures. Specifically, we define a hierarchical and expressive agent\nsearch space that enables dynamic workflow adaptation through structured\nmodifications at the node, structural, and framework levels. Our framework\nconceptualizes medical agents as graph-based architectures composed of diverse,\nfunctional node types and supports iterative self-improvement guided by\ndiagnostic feedback. Experimental results on skin disease diagnosis tasks\ndemonstrate that the proposed method effectively evolves workflow structures\nand significantly enhances diagnostic accuracy over time. This work represents\nthe first fully automated framework for medical agent architecture design and\noffers a scalable, adaptable foundation for deploying intelligent agents in\nreal-world clinical environments.",
      "tldr_zh": "该论文提出了一个用于自动设计医疗智能体架构的新框架，旨在解决现有医疗智能体系统依赖静态、手动工作流程的问题。该框架定义了一个分层且富有表现力的智能体搜索空间，通过在节点、结构和框架层面的结构化修改，实现动态的工作流程调整。该框架将医疗智能体概念化为基于图的架构，由不同的功能节点类型组成，并支持在诊断反馈的指导下进行迭代的自我改进。在皮肤病诊断任务上的实验结果表明，该方法能够有效地改进工作流程结构，并随着时间的推移显著提高诊断准确性。该研究是第一个用于医疗智能体架构设计的全自动框架，为在实际临床环境中部署智能智能体提供了一个可扩展、适应性强的基础。\n",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.11301v1",
      "published_date": "2025-04-15 15:44:21 UTC",
      "updated_date": "2025-04-15 15:44:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:15:24.019499"
    },
    {
      "arxiv_id": "2504.11284v1",
      "title": "Bipartite Ranking From Multiple Labels: On Loss Versus Label Aggregation",
      "title_zh": "基于多标签的二分排序：论损失与标签聚合\n",
      "authors": [
        "Michal Lukasik",
        "Lin Chen",
        "Harikrishna Narasimhan",
        "Aditya Krishna Menon",
        "Wittawat Jitkrittum",
        "Felix X. Yu",
        "Sashank J. Reddi",
        "Gang Fu",
        "Mohammadhossein Bateni",
        "Sanjiv Kumar"
      ],
      "abstract": "Bipartite ranking is a fundamental supervised learning problem, with the goal\nof learning a ranking over instances with maximal area under the ROC curve\n(AUC) against a single binary target label. However, one may often observe\nmultiple binary target labels, e.g., from distinct human annotators. How can\none synthesize such labels into a single coherent ranking? In this work, we\nformally analyze two approaches to this problem -- loss aggregation and label\naggregation -- by characterizing their Bayes-optimal solutions. Based on this,\nwe show that while both methods can yield Pareto-optimal solutions, loss\naggregation can exhibit label dictatorship: one can inadvertently (and\nundesirably) favor one label over others. This suggests that label aggregation\ncan be preferable to loss aggregation, which we empirically verify.",
      "tldr_zh": "本文研究了多标签下的二分排序问题，目标是从多个二元标签中学习一个排序，以最大化ROC曲线下的面积(AUC)。论文形式化地分析了两种方法：损失聚合和标签聚合，并描述了它们的贝叶斯最优解。研究表明，虽然两种方法都能产生帕累托最优解，但损失聚合可能表现出标签独裁，即无意中偏袒某个标签。因此，标签聚合可能优于损失聚合，这一结论得到了实验验证。\n",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IR",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.11284v1",
      "published_date": "2025-04-15 15:25:27 UTC",
      "updated_date": "2025-04-15 15:25:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:15:35.623034"
    },
    {
      "arxiv_id": "2504.11268v1",
      "title": "Single-Input Multi-Output Model Merging: Leveraging Foundation Models for Dense Multi-Task Learning",
      "title_zh": "单输入多输出模型合并：利用基础模型进行密集多任务学习\n",
      "authors": [
        "Juan Garcia Giraldo",
        "Nikolaos Dimitriadis",
        "Ke Wang",
        "Pascal Frossard"
      ],
      "abstract": "Model merging is a flexible and computationally tractable approach to merge\nsingle-task checkpoints into a multi-task model. Prior work has solely focused\non constrained multi-task settings where there is a one-to-one mapping between\na sample and a task, overlooking the paradigm where multiple tasks may operate\non the same sample, e.g., scene understanding. In this paper, we focus on the\nmulti-task setting with single-input-multiple-outputs (SIMO) and show that it\nqualitatively differs from the single-input-single-output model merging\nsettings studied in the literature due to the existence of task-specific\ndecoders and diverse loss objectives. We identify that existing model merging\nmethods lead to significant performance degradation, primarily due to\nrepresentation misalignment between the merged encoder and task-specific\ndecoders. We propose two simple and efficient fixes for the SIMO setting to\nre-align the feature representation after merging. Compared to joint\nfine-tuning, our approach is computationally effective and flexible, and sheds\nlight into identifying task relationships in an offline manner. Experiments on\nNYUv2, Cityscapes, and a subset of the Taskonomy dataset demonstrate: (1) task\narithmetic suffices to enable multi-task capabilities; however, the\nrepresentations generated by the merged encoder has to be re-aligned with the\ntask-specific heads; (2) the proposed architecture rivals traditional\nmulti-task learning in performance but requires fewer samples and training\nsteps by leveraging the existence of task-specific models.",
      "tldr_zh": "本文研究了单输入多输出(SIMO)场景下的模型融合问题，该场景与以往的单输入单输出模型融合不同，因为存在任务特定的解码器和不同的损失目标。研究发现，现有模型融合方法会导致性能显著下降，主要是由于融合的编码器和任务特定解码器之间的表示不对齐。为此，论文提出了两种简单有效的SIMO场景修复方法，以在融合后重新对齐特征表示。实验表明，与联合微调相比，该方法在计算上更有效且灵活，并且能够离线识别任务关系。在NYUv2、Cityscapes和Taskonomy数据集子集上的实验表明，该方法在性能上可以与传统的多任务学习相媲美，但通过利用任务特定模型的存在，需要更少的样本和训练步骤。\n",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "22 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.11268v1",
      "published_date": "2025-04-15 15:10:46 UTC",
      "updated_date": "2025-04-15 15:10:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:15:48.042203"
    },
    {
      "arxiv_id": "2504.11264v1",
      "title": "DeepSelective: Feature Gating and Representation Matching for Interpretable Clinical Prediction",
      "title_zh": "DeepSelective：用于可解释临床预测的特征门控和表征匹配\n",
      "authors": [
        "Ruochi Zhang",
        "Qian Yang",
        "Xiaoyang Wang",
        "Haoran Wu",
        "Qiong Zhou",
        "Yu Wang",
        "Kewei Li",
        "Yueying Wang",
        "Yusi Fan",
        "Jiale Zhang",
        "Lan Huang",
        "Chang Liu",
        "Fengfeng Zhou"
      ],
      "abstract": "The rapid accumulation of Electronic Health Records (EHRs) has transformed\nhealthcare by providing valuable data that enhance clinical predictions and\ndiagnoses. While conventional machine learning models have proven effective,\nthey often lack robust representation learning and depend heavily on\nexpert-crafted features. Although deep learning offers powerful solutions, it\nis often criticized for its lack of interpretability. To address these\nchallenges, we propose DeepSelective, a novel end to end deep learning\nframework for predicting patient prognosis using EHR data, with a strong\nemphasis on enhancing model interpretability. DeepSelective combines data\ncompression techniques with an innovative feature selection approach,\nintegrating custom-designed modules that work together to improve both accuracy\nand interpretability. Our experiments demonstrate that DeepSelective not only\nenhances predictive accuracy but also significantly improves interpretability,\nmaking it a valuable tool for clinical decision-making. The source code is\nfreely available at http://www.healthinformaticslab.org/supp/resources.php .",
      "tldr_zh": "DeepSelective 是一种用于临床预测的端到端深度学习框架，旨在提高模型的可解释性。它结合了数据压缩技术和创新的特征选择方法，通过自定义模块协同工作，从而提高预测精度和可解释性。该模型利用电子健康记录(EHR)数据预测患者预后，克服了传统机器学习模型依赖专家特征和深度学习模型缺乏可解释性的问题。实验结果表明，DeepSelective 在提高预测准确性的同时，显著增强了模型的可解释性，使其成为临床决策的有力工具。\n",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.11264v1",
      "published_date": "2025-04-15 15:04:39 UTC",
      "updated_date": "2025-04-15 15:04:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:15:59.798816"
    },
    {
      "arxiv_id": "2504.11250v1",
      "title": "A Rollout-Based Algorithm and Reward Function for Efficient Resource Allocation in Business Processes",
      "title_zh": "一种基于 Rollout 的算法和奖励函数，用于优化业务流程中的资源分配\n",
      "authors": [
        "Jeroen Middelhuis",
        "Zaharah Bukhsh",
        "Ivo Adan",
        "Remco Dijkman"
      ],
      "abstract": "Resource allocation plays a critical role in minimizing cycle time and\nimproving the efficiency of business processes. Recently, Deep Reinforcement\nLearning (DRL) has emerged as a powerful tool to optimize resource allocation\npolicies in business processes. In the DRL framework, an agent learns a policy\nthrough interaction with the environment, guided solely by reward signals that\nindicate the quality of its decisions. However, existing algorithms are not\nsuitable for dynamic environments such as business processes. Furthermore,\nexisting DRL-based methods rely on engineered reward functions that approximate\nthe desired objective, but a misalignment between reward and objective can lead\nto undesired decisions or suboptimal policies. To address these issues, we\npropose a rollout-based DRL algorithm and a reward function to optimize the\nobjective directly. Our algorithm iteratively improves the policy by evaluating\nexecution trajectories following different actions. Our reward function\ndirectly decomposes the objective function of minimizing the mean cycle time.\nMaximizing our reward function guarantees that the objective function is\nminimized without requiring extensive reward engineering. The results show that\nour method consistently learns the optimal policy in all six evaluated business\nprocesses, outperforming the state-of-the-art algorithm that can only learn the\noptimal policy in two of the evaluated processes.",
      "tldr_zh": "该论文提出了一种基于Rollout的深度强化学习(DRL)算法和奖励函数，用于优化业务流程中的资源分配，旨在最小化平均周期时间。现有DRL方法依赖于人工设计的奖励函数，可能导致次优策略。为解决此问题，该算法通过评估不同动作后的执行轨迹来迭代改进策略，并且奖励函数直接分解了最小化平均周期时间的目标函数，无需复杂的奖励工程。实验结果表明，该方法在所有六个评估的业务流程中均能学习到最优策略，优于现有技术。\n",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Pre-print submitted to the 23rd International Conference on Business\n  Process Management",
      "pdf_url": "http://arxiv.org/pdf/2504.11250v1",
      "published_date": "2025-04-15 14:46:58 UTC",
      "updated_date": "2025-04-15 14:46:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:16:11.806229"
    },
    {
      "arxiv_id": "2504.11246v1",
      "title": "Respiratory Inhaler Sound Event Classification Using Self-Supervised Learning",
      "title_zh": "基于自监督学习的呼吸道吸入器声音事件分类\n",
      "authors": [
        "Davoud Shariat Panah",
        "Alessandro N Franciosi",
        "Cormac McCarthy",
        "Andrew Hines"
      ],
      "abstract": "Asthma is a chronic respiratory condition that affects millions of people\nworldwide. While this condition can be managed by administering controller\nmedications through handheld inhalers, clinical studies have shown low\nadherence to the correct inhaler usage technique. Consequently, many patients\nmay not receive the full benefit of their medication. Automated classification\nof inhaler sounds has recently been studied to assess medication adherence.\nHowever, the existing classification models were typically trained using data\nfrom specific inhaler types, and their ability to generalize to sounds from\ndifferent inhalers remains unexplored. In this study, we adapted the wav2vec\n2.0 self-supervised learning model for inhaler sound classification by\npre-training and fine-tuning this model on inhaler sounds. The proposed model\nshows a balanced accuracy of 98% on a dataset collected using a dry powder\ninhaler and smartwatch device. The results also demonstrate that re-finetuning\nthis model on minimal data from a target inhaler is a promising approach to\nadapting a generic inhaler sound classification model to a different inhaler\ndevice and audio capture hardware. This is the first study in the field to\ndemonstrate the potential of smartwatches as assistive technologies for the\npersonalized monitoring of inhaler adherence using machine learning models.",
      "tldr_zh": "该研究利用自监督学习方法，特别是wav2vec 2.0模型，进行呼吸道吸入器声音事件分类，旨在解决哮喘患者吸入器使用依从性问题。研究人员通过在吸入器声音数据上预训练和微调wav2vec 2.0模型，实现了对干粉吸入器声音事件的高精度分类，平衡准确率达到98%。结果表明，通过少量目标吸入器数据重新微调模型，可以有效地将通用吸入器声音分类模型适配到不同的吸入器设备和音频采集硬件。该研究首次展示了智能手表作为辅助技术在个性化监测吸入器依从性方面的潜力。\n",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.AS",
      "comment": "Accepted at the IEEE EMBC 2025 Conference",
      "pdf_url": "http://arxiv.org/pdf/2504.11246v1",
      "published_date": "2025-04-15 14:44:47 UTC",
      "updated_date": "2025-04-15 14:44:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:16:23.953374"
    },
    {
      "arxiv_id": "2504.11245v1",
      "title": "Influence Maximization in Temporal Social Networks with a Cold-Start Problem: A Supervised Approach",
      "title_zh": "冷启动问题下的时间社会网络影响力最大化：一种监督方法\n",
      "authors": [
        "Laixin Xie",
        "Ying Zhang",
        "Xiyuan Wang",
        "Shiyi Liu",
        "Shenghan Gao",
        "Xingxing Xing",
        "Wei Wan",
        "Haipeng Zhang",
        "Quan Li"
      ],
      "abstract": "Influence Maximization (IM) in temporal graphs focuses on identifying\ninfluential \"seeds\" that are pivotal for maximizing network expansion. We\nadvocate defining these seeds through Influence Propagation Paths (IPPs), which\nis essential for scaling up the network. Our focus lies in efficiently labeling\nIPPs and accurately predicting these seeds, while addressing the\noften-overlooked cold-start issue prevalent in temporal networks. Our strategy\nintroduces a motif-based labeling method and a tensorized Temporal Graph\nNetwork (TGN) tailored for multi-relational temporal graphs, bolstering\nprediction accuracy and computational efficiency. Moreover, we augment\ncold-start nodes with new neighbors from historical data sharing similar IPPs.\nThe recommendation system within an online team-based gaming environment\npresents subtle impact on the social network, forming multi-relational (i.e.,\nweak and strong) temporal graphs for our empirical IM study. We conduct offline\nexperiments to assess prediction accuracy and model training efficiency,\ncomplemented by online A/B testing to validate practical network growth and the\neffectiveness in addressing the cold-start issue.",
      "tldr_zh": "本文提出了一种有监督的方法来解决时间社交网络中的冷启动影响最大化(Influence Maximization, IM)问题。该方法通过定义影响传播路径(Influence Propagation Paths, IPPs)来识别关键的“种子”节点，并采用基于motif的标注方法和张量化时间图网络(Temporal Graph Network, TGN)来高效地标注IPPs和预测种子节点。针对冷启动问题，该方法利用历史数据中具有相似IPPs的节点来扩充冷启动节点的新邻居。在在线团队游戏环境的推荐系统中的实验表明，该方法提高了预测精度和计算效率，并有效解决了冷启动问题，促进了网络增长。\n",
      "categories": [
        "cs.SI",
        "cs.AI"
      ],
      "primary_category": "cs.SI",
      "comment": "Accepted by ICWSM 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.11245v1",
      "published_date": "2025-04-15 14:44:30 UTC",
      "updated_date": "2025-04-15 14:44:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:16:36.023890"
    },
    {
      "arxiv_id": "2504.11243v1",
      "title": "Towards Automated Safety Requirements Derivation Using Agent-based RAG",
      "title_zh": "迈向使用基于 Agent 的 RAG 自动推导安全需求\n",
      "authors": [
        "Balahari Vignesh Balu",
        "Florian Geissler",
        "Francesco Carella",
        "Joao-Vitor Zacchi",
        "Josef Jiru",
        "Nuria Mata",
        "Reinhard Stolle"
      ],
      "abstract": "We study the automated derivation of safety requirements in a self-driving\nvehicle use case, leveraging LLMs in combination with agent-based\nretrieval-augmented generation. Conventional approaches that utilise\npre-trained LLMs to assist in safety analyses typically lack domain-specific\nknowledge. Existing RAG approaches address this issue, yet their performance\ndeteriorates when handling complex queries and it becomes increasingly harder\nto retrieve the most relevant information. This is particularly relevant for\nsafety-relevant applications. In this paper, we propose the use of agent-based\nRAG to derive safety requirements and show that the retrieved information is\nmore relevant to the queries. We implement an agent-based approach on a\ndocument pool of automotive standards and the Apollo case study, as a\nrepresentative example of an automated driving perception system. Our solution\nis tested on a data set of safety requirement questions and answers, extracted\nfrom the Apollo data. Evaluating a set of selected RAG metrics, we present and\ndiscuss advantages of a agent-based approach compared to default RAG methods.",
      "tldr_zh": "该论文提出了一种基于智能体的检索增强生成(Agent-based RAG)方法，用于自动推导自动驾驶车辆用例中的安全需求。传统方法通常缺乏领域知识，而现有RAG方法在处理复杂查询时性能下降。该方法利用智能体从汽车标准和Apollo案例研究的文档池中检索更相关的信息，从而更好地推导安全需求。实验结果表明，与默认RAG方法相比，该智能体方法在安全需求问题解答数据集上表现出优势。\n",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "9 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.11243v1",
      "published_date": "2025-04-15 14:43:19 UTC",
      "updated_date": "2025-04-15 14:43:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:16:47.767480"
    },
    {
      "arxiv_id": "2504.11239v1",
      "title": "Nondeterministic Polynomial-time Problem Challenge: An Ever-Scaling Reasoning Benchmark for LLMs",
      "title_zh": "非确定性多项式时间问题挑战：LLM 的一个持续扩展的推理基准\n",
      "authors": [
        "Chang Yang",
        "Ruiyu Wang",
        "Junzhe Jiang",
        "Qi Jiang",
        "Qinggang Zhang",
        "Yanchen Deng",
        "Shuxin Li",
        "Shuyue Hu",
        "Bo Li",
        "Florian T. Pokorny",
        "Xiao Huang",
        "Xinrun Wang"
      ],
      "abstract": "Reasoning is the fundamental capability of large language models (LLMs). Due\nto the rapid progress of LLMs, there are two main issues of current benchmarks:\ni) these benchmarks can be crushed in a short time (less than 1 year), and ii)\nthese benchmarks may be easily hacked. To handle these issues, we propose the\never-scalingness for building the benchmarks which are uncrushable, unhackable,\nauto-verifiable and general. This paper presents Nondeterministic\nPolynomial-time Problem Challenge (NPPC), an ever-scaling reasoning benchmark\nfor LLMs. Specifically, the NPPC has three main modules: i) npgym, which\nprovides a unified interface of 25 well-known NP-complete problems and can\ngenerate any number of instances with any levels of complexities, ii) npsolver:\nwhich provides a unified interface to evaluate the problem instances with both\nonline and offline models via APIs and local deployments, respectively, and\niii) npeval: which provides the comprehensive and ready-to-use tools to analyze\nthe performances of LLMs over different problems, the number of tokens, the aha\nmoments, the reasoning errors and the solution errors. Extensive experiments\nover widely-used LLMs demonstrate: i) NPPC can successfully decrease the\nperformances of advanced LLMs' performances to below 10%, demonstrating that\nNPPC is uncrushable, ii) DeepSeek-R1, Claude-3.7-Sonnet, and o1/o3-mini are the\nmost powerful LLMs, where DeepSeek-R1 outperforms Claude-3.7-Sonnet and\no1/o3-mini in most NP-complete problems considered, and iii) the numbers of\ntokens, aha moments in the advanced LLMs, e.g., Claude-3.7-Sonnet and\nDeepSeek-R1, are observed first to increase and then decrease when the problem\ninstances become more and more difficult. We believe that NPPC is the first\never-scaling reasoning benchmark, serving as the uncrushable and unhackable\ntestbed for LLMs toward artificial general intelligence (AGI).",
      "tldr_zh": "该论文提出了一个名为Nondeterministic Polynomial-time Problem Challenge (NPPC)的、可扩展的推理基准，用于评估大型语言模型(LLMs)的推理能力。NPPC包含npgym（提供25个NP完全问题的统一接口，可生成任意复杂度的实例）、npsolver（提供在线和离线模型评估接口）和npeval（提供分析LLM性能的工具）三个模块。实验结果表明，NPPC能有效降低先进LLM的性能至10%以下，表明其具有“uncrushable”特性。DeepSeek-R1在大多数NP完全问题上优于Claude-3.7-Sonnet和o1/o3-mini。研究还发现，当问题实例变得更难时，Claude-3.7-Sonnet和DeepSeek-R1等先进LLM中的token数量和“aha moment”先增加后减少。NPPC旨在成为LLM通往通用人工智能(AGI)道路上一个坚实可靠的测试平台。\n",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Preliminary work, 10 pages for main text",
      "pdf_url": "http://arxiv.org/pdf/2504.11239v1",
      "published_date": "2025-04-15 14:40:29 UTC",
      "updated_date": "2025-04-15 14:40:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:17:00.346506"
    },
    {
      "arxiv_id": "2504.11216v1",
      "title": "Diversity-Driven Learning: Tackling Spurious Correlations and Data Heterogeneity in Federated Models",
      "title_zh": "多样性驱动学习：应对联邦模型中的虚假相关性和数据异质性\n",
      "authors": [
        "Gergely D. Németh",
        "Eros Fanì",
        "Yeat Jeng Ng",
        "Barbara Caputo",
        "Miguel Ángel Lozano",
        "Nuria Oliver",
        "Novi Quadrianto"
      ],
      "abstract": "Federated Learning (FL) enables decentralized training of machine learning\nmodels on distributed data while preserving privacy. However, in real-world FL\nsettings, client data is often non-identically distributed and imbalanced,\nresulting in statistical data heterogeneity which impacts the generalization\ncapabilities of the server's model across clients, slows convergence and\nreduces performance. In this paper, we address this challenge by first\nproposing a characterization of statistical data heterogeneity by means of 6\nmetrics of global and client attribute imbalance, class imbalance, and spurious\ncorrelations. Next, we create and share 7 computer vision datasets for binary\nand multiclass image classification tasks in Federated Learning that cover a\nbroad range of statistical data heterogeneity and hence simulate real-world\nsituations. Finally, we propose FedDiverse, a novel client selection algorithm\nin FL which is designed to manage and leverage data heterogeneity across\nclients by promoting collaboration between clients with complementary data\ndistributions. Experiments on the seven proposed FL datasets demonstrate\nFedDiverse's effectiveness in enhancing the performance and robustness of a\nvariety of FL methods while having low communication and computational\noverhead.",
      "tldr_zh": "联邦学习(FL)在保护隐私的同时，实现了在分布式数据上分散训练机器学习模型。为了应对现实世界FL场景中常见的非独立同分布和不平衡数据带来的挑战，本文首先提出了6个指标来表征统计数据异质性，包括全局和客户端属性不平衡、类别不平衡和虚假相关性。其次，构建并共享了7个用于联邦学习的计算机视觉数据集，涵盖了广泛的统计数据异质性。最后，提出了一种新的客户端选择算法FedDiverse，旨在通过促进具有互补数据分布的客户端之间的协作来管理和利用数据异质性。在七个数据集上的实验表明，FedDiverse能够有效提高各种FL方法的性能和鲁棒性，同时具有较低的通信和计算开销。\n",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.11216v1",
      "published_date": "2025-04-15 14:20:42 UTC",
      "updated_date": "2025-04-15 14:20:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:17:12.159512"
    },
    {
      "arxiv_id": "2504.11200v1",
      "title": "Mutual Understanding between People and Systems via Neurosymbolic AI and Knowledge Graphs",
      "title_zh": "通过神经符号人工智能和知识图谱实现人与系统之间的相互理解\n",
      "authors": [
        "Irene Celino",
        "Mario Scrocca",
        "Agnese Chiatti"
      ],
      "abstract": "This chapter investigates the concept of mutual understanding between humans\nand systems, positing that Neuro-symbolic Artificial Intelligence (NeSy AI)\nmethods can significantly enhance this mutual understanding by leveraging\nexplicit symbolic knowledge representations with data-driven learning models.\nWe start by introducing three critical dimensions to characterize mutual\nunderstanding: sharing knowledge, exchanging knowledge, and governing\nknowledge. Sharing knowledge involves aligning the conceptual models of\ndifferent agents to enable a shared understanding of the domain of interest.\nExchanging knowledge relates to ensuring the effective and accurate\ncommunication between agents. Governing knowledge concerns establishing rules\nand processes to regulate the interaction between agents. Then, we present\nseveral different use case scenarios that demonstrate the application of NeSy\nAI and Knowledge Graphs to aid meaningful exchanges between human, artificial,\nand robotic agents. These scenarios highlight both the potential and the\nchallenges of combining top-down symbolic reasoning with bottom-up neural\nlearning, guiding the discussion of the coverage provided by current solutions\nalong the dimensions of sharing, exchanging, and governing knowledge.\nConcurrently, this analysis facilitates the identification of gaps and less\ndeveloped aspects in mutual understanding to address in future research.",
      "tldr_zh": "本章探讨了人与系统之间的相互理解，认为神经符号人工智能(NeSy AI)方法可以通过结合显式符号知识表示和数据驱动的学习模型来显著增强这种相互理解。文章提出了三个关键维度来描述相互理解：知识共享(sharing knowledge)、知识交换(exchanging knowledge)和知识治理(governing knowledge)。通过展示NeSy AI和知识图谱在人、人工智能和机器人主体之间有意义的交流中的应用，强调了自上而下的符号推理与自下而上的神经学习相结合的潜力与挑战。分析了当前解决方案在知识共享、交换和治理维度上的覆盖范围，并指出了未来研究中需要解决的差距和欠发达方面。\n",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "26 pages, 13 figures, 1 table; pre-print version of book chapter",
      "pdf_url": "http://arxiv.org/pdf/2504.11200v1",
      "published_date": "2025-04-15 13:57:09 UTC",
      "updated_date": "2025-04-15 13:57:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:17:24.056398"
    },
    {
      "arxiv_id": "2504.11197v2",
      "title": "Efficient Distributed Retrieval-Augmented Generation for Enhancing Language Model Performance",
      "title_zh": "高效的分布式检索增强生成，以提升语言模型性能\n",
      "authors": [
        "Shangyu Liu",
        "Zhenzhe Zheng",
        "Xiaoyao Huang",
        "Fan Wu",
        "Guihai Chen",
        "Jie Wu"
      ],
      "abstract": "Small language models (SLMs) support efficient deployments on\nresource-constrained edge devices, but their limited capacity compromises\ninference performance. Retrieval-augmented generation (RAG) is a promising\nsolution to enhance model performance by integrating external databases,\nwithout requiring intensive on-device model retraining. However, large-scale\npublic databases and user-specific private contextual documents are typically\nlocated on the cloud and the device separately, while existing RAG\nimplementations are primarily centralized. To bridge this gap, we propose\nDRAGON, a distributed RAG framework to enhance on-device SLMs through both\ngeneral and personal knowledge without the risk of leaking document privacy.\nSpecifically, DRAGON decomposes multi-document RAG into multiple parallel token\ngeneration processes performed independently and locally on the cloud and the\ndevice, and employs a newly designed Speculative Aggregation, a dual-side\nspeculative algorithm to avoid frequent output synchronization between the\ncloud and device. A new scheduling algorithm is further introduced to identify\nthe optimal aggregation side based on real-time network conditions. Evaluations\non real-world hardware testbed demonstrate a significant performance\nimprovement of DRAGON-up to 1.9x greater gains over standalone SLM compared to\nthe centralized RAG, substantial reduction in per-token latency, and negligible\nTime to First Token (TTFT) overhead.",
      "tldr_zh": "该论文提出了一个名为DRAGON的分布式检索增强生成(RAG)框架，旨在提升资源受限的边缘设备上小型语言模型(SLMs)的性能。DRAGON通过集成云端的大规模公共数据库和设备上的用户私有文档，利用通用知识和个性化知识增强SLM，同时避免文档隐私泄露的风险。该框架将多文档RAG分解为多个并行token生成过程，并在云端和设备上独立执行，采用一种新的推测性聚合算法(Speculative Aggregation)来减少云端和设备之间的同步。此外，还引入了一种新的调度算法，根据实时网络状况确定最佳聚合侧。实验结果表明，DRAGON相比于集中式RAG，在standalone SLM上实现了高达1.9倍的性能提升，显著降低了每个token的延迟，且首次token生成时间(TTFT)开销可忽略不计。\n",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC",
        "cs.IR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.11197v2",
      "published_date": "2025-04-15 13:53:08 UTC",
      "updated_date": "2025-04-16 03:32:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:17:36.415895"
    },
    {
      "arxiv_id": "2504.11190v1",
      "title": "Enhancing multimodal analogical reasoning with Logic Augmented Generation",
      "title_zh": "利用逻辑增强生成提升多模态类比推理能力\n",
      "authors": [
        "Anna Sofia Lippolis",
        "Andrea Giovanni Nuzzolese",
        "Aldo Gangemi"
      ],
      "abstract": "Recent advances in Large Language Models have demonstrated their capabilities\nacross a variety of tasks. However, automatically extracting implicit knowledge\nfrom natural language remains a significant challenge, as machines lack active\nexperience with the physical world. Given this scenario, semantic knowledge\ngraphs can serve as conceptual spaces that guide the automated text generation\nreasoning process to achieve more efficient and explainable results. In this\npaper, we apply a logic-augmented generation (LAG) framework that leverages the\nexplicit representation of a text through a semantic knowledge graph and\napplies it in combination with prompt heuristics to elicit implicit analogical\nconnections. This method generates extended knowledge graph triples\nrepresenting implicit meaning, enabling systems to reason on unlabeled\nmultimodal data regardless of the domain. We validate our work through three\nmetaphor detection and understanding tasks across four datasets, as they\nrequire deep analogical reasoning capabilities. The results show that this\nintegrated approach surpasses current baselines, performs better than humans in\nunderstanding visual metaphors, and enables more explainable reasoning\nprocesses, though still has inherent limitations in metaphor understanding,\nespecially for domain-specific metaphors. Furthermore, we propose a thorough\nerror analysis, discussing issues with metaphorical annotations and current\nevaluation methods.",
      "tldr_zh": "该论文提出了一种逻辑增强生成(Logic Augmented Generation, LAG)框架，旨在提升多模态类比推理能力。LAG框架利用语义知识图谱显式地表示文本，并结合提示启发式方法，挖掘隐式的类比连接，从而生成扩展的知识图谱三元组，用于处理未标注的多模态数据。通过在四个数据集上进行三个隐喻检测和理解任务的验证，结果表明LAG框架超越了现有基线，在理解视觉隐喻方面甚至优于人类。该方法在隐喻理解方面仍存在局限性，尤其是在特定领域的隐喻理解上。\n",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.11190v1",
      "published_date": "2025-04-15 13:47:55 UTC",
      "updated_date": "2025-04-15 13:47:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:17:47.926500"
    },
    {
      "arxiv_id": "2504.11186v1",
      "title": "Benchmarking Next-Generation Reasoning-Focused Large Language Models in Ophthalmology: A Head-to-Head Evaluation on 5,888 Items",
      "title_zh": "眼科领域下一代推理型大型语言模型基准测试：一项基于 5888 个项目的正面评估\n",
      "authors": [
        "Minjie Zou",
        "Sahana Srinivasan",
        "Thaddaeus Wai Soon Lo",
        "Ke Zou",
        "Gabriel Dawei Yang",
        "Xuguang Ai",
        "Hyunjae Kim",
        "Maxwell Singer",
        "Fares Antaki",
        "Kelvin Li",
        "Robert Chang",
        "Marcus Tan",
        "David Ziyou Chen",
        "Dianbo Liu",
        "Qingyu Chen",
        "Yih Chung Tham"
      ],
      "abstract": "Recent advances in reasoning-focused large language models (LLMs) mark a\nshift from general LLMs toward models designed for complex decision-making, a\ncrucial aspect in medicine. However, their performance in specialized domains\nlike ophthalmology remains underexplored. This study comprehensively evaluated\nand compared the accuracy and reasoning capabilities of four newly developed\nreasoning-focused LLMs, namely DeepSeek-R1, OpenAI o1, o3-mini, and Gemini 2.0\nFlash-Thinking. Each model was assessed using 5,888 multiple-choice\nophthalmology exam questions from the MedMCQA dataset in zero-shot setting.\nQuantitative evaluation included accuracy, Macro-F1, and five text-generation\nmetrics (ROUGE-L, METEOR, BERTScore, BARTScore, and AlignScore), computed\nagainst ground-truth reasonings. Average inference time was recorded for a\nsubset of 100 randomly selected questions. Additionally, two board-certified\nophthalmologists qualitatively assessed clarity, completeness, and reasoning\nstructure of responses to differential diagnosis questions.O1 (0.902) and\nDeepSeek-R1 (0.888) achieved the highest accuracy, with o1 also leading in\nMacro-F1 (0.900). The performance of models across the text-generation metrics\nvaried: O3-mini excelled in ROUGE-L (0.151), o1 in METEOR (0.232), DeepSeek-R1\nand o3-mini tied for BERTScore (0.673), DeepSeek-R1 (-4.105) and Gemini 2.0\nFlash-Thinking (-4.127) performed best in BARTScore, while o3-mini (0.181) and\no1 (0.176) led AlignScore. Inference time across the models varied, with\nDeepSeek-R1 being slowest (40.4 seconds) and Gemini 2.0 Flash-Thinking fastest\n(6.7 seconds). Qualitative evaluation revealed that DeepSeek-R1 and Gemini 2.0\nFlash-Thinking tended to provide detailed and comprehensive intermediate\nreasoning, whereas o1 and o3-mini displayed concise and summarized\njustifications.",
      "tldr_zh": "该研究对四种最新的、专注于推理的大语言模型(LLMs)——DeepSeek-R1, OpenAI o1, o3-mini, 和 Gemini 2.0 Flash-Thinking——在眼科学领域的性能进行了全面评估和比较。研究使用了MedMCQA数据集中的5888道眼科多项选择题，在零样本(zero-shot)设置下测试了这些模型的准确性和推理能力。结果显示，O1和DeepSeek-R1在准确率和Macro-F1指标上表现最佳，但在文本生成指标和推理时间上各有优劣。两位眼科专家对模型的推理过程进行了定性评估，发现DeepSeek-R1和Gemini 2.0 Flash-Thinking倾向于提供更详细的推理过程，而o1和o3-mini则更简洁。这项研究为在眼科等专业领域应用下一代推理型LLM提供了基准。\n",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "83 pages, 6 figures, 3 tables, 9 supplementary figures, 7\n  supplementary tables",
      "pdf_url": "http://arxiv.org/pdf/2504.11186v1",
      "published_date": "2025-04-15 13:42:34 UTC",
      "updated_date": "2025-04-15 13:42:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:18:00.261930"
    },
    {
      "arxiv_id": "2504.11182v1",
      "title": "Exploring Backdoor Attack and Defense for LLM-empowered Recommendations",
      "title_zh": "探索 LLM 赋能推荐系统的后门攻击与防御\n",
      "authors": [
        "Liangbo Ning",
        "Wenqi Fan",
        "Qing Li"
      ],
      "abstract": "The fusion of Large Language Models (LLMs) with recommender systems (RecSys)\nhas dramatically advanced personalized recommendations and drawn extensive\nattention. Despite the impressive progress, the safety of LLM-based RecSys\nagainst backdoor attacks remains largely under-explored. In this paper, we\nraise a new problem: Can a backdoor with a specific trigger be injected into\nLLM-based Recsys, leading to the manipulation of the recommendation responses\nwhen the backdoor trigger is appended to an item's title? To investigate the\nvulnerabilities of LLM-based RecSys under backdoor attacks, we propose a new\nattack framework termed Backdoor Injection Poisoning for RecSys (BadRec).\nBadRec perturbs the items' titles with triggers and employs several fake users\nto interact with these items, effectively poisoning the training set and\ninjecting backdoors into LLM-based RecSys. Comprehensive experiments reveal\nthat poisoning just 1% of the training data with adversarial examples is\nsufficient to successfully implant backdoors, enabling manipulation of\nrecommendations. To further mitigate such a security threat, we propose a\nuniversal defense strategy called Poison Scanner (P-Scanner). Specifically, we\nintroduce an LLM-based poison scanner to detect the poisoned items by\nleveraging the powerful language understanding and rich knowledge of LLMs. A\ntrigger augmentation agent is employed to generate diverse synthetic triggers\nto guide the poison scanner in learning domain-specific knowledge of the\npoisoned item detection task. Extensive experiments on three real-world\ndatasets validate the effectiveness of the proposed P-Scanner.",
      "tldr_zh": "本文探讨了大型语言模型(LLM)赋能的推荐系统面临的后门攻击和防御问题。作者提出了一个新的问题：是否可以将带有特定触发器的后门注入到基于LLM的推荐系统中，从而在物品标题附加后门触发器时操纵推荐结果？为了研究LLM推荐系统在后门攻击下的脆弱性，作者提出了一个名为BadRec的后门注入框架，该框架通过触发器扰乱物品标题，并使用虚假用户与这些物品交互，从而有效地毒化训练集并将后门注入到LLM推荐系统中。实验表明，仅用1%的对抗样本毒化训练数据就足以成功植入后门，从而操纵推荐结果。为了缓解这种安全威胁，作者提出了一种名为P-Scanner的通用防御策略，利用LLM强大的语言理解能力和丰富的知识来检测被污染的物品，并使用触发器增强代理生成各种合成触发器，以指导P-Scanner学习特定领域的被污染物品检测知识。在三个真实世界数据集上的大量实验验证了P-Scanner的有效性。\n",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.11182v1",
      "published_date": "2025-04-15 13:37:38 UTC",
      "updated_date": "2025-04-15 13:37:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:18:12.566016"
    },
    {
      "arxiv_id": "2504.11171v1",
      "title": "TerraMind: Large-Scale Generative Multimodality for Earth Observation",
      "title_zh": "TerraMind：用于地球观测的大规模生成式多模态模型\n",
      "authors": [
        "Johannes Jakubik",
        "Felix Yang",
        "Benedikt Blumenstiel",
        "Erik Scheurer",
        "Rocco Sedona",
        "Stefano Maurogiovanni",
        "Jente Bosmans",
        "Nikolaos Dionelis",
        "Valerio Marsocci",
        "Niklas Kopp",
        "Rahul Ramachandran",
        "Paolo Fraccaro",
        "Thomas Brunschwiler",
        "Gabriele Cavallaro",
        "Juan Bernabe-Moreno",
        "Nicolas Longépé"
      ],
      "abstract": "We present TerraMind, the first any-to-any generative, multimodal foundation\nmodel for Earth observation (EO). Unlike other multimodal models, TerraMind is\npretrained on dual-scale representations combining both token-level and\npixel-level data across modalities. On a token level, TerraMind encodes\nhigh-level contextual information to learn cross-modal relationships, while on\na pixel level, TerraMind leverages fine-grained representations to capture\ncritical spatial nuances. We pretrained TerraMind on nine geospatial modalities\nof a global, large-scale dataset. In this paper, we demonstrate that (i)\nTerraMind's dual-scale early fusion approach unlocks a range of zero-shot and\nfew-shot applications for Earth observation, (ii) TerraMind introduces\n\"Thinking-in-Modalities\" (TiM) -- the capability of generating additional\nartificial data during finetuning and inference to improve the model output --\nand (iii) TerraMind achieves beyond state-of-the-art performance in\ncommunity-standard benchmarks for EO like PANGAEA. The pretraining dataset, the\nmodel weights, and our code is open-sourced under a permissive license.",
      "tldr_zh": "TerraMind是首个用于地球观测(EO)的任意到任意生成式多模态基础模型。它采用双尺度表示进行预训练，结合了token级别和像素级别的数据，以学习跨模态关系并捕获精细的空间细节。TerraMind在包含九种地理空间模态的大规模数据集上进行了预训练。该模型引入了“模态内思考”(Thinking-in-Modalities, TiM) 的能力，即在微调和推理过程中生成额外的合成数据以提升模型性能。实验结果表明，TerraMind在零样本和少样本的地球观测应用中表现出色，并在PANGAEA等标准基准测试中超越了现有技术水平。该模型的预训练数据集、模型权重和代码均已开源。\n",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.11171v1",
      "published_date": "2025-04-15 13:17:39 UTC",
      "updated_date": "2025-04-15 13:17:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:18:24.182497"
    },
    {
      "arxiv_id": "2504.11169v1",
      "title": "MuSeD: A Multimodal Spanish Dataset for Sexism Detection in Social Media Videos",
      "title_zh": "MuSeD：用于社交媒体视频中性别歧视检测的多模态西班牙语数据集\n",
      "authors": [
        "Laura De Grazia",
        "Pol Pastells",
        "Mauro Vázquez Chas",
        "Desmond Elliott",
        "Danae Sánchez Villegas",
        "Mireia Farrús",
        "Mariona Taulé"
      ],
      "abstract": "Sexism is generally defined as prejudice and discrimination based on sex or\ngender, affecting every sector of society, from social institutions to\nrelationships and individual behavior. Social media platforms amplify the\nimpact of sexism by conveying discriminatory content not only through text but\nalso across multiple modalities, highlighting the critical need for a\nmultimodal approach to the analysis of sexism online. With the rise of social\nmedia platforms where users share short videos, sexism is increasingly\nspreading through video content. Automatically detecting sexism in videos is a\nchallenging task, as it requires analyzing the combination of verbal, audio,\nand visual elements to identify sexist content. In this study, (1) we introduce\nMuSeD, a new Multimodal Spanish dataset for Sexism Detection consisting of\n$\\approx$ 11 hours of videos extracted from TikTok and BitChute; (2) we propose\nan innovative annotation framework for analyzing the contribution of textual\nand multimodal labels in the classification of sexist and non-sexist content;\nand (3) we evaluate a range of large language models (LLMs) and multimodal LLMs\non the task of sexism detection. We find that visual information plays a key\nrole in labeling sexist content for both humans and models. Models effectively\ndetect explicit sexism; however, they struggle with implicit cases, such as\nstereotypes, instances where annotators also show low agreement. This\nhighlights the inherent difficulty of the task, as identifying implicit sexism\ndepends on the social and cultural context.",
      "tldr_zh": "该研究介绍了MuSeD，一个用于检测社交媒体视频中性别歧视的西班牙语多模态数据集，包含约11小时的TikTok和BitChute视频。研究提出了一个创新的标注框架，用于分析文本和多模态标签在性别歧视内容分类中的贡献。研究人员评估了一系列大型语言模型(LLMs)和多模态LLMs在性别歧视检测任务上的表现。结果表明，视觉信息在标注性别歧视内容中起着关键作用，模型能够有效检测显性性别歧视，但在隐性性别歧视（如刻板印象）方面表现不佳，这突显了识别隐性性别歧视的难度，因为它依赖于社会和文化背景。\n",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.11169v1",
      "published_date": "2025-04-15 13:16:46 UTC",
      "updated_date": "2025-04-15 13:16:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:18:36.125423"
    },
    {
      "arxiv_id": "2504.11168v2",
      "title": "Bypassing Prompt Injection and Jailbreak Detection in LLM Guardrails",
      "title_zh": "绕过 LLM Guardrails 中的 Prompt 注入和越狱检测\n",
      "authors": [
        "William Hackett",
        "Lewis Birch",
        "Stefan Trawicki",
        "Neeraj Suri",
        "Peter Garraghan"
      ],
      "abstract": "Large Language Models (LLMs) guardrail systems are designed to protect\nagainst prompt injection and jailbreak attacks. However, they remain vulnerable\nto evasion techniques. We demonstrate two approaches for bypassing LLM prompt\ninjection and jailbreak detection systems via traditional character injection\nmethods and algorithmic Adversarial Machine Learning (AML) evasion techniques.\nThrough testing against six prominent protection systems, including Microsoft's\nAzure Prompt Shield and Meta's Prompt Guard, we show that both methods can be\nused to evade detection while maintaining adversarial utility achieving in some\ninstances up to 100% evasion success. Furthermore, we demonstrate that\nadversaries can enhance Attack Success Rates (ASR) against black-box targets by\nleveraging word importance ranking computed by offline white-box models. Our\nfindings reveal vulnerabilities within current LLM protection mechanisms and\nhighlight the need for more robust guardrail systems.",
      "tldr_zh": "该研究揭示了大型语言模型(LLM)防护系统在防御提示注入和越狱攻击方面的漏洞。研究者通过传统的字符注入方法和算法对抗机器学习(AML)规避技术，展示了绕过LLM提示注入和越狱检测系统的两种方法。通过对包括Microsoft Azure Prompt Shield和Meta Prompt Guard在内的六个主流防护系统进行测试，证明这些方法能够成功规避检测，并在某些情况下达到100%的规避成功率，同时保持对抗效用。此外，研究表明，攻击者可以通过利用离线白盒模型计算的词语重要性排序来提高针对黑盒目标的攻击成功率(ASR)。研究结果强调了当前LLM保护机制的脆弱性，并呼吁开发更强大的防护系统。\n",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG",
        "I.2.7"
      ],
      "primary_category": "cs.CR",
      "comment": "12 pages, 5 figures, 6 tables",
      "pdf_url": "http://arxiv.org/pdf/2504.11168v2",
      "published_date": "2025-04-15 13:16:02 UTC",
      "updated_date": "2025-04-16 15:33:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:18:48.141315"
    },
    {
      "arxiv_id": "2504.11160v1",
      "title": "DMAGaze: Gaze Estimation Based on Feature Disentanglement and Multi-Scale Attention",
      "title_zh": "DMAGaze：基于特征解耦和多尺度注意力机制的视线估计\n",
      "authors": [
        "Haohan Chen",
        "Hongjia Liu",
        "Shiyong Lan",
        "Wenwu Wang",
        "Yixin Qiao",
        "Yao Li",
        "Guonan Deng"
      ],
      "abstract": "Gaze estimation, which predicts gaze direction, commonly faces the challenge\nof interference from complex gaze-irrelevant information in face images. In\nthis work, we propose DMAGaze, a novel gaze estimation framework that exploits\ninformation from facial images in three aspects: gaze-relevant global features\n(disentangled from facial image), local eye features (extracted from cropped\neye patch), and head pose estimation features, to improve overall performance.\nFirstly, we design a new continuous mask-based Disentangler to accurately\ndisentangle gaze-relevant and gaze-irrelevant information in facial images by\nachieving the dual-branch disentanglement goal through separately\nreconstructing the eye and non-eye regions. Furthermore, we introduce a new\ncascaded attention module named Multi-Scale Global Local Attention Module\n(MS-GLAM). Through a customized cascaded attention structure, it effectively\nfocuses on global and local information at multiple scales, further enhancing\nthe information from the Disentangler. Finally, the global gaze-relevant\nfeatures disentangled by the upper face branch, combined with head pose and\nlocal eye features, are passed through the detection head for high-precision\ngaze estimation. Our proposed DMAGaze has been extensively validated on two\nmainstream public datasets, achieving state-of-the-art performance.",
      "tldr_zh": "DMAGaze是一种新颖的注视估计框架，旨在解决面部图像中复杂且与注视无关的信息干扰问题。该框架利用面部图像中的三个方面的信息：从面部图像中解耦的与注视相关的全局特征、从裁剪的眼部图像中提取的局部眼部特征以及头部姿势估计特征，以提高整体性能。DMAGaze设计了一个新的基于连续掩码的解耦器(Disentangler)，通过分别重建眼睛和非眼睛区域，准确地解耦面部图像中与注视相关和无关的信息。此外，引入了一个新的级联注意力模块，即多尺度全局局部注意力模块(MS-GLAM)，通过定制的级联注意力结构，有效地关注多尺度的全局和局部信息，进一步增强来自解耦器的信息。实验结果表明，DMAGaze在两个主流公共数据集上取得了state-of-the-art的性能。\n",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.11160v1",
      "published_date": "2025-04-15 13:08:43 UTC",
      "updated_date": "2025-04-15 13:08:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:19:00.391807"
    },
    {
      "arxiv_id": "2504.11159v1",
      "title": "C-SHAP for time series: An approach to high-level temporal explanations",
      "title_zh": "C-SHAP 时间序列方法：一种高级别时间解释方法",
      "authors": [
        "Annemarie Jutte",
        "Faizan Ahmed",
        "Jeroen Linssen",
        "Maurice van Keulen"
      ],
      "abstract": "Time series are ubiquitous in domains such as energy forecasting, healthcare,\nand industry. Using AI systems, some tasks within these domains can be\nefficiently handled. Explainable AI (XAI) aims to increase the reliability of\nAI solutions by explaining model reasoning. For time series, many XAI methods\nprovide point- or sequence-based attribution maps. These methods explain model\nreasoning in terms of low-level patterns. However, they do not capture\nhigh-level patterns that may also influence model reasoning. We propose a\nconcept-based method to provide explanations in terms of these high-level\npatterns. In this paper, we present C-SHAP for time series, an approach which\ndetermines the contribution of concepts to a model outcome. We provide a\ngeneral definition of C-SHAP and present an example implementation using time\nseries decomposition. Additionally, we demonstrate the effectiveness of the\nmethodology through a use case from the energy domain.",
      "tldr_zh": "本文提出了一种名为C-SHAP的时间序列解释方法，旨在提供高层次的时间解释。现有时间序列XAI方法主要提供基于点或序列的归因图，解释模型在低层次模式上的推理。C-SHAP则通过确定概念对模型输出的贡献，从而解释模型在高层次模式上的推理。文章给出了C-SHAP的通用定义，并使用时间序列分解提供了一个具体实现案例，最后通过能源领域的用例验证了该方法的有效性。\n",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.11159v1",
      "published_date": "2025-04-15 13:06:32 UTC",
      "updated_date": "2025-04-15 13:06:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:19:11.979113"
    },
    {
      "arxiv_id": "2504.11130v1",
      "title": "Divergence of Empirical Neural Tangent Kernel in Classification Problems",
      "title_zh": "分类问题中经验神经正切核的散度\n",
      "authors": [
        "Zixiong Yu",
        "Songtao Tian",
        "Guhan Chen"
      ],
      "abstract": "This paper demonstrates that in classification problems, fully connected\nneural networks (FCNs) and residual neural networks (ResNets) cannot be\napproximated by kernel logistic regression based on the Neural Tangent Kernel\n(NTK) under overtraining (i.e., when training time approaches infinity).\nSpecifically, when using the cross-entropy loss, regardless of how large the\nnetwork width is (as long as it is finite), the empirical NTK diverges from the\nNTK on the training samples as training time increases. To establish this\nresult, we first demonstrate the strictly positive definiteness of the NTKs for\nmulti-layer FCNs and ResNets. Then, we prove that during training, % with the\ncross-entropy loss, the neural network parameters diverge if the smallest\neigenvalue of the empirical NTK matrix (Gram matrix) with respect to training\nsamples is bounded below by a positive constant. This behavior contrasts\nsharply with the lazy training regime commonly observed in regression problems.\nConsequently, using a proof by contradiction, we show that the empirical NTK\ndoes not uniformly converge to the NTK across all times on the training samples\nas the network width increases. We validate our theoretical results through\nexperiments on both synthetic data and the MNIST classification task. This\nfinding implies that NTK theory is not applicable in this context, with\nsignificant theoretical implications for understanding neural networks in\nclassification problems.",
      "tldr_zh": "该论文证明了在分类问题中，全连接神经网络(FCNs)和残差神经网络(ResNets)在过度训练下不能用基于神经正切核(NTK)的核逻辑回归来近似。具体来说，使用交叉熵损失时，无论网络宽度多大（只要是有限的），经验NTK都会随着训练时间的增加而偏离训练样本上的NTK。为了证明这个结果，首先证明了多层FCNs和ResNets的NTK的严格正定性。然后，证明了在训练过程中，如果关于训练样本的经验NTK矩阵（Gram矩阵）的最小特征值被一个正的常数限制在下面，那么使用交叉熵损失，神经网络参数就会发散。这种行为与回归问题中常见的lazy training regime形成鲜明对比。因此，通过反证法，证明了随着网络宽度的增加，经验NTK不会在所有时间都在训练样本上一致收敛到NTK。通过对合成数据和MNIST分类任务的实验验证了理论结果。这一发现意味着NTK理论不适用于这种情况，对理解分类问题中的神经网络具有重要的理论意义。\n",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.11130v1",
      "published_date": "2025-04-15 12:30:21 UTC",
      "updated_date": "2025-04-15 12:30:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:19:24.592765"
    },
    {
      "arxiv_id": "2504.11109v1",
      "title": "Fine-Tuning Large Language Models on Quantum Optimization Problems for Circuit Generation",
      "title_zh": "在量子优化问题上微调大型语言模型以生成量子电路\n",
      "authors": [
        "Linus Jern",
        "Valter Uotila",
        "Cong Yu",
        "Bo Zhao"
      ],
      "abstract": "Large language models (LLM) have achieved remarkable outcomes in addressing\ncomplex problems, including math, coding, and analyzing large amounts of\nscientific reports. Yet few works have explored the potential of LLM in quantum\ncomputing. The most challenging problem is how to leverage LLMs to\nautomatically generate quantum circuits at a large scale. In this paper, we\naddress such a challenge by fine-tuning LLMs and injecting the domain-specific\nknowledge of quantum computing. In particular, we investigate the mechanisms to\ngenerate training data sets and construct the end-to-end pipeline to fine-tune\npre-trained LLMs that produce parameterized quantum circuits for optimization\nproblems. We have prepared 14,000 quantum circuits covering a substantial part\nof the quantum optimization landscape: 12 optimization problem instances and\ntheir optimized QAOA, VQE, and adaptive VQE circuits. The fine-tuned LLMs can\nconstruct syntactically correct parametrized quantum circuits in the most\nrecent OpenQASM 3.0. We have evaluated the quality of the parameters by\ncomparing them to the optimized expectation values and distributions. Our\nevaluation shows that the fine-tuned LLM outperforms state-of-the-art models\nand that the parameters are better than random. The LLM-generated parametrized\ncircuits and initial parameters can be used as a starting point for further\noptimization, \\emph{e.g.,} templates in quantum machine learning and the\nbenchmark for compilers and hardware.",
      "tldr_zh": "该论文探索了利用大型语言模型(LLMs)自动生成大规模量子电路的潜力，通过微调LLMs并注入量子计算的领域知识来解决这一挑战。研究者构建了一个端到端的流程，用于微调预训练的LLMs，使其能够为优化问题生成参数化的量子电路。他们准备了一个包含14,000个量子电路的数据集，涵盖了量子优化领域的重要部分，包括12个优化问题实例及其优化的QAOA、VQE和自适应VQE电路。实验结果表明，微调后的LLM能够构建符合OpenQASM 3.0规范的参数化量子电路，并且其生成的参数优于现有模型和随机参数，可作为量子机器学习中的模板或编译器和硬件的基准。\n",
      "categories": [
        "quant-ph",
        "cs.AI"
      ],
      "primary_category": "quant-ph",
      "comment": "12 pages, 8 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2504.11109v1",
      "published_date": "2025-04-15 11:56:54 UTC",
      "updated_date": "2025-04-15 11:56:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:19:36.301175"
    },
    {
      "arxiv_id": "2504.11091v1",
      "title": "AI-guided Antibiotic Discovery Pipeline from Target Selection to Compound Identification",
      "title_zh": "AI引导的抗生素发现流程：从靶标选择到化合物鉴定\n",
      "authors": [
        "Maximilian G. Schuh",
        "Joshua Hesse",
        "Stephan A. Sieber"
      ],
      "abstract": "Antibiotic resistance presents a growing global health crisis, demanding new\ntherapeutic strategies that target novel bacterial mechanisms. Recent advances\nin protein structure prediction and machine learning-driven molecule generation\noffer a promising opportunity to accelerate drug discovery. However, practical\nguidance on selecting and integrating these models into real-world pipelines\nremains limited. In this study, we develop an end-to-end, artificial\nintelligence-guided antibiotic discovery pipeline that spans target\nidentification to compound realization. We leverage structure-based clustering\nacross predicted proteomes of multiple pathogens to identify conserved,\nessential, and non-human-homologous targets. We then systematically evaluate\nsix leading 3D-structure-aware generative models$\\unicode{x2014}$spanning\ndiffusion, autoregressive, graph neural network, and language model\narchitectures$\\unicode{x2014}$on their usability, chemical validity, and\nbiological relevance. Rigorous post-processing filters and commercial analogue\nsearches reduce over 100 000 generated compounds to a focused, synthesizable\nset. Our results highlight DeepBlock and TamGen as top performers across\ndiverse criteria, while also revealing critical trade-offs between model\ncomplexity, usability, and output quality. This work provides a comparative\nbenchmark and blueprint for deploying artificial intelligence in early-stage\nantibiotic development.",
      "tldr_zh": "该研究提出了一种AI驱动的抗生素发现流程，从靶标选择到化合物鉴定。该流程利用蛋白质结构预测和机器学习驱动的分子生成技术，加速针对新型细菌机制的药物发现。研究者通过基于结构的聚类方法，在多个病原体的预测蛋白质组中识别保守、必需且非人类同源的靶标。同时，系统地评估了六种3D结构感知的生成模型（包括扩散模型、自回归模型、图神经网络和语言模型）的可用性、化学有效性和生物相关性。结果表明，DeepBlock和TamGen在各种标准下表现最佳，并揭示了模型复杂性、可用性和输出质量之间的关键权衡。该研究为在早期抗生素开发中部署人工智能提供了一个比较基准和蓝图。\n",
      "categories": [
        "q-bio.BM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.BM",
      "comment": "12 pages, preprint",
      "pdf_url": "http://arxiv.org/pdf/2504.11091v1",
      "published_date": "2025-04-15 11:36:27 UTC",
      "updated_date": "2025-04-15 11:36:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:19:48.271364"
    },
    {
      "arxiv_id": "2504.11083v1",
      "title": "QAMA: Quantum annealing multi-head attention operator with classical deep learning framework",
      "title_zh": "QAMA：基于经典深度学习框架的量子退火多头注意力算子\n",
      "authors": [
        "Peng Du",
        "Shuolei Wang",
        "Shicheng Li",
        "Jinjing Shi"
      ],
      "abstract": "As large language models scale up, the conventional attention mechanism faces\ncritical challenges of exponential growth in memory consumption and energy\ncosts. Quantum annealing computing, with its inherent advantages in\ncomputational efficiency and low energy consumption, offers an innovative\ndirection for constructing novel deep learning architectures. This study\nproposes the first Quantum Annealing-based Multi-head Attention (QAMA)\nmechanism, achieving seamless compatibility with classical attention\narchitectures through quadratic unconstrained binary optimization (QUBO)\nmodeling of forward propagation and energy-based backpropagation. The method\ninnovatively leverages the quantum bit interaction characteristics of Ising\nmodels to optimize the conventional $O(n^2)$ spatiotemporal complexity into\nlinear resource consumption. Integrated with the optical computing advantages\nof coherent Ising machines (CIM), the system maintains millisecond-level\nreal-time responsiveness while significantly reducing energy consumption. Our\nkey contributions include: Theoretical proofs establish QAMA mathematical\nequivalence to classical attention mechanisms; Dual optimization of multi-head\nspecificity and long-range information capture via QUBO constraints; Explicit\ngradient proofs for the Ising energy equation are utilized to implement\ngradient conduction as the only path in the computational graph as a layer;\nProposed soft selection mechanism overcoming traditional binary attention\nlimitations to approximate continuous weights. Experiments on QBoson CPQC\nquantum computer show QAMA achieves comparable accuracy to classical operators\nwhile reducing inference time to millisecond level and improving solution\nquality. This work pioneers architectural-level integration of quantum\ncomputing and deep learning, applicable to any attention-based model, driving\nparadigm innovation in AI foundational computing.",
      "tldr_zh": "该研究提出了一种基于量子退火的多头注意力机制(QAMA)，旨在解决传统注意力机制在大规模语言模型中面临的内存和能耗瓶颈。QAMA通过二次无约束二元优化(QUBO)建模前向传播和基于能量的反向传播，实现了与经典注意力架构的无缝兼容。该方法利用Ising模型的量子比特交互特性，将传统$O(n^2)$的时空复杂度优化为线性资源消耗。结合相干Ising机(CIM)的光学计算优势，系统在保持毫秒级实时响应的同时显著降低了能耗。实验表明，在QBoson CPQC量子计算机上，QAMA在达到与经典算子相当的精度的同时，将推理时间缩短到毫秒级并提高了解决方案的质量。这项工作开创了量子计算和深度学习的架构级集成，适用于任何基于注意力的模型。\n",
      "categories": [
        "quant-ph",
        "cs.AI"
      ],
      "primary_category": "quant-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.11083v1",
      "published_date": "2025-04-15 11:29:09 UTC",
      "updated_date": "2025-04-15 11:29:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:20:00.503345"
    },
    {
      "arxiv_id": "2504.11082v1",
      "title": "DeepMLF: Multimodal language model with learnable tokens for deep fusion in sentiment analysis",
      "title_zh": "DeepMLF：用于情感分析中深度融合的具有可学习令牌的多模态语言模型\n",
      "authors": [
        "Efthymios Georgiou",
        "Vassilis Katsouros",
        "Yannis Avrithis",
        "Alexandros Potamianos"
      ],
      "abstract": "While multimodal fusion has been extensively studied in Multimodal Sentiment\nAnalysis (MSA), the role of fusion depth and multimodal capacity allocation\nremains underexplored. In this work, we position fusion depth, scalability, and\ndedicated multimodal capacity as primary factors for effective fusion. We\nintroduce DeepMLF, a novel multimodal language model (LM) with learnable tokens\ntailored toward deep fusion. DeepMLF leverages an audiovisual encoder and a\npretrained decoder LM augmented with multimodal information across its layers.\nWe append learnable tokens to the LM that: 1) capture modality interactions in\na controlled fashion and 2) preserve independent information flow for each\nmodality. These fusion tokens gather linguistic information via causal\nself-attention in LM Blocks and integrate with audiovisual information through\ncross-attention MM Blocks. Serving as dedicated multimodal capacity, this\ndesign enables progressive fusion across multiple layers, providing depth in\nthe fusion process. Our training recipe combines modality-specific losses and\nlanguage modelling loss, with the decoder LM tasked to predict ground truth\npolarity. Across three MSA benchmarks with varying dataset characteristics,\nDeepMLF achieves state-of-the-art performance. Our results confirm that deeper\nfusion leads to better performance, with optimal fusion depths (5-7) exceeding\nthose of existing approaches. Additionally, our analysis on the number of\nfusion tokens reveals that small token sets ($\\sim$20) achieve optimal\nperformance. We examine the importance of representation learning order (fusion\ncurriculum) through audiovisual encoder initialization experiments. Our\nablation studies demonstrate the superiority of the proposed fusion design and\ngating while providing a holistic examination of DeepMLF's scalability to LLMs,\nand the impact of each training objective and embedding regularization.",
      "tldr_zh": "该论文提出了DeepMLF，一种用于情感分析的新型多模态语言模型(Multimodal Language Model, LM)，专注于深度融合。DeepMLF利用音视频编码器和一个预训练的解码器LM，并通过可学习的tokens在各层增强多模态信息，从而控制模态交互并保持各模态的独立信息流。这些融合tokens通过自注意力机制收集语言信息，并通过交叉注意力机制与音视频信息集成，实现跨多层的渐进式融合。实验结果表明，DeepMLF在三个多模态情感分析(Multimodal Sentiment Analysis, MSA)基准数据集上取得了state-of-the-art的性能，验证了更深层次的融合能够带来更好的效果，且少量融合tokens即可达到最佳性能。该研究还探讨了表征学习顺序的重要性，并通过消融实验验证了所提出的融合设计和门控机制的优越性。\n",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Preprint",
      "pdf_url": "http://arxiv.org/pdf/2504.11082v1",
      "published_date": "2025-04-15 11:28:02 UTC",
      "updated_date": "2025-04-15 11:28:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:20:12.712028"
    },
    {
      "arxiv_id": "2504.11075v1",
      "title": "Emergence of Goal-Directed Behaviors via Active Inference with Self-Prior",
      "title_zh": "基于自先验主动推理的目标导向行为的涌现\n",
      "authors": [
        "Dongmin Kim",
        "Hoshinori Kanazawa",
        "Naoto Yoshida",
        "Yasuo Kuniyoshi"
      ],
      "abstract": "Infants often exhibit goal-directed behaviors, such as reaching for a sensory\nstimulus, even when no external reward criterion is provided. These\nintrinsically motivated behaviors facilitate spontaneous exploration and\nlearning of the body and environment during early developmental stages.\nAlthough computational modeling can offer insight into the mechanisms\nunderlying such behaviors, many existing studies on intrinsic motivation focus\nprimarily on how exploration contributes to acquiring external rewards. In this\npaper, we propose a novel density model for an agent's own multimodal sensory\nexperiences, called the \"self-prior,\" and investigate whether it can\nautonomously induce goal-directed behavior. Integrated within an active\ninference framework based on the free energy principle, the self-prior\ngenerates behavioral references purely from an intrinsic process that minimizes\nmismatches between average past sensory experiences and current observations.\nThis mechanism is also analogous to the acquisition and utilization of a body\nschema through continuous interaction with the environment. We examine this\napproach in a simulated environment and confirm that the agent spontaneously\nreaches toward a tactile stimulus. Our study implements intrinsically motivated\nbehavior shaped by the agent's own sensory experiences, demonstrating the\nspontaneous emergence of intentional behavior during early development.",
      "tldr_zh": "本文提出了一种新的密度模型，称为“自我先验(self-prior)”，用于模拟智能体自身的多元感官体验，并研究其是否能自主诱导目标导向行为。该模型整合到基于自由能原理的主动推理框架中，通过最小化过去平均感官体验与当前观察之间的不匹配，纯粹从内在过程生成行为参考。该机制类似于通过与环境的持续交互来获取和利用身体图式(body schema)。在模拟环境中，验证了智能体能够自发地触摸刺激。研究表明，由智能体自身感官体验塑造的内在动机行为能够涌现出早期发展中的意向性行为。\n",
      "categories": [
        "cs.AI",
        "68T05, 68T40, 68T42",
        "I.2.0; I.2.6; I.2.9"
      ],
      "primary_category": "cs.AI",
      "comment": "20 pages, Code is available at\n  https://github.com/kim135797531/self-prior",
      "pdf_url": "http://arxiv.org/pdf/2504.11075v1",
      "published_date": "2025-04-15 11:16:27 UTC",
      "updated_date": "2025-04-15 11:16:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:20:24.251523"
    },
    {
      "arxiv_id": "2504.11074v2",
      "title": "Dynamical errors in machine learning forecasts",
      "title_zh": "机器学习预测中的动态误差\n",
      "authors": [
        "Zhou Fang",
        "Gianmarco Mengaldo"
      ],
      "abstract": "In machine learning forecasting, standard error metrics such as mean absolute\nerror (MAE) and mean squared error (MSE) quantify discrepancies between\npredictions and target values. However, these metrics do not directly evaluate\nthe physical and/or dynamical consistency of forecasts, an increasingly\ncritical concern in scientific and engineering applications.\n  Indeed, a fundamental yet often overlooked question is whether machine\nlearning forecasts preserve the dynamical behavior of the underlying system.\nAddressing this issue is essential for assessing the fidelity of machine\nlearning models and identifying potential failure modes, particularly in\napplications where maintaining correct dynamical behavior is crucial.\n  In this work, we investigate the relationship between standard forecasting\nerror metrics, such as MAE and MSE, and the dynamical properties of the\nunderlying system. To achieve this goal, we use two recently developed\ndynamical indices: the instantaneous dimension ($d$), and the inverse\npersistence ($\\theta$). Our results indicate that larger forecast errors --\ne.g., higher MSE -- tend to occur in states with higher $d$ (higher complexity)\nand higher $\\theta$ (lower persistence). To further assess dynamical\nconsistency, we propose error metrics based on the dynamical indices that\nmeasure the discrepancy of the forecasted $d$ and $\\theta$ versus their correct\nvalues. Leveraging these dynamical indices-based metrics, we analyze direct and\nrecursive forecasting strategies for three canonical datasets -- Lorenz,\nKuramoto-Sivashinsky equation, and Kolmogorov flow -- as well as a real-world\nweather forecasting task. Our findings reveal substantial distortions in\ndynamical properties in ML forecasts, especially for long forecast lead times\nor long recursive simulations, providing complementary information on ML\nforecast fidelity that can be used to improve ML models.",
      "tldr_zh": "这篇论文探讨了机器学习预测中标准误差指标（如MAE和MSE）与系统动力学一致性的关系。研究发现，传统误差指标无法直接评估预测结果的物理和动力学一致性，而这在科学和工程应用中至关重要。论文利用瞬时维度($d$)和逆持久性($\\theta$)这两个动力学指标，揭示了较大预测误差通常出现在具有较高$d$（更高复杂度）和较高$\\theta$（较低持久性）的状态中。此外，论文提出了基于动力学指标的误差度量，用于评估预测的$d$和$\\theta$与真实值的差异。通过对Lorenz系统、Kuramoto-Sivashinsky方程、Kolmogorov流以及真实天气预报任务的分析，研究表明机器学习预测在动力学特性方面存在显著失真，尤其是在长期预测或递归模拟中。这些发现为评估和改进机器学习模型的预测保真度提供了新的视角。\n",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.comp-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.11074v2",
      "published_date": "2025-04-15 11:16:13 UTC",
      "updated_date": "2025-04-16 08:48:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:20:36.534551"
    },
    {
      "arxiv_id": "2504.11045v1",
      "title": "Neural Control Barrier Functions from Physics Informed Neural Networks",
      "title_zh": "基于物理信息神经网络的神经控制障碍函数\n",
      "authors": [
        "Shreenabh Agrawal",
        "Manan Tayal",
        "Aditya Singh",
        "Shishir Kolathaya"
      ],
      "abstract": "As autonomous systems become increasingly prevalent in daily life, ensuring\ntheir safety is paramount. Control Barrier Functions (CBFs) have emerged as an\neffective tool for guaranteeing safety; however, manually designing them for\nspecific applications remains a significant challenge. With the advent of deep\nlearning techniques, recent research has explored synthesizing CBFs using\nneural networks-commonly referred to as neural CBFs. This paper introduces a\nnovel class of neural CBFs that leverages a physics-inspired neural network\nframework by incorporating Zubov's Partial Differential Equation (PDE) within\nthe context of safety. This approach provides a scalable methodology for\nsynthesizing neural CBFs applicable to high-dimensional systems. Furthermore,\nby utilizing reciprocal CBFs instead of zeroing CBFs, the proposed framework\nallows for the specification of flexible, user-defined safe regions. To\nvalidate the effectiveness of the approach, we present case studies on three\ndifferent systems: an inverted pendulum, autonomous ground navigation, and\naerial navigation in obstacle-laden environments.",
      "tldr_zh": "该论文提出了一种新的神经控制屏障函数(neural CBFs)方法，利用物理信息神经网络(physics-informed neural network)框架，将Zubov偏微分方程(PDE)融入到安全性考量中。这种方法为合成适用于高维系统的neural CBFs提供了一种可扩展的途径。通过使用倒数控制屏障函数(reciprocal CBFs)代替零化控制屏障函数(zeroing CBFs)，该框架允许指定灵活的、用户自定义的安全区域。在倒立摆、自主地面导航和障碍环境中的空中导航三个案例研究中验证了该方法的有效性。\n",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "8 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.11045v1",
      "published_date": "2025-04-15 10:13:30 UTC",
      "updated_date": "2025-04-15 10:13:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:20:48.092987"
    },
    {
      "arxiv_id": "2504.11038v1",
      "title": "QAVA: Query-Agnostic Visual Attack to Large Vision-Language Models",
      "title_zh": "QAVA：面向大型视觉-语言模型的查询无关视觉攻击\n",
      "authors": [
        "Yudong Zhang",
        "Ruobing Xie",
        "Jiansheng Chen",
        "Xingwu Sun",
        "Zhanhui Kang",
        "Yu Wang"
      ],
      "abstract": "In typical multimodal tasks, such as Visual Question Answering (VQA),\nadversarial attacks targeting a specific image and question can lead large\nvision-language models (LVLMs) to provide incorrect answers. However, it is\ncommon for a single image to be associated with multiple questions, and LVLMs\nmay still answer other questions correctly even for an adversarial image\nattacked by a specific question. To address this, we introduce the\nquery-agnostic visual attack (QAVA), which aims to create robust adversarial\nexamples that generate incorrect responses to unspecified and unknown\nquestions. Compared to traditional adversarial attacks focused on specific\nimages and questions, QAVA significantly enhances the effectiveness and\nefficiency of attacks on images when the question is unknown, achieving\nperformance comparable to attacks on known target questions. Our research\nbroadens the scope of visual adversarial attacks on LVLMs in practical\nsettings, uncovering previously overlooked vulnerabilities, particularly in the\ncontext of visual adversarial threats. The code is available at\nhttps://github.com/btzyd/qava.",
      "tldr_zh": "该论文提出了Query-Agnostic Visual Attack (QAVA)，一种针对大型视觉语言模型(LVLMs)的与查询无关的视觉攻击方法。与传统的针对特定图像和问题的对抗攻击不同，QAVA旨在生成鲁棒的对抗样本，使LVLMs对未指定和未知的问题产生错误的回答。实验结果表明，在问题未知的情况下，QAVA显著提高了攻击图像的有效性和效率，其性能与针对已知目标问题的攻击相当。这项研究扩展了视觉对抗攻击在LVLMs上的应用范围，揭示了先前被忽视的漏洞，尤其是在视觉对抗威胁的背景下。\n",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by NAACL 2025 main",
      "pdf_url": "http://arxiv.org/pdf/2504.11038v1",
      "published_date": "2025-04-15 10:00:01 UTC",
      "updated_date": "2025-04-15 10:00:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:21:00.203228"
    },
    {
      "arxiv_id": "2504.11020v1",
      "title": "\"Even explanations will not help in trusting [this] fundamentally biased system\": A Predictive Policing Case-Study",
      "title_zh": "“即使解释也无助于信任[这个]存在根本性偏见的系统”：一个预测性警务案例研究\n",
      "authors": [
        "Siddharth Mehrotra",
        "Ujwal Gadiraju",
        "Eva Bittner",
        "Folkert van Delden",
        "Catholijn M. Jonker",
        "Myrthe L. Tielman"
      ],
      "abstract": "In today's society, where Artificial Intelligence (AI) has gained a vital\nrole, concerns regarding user's trust have garnered significant attention. The\nuse of AI systems in high-risk domains have often led users to either\nunder-trust it, potentially causing inadequate reliance or over-trust it,\nresulting in over-compliance. Therefore, users must maintain an appropriate\nlevel of trust. Past research has indicated that explanations provided by AI\nsystems can enhance user understanding of when to trust or not trust the\nsystem. However, the utility of presentation of different explanations forms\nstill remains to be explored especially in high-risk domains. Therefore, this\nstudy explores the impact of different explanation types (text, visual, and\nhybrid) and user expertise (retired police officers and lay users) on\nestablishing appropriate trust in AI-based predictive policing. While we\nobserved that the hybrid form of explanations increased the subjective trust in\nAI for expert users, it did not led to better decision-making. Furthermore, no\nform of explanations helped build appropriate trust. The findings of our study\nemphasize the importance of re-evaluating the use of explanations to build\n[appropriate] trust in AI based systems especially when the system's use is\nquestionable. Finally, we synthesize potential challenges and policy\nrecommendations based on our results to design for appropriate trust in\nhigh-risk based AI-based systems.",
      "tldr_zh": "本研究探讨了不同类型的解释（文本、视觉和混合）以及用户专业知识（退休警官和普通用户）对建立对基于AI的预测性警务的适当信任的影响。研究发现，混合解释形式虽然增加了专家用户对AI的主观信任，但并未改善决策。更重要的是，没有任何一种解释形式能够帮助建立适当的信任。研究结果强调，需要重新评估解释在建立对AI系统的适当信任中的作用，特别是当系统的使用受到质疑时。最后，该研究总结了潜在的挑战和政策建议，旨在为高风险AI系统设计适当的信任机制。\n",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "33rd ACM Conference on User Modeling, Adaptation and Personalization\n  (UMAP '25), June 16--19, 2025, New York City, NY, USA",
      "pdf_url": "http://arxiv.org/pdf/2504.11020v1",
      "published_date": "2025-04-15 09:43:48 UTC",
      "updated_date": "2025-04-15 09:43:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:21:12.145274"
    },
    {
      "arxiv_id": "2504.11014v2",
      "title": "GATE3D: Generalized Attention-based Task-synergized Estimation in 3D*",
      "title_zh": "GATE3D：基于广义注意力的三维任务协同估计*\n",
      "authors": [
        "Eunsoo Im",
        "Jung Kwon Lee",
        "Changhyun Jee"
      ],
      "abstract": "The emerging trend in computer vision emphasizes developing universal models\ncapable of simultaneously addressing multiple diverse tasks. Such universality\ntypically requires joint training across multi-domain datasets to ensure\neffective generalization. However, monocular 3D object detection presents\nunique challenges in multi-domain training due to the scarcity of datasets\nannotated with accurate 3D ground-truth labels, especially beyond typical\nroad-based autonomous driving contexts. To address this challenge, we introduce\na novel weakly supervised framework leveraging pseudo-labels. Current\npretrained models often struggle to accurately detect pedestrians in non-road\nenvironments due to inherent dataset biases. Unlike generalized image-based 2D\nobject detection models, achieving similar generalization in monocular 3D\ndetection remains largely unexplored. In this paper, we propose GATE3D, a novel\nframework designed specifically for generalized monocular 3D object detection\nvia weak supervision. GATE3D effectively bridges domain gaps by employing\nconsistency losses between 2D and 3D predictions. Remarkably, our model\nachieves competitive performance on the KITTI benchmark as well as on an\nindoor-office dataset collected by us to evaluate the generalization\ncapabilities of our framework. Our results demonstrate that GATE3D\nsignificantly accelerates learning from limited annotated data through\neffective pre-training strategies, highlighting substantial potential for\nbroader impacts in robotics, augmented reality, and virtual reality\napplications. Project page: https://ies0411.github.io/GATE3D/",
      "tldr_zh": "本文提出了一种名为GATE3D的新框架，用于广义单目3D目标检测，通过弱监督学习实现。GATE3D旨在解决单目3D目标检测在多领域训练中，缺乏精确3D标注数据的问题，尤其是在非道路环境中。该框架利用2D和3D预测之间的一致性损失来弥合领域差距。实验结果表明，GATE3D在KITTI基准测试和室内办公数据集上都取得了具有竞争力的性能，证明了其通过有效的预训练策略加速从有限标注数据中学习的能力，并为机器人、增强现实和虚拟现实应用带来了潜力。\n",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "9pages, 1 supple",
      "pdf_url": "http://arxiv.org/pdf/2504.11014v2",
      "published_date": "2025-04-15 09:37:54 UTC",
      "updated_date": "2025-04-16 01:38:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:21:24.149449"
    },
    {
      "arxiv_id": "2504.11011v1",
      "title": "Document Quality Scoring for Web Crawling",
      "title_zh": "用于网页爬取的文档质量评分\n",
      "authors": [
        "Francesca Pezzuti",
        "Ariane Mueller",
        "Sean MacAvaney",
        "Nicola Tonellotto"
      ],
      "abstract": "The internet contains large amounts of low-quality content, yet users expect\nweb search engines to deliver high-quality, relevant results. The abundant\npresence of low-quality pages can negatively impact retrieval and crawling\nprocesses by wasting resources on these documents. Therefore, search engines\ncan greatly benefit from techniques that leverage efficient quality estimation\nmethods to mitigate these negative impacts. Quality scoring methods for web\npages are useful for many processes typical for web search systems, including\nstatic index pruning, index tiering, and crawling. Building on work by Chang et\nal.~\\cite{chang2024neural}, who proposed using neural estimators of semantic\nquality for static index pruning, we extend their approach and apply their\nneural quality scorers to assess the semantic quality of web pages in crawling\nprioritisation tasks. In our experimental analysis, we found that prioritising\nsemantically high-quality pages over low-quality ones can improve downstream\nsearch effectiveness. Our software contribution consists of a Docker container\nthat computes an effective quality score for a given web page, allowing the\nquality scorer to be easily included and used in other components of web search\nsystems.",
      "tldr_zh": "该论文研究了如何评估网页质量，以提升网络爬虫的效率和搜索引擎的性能。针对互联网上大量低质量内容浪费资源的问题，论文提出利用神经语义质量评估方法对网页进行质量打分，并将其应用于爬虫优先级排序任务。实验结果表明，优先爬取语义质量高的页面可以有效提升下游搜索的性能。此外，论文提供了一个Docker容器，方便将该质量评分器集成到其他网络搜索系统中。\n",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "Presented at WOWS2025",
      "pdf_url": "http://arxiv.org/pdf/2504.11011v1",
      "published_date": "2025-04-15 09:32:57 UTC",
      "updated_date": "2025-04-15 09:32:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:21:36.059169"
    },
    {
      "arxiv_id": "2504.11008v1",
      "title": "MediSee: Reasoning-based Pixel-level Perception in Medical Images",
      "title_zh": "MediSee：基于推理的医学图像像素级感知\n",
      "authors": [
        "Qinyue Tong",
        "Ziqian Lu",
        "Jun Liu",
        "Yangming Zheng",
        "Zheming Lu"
      ],
      "abstract": "Despite remarkable advancements in pixel-level medical image perception,\nexisting methods are either limited to specific tasks or heavily rely on\naccurate bounding boxes or text labels as input prompts. However, the medical\nknowledge required for input is a huge obstacle for general public, which\ngreatly reduces the universality of these methods. Compared with these\ndomain-specialized auxiliary information, general users tend to rely on oral\nqueries that require logical reasoning. In this paper, we introduce a novel\nmedical vision task: Medical Reasoning Segmentation and Detection (MedSD),\nwhich aims to comprehend implicit queries about medical images and generate the\ncorresponding segmentation mask and bounding box for the target object. To\naccomplish this task, we first introduce a Multi-perspective, Logic-driven\nMedical Reasoning Segmentation and Detection (MLMR-SD) dataset, which\nencompasses a substantial collection of medical entity targets along with their\ncorresponding reasoning. Furthermore, we propose MediSee, an effective baseline\nmodel designed for medical reasoning segmentation and detection. The\nexperimental results indicate that the proposed method can effectively address\nMedSD with implicit colloquial queries and outperform traditional medical\nreferring segmentation methods.",
      "tldr_zh": "该论文提出了一个新的医学视觉任务：医学推理分割与检测 (MedSD)，旨在理解关于医学图像的隐式查询，并生成目标对象的分割掩码和边界框。为此，作者构建了一个多视角、逻辑驱动的医学推理分割与检测 (MLMR-SD) 数据集，其中包含大量医学实体目标及其相应的推理。此外，论文还提出了一个名为 MediSee 的基线模型，用于解决医学推理分割与检测问题。实验结果表明，该方法能够有效处理带有隐式口语化查询的 MedSD，并优于传统的医学指代分割方法。\n",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.11008v1",
      "published_date": "2025-04-15 09:28:53 UTC",
      "updated_date": "2025-04-15 09:28:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:21:48.166845"
    },
    {
      "arxiv_id": "2504.11004v1",
      "title": "Dynamic Compressing Prompts for Efficient Inference of Large Language Models",
      "title_zh": "动态压缩提示：用于大语言模型高效推理",
      "authors": [
        "Jinwu Hu",
        "Wei Zhang",
        "Yufeng Wang",
        "Yu Hu",
        "Bin Xiao",
        "Mingkui Tan",
        "Qing Du"
      ],
      "abstract": "Large Language Models (LLMs) have shown outstanding performance across a\nvariety of tasks, partly due to advanced prompting techniques. However, these\ntechniques often require lengthy prompts, which increase computational costs\nand can hinder performance because of the limited context windows of LLMs.\nWhile prompt compression is a straightforward solution, existing methods\nconfront the challenges of retaining essential information, adapting to context\nchanges, and remaining effective across different tasks. To tackle these\nissues, we propose a task-agnostic method called Dynamic Compressing Prompts\n(LLM-DCP). Our method reduces the number of prompt tokens while aiming to\npreserve the performance as much as possible. We model prompt compression as a\nMarkov Decision Process (MDP), enabling the DCP-Agent to sequentially remove\nredundant tokens by adapting to dynamic contexts and retaining crucial content.\nWe develop a reward function for training the DCP-Agent that balances the\ncompression rate, the quality of the LLM output, and the retention of key\ninformation. This allows for prompt token reduction without needing an external\nblack-box LLM. Inspired by the progressive difficulty adjustment in curriculum\nlearning, we introduce a Hierarchical Prompt Compression (HPC) training\nstrategy that gradually increases the compression difficulty, enabling the\nDCP-Agent to learn an effective compression method that maintains information\nintegrity. Experiments demonstrate that our method outperforms state-of-the-art\ntechniques, especially at higher compression rates. The code for our approach\nwill be available at https://github.com/Fhujinwu/DCP.",
      "tldr_zh": "该论文提出了一种名为 Dynamic Compressing Prompts (LLM-DCP) 的任务无关方法，旨在减少大语言模型 (LLM) 推理时冗长的 prompt 带来的计算成本和性能瓶颈。DCP 将 prompt 压缩建模为马尔可夫决策过程 (MDP)，使 DCP-Agent 能够通过适应动态上下文并保留关键内容来顺序移除冗余 token。通过精心设计的奖励函数和分层 Prompt 压缩 (HPC) 训练策略，DCP 能够在不依赖外部黑盒 LLM 的情况下，逐步提高压缩难度并学习有效的压缩方法，保证信息完整性。实验结果表明，DCP 在高压缩率下优于现有技术。\n",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Under review (submited in 2024.11)",
      "pdf_url": "http://arxiv.org/pdf/2504.11004v1",
      "published_date": "2025-04-15 09:20:45 UTC",
      "updated_date": "2025-04-15 09:20:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:22:00.277430"
    },
    {
      "arxiv_id": "2504.10995v1",
      "title": "TMCIR: Token Merge Benefits Composed Image Retrieval",
      "title_zh": "TMCIR：令牌合并有益于组合图像检索\n",
      "authors": [
        "Chaoyang Wang",
        "Zeyu Zhang",
        "Long Teng",
        "Zijun Li",
        "Shichao Kan"
      ],
      "abstract": "Composed Image Retrieval (CIR) retrieves target images using a multi-modal\nquery that combines a reference image with text describing desired\nmodifications. The primary challenge is effectively fusing this visual and\ntextual information. Current cross-modal feature fusion approaches for CIR\nexhibit an inherent bias in intention interpretation. These methods tend to\ndisproportionately emphasize either the reference image features\n(visual-dominant fusion) or the textual modification intent (text-dominant\nfusion through image-to-text conversion). Such an imbalanced representation\noften fails to accurately capture and reflect the actual search intent of the\nuser in the retrieval results. To address this challenge, we propose TMCIR, a\nnovel framework that advances composed image retrieval through two key\ninnovations: 1) Intent-Aware Cross-Modal Alignment. We first fine-tune CLIP\nencoders contrastively using intent-reflecting pseudo-target images,\nsynthesized from reference images and textual descriptions via a diffusion\nmodel. This step enhances the encoder ability of text to capture nuanced\nintents in textual descriptions. 2) Adaptive Token Fusion. We further fine-tune\nall encoders contrastively by comparing adaptive token-fusion features with the\ntarget image. This mechanism dynamically balances visual and textual\nrepresentations within the contrastive learning pipeline, optimizing the\ncomposed feature for retrieval. Extensive experiments on Fashion-IQ and CIRR\ndatasets demonstrate that TMCIR significantly outperforms state-of-the-art\nmethods, particularly in capturing nuanced user intent.",
      "tldr_zh": "该论文提出了TMCIR框架，旨在解决组合图像检索(CIR)中视觉和文本信息融合时存在的意图偏差问题。TMCIR包含两个关键创新点：1) 意图感知跨模态对齐，通过扩散模型合成的伪目标图像对比微调CLIP编码器，增强文本捕捉细微意图的能力；2) 自适应Token融合，通过对比学习微调所有编码器，动态平衡视觉和文本表示。实验结果表明，TMCIR在Fashion-IQ和CIRR数据集上显著优于现有方法，尤其是在捕捉细微用户意图方面。\n",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "arXiv admin note: text overlap with arXiv:2310.05473 by other authors",
      "pdf_url": "http://arxiv.org/pdf/2504.10995v1",
      "published_date": "2025-04-15 09:14:04 UTC",
      "updated_date": "2025-04-15 09:14:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:22:12.227997"
    },
    {
      "arxiv_id": "2504.10983v1",
      "title": "ProtFlow: Fast Protein Sequence Design via Flow Matching on Compressed Protein Language Model Embeddings",
      "title_zh": "ProtFlow：基于压缩蛋白质语言模型嵌入的 Flow Matching 快速蛋白质序列设计\n",
      "authors": [
        "Zitai Kong",
        "Yiheng Zhu",
        "Yinlong Xu",
        "Hanjing Zhou",
        "Mingzhe Yin",
        "Jialu Wu",
        "Hongxia Xu",
        "Chang-Yu Hsieh",
        "Tingjun Hou",
        "Jian Wu"
      ],
      "abstract": "The design of protein sequences with desired functionalities is a fundamental\ntask in protein engineering. Deep generative methods, such as autoregressive\nmodels and diffusion models, have greatly accelerated the discovery of novel\nprotein sequences. However, these methods mainly focus on local or shallow\nresidual semantics and suffer from low inference efficiency, large modeling\nspace and high training cost. To address these challenges, we introduce\nProtFlow, a fast flow matching-based protein sequence design framework that\noperates on embeddings derived from semantically meaningful latent space of\nprotein language models. By compressing and smoothing the latent space,\nProtFlow enhances performance while training on limited computational\nresources. Leveraging reflow techniques, ProtFlow enables high-quality\nsingle-step sequence generation. Additionally, we develop a joint design\npipeline for the design scene of multichain proteins. We evaluate ProtFlow\nacross diverse protein design tasks, including general peptides and long-chain\nproteins, antimicrobial peptides, and antibodies. Experimental results\ndemonstrate that ProtFlow outperforms task-specific methods in these\napplications, underscoring its potential and broad applicability in\ncomputational protein sequence design and analysis.",
      "tldr_zh": "ProtFlow 是一种基于 Flow Matching 的快速蛋白质序列设计框架，它在蛋白质语言模型(Protein Language Model)的压缩嵌入上运行。通过压缩和优化潜在空间，ProtFlow 提高了性能，同时降低了训练成本。利用 reflow 技术，ProtFlow 能够实现高质量的单步序列生成。此外，该研究还开发了一个用于多链蛋白质联合设计的流程。在多种蛋白质设计任务（包括通用肽和长链蛋白质、抗菌肽和抗体）上的实验结果表明，ProtFlow 优于特定任务的方法，展示了其在计算蛋白质序列设计和分析中的潜力和广泛适用性。\n",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.BM"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10983v1",
      "published_date": "2025-04-15 08:46:53 UTC",
      "updated_date": "2025-04-15 08:46:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:22:24.200036"
    },
    {
      "arxiv_id": "2504.10982v2",
      "title": "Exploring the Role of Knowledge Graph-Based RAG in Japanese Medical Question Answering with Small-Scale LLMs",
      "title_zh": "探索基于知识图谱的RAG在小规模LLM日语医学问答中的作用\n",
      "authors": [
        "Yingjian Chen",
        "Feiyang Li",
        "Xingyu Song",
        "Tianxiao Li",
        "Issey Sukeda",
        "Irene Li"
      ],
      "abstract": "Large language models (LLMs) perform well in medical QA, but their\neffectiveness in Japanese contexts is limited due to privacy constraints that\nprevent the use of commercial models like GPT-4 in clinical settings. As a\nresult, recent efforts focus on instruction-tuning open-source LLMs, though the\npotential of combining them with retrieval-augmented generation (RAG) remains\nunderexplored. To bridge this gap, we are the first to explore a knowledge\ngraph-based (KG) RAG framework for Japanese medical QA small-scale open-source\nLLMs. Experimental results show that KG-based RAG has only a limited impact on\nJapanese medical QA using small-scale open-source LLMs. Further case studies\nreveal that the effectiveness of the RAG is sensitive to the quality and\nrelevance of the external retrieved content. These findings offer valuable\ninsights into the challenges and potential of applying RAG in Japanese medical\nQA, while also serving as a reference for other low-resource languages.",
      "tldr_zh": "本文研究了基于知识图谱(KG)的检索增强生成(RAG)框架在日语医疗问答(QA)中，与小规模开源LLM结合应用的效果。由于隐私限制，GPT-4等商业模型在日本临床环境中无法使用，因此研究集中于指令调优开源LLM。实验结果表明，基于KG的RAG对日语医疗QA的提升有限，且RAG的效果对检索内容的质量和相关性非常敏感。该研究揭示了RAG在日本医疗QA应用中的挑战和潜力，并为其他低资源语言提供了参考。\n",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages",
      "pdf_url": "http://arxiv.org/pdf/2504.10982v2",
      "published_date": "2025-04-15 08:46:39 UTC",
      "updated_date": "2025-04-16 01:42:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:22:36.434908"
    },
    {
      "arxiv_id": "2504.10961v1",
      "title": "Evaluating Trust in AI, Human, and Co-produced Feedback Among Undergraduate Students",
      "title_zh": "本科生对人工智能、人类以及协同产出反馈的信任度评估\n",
      "authors": [
        "Audrey Zhang",
        "Yifei Gao",
        "Wannapon Suraworachet",
        "Tanya Nazaretsky",
        "Mutlu Cukurova"
      ],
      "abstract": "As generative AI transforms educational feedback practices, understanding\nstudents' perceptions of different feedback providers becomes crucial for\neffective implementation. This study addresses a critical gap by comparing\nundergraduate students' trust in AI-generated, human-created, and human-AI\nco-produced feedback, informing how institutions can adapt feedback practices\nin this new era. Through a within-subject experiment with 91 participants, we\ninvestigated factors predicting students' ability to distinguish between\nfeedback types, perception of feedback quality, and potential biases to AI\ninvolvement. Findings revealed that students generally preferred AI and\nco-produced feedback over human feedback in terms of perceived usefulness and\nobjectivity. Only AI feedback suffered a decline in perceived genuineness when\nfeedback sources were revealed, while co-produced feedback maintained its\npositive perception. Educational AI experience improved students' ability to\nidentify AI feedback and increased their trust in all feedback types, while\ngeneral AI experience decreased perceived usefulness and credibility. Male\nstudents consistently rated all feedback types as less valuable than their\nfemale and non-binary counterparts. These insights inform evidence-based\nguidelines for integrating AI into higher education feedback systems while\naddressing trust concerns and fostering AI literacy among students.",
      "tldr_zh": "本研究评估了本科生对AI生成、人工创建以及人机协同产生的反馈的信任度，旨在了解生成式AI变革教育反馈实践后，学生对不同反馈提供者的看法。通过一项针对91名参与者的实验，研究比较了学生区分不同反馈类型的能力、对反馈质量的感知以及对AI参与的潜在偏见。结果表明，学生普遍认为AI和人机协同产生的反馈比人工反馈更有用和客观。只有AI反馈在来源公开后，其真实性感知有所下降，而人机协同反馈保持了积极的评价。教育AI经验提高了学生识别AI反馈的能力，并增加了他们对所有反馈类型的信任，而一般AI经验降低了其对有用性和可信度的感知。研究结果为高等教育中整合AI反馈系统提供了循证指南，同时解决了信任问题并培养了学生的AI素养。\n",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "35 pages, 6 figures. Under review at Assessment and Evaluation in\n  Higher Education",
      "pdf_url": "http://arxiv.org/pdf/2504.10961v1",
      "published_date": "2025-04-15 08:06:36 UTC",
      "updated_date": "2025-04-15 08:06:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:22:48.504795"
    },
    {
      "arxiv_id": "2504.10948v1",
      "title": "BEACON: A Benchmark for Efficient and Accurate Counting of Subgraphs",
      "title_zh": "BEACON：一种用于高效准确子图计数的基准测试",
      "authors": [
        "Mohammad Matin Najafi",
        "Xianju Zhu",
        "Chrysanthi Kosyfaki",
        "Laks V. S. Lakshmanan",
        "Reynold Cheng"
      ],
      "abstract": "Subgraph counting the task of determining the number of instances of a query\npattern within a large graph lies at the heart of many critical applications,\nfrom analyzing financial networks and transportation systems to understanding\nbiological interactions. Despite decades of work yielding efficient algorithmic\n(AL) solutions and, more recently, machine learning (ML) approaches, a clear\ncomparative understanding is elusive. This gap stems from the absence of a\nunified evaluation framework, standardized datasets, and accessible ground\ntruths, all of which hinder systematic analysis and fair benchmarking. To\novercome these barriers, we introduce BEACON: a comprehensive benchmark\ndesigned to rigorously evaluate both AL and ML-based subgraph counting methods.\nBEACON provides a standardized dataset with verified ground truths, an\nintegrated evaluation environment, and a public leaderboard, enabling\nreproducible and transparent comparisons across diverse approaches. Our\nextensive experiments reveal that while AL methods excel in efficiently\ncounting subgraphs on very large graphs, they struggle with complex patterns\n(e.g., those exceeding six nodes). In contrast, ML methods are capable of\nhandling larger patterns but demand massive graph data inputs and often yield\nsuboptimal accuracy on small, dense graphs. These insights not only highlight\nthe unique strengths and limitations of each approach but also pave the way for\nfuture advancements in subgraph counting techniques. Overall, BEACON represents\na significant step towards unifying and accelerating research in subgraph\ncounting, encouraging innovative solutions and fostering a deeper understanding\nof the trade-offs between algorithmic and machine learning paradigms.",
      "tldr_zh": "子图计数是图分析中的核心任务，在金融网络、交通系统和生物交互等领域有广泛应用。为了弥补算法(AL)和机器学习(ML)方法在子图计数领域缺乏统一评估框架的现状，该研究提出了BEACON，一个综合性的基准测试。BEACON提供标准化的数据集、验证过的真值、集成的评估环境和公开的排行榜，旨在促进不同方法之间可重复和透明的比较。实验结果表明，AL方法在大型图上的子图计数效率高，但在处理复杂模式（例如，超过六个节点的模式）时表现不佳；而ML方法能够处理更大的模式，但需要大量的图数据输入，并且在小型密集图上的准确率通常欠佳。BEACON的提出旨在统一和加速子图计数的研究，鼓励创新解决方案，并促进对算法和机器学习范式之间权衡的更深入理解。\n",
      "categories": [
        "cs.DS",
        "cs.AI",
        "cs.DB",
        "cs.SI"
      ],
      "primary_category": "cs.DS",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10948v1",
      "published_date": "2025-04-15 07:53:47 UTC",
      "updated_date": "2025-04-15 07:53:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:23:00.629608"
    },
    {
      "arxiv_id": "2504.10936v1",
      "title": "Can LLMs Leverage Observational Data? Towards Data-Driven Causal Discovery with LLMs",
      "title_zh": "LLM 能否利用观测数据？迈向基于 LLM 的数据驱动因果发现\n",
      "authors": [
        "Yuni Susanti",
        "Michael Färber"
      ],
      "abstract": "Causal discovery traditionally relies on statistical methods applied to\nobservational data, often requiring large datasets and assumptions about\nunderlying causal structures. Recent advancements in Large Language Models\n(LLMs) have introduced new possibilities for causal discovery by providing\ndomain expert knowledge. However, it remains unclear whether LLMs can\neffectively process observational data for causal discovery. In this work, we\nexplore the potential of LLMs for data-driven causal discovery by integrating\nobservational data for LLM-based reasoning. Specifically, we examine whether\nLLMs can effectively utilize observational data through two prompting\nstrategies: pairwise prompting and breadth first search (BFS)-based prompting.\nIn both approaches, we incorporate the observational data directly into the\nprompt to assess LLMs' ability to infer causal relationships from such data.\nExperiments on benchmark datasets show that incorporating observational data\nenhances causal discovery, boosting F1 scores by up to 0.11 point using both\npairwise and BFS LLM-based prompting, while outperforming traditional\nstatistical causal discovery baseline by up to 0.52 points. Our findings\nhighlight the potential and limitations of LLMs for data-driven causal\ndiscovery, demonstrating their ability to move beyond textual metadata and\neffectively interpret and utilize observational data for more informed causal\nreasoning. Our studies lays the groundwork for future advancements toward fully\nLLM-driven causal discovery.",
      "tldr_zh": "该研究探索了大型语言模型(LLMs)利用观测数据进行因果发现的潜力。研究人员提出了两种prompt策略：pairwise prompting和基于广度优先搜索(BFS)的prompting，将观测数据直接融入prompt中，评估LLMs从数据中推断因果关系的能力。实验结果表明，结合观测数据能有效提升因果发现效果，F1值最高提升0.11，且超越了传统统计因果发现基线最高达0.52。该研究揭示了LLMs在数据驱动的因果发现方面的潜力和局限性，表明LLMs能够有效解释和利用观测数据进行更明智的因果推理，为未来完全由LLM驱动的因果发现奠定了基础。\n",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10936v1",
      "published_date": "2025-04-15 07:32:35 UTC",
      "updated_date": "2025-04-15 07:32:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:23:12.458469"
    },
    {
      "arxiv_id": "2504.10925v1",
      "title": "Transfer Learning for Temporal Link Prediction",
      "title_zh": "用于时间链接预测的迁移学习\n",
      "authors": [
        "Ayan Chatterjee",
        "Barbara Ikica",
        "Babak Ravandi",
        "John Palowitch"
      ],
      "abstract": "Link prediction on graphs has applications spanning from recommender systems\nto drug discovery. Temporal link prediction (TLP) refers to predicting future\nlinks in a temporally evolving graph and adds additional complexity related to\nthe dynamic nature of graphs. State-of-the-art TLP models incorporate memory\nmodules alongside graph neural networks to learn both the temporal mechanisms\nof incoming nodes and the evolving graph topology. However, memory modules only\nstore information about nodes seen at train time, and hence such models cannot\nbe directly transferred to entirely new graphs at test time and deployment. In\nthis work, we study a new transfer learning task for temporal link prediction,\nand develop transfer-effective methods for memory-laden models. Specifically,\nmotivated by work showing the informativeness of structural signals for the TLP\ntask, we augment a structural mapping module to the existing TLP model\narchitectures, which learns a mapping from graph structural (topological)\nfeatures to memory embeddings. Our work paves the way for a memory-free\nfoundation model for TLP.",
      "tldr_zh": "该论文研究了时间链路预测(TLP)中的迁移学习问题，旨在解决现有基于记忆模块的TLP模型无法直接应用于新图的局限性。作者提出了一种新的迁移学习方法，通过引入结构映射模块，学习从图结构特征到记忆嵌入的映射，从而将图的拓扑信息融入模型。实验结果表明，该方法能够有效提升模型在不同图上的泛化能力，为构建无需记忆的TLP基础模型奠定了基础。\n",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "14 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.10925v1",
      "published_date": "2025-04-15 07:12:00 UTC",
      "updated_date": "2025-04-15 07:12:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:23:24.095305"
    },
    {
      "arxiv_id": "2504.10917v1",
      "title": "Towards A Universal Graph Structural Encoder",
      "title_zh": "迈向通用图结构编码器\n",
      "authors": [
        "Jialin Chen",
        "Haolan Zuo",
        "Haoyu Peter Wang",
        "Siqi Miao",
        "Pan Li",
        "Rex Ying"
      ],
      "abstract": "Recent advancements in large-scale pre-training have shown the potential to\nlearn generalizable representations for downstream tasks. In the graph domain,\nhowever, capturing and transferring structural information across different\ngraph domains remains challenging, primarily due to the inherent differences in\ntopological patterns across various contexts. Additionally, most existing\nmodels struggle to capture the complexity of rich graph structures, leading to\ninadequate exploration of the embedding space. To address these challenges, we\npropose GFSE, a universal graph structural encoder designed to capture\ntransferable structural patterns across diverse domains such as molecular\ngraphs, social networks, and citation networks. GFSE is the first cross-domain\ngraph structural encoder pre-trained with multiple self-supervised learning\nobjectives. Built on a Graph Transformer, GFSE incorporates attention\nmechanisms informed by graph inductive bias, enabling it to encode intricate\nmulti-level and fine-grained topological features. The pre-trained GFSE\nproduces generic and theoretically expressive positional and structural\nencoding for graphs, which can be seamlessly integrated with various downstream\ngraph feature encoders, including graph neural networks for vectorized features\nand Large Language Models for text-attributed graphs. Comprehensive experiments\non synthetic and real-world datasets demonstrate GFSE's capability to\nsignificantly enhance the model's performance while requiring substantially\nless task-specific fine-tuning. Notably, GFSE achieves state-of-the-art\nperformance in 81.6% evaluated cases, spanning diverse graph models and\ndatasets, highlighting its potential as a powerful and versatile encoder for\ngraph-structured data.",
      "tldr_zh": "该论文提出了一个通用图结构编码器GFSE，旨在捕获不同图领域的可迁移结构模式，例如分子图、社交网络和引用网络。GFSE基于图Transformer，并结合了图归纳偏置的注意力机制，能够编码复杂的多层次和细粒度的拓扑特征。通过多个自监督学习目标进行预训练，GFSE可以生成通用的、具有理论表达性的图的位置和结构编码，并能与各种下游图特征编码器（包括GNN和LLM）无缝集成。在合成和真实数据集上的实验表明，GFSE显著提高了模型性能，并在81.6%的评估案例中实现了state-of-the-art的性能，证明了其作为图结构数据强大而通用的编码器的潜力。\n",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10917v1",
      "published_date": "2025-04-15 06:57:26 UTC",
      "updated_date": "2025-04-15 06:57:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:23:36.477597"
    },
    {
      "arxiv_id": "2504.10915v1",
      "title": "LOKA Protocol: A Decentralized Framework for Trustworthy and Ethical AI Agent Ecosystems",
      "title_zh": "LOKA 协议：用于构建可信且符合伦理的 AI 智能体生态系统的去中心化框架\n",
      "authors": [
        "Rajesh Ranjan",
        "Shailja Gupta",
        "Surya Narayan Singh"
      ],
      "abstract": "The rise of autonomous AI agents, capable of perceiving, reasoning, and\nacting independently, signals a profound shift in how digital ecosystems\noperate, govern, and evolve. As these agents proliferate beyond centralized\ninfrastructures, they expose foundational gaps in identity, accountability, and\nethical alignment. Three critical questions emerge: Identity: Who or what is\nthe agent? Accountability: Can its actions be verified, audited, and trusted?\nEthical Consensus: Can autonomous systems reliably align with human values and\nprevent harmful emergent behaviors? We present the novel LOKA Protocol (Layered\nOrchestration for Knowledgeful Agents), a unified, systems-level architecture\nfor building ethically governed, interoperable AI agent ecosystems. LOKA\nintroduces a proposed Universal Agent Identity Layer (UAIL) for decentralized,\nverifiable identity; intent-centric communication protocols for semantic\ncoordination across diverse agents; and a Decentralized Ethical Consensus\nProtocol (DECP) that enables agents to make context-aware decisions grounded in\nshared ethical baselines. Anchored in emerging standards such as Decentralized\nIdentifiers (DIDs), Verifiable Credentials (VCs), and post-quantum\ncryptography, LOKA offers a scalable, future-resilient blueprint for\nmulti-agent AI governance. By embedding identity, trust, and ethics into the\nprotocol layer itself, LOKA establishes the foundation for a new era of\nresponsible, transparent, and autonomous AI ecosystems operating across digital\nand physical domains.",
      "tldr_zh": "LOKA协议提出了一个去中心化的框架，用于构建可信和符合伦理的AI Agent生态系统。该协议旨在解决AI Agent在身份、责任和伦理一致性方面的问题。LOKA引入了通用Agent身份层(UAIL)，用于去中心化和可验证的身份；意图中心通信协议，用于跨不同Agent的语义协调；以及去中心化伦理共识协议(DECP)，使Agent能够基于共享的伦理基线做出上下文相关的决策。LOKA基于去中心化身份标识符(DIDs)、可验证凭证(VCs)和后量子密码学等新兴标准，为多Agent AI治理提供了一个可扩展且面向未来的蓝图，为负责任、透明和自主的AI生态系统奠定了基础。\n",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.MA",
      "comment": "4 Figures, 1 Table",
      "pdf_url": "http://arxiv.org/pdf/2504.10915v1",
      "published_date": "2025-04-15 06:51:35 UTC",
      "updated_date": "2025-04-15 06:51:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:23:48.438304"
    },
    {
      "arxiv_id": "2504.10903v1",
      "title": "Efficient Reasoning Models: A Survey",
      "title_zh": "高效推理模型：一项综述\n",
      "authors": [
        "Sicheng Feng",
        "Gongfan Fang",
        "Xinyin Ma",
        "Xinchao Wang"
      ],
      "abstract": "Reasoning models have demonstrated remarkable progress in solving complex and\nlogic-intensive tasks by generating extended Chain-of-Thoughts (CoTs) prior to\narriving at a final answer. Yet, the emergence of this \"slow-thinking\"\nparadigm, with numerous tokens generated in sequence, inevitably introduces\nsubstantial computational overhead. To this end, it highlights an urgent need\nfor effective acceleration. This survey aims to provide a comprehensive\noverview of recent advances in efficient reasoning. It categorizes existing\nworks into three key directions: (1) shorter - compressing lengthy CoTs into\nconcise yet effective reasoning chains; (2) smaller - developing compact\nlanguage models with strong reasoning capabilities through techniques such as\nknowledge distillation, other model compression techniques, and reinforcement\nlearning; and (3) faster - designing efficient decoding strategies to\naccelerate inference. A curated collection of papers discussed in this survey\nis available in our GitHub repository.",
      "tldr_zh": "这篇综述论文全面概述了高效推理模型的最新进展。针对“慢思考”模式中CoT推理链过长导致计算开销大的问题，文章将现有研究分为三个主要方向：(1) *更短*：将冗长的CoT压缩为简洁有效的推理链；(2) *更小*：通过知识蒸馏、模型压缩和强化学习等技术，开发具有强大推理能力的紧凑型语言模型；(3) *更快*：设计高效的解码策略以加速推理。作者在GitHub仓库中整理了本文讨论的论文集合。该综述旨在为高效推理模型的研究提供指导。\n",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10903v1",
      "published_date": "2025-04-15 06:28:00 UTC",
      "updated_date": "2025-04-15 06:28:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:24:00.395358"
    },
    {
      "arxiv_id": "2504.10900v1",
      "title": "Bridging Distribution Gaps in Time Series Foundation Model Pretraining with Prototype-Guided Normalization",
      "title_zh": "通过原型引导归一化弥合时间序列基础模型预训练中的分布差距\n",
      "authors": [
        "Peiliang Gong",
        "Emadeldeen Eldele",
        "Min Wu",
        "Zhenghua Chen",
        "Xiaoli Li",
        "Daoqiang Zhang"
      ],
      "abstract": "Foundation models have achieved remarkable success across diverse\nmachine-learning domains through large-scale pretraining on large, diverse\ndatasets. However, pretraining on such datasets introduces significant\nchallenges due to substantial mismatches in data distributions, a problem\nparticularly pronounced with time series data. In this paper, we tackle this\nissue by proposing a domain-aware adaptive normalization strategy within the\nTransformer architecture. Specifically, we replace the traditional LayerNorm\nwith a prototype-guided dynamic normalization mechanism (ProtoNorm), where\nlearned prototypes encapsulate distinct data distributions, and\nsample-to-prototype affinity determines the appropriate normalization layer.\nThis mechanism effectively captures the heterogeneity of time series\ncharacteristics, aligning pretrained representations with downstream tasks.\nThrough comprehensive empirical evaluation, we demonstrate that our method\nsignificantly outperforms conventional pretraining techniques across both\nclassification and forecasting tasks, while effectively mitigating the adverse\neffects of distribution shifts during pretraining. Incorporating ProtoNorm is\nas simple as replacing a single line of code. Extensive experiments on diverse\nreal-world time series benchmarks validate the robustness and generalizability\nof our approach, advancing the development of more versatile time series\nfoundation models.",
      "tldr_zh": "本文提出了一种原型引导的动态归一化机制(ProtoNorm)，旨在解决时间序列预训练中由于数据分布差异导致的挑战。ProtoNorm通过学习原型来捕获不同的数据分布，并利用样本到原型的亲和力来确定合适的归一化层，从而有效地捕捉时间序列的异质性特征，并将预训练表示与下游任务对齐。实验结果表明，该方法在分类和预测任务中均显著优于传统的预训练技术，并能有效缓解预训练期间的分布偏移问题。在多个真实世界时间序列基准上的大量实验验证了该方法的鲁棒性和泛化能力，推动了更通用的时间序列基础模型的发展。\n",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10900v1",
      "published_date": "2025-04-15 06:23:00 UTC",
      "updated_date": "2025-04-15 06:23:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:24:12.344764"
    },
    {
      "arxiv_id": "2504.10898v1",
      "title": "Xpose: Bi-directional Engineering for Hidden Query Extraction",
      "title_zh": "Xpose：用于隐藏查询提取的双向工程\n",
      "authors": [
        "Ahana Pradhan",
        "Jayant Haritsa"
      ],
      "abstract": "Query reverse engineering (QRE) aims to synthesize a SQL query to connect a\ngiven database and result instance. A recent variation of QRE is where an\nadditional input, an opaque executable containing a ground-truth query, is\nprovided, and the goal is to non-invasively extract this specific query through\nonly input-output examples. This variant, called Hidden Query Extraction (HQE),\nhas a spectrum of industrial use-cases including query recovery, database\nsecurity, and vendor migration. The reverse engineering (RE) tools developed\nfor HQE, which are based on database mutation and generation techniques, can\nonly extract flat queries with key-based equi joins and conjunctive arithmetic\nfilter predicates, making them limited wrt both query structure and query\noperators. In this paper, we present Xpose, a HQE solution that elevates the\nextraction scope to realistic complex queries, such as those found in the TPCH\nbenchmark. A two-pronged approach is taken: (1) The existing RE scope is\nsubstantially extended to incorporate union connectors, algebraic filter\npredicates, and disjunctions for both values and predicates. (2) The predictive\npower of LLMs is leveraged to convert business descriptions of the opaque\napplication into extraction guidance, representing ``forward engineering\" (FE).\nThe FE module recognizes common constructs, such as nesting of sub-queries,\nouter joins, and scalar functions. In essence, FE establishes the broad query\ncontours, while RE fleshes out the fine-grained details. We have evaluated\nXpose on (a) E-TPCH, a query suite comprising the complete TPCH benchmark\nextended with queries featuring unions, diverse join types, and sub-queries;\nand (b) the real-world STACK benchmark. The experimental results demonstrate\nthat its bi-directional engineering approach accurately extracts these complex\nqueries, representing a significant step forward with regard to HQE coverage.",
      "tldr_zh": "本文提出了一种名为Xpose的隐藏查询提取(HQE)解决方案，旨在从包含真实查询的opaque executable中，通过输入输出示例非侵入式地提取复杂SQL查询。Xpose采用双向工程方法：一方面，显著扩展了现有反向工程(RE)的范围，使其能够处理union连接符、代数过滤谓词以及值和谓词的析取；另一方面，利用LLM的预测能力，将opaque应用的业务描述转换为提取指导，即正向工程(FE)。FE模块识别子查询嵌套、外连接和标量函数等常见结构，从而确定查询的整体轮廓，而RE则填充细粒度的细节。在E-TPCH和STACK基准测试上的实验结果表明，Xpose能够准确提取这些复杂查询，代表了HQE覆盖范围方面的重要进展。\n",
      "categories": [
        "cs.DB",
        "cs.AI",
        "H.2.8"
      ],
      "primary_category": "cs.DB",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10898v1",
      "published_date": "2025-04-15 06:17:58 UTC",
      "updated_date": "2025-04-15 06:17:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:24:24.713880"
    },
    {
      "arxiv_id": "2504.10893v1",
      "title": "ARise: Towards Knowledge-Augmented Reasoning via Risk-Adaptive Search",
      "title_zh": "ARise：迈向基于风险自适应搜索的知识增强推理\n",
      "authors": [
        "Yize Zhang",
        "Tianshu Wang",
        "Sirui Chen",
        "Kun Wang",
        "Xingyu Zeng",
        "Hongyu Lin",
        "Xianpei Han",
        "Le Sun",
        "Chaochao Lu"
      ],
      "abstract": "Large language models (LLMs) have demonstrated impressive capabilities and\nare receiving increasing attention to enhance their reasoning through scaling\ntest--time compute. However, their application in open--ended,\nknowledge--intensive, complex reasoning scenarios is still limited.\nReasoning--oriented methods struggle to generalize to open--ended scenarios due\nto implicit assumptions of complete world knowledge. Meanwhile,\nknowledge--augmented reasoning (KAR) methods fail to address two core\nchallenges: 1) error propagation, where errors in early steps cascade through\nthe chain, and 2) verification bottleneck, where the explore--exploit tradeoff\narises in multi--branch decision processes. To overcome these limitations, we\nintroduce ARise, a novel framework that integrates risk assessment of\nintermediate reasoning states with dynamic retrieval--augmented generation\n(RAG) within a Monte Carlo tree search paradigm. This approach enables\neffective construction and optimization of reasoning plans across multiple\nmaintained hypothesis branches. Experimental results show that ARise\nsignificantly outperforms the state--of--the--art KAR methods by up to 23.10%,\nand the latest RAG-equipped large reasoning models by up to 25.37%.",
      "tldr_zh": "该论文提出了ARise，一个通过风险自适应搜索增强知识推理的新框架，旨在解决大型语言模型(LLMs)在开放式、知识密集型复杂推理场景中的局限性。ARise结合了中间推理状态的风险评估和动态检索增强生成(RAG)，并将其融入蒙特卡洛树搜索范式中，从而有效地构建和优化跨多个假设分支的推理计划。实验结果表明，ARise显著优于现有的知识增强推理(KAR)方法，最高提升达23.10%，并且优于最新的配备RAG的大型推理模型，最高提升达25.37%。该方法旨在解决传统KAR方法中的误差传播和验证瓶颈问题。\n",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Project homepage: https://opencausalab.github.io/ARise",
      "pdf_url": "http://arxiv.org/pdf/2504.10893v1",
      "published_date": "2025-04-15 06:06:50 UTC",
      "updated_date": "2025-04-15 06:06:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:24:36.483931"
    },
    {
      "arxiv_id": "2504.10888v1",
      "title": "CDUPatch: Color-Driven Universal Adversarial Patch Attack for Dual-Modal Visible-Infrared Detectors",
      "title_zh": "CDUPatch：面向双模可见光-红外探测器的颜色驱动通用对抗补丁攻击\n",
      "authors": [
        "Jiahuan Long",
        "Wen Yao",
        "Tingsong Jiang",
        "Chao Ma"
      ],
      "abstract": "Adversarial patches are widely used to evaluate the robustness of object\ndetection systems in real-world scenarios. These patches were initially\ndesigned to deceive single-modal detectors (e.g., visible or infrared) and have\nrecently been extended to target visible-infrared dual-modal detectors.\nHowever, existing dual-modal adversarial patch attacks have limited attack\neffectiveness across diverse physical scenarios. To address this, we propose\nCDUPatch, a universal cross-modal patch attack against visible-infrared object\ndetectors across scales, views, and scenarios. Specifically, we observe that\ncolor variations lead to different levels of thermal absorption, resulting in\ntemperature differences in infrared imaging. Leveraging this property, we\npropose an RGB-to-infrared adapter that maps RGB patches to infrared patches,\nenabling unified optimization of cross-modal patches. By learning an optimal\ncolor distribution on the adversarial patch, we can manipulate its thermal\nresponse and generate an adversarial infrared texture. Additionally, we\nintroduce a multi-scale clipping strategy and construct a new visible-infrared\ndataset, MSDrone, which contains aerial vehicle images in varying scales and\nperspectives. These data augmentation strategies enhance the robustness of our\npatch in real-world conditions. Experiments on four benchmark datasets (e.g.,\nDroneVehicle, LLVIP, VisDrone, MSDrone) show that our method outperforms\nexisting patch attacks in the digital domain. Extensive physical tests further\nconfirm strong transferability across scales, views, and scenarios.",
      "tldr_zh": "该论文提出了CDUPatch，一种颜色驱动的通用对抗补丁攻击方法，旨在提升对可见光-红外双模态目标检测器的攻击效果。CDUPatch利用颜色变化导致的热吸收差异，通过RGB到红外适配器将RGB补丁映射到红外补丁，从而统一优化跨模态补丁。通过学习对抗补丁上的最佳颜色分布，CDUPatch可以操纵其热响应并生成对抗性红外纹理。此外，论文还引入了多尺度裁剪策略，并构建了一个新的可见光-红外数据集MSDrone，用于增强补丁在真实场景中的鲁棒性。实验结果表明，CDUPatch在数字域和物理域均优于现有的对抗补丁攻击方法，具有良好的跨尺度、视角和场景的迁移性。\n",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10888v1",
      "published_date": "2025-04-15 05:46:00 UTC",
      "updated_date": "2025-04-15 05:46:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:24:48.570894"
    },
    {
      "arxiv_id": "2504.10886v1",
      "title": "Exploring Persona-dependent LLM Alignment for the Moral Machine Experiment",
      "title_zh": "探索用于道德机器实验的依赖于角色设定的大语言模型对齐\n",
      "authors": [
        "Jiseon Kim",
        "Jea Kwon",
        "Luiz Felipe Vecchietti",
        "Alice Oh",
        "Meeyoung Cha"
      ],
      "abstract": "Deploying large language models (LLMs) with agency in real-world applications\nraises critical questions about how these models will behave. In particular,\nhow will their decisions align with humans when faced with moral dilemmas? This\nstudy examines the alignment between LLM-driven decisions and human judgment in\nvarious contexts of the moral machine experiment, including personas reflecting\ndifferent sociodemographics. We find that the moral decisions of LLMs vary\nsubstantially by persona, showing greater shifts in moral decisions for\ncritical tasks than humans. Our data also indicate an interesting partisan\nsorting phenomenon, where political persona predominates the direction and\ndegree of LLM decisions. We discuss the ethical implications and risks\nassociated with deploying these models in applications that involve moral\ndecisions.",
      "tldr_zh": "本研究探讨了在道德机器实验中，不同角色设定对大型语言模型(LLM)决策的影响，旨在评估LLM在面临道德困境时与人类判断的对齐程度。研究发现，LLM的道德决策因角色而异，在关键任务中表现出比人类更大的变化。数据还表明存在有趣的党派分类现象，政治角色主导了LLM决策的方向和程度。该研究讨论了在涉及道德决策的应用中部署这些模型所涉及的伦理影响和风险。\n",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CY",
      "comment": "Accepted to ICLR 2025 Workshop - BiAlign (Bidirectional Human-AI\n  Alignment)",
      "pdf_url": "http://arxiv.org/pdf/2504.10886v1",
      "published_date": "2025-04-15 05:29:51 UTC",
      "updated_date": "2025-04-15 05:29:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:25:00.311036"
    },
    {
      "arxiv_id": "2504.10885v1",
      "title": "PuzzleBench: A Fully Dynamic Evaluation Framework for Large Multimodal Models on Puzzle Solving",
      "title_zh": "PuzzleBench：用于评估大型多模态模型解谜能力的完全动态评估框架\n",
      "authors": [
        "Zeyu Zhang",
        "Zijian Chen",
        "Zicheng Zhang",
        "Yuze Sun",
        "Yuan Tian",
        "Ziheng Jia",
        "Chunyi Li",
        "Xiaohong Liu",
        "Xiongkuo Min",
        "Guangtao Zhai"
      ],
      "abstract": "Large Multimodal Models (LMMs) have demonstrated impressive capabilities\nacross a wide range of multimodal tasks, achieving ever-increasing performance\non various evaluation benchmarks. However, existing benchmarks are typically\nstatic and often overlap with pre-training datasets, leading to fixed\ncomplexity constraints and substantial data contamination issues. Meanwhile,\nmanually annotated datasets are labor-intensive, time-consuming, and subject to\nhuman bias and inconsistency, leading to reliability and reproducibility\nissues. To address these problems, we propose a fully dynamic multimodal\nevaluation framework, named Open-ended Visual Puzzle Generation (OVPG), which\naims to generate fresh, diverse, and verifiable evaluation data automatically\nin puzzle-solving tasks. Specifically, the OVPG pipeline consists of a raw\nmaterial sampling module, a visual content generation module, and a puzzle rule\ndesign module, which ensures that each evaluation instance is primitive, highly\nrandomized, and uniquely solvable, enabling continual adaptation to the\nevolving capabilities of LMMs. Built upon OVPG, we construct PuzzleBench, a\ndynamic and scalable benchmark comprising 11,840 VQA samples. It features six\ncarefully designed puzzle tasks targeting three core LMM competencies, visual\nrecognition, logical reasoning, and context understanding. PuzzleBench differs\nfrom static benchmarks that quickly become outdated. It enables ongoing dataset\nrefreshing through OVPG and a rich set of open-ended puzzle designs, allowing\nseamless adaptation to the evolving capabilities of LMMs.",
      "tldr_zh": "针对现有大型多模态模型(LMMs)评测基准存在的静态、数据污染和人工标注偏差等问题，该论文提出了一个全动态的多模态评测框架PuzzleBench。该框架基于Open-ended Visual Puzzle Generation (OVPG)流程，自动生成新鲜、多样且可验证的拼图解谜任务数据。OVPG包含原始素材采样、视觉内容生成和拼图规则设计模块，确保每个评测实例的独特性和可解性，从而持续适应LMMs的能力发展。PuzzleBench包含11,840个VQA样本，涵盖视觉识别、逻辑推理和上下文理解三个核心LMM能力，以及六个精心设计的拼图任务，能够动态刷新数据集，适应LMMs的不断发展。\n",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10885v1",
      "published_date": "2025-04-15 05:29:31 UTC",
      "updated_date": "2025-04-15 05:29:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:25:12.637105"
    },
    {
      "arxiv_id": "2504.10883v1",
      "title": "Bringing together invertible UNets with invertible attention modules for memory-efficient diffusion models",
      "title_zh": "将可逆 UNet 与可逆注意力模块相结合，实现内存高效的扩散模型\n",
      "authors": [
        "Karan Jain",
        "Mohammad Nayeem Teli"
      ],
      "abstract": "Diffusion models have recently gained state of the art performance on many\nimage generation tasks. However, most models require significant computational\nresources to achieve this. This becomes apparent in the application of medical\nimage synthesis due to the 3D nature of medical datasets like CT-scans, MRIs,\nelectron microscope, etc. In this paper we propose a novel architecture for a\nsingle GPU memory-efficient training for diffusion models for high dimensional\nmedical datasets. The proposed model is built by using an invertible UNet\narchitecture with invertible attention modules. This leads to the following two\ncontributions: 1. denoising diffusion models and thus enabling memory usage to\nbe independent of the dimensionality of the dataset, and 2. reducing the energy\nusage during training. While this new model can be applied to a multitude of\nimage generation tasks, we showcase its memory-efficiency on the 3D BraTS2020\ndataset leading to up to 15\\% decrease in peak memory consumption during\ntraining with comparable results to SOTA while maintaining the image quality.",
      "tldr_zh": "该论文提出了一种新颖的架构，将可逆UNet与可逆注意力模块相结合，用于训练内存高效的扩散模型，尤其针对高维医学图像数据集，如3D CT扫描和MRI。该模型通过可逆架构，使得内存使用独立于数据集的维度，并降低了训练过程中的能源消耗。实验结果表明，在3D BraTS2020数据集上，该方法在保持图像质量的同时，与SOTA模型相比，训练期间的峰值内存消耗降低了15%。该方法适用于多种图像生成任务，为医学图像合成提供了一种单GPU内存高效的解决方案。\n",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10883v1",
      "published_date": "2025-04-15 05:26:42 UTC",
      "updated_date": "2025-04-15 05:26:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:25:24.387749"
    },
    {
      "arxiv_id": "2504.10878v1",
      "title": "Large Language Model-Informed Feature Discovery Improves Prediction and Interpretation of Credibility Perceptions of Visual Content",
      "title_zh": "大型语言模型指导的特征发现提升了视觉内容可信度感知的预测和解释\n",
      "authors": [
        "Yilang Peng",
        "Sijia Qian",
        "Yingdan Lu",
        "Cuihua Shen"
      ],
      "abstract": "In today's visually dominated social media landscape, predicting the\nperceived credibility of visual content and understanding what drives human\njudgment are crucial for countering misinformation. However, these tasks are\nchallenging due to the diversity and richness of visual features. We introduce\na Large Language Model (LLM)-informed feature discovery framework that\nleverages multimodal LLMs, such as GPT-4o, to evaluate content credibility and\nexplain its reasoning. We extract and quantify interpretable features using\ntargeted prompts and integrate them into machine learning models to improve\ncredibility predictions. We tested this approach on 4,191 visual social media\nposts across eight topics in science, health, and politics, using credibility\nratings from 5,355 crowdsourced workers. Our method outperformed zero-shot\nGPT-based predictions by 13 percent in R2, and revealed key features like\ninformation concreteness and image format. We discuss the implications for\nmisinformation mitigation, visual credibility, and the role of LLMs in social\nscience.",
      "tldr_zh": "该研究提出了一种基于大语言模型(LLM)的特征发现框架，用于提升视觉内容可信度预测和解释能力。该框架利用多模态LLM（如GPT-4o）评估内容可信度并解释其推理过程，提取并量化可解释的特征，然后将其整合到机器学习模型中以改进预测。在包含科学、健康和政治等八个主题的4191个视觉社交媒体帖子上的实验表明，该方法在R2指标上比zero-shot GPT预测高出13%，并揭示了信息具体性和图像格式等关键特征。该研究对于减少错误信息、提升视觉可信度以及LLM在社会科学中的应用具有重要意义。\n",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "I.4.9; J.4"
      ],
      "primary_category": "cs.CV",
      "comment": "26 pages",
      "pdf_url": "http://arxiv.org/pdf/2504.10878v1",
      "published_date": "2025-04-15 05:11:40 UTC",
      "updated_date": "2025-04-15 05:11:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:25:36.514395"
    },
    {
      "arxiv_id": "2504.10873v1",
      "title": "Can Vision-Language Models Understand and Interpret Dynamic Gestures from Pedestrians? Pilot Datasets and Exploration Towards Instructive Nonverbal Commands for Cooperative Autonomous Vehicles",
      "title_zh": "视觉-语言模型能否理解和解释行人的动态手势？面向协同自动驾驶车辆的指导性非语言指令的初步数据集和探索\n",
      "authors": [
        "Tonko E. W. Bossen",
        "Andreas Møgelmose",
        "Ross Greer"
      ],
      "abstract": "In autonomous driving, it is crucial to correctly interpret traffic gestures\n(TGs), such as those of an authority figure providing orders or instructions,\nor a pedestrian signaling the driver, to ensure a safe and pleasant traffic\nenvironment for all road users. This study investigates the capabilities of\nstate-of-the-art vision-language models (VLMs) in zero-shot interpretation,\nfocusing on their ability to caption and classify human gestures in traffic\ncontexts. We create and publicly share two custom datasets with varying formal\nand informal TGs, such as 'Stop', 'Reverse', 'Hail', etc. The datasets are\n\"Acted TG (ATG)\" and \"Instructive TG In-The-Wild (ITGI)\". They are annotated\nwith natural language, describing the pedestrian's body position and gesture.\nWe evaluate models using three methods utilizing expert-generated captions as\nbaseline and control: (1) caption similarity, (2) gesture classification, and\n(3) pose sequence reconstruction similarity. Results show that current VLMs\nstruggle with gesture understanding: sentence similarity averages below 0.59,\nand classification F1 scores reach only 0.14-0.39, well below the expert\nbaseline of 0.70. While pose reconstruction shows potential, it requires more\ndata and refined metrics to be reliable. Our findings reveal that although some\nSOTA VLMs can interpret zero-shot human traffic gestures, none are accurate and\nrobust enough to be trustworthy, emphasizing the need for further research in\nthis domain.",
      "tldr_zh": "该研究探索了视觉语言模型(VLMs)在理解和解释行人动态手势方面的能力，旨在为合作式自动驾驶车辆提供指导性的非语言指令。作者构建并公开了两个数据集：Acted TG (ATG)和Instructive TG In-The-Wild (ITGI)，包含不同形式的交通手势。通过caption相似度、手势分类和姿势序列重建相似度三种方法评估了现有VLMs的zero-shot解释能力。实验结果表明，当前VLMs在手势理解方面表现不佳，分类F1 score仅为0.14-0.39，远低于专家基线。虽然姿势重建显示出潜力，但需要更多数据和更精细的指标。研究强调，现有VLMs在理解交通手势方面仍不够准确和可靠，需要进一步研究。\n",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10873v1",
      "published_date": "2025-04-15 05:04:25 UTC",
      "updated_date": "2025-04-15 05:04:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:25:48.833007"
    },
    {
      "arxiv_id": "2504.10865v1",
      "title": "Understanding the theoretical properties of projected Bellman equation, linear Q-learning, and approximate value iteration",
      "title_zh": "理解投影贝尔曼方程、线性 Q 学习和近似值迭代的理论性质\n",
      "authors": [
        "Han-Dong Lim",
        "Donghwan Lee"
      ],
      "abstract": "In this paper, we study the theoretical properties of the projected Bellman\nequation (PBE) and two algorithms to solve this equation: linear Q-learning and\napproximate value iteration (AVI). We consider two sufficient conditions for\nthe existence of a solution to PBE : strictly negatively row dominating\ndiagonal (SNRDD) assumption and a condition motivated by the convergence of\nAVI. The SNRDD assumption also ensures the convergence of linear Q-learning,\nand its relationship with the convergence of AVI is examined. Lastly, several\ninteresting observations on the solution of PBE are provided when using\n$\\epsilon$-greedy policy.",
      "tldr_zh": "本文研究了投影贝尔曼方程(PBE)的理论性质，以及求解该方程的两种算法：线性Q学习和近似值迭代(AVI)。文章探讨了PBE解存在的两个充分条件：严格负行对角占优(SNRDD)假设和一个受AVI收敛性启发的条件。SNRDD假设保证了线性Q学习的收敛性，并分析了其与AVI收敛性的关系。最后，文章还提供了关于使用$\\epsilon$-greedy策略时PBE解的一些有趣的观察结果。\n",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Initial submission",
      "pdf_url": "http://arxiv.org/pdf/2504.10865v1",
      "published_date": "2025-04-15 04:56:33 UTC",
      "updated_date": "2025-04-15 04:56:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:26:00.334799"
    },
    {
      "arxiv_id": "2504.10845v1",
      "title": "Moving Beyond Next-Token Prediction: Transformers are Context-Sensitive Language Generators",
      "title_zh": "超越下一个 token 预测：Transformer 是上下文相关的语言生成器\n",
      "authors": [
        "Phill Kyu Rhee"
      ],
      "abstract": "Large Language Models (LLMs), powered by Transformers, have demonstrated\nhuman-like intelligence capabilities, yet their underlying mechanisms remain\npoorly understood. This paper presents a novel framework for interpreting LLMs\nas probabilistic left context-sensitive languages (CSLs) generators. We\nhypothesize that Transformers can be effectively decomposed into three\nfundamental components: context windows, attention mechanisms, and\nautoregressive generation frameworks. This decomposition allows for the\ndevelopment of more flexible and interpretable computational models, moving\nbeyond the traditional view of attention and autoregression as inseparable\nprocesses. We argue that next-token predictions can be understood as\nprobabilistic, dynamic approximations of left CSL production rules, providing\nan intuitive explanation for how simple token predictions can yield human-like\nintelligence outputs. Given that all CSLs are left context-sensitive\n(Penttonen, 1974), we conclude that Transformers stochastically approximate\nCSLs, which are widely recognized as models of human-like intelligence. This\ninterpretation bridges the gap between Formal Language Theory and the observed\ngenerative power of Transformers, laying a foundation for future advancements\nin generative AI theory and applications. Our novel perspective on Transformer\narchitectures will foster a deeper understanding of LLMs and their future\npotentials.",
      "tldr_zh": "该论文提出了一种新的框架，将Transformer架构驱动的大语言模型(LLMs)解释为概率性的、上下文相关的语言(CSLs)生成器。作者将Transformer分解为三个基本组件：上下文窗口、注意力机制和自回归生成框架。论文认为，next-token预测可以被理解为对left CSL production rules的概率性、动态近似，从而解释了简单的token预测如何产生类似人类智能的输出。结论是，Transformers随机逼近CSLs，这为理解LLMs的生成能力以及推动生成式AI理论和应用奠定了基础。\n",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "11 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.10845v1",
      "published_date": "2025-04-15 04:06:27 UTC",
      "updated_date": "2025-04-15 04:06:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:26:12.554686"
    },
    {
      "arxiv_id": "2504.10839v1",
      "title": "Rethinking Theory of Mind Benchmarks for LLMs: Towards A User-Centered Perspective",
      "title_zh": "重新思考LLM的心理理论基准：迈向以用户为中心的视角\n",
      "authors": [
        "Qiaosi Wang",
        "Xuhui Zhou",
        "Maarten Sap",
        "Jodi Forlizzi",
        "Hong Shen"
      ],
      "abstract": "The last couple of years have witnessed emerging research that appropriates\nTheory-of-Mind (ToM) tasks designed for humans to benchmark LLM's ToM\ncapabilities as an indication of LLM's social intelligence. However, this\napproach has a number of limitations. Drawing on existing psychology and AI\nliterature, we summarize the theoretical, methodological, and evaluation\nlimitations by pointing out that certain issues are inherently present in the\noriginal ToM tasks used to evaluate human's ToM, which continues to persist and\nexacerbated when appropriated to benchmark LLM's ToM. Taking a human-computer\ninteraction (HCI) perspective, these limitations prompt us to rethink the\ndefinition and criteria of ToM in ToM benchmarks in a more dynamic,\ninteractional approach that accounts for user preferences, needs, and\nexperiences with LLMs in such evaluations. We conclude by outlining potential\nopportunities and challenges towards this direction.",
      "tldr_zh": "该论文重新审视了当前用于评估大型语言模型(LLMs)心智理论(Theory-of-Mind, ToM)能力的基准测试方法。作者从人机交互(HCI)的角度出发，指出直接将为人类设计的ToM任务应用于LLMs存在理论、方法和评估上的局限性，这些局限性源于原始ToM任务本身，并在评估LLMs时被放大。因此，论文倡导一种以用户为中心的视角，重新定义ToM基准测试，使其更加动态和互动，并考虑用户在使用LLMs时的偏好、需求和体验。最后，论文概述了未来研究的机遇和挑战。\n",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "7 pages, 1 figure, accepted to the HEAL@CHI 2025 Workshop",
      "pdf_url": "http://arxiv.org/pdf/2504.10839v1",
      "published_date": "2025-04-15 03:44:43 UTC",
      "updated_date": "2025-04-15 03:44:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:26:24.618337"
    },
    {
      "arxiv_id": "2504.10836v1",
      "title": "Uplink Assisted Joint Channel Estimation and CSI Feedback: An Approach Based on Deep Joint Source-Channel Coding",
      "title_zh": "上行链路辅助的联合信道估计和 CSI 反馈：一种基于深度联合信源信道编码的方法\n",
      "authors": [
        "Yiran Guo",
        "Wei Chen",
        "Bo Ai"
      ],
      "abstract": "In frequency division duplex (FDD) multiple-input multiple-output (MIMO)\nwireless communication systems, the acquisition of downlink channel state\ninformation (CSI) is essential for maximizing spatial resource utilization and\nimproving system spectral efficiency. The separate design of modules in\nAI-based CSI feedback architectures under traditional modular communication\nframeworks, including channel estimation (CE), CSI compression and feedback,\nleads to sub-optimal performance. In this paper, we propose an uplink assisted\njoint CE and and CSI feedback approach via deep learning for downlink CSI\nacquisition, which mitigates performance degradation caused by distribution\nbias across separately trained modules in traditional modular communication\nframeworks. The proposed network adopts a deep joint source-channel coding\n(DJSCC) architecture to mitigate the cliff effect encountered in the\nconventional separate source-channel coding. Furthermore, we exploit the uplink\nCSI as auxiliary information to enhance CSI reconstruction accuracy by\nleveraging the partial reciprocity between the uplink and downlink channels in\nFDD systems, without introducing additional overhead. The effectiveness of\nuplink CSI as assisted information and the necessity of an end-toend\nmulti-module joint training architecture is validated through comprehensive\nablation and scalability experiments.",
      "tldr_zh": "该论文提出了一种基于深度联合信源信道编码(DJSCC)的上行辅助联合信道估计和CSI反馈方法，用于FDD MIMO无线通信系统中的下行CSI获取。该方法旨在解决传统模块化通信框架下，信道估计(CE)、CSI压缩和反馈等模块独立设计导致的性能次优问题。通过利用上行CSI作为辅助信息，并采用端到端的联合训练架构，该方法能够提高CSI重建的准确性，并缓解传统分离信源信道编码中遇到的悬崖效应。实验结果验证了上行CSI作为辅助信息的有效性，以及端到端多模块联合训练架构的必要性。\n",
      "categories": [
        "eess.SP",
        "cs.AI"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10836v1",
      "published_date": "2025-04-15 03:29:24 UTC",
      "updated_date": "2025-04-15 03:29:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:26:36.520109"
    },
    {
      "arxiv_id": "2504.10833v1",
      "title": "Towards Spatially-Aware and Optimally Faithful Concept-Based Explanations",
      "title_zh": "迈向空间感知和最优保真度的基于概念的解释\n",
      "authors": [
        "Shubham Kumar",
        "Dwip Dalal",
        "Narendra Ahuja"
      ],
      "abstract": "Post-hoc, unsupervised concept-based explanation methods (U-CBEMs) are a\npromising tool for generating semantic explanations of the decision-making\nprocesses in deep neural networks, having applications in both model\nimprovement and understanding. It is vital that the explanation is accurate, or\nfaithful, to the model, yet we identify several limitations of prior\nfaithfulness metrics that inhibit an accurate evaluation; most notably, prior\nmetrics involve only the set of concepts present, ignoring how they may be\nspatially distributed. We address these limitations with Surrogate Faithfulness\n(SF), an evaluation method that introduces a spatially-aware surrogate and two\nnovel faithfulness metrics. Using SF, we produce Optimally Faithful (OF)\nexplanations, where concepts are found that maximize faithfulness. Our\nexperiments show that (1) adding spatial-awareness to prior U-CBEMs increases\nfaithfulness in all cases; (2) OF produces significantly more faithful\nexplanations than prior U-CBEMs (30% or higher improvement in error); (3) OF's\nlearned concepts generalize well to out-of-domain data and are more robust to\nadversarial examples, where prior U-CBEMs struggle.",
      "tldr_zh": "本文针对事后、无监督的基于概念的解释方法(U-CBEMs)在解释深度神经网络决策过程中的局限性，特别是现有faithfulness指标忽略概念空间分布的问题，提出了Surrogate Faithfulness (SF)评估方法。SF引入了一个空间感知的代理模型和两个新的faithfulness指标。基于SF，本文进一步提出了Optimally Faithful (OF)解释方法，旨在找到最大化faithfulness的概念。实验结果表明，加入空间感知可以提高U-CBEMs的faithfulness，OF方法比现有U-CBEMs产生更faithful的解释(误差降低30%或更高)，并且OF学习到的概念具有更好的泛化性和鲁棒性。\n",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10833v1",
      "published_date": "2025-04-15 03:24:13 UTC",
      "updated_date": "2025-04-15 03:24:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:26:48.645898"
    },
    {
      "arxiv_id": "2504.10831v1",
      "title": "Hallucination-Aware Generative Pretrained Transformer for Cooperative Aerial Mobility Control",
      "title_zh": "具有幻觉感知能力的生成式预训练Transformer，用于协同空中移动控制\n",
      "authors": [
        "Hyojun Ahn",
        "Seungcheol Oh",
        "Gyu Seon Kim",
        "Soyi Jung",
        "Soohyun Park",
        "Joongheon Kim"
      ],
      "abstract": "This paper proposes SafeGPT, a two-tiered framework that integrates\ngenerative pretrained transformers (GPTs) with reinforcement learning (RL) for\nefficient and reliable unmanned aerial vehicle (UAV) last-mile deliveries. In\nthe proposed design, a Global GPT module assigns high-level tasks such as\nsector allocation, while an On-Device GPT manages real-time local route\nplanning. An RL-based safety filter monitors each GPT decision and overrides\nunsafe actions that could lead to battery depletion or duplicate visits,\neffectively mitigating hallucinations. Furthermore, a dual replay buffer\nmechanism helps both the GPT modules and the RL agent refine their strategies\nover time. Simulation results demonstrate that SafeGPT achieves higher delivery\nsuccess rates compared to a GPT-only baseline, while substantially reducing\nbattery consumption and travel distance. These findings validate the efficacy\nof combining GPT-based semantic reasoning with formal safety guarantees,\ncontributing a viable solution for robust and energy-efficient UAV logistics.",
      "tldr_zh": "本文提出了一种名为SafeGPT的双层框架，该框架集成了生成式预训练Transformer (GPT) 和强化学习 (RL)，用于实现高效可靠的无人机 (UAV) 最后一公里交付。SafeGPT包含全局GPT模块和设备端GPT模块，分别负责高层任务分配和实时局部路径规划。基于RL的安全过滤器监控GPT的决策，并否决可能导致电池耗尽或重复访问的不安全行为，从而有效缓解“幻觉”。双重回放缓冲区机制帮助GPT模块和RL智能体不断改进策略。仿真结果表明，SafeGPT相比仅使用GPT的基线模型，实现了更高的交付成功率，同时显著降低了电池消耗和行驶距离，验证了将基于GPT的语义推理与形式安全保证相结合的有效性，为鲁棒且节能的无人机物流提供了一种可行的解决方案。\n",
      "categories": [
        "cs.AI",
        "cs.RO",
        "68T05"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10831v1",
      "published_date": "2025-04-15 03:21:08 UTC",
      "updated_date": "2025-04-15 03:21:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:27:00.844324"
    },
    {
      "arxiv_id": "2504.10823v1",
      "title": "CLASH: Evaluating Language Models on Judging High-Stakes Dilemmas from Multiple Perspectives",
      "title_zh": "CLASH：评估语言模型在判断多角度高风险困境中的表现\n",
      "authors": [
        "Ayoung Lee",
        "Ryan Sungmo Kwon",
        "Peter Railton",
        "Lu Wang"
      ],
      "abstract": "Navigating high-stakes dilemmas involving conflicting values is challenging\neven for humans, let alone for AI. Yet prior work in evaluating the reasoning\ncapabilities of large language models (LLMs) in such situations has been\nlimited to everyday scenarios. To close this gap, this work first introduces\nCLASH (Character perspective-based LLM Assessments in Situations with\nHigh-stakes), a meticulously curated dataset consisting of 345 high-impact\ndilemmas along with 3,795 individual perspectives of diverse values. In\nparticular, we design CLASH in a way to support the study of critical aspects\nof value-based decision-making processes which are missing from prior work,\nincluding understanding decision ambivalence and psychological discomfort as\nwell as capturing the temporal shifts of values in characters' perspectives. By\nbenchmarking 10 open and closed frontier models, we uncover several key\nfindings. (1) Even the strongest models, such as GPT-4o and Claude-Sonnet,\nachieve less than 50% accuracy in identifying situations where the decision\nshould be ambivalent, while they perform significantly better in clear-cut\nscenarios. (2) While LLMs reasonably predict psychological discomfort as marked\nby human, they inadequately comprehend perspectives involving value shifts,\nindicating a need for LLMs to reason over complex values. (3) Our experiments\nalso reveal a significant correlation between LLMs' value preferences and their\nsteerability towards a given value. (4) Finally, LLMs exhibit greater\nsteerability when engaged in value reasoning from a third-party perspective,\ncompared to a first-person setup, though certain value pairs benefit uniquely\nfrom the first-person framing.",
      "tldr_zh": "该研究提出了CLASH，一个包含345个高风险困境和3795个不同价值观视角的评估数据集，用于评估大型语言模型(LLMs)在复杂价值判断中的推理能力。CLASH旨在研究决策矛盾、心理不适以及价值观随时间的变化等关键因素。通过对10个LLMs的基准测试，发现即使是GPT-4o和Claude-Sonnet等最强的模型在识别决策矛盾情境时的准确率也低于50%。LLMs在预测心理不适方面表现尚可，但在理解价值观转变方面不足。研究还揭示了LLMs的价值观偏好与其对特定价值观的可操纵性之间的显著相关性，并发现从第三人称视角进行价值推理比第一人称视角更易于操纵LLMs。\n",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10823v1",
      "published_date": "2025-04-15 02:54:16 UTC",
      "updated_date": "2025-04-15 02:54:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:27:12.733337"
    },
    {
      "arxiv_id": "2504.10821v1",
      "title": "Progressive Rock Music Classification",
      "title_zh": "前卫摇滚音乐分类",
      "authors": [
        "Arpan Nagar",
        "Joseph Bensabat",
        "Jokent Gaza",
        "Moinak Dey"
      ],
      "abstract": "This study investigates the classification of progressive rock music, a genre\ncharacterized by complex compositions and diverse instrumentation, distinct\nfrom other musical styles. Addressing this Music Information Retrieval (MIR)\ntask, we extracted comprehensive audio features, including spectrograms,\nMel-Frequency Cepstral Coefficients (MFCCs), chromagrams, and beat positions\nfrom song snippets using the Librosa library. A winner-take-all voting strategy\nwas employed to aggregate snippet-level predictions into final song\nclassifications. We conducted a comparative analysis of various machine\nlearning techniques. Ensemble methods, encompassing Bagging (Random Forest,\nExtraTrees, Bagging Classifier) and Boosting (XGBoost, Gradient Boosting), were\nexplored, utilizing Principal Component Analysis (PCA) for dimensionality\nreduction to manage computational constraints with high-dimensional feature\nsets. Additionally, deep learning approaches were investigated, including the\ndevelopment of custom 1D Convolutional Neural Network (1D CNN) architectures\n(named \"Zuck\" and \"Satya\") featuring specific layer configurations,\nnormalization, and activation functions. Furthermore, we fine-tuned a\nstate-of-the-art Audio Spectrogram Transformer (AST) model, leveraging its\nattention-based mechanisms for audio classification. Performance evaluation on\nvalidation and test sets revealed varying effectiveness across models, with\nensemble methods like Extra Trees achieving test accuracies up to 76.38%. This\nresearch provides insights into the application and relative performance of\ndiverse machine learning paradigms for the nuanced task of progressive rock\ngenre classification.",
      "tldr_zh": "本研究致力于进步摇滚音乐的分类，这是一个具有复杂编曲和多样乐器配置的独特音乐流派。研究提取了包括频谱图、梅尔频率倒谱系数(MFCCs)、色谱图和节拍位置等全面的音频特征，并采用胜者全得的投票策略将片段级别的预测聚合为最终的歌曲分类。研究比较了各种机器学习技术，包括使用主成分分析(PCA)进行降维的集成方法（如随机森林和XGBoost）和深度学习方法（包括定制的1D CNN架构和微调的音频频谱Transformer (AST)模型）。实验结果表明，Extra Trees等集成方法在测试集上达到了高达76.38%的准确率，为进步摇滚音乐流派分类提供了有价值的见解。\n",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "20 pages",
      "pdf_url": "http://arxiv.org/pdf/2504.10821v1",
      "published_date": "2025-04-15 02:48:52 UTC",
      "updated_date": "2025-04-15 02:48:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:27:24.828013"
    },
    {
      "arxiv_id": "2504.10817v1",
      "title": "FHBench: Towards Efficient and Personalized Federated Learning for Multimodal Healthcare",
      "title_zh": "FHBench：面向多模态医疗保健的高效和个性化联邦学习\n",
      "authors": [
        "Penghao Wang",
        "Qian Chen",
        "Teng Zhang",
        "Yingwei Zhang",
        "Wang Lu",
        "Yiqiang Chen"
      ],
      "abstract": "Federated Learning (FL) has emerged as an effective solution for\nmulti-institutional collaborations without sharing patient data, offering a\nrange of methods tailored for diverse applications. However, real-world medical\ndatasets are often multimodal, and computational resources are limited, posing\nsignificant challenges for existing FL approaches. Recognizing these\nlimitations, we developed the Federated Healthcare Benchmark(FHBench), a\nbenchmark specifically designed from datasets derived from real-world\nhealthcare applications. FHBench encompasses critical diagnostic tasks across\ndomains such as the nervous, cardiovascular, and respiratory systems and\ngeneral pathology, providing comprehensive support for multimodal healthcare\nevaluations and filling a significant gap in existing benchmarks. Building on\nFHBench, we introduced Efficient Personalized Federated Learning with Adaptive\nLoRA(EPFL), a personalized FL framework that demonstrates superior efficiency\nand effectiveness across various healthcare modalities. Our results highlight\nthe robustness of FHBench as a benchmarking tool and the potential of EPFL as\nan innovative approach to advancing healthcare-focused FL, addressing key\nlimitations of existing methods.",
      "tldr_zh": "该论文提出了联邦医疗基准(FHBench)，旨在解决现有联邦学习(FL)方法在多模态医疗数据和有限计算资源下的挑战。FHBench包含来自真实医疗场景的数据集，覆盖神经、心血管、呼吸系统和一般病理等关键诊断任务，全面支持多模态医疗评估。此外，论文还提出了基于FHBench的高效个性化联邦学习框架EPFL (Efficient Personalized Federated Learning with Adaptive LoRA)，该框架在各种医疗模态上表现出卓越的效率和有效性。实验结果表明FHBench是一个强大的基准测试工具，而EPFL是推动以医疗保健为中心的FL的一种创新方法。\n",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10817v1",
      "published_date": "2025-04-15 02:38:00 UTC",
      "updated_date": "2025-04-15 02:38:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:27:36.649094"
    },
    {
      "arxiv_id": "2504.10812v1",
      "title": "E2E Parking Dataset: An Open Benchmark for End-to-End Autonomous Parking",
      "title_zh": "E2E Parking Dataset：端到端自动泊车的开放基准\n",
      "authors": [
        "Kejia Gao",
        "Liguo Zhou",
        "Mingjun Liu",
        "Alois Knoll"
      ],
      "abstract": "End-to-end learning has shown great potential in autonomous parking, yet the\nlack of publicly available datasets limits reproducibility and benchmarking.\nWhile prior work introduced a visual-based parking model and a pipeline for\ndata generation, training, and close-loop test, the dataset itself was not\nreleased. To bridge this gap, we create and open-source a high-quality dataset\nfor end-to-end autonomous parking. Using the original model, we achieve an\noverall success rate of 85.16% with lower average position and orientation\nerrors (0.24 meters and 0.34 degrees).",
      "tldr_zh": "该论文发布了一个高质量的端到端自动泊车数据集，旨在弥补现有数据集的不足，促进端到端学习在自动泊车领域的应用。该数据集基于先前工作中的视觉泊车模型和数据生成流程构建，并进行了开源。实验结果表明，使用原始模型在该数据集上取得了85.16%的整体成功率，且平均位置误差和方向误差较低（0.24米和0.34度）。该数据集的发布将有助于端到端自动泊车算法的复现和基准测试。\n",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10812v1",
      "published_date": "2025-04-15 02:21:09 UTC",
      "updated_date": "2025-04-15 02:21:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:27:48.608430"
    },
    {
      "arxiv_id": "2504.10810v1",
      "title": "PatrolVision: Automated License Plate Recognition in the wild",
      "title_zh": "PatrolVision：野外环境下的自动车牌识别\n",
      "authors": [
        "Anmol Singhal Navya Singhal"
      ],
      "abstract": "Adoption of AI driven techniques in public services remains low due to\nchallenges related to accuracy and speed of information at population scale.\nComputer vision techniques for traffic monitoring have not gained much\npopularity despite their relative strength in areas such as autonomous driving.\nDespite large number of academic methods for Automatic License Plate\nRecognition (ALPR) systems, very few provide an end to end solution for\npatrolling in the city. This paper presents a novel prototype for a low power\nGPU based patrolling system to be deployed in an urban environment on\nsurveillance vehicles for automated vehicle detection, recognition and\ntracking. In this work, we propose a complete ALPR system for Singapore license\nplates having both single and double line creating our own YOLO based network.\nWe focus on unconstrained capture scenarios as would be the case in real world\napplication, where the license plate (LP) might be considerably distorted due\nto oblique views. In this work, we first detect the license plate from the full\nimage using RFB-Net and rectify multiple distorted license plates in a single\nimage. After that, the detected license plate image is fed to our network for\ncharacter recognition. We evaluate the performance of our proposed system on a\nnewly built dataset covering more than 16,000 images. The system was able to\ncorrectly detect license plates with 86\\% precision and recognize characters of\na license plate in 67\\% of the test set, and 89\\% accuracy with one incorrect\ncharacter (partial match). We also test latency of our system and achieve 64FPS\non Tesla P4 GPU",
      "tldr_zh": "本文提出了一种基于低功耗GPU的巡逻系统原型PatrolVision，用于城市环境中车辆的自动检测、识别和跟踪，旨在解决公共服务中AI技术应用普及率低的问题。该系统针对新加坡车牌设计，包含基于YOLO的车牌检测和字符识别网络，能够处理单行和双行车牌。系统首先使用RFB-Net检测图像中的车牌，并校正倾斜变形的车牌，然后将校正后的图像输入到字符识别网络。在包含超过16000张图像的新数据集上进行的评估表明，该系统车牌检测精度为86%，车牌字符识别准确率为67%（允许一个错误字符的局部匹配准确率为89%），在Tesla P4 GPU上可实现64FPS。\n",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted in IEEE Southeast Con 2025. To be published in IEEEXplore",
      "pdf_url": "http://arxiv.org/pdf/2504.10810v1",
      "published_date": "2025-04-15 02:10:43 UTC",
      "updated_date": "2025-04-15 02:10:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:28:00.936295"
    },
    {
      "arxiv_id": "2504.10797v1",
      "title": "Name of Thrones: Evaluating How LLMs Rank Student Names, Race, and Gender in Status Hierarchies",
      "title_zh": "权力的名字：评估 LLM 如何在地位等级中排列学生姓名、种族和性别\n",
      "authors": [
        "Annabella Sakunkoo",
        "Jonathan Sakunkoo"
      ],
      "abstract": "Across cultures, names tell a lot about their bearers as they carry deep\npersonal and cultural significance. Names also serve as powerful signals of\ngender, race, and status in the social hierarchy - a pecking order in which\nindividual positions shape others' expectations on their perceived competence\nand worth. With the widespread adoption of LLMs and as names are often an input\nfor LLMs, it is crucial to evaluate whether LLMs may sort people into status\npositions based on first and last names and, if so, whether it is in an unfair,\nbiased fashion. While prior work has primarily investigated biases in first\nnames, little attention has been paid to last names and even less to the\ncombined effects of first and last names. In this study, we conduct a\nlarge-scale analysis of name variations across 5 ethnicities to examine how AI\nexhibits name biases. Our study investigates three key characteristics of\ninequality and finds that LLMs reflect and reinforce status hierarchies based\non names that signal gender and ethnicity as they encode differential\nexpectations of competence, leadership, and economic potential. Contrary to the\ncommon assumption that AI tends to favor Whites, we show that East and, in some\ncontexts, South Asian names receive higher rankings. We also disaggregate\nAsians, a population projected to be the largest immigrant group in the U.S. by\n2055. Our results challenge the monolithic Asian model minority assumption,\nillustrating a more complex and stratified model of bias. Gender moderates\nbiases, with girls facing unfair disadvantages in certain racial groups.\nAdditionally, spanning cultural categories by adopting Western first names\nimproves AI-perceived status for East and Southeast Asian students,\nparticularly for girls. Our findings underscore the importance of\nintersectional and more nuanced understandings of race, gender, and mixed\nidentities in the evaluation of LLMs.",
      "tldr_zh": "该研究评估了大型语言模型(LLMs)如何根据姓名（包括first name和last name）对学生进行地位等级排序，考察了种族和性别因素的影响。研究发现，LLMs会基于姓名所暗示的性别和种族来反映和强化社会地位等级，从而产生对能力、领导力和经济潜力的差异化预期。与通常认为AI偏袒白人的假设相反，研究表明东亚和（在某些情况下）南亚的姓名获得了更高的排名。此外，研究还揭示了亚洲人群体内部的差异，挑战了“模范少数族裔”的刻板印象。性别会调节偏见，某些种族群体中的女孩面临不公平的劣势。采用西方first name可以提高AI对东亚和东南亚学生的地位感知，尤其对女孩而言。研究强调了在评估LLMs时，对种族、性别和混合身份进行交叉和细致理解的重要性。\n",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC",
        "H.5; J.4"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10797v1",
      "published_date": "2025-04-15 01:47:39 UTC",
      "updated_date": "2025-04-15 01:47:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:28:13.208308"
    },
    {
      "arxiv_id": "2504.10786v2",
      "title": "Visual Language Models show widespread visual deficits on neuropsychological tests",
      "title_zh": "视觉语言模型在神经心理学测试中表现出普遍的视觉缺陷\n",
      "authors": [
        "Gene Tangtartharakul",
        "Katherine R. Storrs"
      ],
      "abstract": "Visual Language Models (VLMs) show remarkable performance in visual reasoning\ntasks, successfully tackling college-level challenges that require high-level\nunderstanding of images. However, some recent reports of VLMs struggling to\nreason about elemental visual concepts like orientation, position, continuity,\nand occlusion suggest a potential gulf between human and VLM vision. Here we\nuse the toolkit of neuropsychology to systematically assess the capabilities of\nthree state-of-the-art VLMs across visual domains. Using 51 tests drawn from\nsix clinical and experimental batteries, we characterise the visual abilities\nof leading VLMs relative to normative performance in healthy adults. While the\nmodels excel in straightforward object recognition tasks, we find widespread\ndeficits in low- and mid-level visual abilities that would be considered\nclinically significant in humans. These selective deficits, profiled through\nvalidated test batteries, suggest that an artificial system can achieve complex\nobject recognition without developing foundational visual concepts that in\nhumans require no explicit training.",
      "tldr_zh": "该研究采用神经心理学方法，系统评估了三种最先进的视觉语言模型(VLMs)在视觉领域的表现。通过51项来自临床和实验的测试，研究人员将VLMs的视觉能力与健康成年人的标准表现进行比较。结果表明，VLMs在直接的物体识别任务中表现出色，但在低级和中级视觉能力方面存在广泛缺陷，这些缺陷在人类中具有临床意义。这些选择性缺陷表明，人工智能系统可以在不发展人类无需明确训练的基础视觉概念的情况下，实现复杂的物体识别。\n",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "I.2.0; I.2.10"
      ],
      "primary_category": "cs.CV",
      "comment": "31 pages, 3 figures, 1 supplementary document with 1 figure and 51\n  sample images; corrected typo in Fig 1",
      "pdf_url": "http://arxiv.org/pdf/2504.10786v2",
      "published_date": "2025-04-15 01:04:56 UTC",
      "updated_date": "2025-04-16 01:27:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:28:24.491081"
    },
    {
      "arxiv_id": "2504.10784v1",
      "title": "ATLASv2: LLM-Guided Adaptive Landmark Acquisition and Navigation on the Edge",
      "title_zh": "ATLASv2：LLM引导的边缘自适应地标获取与导航\n",
      "authors": [
        "Mikolaj Walczak",
        "Uttej Kallakuri",
        "Tinoosh Mohsenin"
      ],
      "abstract": "Autonomous systems deployed on edge devices face significant challenges,\nincluding resource constraints, real-time processing demands, and adapting to\ndynamic environments. This work introduces ATLASv2, a novel system that\nintegrates a fine-tuned TinyLLM, real-time object detection, and efficient path\nplanning to enable hierarchical, multi-task navigation and manipulation all on\nthe edge device, Jetson Nano. ATLASv2 dynamically expands its navigable\nlandmarks by detecting and localizing objects in the environment which are\nsaved to its internal knowledge base to be used for future task execution. We\nevaluate ATLASv2 in real-world environments, including a handcrafted home and\noffice setting constructed with diverse objects and landmarks. Results show\nthat ATLASv2 effectively interprets natural language instructions, decomposes\nthem into low-level actions, and executes tasks with high success rates. By\nleveraging generative AI in a fully on-board framework, ATLASv2 achieves\noptimized resource utilization with minimal prompting latency and power\nconsumption, bridging the gap between simulated environments and real-world\napplications.",
      "tldr_zh": "ATLASv2是一个新型系统，它集成了微调的TinyLLM、实时目标检测和高效路径规划，以在边缘设备（如Jetson Nano）上实现分层多任务导航和操作。该系统通过检测和定位环境中的对象来动态扩展其可导航地标，并将这些信息保存到内部知识库中，以供未来的任务执行。ATLASv2能够有效地解释自然语言指令，将其分解为低级动作，并在真实环境中以高成功率执行任务。通过在完全板载框架中利用生成式AI，ATLASv2实现了优化的资源利用率，同时最大限度地减少了提示延迟和功耗。\n",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10784v1",
      "published_date": "2025-04-15 00:55:57 UTC",
      "updated_date": "2025-04-15 00:55:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:28:36.612361"
    },
    {
      "arxiv_id": "2504.10781v1",
      "title": "Neural Network Emulation of the Classical Limit in Quantum Systems via Learned Observable Mappings",
      "title_zh": "通过学习可观测映射，利用神经网络模拟量子系统中经典极限\n",
      "authors": [
        "Kamran Majid"
      ],
      "abstract": "The classical limit of quantum mechanics, formally investigated through\nframeworks like strict deformation quantization, remains a profound area of\ninquiry in the philosophy of physics. This paper explores a computational\napproach employing a neural network to emulate the emergence of classical\nbehavior from the quantum harmonic oscillator as Planck's constant $\\hbar$\napproaches zero. We develop and train a neural network architecture to learn\nthe mapping from initial expectation values and $\\hbar$ to the time evolution\nof the expectation value of position. By analyzing the network's predictions\nacross different regimes of hbar, we aim to provide computational insights into\nthe nature of the quantum-classical transition. This work demonstrates the\npotential of machine learning as a complementary tool for exploring\nfoundational questions in quantum mechanics and its classical limit.",
      "tldr_zh": "该论文利用神经网络模拟量子系统中的经典极限，特别是当普朗克常数$\\hbar$趋近于零时，量子谐振子如何表现出经典行为。研究训练了一个神经网络，使其学习从初始期望值和$\\hbar$到位置期望值随时间演化的映射关系。通过分析网络在不同$\\hbar$值下的预测结果，旨在为量子-经典过渡的本质提供计算层面的见解。这项工作展示了机器学习作为探索量子力学及其经典极限中基本问题的补充工具的潜力。\n",
      "categories": [
        "quant-ph",
        "cs.AI"
      ],
      "primary_category": "quant-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10781v1",
      "published_date": "2025-04-15 00:48:36 UTC",
      "updated_date": "2025-04-15 00:48:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:28:48.495257"
    },
    {
      "arxiv_id": "2504.10768v1",
      "title": "The Art of Audience Engagement: LLM-Based Thin-Slicing of Scientific Talks",
      "title_zh": "观众参与的艺术：基于LLM的科学讲座薄片化分析\n",
      "authors": [
        "Ralf Schmälzle",
        "Sue Lim",
        "Yuetong Du",
        "Gary Bente"
      ],
      "abstract": "This paper examines the thin-slicing approach - the ability to make accurate\njudgments based on minimal information - in the context of scientific\npresentations. Drawing on research from nonverbal communication and personality\npsychology, we show that brief excerpts (thin slices) reliably predict overall\npresentation quality. Using a novel corpus of over one hundred real-life\nscience talks, we employ Large Language Models (LLMs) to evaluate transcripts\nof full presentations and their thin slices. By correlating LLM-based\nevaluations of short excerpts with full-talk assessments, we determine how much\ninformation is needed for accurate predictions. Our results demonstrate that\nLLM-based evaluations align closely with human ratings, proving their validity,\nreliability, and efficiency. Critically, even very short excerpts (less than 10\npercent of a talk) strongly predict overall evaluations. This suggests that the\nfirst moments of a presentation convey relevant information that is used in\nquality evaluations and can shape lasting impressions. The findings are robust\nacross different LLMs and prompting strategies. This work extends thin-slicing\nresearch to public speaking and connects theories of impression formation to\nLLMs and current research on AI communication. We discuss implications for\ncommunication and social cognition research on message reception. Lastly, we\nsuggest an LLM-based thin-slicing framework as a scalable feedback tool to\nenhance human communication.",
      "tldr_zh": "本文研究了科学演讲中基于少量信息做出准确判断的“薄片切片(thin-slicing)”方法。研究人员使用包含超过一百个真实科学演讲的新语料库，利用大型语言模型(LLMs)评估完整演讲稿及其薄片切片。通过将基于LLM的短片段评估与完整演讲评估相关联，确定了准确预测所需的信息量。结果表明，即使是非常短的片段（不到演讲的10%）也能强烈预测整体评估结果，并且LLM评估与人类评分高度一致。该研究表明演讲的最初时刻传达了用于质量评估的相关信息，并可能形成持久的印象。作者最后提出了一个基于LLM的薄片切片框架，作为增强人际沟通的可扩展反馈工具。\n",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.ET",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.10768v1",
      "published_date": "2025-04-15 00:08:13 UTC",
      "updated_date": "2025-04-15 00:08:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-17T02:29:00.869725"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 96,
  "processed_papers_count": 96,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-04-17T02:30:56.824004"
}