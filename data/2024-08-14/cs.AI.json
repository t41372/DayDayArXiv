{
  "date": "2024-08-14",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-08-14 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文聚焦于 AI 模型的安全性、优化和实际应用，包括 LLM 的幻觉检测、多模态学习、强化学习在医疗和交通中的创新，以及一些理论进展如逻辑编程和知识图谱；令人印象深刻的是论文 2（LLM 幻觉研究，作者包括 Simon Kornblith）和论文 19（LLM 模型合并综述），它们探讨了 LLM 的核心挑战和扩展潜力。\n\n以下是今日论文的精选摘要，我会优先讨论重要、话题度高的论文（如 LLM 相关和实际应用），并将相关主题归类讨论。不那么重要的论文（如纯理论或小众领域）将快速掠过，只列出标题和核心点。\n\n### LLM 和 AI 安全相关\n- **Training Language Models on the Knowledge Graph: Insights on Hallucinations and Their Detectability（在知识图谱上训练语言模型：关于幻觉及其可检测性的洞见）**  \n  主要贡献：提出使用知识图谱训练 LLM 以减少幻觉（hallucinations），发现更大模型在固定数据集上幻觉更少，但检测幻觉时模型规模与检测性能呈反比。发现：更大模型需要更多计算资源来控制幻觉，这对 LLM 可靠性有重要启示。作者包括知名学者 Simon Kornblith 等，发表在 COLM 2024。\n\n- **CodeMirage: Hallucinations in Code Generated by Large Language Models（CodeMirage：大型语言模型生成的代码中的幻觉）**  \n  主要贡献：首次定义代码生成中的幻觉类型（如语法错误、安全漏洞），并构建基准数据集 CodeMirage（1137 个样本）。发现：GPT-4 在检测幻觉时表现最佳，并提出缓解策略。这对代码生成工具的安全性有实际影响。\n\n- **Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities（LLM、MLLM 及更广泛的模型合并：方法、理论、应用和机会）**  \n  主要贡献：全面综述模型合并技术（无需原始数据），包括方法分类和在 LLM、多模态模型中的应用。发现：模型合并能提升计算效率，但需解决泛化问题。这是一篇高影响力综述，作者 Enneng Yang 等。\n\n- **Alignment-Enhanced Decoding: Defending via Token-Level Adaptive Refining of Probability Distributions（对齐增强解码：通过标记级自适应概率分布细化进行防御）**  \n  主要贡献：提出 AED 框架，使用自评估反馈优化 LLM 输出以防御越狱攻击（jailbreak）。发现：能提升模型的安全性，同时保持有用性。接受于 EMNLP 2024，这对 LLM 实际部署有直接价值。\n\n- **Fast Inference for Probabilistic Answer Set Programs via the Residual Program（通过残差程序加速概率答案集程序的推理）**  \n  主要贡献：优化概率答案集程序的推理过程，移除无关部分加速计算。发现：在图数据集上显著提升效率。这对逻辑编程和 AI 推理有技术提升，但相对小众，快速掠过。\n\n### 多模态学习和图像处理\n- **SER Evals: In-domain and Out-of-domain Benchmarking for Speech Emotion Recognition（SER Evals：语音情感识别的领域内和领域外基准测试）**  \n  主要贡献：构建多语言基准数据集评估语音情感识别模型，Whisper 模型在跨语言任务中超越专用模型。发现：模型泛化性不足，这推动了更鲁棒的 SER 研究。接受于 INTERSPEECH 2024。\n\n- **End-to-end Semantic-centric Video-based Multimodal Affective Computing（端到端语义中心视频多模态情感计算）**  \n  主要贡献：提出 SemanticMAC 框架，使用 Transformer 处理视频和文本的多模态情感，结合语义一致性损失。发现：在多个任务上超越 SOTA，提升了情感计算的准确性。\n\n- **A Spitting Image: Modular Superpixel Tokenization in Vision Transformers（镜像分割：Vision Transformers 中的模块化超像素标记化）**  \n  主要贡献：引入超像素标记化策略，改进 Vision Transformers 在图像分割和密集预测中的性能。发现：提升了归因的可解释性和像素级精度。\n\n其他图像相关论文如 **MetaSeg: MetaFormer-based Global Contexts-aware Network for Efficient Semantic Segmentation（MetaSeg：基于 MetaFormer 的全局上下文感知网络用于高效语义分割）** 等，贡献在于优化分割模型效率，但不那么话题度高，快速掠过：它们提出新网络架构提升分割性能，在基准上表现良好。\n\n### 强化学习和实际应用\n- **Enhancing Equitable Access to AI in Housing and Homelessness System of Care through Federated Learning（通过联邦学习增强住房和无家可归者护理系统中的 AI 公平访问）**  \n  主要贡献：使用联邦学习让多个机构共享模型训练而不泄露敏感数据。发现：在真实数据上性能与完全共享相当，这对医疗 AI 隐私保护有启发。\n\n- **SustainDC: Benchmarking for Sustainable Data Center Control（SustainDC：可持续数据中心控制的基准测试）**  \n  主要贡献：构建 Python 环境基准多代理强化学习算法优化数据中心能效。发现：MARL 可显著降低能耗，这对绿色计算有实际意义。接受于 NeurIPS 2024。\n\n- **The Restaurant Meal Delivery Problem with Ghost Kitchens（带虚拟厨房的餐厅送餐问题）**  \n  主要贡献：使用强化学习优化虚拟厨房的送餐调度。发现：整合烹饪和派送可减少拥堵，这对物流优化有应用价值。\n\n医疗和交通相关论文如 **Deep Learning: a Heuristic Three-stage Mechanism for Grid Searches to Optimize the Future Risk Prediction of Breast Cancer Metastasis（深度学习：用于优化乳腺癌转移风险预测的启发式三阶段网格搜索机制）**，贡献在于改进网格搜索提升预测准确性；以及 **Optimizing Dynamic Traffic Distribution for Urban Networks with Answer Set Programming（使用答案集编程优化城市网络的动态交通分布）** 等，快速掠过：它们提供新框架提升预测和交通效率。\n\n### 其他快速掠过\n剩余论文多为理论或小众主题，如逻辑编程、知识图谱和因果推理（例如 **Quantifying over Optimum Answer Sets（量化最优答案集）** 和 **Relational Graph Convolutional Networks Do Not Learn Sound Rules（关系图卷积网络无法学习可靠规则）**），它们探讨了 AI 模型的理论局限性，但不那么引人注目，仅列出标题：**PeriodWave: Multi-Period Flow Matching for High-Fidelity Waveform Generation（PeriodWave：多周期流匹配用于高保真波形生成）** 等，贡献在于音频生成优化；**Drug Discovery SMILES-to-Pharmacokinetics Diffusion Models（药物发现 SMILES 到药代动力学的扩散模型）**，提出合成数据生成框架。\n\n总之，今天的论文突出了 AI 模型的安全和应用潜力，LLM 相关研究尤其值得关注。如果你对 LLM 幻觉或多模态学习感兴趣，建议优先查看论文 2 和 19。更多细节可查阅 arXiv。明天的快报见！",
  "papers": [
    {
      "arxiv_id": "2408.07854v1",
      "title": "CON-FOLD -- Explainable Machine Learning with Confidence",
      "title_zh": "翻译失败",
      "authors": [
        "Lachlan McGinness",
        "Peter Baumgartner"
      ],
      "abstract": "FOLD-RM is an explainable machine learning classification algorithm that uses\ntraining data to create a set of classification rules. In this paper we\nintroduce CON-FOLD which extends FOLD-RM in several ways. CON-FOLD assigns\nprobability-based confidence scores to rules learned for a classification task.\nThis allows users to know how confident they should be in a prediction made by\nthe model. We present a confidence-based pruning algorithm that uses the unique\nstructure of FOLD-RM rules to efficiently prune rules and prevent overfitting.\nFurthermore, CON-FOLD enables the user to provide pre-existing knowledge in the\nform of logic program rules that are either (fixed) background knowledge or\n(modifiable) initial rule candidates. The paper describes our method in detail\nand reports on practical experiments. We demonstrate the performance of the\nalgorithm on benchmark datasets from the UCI Machine Learning Repository. For\nthat, we introduce a new metric, Inverse Brier Score, to evaluate the accuracy\nof the produced confidence scores. Finally we apply this extension to a real\nworld example that requires explainability: marking of student responses to a\nshort answer question from the Australian Physics Olympiad.",
      "tldr_zh": "该论文介绍了 CON-FOLD，一种扩展 FOLD-RM 的可解释机器学习分类算法，能够为分类规则分配基于概率的 confidence scores，从而帮助用户评估预测的可靠性。CON-FOLD 包括一个 confidence-based pruning 算法，利用规则的独特结构来高效修剪规则并防止过拟合，同时允许用户整合预有知识，如逻辑程序规则作为背景或初始候选。实验在 UCI Machine Learning Repository 的基准数据集上验证了其性能，引入了新指标 Inverse Brier Score 来评估 confidence scores 的准确性，并将其应用于真实案例，如标记澳大利亚物理奥林匹克简答题的学生响应，以提升模型的可解释性。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "F.4.1"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.07854v1",
      "published_date": "2024-08-14 23:45:21 UTC",
      "updated_date": "2024-08-14 23:45:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:10:21.594893"
    },
    {
      "arxiv_id": "2408.07852v1",
      "title": "Training Language Models on the Knowledge Graph: Insights on Hallucinations and Their Detectability",
      "title_zh": "在知识图谱上训练语言模型：关于幻觉及其可检测性的洞见",
      "authors": [
        "Jiri Hron",
        "Laura Culp",
        "Gamaleldin Elsayed",
        "Rosanne Liu",
        "Ben Adlam",
        "Maxwell Bileschi",
        "Bernd Bohnet",
        "JD Co-Reyes",
        "Noah Fiedel",
        "C. Daniel Freeman",
        "Izzeddin Gur",
        "Kathleen Kenealy",
        "Jaehoon Lee",
        "Peter J. Liu",
        "Gaurav Mishra",
        "Igor Mordatch",
        "Azade Nova",
        "Roman Novak",
        "Aaron Parisi",
        "Jeffrey Pennington",
        "Alex Rizkowsky",
        "Isabelle Simpson",
        "Hanie Sedghi",
        "Jascha Sohl-dickstein",
        "Kevin Swersky",
        "Sharad Vikram",
        "Tris Warkentin",
        "Lechao Xiao",
        "Kelvin Xu",
        "Jasper Snoek",
        "Simon Kornblith"
      ],
      "abstract": "While many capabilities of language models (LMs) improve with increased\ntraining budget, the influence of scale on hallucinations is not yet fully\nunderstood. Hallucinations come in many forms, and there is no universally\naccepted definition. We thus focus on studying only those hallucinations where\na correct answer appears verbatim in the training set. To fully control the\ntraining data content, we construct a knowledge graph (KG)-based dataset, and\nuse it to train a set of increasingly large LMs. We find that for a fixed\ndataset, larger and longer-trained LMs hallucinate less. However, hallucinating\non $\\leq5$% of the training data requires an order of magnitude larger model,\nand thus an order of magnitude more compute, than Hoffmann et al. (2022)\nreported was optimal. Given this costliness, we study how hallucination\ndetectors depend on scale. While we see detector size improves performance on\nfixed LM's outputs, we find an inverse relationship between the scale of the LM\nand the detectability of its hallucinations.",
      "tldr_zh": "这篇论文探讨了在知识图谱(KG)上训练语言模型(LMs)时，模型规模对幻觉(hallucinations)的影响，特别关注那些正确答案在训练集中出现的幻觉类型。研究者构建了一个KG-based数据集来训练一系列规模渐增的LMs，发现对于固定数据集，更大和训练更久的模型幻觉率降低，但将幻觉控制在训练数据的≤5%需要比Hoffmann et al. (2022)建议的模型大一个数量级，从而显著增加计算成本。同时，论文揭示了幻觉检测器的性能与模型规模的关系：检测器规模增大能提升对固定LM输出的检测效果，但LM规模越大，其幻觉的可检测性越低。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Published at COLM 2024. 16 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.07852v1",
      "published_date": "2024-08-14 23:34:28 UTC",
      "updated_date": "2024-08-14 23:34:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:10:34.793955"
    },
    {
      "arxiv_id": "2408.07851v1",
      "title": "SER Evals: In-domain and Out-of-domain Benchmarking for Speech Emotion Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Mohamed Osman",
        "Daniel Z. Kaplan",
        "Tamer Nadeem"
      ],
      "abstract": "Speech emotion recognition (SER) has made significant strides with the advent\nof powerful self-supervised learning (SSL) models. However, the generalization\nof these models to diverse languages and emotional expressions remains a\nchallenge. We propose a large-scale benchmark to evaluate the robustness and\nadaptability of state-of-the-art SER models in both in-domain and out-of-domain\nsettings. Our benchmark includes a diverse set of multilingual datasets,\nfocusing on less commonly used corpora to assess generalization to new data. We\nemploy logit adjustment to account for varying class distributions and\nestablish a single dataset cluster for systematic evaluation. Surprisingly, we\nfind that the Whisper model, primarily designed for automatic speech\nrecognition, outperforms dedicated SSL models in cross-lingual SER. Our results\nhighlight the need for more robust and generalizable SER models, and our\nbenchmark serves as a valuable resource to drive future research in this\ndirection.",
      "tldr_zh": "本研究提出SER Evals基准测试，用于评估语音情感识别(SER)模型在领域内(in-domain)和领域外(out-of-domain)场景下的鲁棒性和适应性，针对自监督学习(SSL)模型的泛化挑战。基准测试包括多语言数据集，重点关注较少使用的语料库，并采用logit adjustment处理类别分布差异，同时建立单一数据集集群进行系统评估。结果显示，Whisper模型（原本设计用于自动语音识别）在跨语言SER任务中超过了专用的SSL模型。这些发现突出了开发更鲁棒、可泛化SER模型的必要性，并为未来研究提供宝贵资源。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at INTERSPEECH 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.07851v1",
      "published_date": "2024-08-14 23:33:10 UTC",
      "updated_date": "2024-08-14 23:33:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:10:46.151000"
    },
    {
      "arxiv_id": "2408.07846v2",
      "title": "A System for Automated Unit Test Generation Using Large Language Models and Assessment of Generated Test Suites",
      "title_zh": "翻译失败",
      "authors": [
        "Andrea Lops",
        "Fedelucio Narducci",
        "Azzurra Ragone",
        "Michelantonio Trizio",
        "Claudio Bartolini"
      ],
      "abstract": "Unit tests represent the most basic level of testing within the software\ntesting lifecycle and are crucial to ensuring software correctness. Designing\nand creating unit tests is a costly and labor-intensive process that is ripe\nfor automation. Recently, Large Language Models (LLMs) have been applied to\nvarious aspects of software development, including unit test generation.\nAlthough several empirical studies evaluating LLMs' capabilities in test code\ngeneration exist, they primarily focus on simple scenarios, such as the\nstraightforward generation of unit tests for individual methods. These\nevaluations often involve independent and small-scale test units, providing a\nlimited view of LLMs' performance in real-world software development scenarios.\nMoreover, previous studies do not approach the problem at a suitable scale for\nreal-life applications. Generated unit tests are often evaluated via manual\nintegration into the original projects, a process that limits the number of\ntests executed and reduces overall efficiency. To address these gaps, we have\ndeveloped an approach for generating and evaluating more real-life complexity\ntest suites. Our approach focuses on class-level test code generation and\nautomates the entire process from test generation to test assessment. In this\nwork, we present AgoneTest: an automated system for generating test suites for\nJava projects and a comprehensive and principled methodology for evaluating the\ngenerated test suites. Starting from a state-of-the-art dataset (i.e.,\nMethods2Test), we built a new dataset for comparing human-written tests with\nthose generated by LLMs. Our key contributions include a scalable automated\nsoftware system, a new dataset, and a detailed methodology for evaluating test\nquality.",
      "tldr_zh": "本研究开发了AgoneTest系统，使用Large Language Models (LLMs)自动生成Java项目的单元测试套件，并提供全面评估方法，以解决现有方法局限于简单场景和手动评估效率低的问题。该系统专注于类级测试代码生成，自动化从测试生成到评估的全过程，并基于Methods2Test数据集构建新数据集，用于比较人类编写测试与LLMs生成测试的质量。关键贡献包括一个可扩展的自动化软件系统、一个新数据集，以及一个详细的测试质量评估方法。该方法在真实世界软件开发场景中提升了测试生成和评估的效率和准确性。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.07846v2",
      "published_date": "2024-08-14 23:02:16 UTC",
      "updated_date": "2024-08-16 00:18:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:10:58.398850"
    },
    {
      "arxiv_id": "2408.07845v1",
      "title": "Enhancing Equitable Access to AI in Housing and Homelessness System of Care through Federated Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Musa Taib",
        "Jiajun Wu",
        "Steve Drew",
        "Geoffrey G. Messier"
      ],
      "abstract": "The top priority of a Housing and Homelessness System of Care (HHSC) is to\nconnect people experiencing homelessness to supportive housing. An HHSC\ntypically consists of many agencies serving the same population. Information\ntechnology platforms differ in type and quality between agencies, so their data\nare usually isolated from one agency to another. Larger agencies may have\nsufficient data to train and test artificial intelligence (AI) tools but\nsmaller agencies typically do not. To address this gap, we introduce a\nFederated Learning (FL) approach enabling all agencies to train a predictive\nmodel collaboratively without sharing their sensitive data. We demonstrate how\nFL can be used within an HHSC to provide all agencies equitable access to\nquality AI and further assist human decision-makers in the allocation of\nresources within HHSC. This is achieved while preserving the privacy of the\npeople within the data by not sharing identifying information between agencies\nwithout their consent. Our experimental results using real-world HHSC data from\nCalgary, Alberta, demonstrate that our FL approach offers comparable\nperformance with the idealized scenario of training the predictive model with\ndata fully shared and linked between agencies.",
      "tldr_zh": "该研究针对住房和无家可归者护理系统(HHSC)中机构数据孤立的问题，引入Federated Learning (FL)方法，让多个机构协作训练预测模型，而不共享敏感数据，从而实现AI工具的公平访问。FL帮助小机构克服数据不足的局限，并辅助人类决策者优化资源分配，同时保护个体隐私不被泄露。实验结果显示，使用Calgary真实数据的FL模型性能与完全共享数据训练的理想场景相当，证明了其有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at the 2024 AAAI/ACM Conference on AI, Ethics, and Society\n  (AIES)",
      "pdf_url": "http://arxiv.org/pdf/2408.07845v1",
      "published_date": "2024-08-14 23:01:02 UTC",
      "updated_date": "2024-08-14 23:01:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:11:09.995964"
    },
    {
      "arxiv_id": "2408.08333v1",
      "title": "CodeMirage: Hallucinations in Code Generated by Large Language Models",
      "title_zh": "CodeMirage：大语言模型生成的代码中的幻觉",
      "authors": [
        "Vibhor Agarwal",
        "Yulong Pei",
        "Salwa Alamir",
        "Xiaomo Liu"
      ],
      "abstract": "Large Language Models (LLMs) have shown promising potentials in program\ngeneration and no-code automation. However, LLMs are prone to generate\nhallucinations, i.e., they generate text which sounds plausible but is\nincorrect. Although there has been a recent surge in research on LLM\nhallucinations for text generation, similar hallucination phenomenon can happen\nin code generation. Sometimes the generated code can have syntactical or\nlogical errors as well as more advanced issues like security vulnerabilities,\nmemory leaks, etc. Given the wide adaptation of LLMs to enhance efficiency in\ncode generation and development in general, it becomes imperative to\ninvestigate hallucinations in code generation. To the best of our knowledge,\nthis is the first attempt at studying hallucinations in the code generated by\nLLMs. We start by introducing the code hallucination definition and a\ncomprehensive taxonomy of code hallucination types. We propose the first\nbenchmark CodeMirage dataset for code hallucinations. The benchmark contains\n1,137 GPT-3.5 generated hallucinated code snippets for Python programming\nproblems from two base datasets - HumanEval and MBPP. We then propose the\nmethodology for code hallucination detection and experiment with open source\nLLMs such as CodeLLaMA as well as OpenAI's GPT-3.5 and GPT-4 models using\none-shot prompt. We find that GPT-4 performs the best on HumanEval dataset and\ngives comparable results to the fine-tuned CodeBERT baseline on MBPP dataset.\nTowards the end, we discuss various mitigation strategies for code\nhallucinations and conclude our work.",
      "tldr_zh": "本研究探讨了大型语言模型（LLMs）在代码生成中产生的幻觉（hallucinations），即生成看似合理但实际错误的代码，可能包括语法错误、逻辑错误或安全漏洞等问题。作者首次定义了代码幻觉的分类，并构建了首个基准数据集CodeMirage，包含1,137个由GPT-3.5生成的Python代码片段，基于HumanEval和MBPP数据集。实验使用one-shot提示测试了CodeLLaMA、GPT-3.5和GPT-4模型，结果显示GPT-4在HumanEval数据集上表现最佳，并在MBPP数据集上与fine-tuned CodeBERT相当；最后，讨论了缓解代码幻觉的策略，为提升LLMs代码生成可靠性提供了基础。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted at AutoMates @ IJCAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.08333v1",
      "published_date": "2024-08-14 22:53:07 UTC",
      "updated_date": "2024-08-14 22:53:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:11:23.038493"
    },
    {
      "arxiv_id": "2408.07841v5",
      "title": "SustainDC: Benchmarking for Sustainable Data Center Control",
      "title_zh": "SustainDC：可持续数据中心控制的基准测试",
      "authors": [
        "Avisek Naug",
        "Antonio Guillen",
        "Ricardo Luna",
        "Vineet Gundecha",
        "Desik Rengarajan",
        "Sahand Ghorbanpour",
        "Sajad Mousavi",
        "Ashwin Ramesh Babu",
        "Dejan Markovikj",
        "Lekhapriya D Kashyap",
        "Soumyendu Sarkar"
      ],
      "abstract": "Machine learning has driven an exponential increase in computational demand,\nleading to massive data centers that consume significant amounts of energy and\ncontribute to climate change. This makes sustainable data center control a\npriority. In this paper, we introduce SustainDC, a set of Python environments\nfor benchmarking multi-agent reinforcement learning (MARL) algorithms for data\ncenters (DC). SustainDC supports custom DC configurations and tasks such as\nworkload scheduling, cooling optimization, and auxiliary battery management,\nwith multiple agents managing these operations while accounting for the effects\nof each other. We evaluate various MARL algorithms on SustainDC, showing their\nperformance across diverse DC designs, locations, weather conditions, grid\ncarbon intensity, and workload requirements. Our results highlight significant\nopportunities for improvement of data center operations using MARL algorithms.\nGiven the increasing use of DC due to AI, SustainDC provides a crucial platform\nfor the development and benchmarking of advanced algorithms essential for\nachieving sustainable computing and addressing other heterogeneous real-world\nchallenges.",
      "tldr_zh": "该论文探讨了机器学习驱动的数据中心（DC）能源消耗增加对气候变化的影响，并提出SustainDC，这是一个用于基准测试多智能体强化学习（MARL）算法的Python环境。SustainDC支持自定义DC配置和任务，如工作负载调度、冷却优化以及辅助电池管理，允许多个代理协同操作并考虑相互影响。实验结果显示，MARL算法在不同DC设计、位置、天气条件、电网碳强度和工作负载需求下表现出色，可显著提升数据中心运营效率；该平台为开发可持续计算算法提供关键工具，以应对AI时代的数据中心挑战。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at Advances in Neural Information Processing Systems 2024\n  (NeurIPS 2024)",
      "pdf_url": "http://arxiv.org/pdf/2408.07841v5",
      "published_date": "2024-08-14 22:43:52 UTC",
      "updated_date": "2025-04-30 08:01:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:11:33.044118"
    },
    {
      "arxiv_id": "2408.07840v1",
      "title": "ONSEP: A Novel Online Neural-Symbolic Framework for Event Prediction Based on Large Language Model",
      "title_zh": "ONSEP：一种新颖的在线神经符号框架，用于基于",
      "authors": [
        "Xuanqing Yu",
        "Wangtao Sun",
        "Jingwei Li",
        "Kang Liu",
        "Chengbao Liu",
        "Jie Tan"
      ],
      "abstract": "In the realm of event prediction, temporal knowledge graph forecasting (TKGF)\nstands as a pivotal technique. Previous approaches face the challenges of not\nutilizing experience during testing and relying on a single short-term history,\nwhich limits adaptation to evolving data. In this paper, we introduce the\nOnline Neural-Symbolic Event Prediction (ONSEP) framework, which innovates by\nintegrating dynamic causal rule mining (DCRM) and dual history augmented\ngeneration (DHAG). DCRM dynamically constructs causal rules from real-time\ndata, allowing for swift adaptation to new causal relationships. In parallel,\nDHAG merges short-term and long-term historical contexts, leveraging a\nbi-branch approach to enrich event prediction. Our framework demonstrates\nnotable performance enhancements across diverse datasets, with significant\nHit@k (k=1,3,10) improvements, showcasing its ability to augment large language\nmodels (LLMs) for event prediction without necessitating extensive retraining.\nThe ONSEP framework not only advances the field of TKGF but also underscores\nthe potential of neural-symbolic approaches in adapting to dynamic data\nenvironments.",
      "tldr_zh": "本研究针对事件预测中的 Temporal Knowledge Graph Forecasting (TKGF) 问题，提出了一种新型在线神经符号框架 ONSEP，以解决现有方法无法利用测试阶段经验和仅依赖短期历史数据的局限性。ONSEP 通过整合动态因果规则挖掘 (DCRM) 和双重历史增强生成 (DHAG)，实现了对实时数据的快速适应和短期与长期历史上下文的融合，从而增强 Large Language Models (LLMs) 在事件预测中的性能。实验结果显示，该框架在多种数据集上显著提升了 Hit@k (k=1,3,10) 指标，且无需大规模重新训练，展示了神经符号方法在动态数据环境中的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SC"
      ],
      "primary_category": "cs.CL",
      "comment": "16 pages, ACL 2024 Findings",
      "pdf_url": "http://arxiv.org/pdf/2408.07840v1",
      "published_date": "2024-08-14 22:28:19 UTC",
      "updated_date": "2024-08-14 22:28:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:11:45.538058"
    },
    {
      "arxiv_id": "2408.11852v2",
      "title": "Fast Training Dataset Attribution via In-Context Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Milad Fotouhi",
        "Mohammad Taha Bahadori",
        "Oluwaseyi Feyisetan",
        "Payman Arabshahi",
        "David Heckerman"
      ],
      "abstract": "We investigate the use of in-context learning and prompt engineering to\nestimate the contributions of training data in the outputs of instruction-tuned\nlarge language models (LLMs). We propose two novel approaches: (1) a\nsimilarity-based approach that measures the difference between LLM outputs with\nand without provided context, and (2) a mixture distribution model approach\nthat frames the problem of identifying contribution scores as a matrix\nfactorization task. Our empirical comparison demonstrates that the mixture\nmodel approach is more robust to retrieval noise in in-context learning,\nproviding a more reliable estimation of data contributions.",
      "tldr_zh": "这篇论文探讨了利用 in-context learning 和 prompt engineering 来快速评估训练数据对 instruction-tuned large language models (LLMs) 输出贡献的方法。研究者提出了两种新方法：(1) 基于相似性的 approach，通过比较提供上下文前后LLMs输出的差异来测量贡献；(2) 混合分布模型 approach，将识别贡献分数的问题框架化为矩阵分解任务。实验比较显示，混合分布模型方法对 in-context learning 中的 retrieval noise 更 robust，能提供更可靠的数据贡献估计。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.11852v2",
      "published_date": "2024-08-14 20:48:45 UTC",
      "updated_date": "2025-03-18 21:10:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:11:57.852881"
    },
    {
      "arxiv_id": "2408.08918v1",
      "title": "Supervised and Unsupervised Alignments for Spoofing Behavioral Biometrics",
      "title_zh": "翻译失败",
      "authors": [
        "Thomas Thebaud",
        "Gaël Le Lan",
        "Anthony Larcher"
      ],
      "abstract": "Biometric recognition systems are security systems based on intrinsic\nproperties of their users, usually encoded in high dimension representations\ncalled embeddings, which potential theft would represent a greater threat than\na temporary password or a replaceable key. To study the threat of embedding\ntheft, we perform spoofing attacks on two behavioral biometric systems (an\nautomatic speaker verification system and a handwritten digit analysis system)\nusing a set of alignment techniques. Biometric recognition systems based on\nembeddings work in two phases: enrollment - where embeddings are collected and\nstored - then authentication - when new embeddings are compared to the stored\nones -.The threat of stolen enrollment embeddings has been explored by the\ntemplate reconstruction attack literature: reconstructing the original data to\nspoof an authentication system is doable with black-box access to their\nencoder. In this document, we explore the options available to perform template\nreconstruction attacks without any access to the encoder. To perform those\nattacks, we suppose general rules over the distribution of embeddings across\nencoders and use supervised and unsupervised algorithms to align an unlabeled\nset of embeddings with a set from a known encoder. The use of an alignment\nalgorithm from the unsupervised translation literature gives promising results\non spoofing two behavioral biometric systems.",
      "tldr_zh": "该论文探讨了行为生物识别系统的安全威胁，特别关注嵌入(embeddings)盗取对语音验证和手写数字分析系统的影响。作者提出使用监督和无监督对齐技术(template reconstruction attack)来模拟欺骗攻击，这些方法假设嵌入分布的通用规则，并在无访问编码器的情况下对齐来自不同编码器的嵌入。实验结果显示，无监督翻译文献中的对齐算法在欺骗上述两个行为生物识别系统方面取得了有前景的效果，为评估和提升生物识别系统的鲁棒性提供了新见解。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "11 pages, 4 figures, 5 tables, submission in progress",
      "pdf_url": "http://arxiv.org/pdf/2408.08918v1",
      "published_date": "2024-08-14 20:46:59 UTC",
      "updated_date": "2024-08-14 20:46:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:12:10.493373"
    },
    {
      "arxiv_id": "2408.07791v1",
      "title": "An Efficient and Explanatory Image and Text Clustering System with Multimodal Autoencoder Architecture",
      "title_zh": "翻译失败",
      "authors": [
        "Tiancheng Shi",
        "Yuanchen Wei",
        "John R. Kender"
      ],
      "abstract": "We demonstrate the efficiencies and explanatory abilities of extensions to\nthe common tools of Autoencoders and LLM interpreters, in the novel context of\ncomparing different cultural approaches to the same international news event.\nWe develop a new Convolutional-Recurrent Variational Autoencoder (CRVAE) model\nthat extends the modalities of previous CVAE models, by using fully-connected\nlatent layers to embed in parallel the CNN encodings of video frames, together\nwith the LSTM encodings of their related text derived from audio. We\nincorporate the model within a larger system that includes frame-caption\nalignment, latent space vector clustering, and a novel LLM-based cluster\ninterpreter. We measure, tune, and apply this system to the task of summarizing\na video into three to five thematic clusters, with each theme described by ten\nLLM-produced phrases. We apply this system to two news topics, COVID-19 and the\nWinter Olympics, and five other topics are in progress.",
      "tldr_zh": "这篇论文提出了一种高效且可解释的图像和文本聚类系统，利用 Multimodal Autoencoder 架构来比较不同文化对同一国际新闻事件的处理方式。研究开发了新的 Convolutional-Recurrent Variational Autoencoder (CRVAE) 模型，通过全连接潜层并行嵌入 CNN 编码的视频帧和 LSTM 编码的相关文本（从音频中获取），并整合框架-标题对齐、潜空间向量聚类以及 LLM-based 集群解释器。系统可将视频总结为 3 到 5 个主题聚类，每个主题由 10 个 LLM 生成的短语描述，并已应用于 COVID-19 和 Winter Olympics 等新闻主题，展示了其在跨文化分析中的潜力。",
      "categories": [
        "cs.MM",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.MM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.07791v1",
      "published_date": "2024-08-14 20:03:53 UTC",
      "updated_date": "2024-08-14 20:03:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:12:25.211354"
    },
    {
      "arxiv_id": "2408.07768v1",
      "title": "On learning capacities of Sugeno integrals with systems of fuzzy relational equations",
      "title_zh": "翻译失败",
      "authors": [
        "Ismaïl Baaj"
      ],
      "abstract": "In this article, we introduce a method for learning a capacity underlying a\nSugeno integral according to training data based on systems of fuzzy relational\nequations. To the training data, we associate two systems of equations: a\n$\\max-\\min$ system and a $\\min-\\max$ system. By solving these two systems (in\nthe case that they are consistent) using Sanchez's results, we show that we can\ndirectly obtain the extremal capacities representing the training data. By\nreducing the $\\max-\\min$ (resp. $\\min-\\max$) system of equations to subsets of\ncriteria of cardinality less than or equal to $q$ (resp. of cardinality greater\nthan or equal to $n-q$), where $n$ is the number of criteria, we give a\nsufficient condition for deducing, from its potential greatest solution (resp.\nits potential lowest solution), a $q$-maxitive (resp. $q$-minitive) capacity.\nFinally, if these two reduced systems of equations are inconsistent, we show\nhow to obtain the greatest approximate $q$-maxitive capacity and the lowest\napproximate $q$-minitive capacity, using recent results to handle the\ninconsistency of systems of fuzzy relational equations.",
      "tldr_zh": "本研究提出了一种基于模糊关系方程系统的方法，用于根据训练数据学习Sugeno integrals的潜在容量。具体而言，通过将训练数据关联到$\\max-\\min$系统和$\\min-\\max$系统，并利用Sanchez的结果求解这些系统（若一致），可以直接获得代表训练数据的极值容量。该方法进一步通过减少系统子集（基于标准数量），给出推导出$q$-maxitive容量或$q$-minitive容量的充分条件；若减少后的系统不一致，则能计算出最大的近似$q$-maxitive容量和最小的近似$q$-minitive容量。该框架为处理模糊关系方程的不一致性提供了新途径，提升了容量学习的可行性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.07768v1",
      "published_date": "2024-08-14 18:40:01 UTC",
      "updated_date": "2024-08-14 18:40:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:12:35.490606"
    },
    {
      "arxiv_id": "2408.07697v1",
      "title": "Quantifying over Optimum Answer Sets",
      "title_zh": "翻译失败",
      "authors": [
        "Giuseppe Mazzotta",
        "Francesco Ricca",
        "Mirek Truszczynski"
      ],
      "abstract": "Answer Set Programming with Quantifiers (ASP(Q)) has been introduced to\nprovide a natural extension of ASP modeling to problems in the polynomial\nhierarchy (PH). However, ASP(Q) lacks a method for encoding in an elegant and\ncompact way problems requiring a polynomial number of calls to an oracle in\n$\\Sigma_n^p$ (that is, problems in $\\Delta_{n+1}^p$). Such problems include, in\nparticular, optimization problems. In this paper we propose an extension of\nASP(Q), in which component programs may contain weak constraints. Weak\nconstraints can be used both for expressing local optimization within\nquantified component programs and for modeling global optimization criteria. We\nshowcase the modeling capabilities of the new formalism through various\napplication scenarios. Further, we study its computational properties obtaining\ncomplexity results and unveiling non-obvious characteristics of ASP(Q) programs\nwith weak constraints.",
      "tldr_zh": "本文扩展了 Answer Set Programming with Quantifiers (ASP(Q))，通过引入弱约束 (weak constraints) 来优雅地处理多项式层次 (PH) 中的优化问题，这些问题通常需要多项式次数的 $\\Sigma_n^p$ 预言机调用。\n弱约束可用于表达量化组件程序内的局部优化以及全局优化标准，从而使建模更紧凑和灵活。\n研究通过各种应用场景展示了该形式化的建模能力，并分析了其计算属性，获得了复杂性结果并揭示了 ASP(Q) 程序的非显着特性。",
      "categories": [
        "cs.AI",
        "cs.CC",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.07697v1",
      "published_date": "2024-08-14 17:53:13 UTC",
      "updated_date": "2024-08-14 17:53:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:12:47.836115"
    },
    {
      "arxiv_id": "2408.07736v1",
      "title": "Enhancing Model Interpretability with Local Attribution over Global Exploration",
      "title_zh": "翻译失败",
      "authors": [
        "Zhiyu Zhu",
        "Zhibo Jin",
        "Jiayu Zhang",
        "Huaming Chen"
      ],
      "abstract": "In the field of artificial intelligence, AI models are frequently described\nas `black boxes' due to the obscurity of their internal mechanisms. It has\nignited research interest on model interpretability, especially in attribution\nmethods that offers precise explanations of model decisions. Current\nattribution algorithms typically evaluate the importance of each parameter by\nexploring the sample space. A large number of intermediate states are\nintroduced during the exploration process, which may reach the model's\nOut-of-Distribution (OOD) space. Such intermediate states will impact the\nattribution results, making it challenging to grasp the relative importance of\nfeatures. In this paper, we firstly define the local space and its relevant\nproperties, and we propose the Local Attribution (LA) algorithm that leverages\nthese properties. The LA algorithm comprises both targeted and untargeted\nexploration phases, which are designed to effectively generate intermediate\nstates for attribution that thoroughly encompass the local space. Compared to\nthe state-of-the-art attribution methods, our approach achieves an average\nimprovement of 38.21\\% in attribution effectiveness. Extensive ablation studies\nin our experiments also validate the significance of each component in our\nalgorithm. Our code is available at: https://github.com/LMBTough/LA/",
      "tldr_zh": "该论文针对 AI 模型的“黑盒”问题，提出 Local Attribution (LA) 算法，以提升模型可解释性，通过定义 local space 的属性并避免 Out-of-Distribution (OOD) 状态对归因结果的影响。LA 算法包括 targeted 和 untargeted exploration 阶段，用于生成覆盖 local space 的中间状态，从而更准确地评估特征重要性。与现有 attribution methods 相比，该方法在归因有效性上平均提高了 38.21%。实验还通过广泛的消融研究验证了算法各组件的关键作用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by ACMMM 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.07736v1",
      "published_date": "2024-08-14 17:53:08 UTC",
      "updated_date": "2024-08-14 17:53:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:13:00.178906"
    },
    {
      "arxiv_id": "2408.07694v1",
      "title": "End-to-end Semantic-centric Video-based Multimodal Affective Computing",
      "title_zh": "翻译失败",
      "authors": [
        "Ronghao Lin",
        "Ying Zeng",
        "Sijie Mai",
        "Haifeng Hu"
      ],
      "abstract": "In the pathway toward Artificial General Intelligence (AGI), understanding\nhuman's affection is essential to enhance machine's cognition abilities. For\nachieving more sensual human-AI interaction, Multimodal Affective Computing\n(MAC) in human-spoken videos has attracted increasing attention. However,\nprevious methods are mainly devoted to designing multimodal fusion algorithms,\nsuffering from two issues: semantic imbalance caused by diverse pre-processing\noperations and semantic mismatch raised by inconsistent affection content\ncontained in different modalities comparing with the multimodal ground truth.\nBesides, the usage of manual features extractors make they fail in building\nend-to-end pipeline for multiple MAC downstream tasks. To address above\nchallenges, we propose a novel end-to-end framework named SemanticMAC to\ncompute multimodal semantic-centric affection for human-spoken videos. We\nfirstly employ pre-trained Transformer model in multimodal data pre-processing\nand design Affective Perceiver module to capture unimodal affective\ninformation. Moreover, we present a semantic-centric approach to unify\nmultimodal representation learning in three ways, including gated feature\ninteraction, multi-task pseudo label generation, and intra-/inter-sample\ncontrastive learning. Finally, SemanticMAC effectively learn specific- and\nshared-semantic representations in the guidance of semantic-centric labels.\nExtensive experimental results demonstrate that our approach surpass the\nstate-of-the-art methods on 7 public datasets in four MAC downstream tasks.",
      "tldr_zh": "该论文提出了一种端到-end的语义中心框架SemanticMAC，用于基于视频的多模态情感计算（Multimodal Affective Computing），旨在解决现有方法中的语义不平衡、语义不匹配问题以及无法构建端到-end管道的局限性。该框架利用预训练Transformer模型处理多模态数据，并引入Affective Perceiver模块捕获单模态情感信息，同时通过门控特征交互、多任务伪标签生成和内部/外部样本对比学习等语义中心方法统一多模态表示学习。实验结果显示，SemanticMAC在7个公共数据集上，在四个MAC下游任务中超越了最先进方法，为实现更自然的AI-人类交互提供了重要进展。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "Under Review",
      "pdf_url": "http://arxiv.org/pdf/2408.07694v1",
      "published_date": "2024-08-14 17:50:27 UTC",
      "updated_date": "2024-08-14 17:50:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:13:12.012856"
    },
    {
      "arxiv_id": "2408.07680v2",
      "title": "A Spitting Image: Modular Superpixel Tokenization in Vision Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Marius Aasan",
        "Odd Kolbjørnsen",
        "Anne Schistad Solberg",
        "Adín Ramirez Rivera"
      ],
      "abstract": "Vision Transformer (ViT) architectures traditionally employ a grid-based\napproach to tokenization independent of the semantic content of an image. We\npropose a modular superpixel tokenization strategy which decouples tokenization\nand feature extraction; a shift from contemporary approaches where these are\ntreated as an undifferentiated whole. Using on-line content-aware tokenization\nand scale- and shape-invariant positional embeddings, we perform experiments\nand ablations that contrast our approach with patch-based tokenization and\nrandomized partitions as baselines. We show that our method significantly\nimproves the faithfulness of attributions, gives pixel-level granularity on\nzero-shot unsupervised dense prediction tasks, while maintaining predictive\nperformance in classification tasks. Our approach provides a modular\ntokenization framework commensurable with standard architectures, extending the\nspace of ViTs to a larger class of semantically-rich models.",
      "tldr_zh": "本文提出了一种模块化的 superpixel tokenization 策略，用于 Vision Transformers (ViT)，将 tokenization 和特征提取解耦，以解决传统网格-based tokenization 忽略图像语义内容的问题。该策略采用在线内容感知 tokenization 和尺度及形状不变的 positional embeddings，与基于 patch 的 tokenization 和随机分区作为基线进行对比实验。结果显示，该方法显著提升了归因的忠实度，在零样本无监督密集预测任务中实现像素级粒度，同时在分类任务中保持预测性能。该框架扩展了 ViT 的适用范围，提供了一个兼容标准架构的语义更丰富的模块化模型。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "68T45",
        "I.2.10; I.4.10"
      ],
      "primary_category": "cs.CV",
      "comment": "To appear in ECCV (MELEX) 2024 Workshop Proceedings",
      "pdf_url": "http://arxiv.org/pdf/2408.07680v2",
      "published_date": "2024-08-14 17:28:58 UTC",
      "updated_date": "2024-08-15 12:07:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:13:25.017900"
    },
    {
      "arxiv_id": "2408.16772v2",
      "title": "An Effective Information Theoretic Framework for Channel Pruning",
      "title_zh": "翻译失败",
      "authors": [
        "Yihao Chen",
        "Zefang Wang"
      ],
      "abstract": "Channel pruning is a promising method for accelerating and compressing\nconvolutional neural networks. However, current pruning algorithms still remain\nunsolved problems that how to assign layer-wise pruning ratios properly and\ndiscard the least important channels with a convincing criterion. In this\npaper, we present a novel channel pruning approach via information theory and\ninterpretability of neural networks. Specifically, we regard information\nentropy as the expected amount of information for convolutional layers. In\naddition, if we suppose a matrix as a system of linear equations, a higher-rank\nmatrix represents there exist more solutions to it, which indicates more\nuncertainty. From the point of view of information theory, the rank can also\ndescribe the amount of information. In a neural network, considering the rank\nand entropy as two information indicators of convolutional layers, we propose a\nfusion function to reach a compromise of them, where the fusion results are\ndefined as ``information concentration''. When pre-defining layer-wise pruning\nratios, we employ the information concentration as a reference instead of\nheuristic and engineering tuning to provide a more interpretable solution.\nMoreover, we leverage Shapley values, which are a potent tool in the\ninterpretability of neural networks, to evaluate the channel contributions and\ndiscard the least important channels for model compression while maintaining\nits performance. Extensive experiments demonstrate the effectiveness and\npromising performance of our method. For example, our method improves the\naccuracy by 0.21% when reducing 45.5% FLOPs and removing 40.3% parameters for\nResNet-56 on CIFAR-10. Moreover, our method obtains loss in Top-1/Top-5\naccuracies of 0.43%/0.11% by reducing 41.6% FLOPs and removing 35.0% parameters\nfor ResNet-50 on ImageNet.",
      "tldr_zh": "该论文提出了一种基于信息理论的框架，用于 channel pruning，以加速和压缩卷积神经网络，通过解决层级修剪比例分配和通道重要性评估的问题。该方法结合 information entropy 和矩阵 rank 计算“information concentration”作为修剪参考，并利用 Shapley values 评估通道贡献，以删除不重要通道同时保持模型性能。实验结果显示，在 ResNet-56 上 CIFAR-10 数据集减少 45.5% FLOPs 和 40.3% 参数后，准确率提高 0.21%；而在 ResNet-50 上 ImageNet 数据集减少 41.6% FLOPs 和 35.0% 参数时，Top-1/Top-5 准确率损失仅为 0.43%/0.11%。",
      "categories": [
        "cs.IT",
        "cs.AI",
        "cs.LG",
        "math.IT"
      ],
      "primary_category": "cs.IT",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.16772v2",
      "published_date": "2024-08-14 17:19:56 UTC",
      "updated_date": "2024-09-02 13:19:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:13:37.521778"
    },
    {
      "arxiv_id": "2408.07673v2",
      "title": "Deep Learning: a Heuristic Three-stage Mechanism for Grid Searches to Optimize the Future Risk Prediction of Breast Cancer Metastasis Using EHR-based Clinical Data",
      "title_zh": "翻译失败",
      "authors": [
        "Xia Jiang",
        "Yijun Zhou",
        "Chuhan Xu",
        "Adam Brufsky",
        "Alan Wells"
      ],
      "abstract": "A grid search, at the cost of training and testing a large number of models,\nis an effective way to optimize the prediction performance of deep learning\nmodels. A challenging task concerning grid search is the time management.\nWithout a good time management scheme, a grid search can easily be set off as a\nmission that will not finish in our lifetime. In this study, we introduce a\nheuristic three-stage mechanism for managing the running time of low-budget\ngrid searches, and the sweet-spot grid search (SSGS) and randomized grid search\n(RGS) strategies for improving model prediction performance, in predicting the\n5-year, 10-year, and 15-year risk of breast cancer metastasis. We develop deep\nfeedforward neural network (DFNN) models and optimize them through grid\nsearches. We conduct eight cycles of grid searches by applying our three-stage\nmechanism and SSGS and RGS strategies. We conduct various SHAP analyses\nincluding unique ones that interpret the importance of the DFNN-model\nhyperparameters. Our results show that grid search can greatly improve model\nprediction. The grid searches we conducted improved the risk prediction of\n5-year, 10-year, and 15-year breast cancer metastasis by 18.6%, 16.3%, and\n17.3% respectively, over the average performance of all corresponding models we\ntrained using the RGS strategy. We not only demonstrate best model performance\nbut also characterize grid searches from various aspects such as their\ncapabilities of discovering decent models and the unit grid search time. The\nthree-stage mechanism worked effectively. It made our low-budget grid searches\nfeasible and manageable, and in the meantime helped improve model prediction\nperformance. Our SHAP analyses identified both clinical risk factors important\nfor the prediction of future risk of breast cancer metastasis, and DFNN-model\nhyperparameters important to the prediction of performance scores.",
      "tldr_zh": "本研究提出了一种启发式三阶段机制，用于管理网格搜索(Grid Search)的运行时间，以优化基于电子健康记录(EHR)临床数据的深度学习(Deep Learning)模型，预测乳腺癌转移的5年、10年和15年风险。该机制结合甜点网格搜索(SSGS)和随机网格搜索(RGS)策略，应用于深度前馈神经网络(DFNN)模型，通过八轮网格搜索显著提升了预测性能，分别提高了18.6%、16.3%和17.3%的准确率。研究还利用SHAP分析解释了关键临床风险因素和模型超参数的重要性，为低预算网格搜索提供了可行且高效的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE",
        "q-bio.QM"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.07673v2",
      "published_date": "2024-08-14 17:16:50 UTC",
      "updated_date": "2024-08-15 14:35:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:13:51.200835"
    },
    {
      "arxiv_id": "2408.07666v4",
      "title": "Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities",
      "title_zh": "翻译失败",
      "authors": [
        "Enneng Yang",
        "Li Shen",
        "Guibing Guo",
        "Xingwei Wang",
        "Xiaochun Cao",
        "Jie Zhang",
        "Dacheng Tao"
      ],
      "abstract": "Model merging is an efficient empowerment technique in the machine learning\ncommunity that does not require the collection of raw training data and does\nnot require expensive computation. As model merging becomes increasingly\nprevalent across various fields, it is crucial to understand the available\nmodel merging techniques comprehensively. However, there is a significant gap\nin the literature regarding a systematic and thorough review of these\ntechniques. This survey provides a comprehensive overview of model merging\nmethods and theories, their applications in various domains and settings, and\nfuture research directions. Specifically, we first propose a new taxonomic\napproach that exhaustively discusses existing model merging methods. Secondly,\nwe discuss the application of model merging techniques in large language\nmodels, multimodal large language models, and 10+ machine learning subfields,\nincluding continual learning, multi-task learning, few-shot learning, etc.\nFinally, we highlight the remaining challenges of model merging and discuss\nfuture research directions. A comprehensive list of papers about model merging\nis available at\n\\url{https://github.com/EnnengYang/Awesome-Model-Merging-Methods-Theories-Applications}.",
      "tldr_zh": "这篇论文对模型合并(Model Merging)技术进行了全面调查，作为一种高效的机器学习方法，它无需原始训练数据和昂贵计算。作者提出了一种新的分类方法，系统讨论了现有的模型合并方法和理论，并将其应用于大型语言模型(LLMs)、多模态大型语言模型(MLLMs)以及10+子领域，如持续学习、 multi-task learning 和 few-shot learning。最终，论文突出了模型合并的挑战和未来研究方向，并提供了一个资源列表（https://github.com/EnnengYang/Awesome-Model-Merging-Methods-Theories-Applications）。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.07666v4",
      "published_date": "2024-08-14 16:58:48 UTC",
      "updated_date": "2024-09-05 14:37:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:14:00.314977"
    },
    {
      "arxiv_id": "2408.07663v2",
      "title": "Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions",
      "title_zh": "翻译失败",
      "authors": [
        "Quan Liu",
        "Zhenhong Zhou",
        "Longzhu He",
        "Yi Liu",
        "Wei Zhang",
        "Sen Su"
      ],
      "abstract": "Large language models are susceptible to jailbreak attacks, which can result\nin the generation of harmful content. While prior defenses mitigate these risks\nby perturbing or inspecting inputs, they ignore competing objectives, the\nunderlying cause of alignment failures. In this paper, we propose\nAlignment-Enhanced Decoding (AED), a novel defense that employs adaptive\ndecoding to address the root causes of jailbreak issues. We first define the\nCompetitive Index to quantify alignment failures and utilize feedback from\nself-evaluation to compute post-alignment logits. Then, AED adaptively combines\nAED and post-alignment logits with the original logits to obtain harmless and\nhelpful distributions. Consequently, our method enhances safety alignment while\nmaintaining helpfulness. We conduct experiments across five models and four\ncommon jailbreaks, with the results validating the effectiveness of our\napproach. Code is available at https://github.com/GIGABaozi/AED.git.",
      "tldr_zh": "该论文针对大语言模型易受jailbreak attacks的影响，导致生成有害内容的问题，提出了一种新防御方法Alignment-Enhanced Decoding (AED)。AED通过定义Competitive Index量化对齐失败，并利用self-evaluation反馈计算后对齐logits，然后自适应地将这些logits与原始logits结合，生成无害且有帮助的概率分布，从而增强安全对齐同时保持模型的实用性。实验在五个模型和四种常见jailbreak上验证了AED的有效性，并提供了开源代码。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by EMNLP 2024, 15 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.07663v2",
      "published_date": "2024-08-14 16:51:21 UTC",
      "updated_date": "2024-12-19 06:34:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:14:11.581604"
    },
    {
      "arxiv_id": "2408.07647v1",
      "title": "Adaptive Behavioral AI: Reinforcement Learning to Enhance Pharmacy Services",
      "title_zh": "翻译失败",
      "authors": [
        "Ana Fernández del Río",
        "Michael Brennan Leong",
        "Paulo Saraiva",
        "Ivan Nazarov",
        "Aditya Rastogi",
        "Moiz Hassan",
        "Dexian Tang",
        "África Periáñez"
      ],
      "abstract": "Pharmacies are critical in healthcare systems, particularly in low- and\nmiddle-income countries. Procuring pharmacists with the right behavioral\ninterventions or nudges can enhance their skills, public health awareness, and\npharmacy inventory management, ensuring access to essential medicines that\nultimately benefit their patients. We introduce a reinforcement learning\noperational system to deliver personalized behavioral interventions through\nmobile health applications. We illustrate its potential by discussing a series\nof initial experiments run with SwipeRx, an all-in-one app for pharmacists,\nincluding B2B e-commerce, in Indonesia. The proposed method has broader\napplications extending beyond pharmacy operations to optimize healthcare\ndelivery.",
      "tldr_zh": "本研究针对药房在医疗系统中的关键作用，特别是低中收入国家，提出了一种基于Reinforcement Learning的适应性行为AI系统，通过移动健康应用提供个性化的行为干预，以提升药剂师技能、公共卫生意识和库存管理。系统旨在优化药房服务，确保患者获得基本药物。研究通过与SwipeRx应用的初步实验在印尼进行验证，展示了其潜力；此外，该方法可扩展到更广泛的医疗交付优化领域。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY",
        "physics.data-an"
      ],
      "primary_category": "cs.LG",
      "comment": "Presented at The First Workshop on AI Behavioral Science (AIBS'24) at\n  KDD 2024, August 25, Barcelona, Spain",
      "pdf_url": "http://arxiv.org/pdf/2408.07647v1",
      "published_date": "2024-08-14 16:18:51 UTC",
      "updated_date": "2024-08-14 16:18:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:14:24.205755"
    },
    {
      "arxiv_id": "2408.07642v1",
      "title": "Boosting Unconstrained Face Recognition with Targeted Style Adversary",
      "title_zh": "通过目标样式对抗提升无约束人脸识别",
      "authors": [
        "Mohammad Saeed Ebrahimi Saadabadi",
        "Sahar Rahimi Malakshan",
        "Seyed Rasoul Hosseini",
        "Nasser M. Nasrabadi"
      ],
      "abstract": "While deep face recognition models have demonstrated remarkable performance,\nthey often struggle on the inputs from domains beyond their training data.\nRecent attempts aim to expand the training set by relying on computationally\nexpensive and inherently challenging image-space augmentation of image\ngeneration modules. In an orthogonal direction, we present a simple yet\neffective method to expand the training data by interpolating between\ninstance-level feature statistics across labeled and unlabeled sets. Our\nmethod, dubbed Targeted Style Adversary (TSA), is motivated by two\nobservations: (i) the input domain is reflected in feature statistics, and (ii)\nface recognition model performance is influenced by style information. Shifting\ntowards an unlabeled style implicitly synthesizes challenging training\ninstances. We devise a recognizability metric to constraint our framework to\npreserve the inherent identity-related information of labeled instances. The\nefficacy of our method is demonstrated through evaluations on unconstrained\nbenchmarks, outperforming or being on par with its competitors while offering\nnearly a 70\\% improvement in training speed and 40\\% less memory consumption.",
      "tldr_zh": "该研究针对深度面部识别模型在处理训练数据以外输入时的性能挑战，提出了一种简单有效的 Targeted Style Adversary (TSA) 方法，通过在标记和未标记数据集之间插值实例级特征统计来扩展训练数据。TSA 基于特征统计反映输入域和风格信息影响模型性能的观察，利用向未标记风格转移合成挑战性训练实例，同时通过 recognizability metric 确保保留身份相关信息。实验结果显示，该方法在不受约束的面部识别基准测试中优于或相当竞争对手，同时实现了近70%的训练速度提升和40%的内存消耗减少。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.07642v1",
      "published_date": "2024-08-14 16:13:03 UTC",
      "updated_date": "2024-08-14 16:13:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:14:39.360688"
    },
    {
      "arxiv_id": "2408.08916v1",
      "title": "Cyclic Supports in Recursive Bipolar Argumentation Frameworks: Semantics and LP Mapping",
      "title_zh": "翻译失败",
      "authors": [
        "Gianvincenzo Alfano",
        "Sergio Greco",
        "Francesco Parisi",
        "Irina Trubitsyna"
      ],
      "abstract": "Dung's Abstract Argumentation Framework (AF) has emerged as a key formalism\nfor argumentation in Artificial Intelligence. It has been extended in several\ndirections, including the possibility to express supports, leading to the\ndevelopment of the Bipolar Argumentation Framework (BAF), and recursive attacks\nand supports, resulting in the Recursive BAF (Rec-BAF). Different\ninterpretations of supports have been proposed, whereas for Rec-BAF (where the\ntarget of attacks and supports may also be attacks and supports) even different\nsemantics for attacks have been defined. However, the semantics of these\nframeworks have either not been defined in the presence of support cycles, or\nare often quite intricate in terms of the involved definitions. We encompass\nthis limitation and present classical semantics for general BAF and Rec-BAF and\nshow that the semantics for specific BAF and Rec-BAF frameworks can be defined\nby very simple and intuitive modifications of that defined for the case of AF.\nThis is achieved by providing a modular definition of the sets of defeated and\nacceptable elements for each AF-based framework. We also characterize, in an\nelegant and uniform way, the semantics of general BAF and Rec-BAF in terms of\nlogic programming and partial stable model semantics.",
      "tldr_zh": "该论文探讨了Dung's Abstract Argumentation Framework (AF) 的扩展，包括Bipolar Argumentation Framework (BAF) 和Recursive BAF (Rec-BAF)，重点解决支持循环（cyclic supports）下的语义定义问题。作者提出了一种经典语义（classical semantics）框架，通过模块化的定义来处理失败和可接受元素，并展示了特定BAF和Rec-BAF的语义可以通过简单修改AF的定义实现。最终，该方法优雅地使用逻辑编程（logic programming）和部分稳定模型语义（partial stable model semantics）统一表征这些框架的语义。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Paper presented at the 40th International Conference on Logic\n  Programming (ICLP 2024), University of Texas at Dallas, USA, October 2024.\n  arXiv admin note: text overlap with arXiv:2008.02550",
      "pdf_url": "http://arxiv.org/pdf/2408.08916v1",
      "published_date": "2024-08-14 16:06:16 UTC",
      "updated_date": "2024-08-14 16:06:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:14:48.947094"
    },
    {
      "arxiv_id": "2408.07636v1",
      "title": "Drug Discovery SMILES-to-Pharmacokinetics Diffusion Models with Deep Molecular Understanding",
      "title_zh": "翻译失败",
      "authors": [
        "Bing Hu",
        "Anita Layton",
        "Helen Chen"
      ],
      "abstract": "Artificial intelligence (AI) is increasingly used in every stage of drug\ndevelopment. One challenge facing drug discovery AI is that drug\npharmacokinetic (PK) datasets are often collected independently from each\nother, often with limited overlap, creating data overlap sparsity. Data\nsparsity makes data curation difficult for researchers looking to answer\nresearch questions in poly-pharmacy, drug combination research, and\nhigh-throughput screening. We propose Imagand, a novel\nSMILES-to-Pharmacokinetic (S2PK) diffusion model capable of generating an array\nof PK target properties conditioned on SMILES inputs. We show that\nImagand-generated synthetic PK data closely resembles real data univariate and\nbivariate distributions, and improves performance for downstream tasks. Imagand\nis a promising solution for data overlap sparsity and allows researchers to\nefficiently generate ligand PK data for drug discovery research. Code is\navailable at \\url{https://github.com/bing1100/Imagand}.",
      "tldr_zh": "该论文针对药物发现中PK（Pharmacokinetics）数据集的稀疏性和缺乏重叠问题，提出了一种名为Imagand的SMILES-to-Pharmacokinetics (S2PK) 扩散模型，以实现深度分子理解。Imagand模型能够基于SMILES输入生成多种PK目标属性，并通过合成数据模拟真实数据的单变量和双变量分布，从而改善下游任务如多药治疗和高速筛选的性能。实验结果显示，该模型有效缓解了数据稀疏问题，为药物发现研究提供了高效的配体PK数据生成工具，代码已在GitHub上开源。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.QM",
      "comment": "13 pages, 5 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2408.07636v1",
      "published_date": "2024-08-14 16:01:02 UTC",
      "updated_date": "2024-08-14 16:01:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:15:01.530966"
    },
    {
      "arxiv_id": "2408.07629v1",
      "title": "Optimizing HIV Patient Engagement with Reinforcement Learning in Resource-Limited Settings",
      "title_zh": "翻译失败",
      "authors": [
        "África Periáñez",
        "Kathrin Schmitz",
        "Lazola Makhupula",
        "Moiz Hassan",
        "Moeti Moleko",
        "Ana Fernández del Río",
        "Ivan Nazarov",
        "Aditya Rastogi",
        "Dexian Tang"
      ],
      "abstract": "By providing evidence-based clinical decision support, digital tools and\nelectronic health records can revolutionize patient management, especially in\nresource-poor settings where fewer health workers are available and often need\nmore training. When these tools are integrated with AI, they can offer\npersonalized support and adaptive interventions, effectively connecting\ncommunity health workers (CHWs) and healthcare facilities. The CHARM (Community\nHealth Access & Resource Management) app is an AI-native mobile app for CHWs.\nDeveloped through a joint partnership of Causal Foundry (CF) and\nmothers2mothers (m2m), CHARM empowers CHWs, mainly local women, by streamlining\ncase management, enhancing learning, and improving communication. This paper\ndetails CHARM's development, integration, and upcoming reinforcement\nlearning-based adaptive interventions, all aimed at enhancing health worker\nengagement, efficiency, and patient outcomes, thereby enhancing CHWs'\ncapabilities and community health.",
      "tldr_zh": "该研究旨在通过数字工具和AI优化资源有限环境下的HIV患者参与，特别是针对社区卫生工作者(CHWs)。他们开发了CHARM app，这是一个AI-native mobile app，结合强化学习(Reinforcement Learning)提供个性化支持和自适应干预，以提升CHWs的案例管理、学习和通信效率。论文详细阐述了CHARM的开发、整合过程及其预期效果，包括提高健康工作者参与度、效率和患者结果，从而加强社区健康管理。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "Presented at the 7th epiDAMIK ACM SIGKDD International Workshop on\n  Epidemiology meets Data Mining and Knowledge Discovery, August 26, 2024,\n  Barcelona, Spain",
      "pdf_url": "http://arxiv.org/pdf/2408.07629v1",
      "published_date": "2024-08-14 15:55:31 UTC",
      "updated_date": "2024-08-14 15:55:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:15:23.420462"
    },
    {
      "arxiv_id": "2408.10261v1",
      "title": "Relational Graph Convolutional Networks Do Not Learn Sound Rules",
      "title_zh": "翻译失败",
      "authors": [
        "Matthew Morris",
        "David J. Tena Cucala",
        "Bernardo Cuenca Grau",
        "Ian Horrocks"
      ],
      "abstract": "Graph neural networks (GNNs) are frequently used to predict missing facts in\nknowledge graphs (KGs). Motivated by the lack of explainability for the outputs\nof these models, recent work has aimed to explain their predictions using\nDatalog, a widely used logic-based formalism. However, such work has been\nrestricted to certain subclasses of GNNs. In this paper, we consider one of the\nmost popular GNN architectures for KGs, R-GCN, and we provide two methods to\nextract rules that explain its predictions and are sound, in the sense that\neach fact derived by the rules is also predicted by the GNN, for any input\ndataset. Furthermore, we provide a method that can verify that certain classes\nof Datalog rules are not sound for the R-GCN. In our experiments, we train\nR-GCNs on KG completion benchmarks, and we are able to verify that no Datalog\nrule is sound for these models, even though the models often obtain high to\nnear-perfect accuracy. This raises some concerns about the ability of R-GCN\nmodels to generalise and about the explainability of their predictions. We\nfurther provide two variations to the training paradigm of R-GCN that encourage\nit to learn sound rules and find a trade-off between model accuracy and the\nnumber of learned sound rules.",
      "tldr_zh": "该研究发现，Relational Graph Convolutional Networks (R-GCN) 在知识图谱 (KGs) 的事实预测中无法学习 sound 规则，尽管模型准确率通常很高。论文提出两种方法来提取解释 R-GCN 预测的 Datalog 规则，这些规则确保每个由规则导出的事实也由 GNN 预测。作者还开发了一个方法来验证某些 Datalog 规则类是否对 R-GCN 不 sound。实验结果显示，在 KG 完成基准上训练的 R-GCN 模型没有 sound 规则，这引发了对模型泛化能力和预测可解释性的担忧；同时，论文探索了两种训练变体，以在模型准确性和 sound 规则数量之间实现平衡。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.LO",
        "03B70",
        "I.2.6; G.2.2; I.2.4; I.2.3"
      ],
      "primary_category": "cs.LG",
      "comment": "Full version (with appendices) of paper accepted to KR 2024 (21st\n  International Conference on Principles of Knowledge Representation and\n  Reasoning)",
      "pdf_url": "http://arxiv.org/pdf/2408.10261v1",
      "published_date": "2024-08-14 15:46:42 UTC",
      "updated_date": "2024-08-14 15:46:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:15:26.110617"
    },
    {
      "arxiv_id": "2408.07624v1",
      "title": "Battery GraphNets : Relational Learning for Lithium-ion Batteries(LiBs) Life Estimation",
      "title_zh": "翻译失败",
      "authors": [
        "Sakhinana Sagar Srinivas",
        "Rajat Kumar Sarkar",
        "Venkataramana Runkana"
      ],
      "abstract": "Battery life estimation is critical for optimizing battery performance and\nguaranteeing minimal degradation for better efficiency and reliability of\nbattery-powered systems. The existing methods to predict the Remaining Useful\nLife(RUL) of Lithium-ion Batteries (LiBs) neglect the relational dependencies\nof the battery parameters to model the nonlinear degradation trajectories. We\npresent the Battery GraphNets framework that jointly learns to incorporate a\ndiscrete dependency graph structure between battery parameters to capture the\ncomplex interactions and the graph-learning algorithm to model the intrinsic\nbattery degradation for RUL prognosis. The proposed method outperforms several\npopular methods by a significant margin on publicly available battery datasets\nand achieves SOTA performance. We report the ablation studies to support the\nefficacy of our approach.",
      "tldr_zh": "这篇论文提出了 Battery GraphNets 框架，用于锂离子电池 (LiBs) 的剩余可用寿命 (RUL) 估计，以优化电池性能并减少退化。框架通过学习电池参数之间的离散依赖图结构和图学习算法，捕捉复杂交互并建模非线性退化轨迹，从而解决了现有方法忽略关系依赖性的问题。在公开数据集上，该方法显著优于流行基准，达到了 SOTA 性能，并通过消融研究证实了其有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted in Workshop on Graph Learning for Industrial Applications :\n  Finance, Crime Detection, Medicine, and Social Media (NeurIPS 2022)",
      "pdf_url": "http://arxiv.org/pdf/2408.07624v1",
      "published_date": "2024-08-14 15:44:56 UTC",
      "updated_date": "2024-08-14 15:44:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:15:37.458249"
    },
    {
      "arxiv_id": "2408.08915v1",
      "title": "A Survey on Blockchain-based Supply Chain Finance with Progress and Future directions",
      "title_zh": "基于区块链的供应链金融调查：进展和未来方向",
      "authors": [
        "Zhengdong Luo"
      ],
      "abstract": "Supply Chain Finance is very important for supply chain competition, which is\nan important tool to activate the capital flow in the supply chain. Supply\nChain Finance-related research can support multiple applications and services,\nsuch as providing accounts receivable financing, enhancing risk management, and\noptimizing supply chain management. For more than a decade, the development of\nBlockchain has attracted widely attention in various fields, especially in\nfinance. With the characteristics of data tamper-proof, forgery-proof,\ncryptography, consensus verification, and decentralization, Blockchain fits\nwell with the realistic needs of Supply Chain Finance, which requires data\nintegrity, authenticity, privacy, and information sharing. Therefore, it is\ntime to summarize the applications of Blockchain technology in the field of\nSupply Chain Finance. What Blockchain technology brings to Supply Chain Finance\nis not only to alleviate the problems of information asymmetry, credit\ndisassembly, and financing cost, but also to improve Supply Chain Finance\noperations through smart contracts to intelligent Supply Chain Finance and in\ncombination with other technologies, such as artificial intelligence, cloud\ncomputing, and data mining, jointly. So there has been some work in\nBlockchain-based Supply Chain Finance research for different Supply Chain\nFinance oriented applications, but most of these work are at the management\nlevel to propose conceptual frameworks or simply use Blockchain without\nexploiting its deep applications. Moreover, there are few systematic reviews\nproviding a comprehensive summary of current work in the area of\nBlockchain-based Supply Chain Finance. In this paper, we ...",
      "tldr_zh": "这篇论文对基于Blockchain的Supply Chain Finance进行了系统综述，强调了Blockchain的技术特性（如数据防篡改、加密和去中心化）如何满足供应链金融的需求，包括缓解信息不对称、信用问题和融资成本。论文分析了现有研究，发现大多数工作仅停留在管理层面，提出概念框架或简单应用Blockchain，而未深入探索其潜力，如通过smart contracts优化操作。未来方向包括将Blockchain与其他技术（如artificial intelligence、cloud computing和data mining）结合，推动智能Supply Chain Finance的发展。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.08915v1",
      "published_date": "2024-08-14 15:08:51 UTC",
      "updated_date": "2024-08-14 15:08:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:15:49.598156"
    },
    {
      "arxiv_id": "2408.07583v2",
      "title": "Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey",
      "title_zh": "Transformers 与大型语言模型用于高效入侵检测系统：一项全面综述",
      "authors": [
        "Hamza Kheddar"
      ],
      "abstract": "With significant advancements in Transformers LLMs, NLP has extended its\nreach into many research fields due to its enhanced capabilities in text\ngeneration and user interaction. One field benefiting greatly from these\nadvancements is cybersecurity. In cybersecurity, many parameters that need to\nbe protected and exchanged between senders and receivers are in the form of\ntext and tabular data, making NLP a valuable tool in enhancing the security\nmeasures of communication protocols. This survey paper provides a comprehensive\nanalysis of the utilization of Transformers and LLMs in cyber-threat detection\nsystems. The methodology of paper selection and bibliometric analysis is\noutlined to establish a rigorous framework for evaluating existing research.\nThe fundamentals of Transformers are discussed, including background\ninformation on various cyber-attacks and datasets commonly used in this field.\nThe survey explores the application of Transformers in IDSs, focusing on\ndifferent architectures such as Attention-based models, LLMs like BERT and GPT,\nCNN/LSTM-Transformer hybrids, emerging approaches like ViTs, among others.\nFurthermore, it explores the diverse environments and applications where\nTransformers and LLMs-based IDS have been implemented, including computer\nnetworks, IoT devices, critical infrastructure protection, cloud computing,\nSDN, as well as in autonomous vehicles. The paper also addresses research\nchallenges and future directions in this area, identifying key issues such as\ninterpretability, scalability, and adaptability to evolving threats, and more.\nFinally, the conclusion summarizes the findings and highlights the significance\nof Transformers and LLMs in enhancing cyber-threat detection capabilities,\nwhile also outlining potential avenues for further research and development.",
      "tldr_zh": "这篇调查论文全面分析了Transformers和Large Language Models (LLMs) 在入侵检测系统(IDS)中的应用，探讨了这些模型如何提升网络威胁检测的效率。论文通过文献选择和文献计量分析方法，审视了Transformers的基础知识、常见网络攻击数据集，以及各种架构如Attention-based 模型、BERT、GPT、CNN/LSTM-Transformer 混合体和ViTs 等在IDS中的作用。研究发现，这些模型已在计算机网络、IoT 设备、云计算和自主车辆等环境中广泛应用，但面临挑战包括可解释性、可伸缩性和对动态威胁的适应性；论文总结了其在提升网络安全方面的显著价值，并指出了未来研究方向如改进模型鲁棒性和集成更多场景。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "eess.AS"
      ],
      "primary_category": "cs.CR",
      "comment": "arXiv admin note: text overlap with arXiv:2405.04760 by other authors",
      "pdf_url": "http://arxiv.org/pdf/2408.07583v2",
      "published_date": "2024-08-14 14:28:11 UTC",
      "updated_date": "2025-01-14 10:52:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:16:10.928080"
    },
    {
      "arxiv_id": "2408.07726v2",
      "title": "Development of a graph neural network surrogate for travel demand modelling",
      "title_zh": "翻译失败",
      "authors": [
        "Nikita Makarov",
        "Santhanakrishnan Narayanan",
        "Constantinos Antoniou"
      ],
      "abstract": "As urban environments grow, the modelling of transportation systems becomes\nincreasingly complex. This paper advances the field of travel demand modelling\nby introducing advanced Graph Neural Network (GNN) architectures as surrogate\nmodels, addressing key limitations of previous approaches. Building on prior\nwork with Graph Convolutional Networks (GCNs), we introduce GATv3, a new Graph\nAttention Network (GAT) variant that mitigates over-smoothing through residual\nconnections, enabling deeper and more expressive architectures. Additionally,\nwe propose a fine-grained classification framework that improves predictive\nstability while achieving numerical precision comparable to regression,\noffering a more interpretable and efficient alternative. To enhance model\nperformance, we develop a synthetic data generation strategy, which expands the\naugmented training dataset without overfitting. Our experiments demonstrate\nthat GATv3 significantly improves classification performance, while the GCN\nmodel shows unexpected dominance in fine-grained classification when\nsupplemented with additional training data. The results highlight the\nadvantages of fine-grained classification over regression for travel demand\nmodelling tasks and reveal new challenges in extending GAT-based architectures\nto complex transport scenarios. Notably, GATv3 appears well-suited for\nclassification-based transportation applications, such as section control and\ncongestion warning systems, which require a higher degree of differentiation\namong neighboring links. These findings contribute to refining GNN-based\nsurrogates, offering new possibilities for applying GATv3 and fine-grained\nclassification in broader transportation challenges.",
      "tldr_zh": "本研究开发了基于图神经网络 (Graph Neural Network, GNN) 的代理模型，用于改进城市交通系统的旅行需求建模，解决了传统方法的局限性。研究引入了 GATv3（Graph Attention Network 的新变体），通过残差连接缓解过平滑问题，实现更深层和更具表现力的架构，并提出细粒度分类框架，以提升预测稳定性和可解释性，同时开发合成数据生成策略来扩展训练数据集并避免过拟合。实验结果显示，GATv3 显著提高了分类性能，而 Graph Convolutional Networks (GCNs) 在添加额外数据后在细粒度分类中表现出意外优势；整体而言，细粒度分类比回归方法更适合旅行需求任务，并为交通应用如路段控制和拥堵预警系统提供了新可能性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.07726v2",
      "published_date": "2024-08-14 14:18:47 UTC",
      "updated_date": "2025-03-20 10:47:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:16:14.545701"
    },
    {
      "arxiv_id": "2408.07576v2",
      "title": "MetaSeg: MetaFormer-based Global Contexts-aware Network for Efficient Semantic Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Beoungwoo Kang",
        "Seunghun Moon",
        "Yubin Cho",
        "Hyunwoo Yu",
        "Suk-Ju Kang"
      ],
      "abstract": "Beyond the Transformer, it is important to explore how to exploit the\ncapacity of the MetaFormer, an architecture that is fundamental to the\nperformance improvements of the Transformer. Previous studies have exploited it\nonly for the backbone network. Unlike previous studies, we explore the capacity\nof the Metaformer architecture more extensively in the semantic segmentation\ntask. We propose a powerful semantic segmentation network, MetaSeg, which\nleverages the Metaformer architecture from the backbone to the decoder. Our\nMetaSeg shows that the MetaFormer architecture plays a significant role in\ncapturing the useful contexts for the decoder as well as for the backbone. In\naddition, recent segmentation methods have shown that using a CNN-based\nbackbone for extracting the spatial information and a decoder for extracting\nthe global information is more effective than using a transformer-based\nbackbone with a CNN-based decoder. This motivates us to adopt the CNN-based\nbackbone using the MetaFormer block and design our MetaFormer-based decoder,\nwhich consists of a novel self-attention module to capture the global contexts.\nTo consider both the global contexts extraction and the computational\nefficiency of the self-attention for semantic segmentation, we propose a\nChannel Reduction Attention (CRA) module that reduces the channel dimension of\nthe query and key into the one dimension. In this way, our proposed MetaSeg\noutperforms the previous state-of-the-art methods with more efficient\ncomputational costs on popular semantic segmentation and a medical image\nsegmentation benchmark, including ADE20K, Cityscapes, COCO-stuff, and Synapse.\nThe code is available at https://github.com/hyunwoo137/MetaSeg.",
      "tldr_zh": "该研究探索了 MetaFormer 架构在语义分割任务中的潜力，提出了一种高效网络 MetaSeg，将 MetaFormer 应用于 backbone 和 decoder，以更好地捕获全局上下文。MetaSeg 采用 CNN-based backbone 提取空间信息，并设计了基于 MetaFormer 的 decoder，包括一个新颖的 Channel Reduction Attention (CRA) 模块，该模块通过减少 query 和 key 的通道维度，提升了计算效率和全局上下文提取能力。与现有最先进方法相比，MetaSeg 在 ADE20K、Cityscapes、COCO-stuff 和 Synapse 等基准上实现了更高的分割性能，同时降低了计算成本。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by WACV 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.07576v2",
      "published_date": "2024-08-14 14:16:52 UTC",
      "updated_date": "2024-08-15 03:55:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:16:28.282881"
    },
    {
      "arxiv_id": "2408.07575v1",
      "title": "A General Framework for Constraint-based Causal Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Kai Z. Teh",
        "Kayvan Sadeghi",
        "Terry Soo"
      ],
      "abstract": "By representing any constraint-based causal learning algorithm via a\nplaceholder property, we decompose the correctness condition into a part\nrelating the distribution and the true causal graph, and a part that depends\nsolely on the distribution. This provides a general framework to obtain\ncorrectness conditions for causal learning, and has the following implications.\nWe provide exact correctness conditions for the PC algorithm, which are then\nrelated to correctness conditions of some other existing causal discovery\nalgorithms. We show that the sparsest Markov representation condition is the\nweakest correctness condition resulting from existing notions of minimality for\nmaximal ancestral graphs and directed acyclic graphs. We also reason that\nadditional knowledge than just Pearl-minimality is necessary for causal\nlearning beyond faithfulness.",
      "tldr_zh": "本论文提出一个通用框架，通过占位符属性表示基于约束的因果学习算法，将正确性条件分解为与分布和真实因果图相关的部分，以及仅依赖于分布的部分，从而为因果学习提供精确的正确性条件。研究者为 PC algorithm 提供了确切的正确性条件，并将其与现有因果发现算法的条件相关联。同时，他们证明 sparsest Markov representation 条件是现有最小性概念下最弱的正确性条件。论文还论证，在超越 faithfulness 的因果学习中，仅靠 Pearl-minimality 的知识是不够的，需要额外的知识支持。",
      "categories": [
        "cs.AI",
        "math.ST",
        "stat.ME",
        "stat.TH"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.07575v1",
      "published_date": "2024-08-14 14:16:02 UTC",
      "updated_date": "2024-08-14 14:16:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:16:40.403983"
    },
    {
      "arxiv_id": "2408.07569v1",
      "title": "Multi-task Heterogeneous Graph Learning on Electronic Health Records",
      "title_zh": "多任务异构图学习在电子健康记录上的应用",
      "authors": [
        "Tsai Hor Chan",
        "Guosheng Yin",
        "Kyongtae Bae",
        "Lequan Yu"
      ],
      "abstract": "Learning electronic health records (EHRs) has received emerging attention\nbecause of its capability to facilitate accurate medical diagnosis. Since the\nEHRs contain enriched information specifying complex interactions between\nentities, modeling EHRs with graphs is shown to be effective in practice. The\nEHRs, however, present a great degree of heterogeneity, sparsity, and\ncomplexity, which hamper the performance of most of the models applied to them.\nMoreover, existing approaches modeling EHRs often focus on learning the\nrepresentations for a single task, overlooking the multi-task nature of EHR\nanalysis problems and resulting in limited generalizability across different\ntasks. In view of these limitations, we propose a novel framework for EHR\nmodeling, namely MulT-EHR (Multi-Task EHR), which leverages a heterogeneous\ngraph to mine the complex relations and model the heterogeneity in the EHRs. To\nmitigate the large degree of noise, we introduce a denoising module based on\nthe causal inference framework to adjust for severe confounding effects and\nreduce noise in the EHR data. Additionally, since our model adopts a single\ngraph neural network for simultaneous multi-task prediction, we design a\nmulti-task learning module to leverage the inter-task knowledge to regularize\nthe training process. Extensive empirical studies on MIMIC-III and MIMIC-IV\ndatasets validate that the proposed method consistently outperforms the\nstate-of-the-art designs in four popular EHR analysis tasks -- drug\nrecommendation, and predictions of the length of stay, mortality, and\nreadmission. Thorough ablation studies demonstrate the robustness of our method\nupon variations to key components and hyperparameters.",
      "tldr_zh": "这篇论文针对电子健康记录(EHRs)的异质性、稀疏性和复杂性，提出了一种新型多任务学习框架MulT-EHR，利用heterogeneous graph来挖掘EHRs中的复杂关系。框架中引入基于causal inference的去噪模块，以减少噪声和混杂效应，并设计multi-task learning模块来利用任务间知识优化训练过程。实验结果显示，在MIMIC-III和MIMIC-IV数据集上，MulT-EHR在药物推荐、住院时间预测、死亡率预测和再入院预测等四个任务中，显著优于现有方法，并通过消融实验证明了其鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by Neural Networks",
      "pdf_url": "http://arxiv.org/pdf/2408.07569v1",
      "published_date": "2024-08-14 14:06:13 UTC",
      "updated_date": "2024-08-14 14:06:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:16:52.435723"
    },
    {
      "arxiv_id": "2408.07547v1",
      "title": "PeriodWave: Multi-Period Flow Matching for High-Fidelity Waveform Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Sang-Hoon Lee",
        "Ha-Yeong Choi",
        "Seong-Whan Lee"
      ],
      "abstract": "Recently, universal waveform generation tasks have been investigated\nconditioned on various out-of-distribution scenarios. Although GAN-based\nmethods have shown their strength in fast waveform generation, they are\nvulnerable to train-inference mismatch scenarios such as two-stage\ntext-to-speech. Meanwhile, diffusion-based models have shown their powerful\ngenerative performance in other domains; however, they stay out of the\nlimelight due to slow inference speed in waveform generation tasks. Above all,\nthere is no generator architecture that can explicitly disentangle the natural\nperiodic features of high-resolution waveform signals. In this paper, we\npropose PeriodWave, a novel universal waveform generation model. First, we\nintroduce a period-aware flow matching estimator that can capture the periodic\nfeatures of the waveform signal when estimating the vector fields.\nAdditionally, we utilize a multi-period estimator that avoids overlaps to\ncapture different periodic features of waveform signals. Although increasing\nthe number of periods can improve the performance significantly, this requires\nmore computational costs. To reduce this issue, we also propose a single\nperiod-conditional universal estimator that can feed-forward parallel by\nperiod-wise batch inference. Additionally, we utilize discrete wavelet\ntransform to losslessly disentangle the frequency information of waveform\nsignals for high-frequency modeling, and introduce FreeU to reduce the\nhigh-frequency noise for waveform generation. The experimental results\ndemonstrated that our model outperforms the previous models both in\nMel-spectrogram reconstruction and text-to-speech tasks. All source code will\nbe available at \\url{https://github.com/sh-lee-prml/PeriodWave}.",
      "tldr_zh": "这篇论文提出了 PeriodWave，一种新型的通用波形生成模型，旨在解决 GAN-based 方法的训练推断不匹配问题和 diffusion-based 方法的推理速度慢等问题，同时显式捕捉波形信号的周期特征。PeriodWave 引入了 period-aware flow matching estimator 和 multi-period estimator 来处理不同周期特征，避免重叠，并通过 single period-conditional universal estimator 实现高效的并行推断；此外，利用 discrete wavelet transform 分离频率信息和 FreeU 减少高频噪声，以提升生成 fidelity。实验结果表明，PeriodWave 在 Mel-spectrogram 重建和 text-to-speech 任务中优于现有模型，展示了其在高保真波形生成中的显著优势。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG",
        "eess.AS",
        "eess.SP"
      ],
      "primary_category": "cs.SD",
      "comment": "24 pages, 16 tables, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.07547v1",
      "published_date": "2024-08-14 13:36:17 UTC",
      "updated_date": "2024-08-14 13:36:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:17:05.841581"
    },
    {
      "arxiv_id": "2408.07545v1",
      "title": "$χ$SPN: Characteristic Interventional Sum-Product Networks for Causal Inference in Hybrid Domains",
      "title_zh": "翻译失败",
      "authors": [
        "Harsh Poonia",
        "Moritz Willig",
        "Zhongjie Yu",
        "Matej Zečević",
        "Kristian Kersting",
        "Devendra Singh Dhami"
      ],
      "abstract": "Causal inference in hybrid domains, characterized by a mixture of discrete\nand continuous variables, presents a formidable challenge. We take a step\ntowards this direction and propose Characteristic Interventional Sum-Product\nNetwork ($\\chi$SPN) that is capable of estimating interventional distributions\nin presence of random variables drawn from mixed distributions. $\\chi$SPN uses\ncharacteristic functions in the leaves of an interventional SPN (iSPN) thereby\nproviding a unified view for discrete and continuous random variables through\nthe Fourier-Stieltjes transform of the probability measures. A neural network\nis used to estimate the parameters of the learned iSPN using the intervened\ndata. Our experiments on 3 synthetic heterogeneous datasets suggest that\n$\\chi$SPN can effectively capture the interventional distributions for both\ndiscrete and continuous variables while being expressive and causally adequate.\nWe also show that $\\chi$SPN generalize to multiple interventions while being\ntrained only on a single intervention data.",
      "tldr_zh": "该论文针对混合域（包含离散和连续变量）的因果推理挑战，提出了一种名为 $χ$SPN 的模型，即 Characteristic Interventional Sum-Product Networks，用于估计干预分布。$χ$SPN 在 interventional SPN (iSPN) 的叶节点使用 characteristic functions，并通过 Fourier-Stieltjes 变换统一处理离散和连续随机变量，同时利用神经网络基于干预数据估计参数。实验结果显示，在 3 个合成异构数据集上，$χ$SPN 能够有效捕获干预分布，并表现出色地泛化到多个干预场景，而仅需单次干预训练。总的来说，该方法提升了混合域因果推理的表达性和因果充分性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "17 pages, 11 figures. Accepted as poster at UAI (Uncertainty in\n  Artificial Intelligence) 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.07545v1",
      "published_date": "2024-08-14 13:31:32 UTC",
      "updated_date": "2024-08-14 13:31:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:17:15.935092"
    },
    {
      "arxiv_id": "2408.07544v1",
      "title": "Planning with OWL-DL Ontologies (Extended Version)",
      "title_zh": "翻译失败",
      "authors": [
        "Tobias John",
        "Patrick Koopmann"
      ],
      "abstract": "We introduce ontology-mediated planning, in which planning problems are\ncombined with an ontology. Our formalism differs from existing ones in that we\nfocus on a strong separation of the formalisms for describing planning problems\nand ontologies, which are only losely coupled by an interface. Moreover, we\npresent a black-box algorithm that supports the full expressive power of OWL\nDL. This goes beyond what existing approaches combining automated planning with\nontologies can do, which only support limited description logics such as\nDL-Lite and description logics that are Horn. Our main algorithm relies on\nrewritings of the ontology-mediated planning specifications into PDDL, so that\nexisting planning systems can be used to solve them. The algorithm relies on\njustifications, which allows for a generic approach that is independent of the\nexpressivity of the ontology language. However, dedicated optimizations for\ncomputing justifications need to be implemented to enable an efficient\nrewriting procedure. We evaluated our implementation on benchmark sets from\nseveral domains. The evaluation shows that our procedure works in practice and\nthat tailoring the reasoning procedure has significant impact on the\nperformance.",
      "tldr_zh": "本研究引入了ontology-mediated planning形式主义，将规划问题与OWL DL本体结合，强调了二者之间的松散耦合和形式主义分离，从而支持OWL DL的完整表达能力，超越了现有仅限于DL-Lite或Horn描述逻辑的方法。研究提出了一种基于justifications的黑箱算法，将本体中介规划规范重写为PDDL，以便利用现有规划系统进行求解，同时通过优化justifications计算来提升效率。实验评估显示，该方法在多个领域的基准集上表现出色，证明了其实用性和针对推理过程的优化对性能的显著影响。",
      "categories": [
        "cs.AI",
        "I.2.4"
      ],
      "primary_category": "cs.AI",
      "comment": "Extended version of a paper accepted at ECAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.07544v1",
      "published_date": "2024-08-14 13:27:02 UTC",
      "updated_date": "2024-08-14 13:27:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:17:27.237187"
    },
    {
      "arxiv_id": "2408.07542v1",
      "title": "New Curriculum, New Chance -- Retrieval Augmented Generation for Lesson Planning in Ugandan Secondary Schools. Prototype Quality Evaluation",
      "title_zh": "翻译失败",
      "authors": [
        "Simon Kloker",
        "Herbertson Bukoli",
        "Twaha Kateete"
      ],
      "abstract": "Introduction: Poor educational quality in Secondary Schools is still regarded\nas one of the major struggles in 21st century Uganda - especially in rural\nareas. Research identifies several problems, including low quality or absent\nteacher lesson planning. As the government pushes towards the implementation of\na new curriculum, exiting lesson plans become obsolete and the problem is\nworsened. Using a Retrieval Augmented Generation approach, we developed a\nprototype that generates customized lesson plans based on the\ngovernment-accredited textbooks. This helps teachers create lesson plans more\nefficiently and with better quality, ensuring they are fully aligned the new\ncurriculum and the competence-based learning approach.\n  Methods: The prototype was created using Cohere LLM and Sentence Embeddings,\nand LangChain Framework - and thereafter made available on a public website.\nVector stores were trained for three new curriculum textbooks (ICT,\nMathematics, History), all at Secondary 1 Level. Twenty-four lessons plans were\ngenerated following a pseudo-random generation protocol, based on the suggested\nperiods in the textbooks. The lesson plans were analyzed regarding their\ntechnical quality by three independent raters following the Lesson Plan\nAnalysis Protocol (LPAP) by Ndihokubwayo et al. (2022) that is specifically\ndesigned for East Africa and competence-based curriculums.\n  Results: Evaluation of 24 lesson plans using the LPAP resulted in an average\nquality of between 75 and 80%, corresponding to \"very good lesson plan\". None\nof the lesson plans scored below 65%, although one lesson plan could be argued\nto have been missing the topic. In conclusion, the quality of the generated\nlesson plans is at least comparable, if not better, than those created by\nhumans, as demonstrated in a study in Rwanda, whereby no lesson plan even\nreached the benchmark of 50%.",
      "tldr_zh": "本研究针对乌干达农村中学教育质量低下问题，特别是教师课程规划不足，开发了一个基于 Retrieval Augmented Generation (RAG) 的原型系统，以生成符合新课程和能力导向学习方法的个性化课程计划。系统利用 Cohere LLM、Sentence Embeddings 和 LangChain 框架，对三个新课程教科书（ICT、Mathematics、History）的向量存储进行训练，并生成了24个课程计划。评估结果显示，这些计划的平均质量为75-80%，被评为“非常好”，且无计划低于65%，其质量比人类创建的计划更优，为提升教学效率提供了可靠工具。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "Presented at Ndejje University Second Annual Research Dissemination\n  Symposium 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.07542v1",
      "published_date": "2024-08-14 13:22:14 UTC",
      "updated_date": "2024-08-14 13:22:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:17:40.861230"
    },
    {
      "arxiv_id": "2408.07541v1",
      "title": "DifuzCam: Replacing Camera Lens with a Mask and a Diffusion Model",
      "title_zh": "翻译失败",
      "authors": [
        "Erez Yosef",
        "Raja Giryes"
      ],
      "abstract": "The flat lensless camera design reduces the camera size and weight\nsignificantly. In this design, the camera lens is replaced by another optical\nelement that interferes with the incoming light. The image is recovered from\nthe raw sensor measurements using a reconstruction algorithm. Yet, the quality\nof the reconstructed images is not satisfactory. To mitigate this, we propose\nutilizing a pre-trained diffusion model with a control network and a learned\nseparable transformation for reconstruction. This allows us to build a\nprototype flat camera with high-quality imaging, presenting state-of-the-art\nresults in both terms of quality and perceptuality. We demonstrate its ability\nto leverage also textual descriptions of the captured scene to further enhance\nreconstruction. Our reconstruction method which leverages the strong\ncapabilities of a pre-trained diffusion model can be used in other imaging\nsystems for improved reconstruction results.",
      "tldr_zh": "本研究提出DifuzCam，一种创新的平坦无镜头相机设计，通过用一个mask替换传统镜头，并结合预训练的diffusion model、控制网络和可学习的分离变换来重建图像，从而显著减少相机的大小和重量。相比传统方法，该框架解决了图像重建质量不佳的问题，实现state-of-the-art的图像质量和感知性表现。实验还展示了DifuzCam能利用场景的文本描述进一步增强重建效果，并可扩展应用于其他成像系统以改善整体性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.07541v1",
      "published_date": "2024-08-14 13:20:52 UTC",
      "updated_date": "2024-08-14 13:20:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:17:51.807822"
    },
    {
      "arxiv_id": "2408.07539v1",
      "title": "Cross-aware Early Fusion with Stage-divided Vision and Language Transformer Encoders for Referring Image Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Yubin Cho",
        "Hyunwoo Yu",
        "Suk-ju Kang"
      ],
      "abstract": "Referring segmentation aims to segment a target object related to a natural\nlanguage expression. Key challenges of this task are understanding the meaning\nof complex and ambiguous language expressions and determining the relevant\nregions in the image with multiple objects by referring to the expression.\nRecent models have focused on the early fusion with the language features at\nthe intermediate stage of the vision encoder, but these approaches have a\nlimitation that the language features cannot refer to the visual information.\nTo address this issue, this paper proposes a novel architecture, Cross-aware\nearly fusion with stage-divided Vision and Language Transformer encoders\n(CrossVLT), which allows both language and vision encoders to perform the early\nfusion for improving the ability of the cross-modal context modeling. Unlike\nprevious methods, our method enables the vision and language features to refer\nto each other's information at each stage to mutually enhance the robustness of\nboth encoders. Furthermore, unlike the conventional scheme that relies solely\non the high-level features for the cross-modal alignment, we introduce a\nfeature-based alignment scheme that enables the low-level to high-level\nfeatures of the vision and language encoders to engage in the cross-modal\nalignment. By aligning the intermediate cross-modal features in all encoder\nstages, this scheme leads to effective cross-modal fusion. In this way, the\nproposed approach is simple but effective for referring image segmentation, and\nit outperforms the previous state-of-the-art methods on three public\nbenchmarks.",
      "tldr_zh": "本研究针对 Referring Image Segmentation 任务，提出了一种新型架构 CrossVLT，以解决理解复杂语言表达和定位图像相关区域的挑战。CrossVLT 通过阶段划分的 Vision and Language Transformer Encoders 实现早融合，允许视觉和语言特征在每个阶段相互引用信息，从而增强跨模态上下文建模的鲁棒性。该方法引入特征-based alignment 方案，使视觉和语言编码器的低级到高级特征参与跨模态对齐，实现有效的融合。最后，CrossVLT 在三个公共基准上超过了现有最先进方法，展示了其简单而高效的性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Published in IEEE Transactions on Multimedia (TMM)",
      "pdf_url": "http://arxiv.org/pdf/2408.07539v1",
      "published_date": "2024-08-14 13:17:41 UTC",
      "updated_date": "2024-08-14 13:17:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:18:06.108923"
    },
    {
      "arxiv_id": "2408.07531v2",
      "title": "Development of a Large Language Model-based Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments",
      "title_zh": "翻译失败",
      "authors": [
        "Seungjun Han",
        "Wongyung Choi"
      ],
      "abstract": "Emergency department (ED) overcrowding and the complexity of rapid\ndecision-making in critical care settings pose significant challenges to\nhealthcare systems worldwide. While clinical decision support systems (CDSS)\nhave shown promise, the integration of large language models (LLMs) offers new\npossibilities for enhancing triage accuracy and clinical decision-making. This\nstudy presents an LLM-driven CDSS designed to assist ED physicians and nurses\nin patient triage, treatment planning, and overall emergency care management.\n  We developed a multi-agent CDSS utilizing Llama-3-70b as the base LLM,\norchestrated by CrewAI and Langchain. The system comprises four AI agents\nemulating key ED roles: Triage Nurse, Emergency Physician, Pharmacist, and ED\nCoordinator. It incorporates the Korean Triage and Acuity Scale (KTAS) for\ntriage assessment and integrates with the RxNorm API for medication management.\n  The model was evaluated using the Asclepius dataset, with performance\nassessed by a clinical emergency medicine specialist. The CDSS demonstrated\nhigh accuracy in triage decision-making compared to the baseline of a\nsingle-agent system. Furthermore, the system exhibited strong performance in\ncritical areas, including primary diagnosis, critical findings identification,\ndisposition decision-making, treatment planning, and resource allocation.\n  Our multi-agent CDSS demonstrates significant potential for supporting\ncomprehensive emergency care management. By leveraging state-of-the-art AI\ntechnologies, this system offers a scalable and adaptable tool that could\nenhance emergency medical care delivery, potentially alleviating ED\novercrowding and improving patient outcomes. This work contributes to the\ngrowing field of AI applications in emergency medicine and offers a promising\ndirection for future research and clinical implementation.",
      "tldr_zh": "本研究开发了一个基于 Large Language Models (LLMs) 的多智能体 Clinical Decision Support System (CDSS)，旨在辅助急诊部门 (ED) 进行 Korean Triage and Acuity Scale (KTAS) 分流、治疗规划和整体护理管理。系统以 Llama-3-70b 为基础模型，通过 CrewAI 和 Langchain 编排四个 AI 代理（Triage Nurse、Emergency Physician、Pharmacist 和 ED Coordinator），并整合 RxNorm API 以提升决策准确性。评估结果显示，该系统在使用 Asclepius 数据集时，在诊断、关键发现识别、处置决策和资源分配等方面比单智能体系统准确性更高，有望缓解 ED 拥挤并改善患者结果。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.07531v2",
      "published_date": "2024-08-14 13:03:41 UTC",
      "updated_date": "2024-08-27 15:16:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:18:18.542171"
    },
    {
      "arxiv_id": "2408.07527v2",
      "title": "Evidential Graph Contrastive Alignment for Source-Free Blending-Target Domain Adaptation",
      "title_zh": "翻译失败",
      "authors": [
        "Juepeng Zheng",
        "Yibin Wen",
        "Jinxiao Zhang",
        "Runmin Dong",
        "Haohuan Fu"
      ],
      "abstract": "In this paper, we firstly tackle a more realistic Domain Adaptation (DA)\nsetting: Source-Free Blending-Target Domain Adaptation (SF-BTDA), where we can\nnot access to source domain data while facing mixed multiple target domains\nwithout any domain labels in prior. Compared to existing DA scenarios, SF-BTDA\ngenerally faces the co-existence of different label shifts in different\ntargets, along with noisy target pseudo labels generated from the source model.\nIn this paper, we propose a new method called Evidential Contrastive Alignment\n(ECA) to decouple the blending target domain and alleviate the effect from\nnoisy target pseudo labels. First, to improve the quality of pseudo target\nlabels, we propose a calibrated evidential learning module to iteratively\nimprove both the accuracy and certainty of the resulting model and adaptively\ngenerate high-quality pseudo target labels. Second, we design a graph\ncontrastive learning with the domain distance matrix and confidence-uncertainty\ncriterion, to minimize the distribution gap of samples of a same class in the\nblended target domains, which alleviates the co-existence of different label\nshifts in blended targets. We conduct a new benchmark based on three standard\nDA datasets and ECA outperforms other methods with considerable gains and\nachieves comparable results compared with those that have domain labels or\nsource data in prior.",
      "tldr_zh": "本论文首次探讨了Source-Free Blending-Target Domain Adaptation (SF-BTDA)场景，即无法访问源域数据且目标域为混合多域无先验标签的情况，面临不同标签偏移共存和噪声伪标签的挑战。作者提出Evidential Contrastive Alignment (ECA)方法，包括一个校准的evidential learning模块，用于迭代提升模型准确性和确定性，并自适应生成高质量伪目标标签。其次，ECA引入基于域距离矩阵和置信度-不确定性标准的graph contrastive learning，以最小化混合目标域中同一类样本的分布差距，从而缓解标签偏移问题。在三个标准DA数据集上的新基准测试中，ECA显著优于其他方法，并在无域标签或源数据的情况下实现可比性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.07527v2",
      "published_date": "2024-08-14 13:02:20 UTC",
      "updated_date": "2024-08-25 11:53:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:18:32.735250"
    },
    {
      "arxiv_id": "2408.07524v1",
      "title": "Fast Inference for Probabilistic Answer Set Programs via the Residual Program",
      "title_zh": "通过剩余程序实现概率答案集程序的快速推理",
      "authors": [
        "Damiano Azzolini",
        "Fabrizio Riguzzi"
      ],
      "abstract": "When we want to compute the probability of a query from a Probabilistic\nAnswer Set Program, some parts of a program may not influence the probability\nof a query, but they impact on the size of the grounding. Identifying and\nremoving them is crucial to speed up the computation. Algorithms for SLG\nresolution offer the possibility of returning the residual program which can be\nused for computing answer sets for normal programs that do have a total\nwell-founded model. The residual program does not contain the parts of the\nprogram that do not influence the probability. In this paper, we propose to\nexploit the residual program for performing inference. Empirical results on\ngraph datasets show that the approach leads to significantly faster inference.",
      "tldr_zh": "这篇论文针对 Probabilistic Answer Set Programs 的查询概率计算，提出一种利用 residual program 的方法来加速推理过程，以移除不影响查询概率但增加 grounding 规模的程序部分。作者基于 SLG resolution 算法生成 residual program，确保仅保留影响概率的关键元素。实验结果显示，在图数据集上，该方法显著提高了推理效率，验证了其有效性。",
      "categories": [
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "The paper has been accepted at the ICLP2024 conference and under\n  consideration in Theory and Practice of Logic Programming (TPLP)",
      "pdf_url": "http://arxiv.org/pdf/2408.07524v1",
      "published_date": "2024-08-14 12:58:22 UTC",
      "updated_date": "2024-08-14 12:58:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:18:43.239936"
    },
    {
      "arxiv_id": "2408.07521v1",
      "title": "Optimising Dynamic Traffic Distribution for Urban Networks with Answer Set Programming",
      "title_zh": "翻译失败",
      "authors": [
        "Matteo Cardellini",
        "Carmine Dodaro",
        "Marco Maratea",
        "Mauro Vallati"
      ],
      "abstract": "Answer Set Programming (ASP) has demonstrated its potential as an effective\ntool for concisely representing and reasoning about real-world problems. In\nthis paper, we present an application in which ASP has been successfully used\nin the context of dynamic traffic distribution for urban networks, within a\nmore general framework devised for solving such a real-world problem. In\nparticular, ASP has been employed for the computation of the \"optimal\" routes\nfor all the vehicles in the network. We also provide an empirical analysis of\nthe performance of the whole framework, and of its part in which ASP is\nemployed, on two European urban areas, which shows the viability of the\nframework and the contribution ASP can give.",
      "tldr_zh": "这篇论文探讨了使用 Answer Set Programming (ASP) 优化城市网络动态交通分配的方法，作为一个更大框架的一部分。论文中，ASP 被应用于计算网络中所有车辆的最优路线，从而实现高效的交通管理。通过在两个欧洲城市区域进行的实证分析，框架整体性能良好，ASP 部分也展示了显著的贡献，证明了其在真实世界问题中的可行性。",
      "categories": [
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.07521v1",
      "published_date": "2024-08-14 12:54:26 UTC",
      "updated_date": "2024-08-14 12:54:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:18:54.741690"
    },
    {
      "arxiv_id": "2408.07510v1",
      "title": "Dominating Set Reconfiguration with Answer Set Programming",
      "title_zh": "翻译失败",
      "authors": [
        "Masato Kato",
        "Torsten Schaub",
        "Takehide Soh",
        "Naoyuki Tamura",
        "Mutsunori Banbara"
      ],
      "abstract": "The dominating set reconfiguration problem is defined as determining, for a\ngiven dominating set problem and two among its feasible solutions, whether one\nis reachable from the other via a sequence of feasible solutions subject to a\ncertain adjacency relation. This problem is PSPACE-complete in general. The\nconcept of the dominating set is known to be quite useful for analyzing\nwireless networks, social networks, and sensor networks. We develop an approach\nto solve the dominating set reconfiguration problem based on Answer Set\nProgramming (ASP). Our declarative approach relies on a high-level ASP\nencoding, and both the grounding and solving tasks are delegated to an\nASP-based combinatorial reconfiguration solver. To evaluate the effectiveness\nof our approach, we conduct experiments on a newly created benchmark set.",
      "tldr_zh": "本文研究了 Dominating Set Reconfiguration 问题，该问题涉及判断两个可行解是否可以通过一系列遵守特定邻接关系的可行解序列相互转换，且该问题是 PSPACE-complete，在无线网络、社会网络和传感器网络分析中具有重要应用。作者提出了一种基于 Answer Set Programming (ASP) 的声明式方法，通过高水平编码将 grounding 和 solving 任务委托给 ASP-based 组合重构求解器。实验在新建的基准集上进行，证明了该方法的有效性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.07510v1",
      "published_date": "2024-08-14 12:38:12 UTC",
      "updated_date": "2024-08-14 12:38:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:19:08.315053"
    },
    {
      "arxiv_id": "2408.07482v3",
      "title": "Training Overhead Ratio: A Practical Reliability Metric for Large Language Model Training Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Ning Lu",
        "Qian Xie",
        "Hao Zhang",
        "Wenyi Fang",
        "Yang Zheng",
        "Zheng Hu",
        "Jiantao Ma"
      ],
      "abstract": "Large Language Models (LLMs) are revolutionizing the AI industry with their\nsuperior capabilities. Training these models requires large-scale GPU clusters\nand significant computing time, leading to frequent failures that significantly\nincrease training costs. Despite its significance, this field lacks a metric\nfor evaluating reliability. In this work, we introduce a novel reliability\nmetric called \\emph{Training Overhead Ratio} (TOR) to evaluate the reliability\nof fault-tolerant LLM training systems. TOR is defined as the ratio of optimal\ntraining time to the observed training time of a system, serving as a practical\ntool for users to estimate the actual time required to train an LLM on a given\nsystem. Furthermore, our investigation identifies the key factor for enhancing\nreliability and present TOR equations for various types of failures encountered\nin practice.",
      "tldr_zh": "本研究针对大型语言模型 (LLMs) 训练系统的问题，提出了一种新的可靠性指标 Training Overhead Ratio (TOR)，用于评估故障对训练效率的影响。TOR 定义为最优训练时间与实际观察训练时间的比率，帮助用户估算在给定系统上训练 LLM 的实际所需时间。通过分析各种实际失败类型，论文识别了提升系统可靠性的关键因素，并提供了相应的 TOR 方程。该指标为优化 LLM 训练系统提供了实用工具，减少了因故障导致的成本增加。",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "To be published in: IEEE International Symposium on Software\n  Reliability Engineering (ISSRE2024) workshop",
      "pdf_url": "http://arxiv.org/pdf/2408.07482v3",
      "published_date": "2024-08-14 11:55:28 UTC",
      "updated_date": "2024-10-09 08:43:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:19:29.323249"
    },
    {
      "arxiv_id": "2408.07479v1",
      "title": "A Study on Bias Detection and Classification in Natural Language Processing",
      "title_zh": "翻译失败",
      "authors": [
        "Ana Sofia Evans",
        "Helena Moniz",
        "Luísa Coheur"
      ],
      "abstract": "Human biases have been shown to influence the performance of models and\nalgorithms in various fields, including Natural Language Processing. While the\nstudy of this phenomenon is garnering focus in recent years, the available\nresources are still relatively scarce, often focusing on different forms or\nmanifestations of biases. The aim of our work is twofold: 1) gather\npublicly-available datasets and determine how to better combine them to\neffectively train models in the task of hate speech detection and\nclassification; 2) analyse the main issues with these datasets, such as\nscarcity, skewed resources, and reliance on non-persistent data. We discuss\nthese issues in tandem with the development of our experiments, in which we\nshow that the combinations of different datasets greatly impact the models'\nperformance.",
      "tldr_zh": "这篇论文探讨了人类偏见在自然语言处理(NLP)中的影响，特别关注偏见检测和分类的问题。研究的目标是：1) 收集公开数据集并优化其组合，以训练仇恨言论检测和分类模型；2) 分析数据集的常见问题，如资源稀缺、数据偏差和依赖非持久数据。通过实验，作者发现不同数据集的组合对模型性能有显著影响，为改进偏见相关NLP任务提供了见解。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "68T50",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "31 pages, 15 Tables, 4 Figures",
      "pdf_url": "http://arxiv.org/pdf/2408.07479v1",
      "published_date": "2024-08-14 11:49:24 UTC",
      "updated_date": "2024-08-14 11:49:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:19:30.713251"
    },
    {
      "arxiv_id": "2408.07465v1",
      "title": "Large Language Models Prompting With Episodic Memory",
      "title_zh": "大型语言模型的提示方法结合情景记忆",
      "authors": [
        "Dai Do",
        "Quan Tran",
        "Svetha Venkatesh",
        "Hung Le"
      ],
      "abstract": "Prompt optimization is essential for enhancing the performance of Large\nLanguage Models (LLMs) in a range of Natural Language Processing (NLP) tasks,\nparticularly in scenarios of few-shot learning where training examples are\nincorporated directly into the prompt. Despite the growing interest in\noptimizing prompts with few-shot examples, existing methods for prompt\noptimization are often resource-intensive or perform inadequately. In this\nwork, we propose PrOmpting with Episodic Memory (POEM), a novel prompt\noptimization technique that is simple, efficient, and demonstrates strong\ngeneralization capabilities. We approach prompt optimization as a Reinforcement\nLearning (RL) challenge, using episodic memory to archive combinations of input\ndata, permutations of few-shot examples, and the rewards observed during\ntraining. In the testing phase, we optimize the sequence of examples for each\ntest query by selecting the sequence that yields the highest total rewards from\nthe top-k most similar training examples in the episodic memory. Our results\nshow that POEM outperforms recent techniques like TEMPERA and RLPrompt by over\n5.3% in various text classification tasks. Furthermore, our approach adapts\nwell to broader language understanding tasks, consistently outperforming\nconventional heuristic methods for ordering examples.",
      "tldr_zh": "这篇论文提出了一种名为 POEM（PrOmpting with Episodic Memory）的提示优化技术，用于提升 Large Language Models (LLMs) 在 Few-shot learning 场景下的性能，解决现有方法资源密集或效果不足的问题。POEM 将提示优化视为 Reinforcement Learning (RL) 挑战，通过 Episodic Memory 存储输入数据、Few-shot examples 的排列及其奖励，并在测试阶段选择与查询最相似的序列以优化例子顺序。实验结果显示，POEM 在各种文本分类任务中比 TEMPERA 和 RLPrompt 高出 5.3% 以上，并在更广泛的语言理解任务中优于传统启发式方法。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.07465v1",
      "published_date": "2024-08-14 11:19:28 UTC",
      "updated_date": "2024-08-14 11:19:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:19:44.052783"
    },
    {
      "arxiv_id": "2408.07461v4",
      "title": "Problem Solving Through Human-AI Preference-Based Cooperation",
      "title_zh": "翻译失败",
      "authors": [
        "Subhabrata Dutta",
        "Timo Kaufmann",
        "Goran Glavaš",
        "Ivan Habernal",
        "Kristian Kersting",
        "Frauke Kreuter",
        "Mira Mezini",
        "Iryna Gurevych",
        "Eyke Hüllermeier",
        "Hinrich Schuetze"
      ],
      "abstract": "While there is a widespread belief that artificial general intelligence (AGI)\n-- or even superhuman AI -- is imminent, complex problems in expert domains are\nfar from being solved. We argue that such problems require human-AI cooperation\nand that the current state of the art in generative AI is unable to play the\nrole of a reliable partner due to a multitude of shortcomings, including\ndifficulty to keep track of a complex solution artifact (e.g., a software\nprogram), limited support for versatile human preference expression and lack of\nadapting to human preference in an interactive setting. To address these\nchallenges, we propose HAICo2, a novel human-AI co-construction framework. We\ntake first steps towards a formalization of HAICo2 and discuss the difficult\nopen research problems that it faces.",
      "tldr_zh": "该论文认为，复杂问题在专家领域远未解决，需要人类-AI 合作，但当前生成 AI 存在诸多缺陷，包括难以跟踪复杂解决方案（如软件程序）、有限的人类偏好表达支持，以及在互动环境中无法适应人类偏好。为了解决这些挑战，研究者提出了一种新型框架 HAICo2（Human-AI Co-Construction），并对其进行初步形式化。论文讨论了 HAICo2 面临的开放研究问题，为实现可靠的人类-AI 合作奠定基础。",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "20 pages",
      "pdf_url": "http://arxiv.org/pdf/2408.07461v4",
      "published_date": "2024-08-14 11:06:57 UTC",
      "updated_date": "2025-04-29 13:57:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:19:56.178942"
    },
    {
      "arxiv_id": "2408.07453v1",
      "title": "Fact or Fiction? Improving Fact Verification with Knowledge Graphs through Simplified Subgraph Retrievals",
      "title_zh": "翻译失败",
      "authors": [
        "Tobias A. Opsahl"
      ],
      "abstract": "Despite recent success in natural language processing (NLP), fact\nverification still remains a difficult task. Due to misinformation spreading\nincreasingly fast, attention has been directed towards automatically verifying\nthe correctness of claims. In the domain of NLP, this is usually done by\ntraining supervised machine learning models to verify claims by utilizing\nevidence from trustworthy corpora. We present efficient methods for verifying\nclaims on a dataset where the evidence is in the form of structured knowledge\ngraphs. We use the FactKG dataset, which is constructed from the DBpedia\nknowledge graph extracted from Wikipedia. By simplifying the evidence retrieval\nprocess, from fine-tuned language models to simple logical retrievals, we are\nable to construct models that both require less computational resources and\nachieve better test-set accuracy.",
      "tldr_zh": "这篇论文针对自然语言处理(NLP)中的事实验证难题，提出了一种通过简化子图检索(subgraph retrievals)来利用知识图谱(knowledge graphs)的方法，以提高声明正确性的自动验证效率。研究使用FactKG数据集（基于DBpedia知识图谱，从Wikipedia提取），将证据检索从微调语言模型切换到简单逻辑检索，从而减少计算资源需求。实验结果显示，这种方法在测试集上实现了更高的准确率，证明了其在处理结构化证据时的优势。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages, 3 figures, appendix",
      "pdf_url": "http://arxiv.org/pdf/2408.07453v1",
      "published_date": "2024-08-14 10:46:15 UTC",
      "updated_date": "2024-08-14 10:46:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:20:07.241112"
    },
    {
      "arxiv_id": "2408.07452v1",
      "title": "CMU's IWSLT 2024 Simultaneous Speech Translation System",
      "title_zh": "翻译失败",
      "authors": [
        "Xi Xu",
        "Siqi Ouyang",
        "Brian Yan",
        "Patrick Fernandes",
        "William Chen",
        "Lei Li",
        "Graham Neubig",
        "Shinji Watanabe"
      ],
      "abstract": "This paper describes CMU's submission to the IWSLT 2024 Simultaneous Speech\nTranslation (SST) task for translating English speech to German text in a\nstreaming manner. Our end-to-end speech-to-text (ST) system integrates the\nWavLM speech encoder, a modality adapter, and the Llama2-7B-Base model as the\ndecoder. We employ a two-stage training approach: initially, we align the\nrepresentations of speech and text, followed by full fine-tuning. Both stages\nare trained on MuST-c v2 data with cross-entropy loss. We adapt our offline ST\nmodel for SST using a simple fixed hold-n policy. Experiments show that our\nmodel obtains an offline BLEU score of 31.1 and a BLEU score of 29.5 under 2\nseconds latency on the MuST-C-v2 tst-COMMON.",
      "tldr_zh": "这篇论文介绍了 CMU 提交给 IWSLT 2024 的同时性语音翻译 (SST) 系统，用于实时将英语语音翻译成德语文本。系统采用端到端的语音到文本 (ST) 架构，整合 WavLM 语音编码器、模态适配器和 Llama2-7B-Base 模型，并通过两阶段训练方法：首先对齐语音和文本表示，然后进行完全微调，使用 MuST-c v2 数据和交叉熵损失。系统通过简单的固定 hold-n policy 将离线模型适应为同时性翻译。实验结果显示，在 MuST-C-v2 tst-COMMON 测试集上，该系统实现了离线 BLEU 分数 31.1，以及在 2 秒延迟下的 BLEU 分数 29.5。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.07452v1",
      "published_date": "2024-08-14 10:44:51 UTC",
      "updated_date": "2024-08-14 10:44:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:20:21.407902"
    },
    {
      "arxiv_id": "2408.07448v2",
      "title": "LiveFC: A System for Live Fact-Checking of Audio Streams",
      "title_zh": "LiveFC: 用于实时事实核查音频流系统的设计",
      "authors": [
        "Venktesh V",
        "Vinay Setty"
      ],
      "abstract": "The advances in the digital era have led to rapid dissemination of\ninformation. This has also aggravated the spread of misinformation and\ndisinformation. This has potentially serious consequences, such as civil\nunrest. While fact-checking aims to combat this, manual fact-checking is\ncumbersome and not scalable. While automated fact-checking approaches exist,\nthey do not operate in real-time and do not always account for spread of\nmisinformation through different modalities. This is particularly important as\nproactive fact-checking on live streams in real-time can help people be\ninformed of false narratives and prevent catastrophic consequences that may\ncause civil unrest. This is particularly relevant with the rapid dissemination\nof information through video on social media platforms or other streams like\npolitical rallies and debates. Hence, in this work we develop a platform named\nLiveFC, that can aid in fact-checking live audio streams in real-time. LiveFC\nhas a user-friendly interface that displays the claims detected along with\ntheir veracity and evidence for live streams with associated speakers for\nclaims from respective segments. The app can be accessed at\nhttp://livefc.factiverse.ai and a screen recording of the demo can be found at\nhttps://bit.ly/3WVAoIw.",
      "tldr_zh": "本研究针对数字时代虚假信息快速传播的问题，开发了LiveFC系统，用于实时事实核查音频流，以防范潜在的社会动荡和误导性叙述。LiveFC采用自动化方法检测声明、评估其真实性（veracity）、提供证据，并将声明与相关演讲者和音频段关联，具备用户友好的界面。相比传统手动或非实时fact-checking方法，该系统提升了可扩展性和及时性，可通过指定链接访问演示。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Under Review, 11 pages",
      "pdf_url": "http://arxiv.org/pdf/2408.07448v2",
      "published_date": "2024-08-14 10:36:17 UTC",
      "updated_date": "2024-09-02 11:45:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:20:33.650840"
    },
    {
      "arxiv_id": "2408.12622v2",
      "title": "The AI Risk Repository: A Comprehensive Meta-Review, Database, and Taxonomy of Risks From Artificial Intelligence",
      "title_zh": "翻译失败",
      "authors": [
        "Peter Slattery",
        "Alexander K. Saeri",
        "Emily A. C. Grundy",
        "Jess Graham",
        "Michael Noetel",
        "Risto Uuk",
        "James Dao",
        "Soroush Pour",
        "Stephen Casper",
        "Neil Thompson"
      ],
      "abstract": "The risks posed by Artificial Intelligence (AI) are of considerable concern\nto academics, auditors, policymakers, AI companies, and the public. However, a\nlack of shared understanding of AI risks can impede our ability to\ncomprehensively discuss, research, and react to them. This paper addresses this\ngap by creating an AI Risk Repository to serve as a common frame of reference.\nThis comprises a living database of 777 risks extracted from 43 taxonomies,\nwhich can be filtered based on two overarching taxonomies and easily accessed,\nmodified, and updated via our website and online spreadsheets. We construct our\nRepository with a systematic review of taxonomies and other structured\nclassifications of AI risk followed by an expert consultation. We develop our\ntaxonomies of AI risk using a best-fit framework synthesis. Our high-level\nCausal Taxonomy of AI Risks classifies each risk by its causal factors (1)\nEntity: Human, AI; (2) Intentionality: Intentional, Unintentional; and (3)\nTiming: Pre-deployment; Post-deployment. Our mid-level Domain Taxonomy of AI\nRisks classifies risks into seven AI risk domains: (1) Discrimination &\ntoxicity, (2) Privacy & security, (3) Misinformation, (4) Malicious actors &\nmisuse, (5) Human-computer interaction, (6) Socioeconomic & environmental, and\n(7) AI system safety, failures, & limitations. These are further divided into\n23 subdomains. The AI Risk Repository is, to our knowledge, the first attempt\nto rigorously curate, analyze, and extract AI risk frameworks into a publicly\naccessible, comprehensive, extensible, and categorized risk database. This\ncreates a foundation for a more coordinated, coherent, and complete approach to\ndefining, auditing, and managing the risks posed by AI systems.",
      "tldr_zh": "本论文构建了AI Risk Repository，这是一个全面的AI风险数据库，包含从43个分类中提取的777个风险，并提供了两个关键分类系统：Causal Taxonomy（基于实体、意图和时间分类风险，如Human/AI、Intentional/Unintentional和Pre-deployment/Post-deployment）和Domain Taxonomy（将风险分为七个领域和23个子领域，包括Discrimination & toxicity、Privacy & security等）。研究团队通过系统审查现有AI风险分类和专家咨询，采用best-fit framework synthesis方法开发这些分类框架。该数据库作为首个公开、可扩展的资源，有助于促进AI风险的统一讨论、审计和管理，提供更协调的应对策略。",
      "categories": [
        "cs.AI",
        "cs.CR",
        "cs.ET",
        "cs.LG",
        "cs.SY",
        "eess.SY",
        "I.2.0; K.4.1; K.4.1; K.4.2; K.4.3; K.6.0"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12622v2",
      "published_date": "2024-08-14 10:32:06 UTC",
      "updated_date": "2025-04-10 21:14:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:20:45.697027"
    },
    {
      "arxiv_id": "2408.07438v1",
      "title": "Achieving Data Efficient Neural Networks with Hybrid Concept-based Models",
      "title_zh": "通过混合概念-based 模型实现",
      "authors": [
        "Tobias A. Opsahl",
        "Vegard Antun"
      ],
      "abstract": "Most datasets used for supervised machine learning consist of a single label\nper data point. However, in cases where more information than just the class\nlabel is available, would it be possible to train models more efficiently? We\nintroduce two novel model architectures, which we call hybrid concept-based\nmodels, that train using both class labels and additional information in the\ndataset referred to as concepts. In order to thoroughly assess their\nperformance, we introduce ConceptShapes, an open and flexible class of datasets\nwith concept labels. We show that the hybrid concept-based models outperform\nstandard computer vision models and previously proposed concept-based models\nwith respect to accuracy, especially in sparse data settings. We also introduce\nan algorithm for performing adversarial concept attacks, where an image is\nperturbed in a way that does not change a concept-based model's concept\npredictions, but changes the class prediction. The existence of such\nadversarial examples raises questions about the interpretable qualities\npromised by concept-based models.",
      "tldr_zh": "这篇论文提出了一种名为hybrid concept-based models的新型神经网络架构，利用类别标签和额外概念信息来提升模型在数据稀疏环境下的训练效率。研究者开发了ConceptShapes数据集——一个开放灵活的带有概念标签的数据集——用于评估这些模型，结果显示hybrid concept-based models在准确性上优于标准计算机视觉模型和现有概念模型。论文还引入了adversarial concept attacks算法，通过对图像的扰动来改变类别预测而不影响概念预测，从而质疑了概念模型的可解释性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "11 pages, 8 figures, appendix",
      "pdf_url": "http://arxiv.org/pdf/2408.07438v1",
      "published_date": "2024-08-14 10:15:34 UTC",
      "updated_date": "2024-08-14 10:15:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:20:58.350048"
    },
    {
      "arxiv_id": "2408.07720v1",
      "title": "Re-Thinking Process Mining in the AI-Based Agents Era",
      "title_zh": "在基于AI",
      "authors": [
        "Alessandro Berti",
        "Mayssa Maatallah",
        "Urszula Jessen",
        "Michal Sroka",
        "Sonia Ayachi Ghannouchi"
      ],
      "abstract": "Large Language Models (LLMs) have emerged as powerful conversational\ninterfaces, and their application in process mining (PM) tasks has shown\npromising results. However, state-of-the-art LLMs struggle with complex\nscenarios that demand advanced reasoning capabilities. In the literature, two\nprimary approaches have been proposed for implementing PM using LLMs: providing\ntextual insights based on a textual abstraction of the process mining artifact,\nand generating code executable on the original artifact. This paper proposes\nutilizing the AI-Based Agents Workflow (AgWf) paradigm to enhance the\neffectiveness of PM on LLMs. This approach allows for: i) the decomposition of\ncomplex tasks into simpler workflows, and ii) the integration of deterministic\ntools with the domain knowledge of LLMs. We examine various implementations of\nAgWf and the types of AI-based tasks involved. Additionally, we discuss the\nCrewAI implementation framework and present examples related to process mining.",
      "tldr_zh": "这篇论文重新审视了在AI代理时代的过程挖掘(Process Mining)，指出大型语言模型(LLMs)虽然在PM任务中表现出色，但难以处理需要高级推理的复杂场景。论文提出利用AI-Based Agents Workflow (AgWf) 范式，将复杂任务分解为简单工作流，并整合确定性工具与LLMs的领域知识，从而提升PM的有效性。作者探讨了AgWf的各种实现形式、涉及的AI任务类型，并通过CrewAI框架提供过程挖掘相关的示例，展示了这一方法的实际应用潜力。",
      "categories": [
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.07720v1",
      "published_date": "2024-08-14 10:14:18 UTC",
      "updated_date": "2024-08-14 10:14:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:21:10.439780"
    },
    {
      "arxiv_id": "2408.07435v2",
      "title": "Real-world validation of safe reinforcement learning, model predictive control and decision tree-based home energy management systems",
      "title_zh": "翻译失败",
      "authors": [
        "Julian Ruddick",
        "Glenn Ceusters",
        "Gilles Van Kriekinge",
        "Evgenii Genov",
        "Cedric De Cauwer",
        "Thierry Coosemans",
        "Maarten Messagie"
      ],
      "abstract": "Recent advancements in machine learning based energy management approaches,\nspecifically reinforcement learning with a safety layer (OptLayerPolicy) and a\nmetaheuristic algorithm generating a decision tree control policy (TreeC), have\nshown promise. However, their effectiveness has only been demonstrated in\ncomputer simulations. This paper presents the real-world validation of these\nmethods, comparing against model predictive control and simple rule-based\ncontrol benchmark. The experiments were conducted on the electrical\ninstallation of 4 reproductions of residential houses, which all have their own\nbattery, photovoltaic and dynamic load system emulating a non-controllable\nelectrical load and a controllable electric vehicle charger. The results show\nthat the simple rules, TreeC, and model predictive control-based methods\nachieved similar costs, with a difference of only 0.6%. The reinforcement\nlearning based method, still in its training phase, obtained a cost 25.5\\%\nhigher to the other methods. Additional simulations show that the costs can be\nfurther reduced by using a more representative training dataset for TreeC and\naddressing errors in the model predictive control implementation caused by its\nreliance on accurate data from various sources. The OptLayerPolicy safety layer\nallows safe online training of a reinforcement learning agent in the\nreal-world, given an accurate constraint function formulation. The proposed\nsafety layer method remains error-prone, nonetheless, it is found beneficial\nfor all investigated methods. The TreeC method, which does require building a\nrealistic simulation for training, exhibits the safest operational performance,\nexceeding the grid limit by only 27.1 Wh compared to 593.9 Wh for reinforcement\nlearning.",
      "tldr_zh": "这篇论文在真实世界环境中验证了安全强化学习 (OptLayerPolicy) 和决策树控制策略 (TreeC) 等机器学习方法，并与模型预测控制和简单规则控制进行比较，针对家庭能源管理系统。实验在4个模拟住宅电气系统中进行，结果显示TreeC、模型预测控制和简单规则方法的成本仅相差0.6%，而强化学习方法由于仍在训练中，成本高出25.5%。此外，TreeC 方法表现出最高的运行安全性，仅超过电网限制27.1 Wh，而OptLayerPolicy 的安全层虽允许在线训练但易出错。作者建议通过优化训练数据集和修复模型预测控制的实现错误，进一步降低系统成本并提升性能。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.LG",
        "cs.NE",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "Accepted version Energy and AI:\n  https://doi.org/10.1016/j.egyai.2024.100448",
      "pdf_url": "http://arxiv.org/pdf/2408.07435v2",
      "published_date": "2024-08-14 10:12:15 UTC",
      "updated_date": "2024-11-25 09:45:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:21:23.623954"
    },
    {
      "arxiv_id": "2408.07433v5",
      "title": "MagicFace: Training-free Universal-Style Human Image Customized Synthesis",
      "title_zh": "翻译失败",
      "authors": [
        "Yibin Wang",
        "Weizhong Zhang",
        "Cheng Jin"
      ],
      "abstract": "Current human image customization methods leverage Stable Diffusion (SD) for\nits rich semantic prior. However, since SD is not specifically designed for\nhuman-oriented generation, these methods often require extensive fine-tuning on\nlarge-scale datasets, which renders them susceptible to overfitting and hinders\ntheir ability to personalize individuals with previously unseen styles.\nMoreover, these methods extensively focus on single-concept human image\nsynthesis and lack the flexibility to customize individuals using multiple\ngiven concepts, thereby impeding their broader practical application. This\npaper proposes MagicFace, a novel training-free method for multi-concept\nuniversal-style human image personalized synthesis. Our core idea is to\nsimulate how humans create images given specific concepts, i.e., first\nestablish a semantic layout considering factors such as concepts' shape and\nposture, then optimize details by comparing with concepts at the pixel level.\nTo implement this process, we introduce a coarse-to-fine generation pipeline,\ninvolving two sequential stages: semantic layout construction and concept\nfeature injection. This is achieved by our Reference-aware Self-Attention (RSA)\nand Region-grouped Blend Attention (RBA) mechanisms. In the first stage, RSA\nenables the latent image to query features from all reference concepts\nsimultaneously, extracting the overall semantic understanding to facilitate the\ninitial semantic layout establishment. In the second stage, we employ an\nattention-based semantic segmentation method to pinpoint the latent generated\nregions of all concepts at each step. Following this, RBA divides the pixels of\nthe latent image into semantic groups, with each group querying fine-grained\nfeatures from the corresponding reference concept. Extensive experiments\ndemonstrate the superiority of our MagicFace.",
      "tldr_zh": "本论文提出 MagicFace，一种无需训练的多概念通用样式人类图像个性化合成方法，以解决现有基于 Stable Diffusion (SD) 的方法在微调需求、过拟合和多概念处理灵活性不足的问题。核心思路模拟人类图像创建过程，通过粗到细的生成管道，先使用 Reference-aware Self-Attention (RSA) 机制从所有参考概念中提取整体语义布局（如概念形状和姿势），然后采用 Region-grouped Blend Attention (RBA) 机制进行像素级概念特征注入，实现精确的细节优化。实验结果显示，MagicFace 在多概念合成任务上显著优于基线方法，证明了其在实际应用中的有效性和泛化能力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "project page: https://codegoat24.github.io/MagicFace",
      "pdf_url": "http://arxiv.org/pdf/2408.07433v5",
      "published_date": "2024-08-14 10:08:46 UTC",
      "updated_date": "2024-11-18 03:14:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:21:35.369534"
    },
    {
      "arxiv_id": "2408.07425v1",
      "title": "Exploring Retrieval Augmented Generation in Arabic",
      "title_zh": "探索阿拉伯语中的检索增强生成",
      "authors": [
        "Samhaa R. El-Beltagy",
        "Mohamed A. Abdallah"
      ],
      "abstract": "Recently, Retrieval Augmented Generation (RAG) has emerged as a powerful\ntechnique in natural language processing, combining the strengths of\nretrieval-based and generation-based models to enhance text generation tasks.\nHowever, the application of RAG in Arabic, a language with unique\ncharacteristics and resource constraints, remains underexplored. This paper\npresents a comprehensive case study on the implementation and evaluation of RAG\nfor Arabic text. The work focuses on exploring various semantic embedding\nmodels in the retrieval stage and several LLMs in the generation stage, in\norder to investigate what works and what doesn't in the context of Arabic. The\nwork also touches upon the issue of variations between document dialect and\nquery dialect in the retrieval stage. Results show that existing semantic\nembedding models and LLMs can be effectively employed to build Arabic RAG\npipelines.",
      "tldr_zh": "Retrieval Augmented Generation (RAG) 是一种结合检索和生成模型的强大技术，本文通过一个全面案例研究探讨了其在阿拉伯语中的应用，以应对该语言的独特特性和资源限制。研究重点考察了检索阶段的各种语义嵌入模型、生成阶段的几种 LLMs，以及文档方言和查询方言差异的影响。结果显示，现有的语义嵌入模型和 LLMs 可以有效构建阿拉伯语 RAG 管道，为该领域的进一步发展提供了宝贵见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.07425v1",
      "published_date": "2024-08-14 10:03:28 UTC",
      "updated_date": "2024-08-14 10:03:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:21:46.770483"
    },
    {
      "arxiv_id": "2408.07422v2",
      "title": "LLMI3D: MLLM-based 3D Perception from a Single 2D Image",
      "title_zh": "翻译失败",
      "authors": [
        "Fan Yang",
        "Sicheng Zhao",
        "Yanhao Zhang",
        "Hui Chen",
        "Haonan Lu",
        "Jungong Han",
        "Guiguang Ding"
      ],
      "abstract": "Recent advancements in autonomous driving, augmented reality, robotics, and\nembodied intelligence have necessitated 3D perception algorithms. However,\ncurrent 3D perception methods, especially specialized small models, exhibit\npoor generalization in open scenarios. On the other hand, multimodal large\nlanguage models (MLLMs) excel in general capacity but underperform in 3D tasks,\ndue to weak 3D local spatial object perception, poor text-based geometric\nnumerical output, and inability to handle camera focal variations. To address\nthese challenges, we propose the following solutions: Spatial-Enhanced Local\nFeature Mining for better spatial feature extraction, 3D Query Token-Derived\nInfo Decoding for precise geometric regression, and Geometry Projection-Based\n3D Reasoning for handling camera focal length variations. We employ\nparameter-efficient fine-tuning for a pre-trained MLLM and develop LLMI3D, a\npowerful 3D perception MLLM. Additionally, we have constructed the IG3D\ndataset, which provides fine-grained descriptions and question-answer\nannotations. Extensive experiments demonstrate that our LLMI3D achieves\nstate-of-the-art performance, outperforming other methods by a large margin.",
      "tldr_zh": "该论文提出 LLMI3D，一种基于多模态大型语言模型 (MLLM) 的框架，用于从单张 2D 图像实现 3D 感知，解决现有模型在 3D 局部空间物体感知、文本-based 几何输出和相机焦距变化处理方面的不足。关键方法包括 Spatial-Enhanced Local Feature Mining 用于提升空间特征提取、3D Query Token-Derived Info Decoding 用于精确几何回归，以及 Geometry Projection-Based 3D Reasoning 用于适应焦距变异，并通过参数高效微调优化预训练 MLLM。作者构建了 IG3D 数据集，提供细粒度描述和问答注释，实验结果显示 LLMI3D 在 3D 感知任务中大幅优于其他方法，达到了最先进性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.07422v2",
      "published_date": "2024-08-14 10:00:16 UTC",
      "updated_date": "2025-02-13 09:32:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:22:02.023574"
    },
    {
      "arxiv_id": "2408.07417v1",
      "title": "The Restaurant Meal Delivery Problem with Ghost Kitchens",
      "title_zh": "带幽灵厨房的餐厅送餐问题",
      "authors": [
        "Gal Neria",
        "Florentin D Hildebrandt",
        "Michal Tzur",
        "Marlin W Ulmer"
      ],
      "abstract": "Restaurant meal delivery has been rapidly growing in the last few years. The\nmain challenges in operating it are the temporally and spatially dispersed\nstochastic demand that arrives from customers all over town as well as the\ncustomers' expectation of timely and fresh delivery. To overcome these\nchallenges a new business concept emerged, \"Ghost kitchens\". This concept\nproposes synchronized food preparation of several restaurants in a central\ncomplex, exploiting consolidation benefits. However, dynamically scheduling\nfood preparation and delivery is challenging and we propose operational\nstrategies for the effective operations of ghost kitchens. We model the problem\nas a sequential decision process. For the complex, combinatorial decision space\nof scheduling order preparations, consolidating orders to trips, and scheduling\ntrip departures, we propose a large neighborhood search procedure based on\npartial decisions and driven by analytical properties. Within the large\nneighborhood search, decisions are evaluated via a value function\napproximation, enabling anticipatory and real-time decision making. We show the\neffectiveness of our method and demonstrate the value of ghost kitchens\ncompared to conventional meal delivery systems. We show that both integrated\noptimization of cook scheduling and vehicle dispatching, as well as\nanticipation of future demand and decisions, are essential for successful\noperations. We further derive several managerial insights, amongst others, that\ncompanies should carefully consider the trade-off between fast delivery and\nfresh food.",
      "tldr_zh": "这篇论文探讨了引入“Ghost Kitchens”概念来应对餐厅外卖的挑战，包括时空分散的随机需求和客户对及时新鲜交付的期望。作者将问题建模为顺序决策过程，并提出一种基于大型邻域搜索（large neighborhood search）的优化策略，利用部分决策和价值函数近似（value function approximation）实现预见性实时调度。实验证明，该方法显著提升了Ghost Kitchens的运营效率，与传统系统相比提高了整合优化和需求预测的价值，并提供了管理洞见，如权衡快速交付与食物新鲜度的平衡。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.07417v1",
      "published_date": "2024-08-14 09:54:03 UTC",
      "updated_date": "2024-08-14 09:54:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:22:11.277718"
    },
    {
      "arxiv_id": "2408.07719v1",
      "title": "Operator Feature Neural Network for Symbolic Regression",
      "title_zh": "用于符号回归的操作符特征神经网络",
      "authors": [
        "Yusong Deng",
        "Min Wu",
        "Lina Yu",
        "Jingyi Liu",
        "Shu Wei",
        "Yanjie Li",
        "Weijun Li"
      ],
      "abstract": "Symbolic regression is a task aimed at identifying patterns in data and\nrepresenting them through mathematical expressions, generally involving\nskeleton prediction and constant optimization. Many methods have achieved some\nsuccess, however they treat variables and symbols merely as characters of\nnatural language without considering their mathematical essence. This paper\nintroduces the operator feature neural network (OF-Net) which employs operator\nrepresentation for expressions and proposes an implicit feature encoding method\nfor the intrinsic mathematical operational logic of operators. By substituting\noperator features for numeric loss, we can predict the combination of operators\nof target expressions. We evaluate the model on public datasets, and the\nresults demonstrate that the model achieves superior recovery rates and high\n$R^2$ scores. With the discussion of the results, we analyze the merit and\ndemerit of OF-Net and propose optimizing schemes.",
      "tldr_zh": "本文针对 Symbolic Regression 的局限性，即现有方法未考虑变量和符号的数学本质，提出 Operator Feature Neural Network (OF-Net)。该网络采用操作符表示法和隐式特征编码方法，捕捉操作符的内在数学逻辑，并通过替换数字损失为操作符特征来预测目标表达式的操作符组合。在公共数据集上实验表明，OF-Net 取得了较高的恢复率和 $R^2$ 分数，并通过结果讨论分析了其优缺点并提出优化方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "12 pages",
      "pdf_url": "http://arxiv.org/pdf/2408.07719v1",
      "published_date": "2024-08-14 09:47:13 UTC",
      "updated_date": "2024-08-14 09:47:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:22:22.900733"
    },
    {
      "arxiv_id": "2408.10260v1",
      "title": "Optical Music Recognition in Manuscripts from the Ricordi Archive",
      "title_zh": "Ricordi 档案馆手稿中的光学音乐识别",
      "authors": [
        "Federico Simonetta",
        "Rishav Mondal",
        "Luca Andrea Ludovico",
        "Stavros Ntalampiras"
      ],
      "abstract": "The Ricordi archive, a prestigious collection of significant musical\nmanuscripts from renowned opera composers such as Donizetti, Verdi and Puccini,\nhas been digitized. This process has allowed us to automatically extract\nsamples that represent various musical elements depicted on the manuscripts,\nincluding notes, staves, clefs, erasures, and composer's annotations, among\nothers. To distinguish between digitization noise and actual music elements, a\nsubset of these images was meticulously grouped and labeled by multiple\nindividuals into several classes. After assessing the consistency of the\nannotations, we trained multiple neural network-based classifiers to\ndifferentiate between the identified music elements. The primary objective of\nthis study was to evaluate the reliability of these classifiers, with the\nultimate goal of using them for the automatic categorization of the remaining\nunannotated data set. The dataset, complemented by manual annotations, models,\nand source code used in these experiments are publicly accessible for\nreplication purposes.",
      "tldr_zh": "这篇论文针对 Ricordi 档案中的音乐手稿数字化，开发了 Optical Music Recognition 技术，以识别元素如音符、谱线、谱号和作曲家注解。研究者通过手动分组和标注图像子集，评估标注一致性后训练多个 neural network-based classifiers，来区分实际音乐元素与数字化噪声。主要贡献在于验证了这些分类器的可靠性，并将其应用于自动分类剩余未标注数据，同时公开数据集、模型和源代码以便复制研究。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.DL"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at AudioMostly 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.10260v1",
      "published_date": "2024-08-14 09:29:11 UTC",
      "updated_date": "2024-08-14 09:29:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:22:36.512788"
    },
    {
      "arxiv_id": "2408.07404v1",
      "title": "Efficient Edge AI: Deploying Convolutional Neural Networks on FPGA with the Gemmini Accelerator",
      "title_zh": "高效边缘 AI：使用 Gemmini 加速器在 FPGA 上部署卷积神经网络",
      "authors": [
        "Federico Nicolas Peccia",
        "Svetlana Pavlitska",
        "Tobias Fleck",
        "Oliver Bringmann"
      ],
      "abstract": "The growing concerns regarding energy consumption and privacy have prompted\nthe development of AI solutions deployable on the edge, circumventing the\nsubstantial CO2 emissions associated with cloud servers and mitigating risks\nrelated to sharing sensitive data. But deploying Convolutional Neural Networks\n(CNNs) on non-off-the-shelf edge devices remains a complex and labor-intensive\ntask. In this paper, we present and end-to-end workflow for deployment of CNNs\non Field Programmable Gate Arrays (FPGAs) using the Gemmini accelerator, which\nwe modified for efficient implementation on FPGAs. We describe how we leverage\nthe use of open source software on each optimization step of the deployment\nprocess, the customizations we added to them and its impact on the final\nsystem's performance. We were able to achieve real-time performance by\ndeploying a YOLOv7 model on a Xilinx ZCU102 FPGA with an energy efficiency of\n36.5 GOP/s/W. Our FPGA-based solution demonstrates superior power efficiency\ncompared with other embedded hardware devices, and even outperforms other FPGA\nreference implementations. Finally, we present how this kind of solution can be\nintegrated into a wider system, by testing our proposed platform in a traffic\nmonitoring scenario.",
      "tldr_zh": "该论文针对边缘 AI 的能源消耗和隐私问题，提出了一种端到端工作流，用于部署 Convolutional Neural Networks (CNNs) 到 Field Programmable Gate Arrays (FPGAs) 上，利用修改后的 Gemmini 加速器和开源软件进行优化。研究者详细描述了部署过程中的自定义步骤，包括模型优化和性能提升，最终在 Xilinx ZCU102 FPGA 上实现了 YOLOv7 模型的实时运行，达到 36.5 GOP/s/W 的能效。相比其他嵌入式硬件和 FPGA 实现，该方案展示了更高的功耗效率，并在交通监控场景中成功集成验证。",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.AR",
      "comment": "8 pages, 9 figures, accepted at the 27th Euromicro Conference Series\n  on Digital System Design (DSD) 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.07404v1",
      "published_date": "2024-08-14 09:24:00 UTC",
      "updated_date": "2024-08-14 09:24:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:22:48.340223"
    },
    {
      "arxiv_id": "2408.07402v1",
      "title": "A Quantum-Inspired Analysis of Human Disambiguation Processes",
      "title_zh": "翻译失败",
      "authors": [
        "Daphne Wang"
      ],
      "abstract": "Formal languages are essential for computer programming and are constructed\nto be easily processed by computers. In contrast, natural languages are much\nmore challenging and instigated the field of Natural Language Processing (NLP).\nOne major obstacle is the ubiquity of ambiguities. Recent advances in NLP have\nled to the development of large language models, which can resolve ambiguities\nwith high accuracy. At the same time, quantum computers have gained much\nattention in recent years as they can solve some computational problems faster\nthan classical computers. This new computing paradigm has reached the fields of\nmachine learning and NLP, where hybrid classical-quantum learning algorithms\nhave emerged. However, more research is needed to identify which NLP tasks\ncould benefit from a genuine quantum advantage. In this thesis, we applied\nformalisms arising from foundational quantum mechanics, such as contextuality\nand causality, to study ambiguities arising from linguistics. By doing so, we\nalso reproduced psycholinguistic results relating to the human disambiguation\nprocess. These results were subsequently used to predict human behaviour and\noutperformed current NLP methods.",
      "tldr_zh": "本论文受量子力学启发，运用contextuality和causality等形式主义分析人类处理自然语言模糊性的过程。\n研究通过这些量子灵感方法复制了心理语言学实验的结果，并将其应用于预测人类行为。\n结果显示，该方法在预测准确性上优于当前NLP模型，为NLP任务的量子优势提供了新见解。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LO",
        "quant-ph"
      ],
      "primary_category": "cs.CL",
      "comment": "PhD thesis",
      "pdf_url": "http://arxiv.org/pdf/2408.07402v1",
      "published_date": "2024-08-14 09:21:23 UTC",
      "updated_date": "2024-08-14 09:21:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:22:59.019503"
    },
    {
      "arxiv_id": "2408.07401v2",
      "title": "DataVisT5: A Pre-trained Language Model for Jointly Understanding Text and Data Visualization",
      "title_zh": "DataVisT5：一种用于联合",
      "authors": [
        "Zhuoyue Wan",
        "Yuanfeng Song",
        "Shuaimin Li",
        "Chen Jason Zhang",
        "Raymond Chi-Wing Wong"
      ],
      "abstract": "Data visualization (DV) is the fundamental and premise tool to improve the\nefficiency in conveying the insights behind the big data, which has been widely\naccepted in existing data-driven world. Task automation in DV, such as\nconverting natural language queries to visualizations (i.e., text-to-vis),\ngenerating explanations from visualizations (i.e., vis-to-text), answering\nDV-related questions in free form (i.e. FeVisQA), and explicating tabular data\n(i.e., table-to-text), is vital for advancing the field. Despite their\npotential, the application of pre-trained language models (PLMs) like T5 and\nBERT in DV has been limited by high costs and challenges in handling\ncross-modal information, leading to few studies on PLMs for DV. We introduce\nDataVisT5, a novel PLM tailored for DV that enhances the T5 architecture\nthrough a hybrid objective pre-training and multi-task fine-tuning strategy,\nintegrating text and DV datasets to effectively interpret cross-modal\nsemantics. Extensive evaluations on public datasets show that DataVisT5\nconsistently outperforms current state-of-the-art models on various DV-related\ntasks. We anticipate that DataVisT5 will not only inspire further research on\nvertical PLMs but also expand the range of applications for PLMs.",
      "tldr_zh": "该研究提出DataVisT5，一种针对数据可视化(DV)的预训练语言模型(PLM)，旨在联合理解文本和DV，以自动化任务如文本到可视化(text-to-vis)、可视化到文本(vis-to-text)以及FeVisQA等。\nDataVisT5基于T5架构，通过混合目标预训练和多任务微调策略，整合文本和DV数据集来有效处理跨模态语义。\n实验结果显示，DataVisT5在公共数据集上优于现有最先进模型，推动了垂直PLM的研究和应用扩展。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.07401v2",
      "published_date": "2024-08-14 09:20:17 UTC",
      "updated_date": "2024-11-27 17:42:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:23:13.764978"
    },
    {
      "arxiv_id": "2408.07395v1",
      "title": "Improving Global Parameter-sharing in Physically Heterogeneous Multi-agent Reinforcement Learning with Unified Action Space",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaoyang Yu",
        "Youfang Lin",
        "Shuo Wang",
        "Kai Lv",
        "Sheng Han"
      ],
      "abstract": "In a multi-agent system (MAS), action semantics indicates the different\ninfluences of agents' actions toward other entities, and can be used to divide\nagents into groups in a physically heterogeneous MAS. Previous multi-agent\nreinforcement learning (MARL) algorithms apply global parameter-sharing across\ndifferent types of heterogeneous agents without careful discrimination of\ndifferent action semantics. This common implementation decreases the\ncooperation and coordination between agents in complex situations. However,\nfully independent agent parameters dramatically increase the computational cost\nand training difficulty. In order to benefit from the usage of different action\nsemantics while also maintaining a proper parameter-sharing structure, we\nintroduce the Unified Action Space (UAS) to fulfill the requirement. The UAS is\nthe union set of all agent actions with different semantics. All agents first\ncalculate their unified representation in the UAS, and then generate their\nheterogeneous action policies using different available-action-masks. To\nfurther improve the training of extra UAS parameters, we introduce a\nCross-Group Inverse (CGI) loss to predict other groups' agent policies with the\ntrajectory information. As a universal method for solving the physically\nheterogeneous MARL problem, we implement the UAS adding to both value-based and\npolicy-based MARL algorithms, and propose two practical algorithms: U-QMIX and\nU-MAPPO. Experimental results in the SMAC environment prove the effectiveness\nof both U-QMIX and U-MAPPO compared with several state-of-the-art MARL methods.",
      "tldr_zh": "本文针对物理异构多智能体强化学习(MARL)中全局参数共享的问题，提出Unified Action Space (UAS)方法，将不同代理的行动语义整合为一个统一集合，允许代理先计算统一表示再生成异构策略，同时引入Cross-Group Inverse (CGI)损失来优化训练过程。基于此，论文开发了U-QMIX和U-MAPPO算法，这些算法在SMAC环境中表现出色，比现有MARL方法提高了代理间的合作和协调效果。实验结果证明了UAS在提升计算效率和性能方面的有效性。",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.07395v1",
      "published_date": "2024-08-14 09:15:11 UTC",
      "updated_date": "2024-08-14 09:15:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:23:25.278268"
    },
    {
      "arxiv_id": "2408.07394v2",
      "title": "Sum-Product-Set Networks: Deep Tractable Models for Tree-Structured Graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Milan Papež",
        "Martin Rektoris",
        "Tomáš Pevný",
        "Václav Šmídl"
      ],
      "abstract": "Daily internet communication relies heavily on tree-structured graphs,\nembodied by popular data formats such as XML and JSON. However, many recent\ngenerative (probabilistic) models utilize neural networks to learn a\nprobability distribution over undirected cyclic graphs. This assumption of a\ngeneric graph structure brings various computational challenges, and, more\nimportantly, the presence of non-linearities in neural networks does not permit\ntractable probabilistic inference. We address these problems by proposing\nsum-product-set networks, an extension of probabilistic circuits from\nunstructured tensor data to tree-structured graph data. To this end, we use\nrandom finite sets to reflect a variable number of nodes and edges in the graph\nand to allow for exact and efficient inference. We demonstrate that our\ntractable model performs comparably to various intractable models based on\nneural networks.",
      "tldr_zh": "该论文针对互联网通信中常见的树状结构图（如XML和JSON）提出sum-product-set networks，一种将probabilistic circuits扩展到树状图数据的深度可计算模型，以解决现有神经网络生成模型在处理无向循环图时面临的计算挑战和不可计算概率推理问题。该模型使用random finite sets来处理图中的可变节点和边，支持精确高效的推理。实验结果显示，sum-product-set networks的性能与各种基于神经网络的不可计算模型相当，为树状图数据的生成建模提供了可扩展的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.07394v2",
      "published_date": "2024-08-14 09:13:27 UTC",
      "updated_date": "2024-08-18 12:01:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:23:35.276748"
    },
    {
      "arxiv_id": "2408.07377v2",
      "title": "Do GPT Language Models Suffer From Split Personality Disorder? The Advent Of Substrate-Free Psychometrics",
      "title_zh": "翻译失败",
      "authors": [
        "Peter Romero",
        "Stephen Fitz",
        "Teruo Nakatsuma"
      ],
      "abstract": "Previous research on emergence in large language models shows these display\napparent human-like abilities and psychological latent traits. However, results\nare partly contradicting in expression and magnitude of these latent traits,\nyet agree on the worrisome tendencies to score high on the Dark Triad of\nnarcissism, psychopathy, and Machiavellianism, which, together with a track\nrecord of derailments, demands more rigorous research on safety of these\nmodels. We provided a state of the art language model with the same personality\nquestionnaire in nine languages, and performed Bayesian analysis of Gaussian\nMixture Model, finding evidence for a deeper-rooted issue. Our results suggest\nboth interlingual and intralingual instabilities, which indicate that current\nlanguage models do not develop a consistent core personality. This can lead to\nunsafe behaviour of artificial intelligence systems that are based on these\nfoundation models, and are increasingly integrated in human life. We\nsubsequently discuss the shortcomings of modern psychometrics, abstract it, and\nprovide a framework for its species-neutral, substrate-free formulation.",
      "tldr_zh": "本研究探讨了GPT语言模型是否像人类一样存在“分裂人格”问题，通过测试模型在九种语言下的个性问卷并运用Bayesian分析和Gaussian Mixture Model，发现这些模型表现出interlingual和intralingual不稳定性，表明它们缺乏一致的核心个性，尤其在Dark Triad（自恋、精神病态和马基雅维利主义）上得分偏高，可能导致AI系统行为不安全。作者分析了现代psychometrics的缺点，并提出一个物种中立、substrate-free的框架，以改进跨物种心理测量方法。该框架为评估AI心理特质提供新途径，有助于提升语言模型的安全性和可靠性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "37 pages, 7 figures, 3 tables, date v1: Mar 26 2023; replaced with\n  new version; reason: removed journal logo from older version of article that\n  is no longer valid",
      "pdf_url": "http://arxiv.org/pdf/2408.07377v2",
      "published_date": "2024-08-14 08:53:00 UTC",
      "updated_date": "2024-08-15 05:15:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:23:48.521374"
    },
    {
      "arxiv_id": "2408.07718v1",
      "title": "Impact of Inaccurate Contamination Ratio on Robust Unsupervised Anomaly Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Jordan F. Masakuna",
        "DJeff Kanda Nkashama",
        "Arian Soltani",
        "Marc Frappier",
        "Pierre-Martin Tardif",
        "Froduald Kabanza"
      ],
      "abstract": "Training data sets intended for unsupervised anomaly detection, typically\npresumed to be anomaly-free, often contain anomalies (or contamination), a\nchallenge that significantly undermines model performance. Most robust\nunsupervised anomaly detection models rely on contamination ratio information\nto tackle contamination. However, in reality, contamination ratio may be\ninaccurate. We investigate on the impact of inaccurate contamination ratio\ninformation in robust unsupervised anomaly detection. We verify whether they\nare resilient to misinformed contamination ratios. Our investigation on 6\nbenchmark data sets reveals that such models are not adversely affected by\nexposure to misinformation. In fact, they can exhibit improved performance when\nprovided with such inaccurate contamination ratios.",
      "tldr_zh": "这篇论文探讨了不准确的contamination ratio对robust unsupervised anomaly detection的影响，因为训练数据通常包含未预期的anomalies（异常），这会损害模型性能。作者通过在6个基准数据集上进行调查，验证了现有鲁棒模型对misinformed contamination ratios的韧性。研究发现，这些模型不仅未受负面影响，反而在某些情况下表现出改善的性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "This is an accepted extended abstract at Black in AI Workshop which\n  will be co-located with NeurIPS 2024 in Canada",
      "pdf_url": "http://arxiv.org/pdf/2408.07718v1",
      "published_date": "2024-08-14 08:49:41 UTC",
      "updated_date": "2024-08-14 08:49:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:23:58.975990"
    },
    {
      "arxiv_id": "2408.11851v1",
      "title": "SAGE-RT: Synthetic Alignment data Generation for Safety Evaluation and Red Teaming",
      "title_zh": "SAGE-RT：用于安全评估和红队测试的合成对齐数据生成",
      "authors": [
        "Anurakt Kumar",
        "Divyanshu Kumar",
        "Jatan Loya",
        "Nitin Aravind Birur",
        "Tanay Baswa",
        "Sahil Agarwal",
        "Prashanth Harshangi"
      ],
      "abstract": "We introduce Synthetic Alignment data Generation for Safety Evaluation and\nRed Teaming (SAGE-RT or SAGE) a novel pipeline for generating synthetic\nalignment and red-teaming data. Existing methods fall short in creating nuanced\nand diverse datasets, providing necessary control over the data generation and\nvalidation processes, or require large amount of manually generated seed data.\nSAGE addresses these limitations by using a detailed taxonomy to produce\nsafety-alignment and red-teaming data across a wide range of topics. We\ngenerated 51,000 diverse and in-depth prompt-response pairs, encompassing over\n1,500 topics of harmfulness and covering variations of the most frequent types\nof jailbreaking prompts faced by large language models (LLMs). We show that the\nred-teaming data generated through SAGE jailbreaks state-of-the-art LLMs in\nmore than 27 out of 32 sub-categories, and in more than 58 out of 279\nleaf-categories (sub-sub categories). The attack success rate for GPT-4o,\nGPT-3.5-turbo is 100% over the sub-categories of harmfulness. Our approach\navoids the pitfalls of synthetic safety-training data generation such as mode\ncollapse and lack of nuance in the generation pipeline by ensuring a detailed\ncoverage of harmful topics using iterative expansion of the topics and\nconditioning the outputs on the generated raw-text. This method can be used to\ngenerate red-teaming and alignment data for LLM Safety completely synthetically\nto make LLMs safer or for red-teaming the models over a diverse range of\ntopics.",
      "tldr_zh": "本文提出了一种名为 SAGE-RT 的合成对齐数据生成管道，用于安全评估和红队测试（Red Teaming），它通过详细的 taxonomy 解决现有方法的局限性，如数据多样性不足和对生成过程的控制缺失。SAGE 生成了超过 51,000 个多样化的提示-响应对，涵盖 1,500 多个有害主题，并针对大型语言模型（LLMs）常见越狱提示进行变体扩展；实验显示，该数据在 32 个子类别中成功越狱超过 27 个，且在 GPT-4o 和 GPT-3.5-turbo 上实现 100% 的攻击成功率。该方法通过迭代主题扩展和基于原始文本的条件输出，避免了合成数据生成的模式崩溃等问题，从而为完全合成的 LLM 安全训练和红队测试提供高效工具。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CR"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.11851v1",
      "published_date": "2024-08-14 08:38:31 UTC",
      "updated_date": "2024-08-14 08:38:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:24:14.549929"
    },
    {
      "arxiv_id": "2408.07368v1",
      "title": "The Complexity of Manipulation of k-Coalitional Games on Graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Hodaya Barr",
        "Yohai Trabelsi",
        "Sarit Kraus",
        "Liam Roditty",
        "Noam Hazon"
      ],
      "abstract": "In many settings, there is an organizer who would like to divide a set of\nagents into $k$ coalitions, and cares about the friendships within each\ncoalition. Specifically, the organizer might want to maximize utilitarian\nsocial welfare, maximize egalitarian social welfare, or simply guarantee that\nevery agent will have at least one friend within his coalition. However, in\nmany situations, the organizer is not familiar with the friendship connections,\nand he needs to obtain them from the agents. In this setting, a manipulative\nagent may falsely report friendship connections in order to increase his\nutility. In this paper, we analyze the complexity of finding manipulation in\nsuch $k$-coalitional games on graphs. We also introduce a new type of\nmanipulation, socially-aware manipulation, in which the manipulator would like\nto increase his utility without decreasing the social welfare. We then study\nthe complexity of finding socially-aware manipulation in our setting. Finally,\nwe examine the frequency of socially-aware manipulation and the running time of\nour algorithms via simulation results.",
      "tldr_zh": "这篇论文研究了在图上的 k-Coalitional Games 中，代理人对友谊连接的操纵复杂性，特别是在组织者试图最大化 utilitarian social welfare、egalitarian social welfare 或确保每个代理人有至少一个朋友时。论文分析了代理人虚假报告友谊以增加自身效用的操纵行为，并引入了 socially-aware manipulation 的新概念，该概念要求操纵不降低整体社会福利。最终，通过复杂性分析和模拟实验，论文探讨了 socially-aware manipulation 的频率和算法运行时间，为理解此类游戏中的策略行为提供了理论基础。",
      "categories": [
        "cs.GT",
        "cs.AI"
      ],
      "primary_category": "cs.GT",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.07368v1",
      "published_date": "2024-08-14 08:29:30 UTC",
      "updated_date": "2024-08-14 08:29:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:24:24.454823"
    },
    {
      "arxiv_id": "2408.16008v2",
      "title": "Novel Methods for Analyzing Cellular Interactions in Deep Learning-Based Image Cytometry: Spatial Interaction Potential and Co-Localization Index",
      "title_zh": "翻译失败",
      "authors": [
        "Toru Nagasaka",
        "Kimihiro Yamashita",
        "Mitsugu Fujita"
      ],
      "abstract": "The study presents a novel approach for quantifying cellular interactions in\ndigital pathology using deep learning-based image cytometry. Traditional\nmethods struggle with the diversity and heterogeneity of cells within tissues.\nTo address this, we introduce the Spatial Interaction Potential (SIP) and the\nCo-Localization Index (CLI), leveraging deep learning classification\nprobabilities. SIP assesses the potential for cell-to-cell interactions,\nsimilar to an electric field, while CLI incorporates distances between cells,\naccounting for dynamic cell movements. Our approach enhances traditional\nmethods, providing a more sophisticated analysis of cellular interactions. We\nvalidate SIP and CLI through simulations and apply them to colorectal cancer\nspecimens, demonstrating strong correlations with actual biological data. This\ninnovative method offers significant improvements in understanding cellular\ninteractions and has potential applications in various fields of digital\npathology.",
      "tldr_zh": "本研究提出了一种新型方法，用于基于深度学习的图像细胞测量（deep learning-based image cytometry）中量化数字病理学中的细胞互动，旨在解决传统方法对细胞多样性和异质性的处理难题。  \n他们引入了 Spatial Interaction Potential (SIP) 和 Co-Localization Index (CLI) 两个指标：SIP 类似于电场，评估细胞间互动潜力；CLI 则整合细胞间距离并考虑动态细胞运动，提供更先进的分析。  \n通过模拟和应用到结肠癌样本的验证，该方法展示了与实际生物数据的强相关性，并显著提升了细胞互动的分析精度。  \n这项创新有望在数字病理学领域广泛应用，推动对细胞互动的深入理解。",
      "categories": [
        "q-bio.QM",
        "cs.AI"
      ],
      "primary_category": "q-bio.QM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.16008v2",
      "published_date": "2024-08-14 08:07:17 UTC",
      "updated_date": "2024-08-30 13:42:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:24:38.624998"
    },
    {
      "arxiv_id": "2408.07344v1",
      "title": "RTAT: A Robust Two-stage Association Tracker for Multi-Object Tracking",
      "title_zh": "翻译失败",
      "authors": [
        "Song Guo",
        "Rujie Liu",
        "Narishige Abe"
      ],
      "abstract": "Data association is an essential part in the tracking-by-detection based\nMulti-Object Tracking (MOT). Most trackers focus on how to design a better data\nassociation strategy to improve the tracking performance. The rule-based\nhandcrafted association methods are simple and highly efficient but lack\ngeneralization capability to deal with complex scenes. While the learnt\nassociation methods can learn high-order contextual information to deal with\nvarious complex scenes, but they have the limitations of higher complexity and\ncost. To address these limitations, we propose a Robust Two-stage Association\nTracker, named RTAT. The first-stage association is performed between tracklets\nand detections to generate tracklets with high purity, and the second-stage\nassociation is performed between tracklets to form complete trajectories. For\nthe first-stage association, we use a simple data association strategy to\ngenerate tracklets with high purity by setting a low threshold for the matching\ncost in the assignment process. We conduct the tracklet association in the\nsecond-stage based on the framework of message-passing GNN. Our method models\nthe tracklet association as a series of edge classification problem in\nhierarchical graphs, which can recursively merge short tracklets into longer\nones. Our tracker RTAT ranks first on the test set of MOT17 and MOT20\nbenchmarks in most of the main MOT metrics: HOTA, IDF1, and AssA. We achieve\n67.2 HOTA, 84.7 IDF1, and 69.7 AssA on MOT17, and 66.2 HOTA, 82.5 IDF1, and\n68.1 AssA on MOT20.",
      "tldr_zh": "该论文提出 RTAT，一种鲁棒的两阶段关联跟踪器，用于多目标跟踪（MOT），旨在解决基于规则方法缺乏泛化和学习方法复杂度高的局限性。第一阶段通过简单的数据关联策略和低阈值，在轨迹片段（tracklets）和检测之间生成高纯度轨迹片段；第二阶段则使用消息传递 GNN（Graph Neural Network）框架，将轨迹片段关联建模为层次图中的边分类问题，实现递归合并以形成完整轨迹。在 MOT17 和 MOT20 基准测试中，RTAT 在主要指标上排名第一，分别取得 67.2 HOTA、84.7 IDF1 和 69.7 AssA（MOT17），以及 66.2 HOTA、82.5 IDF1 和 68.1 AssA（MOT20）。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "ICPR2024",
      "pdf_url": "http://arxiv.org/pdf/2408.07344v1",
      "published_date": "2024-08-14 07:37:24 UTC",
      "updated_date": "2024-08-14 07:37:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:24:52.322253"
    },
    {
      "arxiv_id": "2408.07341v2",
      "title": "Robust Semi-supervised Multimodal Medical Image Segmentation via Cross Modality Collaboration",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaogen Zhou",
        "Yiyou Sun",
        "Min Deng",
        "Winnie Chiu Wing Chu",
        "Qi Dou"
      ],
      "abstract": "Multimodal learning leverages complementary information derived from\ndifferent modalities, thereby enhancing performance in medical image\nsegmentation. However, prevailing multimodal learning methods heavily rely on\nextensive well-annotated data from various modalities to achieve accurate\nsegmentation performance. This dependence often poses a challenge in clinical\nsettings due to limited availability of such data. Moreover, the inherent\nanatomical misalignment between different imaging modalities further\ncomplicates the endeavor to enhance segmentation performance. To address this\nproblem, we propose a novel semi-supervised multimodal segmentation framework\nthat is robust to scarce labeled data and misaligned modalities. Our framework\nemploys a novel cross modality collaboration strategy to distill\nmodality-independent knowledge, which is inherently associated with each\nmodality, and integrates this information into a unified fusion layer for\nfeature amalgamation. With a channel-wise semantic consistency loss, our\nframework ensures alignment of modality-independent information from a\nfeature-wise perspective across modalities, thereby fortifying it against\nmisalignments in multimodal scenarios. Furthermore, our framework effectively\nintegrates contrastive consistent learning to regulate anatomical structures,\nfacilitating anatomical-wise prediction alignment on unlabeled data in\nsemi-supervised segmentation tasks. Our method achieves competitive performance\ncompared to other multimodal methods across three tasks: cardiac, abdominal\nmulti-organ, and thyroid-associated orbitopathy segmentations. It also\ndemonstrates outstanding robustness in scenarios involving scarce labeled data\nand misaligned modalities.",
      "tldr_zh": "该论文提出了一种鲁棒的半监督多模态医疗图像分割框架，通过Cross Modality Collaboration策略来应对标注数据稀缺和模态不对齐问题。该框架提取模态无关知识并整合到统一融合层中，同时使用通道-wise语义一致性损失和对比一致性学习，确保特征和解剖结构的跨模态对齐，从而提升无标签数据的分割性能。在心脏、腹部多器官和甲状腺相关眼病分割任务中，该方法表现出色，并在数据稀缺或模态不对齐场景下比其他多模态方法具有更强的鲁棒性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.07341v2",
      "published_date": "2024-08-14 07:34:12 UTC",
      "updated_date": "2024-09-04 03:22:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:25:02.014949"
    },
    {
      "arxiv_id": "2408.07340v1",
      "title": "Towards Few-shot Self-explaining Graph Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Jingyu Peng",
        "Qi Liu",
        "Linan Yue",
        "Zaixi Zhang",
        "Kai Zhang",
        "Yunhao Sha"
      ],
      "abstract": "Recent advancements in Graph Neural Networks (GNNs) have spurred an upsurge\nof research dedicated to enhancing the explainability of GNNs, particularly in\ncritical domains such as medicine. A promising approach is the self-explaining\nmethod, which outputs explanations along with predictions. However, existing\nself-explaining models require a large amount of training data, rendering them\nunavailable in few-shot scenarios. To address this challenge, in this paper, we\npropose a Meta-learned Self-Explaining GNN (MSE-GNN), a novel framework that\ngenerates explanations to support predictions in few-shot settings. MSE-GNN\nadopts a two-stage self-explaining structure, consisting of an explainer and a\npredictor. Specifically, the explainer first imitates the attention mechanism\nof humans to select the explanation subgraph, whereby attention is naturally\npaid to regions containing important characteristics. Subsequently, the\npredictor mimics the decision-making process, which makes predictions based on\nthe generated explanation. Moreover, with a novel meta-training process and a\ndesigned mechanism that exploits task information, MSE-GNN can achieve\nremarkable performance on new few-shot tasks. Extensive experimental results on\nfour datasets demonstrate that MSE-GNN can achieve superior performance on\nprediction tasks while generating high-quality explanations compared with\nexisting methods. The code is publicly available at\nhttps://github.com/jypeng28/MSE-GNN.",
      "tldr_zh": "这篇论文针对 Graph Neural Networks (GNNs) 的可解释性问题，提出了一种 Meta-learned Self-Explaining GNN (MSE-GNN) 框架，以支持 few-shot 场景下的预测和解释生成。MSE-GNN 采用两阶段结构，包括 explainer（模仿人类注意力机制选择解释子图）和 predictor（基于子图进行决策），并通过元训练过程和任务信息机制提升在新任务上的性能。实验结果显示，该框架在四个数据集上实现了优于现有方法的预测准确性和解释质量，代码已在 GitHub 上公开。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.07340v1",
      "published_date": "2024-08-14 07:31:11 UTC",
      "updated_date": "2024-08-14 07:31:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:25:15.758813"
    },
    {
      "arxiv_id": "2408.07327v1",
      "title": "An Offline Meta Black-box Optimization Framework for Adaptive Design of Urban Traffic Light Management Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Taeyoung Yun",
        "Kanghoon Lee",
        "Sujin Yun",
        "Ilmyung Kim",
        "Won-Woo Jung",
        "Min-Cheol Kwon",
        "Kyujin Choi",
        "Yoohyeon Lee",
        "Jinkyoo Park"
      ],
      "abstract": "Complex urban road networks with high vehicle occupancy frequently face\nsevere traffic congestion. Designing an effective strategy for managing\nmultiple traffic lights plays a crucial role in managing congestion. However,\nmost current traffic light management systems rely on human-crafted decisions,\nwhich may not adapt well to diverse traffic patterns. In this paper, we delve\ninto two pivotal design components of the traffic light management system that\ncan be dynamically adjusted to various traffic conditions: phase combination\nand phase time allocation. While numerous studies have sought an efficient\nstrategy for managing traffic lights, most of these approaches consider a fixed\ntraffic pattern and are limited to relatively small road networks. To overcome\nthese limitations, we introduce a novel and practical framework to formulate\nthe optimization of such design components using an offline meta black-box\noptimization. We then present a simple yet effective method to efficiently find\na solution for the aforementioned problem. In our framework, we first collect\nan offline meta dataset consisting of pairs of design choices and corresponding\ncongestion measures from various traffic patterns. After collecting the\ndataset, we employ the Attentive Neural Process (ANP) to predict the impact of\nthe proposed design on congestion across various traffic patterns with\nwell-calibrated uncertainty. Finally, Bayesian optimization, with ANP as a\nsurrogate model, is utilized to find an optimal design for unseen traffic\npatterns through limited online simulations. Our experiment results show that\nour method outperforms state-of-the-art baselines on complex road networks in\nterms of the number of waiting vehicles. Surprisingly, the deployment of our\nmethod into a real-world traffic system was able to improve traffic throughput\nby 4.80\\% compared to the original strategy.",
      "tldr_zh": "该论文提出一个离线元黑箱优化（offline meta black-box optimization）框架，用于适应性设计城市交通灯管理系统，针对相位组合（phase combination）和相位时间分配（phase time allocation）等关键组件，以应对多样化交通模式的拥堵问题。框架首先收集离线元数据集，然后使用 Attentive Neural Process (ANP) 预测设计方案对不同交通模式的影响，并通过 Bayesian optimization 以 ANP 作为代理模型，在有限的在线模拟中找到最优设计。实验结果显示，该方法在复杂路网中显著减少等待车辆数量，并在实际部署中将交通通过量提高了 4.80%，优于现有基线。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "12 pages, 7 figures, 10 tables",
      "pdf_url": "http://arxiv.org/pdf/2408.07327v1",
      "published_date": "2024-08-14 06:57:58 UTC",
      "updated_date": "2024-08-14 06:57:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:25:26.649505"
    },
    {
      "arxiv_id": "2408.07324v1",
      "title": "On-the-fly Synthesis for LTL over Finite Traces: An Efficient Approach that Counts",
      "title_zh": "翻译失败",
      "authors": [
        "Shengping Xiao",
        "Yongkang Li",
        "Shufang Zhu",
        "Jun Sun",
        "Jianwen Li",
        "Geguang Pu",
        "Moshe Y. Vardi"
      ],
      "abstract": "We present an on-the-fly synthesis framework for Linear Temporal Logic over\nfinite traces (LTLf) based on top-down deterministic automata construction.\nExisting approaches rely on constructing a complete Deterministic Finite\nAutomaton (DFA) corresponding to the LTLf specification, a process with doubly\nexponential complexity relative to the formula size in the worst case. In this\ncase, the synthesis procedure cannot be conducted until the entire DFA is\nconstructed. This inefficiency is the main bottleneck of existing approaches.\nTo address this challenge, we first present a method for converting LTLf into\nTransition-based DFA (TDFA) by directly leveraging LTLf semantics,\nincorporating intermediate results as direct components of the final automaton\nto enable parallelized synthesis and automata construction. We then explore the\nrelationship between LTLf synthesis and TDFA games and subsequently develop an\nalgorithm for performing LTLf synthesis using on-the-fly TDFA game solving.\nThis algorithm traverses the state space in a global forward manner combined\nwith a local backward method, along with the detection of strongly connected\ncomponents. Moreover, we introduce two optimization techniques -- model-guided\nsynthesis and state entailment -- to enhance the practical efficiency of our\napproach. Experimental results demonstrate that our on-the-fly approach\nachieves the best performance on the tested benchmarks and effectively\ncomplements existing tools and approaches.",
      "tldr_zh": "本研究提出了一种高效的 on-the-fly 合成框架，用于 Linear Temporal Logic over finite traces (LTLf)，基于顶层确定性自动机构造，以解决现有方法依赖完整 Deterministic Finite Automaton (DFA) 构建导致的双重指数复杂度瓶颈。框架首先将 LTLf 转换为 Transition-based DFA (TDFA)，利用 LTLf 语义整合中间结果，支持并行化合成和自动机构造，并探索 LTLf 合成与 TDFA 游戏的关系。算法采用全局前向遍历结合局部后向方法，以及强连通组件检测，同时引入 model-guided synthesis 和 state entailment 等优化技术。实验结果显示，该方法在基准测试中表现出最佳性能，并有效补充现有工具。",
      "categories": [
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "32 pages, 3 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2408.07324v1",
      "published_date": "2024-08-14 06:52:58 UTC",
      "updated_date": "2024-08-14 06:52:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:25:38.049932"
    },
    {
      "arxiv_id": "2408.07314v3",
      "title": "Kolmogorov-Arnold Networks (KAN) for Time Series Classification and Robust Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Chang Dong",
        "Liangwei Zheng",
        "Weitong Chen"
      ],
      "abstract": "Kolmogorov-Arnold Networks (KAN) has recently attracted significant attention\nas a promising alternative to traditional Multi-Layer Perceptrons (MLP).\nDespite their theoretical appeal, KAN require validation on large-scale\nbenchmark datasets. Time series data, which has become increasingly prevalent\nin recent years, especially univariate time series are naturally suited for\nvalidating KAN. Therefore, we conducted a fair comparison among KAN, MLP, and\nmixed structures. The results indicate that KAN can achieve performance\ncomparable to, or even slightly better than, MLP across 128 time series\ndatasets. We also performed an ablation study on KAN, revealing that the output\nis primarily determined by the base component instead of b-spline function.\nFurthermore, we assessed the robustness of these models and found that KAN and\nthe hybrid structure MLP\\_KAN exhibit significant robustness advantages,\nattributed to their lower Lipschitz constants. This suggests that KAN and KAN\nlayers hold strong potential to be robust models or to improve the adversarial\nrobustness of other models.",
      "tldr_zh": "这篇论文评估了Kolmogorov-Arnold Networks (KAN)作为传统Multi-Layer Perceptrons (MLP)的替代方案，在时间序列分类中的性能。研究者在128个时间序列数据集上进行公平比较，发现KAN的准确率与MLP相当或略高，且通过消融研究揭示KAN的输出主要由基础组件决定，而非b-spline函数。论文进一步证明，KAN和混合结构（如MLP_KAN）具有显著的鲁棒性优势，归因于较低的Lipschitz constants，从而为提升模型的对抗鲁棒性提供了潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "I.2.0"
      ],
      "primary_category": "cs.LG",
      "comment": "14 pages, 8 figs",
      "pdf_url": "http://arxiv.org/pdf/2408.07314v3",
      "published_date": "2024-08-14 06:15:55 UTC",
      "updated_date": "2024-09-11 05:10:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:25:50.760942"
    },
    {
      "arxiv_id": "2408.07292v1",
      "title": "LiPCoT: Linear Predictive Coding based Tokenizer for Self-supervised Learning of Time Series Data via Language Models",
      "title_zh": "LiPC",
      "authors": [
        "Md Fahim Anjum"
      ],
      "abstract": "Language models have achieved remarkable success in various natural language\nprocessing tasks. However, their application to time series data, a crucial\ncomponent in many domains, remains limited. This paper proposes LiPCoT (Linear\nPredictive Coding based Tokenizer for time series), a novel tokenizer that\nencodes time series data into a sequence of tokens, enabling self-supervised\nlearning of time series using existing Language model architectures such as\nBERT. Unlike traditional time series tokenizers that rely heavily on CNN\nencoder for time series feature generation, LiPCoT employs stochastic modeling\nthrough linear predictive coding to create a latent space for time series\nproviding a compact yet rich representation of the inherent stochastic nature\nof the data. Furthermore, LiPCoT is computationally efficient and can\neffectively handle time series data with varying sampling rates and lengths,\novercoming common limitations of existing time series tokenizers. In this\nproof-of-concept work, we present the effectiveness of LiPCoT in classifying\nParkinson's disease (PD) using an EEG dataset from 46 participants. In\nparticular, we utilize LiPCoT to encode EEG data into a small vocabulary of\ntokens and then use BERT for self-supervised learning and the downstream task\nof PD classification. We benchmark our approach against several\nstate-of-the-art CNN-based deep learning architectures for PD detection. Our\nresults reveal that BERT models utilizing self-supervised learning outperformed\nthe best-performing existing method by 7.1% in precision, 2.3% in recall, 5.5%\nin accuracy, 4% in AUC, and 5% in F1-score highlighting the potential for\nself-supervised learning even on small datasets. Our work will inform future\nfoundational models for time series, particularly for self-supervised learning.",
      "tldr_zh": "本论文提出 LiPCoT，一种基于 Linear Predictive Coding 的分词器，用于将时间序列数据编码成 token 序列，从而支持现有语言模型（如 BERT）进行自监督学习。\nLiPCoT 通过随机建模创建紧凑的潜在空间，提供丰富的表示，同时计算高效，并能处理不同采样率和长度的序列，克服了传统依赖 CNN 的分词器局限。\n在帕金森病分类任务中，LiPCoT 编码 EEG 数据后结合 BERT 进行自监督学习，相比最先进的 CNN 方法，精度提升 7.1%、准确率 5.5%、AUC 提升 4%，证明其在小数据集上的有效性。\n这项工作为时间序列数据的自监督学习提供新基础。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "17 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.07292v1",
      "published_date": "2024-08-14 04:51:33 UTC",
      "updated_date": "2024-08-14 04:51:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:26:03.690140"
    },
    {
      "arxiv_id": "2408.07272v2",
      "title": "Abstract Operations Research Modeling Using Natural Language Inputs",
      "title_zh": "翻译失败",
      "authors": [
        "Junxuan Li",
        "Ryan Wickman",
        "Sahil Bhatnagar",
        "Raj Kumar Maity",
        "Arko Mukherjee"
      ],
      "abstract": "Operations research (OR) uses mathematical models to enhance decision-making,\nbut developing these models requires expert knowledge and can be\ntime-consuming. Automated mathematical programming (AMP) has emerged to\nsimplify this process, but existing systems have limitations. This paper\nintroduces a novel methodology that uses recent advances in Large Language\nModel (LLM) to create and edit OR solutions from non-expert user queries\nexpressed using Natural Language. This reduces the need for domain expertise\nand the time to formulate a problem. The paper presents an end-to-end pipeline,\nnamed NL2OR, that generates solutions to OR problems from natural language\ninput, and shares experimental results on several important OR problems.",
      "tldr_zh": "这篇论文解决了Operations Research (OR)建模过程需要专家知识且耗时的挑战，提出了一种新方法，利用Large Language Model (LLM)的最新进展，从非专家用户的自然语言查询中自动创建和编辑OR解决方案。论文引入了一个端到端管道，名为NL2OR，能够从自然语言输入生成OR问题的解决方案，从而减少领域专长的需求和问题表述时间。实验结果在多个重要OR问题上验证了该方法的有效性。",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.07272v2",
      "published_date": "2024-08-14 03:42:53 UTC",
      "updated_date": "2025-01-28 18:40:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:26:14.777921"
    },
    {
      "arxiv_id": "2408.07262v3",
      "title": "Ensemble architecture in polyp segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Hao-Yun Hsu",
        "Yi-Ching Cheng",
        "Guan-Hua Huang"
      ],
      "abstract": "This study explored the architecture of semantic segmentation and evaluated\nmodels that excel in polyp segmentation. We present an integrated framework\nthat harnesses the advantages of different models to attain an optimal outcome.\nSpecifically, in this framework, we fuse the learned features from\nconvolutional and transformer models for prediction, thus engendering an\nensemble technique to enhance model performance. Our experiments on polyp\nsegmentation revealed that the proposed architecture surpassed other top\nmodels, exhibiting improved learning capacity and resilience. The code is\navailable at https://github.com/HuangDLab/EnFormer.",
      "tldr_zh": "这篇论文探讨了在息肉分割(polyp segmentation)中的集成架构(ensemble architecture)，提出一个集成框架来利用不同模型的优势，实现最佳分割效果。具体来说，该框架通过融合卷积(convolutional)模型和Transformer模型的特征进行预测，从而提升整体性能。在息肉分割的实验中，该架构超过了其他顶级模型，展示了更强的学习能力和鲁棒性。代码已在GitHub上开源（https://github.com/HuangDLab/EnFormer）。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "13 pages, 3 figures, and 7 tables",
      "pdf_url": "http://arxiv.org/pdf/2408.07262v3",
      "published_date": "2024-08-14 02:57:38 UTC",
      "updated_date": "2024-10-25 02:00:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:26:25.718760"
    },
    {
      "arxiv_id": "2408.07259v1",
      "title": "GRIF-DM: Generation of Rich Impression Fonts using Diffusion Models",
      "title_zh": "GRIF-DM：使用扩散模型生成富有印象的字体",
      "authors": [
        "Lei Kang",
        "Fei Yang",
        "Kai Wang",
        "Mohamed Ali Souibgui",
        "Lluis Gomez",
        "Alicia Fornés",
        "Ernest Valveny",
        "Dimosthenis Karatzas"
      ],
      "abstract": "Fonts are integral to creative endeavors, design processes, and artistic\nproductions. The appropriate selection of a font can significantly enhance\nartwork and endow advertisements with a higher level of expressivity. Despite\nthe availability of numerous diverse font designs online, traditional\nretrieval-based methods for font selection are increasingly being supplanted by\ngeneration-based approaches. These newer methods offer enhanced flexibility,\ncatering to specific user preferences and capturing unique stylistic\nimpressions. However, current impression font techniques based on Generative\nAdversarial Networks (GANs) necessitate the utilization of multiple auxiliary\nlosses to provide guidance during generation. Furthermore, these methods\ncommonly employ weighted summation for the fusion of impression-related\nkeywords. This leads to generic vectors with the addition of more impression\nkeywords, ultimately lacking in detail generation capacity. In this paper, we\nintroduce a diffusion-based method, termed \\ourmethod, to generate fonts that\nvividly embody specific impressions, utilizing an input consisting of a single\nletter and a set of descriptive impression keywords. The core innovation of\n\\ourmethod lies in the development of dual cross-attention modules, which\nprocess the characteristics of the letters and impression keywords\nindependently but synergistically, ensuring effective integration of both types\nof information. Our experimental results, conducted on the MyFonts dataset,\naffirm that this method is capable of producing realistic, vibrant, and\nhigh-fidelity fonts that are closely aligned with user specifications. This\nconfirms the potential of our approach to revolutionize font generation by\naccommodating a broad spectrum of user-driven design requirements. Our code is\npublicly available at \\url{https://github.com/leitro/GRIF-DM}.",
      "tldr_zh": "该论文探讨了字体生成技术的演进，指出现有基于Generative Adversarial Networks (GANs)的方法依赖多辅助损失和加权求和，导致处理印象关键词时细节不足。论文提出GRIF-DM，一种基于Diffusion Models的创新框架，使用双重交叉注意力模块（dual cross-attention modules）来独立处理输入字母和描述性关键词，并实现协同整合，从而生成生动、逼真的字体。实验在MyFonts数据集上验证了GRIF-DM的效能，其生成的字体高度符合用户规格，并展示了在个性化设计领域的革命性潜力。代码已在GitHub上公开。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to ECAI2024",
      "pdf_url": "http://arxiv.org/pdf/2408.07259v1",
      "published_date": "2024-08-14 02:26:46 UTC",
      "updated_date": "2024-08-14 02:26:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:26:41.326893"
    },
    {
      "arxiv_id": "2409.00001v1",
      "title": "Evaluating Explainable AI Methods in Deep Learning Models for Early Detection of Cerebral Palsy",
      "title_zh": "翻译失败",
      "authors": [
        "Kimji N. Pellano",
        "Inga Strümke",
        "Daniel Groos",
        "Lars Adde",
        "Espen Alexander F. Ihlen"
      ],
      "abstract": "Early detection of Cerebral Palsy (CP) is crucial for effective intervention\nand monitoring. This paper tests the reliability and applicability of\nExplainable AI (XAI) methods using a deep learning method that predicts CP by\nanalyzing skeletal data extracted from video recordings of infant movements.\nSpecifically, we use XAI evaluation metrics -- namely faithfulness and\nstability -- to quantitatively assess the reliability of Class Activation\nMapping (CAM) and Gradient-weighted Class Activation Mapping (Grad-CAM) in this\nspecific medical application. We utilize a unique dataset of infant movements\nand apply skeleton data perturbations without distorting the original dynamics\nof the infant movements. Our CP prediction model utilizes an ensemble approach,\nso we evaluate the XAI metrics performances for both the overall ensemble and\nthe individual models. Our findings indicate that both XAI methods effectively\nidentify key body points influencing CP predictions and that the explanations\nare robust against minor data perturbations. Grad-CAM significantly outperforms\nCAM in the RISv metric, which measures stability in terms of velocity. In\ncontrast, CAM performs better in the RISb metric, which relates to bone\nstability, and the RRS metric, which assesses internal representation\nrobustness. Individual models within the ensemble show varied results, and\nneither CAM nor Grad-CAM consistently outperform the other, with the ensemble\napproach providing a representation of outcomes from its constituent models.",
      "tldr_zh": "本研究评估了Explainable AI (XAI) 方法在深度学习模型中用于大脑性麻痹 (Cerebral Palsy, CP) 早期检测的可信度和适用性，通过分析婴儿运动视频中的骨骼数据构建预测模型。研究聚焦于Class Activation Mapping (CAM) 和Gradient-weighted Class Activation Mapping (Grad-CAM)，使用faithfulness 和 stability 等指标量化评估这些方法在集成模型（ensemble approach）和单个模型中的表现。结果显示，Grad-CAM 在RISv（速度稳定性）指标上显著优于CAM，而CAM 在RISb（骨骼稳定性）和RRS（内部表示鲁棒性）指标上表现更好；整体而言，XAI 方法能有效识别关键身体点并对轻微数据扰动保持鲁棒性，为CP 早期诊断提供可靠解释。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.00001v1",
      "published_date": "2024-08-14 00:27:09 UTC",
      "updated_date": "2024-08-14 00:27:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:26:53.147097"
    },
    {
      "arxiv_id": "2408.07239v1",
      "title": "Enhancing Autonomous Vehicle Perception in Adverse Weather through Image Augmentation during Semantic Segmentation Training",
      "title_zh": "通过图像增强在语义分割训练中提升自动驾驶车辆在恶劣天气下的感知能力",
      "authors": [
        "Ethan Kou",
        "Noah Curran"
      ],
      "abstract": "Robust perception is crucial in autonomous vehicle navigation and\nlocalization. Visual processing tasks, like semantic segmentation, should work\nin varying weather conditions and during different times of day. Semantic\nsegmentation is where each pixel is assigned a class, which is useful for\nlocating overall features (1). Training a segmentation model requires large\namounts of data, and the labeling process for segmentation data is especially\ntedious. Additionally, many large datasets include only images taken in clear\nweather. This is a problem because training a model exclusively on clear\nweather data hinders performance in adverse weather conditions like fog or\nrain. We hypothesize that given a dataset of only clear days images, applying\nimage augmentation (such as random rain, fog, and brightness) during training\nallows for domain adaptation to diverse weather conditions. We used CARLA, a 3D\nrealistic autonomous vehicle simulator, to collect 1200 images in clear weather\ncomposed of 29 classes from 10 different towns (2). We also collected 1200\nimages of random weather effects. We trained encoder-decoder UNet models to\nperform semantic segmentation. Applying augmentations significantly improved\nsegmentation under weathered night conditions (p < 0.001). However, models\ntrained on weather data have significantly lower losses than those trained on\naugmented data in all conditions except for clear days. This shows there is\nroom for improvement in the domain adaptation approach. Future work should test\nmore types of augmentations and also use real-life images instead of CARLA.\nIdeally, the augmented model meets or exceeds the performance of the weather\nmodel.",
      "tldr_zh": "本研究针对自动驾驶车辆在恶劣天气下的语义分割性能问题，提出通过在训练过程中应用图像 augmentation（如随机雨、雾和亮度调整）来实现领域适应。研究者使用 CARLA 模拟器收集了 1200 张晴天图像和 1200 张随机天气图像，训练 UNet 模型进行语义分割。结果显示，图像 augmentation 显著提升了模型在恶劣天气和夜间条件下的分割准确性（p < 0.001），但基于天气数据的模型在大多数条件下损失更低，表明该方法仍有改进潜力。未来工作将探索更多 augmentation 类型并验证于真实图像数据集。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.07239v1",
      "published_date": "2024-08-14 00:08:28 UTC",
      "updated_date": "2024-08-14 00:08:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T15:27:03.094098"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 83,
  "processed_papers_count": 83,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-19T15:27:34.324156"
}