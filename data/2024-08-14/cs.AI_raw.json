[
  {
    "arxiv_id": "2408.07854v1",
    "title": "CON-FOLD -- Explainable Machine Learning with Confidence",
    "authors": [
      "Lachlan McGinness",
      "Peter Baumgartner"
    ],
    "abstract": "FOLD-RM is an explainable machine learning classification algorithm that uses\ntraining data to create a set of classification rules. In this paper we\nintroduce CON-FOLD which extends FOLD-RM in several ways. CON-FOLD assigns\nprobability-based confidence scores to rules learned for a classification task.\nThis allows users to know how confident they should be in a prediction made by\nthe model. We present a confidence-based pruning algorithm that uses the unique\nstructure of FOLD-RM rules to efficiently prune rules and prevent overfitting.\nFurthermore, CON-FOLD enables the user to provide pre-existing knowledge in the\nform of logic program rules that are either (fixed) background knowledge or\n(modifiable) initial rule candidates. The paper describes our method in detail\nand reports on practical experiments. We demonstrate the performance of the\nalgorithm on benchmark datasets from the UCI Machine Learning Repository. For\nthat, we introduce a new metric, Inverse Brier Score, to evaluate the accuracy\nof the produced confidence scores. Finally we apply this extension to a real\nworld example that requires explainability: marking of student responses to a\nshort answer question from the Australian Physics Olympiad.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "F.4.1"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.07854v1",
    "published_date": "2024-08-14 23:45:21 UTC",
    "updated_date": "2024-08-14 23:45:21 UTC"
  },
  {
    "arxiv_id": "2408.07852v1",
    "title": "Training Language Models on the Knowledge Graph: Insights on Hallucinations and Their Detectability",
    "authors": [
      "Jiri Hron",
      "Laura Culp",
      "Gamaleldin Elsayed",
      "Rosanne Liu",
      "Ben Adlam",
      "Maxwell Bileschi",
      "Bernd Bohnet",
      "JD Co-Reyes",
      "Noah Fiedel",
      "C. Daniel Freeman",
      "Izzeddin Gur",
      "Kathleen Kenealy",
      "Jaehoon Lee",
      "Peter J. Liu",
      "Gaurav Mishra",
      "Igor Mordatch",
      "Azade Nova",
      "Roman Novak",
      "Aaron Parisi",
      "Jeffrey Pennington",
      "Alex Rizkowsky",
      "Isabelle Simpson",
      "Hanie Sedghi",
      "Jascha Sohl-dickstein",
      "Kevin Swersky",
      "Sharad Vikram",
      "Tris Warkentin",
      "Lechao Xiao",
      "Kelvin Xu",
      "Jasper Snoek",
      "Simon Kornblith"
    ],
    "abstract": "While many capabilities of language models (LMs) improve with increased\ntraining budget, the influence of scale on hallucinations is not yet fully\nunderstood. Hallucinations come in many forms, and there is no universally\naccepted definition. We thus focus on studying only those hallucinations where\na correct answer appears verbatim in the training set. To fully control the\ntraining data content, we construct a knowledge graph (KG)-based dataset, and\nuse it to train a set of increasingly large LMs. We find that for a fixed\ndataset, larger and longer-trained LMs hallucinate less. However, hallucinating\non $\\leq5$% of the training data requires an order of magnitude larger model,\nand thus an order of magnitude more compute, than Hoffmann et al. (2022)\nreported was optimal. Given this costliness, we study how hallucination\ndetectors depend on scale. While we see detector size improves performance on\nfixed LM's outputs, we find an inverse relationship between the scale of the LM\nand the detectability of its hallucinations.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Published at COLM 2024. 16 pages, 11 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.07852v1",
    "published_date": "2024-08-14 23:34:28 UTC",
    "updated_date": "2024-08-14 23:34:28 UTC"
  },
  {
    "arxiv_id": "2408.07851v1",
    "title": "SER Evals: In-domain and Out-of-domain Benchmarking for Speech Emotion Recognition",
    "authors": [
      "Mohamed Osman",
      "Daniel Z. Kaplan",
      "Tamer Nadeem"
    ],
    "abstract": "Speech emotion recognition (SER) has made significant strides with the advent\nof powerful self-supervised learning (SSL) models. However, the generalization\nof these models to diverse languages and emotional expressions remains a\nchallenge. We propose a large-scale benchmark to evaluate the robustness and\nadaptability of state-of-the-art SER models in both in-domain and out-of-domain\nsettings. Our benchmark includes a diverse set of multilingual datasets,\nfocusing on less commonly used corpora to assess generalization to new data. We\nemploy logit adjustment to account for varying class distributions and\nestablish a single dataset cluster for systematic evaluation. Surprisingly, we\nfind that the Whisper model, primarily designed for automatic speech\nrecognition, outperforms dedicated SSL models in cross-lingual SER. Our results\nhighlight the need for more robust and generalizable SER models, and our\nbenchmark serves as a valuable resource to drive future research in this\ndirection.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at INTERSPEECH 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.07851v1",
    "published_date": "2024-08-14 23:33:10 UTC",
    "updated_date": "2024-08-14 23:33:10 UTC"
  },
  {
    "arxiv_id": "2408.07846v2",
    "title": "A System for Automated Unit Test Generation Using Large Language Models and Assessment of Generated Test Suites",
    "authors": [
      "Andrea Lops",
      "Fedelucio Narducci",
      "Azzurra Ragone",
      "Michelantonio Trizio",
      "Claudio Bartolini"
    ],
    "abstract": "Unit tests represent the most basic level of testing within the software\ntesting lifecycle and are crucial to ensuring software correctness. Designing\nand creating unit tests is a costly and labor-intensive process that is ripe\nfor automation. Recently, Large Language Models (LLMs) have been applied to\nvarious aspects of software development, including unit test generation.\nAlthough several empirical studies evaluating LLMs' capabilities in test code\ngeneration exist, they primarily focus on simple scenarios, such as the\nstraightforward generation of unit tests for individual methods. These\nevaluations often involve independent and small-scale test units, providing a\nlimited view of LLMs' performance in real-world software development scenarios.\nMoreover, previous studies do not approach the problem at a suitable scale for\nreal-life applications. Generated unit tests are often evaluated via manual\nintegration into the original projects, a process that limits the number of\ntests executed and reduces overall efficiency. To address these gaps, we have\ndeveloped an approach for generating and evaluating more real-life complexity\ntest suites. Our approach focuses on class-level test code generation and\nautomates the entire process from test generation to test assessment. In this\nwork, we present AgoneTest: an automated system for generating test suites for\nJava projects and a comprehensive and principled methodology for evaluating the\ngenerated test suites. Starting from a state-of-the-art dataset (i.e.,\nMethods2Test), we built a new dataset for comparing human-written tests with\nthose generated by LLMs. Our key contributions include a scalable automated\nsoftware system, a new dataset, and a detailed methodology for evaluating test\nquality.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.07846v2",
    "published_date": "2024-08-14 23:02:16 UTC",
    "updated_date": "2024-08-16 00:18:03 UTC"
  },
  {
    "arxiv_id": "2408.07845v1",
    "title": "Enhancing Equitable Access to AI in Housing and Homelessness System of Care through Federated Learning",
    "authors": [
      "Musa Taib",
      "Jiajun Wu",
      "Steve Drew",
      "Geoffrey G. Messier"
    ],
    "abstract": "The top priority of a Housing and Homelessness System of Care (HHSC) is to\nconnect people experiencing homelessness to supportive housing. An HHSC\ntypically consists of many agencies serving the same population. Information\ntechnology platforms differ in type and quality between agencies, so their data\nare usually isolated from one agency to another. Larger agencies may have\nsufficient data to train and test artificial intelligence (AI) tools but\nsmaller agencies typically do not. To address this gap, we introduce a\nFederated Learning (FL) approach enabling all agencies to train a predictive\nmodel collaboratively without sharing their sensitive data. We demonstrate how\nFL can be used within an HHSC to provide all agencies equitable access to\nquality AI and further assist human decision-makers in the allocation of\nresources within HHSC. This is achieved while preserving the privacy of the\npeople within the data by not sharing identifying information between agencies\nwithout their consent. Our experimental results using real-world HHSC data from\nCalgary, Alberta, demonstrate that our FL approach offers comparable\nperformance with the idealized scenario of training the predictive model with\ndata fully shared and linked between agencies.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at the 2024 AAAI/ACM Conference on AI, Ethics, and Society\n  (AIES)",
    "pdf_url": "http://arxiv.org/pdf/2408.07845v1",
    "published_date": "2024-08-14 23:01:02 UTC",
    "updated_date": "2024-08-14 23:01:02 UTC"
  },
  {
    "arxiv_id": "2408.08333v1",
    "title": "CodeMirage: Hallucinations in Code Generated by Large Language Models",
    "authors": [
      "Vibhor Agarwal",
      "Yulong Pei",
      "Salwa Alamir",
      "Xiaomo Liu"
    ],
    "abstract": "Large Language Models (LLMs) have shown promising potentials in program\ngeneration and no-code automation. However, LLMs are prone to generate\nhallucinations, i.e., they generate text which sounds plausible but is\nincorrect. Although there has been a recent surge in research on LLM\nhallucinations for text generation, similar hallucination phenomenon can happen\nin code generation. Sometimes the generated code can have syntactical or\nlogical errors as well as more advanced issues like security vulnerabilities,\nmemory leaks, etc. Given the wide adaptation of LLMs to enhance efficiency in\ncode generation and development in general, it becomes imperative to\ninvestigate hallucinations in code generation. To the best of our knowledge,\nthis is the first attempt at studying hallucinations in the code generated by\nLLMs. We start by introducing the code hallucination definition and a\ncomprehensive taxonomy of code hallucination types. We propose the first\nbenchmark CodeMirage dataset for code hallucinations. The benchmark contains\n1,137 GPT-3.5 generated hallucinated code snippets for Python programming\nproblems from two base datasets - HumanEval and MBPP. We then propose the\nmethodology for code hallucination detection and experiment with open source\nLLMs such as CodeLLaMA as well as OpenAI's GPT-3.5 and GPT-4 models using\none-shot prompt. We find that GPT-4 performs the best on HumanEval dataset and\ngives comparable results to the fine-tuned CodeBERT baseline on MBPP dataset.\nTowards the end, we discuss various mitigation strategies for code\nhallucinations and conclude our work.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.SE",
    "comment": "Accepted at AutoMates @ IJCAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.08333v1",
    "published_date": "2024-08-14 22:53:07 UTC",
    "updated_date": "2024-08-14 22:53:07 UTC"
  },
  {
    "arxiv_id": "2408.07841v5",
    "title": "SustainDC: Benchmarking for Sustainable Data Center Control",
    "authors": [
      "Avisek Naug",
      "Antonio Guillen",
      "Ricardo Luna",
      "Vineet Gundecha",
      "Desik Rengarajan",
      "Sahand Ghorbanpour",
      "Sajad Mousavi",
      "Ashwin Ramesh Babu",
      "Dejan Markovikj",
      "Lekhapriya D Kashyap",
      "Soumyendu Sarkar"
    ],
    "abstract": "Machine learning has driven an exponential increase in computational demand,\nleading to massive data centers that consume significant amounts of energy and\ncontribute to climate change. This makes sustainable data center control a\npriority. In this paper, we introduce SustainDC, a set of Python environments\nfor benchmarking multi-agent reinforcement learning (MARL) algorithms for data\ncenters (DC). SustainDC supports custom DC configurations and tasks such as\nworkload scheduling, cooling optimization, and auxiliary battery management,\nwith multiple agents managing these operations while accounting for the effects\nof each other. We evaluate various MARL algorithms on SustainDC, showing their\nperformance across diverse DC designs, locations, weather conditions, grid\ncarbon intensity, and workload requirements. Our results highlight significant\nopportunities for improvement of data center operations using MARL algorithms.\nGiven the increasing use of DC due to AI, SustainDC provides a crucial platform\nfor the development and benchmarking of advanced algorithms essential for\nachieving sustainable computing and addressing other heterogeneous real-world\nchallenges.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at Advances in Neural Information Processing Systems 2024\n  (NeurIPS 2024)",
    "pdf_url": "http://arxiv.org/pdf/2408.07841v5",
    "published_date": "2024-08-14 22:43:52 UTC",
    "updated_date": "2025-04-30 08:01:16 UTC"
  },
  {
    "arxiv_id": "2408.07840v1",
    "title": "ONSEP: A Novel Online Neural-Symbolic Framework for Event Prediction Based on Large Language Model",
    "authors": [
      "Xuanqing Yu",
      "Wangtao Sun",
      "Jingwei Li",
      "Kang Liu",
      "Chengbao Liu",
      "Jie Tan"
    ],
    "abstract": "In the realm of event prediction, temporal knowledge graph forecasting (TKGF)\nstands as a pivotal technique. Previous approaches face the challenges of not\nutilizing experience during testing and relying on a single short-term history,\nwhich limits adaptation to evolving data. In this paper, we introduce the\nOnline Neural-Symbolic Event Prediction (ONSEP) framework, which innovates by\nintegrating dynamic causal rule mining (DCRM) and dual history augmented\ngeneration (DHAG). DCRM dynamically constructs causal rules from real-time\ndata, allowing for swift adaptation to new causal relationships. In parallel,\nDHAG merges short-term and long-term historical contexts, leveraging a\nbi-branch approach to enrich event prediction. Our framework demonstrates\nnotable performance enhancements across diverse datasets, with significant\nHit@k (k=1,3,10) improvements, showcasing its ability to augment large language\nmodels (LLMs) for event prediction without necessitating extensive retraining.\nThe ONSEP framework not only advances the field of TKGF but also underscores\nthe potential of neural-symbolic approaches in adapting to dynamic data\nenvironments.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SC"
    ],
    "primary_category": "cs.CL",
    "comment": "16 pages, ACL 2024 Findings",
    "pdf_url": "http://arxiv.org/pdf/2408.07840v1",
    "published_date": "2024-08-14 22:28:19 UTC",
    "updated_date": "2024-08-14 22:28:19 UTC"
  },
  {
    "arxiv_id": "2408.11852v2",
    "title": "Fast Training Dataset Attribution via In-Context Learning",
    "authors": [
      "Milad Fotouhi",
      "Mohammad Taha Bahadori",
      "Oluwaseyi Feyisetan",
      "Payman Arabshahi",
      "David Heckerman"
    ],
    "abstract": "We investigate the use of in-context learning and prompt engineering to\nestimate the contributions of training data in the outputs of instruction-tuned\nlarge language models (LLMs). We propose two novel approaches: (1) a\nsimilarity-based approach that measures the difference between LLM outputs with\nand without provided context, and (2) a mixture distribution model approach\nthat frames the problem of identifying contribution scores as a matrix\nfactorization task. Our empirical comparison demonstrates that the mixture\nmodel approach is more robust to retrieval noise in in-context learning,\nproviding a more reliable estimation of data contributions.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.11852v2",
    "published_date": "2024-08-14 20:48:45 UTC",
    "updated_date": "2025-03-18 21:10:24 UTC"
  },
  {
    "arxiv_id": "2408.08918v1",
    "title": "Supervised and Unsupervised Alignments for Spoofing Behavioral Biometrics",
    "authors": [
      "Thomas Thebaud",
      "Gaël Le Lan",
      "Anthony Larcher"
    ],
    "abstract": "Biometric recognition systems are security systems based on intrinsic\nproperties of their users, usually encoded in high dimension representations\ncalled embeddings, which potential theft would represent a greater threat than\na temporary password or a replaceable key. To study the threat of embedding\ntheft, we perform spoofing attacks on two behavioral biometric systems (an\nautomatic speaker verification system and a handwritten digit analysis system)\nusing a set of alignment techniques. Biometric recognition systems based on\nembeddings work in two phases: enrollment - where embeddings are collected and\nstored - then authentication - when new embeddings are compared to the stored\nones -.The threat of stolen enrollment embeddings has been explored by the\ntemplate reconstruction attack literature: reconstructing the original data to\nspoof an authentication system is doable with black-box access to their\nencoder. In this document, we explore the options available to perform template\nreconstruction attacks without any access to the encoder. To perform those\nattacks, we suppose general rules over the distribution of embeddings across\nencoders and use supervised and unsupervised algorithms to align an unlabeled\nset of embeddings with a set from a known encoder. The use of an alignment\nalgorithm from the unsupervised translation literature gives promising results\non spoofing two behavioral biometric systems.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "11 pages, 4 figures, 5 tables, submission in progress",
    "pdf_url": "http://arxiv.org/pdf/2408.08918v1",
    "published_date": "2024-08-14 20:46:59 UTC",
    "updated_date": "2024-08-14 20:46:59 UTC"
  },
  {
    "arxiv_id": "2408.07791v1",
    "title": "An Efficient and Explanatory Image and Text Clustering System with Multimodal Autoencoder Architecture",
    "authors": [
      "Tiancheng Shi",
      "Yuanchen Wei",
      "John R. Kender"
    ],
    "abstract": "We demonstrate the efficiencies and explanatory abilities of extensions to\nthe common tools of Autoencoders and LLM interpreters, in the novel context of\ncomparing different cultural approaches to the same international news event.\nWe develop a new Convolutional-Recurrent Variational Autoencoder (CRVAE) model\nthat extends the modalities of previous CVAE models, by using fully-connected\nlatent layers to embed in parallel the CNN encodings of video frames, together\nwith the LSTM encodings of their related text derived from audio. We\nincorporate the model within a larger system that includes frame-caption\nalignment, latent space vector clustering, and a novel LLM-based cluster\ninterpreter. We measure, tune, and apply this system to the task of summarizing\na video into three to five thematic clusters, with each theme described by ten\nLLM-produced phrases. We apply this system to two news topics, COVID-19 and the\nWinter Olympics, and five other topics are in progress.",
    "categories": [
      "cs.MM",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.MM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.07791v1",
    "published_date": "2024-08-14 20:03:53 UTC",
    "updated_date": "2024-08-14 20:03:53 UTC"
  },
  {
    "arxiv_id": "2408.07768v1",
    "title": "On learning capacities of Sugeno integrals with systems of fuzzy relational equations",
    "authors": [
      "Ismaïl Baaj"
    ],
    "abstract": "In this article, we introduce a method for learning a capacity underlying a\nSugeno integral according to training data based on systems of fuzzy relational\nequations. To the training data, we associate two systems of equations: a\n$\\max-\\min$ system and a $\\min-\\max$ system. By solving these two systems (in\nthe case that they are consistent) using Sanchez's results, we show that we can\ndirectly obtain the extremal capacities representing the training data. By\nreducing the $\\max-\\min$ (resp. $\\min-\\max$) system of equations to subsets of\ncriteria of cardinality less than or equal to $q$ (resp. of cardinality greater\nthan or equal to $n-q$), where $n$ is the number of criteria, we give a\nsufficient condition for deducing, from its potential greatest solution (resp.\nits potential lowest solution), a $q$-maxitive (resp. $q$-minitive) capacity.\nFinally, if these two reduced systems of equations are inconsistent, we show\nhow to obtain the greatest approximate $q$-maxitive capacity and the lowest\napproximate $q$-minitive capacity, using recent results to handle the\ninconsistency of systems of fuzzy relational equations.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.07768v1",
    "published_date": "2024-08-14 18:40:01 UTC",
    "updated_date": "2024-08-14 18:40:01 UTC"
  },
  {
    "arxiv_id": "2408.07697v1",
    "title": "Quantifying over Optimum Answer Sets",
    "authors": [
      "Giuseppe Mazzotta",
      "Francesco Ricca",
      "Mirek Truszczynski"
    ],
    "abstract": "Answer Set Programming with Quantifiers (ASP(Q)) has been introduced to\nprovide a natural extension of ASP modeling to problems in the polynomial\nhierarchy (PH). However, ASP(Q) lacks a method for encoding in an elegant and\ncompact way problems requiring a polynomial number of calls to an oracle in\n$\\Sigma_n^p$ (that is, problems in $\\Delta_{n+1}^p$). Such problems include, in\nparticular, optimization problems. In this paper we propose an extension of\nASP(Q), in which component programs may contain weak constraints. Weak\nconstraints can be used both for expressing local optimization within\nquantified component programs and for modeling global optimization criteria. We\nshowcase the modeling capabilities of the new formalism through various\napplication scenarios. Further, we study its computational properties obtaining\ncomplexity results and unveiling non-obvious characteristics of ASP(Q) programs\nwith weak constraints.",
    "categories": [
      "cs.AI",
      "cs.CC",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.07697v1",
    "published_date": "2024-08-14 17:53:13 UTC",
    "updated_date": "2024-08-14 17:53:13 UTC"
  },
  {
    "arxiv_id": "2408.07736v1",
    "title": "Enhancing Model Interpretability with Local Attribution over Global Exploration",
    "authors": [
      "Zhiyu Zhu",
      "Zhibo Jin",
      "Jiayu Zhang",
      "Huaming Chen"
    ],
    "abstract": "In the field of artificial intelligence, AI models are frequently described\nas `black boxes' due to the obscurity of their internal mechanisms. It has\nignited research interest on model interpretability, especially in attribution\nmethods that offers precise explanations of model decisions. Current\nattribution algorithms typically evaluate the importance of each parameter by\nexploring the sample space. A large number of intermediate states are\nintroduced during the exploration process, which may reach the model's\nOut-of-Distribution (OOD) space. Such intermediate states will impact the\nattribution results, making it challenging to grasp the relative importance of\nfeatures. In this paper, we firstly define the local space and its relevant\nproperties, and we propose the Local Attribution (LA) algorithm that leverages\nthese properties. The LA algorithm comprises both targeted and untargeted\nexploration phases, which are designed to effectively generate intermediate\nstates for attribution that thoroughly encompass the local space. Compared to\nthe state-of-the-art attribution methods, our approach achieves an average\nimprovement of 38.21\\% in attribution effectiveness. Extensive ablation studies\nin our experiments also validate the significance of each component in our\nalgorithm. Our code is available at: https://github.com/LMBTough/LA/",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by ACMMM 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.07736v1",
    "published_date": "2024-08-14 17:53:08 UTC",
    "updated_date": "2024-08-14 17:53:08 UTC"
  },
  {
    "arxiv_id": "2408.07694v1",
    "title": "End-to-end Semantic-centric Video-based Multimodal Affective Computing",
    "authors": [
      "Ronghao Lin",
      "Ying Zeng",
      "Sijie Mai",
      "Haifeng Hu"
    ],
    "abstract": "In the pathway toward Artificial General Intelligence (AGI), understanding\nhuman's affection is essential to enhance machine's cognition abilities. For\nachieving more sensual human-AI interaction, Multimodal Affective Computing\n(MAC) in human-spoken videos has attracted increasing attention. However,\nprevious methods are mainly devoted to designing multimodal fusion algorithms,\nsuffering from two issues: semantic imbalance caused by diverse pre-processing\noperations and semantic mismatch raised by inconsistent affection content\ncontained in different modalities comparing with the multimodal ground truth.\nBesides, the usage of manual features extractors make they fail in building\nend-to-end pipeline for multiple MAC downstream tasks. To address above\nchallenges, we propose a novel end-to-end framework named SemanticMAC to\ncompute multimodal semantic-centric affection for human-spoken videos. We\nfirstly employ pre-trained Transformer model in multimodal data pre-processing\nand design Affective Perceiver module to capture unimodal affective\ninformation. Moreover, we present a semantic-centric approach to unify\nmultimodal representation learning in three ways, including gated feature\ninteraction, multi-task pseudo label generation, and intra-/inter-sample\ncontrastive learning. Finally, SemanticMAC effectively learn specific- and\nshared-semantic representations in the guidance of semantic-centric labels.\nExtensive experimental results demonstrate that our approach surpass the\nstate-of-the-art methods on 7 public datasets in four MAC downstream tasks.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "Under Review",
    "pdf_url": "http://arxiv.org/pdf/2408.07694v1",
    "published_date": "2024-08-14 17:50:27 UTC",
    "updated_date": "2024-08-14 17:50:27 UTC"
  },
  {
    "arxiv_id": "2408.07680v2",
    "title": "A Spitting Image: Modular Superpixel Tokenization in Vision Transformers",
    "authors": [
      "Marius Aasan",
      "Odd Kolbjørnsen",
      "Anne Schistad Solberg",
      "Adín Ramirez Rivera"
    ],
    "abstract": "Vision Transformer (ViT) architectures traditionally employ a grid-based\napproach to tokenization independent of the semantic content of an image. We\npropose a modular superpixel tokenization strategy which decouples tokenization\nand feature extraction; a shift from contemporary approaches where these are\ntreated as an undifferentiated whole. Using on-line content-aware tokenization\nand scale- and shape-invariant positional embeddings, we perform experiments\nand ablations that contrast our approach with patch-based tokenization and\nrandomized partitions as baselines. We show that our method significantly\nimproves the faithfulness of attributions, gives pixel-level granularity on\nzero-shot unsupervised dense prediction tasks, while maintaining predictive\nperformance in classification tasks. Our approach provides a modular\ntokenization framework commensurable with standard architectures, extending the\nspace of ViTs to a larger class of semantically-rich models.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "68T45",
      "I.2.10; I.4.10"
    ],
    "primary_category": "cs.CV",
    "comment": "To appear in ECCV (MELEX) 2024 Workshop Proceedings",
    "pdf_url": "http://arxiv.org/pdf/2408.07680v2",
    "published_date": "2024-08-14 17:28:58 UTC",
    "updated_date": "2024-08-15 12:07:00 UTC"
  },
  {
    "arxiv_id": "2408.16772v2",
    "title": "An Effective Information Theoretic Framework for Channel Pruning",
    "authors": [
      "Yihao Chen",
      "Zefang Wang"
    ],
    "abstract": "Channel pruning is a promising method for accelerating and compressing\nconvolutional neural networks. However, current pruning algorithms still remain\nunsolved problems that how to assign layer-wise pruning ratios properly and\ndiscard the least important channels with a convincing criterion. In this\npaper, we present a novel channel pruning approach via information theory and\ninterpretability of neural networks. Specifically, we regard information\nentropy as the expected amount of information for convolutional layers. In\naddition, if we suppose a matrix as a system of linear equations, a higher-rank\nmatrix represents there exist more solutions to it, which indicates more\nuncertainty. From the point of view of information theory, the rank can also\ndescribe the amount of information. In a neural network, considering the rank\nand entropy as two information indicators of convolutional layers, we propose a\nfusion function to reach a compromise of them, where the fusion results are\ndefined as ``information concentration''. When pre-defining layer-wise pruning\nratios, we employ the information concentration as a reference instead of\nheuristic and engineering tuning to provide a more interpretable solution.\nMoreover, we leverage Shapley values, which are a potent tool in the\ninterpretability of neural networks, to evaluate the channel contributions and\ndiscard the least important channels for model compression while maintaining\nits performance. Extensive experiments demonstrate the effectiveness and\npromising performance of our method. For example, our method improves the\naccuracy by 0.21% when reducing 45.5% FLOPs and removing 40.3% parameters for\nResNet-56 on CIFAR-10. Moreover, our method obtains loss in Top-1/Top-5\naccuracies of 0.43%/0.11% by reducing 41.6% FLOPs and removing 35.0% parameters\nfor ResNet-50 on ImageNet.",
    "categories": [
      "cs.IT",
      "cs.AI",
      "cs.LG",
      "math.IT"
    ],
    "primary_category": "cs.IT",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.16772v2",
    "published_date": "2024-08-14 17:19:56 UTC",
    "updated_date": "2024-09-02 13:19:40 UTC"
  },
  {
    "arxiv_id": "2408.07673v2",
    "title": "Deep Learning: a Heuristic Three-stage Mechanism for Grid Searches to Optimize the Future Risk Prediction of Breast Cancer Metastasis Using EHR-based Clinical Data",
    "authors": [
      "Xia Jiang",
      "Yijun Zhou",
      "Chuhan Xu",
      "Adam Brufsky",
      "Alan Wells"
    ],
    "abstract": "A grid search, at the cost of training and testing a large number of models,\nis an effective way to optimize the prediction performance of deep learning\nmodels. A challenging task concerning grid search is the time management.\nWithout a good time management scheme, a grid search can easily be set off as a\nmission that will not finish in our lifetime. In this study, we introduce a\nheuristic three-stage mechanism for managing the running time of low-budget\ngrid searches, and the sweet-spot grid search (SSGS) and randomized grid search\n(RGS) strategies for improving model prediction performance, in predicting the\n5-year, 10-year, and 15-year risk of breast cancer metastasis. We develop deep\nfeedforward neural network (DFNN) models and optimize them through grid\nsearches. We conduct eight cycles of grid searches by applying our three-stage\nmechanism and SSGS and RGS strategies. We conduct various SHAP analyses\nincluding unique ones that interpret the importance of the DFNN-model\nhyperparameters. Our results show that grid search can greatly improve model\nprediction. The grid searches we conducted improved the risk prediction of\n5-year, 10-year, and 15-year breast cancer metastasis by 18.6%, 16.3%, and\n17.3% respectively, over the average performance of all corresponding models we\ntrained using the RGS strategy. We not only demonstrate best model performance\nbut also characterize grid searches from various aspects such as their\ncapabilities of discovering decent models and the unit grid search time. The\nthree-stage mechanism worked effectively. It made our low-budget grid searches\nfeasible and manageable, and in the meantime helped improve model prediction\nperformance. Our SHAP analyses identified both clinical risk factors important\nfor the prediction of future risk of breast cancer metastasis, and DFNN-model\nhyperparameters important to the prediction of performance scores.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE",
      "q-bio.QM"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.07673v2",
    "published_date": "2024-08-14 17:16:50 UTC",
    "updated_date": "2024-08-15 14:35:24 UTC"
  },
  {
    "arxiv_id": "2408.07666v4",
    "title": "Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities",
    "authors": [
      "Enneng Yang",
      "Li Shen",
      "Guibing Guo",
      "Xingwei Wang",
      "Xiaochun Cao",
      "Jie Zhang",
      "Dacheng Tao"
    ],
    "abstract": "Model merging is an efficient empowerment technique in the machine learning\ncommunity that does not require the collection of raw training data and does\nnot require expensive computation. As model merging becomes increasingly\nprevalent across various fields, it is crucial to understand the available\nmodel merging techniques comprehensively. However, there is a significant gap\nin the literature regarding a systematic and thorough review of these\ntechniques. This survey provides a comprehensive overview of model merging\nmethods and theories, their applications in various domains and settings, and\nfuture research directions. Specifically, we first propose a new taxonomic\napproach that exhaustively discusses existing model merging methods. Secondly,\nwe discuss the application of model merging techniques in large language\nmodels, multimodal large language models, and 10+ machine learning subfields,\nincluding continual learning, multi-task learning, few-shot learning, etc.\nFinally, we highlight the remaining challenges of model merging and discuss\nfuture research directions. A comprehensive list of papers about model merging\nis available at\n\\url{https://github.com/EnnengYang/Awesome-Model-Merging-Methods-Theories-Applications}.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.07666v4",
    "published_date": "2024-08-14 16:58:48 UTC",
    "updated_date": "2024-09-05 14:37:59 UTC"
  },
  {
    "arxiv_id": "2408.07663v2",
    "title": "Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions",
    "authors": [
      "Quan Liu",
      "Zhenhong Zhou",
      "Longzhu He",
      "Yi Liu",
      "Wei Zhang",
      "Sen Su"
    ],
    "abstract": "Large language models are susceptible to jailbreak attacks, which can result\nin the generation of harmful content. While prior defenses mitigate these risks\nby perturbing or inspecting inputs, they ignore competing objectives, the\nunderlying cause of alignment failures. In this paper, we propose\nAlignment-Enhanced Decoding (AED), a novel defense that employs adaptive\ndecoding to address the root causes of jailbreak issues. We first define the\nCompetitive Index to quantify alignment failures and utilize feedback from\nself-evaluation to compute post-alignment logits. Then, AED adaptively combines\nAED and post-alignment logits with the original logits to obtain harmless and\nhelpful distributions. Consequently, our method enhances safety alignment while\nmaintaining helpfulness. We conduct experiments across five models and four\ncommon jailbreaks, with the results validating the effectiveness of our\napproach. Code is available at https://github.com/GIGABaozi/AED.git.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by EMNLP 2024, 15 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.07663v2",
    "published_date": "2024-08-14 16:51:21 UTC",
    "updated_date": "2024-12-19 06:34:31 UTC"
  },
  {
    "arxiv_id": "2408.07647v1",
    "title": "Adaptive Behavioral AI: Reinforcement Learning to Enhance Pharmacy Services",
    "authors": [
      "Ana Fernández del Río",
      "Michael Brennan Leong",
      "Paulo Saraiva",
      "Ivan Nazarov",
      "Aditya Rastogi",
      "Moiz Hassan",
      "Dexian Tang",
      "África Periáñez"
    ],
    "abstract": "Pharmacies are critical in healthcare systems, particularly in low- and\nmiddle-income countries. Procuring pharmacists with the right behavioral\ninterventions or nudges can enhance their skills, public health awareness, and\npharmacy inventory management, ensuring access to essential medicines that\nultimately benefit their patients. We introduce a reinforcement learning\noperational system to deliver personalized behavioral interventions through\nmobile health applications. We illustrate its potential by discussing a series\nof initial experiments run with SwipeRx, an all-in-one app for pharmacists,\nincluding B2B e-commerce, in Indonesia. The proposed method has broader\napplications extending beyond pharmacy operations to optimize healthcare\ndelivery.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY",
      "physics.data-an"
    ],
    "primary_category": "cs.LG",
    "comment": "Presented at The First Workshop on AI Behavioral Science (AIBS'24) at\n  KDD 2024, August 25, Barcelona, Spain",
    "pdf_url": "http://arxiv.org/pdf/2408.07647v1",
    "published_date": "2024-08-14 16:18:51 UTC",
    "updated_date": "2024-08-14 16:18:51 UTC"
  },
  {
    "arxiv_id": "2408.07642v1",
    "title": "Boosting Unconstrained Face Recognition with Targeted Style Adversary",
    "authors": [
      "Mohammad Saeed Ebrahimi Saadabadi",
      "Sahar Rahimi Malakshan",
      "Seyed Rasoul Hosseini",
      "Nasser M. Nasrabadi"
    ],
    "abstract": "While deep face recognition models have demonstrated remarkable performance,\nthey often struggle on the inputs from domains beyond their training data.\nRecent attempts aim to expand the training set by relying on computationally\nexpensive and inherently challenging image-space augmentation of image\ngeneration modules. In an orthogonal direction, we present a simple yet\neffective method to expand the training data by interpolating between\ninstance-level feature statistics across labeled and unlabeled sets. Our\nmethod, dubbed Targeted Style Adversary (TSA), is motivated by two\nobservations: (i) the input domain is reflected in feature statistics, and (ii)\nface recognition model performance is influenced by style information. Shifting\ntowards an unlabeled style implicitly synthesizes challenging training\ninstances. We devise a recognizability metric to constraint our framework to\npreserve the inherent identity-related information of labeled instances. The\nefficacy of our method is demonstrated through evaluations on unconstrained\nbenchmarks, outperforming or being on par with its competitors while offering\nnearly a 70\\% improvement in training speed and 40\\% less memory consumption.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.07642v1",
    "published_date": "2024-08-14 16:13:03 UTC",
    "updated_date": "2024-08-14 16:13:03 UTC"
  },
  {
    "arxiv_id": "2408.08916v1",
    "title": "Cyclic Supports in Recursive Bipolar Argumentation Frameworks: Semantics and LP Mapping",
    "authors": [
      "Gianvincenzo Alfano",
      "Sergio Greco",
      "Francesco Parisi",
      "Irina Trubitsyna"
    ],
    "abstract": "Dung's Abstract Argumentation Framework (AF) has emerged as a key formalism\nfor argumentation in Artificial Intelligence. It has been extended in several\ndirections, including the possibility to express supports, leading to the\ndevelopment of the Bipolar Argumentation Framework (BAF), and recursive attacks\nand supports, resulting in the Recursive BAF (Rec-BAF). Different\ninterpretations of supports have been proposed, whereas for Rec-BAF (where the\ntarget of attacks and supports may also be attacks and supports) even different\nsemantics for attacks have been defined. However, the semantics of these\nframeworks have either not been defined in the presence of support cycles, or\nare often quite intricate in terms of the involved definitions. We encompass\nthis limitation and present classical semantics for general BAF and Rec-BAF and\nshow that the semantics for specific BAF and Rec-BAF frameworks can be defined\nby very simple and intuitive modifications of that defined for the case of AF.\nThis is achieved by providing a modular definition of the sets of defeated and\nacceptable elements for each AF-based framework. We also characterize, in an\nelegant and uniform way, the semantics of general BAF and Rec-BAF in terms of\nlogic programming and partial stable model semantics.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Paper presented at the 40th International Conference on Logic\n  Programming (ICLP 2024), University of Texas at Dallas, USA, October 2024.\n  arXiv admin note: text overlap with arXiv:2008.02550",
    "pdf_url": "http://arxiv.org/pdf/2408.08916v1",
    "published_date": "2024-08-14 16:06:16 UTC",
    "updated_date": "2024-08-14 16:06:16 UTC"
  },
  {
    "arxiv_id": "2408.07636v1",
    "title": "Drug Discovery SMILES-to-Pharmacokinetics Diffusion Models with Deep Molecular Understanding",
    "authors": [
      "Bing Hu",
      "Anita Layton",
      "Helen Chen"
    ],
    "abstract": "Artificial intelligence (AI) is increasingly used in every stage of drug\ndevelopment. One challenge facing drug discovery AI is that drug\npharmacokinetic (PK) datasets are often collected independently from each\nother, often with limited overlap, creating data overlap sparsity. Data\nsparsity makes data curation difficult for researchers looking to answer\nresearch questions in poly-pharmacy, drug combination research, and\nhigh-throughput screening. We propose Imagand, a novel\nSMILES-to-Pharmacokinetic (S2PK) diffusion model capable of generating an array\nof PK target properties conditioned on SMILES inputs. We show that\nImagand-generated synthetic PK data closely resembles real data univariate and\nbivariate distributions, and improves performance for downstream tasks. Imagand\nis a promising solution for data overlap sparsity and allows researchers to\nefficiently generate ligand PK data for drug discovery research. Code is\navailable at \\url{https://github.com/bing1100/Imagand}.",
    "categories": [
      "q-bio.QM",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.QM",
    "comment": "13 pages, 5 figures, 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2408.07636v1",
    "published_date": "2024-08-14 16:01:02 UTC",
    "updated_date": "2024-08-14 16:01:02 UTC"
  },
  {
    "arxiv_id": "2408.07629v1",
    "title": "Optimizing HIV Patient Engagement with Reinforcement Learning in Resource-Limited Settings",
    "authors": [
      "África Periáñez",
      "Kathrin Schmitz",
      "Lazola Makhupula",
      "Moiz Hassan",
      "Moeti Moleko",
      "Ana Fernández del Río",
      "Ivan Nazarov",
      "Aditya Rastogi",
      "Dexian Tang"
    ],
    "abstract": "By providing evidence-based clinical decision support, digital tools and\nelectronic health records can revolutionize patient management, especially in\nresource-poor settings where fewer health workers are available and often need\nmore training. When these tools are integrated with AI, they can offer\npersonalized support and adaptive interventions, effectively connecting\ncommunity health workers (CHWs) and healthcare facilities. The CHARM (Community\nHealth Access & Resource Management) app is an AI-native mobile app for CHWs.\nDeveloped through a joint partnership of Causal Foundry (CF) and\nmothers2mothers (m2m), CHARM empowers CHWs, mainly local women, by streamlining\ncase management, enhancing learning, and improving communication. This paper\ndetails CHARM's development, integration, and upcoming reinforcement\nlearning-based adaptive interventions, all aimed at enhancing health worker\nengagement, efficiency, and patient outcomes, thereby enhancing CHWs'\ncapabilities and community health.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "Presented at the 7th epiDAMIK ACM SIGKDD International Workshop on\n  Epidemiology meets Data Mining and Knowledge Discovery, August 26, 2024,\n  Barcelona, Spain",
    "pdf_url": "http://arxiv.org/pdf/2408.07629v1",
    "published_date": "2024-08-14 15:55:31 UTC",
    "updated_date": "2024-08-14 15:55:31 UTC"
  },
  {
    "arxiv_id": "2408.10261v1",
    "title": "Relational Graph Convolutional Networks Do Not Learn Sound Rules",
    "authors": [
      "Matthew Morris",
      "David J. Tena Cucala",
      "Bernardo Cuenca Grau",
      "Ian Horrocks"
    ],
    "abstract": "Graph neural networks (GNNs) are frequently used to predict missing facts in\nknowledge graphs (KGs). Motivated by the lack of explainability for the outputs\nof these models, recent work has aimed to explain their predictions using\nDatalog, a widely used logic-based formalism. However, such work has been\nrestricted to certain subclasses of GNNs. In this paper, we consider one of the\nmost popular GNN architectures for KGs, R-GCN, and we provide two methods to\nextract rules that explain its predictions and are sound, in the sense that\neach fact derived by the rules is also predicted by the GNN, for any input\ndataset. Furthermore, we provide a method that can verify that certain classes\nof Datalog rules are not sound for the R-GCN. In our experiments, we train\nR-GCNs on KG completion benchmarks, and we are able to verify that no Datalog\nrule is sound for these models, even though the models often obtain high to\nnear-perfect accuracy. This raises some concerns about the ability of R-GCN\nmodels to generalise and about the explainability of their predictions. We\nfurther provide two variations to the training paradigm of R-GCN that encourage\nit to learn sound rules and find a trade-off between model accuracy and the\nnumber of learned sound rules.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.LO",
      "03B70",
      "I.2.6; G.2.2; I.2.4; I.2.3"
    ],
    "primary_category": "cs.LG",
    "comment": "Full version (with appendices) of paper accepted to KR 2024 (21st\n  International Conference on Principles of Knowledge Representation and\n  Reasoning)",
    "pdf_url": "http://arxiv.org/pdf/2408.10261v1",
    "published_date": "2024-08-14 15:46:42 UTC",
    "updated_date": "2024-08-14 15:46:42 UTC"
  },
  {
    "arxiv_id": "2408.07624v1",
    "title": "Battery GraphNets : Relational Learning for Lithium-ion Batteries(LiBs) Life Estimation",
    "authors": [
      "Sakhinana Sagar Srinivas",
      "Rajat Kumar Sarkar",
      "Venkataramana Runkana"
    ],
    "abstract": "Battery life estimation is critical for optimizing battery performance and\nguaranteeing minimal degradation for better efficiency and reliability of\nbattery-powered systems. The existing methods to predict the Remaining Useful\nLife(RUL) of Lithium-ion Batteries (LiBs) neglect the relational dependencies\nof the battery parameters to model the nonlinear degradation trajectories. We\npresent the Battery GraphNets framework that jointly learns to incorporate a\ndiscrete dependency graph structure between battery parameters to capture the\ncomplex interactions and the graph-learning algorithm to model the intrinsic\nbattery degradation for RUL prognosis. The proposed method outperforms several\npopular methods by a significant margin on publicly available battery datasets\nand achieves SOTA performance. We report the ablation studies to support the\nefficacy of our approach.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted in Workshop on Graph Learning for Industrial Applications :\n  Finance, Crime Detection, Medicine, and Social Media (NeurIPS 2022)",
    "pdf_url": "http://arxiv.org/pdf/2408.07624v1",
    "published_date": "2024-08-14 15:44:56 UTC",
    "updated_date": "2024-08-14 15:44:56 UTC"
  },
  {
    "arxiv_id": "2408.08915v1",
    "title": "A Survey on Blockchain-based Supply Chain Finance with Progress and Future directions",
    "authors": [
      "Zhengdong Luo"
    ],
    "abstract": "Supply Chain Finance is very important for supply chain competition, which is\nan important tool to activate the capital flow in the supply chain. Supply\nChain Finance-related research can support multiple applications and services,\nsuch as providing accounts receivable financing, enhancing risk management, and\noptimizing supply chain management. For more than a decade, the development of\nBlockchain has attracted widely attention in various fields, especially in\nfinance. With the characteristics of data tamper-proof, forgery-proof,\ncryptography, consensus verification, and decentralization, Blockchain fits\nwell with the realistic needs of Supply Chain Finance, which requires data\nintegrity, authenticity, privacy, and information sharing. Therefore, it is\ntime to summarize the applications of Blockchain technology in the field of\nSupply Chain Finance. What Blockchain technology brings to Supply Chain Finance\nis not only to alleviate the problems of information asymmetry, credit\ndisassembly, and financing cost, but also to improve Supply Chain Finance\noperations through smart contracts to intelligent Supply Chain Finance and in\ncombination with other technologies, such as artificial intelligence, cloud\ncomputing, and data mining, jointly. So there has been some work in\nBlockchain-based Supply Chain Finance research for different Supply Chain\nFinance oriented applications, but most of these work are at the management\nlevel to propose conceptual frameworks or simply use Blockchain without\nexploiting its deep applications. Moreover, there are few systematic reviews\nproviding a comprehensive summary of current work in the area of\nBlockchain-based Supply Chain Finance. In this paper, we ...",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.08915v1",
    "published_date": "2024-08-14 15:08:51 UTC",
    "updated_date": "2024-08-14 15:08:51 UTC"
  },
  {
    "arxiv_id": "2408.07583v2",
    "title": "Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey",
    "authors": [
      "Hamza Kheddar"
    ],
    "abstract": "With significant advancements in Transformers LLMs, NLP has extended its\nreach into many research fields due to its enhanced capabilities in text\ngeneration and user interaction. One field benefiting greatly from these\nadvancements is cybersecurity. In cybersecurity, many parameters that need to\nbe protected and exchanged between senders and receivers are in the form of\ntext and tabular data, making NLP a valuable tool in enhancing the security\nmeasures of communication protocols. This survey paper provides a comprehensive\nanalysis of the utilization of Transformers and LLMs in cyber-threat detection\nsystems. The methodology of paper selection and bibliometric analysis is\noutlined to establish a rigorous framework for evaluating existing research.\nThe fundamentals of Transformers are discussed, including background\ninformation on various cyber-attacks and datasets commonly used in this field.\nThe survey explores the application of Transformers in IDSs, focusing on\ndifferent architectures such as Attention-based models, LLMs like BERT and GPT,\nCNN/LSTM-Transformer hybrids, emerging approaches like ViTs, among others.\nFurthermore, it explores the diverse environments and applications where\nTransformers and LLMs-based IDS have been implemented, including computer\nnetworks, IoT devices, critical infrastructure protection, cloud computing,\nSDN, as well as in autonomous vehicles. The paper also addresses research\nchallenges and future directions in this area, identifying key issues such as\ninterpretability, scalability, and adaptability to evolving threats, and more.\nFinally, the conclusion summarizes the findings and highlights the significance\nof Transformers and LLMs in enhancing cyber-threat detection capabilities,\nwhile also outlining potential avenues for further research and development.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "eess.AS"
    ],
    "primary_category": "cs.CR",
    "comment": "arXiv admin note: text overlap with arXiv:2405.04760 by other authors",
    "pdf_url": "http://arxiv.org/pdf/2408.07583v2",
    "published_date": "2024-08-14 14:28:11 UTC",
    "updated_date": "2025-01-14 10:52:15 UTC"
  },
  {
    "arxiv_id": "2408.07726v2",
    "title": "Development of a graph neural network surrogate for travel demand modelling",
    "authors": [
      "Nikita Makarov",
      "Santhanakrishnan Narayanan",
      "Constantinos Antoniou"
    ],
    "abstract": "As urban environments grow, the modelling of transportation systems becomes\nincreasingly complex. This paper advances the field of travel demand modelling\nby introducing advanced Graph Neural Network (GNN) architectures as surrogate\nmodels, addressing key limitations of previous approaches. Building on prior\nwork with Graph Convolutional Networks (GCNs), we introduce GATv3, a new Graph\nAttention Network (GAT) variant that mitigates over-smoothing through residual\nconnections, enabling deeper and more expressive architectures. Additionally,\nwe propose a fine-grained classification framework that improves predictive\nstability while achieving numerical precision comparable to regression,\noffering a more interpretable and efficient alternative. To enhance model\nperformance, we develop a synthetic data generation strategy, which expands the\naugmented training dataset without overfitting. Our experiments demonstrate\nthat GATv3 significantly improves classification performance, while the GCN\nmodel shows unexpected dominance in fine-grained classification when\nsupplemented with additional training data. The results highlight the\nadvantages of fine-grained classification over regression for travel demand\nmodelling tasks and reveal new challenges in extending GAT-based architectures\nto complex transport scenarios. Notably, GATv3 appears well-suited for\nclassification-based transportation applications, such as section control and\ncongestion warning systems, which require a higher degree of differentiation\namong neighboring links. These findings contribute to refining GNN-based\nsurrogates, offering new possibilities for applying GATv3 and fine-grained\nclassification in broader transportation challenges.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.07726v2",
    "published_date": "2024-08-14 14:18:47 UTC",
    "updated_date": "2025-03-20 10:47:07 UTC"
  },
  {
    "arxiv_id": "2408.07576v2",
    "title": "MetaSeg: MetaFormer-based Global Contexts-aware Network for Efficient Semantic Segmentation",
    "authors": [
      "Beoungwoo Kang",
      "Seunghun Moon",
      "Yubin Cho",
      "Hyunwoo Yu",
      "Suk-Ju Kang"
    ],
    "abstract": "Beyond the Transformer, it is important to explore how to exploit the\ncapacity of the MetaFormer, an architecture that is fundamental to the\nperformance improvements of the Transformer. Previous studies have exploited it\nonly for the backbone network. Unlike previous studies, we explore the capacity\nof the Metaformer architecture more extensively in the semantic segmentation\ntask. We propose a powerful semantic segmentation network, MetaSeg, which\nleverages the Metaformer architecture from the backbone to the decoder. Our\nMetaSeg shows that the MetaFormer architecture plays a significant role in\ncapturing the useful contexts for the decoder as well as for the backbone. In\naddition, recent segmentation methods have shown that using a CNN-based\nbackbone for extracting the spatial information and a decoder for extracting\nthe global information is more effective than using a transformer-based\nbackbone with a CNN-based decoder. This motivates us to adopt the CNN-based\nbackbone using the MetaFormer block and design our MetaFormer-based decoder,\nwhich consists of a novel self-attention module to capture the global contexts.\nTo consider both the global contexts extraction and the computational\nefficiency of the self-attention for semantic segmentation, we propose a\nChannel Reduction Attention (CRA) module that reduces the channel dimension of\nthe query and key into the one dimension. In this way, our proposed MetaSeg\noutperforms the previous state-of-the-art methods with more efficient\ncomputational costs on popular semantic segmentation and a medical image\nsegmentation benchmark, including ADE20K, Cityscapes, COCO-stuff, and Synapse.\nThe code is available at https://github.com/hyunwoo137/MetaSeg.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by WACV 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.07576v2",
    "published_date": "2024-08-14 14:16:52 UTC",
    "updated_date": "2024-08-15 03:55:11 UTC"
  },
  {
    "arxiv_id": "2408.07575v1",
    "title": "A General Framework for Constraint-based Causal Learning",
    "authors": [
      "Kai Z. Teh",
      "Kayvan Sadeghi",
      "Terry Soo"
    ],
    "abstract": "By representing any constraint-based causal learning algorithm via a\nplaceholder property, we decompose the correctness condition into a part\nrelating the distribution and the true causal graph, and a part that depends\nsolely on the distribution. This provides a general framework to obtain\ncorrectness conditions for causal learning, and has the following implications.\nWe provide exact correctness conditions for the PC algorithm, which are then\nrelated to correctness conditions of some other existing causal discovery\nalgorithms. We show that the sparsest Markov representation condition is the\nweakest correctness condition resulting from existing notions of minimality for\nmaximal ancestral graphs and directed acyclic graphs. We also reason that\nadditional knowledge than just Pearl-minimality is necessary for causal\nlearning beyond faithfulness.",
    "categories": [
      "cs.AI",
      "math.ST",
      "stat.ME",
      "stat.TH"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.07575v1",
    "published_date": "2024-08-14 14:16:02 UTC",
    "updated_date": "2024-08-14 14:16:02 UTC"
  },
  {
    "arxiv_id": "2408.07569v1",
    "title": "Multi-task Heterogeneous Graph Learning on Electronic Health Records",
    "authors": [
      "Tsai Hor Chan",
      "Guosheng Yin",
      "Kyongtae Bae",
      "Lequan Yu"
    ],
    "abstract": "Learning electronic health records (EHRs) has received emerging attention\nbecause of its capability to facilitate accurate medical diagnosis. Since the\nEHRs contain enriched information specifying complex interactions between\nentities, modeling EHRs with graphs is shown to be effective in practice. The\nEHRs, however, present a great degree of heterogeneity, sparsity, and\ncomplexity, which hamper the performance of most of the models applied to them.\nMoreover, existing approaches modeling EHRs often focus on learning the\nrepresentations for a single task, overlooking the multi-task nature of EHR\nanalysis problems and resulting in limited generalizability across different\ntasks. In view of these limitations, we propose a novel framework for EHR\nmodeling, namely MulT-EHR (Multi-Task EHR), which leverages a heterogeneous\ngraph to mine the complex relations and model the heterogeneity in the EHRs. To\nmitigate the large degree of noise, we introduce a denoising module based on\nthe causal inference framework to adjust for severe confounding effects and\nreduce noise in the EHR data. Additionally, since our model adopts a single\ngraph neural network for simultaneous multi-task prediction, we design a\nmulti-task learning module to leverage the inter-task knowledge to regularize\nthe training process. Extensive empirical studies on MIMIC-III and MIMIC-IV\ndatasets validate that the proposed method consistently outperforms the\nstate-of-the-art designs in four popular EHR analysis tasks -- drug\nrecommendation, and predictions of the length of stay, mortality, and\nreadmission. Thorough ablation studies demonstrate the robustness of our method\nupon variations to key components and hyperparameters.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by Neural Networks",
    "pdf_url": "http://arxiv.org/pdf/2408.07569v1",
    "published_date": "2024-08-14 14:06:13 UTC",
    "updated_date": "2024-08-14 14:06:13 UTC"
  },
  {
    "arxiv_id": "2408.07547v1",
    "title": "PeriodWave: Multi-Period Flow Matching for High-Fidelity Waveform Generation",
    "authors": [
      "Sang-Hoon Lee",
      "Ha-Yeong Choi",
      "Seong-Whan Lee"
    ],
    "abstract": "Recently, universal waveform generation tasks have been investigated\nconditioned on various out-of-distribution scenarios. Although GAN-based\nmethods have shown their strength in fast waveform generation, they are\nvulnerable to train-inference mismatch scenarios such as two-stage\ntext-to-speech. Meanwhile, diffusion-based models have shown their powerful\ngenerative performance in other domains; however, they stay out of the\nlimelight due to slow inference speed in waveform generation tasks. Above all,\nthere is no generator architecture that can explicitly disentangle the natural\nperiodic features of high-resolution waveform signals. In this paper, we\npropose PeriodWave, a novel universal waveform generation model. First, we\nintroduce a period-aware flow matching estimator that can capture the periodic\nfeatures of the waveform signal when estimating the vector fields.\nAdditionally, we utilize a multi-period estimator that avoids overlaps to\ncapture different periodic features of waveform signals. Although increasing\nthe number of periods can improve the performance significantly, this requires\nmore computational costs. To reduce this issue, we also propose a single\nperiod-conditional universal estimator that can feed-forward parallel by\nperiod-wise batch inference. Additionally, we utilize discrete wavelet\ntransform to losslessly disentangle the frequency information of waveform\nsignals for high-frequency modeling, and introduce FreeU to reduce the\nhigh-frequency noise for waveform generation. The experimental results\ndemonstrated that our model outperforms the previous models both in\nMel-spectrogram reconstruction and text-to-speech tasks. All source code will\nbe available at \\url{https://github.com/sh-lee-prml/PeriodWave}.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "eess.AS",
      "eess.SP"
    ],
    "primary_category": "cs.SD",
    "comment": "24 pages, 16 tables, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.07547v1",
    "published_date": "2024-08-14 13:36:17 UTC",
    "updated_date": "2024-08-14 13:36:17 UTC"
  },
  {
    "arxiv_id": "2408.07545v1",
    "title": "$χ$SPN: Characteristic Interventional Sum-Product Networks for Causal Inference in Hybrid Domains",
    "authors": [
      "Harsh Poonia",
      "Moritz Willig",
      "Zhongjie Yu",
      "Matej Zečević",
      "Kristian Kersting",
      "Devendra Singh Dhami"
    ],
    "abstract": "Causal inference in hybrid domains, characterized by a mixture of discrete\nand continuous variables, presents a formidable challenge. We take a step\ntowards this direction and propose Characteristic Interventional Sum-Product\nNetwork ($\\chi$SPN) that is capable of estimating interventional distributions\nin presence of random variables drawn from mixed distributions. $\\chi$SPN uses\ncharacteristic functions in the leaves of an interventional SPN (iSPN) thereby\nproviding a unified view for discrete and continuous random variables through\nthe Fourier-Stieltjes transform of the probability measures. A neural network\nis used to estimate the parameters of the learned iSPN using the intervened\ndata. Our experiments on 3 synthetic heterogeneous datasets suggest that\n$\\chi$SPN can effectively capture the interventional distributions for both\ndiscrete and continuous variables while being expressive and causally adequate.\nWe also show that $\\chi$SPN generalize to multiple interventions while being\ntrained only on a single intervention data.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "17 pages, 11 figures. Accepted as poster at UAI (Uncertainty in\n  Artificial Intelligence) 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.07545v1",
    "published_date": "2024-08-14 13:31:32 UTC",
    "updated_date": "2024-08-14 13:31:32 UTC"
  },
  {
    "arxiv_id": "2408.07544v1",
    "title": "Planning with OWL-DL Ontologies (Extended Version)",
    "authors": [
      "Tobias John",
      "Patrick Koopmann"
    ],
    "abstract": "We introduce ontology-mediated planning, in which planning problems are\ncombined with an ontology. Our formalism differs from existing ones in that we\nfocus on a strong separation of the formalisms for describing planning problems\nand ontologies, which are only losely coupled by an interface. Moreover, we\npresent a black-box algorithm that supports the full expressive power of OWL\nDL. This goes beyond what existing approaches combining automated planning with\nontologies can do, which only support limited description logics such as\nDL-Lite and description logics that are Horn. Our main algorithm relies on\nrewritings of the ontology-mediated planning specifications into PDDL, so that\nexisting planning systems can be used to solve them. The algorithm relies on\njustifications, which allows for a generic approach that is independent of the\nexpressivity of the ontology language. However, dedicated optimizations for\ncomputing justifications need to be implemented to enable an efficient\nrewriting procedure. We evaluated our implementation on benchmark sets from\nseveral domains. The evaluation shows that our procedure works in practice and\nthat tailoring the reasoning procedure has significant impact on the\nperformance.",
    "categories": [
      "cs.AI",
      "I.2.4"
    ],
    "primary_category": "cs.AI",
    "comment": "Extended version of a paper accepted at ECAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.07544v1",
    "published_date": "2024-08-14 13:27:02 UTC",
    "updated_date": "2024-08-14 13:27:02 UTC"
  },
  {
    "arxiv_id": "2408.07542v1",
    "title": "New Curriculum, New Chance -- Retrieval Augmented Generation for Lesson Planning in Ugandan Secondary Schools. Prototype Quality Evaluation",
    "authors": [
      "Simon Kloker",
      "Herbertson Bukoli",
      "Twaha Kateete"
    ],
    "abstract": "Introduction: Poor educational quality in Secondary Schools is still regarded\nas one of the major struggles in 21st century Uganda - especially in rural\nareas. Research identifies several problems, including low quality or absent\nteacher lesson planning. As the government pushes towards the implementation of\na new curriculum, exiting lesson plans become obsolete and the problem is\nworsened. Using a Retrieval Augmented Generation approach, we developed a\nprototype that generates customized lesson plans based on the\ngovernment-accredited textbooks. This helps teachers create lesson plans more\nefficiently and with better quality, ensuring they are fully aligned the new\ncurriculum and the competence-based learning approach.\n  Methods: The prototype was created using Cohere LLM and Sentence Embeddings,\nand LangChain Framework - and thereafter made available on a public website.\nVector stores were trained for three new curriculum textbooks (ICT,\nMathematics, History), all at Secondary 1 Level. Twenty-four lessons plans were\ngenerated following a pseudo-random generation protocol, based on the suggested\nperiods in the textbooks. The lesson plans were analyzed regarding their\ntechnical quality by three independent raters following the Lesson Plan\nAnalysis Protocol (LPAP) by Ndihokubwayo et al. (2022) that is specifically\ndesigned for East Africa and competence-based curriculums.\n  Results: Evaluation of 24 lesson plans using the LPAP resulted in an average\nquality of between 75 and 80%, corresponding to \"very good lesson plan\". None\nof the lesson plans scored below 65%, although one lesson plan could be argued\nto have been missing the topic. In conclusion, the quality of the generated\nlesson plans is at least comparable, if not better, than those created by\nhumans, as demonstrated in a study in Rwanda, whereby no lesson plan even\nreached the benchmark of 50%.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "Presented at Ndejje University Second Annual Research Dissemination\n  Symposium 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.07542v1",
    "published_date": "2024-08-14 13:22:14 UTC",
    "updated_date": "2024-08-14 13:22:14 UTC"
  },
  {
    "arxiv_id": "2408.07541v1",
    "title": "DifuzCam: Replacing Camera Lens with a Mask and a Diffusion Model",
    "authors": [
      "Erez Yosef",
      "Raja Giryes"
    ],
    "abstract": "The flat lensless camera design reduces the camera size and weight\nsignificantly. In this design, the camera lens is replaced by another optical\nelement that interferes with the incoming light. The image is recovered from\nthe raw sensor measurements using a reconstruction algorithm. Yet, the quality\nof the reconstructed images is not satisfactory. To mitigate this, we propose\nutilizing a pre-trained diffusion model with a control network and a learned\nseparable transformation for reconstruction. This allows us to build a\nprototype flat camera with high-quality imaging, presenting state-of-the-art\nresults in both terms of quality and perceptuality. We demonstrate its ability\nto leverage also textual descriptions of the captured scene to further enhance\nreconstruction. Our reconstruction method which leverages the strong\ncapabilities of a pre-trained diffusion model can be used in other imaging\nsystems for improved reconstruction results.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.07541v1",
    "published_date": "2024-08-14 13:20:52 UTC",
    "updated_date": "2024-08-14 13:20:52 UTC"
  },
  {
    "arxiv_id": "2408.07539v1",
    "title": "Cross-aware Early Fusion with Stage-divided Vision and Language Transformer Encoders for Referring Image Segmentation",
    "authors": [
      "Yubin Cho",
      "Hyunwoo Yu",
      "Suk-ju Kang"
    ],
    "abstract": "Referring segmentation aims to segment a target object related to a natural\nlanguage expression. Key challenges of this task are understanding the meaning\nof complex and ambiguous language expressions and determining the relevant\nregions in the image with multiple objects by referring to the expression.\nRecent models have focused on the early fusion with the language features at\nthe intermediate stage of the vision encoder, but these approaches have a\nlimitation that the language features cannot refer to the visual information.\nTo address this issue, this paper proposes a novel architecture, Cross-aware\nearly fusion with stage-divided Vision and Language Transformer encoders\n(CrossVLT), which allows both language and vision encoders to perform the early\nfusion for improving the ability of the cross-modal context modeling. Unlike\nprevious methods, our method enables the vision and language features to refer\nto each other's information at each stage to mutually enhance the robustness of\nboth encoders. Furthermore, unlike the conventional scheme that relies solely\non the high-level features for the cross-modal alignment, we introduce a\nfeature-based alignment scheme that enables the low-level to high-level\nfeatures of the vision and language encoders to engage in the cross-modal\nalignment. By aligning the intermediate cross-modal features in all encoder\nstages, this scheme leads to effective cross-modal fusion. In this way, the\nproposed approach is simple but effective for referring image segmentation, and\nit outperforms the previous state-of-the-art methods on three public\nbenchmarks.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Published in IEEE Transactions on Multimedia (TMM)",
    "pdf_url": "http://arxiv.org/pdf/2408.07539v1",
    "published_date": "2024-08-14 13:17:41 UTC",
    "updated_date": "2024-08-14 13:17:41 UTC"
  },
  {
    "arxiv_id": "2408.07531v2",
    "title": "Development of a Large Language Model-based Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments",
    "authors": [
      "Seungjun Han",
      "Wongyung Choi"
    ],
    "abstract": "Emergency department (ED) overcrowding and the complexity of rapid\ndecision-making in critical care settings pose significant challenges to\nhealthcare systems worldwide. While clinical decision support systems (CDSS)\nhave shown promise, the integration of large language models (LLMs) offers new\npossibilities for enhancing triage accuracy and clinical decision-making. This\nstudy presents an LLM-driven CDSS designed to assist ED physicians and nurses\nin patient triage, treatment planning, and overall emergency care management.\n  We developed a multi-agent CDSS utilizing Llama-3-70b as the base LLM,\norchestrated by CrewAI and Langchain. The system comprises four AI agents\nemulating key ED roles: Triage Nurse, Emergency Physician, Pharmacist, and ED\nCoordinator. It incorporates the Korean Triage and Acuity Scale (KTAS) for\ntriage assessment and integrates with the RxNorm API for medication management.\n  The model was evaluated using the Asclepius dataset, with performance\nassessed by a clinical emergency medicine specialist. The CDSS demonstrated\nhigh accuracy in triage decision-making compared to the baseline of a\nsingle-agent system. Furthermore, the system exhibited strong performance in\ncritical areas, including primary diagnosis, critical findings identification,\ndisposition decision-making, treatment planning, and resource allocation.\n  Our multi-agent CDSS demonstrates significant potential for supporting\ncomprehensive emergency care management. By leveraging state-of-the-art AI\ntechnologies, this system offers a scalable and adaptable tool that could\nenhance emergency medical care delivery, potentially alleviating ED\novercrowding and improving patient outcomes. This work contributes to the\ngrowing field of AI applications in emergency medicine and offers a promising\ndirection for future research and clinical implementation.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.07531v2",
    "published_date": "2024-08-14 13:03:41 UTC",
    "updated_date": "2024-08-27 15:16:06 UTC"
  },
  {
    "arxiv_id": "2408.07527v2",
    "title": "Evidential Graph Contrastive Alignment for Source-Free Blending-Target Domain Adaptation",
    "authors": [
      "Juepeng Zheng",
      "Yibin Wen",
      "Jinxiao Zhang",
      "Runmin Dong",
      "Haohuan Fu"
    ],
    "abstract": "In this paper, we firstly tackle a more realistic Domain Adaptation (DA)\nsetting: Source-Free Blending-Target Domain Adaptation (SF-BTDA), where we can\nnot access to source domain data while facing mixed multiple target domains\nwithout any domain labels in prior. Compared to existing DA scenarios, SF-BTDA\ngenerally faces the co-existence of different label shifts in different\ntargets, along with noisy target pseudo labels generated from the source model.\nIn this paper, we propose a new method called Evidential Contrastive Alignment\n(ECA) to decouple the blending target domain and alleviate the effect from\nnoisy target pseudo labels. First, to improve the quality of pseudo target\nlabels, we propose a calibrated evidential learning module to iteratively\nimprove both the accuracy and certainty of the resulting model and adaptively\ngenerate high-quality pseudo target labels. Second, we design a graph\ncontrastive learning with the domain distance matrix and confidence-uncertainty\ncriterion, to minimize the distribution gap of samples of a same class in the\nblended target domains, which alleviates the co-existence of different label\nshifts in blended targets. We conduct a new benchmark based on three standard\nDA datasets and ECA outperforms other methods with considerable gains and\nachieves comparable results compared with those that have domain labels or\nsource data in prior.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.07527v2",
    "published_date": "2024-08-14 13:02:20 UTC",
    "updated_date": "2024-08-25 11:53:23 UTC"
  },
  {
    "arxiv_id": "2408.07524v1",
    "title": "Fast Inference for Probabilistic Answer Set Programs via the Residual Program",
    "authors": [
      "Damiano Azzolini",
      "Fabrizio Riguzzi"
    ],
    "abstract": "When we want to compute the probability of a query from a Probabilistic\nAnswer Set Program, some parts of a program may not influence the probability\nof a query, but they impact on the size of the grounding. Identifying and\nremoving them is crucial to speed up the computation. Algorithms for SLG\nresolution offer the possibility of returning the residual program which can be\nused for computing answer sets for normal programs that do have a total\nwell-founded model. The residual program does not contain the parts of the\nprogram that do not influence the probability. In this paper, we propose to\nexploit the residual program for performing inference. Empirical results on\ngraph datasets show that the approach leads to significantly faster inference.",
    "categories": [
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "The paper has been accepted at the ICLP2024 conference and under\n  consideration in Theory and Practice of Logic Programming (TPLP)",
    "pdf_url": "http://arxiv.org/pdf/2408.07524v1",
    "published_date": "2024-08-14 12:58:22 UTC",
    "updated_date": "2024-08-14 12:58:22 UTC"
  },
  {
    "arxiv_id": "2408.07521v1",
    "title": "Optimising Dynamic Traffic Distribution for Urban Networks with Answer Set Programming",
    "authors": [
      "Matteo Cardellini",
      "Carmine Dodaro",
      "Marco Maratea",
      "Mauro Vallati"
    ],
    "abstract": "Answer Set Programming (ASP) has demonstrated its potential as an effective\ntool for concisely representing and reasoning about real-world problems. In\nthis paper, we present an application in which ASP has been successfully used\nin the context of dynamic traffic distribution for urban networks, within a\nmore general framework devised for solving such a real-world problem. In\nparticular, ASP has been employed for the computation of the \"optimal\" routes\nfor all the vehicles in the network. We also provide an empirical analysis of\nthe performance of the whole framework, and of its part in which ASP is\nemployed, on two European urban areas, which shows the viability of the\nframework and the contribution ASP can give.",
    "categories": [
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.07521v1",
    "published_date": "2024-08-14 12:54:26 UTC",
    "updated_date": "2024-08-14 12:54:26 UTC"
  },
  {
    "arxiv_id": "2408.07510v1",
    "title": "Dominating Set Reconfiguration with Answer Set Programming",
    "authors": [
      "Masato Kato",
      "Torsten Schaub",
      "Takehide Soh",
      "Naoyuki Tamura",
      "Mutsunori Banbara"
    ],
    "abstract": "The dominating set reconfiguration problem is defined as determining, for a\ngiven dominating set problem and two among its feasible solutions, whether one\nis reachable from the other via a sequence of feasible solutions subject to a\ncertain adjacency relation. This problem is PSPACE-complete in general. The\nconcept of the dominating set is known to be quite useful for analyzing\nwireless networks, social networks, and sensor networks. We develop an approach\nto solve the dominating set reconfiguration problem based on Answer Set\nProgramming (ASP). Our declarative approach relies on a high-level ASP\nencoding, and both the grounding and solving tasks are delegated to an\nASP-based combinatorial reconfiguration solver. To evaluate the effectiveness\nof our approach, we conduct experiments on a newly created benchmark set.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.07510v1",
    "published_date": "2024-08-14 12:38:12 UTC",
    "updated_date": "2024-08-14 12:38:12 UTC"
  },
  {
    "arxiv_id": "2408.07482v3",
    "title": "Training Overhead Ratio: A Practical Reliability Metric for Large Language Model Training Systems",
    "authors": [
      "Ning Lu",
      "Qian Xie",
      "Hao Zhang",
      "Wenyi Fang",
      "Yang Zheng",
      "Zheng Hu",
      "Jiantao Ma"
    ],
    "abstract": "Large Language Models (LLMs) are revolutionizing the AI industry with their\nsuperior capabilities. Training these models requires large-scale GPU clusters\nand significant computing time, leading to frequent failures that significantly\nincrease training costs. Despite its significance, this field lacks a metric\nfor evaluating reliability. In this work, we introduce a novel reliability\nmetric called \\emph{Training Overhead Ratio} (TOR) to evaluate the reliability\nof fault-tolerant LLM training systems. TOR is defined as the ratio of optimal\ntraining time to the observed training time of a system, serving as a practical\ntool for users to estimate the actual time required to train an LLM on a given\nsystem. Furthermore, our investigation identifies the key factor for enhancing\nreliability and present TOR equations for various types of failures encountered\nin practice.",
    "categories": [
      "cs.DC",
      "cs.AI"
    ],
    "primary_category": "cs.DC",
    "comment": "To be published in: IEEE International Symposium on Software\n  Reliability Engineering (ISSRE2024) workshop",
    "pdf_url": "http://arxiv.org/pdf/2408.07482v3",
    "published_date": "2024-08-14 11:55:28 UTC",
    "updated_date": "2024-10-09 08:43:25 UTC"
  },
  {
    "arxiv_id": "2408.07479v1",
    "title": "A Study on Bias Detection and Classification in Natural Language Processing",
    "authors": [
      "Ana Sofia Evans",
      "Helena Moniz",
      "Luísa Coheur"
    ],
    "abstract": "Human biases have been shown to influence the performance of models and\nalgorithms in various fields, including Natural Language Processing. While the\nstudy of this phenomenon is garnering focus in recent years, the available\nresources are still relatively scarce, often focusing on different forms or\nmanifestations of biases. The aim of our work is twofold: 1) gather\npublicly-available datasets and determine how to better combine them to\neffectively train models in the task of hate speech detection and\nclassification; 2) analyse the main issues with these datasets, such as\nscarcity, skewed resources, and reliance on non-persistent data. We discuss\nthese issues in tandem with the development of our experiments, in which we\nshow that the combinations of different datasets greatly impact the models'\nperformance.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "68T50",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "31 pages, 15 Tables, 4 Figures",
    "pdf_url": "http://arxiv.org/pdf/2408.07479v1",
    "published_date": "2024-08-14 11:49:24 UTC",
    "updated_date": "2024-08-14 11:49:24 UTC"
  },
  {
    "arxiv_id": "2408.07465v1",
    "title": "Large Language Models Prompting With Episodic Memory",
    "authors": [
      "Dai Do",
      "Quan Tran",
      "Svetha Venkatesh",
      "Hung Le"
    ],
    "abstract": "Prompt optimization is essential for enhancing the performance of Large\nLanguage Models (LLMs) in a range of Natural Language Processing (NLP) tasks,\nparticularly in scenarios of few-shot learning where training examples are\nincorporated directly into the prompt. Despite the growing interest in\noptimizing prompts with few-shot examples, existing methods for prompt\noptimization are often resource-intensive or perform inadequately. In this\nwork, we propose PrOmpting with Episodic Memory (POEM), a novel prompt\noptimization technique that is simple, efficient, and demonstrates strong\ngeneralization capabilities. We approach prompt optimization as a Reinforcement\nLearning (RL) challenge, using episodic memory to archive combinations of input\ndata, permutations of few-shot examples, and the rewards observed during\ntraining. In the testing phase, we optimize the sequence of examples for each\ntest query by selecting the sequence that yields the highest total rewards from\nthe top-k most similar training examples in the episodic memory. Our results\nshow that POEM outperforms recent techniques like TEMPERA and RLPrompt by over\n5.3% in various text classification tasks. Furthermore, our approach adapts\nwell to broader language understanding tasks, consistently outperforming\nconventional heuristic methods for ordering examples.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.07465v1",
    "published_date": "2024-08-14 11:19:28 UTC",
    "updated_date": "2024-08-14 11:19:28 UTC"
  },
  {
    "arxiv_id": "2408.07461v4",
    "title": "Problem Solving Through Human-AI Preference-Based Cooperation",
    "authors": [
      "Subhabrata Dutta",
      "Timo Kaufmann",
      "Goran Glavaš",
      "Ivan Habernal",
      "Kristian Kersting",
      "Frauke Kreuter",
      "Mira Mezini",
      "Iryna Gurevych",
      "Eyke Hüllermeier",
      "Hinrich Schuetze"
    ],
    "abstract": "While there is a widespread belief that artificial general intelligence (AGI)\n-- or even superhuman AI -- is imminent, complex problems in expert domains are\nfar from being solved. We argue that such problems require human-AI cooperation\nand that the current state of the art in generative AI is unable to play the\nrole of a reliable partner due to a multitude of shortcomings, including\ndifficulty to keep track of a complex solution artifact (e.g., a software\nprogram), limited support for versatile human preference expression and lack of\nadapting to human preference in an interactive setting. To address these\nchallenges, we propose HAICo2, a novel human-AI co-construction framework. We\ntake first steps towards a formalization of HAICo2 and discuss the difficult\nopen research problems that it faces.",
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "20 pages",
    "pdf_url": "http://arxiv.org/pdf/2408.07461v4",
    "published_date": "2024-08-14 11:06:57 UTC",
    "updated_date": "2025-04-29 13:57:16 UTC"
  },
  {
    "arxiv_id": "2408.07453v1",
    "title": "Fact or Fiction? Improving Fact Verification with Knowledge Graphs through Simplified Subgraph Retrievals",
    "authors": [
      "Tobias A. Opsahl"
    ],
    "abstract": "Despite recent success in natural language processing (NLP), fact\nverification still remains a difficult task. Due to misinformation spreading\nincreasingly fast, attention has been directed towards automatically verifying\nthe correctness of claims. In the domain of NLP, this is usually done by\ntraining supervised machine learning models to verify claims by utilizing\nevidence from trustworthy corpora. We present efficient methods for verifying\nclaims on a dataset where the evidence is in the form of structured knowledge\ngraphs. We use the FactKG dataset, which is constructed from the DBpedia\nknowledge graph extracted from Wikipedia. By simplifying the evidence retrieval\nprocess, from fine-tuned language models to simple logical retrievals, we are\nable to construct models that both require less computational resources and\nachieve better test-set accuracy.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "10 pages, 3 figures, appendix",
    "pdf_url": "http://arxiv.org/pdf/2408.07453v1",
    "published_date": "2024-08-14 10:46:15 UTC",
    "updated_date": "2024-08-14 10:46:15 UTC"
  },
  {
    "arxiv_id": "2408.07452v1",
    "title": "CMU's IWSLT 2024 Simultaneous Speech Translation System",
    "authors": [
      "Xi Xu",
      "Siqi Ouyang",
      "Brian Yan",
      "Patrick Fernandes",
      "William Chen",
      "Lei Li",
      "Graham Neubig",
      "Shinji Watanabe"
    ],
    "abstract": "This paper describes CMU's submission to the IWSLT 2024 Simultaneous Speech\nTranslation (SST) task for translating English speech to German text in a\nstreaming manner. Our end-to-end speech-to-text (ST) system integrates the\nWavLM speech encoder, a modality adapter, and the Llama2-7B-Base model as the\ndecoder. We employ a two-stage training approach: initially, we align the\nrepresentations of speech and text, followed by full fine-tuning. Both stages\nare trained on MuST-c v2 data with cross-entropy loss. We adapt our offline ST\nmodel for SST using a simple fixed hold-n policy. Experiments show that our\nmodel obtains an offline BLEU score of 31.1 and a BLEU score of 29.5 under 2\nseconds latency on the MuST-C-v2 tst-COMMON.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.07452v1",
    "published_date": "2024-08-14 10:44:51 UTC",
    "updated_date": "2024-08-14 10:44:51 UTC"
  },
  {
    "arxiv_id": "2408.07448v2",
    "title": "LiveFC: A System for Live Fact-Checking of Audio Streams",
    "authors": [
      "Venktesh V",
      "Vinay Setty"
    ],
    "abstract": "The advances in the digital era have led to rapid dissemination of\ninformation. This has also aggravated the spread of misinformation and\ndisinformation. This has potentially serious consequences, such as civil\nunrest. While fact-checking aims to combat this, manual fact-checking is\ncumbersome and not scalable. While automated fact-checking approaches exist,\nthey do not operate in real-time and do not always account for spread of\nmisinformation through different modalities. This is particularly important as\nproactive fact-checking on live streams in real-time can help people be\ninformed of false narratives and prevent catastrophic consequences that may\ncause civil unrest. This is particularly relevant with the rapid dissemination\nof information through video on social media platforms or other streams like\npolitical rallies and debates. Hence, in this work we develop a platform named\nLiveFC, that can aid in fact-checking live audio streams in real-time. LiveFC\nhas a user-friendly interface that displays the claims detected along with\ntheir veracity and evidence for live streams with associated speakers for\nclaims from respective segments. The app can be accessed at\nhttp://livefc.factiverse.ai and a screen recording of the demo can be found at\nhttps://bit.ly/3WVAoIw.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Under Review, 11 pages",
    "pdf_url": "http://arxiv.org/pdf/2408.07448v2",
    "published_date": "2024-08-14 10:36:17 UTC",
    "updated_date": "2024-09-02 11:45:41 UTC"
  },
  {
    "arxiv_id": "2408.12622v2",
    "title": "The AI Risk Repository: A Comprehensive Meta-Review, Database, and Taxonomy of Risks From Artificial Intelligence",
    "authors": [
      "Peter Slattery",
      "Alexander K. Saeri",
      "Emily A. C. Grundy",
      "Jess Graham",
      "Michael Noetel",
      "Risto Uuk",
      "James Dao",
      "Soroush Pour",
      "Stephen Casper",
      "Neil Thompson"
    ],
    "abstract": "The risks posed by Artificial Intelligence (AI) are of considerable concern\nto academics, auditors, policymakers, AI companies, and the public. However, a\nlack of shared understanding of AI risks can impede our ability to\ncomprehensively discuss, research, and react to them. This paper addresses this\ngap by creating an AI Risk Repository to serve as a common frame of reference.\nThis comprises a living database of 777 risks extracted from 43 taxonomies,\nwhich can be filtered based on two overarching taxonomies and easily accessed,\nmodified, and updated via our website and online spreadsheets. We construct our\nRepository with a systematic review of taxonomies and other structured\nclassifications of AI risk followed by an expert consultation. We develop our\ntaxonomies of AI risk using a best-fit framework synthesis. Our high-level\nCausal Taxonomy of AI Risks classifies each risk by its causal factors (1)\nEntity: Human, AI; (2) Intentionality: Intentional, Unintentional; and (3)\nTiming: Pre-deployment; Post-deployment. Our mid-level Domain Taxonomy of AI\nRisks classifies risks into seven AI risk domains: (1) Discrimination &\ntoxicity, (2) Privacy & security, (3) Misinformation, (4) Malicious actors &\nmisuse, (5) Human-computer interaction, (6) Socioeconomic & environmental, and\n(7) AI system safety, failures, & limitations. These are further divided into\n23 subdomains. The AI Risk Repository is, to our knowledge, the first attempt\nto rigorously curate, analyze, and extract AI risk frameworks into a publicly\naccessible, comprehensive, extensible, and categorized risk database. This\ncreates a foundation for a more coordinated, coherent, and complete approach to\ndefining, auditing, and managing the risks posed by AI systems.",
    "categories": [
      "cs.AI",
      "cs.CR",
      "cs.ET",
      "cs.LG",
      "cs.SY",
      "eess.SY",
      "I.2.0; K.4.1; K.4.1; K.4.2; K.4.3; K.6.0"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.12622v2",
    "published_date": "2024-08-14 10:32:06 UTC",
    "updated_date": "2025-04-10 21:14:02 UTC"
  },
  {
    "arxiv_id": "2408.07438v1",
    "title": "Achieving Data Efficient Neural Networks with Hybrid Concept-based Models",
    "authors": [
      "Tobias A. Opsahl",
      "Vegard Antun"
    ],
    "abstract": "Most datasets used for supervised machine learning consist of a single label\nper data point. However, in cases where more information than just the class\nlabel is available, would it be possible to train models more efficiently? We\nintroduce two novel model architectures, which we call hybrid concept-based\nmodels, that train using both class labels and additional information in the\ndataset referred to as concepts. In order to thoroughly assess their\nperformance, we introduce ConceptShapes, an open and flexible class of datasets\nwith concept labels. We show that the hybrid concept-based models outperform\nstandard computer vision models and previously proposed concept-based models\nwith respect to accuracy, especially in sparse data settings. We also introduce\nan algorithm for performing adversarial concept attacks, where an image is\nperturbed in a way that does not change a concept-based model's concept\npredictions, but changes the class prediction. The existence of such\nadversarial examples raises questions about the interpretable qualities\npromised by concept-based models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "11 pages, 8 figures, appendix",
    "pdf_url": "http://arxiv.org/pdf/2408.07438v1",
    "published_date": "2024-08-14 10:15:34 UTC",
    "updated_date": "2024-08-14 10:15:34 UTC"
  },
  {
    "arxiv_id": "2408.07720v1",
    "title": "Re-Thinking Process Mining in the AI-Based Agents Era",
    "authors": [
      "Alessandro Berti",
      "Mayssa Maatallah",
      "Urszula Jessen",
      "Michal Sroka",
      "Sonia Ayachi Ghannouchi"
    ],
    "abstract": "Large Language Models (LLMs) have emerged as powerful conversational\ninterfaces, and their application in process mining (PM) tasks has shown\npromising results. However, state-of-the-art LLMs struggle with complex\nscenarios that demand advanced reasoning capabilities. In the literature, two\nprimary approaches have been proposed for implementing PM using LLMs: providing\ntextual insights based on a textual abstraction of the process mining artifact,\nand generating code executable on the original artifact. This paper proposes\nutilizing the AI-Based Agents Workflow (AgWf) paradigm to enhance the\neffectiveness of PM on LLMs. This approach allows for: i) the decomposition of\ncomplex tasks into simpler workflows, and ii) the integration of deterministic\ntools with the domain knowledge of LLMs. We examine various implementations of\nAgWf and the types of AI-based tasks involved. Additionally, we discuss the\nCrewAI implementation framework and present examples related to process mining.",
    "categories": [
      "cs.AI",
      "cs.DB"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.07720v1",
    "published_date": "2024-08-14 10:14:18 UTC",
    "updated_date": "2024-08-14 10:14:18 UTC"
  },
  {
    "arxiv_id": "2408.07435v2",
    "title": "Real-world validation of safe reinforcement learning, model predictive control and decision tree-based home energy management systems",
    "authors": [
      "Julian Ruddick",
      "Glenn Ceusters",
      "Gilles Van Kriekinge",
      "Evgenii Genov",
      "Cedric De Cauwer",
      "Thierry Coosemans",
      "Maarten Messagie"
    ],
    "abstract": "Recent advancements in machine learning based energy management approaches,\nspecifically reinforcement learning with a safety layer (OptLayerPolicy) and a\nmetaheuristic algorithm generating a decision tree control policy (TreeC), have\nshown promise. However, their effectiveness has only been demonstrated in\ncomputer simulations. This paper presents the real-world validation of these\nmethods, comparing against model predictive control and simple rule-based\ncontrol benchmark. The experiments were conducted on the electrical\ninstallation of 4 reproductions of residential houses, which all have their own\nbattery, photovoltaic and dynamic load system emulating a non-controllable\nelectrical load and a controllable electric vehicle charger. The results show\nthat the simple rules, TreeC, and model predictive control-based methods\nachieved similar costs, with a difference of only 0.6%. The reinforcement\nlearning based method, still in its training phase, obtained a cost 25.5\\%\nhigher to the other methods. Additional simulations show that the costs can be\nfurther reduced by using a more representative training dataset for TreeC and\naddressing errors in the model predictive control implementation caused by its\nreliance on accurate data from various sources. The OptLayerPolicy safety layer\nallows safe online training of a reinforcement learning agent in the\nreal-world, given an accurate constraint function formulation. The proposed\nsafety layer method remains error-prone, nonetheless, it is found beneficial\nfor all investigated methods. The TreeC method, which does require building a\nrealistic simulation for training, exhibits the safest operational performance,\nexceeding the grid limit by only 27.1 Wh compared to 593.9 Wh for reinforcement\nlearning.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.LG",
      "cs.NE",
      "cs.SY"
    ],
    "primary_category": "eess.SY",
    "comment": "Accepted version Energy and AI:\n  https://doi.org/10.1016/j.egyai.2024.100448",
    "pdf_url": "http://arxiv.org/pdf/2408.07435v2",
    "published_date": "2024-08-14 10:12:15 UTC",
    "updated_date": "2024-11-25 09:45:15 UTC"
  },
  {
    "arxiv_id": "2408.07433v5",
    "title": "MagicFace: Training-free Universal-Style Human Image Customized Synthesis",
    "authors": [
      "Yibin Wang",
      "Weizhong Zhang",
      "Cheng Jin"
    ],
    "abstract": "Current human image customization methods leverage Stable Diffusion (SD) for\nits rich semantic prior. However, since SD is not specifically designed for\nhuman-oriented generation, these methods often require extensive fine-tuning on\nlarge-scale datasets, which renders them susceptible to overfitting and hinders\ntheir ability to personalize individuals with previously unseen styles.\nMoreover, these methods extensively focus on single-concept human image\nsynthesis and lack the flexibility to customize individuals using multiple\ngiven concepts, thereby impeding their broader practical application. This\npaper proposes MagicFace, a novel training-free method for multi-concept\nuniversal-style human image personalized synthesis. Our core idea is to\nsimulate how humans create images given specific concepts, i.e., first\nestablish a semantic layout considering factors such as concepts' shape and\nposture, then optimize details by comparing with concepts at the pixel level.\nTo implement this process, we introduce a coarse-to-fine generation pipeline,\ninvolving two sequential stages: semantic layout construction and concept\nfeature injection. This is achieved by our Reference-aware Self-Attention (RSA)\nand Region-grouped Blend Attention (RBA) mechanisms. In the first stage, RSA\nenables the latent image to query features from all reference concepts\nsimultaneously, extracting the overall semantic understanding to facilitate the\ninitial semantic layout establishment. In the second stage, we employ an\nattention-based semantic segmentation method to pinpoint the latent generated\nregions of all concepts at each step. Following this, RBA divides the pixels of\nthe latent image into semantic groups, with each group querying fine-grained\nfeatures from the corresponding reference concept. Extensive experiments\ndemonstrate the superiority of our MagicFace.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "project page: https://codegoat24.github.io/MagicFace",
    "pdf_url": "http://arxiv.org/pdf/2408.07433v5",
    "published_date": "2024-08-14 10:08:46 UTC",
    "updated_date": "2024-11-18 03:14:37 UTC"
  },
  {
    "arxiv_id": "2408.07425v1",
    "title": "Exploring Retrieval Augmented Generation in Arabic",
    "authors": [
      "Samhaa R. El-Beltagy",
      "Mohamed A. Abdallah"
    ],
    "abstract": "Recently, Retrieval Augmented Generation (RAG) has emerged as a powerful\ntechnique in natural language processing, combining the strengths of\nretrieval-based and generation-based models to enhance text generation tasks.\nHowever, the application of RAG in Arabic, a language with unique\ncharacteristics and resource constraints, remains underexplored. This paper\npresents a comprehensive case study on the implementation and evaluation of RAG\nfor Arabic text. The work focuses on exploring various semantic embedding\nmodels in the retrieval stage and several LLMs in the generation stage, in\norder to investigate what works and what doesn't in the context of Arabic. The\nwork also touches upon the issue of variations between document dialect and\nquery dialect in the retrieval stage. Results show that existing semantic\nembedding models and LLMs can be effectively employed to build Arabic RAG\npipelines.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.07425v1",
    "published_date": "2024-08-14 10:03:28 UTC",
    "updated_date": "2024-08-14 10:03:28 UTC"
  },
  {
    "arxiv_id": "2408.07422v2",
    "title": "LLMI3D: MLLM-based 3D Perception from a Single 2D Image",
    "authors": [
      "Fan Yang",
      "Sicheng Zhao",
      "Yanhao Zhang",
      "Hui Chen",
      "Haonan Lu",
      "Jungong Han",
      "Guiguang Ding"
    ],
    "abstract": "Recent advancements in autonomous driving, augmented reality, robotics, and\nembodied intelligence have necessitated 3D perception algorithms. However,\ncurrent 3D perception methods, especially specialized small models, exhibit\npoor generalization in open scenarios. On the other hand, multimodal large\nlanguage models (MLLMs) excel in general capacity but underperform in 3D tasks,\ndue to weak 3D local spatial object perception, poor text-based geometric\nnumerical output, and inability to handle camera focal variations. To address\nthese challenges, we propose the following solutions: Spatial-Enhanced Local\nFeature Mining for better spatial feature extraction, 3D Query Token-Derived\nInfo Decoding for precise geometric regression, and Geometry Projection-Based\n3D Reasoning for handling camera focal length variations. We employ\nparameter-efficient fine-tuning for a pre-trained MLLM and develop LLMI3D, a\npowerful 3D perception MLLM. Additionally, we have constructed the IG3D\ndataset, which provides fine-grained descriptions and question-answer\nannotations. Extensive experiments demonstrate that our LLMI3D achieves\nstate-of-the-art performance, outperforming other methods by a large margin.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.07422v2",
    "published_date": "2024-08-14 10:00:16 UTC",
    "updated_date": "2025-02-13 09:32:44 UTC"
  },
  {
    "arxiv_id": "2408.07417v1",
    "title": "The Restaurant Meal Delivery Problem with Ghost Kitchens",
    "authors": [
      "Gal Neria",
      "Florentin D Hildebrandt",
      "Michal Tzur",
      "Marlin W Ulmer"
    ],
    "abstract": "Restaurant meal delivery has been rapidly growing in the last few years. The\nmain challenges in operating it are the temporally and spatially dispersed\nstochastic demand that arrives from customers all over town as well as the\ncustomers' expectation of timely and fresh delivery. To overcome these\nchallenges a new business concept emerged, \"Ghost kitchens\". This concept\nproposes synchronized food preparation of several restaurants in a central\ncomplex, exploiting consolidation benefits. However, dynamically scheduling\nfood preparation and delivery is challenging and we propose operational\nstrategies for the effective operations of ghost kitchens. We model the problem\nas a sequential decision process. For the complex, combinatorial decision space\nof scheduling order preparations, consolidating orders to trips, and scheduling\ntrip departures, we propose a large neighborhood search procedure based on\npartial decisions and driven by analytical properties. Within the large\nneighborhood search, decisions are evaluated via a value function\napproximation, enabling anticipatory and real-time decision making. We show the\neffectiveness of our method and demonstrate the value of ghost kitchens\ncompared to conventional meal delivery systems. We show that both integrated\noptimization of cook scheduling and vehicle dispatching, as well as\nanticipation of future demand and decisions, are essential for successful\noperations. We further derive several managerial insights, amongst others, that\ncompanies should carefully consider the trade-off between fast delivery and\nfresh food.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.07417v1",
    "published_date": "2024-08-14 09:54:03 UTC",
    "updated_date": "2024-08-14 09:54:03 UTC"
  },
  {
    "arxiv_id": "2408.07719v1",
    "title": "Operator Feature Neural Network for Symbolic Regression",
    "authors": [
      "Yusong Deng",
      "Min Wu",
      "Lina Yu",
      "Jingyi Liu",
      "Shu Wei",
      "Yanjie Li",
      "Weijun Li"
    ],
    "abstract": "Symbolic regression is a task aimed at identifying patterns in data and\nrepresenting them through mathematical expressions, generally involving\nskeleton prediction and constant optimization. Many methods have achieved some\nsuccess, however they treat variables and symbols merely as characters of\nnatural language without considering their mathematical essence. This paper\nintroduces the operator feature neural network (OF-Net) which employs operator\nrepresentation for expressions and proposes an implicit feature encoding method\nfor the intrinsic mathematical operational logic of operators. By substituting\noperator features for numeric loss, we can predict the combination of operators\nof target expressions. We evaluate the model on public datasets, and the\nresults demonstrate that the model achieves superior recovery rates and high\n$R^2$ scores. With the discussion of the results, we analyze the merit and\ndemerit of OF-Net and propose optimizing schemes.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "12 pages",
    "pdf_url": "http://arxiv.org/pdf/2408.07719v1",
    "published_date": "2024-08-14 09:47:13 UTC",
    "updated_date": "2024-08-14 09:47:13 UTC"
  },
  {
    "arxiv_id": "2408.10260v1",
    "title": "Optical Music Recognition in Manuscripts from the Ricordi Archive",
    "authors": [
      "Federico Simonetta",
      "Rishav Mondal",
      "Luca Andrea Ludovico",
      "Stavros Ntalampiras"
    ],
    "abstract": "The Ricordi archive, a prestigious collection of significant musical\nmanuscripts from renowned opera composers such as Donizetti, Verdi and Puccini,\nhas been digitized. This process has allowed us to automatically extract\nsamples that represent various musical elements depicted on the manuscripts,\nincluding notes, staves, clefs, erasures, and composer's annotations, among\nothers. To distinguish between digitization noise and actual music elements, a\nsubset of these images was meticulously grouped and labeled by multiple\nindividuals into several classes. After assessing the consistency of the\nannotations, we trained multiple neural network-based classifiers to\ndifferentiate between the identified music elements. The primary objective of\nthis study was to evaluate the reliability of these classifiers, with the\nultimate goal of using them for the automatic categorization of the remaining\nunannotated data set. The dataset, complemented by manual annotations, models,\nand source code used in these experiments are publicly accessible for\nreplication purposes.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.DL"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at AudioMostly 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.10260v1",
    "published_date": "2024-08-14 09:29:11 UTC",
    "updated_date": "2024-08-14 09:29:11 UTC"
  },
  {
    "arxiv_id": "2408.07404v1",
    "title": "Efficient Edge AI: Deploying Convolutional Neural Networks on FPGA with the Gemmini Accelerator",
    "authors": [
      "Federico Nicolas Peccia",
      "Svetlana Pavlitska",
      "Tobias Fleck",
      "Oliver Bringmann"
    ],
    "abstract": "The growing concerns regarding energy consumption and privacy have prompted\nthe development of AI solutions deployable on the edge, circumventing the\nsubstantial CO2 emissions associated with cloud servers and mitigating risks\nrelated to sharing sensitive data. But deploying Convolutional Neural Networks\n(CNNs) on non-off-the-shelf edge devices remains a complex and labor-intensive\ntask. In this paper, we present and end-to-end workflow for deployment of CNNs\non Field Programmable Gate Arrays (FPGAs) using the Gemmini accelerator, which\nwe modified for efficient implementation on FPGAs. We describe how we leverage\nthe use of open source software on each optimization step of the deployment\nprocess, the customizations we added to them and its impact on the final\nsystem's performance. We were able to achieve real-time performance by\ndeploying a YOLOv7 model on a Xilinx ZCU102 FPGA with an energy efficiency of\n36.5 GOP/s/W. Our FPGA-based solution demonstrates superior power efficiency\ncompared with other embedded hardware devices, and even outperforms other FPGA\nreference implementations. Finally, we present how this kind of solution can be\nintegrated into a wider system, by testing our proposed platform in a traffic\nmonitoring scenario.",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.AR",
    "comment": "8 pages, 9 figures, accepted at the 27th Euromicro Conference Series\n  on Digital System Design (DSD) 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.07404v1",
    "published_date": "2024-08-14 09:24:00 UTC",
    "updated_date": "2024-08-14 09:24:00 UTC"
  },
  {
    "arxiv_id": "2408.07402v1",
    "title": "A Quantum-Inspired Analysis of Human Disambiguation Processes",
    "authors": [
      "Daphne Wang"
    ],
    "abstract": "Formal languages are essential for computer programming and are constructed\nto be easily processed by computers. In contrast, natural languages are much\nmore challenging and instigated the field of Natural Language Processing (NLP).\nOne major obstacle is the ubiquity of ambiguities. Recent advances in NLP have\nled to the development of large language models, which can resolve ambiguities\nwith high accuracy. At the same time, quantum computers have gained much\nattention in recent years as they can solve some computational problems faster\nthan classical computers. This new computing paradigm has reached the fields of\nmachine learning and NLP, where hybrid classical-quantum learning algorithms\nhave emerged. However, more research is needed to identify which NLP tasks\ncould benefit from a genuine quantum advantage. In this thesis, we applied\nformalisms arising from foundational quantum mechanics, such as contextuality\nand causality, to study ambiguities arising from linguistics. By doing so, we\nalso reproduced psycholinguistic results relating to the human disambiguation\nprocess. These results were subsequently used to predict human behaviour and\noutperformed current NLP methods.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LO",
      "quant-ph"
    ],
    "primary_category": "cs.CL",
    "comment": "PhD thesis",
    "pdf_url": "http://arxiv.org/pdf/2408.07402v1",
    "published_date": "2024-08-14 09:21:23 UTC",
    "updated_date": "2024-08-14 09:21:23 UTC"
  },
  {
    "arxiv_id": "2408.07401v2",
    "title": "DataVisT5: A Pre-trained Language Model for Jointly Understanding Text and Data Visualization",
    "authors": [
      "Zhuoyue Wan",
      "Yuanfeng Song",
      "Shuaimin Li",
      "Chen Jason Zhang",
      "Raymond Chi-Wing Wong"
    ],
    "abstract": "Data visualization (DV) is the fundamental and premise tool to improve the\nefficiency in conveying the insights behind the big data, which has been widely\naccepted in existing data-driven world. Task automation in DV, such as\nconverting natural language queries to visualizations (i.e., text-to-vis),\ngenerating explanations from visualizations (i.e., vis-to-text), answering\nDV-related questions in free form (i.e. FeVisQA), and explicating tabular data\n(i.e., table-to-text), is vital for advancing the field. Despite their\npotential, the application of pre-trained language models (PLMs) like T5 and\nBERT in DV has been limited by high costs and challenges in handling\ncross-modal information, leading to few studies on PLMs for DV. We introduce\nDataVisT5, a novel PLM tailored for DV that enhances the T5 architecture\nthrough a hybrid objective pre-training and multi-task fine-tuning strategy,\nintegrating text and DV datasets to effectively interpret cross-modal\nsemantics. Extensive evaluations on public datasets show that DataVisT5\nconsistently outperforms current state-of-the-art models on various DV-related\ntasks. We anticipate that DataVisT5 will not only inspire further research on\nvertical PLMs but also expand the range of applications for PLMs.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.DB"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.07401v2",
    "published_date": "2024-08-14 09:20:17 UTC",
    "updated_date": "2024-11-27 17:42:57 UTC"
  },
  {
    "arxiv_id": "2408.07395v1",
    "title": "Improving Global Parameter-sharing in Physically Heterogeneous Multi-agent Reinforcement Learning with Unified Action Space",
    "authors": [
      "Xiaoyang Yu",
      "Youfang Lin",
      "Shuo Wang",
      "Kai Lv",
      "Sheng Han"
    ],
    "abstract": "In a multi-agent system (MAS), action semantics indicates the different\ninfluences of agents' actions toward other entities, and can be used to divide\nagents into groups in a physically heterogeneous MAS. Previous multi-agent\nreinforcement learning (MARL) algorithms apply global parameter-sharing across\ndifferent types of heterogeneous agents without careful discrimination of\ndifferent action semantics. This common implementation decreases the\ncooperation and coordination between agents in complex situations. However,\nfully independent agent parameters dramatically increase the computational cost\nand training difficulty. In order to benefit from the usage of different action\nsemantics while also maintaining a proper parameter-sharing structure, we\nintroduce the Unified Action Space (UAS) to fulfill the requirement. The UAS is\nthe union set of all agent actions with different semantics. All agents first\ncalculate their unified representation in the UAS, and then generate their\nheterogeneous action policies using different available-action-masks. To\nfurther improve the training of extra UAS parameters, we introduce a\nCross-Group Inverse (CGI) loss to predict other groups' agent policies with the\ntrajectory information. As a universal method for solving the physically\nheterogeneous MARL problem, we implement the UAS adding to both value-based and\npolicy-based MARL algorithms, and propose two practical algorithms: U-QMIX and\nU-MAPPO. Experimental results in the SMAC environment prove the effectiveness\nof both U-QMIX and U-MAPPO compared with several state-of-the-art MARL methods.",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "primary_category": "cs.MA",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.07395v1",
    "published_date": "2024-08-14 09:15:11 UTC",
    "updated_date": "2024-08-14 09:15:11 UTC"
  },
  {
    "arxiv_id": "2408.07394v2",
    "title": "Sum-Product-Set Networks: Deep Tractable Models for Tree-Structured Graphs",
    "authors": [
      "Milan Papež",
      "Martin Rektoris",
      "Tomáš Pevný",
      "Václav Šmídl"
    ],
    "abstract": "Daily internet communication relies heavily on tree-structured graphs,\nembodied by popular data formats such as XML and JSON. However, many recent\ngenerative (probabilistic) models utilize neural networks to learn a\nprobability distribution over undirected cyclic graphs. This assumption of a\ngeneric graph structure brings various computational challenges, and, more\nimportantly, the presence of non-linearities in neural networks does not permit\ntractable probabilistic inference. We address these problems by proposing\nsum-product-set networks, an extension of probabilistic circuits from\nunstructured tensor data to tree-structured graph data. To this end, we use\nrandom finite sets to reflect a variable number of nodes and edges in the graph\nand to allow for exact and efficient inference. We demonstrate that our\ntractable model performs comparably to various intractable models based on\nneural networks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.07394v2",
    "published_date": "2024-08-14 09:13:27 UTC",
    "updated_date": "2024-08-18 12:01:38 UTC"
  },
  {
    "arxiv_id": "2408.07377v2",
    "title": "Do GPT Language Models Suffer From Split Personality Disorder? The Advent Of Substrate-Free Psychometrics",
    "authors": [
      "Peter Romero",
      "Stephen Fitz",
      "Teruo Nakatsuma"
    ],
    "abstract": "Previous research on emergence in large language models shows these display\napparent human-like abilities and psychological latent traits. However, results\nare partly contradicting in expression and magnitude of these latent traits,\nyet agree on the worrisome tendencies to score high on the Dark Triad of\nnarcissism, psychopathy, and Machiavellianism, which, together with a track\nrecord of derailments, demands more rigorous research on safety of these\nmodels. We provided a state of the art language model with the same personality\nquestionnaire in nine languages, and performed Bayesian analysis of Gaussian\nMixture Model, finding evidence for a deeper-rooted issue. Our results suggest\nboth interlingual and intralingual instabilities, which indicate that current\nlanguage models do not develop a consistent core personality. This can lead to\nunsafe behaviour of artificial intelligence systems that are based on these\nfoundation models, and are increasingly integrated in human life. We\nsubsequently discuss the shortcomings of modern psychometrics, abstract it, and\nprovide a framework for its species-neutral, substrate-free formulation.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL",
    "comment": "37 pages, 7 figures, 3 tables, date v1: Mar 26 2023; replaced with\n  new version; reason: removed journal logo from older version of article that\n  is no longer valid",
    "pdf_url": "http://arxiv.org/pdf/2408.07377v2",
    "published_date": "2024-08-14 08:53:00 UTC",
    "updated_date": "2024-08-15 05:15:55 UTC"
  },
  {
    "arxiv_id": "2408.07718v1",
    "title": "Impact of Inaccurate Contamination Ratio on Robust Unsupervised Anomaly Detection",
    "authors": [
      "Jordan F. Masakuna",
      "DJeff Kanda Nkashama",
      "Arian Soltani",
      "Marc Frappier",
      "Pierre-Martin Tardif",
      "Froduald Kabanza"
    ],
    "abstract": "Training data sets intended for unsupervised anomaly detection, typically\npresumed to be anomaly-free, often contain anomalies (or contamination), a\nchallenge that significantly undermines model performance. Most robust\nunsupervised anomaly detection models rely on contamination ratio information\nto tackle contamination. However, in reality, contamination ratio may be\ninaccurate. We investigate on the impact of inaccurate contamination ratio\ninformation in robust unsupervised anomaly detection. We verify whether they\nare resilient to misinformed contamination ratios. Our investigation on 6\nbenchmark data sets reveals that such models are not adversely affected by\nexposure to misinformation. In fact, they can exhibit improved performance when\nprovided with such inaccurate contamination ratios.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "This is an accepted extended abstract at Black in AI Workshop which\n  will be co-located with NeurIPS 2024 in Canada",
    "pdf_url": "http://arxiv.org/pdf/2408.07718v1",
    "published_date": "2024-08-14 08:49:41 UTC",
    "updated_date": "2024-08-14 08:49:41 UTC"
  },
  {
    "arxiv_id": "2408.11851v1",
    "title": "SAGE-RT: Synthetic Alignment data Generation for Safety Evaluation and Red Teaming",
    "authors": [
      "Anurakt Kumar",
      "Divyanshu Kumar",
      "Jatan Loya",
      "Nitin Aravind Birur",
      "Tanay Baswa",
      "Sahil Agarwal",
      "Prashanth Harshangi"
    ],
    "abstract": "We introduce Synthetic Alignment data Generation for Safety Evaluation and\nRed Teaming (SAGE-RT or SAGE) a novel pipeline for generating synthetic\nalignment and red-teaming data. Existing methods fall short in creating nuanced\nand diverse datasets, providing necessary control over the data generation and\nvalidation processes, or require large amount of manually generated seed data.\nSAGE addresses these limitations by using a detailed taxonomy to produce\nsafety-alignment and red-teaming data across a wide range of topics. We\ngenerated 51,000 diverse and in-depth prompt-response pairs, encompassing over\n1,500 topics of harmfulness and covering variations of the most frequent types\nof jailbreaking prompts faced by large language models (LLMs). We show that the\nred-teaming data generated through SAGE jailbreaks state-of-the-art LLMs in\nmore than 27 out of 32 sub-categories, and in more than 58 out of 279\nleaf-categories (sub-sub categories). The attack success rate for GPT-4o,\nGPT-3.5-turbo is 100% over the sub-categories of harmfulness. Our approach\navoids the pitfalls of synthetic safety-training data generation such as mode\ncollapse and lack of nuance in the generation pipeline by ensuring a detailed\ncoverage of harmful topics using iterative expansion of the topics and\nconditioning the outputs on the generated raw-text. This method can be used to\ngenerate red-teaming and alignment data for LLM Safety completely synthetically\nto make LLMs safer or for red-teaming the models over a diverse range of\ntopics.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CR"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.11851v1",
    "published_date": "2024-08-14 08:38:31 UTC",
    "updated_date": "2024-08-14 08:38:31 UTC"
  },
  {
    "arxiv_id": "2408.07368v1",
    "title": "The Complexity of Manipulation of k-Coalitional Games on Graphs",
    "authors": [
      "Hodaya Barr",
      "Yohai Trabelsi",
      "Sarit Kraus",
      "Liam Roditty",
      "Noam Hazon"
    ],
    "abstract": "In many settings, there is an organizer who would like to divide a set of\nagents into $k$ coalitions, and cares about the friendships within each\ncoalition. Specifically, the organizer might want to maximize utilitarian\nsocial welfare, maximize egalitarian social welfare, or simply guarantee that\nevery agent will have at least one friend within his coalition. However, in\nmany situations, the organizer is not familiar with the friendship connections,\nand he needs to obtain them from the agents. In this setting, a manipulative\nagent may falsely report friendship connections in order to increase his\nutility. In this paper, we analyze the complexity of finding manipulation in\nsuch $k$-coalitional games on graphs. We also introduce a new type of\nmanipulation, socially-aware manipulation, in which the manipulator would like\nto increase his utility without decreasing the social welfare. We then study\nthe complexity of finding socially-aware manipulation in our setting. Finally,\nwe examine the frequency of socially-aware manipulation and the running time of\nour algorithms via simulation results.",
    "categories": [
      "cs.GT",
      "cs.AI"
    ],
    "primary_category": "cs.GT",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.07368v1",
    "published_date": "2024-08-14 08:29:30 UTC",
    "updated_date": "2024-08-14 08:29:30 UTC"
  },
  {
    "arxiv_id": "2408.16008v2",
    "title": "Novel Methods for Analyzing Cellular Interactions in Deep Learning-Based Image Cytometry: Spatial Interaction Potential and Co-Localization Index",
    "authors": [
      "Toru Nagasaka",
      "Kimihiro Yamashita",
      "Mitsugu Fujita"
    ],
    "abstract": "The study presents a novel approach for quantifying cellular interactions in\ndigital pathology using deep learning-based image cytometry. Traditional\nmethods struggle with the diversity and heterogeneity of cells within tissues.\nTo address this, we introduce the Spatial Interaction Potential (SIP) and the\nCo-Localization Index (CLI), leveraging deep learning classification\nprobabilities. SIP assesses the potential for cell-to-cell interactions,\nsimilar to an electric field, while CLI incorporates distances between cells,\naccounting for dynamic cell movements. Our approach enhances traditional\nmethods, providing a more sophisticated analysis of cellular interactions. We\nvalidate SIP and CLI through simulations and apply them to colorectal cancer\nspecimens, demonstrating strong correlations with actual biological data. This\ninnovative method offers significant improvements in understanding cellular\ninteractions and has potential applications in various fields of digital\npathology.",
    "categories": [
      "q-bio.QM",
      "cs.AI"
    ],
    "primary_category": "q-bio.QM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.16008v2",
    "published_date": "2024-08-14 08:07:17 UTC",
    "updated_date": "2024-08-30 13:42:04 UTC"
  },
  {
    "arxiv_id": "2408.07344v1",
    "title": "RTAT: A Robust Two-stage Association Tracker for Multi-Object Tracking",
    "authors": [
      "Song Guo",
      "Rujie Liu",
      "Narishige Abe"
    ],
    "abstract": "Data association is an essential part in the tracking-by-detection based\nMulti-Object Tracking (MOT). Most trackers focus on how to design a better data\nassociation strategy to improve the tracking performance. The rule-based\nhandcrafted association methods are simple and highly efficient but lack\ngeneralization capability to deal with complex scenes. While the learnt\nassociation methods can learn high-order contextual information to deal with\nvarious complex scenes, but they have the limitations of higher complexity and\ncost. To address these limitations, we propose a Robust Two-stage Association\nTracker, named RTAT. The first-stage association is performed between tracklets\nand detections to generate tracklets with high purity, and the second-stage\nassociation is performed between tracklets to form complete trajectories. For\nthe first-stage association, we use a simple data association strategy to\ngenerate tracklets with high purity by setting a low threshold for the matching\ncost in the assignment process. We conduct the tracklet association in the\nsecond-stage based on the framework of message-passing GNN. Our method models\nthe tracklet association as a series of edge classification problem in\nhierarchical graphs, which can recursively merge short tracklets into longer\nones. Our tracker RTAT ranks first on the test set of MOT17 and MOT20\nbenchmarks in most of the main MOT metrics: HOTA, IDF1, and AssA. We achieve\n67.2 HOTA, 84.7 IDF1, and 69.7 AssA on MOT17, and 66.2 HOTA, 82.5 IDF1, and\n68.1 AssA on MOT20.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "ICPR2024",
    "pdf_url": "http://arxiv.org/pdf/2408.07344v1",
    "published_date": "2024-08-14 07:37:24 UTC",
    "updated_date": "2024-08-14 07:37:24 UTC"
  },
  {
    "arxiv_id": "2408.07341v2",
    "title": "Robust Semi-supervised Multimodal Medical Image Segmentation via Cross Modality Collaboration",
    "authors": [
      "Xiaogen Zhou",
      "Yiyou Sun",
      "Min Deng",
      "Winnie Chiu Wing Chu",
      "Qi Dou"
    ],
    "abstract": "Multimodal learning leverages complementary information derived from\ndifferent modalities, thereby enhancing performance in medical image\nsegmentation. However, prevailing multimodal learning methods heavily rely on\nextensive well-annotated data from various modalities to achieve accurate\nsegmentation performance. This dependence often poses a challenge in clinical\nsettings due to limited availability of such data. Moreover, the inherent\nanatomical misalignment between different imaging modalities further\ncomplicates the endeavor to enhance segmentation performance. To address this\nproblem, we propose a novel semi-supervised multimodal segmentation framework\nthat is robust to scarce labeled data and misaligned modalities. Our framework\nemploys a novel cross modality collaboration strategy to distill\nmodality-independent knowledge, which is inherently associated with each\nmodality, and integrates this information into a unified fusion layer for\nfeature amalgamation. With a channel-wise semantic consistency loss, our\nframework ensures alignment of modality-independent information from a\nfeature-wise perspective across modalities, thereby fortifying it against\nmisalignments in multimodal scenarios. Furthermore, our framework effectively\nintegrates contrastive consistent learning to regulate anatomical structures,\nfacilitating anatomical-wise prediction alignment on unlabeled data in\nsemi-supervised segmentation tasks. Our method achieves competitive performance\ncompared to other multimodal methods across three tasks: cardiac, abdominal\nmulti-organ, and thyroid-associated orbitopathy segmentations. It also\ndemonstrates outstanding robustness in scenarios involving scarce labeled data\nand misaligned modalities.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.07341v2",
    "published_date": "2024-08-14 07:34:12 UTC",
    "updated_date": "2024-09-04 03:22:05 UTC"
  },
  {
    "arxiv_id": "2408.07340v1",
    "title": "Towards Few-shot Self-explaining Graph Neural Networks",
    "authors": [
      "Jingyu Peng",
      "Qi Liu",
      "Linan Yue",
      "Zaixi Zhang",
      "Kai Zhang",
      "Yunhao Sha"
    ],
    "abstract": "Recent advancements in Graph Neural Networks (GNNs) have spurred an upsurge\nof research dedicated to enhancing the explainability of GNNs, particularly in\ncritical domains such as medicine. A promising approach is the self-explaining\nmethod, which outputs explanations along with predictions. However, existing\nself-explaining models require a large amount of training data, rendering them\nunavailable in few-shot scenarios. To address this challenge, in this paper, we\npropose a Meta-learned Self-Explaining GNN (MSE-GNN), a novel framework that\ngenerates explanations to support predictions in few-shot settings. MSE-GNN\nadopts a two-stage self-explaining structure, consisting of an explainer and a\npredictor. Specifically, the explainer first imitates the attention mechanism\nof humans to select the explanation subgraph, whereby attention is naturally\npaid to regions containing important characteristics. Subsequently, the\npredictor mimics the decision-making process, which makes predictions based on\nthe generated explanation. Moreover, with a novel meta-training process and a\ndesigned mechanism that exploits task information, MSE-GNN can achieve\nremarkable performance on new few-shot tasks. Extensive experimental results on\nfour datasets demonstrate that MSE-GNN can achieve superior performance on\nprediction tasks while generating high-quality explanations compared with\nexisting methods. The code is publicly available at\nhttps://github.com/jypeng28/MSE-GNN.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.07340v1",
    "published_date": "2024-08-14 07:31:11 UTC",
    "updated_date": "2024-08-14 07:31:11 UTC"
  },
  {
    "arxiv_id": "2408.07327v1",
    "title": "An Offline Meta Black-box Optimization Framework for Adaptive Design of Urban Traffic Light Management Systems",
    "authors": [
      "Taeyoung Yun",
      "Kanghoon Lee",
      "Sujin Yun",
      "Ilmyung Kim",
      "Won-Woo Jung",
      "Min-Cheol Kwon",
      "Kyujin Choi",
      "Yoohyeon Lee",
      "Jinkyoo Park"
    ],
    "abstract": "Complex urban road networks with high vehicle occupancy frequently face\nsevere traffic congestion. Designing an effective strategy for managing\nmultiple traffic lights plays a crucial role in managing congestion. However,\nmost current traffic light management systems rely on human-crafted decisions,\nwhich may not adapt well to diverse traffic patterns. In this paper, we delve\ninto two pivotal design components of the traffic light management system that\ncan be dynamically adjusted to various traffic conditions: phase combination\nand phase time allocation. While numerous studies have sought an efficient\nstrategy for managing traffic lights, most of these approaches consider a fixed\ntraffic pattern and are limited to relatively small road networks. To overcome\nthese limitations, we introduce a novel and practical framework to formulate\nthe optimization of such design components using an offline meta black-box\noptimization. We then present a simple yet effective method to efficiently find\na solution for the aforementioned problem. In our framework, we first collect\nan offline meta dataset consisting of pairs of design choices and corresponding\ncongestion measures from various traffic patterns. After collecting the\ndataset, we employ the Attentive Neural Process (ANP) to predict the impact of\nthe proposed design on congestion across various traffic patterns with\nwell-calibrated uncertainty. Finally, Bayesian optimization, with ANP as a\nsurrogate model, is utilized to find an optimal design for unseen traffic\npatterns through limited online simulations. Our experiment results show that\nour method outperforms state-of-the-art baselines on complex road networks in\nterms of the number of waiting vehicles. Surprisingly, the deployment of our\nmethod into a real-world traffic system was able to improve traffic throughput\nby 4.80\\% compared to the original strategy.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "12 pages, 7 figures, 10 tables",
    "pdf_url": "http://arxiv.org/pdf/2408.07327v1",
    "published_date": "2024-08-14 06:57:58 UTC",
    "updated_date": "2024-08-14 06:57:58 UTC"
  },
  {
    "arxiv_id": "2408.07324v1",
    "title": "On-the-fly Synthesis for LTL over Finite Traces: An Efficient Approach that Counts",
    "authors": [
      "Shengping Xiao",
      "Yongkang Li",
      "Shufang Zhu",
      "Jun Sun",
      "Jianwen Li",
      "Geguang Pu",
      "Moshe Y. Vardi"
    ],
    "abstract": "We present an on-the-fly synthesis framework for Linear Temporal Logic over\nfinite traces (LTLf) based on top-down deterministic automata construction.\nExisting approaches rely on constructing a complete Deterministic Finite\nAutomaton (DFA) corresponding to the LTLf specification, a process with doubly\nexponential complexity relative to the formula size in the worst case. In this\ncase, the synthesis procedure cannot be conducted until the entire DFA is\nconstructed. This inefficiency is the main bottleneck of existing approaches.\nTo address this challenge, we first present a method for converting LTLf into\nTransition-based DFA (TDFA) by directly leveraging LTLf semantics,\nincorporating intermediate results as direct components of the final automaton\nto enable parallelized synthesis and automata construction. We then explore the\nrelationship between LTLf synthesis and TDFA games and subsequently develop an\nalgorithm for performing LTLf synthesis using on-the-fly TDFA game solving.\nThis algorithm traverses the state space in a global forward manner combined\nwith a local backward method, along with the detection of strongly connected\ncomponents. Moreover, we introduce two optimization techniques -- model-guided\nsynthesis and state entailment -- to enhance the practical efficiency of our\napproach. Experimental results demonstrate that our on-the-fly approach\nachieves the best performance on the tested benchmarks and effectively\ncomplements existing tools and approaches.",
    "categories": [
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "32 pages, 3 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2408.07324v1",
    "published_date": "2024-08-14 06:52:58 UTC",
    "updated_date": "2024-08-14 06:52:58 UTC"
  },
  {
    "arxiv_id": "2408.07314v3",
    "title": "Kolmogorov-Arnold Networks (KAN) for Time Series Classification and Robust Analysis",
    "authors": [
      "Chang Dong",
      "Liangwei Zheng",
      "Weitong Chen"
    ],
    "abstract": "Kolmogorov-Arnold Networks (KAN) has recently attracted significant attention\nas a promising alternative to traditional Multi-Layer Perceptrons (MLP).\nDespite their theoretical appeal, KAN require validation on large-scale\nbenchmark datasets. Time series data, which has become increasingly prevalent\nin recent years, especially univariate time series are naturally suited for\nvalidating KAN. Therefore, we conducted a fair comparison among KAN, MLP, and\nmixed structures. The results indicate that KAN can achieve performance\ncomparable to, or even slightly better than, MLP across 128 time series\ndatasets. We also performed an ablation study on KAN, revealing that the output\nis primarily determined by the base component instead of b-spline function.\nFurthermore, we assessed the robustness of these models and found that KAN and\nthe hybrid structure MLP\\_KAN exhibit significant robustness advantages,\nattributed to their lower Lipschitz constants. This suggests that KAN and KAN\nlayers hold strong potential to be robust models or to improve the adversarial\nrobustness of other models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "I.2.0"
    ],
    "primary_category": "cs.LG",
    "comment": "14 pages, 8 figs",
    "pdf_url": "http://arxiv.org/pdf/2408.07314v3",
    "published_date": "2024-08-14 06:15:55 UTC",
    "updated_date": "2024-09-11 05:10:12 UTC"
  },
  {
    "arxiv_id": "2408.07292v1",
    "title": "LiPCoT: Linear Predictive Coding based Tokenizer for Self-supervised Learning of Time Series Data via Language Models",
    "authors": [
      "Md Fahim Anjum"
    ],
    "abstract": "Language models have achieved remarkable success in various natural language\nprocessing tasks. However, their application to time series data, a crucial\ncomponent in many domains, remains limited. This paper proposes LiPCoT (Linear\nPredictive Coding based Tokenizer for time series), a novel tokenizer that\nencodes time series data into a sequence of tokens, enabling self-supervised\nlearning of time series using existing Language model architectures such as\nBERT. Unlike traditional time series tokenizers that rely heavily on CNN\nencoder for time series feature generation, LiPCoT employs stochastic modeling\nthrough linear predictive coding to create a latent space for time series\nproviding a compact yet rich representation of the inherent stochastic nature\nof the data. Furthermore, LiPCoT is computationally efficient and can\neffectively handle time series data with varying sampling rates and lengths,\novercoming common limitations of existing time series tokenizers. In this\nproof-of-concept work, we present the effectiveness of LiPCoT in classifying\nParkinson's disease (PD) using an EEG dataset from 46 participants. In\nparticular, we utilize LiPCoT to encode EEG data into a small vocabulary of\ntokens and then use BERT for self-supervised learning and the downstream task\nof PD classification. We benchmark our approach against several\nstate-of-the-art CNN-based deep learning architectures for PD detection. Our\nresults reveal that BERT models utilizing self-supervised learning outperformed\nthe best-performing existing method by 7.1% in precision, 2.3% in recall, 5.5%\nin accuracy, 4% in AUC, and 5% in F1-score highlighting the potential for\nself-supervised learning even on small datasets. Our work will inform future\nfoundational models for time series, particularly for self-supervised learning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "comment": "17 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.07292v1",
    "published_date": "2024-08-14 04:51:33 UTC",
    "updated_date": "2024-08-14 04:51:33 UTC"
  },
  {
    "arxiv_id": "2408.07272v2",
    "title": "Abstract Operations Research Modeling Using Natural Language Inputs",
    "authors": [
      "Junxuan Li",
      "Ryan Wickman",
      "Sahil Bhatnagar",
      "Raj Kumar Maity",
      "Arko Mukherjee"
    ],
    "abstract": "Operations research (OR) uses mathematical models to enhance decision-making,\nbut developing these models requires expert knowledge and can be\ntime-consuming. Automated mathematical programming (AMP) has emerged to\nsimplify this process, but existing systems have limitations. This paper\nintroduces a novel methodology that uses recent advances in Large Language\nModel (LLM) to create and edit OR solutions from non-expert user queries\nexpressed using Natural Language. This reduces the need for domain expertise\nand the time to formulate a problem. The paper presents an end-to-end pipeline,\nnamed NL2OR, that generates solutions to OR problems from natural language\ninput, and shares experimental results on several important OR problems.",
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.07272v2",
    "published_date": "2024-08-14 03:42:53 UTC",
    "updated_date": "2025-01-28 18:40:26 UTC"
  },
  {
    "arxiv_id": "2408.07262v3",
    "title": "Ensemble architecture in polyp segmentation",
    "authors": [
      "Hao-Yun Hsu",
      "Yi-Ching Cheng",
      "Guan-Hua Huang"
    ],
    "abstract": "This study explored the architecture of semantic segmentation and evaluated\nmodels that excel in polyp segmentation. We present an integrated framework\nthat harnesses the advantages of different models to attain an optimal outcome.\nSpecifically, in this framework, we fuse the learned features from\nconvolutional and transformer models for prediction, thus engendering an\nensemble technique to enhance model performance. Our experiments on polyp\nsegmentation revealed that the proposed architecture surpassed other top\nmodels, exhibiting improved learning capacity and resilience. The code is\navailable at https://github.com/HuangDLab/EnFormer.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "13 pages, 3 figures, and 7 tables",
    "pdf_url": "http://arxiv.org/pdf/2408.07262v3",
    "published_date": "2024-08-14 02:57:38 UTC",
    "updated_date": "2024-10-25 02:00:22 UTC"
  },
  {
    "arxiv_id": "2408.07259v1",
    "title": "GRIF-DM: Generation of Rich Impression Fonts using Diffusion Models",
    "authors": [
      "Lei Kang",
      "Fei Yang",
      "Kai Wang",
      "Mohamed Ali Souibgui",
      "Lluis Gomez",
      "Alicia Fornés",
      "Ernest Valveny",
      "Dimosthenis Karatzas"
    ],
    "abstract": "Fonts are integral to creative endeavors, design processes, and artistic\nproductions. The appropriate selection of a font can significantly enhance\nartwork and endow advertisements with a higher level of expressivity. Despite\nthe availability of numerous diverse font designs online, traditional\nretrieval-based methods for font selection are increasingly being supplanted by\ngeneration-based approaches. These newer methods offer enhanced flexibility,\ncatering to specific user preferences and capturing unique stylistic\nimpressions. However, current impression font techniques based on Generative\nAdversarial Networks (GANs) necessitate the utilization of multiple auxiliary\nlosses to provide guidance during generation. Furthermore, these methods\ncommonly employ weighted summation for the fusion of impression-related\nkeywords. This leads to generic vectors with the addition of more impression\nkeywords, ultimately lacking in detail generation capacity. In this paper, we\nintroduce a diffusion-based method, termed \\ourmethod, to generate fonts that\nvividly embody specific impressions, utilizing an input consisting of a single\nletter and a set of descriptive impression keywords. The core innovation of\n\\ourmethod lies in the development of dual cross-attention modules, which\nprocess the characteristics of the letters and impression keywords\nindependently but synergistically, ensuring effective integration of both types\nof information. Our experimental results, conducted on the MyFonts dataset,\naffirm that this method is capable of producing realistic, vibrant, and\nhigh-fidelity fonts that are closely aligned with user specifications. This\nconfirms the potential of our approach to revolutionize font generation by\naccommodating a broad spectrum of user-driven design requirements. Our code is\npublicly available at \\url{https://github.com/leitro/GRIF-DM}.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to ECAI2024",
    "pdf_url": "http://arxiv.org/pdf/2408.07259v1",
    "published_date": "2024-08-14 02:26:46 UTC",
    "updated_date": "2024-08-14 02:26:46 UTC"
  },
  {
    "arxiv_id": "2409.00001v1",
    "title": "Evaluating Explainable AI Methods in Deep Learning Models for Early Detection of Cerebral Palsy",
    "authors": [
      "Kimji N. Pellano",
      "Inga Strümke",
      "Daniel Groos",
      "Lars Adde",
      "Espen Alexander F. Ihlen"
    ],
    "abstract": "Early detection of Cerebral Palsy (CP) is crucial for effective intervention\nand monitoring. This paper tests the reliability and applicability of\nExplainable AI (XAI) methods using a deep learning method that predicts CP by\nanalyzing skeletal data extracted from video recordings of infant movements.\nSpecifically, we use XAI evaluation metrics -- namely faithfulness and\nstability -- to quantitatively assess the reliability of Class Activation\nMapping (CAM) and Gradient-weighted Class Activation Mapping (Grad-CAM) in this\nspecific medical application. We utilize a unique dataset of infant movements\nand apply skeleton data perturbations without distorting the original dynamics\nof the infant movements. Our CP prediction model utilizes an ensemble approach,\nso we evaluate the XAI metrics performances for both the overall ensemble and\nthe individual models. Our findings indicate that both XAI methods effectively\nidentify key body points influencing CP predictions and that the explanations\nare robust against minor data perturbations. Grad-CAM significantly outperforms\nCAM in the RISv metric, which measures stability in terms of velocity. In\ncontrast, CAM performs better in the RISb metric, which relates to bone\nstability, and the RRS metric, which assesses internal representation\nrobustness. Individual models within the ensemble show varied results, and\nneither CAM nor Grad-CAM consistently outperform the other, with the ensemble\napproach providing a representation of outcomes from its constituent models.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.00001v1",
    "published_date": "2024-08-14 00:27:09 UTC",
    "updated_date": "2024-08-14 00:27:09 UTC"
  },
  {
    "arxiv_id": "2408.07239v1",
    "title": "Enhancing Autonomous Vehicle Perception in Adverse Weather through Image Augmentation during Semantic Segmentation Training",
    "authors": [
      "Ethan Kou",
      "Noah Curran"
    ],
    "abstract": "Robust perception is crucial in autonomous vehicle navigation and\nlocalization. Visual processing tasks, like semantic segmentation, should work\nin varying weather conditions and during different times of day. Semantic\nsegmentation is where each pixel is assigned a class, which is useful for\nlocating overall features (1). Training a segmentation model requires large\namounts of data, and the labeling process for segmentation data is especially\ntedious. Additionally, many large datasets include only images taken in clear\nweather. This is a problem because training a model exclusively on clear\nweather data hinders performance in adverse weather conditions like fog or\nrain. We hypothesize that given a dataset of only clear days images, applying\nimage augmentation (such as random rain, fog, and brightness) during training\nallows for domain adaptation to diverse weather conditions. We used CARLA, a 3D\nrealistic autonomous vehicle simulator, to collect 1200 images in clear weather\ncomposed of 29 classes from 10 different towns (2). We also collected 1200\nimages of random weather effects. We trained encoder-decoder UNet models to\nperform semantic segmentation. Applying augmentations significantly improved\nsegmentation under weathered night conditions (p < 0.001). However, models\ntrained on weather data have significantly lower losses than those trained on\naugmented data in all conditions except for clear days. This shows there is\nroom for improvement in the domain adaptation approach. Future work should test\nmore types of augmentations and also use real-life images instead of CARLA.\nIdeally, the augmented model meets or exceeds the performance of the weather\nmodel.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.07239v1",
    "published_date": "2024-08-14 00:08:28 UTC",
    "updated_date": "2024-08-14 00:08:28 UTC"
  }
]