{
  "date": "2024-02-05",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-02-05 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 论文主要聚焦于 AI 模型优化、强化学习、多模态处理和大型语言模型（LLM）的应用等领域，强调了 LLM 在科学推理和多代理系统中的潜力，以及强化学习的分布鲁棒性改进；令人印象深刻的文章包括 DeepSeekMath（数学推理）和 LLM Multi-Agent Systems（多代理挑战），有名的学者如 Boaz Barak 和 Dale Schuurmans 参与的相关工作值得关注。\n\n下面，我将逐一简要概述部分关键论文，先优先讨论那些重要、话题度高或有潜在影响的文章（如 LLM 应用、强化学习和多模态模型），并将相关主题归类讨论。对于其他较次要的论文（如某些哲学讨论或特定领域小众工作），我将快速掠过，只提及核心点。\n\n### LLM 应用与优化\n- **LLM Multi-Agent Systems: Challenges and Open Problems**（英文原标题：LLM Multi-Agent Systems: Challenges and Open Problems）：这篇论文探讨了多代理系统中的挑战，如任务分配和上下文管理，强调 LLM 在区块链等分布式系统中的潜力。主要贡献是通过分析多代理协作，提出了优化迭代推理和内存管理的框架，作者包括知名学者如 Boaz Barak。\n- **Toward Human-AI Alignment in Large-Scale Multi-Player Games**（英文原标题：Toward Human-AI Alignment in Large-Scale Multi-Player Games）：论文提出了一种基于行为流形的可解释框架，用于评估 AI 在游戏中的行为与人类一致性。主要发现是 AI 倾向于单一行为模式，而人类更灵活，这为生成式 AI 的对齐提供了可测量的基准。\n- **Distinguishing the Knowable from the Unknowable with Language Models**（英文原标题：Distinguishing the Knowable from the Unknowable with Language Models）：Boaz Barak 等作者的工作，利用更大模型作为代理，分析 LLM 的不确定性（认识论 vs. 随机性）。主要贡献是开发了无监督方法来预测 LLM 的置信度，提升了模型在实际应用中的可靠性。\n- **DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models**（英文原标题：DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models）：这篇论文引入了 Group Relative Policy Optimization，显著提升了开源 LLM 的数学推理能力。主要发现是通过海量数学数据训练，模型在复杂任务上实现了 51.7% 的准确率，接近 GPT-4 水平。\n- **Understanding Reasoning Ability of Language Models From the Perspective of Reasoning Paths Aggregation**（英文原标题：Understanding Reasoning Ability of Language Models From the Perspective of Reasoning Paths Aggregation）：论文从推理路径角度分析 LLM 的推理能力，提出使用随机游走建模。主要贡献是证明了 LLM 通过聚合路径能更好地处理知识图谱任务，并通过实验验证了改进后的泛化性能。\n\n这些 LLM 相关论文突出了模型在推理、多代理和不确定性处理中的进展，但也暴露了潜在局限，如对复杂任务的鲁棒性不足。\n\n### 强化学习与鲁棒性\n- **Assessing the Impact of Distribution Shift on Reinforcement Learning Performance**（英文原标题：Assessing the Impact of Distribution Shift on Reinforcement Learning Performance）：论文提出了一套评估强化学习（RL）算法在分布偏移下的鲁棒性方法，包括时间序列分析。主要发现是 RL 算法在偏移环境中易过拟合，作者建议使用因果影响测量来提升评估。\n- **Diffusion World Model: Future Modeling Beyond Step-by-Step Rollout for Offline Reinforcement Learning**（英文原标题：Diffusion World Model: Future Modeling Beyond Step-by-Step Rollout for Offline Reinforcement Learning）：这项工作使用扩散模型预测多步未来状态，实现离线 RL 的高效模拟。主要贡献是模型在 D4RL 数据集上超越了单步动态模型，性能提升 44%，并展示了在真实环境中的鲁棒性。\n- **Q-Star Meets Scalable Posterior Sampling: Bridging Theory and Practice via HyperAgent**（英文原标题：Q-Star Meets Scalable Posterior Sampling: Bridging Theory and Practice via HyperAgent）：Dale Schuurmans 等作者的工作，将后验采样应用于 RL，提出 HyperAgent 框架。主要发现是它在复杂环境中实现了亚线性遗憾，同时保持计算效率。\n\n这些论文强调了 RL 的泛化与效率改进，尤其在分布偏移和离线场景中，但仍需解决计算开销问题。\n\n### 多模态与生成模型\n- **VLN-Video: Utilizing Driving Videos for Outdoor Vision-and-Language Navigation**（英文原标题：VLN-Video: Utilizing Driving Videos for Outdoor Vision-and-Language Navigation）：论文利用驾驶视频增强户外视觉-语言导航，提出预训练任务如指令匹配。主要贡献是模型在 Touchdown 数据集上提升了 2.1% 的任务完成率。\n- **InstanceDiffusion: Instance-level Control for Image Generation**（英文原标题：InstanceDiffusion: Instance-level Control for Image Generation）：这项工作在扩散模型中实现了实例级控制，支持语言和边界框输入。主要发现是它在 COCO 数据集上提升了 20.4% 的实例检测性能。\n- **ConsiStory: Training-Free Consistent Text-to-Image Generation**（英文原标题：ConsiStory: Training-Free Consistent Text-to-Image Generation）：论文提出无训练方法生成一致的文本到图像结果，使用共享注意力块。主要贡献是模型在多主题生成中提升了主观一致性。\n\n这些多模态论文展示了生成模型在控制和一致性上的创新，但也需关注潜在的安全风险。\n\n### 其他值得注意的论文\n- **Shadowcast: Stealthy Data Poisoning Attacks Against Vision-Language Models**（英文原标题：Shadowcast: Stealthy Data Poisoning Attacks Against Vision-Language Models）：快速提及，这篇论文揭示了视觉-语言模型的毒化攻击风险，主要发现是攻击可在 50 个样本下成功转移。\n- **A Systematic Survey of Prompt Engineering in Large Language Models**（英文原标题：A Systematic Survey of Prompt Engineering in Large Language Models）：这是一篇系统综述，总结了 LLM 提示工程的技术和应用。主要贡献是提供了分类框架和实验分析，帮助理解提示优化。\n- 其他论文如 **Preliminary Report on Mantis Shrimp**（英文原标题：Preliminary Report on Mantis Shrimp）等，涉及天文图像处理，但影响较小，仅快速掠过：它使用计算机视觉模型估计光度红移，提供了解释性诊断。\n\n总体而言，今天的论文展示了 AI 领域的多样性与深度，许多工作（如 LLM 和 RL）有潜力推动实际应用，但也暴露了安全和泛化挑战。更多细节可查阅 arXiv。",
  "papers": [
    {
      "arxiv_id": "2402.03590v1",
      "title": "Assessing the Impact of Distribution Shift on Reinforcement Learning Performance",
      "title_zh": "评估分布偏移对强化学习性能的影响",
      "authors": [
        "Ted Fujimoto",
        "Joshua Suetterlein",
        "Samrat Chatterjee",
        "Auroop Ganguly"
      ],
      "abstract": "Research in machine learning is making progress in fixing its own\nreproducibility crisis. Reinforcement learning (RL), in particular, faces its\nown set of unique challenges. Comparison of point estimates, and plots that\nshow successful convergence to the optimal policy during training, may\nobfuscate overfitting or dependence on the experimental setup. Although\nresearchers in RL have proposed reliability metrics that account for\nuncertainty to better understand each algorithm's strengths and weaknesses, the\nrecommendations of past work do not assume the presence of out-of-distribution\nobservations. We propose a set of evaluation methods that measure the\nrobustness of RL algorithms under distribution shifts. The tools presented here\nargue for the need to account for performance over time while the agent is\nacting in its environment. In particular, we recommend time series analysis as\na method of observational RL evaluation. We also show that the unique\nproperties of RL and simulated dynamic environments allow us to make stronger\nassumptions to justify the measurement of causal impact in our evaluations. We\nthen apply these tools to single-agent and multi-agent environments to show the\nimpact of introducing distribution shifts during test time. We present this\nmethodology as a first step toward rigorous RL evaluation in the presence of\ndistribution shifts.",
      "tldr_zh": "本文评估了分布偏移（distribution shifts）对强化学习（RL）性能的影响，指出传统评估方法如点估计和收敛图可能掩盖过拟合或对实验设置的依赖。研究提出一组鲁棒性评估工具，包括时间序列分析（time series analysis）和因果影响（causal impact）测量，以考察RL算法在动态环境中的性能变化。实验结果显示，在单代理和多代理环境中引入分布偏移会显著影响RL表现，这为在分布偏移条件下进行更严格的RL评估提供了重要方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.LG",
      "comment": "Poster at the Workshop on Regulatable Machine Learning at the 37th\n  Conference on Neural Information Processing Systems (RegML @ NeurIPS 2023)",
      "pdf_url": "http://arxiv.org/pdf/2402.03590v1",
      "published_date": "2024-02-05 23:50:55 UTC",
      "updated_date": "2024-02-05 23:50:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:12:39.032820"
    },
    {
      "arxiv_id": "2402.03588v1",
      "title": "Continual Domain Adversarial Adaptation via Double-Head Discriminators",
      "title_zh": "通过双头判别器的持续领域对抗适配",
      "authors": [
        "Yan Shen",
        "Zhanghexuan Ji",
        "Chunwei Ma",
        "Mingchen Gao"
      ],
      "abstract": "Domain adversarial adaptation in a continual setting poses a significant\nchallenge due to the limitations on accessing previous source domain data.\nDespite extensive research in continual learning, the task of adversarial\nadaptation cannot be effectively accomplished using only a small number of\nstored source domain data, which is a standard setting in memory replay\napproaches. This limitation arises from the erroneous empirical estimation of\n$\\gH$-divergence with few source domain samples. To tackle this problem, we\npropose a double-head discriminator algorithm, by introducing an addition\nsource-only domain discriminator that are trained solely on source learning\nphase. We prove that with the introduction of a pre-trained source-only domain\ndiscriminator, the empirical estimation error of $\\gH$-divergence related\nadversarial loss is reduced from the source domain side. Further experiments on\nexisting domain adaptation benchmark show that our proposed algorithm achieves\nmore than 2$\\%$ improvement on all categories of target domain adaptation task\nwhile significantly mitigating the forgetting on source domain.",
      "tldr_zh": "这篇论文解决了持续域对抗适配（continual domain adversarial adaptation）中的关键挑战，即由于无法访问之前源域数据，导致对 $\\gH$-divergence 的经验估计错误。作者提出了一种双头鉴别器（double-head discriminator）算法，引入一个仅在源域训练的鉴别器，以减少对抗损失的估计误差。实验在现有域适配基准上显示，该方法在目标域适配任务上提高了超过2%的性能，同时显著缓解了源域的遗忘问题。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "AISTATS 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.03588v1",
      "published_date": "2024-02-05 23:46:03 UTC",
      "updated_date": "2024-02-05 23:46:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:12:50.920884"
    },
    {
      "arxiv_id": "2402.03583v3",
      "title": "MQuinE: a cure for \"Z-paradox\" in knowledge graph embedding models",
      "title_zh": "翻译失败",
      "authors": [
        "Yang Liu",
        "Huang Fang",
        "Yunfeng Cai",
        "Mingming Sun"
      ],
      "abstract": "Knowledge graph embedding (KGE) models achieved state-of-the-art results on\nmany knowledge graph tasks including link prediction and information retrieval.\nDespite the superior performance of KGE models in practice, we discover a\ndeficiency in the expressiveness of some popular existing KGE models called\n\\emph{Z-paradox}. Motivated by the existence of Z-paradox, we propose a new KGE\nmodel called \\emph{MQuinE} that does not suffer from Z-paradox while preserves\nstrong expressiveness to model various relation patterns including\nsymmetric/asymmetric, inverse, 1-N/N-1/N-N, and composition relations with\ntheoretical justification. Experiments on real-world knowledge bases indicate\nthat Z-paradox indeed degrades the performance of existing KGE models, and can\ncause more than 20\\% accuracy drop on some challenging test samples. Our\nexperiments further demonstrate that MQuinE can mitigate the negative impact of\nZ-paradox and outperform existing KGE models by a visible margin on link\nprediction tasks.",
      "tldr_zh": "本研究发现现有知识图谱嵌入(KGE)模型存在\"Z-paradox\"缺陷，导致在处理某些关系模式时表达能力不足，从而影响链接预测等任务的性能。针对这一问题，研究提出了一种新KGE模型MQuinE，它能避免Z-paradox，同时保持对对称/不对称、逆关系、1-N/N-1/N-N和组合关系的强表达能力，并通过理论证明其有效性。在真实世界知识库上的实验显示，Z-paradox可能导致现有模型准确率下降超过20%，而MQuinE显著缓解了这一问题，并在链接预测任务中明显超越基线模型。",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SI",
      "comment": "18pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2402.03583v3",
      "published_date": "2024-02-05 23:20:05 UTC",
      "updated_date": "2024-09-20 05:31:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:13:02.551152"
    },
    {
      "arxiv_id": "2402.03578v2",
      "title": "LLM Multi-Agent Systems: Challenges and Open Problems",
      "title_zh": "LLM 多智能体系统：挑战和开放问题",
      "authors": [
        "Shanshan Han",
        "Qifan Zhang",
        "Yuhang Yao",
        "Weizhao Jin",
        "Zhaozhuo Xu"
      ],
      "abstract": "This paper explores multi-agent systems and identify challenges that remain\ninadequately addressed. By leveraging the diverse capabilities and roles of\nindividual agents, multi-agent systems can tackle complex tasks through agent\ncollaboration. We discuss optimizing task allocation, fostering robust\nreasoning through iterative debates, managing complex and layered context\ninformation, and enhancing memory management to support the intricate\ninteractions within multi-agent systems. We also explore potential applications\nof multi-agent systems in blockchain systems to shed light on their future\ndevelopment and application in real-world distributed systems.",
      "tldr_zh": "这篇论文探讨了LLM多智能体系统（Multi-Agent Systems）的挑战和未解决问题，通过利用个体智能体的多样能力和协作来处理复杂任务。论文重点讨论了优化任务分配、通过迭代辩论促进稳健推理、管理复杂分层上下文信息，以及增强记忆管理等关键挑战，以支持系统中的复杂交互。同时，它考察了多智能体系统在区块链系统中的潜在应用，并为这些系统在真实世界分布式环境中的未来发展和应用提供了见解。",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.03578v2",
      "published_date": "2024-02-05 23:06:42 UTC",
      "updated_date": "2025-05-12 18:42:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:13:14.938047"
    },
    {
      "arxiv_id": "2402.03575v2",
      "title": "Toward Human-AI Alignment in Large-Scale Multi-Player Games",
      "title_zh": "翻译失败",
      "authors": [
        "Sugandha Sharma",
        "Guy Davidson",
        "Khimya Khetarpal",
        "Anssi Kanervisto",
        "Udit Arora",
        "Katja Hofmann",
        "Ida Momennejad"
      ],
      "abstract": "Achieving human-AI alignment in complex multi-agent games is crucial for\ncreating trustworthy AI agents that enhance gameplay. We propose a method to\nevaluate this alignment using an interpretable task-sets framework, focusing on\nhigh-level behavioral tasks instead of low-level policies. Our approach has\nthree components. First, we analyze extensive human gameplay data from Xbox's\nBleeding Edge (100K+ games), uncovering behavioral patterns in a complex task\nspace. This task space serves as a basis set for a behavior manifold capturing\ninterpretable axes: fight-flight, explore-exploit, and solo-multi-agent.\nSecond, we train an AI agent to play Bleeding Edge using a Generative\nPretrained Causal Transformer and measure its behavior. Third, we project human\nand AI gameplay to the proposed behavior manifold to compare and contrast. This\nallows us to interpret differences in policy as higher-level behavioral\nconcepts, e.g., we find that while human players exhibit variability in\nfight-flight and explore-exploit behavior, AI players tend towards uniformity.\nFurthermore, AI agents predominantly engage in solo play, while humans often\nengage in cooperative and competitive multi-agent patterns. These stark\ndifferences underscore the need for interpretable evaluation, design, and\nintegration of AI in human-aligned applications. Our study advances the\nalignment discussion in AI and especially generative AI research, offering a\nmeasurable framework for interpretable human-agent alignment in multiplayer\ngaming.",
      "tldr_zh": "本研究针对大型多玩家游戏中的人类-AI 对齐（human-AI alignment）问题，提出了一种基于可解释任务集框架（interpretable task-sets framework）的评估方法，重点关注高层行为任务而非低层策略。研究团队分析了 Xbox 的 Bleeding Edge 游戏中超过10万场人类游戏数据，识别出行为流形（behavior manifold）的关键轴，包括 fight-flight、explore-exploit 和 solo-multi-agent，并使用 Generative Pretrained Causal Transformer 训练 AI 代理进行行为比较。结果显示，人类玩家在 fight-flight 和 explore-exploit 行为上表现出变异性，而 AI 玩家趋于统一，且更偏好 solo 玩法而非人类的合作或竞争多代理模式；这一差异强调了开发可解释 AI 评估框架的必要性，为生成式 AI 在多玩家游戏中的人类对齐提供了可衡量的指导。",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.03575v2",
      "published_date": "2024-02-05 22:55:33 UTC",
      "updated_date": "2024-06-18 20:23:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:13:28.309826"
    },
    {
      "arxiv_id": "2402.03570v4",
      "title": "Diffusion World Model: Future Modeling Beyond Step-by-Step Rollout for Offline Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Zihan Ding",
        "Amy Zhang",
        "Yuandong Tian",
        "Qinqing Zheng"
      ],
      "abstract": "We introduce Diffusion World Model (DWM), a conditional diffusion model\ncapable of predicting multistep future states and rewards concurrently. As\nopposed to traditional one-step dynamics models, DWM offers long-horizon\npredictions in a single forward pass, eliminating the need for recursive\nqueries. We integrate DWM into model-based value estimation, where the\nshort-term return is simulated by future trajectories sampled from DWM. In the\ncontext of offline reinforcement learning, DWM can be viewed as a conservative\nvalue regularization through generative modeling. Alternatively, it can be seen\nas a data source that enables offline Q-learning with synthetic data. Our\nexperiments on the D4RL dataset confirm the robustness of DWM to long-horizon\nsimulation. In terms of absolute performance, DWM significantly surpasses\none-step dynamics models with a $44\\%$ performance gain, and is comparable to\nor slightly surpassing their model-free counterparts.",
      "tldr_zh": "本文提出Diffusion World Model (DWM)，一个条件扩散模型，能够在单次前向传递中同时预测多步未来的状态和奖励，从而避免传统一步动态模型的递归查询。DWM被整合到模型-based价值估计中，用于offline reinforcement learning，作为保守的价值正则化或合成数据源，支持离线Q-learning。实验结果显示，在D4RL数据集上，DWM比一步动态模型性能提升44%，并与model-free方法相当或略胜一筹。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.03570v4",
      "published_date": "2024-02-05 22:43:57 UTC",
      "updated_date": "2024-10-15 20:56:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:13:39.410037"
    },
    {
      "arxiv_id": "2402.03563v2",
      "title": "Distinguishing the Knowable from the Unknowable with Language Models",
      "title_zh": "通过语言模型区分",
      "authors": [
        "Gustaf Ahdritz",
        "Tian Qin",
        "Nikhil Vyas",
        "Boaz Barak",
        "Benjamin L. Edelman"
      ],
      "abstract": "We study the feasibility of identifying epistemic uncertainty (reflecting a\nlack of knowledge), as opposed to aleatoric uncertainty (reflecting entropy in\nthe underlying distribution), in the outputs of large language models (LLMs)\nover free-form text. In the absence of ground-truth probabilities, we explore a\nsetting where, in order to (approximately) disentangle a given LLM's\nuncertainty, a significantly larger model stands in as a proxy for the ground\ntruth. We show that small linear probes trained on the embeddings of frozen,\npretrained models accurately predict when larger models will be more confident\nat the token level and that probes trained on one text domain generalize to\nothers. Going further, we propose a fully unsupervised method that achieves\nnon-trivial accuracy on the same task. Taken together, we interpret these\nresults as evidence that LLMs naturally contain internal representations of\ndifferent types of uncertainty that could potentially be leveraged to devise\nmore informative indicators of model confidence in diverse practical settings.",
      "tldr_zh": "这篇论文探讨了如何使用大型语言模型（LLMs）区分认识论不确定性（epistemic uncertainty，表示知识缺乏）和偶然不确定性（aleatoric uncertainty，表示底层分布的熵）。研究者采用一个更大的模型作为真实代理，通过训练小线性探针（linear probes）在冻结的预训练模型嵌入上，准确预测token级别的置信度，并证明这些探针在不同文本领域具有泛化能力。论文还提出了一种完全无监督方法，实现了非微不足道的准确率。这些发现表明，LLMs内部自然包含不同类型不确定性的表示，可能用于开发更具信息性的模型置信度指标。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.03563v2",
      "published_date": "2024-02-05 22:22:49 UTC",
      "updated_date": "2024-02-27 07:37:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:13:53.230391"
    },
    {
      "arxiv_id": "2402.03561v2",
      "title": "VLN-Video: Utilizing Driving Videos for Outdoor Vision-and-Language Navigation",
      "title_zh": "VLN-Video：利用驾驶视频进行室外视觉和语言导航",
      "authors": [
        "Jialu Li",
        "Aishwarya Padmakumar",
        "Gaurav Sukhatme",
        "Mohit Bansal"
      ],
      "abstract": "Outdoor Vision-and-Language Navigation (VLN) requires an agent to navigate\nthrough realistic 3D outdoor environments based on natural language\ninstructions. The performance of existing VLN methods is limited by\ninsufficient diversity in navigation environments and limited training data. To\naddress these issues, we propose VLN-Video, which utilizes the diverse outdoor\nenvironments present in driving videos in multiple cities in the U.S. augmented\nwith automatically generated navigation instructions and actions to improve\noutdoor VLN performance. VLN-Video combines the best of intuitive classical\napproaches and modern deep learning techniques, using template infilling to\ngenerate grounded navigation instructions, combined with an image rotation\nsimilarity-based navigation action predictor to obtain VLN style data from\ndriving videos for pretraining deep learning VLN models. We pre-train the model\non the Touchdown dataset and our video-augmented dataset created from driving\nvideos with three proxy tasks: Masked Language Modeling, Instruction and\nTrajectory Matching, and Next Action Prediction, so as to learn\ntemporally-aware and visually-aligned instruction representations. The learned\ninstruction representation is adapted to the state-of-the-art navigator when\nfine-tuning on the Touchdown dataset. Empirical results demonstrate that\nVLN-Video significantly outperforms previous state-of-the-art models by 2.1% in\ntask completion rate, achieving a new state-of-the-art on the Touchdown\ndataset.",
      "tldr_zh": "本文提出 VLN-Video 方法，利用美国多个城市的驾驶视频，通过自动生成导航指令和动作，来解决户外 Vision-and-Language Navigation (VLN) 的环境多样性和训练数据不足问题。该方法结合模板 infilling 生成指令，以及基于图像旋转相似性的导航动作预测器，并在 Touchdown 数据集上预训练模型，使用 Masked Language Modeling、Instruction and Trajectory Matching 和 Next Action Prediction 等任务，以学习时间感知和视觉对齐的指令表示。实验结果显示，VLN-Video 在 Touchdown 数据集上微调后，任务完成率比现有最先进模型提高了 2.1%，达到了新的性能基准。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "AAAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.03561v2",
      "published_date": "2024-02-05 22:20:19 UTC",
      "updated_date": "2024-02-07 18:02:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:14:05.318267"
    },
    {
      "arxiv_id": "2402.03559v3",
      "title": "Constrained Synthesis with Projected Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jacob K Christopher",
        "Stephen Baek",
        "Ferdinando Fioretto"
      ],
      "abstract": "This paper introduces an approach to endow generative diffusion processes the\nability to satisfy and certify compliance with constraints and physical\nprinciples. The proposed method recast the traditional sampling process of\ngenerative diffusion models as a constrained optimization problem, steering the\ngenerated data distribution to remain within a specified region to ensure\nadherence to the given constraints. These capabilities are validated on\napplications featuring both convex and challenging, non-convex, constraints as\nwell as ordinary differential equations, in domains spanning from synthesizing\nnew materials with precise morphometric properties, generating physics-informed\nmotion, optimizing paths in planning scenarios, and human motion synthesis.",
      "tldr_zh": "这篇论文提出了一种名为“Constrained Synthesis with Projected Diffusion Models”的方法，使生成扩散模型（generative diffusion models）能够满足并验证约束和物理原则。核心机制是将传统的采样过程转化为约束优化问题（constrained optimization problem），通过投影技术确保生成的数据分布保持在指定区域内，从而处理凸约束、非凸约束以及普通微分方程（ordinary differential equations）。实验验证了该方法在多种应用中的有效性，包括合成具有精确形态特性的新材料、生成物理信息运动、优化路径规划场景以及人类运动合成。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Published at the 38th Conference on Neural Information Processing\n  Systems (NeurIPS 2024)",
      "pdf_url": "http://arxiv.org/pdf/2402.03559v3",
      "published_date": "2024-02-05 22:18:16 UTC",
      "updated_date": "2024-11-01 20:15:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:14:15.500797"
    },
    {
      "arxiv_id": "2402.03539v1",
      "title": "Extended Version of: On the Structural Hardness of Answer Set Programming: Can Structure Efficiently Confine the Power of Disjunctions?",
      "title_zh": "翻译失败",
      "authors": [
        "Markus Hecher",
        "Rafael Kiesel"
      ],
      "abstract": "Answer Set Programming (ASP) is a generic problem modeling and solving\nframework with a strong focus on knowledge representation and a rapid growth of\nindustrial applications. So far, the study of complexity resulted in\ncharacterizing hardness and determining their sources, fine-grained insights in\nthe form of dichotomy-style results, as well as detailed parameterized\ncomplexity landscapes. Unfortunately, for the well-known parameter treewidth\ndisjunctive programs require double-exponential runtime under reasonable\ncomplexity assumptions. This quickly becomes out of reach. We deal with the\nclassification of structural parameters for disjunctive ASP on the program's\nrule structure (incidence graph).\n  First, we provide a polynomial kernel to obtain single-exponential runtime in\nterms of vertex cover size, despite subset-minimization being not represented\nin the program's structure. Then we turn our attention to strictly better\nstructural parameters between vertex cover size and treewidth. Here, we provide\ndouble-exponential lower bounds for the most prominent parameters in that\nrange: treedepth, feedback vertex size, and cliquewidth. Based on this, we\nargue that unfortunately our options beyond vertex cover size are limited. Our\nresults provide an in-depth hardness study, relying on a novel reduction from\nnormal to disjunctive programs, trading the increase of complexity for an\nexponential parameter compression.",
      "tldr_zh": "这篇论文扩展了对 Answer Set Programming (ASP) 的结构硬度研究，探讨结构参数是否能有效限制 disjunctions 的威力，特别是针对程序的规则结构（incidence graph）。作者提供了一个多项式 kernel，使 disjunctive ASP 在 vertex cover size 参数下实现单指数运行时间，尽管 subset-minimization 不在结构中。论文进一步证明了 treedepth、feedback vertex size 和 cliquewidth 等参数存在双指数下界，表明这些参数的实用性有限。总体结果基于一个新颖的从 normal 到 disjunctive programs 的归约，实现了指数参数压缩但增加了复杂性。",
      "categories": [
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.03539v1",
      "published_date": "2024-02-05 21:51:36 UTC",
      "updated_date": "2024-02-05 21:51:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:14:28.081625"
    },
    {
      "arxiv_id": "2402.03535v1",
      "title": "Preliminary Report on Mantis Shrimp: a Multi-Survey Computer Vision Photometric Redshift Model",
      "title_zh": "翻译失败",
      "authors": [
        "Andrew Engel",
        "Gautham Narayan",
        "Nell Byler"
      ],
      "abstract": "The availability of large, public, multi-modal astronomical datasets presents\nan opportunity to execute novel research that straddles the line between\nscience of AI and science of astronomy. Photometric redshift estimation is a\nwell-established subfield of astronomy. Prior works show that computer vision\nmodels typically outperform catalog-based models, but these models face\nadditional complexities when incorporating images from more than one instrument\nor sensor. In this report, we detail our progress creating Mantis Shrimp, a\nmulti-survey computer vision model for photometric redshift estimation that\nfuses ultra-violet (GALEX), optical (PanSTARRS), and infrared (UnWISE) imagery.\nWe use deep learning interpretability diagnostics to measure how the model\nleverages information from the different inputs. We reason about the behavior\nof the CNNs from the interpretability metrics, specifically framing the result\nin terms of physically-grounded knowledge of galaxy properties.",
      "tldr_zh": "该报告介绍了Mantis Shrimp，一种多调查计算机视觉模型，用于光度红shift estimation（光度红移估计），它融合了GALEX的紫外线、PanSTARRS的光学和UnWISE的红外图像，以处理多模态天文数据集。模型通过计算机视觉技术超越了传统的目录-based方法，并利用深度学习可解释性诊断来分析如何从不同输入中提取信息。研究结果将CNNs的行为与星系属性的物理知识联系起来，展示了AI与天文学交叉研究的潜力。",
      "categories": [
        "astro-ph.IM",
        "cs.AI"
      ],
      "primary_category": "astro-ph.IM",
      "comment": "4 pages, 1 figure, 1 table. Submitted to AI4Differential Equations in\n  Science Workshop at ICLR24. Public repository unavailable while under\n  institutional review",
      "pdf_url": "http://arxiv.org/pdf/2402.03535v1",
      "published_date": "2024-02-05 21:44:19 UTC",
      "updated_date": "2024-02-05 21:44:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:14:40.951918"
    },
    {
      "arxiv_id": "2402.06660v3",
      "title": "A philosophical and ontological perspective on Artificial General Intelligence and the Metaverse",
      "title_zh": "翻译失败",
      "authors": [
        "Martin Schmalzried"
      ],
      "abstract": "This paper leverages various philosophical and ontological frameworks to\nexplore the concept of embodied artificial general intelligence (AGI), its\nrelationship to human consciousness, and the key role of the metaverse in\nfacilitating this relationship. Several theoretical frameworks underpin this\nexploration, such as embodied cognition, Michael Levin's computational boundary\nof a \"Self,\" Donald D. Hoffman's Interface Theory of Perception, and Bernardo\nKastrup's analytical idealism, which lead to considering our perceived outer\nreality as a symbolic representation of alternate inner states of being, and\nwhere AGI could embody a different form of consciousness with a larger\ncomputational boundary. The paper further discusses the developmental stages of\nAGI, the requirements for the emergence of an embodied AGI, the importance of a\ncalibrated symbolic interface for AGI, and the key role played by the\nmetaverse, decentralized systems, open-source blockchain technology, as well as\nopen-source AI research. It also explores the idea of a feedback loop between\nAGI and human users in metaverse spaces as a tool for AGI calibration, as well\nas the role of local homeostasis and decentralized governance as preconditions\nfor achieving a stable embodied AGI. The paper concludes by emphasizing the\nimportance of achieving a certain degree of harmony in human relations and\nrecognizing the interconnectedness of humanity at a global level, as key\nprerequisites for the emergence of a stable embodied AGI.",
      "tldr_zh": "本论文从哲学和本体论角度探讨了具身人工智能通用智能 (embodied AGI) 与人类意识的关系，以及 Metaverse 在其中扮演的关键角色，运用理论框架如 embodied cognition、Michael Levin 的 computational boundary of a \"Self\"、Donald D. Hoffman 的 Interface Theory of Perception 和 Bernardo Kastrup 的 analytical idealism，将外在现实视为内在状态的象征表示。论文分析了 AGI 的发展阶段、实现具身 AGI 的要求（如校准的象征接口）和 Metaverse 的重要性，包括去中心化系统、开源区块链技术和反馈循环作为 AGI 校准工具。最终，它强调了局部稳态、去中心化治理以及全球人类和谐与互联作为稳定具身 AGI 出现的关键先决条件。",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "Presented at the conference second international conference on\n  human-centred AI ethics: seeing the human in the artificial (HCAIE 2023):\n  https://ethics-ai.eu/hcaie2023/",
      "pdf_url": "http://arxiv.org/pdf/2402.06660v3",
      "published_date": "2024-02-05 21:43:11 UTC",
      "updated_date": "2024-12-09 12:40:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:14:55.090568"
    },
    {
      "arxiv_id": "2402.03525v1",
      "title": "Deep Reinforcement Learning for Picker Routing Problem in Warehousing",
      "title_zh": "翻译失败",
      "authors": [
        "George Dunn",
        "Hadi Charkhgard",
        "Ali Eshragh",
        "Sasan Mahmoudinazlou",
        "Elizabeth Stojanovski"
      ],
      "abstract": "Order Picker Routing is a critical issue in Warehouse Operations Management.\nDue to the complexity of the problem and the need for quick solutions,\nsuboptimal algorithms are frequently employed in practice. However,\nReinforcement Learning offers an appealing alternative to traditional\nheuristics, potentially outperforming existing methods in terms of speed and\naccuracy. We introduce an attention based neural network for modeling picker\ntours, which is trained using Reinforcement Learning. Our method is evaluated\nagainst existing heuristics across a range of problem parameters to demonstrate\nits efficacy. A key advantage of our proposed method is its ability to offer an\noption to reduce the perceived complexity of routes.",
      "tldr_zh": "这篇论文针对仓库运营中的订单拣货路由问题（Picker Routing Problem），提出使用深度强化学习（Deep Reinforcement Learning）作为替代传统次优算法的方法，以提高速度和准确性。研究团队开发了一个基于注意力的神经网络（attention based neural network），通过强化学习训练来优化拣货路径，并在各种问题参数下与现有启发式算法（heuristics）进行比较。结果表明，该方法表现出色，并能降低路由的感知复杂性，提供更高效的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.03525v1",
      "published_date": "2024-02-05 21:25:45 UTC",
      "updated_date": "2024-02-05 21:25:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:15:06.226786"
    },
    {
      "arxiv_id": "2402.07928v1",
      "title": "Abstracted Trajectory Visualization for Explainability in Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Yoshiki Takagi",
        "Roderick Tabalba",
        "Nurit Kirshenbaum",
        "Jason Leigh"
      ],
      "abstract": "Explainable AI (XAI) has demonstrated the potential to help reinforcement\nlearning (RL) practitioners to understand how RL models work. However, XAI for\nusers who do not have RL expertise (non-RL experts), has not been studied\nsufficiently. This results in a difficulty for the non-RL experts to\nparticipate in the fundamental discussion of how RL models should be designed\nfor an incoming society where humans and AI coexist. Solving such a problem\nwould enable RL experts to communicate with the non-RL experts in producing\nmachine learning solutions that better fit our society. We argue that\nabstracted trajectories, that depicts transitions between the major states of\nthe RL model, will be useful for non-RL experts to build a mental model of the\nagents. Our early results suggest that by leveraging a visualization of the\nabstracted trajectories, users without RL expertise are able to infer the\nbehavior patterns of RL.",
      "tldr_zh": "该研究探讨了Explainable AI (XAI)在Reinforcement Learning (RL)中的应用，强调现有方法主要针对RL专家，而非RL专家难以参与RL模型设计的讨论，从而阻碍了人类与AI共存社会的构建。论文提出使用抽象轨迹（abstracted trajectories）可视化方法，该技术描绘RL模型主要状态之间的转换，帮助非RL专家建立对代理行为的心理模型。初步实验结果表明，这种可视化能使非RL专家有效推断RL的行为模式，从而促进RL专家与非专家的沟通，推动更适合社会的机器学习解决方案。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.HC",
      "comment": "14pages, 11figures",
      "pdf_url": "http://arxiv.org/pdf/2402.07928v1",
      "published_date": "2024-02-05 21:17:44 UTC",
      "updated_date": "2024-02-05 21:17:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:15:16.206337"
    },
    {
      "arxiv_id": "2402.03519v1",
      "title": "Resolving Transcription Ambiguity in Spanish: A Hybrid Acoustic-Lexical System for Punctuation Restoration",
      "title_zh": "翻译失败",
      "authors": [
        "Xiliang Zhu",
        "Chia-Tien Chang",
        "Shayna Gardiner",
        "David Rossouw",
        "Jonas Robertson"
      ],
      "abstract": "Punctuation restoration is a crucial step after Automatic Speech Recognition\n(ASR) systems to enhance transcript readability and facilitate subsequent NLP\ntasks. Nevertheless, conventional lexical-based approaches are inadequate for\nsolving the punctuation restoration task in Spanish, where ambiguity can be\noften found between unpunctuated declaratives and questions. In this study, we\npropose a novel hybrid acoustic-lexical punctuation restoration system for\nSpanish transcription, which consolidates acoustic and lexical signals through\na modular process. Our experiment results show that the proposed system can\neffectively improve F1 score of question marks and overall punctuation\nrestoration on both public and internal Spanish conversational datasets.\nAdditionally, benchmark comparison against LLMs (Large Language Model)\nindicates the superiority of our approach in accuracy, reliability and latency.\nFurthermore, we demonstrate that the Word Error Rate (WER) of the ASR module\nalso benefits from our proposed system.",
      "tldr_zh": "本研究针对西班牙语转录中的歧义问题，提出了一种混合声学-词汇系统，用于Automatic Speech Recognition (ASR)后的标点符号恢复，以提升转录可读性和后续NLP任务。该系统通过模块化过程整合声学和词汇信号，解决了传统词汇方法在声明句和疑问句歧义上的不足。实验结果显示，该系统在公共和内部西班牙语对话数据集上显著提高了问号的F1 score和整体标点恢复性能，且在准确性、可靠性和延迟方面优于Large Language Models (LLMs)，同时还改善了ASR模块的Word Error Rate (WER)。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to UnImplicit workshop at EACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.03519v1",
      "published_date": "2024-02-05 21:05:35 UTC",
      "updated_date": "2024-02-05 21:05:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:15:28.843626"
    },
    {
      "arxiv_id": "2402.03509v1",
      "title": "Evaluating the Factuality of Zero-shot Summarizers Across Varied Domains",
      "title_zh": "翻译失败",
      "authors": [
        "Sanjana Ramprasad",
        "Kundan Krishna",
        "Zachary C Lipton",
        "Byron C Wallace"
      ],
      "abstract": "Recent work has shown that large language models (LLMs) are capable of\ngenerating summaries zero-shot (i.e., without explicit supervision) that, under\nhuman assessment, are often comparable or even preferred to manually composed\nreference summaries. However, this prior work has focussed almost exclusively\non evaluating news article summarization. How do zero-shot summarizers perform\nin other (potentially more specialized) domains? In this work we evaluate\nzero-shot generated summaries across specialized domains including biomedical\narticles, and legal bills (in addition to standard news benchmarks for\nreference). We focus especially on the factuality of outputs. We acquire\nannotations from domain experts to identify inconsistencies in summaries and\nsystematically categorize these errors. We analyze whether the prevalence of a\ngiven domain in the pretraining corpus affects extractiveness and faithfulness\nof generated summaries of articles in this domain. We release all collected\nannotations to facilitate additional research toward measuring and realizing\nfactually accurate summarization, beyond news articles. The dataset can be\ndownloaded from https://github.com/sanjanaramprasad/zero_shot_faceval_domains",
      "tldr_zh": "该研究评估了大型语言模型 (LLMs) 在零-shot 条件下生成摘要的真实性 (factuality)，扩展到新闻以外的领域，如生物医学文章和法律法案。研究人员通过领域专家的注解识别和系统分类摘要中的不一致错误，并分析特定领域在预训练语料中的出现频率对摘要的提取性 (extractiveness) 和忠实度 (faithfulness) 的影响。结果显示，零-shot 摘要生成器在专业领域可能存在显著问题，实验数据有助于提升摘要的准确性。该数据集已公开，以推动更多真实性相关的总结研究。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.03509v1",
      "published_date": "2024-02-05 20:51:11 UTC",
      "updated_date": "2024-02-05 20:51:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:15:40.721143"
    },
    {
      "arxiv_id": "2402.03507v1",
      "title": "Neural networks for abstraction and reasoning: Towards broad generalization in machines",
      "title_zh": "用于抽象和推理的神经网络：朝向机器中的广泛泛化",
      "authors": [
        "Mikel Bober-Irizar",
        "Soumya Banerjee"
      ],
      "abstract": "For half a century, artificial intelligence research has attempted to\nreproduce the human qualities of abstraction and reasoning - creating computer\nsystems that can learn new concepts from a minimal set of examples, in settings\nwhere humans find this easy. While specific neural networks are able to solve\nan impressive range of problems, broad generalisation to situations outside\ntheir training data has proved elusive.In this work, we look at several novel\napproaches for solving the Abstraction & Reasoning Corpus (ARC), a dataset of\nabstract visual reasoning tasks introduced to test algorithms on broad\ngeneralization. Despite three international competitions with $100,000 in\nprizes, the best algorithms still fail to solve a majority of ARC tasks and\nrely on complex hand-crafted rules, without using machine learning at all. We\nrevisit whether recent advances in neural networks allow progress on this task.\n  First, we adapt the DreamCoder neurosymbolic reasoning solver to ARC.\nDreamCoder automatically writes programs in a bespoke domain-specific language\nto perform reasoning, using a neural network to mimic human intuition. We\npresent the Perceptual Abstraction and Reasoning Language (PeARL) language,\nwhich allows DreamCoder to solve ARC tasks, and propose a new recognition model\nthat allows us to significantly improve on the previous best implementation.We\nalso propose a new encoding and augmentation scheme that allows large language\nmodels (LLMs) to solve ARC tasks, and find that the largest models can solve\nsome ARC tasks. LLMs are able to solve a different group of problems to\nstate-of-the-art solvers, and provide an interesting way to complement other\napproaches. We perform an ensemble analysis, combining models to achieve better\nresults than any system alone. Finally, we publish the arckit Python library to\nmake future research on ARC easier.",
      "tldr_zh": "本研究探讨了神经网络在抽象和推理方面的应用，旨在实现机器的广义泛化（broad generalization），以解决人工智能在学习新概念时的挑战，特别是针对Abstraction & Reasoning Corpus (ARC)数据集。研究者改进了DreamCoder神经符号推理求解器，引入了Perceptual Abstraction and Reasoning Language (PeARL)语言，并开发了新的编码和增强方案，使Large Language Models (LLMs)能够解决部分ARC任务；同时，通过ensemble analysis结合不同模型，显著提升了性能。实验结果显示，LLMs能处理DreamCoder无法覆盖的问题，最终研究还发布了arckit Python库，以促进未来ARC相关研究。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "32 pages main text, 17 pages",
      "pdf_url": "http://arxiv.org/pdf/2402.03507v1",
      "published_date": "2024-02-05 20:48:57 UTC",
      "updated_date": "2024-02-05 20:48:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:15:52.428335"
    },
    {
      "arxiv_id": "2402.03501v1",
      "title": "An Inpainting-Infused Pipeline for Attire and Background Replacement",
      "title_zh": "翻译失败",
      "authors": [
        "Felipe Rodrigues Perche-Mahlow",
        "André Felipe-Zanella",
        "William Alberto Cruz-Castañeda",
        "Marcellus Amadeus"
      ],
      "abstract": "In recent years, groundbreaking advancements in Generative Artificial\nIntelligence (GenAI) have triggered a transformative paradigm shift,\nsignificantly influencing various domains. In this work, we specifically\nexplore an integrated approach, leveraging advanced techniques in GenAI and\ncomputer vision emphasizing image manipulation. The methodology unfolds through\nseveral stages, including depth estimation, the creation of inpaint masks based\non depth information, the generation and replacement of backgrounds utilizing\nStable Diffusion in conjunction with Latent Consistency Models (LCMs), and the\nsubsequent replacement of clothes and application of aesthetic changes through\nan inpainting pipeline. Experiments conducted in this study underscore the\nmethodology's efficacy, highlighting its potential to produce visually\ncaptivating content. The convergence of these advanced techniques allows users\nto input photographs of individuals and manipulate them to modify clothing and\nbackground based on specific prompts without manually input inpainting masks,\neffectively placing the subjects within the vast landscape of creative\nimagination.",
      "tldr_zh": "该论文提出了一种融入修复(inpainting)技术的管道，用于图像中服装(attire)和背景的自动替换，旨在利用Generative Artificial Intelligence (GenAI)和计算机视觉技术实现创意图像操作。方法包括深度估计(depth estimation)、基于深度信息生成修复掩码(inpaint masks)、利用Stable Diffusion和Latent Consistency Models (LCMs)替换背景，以及通过修复管道应用服装替换和美学变化。实验结果证明了该方法的有效性，用户只需输入照片和提示，即可轻松修改内容，而无需手动创建修复掩码，从而扩展了图像处理的创意潜力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.03501v1",
      "published_date": "2024-02-05 20:34:32 UTC",
      "updated_date": "2024-02-05 20:34:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:16:05.053749"
    },
    {
      "arxiv_id": "2402.03500v1",
      "title": "Curriculum reinforcement learning for quantum architecture search under hardware errors",
      "title_zh": "课程式强化学习用于硬件错误下的量子架构搜索",
      "authors": [
        "Yash J. Patel",
        "Akash Kundu",
        "Mateusz Ostaszewski",
        "Xavier Bonet-Monroig",
        "Vedran Dunjko",
        "Onur Danaci"
      ],
      "abstract": "The key challenge in the noisy intermediate-scale quantum era is finding\nuseful circuits compatible with current device limitations. Variational quantum\nalgorithms (VQAs) offer a potential solution by fixing the circuit architecture\nand optimizing individual gate parameters in an external loop. However,\nparameter optimization can become intractable, and the overall performance of\nthe algorithm depends heavily on the initially chosen circuit architecture.\nSeveral quantum architecture search (QAS) algorithms have been developed to\ndesign useful circuit architectures automatically. In the case of parameter\noptimization alone, noise effects have been observed to dramatically influence\nthe performance of the optimizer and final outcomes, which is a key line of\nstudy. However, the effects of noise on the architecture search, which could be\njust as critical, are poorly understood. This work addresses this gap by\nintroducing a curriculum-based reinforcement learning QAS (CRLQAS) algorithm\ndesigned to tackle challenges in realistic VQA deployment. The algorithm\nincorporates (i) a 3D architecture encoding and restrictions on environment\ndynamics to explore the search space of possible circuits efficiently, (ii) an\nepisode halting scheme to steer the agent to find shorter circuits, and (iii) a\nnovel variant of simultaneous perturbation stochastic approximation as an\noptimizer for faster convergence. To facilitate studies, we developed an\noptimized simulator for our algorithm, significantly improving computational\nefficiency in simulating noisy quantum circuits by employing the Pauli-transfer\nmatrix formalism in the Pauli-Liouville basis. Numerical experiments focusing\non quantum chemistry tasks demonstrate that CRLQAS outperforms existing QAS\nalgorithms across several metrics in both noiseless and noisy environments.",
      "tldr_zh": "本研究针对噪声中等规模量子时代下量子电路设计的挑战，提出了一种基于课程强化学习的量子架构搜索算法（CRLQAS），旨在自动优化变分量子算法（VQAs）的电路架构以适应硬件错误。CRLQAS 创新性地整合了3D 架构编码、环境动态限制、剧集中止方案以及一种新型的同步扰动随机逼近优化器，以高效探索搜索空间并实现更快收敛；同时，开发了一个基于 Pauli-transfer matrix 形式主义的优化模拟器，提升了噪声量子电路模拟的计算效率。在量子化学任务的数值实验中，CRLQAS 在无噪声和有噪声环境中均优于现有 QAS 算法，在多个指标上表现出色。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "quant-ph",
      "comment": "32 pages, 11 figures, 6 tables. Accepted at ICLR 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.03500v1",
      "published_date": "2024-02-05 20:33:00 UTC",
      "updated_date": "2024-02-05 20:33:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:16:16.977872"
    },
    {
      "arxiv_id": "2402.03494v3",
      "title": "Beyond Text: Utilizing Vocal Cues to Improve Decision Making in LLMs for Robot Navigation Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Xingpeng Sun",
        "Haoming Meng",
        "Souradip Chakraborty",
        "Amrit Singh Bedi",
        "Aniket Bera"
      ],
      "abstract": "While LLMs excel in processing text in these human conversations, they\nstruggle with the nuances of verbal instructions in scenarios like social\nnavigation, where ambiguity and uncertainty can erode trust in robotic and\nother AI systems. We can address this shortcoming by moving beyond text and\nadditionally focusing on the paralinguistic features of these audio responses.\nThese features are the aspects of spoken communication that do not involve the\nliteral wording (lexical content) but convey meaning and nuance through how\nsomething is said. We present Beyond Text: an approach that improves LLM\ndecision-making by integrating audio transcription along with a subsection of\nthese features, which focus on the affect and more relevant in human-robot\nconversations.This approach not only achieves a 70.26% winning rate,\noutperforming existing LLMs by 22.16% to 48.30% (gemini-1.5-pro and gpt-3.5\nrespectively), but also enhances robustness against token manipulation\nadversarial attacks, highlighted by a 22.44% less decrease ratio than the\ntext-only language model in winning rate. Beyond Text' marks an advancement in\nsocial robot navigation and broader Human-Robot interactions, seamlessly\nintegrating text-based guidance with human-audio-informed language models.",
      "tldr_zh": "本研究探讨了大型语言模型（LLMs）在机器人导航任务中处理人类对话时存在的不足，特别是对语音指令的模糊性和不确定性的敏感度问题。为此，提出Beyond Text方法，通过整合音频转录和语音特征（如情感表达），提升LLMs的决策能力。该方法在实验中实现了70.26%的获胜率，比gemini-1.5-pro和gpt-3.5分别高出22.16%和48.30%，并显著提高了对token manipulation adversarial attacks的鲁棒性，降低了22.44%的获胜率下降比例。总之，Beyond Text推动了社交机器人导航和人机交互的进步，实现文本指导与音频信息的无缝融合。",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "30 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.03494v3",
      "published_date": "2024-02-05 20:11:56 UTC",
      "updated_date": "2024-11-11 04:03:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:16:29.332826"
    },
    {
      "arxiv_id": "2402.03486v1",
      "title": "Early prediction of onset of sepsis in Clinical Setting",
      "title_zh": "在临床环境中对败血症发作的早期预测",
      "authors": [
        "Fahim Mohammad",
        "Lakshmi Arunachalam",
        "Samanway Sadhu",
        "Boudewijn Aasman",
        "Shweta Garg",
        "Adil Ahmed",
        "Silvie Colman",
        "Meena Arunachalam",
        "Sudhir Kulkarni",
        "Parsa Mirhaji"
      ],
      "abstract": "This study proposes the use of Machine Learning models to predict the early\nonset of sepsis using deidentified clinical data from Montefiore Medical Center\nin Bronx, NY, USA. A supervised learning approach was adopted, wherein an\nXGBoost model was trained utilizing 80\\% of the train dataset, encompassing 107\nfeatures (including the original and derived features). Subsequently, the model\nwas evaluated on the remaining 20\\% of the test data. The model was validated\non prospective data that was entirely unseen during the training phase. To\nassess the model's performance at the individual patient level and timeliness\nof the prediction, a normalized utility score was employed, a widely recognized\nscoring methodology for sepsis detection, as outlined in the PhysioNet Sepsis\nChallenge paper. Metrics such as F1 Score, Sensitivity, Specificity, and Flag\nRate were also devised. The model achieved a normalized utility score of 0.494\non test data and 0.378 on prospective data at threshold 0.3. The F1 scores were\n80.8\\% and 67.1\\% respectively for the test data and the prospective data for\nthe same threshold, highlighting its potential to be integrated into clinical\ndecision-making processes effectively. These results bear testament to the\nmodel's robust predictive capabilities and its potential to substantially\nimpact clinical decision-making processes.",
      "tldr_zh": "这篇论文提出使用 XGBoost 模型进行败血症早期发作的预测，基于 Montefiore Medical Center 的去标识化临床数据，采用监督学习方法训练了包含 107 个特征的数据集。模型在 80% 的训练数据上训练，并通过 20% 的测试数据以及未见的前瞻性数据进行验证，使用归一化效用分数、F1 Score、灵敏度、特异性和标记率等指标评估。结果显示，在阈值 0.3 时，测试数据的 F1 Score 为 80.8%、归一化效用分数为 0.494，而前瞻性数据的相应值为 67.1% 和 0.378，证明了模型的鲁棒性和在临床决策中的潜在应用价值。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.LG",
      "comment": "16 pages, 6 figures and 7 tables",
      "pdf_url": "http://arxiv.org/pdf/2402.03486v1",
      "published_date": "2024-02-05 19:58:40 UTC",
      "updated_date": "2024-02-05 19:58:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:16:44.480989"
    },
    {
      "arxiv_id": "2402.03483v2",
      "title": "SWAG: Storytelling With Action Guidance",
      "title_zh": "翻译失败",
      "authors": [
        "Zeeshan Patel",
        "Karim El-Refai",
        "Jonathan Pei",
        "Tianle Li"
      ],
      "abstract": "Automated long-form story generation typically employs long-context large\nlanguage models (LLMs) for one-shot creation, which can produce cohesive but\nnot necessarily engaging content. We introduce Storytelling With Action\nGuidance (SWAG), a novel approach to storytelling with LLMs. Our approach\nframes story writing as a search problem through a two-model feedback loop: one\nLLM generates story content, and another auxiliary LLM is used to choose the\nnext best \"action\" to steer the story's future direction. Our results show that\nSWAG can substantially outperform previous end-to-end story generation\ntechniques when evaluated by GPT-4 and through human evaluation. Our SWAG\npipeline using only small open-source models surpasses GPT-3.5-Turbo.",
      "tldr_zh": "本文提出 SWAG（Storytelling With Action Guidance），一种创新的基于 LLMs 的故事生成方法，将故事写作视为搜索问题，通过两个模型的反馈循环实现：一个 LLM 生成故事内容，另一个辅助 LLM 选择最佳“action”来引导故事方向。相比传统的端到端生成技术，SWAG 在 GPT-4 和人类评估中表现出显著优势。实验结果表明，使用小开源模型的 SWAG 管道甚至超过了 GPT-3.5-Turbo，在自动化长篇故事生成中提升了内容的连贯性和吸引力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "EMNLP Findings 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.03483v2",
      "published_date": "2024-02-05 19:55:06 UTC",
      "updated_date": "2024-10-07 22:36:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:16:53.285684"
    },
    {
      "arxiv_id": "2402.05968v1",
      "title": "Federated Learning Priorities Under the European Union Artificial Intelligence Act",
      "title_zh": "翻译失败",
      "authors": [
        "Herbert Woisetschläger",
        "Alexander Erben",
        "Bill Marino",
        "Shiqiang Wang",
        "Nicholas D. Lane",
        "Ruben Mayer",
        "Hans-Arno Jacobsen"
      ],
      "abstract": "The age of AI regulation is upon us, with the European Union Artificial\nIntelligence Act (AI Act) leading the way. Our key inquiry is how this will\naffect Federated Learning (FL), whose starting point of prioritizing data\nprivacy while performing ML fundamentally differs from that of centralized\nlearning. We believe the AI Act and future regulations could be the missing\ncatalyst that pushes FL toward mainstream adoption. However, this can only\noccur if the FL community reprioritizes its research focus. In our position\npaper, we perform a first-of-its-kind interdisciplinary analysis (legal and ML)\nof the impact the AI Act may have on FL and make a series of observations\nsupporting our primary position through quantitative and qualitative analysis.\nWe explore data governance issues and the concern for privacy. We establish new\nchallenges regarding performance and energy efficiency within lifecycle\nmonitoring. Taken together, our analysis suggests there is a sizable\nopportunity for FL to become a crucial component of AI Act-compliant ML systems\nand for the new regulation to drive the adoption of FL techniques in general.\nMost noteworthy are the opportunities to defend against data bias and enhance\nprivate and secure computation",
      "tldr_zh": "本论文探讨了欧盟人工智能法案（AI Act）对联邦学习（Federated Learning, FL）的潜在影响，强调FL以数据隐私为优先的特性可能使其在AI Act下获得主流采用，但需重新调整研究焦点。作者通过首次跨学科分析（结合法律和机器学习，ML），利用定量和定性方法，评估了数据治理、隐私保护、性能及能源效率等方面的挑战和机遇。研究发现，FL有机会成为AI Act合规ML系统的重要组成部分，特别是通过防御数据偏差和提升私有安全计算来推动其应用和发展。总体而言，此分析为FL社区提供了战略指导，以适应新法规并促进技术创新。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY",
        "cs.DC",
        "I.2; I.2.11; K.5"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.05968v1",
      "published_date": "2024-02-05 19:52:19 UTC",
      "updated_date": "2024-02-05 19:52:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:17:06.770945"
    },
    {
      "arxiv_id": "2402.07927v2",
      "title": "A Systematic Survey of Prompt Engineering in Large Language Models: Techniques and Applications",
      "title_zh": "大型语言模型中提示工程的系统调查：技术与应用",
      "authors": [
        "Pranab Sahoo",
        "Ayush Kumar Singh",
        "Sriparna Saha",
        "Vinija Jain",
        "Samrat Mondal",
        "Aman Chadha"
      ],
      "abstract": "Prompt engineering has emerged as an indispensable technique for extending\nthe capabilities of large language models (LLMs) and vision-language models\n(VLMs). This approach leverages task-specific instructions, known as prompts,\nto enhance model efficacy without modifying the core model parameters. Rather\nthan updating the model parameters, prompts allow seamless integration of\npre-trained models into downstream tasks by eliciting desired model behaviors\nsolely based on the given prompt. Prompts can be natural language instructions\nthat provide context to guide the model or learned vector representations that\nactivate relevant knowledge. This burgeoning field has enabled success across\nvarious applications, from question-answering to commonsense reasoning.\nHowever, there remains a lack of systematic organization and understanding of\nthe diverse prompt engineering methods and techniques. This survey paper\naddresses the gap by providing a structured overview of recent advancements in\nprompt engineering, categorized by application area. For each prompting\napproach, we provide a summary detailing the prompting methodology, its\napplications, the models involved, and the datasets utilized. We also delve\ninto the strengths and limitations of each approach and include a taxonomy\ndiagram and table summarizing datasets, models, and critical points of each\nprompting technique. This systematic analysis enables a better understanding of\nthis rapidly developing field and facilitates future research by illuminating\nopen challenges and opportunities for prompt engineering.",
      "tldr_zh": "这篇论文对大型语言模型（LLMs）和视觉语言模型（VLMs）的提示工程（Prompt Engineering）进行了系统调查，强调了通过任务特定提示（如自然语言指令或学习向量）提升模型效能的方法，而无需修改核心参数。论文按应用领域分类概述了各种提示技术，包括其原理、应用、涉及的模型（如LLMs）、数据集，以及每个方法的优势（如无缝集成）和局限性（如潜在知识缺口）。最终，该研究通过分类图表和表格总结关键点，揭示了提示工程的快速发展，并为未来研究指出了挑战和机会。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "12 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.07927v2",
      "published_date": "2024-02-05 19:49:13 UTC",
      "updated_date": "2025-03-16 06:23:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:17:18.532058"
    },
    {
      "arxiv_id": "2402.03480v1",
      "title": "Trillion Parameter AI Serving Infrastructure for Scientific Discovery: A Survey and Vision",
      "title_zh": "翻译失败",
      "authors": [
        "Nathaniel Hudson",
        "J. Gregory Pauloski",
        "Matt Baughman",
        "Alok Kamatar",
        "Mansi Sakarvadia",
        "Logan Ward",
        "Ryan Chard",
        "André Bauer",
        "Maksim Levental",
        "Wenyi Wang",
        "Will Engler",
        "Owen Price Skelly",
        "Ben Blaiszik",
        "Rick Stevens",
        "Kyle Chard",
        "Ian Foster"
      ],
      "abstract": "Deep learning methods are transforming research, enabling new techniques, and\nultimately leading to new discoveries. As the demand for more capable AI models\ncontinues to grow, we are now entering an era of Trillion Parameter Models\n(TPM), or models with more than a trillion parameters -- such as Huawei's\nPanGu-$\\Sigma$. We describe a vision for the ecosystem of TPM users and\nproviders that caters to the specific needs of the scientific community. We\nthen outline the significant technical challenges and open problems in system\ndesign for serving TPMs to enable scientific research and discovery.\nSpecifically, we describe the requirements of a comprehensive software stack\nand interfaces to support the diverse and flexible requirements of researchers.",
      "tldr_zh": "这篇论文调查了万亿参数模型（Trillion Parameter Models, TPMs）在科学发现中的服务基础设施，并提出了一个针对科学社区的生态系统愿景，例如华为的PanGu-Σ模型。论文强调，随着AI模型规模的增长，需要应对系统设计中的技术挑战和开放问题，以支持高效的模型服务。作者特别描述了全面软件栈和接口的设计要求，以满足研究者多样化的灵活需求，从而推动AI在科学研究中的应用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 3 figures, accepted for publication in the proceedings of\n  the 10th IEEE/ACM International Conference on Big Data Computing,\n  Applications and Technologies (BDCAT2023)",
      "pdf_url": "http://arxiv.org/pdf/2402.03480v1",
      "published_date": "2024-02-05 19:48:31 UTC",
      "updated_date": "2024-02-05 19:48:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:17:29.545849"
    },
    {
      "arxiv_id": "2402.03479v4",
      "title": "DRED: Zero-Shot Transfer in Reinforcement Learning via Data-Regularised Environment Design",
      "title_zh": "翻译失败",
      "authors": [
        "Samuel Garcin",
        "James Doran",
        "Shangmin Guo",
        "Christopher G. Lucas",
        "Stefano V. Albrecht"
      ],
      "abstract": "Autonomous agents trained using deep reinforcement learning (RL) often lack\nthe ability to successfully generalise to new environments, even when these\nenvironments share characteristics with the ones they have encountered during\ntraining. In this work, we investigate how the sampling of individual\nenvironment instances, or levels, affects the zero-shot generalisation (ZSG)\nability of RL agents. We discover that, for deep actor-critic architectures\nsharing their base layers, prioritising levels according to their value loss\nminimises the mutual information between the agent's internal representation\nand the set of training levels in the generated training data. This provides a\nnovel theoretical justification for the regularisation achieved by certain\nadaptive sampling strategies. We then turn our attention to unsupervised\nenvironment design (UED) methods, which assume control over level generation.\nWe find that existing UED methods can significantly shift the training\ndistribution, which translates to low ZSG performance. To prevent both\noverfitting and distributional shift, we introduce data-regularised environment\ndesign (DRED). DRED generates levels using a generative model trained to\napproximate the ground truth distribution of an initial set of level\nparameters. Through its grounding, DRED achieves significant improvements in\nZSG over adaptive level sampling strategies and UED methods. Our code and\nexperimental data are available at https://github.com/uoe-agents/dred.",
      "tldr_zh": "本研究探讨了强化学习（RL）代理在零-shot transfer（零样本转移）中的泛化挑战，发现通过根据价值损失优先采样环境实例，可以最小化代理内部表示与训练级别的互信息，从而提供理论支持。该文分析了无监督环境设计（UED）方法的局限性，即可能导致训练分布偏移和泛化性能下降。为解决此问题，研究引入了数据-regularised environment design（DRED），该方法使用训练生成模型逼近初始环境参数的真实分布，以防止过拟合和分布偏移。实验结果显示，DRED 在零-shot generalisation（ZSG）性能上显著优于自适应采样策略和现有 UED 方法，并提供了开源代码以供验证。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "To appear in ICML 2024. A preliminary version of this work\n  (arXiv:2310.03494) was presented at the ALOE workshop, NeurIPS 2023. arXiv\n  admin note: text overlap with arXiv:2310.03494",
      "pdf_url": "http://arxiv.org/pdf/2402.03479v4",
      "published_date": "2024-02-05 19:47:45 UTC",
      "updated_date": "2024-06-11 21:25:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:17:42.170740"
    },
    {
      "arxiv_id": "2402.03457v1",
      "title": "Efficient and Interpretable Traffic Destination Prediction using Explainable Boosting Machines",
      "title_zh": "翻译失败",
      "authors": [
        "Yasin Yousif",
        "Jörg Müller"
      ],
      "abstract": "Developing accurate models for traffic trajectory predictions is crucial for\nachieving fully autonomous driving. Various deep neural network models have\nbeen employed to address this challenge, but their black-box nature hinders\ntransparency and debugging capabilities in a deployed system. Glass-box models\noffer a solution by providing full interpretability through methods like\n\\ac{GAM}. In this study, we evaluate an efficient additive model called\n\\ac{EBM} for traffic prediction on three popular mixed traffic datasets:\n\\ac{SDD}, \\ac{InD}, and Argoverse. Our results show that the \\ac{EBM} models\nperform competitively in predicting pedestrian destinations within \\ac{SDD} and\n\\ac{InD} while providing modest predictions for vehicle-dominant Argoverse\ndataset. Additionally, our transparent trained models allow us to analyse\nfeature importance and interactions, as well as provide qualitative examples of\npredictions explanation. The full training code will be made public upon\npublication.",
      "tldr_zh": "该研究针对交通轨迹预测的关键挑战，提出使用 Explainable Boosting Machines (EBM) 这种可解释的加性模型 (Generalized Additive Model, GAM)，以提升自治驾驶系统的透明度和调试能力。实验在 SDD、InD 和 Argoverse 等混合交通数据集上进行，结果显示 EBM 在 SDD 和 InD 数据集上对行人目的地预测表现出色，与基线模型竞争，而在车辆主导的 Argoverse 上表现适中。通过 EBM 的可解释性，研究者分析了特征重要性和交互，并提供了预测解释示例。作者计划公开完整训练代码，以促进进一步应用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.03457v1",
      "published_date": "2024-02-05 19:09:42 UTC",
      "updated_date": "2024-02-05 19:09:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:17:54.127408"
    },
    {
      "arxiv_id": "2402.03435v1",
      "title": "Psychological Assessments with Large Language Models: A Privacy-Focused and Cost-Effective Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Sergi Blanco-Cuaresma"
      ],
      "abstract": "This study explores the use of Large Language Models (LLMs) to analyze text\ncomments from Reddit users, aiming to achieve two primary objectives: firstly,\nto pinpoint critical excerpts that support a predefined psychological\nassessment of suicidal risk; and secondly, to summarize the material to\nsubstantiate the preassigned suicidal risk level. The work is circumscribed to\nthe use of \"open-source\" LLMs that can be run locally, thereby enhancing data\nprivacy. Furthermore, it prioritizes models with low computational\nrequirements, making it accessible to both individuals and institutions\noperating on limited computing budgets. The implemented strategy only relies on\na carefully crafted prompt and a grammar to guide the LLM's text completion.\nDespite its simplicity, the evaluation metrics show outstanding results, making\nit a valuable privacy-focused and cost-effective approach. This work is part of\nthe Computational Linguistics and Clinical Psychology (CLPsych) 2024 shared\ntask.",
      "tldr_zh": "本研究探讨了使用 Large Language Models (LLMs) 分析 Reddit 用户文本评论，以实现心理评估的两大目标：识别支持预定义自杀风险评估的关键片段，并总结材料以证明预先分配的风险水平。该方法仅依赖开源 LLMs，这些模型可在本地运行，从而增强数据隐私，并优先选择计算需求低的版本，适合资源有限的个人和机构。研究通过精心设计的提示和语法引导 LLM 的文本完成，尽管方法简单，评估指标显示出优秀结果，使其成为一种高效的隐私导向和成本有效的心理评估方案。该工作是 Computational Linguistics and Clinical Psychology (CLPsych) 2024 共享任务的一部分。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to the Workshop on Computational Linguistics and Clinical\n  Psychology (CLPsych) at EACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.03435v1",
      "published_date": "2024-02-05 19:00:02 UTC",
      "updated_date": "2024-02-05 19:00:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:18:05.834849"
    },
    {
      "arxiv_id": "2402.03311v1",
      "title": "HASSOD: Hierarchical Adaptive Self-Supervised Object Detection",
      "title_zh": "HASSOD：分层自适应自监督物体检测",
      "authors": [
        "Shengcao Cao",
        "Dhiraj Joshi",
        "Liang-Yan Gui",
        "Yu-Xiong Wang"
      ],
      "abstract": "The human visual perception system demonstrates exceptional capabilities in\nlearning without explicit supervision and understanding the part-to-whole\ncomposition of objects. Drawing inspiration from these two abilities, we\npropose Hierarchical Adaptive Self-Supervised Object Detection (HASSOD), a\nnovel approach that learns to detect objects and understand their compositions\nwithout human supervision. HASSOD employs a hierarchical adaptive clustering\nstrategy to group regions into object masks based on self-supervised visual\nrepresentations, adaptively determining the number of objects per image.\nFurthermore, HASSOD identifies the hierarchical levels of objects in terms of\ncomposition, by analyzing coverage relations between masks and constructing\ntree structures. This additional self-supervised learning task leads to\nimproved detection performance and enhanced interpretability. Lastly, we\nabandon the inefficient multi-round self-training process utilized in prior\nmethods and instead adapt the Mean Teacher framework from semi-supervised\nlearning, which leads to a smoother and more efficient training process.\nThrough extensive experiments on prevalent image datasets, we demonstrate the\nsuperiority of HASSOD over existing methods, thereby advancing the state of the\nart in self-supervised object detection. Notably, we improve Mask AR from 20.2\nto 22.5 on LVIS, and from 17.0 to 26.0 on SA-1B. Project page:\nhttps://HASSOD-NeurIPS23.github.io.",
      "tldr_zh": "本研究提出 HASSOD，一种 Hierarchical Adaptive Self-Supervised Object Detection 方法，受人类视觉感知启发，实现无需人类监督的对象检测和层次组成理解。HASSOD 通过分层自适应聚类策略基于自监督视觉表示将图像区域分组成对象掩码，并分析掩码间的覆盖关系构建树结构，以识别对象的层次关系，从而提升检测性能和可解释性。该方法放弃多轮自训练，转而采用 Mean Teacher 框架，实现更高效的训练过程；在 LVIS 和 SA-1B 数据集上，HASSOD 将 Mask AR 分别从 20.2 提高到 22.5 和从 17.0 提高到 26.0，显著超越现有方法。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "NeurIPS 2023",
      "pdf_url": "http://arxiv.org/pdf/2402.03311v1",
      "published_date": "2024-02-05 18:59:41 UTC",
      "updated_date": "2024-02-05 18:59:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:18:18.332301"
    },
    {
      "arxiv_id": "2402.03310v3",
      "title": "V-IRL: Grounding Virtual Intelligence in Real Life",
      "title_zh": "翻译失败",
      "authors": [
        "Jihan Yang",
        "Runyu Ding",
        "Ellis Brown",
        "Xiaojuan Qi",
        "Saining Xie"
      ],
      "abstract": "There is a sensory gulf between the Earth that humans inhabit and the digital\nrealms in which modern AI agents are created. To develop AI agents that can\nsense, think, and act as flexibly as humans in real-world settings, it is\nimperative to bridge the realism gap between the digital and physical worlds.\nHow can we embody agents in an environment as rich and diverse as the one we\ninhabit, without the constraints imposed by real hardware and control? Towards\nthis end, we introduce V-IRL: a platform that enables agents to scalably\ninteract with the real world in a virtual yet realistic environment. Our\nplatform serves as a playground for developing agents that can accomplish\nvarious practical tasks and as a vast testbed for measuring progress in\ncapabilities spanning perception, decision-making, and interaction with\nreal-world data across the entire globe.",
      "tldr_zh": "该研究指出，AI agents 在数字环境中创建，导致与真实世界的感官差距，无法像人类一样灵活地感知、思考和行动。为桥接这一 realism gap，论文引入了 V-IRL 平台，这是一个虚拟却真实的交互环境，允许代理大规模地与真实世界数据互动，而不受硬件限制。V-IRL 可作为开发实际任务代理的 playground，并提供一个广阔的测试床，用于评估代理在感知、决策和互动能力方面的全球性进步。",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "Project page: https://virl-platform.github.io",
      "pdf_url": "http://arxiv.org/pdf/2402.03310v3",
      "published_date": "2024-02-05 18:59:36 UTC",
      "updated_date": "2024-07-18 08:08:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:18:57.763015"
    },
    {
      "arxiv_id": "2402.03305v2",
      "title": "Do Diffusion Models Learn Semantically Meaningful and Efficient Representations?",
      "title_zh": "扩散模型是否学习了语义上有意义且高效的表示？",
      "authors": [
        "Qiyao Liang",
        "Ziming Liu",
        "Ila Fiete"
      ],
      "abstract": "Diffusion models are capable of impressive feats of image generation with\nuncommon juxtapositions such as astronauts riding horses on the moon with\nproperly placed shadows. These outputs indicate the ability to perform\ncompositional generalization, but how do the models do so? We perform\ncontrolled experiments on conditional DDPMs learning to generate 2D spherical\nGaussian bumps centered at specified $x$- and $y$-positions. Our results show\nthat the emergence of semantically meaningful latent representations is key to\nachieving high performance. En route to successful performance over learning,\nthe model traverses three distinct phases of latent representations: (phase A)\nno latent structure, (phase B) a 2D manifold of disordered states, and (phase\nC) a 2D ordered manifold. Corresponding to each of these phases, we identify\nqualitatively different generation behaviors: 1) multiple bumps are generated,\n2) one bump is generated but at inaccurate $x$ and $y$ locations, 3) a bump is\ngenerated at the correct $x$ and y location. Furthermore, we show that even\nunder imbalanced datasets where features ($x$- versus $y$-positions) are\nrepresented with skewed frequencies, the learning process for $x$ and $y$ is\ncoupled rather than factorized, demonstrating that simple vanilla-flavored\ndiffusion models cannot learn efficient representations in which localization\nin $x$ and $y$ are factorized into separate 1D tasks. These findings suggest\nthe need for future work to find inductive biases that will push generative\nmodels to discover and exploit factorizable independent structures in their\ninputs, which will be required to vault these models into more data-efficient\nregimes.",
      "tldr_zh": "这篇论文探讨了Diffusion Models是否能够学习语义上有意义的和高效的表示，通过控制实验使用条件DDPMs生成2D球形高斯凸起来检验组合泛化能力。研究发现，模型学习过程分为三个阶段：（A）无潜在结构、（B）2D无序流形和（C）2D有序流形，对应的生成行为从生成多个凸起逐步过渡到准确定位x和y位置。结果表明，即使在不平衡数据集下，x和y位置的学习是耦合而非因子化的，这暴露了Diffusion Models在学习高效表示方面的局限性，并呼吁未来工作开发诱导偏差以提升模型的数据效率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "13 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.03305v2",
      "published_date": "2024-02-05 18:58:38 UTC",
      "updated_date": "2024-04-30 14:32:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:19:11.507751"
    },
    {
      "arxiv_id": "2402.03303v1",
      "title": "Nevermind: Instruction Override and Moderation in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Edward Kim"
      ],
      "abstract": "Given the impressive capabilities of recent Large Language Models (LLMs), we\ninvestigate and benchmark the most popular proprietary and different sized open\nsource models on the task of explicit instruction following in conflicting\nsituations, e.g. overrides. These include the ability of the model to override\nthe knowledge within the weights of the model, the ability to override (or\nmoderate) extracted knowledge in the prompt, and lastly the ability to perform\na full jailbreak. Experimentation performed suggest several key findings to\nimprove instruction following - larger models perform the best in following\ninstructions that override internal and contextual instructions, and are\nobedient, even to a fault. When scaling to longer contexts via rope scaling, a\nsignificant buffer needs to be maintained from the edge of the perplexity cliff\nin order to maintain instruction following capabilities. Finally, we observe\nimproving instruction following, and subsequently instruction\noverrides/jailbreaks, is fundamentally at odds with the ability of a language\nmodel to follow given safety filters or guidelines. Thus, we postulate the most\neffective approach for safe, trustworthy AI should be dealt external to the LLM\nitself.",
      "tldr_zh": "这篇论文评估了大型语言模型 (LLMs) 在处理冲突指令时的表现，包括覆盖模型内部知识、提示中的提取知识，以及执行完整越狱 (jailbreak)。通过实验基准测试各种专有和开源模型，研究发现更大模型在指令遵循方面更出色，但可能过于服从，且在扩展上下文时需要保持缓冲以避免性能下降。最终，论文指出，增强指令遵循能力会与模型的安全过滤机制相冲突，因此建议将安全措施置于LLM外部，以实现更可靠的AI系统。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "11 pages",
      "pdf_url": "http://arxiv.org/pdf/2402.03303v1",
      "published_date": "2024-02-05 18:58:19 UTC",
      "updated_date": "2024-02-05 18:58:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:19:23.589796"
    },
    {
      "arxiv_id": "2402.06659v2",
      "title": "Shadowcast: Stealthy Data Poisoning Attacks Against Vision-Language Models",
      "title_zh": "Shadowcast：针对视觉语言模型的隐蔽数据投毒攻击",
      "authors": [
        "Yuancheng Xu",
        "Jiarui Yao",
        "Manli Shu",
        "Yanchao Sun",
        "Zichu Wu",
        "Ning Yu",
        "Tom Goldstein",
        "Furong Huang"
      ],
      "abstract": "Vision-Language Models (VLMs) excel in generating textual responses from\nvisual inputs, but their versatility raises security concerns. This study takes\nthe first step in exposing VLMs' susceptibility to data poisoning attacks that\ncan manipulate responses to innocuous, everyday prompts. We introduce\nShadowcast, a stealthy data poisoning attack where poison samples are visually\nindistinguishable from benign images with matching texts. Shadowcast\ndemonstrates effectiveness in two attack types. The first is a traditional\nLabel Attack, tricking VLMs into misidentifying class labels, such as confusing\nDonald Trump for Joe Biden. The second is a novel Persuasion Attack, leveraging\nVLMs' text generation capabilities to craft persuasive and seemingly rational\nnarratives for misinformation, such as portraying junk food as healthy. We show\nthat Shadowcast effectively achieves the attacker's intentions using as few as\n50 poison samples. Crucially, the poisoned samples demonstrate transferability\nacross different VLM architectures, posing a significant concern in black-box\nsettings. Moreover, Shadowcast remains potent under realistic conditions\ninvolving various text prompts, training data augmentation, and image\ncompression techniques. This work reveals how poisoned VLMs can disseminate\nconvincing yet deceptive misinformation to everyday, benign users, emphasizing\nthe importance of data integrity for responsible VLM deployments. Our code is\navailable at: https://github.com/umd-huang-lab/VLM-Poisoning.",
      "tldr_zh": "该研究揭示了 Vision-Language Models (VLMs) 面对数据毒化攻击的脆弱性，首次提出 Shadowcast 隐秘攻击框架，使毒化样本在视觉上与正常图像无异。Shadowcast 包括传统 Label Attack（例如误将 Donald Trump 识别为 Joe Biden）和创新 Persuasion Attack（利用 VLMs 的文本生成能力创建说服性错误叙述，如将垃圾食品描述为健康）。实验显示，仅需 50 个毒化样本，攻击即可在不同 VLM 架构间转移，并在现实条件下（如文本提示增强和图像压缩）保持有效性，强调了数据完整性对 VLMs 部署的责任性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted by Thirty-Eighth Annual Conference on Neural Information\n  Processing Systems (Neurips 2024)",
      "pdf_url": "http://arxiv.org/pdf/2402.06659v2",
      "published_date": "2024-02-05 18:55:53 UTC",
      "updated_date": "2024-10-14 16:17:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:19:35.229820"
    },
    {
      "arxiv_id": "2402.03300v3",
      "title": "DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zhihong Shao",
        "Peiyi Wang",
        "Qihao Zhu",
        "Runxin Xu",
        "Junxiao Song",
        "Xiao Bi",
        "Haowei Zhang",
        "Mingchuan Zhang",
        "Y. K. Li",
        "Y. Wu",
        "Daya Guo"
      ],
      "abstract": "Mathematical reasoning poses a significant challenge for language models due\nto its complex and structured nature. In this paper, we introduce DeepSeekMath\n7B, which continues pre-training DeepSeek-Coder-Base-v1.5 7B with 120B\nmath-related tokens sourced from Common Crawl, together with natural language\nand code data. DeepSeekMath 7B has achieved an impressive score of 51.7% on the\ncompetition-level MATH benchmark without relying on external toolkits and\nvoting techniques, approaching the performance level of Gemini-Ultra and GPT-4.\nSelf-consistency over 64 samples from DeepSeekMath 7B achieves 60.9% on MATH.\nThe mathematical reasoning capability of DeepSeekMath is attributed to two key\nfactors: First, we harness the significant potential of publicly available web\ndata through a meticulously engineered data selection pipeline. Second, we\nintroduce Group Relative Policy Optimization (GRPO), a variant of Proximal\nPolicy Optimization (PPO), that enhances mathematical reasoning abilities while\nconcurrently optimizing the memory usage of PPO.",
      "tldr_zh": "这篇论文介绍了 DeepSeekMath 7B，一种开源语言模型，通过继续预训练 DeepSeek-Coder-Base-v1.5 7B 并使用 120B 数学相关 tokens（源自 Common Crawl 及自然语言和代码数据），来提升数学推理能力。模型在 competition-level MATH benchmark 上实现了 51.7% 的分数，而无需外部工具或投票技术，性能接近 Gemini-Ultra 和 GPT-4；通过自一致性（self-consistency）在 64 个样本上进一步达到 60.9%。关键因素包括精心设计的数据选择管道，以利用公开网络数据的潜力，以及引入 Group Relative Policy Optimization (GRPO)——一种 Proximal Policy Optimization (PPO) 的变体，用于增强数学推理同时优化内存使用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.03300v3",
      "published_date": "2024-02-05 18:55:32 UTC",
      "updated_date": "2024-04-27 15:25:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:19:48.527049"
    },
    {
      "arxiv_id": "2402.03295v1",
      "title": "Ginger: An Efficient Curvature Approximation with Linear Complexity for General Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Yongchang Hao",
        "Yanshuai Cao",
        "Lili Mou"
      ],
      "abstract": "Second-order optimization approaches like the generalized Gauss-Newton method\nare considered more powerful as they utilize the curvature information of the\nobjective function with preconditioning matrices. Albeit offering tempting\ntheoretical benefits, they are not easily applicable to modern deep learning.\nThe major reason is due to the quadratic memory and cubic time complexity to\ncompute the inverse of the matrix. These requirements are infeasible even with\nstate-of-the-art hardware. In this work, we propose Ginger, an\neigendecomposition for the inverse of the generalized Gauss-Newton matrix. Our\nmethod enjoys efficient linear memory and time complexity for each iteration.\nInstead of approximating the conditioning matrix, we directly maintain its\ninverse to make the approximation more accurate. We provide the convergence\nresult of Ginger for non-convex objectives. Our experiments on different tasks\nwith different model architectures verify the effectiveness of our method. Our\ncode is publicly available.",
      "tldr_zh": "本研究针对二阶优化方法（如generalized Gauss-Newton method）的计算瓶颈，提出了一种高效的曲率近似框架Ginger，以线性复杂度适用于general neural networks。具体来说，Ginger通过对generalized Gauss-Newton矩阵进行eigendecomposition，直接维护其逆矩阵，从而实现每个迭代的线性内存和时间复杂度，并提升近似准确性。该方法为非凸目标提供了收敛证明，并在不同任务和模型架构的实验中验证了其有效性，代码已公开可用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.03295v1",
      "published_date": "2024-02-05 18:51:17 UTC",
      "updated_date": "2024-02-05 18:51:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:19:57.583059"
    },
    {
      "arxiv_id": "2402.03293v2",
      "title": "Flora: Low-Rank Adapters Are Secretly Gradient Compressors",
      "title_zh": "翻译失败",
      "authors": [
        "Yongchang Hao",
        "Yanshuai Cao",
        "Lili Mou"
      ],
      "abstract": "Despite large neural networks demonstrating remarkable abilities to complete\ndifferent tasks, they require excessive memory usage to store the optimization\nstates for training. To alleviate this, the low-rank adaptation (LoRA) is\nproposed to reduce the optimization states by training fewer parameters.\nHowever, LoRA restricts overall weight update matrices to be low-rank, limiting\nthe model performance. In this work, we investigate the dynamics of LoRA and\nidentify that it can be approximated by a random projection. Based on this\nobservation, we propose Flora, which is able to achieve high-rank updates by\nresampling the projection matrices while enjoying the sublinear space\ncomplexity of optimization states. We conduct experiments across different\ntasks and model architectures to verify the effectiveness of our approach.",
      "tldr_zh": "本研究发现，低秩适配器（LoRA）虽然能减少神经网络训练的内存使用，但其限制权重更新矩阵为低秩会影响模型性能。通过分析LoRA的动态，作者将其近似为随机投影，并提出Flora方法，该方法通过重新采样投影矩阵实现高秩更新，同时保持优化状态的子线性空间复杂度。实验结果显示，Flora在不同任务和模型架构上表现出色，验证了其有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted @ ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.03293v2",
      "published_date": "2024-02-05 18:50:39 UTC",
      "updated_date": "2024-06-12 22:17:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:20:10.230695"
    },
    {
      "arxiv_id": "2402.03290v1",
      "title": "InstanceDiffusion: Instance-level Control for Image Generation",
      "title_zh": "InstanceDiffusion：实例级控制用于图像生成",
      "authors": [
        "Xudong Wang",
        "Trevor Darrell",
        "Sai Saketh Rambhatla",
        "Rohit Girdhar",
        "Ishan Misra"
      ],
      "abstract": "Text-to-image diffusion models produce high quality images but do not offer\ncontrol over individual instances in the image. We introduce InstanceDiffusion\nthat adds precise instance-level control to text-to-image diffusion models.\nInstanceDiffusion supports free-form language conditions per instance and\nallows flexible ways to specify instance locations such as simple single\npoints, scribbles, bounding boxes or intricate instance segmentation masks, and\ncombinations thereof. We propose three major changes to text-to-image models\nthat enable precise instance-level control. Our UniFusion block enables\ninstance-level conditions for text-to-image models, the ScaleU block improves\nimage fidelity, and our Multi-instance Sampler improves generations for\nmultiple instances. InstanceDiffusion significantly surpasses specialized\nstate-of-the-art models for each location condition. Notably, on the COCO\ndataset, we outperform previous state-of-the-art by 20.4% AP$_{50}^\\text{box}$\nfor box inputs, and 25.4% IoU for mask inputs.",
      "tldr_zh": "该研究引入了InstanceDiffusion，一种为文本到图像扩散模型添加精确实例级控制的方法，以实现对图像中单个实例的高质量生成。InstanceDiffusion支持每实例的自由形式语言条件，并允许通过单点、涂鸦、边界框或实例分割掩码等灵活方式指定实例位置。论文提出了三个关键改进：UniFusion块用于处理实例级条件、ScaleU块提升图像保真度，以及Multi-instance Sampler优化多实例生成。在COCO数据集上，InstanceDiffusion比现有最先进模型提升20.4% AP$_{50}^\\text{box}$（框输入）和25.4% IoU（掩码输入），显著提高了生成控制的性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Preprint; Project page:\n  https://people.eecs.berkeley.edu/~xdwang/projects/InstDiff/",
      "pdf_url": "http://arxiv.org/pdf/2402.03290v1",
      "published_date": "2024-02-05 18:49:17 UTC",
      "updated_date": "2024-02-05 18:49:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:20:23.102508"
    },
    {
      "arxiv_id": "2402.03289v1",
      "title": "Make Every Move Count: LLM-based High-Quality RTL Code Generation Using MCTS",
      "title_zh": "翻译失败",
      "authors": [
        "Matthew DeLorenzo",
        "Animesh Basak Chowdhury",
        "Vasudev Gohil",
        "Shailja Thakur",
        "Ramesh Karri",
        "Siddharth Garg",
        "Jeyavijayan Rajendran"
      ],
      "abstract": "Existing large language models (LLMs) for register transfer level code\ngeneration face challenges like compilation failures and suboptimal power,\nperformance, and area (PPA) efficiency. This is due to the lack of PPA\nawareness in conventional transformer decoding algorithms. In response, we\npresent an automated transformer decoding algorithm that integrates Monte Carlo\ntree-search for lookahead, guiding the transformer to produce compilable,\nfunctionally correct, and PPA-optimized code. Empirical evaluation with a\nfine-tuned language model on RTL codesets shows that our proposed technique\nconsistently generates functionally correct code compared to prompting-only\nmethods and effectively addresses the PPA-unawareness drawback of naive large\nlanguage models. For the largest design generated by the state-of-the-art LLM\n(16-bit adder), our technique can achieve a 31.8% improvement in the area-delay\nproduct.",
      "tldr_zh": "现有大语言模型 (LLMs) 在生成寄存器传输级别 (RTL) 代码时，常面临编译失败和 suboptimal 的 power, performance, and area (PPA) 效率问题，因为传统的 transformer 解码算法缺乏 PPA 意识。本文提出了一种自动化的 transformer 解码算法，整合 Monte Carlo Tree Search (MCTS) 用于前瞻性指导，从而生成可编译的、功能正确的且 PPA 优化的代码。实验评估显示，与仅使用提示的方法相比，该技术显著提高了代码功能正确性和 PPA 性能，并在最先进的 LLM 生成的 16-bit adder 设计上实现了 31.8% 的 area-delay product 改进。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.AR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.03289v1",
      "published_date": "2024-02-05 18:47:04 UTC",
      "updated_date": "2024-02-05 18:47:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:20:35.657087"
    },
    {
      "arxiv_id": "2402.03286v3",
      "title": "Training-Free Consistent Text-to-Image Generation",
      "title_zh": "无需训练的一致文本到图像生成",
      "authors": [
        "Yoad Tewel",
        "Omri Kaduri",
        "Rinon Gal",
        "Yoni Kasten",
        "Lior Wolf",
        "Gal Chechik",
        "Yuval Atzmon"
      ],
      "abstract": "Text-to-image models offer a new level of creative flexibility by allowing\nusers to guide the image generation process through natural language. However,\nusing these models to consistently portray the same subject across diverse\nprompts remains challenging. Existing approaches fine-tune the model to teach\nit new words that describe specific user-provided subjects or add image\nconditioning to the model. These methods require lengthy per-subject\noptimization or large-scale pre-training. Moreover, they struggle to align\ngenerated images with text prompts and face difficulties in portraying multiple\nsubjects. Here, we present ConsiStory, a training-free approach that enables\nconsistent subject generation by sharing the internal activations of the\npretrained model. We introduce a subject-driven shared attention block and\ncorrespondence-based feature injection to promote subject consistency between\nimages. Additionally, we develop strategies to encourage layout diversity while\nmaintaining subject consistency. We compare ConsiStory to a range of baselines,\nand demonstrate state-of-the-art performance on subject consistency and text\nalignment, without requiring a single optimization step. Finally, ConsiStory\ncan naturally extend to multi-subject scenarios, and even enable training-free\npersonalization for common objects.",
      "tldr_zh": "本文提出 ConsiStory，一种无需训练的文本到图像生成方法，通过共享预训练模型的内部激活来实现同一主题在不同提示下的一致性。关键技术包括 subject-driven shared attention block 和 correspondence-based feature injection，以促进图像间主题一致性，同时鼓励布局多样性。实验结果显示，ConsiStory 在主题一致性和文本对齐上达到 state-of-the-art 水平，并能自然扩展到多主题场景和训练-free 个性化应用。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to journal track of SIGGRAPH 2024 (TOG). Project page is at\n  https://consistory-paper.github.io",
      "pdf_url": "http://arxiv.org/pdf/2402.03286v3",
      "published_date": "2024-02-05 18:42:34 UTC",
      "updated_date": "2024-05-30 11:42:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:20:47.615735"
    },
    {
      "arxiv_id": "2402.03284v1",
      "title": "Deal, or no deal (or who knows)? Forecasting Uncertainty in Conversations using Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Anthony Sicilia",
        "Hyunwoo Kim",
        "Khyathi Raghavi Chandu",
        "Malihe Alikhani",
        "Jack Hessel"
      ],
      "abstract": "Effective interlocutors account for the uncertain goals, beliefs, and\nemotions of others. But even the best human conversationalist cannot perfectly\nanticipate the trajectory of a dialogue. How well can language models represent\ninherent uncertainty in conversations? We propose FortUne Dial, an expansion of\nthe long-standing \"conversation forecasting\" task: instead of just accuracy,\nevaluation is conducted with uncertainty-aware metrics, effectively enabling\nabstention on individual instances. We study two ways in which language models\npotentially represent outcome uncertainty (internally, using scores and\ndirectly, using tokens) and propose fine-tuning strategies to improve\ncalibration of both representations. Experiments on eight difficult negotiation\ncorpora demonstrate that our proposed fine-tuning strategies (a traditional\nsupervision strategy and an off-policy reinforcement learning strategy) can\ncalibrate smaller open-source models to compete with pre-trained models 10x\ntheir size.",
      "tldr_zh": "本研究探讨了Large Language Models在对话预测中如何表示和处理不确定性（如目标、信念和情绪），并引入FortUne Dial任务作为“对话预测”的扩展，使用不确定性感知指标来评估模型的准确性和弃权能力。研究者提出两种微调策略，包括传统监督学习和off-policy reinforcement learning，以改善模型内部分数和标记表示的校准。实验结果显示，在八个谈判语料库上，这些策略使较小的开源模型在性能上与规模大十倍的预训练模型相媲美。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "2 Figures; 7 Tables; 27 pages",
      "pdf_url": "http://arxiv.org/pdf/2402.03284v1",
      "published_date": "2024-02-05 18:39:47 UTC",
      "updated_date": "2024-02-05 18:39:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:20:58.794688"
    },
    {
      "arxiv_id": "2402.03282v3",
      "title": "A Theoretical Framework for Partially Observed Reward-States in RLHF",
      "title_zh": "翻译失败",
      "authors": [
        "Chinmaya Kausik",
        "Mirco Mutti",
        "Aldo Pacchiano",
        "Ambuj Tewari"
      ],
      "abstract": "The growing deployment of reinforcement learning from human feedback (RLHF)\ncalls for a deeper theoretical investigation of its underlying models. The\nprevalent models of RLHF do not account for neuroscience-backed,\npartially-observed \"internal states\" that can affect human feedback, nor do\nthey accommodate intermediate feedback during an interaction. Both of these can\nbe instrumental in speeding up learning and improving alignment. To address\nthese limitations, we model RLHF as reinforcement learning with partially\nobserved reward-states (PORRL). We accommodate two kinds of feedback $-$\ncardinal and dueling feedback. We first demonstrate that PORRL subsumes a wide\nclass of RL problems, including traditional RL, RLHF, and reward machines. For\ncardinal feedback, we present two model-based methods (POR-UCRL, POR-UCBVI). We\ngive both cardinal regret and sample complexity guarantees for the methods,\nshowing that they improve over naive history-summarization. We then discuss the\nbenefits of a model-free method like GOLF with naive history-summarization in\nsettings with recursive internal states and dense intermediate feedback. For\nthis purpose, we define a new history aware version of the Bellman-eluder\ndimension and give a new guarantee for GOLF in our setting, which can be\nexponentially sharper in illustrative examples. For dueling feedback, we show\nthat a naive reduction to cardinal feedback fails to achieve sublinear dueling\nregret. We then present the first explicit reduction that converts guarantees\nfor cardinal regret to dueling regret. In both feedback settings, we show that\nour models and guarantees generalize and extend existing ones.",
      "tldr_zh": "这篇论文提出了一种理论框架PORRL（Partially Observed Reward-States in RLHF），用于强化学习从人类反馈（RLHF）中处理部分观察的内部状态和中间反馈，从而提升学习效率和对齐度。该框架涵盖了传统RL、RLHF和奖励机器等场景，对于cardinal feedback，引入了基于模型的方法POR-UCRL和POR-UCBVI，并证明了它们在regret和sample complexity上的改进，优于简单的历史总结。对于dueling feedback，论文展示了直接归约的不足，并首次提供了一个显式归约，将cardinal regret保证转换为dueling regret。总体上，这些方法和理论保证扩展了现有RLHF模型，为更精确的反馈处理奠定了基础。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "64 pages. 14 pages for main paper, 50 pages for references + appendix",
      "pdf_url": "http://arxiv.org/pdf/2402.03282v3",
      "published_date": "2024-02-05 18:38:55 UTC",
      "updated_date": "2024-11-09 07:09:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:21:14.105719"
    },
    {
      "arxiv_id": "2402.03271v3",
      "title": "Uncertainty of Thoughts: Uncertainty-Aware Planning Enhances Information Seeking in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zhiyuan Hu",
        "Chumin Liu",
        "Xidong Feng",
        "Yilun Zhao",
        "See-Kiong Ng",
        "Anh Tuan Luu",
        "Junxian He",
        "Pang Wei Koh",
        "Bryan Hooi"
      ],
      "abstract": "In the face of uncertainty, the ability to *seek information* is of\nfundamental importance. In many practical applications, such as medical\ndiagnosis and troubleshooting, the information needed to solve the task is not\ninitially given and has to be actively sought by asking follow-up questions\n(for example, a doctor asking a patient for more details about their symptoms).\nIn this work, we introduce Uncertainty of Thoughts (UoT), an algorithm to\naugment large language models with the ability to actively seek information by\nasking effective questions. UoT combines 1) an *uncertainty-aware simulation\napproach* which enables the model to simulate possible future scenarios and how\nlikely they are to occur, 2) *uncertainty-based rewards* motivated by\ninformation gain which incentivizes the model to seek information, and 3) a\n*reward propagation scheme* to select the optimal question to ask in a way that\nmaximizes the expected reward. In experiments on medical diagnosis,\ntroubleshooting, and the `20 Questions` game, UoT achieves an average\nperformance improvement of 38.1% in the rate of successful task completion\nacross multiple LLMs compared with direct prompting and also improves\nefficiency (i.e., the number of questions needed to complete the task). Our\ncode has been released [here](https://github.com/zhiyuanhubj/UoT)",
      "tldr_zh": "本文提出Uncertainty of Thoughts (UoT)，一种算法，用于增强大型语言模型(LLMs)在不确定性情境下主动寻求信息的能力，例如通过问问题获取更多细节。UoT 结合了uncertainty-aware simulation approach（不确定性感知模拟）、uncertainty-based rewards（基于信息增益的奖励）和reward propagation scheme（奖励传播机制），以模拟未来场景、激励有效信息获取并选择最优问题。在医疗诊断、故障排除和“20 Questions”游戏的实验中，UoT 使多种LLMs的任务完成率平均提高38.1%，并显著提升了效率（减少问题数量）。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.03271v3",
      "published_date": "2024-02-05 18:28:44 UTC",
      "updated_date": "2024-11-13 17:10:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:21:24.912892"
    },
    {
      "arxiv_id": "2402.03268v3",
      "title": "Understanding Reasoning Ability of Language Models From the Perspective of Reasoning Paths Aggregation",
      "title_zh": "从推理路径聚合的视角理解语言模型的推理能力",
      "authors": [
        "Xinyi Wang",
        "Alfonso Amayuelas",
        "Kexun Zhang",
        "Liangming Pan",
        "Wenhu Chen",
        "William Yang Wang"
      ],
      "abstract": "Pre-trained language models (LMs) are able to perform complex reasoning\nwithout explicit fine-tuning. To understand how pre-training with a next-token\nprediction objective contributes to the emergence of such reasoning capability,\nwe propose that we can view an LM as deriving new conclusions by aggregating\nindirect reasoning paths seen at pre-training time. We found this perspective\neffective in two important cases of reasoning: logic reasoning with knowledge\ngraphs (KGs) and chain-of-thought (CoT) reasoning. More specifically, we\nformalize the reasoning paths as random walk paths on the knowledge/reasoning\ngraphs. Analyses of learned LM distributions suggest that a weighted sum of\nrelevant random walk path probabilities is a reasonable way to explain how LMs\nreason. Experiments and analysis on multiple KG and CoT datasets reveal the\neffect of training on random walk paths and suggest that augmenting unlabeled\nrandom walk reasoning paths can improve real-world multi-step reasoning\nperformance. code: https://github.com/WANGXinyiLinda/LM_random_walk",
      "tldr_zh": "本论文从推理路径聚合的视角探讨了预训练语言模型（LMs）的推理能力，提出 LMs 通过聚合预训练时看到的间接推理路径来实现复杂推理。研究将推理路径形式化为知识图谱（KGs）和推理图上的随机游走路径，并通过分析 LM 分布发现，相关路径概率的加权和可以解释模型的推理机制。在多个 KG 和 Chain-of-Thought (CoT) 数据集上的实验表明，训练中的随机游走路径对多步推理性能有显著影响，并证明增强这些路径可以提升实际推理效果。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.03268v3",
      "published_date": "2024-02-05 18:25:51 UTC",
      "updated_date": "2024-06-20 18:46:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:21:35.638304"
    },
    {
      "arxiv_id": "2402.03251v1",
      "title": "CLIP Can Understand Depth",
      "title_zh": "CLIP 可以理解深度",
      "authors": [
        "Dunam Kim",
        "Seokju Lee"
      ],
      "abstract": "Recent studies on generalizing CLIP for monocular depth estimation reveal\nthat CLIP pre-trained on web-crawled data is inefficient for deriving proper\nsimilarities between image patches and depth-related prompts. In this paper, we\nadapt CLIP for meaningful quality of monocular depth estimation with dense\nprediction, without fine-tuning its original vision-language alignment. By\njointly training a compact deconvolutional decoder with a tiny learnable\nembedding matrix named mirror, as a static prompt for its text encoder, CLIP is\nenabled to understand depth. With this approach, our model exhibits impressive\nperformance matching several previous state-of-the-art vision-only models on\nthe NYU Depth v2 and KITTI datasets, outperforming every CLIP-based depth\nestimation model with a large margin. Experiments on temporal depth consistency\nand spatial continuity demonstrate that the prior knowledge of CLIP can be\neffectively refined by our proposed framework. Furthermore, an ablation study\non mirror proves that the resulting model estimates depth utilizing knowledge\nnot only from the image encoder but also text encoder despite not being given\nany prompt written in a human way. This research demonstrates that through\nminimal adjustments, the prior knowledge of vision-language foundation models,\nsuch as CLIP, can be generalized even to domains where learning during\npretraining is challenging. We facilitate future works focused on methods to\nadjust suboptimal prior knowledge of vision-language models using non-human\nlanguage prompts, achieving performance on par with task-specific\nstate-of-the-art methodologies.",
      "tldr_zh": "本文研究了如何使预训练模型 CLIP 用于单目深度估计（monocular depth estimation），通过引入一个紧凑的去卷积解码器（deconvolutional decoder）和一个微小的可学习嵌入矩阵（mirror）作为文本编码器的静态提示，而不需微调 CLIP 的原始视觉-语言对齐。实验结果显示，该模型在 NYU Depth v2 和 KITTI 数据集上表现与多项最先进视觉-only 模型相当，并大幅优于其他 CLIP-based 方法。进一步的消融研究和一致性测试证明，CLIP 的先验知识能有效提炼，利用图像编码器和文本编码器的结合，即使没有人类语言提示，也能实现高性能深度估计。该工作展示了通过最小调整，将视觉-语言基础模型泛化到深度估计等挑战性领域的潜力，为未来优化此类模型提供新方向。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.03251v1",
      "published_date": "2024-02-05 18:09:33 UTC",
      "updated_date": "2024-02-05 18:09:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:21:48.833461"
    },
    {
      "arxiv_id": "2402.03247v3",
      "title": "HEANA: A Hybrid Time-Amplitude Analog Optical Accelerator with Flexible Dataflows for Energy-Efficient CNN Inference",
      "title_zh": "翻译失败",
      "authors": [
        "Sairam Sri Vatsavai",
        "Venkata Sai Praneeth Karempudi",
        "Ishan Thakkar"
      ],
      "abstract": "Several photonic microring resonators (MRRs) based analog accelerators have\nbeen proposed to accelerate the inference of integer-quantized CNNs with\nremarkably higher throughput and energy efficiency compared to their electronic\ncounterparts. However, the existing analog photonic accelerators suffer from\nthree shortcomings: (i) severe hampering of wavelength parallelism due to\nvarious crosstalk effects, (ii) inflexibility of supporting various dataflows\nother than the weight-stationary dataflow, and (iii) failure in fully\nleveraging the ability of photodetectors to perform in-situ accumulations.\nThese shortcomings collectively hamper the performance and energy efficiency of\nprior accelerators. To tackle these shortcomings, we present a novel Hybrid\ntimE Amplitude aNalog optical Accelerator, called HEANA. HEANA employs hybrid\ntime-amplitude analog optical multipliers (TAOMs) that increase the flexibility\nof HEANA to support multiple dataflows. A spectrally hitless arrangement of\nTAOMs significantly reduces the crosstalk effects, thereby increasing the\nwavelength parallelism in HEANA. Moreover, HEANA employs our invented balanced\nphoto-charge accumulators (BPCAs) that enable buffer-less, in-situ, temporal\naccumulations to eliminate the need to use reduction networks in HEANA,\nrelieving it from related latency and energy overheads. Our evaluation for the\ninference of four modern CNNs indicates that HEANA provides improvements of\natleast 66x and 84x in frames-per-second (FPS) and FPS/W (energy-efficiency),\nrespectively, for equal-area comparisons, on gmean over two MRR-based analog\nCNN accelerators from prior work.",
      "tldr_zh": "本研究提出了一种混合时-幅度模拟光学加速器HEANA，旨在解决现有基于光子微环谐振器(MRRs)的模拟加速器在串扰影响、数据流灵活性和光探测器原位积累利用方面的三大缺点。HEANA采用混合时-幅度模拟光学乘法器(TAOMs)来支持多种数据流，并通过无光谱影响的TAOMs排列显著减少串扰，提高波长并行性。同时，引入平衡光电荷积累器(BPCAs)实现无缓冲原位时间积累，消除减少网络的延迟和能量开销。实验评估显示，对于四个现代CNNs的推理，HEANA在相同面积下比现有加速器平均提高66倍的帧率(FPS)和84倍的能量效率(FPS/W)。",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "cs.AR",
      "comment": "The paper is accepted at ACM TODAES",
      "pdf_url": "http://arxiv.org/pdf/2402.03247v3",
      "published_date": "2024-02-05 18:05:34 UTC",
      "updated_date": "2024-12-15 19:36:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:22:00.313755"
    },
    {
      "arxiv_id": "2402.03246v6",
      "title": "SGS-SLAM: Semantic Gaussian Splatting For Neural Dense SLAM",
      "title_zh": "翻译失败",
      "authors": [
        "Mingrui Li",
        "Shuhong Liu",
        "Heng Zhou",
        "Guohao Zhu",
        "Na Cheng",
        "Tianchen Deng",
        "Hongyu Wang"
      ],
      "abstract": "We present SGS-SLAM, the first semantic visual SLAM system based on Gaussian\nSplatting. It incorporates appearance, geometry, and semantic features through\nmulti-channel optimization, addressing the oversmoothing limitations of neural\nimplicit SLAM systems in high-quality rendering, scene understanding, and\nobject-level geometry. We introduce a unique semantic feature loss that\neffectively compensates for the shortcomings of traditional depth and color\nlosses in object optimization. Through a semantic-guided keyframe selection\nstrategy, we prevent erroneous reconstructions caused by cumulative errors.\nExtensive experiments demonstrate that SGS-SLAM delivers state-of-the-art\nperformance in camera pose estimation, map reconstruction, precise semantic\nsegmentation, and object-level geometric accuracy, while ensuring real-time\nrendering capabilities.",
      "tldr_zh": "该研究提出了 SGS-SLAM，一种基于 Gaussian Splatting 的语义视觉 SLAM 系统，通过多通道优化整合外观、几何和语义特征，解决了神经隐式 SLAM 在高品质渲染、场景理解和对象级几何方面的过度平滑问题。系统引入了语义特征 loss 来弥补传统深度和颜色 loss 的不足，并采用语义引导的关键帧选择策略，以防止累积错误导致的重建错误。实验结果显示，SGS-SLAM 在相机位姿估计、地图重建、精确语义分割和对象级几何精度上达到了最先进水平，同时支持实时渲染。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.03246v6",
      "published_date": "2024-02-05 18:03:53 UTC",
      "updated_date": "2024-11-24 09:56:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:22:11.584438"
    },
    {
      "arxiv_id": "2402.05967v7",
      "title": "The last Dance : Robust backdoor attack via diffusion models and bayesian approach",
      "title_zh": "The last Dance：通过扩散模型和贝叶斯",
      "authors": [
        "Orson Mengara"
      ],
      "abstract": "Diffusion models are state-of-the-art deep learning generative models that\nare trained on the principle of learning forward and backward diffusion\nprocesses via the progressive addition of noise and denoising. In this paper,\nwe aim to fool audio-based DNN models, such as those from the Hugging Face\nframework, primarily those that focus on audio, in particular transformer-based\nartificial intelligence models, which are powerful machine learning models that\nsave time and achieve results faster and more efficiently. We demonstrate the\nfeasibility of backdoor attacks (called `BacKBayDiffMod`) on audio transformers\nderived from Hugging Face, a popular framework in the world of artificial\nintelligence research. The backdoor attack developed in this paper is based on\npoisoning model training data uniquely by incorporating backdoor diffusion\nsampling and a Bayesian approach to the distribution of poisoned data.",
      "tldr_zh": "该论文提出了一种鲁棒的后门攻击方法，名为“The last Dance”，利用diffusion models和Bayesian approach针对音频-based DNN模型进行攻击。攻击通过毒化训练数据，结合后门扩散采样和贝叶斯方法，专注于Hugging Face框架下的音频transformer模型，以实现高效的模型欺骗。实验证明，这种方法在音频transformer上可行，展示了潜在的安全风险，并为提升AI模型的防御机制提供了新见解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "Preprint (Last update, will never be modified again( correction of a\n  sketch)): audio backdoor attack on Hugging Face's Transformer pre-trained\n  models. This attack incorporates state-of-the-art Bayesian techniques, a\n  modified Fokker-Planck equation (via Yang-Mills), and a diffusion model\n  approach",
      "pdf_url": "http://arxiv.org/pdf/2402.05967v7",
      "published_date": "2024-02-05 18:00:07 UTC",
      "updated_date": "2025-04-20 19:42:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:22:22.255649"
    },
    {
      "arxiv_id": "2402.03227v4",
      "title": "IGUANe: a 3D generalizable CycleGAN for multicenter harmonization of brain MR images",
      "title_zh": "翻译失败",
      "authors": [
        "Vincent Roca",
        "Grégory Kuchcinski",
        "Jean-Pierre Pruvo",
        "Dorian Manouvriez",
        "Renaud Lopes"
      ],
      "abstract": "In MRI studies, the aggregation of imaging data from multiple acquisition\nsites enhances sample size but may introduce site-related variabilities that\nhinder consistency in subsequent analyses. Deep learning methods for image\ntranslation have emerged as a solution for harmonizing MR images across sites.\nIn this study, we introduce IGUANe (Image Generation with Unified Adversarial\nNetworks), an original 3D model that leverages the strengths of domain\ntranslation and straightforward application of style transfer methods for\nmulticenter brain MR image harmonization. IGUANe extends CycleGAN by\nintegrating an arbitrary number of domains for training through a many-to-one\narchitecture. The framework based on domain pairs enables the implementation of\nsampling strategies that prevent confusion between site-related and biological\nvariabilities. During inference, the model can be applied to any image, even\nfrom an unknown acquisition site, making it a universal generator for\nharmonization. Trained on a dataset comprising T1-weighted images from 11\ndifferent scanners, IGUANe was evaluated on data from unseen sites. The\nassessments included the transformation of MR images with traveling subjects,\nthe preservation of pairwise distances between MR images within domains, the\nevolution of volumetric patterns related to age and Alzheimer$'$s disease (AD),\nand the performance in age regression and patient classification tasks.\nComparisons with other harmonization and normalization methods suggest that\nIGUANe better preserves individual information in MR images and is more\nsuitable for maintaining and reinforcing variabilities related to age and AD.\nFuture studies may further assess IGUANe in other multicenter contexts, either\nusing the same model or retraining it for applications to different image\nmodalities. IGUANe is available at\nhttps://github.com/RocaVincent/iguane_harmonization.git.",
      "tldr_zh": "该研究提出 IGUANe，一种 3D 通用 CycleGAN 模型，用于多中心脑部 MR 图像协调，以解决数据聚合带来的站点相关变异性问题。IGUANe 扩展了 CycleGAN 的 many-to-one 架构，支持任意数量域的训练，并通过采样策略区分站点变异和生物变异，确保在推理时适用于未知站点图像。实验在 11 个扫描仪的 T1-weighted 图像数据集上进行，结果显示 IGUANe 比其他协调方法更好地保留个体信息，并在年龄回归和 Alzheimer’s disease (AD) 分类任务中维持相关变异性，提供了一个通用的协调框架，并已在 GitHub 上开源。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "29 pages, 14 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.03227v4",
      "published_date": "2024-02-05 17:38:49 UTC",
      "updated_date": "2024-11-14 14:11:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:22:36.595848"
    },
    {
      "arxiv_id": "2402.03216v4",
      "title": "BGE M3-Embedding: Multi-Lingual, Multi-Functionality, Multi-Granularity Text Embeddings Through Self-Knowledge Distillation",
      "title_zh": "翻译失败",
      "authors": [
        "Jianlv Chen",
        "Shitao Xiao",
        "Peitian Zhang",
        "Kun Luo",
        "Defu Lian",
        "Zheng Liu"
      ],
      "abstract": "In this paper, we present a new embedding model, called M3-Embedding, which\nis distinguished for its versatility in Multi-Linguality, Multi-Functionality,\nand Multi-Granularity. It can support more than 100 working languages, leading\nto new state-of-the-art performances on multi-lingual and cross-lingual\nretrieval tasks. It can simultaneously perform the three common retrieval\nfunctionalities of embedding model: dense retrieval, multi-vector retrieval,\nand sparse retrieval, which provides a unified model foundation for real-world\nIR applications. It is able to process inputs of different granularities,\nspanning from short sentences to long documents of up to 8192 tokens. The\neffective training of M3-Embedding involves the following technical\ncontributions. We propose a novel self-knowledge distillation approach, where\nthe relevance scores from different retrieval functionalities can be integrated\nas the teacher signal to enhance the training quality. We also optimize the\nbatching strategy, enabling a large batch size and high training throughput to\nensure the discriminativeness of embeddings. To the best of our knowledge,\nM3-Embedding is the first embedding model which realizes such a strong\nversatility. The model and code will be publicly available at\nhttps://github.com/FlagOpen/FlagEmbedding.",
      "tldr_zh": "本研究引入了 BGE M3-Embedding 模型，该模型在 Multi-Linguality、多语言支持方面实现超过 100 种语言，并在多语言和跨语言检索任务上达到新状态-of-the-art 性能。M3-Embedding 同时支持 Multi-Functionality，包括 dense retrieval、multi-vector retrieval 和 sparse retrieval 等功能，提供统一的模型基础适用于实际信息检索应用；此外，它还能处理 Multi-Granularity 输入，从短句到长达 8192 tokens 的文档。训练过程中，作者提出了一种自知识 distillation 方法，将不同检索功能的相关性分数整合作为教师信号，以提升训练质量，并优化批处理策略实现大批量和高吞吐量，确保嵌入的区分性。作为首个实现这种多功能性的嵌入模型，M3-Embedding 的代码已在 GitHub 上公开。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.03216v4",
      "published_date": "2024-02-05 17:26:49 UTC",
      "updated_date": "2024-06-28 09:55:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:22:47.517832"
    },
    {
      "arxiv_id": "2402.03214v3",
      "title": "Organic or Diffused: Can We Distinguish Human Art from AI-generated Images?",
      "title_zh": "翻译失败",
      "authors": [
        "Anna Yoo Jeong Ha",
        "Josephine Passananti",
        "Ronik Bhaskar",
        "Shawn Shan",
        "Reid Southen",
        "Haitao Zheng",
        "Ben Y. Zhao"
      ],
      "abstract": "The advent of generative AI images has completely disrupted the art world.\nDistinguishing AI generated images from human art is a challenging problem\nwhose impact is growing over time. A failure to address this problem allows bad\nactors to defraud individuals paying a premium for human art and companies\nwhose stated policies forbid AI imagery. It is also critical for content owners\nto establish copyright, and for model trainers interested in curating training\ndata in order to avoid potential model collapse.\n  There are several different approaches to distinguishing human art from AI\nimages, including classifiers trained by supervised learning, research tools\ntargeting diffusion models, and identification by professional artists using\ntheir knowledge of artistic techniques. In this paper, we seek to understand\nhow well these approaches can perform against today's modern generative models\nin both benign and adversarial settings. We curate real human art across 7\nstyles, generate matching images from 5 generative models, and apply 8\ndetectors (5 automated detectors and 3 different human groups including 180\ncrowdworkers, 4000+ professional artists, and 13 expert artists experienced at\ndetecting AI). Both Hive and expert artists do very well, but make mistakes in\ndifferent ways (Hive is weaker against adversarial perturbations while Expert\nartists produce higher false positives). We believe these weaknesses will\nremain as models continue to evolve, and use our data to demonstrate why a\ncombined team of human and automated detectors provides the best combination of\naccuracy and robustness.",
      "tldr_zh": "本研究探讨了区分人类艺术和 AI 生成图像的可行性及其重要性，以防范诈骗、维护版权并避免模型崩溃。研究者汇集了7种艺术风格的真实人类艺术，并使用5个生成模型生成匹配图像，然后评估了8个检测器（包括5个自动化检测器和3组人类检测器：180名众包工人、4000+名专业艺术家以及13名专家艺术家）。结果显示，Hive和专家艺术家检测表现突出，但存在不同弱点：Hive对对抗性扰动(adversarial perturbations)更脆弱，而专家艺术家有更高假阳性(false positives)率。研究认为，这些局限性将随着模型演进而持续，建议采用人类与自动化检测器的结合策略，以实现最佳的准确性和鲁棒性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.03214v3",
      "published_date": "2024-02-05 17:25:04 UTC",
      "updated_date": "2024-07-02 20:22:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:23:00.724955"
    },
    {
      "arxiv_id": "2402.03204v1",
      "title": "Multi-agent Reinforcement Learning for Energy Saving in Multi-Cell Massive MIMO Systems",
      "title_zh": "多智能体强化学习用于多小区大规模MIMO系统的节能",
      "authors": [
        "Tianzhang Cai",
        "Qichen Wang",
        "Shuai Zhang",
        "Özlem Tuğfe Demir",
        "Cicek Cavdar"
      ],
      "abstract": "We develop a multi-agent reinforcement learning (MARL) algorithm to minimize\nthe total energy consumption of multiple massive MIMO (multiple-input\nmultiple-output) base stations (BSs) in a multi-cell network while preserving\nthe overall quality-of-service (QoS) by making decisions on the multi-level\nadvanced sleep modes (ASMs) and antenna switching of these BSs. The problem is\nmodeled as a decentralized partially observable Markov decision process\n(DEC-POMDP) to enable collaboration between individual BSs, which is necessary\nto tackle inter-cell interference. A multi-agent proximal policy optimization\n(MAPPO) algorithm is designed to learn a collaborative BS control policy. To\nenhance its scalability, a modified version called MAPPO-neighbor policy is\nfurther proposed. Simulation results demonstrate that the trained MAPPO agent\nachieves better performance compared to baseline policies. Specifically,\ncompared to the auto sleep mode 1 (symbol-level sleeping) algorithm, the\nMAPPO-neighbor policy reduces power consumption by approximately 8.7% during\nlow-traffic hours and improves energy efficiency by approximately 19% during\nhigh-traffic hours, respectively.",
      "tldr_zh": "本研究开发了多智能体强化学习 (MARL) 算法，用于最小化多小区大规模 MIMO 系统中的基站总体能耗，同时通过多级高级睡眠模式 (ASMs) 和天线切换决策来维持服务质量 (QoS)。\n问题被建模为去中心化部分可观测 Markov 决策过程 (DEC-POMDP)，以实现基站间的协作并处理小区间干扰，并设计了多智能体近端策略优化 (MAPPO) 算法及其改进版 MAPPO-neighbor，以提升可扩展性。\n模拟结果表明，MAPPO-neighbor 策略相较基线算法，在低流量时段减少能耗约 8.7%，在高流量时段提高能效约 19%。",
      "categories": [
        "cs.IT",
        "cs.AI",
        "cs.LG",
        "math.IT"
      ],
      "primary_category": "cs.IT",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.03204v1",
      "published_date": "2024-02-05 17:15:00 UTC",
      "updated_date": "2024-02-05 17:15:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:23:15.549723"
    },
    {
      "arxiv_id": "2402.05966v4",
      "title": "Vanishing Feature: Diagnosing Model Merging and Beyond",
      "title_zh": "翻译失败",
      "authors": [
        "Xingyu Qu",
        "Samuel Horvath"
      ],
      "abstract": "Model merging offers an efficient way to combine pre-trained neural networks\nbut often suffers from inconsistent performance, especially when merging models\nwith different initializations. We identify the ``vanishing feature''\nphenomenon, where input-induced features diminish during propagation through\nthe merged model, degrading performance. Through theoretical and empirical\nanalysis, we reveal that this phenomenon underpins challenges like variance\ncollapse and explains techniques like permutation-based merging, post-merging\nnormalization, etc. We show that existing normalization strategies can be\nenhanced by precisely targeting the vanishing feature issue. Leveraging these\ninsights, we propose the ``Preserve-First Merging'' (PFM) strategy, which\nfocuses on preserving early-layer features, enabling the merged models, for the\nfirst time, to outperform the original models in advanced settings without\npost-training. Furthermore, we demonstrate that the vanishing feature\nphenomenon extends to other contexts, such as model pruning. Applying\npost-pruning normalization to mitigate the issue significantly improves\none-shot pruning performance at high sparsity, offering a simple and effective\npost-pruning solution. The code is available at https://github.com/XingyuQu/VF.",
      "tldr_zh": "这篇论文诊断了模型合并（model merging）中的“vanishing feature”现象，即输入诱导的特征在传播过程中减弱，导致性能下降，并通过理论和实证分析揭示了其与方差崩溃（variance collapse）等挑战的关联。作者提出“Preserve-First Merging (PFM)”策略，专注于保留早期层特征，使合并模型在高级设置中首次无需后训练就优于原模型。进一步，他们扩展这一现象到模型剪枝（model pruning）领域，发现应用后剪枝归一化能显著改善高稀疏度下的单次剪枝性能，提供了一个简单有效的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "36 pages, published as a conference paper (Oral) at the Second\n  Conference on Parsimony and Learning (CPAL 2025)",
      "pdf_url": "http://arxiv.org/pdf/2402.05966v4",
      "published_date": "2024-02-05 17:06:26 UTC",
      "updated_date": "2025-02-26 20:48:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:23:27.655596"
    },
    {
      "arxiv_id": "2402.03190v4",
      "title": "Unified Hallucination Detection for Multimodal Large Language Models",
      "title_zh": "多模态大型语言模型的统一幻觉检测",
      "authors": [
        "Xiang Chen",
        "Chenxi Wang",
        "Yida Xue",
        "Ningyu Zhang",
        "Xiaoyan Yang",
        "Qiang Li",
        "Yue Shen",
        "Lei Liang",
        "Jinjie Gu",
        "Huajun Chen"
      ],
      "abstract": "Despite significant strides in multimodal tasks, Multimodal Large Language\nModels (MLLMs) are plagued by the critical issue of hallucination. The reliable\ndetection of such hallucinations in MLLMs has, therefore, become a vital aspect\nof model evaluation and the safeguarding of practical application deployment.\nPrior research in this domain has been constrained by a narrow focus on\nsingular tasks, an inadequate range of hallucination categories addressed, and\na lack of detailed granularity. In response to these challenges, our work\nexpands the investigative horizons of hallucination detection. We present a\nnovel meta-evaluation benchmark, MHaluBench, meticulously crafted to facilitate\nthe evaluation of advancements in hallucination detection methods.\nAdditionally, we unveil a novel unified multimodal hallucination detection\nframework, UNIHD, which leverages a suite of auxiliary tools to validate the\noccurrence of hallucinations robustly. We demonstrate the effectiveness of\nUNIHD through meticulous evaluation and comprehensive analysis. We also provide\nstrategic insights on the application of specific tools for addressing various\ncategories of hallucinations.",
      "tldr_zh": "尽管多模态大语言模型（MLLMs）在任务中取得显著进展，但幻觉问题严重影响其可靠性和实际部署，因此亟需有效的检测方法。论文提出一个新型元评估基准MHaluBench，以扩展幻觉检测的范围、类别和粒度，支持更全面的模型评估。同时，引入统一多模态幻觉检测框架UNIHD，该框架利用辅助工具（如检索和验证机制）来 robustly 检测幻觉，并通过实验证明其有效性。最终，论文还提供了针对不同幻觉类别的战略性工具应用见解，为提升MLLMs的准确性和可信度奠定基础。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by ACL 2024 (main conference)",
      "pdf_url": "http://arxiv.org/pdf/2402.03190v4",
      "published_date": "2024-02-05 16:56:11 UTC",
      "updated_date": "2024-05-27 11:52:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:23:37.964850"
    },
    {
      "arxiv_id": "2402.05130v2",
      "title": "LB-KBQA: Large-language-model and BERT based Knowledge-Based Question and Answering System",
      "title_zh": "LB-KBQA：基于大型语言模型和 BERT 的知识库问答系统",
      "authors": [
        "Yan Zhao",
        "Zhongyun Li",
        "Yushan Pan",
        "Jiaxing Wang",
        "Yihong Wang"
      ],
      "abstract": "Generative Artificial Intelligence (AI), because of its emergent abilities,\nhas empowered various fields, one typical of which is large language models\n(LLMs). One of the typical application fields of Generative AI is large\nlanguage models (LLMs), and the natural language understanding capability of\nLLM is dramatically improved when compared with conventional AI-based methods.\nThe natural language understanding capability has always been a barrier to the\nintent recognition performance of the Knowledge-Based-Question-and-Answer\n(KBQA) system, which arises from linguistic diversity and the newly appeared\nintent. Conventional AI-based methods for intent recognition can be divided\ninto semantic parsing-based and model-based approaches. However, both of the\nmethods suffer from limited resources in intent recognition. To address this\nissue, we propose a novel KBQA system based on a Large Language Model(LLM) and\nBERT (LB-KBQA). With the help of generative AI, our proposed method could\ndetect newly appeared intent and acquire new knowledge. In experiments on\nfinancial domain question answering, our model has demonstrated superior\neffectiveness.",
      "tldr_zh": "这篇论文提出了一种基于 Large Language Model (LLM) 和 BERT 的知识库问答系统，名为 LB-KBQA，以解决传统 Knowledge-Based Question and Answering (KBQA) 系统在意图识别中的资源限制问题，如语言多样性和新意图的挑战。  \n该系统利用生成式 AI 的能力，能够检测新出现的意图并动态获取新知识，从而提升自然语言理解的性能。  \n在金融领域问答实验中，LB-KBQA 展示了比传统方法更优越的效能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.05130v2",
      "published_date": "2024-02-05 16:47:17 UTC",
      "updated_date": "2024-02-09 02:45:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:23:49.074088"
    },
    {
      "arxiv_id": "2402.03183v1",
      "title": "Predicting Configuration Performance in Multiple Environments with Sequential Meta-learning",
      "title_zh": "在多个环境中使用顺序元学习预测配置性能",
      "authors": [
        "Jingzhi Gong",
        "Tao Chen"
      ],
      "abstract": "Learning and predicting the performance of given software configurations are\nof high importance to many software engineering activities. While configurable\nsoftware systems will almost certainly face diverse running environments (e.g.,\nversion, hardware, and workload), current work often either builds performance\nmodels under a single environment or fails to properly handle data from diverse\nsettings, hence restricting their accuracy for new environments. In this paper,\nwe target configuration performance learning under multiple environments. We do\nso by designing SeMPL - a meta-learning framework that learns the common\nunderstanding from configurations measured in distinct (meta) environments and\ngeneralizes them to the unforeseen, target environment. What makes it unique is\nthat unlike common meta-learning frameworks (e.g., MAML and MetaSGD) that train\nthe meta environments in parallel, we train them sequentially, one at a time.\nThe order of training naturally allows discriminating the contributions among\nmeta environments in the meta-model built, which fits better with the\ncharacteristic of configuration data that is known to dramatically differ\nbetween different environments. Through comparing with 15 state-of-the-art\nmodels under nine systems, our extensive experimental results demonstrate that\nSeMPL performs considerably better on 89% of the systems with up to 99%\naccuracy improvement, while being data-efficient, leading to a maximum of 3.86x\nspeedup. All code and data can be found at our repository:\nhttps://github.com/ideas-labo/SeMPL.",
      "tldr_zh": "本文提出 SeMPL，一种基于顺序元学习(Sequential Meta-learning)的框架，用于在多个环境中预测软件配置性能，解决了现有方法在处理多样化环境数据时的准确性不足问题。不同于传统元学习框架如 MAML 和 MetaSGD 的并行训练，SeMPL 通过顺序训练元环境来区分不同环境间的贡献，更适合配置数据的特性。实验结果显示，与 15 个最先进模型比较，SeMPL 在 89% 的系统中表现优异，准确率最高提升 99%，并实现最多 3.86 倍的加速，提高了数据效率。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG",
        "cs.PF"
      ],
      "primary_category": "cs.SE",
      "comment": "This paper has been accepted by FSE'24",
      "pdf_url": "http://arxiv.org/pdf/2402.03183v1",
      "published_date": "2024-02-05 16:47:13 UTC",
      "updated_date": "2024-02-05 16:47:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:24:02.579637"
    },
    {
      "arxiv_id": "2402.03181v5",
      "title": "C-RAG: Certified Generation Risks for Retrieval-Augmented Language Models",
      "title_zh": "C-RAG：针对检索增强语言模型的生成风险认证",
      "authors": [
        "Mintong Kang",
        "Nezihe Merve Gürel",
        "Ning Yu",
        "Dawn Song",
        "Bo Li"
      ],
      "abstract": "Despite the impressive capabilities of large language models (LLMs) across\ndiverse applications, they still suffer from trustworthiness issues, such as\nhallucinations and misalignments. Retrieval-augmented language models (RAG)\nhave been proposed to enhance the credibility of generations by grounding\nexternal knowledge, but the theoretical understandings of their generation\nrisks remains unexplored. In this paper, we answer: 1) whether RAG can indeed\nlead to low generation risks, 2) how to provide provable guarantees on the\ngeneration risks of RAG and vanilla LLMs, and 3) what sufficient conditions\nenable RAG models to reduce generation risks. We propose C-RAG, the first\nframework to certify generation risks for RAG models. Specifically, we provide\nconformal risk analysis for RAG models and certify an upper confidence bound of\ngeneration risks, which we refer to as conformal generation risk. We also\nprovide theoretical guarantees on conformal generation risks for general\nbounded risk functions under test distribution shifts. We prove that RAG\nachieves a lower conformal generation risk than that of a single LLM when the\nquality of the retrieval model and transformer is non-trivial. Our intensive\nempirical results demonstrate the soundness and tightness of our conformal\ngeneration risk guarantees across four widely-used NLP datasets on four\nstate-of-the-art retrieval models.",
      "tldr_zh": "本文研究了检索增强语言模型 (RAG) 在降低大型语言模型 (LLMs) 生成风险（如幻觉和不对齐）方面的潜力，并回答了 RAG 是否能减少风险、如何提供可证明的生成风险保证，以及什么条件使其有效。作者提出 C-RAG 框架，这是首个为 RAG 模型认证生成风险的系统，通过保形风险分析 (conformal risk analysis) 提供生成风险的上限置信界 (conformal generation risk)。理论证明显示，当检索模型和变换器的质量较高时，RAG 的生成风险低于单一 LLM，尤其在测试分布偏移下。实验结果在四个 NLP 数据集和四种最先进检索模型上验证了 C-RAG 保证的可靠性和精确性。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.IR"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.03181v5",
      "published_date": "2024-02-05 16:46:16 UTC",
      "updated_date": "2024-07-30 02:47:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:24:15.444705"
    },
    {
      "arxiv_id": "2402.03176v1",
      "title": "Comparison of Topic Modelling Approaches in the Banking Context",
      "title_zh": "银行语境中主题建模方法的比较",
      "authors": [
        "Bayode Ogunleye",
        "Tonderai Maswera",
        "Laurence Hirsch",
        "Jotham Gaudoin",
        "Teresa Brunsdon"
      ],
      "abstract": "Topic modelling is a prominent task for automatic topic extraction in many\napplications such as sentiment analysis and recommendation systems. The\napproach is vital for service industries to monitor their customer discussions.\nThe use of traditional approaches such as Latent Dirichlet Allocation (LDA) for\ntopic discovery has shown great performances, however, they are not consistent\nin their results as these approaches suffer from data sparseness and inability\nto model the word order in a document. Thus, this study presents the use of\nKernel Principal Component Analysis (KernelPCA) and K-means Clustering in the\nBERTopic architecture. We have prepared a new dataset using tweets from\ncustomers of Nigerian banks and we use this to compare the topic modelling\napproaches. Our findings showed KernelPCA and K-means in the BERTopic\narchitecture-produced coherent topics with a coherence score of 0.8463.",
      "tldr_zh": "本研究比较了不同主题建模方法在银行情境中的性能，特别是针对传统方法如 Latent Dirichlet Allocation (LDA) 的局限性（如数据稀疏性和无法处理词序）。研究者引入了 Kernel Principal Component Analysis (KernelPCA) 和 K-means Clustering 整合到 BERTopic 架构中，并使用一个新数据集（基于尼日利亚银行客户推文）进行实验。结果显示，该新方法生成的主题更连贯，coherence score 达到 0.8463，证明了其在监控客户讨论方面的潜在优势。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG",
        "stat.CO",
        "H.3.3"
      ],
      "primary_category": "cs.IR",
      "comment": "14 pages, Journal of Applied Science",
      "pdf_url": "http://arxiv.org/pdf/2402.03176v1",
      "published_date": "2024-02-05 16:43:53 UTC",
      "updated_date": "2024-02-05 16:43:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:24:24.087560"
    },
    {
      "arxiv_id": "2402.03175v2",
      "title": "Beyond the Black Box: A Statistical Model for LLM Reasoning and Inference",
      "title_zh": "超越黑箱：LLM 推理与推断的统计模型",
      "authors": [
        "Siddhartha Dalal",
        "Vishal Misra"
      ],
      "abstract": "This paper introduces a novel Bayesian learning model to explain the behavior\nof Large Language Models (LLMs), focusing on their core optimization metric of\nnext token prediction. We develop a theoretical framework based on an ideal\ngenerative text model represented by a multinomial transition probability\nmatrix with a prior, and examine how LLMs approximate this matrix. Key\ncontributions include: (i) a continuity theorem relating embeddings to\nmultinomial distributions, (ii) a demonstration that LLM text generation aligns\nwith Bayesian learning principles, (iii) an explanation for the emergence of\nin-context learning in larger models, (iv) empirical validation using\nvisualizations of next token probabilities from an instrumented Llama model Our\nfindings provide new insights into LLM functioning, offering a statistical\nfoundation for understanding their capabilities and limitations. This framework\nhas implications for LLM design, training, and application, potentially guiding\nfuture developments in the field.",
      "tldr_zh": "本论文提出了一种新型贝叶斯学习模型，用于解释大语言模型（LLMs）的行为，焦点在于其核心优化指标——下一个标记预测。研究开发了一个理论框架，基于带有先验的多项式转移概率矩阵（multinomial transition probability matrix），并分析 LLMs 如何逼近这一理想生成文本模型。关键贡献包括：(i) 一个连续性定理（continuity theorem）将嵌入与多项式分布相关联，(ii) 证明 LLM 文本生成符合贝叶斯学习（Bayesian learning）原则，(iii) 解释更大模型中上下文学习（in-context learning）的出现，以及(iv) 通过工具化 Llama 模型的下一个标记概率可视化进行实证验证。这些发现为理解 LLM 的能力和局限性提供了统计基础，并可能指导未来的 LLM 设计、训练和应用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "I.2.7"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.03175v2",
      "published_date": "2024-02-05 16:42:10 UTC",
      "updated_date": "2024-09-24 13:30:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:24:37.791869"
    },
    {
      "arxiv_id": "2402.03173v3",
      "title": "MULTI: Multimodal Understanding Leaderboard with Text and Images",
      "title_zh": "翻译失败",
      "authors": [
        "Zichen Zhu",
        "Yang Xu",
        "Lu Chen",
        "Jingkai Yang",
        "Yichuan Ma",
        "Yiming Sun",
        "Hailin Wen",
        "Jiaqi Liu",
        "Jinyu Cai",
        "Yingzi Ma",
        "Situo Zhang",
        "Zihan Zhao",
        "Liangtai Sun",
        "Kai Yu"
      ],
      "abstract": "The rapid development of multimodal large language models (MLLMs) raises the\nquestion of how they compare to human performance. While existing datasets\noften feature synthetic or overly simplistic tasks, some models have already\nsurpassed human expert baselines. In this paper, we present MULTI, a Chinese\nmultimodal dataset derived from authentic examination questions. Comprising\nover 18,000 carefully selected and refined questions, MULTI evaluates models\nusing real-world examination standards, encompassing image-text comprehension,\ncomplex reasoning, and knowledge recall. Additionally, We also introduce\nMULTI-Elite, a 500-question selected hard subset, and MULTI-Extend with more\nthan 4,500 external knowledge context pieces for testing in-context learning\ncapabilities. Our evaluation highlights substantial room for MLLM advancement,\nwith Qwen2-VL-72B achieving a 76.9% accuracy on MULTI and 53.1% on MULTI-Elite\nleading 25 evaluated models, compared to human expert baselines of 86.1% and\n73.1%. MULTI serves not only as a robust evaluation platform but also paves the\nway for the development of expert-level AI.",
      "tldr_zh": "这篇论文介绍了MULTI，一个基于真实考试问题的中文多模态数据集，用于评估多模态大语言模型(MLLMs)的性能，旨在解决现有数据集过于简单的问题。数据集包含超过18,000个问题，涵盖图像-文本理解、复杂推理和知识回忆等领域。论文还推出了MULTI-Elite（一个500题的难题子集）和MULTI-Extend（超过4,500个外部知识片段，用于测试in-context learning能力）。评估25个模型后，Qwen2-VL-72B在MULTI上达到76.9%准确率，在MULTI-Elite上为53.1%，但仍低于人类专家基线的86.1%和73.1%，为开发专家级AI提供了改进方向。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "comment": "24 pages, 19 figures, 10 tables. Details and access are available at:\n  https://OpenDFM.github.io/MULTI-Benchmark/",
      "pdf_url": "http://arxiv.org/pdf/2402.03173v3",
      "published_date": "2024-02-05 16:41:02 UTC",
      "updated_date": "2025-01-07 07:05:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:24:50.478781"
    },
    {
      "arxiv_id": "2402.03172v1",
      "title": "Accurate and Well-Calibrated ICD Code Assignment Through Attention Over Diverse Label Embeddings",
      "title_zh": "翻译失败",
      "authors": [
        "Gonçalo Gomes",
        "Isabel Coutinho",
        "Bruno Martins"
      ],
      "abstract": "Although the International Classification of Diseases (ICD) has been adopted\nworldwide, manually assigning ICD codes to clinical text is time-consuming,\nerror-prone, and expensive, motivating the development of automated approaches.\nThis paper describes a novel approach for automated ICD coding, combining\nseveral ideas from previous related work. We specifically employ a strong\nTransformer-based model as a text encoder and, to handle lengthy clinical\nnarratives, we explored either (a) adapting the base encoder model into a\nLongformer, or (b) dividing the text into chunks and processing each chunk\nindependently. The representations produced by the encoder are combined with a\nlabel embedding mechanism that explores diverse ICD code synonyms. Experiments\nwith different splits of the MIMIC-III dataset show that the proposed approach\noutperforms the current state-of-the-art models in ICD coding, with the label\nembeddings significantly contributing to the good performance. Our approach\nalso leads to properly calibrated classification results, which can effectively\ninform downstream tasks such as quantification.",
      "tldr_zh": "这篇论文提出了一种新的 ICD 代码自动分配方法，使用 Transformer-based 模型作为文本编码器，通过 Longformer 或文本分块处理长临床叙述，并结合多样标签嵌入机制来利用 ICD 代码的同义词。实验在 MIMIC-III 数据集的不同分割上显示，该方法优于现有最先进模型，标签嵌入机制显著提升了性能。结果不仅准确，还实现了良好校准，支持下游任务如量化。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to EACL2024",
      "pdf_url": "http://arxiv.org/pdf/2402.03172v1",
      "published_date": "2024-02-05 16:40:23 UTC",
      "updated_date": "2024-02-05 16:40:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:25:00.668936"
    },
    {
      "arxiv_id": "2402.03164v1",
      "title": "Decidable Reasoning About Time in Finite-Domain Situation Calculus Theories",
      "title_zh": "有限域情境演算理论中时间的可判定推理",
      "authors": [
        "Till Hofmann",
        "Stefan Schupp",
        "Gerhard Lakemeyer"
      ],
      "abstract": "Representing time is crucial for cyber-physical systems and has been studied\nextensively in the Situation Calculus. The most commonly used approach\nrepresents time by adding a real-valued fluent $\\mathit{time}(a)$ that attaches\na time point to each action and consequently to each situation. We show that in\nthis approach, checking whether there is a reachable situation that satisfies a\ngiven formula is undecidable, even if the domain of discourse is restricted to\na finite set of objects. We present an alternative approach based on\nwell-established results from timed automata theory by introducing clocks as\nreal-valued fluents with restricted successor state axioms and comparison\noperators. %that only allow comparisons against fixed rationals. With this\nrestriction, we can show that the reachability problem for finite-domain basic\naction theories is decidable. Finally, we apply our results on Golog program\nrealization by presenting a decidable procedure for determining an action\nsequence that is a successful execution of a given program.",
      "tldr_zh": "这篇论文探讨了在有限域情境演算(Situation Calculus)理论中关于时间的推理问题，证明了传统方法——使用实值fluent $\\mathit{time}(a)$ 来为动作和情境附加时间点——会导致可达性检查不可判定，即使在有限域中。作者提出了一种替代方法，通过引入时钟作为受限实值fluent，并结合后继状态公理和比较操作符，借鉴timed automata理论，使有限域基本动作理论的可达性问题变得可判定。该方法的应用包括为Golog程序提供一个可判定的过程，以确定成功的动作序列，从而提升了时间推理的实用性。",
      "categories": [
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.03164v1",
      "published_date": "2024-02-05 16:32:12 UTC",
      "updated_date": "2024-02-05 16:32:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:25:13.557708"
    },
    {
      "arxiv_id": "2402.07925v1",
      "title": "Point and Instruct: Enabling Precise Image Editing by Unifying Direct Manipulation and Text Instructions",
      "title_zh": "翻译失败",
      "authors": [
        "Alec Helbling",
        "Seongmin Lee",
        "Polo Chau"
      ],
      "abstract": "Machine learning has enabled the development of powerful systems capable of\nediting images from natural language instructions. However, in many common\nscenarios it is difficult for users to specify precise image transformations\nwith text alone. For example, in an image with several dogs, it is difficult to\nselect a particular dog and move it to a precise location. Doing this with text\nalone would require a complex prompt that disambiguates the target dog and\ndescribes the destination. However, direct manipulation is well suited to\nvisual tasks like selecting objects and specifying locations. We introduce\nPoint and Instruct, a system for seamlessly combining familiar direct\nmanipulation and textual instructions to enable precise image manipulation.\nWith our system, a user can visually mark objects and locations, and reference\nthem in textual instructions. This allows users to benefit from both the visual\ndescriptiveness of natural language and the spatial precision of direct\nmanipulation.",
      "tldr_zh": "该论文指出，使用自然语言指令进行图像编辑时，难以精确指定对象和位置，例如在多狗图像中选择特定狗并移动到精确地点。研究者提出 Point and Instruct 系统，将 direct manipulation（直接操作）和 text instructions（文本指令）统一起来，允许用户通过视觉标记对象和位置，并在文本中引用它们。这样的结合充分利用了自然语言的描述性和直接操作的空间精确性，从而提升图像编辑的准确性和用户友好性。",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.07925v1",
      "published_date": "2024-02-05 16:23:07 UTC",
      "updated_date": "2024-02-05 16:23:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:25:26.120307"
    },
    {
      "arxiv_id": "2403.05544v1",
      "title": "From Algorithm Worship to the Art of Human Learning: Insights from 50-year journey of AI in Education",
      "title_zh": "从算法崇拜到人类学习的艺术：AI 在教育领域 50 年旅程的洞见",
      "authors": [
        "Kaska Porayska-Pomsta"
      ],
      "abstract": "Current discourse surrounding Artificial Intelligence (AI) oscillates between\nhope and apprehension, painting a future where AI reshapes every facet of human\nlife, including Education. This paper delves into the complexities of AI's role\nin Education, addressing the mixed messages that have both enthused and alarmed\neducators, policymakers, and the public. It explores the promises that AI holds\nfor enhancing learning through personalisation at scale, against the backdrop\nof concerns about ethical implications, the devaluation of non-STEM subjects,\nand the potential transformative impact on our neurocognitive and\nsocio-emotional functioning. Drawing on recent research and global discourse,\nthe paper seeks to unpack the reasons behind the vagueness of current\ndiscussions on AI in Education (AIED) and the implications of this ambiguity\nfor future educational practices and policies. By highlighting insights from\neducational research and synthesising evidence-based best practices in AIED,\nthe aim is to provide a clearer understanding of how AI technologies can be\naligned with the fundamental principles of learning and teaching, and explore\nwhat concrete actions may need to be prioritised now to truly enhance learning\nexperiences and outcomes for all in the future.",
      "tldr_zh": "这篇论文回顾了AI在教育（AIED）领域的50年发展历程，从对算法的崇拜转向强调人类学习艺术，探讨AI的双重影响。论文分析了AI通过大规模个性化学习提升教育潜力的同时，也指出了伦理问题、非STEM学科贬值以及对神经认知和社会情感功能的影响。基于近期研究和全球讨论，该研究揭示了AIED讨论的模糊性，并合成证据-based最佳实践，以提供更清晰的理解。最终，论文建议优先采取具体行动，将AI技术与学习教学核心原则对齐，从而提升未来学习体验和成果。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "12 pages; opinion piece",
      "pdf_url": "http://arxiv.org/pdf/2403.05544v1",
      "published_date": "2024-02-05 16:12:14 UTC",
      "updated_date": "2024-02-05 16:12:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:25:38.019854"
    },
    {
      "arxiv_id": "2402.03141v2",
      "title": "Boosting Reinforcement Learning with Strongly Delayed Feedback Through Auxiliary Short Delays",
      "title_zh": "翻译失败",
      "authors": [
        "Qingyuan Wu",
        "Simon Sinong Zhan",
        "Yixuan Wang",
        "Yuhui Wang",
        "Chung-Wei Lin",
        "Chen Lv",
        "Qi Zhu",
        "Jürgen Schmidhuber",
        "Chao Huang"
      ],
      "abstract": "Reinforcement learning (RL) is challenging in the common case of delays\nbetween events and their sensory perceptions. State-of-the-art (SOTA) state\naugmentation techniques either suffer from state space explosion or performance\ndegeneration in stochastic environments. To address these challenges, we\npresent a novel Auxiliary-Delayed Reinforcement Learning (AD-RL) method that\nleverages auxiliary tasks involving short delays to accelerate RL with long\ndelays, without compromising performance in stochastic environments.\nSpecifically, AD-RL learns a value function for short delays and uses\nbootstrapping and policy improvement techniques to adjust it for long delays.\nWe theoretically show that this can greatly reduce the sample complexity. On\ndeterministic and stochastic benchmarks, our method significantly outperforms\nthe SOTAs in both sample efficiency and policy performance. Code is available\nat https://github.com/QingyuanWuNothing/AD-RL.",
      "tldr_zh": "该论文针对强化学习（Reinforcement Learning）中事件与感知延迟的挑战，提出了一种新方法Auxiliary-Delayed Reinforcement Learning (AD-RL)，通过引入辅助短延迟任务来加速长延迟环境的训练，同时避免在随机环境（stochastic environments）中性能下降。AD-RL 具体通过学习短延迟的价值函数（value function），并运用 bootstrapping 和 policy improvement 技术调整以适应长延迟，从而显著降低样本复杂度（sample complexity）。实验结果显示，该方法在确定性和随机基准测试中，在样本效率（sample efficiency）和策略性能（policy performance）上均优于现有最佳技术（SOTAs）。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.03141v2",
      "published_date": "2024-02-05 16:11:03 UTC",
      "updated_date": "2024-06-05 19:12:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:25:52.855744"
    },
    {
      "arxiv_id": "2402.03138v2",
      "title": "Just Cluster It: An Approach for Exploration in High-Dimensions using Clustering and Pre-Trained Representations",
      "title_zh": "翻译失败",
      "authors": [
        "Stefan Sylvius Wagner",
        "Stefan Harmeling"
      ],
      "abstract": "In this paper we adopt a representation-centric perspective on exploration in\nreinforcement learning, viewing exploration fundamentally as a density\nestimation problem. We investigate the effectiveness of clustering\nrepresentations for exploration in 3-D environments, based on the observation\nthat the importance of pixel changes between transitions is less pronounced in\n3-D environments compared to 2-D environments, where pixel changes between\ntransitions are typically distinct and significant. We propose a method that\nperforms episodic and global clustering on random representations and on\npre-trained DINO representations to count states, i.e, estimate pseudo-counts.\nSurprisingly, even random features can be clustered effectively to count states\nin 3-D environments, however when these become visually more complex,\npre-trained DINO representations are more effective thanks to the pre-trained\ninductive biases in the representations. Overall, this presents a pathway for\nintegrating pre-trained biases into exploration. We evaluate our approach on\nthe VizDoom and Habitat environments, demonstrating that our method surpasses\nother well-known exploration methods in these settings.",
      "tldr_zh": "本论文将强化学习中的探索视为密度估计问题，提出一种名为“Just Cluster It”的方法，通过在高维空间中使用聚类（clustering）和预训练表示（pre-trained representations）来提升探索效率。该方法在3-D环境中对随机表示和预训练DINO表示进行剧集级（episodic）和全局聚类，以估计伪计数（pseudo-counts），并观察到像素变化在3-D环境中的重要性不如2-D环境显著。实验结果显示，该方法在VizDoom和Habitat环境中超越了其他知名探索方法，尤其在视觉复杂环境中，预训练表示的归纳偏差（inductive biases）使其更具优势。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at the International Conference On Machine Learning (ICML)\n  2024",
      "pdf_url": "http://arxiv.org/pdf/2402.03138v2",
      "published_date": "2024-02-05 16:08:58 UTC",
      "updated_date": "2024-08-14 19:08:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:26:02.400921"
    },
    {
      "arxiv_id": "2402.03136v2",
      "title": "Mastering Zero-Shot Interactions in Cooperative and Competitive Simultaneous Games",
      "title_zh": "精通合作与竞争同时游戏中的零样本互动",
      "authors": [
        "Yannik Mahlau",
        "Frederik Schubert",
        "Bodo Rosenhahn"
      ],
      "abstract": "The combination of self-play and planning has achieved great successes in\nsequential games, for instance in Chess and Go. However, adapting algorithms\nsuch as AlphaZero to simultaneous games poses a new challenge. In these games,\nmissing information about concurrent actions of other agents is a limiting\nfactor as they may select different Nash equilibria or do not play optimally at\nall. Thus, it is vital to model the behavior of the other agents when\ninteracting with them in simultaneous games. To this end, we propose Albatross:\nAlphaZero for Learning Bounded-rational Agents and Temperature-based Response\nOptimization using Simulated Self-play. Albatross learns to play the novel\nequilibrium concept of a Smooth Best Response Logit Equilibrium (SBRLE), which\nenables cooperation and competition with agents of any playing strength. We\nperform an extensive evaluation of Albatross on a set of cooperative and\ncompetitive simultaneous perfect-information games. In contrast to AlphaZero,\nAlbatross is able to exploit weak agents in the competitive game of\nBattlesnake. Additionally, it yields an improvement of 37.6% compared to\nprevious state of the art in the cooperative Overcooked benchmark.",
      "tldr_zh": "这篇论文提出了 Albatross 算法，一种基于 AlphaZero 的框架，用于在合作和竞争的 simultaneous games 中实现零样本互动，以解决代理行为建模的挑战。Albatross 通过自对弈模拟学习 Smooth Best Response Logit Equilibrium (SBRLE) 概念，能够处理其他代理的非最优行为，并在不同游戏强度下实现合作或竞争。实验结果显示，在竞争游戏 Battlesnake 中，Albatross 能有效利用弱代理，而在合作游戏 Overcooked 中，其性能比之前最先进方法提升 37.6%。",
      "categories": [
        "cs.AI",
        "cs.GT"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.03136v2",
      "published_date": "2024-02-05 16:03:44 UTC",
      "updated_date": "2024-06-11 12:26:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:26:14.105297"
    },
    {
      "arxiv_id": "2402.03130v3",
      "title": "User Centric Evaluation of Code Generation Tools",
      "title_zh": "翻译失败",
      "authors": [
        "Tanha Miah",
        "Hong Zhu"
      ],
      "abstract": "With the rapid advance of machine learning (ML) technology, large language\nmodels (LLMs) are increasingly explored as an intelligent tool to generate\nprogram code from natural language specifications. However, existing\nevaluations of LLMs have focused on their capabilities in comparison with\nhumans. It is desirable to evaluate their usability when deciding on whether to\nuse a LLM in software production. This paper proposes a user centric method for\nthis purpose. It includes metadata in the test cases of a benchmark to describe\ntheir usages, conducts testing in a multi-attempt process that mimics the uses\nof LLMs, measures LLM generated solutions on a set of quality attributes that\nreflect usability, and evaluates the performance based on user experiences in\nthe uses of LLMs as a tool.\n  The paper also reports a case study with the method in the evaluation of\nChatGPT's usability as a code generation tool for the R programming language.\nOur experiments demonstrated that ChatGPT is highly useful for generating R\nprogram code although it may fail on hard programming tasks. The user\nexperiences are good with overall average number of attempts being 1.61 and the\naverage time of completion being 47.02 seconds. Our experiments also found that\nthe weakest aspect of usability is conciseness, which has a score of 3.80 out\nof 5.",
      "tldr_zh": "这篇论文提出了一种以用户为中心的评估方法，用于评估大型语言模型(LLMs)作为代码生成工具的可用性，强调了测试中的元数据添加、多尝试过程以及基于用户体验的质量属性测量。方法通过模拟实际使用场景，评估LLMs生成的代码在可用性方面的性能。案例研究显示，ChatGPT在R编程语言代码生成上表现优秀，平均尝试次数仅1.61次、完成时间47.02秒，但简洁性是最弱环节，得分3.80/5。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "The paper is accepted by IEEE AITest 2024 at IEEE CISOSE 2024\n  Congress as an invited paper, and will appear in the AITest 2024 Conference\n  Proceedings",
      "pdf_url": "http://arxiv.org/pdf/2402.03130v3",
      "published_date": "2024-02-05 15:56:19 UTC",
      "updated_date": "2024-06-18 13:45:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:26:25.629830"
    },
    {
      "arxiv_id": "2402.03119v2",
      "title": "Good Teachers Explain: Explanation-Enhanced Knowledge Distillation",
      "title_zh": "翻译失败",
      "authors": [
        "Amin Parchami-Araghi",
        "Moritz Böhle",
        "Sukrut Rao",
        "Bernt Schiele"
      ],
      "abstract": "Knowledge Distillation (KD) has proven effective for compressing large\nteacher models into smaller student models. While it is well known that student\nmodels can achieve similar accuracies as the teachers, it has also been shown\nthat they nonetheless often do not learn the same function. It is, however,\noften highly desirable that the student's and teacher's functions share similar\nproperties such as basing the prediction on the same input features, as this\nensures that students learn the 'right features' from the teachers. In this\nwork, we explore whether this can be achieved by not only optimizing the\nclassic KD loss but also the similarity of the explanations generated by the\nteacher and the student. Despite the idea being simple and intuitive, we find\nthat our proposed 'explanation-enhanced' KD (e$^2$KD) (1) consistently provides\nlarge gains in terms of accuracy and student-teacher agreement, (2) ensures\nthat the student learns from the teacher to be right for the right reasons and\nto give similar explanations, and (3) is robust with respect to the model\narchitectures, the amount of training data, and even works with 'approximate',\npre-computed explanations.",
      "tldr_zh": "该论文提出了一种名为 e²KD 的增强型知识蒸馏方法，通过优化教师模型和学生模型的解释相似性，确保学生不仅达到相似的准确率，还学习相同的输入特征和推理逻辑。不同于传统 KD，该方法同时最小化解释差异，帮助学生模型“正确地”学习教师的决策过程。实验结果显示，e²KD 显著提高了准确率、学生-教师一致性，并对模型架构、训练数据量和预计算解释表现出鲁棒性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "32 pages, 11 figures, European Conference on Computer Vision (ECCV)\n  2024",
      "pdf_url": "http://arxiv.org/pdf/2402.03119v2",
      "published_date": "2024-02-05 15:47:54 UTC",
      "updated_date": "2024-07-21 16:37:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:26:37.054500"
    },
    {
      "arxiv_id": "2402.03112v1",
      "title": "Infrared Spectra Prediction for Diazo Groups Utilizing a Machine Learning Approach with Structural Attention Mechanism",
      "title_zh": "翻译失败",
      "authors": [
        "Chengchun Liu",
        "Fanyang Mo"
      ],
      "abstract": "Infrared (IR) spectroscopy is a pivotal technique in chemical research for\nelucidating molecular structures and dynamics through vibrational and\nrotational transitions. However, the intricate molecular fingerprints\ncharacterized by unique vibrational and rotational patterns present substantial\nanalytical challenges. Here, we present a machine learning approach employing a\nStructural Attention Mechanism tailored to enhance the prediction and\ninterpretation of infrared spectra, particularly for diazo compounds. Our model\ndistinguishes itself by honing in on chemical information proximal to\nfunctional groups, thereby significantly bolstering the accuracy, robustness,\nand interpretability of spectral predictions. This method not only demystifies\nthe correlations between infrared spectral features and molecular structures\nbut also offers a scalable and efficient paradigm for dissecting complex\nmolecular interactions.",
      "tldr_zh": "本研究提出了一种机器学习方法，利用 Structural Attention Mechanism 来预测重氮（diazo）化合物的红外（IR）光谱，从而解决分子振动和旋转模式带来的分析挑战。该方法通过关注功能团附近的化学信息，显著提高了光谱预测的准确性、鲁棒性和可解释性。研究不仅揭示了 IR 光谱特征与分子结构之间的相关性，还提供了一个可扩展、高效的框架，用于分析复杂的分子相互作用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.chem-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "21 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.03112v1",
      "published_date": "2024-02-05 15:44:43 UTC",
      "updated_date": "2024-02-05 15:44:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:26:48.828907"
    },
    {
      "arxiv_id": "2402.03110v3",
      "title": "Non-Stationary Latent Auto-Regressive Bandits",
      "title_zh": "非平稳潜在",
      "authors": [
        "Anna L. Trella",
        "Walter Dempsey",
        "Asim H. Gazi",
        "Ziping Xu",
        "Finale Doshi-Velez",
        "Susan A. Murphy"
      ],
      "abstract": "For the non-stationary multi-armed bandit (MAB) problem, many existing\nmethods allow a general mechanism for the non-stationarity, but rely on a\nbudget for the non-stationarity that is sub-linear to the total number of time\nsteps $T$. In many real-world settings, however, the mechanism for the\nnon-stationarity can be modeled, but there is no budget for the\nnon-stationarity. We instead consider the non-stationary bandit problem where\nthe reward means change due to a latent, auto-regressive (AR) state. We develop\nLatent AR LinUCB (LARL), an online linear contextual bandit algorithm that does\nnot rely on the non-stationary budget, but instead forms good predictions of\nreward means by implicitly predicting the latent state. The key idea is to\nreduce the problem to a linear dynamical system which can be solved as a linear\ncontextual bandit. In fact, LARL approximates a steady-state Kalman filter and\nefficiently learns system parameters online. We provide an interpretable regret\nbound for LARL with respect to the level of non-stationarity in the\nenvironment. LARL achieves sub-linear regret in this setting if the noise\nvariance of the latent state process is sufficiently small with respect to $T$.\nEmpirically, LARL outperforms various baseline methods in this non-stationary\nbandit problem.",
      "tldr_zh": "本文研究了非平稳多臂老虎机（MAB）问题，其中奖励均值受潜在自回归（AR）状态的影响，而非依赖传统的非平稳预算。作者提出了一种在线线性上下文老虎机算法——Latent AR LinUCB (LARL)，通过将问题简化为线性动态系统并近似稳态 Kalman 滤波器，来预测潜在状态并优化奖励预测。LARL 能够在在线学习系统参数的同时，提供可解释的后悔界（regret bound），在潜在状态噪声方差较小时实现亚线性后悔。实验结果表明，LARL 在这种非平稳环境中优于多种基线方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.03110v3",
      "published_date": "2024-02-05 15:38:01 UTC",
      "updated_date": "2025-02-28 02:29:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:27:02.370127"
    },
    {
      "arxiv_id": "2402.03099v1",
      "title": "Intent-based Prompt Calibration: Enhancing prompt optimization with synthetic boundary cases",
      "title_zh": "翻译失败",
      "authors": [
        "Elad Levi",
        "Eli Brosh",
        "Matan Friedmann"
      ],
      "abstract": "Prompt engineering is a challenging and important task due to the high\nsensitivity of Large Language Models (LLMs) to the given prompt and the\ninherent ambiguity of a textual task instruction. Automatic prompt engineering\nis essential to achieve optimized performance from LLMs. Recent studies have\ndemonstrated the capabilities of LLMs to automatically conduct prompt\nengineering by employing a meta-prompt that incorporates the outcomes of the\nlast trials and proposes an improved prompt. However, this requires a\nhigh-quality benchmark to compare different prompts, which is difficult and\nexpensive to acquire in many real-world use cases. In this work, we introduce a\nnew method for automatic prompt engineering, using a calibration process that\niteratively refines the prompt to the user intent. During the optimization\nprocess, the system jointly generates synthetic data of boundary use cases and\noptimizes the prompt according to the generated dataset. We demonstrate the\neffectiveness of our method with respect to strong proprietary models on\nreal-world tasks such as moderation and generation. Our method outperforms\nstate-of-the-art methods with a limited number of annotated samples.\nFurthermore, we validate the advantages of each one of the system's key\ncomponents. Our system is built in a modular way, facilitating easy adaptation\nto other tasks. The code is available\n$\\href{https://github.com/Eladlev/AutoPrompt}{here}$.",
      "tldr_zh": "本研究提出了一种基于意图的提示校准（Intent-based Prompt Calibration）方法，通过生成合成边界用例（synthetic boundary cases）来增强自动提示工程（prompt engineering），以优化 Large Language Models (LLMs) 的性能。该方法在优化过程中迭代生成合成数据并据此精炼提示，从而更好地匹配用户意图，并在内容审核和生成等真实任务上超越了现有最先进方法，即使标注样本有限。实验结果验证了系统关键组件的优势，并展示了其模块化设计，便于适应其他任务。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.03099v1",
      "published_date": "2024-02-05 15:28:43 UTC",
      "updated_date": "2024-02-05 15:28:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:27:14.936286"
    },
    {
      "arxiv_id": "2402.03081v1",
      "title": "Preference-Conditioned Language-Guided Abstraction",
      "title_zh": "翻译失败",
      "authors": [
        "Andi Peng",
        "Andreea Bobu",
        "Belinda Z. Li",
        "Theodore R. Sumers",
        "Ilia Sucholutsky",
        "Nishanth Kumar",
        "Thomas L. Griffiths",
        "Julie A. Shah"
      ],
      "abstract": "Learning from demonstrations is a common way for users to teach robots, but\nit is prone to spurious feature correlations. Recent work constructs state\nabstractions, i.e. visual representations containing task-relevant features,\nfrom language as a way to perform more generalizable learning. However, these\nabstractions also depend on a user's preference for what matters in a task,\nwhich may be hard to describe or infeasible to exhaustively specify using\nlanguage alone. How do we construct abstractions to capture these latent\npreferences? We observe that how humans behave reveals how they see the world.\nOur key insight is that changes in human behavior inform us that there are\ndifferences in preferences for how humans see the world, i.e. their state\nabstractions. In this work, we propose using language models (LMs) to query for\nthose preferences directly given knowledge that a change in behavior has\noccurred. In our framework, we use the LM in two ways: first, given a text\ndescription of the task and knowledge of behavioral change between states, we\nquery the LM for possible hidden preferences; second, given the most likely\npreference, we query the LM to construct the state abstraction. In this\nframework, the LM is also able to ask the human directly when uncertain about\nits own estimate. We demonstrate our framework's ability to construct effective\npreference-conditioned abstractions in simulated experiments, a user study, as\nwell as on a real Spot robot performing mobile manipulation tasks.",
      "tldr_zh": "该论文提出了一种偏好条件下的语言引导抽象（Preference-Conditioned Language-Guided Abstraction）框架，以解决从演示中学习机器人任务时出现的无关特征相关性问题。该框架利用语言模型 (LMs) 通过分析人类行为变化来查询和推断隐藏偏好，然后基于这些偏好构建状态抽象 (state abstractions)，并允许 LMs 在不确定时直接询问人类。在模拟实验、用户研究以及真实 Spot 机器人移动操作任务中，该方法证明了其在提高任务泛化性和有效性方面的优势。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "HRI 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.03081v1",
      "published_date": "2024-02-05 15:12:15 UTC",
      "updated_date": "2024-02-05 15:12:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:27:27.607796"
    },
    {
      "arxiv_id": "2402.03072v1",
      "title": "Learning to Abstract Visuomotor Mappings using Meta-Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Carlos A. Velazquez-Vargas",
        "Isaac Ray Christian",
        "Jordan A. Taylor",
        "Sreejan Kumar"
      ],
      "abstract": "We investigated the human capacity to acquire multiple visuomotor mappings\nfor de novo skills. Using a grid navigation paradigm, we tested whether\ncontextual cues implemented as different \"grid worlds\", allow participants to\nlearn two distinct key-mappings more efficiently. Our results indicate that\nwhen contextual information is provided, task performance is significantly\nbetter. The same held true for meta-reinforcement learning agents that differed\nin whether or not they receive contextual information when performing the task.\nWe evaluated their accuracy in predicting human performance in the task and\nanalyzed their internal representations. The results indicate that contextual\ncues allow the formation of separate representations in space and time when\nusing different visuomotor mappings, whereas the absence of them favors sharing\none representation. While both strategies can allow learning of multiple\nvisuomotor mappings, we showed contextual cues provide a computational\nadvantage in terms of how many mappings can be learned.",
      "tldr_zh": "本研究探讨了人类和元强化学习(meta-reinforcement learning)代理如何通过上下文线索来高效学习多个视觉运动映射(visuomotor mappings)，采用网格导航范式测试了不同“网格世界”作为线索的效果。结果表明，提供上下文信息显著提升了任务表现，使人类和代理能够形成分离的时空表示，从而更有效地学习多个映射。相比之下，没有上下文线索时，系统倾向于共享一个表示，这虽然能支持学习但在处理更多映射时缺乏计算优势。该工作强调了上下文线索在抽象学习中的关键作用。",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.NC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.03072v1",
      "published_date": "2024-02-05 15:02:35 UTC",
      "updated_date": "2024-02-05 15:02:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:27:40.132119"
    },
    {
      "arxiv_id": "2402.03067v1",
      "title": "Multilingual transformer and BERTopic for short text topic modeling: The case of Serbian",
      "title_zh": "多语言Transformer与BERTopic在短文本主题建模中的应用：塞尔维亚语的案例",
      "authors": [
        "Darija Medvecki",
        "Bojana Bašaragin",
        "Adela Ljajić",
        "Nikola Milošević"
      ],
      "abstract": "This paper presents the results of the first application of BERTopic, a\nstate-of-the-art topic modeling technique, to short text written in a\nmorphologi-cally rich language. We applied BERTopic with three multilingual\nembed-ding models on two levels of text preprocessing (partial and full) to\nevalu-ate its performance on partially preprocessed short text in Serbian. We\nalso compared it to LDA and NMF on fully preprocessed text. The experiments\nwere conducted on a dataset of tweets expressing hesitancy toward COVID-19\nvaccination. Our results show that with adequate parameter setting, BERTopic\ncan yield informative topics even when applied to partially pre-processed short\ntext. When the same parameters are applied in both prepro-cessing scenarios,\nthe performance drop on partially preprocessed text is minimal. Compared to LDA\nand NMF, judging by the keywords, BERTopic offers more informative topics and\ngives novel insights when the number of topics is not limited. The findings of\nthis paper can be significant for re-searchers working with other\nmorphologically rich low-resource languages and short text.",
      "tldr_zh": "这篇论文首次将BERTopic应用于形态丰富的低资源语言（如塞尔维亚语）的短文本主题建模，使用三种多语言嵌入模型在部分和完整预处理级别上进行实验，并与LDA和NMF进行了比较。实验基于COVID-19疫苗犹豫推文数据集，结果显示BERTopic即使在部分预处理文本上也能生成信息丰富的主题，性能下降最小，且提供比LDA和NMF更具洞见的关键词。研究发现有助于其他形态丰富语言和短文本的研究者应用类似方法。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.03067v1",
      "published_date": "2024-02-05 14:59:29 UTC",
      "updated_date": "2024-02-05 14:59:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:27:50.692202"
    },
    {
      "arxiv_id": "2402.03049v4",
      "title": "EasyInstruct: An Easy-to-use Instruction Processing Framework for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yixin Ou",
        "Ningyu Zhang",
        "Honghao Gui",
        "Ziwen Xu",
        "Shuofei Qiao",
        "Yida Xue",
        "Runnan Fang",
        "Kangwei Liu",
        "Lei Li",
        "Zhen Bi",
        "Guozhou Zheng",
        "Huajun Chen"
      ],
      "abstract": "In recent years, instruction tuning has gained increasing attention and\nemerged as a crucial technique to enhance the capabilities of Large Language\nModels (LLMs). To construct high-quality instruction datasets, many instruction\nprocessing approaches have been proposed, aiming to achieve a delicate balance\nbetween data quantity and data quality. Nevertheless, due to inconsistencies\nthat persist among various instruction processing methods, there is no standard\nopen-source instruction processing implementation framework available for the\ncommunity, which hinders practitioners from further developing and advancing.\nTo facilitate instruction processing research and development, we present\nEasyInstruct, an easy-to-use instruction processing framework for LLMs, which\nmodularizes instruction generation, selection, and prompting, while also\nconsidering their combination and interaction. EasyInstruct is publicly\nreleased and actively maintained at https://github.com/zjunlp/EasyInstruct,\nalong with an online demo app and a demo video for quick-start, calling for\nbroader research centered on instruction data and synthetic data.",
      "tldr_zh": "该研究针对指令调整（instruction tuning）在提升 Large Language Models (LLMs) 能力中的关键作用，提出 EasyInstruct 框架，以解决现有方法的不一致性和缺乏标准开源实现的问题。EasyInstruct 通过模块化设计处理指令生成、选择和提示，并考虑它们的组合与交互，帮助构建高质量的指令数据集。框架已开源在 GitHub 上，并提供在线演示和视频，旨在促进社区进一步开发和研究 synthetic data 相关领域。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "ACL 2024 System Demonstrations; Project website:\n  https://zjunlp.github.io/project/EasyInstruct Code:\n  https://github.com/zjunlp/EasyInstruct Video: https://youtu.be/rfQOWYfziFo\n  Demo: https://huggingface.co/spaces/zjunlp/EasyInstruct",
      "pdf_url": "http://arxiv.org/pdf/2402.03049v4",
      "published_date": "2024-02-05 14:33:56 UTC",
      "updated_date": "2024-06-24 02:10:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:28:02.890030"
    },
    {
      "arxiv_id": "2402.03040v1",
      "title": "InteractiveVideo: User-Centric Controllable Video Generation with Synergistic Multimodal Instructions",
      "title_zh": "翻译失败",
      "authors": [
        "Yiyuan Zhang",
        "Yuhao Kang",
        "Zhixin Zhang",
        "Xiaohan Ding",
        "Sanyuan Zhao",
        "Xiangyu Yue"
      ],
      "abstract": "We introduce $\\textit{InteractiveVideo}$, a user-centric framework for video\ngeneration. Different from traditional generative approaches that operate based\non user-provided images or text, our framework is designed for dynamic\ninteraction, allowing users to instruct the generative model through various\nintuitive mechanisms during the whole generation process, e.g. text and image\nprompts, painting, drag-and-drop, etc. We propose a Synergistic Multimodal\nInstruction mechanism, designed to seamlessly integrate users' multimodal\ninstructions into generative models, thus facilitating a cooperative and\nresponsive interaction between user inputs and the generative process. This\napproach enables iterative and fine-grained refinement of the generation result\nthrough precise and effective user instructions. With\n$\\textit{InteractiveVideo}$, users are given the flexibility to meticulously\ntailor key aspects of a video. They can paint the reference image, edit\nsemantics, and adjust video motions until their requirements are fully met.\nCode, models, and demo are available at\nhttps://github.com/invictus717/InteractiveVideo",
      "tldr_zh": "本研究提出InteractiveVideo框架，这是一个用户中心化的视频生成系统，允许用户通过文本、图像提示、绘画和拖拽等多模态指令在生成过程中进行动态互动。框架引入Synergistic Multimodal Instruction机制，将用户的指令无缝整合到生成模型中，实现迭代式和细粒度的视频结果优化。用户可以绘制参考图像、编辑语义以及调整视频动作，以精确满足个性化需求。该系统提升了视频生成的交互性和控制性，并提供了开源代码、模型和演示以供进一步应用。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "Code, models, and demo are available at\n  https://github.com/invictus717/InteractiveVideo",
      "pdf_url": "http://arxiv.org/pdf/2402.03040v1",
      "published_date": "2024-02-05 14:24:46 UTC",
      "updated_date": "2024-02-05 14:24:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:28:14.584221"
    },
    {
      "arxiv_id": "2402.03038v1",
      "title": "Automatic Combination of Sample Selection Strategies for Few-Shot Learning",
      "title_zh": "少样本学习的样本选择策略自动组合",
      "authors": [
        "Branislav Pecher",
        "Ivan Srba",
        "Maria Bielikova",
        "Joaquin Vanschoren"
      ],
      "abstract": "In few-shot learning, such as meta-learning, few-shot fine-tuning or\nin-context learning, the limited number of samples used to train a model have a\nsignificant impact on the overall success. Although a large number of sample\nselection strategies exist, their impact on the performance of few-shot\nlearning is not extensively known, as most of them have been so far evaluated\nin typical supervised settings only. In this paper, we thoroughly investigate\nthe impact of 20 sample selection strategies on the performance of 5 few-shot\nlearning approaches over 8 image and 6 text datasets. In addition, we propose a\nnew method for automatic combination of sample selection strategies (ACSESS)\nthat leverages the strengths and complementary information of the individual\nstrategies. The experimental results show that our method consistently\noutperforms the individual selection strategies, as well as the recently\nproposed method for selecting support examples for in-context learning. We also\nshow a strong modality, dataset and approach dependence for the majority of\nstrategies as well as their dependence on the number of shots - demonstrating\nthat the sample selection strategies play a significant role for lower number\nof shots, but regresses to random selection at higher number of shots.",
      "tldr_zh": "这篇论文探讨了在Few-Shot Learning（如元学习、少样本微调或in-context learning）中，样本选择策略对模型性能的影响，通过评估20种策略在5种学习方法上的表现，涵盖8个图像和6个文本数据集。作者提出了一种新方法ACSESS（Automatic Combination of Sample Selection Strategies），它自动整合多个策略的优势和互补信息，以提升整体效果。实验结果表明，ACSESS consistently outperforms 单个策略和最近提出的支持示例选择方法，并在样本数量较少时表现出显著优势，而在样本增多时效果趋近随机选择。该研究还揭示了策略对模态、数据集、方法和样本数量的强烈依赖性，为Few-Shot Learning的优化提供了新见解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.03038v1",
      "published_date": "2024-02-05 14:23:43 UTC",
      "updated_date": "2024-02-05 14:23:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:28:28.750792"
    },
    {
      "arxiv_id": "2403.08802v3",
      "title": "Governance of Generative Artificial Intelligence for Companies",
      "title_zh": "针对公司的生成式人工智能治理",
      "authors": [
        "Johannes Schneider",
        "Pauline Kuss",
        "Rene Abraham",
        "Christian Meske"
      ],
      "abstract": "Generative Artificial Intelligence (GenAI), specifically large language\nmodels like ChatGPT, has swiftly entered organizations without adequate\ngovernance, posing both opportunities and risks. Despite extensive debates on\nGenAI's transformative nature and regulatory measures, limited research\naddresses organizational governance, encompassing technical and business\nperspectives. Although numerous frameworks for governance of AI exist, it is\nnot clear to what extent they apply to GenAI. Our review paper fills this gap\nby surveying recent works with the purpose of better understanding fundamental\ncharacteristics of GenAI and adjusting prior frameworks specifically towards\nGenAI governance within companies. To do so, it extends Nickerson's framework\ndevelopment processes to include prior conceptualizations. Our framework\noutlines the scope, objectives, and governance mechanisms tailored to harness\nbusiness opportunities as well as mitigate risks associated with GenAI\nintegration. Our research contributes a focused approach to GenAI governance,\noffering practical insights for companies navigating the challenges of GenAI\nadoption and highlighting research gaps.",
      "tldr_zh": "本研究探讨了生成式人工智能 (GenAI) 在企业中的治理问题，指出像 ChatGPT 这样的模型快速进入组织，却缺乏足够的治理框架，可能带来机遇和风险。作者通过审查现有文献，扩展 Nickerson's framework 发展过程，针对 GenAI 的独特特性调整了先前的 AI 治理框架。提出的新框架定义了治理范围、目标和机制，帮助企业利用 GenAI 的商业机会，同时缓解相关风险，并突出了未来研究空白。",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.08802v3",
      "published_date": "2024-02-05 14:20:19 UTC",
      "updated_date": "2024-12-03 09:39:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:28:38.601988"
    },
    {
      "arxiv_id": "2402.03017v3",
      "title": "A Complete Survey on Contemporary Methods, Emerging Paradigms and Hybrid Approaches for Few-Shot Learning",
      "title_zh": "少样本学习的当代方法、新兴范式和混合方法的完整综述",
      "authors": [
        "Georgios Tsoumplekas",
        "Vladislav Li",
        "Panagiotis Sarigiannidis",
        "Vasileios Argyriou"
      ],
      "abstract": "Despite the widespread success of deep learning, its intense requirements for\nvast amounts of data and extensive training make it impractical for various\nreal-world applications where data is scarce. In recent years, Few-Shot\nLearning (FSL) has emerged as a learning paradigm that aims to address these\nlimitations by leveraging prior knowledge to enable rapid adaptation to novel\nlearning tasks. Due to its properties that highly complement deep learning's\ndata-intensive needs, FSL has seen significant growth in the past few years.\nThis survey provides a comprehensive overview of both well-established methods\nas well as recent advancements in the FSL field. The presented taxonomy extends\npreviously proposed ones by incorporating emerging FSL paradigms, such as\nin-context learning, along with novel categories within the meta-learning\nparadigm for FSL, including neural processes and probabilistic meta-learning.\nFurthermore, a holistic overview of FSL is provided by discussing hybrid FSL\napproaches that extend FSL beyond the typically examined supervised learning\nsetting. The survey also explores FSL's diverse applications across various\ndomains. Finally, recent trends shaping the field, outstanding challenges, and\npromising future research directions are discussed.",
      "tldr_zh": "这篇调查论文对 Few-Shot Learning (FSL) 进行了全面概述，旨在解决深度学习在数据稀缺场景下的局限性，通过利用先验知识实现快速适应新任务。论文扩展了现有的分类体系，涵盖当代方法、新兴范式如 in-context learning，以及 meta-learning 中的新类别，包括 neural processes 和 probabilistic meta-learning，同时探讨了混合 FSL 方法及其在监督学习以外的多样应用。最终，它分析了 FSL 的当前趋势、突出挑战以及未来研究方向，为该领域的发展提供了宝贵见解。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "63 pages, 16 figures. Under review",
      "pdf_url": "http://arxiv.org/pdf/2402.03017v3",
      "published_date": "2024-02-05 13:55:54 UTC",
      "updated_date": "2025-01-24 13:36:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:28:51.319974"
    },
    {
      "arxiv_id": "2402.03014v1",
      "title": "Whom to Trust? Elective Learning for Distributed Gaussian Process Regression",
      "title_zh": "翻译失败",
      "authors": [
        "Zewen Yang",
        "Xiaobing Dai",
        "Akshat Dubey",
        "Sandra Hirche",
        "Georges Hattab"
      ],
      "abstract": "This paper introduces an innovative approach to enhance distributed\ncooperative learning using Gaussian process (GP) regression in multi-agent\nsystems (MASs). The key contribution of this work is the development of an\nelective learning algorithm, namely prior-aware elective distributed GP\n(Pri-GP), which empowers agents with the capability to selectively request\npredictions from neighboring agents based on their trustworthiness. The\nproposed Pri-GP effectively improves individual prediction accuracy, especially\nin cases where the prior knowledge of an agent is incorrect. Moreover, it\neliminates the need for computationally intensive variance calculations for\ndetermining aggregation weights in distributed GP. Furthermore, we establish a\nprediction error bound within the Pri-GP framework, ensuring the reliability of\npredictions, which is regarded as a crucial property in safety-critical MAS\napplications.",
      "tldr_zh": "这篇论文提出了一种创新方法，用于提升多智能体系统（MASs）中的分布式Gaussian process (GP) regression，通过引入prior-aware elective distributed GP (Pri-GP)算法。Pri-GP允许代理根据邻居的可信度选择性地请求预测，从而显著提高预测准确性，尤其在代理先验知识错误的情况下。该算法还消除了计算密集型方差计算的需求，用于确定聚合权重，并建立了预测错误边界，确保预测的可靠性，这对安全关键的MAS应用至关重要。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages, conference preprint",
      "pdf_url": "http://arxiv.org/pdf/2402.03014v1",
      "published_date": "2024-02-05 13:52:56 UTC",
      "updated_date": "2024-02-05 13:52:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:29:03.090043"
    },
    {
      "arxiv_id": "2402.03009v2",
      "title": "UniMem: Towards a Unified View of Long-Context Large Language Models",
      "title_zh": "UniMem: 面向长上下文大语言模型的统一视角",
      "authors": [
        "Junjie Fang",
        "Likai Tang",
        "Hongzhe Bi",
        "Yujia Qin",
        "Si Sun",
        "Zhenyu Li",
        "Haolun Li",
        "Yongjian Li",
        "Xin Cong",
        "Yankai Lin",
        "Yukun Yan",
        "Xiaodong Shi",
        "Sen Song",
        "Zhiyuan Liu",
        "Maosong Sun"
      ],
      "abstract": "Long-context processing is a critical ability that constrains the\napplicability of large language models (LLMs). Although there exist various\nmethods devoted to enhancing the long-context processing ability of LLMs, they\nare developed in an isolated manner and lack systematic analysis and\nintegration of their strengths, hindering further developments. In this paper,\nwe introduce UniMem, a Unified framework that reformulates existing\nlong-context methods from the view of Memory augmentation of LLMs.\nDistinguished by its four core dimensions-Memory Management, Memory Writing,\nMemory Reading, and Memory Injection, UniMem empowers researchers to conduct\nsystematic exploration of long-context methods. We re-formulate 16 existing\nmethods based on UniMem and analyze four representative methods:\nTransformer-XL, Memorizing Transformer, RMT, and Longformer into equivalent\nUniMem forms to reveal their design principles and strengths. Based on these\nanalyses, we propose UniMix, an innovative approach that integrates the\nstrengths of these algorithms. Experimental results show that UniMix achieves\nsuperior performance in handling long contexts with significantly lower\nperplexity than baselines.",
      "tldr_zh": "该论文针对大型语言模型(LLMs)处理长上下文能力的局限性，提出了UniMem框架，将现有方法统一为LLMs的Memory augmentation视角。该框架包括四个核心维度：Memory Management、Memory Writing、Memory Reading和Memory Injection，并重新表述了16种现有方法，同时分析了Transformer-XL、Memorizing Transformer、RMT和Longformer的原理和优势。基于这些分析，作者开发了UniMix方法，整合了多种算法的优点。实验结果显示，UniMix在长上下文处理中显著降低了perplexity，性能优于基线模型。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "COLM 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.03009v2",
      "published_date": "2024-02-05 13:47:53 UTC",
      "updated_date": "2024-08-19 14:47:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:29:15.326050"
    },
    {
      "arxiv_id": "2402.02992v2",
      "title": "Decoding-time Realignment of Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Tianlin Liu",
        "Shangmin Guo",
        "Leonardo Bianco",
        "Daniele Calandriello",
        "Quentin Berthet",
        "Felipe Llinares",
        "Jessica Hoffmann",
        "Lucas Dixon",
        "Michal Valko",
        "Mathieu Blondel"
      ],
      "abstract": "Aligning language models with human preferences is crucial for reducing\nerrors and biases in these models. Alignment techniques, such as reinforcement\nlearning from human feedback (RLHF), are typically cast as optimizing a\ntradeoff between human preference rewards and a proximity regularization term\nthat encourages staying close to the unaligned model. Selecting an appropriate\nlevel of regularization is critical: insufficient regularization can lead to\nreduced model capabilities due to reward hacking, whereas excessive\nregularization hinders alignment. Traditional methods for finding the optimal\nregularization level require retraining multiple models with varying\nregularization strengths. This process, however, is resource-intensive,\nespecially for large models. To address this challenge, we propose\ndecoding-time realignment (DeRa), a simple method to explore and evaluate\ndifferent regularization strengths in aligned models without retraining. DeRa\nenables control over the degree of alignment, allowing users to smoothly\ntransition between unaligned and aligned models. It also enhances the\nefficiency of hyperparameter tuning by enabling the identification of effective\nregularization strengths using a validation dataset.",
      "tldr_zh": "该论文探讨了语言模型与人类偏好校准（alignment）的关键挑战，传统方法如RLHF（Reinforcement Learning from Human Feedback）需优化人类奖励与正则化权衡，但选择不当会导致模型能力下降或校准不足，且需多次重新训练，资源消耗巨大。作者提出Decoding-time Realignment (DeRa)，一种无需重新训练的简单方法，能在解码时探索不同正则化强度，实现从未校准到校准模型的平滑过渡。DeRa 通过使用验证数据集提升超参数调优效率，从而简化校准过程并提高语言模型的可靠性和适应性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "In Proceedings of the 41st International Conference on Machine\n  Learning (ICML 2024)",
      "pdf_url": "http://arxiv.org/pdf/2402.02992v2",
      "published_date": "2024-02-05 13:31:28 UTC",
      "updated_date": "2024-05-24 08:39:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:29:27.945893"
    },
    {
      "arxiv_id": "2402.02987v2",
      "title": "Reconstruct Your Previous Conversations! Comprehensively Investigating Privacy Leakage Risks in Conversations with GPT Models",
      "title_zh": "翻译失败",
      "authors": [
        "Junjie Chu",
        "Zeyang Sha",
        "Michael Backes",
        "Yang Zhang"
      ],
      "abstract": "Significant advancements have recently been made in large language models\nrepresented by GPT models. Users frequently have multi-round private\nconversations with cloud-hosted GPT models for task optimization. Yet, this\noperational paradigm introduces additional attack surfaces, particularly in\ncustom GPTs and hijacked chat sessions. In this paper, we introduce a\nstraightforward yet potent Conversation Reconstruction Attack. This attack\ntargets the contents of previous conversations between GPT models and benign\nusers, i.e., the benign users' input contents during their interaction with GPT\nmodels. The adversary could induce GPT models to leak such contents by querying\nthem with designed malicious prompts. Our comprehensive examination of privacy\nrisks during the interactions with GPT models under this attack reveals GPT-4's\nconsiderable resilience. We present two advanced attacks targeting improved\nreconstruction of past conversations, demonstrating significant privacy leakage\nacross all models under these advanced techniques. Evaluating various defense\nmechanisms, we find them ineffective against these attacks. Our findings\nhighlight the ease with which privacy can be compromised in interactions with\nGPT models, urging the community to safeguard against potential abuses of these\nmodels' capabilities.",
      "tldr_zh": "该研究调查了用户与 GPT 模型进行多轮对话时面临的隐私泄露风险，引入了一种简单有效的 Conversation Reconstruction Attack，通过设计恶意提示诱导模型泄露先前对话内容。实验显示，GPT-4 对基本攻击有较强抵抗力，但两种高级攻击技术导致所有模型出现显著隐私泄露。评估各种防御机制后，发现它们对这些攻击无效，论文呼吁社区加强措施以防范 GPT 模型的滥用风险。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted in EMNLP 2024. 14 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.02987v2",
      "published_date": "2024-02-05 13:18:42 UTC",
      "updated_date": "2024-10-07 12:11:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:29:39.283648"
    },
    {
      "arxiv_id": "2402.02978v1",
      "title": "Evaluating Datalog Tools for Meta-reasoning over OWL 2 QL",
      "title_zh": "评估 Datalog 工具用于 OWL 2 QL 的元推理",
      "authors": [
        "Haya Majid Qureshi",
        "Wolfgang Faber"
      ],
      "abstract": "Metamodeling is a general approach to expressing knowledge about classes and\nproperties in an ontology. It is a desirable modeling feature in multiple\napplications that simplifies the extension and reuse of ontologies.\nNevertheless, allowing metamodeling without restrictions is problematic for\nseveral reasons, mainly due to undecidability issues. Practical languages,\ntherefore, forbid classes to occur as instances of other classes or treat such\noccurrences as semantically different objects. Specifically, meta-querying in\nSPARQL under the Direct Semantic Entailment Regime (DSER) uses the latter\napproach, thereby effectively not supporting meta-queries. However, several\nextensions enabling different metamodeling features have been proposed over the\nlast decade. This paper deals with the Metamodeling Semantics (MS) over OWL 2\nQL and the Metamodeling Semantic Entailment Regime (MSER), as proposed in\nLenzerini et al. (2015) and Lenzerini et al. (2020); Cima et al. (2017). A\nreduction from OWL 2 QL to Datalog for meta-querying was proposed in Cima et\nal. (2017). In this paper, we experiment with various logic programming tools\nthat support Datalog querying to determine their suitability as back-ends to\nMSER query answering. These tools stem from different logic programming\nparadigms (Prolog, pure Datalog, Answer Set Programming, Hybrid Knowledge\nBases). Our work shows that the Datalog approach to MSER querying is practical\nalso for sizeable ontologies with limited resources (time and memory). This\npaper significantly extends Qureshi & Faber (2021) by a more detailed\nexperimental analysis and more background. Under consideration in Theory and\nPractice of Logic Programming (TPLP).",
      "tldr_zh": "该论文评估了各种 Datalog 工具在 OWL 2 QL 元推理（Meta-reasoning）中的适用性，旨在解决元建模（Metamodeling）在本体扩展和重用中的挑战，如不可判定性（undecidability）问题。研究方法包括实验不同逻辑编程工具（如 Prolog、纯 Datalog、Answer Set Programming 和 Hybrid Knowledge Bases），将 OWL 2 QL 归约到 Datalog 以支持 Metamodeling Semantics (MS) 和 Metamodeling Semantic Entailment Regime (MSER)。结果表明，这种 Datalog 方法在时间和内存资源有限的情况下，能够高效处理大型本体查询，并显著扩展了 Qureshi & Faber (2021) 的先前工作。",
      "categories": [
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "Under consideration in Theory and Practice of Logic Programming\n  (TPLP)",
      "pdf_url": "http://arxiv.org/pdf/2402.02978v1",
      "published_date": "2024-02-05 13:06:35 UTC",
      "updated_date": "2024-02-05 13:06:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:29:54.553246"
    },
    {
      "arxiv_id": "2402.02977v4",
      "title": "Variational Flow Models: Flowing in Your Style",
      "title_zh": "翻译失败",
      "authors": [
        "Kien Do",
        "Duc Kieu",
        "Toan Nguyen",
        "Dang Nguyen",
        "Hung Le",
        "Dung Nguyen",
        "Thin Nguyen"
      ],
      "abstract": "We propose a systematic training-free method to transform the probability\nflow of a \"linear\" stochastic process characterized by the equation\nX_{t}=a_{t}X_{0}+\\sigma_{t}X_{1} into a straight constant-speed (SC) flow,\nreminiscent of Rectified Flow. This transformation facilitates fast sampling\nalong the original probability flow via the Euler method without training a new\nmodel of the SC flow. The flexibility of our approach allows us to extend our\ntransformation to inter-convert two posterior flows of two distinct linear\nstochastic processes. Moreover, we can easily integrate high-order numerical\nsolvers into the transformed SC flow, further enhancing the sampling accuracy\nand efficiency. Rigorous theoretical analysis and extensive experimental\nresults substantiate the advantages of our framework. Our code is available at\nthis [https://github.com/clarken92/VFM||link].",
      "tldr_zh": "本研究提出了一种系统化的无训练方法，将线性随机过程(stochastic process)的概率流转换为直线恒速(SC)流，类似于Rectified Flow，从而实现快速采样，而无需训练新模型。该方法利用变换技术（如Euler方法）沿原概率流进行高效采样，并扩展到转换两个不同线性随机过程的后验流，同时整合高阶数值求解器以提升采样精度和效率。通过严格的理论分析和广泛实验，结果证明了该框架在采样准确性和效率方面的显著优势。代码已在GitHub上开源。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Our code is available at: https://github.com/clarken92/VFM",
      "pdf_url": "http://arxiv.org/pdf/2402.02977v4",
      "published_date": "2024-02-05 12:58:29 UTC",
      "updated_date": "2024-08-05 01:24:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:30:02.445957"
    },
    {
      "arxiv_id": "2405.00679v2",
      "title": "Exploring Biologically Inspired Mechanisms of Adversarial Robustness",
      "title_zh": "探索生物启发的对抗鲁棒性机制",
      "authors": [
        "Konstantin Holzhausen",
        "Mia Merlid",
        "Håkon Olav Torvik",
        "Anders Malthe-Sørenssen",
        "Mikkel Elle Lepperød"
      ],
      "abstract": "Backpropagation-optimized artificial neural networks, while precise, lack\nrobustness, leading to unforeseen behaviors that affect their safety.\nBiological neural systems do solve some of these issues already. Unlike\nartificial models, biological neurons adjust connectivity based on neighboring\ncell activity. Understanding the biological mechanisms of robustness can pave\nthe way towards building trust worthy and safe systems. Robustness in neural\nrepresentations is hypothesized to correlate with the smoothness of the\nencoding manifold. Recent work suggests power law covariance spectra, which\nwere observed studying the primary visual cortex of mice, to be indicative of a\nbalanced trade-off between accuracy and robustness in representations. Here, we\nshow that unsupervised local learning models with winner takes all dynamics\nlearn such power law representations, providing upcoming studies a mechanistic\nmodel with that characteristic. Our research aims to understand the interplay\nbetween geometry, spectral properties, robustness, and expressivity in neural\nrepresentations. Hence, we study the link between representation smoothness and\nspectrum by using weight, Jacobian and spectral regularization while assessing\nperformance and adversarial robustness. Our work serves as a foundation for\nfuture research into the mechanisms underlying power law spectra and optimally\nsmooth encodings in both biological and artificial systems. The insights gained\nmay elucidate the mechanisms that realize robust neural networks in mammalian\nbrains and inform the development of more stable and reliable artificial\nsystems.",
      "tldr_zh": "本研究探讨了受生物启发的机制，以提升人工神经网络（backpropagation-optimized artificial neural networks）对抗鲁棒性（adversarial robustness），因为这些网络虽精确但易受安全威胁，而生物神经系统通过邻近细胞活动调整连接实现了更好的鲁棒性。研究发现，功率律协方差谱（power law covariance spectra）与编码流形（encoding manifold）的平滑度相关，能够平衡准确性和鲁棒性，并展示了无监督局部学习模型（unsupervised local learning models）结合赢家通吃动态（winner takes all dynamics）可以学习这种谱表示。作者通过权重、正则化和雅可比矩阵（Jacobian）正则化评估了表示平滑度与谱属性的关联，证明了这些机制在提升性能和对抗鲁棒性方面的作用。该工作为理解神经表示中的几何、谱属性和表达性交互提供基础，并有望指导开发更稳定的人工系统和阐明生物大脑的鲁棒机制。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "q-bio.NC"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.00679v2",
      "published_date": "2024-02-05 12:06:00 UTC",
      "updated_date": "2025-01-29 09:10:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:30:17.822693"
    },
    {
      "arxiv_id": "2402.05128v3",
      "title": "Enhancing textual textbook question answering with large language models and retrieval augmented generation",
      "title_zh": "翻译失败",
      "authors": [
        "Hessa Abdulrahman Alawwad",
        "Areej Alhothali",
        "Usman Naseem",
        "Ali Alkhathlan",
        "Amani Jamal"
      ],
      "abstract": "Textbook question answering (TQA) is a challenging task in artificial\nintelligence due to the complex nature of context needed to answer complex\nquestions. Although previous research has improved the task, there are still\nsome limitations in textual TQA, including weak reasoning and inability to\ncapture contextual information in the lengthy context. We propose a framework\n(PLRTQA) that incorporates the retrieval augmented generation (RAG) technique\nto handle the out-of-domain scenario where concepts are spread across different\nlessons, and utilize transfer learning to handle the long context and enhance\nreasoning abilities. Our architecture outperforms the baseline, achieving an\naccuracy improvement of 4. 12% in the validation set and 9. 84% in the test set\nfor textual multiple-choice questions. While this paper focuses on solving\nchallenges in the textual TQA, It provides a foundation for future work in\nmultimodal TQA where the visual components are integrated to address more\ncomplex educational scenarios. Code: https://github.com/hessaAlawwad/PLR-TQA",
      "tldr_zh": "这篇论文针对教科书问答 (TQA) 的挑战，如弱推理和无法捕获长上下文信息，提出了一种框架 PLRTQA。框架整合了检索增强生成 (RAG) 技术来处理跨课概念的出域场景，并利用 transfer learning 来增强推理能力和长上下文处理。实验结果显示，PLRTQA 在验证集和测试集上分别比基线模型提高了 4.12% 和 9.84% 的准确率。该工作为未来的多模态 TQA 研究奠定了基础，提供代码以便进一步扩展。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.05128v3",
      "published_date": "2024-02-05 11:58:56 UTC",
      "updated_date": "2025-01-22 07:14:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:30:28.389751"
    },
    {
      "arxiv_id": "2402.02921v1",
      "title": "Mining a Minimal Set of Behavioral Patterns using Incremental Evaluation",
      "title_zh": "翻译失败",
      "authors": [
        "Mehdi Acheli",
        "Daniela Grigori",
        "Matthias Weidlich"
      ],
      "abstract": "Process mining provides methods to analyse event logs generated by\ninformation systems during the execution of processes. It thereby supports the\ndesign, validation, and execution of processes in domains ranging from\nhealthcare, through manufacturing, to e-commerce. To explore the regularities\nof flexible processes that show a large behavioral variability, it was\nsuggested to mine recurrent behavioral patterns that jointly describe the\nunderlying process. Existing approaches to behavioral pattern mining, however,\nsuffer from two limitations. First, they show limited scalability as\nincremental computation is incorporated only in the generation of pattern\ncandidates, but not in the evaluation of their quality. Second, process\nanalysis based on mined patterns shows limited effectiveness due to an\noverwhelmingly large number of patterns obtained in practical application\nscenarios, many of which are redundant. In this paper, we address these\nlimitations to facilitate the analysis of complex, flexible processes based on\nbehavioral patterns. Specifically, we improve COBPAM, our initial behavioral\npattern mining algorithm, by an incremental procedure to evaluate the quality\nof pattern candidates, optimizing thereby its efficiency. Targeting a more\neffective use of the resulting patterns, we further propose pruning strategies\nfor redundant patterns and show how relations between the remaining patterns\nare extracted and visualized to provide process insights. Our experiments with\ndiverse real-world datasets indicate a considerable reduction of the runtime\nneeded for pattern mining, while a qualitative assessment highlights how\nrelations between patterns guide the analysis of the underlying process.",
      "tldr_zh": "这篇论文针对过程挖掘（process mining）中行为模式（behavioral patterns）的挖掘问题，提出了改进后的 COBPAM 算法，通过引入增量评估（incremental evaluation）来优化模式候选的质量评估，提高了算法的扩展性和效率。论文进一步开发了修剪冗余模式的策略，并提取及可视化模式之间的关系，以增强对复杂灵活过程的分析。实验结果显示，该方法在真实数据集上显著减少了运行时间，同时通过模式关系提供更有效的过程洞察。",
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.DB",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.02921v1",
      "published_date": "2024-02-05 11:41:37 UTC",
      "updated_date": "2024-02-05 11:41:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:30:40.173896"
    },
    {
      "arxiv_id": "2402.02910v2",
      "title": "DS-MS-TCN: Otago Exercises Recognition with a Dual-Scale Multi-Stage Temporal Convolutional Network",
      "title_zh": "DS-MS-TCN：Otago 锻炼识别",
      "authors": [
        "Meng Shang",
        "Lenore Dedeyne",
        "Jolan Dupont",
        "Laura Vercauteren",
        "Nadjia Amini",
        "Laurence Lapauw",
        "Evelien Gielen",
        "Sabine Verschueren",
        "Carolina Varon",
        "Walter De Raedt",
        "Bart Vanrumste"
      ],
      "abstract": "The Otago Exercise Program (OEP) represents a crucial rehabilitation\ninitiative tailored for older adults, aimed at enhancing balance and strength.\nDespite previous efforts utilizing wearable sensors for OEP recognition,\nexisting studies have exhibited limitations in terms of accuracy and\nrobustness. This study addresses these limitations by employing a single\nwaist-mounted Inertial Measurement Unit (IMU) to recognize OEP exercises among\ncommunity-dwelling older adults in their daily lives. A cohort of 36 older\nadults participated in laboratory settings, supplemented by an additional 7\nolder adults recruited for at-home assessments. The study proposes a Dual-Scale\nMulti-Stage Temporal Convolutional Network (DS-MS-TCN) designed for two-level\nsequence-to-sequence classification, incorporating them in one loss function.\nIn the first stage, the model focuses on recognizing each repetition of the\nexercises (micro labels). Subsequent stages extend the recognition to encompass\nthe complete range of exercises (macro labels). The DS-MS-TCN model surpasses\nexisting state-of-the-art deep learning models, achieving f1-scores exceeding\n80% and Intersection over Union (IoU) f1-scores surpassing 60% for all four\nexercises evaluated. Notably, the model outperforms the prior study utilizing\nthe sliding window technique, eliminating the need for post-processing stages\nand window size tuning. To our knowledge, we are the first to present a novel\nperspective on enhancing Human Activity Recognition (HAR) systems through the\nrecognition of each repetition of activities.",
      "tldr_zh": "本文研究了 Otago Exercise Program (OEP)，一个针对老年人的平衡和力量康复程序，使用单一腰部安装的 Inertial Measurement Unit (IMU) 来识别社区老年人在日常中的练习动作。作者提出了一种 Dual-Scale Multi-Stage Temporal Convolutional Network (DS-MS-TCN)，通过两级序列到序列分类（包括微观标签的重复识别和宏观标签的整体练习识别）结合在一个损失函数中，提升了识别的准确性和鲁棒性。实验结果显示，该模型在四种练习上实现了 f1-scores 超过 80% 和 Intersection over Union (IoU) f1-scores 超过 60%，优于现有深度学习模型，且无需后处理或窗口大小调整，这也是首次通过识别每个活动重复来增强 Human Activity Recognition (HAR) 系统。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.02910v2",
      "published_date": "2024-02-05 11:25:45 UTC",
      "updated_date": "2024-02-07 14:21:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:30:54.199744"
    },
    {
      "arxiv_id": "2402.02904v1",
      "title": "Replication of Impedance Identification Experiments on a Reinforcement-Learning-Controlled Digital Twin of Human Elbows",
      "title_zh": "翻译失败",
      "authors": [
        "Hao Yu",
        "Zebin Huang",
        "Qingbo Liu",
        "Ignacio Carlucho",
        "Mustafa Suphi Erden"
      ],
      "abstract": "This study presents a pioneering effort to replicate human neuromechanical\nexperiments within a virtual environment utilising a digital human model. By\nemploying MyoSuite, a state-of-the-art human motion simulation platform\nenhanced by Reinforcement Learning (RL), multiple types of impedance\nidentification experiments of human elbow were replicated on a musculoskeletal\nmodel. We compared the elbow movement controlled by an RL agent with the motion\nof an actual human elbow in terms of the impedance identified in\ntorque-perturbation experiments. The findings reveal that the RL agent exhibits\nhigher elbow impedance to stabilise the target elbow motion under perturbation\nthan a human does, likely due to its shorter reaction time and superior sensory\ncapabilities. This study serves as a preliminary exploration into the potential\nof virtual environment simulations for neuromechanical research, offering an\ninitial yet promising alternative to conventional experimental approaches. An\nRL-controlled digital twin with complete musculoskeletal models of the human\nbody is expected to be useful in designing experiments and validating\nrehabilitation theory before experiments on real human subjects.",
      "tldr_zh": "这篇论文使用 MyoSuite 平台和 Reinforcement Learning (RL) 控制的数字孪生，复制了人类肘部的阻抗识别实验，通过扭矩扰动测试比较 RL 代理和真实人类肘部运动。研究发现，RL 代理在扰动下表现出更高的肘部阻抗，以稳定目标运动，这可能源于其更短的反应时间和更优的感知能力。该工作初步探索了虚拟环境模拟在神经机械研究中的潜力，为设计实验和验证康复理论提供了一个无需真实人类测试的替代方法。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "8 pages, 5 figures; Submitted to WCCI-2024",
      "pdf_url": "http://arxiv.org/pdf/2402.02904v1",
      "published_date": "2024-02-05 11:16:32 UTC",
      "updated_date": "2024-02-05 11:16:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:31:06.098644"
    },
    {
      "arxiv_id": "2402.02896v1",
      "title": "LLM Agents in Interaction: Measuring Personality Consistency and Linguistic Alignment in Interacting Populations of Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Ivar Frisch",
        "Mario Giulianelli"
      ],
      "abstract": "While both agent interaction and personalisation are vibrant topics in\nresearch on large language models (LLMs), there has been limited focus on the\neffect of language interaction on the behaviour of persona-conditioned LLM\nagents. Such an endeavour is important to ensure that agents remain consistent\nto their assigned traits yet are able to engage in open, naturalistic\ndialogues. In our experiments, we condition GPT-3.5 on personality profiles\nthrough prompting and create a two-group population of LLM agents using a\nsimple variability-inducing sampling algorithm. We then administer personality\ntests and submit the agents to a collaborative writing task, finding that\ndifferent profiles exhibit different degrees of personality consistency and\nlinguistic alignment to their conversational partners. Our study seeks to lay\nthe groundwork for better understanding of dialogue-based interaction between\nLLMs and highlights the need for new approaches to crafting robust, more\nhuman-like LLM personas for interactive environments.",
      "tldr_zh": "本研究探讨了LLM代理在互动中的个性一致性和语言对齐问题，通过对GPT-3.5进行提示-based个性配置，并使用变异性采样算法创建两个代理群组。实验涉及个性测试和协作写作任务，结果显示不同个性配置文件表现出不同的行为一致性及与对话伙伴的语言适应性。该研究为理解LLM间的对话互动提供基础，并强调需要新方法来构建更鲁棒、人性化的LLM角色。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.MA"
      ],
      "primary_category": "cs.CL",
      "comment": "To appear in Proceedings of the 1st Personalization of Generative AI\n  Workshop, EACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.02896v1",
      "published_date": "2024-02-05 11:05:20 UTC",
      "updated_date": "2024-02-05 11:05:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:31:18.634776"
    },
    {
      "arxiv_id": "2402.02885v1",
      "title": "A Review on Building Blocks of Decentralized Artificial Intelligence",
      "title_zh": "翻译失败",
      "authors": [
        "Vid Kersic",
        "Muhamed Turkanovic"
      ],
      "abstract": "Artificial intelligence is transforming our lives, and technological progress\nand transfer from the academic and theoretical sphere to the real world are\naccelerating yearly. But during that progress and transition, several open\nproblems and questions need to be addressed for the field to develop ethically,\nsuch as digital privacy, ownership, and control. These are some of the reasons\nwhy the currently most popular approaches of artificial intelligence, i.e.,\ncentralized AI (CEAI), are questionable, with other directions also being\nwidely explored, such as decentralized artificial intelligence (DEAI), to solve\nsome of the most reaching problems. This paper provides a systematic literature\nreview (SLR) of existing work in the field of DEAI, presenting the findings of\n71 identified studies. The paper's primary focus is identifying the building\nblocks of DEAI solutions and networks, tackling the DEAI analysis from a\nbottom-up approach. In the end, future directions of research and open problems\nare proposed.",
      "tldr_zh": "这篇论文对去中心化人工智能（DEAI）的构建块进行了系统文献综述（SLR），旨在解决中心化 AI（CEAI）在数字隐私、所有权和控制等方面的伦理挑战。通过分析 71 篇相关研究，论文从底层角度探讨了 DEAI 解决方案的核心组成部分，包括网络结构和关键技术。最终，论文提出了未来的研究方向和开放问题，以推动 DEAI 的可持续发展。",
      "categories": [
        "cs.AI",
        "cs.CR",
        "cs.DC"
      ],
      "primary_category": "cs.AI",
      "comment": "This work has been submitted to the IEEE for possible publication",
      "pdf_url": "http://arxiv.org/pdf/2402.02885v1",
      "published_date": "2024-02-05 10:54:14 UTC",
      "updated_date": "2024-02-05 10:54:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:31:30.948235"
    },
    {
      "arxiv_id": "2402.05963v1",
      "title": "Frugal Actor-Critic: Sample Efficient Off-Policy Deep Reinforcement Learning Using Unique Experiences",
      "title_zh": "翻译失败",
      "authors": [
        "Nikhil Kumar Singh",
        "Indranil Saha"
      ],
      "abstract": "Efficient utilization of the replay buffer plays a significant role in the\noff-policy actor-critic reinforcement learning (RL) algorithms used for\nmodel-free control policy synthesis for complex dynamical systems. We propose a\nmethod for achieving sample efficiency, which focuses on selecting unique\nsamples and adding them to the replay buffer during the exploration with the\ngoal of reducing the buffer size and maintaining the independent and\nidentically distributed (IID) nature of the samples. Our method is based on\nselecting an important subset of the set of state variables from the\nexperiences encountered during the initial phase of random exploration,\npartitioning the state space into a set of abstract states based on the\nselected important state variables, and finally selecting the experiences with\nunique state-reward combination by using a kernel density estimator. We\nformally prove that the off-policy actor-critic algorithm incorporating the\nproposed method for unique experience accumulation converges faster than the\nvanilla off-policy actor-critic algorithm. Furthermore, we evaluate our method\nby comparing it with two state-of-the-art actor-critic RL algorithms on several\ncontinuous control benchmarks available in the Gym environment. Experimental\nresults demonstrate that our method achieves a significant reduction in the\nsize of the replay buffer for all the benchmarks while achieving either faster\nconvergent or better reward accumulation compared to the baseline algorithms.",
      "tldr_zh": "本文提出 Frugal Actor-Critic 方法，旨在提升 off-policy actor-critic 强化学习的样本效率，通过选择唯一 experiences 来优化 replay buffer 的利用，减少其大小并保持样本的 independent and identically distributed (IID) 性质。方法包括从初始随机探索中选取重要状态变量子集、基于这些变量分区状态空间，以及使用 kernel density estimator 筛选具有唯一状态-奖励组合的 experiences。理论证明表明，该方法使 off-policy actor-critic 算法收敛更快；实验在 Gym 环境的连续控制基准上显示，与现有 state-of-the-art 算法相比，replay buffer 尺寸显著降低，同时实现了更快收敛或更高的奖励积累。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.05963v1",
      "published_date": "2024-02-05 10:04:00 UTC",
      "updated_date": "2024-02-05 10:04:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:31:45.087983"
    },
    {
      "arxiv_id": "2402.04012v2",
      "title": "Quantized Approximately Orthogonal Recurrent Neural Networks",
      "title_zh": "量化近似正交循环神经网络",
      "authors": [
        "Armand Foucault",
        "Franck Mamalet",
        "François Malgouyres"
      ],
      "abstract": "In recent years, Orthogonal Recurrent Neural Networks (ORNNs) have gained\npopularity due to their ability to manage tasks involving long-term\ndependencies, such as the copy-task, and their linear complexity. However,\nexisting ORNNs utilize full precision weights and activations, which prevents\ntheir deployment on compact devices.In this paper, we explore the quantization\nof the weight matrices in ORNNs, leading to Quantized approximately Orthogonal\nRNNs (QORNNs). The construction of such networks remained an open problem,\nacknowledged for its inherent instability. We propose and investigate two\nstrategies to learn QORNN by combining quantization-aware training (QAT) and\northogonal projections. We also study post-training quantization of the\nactivations for pure integer computation of the recurrent loop. The most\nefficient models achieve results similar to state-of-the-art full-precision\nORNN, LSTM and FastRNN on a variety of standard benchmarks, even with 4-bits\nquantization.",
      "tldr_zh": "本研究探讨了正交循环神经网络 (ORNNs) 在处理长程依赖任务的优势，但其依赖全精度权重和激活，导致无法部署在紧凑设备上。论文提出量化近似正交 RNNs (QORNNs)，通过结合量化感知训练 (QAT) 和正交投影的两种策略，来学习量化后的权重矩阵，并研究激活的训练后量化以实现纯整数计算。这些方法确保了模型的稳定性，并在多种标准基准测试中，即使在 4 位量化下，QORNNs 的性能与全精度 ORNNs、LSTM 和 FastRNN 相当。总的来说，此工作为高效部署 ORNNs 提供了可行路径。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG",
        "eess.SP",
        "math.ST",
        "stat.TH"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.04012v2",
      "published_date": "2024-02-05 09:59:57 UTC",
      "updated_date": "2024-06-10 11:40:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:31:54.898905"
    },
    {
      "arxiv_id": "2402.02844v1",
      "title": "Comparing Knowledge Sources for Open-Domain Scientific Claim Verification",
      "title_zh": "开放域科学声明验证的知识来源比较",
      "authors": [
        "Juraj Vladika",
        "Florian Matthes"
      ],
      "abstract": "The increasing rate at which scientific knowledge is discovered and health\nclaims shared online has highlighted the importance of developing efficient\nfact-checking systems for scientific claims. The usual setting for this task in\nthe literature assumes that the documents containing the evidence for claims\nare already provided and annotated or contained in a limited corpus. This\nrenders the systems unrealistic for real-world settings where knowledge sources\nwith potentially millions of documents need to be queried to find relevant\nevidence. In this paper, we perform an array of experiments to test the\nperformance of open-domain claim verification systems. We test the final\nverdict prediction of systems on four datasets of biomedical and health claims\nin different settings. While keeping the pipeline's evidence selection and\nverdict prediction parts constant, document retrieval is performed over three\ncommon knowledge sources (PubMed, Wikipedia, Google) and using two different\ninformation retrieval techniques. We show that PubMed works better with\nspecialized biomedical claims, while Wikipedia is more suited for everyday\nhealth concerns. Likewise, BM25 excels in retrieval precision, while semantic\nsearch in recall of relevant evidence. We discuss the results, outline frequent\nretrieval patterns and challenges, and provide promising future directions.",
      "tldr_zh": "该论文比较了不同知识源在开放域科学声明验证中的性能，旨在解决证据检索在真实世界场景中的挑战。研究者通过实验在四个生物医学和健康声明数据集上测试系统，使用PubMed、Wikipedia和Google作为知识源，并采用BM25和语义搜索两种信息检索技术。结果显示，PubMed更适合专业生物医学声明，而Wikipedia更适用于日常健康问题；BM25在检索精度上表现优异，语义搜索则在相关证据召回方面更强。论文还讨论了常见检索模式、面临的挑战，并提出了未来改进方向。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to EACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.02844v1",
      "published_date": "2024-02-05 09:57:15 UTC",
      "updated_date": "2024-02-05 09:57:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:32:08.231865"
    },
    {
      "arxiv_id": "2402.02826v1",
      "title": "SynthVision -- Harnessing Minimal Input for Maximal Output in Computer Vision Models using Synthetic Image data",
      "title_zh": "翻译失败",
      "authors": [
        "Yudara Kularathne",
        "Prathapa Janitha",
        "Sithira Ambepitiya",
        "Thanveer Ahamed",
        "Dinuka Wijesundara",
        "Prarththanan Sothyrajah"
      ],
      "abstract": "Rapid development of disease detection computer vision models is vital in\nresponse to urgent medical crises like epidemics or events of bioterrorism.\nHowever, traditional data gathering methods are too slow for these scenarios\nnecessitating innovative approaches to generate reliable models quickly from\nminimal data. We demonstrate our new approach by building a comprehensive\ncomputer vision model for detecting Human Papilloma Virus Genital warts using\nonly synthetic data. In our study, we employed a two phase experimental design\nusing diffusion models. In the first phase diffusion models were utilized to\ngenerate a large number of diverse synthetic images from 10 HPV guide images\nexplicitly focusing on accurately depicting genital warts. The second phase\ninvolved the training and testing vision model using this synthetic dataset.\nThis method aimed to assess the effectiveness of diffusion models in rapidly\ngenerating high quality training data and the subsequent impact on the vision\nmodel performance in medical image recognition. The study findings revealed\nsignificant insights into the performance of the vision model trained on\nsynthetic images generated through diffusion models. The vision model showed\nexceptional performance in accurately identifying cases of genital warts. It\nachieved an accuracy rate of 96% underscoring its effectiveness in medical\nimage classification. For HPV cases the model demonstrated a high precision of\n99% and a recall of 94%. In normal cases the precision was 95% with an\nimpressive recall of 99%. These metrics indicate the model capability to\ncorrectly identify true positive cases and minimize false positives. The model\nachieved an F1 Score of 96% for HPV cases and 97% for normal cases. The high F1\nScore across both categories highlights the balanced nature of the model\nprecision and recall ensuring reliability and robustness in its predictions.",
      "tldr_zh": "这篇论文介绍了 SynthVision 方法，利用 synthetic data 和 diffusion models，从最小输入（如10张HPV指导图像）生成大量多样合成图像，以加速计算机视觉模型的开发，特别针对紧急医疗危机。研究采用两阶段实验设计：第一阶段使用 diffusion models 生成高质量合成数据集；第二阶段以此数据集训练和测试视觉模型，用于检测 Human Papilloma Virus (HPV) 生殖器疣。结果显示，模型在医疗图像识别中表现出色，准确率达96%，HPV病例的精确率99%、召回率94%、F1 Score为96%，而正常病例的F1 Score为97%，证明了这种方法在快速生成可靠模型方面的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "12 pages 5 figures 1 table",
      "pdf_url": "http://arxiv.org/pdf/2402.02826v1",
      "published_date": "2024-02-05 09:18:49 UTC",
      "updated_date": "2024-02-05 09:18:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:32:19.730761"
    },
    {
      "arxiv_id": "2402.02823v2",
      "title": "Evading Data Contamination Detection for Language Models is (too) Easy",
      "title_zh": "翻译失败",
      "authors": [
        "Jasper Dekoninck",
        "Mark Niklas Müller",
        "Maximilian Baader",
        "Marc Fischer",
        "Martin Vechev"
      ],
      "abstract": "Large language models are widespread, with their performance on benchmarks\nfrequently guiding user preferences for one model over another. However, the\nvast amount of data these models are trained on can inadvertently lead to\ncontamination with public benchmarks, thus compromising performance\nmeasurements. While recently developed contamination detection methods try to\naddress this issue, they overlook the possibility of deliberate contamination\nby malicious model providers aiming to evade detection. We argue that this\nsetting is of crucial importance as it casts doubt on the reliability of public\nbenchmarks. To more rigorously study this issue, we propose a categorization of\nboth model providers and contamination detection methods. This reveals\nvulnerabilities in existing methods that we exploit with EAL, a simple yet\neffective contamination technique that significantly inflates benchmark\nperformance while completely evading current detection methods.",
      "tldr_zh": "该研究探讨了大型语言模型（Large Language Models）在基准测试（Benchmarks）中的数据污染（Data Contamination）问题，指出现有检测方法忽略了恶意模型提供者故意规避检测的可能性，这质疑了公共基准的可靠性。作者提出了一种分类框架来区分模型提供者和污染检测方法，揭示了这些方法的漏洞。针对此，他们开发了EAL技术，这是一种简单有效的污染策略，能显著提升模型在基准测试上的性能，同时完全逃避当前检测方法。最终，该工作强调了加强检测机制的必要性，以确保基准测试的真实性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.02823v2",
      "published_date": "2024-02-05 09:10:32 UTC",
      "updated_date": "2024-02-12 17:50:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:32:30.103891"
    },
    {
      "arxiv_id": "2402.02805v2",
      "title": "Graph-enhanced Large Language Models in Asynchronous Plan Reasoning",
      "title_zh": "基于图增强的大型语言模型在异步计划推理中的应用",
      "authors": [
        "Fangru Lin",
        "Emanuele La Malfa",
        "Valentin Hofmann",
        "Elle Michelle Yang",
        "Anthony Cohn",
        "Janet B. Pierrehumbert"
      ],
      "abstract": "Planning is a fundamental property of human intelligence. Reasoning about\nasynchronous plans is challenging since it requires sequential and parallel\nplanning to optimize time costs. Can large language models (LLMs) succeed at\nthis task? Here, we present the first large-scale study investigating this\nquestion. We find that a representative set of closed and open-source LLMs,\nincluding GPT-4 and LLaMA-2, behave poorly when not supplied with illustrations\nabout the task-solving process in our benchmark AsyncHow. We propose a novel\ntechnique called Plan Like a Graph (PLaG) that combines graphs with natural\nlanguage prompts and achieves state-of-the-art results. We show that although\nPLaG can boost model performance, LLMs still suffer from drastic degradation\nwhen task complexity increases, highlighting the limits of utilizing LLMs for\nsimulating digital devices. We see our study as an exciting step towards using\nLLMs as efficient autonomous agents. Our code and data are available at\nhttps://github.com/fangru-lin/graph-llm-asynchow-plan.",
      "tldr_zh": "这篇论文研究了大型语言模型（LLMs）在异步规划推理中的性能，发现模型如 GPT-4 和 LLaMA-2 在基准 AsyncHow 上表现不佳，因为它们难以处理顺序和并行规划以优化时间成本。作者提出了 PLaG（Plan Like a Graph）技术，该方法结合图结构与自然语言提示，实现了最先进的性能提升。实验结果显示，虽然 PLaG 显著提高了模型准确率，但 LLMs 在任务复杂度增加时仍会大幅下降，突显了其在模拟数字设备方面的局限性。该研究为利用 LLMs 作为高效自治代理提供了关键见解，并公开了代码和数据。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at ICML-2024",
      "pdf_url": "http://arxiv.org/pdf/2402.02805v2",
      "published_date": "2024-02-05 08:26:33 UTC",
      "updated_date": "2024-06-03 13:07:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:32:43.540093"
    },
    {
      "arxiv_id": "2402.02803v2",
      "title": "Large Language Model Distilling Medication Recommendation Model",
      "title_zh": "大语言模型蒸馏药物推荐模型",
      "authors": [
        "Qidong Liu",
        "Xian Wu",
        "Xiangyu Zhao",
        "Yuanshao Zhu",
        "Zijian Zhang",
        "Feng Tian",
        "Yefeng Zheng"
      ],
      "abstract": "The recommendation of medication is a vital aspect of intelligent healthcare\nsystems, as it involves prescribing the most suitable drugs based on a\npatient's specific health needs. Unfortunately, many sophisticated models\ncurrently in use tend to overlook the nuanced semantics of medical data, while\nonly relying heavily on identities. Furthermore, these models face significant\nchallenges in handling cases involving patients who are visiting the hospital\nfor the first time, as they lack prior prescription histories to draw upon. To\ntackle these issues, we harness the powerful semantic comprehension and\ninput-agnostic characteristics of Large Language Models (LLMs). Our research\naims to transform existing medication recommendation methodologies using LLMs.\nIn this paper, we introduce a novel approach called Large Language Model\nDistilling Medication Recommendation (LEADER). We begin by creating appropriate\nprompt templates that enable LLMs to suggest medications effectively. However,\nthe straightforward integration of LLMs into recommender systems leads to an\nout-of-corpus issue specific to drugs. We handle it by adapting the LLMs with a\nnovel output layer and a refined tuning loss function. Although LLM-based\nmodels exhibit remarkable capabilities, they are plagued by high computational\ncosts during inference, which is impractical for the healthcare sector. To\nmitigate this, we have developed a feature-level knowledge distillation\ntechnique, which transfers the LLM's proficiency to a more compact model.\nExtensive experiments conducted on two real-world datasets, MIMIC-III and\nMIMIC-IV, demonstrate that our proposed model not only delivers effective\nresults but also is efficient. To ease the reproducibility of our experiments,\nwe release the implementation code online.",
      "tldr_zh": "本研究针对药物推荐模型存在的语义忽略和首次就诊患者处理难题，提出了一种名为LEADER的创新方法，利用Large Language Models (LLMs)提升推荐的语义理解和泛化能力。方法包括设计合适的提示模板、添加新输出层及精炼的调优损失函数来处理药物out-of-corpus问题，并通过特征级知识蒸馏技术将LLMs的能力转移到更紧凑的模型，以降低计算成本。在MIMIC-III和MIMIC-IV真实数据集上的实验显示，该模型表现出色且高效，并开源代码以便复现。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.02803v2",
      "published_date": "2024-02-05 08:25:22 UTC",
      "updated_date": "2025-01-27 04:30:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:32:53.980623"
    },
    {
      "arxiv_id": "2402.02801v2",
      "title": "KS-Lottery: Finding Certified Lottery Tickets for Multilingual Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Fei Yuan",
        "Chang Ma",
        "Shuai Yuan",
        "Qiushi Sun",
        "Lei Li"
      ],
      "abstract": "The lottery ticket hypothesis posits the existence of ``winning tickets''\nwithin a randomly initialized neural network. Do winning tickets exist for LLMs\nin fine-tuning scenarios? How can we find such winning tickets? In this paper,\nwe propose KS-Lottery, a method to identify a small subset of LLM parameters\nhighly effective in multilingual fine-tuning. Our key idea is to use\nKolmogorov-Smirnov Test to analyze the distribution shift of parameters before\nand after fine-tuning. We further theoretically prove that KS-Lottery can find\nthe certified winning tickets in the embedding layer, fine-tuning on the found\nparameters is guaranteed to perform as well as full fine-tuning. Comparing\nKS-Lottery with other parameter-efficient tuning algorithms on translation\ntasks, the experimental results show that KS-Lottery finds a much smaller set\nof parameters for fine-tuning while achieving the comparable performance as\nfull fine-tuning LLM. Surprisingly, we find that fine-tuning 18 tokens'\nembedding of LLaMA suffices to reach the fine-tuning translation\nperformance~\\footnote{https://github.com/CONE-MT/KS-Lottery.}.",
      "tldr_zh": "本文提出KS-Lottery方法，利用Kolmogorov-Smirnov Test分析参数在多语言语言模型(LLMs)微调前后分布的偏移，从而识别出高度有效的参数子集，即certified winning tickets。理论证明显示，该方法能在embedding layer找到这些winning tickets，确保仅微调这些参数即可达到与全微调相当的性能。在翻译任务的实验中，KS-Lottery比其他参数高效调优算法更节省参数，仅微调LLaMA的18个tokens的embedding就实现了可比性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.02801v2",
      "published_date": "2024-02-05 08:19:56 UTC",
      "updated_date": "2024-06-03 07:35:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:33:07.092953"
    },
    {
      "arxiv_id": "2402.02791v4",
      "title": "PanGu-$π$ Pro:Rethinking Optimization and Architecture for Tiny Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yehui Tang",
        "Kai Han",
        "Fangcheng Liu",
        "Yunsheng Ni",
        "Yuchuan Tian",
        "Zheyuan Bai",
        "Yi-Qi Hu",
        "Sichao Liu",
        "Shangling Jui",
        "Yunhe Wang"
      ],
      "abstract": "The power of large language models (LLMs) has been demonstrated through\nnumerous data and computing resources. However, the application of language\nmodels on mobile devices is facing huge challenge on the computation and memory\ncosts, that is, tiny language models with high performance are urgently\nrequired. Limited by the highly complex training process, there are many\ndetails for optimizing language models that are seldom studied carefully. In\nthis study, based on a tiny language model with 1B parameters, we carefully\ndesign a series of empirical study to analyze the effect of each component.\nThree perspectives are mainly discussed, \\ie, neural architecture, parameter\ninitialization, and optimization strategy. Several design formulas are\nempirically proved especially effective for tiny language models, including\ntokenizer compression, architecture tweaking, parameter inheritance and\nmultiple-round training. Then we train PanGu-$\\pi$-1B Pro and PanGu-$\\pi$-1.5B\nPro on 1.6T multilingual corpora, following the established formulas.\nExperimental results demonstrate the improved optimization and architecture\nyield a notable average improvement of 8.87 on benchmark evaluation sets for\nPanGu-$\\pi$-1B Pro. Besides, PanGu-$\\pi$-1.5B Pro surpasses a range of SOTA\nmodels with larger model sizes, validating its superior performance. The code\nis available at https://github.com/YuchuanTian/RethinkTinyLM.",
      "tldr_zh": "本研究重新审视了微型语言模型（tiny language models）的优化和架构设计，以应对大型语言模型（LLMs）在移动设备上计算和内存成本的挑战。作者基于一个1B参数的模型，进行实证研究，分析神经架构、参数初始化和优化策略的影响，并证明tokenizer compression、architecture tweaking、parameter inheritance和multiple-round training等设计公式特别有效。随后，他们训练了PanGu-$π$-1B Pro和PanGu-$π$-1.5B Pro，使用1.6T多语言语料，实验结果显示PanGu-$π$-1B Pro在基准评估集上平均提升8.87%，而PanGu-$π$-1.5B Pro超越了更大规模的SOTA模型，展示了其优越性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.02791v4",
      "published_date": "2024-02-05 07:59:38 UTC",
      "updated_date": "2025-04-03 02:13:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:33:20.889893"
    },
    {
      "arxiv_id": "2402.02781v1",
      "title": "Dual Knowledge Distillation for Efficient Sound Event Detection",
      "title_zh": "双重知识蒸馏用于高效的声音事件检测",
      "authors": [
        "Yang Xiao",
        "Rohan Kumar Das"
      ],
      "abstract": "Sound event detection (SED) is essential for recognizing specific sounds and\ntheir temporal locations within acoustic signals. This becomes challenging\nparticularly for on-device applications, where computational resources are\nlimited. To address this issue, we introduce a novel framework referred to as\ndual knowledge distillation for developing efficient SED systems in this work.\nOur proposed dual knowledge distillation commences with temporal-averaging\nknowledge distillation (TAKD), utilizing a mean student model derived from the\ntemporal averaging of the student model's parameters. This allows the student\nmodel to indirectly learn from a pre-trained teacher model, ensuring a stable\nknowledge distillation. Subsequently, we introduce embedding-enhanced feature\ndistillation (EEFD), which involves incorporating an embedding distillation\nlayer within the student model to bolster contextual learning. On DCASE 2023\nTask 4A public evaluation dataset, our proposed SED system with dual knowledge\ndistillation having merely one-third of the baseline model's parameters,\ndemonstrates superior performance in terms of PSDS1 and PSDS2. This highlights\nthe importance of proposed dual knowledge distillation for compact SED systems,\nwhich can be ideal for edge devices.",
      "tldr_zh": "该论文针对声事件检测（Sound Event Detection, SED）在设备上计算资源有限的挑战，提出了一种双重知识蒸馏框架，以开发高效的SED系统。该框架包括temporal-averaging knowledge distillation (TAKD)，通过学生模型参数的temporal averaging实现从预训练教师模型的稳定学习；以及embedding-enhanced feature distillation (EEFD)，在学生模型中添加嵌入蒸馏层以增强上下文学习。在DCASE 2023 Task 4A数据集上，该系统仅使用基线模型三分之一的参数，却在PSDS1和PSDS2指标上表现出色，证明了其适用于边缘设备的潜力。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted to ICASSP 2024 (Deep Neural Network Model Compression\n  Workshop)",
      "pdf_url": "http://arxiv.org/pdf/2402.02781v1",
      "published_date": "2024-02-05 07:30:32 UTC",
      "updated_date": "2024-02-05 07:30:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:33:33.064023"
    },
    {
      "arxiv_id": "2402.10228v5",
      "title": "Q-Star Meets Scalable Posterior Sampling: Bridging Theory and Practice via HyperAgent",
      "title_zh": "翻译失败",
      "authors": [
        "Yingru Li",
        "Jiawei Xu",
        "Lei Han",
        "Zhi-Quan Luo"
      ],
      "abstract": "We propose HyperAgent, a reinforcement learning (RL) algorithm based on the\nhypermodel framework for exploration in RL. HyperAgent allows for the efficient\nincremental approximation of posteriors associated with an optimal action-value\nfunction ($Q^\\star$) without the need for conjugacy and follows the greedy\npolicies w.r.t. these approximate posterior samples. We demonstrate that\nHyperAgent offers robust performance in large-scale deep RL benchmarks. It can\nsolve Deep Sea hard exploration problems with episodes that optimally scale\nwith problem size and exhibits significant efficiency gains in the Atari suite.\nImplementing HyperAgent requires minimal code addition to well-established deep\nRL frameworks like DQN. We theoretically prove that, under tabular assumptions,\nHyperAgent achieves logarithmic per-step computational complexity while\nattaining sublinear regret, matching the best known randomized tabular RL\nalgorithm.",
      "tldr_zh": "我们提出 HyperAgent，一种基于 hypermodel 框架的强化学习 (RL) 算法，用于高效探索和近似最优动作价值函数 ($Q^\\star$) 的后验分布，而无需共轭假设，并采用贪婪策略。实验结果显示，该算法在 Deep Sea 难题中实现了与问题规模最佳匹配的 episode 数量，并在 Atari 套件中表现出显著效率提升，同时只需在现有框架如 DQN 中添加少量代码。理论上，HyperAgent 在表格假设下达到了每步对数计算复杂度和次线性遗憾，与已知最佳随机表格 RL 算法相当。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Proceedings of the $\\mathit{41}^{st}$ International Conference on\n  Machine Learning, Vienna, Austria. PMLR 235, 2024. Copyright 2024 by the\n  author(s). Invited talk in Informs Optimization Conference 2024 and\n  International Symposium on Mathematical Programming 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.10228v5",
      "published_date": "2024-02-05 07:07:30 UTC",
      "updated_date": "2024-06-14 04:51:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:33:44.926457"
    },
    {
      "arxiv_id": "2402.02769v3",
      "title": "Learning from Teaching Regularization: Generalizable Correlations Should be Easy to Imitate",
      "title_zh": "翻译失败",
      "authors": [
        "Can Jin",
        "Tong Che",
        "Hongwu Peng",
        "Yiyuan Li",
        "Dimitris N. Metaxas",
        "Marco Pavone"
      ],
      "abstract": "Generalization remains a central challenge in machine learning. In this work,\nwe propose Learning from Teaching (LoT), a novel regularization technique for\ndeep neural networks to enhance generalization. Inspired by the human ability\nto capture concise and abstract patterns, we hypothesize that generalizable\ncorrelations are expected to be easier to imitate. LoT operationalizes this\nconcept to improve the generalization of the main model with auxiliary student\nlearners. The student learners are trained by the main model and, in turn,\nprovide feedback to help the main model capture more generalizable and imitable\ncorrelations. Our experimental results across several domains, including\nComputer Vision, Natural Language Processing, and methodologies like\nReinforcement Learning, demonstrate that the introduction of LoT brings\nsignificant benefits compared to training models on the original dataset. The\nresults suggest the effectiveness and efficiency of LoT in identifying\ngeneralizable information at the right scales while discarding spurious data\ncorrelations, thus making LoT a valuable addition to current machine learning.\nCode is available at https://github.com/jincan333/LoT.",
      "tldr_zh": "本研究提出了一种名为 Learning from Teaching (LoT) 的新正则化技术，旨在提升深度神经网络的泛化能力，通过假设可泛化的相关性更容易模仿来实现。LoT 方法利用辅助学生学习器，由主模型训练学生学习器并接收其反馈，帮助主模型捕捉更抽象和通用的模式，同时过滤虚假数据相关性。在计算机视觉、自然语言处理和强化学习等领域的实验中，LoT 显著优于直接训练方法，证明了其在识别有效泛化信息方面的有效性和效率。代码已在 GitHub 上公开，可供进一步应用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.02769v3",
      "published_date": "2024-02-05 07:05:17 UTC",
      "updated_date": "2024-10-31 06:17:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:33:56.087996"
    },
    {
      "arxiv_id": "2402.02768v1",
      "title": "Intent Profiling and Translation Through Emergent Communication",
      "title_zh": "基于涌现通信的意图分析与翻译",
      "authors": [
        "Salwa Mostafa",
        "Mohammed S. Elbamby",
        "Mohamed K. Abdel-Aziz",
        "Mehdi Bennis"
      ],
      "abstract": "To effectively express and satisfy network application requirements,\nintent-based network management has emerged as a promising solution. In\nintent-based methods, users and applications express their intent in a\nhigh-level abstract language to the network. Although this abstraction\nsimplifies network operation, it induces many challenges to efficiently express\napplications' intents and map them to different network capabilities.\nTherefore, in this work, we propose an AI-based framework for intent profiling\nand translation. We consider a scenario where applications interacting with the\nnetwork express their needs for network services in their domain language. The\nmachine-to-machine communication (i.e., between applications and the network)\nis complex since it requires networks to learn how to understand the domain\nlanguages of each application, which is neither practical nor scalable.\nInstead, a framework based on emergent communication is proposed for intent\nprofiling, in which applications express their abstract quality-of-experience\n(QoE) intents to the network through emergent communication messages.\nSubsequently, the network learns how to interpret these communication messages\nand map them to network capabilities (i.e., slices) to guarantee the requested\nQuality-of-Service (QoS). Simulation results show that the proposed method\noutperforms self-learning slicing and other baselines, and achieves a\nperformance close to the perfect knowledge baseline.",
      "tldr_zh": "本研究针对意图型网络管理（intent-based network management）中的挑战，提出了一种基于 emergent communication 的 AI 框架，用于意图剖析（intent profiling）和翻译。框架允许应用使用其领域语言表达抽象的 Quality-of-Experience (QoE) 意图，通过 emergent communication 消息与网络进行通信，从而避免网络学习每个应用的语言带来的复杂性和不可扩展性。网络随后学习解读这些消息，并将其映射到网络能力（如 slices），以确保所需的 Quality-of-Service (QoS)。模拟结果表明，该方法优于自学习切片和其他基线，性能接近完美知识基线。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.02768v1",
      "published_date": "2024-02-05 07:02:43 UTC",
      "updated_date": "2024-02-05 07:02:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:34:07.315101"
    },
    {
      "arxiv_id": "2402.02764v1",
      "title": "List-aware Reranking-Truncation Joint Model for Search and Retrieval-augmented Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Shicheng Xu",
        "Liang Pang",
        "Jun Xu",
        "Huawei Shen",
        "Xueqi Cheng"
      ],
      "abstract": "The results of information retrieval (IR) are usually presented in the form\nof a ranked list of candidate documents, such as web search for humans and\nretrieval-augmented generation for large language models (LLMs). List-aware\nretrieval aims to capture the list-level contextual features to return a better\nlist, mainly including reranking and truncation. Reranking finely re-scores the\ndocuments in the list. Truncation dynamically determines the cut-off point of\nthe ranked list to achieve the trade-off between overall relevance and avoiding\nmisinformation from irrelevant documents. Previous studies treat them as two\nseparate tasks and model them separately. However, the separation is not\noptimal. First, it is hard to share the contextual information of the ranking\nlist between the two tasks. Second, the separate pipeline usually meets the\nerror accumulation problem, where the small error from the reranking stage can\nlargely affect the truncation stage. To solve these problems, we propose a\nReranking-Truncation joint model (GenRT) that can perform the two tasks\nconcurrently. GenRT integrates reranking and truncation via generative paradigm\nbased on encoder-decoder architecture. We also design the novel loss functions\nfor joint optimization to make the model learn both tasks. Sharing parameters\nby the joint model is conducive to making full use of the common modeling\ninformation of the two tasks. Besides, the two tasks are performed concurrently\nand co-optimized to solve the error accumulation problem between separate\nstages. Experiments on public learning-to-rank benchmarks and open-domain Q\\&A\ntasks show that our method achieves SOTA performance on both reranking and\ntruncation tasks for web search and retrieval-augmented LLMs.",
      "tldr_zh": "本文提出 GenRT，一种联合模型，用于信息检索（IR）的 reranking（重新排序文档）和 truncation（动态截断列表）任务，以优化列表级上下文特征并避免传统分离方法中的错误积累问题。该模型采用编码器-解码器架构，通过生成范式同时执行两个任务，并设计新型损失函数进行联合优化，实现参数共享和信息充分利用。实验在公共学习到排序基准和开放域 Q&A 任务上表明，GenRT 在 web search 和检索增强 LLMs（大语言模型）场景下，均达到 SOTA（最先进）性能。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "Accepted by WWW 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.02764v1",
      "published_date": "2024-02-05 06:52:53 UTC",
      "updated_date": "2024-02-05 06:52:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:34:19.968888"
    },
    {
      "arxiv_id": "2402.06147v2",
      "title": "DeAL: Decoding-time Alignment for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "James Y. Huang",
        "Sailik Sengupta",
        "Daniele Bonadiman",
        "Yi-an Lai",
        "Arshit Gupta",
        "Nikolaos Pappas",
        "Saab Mansour",
        "Katrin Kirchhoff",
        "Dan Roth"
      ],
      "abstract": "Large Language Models (LLMs) are nowadays expected to generate content\naligned with human preferences. Current work focuses on alignment at model\ntraining time, through techniques such as Reinforcement Learning with Human\nFeedback (RLHF). However, it is unclear if such methods are an effective choice\nto teach alignment objectives to the model. First, the inability to incorporate\nmultiple, custom rewards and reliance on a model developer's view of universal\nand static principles are key limitations. Second, the residual gaps in model\ntraining and the reliability of such approaches are also questionable (e.g.\nsusceptibility to jail-breaking even after safety training). To address these,\nwe propose DeAL, a framework that allows the user to customize reward functions\nand enables Decoding-time Alignment of LLMs (DeAL). At its core, we view\ndecoding as a heuristic-guided search process and facilitate the use of a wide\nvariety of alignment objectives. Our experiments with programmatic constraints\nsuch as keyword and length constraints (studied widely in the pre-LLM era) and\nabstract objectives such as harmlessness and helpfulness (proposed in the\npost-LLM era) show that we can DeAL with fine-grained trade-offs, improve\nadherence to alignment objectives, and address residual gaps in LLMs. Lastly,\nwhile DeAL can be effectively paired with RLHF and prompting techniques, its\ngenerality makes decoding slower, an optimization we leave for future work.",
      "tldr_zh": "该研究批评了现有的大语言模型(LLMs)对齐方法，如基于人类反馈的强化学习(Reinforcement Learning with Human Feedback, RLHF)，指出其在处理自定义奖励和残差问题方面的局限性。论文提出DeAL框架，通过将解码过程视为启发式引导的搜索机制，允许用户自定义奖励函数，并在解码时实现LLMs的对齐。实验结果显示，DeAL能有效处理程序化约束（如关键词和长度限制）以及抽象目标（如无害性和帮助性），显著提升模型对对齐目标的遵守，尽管会增加解码时间，需要进一步优化。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "The appendix contains data that is offensive / disturbing in nature",
      "pdf_url": "http://arxiv.org/pdf/2402.06147v2",
      "published_date": "2024-02-05 06:12:29 UTC",
      "updated_date": "2024-02-21 02:25:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:34:31.761650"
    },
    {
      "arxiv_id": "2402.05127v1",
      "title": "Illuminate: A novel approach for depression detection with explainable analysis and proactive therapy using prompt engineering",
      "title_zh": "翻译失败",
      "authors": [
        "Aryan Agrawal"
      ],
      "abstract": "This paper introduces a novel paradigm for depression detection and treatment\nusing advanced Large Language Models (LLMs): Generative Pre-trained Transformer\n4 (GPT-4), Llama 2 chat, and Gemini. These LLMs are fine-tuned with specialized\nprompts to diagnose, explain, and suggest therapeutic interventions for\ndepression. A unique few-shot prompting method enhances the models' ability to\nanalyze and explain depressive symptoms based on the DSM-5 criteria. In the\ninteraction phase, the models engage in empathetic dialogue management, drawing\nfrom resources like PsychDB and a Cognitive Behavioral Therapy (CBT) Guide,\nfostering supportive interactions with individuals experiencing major\ndepressive disorders. Additionally, the research introduces the Illuminate\nDatabase, enriched with various CBT modules, aiding in personalized therapy\nrecommendations. The study evaluates LLM performance using metrics such as F1\nscores, Precision, Recall, Cosine similarity, and Recall-Oriented Understudy\nfor Gisting Evaluation (ROUGE) across different test sets, demonstrating their\neffectiveness. This comprehensive approach blends cutting-edge AI with\nestablished psychological methods, offering new possibilities in mental health\ncare and showcasing the potential of LLMs in revolutionizing depression\ndiagnosis and treatment strategies.",
      "tldr_zh": "这篇论文提出了一种名为Illuminate的新方法，利用LLMs（如GPT-4、Llama 2 chat和Gemini）结合prompt engineering，实现抑郁检测的可解释分析和主动治疗建议。方法包括few-shot prompting基于DSM-5标准分析症状，并通过PsychDB和CBT Guide资源进行移情对话管理，以及引入Illuminate Database提供个性化CBT模块。实验评估使用F1 scores、Precision、Recall、Cosine similarity和ROUGE等指标，证明了该方法在不同测试集上的有效性，并展示了AI在心理健康领域的革命性潜力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages, 9 figures, 9 tables",
      "pdf_url": "http://arxiv.org/pdf/2402.05127v1",
      "published_date": "2024-02-05 06:08:06 UTC",
      "updated_date": "2024-02-05 06:08:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:34:44.921699"
    },
    {
      "arxiv_id": "2402.02733v4",
      "title": "ToonAging: Face Re-Aging upon Artistic Portrait Style Transfer",
      "title_zh": "翻译失败",
      "authors": [
        "Bumsoo Kim",
        "Abdul Muqeet",
        "Kyuchul Lee",
        "Sanghyun Seo"
      ],
      "abstract": "Face re-aging is a prominent field in computer vision and graphics, with\nsignificant applications in photorealistic domains such as movies, advertising,\nand live streaming. Recently, the need to apply face re-aging to\nnon-photorealistic images, like comics, illustrations, and animations, has\nemerged as an extension in various entertainment sectors. However, the lack of\na network that can seamlessly edit the apparent age in NPR images has limited\nthese tasks to a naive, sequential approach. This often results in unpleasant\nartifacts and a loss of facial attributes due to domain discrepancies. In this\npaper, we introduce a novel one-stage method for face re-aging combined with\nportrait style transfer, executed in a single generative step. We leverage\nexisting face re-aging and style transfer networks, both trained within the\nsame PR domain. Our method uniquely fuses distinct latent vectors, each\nresponsible for managing aging-related attributes and NPR appearance. By\nadopting an exemplar-based approach, our method offers greater flexibility\ncompared to domain-level fine-tuning approaches, which typically require\nseparate training or fine-tuning for each domain. This effectively addresses\nthe limitation of requiring paired datasets for re-aging and domain-level,\ndata-driven approaches for stylization. Our experiments show that our model can\neffortlessly generate re-aged images while simultaneously transferring the\nstyle of examples, maintaining both natural appearance and controllability.",
      "tldr_zh": "本论文提出 ToonAging，一种创新的一阶段方法，将 face re-aging 与 artistic portrait style transfer 结合，在单个生成步骤中处理非真实感图像（如漫画和动画）的面部重龄化问题。该方法通过融合管理老化相关属性和 NPR 外观的独立潜在向量，利用现有在 photorealistic 域训练的网络，避免了传统顺序方法导致的伪影和面部属性丢失。相比域级微调，该基于示例的方法更灵活，无需配对数据集或单独训练。实验结果表明，ToonAging 能生成自然外观且可控的风格转移图像，提升了娱乐领域的应用潜力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at CVPR 2024 AI4CC Workshop, Project Page:\n  https://gh-bumsookim.github.io/ToonAging/",
      "pdf_url": "http://arxiv.org/pdf/2402.02733v4",
      "published_date": "2024-02-05 05:25:33 UTC",
      "updated_date": "2024-05-28 05:00:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:34:57.115124"
    },
    {
      "arxiv_id": "2402.02732v1",
      "title": "A Generative Approach to Surrogate-based Black-box Attacks",
      "title_zh": "翻译失败",
      "authors": [
        "Raha Moraffah",
        "Huan Liu"
      ],
      "abstract": "Surrogate-based black-box attacks have exposed the heightened vulnerability\nof DNNs. These attacks are designed to craft adversarial examples for any\nsamples with black-box target feedback for only a given set of samples.\nState-of-the-art surrogate-based attacks involve training a discriminative\nsurrogate that mimics the target's outputs. The goal is to learn the decision\nboundaries of the target. The surrogate is then attacked by white-box attacks\nto craft adversarial examples similar to the original samples but belong to\nother classes. With limited samples, the discriminative surrogate fails to\naccurately learn the target's decision boundaries, and these surrogate-based\nattacks suffer from low success rates. Different from the discriminative\napproach, we propose a generative surrogate that learns the distribution of\nsamples residing on or close to the target's decision boundaries. The\ndistribution learned by the generative surrogate can be used to craft\nadversarial examples that have imperceptible differences from the original\nsamples but belong to other classes. The proposed generative approach results\nin attacks with remarkably high attack success rates on various targets and\ndatasets.",
      "tldr_zh": "现有基于代理的黑盒攻击通常采用判别式 surrogate 来模仿目标模型的决策边界，但当样本数量有限时，这些攻击的成功率较低。作者提出了一种生成式 surrogate 方法，通过学习样本分布（尤其是位于或接近目标决策边界的样本），生成与原样本差异微小的 adversarial examples，同时使其属于其他类。该方法在各种目标模型和数据集上实现了显著更高的攻击成功率，暴露了 DNNs 的更高脆弱性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.02732v1",
      "published_date": "2024-02-05 05:22:58 UTC",
      "updated_date": "2024-02-05 05:22:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:35:07.310195"
    },
    {
      "arxiv_id": "2402.02718v1",
      "title": "Denoising Time Cycle Modeling for Recommendation",
      "title_zh": "翻译失败",
      "authors": [
        "Sicong Xie",
        "Qunwei Li",
        "Weidi Xu",
        "Kaiming Shen",
        "Shaohu Chen",
        "Wenliang Zhong"
      ],
      "abstract": "Recently, modeling temporal patterns of user-item interactions have attracted\nmuch attention in recommender systems. We argue that existing methods ignore\nthe variety of temporal patterns of user behaviors. We define the subset of\nuser behaviors that are irrelevant to the target item as noises, which limits\nthe performance of target-related time cycle modeling and affect the\nrecommendation performance. In this paper, we propose Denoising Time Cycle\nModeling (DiCycle), a novel approach to denoise user behaviors and select the\nsubset of user behaviors that are highly related to the target item. DiCycle is\nable to explicitly model diverse time cycle patterns for recommendation.\nExtensive experiments are conducted on both public benchmarks and a real-world\ndataset, demonstrating the superior performance of DiCycle over the\nstate-of-the-art recommendation methods.",
      "tldr_zh": "现有推荐系统中，用户行为的时间模式多样性常被忽略，导致与目标物品无关的行为（如噪音）影响模型性能。论文提出Denoising Time Cycle Modeling (DiCycle)方法，通过去除噪音并选择与目标物品高度相关的用户行为子集，来显式建模多样化的时间周期模式。实验结果显示，DiCycle在公共基准和真实世界数据集上优于最先进的方法，提升了推荐系统的整体表现。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.02718v1",
      "published_date": "2024-02-05 04:28:08 UTC",
      "updated_date": "2024-02-05 04:28:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:35:19.224704"
    },
    {
      "arxiv_id": "2402.02716v1",
      "title": "Understanding the planning of LLM agents: A survey",
      "title_zh": "翻译失败",
      "authors": [
        "Xu Huang",
        "Weiwen Liu",
        "Xiaolong Chen",
        "Xingmei Wang",
        "Hao Wang",
        "Defu Lian",
        "Yasheng Wang",
        "Ruiming Tang",
        "Enhong Chen"
      ],
      "abstract": "As Large Language Models (LLMs) have shown significant intelligence, the\nprogress to leverage LLMs as planning modules of autonomous agents has\nattracted more attention. This survey provides the first systematic view of\nLLM-based agents planning, covering recent works aiming to improve planning\nability. We provide a taxonomy of existing works on LLM-Agent planning, which\ncan be categorized into Task Decomposition, Plan Selection, External Module,\nReflection and Memory. Comprehensive analyses are conducted for each direction,\nand further challenges for the field of research are discussed.",
      "tldr_zh": "这篇调查论文系统地审视了大型语言模型 (LLMs) 作为自主代理规划模块的进展，提供了首个对 LLM 代理规划能力的系统性概述。论文将现有工作分类为任务分解 (Task Decomposition)、计划选择 (Plan Selection)、外部模块 (External Module)、反思 (Reflection) 和记忆 (Memory)，并对每个类别进行了全面分析。最终，论文讨论了该研究领域的进一步挑战，以推动 LLM 代理规划的改进。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "9 pages, 2 tables, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.02716v1",
      "published_date": "2024-02-05 04:25:24 UTC",
      "updated_date": "2024-02-05 04:25:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:35:31.251938"
    },
    {
      "arxiv_id": "2402.02713v2",
      "title": "Position: What Can Large Language Models Tell Us about Time Series Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Ming Jin",
        "Yifan Zhang",
        "Wei Chen",
        "Kexin Zhang",
        "Yuxuan Liang",
        "Bin Yang",
        "Jindong Wang",
        "Shirui Pan",
        "Qingsong Wen"
      ],
      "abstract": "Time series analysis is essential for comprehending the complexities inherent\nin various realworld systems and applications. Although large language models\n(LLMs) have recently made significant strides, the development of artificial\ngeneral intelligence (AGI) equipped with time series analysis capabilities\nremains in its nascent phase. Most existing time series models heavily rely on\ndomain knowledge and extensive model tuning, predominantly focusing on\nprediction tasks. In this paper, we argue that current LLMs have the potential\nto revolutionize time series analysis, thereby promoting efficient\ndecision-making and advancing towards a more universal form of time series\nanalytical intelligence. Such advancement could unlock a wide range of\npossibilities, including time series modality switching and question answering.\nWe encourage researchers and practitioners to recognize the potential of LLMs\nin advancing time series analysis and emphasize the need for trust in these\nrelated efforts. Furthermore, we detail the seamless integration of time series\nanalysis with existing LLM technologies and outline promising avenues for\nfuture research.",
      "tldr_zh": "本论文探讨大型语言模型（LLMs）在时间序列分析中的潜力，指出现有时间序列模型过度依赖领域知识和调优，主要限于预测任务。作者认为LLMs可革新这一领域，推动高效决策和通用分析智能的实现，包括时间序列模态切换和问答功能。论文强调信任LLMs的潜力，并详细说明其与现有LLM技术的无缝整合以及未来研究方向。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by the 41st International Conference on Machine Learning\n  (ICML 2024)",
      "pdf_url": "http://arxiv.org/pdf/2402.02713v2",
      "published_date": "2024-02-05 04:17:49 UTC",
      "updated_date": "2024-06-01 06:42:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:35:43.863620"
    },
    {
      "arxiv_id": "2402.09453v1",
      "title": "Improving EEG Signal Classification Accuracy Using Wasserstein Generative Adversarial Networks",
      "title_zh": "使用 Wasserstein 生成对抗网络提高 EEG 信号分类准确性",
      "authors": [
        "Joshua Park",
        "Priyanshu Mahey",
        "Ore Adeniyi"
      ],
      "abstract": "Electroencephalography (EEG) plays a vital role in recording brain activities\nand is integral to the development of brain-computer interface (BCI)\ntechnologies. However, the limited availability and high variability of EEG\nsignals present substantial challenges in creating reliable BCIs. To address\nthis issue, we propose a practical solution drawing on the latest developments\nin deep learning and Wasserstein Generative Adversarial Network (WGAN). The\nWGAN was trained on the BCI2000 dataset, consisting of around 1500 EEG\nrecordings and 64 channels from 45 individuals. The generated EEG signals were\nevaluated via three classifiers yielding improved average accuracies. The\nquality of generated signals measured using Frechet Inception Distance (FID)\nyielded scores of 1.345 and 11.565 for eyes-open and closed respectively. Even\nwithout a spectral or spatial loss term, our WGAN model was able to emulate the\nspectral and spatial properties of the EEG training data. The WGAN-generated\ndata mirrored the dominant alpha activity during closed-eye resting and high\ndelta waves in the training data in its topographic map and power spectral\ndensity (PSD) plot. Our research testifies to the potential of WGANs in\naddressing the limited EEG data issue for BCI development by enhancing a small\ndataset to improve classifier generalizability.",
      "tldr_zh": "本研究针对 EEG（脑电图）信号数据有限且变异性高的挑战，提出使用 Wasserstein Generative Adversarial Networks (WGAN) 生成合成信号，以提升脑机接口 (BCI) 分类器的准确率。WGAN 模型在 BCI2000 数据集上训练，该数据集包含约 1500 个 EEG 记录、64 通道和 45 个个体，生成的信号通过三个分类器评估，平均准确率得到改善，且 Frechet Inception Distance (FID) 得分分别为眼睛睁开 1.345 和闭眼 11.565。结果显示，WGAN 即使没有光谱或空间损失项，也能有效模拟 EEG 的光谱和空间特性，如闭眼时的 alpha 活动和 delta 波，从而增强小数据集的泛化能力，为 BCI 技术发展提供实用解决方案。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "11 pages, 2 tables, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.09453v1",
      "published_date": "2024-02-05 03:57:30 UTC",
      "updated_date": "2024-02-05 03:57:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:35:58.411819"
    },
    {
      "arxiv_id": "2402.06656v1",
      "title": "DiffsFormer: A Diffusion Transformer on Stock Factor Augmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Yuan Gao",
        "Haokun Chen",
        "Xiang Wang",
        "Zhicai Wang",
        "Xue Wang",
        "Jinyang Gao",
        "Bolin Ding"
      ],
      "abstract": "Machine learning models have demonstrated remarkable efficacy and efficiency\nin a wide range of stock forecasting tasks. However, the inherent challenges of\ndata scarcity, including low signal-to-noise ratio (SNR) and data homogeneity,\npose significant obstacles to accurate forecasting. To address this issue, we\npropose a novel approach that utilizes artificial intelligence-generated\nsamples (AIGS) to enhance the training procedures. In our work, we introduce\nthe Diffusion Model to generate stock factors with Transformer architecture\n(DiffsFormer). DiffsFormer is initially trained on a large-scale source domain,\nincorporating conditional guidance so as to capture global joint distribution.\nWhen presented with a specific downstream task, we employ DiffsFormer to\naugment the training procedure by editing existing samples. This editing step\nallows us to control the strength of the editing process, determining the\nextent to which the generated data deviates from the target domain. To evaluate\nthe effectiveness of DiffsFormer augmented training, we conduct experiments on\nthe CSI300 and CSI800 datasets, employing eight commonly used machine learning\nmodels. The proposed method achieves relative improvements of 7.2% and 27.8% in\nannualized return ratio for the respective datasets. Furthermore, we perform\nextensive experiments to gain insights into the functionality of DiffsFormer\nand its constituent components, elucidating how they address the challenges of\ndata scarcity and enhance the overall model performance. Our research\ndemonstrates the efficacy of leveraging AIGS and the DiffsFormer architecture\nto mitigate data scarcity in stock forecasting tasks.",
      "tldr_zh": "该论文针对股票预测中的数据稀缺、低信噪比 (SNR) 和数据同质性问题，提出了一种新型框架 DiffsFormer，该框架结合 Diffusion Model 和 Transformer 架构，通过人工智能生成样本 (AIGS) 来增强训练过程。DiffsFormer 先在大型源域上训练以捕获全局联合分布，然后通过编辑现有样本并控制编辑强度，来为下游任务生成相关股票因子 (stock factors)。实验结果显示，在 CSI300 和 CSI800 数据集上，使用八种常见机器学习模型，该方法分别实现了 7.2% 和 27.8% 的年化回报率提升，证明了其在缓解数据稀缺问题和提升模型性能方面的有效性。",
      "categories": [
        "q-fin.ST",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-fin.ST",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.06656v1",
      "published_date": "2024-02-05 03:54:36 UTC",
      "updated_date": "2024-02-05 03:54:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:36:09.618985"
    },
    {
      "arxiv_id": "2402.02705v2",
      "title": "Representation Surgery for Multi-Task Model Merging",
      "title_zh": "翻译失败",
      "authors": [
        "Enneng Yang",
        "Li Shen",
        "Zhenyi Wang",
        "Guibing Guo",
        "Xiaojun Chen",
        "Xingwei Wang",
        "Dacheng Tao"
      ],
      "abstract": "Multi-task learning (MTL) compresses the information from multiple tasks into\na unified backbone to improve computational efficiency and generalization.\nRecent work directly merges multiple independently trained models to perform\nMTL instead of collecting their raw data for joint training, greatly expanding\nthe application scenarios of MTL. However, by visualizing the representation\ndistribution of existing model merging schemes, we find that the merged model\noften suffers from the dilemma of representation bias. That is, there is a\nsignificant discrepancy in the representation distribution between the merged\nand individual models, resulting in poor performance of merged MTL. In this\npaper, we propose a representation surgery solution called \"Surgery\" to reduce\nrepresentation bias in the merged model. Specifically, Surgery is a lightweight\ntask-specific module that takes the representation of the merged model as input\nand attempts to output the biases contained in the representation from the\nmerged model. We then designed an unsupervised optimization objective that\nupdates the Surgery module by minimizing the distance between the merged\nmodel's representation and the individual model's representation. Extensive\nexperiments demonstrate significant MTL performance improvements when our\nSurgery module is applied to state-of-the-art (SOTA) model merging schemes.",
      "tldr_zh": "该论文探讨了多任务学习 (MTL) 中的模型合并问题，发现现有方案常因表示偏差 (representation bias) 而导致合并模型性能下降。作者提出了一种名为 \"Surgery\" 的轻量级任务特定模块，该模块以合并模型的表示为输入，输出并减少其中的偏差，并通过无监督优化目标最小化合并模型与单个模型表示之间的距离。实验结果显示，在多种 state-of-the-art (SOTA) 模型合并方案上应用 \"Surgery\" 后，MTL 性能得到显著提升。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Forty-first International Conference on Machine Learning (ICML 2024)",
      "pdf_url": "http://arxiv.org/pdf/2402.02705v2",
      "published_date": "2024-02-05 03:39:39 UTC",
      "updated_date": "2024-05-28 09:35:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:36:18.690583"
    },
    {
      "arxiv_id": "2402.02701v2",
      "title": "Understanding What Affects the Generalization Gap in Visual Reinforcement Learning: Theory and Empirical Evidence",
      "title_zh": "理解什么影响了视觉强化学习中的泛化差距：理论和实证证据",
      "authors": [
        "Jiafei Lyu",
        "Le Wan",
        "Xiu Li",
        "Zongqing Lu"
      ],
      "abstract": "Recently, there are many efforts attempting to learn useful policies for\ncontinuous control in visual reinforcement learning (RL). In this scenario, it\nis important to learn a generalizable policy, as the testing environment may\ndiffer from the training environment, e.g., there exist distractors during\ndeployment. Many practical algorithms are proposed to handle this problem.\nHowever, to the best of our knowledge, none of them provide a theoretical\nunderstanding of what affects the generalization gap and why their proposed\nmethods work. In this paper, we bridge this issue by theoretically answering\nthe key factors that contribute to the generalization gap when the testing\nenvironment has distractors. Our theories indicate that minimizing the\nrepresentation distance between training and testing environments, which aligns\nwith human intuition, is the most critical for the benefit of reducing the\ngeneralization gap. Our theoretical results are supported by the empirical\nevidence in the DMControl Generalization Benchmark (DMC-GB).",
      "tldr_zh": "这篇论文探讨了在 visual reinforcement learning 中影响泛化差距的关键因素，特别是当测试环境存在干扰物时。论文通过理论分析表明，最重要的策略是最小化训练和测试环境之间表示距离，这与人类直觉相符，并解释了为什么现有算法有效。实证证据来自 DMControl Generalization Benchmark 的实验，支持了这些理论结果，为提升 visual reinforcement learning 的泛化性能提供了指导。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by Journal of Artificial Intelligence Research (JAIR)",
      "pdf_url": "http://arxiv.org/pdf/2402.02701v2",
      "published_date": "2024-02-05 03:27:52 UTC",
      "updated_date": "2024-10-16 08:12:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:36:31.949894"
    },
    {
      "arxiv_id": "2402.02698v1",
      "title": "Beyond Expectations: Learning with Stochastic Dominance Made Practical",
      "title_zh": "翻译失败",
      "authors": [
        "Shicong Cen",
        "Jincheng Mei",
        "Hanjun Dai",
        "Dale Schuurmans",
        "Yuejie Chi",
        "Bo Dai"
      ],
      "abstract": "Stochastic dominance models risk-averse preferences for decision making with\nuncertain outcomes, which naturally captures the intrinsic structure of the\nunderlying uncertainty, in contrast to simply resorting to the expectations.\nDespite theoretically appealing, the application of stochastic dominance in\nmachine learning has been scarce, due to the following challenges:\n$\\textbf{i)}$, the original concept of stochastic dominance only provides a\n$\\textit{partial order}$, therefore, is not amenable to serve as an optimality\ncriterion; and $\\textbf{ii)}$, an efficient computational recipe remains\nlacking due to the continuum nature of evaluating stochastic dominance.%, which\nbarriers its application for machine learning.\n  In this work, we make the first attempt towards establishing a general\nframework of learning with stochastic dominance. We first generalize the\nstochastic dominance concept to enable feasible comparisons between any\narbitrary pair of random variables. We next develop a simple and\ncomputationally efficient approach for finding the optimal solution in terms of\nstochastic dominance, which can be seamlessly plugged into many learning tasks.\nNumerical experiments demonstrate that the proposed method achieves comparable\nperformance as standard risk-neutral strategies and obtains better trade-offs\nagainst risk across a variety of applications including supervised learning,\nreinforcement learning, and portfolio optimization.",
      "tldr_zh": "这篇论文提出了一种实用的学习框架，使用随机主导（Stochastic Dominance）来处理不确定性决策中的风险厌恶偏好，该方法捕捉不确定性的内在结构，而非仅依赖期望值。论文首先解决随机主导的挑战，通过泛化其概念，使任意一对随机变量可比，并开发了一个简单高效的优化方法，可无缝整合到监督学习、强化学习和投资组合优化等任务中。实验结果显示，该方法与标准风险中性策略性能相当，并在风险权衡上取得了更好的 tradeoff，证明了其在实际应用中的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.02698v1",
      "published_date": "2024-02-05 03:21:23 UTC",
      "updated_date": "2024-02-05 03:21:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:36:43.212112"
    },
    {
      "arxiv_id": "2402.02696v1",
      "title": "Causal Feature Selection for Responsible Machine Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Raha Moraffah",
        "Paras Sheth",
        "Saketh Vishnubhatla",
        "Huan Liu"
      ],
      "abstract": "Machine Learning (ML) has become an integral aspect of many real-world\napplications. As a result, the need for responsible machine learning has\nemerged, focusing on aligning ML models to ethical and social values, while\nenhancing their reliability and trustworthiness. Responsible ML involves many\nissues. This survey addresses four main issues: interpretability, fairness,\nadversarial robustness, and domain generalization. Feature selection plays a\npivotal role in the responsible ML tasks. However, building upon statistical\ncorrelations between variables can lead to spurious patterns with biases and\ncompromised performance. This survey focuses on the current study of causal\nfeature selection: what it is and how it can reinforce the four aspects of\nresponsible ML. By identifying features with causal impacts on outcomes and\ndistinguishing causality from correlation, causal feature selection is posited\nas a unique approach to ensuring ML models to be ethically and socially\nresponsible in high-stakes applications.",
      "tldr_zh": "这篇调研论文探讨了因果特征选择（Causal Feature Selection）在负责任机器学习（Responsible Machine Learning）中的关键作用，旨在解决传统基于统计相关性的特征选择可能带来的偏差和性能问题。论文关注四个主要方面：interpretability（可解释性）、fairness（公平性）、adversarial robustness（对抗鲁棒性）和domain generalization（领域泛化）。通过识别特征的因果影响而非简单相关性，因果特征选择可提升ML模型的可靠性和可信度，最终为高风险应用中的伦理和社会责任提供独特方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.02696v1",
      "published_date": "2024-02-05 03:20:28 UTC",
      "updated_date": "2024-02-05 03:20:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:36:56.820801"
    },
    {
      "arxiv_id": "2402.02695v2",
      "title": "Exploiting Class Probabilities for Black-box Sentence-level Attacks",
      "title_zh": "利用类概率进行黑盒句子级攻击",
      "authors": [
        "Raha Moraffah",
        "Huan Liu"
      ],
      "abstract": "Sentence-level attacks craft adversarial sentences that are synonymous with\ncorrectly-classified sentences but are misclassified by the text classifiers.\nUnder the black-box setting, classifiers are only accessible through their\nfeedback to queried inputs, which is predominately available in the form of\nclass probabilities. Even though utilizing class probabilities results in\nstronger attacks, due to the challenges of using them for sentence-level\nattacks, existing attacks use either no feedback or only the class labels.\nOvercoming the challenges, we develop a novel algorithm that uses class\nprobabilities for black-box sentence-level attacks, investigate the\neffectiveness of using class probabilities on the attack's success, and examine\nthe question if it is worthy or practical to use class probabilities by\nblack-box sentence-level attacks. We conduct extensive evaluations of our\nattack comparing with the baselines across various classifiers and benchmark\ndatasets.",
      "tldr_zh": "本研究探讨了在黑盒环境中利用类 probabilities 进行句级 attacks（sentence-level attacks），旨在创建与正确分类句子同义但被分类器误分类的对抗句子。作者开发了一个新算法，克服了使用类 probabilities 的挑战，并评估了其对攻击成功率的影响，同时考察了这种方法的实用性。通过在各种分类器和基准数据集上的广泛实验，与基线方法比较，证明了该算法的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "EACL 2024 Findings",
      "pdf_url": "http://arxiv.org/pdf/2402.02695v2",
      "published_date": "2024-02-05 03:15:26 UTC",
      "updated_date": "2024-02-21 00:09:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:37:07.478672"
    },
    {
      "arxiv_id": "2402.02687v1",
      "title": "Poisson Process for Bayesian Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaoxing Wang",
        "Jiaxing Li",
        "Chao Xue",
        "Wei Liu",
        "Weifeng Liu",
        "Xiaokang Yang",
        "Junchi Yan",
        "Dacheng Tao"
      ],
      "abstract": "BayesianOptimization(BO) is a sample-efficient black-box optimizer, and\nextensive methods have been proposed to build the absolute function response of\nthe black-box function through a probabilistic surrogate model, including\nTree-structured Parzen Estimator (TPE), random forest (SMAC), and Gaussian\nprocess (GP). However, few methods have been explored to estimate the relative\nrankings of candidates, which can be more robust to noise and have better\npracticality than absolute function responses, especially when the function\nresponses are intractable but preferences can be acquired. To this end, we\npropose a novel ranking-based surrogate model based on the Poisson process and\nintroduce an efficient BO framework, namely Poisson Process Bayesian\nOptimization (PoPBO). Two tailored acquisition functions are further derived\nfrom classic LCB and EI to accommodate it. Compared to the classic GP-BO\nmethod, our PoPBO has lower computation costs and better robustness to noise,\nwhich is verified by abundant experiments. The results on both simulated and\nreal-world benchmarks, including hyperparameter optimization (HPO) and neural\narchitecture search (NAS), show the effectiveness of PoPBO.",
      "tldr_zh": "本研究提出了一种基于Poisson Process的排名-based代理模型，用于Bayesian Optimization (BO)，以估计候选者的相对排名，从而比传统关注绝对响应的方法（如TPE、SMAC和Gaussian Process (GP)）更鲁棒于噪声，尤其适用于函数响应难以获取但偏好可用的场景。PoPBO框架结合Poisson Process构建了新型代理模型，并设计了基于LCB和EI的定制采集函数，以提升优化效率。与GP-BO相比，PoPBO计算成本更低且对噪声更具鲁棒性。实验在模拟和真实基准上，包括hyperparameter optimization (HPO)和neural architecture search (NAS)，验证了其有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.02687v1",
      "published_date": "2024-02-05 02:54:50 UTC",
      "updated_date": "2024-02-05 02:54:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:37:20.121367"
    },
    {
      "arxiv_id": "2402.06655v1",
      "title": "Adversarial Text Purification: A Large Language Model Approach for Defense",
      "title_zh": "对抗文本净化：一种大语言模型方法用于防御",
      "authors": [
        "Raha Moraffah",
        "Shubh Khandelwal",
        "Amrita Bhattacharjee",
        "Huan Liu"
      ],
      "abstract": "Adversarial purification is a defense mechanism for safeguarding classifiers\nagainst adversarial attacks without knowing the type of attacks or training of\nthe classifier. These techniques characterize and eliminate adversarial\nperturbations from the attacked inputs, aiming to restore purified samples that\nretain similarity to the initially attacked ones and are correctly classified\nby the classifier. Due to the inherent challenges associated with\ncharacterizing noise perturbations for discrete inputs, adversarial text\npurification has been relatively unexplored. In this paper, we investigate the\neffectiveness of adversarial purification methods in defending text\nclassifiers. We propose a novel adversarial text purification that harnesses\nthe generative capabilities of Large Language Models (LLMs) to purify\nadversarial text without the need to explicitly characterize the discrete noise\nperturbations. We utilize prompt engineering to exploit LLMs for recovering the\npurified examples for given adversarial examples such that they are\nsemantically similar and correctly classified. Our proposed method demonstrates\nremarkable performance over various classifiers, improving their accuracy under\nthe attack by over 65% on average.",
      "tldr_zh": "该论文提出了一种名为Adversarial Text Purification的新防御机制，利用Large Language Models (LLMs)来保护文本分类器免受对抗性攻击，而无需显式表征离散噪声扰动。方法通过Prompt Engineering引导LLMs生成语义相似的纯净文本样本，从而恢复对抗性示例并确保其正确分类。与传统方法不同，该框架不依赖于攻击类型或分类器训练细节。实验结果显示，该方法在多种分类器上将攻击下的准确率平均提高了65%以上，为文本领域对抗性防御提供了高效解决方案。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "PAKDD 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.06655v1",
      "published_date": "2024-02-05 02:36:41 UTC",
      "updated_date": "2024-02-05 02:36:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:37:31.302975"
    },
    {
      "arxiv_id": "2402.02681v3",
      "title": "Equivariant Symmetry Breaking Sets",
      "title_zh": "等变对称性破缺集合",
      "authors": [
        "YuQing Xie",
        "Tess Smidt"
      ],
      "abstract": "Equivariant neural networks (ENNs) have been shown to be extremely effective\nin applications involving underlying symmetries. By construction ENNs cannot\nproduce lower symmetry outputs given a higher symmetry input. However, symmetry\nbreaking occurs in many physical systems and we may obtain a less symmetric\nstable state from an initial highly symmetric one. Hence, it is imperative that\nwe understand how to systematically break symmetry in ENNs. In this work, we\npropose a novel symmetry breaking framework that is fully equivariant and is\nthe first which fully addresses spontaneous symmetry breaking. We emphasize\nthat our approach is general and applicable to equivariance under any group. To\nachieve this, we introduce the idea of symmetry breaking sets (SBS). Rather\nthan redesign existing networks, we design sets of symmetry breaking objects\nwhich we feed into our network based on the symmetry of our inputs and outputs.\nWe show there is a natural way to define equivariance on these sets, which\ngives an additional constraint. Minimizing the size of these sets equates to\ndata efficiency. We prove that minimizing these sets translates to a well\nstudied group theory problem, and tabulate solutions to this problem for the\npoint groups. Finally, we provide some examples of symmetry breaking to\ndemonstrate how our approach works in practice. The code for these examples is\navailable at \\url{https://github.com/atomicarchitects/equivariant-SBS}.",
      "tldr_zh": "本研究针对 Equivariant Neural Networks (ENNs) 在处理对称性破缺时存在的局限性，提出了一种新型框架，用于系统地实现对称性破缺。该框架基于 Symmetry Breaking Sets (SBS)，通过设计一组对称性破缺对象并根据输入和输出的对称性喂入网络，确保整个过程保持等变性（equivariance），并首次全面解决自发对称性破缺问题。研究证明，SBS 的最小化等同于一个经典的群论问题，并为点群提供了解决方案，从而提升了数据效率。最后，通过实际例子演示了框架的应用，并公开了相关代码。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "50 pages, 19 figures Published in Transactions on Machine Learning\n  Research, October 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.02681v3",
      "published_date": "2024-02-05 02:35:11 UTC",
      "updated_date": "2024-11-14 16:30:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:37:45.732558"
    },
    {
      "arxiv_id": "2402.02680v2",
      "title": "Large Language Models are Geographically Biased",
      "title_zh": "大型语言模型存在地理偏差",
      "authors": [
        "Rohin Manvi",
        "Samar Khanna",
        "Marshall Burke",
        "David Lobell",
        "Stefano Ermon"
      ],
      "abstract": "Large Language Models (LLMs) inherently carry the biases contained in their\ntraining corpora, which can lead to the perpetuation of societal harm. As the\nimpact of these foundation models grows, understanding and evaluating their\nbiases becomes crucial to achieving fairness and accuracy. We propose to study\nwhat LLMs know about the world we live in through the lens of geography. This\napproach is particularly powerful as there is ground truth for the numerous\naspects of human life that are meaningfully projected onto geographic space\nsuch as culture, race, language, politics, and religion. We show various\nproblematic geographic biases, which we define as systemic errors in geospatial\npredictions. Initially, we demonstrate that LLMs are capable of making accurate\nzero-shot geospatial predictions in the form of ratings that show strong\nmonotonic correlation with ground truth (Spearman's $\\rho$ of up to 0.89). We\nthen show that LLMs exhibit common biases across a range of objective and\nsubjective topics. In particular, LLMs are clearly biased against locations\nwith lower socioeconomic conditions (e.g. most of Africa) on a variety of\nsensitive subjective topics such as attractiveness, morality, and intelligence\n(Spearman's $\\rho$ of up to 0.70). Finally, we introduce a bias score to\nquantify this and find that there is significant variation in the magnitude of\nbias across existing LLMs. Code is available on the project website:\nhttps://rohinmanvi.github.io/GeoLLM",
      "tldr_zh": "这篇论文揭示了 Large Language Models (LLMs) 在地理空间预测中存在的系统性偏见，这些偏见源于训练数据，可能加剧社会不公。研究通过地理视角评估 LLMs 对文化、种族和经济等因素的理解，发现模型能在零-shot 条件下进行准确预测（Spearman's ρ 高达 0.89），但对低 socioeconomic 地区（如非洲）表现出负面偏见，尤其在主观话题如吸引力、道德和智力上（Spearman's ρ 高达 0.70）。为了量化偏见，论文引入了 bias score，并比较了不同 LLMs 的偏见程度差异。该工作强调了评估和减轻 LLMs 地理偏见的重要性，以提升模型的公平性和准确性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.02680v2",
      "published_date": "2024-02-05 02:32:09 UTC",
      "updated_date": "2024-10-05 18:20:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:37:57.207128"
    },
    {
      "arxiv_id": "2402.02675v2",
      "title": "Verifiable evaluations of machine learning models using zkSNARKs",
      "title_zh": "翻译失败",
      "authors": [
        "Tobin South",
        "Alexander Camuto",
        "Shrey Jain",
        "Shayla Nguyen",
        "Robert Mahari",
        "Christian Paquin",
        "Jason Morton",
        "Alex 'Sandy' Pentland"
      ],
      "abstract": "In a world of increasing closed-source commercial machine learning models,\nmodel evaluations from developers must be taken at face value. These benchmark\nresults-whether over task accuracy, bias evaluations, or safety checks-are\ntraditionally impossible to verify by a model end-user without the costly or\nimpossible process of re-performing the benchmark on black-box model outputs.\nThis work presents a method of verifiable model evaluation using model\ninference through zkSNARKs. The resulting zero-knowledge computational proofs\nof model outputs over datasets can be packaged into verifiable evaluation\nattestations showing that models with fixed private weights achieve stated\nperformance or fairness metrics over public inputs. We present a flexible\nproving system that enables verifiable attestations to be performed on any\nstandard neural network model with varying compute requirements. For the first\ntime, we demonstrate this across a sample of real-world models and highlight\nkey challenges and design solutions. This presents a new transparency paradigm\nin the verifiable evaluation of private models.",
      "tldr_zh": "本研究针对封闭源代码机器学习模型的评估问题，提出了一种使用 zkSNARKs 的可验证评估方法，以解决用户无法独立验证基准结果（如任务准确率、偏差评估或安全检查）的挑战。该方法通过零-knowledge computational proofs 对模型输出进行证明，生成可验证的评估证明，证明固定私有权重的模型在公共输入上达到了指定的性能或公平性指标。研究开发了一个灵活的证明系统，并首次在真实世界模型上进行了演示，突出了关键挑战（如计算需求）和设计解决方案，最终为私有模型的透明评估带来新的范式。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "68T01"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.02675v2",
      "published_date": "2024-02-05 02:21:11 UTC",
      "updated_date": "2024-05-22 17:36:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:38:08.392872"
    },
    {
      "arxiv_id": "2402.02658v2",
      "title": "Multi-step Problem Solving Through a Verifier: An Empirical Analysis on Model-induced Process Supervision",
      "title_zh": "翻译失败",
      "authors": [
        "Zihan Wang",
        "Yunxuan Li",
        "Yuexin Wu",
        "Liangchen Luo",
        "Le Hou",
        "Hongkun Yu",
        "Jingbo Shang"
      ],
      "abstract": "Process supervision, using a trained verifier to evaluate the intermediate\nsteps generated by a reasoner, has demonstrated significant improvements in\nmulti-step problem solving. In this paper, to avoid the expensive effort of\nhuman annotation on the verifier training data, we introduce Model-induced\nProcess Supervision (MiPS), a novel method for automating data curation. MiPS\nannotates an intermediate step by sampling completions of this solution through\nthe reasoning model, and obtaining an accuracy defined as the proportion of\ncorrect completions. Inaccuracies of the reasoner would cause MiPS\nunderestimating the accuracy of intermediate steps, therefore, we suggest and\nempirically show that verification focusing on high predicted scores of the\nverifier shall be preferred over that of low predicted scores, contrary to\nprior observations on human curated data. Our approach significantly improves\nthe performance of PaLM 2 on math and coding tasks (accuracy +0.67% on GSM8K,\n+4.16% on MATH, +0.92% on MBPP compared with an output supervision trained\nverifier). Additionally, our study demonstrates that the verifier exhibits\nstrong generalization ability across different reasoning models.",
      "tldr_zh": "本文提出 Model-induced Process Supervision (MiPS)，一种自动化方法，用于训练 verifier 评估多步问题解决中的中间步骤，从而避免昂贵的人类标注过程。MiPS 通过采样推理模型的完成解决方案并计算正确完成比例来标注数据，并发现优先关注 verifier 高预测分数的验证更有效，这与先前的人类数据观察相反。实验结果显示，MiPS 显著提升了 PaLM 2 在数学和编码任务上的性能，包括 GSM8K 准确率提高 0.67%、MATH 提高 4.16% 以及 MBPP 提高 0.92%。此外，该 verifier 展示了在不同推理模型上的强泛化能力。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.02658v2",
      "published_date": "2024-02-05 00:57:51 UTC",
      "updated_date": "2024-10-14 19:33:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:38:21.724433"
    },
    {
      "arxiv_id": "2402.02651v3",
      "title": "Vision-Language Models Provide Promptable Representations for Reinforcement Learning",
      "title_zh": "视觉语言模型为强化学习提供可提示的表示",
      "authors": [
        "William Chen",
        "Oier Mees",
        "Aviral Kumar",
        "Sergey Levine"
      ],
      "abstract": "Humans can quickly learn new behaviors by leveraging background world\nknowledge. In contrast, agents trained with reinforcement learning (RL)\ntypically learn behaviors from scratch. We thus propose a novel approach that\nuses the vast amounts of general and indexable world knowledge encoded in\nvision-language models (VLMs) pre-trained on Internet-scale data for embodied\nRL. We initialize policies with VLMs by using them as promptable\nrepresentations: embeddings that encode semantic features of visual\nobservations based on the VLM's internal knowledge and reasoning capabilities,\nas elicited through prompts that provide task context and auxiliary\ninformation. We evaluate our approach on visually-complex, long horizon RL\ntasks in Minecraft and robot navigation in Habitat. We find that our policies\ntrained on embeddings from off-the-shelf, general-purpose VLMs outperform\nequivalent policies trained on generic, non-promptable image embeddings. We\nalso find our approach outperforms instruction-following methods and performs\ncomparably to domain-specific embeddings. Finally, we show that our approach\ncan use chain-of-thought prompting to produce representations of common-sense\nsemantic reasoning, improving policy performance in novel scenes by 1.5 times.",
      "tldr_zh": "这篇论文提出了一种新方法，使用预训练的 Vision-Language Models (VLMs) 作为 promptable representations 来增强 Reinforcement Learning (RL) 代理的学习能力，旨在利用 VLMs 的互联网规模知识帮助代理快速适应新任务。方法通过提示提供任务上下文和辅助信息，生成视觉观察的语义嵌入，从而初始化 RL 策略，并在 Minecraft 和 Habitat 的视觉复杂长时序任务上进行评估。实验结果显示，该方法优于使用通用图像嵌入的策略，并通过 chain-of-thought 提示提升了在新场景下的性能 1.5 倍，展现出与领域特定嵌入相当的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.02651v3",
      "published_date": "2024-02-05 00:48:56 UTC",
      "updated_date": "2024-05-23 01:04:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:38:33.378531"
    },
    {
      "arxiv_id": "2402.02648v2",
      "title": "Recursive Chain-of-Feedback Prevents Performance Degradation from Redundant Prompting",
      "title_zh": "递归链式反馈防止冗余提示导致的性能退化",
      "authors": [
        "Jinwoo Ahn",
        "Kyuseung Shin"
      ],
      "abstract": "Large Language Models (LLMs) frequently struggle with complex reasoning\ntasks, failing to construct logically sound steps towards the solution. In\nresponse to this behavior, users often try prompting the LLMs repeatedly in\nhopes of reaching a better response. This paper studies such repetitive\nbehavior and its effect by defining a novel setting, Chain-of-Feedback (CoF).\nThe setting takes questions that require multi-step reasoning as an input. Upon\nresponse, we repetitively prompt meaningless feedback (e.g. 'make another\nattempt') requesting additional trials. Surprisingly, our preliminary results\nshow that repeated meaningless feedback gradually decreases the quality of the\nresponses, eventually leading to a larger deviation from the intended outcome.\nTo alleviate these troubles, we propose a novel method, Recursive\nChain-of-Feedback (R-CoF). Following the logic of recursion in computer\nscience, R-CoF recursively revises the initially incorrect response by breaking\ndown each incorrect reasoning step into smaller individual problems. Our\npreliminary results show that majority of questions that LLMs fail to respond\ncorrectly can be answered using R-CoF without any sample data outlining the\nlogical process.",
      "tldr_zh": "本研究发现，大语言模型 (LLMs) 在复杂推理任务中常因逻辑步骤不当而失败，用户重复提示（如无意义反馈）反而导致性能下降。论文引入 Chain-of-Feedback (CoF) 设置，通过反复提供无意义的反馈（如“再试一次”）来模拟这一行为，结果显示响应质量会逐渐恶化，并加大与预期结果的偏差。为解决此问题，研究提出 Recursive Chain-of-Feedback (R-CoF) 方法，该方法借鉴计算机科学递归逻辑，将错误推理步骤分解为更小的子问题进行逐步修正。初步实验表明，R-CoF 能在无需样本数据的情况下，帮助 LLMs 正确回答大多数原本失败的问题。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Still Ongoing Work; 8 Pages; 2 Figures",
      "pdf_url": "http://arxiv.org/pdf/2402.02648v2",
      "published_date": "2024-02-05 00:44:28 UTC",
      "updated_date": "2024-03-01 10:46:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:38:44.908855"
    },
    {
      "arxiv_id": "2402.05125v3",
      "title": "Zero-Shot Clinical Trial Patient Matching with LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Michael Wornow",
        "Alejandro Lozano",
        "Dev Dash",
        "Jenelle Jindal",
        "Kenneth W. Mahaffey",
        "Nigam H. Shah"
      ],
      "abstract": "Matching patients to clinical trials is a key unsolved challenge in bringing\nnew drugs to market. Today, identifying patients who meet a trial's eligibility\ncriteria is highly manual, taking up to 1 hour per patient. Automated screening\nis challenging, however, as it requires understanding unstructured clinical\ntext. Large language models (LLMs) offer a promising solution. In this work, we\nexplore their application to trial matching. First, we design an LLM-based\nsystem which, given a patient's medical history as unstructured clinical text,\nevaluates whether that patient meets a set of inclusion criteria (also\nspecified as free text). Our zero-shot system achieves state-of-the-art scores\non the n2c2 2018 cohort selection benchmark. Second, we improve the data and\ncost efficiency of our method by identifying a prompting strategy which matches\npatients an order of magnitude faster and more cheaply than the status quo, and\ndevelop a two-stage retrieval pipeline that reduces the number of tokens\nprocessed by up to a third while retaining high performance. Third, we evaluate\nthe interpretability of our system by having clinicians evaluate the natural\nlanguage justifications generated by the LLM for each eligibility decision, and\nshow that it can output coherent explanations for 97% of its correct decisions\nand 75% of its incorrect ones. Our results establish the feasibility of using\nLLMs to accelerate clinical trial operations.",
      "tldr_zh": "本研究探讨了使用大型语言模型(LLMs)实现零-shot临床试验患者匹配，以解决手动筛选的低效问题（如每位患者需1小时）。他们设计了一个基于LLMs的系统，能从非结构化临床文本中评估患者是否符合纳入标准，并在n2c2 2018基准上达到最先进成绩；同时，通过优化提示策略和两阶段检索管道，提高了处理速度和成本效率，减少了token处理量最多三分之一。实验结果显示，该系统能为97%的正确决定和75%的错误决定生成连贯的自然语言解释，证明了LLMs在加速临床试验操作方面的可行性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.05125v3",
      "published_date": "2024-02-05 00:06:08 UTC",
      "updated_date": "2024-04-10 05:37:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T03:38:56.651727"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 129,
  "processed_papers_count": 129,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-17T03:39:24.078668"
}