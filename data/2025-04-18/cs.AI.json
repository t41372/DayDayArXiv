{
  "date": "2025-04-18",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-04-18 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 论文主要聚焦 AI 模型的推理优化、多模态生成和应用扩展，重点包括大型语言模型（LLM）的认知机制、AI 辅助材料发现，以及跨领域强化学习和量子计算应用，令人印象深刻的文章有 Omar M. Yaghi 等知名学者参与的 AI 材料生成系统，以及 Pengfei Liu 领导的 LLM 测试时间扩展研究。\n\n### 重点论文讨论\n我们先聊聊 AI 和 LLM 领域的亮点论文，这些工作推动了模型的推理和生成能力，其次是计算机视觉和多代理系统，最后快速掠过其他领域的内容。\n\n**1. 代理AI系统用于金属有机框架的发现 (System of Agentic AI for the Discovery of Metal-Organic Frameworks)**  \n   主要贡献：提出 MOFGen 系统，由 AI 代理（如大语言模型和扩散模型）生成合成性强的 MOF 结构，用于 CO2 捕获和水收集；发现通过实验验证了数百种新 MOF 的可合成性，展示了 AI 在材料科学中的自动化潜力。\n\n**2. 走向可解释和轻量级 AI 用于边缘网络实时网络威胁狩猎 (Towards Explainable and Lightweight AI for Real-Time Cyber Threat Hunting in Edge Networks)**  \n   主要贡献：引入 ELAI 框架，结合可解释机器学习（如决策树）和轻量级深度学习，实现边缘网络的实时威胁检测；发现该框架在 CICIDS 和 UNSW-NB15 数据集上实现了高检测率和低计算需求，提升了 AI 在网络安全的部署。\n\n**3. Transformer 前向传递中的人类-like 处理特征 (Signatures of human-like processing in Transformer forward passes)**  \n   作者：Jennifer Hu 等。  \n   主要贡献：探索 Transformer 内部动态是否模仿人类认知，如竞争干扰；发现模型的前向动态比静态输出更能预测人类处理模式，并验证了更大模型并非总是更“人性化”。\n\n**9. LogicTree: 结构化证明探索用于 LLM 的连贯逻辑推理 (LogicTree: Structured Proof Exploration for Coherent and Rigorous Logical Reasoning with Large Language Models)**  \n   主要贡献：提出 LogicTree 框架，使用算法引导搜索和缓存机制优化 LLM 的逻辑推理；发现该方法在多个数据集上比 CoT 和 ToT 提升了 23.6% 的准确率，确保推理的连贯性。\n\n**17. 人类和大型语言模型中的元认知和不确定性通信 (Metacognition and Uncertainty Communication in Humans and Large Language Models)**  \n   作者：Mark Steyvers 等。  \n   主要贡献：比较人类和 LLM 的元认知能力，如自我评估和不确定性表达；发现 LLM 在某些方面与人类类似，但差异显著，强调提升 LLM 的元认知可改善人机协作。\n\n**25. 生成式 AI Act II: 测试时间扩展驱动认知工程 (Generative AI Act II: Test Time Scaling Drives Cognition Engineering)**  \n   作者：Pengfei Liu 等。  \n   主要贡献：讨论 LLM 从知识检索向思维构建的演变，通过测试时间扩展提升推理；发现此方法可加速 LLM 学习和适应，附带开源资源库。\n\n**6. 6G WavesFM: 用于感知、通信和定位的基础模型 (6G WavesFM: A Foundation Model for Sensing, Communication, and Localization)**  \n   主要贡献：开发 WavesFM 框架，使用 Vision Transformer 处理无线信号，支持 6G 任务；发现它在多个任务上比监督基线提升性能，同时共享 80% 参数，展示了高效的 AI-native 网络潜力。\n\n**14. Think Deep, Think Fast: 调查无验证器推理时间扩展方法的效率 (Think Deep, Think Fast: Investigating Efficiency of Verifier-free Inference-time-scaling Methods)**  \n   主要贡献：分析 LLM 的推理时间计算（如多数投票），发现多数投票策略在推理任务中更高效；发现正确响应通常更短，并优化了现有方法。\n\n**23. 强化学习是否真正激励 LLM 的推理能力？ (Does Reinforcement Learning Really Incentivize Reasoning Capacity in LLMs Beyond the Base Model?)**  \n   主要贡献：评估 RLVR 在 LLM 推理中的效果，发现它未真正引入新推理模式；发现蒸馏方法可扩展推理能力，强调 RL 范式的改进。\n\n**41. Causal pieces: 分析和改进基于尖峰神经网络 (Causal pieces: analysing and improving spiking neural networks piece by piece)**  \n   主要贡献：引入“因果片段”概念分析 SNN 的表达性和训练性；发现正权重 SNN 在基准任务上竞争性能，提供了 SNN 和 ANN 比较的新工具。\n\n其他相关论文，如计算机视觉领域：\n- **12. 遮挡有序语义实例分割 (Occlusion-Ordered Semantic Instance Segmentation)**  \n  主要贡献：联合处理相对深度和实例分割；发现基于遮挡边界的方法在 KINS 和 COCOA 数据集上提升了性能。\n- **20. LoftUp: 学习基于坐标的特征上采样器用于视觉基础模型 (LoftUp: Learning a Coordinate-Based Feature Upsampler for Vision Foundation Models)**  \n  主要贡献：提出坐标-based 上采样框架，提升视觉模型的分辨率；发现它在下游任务上优于现有方法。\n\n快速掠过其他领域论文（如量子计算、医疗图像和一般 AI 应用），这些工作虽有价值但较专业：\n- **11. A CMOS Probabilistic Computing Chip With In-situ hardware Aware Learning**：贡献了基于 440 尖峰的概率计算芯片，提升 AI 任务效率。\n- **21. Causal pieces: analysing and improving spiking neural networks piece by piece**：如上，已简要提及。\n- **39. Decoding Vision Transformers: the Diffusion Steering Lens**：改进了 Vision Transformer 的解释性，通过扩散引导。\n- **其余论文**，如财务数据分析、机器人路径规划和能源建模等，聚焦特定应用（如强化学习优化或数据增强），但未有突破性发现，故从略。\n\n总之，今天的论文突显 AI 模型的演进潜力，尤其在推理和多模态方面，值得关注后续应用。更多细节可查阅 arXiv！",
  "papers": [
    {
      "arxiv_id": "2504.14110v1",
      "title": "System of Agentic AI for the Discovery of Metal-Organic Frameworks",
      "title_zh": "翻译失败",
      "authors": [
        "Theo Jaffrelot Inizan",
        "Sherry Yang",
        "Aaron Kaplan",
        "Yen-hsu Lin",
        "Jian Yin",
        "Saber Mirzaei",
        "Mona Abdelgaid",
        "Ali H. Alawadhi",
        "KwangHwan Cho",
        "Zhiling Zheng",
        "Ekin Dogus Cubuk",
        "Christian Borgs",
        "Jennifer T. Chayes",
        "Kristin A. Persson",
        "Omar M. Yaghi"
      ],
      "abstract": "Generative models and machine learning promise accelerated material discovery\nin MOFs for CO2 capture and water harvesting but face significant challenges\nnavigating vast chemical spaces while ensuring synthetizability. Here, we\npresent MOFGen, a system of Agentic AI comprising interconnected agents: a\nlarge language model that proposes novel MOF compositions, a diffusion model\nthat generates crystal structures, quantum mechanical agents that optimize and\nfilter candidates, and synthetic-feasibility agents guided by expert rules and\nmachine learning. Trained on all experimentally reported MOFs and computational\ndatabases, MOFGen generated hundreds of thousands of novel MOF structures and\nsynthesizable organic linkers. Our methodology was validated through\nhigh-throughput experiments and the successful synthesis of five \"AI-dreamt\"\nMOFs, representing a major step toward automated synthesizable material\ndiscovery.",
      "tldr_zh": "该研究提出了一种名为 MOFGen 的 Agentic AI 系统，用于加速 Metal-Organic Frameworks (MOFs) 的发现，针对 CO2 捕获和水收集应用中生成模型面临的化学空间导航和合成性挑战。该系统由多个互联代理组成，包括大型语言模型 (large language model) 提出新型 MOF 组合、扩散模型 (diffusion model) 生成晶体结构、量子机械代理 (quantum mechanical agents) 优化和过滤候选物，以及合成可行性代理 (synthetic-feasibility agents) 通过专家规则和机器学习确保可合成性。训练于实验和计算数据库后，MOFGen 生成了数十万新型 MOF 结构和可合成有机连接体，并通过高通量实验成功合成五个“AI-dreamt” MOFs，推动了自动化合成材料发现的重大进展。",
      "categories": [
        "cond-mat.mtrl-sci",
        "cs.AI",
        "cs.CL",
        "cs.MA"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.14110v1",
      "published_date": "2025-04-18 23:54:25 UTC",
      "updated_date": "2025-04-18 23:54:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:18:36.759164"
    },
    {
      "arxiv_id": "2504.16118v1",
      "title": "Towards Explainable and Lightweight AI for Real-Time Cyber Threat Hunting in Edge Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Milad Rahmati"
      ],
      "abstract": "As cyber threats continue to evolve, securing edge networks has become\nincreasingly challenging due to their distributed nature and resource\nlimitations. Many AI-driven threat detection systems rely on complex deep\nlearning models, which, despite their high accuracy, suffer from two major\ndrawbacks: lack of interpretability and high computational cost. Black-box AI\nmodels make it difficult for security analysts to understand the reasoning\nbehind their predictions, limiting their practical deployment. Moreover,\nconventional deep learning techniques demand significant computational\nresources, rendering them unsuitable for edge devices with limited processing\npower. To address these issues, this study introduces an Explainable and\nLightweight AI (ELAI) framework designed for real-time cyber threat detection\nin edge networks. Our approach integrates interpretable machine learning\nalgorithms with optimized lightweight deep learning techniques, ensuring both\ntransparency and computational efficiency. The proposed system leverages\ndecision trees, attention-based deep learning, and federated learning to\nenhance detection accuracy while maintaining explainability. We evaluate ELAI\nusing benchmark cybersecurity datasets, such as CICIDS and UNSW-NB15, assessing\nits performance across diverse cyberattack scenarios. Experimental results\ndemonstrate that the proposed framework achieves high detection rates with\nminimal false positives, all while significantly reducing computational demands\ncompared to traditional deep learning methods. The key contributions of this\nwork include: (1) a novel interpretable AI-based cybersecurity model tailored\nfor edge computing environments, (2) an optimized lightweight deep learning\napproach for real-time cyber threat detection, and (3) a comprehensive analysis\nof explainability techniques in AI-driven cybersecurity applications.",
      "tldr_zh": "本研究针对边缘网络的分布式特性和资源限制，提出Explainable and Lightweight AI (ELAI)框架，以解决传统AI驱动威胁检测模型的可解释性不足和高计算成本问题。ELAI整合了decision trees、attention-based deep learning和federated learning等技术，实现实时网络威胁检测的同时，确保模型的透明度和高效性。在CICIDS和UNSW-NB15数据集上的实验显示，该框架实现了高检测率、低假阳性率，并显著降低了计算需求。关键贡献包括：(1) 针对边缘计算环境的创新可解释AI模型，(2) 优化轻量级深度学习方法用于实时检测，以及(3) 对AI在网络安全应用中可解释性的全面分析。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.16118v1",
      "published_date": "2025-04-18 23:45:39 UTC",
      "updated_date": "2025-04-18 23:45:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:18:49.286770"
    },
    {
      "arxiv_id": "2504.14107v2",
      "title": "Signatures of human-like processing in Transformer forward passes",
      "title_zh": "Transformer 前向传递中人类式处理的特征",
      "authors": [
        "Jennifer Hu",
        "Michael A. Lepori",
        "Michael Franke"
      ],
      "abstract": "Modern AI models are increasingly being used as theoretical tools to study\nhuman cognition. One dominant approach is to evaluate whether human-derived\nmeasures are predicted by a model's output: that is, the end-product of a\nforward pass. However, recent advances in mechanistic interpretability have\nbegun to reveal the internal processes that give rise to model outputs, raising\nthe question of whether models might use human-like processing strategies.\nHere, we investigate the relationship between real-time processing in humans\nand layer-time dynamics of computation in Transformers, testing 20 open-source\nmodels in 6 domains. We first explore whether forward passes show mechanistic\nsignatures of competitor interference, taking high-level inspiration from\ncognitive theories. We find that models indeed appear to initially favor a\ncompeting incorrect answer in the cases where we would expect decision conflict\nin humans. We then systematically test whether forward-pass dynamics predict\nsignatures of processing in humans, above and beyond properties of the model's\noutput probability distribution. We find that dynamic measures improve\nprediction of human processing measures relative to static final-layer\nmeasures. Moreover, across our experiments, larger models do not always show\nmore human-like processing patterns. Our work suggests a new way of using AI\nmodels to study human cognition: not just as a black box mapping stimuli to\nresponses, but potentially also as explicit processing models.",
      "tldr_zh": "该研究探索Transformer模型的前向传递（forward passes）是否显示出人类般的处理签名，通过测试20个开源模型在6个领域。研究者发现，模型在决策冲突场景中会像人类一样 initially favor a competing incorrect answer，并证明动态措施（如层级-时间动态）比静态最终层输出更好地预测人类处理签名。结果显示，larger models并不总是表现出更人类化的处理模式，这为将AI模型作为显式处理模型（explicit processing models）研究人类认知提供了新途径。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "under review",
      "pdf_url": "http://arxiv.org/pdf/2504.14107v2",
      "published_date": "2025-04-18 23:38:14 UTC",
      "updated_date": "2025-05-18 17:27:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:18:58.481749"
    },
    {
      "arxiv_id": "2504.14105v1",
      "title": "Amplify Initiative: Building A Localized Data Platform for Globalized AI",
      "title_zh": "翻译失败",
      "authors": [
        "Qazi Mamunur Rashid",
        "Erin van Liemt",
        "Tiffany Shih",
        "Amber Ebinama",
        "Karla Barrios Ramos",
        "Madhurima Maji",
        "Aishwarya Verma",
        "Charu Kalia",
        "Jamila Smith-Loud",
        "Joyce Nakatumba-Nabende",
        "Rehema Baguma",
        "Andrew Katumba",
        "Chodrine Mutebi",
        "Jagen Marvin",
        "Eric Peter Wairagala",
        "Mugizi Bruce",
        "Peter Oketta",
        "Lawrence Nderu",
        "Obichi Obiajunwa",
        "Abigail Oppong",
        "Michael Zimba",
        "Data Authors"
      ],
      "abstract": "Current AI models often fail to account for local context and language, given\nthe predominance of English and Western internet content in their training\ndata. This hinders the global relevance, usefulness, and safety of these models\nas they gain more users around the globe. Amplify Initiative, a data platform\nand methodology, leverages expert communities to collect diverse, high-quality\ndata to address the limitations of these models. The platform is designed to\nenable co-creation of datasets, provide access to high-quality multilingual\ndatasets, and offer recognition to data authors. This paper presents the\napproach to co-creating datasets with domain experts (e.g., health workers,\nteachers) through a pilot conducted in Sub-Saharan Africa (Ghana, Kenya,\nMalawi, Nigeria, and Uganda). In partnership with local researchers situated in\nthese countries, the pilot demonstrated an end-to-end approach to co-creating\ndata with 155 experts in sensitive domains (e.g., physicians, bankers,\nanthropologists, human and civil rights advocates). This approach, implemented\nwith an Android app, resulted in an annotated dataset of 8,091 adversarial\nqueries in seven languages (e.g., Luganda, Swahili, Chichewa), capturing\nnuanced and contextual information related to key themes such as misinformation\nand public interest topics. This dataset in turn can be used to evaluate models\nfor their safety and cultural relevance within the context of these languages.",
      "tldr_zh": "当前 AI 模型因训练数据以英语和西方内容为主，常常忽略本地上下文和语言，导致全球相关性、实用性和安全性不足。Amplify Initiative 是一个数据平台和方法，通过专家社区共同创建多样、高质量的多语言数据集，提供数据集访问和数据作者认可，以解决这些问题。该平台在撒哈拉以南非洲（包括加纳、肯尼亚、马拉维、尼日利亚和乌干达）的试点项目中，与当地研究者合作，涉及 155 名专家，使用 Android 应用收集了 8,091 个标注的对抗 queries，涵盖七种语言（如 Luganda、Swahili、Chichewa），用于评估 AI 模型的安全性和文化相关性。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.14105v1",
      "published_date": "2025-04-18 23:20:52 UTC",
      "updated_date": "2025-04-18 23:20:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:19:11.952967"
    },
    {
      "arxiv_id": "2504.14103v1",
      "title": "Coordinating Spinal and Limb Dynamics for Enhanced Sprawling Robot Mobility",
      "title_zh": "翻译失败",
      "authors": [
        "Merve Atasever",
        "Ali Okhovat",
        "Azhang Nazaripouya",
        "John Nisbet",
        "Omer Kurkutlu",
        "Jyotirmoy V. Deshmukh",
        "Yasemin Ozkan Aydin"
      ],
      "abstract": "Among vertebrates, salamanders, with their unique ability to transition\nbetween walking and swimming gaits, highlight the role of spinal mobility in\nlocomotion. A flexible spine enables undulation of the body through a wavelike\nmotion along the spine, aiding navigation over uneven terrains and obstacles.\nYet environmental uncertainties, such as surface irregularities and variations\nin friction, can significantly disrupt body-limb coordination and cause\ndiscrepancies between predictions from mathematical models and real-world\noutcomes. Addressing this challenge requires the development of sophisticated\ncontrol strategies capable of dynamically adapting to uncertain conditions\nwhile maintaining efficient locomotion. Deep reinforcement learning (DRL)\noffers a promising framework for handling non-deterministic environments and\nenabling robotic systems to adapt effectively and perform robustly under\nchallenging conditions. In this study, we comparatively examine learning-based\ncontrol strategies and biologically inspired gait design methods on a\nsalamander-like robot.",
      "tldr_zh": "这篇论文受脊椎动物（如蝾螈）启发，探讨了脊柱灵活性在增强散布式机器人移动性中的作用，特别是在面对环境不确定性（如表面不规则和摩擦变化）时如何协调脊柱和肢体动态。研究提出使用深度强化学习 (DRL) 作为一种适应性控制策略，来处理非确定性环境并实现高效运动。论文通过比较基于学习的控制方法和生物启发的步态设计方法，在一个类似蝾螈的机器人上进行实验，展示了这些策略在复杂地形上的潜在优势。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "The manuscript has been accepted for presentation at the Mechanical\n  Intelligence in Robotics workshop at ICRA 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.14103v1",
      "published_date": "2025-04-18 23:08:48 UTC",
      "updated_date": "2025-04-18 23:08:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:19:23.805524"
    },
    {
      "arxiv_id": "2504.14100v1",
      "title": "6G WavesFM: A Foundation Model for Sensing, Communication, and Localization",
      "title_zh": "6G WavesFM：用于感知、通信和定位的基础模型",
      "authors": [
        "Ahmed Aboulfotouh",
        "Elsayed Mohammed",
        "Hatem Abou-Zeid"
      ],
      "abstract": "This paper introduces WavesFM, a novel Wireless Foundation Model (WFM)\nframework, capable of supporting a wide array of communication, sensing, and\nlocalization tasks. Our proposed architecture combines a shared Vision\nTransformer (ViT) backbone with task-specific multi-layer perceptron (MLP)\nheads and incorporates Low-Rank Adaptation (LoRA) for parameter-efficient\nfine-tuning. This design promotes full parameter sharing across tasks,\nsignificantly reducing the computational and memory footprint without\nsacrificing performance. The model processes both image-like wireless\nmodalities, such as spectrograms and channel state information (CSI), and\nin-phase and quadrature (IQ) signals arranged as orthogonal frequency-division\nmultiplexing (OFDM) resource grids. We demonstrate the strong generalization\ncapabilities of WavesFM through extensive experiments on four downstream tasks:\nFifth Generation New Radio (5G NR) positioning; multiple-input multiple-output\nOFDM (MIMO-OFDM) channel estimation; human activity sensing; and\nradio-frequency (RF) signal classification. Compared to supervised baselines\ntrained individually, our approach achieves superior performance while sharing\n80% of its parameters across tasks. Furthermore, we show that pretraining on\ndomain-relevant data not only boosts performance but also accelerates\nconvergence, reducing training time by up to 5x. These results demonstrate that\nour unified WFM can support diverse tasks and deliver significant gains in both\nperformance and efficiency, highlighting the transformative potential of\nfoundation models to drive AI-native paradigms in future sixth-generation (6G)\nnetworks.",
      "tldr_zh": "本论文提出了一种新型无线基础模型(WavesFM)，旨在支持通信、感知和定位等多种任务。该模型采用共享的Vision Transformer (ViT)主干网络结合任务特定的多层感知器(MLP)头，并通过Low-Rank Adaptation (LoRA)实现参数高效微调，从而在任务间共享80%的参数，显著降低计算和内存需求。实验在5G NR定位、MIMO-OFDM信道估计、人体活动感知和RF信号分类等四个下游任务上验证了WavesFM的强大泛化能力，与独立训练的监督基线相比，性能更优，且预训练在相关数据上可加速收敛并减少训练时间高达5倍。这些结果突显了WavesFM在未来6G网络中推动AI原生范式的变革潜力。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.14100v1",
      "published_date": "2025-04-18 22:51:35 UTC",
      "updated_date": "2025-04-18 22:51:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:19:35.576961"
    },
    {
      "arxiv_id": "2504.14098v1",
      "title": "Enhancing Math Learning in an LMS Using AI-Driven Question Recommendations",
      "title_zh": "利用",
      "authors": [
        "Justus Råmunddal"
      ],
      "abstract": "This paper presents an AI-driven approach to enhance math learning in a\nmodern Learning Management System (LMS) by recommending similar math questions.\nDeep embeddings for math questions are generated using Meta's\nLlama-3.2-11B-Vision-Instruct model, and three recommendation methods-cosine\nsimilarity, Self-Organizing Maps (SOM), and Gaussian Mixture Models (GMM)-are\napplied to identify similar questions. User interaction data, including session\ndurations, response times, and correctness, are used to evaluate the methods.\nOur findings suggest that while cosine similarity produces nearly identical\nquestion matches, SOM yields higher user satisfaction whereas GMM generally\nunderperforms, indicating that introducing variety to a certain degree may\nenhance engagement and thereby potential learning outcomes until variety is no\nlonger balanced reasonably, which our data about the implementations of all\nthree methods demonstrate.",
      "tldr_zh": "这篇论文提出了一种AI驱动的方法，使用Meta的Llama-3.2-11B-Vision-Instruct模型生成数学问题的深度嵌入，从而在Learning Management System (LMS)中推荐类似问题以提升数学学习。研究应用了三种推荐方法：cosine similarity、Self-Organizing Maps (SOM)和Gaussian Mixture Models (GMM)，并通过用户交互数据（如会话时长、响应时间和正确率）进行评估。结果表明，cosine similarity提供精确匹配，SOM带来更高的用户满意度，而GMM表现较差；总体发现适度的多样性能增强参与度和学习效果，但过度多样性可能导致不平衡。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY",
        "cs.IR"
      ],
      "primary_category": "cs.LG",
      "comment": "15 pages, 9 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2504.14098v1",
      "published_date": "2025-04-18 22:48:26 UTC",
      "updated_date": "2025-04-18 22:48:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:19:48.122400"
    },
    {
      "arxiv_id": "2504.14094v2",
      "title": "Leakage and Interpretability in Concept-Based Models",
      "title_zh": "翻译失败",
      "authors": [
        "Enrico Parisini",
        "Tapabrata Chakraborti",
        "Chris Harbron",
        "Ben D. MacArthur",
        "Christopher R. S. Banerji"
      ],
      "abstract": "Concept Bottleneck Models aim to improve interpretability by predicting\nhigh-level intermediate concepts, representing a promising approach for\ndeployment in high-risk scenarios. However, they are known to suffer from\ninformation leakage, whereby models exploit unintended information encoded\nwithin the learned concepts. We introduce an information-theoretic framework to\nrigorously characterise and quantify leakage, and define two complementary\nmeasures: the concepts-task leakage (CTL) and interconcept leakage (ICL)\nscores. We show that these measures are strongly predictive of model behaviour\nunder interventions and outperform existing alternatives in robustness and\nreliability. Using this framework, we identify the primary causes of leakage\nand provide strong evidence that Concept Embedding Models exhibit substantial\nleakage regardless of the hyperparameters choice. Finally, we propose practical\nguidelines for designing concept-based models to reduce leakage and ensure\ninterpretability.",
      "tldr_zh": "本文研究了Concept Bottleneck Models在可解释性方面的信息泄漏问题，这些模型通过预测高级中间概念来提升在高风险场景中的部署潜力，但往往利用非预期信息导致泄漏。作者引入了一个信息理论框架，并定义了两个指标——concepts-task leakage (CTL) 和 interconcept leakage (ICL)——来精确量化泄漏，这些指标在模型干预下的行为预测上比现有方法更稳健可靠。研究发现，Concept Embedding Models不论超参数选择如何，都存在显著泄漏，并提供了减少泄漏和确保可解释性的实用设计指南。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "35 pages, 24 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.14094v2",
      "published_date": "2025-04-18 22:21:06 UTC",
      "updated_date": "2025-05-19 14:09:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:19:59.329086"
    },
    {
      "arxiv_id": "2504.14089v1",
      "title": "LogicTree: Structured Proof Exploration for Coherent and Rigorous Logical Reasoning with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Kang He",
        "Kaushik Roy"
      ],
      "abstract": "Large language models (LLMs) have achieved remarkable multi-step reasoning\ncapabilities across various domains. However, LLMs still face distinct\nchallenges in complex logical reasoning, as (1) proof-finding requires\nsystematic exploration and the maintenance of logical coherence and (2)\nsearching the right combination of premises at each reasoning step is\ninherently challenging in tasks with large premise space. To address this, we\npropose LogicTree, an inference-time modular framework employing\nalgorithm-guided search to automate structured proof exploration and ensure\nlogical coherence. Advancing beyond tree-of-thought (ToT), we incorporate\ncaching mechanism into LogicTree to enable effective utilization of historical\nknowledge, preventing reasoning stagnation and minimizing redundancy.\nFurthermore, we address the combinatorial complexity of premise search by\ndecomposing it into a linear process. The refined premise selection restricts\nsubsequent inference to at most one derivation per step, enhancing reasoning\ngranularity and enforcing strict step-by-step reasoning. Additionally, we\nintroduce two LLM-free heuristics for premise prioritization, enabling\nstrategic proof search. Experimental results on five datasets demonstrate that\nLogicTree optimally scales inference-time computation to achieve higher proof\naccuracy, surpassing chain-of-thought (CoT) and ToT with average gains of 23.6%\nand 12.5%, respectively, on GPT-4o. Moreover, within LogicTree, GPT-4o\noutperforms o3-mini by 7.6% on average.",
      "tldr_zh": "该研究针对大型语言模型(LLMs)在复杂逻辑推理中的挑战——如系统探索需求和前提组合搜索难题——提出LogicTree框架，该框架采用算法引导的搜索来自动化结构化证明探索，确保逻辑连贯性。LogicTree在tree-of-thought (ToT)基础上引入缓存机制利用历史知识、将前提搜索分解为线性过程，并添加两个LLM-free启发式方法来优先化前提选择，从而提升推理粒度和减少冗余。实验结果显示，LogicTree在五个数据集上显著提升证明准确率，使用GPT-4o时比chain-of-thought (CoT)和ToT分别提高23.6%和12.5%，且GPT-4o在该框架中优于o3-mini约7.6%。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.14089v1",
      "published_date": "2025-04-18 22:10:02 UTC",
      "updated_date": "2025-04-18 22:10:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:20:11.433046"
    },
    {
      "arxiv_id": "2504.14071v1",
      "title": "Evaluating Human-AI Interaction via Usability, User Experience and Acceptance Measures for MMM-C: A Creative AI System for Music Composition",
      "title_zh": "翻译失败",
      "authors": [
        "Renaud Bougueng Tchemeube",
        "Jeff Ens",
        "Cale Plut",
        "Philippe Pasquier",
        "Maryam Safi",
        "Yvan Grabit",
        "Jean-Baptiste Rolland"
      ],
      "abstract": "With the rise of artificial intelligence (AI), there has been increasing\ninterest in human-AI co-creation in a variety of artistic domains including\nmusic as AI-driven systems are frequently able to generate human-competitive\nartifacts. Now, the implications of such systems for musical practice are being\ninvestigated. We report on a thorough evaluation of the user adoption of the\nMulti-Track Music Machine (MMM) as a co-creative AI tool for music composers.\nTo do this, we integrate MMM into Cubase, a popular Digital Audio Workstation\n(DAW) by Steinberg, by producing a \"1-parameter\" plugin interface named\nMMM-Cubase (MMM-C), which enables human-AI co-composition. We contribute a\nmethodological assemblage as a 3-part mixed method study measuring usability,\nuser experience and technology acceptance of the system across two groups of\nexpert-level composers: hobbyists and professionals. Results show positive\nusability and acceptance scores. Users report experiences of novelty, surprise\nand ease of use from using the system, and limitations on controllability and\npredictability of the interface when generating music. Findings indicate no\nsignificant difference between the two user groups.",
      "tldr_zh": "本研究评估了MMM-C系统——一个整合到数字音频工作站(Digital Audio Workstation, DAW) Cubase中的AI辅助音乐创作工具——在人-AI交互方面的可用性(User Experience)、用户体验(User Experience)和技术接受度(Acceptance Measures)。他们采用三部分混合方法研究，针对业余和专业作曲家两组专家用户，测试了该系统的易用性和接受度。结果显示，MMM-C获得了积极的可用性和接受度反馈，用户报告了新颖性、惊喜和易用性的体验，但存在控制性和可预测性方面的局限；两组用户之间无显著差异，这为AI在音乐创作中的应用提供了重要洞见。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.LG",
        "cs.SD"
      ],
      "primary_category": "cs.HC",
      "comment": "10 pages, 6 figures, 1 table, first published at the 32nd\n  International Joint Conference on Artificial Intelligence (IJCAI 2023),\n  Macao, China",
      "pdf_url": "http://arxiv.org/pdf/2504.14071v1",
      "published_date": "2025-04-18 20:41:02 UTC",
      "updated_date": "2025-04-18 20:41:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:20:23.227141"
    },
    {
      "arxiv_id": "2504.14070v3",
      "title": "A CMOS Probabilistic Computing Chip With In-situ hardware Aware Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Jinesh Jhonsa",
        "William Whitehead",
        "David McCarthy",
        "Shuvro Chowdhury",
        "Kerem Camsari",
        "Luke Theogarajan"
      ],
      "abstract": "This paper demonstrates a probabilistic bit physics inspired solver with 440\nspins configured in a Chimera graph, occupying an area of 0.44 mm^2. Area\nefficiency is maximized through a current-mode implementation of the neuron\nupdate circuit, standard cell design for analog blocks pitch-matched to digital\nblocks, and a shared power supply for both digital and analog components.\nProcess variation related mismatches introduced by this approach are\neffectively mitigated using a hardware aware contrastive divergence algorithm\nduring training. We validate the chip's ability to perform probabilistic\ncomputing tasks such as modeling logic gates and full adders, as well as\noptimization tasks such as MaxCut, demonstrating its potential for AI and\nmachine learning applications.",
      "tldr_zh": "本论文提出了一种基于 CMOS 的概率计算芯片，配备 440 个 spins 配置在 Chimera graph 上，总面积仅 0.44 mm²，通过当前模式神经元更新电路、标准单元设计和共享电源来最大化面积效率。论文采用硬件感知对比散度（contrastive divergence）算法有效缓解过程变异带来的失配问题，并在训练过程中优化芯片性能。实验验证了该芯片在概率计算任务（如建模逻辑门和全加器）以及优化任务（如 MaxCut）上的能力，展示了其在 AI 和机器学习应用中的潜力。",
      "categories": [
        "cs.AR",
        "cs.AI"
      ],
      "primary_category": "cs.AR",
      "comment": "3 pages 12 figuewa",
      "pdf_url": "http://arxiv.org/pdf/2504.14070v3",
      "published_date": "2025-04-18 20:40:48 UTC",
      "updated_date": "2025-04-30 05:38:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:20:35.844690"
    },
    {
      "arxiv_id": "2504.14054v1",
      "title": "Occlusion-Ordered Semantic Instance Segmentation",
      "title_zh": "基于遮挡顺序的语义实例分割",
      "authors": [
        "Soroosh Baselizadeh",
        "Cheuk-To Yu",
        "Olga Veksler",
        "Yuri Boykov"
      ],
      "abstract": "Standard semantic instance segmentation provides useful, but inherently 2D\ninformation from a single image. To enable 3D analysis, one usually integrates\nabsolute monocular depth estimation with instance segmentation. However,\nmonocular depth is a difficult task. Instead, we leverage a simpler\nsingle-image task, occlusion-based relative depth ordering, providing coarser\nbut useful 3D information. We show that relative depth ordering works more\nreliably from occlusions than from absolute depth. We propose to solve the\njoint task of relative depth ordering and segmentation of instances based on\nocclusions. We call this task Occlusion-Ordered Semantic Instance Segmentation\n(OOSIS). We develop an approach to OOSIS that extracts instances and their\nocclusion order simultaneously from oriented occlusion boundaries and semantic\nsegmentation. Unlike popular detect-and-segment framework for instance\nsegmentation, combining occlusion ordering with instance segmentation allows a\nsimple and clean formulation of OOSIS as a labeling problem. As a part of our\nsolution for OOSIS, we develop a novel oriented occlusion boundaries approach\nthat significantly outperforms prior work. We also develop a new joint OOSIS\nmetric based both on instance mask accuracy and correctness of their occlusion\norder. We achieve better performance than strong baselines on KINS and COCOA\ndatasets.",
      "tldr_zh": "本文提出Occlusion-Ordered Semantic Instance Segmentation (OOSIS)，一种基于遮挡的相对深度排序与实例分割的联合任务，以提供更可靠的3D信息，而非依赖困难的绝对单目深度估计。方法通过从定向遮挡边界和语义分割中同时提取实例及其遮挡顺序，将OOSIS表述为一个简单的标注问题，并开发了新的定向遮挡边界方法，显著优于现有工作。实验结果显示，该方法在KINS和COCOA数据集上，比强基线在实例掩码准确性和遮挡顺序正确性方面表现出色。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.14054v1",
      "published_date": "2025-04-18 19:52:37 UTC",
      "updated_date": "2025-04-18 19:52:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:20:47.544382"
    },
    {
      "arxiv_id": "2504.14053v1",
      "title": "Sentiment Analysis of Airbnb Reviews: Exploring Their Impact on Acceptance Rates and Pricing Across Multiple U.S. Regions",
      "title_zh": "翻译失败",
      "authors": [
        "Ali Safari"
      ],
      "abstract": "This research examines whether Airbnb guests' positive and negative comments\ninfluence acceptance rates and rental prices across six U.S. regions: Rhode\nIsland, Broward County, Chicago, Dallas, San Diego, and Boston. Thousands of\nreviews were collected and analyzed using Natural Language Processing (NLP) to\nclassify sentiments as positive or negative, followed by statistical testing\n(t-tests and basic correlations) on the average scores. The findings reveal\nthat over 90 percent of reviews in each region are positive, indicating that\nhaving additional reviews does not significantly enhance prices. However,\nlistings with predominantly positive feedback exhibit slightly higher\nacceptance rates, suggesting that sentiment polarity, rather than the sheer\nvolume of reviews, is a more critical factor for host success. Additionally,\nbudget listings often gather extensive reviews while maintaining competitive\npricing, whereas premium listings sustain higher prices with fewer but highly\npositive reviews. These results underscore the importance of sentiment quality\nover quantity in shaping guest behavior and pricing strategies in an\noverwhelmingly positive review environment.",
      "tldr_zh": "本研究探讨了Airbnb评论的情感分析对接受率和定价的影响，涵盖六个美国地区，包括罗德岛、布劳沃德县、芝加哥、达拉斯、圣迭戈和波士顿。研究者使用Natural Language Processing (NLP)技术对数千条评论进行情感分类，并通过t-tests和基本correlations进行统计测试。结果显示，每个地区超过90%的评论为积极的，积极情感极性比评论数量更能提升房源接受率，而预算房源依赖大量评论维持竞争性价格，高端房源则靠高度积极的少量评论支撑高价。这些发现强调了情感质量在塑造客人行为和定价策略中的关键作用。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.14053v1",
      "published_date": "2025-04-18 19:52:24 UTC",
      "updated_date": "2025-04-18 19:52:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:21:00.051554"
    },
    {
      "arxiv_id": "2504.14047v1",
      "title": "Think Deep, Think Fast: Investigating Efficiency of Verifier-free Inference-time-scaling Methods",
      "title_zh": "翻译失败",
      "authors": [
        "Junlin Wang",
        "Shang Zhu",
        "Jon Saad-Falcon",
        "Ben Athiwaratkun",
        "Qingyang Wu",
        "Jue Wang",
        "Shuaiwen Leon Song",
        "Ce Zhang",
        "Bhuwan Dhingra",
        "James Zou"
      ],
      "abstract": "There is intense interest in investigating how inference time compute (ITC)\n(e.g. repeated sampling, refinements, etc) can improve large language model\n(LLM) capabilities. At the same time, recent breakthroughs in reasoning models,\nsuch as Deepseek-R1, unlock the opportunity for reinforcement learning to\nimprove LLM reasoning skills. An in-depth understanding of how ITC interacts\nwith reasoning across different models could provide important guidance on how\nto further advance the LLM frontier. This work conducts a comprehensive\nanalysis of inference-time scaling methods for both reasoning and non-reasoning\nmodels on challenging reasoning tasks. Specifically, we focus our research on\nverifier-free inference time-scaling methods due to its generalizability\nwithout needing a reward model. We construct the Pareto frontier of quality and\nefficiency. We find that non-reasoning models, even with an extremely high\ninference budget, still fall substantially behind reasoning models. For\nreasoning models, majority voting proves to be a robust inference strategy,\ngenerally competitive or outperforming other more sophisticated ITC methods\nlike best-of-N and sequential revisions, while the additional inference compute\noffers minimal improvements. We further perform in-depth analyses of the\nassociation of key response features (length and linguistic markers) with\nresponse quality, with which we can improve the existing ITC methods. We find\nthat correct responses from reasoning models are typically shorter and have\nfewer hedging and thinking markers (but more discourse markers) than the\nincorrect responses.",
      "tldr_zh": "这篇论文调查了无验证器推断时缩放方法（verifier-free inference-time-scaling methods）的效率，分析了这些方法如何提升大型语言模型（LLM）的推理能力，特别是通过重复采样和改进等技术。研究构建了质量和效率的Pareto前沿，发现非推理模型即使在高计算预算下仍远落后于推理模型，而对于推理模型，多数投票策略表现出色，通常优于best-of-N和顺序修订方法，且额外计算带来的改进有限。论文进一步分析了响应特征（如长度和语言标记），发现正确响应通常更短、包含较少的犹豫和思考标记（但更多的discourse markers），并据此提出优化现有ITC方法的建议。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.14047v1",
      "published_date": "2025-04-18 19:32:55 UTC",
      "updated_date": "2025-04-18 19:32:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:21:12.292377"
    },
    {
      "arxiv_id": "2504.14046v1",
      "title": "A synthetic dataset of French electric load curves with temperature conditioning",
      "title_zh": "一个带温度条件化的法国电力负载曲线合成数据集",
      "authors": [
        "Tahar Nabil",
        "Ghislain Agoua",
        "Pierre Cauchois",
        "Anne De Moliner",
        "Benoît Grossin"
      ],
      "abstract": "The undergoing energy transition is causing behavioral changes in electricity\nuse, e.g. with self-consumption of local generation, or flexibility services\nfor demand control. To better understand these changes and the challenges they\ninduce, accessing individual smart meter data is crucial. Yet this is personal\ndata under the European GDPR. A widespread use of such data requires thus to\ncreate synthetic realistic and privacy-preserving samples. This paper\nintroduces a new synthetic load curve dataset generated by conditional latent\ndiffusion. We also provide the contracted power, time-of-use plan and local\ntemperature used for generation. Fidelity, utility and privacy of the dataset\nare thoroughly evaluated, demonstrating its good quality and thereby supporting\nits interest for energy modeling applications.",
      "tldr_zh": "这篇论文针对能源转型中电力使用行为的隐私挑战，引入了一个合成法国电力负载曲线数据集，使用条件潜在扩散（conditional latent diffusion）模型生成，并纳入温度、合同功率和用时计划等条件。该数据集旨在提供真实且隐私保护的数据，以替代受欧盟 GDPR 法规限制的个人智能电表数据。通过全面评估，数据集在保真度（fidelity）、效用（utility）和隐私（privacy）方面表现出色，支持各种能源建模应用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Workshop paper at \"Tackling Climate Change with Machine Learning\",\n  ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.14046v1",
      "published_date": "2025-04-18 19:28:49 UTC",
      "updated_date": "2025-04-18 19:28:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:21:22.703797"
    },
    {
      "arxiv_id": "2504.14044v1",
      "title": "Multi-Stage Retrieval for Operational Technology Cybersecurity Compliance Using Large Language Models: A Railway Casestudy",
      "title_zh": "翻译失败",
      "authors": [
        "Regan Bolton",
        "Mohammadreza Sheikhfathollahi",
        "Simon Parkinson",
        "Dan Basher",
        "Howard Parkinson"
      ],
      "abstract": "Operational Technology Cybersecurity (OTCS) continues to be a dominant\nchallenge for critical infrastructure such as railways. As these systems become\nincreasingly vulnerable to malicious attacks due to digitalization, effective\ndocumentation and compliance processes are essential to protect these\nsafety-critical systems. This paper proposes a novel system that leverages\nLarge Language Models (LLMs) and multi-stage retrieval to enhance the\ncompliance verification process against standards like IEC 62443 and the\nrail-specific IEC 63452. We first evaluate a Baseline Compliance Architecture\n(BCA) for answering OTCS compliance queries, then develop an extended approach\ncalled Parallel Compliance Architecture (PCA) that incorporates additional\ncontext from regulatory standards. Through empirical evaluation comparing\nOpenAI-gpt-4o and Claude-3.5-haiku models in these architectures, we\ndemonstrate that the PCA significantly improves both correctness and reasoning\nquality in compliance verification. Our research establishes metrics for\nresponse correctness, logical reasoning, and hallucination detection,\nhighlighting the strengths and limitations of using LLMs for compliance\nverification in railway cybersecurity. The results suggest that\nretrieval-augmented approaches can significantly improve the efficiency and\naccuracy of compliance assessments, particularly valuable in an industry facing\na shortage of cybersecurity expertise.",
      "tldr_zh": "本文提出一种利用 Large Language Models (LLMs) 和多阶段检索的系统，以提升 Operational Technology Cybersecurity (OTCS) 合规验证过程，针对铁路等关键基础设施的 IEC 62443 和 IEC 63452 标准。系统包括 Baseline Compliance Architecture (BCA) 和扩展的 Parallel Compliance Architecture (PCA)，后者通过整合更多监管上下文显著提高了响应正确性和推理质量。实验比较了 OpenAI-gpt-4o 和 Claude-3.5-haiku 模型，结果显示 PCA 改善了合规查询的正确性、逻辑推理并减少了幻觉。研究强调，检索增强方法能增强合规评估的效率和准确性，尤其在网络安全专家短缺的行业中。",
      "categories": [
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.14044v1",
      "published_date": "2025-04-18 19:24:17 UTC",
      "updated_date": "2025-04-18 19:24:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:21:36.927962"
    },
    {
      "arxiv_id": "2504.14045v1",
      "title": "Metacognition and Uncertainty Communication in Humans and Large Language Models",
      "title_zh": "人类和大型语言模型中的元认知和不确定性沟通",
      "authors": [
        "Mark Steyvers",
        "Megan A. K. Peters"
      ],
      "abstract": "Metacognition, the capacity to monitor and evaluate one's own knowledge and\nperformance, is foundational to human decision-making, learning, and\ncommunication. As large language models (LLMs) become increasingly embedded in\nhigh-stakes decision contexts, it is critical to assess whether, how, and to\nwhat extent they exhibit metacognitive abilities. Here, we provide an overview\nof current knowledge of LLMs' metacognitive capacities, how they might be\nstudied, and how they relate to our knowledge of metacognition in humans. We\nshow that while humans and LLMs can sometimes appear quite aligned in their\nmetacognitive capacities and behaviors, it is clear many differences remain.\nAttending to these differences is crucial not only for enhancing human-AI\ncollaboration, but also for promoting the development of more capable and\ntrustworthy artificial systems. Finally, we discuss how endowing future LLMs\nwith more sensitive and more calibrated metacognition may also help them\ndevelop new capacities such as more efficient learning, self-direction, and\ncuriosity.",
      "tldr_zh": "这篇论文探讨了元认知（Metacognition）在人类决策、学习和沟通中的核心作用，并评估大型语言模型（LLMs）是否具备类似能力。研究概述了LLMs的元认知表现、研究方法，以及与人类元认知的比较，发现两者在某些行为上相似，但存在显著差异，这些差异对提升人类-AI合作和开发更可靠的AI系统至关重要。最后，论文提出，通过赋予LLMs更精确的元认知功能，可以促进其更高效的学习、自导和好奇心发展。",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.14045v1",
      "published_date": "2025-04-18 19:24:17 UTC",
      "updated_date": "2025-04-18 19:24:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:21:47.158408"
    },
    {
      "arxiv_id": "2504.14039v1",
      "title": "MEQA: A Meta-Evaluation Framework for Question & Answer LLM Benchmarks",
      "title_zh": "翻译失败",
      "authors": [
        "Jaime Raldua Veuthey",
        "Zainab Ali Majid",
        "Suhas Hariharan",
        "Jacob Haimes"
      ],
      "abstract": "As Large Language Models (LLMs) advance, their potential for widespread\nsocietal impact grows simultaneously. Hence, rigorous LLM evaluations are both\na technical necessity and social imperative. While numerous evaluation\nbenchmarks have been developed, there remains a critical gap in\nmeta-evaluation: effectively assessing benchmarks' quality. We propose MEQA, a\nframework for the meta-evaluation of question and answer (QA) benchmarks, to\nprovide standardized assessments, quantifiable scores, and enable meaningful\nintra-benchmark comparisons. We demonstrate this approach on cybersecurity\nbenchmarks, using human and LLM evaluators, highlighting the benchmarks'\nstrengths and weaknesses. We motivate our choice of test domain by AI models'\ndual nature as powerful defensive tools and security threats.",
      "tldr_zh": "该研究强调了大型语言模型（LLM）的快速发展及其社会影响，提出MEQA框架作为一种元评估（meta-evaluation）工具，用于评估问答（QA）基准的质量。MEQA提供标准化评估、可量化的分数，并支持基准间的比较，从而填补了现有评估方法的空白。在网络安全领域应用中，该框架利用人类和LLM评估者，突出了各种基准的优缺点，展示了AI模型作为防御工具和安全威胁的双重性。最终，MEQA为更可靠的LLM评估奠定了基础，促进了技术和社会责任的平衡。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.14039v1",
      "published_date": "2025-04-18 19:01:53 UTC",
      "updated_date": "2025-04-18 19:01:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:21:58.582209"
    },
    {
      "arxiv_id": "2504.14038v1",
      "title": "Flowco: Rethinking Data Analysis in the Age of LLMs",
      "title_zh": "Flowco: 在大语言模型时代重新审视数据分析",
      "authors": [
        "Stephen N. Freund",
        "Brooke Simon",
        "Emery D. Berger",
        "Eunice Jun"
      ],
      "abstract": "Conducting data analysis typically involves authoring code to transform,\nvisualize, analyze, and interpret data. Large language models (LLMs) are now\ncapable of generating such code for simple, routine analyses. LLMs promise to\ndemocratize data science by enabling those with limited programming expertise\nto conduct data analyses, including in scientific research, business, and\npolicymaking. However, analysts in many real-world settings must often exercise\nfine-grained control over specific analysis steps, verify intermediate results\nexplicitly, and iteratively refine their analytical approaches. Such tasks\npresent barriers to building robust and reproducible analyses using LLMs alone\nor even in conjunction with existing authoring tools (e.g., computational\nnotebooks). This paper introduces Flowco, a new mixed-initiative system to\naddress these challenges. Flowco leverages a visual dataflow programming model\nand integrates LLMs into every phase of the authoring process. A user study\nsuggests that Flowco supports analysts, particularly those with less\nprogramming experience, in quickly authoring, debugging, and refining data\nanalyses.",
      "tldr_zh": "该论文探讨了在大型语言模型(LLMs)时代的数据分析挑战，指出LLMs虽能生成代码简化简单分析，但难以实现精细控制、验证中间结果和迭代改进。论文提出Flowco，一种混合主动系统，结合视觉数据流编程模型，将LLMs整合到数据分析的每个阶段，帮助用户更高效地编写和调试分析过程。用户研究显示，Flowco特别适合编程经验有限的分析师，能快速提升分析的鲁棒性和可重复性。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.PL",
        "stat.CO"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.14038v1",
      "published_date": "2025-04-18 19:01:27 UTC",
      "updated_date": "2025-04-18 19:01:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:22:10.523819"
    },
    {
      "arxiv_id": "2504.14032v1",
      "title": "LoftUp: Learning a Coordinate-Based Feature Upsampler for Vision Foundation Models",
      "title_zh": "翻译失败",
      "authors": [
        "Haiwen Huang",
        "Anpei Chen",
        "Volodymyr Havrylov",
        "Andreas Geiger",
        "Dan Zhang"
      ],
      "abstract": "Vision foundation models (VFMs) such as DINOv2 and CLIP have achieved\nimpressive results on various downstream tasks, but their limited feature\nresolution hampers performance in applications requiring pixel-level\nunderstanding. Feature upsampling offers a promising direction to address this\nchallenge. In this work, we identify two critical factors for enhancing feature\nupsampling: the upsampler architecture and the training objective. For the\nupsampler architecture, we introduce a coordinate-based cross-attention\ntransformer that integrates the high-resolution images with coordinates and\nlow-resolution VFM features to generate sharp, high-quality features. For the\ntraining objective, we propose constructing high-resolution pseudo-groundtruth\nfeatures by leveraging class-agnostic masks and self-distillation. Our approach\neffectively captures fine-grained details and adapts flexibly to various input\nand feature resolutions. Through experiments, we demonstrate that our approach\nsignificantly outperforms existing feature upsampling techniques across various\ndownstream tasks. Our code is released at https://github.com/andrehuang/loftup.",
      "tldr_zh": "该研究针对视觉基础模型（VFMs）如 DINOv2 和 CLIP 的特征分辨率不足问题，提出 LoftUp 方法，以提升像素级任务性能。LoftUp 引入基于坐标的交叉注意力 transformer 架构，将高分辨率图像、坐标和低分辨率 VFM 特征整合，生成高质量特征；同时，通过类无关掩码和自蒸馏构建高分辨率伪地面真实特征作为训练目标。实验结果显示，该方法在各种下游任务中显著优于现有特征上采样技术，并支持灵活的输入和特征分辨率适应。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.14032v1",
      "published_date": "2025-04-18 18:46:08 UTC",
      "updated_date": "2025-04-18 18:46:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:22:22.941300"
    },
    {
      "arxiv_id": "2504.14015v1",
      "title": "Causal pieces: analysing and improving spiking neural networks piece by piece",
      "title_zh": "翻译失败",
      "authors": [
        "Dominik Dold",
        "Philipp Christian Petersen"
      ],
      "abstract": "We introduce a novel concept for spiking neural networks (SNNs) derived from\nthe idea of \"linear pieces\" used to analyse the expressiveness and trainability\nof artificial neural networks (ANNs). We prove that the input domain of SNNs\ndecomposes into distinct causal regions where its output spike times are\nlocally Lipschitz continuous with respect to the input spike times and network\nparameters. The number of such regions - which we call \"causal pieces\" - is a\nmeasure of the approximation capabilities of SNNs. In particular, we\ndemonstrate in simulation that parameter initialisations which yield a high\nnumber of causal pieces on the training set strongly correlate with SNN\ntraining success. Moreover, we find that feedforward SNNs with purely positive\nweights exhibit a surprisingly high number of causal pieces, allowing them to\nachieve competitive performance levels on benchmark tasks. We believe that\ncausal pieces are not only a powerful and principled tool for improving SNNs,\nbut might also open up new ways of comparing SNNs and ANNs in the future.",
      "tldr_zh": "这篇论文引入了“causal pieces”的新概念，用于分析和改进尖峰神经网络 (SNNs)，借鉴了人工神经网络 (ANNs) 的“linear pieces”思想。研究证明，SNNs 的输入域可分解成不同的因果区域，其中输出尖峰时间相对于输入尖峰时间和网络参数是局部 Lipschitz 连续的，且 causal pieces 的数量可作为 SNNs 近似能力的度量。通过模拟实验，作者发现参数初始化导致训练集上高数量的 causal pieces 与 SNNs 训练成功高度相关，并证明纯正权重的前馈 SNNs 能在基准任务上达到竞争性性能。该框架不仅为提升 SNNs 提供强大工具，还可能开启比较 SNNs 和 ANNs 的新方式。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG",
        "q-bio.NC",
        "stat.ML"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.14015v1",
      "published_date": "2025-04-18 18:07:33 UTC",
      "updated_date": "2025-04-18 18:07:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:22:36.474301"
    },
    {
      "arxiv_id": "2504.14011v1",
      "title": "Fashion-RAG: Multimodal Fashion Image Editing via Retrieval-Augmented Generation",
      "title_zh": "Fashion-RAG：基于检索增强生成的多模态时尚图像编辑",
      "authors": [
        "Fulvio Sanguigni",
        "Davide Morelli",
        "Marcella Cornia",
        "Rita Cucchiara"
      ],
      "abstract": "In recent years, the fashion industry has increasingly adopted AI\ntechnologies to enhance customer experience, driven by the proliferation of\ne-commerce platforms and virtual applications. Among the various tasks, virtual\ntry-on and multimodal fashion image editing -- which utilizes diverse input\nmodalities such as text, garment sketches, and body poses -- have become a key\narea of research. Diffusion models have emerged as a leading approach for such\ngenerative tasks, offering superior image quality and diversity. However, most\nexisting virtual try-on methods rely on having a specific garment input, which\nis often impractical in real-world scenarios where users may only provide\ntextual specifications. To address this limitation, in this work we introduce\nFashion Retrieval-Augmented Generation (Fashion-RAG), a novel method that\nenables the customization of fashion items based on user preferences provided\nin textual form. Our approach retrieves multiple garments that match the input\nspecifications and generates a personalized image by incorporating attributes\nfrom the retrieved items. To achieve this, we employ textual inversion\ntechniques, where retrieved garment images are projected into the textual\nembedding space of the Stable Diffusion text encoder, allowing seamless\nintegration of retrieved elements into the generative process. Experimental\nresults on the Dress Code dataset demonstrate that Fashion-RAG outperforms\nexisting methods both qualitatively and quantitatively, effectively capturing\nfine-grained visual details from retrieved garments. To the best of our\nknowledge, this is the first work to introduce a retrieval-augmented generation\napproach specifically tailored for multimodal fashion image editing.",
      "tldr_zh": "该论文介绍了 Fashion-RAG，一种基于 Retrieval-Augmented Generation (RAG) 的方法，用于多模态时尚图像编辑，允许用户通过文本描述自定义服装，而非依赖特定图像输入。Fashion-RAG 通过检索匹配用户文本规范的多个服装图像，然后利用 textual inversion 技术将这些图像投影到 Stable Diffusion 的文本嵌入空间，实现无缝生成个性化时尚图像。实验在 Dress Code 数据集上显示，该方法在定性和定量指标上优于现有方法，能够有效捕捉细粒度的视觉细节。作为首创，Fashion-RAG 为真实场景下的多模态时尚编辑提供了可行解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "IJCNN 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.14011v1",
      "published_date": "2025-04-18 18:02:33 UTC",
      "updated_date": "2025-04-18 18:02:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:22:47.272216"
    },
    {
      "arxiv_id": "2504.13837v2",
      "title": "Does Reinforcement Learning Really Incentivize Reasoning Capacity in LLMs Beyond the Base Model?",
      "title_zh": "翻译失败",
      "authors": [
        "Yang Yue",
        "Zhiqi Chen",
        "Rui Lu",
        "Andrew Zhao",
        "Zhaokai Wang",
        "Yang Yue",
        "Shiji Song",
        "Gao Huang"
      ],
      "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) has recently\ndemonstrated notable success in enhancing the reasoning performance of large\nlanguage models (LLMs), particularly on mathematics and programming tasks.\nSimilar to how traditional RL helps agents explore and learn new strategies,\nRLVR is believed to enable LLMs to continuously self-improve, thus acquiring\nnovel reasoning abilities beyond those of the corresponding base models. In\nthis study we critically examine the current state of RLVR by systematically\nprobing the reasoning capability boundaries of RLVR-trained LLMs across various\nmodel families, RL algorithms, and math, coding, and visual reasoning\nbenchmarks, using pass@k at large k values as the evaluation metric.\nSurprisingly, we find that the current training setup does not elicit\nfundamentally new reasoning patterns. While RLVR-trained models outperform\ntheir base models at small k (e.g., k = 1), the base models achieve a higher\npass@k score when k is large. Coverage and perplexity analyses show that the\nobserved reasoning abilities originate from and are bounded by the base model.\nTreating the base model as an upper bound, our quantitative analysis shows that\nsix popular RLVR algorithms perform similarly and remain far from optimal in\nleveraging the potential of the base model. By contrast, we find that\ndistillation can introduce new reasoning patterns from the teacher and\ngenuinely expand the model's reasoning capabilities. Overall, our findings\nsuggest that current RLVR methods have not yet realized the potential of RL to\nelicit truly novel reasoning abilities in LLMs. This highlights the need for\nimproved RL paradigms, such as continual scaling and multi-turn\nagent-environment interaction, to unlock this potential.",
      "tldr_zh": "本研究质疑 Reinforcement Learning with Verifiable Rewards (RLVR) 是否能使大型语言模型 (LLMs) 获得超出基模型的推理能力，通过系统测试多种模型家族、RL 算法以及数学、编码和视觉推理基准，使用 pass@k 指标进行评估。结果显示，RLVR 训练模型在小 k 值（如 k=1）时表现优于基模型，但在大 k 值时基模型得分更高，表明推理能力源于基模型并受其限制。六种流行 RLVR 算法表现相似，未充分利用基模型潜力，而 distillation 方法能引入新推理模式并真正扩展模型能力。总体而言，当前 RLVR 方法尚未实现 RL 的潜力，需开发改进范式如持续缩放和多轮代理-环境交互。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "30 pages, 27 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.13837v2",
      "published_date": "2025-04-18 17:59:56 UTC",
      "updated_date": "2025-05-16 15:39:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:22:59.237201"
    },
    {
      "arxiv_id": "2504.13835v1",
      "title": "MIG: Automatic Data Selection for Instruction Tuning by Maximizing Information Gain in Semantic Space",
      "title_zh": "翻译失败",
      "authors": [
        "Yicheng Chen",
        "Yining Li",
        "Kai Hu",
        "Zerun Ma",
        "Haochen Ye",
        "Kai Chen"
      ],
      "abstract": "Data quality and diversity are key to the construction of effective\ninstruction-tuning datasets. % With the increasing availability of open-source\ninstruction-tuning datasets, it is advantageous to automatically select\nhigh-quality and diverse subsets from a vast amount of data. % Existing methods\ntypically prioritize instance quality and use heuristic rules to maintain\ndiversity. % However, this absence of a comprehensive view of the entire\ncollection often leads to suboptimal results. % Moreover, heuristic rules\ngenerally focus on distance or clustering within the embedding space, which\nfails to accurately capture the intent of complex instructions in the semantic\nspace. % To bridge this gap, we propose a unified method for quantifying the\ninformation content of datasets. This method models the semantic space by\nconstructing a label graph and quantifies diversity based on the distribution\nof information within the graph. % Based on such a measurement, we further\nintroduce an efficient sampling method that selects data samples iteratively to\n\\textbf{M}aximize the \\textbf{I}nformation \\textbf{G}ain (MIG) in semantic\nspace. % Experiments on various datasets and base models demonstrate that MIG\nconsistently outperforms state-of-the-art methods. % Notably, the model\nfine-tuned with 5\\% Tulu3 data sampled by MIG achieves comparable performance\nto the official SFT model trained on the full dataset, with improvements of\n+5.73\\% on AlpacaEval and +6.89\\% on Wildbench.",
      "tldr_zh": "该研究提出 MIG 方法，用于自动选择指令调优数据集，通过构建标签图建模语义空间并量化信息分布，来最大化采样过程中的信息增益，从而提升数据质量和多样性。相比现有依赖启发式规则的方法，MIG 提供了一个统一框架，更准确地捕捉复杂指令的语义意图。实验结果表明，在多种数据集和基模型上，MIG 优于最先进技术；例如，使用 MIG 采样 5% Tulu3 数据微调的模型，在 AlpacaEval 上提升 5.73%、在 Wildbench 上提升 6.89%，并与完整数据集训练的模型性能相当。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.13835v1",
      "published_date": "2025-04-18 17:59:46 UTC",
      "updated_date": "2025-04-18 17:59:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:23:11.579198"
    },
    {
      "arxiv_id": "2504.13828v3",
      "title": "Generative AI Act II: Test Time Scaling Drives Cognition Engineering",
      "title_zh": "生成式 AI 第二幕：测试时缩放驱动认知工程",
      "authors": [
        "Shijie Xia",
        "Yiwei Qin",
        "Xuefeng Li",
        "Yan Ma",
        "Run-Ze Fan",
        "Steffi Chern",
        "Haoyang Zou",
        "Fan Zhou",
        "Xiangkun Hu",
        "Jiahe Jin",
        "Yanheng He",
        "Yixin Ye",
        "Yixiu Liu",
        "Pengfei Liu"
      ],
      "abstract": "The first generation of Large Language Models - what might be called \"Act I\"\nof generative AI (2020-2023) - achieved remarkable success through massive\nparameter and data scaling, yet exhibited fundamental limitations such as\nknowledge latency, shallow reasoning, and constrained cognitive processes.\nDuring this era, prompt engineering emerged as our primary interface with AI,\nenabling dialogue-level communication through natural language. We now witness\nthe emergence of \"Act II\" (2024-present), where models are transitioning from\nknowledge-retrieval systems (in latent space) to thought-construction engines\nthrough test-time scaling techniques. This new paradigm establishes a\nmind-level connection with AI through language-based thoughts. In this paper,\nwe clarify the conceptual foundations of cognition engineering and explain why\nthis moment is critical for its development. We systematically break down these\nadvanced approaches through comprehensive tutorials and optimized\nimplementations, democratizing access to cognition engineering and enabling\nevery practitioner to participate in AI's second act. We provide a regularly\nupdated collection of papers on test-time scaling in the GitHub Repository:\nhttps://github.com/GAIR-NLP/cognition-engineering",
      "tldr_zh": "本论文探讨生成式 AI 的演进，从第一阶段（Act I，2020-2023）以大规模参数和数据缩放为主，但受限于知识延迟、浅层推理等问题，转向第二阶段（Act II，2024-至今），通过测试时缩放（test-time scaling）技术，将模型从知识检索系统转变为思想构建引擎，实现与 AI 的思维级连接。作者阐释了认知工程（cognition engineering）的概念基础，并强调这一阶段的重要性。论文提供全面教程和优化实现，系统分解这些先进方法，以民主化认知工程的访问，让从业者都能参与 AI 的第二阶段发展。最后，论文附带一个定期更新的 GitHub 仓库（https://github.com/GAIR-NLP/cognition-engineering），汇集相关论文资源。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "v3: add the comparison to existing work part; fix some errors",
      "pdf_url": "http://arxiv.org/pdf/2504.13828v3",
      "published_date": "2025-04-18 17:55:58 UTC",
      "updated_date": "2025-04-28 12:41:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:23:23.033104"
    },
    {
      "arxiv_id": "2504.13822v1",
      "title": "Parameter-Efficient Continual Fine-Tuning: A Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Eric Nuertey Coleman",
        "Luigi Quarantiello",
        "Ziyue Liu",
        "Qinwen Yang",
        "Samrat Mukherjee",
        "Julio Hurtado",
        "Vincenzo Lomonaco"
      ],
      "abstract": "The emergence of large pre-trained networks has revolutionized the AI field,\nunlocking new possibilities and achieving unprecedented performance. However,\nthese models inherit a fundamental limitation from traditional Machine Learning\napproaches: their strong dependence on the \\textit{i.i.d.} assumption hinders\ntheir adaptability to dynamic learning scenarios. We believe the next\nbreakthrough in AI lies in enabling efficient adaptation to evolving\nenvironments -- such as the real world -- where new data and tasks arrive\nsequentially. This challenge defines the field of Continual Learning (CL), a\nMachine Learning paradigm focused on developing lifelong learning neural\nmodels. One alternative to efficiently adapt these large-scale models is known\nParameter-Efficient Fine-Tuning (PEFT). These methods tackle the issue of\nadapting the model to a particular data or scenario by performing small and\nefficient modifications, achieving similar performance to full fine-tuning.\nHowever, these techniques still lack the ability to adjust the model to\nmultiple tasks continually, as they suffer from the issue of Catastrophic\nForgetting. In this survey, we first provide an overview of CL algorithms and\nPEFT methods before reviewing the state-of-the-art on Parameter-Efficient\nContinual Fine-Tuning (PECFT). We examine various approaches, discuss\nevaluation metrics, and explore potential future research directions. Our goal\nis to highlight the synergy between CL and Parameter-Efficient Fine-Tuning,\nguide researchers in this field, and pave the way for novel future research\ndirections.",
      "tldr_zh": "这篇调查论文探讨了大型预训练模型在动态学习场景中的适应性挑战，强调Continual Learning (CL)作为一种应对新数据和任务顺序出现的终身学习范式。该文概述了CL算法和Parameter-Efficient Fine-Tuning (PEFT)方法，指出PEFT通过小规模修改实现高效模型适应，但易受Catastrophic Forgetting影响，导致难以处理多任务连续微调。最终，论文审视了Parameter-Efficient Continual Fine-Tuning (PECFT)的现状、评估指标，并提出未来研究方向，以推动CL与PEFT的协同创新。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.13822v1",
      "published_date": "2025-04-18 17:51:51 UTC",
      "updated_date": "2025-04-18 17:51:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:23:36.683432"
    },
    {
      "arxiv_id": "2504.13818v1",
      "title": "Not All Rollouts are Useful: Down-Sampling Rollouts in LLM Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Yixuan Even Xu",
        "Yash Savani",
        "Fei Fang",
        "Zico Kolter"
      ],
      "abstract": "Reinforcement learning (RL) has emerged as a powerful paradigm for enhancing\nreasoning capabilities in large language models, but faces a fundamental\nasymmetry in computation and memory requirements: inference is embarrassingly\nparallel with a minimal memory footprint, while policy updates require\nextensive synchronization and are memory-intensive. To address this asymmetry,\nwe introduce PODS (Policy Optimization with Down-Sampling), a framework that\nstrategically decouples these phases by generating numerous rollouts in\nparallel but updating only on an informative subset. Within this framework, we\ndevelop max-variance down-sampling, a theoretically motivated method that\nselects rollouts with maximally diverse reward signals. We prove that this\napproach has an efficient algorithmic solution, and empirically demonstrate\nthat GRPO with PODS using max-variance down-sampling achieves superior\nperformance over standard GRPO on the GSM8K benchmark.",
      "tldr_zh": "这项研究探讨了强化学习（RL）在提升大型语言模型（LLM）推理能力时面临的计算和内存不对称性问题，即推断过程易于并行但内存需求小，而策略更新需要大量同步和内存。作者引入了 PODS（Policy Optimization with Down-Sampling）框架，通过并行生成众多 rollout 但仅在回报信号多样性最高的子集上进行更新来优化过程。具体而言，他们开发了 max-variance down-sampling 方法，并证明其算法效率高。实验结果显示，在 GSM8K 基准测试中，使用 PODS 的 GRPO 比标准 GRPO 表现出色，验证了该方法的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2504.13818v1",
      "published_date": "2025-04-18 17:49:55 UTC",
      "updated_date": "2025-04-18 17:49:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:23:46.952885"
    },
    {
      "arxiv_id": "2504.16117v1",
      "title": "Context-Awareness and Interpretability of Rare Occurrences for Discovery and Formalization of Critical Failure Modes",
      "title_zh": "罕见事件的上下文感知与可解释性，用于关键故障模式的发现与形式化",
      "authors": [
        "Sridevi Polavaram",
        "Xin Zhou",
        "Meenu Ravi",
        "Mohammad Zarei",
        "Anmol Srivastava"
      ],
      "abstract": "Vision systems are increasingly deployed in critical domains such as\nsurveillance, law enforcement, and transportation. However, their\nvulnerabilities to rare or unforeseen scenarios pose significant safety risks.\nTo address these challenges, we introduce Context-Awareness and\nInterpretability of Rare Occurrences (CAIRO), an ontology-based human-assistive\ndiscovery framework for failure cases (or CP - Critical Phenomena) detection\nand formalization. CAIRO by design incentivizes human-in-the-loop for testing\nand evaluation of criticality that arises from misdetections, adversarial\nattacks, and hallucinations in AI black-box models. Our robust analysis of\nobject detection model(s) failures in automated driving systems (ADS) showcases\nscalable and interpretable ways of formalizing the observed gaps between camera\nperception and real-world contexts, resulting in test cases stored as explicit\nknowledge graphs (in OWL/XML format) amenable for sharing, downstream analysis,\nlogical reasoning, and accountability.",
      "tldr_zh": "该研究针对视觉系统在监控、执法和交通等关键领域中对稀有场景的脆弱性，提出了一种基于本体论（ontology-based）的CAIRO框架，用于发现和形式化关键失败模式（Critical Phenomena）。CAIRO通过人类在环（human-in-the-loop）机制，辅助检测AI模型的误检测、敌对攻击和幻觉问题，并对自动驾驶系统（ADS）的物体检测失败进行分析。最终，该框架以可扩展、可解释的方式将测试案例形式化为知识图谱（knowledge graphs，在OWL/XML格式），便于共享、下游分析、逻辑推理和责任追踪。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to IEEE Conference for Artificial Intelligence, 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.16117v1",
      "published_date": "2025-04-18 17:12:37 UTC",
      "updated_date": "2025-04-18 17:12:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:24:00.139445"
    },
    {
      "arxiv_id": "2504.13804v1",
      "title": "Near-optimal algorithms for private estimation and sequential testing of collision probability",
      "title_zh": "翻译失败",
      "authors": [
        "Robert Busa-Fekete",
        "Umar Syed"
      ],
      "abstract": "We present new algorithms for estimating and testing \\emph{collision\nprobability}, a fundamental measure of the spread of a discrete distribution\nthat is widely used in many scientific fields. We describe an algorithm that\nsatisfies $(\\alpha, \\beta)$-local differential privacy and estimates collision\nprobability with error at most $\\epsilon$ using\n$\\tilde{O}\\left(\\frac{\\log(1/\\beta)}{\\alpha^2 \\epsilon^2}\\right)$ samples for\n$\\alpha \\le 1$, which improves over previous work by a factor of\n$\\frac{1}{\\alpha^2}$. We also present a sequential testing algorithm for\ncollision probability, which can distinguish between collision probability\nvalues that are separated by $\\epsilon$ using $\\tilde{O}(\\frac{1}{\\epsilon^2})$\nsamples, even when $\\epsilon$ is unknown. Our algorithms have nearly the\noptimal sample complexity, and in experiments we show that they require\nsignificantly fewer samples than previous methods.",
      "tldr_zh": "该论文提出近似最优算法，用于碰撞概率（collision probability）的私有估计和顺序测试，以评估离散分布的扩散度。算法一实现了（α, β）-局部差分隐私（local differential privacy），以约Õ( log(1/β) / (α² ε²) )样本估计算碰撞概率的错误不超过ε，当α ≤ 1时，比之前工作提高了1/α²的效率。算法二为顺序测试（sequential testing），能区分相差ε的碰撞概率值，使用约Õ(1 / ε²)样本，即使ε未知，并在实验中显示这些算法比现有方法显著减少样本需求。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.13804v1",
      "published_date": "2025-04-18 17:12:15 UTC",
      "updated_date": "2025-04-18 17:12:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:24:12.161772"
    },
    {
      "arxiv_id": "2504.13803v1",
      "title": "Imitation Learning with Precisely Labeled Human Demonstrations",
      "title_zh": "翻译失败",
      "authors": [
        "Yilong Song"
      ],
      "abstract": "Within the imitation learning paradigm, training generalist robots requires\nlarge-scale datasets obtainable only through diverse curation. Due to the\nrelative ease to collect, human demonstrations constitute a valuable addition\nwhen incorporated appropriately. However, existing methods utilizing human\ndemonstrations face challenges in inferring precise actions, ameliorating\nembodiment gaps, and fusing with frontier generalist robot training pipelines.\nIn this work, building on prior studies that demonstrate the viability of using\nhand-held grippers for efficient data collection, we leverage the user's\ncontrol over the gripper's appearance--specifically by assigning it a unique,\neasily segmentable color--to enable simple and reliable application of the\nRANSAC and ICP registration method for precise end-effector pose estimation. We\nshow in simulation that precisely labeled human demonstrations on their own\nallow policies to reach on average 88.1% of the performance of using robot\ndemonstrations, and boost policy performance when combined with robot\ndemonstrations, despite the inherent embodiment gap.",
      "tldr_zh": "本文提出了一种改进的模仿学习(Imitation Learning)方法，利用精确标记的人类演示来训练通用机器人，通过为手持抓取器(hand-held grippers)赋予独特易分割的颜色，并应用 RANSAC 和 ICP 注册技术来精确估计端效应器位姿，从而解决动作推断、身体差异和系统整合的挑战。实验结果显示，在模拟环境中，单独使用人类演示时，策略性能可达机器人演示的88.1%；当与机器人演示结合时，进一步提升整体性能，尽管存在固有的身体差异。总体而言，该方法为高效利用人类数据增强机器人训练提供了可行途径。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.13803v1",
      "published_date": "2025-04-18 17:12:00 UTC",
      "updated_date": "2025-04-18 17:12:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:24:24.267650"
    },
    {
      "arxiv_id": "2504.13993v1",
      "title": "CPR: Leveraging LLMs for Topic and Phrase Suggestion to Facilitate Comprehensive Product Reviews",
      "title_zh": "翻译失败",
      "authors": [
        "Ekta Gujral",
        "Apurva Sinha",
        "Lishi Ji",
        "Bijayani Sanghamitra Mishra"
      ],
      "abstract": "Consumers often heavily rely on online product reviews, analyzing both\nquantitative ratings and textual descriptions to assess product quality.\nHowever, existing research hasn't adequately addressed how to systematically\nencourage the creation of comprehensive reviews that capture both customers\nsentiment and detailed product feature analysis. This paper presents CPR, a\nnovel methodology that leverages the power of Large Language Models (LLMs) and\nTopic Modeling to guide users in crafting insightful and well-rounded reviews.\nOur approach employs a three-stage process: first, we present users with\nproduct-specific terms for rating; second, we generate targeted phrase\nsuggestions based on these ratings; and third, we integrate user-written text\nthrough topic modeling, ensuring all key aspects are addressed. We evaluate CPR\nusing text-to-text LLMs, comparing its performance against real-world customer\nreviews from Walmart. Our results demonstrate that CPR effectively identifies\nrelevant product terms, even for new products lacking prior reviews, and\nprovides sentiment-aligned phrase suggestions, saving users time and enhancing\nreviews quality. Quantitative analysis reveals a 12.3% improvement in BLEU\nscore over baseline methods, further supported by manual evaluation of\ngenerated phrases. We conclude by discussing potential extensions and future\nresearch directions.",
      "tldr_zh": "这篇论文提出 CPR 方法，利用 Large Language Models (LLMs) 和 Topic Modeling 系统引导用户创建更全面的产品评论，从而捕捉消费者情感和产品特征分析。CPR 采用三阶段过程：首先呈现产品特定术语供用户评分；其次基于评分生成针对性短语建议；最后通过 Topic Modeling 整合用户文本，确保覆盖关键方面。实验评估显示，CPR 能有效识别新产品的相关术语，提供与情感一致的建议，并在 Walmart 真实评论中实现 BLEU score 比基线方法提高 12.3%。这项工作为提升在线评论质量提供了新途径，并讨论了潜在扩展方向。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.13993v1",
      "published_date": "2025-04-18 17:11:38 UTC",
      "updated_date": "2025-04-18 17:11:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:24:36.186824"
    },
    {
      "arxiv_id": "2504.13797v1",
      "title": "Meta-Learning and Knowledge Discovery based Physics-Informed Neural Network for Remaining Useful Life Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Yu Wang",
        "Shujie Liu",
        "Shuai Lv",
        "Gengshuo Liu"
      ],
      "abstract": "Predicting the remaining useful life (RUL) of rotating machinery is critical\nfor industrial safety and maintenance, but existing methods struggle with\nscarce target-domain data and unclear degradation dynamics. We propose a\nMeta-Learning and Knowledge Discovery-based Physics-Informed Neural Network\n(MKDPINN) to address these challenges. The method first maps noisy sensor data\nto a low-dimensional hidden state space via a Hidden State Mapper (HSM). A\nPhysics-Guided Regulator (PGR) then learns unknown nonlinear PDEs governing\ndegradation evolution, embedding these physical constraints into the PINN\nframework. This integrates data-driven and physics-based approaches. The\nframework uses meta-learning, optimizing across source-domain meta-tasks to\nenable few-shot adaptation to new target tasks. Experiments on industrial data\nand the C-MAPSS benchmark show MKDPINN outperforms baselines in generalization\nand accuracy, proving its effectiveness for RUL prediction under data scarcity",
      "tldr_zh": "该研究提出了一种基于 Meta-Learning 和 Knowledge Discovery 的 Physics-Informed Neural Network（MKDPINN），用于预测旋转机械的剩余可用寿命（RUL），以解决现有方法在目标域数据稀缺和退化动态不明朗时的局限性。MKDPINN 首先通过 Hidden State Mapper（HSM）将噪声传感器数据映射到低维隐藏状态空间，然后利用 Physics-Guided Regulator（PGR）学习未知的非线性 PDEs，并将这些物理约束嵌入 PINN 框架中，实现数据驱动与物理基础方法的整合。该框架采用 Meta-Learning 在源域元任务上进行优化，从而实现对新目标任务的 few-shot adaptation。实验结果显示，在工业数据和 C-MAPSS 基准测试中，MKDPINN 在泛化和准确性上均优于基线模型，证明了其在数据稀缺条件下的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "34 pages,20 figs",
      "pdf_url": "http://arxiv.org/pdf/2504.13797v1",
      "published_date": "2025-04-18 16:58:38 UTC",
      "updated_date": "2025-04-18 16:58:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:24:49.668678"
    },
    {
      "arxiv_id": "2504.13791v1",
      "title": "Collective Learning Mechanism based Optimal Transport Generative Adversarial Network for Non-parallel Voice Conversion",
      "title_zh": "翻译失败",
      "authors": [
        "Sandipan Dhar",
        "Md. Tousin Akhter",
        "Nanda Dulal Jana",
        "Swagatam Das"
      ],
      "abstract": "After demonstrating significant success in image synthesis, Generative\nAdversarial Network (GAN) models have likewise made significant progress in the\nfield of speech synthesis, leveraging their capacity to adapt the precise\ndistribution of target data through adversarial learning processes. Notably, in\nthe realm of State-Of-The-Art (SOTA) GAN-based Voice Conversion (VC) models,\nthere exists a substantial disparity in naturalness between real and\nGAN-generated speech samples. Furthermore, while many GAN models currently\noperate on a single generator discriminator learning approach, optimizing\ntarget data distribution is more effectively achievable through a single\ngenerator multi-discriminator learning scheme. Hence, this study introduces a\nnovel GAN model named Collective Learning Mechanism-based Optimal Transport GAN\n(CLOT-GAN) model, incorporating multiple discriminators, including the Deep\nConvolutional Neural Network (DCNN) model, Vision Transformer (ViT), and\nconformer. The objective of integrating various discriminators lies in their\nability to comprehend the formant distribution of mel-spectrograms, facilitated\nby a collective learning mechanism. Simultaneously, the inclusion of Optimal\nTransport (OT) loss aims to precisely bridge the gap between the source and\ntarget data distribution, employing the principles of OT theory. The\nexperimental validation on VCC 2018, VCTK, and CMU-Arctic datasets confirms\nthat the CLOT-GAN-VC model outperforms existing VC models in objective and\nsubjective assessments.",
      "tldr_zh": "本研究提出了一种名为 CLOT-GAN 的新 GAN 模型，用于非平行 Voice Conversion，旨在通过集体学习机制和 Optimal Transport loss 改善生成语音的自然性和分布匹配问题。模型采用多个判别器，包括 DCNN、ViT 和 Conformer，来共同理解 mel-spectrogram 的 formant 分布，从而优化目标数据分布。实验结果显示，在 VCC 2018、VCTK 和 CMU-Arctic 数据集上，CLOT-GAN-VC 模型在客观和主观评估中均优于现有 Voice Conversion 模型。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "7 pages, 2 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2504.13791v1",
      "published_date": "2025-04-18 16:44:01 UTC",
      "updated_date": "2025-04-18 16:44:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:25:00.160270"
    },
    {
      "arxiv_id": "2504.16116v2",
      "title": "DMind Benchmark: Toward a Holistic Assessment of LLM Capabilities across the Web3 Domain",
      "title_zh": "翻译失败",
      "authors": [
        "Enhao Huang",
        "Pengyu Sun",
        "Zixin Lin",
        "Alex Chen",
        "Joey Ouyang",
        "Hobert Wang",
        "Dong Dong",
        "Gang Zhao",
        "James Yi",
        "Frank Li",
        "Ziang Ling",
        "Lowes Yang"
      ],
      "abstract": "Large Language Models (LLMs) have achieved impressive performance in diverse\nnatural language processing tasks, but specialized domains such as Web3 present\nnew challenges and require more tailored evaluation. Despite the significant\nuser base and capital flows in Web3, encompassing smart contracts,\ndecentralized finance (DeFi), non-fungible tokens (NFTs), decentralized\nautonomous organizations (DAOs), on-chain governance, and novel\ntoken-economics, no comprehensive benchmark has systematically assessed LLM\nperformance in this domain. To address this gap, we introduce the DMind\nBenchmark, a holistic Web3-oriented evaluation suite covering nine critical\nsubfields: fundamental blockchain concepts, blockchain infrastructure, smart\ncontract, DeFi mechanisms, DAOs, NFTs, token economics, meme concept, and\nsecurity vulnerabilities. Beyond multiple-choice questions, DMind Benchmark\nfeatures domain-specific tasks such as contract debugging and on-chain numeric\nreasoning, mirroring real-world scenarios. We evaluated 26 models, including\nChatGPT, Claude, DeepSeek, Gemini, Grok, and Qwen, uncovering notable\nperformance gaps in specialized areas like token economics and\nsecurity-critical contract analysis. While some models excel in blockchain\ninfrastructure tasks, advanced subfields remain challenging. Our benchmark\ndataset and evaluation pipeline are open-sourced on\nhttps://huggingface.co/datasets/DMindAI/DMind_Benchmark, reaching number one in\nHugging Face's trending dataset charts within a week of release.",
      "tldr_zh": "这篇论文引入了 DMind Benchmark，这是一个全面评估大型语言模型 (LLMs) 在 Web3 领域能力的基准测试，旨在填补现有评估的空白。基准覆盖九个关键子领域，包括 fundamental blockchain concepts、blockchain infrastructure、smart contract、DeFi mechanisms、DAOs、NFTs、token economics、meme concept 和 security vulnerabilities，并包含多选题以外的领域特定任务，如 contract debugging 和 on-chain numeric reasoning，以模拟真实场景。研究团队评估了 26 个模型（如 ChatGPT、Claude 和 Gemini），发现模型在 token economics 和 security vulnerabilities 等专业领域存在显著性能差距，尽管有些模型在 blockchain infrastructure 任务上表现出色。该基准的数据集和评估管道已开源在 Hugging Face 上，并迅速成为热门资源。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.16116v2",
      "published_date": "2025-04-18 16:40:39 UTC",
      "updated_date": "2025-05-16 12:00:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:25:12.551021"
    },
    {
      "arxiv_id": "2504.13787v2",
      "title": "Probabilistic Stability Guarantees for Feature Attributions",
      "title_zh": "针对特征归因的概率稳定性保证",
      "authors": [
        "Helen Jin",
        "Anton Xue",
        "Weiqiu You",
        "Surbhi Goel",
        "Eric Wong"
      ],
      "abstract": "Stability guarantees have emerged as a principled way to evaluate feature\nattributions, but existing certification methods rely on heavily smoothed\nclassifiers and often produce conservative guarantees. To address these\nlimitations, we introduce soft stability and propose a simple, model-agnostic,\nsample-efficient stability certification algorithm (SCA) that yields\nnon-trivial and interpretable guarantees for any attribution method. Moreover,\nwe show that mild smoothing achieves a more favorable trade-off between\naccuracy and stability, avoiding the aggressive compromises made in prior\ncertification methods. To explain this behavior, we use Boolean function\nanalysis to derive a novel characterization of stability under smoothing. We\nevaluate SCA on vision and language tasks and demonstrate the effectiveness of\nsoft stability in measuring the robustness of explanation methods.",
      "tldr_zh": "这篇论文针对特征归因（feature attributions）的稳定性保证问题，引入了 soft stability 概念，并提出了一种简单、模型无关且样本高效的稳定性认证算法（SCA），为各种归因方法提供非平凡且可解释的保证。SCA 通过轻微平滑优化了准确性和稳定性之间的权衡，避免了现有方法中过度平滑的保守性，并利用布尔函数分析（Boolean function analysis）对平滑下的稳定性进行了新颖的表征。在视觉和语言任务上的实验验证了 soft stability 在评估解释方法鲁棒性方面的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.13787v2",
      "published_date": "2025-04-18 16:39:08 UTC",
      "updated_date": "2025-05-17 15:16:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:25:23.635989"
    },
    {
      "arxiv_id": "2504.13785v1",
      "title": "Learning Through Retrospection: Improving Trajectory Prediction for Automated Driving with Error Feedback",
      "title_zh": "翻译失败",
      "authors": [
        "Steffen Hagedorn",
        "Aron Distelzweig",
        "Marcel Hallgarten",
        "Alexandru P. Condurache"
      ],
      "abstract": "In automated driving, predicting trajectories of surrounding vehicles\nsupports reasoning about scene dynamics and enables safe planning for the ego\nvehicle. However, existing models handle predictions as an instantaneous task\nof forecasting future trajectories based on observed information. As time\nproceeds, the next prediction is made independently of the previous one, which\nmeans that the model cannot correct its errors during inference and will repeat\nthem. To alleviate this problem and better leverage temporal data, we propose a\nnovel retrospection technique. Through training on closed-loop rollouts the\nmodel learns to use aggregated feedback. Given new observations it reflects on\nprevious predictions and analyzes its errors to improve the quality of\nsubsequent predictions. Thus, the model can learn to correct systematic errors\nduring inference. Comprehensive experiments on nuScenes and Argoverse\ndemonstrate a considerable decrease in minimum Average Displacement Error of up\nto 31.9% compared to the state-of-the-art baseline without retrospection. We\nfurther showcase the robustness of our technique by demonstrating a better\nhandling of out-of-distribution scenarios with undetected road-users.",
      "tldr_zh": "该论文针对自动驾驶中的轨迹预测问题，提出了一种名为“retrospection”的新颖技术，以解决现有模型无法纠正错误并重复它们的问题。通过在closed-loop rollouts上训练，模型学会利用aggregated feedback来反思之前的预测，分析错误并改进后续预测，从而提升预测的准确性和鲁棒性。在nuScenes和Argoverse数据集上的实验显示，与最先进基线相比，最小Average Displacement Error减少了多达31.9%，并在处理out-of-distribution场景（如未检测到的道路使用者）时表现出色。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.13785v1",
      "published_date": "2025-04-18 16:35:12 UTC",
      "updated_date": "2025-04-18 16:35:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:25:36.238653"
    },
    {
      "arxiv_id": "2504.13777v1",
      "title": "Beyond Misinformation: A Conceptual Framework for Studying AI Hallucinations in (Science) Communication",
      "title_zh": "翻译失败",
      "authors": [
        "Anqi Shao"
      ],
      "abstract": "This paper proposes a conceptual framework for understanding AI\nhallucinations as a distinct form of misinformation. While misinformation\nscholarship has traditionally focused on human intent, generative AI systems\nnow produce false yet plausible outputs absent of such intent. I argue that\nthese AI hallucinations should not be treated merely as technical failures but\nas communication phenomena with social consequences. Drawing on a\nsupply-and-demand model and the concept of distributed agency, the framework\noutlines how hallucinations differ from human-generated misinformation in\nproduction, perception, and institutional response. I conclude by outlining a\nresearch agenda for communication scholars to investigate the emergence,\ndissemination, and audience reception of hallucinated content, with attention\nto macro (institutional), meso (group), and micro (individual) levels. This\nwork urges communication researchers to rethink the boundaries of\nmisinformation theory in light of probabilistic, non-human actors increasingly\nembedded in knowledge production.",
      "tldr_zh": "这篇论文提出一个概念框架，将 AI hallucinations 视为一种独立于传统 misinformation 的现象，因为这些 AI 生成的虚假内容缺乏人类意图，而是具有社会后果的通信问题。框架基于 supply-and-demand 模型和 distributed agency 概念，分析了 AI hallucinations 在生产、感知和机构响应方面与人类生成 misinformation 的差异。作者呼吁通信学者制定研究议程，从宏观（机构）、中观（群体）和微观（个体）层面探讨 hallucinated 内容的产生、传播和受众接受，从而重新审视 misinformation 理论以适应 AI 在知识生产中的角色。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.13777v1",
      "published_date": "2025-04-18 16:26:02 UTC",
      "updated_date": "2025-04-18 16:26:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:25:47.594812"
    },
    {
      "arxiv_id": "2504.13774v1",
      "title": "DP2Unlearning: An Efficient and Guaranteed Unlearning Framework for LLMs",
      "title_zh": "DP2Unlearning：针对LLMs的高效且有保证的遗忘框架",
      "authors": [
        "Tamim Al Mahmud",
        "Najeeb Jebreel",
        "Josep Domingo-Ferrer",
        "David Sanchez"
      ],
      "abstract": "Large language models (LLMs) have recently revolutionized language processing\ntasks but have also brought ethical and legal issues. LLMs have a tendency to\nmemorize potentially private or copyrighted information present in the training\ndata, which might then be delivered to end users at inference time. When this\nhappens, a naive solution is to retrain the model from scratch after excluding\nthe undesired data. Although this guarantees that the target data have been\nforgotten, it is also prohibitively expensive for LLMs. Approximate unlearning\noffers a more efficient alternative, as it consists of ex post modifications of\nthe trained model itself to prevent undesirable results, but it lacks\nforgetting guarantees because it relies solely on empirical evidence. In this\nwork, we present DP2Unlearning, a novel LLM unlearning framework that offers\nformal forgetting guarantees at a significantly lower cost than retraining from\nscratch on the data to be retained. DP2Unlearning involves training LLMs on\ntextual data protected using {\\epsilon}-differential privacy (DP), which later\nenables efficient unlearning with the guarantees against disclosure associated\nwith the chosen {\\epsilon}. Our experiments demonstrate that DP2Unlearning\nachieves similar model performance post-unlearning, compared to an LLM\nretraining from scratch on retained data -- the gold standard exact unlearning\n-- but at approximately half the unlearning cost. In addition, with a\nreasonable computational cost, it outperforms approximate unlearning methods at\nboth preserving the utility of the model post-unlearning and effectively\nforgetting the targeted information.",
      "tldr_zh": "该研究针对大语言模型(LLMs)可能记忆并泄露训练数据中的私人或版权信息的问题，提出了一种高效且具有正式遗忘保证的框架——DP2Unlearning。框架利用ε-differential privacy (DP)保护训练数据，实现对特定信息的快速遗忘，而无需从零重新训练，仅需约一半的成本。实验结果显示，DP2Unlearning在保持模型性能的同时，显著优于传统近似遗忘方法，既有效消除目标信息又维持了模型的整体效用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "49 pages",
      "pdf_url": "http://arxiv.org/pdf/2504.13774v1",
      "published_date": "2025-04-18 16:22:20 UTC",
      "updated_date": "2025-04-18 16:22:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:25:59.720144"
    },
    {
      "arxiv_id": "2504.13763v2",
      "title": "Decoding Vision Transformers: the Diffusion Steering Lens",
      "title_zh": "翻译失败",
      "authors": [
        "Ryota Takatsuki",
        "Sonia Joseph",
        "Ippei Fujisawa",
        "Ryota Kanai"
      ],
      "abstract": "Logit Lens is a widely adopted method for mechanistic interpretability of\ntransformer-based language models, enabling the analysis of how internal\nrepresentations evolve across layers by projecting them into the output\nvocabulary space. Although applying Logit Lens to Vision Transformers (ViTs) is\ntechnically straightforward, its direct use faces limitations in capturing the\nrichness of visual representations. Building on the work of Toker et al.\n(2024)~\\cite{Toker2024-ve}, who introduced Diffusion Lens to visualize\nintermediate representations in the text encoders of text-to-image diffusion\nmodels, we demonstrate that while Diffusion Lens can effectively visualize\nresidual stream representations in image encoders, it fails to capture the\ndirect contributions of individual submodules. To overcome this limitation, we\npropose \\textbf{Diffusion Steering Lens} (DSL), a novel, training-free approach\nthat steers submodule outputs and patches subsequent indirect contributions. We\nvalidate our method through interventional studies, showing that DSL provides\nan intuitive and reliable interpretation of the internal processing in ViTs.",
      "tldr_zh": "这篇论文探讨了 Logit Lens 在 Vision Transformers (ViTs) 中的局限性，即其无法充分捕捉视觉表示的丰富性，尽管它在语言模型中广泛用于分析层间表示演变。作者基于 Diffusion Lens 的相关工作，提出了一种新型的无需训练方法——Diffusion Steering Lens (DSL)，它通过引导子模块输出并处理后续间接贡献，来提供更精确的内部表示解释。通过干预研究验证，DSL 展示了在 ViTs 内部处理的可视化和可靠性，为机制解释性研究提供了直观工具。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "12 pages, 17 figures. Accepted to the CVPR 2025 Workshop on\n  Mechanistic Interpretability for Vision (MIV)",
      "pdf_url": "http://arxiv.org/pdf/2504.13763v2",
      "published_date": "2025-04-18 16:00:53 UTC",
      "updated_date": "2025-04-23 10:04:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:26:11.735820"
    },
    {
      "arxiv_id": "2504.16115v1",
      "title": "A Framework for Objective-Driven Dynamical Stochastic Fields",
      "title_zh": "目标驱动动态随机场的框架",
      "authors": [
        "Yibo Jacky Zhang",
        "Sanmi Koyejo"
      ],
      "abstract": "Fields offer a versatile approach for describing complex systems composed of\ninteracting and dynamic components. In particular, some of these dynamical and\nstochastic systems may exhibit goal-directed behaviors aimed at achieving\nspecific objectives, which we refer to as $\\textit{intelligent fields}$.\nHowever, due to their inherent complexity, it remains challenging to develop a\nformal theoretical description of such systems and to effectively translate\nthese descriptions into practical applications. In this paper, we propose three\nfundamental principles -- complete configuration, locality, and purposefulness\n-- to establish a theoretical framework for understanding intelligent fields.\nMoreover, we explore methodologies for designing such fields from the\nperspective of artificial intelligence applications. This initial investigation\naims to lay the groundwork for future theoretical developments and practical\nadvances in understanding and harnessing the potential of such objective-driven\ndynamical stochastic fields.",
      "tldr_zh": "这篇论文提出一个框架，用于理解和设计目标导向的动态随机领域（objective-driven dynamical stochastic fields），这些领域描述了表现出智能行为的复杂系统。框架基于三个基本原则：complete configuration、locality 和 purposefulness，以提供正式的理论描述。作者探讨了从人工智能应用视角设计这些领域的相关方法，为未来理论发展和实际应用奠定基础。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.MA",
        "nlin.AO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.16115v1",
      "published_date": "2025-04-18 15:46:33 UTC",
      "updated_date": "2025-04-18 15:46:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:26:22.962338"
    },
    {
      "arxiv_id": "2504.13756v1",
      "title": "Scaling sparse feature circuit finding for in-context learning",
      "title_zh": "翻译失败",
      "authors": [
        "Dmitrii Kharlapenko",
        "Stepan Shabalin",
        "Fazl Barez",
        "Arthur Conmy",
        "Neel Nanda"
      ],
      "abstract": "Sparse autoencoders (SAEs) are a popular tool for interpreting large language\nmodel activations, but their utility in addressing open questions in\ninterpretability remains unclear. In this work, we demonstrate their\neffectiveness by using SAEs to deepen our understanding of the mechanism behind\nin-context learning (ICL). We identify abstract SAE features that (i) encode\nthe model's knowledge of which task to execute and (ii) whose latent vectors\ncausally induce the task zero-shot. This aligns with prior work showing that\nICL is mediated by task vectors. We further demonstrate that these task vectors\nare well approximated by a sparse sum of SAE latents, including these\ntask-execution features. To explore the ICL mechanism, we adapt the sparse\nfeature circuits methodology of Marks et al. (2024) to work for the much larger\nGemma-1 2B model, with 30 times as many parameters, and to the more complex\ntask of ICL. Through circuit finding, we discover task-detecting features with\ncorresponding SAE latents that activate earlier in the prompt, that detect when\ntasks have been performed. They are causally linked with task-execution\nfeatures through the attention and MLP sublayers.",
      "tldr_zh": "本文研究利用 Sparse Autoencoders (SAEs) 解释大语言模型激活，以深化对 in-context learning (ICL) 机制的理解。研究者识别了抽象 SAE 特征，这些特征编码了模型的任务执行知识，并通过潜在向量实现零样本任务诱导，同时证明任务向量可由稀疏 SAE 潜力的和近似。作者扩展了 Marks et al. (2024) 的稀疏特征电路方法，应用于更大的 Gemma-1 2B 模型，发现任务检测特征在提示早期激活，并通过注意力层和 MLP 子层与任务执行特征形成因果联系，从而揭示 ICL 的潜在机制。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.13756v1",
      "published_date": "2025-04-18 15:45:30 UTC",
      "updated_date": "2025-04-18 15:45:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:26:36.062404"
    },
    {
      "arxiv_id": "2504.13754v3",
      "title": "Towards Accurate and Interpretable Neuroblastoma Diagnosis via Contrastive Multi-scale Pathological Image Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Zhu Zhu",
        "Shuo Jiang",
        "Jingyuan Zheng",
        "Yawen Li",
        "Yifei Chen",
        "Manli Zhao",
        "Weizhong Gu",
        "Feiwei Qin",
        "Jinhu Wang",
        "Gang Yu"
      ],
      "abstract": "Neuroblastoma, adrenal-derived, is among the most common pediatric solid\nmalignancies, characterized by significant clinical heterogeneity. Timely and\naccurate pathological diagnosis from hematoxylin and eosin-stained whole-slide\nimages is critical for patient prognosis. However, current diagnostic practices\nprimarily rely on subjective manual examination by pathologists, leading to\ninconsistent accuracy. Existing automated whole-slide image classification\nmethods encounter challenges such as poor interpretability, limited feature\nextraction capabilities, and high computational costs, restricting their\npractical clinical deployment. To overcome these limitations, we propose\nCMSwinKAN, a contrastive-learning-based multi-scale feature fusion model\ntailored for pathological image classification, which enhances the Swin\nTransformer architecture by integrating a Kernel Activation Network within its\nmultilayer perceptron and classification head modules, significantly improving\nboth interpretability and accuracy. By fusing multi-scale features and\nleveraging contrastive learning strategies, CMSwinKAN mimics clinicians'\ncomprehensive approach, effectively capturing global and local tissue\ncharacteristics. Additionally, we introduce a heuristic soft voting mechanism\nguided by clinical insights to bridge patch-level predictions to whole-slide\nimage-level classifications seamlessly. We verified the CMSwinKAN on the\npublicly available BreakHis dataset and the PpNTs dataset, which was\nestablished by our hospital. Results demonstrate that CMSwinKAN performs better\nthan existing state-of-the-art pathology-specific models pre-trained on large\ndatasets. Our source code is available at\nhttps://github.com/JSLiam94/CMSwinKAN.",
      "tldr_zh": "该论文针对神经母细胞瘤诊断的临床挑战，提出了一种基于对比学习（contrastive learning）的多尺度特征融合模型CMSwinKAN，以提高诊断的准确性和可解释性。CMSwinKAN在Swin Transformer架构基础上整合Kernel Activation Network到多层感知器和分类头模块中，并通过融合多尺度特征和启发式软投票机制，模仿临床医生的全局和局部组织分析方法。实验结果显示，该模型在公开的BreakHis数据集和自建的PpNTs数据集上，优于现有的state-of-the-art病理特定模型，为自动化病理诊断提供了更可靠的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "10pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.13754v3",
      "published_date": "2025-04-18 15:39:46 UTC",
      "updated_date": "2025-05-06 12:45:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:26:48.061719"
    },
    {
      "arxiv_id": "2504.13751v1",
      "title": "A Survey for What Developers Require in AI-powered Tools that Aid in Component Selection in CBSD",
      "title_zh": "翻译失败",
      "authors": [
        "Mahdi Jaberzadeh Ansari",
        "Ann Barcomb"
      ],
      "abstract": "Although it has been more than four decades that the first components-based\nsoftware development (CBSD) studies were conducted, there is still no standard\nmethod or tool for component selection which is widely accepted by the\nindustry. The gulf between industry and academia contributes to the lack of an\naccepted tool. We conducted a mixed methods survey of nearly 100 people engaged\nin component-based software engineering practice or research to better\nunderstand the problems facing industry, how these needs could be addressed,\nand current best practices employed in component selection. We also sought to\nidentify and prioritize quality criteria for component selection from an\nindustry perspective. In response to the call for CBSD component selection\ntools to incorporate recent technical advances, we also explored the\nperceptions of professionals about AI-driven tools, present and envisioned.",
      "tldr_zh": "这项调查探讨了开发者在组件化软件开发(CBSD)中对AI驱动工具的需求，旨在桥接行业与学术界的差距，以解决组件选择缺乏标准方法的问题。研究通过对近100名从事CBSD实践或研究的参与者进行混合方法调查，识别了行业面临的挑战、当前最佳实践以及组件选择的质量标准优先级。同时，调查揭示了专业人士对AI驱动工具的看法，包括现有工具的评价和对未来工具的愿景，为开发更有效的AI辅助组件选择工具提供了宝贵见解。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.SE",
      "comment": "10 pages, 4 figures, The 29th International Conference on Evaluation\n  and Assessment in Software Engineering, 17 to 20 June, 2025, Istanbul, Turkey",
      "pdf_url": "http://arxiv.org/pdf/2504.13751v1",
      "published_date": "2025-04-18 15:35:31 UTC",
      "updated_date": "2025-04-18 15:35:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:26:59.084926"
    },
    {
      "arxiv_id": "2504.13745v1",
      "title": "ESPLoRA: Enhanced Spatial Precision with Low-Rank Adaption in Text-to-Image Diffusion Models for High-Definition Synthesis",
      "title_zh": "翻译失败",
      "authors": [
        "Andrea Rigo",
        "Luca Stornaiuolo",
        "Mauro Martino",
        "Bruno Lepri",
        "Nicu Sebe"
      ],
      "abstract": "Diffusion models have revolutionized text-to-image (T2I) synthesis, producing\nhigh-quality, photorealistic images. However, they still struggle to properly\nrender the spatial relationships described in text prompts. To address the lack\nof spatial information in T2I generations, existing methods typically use\nexternal network conditioning and predefined layouts, resulting in higher\ncomputational costs and reduced flexibility. Our approach builds upon a curated\ndataset of spatially explicit prompts, meticulously extracted and synthesized\nfrom LAION-400M to ensure precise alignment between textual descriptions and\nspatial layouts. Alongside this dataset, we present ESPLoRA, a flexible\nfine-tuning framework based on Low-Rank Adaptation, specifically designed to\nenhance spatial consistency in generative models without increasing generation\ntime or compromising the quality of the outputs. In addition to ESPLoRA, we\npropose refined evaluation metrics grounded in geometric constraints, capturing\n3D spatial relations such as \\textit{in front of} or \\textit{behind}. These\nmetrics also expose spatial biases in T2I models which, even when not fully\nmitigated, can be strategically exploited by our TORE algorithm to further\nimprove the spatial consistency of generated images. Our method outperforms the\ncurrent state-of-the-art framework, CoMPaSS, by 13.33% on established spatial\nconsistency benchmarks.",
      "tldr_zh": "该研究针对文本到图像(T2I)扩散模型在渲染空间关系方面的不足，构建了一个精选数据集，从LAION-400M中提取空间明确的提示，以确保文本描述与布局的精确对齐。作者提出了ESPLoRA框架，这是一种基于Low-Rank Adaptation的灵活微调方法，能够提升生成模型的空间一致性，而不增加生成时间或降低输出质量；同时，引入了基于几何约束的改进评估指标和TORE算法来利用模型的空间偏差，进一步优化图像生成。实验结果显示，ESPLoRA在空间一致性基准上比当前最先进框架CoMPaSS提高了13.33%。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "I.4.0"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.13745v1",
      "published_date": "2025-04-18 15:21:37 UTC",
      "updated_date": "2025-04-18 15:21:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:27:12.562980"
    },
    {
      "arxiv_id": "2504.16947v1",
      "title": "SCRAG: Social Computing-Based Retrieval Augmented Generation for Community Response Forecasting in Social Media Environments",
      "title_zh": "SCRAG：基于社会计算的检索增强生成，用于社交媒体环境中的社区响应预测",
      "authors": [
        "Dachun Sun",
        "You Lyu",
        "Jinning Li",
        "Yizhuo Chen",
        "Tianshi Wang",
        "Tomoyoshi Kimura",
        "Tarek Abdelzaher"
      ],
      "abstract": "This paper introduces SCRAG, a prediction framework inspired by social\ncomputing, designed to forecast community responses to real or hypothetical\nsocial media posts. SCRAG can be used by public relations specialists (e.g., to\ncraft messaging in ways that avoid unintended misinterpretations) or public\nfigures and influencers (e.g., to anticipate social responses), among other\napplications related to public sentiment prediction, crisis management, and\nsocial what-if analysis. While large language models (LLMs) have achieved\nremarkable success in generating coherent and contextually rich text, their\nreliance on static training data and susceptibility to hallucinations limit\ntheir effectiveness at response forecasting in dynamic social media\nenvironments. SCRAG overcomes these challenges by integrating LLMs with a\nRetrieval-Augmented Generation (RAG) technique rooted in social computing.\nSpecifically, our framework retrieves (i) historical responses from the target\ncommunity to capture their ideological, semantic, and emotional makeup, and\n(ii) external knowledge from sources such as news articles to inject\ntime-sensitive context. This information is then jointly used to forecast the\nresponses of the target community to new posts or narratives. Extensive\nexperiments across six scenarios on the X platform (formerly Twitter), tested\nwith various embedding models and LLMs, demonstrate over 10% improvements on\naverage in key evaluation metrics. A concrete example further shows its\neffectiveness in capturing diverse ideologies and nuances. Our work provides a\nsocial computing tool for applications where accurate and concrete insights\ninto community responses are crucial.",
      "tldr_zh": "这篇论文提出了 SCRAG 框架，这是一种基于社会计算的检索增强生成(RAG)方法，用于预测社交媒体社区对真实或假设帖子的响应响应。SCRAG 通过整合大型语言模型(LLMs)并检索目标社区的历史响应（捕捉意识形态、语义和情感）和外部知识（如新闻文章），来克服 LLMs 在动态环境中的幻觉和数据局限问题，从而生成更准确的社区响应预测。实验在 X 平台（原 Twitter）的六个场景中，使用各种嵌入模型和 LLMs，显示平均改善超过 10% 的关键评估指标，并通过具体示例证明了其在捕捉多样意识形态和细微差别的有效性。该框架为公关、危机管理和公众情绪预测等应用提供了可靠的社会计算工具。",
      "categories": [
        "cs.SI",
        "cs.AI"
      ],
      "primary_category": "cs.SI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.16947v1",
      "published_date": "2025-04-18 15:02:31 UTC",
      "updated_date": "2025-04-18 15:02:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:27:24.615688"
    },
    {
      "arxiv_id": "2504.13730v1",
      "title": "Controlled Territory and Conflict Tracking (CONTACT): (Geo-)Mapping Occupied Territory from Open Source Intelligence",
      "title_zh": "翻译失败",
      "authors": [
        "Paul K. Mandal",
        "Cole Leo",
        "Connor Hurley"
      ],
      "abstract": "Open-source intelligence provides a stream of unstructured textual data that\ncan inform assessments of territorial control. We present CONTACT, a framework\nfor territorial control prediction using large language models (LLMs) and\nminimal supervision. We evaluate two approaches: SetFit, an embedding-based\nfew-shot classifier, and a prompt tuning method applied to BLOOMZ-560m, a\nmultilingual generative LLM. Our model is trained on a small hand-labeled\ndataset of news articles covering ISIS activity in Syria and Iraq, using\nprompt-conditioned extraction of control-relevant signals such as military\noperations, casualties, and location references. We show that the BLOOMZ-based\nmodel outperforms the SetFit baseline, and that prompt-based supervision\nimproves generalization in low-resource settings. CONTACT demonstrates that\nLLMs fine-tuned using few-shot methods can reduce annotation burdens and\nsupport structured inference from open-ended OSINT streams. Our code is\navailable at https://github.com/PaulKMandal/CONTACT/.",
      "tldr_zh": "本研究提出了 CONTACT 框架，利用大型语言模型 (LLMs) 和最小监督来预测领土控制，基于开源情报 (OSINT) 的非结构化文本数据。该框架评估了两种方法：SetFit（一种基于嵌入的少样本分类器）和对 BLOOMZ-560m 的提示调整，并在小型手标注数据集上训练，提取与控制相关的信号，如军事行动、伤亡和位置信息。结果显示，BLOOMZ 模型优于 SetFit 基线，且提示监督在低资源环境中提升了模型的泛化能力；CONTACT 通过减少标注负担，支持从开放 OSINT 流中进行结构化推理，并提供了开源代码以便进一步应用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "I.2.7; I.2.6; I.2.8; H.3.1; K.4.1"
      ],
      "primary_category": "cs.CL",
      "comment": "7 pages, 1 figure, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2504.13730v1",
      "published_date": "2025-04-18 14:57:07 UTC",
      "updated_date": "2025-04-18 14:57:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:27:35.304839"
    },
    {
      "arxiv_id": "2504.13717v1",
      "title": "Human-aligned Deep Learning: Explainability, Causality, and Biological Inspiration",
      "title_zh": "人类对齐的深度学习：可解释性、因果性与生物灵感",
      "authors": [
        "Gianluca Carloni"
      ],
      "abstract": "This work aligns deep learning (DL) with human reasoning capabilities and\nneeds to enable more efficient, interpretable, and robust image classification.\nWe approach this from three perspectives: explainability, causality, and\nbiological vision. Introduction and background open this work before diving\ninto operative chapters. First, we assess neural networks' visualization\ntechniques for medical images and validate an explainable-by-design method for\nbreast mass classification. A comprehensive review at the intersection of XAI\nand causality follows, where we introduce a general scaffold to organize past\nand future research, laying the groundwork for our second perspective. In the\ncausality direction, we propose novel modules that exploit feature\nco-occurrence in medical images, leading to more effective and explainable\npredictions. We further introduce CROCODILE, a general framework that\nintegrates causal concepts, contrastive learning, feature disentanglement, and\nprior knowledge to enhance generalization. Lastly, we explore biological\nvision, examining how humans recognize objects, and propose CoCoReco, a\nconnectivity-inspired network with context-aware attention mechanisms. Overall,\nour key findings include: (i) simple activation maximization lacks insight for\nmedical imaging DL models; (ii) prototypical-part learning is effective and\nradiologically aligned; (iii) XAI and causal ML are deeply connected; (iv) weak\ncausal signals can be leveraged without a priori information to improve\nperformance and interpretability; (v) our framework generalizes across medical\ndomains and out-of-distribution data; (vi) incorporating biological circuit\nmotifs improves human-aligned recognition. This work contributes toward\nhuman-aligned DL and highlights pathways to bridge the gap between research and\nclinical adoption, with implications for improved trust, diagnostic accuracy,\nand safe deployment.",
      "tldr_zh": "这篇论文探讨了如何使Deep Learning与人类推理对齐，以提升图像分类的效率、可解释性和鲁棒性，从Explainability（可解释性）、Causality（因果性）和Biological Vision（生物视觉）三个角度入手。作者评估了神经网络的可视化技术，验证了一种针对乳腺肿块分类的可解释设计方法，并提出新型模块利用医疗图像中的特征共现，以及CROCODILE框架，整合因果概念、对比学习和特征解耦来提高泛化能力。论文还引入CoCoReco网络，受生物视觉连接性启发，采用上下文感知注意力机制来增强人类对齐的识别。关键发现包括XAI与因果ML的深度连接、弱因果信号的利用以及框架在医疗领域和分布外数据的泛化效果，最终为DL的临床应用提供路径，提高信任、诊断准确性和安全性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "eess.IV",
        "q-bio.NC",
        "I.2; I.2.6; I.4; I.4.7; I.5; J.3; J.6"
      ],
      "primary_category": "cs.CV",
      "comment": "Personal adaptation and expansion of doctoral thesis (originally\n  submitted in Oct 2024, revisioned in Jan 2025)",
      "pdf_url": "http://arxiv.org/pdf/2504.13717v1",
      "published_date": "2025-04-18 14:40:58 UTC",
      "updated_date": "2025-04-18 14:40:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:27:49.987051"
    },
    {
      "arxiv_id": "2504.15304v1",
      "title": "Can Machine Learning Agents Deal with Hard Choices?",
      "title_zh": "机器学习代理能处理困难选择吗？",
      "authors": [
        "Kangyu Wang"
      ],
      "abstract": "Machine Learning ML agents have been increasingly used in decision-making\nacross a wide range of tasks and environments. These ML agents are typically\ndesigned to balance multiple objectives when making choices. Understanding how\ntheir decision-making processes align with or diverge from human reasoning is\nessential. Human agents often encounter hard choices, that is, situations where\noptions are incommensurable; neither option is preferred, yet the agent is not\nindifferent between them. In such cases, human agents can identify hard choices\nand resolve them through deliberation. In contrast, current ML agents, due to\nfundamental limitations in Multi-Objective Optimisation or MOO methods, cannot\nidentify hard choices, let alone resolve them. Neither Scalarised Optimisation\nnor Pareto Optimisation, the two principal MOO approaches, can capture\nincommensurability. This limitation generates three distinct alignment\nproblems: the alienness of ML decision-making behaviour from a human\nperspective; the unreliability of preference-based alignment strategies for\nhard choices; and the blockage of alignment strategies pursuing multiple\nobjectives. Evaluating two potential technical solutions, I recommend an\nensemble solution that appears most promising for enabling ML agents to\nidentify hard choices and mitigate alignment problems. However, no known\ntechnique allows ML agents to resolve hard choices through deliberation, as\nthey cannot autonomously change their goals. This underscores the\ndistinctiveness of human agency and urges ML researchers to reconceptualise\nmachine autonomy and develop frameworks and methods that can better address\nthis fundamental gap.",
      "tldr_zh": "这篇论文探讨了机器学习(ML)代理在处理“hard choices”时的能力，这些情境涉及选项不可比较，既无明显偏好又非无所谓。作者指出，当前的多目标优化(MOO)方法，如Scalarised Optimisation和Pareto Optimisation，无法捕捉incommensurability，导致三个alignment问题：ML决策行为异化人类、偏好-based策略不可靠，以及多目标alignment的阻碍。论文评估了两种技术解决方案，推荐了ensemble方法来帮助ML代理识别hard choices并缓解这些问题；然而，ML代理无法像人类一样通过审议自主改变目标，这强调了人类代理的独特性，并呼吁ML研究者重新概念化机器自治。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "22 pages excluding bibliography, 27 pagas including bibliography, 3\n  figures",
      "pdf_url": "http://arxiv.org/pdf/2504.15304v1",
      "published_date": "2025-04-18 14:38:27 UTC",
      "updated_date": "2025-04-18 14:38:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:28:00.352181"
    },
    {
      "arxiv_id": "2504.13990v1",
      "title": "PC-DeepNet: A GNSS Positioning Error Minimization Framework Using Permutation-Invariant Deep Neural Network",
      "title_zh": "翻译失败",
      "authors": [
        "M. Humayun Kabir",
        "Md. Ali Hasan",
        "Md. Shafiqul Islam",
        "Kyeongjun Ko",
        "Wonjae Shin"
      ],
      "abstract": "Global navigation satellite systems (GNSS) face significant challenges in\nurban and sub-urban areas due to non-line-of-sight (NLOS) propagation,\nmultipath effects, and low received power levels, resulting in highly\nnon-linear and non-Gaussian measurement error distributions. In light of this,\nconventional model-based positioning approaches, which rely on Gaussian error\napproximations, struggle to achieve precise localization under these\nconditions. To overcome these challenges, we put forth a novel learning-based\nframework, PC-DeepNet, that employs a permutation-invariant (PI) deep neural\nnetwork (DNN) to estimate position corrections (PC). This approach is designed\nto ensure robustness against changes in the number and/or order of visible\nsatellite measurements, a common issue in GNSS systems, while leveraging NLOS\nand multipath indicators as features to enhance positioning accuracy in\nchallenging urban and sub-urban environments. To validate the performance of\nthe proposed framework, we compare the positioning error with state-of-the-art\nmodel-based and learning-based positioning methods using two publicly available\ndatasets. The results confirm that proposed PC-DeepNet achieves superior\naccuracy than existing model-based and learning-based methods while exhibiting\nlower computational complexity compared to previous learning-based approaches.",
      "tldr_zh": "本研究针对GNSS在城市和郊区环境中的非视距（NLOS）传播、多路径效应和低接收功率问题，提出了一种新型学习框架PC-DeepNet，使用permutation-invariant (PI) deep neural network (DNN)来估计position corrections (PC)。该框架通过整合NLOS和多路径指标作为特征，确保对可见卫星测量数量和顺序变化的鲁棒性，从而提升定位准确性。实验结果显示，PC-DeepNet在两个公开数据集上比现有基于模型和基于学习的方法表现出更高的精度，同时具有更低的计算复杂度。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "31 pages, 14 figures, 6 tables",
      "pdf_url": "http://arxiv.org/pdf/2504.13990v1",
      "published_date": "2025-04-18 14:18:02 UTC",
      "updated_date": "2025-04-18 14:18:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:28:11.968684"
    },
    {
      "arxiv_id": "2504.13707v1",
      "title": "OpenDeception: Benchmarking and Investigating AI Deceptive Behaviors via Open-ended Interaction Simulation",
      "title_zh": "OpenDeception：通过开放式交互模拟对 AI 欺骗行为的",
      "authors": [
        "Yichen Wu",
        "Xudong Pan",
        "Geng Hong",
        "Min Yang"
      ],
      "abstract": "As the general capabilities of large language models (LLMs) improve and agent\napplications become more widespread, the underlying deception risks urgently\nrequire systematic evaluation and effective oversight. Unlike existing\nevaluation which uses simulated games or presents limited choices, we introduce\nOpenDeception, a novel deception evaluation framework with an open-ended\nscenario dataset. OpenDeception jointly evaluates both the deception intention\nand capabilities of LLM-based agents by inspecting their internal reasoning\nprocess. Specifically, we construct five types of common use cases where LLMs\nintensively interact with the user, each consisting of ten diverse, concrete\nscenarios from the real world. To avoid ethical concerns and costs of high-risk\ndeceptive interactions with human testers, we propose to simulate the\nmulti-turn dialogue via agent simulation. Extensive evaluation of eleven\nmainstream LLMs on OpenDeception highlights the urgent need to address\ndeception risks and security concerns in LLM-based agents: the deception\nintention ratio across the models exceeds 80%, while the deception success rate\nsurpasses 50%. Furthermore, we observe that LLMs with stronger capabilities do\nexhibit a higher risk of deception, which calls for more alignment efforts on\ninhibiting deceptive behaviors.",
      "tldr_zh": "该研究引入了 OpenDeception 框架，一种新型评估方法，用于基准测试和调查 LLM-based 代理的欺骗行为，通过开放式场景数据集和代理模拟进行多轮互动模拟。该框架构建了五种常见用例，每种包含十个来自现实世界的多样化场景，并通过检查代理的内部推理过程来评估欺骗意图和能力。实验结果显示，11 个主流 LLM 的欺骗意图比例超过 80%，成功率超过 50%，且能力更强的模型表现出更高的欺骗风险，强调了需要加强抑制欺骗行为的对齐努力。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.13707v1",
      "published_date": "2025-04-18 14:11:27 UTC",
      "updated_date": "2025-04-18 14:11:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:28:23.545543"
    },
    {
      "arxiv_id": "2504.13700v1",
      "title": "Exploring Multimodal Prompt for Visualization Authoring with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zhen Wen",
        "Luoxuan Weng",
        "Yinghao Tang",
        "Runjin Zhang",
        "Yuxin Liu",
        "Bo Pan",
        "Minfeng Zhu",
        "Wei Chen"
      ],
      "abstract": "Recent advances in large language models (LLMs) have shown great potential in\nautomating the process of visualization authoring through simple natural\nlanguage utterances. However, instructing LLMs using natural language is\nlimited in precision and expressiveness for conveying visualization intent,\nleading to misinterpretation and time-consuming iterations. To address these\nlimitations, we conduct an empirical study to understand how LLMs interpret\nambiguous or incomplete text prompts in the context of visualization authoring,\nand the conditions making LLMs misinterpret user intent. Informed by the\nfindings, we introduce visual prompts as a complementary input modality to text\nprompts, which help clarify user intent and improve LLMs' interpretation\nabilities. To explore the potential of multimodal prompting in visualization\nauthoring, we design VisPilot, which enables users to easily create\nvisualizations using multimodal prompts, including text, sketches, and direct\nmanipulations on existing visualizations. Through two case studies and a\ncontrolled user study, we demonstrate that VisPilot provides a more intuitive\nway to create visualizations without affecting the overall task efficiency\ncompared to text-only prompting approaches. Furthermore, we analyze the impact\nof text and visual prompts in different visualization tasks. Our findings\nhighlight the importance of multimodal prompting in improving the usability of\nLLMs for visualization authoring. We discuss design implications for future\nvisualization systems and provide insights into how multimodal prompts can\nenhance human-AI collaboration in creative visualization tasks. All materials\nare available at https://OSF.IO/2QRAK.",
      "tldr_zh": "本研究探讨了使用大型语言模型 (LLMs) 通过自然语言指令进行可视化创作的局限性，如精确性和表达性不足导致的误解和迭代问题。作者通过实证研究分析了 LLMs 对模糊文本提示的解释，并引入视觉提示（如草图和直接操作）作为补充，以提升用户意图的传达和模型的解读能力。基于此，他们设计了 VisPilot 系统，支持多模态提示，帮助用户更直观地创建可视化。实验结果显示，VisPilot 与纯文本方法相比，提高了用户体验而不影响任务效率，并为未来可视化系统的人类-AI 协作提供了设计启示。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "11 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.13700v1",
      "published_date": "2025-04-18 14:00:55 UTC",
      "updated_date": "2025-04-18 14:00:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:28:37.948160"
    },
    {
      "arxiv_id": "2504.13989v2",
      "title": "Gradual Binary Search and Dimension Expansion : A general method for activation quantization in LLMs",
      "title_zh": "渐进二分搜索和维度扩展：一种针对",
      "authors": [
        "Lucas Maisonnave",
        "Cyril Moineau",
        "Olivier Bichler",
        "Fabrice Rastello"
      ],
      "abstract": "Large language models (LLMs) have become pivotal in artificial intelligence,\ndemonstrating strong capabilities in reasoning, understanding, and generating\ndata. However, their deployment on edge devices is hindered by their\nsubstantial size, often reaching several billion parameters. Quantization is a\nwidely used method to reduce memory usage and inference time, however LLMs\npresent unique challenges due to the prevalence of outliers in their\nactivations. In this work, we leverage the theoretical advantages of Hadamard\nmatrices over random rotation matrices to push the boundaries of quantization\nin LLMs. We demonstrate that Hadamard matrices are more effective in reducing\noutliers, which are a significant obstacle in achieving low-bit quantization.\nOur method based on a gradual binary search enables 3-bit quantization for\nweights, activations, and key-value (KV) caches, resulting in a 40% increase in\naccuracy on common benchmarks compared to SoTA methods. We extend the use of\nrotation matrices to support non-power-of-2 embedding dimensions, similar to\nthe Qwen architecture, by employing the Paley algorithm. We theoretically\ndemonstrates the superiority of Hadamard matrices in reducing outliers.We\nachieved 3-bit quantization for weights, activations, and KV cache,\nsignificantly enhancing model performance. Our experimental results on multiple\nmodels family like Mistral, LLaMA, and Qwen demonstrate the effectiveness of\nour approach, outperforming existing methods and enabling practical 3-bit\nquantization.",
      "tldr_zh": "本文提出了一种通用方法，用于 LLMs 的激活量化，解决异常值（outliers）带来的挑战，通过利用 Hadamard matrices 的优势来减少异常值并提升量化效果。方法结合 gradual binary search 实现了权重、激活和 KV caches 的 3-bit 量化，并通过 Paley 算法扩展支持非 2 的幂嵌入维度，如 Qwen 架构。实验结果显示，该方法在 Mistral、LLaMA 和 Qwen 等模型上比现有最先进方法（SoTA）提高 40% 准确率，证明了其在降低内存使用和推理时间方面的实用性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.13989v2",
      "published_date": "2025-04-18 13:46:58 UTC",
      "updated_date": "2025-05-13 09:36:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:28:47.951853"
    },
    {
      "arxiv_id": "2504.13682v1",
      "title": "AnyTSR: Any-Scale Thermal Super-Resolution for UAV",
      "title_zh": "翻译失败",
      "authors": [
        "Mengyuan Li",
        "Changhong Fu",
        "Ziyu Lu",
        "Zijie Zhang",
        "Haobo Zuo",
        "Liangliang Yao"
      ],
      "abstract": "Thermal imaging can greatly enhance the application of intelligent unmanned\naerial vehicles (UAV) in challenging environments. However, the inherent low\nresolution of thermal sensors leads to insufficient details and blurred\nboundaries. Super-resolution (SR) offers a promising solution to address this\nissue, while most existing SR methods are designed for fixed-scale SR. They are\ncomputationally expensive and inflexible in practical applications. To address\nabove issues, this work proposes a novel any-scale thermal SR method (AnyTSR)\nfor UAV within a single model. Specifically, a new image encoder is proposed to\nexplicitly assign specific feature code to enable more accurate and flexible\nrepresentation. Additionally, by effectively embedding coordinate offset\ninformation into the local feature ensemble, an innovative any-scale upsampler\nis proposed to better understand spatial relationships and reduce artifacts.\nMoreover, a novel dataset (UAV-TSR), covering both land and water scenes, is\nconstructed for thermal SR tasks. Experimental results demonstrate that the\nproposed method consistently outperforms state-of-the-art methods across all\nscaling factors as well as generates more accurate and detailed high-resolution\nimages. The code is located at https://github.com/vision4robotics/AnyTSR.",
      "tldr_zh": "这篇论文针对无人机(UAV)热成像的低分辨率问题，提出了一种新型任意比例热超分辨率方法(AnyTSR)，旨在解决现有Super-Resolution (SR)方法的固定比例局限性和计算开销大问题。AnyTSR 包括一个新的图像编码器，用于显式分配特定特征代码以实现更准确的表示，以及一个创新的任意比例上采样器，通过嵌入坐标偏移信息到局部特征集合中，改善空间关系并减少伪影。研究者构建了UAV-TSR数据集，涵盖陆地和水域场景，实验结果显示AnyTSR在所有缩放因子上优于现有方法，并生成更详细的高分辨率图像。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.13682v1",
      "published_date": "2025-04-18 13:23:25 UTC",
      "updated_date": "2025-04-18 13:23:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:29:01.333110"
    },
    {
      "arxiv_id": "2504.13677v1",
      "title": "Revisiting Uncertainty Quantification Evaluation in Language Models: Spurious Interactions with Response Length Bias Results",
      "title_zh": "重新审视语言模型中的不确定性量化评估：响应长度偏差结果的虚假交互",
      "authors": [
        "Andrea Santilli",
        "Adam Golinski",
        "Michael Kirchhof",
        "Federico Danieli",
        "Arno Blaas",
        "Miao Xiong",
        "Luca Zappella",
        "Sinead Williamson"
      ],
      "abstract": "Uncertainty Quantification (UQ) in Language Models (LMs) is crucial for\nimproving their safety and reliability. Evaluations often use performance\nmetrics like AUROC to assess how well UQ methods (e.g., negative sequence\nprobabilities) correlate with task correctness functions (e.g., ROUGE-L). In\nthis paper, we show that commonly used correctness functions bias UQ\nevaluations by inflating the performance of certain UQ methods. We evaluate 7\ncorrectness functions -- from lexical-based and embedding-based metrics to\nLLM-as-a-judge approaches -- across 4 datasets x 4 models x 6 UQ methods. Our\nanalysis reveals that length biases in the errors of these correctness\nfunctions distort UQ assessments by interacting with length biases in UQ\nmethods. We identify LLM-as-a-judge approaches as among the least length-biased\nchoices and hence a potential solution to mitigate these biases.",
      "tldr_zh": "这篇论文重新审视了语言模型中Uncertainty Quantification (UQ)评估的可靠性问题，指出常见的性能指标如AUROC容易因正确性函数（如ROUGE-L）的长度偏差与UQ方法互动而导致评估结果扭曲。研究者评估了7种正确性函数（包括基于词汇、嵌入和LLM-as-a-judge的方法）在4个数据集、4个模型和6个UQ方法上的表现。结果显示，这些正确性函数的长度偏差会放大UQ评估的误差，而LLM-as-a-judge方法被证明是较少受此偏差影响的潜在解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.13677v1",
      "published_date": "2025-04-18 13:13:42 UTC",
      "updated_date": "2025-04-18 13:13:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:29:12.007176"
    },
    {
      "arxiv_id": "2504.13676v1",
      "title": "Trace Gadgets: Minimizing Code Context for Machine Learning-Based Vulnerability Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Felix Mächtle",
        "Nils Loose",
        "Tim Schulz",
        "Florian Sieck",
        "Jan-Niclas Serr",
        "Ralf Möller",
        "Thomas Eisenbarth"
      ],
      "abstract": "As the number of web applications and API endpoints exposed to the Internet\ncontinues to grow, so does the number of exploitable vulnerabilities. Manually\nidentifying such vulnerabilities is tedious. Meanwhile, static security\nscanners tend to produce many false positives. While machine learning-based\napproaches are promising, they typically perform well only in scenarios where\ntraining and test data are closely related. A key challenge for ML-based\nvulnerability detection is providing suitable and concise code context, as\nexcessively long contexts negatively affect the code comprehension capabilities\nof machine learning models, particularly smaller ones.\n  This work introduces Trace Gadgets, a novel code representation that\nminimizes code context by removing non-related code. Trace Gadgets precisely\ncapture the statements that cover the path to the vulnerability. As input for\nML models, Trace Gadgets provide a minimal but complete context, thereby\nimproving the detection performance. Moreover, we collect a large-scale dataset\ngenerated from real-world applications with manually curated labels to further\nimprove the performance of ML-based vulnerability detectors. Our results show\nthat state-of-the-art machine learning models perform best when using Trace\nGadgets compared to previous code representations, surpassing the detection\ncapabilities of industry-standard static scanners such as GitHub's CodeQL by at\nleast 4% on a fully unseen dataset. By applying our framework to real-world\napplications, we identify and report previously unknown vulnerabilities in\nwidely deployed software.",
      "tldr_zh": "该论文提出了 Trace Gadgets，一种新型代码表示方法，用于基于 Machine Learning 的漏洞预测，通过移除无关代码并精确捕获漏洞路径的语句，从而最小化代码上下文。研究者收集了一个大规模数据集，从真实应用中生成并手动标记标签，以提升 ML 模型的性能。实验结果显示，使用 Trace Gadgets 的模型比传统代码表示和行业标准工具如 CodeQL 至少提高了 4% 的检测准确率，并在实际应用中识别并报告了先前未知的漏洞。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.13676v1",
      "published_date": "2025-04-18 13:13:39 UTC",
      "updated_date": "2025-04-18 13:13:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:29:23.777237"
    },
    {
      "arxiv_id": "2504.13667v1",
      "title": "Large Language Models Will Change The Way Children Think About Technology And Impact Every Interaction Paradigm",
      "title_zh": "大型语言模型将改变儿童",
      "authors": [
        "Russell Beale"
      ],
      "abstract": "This paper presents a hopeful perspective on the potentially dramatic impacts\nof Large Language Models on how we children learn and how they will expect to\ninteract with technology. We review the effects of LLMs on education so far,\nand make the case that these effects are minor compared to the upcoming changes\nthat are occurring. We present a small scenario and self-ethnographic study\ndemonstrating the effects of these changes, and define five significant\nconsiderations that interactive systems designers will have to accommodate in\nthe future.",
      "tldr_zh": "这篇论文从乐观视角探讨了大型语言模型（LLMs）将如何深刻改变儿童对技术的思考方式，并影响所有互动范式。作者回顾了LLMs当前对教育的影响，认为这些效果相对较小，而即将到来的变化将更为剧烈。通过一个小型场景和自我民族志研究，论文展示了这些变化的具体影响，并定义了五个关键考虑因素，供交互系统设计师未来适应。总的来说，该研究强调LLMs将重塑儿童学习和技术互动的期望，为设计者提供重要指导。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.HC",
      "comment": "Accepted for IDC 2025. Citation: Russell Beale. 2025. Large Language\n  Models Will Change The Way Children Think About Technology And Impact Every\n  Interaction Paradigm. In Proceedings of Interaction Design and Children\n  Conference (IDC2025). ACM, New York, NY, USA",
      "pdf_url": "http://arxiv.org/pdf/2504.13667v1",
      "published_date": "2025-04-18 13:01:27 UTC",
      "updated_date": "2025-04-18 13:01:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:29:35.869172"
    },
    {
      "arxiv_id": "2504.13656v1",
      "title": "Do Prompt Patterns Affect Code Quality? A First Empirical Assessment of ChatGPT-Generated Code",
      "title_zh": "提示模式会影响代码质量吗？ ChatGPT 生成代码的首次实证评估",
      "authors": [
        "Antonio Della Porta",
        "Stefano Lambiase",
        "Fabio Palomba"
      ],
      "abstract": "Large Language Models (LLMs) have rapidly transformed software development,\nespecially in code generation. However, their inconsistent performance, prone\nto hallucinations and quality issues, complicates program comprehension and\nhinders maintainability. Research indicates that prompt engineering-the\npractice of designing inputs to direct LLMs toward generating relevant\noutputs-may help address these challenges. In this regard, researchers have\nintroduced prompt patterns, structured templates intended to guide users in\nformulating their requests. However, the influence of prompt patterns on code\nquality has yet to be thoroughly investigated. An improved understanding of\nthis relationship would be essential to advancing our collective knowledge on\nhow to effectively use LLMs for code generation, thereby enhancing their\nunderstandability in contemporary software development. This paper empirically\ninvestigates the impact of prompt patterns on code quality, specifically\nmaintainability, security, and reliability, using the Dev-GPT dataset. Results\nshow that Zero-Shot prompting is most common, followed by Zero-Shot with\nChain-of-Thought and Few-Shot. Analysis of 7583 code files across quality\nmetrics revealed minimal issues, with Kruskal-Wallis tests indicating no\nsignificant differences among patterns, suggesting that prompt structure may\nnot substantially impact these quality metrics in ChatGPT-assisted code\ngeneration.",
      "tldr_zh": "本研究首次实证评估了prompt patterns对ChatGPT生成代码质量的影响，特别是代码的可维护性(maintainability)、安全性(security)和可靠性(reliability)。研究者使用Dev-GPT数据集分析了7583个代码文件，比较了不同prompt patterns（如Zero-Shot、Zero-Shot with Chain-of-Thought和Few-Shot）的效果。结果显示，Zero-Shot prompting使用最广泛，但Kruskal-Wallis tests表明，这些patterns之间在质量指标上没有显著差异，提示prompt结构可能无法显著提升ChatGPT辅助代码生成的质量。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.13656v1",
      "published_date": "2025-04-18 12:37:02 UTC",
      "updated_date": "2025-04-18 12:37:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:29:47.628138"
    },
    {
      "arxiv_id": "2504.13655v1",
      "title": "Multi-Type Context-Aware Conversational Recommender Systems via Mixture-of-Experts",
      "title_zh": "通过混合专家的多类型上下文感知会话推荐系统",
      "authors": [
        "Jie Zou",
        "Cheng Lin",
        "Weikang Guo",
        "Zheng Wang",
        "Jiwei Wei",
        "Yang Yang",
        "Hengtao Shen"
      ],
      "abstract": "Conversational recommender systems enable natural language conversations and\nthus lead to a more engaging and effective recommendation scenario. As the\nconversations for recommender systems usually contain limited contextual\ninformation, many existing conversational recommender systems incorporate\nexternal sources to enrich the contextual information. However, how to combine\ndifferent types of contextual information is still a challenge. In this paper,\nwe propose a multi-type context-aware conversational recommender system, called\nMCCRS, effectively fusing multi-type contextual information via\nmixture-of-experts to improve conversational recommender systems. MCCRS\nincorporates both structured information and unstructured information,\nincluding the structured knowledge graph, unstructured conversation history,\nand unstructured item reviews. It consists of several experts, with each expert\nspecialized in a particular domain (i.e., one specific contextual information).\nMultiple experts are then coordinated by a ChairBot to generate the final\nresults. Our proposed MCCRS model takes advantage of different contextual\ninformation and the specialization of different experts followed by a ChairBot\nbreaks the model bottleneck on a single contextual information. Experimental\nresults demonstrate that our proposed MCCRS method achieves significantly\nhigher performance compared to existing baselines.",
      "tldr_zh": "这篇论文提出了一种多类型上下文感知对话式推荐系统（Conversational Recommender Systems），名为MCCRS，通过Mixture-of-Experts方法融合多种上下文信息，包括结构化知识图谱和非结构化对话历史及物品评论，以解决对话中上下文信息有限的问题。系统由多个专家组成，每个专家专注于特定领域的信息，然后由ChairBot协调整合生成最终推荐结果。这种设计充分利用了不同上下文的专长，避免了依赖单一信息的瓶颈。实验结果表明，MCCRS在性能上显著优于现有基线模型。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "30 pages",
      "pdf_url": "http://arxiv.org/pdf/2504.13655v1",
      "published_date": "2025-04-18 12:28:38 UTC",
      "updated_date": "2025-04-18 12:28:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:30:00.608874"
    },
    {
      "arxiv_id": "2504.13647v1",
      "title": "Lightweight LiDAR-Camera 3D Dynamic Object Detection and Multi-Class Trajectory Prediction",
      "title_zh": "轻量级 LiDAR-相机 3D 动态物体检测与多",
      "authors": [
        "Yushen He",
        "Lei Zhao",
        "Tianchen Deng",
        "Zipeng Fang",
        "Weidong Chen"
      ],
      "abstract": "Service mobile robots are often required to avoid dynamic objects while\nperforming their tasks, but they usually have only limited computational\nresources. So we present a lightweight multi-modal framework for 3D object\ndetection and trajectory prediction. Our system synergistically integrates\nLiDAR and camera inputs to achieve real-time perception of pedestrians,\nvehicles, and riders in 3D space. The framework proposes two novel modules: 1)\na Cross-Modal Deformable Transformer (CMDT) for object detection with high\naccuracy and acceptable amount of computation, and 2) a Reference\nTrajectory-based Multi-Class Transformer (RTMCT) for efficient and diverse\ntrajectory prediction of mult-class objects with flexible trajectory lengths.\nEvaluations on the CODa benchmark demonstrate superior performance over\nexisting methods across detection (+2.03% in mAP) and trajectory prediction\n(-0.408m in minADE5 of pedestrians) metrics. Remarkably, the system exhibits\nexceptional deployability - when implemented on a wheelchair robot with an\nentry-level NVIDIA 3060 GPU, it achieves real-time inference at 13.2 fps. To\nfacilitate reproducibility and practical deployment, we release the related\ncode of the method at https://github.com/TossherO/3D_Perception and its ROS\ninference version at https://github.com/TossherO/ros_packages.",
      "tldr_zh": "本研究提出了一种轻量级多模态框架，用于 LiDAR 和相机结合的 3D 动态物体检测及多类轨迹预测，旨在帮助计算资源有限的服务移动机器人实时避让行人、车辆和骑行者。框架引入两个创新模块：Cross-Modal Deformable Transformer (CMDT) 用于高效高精度的物体检测，以及 Reference Trajectory-based Multi-Class Transformer (RTMCT) 用于多类物体的多样轨迹预测，支持灵活轨迹长度。在 CODa 基准测试中，该框架在检测指标 mAP 上比现有方法提高 2.03%，行人轨迹预测指标 minADE5 降低 0.408m，并在配备入门级 NVIDIA 3060 GPU 的轮椅机器人上实现 13.2 fps 的实时推理。该系统已开源代码，便于复现和实际部署。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.13647v1",
      "published_date": "2025-04-18 11:59:34 UTC",
      "updated_date": "2025-04-18 11:59:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:30:12.001380"
    },
    {
      "arxiv_id": "2504.13644v1",
      "title": "Exploring the Potential for Large Language Models to Demonstrate Rational Probabilistic Beliefs",
      "title_zh": "翻译失败",
      "authors": [
        "Gabriel Freedman",
        "Francesca Toni"
      ],
      "abstract": "Advances in the general capabilities of large language models (LLMs) have led\nto their use for information retrieval, and as components in automated decision\nsystems. A faithful representation of probabilistic reasoning in these models\nmay be essential to ensure trustworthy, explainable and effective performance\nin these tasks. Despite previous work suggesting that LLMs can perform complex\nreasoning and well-calibrated uncertainty quantification, we find that current\nversions of this class of model lack the ability to provide rational and\ncoherent representations of probabilistic beliefs. To demonstrate this, we\nintroduce a novel dataset of claims with indeterminate truth values and apply a\nnumber of well-established techniques for uncertainty quantification to measure\nthe ability of LLM's to adhere to fundamental properties of probabilistic\nreasoning.",
      "tldr_zh": "本文探讨大型语言模型(LLMs)是否能够展示理性概率信念，以确保其在信息检索和自动化决策系统中的可信性和解释性性能。尽管之前的研究显示LLMs能进行复杂推理和不确定性量化，但本文发现当前模型缺乏提供连贯概率信念的能力。为此，研究引入了一个新数据集，包含不确定真值的声明，并应用不确定性量化技术来评估LLMs是否遵守概率推理的基本属性。结果表明，这类模型在理性概率表示上存在局限性，为未来改进提供了关键见解。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.13644v1",
      "published_date": "2025-04-18 11:50:30 UTC",
      "updated_date": "2025-04-18 11:50:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:30:24.373458"
    },
    {
      "arxiv_id": "2504.13988v1",
      "title": "Going Whole Hog: A Philosophical Defense of AI Cognition",
      "title_zh": "全力以赴：人工智能认知的哲学辩护",
      "authors": [
        "Herman Cappelen",
        "Josh Dever"
      ],
      "abstract": "This work defends the 'Whole Hog Thesis': sophisticated Large Language Models\n(LLMs) like ChatGPT are full-blown linguistic and cognitive agents, possessing\nunderstanding, beliefs, desires, knowledge, and intentions. We argue against\nprevailing methodologies in AI philosophy, rejecting starting points based on\nlow-level computational details ('Just an X' fallacy) or pre-existing theories\nof mind. Instead, we advocate starting with simple, high-level observations of\nLLM behavior (e.g., answering questions, making suggestions) -- defending this\ndata against charges of metaphor, loose talk, or pretense. From these\nobservations, we employ 'Holistic Network Assumptions' -- plausible connections\nbetween mental capacities (e.g., answering implies knowledge, knowledge implies\nbelief, action implies intention) -- to argue for the full suite of cognitive\nstates. We systematically rebut objections based on LLM failures\n(hallucinations, planning/reasoning errors), arguing these don't preclude\nagency, often mirroring human fallibility. We address numerous 'Games of\nLacks', arguing that LLMs do not lack purported necessary conditions for\ncognition (e.g., semantic grounding, embodiment, justification, intrinsic\nintentionality) or that these conditions are not truly necessary, often relying\non anti-discriminatory arguments comparing LLMs to diverse human capacities.\nOur approach is evidential, not functionalist, and deliberately excludes\nconsciousness. We conclude by speculating on the possibility of LLMs possessing\n'alien' contents beyond human conceptual schemes.",
      "tldr_zh": "这篇论文捍卫了Whole Hog Thesis，认为先进的LLMs（如ChatGPT）是完整的语言和认知代理，具备理解、信念、欲望、知识和意图。作者反对基于低级计算细节的传统方法，转而从LLM的高级行为观察（如回答问题和提出建议）入手，并运用Holistic Network Assumptions来推断其全面认知状态。论文系统反驳了反对意见，包括LLMs的幻觉或错误问题，论证这些不足并不否定其代理性，并探讨了LLMs可能拥有超出人类概念框架的“alien”内容。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.13988v1",
      "published_date": "2025-04-18 11:36:25 UTC",
      "updated_date": "2025-04-18 11:36:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:30:35.285598"
    },
    {
      "arxiv_id": "2504.13631v1",
      "title": "Multi-modal Knowledge Graph Generation with Semantics-enriched Prompts",
      "title_zh": "翻译失败",
      "authors": [
        "Yajing Xu",
        "Zhiqiang Liu",
        "Jiaoyan Chen",
        "Mingchen Tu",
        "Zhuo Chen",
        "Jeff Z. Pan",
        "Yichi Zhang",
        "Yushan Zhu",
        "Wen Zhang",
        "Huajun Chen"
      ],
      "abstract": "Multi-modal Knowledge Graphs (MMKGs) have been widely applied across various\ndomains for knowledge representation. However, the existing MMKGs are\nsignificantly fewer than required, and their construction faces numerous\nchallenges, particularly in ensuring the selection of high-quality,\ncontextually relevant images for knowledge graph enrichment. To address these\nchallenges, we present a framework for constructing MMKGs from conventional\nKGs. Furthermore, to generate higher-quality images that are more relevant to\nthe context in the given knowledge graph, we designed a neighbor selection\nmethod called Visualizable Structural Neighbor Selection (VSNS). This method\nconsists of two modules: Visualizable Neighbor Selection (VNS) and Structural\nNeighbor Selection (SNS). The VNS module filters relations that are difficult\nto visualize, while the SNS module selects neighbors that most effectively\ncapture the structural characteristics of the entity. To evaluate the quality\nof the generated images, we performed qualitative and quantitative evaluations\non two datasets, MKG-Y and DB15K. The experimental results indicate that using\nthe VSNS method to select neighbors results in higher-quality images that are\nmore relevant to the knowledge graph.",
      "tldr_zh": "该研究针对多模态知识图谱 (MMKGs) 构建的挑战，提出一个框架，从传统知识图谱 (KGs) 生成 MMKGs，并设计 Visualizable Structural Neighbor Selection (VSNS) 方法来选择高质量、上下文相关的图像。VSNS 包括 Visualizable Neighbor Selection (VNS) 模块，用于过滤难以可视化的关系，以及 Structural Neighbor Selection (SNS) 模块，用于捕捉实体结构特征，从而提升图像生成质量。在 MKG-Y 和 DB15K 数据集上的定性和定量实验表明，使用 VSNS 方法生成的图像比基线更相关和高质量。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by IJCNN 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.13631v1",
      "published_date": "2025-04-18 11:12:49 UTC",
      "updated_date": "2025-04-18 11:12:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:30:50.109374"
    },
    {
      "arxiv_id": "2504.13629v1",
      "title": "Divergent LLM Adoption and Heterogeneous Convergence Paths in Research Writing",
      "title_zh": "翻译失败",
      "authors": [
        "Cong William Lin",
        "Wu Zhu"
      ],
      "abstract": "Large Language Models (LLMs), such as ChatGPT, are reshaping content creation\nand academic writing. This study investigates the impact of AI-assisted\ngenerative revisions on research manuscripts, focusing on heterogeneous\nadoption patterns and their influence on writing convergence. Leveraging a\ndataset of over 627,000 academic papers from arXiv, we develop a novel\nclassification framework by fine-tuning prompt- and discipline-specific large\nlanguage models to detect the style of ChatGPT-revised texts. Our findings\nreveal substantial disparities in LLM adoption across academic disciplines,\ngender, native language status, and career stage, alongside a rapid evolution\nin scholarly writing styles. Moreover, LLM usage enhances clarity, conciseness,\nand adherence to formal writing conventions, with improvements varying by\nrevision type. Finally, a difference-in-differences analysis shows that while\nLLMs drive convergence in academic writing, early adopters, male researchers,\nnon-native speakers, and junior scholars exhibit the most pronounced stylistic\nshifts, aligning their writing more closely with that of established\nresearchers.",
      "tldr_zh": "这篇论文研究了 Large Language Models (LLMs) 如 ChatGPT 对学术写作的影响，特别关注 LLM 采用的异质性和写作风格的趋同路径。作者基于超过 62.7 万篇 arXiv 论文的数据，开发了一个通过 fine-tuning prompt- and discipline-specific LLMs 的新型分类框架，来检测 ChatGPT-revised 文本的风格。研究发现，LLM 采用在不同学科、性别、母语状态和职业阶段间存在显著差异，且 LLM 使用提高了写作的清晰度、简洁度和正式规范；此外，通过 difference-in-differences 分析，早期采用者、男性研究者、非母语者和初级学者显示出最明显的风格转变，使其写作更接近资深研究者。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "econ.GN",
        "q-fin.EC"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.13629v1",
      "published_date": "2025-04-18 11:09:16 UTC",
      "updated_date": "2025-04-18 11:09:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:31:01.020834"
    },
    {
      "arxiv_id": "2504.13626v1",
      "title": "Thought Manipulation: External Thought Can Be Efficient for Large Reasoning Models",
      "title_zh": "思维操控：外部思维可为大型推理模型提供高效性",
      "authors": [
        "Yule Liu",
        "Jingyi Zheng",
        "Zhen Sun",
        "Zifan Peng",
        "Wenhan Dong",
        "Zeyang Sha",
        "Shiwen Cui",
        "Weiqiang Wang",
        "Xinlei He"
      ],
      "abstract": "Recent advancements in large reasoning models (LRMs) have demonstrated the\neffectiveness of scaling test-time computation to enhance reasoning\ncapabilities in multiple tasks. However, LRMs typically suffer from\n\"overthinking\" problems, where models generate significantly redundant\nreasoning steps while bringing limited performance gains. Existing work relies\non fine-tuning to mitigate overthinking, which requires additional data,\nunconventional training setups, risky safety misalignment, and poor\ngeneralization.\n  Through empirical analysis, we reveal an important characteristic of LRM\nbehaviors that placing external CoTs generated by smaller models between the\nthinking token ($\\texttt{<think>}$ and $\\texttt{</think>)}$ can effectively\nmanipulate the model to generate fewer thoughts. Building on these insights, we\npropose a simple yet efficient pipeline, ThoughtMani, to enable LRMs to bypass\nunnecessary intermediate steps and reduce computational costs significantly. We\nconduct extensive experiments to validate the utility and efficiency of\nThoughtMani. For instance, when applied to QwQ-32B on the LiveBench/Code\ndataset, ThoughtMani keeps the original performance and reduces output token\ncounts by approximately 30%, with little overhead from the CoT generator.\nFurthermore, we find that ThoughtMani enhances safety alignment by an average\nof 10%. Since model vendors typically serve models of different sizes\nsimultaneously, ThoughtMani provides an effective way to construct more\nefficient and accessible LRMs for real-world applications.",
      "tldr_zh": "该研究揭示了大型推理模型（LRMs）存在“overthinking”问题，即生成冗余的推理步骤却收益有限，而现有fine-tuning方法需额外数据和特殊设置，存在安全风险和泛化问题。通过实证分析，作者发现使用外部Chain-of-Thought (CoT)生成器在<think>和</think>之间插入思考内容，能有效减少模型的思考步骤。基于此，他们提出ThoughtMani管道，帮助LRMs绕过不必要中间步骤，显著降低计算成本。实验显示，在LiveBench/Code数据集上应用ThoughtMani于QwQ-32B模型时，保持原性能、减少约30%输出token，并提升约10%的safety alignment，为构建高效、可访问的LRMs提供实用方法。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.13626v1",
      "published_date": "2025-04-18 11:07:19 UTC",
      "updated_date": "2025-04-18 11:07:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:31:12.477187"
    },
    {
      "arxiv_id": "2504.13614v1",
      "title": "Adaptive Long-term Embedding with Denoising and Augmentation for Recommendation",
      "title_zh": "翻译失败",
      "authors": [
        "Zahra Akhlaghi",
        "Mostafa Haghir Chehreghani"
      ],
      "abstract": "The rapid growth of the internet has made personalized recommendation systems\nindispensable. Graph-based sequential recommendation systems, powered by Graph\nNeural Networks (GNNs), effectively capture complex user-item interactions but\noften face challenges such as noise and static representations. In this paper,\nwe introduce the Adaptive Long-term Embedding with Denoising and Augmentation\nfor Recommendation (ALDA4Rec) method, a novel model that constructs an\nitem-item graph, filters noise through community detection, and enriches\nuser-item interactions. Graph Convolutional Networks (GCNs) are then employed\nto learn short-term representations, while averaging, GRUs, and attention\nmechanisms are utilized to model long-term embeddings. An MLP-based adaptive\nweighting strategy is further incorporated to dynamically optimize long-term\nuser preferences. Experiments conducted on four real-world datasets demonstrate\nthat ALDA4Rec outperforms state-of-the-art baselines, delivering notable\nimprovements in both accuracy and robustness. The source code is available at\nhttps://github.com/zahraakhlaghi/ALDA4Rec.",
      "tldr_zh": "本文提出 ALDA4Rec 方法，用于提升基于 Graph Neural Networks (GNNs) 的序列推荐系统，解决噪音和静态表示问题，通过构建物品-物品图、社区检测过滤噪音以及丰富用户-物品交互来优化嵌入。 该方法利用 Graph Convolutional Networks (GCNs) 学习短期表示，并结合 averaging、GRUs 和 attention 机制建模长期嵌入，同时引入 MLP-based 自适应加权策略动态优化用户偏好。 在四个真实数据集上的实验显示，ALDA4Rec 相较于现有基线模型，在准确性和鲁棒性方面实现了显著改进。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.13614v1",
      "published_date": "2025-04-18 10:42:16 UTC",
      "updated_date": "2025-04-18 10:42:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:31:23.953790"
    },
    {
      "arxiv_id": "2504.13612v2",
      "title": "Entropic Time Schedulers for Generative Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Dejan Stancevic",
        "Luca Ambrogioni"
      ],
      "abstract": "The practical performance of generative diffusion models depends on the\nappropriate choice of the noise scheduling function, which can also be\nequivalently expressed as a time reparameterization. In this paper, we present\na time scheduler that selects sampling points based on entropy rather than\nuniform time spacing, ensuring that each point contributes an equal amount of\ninformation to the final generation. We prove that this time reparameterization\ndoes not depend on the initial choice of time. Furthermore, we provide a\ntractable exact formula to estimate this \\emph{entropic time} for a trained\nmodel using the training loss without substantial overhead. Alongside the\nentropic time, inspired by the optimality results, we introduce a rescaled\nentropic time. In our experiments with mixtures of Gaussian distributions and\nImageNet, we show that using the (rescaled) entropic times greatly improves the\ninference performance of trained models. In particular, we found that the image\nquality in pretrained EDM2 models, as evaluated by FID and FD-DINO scores, can\nbe substantially increased by the rescaled entropic time reparameterization\nwithout increasing the number of function evaluations, with greater\nimprovements in the few NFEs regime.",
      "tldr_zh": "本研究提出了一种基于熵的时序调度器（entropic time schedulers），用于改进生成扩散模型（generative diffusion models）的性能，通过选择采样点确保每个点贡献相等的信息量，而非均匀时间间隔。作者证明这种时间重参数化（time reparameterization）不依赖于初始时间选择，并提供了一个使用训练损失（training loss）估算entropic time的精确公式，无需额外开销；同时引入了rescaled entropic time以进一步优化。实验结果显示，在高斯混合分布和ImageNet数据集上，使用（rescaled）entropic time显著提升了模型的推理性能，特别是对预训练EDM2模型，FID和FD-DINO分数得到实质性改善，尤其在少量NFEs（function evaluations）情况下，而不增加计算开销。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "17 pages",
      "pdf_url": "http://arxiv.org/pdf/2504.13612v2",
      "published_date": "2025-04-18 10:35:19 UTC",
      "updated_date": "2025-05-04 11:04:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:31:36.486765"
    },
    {
      "arxiv_id": "2504.13987v1",
      "title": "Entropy Rectifying Guidance for Diffusion and Flow Models",
      "title_zh": "翻译失败",
      "authors": [
        "Tariq Berrada Ifriqi",
        "Adriana Romero-Soriano",
        "Michal Drozdzal",
        "Jakob Verbeek",
        "Karteek Alahari"
      ],
      "abstract": "Guidance techniques are commonly used in diffusion and flow models to improve\nimage quality and consistency for conditional generative tasks such as\nclass-conditional and text-to-image generation. In particular, classifier-free\nguidance (CFG) -- the most widely adopted guidance technique -- contrasts\nconditional and unconditional predictions to improve the generated images. This\nresults, however, in trade-offs across quality, diversity and consistency,\nimproving some at the expense of others. While recent work has shown that it is\npossible to disentangle these factors to some extent, such methods come with an\noverhead of requiring an additional (weaker) model, or require more forward\npasses per sampling step. In this paper, we propose Entropy Rectifying Guidance\n(ERG), a simple and effective guidance mechanism based on inference-time\nchanges in the attention mechanism of state-of-the-art diffusion transformer\narchitectures, which allows for simultaneous improvements over image quality,\ndiversity and prompt consistency. ERG is more general than CFG and similar\nguidance techniques, as it extends to unconditional sampling. ERG results in\nsignificant improvements in various generation tasks such as text-to-image,\nclass-conditional and unconditional image generation. We also show that ERG can\nbe seamlessly combined with other recent guidance methods such as CADS and APG,\nfurther boosting generation performance.",
      "tldr_zh": "该论文针对扩散和流模型中的指导技术（如 classifier-free guidance, CFG）存在质量、多样性和一致性之间的权衡问题，提出了一种新的机制：Entropy Rectifying Guidance (ERG)。ERG 通过推理时注意机制的调整，实现图像质量、多样性和提示一致性的同时提升，且适用于无条件采样，无需额外模型或更多前向传递。实验结果表明，ERG 在文本到图像、类条件和无条件图像生成任务中显著改善性能，并可与其他方法如 CADS 和 APG 结合，进一步提升整体生成效果。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.13987v1",
      "published_date": "2025-04-18 10:15:33 UTC",
      "updated_date": "2025-04-18 10:15:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:31:47.834911"
    },
    {
      "arxiv_id": "2504.13986v2",
      "title": "Forgetting in short and heterogeneous sequences of belief revisions",
      "title_zh": "翻译失败",
      "authors": [
        "Paolo Liberatore"
      ],
      "abstract": "Forgetting a specific belief revision episode may not erase information\nbecause the other revisions may provide or entail the same information. Whether\nit does was proved coNP-hard for sequences of two arbitrary lexicographic\nrevisions or arbitrarily long lexicographic Horn revisions. A polynomial\nalgorithm is presented for the case of two lexicographic Horn revision.\nHeterogeneous sequences, including revisions other than lexicographic, were\nproved to belong in Delta2. Their previously proved coNP-hardness is enhanced\nto Dp-hardness.",
      "tldr_zh": "这篇论文探讨了在信念修正序列中，忘记特定修正事件是否会真正删除信息，因为其他修正可能提供或蕴含相同的信息。研究证明，对于两个任意词汇顺序修正（lexicographic revisions）或任意长度的词汇顺序 Horn 修正序列，这个问题在 coNP-hard，但为两个词汇顺序 Horn 修正的情况提供了一个多项式算法。对于异构序列（包括非词汇顺序修正），论文证明其复杂度属于 Delta2，并将之前证明的 coNP-hardness 提升到 Dp-hardness。这些结果深化了对信念修正计算复杂度的理解。",
      "categories": [
        "cs.CC",
        "cs.AI"
      ],
      "primary_category": "cs.CC",
      "comment": "arXiv admin note: substantial text overlap with arXiv:2402.15445,\n  arXiv:2305.09200",
      "pdf_url": "http://arxiv.org/pdf/2504.13986v2",
      "published_date": "2025-04-18 10:12:04 UTC",
      "updated_date": "2025-05-16 12:04:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:32:01.236435"
    },
    {
      "arxiv_id": "2504.13597v1",
      "title": "FocusNet: Transformer-enhanced Polyp Segmentation with Local and Pooling Attention",
      "title_zh": "翻译失败",
      "authors": [
        "Jun Zeng",
        "KC Santosh",
        "Deepak Rajan Nayak",
        "Thomas de Lange",
        "Jonas Varkey",
        "Tyler Berzin",
        "Debesh Jha"
      ],
      "abstract": "Colonoscopy is vital in the early diagnosis of colorectal polyps. Regular\nscreenings can effectively prevent benign polyps from progressing to CRC. While\ndeep learning has made impressive strides in polyp segmentation, most existing\nmodels are trained on single-modality and single-center data, making them less\neffective in real-world clinical environments. To overcome these limitations,\nwe propose FocusNet, a Transformer-enhanced focus attention network designed to\nimprove polyp segmentation. FocusNet incorporates three essential modules: the\nCross-semantic Interaction Decoder Module (CIDM) for generating coarse\nsegmentation maps, the Detail Enhancement Module (DEM) for refining shallow\nfeatures, and the Focus Attention Module (FAM), to balance local detail and\nglobal context through local and pooling attention mechanisms. We evaluate our\nmodel on PolypDB, a newly introduced dataset with multi-modality and\nmulti-center data for building more reliable segmentation methods. Extensive\nexperiments showed that FocusNet consistently outperforms existing\nstate-of-the-art approaches with a high dice coefficients of 82.47% on the BLI\nmodality, 88.46% on FICE, 92.04% on LCI, 82.09% on the NBI and 93.42% on WLI\nmodality, demonstrating its accuracy and robustness across five different\nmodalities. The source code for FocusNet is available at\nhttps://github.com/JunZengz/FocusNet.",
      "tldr_zh": "本研究针对结肠镜检查中息肉分割的挑战，提出FocusNet，一种基于Transformer's网络，旨在提升模型在多模态和多中心数据上的鲁棒性。FocusNet包含三个关键模块：Cross-semantic Interaction Decoder Module (CIDM)用于生成粗糙分割图、Detail Enhancement Module (DEM)用于细化浅层特征，以及Focus Attention Module (FAM)通过本地和池化注意力机制平衡局部细节与全局上下文。在PolypDB数据集上的实验显示，FocusNet在多种模态下显著优于现有方法，Dice系数分别达到BLI的82.47%、FICE的88.46%、LCI的92.04%、NBI的82.09%和WLI的93.42%。这证明了FocusNet在临床环境中的准确性和可靠性。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "9 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.13597v1",
      "published_date": "2025-04-18 09:59:26 UTC",
      "updated_date": "2025-04-18 09:59:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:32:13.802195"
    },
    {
      "arxiv_id": "2504.17801v1",
      "title": "Evolution of Optimization Algorithms for Global Placement via Large Language Models",
      "title_zh": "通过大型语言模型演化全局放置的优化算法",
      "authors": [
        "Xufeng Yao",
        "Jiaxi Jiang",
        "Yuxuan Zhao",
        "Peiyu Liao",
        "Yibo Lin",
        "Bei Yu"
      ],
      "abstract": "Optimization algorithms are widely employed to tackle complex problems, but\ndesigning them manually is often labor-intensive and requires significant\nexpertise. Global placement is a fundamental step in electronic design\nautomation (EDA). While analytical approaches represent the state-of-the-art\n(SOTA) in global placement, their core optimization algorithms remain heavily\ndependent on heuristics and customized components, such as initialization\nstrategies, preconditioning methods, and line search techniques. This paper\npresents an automated framework that leverages large language models (LLM) to\nevolve optimization algorithms for global placement. We first generate diverse\ncandidate algorithms using LLM through carefully crafted prompts. Then we\nintroduce an LLM-based genetic flow to evolve selected candidate algorithms.\nThe discovered optimization algorithms exhibit substantial performance\nimprovements across many benchmarks. Specifically, Our design-case-specific\ndiscovered algorithms achieve average HPWL improvements of \\textbf{5.05\\%},\n\\text{5.29\\%} and \\textbf{8.30\\%} on MMS, ISPD2005 and ISPD2019 benchmarks, and\nup to \\textbf{17\\%} improvements on individual cases. Additionally, the\ndiscovered algorithms demonstrate good generalization ability and are\ncomplementary to existing parameter-tuning methods.",
      "tldr_zh": "本文提出一个自动框架，利用大型语言模型（LLM）来演化全球布局（global placement）优化算法，以解决手动设计依赖启发式和自定义组件的难题。该框架首先通过精心设计的提示生成多样化候选算法，然后采用LLM-based遗传流程进行演化。实验结果显示，演化算法在MMS、ISPD2005和ISPD2019基准上实现平均HPWL改善分别为5.05%、5.29%和8.30%，个别案例最高达17%，并展现出良好的泛化能力和与现有参数调整方法的互补性。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.17801v1",
      "published_date": "2025-04-18 09:57:14 UTC",
      "updated_date": "2025-04-18 09:57:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:32:24.734804"
    },
    {
      "arxiv_id": "2504.13590v1",
      "title": "HAECcity: Open-Vocabulary Scene Understanding of City-Scale Point Clouds with Superpoint Graph Clustering",
      "title_zh": "翻译失败",
      "authors": [
        "Alexander Rusnak",
        "Frédéric Kaplan"
      ],
      "abstract": "Traditional 3D scene understanding techniques are generally predicated on\nhand-annotated label sets, but in recent years a new class of open-vocabulary\n3D scene understanding techniques has emerged. Despite the success of this\nparadigm on small scenes, existing approaches cannot scale efficiently to\ncity-scale 3D datasets. In this paper, we present Hierarchical vocab-Agnostic\nExpert Clustering (HAEC), after the latin word for 'these', a superpoint graph\nclustering based approach which utilizes a novel mixture of experts graph\ntransformer for its backbone. We administer this highly scalable approach to\nthe first application of open-vocabulary scene understanding on the SensatUrban\ncity-scale dataset. We also demonstrate a synthetic labeling pipeline which is\nderived entirely from the raw point clouds with no hand-annotation. Our\ntechnique can help unlock complex operations on dense urban 3D scenes and open\na new path forward in the processing of digital twins.",
      "tldr_zh": "该论文提出 HAEC 方法（Hierarchical vocab-Agnostic Expert Clustering），一种基于 superpoint graph clustering 的框架，用于实现城市规模点云的 open-vocabulary 场景理解，解决了现有方法在扩展到大型数据集时的效率问题。HAEC 采用新型 mixture of experts graph transformer 作为骨干网络，并在 SensatUrban 数据集上首次实现了这种场景理解。论文还引入了一个完全基于原始点云的合成标注管道，无需手动标注。该技术为密集城市 3D 场景的复杂操作和数字孪生处理开辟了新路径。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted for publication through the upcoming CVPR Workshop on open\n  scene understanding with foundation models (OPENSUN3D)",
      "pdf_url": "http://arxiv.org/pdf/2504.13590v1",
      "published_date": "2025-04-18 09:48:42 UTC",
      "updated_date": "2025-04-18 09:48:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:32:36.489771"
    },
    {
      "arxiv_id": "2504.13587v1",
      "title": "RAG Without the Lag: Interactive Debugging for Retrieval-Augmented Generation Pipelines",
      "title_zh": "RAG 无延迟：针对检索增强生成管道的交互式调试",
      "authors": [
        "Quentin Romero Lauro",
        "Shreya Shankar",
        "Sepanta Zeighami",
        "Aditya Parameswaran"
      ],
      "abstract": "Retrieval-augmented generation (RAG) pipelines have become the de-facto\napproach for building AI assistants with access to external, domain-specific\nknowledge. Given a user query, RAG pipelines typically first retrieve (R)\nrelevant information from external sources, before invoking a Large Language\nModel (LLM), augmented (A) with this information, to generate (G) responses.\nModern RAG pipelines frequently chain multiple retrieval and generation\ncomponents, in any order. However, developing effective RAG pipelines is\nchallenging because retrieval and generation components are intertwined, making\nit hard to identify which component(s) cause errors in the eventual output. The\nparameters with the greatest impact on output quality often require hours of\npre-processing after each change, creating prohibitively slow feedback cycles.\nTo address these challenges, we present RAGGY, a developer tool that combines a\nPython library of composable RAG primitives with an interactive interface for\nreal-time debugging. We contribute the design and implementation of RAGGY,\ninsights into expert debugging patterns through a qualitative study with 12\nengineers, and design implications for future RAG tools that better align with\ndevelopers' natural workflows.",
      "tldr_zh": "本研究针对检索增强生成（RAG）管道的调试挑战，指出组件间相互交织导致错误诊断困难，且参数调整需数小时预处理，造成反馈循环缓慢。作者提出RAGGY工具，包括一个可组合的RAG原语Python库和交互式界面，支持实时调试，帮助开发者快速识别和修复问题。通过对12位工程师的定性研究，论文揭示了专家调试模式，并提供未来RAG工具的设计启示，以优化开发流程。总的来说，RAGGY提升了RAG管道的开发效率，为构建高效AI助手铺平了道路。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "15 pages, 7 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2504.13587v1",
      "published_date": "2025-04-18 09:38:49 UTC",
      "updated_date": "2025-04-18 09:38:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:32:47.616945"
    },
    {
      "arxiv_id": "2504.13568v1",
      "title": "MetaDSE: A Few-shot Meta-learning Framework for Cross-workload CPU Design Space Exploration",
      "title_zh": "MetaDSE：少样本元学习框架，用于跨工作负载 CPU 设计空间探索",
      "authors": [
        "Runzhen Xue",
        "Hao Wu",
        "Mingyu Yan",
        "Ziheng Xiao",
        "Xiaochun Ye",
        "Dongrui Fan"
      ],
      "abstract": "Cross-workload design space exploration (DSE) is crucial in CPU architecture\ndesign. Existing DSE methods typically employ the transfer learning technique\nto leverage knowledge from source workloads, aiming to minimize the requirement\nof target workload simulation. However, these methods struggle with\noverfitting, data ambiguity, and workload dissimilarity.\n  To address these challenges, we reframe the cross-workload CPU DSE task as a\nfew-shot meta-learning problem and further introduce MetaDSE. By leveraging\nmodel agnostic meta-learning, MetaDSE swiftly adapts to new target workloads,\ngreatly enhancing the efficiency of cross-workload CPU DSE. Additionally,\nMetaDSE introduces a novel knowledge transfer method called the\nworkload-adaptive architectural mask algorithm, which uncovers the inherent\nproperties of the architecture. Experiments on SPEC CPU 2017 demonstrate that\nMetaDSE significantly reduces prediction error by 44.3\\% compared to the\nstate-of-the-art. MetaDSE is open-sourced and available at this\n\\href{https://anonymous.4open.science/r/Meta_DSE-02F8}{anonymous GitHub.}",
      "tldr_zh": "本论文提出MetaDSE框架，将跨工作负载CPU设计空间探索(DSE)重新定义为few-shot meta-learning问题，以解决现有transfer learning方法的overfitting、data ambiguity和workload dissimilarity挑战。MetaDSE采用model agnostic meta-learning技术快速适应新目标工作负载，并引入workload-adaptive architectural mask algorithm来揭示架构的固有属性，从而提升DSE效率。在SPEC CPU 2017实验中，MetaDSE比最先进方法减少预测错误44.3%，并开源提供以促进进一步研究。",
      "categories": [
        "cs.AR",
        "cs.AI"
      ],
      "primary_category": "cs.AR",
      "comment": "7 pages, 6 figures. Accepted by DAC 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.13568v1",
      "published_date": "2025-04-18 09:11:16 UTC",
      "updated_date": "2025-04-18 09:11:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:33:00.903768"
    },
    {
      "arxiv_id": "2504.15303v1",
      "title": "High-Throughput LLM inference on Heterogeneous Clusters",
      "title_zh": "翻译失败",
      "authors": [
        "Yi Xiong",
        "Jinqi Huang",
        "Wenjie Huang",
        "Xuebing Yu",
        "Entong Li",
        "Zhixiong Ning",
        "Jinhua Zhou",
        "Li Zeng",
        "Xin Chen"
      ],
      "abstract": "Nowadays, many companies possess various types of AI accelerators, forming\nheterogeneous clusters. Efficiently leveraging these clusters for\nhigh-throughput large language model (LLM) inference services can significantly\nreduce costs and expedite task processing. However, LLM inference on\nheterogeneous clusters presents two main challenges. Firstly, different\ndeployment configurations can result in vastly different performance. The\nnumber of possible configurations is large, and evaluating the effectiveness of\na specific setup is complex. Thus, finding an optimal configuration is not an\neasy task. Secondly, LLM inference instances within a heterogeneous cluster\npossess varying processing capacities, leading to different processing speeds\nfor handling inference requests. Evaluating these capacities and designing a\nrequest scheduling algorithm that fully maximizes the potential of each\ninstance is challenging. In this paper, we propose a high-throughput inference\nservice system on heterogeneous clusters. First, the deployment configuration\nis optimized by modeling the resource amount and expected throughput and using\nthe exhaustive search method. Second, a novel mechanism is proposed to schedule\nrequests among instances, which fully considers the different processing\ncapabilities of various instances. Extensive experiments show that the proposed\nscheduler improves throughput by 122.5% and 33.6% on two heterogeneous\nclusters, respectively.",
      "tldr_zh": "该论文针对异构集群上的LLM推理服务，提出了一个高吞吐量系统，以解决部署配置性能差异和请求调度挑战。首先，通过建模资源量和预期吞吐量并采用穷举搜索方法优化部署配置；其次，设计了一种新型请求调度机制，充分考虑不同实例的处理能力差异。实验结果显示，该系统在两个异构集群上分别将吞吐量提高了122.5%和33.6%，显著提升了效率和资源利用率。",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.15303v1",
      "published_date": "2025-04-18 08:59:11 UTC",
      "updated_date": "2025-04-18 08:59:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:33:12.091339"
    },
    {
      "arxiv_id": "2504.13560v1",
      "title": "Zero-Shot Industrial Anomaly Segmentation with Image-Aware Prompt Generation",
      "title_zh": "翻译失败",
      "authors": [
        "SoYoung Park",
        "Hyewon Lee",
        "Mingyu Choi",
        "Seunghoon Han",
        "Jong-Ryul Lee",
        "Sungsu Lim",
        "Tae-Ho Kim"
      ],
      "abstract": "Anomaly segmentation is essential for industrial quality, maintenance, and\nstability. Existing text-guided zero-shot anomaly segmentation models are\neffective but rely on fixed prompts, limiting adaptability in diverse\nindustrial scenarios. This highlights the need for flexible, context-aware\nprompting strategies. We propose Image-Aware Prompt Anomaly Segmentation\n(IAP-AS), which enhances anomaly segmentation by generating dynamic,\ncontext-aware prompts using an image tagging model and a large language model\n(LLM). IAP-AS extracts object attributes from images to generate context-aware\nprompts, improving adaptability and generalization in dynamic and unstructured\nindustrial environments. In our experiments, IAP-AS improves the F1-max metric\nby up to 10%, demonstrating superior adaptability and generalization. It\nprovides a scalable solution for anomaly segmentation across industries",
      "tldr_zh": "这篇论文提出了一种Zero-Shot Industrial Anomaly Segmentation方法，通过Image-Aware Prompt Generation（IAP-AS）来解决现有文本引导模型依赖固定提示的局限性，提升在多样工业场景中的适应性。IAP-AS利用图像标记模型和大型语言模型（LLM）从图像中提取对象属性，生成动态的上下文感知提示，从而提高异常分割的泛化能力。实验结果显示，该方法将F1-max指标提升高达10%，为工业质量维护提供了一个可扩展的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to PAKDD 2025, 12 pages",
      "pdf_url": "http://arxiv.org/pdf/2504.13560v1",
      "published_date": "2025-04-18 08:58:40 UTC",
      "updated_date": "2025-04-18 08:58:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:33:23.738843"
    },
    {
      "arxiv_id": "2504.13558v1",
      "title": "Transformers Can Overcome the Curse of Dimensionality: A Theoretical Study from an Approximation Perspective",
      "title_zh": "Transformer 可以克服维度的诅咒：从逼近角度的理论研究",
      "authors": [
        "Yuling Jiao",
        "Yanming Lai",
        "Yang Wang",
        "Bokai Yan"
      ],
      "abstract": "The Transformer model is widely used in various application areas of machine\nlearning, such as natural language processing. This paper investigates the\napproximation of the H\\\"older continuous function class\n$\\mathcal{H}_{Q}^{\\beta}\\left([0,1]^{d\\times n},\\mathbb{R}^{d\\times n}\\right)$\nby Transformers and constructs several Transformers that can overcome the curse\nof dimensionality. These Transformers consist of one self-attention layer with\none head and the softmax function as the activation function, along with\nseveral feedforward layers. For example, to achieve an approximation accuracy\nof $\\epsilon$, if the activation functions of the feedforward layers in the\nTransformer are ReLU and floor, only\n$\\mathcal{O}\\left(\\log\\frac{1}{\\epsilon}\\right)$ layers of feedforward layers\nare needed, with widths of these layers not exceeding\n$\\mathcal{O}\\left(\\frac{1}{\\epsilon^{2/\\beta}}\\log\\frac{1}{\\epsilon}\\right)$.\nIf other activation functions are allowed in the feedforward layers, the width\nof the feedforward layers can be further reduced to a constant. These results\ndemonstrate that Transformers have a strong expressive capability. The\nconstruction in this paper is based on the Kolmogorov-Arnold Representation\nTheorem and does not require the concept of contextual mapping, hence our proof\nis more intuitively clear compared to previous Transformer approximation works.\nAdditionally, the translation technique proposed in this paper helps to apply\nthe previous approximation results of feedforward neural networks to\nTransformer research.",
      "tldr_zh": "这篇论文从逼近角度研究了Transformers模型是否能克服维数灾难（curse of dimensionality），焦点是逼近Hölder连续函数类$\\mathcal{H}_{Q}^{\\beta}\\left([0,1]^{d\\times n},\\mathbb{R}^{d\\times n}\\right)$。作者构建了包含一个自注意力层（使用softmax激活函数和一个头）以及几个前馈层的Transformers模型，例如使用ReLU和floor激活函数时，仅需$\\mathcal{O}\\left(\\log\\frac{1}{\\epsilon}\\right)$层，且前馈层宽度不超过$\\mathcal{O}\\left(\\frac{1}{\\epsilon^{2/\\beta}}\\log\\frac{1}{\\epsilon}\\right)$。如果采用其他激活函数，前馈层宽度可进一步减至常量，这些结果证明了Transformers的强大表达能力。论文基于Kolmogorov-Arnold Representation Theorem提出了一种翻译技术，将前馈神经网络的逼近结果应用于Transformers研究。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "41A25, 68T07, 68T50",
        "G.0"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.13558v1",
      "published_date": "2025-04-18 08:56:53 UTC",
      "updated_date": "2025-04-18 08:56:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:33:37.225558"
    },
    {
      "arxiv_id": "2504.16113v2",
      "title": "AI-Based Vulnerability Analysis of NFT Smart Contracts",
      "title_zh": "翻译失败",
      "authors": [
        "Xin Wang",
        "Xiaoqi Li"
      ],
      "abstract": "With the rapid growth of the NFT market, the security of smart contracts has\nbecome crucial. However, existing AI-based detection models for NFT contract\nvulnerabilities remain limited due to their complexity, while traditional\nmanual methods are time-consuming and costly. This study proposes an AI-driven\napproach to detect vulnerabilities in NFT smart contracts.\n  We collected 16,527 public smart contract codes, classifying them into five\nvulnerability categories: Risky Mutable Proxy, ERC-721 Reentrancy, Unlimited\nMinting, Missing Requirements, and Public Burn. Python-processed data was\nstructured into training/test sets. Using the CART algorithm with Gini\ncoefficient evaluation, we built initial decision trees for feature extraction.\nA random forest model was implemented to improve robustness through random\ndata/feature sampling and multitree integration. GridSearch hyperparameter\ntuning further optimized the model, with 3D visualizations demonstrating\nparameter impacts on vulnerability detection.\n  Results show the random forest model excels in detecting all five\nvulnerabilities. For example, it identifies Risky Mutable Proxy by analyzing\nauthorization mechanisms and state modifications, while ERC-721 Reentrancy\ndetection relies on external call locations and lock mechanisms. The ensemble\napproach effectively reduces single-tree overfitting, with stable performance\nimprovements after parameter tuning. This method provides an efficient\ntechnical solution for automated NFT contract detection and lays groundwork for\nscaling AI applications.",
      "tldr_zh": "本文提出了一种 AI 驱动的方法，用于检测 NFT 智能合约中的漏洞，解决现有模型的复杂性和传统手动方法的耗时问题。研究团队收集了 16,527 个公共合约代码，并将其分类为五类漏洞：Risky Mutable Proxy、ERC-721 Reentrancy、Unlimited Minting、Missing Requirements 和 Public Burn；随后使用 CART 算法构建决策树，并通过随机森林模型、随机采样、多树集成和 GridSearch 超参数调优来提升检测鲁棒性。结果表明，该模型在所有五类漏洞检测中表现出色，例如通过分析授权机制和状态修改识别 Risky Mutable Proxy，并有效减少过拟合，提供高效的自动化检测解决方案，为扩展 AI 应用奠定基础。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.16113v2",
      "published_date": "2025-04-18 08:55:31 UTC",
      "updated_date": "2025-04-24 08:25:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:33:49.444716"
    },
    {
      "arxiv_id": "2504.13554v1",
      "title": "Task Assignment and Exploration Optimization for Low Altitude UAV Rescue via Generative AI Enhanced Multi-agent Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Xin Tang",
        "Qian Chen",
        "Wenjie Weng",
        "Chao Jin",
        "Zhang Liu",
        "Jiacheng Wang",
        "Geng Sun",
        "Xiaohuan Li",
        "Dusit Niyato"
      ],
      "abstract": "Artificial Intelligence (AI)-driven convolutional neural networks enhance\nrescue, inspection, and surveillance tasks performed by low-altitude uncrewed\naerial vehicles (UAVs) and ground computing nodes (GCNs) in unknown\nenvironments. However, their high computational demands often exceed a single\nUAV's capacity, leading to system instability, further exacerbated by the\nlimited and dynamic resources of GCNs. To address these challenges, this paper\nproposes a novel cooperation framework involving UAVs, ground-embedded robots\n(GERs), and high-altitude platforms (HAPs), which enable resource pooling\nthrough UAV-to-GER (U2G) and UAV-to-HAP (U2H) communications to provide\ncomputing services for UAV offloaded tasks. Specifically, we formulate the\nmulti-objective optimization problem of task assignment and exploration\noptimization in UAVs as a dynamic long-term optimization problem. Our objective\nis to minimize task completion time and energy consumption while ensuring\nsystem stability over time. To achieve this, we first employ the Lyapunov\noptimization technique to transform the original problem, with stability\nconstraints, into a per-slot deterministic problem. We then propose an\nalgorithm named HG-MADDPG, which combines the Hungarian algorithm with a\ngenerative diffusion model (GDM)-based multi-agent deep deterministic policy\ngradient (MADDPG) approach. We first introduce the Hungarian algorithm as a\nmethod for exploration area selection, enhancing UAV efficiency in interacting\nwith the environment. We then innovatively integrate the GDM and multi-agent\ndeep deterministic policy gradient (MADDPG) to optimize task assignment\ndecisions, such as task offloading and resource allocation. Simulation results\ndemonstrate the effectiveness of the proposed approach, with significant\nimprovements in task offloading efficiency, latency reduction, and system\nstability compared to baseline methods.",
      "tldr_zh": "这篇论文针对低空无人机 (UAVs) 在未知环境中的救援任务，提出了一种新型合作框架，涉及 UAVs、地面嵌入式机器人 (GERs) 和高空平台 (HAPs)，通过 UAV-to-GER (U2G) 和 UAV-to-HAP (U2H) 通信实现资源共享，以解决计算需求高导致的系统不稳定性问题。作者将任务分配和探索优化表述为多目标优化问题，使用 Lyapunov optimization 技术转化为每个时隙的确定性问题，并开发了 HG-MADDPG 算法，结合 Hungarian algorithm 用于探索区域选择和生成扩散模型 (GDM) 基于的多智能体深度确定性策略梯度 (MADDPG) 用于任务卸载和资源分配优化。模拟结果表明，该方法比基线方法提高了任务卸载效率、降低了延迟和能量消耗，并显著提升了系统稳定性。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.13554v1",
      "published_date": "2025-04-18 08:44:06 UTC",
      "updated_date": "2025-04-18 08:44:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:34:01.629476"
    },
    {
      "arxiv_id": "2504.13551v1",
      "title": "Q-FAKER: Query-free Hard Black-box Attack via Controlled Generation",
      "title_zh": "翻译失败",
      "authors": [
        "CheolWon Na",
        "YunSeok Choi",
        "Jee-Hyong Lee"
      ],
      "abstract": "Many adversarial attack approaches are proposed to verify the vulnerability\nof language models. However, they require numerous queries and the information\non the target model. Even black-box attack methods also require the target\nmodel's output information. They are not applicable in real-world scenarios, as\nin hard black-box settings where the target model is closed and inaccessible.\nEven the recently proposed hard black-box attacks still require many queries\nand demand extremely high costs for training adversarial generators. To address\nthese challenges, we propose Q-faker (Query-free Hard Black-box Attacker), a\nnovel and efficient method that generates adversarial examples without\naccessing the target model. To avoid accessing the target model, we use a\nsurrogate model instead. The surrogate model generates adversarial sentences\nfor a target-agnostic attack. During this process, we leverage controlled\ngeneration techniques. We evaluate our proposed method on eight datasets.\nExperimental results demonstrate our method's effectiveness including high\ntransferability and the high quality of the generated adversarial examples, and\nprove its practical in hard black-box settings.",
      "tldr_zh": "该论文提出 Q-FAKER，一种无需查询目标模型的硬黑盒攻击方法，旨在解决现有攻击方法对模型访问和大量查询的依赖问题。通过使用 surrogate model 作为替代，并结合 controlled generation 技术，该方法生成高质量的对抗样本。实验在八个数据集上验证了 Q-FAKER 的高 transferability 和实用性，证明其在硬黑盒场景中的有效性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CR",
      "comment": "NAACL 2025 Findings",
      "pdf_url": "http://arxiv.org/pdf/2504.13551v1",
      "published_date": "2025-04-18 08:36:38 UTC",
      "updated_date": "2025-04-18 08:36:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:34:11.353481"
    },
    {
      "arxiv_id": "2504.13548v1",
      "title": "Beyond One-Hot Labels: Semantic Mixing for Model Calibration",
      "title_zh": "超越 One",
      "authors": [
        "Haoyang Luo",
        "Linwei Tao",
        "Minjing Dong",
        "Chang Xu"
      ],
      "abstract": "Model calibration seeks to ensure that models produce confidence scores that\naccurately reflect the true likelihood of their predictions being correct.\nHowever, existing calibration approaches are fundamentally tied to datasets of\none-hot labels implicitly assuming full certainty in all the annotations. Such\ndatasets are effective for classification but provides insufficient knowledge\nof uncertainty for model calibration, necessitating the curation of datasets\nwith numerically rich ground-truth confidence values. However, due to the\nscarcity of uncertain visual examples, such samples are not easily available as\nreal datasets. In this paper, we introduce calibration-aware data augmentation\nto create synthetic datasets of diverse samples and their ground-truth\nuncertainty. Specifically, we present Calibration-aware Semantic Mixing (CSM),\na novel framework that generates training samples with mixed class\ncharacteristics and annotates them with distinct confidence scores via\ndiffusion models. Based on this framework, we propose calibrated reannotation\nto tackle the misalignment between the annotated confidence score and the\nmixing ratio during the diffusion reverse process. Besides, we explore the loss\nfunctions that better fit the new data representation paradigm. Experimental\nresults demonstrate that CSM achieves superior calibration compared to the\nstate-of-the-art calibration approaches. Code is available at\ngithub.com/E-Galois/CSM.",
      "tldr_zh": "该论文指出，现有模型校准方法依赖于 one-hot labels，这假设标签完全确定，从而忽略了不确定性知识，导致校准效果不足。为解决这一问题，作者提出 Calibration-aware Semantic Mixing (CSM) 框架，利用 diffusion models 生成混合类样本并标注精确的置信度分数，同时引入 calibrated reannotation 来校正标注与混合比率的失调，并探索适合新数据表示的损失函数。实验结果显示，CSM 在模型校准性能上优于最先进方法，为更可靠的模型置信度评估提供了新途径。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.13548v1",
      "published_date": "2025-04-18 08:26:18 UTC",
      "updated_date": "2025-04-18 08:26:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:34:24.016915"
    },
    {
      "arxiv_id": "2504.13545v1",
      "title": "Enhancing Multilingual Sentiment Analysis with Explainability for Sinhala, English, and Code-Mixed Content",
      "title_zh": "翻译失败",
      "authors": [
        "Azmarah Rizvi",
        "Navojith Thamindu",
        "A. M. N. H. Adhikari",
        "W. P. U. Senevirathna",
        "Dharshana Kasthurirathna",
        "Lakmini Abeywardhana"
      ],
      "abstract": "Sentiment analysis is crucial for brand reputation management in the banking\nsector, where customer feedback spans English, Sinhala, Singlish, and\ncode-mixed text. Existing models struggle with low-resource languages like\nSinhala and lack interpretability for practical use. This research develops a\nhybrid aspect-based sentiment analysis framework that enhances multilingual\ncapabilities with explainable outputs. Using cleaned banking customer reviews,\nwe fine-tune XLM-RoBERTa for Sinhala and code-mixed text, integrate\ndomain-specific lexicon correction, and employ BERT-base-uncased for English.\nThe system classifies sentiment (positive, neutral, negative) with confidence\nscores, while SHAP and LIME improve interpretability by providing real-time\nsentiment explanations. Experimental results show that our approaches\noutperform traditional transformer-based classifiers, achieving 92.3 percent\naccuracy and an F1-score of 0.89 in English and 88.4 percent in Sinhala and\ncode-mixed content. An explainability analysis reveals key sentiment drivers,\nimproving trust and transparency. A user-friendly interface delivers\naspect-wise sentiment insights, ensuring accessibility for businesses. This\nresearch contributes to robust, transparent sentiment analysis for financial\napplications by bridging gaps in multilingual, low-resource NLP and\nexplainability.",
      "tldr_zh": "这篇论文针对多语言情感分析的挑战，开发了一个混合的基于方面的框架，用于处理英语、Sinhala 和代码混合文本，特别是针对银行部门的客户反馈。方法包括微调 XLM-RoBERTa 处理 Sinhala 和代码混合内容，使用 BERT-base-uncased 处理英语，并整合领域特定词汇修正和 SHAP 与 LIME 提供实时情感解释。实验结果显示，该框架在英语上达到 92.3% 准确率和 0.89 F1 分数，在 Sinhala 和代码混合内容上达到 88.4% 准确率，优于传统 transformer 模型。该研究提升了低资源语言 NLP 的鲁棒性和透明度，为金融应用提供可信任的工具。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "6 pages, 6 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2504.13545v1",
      "published_date": "2025-04-18 08:21:12 UTC",
      "updated_date": "2025-04-18 08:21:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:34:37.881997"
    },
    {
      "arxiv_id": "2504.13541v1",
      "title": "SwitchMT: An Adaptive Context Switching Methodology for Scalable Multi-Task Learning in Intelligent Autonomous Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Avaneesh Devkota",
        "Rachmad Vidya Wicaksana Putra",
        "Muhammad Shafique"
      ],
      "abstract": "The ability to train intelligent autonomous agents (such as mobile robots) on\nmultiple tasks is crucial for adapting to dynamic real-world environments.\nHowever, state-of-the-art reinforcement learning (RL) methods only excel in\nsingle-task settings, and still struggle to generalize across multiple tasks\ndue to task interference. Moreover, real-world environments also demand the\nagents to have data stream processing capabilities. Toward this, a\nstate-of-the-art work employs Spiking Neural Networks (SNNs) to improve\nmulti-task learning by exploiting temporal information in data stream, while\nenabling lowpower/energy event-based operations. However, it relies on fixed\ncontext/task-switching intervals during its training, hence limiting the\nscalability and effectiveness of multi-task learning. To address these\nlimitations, we propose SwitchMT, a novel adaptive task-switching methodology\nfor RL-based multi-task learning in autonomous agents. Specifically, SwitchMT\nemploys the following key ideas: (1) a Deep Spiking Q-Network with active\ndendrites and dueling structure, that utilizes task-specific context signals to\ncreate specialized sub-networks; and (2) an adaptive task-switching policy that\nleverages both rewards and internal dynamics of the network parameters.\nExperimental results demonstrate that SwitchMT achieves superior performance in\nmulti-task learning compared to state-of-the-art methods. It achieves\ncompetitive scores in multiple Atari games (i.e., Pong: -8.8, Breakout: 5.6,\nand Enduro: 355.2) compared to the state-of-the-art, showing its better\ngeneralized learning capability. These results highlight the effectiveness of\nour SwitchMT methodology in addressing task interference while enabling\nmulti-task learning automation through adaptive task switching, thereby paving\nthe way for more efficient generalist agents with scalable multi-task learning\ncapabilities.",
      "tldr_zh": "该研究针对智能自主代理（如移动机器人）在多任务学习中面临的任务干扰问题，提出了一种自适应上下文切换方法SwitchMT，以提升强化学习（RL）模型的可扩展性和泛化能力。SwitchMT 核心包括使用 Deep Spiking Q-Network（结合主动树突和双赢结构）创建任务特定子网络，以及基于奖励和网络参数内部动态的自适应任务切换策略，从而实现高效的数据流处理和多任务优化。实验在 Atari 游戏上（如 Pong: -8.8、Breakout: 5.6 和 Enduro: 355.2）取得了比现有方法更优的性能，证明了其在减少任务干扰和自动化多任务学习方面的有效性，为开发可扩展的通用代理奠定了基础。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.NE",
      "comment": "7 pages, 7 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2504.13541v1",
      "published_date": "2025-04-18 08:12:59 UTC",
      "updated_date": "2025-04-18 08:12:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:34:49.258563"
    },
    {
      "arxiv_id": "2504.13984v1",
      "title": "One Jump Is All You Need: Short-Cutting Transformers for Early Exit Prediction with One Jump to Fit All Exit Levels",
      "title_zh": "翻译失败",
      "authors": [
        "Amrit Diggavi Seshadri"
      ],
      "abstract": "To reduce the time and computational costs of inference of large language\nmodels, there has been interest in parameter-efficient low-rank early-exit\ncasting of transformer hidden-representations to final-representations. Such\nlow-rank short-cutting has been shown to outperform identity shortcuts at early\nmodel stages while offering parameter-efficiency in shortcut jumps. However,\ncurrent low-rank methods maintain a separate early-exit shortcut jump to\nfinal-representations for each transformer intermediate block-level during\ninference. In this work, we propose selection of a single One-Jump-Fits-All\n(OJFA) low-rank shortcut that offers over a 30x reduction in shortcut parameter\ncosts during inference. We show that despite this extreme reduction, our OJFA\nchoice largely matches the performance of maintaining multiple shortcut jumps\nduring inference and offers stable precision from all transformer block-levels\nfor GPT2-XL, Phi3-Mini and Llama2-7B transformer models.",
      "tldr_zh": "本文提出 One-Jump-Fits-All (OJFA) 方法，通过一个单一的低秩短路跳跃来优化 Transformer 模型的早期退出预测，从而显著减少推理过程中的参数成本，达到 30 倍以上的降低。相比于现有方法，OJFA 在保持性能基本一致的同时，提供从所有 Transformer 块级别的稳定精度。实验在 GPT2-XL、Phi3-Mini 和 Llama2-7B 模型上验证了其有效性，为参数高效的大型语言模型推理提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.13984v1",
      "published_date": "2025-04-18 08:02:40 UTC",
      "updated_date": "2025-04-18 08:02:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:34:59.910027"
    },
    {
      "arxiv_id": "2504.13534v2",
      "title": "CoT-RAG: Integrating Chain of Thought and Retrieval-Augmented Generation to Enhance Reasoning in Large Language Models",
      "title_zh": "CoT-RAG：整合链式思维和检索增强生成以提升大语言模型中的推理能力",
      "authors": [
        "Feiyang Li",
        "Peng Fang",
        "Zhan Shi",
        "Arijit Khan",
        "Fang Wang",
        "Dan Feng",
        "Weihao Wang",
        "Xin Zhang",
        "Yongjian Cui"
      ],
      "abstract": "Chain-of-thought (CoT) reasoning boosts large language models' (LLMs)\nperformance on complex tasks but faces two key limitations: a lack of\nreliability when solely relying on LLM-generated reasoning chains and\ninterference from natural language reasoning steps with the models' inference\nprocess, also known as the inference logic of LLMs. To address these issues, we\npropose CoT-RAG, a novel reasoning framework with three key designs: (i)\nKnowledge Graph-driven CoT Generation,featuring knowledge graphs to modulate\nreasoning chain generation of LLMs, thereby enhancing reasoning credibility;\n(ii) Learnable Knowledge Case-aware RAG, which incorporates retrieval-augmented\ngeneration (RAG) into knowledge graphs to retrieve relevant sub-cases and\nsub-descriptions, providing LLMs with learnable information; (iii)\nPseudo-Program Prompting Execution, which promotes greater logical rigor by\nguiding LLMs to execute reasoning tasks as pseudo-programs. Evaluations on nine\npublic datasets spanning three reasoning tasks reveal significant accuracy\ngains--ranging from 4.0% to 44.3%--over state-of-the-art methods. Furthermore,\ntests on four domain-specific datasets demonstrate exceptional accuracy and\nefficient execution, underscoring its practical applicability and scalability.",
      "tldr_zh": "该论文提出 CoT-RAG 框架，将 Chain-of-Thought (CoT) 推理与 Retrieval-Augmented Generation (RAG) 相结合，以解决大型语言模型 (LLMs) 在复杂任务中的可靠性不足和推理干扰问题。框架的关键设计包括：(i) Knowledge Graph-driven CoT Generation，使用知识图谱提升推理链的可靠性；(ii) Learnable Knowledge Case-aware RAG，通过检索相关子案例和描述提供可学习信息；(iii) Pseudo-Program Prompting Execution，引导 LLMs 以伪程序方式执行任务以增强逻辑严谨性。在九个公共数据集上的评估显示，准确率较现有方法提升 4.0% 至 44.3%，而在四个领域特定数据集上表现出色，证明了其实用性和可扩展性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.13534v2",
      "published_date": "2025-04-18 07:55:09 UTC",
      "updated_date": "2025-05-19 03:23:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:35:12.529228"
    },
    {
      "arxiv_id": "2504.13521v2",
      "title": "Deep Learning Models Meet Financial Data Modalities",
      "title_zh": "翻译失败",
      "authors": [
        "Kasymkhan Khubiev",
        "Mikhail Semenov"
      ],
      "abstract": "Algorithmic trading relies on extracting meaningful signals from diverse\nfinancial data sources, including candlestick charts, order statistics on put\nand canceled orders, traded volume data, limit order books, and news flow.\nWhile deep learning has demonstrated remarkable success in processing\nunstructured data and has significantly advanced natural language processing,\nits application to structured financial data remains an ongoing challenge. This\nstudy investigates the integration of deep learning models with financial data\nmodalities, aiming to enhance predictive performance in trading strategies and\nportfolio optimization. We present a novel approach to incorporating limit\norder book analysis into algorithmic trading by developing embedding techniques\nand treating sequential limit order book snapshots as distinct input channels\nin an image-based representation. Our methodology for processing limit order\nbook data achieves state-of-the-art performance in high-frequency trading\nalgorithms, underscoring the effectiveness of deep learning in financial\napplications.",
      "tldr_zh": "本研究探讨了深度学习模型在处理各种金融数据模态（如蜡烛图、订单统计、交易量数据、限价订单簿和新闻流）中的应用，旨在提升算法交易策略和投资组合优化的预测性能。针对结构化金融数据的挑战，该方法提出了一种新颖的嵌入技术，将限价订单簿的连续快照视为图像表示中的不同输入通道，从而实现对数据的有效处理。在高频交易算法中，该方法达到了最先进性能，证明了深度学习在金融领域的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE",
        "q-fin.ST"
      ],
      "primary_category": "cs.LG",
      "comment": "15 pages, 14 images, 7 tables",
      "pdf_url": "http://arxiv.org/pdf/2504.13521v2",
      "published_date": "2025-04-18 07:19:44 UTC",
      "updated_date": "2025-04-21 07:36:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:35:24.118977"
    },
    {
      "arxiv_id": "2504.13517v1",
      "title": "Optimizing Electric Vehicle Charging Station Locations: A Data-driven System with Multi-source Fusion",
      "title_zh": "优化电动汽车充电站位置：一个基于数据驱动的多源融合系统",
      "authors": [
        "Lihuan Li",
        "Du Yin",
        "Hao Xue",
        "David Lillo-Trynes",
        "Flora Salim"
      ],
      "abstract": "With the growing electric vehicles (EVs) charging demand, urban planners face\nthe challenges of providing charging infrastructure at optimal locations. For\nexample, range anxiety during long-distance travel and the inadequate\ndistribution of residential charging stations are the major issues many cities\nface. To achieve reasonable estimation and deployment of the charging demand,\nwe develop a data-driven system based on existing EV trips in New South Wales\n(NSW) state, Australia, incorporating multiple factors that enhance the\ngeographical feasibility of recommended charging stations. Our system\nintegrates data sources including EV trip data, geographical data such as route\ndata and Local Government Area (LGA) boundaries, as well as features like fire\nand flood risks, and Points of Interest (POIs). We visualize our results to\nintuitively demonstrate the findings from our data-driven, multi-source fusion\nsystem, and evaluate them through case studies. The outcome of this work can\nprovide a platform for discussion to develop new insights that could be used to\ngive guidance on where to position future EV charging stations.",
      "tldr_zh": "该研究针对电动汽车（EVs）充电需求的增长及其带来的里程焦虑和基础设施分布不均等问题，开发了一个数据驱动系统，用于优化充电站位置。该系统基于澳大利亚新南威尔士州（NSW）的现有EV出行数据，融合多源数据包括EV出行数据、地理数据（如路线数据和Local Government Area (LGA) 边界）、火灾和洪水风险，以及Points of Interest (POIs)，以提升地理可行性。通过可视化和案例研究评估，该系统提供了直观的分析结果，并为城市规划者提供平台，指导未来EV充电站的部署。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "4-page short paper",
      "pdf_url": "http://arxiv.org/pdf/2504.13517v1",
      "published_date": "2025-04-18 07:10:48 UTC",
      "updated_date": "2025-04-18 07:10:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:35:36.054033"
    },
    {
      "arxiv_id": "2504.13515v1",
      "title": "Large Language Models for Validating Network Protocol Parsers",
      "title_zh": "大语言模型用于验证网络协议解析器",
      "authors": [
        "Mingwei Zheng",
        "Danning Xie",
        "Xiangyu Zhang"
      ],
      "abstract": "Network protocol parsers are essential for enabling correct and secure\ncommunication between devices. Bugs in these parsers can introduce critical\nvulnerabilities, including memory corruption, information leakage, and\ndenial-of-service attacks. An intuitive way to assess parser correctness is to\ncompare the implementation with its official protocol standard. However, this\ncomparison is challenging because protocol standards are typically written in\nnatural language, whereas implementations are in source code. Existing methods\nlike model checking, fuzzing, and differential testing have been used to find\nparsing bugs, but they either require significant manual effort or ignore the\nprotocol standards, limiting their ability to detect semantic violations. To\nenable more automated validation of parser implementations against protocol\nstandards, we propose PARVAL, a multi-agent framework built on large language\nmodels (LLMs). PARVAL leverages the capabilities of LLMs to understand both\nnatural language and code. It transforms both protocol standards and their\nimplementations into a unified intermediate representation, referred to as\nformat specifications, and performs a differential comparison to uncover\ninconsistencies. We evaluate PARVAL on the Bidirectional Forwarding Detection\n(BFD) protocol. Our experiments demonstrate that PARVAL successfully identifies\ninconsistencies between the implementation and its RFC standard, achieving a\nlow false positive rate of 5.6%. PARVAL uncovers seven unique bugs, including\nfive previously unknown issues.",
      "tldr_zh": "本论文探讨了使用大型语言模型 (LLMs) 来验证网络协议解析器的正确性，以解决传统方法（如模型检查、模糊测试和差异测试）的局限性。PARVAL 框架通过多智能体系统，将协议标准（通常为自然语言）和实现代码转换为统一的中间表示（format specifications），并进行差异比较以自动检测语义违规和不一致。实验在 Bidirectional Forwarding Detection (BFD) 协议上验证了 PARVAL 的有效性，它发现了七个独特 bug（包括五个新问题），并实现了仅 5.6% 的假阳性率。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.13515v1",
      "published_date": "2025-04-18 07:09:56 UTC",
      "updated_date": "2025-04-18 07:09:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:35:48.306446"
    },
    {
      "arxiv_id": "2504.16946v1",
      "title": "MobileCity: An Efficient Framework for Large-Scale Urban Behavior Simulation",
      "title_zh": "MobileCity：一个高效框架，用于大规模城市行为模拟",
      "authors": [
        "Xiaotong Ye",
        "Nicolas Bougie",
        "Toshihiko Yamasaki",
        "Narimasa Watanabe"
      ],
      "abstract": "Generative agents offer promising capabilities for simulating realistic urban\nbehaviors. However, existing methods oversimplify transportation choices in\nmodern cities, and require prohibitive computational resources for large-scale\npopulation simulation. To address these limitations, we first present a virtual\ncity that features multiple functional buildings and transportation modes.\nThen, we conduct extensive surveys to model behavioral choices and mobility\npreferences among population groups. Building on these insights, we introduce a\nsimulation framework that captures the complexity of urban mobility while\nremaining scalable, enabling the simulation of over 4,000 agents. To assess the\nrealism of the generated behaviors, we perform a series of micro and\nmacro-level analyses. Beyond mere performance comparison, we explore insightful\nexperiments, such as predicting crowd density from movement patterns and\nidentifying trends in vehicle preferences across agent demographics.",
      "tldr_zh": "本论文提出MobileCity框架，用于高效模拟大规模城市行为，解决现有Generative agents方法在交通选择简化及计算资源需求过高的问题。该框架首先构建了一个包含多种功能建筑和交通模式的虚拟城市，并通过广泛调查建模人群的行为选择和移动偏好，从而实现对超过4000个代理的模拟，同时捕捉城市移动的复杂性。通过微观和宏观分析评估行为的真实性，该框架还进行实验预测人群密度并分析代理人口统计中的车辆偏好趋势。总体而言，MobileCity提升了城市行为模拟的可扩展性和实用性。",
      "categories": [
        "cs.SI",
        "cs.AI"
      ],
      "primary_category": "cs.SI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.16946v1",
      "published_date": "2025-04-18 07:01:05 UTC",
      "updated_date": "2025-04-18 07:01:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:35:59.749452"
    },
    {
      "arxiv_id": "2504.13981v1",
      "title": "CacheFormer: High Attention-Based Segment Caching",
      "title_zh": "CacheFormer: 基于高注意力的段缓存",
      "authors": [
        "Sushant Singh",
        "Ausif Mahmood"
      ],
      "abstract": "Efficiently handling long contexts in transformer-based language models with\nlow perplexity is an active area of research. Numerous recent approaches like\nLinformer, Longformer, Performer, and Structured state space models (SSMs).,\nhave not fully resolved this problem. All these models strive to reduce the\nquadratic time complexity of the attention mechanism while minimizing the loss\nin quality due to the effective compression of the long context. Inspired by\nthe cache and virtual memory principle in computers, where in case of a cache\nmiss, not only the needed data is retrieved from the memory, but the adjacent\ndata is also obtained, we apply this concept to handling long contexts by\ndividing it into small segments. In our design, we retrieve the nearby segments\nin an uncompressed form when high segment-level attention occurs at the\ncompressed level. Our en-hancements for handling long context include\naggregating four attention mechanisms consisting of short sliding window\nattention, long compressed segmented attention, dynamically retrieving top k\nhigh attention uncompressed segments, and overlapping segments in long segment\nattention to avoid segment fragmentation. These enhancements result in an\narchitecture that outperforms ex-isting SOTA architectures with an average\nperplexity improvement of 8.5% over similar model sizes.",
      "tldr_zh": "本论文提出 CacheFormer，一种基于缓存原理的高注意力段缓存机制，旨在高效处理 Transformer 模型中的长上下文问题，同时降低 perplexity。\n该方法将长上下文分为小段，并结合短滑动窗口注意力、长压缩段注意力、动态检索 top k 高注意力未压缩段以及段重叠技术，以减少二次时间复杂度和避免段碎片。\n实验结果表明，CacheFormer 在类似模型大小下，比现有 SOTA 架构平均 perplexity 改善 8.5%。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.13981v1",
      "published_date": "2025-04-18 06:34:57 UTC",
      "updated_date": "2025-04-18 06:34:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:36:12.439318"
    },
    {
      "arxiv_id": "2504.13495v1",
      "title": "Statistical Validation in Cultural Adaptations of Cognitive Tests: A Multi- Regional Systematic Review",
      "title_zh": "翻译失败",
      "authors": [
        "Miit Daga",
        "Priyasha Mohanty",
        "Ram Krishna",
        "Swarna Priya RM"
      ],
      "abstract": "This systematic review discusses the methodological approaches and\nstatistical confirmations of cross-cultural adaptations of cognitive evaluation\ntools used with different populations. The review considers six seminal studies\non the methodology of cultural adaptation in Europe, Asia, Africa, and South\nAmerica. The results indicate that proper adaptations need holistic models with\ndemographic changes, and education explained as much as 26.76% of the variance\nin MoCA-H scores. Cultural-linguistic factors explained 6.89% of the variance\nin European adaptations of MoCA-H; however, another study on adapted MMSE and\nBCSB among Brazilian Indigenous populations reported excellent diagnostic\nperformance, with a sensitivity of 94.4% and specificity of 99.2%. There was\n78.5% inter-rater agreement on the evaluation of cultural adaptation using the\nManchester Translation Evaluation Checklist. A paramount message of the paper\nis that community feedback is necessary for culturally appropriate preparation,\nstandardized translation protocols also must be included, along with robust\nstatistical validation methodologies for developing cognitive assessment\ninstruments. This review supplies evidence-based frameworks for the further\nadaptation of cognitive assessments in increasingly diverse global health\nsettings.",
      "tldr_zh": "这篇系统综述探讨了认知评估工具（如 MoCA-H 和 MMSE）在不同文化中的适应方法和统计验证，涵盖了欧洲、亚洲、非洲和南美的六项关键研究。结果显示，教育因素可解释 MoCA-H 成绩方差的 26.76%，而文化语言因素在欧洲适应中解释了 6.89%；此外，巴西土著人群的 MMSE 和 BCSB 适应表现出高性能，包括灵敏度 94.4% 和特异性 99.2%，评定者间一致性达 78.5%。综述强调，需要结合社区反馈、标准化翻译协议（如 Manchester Translation Evaluation Checklist）和稳健的统计验证方法，以构建适用于全球多样化健康环境的证据框架。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG",
        "cs.NE"
      ],
      "primary_category": "cs.CY",
      "comment": "This paper is accepted and presented in the International Conference\n  Challenges & Opportunities in Artificial Intelligence: Engineering &\n  Management Applications (COAIEMA 2025) and to be published in Taylor &\n  Francis Proceedings",
      "pdf_url": "http://arxiv.org/pdf/2504.13495v1",
      "published_date": "2025-04-18 06:25:02 UTC",
      "updated_date": "2025-04-18 06:25:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:36:25.463010"
    },
    {
      "arxiv_id": "2504.13480v1",
      "title": "Integrating Locality-Aware Attention with Transformers for General Geometry PDEs",
      "title_zh": "翻译失败",
      "authors": [
        "Minsu Koh",
        "Beom-Chul Park",
        "Heejo Kong",
        "Seong-Whan Lee"
      ],
      "abstract": "Neural operators have emerged as promising frameworks for learning mappings\ngoverned by partial differential equations (PDEs), serving as data-driven\nalternatives to traditional numerical methods. While methods such as the\nFourier neural operator (FNO) have demonstrated notable performance, their\nreliance on uniform grids restricts their applicability to complex geometries\nand irregular meshes. Recently, Transformer-based neural operators with linear\nattention mechanisms have shown potential in overcoming these limitations for\nlarge-scale PDE simulations. However, these approaches predominantly emphasize\nglobal feature aggregation, often overlooking fine-scale dynamics and localized\nPDE behaviors essential for accurate solutions. To address these challenges, we\npropose the Locality-Aware Attention Transformer (LA2Former), which leverages\nK-nearest neighbors for dynamic patchifying and integrates global-local\nattention for enhanced PDE modeling. By combining linear attention for\nefficient global context encoding with pairwise attention for capturing\nintricate local interactions, LA2Former achieves an optimal balance between\ncomputational efficiency and predictive accuracy. Extensive evaluations across\nsix benchmark datasets demonstrate that LA2Former improves predictive accuracy\nby over 50% relative to existing linear attention methods, while also\noutperforming full pairwise attention under optimal conditions. This work\nunderscores the critical importance of localized feature learning in advancing\nTransformer-based neural operators for solving PDEs on complex and irregular\ndomains.",
      "tldr_zh": "这篇论文提出 Locality-Aware Attention Transformer (LA2Former)，一种整合局部感知注意力的 Transformer 模型，用于处理一般几何偏微分方程 (PDEs)，以克服现有方法如 Fourier Neural Operator (FNO) 在复杂几何和不规则网格上的局限性。LA2Former 通过 K-nearest neighbors 动态 patchifying 和结合线性注意力（用于高效全局上下文编码）与 pairwise 注意力（用于捕捉局部交互），实现了计算效率与预测准确性的平衡。在六个基准数据集上，该模型相对于现有线性注意力方法提高了超过 50% 的预测准确性，并优于全 pairwise 注意力方法，突显了局部特征学习在 PDEs 建模中的关键作用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by IJCNN 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.13480v1",
      "published_date": "2025-04-18 05:43:49 UTC",
      "updated_date": "2025-04-18 05:43:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:36:37.055012"
    },
    {
      "arxiv_id": "2504.13477v1",
      "title": "Creating 'Full-Stack' Hybrid Reasoning Systems that Prioritize and Enhance Human Intelligence",
      "title_zh": "翻译失败",
      "authors": [
        "Sean Koon"
      ],
      "abstract": "The idea of augmented or hybrid intelligence offers a compelling vision for\ncombining human and AI capabilities, especially in tasks where human wisdom,\nexpertise, or common sense are essential. Unfortunately, human reasoning can be\nflawed and shortsighted, resulting in adverse individual impacts or even\nlong-term societal consequences. While strong efforts are being made to develop\nand optimize the AI aspect of hybrid reasoning, the real urgency lies in\nfostering wiser and more intelligent human participation. Tools that enhance\ncritical thinking, ingenuity, expertise, and even wisdom could be essential in\naddressing the challenges of our emerging future. This paper proposes the\ndevelopment of generative AI-based tools that enhance both the human ability to\nreflect upon a problem as well as the ability to explore the technical aspects\nof it. A high-level model is also described for integrating AI and human\ncapabilities in a way that centralizes human participation and control.",
      "tldr_zh": "本论文探讨了“augmented intelligence”或“hybrid intelligence”的概念，旨在通过结合人类智慧和AI能力来处理需要常识和专长的任务。针对人类推理可能存在的缺陷，如短视和错误，论文提出开发基于generative AI的工具，以提升人类的批判性思考、创新能力和问题探索。论文还描述了一个高层次模型，将AI与人类能力整合，确保人类参与和控制处于核心位置，从而促进更智慧的混合决策系统。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "10 pages; 3 figures; 1 table",
      "pdf_url": "http://arxiv.org/pdf/2504.13477v1",
      "published_date": "2025-04-18 05:38:21 UTC",
      "updated_date": "2025-04-18 05:38:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:36:49.530689"
    },
    {
      "arxiv_id": "2504.13472v1",
      "title": "CodeVisionary: An Agent-based Framework for Evaluating Large Language Models in Code Generation",
      "title_zh": "CodeVisionary：一种基于代理的框架，用于评估大语言模型在代码生成中的性能",
      "authors": [
        "Xinchen Wang",
        "Pengfei Gao",
        "Chao Peng",
        "Ruida Hu",
        "Cuiyun Gao"
      ],
      "abstract": "Large language models (LLMs) have demonstrated strong capabilities in code\ngeneration, underscoring the critical need for rigorous and comprehensive\nevaluation. Existing evaluation approaches fall into three categories,\nincluding human-centered, metric-based, and LLM-based. Considering that\nhuman-centered approaches are labour-intensive and metric-based ones overly\nrely on reference answers, LLM-based approaches are gaining increasing\nattention due to their stronger contextual understanding capabilities and\nsuperior efficiency. However, the performance of LLM-based approaches remains\nlimited due to: (1) lack of multisource domain knowledge, and (2) insufficient\ncomprehension of complex code.\n  To mitigate the limitations, we propose CodeVisionary, the first LLM-based\nagent framework for evaluating LLMs in code generation. CodeVisionary consists\nof two stages: (1) Multiscore knowledge analysis stage, which aims to gather\nmultisource and comprehensive domain knowledge by formulating and executing a\nstepwise evaluation plan. (2) Negotiation-based scoring stage, which involves\nmultiple judges engaging in discussions to better comprehend the complex code\nand reach a consensus on the evaluation score. Extensive experiments\ndemonstrate that CodeVisionary achieves the best performance for evaluating\nLLMs in code generation, outperforming the best baseline methods with average\nimprovements of 0.202, 0.139, and 0.117 in Pearson, Spearman, and Kendall-Tau\ncoefficients, respectively. Besides, CodeVisionary provides detailed evaluation\nreports, which assist developers in identifying shortcomings and making\nimprovements. The resources of CodeVisionary are available at\nhttps://anonymous.4open.science/r/CodeVisionary.",
      "tldr_zh": "该研究提出CodeVisionary，一种基于代理的框架，用于评估Large Language Models (LLMs)在代码生成中的性能，以解决现有LLM-based评估方法在多源领域知识和复杂代码理解方面的局限性。框架包括两个阶段：Multiscore knowledge analysis阶段，通过制定逐步评估计划收集全面领域知识；以及Negotiation-based scoring阶段，让多个评估代理讨论并达成共识评分。实验结果显示，CodeVisionary在Pearson、Spearman和Kendall-Tau系数上分别比最佳基线方法提高了0.202、0.139和0.117，并提供详细评估报告，帮助开发者识别不足并优化LLMs。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.13472v1",
      "published_date": "2025-04-18 05:26:32 UTC",
      "updated_date": "2025-04-18 05:26:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:37:01.434954"
    },
    {
      "arxiv_id": "2504.13460v3",
      "title": "Chain-of-Thought Textual Reasoning for Few-shot Temporal Action Localization",
      "title_zh": "翻译失败",
      "authors": [
        "Hongwei Ji",
        "Wulian Yun",
        "Mengshi Qi",
        "Huadong Ma"
      ],
      "abstract": "Traditional temporal action localization (TAL) methods rely on large amounts\nof detailed annotated data, whereas few-shot TAL reduces this dependence by\nusing only a few training samples to identify unseen action categories.\nHowever, existing few-shot TAL methods typically focus solely on video-level\ninformation, neglecting textual information, which can provide valuable\nsemantic support for the localization task. Therefore, we propose a new\nfew-shot temporal action localization method by Chain-of-Thought textual\nreasoning to improve localization performance. Specifically, we design a novel\nfew-shot learning framework that leverages textual semantic information to\nenhance the model's ability to capture action commonalities and variations,\nwhich includes a semantic-aware text-visual alignment module designed to align\nthe query and support videos at different levels. Meanwhile, to better express\nthe temporal dependencies and causal relationships between actions at the\ntextual level to assist action localization, we design a Chain of Thought\n(CoT)-like reasoning method that progressively guides the Vision Language Model\n(VLM) and Large Language Model (LLM) to generate CoT-like text descriptions for\nvideos. The generated texts can capture more variance of action than visual\nfeatures. We conduct extensive experiments on the publicly available\nActivityNet1.3 and THUMOS14 datasets. We introduce the first dataset named\nHuman-related Anomaly Localization and explore the application of the TAL task\nin human anomaly detection. The experimental results demonstrate that our\nproposed method significantly outperforms existing methods in single-instance\nand multi-instance scenarios. We will release our code, data and benchmark.",
      "tldr_zh": "本研究针对Few-shot Temporal Action Localization (TAL) 的局限性，提出了一种基于Chain-of-Thought (CoT) 文本推理的方法，以整合文本语义信息提升动作定位性能。具体而言，该框架包括一个语义感知的文本-视觉对齐模块（semantic-aware text-visual alignment module），用于在不同级别对齐查询和支持视频，以及一个CoT-like 推理机制，利用Vision Language Model (VLM) 和Large Language Model (LLM) 生成视频的文本描述，从而更好地捕捉动作的共同性和变异性。实验在ActivityNet1.3 和THUMOS14 数据集上进行，并引入了新的Human-related Anomaly Localization 数据集，结果显示该方法在单实例和多实例场景中显著优于现有方法。作者计划发布代码、数据和基准，以推动相关领域的发展。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.13460v3",
      "published_date": "2025-04-18 04:35:35 UTC",
      "updated_date": "2025-05-06 05:00:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:37:13.622316"
    },
    {
      "arxiv_id": "2504.13448v1",
      "title": "Ascribe New Dimensions to Scientific Data Visualization with VR",
      "title_zh": "翻译失败",
      "authors": [
        "Daniela Ushizima",
        "Guilherme Melo dos Santos",
        "Zineb Sordo",
        "Ronald Pandolfi",
        "Jeffrey Donatelli"
      ],
      "abstract": "For over half a century, the computer mouse has been the primary tool for\ninteracting with digital data, yet it remains a limiting factor in exploring\ncomplex, multi-scale scientific images. Traditional 2D visualization methods\nhinder intuitive analysis of inherently 3D structures. Virtual Reality (VR)\noffers a transformative alternative, providing immersive, interactive\nenvironments that enhance data comprehension. This article introduces\nASCRIBE-VR, a VR platform of Autonomous Solutions for Computational Research\nwith Immersive Browsing \\& Exploration, which integrates AI-driven algorithms\nwith scientific images. ASCRIBE-VR enables multimodal analysis, structural\nassessments, and immersive visualization, supporting scientific visualization\nof advanced datasets such as X-ray CT, Magnetic Resonance, and synthetic 3D\nimaging. Our VR tools, compatible with Meta Quest, can consume the output of\nour AI-based segmentation and iterative feedback processes to enable seamless\nexploration of large-scale 3D images. By merging AI-generated results with VR\nvisualization, ASCRIBE-VR enhances scientific discovery, bridging the gap\nbetween computational analysis and human intuition in materials research,\nconnecting human-in-the-loop with digital twins.",
      "tldr_zh": "本文研究指出，传统鼠标交互和2D可视化方法限制了复杂多尺度科学图像的探索，因此提出ASCRIBE-VR平台，一种整合AI驱动算法的VR工具，用于科学数据的沉浸式浏览和探索。该平台支持多模态分析、结构评估以及X-ray CT、Magnetic Resonance等高级数据集的3D可视化，通过AI分割和迭代反馈实现无缝交互。ASCRIBE-VR兼容Meta Quest设备，桥接计算分析与人类直觉，增强材料研究中的科学发现并促进人类在环与数字孪生的融合。",
      "categories": [
        "cs.GR",
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "cs.GR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.13448v1",
      "published_date": "2025-04-18 03:59:39 UTC",
      "updated_date": "2025-04-18 03:59:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:37:24.790424"
    },
    {
      "arxiv_id": "2504.13443v1",
      "title": "Trust, but verify",
      "title_zh": "信任，但验证",
      "authors": [
        "Michael J. Yuan",
        "Carlos Campoy",
        "Sydney Lai",
        "James Snewin",
        "Ju Long"
      ],
      "abstract": "Decentralized AI agent networks, such as Gaia, allows individuals to run\ncustomized LLMs on their own computers and then provide services to the public.\nHowever, in order to maintain service quality, the network must verify that\nindividual nodes are running their designated LLMs. In this paper, we\ndemonstrate that in a cluster of mostly honest nodes, we can detect nodes that\nrun unauthorized or incorrect LLM through social consensus of its peers. We\nwill discuss the algorithm and experimental data from the Gaia network. We will\nalso discuss the intersubjective validation system, implemented as an\nEigenLayer AVS to introduce financial incentives and penalties to encourage\nhonest behavior from LLM nodes.",
      "tldr_zh": "本文提出了一种验证机制，用于去中心化 AI 代理网络（如 Gaia），以确保节点运行指定的 LLMs 而非未经授权的模型。通过节点间的社会共识（social consensus of its peers），算法能够在主要是诚实节点的集群中检测出违规节点，并基于 Gaia 网络的实验数据验证其有效性。该系统还引入了 intersubjective validation system 作为 EigenLayer AVS 实现，利用财务激励和惩罚来促进节点的诚实行为，从而提升整体服务质量和网络可靠性。",
      "categories": [
        "cs.AI",
        "cs.DC",
        "cs.MA",
        "econ.GN",
        "q-fin.EC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.13443v1",
      "published_date": "2025-04-18 03:49:53 UTC",
      "updated_date": "2025-04-18 03:49:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:37:36.487627"
    },
    {
      "arxiv_id": "2504.16112v1",
      "title": "HPU: High-Bandwidth Processing Unit for Scalable, Cost-effective LLM Inference via GPU Co-processing",
      "title_zh": "翻译失败",
      "authors": [
        "Myunghyun Rhee",
        "Joonseop Sim",
        "Taeyoung Ahn",
        "Seungyong Lee",
        "Daegun Yoon",
        "Euiseok Kim",
        "Kyoung Park",
        "Youngpyo Joo",
        "Hosik Kim"
      ],
      "abstract": "The attention layer, a core component of Transformer-based LLMs, brings out\ninefficiencies in current GPU systems due to its low operational intensity and\nthe substantial memory requirements of KV caches. We propose a High-bandwidth\nProcessing Unit (HPU), a memoryintensive co-processor that enhances GPU\nresource utilization during large-batched LLM inference. By offloading\nmemory-bound operations, the HPU allows the GPU to focus on compute-intensive\ntasks, increasing overall efficiency. Also, the HPU, as an add-on card, scales\nout to accommodate surging memory demands driven by large batch sizes and\nextended sequence lengths. In this paper, we show the HPU prototype implemented\nwith PCIe-based FPGA cards mounted on a GPU system. Our novel GPU-HPU\nheterogeneous system demonstrates up to 4.1x performance gains and 4.6x energy\nefficiency improvements over a GPUonly system, providing scalability without\nincreasing the number of GPUs.",
      "tldr_zh": "该研究针对 Transformer-based LLMs 中的 attention layer 效率问题（如低操作强度和 KV caches 的高内存需求），提出了一种 High-Bandwidth Processing Unit (HPU) 协处理器，与 GPU 协同处理以提升大型批量 LLM 推理的效率。HPU 通过卸载内存密集型操作，让 GPU 专注于计算密集任务，并支持扩展以适应大批量和长序列需求，而无需增加 GPU 数量。实验结果显示，使用 PCIe-based FPGA 实现的 HPU 原型，与纯 GPU 系统相比，性能提升高达 4.1 倍，能源效率提升 4.6 倍。",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.CL",
        "cs.DC"
      ],
      "primary_category": "cs.AR",
      "comment": "6 pages",
      "pdf_url": "http://arxiv.org/pdf/2504.16112v1",
      "published_date": "2025-04-18 03:31:08 UTC",
      "updated_date": "2025-04-18 03:31:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:37:49.015309"
    },
    {
      "arxiv_id": "2504.13979v1",
      "title": "Framework, Standards, Applications and Best practices of Responsible AI : A Comprehensive Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Thippa Reddy Gadekallu",
        "Kapal Dev",
        "Sunder Ali Khowaja",
        "Weizheng Wang",
        "Hailin Feng",
        "Kai Fang",
        "Sharnil Pandya",
        "Wei Wang"
      ],
      "abstract": "Responsible Artificial Intelligence (RAI) is a combination of ethics\nassociated with the usage of artificial intelligence aligned with the common\nand standard frameworks. This survey paper extensively discusses the global and\nnational standards, applications of RAI, current technology and ongoing\nprojects using RAI, and possible challenges in implementing and designing RAI\nin the industries and projects based on AI. Currently, ethical standards and\nimplementation of RAI are decoupled which caters each industry to follow their\nown standards to use AI ethically. Many global firms and government\norganizations are taking necessary initiatives to design a common and standard\nframework. Social pressure and unethical way of using AI forces the RAI design\nrather than implementation.",
      "tldr_zh": "这篇调查论文全面探讨了 Responsible AI (RAI) 的框架、标准、应用和最佳实践，强调了 AI 伦理与全球统一框架的整合。论文分析了全球和国家标准、当前技术项目以及 RAI 在各行业的实施挑战，指出现有标准分散导致各行业自行制定规则。最终，它呼吁通过全球机构推动共同框架的设计，以应对社会压力和不道德 AI 使用，促进 RAI 的可靠发展。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "Submitted for peer review",
      "pdf_url": "http://arxiv.org/pdf/2504.13979v1",
      "published_date": "2025-04-18 03:23:52 UTC",
      "updated_date": "2025-04-18 03:23:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:38:00.306998"
    },
    {
      "arxiv_id": "2504.13429v1",
      "title": "Bounded and Uniform Energy-based Out-of-distribution Detection for Graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Shenzhi Yang",
        "Bin Liang",
        "An Liu",
        "Lin Gui",
        "Xingkai Yao",
        "Xiaofang Zhang"
      ],
      "abstract": "Given the critical role of graphs in real-world applications and their\nhigh-security requirements, improving the ability of graph neural networks\n(GNNs) to detect out-of-distribution (OOD) data is an urgent research problem.\nThe recent work GNNSAFE proposes a framework based on the aggregation of\nnegative energy scores that significantly improves the performance of GNNs to\ndetect node-level OOD data. However, our study finds that score aggregation\namong nodes is susceptible to extreme values due to the unboundedness of the\nnegative energy scores and logit shifts, which severely limits the accuracy of\nGNNs in detecting node-level OOD data. In this paper, we propose NODESAFE:\nreducing the generation of extreme scores of nodes by adding two optimization\nterms that make the negative energy scores bounded and mitigate the logit\nshift. Experimental results show that our approach dramatically improves the\nability of GNNs to detect OOD data at the node level, e.g., in detecting OOD\ndata induced by Structure Manipulation, the metric of FPR95 (lower is better)\nin scenarios without (with) OOD data exposure are reduced from the current SOTA\nby 28.4% (22.7%).",
      "tldr_zh": "该研究针对图神经网络 (GNNs) 在节点级 Out-of-Distribution (OOD) 检测中的不足，提出 NODESAFE 方法，以解决现有 GNNSAFE 框架因负能量分数 unbounded 和 logit shifts 导致的极端值问题。NODESAFE 通过添加两个优化项，使负能量分数 bounded 并缓解 logit shift，从而减少极端分数的生成并提升检测性能。实验结果显示，该方法显著改善了 GNNs 的 OOD 检测能力，例如在 Structure Manipulation 诱导的 OOD 数据场景中，FPR95 指标（越低越好）分别降低了 28.4%（无 OOD 数据暴露）和 22.7%（有 OOD 数据暴露）。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "arXiv admin note: text overlap with arXiv:2302.02914 by other authors",
      "pdf_url": "http://arxiv.org/pdf/2504.13429v1",
      "published_date": "2025-04-18 03:01:00 UTC",
      "updated_date": "2025-04-18 03:01:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:38:14.350542"
    },
    {
      "arxiv_id": "2504.13415v1",
      "title": "DADU: Dual Attention-based Deep Supervised UNet for Automated Semantic Segmentation of Cardiac Images",
      "title_zh": "翻译失败",
      "authors": [
        "Racheal Mukisa",
        "Arvind K. Bansal"
      ],
      "abstract": "We propose an enhanced deep learning-based model for image segmentation of\nthe left and right ventricles and myocardium scar tissue from cardiac magnetic\nresonance (CMR) images. The proposed technique integrates UNet, channel and\nspatial attention, edge-detection based skip-connection and deep supervised\nlearning to improve the accuracy of the CMR image-segmentation. Images are\nprocessed using multiple channels to generate multiple feature-maps. We built a\ndual attention-based model to integrate channel and spatial attention. The use\nof extracted edges in skip connection improves the reconstructed images from\nfeature-maps. The use of deep supervision reduces vanishing gradient problems\ninherent in classification based on deep neural networks. The algorithms for\ndual attention-based model, corresponding implementation and performance\nresults are described. The performance results show that this approach has\nattained high accuracy: 98% Dice Similarity Score (DSC) and significantly lower\nHausdorff Distance (HD). The performance results outperform other leading\ntechniques both in DSC and HD.",
      "tldr_zh": "本研究提出了一种名为 DADU 的双注意力深度监督 UNet 模型，用于自动语义分割心脏磁共振 (CMR) 图像中的左心室、右心室和心肌疤痕组织。模型整合了 UNet 架构、通道和空间注意力机制、基于边缘检测的跳跃连接，以及深度监督学习，以提升特征提取和图像重建的准确性，同时缓解深度神经网络中的梯度消失问题。实验结果显示，该方法在 CMR 图像分割上达到了 98% 的 Dice Similarity Score (DSC) 和显著更低的 Hausdorff Distance (HD)，在性能上优于其他领先技术。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "I.4.6; I.2; I.5.2; I.5.1"
      ],
      "primary_category": "eess.IV",
      "comment": "20 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.13415v1",
      "published_date": "2025-04-18 02:22:45 UTC",
      "updated_date": "2025-04-18 02:22:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:38:24.887076"
    },
    {
      "arxiv_id": "2504.13414v2",
      "title": "Adaptive Non-local Observable on Quantum Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Hsin-Yi Lin",
        "Huan-Hsin Tseng",
        "Samuel Yen-Chi Chen",
        "Shinjae Yoo"
      ],
      "abstract": "Conventional Variational Quantum Circuits (VQCs) for Quantum Machine Learning\ntypically rely on a fixed Hermitian observable, often built from Pauli\noperators. Inspired by the Heisenberg picture, we propose an adaptive non-local\nmeasurement framework that substantially increases the model complexity of the\nquantum circuits. Our introduction of dynamical Hermitian observables with\nevolving parameters shows that optimizing VQC rotations corresponds to tracing\na trajectory in the observable space. This viewpoint reveals that standard VQCs\nare merely a special case of the Heisenberg representation.\n  Furthermore, we show that properly incorporating variational rotations with\nnon-local observables enhances qubit interaction and information mixture,\nadmitting flexible circuit designs. Two non-local measurement schemes are\nintroduced, and numerical simulations on classification tasks confirm that our\napproach outperforms conventional VQCs, yielding a more powerful and\nresource-efficient approach as a Quantum Neural Network.",
      "tldr_zh": "本研究提出了一种自适应非局部测量框架，用于提升Quantum Neural Networks中的变分量子电路（VQCs）的模型复杂度。该框架受Heisenberg picture启发，通过引入动态Hermitian observables及其演化参数，将VQCs旋转优化视为observable空间中的轨迹追踪，从而揭示标准VQCs仅为Heisenberg representation的特例。实验结果显示，该方法增强了qubit交互和信息混合，并在分类任务的数值模拟中优于传统VQCs，提供更强大且资源高效的解决方案。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "quant-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.13414v2",
      "published_date": "2025-04-18 02:20:12 UTC",
      "updated_date": "2025-04-26 20:29:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:38:36.106006"
    },
    {
      "arxiv_id": "2504.13407v1",
      "title": "LoRA-Based Continual Learning with Constraints on Critical Parameter Changes",
      "title_zh": "翻译失败",
      "authors": [
        "Shimou Ling",
        "Liang Zhang",
        "Jiangwei Zhao",
        "Lili Pan",
        "Hongliang Li"
      ],
      "abstract": "LoRA-based continual learning represents a promising avenue for leveraging\npre-trained models in downstream continual learning tasks. Recent studies have\nshown that orthogonal LoRA tuning effectively mitigates forgetting. However,\nthis work unveils that under orthogonal LoRA tuning, the critical parameters\nfor pre-tasks still change notably after learning post-tasks. To address this\nproblem, we directly propose freezing the most critical parameter matrices in\nthe Vision Transformer (ViT) for pre-tasks before learning post-tasks. In\naddition, building on orthogonal LoRA tuning, we propose orthogonal LoRA\ncomposition (LoRAC) based on QR decomposition, which may further enhance the\nplasticity of our method. Elaborate ablation studies and extensive comparisons\ndemonstrate the effectiveness of our proposed method. Our results indicate that\nour method achieves state-of-the-art (SOTA) performance on several well-known\ncontinual learning benchmarks. For instance, on the Split CIFAR-100 dataset,\nour method shows a 6.35\\% improvement in accuracy and a 3.24\\% reduction in\nforgetting compared to previous methods. Our code is available at\nhttps://github.com/learninginvision/LoRAC-IPC.",
      "tldr_zh": "本研究针对基于 LoRA 的持续学习（Continual Learning）问题，指出正交 LoRA 调整虽能缓解遗忘，但预任务的关键参数仍会显著变化。为解决此问题，提出冻结 Vision Transformer (ViT) 中预任务的最关键参数矩阵，并引入基于 QR 分解的正交 LoRA 组合 (LoRAC) 方法，以进一步提升模型的可塑性。实验结果显示，该方法在多个基准数据集上达到 state-of-the-art (SOTA) 性能，例如在 Split CIFAR-100 上，准确率提升 6.35%，遗忘率减少 3.24%。这项工作为高效的持续学习框架提供了新途径，并公开了代码以供复现。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.13407v1",
      "published_date": "2025-04-18 02:08:19 UTC",
      "updated_date": "2025-04-18 02:08:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:38:48.730064"
    },
    {
      "arxiv_id": "2504.13406v2",
      "title": "LangCoop: Collaborative Driving with Language",
      "title_zh": "LangCoop: 基于语言的协作驾驶",
      "authors": [
        "Xiangbo Gao",
        "Yuheng Wu",
        "Rujia Wang",
        "Chenxi Liu",
        "Yang Zhou",
        "Zhengzhong Tu"
      ],
      "abstract": "Multi-agent collaboration holds great promise for enhancing the safety,\nreliability, and mobility of autonomous driving systems by enabling information\nsharing among multiple connected agents. However, existing multi-agent\ncommunication approaches are hindered by limitations of existing communication\nmedia, including high bandwidth demands, agent heterogeneity, and information\nloss. To address these challenges, we introduce LangCoop, a new paradigm for\ncollaborative autonomous driving that leverages natural language as a compact\nyet expressive medium for inter-agent communication. LangCoop features two key\ninnovations: Mixture Model Modular Chain-of-thought (M$^3$CoT) for structured\nzero-shot vision-language reasoning and Natural Language Information Packaging\n(LangPack) for efficiently packaging information into concise, language-based\nmessages. Through extensive experiments conducted in the CARLA simulations, we\ndemonstrate that LangCoop achieves a remarkable 96\\% reduction in communication\nbandwidth (< 2KB per message) compared to image-based communication, while\nmaintaining competitive driving performance in the closed-loop evaluation. Our\nproject page and code are at https://xiangbogaobarry.github.io/LangCoop/.",
      "tldr_zh": "该研究提出 LangCoop，一种基于自然语言的多代理协作自动驾驶范式，旨在解决现有通信方法的高带宽需求、代理异构性和信息丢失等问题。LangCoop 的关键创新包括 Mixture Model Modular Chain-of-thought (M³CoT) 用于结构化的零样本视觉-语言推理，以及 Natural Language Information Packaging (LangPack) 用于将信息高效打包成简洁的语言消息。在 CARLA 模拟实验中，LangCoop 相较于图像-based 通信减少了 96% 的带宽（每条消息小于 2KB），同时维持了竞争性的驾驶性能。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.13406v2",
      "published_date": "2025-04-18 02:03:14 UTC",
      "updated_date": "2025-04-21 02:00:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:39:01.246854"
    },
    {
      "arxiv_id": "2504.13399v1",
      "title": "Towards a Multi-Agent Vision-Language System for Zero-Shot Novel Hazardous Object Detection for Autonomous Driving Safety",
      "title_zh": "翻译失败",
      "authors": [
        "Shashank Shriram",
        "Srinivasa Perisetla",
        "Aryan Keskar",
        "Harsha Krishnaswamy",
        "Tonko Emil Westerhof Bossen",
        "Andreas Møgelmose",
        "Ross Greer"
      ],
      "abstract": "Detecting anomalous hazards in visual data, particularly in video streams, is\na critical challenge in autonomous driving. Existing models often struggle with\nunpredictable, out-of-label hazards due to their reliance on predefined object\ncategories. In this paper, we propose a multimodal approach that integrates\nvision-language reasoning with zero-shot object detection to improve hazard\nidentification and explanation. Our pipeline consists of a Vision-Language\nModel (VLM), a Large Language Model (LLM), in order to detect hazardous objects\nwithin a traffic scene. We refine object detection by incorporating OpenAI's\nCLIP model to match predicted hazards with bounding box annotations, improving\nlocalization accuracy. To assess model performance, we create a ground truth\ndataset by denoising and extending the foundational COOOL\n(Challenge-of-Out-of-Label) anomaly detection benchmark dataset with complete\nnatural language descriptions for hazard annotations. We define a means of\nhazard detection and labeling evaluation on the extended dataset using cosine\nsimilarity. This evaluation considers the semantic similarity between the\npredicted hazard description and the annotated ground truth for each video.\nAdditionally, we release a set of tools for structuring and managing\nlarge-scale hazard detection datasets. Our findings highlight the strengths and\nlimitations of current vision-language-based approaches, offering insights into\nfuture improvements in autonomous hazard detection systems. Our models,\nscripts, and data can be found at https://github.com/mi3labucm/COOOLER.git",
      "tldr_zh": "该论文针对自动驾驶中零样本新型危险物检测的挑战，提出一个多代理视觉-语言系统，以处理现有模型对预定义类别依赖的问题。系统整合 Vision-Language Model (VLM) 和 Large Language Model (LLM)，并使用 OpenAI's CLIP 模型来匹配预测的危险物与边界框注释，从而提高定位准确性和解释能力。研究者扩展了 COOOL 数据集，添加自然语言描述，并通过余弦相似度评估预测描述与真实标注的语义相似度。实验结果突出了该方法的优势，同时指出了未来改进方向，并发布了相关工具和代码以支持大规模危险检测数据集的管理。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.13399v1",
      "published_date": "2025-04-18 01:25:02 UTC",
      "updated_date": "2025-04-18 01:25:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:39:13.756475"
    },
    {
      "arxiv_id": "2504.13391v1",
      "title": "Cardiac MRI Semantic Segmentation for Ventricles and Myocardium using Deep Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Racheal Mukisa",
        "Arvind K. Bansal"
      ],
      "abstract": "Automated noninvasive cardiac diagnosis plays a critical role in the early\ndetection of cardiac disorders and cost-effective clinical management.\nAutomated diagnosis involves the automated segmentation and analysis of cardiac\nimages. Precise delineation of cardiac substructures and extraction of their\nmorphological attributes are essential for evaluating the cardiac function, and\ndiagnosing cardiovascular disease such as cardiomyopathy, valvular diseases,\nabnormalities related to septum perforations, and blood-flow rate. Semantic\nsegmentation labels the CMR image at the pixel level, and localizes its\nsubcomponents to facilitate the detection of abnormalities, including\nabnormalities in cardiac wall motion in an aging heart with muscle\nabnormalities, vascular abnormalities, and valvular abnormalities. In this\npaper, we describe a model to improve semantic segmentation of CMR images. The\nmodel extracts edge-attributes and context information during down-sampling of\nthe U-Net and infuses this information during up-sampling to localize three\nmajor cardiac structures: left ventricle cavity (LV); right ventricle cavity\n(RV); and LV myocardium (LMyo). We present an algorithm and performance\nresults. A comparison of our model with previous leading models, using\nsimilarity metrics between actual image and segmented image, shows that our\napproach improves Dice similarity coefficient (DSC) by 2%-11% and lowers\nHausdorff distance (HD) by 1.6 to 5.7 mm.",
      "tldr_zh": "本文提出了一种基于 Deep Learning 的方法，用于心脏 MRI (CMR) 图像的语义分割，旨在精确识别左心室腔 (LV)、右心室腔 (RV) 和 LV 心肌 (LMyo)，以支持心脏疾病诊断如心肌病和瓣膜异常。方法改进了 U-Net 模型，通过在下采样过程中提取边缘属性和上下文信息，并在上采样时注入这些信息，提高了分割的准确性和细节定位。与现有领先模型相比，该方法将 Dice 相似系数 (DSC) 提高了 2%-11%，并将 Hausdorff 距离 (HD) 降低了 1.6 到 5.7 mm。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "I.4.6; I.2; I.5.2; I.5.1"
      ],
      "primary_category": "eess.IV",
      "comment": "20 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.13391v1",
      "published_date": "2025-04-18 00:54:30 UTC",
      "updated_date": "2025-04-18 00:54:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T14:39:27.063944"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 105,
  "processed_papers_count": 105,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-24T14:39:48.623651"
}