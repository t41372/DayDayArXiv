[
  {
    "arxiv_id": "2504.14110v1",
    "title": "System of Agentic AI for the Discovery of Metal-Organic Frameworks",
    "authors": [
      "Theo Jaffrelot Inizan",
      "Sherry Yang",
      "Aaron Kaplan",
      "Yen-hsu Lin",
      "Jian Yin",
      "Saber Mirzaei",
      "Mona Abdelgaid",
      "Ali H. Alawadhi",
      "KwangHwan Cho",
      "Zhiling Zheng",
      "Ekin Dogus Cubuk",
      "Christian Borgs",
      "Jennifer T. Chayes",
      "Kristin A. Persson",
      "Omar M. Yaghi"
    ],
    "abstract": "Generative models and machine learning promise accelerated material discovery\nin MOFs for CO2 capture and water harvesting but face significant challenges\nnavigating vast chemical spaces while ensuring synthetizability. Here, we\npresent MOFGen, a system of Agentic AI comprising interconnected agents: a\nlarge language model that proposes novel MOF compositions, a diffusion model\nthat generates crystal structures, quantum mechanical agents that optimize and\nfilter candidates, and synthetic-feasibility agents guided by expert rules and\nmachine learning. Trained on all experimentally reported MOFs and computational\ndatabases, MOFGen generated hundreds of thousands of novel MOF structures and\nsynthesizable organic linkers. Our methodology was validated through\nhigh-throughput experiments and the successful synthesis of five \"AI-dreamt\"\nMOFs, representing a major step toward automated synthesizable material\ndiscovery.",
    "categories": [
      "cond-mat.mtrl-sci",
      "cs.AI",
      "cs.CL",
      "cs.MA"
    ],
    "primary_category": "cond-mat.mtrl-sci",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.14110v1",
    "published_date": "2025-04-18 23:54:25 UTC",
    "updated_date": "2025-04-18 23:54:25 UTC"
  },
  {
    "arxiv_id": "2504.16118v1",
    "title": "Towards Explainable and Lightweight AI for Real-Time Cyber Threat Hunting in Edge Networks",
    "authors": [
      "Milad Rahmati"
    ],
    "abstract": "As cyber threats continue to evolve, securing edge networks has become\nincreasingly challenging due to their distributed nature and resource\nlimitations. Many AI-driven threat detection systems rely on complex deep\nlearning models, which, despite their high accuracy, suffer from two major\ndrawbacks: lack of interpretability and high computational cost. Black-box AI\nmodels make it difficult for security analysts to understand the reasoning\nbehind their predictions, limiting their practical deployment. Moreover,\nconventional deep learning techniques demand significant computational\nresources, rendering them unsuitable for edge devices with limited processing\npower. To address these issues, this study introduces an Explainable and\nLightweight AI (ELAI) framework designed for real-time cyber threat detection\nin edge networks. Our approach integrates interpretable machine learning\nalgorithms with optimized lightweight deep learning techniques, ensuring both\ntransparency and computational efficiency. The proposed system leverages\ndecision trees, attention-based deep learning, and federated learning to\nenhance detection accuracy while maintaining explainability. We evaluate ELAI\nusing benchmark cybersecurity datasets, such as CICIDS and UNSW-NB15, assessing\nits performance across diverse cyberattack scenarios. Experimental results\ndemonstrate that the proposed framework achieves high detection rates with\nminimal false positives, all while significantly reducing computational demands\ncompared to traditional deep learning methods. The key contributions of this\nwork include: (1) a novel interpretable AI-based cybersecurity model tailored\nfor edge computing environments, (2) an optimized lightweight deep learning\napproach for real-time cyber threat detection, and (3) a comprehensive analysis\nof explainability techniques in AI-driven cybersecurity applications.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16118v1",
    "published_date": "2025-04-18 23:45:39 UTC",
    "updated_date": "2025-04-18 23:45:39 UTC"
  },
  {
    "arxiv_id": "2504.14107v2",
    "title": "Signatures of human-like processing in Transformer forward passes",
    "authors": [
      "Jennifer Hu",
      "Michael A. Lepori",
      "Michael Franke"
    ],
    "abstract": "Modern AI models are increasingly being used as theoretical tools to study\nhuman cognition. One dominant approach is to evaluate whether human-derived\nmeasures are predicted by a model's output: that is, the end-product of a\nforward pass. However, recent advances in mechanistic interpretability have\nbegun to reveal the internal processes that give rise to model outputs, raising\nthe question of whether models might use human-like processing strategies.\nHere, we investigate the relationship between real-time processing in humans\nand layer-time dynamics of computation in Transformers, testing 20 open-source\nmodels in 6 domains. We first explore whether forward passes show mechanistic\nsignatures of competitor interference, taking high-level inspiration from\ncognitive theories. We find that models indeed appear to initially favor a\ncompeting incorrect answer in the cases where we would expect decision conflict\nin humans. We then systematically test whether forward-pass dynamics predict\nsignatures of processing in humans, above and beyond properties of the model's\noutput probability distribution. We find that dynamic measures improve\nprediction of human processing measures relative to static final-layer\nmeasures. Moreover, across our experiments, larger models do not always show\nmore human-like processing patterns. Our work suggests a new way of using AI\nmodels to study human cognition: not just as a black box mapping stimuli to\nresponses, but potentially also as explicit processing models.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "under review",
    "pdf_url": "http://arxiv.org/pdf/2504.14107v2",
    "published_date": "2025-04-18 23:38:14 UTC",
    "updated_date": "2025-05-18 17:27:52 UTC"
  },
  {
    "arxiv_id": "2504.14105v1",
    "title": "Amplify Initiative: Building A Localized Data Platform for Globalized AI",
    "authors": [
      "Qazi Mamunur Rashid",
      "Erin van Liemt",
      "Tiffany Shih",
      "Amber Ebinama",
      "Karla Barrios Ramos",
      "Madhurima Maji",
      "Aishwarya Verma",
      "Charu Kalia",
      "Jamila Smith-Loud",
      "Joyce Nakatumba-Nabende",
      "Rehema Baguma",
      "Andrew Katumba",
      "Chodrine Mutebi",
      "Jagen Marvin",
      "Eric Peter Wairagala",
      "Mugizi Bruce",
      "Peter Oketta",
      "Lawrence Nderu",
      "Obichi Obiajunwa",
      "Abigail Oppong",
      "Michael Zimba",
      "Data Authors"
    ],
    "abstract": "Current AI models often fail to account for local context and language, given\nthe predominance of English and Western internet content in their training\ndata. This hinders the global relevance, usefulness, and safety of these models\nas they gain more users around the globe. Amplify Initiative, a data platform\nand methodology, leverages expert communities to collect diverse, high-quality\ndata to address the limitations of these models. The platform is designed to\nenable co-creation of datasets, provide access to high-quality multilingual\ndatasets, and offer recognition to data authors. This paper presents the\napproach to co-creating datasets with domain experts (e.g., health workers,\nteachers) through a pilot conducted in Sub-Saharan Africa (Ghana, Kenya,\nMalawi, Nigeria, and Uganda). In partnership with local researchers situated in\nthese countries, the pilot demonstrated an end-to-end approach to co-creating\ndata with 155 experts in sensitive domains (e.g., physicians, bankers,\nanthropologists, human and civil rights advocates). This approach, implemented\nwith an Android app, resulted in an annotated dataset of 8,091 adversarial\nqueries in seven languages (e.g., Luganda, Swahili, Chichewa), capturing\nnuanced and contextual information related to key themes such as misinformation\nand public interest topics. This dataset in turn can be used to evaluate models\nfor their safety and cultural relevance within the context of these languages.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.14105v1",
    "published_date": "2025-04-18 23:20:52 UTC",
    "updated_date": "2025-04-18 23:20:52 UTC"
  },
  {
    "arxiv_id": "2504.14103v1",
    "title": "Coordinating Spinal and Limb Dynamics for Enhanced Sprawling Robot Mobility",
    "authors": [
      "Merve Atasever",
      "Ali Okhovat",
      "Azhang Nazaripouya",
      "John Nisbet",
      "Omer Kurkutlu",
      "Jyotirmoy V. Deshmukh",
      "Yasemin Ozkan Aydin"
    ],
    "abstract": "Among vertebrates, salamanders, with their unique ability to transition\nbetween walking and swimming gaits, highlight the role of spinal mobility in\nlocomotion. A flexible spine enables undulation of the body through a wavelike\nmotion along the spine, aiding navigation over uneven terrains and obstacles.\nYet environmental uncertainties, such as surface irregularities and variations\nin friction, can significantly disrupt body-limb coordination and cause\ndiscrepancies between predictions from mathematical models and real-world\noutcomes. Addressing this challenge requires the development of sophisticated\ncontrol strategies capable of dynamically adapting to uncertain conditions\nwhile maintaining efficient locomotion. Deep reinforcement learning (DRL)\noffers a promising framework for handling non-deterministic environments and\nenabling robotic systems to adapt effectively and perform robustly under\nchallenging conditions. In this study, we comparatively examine learning-based\ncontrol strategies and biologically inspired gait design methods on a\nsalamander-like robot.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "The manuscript has been accepted for presentation at the Mechanical\n  Intelligence in Robotics workshop at ICRA 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.14103v1",
    "published_date": "2025-04-18 23:08:48 UTC",
    "updated_date": "2025-04-18 23:08:48 UTC"
  },
  {
    "arxiv_id": "2504.14100v1",
    "title": "6G WavesFM: A Foundation Model for Sensing, Communication, and Localization",
    "authors": [
      "Ahmed Aboulfotouh",
      "Elsayed Mohammed",
      "Hatem Abou-Zeid"
    ],
    "abstract": "This paper introduces WavesFM, a novel Wireless Foundation Model (WFM)\nframework, capable of supporting a wide array of communication, sensing, and\nlocalization tasks. Our proposed architecture combines a shared Vision\nTransformer (ViT) backbone with task-specific multi-layer perceptron (MLP)\nheads and incorporates Low-Rank Adaptation (LoRA) for parameter-efficient\nfine-tuning. This design promotes full parameter sharing across tasks,\nsignificantly reducing the computational and memory footprint without\nsacrificing performance. The model processes both image-like wireless\nmodalities, such as spectrograms and channel state information (CSI), and\nin-phase and quadrature (IQ) signals arranged as orthogonal frequency-division\nmultiplexing (OFDM) resource grids. We demonstrate the strong generalization\ncapabilities of WavesFM through extensive experiments on four downstream tasks:\nFifth Generation New Radio (5G NR) positioning; multiple-input multiple-output\nOFDM (MIMO-OFDM) channel estimation; human activity sensing; and\nradio-frequency (RF) signal classification. Compared to supervised baselines\ntrained individually, our approach achieves superior performance while sharing\n80% of its parameters across tasks. Furthermore, we show that pretraining on\ndomain-relevant data not only boosts performance but also accelerates\nconvergence, reducing training time by up to 5x. These results demonstrate that\nour unified WFM can support diverse tasks and deliver significant gains in both\nperformance and efficiency, highlighting the transformative potential of\nfoundation models to drive AI-native paradigms in future sixth-generation (6G)\nnetworks.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.14100v1",
    "published_date": "2025-04-18 22:51:35 UTC",
    "updated_date": "2025-04-18 22:51:35 UTC"
  },
  {
    "arxiv_id": "2504.14098v1",
    "title": "Enhancing Math Learning in an LMS Using AI-Driven Question Recommendations",
    "authors": [
      "Justus Råmunddal"
    ],
    "abstract": "This paper presents an AI-driven approach to enhance math learning in a\nmodern Learning Management System (LMS) by recommending similar math questions.\nDeep embeddings for math questions are generated using Meta's\nLlama-3.2-11B-Vision-Instruct model, and three recommendation methods-cosine\nsimilarity, Self-Organizing Maps (SOM), and Gaussian Mixture Models (GMM)-are\napplied to identify similar questions. User interaction data, including session\ndurations, response times, and correctness, are used to evaluate the methods.\nOur findings suggest that while cosine similarity produces nearly identical\nquestion matches, SOM yields higher user satisfaction whereas GMM generally\nunderperforms, indicating that introducing variety to a certain degree may\nenhance engagement and thereby potential learning outcomes until variety is no\nlonger balanced reasonably, which our data about the implementations of all\nthree methods demonstrate.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY",
      "cs.IR"
    ],
    "primary_category": "cs.LG",
    "comment": "15 pages, 9 figures, 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2504.14098v1",
    "published_date": "2025-04-18 22:48:26 UTC",
    "updated_date": "2025-04-18 22:48:26 UTC"
  },
  {
    "arxiv_id": "2504.14094v2",
    "title": "Leakage and Interpretability in Concept-Based Models",
    "authors": [
      "Enrico Parisini",
      "Tapabrata Chakraborti",
      "Chris Harbron",
      "Ben D. MacArthur",
      "Christopher R. S. Banerji"
    ],
    "abstract": "Concept Bottleneck Models aim to improve interpretability by predicting\nhigh-level intermediate concepts, representing a promising approach for\ndeployment in high-risk scenarios. However, they are known to suffer from\ninformation leakage, whereby models exploit unintended information encoded\nwithin the learned concepts. We introduce an information-theoretic framework to\nrigorously characterise and quantify leakage, and define two complementary\nmeasures: the concepts-task leakage (CTL) and interconcept leakage (ICL)\nscores. We show that these measures are strongly predictive of model behaviour\nunder interventions and outperform existing alternatives in robustness and\nreliability. Using this framework, we identify the primary causes of leakage\nand provide strong evidence that Concept Embedding Models exhibit substantial\nleakage regardless of the hyperparameters choice. Finally, we propose practical\nguidelines for designing concept-based models to reduce leakage and ensure\ninterpretability.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "35 pages, 24 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.14094v2",
    "published_date": "2025-04-18 22:21:06 UTC",
    "updated_date": "2025-05-19 14:09:26 UTC"
  },
  {
    "arxiv_id": "2504.14089v1",
    "title": "LogicTree: Structured Proof Exploration for Coherent and Rigorous Logical Reasoning with Large Language Models",
    "authors": [
      "Kang He",
      "Kaushik Roy"
    ],
    "abstract": "Large language models (LLMs) have achieved remarkable multi-step reasoning\ncapabilities across various domains. However, LLMs still face distinct\nchallenges in complex logical reasoning, as (1) proof-finding requires\nsystematic exploration and the maintenance of logical coherence and (2)\nsearching the right combination of premises at each reasoning step is\ninherently challenging in tasks with large premise space. To address this, we\npropose LogicTree, an inference-time modular framework employing\nalgorithm-guided search to automate structured proof exploration and ensure\nlogical coherence. Advancing beyond tree-of-thought (ToT), we incorporate\ncaching mechanism into LogicTree to enable effective utilization of historical\nknowledge, preventing reasoning stagnation and minimizing redundancy.\nFurthermore, we address the combinatorial complexity of premise search by\ndecomposing it into a linear process. The refined premise selection restricts\nsubsequent inference to at most one derivation per step, enhancing reasoning\ngranularity and enforcing strict step-by-step reasoning. Additionally, we\nintroduce two LLM-free heuristics for premise prioritization, enabling\nstrategic proof search. Experimental results on five datasets demonstrate that\nLogicTree optimally scales inference-time computation to achieve higher proof\naccuracy, surpassing chain-of-thought (CoT) and ToT with average gains of 23.6%\nand 12.5%, respectively, on GPT-4o. Moreover, within LogicTree, GPT-4o\noutperforms o3-mini by 7.6% on average.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.14089v1",
    "published_date": "2025-04-18 22:10:02 UTC",
    "updated_date": "2025-04-18 22:10:02 UTC"
  },
  {
    "arxiv_id": "2504.14071v1",
    "title": "Evaluating Human-AI Interaction via Usability, User Experience and Acceptance Measures for MMM-C: A Creative AI System for Music Composition",
    "authors": [
      "Renaud Bougueng Tchemeube",
      "Jeff Ens",
      "Cale Plut",
      "Philippe Pasquier",
      "Maryam Safi",
      "Yvan Grabit",
      "Jean-Baptiste Rolland"
    ],
    "abstract": "With the rise of artificial intelligence (AI), there has been increasing\ninterest in human-AI co-creation in a variety of artistic domains including\nmusic as AI-driven systems are frequently able to generate human-competitive\nartifacts. Now, the implications of such systems for musical practice are being\ninvestigated. We report on a thorough evaluation of the user adoption of the\nMulti-Track Music Machine (MMM) as a co-creative AI tool for music composers.\nTo do this, we integrate MMM into Cubase, a popular Digital Audio Workstation\n(DAW) by Steinberg, by producing a \"1-parameter\" plugin interface named\nMMM-Cubase (MMM-C), which enables human-AI co-composition. We contribute a\nmethodological assemblage as a 3-part mixed method study measuring usability,\nuser experience and technology acceptance of the system across two groups of\nexpert-level composers: hobbyists and professionals. Results show positive\nusability and acceptance scores. Users report experiences of novelty, surprise\nand ease of use from using the system, and limitations on controllability and\npredictability of the interface when generating music. Findings indicate no\nsignificant difference between the two user groups.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.LG",
      "cs.SD"
    ],
    "primary_category": "cs.HC",
    "comment": "10 pages, 6 figures, 1 table, first published at the 32nd\n  International Joint Conference on Artificial Intelligence (IJCAI 2023),\n  Macao, China",
    "pdf_url": "http://arxiv.org/pdf/2504.14071v1",
    "published_date": "2025-04-18 20:41:02 UTC",
    "updated_date": "2025-04-18 20:41:02 UTC"
  },
  {
    "arxiv_id": "2504.14070v3",
    "title": "A CMOS Probabilistic Computing Chip With In-situ hardware Aware Learning",
    "authors": [
      "Jinesh Jhonsa",
      "William Whitehead",
      "David McCarthy",
      "Shuvro Chowdhury",
      "Kerem Camsari",
      "Luke Theogarajan"
    ],
    "abstract": "This paper demonstrates a probabilistic bit physics inspired solver with 440\nspins configured in a Chimera graph, occupying an area of 0.44 mm^2. Area\nefficiency is maximized through a current-mode implementation of the neuron\nupdate circuit, standard cell design for analog blocks pitch-matched to digital\nblocks, and a shared power supply for both digital and analog components.\nProcess variation related mismatches introduced by this approach are\neffectively mitigated using a hardware aware contrastive divergence algorithm\nduring training. We validate the chip's ability to perform probabilistic\ncomputing tasks such as modeling logic gates and full adders, as well as\noptimization tasks such as MaxCut, demonstrating its potential for AI and\nmachine learning applications.",
    "categories": [
      "cs.AR",
      "cs.AI"
    ],
    "primary_category": "cs.AR",
    "comment": "3 pages 12 figuewa",
    "pdf_url": "http://arxiv.org/pdf/2504.14070v3",
    "published_date": "2025-04-18 20:40:48 UTC",
    "updated_date": "2025-04-30 05:38:53 UTC"
  },
  {
    "arxiv_id": "2504.14054v1",
    "title": "Occlusion-Ordered Semantic Instance Segmentation",
    "authors": [
      "Soroosh Baselizadeh",
      "Cheuk-To Yu",
      "Olga Veksler",
      "Yuri Boykov"
    ],
    "abstract": "Standard semantic instance segmentation provides useful, but inherently 2D\ninformation from a single image. To enable 3D analysis, one usually integrates\nabsolute monocular depth estimation with instance segmentation. However,\nmonocular depth is a difficult task. Instead, we leverage a simpler\nsingle-image task, occlusion-based relative depth ordering, providing coarser\nbut useful 3D information. We show that relative depth ordering works more\nreliably from occlusions than from absolute depth. We propose to solve the\njoint task of relative depth ordering and segmentation of instances based on\nocclusions. We call this task Occlusion-Ordered Semantic Instance Segmentation\n(OOSIS). We develop an approach to OOSIS that extracts instances and their\nocclusion order simultaneously from oriented occlusion boundaries and semantic\nsegmentation. Unlike popular detect-and-segment framework for instance\nsegmentation, combining occlusion ordering with instance segmentation allows a\nsimple and clean formulation of OOSIS as a labeling problem. As a part of our\nsolution for OOSIS, we develop a novel oriented occlusion boundaries approach\nthat significantly outperforms prior work. We also develop a new joint OOSIS\nmetric based both on instance mask accuracy and correctness of their occlusion\norder. We achieve better performance than strong baselines on KINS and COCOA\ndatasets.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.14054v1",
    "published_date": "2025-04-18 19:52:37 UTC",
    "updated_date": "2025-04-18 19:52:37 UTC"
  },
  {
    "arxiv_id": "2504.14053v1",
    "title": "Sentiment Analysis of Airbnb Reviews: Exploring Their Impact on Acceptance Rates and Pricing Across Multiple U.S. Regions",
    "authors": [
      "Ali Safari"
    ],
    "abstract": "This research examines whether Airbnb guests' positive and negative comments\ninfluence acceptance rates and rental prices across six U.S. regions: Rhode\nIsland, Broward County, Chicago, Dallas, San Diego, and Boston. Thousands of\nreviews were collected and analyzed using Natural Language Processing (NLP) to\nclassify sentiments as positive or negative, followed by statistical testing\n(t-tests and basic correlations) on the average scores. The findings reveal\nthat over 90 percent of reviews in each region are positive, indicating that\nhaving additional reviews does not significantly enhance prices. However,\nlistings with predominantly positive feedback exhibit slightly higher\nacceptance rates, suggesting that sentiment polarity, rather than the sheer\nvolume of reviews, is a more critical factor for host success. Additionally,\nbudget listings often gather extensive reviews while maintaining competitive\npricing, whereas premium listings sustain higher prices with fewer but highly\npositive reviews. These results underscore the importance of sentiment quality\nover quantity in shaping guest behavior and pricing strategies in an\noverwhelmingly positive review environment.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.14053v1",
    "published_date": "2025-04-18 19:52:24 UTC",
    "updated_date": "2025-04-18 19:52:24 UTC"
  },
  {
    "arxiv_id": "2504.14047v1",
    "title": "Think Deep, Think Fast: Investigating Efficiency of Verifier-free Inference-time-scaling Methods",
    "authors": [
      "Junlin Wang",
      "Shang Zhu",
      "Jon Saad-Falcon",
      "Ben Athiwaratkun",
      "Qingyang Wu",
      "Jue Wang",
      "Shuaiwen Leon Song",
      "Ce Zhang",
      "Bhuwan Dhingra",
      "James Zou"
    ],
    "abstract": "There is intense interest in investigating how inference time compute (ITC)\n(e.g. repeated sampling, refinements, etc) can improve large language model\n(LLM) capabilities. At the same time, recent breakthroughs in reasoning models,\nsuch as Deepseek-R1, unlock the opportunity for reinforcement learning to\nimprove LLM reasoning skills. An in-depth understanding of how ITC interacts\nwith reasoning across different models could provide important guidance on how\nto further advance the LLM frontier. This work conducts a comprehensive\nanalysis of inference-time scaling methods for both reasoning and non-reasoning\nmodels on challenging reasoning tasks. Specifically, we focus our research on\nverifier-free inference time-scaling methods due to its generalizability\nwithout needing a reward model. We construct the Pareto frontier of quality and\nefficiency. We find that non-reasoning models, even with an extremely high\ninference budget, still fall substantially behind reasoning models. For\nreasoning models, majority voting proves to be a robust inference strategy,\ngenerally competitive or outperforming other more sophisticated ITC methods\nlike best-of-N and sequential revisions, while the additional inference compute\noffers minimal improvements. We further perform in-depth analyses of the\nassociation of key response features (length and linguistic markers) with\nresponse quality, with which we can improve the existing ITC methods. We find\nthat correct responses from reasoning models are typically shorter and have\nfewer hedging and thinking markers (but more discourse markers) than the\nincorrect responses.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.14047v1",
    "published_date": "2025-04-18 19:32:55 UTC",
    "updated_date": "2025-04-18 19:32:55 UTC"
  },
  {
    "arxiv_id": "2504.14046v1",
    "title": "A synthetic dataset of French electric load curves with temperature conditioning",
    "authors": [
      "Tahar Nabil",
      "Ghislain Agoua",
      "Pierre Cauchois",
      "Anne De Moliner",
      "Benoît Grossin"
    ],
    "abstract": "The undergoing energy transition is causing behavioral changes in electricity\nuse, e.g. with self-consumption of local generation, or flexibility services\nfor demand control. To better understand these changes and the challenges they\ninduce, accessing individual smart meter data is crucial. Yet this is personal\ndata under the European GDPR. A widespread use of such data requires thus to\ncreate synthetic realistic and privacy-preserving samples. This paper\nintroduces a new synthetic load curve dataset generated by conditional latent\ndiffusion. We also provide the contracted power, time-of-use plan and local\ntemperature used for generation. Fidelity, utility and privacy of the dataset\nare thoroughly evaluated, demonstrating its good quality and thereby supporting\nits interest for energy modeling applications.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Workshop paper at \"Tackling Climate Change with Machine Learning\",\n  ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.14046v1",
    "published_date": "2025-04-18 19:28:49 UTC",
    "updated_date": "2025-04-18 19:28:49 UTC"
  },
  {
    "arxiv_id": "2504.14044v1",
    "title": "Multi-Stage Retrieval for Operational Technology Cybersecurity Compliance Using Large Language Models: A Railway Casestudy",
    "authors": [
      "Regan Bolton",
      "Mohammadreza Sheikhfathollahi",
      "Simon Parkinson",
      "Dan Basher",
      "Howard Parkinson"
    ],
    "abstract": "Operational Technology Cybersecurity (OTCS) continues to be a dominant\nchallenge for critical infrastructure such as railways. As these systems become\nincreasingly vulnerable to malicious attacks due to digitalization, effective\ndocumentation and compliance processes are essential to protect these\nsafety-critical systems. This paper proposes a novel system that leverages\nLarge Language Models (LLMs) and multi-stage retrieval to enhance the\ncompliance verification process against standards like IEC 62443 and the\nrail-specific IEC 63452. We first evaluate a Baseline Compliance Architecture\n(BCA) for answering OTCS compliance queries, then develop an extended approach\ncalled Parallel Compliance Architecture (PCA) that incorporates additional\ncontext from regulatory standards. Through empirical evaluation comparing\nOpenAI-gpt-4o and Claude-3.5-haiku models in these architectures, we\ndemonstrate that the PCA significantly improves both correctness and reasoning\nquality in compliance verification. Our research establishes metrics for\nresponse correctness, logical reasoning, and hallucination detection,\nhighlighting the strengths and limitations of using LLMs for compliance\nverification in railway cybersecurity. The results suggest that\nretrieval-augmented approaches can significantly improve the efficiency and\naccuracy of compliance assessments, particularly valuable in an industry facing\na shortage of cybersecurity expertise.",
    "categories": [
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.14044v1",
    "published_date": "2025-04-18 19:24:17 UTC",
    "updated_date": "2025-04-18 19:24:17 UTC"
  },
  {
    "arxiv_id": "2504.14045v1",
    "title": "Metacognition and Uncertainty Communication in Humans and Large Language Models",
    "authors": [
      "Mark Steyvers",
      "Megan A. K. Peters"
    ],
    "abstract": "Metacognition, the capacity to monitor and evaluate one's own knowledge and\nperformance, is foundational to human decision-making, learning, and\ncommunication. As large language models (LLMs) become increasingly embedded in\nhigh-stakes decision contexts, it is critical to assess whether, how, and to\nwhat extent they exhibit metacognitive abilities. Here, we provide an overview\nof current knowledge of LLMs' metacognitive capacities, how they might be\nstudied, and how they relate to our knowledge of metacognition in humans. We\nshow that while humans and LLMs can sometimes appear quite aligned in their\nmetacognitive capacities and behaviors, it is clear many differences remain.\nAttending to these differences is crucial not only for enhancing human-AI\ncollaboration, but also for promoting the development of more capable and\ntrustworthy artificial systems. Finally, we discuss how endowing future LLMs\nwith more sensitive and more calibrated metacognition may also help them\ndevelop new capacities such as more efficient learning, self-direction, and\ncuriosity.",
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.14045v1",
    "published_date": "2025-04-18 19:24:17 UTC",
    "updated_date": "2025-04-18 19:24:17 UTC"
  },
  {
    "arxiv_id": "2504.14039v1",
    "title": "MEQA: A Meta-Evaluation Framework for Question & Answer LLM Benchmarks",
    "authors": [
      "Jaime Raldua Veuthey",
      "Zainab Ali Majid",
      "Suhas Hariharan",
      "Jacob Haimes"
    ],
    "abstract": "As Large Language Models (LLMs) advance, their potential for widespread\nsocietal impact grows simultaneously. Hence, rigorous LLM evaluations are both\na technical necessity and social imperative. While numerous evaluation\nbenchmarks have been developed, there remains a critical gap in\nmeta-evaluation: effectively assessing benchmarks' quality. We propose MEQA, a\nframework for the meta-evaluation of question and answer (QA) benchmarks, to\nprovide standardized assessments, quantifiable scores, and enable meaningful\nintra-benchmark comparisons. We demonstrate this approach on cybersecurity\nbenchmarks, using human and LLM evaluators, highlighting the benchmarks'\nstrengths and weaknesses. We motivate our choice of test domain by AI models'\ndual nature as powerful defensive tools and security threats.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.14039v1",
    "published_date": "2025-04-18 19:01:53 UTC",
    "updated_date": "2025-04-18 19:01:53 UTC"
  },
  {
    "arxiv_id": "2504.14038v1",
    "title": "Flowco: Rethinking Data Analysis in the Age of LLMs",
    "authors": [
      "Stephen N. Freund",
      "Brooke Simon",
      "Emery D. Berger",
      "Eunice Jun"
    ],
    "abstract": "Conducting data analysis typically involves authoring code to transform,\nvisualize, analyze, and interpret data. Large language models (LLMs) are now\ncapable of generating such code for simple, routine analyses. LLMs promise to\ndemocratize data science by enabling those with limited programming expertise\nto conduct data analyses, including in scientific research, business, and\npolicymaking. However, analysts in many real-world settings must often exercise\nfine-grained control over specific analysis steps, verify intermediate results\nexplicitly, and iteratively refine their analytical approaches. Such tasks\npresent barriers to building robust and reproducible analyses using LLMs alone\nor even in conjunction with existing authoring tools (e.g., computational\nnotebooks). This paper introduces Flowco, a new mixed-initiative system to\naddress these challenges. Flowco leverages a visual dataflow programming model\nand integrates LLMs into every phase of the authoring process. A user study\nsuggests that Flowco supports analysts, particularly those with less\nprogramming experience, in quickly authoring, debugging, and refining data\nanalyses.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.PL",
      "stat.CO"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.14038v1",
    "published_date": "2025-04-18 19:01:27 UTC",
    "updated_date": "2025-04-18 19:01:27 UTC"
  },
  {
    "arxiv_id": "2504.14032v1",
    "title": "LoftUp: Learning a Coordinate-Based Feature Upsampler for Vision Foundation Models",
    "authors": [
      "Haiwen Huang",
      "Anpei Chen",
      "Volodymyr Havrylov",
      "Andreas Geiger",
      "Dan Zhang"
    ],
    "abstract": "Vision foundation models (VFMs) such as DINOv2 and CLIP have achieved\nimpressive results on various downstream tasks, but their limited feature\nresolution hampers performance in applications requiring pixel-level\nunderstanding. Feature upsampling offers a promising direction to address this\nchallenge. In this work, we identify two critical factors for enhancing feature\nupsampling: the upsampler architecture and the training objective. For the\nupsampler architecture, we introduce a coordinate-based cross-attention\ntransformer that integrates the high-resolution images with coordinates and\nlow-resolution VFM features to generate sharp, high-quality features. For the\ntraining objective, we propose constructing high-resolution pseudo-groundtruth\nfeatures by leveraging class-agnostic masks and self-distillation. Our approach\neffectively captures fine-grained details and adapts flexibly to various input\nand feature resolutions. Through experiments, we demonstrate that our approach\nsignificantly outperforms existing feature upsampling techniques across various\ndownstream tasks. Our code is released at https://github.com/andrehuang/loftup.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.14032v1",
    "published_date": "2025-04-18 18:46:08 UTC",
    "updated_date": "2025-04-18 18:46:08 UTC"
  },
  {
    "arxiv_id": "2504.14015v1",
    "title": "Causal pieces: analysing and improving spiking neural networks piece by piece",
    "authors": [
      "Dominik Dold",
      "Philipp Christian Petersen"
    ],
    "abstract": "We introduce a novel concept for spiking neural networks (SNNs) derived from\nthe idea of \"linear pieces\" used to analyse the expressiveness and trainability\nof artificial neural networks (ANNs). We prove that the input domain of SNNs\ndecomposes into distinct causal regions where its output spike times are\nlocally Lipschitz continuous with respect to the input spike times and network\nparameters. The number of such regions - which we call \"causal pieces\" - is a\nmeasure of the approximation capabilities of SNNs. In particular, we\ndemonstrate in simulation that parameter initialisations which yield a high\nnumber of causal pieces on the training set strongly correlate with SNN\ntraining success. Moreover, we find that feedforward SNNs with purely positive\nweights exhibit a surprisingly high number of causal pieces, allowing them to\nachieve competitive performance levels on benchmark tasks. We believe that\ncausal pieces are not only a powerful and principled tool for improving SNNs,\nbut might also open up new ways of comparing SNNs and ANNs in the future.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG",
      "q-bio.NC",
      "stat.ML"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.14015v1",
    "published_date": "2025-04-18 18:07:33 UTC",
    "updated_date": "2025-04-18 18:07:33 UTC"
  },
  {
    "arxiv_id": "2504.14011v1",
    "title": "Fashion-RAG: Multimodal Fashion Image Editing via Retrieval-Augmented Generation",
    "authors": [
      "Fulvio Sanguigni",
      "Davide Morelli",
      "Marcella Cornia",
      "Rita Cucchiara"
    ],
    "abstract": "In recent years, the fashion industry has increasingly adopted AI\ntechnologies to enhance customer experience, driven by the proliferation of\ne-commerce platforms and virtual applications. Among the various tasks, virtual\ntry-on and multimodal fashion image editing -- which utilizes diverse input\nmodalities such as text, garment sketches, and body poses -- have become a key\narea of research. Diffusion models have emerged as a leading approach for such\ngenerative tasks, offering superior image quality and diversity. However, most\nexisting virtual try-on methods rely on having a specific garment input, which\nis often impractical in real-world scenarios where users may only provide\ntextual specifications. To address this limitation, in this work we introduce\nFashion Retrieval-Augmented Generation (Fashion-RAG), a novel method that\nenables the customization of fashion items based on user preferences provided\nin textual form. Our approach retrieves multiple garments that match the input\nspecifications and generates a personalized image by incorporating attributes\nfrom the retrieved items. To achieve this, we employ textual inversion\ntechniques, where retrieved garment images are projected into the textual\nembedding space of the Stable Diffusion text encoder, allowing seamless\nintegration of retrieved elements into the generative process. Experimental\nresults on the Dress Code dataset demonstrate that Fashion-RAG outperforms\nexisting methods both qualitatively and quantitatively, effectively capturing\nfine-grained visual details from retrieved garments. To the best of our\nknowledge, this is the first work to introduce a retrieval-augmented generation\napproach specifically tailored for multimodal fashion image editing.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "IJCNN 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.14011v1",
    "published_date": "2025-04-18 18:02:33 UTC",
    "updated_date": "2025-04-18 18:02:33 UTC"
  },
  {
    "arxiv_id": "2504.13837v2",
    "title": "Does Reinforcement Learning Really Incentivize Reasoning Capacity in LLMs Beyond the Base Model?",
    "authors": [
      "Yang Yue",
      "Zhiqi Chen",
      "Rui Lu",
      "Andrew Zhao",
      "Zhaokai Wang",
      "Yang Yue",
      "Shiji Song",
      "Gao Huang"
    ],
    "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) has recently\ndemonstrated notable success in enhancing the reasoning performance of large\nlanguage models (LLMs), particularly on mathematics and programming tasks.\nSimilar to how traditional RL helps agents explore and learn new strategies,\nRLVR is believed to enable LLMs to continuously self-improve, thus acquiring\nnovel reasoning abilities beyond those of the corresponding base models. In\nthis study we critically examine the current state of RLVR by systematically\nprobing the reasoning capability boundaries of RLVR-trained LLMs across various\nmodel families, RL algorithms, and math, coding, and visual reasoning\nbenchmarks, using pass@k at large k values as the evaluation metric.\nSurprisingly, we find that the current training setup does not elicit\nfundamentally new reasoning patterns. While RLVR-trained models outperform\ntheir base models at small k (e.g., k = 1), the base models achieve a higher\npass@k score when k is large. Coverage and perplexity analyses show that the\nobserved reasoning abilities originate from and are bounded by the base model.\nTreating the base model as an upper bound, our quantitative analysis shows that\nsix popular RLVR algorithms perform similarly and remain far from optimal in\nleveraging the potential of the base model. By contrast, we find that\ndistillation can introduce new reasoning patterns from the teacher and\ngenuinely expand the model's reasoning capabilities. Overall, our findings\nsuggest that current RLVR methods have not yet realized the potential of RL to\nelicit truly novel reasoning abilities in LLMs. This highlights the need for\nimproved RL paradigms, such as continual scaling and multi-turn\nagent-environment interaction, to unlock this potential.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "30 pages, 27 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.13837v2",
    "published_date": "2025-04-18 17:59:56 UTC",
    "updated_date": "2025-05-16 15:39:33 UTC"
  },
  {
    "arxiv_id": "2504.13835v1",
    "title": "MIG: Automatic Data Selection for Instruction Tuning by Maximizing Information Gain in Semantic Space",
    "authors": [
      "Yicheng Chen",
      "Yining Li",
      "Kai Hu",
      "Zerun Ma",
      "Haochen Ye",
      "Kai Chen"
    ],
    "abstract": "Data quality and diversity are key to the construction of effective\ninstruction-tuning datasets. % With the increasing availability of open-source\ninstruction-tuning datasets, it is advantageous to automatically select\nhigh-quality and diverse subsets from a vast amount of data. % Existing methods\ntypically prioritize instance quality and use heuristic rules to maintain\ndiversity. % However, this absence of a comprehensive view of the entire\ncollection often leads to suboptimal results. % Moreover, heuristic rules\ngenerally focus on distance or clustering within the embedding space, which\nfails to accurately capture the intent of complex instructions in the semantic\nspace. % To bridge this gap, we propose a unified method for quantifying the\ninformation content of datasets. This method models the semantic space by\nconstructing a label graph and quantifies diversity based on the distribution\nof information within the graph. % Based on such a measurement, we further\nintroduce an efficient sampling method that selects data samples iteratively to\n\\textbf{M}aximize the \\textbf{I}nformation \\textbf{G}ain (MIG) in semantic\nspace. % Experiments on various datasets and base models demonstrate that MIG\nconsistently outperforms state-of-the-art methods. % Notably, the model\nfine-tuned with 5\\% Tulu3 data sampled by MIG achieves comparable performance\nto the official SFT model trained on the full dataset, with improvements of\n+5.73\\% on AlpacaEval and +6.89\\% on Wildbench.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.13835v1",
    "published_date": "2025-04-18 17:59:46 UTC",
    "updated_date": "2025-04-18 17:59:46 UTC"
  },
  {
    "arxiv_id": "2504.13828v3",
    "title": "Generative AI Act II: Test Time Scaling Drives Cognition Engineering",
    "authors": [
      "Shijie Xia",
      "Yiwei Qin",
      "Xuefeng Li",
      "Yan Ma",
      "Run-Ze Fan",
      "Steffi Chern",
      "Haoyang Zou",
      "Fan Zhou",
      "Xiangkun Hu",
      "Jiahe Jin",
      "Yanheng He",
      "Yixin Ye",
      "Yixiu Liu",
      "Pengfei Liu"
    ],
    "abstract": "The first generation of Large Language Models - what might be called \"Act I\"\nof generative AI (2020-2023) - achieved remarkable success through massive\nparameter and data scaling, yet exhibited fundamental limitations such as\nknowledge latency, shallow reasoning, and constrained cognitive processes.\nDuring this era, prompt engineering emerged as our primary interface with AI,\nenabling dialogue-level communication through natural language. We now witness\nthe emergence of \"Act II\" (2024-present), where models are transitioning from\nknowledge-retrieval systems (in latent space) to thought-construction engines\nthrough test-time scaling techniques. This new paradigm establishes a\nmind-level connection with AI through language-based thoughts. In this paper,\nwe clarify the conceptual foundations of cognition engineering and explain why\nthis moment is critical for its development. We systematically break down these\nadvanced approaches through comprehensive tutorials and optimized\nimplementations, democratizing access to cognition engineering and enabling\nevery practitioner to participate in AI's second act. We provide a regularly\nupdated collection of papers on test-time scaling in the GitHub Repository:\nhttps://github.com/GAIR-NLP/cognition-engineering",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "v3: add the comparison to existing work part; fix some errors",
    "pdf_url": "http://arxiv.org/pdf/2504.13828v3",
    "published_date": "2025-04-18 17:55:58 UTC",
    "updated_date": "2025-04-28 12:41:07 UTC"
  },
  {
    "arxiv_id": "2504.13822v1",
    "title": "Parameter-Efficient Continual Fine-Tuning: A Survey",
    "authors": [
      "Eric Nuertey Coleman",
      "Luigi Quarantiello",
      "Ziyue Liu",
      "Qinwen Yang",
      "Samrat Mukherjee",
      "Julio Hurtado",
      "Vincenzo Lomonaco"
    ],
    "abstract": "The emergence of large pre-trained networks has revolutionized the AI field,\nunlocking new possibilities and achieving unprecedented performance. However,\nthese models inherit a fundamental limitation from traditional Machine Learning\napproaches: their strong dependence on the \\textit{i.i.d.} assumption hinders\ntheir adaptability to dynamic learning scenarios. We believe the next\nbreakthrough in AI lies in enabling efficient adaptation to evolving\nenvironments -- such as the real world -- where new data and tasks arrive\nsequentially. This challenge defines the field of Continual Learning (CL), a\nMachine Learning paradigm focused on developing lifelong learning neural\nmodels. One alternative to efficiently adapt these large-scale models is known\nParameter-Efficient Fine-Tuning (PEFT). These methods tackle the issue of\nadapting the model to a particular data or scenario by performing small and\nefficient modifications, achieving similar performance to full fine-tuning.\nHowever, these techniques still lack the ability to adjust the model to\nmultiple tasks continually, as they suffer from the issue of Catastrophic\nForgetting. In this survey, we first provide an overview of CL algorithms and\nPEFT methods before reviewing the state-of-the-art on Parameter-Efficient\nContinual Fine-Tuning (PECFT). We examine various approaches, discuss\nevaluation metrics, and explore potential future research directions. Our goal\nis to highlight the synergy between CL and Parameter-Efficient Fine-Tuning,\nguide researchers in this field, and pave the way for novel future research\ndirections.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.13822v1",
    "published_date": "2025-04-18 17:51:51 UTC",
    "updated_date": "2025-04-18 17:51:51 UTC"
  },
  {
    "arxiv_id": "2504.13818v1",
    "title": "Not All Rollouts are Useful: Down-Sampling Rollouts in LLM Reinforcement Learning",
    "authors": [
      "Yixuan Even Xu",
      "Yash Savani",
      "Fei Fang",
      "Zico Kolter"
    ],
    "abstract": "Reinforcement learning (RL) has emerged as a powerful paradigm for enhancing\nreasoning capabilities in large language models, but faces a fundamental\nasymmetry in computation and memory requirements: inference is embarrassingly\nparallel with a minimal memory footprint, while policy updates require\nextensive synchronization and are memory-intensive. To address this asymmetry,\nwe introduce PODS (Policy Optimization with Down-Sampling), a framework that\nstrategically decouples these phases by generating numerous rollouts in\nparallel but updating only on an informative subset. Within this framework, we\ndevelop max-variance down-sampling, a theoretically motivated method that\nselects rollouts with maximally diverse reward signals. We prove that this\napproach has an efficient algorithmic solution, and empirically demonstrate\nthat GRPO with PODS using max-variance down-sampling achieves superior\nperformance over standard GRPO on the GSM8K benchmark.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "9 pages, 1 figure",
    "pdf_url": "http://arxiv.org/pdf/2504.13818v1",
    "published_date": "2025-04-18 17:49:55 UTC",
    "updated_date": "2025-04-18 17:49:55 UTC"
  },
  {
    "arxiv_id": "2504.16117v1",
    "title": "Context-Awareness and Interpretability of Rare Occurrences for Discovery and Formalization of Critical Failure Modes",
    "authors": [
      "Sridevi Polavaram",
      "Xin Zhou",
      "Meenu Ravi",
      "Mohammad Zarei",
      "Anmol Srivastava"
    ],
    "abstract": "Vision systems are increasingly deployed in critical domains such as\nsurveillance, law enforcement, and transportation. However, their\nvulnerabilities to rare or unforeseen scenarios pose significant safety risks.\nTo address these challenges, we introduce Context-Awareness and\nInterpretability of Rare Occurrences (CAIRO), an ontology-based human-assistive\ndiscovery framework for failure cases (or CP - Critical Phenomena) detection\nand formalization. CAIRO by design incentivizes human-in-the-loop for testing\nand evaluation of criticality that arises from misdetections, adversarial\nattacks, and hallucinations in AI black-box models. Our robust analysis of\nobject detection model(s) failures in automated driving systems (ADS) showcases\nscalable and interpretable ways of formalizing the observed gaps between camera\nperception and real-world contexts, resulting in test cases stored as explicit\nknowledge graphs (in OWL/XML format) amenable for sharing, downstream analysis,\nlogical reasoning, and accountability.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to IEEE Conference for Artificial Intelligence, 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.16117v1",
    "published_date": "2025-04-18 17:12:37 UTC",
    "updated_date": "2025-04-18 17:12:37 UTC"
  },
  {
    "arxiv_id": "2504.13804v1",
    "title": "Near-optimal algorithms for private estimation and sequential testing of collision probability",
    "authors": [
      "Robert Busa-Fekete",
      "Umar Syed"
    ],
    "abstract": "We present new algorithms for estimating and testing \\emph{collision\nprobability}, a fundamental measure of the spread of a discrete distribution\nthat is widely used in many scientific fields. We describe an algorithm that\nsatisfies $(\\alpha, \\beta)$-local differential privacy and estimates collision\nprobability with error at most $\\epsilon$ using\n$\\tilde{O}\\left(\\frac{\\log(1/\\beta)}{\\alpha^2 \\epsilon^2}\\right)$ samples for\n$\\alpha \\le 1$, which improves over previous work by a factor of\n$\\frac{1}{\\alpha^2}$. We also present a sequential testing algorithm for\ncollision probability, which can distinguish between collision probability\nvalues that are separated by $\\epsilon$ using $\\tilde{O}(\\frac{1}{\\epsilon^2})$\nsamples, even when $\\epsilon$ is unknown. Our algorithms have nearly the\noptimal sample complexity, and in experiments we show that they require\nsignificantly fewer samples than previous methods.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "stat.ML",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.13804v1",
    "published_date": "2025-04-18 17:12:15 UTC",
    "updated_date": "2025-04-18 17:12:15 UTC"
  },
  {
    "arxiv_id": "2504.13803v1",
    "title": "Imitation Learning with Precisely Labeled Human Demonstrations",
    "authors": [
      "Yilong Song"
    ],
    "abstract": "Within the imitation learning paradigm, training generalist robots requires\nlarge-scale datasets obtainable only through diverse curation. Due to the\nrelative ease to collect, human demonstrations constitute a valuable addition\nwhen incorporated appropriately. However, existing methods utilizing human\ndemonstrations face challenges in inferring precise actions, ameliorating\nembodiment gaps, and fusing with frontier generalist robot training pipelines.\nIn this work, building on prior studies that demonstrate the viability of using\nhand-held grippers for efficient data collection, we leverage the user's\ncontrol over the gripper's appearance--specifically by assigning it a unique,\neasily segmentable color--to enable simple and reliable application of the\nRANSAC and ICP registration method for precise end-effector pose estimation. We\nshow in simulation that precisely labeled human demonstrations on their own\nallow policies to reach on average 88.1% of the performance of using robot\ndemonstrations, and boost policy performance when combined with robot\ndemonstrations, despite the inherent embodiment gap.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.13803v1",
    "published_date": "2025-04-18 17:12:00 UTC",
    "updated_date": "2025-04-18 17:12:00 UTC"
  },
  {
    "arxiv_id": "2504.13993v1",
    "title": "CPR: Leveraging LLMs for Topic and Phrase Suggestion to Facilitate Comprehensive Product Reviews",
    "authors": [
      "Ekta Gujral",
      "Apurva Sinha",
      "Lishi Ji",
      "Bijayani Sanghamitra Mishra"
    ],
    "abstract": "Consumers often heavily rely on online product reviews, analyzing both\nquantitative ratings and textual descriptions to assess product quality.\nHowever, existing research hasn't adequately addressed how to systematically\nencourage the creation of comprehensive reviews that capture both customers\nsentiment and detailed product feature analysis. This paper presents CPR, a\nnovel methodology that leverages the power of Large Language Models (LLMs) and\nTopic Modeling to guide users in crafting insightful and well-rounded reviews.\nOur approach employs a three-stage process: first, we present users with\nproduct-specific terms for rating; second, we generate targeted phrase\nsuggestions based on these ratings; and third, we integrate user-written text\nthrough topic modeling, ensuring all key aspects are addressed. We evaluate CPR\nusing text-to-text LLMs, comparing its performance against real-world customer\nreviews from Walmart. Our results demonstrate that CPR effectively identifies\nrelevant product terms, even for new products lacking prior reviews, and\nprovides sentiment-aligned phrase suggestions, saving users time and enhancing\nreviews quality. Quantitative analysis reveals a 12.3% improvement in BLEU\nscore over baseline methods, further supported by manual evaluation of\ngenerated phrases. We conclude by discussing potential extensions and future\nresearch directions.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.13993v1",
    "published_date": "2025-04-18 17:11:38 UTC",
    "updated_date": "2025-04-18 17:11:38 UTC"
  },
  {
    "arxiv_id": "2504.13797v1",
    "title": "Meta-Learning and Knowledge Discovery based Physics-Informed Neural Network for Remaining Useful Life Prediction",
    "authors": [
      "Yu Wang",
      "Shujie Liu",
      "Shuai Lv",
      "Gengshuo Liu"
    ],
    "abstract": "Predicting the remaining useful life (RUL) of rotating machinery is critical\nfor industrial safety and maintenance, but existing methods struggle with\nscarce target-domain data and unclear degradation dynamics. We propose a\nMeta-Learning and Knowledge Discovery-based Physics-Informed Neural Network\n(MKDPINN) to address these challenges. The method first maps noisy sensor data\nto a low-dimensional hidden state space via a Hidden State Mapper (HSM). A\nPhysics-Guided Regulator (PGR) then learns unknown nonlinear PDEs governing\ndegradation evolution, embedding these physical constraints into the PINN\nframework. This integrates data-driven and physics-based approaches. The\nframework uses meta-learning, optimizing across source-domain meta-tasks to\nenable few-shot adaptation to new target tasks. Experiments on industrial data\nand the C-MAPSS benchmark show MKDPINN outperforms baselines in generalization\nand accuracy, proving its effectiveness for RUL prediction under data scarcity",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "34 pages,20 figs",
    "pdf_url": "http://arxiv.org/pdf/2504.13797v1",
    "published_date": "2025-04-18 16:58:38 UTC",
    "updated_date": "2025-04-18 16:58:38 UTC"
  },
  {
    "arxiv_id": "2504.13791v1",
    "title": "Collective Learning Mechanism based Optimal Transport Generative Adversarial Network for Non-parallel Voice Conversion",
    "authors": [
      "Sandipan Dhar",
      "Md. Tousin Akhter",
      "Nanda Dulal Jana",
      "Swagatam Das"
    ],
    "abstract": "After demonstrating significant success in image synthesis, Generative\nAdversarial Network (GAN) models have likewise made significant progress in the\nfield of speech synthesis, leveraging their capacity to adapt the precise\ndistribution of target data through adversarial learning processes. Notably, in\nthe realm of State-Of-The-Art (SOTA) GAN-based Voice Conversion (VC) models,\nthere exists a substantial disparity in naturalness between real and\nGAN-generated speech samples. Furthermore, while many GAN models currently\noperate on a single generator discriminator learning approach, optimizing\ntarget data distribution is more effectively achievable through a single\ngenerator multi-discriminator learning scheme. Hence, this study introduces a\nnovel GAN model named Collective Learning Mechanism-based Optimal Transport GAN\n(CLOT-GAN) model, incorporating multiple discriminators, including the Deep\nConvolutional Neural Network (DCNN) model, Vision Transformer (ViT), and\nconformer. The objective of integrating various discriminators lies in their\nability to comprehend the formant distribution of mel-spectrograms, facilitated\nby a collective learning mechanism. Simultaneously, the inclusion of Optimal\nTransport (OT) loss aims to precisely bridge the gap between the source and\ntarget data distribution, employing the principles of OT theory. The\nexperimental validation on VCC 2018, VCTK, and CMU-Arctic datasets confirms\nthat the CLOT-GAN-VC model outperforms existing VC models in objective and\nsubjective assessments.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "7 pages, 2 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2504.13791v1",
    "published_date": "2025-04-18 16:44:01 UTC",
    "updated_date": "2025-04-18 16:44:01 UTC"
  },
  {
    "arxiv_id": "2504.16116v2",
    "title": "DMind Benchmark: Toward a Holistic Assessment of LLM Capabilities across the Web3 Domain",
    "authors": [
      "Enhao Huang",
      "Pengyu Sun",
      "Zixin Lin",
      "Alex Chen",
      "Joey Ouyang",
      "Hobert Wang",
      "Dong Dong",
      "Gang Zhao",
      "James Yi",
      "Frank Li",
      "Ziang Ling",
      "Lowes Yang"
    ],
    "abstract": "Large Language Models (LLMs) have achieved impressive performance in diverse\nnatural language processing tasks, but specialized domains such as Web3 present\nnew challenges and require more tailored evaluation. Despite the significant\nuser base and capital flows in Web3, encompassing smart contracts,\ndecentralized finance (DeFi), non-fungible tokens (NFTs), decentralized\nautonomous organizations (DAOs), on-chain governance, and novel\ntoken-economics, no comprehensive benchmark has systematically assessed LLM\nperformance in this domain. To address this gap, we introduce the DMind\nBenchmark, a holistic Web3-oriented evaluation suite covering nine critical\nsubfields: fundamental blockchain concepts, blockchain infrastructure, smart\ncontract, DeFi mechanisms, DAOs, NFTs, token economics, meme concept, and\nsecurity vulnerabilities. Beyond multiple-choice questions, DMind Benchmark\nfeatures domain-specific tasks such as contract debugging and on-chain numeric\nreasoning, mirroring real-world scenarios. We evaluated 26 models, including\nChatGPT, Claude, DeepSeek, Gemini, Grok, and Qwen, uncovering notable\nperformance gaps in specialized areas like token economics and\nsecurity-critical contract analysis. While some models excel in blockchain\ninfrastructure tasks, advanced subfields remain challenging. Our benchmark\ndataset and evaluation pipeline are open-sourced on\nhttps://huggingface.co/datasets/DMindAI/DMind_Benchmark, reaching number one in\nHugging Face's trending dataset charts within a week of release.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16116v2",
    "published_date": "2025-04-18 16:40:39 UTC",
    "updated_date": "2025-05-16 12:00:59 UTC"
  },
  {
    "arxiv_id": "2504.13787v2",
    "title": "Probabilistic Stability Guarantees for Feature Attributions",
    "authors": [
      "Helen Jin",
      "Anton Xue",
      "Weiqiu You",
      "Surbhi Goel",
      "Eric Wong"
    ],
    "abstract": "Stability guarantees have emerged as a principled way to evaluate feature\nattributions, but existing certification methods rely on heavily smoothed\nclassifiers and often produce conservative guarantees. To address these\nlimitations, we introduce soft stability and propose a simple, model-agnostic,\nsample-efficient stability certification algorithm (SCA) that yields\nnon-trivial and interpretable guarantees for any attribution method. Moreover,\nwe show that mild smoothing achieves a more favorable trade-off between\naccuracy and stability, avoiding the aggressive compromises made in prior\ncertification methods. To explain this behavior, we use Boolean function\nanalysis to derive a novel characterization of stability under smoothing. We\nevaluate SCA on vision and language tasks and demonstrate the effectiveness of\nsoft stability in measuring the robustness of explanation methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.13787v2",
    "published_date": "2025-04-18 16:39:08 UTC",
    "updated_date": "2025-05-17 15:16:40 UTC"
  },
  {
    "arxiv_id": "2504.13785v1",
    "title": "Learning Through Retrospection: Improving Trajectory Prediction for Automated Driving with Error Feedback",
    "authors": [
      "Steffen Hagedorn",
      "Aron Distelzweig",
      "Marcel Hallgarten",
      "Alexandru P. Condurache"
    ],
    "abstract": "In automated driving, predicting trajectories of surrounding vehicles\nsupports reasoning about scene dynamics and enables safe planning for the ego\nvehicle. However, existing models handle predictions as an instantaneous task\nof forecasting future trajectories based on observed information. As time\nproceeds, the next prediction is made independently of the previous one, which\nmeans that the model cannot correct its errors during inference and will repeat\nthem. To alleviate this problem and better leverage temporal data, we propose a\nnovel retrospection technique. Through training on closed-loop rollouts the\nmodel learns to use aggregated feedback. Given new observations it reflects on\nprevious predictions and analyzes its errors to improve the quality of\nsubsequent predictions. Thus, the model can learn to correct systematic errors\nduring inference. Comprehensive experiments on nuScenes and Argoverse\ndemonstrate a considerable decrease in minimum Average Displacement Error of up\nto 31.9% compared to the state-of-the-art baseline without retrospection. We\nfurther showcase the robustness of our technique by demonstrating a better\nhandling of out-of-distribution scenarios with undetected road-users.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.13785v1",
    "published_date": "2025-04-18 16:35:12 UTC",
    "updated_date": "2025-04-18 16:35:12 UTC"
  },
  {
    "arxiv_id": "2504.13777v1",
    "title": "Beyond Misinformation: A Conceptual Framework for Studying AI Hallucinations in (Science) Communication",
    "authors": [
      "Anqi Shao"
    ],
    "abstract": "This paper proposes a conceptual framework for understanding AI\nhallucinations as a distinct form of misinformation. While misinformation\nscholarship has traditionally focused on human intent, generative AI systems\nnow produce false yet plausible outputs absent of such intent. I argue that\nthese AI hallucinations should not be treated merely as technical failures but\nas communication phenomena with social consequences. Drawing on a\nsupply-and-demand model and the concept of distributed agency, the framework\noutlines how hallucinations differ from human-generated misinformation in\nproduction, perception, and institutional response. I conclude by outlining a\nresearch agenda for communication scholars to investigate the emergence,\ndissemination, and audience reception of hallucinated content, with attention\nto macro (institutional), meso (group), and micro (individual) levels. This\nwork urges communication researchers to rethink the boundaries of\nmisinformation theory in light of probabilistic, non-human actors increasingly\nembedded in knowledge production.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.13777v1",
    "published_date": "2025-04-18 16:26:02 UTC",
    "updated_date": "2025-04-18 16:26:02 UTC"
  },
  {
    "arxiv_id": "2504.13774v1",
    "title": "DP2Unlearning: An Efficient and Guaranteed Unlearning Framework for LLMs",
    "authors": [
      "Tamim Al Mahmud",
      "Najeeb Jebreel",
      "Josep Domingo-Ferrer",
      "David Sanchez"
    ],
    "abstract": "Large language models (LLMs) have recently revolutionized language processing\ntasks but have also brought ethical and legal issues. LLMs have a tendency to\nmemorize potentially private or copyrighted information present in the training\ndata, which might then be delivered to end users at inference time. When this\nhappens, a naive solution is to retrain the model from scratch after excluding\nthe undesired data. Although this guarantees that the target data have been\nforgotten, it is also prohibitively expensive for LLMs. Approximate unlearning\noffers a more efficient alternative, as it consists of ex post modifications of\nthe trained model itself to prevent undesirable results, but it lacks\nforgetting guarantees because it relies solely on empirical evidence. In this\nwork, we present DP2Unlearning, a novel LLM unlearning framework that offers\nformal forgetting guarantees at a significantly lower cost than retraining from\nscratch on the data to be retained. DP2Unlearning involves training LLMs on\ntextual data protected using {\\epsilon}-differential privacy (DP), which later\nenables efficient unlearning with the guarantees against disclosure associated\nwith the chosen {\\epsilon}. Our experiments demonstrate that DP2Unlearning\nachieves similar model performance post-unlearning, compared to an LLM\nretraining from scratch on retained data -- the gold standard exact unlearning\n-- but at approximately half the unlearning cost. In addition, with a\nreasonable computational cost, it outperforms approximate unlearning methods at\nboth preserving the utility of the model post-unlearning and effectively\nforgetting the targeted information.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "49 pages",
    "pdf_url": "http://arxiv.org/pdf/2504.13774v1",
    "published_date": "2025-04-18 16:22:20 UTC",
    "updated_date": "2025-04-18 16:22:20 UTC"
  },
  {
    "arxiv_id": "2504.13763v2",
    "title": "Decoding Vision Transformers: the Diffusion Steering Lens",
    "authors": [
      "Ryota Takatsuki",
      "Sonia Joseph",
      "Ippei Fujisawa",
      "Ryota Kanai"
    ],
    "abstract": "Logit Lens is a widely adopted method for mechanistic interpretability of\ntransformer-based language models, enabling the analysis of how internal\nrepresentations evolve across layers by projecting them into the output\nvocabulary space. Although applying Logit Lens to Vision Transformers (ViTs) is\ntechnically straightforward, its direct use faces limitations in capturing the\nrichness of visual representations. Building on the work of Toker et al.\n(2024)~\\cite{Toker2024-ve}, who introduced Diffusion Lens to visualize\nintermediate representations in the text encoders of text-to-image diffusion\nmodels, we demonstrate that while Diffusion Lens can effectively visualize\nresidual stream representations in image encoders, it fails to capture the\ndirect contributions of individual submodules. To overcome this limitation, we\npropose \\textbf{Diffusion Steering Lens} (DSL), a novel, training-free approach\nthat steers submodule outputs and patches subsequent indirect contributions. We\nvalidate our method through interventional studies, showing that DSL provides\nan intuitive and reliable interpretation of the internal processing in ViTs.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "12 pages, 17 figures. Accepted to the CVPR 2025 Workshop on\n  Mechanistic Interpretability for Vision (MIV)",
    "pdf_url": "http://arxiv.org/pdf/2504.13763v2",
    "published_date": "2025-04-18 16:00:53 UTC",
    "updated_date": "2025-04-23 10:04:20 UTC"
  },
  {
    "arxiv_id": "2504.16115v1",
    "title": "A Framework for Objective-Driven Dynamical Stochastic Fields",
    "authors": [
      "Yibo Jacky Zhang",
      "Sanmi Koyejo"
    ],
    "abstract": "Fields offer a versatile approach for describing complex systems composed of\ninteracting and dynamic components. In particular, some of these dynamical and\nstochastic systems may exhibit goal-directed behaviors aimed at achieving\nspecific objectives, which we refer to as $\\textit{intelligent fields}$.\nHowever, due to their inherent complexity, it remains challenging to develop a\nformal theoretical description of such systems and to effectively translate\nthese descriptions into practical applications. In this paper, we propose three\nfundamental principles -- complete configuration, locality, and purposefulness\n-- to establish a theoretical framework for understanding intelligent fields.\nMoreover, we explore methodologies for designing such fields from the\nperspective of artificial intelligence applications. This initial investigation\naims to lay the groundwork for future theoretical developments and practical\nadvances in understanding and harnessing the potential of such objective-driven\ndynamical stochastic fields.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.MA",
      "nlin.AO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16115v1",
    "published_date": "2025-04-18 15:46:33 UTC",
    "updated_date": "2025-04-18 15:46:33 UTC"
  },
  {
    "arxiv_id": "2504.13756v1",
    "title": "Scaling sparse feature circuit finding for in-context learning",
    "authors": [
      "Dmitrii Kharlapenko",
      "Stepan Shabalin",
      "Fazl Barez",
      "Arthur Conmy",
      "Neel Nanda"
    ],
    "abstract": "Sparse autoencoders (SAEs) are a popular tool for interpreting large language\nmodel activations, but their utility in addressing open questions in\ninterpretability remains unclear. In this work, we demonstrate their\neffectiveness by using SAEs to deepen our understanding of the mechanism behind\nin-context learning (ICL). We identify abstract SAE features that (i) encode\nthe model's knowledge of which task to execute and (ii) whose latent vectors\ncausally induce the task zero-shot. This aligns with prior work showing that\nICL is mediated by task vectors. We further demonstrate that these task vectors\nare well approximated by a sparse sum of SAE latents, including these\ntask-execution features. To explore the ICL mechanism, we adapt the sparse\nfeature circuits methodology of Marks et al. (2024) to work for the much larger\nGemma-1 2B model, with 30 times as many parameters, and to the more complex\ntask of ICL. Through circuit finding, we discover task-detecting features with\ncorresponding SAE latents that activate earlier in the prompt, that detect when\ntasks have been performed. They are causally linked with task-execution\nfeatures through the attention and MLP sublayers.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.13756v1",
    "published_date": "2025-04-18 15:45:30 UTC",
    "updated_date": "2025-04-18 15:45:30 UTC"
  },
  {
    "arxiv_id": "2504.13754v3",
    "title": "Towards Accurate and Interpretable Neuroblastoma Diagnosis via Contrastive Multi-scale Pathological Image Analysis",
    "authors": [
      "Zhu Zhu",
      "Shuo Jiang",
      "Jingyuan Zheng",
      "Yawen Li",
      "Yifei Chen",
      "Manli Zhao",
      "Weizhong Gu",
      "Feiwei Qin",
      "Jinhu Wang",
      "Gang Yu"
    ],
    "abstract": "Neuroblastoma, adrenal-derived, is among the most common pediatric solid\nmalignancies, characterized by significant clinical heterogeneity. Timely and\naccurate pathological diagnosis from hematoxylin and eosin-stained whole-slide\nimages is critical for patient prognosis. However, current diagnostic practices\nprimarily rely on subjective manual examination by pathologists, leading to\ninconsistent accuracy. Existing automated whole-slide image classification\nmethods encounter challenges such as poor interpretability, limited feature\nextraction capabilities, and high computational costs, restricting their\npractical clinical deployment. To overcome these limitations, we propose\nCMSwinKAN, a contrastive-learning-based multi-scale feature fusion model\ntailored for pathological image classification, which enhances the Swin\nTransformer architecture by integrating a Kernel Activation Network within its\nmultilayer perceptron and classification head modules, significantly improving\nboth interpretability and accuracy. By fusing multi-scale features and\nleveraging contrastive learning strategies, CMSwinKAN mimics clinicians'\ncomprehensive approach, effectively capturing global and local tissue\ncharacteristics. Additionally, we introduce a heuristic soft voting mechanism\nguided by clinical insights to bridge patch-level predictions to whole-slide\nimage-level classifications seamlessly. We verified the CMSwinKAN on the\npublicly available BreakHis dataset and the PpNTs dataset, which was\nestablished by our hospital. Results demonstrate that CMSwinKAN performs better\nthan existing state-of-the-art pathology-specific models pre-trained on large\ndatasets. Our source code is available at\nhttps://github.com/JSLiam94/CMSwinKAN.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "10pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.13754v3",
    "published_date": "2025-04-18 15:39:46 UTC",
    "updated_date": "2025-05-06 12:45:03 UTC"
  },
  {
    "arxiv_id": "2504.13751v1",
    "title": "A Survey for What Developers Require in AI-powered Tools that Aid in Component Selection in CBSD",
    "authors": [
      "Mahdi Jaberzadeh Ansari",
      "Ann Barcomb"
    ],
    "abstract": "Although it has been more than four decades that the first components-based\nsoftware development (CBSD) studies were conducted, there is still no standard\nmethod or tool for component selection which is widely accepted by the\nindustry. The gulf between industry and academia contributes to the lack of an\naccepted tool. We conducted a mixed methods survey of nearly 100 people engaged\nin component-based software engineering practice or research to better\nunderstand the problems facing industry, how these needs could be addressed,\nand current best practices employed in component selection. We also sought to\nidentify and prioritize quality criteria for component selection from an\nindustry perspective. In response to the call for CBSD component selection\ntools to incorporate recent technical advances, we also explored the\nperceptions of professionals about AI-driven tools, present and envisioned.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.SE",
    "comment": "10 pages, 4 figures, The 29th International Conference on Evaluation\n  and Assessment in Software Engineering, 17 to 20 June, 2025, Istanbul, Turkey",
    "pdf_url": "http://arxiv.org/pdf/2504.13751v1",
    "published_date": "2025-04-18 15:35:31 UTC",
    "updated_date": "2025-04-18 15:35:31 UTC"
  },
  {
    "arxiv_id": "2504.13745v1",
    "title": "ESPLoRA: Enhanced Spatial Precision with Low-Rank Adaption in Text-to-Image Diffusion Models for High-Definition Synthesis",
    "authors": [
      "Andrea Rigo",
      "Luca Stornaiuolo",
      "Mauro Martino",
      "Bruno Lepri",
      "Nicu Sebe"
    ],
    "abstract": "Diffusion models have revolutionized text-to-image (T2I) synthesis, producing\nhigh-quality, photorealistic images. However, they still struggle to properly\nrender the spatial relationships described in text prompts. To address the lack\nof spatial information in T2I generations, existing methods typically use\nexternal network conditioning and predefined layouts, resulting in higher\ncomputational costs and reduced flexibility. Our approach builds upon a curated\ndataset of spatially explicit prompts, meticulously extracted and synthesized\nfrom LAION-400M to ensure precise alignment between textual descriptions and\nspatial layouts. Alongside this dataset, we present ESPLoRA, a flexible\nfine-tuning framework based on Low-Rank Adaptation, specifically designed to\nenhance spatial consistency in generative models without increasing generation\ntime or compromising the quality of the outputs. In addition to ESPLoRA, we\npropose refined evaluation metrics grounded in geometric constraints, capturing\n3D spatial relations such as \\textit{in front of} or \\textit{behind}. These\nmetrics also expose spatial biases in T2I models which, even when not fully\nmitigated, can be strategically exploited by our TORE algorithm to further\nimprove the spatial consistency of generated images. Our method outperforms the\ncurrent state-of-the-art framework, CoMPaSS, by 13.33% on established spatial\nconsistency benchmarks.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "I.4.0"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.13745v1",
    "published_date": "2025-04-18 15:21:37 UTC",
    "updated_date": "2025-04-18 15:21:37 UTC"
  },
  {
    "arxiv_id": "2504.16947v1",
    "title": "SCRAG: Social Computing-Based Retrieval Augmented Generation for Community Response Forecasting in Social Media Environments",
    "authors": [
      "Dachun Sun",
      "You Lyu",
      "Jinning Li",
      "Yizhuo Chen",
      "Tianshi Wang",
      "Tomoyoshi Kimura",
      "Tarek Abdelzaher"
    ],
    "abstract": "This paper introduces SCRAG, a prediction framework inspired by social\ncomputing, designed to forecast community responses to real or hypothetical\nsocial media posts. SCRAG can be used by public relations specialists (e.g., to\ncraft messaging in ways that avoid unintended misinterpretations) or public\nfigures and influencers (e.g., to anticipate social responses), among other\napplications related to public sentiment prediction, crisis management, and\nsocial what-if analysis. While large language models (LLMs) have achieved\nremarkable success in generating coherent and contextually rich text, their\nreliance on static training data and susceptibility to hallucinations limit\ntheir effectiveness at response forecasting in dynamic social media\nenvironments. SCRAG overcomes these challenges by integrating LLMs with a\nRetrieval-Augmented Generation (RAG) technique rooted in social computing.\nSpecifically, our framework retrieves (i) historical responses from the target\ncommunity to capture their ideological, semantic, and emotional makeup, and\n(ii) external knowledge from sources such as news articles to inject\ntime-sensitive context. This information is then jointly used to forecast the\nresponses of the target community to new posts or narratives. Extensive\nexperiments across six scenarios on the X platform (formerly Twitter), tested\nwith various embedding models and LLMs, demonstrate over 10% improvements on\naverage in key evaluation metrics. A concrete example further shows its\neffectiveness in capturing diverse ideologies and nuances. Our work provides a\nsocial computing tool for applications where accurate and concrete insights\ninto community responses are crucial.",
    "categories": [
      "cs.SI",
      "cs.AI"
    ],
    "primary_category": "cs.SI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16947v1",
    "published_date": "2025-04-18 15:02:31 UTC",
    "updated_date": "2025-04-18 15:02:31 UTC"
  },
  {
    "arxiv_id": "2504.13730v1",
    "title": "Controlled Territory and Conflict Tracking (CONTACT): (Geo-)Mapping Occupied Territory from Open Source Intelligence",
    "authors": [
      "Paul K. Mandal",
      "Cole Leo",
      "Connor Hurley"
    ],
    "abstract": "Open-source intelligence provides a stream of unstructured textual data that\ncan inform assessments of territorial control. We present CONTACT, a framework\nfor territorial control prediction using large language models (LLMs) and\nminimal supervision. We evaluate two approaches: SetFit, an embedding-based\nfew-shot classifier, and a prompt tuning method applied to BLOOMZ-560m, a\nmultilingual generative LLM. Our model is trained on a small hand-labeled\ndataset of news articles covering ISIS activity in Syria and Iraq, using\nprompt-conditioned extraction of control-relevant signals such as military\noperations, casualties, and location references. We show that the BLOOMZ-based\nmodel outperforms the SetFit baseline, and that prompt-based supervision\nimproves generalization in low-resource settings. CONTACT demonstrates that\nLLMs fine-tuned using few-shot methods can reduce annotation burdens and\nsupport structured inference from open-ended OSINT streams. Our code is\navailable at https://github.com/PaulKMandal/CONTACT/.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "I.2.7; I.2.6; I.2.8; H.3.1; K.4.1"
    ],
    "primary_category": "cs.CL",
    "comment": "7 pages, 1 figure, 1 table",
    "pdf_url": "http://arxiv.org/pdf/2504.13730v1",
    "published_date": "2025-04-18 14:57:07 UTC",
    "updated_date": "2025-04-18 14:57:07 UTC"
  },
  {
    "arxiv_id": "2504.13717v1",
    "title": "Human-aligned Deep Learning: Explainability, Causality, and Biological Inspiration",
    "authors": [
      "Gianluca Carloni"
    ],
    "abstract": "This work aligns deep learning (DL) with human reasoning capabilities and\nneeds to enable more efficient, interpretable, and robust image classification.\nWe approach this from three perspectives: explainability, causality, and\nbiological vision. Introduction and background open this work before diving\ninto operative chapters. First, we assess neural networks' visualization\ntechniques for medical images and validate an explainable-by-design method for\nbreast mass classification. A comprehensive review at the intersection of XAI\nand causality follows, where we introduce a general scaffold to organize past\nand future research, laying the groundwork for our second perspective. In the\ncausality direction, we propose novel modules that exploit feature\nco-occurrence in medical images, leading to more effective and explainable\npredictions. We further introduce CROCODILE, a general framework that\nintegrates causal concepts, contrastive learning, feature disentanglement, and\nprior knowledge to enhance generalization. Lastly, we explore biological\nvision, examining how humans recognize objects, and propose CoCoReco, a\nconnectivity-inspired network with context-aware attention mechanisms. Overall,\nour key findings include: (i) simple activation maximization lacks insight for\nmedical imaging DL models; (ii) prototypical-part learning is effective and\nradiologically aligned; (iii) XAI and causal ML are deeply connected; (iv) weak\ncausal signals can be leveraged without a priori information to improve\nperformance and interpretability; (v) our framework generalizes across medical\ndomains and out-of-distribution data; (vi) incorporating biological circuit\nmotifs improves human-aligned recognition. This work contributes toward\nhuman-aligned DL and highlights pathways to bridge the gap between research and\nclinical adoption, with implications for improved trust, diagnostic accuracy,\nand safe deployment.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "eess.IV",
      "q-bio.NC",
      "I.2; I.2.6; I.4; I.4.7; I.5; J.3; J.6"
    ],
    "primary_category": "cs.CV",
    "comment": "Personal adaptation and expansion of doctoral thesis (originally\n  submitted in Oct 2024, revisioned in Jan 2025)",
    "pdf_url": "http://arxiv.org/pdf/2504.13717v1",
    "published_date": "2025-04-18 14:40:58 UTC",
    "updated_date": "2025-04-18 14:40:58 UTC"
  },
  {
    "arxiv_id": "2504.15304v1",
    "title": "Can Machine Learning Agents Deal with Hard Choices?",
    "authors": [
      "Kangyu Wang"
    ],
    "abstract": "Machine Learning ML agents have been increasingly used in decision-making\nacross a wide range of tasks and environments. These ML agents are typically\ndesigned to balance multiple objectives when making choices. Understanding how\ntheir decision-making processes align with or diverge from human reasoning is\nessential. Human agents often encounter hard choices, that is, situations where\noptions are incommensurable; neither option is preferred, yet the agent is not\nindifferent between them. In such cases, human agents can identify hard choices\nand resolve them through deliberation. In contrast, current ML agents, due to\nfundamental limitations in Multi-Objective Optimisation or MOO methods, cannot\nidentify hard choices, let alone resolve them. Neither Scalarised Optimisation\nnor Pareto Optimisation, the two principal MOO approaches, can capture\nincommensurability. This limitation generates three distinct alignment\nproblems: the alienness of ML decision-making behaviour from a human\nperspective; the unreliability of preference-based alignment strategies for\nhard choices; and the blockage of alignment strategies pursuing multiple\nobjectives. Evaluating two potential technical solutions, I recommend an\nensemble solution that appears most promising for enabling ML agents to\nidentify hard choices and mitigate alignment problems. However, no known\ntechnique allows ML agents to resolve hard choices through deliberation, as\nthey cannot autonomously change their goals. This underscores the\ndistinctiveness of human agency and urges ML researchers to reconceptualise\nmachine autonomy and develop frameworks and methods that can better address\nthis fundamental gap.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "22 pages excluding bibliography, 27 pagas including bibliography, 3\n  figures",
    "pdf_url": "http://arxiv.org/pdf/2504.15304v1",
    "published_date": "2025-04-18 14:38:27 UTC",
    "updated_date": "2025-04-18 14:38:27 UTC"
  },
  {
    "arxiv_id": "2504.13990v1",
    "title": "PC-DeepNet: A GNSS Positioning Error Minimization Framework Using Permutation-Invariant Deep Neural Network",
    "authors": [
      "M. Humayun Kabir",
      "Md. Ali Hasan",
      "Md. Shafiqul Islam",
      "Kyeongjun Ko",
      "Wonjae Shin"
    ],
    "abstract": "Global navigation satellite systems (GNSS) face significant challenges in\nurban and sub-urban areas due to non-line-of-sight (NLOS) propagation,\nmultipath effects, and low received power levels, resulting in highly\nnon-linear and non-Gaussian measurement error distributions. In light of this,\nconventional model-based positioning approaches, which rely on Gaussian error\napproximations, struggle to achieve precise localization under these\nconditions. To overcome these challenges, we put forth a novel learning-based\nframework, PC-DeepNet, that employs a permutation-invariant (PI) deep neural\nnetwork (DNN) to estimate position corrections (PC). This approach is designed\nto ensure robustness against changes in the number and/or order of visible\nsatellite measurements, a common issue in GNSS systems, while leveraging NLOS\nand multipath indicators as features to enhance positioning accuracy in\nchallenging urban and sub-urban environments. To validate the performance of\nthe proposed framework, we compare the positioning error with state-of-the-art\nmodel-based and learning-based positioning methods using two publicly available\ndatasets. The results confirm that proposed PC-DeepNet achieves superior\naccuracy than existing model-based and learning-based methods while exhibiting\nlower computational complexity compared to previous learning-based approaches.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.LG",
    "comment": "31 pages, 14 figures, 6 tables",
    "pdf_url": "http://arxiv.org/pdf/2504.13990v1",
    "published_date": "2025-04-18 14:18:02 UTC",
    "updated_date": "2025-04-18 14:18:02 UTC"
  },
  {
    "arxiv_id": "2504.13707v1",
    "title": "OpenDeception: Benchmarking and Investigating AI Deceptive Behaviors via Open-ended Interaction Simulation",
    "authors": [
      "Yichen Wu",
      "Xudong Pan",
      "Geng Hong",
      "Min Yang"
    ],
    "abstract": "As the general capabilities of large language models (LLMs) improve and agent\napplications become more widespread, the underlying deception risks urgently\nrequire systematic evaluation and effective oversight. Unlike existing\nevaluation which uses simulated games or presents limited choices, we introduce\nOpenDeception, a novel deception evaluation framework with an open-ended\nscenario dataset. OpenDeception jointly evaluates both the deception intention\nand capabilities of LLM-based agents by inspecting their internal reasoning\nprocess. Specifically, we construct five types of common use cases where LLMs\nintensively interact with the user, each consisting of ten diverse, concrete\nscenarios from the real world. To avoid ethical concerns and costs of high-risk\ndeceptive interactions with human testers, we propose to simulate the\nmulti-turn dialogue via agent simulation. Extensive evaluation of eleven\nmainstream LLMs on OpenDeception highlights the urgent need to address\ndeception risks and security concerns in LLM-based agents: the deception\nintention ratio across the models exceeds 80%, while the deception success rate\nsurpasses 50%. Furthermore, we observe that LLMs with stronger capabilities do\nexhibit a higher risk of deception, which calls for more alignment efforts on\ninhibiting deceptive behaviors.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.13707v1",
    "published_date": "2025-04-18 14:11:27 UTC",
    "updated_date": "2025-04-18 14:11:27 UTC"
  },
  {
    "arxiv_id": "2504.13700v1",
    "title": "Exploring Multimodal Prompt for Visualization Authoring with Large Language Models",
    "authors": [
      "Zhen Wen",
      "Luoxuan Weng",
      "Yinghao Tang",
      "Runjin Zhang",
      "Yuxin Liu",
      "Bo Pan",
      "Minfeng Zhu",
      "Wei Chen"
    ],
    "abstract": "Recent advances in large language models (LLMs) have shown great potential in\nautomating the process of visualization authoring through simple natural\nlanguage utterances. However, instructing LLMs using natural language is\nlimited in precision and expressiveness for conveying visualization intent,\nleading to misinterpretation and time-consuming iterations. To address these\nlimitations, we conduct an empirical study to understand how LLMs interpret\nambiguous or incomplete text prompts in the context of visualization authoring,\nand the conditions making LLMs misinterpret user intent. Informed by the\nfindings, we introduce visual prompts as a complementary input modality to text\nprompts, which help clarify user intent and improve LLMs' interpretation\nabilities. To explore the potential of multimodal prompting in visualization\nauthoring, we design VisPilot, which enables users to easily create\nvisualizations using multimodal prompts, including text, sketches, and direct\nmanipulations on existing visualizations. Through two case studies and a\ncontrolled user study, we demonstrate that VisPilot provides a more intuitive\nway to create visualizations without affecting the overall task efficiency\ncompared to text-only prompting approaches. Furthermore, we analyze the impact\nof text and visual prompts in different visualization tasks. Our findings\nhighlight the importance of multimodal prompting in improving the usability of\nLLMs for visualization authoring. We discuss design implications for future\nvisualization systems and provide insights into how multimodal prompts can\nenhance human-AI collaboration in creative visualization tasks. All materials\nare available at https://OSF.IO/2QRAK.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "11 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.13700v1",
    "published_date": "2025-04-18 14:00:55 UTC",
    "updated_date": "2025-04-18 14:00:55 UTC"
  },
  {
    "arxiv_id": "2504.13989v2",
    "title": "Gradual Binary Search and Dimension Expansion : A general method for activation quantization in LLMs",
    "authors": [
      "Lucas Maisonnave",
      "Cyril Moineau",
      "Olivier Bichler",
      "Fabrice Rastello"
    ],
    "abstract": "Large language models (LLMs) have become pivotal in artificial intelligence,\ndemonstrating strong capabilities in reasoning, understanding, and generating\ndata. However, their deployment on edge devices is hindered by their\nsubstantial size, often reaching several billion parameters. Quantization is a\nwidely used method to reduce memory usage and inference time, however LLMs\npresent unique challenges due to the prevalence of outliers in their\nactivations. In this work, we leverage the theoretical advantages of Hadamard\nmatrices over random rotation matrices to push the boundaries of quantization\nin LLMs. We demonstrate that Hadamard matrices are more effective in reducing\noutliers, which are a significant obstacle in achieving low-bit quantization.\nOur method based on a gradual binary search enables 3-bit quantization for\nweights, activations, and key-value (KV) caches, resulting in a 40% increase in\naccuracy on common benchmarks compared to SoTA methods. We extend the use of\nrotation matrices to support non-power-of-2 embedding dimensions, similar to\nthe Qwen architecture, by employing the Paley algorithm. We theoretically\ndemonstrates the superiority of Hadamard matrices in reducing outliers.We\nachieved 3-bit quantization for weights, activations, and KV cache,\nsignificantly enhancing model performance. Our experimental results on multiple\nmodels family like Mistral, LLaMA, and Qwen demonstrate the effectiveness of\nour approach, outperforming existing methods and enabling practical 3-bit\nquantization.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.13989v2",
    "published_date": "2025-04-18 13:46:58 UTC",
    "updated_date": "2025-05-13 09:36:03 UTC"
  },
  {
    "arxiv_id": "2504.13682v1",
    "title": "AnyTSR: Any-Scale Thermal Super-Resolution for UAV",
    "authors": [
      "Mengyuan Li",
      "Changhong Fu",
      "Ziyu Lu",
      "Zijie Zhang",
      "Haobo Zuo",
      "Liangliang Yao"
    ],
    "abstract": "Thermal imaging can greatly enhance the application of intelligent unmanned\naerial vehicles (UAV) in challenging environments. However, the inherent low\nresolution of thermal sensors leads to insufficient details and blurred\nboundaries. Super-resolution (SR) offers a promising solution to address this\nissue, while most existing SR methods are designed for fixed-scale SR. They are\ncomputationally expensive and inflexible in practical applications. To address\nabove issues, this work proposes a novel any-scale thermal SR method (AnyTSR)\nfor UAV within a single model. Specifically, a new image encoder is proposed to\nexplicitly assign specific feature code to enable more accurate and flexible\nrepresentation. Additionally, by effectively embedding coordinate offset\ninformation into the local feature ensemble, an innovative any-scale upsampler\nis proposed to better understand spatial relationships and reduce artifacts.\nMoreover, a novel dataset (UAV-TSR), covering both land and water scenes, is\nconstructed for thermal SR tasks. Experimental results demonstrate that the\nproposed method consistently outperforms state-of-the-art methods across all\nscaling factors as well as generates more accurate and detailed high-resolution\nimages. The code is located at https://github.com/vision4robotics/AnyTSR.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.13682v1",
    "published_date": "2025-04-18 13:23:25 UTC",
    "updated_date": "2025-04-18 13:23:25 UTC"
  },
  {
    "arxiv_id": "2504.13677v1",
    "title": "Revisiting Uncertainty Quantification Evaluation in Language Models: Spurious Interactions with Response Length Bias Results",
    "authors": [
      "Andrea Santilli",
      "Adam Golinski",
      "Michael Kirchhof",
      "Federico Danieli",
      "Arno Blaas",
      "Miao Xiong",
      "Luca Zappella",
      "Sinead Williamson"
    ],
    "abstract": "Uncertainty Quantification (UQ) in Language Models (LMs) is crucial for\nimproving their safety and reliability. Evaluations often use performance\nmetrics like AUROC to assess how well UQ methods (e.g., negative sequence\nprobabilities) correlate with task correctness functions (e.g., ROUGE-L). In\nthis paper, we show that commonly used correctness functions bias UQ\nevaluations by inflating the performance of certain UQ methods. We evaluate 7\ncorrectness functions -- from lexical-based and embedding-based metrics to\nLLM-as-a-judge approaches -- across 4 datasets x 4 models x 6 UQ methods. Our\nanalysis reveals that length biases in the errors of these correctness\nfunctions distort UQ assessments by interacting with length biases in UQ\nmethods. We identify LLM-as-a-judge approaches as among the least length-biased\nchoices and hence a potential solution to mitigate these biases.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.13677v1",
    "published_date": "2025-04-18 13:13:42 UTC",
    "updated_date": "2025-04-18 13:13:42 UTC"
  },
  {
    "arxiv_id": "2504.13676v1",
    "title": "Trace Gadgets: Minimizing Code Context for Machine Learning-Based Vulnerability Prediction",
    "authors": [
      "Felix Mächtle",
      "Nils Loose",
      "Tim Schulz",
      "Florian Sieck",
      "Jan-Niclas Serr",
      "Ralf Möller",
      "Thomas Eisenbarth"
    ],
    "abstract": "As the number of web applications and API endpoints exposed to the Internet\ncontinues to grow, so does the number of exploitable vulnerabilities. Manually\nidentifying such vulnerabilities is tedious. Meanwhile, static security\nscanners tend to produce many false positives. While machine learning-based\napproaches are promising, they typically perform well only in scenarios where\ntraining and test data are closely related. A key challenge for ML-based\nvulnerability detection is providing suitable and concise code context, as\nexcessively long contexts negatively affect the code comprehension capabilities\nof machine learning models, particularly smaller ones.\n  This work introduces Trace Gadgets, a novel code representation that\nminimizes code context by removing non-related code. Trace Gadgets precisely\ncapture the statements that cover the path to the vulnerability. As input for\nML models, Trace Gadgets provide a minimal but complete context, thereby\nimproving the detection performance. Moreover, we collect a large-scale dataset\ngenerated from real-world applications with manually curated labels to further\nimprove the performance of ML-based vulnerability detectors. Our results show\nthat state-of-the-art machine learning models perform best when using Trace\nGadgets compared to previous code representations, surpassing the detection\ncapabilities of industry-standard static scanners such as GitHub's CodeQL by at\nleast 4% on a fully unseen dataset. By applying our framework to real-world\napplications, we identify and report previously unknown vulnerabilities in\nwidely deployed software.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.13676v1",
    "published_date": "2025-04-18 13:13:39 UTC",
    "updated_date": "2025-04-18 13:13:39 UTC"
  },
  {
    "arxiv_id": "2504.13667v1",
    "title": "Large Language Models Will Change The Way Children Think About Technology And Impact Every Interaction Paradigm",
    "authors": [
      "Russell Beale"
    ],
    "abstract": "This paper presents a hopeful perspective on the potentially dramatic impacts\nof Large Language Models on how we children learn and how they will expect to\ninteract with technology. We review the effects of LLMs on education so far,\nand make the case that these effects are minor compared to the upcoming changes\nthat are occurring. We present a small scenario and self-ethnographic study\ndemonstrating the effects of these changes, and define five significant\nconsiderations that interactive systems designers will have to accommodate in\nthe future.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.HC",
    "comment": "Accepted for IDC 2025. Citation: Russell Beale. 2025. Large Language\n  Models Will Change The Way Children Think About Technology And Impact Every\n  Interaction Paradigm. In Proceedings of Interaction Design and Children\n  Conference (IDC2025). ACM, New York, NY, USA",
    "pdf_url": "http://arxiv.org/pdf/2504.13667v1",
    "published_date": "2025-04-18 13:01:27 UTC",
    "updated_date": "2025-04-18 13:01:27 UTC"
  },
  {
    "arxiv_id": "2504.13656v1",
    "title": "Do Prompt Patterns Affect Code Quality? A First Empirical Assessment of ChatGPT-Generated Code",
    "authors": [
      "Antonio Della Porta",
      "Stefano Lambiase",
      "Fabio Palomba"
    ],
    "abstract": "Large Language Models (LLMs) have rapidly transformed software development,\nespecially in code generation. However, their inconsistent performance, prone\nto hallucinations and quality issues, complicates program comprehension and\nhinders maintainability. Research indicates that prompt engineering-the\npractice of designing inputs to direct LLMs toward generating relevant\noutputs-may help address these challenges. In this regard, researchers have\nintroduced prompt patterns, structured templates intended to guide users in\nformulating their requests. However, the influence of prompt patterns on code\nquality has yet to be thoroughly investigated. An improved understanding of\nthis relationship would be essential to advancing our collective knowledge on\nhow to effectively use LLMs for code generation, thereby enhancing their\nunderstandability in contemporary software development. This paper empirically\ninvestigates the impact of prompt patterns on code quality, specifically\nmaintainability, security, and reliability, using the Dev-GPT dataset. Results\nshow that Zero-Shot prompting is most common, followed by Zero-Shot with\nChain-of-Thought and Few-Shot. Analysis of 7583 code files across quality\nmetrics revealed minimal issues, with Kruskal-Wallis tests indicating no\nsignificant differences among patterns, suggesting that prompt structure may\nnot substantially impact these quality metrics in ChatGPT-assisted code\ngeneration.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.13656v1",
    "published_date": "2025-04-18 12:37:02 UTC",
    "updated_date": "2025-04-18 12:37:02 UTC"
  },
  {
    "arxiv_id": "2504.13655v1",
    "title": "Multi-Type Context-Aware Conversational Recommender Systems via Mixture-of-Experts",
    "authors": [
      "Jie Zou",
      "Cheng Lin",
      "Weikang Guo",
      "Zheng Wang",
      "Jiwei Wei",
      "Yang Yang",
      "Hengtao Shen"
    ],
    "abstract": "Conversational recommender systems enable natural language conversations and\nthus lead to a more engaging and effective recommendation scenario. As the\nconversations for recommender systems usually contain limited contextual\ninformation, many existing conversational recommender systems incorporate\nexternal sources to enrich the contextual information. However, how to combine\ndifferent types of contextual information is still a challenge. In this paper,\nwe propose a multi-type context-aware conversational recommender system, called\nMCCRS, effectively fusing multi-type contextual information via\nmixture-of-experts to improve conversational recommender systems. MCCRS\nincorporates both structured information and unstructured information,\nincluding the structured knowledge graph, unstructured conversation history,\nand unstructured item reviews. It consists of several experts, with each expert\nspecialized in a particular domain (i.e., one specific contextual information).\nMultiple experts are then coordinated by a ChairBot to generate the final\nresults. Our proposed MCCRS model takes advantage of different contextual\ninformation and the specialization of different experts followed by a ChairBot\nbreaks the model bottleneck on a single contextual information. Experimental\nresults demonstrate that our proposed MCCRS method achieves significantly\nhigher performance compared to existing baselines.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "30 pages",
    "pdf_url": "http://arxiv.org/pdf/2504.13655v1",
    "published_date": "2025-04-18 12:28:38 UTC",
    "updated_date": "2025-04-18 12:28:38 UTC"
  },
  {
    "arxiv_id": "2504.13647v1",
    "title": "Lightweight LiDAR-Camera 3D Dynamic Object Detection and Multi-Class Trajectory Prediction",
    "authors": [
      "Yushen He",
      "Lei Zhao",
      "Tianchen Deng",
      "Zipeng Fang",
      "Weidong Chen"
    ],
    "abstract": "Service mobile robots are often required to avoid dynamic objects while\nperforming their tasks, but they usually have only limited computational\nresources. So we present a lightweight multi-modal framework for 3D object\ndetection and trajectory prediction. Our system synergistically integrates\nLiDAR and camera inputs to achieve real-time perception of pedestrians,\nvehicles, and riders in 3D space. The framework proposes two novel modules: 1)\na Cross-Modal Deformable Transformer (CMDT) for object detection with high\naccuracy and acceptable amount of computation, and 2) a Reference\nTrajectory-based Multi-Class Transformer (RTMCT) for efficient and diverse\ntrajectory prediction of mult-class objects with flexible trajectory lengths.\nEvaluations on the CODa benchmark demonstrate superior performance over\nexisting methods across detection (+2.03% in mAP) and trajectory prediction\n(-0.408m in minADE5 of pedestrians) metrics. Remarkably, the system exhibits\nexceptional deployability - when implemented on a wheelchair robot with an\nentry-level NVIDIA 3060 GPU, it achieves real-time inference at 13.2 fps. To\nfacilitate reproducibility and practical deployment, we release the related\ncode of the method at https://github.com/TossherO/3D_Perception and its ROS\ninference version at https://github.com/TossherO/ros_packages.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.13647v1",
    "published_date": "2025-04-18 11:59:34 UTC",
    "updated_date": "2025-04-18 11:59:34 UTC"
  },
  {
    "arxiv_id": "2504.13644v1",
    "title": "Exploring the Potential for Large Language Models to Demonstrate Rational Probabilistic Beliefs",
    "authors": [
      "Gabriel Freedman",
      "Francesca Toni"
    ],
    "abstract": "Advances in the general capabilities of large language models (LLMs) have led\nto their use for information retrieval, and as components in automated decision\nsystems. A faithful representation of probabilistic reasoning in these models\nmay be essential to ensure trustworthy, explainable and effective performance\nin these tasks. Despite previous work suggesting that LLMs can perform complex\nreasoning and well-calibrated uncertainty quantification, we find that current\nversions of this class of model lack the ability to provide rational and\ncoherent representations of probabilistic beliefs. To demonstrate this, we\nintroduce a novel dataset of claims with indeterminate truth values and apply a\nnumber of well-established techniques for uncertainty quantification to measure\nthe ability of LLM's to adhere to fundamental properties of probabilistic\nreasoning.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "8 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.13644v1",
    "published_date": "2025-04-18 11:50:30 UTC",
    "updated_date": "2025-04-18 11:50:30 UTC"
  },
  {
    "arxiv_id": "2504.13988v1",
    "title": "Going Whole Hog: A Philosophical Defense of AI Cognition",
    "authors": [
      "Herman Cappelen",
      "Josh Dever"
    ],
    "abstract": "This work defends the 'Whole Hog Thesis': sophisticated Large Language Models\n(LLMs) like ChatGPT are full-blown linguistic and cognitive agents, possessing\nunderstanding, beliefs, desires, knowledge, and intentions. We argue against\nprevailing methodologies in AI philosophy, rejecting starting points based on\nlow-level computational details ('Just an X' fallacy) or pre-existing theories\nof mind. Instead, we advocate starting with simple, high-level observations of\nLLM behavior (e.g., answering questions, making suggestions) -- defending this\ndata against charges of metaphor, loose talk, or pretense. From these\nobservations, we employ 'Holistic Network Assumptions' -- plausible connections\nbetween mental capacities (e.g., answering implies knowledge, knowledge implies\nbelief, action implies intention) -- to argue for the full suite of cognitive\nstates. We systematically rebut objections based on LLM failures\n(hallucinations, planning/reasoning errors), arguing these don't preclude\nagency, often mirroring human fallibility. We address numerous 'Games of\nLacks', arguing that LLMs do not lack purported necessary conditions for\ncognition (e.g., semantic grounding, embodiment, justification, intrinsic\nintentionality) or that these conditions are not truly necessary, often relying\non anti-discriminatory arguments comparing LLMs to diverse human capacities.\nOur approach is evidential, not functionalist, and deliberately excludes\nconsciousness. We conclude by speculating on the possibility of LLMs possessing\n'alien' contents beyond human conceptual schemes.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.13988v1",
    "published_date": "2025-04-18 11:36:25 UTC",
    "updated_date": "2025-04-18 11:36:25 UTC"
  },
  {
    "arxiv_id": "2504.13631v1",
    "title": "Multi-modal Knowledge Graph Generation with Semantics-enriched Prompts",
    "authors": [
      "Yajing Xu",
      "Zhiqiang Liu",
      "Jiaoyan Chen",
      "Mingchen Tu",
      "Zhuo Chen",
      "Jeff Z. Pan",
      "Yichi Zhang",
      "Yushan Zhu",
      "Wen Zhang",
      "Huajun Chen"
    ],
    "abstract": "Multi-modal Knowledge Graphs (MMKGs) have been widely applied across various\ndomains for knowledge representation. However, the existing MMKGs are\nsignificantly fewer than required, and their construction faces numerous\nchallenges, particularly in ensuring the selection of high-quality,\ncontextually relevant images for knowledge graph enrichment. To address these\nchallenges, we present a framework for constructing MMKGs from conventional\nKGs. Furthermore, to generate higher-quality images that are more relevant to\nthe context in the given knowledge graph, we designed a neighbor selection\nmethod called Visualizable Structural Neighbor Selection (VSNS). This method\nconsists of two modules: Visualizable Neighbor Selection (VNS) and Structural\nNeighbor Selection (SNS). The VNS module filters relations that are difficult\nto visualize, while the SNS module selects neighbors that most effectively\ncapture the structural characteristics of the entity. To evaluate the quality\nof the generated images, we performed qualitative and quantitative evaluations\non two datasets, MKG-Y and DB15K. The experimental results indicate that using\nthe VSNS method to select neighbors results in higher-quality images that are\nmore relevant to the knowledge graph.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted by IJCNN 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.13631v1",
    "published_date": "2025-04-18 11:12:49 UTC",
    "updated_date": "2025-04-18 11:12:49 UTC"
  },
  {
    "arxiv_id": "2504.13629v1",
    "title": "Divergent LLM Adoption and Heterogeneous Convergence Paths in Research Writing",
    "authors": [
      "Cong William Lin",
      "Wu Zhu"
    ],
    "abstract": "Large Language Models (LLMs), such as ChatGPT, are reshaping content creation\nand academic writing. This study investigates the impact of AI-assisted\ngenerative revisions on research manuscripts, focusing on heterogeneous\nadoption patterns and their influence on writing convergence. Leveraging a\ndataset of over 627,000 academic papers from arXiv, we develop a novel\nclassification framework by fine-tuning prompt- and discipline-specific large\nlanguage models to detect the style of ChatGPT-revised texts. Our findings\nreveal substantial disparities in LLM adoption across academic disciplines,\ngender, native language status, and career stage, alongside a rapid evolution\nin scholarly writing styles. Moreover, LLM usage enhances clarity, conciseness,\nand adherence to formal writing conventions, with improvements varying by\nrevision type. Finally, a difference-in-differences analysis shows that while\nLLMs drive convergence in academic writing, early adopters, male researchers,\nnon-native speakers, and junior scholars exhibit the most pronounced stylistic\nshifts, aligning their writing more closely with that of established\nresearchers.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "econ.GN",
      "q-fin.EC"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.13629v1",
    "published_date": "2025-04-18 11:09:16 UTC",
    "updated_date": "2025-04-18 11:09:16 UTC"
  },
  {
    "arxiv_id": "2504.13626v1",
    "title": "Thought Manipulation: External Thought Can Be Efficient for Large Reasoning Models",
    "authors": [
      "Yule Liu",
      "Jingyi Zheng",
      "Zhen Sun",
      "Zifan Peng",
      "Wenhan Dong",
      "Zeyang Sha",
      "Shiwen Cui",
      "Weiqiang Wang",
      "Xinlei He"
    ],
    "abstract": "Recent advancements in large reasoning models (LRMs) have demonstrated the\neffectiveness of scaling test-time computation to enhance reasoning\ncapabilities in multiple tasks. However, LRMs typically suffer from\n\"overthinking\" problems, where models generate significantly redundant\nreasoning steps while bringing limited performance gains. Existing work relies\non fine-tuning to mitigate overthinking, which requires additional data,\nunconventional training setups, risky safety misalignment, and poor\ngeneralization.\n  Through empirical analysis, we reveal an important characteristic of LRM\nbehaviors that placing external CoTs generated by smaller models between the\nthinking token ($\\texttt{<think>}$ and $\\texttt{</think>)}$ can effectively\nmanipulate the model to generate fewer thoughts. Building on these insights, we\npropose a simple yet efficient pipeline, ThoughtMani, to enable LRMs to bypass\nunnecessary intermediate steps and reduce computational costs significantly. We\nconduct extensive experiments to validate the utility and efficiency of\nThoughtMani. For instance, when applied to QwQ-32B on the LiveBench/Code\ndataset, ThoughtMani keeps the original performance and reduces output token\ncounts by approximately 30%, with little overhead from the CoT generator.\nFurthermore, we find that ThoughtMani enhances safety alignment by an average\nof 10%. Since model vendors typically serve models of different sizes\nsimultaneously, ThoughtMani provides an effective way to construct more\nefficient and accessible LRMs for real-world applications.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.13626v1",
    "published_date": "2025-04-18 11:07:19 UTC",
    "updated_date": "2025-04-18 11:07:19 UTC"
  },
  {
    "arxiv_id": "2504.13614v1",
    "title": "Adaptive Long-term Embedding with Denoising and Augmentation for Recommendation",
    "authors": [
      "Zahra Akhlaghi",
      "Mostafa Haghir Chehreghani"
    ],
    "abstract": "The rapid growth of the internet has made personalized recommendation systems\nindispensable. Graph-based sequential recommendation systems, powered by Graph\nNeural Networks (GNNs), effectively capture complex user-item interactions but\noften face challenges such as noise and static representations. In this paper,\nwe introduce the Adaptive Long-term Embedding with Denoising and Augmentation\nfor Recommendation (ALDA4Rec) method, a novel model that constructs an\nitem-item graph, filters noise through community detection, and enriches\nuser-item interactions. Graph Convolutional Networks (GCNs) are then employed\nto learn short-term representations, while averaging, GRUs, and attention\nmechanisms are utilized to model long-term embeddings. An MLP-based adaptive\nweighting strategy is further incorporated to dynamically optimize long-term\nuser preferences. Experiments conducted on four real-world datasets demonstrate\nthat ALDA4Rec outperforms state-of-the-art baselines, delivering notable\nimprovements in both accuracy and robustness. The source code is available at\nhttps://github.com/zahraakhlaghi/ALDA4Rec.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.13614v1",
    "published_date": "2025-04-18 10:42:16 UTC",
    "updated_date": "2025-04-18 10:42:16 UTC"
  },
  {
    "arxiv_id": "2504.13612v2",
    "title": "Entropic Time Schedulers for Generative Diffusion Models",
    "authors": [
      "Dejan Stancevic",
      "Luca Ambrogioni"
    ],
    "abstract": "The practical performance of generative diffusion models depends on the\nappropriate choice of the noise scheduling function, which can also be\nequivalently expressed as a time reparameterization. In this paper, we present\na time scheduler that selects sampling points based on entropy rather than\nuniform time spacing, ensuring that each point contributes an equal amount of\ninformation to the final generation. We prove that this time reparameterization\ndoes not depend on the initial choice of time. Furthermore, we provide a\ntractable exact formula to estimate this \\emph{entropic time} for a trained\nmodel using the training loss without substantial overhead. Alongside the\nentropic time, inspired by the optimality results, we introduce a rescaled\nentropic time. In our experiments with mixtures of Gaussian distributions and\nImageNet, we show that using the (rescaled) entropic times greatly improves the\ninference performance of trained models. In particular, we found that the image\nquality in pretrained EDM2 models, as evaluated by FID and FD-DINO scores, can\nbe substantially increased by the rescaled entropic time reparameterization\nwithout increasing the number of function evaluations, with greater\nimprovements in the few NFEs regime.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "17 pages",
    "pdf_url": "http://arxiv.org/pdf/2504.13612v2",
    "published_date": "2025-04-18 10:35:19 UTC",
    "updated_date": "2025-05-04 11:04:09 UTC"
  },
  {
    "arxiv_id": "2504.13987v1",
    "title": "Entropy Rectifying Guidance for Diffusion and Flow Models",
    "authors": [
      "Tariq Berrada Ifriqi",
      "Adriana Romero-Soriano",
      "Michal Drozdzal",
      "Jakob Verbeek",
      "Karteek Alahari"
    ],
    "abstract": "Guidance techniques are commonly used in diffusion and flow models to improve\nimage quality and consistency for conditional generative tasks such as\nclass-conditional and text-to-image generation. In particular, classifier-free\nguidance (CFG) -- the most widely adopted guidance technique -- contrasts\nconditional and unconditional predictions to improve the generated images. This\nresults, however, in trade-offs across quality, diversity and consistency,\nimproving some at the expense of others. While recent work has shown that it is\npossible to disentangle these factors to some extent, such methods come with an\noverhead of requiring an additional (weaker) model, or require more forward\npasses per sampling step. In this paper, we propose Entropy Rectifying Guidance\n(ERG), a simple and effective guidance mechanism based on inference-time\nchanges in the attention mechanism of state-of-the-art diffusion transformer\narchitectures, which allows for simultaneous improvements over image quality,\ndiversity and prompt consistency. ERG is more general than CFG and similar\nguidance techniques, as it extends to unconditional sampling. ERG results in\nsignificant improvements in various generation tasks such as text-to-image,\nclass-conditional and unconditional image generation. We also show that ERG can\nbe seamlessly combined with other recent guidance methods such as CADS and APG,\nfurther boosting generation performance.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.13987v1",
    "published_date": "2025-04-18 10:15:33 UTC",
    "updated_date": "2025-04-18 10:15:33 UTC"
  },
  {
    "arxiv_id": "2504.13986v2",
    "title": "Forgetting in short and heterogeneous sequences of belief revisions",
    "authors": [
      "Paolo Liberatore"
    ],
    "abstract": "Forgetting a specific belief revision episode may not erase information\nbecause the other revisions may provide or entail the same information. Whether\nit does was proved coNP-hard for sequences of two arbitrary lexicographic\nrevisions or arbitrarily long lexicographic Horn revisions. A polynomial\nalgorithm is presented for the case of two lexicographic Horn revision.\nHeterogeneous sequences, including revisions other than lexicographic, were\nproved to belong in Delta2. Their previously proved coNP-hardness is enhanced\nto Dp-hardness.",
    "categories": [
      "cs.CC",
      "cs.AI"
    ],
    "primary_category": "cs.CC",
    "comment": "arXiv admin note: substantial text overlap with arXiv:2402.15445,\n  arXiv:2305.09200",
    "pdf_url": "http://arxiv.org/pdf/2504.13986v2",
    "published_date": "2025-04-18 10:12:04 UTC",
    "updated_date": "2025-05-16 12:04:13 UTC"
  },
  {
    "arxiv_id": "2504.13597v1",
    "title": "FocusNet: Transformer-enhanced Polyp Segmentation with Local and Pooling Attention",
    "authors": [
      "Jun Zeng",
      "KC Santosh",
      "Deepak Rajan Nayak",
      "Thomas de Lange",
      "Jonas Varkey",
      "Tyler Berzin",
      "Debesh Jha"
    ],
    "abstract": "Colonoscopy is vital in the early diagnosis of colorectal polyps. Regular\nscreenings can effectively prevent benign polyps from progressing to CRC. While\ndeep learning has made impressive strides in polyp segmentation, most existing\nmodels are trained on single-modality and single-center data, making them less\neffective in real-world clinical environments. To overcome these limitations,\nwe propose FocusNet, a Transformer-enhanced focus attention network designed to\nimprove polyp segmentation. FocusNet incorporates three essential modules: the\nCross-semantic Interaction Decoder Module (CIDM) for generating coarse\nsegmentation maps, the Detail Enhancement Module (DEM) for refining shallow\nfeatures, and the Focus Attention Module (FAM), to balance local detail and\nglobal context through local and pooling attention mechanisms. We evaluate our\nmodel on PolypDB, a newly introduced dataset with multi-modality and\nmulti-center data for building more reliable segmentation methods. Extensive\nexperiments showed that FocusNet consistently outperforms existing\nstate-of-the-art approaches with a high dice coefficients of 82.47% on the BLI\nmodality, 88.46% on FICE, 92.04% on LCI, 82.09% on the NBI and 93.42% on WLI\nmodality, demonstrating its accuracy and robustness across five different\nmodalities. The source code for FocusNet is available at\nhttps://github.com/JunZengz/FocusNet.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "9 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.13597v1",
    "published_date": "2025-04-18 09:59:26 UTC",
    "updated_date": "2025-04-18 09:59:26 UTC"
  },
  {
    "arxiv_id": "2504.17801v1",
    "title": "Evolution of Optimization Algorithms for Global Placement via Large Language Models",
    "authors": [
      "Xufeng Yao",
      "Jiaxi Jiang",
      "Yuxuan Zhao",
      "Peiyu Liao",
      "Yibo Lin",
      "Bei Yu"
    ],
    "abstract": "Optimization algorithms are widely employed to tackle complex problems, but\ndesigning them manually is often labor-intensive and requires significant\nexpertise. Global placement is a fundamental step in electronic design\nautomation (EDA). While analytical approaches represent the state-of-the-art\n(SOTA) in global placement, their core optimization algorithms remain heavily\ndependent on heuristics and customized components, such as initialization\nstrategies, preconditioning methods, and line search techniques. This paper\npresents an automated framework that leverages large language models (LLM) to\nevolve optimization algorithms for global placement. We first generate diverse\ncandidate algorithms using LLM through carefully crafted prompts. Then we\nintroduce an LLM-based genetic flow to evolve selected candidate algorithms.\nThe discovered optimization algorithms exhibit substantial performance\nimprovements across many benchmarks. Specifically, Our design-case-specific\ndiscovered algorithms achieve average HPWL improvements of \\textbf{5.05\\%},\n\\text{5.29\\%} and \\textbf{8.30\\%} on MMS, ISPD2005 and ISPD2019 benchmarks, and\nup to \\textbf{17\\%} improvements on individual cases. Additionally, the\ndiscovered algorithms demonstrate good generalization ability and are\ncomplementary to existing parameter-tuning methods.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.17801v1",
    "published_date": "2025-04-18 09:57:14 UTC",
    "updated_date": "2025-04-18 09:57:14 UTC"
  },
  {
    "arxiv_id": "2504.13590v1",
    "title": "HAECcity: Open-Vocabulary Scene Understanding of City-Scale Point Clouds with Superpoint Graph Clustering",
    "authors": [
      "Alexander Rusnak",
      "Frédéric Kaplan"
    ],
    "abstract": "Traditional 3D scene understanding techniques are generally predicated on\nhand-annotated label sets, but in recent years a new class of open-vocabulary\n3D scene understanding techniques has emerged. Despite the success of this\nparadigm on small scenes, existing approaches cannot scale efficiently to\ncity-scale 3D datasets. In this paper, we present Hierarchical vocab-Agnostic\nExpert Clustering (HAEC), after the latin word for 'these', a superpoint graph\nclustering based approach which utilizes a novel mixture of experts graph\ntransformer for its backbone. We administer this highly scalable approach to\nthe first application of open-vocabulary scene understanding on the SensatUrban\ncity-scale dataset. We also demonstrate a synthetic labeling pipeline which is\nderived entirely from the raw point clouds with no hand-annotation. Our\ntechnique can help unlock complex operations on dense urban 3D scenes and open\na new path forward in the processing of digital twins.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted for publication through the upcoming CVPR Workshop on open\n  scene understanding with foundation models (OPENSUN3D)",
    "pdf_url": "http://arxiv.org/pdf/2504.13590v1",
    "published_date": "2025-04-18 09:48:42 UTC",
    "updated_date": "2025-04-18 09:48:42 UTC"
  },
  {
    "arxiv_id": "2504.13587v1",
    "title": "RAG Without the Lag: Interactive Debugging for Retrieval-Augmented Generation Pipelines",
    "authors": [
      "Quentin Romero Lauro",
      "Shreya Shankar",
      "Sepanta Zeighami",
      "Aditya Parameswaran"
    ],
    "abstract": "Retrieval-augmented generation (RAG) pipelines have become the de-facto\napproach for building AI assistants with access to external, domain-specific\nknowledge. Given a user query, RAG pipelines typically first retrieve (R)\nrelevant information from external sources, before invoking a Large Language\nModel (LLM), augmented (A) with this information, to generate (G) responses.\nModern RAG pipelines frequently chain multiple retrieval and generation\ncomponents, in any order. However, developing effective RAG pipelines is\nchallenging because retrieval and generation components are intertwined, making\nit hard to identify which component(s) cause errors in the eventual output. The\nparameters with the greatest impact on output quality often require hours of\npre-processing after each change, creating prohibitively slow feedback cycles.\nTo address these challenges, we present RAGGY, a developer tool that combines a\nPython library of composable RAG primitives with an interactive interface for\nreal-time debugging. We contribute the design and implementation of RAGGY,\ninsights into expert debugging patterns through a qualitative study with 12\nengineers, and design implications for future RAG tools that better align with\ndevelopers' natural workflows.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "15 pages, 7 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2504.13587v1",
    "published_date": "2025-04-18 09:38:49 UTC",
    "updated_date": "2025-04-18 09:38:49 UTC"
  },
  {
    "arxiv_id": "2504.13568v1",
    "title": "MetaDSE: A Few-shot Meta-learning Framework for Cross-workload CPU Design Space Exploration",
    "authors": [
      "Runzhen Xue",
      "Hao Wu",
      "Mingyu Yan",
      "Ziheng Xiao",
      "Xiaochun Ye",
      "Dongrui Fan"
    ],
    "abstract": "Cross-workload design space exploration (DSE) is crucial in CPU architecture\ndesign. Existing DSE methods typically employ the transfer learning technique\nto leverage knowledge from source workloads, aiming to minimize the requirement\nof target workload simulation. However, these methods struggle with\noverfitting, data ambiguity, and workload dissimilarity.\n  To address these challenges, we reframe the cross-workload CPU DSE task as a\nfew-shot meta-learning problem and further introduce MetaDSE. By leveraging\nmodel agnostic meta-learning, MetaDSE swiftly adapts to new target workloads,\ngreatly enhancing the efficiency of cross-workload CPU DSE. Additionally,\nMetaDSE introduces a novel knowledge transfer method called the\nworkload-adaptive architectural mask algorithm, which uncovers the inherent\nproperties of the architecture. Experiments on SPEC CPU 2017 demonstrate that\nMetaDSE significantly reduces prediction error by 44.3\\% compared to the\nstate-of-the-art. MetaDSE is open-sourced and available at this\n\\href{https://anonymous.4open.science/r/Meta_DSE-02F8}{anonymous GitHub.}",
    "categories": [
      "cs.AR",
      "cs.AI"
    ],
    "primary_category": "cs.AR",
    "comment": "7 pages, 6 figures. Accepted by DAC 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.13568v1",
    "published_date": "2025-04-18 09:11:16 UTC",
    "updated_date": "2025-04-18 09:11:16 UTC"
  },
  {
    "arxiv_id": "2504.15303v1",
    "title": "High-Throughput LLM inference on Heterogeneous Clusters",
    "authors": [
      "Yi Xiong",
      "Jinqi Huang",
      "Wenjie Huang",
      "Xuebing Yu",
      "Entong Li",
      "Zhixiong Ning",
      "Jinhua Zhou",
      "Li Zeng",
      "Xin Chen"
    ],
    "abstract": "Nowadays, many companies possess various types of AI accelerators, forming\nheterogeneous clusters. Efficiently leveraging these clusters for\nhigh-throughput large language model (LLM) inference services can significantly\nreduce costs and expedite task processing. However, LLM inference on\nheterogeneous clusters presents two main challenges. Firstly, different\ndeployment configurations can result in vastly different performance. The\nnumber of possible configurations is large, and evaluating the effectiveness of\na specific setup is complex. Thus, finding an optimal configuration is not an\neasy task. Secondly, LLM inference instances within a heterogeneous cluster\npossess varying processing capacities, leading to different processing speeds\nfor handling inference requests. Evaluating these capacities and designing a\nrequest scheduling algorithm that fully maximizes the potential of each\ninstance is challenging. In this paper, we propose a high-throughput inference\nservice system on heterogeneous clusters. First, the deployment configuration\nis optimized by modeling the resource amount and expected throughput and using\nthe exhaustive search method. Second, a novel mechanism is proposed to schedule\nrequests among instances, which fully considers the different processing\ncapabilities of various instances. Extensive experiments show that the proposed\nscheduler improves throughput by 122.5% and 33.6% on two heterogeneous\nclusters, respectively.",
    "categories": [
      "cs.DC",
      "cs.AI"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15303v1",
    "published_date": "2025-04-18 08:59:11 UTC",
    "updated_date": "2025-04-18 08:59:11 UTC"
  },
  {
    "arxiv_id": "2504.13560v1",
    "title": "Zero-Shot Industrial Anomaly Segmentation with Image-Aware Prompt Generation",
    "authors": [
      "SoYoung Park",
      "Hyewon Lee",
      "Mingyu Choi",
      "Seunghoon Han",
      "Jong-Ryul Lee",
      "Sungsu Lim",
      "Tae-Ho Kim"
    ],
    "abstract": "Anomaly segmentation is essential for industrial quality, maintenance, and\nstability. Existing text-guided zero-shot anomaly segmentation models are\neffective but rely on fixed prompts, limiting adaptability in diverse\nindustrial scenarios. This highlights the need for flexible, context-aware\nprompting strategies. We propose Image-Aware Prompt Anomaly Segmentation\n(IAP-AS), which enhances anomaly segmentation by generating dynamic,\ncontext-aware prompts using an image tagging model and a large language model\n(LLM). IAP-AS extracts object attributes from images to generate context-aware\nprompts, improving adaptability and generalization in dynamic and unstructured\nindustrial environments. In our experiments, IAP-AS improves the F1-max metric\nby up to 10%, demonstrating superior adaptability and generalization. It\nprovides a scalable solution for anomaly segmentation across industries",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to PAKDD 2025, 12 pages",
    "pdf_url": "http://arxiv.org/pdf/2504.13560v1",
    "published_date": "2025-04-18 08:58:40 UTC",
    "updated_date": "2025-04-18 08:58:40 UTC"
  },
  {
    "arxiv_id": "2504.13558v1",
    "title": "Transformers Can Overcome the Curse of Dimensionality: A Theoretical Study from an Approximation Perspective",
    "authors": [
      "Yuling Jiao",
      "Yanming Lai",
      "Yang Wang",
      "Bokai Yan"
    ],
    "abstract": "The Transformer model is widely used in various application areas of machine\nlearning, such as natural language processing. This paper investigates the\napproximation of the H\\\"older continuous function class\n$\\mathcal{H}_{Q}^{\\beta}\\left([0,1]^{d\\times n},\\mathbb{R}^{d\\times n}\\right)$\nby Transformers and constructs several Transformers that can overcome the curse\nof dimensionality. These Transformers consist of one self-attention layer with\none head and the softmax function as the activation function, along with\nseveral feedforward layers. For example, to achieve an approximation accuracy\nof $\\epsilon$, if the activation functions of the feedforward layers in the\nTransformer are ReLU and floor, only\n$\\mathcal{O}\\left(\\log\\frac{1}{\\epsilon}\\right)$ layers of feedforward layers\nare needed, with widths of these layers not exceeding\n$\\mathcal{O}\\left(\\frac{1}{\\epsilon^{2/\\beta}}\\log\\frac{1}{\\epsilon}\\right)$.\nIf other activation functions are allowed in the feedforward layers, the width\nof the feedforward layers can be further reduced to a constant. These results\ndemonstrate that Transformers have a strong expressive capability. The\nconstruction in this paper is based on the Kolmogorov-Arnold Representation\nTheorem and does not require the concept of contextual mapping, hence our proof\nis more intuitively clear compared to previous Transformer approximation works.\nAdditionally, the translation technique proposed in this paper helps to apply\nthe previous approximation results of feedforward neural networks to\nTransformer research.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "41A25, 68T07, 68T50",
      "G.0"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.13558v1",
    "published_date": "2025-04-18 08:56:53 UTC",
    "updated_date": "2025-04-18 08:56:53 UTC"
  },
  {
    "arxiv_id": "2504.16113v2",
    "title": "AI-Based Vulnerability Analysis of NFT Smart Contracts",
    "authors": [
      "Xin Wang",
      "Xiaoqi Li"
    ],
    "abstract": "With the rapid growth of the NFT market, the security of smart contracts has\nbecome crucial. However, existing AI-based detection models for NFT contract\nvulnerabilities remain limited due to their complexity, while traditional\nmanual methods are time-consuming and costly. This study proposes an AI-driven\napproach to detect vulnerabilities in NFT smart contracts.\n  We collected 16,527 public smart contract codes, classifying them into five\nvulnerability categories: Risky Mutable Proxy, ERC-721 Reentrancy, Unlimited\nMinting, Missing Requirements, and Public Burn. Python-processed data was\nstructured into training/test sets. Using the CART algorithm with Gini\ncoefficient evaluation, we built initial decision trees for feature extraction.\nA random forest model was implemented to improve robustness through random\ndata/feature sampling and multitree integration. GridSearch hyperparameter\ntuning further optimized the model, with 3D visualizations demonstrating\nparameter impacts on vulnerability detection.\n  Results show the random forest model excels in detecting all five\nvulnerabilities. For example, it identifies Risky Mutable Proxy by analyzing\nauthorization mechanisms and state modifications, while ERC-721 Reentrancy\ndetection relies on external call locations and lock mechanisms. The ensemble\napproach effectively reduces single-tree overfitting, with stable performance\nimprovements after parameter tuning. This method provides an efficient\ntechnical solution for automated NFT contract detection and lays groundwork for\nscaling AI applications.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16113v2",
    "published_date": "2025-04-18 08:55:31 UTC",
    "updated_date": "2025-04-24 08:25:20 UTC"
  },
  {
    "arxiv_id": "2504.13554v1",
    "title": "Task Assignment and Exploration Optimization for Low Altitude UAV Rescue via Generative AI Enhanced Multi-agent Reinforcement Learning",
    "authors": [
      "Xin Tang",
      "Qian Chen",
      "Wenjie Weng",
      "Chao Jin",
      "Zhang Liu",
      "Jiacheng Wang",
      "Geng Sun",
      "Xiaohuan Li",
      "Dusit Niyato"
    ],
    "abstract": "Artificial Intelligence (AI)-driven convolutional neural networks enhance\nrescue, inspection, and surveillance tasks performed by low-altitude uncrewed\naerial vehicles (UAVs) and ground computing nodes (GCNs) in unknown\nenvironments. However, their high computational demands often exceed a single\nUAV's capacity, leading to system instability, further exacerbated by the\nlimited and dynamic resources of GCNs. To address these challenges, this paper\nproposes a novel cooperation framework involving UAVs, ground-embedded robots\n(GERs), and high-altitude platforms (HAPs), which enable resource pooling\nthrough UAV-to-GER (U2G) and UAV-to-HAP (U2H) communications to provide\ncomputing services for UAV offloaded tasks. Specifically, we formulate the\nmulti-objective optimization problem of task assignment and exploration\noptimization in UAVs as a dynamic long-term optimization problem. Our objective\nis to minimize task completion time and energy consumption while ensuring\nsystem stability over time. To achieve this, we first employ the Lyapunov\noptimization technique to transform the original problem, with stability\nconstraints, into a per-slot deterministic problem. We then propose an\nalgorithm named HG-MADDPG, which combines the Hungarian algorithm with a\ngenerative diffusion model (GDM)-based multi-agent deep deterministic policy\ngradient (MADDPG) approach. We first introduce the Hungarian algorithm as a\nmethod for exploration area selection, enhancing UAV efficiency in interacting\nwith the environment. We then innovatively integrate the GDM and multi-agent\ndeep deterministic policy gradient (MADDPG) to optimize task assignment\ndecisions, such as task offloading and resource allocation. Simulation results\ndemonstrate the effectiveness of the proposed approach, with significant\nimprovements in task offloading efficiency, latency reduction, and system\nstability compared to baseline methods.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.13554v1",
    "published_date": "2025-04-18 08:44:06 UTC",
    "updated_date": "2025-04-18 08:44:06 UTC"
  },
  {
    "arxiv_id": "2504.13551v1",
    "title": "Q-FAKER: Query-free Hard Black-box Attack via Controlled Generation",
    "authors": [
      "CheolWon Na",
      "YunSeok Choi",
      "Jee-Hyong Lee"
    ],
    "abstract": "Many adversarial attack approaches are proposed to verify the vulnerability\nof language models. However, they require numerous queries and the information\non the target model. Even black-box attack methods also require the target\nmodel's output information. They are not applicable in real-world scenarios, as\nin hard black-box settings where the target model is closed and inaccessible.\nEven the recently proposed hard black-box attacks still require many queries\nand demand extremely high costs for training adversarial generators. To address\nthese challenges, we propose Q-faker (Query-free Hard Black-box Attacker), a\nnovel and efficient method that generates adversarial examples without\naccessing the target model. To avoid accessing the target model, we use a\nsurrogate model instead. The surrogate model generates adversarial sentences\nfor a target-agnostic attack. During this process, we leverage controlled\ngeneration techniques. We evaluate our proposed method on eight datasets.\nExperimental results demonstrate our method's effectiveness including high\ntransferability and the high quality of the generated adversarial examples, and\nprove its practical in hard black-box settings.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CR",
    "comment": "NAACL 2025 Findings",
    "pdf_url": "http://arxiv.org/pdf/2504.13551v1",
    "published_date": "2025-04-18 08:36:38 UTC",
    "updated_date": "2025-04-18 08:36:38 UTC"
  },
  {
    "arxiv_id": "2504.13548v1",
    "title": "Beyond One-Hot Labels: Semantic Mixing for Model Calibration",
    "authors": [
      "Haoyang Luo",
      "Linwei Tao",
      "Minjing Dong",
      "Chang Xu"
    ],
    "abstract": "Model calibration seeks to ensure that models produce confidence scores that\naccurately reflect the true likelihood of their predictions being correct.\nHowever, existing calibration approaches are fundamentally tied to datasets of\none-hot labels implicitly assuming full certainty in all the annotations. Such\ndatasets are effective for classification but provides insufficient knowledge\nof uncertainty for model calibration, necessitating the curation of datasets\nwith numerically rich ground-truth confidence values. However, due to the\nscarcity of uncertain visual examples, such samples are not easily available as\nreal datasets. In this paper, we introduce calibration-aware data augmentation\nto create synthetic datasets of diverse samples and their ground-truth\nuncertainty. Specifically, we present Calibration-aware Semantic Mixing (CSM),\na novel framework that generates training samples with mixed class\ncharacteristics and annotates them with distinct confidence scores via\ndiffusion models. Based on this framework, we propose calibrated reannotation\nto tackle the misalignment between the annotated confidence score and the\nmixing ratio during the diffusion reverse process. Besides, we explore the loss\nfunctions that better fit the new data representation paradigm. Experimental\nresults demonstrate that CSM achieves superior calibration compared to the\nstate-of-the-art calibration approaches. Code is available at\ngithub.com/E-Galois/CSM.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.13548v1",
    "published_date": "2025-04-18 08:26:18 UTC",
    "updated_date": "2025-04-18 08:26:18 UTC"
  },
  {
    "arxiv_id": "2504.13545v1",
    "title": "Enhancing Multilingual Sentiment Analysis with Explainability for Sinhala, English, and Code-Mixed Content",
    "authors": [
      "Azmarah Rizvi",
      "Navojith Thamindu",
      "A. M. N. H. Adhikari",
      "W. P. U. Senevirathna",
      "Dharshana Kasthurirathna",
      "Lakmini Abeywardhana"
    ],
    "abstract": "Sentiment analysis is crucial for brand reputation management in the banking\nsector, where customer feedback spans English, Sinhala, Singlish, and\ncode-mixed text. Existing models struggle with low-resource languages like\nSinhala and lack interpretability for practical use. This research develops a\nhybrid aspect-based sentiment analysis framework that enhances multilingual\ncapabilities with explainable outputs. Using cleaned banking customer reviews,\nwe fine-tune XLM-RoBERTa for Sinhala and code-mixed text, integrate\ndomain-specific lexicon correction, and employ BERT-base-uncased for English.\nThe system classifies sentiment (positive, neutral, negative) with confidence\nscores, while SHAP and LIME improve interpretability by providing real-time\nsentiment explanations. Experimental results show that our approaches\noutperform traditional transformer-based classifiers, achieving 92.3 percent\naccuracy and an F1-score of 0.89 in English and 88.4 percent in Sinhala and\ncode-mixed content. An explainability analysis reveals key sentiment drivers,\nimproving trust and transparency. A user-friendly interface delivers\naspect-wise sentiment insights, ensuring accessibility for businesses. This\nresearch contributes to robust, transparent sentiment analysis for financial\napplications by bridging gaps in multilingual, low-resource NLP and\nexplainability.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "6 pages, 6 figures, 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2504.13545v1",
    "published_date": "2025-04-18 08:21:12 UTC",
    "updated_date": "2025-04-18 08:21:12 UTC"
  },
  {
    "arxiv_id": "2504.13541v1",
    "title": "SwitchMT: An Adaptive Context Switching Methodology for Scalable Multi-Task Learning in Intelligent Autonomous Agents",
    "authors": [
      "Avaneesh Devkota",
      "Rachmad Vidya Wicaksana Putra",
      "Muhammad Shafique"
    ],
    "abstract": "The ability to train intelligent autonomous agents (such as mobile robots) on\nmultiple tasks is crucial for adapting to dynamic real-world environments.\nHowever, state-of-the-art reinforcement learning (RL) methods only excel in\nsingle-task settings, and still struggle to generalize across multiple tasks\ndue to task interference. Moreover, real-world environments also demand the\nagents to have data stream processing capabilities. Toward this, a\nstate-of-the-art work employs Spiking Neural Networks (SNNs) to improve\nmulti-task learning by exploiting temporal information in data stream, while\nenabling lowpower/energy event-based operations. However, it relies on fixed\ncontext/task-switching intervals during its training, hence limiting the\nscalability and effectiveness of multi-task learning. To address these\nlimitations, we propose SwitchMT, a novel adaptive task-switching methodology\nfor RL-based multi-task learning in autonomous agents. Specifically, SwitchMT\nemploys the following key ideas: (1) a Deep Spiking Q-Network with active\ndendrites and dueling structure, that utilizes task-specific context signals to\ncreate specialized sub-networks; and (2) an adaptive task-switching policy that\nleverages both rewards and internal dynamics of the network parameters.\nExperimental results demonstrate that SwitchMT achieves superior performance in\nmulti-task learning compared to state-of-the-art methods. It achieves\ncompetitive scores in multiple Atari games (i.e., Pong: -8.8, Breakout: 5.6,\nand Enduro: 355.2) compared to the state-of-the-art, showing its better\ngeneralized learning capability. These results highlight the effectiveness of\nour SwitchMT methodology in addressing task interference while enabling\nmulti-task learning automation through adaptive task switching, thereby paving\nthe way for more efficient generalist agents with scalable multi-task learning\ncapabilities.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.NE",
    "comment": "7 pages, 7 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2504.13541v1",
    "published_date": "2025-04-18 08:12:59 UTC",
    "updated_date": "2025-04-18 08:12:59 UTC"
  },
  {
    "arxiv_id": "2504.13984v1",
    "title": "One Jump Is All You Need: Short-Cutting Transformers for Early Exit Prediction with One Jump to Fit All Exit Levels",
    "authors": [
      "Amrit Diggavi Seshadri"
    ],
    "abstract": "To reduce the time and computational costs of inference of large language\nmodels, there has been interest in parameter-efficient low-rank early-exit\ncasting of transformer hidden-representations to final-representations. Such\nlow-rank short-cutting has been shown to outperform identity shortcuts at early\nmodel stages while offering parameter-efficiency in shortcut jumps. However,\ncurrent low-rank methods maintain a separate early-exit shortcut jump to\nfinal-representations for each transformer intermediate block-level during\ninference. In this work, we propose selection of a single One-Jump-Fits-All\n(OJFA) low-rank shortcut that offers over a 30x reduction in shortcut parameter\ncosts during inference. We show that despite this extreme reduction, our OJFA\nchoice largely matches the performance of maintaining multiple shortcut jumps\nduring inference and offers stable precision from all transformer block-levels\nfor GPT2-XL, Phi3-Mini and Llama2-7B transformer models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.13984v1",
    "published_date": "2025-04-18 08:02:40 UTC",
    "updated_date": "2025-04-18 08:02:40 UTC"
  },
  {
    "arxiv_id": "2504.13534v2",
    "title": "CoT-RAG: Integrating Chain of Thought and Retrieval-Augmented Generation to Enhance Reasoning in Large Language Models",
    "authors": [
      "Feiyang Li",
      "Peng Fang",
      "Zhan Shi",
      "Arijit Khan",
      "Fang Wang",
      "Dan Feng",
      "Weihao Wang",
      "Xin Zhang",
      "Yongjian Cui"
    ],
    "abstract": "Chain-of-thought (CoT) reasoning boosts large language models' (LLMs)\nperformance on complex tasks but faces two key limitations: a lack of\nreliability when solely relying on LLM-generated reasoning chains and\ninterference from natural language reasoning steps with the models' inference\nprocess, also known as the inference logic of LLMs. To address these issues, we\npropose CoT-RAG, a novel reasoning framework with three key designs: (i)\nKnowledge Graph-driven CoT Generation,featuring knowledge graphs to modulate\nreasoning chain generation of LLMs, thereby enhancing reasoning credibility;\n(ii) Learnable Knowledge Case-aware RAG, which incorporates retrieval-augmented\ngeneration (RAG) into knowledge graphs to retrieve relevant sub-cases and\nsub-descriptions, providing LLMs with learnable information; (iii)\nPseudo-Program Prompting Execution, which promotes greater logical rigor by\nguiding LLMs to execute reasoning tasks as pseudo-programs. Evaluations on nine\npublic datasets spanning three reasoning tasks reveal significant accuracy\ngains--ranging from 4.0% to 44.3%--over state-of-the-art methods. Furthermore,\ntests on four domain-specific datasets demonstrate exceptional accuracy and\nefficient execution, underscoring its practical applicability and scalability.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.13534v2",
    "published_date": "2025-04-18 07:55:09 UTC",
    "updated_date": "2025-05-19 03:23:28 UTC"
  },
  {
    "arxiv_id": "2504.13521v2",
    "title": "Deep Learning Models Meet Financial Data Modalities",
    "authors": [
      "Kasymkhan Khubiev",
      "Mikhail Semenov"
    ],
    "abstract": "Algorithmic trading relies on extracting meaningful signals from diverse\nfinancial data sources, including candlestick charts, order statistics on put\nand canceled orders, traded volume data, limit order books, and news flow.\nWhile deep learning has demonstrated remarkable success in processing\nunstructured data and has significantly advanced natural language processing,\nits application to structured financial data remains an ongoing challenge. This\nstudy investigates the integration of deep learning models with financial data\nmodalities, aiming to enhance predictive performance in trading strategies and\nportfolio optimization. We present a novel approach to incorporating limit\norder book analysis into algorithmic trading by developing embedding techniques\nand treating sequential limit order book snapshots as distinct input channels\nin an image-based representation. Our methodology for processing limit order\nbook data achieves state-of-the-art performance in high-frequency trading\nalgorithms, underscoring the effectiveness of deep learning in financial\napplications.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CE",
      "q-fin.ST"
    ],
    "primary_category": "cs.LG",
    "comment": "15 pages, 14 images, 7 tables",
    "pdf_url": "http://arxiv.org/pdf/2504.13521v2",
    "published_date": "2025-04-18 07:19:44 UTC",
    "updated_date": "2025-04-21 07:36:33 UTC"
  },
  {
    "arxiv_id": "2504.13517v1",
    "title": "Optimizing Electric Vehicle Charging Station Locations: A Data-driven System with Multi-source Fusion",
    "authors": [
      "Lihuan Li",
      "Du Yin",
      "Hao Xue",
      "David Lillo-Trynes",
      "Flora Salim"
    ],
    "abstract": "With the growing electric vehicles (EVs) charging demand, urban planners face\nthe challenges of providing charging infrastructure at optimal locations. For\nexample, range anxiety during long-distance travel and the inadequate\ndistribution of residential charging stations are the major issues many cities\nface. To achieve reasonable estimation and deployment of the charging demand,\nwe develop a data-driven system based on existing EV trips in New South Wales\n(NSW) state, Australia, incorporating multiple factors that enhance the\ngeographical feasibility of recommended charging stations. Our system\nintegrates data sources including EV trip data, geographical data such as route\ndata and Local Government Area (LGA) boundaries, as well as features like fire\nand flood risks, and Points of Interest (POIs). We visualize our results to\nintuitively demonstrate the findings from our data-driven, multi-source fusion\nsystem, and evaluate them through case studies. The outcome of this work can\nprovide a platform for discussion to develop new insights that could be used to\ngive guidance on where to position future EV charging stations.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "4-page short paper",
    "pdf_url": "http://arxiv.org/pdf/2504.13517v1",
    "published_date": "2025-04-18 07:10:48 UTC",
    "updated_date": "2025-04-18 07:10:48 UTC"
  },
  {
    "arxiv_id": "2504.13515v1",
    "title": "Large Language Models for Validating Network Protocol Parsers",
    "authors": [
      "Mingwei Zheng",
      "Danning Xie",
      "Xiangyu Zhang"
    ],
    "abstract": "Network protocol parsers are essential for enabling correct and secure\ncommunication between devices. Bugs in these parsers can introduce critical\nvulnerabilities, including memory corruption, information leakage, and\ndenial-of-service attacks. An intuitive way to assess parser correctness is to\ncompare the implementation with its official protocol standard. However, this\ncomparison is challenging because protocol standards are typically written in\nnatural language, whereas implementations are in source code. Existing methods\nlike model checking, fuzzing, and differential testing have been used to find\nparsing bugs, but they either require significant manual effort or ignore the\nprotocol standards, limiting their ability to detect semantic violations. To\nenable more automated validation of parser implementations against protocol\nstandards, we propose PARVAL, a multi-agent framework built on large language\nmodels (LLMs). PARVAL leverages the capabilities of LLMs to understand both\nnatural language and code. It transforms both protocol standards and their\nimplementations into a unified intermediate representation, referred to as\nformat specifications, and performs a differential comparison to uncover\ninconsistencies. We evaluate PARVAL on the Bidirectional Forwarding Detection\n(BFD) protocol. Our experiments demonstrate that PARVAL successfully identifies\ninconsistencies between the implementation and its RFC standard, achieving a\nlow false positive rate of 5.6%. PARVAL uncovers seven unique bugs, including\nfive previously unknown issues.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.13515v1",
    "published_date": "2025-04-18 07:09:56 UTC",
    "updated_date": "2025-04-18 07:09:56 UTC"
  },
  {
    "arxiv_id": "2504.16946v1",
    "title": "MobileCity: An Efficient Framework for Large-Scale Urban Behavior Simulation",
    "authors": [
      "Xiaotong Ye",
      "Nicolas Bougie",
      "Toshihiko Yamasaki",
      "Narimasa Watanabe"
    ],
    "abstract": "Generative agents offer promising capabilities for simulating realistic urban\nbehaviors. However, existing methods oversimplify transportation choices in\nmodern cities, and require prohibitive computational resources for large-scale\npopulation simulation. To address these limitations, we first present a virtual\ncity that features multiple functional buildings and transportation modes.\nThen, we conduct extensive surveys to model behavioral choices and mobility\npreferences among population groups. Building on these insights, we introduce a\nsimulation framework that captures the complexity of urban mobility while\nremaining scalable, enabling the simulation of over 4,000 agents. To assess the\nrealism of the generated behaviors, we perform a series of micro and\nmacro-level analyses. Beyond mere performance comparison, we explore insightful\nexperiments, such as predicting crowd density from movement patterns and\nidentifying trends in vehicle preferences across agent demographics.",
    "categories": [
      "cs.SI",
      "cs.AI"
    ],
    "primary_category": "cs.SI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16946v1",
    "published_date": "2025-04-18 07:01:05 UTC",
    "updated_date": "2025-04-18 07:01:05 UTC"
  },
  {
    "arxiv_id": "2504.13981v1",
    "title": "CacheFormer: High Attention-Based Segment Caching",
    "authors": [
      "Sushant Singh",
      "Ausif Mahmood"
    ],
    "abstract": "Efficiently handling long contexts in transformer-based language models with\nlow perplexity is an active area of research. Numerous recent approaches like\nLinformer, Longformer, Performer, and Structured state space models (SSMs).,\nhave not fully resolved this problem. All these models strive to reduce the\nquadratic time complexity of the attention mechanism while minimizing the loss\nin quality due to the effective compression of the long context. Inspired by\nthe cache and virtual memory principle in computers, where in case of a cache\nmiss, not only the needed data is retrieved from the memory, but the adjacent\ndata is also obtained, we apply this concept to handling long contexts by\ndividing it into small segments. In our design, we retrieve the nearby segments\nin an uncompressed form when high segment-level attention occurs at the\ncompressed level. Our en-hancements for handling long context include\naggregating four attention mechanisms consisting of short sliding window\nattention, long compressed segmented attention, dynamically retrieving top k\nhigh attention uncompressed segments, and overlapping segments in long segment\nattention to avoid segment fragmentation. These enhancements result in an\narchitecture that outperforms ex-isting SOTA architectures with an average\nperplexity improvement of 8.5% over similar model sizes.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.13981v1",
    "published_date": "2025-04-18 06:34:57 UTC",
    "updated_date": "2025-04-18 06:34:57 UTC"
  },
  {
    "arxiv_id": "2504.13495v1",
    "title": "Statistical Validation in Cultural Adaptations of Cognitive Tests: A Multi- Regional Systematic Review",
    "authors": [
      "Miit Daga",
      "Priyasha Mohanty",
      "Ram Krishna",
      "Swarna Priya RM"
    ],
    "abstract": "This systematic review discusses the methodological approaches and\nstatistical confirmations of cross-cultural adaptations of cognitive evaluation\ntools used with different populations. The review considers six seminal studies\non the methodology of cultural adaptation in Europe, Asia, Africa, and South\nAmerica. The results indicate that proper adaptations need holistic models with\ndemographic changes, and education explained as much as 26.76% of the variance\nin MoCA-H scores. Cultural-linguistic factors explained 6.89% of the variance\nin European adaptations of MoCA-H; however, another study on adapted MMSE and\nBCSB among Brazilian Indigenous populations reported excellent diagnostic\nperformance, with a sensitivity of 94.4% and specificity of 99.2%. There was\n78.5% inter-rater agreement on the evaluation of cultural adaptation using the\nManchester Translation Evaluation Checklist. A paramount message of the paper\nis that community feedback is necessary for culturally appropriate preparation,\nstandardized translation protocols also must be included, along with robust\nstatistical validation methodologies for developing cognitive assessment\ninstruments. This review supplies evidence-based frameworks for the further\nadaptation of cognitive assessments in increasingly diverse global health\nsettings.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG",
      "cs.NE"
    ],
    "primary_category": "cs.CY",
    "comment": "This paper is accepted and presented in the International Conference\n  Challenges & Opportunities in Artificial Intelligence: Engineering &\n  Management Applications (COAIEMA 2025) and to be published in Taylor &\n  Francis Proceedings",
    "pdf_url": "http://arxiv.org/pdf/2504.13495v1",
    "published_date": "2025-04-18 06:25:02 UTC",
    "updated_date": "2025-04-18 06:25:02 UTC"
  },
  {
    "arxiv_id": "2504.13480v1",
    "title": "Integrating Locality-Aware Attention with Transformers for General Geometry PDEs",
    "authors": [
      "Minsu Koh",
      "Beom-Chul Park",
      "Heejo Kong",
      "Seong-Whan Lee"
    ],
    "abstract": "Neural operators have emerged as promising frameworks for learning mappings\ngoverned by partial differential equations (PDEs), serving as data-driven\nalternatives to traditional numerical methods. While methods such as the\nFourier neural operator (FNO) have demonstrated notable performance, their\nreliance on uniform grids restricts their applicability to complex geometries\nand irregular meshes. Recently, Transformer-based neural operators with linear\nattention mechanisms have shown potential in overcoming these limitations for\nlarge-scale PDE simulations. However, these approaches predominantly emphasize\nglobal feature aggregation, often overlooking fine-scale dynamics and localized\nPDE behaviors essential for accurate solutions. To address these challenges, we\npropose the Locality-Aware Attention Transformer (LA2Former), which leverages\nK-nearest neighbors for dynamic patchifying and integrates global-local\nattention for enhanced PDE modeling. By combining linear attention for\nefficient global context encoding with pairwise attention for capturing\nintricate local interactions, LA2Former achieves an optimal balance between\ncomputational efficiency and predictive accuracy. Extensive evaluations across\nsix benchmark datasets demonstrate that LA2Former improves predictive accuracy\nby over 50% relative to existing linear attention methods, while also\noutperforming full pairwise attention under optimal conditions. This work\nunderscores the critical importance of localized feature learning in advancing\nTransformer-based neural operators for solving PDEs on complex and irregular\ndomains.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by IJCNN 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.13480v1",
    "published_date": "2025-04-18 05:43:49 UTC",
    "updated_date": "2025-04-18 05:43:49 UTC"
  },
  {
    "arxiv_id": "2504.13477v1",
    "title": "Creating 'Full-Stack' Hybrid Reasoning Systems that Prioritize and Enhance Human Intelligence",
    "authors": [
      "Sean Koon"
    ],
    "abstract": "The idea of augmented or hybrid intelligence offers a compelling vision for\ncombining human and AI capabilities, especially in tasks where human wisdom,\nexpertise, or common sense are essential. Unfortunately, human reasoning can be\nflawed and shortsighted, resulting in adverse individual impacts or even\nlong-term societal consequences. While strong efforts are being made to develop\nand optimize the AI aspect of hybrid reasoning, the real urgency lies in\nfostering wiser and more intelligent human participation. Tools that enhance\ncritical thinking, ingenuity, expertise, and even wisdom could be essential in\naddressing the challenges of our emerging future. This paper proposes the\ndevelopment of generative AI-based tools that enhance both the human ability to\nreflect upon a problem as well as the ability to explore the technical aspects\nof it. A high-level model is also described for integrating AI and human\ncapabilities in a way that centralizes human participation and control.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "10 pages; 3 figures; 1 table",
    "pdf_url": "http://arxiv.org/pdf/2504.13477v1",
    "published_date": "2025-04-18 05:38:21 UTC",
    "updated_date": "2025-04-18 05:38:21 UTC"
  },
  {
    "arxiv_id": "2504.13472v1",
    "title": "CodeVisionary: An Agent-based Framework for Evaluating Large Language Models in Code Generation",
    "authors": [
      "Xinchen Wang",
      "Pengfei Gao",
      "Chao Peng",
      "Ruida Hu",
      "Cuiyun Gao"
    ],
    "abstract": "Large language models (LLMs) have demonstrated strong capabilities in code\ngeneration, underscoring the critical need for rigorous and comprehensive\nevaluation. Existing evaluation approaches fall into three categories,\nincluding human-centered, metric-based, and LLM-based. Considering that\nhuman-centered approaches are labour-intensive and metric-based ones overly\nrely on reference answers, LLM-based approaches are gaining increasing\nattention due to their stronger contextual understanding capabilities and\nsuperior efficiency. However, the performance of LLM-based approaches remains\nlimited due to: (1) lack of multisource domain knowledge, and (2) insufficient\ncomprehension of complex code.\n  To mitigate the limitations, we propose CodeVisionary, the first LLM-based\nagent framework for evaluating LLMs in code generation. CodeVisionary consists\nof two stages: (1) Multiscore knowledge analysis stage, which aims to gather\nmultisource and comprehensive domain knowledge by formulating and executing a\nstepwise evaluation plan. (2) Negotiation-based scoring stage, which involves\nmultiple judges engaging in discussions to better comprehend the complex code\nand reach a consensus on the evaluation score. Extensive experiments\ndemonstrate that CodeVisionary achieves the best performance for evaluating\nLLMs in code generation, outperforming the best baseline methods with average\nimprovements of 0.202, 0.139, and 0.117 in Pearson, Spearman, and Kendall-Tau\ncoefficients, respectively. Besides, CodeVisionary provides detailed evaluation\nreports, which assist developers in identifying shortcomings and making\nimprovements. The resources of CodeVisionary are available at\nhttps://anonymous.4open.science/r/CodeVisionary.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.13472v1",
    "published_date": "2025-04-18 05:26:32 UTC",
    "updated_date": "2025-04-18 05:26:32 UTC"
  },
  {
    "arxiv_id": "2504.13460v3",
    "title": "Chain-of-Thought Textual Reasoning for Few-shot Temporal Action Localization",
    "authors": [
      "Hongwei Ji",
      "Wulian Yun",
      "Mengshi Qi",
      "Huadong Ma"
    ],
    "abstract": "Traditional temporal action localization (TAL) methods rely on large amounts\nof detailed annotated data, whereas few-shot TAL reduces this dependence by\nusing only a few training samples to identify unseen action categories.\nHowever, existing few-shot TAL methods typically focus solely on video-level\ninformation, neglecting textual information, which can provide valuable\nsemantic support for the localization task. Therefore, we propose a new\nfew-shot temporal action localization method by Chain-of-Thought textual\nreasoning to improve localization performance. Specifically, we design a novel\nfew-shot learning framework that leverages textual semantic information to\nenhance the model's ability to capture action commonalities and variations,\nwhich includes a semantic-aware text-visual alignment module designed to align\nthe query and support videos at different levels. Meanwhile, to better express\nthe temporal dependencies and causal relationships between actions at the\ntextual level to assist action localization, we design a Chain of Thought\n(CoT)-like reasoning method that progressively guides the Vision Language Model\n(VLM) and Large Language Model (LLM) to generate CoT-like text descriptions for\nvideos. The generated texts can capture more variance of action than visual\nfeatures. We conduct extensive experiments on the publicly available\nActivityNet1.3 and THUMOS14 datasets. We introduce the first dataset named\nHuman-related Anomaly Localization and explore the application of the TAL task\nin human anomaly detection. The experimental results demonstrate that our\nproposed method significantly outperforms existing methods in single-instance\nand multi-instance scenarios. We will release our code, data and benchmark.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.13460v3",
    "published_date": "2025-04-18 04:35:35 UTC",
    "updated_date": "2025-05-06 05:00:15 UTC"
  },
  {
    "arxiv_id": "2504.13448v1",
    "title": "Ascribe New Dimensions to Scientific Data Visualization with VR",
    "authors": [
      "Daniela Ushizima",
      "Guilherme Melo dos Santos",
      "Zineb Sordo",
      "Ronald Pandolfi",
      "Jeffrey Donatelli"
    ],
    "abstract": "For over half a century, the computer mouse has been the primary tool for\ninteracting with digital data, yet it remains a limiting factor in exploring\ncomplex, multi-scale scientific images. Traditional 2D visualization methods\nhinder intuitive analysis of inherently 3D structures. Virtual Reality (VR)\noffers a transformative alternative, providing immersive, interactive\nenvironments that enhance data comprehension. This article introduces\nASCRIBE-VR, a VR platform of Autonomous Solutions for Computational Research\nwith Immersive Browsing \\& Exploration, which integrates AI-driven algorithms\nwith scientific images. ASCRIBE-VR enables multimodal analysis, structural\nassessments, and immersive visualization, supporting scientific visualization\nof advanced datasets such as X-ray CT, Magnetic Resonance, and synthetic 3D\nimaging. Our VR tools, compatible with Meta Quest, can consume the output of\nour AI-based segmentation and iterative feedback processes to enable seamless\nexploration of large-scale 3D images. By merging AI-generated results with VR\nvisualization, ASCRIBE-VR enhances scientific discovery, bridging the gap\nbetween computational analysis and human intuition in materials research,\nconnecting human-in-the-loop with digital twins.",
    "categories": [
      "cs.GR",
      "cs.AI",
      "cs.CE"
    ],
    "primary_category": "cs.GR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.13448v1",
    "published_date": "2025-04-18 03:59:39 UTC",
    "updated_date": "2025-04-18 03:59:39 UTC"
  },
  {
    "arxiv_id": "2504.13443v1",
    "title": "Trust, but verify",
    "authors": [
      "Michael J. Yuan",
      "Carlos Campoy",
      "Sydney Lai",
      "James Snewin",
      "Ju Long"
    ],
    "abstract": "Decentralized AI agent networks, such as Gaia, allows individuals to run\ncustomized LLMs on their own computers and then provide services to the public.\nHowever, in order to maintain service quality, the network must verify that\nindividual nodes are running their designated LLMs. In this paper, we\ndemonstrate that in a cluster of mostly honest nodes, we can detect nodes that\nrun unauthorized or incorrect LLM through social consensus of its peers. We\nwill discuss the algorithm and experimental data from the Gaia network. We will\nalso discuss the intersubjective validation system, implemented as an\nEigenLayer AVS to introduce financial incentives and penalties to encourage\nhonest behavior from LLM nodes.",
    "categories": [
      "cs.AI",
      "cs.DC",
      "cs.MA",
      "econ.GN",
      "q-fin.EC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.13443v1",
    "published_date": "2025-04-18 03:49:53 UTC",
    "updated_date": "2025-04-18 03:49:53 UTC"
  },
  {
    "arxiv_id": "2504.16112v1",
    "title": "HPU: High-Bandwidth Processing Unit for Scalable, Cost-effective LLM Inference via GPU Co-processing",
    "authors": [
      "Myunghyun Rhee",
      "Joonseop Sim",
      "Taeyoung Ahn",
      "Seungyong Lee",
      "Daegun Yoon",
      "Euiseok Kim",
      "Kyoung Park",
      "Youngpyo Joo",
      "Hosik Kim"
    ],
    "abstract": "The attention layer, a core component of Transformer-based LLMs, brings out\ninefficiencies in current GPU systems due to its low operational intensity and\nthe substantial memory requirements of KV caches. We propose a High-bandwidth\nProcessing Unit (HPU), a memoryintensive co-processor that enhances GPU\nresource utilization during large-batched LLM inference. By offloading\nmemory-bound operations, the HPU allows the GPU to focus on compute-intensive\ntasks, increasing overall efficiency. Also, the HPU, as an add-on card, scales\nout to accommodate surging memory demands driven by large batch sizes and\nextended sequence lengths. In this paper, we show the HPU prototype implemented\nwith PCIe-based FPGA cards mounted on a GPU system. Our novel GPU-HPU\nheterogeneous system demonstrates up to 4.1x performance gains and 4.6x energy\nefficiency improvements over a GPUonly system, providing scalability without\nincreasing the number of GPUs.",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.CL",
      "cs.DC"
    ],
    "primary_category": "cs.AR",
    "comment": "6 pages",
    "pdf_url": "http://arxiv.org/pdf/2504.16112v1",
    "published_date": "2025-04-18 03:31:08 UTC",
    "updated_date": "2025-04-18 03:31:08 UTC"
  },
  {
    "arxiv_id": "2504.13979v1",
    "title": "Framework, Standards, Applications and Best practices of Responsible AI : A Comprehensive Survey",
    "authors": [
      "Thippa Reddy Gadekallu",
      "Kapal Dev",
      "Sunder Ali Khowaja",
      "Weizheng Wang",
      "Hailin Feng",
      "Kai Fang",
      "Sharnil Pandya",
      "Wei Wang"
    ],
    "abstract": "Responsible Artificial Intelligence (RAI) is a combination of ethics\nassociated with the usage of artificial intelligence aligned with the common\nand standard frameworks. This survey paper extensively discusses the global and\nnational standards, applications of RAI, current technology and ongoing\nprojects using RAI, and possible challenges in implementing and designing RAI\nin the industries and projects based on AI. Currently, ethical standards and\nimplementation of RAI are decoupled which caters each industry to follow their\nown standards to use AI ethically. Many global firms and government\norganizations are taking necessary initiatives to design a common and standard\nframework. Social pressure and unethical way of using AI forces the RAI design\nrather than implementation.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "Submitted for peer review",
    "pdf_url": "http://arxiv.org/pdf/2504.13979v1",
    "published_date": "2025-04-18 03:23:52 UTC",
    "updated_date": "2025-04-18 03:23:52 UTC"
  },
  {
    "arxiv_id": "2504.13429v1",
    "title": "Bounded and Uniform Energy-based Out-of-distribution Detection for Graphs",
    "authors": [
      "Shenzhi Yang",
      "Bin Liang",
      "An Liu",
      "Lin Gui",
      "Xingkai Yao",
      "Xiaofang Zhang"
    ],
    "abstract": "Given the critical role of graphs in real-world applications and their\nhigh-security requirements, improving the ability of graph neural networks\n(GNNs) to detect out-of-distribution (OOD) data is an urgent research problem.\nThe recent work GNNSAFE proposes a framework based on the aggregation of\nnegative energy scores that significantly improves the performance of GNNs to\ndetect node-level OOD data. However, our study finds that score aggregation\namong nodes is susceptible to extreme values due to the unboundedness of the\nnegative energy scores and logit shifts, which severely limits the accuracy of\nGNNs in detecting node-level OOD data. In this paper, we propose NODESAFE:\nreducing the generation of extreme scores of nodes by adding two optimization\nterms that make the negative energy scores bounded and mitigate the logit\nshift. Experimental results show that our approach dramatically improves the\nability of GNNs to detect OOD data at the node level, e.g., in detecting OOD\ndata induced by Structure Manipulation, the metric of FPR95 (lower is better)\nin scenarios without (with) OOD data exposure are reduced from the current SOTA\nby 28.4% (22.7%).",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "arXiv admin note: text overlap with arXiv:2302.02914 by other authors",
    "pdf_url": "http://arxiv.org/pdf/2504.13429v1",
    "published_date": "2025-04-18 03:01:00 UTC",
    "updated_date": "2025-04-18 03:01:00 UTC"
  },
  {
    "arxiv_id": "2504.13415v1",
    "title": "DADU: Dual Attention-based Deep Supervised UNet for Automated Semantic Segmentation of Cardiac Images",
    "authors": [
      "Racheal Mukisa",
      "Arvind K. Bansal"
    ],
    "abstract": "We propose an enhanced deep learning-based model for image segmentation of\nthe left and right ventricles and myocardium scar tissue from cardiac magnetic\nresonance (CMR) images. The proposed technique integrates UNet, channel and\nspatial attention, edge-detection based skip-connection and deep supervised\nlearning to improve the accuracy of the CMR image-segmentation. Images are\nprocessed using multiple channels to generate multiple feature-maps. We built a\ndual attention-based model to integrate channel and spatial attention. The use\nof extracted edges in skip connection improves the reconstructed images from\nfeature-maps. The use of deep supervision reduces vanishing gradient problems\ninherent in classification based on deep neural networks. The algorithms for\ndual attention-based model, corresponding implementation and performance\nresults are described. The performance results show that this approach has\nattained high accuracy: 98% Dice Similarity Score (DSC) and significantly lower\nHausdorff Distance (HD). The performance results outperform other leading\ntechniques both in DSC and HD.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "I.4.6; I.2; I.5.2; I.5.1"
    ],
    "primary_category": "eess.IV",
    "comment": "20 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.13415v1",
    "published_date": "2025-04-18 02:22:45 UTC",
    "updated_date": "2025-04-18 02:22:45 UTC"
  },
  {
    "arxiv_id": "2504.13414v2",
    "title": "Adaptive Non-local Observable on Quantum Neural Networks",
    "authors": [
      "Hsin-Yi Lin",
      "Huan-Hsin Tseng",
      "Samuel Yen-Chi Chen",
      "Shinjae Yoo"
    ],
    "abstract": "Conventional Variational Quantum Circuits (VQCs) for Quantum Machine Learning\ntypically rely on a fixed Hermitian observable, often built from Pauli\noperators. Inspired by the Heisenberg picture, we propose an adaptive non-local\nmeasurement framework that substantially increases the model complexity of the\nquantum circuits. Our introduction of dynamical Hermitian observables with\nevolving parameters shows that optimizing VQC rotations corresponds to tracing\na trajectory in the observable space. This viewpoint reveals that standard VQCs\nare merely a special case of the Heisenberg representation.\n  Furthermore, we show that properly incorporating variational rotations with\nnon-local observables enhances qubit interaction and information mixture,\nadmitting flexible circuit designs. Two non-local measurement schemes are\nintroduced, and numerical simulations on classification tasks confirm that our\napproach outperforms conventional VQCs, yielding a more powerful and\nresource-efficient approach as a Quantum Neural Network.",
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "quant-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.13414v2",
    "published_date": "2025-04-18 02:20:12 UTC",
    "updated_date": "2025-04-26 20:29:24 UTC"
  },
  {
    "arxiv_id": "2504.13407v1",
    "title": "LoRA-Based Continual Learning with Constraints on Critical Parameter Changes",
    "authors": [
      "Shimou Ling",
      "Liang Zhang",
      "Jiangwei Zhao",
      "Lili Pan",
      "Hongliang Li"
    ],
    "abstract": "LoRA-based continual learning represents a promising avenue for leveraging\npre-trained models in downstream continual learning tasks. Recent studies have\nshown that orthogonal LoRA tuning effectively mitigates forgetting. However,\nthis work unveils that under orthogonal LoRA tuning, the critical parameters\nfor pre-tasks still change notably after learning post-tasks. To address this\nproblem, we directly propose freezing the most critical parameter matrices in\nthe Vision Transformer (ViT) for pre-tasks before learning post-tasks. In\naddition, building on orthogonal LoRA tuning, we propose orthogonal LoRA\ncomposition (LoRAC) based on QR decomposition, which may further enhance the\nplasticity of our method. Elaborate ablation studies and extensive comparisons\ndemonstrate the effectiveness of our proposed method. Our results indicate that\nour method achieves state-of-the-art (SOTA) performance on several well-known\ncontinual learning benchmarks. For instance, on the Split CIFAR-100 dataset,\nour method shows a 6.35\\% improvement in accuracy and a 3.24\\% reduction in\nforgetting compared to previous methods. Our code is available at\nhttps://github.com/learninginvision/LoRAC-IPC.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.13407v1",
    "published_date": "2025-04-18 02:08:19 UTC",
    "updated_date": "2025-04-18 02:08:19 UTC"
  },
  {
    "arxiv_id": "2504.13406v2",
    "title": "LangCoop: Collaborative Driving with Language",
    "authors": [
      "Xiangbo Gao",
      "Yuheng Wu",
      "Rujia Wang",
      "Chenxi Liu",
      "Yang Zhou",
      "Zhengzhong Tu"
    ],
    "abstract": "Multi-agent collaboration holds great promise for enhancing the safety,\nreliability, and mobility of autonomous driving systems by enabling information\nsharing among multiple connected agents. However, existing multi-agent\ncommunication approaches are hindered by limitations of existing communication\nmedia, including high bandwidth demands, agent heterogeneity, and information\nloss. To address these challenges, we introduce LangCoop, a new paradigm for\ncollaborative autonomous driving that leverages natural language as a compact\nyet expressive medium for inter-agent communication. LangCoop features two key\ninnovations: Mixture Model Modular Chain-of-thought (M$^3$CoT) for structured\nzero-shot vision-language reasoning and Natural Language Information Packaging\n(LangPack) for efficiently packaging information into concise, language-based\nmessages. Through extensive experiments conducted in the CARLA simulations, we\ndemonstrate that LangCoop achieves a remarkable 96\\% reduction in communication\nbandwidth (< 2KB per message) compared to image-based communication, while\nmaintaining competitive driving performance in the closed-loop evaluation. Our\nproject page and code are at https://xiangbogaobarry.github.io/LangCoop/.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.13406v2",
    "published_date": "2025-04-18 02:03:14 UTC",
    "updated_date": "2025-04-21 02:00:43 UTC"
  },
  {
    "arxiv_id": "2504.13399v1",
    "title": "Towards a Multi-Agent Vision-Language System for Zero-Shot Novel Hazardous Object Detection for Autonomous Driving Safety",
    "authors": [
      "Shashank Shriram",
      "Srinivasa Perisetla",
      "Aryan Keskar",
      "Harsha Krishnaswamy",
      "Tonko Emil Westerhof Bossen",
      "Andreas Møgelmose",
      "Ross Greer"
    ],
    "abstract": "Detecting anomalous hazards in visual data, particularly in video streams, is\na critical challenge in autonomous driving. Existing models often struggle with\nunpredictable, out-of-label hazards due to their reliance on predefined object\ncategories. In this paper, we propose a multimodal approach that integrates\nvision-language reasoning with zero-shot object detection to improve hazard\nidentification and explanation. Our pipeline consists of a Vision-Language\nModel (VLM), a Large Language Model (LLM), in order to detect hazardous objects\nwithin a traffic scene. We refine object detection by incorporating OpenAI's\nCLIP model to match predicted hazards with bounding box annotations, improving\nlocalization accuracy. To assess model performance, we create a ground truth\ndataset by denoising and extending the foundational COOOL\n(Challenge-of-Out-of-Label) anomaly detection benchmark dataset with complete\nnatural language descriptions for hazard annotations. We define a means of\nhazard detection and labeling evaluation on the extended dataset using cosine\nsimilarity. This evaluation considers the semantic similarity between the\npredicted hazard description and the annotated ground truth for each video.\nAdditionally, we release a set of tools for structuring and managing\nlarge-scale hazard detection datasets. Our findings highlight the strengths and\nlimitations of current vision-language-based approaches, offering insights into\nfuture improvements in autonomous hazard detection systems. Our models,\nscripts, and data can be found at https://github.com/mi3labucm/COOOLER.git",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.13399v1",
    "published_date": "2025-04-18 01:25:02 UTC",
    "updated_date": "2025-04-18 01:25:02 UTC"
  },
  {
    "arxiv_id": "2504.13391v1",
    "title": "Cardiac MRI Semantic Segmentation for Ventricles and Myocardium using Deep Learning",
    "authors": [
      "Racheal Mukisa",
      "Arvind K. Bansal"
    ],
    "abstract": "Automated noninvasive cardiac diagnosis plays a critical role in the early\ndetection of cardiac disorders and cost-effective clinical management.\nAutomated diagnosis involves the automated segmentation and analysis of cardiac\nimages. Precise delineation of cardiac substructures and extraction of their\nmorphological attributes are essential for evaluating the cardiac function, and\ndiagnosing cardiovascular disease such as cardiomyopathy, valvular diseases,\nabnormalities related to septum perforations, and blood-flow rate. Semantic\nsegmentation labels the CMR image at the pixel level, and localizes its\nsubcomponents to facilitate the detection of abnormalities, including\nabnormalities in cardiac wall motion in an aging heart with muscle\nabnormalities, vascular abnormalities, and valvular abnormalities. In this\npaper, we describe a model to improve semantic segmentation of CMR images. The\nmodel extracts edge-attributes and context information during down-sampling of\nthe U-Net and infuses this information during up-sampling to localize three\nmajor cardiac structures: left ventricle cavity (LV); right ventricle cavity\n(RV); and LV myocardium (LMyo). We present an algorithm and performance\nresults. A comparison of our model with previous leading models, using\nsimilarity metrics between actual image and segmented image, shows that our\napproach improves Dice similarity coefficient (DSC) by 2%-11% and lowers\nHausdorff distance (HD) by 1.6 to 5.7 mm.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "I.4.6; I.2; I.5.2; I.5.1"
    ],
    "primary_category": "eess.IV",
    "comment": "20 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.13391v1",
    "published_date": "2025-04-18 00:54:30 UTC",
    "updated_date": "2025-04-18 00:54:30 UTC"
  }
]