{
  "date": "2024-04-07",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-04-07 的 arXiv 中文 TLDR 快报！今天 arXiv 更新了 45 篇论文，主要聚焦 AI 安全、多模态处理、LLM（Large Language Models）优化与应用、金融预测和医疗诊断等领域，其中 StockGPT 在 AI 驱动金融决策上令人印象深刻，而 LLM 相关论文（如 LoRA 和 jailbreak 攻击）则突显了知名学者（如 Vlad Fomenko 和 Mohamed El Amine Seddik）对模型鲁棒性的贡献，整体强调 AI 在实际场景中的潜力与挑战。\n\n### AI 和 LLM 相关论文（重点优先）\n这些论文探讨了 LLM 的优化、安全和应用，体现了当前 AI 领域的热点。\n- **StockGPT: A GenAI Model for Stock Prediction and Trading（StockGPT: 用于股票预测和交易的生成式 AI 模型）**：这篇论文引入 StockGPT 模型，通过注意力机制从 70 百万日股票回报序列中学习隐藏模式，实现强有力的预测表现，显著超越传统策略，揭示 AI 在金融决策中的潜力。\n- **Active Test-Time Adaptation: Theoretical Analyses and An Algorithm（主动测试时适应：理论分析和算法）**：作者 Shurui Gui 等提出主动测试时适应框架，结合活跃学习和样本熵平衡，理论证明有限标记数据可提升模型性能，避免灾难性遗忘，在跨域任务中显著提高准确率。\n- **How Bad is Training on Synthetic Data? A Statistical Analysis of Language Model Collapse（使用合成数据训练有多糟糕？语言模型崩溃的统计分析）**：Mohamed El Amine Seddik 等分析了 LLM 递归训练导致的模型崩溃现象，证明纯合成数据会丢失原始分布，但混合真实数据可避免此问题，提供最大合成数据量的估算。\n- **A Note on LoRA（关于 LoRA 的笔记）**：Vlad Fomenko 等扩展 LoRA（Low-Rank Adaptation）方法，提供新视角和大规模部署见解，帮助 LLM 高效适应新任务，无需新实验。\n- **Your Finetuned Large Language Model is Already a Powerful Out-of-distribution Detector（你的微调大型语言模型已经是强大的分布外检测器）**：Andi Zhang 等发现微调 LLM 的似然比可有效检测分布外数据，在 QA 系统上提升性能，展示了 LLM 的隐形鲁棒性。\n- **Prompting Multi-Modal Tokens to Enhance End-to-End Autonomous Driving Imitation Learning with LLMs（通过多模态提示增强 LLM 的端到端自动驾驶模仿学习）**：Yiqun Duan 等提出混合框架，将视觉和 LiDAR 输入转化为可学习的多模态标记，结合 LLM 修正错误，提升自动驾驶性能。\n- **Adapting LLMs for Efficient Context Processing through Soft Prompt Compression（通过软提示压缩适应 LLM 的高效上下文处理）**：Cangqing Wang 等开发 SoftPromptComp 框架，利用总结和软提示减少计算开销，同时保持语义完整。\n- **Hidden You Malicious Goal Into Benign Narratives: Jailbreak Large Language Models through Logic Chain Injection（将恶意目标隐藏在良性叙述中：通过逻辑链注入越狱大型语言模型）**：Zhilong Wang 等提出逻辑链注入攻击，隐藏恶意意图于真实叙述中，成功欺骗 LLM 和人类，强调 AI 安全漏洞。\n\n### 医疗和生物应用论文\n这些论文展示了 AI 在医疗诊断中的实用价值，相关性强且有实际影响。\n- **Automated Prediction of Breast Cancer Response to Neoadjuvant Chemotherapy from DWI Data（基于 DWI 数据自动预测乳腺癌对新辅助化疗的反应）**：Shir Nitzan 等开发深度学习模型，使用自适应病变加权自动分割肿瘤，提升乳腺癌预后预测准确率（AUC 达 0.76），无需手动标注。\n- **Primary liver cancer classification from routine tumour biopsy using weakly supervised deep learning（使用弱监督深度学习从常规肿瘤活检分类原发性肝癌）**：Aurélie Beaufrère 等利用 ResNet18 和无监督聚类，从 HES 染色图像中区分肝癌类型，内部验证准确率达 100%，为临床诊断提供高效工具。\n- **Camera-Based Remote Physiology Sensing for Hundreds of Subjects Across Skin Tones（基于相机的远程生理信号检测，覆盖多种肤色）**：Jiankai Tang 等分析 VitalVideo 数据集，证明数百样本训练可实现高效 rPPG（远程光体积描记）模型，强调肤色多样性对性能的影响。\n\n### 强化学习和图像处理论文\n这些领域论文虽重要，但相对次要，快速概述核心贡献。\n- **Percentile Criterion Optimization in Offline Reinforcement Learning（离线强化学习的百分位准则优化）**：Elita A. Lobo 等提出基于 Value-at-Risk 的动态规划算法，优化强化学习策略，减少保守性并提升鲁棒性。\n- **Dynamic Distinction Learning: Adaptive Pseudo Anomalies for Video Anomaly Detection（动态区分学习：用于视频异常检测的自适应伪异常）**：Demetris Lappas 等的方法结合伪异常和动态权重，提升视频异常检测准确率，在 Ped2 和 Avenue 数据集上表现优异。\n- **Msmsfnet: a multi-stream and multi-scale fusion net for edge detection（Msmsfnet: 用于边缘检测的多流多尺度融合网）**：Chenguang Liu 等设计多流融合网络，从头训练实现边缘检测，超越传统方法，尤其适用于 SAR 图像。\n\n其他论文如强化学习优化、音频处理（如 Gull）和图神经网络等，涉及广泛但不具主导话题度，仅提要：这些工作在动态环境适应、音频压缩和图表示上取得进展，但细节较技术化，建议感兴趣读者查阅原论文。\n\n总之，今天的 arXiv 快报突显 AI 模型的创新与风险，LLM 相关研究占主导，医疗应用潜力巨大。读者可关注 StockGPT 和 Active Test-Time Adaptation 等论文，以探索 AI 的实际落地。明日见！",
  "papers": [
    {
      "arxiv_id": "2404.05101v3",
      "title": "StockGPT: A GenAI Model for Stock Prediction and Trading",
      "title_zh": "StockGPT：一个用于股票预测和交易的生成式AI模型",
      "authors": [
        "Dat Mai"
      ],
      "abstract": "This paper introduces StockGPT, an autoregressive ``number'' model trained\nand tested on 70 million daily U.S.\\ stock returns over nearly 100 years.\nTreating each return series as a sequence of tokens, StockGPT automatically\nlearns the hidden patterns predictive of future returns via its attention\nmechanism. On a held-out test sample from 2001 to 2023, daily and monthly\nrebalanced long-short portfolios formed from StockGPT predictions yield strong\nperformance. The StockGPT-based portfolios span momentum and long-/short-term\nreversals, eliminating the need for manually crafted price-based strategies,\nand yield highly significant alphas against leading stock market factors,\nsuggesting a novel AI pricing effect. This highlights the immense promise of\ngenerative AI in surpassing human in making complex financial investment\ndecisions.",
      "tldr_zh": "这篇论文介绍了 StockGPT，一种基于生成式 AI (GenAI) 的自回归模型，用于股票预测和交易，通过注意力机制在近 100 年的 70 百万条美国股票回报数据上训练，自动学习预测未来回报的隐藏模式。在 2001-2023 的测试样本上，基于 StockGPT 预测构建的每日和每月再平衡的多头-空头投资组合表现出色，涵盖动量和长期/短期反转策略，并产生高度显著的 alphas，对领先股票市场因素具有超额回报。StockGPT 消除了手动设计价格策略的需求，证明了生成式 AI 在超越人类复杂金融投资决策方面的巨大潜力。",
      "categories": [
        "q-fin.CP",
        "cs.AI",
        "q-fin.PM",
        "q-fin.PR",
        "q-fin.ST"
      ],
      "primary_category": "q-fin.CP",
      "comment": "26 pages, 3 figures, 8 tables",
      "pdf_url": "http://arxiv.org/pdf/2404.05101v3",
      "published_date": "2024-04-07 22:53:43 UTC",
      "updated_date": "2024-10-23 15:28:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:21:49.371940"
    },
    {
      "arxiv_id": "2404.05094v1",
      "title": "Active Test-Time Adaptation: Theoretical Analyses and An Algorithm",
      "title_zh": "翻译失败",
      "authors": [
        "Shurui Gui",
        "Xiner Li",
        "Shuiwang Ji"
      ],
      "abstract": "Test-time adaptation (TTA) addresses distribution shifts for streaming test\ndata in unsupervised settings. Currently, most TTA methods can only deal with\nminor shifts and rely heavily on heuristic and empirical studies.\n  To advance TTA under domain shifts, we propose the novel problem setting of\nactive test-time adaptation (ATTA) that integrates active learning within the\nfully TTA setting.\n  We provide a learning theory analysis, demonstrating that incorporating\nlimited labeled test instances enhances overall performances across test\ndomains with a theoretical guarantee. We also present a sample entropy\nbalancing for implementing ATTA while avoiding catastrophic forgetting (CF). We\nintroduce a simple yet effective ATTA algorithm, known as SimATTA, using\nreal-time sample selection techniques. Extensive experimental results confirm\nconsistency with our theoretical analyses and show that the proposed ATTA\nmethod yields substantial performance improvements over TTA methods while\nmaintaining efficiency and shares similar effectiveness to the more demanding\nactive domain adaptation (ADA) methods. Our code is available at\nhttps://github.com/divelab/ATTA",
      "tldr_zh": "这篇论文提出主动测试时适应 (ATTA) 的新问题设置，将主动学习整合到测试时适应 (TTA) 中，以更好地处理流式测试数据中的域偏移问题。作者通过学习理论分析证明，添加有限标记测试样本能提升整体性能，并提供理论保证；同时引入 SimATTA 算法，利用样本熵平衡技术避免灾难性遗忘 (CF)。实验结果显示，ATTA 方法显著优于传统 TTA 方法，在效率上保持优势，并与主动域适应 (ADA) 方法具有类似效果。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.05094v1",
      "published_date": "2024-04-07 22:31:34 UTC",
      "updated_date": "2024-04-07 22:31:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:22:01.178254"
    },
    {
      "arxiv_id": "2404.05090v1",
      "title": "How Bad is Training on Synthetic Data? A Statistical Analysis of Language Model Collapse",
      "title_zh": "翻译失败",
      "authors": [
        "Mohamed El Amine Seddik",
        "Suei-Wen Chen",
        "Soufiane Hayou",
        "Pierre Youssef",
        "Merouane Debbah"
      ],
      "abstract": "The phenomenon of model collapse, introduced in (Shumailov et al., 2023),\nrefers to the deterioration in performance that occurs when new models are\ntrained on synthetic data generated from previously trained models. This\nrecursive training loop makes the tails of the original distribution disappear,\nthereby making future-generation models forget about the initial (real)\ndistribution. With the aim of rigorously understanding model collapse in\nlanguage models, we consider in this paper a statistical model that allows us\nto characterize the impact of various recursive training scenarios.\nSpecifically, we demonstrate that model collapse cannot be avoided when\ntraining solely on synthetic data. However, when mixing both real and synthetic\ndata, we provide an estimate of a maximal amount of synthetic data below which\nmodel collapse can eventually be avoided. Our theoretical conclusions are\nfurther supported by empirical validations.",
      "tldr_zh": "这篇论文通过统计模型分析了语言模型在合成数据上训练导致的model collapse现象，即新模型训练时性能恶化，并逐渐忘记原始真实分布。作者证明，如果仅使用synthetic data进行训练，model collapse不可避免。另一方面，当混合使用真实数据和synthetic data时，他们估算了一个最大合成数据量阈值，以避免模型崩溃。这些理论结论得到了实证验证的支持。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.05090v1",
      "published_date": "2024-04-07 22:15:13 UTC",
      "updated_date": "2024-04-07 22:15:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:22:11.374057"
    },
    {
      "arxiv_id": "2404.05086v1",
      "title": "A Note on LoRA",
      "title_zh": "翻译失败",
      "authors": [
        "Vlad Fomenko",
        "Han Yu",
        "Jongho Lee",
        "Stanley Hsieh",
        "Weizhu Chen"
      ],
      "abstract": "LoRA (Low-Rank Adaptation) has emerged as a preferred method for efficiently\nadapting Large Language Models (LLMs) with remarkable simplicity and efficacy.\nThis note extends the original LoRA paper by offering new perspectives that\nwere not initially discussed and presents a series of insights for deploying\nLoRA at scale. Without introducing new experiments, we aim to improve the\nunderstanding and application of LoRA.",
      "tldr_zh": "这篇笔记讨论了 LoRA（Low-Rank Adaptation），一种简单高效的方法，用于适应大型语言模型（LLMs）。论文扩展了原 LoRA 研究，提供了一些未被初始讨论的新视角和见解，专注于大规模部署的策略。总体目标是通过这些分析改善对 LoRA 的理解和实际应用，而不引入新实验。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.05086v1",
      "published_date": "2024-04-07 22:00:50 UTC",
      "updated_date": "2024-04-07 22:00:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:22:22.888141"
    },
    {
      "arxiv_id": "2404.05074v1",
      "title": "On the Uniqueness of Solution for the Bellman Equation of LTL Objectives",
      "title_zh": "翻译失败",
      "authors": [
        "Zetong Xuan",
        "Alper Kamil Bozkurt",
        "Miroslav Pajic",
        "Yu Wang"
      ],
      "abstract": "Surrogate rewards for linear temporal logic (LTL) objectives are commonly\nutilized in planning problems for LTL objectives. In a widely-adopted surrogate\nreward approach, two discount factors are used to ensure that the expected\nreturn approximates the satisfaction probability of the LTL objective. The\nexpected return then can be estimated by methods using the Bellman updates such\nas reinforcement learning. However, the uniqueness of the solution to the\nBellman equation with two discount factors has not been explicitly discussed.\nWe demonstrate with an example that when one of the discount factors is set to\none, as allowed in many previous works, the Bellman equation may have multiple\nsolutions, leading to inaccurate evaluation of the expected return. We then\npropose a condition for the Bellman equation to have the expected return as the\nunique solution, requiring the solutions for states inside a rejecting bottom\nstrongly connected component (BSCC) to be 0. We prove this condition is\nsufficient by showing that the solutions for the states with discounting can be\nseparated from those for the states without discounting under this condition",
      "tldr_zh": "这篇论文探讨了线性时序逻辑 (LTL) 目标的 Bellman 方程解唯一性问题，指出使用两个折扣因子时，如果其中一个设为 1，Bellman 方程可能存在多个解，导致期望回报评估不准确。作者通过示例证明了这一问题，并提出一个条件：要求拒绝的底部强连通组件 (BSCC) 中的状态解为 0，以确保期望回报作为唯一解。最终，他们证明了这一条件是充分的，能够将有折扣和无折扣状态的解分开，从而为 LTL 目标的规划提供更可靠的强化学习方法。",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted for the 2024 Learning for Dynamics and Control Conference\n  (L4DC)",
      "pdf_url": "http://arxiv.org/pdf/2404.05074v1",
      "published_date": "2024-04-07 21:06:52 UTC",
      "updated_date": "2024-04-07 21:06:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:22:36.265026"
    },
    {
      "arxiv_id": "2404.05061v1",
      "title": "Automated Prediction of Breast Cancer Response to Neoadjuvant Chemotherapy from DWI Data",
      "title_zh": "基于 DWI 数据对乳腺癌对新辅助化疗反应的自动预测",
      "authors": [
        "Shir Nitzan",
        "Maya Gilad",
        "Moti Freiman"
      ],
      "abstract": "Effective surgical planning for breast cancer hinges on accurately predicting\npathological complete response (pCR) to neoadjuvant chemotherapy (NAC).\nDiffusion-weighted MRI (DWI) and machine learning offer a non-invasive approach\nfor early pCR assessment. However, most machine-learning models require manual\ntumor segmentation, a cumbersome and error-prone task. We propose a deep\nlearning model employing \"Size-Adaptive Lesion Weighting\" for automatic DWI\ntumor segmentation to enhance pCR prediction accuracy. Despite\nhistopathological changes during NAC complicating DWI image segmentation, our\nmodel demonstrates robust performance. Utilizing the BMMR2 challenge dataset,\nit matches human experts in pCR prediction pre-NAC with an area under the curve\n(AUC) of 0.76 vs. 0.796, and surpasses standard automated methods mid-NAC, with\nan AUC of 0.729 vs. 0.654 and 0.576. Our approach represents a significant\nadvancement in automating breast cancer treatment planning, enabling more\nreliable pCR predictions without manual segmentation.",
      "tldr_zh": "该研究针对乳腺癌对新辅助化疗 (NAC) 的病理完全反应 (pCR) 预测问题，提出了一种基于扩散加权 MRI (DWI) 的深度学习模型，使用 \"Size-Adaptive Lesion Weighting\" 技术实现自动肿瘤分割，从而避免了手动分割的繁琐和错误。模型在 BMMR2 挑战数据集上表现突出，在 NAC 前预测的 AUC 达到 0.76，与人类专家 (AUC 0.796) 相当，并在 NAC 中期预测中超越标准自动方法 (AUC 0.729 vs. 0.654 和 0.576)。这一创新方法显著提升了乳腺癌治疗规划的自动化和可靠性，为非侵入式 pCR 评估提供了新途径。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted for presentation at the IEEE International Symposium on\n  Biomedical Imaging (ISBI)",
      "pdf_url": "http://arxiv.org/pdf/2404.05061v1",
      "published_date": "2024-04-07 20:15:40 UTC",
      "updated_date": "2024-04-07 20:15:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:22:48.733830"
    },
    {
      "arxiv_id": "2404.05055v1",
      "title": "Percentile Criterion Optimization in Offline Reinforcement Learning",
      "title_zh": "离线强化学习中的百分位数准则优化",
      "authors": [
        "Elita A. Lobo",
        "Cyrus Cousins",
        "Yair Zick",
        "Marek Petrik"
      ],
      "abstract": "In reinforcement learning, robust policies for high-stakes decision-making\nproblems with limited data are usually computed by optimizing the\n\\emph{percentile criterion}. The percentile criterion is approximately solved\nby constructing an \\emph{ambiguity set} that contains the true model with high\nprobability and optimizing the policy for the worst model in the set. Since the\npercentile criterion is non-convex, constructing ambiguity sets is often\nchallenging. Existing work uses \\emph{Bayesian credible regions} as ambiguity\nsets, but they are often unnecessarily large and result in learning overly\nconservative policies. To overcome these shortcomings, we propose a novel\nValue-at-Risk based dynamic programming algorithm to optimize the percentile\ncriterion without explicitly constructing any ambiguity sets. Our theoretical\nand empirical results show that our algorithm implicitly constructs much\nsmaller ambiguity sets and learns less conservative robust policies.",
      "tldr_zh": "在离线强化学习中，优化百分位数标准（percentile criterion）通常涉及构建模糊集（ambiguity set）来处理高风险决策，但现有方法如使用 Bayesian credible regions 往往导致模糊集过大，策略过于保守。针对这一问题，本文提出一种基于 Value-at-Risk 的动态规划算法，直接优化百分位数标准，而无需显式构建模糊集。该算法通过隐式创建更小的模糊集，能够学习出更少的保守稳健策略，并得到理论和实证支持。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at Neurips 2023",
      "pdf_url": "http://arxiv.org/pdf/2404.05055v1",
      "published_date": "2024-04-07 19:29:09 UTC",
      "updated_date": "2024-04-07 19:29:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:23:00.972515"
    },
    {
      "arxiv_id": "2404.05769v1",
      "title": "Dynamic Quality-Diversity Search",
      "title_zh": "动态质量多样性搜索",
      "authors": [
        "Roberto Gallotta",
        "Antonios Liapis",
        "Georgios N. Yannakakis"
      ],
      "abstract": "Evolutionary search via the quality-diversity (QD) paradigm can discover\nhighly performing solutions in different behavioural niches, showing\nconsiderable potential in complex real-world scenarios such as evolutionary\nrobotics. Yet most QD methods only tackle static tasks that are fixed over\ntime, which is rarely the case in the real world. Unlike noisy environments,\nwhere the fitness of an individual changes slightly at every evaluation,\ndynamic environments simulate tasks where external factors at unknown and\nirregular intervals alter the performance of the individual with a severity\nthat is unknown a priori. Literature on optimisation in dynamic environments is\nextensive, yet such environments have not been explored in the context of QD\nsearch. This paper introduces a novel and generalisable Dynamic QD methodology\nthat aims to keep the archive of past solutions updated in the case of\nenvironment changes. Secondly, we present a novel characterisation of dynamic\nenvironments that can be easily applied to well-known benchmarks, with minor\ninterventions to move them from a static task to a dynamic one. Our Dynamic QD\nintervention is applied on MAP-Elites and CMA-ME, two powerful QD algorithms,\nand we test the dynamic variants on different dynamic tasks.",
      "tldr_zh": "该论文探讨了质量多样性 (QD) 范式在进化搜索中的应用，特别针对动态环境的问题，这些环境会因未知因素导致个体性能发生不可预测的变化，而现有 QD 方法主要局限于静态任务。研究提出了一种新型的 Dynamic QD 方法ology，能够在环境变化时动态更新过去的解决方案档案，并引入了一种易于应用于基准测试的动态环境表征方法。实验将该方法应用于 MAP-Elites 和 CMA-ME 算法，并在各种动态任务上进行测试，展示了其在复杂真实场景中的潜力。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "Parts of this manuscripts are published at The Genetic and\n  Evolutionary Computation Conference (GECCO) 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.05769v1",
      "published_date": "2024-04-07 19:00:15 UTC",
      "updated_date": "2024-04-07 19:00:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:23:11.755909"
    },
    {
      "arxiv_id": "2404.05012v1",
      "title": "Towards Reliable and Empathetic Depression-Diagnosis-Oriented Chats",
      "title_zh": "翻译失败",
      "authors": [
        "Kunyao Lan",
        "Cong Ming",
        "Binwei Yao",
        "Lu Chen",
        "Mengyue Wu"
      ],
      "abstract": "Chatbots can serve as a viable tool for preliminary depression diagnosis via\ninteractive conversations with potential patients. Nevertheless, the blend of\ntask-oriented and chit-chat in diagnosis-related dialogues necessitates\nprofessional expertise and empathy. Such unique requirements challenge\ntraditional dialogue frameworks geared towards single optimization goals. To\naddress this, we propose an innovative ontology definition and generation\nframework tailored explicitly for depression diagnosis dialogues, combining the\nreliability of task-oriented conversations with the appeal of empathy-related\nchit-chat. We further apply the framework to D$^4$, the only existing public\ndialogue dataset on depression diagnosis-oriented chats. Exhaustive\nexperimental results indicate significant improvements in task completion and\nemotional support generation in depression diagnosis, fostering a more\ncomprehensive approach to task-oriented chat dialogue system development and\nits applications in digital mental health.",
      "tldr_zh": "本文提出一个创新的本体定义和生成框架（ontology），旨在提升聊天机器人（chatbots）在抑郁症诊断对话中的可靠性和同理心，通过融合任务导向对话（task-oriented conversations）的专业性与情感闲聊的吸引力。框架针对抑郁症诊断的独特需求，应用于现有的 D$^4$ 数据集，实验结果显示在任务完成和情感支持生成方面取得了显著改善。该方法推动了任务导向聊天系统在数字心理健康领域的全面发展，提供更有效的初步诊断工具。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.05012v1",
      "published_date": "2024-04-07 16:35:53 UTC",
      "updated_date": "2024-04-07 16:35:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:23:23.992890"
    },
    {
      "arxiv_id": "2404.05003v1",
      "title": "Camera-Based Remote Physiology Sensing for Hundreds of Subjects Across Skin Tones",
      "title_zh": "翻译失败",
      "authors": [
        "Jiankai Tang",
        "Xinyi Li",
        "Jiacheng Liu",
        "Xiyuxing Zhang",
        "Zeyu Wang",
        "Yuntao Wang"
      ],
      "abstract": "Remote photoplethysmography (rPPG) emerges as a promising method for\nnon-invasive, convenient measurement of vital signs, utilizing the widespread\npresence of cameras. Despite advancements, existing datasets fall short in\nterms of size and diversity, limiting comprehensive evaluation under diverse\nconditions. This paper presents an in-depth analysis of the VitalVideo dataset,\nthe largest real-world rPPG dataset to date, encompassing 893 subjects and 6\nFitzpatrick skin tones. Our experimentation with six unsupervised methods and\nthree supervised models demonstrates that datasets comprising a few hundred\nsubjects(i.e., 300 for UBFC-rPPG, 500 for PURE, and 700 for MMPD-Simple) are\nsufficient for effective rPPG model training. Our findings highlight the\nimportance of diversity and consistency in skin tones for precise performance\nevaluation across different datasets.",
      "tldr_zh": "这篇论文分析了基于摄像头的远程光电容积描记术 (rPPG)，一种非侵入式测量生命体征的方法，并引入了 VitalVideo 数据集，这是目前最大的真实世界 rPPG 数据集，涵盖 893 名受试者和 6 种 Fitzpatrick 皮肤色调。研究通过实验评估六种无监督方法和三种监督模型，结果显示，使用几百名受试者（如 UBFC-rPPG 的 300 人、PURE 的 500 人或 MMPD-Simple 的 700 人）即可有效训练 rPPG 模型。论文强调，皮肤色调的多样性和一致性对不同数据集的性能评估至关重要，从而提升 rPPG 技术的可靠性和普适性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "11 pages, 5 figures, CHI24 Workshop PhysioCHI",
      "pdf_url": "http://arxiv.org/pdf/2404.05003v1",
      "published_date": "2024-04-07 15:58:25 UTC",
      "updated_date": "2024-04-07 15:58:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:23:37.543123"
    },
    {
      "arxiv_id": "2404.04998v1",
      "title": "Weakly Supervised Deep Hyperspherical Quantization for Image Retrieval",
      "title_zh": "翻译失败",
      "authors": [
        "Jinpeng Wang",
        "Bin Chen",
        "Qiang Zhang",
        "Zaiqiao Meng",
        "Shangsong Liang",
        "Shu-Tao Xia"
      ],
      "abstract": "Deep quantization methods have shown high efficiency on large-scale image\nretrieval. However, current models heavily rely on ground-truth information,\nhindering the application of quantization in label-hungry scenarios. A more\nrealistic demand is to learn from inexhaustible uploaded images that are\nassociated with informal tags provided by amateur users. Though such sketchy\ntags do not obviously reveal the labels, they actually contain useful semantic\ninformation for supervising deep quantization. To this end, we propose\nWeakly-Supervised Deep Hyperspherical Quantization (WSDHQ), which is the first\nwork to learn deep quantization from weakly tagged images. Specifically, 1) we\nuse word embeddings to represent the tags and enhance their semantic\ninformation based on a tag correlation graph. 2) To better preserve semantic\ninformation in quantization codes and reduce quantization error, we jointly\nlearn semantics-preserving embeddings and supervised quantizer on hypersphere\nby employing a well-designed fusion layer and tailor-made loss functions.\nExtensive experiments show that WSDHQ can achieve state-of-art performance on\nweakly-supervised compact coding. Code is available at\nhttps://github.com/gimpong/AAAI21-WSDHQ.",
      "tldr_zh": "本文提出了一种名为 Weakly-Supervised Deep Hyperspherical Quantization (WSDHQ) 的方法，用于图像检索领域，旨在解决传统深度量化模型对真实标签的过度依赖问题，通过从弱标记图像（如用户提供的非正式标签）中学习来提升效率。方法包括使用 word embeddings 表示标签，并基于 tag correlation graph 增强语义信息，同时在 hypersphere 上联合学习语义保留嵌入和监督量化器，以减少量化误差并更好地保留语义。实验结果显示，WSDHQ 在弱监督紧凑编码任务上达到了 state-of-the-art 性能，并提供了开源代码。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CV",
      "comment": "In proceedings of AAAI 2021. Code and data are available",
      "pdf_url": "http://arxiv.org/pdf/2404.04998v1",
      "published_date": "2024-04-07 15:48:33 UTC",
      "updated_date": "2024-04-07 15:48:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:23:51.500883"
    },
    {
      "arxiv_id": "2404.04997v2",
      "title": "Adapting LLMs for Efficient Context Processing through Soft Prompt Compression",
      "title_zh": "翻译失败",
      "authors": [
        "Cangqing Wang",
        "Yutian Yang",
        "Ruisi Li",
        "Dan Sun",
        "Ruicong Cai",
        "Yuzhu Zhang",
        "Chengqian Fu",
        "Lillian Floyd"
      ],
      "abstract": "The rapid advancement of Large Language Models (LLMs) has inaugurated a\ntransformative epoch in natural language processing, fostering unprecedented\nproficiency in text generation, comprehension, and contextual scrutiny.\nNevertheless, effectively handling extensive contexts, crucial for myriad\napplications, poses a formidable obstacle owing to the intrinsic constraints of\nthe models' context window sizes and the computational burdens entailed by\ntheir operations. This investigation presents an innovative framework that\nstrategically tailors LLMs for streamlined context processing by harnessing the\nsynergies among natural language summarization, soft prompt compression, and\naugmented utility preservation mechanisms. Our methodology, dubbed\nSoftPromptComp, amalgamates natural language prompts extracted from\nsummarization methodologies with dynamically generated soft prompts to forge a\nconcise yet semantically robust depiction of protracted contexts. This\ndepiction undergoes further refinement via a weighting mechanism optimizing\ninformation retention and utility for subsequent tasks. We substantiate that\nour framework markedly diminishes computational overhead and enhances LLMs'\nefficacy across various benchmarks, while upholding or even augmenting the\ncaliber of the produced content. By amalgamating soft prompt compression with\nsophisticated summarization, SoftPromptComp confronts the dual challenges of\nmanaging lengthy contexts and ensuring model scalability. Our findings point\ntowards a propitious trajectory for augmenting LLMs' applicability and\nefficiency, rendering them more versatile and pragmatic for real-world\napplications. This research enriches the ongoing discourse on optimizing\nlanguage models, providing insights into the potency of soft prompts and\nsummarization techniques as pivotal instruments for the forthcoming generation\nof NLP solutions.",
      "tldr_zh": "这篇论文提出SoftPromptComp框架，用于优化Large Language Models (LLMs)处理长上下文的效率，通过整合自然语言总结、软提示压缩和增强实用性机制来应对模型上下文窗口限制和计算负担的挑战。框架的核心方法是将从总结中提取的自然语言提示与动态生成的软提示结合，并通过加权机制优化信息保留，确保语义完整性。实验结果表明，SoftPromptComp显著降低了计算开销，并在各种基准测试中提升了LLMs的性能，同时维持或提高了输出质量。该研究为LLMs的实际应用提供了更具可扩展性的路径，促进了NLP解决方案的创新。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "This paper has been accepted by the 2024 International Conference on\n  Image Processing and Computer Applications (IPCA 2024)",
      "pdf_url": "http://arxiv.org/pdf/2404.04997v2",
      "published_date": "2024-04-07 15:44:20 UTC",
      "updated_date": "2024-04-18 23:23:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:24:02.124282"
    },
    {
      "arxiv_id": "2404.04986v1",
      "title": "Dynamic Distinction Learning: Adaptive Pseudo Anomalies for Video Anomaly Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Demetris Lappas",
        "Vasileios Argyriou",
        "Dimitrios Makris"
      ],
      "abstract": "We introduce Dynamic Distinction Learning (DDL) for Video Anomaly Detection,\na novel video anomaly detection methodology that combines pseudo-anomalies,\ndynamic anomaly weighting, and a distinction loss function to improve detection\naccuracy. By training on pseudo-anomalies, our approach adapts to the\nvariability of normal and anomalous behaviors without fixed anomaly thresholds.\nOur model showcases superior performance on the Ped2, Avenue and ShanghaiTech\ndatasets, where individual models are tailored for each scene. These\nachievements highlight DDL's effectiveness in advancing anomaly detection,\noffering a scalable and adaptable solution for video surveillance challenges.",
      "tldr_zh": "本文提出 Dynamic Distinction Learning (DDL)，一种用于视频异常检测的新方法，通过生成 pseudo-anomalies、dynamic anomaly weighting 和 distinction loss function 来提升检测准确性。DDL 能够在不依赖固定异常阈值的情况下，适应正常和异常行为的变异性，并在 Ped2、Avenue 和 ShanghaiTech 数据集上表现出色，每个场景的模型均经过定制优化。这些成果突显了 DDL 在视频监控领域的可扩展性和适应性潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "To be published in the CVPR2024 Workshop",
      "pdf_url": "http://arxiv.org/pdf/2404.04986v1",
      "published_date": "2024-04-07 15:06:48 UTC",
      "updated_date": "2024-04-07 15:06:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:24:14.711866"
    },
    {
      "arxiv_id": "2404.04983v1",
      "title": "Primary liver cancer classification from routine tumour biopsy using weakly supervised deep learning",
      "title_zh": "翻译失败",
      "authors": [
        "Aurélie Beaufrère",
        "Nora Ouzir",
        "Paul Emile Zafar",
        "Astrid Laurent-Bellue",
        "Miguel Albuquerque",
        "Gwladys Lubuela",
        "Jules Grégory",
        "Catherine Guettier",
        "Kévin Mondet",
        "Jean-Christophe Pesquet",
        "Valérie Paradis"
      ],
      "abstract": "The diagnosis of primary liver cancers (PLCs) can be challenging, especially\non biopsies and for combined hepatocellular-cholangiocarcinoma (cHCC-CCA). We\nautomatically classified PLCs on routine-stained biopsies using a weakly\nsupervised learning method. Weak tumour/non-tumour annotations served as labels\nfor training a Resnet18 neural network, and the network's last convolutional\nlayer was used to extract new tumour tile features. Without knowledge of the\nprecise labels of the malignancies, we then applied an unsupervised clustering\nalgorithm. Our model identified specific features of hepatocellular carcinoma\n(HCC) and intrahepatic cholangiocarcinoma (iCCA). Despite no specific features\nof cHCC-CCA being recognized, the identification of HCC and iCCA tiles within a\nslide could facilitate the diagnosis of primary liver cancers, particularly\ncHCC-CCA.\n  Method and results: 166 PLC biopsies were divided into training, internal and\nexternal validation sets: 90, 29 and 47 samples. Two liver pathologists\nreviewed each whole-slide hematein eosin saffron (HES)-stained image (WSI).\nAfter annotating the tumour/non-tumour areas, 256x256 pixel tiles were\nextracted from the WSIs and used to train a ResNet18. The network was used to\nextract new tile features. An unsupervised clustering algorithm was then\napplied to the new tile features. In a two-cluster model, Clusters 0 and 1\ncontained mainly HCC and iCCA histological features. The diagnostic agreement\nbetween the pathological diagnosis and the model predictions in the internal\nand external validation sets was 100% (11/11) and 96% (25/26) for HCC and 78%\n(7/9) and 87% (13/15) for iCCA, respectively. For cHCC-CCA, we observed a\nhighly variable proportion of tiles from each cluster (Cluster 0: 5-97%;\nCluster 1: 2-94%).",
      "tldr_zh": "该研究提出了一种弱监督深度学习方法，用于从常规肿瘤活检中自动分类原发性肝癌 (PLCs)，特别针对混合性肝细胞-胆管癌 (cHCC-CCA) 的诊断挑战。方法包括使用弱标签训练 ResNet18 神经网络提取肿瘤特征，随后应用无监督聚类算法识别肝细胞癌 (HCC) 和 肝内胆管癌 (iCCA) 的特定特征。实验结果显示，该模型在内部和外部验证集上，对 HCC 的诊断准确率分别为 100% 和 96%，对 iCCA 分别为 78% 和 87%，并通过检测滑片中不同特征比例辅助 cHCC-CCA 的诊断，从而提升了肝癌活检的精确性和效率。",
      "categories": [
        "q-bio.TO",
        "cs.AI",
        "cs.CV",
        "I.5; I.4; I.2"
      ],
      "primary_category": "q-bio.TO",
      "comment": "https://www.sciencedirect.com/science/article/pii/S2589555924000090",
      "pdf_url": "http://arxiv.org/pdf/2404.04983v1",
      "published_date": "2024-04-07 15:03:46 UTC",
      "updated_date": "2024-04-07 15:03:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:24:28.948043"
    },
    {
      "arxiv_id": "2404.04974v1",
      "title": "Neural Network Modeling for Forecasting Tourism Demand in Stopića Cave: A Serbian Cave Tourism Study",
      "title_zh": "翻译失败",
      "authors": [
        "Buda Bajić",
        "Srđan Milićević",
        "Aleksandar Antić",
        "Slobodan Marković",
        "Nemanja Tomić"
      ],
      "abstract": "For modeling the number of visits in Stopi\\'{c}a cave (Serbia) we consider\nthe classical Auto-regressive Integrated Moving Average (ARIMA) model, Machine\nLearning (ML) method Support Vector Regression (SVR), and hybrid NeuralPropeth\nmethod which combines classical and ML concepts. The most accurate predictions\nwere obtained with NeuralPropeth which includes the seasonal component and\ngrowing trend of time-series. In addition, non-linearity is modeled by shallow\nNeural Network (NN), and Google Trend is incorporated as an exogenous variable.\nModeling tourist demand represents great importance for management structures\nand decision-makers due to its applicability in establishing sustainable\ntourism utilization strategies in environmentally vulnerable destinations such\nas caves. The data provided insights into the tourist demand in Stopi\\'{c}a\ncave and preliminary data for addressing the issues of carrying capacity within\nthe most visited cave in Serbia.",
      "tldr_zh": "本研究针对塞尔维亚 Stopića 洞穴的游客需求进行了预测建模，比较了经典 ARIMA 模型、机器学习方法 SVR，以及混合方法 NeuralProphet，后者整合了季节性成分、增长趋势、浅层 Neural Network (NN) 建模非线性，以及 Google Trend 作为外生变量。结果显示，NeuralProphet 提供了最准确的预测。研究为管理者和决策者提供了关键洞见，有助于制定可持续旅游策略，解决环境脆弱地区如洞穴的承载容量问题。",
      "categories": [
        "econ.EM",
        "cs.AI"
      ],
      "primary_category": "econ.EM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.04974v1",
      "published_date": "2024-04-07 14:33:06 UTC",
      "updated_date": "2024-04-07 14:33:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:24:38.403156"
    },
    {
      "arxiv_id": "2404.04969v1",
      "title": "Temporal Generalization Estimation in Evolving Graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Bin Lu",
        "Tingyan Ma",
        "Xiaoying Gan",
        "Xinbing Wang",
        "Yunqiang Zhu",
        "Chenghu Zhou",
        "Shiyu Liang"
      ],
      "abstract": "Graph Neural Networks (GNNs) are widely deployed in vast fields, but they\noften struggle to maintain accurate representations as graphs evolve. We\ntheoretically establish a lower bound, proving that under mild conditions,\nrepresentation distortion inevitably occurs over time. To estimate the temporal\ndistortion without human annotation after deployment, one naive approach is to\npre-train a recurrent model (e.g., RNN) before deployment and use this model\nafterwards, but the estimation is far from satisfactory. In this paper, we\nanalyze the representation distortion from an information theory perspective,\nand attribute it primarily to inaccurate feature extraction during evolution.\nConsequently, we introduce Smart, a straightforward and effective baseline\nenhanced by an adaptive feature extractor through self-supervised graph\nreconstruction. In synthetic random graphs, we further refine the former lower\nbound to show the inevitable distortion over time and empirically observe that\nSmart achieves good estimation performance. Moreover, we observe that Smart\nconsistently shows outstanding generalization estimation on four real-world\nevolving graphs. The ablation studies underscore the necessity of graph\nreconstruction. For example, on OGB-arXiv dataset, the estimation metric MAPE\ndeteriorates from 2.19% to 8.00% without reconstruction.",
      "tldr_zh": "本研究探讨了 Graph Neural Networks (GNNs) 在演化图中的表示失真问题，理论上建立了失真的下界，证明了在温和条件下这种失真不可避免，并从 information theory 角度分析其主要源于特征提取不准确。\n为此，作者提出 Smart 方法，一种简单有效的基准框架，通过自监督图重建增强自适应特征提取器，以精确估计时序失真。\n实验结果显示，Smart 在合成随机图和四个真实世界演化图上表现出色，例如在 OGB-arXiv 数据集上，MAPE 指标从无重建时的 8.00% 改善至 2.19%，验证了图重建的必要性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Published as a conference paper at ICLR 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.04969v1",
      "published_date": "2024-04-07 14:19:22 UTC",
      "updated_date": "2024-04-07 14:19:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:24:51.083158"
    },
    {
      "arxiv_id": "2404.04963v1",
      "title": "SemEval-2024 Task 2: Safe Biomedical Natural Language Inference for Clinical Trials",
      "title_zh": "SemEval-2024 Task 2：临床试验的安全生物",
      "authors": [
        "Mael Jullien",
        "Marco Valentino",
        "André Freitas"
      ],
      "abstract": "Large Language Models (LLMs) are at the forefront of NLP achievements but\nfall short in dealing with shortcut learning, factual inconsistency, and\nvulnerability to adversarial inputs.These shortcomings are especially critical\nin medical contexts, where they can misrepresent actual model capabilities.\nAddressing this, we present SemEval-2024 Task 2: Safe Biomedical Natural\nLanguage Inference for ClinicalTrials. Our contributions include the refined\nNLI4CT-P dataset (i.e., Natural Language Inference for Clinical Trials -\nPerturbed), designed to challenge LLMs with interventional and causal reasoning\ntasks, along with a comprehensive evaluation of methods and results for\nparticipant submissions. A total of 106 participants registered for the task\ncontributing to over 1200 individual submissions and 25 system overview papers.\nThis initiative aims to advance the robustness and applicability of NLI models\nin healthcare, ensuring safer and more dependable AI assistance in clinical\ndecision-making. We anticipate that the dataset, models, and outcomes of this\ntask can support future research in the field of biomedical NLI. The dataset,\ncompetition leaderboard, and website are publicly available.",
      "tldr_zh": "本研究介绍了 SemEval-2024 Task 2：Safe Biomedical Natural Language Inference for Clinical Trials，这是一个针对 Large Language Models (LLMs) 在医疗领域的不足（如快捷学习、事实不一致性和对抗输入脆弱性）而设计的任务。研究的主要贡献是精炼的 NLI4CT-P 数据集，用于挑战 LLMs 在介入和因果推理任务上的能力，并通过竞赛形式评估参与者提交的模型。竞赛吸引了106名参与者、超过1200个提交和25篇系统概述，证明了该任务在提升生物医学 NLI 模型的鲁棒性和可靠性方面的潜力，并提供了公开数据集和资源以支持未来医疗 AI 研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.04963v1",
      "published_date": "2024-04-07 13:58:41 UTC",
      "updated_date": "2024-04-07 13:58:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:25:06.415722"
    },
    {
      "arxiv_id": "2404.04947v2",
      "title": "Gull: A Generative Multifunctional Audio Codec",
      "title_zh": "Gull：一个生成式多功能音频编解码器",
      "authors": [
        "Yi Luo",
        "Jianwei Yu",
        "Hangting Chen",
        "Rongzhi Gu",
        "Chao Weng"
      ],
      "abstract": "We introduce Gull, a generative multifunctional audio codec. Gull is a\ngeneral purpose neural audio compression and decompression model which can be\napplied to a wide range of tasks and applications such as real-time\ncommunication, audio super-resolution, and codec language models. The key\ncomponents of Gull include (1) universal-sample-rate modeling via subband\nmodeling schemes motivated by recent progress in audio source separation, (2)\ngain-shape representations motivated by traditional audio codecs, (3) improved\nresidual vector quantization modules, (4) elastic decoder network that enables\nuser-defined model size and complexity during inference time, (5) built-in\nability for audio super-resolution without the increase of bitrate. We compare\nGull with existing traditional and neural audio codecs and show that Gull is\nable to achieve on par or better performance across various sample rates,\nbitrates and model complexities in both subjective and objective evaluation\nmetrics.",
      "tldr_zh": "本研究引入了 Gull，一种生成式多功能音频编解码器，能够应用于实时通信、音频超分辨率和编解码器语言模型等多种任务。Gull 的关键组件包括基于子带建模的通用采样率处理、受传统编解码器启发的增益-形状表示、改进的残差矢量量化模块、弹性解码器网络（允许推理时自定义模型大小和复杂度），以及内置音频 super-resolution 能力而不增加比特率。通过主观和客观评估，Gull 在各种采样率、比特率和模型复杂度下，与现有传统和神经音频编解码器相比，实现了相当或更好的性能。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.LG",
        "cs.SD",
        "eess.SP"
      ],
      "primary_category": "eess.AS",
      "comment": "Demo page: https://yluo42.github.io/Gull/",
      "pdf_url": "http://arxiv.org/pdf/2404.04947v2",
      "published_date": "2024-04-07 12:57:46 UTC",
      "updated_date": "2024-06-07 07:03:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:25:14.696790"
    },
    {
      "arxiv_id": "2404.04943v1",
      "title": "Chiplet Placement Order Exploration Based on Learning to Rank with Graph Representation",
      "title_zh": "翻译失败",
      "authors": [
        "Zhihui Deng",
        "Yuanyuan Duan",
        "Leilai Shao",
        "Xiaolei Zhu"
      ],
      "abstract": "Chiplet-based systems, integrating various silicon dies manufactured at\ndifferent integrated circuit technology nodes on a carrier interposer, have\ngarnered significant attention in recent years due to their cost-effectiveness\nand competitive performance. The widespread adoption of reinforcement learning\nas a sequential placement method has introduced a new challenge in determining\nthe optimal placement order for each chiplet. The order in which chiplets are\nplaced on the interposer influences the spatial resources available for earlier\nand later placed chiplets, making the placement results highly sensitive to the\nsequence of chiplet placement. To address these challenges, we propose a\nlearning to rank approach with graph representation, building upon the\nreinforcement learning framework RLPlanner. This method aims to select the\noptimal chiplet placement order for each chiplet-based system. Experimental\nresults demonstrate that compared to placement order obtained solely based on\nthe descending order of the chiplet area and the number of interconnect wires\nbetween the chiplets, utilizing the placement order obtained from the learning\nto rank network leads to further improvements in system temperature and\ninter-chiplet wirelength. Specifically, applying the top-ranked placement order\nobtained from the learning to rank network results in a 10.05% reduction in\ntotal inter-chiplet wirelength and a 1.01% improvement in peak system\ntemperature during the chiplet placement process.",
      "tldr_zh": "该论文探讨了 Chiplet-based 系统中的芯片放置顺序问题，提出了一种基于 Learning to Rank 和 Graph Representation 的方法，以优化放置顺序。该方法构建在 Reinforcement Learning 框架 RLPlanner 之上，通过图表示学习来选择最佳芯片放置顺序，从而减少空间资源冲突。实验结果显示，与基于芯片面积和互连线数降序的传统方法相比，新方法实现了总互连线长度减少 10.05% 和峰值系统温度改善 1.01%。这为 Chiplet 系统设计提供了更高效的优化策略。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.AR"
      ],
      "primary_category": "cs.LG",
      "comment": "6 pages, 8 figures and 6 tables, accepted by the Conference ISEDA",
      "pdf_url": "http://arxiv.org/pdf/2404.04943v1",
      "published_date": "2024-04-07 12:40:37 UTC",
      "updated_date": "2024-04-07 12:40:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:25:27.232973"
    },
    {
      "arxiv_id": "2404.04932v1",
      "title": "Towards Understanding the Influence of Reward Margin on Preference Model Performance",
      "title_zh": "翻译失败",
      "authors": [
        "Bowen Qin",
        "Duanyu Feng",
        "Xi Yang"
      ],
      "abstract": "Reinforcement Learning from Human Feedback (RLHF) is a widely used framework\nfor the training of language models. However, the process of using RLHF to\ndevelop a language model that is well-aligned presents challenges, especially\nwhen it comes to optimizing the reward model. Our research has found that\nexisting reward models, when trained using the traditional ranking objective\nbased on human preference data, often struggle to effectively distinguish\nbetween responses that are more or less favorable in real-world scenarios. To\nbridge this gap, our study introduces a novel method to estimate the preference\ndifferences without the need for detailed, exhaustive labels from human\nannotators. Our experimental results provide empirical evidence that\nincorporating margin values into the training process significantly improves\nthe effectiveness of reward models. This comparative analysis not only\ndemonstrates the superiority of our approach in terms of reward prediction\naccuracy but also highlights its effectiveness in practical applications.",
      "tldr_zh": "本研究探讨了强化学习从人类反馈（RLHF）在训练语言模型中的挑战，特别是现有奖励模型在使用传统排名目标训练时，难以有效区分真实场景中优劣响应的问题。为了解决这一问题，研究引入了一种新方法，通过估计偏好差异的方式（无需详细人类标注）将 margin values 融入训练过程，从而显著提升奖励模型的表现。实验结果显示，这种方法在奖励预测准确性和实际应用中均优于传统方法，提供了一个更有效的优化策略。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.04932v1",
      "published_date": "2024-04-07 12:10:04 UTC",
      "updated_date": "2024-04-07 12:10:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:25:37.417939"
    },
    {
      "arxiv_id": "2404.04924v1",
      "title": "GvT: A Graph-based Vision Transformer with Talking-Heads Utilizing Sparsity, Trained from Scratch on Small Datasets",
      "title_zh": "翻译失败",
      "authors": [
        "Dongjing Shan",
        "guiqiang chen"
      ],
      "abstract": "Vision Transformers (ViTs) have achieved impressive results in large-scale\nimage classification. However, when training from scratch on small datasets,\nthere is still a significant performance gap between ViTs and Convolutional\nNeural Networks (CNNs), which is attributed to the lack of inductive bias. To\naddress this issue, we propose a Graph-based Vision Transformer (GvT) that\nutilizes graph convolutional projection and graph-pooling. In each block,\nqueries and keys are calculated through graph convolutional projection based on\nthe spatial adjacency matrix, while dot-product attention is used in another\ngraph convolution to generate values. When using more attention heads, the\nqueries and keys become lower-dimensional, making their dot product an\nuninformative matching function. To overcome this low-rank bottleneck in\nattention heads, we employ talking-heads technology based on bilinear pooled\nfeatures and sparse selection of attention tensors. This allows interaction\namong filtered attention scores and enables each attention mechanism to depend\non all queries and keys. Additionally, we apply graph-pooling between two\nintermediate blocks to reduce the number of tokens and aggregate semantic\ninformation more effectively. Our experimental results show that GvT produces\ncomparable or superior outcomes to deep convolutional networks and surpasses\nvision transformers without pre-training on large datasets. The code for our\nproposed model is publicly available on the website.",
      "tldr_zh": "该论文提出了一种Graph-based Vision Transformer (GvT)，旨在解决Vision Transformers (ViTs)在小数据集上从零训练时性能落后于Convolutional Neural Networks (CNNs)的归纳偏差问题。GvT通过图卷积投影和图池化来计算查询、键和值，并在注意力机制中引入talking-heads技术，利用双线性池化特征和稀疏选择来克服注意力头的低秩瓶颈，从而增强注意力分数间的交互。实验结果显示，GvT在小数据集上训练时，性能可与深度CNNs相当或优于无预训练的ViTs，并提供了公开代码以供复现。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.04924v1",
      "published_date": "2024-04-07 11:48:07 UTC",
      "updated_date": "2024-04-07 11:48:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:25:51.324738"
    },
    {
      "arxiv_id": "2404.04922v1",
      "title": "Efficient Learnable Collaborative Attention for Single Image Super-Resolution",
      "title_zh": "翻译失败",
      "authors": [
        "Yigang Zhao Chaowei Zheng",
        "Jiannan Su",
        "GuangyongChen",
        "MinGan"
      ],
      "abstract": "Non-Local Attention (NLA) is a powerful technique for capturing long-range\nfeature correlations in deep single image super-resolution (SR). However, NLA\nsuffers from high computational complexity and memory consumption, as it\nrequires aggregating all non-local feature information for each query response\nand recalculating the similarity weight distribution for different abstraction\nlevels of features. To address these challenges, we propose a novel Learnable\nCollaborative Attention (LCoA) that introduces inductive bias into non-local\nmodeling. Our LCoA consists of two components: Learnable Sparse Pattern (LSP)\nand Collaborative Attention (CoA). LSP uses the k-means clustering algorithm to\ndynamically adjust the sparse attention pattern of deep features, which reduces\nthe number of non-local modeling rounds compared with existing sparse\nsolutions. CoA leverages the sparse attention pattern and weights learned by\nLSP, and co-optimizes the similarity matrix across different abstraction\nlevels, which avoids redundant similarity matrix calculations. The experimental\nresults show that our LCoA can reduce the non-local modeling time by about 83%\nin the inference stage. In addition, we integrate our LCoA into a deep\nLearnable Collaborative Attention Network (LCoAN), which achieves competitive\nperformance in terms of inference time, memory consumption, and reconstruction\nquality compared with other state-of-the-art SR methods.",
      "tldr_zh": "该论文针对单图像超分辨率 (SR) 中的 Non-Local Attention (NLA) 问题，提出了一种高效的 Learnable Collaborative Attention (LCoA) 方法，以解决其高计算复杂度和内存消耗问题。LCoA 包括两个关键组件：Learnable Sparse Pattern (LSP) 使用 k-means 聚类算法动态调整深层特征的稀疏注意力模式，从而减少非局部建模轮次；以及 Collaborative Attention (CoA) 基于 LSP 学到的模式和权重，在不同抽象级别上共同优化相似性矩阵，避免冗余计算。实验结果表明，LCoA 在推理阶段可将非局部建模时间减少约 83%，并在 Learnable Collaborative Attention Network (LCoAN) 中实现与现有最先进 SR 方法相当的推理时间、内存效率和重建质量。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.04922v1",
      "published_date": "2024-04-07 11:25:04 UTC",
      "updated_date": "2024-04-07 11:25:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:26:04.779769"
    },
    {
      "arxiv_id": "2404.05767v1",
      "title": "CSA-Trans: Code Structure Aware Transformer for AST",
      "title_zh": "翻译失败",
      "authors": [
        "Saeyoon Oh",
        "Shin Yoo"
      ],
      "abstract": "When applying the Transformer architecture to source code, designing a good\nself-attention mechanism is critical as it affects how node relationship is\nextracted from the Abstract Syntax Trees (ASTs) of the source code. We present\nCode Structure Aware Transformer (CSA-Trans), which uses Code Structure\nEmbedder (CSE) to generate specific PE for each node in AST. CSE generates node\nPositional Encoding (PE) using disentangled attention. To further extend the\nself-attention capability, we adopt Stochastic Block Model (SBM) attention. Our\nevaluation shows that our PE captures the relationships between AST nodes\nbetter than other graph-related PE techniques. We also show through\nquantitative and qualitative analysis that SBM attention is able to generate\nmore node specific attention coefficients. We demonstrate that CSA-Trans\noutperforms 14 baselines in code summarization tasks for both Python and Java,\nwhile being 41.92% faster and 25.31% memory efficient in Java dataset compared\nto AST-Trans and SG-Trans respectively.",
      "tldr_zh": "该研究提出了一种Code Structure Aware Transformer (CSA-Trans)，旨在通过更好地提取Abstract Syntax Trees (AST)中的节点关系来提升源代码处理性能。CSA-Trans 利用Code Structure Embedder (CSE)生成特定节点Positional Encoding (PE)，采用disentangled attention机制，并引入Stochastic Block Model (SBM) attention来增强自注意力能力，从而更准确地捕捉AST节点间的关系。实验结果显示，CSA-Trans在Python和Java的代码总结任务中优于14个基线模型，同时在Java数据集上比AST-Trans和SG-Trans分别快41.92%并节省25.31%的内存。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.05767v1",
      "published_date": "2024-04-07 10:59:35 UTC",
      "updated_date": "2024-04-07 10:59:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:26:13.903785"
    },
    {
      "arxiv_id": "2404.08679v2",
      "title": "Your Finetuned Large Language Model is Already a Powerful Out-of-distribution Detector",
      "title_zh": "你的微调大语言模型已经是强大的分布外检测器",
      "authors": [
        "Andi Zhang",
        "Tim Z. Xiao",
        "Weiyang Liu",
        "Robert Bamler",
        "Damon Wischik"
      ],
      "abstract": "We revisit the likelihood ratio between a pretrained large language model\n(LLM) and its finetuned variant as a criterion for out-of-distribution (OOD)\ndetection. The intuition behind such a criterion is that, the pretrained LLM\nhas the prior knowledge about OOD data due to its large amount of training\ndata, and once finetuned with the in-distribution data, the LLM has sufficient\nknowledge to distinguish their difference. Leveraging the power of LLMs, we\nshow that, the likelihood ratio can serve as an effective OOD detection\ncriterion. Moreover, we apply the proposed LLM-based likelihood ratio to detect\nOOD questions in question-answering (QA) systems, which can be used to improve\nthe performance of specialized LLMs for general questions. Given that\nlikelihood can be easily obtained by the loss functions within contemporary\nneural network frameworks, it is straightforward to implement this approach in\npractice. Since both the pretrained LLMs and its various finetuned models are\nwidely available from online platforms such as Hugging Face, our proposed\ncriterion can be effortlessly incorporated for OOD detection without the need\nfor further training. We conduct comprehensive evaluation across on multiple\nsettings, including far OOD, near OOD, spam detection, and QA scenarios, to\ndemonstrate the effectiveness of the method. Code can be found at\nhttps://github.com/andiac/LLMOODratio",
      "tldr_zh": "本文提出使用预训练的大型语言模型 (LLM) 与其微调版本之间的似然比 (likelihood ratio) 作为 Out-of-distribution (OOD) 检测的标准，利用 LLM 的先验知识来有效识别 OOD 数据，而无需额外训练。方法基于损失函数轻松实现，并可直接应用于问答 (QA) 系统，以提升专用 LLM 处理一般问题的性能。实验在远 OOD、近 OOD、垃圾检测和 QA 场景中进行了全面评估，证明该方法显著优于基线。代码可在 https://github.com/andiac/LLMOODratio 获取。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.08679v2",
      "published_date": "2024-04-07 10:32:49 UTC",
      "updated_date": "2025-03-05 19:51:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:26:27.582920"
    },
    {
      "arxiv_id": "2404.04905v1",
      "title": "Review for Handling Missing Data with special missing mechanism",
      "title_zh": "针对特殊缺失",
      "authors": [
        "Youran Zhou",
        "Sunil Aryal",
        "Mohamed Reda Bouadjenek"
      ],
      "abstract": "Missing data poses a significant challenge in data science, affecting\ndecision-making processes and outcomes. Understanding what missing data is, how\nit occurs, and why it is crucial to handle it appropriately is paramount when\nworking with real-world data, especially in tabular data, one of the most\ncommonly used data types in the real world. Three missing mechanisms are\ndefined in the literature: Missing Completely At Random (MCAR), Missing At\nRandom (MAR), and Missing Not At Random (MNAR), each presenting unique\nchallenges in imputation. Most existing work are focused on MCAR that is\nrelatively easy to handle. The special missing mechanisms of MNAR and MAR are\nless explored and understood. This article reviews existing literature on\nhandling missing values. It compares and contrasts existing methods in terms of\ntheir ability to handle different missing mechanisms and data types. It\nidentifies research gap in the existing literature and lays out potential\ndirections for future research in the field. The information in this review\nwill help data analysts and researchers to adopt and promote good practices for\nhandling missing data in real-world problems.",
      "tldr_zh": "该论文审视了缺失数据在数据科学中的挑战，特别是针对特殊缺失机制如 Missing Not At Random (MNAR) 和 Missing At Random (MAR)，而非常见且较易处理的 Missing Completely At Random (MCAR)。作者回顾了现有文献，比较了各种方法在处理不同缺失机制和数据类型（如表格数据）时的优缺点，并识别出研究领域的空白，例如对 MNAR 和 MAR 的不足探索。论文提出未来研究方向，并强调这些见解有助于数据分析师和研究人员在实际问题中采用更有效的缺失数据处理实践。",
      "categories": [
        "stat.ME",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ME",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.04905v1",
      "published_date": "2024-04-07 10:11:22 UTC",
      "updated_date": "2024-04-07 10:11:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:26:37.603220"
    },
    {
      "arxiv_id": "2404.04904v2",
      "title": "Cross-Domain Audio Deepfake Detection: Dataset and Analysis",
      "title_zh": "跨域音频深度伪造检测：数据集和分析",
      "authors": [
        "Yuang Li",
        "Min Zhang",
        "Mengxin Ren",
        "Miaomiao Ma",
        "Daimeng Wei",
        "Hao Yang"
      ],
      "abstract": "Audio deepfake detection (ADD) is essential for preventing the misuse of\nsynthetic voices that may infringe on personal rights and privacy. Recent\nzero-shot text-to-speech (TTS) models pose higher risks as they can clone\nvoices with a single utterance. However, the existing ADD datasets are\noutdated, leading to suboptimal generalization of detection models. In this\npaper, we construct a new cross-domain ADD dataset comprising over 300 hours of\nspeech data that is generated by five advanced zero-shot TTS models. To\nsimulate real-world scenarios, we employ diverse attack methods and audio\nprompts from different datasets. Experiments show that, through novel\nattack-augmented training, the Wav2Vec2-large and Whisper-medium models achieve\nequal error rates of 4.1\\% and 6.5\\% respectively. Additionally, we demonstrate\nour models' outstanding few-shot ADD ability by fine-tuning with just one\nminute of target-domain data. Nonetheless, neural codec compressors greatly\naffect the detection accuracy, necessitating further research.",
      "tldr_zh": "该研究构建了一个新的跨域音频深度伪造检测（Audio Deepfake Detection, ADD）数据集，包含超过300小时的语音数据，由五种先进的零样本文本到语音（Zero-Shot TTS）模型生成，以解决现有数据集过时导致模型泛化性差的问题。数据集通过多样化的攻击方法和音频提示模拟真实场景，并通过攻击增强训练，使Wav2Vec2-large和Whisper-medium模型分别达到4.1%和6.5%的等错误率。实验还证明了这些模型在少样本场景下的出色性能，仅需一分钟目标域数据即可微调；然而，神经编解码器压缩器（neural codec compressors）显著影响检测准确性，需要进一步研究。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.04904v2",
      "published_date": "2024-04-07 10:10:15 UTC",
      "updated_date": "2024-09-20 08:08:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:26:52.548938"
    },
    {
      "arxiv_id": "2404.04903v1",
      "title": "Online Learning under Haphazard Input Conditions: A Comprehensive Review and Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Rohit Agarwal",
        "Arijit Das",
        "Alexander Horsch",
        "Krishna Agarwal",
        "Dilip K. Prasad"
      ],
      "abstract": "The domain of online learning has experienced multifaceted expansion owing to\nits prevalence in real-life applications. Nonetheless, this progression\noperates under the assumption that the input feature space of the streaming\ndata remains constant. In this survey paper, we address the topic of online\nlearning in the context of haphazard inputs, explicitly foregoing such an\nassumption. We discuss, classify, evaluate, and compare the methodologies that\nare adept at modeling haphazard inputs, additionally providing the\ncorresponding code implementations and their carbon footprint. Moreover, we\nclassify the datasets related to the field of haphazard inputs and introduce\nevaluation metrics specifically designed for datasets exhibiting imbalance. The\ncode of each methodology can be found at\nhttps://github.com/Rohit102497/HaphazardInputsReview",
      "tldr_zh": "这篇论文对在线学习（online learning）在haphazard inputs条件下进行了全面审阅和分析，挑战了传统假设，即输入特征空间保持不变。论文分类、评估并比较了处理haphazard inputs的方法，提供对应代码实现及其碳足迹，以促进实际应用。作者还对相关数据集进行了分类，并引入了针对不平衡数据集的专用评估指标，最终在GitHub仓库（https://github.com/Rohit102497/HaphazardInputsReview）中共享代码，支持研究的可复现性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.04903v1",
      "published_date": "2024-04-07 10:07:56 UTC",
      "updated_date": "2024-04-07 10:07:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:27:02.044183"
    },
    {
      "arxiv_id": "2404.04902v1",
      "title": "AI2Apps: A Visual IDE for Building LLM-based AI Agent Applications",
      "title_zh": "翻译失败",
      "authors": [
        "Xin Pang",
        "Zhucong Li",
        "Jiaxiang Chen",
        "Yuan Cheng",
        "Yinghui Xu",
        "Yuan Qi"
      ],
      "abstract": "We introduce AI2Apps, a Visual Integrated Development Environment (Visual\nIDE) with full-cycle capabilities that accelerates developers to build\ndeployable LLM-based AI agent Applications. This Visual IDE prioritizes both\nthe Integrity of its development tools and the Visuality of its components,\nensuring a smooth and efficient building experience.On one hand, AI2Apps\nintegrates a comprehensive development toolkit ranging from a prototyping\ncanvas and AI-assisted code editor to agent debugger, management system, and\ndeployment tools all within a web-based graphical user interface. On the other\nhand, AI2Apps visualizes reusable front-end and back-end code as intuitive\ndrag-and-drop components. Furthermore, a plugin system named AI2Apps Extension\n(AAE) is designed for Extensibility, showcasing how a new plugin with 20\ncomponents enables web agent to mimic human-like browsing behavior. Our case\nstudy demonstrates substantial efficiency improvements, with AI2Apps reducing\ntoken consumption and API calls when debugging a specific sophisticated\nmultimodal agent by approximately 90% and 80%, respectively. The AI2Apps,\nincluding an online demo, open-source code, and a screencast video, is now\npublicly accessible.",
      "tldr_zh": "我们介绍了 AI2Apps，一种视觉集成开发环境 (Visual IDE)，旨在加速开发和部署基于 LLM 的 AI 代理应用，通过整合原型画布、AI 辅助代码编辑器、代理调试器、管理系统和部署工具，提供高效的图形用户界面。AI2Apps 将前端和后端代码可视化为直观的拖拽组件，并通过插件系统 AI2Apps Extension (AAE) 实现扩展性，例如新插件可让网络代理模仿人类浏览行为。案例研究显示，该系统在调试复杂多模态代理时，减少了约 90% 的令牌消耗和 80% 的 API 调用。AI2Apps 现已公开，包括在线演示、开源代码和屏幕录像视频。",
      "categories": [
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.04902v1",
      "published_date": "2024-04-07 10:02:09 UTC",
      "updated_date": "2024-04-07 10:02:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:27:16.485786"
    },
    {
      "arxiv_id": "2404.04886v2",
      "title": "PagPassGPT: Pattern Guided Password Guessing via Generative Pretrained Transformer",
      "title_zh": "翻译失败",
      "authors": [
        "Xingyu Su",
        "Xiaojie Zhu",
        "Yang Li",
        "Yong Li",
        "Chi Chen",
        "Paulo Esteves-Veríssimo"
      ],
      "abstract": "Amidst the surge in deep learning-based password guessing models, challenges\nof generating high-quality passwords and reducing duplicate passwords persist.\nTo address these challenges, we present PagPassGPT, a password guessing model\nconstructed on Generative Pretrained Transformer (GPT). It can perform pattern\nguided guessing by incorporating pattern structure information as background\nknowledge, resulting in a significant increase in the hit rate. Furthermore, we\npropose D&C-GEN to reduce the repeat rate of generated passwords, which adopts\nthe concept of a divide-and-conquer approach. The primary task of guessing\npasswords is recursively divided into non-overlapping subtasks. Each subtask\ninherits the knowledge from the parent task and predicts succeeding tokens. In\ncomparison to the state-of-the-art model, our proposed scheme exhibits the\ncapability to correctly guess 12% more passwords while producing 25% fewer\nduplicates.",
      "tldr_zh": "本研究提出了 PagPassGPT，一种基于 Generative Pretrained Transformer (GPT) 的密码猜测模型，通过整合模式结构信息作为背景知识，实现模式引导的猜测，从而显著提高密码命中率。同时，引入了 D&C-GEN 方法，该方法采用分治策略，将密码猜测任务递归分解为非重叠子任务，每个子任务继承父任务知识并预测后续标记，以减少生成密码的重复率。与最先进模型相比，PagPassGPT 能够正确猜测 12% 更多的密码，同时产生 25% 更少的重复密码。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "Be accepted by DSN 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.04886v2",
      "published_date": "2024-04-07 09:06:14 UTC",
      "updated_date": "2024-06-18 03:05:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:27:27.417783"
    },
    {
      "arxiv_id": "2404.04874v1",
      "title": "Graph Neural Networks for Binary Programming",
      "title_zh": "翻译失败",
      "authors": [
        "Moshe Eliasof",
        "Eldad Haber"
      ],
      "abstract": "This paper investigates a link between Graph Neural Networks (GNNs) and\nBinary Programming (BP) problems, laying the groundwork for GNNs to approximate\nsolutions for these computationally challenging problems. By analyzing the\nsensitivity of BP problems, we are able to frame the solution of BP problems as\na heterophilic node classification task. We then propose Binary-Programming GNN\n(BPGNN), an architecture that integrates graph representation learning\ntechniques with BP-aware features to approximate BP solutions efficiently.\nAdditionally, we introduce a self-supervised data generation mechanism, to\nenable efficient and tractable training data acquisition even for large-scale\nBP problems. Experimental evaluations of BPGNN across diverse BP problem sizes\nshowcase its superior performance compared to exhaustive search and heuristic\napproaches. Finally, we discuss open challenges in the under-explored field of\nBP problems with GNNs.",
      "tldr_zh": "这篇论文探讨了 Graph Neural Networks (GNNs) 在 Binary Programming (BP) 问题中的应用，将 BP 问题建模为异质节点分类任务，以利用 GNNs 高效近似解决方案。作者提出 Binary-Programming GNN (BPGNN) 架构，结合图表示学习技术和 BP 特定特征，提升了问题的求解效率。同时，引入自监督数据生成机制，便于为大规模 BP 问题获取训练数据。实验结果显示，BPGNN 在不同规模的 BP 问题上，性能优于穷举搜索和启发式方法。最后，论文讨论了 GNNs 在 BP 领域存在的开放挑战。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.04874v1",
      "published_date": "2024-04-07 08:38:35 UTC",
      "updated_date": "2024-04-07 08:38:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:27:39.605932"
    },
    {
      "arxiv_id": "2404.04871v1",
      "title": "Data Stream Sampling with Fuzzy Task Boundaries and Noisy Labels",
      "title_zh": "带有模糊任务边界和噪声标签的数据流采样",
      "authors": [
        "Yu-Hsi Chen"
      ],
      "abstract": "In the realm of continual learning, the presence of noisy labels within data\nstreams represents a notable obstacle to model reliability and fairness. We\nfocus on the data stream scenario outlined in pertinent literature,\ncharacterized by fuzzy task boundaries and noisy labels. To address this\nchallenge, we introduce a novel and intuitive sampling method called Noisy Test\nDebiasing (NTD) to mitigate noisy labels in evolving data streams and establish\na fair and robust continual learning algorithm. NTD is straightforward to\nimplement, making it feasible across various scenarios. Our experiments\nbenchmark four datasets, including two synthetic noise datasets (CIFAR10 and\nCIFAR100) and real-world noise datasets (mini-WebVision and Food-101N). The\nresults validate the efficacy of NTD for online continual learning in scenarios\nwith noisy labels in data streams. Compared to the previous leading approach,\nNTD achieves a training speedup enhancement over two times while maintaining or\nsurpassing accuracy levels. Moreover, NTD utilizes less than one-fifth of the\nGPU memory resources compared to previous leading methods.",
      "tldr_zh": "该论文针对持续学习（continual learning）中数据流存在的模糊任务边界（fuzzy task boundaries）和噪声标签（noisy labels）问题，提出了一种新型采样方法Noisy Test Debiasing (NTD)，旨在缓解噪声标签的影响并构建公平、鲁棒的学习算法。NTD方法简单易实现，可应用于各种场景，通过优化采样过程提升模型性能。在实验中，NTD在CIFAR10、CIFAR100、mini-WebVision和Food-101N等四个数据集上验证其有效性，与领先方法相比，训练速度提高两倍以上，同时保持或超越准确率，且仅使用不到五分之一的GPU内存资源。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.04871v1",
      "published_date": "2024-04-07 08:32:16 UTC",
      "updated_date": "2024-04-07 08:32:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:27:52.722129"
    },
    {
      "arxiv_id": "2404.04869v2",
      "title": "Prompting Multi-Modal Tokens to Enhance End-to-End Autonomous Driving Imitation Learning with LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Yiqun Duan",
        "Qiang Zhang",
        "Renjing Xu"
      ],
      "abstract": "The utilization of Large Language Models (LLMs) within the realm of\nreinforcement learning, particularly as planners, has garnered a significant\ndegree of attention in recent scholarly literature. However, a substantial\nproportion of existing research predominantly focuses on planning models for\nrobotics that transmute the outputs derived from perception models into\nlinguistic forms, thus adopting a `pure-language' strategy. In this research,\nwe propose a hybrid End-to-End learning framework for autonomous driving by\ncombining basic driving imitation learning with LLMs based on multi-modality\nprompt tokens. Instead of simply converting perception results from the\nseparated train model into pure language input, our novelty lies in two\naspects. 1) The end-to-end integration of visual and LiDAR sensory input into\nlearnable multi-modality tokens, thereby intrinsically alleviating description\nbias by separated pre-trained perception models. 2) Instead of directly letting\nLLMs drive, this paper explores a hybrid setting of letting LLMs help the\ndriving model correct mistakes and complicated scenarios. The results of our\nexperiments suggest that the proposed methodology can attain driving scores of\n49.21%, coupled with an impressive route completion rate of 91.34% in the\noffline evaluation conducted via CARLA. These performance metrics are\ncomparable to the most advanced driving models.",
      "tldr_zh": "本文提出一种混合 End-to-End 学习框架，将 LLMs 与多模态提示标记结合，用于增强自主驾驶模仿学习。该框架创新性地将视觉和 LiDAR 输入整合为可学习的 multi-modal tokens，避免了分离预训练感知模型的描述偏差，并让 LLMs 辅助驾驶模型修正错误和处理复杂场景。实验结果显示，在 CARLA 平台的离线评估中，该方法实现了 49.21% 的驾驶分数和 91.34% 的路线完成率，与最先进模型性能相当。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.04869v2",
      "published_date": "2024-04-07 08:31:12 UTC",
      "updated_date": "2024-07-29 11:43:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:28:05.953864"
    },
    {
      "arxiv_id": "2404.04856v3",
      "title": "Msmsfnet: a multi-stream and multi-scale fusion net for edge detection",
      "title_zh": "翻译失败",
      "authors": [
        "Chenguang Liu",
        "Chisheng Wang",
        "Feifei Dong",
        "Xiayang Xiao",
        "Xin Su",
        "Chuanhua Zhu",
        "Dejin Zhang",
        "Qingquan Li"
      ],
      "abstract": "Edge detection is a long-standing problem in computer vision. Despite the\nefficiency of existing algorithms, their performance, however, rely heavily on\nthe pre-trained weights of the backbone network on the ImageNet dataset. The\nuse of pre-trained weights in previous methods significantly increases the\ndifficulty to design new models for edge detection without relying on existing\nwell-trained ImageNet models, as pre-training the model on the ImageNet dataset\nis expensive and becomes compulsory to ensure the fairness of comparison.\nBesides, the pre-training and fine-tuning strategy is not always useful and\nsometimes even inaccessible. For instance, the pre-trained weights on the\nImageNet dataset are unlikely to be helpful for edge detection in Synthetic\nAperture Radar (SAR) images due to strong differences in the statistics between\noptical images and SAR images. Moreover, no dataset has comparable size to the\nImageNet dataset for SAR image processing. In this work, we study the\nperformance achievable by state-of-the-art deep learning based edge detectors\nin publicly available datasets when they are trained from scratch, and devise a\nnew network architecture, the multi-stream and multi-scale fusion net\n(msmsfnet), for edge detection. We show in our experiments that by training all\nmodels from scratch, our model outperforms state-of-the-art edge detectors in\nthree publicly available datasets. We also demonstrate the efficiency of our\nmodel for edge detection in SAR images, where no useful pre-trained weight is\navailable. Finally, We show that our model is able to achieve competitive\nperformance on the BSDS500 dataset when the pre-trained weights are used.",
      "tldr_zh": "本文研究了边缘检测在计算机视觉中的挑战，指出现有深度学习方法过度依赖 ImageNet 数据集的预训练权重，导致新模型设计困难，尤其在 Synthetic Aperture Radar (SAR) 图像等场景中不适用。为此，作者提出了一种新网络架构 multi-stream and multi-scale fusion net (msmsfnet)，该模型通过多流和多尺度融合机制，从零开始训练。实验结果显示，msmsfnet 在三个公开数据集上超越了最先进边缘检测器，并在 SAR 图像边缘检测中表现出色；此外，当使用预训练权重时，它在 BSDS500 数据集上也能实现竞争性性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.04856v3",
      "published_date": "2024-04-07 08:03:42 UTC",
      "updated_date": "2025-05-12 08:55:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:28:17.766257"
    },
    {
      "arxiv_id": "2404.04854v1",
      "title": "Contextual Chart Generation for Cyber Deception",
      "title_zh": "翻译失败",
      "authors": [
        "David D. Nguyen",
        "David Liebowitz",
        "Surya Nepal",
        "Salil S. Kanhere",
        "Sharif Abuadbba"
      ],
      "abstract": "Honeyfiles are security assets designed to attract and detect intruders on\ncompromised systems. Honeyfiles are a type of honeypot that mimic real,\nsensitive documents, creating the illusion of the presence of valuable data.\nInteraction with a honeyfile reveals the presence of an intruder, and can\nprovide insights into their goals and intentions. Their practical use, however,\nis limited by the time, cost and effort associated with manually creating\nrealistic content. The introduction of large language models has made\nhigh-quality text generation accessible, but honeyfiles contain a variety of\ncontent including charts, tables and images. This content needs to be plausible\nand realistic, as well as semantically consistent both within honeyfiles and\nwith the real documents they mimic, to successfully deceive an intruder.\n  In this paper, we focus on an important component of the honeyfile content\ngeneration problem: document charts. Charts are ubiquitous in corporate\ndocuments and are commonly used to communicate quantitative and scientific\ndata. Existing image generation models, such as DALL-E, are rather prone to\ngenerating charts with incomprehensible text and unconvincing data. We take a\nmulti-modal approach to this problem by combining two purpose-built generative\nmodels: a multitask Transformer and a specialized multi-head autoencoder. The\nTransformer generates realistic captions and plot text, while the autoencoder\ngenerates the underlying tabular data for the plot.\n  To advance the field of automated honeyplot generation, we also release a new\ndocument-chart dataset and propose a novel metric Keyword Semantic Matching\n(KSM). This metric measures the semantic consistency between keywords of a\ncorpus and a smaller bag of words. Extensive experiments demonstrate excellent\nperformance against multiple large language models, including ChatGPT and GPT4.",
      "tldr_zh": "本论文针对网络欺骗中的蜜饵文件（honeyfiles）生成问题，专注于自动创建真实可信的图表（charts），以克服手动制作的耗时难题。研究提出一种多模态方法，结合多任务Transformer生成真实标题和图表文本，以及专用多头自编码器（multi-head autoencoder）生成底层表格数据，确保图表内容在语义上与真实文档一致。论文贡献包括发布一个新的文档图表数据集（document-chart dataset）和提出新型指标Keyword Semantic Matching (KSM)，用于评估语义一致性。实验结果显示，该方法在多个大型语言模型（如ChatGPT和GPT4）上表现出色，显著提升了蜜饵文件的欺骗效果。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "13 pages including references",
      "pdf_url": "http://arxiv.org/pdf/2404.04854v1",
      "published_date": "2024-04-07 07:56:14 UTC",
      "updated_date": "2024-04-07 07:56:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:28:28.200872"
    },
    {
      "arxiv_id": "2404.04849v2",
      "title": "Hidden You Malicious Goal Into Benign Narratives: Jailbreak Large Language Models through Logic Chain Injection",
      "title_zh": "翻译失败",
      "authors": [
        "Zhilong Wang",
        "Yebo Cao",
        "Peng Liu"
      ],
      "abstract": "Jailbreak attacks on Language Model Models (LLMs) entail crafting prompts\naimed at exploiting the models to generate malicious content. Existing\njailbreak attacks can successfully deceive the LLMs, however they cannot\ndeceive the human. This paper proposes a new type of jailbreak attacks which\ncan deceive both the LLMs and human (i.e., security analyst). The key insight\nof our idea is borrowed from the social psychology - that is human are easily\ndeceived if the lie is hidden in truth. Based on this insight, we proposed the\nlogic-chain injection attacks to inject malicious intention into benign truth.\nLogic-chain injection attack firstly dissembles its malicious target into a\nchain of benign narrations, and then distribute narrations into a related\nbenign article, with undoubted facts. In this way, newly generate prompt cannot\nonly deceive the LLMs, but also deceive human.",
      "tldr_zh": "该论文提出了一种新型越狱攻击（jailbreak attacks），旨在将恶意目标隐藏在良性叙述中，从而同时欺骗大型语言模型（LLMs）和人类安全分析师。攻击方法借鉴社会心理学原理，将恶意意图分解为逻辑链注入攻击（logic-chain injection attacks），即先将恶意目标伪装成一系列良性叙述，然后将其融入相关的事实性文章中。实验表明，这种攻击不仅能成功诱导 LLMs 生成恶意内容，还能使人类难以察觉，从而提升攻击的隐蔽性和有效性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.04849v2",
      "published_date": "2024-04-07 07:42:12 UTC",
      "updated_date": "2024-04-16 22:34:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:28:39.411697"
    },
    {
      "arxiv_id": "2404.04848v2",
      "title": "Task-Aware Encoder Control for Deep Video Compression",
      "title_zh": "翻译失败",
      "authors": [
        "Xingtong Ge",
        "Jixiang Luo",
        "Xinjie Zhang",
        "Tongda Xu",
        "Guo Lu",
        "Dailan He",
        "Jing Geng",
        "Yan Wang",
        "Jun Zhang",
        "Hongwei Qin"
      ],
      "abstract": "Prior research on deep video compression (DVC) for machine tasks typically\nnecessitates training a unique codec for each specific task, mandating a\ndedicated decoder per task. In contrast, traditional video codecs employ a\nflexible encoder controller, enabling the adaptation of a single codec to\ndifferent tasks through mechanisms like mode prediction. Drawing inspiration\nfrom this, we introduce an innovative encoder controller for deep video\ncompression for machines. This controller features a mode prediction and a\nGroup of Pictures (GoP) selection module. Our approach centralizes control at\nthe encoding stage, allowing for adaptable encoder adjustments across different\ntasks, such as detection and tracking, while maintaining compatibility with a\nstandard pre-trained DVC decoder. Empirical evidence demonstrates that our\nmethod is applicable across multiple tasks with various existing pre-trained\nDVCs. Moreover, extensive experiments demonstrate that our method outperforms\nprevious DVC by about 25% bitrate for different tasks, with only one\npre-trained decoder.",
      "tldr_zh": "这篇论文提出了一种任务感知编码器控制器，用于深度视频压缩（DVC），旨在解决现有方法需为每个机器任务（如检测和跟踪）训练专用编解码器的局限性。该控制器包括模式预测和 Group of Pictures (GoP) 选择模块，通过在编码阶段进行集中调整，使单一预训练 DVC 解码器能适应多种任务。实验结果表明，该方法在不同任务上比现有 DVC 技术节省约 25% 的比特率，同时保持了广泛的兼容性。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "Accepted by CVPR 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.04848v2",
      "published_date": "2024-04-07 07:42:04 UTC",
      "updated_date": "2024-04-20 07:54:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:28:52.676296"
    },
    {
      "arxiv_id": "2404.04845v2",
      "title": "SLPL SHROOM at SemEval2024 Task 06: A comprehensive study on models ability to detect hallucination",
      "title_zh": "翻译失败",
      "authors": [
        "Pouya Fallah",
        "Soroush Gooran",
        "Mohammad Jafarinasab",
        "Pouya Sadeghi",
        "Reza Farnia",
        "Amirreza Tarabkhah",
        "Zainab Sadat Taghavi",
        "Hossein Sameti"
      ],
      "abstract": "Language models, particularly generative models, are susceptible to\nhallucinations, generating outputs that contradict factual knowledge or the\nsource text. This study explores methods for detecting hallucinations in three\nSemEval-2024 Task 6 tasks: Machine Translation, Definition Modeling, and\nParaphrase Generation. We evaluate two methods: semantic similarity between the\ngenerated text and factual references, and an ensemble of language models that\njudge each other's outputs. Our results show that semantic similarity achieves\nmoderate accuracy and correlation scores in trial data, while the ensemble\nmethod offers insights into the complexities of hallucination detection but\nfalls short of expectations. This work highlights the challenges of\nhallucination detection and underscores the need for further research in this\ncritical area.",
      "tldr_zh": "该研究探讨了语言模型（特别是生成模型）中的hallucinations问题，即生成与事实知识或源文本矛盾的输出。在SemEval-2024 Task 6的三个子任务（机器翻译、定义建模和释义生成）中，研究者评估了两种检测方法：生成的文本与事实参考的semantic similarity，以及ensemble of language models来判断彼此输出。结果显示，semantic similarity在试验数据中取得了中等准确性和相关性分数，而ensemble方法揭示了检测复杂性但未达到预期效果。该工作强调了hallucination检测的挑战，并呼吁进一步的研究以改进这一关键领域。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.04845v2",
      "published_date": "2024-04-07 07:34:49 UTC",
      "updated_date": "2024-04-09 07:21:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:29:03.583878"
    },
    {
      "arxiv_id": "2404.04839v2",
      "title": "AI for DevSecOps: A Landscape and Future Opportunities",
      "title_zh": "翻译失败",
      "authors": [
        "Michael Fu",
        "Jirat Pasuksmit",
        "Chakkrit Tantithamthavorn"
      ],
      "abstract": "DevOps has emerged as one of the most rapidly evolving software development\nparadigms. With the growing concerns surrounding security in software systems,\nthe DevSecOps paradigm has gained prominence, urging practitioners to\nincorporate security practices seamlessly into the DevOps workflow. However,\nintegrating security into the DevOps workflow can impact agility and impede\ndelivery speed. Recently, the advancement of artificial intelligence (AI) has\nrevolutionized automation in various software domains, including software\nsecurity. AI-driven security approaches, particularly those leveraging machine\nlearning or deep learning, hold promise in automating security workflows. They\nreduce manual efforts, which can be integrated into DevOps to ensure\nuninterrupted delivery speed and align with the DevSecOps paradigm\nsimultaneously. This paper seeks to contribute to the critical intersection of\nAI and DevSecOps by presenting a comprehensive landscape of AI-driven security\ntechniques applicable to DevOps and identifying avenues for enhancing security,\ntrust, and efficiency in software development processes. We analyzed 99\nresearch papers spanning from 2017 to 2023. Specifically, we address two key\nresearch questions (RQs). In RQ1, we identified 12 security tasks associated\nwith the DevSecOps process and reviewed existing AI-driven security approaches,\nthe problems they addressed, and the 65 benchmarks used to evaluate those\napproaches. Drawing insights from our findings, in RQ2, we discussed\nstate-of-the-art AI-driven security approaches, highlighted 15 challenges in\nexisting research, and proposed 15 corresponding avenues for future\nopportunities.",
      "tldr_zh": "这篇论文探讨了人工智能(AI)在DevSecOps中的应用，旨在解决将安全实践融入DevOps流程可能带来的敏捷性挑战。作者通过分析2017年至2023年的99篇研究论文，回答了两个关键研究问题(RQs)：RQ1识别了12个与DevSecOps相关的安全任务，并审阅了现有AI驱动的安全方法、解决的问题以及65个评估基准；RQ2讨论了最先进的技术，突出了15个研究挑战，并提出了15个未来机会。总体而言，该研究为提升软件开发的安全性、信任度和效率提供了全面景观和创新方向。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.04839v2",
      "published_date": "2024-04-07 07:24:58 UTC",
      "updated_date": "2024-09-13 00:08:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:29:17.325122"
    },
    {
      "arxiv_id": "2404.07235v2",
      "title": "LLM-aided explanations of EDA synthesis errors",
      "title_zh": "LLM",
      "authors": [
        "Siyu Qiu",
        "Benjamin Tan",
        "Hammond Pearce"
      ],
      "abstract": "Training new engineers in digital design is a challenge, particularly when it\ncomes to teaching the complex electronic design automation (EDA) tooling used\nin this domain. Learners will typically deploy designs in the Verilog and VHDL\nhardware description languages to Field Programmable Gate Arrays (FPGAs) from\nAltera (Intel) and Xilinx (AMD) via proprietary closed-source toolchains\n(Quartus Prime and Vivado, respectively). These tools are complex and difficult\nto use -- yet, as they are the tools used in industry, they are an essential\nfirst step in this space. In this work, we examine how recent advances in\nartificial intelligence may be leveraged to address aspects of this challenge.\nSpecifically, we investigate if Large Language Models (LLMs), which have\ndemonstrated text comprehension and question-answering capabilities, can be\nused to generate novice-friendly explanations of compile-time synthesis error\nmessages from Quartus Prime and Vivado. To perform this study we generate 936\nerror message explanations using three OpenAI LLMs over 21 different buggy code\nsamples. These are then graded for relevance and correctness, and we find that\nin approximately 71% of cases the LLMs give correct & complete explanations\nsuitable for novice learners.",
      "tldr_zh": "这篇论文探讨了利用 Large Language Models (LLMs) 来生成对初学者友好的解释，帮助新工程师理解电子设计自动化 (EDA) 工具（如 Quartus Prime 和 Vivado）的合成错误消息。研究方法包括使用三个 OpenAI LLMs 对 21 个有错误的代码样本生成 936 个解释，并评估其相关性和正确性。结果显示，约 71% 的解释正确且完整，这为提升 EDA 工具培训效率提供了潜在解决方案。",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.PL",
        "cs.SE"
      ],
      "primary_category": "cs.AR",
      "comment": "6 pages, 6 figures. Accepted in IEEE LLM Aided Design Workshop\n  (LAD'2024)",
      "pdf_url": "http://arxiv.org/pdf/2404.07235v2",
      "published_date": "2024-04-07 07:12:16 UTC",
      "updated_date": "2024-10-17 20:49:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:29:28.210009"
    },
    {
      "arxiv_id": "2404.10782v1",
      "title": "Quantifying AI Vulnerabilities: A Synthesis of Complexity, Dynamical Systems, and Game Theory",
      "title_zh": "翻译失败",
      "authors": [
        "B Kereopa-Yorke"
      ],
      "abstract": "The rapid integration of Artificial Intelligence (AI) systems across critical\ndomains necessitates robust security evaluation frameworks. We propose a novel\napproach that introduces three metrics: System Complexity Index (SCI), Lyapunov\nExponent for AI Stability (LEAIS), and Nash Equilibrium Robustness (NER). SCI\nquantifies the inherent complexity of an AI system, LEAIS captures its\nstability and sensitivity to perturbations, and NER evaluates its strategic\nrobustness against adversarial manipulation. Through comparative analysis, we\ndemonstrate the advantages of our framework over existing techniques. We\ndiscuss the theoretical and practical implications, potential applications,\nlimitations, and future research directions. Our work contributes to the\ndevelopment of secure and trustworthy AI technologies by providing a holistic,\ntheoretically grounded approach to AI security evaluation. As AI continues to\nadvance, prioritising and advancing AI security through interdisciplinary\ncollaboration is crucial to ensure its responsible deployment for the benefit\nof society.",
      "tldr_zh": "该论文提出了一种新型AI安全评估框架，结合复杂性、动力系统和博弈论，引入三个指标：System Complexity Index (SCI) 用于量化AI系统的内在复杂性、Lyapunov Exponent for AI Stability (LEAIS) 用于评估其稳定性和对扰动的敏感性，以及Nash Equilibrium Robustness (NER) 用于衡量AI对对手操纵的战略鲁棒性。通过比较分析，该框架显示出比现有技术更高的优势。论文讨论了其理论和实践含义、潜在应用、限制以及未来研究方向，为开发安全、可信AI技术提供了整体性方法，并强调跨学科合作的重要性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "18 pages",
      "pdf_url": "http://arxiv.org/pdf/2404.10782v1",
      "published_date": "2024-04-07 07:05:59 UTC",
      "updated_date": "2024-04-07 07:05:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:29:43.014525"
    },
    {
      "arxiv_id": "2404.04825v1",
      "title": "Gradient-based Design of Computational Granular Crystals",
      "title_zh": "翻译失败",
      "authors": [
        "Atoosa Parsa",
        "Corey S. O'Hern",
        "Rebecca Kramer-Bottiglio",
        "Josh Bongard"
      ],
      "abstract": "There is growing interest in engineering unconventional computing devices\nthat leverage the intrinsic dynamics of physical substrates to perform fast and\nenergy-efficient computations. Granular metamaterials are one such substrate\nthat has emerged as a promising platform for building wave-based information\nprocessing devices with the potential to integrate sensing, actuation, and\ncomputation. Their high-dimensional and nonlinear dynamics result in nontrivial\nand sometimes counter-intuitive wave responses that can be shaped by the\nmaterial properties, geometry, and configuration of individual grains. Such\nhighly tunable rich dynamics can be utilized for mechanical computing in\nspecial-purpose applications. However, there are currently no general\nframeworks for the inverse design of large-scale granular materials. Here, we\nbuild upon the similarity between the spatiotemporal dynamics of wave\npropagation in material and the computational dynamics of Recurrent Neural\nNetworks to develop a gradient-based optimization framework for harmonically\ndriven granular crystals. We showcase how our framework can be utilized to\ndesign basic logic gates where mechanical vibrations carry the information at\npredetermined frequencies. We compare our design methodology with classic\ngradient-free methods and find that our approach discovers higher-performing\nconfigurations with less computational effort. Our findings show that a\ngradient-based optimization method can greatly expand the design space of\nmetamaterials and provide the opportunity to systematically traverse the\nparameter space to find materials with the desired functionalities.",
      "tldr_zh": "本研究针对颗粒 metamaterials 的逆向设计问题，提出了一种基于梯度的优化框架，利用波传播动态与 Recurrent Neural Networks 的相似性，来设计谐波驱动的计算颗粒晶体。该框架通过优化材料属性、几何和配置，实现对复杂波响应的精确控制，并成功应用于设计基本逻辑门，其中信息通过预定频率的机械振动传输。与传统的梯度-free 方法相比，该方法显著提高了性能配置的发现效率，并减少了计算开销。该发现扩展了 metamaterials 的设计空间，促进了系统化的功能材料开发。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.ET",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.04825v1",
      "published_date": "2024-04-07 06:24:47 UTC",
      "updated_date": "2024-04-07 06:24:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:29:55.537845"
    },
    {
      "arxiv_id": "2404.04824v1",
      "title": "Mixup Domain Adaptations for Dynamic Remaining Useful Life Predictions",
      "title_zh": "Mixup 领域适应用于动态剩余可用寿命预测",
      "authors": [
        "Muhammad Tanzil Furqon",
        "Mahardhika Pratama",
        "Lin Liu",
        "Habibullah",
        "Kutluyil Dogancay"
      ],
      "abstract": "Remaining Useful Life (RUL) predictions play vital role for asset planning\nand maintenance leading to many benefits to industries such as reduced\ndowntime, low maintenance costs, etc. Although various efforts have been\ndevoted to study this topic, most existing works are restricted for i.i.d\nconditions assuming the same condition of the training phase and the deployment\nphase. This paper proposes a solution to this problem where a mix-up domain\nadaptation (MDAN) is put forward. MDAN encompasses a three-staged mechanism\nwhere the mix-up strategy is not only performed to regularize the source and\ntarget domains but also applied to establish an intermediate mix-up domain\nwhere the source and target domains are aligned. The self-supervised learning\nstrategy is implemented to prevent the supervision collapse problem. Rigorous\nevaluations have been performed where MDAN is compared to recently published\nworks for dynamic RUL predictions. MDAN outperforms its counterparts with\nsubstantial margins in 12 out of 12 cases. In addition, MDAN is evaluated with\nthe bearing machine dataset where it beats prior art with significant gaps in 8\nof 12 cases. Source codes of MDAN are made publicly available in\n\\url{https://github.com/furqon3009/MDAN}.",
      "tldr_zh": "该论文针对 Remaining Useful Life (RUL) 预测中的域适应问题，提出了一种 Mix-up Domain Adaptation (MDAN) 方法，以解决现有 i.i.d 假设下训练和部署条件不一致的局限性。MDAN 通过三阶段机制应用 mix-up 策略来正则化源域和目标域、创建中间混淆域进行对齐，并结合 self-supervised learning 防止监督崩溃问题。实验结果显示，MDAN 在动态 RUL 预测的 12 个案例中全面优于现有方法，并在轴承数据集的 8 个案例中显著领先，源代码已公开以供进一步验证。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "accepted for publication in Knowledge-based Systems",
      "pdf_url": "http://arxiv.org/pdf/2404.04824v1",
      "published_date": "2024-04-07 06:23:18 UTC",
      "updated_date": "2024-04-07 06:23:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:30:08.398941"
    },
    {
      "arxiv_id": "2404.04821v5",
      "title": "A Data-to-Product Multimodal Conceptual Framework to Achieve Automated Software Evolution for Context-rich Intelligent Applications",
      "title_zh": "数据到产品的多模态概念框架：实现上下文丰富的智能应用的自动软件演化",
      "authors": [
        "Songhui Yue"
      ],
      "abstract": "While AI is extensively transforming Software Engineering (SE) fields, SE is\nstill in need of a framework to overall consider all phases to facilitate\nAutomated Software Evolution (ASEv), particularly for intelligent applications\nthat are context-rich, instead of conquering each division independently. Its\ncomplexity comes from the intricacy of the intelligent applications, the\nheterogeneity of the data sources, and the constant changes in the context.\nThis study proposes a conceptual framework for achieving automated software\nevolution, emphasizing the importance of multimodality learning. A Selective\nSequential Scope Model (3S) model is developed based on the conceptual\nframework, and it can be used to categorize existing and future research when\nit covers different SE phases and multimodal learning tasks. This research is a\npreliminary step toward the blueprint of a higher-level ASEv. The proposed\nconceptual framework can act as a practical guideline for practitioners to\nprepare themselves for diving into this area. Although the study is about\nintelligent applications, the framework and analysis methods may be adapted for\nother types of software as AI brings more intelligence into their life cycles.",
      "tldr_zh": "该研究提出一个 Data-to-Product Multimodal Conceptual Framework，以实现 Automated Software Evolution (ASEv)，针对上下文丰富的智能应用，解决其复杂性（如数据来源异构和上下文变化）。框架强调多模态学习的重要性，并开发了 Selective Sequential Scope Model (3S) 模型，用于分类现有和未来研究，涵盖不同软件工程（SE）阶段和多模态任务。总体而言，这一框架作为 ASEv 的高层蓝图，可指导从业者实践，并可能适应其他软件类型以提升其生命周期中的智能化。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.04821v5",
      "published_date": "2024-04-07 06:05:25 UTC",
      "updated_date": "2024-10-09 04:49:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:30:19.949924"
    },
    {
      "arxiv_id": "2404.04818v1",
      "title": "DWE+: Dual-Way Matching Enhanced Framework for Multimodal Entity Linking",
      "title_zh": "翻译失败",
      "authors": [
        "Shezheng Song",
        "Shasha Li",
        "Shan Zhao",
        "Xiaopeng Li",
        "Chengyu Wang",
        "Jie Yu",
        "Jun Ma",
        "Tianwei Yan",
        "Bin Ji",
        "Xiaoguang Mao"
      ],
      "abstract": "Multimodal entity linking (MEL) aims to utilize multimodal information\n(usually textual and visual information) to link ambiguous mentions to\nunambiguous entities in knowledge base. Current methods facing main issues:\n(1)treating the entire image as input may contain redundant information. (2)the\ninsufficient utilization of entity-related information, such as attributes in\nimages. (3)semantic inconsistency between the entity in knowledge base and its\nrepresentation. To this end, we propose DWE+ for multimodal entity linking.\nDWE+ could capture finer semantics and dynamically maintain semantic\nconsistency with entities. This is achieved by three aspects: (a)we introduce a\nmethod for extracting fine-grained image features by partitioning the image\ninto multiple local objects. Then, hierarchical contrastive learning is used to\nfurther align semantics between coarse-grained information(text and image) and\nfine-grained (mention and visual objects). (b)we explore ways to extract visual\nattributes from images to enhance fusion feature such as facial features and\nidentity. (c)we leverage Wikipedia and ChatGPT to capture the entity\nrepresentation, achieving semantic enrichment from both static and dynamic\nperspectives, which better reflects the real-world entity semantics.\nExperiments on Wikimel, Richpedia, and Wikidiverse datasets demonstrate the\neffectiveness of DWE+ in improving MEL performance. Specifically, we optimize\nthese datasets and achieve state-of-the-art performance on the enhanced\ndatasets. The code and enhanced datasets are released on\nhttps://github.com/season1blue/DWET",
      "tldr_zh": "论文提出了 DWE+ 框架，用于多模态实体链接 (Multimodal Entity Linking)，旨在解决现有方法中图像冗余信息、实体相关信息利用不足以及实体语义不一致的问题。DWE+ 通过将图像分区提取细粒度特征、应用层次对比学习 (hierarchical contrastive learning) 对齐粗细粒度语义、从图像中提取视觉属性（如面部特征和身份），并结合 Wikipedia 和 ChatGPT 实现静态动态实体表示丰富，从而提升链接性能。在 Wikimel、Richpedia 和 Wikidiverse 数据集上的实验显示，DWE+ 达到了最先进性能，并开源了代码和优化数据集。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "under review on TOIS. arXiv admin note: substantial text overlap with\n  arXiv:2312.11816",
      "pdf_url": "http://arxiv.org/pdf/2404.04818v1",
      "published_date": "2024-04-07 05:56:42 UTC",
      "updated_date": "2024-04-07 05:56:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:30:33.939598"
    },
    {
      "arxiv_id": "2404.04814v4",
      "title": "Inference-Time Rule Eraser: Fair Recognition via Distilling and Removing Biased Rules",
      "title_zh": "推理时规则擦除器：通过提炼和移除偏置规则实现公平识别",
      "authors": [
        "Yi Zhang",
        "Dongyuan Lu",
        "Jitao Sang"
      ],
      "abstract": "Machine learning models often make predictions based on biased features such\nas gender, race, and other social attributes, posing significant fairness\nrisks, especially in societal applications, such as hiring, banking, and\ncriminal justice. Traditional approaches to addressing this issue involve\nretraining or fine-tuning neural networks with fairness-aware optimization\nobjectives. However, these methods can be impractical due to significant\ncomputational resources, complex industrial tests, and the associated CO2\nfootprint. Additionally, regular users often fail to fine-tune models because\nthey lack access to model parameters In this paper, we introduce the\nInference-Time Rule Eraser (Eraser), a novel method designed to address\nfairness concerns by removing biased decision-making rules from deployed models\nduring inference without altering model weights. We begin by establishing a\ntheoretical foundation for modifying model outputs to eliminate biased rules\nthrough Bayesian analysis. Next, we present a specific implementation of Eraser\nthat involves two stages: (1) distilling the biased rules from the deployed\nmodel into an additional patch model, and (2) removing these biased rules from\nthe output of the deployed model during inference. Extensive experiments\nvalidate the effectiveness of our approach, showcasing its superior performance\nin addressing fairness concerns in AI systems.",
      "tldr_zh": "本研究针对机器学习模型在预测中使用偏见特征（如性别、种族）导致的公平性风险，提出了一种创新方法Inference-Time Rule Eraser (Eraser)。该方法通过Bayesian analysis的理论基础，在推理阶段移除偏见规则，而无需修改模型权重，包括两个步骤：(1) 将偏见规则从部署模型中蒸馏(distilling)到附加的patch模型，(2) 在推理时从输出中移除这些规则。与传统重新训练方法相比，Eraser节省计算资源并易于部署。实验结果显示，该方法在解决AI系统公平性问题上表现出优越性能，显著提升了模型的公平性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.04814v4",
      "published_date": "2024-04-07 05:47:41 UTC",
      "updated_date": "2024-08-27 04:43:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:30:43.971276"
    },
    {
      "arxiv_id": "2404.08677v1",
      "title": "PMG : Personalized Multimodal Generation with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaoteng Shen",
        "Rui Zhang",
        "Xiaoyan Zhao",
        "Jieming Zhu",
        "Xi Xiao"
      ],
      "abstract": "The emergence of large language models (LLMs) has revolutionized the\ncapabilities of text comprehension and generation. Multi-modal generation\nattracts great attention from both the industry and academia, but there is\nlittle work on personalized generation, which has important applications such\nas recommender systems. This paper proposes the first method for personalized\nmultimodal generation using LLMs, showcases its applications and validates its\nperformance via an extensive experimental study on two datasets. The proposed\nmethod, Personalized Multimodal Generation (PMG for short) first converts user\nbehaviors (e.g., clicks in recommender systems or conversations with a virtual\nassistant) into natural language to facilitate LLM understanding and extract\nuser preference descriptions. Such user preferences are then fed into a\ngenerator, such as a multimodal LLM or diffusion model, to produce personalized\ncontent. To capture user preferences comprehensively and accurately, we propose\nto let the LLM output a combination of explicit keywords and implicit\nembeddings to represent user preferences. Then the combination of keywords and\nembeddings are used as prompts to condition the generator. We optimize a\nweighted sum of the accuracy and preference scores so that the generated\ncontent has a good balance between them. Compared to a baseline method without\npersonalization, PMG has a significant improvement on personalization for up to\n8% in terms of LPIPS while retaining the accuracy of generation.",
      "tldr_zh": "这篇论文提出了一种名为 PMG 的方法，利用大型语言模型 (LLMs) 实现个性化的多模态生成，针对推荐系统等应用场景填补了现有研究的空白。PMG 先将用户行为（如点击或对话）转换为自然语言以提取偏好，然后通过 LLMs 输出显式关键词和隐式嵌入作为提示，引导生成器（如多模态 LLMs 或扩散模型）产生个性化内容，同时优化准确性和偏好分数的加权和。实验结果显示，与无个人化基线相比，PMG 在 LPIPS 指标上提高了高达 8%，同时保持了生成内容的准确性。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.08677v1",
      "published_date": "2024-04-07 03:05:57 UTC",
      "updated_date": "2024-04-07 03:05:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:30:57.409787"
    },
    {
      "arxiv_id": "2404.04763v1",
      "title": "GenEARL: A Training-Free Generative Framework for Multimodal Event Argument Role Labeling",
      "title_zh": "GenEARL：一种无需训练的生成式框架，用于多模态事件参数角色标注",
      "authors": [
        "Hritik Bansal",
        "Po-Nien Kung",
        "P. Jeffrey Brantingham",
        "Kai-Wei Chang",
        "Nanyun Peng"
      ],
      "abstract": "Multimodal event argument role labeling (EARL), a task that assigns a role\nfor each event participant (object) in an image is a complex challenge. It\nrequires reasoning over the entire image, the depicted event, and the\ninteractions between various objects participating in the event. Existing\nmodels heavily rely on high-quality event-annotated training data to understand\nthe event semantics and structures, and they fail to generalize to new event\ntypes and domains. In this paper, we propose GenEARL, a training-free\ngenerative framework that harness the power of the modern generative models to\nunderstand event task descriptions given image contexts to perform the EARL\ntask. Specifically, GenEARL comprises two stages of generative prompting with a\nfrozen vision-language model (VLM) and a frozen large language model (LLM).\nFirst, a generative VLM learns the semantics of the event argument roles and\ngenerates event-centric object descriptions based on the image. Subsequently, a\nLLM is prompted with the generated object descriptions with a predefined\ntemplate for EARL (i.e., assign an object with an event argument role). We show\nthat GenEARL outperforms the contrastive pretraining (CLIP) baseline by 9.4%\nand 14.2% accuracy for zero-shot EARL on the M2E2 and SwiG datasets,\nrespectively. In addition, we outperform CLIP-Event by 22% precision on M2E2\ndataset. The framework also allows flexible adaptation and generalization to\nunseen domains.",
      "tldr_zh": "本文提出 GenEARL，一个无需训练的生成框架，用于 Multimodal Event Argument Role Labeling (EARL)，旨在通过图像上下文理解事件语义和对象互动，而不依赖高质量训练数据。框架包括两个阶段：先使用冻结的视觉语言模型 (VLM) 生成事件中心对象描述，然后通过冻结的大型语言模型 (LLM) 结合预定义模板分配事件参数角色。实验结果显示，GenEARL 在 M2E2 和 SwiG 数据集的零样本 EARL 任务中，分别比 CLIP 基线提高 9.4% 和 14.2% 的准确率，并比 CLIP-Event 提高 22% 的精确率。该框架还支持灵活适应和泛化到未见领域。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "20 pages, 15 Figures, 13 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.04763v1",
      "published_date": "2024-04-07 00:28:13 UTC",
      "updated_date": "2024-04-07 00:28:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T22:31:09.570705"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 47,
  "processed_papers_count": 47,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-17T22:31:31.501495"
}