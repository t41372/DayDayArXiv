[
  {
    "arxiv_id": "2404.05101v3",
    "title": "StockGPT: A GenAI Model for Stock Prediction and Trading",
    "authors": [
      "Dat Mai"
    ],
    "abstract": "This paper introduces StockGPT, an autoregressive ``number'' model trained\nand tested on 70 million daily U.S.\\ stock returns over nearly 100 years.\nTreating each return series as a sequence of tokens, StockGPT automatically\nlearns the hidden patterns predictive of future returns via its attention\nmechanism. On a held-out test sample from 2001 to 2023, daily and monthly\nrebalanced long-short portfolios formed from StockGPT predictions yield strong\nperformance. The StockGPT-based portfolios span momentum and long-/short-term\nreversals, eliminating the need for manually crafted price-based strategies,\nand yield highly significant alphas against leading stock market factors,\nsuggesting a novel AI pricing effect. This highlights the immense promise of\ngenerative AI in surpassing human in making complex financial investment\ndecisions.",
    "categories": [
      "q-fin.CP",
      "cs.AI",
      "q-fin.PM",
      "q-fin.PR",
      "q-fin.ST"
    ],
    "primary_category": "q-fin.CP",
    "comment": "26 pages, 3 figures, 8 tables",
    "pdf_url": "http://arxiv.org/pdf/2404.05101v3",
    "published_date": "2024-04-07 22:53:43 UTC",
    "updated_date": "2024-10-23 15:28:45 UTC"
  },
  {
    "arxiv_id": "2404.05094v1",
    "title": "Active Test-Time Adaptation: Theoretical Analyses and An Algorithm",
    "authors": [
      "Shurui Gui",
      "Xiner Li",
      "Shuiwang Ji"
    ],
    "abstract": "Test-time adaptation (TTA) addresses distribution shifts for streaming test\ndata in unsupervised settings. Currently, most TTA methods can only deal with\nminor shifts and rely heavily on heuristic and empirical studies.\n  To advance TTA under domain shifts, we propose the novel problem setting of\nactive test-time adaptation (ATTA) that integrates active learning within the\nfully TTA setting.\n  We provide a learning theory analysis, demonstrating that incorporating\nlimited labeled test instances enhances overall performances across test\ndomains with a theoretical guarantee. We also present a sample entropy\nbalancing for implementing ATTA while avoiding catastrophic forgetting (CF). We\nintroduce a simple yet effective ATTA algorithm, known as SimATTA, using\nreal-time sample selection techniques. Extensive experimental results confirm\nconsistency with our theoretical analyses and show that the proposed ATTA\nmethod yields substantial performance improvements over TTA methods while\nmaintaining efficiency and shares similar effectiveness to the more demanding\nactive domain adaptation (ADA) methods. Our code is available at\nhttps://github.com/divelab/ATTA",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.05094v1",
    "published_date": "2024-04-07 22:31:34 UTC",
    "updated_date": "2024-04-07 22:31:34 UTC"
  },
  {
    "arxiv_id": "2404.05090v1",
    "title": "How Bad is Training on Synthetic Data? A Statistical Analysis of Language Model Collapse",
    "authors": [
      "Mohamed El Amine Seddik",
      "Suei-Wen Chen",
      "Soufiane Hayou",
      "Pierre Youssef",
      "Merouane Debbah"
    ],
    "abstract": "The phenomenon of model collapse, introduced in (Shumailov et al., 2023),\nrefers to the deterioration in performance that occurs when new models are\ntrained on synthetic data generated from previously trained models. This\nrecursive training loop makes the tails of the original distribution disappear,\nthereby making future-generation models forget about the initial (real)\ndistribution. With the aim of rigorously understanding model collapse in\nlanguage models, we consider in this paper a statistical model that allows us\nto characterize the impact of various recursive training scenarios.\nSpecifically, we demonstrate that model collapse cannot be avoided when\ntraining solely on synthetic data. However, when mixing both real and synthetic\ndata, we provide an estimate of a maximal amount of synthetic data below which\nmodel collapse can eventually be avoided. Our theoretical conclusions are\nfurther supported by empirical validations.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.05090v1",
    "published_date": "2024-04-07 22:15:13 UTC",
    "updated_date": "2024-04-07 22:15:13 UTC"
  },
  {
    "arxiv_id": "2404.05086v1",
    "title": "A Note on LoRA",
    "authors": [
      "Vlad Fomenko",
      "Han Yu",
      "Jongho Lee",
      "Stanley Hsieh",
      "Weizhu Chen"
    ],
    "abstract": "LoRA (Low-Rank Adaptation) has emerged as a preferred method for efficiently\nadapting Large Language Models (LLMs) with remarkable simplicity and efficacy.\nThis note extends the original LoRA paper by offering new perspectives that\nwere not initially discussed and presents a series of insights for deploying\nLoRA at scale. Without introducing new experiments, we aim to improve the\nunderstanding and application of LoRA.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.05086v1",
    "published_date": "2024-04-07 22:00:50 UTC",
    "updated_date": "2024-04-07 22:00:50 UTC"
  },
  {
    "arxiv_id": "2404.05074v1",
    "title": "On the Uniqueness of Solution for the Bellman Equation of LTL Objectives",
    "authors": [
      "Zetong Xuan",
      "Alper Kamil Bozkurt",
      "Miroslav Pajic",
      "Yu Wang"
    ],
    "abstract": "Surrogate rewards for linear temporal logic (LTL) objectives are commonly\nutilized in planning problems for LTL objectives. In a widely-adopted surrogate\nreward approach, two discount factors are used to ensure that the expected\nreturn approximates the satisfaction probability of the LTL objective. The\nexpected return then can be estimated by methods using the Bellman updates such\nas reinforcement learning. However, the uniqueness of the solution to the\nBellman equation with two discount factors has not been explicitly discussed.\nWe demonstrate with an example that when one of the discount factors is set to\none, as allowed in many previous works, the Bellman equation may have multiple\nsolutions, leading to inaccurate evaluation of the expected return. We then\npropose a condition for the Bellman equation to have the expected return as the\nunique solution, requiring the solutions for states inside a rejecting bottom\nstrongly connected component (BSCC) to be 0. We prove this condition is\nsufficient by showing that the solutions for the states with discounting can be\nseparated from those for the states without discounting under this condition",
    "categories": [
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted for the 2024 Learning for Dynamics and Control Conference\n  (L4DC)",
    "pdf_url": "http://arxiv.org/pdf/2404.05074v1",
    "published_date": "2024-04-07 21:06:52 UTC",
    "updated_date": "2024-04-07 21:06:52 UTC"
  },
  {
    "arxiv_id": "2404.05061v1",
    "title": "Automated Prediction of Breast Cancer Response to Neoadjuvant Chemotherapy from DWI Data",
    "authors": [
      "Shir Nitzan",
      "Maya Gilad",
      "Moti Freiman"
    ],
    "abstract": "Effective surgical planning for breast cancer hinges on accurately predicting\npathological complete response (pCR) to neoadjuvant chemotherapy (NAC).\nDiffusion-weighted MRI (DWI) and machine learning offer a non-invasive approach\nfor early pCR assessment. However, most machine-learning models require manual\ntumor segmentation, a cumbersome and error-prone task. We propose a deep\nlearning model employing \"Size-Adaptive Lesion Weighting\" for automatic DWI\ntumor segmentation to enhance pCR prediction accuracy. Despite\nhistopathological changes during NAC complicating DWI image segmentation, our\nmodel demonstrates robust performance. Utilizing the BMMR2 challenge dataset,\nit matches human experts in pCR prediction pre-NAC with an area under the curve\n(AUC) of 0.76 vs. 0.796, and surpasses standard automated methods mid-NAC, with\nan AUC of 0.729 vs. 0.654 and 0.576. Our approach represents a significant\nadvancement in automating breast cancer treatment planning, enabling more\nreliable pCR predictions without manual segmentation.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted for presentation at the IEEE International Symposium on\n  Biomedical Imaging (ISBI)",
    "pdf_url": "http://arxiv.org/pdf/2404.05061v1",
    "published_date": "2024-04-07 20:15:40 UTC",
    "updated_date": "2024-04-07 20:15:40 UTC"
  },
  {
    "arxiv_id": "2404.05055v1",
    "title": "Percentile Criterion Optimization in Offline Reinforcement Learning",
    "authors": [
      "Elita A. Lobo",
      "Cyrus Cousins",
      "Yair Zick",
      "Marek Petrik"
    ],
    "abstract": "In reinforcement learning, robust policies for high-stakes decision-making\nproblems with limited data are usually computed by optimizing the\n\\emph{percentile criterion}. The percentile criterion is approximately solved\nby constructing an \\emph{ambiguity set} that contains the true model with high\nprobability and optimizing the policy for the worst model in the set. Since the\npercentile criterion is non-convex, constructing ambiguity sets is often\nchallenging. Existing work uses \\emph{Bayesian credible regions} as ambiguity\nsets, but they are often unnecessarily large and result in learning overly\nconservative policies. To overcome these shortcomings, we propose a novel\nValue-at-Risk based dynamic programming algorithm to optimize the percentile\ncriterion without explicitly constructing any ambiguity sets. Our theoretical\nand empirical results show that our algorithm implicitly constructs much\nsmaller ambiguity sets and learns less conservative robust policies.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at Neurips 2023",
    "pdf_url": "http://arxiv.org/pdf/2404.05055v1",
    "published_date": "2024-04-07 19:29:09 UTC",
    "updated_date": "2024-04-07 19:29:09 UTC"
  },
  {
    "arxiv_id": "2404.05769v1",
    "title": "Dynamic Quality-Diversity Search",
    "authors": [
      "Roberto Gallotta",
      "Antonios Liapis",
      "Georgios N. Yannakakis"
    ],
    "abstract": "Evolutionary search via the quality-diversity (QD) paradigm can discover\nhighly performing solutions in different behavioural niches, showing\nconsiderable potential in complex real-world scenarios such as evolutionary\nrobotics. Yet most QD methods only tackle static tasks that are fixed over\ntime, which is rarely the case in the real world. Unlike noisy environments,\nwhere the fitness of an individual changes slightly at every evaluation,\ndynamic environments simulate tasks where external factors at unknown and\nirregular intervals alter the performance of the individual with a severity\nthat is unknown a priori. Literature on optimisation in dynamic environments is\nextensive, yet such environments have not been explored in the context of QD\nsearch. This paper introduces a novel and generalisable Dynamic QD methodology\nthat aims to keep the archive of past solutions updated in the case of\nenvironment changes. Secondly, we present a novel characterisation of dynamic\nenvironments that can be easily applied to well-known benchmarks, with minor\ninterventions to move them from a static task to a dynamic one. Our Dynamic QD\nintervention is applied on MAP-Elites and CMA-ME, two powerful QD algorithms,\nand we test the dynamic variants on different dynamic tasks.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "Parts of this manuscripts are published at The Genetic and\n  Evolutionary Computation Conference (GECCO) 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.05769v1",
    "published_date": "2024-04-07 19:00:15 UTC",
    "updated_date": "2024-04-07 19:00:15 UTC"
  },
  {
    "arxiv_id": "2404.05012v1",
    "title": "Towards Reliable and Empathetic Depression-Diagnosis-Oriented Chats",
    "authors": [
      "Kunyao Lan",
      "Cong Ming",
      "Binwei Yao",
      "Lu Chen",
      "Mengyue Wu"
    ],
    "abstract": "Chatbots can serve as a viable tool for preliminary depression diagnosis via\ninteractive conversations with potential patients. Nevertheless, the blend of\ntask-oriented and chit-chat in diagnosis-related dialogues necessitates\nprofessional expertise and empathy. Such unique requirements challenge\ntraditional dialogue frameworks geared towards single optimization goals. To\naddress this, we propose an innovative ontology definition and generation\nframework tailored explicitly for depression diagnosis dialogues, combining the\nreliability of task-oriented conversations with the appeal of empathy-related\nchit-chat. We further apply the framework to D$^4$, the only existing public\ndialogue dataset on depression diagnosis-oriented chats. Exhaustive\nexperimental results indicate significant improvements in task completion and\nemotional support generation in depression diagnosis, fostering a more\ncomprehensive approach to task-oriented chat dialogue system development and\nits applications in digital mental health.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.05012v1",
    "published_date": "2024-04-07 16:35:53 UTC",
    "updated_date": "2024-04-07 16:35:53 UTC"
  },
  {
    "arxiv_id": "2404.05003v1",
    "title": "Camera-Based Remote Physiology Sensing for Hundreds of Subjects Across Skin Tones",
    "authors": [
      "Jiankai Tang",
      "Xinyi Li",
      "Jiacheng Liu",
      "Xiyuxing Zhang",
      "Zeyu Wang",
      "Yuntao Wang"
    ],
    "abstract": "Remote photoplethysmography (rPPG) emerges as a promising method for\nnon-invasive, convenient measurement of vital signs, utilizing the widespread\npresence of cameras. Despite advancements, existing datasets fall short in\nterms of size and diversity, limiting comprehensive evaluation under diverse\nconditions. This paper presents an in-depth analysis of the VitalVideo dataset,\nthe largest real-world rPPG dataset to date, encompassing 893 subjects and 6\nFitzpatrick skin tones. Our experimentation with six unsupervised methods and\nthree supervised models demonstrates that datasets comprising a few hundred\nsubjects(i.e., 300 for UBFC-rPPG, 500 for PURE, and 700 for MMPD-Simple) are\nsufficient for effective rPPG model training. Our findings highlight the\nimportance of diversity and consistency in skin tones for precise performance\nevaluation across different datasets.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "11 pages, 5 figures, CHI24 Workshop PhysioCHI",
    "pdf_url": "http://arxiv.org/pdf/2404.05003v1",
    "published_date": "2024-04-07 15:58:25 UTC",
    "updated_date": "2024-04-07 15:58:25 UTC"
  },
  {
    "arxiv_id": "2404.04998v1",
    "title": "Weakly Supervised Deep Hyperspherical Quantization for Image Retrieval",
    "authors": [
      "Jinpeng Wang",
      "Bin Chen",
      "Qiang Zhang",
      "Zaiqiao Meng",
      "Shangsong Liang",
      "Shu-Tao Xia"
    ],
    "abstract": "Deep quantization methods have shown high efficiency on large-scale image\nretrieval. However, current models heavily rely on ground-truth information,\nhindering the application of quantization in label-hungry scenarios. A more\nrealistic demand is to learn from inexhaustible uploaded images that are\nassociated with informal tags provided by amateur users. Though such sketchy\ntags do not obviously reveal the labels, they actually contain useful semantic\ninformation for supervising deep quantization. To this end, we propose\nWeakly-Supervised Deep Hyperspherical Quantization (WSDHQ), which is the first\nwork to learn deep quantization from weakly tagged images. Specifically, 1) we\nuse word embeddings to represent the tags and enhance their semantic\ninformation based on a tag correlation graph. 2) To better preserve semantic\ninformation in quantization codes and reduce quantization error, we jointly\nlearn semantics-preserving embeddings and supervised quantizer on hypersphere\nby employing a well-designed fusion layer and tailor-made loss functions.\nExtensive experiments show that WSDHQ can achieve state-of-art performance on\nweakly-supervised compact coding. Code is available at\nhttps://github.com/gimpong/AAAI21-WSDHQ.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CV",
    "comment": "In proceedings of AAAI 2021. Code and data are available",
    "pdf_url": "http://arxiv.org/pdf/2404.04998v1",
    "published_date": "2024-04-07 15:48:33 UTC",
    "updated_date": "2024-04-07 15:48:33 UTC"
  },
  {
    "arxiv_id": "2404.04997v2",
    "title": "Adapting LLMs for Efficient Context Processing through Soft Prompt Compression",
    "authors": [
      "Cangqing Wang",
      "Yutian Yang",
      "Ruisi Li",
      "Dan Sun",
      "Ruicong Cai",
      "Yuzhu Zhang",
      "Chengqian Fu",
      "Lillian Floyd"
    ],
    "abstract": "The rapid advancement of Large Language Models (LLMs) has inaugurated a\ntransformative epoch in natural language processing, fostering unprecedented\nproficiency in text generation, comprehension, and contextual scrutiny.\nNevertheless, effectively handling extensive contexts, crucial for myriad\napplications, poses a formidable obstacle owing to the intrinsic constraints of\nthe models' context window sizes and the computational burdens entailed by\ntheir operations. This investigation presents an innovative framework that\nstrategically tailors LLMs for streamlined context processing by harnessing the\nsynergies among natural language summarization, soft prompt compression, and\naugmented utility preservation mechanisms. Our methodology, dubbed\nSoftPromptComp, amalgamates natural language prompts extracted from\nsummarization methodologies with dynamically generated soft prompts to forge a\nconcise yet semantically robust depiction of protracted contexts. This\ndepiction undergoes further refinement via a weighting mechanism optimizing\ninformation retention and utility for subsequent tasks. We substantiate that\nour framework markedly diminishes computational overhead and enhances LLMs'\nefficacy across various benchmarks, while upholding or even augmenting the\ncaliber of the produced content. By amalgamating soft prompt compression with\nsophisticated summarization, SoftPromptComp confronts the dual challenges of\nmanaging lengthy contexts and ensuring model scalability. Our findings point\ntowards a propitious trajectory for augmenting LLMs' applicability and\nefficiency, rendering them more versatile and pragmatic for real-world\napplications. This research enriches the ongoing discourse on optimizing\nlanguage models, providing insights into the potency of soft prompts and\nsummarization techniques as pivotal instruments for the forthcoming generation\nof NLP solutions.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "This paper has been accepted by the 2024 International Conference on\n  Image Processing and Computer Applications (IPCA 2024)",
    "pdf_url": "http://arxiv.org/pdf/2404.04997v2",
    "published_date": "2024-04-07 15:44:20 UTC",
    "updated_date": "2024-04-18 23:23:53 UTC"
  },
  {
    "arxiv_id": "2404.04986v1",
    "title": "Dynamic Distinction Learning: Adaptive Pseudo Anomalies for Video Anomaly Detection",
    "authors": [
      "Demetris Lappas",
      "Vasileios Argyriou",
      "Dimitrios Makris"
    ],
    "abstract": "We introduce Dynamic Distinction Learning (DDL) for Video Anomaly Detection,\na novel video anomaly detection methodology that combines pseudo-anomalies,\ndynamic anomaly weighting, and a distinction loss function to improve detection\naccuracy. By training on pseudo-anomalies, our approach adapts to the\nvariability of normal and anomalous behaviors without fixed anomaly thresholds.\nOur model showcases superior performance on the Ped2, Avenue and ShanghaiTech\ndatasets, where individual models are tailored for each scene. These\nachievements highlight DDL's effectiveness in advancing anomaly detection,\noffering a scalable and adaptable solution for video surveillance challenges.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "To be published in the CVPR2024 Workshop",
    "pdf_url": "http://arxiv.org/pdf/2404.04986v1",
    "published_date": "2024-04-07 15:06:48 UTC",
    "updated_date": "2024-04-07 15:06:48 UTC"
  },
  {
    "arxiv_id": "2404.04983v1",
    "title": "Primary liver cancer classification from routine tumour biopsy using weakly supervised deep learning",
    "authors": [
      "Aurélie Beaufrère",
      "Nora Ouzir",
      "Paul Emile Zafar",
      "Astrid Laurent-Bellue",
      "Miguel Albuquerque",
      "Gwladys Lubuela",
      "Jules Grégory",
      "Catherine Guettier",
      "Kévin Mondet",
      "Jean-Christophe Pesquet",
      "Valérie Paradis"
    ],
    "abstract": "The diagnosis of primary liver cancers (PLCs) can be challenging, especially\non biopsies and for combined hepatocellular-cholangiocarcinoma (cHCC-CCA). We\nautomatically classified PLCs on routine-stained biopsies using a weakly\nsupervised learning method. Weak tumour/non-tumour annotations served as labels\nfor training a Resnet18 neural network, and the network's last convolutional\nlayer was used to extract new tumour tile features. Without knowledge of the\nprecise labels of the malignancies, we then applied an unsupervised clustering\nalgorithm. Our model identified specific features of hepatocellular carcinoma\n(HCC) and intrahepatic cholangiocarcinoma (iCCA). Despite no specific features\nof cHCC-CCA being recognized, the identification of HCC and iCCA tiles within a\nslide could facilitate the diagnosis of primary liver cancers, particularly\ncHCC-CCA.\n  Method and results: 166 PLC biopsies were divided into training, internal and\nexternal validation sets: 90, 29 and 47 samples. Two liver pathologists\nreviewed each whole-slide hematein eosin saffron (HES)-stained image (WSI).\nAfter annotating the tumour/non-tumour areas, 256x256 pixel tiles were\nextracted from the WSIs and used to train a ResNet18. The network was used to\nextract new tile features. An unsupervised clustering algorithm was then\napplied to the new tile features. In a two-cluster model, Clusters 0 and 1\ncontained mainly HCC and iCCA histological features. The diagnostic agreement\nbetween the pathological diagnosis and the model predictions in the internal\nand external validation sets was 100% (11/11) and 96% (25/26) for HCC and 78%\n(7/9) and 87% (13/15) for iCCA, respectively. For cHCC-CCA, we observed a\nhighly variable proportion of tiles from each cluster (Cluster 0: 5-97%;\nCluster 1: 2-94%).",
    "categories": [
      "q-bio.TO",
      "cs.AI",
      "cs.CV",
      "I.5; I.4; I.2"
    ],
    "primary_category": "q-bio.TO",
    "comment": "https://www.sciencedirect.com/science/article/pii/S2589555924000090",
    "pdf_url": "http://arxiv.org/pdf/2404.04983v1",
    "published_date": "2024-04-07 15:03:46 UTC",
    "updated_date": "2024-04-07 15:03:46 UTC"
  },
  {
    "arxiv_id": "2404.04974v1",
    "title": "Neural Network Modeling for Forecasting Tourism Demand in Stopića Cave: A Serbian Cave Tourism Study",
    "authors": [
      "Buda Bajić",
      "Srđan Milićević",
      "Aleksandar Antić",
      "Slobodan Marković",
      "Nemanja Tomić"
    ],
    "abstract": "For modeling the number of visits in Stopi\\'{c}a cave (Serbia) we consider\nthe classical Auto-regressive Integrated Moving Average (ARIMA) model, Machine\nLearning (ML) method Support Vector Regression (SVR), and hybrid NeuralPropeth\nmethod which combines classical and ML concepts. The most accurate predictions\nwere obtained with NeuralPropeth which includes the seasonal component and\ngrowing trend of time-series. In addition, non-linearity is modeled by shallow\nNeural Network (NN), and Google Trend is incorporated as an exogenous variable.\nModeling tourist demand represents great importance for management structures\nand decision-makers due to its applicability in establishing sustainable\ntourism utilization strategies in environmentally vulnerable destinations such\nas caves. The data provided insights into the tourist demand in Stopi\\'{c}a\ncave and preliminary data for addressing the issues of carrying capacity within\nthe most visited cave in Serbia.",
    "categories": [
      "econ.EM",
      "cs.AI"
    ],
    "primary_category": "econ.EM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.04974v1",
    "published_date": "2024-04-07 14:33:06 UTC",
    "updated_date": "2024-04-07 14:33:06 UTC"
  },
  {
    "arxiv_id": "2404.04969v1",
    "title": "Temporal Generalization Estimation in Evolving Graphs",
    "authors": [
      "Bin Lu",
      "Tingyan Ma",
      "Xiaoying Gan",
      "Xinbing Wang",
      "Yunqiang Zhu",
      "Chenghu Zhou",
      "Shiyu Liang"
    ],
    "abstract": "Graph Neural Networks (GNNs) are widely deployed in vast fields, but they\noften struggle to maintain accurate representations as graphs evolve. We\ntheoretically establish a lower bound, proving that under mild conditions,\nrepresentation distortion inevitably occurs over time. To estimate the temporal\ndistortion without human annotation after deployment, one naive approach is to\npre-train a recurrent model (e.g., RNN) before deployment and use this model\nafterwards, but the estimation is far from satisfactory. In this paper, we\nanalyze the representation distortion from an information theory perspective,\nand attribute it primarily to inaccurate feature extraction during evolution.\nConsequently, we introduce Smart, a straightforward and effective baseline\nenhanced by an adaptive feature extractor through self-supervised graph\nreconstruction. In synthetic random graphs, we further refine the former lower\nbound to show the inevitable distortion over time and empirically observe that\nSmart achieves good estimation performance. Moreover, we observe that Smart\nconsistently shows outstanding generalization estimation on four real-world\nevolving graphs. The ablation studies underscore the necessity of graph\nreconstruction. For example, on OGB-arXiv dataset, the estimation metric MAPE\ndeteriorates from 2.19% to 8.00% without reconstruction.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Published as a conference paper at ICLR 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.04969v1",
    "published_date": "2024-04-07 14:19:22 UTC",
    "updated_date": "2024-04-07 14:19:22 UTC"
  },
  {
    "arxiv_id": "2404.04963v1",
    "title": "SemEval-2024 Task 2: Safe Biomedical Natural Language Inference for Clinical Trials",
    "authors": [
      "Mael Jullien",
      "Marco Valentino",
      "André Freitas"
    ],
    "abstract": "Large Language Models (LLMs) are at the forefront of NLP achievements but\nfall short in dealing with shortcut learning, factual inconsistency, and\nvulnerability to adversarial inputs.These shortcomings are especially critical\nin medical contexts, where they can misrepresent actual model capabilities.\nAddressing this, we present SemEval-2024 Task 2: Safe Biomedical Natural\nLanguage Inference for ClinicalTrials. Our contributions include the refined\nNLI4CT-P dataset (i.e., Natural Language Inference for Clinical Trials -\nPerturbed), designed to challenge LLMs with interventional and causal reasoning\ntasks, along with a comprehensive evaluation of methods and results for\nparticipant submissions. A total of 106 participants registered for the task\ncontributing to over 1200 individual submissions and 25 system overview papers.\nThis initiative aims to advance the robustness and applicability of NLI models\nin healthcare, ensuring safer and more dependable AI assistance in clinical\ndecision-making. We anticipate that the dataset, models, and outcomes of this\ntask can support future research in the field of biomedical NLI. The dataset,\ncompetition leaderboard, and website are publicly available.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.04963v1",
    "published_date": "2024-04-07 13:58:41 UTC",
    "updated_date": "2024-04-07 13:58:41 UTC"
  },
  {
    "arxiv_id": "2404.04947v2",
    "title": "Gull: A Generative Multifunctional Audio Codec",
    "authors": [
      "Yi Luo",
      "Jianwei Yu",
      "Hangting Chen",
      "Rongzhi Gu",
      "Chao Weng"
    ],
    "abstract": "We introduce Gull, a generative multifunctional audio codec. Gull is a\ngeneral purpose neural audio compression and decompression model which can be\napplied to a wide range of tasks and applications such as real-time\ncommunication, audio super-resolution, and codec language models. The key\ncomponents of Gull include (1) universal-sample-rate modeling via subband\nmodeling schemes motivated by recent progress in audio source separation, (2)\ngain-shape representations motivated by traditional audio codecs, (3) improved\nresidual vector quantization modules, (4) elastic decoder network that enables\nuser-defined model size and complexity during inference time, (5) built-in\nability for audio super-resolution without the increase of bitrate. We compare\nGull with existing traditional and neural audio codecs and show that Gull is\nable to achieve on par or better performance across various sample rates,\nbitrates and model complexities in both subjective and objective evaluation\nmetrics.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.LG",
      "cs.SD",
      "eess.SP"
    ],
    "primary_category": "eess.AS",
    "comment": "Demo page: https://yluo42.github.io/Gull/",
    "pdf_url": "http://arxiv.org/pdf/2404.04947v2",
    "published_date": "2024-04-07 12:57:46 UTC",
    "updated_date": "2024-06-07 07:03:30 UTC"
  },
  {
    "arxiv_id": "2404.04943v1",
    "title": "Chiplet Placement Order Exploration Based on Learning to Rank with Graph Representation",
    "authors": [
      "Zhihui Deng",
      "Yuanyuan Duan",
      "Leilai Shao",
      "Xiaolei Zhu"
    ],
    "abstract": "Chiplet-based systems, integrating various silicon dies manufactured at\ndifferent integrated circuit technology nodes on a carrier interposer, have\ngarnered significant attention in recent years due to their cost-effectiveness\nand competitive performance. The widespread adoption of reinforcement learning\nas a sequential placement method has introduced a new challenge in determining\nthe optimal placement order for each chiplet. The order in which chiplets are\nplaced on the interposer influences the spatial resources available for earlier\nand later placed chiplets, making the placement results highly sensitive to the\nsequence of chiplet placement. To address these challenges, we propose a\nlearning to rank approach with graph representation, building upon the\nreinforcement learning framework RLPlanner. This method aims to select the\noptimal chiplet placement order for each chiplet-based system. Experimental\nresults demonstrate that compared to placement order obtained solely based on\nthe descending order of the chiplet area and the number of interconnect wires\nbetween the chiplets, utilizing the placement order obtained from the learning\nto rank network leads to further improvements in system temperature and\ninter-chiplet wirelength. Specifically, applying the top-ranked placement order\nobtained from the learning to rank network results in a 10.05% reduction in\ntotal inter-chiplet wirelength and a 1.01% improvement in peak system\ntemperature during the chiplet placement process.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.AR"
    ],
    "primary_category": "cs.LG",
    "comment": "6 pages, 8 figures and 6 tables, accepted by the Conference ISEDA",
    "pdf_url": "http://arxiv.org/pdf/2404.04943v1",
    "published_date": "2024-04-07 12:40:37 UTC",
    "updated_date": "2024-04-07 12:40:37 UTC"
  },
  {
    "arxiv_id": "2404.04932v1",
    "title": "Towards Understanding the Influence of Reward Margin on Preference Model Performance",
    "authors": [
      "Bowen Qin",
      "Duanyu Feng",
      "Xi Yang"
    ],
    "abstract": "Reinforcement Learning from Human Feedback (RLHF) is a widely used framework\nfor the training of language models. However, the process of using RLHF to\ndevelop a language model that is well-aligned presents challenges, especially\nwhen it comes to optimizing the reward model. Our research has found that\nexisting reward models, when trained using the traditional ranking objective\nbased on human preference data, often struggle to effectively distinguish\nbetween responses that are more or less favorable in real-world scenarios. To\nbridge this gap, our study introduces a novel method to estimate the preference\ndifferences without the need for detailed, exhaustive labels from human\nannotators. Our experimental results provide empirical evidence that\nincorporating margin values into the training process significantly improves\nthe effectiveness of reward models. This comparative analysis not only\ndemonstrates the superiority of our approach in terms of reward prediction\naccuracy but also highlights its effectiveness in practical applications.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.04932v1",
    "published_date": "2024-04-07 12:10:04 UTC",
    "updated_date": "2024-04-07 12:10:04 UTC"
  },
  {
    "arxiv_id": "2404.04924v1",
    "title": "GvT: A Graph-based Vision Transformer with Talking-Heads Utilizing Sparsity, Trained from Scratch on Small Datasets",
    "authors": [
      "Dongjing Shan",
      "guiqiang chen"
    ],
    "abstract": "Vision Transformers (ViTs) have achieved impressive results in large-scale\nimage classification. However, when training from scratch on small datasets,\nthere is still a significant performance gap between ViTs and Convolutional\nNeural Networks (CNNs), which is attributed to the lack of inductive bias. To\naddress this issue, we propose a Graph-based Vision Transformer (GvT) that\nutilizes graph convolutional projection and graph-pooling. In each block,\nqueries and keys are calculated through graph convolutional projection based on\nthe spatial adjacency matrix, while dot-product attention is used in another\ngraph convolution to generate values. When using more attention heads, the\nqueries and keys become lower-dimensional, making their dot product an\nuninformative matching function. To overcome this low-rank bottleneck in\nattention heads, we employ talking-heads technology based on bilinear pooled\nfeatures and sparse selection of attention tensors. This allows interaction\namong filtered attention scores and enables each attention mechanism to depend\non all queries and keys. Additionally, we apply graph-pooling between two\nintermediate blocks to reduce the number of tokens and aggregate semantic\ninformation more effectively. Our experimental results show that GvT produces\ncomparable or superior outcomes to deep convolutional networks and surpasses\nvision transformers without pre-training on large datasets. The code for our\nproposed model is publicly available on the website.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.04924v1",
    "published_date": "2024-04-07 11:48:07 UTC",
    "updated_date": "2024-04-07 11:48:07 UTC"
  },
  {
    "arxiv_id": "2404.04922v1",
    "title": "Efficient Learnable Collaborative Attention for Single Image Super-Resolution",
    "authors": [
      "Yigang Zhao Chaowei Zheng",
      "Jiannan Su",
      "GuangyongChen",
      "MinGan"
    ],
    "abstract": "Non-Local Attention (NLA) is a powerful technique for capturing long-range\nfeature correlations in deep single image super-resolution (SR). However, NLA\nsuffers from high computational complexity and memory consumption, as it\nrequires aggregating all non-local feature information for each query response\nand recalculating the similarity weight distribution for different abstraction\nlevels of features. To address these challenges, we propose a novel Learnable\nCollaborative Attention (LCoA) that introduces inductive bias into non-local\nmodeling. Our LCoA consists of two components: Learnable Sparse Pattern (LSP)\nand Collaborative Attention (CoA). LSP uses the k-means clustering algorithm to\ndynamically adjust the sparse attention pattern of deep features, which reduces\nthe number of non-local modeling rounds compared with existing sparse\nsolutions. CoA leverages the sparse attention pattern and weights learned by\nLSP, and co-optimizes the similarity matrix across different abstraction\nlevels, which avoids redundant similarity matrix calculations. The experimental\nresults show that our LCoA can reduce the non-local modeling time by about 83%\nin the inference stage. In addition, we integrate our LCoA into a deep\nLearnable Collaborative Attention Network (LCoAN), which achieves competitive\nperformance in terms of inference time, memory consumption, and reconstruction\nquality compared with other state-of-the-art SR methods.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.04922v1",
    "published_date": "2024-04-07 11:25:04 UTC",
    "updated_date": "2024-04-07 11:25:04 UTC"
  },
  {
    "arxiv_id": "2404.05767v1",
    "title": "CSA-Trans: Code Structure Aware Transformer for AST",
    "authors": [
      "Saeyoon Oh",
      "Shin Yoo"
    ],
    "abstract": "When applying the Transformer architecture to source code, designing a good\nself-attention mechanism is critical as it affects how node relationship is\nextracted from the Abstract Syntax Trees (ASTs) of the source code. We present\nCode Structure Aware Transformer (CSA-Trans), which uses Code Structure\nEmbedder (CSE) to generate specific PE for each node in AST. CSE generates node\nPositional Encoding (PE) using disentangled attention. To further extend the\nself-attention capability, we adopt Stochastic Block Model (SBM) attention. Our\nevaluation shows that our PE captures the relationships between AST nodes\nbetter than other graph-related PE techniques. We also show through\nquantitative and qualitative analysis that SBM attention is able to generate\nmore node specific attention coefficients. We demonstrate that CSA-Trans\noutperforms 14 baselines in code summarization tasks for both Python and Java,\nwhile being 41.92% faster and 25.31% memory efficient in Java dataset compared\nto AST-Trans and SG-Trans respectively.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.05767v1",
    "published_date": "2024-04-07 10:59:35 UTC",
    "updated_date": "2024-04-07 10:59:35 UTC"
  },
  {
    "arxiv_id": "2404.08679v2",
    "title": "Your Finetuned Large Language Model is Already a Powerful Out-of-distribution Detector",
    "authors": [
      "Andi Zhang",
      "Tim Z. Xiao",
      "Weiyang Liu",
      "Robert Bamler",
      "Damon Wischik"
    ],
    "abstract": "We revisit the likelihood ratio between a pretrained large language model\n(LLM) and its finetuned variant as a criterion for out-of-distribution (OOD)\ndetection. The intuition behind such a criterion is that, the pretrained LLM\nhas the prior knowledge about OOD data due to its large amount of training\ndata, and once finetuned with the in-distribution data, the LLM has sufficient\nknowledge to distinguish their difference. Leveraging the power of LLMs, we\nshow that, the likelihood ratio can serve as an effective OOD detection\ncriterion. Moreover, we apply the proposed LLM-based likelihood ratio to detect\nOOD questions in question-answering (QA) systems, which can be used to improve\nthe performance of specialized LLMs for general questions. Given that\nlikelihood can be easily obtained by the loss functions within contemporary\nneural network frameworks, it is straightforward to implement this approach in\npractice. Since both the pretrained LLMs and its various finetuned models are\nwidely available from online platforms such as Hugging Face, our proposed\ncriterion can be effortlessly incorporated for OOD detection without the need\nfor further training. We conduct comprehensive evaluation across on multiple\nsettings, including far OOD, near OOD, spam detection, and QA scenarios, to\ndemonstrate the effectiveness of the method. Code can be found at\nhttps://github.com/andiac/LLMOODratio",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.08679v2",
    "published_date": "2024-04-07 10:32:49 UTC",
    "updated_date": "2025-03-05 19:51:23 UTC"
  },
  {
    "arxiv_id": "2404.04905v1",
    "title": "Review for Handling Missing Data with special missing mechanism",
    "authors": [
      "Youran Zhou",
      "Sunil Aryal",
      "Mohamed Reda Bouadjenek"
    ],
    "abstract": "Missing data poses a significant challenge in data science, affecting\ndecision-making processes and outcomes. Understanding what missing data is, how\nit occurs, and why it is crucial to handle it appropriately is paramount when\nworking with real-world data, especially in tabular data, one of the most\ncommonly used data types in the real world. Three missing mechanisms are\ndefined in the literature: Missing Completely At Random (MCAR), Missing At\nRandom (MAR), and Missing Not At Random (MNAR), each presenting unique\nchallenges in imputation. Most existing work are focused on MCAR that is\nrelatively easy to handle. The special missing mechanisms of MNAR and MAR are\nless explored and understood. This article reviews existing literature on\nhandling missing values. It compares and contrasts existing methods in terms of\ntheir ability to handle different missing mechanisms and data types. It\nidentifies research gap in the existing literature and lays out potential\ndirections for future research in the field. The information in this review\nwill help data analysts and researchers to adopt and promote good practices for\nhandling missing data in real-world problems.",
    "categories": [
      "stat.ME",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "stat.ME",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.04905v1",
    "published_date": "2024-04-07 10:11:22 UTC",
    "updated_date": "2024-04-07 10:11:22 UTC"
  },
  {
    "arxiv_id": "2404.04904v2",
    "title": "Cross-Domain Audio Deepfake Detection: Dataset and Analysis",
    "authors": [
      "Yuang Li",
      "Min Zhang",
      "Mengxin Ren",
      "Miaomiao Ma",
      "Daimeng Wei",
      "Hao Yang"
    ],
    "abstract": "Audio deepfake detection (ADD) is essential for preventing the misuse of\nsynthetic voices that may infringe on personal rights and privacy. Recent\nzero-shot text-to-speech (TTS) models pose higher risks as they can clone\nvoices with a single utterance. However, the existing ADD datasets are\noutdated, leading to suboptimal generalization of detection models. In this\npaper, we construct a new cross-domain ADD dataset comprising over 300 hours of\nspeech data that is generated by five advanced zero-shot TTS models. To\nsimulate real-world scenarios, we employ diverse attack methods and audio\nprompts from different datasets. Experiments show that, through novel\nattack-augmented training, the Wav2Vec2-large and Whisper-medium models achieve\nequal error rates of 4.1\\% and 6.5\\% respectively. Additionally, we demonstrate\nour models' outstanding few-shot ADD ability by fine-tuning with just one\nminute of target-domain data. Nonetheless, neural codec compressors greatly\naffect the detection accuracy, necessitating further research.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.04904v2",
    "published_date": "2024-04-07 10:10:15 UTC",
    "updated_date": "2024-09-20 08:08:53 UTC"
  },
  {
    "arxiv_id": "2404.04903v1",
    "title": "Online Learning under Haphazard Input Conditions: A Comprehensive Review and Analysis",
    "authors": [
      "Rohit Agarwal",
      "Arijit Das",
      "Alexander Horsch",
      "Krishna Agarwal",
      "Dilip K. Prasad"
    ],
    "abstract": "The domain of online learning has experienced multifaceted expansion owing to\nits prevalence in real-life applications. Nonetheless, this progression\noperates under the assumption that the input feature space of the streaming\ndata remains constant. In this survey paper, we address the topic of online\nlearning in the context of haphazard inputs, explicitly foregoing such an\nassumption. We discuss, classify, evaluate, and compare the methodologies that\nare adept at modeling haphazard inputs, additionally providing the\ncorresponding code implementations and their carbon footprint. Moreover, we\nclassify the datasets related to the field of haphazard inputs and introduce\nevaluation metrics specifically designed for datasets exhibiting imbalance. The\ncode of each methodology can be found at\nhttps://github.com/Rohit102497/HaphazardInputsReview",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.04903v1",
    "published_date": "2024-04-07 10:07:56 UTC",
    "updated_date": "2024-04-07 10:07:56 UTC"
  },
  {
    "arxiv_id": "2404.04902v1",
    "title": "AI2Apps: A Visual IDE for Building LLM-based AI Agent Applications",
    "authors": [
      "Xin Pang",
      "Zhucong Li",
      "Jiaxiang Chen",
      "Yuan Cheng",
      "Yinghui Xu",
      "Yuan Qi"
    ],
    "abstract": "We introduce AI2Apps, a Visual Integrated Development Environment (Visual\nIDE) with full-cycle capabilities that accelerates developers to build\ndeployable LLM-based AI agent Applications. This Visual IDE prioritizes both\nthe Integrity of its development tools and the Visuality of its components,\nensuring a smooth and efficient building experience.On one hand, AI2Apps\nintegrates a comprehensive development toolkit ranging from a prototyping\ncanvas and AI-assisted code editor to agent debugger, management system, and\ndeployment tools all within a web-based graphical user interface. On the other\nhand, AI2Apps visualizes reusable front-end and back-end code as intuitive\ndrag-and-drop components. Furthermore, a plugin system named AI2Apps Extension\n(AAE) is designed for Extensibility, showcasing how a new plugin with 20\ncomponents enables web agent to mimic human-like browsing behavior. Our case\nstudy demonstrates substantial efficiency improvements, with AI2Apps reducing\ntoken consumption and API calls when debugging a specific sophisticated\nmultimodal agent by approximately 90% and 80%, respectively. The AI2Apps,\nincluding an online demo, open-source code, and a screencast video, is now\npublicly accessible.",
    "categories": [
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.04902v1",
    "published_date": "2024-04-07 10:02:09 UTC",
    "updated_date": "2024-04-07 10:02:09 UTC"
  },
  {
    "arxiv_id": "2404.04886v2",
    "title": "PagPassGPT: Pattern Guided Password Guessing via Generative Pretrained Transformer",
    "authors": [
      "Xingyu Su",
      "Xiaojie Zhu",
      "Yang Li",
      "Yong Li",
      "Chi Chen",
      "Paulo Esteves-Veríssimo"
    ],
    "abstract": "Amidst the surge in deep learning-based password guessing models, challenges\nof generating high-quality passwords and reducing duplicate passwords persist.\nTo address these challenges, we present PagPassGPT, a password guessing model\nconstructed on Generative Pretrained Transformer (GPT). It can perform pattern\nguided guessing by incorporating pattern structure information as background\nknowledge, resulting in a significant increase in the hit rate. Furthermore, we\npropose D&C-GEN to reduce the repeat rate of generated passwords, which adopts\nthe concept of a divide-and-conquer approach. The primary task of guessing\npasswords is recursively divided into non-overlapping subtasks. Each subtask\ninherits the knowledge from the parent task and predicts succeeding tokens. In\ncomparison to the state-of-the-art model, our proposed scheme exhibits the\ncapability to correctly guess 12% more passwords while producing 25% fewer\nduplicates.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "Be accepted by DSN 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.04886v2",
    "published_date": "2024-04-07 09:06:14 UTC",
    "updated_date": "2024-06-18 03:05:01 UTC"
  },
  {
    "arxiv_id": "2404.04874v1",
    "title": "Graph Neural Networks for Binary Programming",
    "authors": [
      "Moshe Eliasof",
      "Eldad Haber"
    ],
    "abstract": "This paper investigates a link between Graph Neural Networks (GNNs) and\nBinary Programming (BP) problems, laying the groundwork for GNNs to approximate\nsolutions for these computationally challenging problems. By analyzing the\nsensitivity of BP problems, we are able to frame the solution of BP problems as\na heterophilic node classification task. We then propose Binary-Programming GNN\n(BPGNN), an architecture that integrates graph representation learning\ntechniques with BP-aware features to approximate BP solutions efficiently.\nAdditionally, we introduce a self-supervised data generation mechanism, to\nenable efficient and tractable training data acquisition even for large-scale\nBP problems. Experimental evaluations of BPGNN across diverse BP problem sizes\nshowcase its superior performance compared to exhaustive search and heuristic\napproaches. Finally, we discuss open challenges in the under-explored field of\nBP problems with GNNs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.ET"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.04874v1",
    "published_date": "2024-04-07 08:38:35 UTC",
    "updated_date": "2024-04-07 08:38:35 UTC"
  },
  {
    "arxiv_id": "2404.04871v1",
    "title": "Data Stream Sampling with Fuzzy Task Boundaries and Noisy Labels",
    "authors": [
      "Yu-Hsi Chen"
    ],
    "abstract": "In the realm of continual learning, the presence of noisy labels within data\nstreams represents a notable obstacle to model reliability and fairness. We\nfocus on the data stream scenario outlined in pertinent literature,\ncharacterized by fuzzy task boundaries and noisy labels. To address this\nchallenge, we introduce a novel and intuitive sampling method called Noisy Test\nDebiasing (NTD) to mitigate noisy labels in evolving data streams and establish\na fair and robust continual learning algorithm. NTD is straightforward to\nimplement, making it feasible across various scenarios. Our experiments\nbenchmark four datasets, including two synthetic noise datasets (CIFAR10 and\nCIFAR100) and real-world noise datasets (mini-WebVision and Food-101N). The\nresults validate the efficacy of NTD for online continual learning in scenarios\nwith noisy labels in data streams. Compared to the previous leading approach,\nNTD achieves a training speedup enhancement over two times while maintaining or\nsurpassing accuracy levels. Moreover, NTD utilizes less than one-fifth of the\nGPU memory resources compared to previous leading methods.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.04871v1",
    "published_date": "2024-04-07 08:32:16 UTC",
    "updated_date": "2024-04-07 08:32:16 UTC"
  },
  {
    "arxiv_id": "2404.04869v2",
    "title": "Prompting Multi-Modal Tokens to Enhance End-to-End Autonomous Driving Imitation Learning with LLMs",
    "authors": [
      "Yiqun Duan",
      "Qiang Zhang",
      "Renjing Xu"
    ],
    "abstract": "The utilization of Large Language Models (LLMs) within the realm of\nreinforcement learning, particularly as planners, has garnered a significant\ndegree of attention in recent scholarly literature. However, a substantial\nproportion of existing research predominantly focuses on planning models for\nrobotics that transmute the outputs derived from perception models into\nlinguistic forms, thus adopting a `pure-language' strategy. In this research,\nwe propose a hybrid End-to-End learning framework for autonomous driving by\ncombining basic driving imitation learning with LLMs based on multi-modality\nprompt tokens. Instead of simply converting perception results from the\nseparated train model into pure language input, our novelty lies in two\naspects. 1) The end-to-end integration of visual and LiDAR sensory input into\nlearnable multi-modality tokens, thereby intrinsically alleviating description\nbias by separated pre-trained perception models. 2) Instead of directly letting\nLLMs drive, this paper explores a hybrid setting of letting LLMs help the\ndriving model correct mistakes and complicated scenarios. The results of our\nexperiments suggest that the proposed methodology can attain driving scores of\n49.21%, coupled with an impressive route completion rate of 91.34% in the\noffline evaluation conducted via CARLA. These performance metrics are\ncomparable to the most advanced driving models.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.04869v2",
    "published_date": "2024-04-07 08:31:12 UTC",
    "updated_date": "2024-07-29 11:43:31 UTC"
  },
  {
    "arxiv_id": "2404.04856v3",
    "title": "Msmsfnet: a multi-stream and multi-scale fusion net for edge detection",
    "authors": [
      "Chenguang Liu",
      "Chisheng Wang",
      "Feifei Dong",
      "Xiayang Xiao",
      "Xin Su",
      "Chuanhua Zhu",
      "Dejin Zhang",
      "Qingquan Li"
    ],
    "abstract": "Edge detection is a long-standing problem in computer vision. Despite the\nefficiency of existing algorithms, their performance, however, rely heavily on\nthe pre-trained weights of the backbone network on the ImageNet dataset. The\nuse of pre-trained weights in previous methods significantly increases the\ndifficulty to design new models for edge detection without relying on existing\nwell-trained ImageNet models, as pre-training the model on the ImageNet dataset\nis expensive and becomes compulsory to ensure the fairness of comparison.\nBesides, the pre-training and fine-tuning strategy is not always useful and\nsometimes even inaccessible. For instance, the pre-trained weights on the\nImageNet dataset are unlikely to be helpful for edge detection in Synthetic\nAperture Radar (SAR) images due to strong differences in the statistics between\noptical images and SAR images. Moreover, no dataset has comparable size to the\nImageNet dataset for SAR image processing. In this work, we study the\nperformance achievable by state-of-the-art deep learning based edge detectors\nin publicly available datasets when they are trained from scratch, and devise a\nnew network architecture, the multi-stream and multi-scale fusion net\n(msmsfnet), for edge detection. We show in our experiments that by training all\nmodels from scratch, our model outperforms state-of-the-art edge detectors in\nthree publicly available datasets. We also demonstrate the efficiency of our\nmodel for edge detection in SAR images, where no useful pre-trained weight is\navailable. Finally, We show that our model is able to achieve competitive\nperformance on the BSDS500 dataset when the pre-trained weights are used.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.04856v3",
    "published_date": "2024-04-07 08:03:42 UTC",
    "updated_date": "2025-05-12 08:55:19 UTC"
  },
  {
    "arxiv_id": "2404.04854v1",
    "title": "Contextual Chart Generation for Cyber Deception",
    "authors": [
      "David D. Nguyen",
      "David Liebowitz",
      "Surya Nepal",
      "Salil S. Kanhere",
      "Sharif Abuadbba"
    ],
    "abstract": "Honeyfiles are security assets designed to attract and detect intruders on\ncompromised systems. Honeyfiles are a type of honeypot that mimic real,\nsensitive documents, creating the illusion of the presence of valuable data.\nInteraction with a honeyfile reveals the presence of an intruder, and can\nprovide insights into their goals and intentions. Their practical use, however,\nis limited by the time, cost and effort associated with manually creating\nrealistic content. The introduction of large language models has made\nhigh-quality text generation accessible, but honeyfiles contain a variety of\ncontent including charts, tables and images. This content needs to be plausible\nand realistic, as well as semantically consistent both within honeyfiles and\nwith the real documents they mimic, to successfully deceive an intruder.\n  In this paper, we focus on an important component of the honeyfile content\ngeneration problem: document charts. Charts are ubiquitous in corporate\ndocuments and are commonly used to communicate quantitative and scientific\ndata. Existing image generation models, such as DALL-E, are rather prone to\ngenerating charts with incomprehensible text and unconvincing data. We take a\nmulti-modal approach to this problem by combining two purpose-built generative\nmodels: a multitask Transformer and a specialized multi-head autoencoder. The\nTransformer generates realistic captions and plot text, while the autoencoder\ngenerates the underlying tabular data for the plot.\n  To advance the field of automated honeyplot generation, we also release a new\ndocument-chart dataset and propose a novel metric Keyword Semantic Matching\n(KSM). This metric measures the semantic consistency between keywords of a\ncorpus and a smaller bag of words. Extensive experiments demonstrate excellent\nperformance against multiple large language models, including ChatGPT and GPT4.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "13 pages including references",
    "pdf_url": "http://arxiv.org/pdf/2404.04854v1",
    "published_date": "2024-04-07 07:56:14 UTC",
    "updated_date": "2024-04-07 07:56:14 UTC"
  },
  {
    "arxiv_id": "2404.04849v2",
    "title": "Hidden You Malicious Goal Into Benign Narratives: Jailbreak Large Language Models through Logic Chain Injection",
    "authors": [
      "Zhilong Wang",
      "Yebo Cao",
      "Peng Liu"
    ],
    "abstract": "Jailbreak attacks on Language Model Models (LLMs) entail crafting prompts\naimed at exploiting the models to generate malicious content. Existing\njailbreak attacks can successfully deceive the LLMs, however they cannot\ndeceive the human. This paper proposes a new type of jailbreak attacks which\ncan deceive both the LLMs and human (i.e., security analyst). The key insight\nof our idea is borrowed from the social psychology - that is human are easily\ndeceived if the lie is hidden in truth. Based on this insight, we proposed the\nlogic-chain injection attacks to inject malicious intention into benign truth.\nLogic-chain injection attack firstly dissembles its malicious target into a\nchain of benign narrations, and then distribute narrations into a related\nbenign article, with undoubted facts. In this way, newly generate prompt cannot\nonly deceive the LLMs, but also deceive human.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.04849v2",
    "published_date": "2024-04-07 07:42:12 UTC",
    "updated_date": "2024-04-16 22:34:46 UTC"
  },
  {
    "arxiv_id": "2404.04848v2",
    "title": "Task-Aware Encoder Control for Deep Video Compression",
    "authors": [
      "Xingtong Ge",
      "Jixiang Luo",
      "Xinjie Zhang",
      "Tongda Xu",
      "Guo Lu",
      "Dailan He",
      "Jing Geng",
      "Yan Wang",
      "Jun Zhang",
      "Hongwei Qin"
    ],
    "abstract": "Prior research on deep video compression (DVC) for machine tasks typically\nnecessitates training a unique codec for each specific task, mandating a\ndedicated decoder per task. In contrast, traditional video codecs employ a\nflexible encoder controller, enabling the adaptation of a single codec to\ndifferent tasks through mechanisms like mode prediction. Drawing inspiration\nfrom this, we introduce an innovative encoder controller for deep video\ncompression for machines. This controller features a mode prediction and a\nGroup of Pictures (GoP) selection module. Our approach centralizes control at\nthe encoding stage, allowing for adaptable encoder adjustments across different\ntasks, such as detection and tracking, while maintaining compatibility with a\nstandard pre-trained DVC decoder. Empirical evidence demonstrates that our\nmethod is applicable across multiple tasks with various existing pre-trained\nDVCs. Moreover, extensive experiments demonstrate that our method outperforms\nprevious DVC by about 25% bitrate for different tasks, with only one\npre-trained decoder.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "Accepted by CVPR 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.04848v2",
    "published_date": "2024-04-07 07:42:04 UTC",
    "updated_date": "2024-04-20 07:54:18 UTC"
  },
  {
    "arxiv_id": "2404.04845v2",
    "title": "SLPL SHROOM at SemEval2024 Task 06: A comprehensive study on models ability to detect hallucination",
    "authors": [
      "Pouya Fallah",
      "Soroush Gooran",
      "Mohammad Jafarinasab",
      "Pouya Sadeghi",
      "Reza Farnia",
      "Amirreza Tarabkhah",
      "Zainab Sadat Taghavi",
      "Hossein Sameti"
    ],
    "abstract": "Language models, particularly generative models, are susceptible to\nhallucinations, generating outputs that contradict factual knowledge or the\nsource text. This study explores methods for detecting hallucinations in three\nSemEval-2024 Task 6 tasks: Machine Translation, Definition Modeling, and\nParaphrase Generation. We evaluate two methods: semantic similarity between the\ngenerated text and factual references, and an ensemble of language models that\njudge each other's outputs. Our results show that semantic similarity achieves\nmoderate accuracy and correlation scores in trial data, while the ensemble\nmethod offers insights into the complexities of hallucination detection but\nfalls short of expectations. This work highlights the challenges of\nhallucination detection and underscores the need for further research in this\ncritical area.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.04845v2",
    "published_date": "2024-04-07 07:34:49 UTC",
    "updated_date": "2024-04-09 07:21:37 UTC"
  },
  {
    "arxiv_id": "2404.04839v2",
    "title": "AI for DevSecOps: A Landscape and Future Opportunities",
    "authors": [
      "Michael Fu",
      "Jirat Pasuksmit",
      "Chakkrit Tantithamthavorn"
    ],
    "abstract": "DevOps has emerged as one of the most rapidly evolving software development\nparadigms. With the growing concerns surrounding security in software systems,\nthe DevSecOps paradigm has gained prominence, urging practitioners to\nincorporate security practices seamlessly into the DevOps workflow. However,\nintegrating security into the DevOps workflow can impact agility and impede\ndelivery speed. Recently, the advancement of artificial intelligence (AI) has\nrevolutionized automation in various software domains, including software\nsecurity. AI-driven security approaches, particularly those leveraging machine\nlearning or deep learning, hold promise in automating security workflows. They\nreduce manual efforts, which can be integrated into DevOps to ensure\nuninterrupted delivery speed and align with the DevSecOps paradigm\nsimultaneously. This paper seeks to contribute to the critical intersection of\nAI and DevSecOps by presenting a comprehensive landscape of AI-driven security\ntechniques applicable to DevOps and identifying avenues for enhancing security,\ntrust, and efficiency in software development processes. We analyzed 99\nresearch papers spanning from 2017 to 2023. Specifically, we address two key\nresearch questions (RQs). In RQ1, we identified 12 security tasks associated\nwith the DevSecOps process and reviewed existing AI-driven security approaches,\nthe problems they addressed, and the 65 benchmarks used to evaluate those\napproaches. Drawing insights from our findings, in RQ2, we discussed\nstate-of-the-art AI-driven security approaches, highlighted 15 challenges in\nexisting research, and proposed 15 corresponding avenues for future\nopportunities.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.04839v2",
    "published_date": "2024-04-07 07:24:58 UTC",
    "updated_date": "2024-09-13 00:08:11 UTC"
  },
  {
    "arxiv_id": "2404.07235v2",
    "title": "LLM-aided explanations of EDA synthesis errors",
    "authors": [
      "Siyu Qiu",
      "Benjamin Tan",
      "Hammond Pearce"
    ],
    "abstract": "Training new engineers in digital design is a challenge, particularly when it\ncomes to teaching the complex electronic design automation (EDA) tooling used\nin this domain. Learners will typically deploy designs in the Verilog and VHDL\nhardware description languages to Field Programmable Gate Arrays (FPGAs) from\nAltera (Intel) and Xilinx (AMD) via proprietary closed-source toolchains\n(Quartus Prime and Vivado, respectively). These tools are complex and difficult\nto use -- yet, as they are the tools used in industry, they are an essential\nfirst step in this space. In this work, we examine how recent advances in\nartificial intelligence may be leveraged to address aspects of this challenge.\nSpecifically, we investigate if Large Language Models (LLMs), which have\ndemonstrated text comprehension and question-answering capabilities, can be\nused to generate novice-friendly explanations of compile-time synthesis error\nmessages from Quartus Prime and Vivado. To perform this study we generate 936\nerror message explanations using three OpenAI LLMs over 21 different buggy code\nsamples. These are then graded for relevance and correctness, and we find that\nin approximately 71% of cases the LLMs give correct & complete explanations\nsuitable for novice learners.",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.PL",
      "cs.SE"
    ],
    "primary_category": "cs.AR",
    "comment": "6 pages, 6 figures. Accepted in IEEE LLM Aided Design Workshop\n  (LAD'2024)",
    "pdf_url": "http://arxiv.org/pdf/2404.07235v2",
    "published_date": "2024-04-07 07:12:16 UTC",
    "updated_date": "2024-10-17 20:49:56 UTC"
  },
  {
    "arxiv_id": "2404.10782v1",
    "title": "Quantifying AI Vulnerabilities: A Synthesis of Complexity, Dynamical Systems, and Game Theory",
    "authors": [
      "B Kereopa-Yorke"
    ],
    "abstract": "The rapid integration of Artificial Intelligence (AI) systems across critical\ndomains necessitates robust security evaluation frameworks. We propose a novel\napproach that introduces three metrics: System Complexity Index (SCI), Lyapunov\nExponent for AI Stability (LEAIS), and Nash Equilibrium Robustness (NER). SCI\nquantifies the inherent complexity of an AI system, LEAIS captures its\nstability and sensitivity to perturbations, and NER evaluates its strategic\nrobustness against adversarial manipulation. Through comparative analysis, we\ndemonstrate the advantages of our framework over existing techniques. We\ndiscuss the theoretical and practical implications, potential applications,\nlimitations, and future research directions. Our work contributes to the\ndevelopment of secure and trustworthy AI technologies by providing a holistic,\ntheoretically grounded approach to AI security evaluation. As AI continues to\nadvance, prioritising and advancing AI security through interdisciplinary\ncollaboration is crucial to ensure its responsible deployment for the benefit\nof society.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "18 pages",
    "pdf_url": "http://arxiv.org/pdf/2404.10782v1",
    "published_date": "2024-04-07 07:05:59 UTC",
    "updated_date": "2024-04-07 07:05:59 UTC"
  },
  {
    "arxiv_id": "2404.04825v1",
    "title": "Gradient-based Design of Computational Granular Crystals",
    "authors": [
      "Atoosa Parsa",
      "Corey S. O'Hern",
      "Rebecca Kramer-Bottiglio",
      "Josh Bongard"
    ],
    "abstract": "There is growing interest in engineering unconventional computing devices\nthat leverage the intrinsic dynamics of physical substrates to perform fast and\nenergy-efficient computations. Granular metamaterials are one such substrate\nthat has emerged as a promising platform for building wave-based information\nprocessing devices with the potential to integrate sensing, actuation, and\ncomputation. Their high-dimensional and nonlinear dynamics result in nontrivial\nand sometimes counter-intuitive wave responses that can be shaped by the\nmaterial properties, geometry, and configuration of individual grains. Such\nhighly tunable rich dynamics can be utilized for mechanical computing in\nspecial-purpose applications. However, there are currently no general\nframeworks for the inverse design of large-scale granular materials. Here, we\nbuild upon the similarity between the spatiotemporal dynamics of wave\npropagation in material and the computational dynamics of Recurrent Neural\nNetworks to develop a gradient-based optimization framework for harmonically\ndriven granular crystals. We showcase how our framework can be utilized to\ndesign basic logic gates where mechanical vibrations carry the information at\npredetermined frequencies. We compare our design methodology with classic\ngradient-free methods and find that our approach discovers higher-performing\nconfigurations with less computational effort. Our findings show that a\ngradient-based optimization method can greatly expand the design space of\nmetamaterials and provide the opportunity to systematically traverse the\nparameter space to find materials with the desired functionalities.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.ET",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.04825v1",
    "published_date": "2024-04-07 06:24:47 UTC",
    "updated_date": "2024-04-07 06:24:47 UTC"
  },
  {
    "arxiv_id": "2404.04824v1",
    "title": "Mixup Domain Adaptations for Dynamic Remaining Useful Life Predictions",
    "authors": [
      "Muhammad Tanzil Furqon",
      "Mahardhika Pratama",
      "Lin Liu",
      "Habibullah",
      "Kutluyil Dogancay"
    ],
    "abstract": "Remaining Useful Life (RUL) predictions play vital role for asset planning\nand maintenance leading to many benefits to industries such as reduced\ndowntime, low maintenance costs, etc. Although various efforts have been\ndevoted to study this topic, most existing works are restricted for i.i.d\nconditions assuming the same condition of the training phase and the deployment\nphase. This paper proposes a solution to this problem where a mix-up domain\nadaptation (MDAN) is put forward. MDAN encompasses a three-staged mechanism\nwhere the mix-up strategy is not only performed to regularize the source and\ntarget domains but also applied to establish an intermediate mix-up domain\nwhere the source and target domains are aligned. The self-supervised learning\nstrategy is implemented to prevent the supervision collapse problem. Rigorous\nevaluations have been performed where MDAN is compared to recently published\nworks for dynamic RUL predictions. MDAN outperforms its counterparts with\nsubstantial margins in 12 out of 12 cases. In addition, MDAN is evaluated with\nthe bearing machine dataset where it beats prior art with significant gaps in 8\nof 12 cases. Source codes of MDAN are made publicly available in\n\\url{https://github.com/furqon3009/MDAN}.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "accepted for publication in Knowledge-based Systems",
    "pdf_url": "http://arxiv.org/pdf/2404.04824v1",
    "published_date": "2024-04-07 06:23:18 UTC",
    "updated_date": "2024-04-07 06:23:18 UTC"
  },
  {
    "arxiv_id": "2404.04821v5",
    "title": "A Data-to-Product Multimodal Conceptual Framework to Achieve Automated Software Evolution for Context-rich Intelligent Applications",
    "authors": [
      "Songhui Yue"
    ],
    "abstract": "While AI is extensively transforming Software Engineering (SE) fields, SE is\nstill in need of a framework to overall consider all phases to facilitate\nAutomated Software Evolution (ASEv), particularly for intelligent applications\nthat are context-rich, instead of conquering each division independently. Its\ncomplexity comes from the intricacy of the intelligent applications, the\nheterogeneity of the data sources, and the constant changes in the context.\nThis study proposes a conceptual framework for achieving automated software\nevolution, emphasizing the importance of multimodality learning. A Selective\nSequential Scope Model (3S) model is developed based on the conceptual\nframework, and it can be used to categorize existing and future research when\nit covers different SE phases and multimodal learning tasks. This research is a\npreliminary step toward the blueprint of a higher-level ASEv. The proposed\nconceptual framework can act as a practical guideline for practitioners to\nprepare themselves for diving into this area. Although the study is about\nintelligent applications, the framework and analysis methods may be adapted for\nother types of software as AI brings more intelligence into their life cycles.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.04821v5",
    "published_date": "2024-04-07 06:05:25 UTC",
    "updated_date": "2024-10-09 04:49:27 UTC"
  },
  {
    "arxiv_id": "2404.04818v1",
    "title": "DWE+: Dual-Way Matching Enhanced Framework for Multimodal Entity Linking",
    "authors": [
      "Shezheng Song",
      "Shasha Li",
      "Shan Zhao",
      "Xiaopeng Li",
      "Chengyu Wang",
      "Jie Yu",
      "Jun Ma",
      "Tianwei Yan",
      "Bin Ji",
      "Xiaoguang Mao"
    ],
    "abstract": "Multimodal entity linking (MEL) aims to utilize multimodal information\n(usually textual and visual information) to link ambiguous mentions to\nunambiguous entities in knowledge base. Current methods facing main issues:\n(1)treating the entire image as input may contain redundant information. (2)the\ninsufficient utilization of entity-related information, such as attributes in\nimages. (3)semantic inconsistency between the entity in knowledge base and its\nrepresentation. To this end, we propose DWE+ for multimodal entity linking.\nDWE+ could capture finer semantics and dynamically maintain semantic\nconsistency with entities. This is achieved by three aspects: (a)we introduce a\nmethod for extracting fine-grained image features by partitioning the image\ninto multiple local objects. Then, hierarchical contrastive learning is used to\nfurther align semantics between coarse-grained information(text and image) and\nfine-grained (mention and visual objects). (b)we explore ways to extract visual\nattributes from images to enhance fusion feature such as facial features and\nidentity. (c)we leverage Wikipedia and ChatGPT to capture the entity\nrepresentation, achieving semantic enrichment from both static and dynamic\nperspectives, which better reflects the real-world entity semantics.\nExperiments on Wikimel, Richpedia, and Wikidiverse datasets demonstrate the\neffectiveness of DWE+ in improving MEL performance. Specifically, we optimize\nthese datasets and achieve state-of-the-art performance on the enhanced\ndatasets. The code and enhanced datasets are released on\nhttps://github.com/season1blue/DWET",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "under review on TOIS. arXiv admin note: substantial text overlap with\n  arXiv:2312.11816",
    "pdf_url": "http://arxiv.org/pdf/2404.04818v1",
    "published_date": "2024-04-07 05:56:42 UTC",
    "updated_date": "2024-04-07 05:56:42 UTC"
  },
  {
    "arxiv_id": "2404.04814v4",
    "title": "Inference-Time Rule Eraser: Fair Recognition via Distilling and Removing Biased Rules",
    "authors": [
      "Yi Zhang",
      "Dongyuan Lu",
      "Jitao Sang"
    ],
    "abstract": "Machine learning models often make predictions based on biased features such\nas gender, race, and other social attributes, posing significant fairness\nrisks, especially in societal applications, such as hiring, banking, and\ncriminal justice. Traditional approaches to addressing this issue involve\nretraining or fine-tuning neural networks with fairness-aware optimization\nobjectives. However, these methods can be impractical due to significant\ncomputational resources, complex industrial tests, and the associated CO2\nfootprint. Additionally, regular users often fail to fine-tune models because\nthey lack access to model parameters In this paper, we introduce the\nInference-Time Rule Eraser (Eraser), a novel method designed to address\nfairness concerns by removing biased decision-making rules from deployed models\nduring inference without altering model weights. We begin by establishing a\ntheoretical foundation for modifying model outputs to eliminate biased rules\nthrough Bayesian analysis. Next, we present a specific implementation of Eraser\nthat involves two stages: (1) distilling the biased rules from the deployed\nmodel into an additional patch model, and (2) removing these biased rules from\nthe output of the deployed model during inference. Extensive experiments\nvalidate the effectiveness of our approach, showcasing its superior performance\nin addressing fairness concerns in AI systems.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.04814v4",
    "published_date": "2024-04-07 05:47:41 UTC",
    "updated_date": "2024-08-27 04:43:10 UTC"
  },
  {
    "arxiv_id": "2404.08677v1",
    "title": "PMG : Personalized Multimodal Generation with Large Language Models",
    "authors": [
      "Xiaoteng Shen",
      "Rui Zhang",
      "Xiaoyan Zhao",
      "Jieming Zhu",
      "Xi Xiao"
    ],
    "abstract": "The emergence of large language models (LLMs) has revolutionized the\ncapabilities of text comprehension and generation. Multi-modal generation\nattracts great attention from both the industry and academia, but there is\nlittle work on personalized generation, which has important applications such\nas recommender systems. This paper proposes the first method for personalized\nmultimodal generation using LLMs, showcases its applications and validates its\nperformance via an extensive experimental study on two datasets. The proposed\nmethod, Personalized Multimodal Generation (PMG for short) first converts user\nbehaviors (e.g., clicks in recommender systems or conversations with a virtual\nassistant) into natural language to facilitate LLM understanding and extract\nuser preference descriptions. Such user preferences are then fed into a\ngenerator, such as a multimodal LLM or diffusion model, to produce personalized\ncontent. To capture user preferences comprehensively and accurately, we propose\nto let the LLM output a combination of explicit keywords and implicit\nembeddings to represent user preferences. Then the combination of keywords and\nembeddings are used as prompts to condition the generator. We optimize a\nweighted sum of the accuracy and preference scores so that the generated\ncontent has a good balance between them. Compared to a baseline method without\npersonalization, PMG has a significant improvement on personalization for up to\n8% in terms of LPIPS while retaining the accuracy of generation.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.08677v1",
    "published_date": "2024-04-07 03:05:57 UTC",
    "updated_date": "2024-04-07 03:05:57 UTC"
  },
  {
    "arxiv_id": "2404.04763v1",
    "title": "GenEARL: A Training-Free Generative Framework for Multimodal Event Argument Role Labeling",
    "authors": [
      "Hritik Bansal",
      "Po-Nien Kung",
      "P. Jeffrey Brantingham",
      "Kai-Wei Chang",
      "Nanyun Peng"
    ],
    "abstract": "Multimodal event argument role labeling (EARL), a task that assigns a role\nfor each event participant (object) in an image is a complex challenge. It\nrequires reasoning over the entire image, the depicted event, and the\ninteractions between various objects participating in the event. Existing\nmodels heavily rely on high-quality event-annotated training data to understand\nthe event semantics and structures, and they fail to generalize to new event\ntypes and domains. In this paper, we propose GenEARL, a training-free\ngenerative framework that harness the power of the modern generative models to\nunderstand event task descriptions given image contexts to perform the EARL\ntask. Specifically, GenEARL comprises two stages of generative prompting with a\nfrozen vision-language model (VLM) and a frozen large language model (LLM).\nFirst, a generative VLM learns the semantics of the event argument roles and\ngenerates event-centric object descriptions based on the image. Subsequently, a\nLLM is prompted with the generated object descriptions with a predefined\ntemplate for EARL (i.e., assign an object with an event argument role). We show\nthat GenEARL outperforms the contrastive pretraining (CLIP) baseline by 9.4%\nand 14.2% accuracy for zero-shot EARL on the M2E2 and SwiG datasets,\nrespectively. In addition, we outperform CLIP-Event by 22% precision on M2E2\ndataset. The framework also allows flexible adaptation and generalization to\nunseen domains.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "20 pages, 15 Figures, 13 figures",
    "pdf_url": "http://arxiv.org/pdf/2404.04763v1",
    "published_date": "2024-04-07 00:28:13 UTC",
    "updated_date": "2024-04-07 00:28:13 UTC"
  }
]