[
  {
    "arxiv_id": "2503.15512v1",
    "title": "Beyond Accuracy, SHAP, and Anchors -- On the difficulty of designing effective end-user explanations",
    "authors": [
      "Zahra Abba Omar",
      "Nadia Nahar",
      "Jacob Tjaden",
      "Inès M. Gilles",
      "Fikir Mekonnen",
      "Jane Hsieh",
      "Christian Kästner",
      "Alka Menon"
    ],
    "abstract": "Modern machine learning produces models that are impossible for users or\ndevelopers to fully understand -- raising concerns about trust, oversight and\nhuman dignity. Transparency and explainability methods aim to provide some help\nin understanding models, but it remains challenging for developers to design\nexplanations that are understandable to target users and effective for their\npurpose. Emerging guidelines and regulations set goals but may not provide\neffective actionable guidance to developers. In a controlled experiment with\n124 participants, we investigate whether and how specific forms of policy\nguidance help developers design explanations for an ML-powered screening tool\nfor diabetic retinopathy. Contrary to our expectations, we found that\nparticipants across the board struggled to produce quality explanations, comply\nwith the provided policy requirements for explainability, and provide evidence\nof compliance. We posit that participant noncompliance is in part due to a\nfailure to imagine and anticipate the needs of their audience, particularly\nnon-technical stakeholders. Drawing on cognitive process theory and the\nsociological imagination to contextualize participants' failure, we recommend\neducational interventions.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.15512v1",
    "published_date": "2025-01-28 23:54:00 UTC",
    "updated_date": "2025-01-28 23:54:00 UTC"
  },
  {
    "arxiv_id": "2501.17347v1",
    "title": "Deep-and-Wide Learning: Enhancing Data-Driven Inference via Synergistic Learning of Inter- and Intra-Data Representations",
    "authors": [
      "Md Tauhidul Islam",
      "Lei Xing"
    ],
    "abstract": "Advancements in deep learning are revolutionizing science and engineering.\nThe immense success of deep learning is largely due to its ability to extract\nessential high-dimensional (HD) features from input data and make inference\ndecisions based on this information. However, current deep neural network (DNN)\nmodels face several challenges, such as the requirements of extensive amounts\nof data and computational resources. Here, we introduce a new learning scheme,\nreferred to as deep-and-wide learning (DWL), to systematically capture features\nnot only within individual input data (intra-data features) but also across the\ndata (inter-data features). Furthermore, we propose a dual-interactive-channel\nnetwork (D-Net) to realize the DWL, which leverages our Bayesian formulation of\nlow-dimensional (LD) inter-data feature extraction and its synergistic\ninteraction with the conventional HD representation of the dataset, for\nsubstantially enhanced computational efficiency and inference. The proposed\ntechnique has been applied to data across various disciplines for both\nclassification and regression tasks. Our results demonstrate that DWL surpasses\nstate-of-the-art DNNs in accuracy by a substantial margin with limited training\ndata and improves the computational efficiency by order(s) of magnitude. The\nproposed DWL strategy dramatically alters the data-driven learning techniques,\nincluding emerging large foundation models, and sheds significant insights into\nthe evolving field of AI.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "16 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.17347v1",
    "published_date": "2025-01-28 23:47:34 UTC",
    "updated_date": "2025-01-28 23:47:34 UTC"
  },
  {
    "arxiv_id": "2502.00052v1",
    "title": "Bridging Contrastive Learning and Domain Adaptation: Theoretical Perspective and Practical Application",
    "authors": [
      "Gonzalo Iñaki Quintana",
      "Laurence Vancamberg",
      "Vincent Jugnon",
      "Agnès Desolneux",
      "Mathilde Mougeot"
    ],
    "abstract": "This work studies the relationship between Contrastive Learning and Domain\nAdaptation from a theoretical perspective. The two standard contrastive losses,\nNT-Xent loss (Self-supervised) and Supervised Contrastive loss, are related to\nthe Class-wise Mean Maximum Discrepancy (CMMD), a dissimilarity measure widely\nused for Domain Adaptation. Our work shows that minimizing the contrastive\nlosses decreases the CMMD and simultaneously improves class-separability,\nlaying the theoretical groundwork for the use of Contrastive Learning in the\ncontext of Domain Adaptation. Due to the relevance of Domain Adaptation in\nmedical imaging, we focused the experiments on mammography images. Extensive\nexperiments on three mammography datasets - synthetic patches, clinical (real)\npatches, and clinical (real) images - show improved Domain Adaptation,\nclass-separability, and classification performance, when minimizing the\nSupervised Contrastive loss.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.00052v1",
    "published_date": "2025-01-28 23:45:58 UTC",
    "updated_date": "2025-01-28 23:45:58 UTC"
  },
  {
    "arxiv_id": "2501.17343v1",
    "title": "Post-Training Quantization for 3D Medical Image Segmentation: A Practical Study on Real Inference Engines",
    "authors": [
      "Chongyu Qu",
      "Ritchie Zhao",
      "Ye Yu",
      "Bin Liu",
      "Tianyuan Yao",
      "Junchao Zhu",
      "Bennett A. Landman",
      "Yucheng Tang",
      "Yuankai Huo"
    ],
    "abstract": "Quantizing deep neural networks ,reducing the precision (bit-width) of their\ncomputations, can remarkably decrease memory usage and accelerate processing,\nmaking these models more suitable for large-scale medical imaging applications\nwith limited computational resources. However, many existing methods studied\n\"fake quantization\", which simulates lower precision operations during\ninference, but does not actually reduce model size or improve real-world\ninference speed. Moreover, the potential of deploying real 3D low-bit\nquantization on modern GPUs is still unexplored. In this study, we introduce a\nreal post-training quantization (PTQ) framework that successfully implements\ntrue 8-bit quantization on state-of-the-art (SOTA) 3D medical segmentation\nmodels, i.e., U-Net, SegResNet, SwinUNETR, nnU-Net, UNesT, TransUNet,\nST-UNet,and VISTA3D. Our approach involves two main steps. First, we use\nTensorRT to perform fake quantization for both weights and activations with\nunlabeled calibration dataset. Second, we convert this fake quantization into\nreal quantization via TensorRT engine on real GPUs, resulting in real-world\nreductions in model size and inference latency. Extensive experiments\ndemonstrate that our framework effectively performs 8-bit quantization on GPUs\nwithout sacrificing model performance. This advancement enables the deployment\nof efficient deep learning models in medical imaging applications where\ncomputational resources are constrained. The code and models have been\nreleased, including U-Net, TransUNet pretrained on the BTCV dataset for\nabdominal (13-label) segmentation, UNesT pretrained on the Whole Brain Dataset\nfor whole brain (133-label) segmentation, and nnU-Net, SegResNet, SwinUNETR and\nVISTA3D pretrained on TotalSegmentator V2 for full body (104-label)\nsegmentation. https://github.com/hrlblab/PTQ.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.17343v1",
    "published_date": "2025-01-28 23:29:40 UTC",
    "updated_date": "2025-01-28 23:29:40 UTC"
  },
  {
    "arxiv_id": "2501.17338v1",
    "title": "Inferring from Logits: Exploring Best Practices for Decoding-Free Generative Candidate Selection",
    "authors": [
      "Mingyu Derek Ma",
      "Yanna Ding",
      "Zijie Huang",
      "Jianxi Gao",
      "Yizhou Sun",
      "Wei Wang"
    ],
    "abstract": "Generative Language Models rely on autoregressive decoding to produce the\noutput sequence token by token. Many tasks such as preference optimization,\nrequire the model to produce task-level output consisting of multiple tokens\ndirectly by selecting candidates from a pool as predictions. Determining a\ntask-level prediction from candidates using the ordinary token-level decoding\nmechanism is constrained by time-consuming decoding and interrupted gradients\nby discrete token selection. Existing works have been using decoding-free\ncandidate selection methods to obtain candidate probability from initial output\nlogits over vocabulary. Though these estimation methods are widely used, they\nare not systematically evaluated, especially on end tasks. We introduce an\nevaluation of a comprehensive collection of decoding-free candidate selection\napproaches on a comprehensive set of tasks, including five multiple-choice QA\ntasks with a small candidate pool and four clinical decision tasks with a\nmassive amount of candidates, some with 10k+ options. We evaluate the\nestimation methods paired with a wide spectrum of foundation LMs covering\ndifferent architectures, sizes and training paradigms. The results and insights\nfrom our analysis inform the future model design.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.17338v1",
    "published_date": "2025-01-28 23:21:28 UTC",
    "updated_date": "2025-01-28 23:21:28 UTC"
  },
  {
    "arxiv_id": "2501.18642v1",
    "title": "DebiasPI: Inference-time Debiasing by Prompt Iteration of a Text-to-Image Generative Model",
    "authors": [
      "Sarah Bonna",
      "Yu-Cheng Huang",
      "Ekaterina Novozhilova",
      "Sejin Paik",
      "Zhengyang Shan",
      "Michelle Yilin Feng",
      "Ge Gao",
      "Yonish Tayal",
      "Rushil Kulkarni",
      "Jialin Yu",
      "Nupur Divekar",
      "Deepti Ghadiyaram",
      "Derry Wijaya",
      "Margrit Betke"
    ],
    "abstract": "Ethical intervention prompting has emerged as a tool to counter demographic\nbiases of text-to-image generative AI models. Existing solutions either require\nto retrain the model or struggle to generate images that reflect desired\ndistributions on gender and race. We propose an inference-time process called\nDebiasPI for Debiasing-by-Prompt-Iteration that provides prompt intervention by\nenabling the user to control the distributions of individuals' demographic\nattributes in image generation. DebiasPI keeps track of which attributes have\nbeen generated either by probing the internal state of the model or by using\nexternal attribute classifiers. Its control loop guides the text-to-image model\nto select not yet sufficiently represented attributes, With DebiasPI, we were\nable to create images with equal representations of race and gender that\nvisualize challenging concepts of news headlines. We also experimented with the\nattributes age, body type, profession, and skin tone, and measured how\nattributes change when our intervention prompt targets the distribution of an\nunrelated attribute type. We found, for example, if the text-to-image model is\nasked to balance racial representation, gender representation improves but the\nskin tone becomes less diverse. Attempts to cover a wide range of skin colors\nwith various intervention prompts showed that the model struggles to generate\nthe palest skin tones. We conducted various ablation studies, in which we\nremoved DebiasPI's attribute control, that reveal the model's propensity to\ngenerate young, male characters. It sometimes visualized career success by\ngenerating two-panel images with a pre-success dark-skinned person becoming\nlight-skinned with success, or switching gender from pre-success female to\npost-success male, thus further motivating ethical intervention prompting with\nDebiasPI.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "This work was presented at The European Conference on Computer Vision\n  (ECCV) 2024 Workshop \"Fairness and ethics towards transparent AI: facing the\n  chalLEnge through model Debiasing\" (FAILED), Milano, Italy, on September 29,\n  2024, https://failed-workshop-eccv-2024.github.io",
    "pdf_url": "http://arxiv.org/pdf/2501.18642v1",
    "published_date": "2025-01-28 23:17:20 UTC",
    "updated_date": "2025-01-28 23:17:20 UTC"
  },
  {
    "arxiv_id": "2501.17329v1",
    "title": "Anomaly Detection in Cooperative Vehicle Perception Systems under Imperfect Communication",
    "authors": [
      "Ashish Bastola",
      "Hao Wang",
      "Abolfazl Razi"
    ],
    "abstract": "Anomaly detection is a critical requirement for ensuring safety in autonomous\ndriving. In this work, we leverage Cooperative Perception to share information\nacross nearby vehicles, enabling more accurate identification and consensus of\nanomalous behaviors in complex traffic scenarios. To account for the real-world\nchallenge of imperfect communication, we propose a cooperative-perception-based\nanomaly detection framework (CPAD), which is a robust architecture that remains\neffective under communication interruptions, thereby facilitating reliable\nperformance even in low-bandwidth settings. Since no multi-agent anomaly\ndetection dataset exists for vehicle trajectories, we introduce 15,000\ndifferent scenarios with a 90,000 trajectories benchmark dataset generated\nthrough rule-based vehicle dynamics analysis. Empirical results demonstrate\nthat our approach outperforms standard anomaly classification methods in\nF1-score, AUC and showcase strong robustness to agent connection interruptions.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.MA",
    "comment": "10 pages",
    "pdf_url": "http://arxiv.org/pdf/2501.17329v1",
    "published_date": "2025-01-28 22:41:06 UTC",
    "updated_date": "2025-01-28 22:41:06 UTC"
  },
  {
    "arxiv_id": "2501.17326v1",
    "title": "Memorize and Rank: Elevating Large Language Models for Clinical Diagnosis Prediction",
    "authors": [
      "Mingyu Derek Ma",
      "Xiaoxuan Wang",
      "Yijia Xiao",
      "Anthony Cuturrufo",
      "Vijay S Nori",
      "Eran Halperin",
      "Wei Wang"
    ],
    "abstract": "Clinical diagnosis prediction models, when provided with a patient's medical\nhistory, aim to detect potential diseases early, facilitating timely\nintervention and improving prognostic outcomes. However, the inherent scarcity\nof patient data and large disease candidate space often pose challenges in\ndeveloping satisfactory models for this intricate task. The exploration of\nleveraging Large Language Models (LLMs) for encapsulating clinical decision\nprocesses has been limited. We introduce MERA, a clinical diagnosis prediction\nmodel that bridges pertaining natural language knowledge with medical practice.\nWe apply hierarchical contrastive learning on a disease candidate ranking list\nto alleviate the large decision space issue. With concept memorization through\nfine-tuning, we bridge the natural language clinical knowledge with medical\ncodes. Experimental results on MIMIC-III and IV datasets show that MERA\nachieves the state-of-the-art diagnosis prediction performance and dramatically\nelevates the diagnosis prediction capabilities of generative LMs.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "To appear at AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.17326v1",
    "published_date": "2025-01-28 22:38:45 UTC",
    "updated_date": "2025-01-28 22:38:45 UTC"
  },
  {
    "arxiv_id": "2501.17325v2",
    "title": "Connecting Federated ADMM to Bayes",
    "authors": [
      "Siddharth Swaroop",
      "Mohammad Emtiyaz Khan",
      "Finale Doshi-Velez"
    ],
    "abstract": "We provide new connections between two distinct federated learning approaches\nbased on (i) ADMM and (ii) Variational Bayes (VB), and propose new variants by\ncombining their complementary strengths. Specifically, we show that the dual\nvariables in ADMM naturally emerge through the 'site' parameters used in VB\nwith isotropic Gaussian covariances. Using this, we derive two versions of ADMM\nfrom VB that use flexible covariances and functional regularisation,\nrespectively. Through numerical experiments, we validate the improvements\nobtained in performance. The work shows connection between two fields that are\nbelieved to be fundamentally different and combines them to improve federated\nlearning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.17325v2",
    "published_date": "2025-01-28 22:37:25 UTC",
    "updated_date": "2025-02-28 17:57:52 UTC"
  },
  {
    "arxiv_id": "2501.17315v1",
    "title": "A sketch of an AI control safety case",
    "authors": [
      "Tomek Korbak",
      "Joshua Clymer",
      "Benjamin Hilton",
      "Buck Shlegeris",
      "Geoffrey Irving"
    ],
    "abstract": "As LLM agents gain a greater capacity to cause harm, AI developers might\nincreasingly rely on control measures such as monitoring to justify that they\nare safe. We sketch how developers could construct a \"control safety case\",\nwhich is a structured argument that models are incapable of subverting control\nmeasures in order to cause unacceptable outcomes. As a case study, we sketch an\nargument that a hypothetical LLM agent deployed internally at an AI company\nwon't exfiltrate sensitive information. The sketch relies on evidence from a\n\"control evaluation,\"' where a red team deliberately designs models to\nexfiltrate data in a proxy for the deployment environment. The safety case then\nhinges on several claims: (1) the red team adequately elicits model\ncapabilities to exfiltrate data, (2) control measures remain at least as\neffective in deployment, and (3) developers conservatively extrapolate model\nperformance to predict the probability of data exfiltration in deployment. This\nsafety case sketch is a step toward more concrete arguments that can be used to\nshow that a dangerously capable LLM agent is safe to deploy.",
    "categories": [
      "cs.AI",
      "cs.CR",
      "cs.SE"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.17315v1",
    "published_date": "2025-01-28 21:52:15 UTC",
    "updated_date": "2025-01-28 21:52:15 UTC"
  },
  {
    "arxiv_id": "2501.17310v2",
    "title": "Probing LLM World Models: Enhancing Guesstimation with Wisdom of Crowds Decoding",
    "authors": [
      "Yun-Shiuan Chuang",
      "Nikunj Harlalka",
      "Sameer Narendran",
      "Alexander Cheung",
      "Sizhe Gao",
      "Siddharth Suresh",
      "Junjie Hu",
      "Timothy T. Rogers"
    ],
    "abstract": "Guesstimation, the task of making approximate quantity estimates, is a common\nreal-world challenge. However, it has been largely overlooked in large language\nmodels (LLMs) and vision language models (VLMs) research. We introduce a novel\nguesstimation dataset, MARBLES. This dataset requires one to estimate how many\nitems (e.g., marbles) can fit into containers (e.g., a one-cup measuring cup),\nboth with and without accompanying images. Inspired by the social science\nconcept of the ``Wisdom of Crowds'' (WOC) - taking the median from estimates\nfrom a crowd), which has proven effective in guesstimation, we propose ``WOC\ndecoding'' strategy for LLM guesstimation. We show that LLMs/VLMs perform well\non guesstimation, suggesting that they possess some level of a \"world model\"\nnecessary for guesstimation. Moreover, similar to human performance, the WOC\ndecoding method improves LLM/VLM guesstimation accuracy. Furthermore, the\ninclusion of images in the multimodal condition enhances model performance.\nThese results highlight the value of WOC decoding strategy for LLMs/VLMs and\nposition guesstimation as a probe for evaluating LLMs/VLMs' world model. As\nLLMs' world model is a fundamental prerequisite for many real-world tasks,\ne.g., human-AI teaming, our findings have broad implications for the AI\ncommunity.",
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.17310v2",
    "published_date": "2025-01-28 21:43:56 UTC",
    "updated_date": "2025-01-30 07:15:04 UTC"
  },
  {
    "arxiv_id": "2501.17296v2",
    "title": "Multi-Physics Simulations via Coupled Fourier Neural Operator",
    "authors": [
      "Shibo Li",
      "Tao Wang",
      "Yifei Sun",
      "Hewei Tang"
    ],
    "abstract": "Physical simulations are essential tools across critical fields such as\nmechanical and aerospace engineering, chemistry, meteorology, etc. While neural\noperators, particularly the Fourier Neural Operator (FNO), have shown promise\nin predicting simulation results with impressive performance and efficiency,\nthey face limitations when handling real-world scenarios involving coupled\nmulti-physics outputs. Current neural operator methods either overlook the\ncorrelations between multiple physical processes or employ simplistic\narchitectures that inadequately capture these relationships. To overcome these\nchallenges, we introduce a novel coupled multi-physics neural operator learning\n(COMPOL) framework that extends the capabilities of Fourier operator layers to\nmodel interactions among multiple physical processes. Our approach implements\nfeature aggregation through recurrent and attention mechanisms, enabling\ncomprehensive modeling of coupled interactions. Our method's core is an\ninnovative system for aggregating latent features from multi-physics processes.\nThese aggregated features serve as enriched information sources for neural\noperator layers, allowing our framework to capture complex physical\nrelationships accurately. We evaluated our coupled multi-physics neural\noperator across diverse physical simulation tasks, including biological\nsystems, fluid mechanics, and multiphase flow in porous media. Our proposed\nmodel demonstrates a two to three-fold improvement in predictive performance\ncompared to existing approaches.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.17296v2",
    "published_date": "2025-01-28 20:58:55 UTC",
    "updated_date": "2025-01-30 03:18:31 UTC"
  },
  {
    "arxiv_id": "2501.17295v1",
    "title": "Mitigating Hallucinated Translations in Large Language Models with Hallucination-focused Preference Optimization",
    "authors": [
      "Zilu Tang",
      "Rajen Chatterjee",
      "Sarthak Garg"
    ],
    "abstract": "Machine Translation (MT) is undergoing a paradigm shift, with systems based\non fine-tuned large language models (LLM) becoming increasingly competitive\nwith traditional encoder-decoder models trained specifically for translation\ntasks. However, LLM-based systems are at a higher risk of generating\nhallucinations, which can severely undermine user's trust and safety. Most\nprior research on hallucination mitigation focuses on traditional MT models,\nwith solutions that involve post-hoc mitigation - detecting hallucinated\ntranslations and re-translating them. While effective, this approach introduces\nadditional complexity in deploying extra tools in production and also increases\nlatency. To address these limitations, we propose a method that intrinsically\nlearns to mitigate hallucinations during the model training phase.\nSpecifically, we introduce a data creation framework to generate hallucination\nfocused preference datasets. Fine-tuning LLMs on these preference datasets\nreduces the hallucination rate by an average of 96% across five language pairs,\nwhile preserving overall translation quality. In a zero-shot setting our\napproach reduces hallucinations by 89% on an average across three unseen target\nlanguages.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "NAACL 2025 Main Conference Long paper (9 pages)",
    "pdf_url": "http://arxiv.org/pdf/2501.17295v1",
    "published_date": "2025-01-28 20:58:43 UTC",
    "updated_date": "2025-01-28 20:58:43 UTC"
  },
  {
    "arxiv_id": "2501.17286v1",
    "title": "Fine-Tuning Open-Source Large Language Models to Improve Their Performance on Radiation Oncology Tasks: A Feasibility Study to Investigate Their Potential Clinical Applications in Radiation Oncology",
    "authors": [
      "Peilong Wang",
      "Zhengliang Liu",
      "Yiwei Li",
      "Jason Holmes",
      "Peng Shu",
      "Lian Zhang",
      "Xiang Li",
      "Quanzheng Li",
      "Brady S. Laughlin",
      "Diego Santos Toesca",
      "Sujay A. Vora",
      "Samir H. Patel",
      "Terence T. Sio",
      "Tianming Liu",
      "Wei Liu"
    ],
    "abstract": "Background: The radiation oncology clinical practice involves many steps\nrelying on the dynamic interplay of abundant text data. Large language models\nhave displayed remarkable capabilities in processing complex text information.\nBut their direct applications in specific fields like radiation oncology remain\nunderexplored.\n  Purpose: This study aims to investigate whether fine-tuning LLMs with domain\nknowledge can improve the performance on Task (1) treatment regimen generation,\nTask (2) treatment modality selection (photon, proton, electron, or\nbrachytherapy), and Task (3) ICD-10 code prediction in radiation oncology.\n  Methods: Data for 15,724 patient cases were extracted. Cases where patients\nhad a single diagnostic record, and a clearly identifiable primary treatment\nplan were selected for preprocessing and manual annotation to have 7,903 cases\nof the patient diagnosis, treatment plan, treatment modality, and ICD-10 code.\nEach case was used to construct a pair consisting of patient diagnostics\ndetails and an answer (treatment regimen, treatment modality, or ICD-10 code\nrespectively) for the supervised fine-tuning of these three tasks. Open source\nLLaMA2-7B and Mistral-7B models were utilized for the fine-tuning with the\nLow-Rank Approximations method. Accuracy and ROUGE-1 score were reported for\nthe fine-tuned models and original models. Clinical evaluation was performed on\nTask (1) by radiation oncologists, while precision, recall, and F-1 score were\nevaluated for Task (2) and (3). One-sided Wilcoxon signed-rank tests were used\nto statistically analyze the results.\n  Results: Fine-tuned LLMs outperformed original LLMs across all tasks with\np-value <= 0.001. Clinical evaluation demonstrated that over 60% of the\nfine-tuned LLMs-generated treatment regimens were clinically acceptable.\nPrecision, recall, and F1-score showed improved performance of fine-tuned LLMs.",
    "categories": [
      "physics.med-ph",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "physics.med-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.17286v1",
    "published_date": "2025-01-28 20:37:32 UTC",
    "updated_date": "2025-01-28 20:37:32 UTC"
  },
  {
    "arxiv_id": "2501.17282v3",
    "title": "From Natural Language to Extensive-Form Game Representations",
    "authors": [
      "Shilong Deng",
      "Yongzhao Wang",
      "Rahul Savani"
    ],
    "abstract": "We introduce a framework for translating game descriptions in natural\nlanguage into extensive-form representations in game theory, leveraging Large\nLanguage Models (LLMs) and in-context learning. Given the varying levels of\nstrategic complexity in games, such as perfect versus imperfect information,\ndirectly applying in-context learning would be insufficient. To address this,\nwe introduce a two-stage framework with specialized modules to enhance\nin-context learning, enabling it to divide and conquer the problem effectively.\nIn the first stage, we tackle the challenge of imperfect information by\ndeveloping a module that identifies information sets along and the\ncorresponding partial tree structure. With this information, the second stage\nleverages in-context learning alongside a self-debugging module to produce a\ncomplete extensive-form game tree represented using pygambit, the Python API of\na recognized game-theoretic analysis tool called Gambit. Using this python\nrepresentation enables the automation of tasks such as computing Nash\nequilibria directly from natural language descriptions. We evaluate the\nperformance of the full framework, as well as its individual components, using\nvarious LLMs on games with different levels of strategic complexity. Our\nexperimental results show that the framework significantly outperforms baseline\nmodels in generating accurate extensive-form games, with each module playing a\ncritical role in its success.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.GT",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "This work has been accepted as a full paper for AAMAS 2025. This is a\n  full version of the AAMAS 2025 proceedings",
    "pdf_url": "http://arxiv.org/pdf/2501.17282v3",
    "published_date": "2025-01-28 20:30:36 UTC",
    "updated_date": "2025-01-31 17:26:12 UTC"
  },
  {
    "arxiv_id": "2501.17260v1",
    "title": "ViT-2SPN: Vision Transformer-based Dual-Stream Self-Supervised Pretraining Networks for Retinal OCT Classification",
    "authors": [
      "Mohammadreza Saraei",
      "Igor Kozak",
      "Eung-Joo Lee"
    ],
    "abstract": "Optical Coherence Tomography (OCT) is a non-invasive imaging modality\nessential for diagnosing various eye diseases. Despite its clinical\nsignificance, developing OCT-based diagnostic tools faces challenges, such as\nlimited public datasets, sparse annotations, and privacy concerns. Although\ndeep learning has made progress in automating OCT analysis, these challenges\nremain unresolved. To address these limitations, we introduce the Vision\nTransformer-based Dual-Stream Self-Supervised Pretraining Network (ViT-2SPN), a\nnovel framework designed to enhance feature extraction and improve diagnostic\naccuracy. ViT-2SPN employs a three-stage workflow: Supervised Pretraining,\nSelf-Supervised Pretraining (SSP), and Supervised Fine-Tuning. The pretraining\nphase leverages the OCTMNIST dataset (97,477 unlabeled images across four\ndisease classes) with data augmentation to create dual-augmented views. A\nVision Transformer (ViT-Base) backbone extracts features, while a negative\ncosine similarity loss aligns feature representations. Pretraining is conducted\nover 50 epochs with a learning rate of 0.0001 and momentum of 0.999.\nFine-tuning is performed on a stratified 5.129% subset of OCTMNIST using\n10-fold cross-validation. ViT-2SPN achieves a mean AUC of 0.93, accuracy of\n0.77, precision of 0.81, recall of 0.75, and an F1 score of 0.76, outperforming\nexisting SSP-based methods.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.17260v1",
    "published_date": "2025-01-28 19:41:38 UTC",
    "updated_date": "2025-01-28 19:41:38 UTC"
  },
  {
    "arxiv_id": "2501.17161v1",
    "title": "SFT Memorizes, RL Generalizes: A Comparative Study of Foundation Model Post-training",
    "authors": [
      "Tianzhe Chu",
      "Yuexiang Zhai",
      "Jihan Yang",
      "Shengbang Tong",
      "Saining Xie",
      "Dale Schuurmans",
      "Quoc V. Le",
      "Sergey Levine",
      "Yi Ma"
    ],
    "abstract": "Supervised fine-tuning (SFT) and reinforcement learning (RL) are widely used\npost-training techniques for foundation models. However, their roles in\nenhancing model generalization capabilities remain unclear. This paper studies\nthe difference between SFT and RL on generalization and memorization, focusing\non text-based rule variants and visual variants. We introduce GeneralPoints, an\narithmetic reasoning card game, and adopt V-IRL, a real-world navigation\nenvironment, to assess how models trained with SFT and RL generalize to unseen\nvariants in both textual and visual domains. We show that RL, especially when\ntrained with an outcome-based reward, generalizes across both rule-based\ntextual and visual variants. SFT, in contrast, tends to memorize training data\nand struggles to generalize out-of-distribution scenarios. Further analysis\nreveals that RL improves the model's underlying visual recognition\ncapabilities, contributing to its enhanced generalization in the visual domain.\nDespite RL's superior generalization, we show that SFT remains essential for\neffective RL training; SFT stabilizes the model's output format, enabling\nsubsequent RL to achieve its performance gains. These findings demonstrates the\ncapability of RL for acquiring generalizable knowledge in complex, multi-modal\ntasks.",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Website at https://tianzhechu.com/SFTvsRL",
    "pdf_url": "http://arxiv.org/pdf/2501.17161v1",
    "published_date": "2025-01-28 18:59:44 UTC",
    "updated_date": "2025-01-28 18:59:44 UTC"
  },
  {
    "arxiv_id": "2501.17160v1",
    "title": "A Hybrid Deep Learning CNN Model for Enhanced COVID-19 Detection from Computed Tomography (CT) Scan Images",
    "authors": [
      "Suresh Babu Nettur",
      "Shanthi Karpurapu",
      "Unnati Nettur",
      "Likhit Sagar Gajja",
      "Sravanthy Myneni",
      "Akhil Dusi",
      "Lalithya Posham"
    ],
    "abstract": "Early detection of COVID-19 is crucial for effective treatment and\ncontrolling its spread. This study proposes a novel hybrid deep learning model\nfor detecting COVID-19 from CT scan images, designed to assist overburdened\nmedical professionals. Our proposed model leverages the strengths of VGG16,\nDenseNet121, and MobileNetV2 to extract features, followed by Principal\nComponent Analysis (PCA) for dimensionality reduction, after which the features\nare stacked and classified using a Support Vector Classifier (SVC). We\nconducted comparative analysis between the proposed hybrid model and individual\npre-trained CNN models, using a dataset of 2,108 training images and 373 test\nimages comprising both COVID-positive and non-COVID images. Our proposed hybrid\nmodel achieved an accuracy of 98.93%, outperforming the individual models in\nterms of precision, recall, F1 scores, and ROC curve performance.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "Corresponding authors: Shanthi Karpurapu\n  (shanthi.karpurapu@gmail.com), Suresh Babu Nettur (nettursuresh@gmail.com)\n  Shanthi Karpurapu and Suresh Babu Nettur are co-first authors",
    "pdf_url": "http://arxiv.org/pdf/2501.17160v1",
    "published_date": "2025-01-28 18:59:21 UTC",
    "updated_date": "2025-01-28 18:59:21 UTC"
  },
  {
    "arxiv_id": "2501.17152v1",
    "title": "Three-Dimensional Diffusion-Weighted Multi-Slab MRI With Slice Profile Compensation Using Deep Energy Model",
    "authors": [
      "Reza Ghorbani",
      "Jyothi Rikhab Chand",
      "Chu-Yu Lee",
      "Mathews Jacob",
      "Merry Mani"
    ],
    "abstract": "Three-dimensional (3D) multi-slab acquisition is a technique frequently\nemployed in high-resolution diffusion-weighted MRI in order to achieve the best\nsignal-to-noise ratio (SNR) efficiency. However, this technique is limited by\nslab boundary artifacts that cause intensity fluctuations and aliasing between\nslabs which reduces the accuracy of anatomical imaging. Addressing this issue\nis crucial for advancing diffusion MRI quality and making high-resolution\nimaging more feasible for clinical and research applications. In this work, we\npropose a regularized slab profile encoding (PEN) method within a Plug-and-Play\nADMM framework, incorporating multi-scale energy (MuSE) regularization to\neffectively improve the slab combined reconstruction. Experimental results\ndemonstrate that the proposed method significantly improves image quality\ncompared to non-regularized and TV-regularized PEN approaches. The regularized\nPEN framework provides a more robust and efficient solution for high-resolution\n3D diffusion MRI, potentially enabling clearer, more reliable anatomical\nimaging across various applications.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "physics.med-ph"
    ],
    "primary_category": "eess.IV",
    "comment": "4 pages, 4 figures, ISBI2025 Conference paper",
    "pdf_url": "http://arxiv.org/pdf/2501.17152v1",
    "published_date": "2025-01-28 18:53:16 UTC",
    "updated_date": "2025-01-28 18:53:16 UTC"
  },
  {
    "arxiv_id": "2501.17148v3",
    "title": "AxBench: Steering LLMs? Even Simple Baselines Outperform Sparse Autoencoders",
    "authors": [
      "Zhengxuan Wu",
      "Aryaman Arora",
      "Atticus Geiger",
      "Zheng Wang",
      "Jing Huang",
      "Dan Jurafsky",
      "Christopher D. Manning",
      "Christopher Potts"
    ],
    "abstract": "Fine-grained steering of language model outputs is essential for safety and\nreliability. Prompting and finetuning are widely used to achieve these goals,\nbut interpretability researchers have proposed a variety of\nrepresentation-based techniques as well, including sparse autoencoders (SAEs),\nlinear artificial tomography, supervised steering vectors, linear probes, and\nrepresentation finetuning. At present, there is no benchmark for making direct\ncomparisons between these proposals. Therefore, we introduce AxBench, a\nlarge-scale benchmark for steering and concept detection, and report\nexperiments on Gemma-2-2B and 9B. For steering, we find that prompting\noutperforms all existing methods, followed by finetuning. For concept\ndetection, representation-based methods such as difference-in-means, perform\nthe best. On both evaluations, SAEs are not competitive. We introduce a novel\nweakly-supervised representational method (Rank-1 Representation Finetuning;\nReFT-r1), which is competitive on both tasks while providing the\ninterpretability advantages that prompting lacks. Along with AxBench, we train\nand publicly release SAE-scale feature dictionaries for ReFT-r1 and DiffMean.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.17148v3",
    "published_date": "2025-01-28 18:51:24 UTC",
    "updated_date": "2025-03-03 21:15:30 UTC"
  },
  {
    "arxiv_id": "2501.17144v1",
    "title": "FactCG: Enhancing Fact Checkers with Graph-Based Multi-Hop Data",
    "authors": [
      "Deren Lei",
      "Yaxi Li",
      "Siyao Li",
      "Mengya Hu",
      "Rui Xu",
      "Ken Archer",
      "Mingyu Wang",
      "Emily Ching",
      "Alex Deng"
    ],
    "abstract": "Prior research on training grounded factuality classification models to\ndetect hallucinations in large language models (LLMs) has relied on public\nnatural language inference (NLI) data and synthetic data. However, conventional\nNLI datasets are not well-suited for document-level reasoning, which is\ncritical for detecting LLM hallucinations. Recent approaches to document-level\nsynthetic data generation involve iteratively removing sentences from documents\nand annotating factuality using LLM-based prompts. While effective, this method\nis computationally expensive for long documents and limited by the LLM's\ncapabilities. In this work, we analyze the differences between existing\nsynthetic training data used in state-of-the-art models and real LLM output\nclaims. Based on our findings, we propose a novel approach for synthetic data\ngeneration, CG2C, that leverages multi-hop reasoning on context graphs\nextracted from documents. Our fact checker model, FactCG, demonstrates improved\nperformance with more connected reasoning, using the same backbone models.\nExperiments show it even outperforms GPT-4-o on the LLM-Aggrefact benchmark\nwith much smaller model size.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "NAACL 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.17144v1",
    "published_date": "2025-01-28 18:45:07 UTC",
    "updated_date": "2025-01-28 18:45:07 UTC"
  },
  {
    "arxiv_id": "2502.19422v2",
    "title": "Implementation of a Generative AI Assistant in K-12 Education: The CyberScholar Initiative",
    "authors": [
      "Vania Castro",
      "Ana Karina de Oliveira Nascimento",
      "Raigul Zheldibayeva",
      "Duane Searsmith",
      "Akash Saini",
      "Bill Cope",
      "Mary Kalantzis"
    ],
    "abstract": "This paper focuses on the piloting of CyberScholar, a Generative AI (GenAI)\nassistant tool that aims to provide feedback on writing K-12 contexts. The aim\nwas to use GenAI to provide formative and summative feedback on students' texts\nin English Language Arts (ELA), Social Studies, and Modern World History. The\ntrials discussed in this paper involved Grades 7, 8, 10, and 11 and were\nconducted in three schools in the Midwest and one in the Northwest of the\nUnited States. The tool used two main mechanisms: \"prompt engineering\" based on\nparticipant teachers' assessment rubric and \"fine-tuning\" a Large Language\nModel (LLM) from a customized corpus of teaching materials using Retrieval\nAugmented Generation. This paper focuses on CyberScholar's potential to enhance\nstudents' writing abilities and support teachers in diverse subject areas\nrequiring written assignments.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.19422v2",
    "published_date": "2025-01-28 18:23:03 UTC",
    "updated_date": "2025-03-25 18:13:16 UTC"
  },
  {
    "arxiv_id": "2501.17117v1",
    "title": "Histoires Morales: A French Dataset for Assessing Moral Alignment",
    "authors": [
      "Thibaud Leteno",
      "Irina Proskurina",
      "Antoine Gourru",
      "Julien Velcin",
      "Charlotte Laclau",
      "Guillaume Metzler",
      "Christophe Gravier"
    ],
    "abstract": "Aligning language models with human values is crucial, especially as they\nbecome more integrated into everyday life. While models are often adapted to\nuser preferences, it is equally important to ensure they align with moral norms\nand behaviours in real-world social situations. Despite significant progress in\nlanguages like English and Chinese, French has seen little attention in this\narea, leaving a gap in understanding how LLMs handle moral reasoning in this\nlanguage. To address this gap, we introduce Histoires Morales, a French dataset\nderived from Moral Stories, created through translation and subsequently\nrefined with the assistance of native speakers to guarantee grammatical\naccuracy and adaptation to the French cultural context. We also rely on\nannotations of the moral values within the dataset to ensure their alignment\nwith French norms. Histoires Morales covers a wide range of social situations,\nincluding differences in tipping practices, expressions of honesty in\nrelationships, and responsibilities toward animals. To foster future research,\nwe also conduct preliminary experiments on the alignment of multilingual models\non French and English data and the robustness of the alignment. We find that\nwhile LLMs are generally aligned with human moral norms by default, they can be\neasily influenced with user-preference optimization for both moral and immoral\ndata.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to NAACL 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.17117v1",
    "published_date": "2025-01-28 18:07:30 UTC",
    "updated_date": "2025-01-28 18:07:30 UTC"
  },
  {
    "arxiv_id": "2501.17104v1",
    "title": "COS(M+O)S: Curiosity and RL-Enhanced MCTS for Exploring Story Space via Language Models",
    "authors": [
      "Tobias Materzok"
    ],
    "abstract": "We present COS(M+O)S, a System 2-inspired framework for open-ended plot\ndevelopment that systematically explores the vast space of possible story\nexpansions, enabling a 3B-parameter language model to approach the plot quality\nof a 70B model on select short-story tasks. The method accomplishes this by\ncombining Monte Carlo Tree Search (MCTS), guided by a step-level value model\nthat rewards moderate surprisal (curiosity) while penalizing incoherence, and\nOdds Ratio Preference Optimization (ORPO) to fine-tune the policy on high-value\nplot expansions. This iterative reinforcement learning loop systematically\nexplores multiple candidate plot branches, backpropagates quality signals, and\nadapts the policy for faster convergence, notably shifting the policy from\npuzzle-based Chain-of-Thought to more character-driven storytelling. In\nsmall-scale tests with short-story prompts, 67%-77% of participants favored\nCOS(M+O)S's highest-rated expansions over lower-rated ones, suggesting that our\nlearned value function aligns. GPT-4o ratings further show that COS(M+O)S\nsurpasses naive single-pass decoding from Llama 3.2 3B by 0.59 SD, coming\nwithin 0.06 SD of Llama 3.1 70B (no significant difference, p=0.93). Pairwise\ncomparisons with o1 place COS(M+O)S 1.5 SD above the 3B baseline and find no\nstatistically significant gap from 70B. Nevertheless, absolute story quality\nremains modest, constrained by the small model's capacity and limited training\ndata.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.17104v1",
    "published_date": "2025-01-28 17:44:04 UTC",
    "updated_date": "2025-01-28 17:44:04 UTC"
  },
  {
    "arxiv_id": "2501.17096v1",
    "title": "Why is the estimation of metaorder impact with public market data so challenging?",
    "authors": [
      "Manuel Naviglio",
      "Giacomo Bormetti",
      "Francesco Campigli",
      "German Rodikov",
      "Fabrizio Lillo"
    ],
    "abstract": "Estimating market impact and transaction costs of large trades (metaorders)\nis a very important topic in finance. However, using models of price and trade\nbased on public market data provide average price trajectories which are\nqualitatively different from what is observed during real metaorder executions:\nthe price increases linearly, rather than in a concave way, during the\nexecution and the amount of reversion after its end is very limited. We claim\nthat this is a generic phenomenon due to the fact that even sophisticated\nstatistical models are unable to correctly describe the origin of the\nautocorrelation of the order flow. We propose a modified Transient Impact Model\nwhich provides more realistic trajectories by assuming that only a fraction of\nthe metaorder trading triggers market order flow. Interestingly, in our model\nthere is a critical condition on the kernels of the price and order flow\nequations in which market impact becomes permanent.",
    "categories": [
      "q-fin.TR",
      "cs.AI",
      "econ.EM",
      "physics.soc-ph"
    ],
    "primary_category": "q-fin.TR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.17096v1",
    "published_date": "2025-01-28 17:29:08 UTC",
    "updated_date": "2025-01-28 17:29:08 UTC"
  },
  {
    "arxiv_id": "2501.17088v1",
    "title": "Mamba-Shedder: Post-Transformer Compression for Efficient Selective Structured State Space Models",
    "authors": [
      "J. Pablo Muñoz",
      "Jinjie Yuan",
      "Nilesh Jain"
    ],
    "abstract": "Large pre-trained models have achieved outstanding results in sequence\nmodeling. The Transformer block and its attention mechanism have been the main\ndrivers of the success of these models. Recently, alternative architectures,\nsuch as Selective Structured State Space Models (SSMs), have been proposed to\naddress the inefficiencies of Transformers. This paper explores the compression\nof SSM-based models, particularly Mamba and its hybrids. We study the\nsensitivity of these models to the removal of selected components at different\ngranularities to reduce the model size and computational overhead, thus\nimproving their efficiency while maintaining accuracy. The proposed solutions,\ncollectively referred to as Mamba-Shedder, achieve a speedup of up to 1.4x\nduring inference, demonstrating that model efficiency can be improved by\neliminating several redundancies with minimal impact on the overall model\nperformance. The code is available at\nhttps://github.com/IntelLabs/Hardware-Aware-Automated-Machine-Learning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "I.2.0"
    ],
    "primary_category": "cs.LG",
    "comment": "NAACL-25 - Main track",
    "pdf_url": "http://arxiv.org/pdf/2501.17088v1",
    "published_date": "2025-01-28 17:22:01 UTC",
    "updated_date": "2025-01-28 17:22:01 UTC"
  },
  {
    "arxiv_id": "2501.18638v1",
    "title": "Graph of Attacks with Pruning: Optimizing Stealthy Jailbreak Prompt Generation for Enhanced LLM Content Moderation",
    "authors": [
      "Daniel Schwartz",
      "Dmitriy Bespalov",
      "Zhe Wang",
      "Ninad Kulkarni",
      "Yanjun Qi"
    ],
    "abstract": "We present a modular pipeline that automates the generation of stealthy\njailbreak prompts derived from high-level content policies, enhancing LLM\ncontent moderation. First, we address query inefficiency and jailbreak strength\nby developing Graph of Attacks with Pruning (GAP), a method that utilizes\nstrategies from prior jailbreaks, resulting in 92% attack success rate on\nGPT-3.5 using only 54% of the queries of the prior algorithm. Second, we\naddress the cold-start issue by automatically generating seed prompts from the\nhigh-level policy using LLMs. Finally, we demonstrate the utility of these\ngenerated jailbreak prompts of improving content moderation by fine-tuning\nPromptGuard, a model trained to detect jailbreaks, increasing its accuracy on\nthe Toxic-Chat dataset from 5.1% to 93.89%.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CR",
    "comment": "15 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.18638v1",
    "published_date": "2025-01-28 17:10:20 UTC",
    "updated_date": "2025-01-28 17:10:20 UTC"
  },
  {
    "arxiv_id": "2501.17081v1",
    "title": "Graph Transformers for inverse physics: reconstructing flows around arbitrary 2D airfoils",
    "authors": [
      "Gregory Duthé",
      "Imad Abdallah",
      "Eleni Chatzi"
    ],
    "abstract": "We introduce a Graph Transformer framework that serves as a general inverse\nphysics engine on meshes, demonstrated through the challenging task of\nreconstructing aerodynamic flow fields from sparse surface measurements. While\ndeep learning has shown promising results in forward physics simulation,\ninverse problems remain particularly challenging due to their ill-posed nature\nand the difficulty of propagating information from limited boundary\nobservations. Our approach addresses these challenges by combining the\ngeometric expressiveness of message-passing neural networks with the global\nreasoning of Transformers, enabling efficient learning of inverse mappings from\nboundary conditions to complete states. We evaluate this framework on a\ncomprehensive dataset of steady-state RANS simulations around diverse airfoil\ngeometries, where the task is to reconstruct full pressure and velocity fields\nfrom surface pressure measurements alone. The architecture achieves high\nreconstruction accuracy while maintaining fast inference times. We conduct\nexperiments and provide insights into the relative importance of local\ngeometric processing and global attention mechanisms in mesh-based inverse\nproblems. We also find that the framework is robust to reduced sensor coverage.\nThese results suggest that Graph Transformers can serve as effective inverse\nphysics engines across a broader range of applications where complete system\nstates must be reconstructed from limited boundary observations.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.17081v1",
    "published_date": "2025-01-28 17:06:09 UTC",
    "updated_date": "2025-01-28 17:06:09 UTC"
  },
  {
    "arxiv_id": "2501.17079v1",
    "title": "Learning Mean Field Control on Sparse Graphs",
    "authors": [
      "Christian Fabian",
      "Kai Cui",
      "Heinz Koeppl"
    ],
    "abstract": "Large agent networks are abundant in applications and nature and pose\ndifficult challenges in the field of multi-agent reinforcement learning (MARL)\ndue to their computational and theoretical complexity. While graphon mean field\ngames and their extensions provide efficient learning algorithms for dense and\nmoderately sparse agent networks, the case of realistic sparser graphs remains\nlargely unsolved. Thus, we propose a novel mean field control model inspired by\nlocal weak convergence to include sparse graphs such as power law networks with\ncoefficients above two. Besides a theoretical analysis, we design scalable\nlearning algorithms which apply to the challenging class of graph sequences\nwith finite first moment. We compare our model and algorithms for various\nexamples on synthetic and real world networks with mean field algorithms based\non Lp graphons and graphexes. As it turns out, our approach outperforms\nexisting methods in many examples and on various networks due to the special\ndesign aiming at an important, but so far hard to solve class of MARL problems.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.GT",
      "cs.LG"
    ],
    "primary_category": "cs.MA",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.17079v1",
    "published_date": "2025-01-28 17:03:30 UTC",
    "updated_date": "2025-01-28 17:03:30 UTC"
  },
  {
    "arxiv_id": "2501.17077v1",
    "title": "Induced Modularity and Community Detection for Functionally Interpretable Reinforcement Learning",
    "authors": [
      "Anna Soligo",
      "Pietro Ferraro",
      "David Boyle"
    ],
    "abstract": "Interpretability in reinforcement learning is crucial for ensuring AI systems\nalign with human values and fulfill the diverse related requirements including\nsafety, robustness and fairness. Building on recent approaches to encouraging\nsparsity and locality in neural networks, we demonstrate how the penalisation\nof non-local weights leads to the emergence of functionally independent modules\nin the policy network of a reinforcement learning agent. To illustrate this, we\ndemonstrate the emergence of two parallel modules for assessment of movement\nalong the X and Y axes in a stochastic Minigrid environment. Through the novel\napplication of community detection algorithms, we show how these modules can be\nautomatically identified and their functional roles verified through direct\nintervention on the network weights prior to inference. This establishes a\nscalable framework for reinforcement learning interpretability through\nfunctional modularity, addressing challenges regarding the trade-off between\ncompleteness and cognitive tractability of reinforcement learning explanations.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.17077v1",
    "published_date": "2025-01-28 17:02:16 UTC",
    "updated_date": "2025-01-28 17:02:16 UTC"
  },
  {
    "arxiv_id": "2501.18636v2",
    "title": "SafeRAG: Benchmarking Security in Retrieval-Augmented Generation of Large Language Model",
    "authors": [
      "Xun Liang",
      "Simin Niu",
      "Zhiyu Li",
      "Sensen Zhang",
      "Hanyu Wang",
      "Feiyu Xiong",
      "Jason Zhaoxin Fan",
      "Bo Tang",
      "Shichao Song",
      "Mengwei Wang",
      "Jiawei Yang"
    ],
    "abstract": "The indexing-retrieval-generation paradigm of retrieval-augmented generation\n(RAG) has been highly successful in solving knowledge-intensive tasks by\nintegrating external knowledge into large language models (LLMs). However, the\nincorporation of external and unverified knowledge increases the vulnerability\nof LLMs because attackers can perform attack tasks by manipulating knowledge.\nIn this paper, we introduce a benchmark named SafeRAG designed to evaluate the\nRAG security. First, we classify attack tasks into silver noise, inter-context\nconflict, soft ad, and white Denial-of-Service. Next, we construct RAG security\nevaluation dataset (i.e., SafeRAG dataset) primarily manually for each task. We\nthen utilize the SafeRAG dataset to simulate various attack scenarios that RAG\nmay encounter. Experiments conducted on 14 representative RAG components\ndemonstrate that RAG exhibits significant vulnerability to all attack tasks and\neven the most apparent attack task can easily bypass existing retrievers,\nfilters, or advanced LLMs, resulting in the degradation of RAG service quality.\nCode is available at: https://github.com/IAAR-Shanghai/SafeRAG.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.18636v2",
    "published_date": "2025-01-28 17:01:31 UTC",
    "updated_date": "2025-02-23 10:46:28 UTC"
  },
  {
    "arxiv_id": "2501.17062v1",
    "title": "EdgeMLOps: Operationalizing ML models with Cumulocity IoT and thin-edge.io for Visual quality Inspection",
    "authors": [
      "Kanishk Chaturvedi",
      "Johannes Gasthuber",
      "Mohamed Abdelaal"
    ],
    "abstract": "This paper introduces EdgeMLOps, a framework leveraging Cumulocity IoT and\nthin-edge.io for deploying and managing machine learning models on\nresource-constrained edge devices. We address the challenges of model\noptimization, deployment, and lifecycle management in edge environments. The\nframework's efficacy is demonstrated through a visual quality inspection (VQI)\nuse case where images of assets are processed on edge devices, enabling\nreal-time condition updates within an asset management system. Furthermore, we\nevaluate the performance benefits of different quantization methods,\nspecifically static and dynamic signed-int8, on a Raspberry Pi 4, demonstrating\nsignificant inference time reductions compared to FP32 precision. Our results\nhighlight the potential of EdgeMLOps to enable efficient and scalable AI\ndeployments at the edge for industrial applications.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.17062v1",
    "published_date": "2025-01-28 16:40:40 UTC",
    "updated_date": "2025-01-28 16:40:40 UTC"
  },
  {
    "arxiv_id": "2501.17044v2",
    "title": "Synthesizing 3D Abstractions by Inverting Procedural Buildings with Transformers",
    "authors": [
      "Maximilian Dax",
      "Jordi Berbel",
      "Jan Stria",
      "Leonidas Guibas",
      "Urs Bergmann"
    ],
    "abstract": "We generate abstractions of buildings, reflecting the essential aspects of\ntheir geometry and structure, by learning to invert procedural models. We first\nbuild a dataset of abstract procedural building models paired with simulated\npoint clouds and then learn the inverse mapping through a transformer. Given a\npoint cloud, the trained transformer then infers the corresponding abstracted\nbuilding in terms of a programmatic language description. This approach\nleverages expressive procedural models developed for gaming and animation, and\nthereby retains desirable properties such as efficient rendering of the\ninferred abstractions and strong priors for regularity and symmetry. Our\napproach achieves good reconstruction accuracy in terms of geometry and\nstructure, as well as structurally consistent inpainting.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "4 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.17044v2",
    "published_date": "2025-01-28 16:09:34 UTC",
    "updated_date": "2025-01-29 11:06:57 UTC"
  },
  {
    "arxiv_id": "2501.17041v1",
    "title": "Benchmarking Quantum Convolutional Neural Networks for Signal Classification in Simulated Gamma-Ray Burst Detection",
    "authors": [
      "Farida Farsian",
      "Nicolò Parmiggiani",
      "Alessandro Rizzo",
      "Gabriele Panebianco",
      "Andrea Bulgarelli",
      "Francesco Schillirò",
      "Carlo Burigana",
      "Vincenzo Cardone",
      "Luca Cappelli",
      "Massimo Meneghetti",
      "Giuseppe Murante",
      "Giuseppe Sarracino",
      "Roberto Scaramella",
      "Vincenzo Testa",
      "Tiziana Trombetti"
    ],
    "abstract": "This study evaluates the use of Quantum Convolutional Neural Networks (QCNNs)\nfor identifying signals resembling Gamma-Ray Bursts (GRBs) within simulated\nastrophysical datasets in the form of light curves. The task addressed here\nfocuses on distinguishing GRB-like signals from background noise in simulated\nCherenkov Telescope Array Observatory (CTAO) data, the next-generation\nastrophysical observatory for very high-energy gamma-ray science. QCNNs, a\nquantum counterpart of classical Convolutional Neural Networks (CNNs), leverage\nquantum principles to process and analyze high-dimensional data efficiently. We\nimplemented a hybrid quantum-classical machine learning technique using the\nQiskit framework, with the QCNNs trained on a quantum simulator. Several QCNN\narchitectures were tested, employing different encoding methods such as Data\nReuploading and Amplitude encoding. Key findings include that QCNNs achieved\naccuracy comparable to classical CNNs, often surpassing 90\\%, while using fewer\nparameters, potentially leading to more efficient models in terms of\ncomputational resources. A benchmark study further examined how hyperparameters\nlike the number of qubits and encoding methods affected performance, with more\nqubits and advanced encoding methods generally enhancing accuracy but\nincreasing complexity. QCNNs showed robust performance on time-series datasets,\nsuccessfully detecting GRB signals with high precision. The research is a\npioneering effort in applying QCNNs to astrophysics, offering insights into\ntheir potential and limitations. This work sets the stage for future\ninvestigations to fully realize the advantages of QCNNs in astrophysical data\nanalysis.",
    "categories": [
      "astro-ph.HE",
      "cs.AI",
      "quant-ph"
    ],
    "primary_category": "astro-ph.HE",
    "comment": "9 pages, Accepted for publication in 33rd Euromicro/IEEE\n  International Conference on Parallel, Distributed and Network-Based\n  Processing (PDP 2025)",
    "pdf_url": "http://arxiv.org/pdf/2501.17041v1",
    "published_date": "2025-01-28 16:07:12 UTC",
    "updated_date": "2025-01-28 16:07:12 UTC"
  },
  {
    "arxiv_id": "2501.17037v1",
    "title": "Standardised schema and taxonomy for AI incident databases in critical digital infrastructure",
    "authors": [
      "Avinash Agarwal",
      "Manisha J. Nene"
    ],
    "abstract": "The rapid deployment of Artificial Intelligence (AI) in critical digital\ninfrastructure introduces significant risks, necessitating a robust framework\nfor systematically collecting AI incident data to prevent future incidents.\nExisting databases lack the granularity as well as the standardized structure\nrequired for consistent data collection and analysis, impeding effective\nincident management. This work proposes a standardized schema and taxonomy for\nAI incident databases, addressing these challenges by enabling detailed and\nstructured documentation of AI incidents across sectors. Key contributions\ninclude developing a unified schema, introducing new fields such as incident\nseverity, causes, and harms caused, and proposing a taxonomy for classifying AI\nincidents in critical digital infrastructure. The proposed solution facilitates\nmore effective incident data collection and analysis, thus supporting\nevidence-based policymaking, enhancing industry safety measures, and promoting\ntransparency. This work lays the foundation for a coordinated global response\nto AI incidents, ensuring trust, safety, and accountability in using AI across\nregions.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CY",
    "comment": "6 pages, 3 tables. Accepted at the 2024 IEEE Pune Section\n  International Conference (PuneCon)",
    "pdf_url": "http://arxiv.org/pdf/2501.17037v1",
    "published_date": "2025-01-28 15:59:01 UTC",
    "updated_date": "2025-01-28 15:59:01 UTC"
  },
  {
    "arxiv_id": "2501.17030v1",
    "title": "Challenges in Ensuring AI Safety in DeepSeek-R1 Models: The Shortcomings of Reinforcement Learning Strategies",
    "authors": [
      "Manojkumar Parmar",
      "Yuvaraj Govindarajulu"
    ],
    "abstract": "Large Language Models (LLMs) have achieved remarkable progress in reasoning,\nalignment, and task-specific performance. However, ensuring harmlessness in\nthese systems remains a critical challenge, particularly in advanced models\nlike DeepSeek-R1. This paper examines the limitations of Reinforcement Learning\n(RL) as the primary approach for reducing harmful outputs in DeepSeek-R1 and\ncompares it with Supervised Fine-Tuning (SFT). While RL improves reasoning\ncapabilities, it faces challenges such as reward hacking, generalization\nfailures, language mixing, and high computational costs. We propose hybrid\ntraining approaches combining RL and SFT to achieve robust harmlessness\nreduction. Usage recommendations and future directions for deploying\nDeepSeek-R1 responsibly are also presented.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "9 pages, 1 table",
    "pdf_url": "http://arxiv.org/pdf/2501.17030v1",
    "published_date": "2025-01-28 15:52:51 UTC",
    "updated_date": "2025-01-28 15:52:51 UTC"
  },
  {
    "arxiv_id": "2501.17015v1",
    "title": "Revisit Mixture Models for Multi-Agent Simulation: Experimental Study within a Unified Framework",
    "authors": [
      "Longzhong Lin",
      "Xuewu Lin",
      "Kechun Xu",
      "Haojian Lu",
      "Lichao Huang",
      "Rong Xiong",
      "Yue Wang"
    ],
    "abstract": "Simulation plays a crucial role in assessing autonomous driving systems,\nwhere the generation of realistic multi-agent behaviors is a key aspect. In\nmulti-agent simulation, the primary challenges include behavioral multimodality\nand closed-loop distributional shifts. In this study, we revisit mixture models\nfor generating multimodal agent behaviors, which can cover the mainstream\nmethods including continuous mixture models and GPT-like discrete models.\nFurthermore, we introduce a closed-loop sample generation approach tailored for\nmixture models to mitigate distributional shifts. Within the unified mixture\nmodel~(UniMM) framework, we recognize critical configurations from both model\nand data perspectives. We conduct a systematic examination of various model\nconfigurations, including positive component matching, continuous regression,\nprediction horizon, and the number of components. Moreover, our investigation\ninto the data configuration highlights the pivotal role of closed-loop samples\nin achieving realistic simulations. To extend the benefits of closed-loop\nsamples across a broader range of mixture models, we further address the\nshortcut learning and off-policy learning issues. Leveraging insights from our\nexploration, the distinct variants proposed within the UniMM framework,\nincluding discrete, anchor-free, and anchor-based models, all achieve\nstate-of-the-art performance on the WOSAC benchmark.",
    "categories": [
      "cs.AI",
      "cs.MA",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.17015v1",
    "published_date": "2025-01-28 15:26:25 UTC",
    "updated_date": "2025-01-28 15:26:25 UTC"
  },
  {
    "arxiv_id": "2501.16986v1",
    "title": "Generative quantum combinatorial optimization by means of a novel conditional generative quantum eigensolver",
    "authors": [
      "Shunya Minami",
      "Kouhei Nakaji",
      "Yohichi Suzuki",
      "Alán Aspuru-Guzik",
      "Tadashi Kadowaki"
    ],
    "abstract": "Quantum computing is entering a transformative phase with the emergence of\nlogical quantum processors, which hold the potential to tackle complex problems\nbeyond classical capabilities. While significant progress has been made,\napplying quantum algorithms to real-world problems remains challenging. Hybrid\nquantum-classical techniques have been explored to bridge this gap, but they\noften face limitations in expressiveness, trainability, or scalability. In this\nwork, we introduce conditional Generative Quantum Eigensolver\n(conditional-GQE), a context-aware quantum circuit generator powered by an\nencoder-decoder Transformer. Focusing on combinatorial optimization, we train\nour generator for solving problems with up to 10 qubits, exhibiting nearly\nperfect performance on new problems. By leveraging the high expressiveness and\nflexibility of classical generative models, along with an efficient\npreference-based training scheme, conditional-GQE provides a generalizable and\nscalable framework for quantum circuit generation. Our approach advances hybrid\nquantum-classical computing and contributes to accelerate the transition toward\nfault-tolerant quantum computing.",
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "quant-ph",
    "comment": "26 pages, 12 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.16986v1",
    "published_date": "2025-01-28 14:35:46 UTC",
    "updated_date": "2025-01-28 14:35:46 UTC"
  },
  {
    "arxiv_id": "2501.16966v1",
    "title": "Heterogeneity-aware Personalized Federated Learning via Adaptive Dual-Agent Reinforcement Learning",
    "authors": [
      "Xi Chen",
      "Qin Li",
      "Haibin Cai",
      "Ting Wang"
    ],
    "abstract": "Federated Learning (FL) empowers multiple clients to collaboratively train\nmachine learning models without sharing local data, making it highly applicable\nin heterogeneous Internet of Things (IoT) environments. However, intrinsic\nheterogeneity in clients' model architectures and computing capabilities often\nresults in model accuracy loss and the intractable straggler problem, which\nsignificantly impairs training effectiveness. To tackle these challenges, this\npaper proposes a novel Heterogeneity-aware Personalized Federated Learning\nmethod, named HAPFL, via multi-level Reinforcement Learning (RL) mechanisms.\nHAPFL optimizes the training process by incorporating three strategic\ncomponents: 1) An RL-based heterogeneous model allocation mechanism. The\nparameter server employs a Proximal Policy Optimization (PPO)-based RL agent to\nadaptively allocate appropriately sized, differentiated models to clients based\non their performance, effectively mitigating performance disparities. 2) An\nRL-based training intensity adjustment scheme. The parameter server leverages\nanother PPO-based RL agent to dynamically fine-tune the training intensity for\neach client to further enhance training efficiency and reduce straggling\nlatency. 3) A knowledge distillation-based mutual learning mechanism. Each\nclient deploys both a heterogeneous local model and a homogeneous lightweight\nmodel named LiteModel, where these models undergo mutual learning through\nknowledge distillation. This uniform LiteModel plays a pivotal role in\naggregating and sharing global knowledge, significantly enhancing the\neffectiveness of personalized local training. Experimental results across\nmultiple benchmark datasets demonstrate that HAPFL not only achieves high\naccuracy but also substantially reduces the overall training time by\n20.9%-40.4% and decreases straggling latency by 19.0%-48.0% compared to\nexisting solutions.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.16966v1",
    "published_date": "2025-01-28 14:08:57 UTC",
    "updated_date": "2025-01-28 14:08:57 UTC"
  },
  {
    "arxiv_id": "2501.16961v2",
    "title": "Instantiation-based Formalization of Logical Reasoning Tasks using Language Models and Logical Solvers",
    "authors": [
      "Mohammad Raza",
      "Natasa Milic-Frayling"
    ],
    "abstract": "Robustness of reasoning remains a significant challenge for large language\nmodels, and addressing it is essential for the practical applicability of\nAI-driven reasoning systems. We introduce Semantic Self-Verification (SSV), a\nnovel approach that addresses the key challenge in combining language models\nwith the rigor of logical solvers: to accurately formulate the reasoning\nproblem from natural language to the formal language of the solver. SSV uses a\nconsistency-based approach to produce strong abstract formalizations of\nproblems using concrete instantiations that are generated by the model and\nverified by the solver. In addition to significantly advancing the overall\nreasoning accuracy over the state-of-the-art, a key novelty that this approach\npresents is a feature of verification that has near-perfect precision over a\nsignificant coverage of cases, as we demonstrate on open reasoning benchmarks.\nWe propose such *near-certain reasoning* as a new approach to reduce the need\nfor manual verification in many cases, taking us closer to more dependable and\nautonomous AI reasoning systems.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "IJCAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.16961v2",
    "published_date": "2025-01-28 14:04:49 UTC",
    "updated_date": "2025-05-01 10:16:10 UTC"
  },
  {
    "arxiv_id": "2501.16952v1",
    "title": "Multiple Abstraction Level Retrieve Augment Generation",
    "authors": [
      "Zheng Zheng",
      "Xinyi Ni",
      "Pengyu Hong"
    ],
    "abstract": "A Retrieval-Augmented Generation (RAG) model powered by a large language\nmodel (LLM) provides a faster and more cost-effective solution for adapting to\nnew data and knowledge. It also delivers more specialized responses compared to\npre-trained LLMs. However, most existing approaches rely on retrieving\nprefix-sized chunks as references to support question-answering (Q/A). This\napproach is often deployed to address information needs at a single level of\nabstraction, as it struggles to generate answers across multiple levels of\nabstraction. In an RAG setting, while LLMs can summarize and answer questions\neffectively when provided with sufficient details, retrieving excessive\ninformation often leads to the 'lost in the middle' problem and exceeds token\nlimitations. We propose a novel RAG approach that uses chunks of multiple\nabstraction levels (MAL), including multi-sentence-level, paragraph-level,\nsection-level, and document-level. The effectiveness of our approach is\ndemonstrated in an under-explored scientific domain of Glycoscience. Compared\nto traditional single-level RAG approaches, our approach improves AI evaluated\nanswer correctness of Q/A by 25.739\\% on Glyco-related papers.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.16952v1",
    "published_date": "2025-01-28 13:49:39 UTC",
    "updated_date": "2025-01-28 13:49:39 UTC"
  },
  {
    "arxiv_id": "2501.16945v1",
    "title": "ToolFactory: Automating Tool Generation by Leveraging LLM to Understand REST API Documentations",
    "authors": [
      "Xinyi Ni",
      "Qiuyang Wang",
      "Yukun Zhang",
      "Pengyu Hong"
    ],
    "abstract": "LLM-based tool agents offer natural language interfaces, enabling users to\nseamlessly interact with computing services. While REST APIs are valuable\nresources for building such agents, they must first be transformed into\nAI-compatible tools. Automatically generating AI-compatible tools from REST API\ndocuments can greatly streamline tool agent development and minimize user\nlearning curves. However, API documentation often suffers from a lack of\nstandardization, inconsistent schemas, and incomplete information. To address\nthese issues, we developed \\textbf{ToolFactory}, an open-source pipeline for\nautomating tool generation from unstructured API documents. To enhance the\nreliability of the developed tools, we implemented an evaluation method to\ndiagnose errors. Furthermore, we built a knowledge base of verified tools,\nwhich we leveraged to infer missing information from poorly documented APIs. We\ndeveloped the API Extraction Benchmark, comprising 167 API documents and 744\nendpoints in various formats, and designed a JSON schema to annotate them. This\nannotated dataset was utilized to train and validate ToolFactory. The\nexperimental results highlight the effectiveness of ToolFactory. We also\ndemonstrated ToolFactory by creating a domain-specific AI agent for\nglycomaterials research. ToolFactory exhibits significant potential for\nfacilitating the seamless integration of scientific REST APIs into AI\nworkflows.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.SE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.16945v1",
    "published_date": "2025-01-28 13:42:33 UTC",
    "updated_date": "2025-01-28 13:42:33 UTC"
  },
  {
    "arxiv_id": "2501.16944v2",
    "title": "Exact Computation of Any-Order Shapley Interactions for Graph Neural Networks",
    "authors": [
      "Maximilian Muschalik",
      "Fabian Fumagalli",
      "Paolo Frazzetto",
      "Janine Strotherm",
      "Luca Hermes",
      "Alessandro Sperduti",
      "Eyke Hüllermeier",
      "Barbara Hammer"
    ],
    "abstract": "Albeit the ubiquitous use of Graph Neural Networks (GNNs) in machine learning\n(ML) prediction tasks involving graph-structured data, their interpretability\nremains challenging. In explainable artificial intelligence (XAI), the Shapley\nValue (SV) is the predominant method to quantify contributions of individual\nfeatures to a ML model's output. Addressing the limitations of SVs in complex\nprediction models, Shapley Interactions (SIs) extend the SV to groups of\nfeatures. In this work, we explain single graph predictions of GNNs with SIs\nthat quantify node contributions and interactions among multiple nodes. By\nexploiting the GNN architecture, we show that the structure of interactions in\nnode embeddings are preserved for graph prediction. As a result, the\nexponential complexity of SIs depends only on the receptive fields, i.e. the\nmessage-passing ranges determined by the connectivity of the graph and the\nnumber of convolutional layers. Based on our theoretical results, we introduce\nGraphSHAP-IQ, an efficient approach to compute any-order SIs exactly.\nGraphSHAP-IQ is applicable to popular message passing techniques in conjunction\nwith a linear global pooling and output layer. We showcase that GraphSHAP-IQ\nsubstantially reduces the exponential complexity of computing exact SIs on\nmultiple benchmark datasets. Beyond exact computation, we evaluate\nGraphSHAP-IQ's approximation of SIs on popular GNN architectures and compare\nwith existing baselines. Lastly, we visualize SIs of real-world water\ndistribution networks and molecule structures using a SI-Graph.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Preprint Version. Accepted at ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.16944v2",
    "published_date": "2025-01-28 13:37:44 UTC",
    "updated_date": "2025-03-17 09:46:45 UTC"
  },
  {
    "arxiv_id": "2501.16937v4",
    "title": "TAID: Temporally Adaptive Interpolated Distillation for Efficient Knowledge Transfer in Language Models",
    "authors": [
      "Makoto Shing",
      "Kou Misaki",
      "Han Bao",
      "Sho Yokoi",
      "Takuya Akiba"
    ],
    "abstract": "Causal language models have demonstrated remarkable capabilities, but their\nsize poses significant challenges for deployment in resource-constrained\nenvironments. Knowledge distillation, a widely-used technique for transferring\nknowledge from a large teacher model to a small student model, presents a\npromising approach for model compression. A significant remaining issue lies in\nthe major differences between teacher and student models, namely the\nsubstantial capacity gap, mode averaging, and mode collapse, which pose\nbarriers during distillation. To address these issues, we introduce\n$\\textit{Temporally Adaptive Interpolated Distillation (TAID)}$, a novel\nknowledge distillation approach that dynamically interpolates student and\nteacher distributions through an adaptive intermediate distribution, gradually\nshifting from the student's initial distribution towards the teacher's\ndistribution. We provide a theoretical analysis demonstrating TAID's ability to\nprevent mode collapse and empirically show its effectiveness in addressing the\ncapacity gap while balancing mode averaging and mode collapse. Our\ncomprehensive experiments demonstrate TAID's superior performance across\nvarious model sizes and architectures in both instruction tuning and\npre-training scenarios. Furthermore, we showcase TAID's practical impact by\ndeveloping two state-of-the-art compact foundation models:\n$\\texttt{TAID-LLM-1.5B}$ for language tasks and $\\texttt{TAID-VLM-2B}$ for\nvision-language tasks. These results demonstrate TAID's effectiveness in\ncreating high-performing and efficient models, advancing the development of\nmore accessible AI technologies.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "To appear at the 13th International Conference on Learning\n  Representations (ICLR 2025) as a Spotlight presentation",
    "pdf_url": "http://arxiv.org/pdf/2501.16937v4",
    "published_date": "2025-01-28 13:31:18 UTC",
    "updated_date": "2025-02-27 23:41:37 UTC"
  },
  {
    "arxiv_id": "2501.16922v1",
    "title": "Agential AI for Integrated Continual Learning, Deliberative Behavior, and Comprehensible Models",
    "authors": [
      "Zeki Doruk Erden",
      "Boi Faltings"
    ],
    "abstract": "Contemporary machine learning paradigm excels in statistical data analysis,\nsolving problems that classical AI couldn't. However, it faces key limitations,\nsuch as a lack of integration with planning, incomprehensible internal\nstructure, and inability to learn continually. We present the initial design\nfor an AI system, Agential AI (AAI), in principle operating independently or on\ntop of statistical methods, designed to overcome these issues. AAI's core is a\nlearning method that models temporal dynamics with guarantees of completeness,\nminimality, and continual learning, using component-level variation and\nselection to learn the structure of the environment. It integrates this with a\nbehavior algorithm that plans on a learned model and encapsulates high-level\nbehavior patterns. Preliminary experiments on a simple environment show AAI's\neffectiveness and potential.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.16922v1",
    "published_date": "2025-01-28 13:09:08 UTC",
    "updated_date": "2025-01-28 13:09:08 UTC"
  },
  {
    "arxiv_id": "2501.16899v1",
    "title": "RDMM: Fine-Tuned LLM Models for On-Device Robotic Decision Making with Enhanced Contextual Awareness in Specific Domains",
    "authors": [
      "Shady Nasrat",
      "Myungsu Kim",
      "Seonil Lee",
      "Jiho Lee",
      "Yeoncheol Jang",
      "Seung-joon Yi"
    ],
    "abstract": "Large language models (LLMs) represent a significant advancement in\nintegrating physical robots with AI-driven systems. We showcase the\ncapabilities of our framework within the context of the real-world household\ncompetition. This research introduces a framework that utilizes RDMM (Robotics\nDecision-Making Models), which possess the capacity for decision-making within\ndomain-specific contexts, as well as an awareness of their personal knowledge\nand capabilities. The framework leverages information to enhance the autonomous\ndecision-making of the system. In contrast to other approaches, our focus is on\nreal-time, on-device solutions, successfully operating on hardware with as\nlittle as 8GB of memory. Our framework incorporates visual perception models\nequipping robots with understanding of their environment. Additionally, the\nframework has integrated real-time speech recognition capabilities, thus\nenhancing the human-robot interaction experience. Experimental results\ndemonstrate that the RDMM framework can plan with an 93\\% accuracy.\nFurthermore, we introduce a new dataset consisting of 27k planning instances,\nas well as 1.3k text-image annotated samples derived from the competition. The\nframework, benchmarks, datasets, and models developed in this work are publicly\navailable on our GitHub repository at https://github.com/shadynasrat/RDMM.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.16899v1",
    "published_date": "2025-01-28 12:35:06 UTC",
    "updated_date": "2025-01-28 12:35:06 UTC"
  },
  {
    "arxiv_id": "2501.16889v1",
    "title": "Extending Information Bottleneck Attribution to Video Sequences",
    "authors": [
      "Veronika Solopova",
      "Lucas Schmidt",
      "Dorothea Kolossa"
    ],
    "abstract": "We introduce VIBA, a novel approach for explainable video classification by\nadapting Information Bottlenecks for Attribution (IBA) to video sequences.\nWhile most traditional explainability methods are designed for image models,\nour IBA framework addresses the need for explainability in temporal models used\nfor video analysis. To demonstrate its effectiveness, we apply VIBA to video\ndeepfake detection, testing it on two architectures: the Xception model for\nspatial features and a VGG11-based model for capturing motion dynamics through\noptical flow. Using a custom dataset that reflects recent deepfake generation\ntechniques, we adapt IBA to create relevance and optical flow maps, visually\nhighlighting manipulated regions and motion inconsistencies. Our results show\nthat VIBA generates temporally and spatially consistent explanations, which\nalign closely with human annotations, thus providing interpretability for video\nclassification and particularly for deepfake detection.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.16889v1",
    "published_date": "2025-01-28 12:19:44 UTC",
    "updated_date": "2025-01-28 12:19:44 UTC"
  },
  {
    "arxiv_id": "2501.16884v1",
    "title": "Irony Detection, Reasoning and Understanding in Zero-shot Learning",
    "authors": [
      "Peiling Yi",
      "Yuhan Xia"
    ],
    "abstract": "Irony is a powerful figurative language (FL) on social media that can\npotentially mislead various NLP tasks, such as recommendation systems,\nmisinformation checks, and sentiment analysis. Understanding the implicit\nmeaning of this kind of subtle language is essential to mitigate irony's\nnegative impact on NLP tasks. However, building models to understand irony\npresents a unique set of challenges, because irony is a complex form of\nlanguage that often relies on context, tone, and subtle cues to convey meaning\nthat is opposite or different from the literal interpretation. Large language\nmodels, such as ChatGPT, are increasingly able to capture implicit and\ncontextual information. In this study, we investigate the generalization,\nreasoning and understanding ability of ChatGPT on irony detection across six\ndifferent genre irony detection datasets. Our findings suggest that ChatGPT\nappears to show an enhanced language understanding and reasoning ability. But\nit needs to be very careful in prompt engineering design. Thus, we propose a\nprompt engineering design framework IDADP to achieve higher irony detection\naccuracy, improved understanding of irony, and more effective explanations\ncompared to other state-of-the-art ChatGPT zero-shot approaches. And ascertain\nvia experiments that the practice generated under the framework is likely to be\nthe promised solution to resolve the generalization issues of LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.16884v1",
    "published_date": "2025-01-28 12:13:07 UTC",
    "updated_date": "2025-01-28 12:13:07 UTC"
  },
  {
    "arxiv_id": "2502.00048v1",
    "title": "Contextually Entangled Gradient Mapping for Optimized LLM Comprehension",
    "authors": [
      "Colin Sisate",
      "Alistair Goldfinch",
      "Vincent Waterstone",
      "Sebastian Kingsley",
      "Mariana Blackthorn"
    ],
    "abstract": "Contextually Entangled Gradient Mapping (CEGM) introduces a new approach to\ngradient optimization, redefining the relationship between contextual\nembeddings and gradient updates to enhance semantic coherence and reasoning\ncapabilities in neural architectures. By treating gradients as dynamic carriers\nof contextual dependencies rather than isolated numerical entities, the\nproposed methodology bridges critical gaps in existing optimization strategies.\nThe integration of entangled gradient dynamics into a loss regularization\nframework demonstrated significant improvements in tasks involving long-form\nreasoning, contextual retention, and adaptability to unseen domains.\nExperimental evaluations showed that the CEGM-enhanced model consistently\noutperformed baseline approaches, achieving higher accuracy in token-level\npredictions and greater resilience to noisy inputs. Practical implementations\ninvolved modifications to training pipelines, introducing entanglement layers\nand dynamic coefficient adjustments that seamlessly align with existing\narchitectures. Results further highlighted reductions in semantic drift during\nsequential transformations and improvements in embedding coherence across\nparaphrased sentences, showing the robustness and versatility of the proposed\nmethodology. The findings demonstrate the broader implications of gradient\nentanglement for both theoretical advancements and practical applications in\noptimization strategies.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.00048v1",
    "published_date": "2025-01-28 11:50:35 UTC",
    "updated_date": "2025-01-28 11:50:35 UTC"
  },
  {
    "arxiv_id": "2502.15724v1",
    "title": "Instruction-Based Fine-tuning of Open-Source LLMs for Predicting Customer Purchase Behaviors",
    "authors": [
      "Halil Ibrahim Ergul",
      "Selim Balcisoy",
      "Burcin Bozkaya"
    ],
    "abstract": "In this study, the performance of various predictive models, including\nprobabilistic baseline, CNN, LSTM, and finetuned LLMs, in forecasting merchant\ncategories from financial transaction data have been evaluated. Utilizing\ndatasets from Bank A for training and Bank B for testing, the superior\npredictive capabilities of the fine-tuned Mistral Instruct model, which was\ntrained using customer data converted into natural language format have been\ndemonstrated. The methodology of this study involves instruction fine-tuning\nMistral via LoRA (LowRank Adaptation of Large Language Models) to adapt its\nvast pre-trained knowledge to the specific domain of financial transactions.\nThe Mistral model significantly outperforms traditional sequential models,\nachieving higher F1 scores in the three key merchant categories of bank\ntransaction data (grocery, clothing, and gas stations) that is crucial for\ntargeted marketing campaigns. This performance is attributed to the model's\nenhanced semantic understanding and adaptability which enables it to better\nmanage minority classes and predict transaction categories with greater\naccuracy. These findings highlight the potential of LLMs in predicting human\nbehavior.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15724v1",
    "published_date": "2025-01-28 11:34:22 UTC",
    "updated_date": "2025-01-28 11:34:22 UTC"
  },
  {
    "arxiv_id": "2501.16836v1",
    "title": "Misspellings in Natural Language Processing: A survey",
    "authors": [
      "Gianluca Sperduti",
      "Alejandro Moreo"
    ],
    "abstract": "This survey provides an overview of the challenges of misspellings in natural\nlanguage processing (NLP). While often unintentional, misspellings have become\nubiquitous in digital communication, especially with the proliferation of Web\n2.0, user-generated content, and informal text mediums such as social media,\nblogs, and forums. Even if humans can generally interpret misspelled text, NLP\nmodels frequently struggle to handle it: this causes a decline in performance\nin common tasks like text classification and machine translation. In this\npaper, we reconstruct a history of misspellings as a scientific problem. We\nthen discuss the latest advancements to address the challenge of misspellings\nin NLP. Main strategies to mitigate the effect of misspellings include data\naugmentation, double step, character-order agnostic, and tuple-based methods,\namong others. This survey also examines dedicated data challenges and\ncompetitions to spur progress in the field. Critical safety and ethical\nconcerns are also examined, for example, the voluntary use of misspellings to\ninject malicious messages and hate speech on social networks. Furthermore, the\nsurvey explores psycholinguistic perspectives on how humans process\nmisspellings, potentially informing innovative computational techniques for\ntext normalization and representation. Finally, the misspelling-related\nchallenges and opportunities associated with modern large language models are\nalso analyzed, including benchmarks, datasets, and performances of the most\nprominent language models against misspellings. This survey aims to be an\nexhaustive resource for researchers seeking to mitigate the impact of\nmisspellings in the rapidly evolving landscape of NLP.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.16836v1",
    "published_date": "2025-01-28 10:26:04 UTC",
    "updated_date": "2025-01-28 10:26:04 UTC"
  },
  {
    "arxiv_id": "2501.17889v1",
    "title": "Knoop: Practical Enhancement of Knockoff with Over-Parameterization for Variable Selection",
    "authors": [
      "Xiaochen Zhang",
      "Yunfeng Cai",
      "Haoyi Xiong"
    ],
    "abstract": "Variable selection plays a crucial role in enhancing modeling effectiveness\nacross diverse fields, addressing the challenges posed by high-dimensional\ndatasets of correlated variables. This work introduces a novel approach namely\nKnockoff with over-parameterization (Knoop) to enhance Knockoff filters for\nvariable selection. Specifically, Knoop first generates multiple knockoff\nvariables for each original variable and integrates them with the original\nvariables into an over-parameterized Ridgeless regression model. For each\noriginal variable, Knoop evaluates the coefficient distribution of its\nknockoffs and compares these with the original coefficients to conduct an\nanomaly-based significance test, ensuring robust variable selection. Extensive\nexperiments demonstrate superior performance compared to existing methods in\nboth simulation and real-world datasets. Knoop achieves a notably higher Area\nunder the Curve (AUC) of the Receiver Operating Characteristic (ROC) Curve for\neffectively identifying relevant variables against the ground truth by\ncontrolled simulations, while showcasing enhanced predictive accuracy across\ndiverse regression and classification tasks. The analytical results further\nbackup our observations.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "stat.ML",
    "comment": "An earlier version of our paper at Machine Learning",
    "pdf_url": "http://arxiv.org/pdf/2501.17889v1",
    "published_date": "2025-01-28 09:27:04 UTC",
    "updated_date": "2025-01-28 09:27:04 UTC"
  },
  {
    "arxiv_id": "2502.00047v4",
    "title": "HadamRNN: Binary and Sparse Ternary Orthogonal RNNs",
    "authors": [
      "Armand Foucault",
      "Franck Mamalet",
      "François Malgouyres"
    ],
    "abstract": "Binary and sparse ternary weights in neural networks enable faster\ncomputations and lighter representations, facilitating their use on edge\ndevices with limited computational power. Meanwhile, vanilla RNNs are highly\nsensitive to changes in their recurrent weights, making the binarization and\nternarization of these weights inherently challenging. To date, no method has\nsuccessfully achieved binarization or ternarization of vanilla RNN weights. We\npresent a new approach leveraging the properties of Hadamard matrices to\nparameterize a subset of binary and sparse ternary orthogonal matrices. This\nmethod enables the training of orthogonal RNNs (ORNNs) with binary and sparse\nternary recurrent weights, effectively creating a specific class of binary and\nsparse ternary vanilla RNNs. The resulting ORNNs, called HadamRNN and\nBlock-HadamRNN, are evaluated on benchmarks such as the copy task, permuted and\nsequential MNIST tasks, the IMDB dataset, two GLUE benchmarks, and two IoT\nbenchmarks. Despite binarization or sparse ternarization, these RNNs maintain\nperformance levels comparable to state-of-the-art full-precision models,\nhighlighting the effectiveness of our approach. Notably, our approach is the\nfirst solution with binary recurrent weights capable of tackling the copy task\nover 1000 timesteps.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.00047v4",
    "published_date": "2025-01-28 09:16:28 UTC",
    "updated_date": "2025-05-06 09:45:34 UTC"
  },
  {
    "arxiv_id": "2501.16800v1",
    "title": "DIRIGENt: End-To-End Robotic Imitation of Human Demonstrations Based on a Diffusion Model",
    "authors": [
      "Josua Spisak",
      "Matthias Kerzel",
      "Stefan Wermter"
    ],
    "abstract": "There has been substantial progress in humanoid robots, with new skills\ncontinuously being taught, ranging from navigation to manipulation. While these\nabilities may seem impressive, the teaching methods often remain inefficient.\nTo enhance the process of teaching robots, we propose leveraging a mechanism\neffectively used by humans: teaching by demonstrating. In this paper, we\nintroduce DIRIGENt (DIrect Robotic Imitation GENeration model), a novel\nend-to-end diffusion approach that directly generates joint values from\nobserving human demonstrations, enabling a robot to imitate these actions\nwithout any existing mapping between it and humans. We create a dataset in\nwhich humans imitate a robot and then use this collected data to train a\ndiffusion model that enables a robot to imitate humans. The following three\naspects are the core of our contribution. First is our novel dataset with\nnatural pairs between human and robot poses, allowing our approach to imitate\nhumans accurately despite the gap between their anatomies. Second, the\ndiffusion input to our model alleviates the challenge of redundant joint\nconfigurations, limiting the search space. And finally, our end-to-end\narchitecture from perception to action leads to an improved learning\ncapability. Through our experimental analysis, we show that combining these\nthree aspects allows DIRIGENt to outperform existing state-of-the-art\napproaches in the field of generating joint values from RGB images.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.16800v1",
    "published_date": "2025-01-28 09:05:03 UTC",
    "updated_date": "2025-01-28 09:05:03 UTC"
  },
  {
    "arxiv_id": "2501.16783v1",
    "title": "A Stochastic Dynamical Theory of LLM Self-Adversariality: Modeling Severity Drift as a Critical Process",
    "authors": [
      "Jack David Carson"
    ],
    "abstract": "This paper introduces a continuous-time stochastic dynamical framework for\nunderstanding how large language models (LLMs) may self-amplify latent biases\nor toxicity through their own chain-of-thought reasoning. The model posits an\ninstantaneous \"severity\" variable $x(t) \\in [0,1]$ evolving under a stochastic\ndifferential equation (SDE) with a drift term $\\mu(x)$ and diffusion\n$\\sigma(x)$. Crucially, such a process can be consistently analyzed via the\nFokker--Planck approach if each incremental step behaves nearly Markovian in\nseverity space. The analysis investigates critical phenomena, showing that\ncertain parameter regimes create phase transitions from subcritical\n(self-correcting) to supercritical (runaway severity). The paper derives\nstationary distributions, first-passage times to harmful thresholds, and\nscaling laws near critical points. Finally, it highlights implications for\nagents and extended LLM reasoning models: in principle, these equations might\nserve as a basis for formal verification of whether a model remains stable or\npropagates bias over repeated inferences.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "nlin.AO"
    ],
    "primary_category": "cs.CL",
    "comment": "Experimental verification and more formal argument for Markov\n  approximation of bias propagation to be released soon. Primarily pushed now\n  to establish novelty and ease of sharing. Please do not cite this work until\n  the forthcoming experimental validation and updated mathematical model are\n  provided",
    "pdf_url": "http://arxiv.org/pdf/2501.16783v1",
    "published_date": "2025-01-28 08:08:25 UTC",
    "updated_date": "2025-01-28 08:08:25 UTC"
  },
  {
    "arxiv_id": "2501.16778v1",
    "title": "FlexMotion: Lightweight, Physics-Aware, and Controllable Human Motion Generation",
    "authors": [
      "Arvin Tashakori",
      "Arash Tashakori",
      "Gongbo Yang",
      "Z. Jane Wang",
      "Peyman Servati"
    ],
    "abstract": "Lightweight, controllable, and physically plausible human motion synthesis is\ncrucial for animation, virtual reality, robotics, and human-computer\ninteraction applications. Existing methods often compromise between\ncomputational efficiency, physical realism, or spatial controllability. We\npropose FlexMotion, a novel framework that leverages a computationally\nlightweight diffusion model operating in the latent space, eliminating the need\nfor physics simulators and enabling fast and efficient training. FlexMotion\nemploys a multimodal pre-trained Transformer encoder-decoder, integrating joint\nlocations, contact forces, joint actuations and muscle activations to ensure\nthe physical plausibility of the generated motions. FlexMotion also introduces\na plug-and-play module, which adds spatial controllability over a range of\nmotion parameters (e.g., joint locations, joint actuations, contact forces, and\nmuscle activations). Our framework achieves realistic motion generation with\nimproved efficiency and control, setting a new benchmark for human motion\nsynthesis. We evaluate FlexMotion on extended datasets and demonstrate its\nsuperior performance in terms of realism, physical plausibility, and\ncontrollability.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.16778v1",
    "published_date": "2025-01-28 08:02:21 UTC",
    "updated_date": "2025-01-28 08:02:21 UTC"
  },
  {
    "arxiv_id": "2501.17888v3",
    "title": "RadioLLM: Introducing Large Language Model into Cognitive Radio via Hybrid Prompt and Token Reprogrammings",
    "authors": [
      "Shuai Chen",
      "Yong Zu",
      "Zhixi Feng",
      "Shuyuan Yang",
      "Mengchang Li"
    ],
    "abstract": "The growing scarcity of spectrum resources and rapid proliferation of\nwireless devices make efficient radio network management critical. While deep\nlearning-enhanced Cognitive Radio Technology (CRT) provides promising solutions\nfor tasks such as radio signal classification (RSC), denoising, and spectrum\nallocation, existing DL-based CRT frameworks are typically task-specific and\nlack scalability in diverse real-world applications. This limitation naturally\nleads to the exploration of Large Language Models (LLMs), whose exceptional\ncross-domain generalization capabilities offer new potential for advancing CRT.\nTo bridge this gap, we propose RadioLLM, a novel framework that integrates\nHybrid Prompt and Token Reprogramming (HPTR) for combining radio signal\nfeatures with expert knowledge, and a Frequency-Attuned Fusion (FAF) module for\nenhanced high-frequency feature modeling. Extensive evaluations on multiple\nbenchmark datasets demonstrate that RadioLLM achieves superior performance\ncompared to existing baselines in the majority of testing scenarios.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "This work has been submitted to the IEEE JSAC for possible\n  publication",
    "pdf_url": "http://arxiv.org/pdf/2501.17888v3",
    "published_date": "2025-01-28 07:38:04 UTC",
    "updated_date": "2025-05-13 01:17:48 UTC"
  },
  {
    "arxiv_id": "2501.17207v1",
    "title": "Rethinking Functional Brain Connectome Analysis: Do Graph Deep Learning Models Help?",
    "authors": [
      "Keqi Han",
      "Yao Su",
      "Lifang He",
      "Liang Zhan",
      "Sergey Plis",
      "Vince Calhoun",
      "Carl Yang"
    ],
    "abstract": "Functional brain connectome is crucial for deciphering the neural mechanisms\nunderlying cognitive functions and neurological disorders. Graph deep learning\nmodels have recently gained tremendous popularity in this field. However, their\nactual effectiveness in modeling the brain connectome remains unclear. In this\nstudy, we re-examine graph deep learning models based on four large-scale\nneuroimaging studies encompassing diverse cognitive and clinical outcomes.\nSurprisingly, we find that the message aggregation mechanism, a hallmark of\ngraph deep learning models, does not help with predictive performance as\ntypically assumed, but rather consistently degrades it. To address this issue,\nwe propose a hybrid model combining a linear model with a graph attention\nnetwork through dual pathways, achieving robust predictions and enhanced\ninterpretability by revealing both localized and global neural connectivity\npatterns. Our findings urge caution in adopting complex deep learning models\nfor functional brain connectome analysis, emphasizing the need for rigorous\nexperimental designs to establish tangible performance gains and perhaps more\nimportantly, to pursue improvements in model interpretability.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG",
      "q-bio.NC"
    ],
    "primary_category": "cs.NE",
    "comment": "22 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.17207v1",
    "published_date": "2025-01-28 07:24:16 UTC",
    "updated_date": "2025-01-28 07:24:16 UTC"
  },
  {
    "arxiv_id": "2501.16753v1",
    "title": "Overcoming Semantic Dilution in Transformer-Based Next Frame Prediction",
    "authors": [
      "Hy Nguyen",
      "Srikanth Thudumu",
      "Hung Du",
      "Rajesh Vasa",
      "Kon Mouzakis"
    ],
    "abstract": "Next-frame prediction in videos is crucial for applications such as\nautonomous driving, object tracking, and motion prediction. The primary\nchallenge in next-frame prediction lies in effectively capturing and processing\nboth spatial and temporal information from previous video sequences. The\ntransformer architecture, known for its prowess in handling sequence data, has\nmade remarkable progress in this domain. However, transformer-based next-frame\nprediction models face notable issues: (a) The multi-head self-attention (MHSA)\nmechanism requires the input embedding to be split into $N$ chunks, where $N$\nis the number of heads. Each segment captures only a fraction of the original\nembeddings information, which distorts the representation of the embedding in\nthe latent space, resulting in a semantic dilution problem; (b) These models\npredict the embeddings of the next frames rather than the frames themselves,\nbut the loss function based on the errors of the reconstructed frames, not the\npredicted embeddings -- this creates a discrepancy between the training\nobjective and the model output. We propose a Semantic Concentration Multi-Head\nSelf-Attention (SCMHSA) architecture, which effectively mitigates semantic\ndilution in transformer-based next-frame prediction. Additionally, we introduce\na loss function that optimizes SCMHSA in the latent space, aligning the\ntraining objective more closely with the model output. Our method demonstrates\nsuperior performance compared to the original transformer-based predictors.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.16753v1",
    "published_date": "2025-01-28 07:12:29 UTC",
    "updated_date": "2025-01-28 07:12:29 UTC"
  },
  {
    "arxiv_id": "2502.20403v1",
    "title": "Adversarial Robustness of Partitioned Quantum Classifiers",
    "authors": [
      "Pouya Kananian",
      "Hans-Arno Jacobsen"
    ],
    "abstract": "Adversarial robustness in quantum classifiers is a critical area of study,\nproviding insights into their performance compared to classical models and\nuncovering potential advantages inherent to quantum machine learning. In the\nNISQ era of quantum computing, circuit cutting is a notable technique for\nsimulating circuits that exceed the qubit limitations of current devices,\nenabling the distribution of a quantum circuit's execution across multiple\nquantum processing units through classical communication. We examine how\npartitioning quantum classifiers through circuit cutting increase their\nsusceptibility to adversarial attacks, establishing a link between attacking\nthe state preparation channels in wire cutting and implementing adversarial\ngates within intermediate layers of a quantum classifier. We then proceed to\nstudy the latter problem from both a theoretical and experimental perspective.",
    "categories": [
      "cs.ET",
      "cs.AI",
      "cs.CR",
      "cs.LG",
      "quant-ph"
    ],
    "primary_category": "cs.ET",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.20403v1",
    "published_date": "2025-01-28 07:10:40 UTC",
    "updated_date": "2025-01-28 07:10:40 UTC"
  },
  {
    "arxiv_id": "2501.16751v3",
    "title": "HiBug2: Efficient and Interpretable Error Slice Discovery for Comprehensive Model Debugging",
    "authors": [
      "Muxi Chen",
      "Chenchen Zhao",
      "Qiang Xu"
    ],
    "abstract": "Despite the significant success of deep learning models in computer vision,\nthey often exhibit systematic failures on specific data subsets, known as error\nslices. Identifying and mitigating these error slices is crucial to enhancing\nmodel robustness and reliability in real-world scenarios. In this paper, we\nintroduce HiBug2, an automated framework for error slice discovery and model\nrepair. HiBug2 first generates task-specific visual attributes to highlight\ninstances prone to errors through an interpretable and structured process. It\nthen employs an efficient slice enumeration algorithm to systematically\nidentify error slices, overcoming the combinatorial challenges that arise\nduring slice exploration. Additionally, HiBug2 extends its capabilities by\npredicting error slices beyond the validation set, addressing a key limitation\nof prior approaches. Extensive experiments across multiple domains, including\nimage classification, pose estimation, and object detection - show that HiBug2\nnot only improves the coherence and precision of identified error slices but\nalso significantly enhances the model repair capabilities.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.16751v3",
    "published_date": "2025-01-28 07:08:20 UTC",
    "updated_date": "2025-03-03 09:07:59 UTC"
  },
  {
    "arxiv_id": "2501.16744v1",
    "title": "LLM Assisted Anomaly Detection Service for Site Reliability Engineers: Enhancing Cloud Infrastructure Resilience",
    "authors": [
      "Nimesh Jha",
      "Shuxin Lin",
      "Srideepika Jayaraman",
      "Kyle Frohling",
      "Christodoulos Constantinides",
      "Dhaval Patel"
    ],
    "abstract": "This paper introduces a scalable Anomaly Detection Service with a\ngeneralizable API tailored for industrial time-series data, designed to assist\nSite Reliability Engineers (SREs) in managing cloud infrastructure. The service\nenables efficient anomaly detection in complex data streams, supporting\nproactive identification and resolution of issues. Furthermore, it presents an\ninnovative approach to anomaly modeling in cloud infrastructure by utilizing\nLarge Language Models (LLMs) to understand key components, their failure modes,\nand behaviors. A suite of algorithms for detecting anomalies is offered in\nunivariate and multivariate time series data, including regression-based,\nmixture-model-based, and semi-supervised approaches. We provide insights into\nthe usage patterns of the service, with over 500 users and 200,000 API calls in\na year. The service has been successfully applied in various industrial\nsettings, including IoT-based AI applications. We have also evaluated our\nsystem on public anomaly benchmarks to show its effectiveness. By leveraging\nit, SREs can proactively identify potential issues before they escalate,\nreducing downtime and improving response times to incidents, ultimately\nenhancing the overall customer experience. We plan to extend the system to\ninclude time series foundation models, enabling zero-shot anomaly detection\ncapabilities.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at the AAAI-2025 Deployable AI Workshop",
    "pdf_url": "http://arxiv.org/pdf/2501.16744v1",
    "published_date": "2025-01-28 06:41:37 UTC",
    "updated_date": "2025-01-28 06:41:37 UTC"
  },
  {
    "arxiv_id": "2501.17206v1",
    "title": "Integrating Reinforcement Learning and AI Agents for Adaptive Robotic Interaction and Assistance in Dementia Care",
    "authors": [
      "Fengpei Yuan",
      "Nehal Hasnaeen",
      "Ran Zhang",
      "Bryce Bible",
      "Joseph Riley Taylor",
      "Hairong Qi",
      "Fenghui Yao",
      "Xiaopeng Zhao"
    ],
    "abstract": "This study explores a novel approach to advancing dementia care by\nintegrating socially assistive robotics, reinforcement learning (RL), large\nlanguage models (LLMs), and clinical domain expertise within a simulated\nenvironment. This integration addresses the critical challenge of limited\nexperimental data in socially assistive robotics for dementia care, providing a\ndynamic simulation environment that realistically models interactions between\npersons living with dementia (PLWDs) and robotic caregivers. The proposed\nframework introduces a probabilistic model to represent the cognitive and\nemotional states of PLWDs, combined with an LLM-based behavior simulation to\nemulate their responses. We further develop and train an adaptive RL system\nenabling humanoid robots, such as Pepper, to deliver context-aware and\npersonalized interactions and assistance based on PLWDs' cognitive and\nemotional states. The framework also generalizes to computer-based agents,\nhighlighting its versatility. Results demonstrate that the RL system, enhanced\nby LLMs, effectively interprets and responds to the complex needs of PLWDs,\nproviding tailored caregiving strategies. This research contributes to\nhuman-computer and human-robot interaction by offering a customizable AI-driven\ncaregiving platform, advancing understanding of dementia-related challenges,\nand fostering collaborative innovation in assistive technologies. The proposed\napproach has the potential to enhance the independence and quality of life for\nPLWDs while alleviating caregiver burden, underscoring the transformative role\nof interaction-focused AI systems in dementia care.",
    "categories": [
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "18 pages, 12 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.17206v1",
    "published_date": "2025-01-28 06:38:24 UTC",
    "updated_date": "2025-01-28 06:38:24 UTC"
  },
  {
    "arxiv_id": "2501.16740v1",
    "title": "Efficient Knowledge Distillation of SAM for Medical Image Segmentation",
    "authors": [
      "Kunal Dasharath Patil",
      "Gowthamaan Palani",
      "Ganapathy Krishnamurthi"
    ],
    "abstract": "The Segment Anything Model (SAM) has set a new standard in interactive image\nsegmentation, offering robust performance across various tasks. However, its\nsignificant computational requirements limit its deployment in real-time or\nresource-constrained environments. To address these challenges, we propose a\nnovel knowledge distillation approach, KD SAM, which incorporates both encoder\nand decoder optimization through a combination of Mean Squared Error (MSE) and\nPerceptual Loss. This dual-loss framework captures structural and semantic\nfeatures, enabling the student model to maintain high segmentation accuracy\nwhile reducing computational complexity. Based on the model evaluation on\ndatasets, including Kvasir-SEG, ISIC 2017, Fetal Head Ultrasound, and Breast\nUltrasound, we demonstrate that KD SAM achieves comparable or superior\nperformance to the baseline models, with significantly fewer parameters. KD SAM\neffectively balances segmentation accuracy and computational efficiency, making\nit well-suited for real-time medical image segmentation applications in\nresource-constrained environments.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "5 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.16740v1",
    "published_date": "2025-01-28 06:33:30 UTC",
    "updated_date": "2025-01-28 06:33:30 UTC"
  },
  {
    "arxiv_id": "2501.16734v2",
    "title": "Distilling Large Language Models for Network Active Queue Management",
    "authors": [
      "Deol Satish",
      "Shiva Raj Pokhrel",
      "Jonathan Kua",
      "Anwar Walid"
    ],
    "abstract": "The growing complexity of network traffic and demand for ultra-low latency\ncommunication require smarter packet traffic management. Existing Deep\nLearning-based queuing approaches struggle with dynamic network scenarios and\ndemand high engineering effort. We propose AQM-LLM, distilling Large Language\nModels (LLMs) with few-shot learning, contextual understanding, and pattern\nrecognition to improve Active Queue Management (AQM) [RFC 9330] with minimal\nmanual effort. We consider a specific case where AQM is Low Latency, Low Loss,\nand Scalable Throughput (L4S) and our design of AQM-LLM builds on speculative\ndecoding and reinforcement-based distilling of LLM by tackling congestion\nprevention in the L4S architecture using Explicit Congestion Notification (ECN)\n[RFC 9331] and periodic packet dropping. We develop a new open-source\nexperimental platform by executing L4S-AQM on FreeBSD-14, providing\ninteroperable modules to support LLM integration and facilitate IETF\nrecognition through wider testing. Our extensive evaluations show L4S-LLM\nenhances queue management, prevents congestion, reduces latency, and boosts\nnetwork performance, showcasing LLMs' adaptability and efficiency in uplifting\nAQM systems.",
    "categories": [
      "cs.NI",
      "cs.AI"
    ],
    "primary_category": "cs.NI",
    "comment": "After a careful review, we identified some issues that need to be\n  addressed. We temporarily withdraw the paper while we update our experimental\n  results, ensuring that our demonstration and findings meet the highest\n  standards of accuracy and clarity",
    "pdf_url": "http://arxiv.org/pdf/2501.16734v2",
    "published_date": "2025-01-28 06:19:29 UTC",
    "updated_date": "2025-03-04 21:15:56 UTC"
  },
  {
    "arxiv_id": "2501.16729v2",
    "title": "On the Interplay Between Sparsity and Training in Deep Reinforcement Learning",
    "authors": [
      "Fatima Davelouis",
      "John D. Martin",
      "Michael Bowling"
    ],
    "abstract": "We study the benefits of different sparse architectures for deep\nreinforcement learning. In particular, we focus on image-based domains where\nspatially-biased and fully-connected architectures are common. Using these and\nseveral other architectures of equal capacity, we show that sparse structure\nhas a significant effect on learning performance. We also observe that choosing\nthe best sparse architecture for a given domain depends on whether the hidden\nlayer weights are fixed or learned.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.16729v2",
    "published_date": "2025-01-28 06:13:35 UTC",
    "updated_date": "2025-02-01 06:43:04 UTC"
  },
  {
    "arxiv_id": "2501.16726v1",
    "title": "Bridging Neural Networks and Wireless Systems with MIMO-OFDM Semantic Communications",
    "authors": [
      "Hanju Yoo",
      "Dongha Choi",
      "Yonghwi Kim",
      "Yoontae Kim",
      "Songkuk Kim",
      "Chan-Byoung Chae",
      "Robert W. Heath Jr"
    ],
    "abstract": "Semantic communications aim to enhance transmission efficiency by jointly\noptimizing source coding, channel coding, and modulation. While prior research\nhas demonstrated promising performance in simulations, real-world\nimplementations often face significant challenges, including noise variability\nand nonlinear distortions, leading to performance gaps. This article\ninvestigates these challenges in a multiple-input multiple-output (MIMO) and\northogonal frequency division multiplexing (OFDM)-based semantic communication\nsystem, focusing on the practical impacts of power amplifier (PA) nonlinearity\nand peak-to-average power ratio (PAPR) variations. Our analysis identifies\nfrequency selectivity of the actual channel as a critical factor in performance\ndegradation and demonstrates that targeted mitigation strategies can enable\nsemantic systems to approach theoretical performance. By addressing key\nlimitations in existing designs, we provide actionable insights for advancing\nsemantic communications in practical wireless environments. This work\nestablishes a foundation for bridging the gap between theoretical models and\nreal-world deployment, highlighting essential considerations for system design\nand optimization.",
    "categories": [
      "cs.IT",
      "cs.AI",
      "cs.NI",
      "math.IT"
    ],
    "primary_category": "cs.IT",
    "comment": "7 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.16726v1",
    "published_date": "2025-01-28 06:07:39 UTC",
    "updated_date": "2025-01-28 06:07:39 UTC"
  },
  {
    "arxiv_id": "2502.15723v3",
    "title": "Balancing Content Size in RAG-Text2SQL System",
    "authors": [
      "Prakhar Gurawa",
      "Anjali Dharmik"
    ],
    "abstract": "Large Language Models (LLMs) have emerged as a promising solution for\nconverting natural language queries into SQL commands, enabling seamless\ndatabase interaction. However, these Text-to-SQL (Text2SQL) systems face\ninherent limitations, hallucinations, outdated knowledge, and untraceable\nreasoning. To address these challenges, the integration of retrieval-augmented\ngeneration (RAG) with Text2SQL models has gained traction. RAG serves as a\nretrieval mechanism, providing essential contextual information, such as table\nschemas and metadata, to enhance the query generation process. Despite their\npotential, RAG + Text2SQL systems are susceptible to the quality and size of\nretrieved documents. While richer document content can improve schema relevance\nand retrieval accuracy, it also introduces noise, increasing the risk of\nhallucinations and reducing query fidelity as the prompt size of the Text2SQL\nmodel increases. This research investigates the nuanced trade-off between\ndocument size and quality, aiming to strike a balance that optimizes system\nperformance. Key thresholds are identified where performance degradation\noccurs, along with actionable strategies to mitigate these challenges.\nAdditionally, we explore the phenomenon of hallucinations in Text2SQL models,\nemphasizing the critical role of curated document presentation in minimizing\nerrors. Our findings provide a roadmap for enhancing the robustness of RAG +\nText2SQL systems, offering practical insights for real-world applications.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.DB"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15723v3",
    "published_date": "2025-01-28 06:06:28 UTC",
    "updated_date": "2025-03-23 18:27:29 UTC"
  },
  {
    "arxiv_id": "2501.16722v1",
    "title": "Hypergraph Diffusion for High-Order Recommender Systems",
    "authors": [
      "Darnbi Sakong",
      "Thanh Trung Huynh",
      "Jun Jo"
    ],
    "abstract": "Recommender systems rely on Collaborative Filtering (CF) to predict user\npreferences by leveraging patterns in historical user-item interactions. While\ntraditional CF methods primarily focus on learning compact vector embeddings\nfor users and items, graph neural network (GNN)-based approaches have emerged\nas a powerful alternative, utilizing the structure of user-item interaction\ngraphs to enhance recommendation accuracy. However, existing GNN-based models,\nsuch as LightGCN and UltraGCN, often struggle with two major limitations: an\ninability to fully account for heterophilic interactions, where users engage\nwith diverse item categories, and the over-smoothing problem in multi-layer\nGNNs, which hinders their ability to model complex, high-order relationships.\nTo address these gaps, we introduce WaveHDNN, an innovative wavelet-enhanced\nhypergraph diffusion framework. WaveHDNN integrates a Heterophily-aware\nCollaborative Encoder, designed to capture user-item interactions across\ndiverse categories, with a Multi-scale Group-wise Structure Encoder, which\nleverages wavelet transforms to effectively model localized graph structures.\nAdditionally, cross-view contrastive learning is employed to maintain robust\nand consistent representations. Experiments on benchmark datasets validate the\nefficacy of WaveHDNN, demonstrating its superior ability to capture both\nheterophilic and localized structural information, leading to improved\nrecommendation performance.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.DB",
      "cs.LG",
      "cs.SI"
    ],
    "primary_category": "cs.IR",
    "comment": "Technical Report",
    "pdf_url": "http://arxiv.org/pdf/2501.16722v1",
    "published_date": "2025-01-28 05:59:29 UTC",
    "updated_date": "2025-01-28 05:59:29 UTC"
  },
  {
    "arxiv_id": "2501.16720v1",
    "title": "One Head Eight Arms: Block Matrix based Low Rank Adaptation for CLIP-based Few-Shot Learning",
    "authors": [
      "Chunpeng Zhou",
      "Qianqian Shen",
      "Zhi Yu",
      "Jiajun Bu",
      "Haishuai Wang"
    ],
    "abstract": "Recent advancements in fine-tuning Vision-Language Foundation Models (VLMs)\nhave garnered significant attention for their effectiveness in downstream\nfew-shot learning tasks.While these recent approaches exhibits some performance\nimprovements, they often suffer from excessive training parameters and high\ncomputational costs. To address these challenges, we propose a novel Block\nmatrix-based low-rank adaptation framework, called Block-LoRA, for fine-tuning\nVLMs on downstream few-shot tasks. Inspired by recent work on Low-Rank\nAdaptation (LoRA), Block-LoRA partitions the original low-rank decomposition\nmatrix of LoRA into a series of sub-matrices while sharing all down-projection\nsub-matrices. This structure not only reduces the number of training\nparameters, but also transforms certain complex matrix multiplication\noperations into simpler matrix addition, significantly lowering the\ncomputational cost of fine-tuning. Notably, Block-LoRA enables fine-tuning CLIP\non the ImageNet few-shot benchmark using a single 24GB GPU. We also show that\nBlock-LoRA has the more tighter bound of generalization error than vanilla\nLoRA. Without bells and whistles, extensive experiments demonstrate that\nBlock-LoRA achieves competitive performance compared to state-of-the-art\nCLIP-based few-shot methods, while maintaining a low training parameters count\nand reduced computational overhead.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Under Review",
    "pdf_url": "http://arxiv.org/pdf/2501.16720v1",
    "published_date": "2025-01-28 05:54:55 UTC",
    "updated_date": "2025-01-28 05:54:55 UTC"
  },
  {
    "arxiv_id": "2501.16714v1",
    "title": "Separate Motion from Appearance: Customizing Motion via Customizing Text-to-Video Diffusion Models",
    "authors": [
      "Huijie Liu",
      "Jingyun Wang",
      "Shuai Ma",
      "Jie Hu",
      "Xiaoming Wei",
      "Guoliang Kang"
    ],
    "abstract": "Motion customization aims to adapt the diffusion model (DM) to generate\nvideos with the motion specified by a set of video clips with the same motion\nconcept. To realize this goal, the adaptation of DM should be possible to model\nthe specified motion concept, without compromising the ability to generate\ndiverse appearances. Thus, the key to solving this problem lies in how to\nseparate the motion concept from the appearance in the adaptation process of\nDM. Typical previous works explore different ways to represent and insert a\nmotion concept into large-scale pretrained text-to-video diffusion models,\ne.g., learning a motion LoRA, using latent noise residuals, etc. While those\nmethods can encode the motion concept, they also inevitably encode the\nappearance in the reference videos, resulting in weakened appearance generation\ncapability. In this paper, we follow the typical way to learn a motion LoRA to\nencode the motion concept, but propose two novel strategies to enhance\nmotion-appearance separation, including temporal attention purification (TAP)\nand appearance highway (AH). Specifically, we assume that in the temporal\nattention module, the pretrained Value embeddings are sufficient to serve as\nbasic components needed by producing a new motion. Thus, in TAP, we choose only\nto reshape the temporal attention with motion LoRAs so that Value embeddings\ncan be reorganized to produce a new motion. Further, in AH, we alter the\nstarting point of each skip connection in U-Net from the output of each\ntemporal attention module to the output of each spatial attention module.\nExtensive experiments demonstrate that compared to previous works, our method\ncan generate videos with appearance more aligned with the text descriptions and\nmotion more consistent with the reference videos.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "8 pages,6 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.16714v1",
    "published_date": "2025-01-28 05:40:20 UTC",
    "updated_date": "2025-01-28 05:40:20 UTC"
  },
  {
    "arxiv_id": "2501.16700v1",
    "title": "Determining Mosaic Resilience in Sugarcane Plants using Hyperspectral Images",
    "authors": [
      "Ali Zia",
      "Jun Zhou",
      "Muyiwa Olayemi"
    ],
    "abstract": "Sugarcane mosaic disease poses a serious threat to the Australian sugarcane\nindustry, leading to yield losses of up to 30% in susceptible varieties.\nExisting manual inspection methods for detecting mosaic resilience are\ninefficient and impractical for large-scale application. This study introduces\na novel approach using hyperspectral imaging and machine learning to detect\nmosaic resilience by leveraging global feature representation from local\nspectral patches. Hyperspectral data were collected from eight sugarcane\nvarieties under controlled and field conditions. Local spectral patches were\nanalyzed to capture spatial and spectral variations, which were then aggregated\ninto global feature representations using a ResNet18 deep learning\narchitecture. While classical methods like Support Vector Machines struggled to\nutilize spatial-spectral relationships effectively, the deep learning model\nachieved high classification accuracy, demonstrating its capacity to identify\nmosaic resilience from fine-grained hyperspectral data. This approach enhances\nearly detection capabilities, enabling more efficient management of susceptible\nstrains and contributing to sustainable sugarcane production.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.16700v1",
    "published_date": "2025-01-28 04:33:28 UTC",
    "updated_date": "2025-01-28 04:33:28 UTC"
  },
  {
    "arxiv_id": "2501.16692v2",
    "title": "Optimizing Code Runtime Performance through Context-Aware Retrieval-Augmented Generation",
    "authors": [
      "Manish Acharya",
      "Yifan Zhang",
      "Kevin Leach",
      "Yu Huang"
    ],
    "abstract": "Optimizing software performance through automated code refinement offers a\npromising avenue for enhancing execution speed and efficiency. Despite recent\nadvancements in LLMs, a significant gap remains in their ability to perform\nin-depth program analysis. This study introduces AUTOPATCH, an in-context\nlearning approach designed to bridge this gap by enabling LLMs to automatically\ngenerate optimized code. Inspired by how programmers learn and apply knowledge\nto optimize software, AUTOPATCH incorporates three key components: (1) an\nanalogy-driven framework to align LLM optimization with human cognitive\nprocesses, (2) a unified approach that integrates historical code examples and\nCFG analysis for context-aware learning, and (3) an automated pipeline for\ngenerating optimized code through in-context prompting. Experimental results\ndemonstrate that AUTOPATCH achieves a 7.3% improvement in execution efficiency\nover GPT-4o across common generated executable code, highlighting its potential\nto advance automated program runtime optimization.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.16692v2",
    "published_date": "2025-01-28 04:00:35 UTC",
    "updated_date": "2025-01-29 04:36:03 UTC"
  },
  {
    "arxiv_id": "2501.16689v2",
    "title": "MACI: Multi-Agent Collaborative Intelligence for Adaptive Reasoning and Temporal Planning",
    "authors": [
      "Edward Y. Chang"
    ],
    "abstract": "Artificial intelligence requires deliberate reasoning, temporal awareness,\nand effective constraint management, capabilities traditional LLMs often lack\ndue to their reliance on pattern matching, limited self-verification, and\ninconsistent constraint handling. We introduce Multi-Agent Collaborative\nIntelligence (MACI), a framework comprising three key components: 1) a\nmeta-planner (MP) that identifies, formulates, and refines all roles and\nconstraints of a task (e.g., wedding planning) while generating a dependency\ngraph, with common-sense augmentation to ensure realistic and practical\nconstraints; 2) a collection of agents to facilitate planning and address\ntask-specific requirements; and 3) a run-time monitor that manages plan\nadjustments as needed. By decoupling planning from validation, maintaining\nminimal agent context, and integrating common-sense reasoning, MACI overcomes\nthe aforementioned limitations and demonstrates robust performance in two\nscheduling problems.",
    "categories": [
      "cs.AI",
      "F.2.2"
    ],
    "primary_category": "cs.AI",
    "comment": "21 pages, 19 tables",
    "pdf_url": "http://arxiv.org/pdf/2501.16689v2",
    "published_date": "2025-01-28 03:57:22 UTC",
    "updated_date": "2025-01-29 07:23:47 UTC"
  },
  {
    "arxiv_id": "2501.16677v1",
    "title": "Improving Interpretability and Accuracy in Neuro-Symbolic Rule Extraction Using Class-Specific Sparse Filters",
    "authors": [
      "Parth Padalkar",
      "Jaeseong Lee",
      "Shiyi Wei",
      "Gopal Gupta"
    ],
    "abstract": "There has been significant focus on creating neuro-symbolic models for\ninterpretable image classification using Convolutional Neural Networks (CNNs).\nThese methods aim to replace the CNN with a neuro-symbolic model consisting of\nthe CNN, which is used as a feature extractor, and an interpretable rule-set\nextracted from the CNN itself. While these approaches provide interpretability\nthrough the extracted rule-set, they often compromise accuracy compared to the\noriginal CNN model. In this paper, we identify the root cause of this accuracy\nloss as the post-training binarization of filter activations to extract the\nrule-set. To address this, we propose a novel sparsity loss function that\nenables class-specific filter binarization during CNN training, thus minimizing\ninformation loss when extracting the rule-set. We evaluate several training\nstrategies with our novel sparsity loss, analyzing their effectiveness and\nproviding guidance on their appropriate use. Notably, we set a new benchmark,\nachieving a 9% improvement in accuracy and a 53% reduction in rule-set size on\naverage, compared to the previous SOTA, while coming within 3% of the original\nCNN's accuracy. This highlights the significant potential of interpretable\nneuro-symbolic models as viable alternatives to black-box CNNs.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.16677v1",
    "published_date": "2025-01-28 03:22:23 UTC",
    "updated_date": "2025-01-28 03:22:23 UTC"
  },
  {
    "arxiv_id": "2501.16672v1",
    "title": "VeriFact: Verifying Facts in LLM-Generated Clinical Text with Electronic Health Records",
    "authors": [
      "Philip Chung",
      "Akshay Swaminathan",
      "Alex J. Goodell",
      "Yeasul Kim",
      "S. Momsen Reincke",
      "Lichy Han",
      "Ben Deverett",
      "Mohammad Amin Sadeghi",
      "Abdel-Badih Ariss",
      "Marc Ghanem",
      "David Seong",
      "Andrew A. Lee",
      "Caitlin E. Coombes",
      "Brad Bradshaw",
      "Mahir A. Sufian",
      "Hyo Jung Hong",
      "Teresa P. Nguyen",
      "Mohammad R. Rasouli",
      "Komal Kamra",
      "Mark A. Burbridge",
      "James C. McAvoy",
      "Roya Saffary",
      "Stephen P. Ma",
      "Dev Dash",
      "James Xie",
      "Ellen Y. Wang",
      "Clifford A. Schmiesing",
      "Nigam Shah",
      "Nima Aghaeepour"
    ],
    "abstract": "Methods to ensure factual accuracy of text generated by large language models\n(LLM) in clinical medicine are lacking. VeriFact is an artificial intelligence\nsystem that combines retrieval-augmented generation and LLM-as-a-Judge to\nverify whether LLM-generated text is factually supported by a patient's medical\nhistory based on their electronic health record (EHR). To evaluate this system,\nwe introduce VeriFact-BHC, a new dataset that decomposes Brief Hospital Course\nnarratives from discharge summaries into a set of simple statements with\nclinician annotations for whether each statement is supported by the patient's\nEHR clinical notes. Whereas highest agreement between clinicians was 88.5%,\nVeriFact achieves up to 92.7% agreement when compared to a denoised and\nadjudicated average human clinican ground truth, suggesting that VeriFact\nexceeds the average clinician's ability to fact-check text against a patient's\nmedical record. VeriFact may accelerate the development of LLM-based EHR\napplications by removing current evaluation bottlenecks.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.IR",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "62 pages, 5 figures, 1 table, pre-print manuscript",
    "pdf_url": "http://arxiv.org/pdf/2501.16672v1",
    "published_date": "2025-01-28 03:13:16 UTC",
    "updated_date": "2025-01-28 03:13:16 UTC"
  },
  {
    "arxiv_id": "2501.16671v1",
    "title": "Data-Free Model-Related Attacks: Unleashing the Potential of Generative AI",
    "authors": [
      "Dayong Ye",
      "Tianqing Zhu",
      "Shang Wang",
      "Bo Liu",
      "Leo Yu Zhang",
      "Wanlei Zhou",
      "Yang Zhang"
    ],
    "abstract": "Generative AI technology has become increasingly integrated into our daily\nlives, offering powerful capabilities to enhance productivity. However, these\nsame capabilities can be exploited by adversaries for malicious purposes. While\nexisting research on adversarial applications of generative AI predominantly\nfocuses on cyberattacks, less attention has been given to attacks targeting\ndeep learning models. In this paper, we introduce the use of generative AI for\nfacilitating model-related attacks, including model extraction, membership\ninference, and model inversion. Our study reveals that adversaries can launch a\nvariety of model-related attacks against both image and text models in a\ndata-free and black-box manner, achieving comparable performance to baseline\nmethods that have access to the target models' training data and parameters in\na white-box manner. This research serves as an important early warning to the\ncommunity about the potential risks associated with generative AI-powered\nattacks on deep learning models.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "Accepted at USENIX Security 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.16671v1",
    "published_date": "2025-01-28 03:12:57 UTC",
    "updated_date": "2025-01-28 03:12:57 UTC"
  },
  {
    "arxiv_id": "2501.16666v1",
    "title": "Federated Learning for Efficient Condition Monitoring and Anomaly Detection in Industrial Cyber-Physical Systems",
    "authors": [
      "William Marfo",
      "Deepak K. Tosh",
      "Shirley V. Moore"
    ],
    "abstract": "Detecting and localizing anomalies in cyber-physical systems (CPS) has become\nincreasingly challenging as systems grow in complexity, particularly due to\nvarying sensor reliability and node failures in distributed environments. While\nfederated learning (FL) provides a foundation for distributed model training,\nexisting approaches often lack mechanisms to address these CPS-specific\nchallenges. This paper introduces an enhanced FL framework with three key\ninnovations: adaptive model aggregation based on sensor reliability, dynamic\nnode selection for resource optimization, and Weibull-based checkpointing for\nfault tolerance. The proposed framework ensures reliable condition monitoring\nwhile tackling the computational and reliability challenges of industrial CPS\ndeployments. Experiments on the NASA Bearing and Hydraulic System datasets\ndemonstrate superior performance compared to state-of-the-art FL methods,\nachieving 99.5% AUC-ROC in anomaly detection and maintaining accuracy even\nunder node failures. Statistical validation using the Mann-Whitney U test\nconfirms significant improvements, with a p-value less than 0.05, in both\ndetection accuracy and computational efficiency across various operational\nscenarios.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.16666v1",
    "published_date": "2025-01-28 03:04:47 UTC",
    "updated_date": "2025-01-28 03:04:47 UTC"
  },
  {
    "arxiv_id": "2501.16663v2",
    "title": "Data Duplication: A Novel Multi-Purpose Attack Paradigm in Machine Unlearning",
    "authors": [
      "Dayong Ye",
      "Tianqing Zhu",
      "Jiayang Li",
      "Kun Gao",
      "Bo Liu",
      "Leo Yu Zhang",
      "Wanlei Zhou",
      "Yang Zhang"
    ],
    "abstract": "Duplication is a prevalent issue within datasets. Existing research has\ndemonstrated that the presence of duplicated data in training datasets can\nsignificantly influence both model performance and data privacy. However, the\nimpact of data duplication on the unlearning process remains largely\nunexplored. This paper addresses this gap by pioneering a comprehensive\ninvestigation into the role of data duplication, not only in standard machine\nunlearning but also in federated and reinforcement unlearning paradigms.\nSpecifically, we propose an adversary who duplicates a subset of the target\nmodel's training set and incorporates it into the training set. After training,\nthe adversary requests the model owner to unlearn this duplicated subset, and\nanalyzes the impact on the unlearned model. For example, the adversary can\nchallenge the model owner by revealing that, despite efforts to unlearn it, the\ninfluence of the duplicated subset remains in the model. Moreover, to\ncircumvent detection by de-duplication techniques, we propose three novel\nnear-duplication methods for the adversary, each tailored to a specific\nunlearning paradigm. We then examine their impacts on the unlearning process\nwhen de-duplication techniques are applied. Our findings reveal several crucial\ninsights: 1) the gold standard unlearning method, retraining from scratch,\nfails to effectively conduct unlearning under certain conditions; 2) unlearning\nduplicated data can lead to significant model degradation in specific\nscenarios; and 3) meticulously crafted duplicates can evade detection by\nde-duplication methods.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "Accepted at USENIX Security 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.16663v2",
    "published_date": "2025-01-28 02:52:51 UTC",
    "updated_date": "2025-03-11 04:54:03 UTC"
  },
  {
    "arxiv_id": "2501.16662v2",
    "title": "Vision-based autonomous structural damage detection using data-driven methods",
    "authors": [
      "Seyyed Taghi Ataei",
      "Parviz Mohammad Zadeh",
      "Saeid Ataei"
    ],
    "abstract": "This study addresses the urgent need for efficient and accurate damage\ndetection in wind turbine structures, a crucial component of renewable energy\ninfrastructure. Traditional inspection methods, such as manual assessments and\nnon-destructive testing (NDT), are often costly, time-consuming, and prone to\nhuman error. To tackle these challenges, this research investigates advanced\ndeep learning algorithms for vision-based structural health monitoring (SHM). A\ndataset of wind turbine surface images, featuring various damage types and\npollution, was prepared and augmented for enhanced model training. Three\nalgorithms-YOLOv7, its lightweight variant, and Faster R-CNN- were employed to\ndetect and classify surface damage. The models were trained and evaluated on a\ndataset split into training, testing, and evaluation subsets (80%-10%-10%).\nResults indicate that YOLOv7 outperformed the others, achieving 82.4% mAP@50\nand high processing speed, making it suitable for real-time inspections. By\noptimizing hyperparameters like learning rate and batch size, the models'\naccuracy and efficiency improved further. YOLOv7 demonstrated significant\nadvancements in detection precision and execution speed, especially for\nreal-time applications. However, challenges such as dataset limitations and\nenvironmental variability were noted, suggesting future work on segmentation\nmethods and larger datasets. This research underscores the potential of\nvision-based deep learning techniques to transform SHM practices by reducing\ncosts, enhancing safety, and improving reliability, thus contributing to the\nsustainable maintenance of critical infrastructure and supporting the longevity\nof wind energy systems.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV",
      "68A00 (Primary), 68C02 (Secondary)"
    ],
    "primary_category": "cs.CV",
    "comment": "14 pages, 8 figures. This study examines advanced deep learning\n  algorithms, specifically YOLOv7, for efficient and accurate damage detection\n  in wind turbine structures. It significantly enhances detection precision and\n  speed for real-time inspections",
    "pdf_url": "http://arxiv.org/pdf/2501.16662v2",
    "published_date": "2025-01-28 02:52:04 UTC",
    "updated_date": "2025-01-30 18:48:48 UTC"
  },
  {
    "arxiv_id": "2501.16658v1",
    "title": "Contextual Reinforcement in Multimodal Token Compression for Large Language Models",
    "authors": [
      "Naderdel Piero",
      "Zacharias Cromwell",
      "Nathaniel Wainwright",
      "Matthias Nethercott"
    ],
    "abstract": "Effective token compression remains a critical challenge for scaling models\nto handle increasingly complex and diverse datasets. A novel mechanism based on\ncontextual reinforcement is introduced, dynamically adjusting token importance\nthrough interdependencies and semantic relevance. This approach enables\nsubstantial reductions in token usage while preserving the quality and\ncoherence of information representation. Incorporating graph-based algorithms\nand adaptive weighting, the method captures subtle contextual relationships\nacross textual and multimodal data, ensuring robust alignment and performance\nin downstream tasks. Evaluations across varied domains reveal significant\nimprovements in accuracy and semantic retention, particularly for tasks\nrequiring detailed cross-modal interactions. Memory usage analyses demonstrate\nimproved computational efficiency, with minimal overhead despite the additional\nreinforcement processes. Performance gains are further validated through error\ndistribution analyses, showing reduced semantic loss and syntactic\ninconsistencies compared to baseline models. The modular architecture ensures\ncompatibility with a wide range of open-source frameworks, facilitating\nscalable implementation for real-world applications. These findings highlight\nthe potential of contextual reinforcement in redefining token management\nstrategies and advancing large-scale model design.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.16658v1",
    "published_date": "2025-01-28 02:44:31 UTC",
    "updated_date": "2025-01-28 02:44:31 UTC"
  },
  {
    "arxiv_id": "2501.16655v1",
    "title": "Large Language Model Critics for Execution-Free Evaluation of Code Changes",
    "authors": [
      "Aashish Yadavally",
      "Hoan Nguyen",
      "Laurent Callot",
      "Gauthier Guinet"
    ],
    "abstract": "Large language models (LLMs) offer a promising way forward for automating\nsoftware engineering tasks, such as bug fixes, feature additions, etc., via\nmulti-step LLM-based agentic workflows. However, existing metrics for\nevaluating such workflows, mainly build status and occasionally log analysis,\nare too sparse and limited in providing the information needed to assess the\nquality of changes made. In this work, we designed LLM-based critics to derive\nwell-structured and rigorous intermediate/step-level, execution-free evaluation\nproxies for repo-level code changes. Importantly, we assume access to the gold\ntest patch for the problem (i.e., reference-aware) to assess both semantics and\nexecutability of generated patches. With the gold test patch as a reference, we\npredict executability of all editing locations with an F1 score of 91.6%,\naggregating which, we can predict the build status in 84.8% of the instances in\nSWE-bench. In particular, such an execution-focused LLM critic outperforms\nother reference-free and reference-aware LLM critics by 38.9% to 72.5%.\nMoreover, we demonstrate the usefulness of such a reference-aware framework in\ncomparing patches generated by different agentic workflows. Finally, we\nopen-source the library developed for this project, which allows further usage\nfor either other agentic workflows or other benchmarks. The source code is\navailable at https://github.com/amazon-science/code-agent-eval.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.CL",
    "comment": "10 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.16655v1",
    "published_date": "2025-01-28 02:38:56 UTC",
    "updated_date": "2025-01-28 02:38:56 UTC"
  },
  {
    "arxiv_id": "2501.16652v1",
    "title": "Molecular-driven Foundation Model for Oncologic Pathology",
    "authors": [
      "Anurag Vaidya",
      "Andrew Zhang",
      "Guillaume Jaume",
      "Andrew H. Song",
      "Tong Ding",
      "Sophia J. Wagner",
      "Ming Y. Lu",
      "Paul Doucet",
      "Harry Robertson",
      "Cristina Almagro-Perez",
      "Richard J. Chen",
      "Dina ElHarouni",
      "Georges Ayoub",
      "Connor Bossi",
      "Keith L. Ligon",
      "Georg Gerber",
      "Long Phi Le",
      "Faisal Mahmood"
    ],
    "abstract": "Foundation models are reshaping computational pathology by enabling transfer\nlearning, where models pre-trained on vast datasets can be adapted for\ndownstream diagnostic, prognostic, and therapeutic response tasks. Despite\nthese advances, foundation models are still limited in their ability to encode\nthe entire gigapixel whole-slide images without additional training and often\nlack complementary multimodal data. Here, we introduce Threads, a slide-level\nfoundation model capable of generating universal representations of whole-slide\nimages of any size. Threads was pre-trained using a multimodal learning\napproach on a diverse cohort of 47,171 hematoxylin and eosin (H&E)-stained\ntissue sections, paired with corresponding genomic and transcriptomic profiles\n- the largest such paired dataset to be used for foundation model development\nto date. This unique training paradigm enables Threads to capture the tissue's\nunderlying molecular composition, yielding powerful representations applicable\nto a wide array of downstream tasks. In extensive benchmarking across 54\noncology tasks, including clinical subtyping, grading, mutation prediction,\nimmunohistochemistry status determination, treatment response prediction, and\nsurvival prediction, Threads outperformed all baselines while demonstrating\nremarkable generalizability and label efficiency. It is particularly well\nsuited for predicting rare events, further emphasizing its clinical utility. We\nintend to make the model publicly available for the broader community.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.16652v1",
    "published_date": "2025-01-28 02:35:02 UTC",
    "updated_date": "2025-01-28 02:35:02 UTC"
  },
  {
    "arxiv_id": "2501.16650v1",
    "title": "DOCS: Quantifying Weight Similarity for Deeper Insights into Large Language Models",
    "authors": [
      "Zeping Min",
      "Xinshang Wang"
    ],
    "abstract": "We introduce a novel index, the Distribution of Cosine Similarity (DOCS), for\nquantitatively assessing the similarity between weight matrices in Large\nLanguage Models (LLMs), aiming to facilitate the analysis of their complex\narchitectures. Leveraging DOCS, our analysis uncovers intriguing patterns in\nthe latest open-source LLMs: adjacent layers frequently exhibit high weight\nsimilarity and tend to form clusters, suggesting depth-wise functional\nspecialization. Additionally, we prove that DOCS is theoretically effective in\nquantifying similarity for orthogonal matrices, a crucial aspect given the\nprevalence of orthogonal initializations in LLMs. This research contributes to\na deeper understanding of LLM architecture and behavior, offering tools with\npotential implications for developing more efficient and interpretable models.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.16650v1",
    "published_date": "2025-01-28 02:32:49 UTC",
    "updated_date": "2025-01-28 02:32:49 UTC"
  },
  {
    "arxiv_id": "2501.16643v2",
    "title": "An LLM Benchmark for Addressee Recognition in Multi-modal Multi-party Dialogue",
    "authors": [
      "Koji Inoue",
      "Divesh Lala",
      "Mikey Elmers",
      "Keiko Ochi",
      "Tatsuya Kawahara"
    ],
    "abstract": "Handling multi-party dialogues represents a significant step for advancing\nspoken dialogue systems, necessitating the development of tasks specific to\nmulti-party interactions. To address this challenge, we are constructing a\nmulti-modal multi-party dialogue corpus of triadic (three-participant)\ndiscussions. This paper focuses on the task of addressee recognition,\nidentifying who is being addressed to take the next turn, a critical component\nunique to multi-party dialogue systems. A subset of the corpus was annotated\nwith addressee information, revealing that explicit addressees are indicated in\napproximately 20% of conversational turns. To evaluate the task's complexity,\nwe benchmarked the performance of a large language model (GPT-4o) on addressee\nrecognition. The results showed that GPT-4o achieved an accuracy only\nmarginally above chance, underscoring the challenges of addressee recognition\nin multi-party dialogue. These findings highlight the need for further research\nto enhance the capabilities of large language models in understanding and\nnavigating the intricacies of multi-party conversational dynamics.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL",
    "comment": "This paper has been accepted for presentation at International\n  Workshop on Spoken Dialogue Systems Technology 2025 (IWSDS 2025) and\n  represents the author's version of the work",
    "pdf_url": "http://arxiv.org/pdf/2501.16643v2",
    "published_date": "2025-01-28 02:27:55 UTC",
    "updated_date": "2025-03-18 06:39:36 UTC"
  },
  {
    "arxiv_id": "2501.16635v2",
    "title": "Why Do We Laugh? Annotation and Taxonomy Generation for Laughable Contexts in Spontaneous Text Conversation",
    "authors": [
      "Koji Inoue",
      "Mikey Elmers",
      "Divesh Lala",
      "Tatsuya Kawahara"
    ],
    "abstract": "Laughter serves as a multifaceted communicative signal in human interaction,\nyet its identification within dialogue presents a significant challenge for\nconversational AI systems. This study addresses this challenge by annotating\nlaughable contexts in Japanese spontaneous text conversation data and\ndeveloping a taxonomy to classify the underlying reasons for such contexts.\nInitially, multiple annotators manually labeled laughable contexts using a\nbinary decision (laughable or non-laughable). Subsequently, an LLM was used to\ngenerate explanations for the binary annotations of laughable contexts, which\nwere then categorized into a taxonomy comprising ten categories, including\n\"Empathy and Affinity\" and \"Humor and Surprise,\" highlighting the diverse range\nof laughter-inducing scenarios. The study also evaluated GPT-4o's performance\nin recognizing the majority labels of laughable contexts, achieving an F1 score\nof 43.14%. These findings contribute to the advancement of conversational AI by\nestablishing a foundation for more nuanced recognition and generation of\nlaughter, ultimately fostering more natural and engaging human-AI interactions.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "This paper has been accepted for presentation at International\n  Workshop on Spoken Dialogue Systems Technology 2025 (IWSDS 2025) and\n  represents the author's version of the work",
    "pdf_url": "http://arxiv.org/pdf/2501.16635v2",
    "published_date": "2025-01-28 02:16:18 UTC",
    "updated_date": "2025-03-18 11:50:37 UTC"
  },
  {
    "arxiv_id": "2501.16634v3",
    "title": "Towards Resource-Efficient Compound AI Systems",
    "authors": [
      "Gohar Irfan Chaudhry",
      "Esha Choukse",
      "Íñigo Goiri",
      "Rodrigo Fonseca",
      "Adam Belay",
      "Ricardo Bianchini"
    ],
    "abstract": "Compound AI Systems, integrating multiple interacting components like models,\nretrievers, and external tools, have emerged as essential for addressing\ncomplex AI tasks. However, current implementations suffer from inefficient\nresource utilization due to tight coupling between application logic and\nexecution details, a disconnect between orchestration and resource management\nlayers, and the perceived exclusiveness between efficiency and quality.\n  We propose a vision for resource-efficient Compound AI Systems through a\ndeclarative workflow programming model and an adaptive runtime system for\ndynamic scheduling and resource-aware decision-making. Decoupling application\nlogic from low-level details exposes levers for the runtime to flexibly\nconfigure the execution environment and resources, without compromising on\nquality. Enabling collaboration between the workflow orchestration and cluster\nmanager enables higher efficiency through better scheduling and resource\nmanagement.\n  We are building a prototype system, called Murakkab, to realize this vision.\nOur preliminary evaluation demonstrates speedups up to $\\sim 3.4\\times$ in\nworkflow completion times while delivering $\\sim 4.5\\times$ higher energy\nefficiency, showing promise in optimizing resources and advancing AI system\ndesign.",
    "categories": [
      "cs.DC",
      "cs.AI"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.16634v3",
    "published_date": "2025-01-28 02:15:34 UTC",
    "updated_date": "2025-03-17 20:14:48 UTC"
  },
  {
    "arxiv_id": "2501.16627v1",
    "title": "Engaging with AI: How Interface Design Shapes Human-AI Collaboration in High-Stakes Decision-Making",
    "authors": [
      "Zichen Chen",
      "Yunhao Luo",
      "Misha Sra"
    ],
    "abstract": "As reliance on AI systems for decision-making grows, it becomes critical to\nensure that human users can appropriately balance trust in AI suggestions with\ntheir own judgment, especially in high-stakes domains like healthcare. However,\nhuman + AI teams have been shown to perform worse than AI alone, with evidence\nindicating automation bias as the reason for poorer performance, particularly\nbecause humans tend to follow AI's recommendations even when they are\nincorrect. In many existing human + AI systems, decision-making support is\ntypically provided in the form of text explanations (XAI) to help users\nunderstand the AI's reasoning. Since human decision-making often relies on\nSystem 1 thinking, users may ignore or insufficiently engage with the\nexplanations, leading to poor decision-making. Previous research suggests that\nthere is a need for new approaches that encourage users to engage with the\nexplanations and one proposed method is the use of cognitive forcing functions\n(CFFs). In this work, we examine how various decision-support mechanisms impact\nuser engagement, trust, and human-AI collaborative task performance in a\ndiabetes management decision-making scenario. In a controlled experiment with\n108 participants, we evaluated the effects of six decision-support mechanisms\nsplit into two categories of explanations (text, visual) and four CFFs. Our\nfindings reveal that mechanisms like AI confidence levels, text explanations,\nand performance visualizations enhanced human-AI collaborative task\nperformance, and improved trust when AI reasoning clues were provided.\nMechanisms like human feedback and AI-driven questions encouraged deeper\nreflection but often reduced task performance by increasing cognitive effort,\nwhich in turn affected trust. Simple mechanisms like visual explanations had\nlittle effect on trust, highlighting the importance of striking a balance in\nCFF and XAI design.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "36 pages, 6 figures, 6 tables. Preprint version",
    "pdf_url": "http://arxiv.org/pdf/2501.16627v1",
    "published_date": "2025-01-28 02:03:00 UTC",
    "updated_date": "2025-01-28 02:03:00 UTC"
  },
  {
    "arxiv_id": "2501.16621v1",
    "title": "Chinese Stock Prediction Based on a Multi-Modal Transformer Framework: Macro-Micro Information Fusion",
    "authors": [
      "Lumen AI",
      "Tengzhou No. 1 Middle School",
      "Shihao Ji",
      "Zihui Song",
      "Fucheng Zhong",
      "Jisen Jia",
      "Zhaobo Wu",
      "Zheyi Cao",
      "Xu Tianhao"
    ],
    "abstract": "This paper proposes an innovative Multi-Modal Transformer framework\n(MMF-Trans) designed to significantly improve the prediction accuracy of the\nChinese stock market by integrating multi-source heterogeneous information\nincluding macroeconomy, micro-market, financial text, and event knowledge. The\nframework consists of four core modules: (1) A four-channel parallel encoder\nthat processes technical indicators, financial text, macro data, and event\nknowledge graph respectively for independent feature extraction of multi-modal\ndata; (2) A dynamic gated cross-modal fusion mechanism that adaptively learns\nthe importance of different modalities through differentiable weight allocation\nfor effective information integration; (3) A time-aligned mixed-frequency\nprocessing layer that uses an innovative position encoding method to\neffectively fuse data of different time frequencies and solves the time\nalignment problem of heterogeneous data; (4) A graph attention-based event\nimpact quantification module that captures the dynamic impact of events on the\nmarket through event knowledge graph and quantifies the event impact\ncoefficient. We introduce a hybrid-frequency Transformer and Event2Vec\nalgorithm to effectively fuse data of different frequencies and quantify the\nevent impact. Experimental results show that in the prediction task of CSI 300\nconstituent stocks, the root mean square error (RMSE) of the MMF-Trans\nframework is reduced by 23.7% compared to the baseline model, the event\nresponse prediction accuracy is improved by 41.2%, and the Sharpe ratio is\nimproved by 32.6%.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.16621v1",
    "published_date": "2025-01-28 01:39:35 UTC",
    "updated_date": "2025-01-28 01:39:35 UTC"
  },
  {
    "arxiv_id": "2501.16613v1",
    "title": "Safe Reinforcement Learning for Real-World Engine Control",
    "authors": [
      "Julian Bedei",
      "Lucas Koch",
      "Kevin Badalian",
      "Alexander Winkler",
      "Patrick Schaber",
      "Jakob Andert"
    ],
    "abstract": "This work introduces a toolchain for applying Reinforcement Learning (RL),\nspecifically the Deep Deterministic Policy Gradient (DDPG) algorithm, in\nsafety-critical real-world environments. As an exemplary application, transient\nload control is demonstrated on a single-cylinder internal combustion engine\ntestbench in Homogeneous Charge Compression Ignition (HCCI) mode, that offers\nhigh thermal efficiency and low emissions. However, HCCI poses challenges for\ntraditional control methods due to its nonlinear, autoregressive, and\nstochastic nature. RL provides a viable solution, however, safety concerns,\nsuch as excessive pressure rise rates, must be addressed when applying to HCCI.\nA single unsuitable control input can severely damage the engine or cause\nmisfiring and shut down. Additionally, operating limits are not known a priori\nand must be determined experimentally. To mitigate these risks, real-time\nsafety monitoring based on the k-nearest neighbor algorithm is implemented,\nenabling safe interaction with the testbench. The feasibility of this approach\nis demonstrated as the RL agent learns a control policy through interaction\nwith the testbench. A root mean square error of 0.1374 bar is achieved for the\nindicated mean effective pressure, comparable to neural network-based\ncontrollers from the literature. The toolchain's flexibility is further\ndemonstrated by adapting the agent's policy to increase ethanol energy shares,\npromoting renewable fuel use while maintaining safety. This RL approach\naddresses the longstanding challenge of applying RL to safety-critical\nreal-world environments. The developed toolchain, with its adaptability and\nsafety mechanisms, paves the way for future applicability of RL in engine\ntestbenches and other safety-critical settings.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.16613v1",
    "published_date": "2025-01-28 01:19:05 UTC",
    "updated_date": "2025-01-28 01:19:05 UTC"
  },
  {
    "arxiv_id": "2501.16609v3",
    "title": "CowPilot: A Framework for Autonomous and Human-Agent Collaborative Web Navigation",
    "authors": [
      "Faria Huq",
      "Zora Zhiruo Wang",
      "Frank F. Xu",
      "Tianyue Ou",
      "Shuyan Zhou",
      "Jeffrey P. Bigham",
      "Graham Neubig"
    ],
    "abstract": "While much work on web agents emphasizes the promise of autonomously\nperforming tasks on behalf of users, in reality, agents often fall short on\ncomplex tasks in real-world contexts and modeling user preference. This\npresents an opportunity for humans to collaborate with the agent and leverage\nthe agent's capabilities effectively. We propose CowPilot, a framework\nsupporting autonomous as well as human-agent collaborative web navigation, and\nevaluation across task success and task efficiency. CowPilot reduces the number\nof steps humans need to perform by allowing agents to propose next steps, while\nusers are able to pause, reject, or take alternative actions. During execution,\nusers can interleave their actions with the agent by overriding suggestions or\nresuming agent control when needed. We conducted case studies on five common\nwebsites and found that the human-agent collaborative mode achieves the highest\nsuccess rate of 95% while requiring humans to perform only 15.2% of the total\nsteps. Even with human interventions during task execution, the agent\nsuccessfully drives up to half of task success on its own. CowPilot can serve\nas a useful tool for data collection and agent evaluation across websites,\nwhich we believe will enable research in how users and agents can work\ntogether. Video demonstrations are available at\nhttps://oaishi.github.io/cowpilot.html",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "Preprint",
    "pdf_url": "http://arxiv.org/pdf/2501.16609v3",
    "published_date": "2025-01-28 00:56:53 UTC",
    "updated_date": "2025-04-05 23:49:31 UTC"
  },
  {
    "arxiv_id": "2501.16607v1",
    "title": "MCTS-SQL: An Effective Framework for Text-to-SQL with Monte Carlo Tree Search",
    "authors": [
      "Shuozhi Yuan",
      "Liming Chen",
      "Miaomiao Yuan",
      "Jin Zhao",
      "Haoran Peng",
      "Wenming Guo"
    ],
    "abstract": "Text-to-SQL is a fundamental and longstanding problem in the NLP area, aiming\nat converting natural language queries into SQL, enabling non-expert users to\noperate databases. Recent advances in LLM have greatly improved text-to-SQL\nperformance. However, challenges persist, especially when dealing with complex\nuser queries. Current approaches (e.g., COT prompting and multi-agent\nframeworks) rely on the ability of models to plan and generate SQL\nautonomously, but controlling performance remains difficult. In addition, LLMs\nare still prone to hallucinations. To alleviate these challenges, we designed a\nnovel MCTS-SQL to guide SQL generation iteratively. The approach generates SQL\nqueries through Monte Carlo Tree Search (MCTS) and a heuristic self-refinement\nmechanism are used to enhance accuracy and reliability. Key components include\na schema selector for extracting relevant information and an MCTS-based\ngenerator for iterative query refinement. Experimental results from the SPIDER\nand BIRD benchmarks show that MCTS-SQL achieves state-of-the-art performance.\nSpecifically, on the BIRD development dataset, MCTS-SQL achieves an Execution\n(EX) accuracy of 69.40% using GPT-4o as the base model and a significant\nimprovement when dealing with challenging tasks, with an EX of 51.48%, which is\n3.41% higher than the existing method.",
    "categories": [
      "cs.DB",
      "cs.AI",
      "cs.CL",
      "cs.PL"
    ],
    "primary_category": "cs.DB",
    "comment": "8 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.16607v1",
    "published_date": "2025-01-28 00:52:23 UTC",
    "updated_date": "2025-01-28 00:52:23 UTC"
  },
  {
    "arxiv_id": "2501.16606v2",
    "title": "Can We Govern the Agent-to-Agent Economy?",
    "authors": [
      "Tomer Jordi Chaffer"
    ],
    "abstract": "Current approaches to AI governance often fall short in anticipating a future\nwhere AI agents manage critical tasks, such as financial operations,\nadministrative functions, and beyond. While cryptocurrencies could serve as the\nfoundation for monetizing value exchange in a collaboration and delegation\ndynamic among AI agents, a critical question remains: how can humans ensure\nmeaningful oversight and control as a future economy of AI agents scales and\nevolves? In this philosophical exploration, we highlight emerging concepts in\nthe industry to inform research and development efforts in anticipation of a\nfuture decentralized agentic economy.",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "primary_category": "cs.MA",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.16606v2",
    "published_date": "2025-01-28 00:50:35 UTC",
    "updated_date": "2025-04-25 17:21:28 UTC"
  },
  {
    "arxiv_id": "2501.16605v1",
    "title": "Impact and influence of modern AI in metadata management",
    "authors": [
      "Wenli Yang",
      "Rui Fu",
      "Muhammad Bilal Amin",
      "Byeong Kang"
    ],
    "abstract": "Metadata management plays a critical role in data governance, resource\ndiscovery, and decision-making in the data-driven era. While traditional\nmetadata approaches have primarily focused on organization, classification, and\nresource reuse, the integration of modern artificial intelligence (AI)\ntechnologies has significantly transformed these processes. This paper\ninvestigates both traditional and AI-driven metadata approaches by examining\nopen-source solutions, commercial tools, and research initiatives. A\ncomparative analysis of traditional and AI-driven metadata management methods\nis provided, highlighting existing challenges and their impact on\nnext-generation datasets. The paper also presents an innovative AI-assisted\nmetadata management framework designed to address these challenges. This\nframework leverages more advanced modern AI technologies to automate metadata\ngeneration, enhance governance, and improve the accessibility and usability of\nmodern datasets. Finally, the paper outlines future directions for research and\ndevelopment, proposing opportunities to further advance metadata management in\nthe context of AI-driven innovation and complex datasets.",
    "categories": [
      "cs.DB",
      "cs.AI"
    ],
    "primary_category": "cs.DB",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.16605v1",
    "published_date": "2025-01-28 00:44:38 UTC",
    "updated_date": "2025-01-28 00:44:38 UTC"
  },
  {
    "arxiv_id": "2501.16591v1",
    "title": "Applying Ensemble Models based on Graph Neural Network and Reinforcement Learning for Wind Power Forecasting",
    "authors": [
      "Hongjin Song",
      "Qianrun Chen",
      "Tianqi Jiang",
      "Yongfeng Li",
      "Xusheng Li",
      "Wenjun Xi",
      "Songtao Huang"
    ],
    "abstract": "Accurately predicting the wind power output of a wind farm across various\ntime scales utilizing Wind Power Forecasting (WPF) is a critical issue in wind\npower trading and utilization. The WPF problem remains unresolved due to\nnumerous influencing variables, such as wind speed, temperature, latitude, and\nlongitude. Furthermore, achieving high prediction accuracy is crucial for\nmaintaining electric grid stability and ensuring supply security. In this\npaper, we model all wind turbines within a wind farm as graph nodes in a graph\nbuilt by their geographical locations. Accordingly, we propose an ensemble\nmodel based on graph neural networks and reinforcement learning (EMGRL) for\nWPF. Our approach includes: (1) applying graph neural networks to capture the\ntime-series data from neighboring wind farms relevant to the target wind farm;\n(2) establishing a general state embedding that integrates the target wind\nfarm's data with the historical performance of base models on the target wind\nfarm; (3) ensembling and leveraging the advantages of all base models through\nan actor-critic reinforcement learning framework for WPF.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.16591v1",
    "published_date": "2025-01-28 00:12:26 UTC",
    "updated_date": "2025-01-28 00:12:26 UTC"
  }
]