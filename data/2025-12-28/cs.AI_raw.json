[
  {
    "arxiv_id": "2512.23109v1",
    "title": "How Much Data Is Enough? Uniform Convergence Bounds for Generative & Vision-Language Models under Low-Dimensional Structure",
    "authors": [
      "Paul M. Thompson"
    ],
    "abstract": "Modern generative and vision-language models (VLMs) are increasingly used in scientific and medical decision support, where predicted probabilities must be both accurate and well calibrated. Despite strong empirical results with moderate data, it remains unclear when such predictions generalize uniformly across inputs, classes, or subpopulations, rather than only on average-a critical issue in biomedicine, where rare conditions and specific groups can exhibit large errors even when overall loss is low.\n  We study this question from a finite-sample perspective and ask: under what structural assumptions can generative and VLM-based predictors achieve uniformly accurate and calibrated behavior with practical sample sizes? Rather than analyzing arbitrary parameterizations, we focus on induced families of classifiers obtained by varying prompts or semantic embeddings within a restricted representation space. When model outputs depend smoothly on a low-dimensional semantic representation-an assumption supported by spectral structure in text and joint image-text embeddings-classical uniform convergence tools yield meaningful non-asymptotic guarantees.\n  Our main results give finite-sample uniform convergence bounds for accuracy and calibration functionals of VLM-induced classifiers under Lipschitz stability with respect to prompt embeddings. The implied sample complexity depends on intrinsic/effective dimension, not ambient embedding dimension, and we further derive spectrum-dependent bounds that make explicit how eigenvalue decay governs data requirements. We conclude with implications for data-limited biomedical modeling, including when current dataset sizes can support uniformly reliable predictions and why average calibration metrics may miss worst-case miscalibration.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "13 pages, 2 figures",
    "pdf_url": "https://arxiv.org/pdf/2512.23109v1",
    "published_date": "2025-12-28 23:16:22 UTC",
    "updated_date": "2025-12-28 23:16:22 UTC"
  },
  {
    "arxiv_id": "2601.04225v1",
    "title": "Can Consumer Chatbots Reason? A Student-Led Field Experiment Embedded in an \"AI-for-All\" Undergraduate Course",
    "authors": [
      "Amarda Shehu",
      "Adonyas Ababu",
      "Asma Akbary",
      "Griffin Allen",
      "Aroush Baig",
      "Tereana Battle",
      "Elias Beall",
      "Christopher Byrom",
      "Matt Dean",
      "Kate Demarco",
      "Ethan Douglass",
      "Luis Granados",
      "Layla Hantush",
      "Andy Hay",
      "Eleanor Hay",
      "Caleb Jackson",
      "Jaewon Jang",
      "Carter Jones",
      "Quanyang Li",
      "Adrian Lopez",
      "Logan Massimo",
      "Garrett McMullin",
      "Ariana Mendoza Maldonado",
      "Eman Mirza",
      "Hadiya Muddasar",
      "Sara Nuwayhid",
      "Brandon Pak",
      "Ashley Petty",
      "Dryden Rancourt",
      "Lily Rodriguez",
      "Corbin Rogers",
      "Jacob Schiek",
      "Taeseo Seok",
      "Aarav Sethi",
      "Giovanni Vitela",
      "Winston Williams",
      "Jagan Yetukuri"
    ],
    "abstract": "Claims about whether large language model (LLM) chatbots \"reason\" are typically debated using curated benchmarks and laboratory-style evaluation protocols. This paper offers a complementary perspective: a student-led field experiment embedded as a midterm project in UNIV 182 (AI4All) at George Mason University, a Mason Core course designed for undergraduates across disciplines with no expected prior STEM exposure. Student teams designed their own reasoning tasks, ran them on widely used consumer chatbots representative of current capabilities, and evaluated both (i) answer correctness and (ii) the validity of the chatbot's stated reasoning (for example, cases where an answer is correct but the explanation is not, or vice versa). Across eight teams that reported standardized scores, students contributed 80 original reasoning prompts spanning six categories: pattern completion, transformation rules, spatial/visual reasoning, quantitative reasoning, relational/logic reasoning, and analogical reasoning. These prompts yielded 320 model responses plus follow-up explanations. Aggregating team-level results, OpenAI GPT-5 and Claude 4.5 achieved the highest mean answer accuracy (86.2% and 83.8%), followed by Grok 4 (82.5%) and Perplexity (73.1%); explanation validity showed a similar ordering (81.2%, 80.0%, 77.5%, 66.2%). Qualitatively, teams converged on a consistent error signature: strong performance on short, structured math and pattern items but reduced reliability on spatial/visual reasoning and multi-step transformations, with frequent \"sound right but reason wrong\" explanations. The assignment's primary contribution is pedagogical: it operationalizes AI literacy as experimental practice (prompt design, measurement, rater disagreement, and interpretability/grounding) while producing a reusable, student-generated corpus of reasoning probes grounded in authentic end-user interaction.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2601.04225v1",
    "published_date": "2025-12-28 22:51:25 UTC",
    "updated_date": "2025-12-28 22:51:25 UTC"
  },
  {
    "arxiv_id": "2512.23097v1",
    "title": "A Note on Hybrid Online Reinforcement and Imitation Learning for LLMs: Formulations and Algorithms",
    "authors": [
      "Yingru Li",
      "Ziniu Li",
      "Jiacai Liu"
    ],
    "abstract": "We present a unified framework for Large Language Model (LLM) fine-tuning that integrates Imitation Learning and Reinforcement Learning. By analyzing the gradient of a composite objective combining trajectory-level KL divergence with task rewards, we derive a natural decomposition into two components: (1) an analytically computable Dense Gradient for token-level imitation, and (2) a Monte Carlo estimated Sparse Gradient for long-horizon reward optimization. The Dense Gradient admits a closed-form logit-level formula, enabling efficient GPU implementation.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.23097v1",
    "published_date": "2025-12-28 22:25:27 UTC",
    "updated_date": "2025-12-28 22:25:27 UTC"
  },
  {
    "arxiv_id": "2512.23762v1",
    "title": "Drift-Based Dataset Stability Benchmark",
    "authors": [
      "Dominik Soukup",
      "Richard Plný",
      "Daniel Vašata",
      "Tomáš Čejka"
    ],
    "abstract": "Machine learning (ML) represents an efficient and popular approach for network traffic classification. However, network traffic classification is a challenging domain, and trained models may degrade soon after deployment due to the obsolete datasets and quick evolution of computer networks as new or updated protocols appear. Moreover, significant change in the behavior of a traffic type (and, therefore, the underlying features representing the traffic) can produce a large and sudden performance drop of the deployed model, known as a data or concept drift. In most cases, complete retraining is performed, often without further investigation of root causes, as good dataset quality is assumed. However, this is not always the case and further investigation must be performed. This paper proposes a novel methodology to evaluate the stability of datasets and a benchmark workflow that can be used to compare datasets.\n  The proposed framework is based on a concept drift detection method that also uses ML feature weights to boost the detection performance. The benefits of this work are demonstrated on CESNET-TLS-Year22 dataset. We provide the initial dataset stability benchmark that is used to describe dataset stability and weak points to identify the next steps for optimization. Lastly, using the proposed benchmarking methodology, we show the optimization impact on the created dataset variants.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NI"
    ],
    "primary_category": "cs.LG",
    "comment": "9 pages",
    "pdf_url": "https://arxiv.org/pdf/2512.23762v1",
    "published_date": "2025-12-28 22:02:19 UTC",
    "updated_date": "2025-12-28 22:02:19 UTC"
  },
  {
    "arxiv_id": "2512.23090v2",
    "title": "Benchmark Success, Clinical Failure: When Reinforcement Learning Optimizes for Benchmarks, Not Patients",
    "authors": [
      "Armin Berger",
      "Manuela Bergau",
      "Helen Schneider",
      "Saad Ahmad",
      "Tom Anglim Lagones",
      "Gianluca Brugnara",
      "Martha Foltyn-Dumitru",
      "Kai Schlamp",
      "Philipp Vollmuth",
      "Rafet Sifa"
    ],
    "abstract": "Recent Reinforcement Learning (RL) advances for Large Language Models (LLMs) have improved reasoning tasks, yet their resource-constrained application to medical imaging remains underexplored. We introduce ChexReason, a vision-language model trained via R1-style methodology (SFT followed by GRPO) using only 2,000 SFT samples, 1,000 RL samples, and a single A100 GPU. Evaluations on CheXpert and NIH benchmarks reveal a fundamental tension: GRPO recovers in-distribution performance (23% improvement on CheXpert, macro-F1 = 0.346) but degrades cross-dataset transferability (19% drop on NIH). This mirrors high-resource models like NV-Reason-CXR-3B, suggesting the issue stems from the RL paradigm rather than scale. We identify a generalization paradox where the SFT checkpoint uniquely improves on NIH before optimization, indicating teacher-guided reasoning captures more institution-agnostic features. Furthermore, cross-model comparisons show structured reasoning scaffolds benefit general-purpose VLMs but offer minimal gain for medically pre-trained models. Consequently, curated supervised fine-tuning may outperform aggressive RL for clinical deployment requiring robustness across diverse populations.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.23090v2",
    "published_date": "2025-12-28 21:57:42 UTC",
    "updated_date": "2026-01-02 18:25:09 UTC"
  },
  {
    "arxiv_id": "2512.23089v1",
    "title": "MedSAM-based lung masking for multi-label chest X-ray classification",
    "authors": [
      "Brayden Miao",
      "Zain Rehman",
      "Xin Miao",
      "Siming Liu",
      "Jianjie Wang"
    ],
    "abstract": "Chest X-ray (CXR) imaging is widely used for screening and diagnosing pulmonary abnormalities, yet automated interpretation remains challenging due to weak disease signals, dataset bias, and limited spatial supervision. Foundation models for medical image segmentation (MedSAM) provide an opportunity to introduce anatomically grounded priors that may improve robustness and interpretability in CXR analysis. We propose a segmentation-guided CXR classification pipeline that integrates MedSAM as a lung region extraction module prior to multi-label abnormality classification. MedSAM is fine-tuned using a public image-mask dataset from Airlangga University Hospital. We then apply it to a curated subset of the public NIH CXR dataset to train and evaluate deep convolutional neural networks for multi-label prediction of five abnormalities (Mass, Nodule, Pneumonia, Edema, and Fibrosis), with the normal case (No Finding) evaluated via a derived score. Experiments show that MedSAM produces anatomically plausible lung masks across diverse imaging conditions. We find that masking effects are both task-dependent and architecture-dependent. ResNet50 trained on original images achieves the strongest overall abnormality discrimination, while loose lung masking yields comparable macro AUROC but significantly improves No Finding discrimination, indicating a trade-off between abnormality-specific classification and normal case screening. Tight masking consistently reduces abnormality level performance but improves training efficiency. Loose masking partially mitigates this degradation by preserving perihilar and peripheral context. These results suggest that lung masking should be treated as a controllable spatial prior selected to match the backbone and clinical objective, rather than applied uniformly.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "16 pages, 8 figures",
    "pdf_url": "https://arxiv.org/pdf/2512.23089v1",
    "published_date": "2025-12-28 21:56:41 UTC",
    "updated_date": "2025-12-28 21:56:41 UTC"
  },
  {
    "arxiv_id": "2512.23087v1",
    "title": "Taming the Tail: Stable LLM Reinforcement Learning via Dynamic Vocabulary Pruning",
    "authors": [
      "Yingru Li",
      "Jiawei Xu",
      "Jiacai Liu",
      "Yuxuan Tong",
      "Ziniu Li",
      "Tianle Cai",
      "Ge Zhang",
      "Qian Liu",
      "Baoxiang Wang"
    ],
    "abstract": "Reinforcement learning for large language models (LLMs) faces a fundamental tension: high-throughput inference engines and numerically-precise training systems produce different probability distributions from the same parameters, creating a training-inference mismatch. We prove this mismatch has an asymmetric effect: the bound on log-probability mismatch scales as $(1-p)$ where $p$ is the token probability. For high-probability tokens, this bound vanishes, contributing negligibly to sequence-level mismatch. For low-probability tokens in the tail, the bound remains large, and moreover, when sampled, these tokens exhibit systematically biased mismatches that accumulate over sequences, destabilizing gradient estimation. Rather than applying post-hoc corrections, we propose constraining the RL objective to a dynamically-pruned ``safe'' vocabulary that excludes the extreme tail. By pruning such tokens, we trade large, systematically biased mismatches for a small, bounded optimization bias. Empirically, our method achieves stable training; theoretically, we bound the optimization bias introduced by vocabulary pruning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.23087v1",
    "published_date": "2025-12-28 21:44:07 UTC",
    "updated_date": "2025-12-28 21:44:07 UTC"
  },
  {
    "arxiv_id": "2512.23078v1",
    "title": "Deep Learning for Art Market Valuation",
    "authors": [
      "Jianping Mei",
      "Michael Moses",
      "Jan Waelty",
      "Yucheng Yang"
    ],
    "abstract": "We study how deep learning can improve valuation in the art market by incorporating the visual content of artworks into predictive models. Using a large repeated-sales dataset from major auction houses, we benchmark classical hedonic regressions and tree-based methods against modern deep architectures, including multi-modal models that fuse tabular and image data. We find that while artist identity and prior transaction history dominate overall predictive power, visual embeddings provide a distinct and economically meaningful contribution for fresh-to-market works where historical anchors are absent. Interpretability analyses using Grad-CAM and embedding visualizations show that models attend to compositional and stylistic cues. Our findings demonstrate that multi-modal deep learning delivers significant value precisely when valuation is hardest, namely first-time sales, and thus offers new insights for both academic research and practice in art market valuation.",
    "categories": [
      "q-fin.GN",
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "econ.GN"
    ],
    "primary_category": "q-fin.GN",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.23078v1",
    "published_date": "2025-12-28 21:04:09 UTC",
    "updated_date": "2025-12-28 21:04:09 UTC"
  },
  {
    "arxiv_id": "2512.23076v1",
    "title": "Multimodal Functional Maximum Correlation for Emotion Recognition",
    "authors": [
      "Deyang Zheng",
      "Tianyi Zhang",
      "Wenming Zheng",
      "Shujian Yu"
    ],
    "abstract": "Emotional states manifest as coordinated yet heterogeneous physiological responses across central and autonomic systems, posing a fundamental challenge for multimodal representation learning in affective computing. Learning such joint dynamics is further complicated by the scarcity and subjectivity of affective annotations, which motivates the use of self-supervised learning (SSL). However, most existing SSL approaches rely on pairwise alignment objectives, which are insufficient to characterize dependencies among more than two modalities and fail to capture higher-order interactions arising from coordinated brain and autonomic responses.\n  To address this limitation, we propose Multimodal Functional Maximum Correlation (MFMC), a principled SSL framework that maximizes higher-order multimodal dependence through a Dual Total Correlation (DTC) objective. By deriving a tight sandwich bound and optimizing it using a functional maximum correlation analysis (FMCA) based trace surrogate, MFMC captures joint multimodal interactions directly, without relying on pairwise contrastive losses.\n  Experiments on three public affective computing benchmarks demonstrate that MFMC consistently achieves state-of-the-art or competitive performance under both subject-dependent and subject-independent evaluation protocols, highlighting its robustness to inter-subject variability. In particular, MFMC improves subject-dependent accuracy on CEAP-360VR from 78.9% to 86.8%, and subject-independent accuracy from 27.5% to 33.1% using the EDA signal alone. Moreover, MFMC remains within 0.8 percentage points of the best-performing method on the most challenging EEG subject-independent split of MAHNOB-HCI. Our code is available at https://github.com/DY9910/MFMC.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.LG",
    "comment": "manuscript currently under review at IEEE journals, 20 pages, 6 figures",
    "pdf_url": "https://arxiv.org/pdf/2512.23076v1",
    "published_date": "2025-12-28 20:48:02 UTC",
    "updated_date": "2025-12-28 20:48:02 UTC"
  },
  {
    "arxiv_id": "2512.23075v1",
    "title": "Trust Region Masking for Long-Horizon LLM Reinforcement Learning",
    "authors": [
      "Yingru Li",
      "Jiacai Liu",
      "Jiawei Xu",
      "Yuxuan Tong",
      "Ziniu Li",
      "Baoxiang Wang"
    ],
    "abstract": "Policy gradient methods for large language models optimize a surrogate objective computed from samples of a rollout policy $π_{\\text{roll}}$. When $π_{\\text{roll}} \\ne π_θ$, there is approximation error between the surrogate and the true objective. Prior work has shown that this off-policy mismatch is unavoidable in modern LLM-RL due to implementation divergence, mixture-of-experts routing discontinuities, and distributed training staleness. Classical trust region bounds on the resulting error scale as $O(T^2)$ with sequence length $T$, rendering them vacuous for long-horizon tasks. We derive two tighter bounds: a Pinsker-Marginal bound scaling as $O(T^{3/2})$ and a Mixed bound scaling as $O(T)$. Crucially, both bounds depend on $D_{kl}^{tok,max}$ -- the maximum token-level KL divergence across all positions in a sequence. This is inherently a sequence-level quantity: it requires examining the entire trajectory to compute, and therefore cannot be controlled by token-independent methods like PPO clipping. We propose Trust Region Masking (TRM), which excludes entire sequences from gradient computation if any token violates the trust region, providing the first non-vacuous monotonic improvement guarantees for long-horizon LLM-RL.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IT",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.23075v1",
    "published_date": "2025-12-28 20:41:59 UTC",
    "updated_date": "2025-12-28 20:41:59 UTC"
  },
  {
    "arxiv_id": "2512.23067v2",
    "title": "The Reward Model Selection Crisis in Personalized Alignment",
    "authors": [
      "Fady Rezk",
      "Yuangang Pan",
      "Chuan-Sheng Foo",
      "Xun Xu",
      "Nancy Chen",
      "Henry Gouk",
      "Timothy Hospedales"
    ],
    "abstract": "Personalized alignment from preference data has focused primarily on improving personal reward model (RM) accuracy, with the implicit assumption that better preference ranking translates to better personalized behavior. However, in deployment, computational constraints necessitate inference-time adaptation such as reward-guided decoding (RGD) rather than per-user policy fine-tuning. This creates a critical but overlooked requirement: reward models must not only rank preferences accurately but also effectively guide generation. We demonstrate that standard RM accuracy fails catastrophically as a selection criterion for deployment-ready personalized rewards. We introduce policy accuracy; a metric quantifying whether RGD-adapted LLMs correctly discriminate between preferred and dispreferred responses and show that upstream RM accuracy correlates only weakly with downstream policy accuracy (Kendall's tau = 0.08--0.31). More critically, we introduce Pref-LaMP the first personalized alignment benchmark with ground-truth user completions, enabling direct behavioural evaluation. On Pref-LaMP, we expose a complete decoupling between discriminative ranking and generation metrics: methods with 20-point RM accuracy differences produce almost identical output quality, and methods with high ranking accuracy can fail to generate behaviorally aligned responses. These findings reveal that the field has been optimizing for proxy metrics that do not predict deployment performance, and that current personalized alignment methods fail to operationalize preferences into behavioral adaptation under realistic deployment constraints. In contrast, we find simple in-context learning (ICL) to be highly effective - dominating all reward-guided methods for models $\\geq$3B parameters, achieving $\\sim$3 point ROUGE-1 gains over the best reward method at 7B scale.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.23067v2",
    "published_date": "2025-12-28 20:27:15 UTC",
    "updated_date": "2026-01-07 20:10:03 UTC"
  },
  {
    "arxiv_id": "2601.00844v1",
    "title": "Value-guided action planning with JEPA world models",
    "authors": [
      "Matthieu Destrade",
      "Oumayma Bounou",
      "Quentin Le Lidec",
      "Jean Ponce",
      "Yann LeCun"
    ],
    "abstract": "Building deep learning models that can reason about their environment requires capturing its underlying dynamics. Joint-Embedded Predictive Architectures (JEPA) provide a promising framework to model such dynamics by learning representations and predictors through a self-supervised prediction objective. However, their ability to support effective action planning remains limited. We propose an approach to enhance planning with JEPA world models by shaping their representation space so that the negative goal-conditioned value function for a reaching cost in a given environment is approximated by a distance (or quasi-distance) between state embeddings. We introduce a practical method to enforce this constraint during training and show that it leads to significantly improved planning performance compared to standard JEPA models on simple control tasks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "Presented as a poster at the World Modeling Workshop 2026, Mila",
    "pdf_url": "https://arxiv.org/pdf/2601.00844v1",
    "published_date": "2025-12-28 20:17:49 UTC",
    "updated_date": "2025-12-28 20:17:49 UTC"
  },
  {
    "arxiv_id": "2512.23760v1",
    "title": "Audited Skill-Graph Self-Improvement for Agentic LLMs via Verifiable Rewards, Experience Synthesis, and Continual Memory",
    "authors": [
      "Ken Huang",
      "Jerry Huang"
    ],
    "abstract": "Reinforcement learning is increasingly used to transform large language models into agentic systems that act over long horizons, invoke tools, and manage memory under partial observability. While recent work has demonstrated performance gains through tool learning, verifiable rewards, and continual training, deployed self-improving agents raise unresolved security and governance challenges: optimization pressure can incentivize reward hacking, behavioral drift is difficult to audit or reproduce, and improvements are often entangled in opaque parameter updates rather than reusable, verifiable artifacts.\n  This paper proposes Audited Skill-Graph Self-Improvement (ASG-SI), a framework that treats self-improvement as iterative compilation of an agent into a growing, auditable skill graph. Each candidate improvement is extracted from successful trajectories, normalized into a skill with an explicit interface, and promoted only after passing verifier-backed replay and contract checks. Rewards are decomposed into reconstructible components derived from replayable evidence, enabling independent audit of promotion decisions and learning signals. ASG-SI further integrates experience synthesis for scalable stress testing and continual memory control to preserve long-horizon performance under bounded context.\n  We present a complete system architecture, threat model, and security analysis, and provide a fully runnable reference implementation that demonstrates verifier-backed reward construction, skill compilation, audit logging, and measurable improvement under continual task streams. ASG-SI reframes agentic self-improvement as accumulation of verifiable, reusable capabilities, offering a practical path toward reproducible evaluation and operational governance of self-improving AI agents.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "11 pages, 4 figures. Includes a complete runnable reference implementation and audit logging framework",
    "pdf_url": "https://arxiv.org/pdf/2512.23760v1",
    "published_date": "2025-12-28 19:39:47 UTC",
    "updated_date": "2025-12-28 19:39:47 UTC"
  },
  {
    "arxiv_id": "2512.23036v1",
    "title": "Problems With Large Language Models for Learner Modelling: Why LLMs Alone Fall Short for Responsible Tutoring in K--12 Education",
    "authors": [
      "Danial Hooshyar",
      "Yeongwook Yang",
      "Gustav Šíř",
      "Tommi Kärkkäinen",
      "Raija Hämäläinen",
      "Mutlu Cukurova",
      "Roger Azevedo"
    ],
    "abstract": "The rapid rise of large language model (LLM)-based tutors in K--12 education has fostered a misconception that generative models can replace traditional learner modelling for adaptive instruction. This is especially problematic in K--12 settings, which the EU AI Act classifies as high-risk domain requiring responsible design. Motivated by these concerns, this study synthesises evidence on limitations of LLM-based tutors and empirically investigates one critical issue: the accuracy, reliability, and temporal coherence of assessing learners' evolving knowledge over time. We compare a deep knowledge tracing (DKT) model with a widely used LLM, evaluated zero-shot and fine-tuned, using a large open-access dataset. Results show that DKT achieves the highest discrimination performance (AUC = 0.83) on next-step correctness prediction and consistently outperforms the LLM across settings. Although fine-tuning improves the LLM's AUC by approximately 8\\% over the zero-shot baseline, it remains 6\\% below DKT and produces higher early-sequence errors, where incorrect predictions are most harmful for adaptive support. Temporal analyses further reveal that DKT maintains stable, directionally correct mastery updates, whereas LLM variants exhibit substantial temporal weaknesses, including inconsistent and wrong-direction updates. These limitations persist despite the fine-tuned LLM requiring nearly 198 hours of high-compute training, far exceeding the computational demands of DKT. Our qualitative analysis of multi-skill mastery estimation further shows that, even after fine-tuning, the LLM produced inconsistent mastery trajectories, while DKT maintained smooth and coherent updates. Overall, the findings suggest that LLMs alone are unlikely to match the effectiveness of established intelligent tutoring systems, and that responsible tutoring requires hybrid frameworks that incorporate learner modelling.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.23036v1",
    "published_date": "2025-12-28 18:26:22 UTC",
    "updated_date": "2025-12-28 18:26:22 UTC"
  },
  {
    "arxiv_id": "2512.23032v1",
    "title": "Is Chain-of-Thought Really Not Explainability? Chain-of-Thought Can Be Faithful without Hint Verbalization",
    "authors": [
      "Kerem Zaman",
      "Shashank Srivastava"
    ],
    "abstract": "Recent work, using the Biasing Features metric, labels a CoT as unfaithful if it omits a prompt-injected hint that affected the prediction. We argue this metric confuses unfaithfulness with incompleteness, the lossy compression needed to turn distributed transformer computation into a linear natural language narrative. On multi-hop reasoning tasks with Llama-3 and Gemma-3, many CoTs flagged as unfaithful by Biasing Features are judged faithful by other metrics, exceeding 50% in some models. With a new faithful@k metric, we show that larger inference-time token budgets greatly increase hint verbalization (up to 90% in some settings), suggesting much apparent unfaithfulness is due to tight token limits. Using Causal Mediation Analysis, we further show that even non-verbalized hints can causally mediate prediction changes through the CoT. We therefore caution against relying solely on hint-based evaluations and advocate a broader interpretability toolkit, including causal mediation and corruption-based metrics.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "18 pages, 20 figures, 5 tables",
    "pdf_url": "https://arxiv.org/pdf/2512.23032v1",
    "published_date": "2025-12-28 18:18:02 UTC",
    "updated_date": "2025-12-28 18:18:02 UTC"
  },
  {
    "arxiv_id": "2512.23029v1",
    "title": "Viability and Performance of a Private LLM Server for SMBs: A Benchmark Analysis of Qwen3-30B on Consumer-Grade Hardware",
    "authors": [
      "Alex Khalil",
      "Guillaume Heilles",
      "Maria Parraga",
      "Simon Heilles"
    ],
    "abstract": "The proliferation of Large Language Models (LLMs) has been accompanied by a reliance on cloud-based, proprietary systems, raising significant concerns regarding data privacy, operational sovereignty, and escalating costs. This paper investigates the feasibility of deploying a high-performance, private LLM inference server at a cost accessible to Small and Medium Businesses (SMBs). We present a comprehensive benchmarking analysis of a locally hosted, quantized 30-billion parameter Mixture-of-Experts (MoE) model based on Qwen3, running on a consumer-grade server equipped with a next-generation NVIDIA GPU. Unlike cloud-based offerings, which are expensive and complex to integrate, our approach provides an affordable and private solution for SMBs. We evaluate two dimensions: the model's intrinsic capabilities and the server's performance under load. Model performance is benchmarked against academic and industry standards to quantify reasoning and knowledge relative to cloud services. Concurrently, we measure server efficiency through latency, tokens per second, and time to first token, analyzing scalability under increasing concurrent users. Our findings demonstrate that a carefully configured on-premises setup with emerging consumer hardware and a quantized open-source model can achieve performance comparable to cloud-based services, offering SMBs a viable pathway to deploy powerful LLMs without prohibitive costs or privacy compromises.",
    "categories": [
      "cs.DC",
      "cs.AI"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.23029v1",
    "published_date": "2025-12-28 18:08:01 UTC",
    "updated_date": "2025-12-28 18:08:01 UTC"
  },
  {
    "arxiv_id": "2512.23028v1",
    "title": "An Architecture-Led Hybrid Report on Body Language Detection Project",
    "authors": [
      "Thomson Tong",
      "Diba Darooneh"
    ],
    "abstract": "This report provides an architecture-led analysis of two modern vision-language models (VLMs), Qwen2.5-VL-7B-Instruct and Llama-4-Scout-17B-16E-Instruct, and explains how their architectural properties map to a practical video-to-artifact pipeline implemented in the BodyLanguageDetection repository [1]. The system samples video frames, prompts a VLM to detect visible people and generate pixel-space bounding boxes with prompt-conditioned attributes (emotion by default), validates output structure using a predefined schema, and optionally renders an annotated video. We first summarize the shared multimodal foundation (visual tokenization, Transformer attention, and instruction following), then describe each architecture at a level sufficient to justify engineering choices without speculative internals. Finally, we connect model behavior to system constraints: structured outputs can be syntactically valid while semantically incorrect, schema validation is structural (not geometric correctness), person identifiers are frame-local in the current prompting contract, and interactive single-frame analysis returns free-form text rather than schema-enforced JSON. These distinctions are critical for writing defensible claims, designing robust interfaces, and planning evaluation.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.23028v1",
    "published_date": "2025-12-28 18:03:00 UTC",
    "updated_date": "2025-12-28 18:03:00 UTC"
  },
  {
    "arxiv_id": "2512.23025v1",
    "title": "LENS: LLM-Enabled Narrative Synthesis for Mental Health by Aligning Multimodal Sensing with Language Models",
    "authors": [
      "Wenxuan Xu",
      "Arvind Pillai",
      "Subigya Nepal",
      "Amanda C Collins",
      "Daniel M Mackin",
      "Michael V Heinz",
      "Tess Z Griffin",
      "Nicholas C Jacobson",
      "Andrew Campbell"
    ],
    "abstract": "Multimodal health sensing offers rich behavioral signals for assessing mental health, yet translating these numerical time-series measurements into natural language remains challenging. Current LLMs cannot natively ingest long-duration sensor streams, and paired sensor-text datasets are scarce. To address these challenges, we introduce LENS, a framework that aligns multimodal sensing data with language models to generate clinically grounded mental-health narratives. LENS first constructs a large-scale dataset by transforming Ecological Momentary Assessment (EMA) responses related to depression and anxiety symptoms into natural-language descriptions, yielding over 100,000 sensor-text QA pairs from 258 participants. To enable native time-series integration, we train a patch-level encoder that projects raw sensor signals directly into an LLM's representation space. Our results show that LENS outperforms strong baselines on standard NLP metrics and task-specific measures of symptom-severity accuracy. A user study with 13 mental-health professionals further indicates that LENS-produced narratives are comprehensive and clinically meaningful. Ultimately, our approach advances LLMs as interfaces for health sensing, providing a scalable path toward models that can reason over raw behavioral signals and support downstream clinical decision-making.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "22 pages, 9 figures, under review",
    "pdf_url": "https://arxiv.org/pdf/2512.23025v1",
    "published_date": "2025-12-28 18:00:57 UTC",
    "updated_date": "2025-12-28 18:00:57 UTC"
  },
  {
    "arxiv_id": "2512.23020v2",
    "title": "OpenGround: Active Cognition-based Reasoning for Open-World 3D Visual Grounding",
    "authors": [
      "Wenyuan Huang",
      "Zhao Wang",
      "Zhou Wei",
      "Ting Huang",
      "Fang Zhao",
      "Jian Yang",
      "Zhenyu Zhang"
    ],
    "abstract": "3D visual grounding aims to locate objects based on natural language descriptions in 3D scenes. Existing methods rely on a pre-defined Object Lookup Table (OLT) to query Visual Language Models (VLMs) for reasoning about object locations, which limits the applications in scenarios with undefined or unforeseen targets. To address this problem, we present OpenGround, a novel zero-shot framework for open-world 3D visual grounding. Central to OpenGround is the Active Cognition-based Reasoning (ACR) module, which is designed to overcome the fundamental limitation of pre-defined OLTs by progressively augmenting the cognitive scope of VLMs. The ACR module performs human-like perception of the target via a cognitive task chain and actively reasons about contextually relevant objects, thereby extending VLM cognition through a dynamically updated OLT. This allows OpenGround to function with both pre-defined and open-world categories. We also propose a new dataset named OpenTarget, which contains over 7000 object-description pairs to evaluate our method in open-world scenarios. Extensive experiments demonstrate that OpenGround achieves competitive performance on Nr3D, state-of-the-art on ScanRefer, and delivers a substantial 17.6% improvement on OpenTarget. Project Page at https://why-102.github.io/openground.io/.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "27 pages, 15 figures, 14 tables, Project Page at https://why-102.github.io/openground.io/",
    "pdf_url": "https://arxiv.org/pdf/2512.23020v2",
    "published_date": "2025-12-28 17:44:20 UTC",
    "updated_date": "2025-12-31 10:56:28 UTC"
  },
  {
    "arxiv_id": "2601.09730v1",
    "title": "Clinical Document Metadata Extraction: A Scoping Review",
    "authors": [
      "Kurt Miller",
      "Qiuhao Lu",
      "William Hersh",
      "Kirk Roberts",
      "Steven Bedrick",
      "Andrew Wen",
      "Hongfang Liu"
    ],
    "abstract": "Clinical document metadata, such as document type, structure, author role, medical specialty, and encounter setting, is essential for accurate interpretation of information captured in clinical documents. However, vast documentation heterogeneity and drift over time challenge harmonization of document metadata. Automated extraction methods have emerged to coalesce metadata from disparate practices into target schema. This scoping review aims to catalog research on clinical document metadata extraction, identify methodological trends and applications, and highlight gaps. We followed the PRISMA-ScR (Preferred Reporting Items for Systematic Reviews and Meta-Analyses Extension for Scoping Reviews) guidelines to identify articles that perform clinical document metadata extraction. We initially found and screened 266 articles published between January 2011 and August 2025, then comprehensively reviewed 67 we deemed relevant to our study. Among the articles included, 45 were methodological, 17 used document metadata as features in a downstream application, and 5 analyzed document metadata composition. We observe myriad purposes for methodological study and application types. Available labelled public data remains sparse except for structural section datasets. Methods for extracting document metadata have progressed from largely rule-based and traditional machine learning with ample feature engineering to transformer-based architectures with minimal feature engineering. The emergence of large language models has enabled broader exploration of generalizability across tasks and datasets, allowing the possibility of advanced clinical text processing systems. We anticipate that research will continue to expand into richer document metadata representations and integrate further into clinical applications and workflows.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2601.09730v1",
    "published_date": "2025-12-28 17:21:16 UTC",
    "updated_date": "2025-12-28 17:21:16 UTC"
  },
  {
    "arxiv_id": "2512.22999v1",
    "title": "JADAI: Jointly Amortizing Adaptive Design and Bayesian Inference",
    "authors": [
      "Niels Bracher",
      "Lars Kühmichel",
      "Desi R. Ivanova",
      "Xavier Intes",
      "Paul-Christian Bürkner",
      "Stefan T. Radev"
    ],
    "abstract": "We consider problems of parameter estimation where design variables can be actively optimized to maximize information gain. To this end, we introduce JADAI, a framework that jointly amortizes Bayesian adaptive design and inference by training a policy, a history network, and an inference network end-to-end. The networks minimize a generic loss that aggregates incremental reductions in posterior error along experimental sequences. Inference networks are instantiated with diffusion-based posterior estimators that can approximate high-dimensional and multimodal posteriors at every experimental step. Across standard adaptive design benchmarks, JADAI achieves superior or competitive performance.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "stat.ML",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.22999v1",
    "published_date": "2025-12-28 16:54:43 UTC",
    "updated_date": "2025-12-28 16:54:43 UTC"
  },
  {
    "arxiv_id": "2601.09729v1",
    "title": "Enhancing Business Analytics through Hybrid Summarization of Financial Reports",
    "authors": [
      "Tohida Rehman"
    ],
    "abstract": "Financial reports and earnings communications contain large volumes of structured and semi structured information, making detailed manual analysis inefficient. Earnings conference calls provide valuable evidence about a firm's performance, outlook, and strategic priorities. The manual analysis of lengthy call transcripts requires substantial effort and is susceptible to interpretive bias and unintentional error. In this work, we present a hybrid summarization framework that combines extractive and abstractive techniques to produce concise and factually reliable Reuters-style summaries from the ECTSum dataset. The proposed two stage pipeline first applies the LexRank algorithm to identify salient sentences, which are subsequently summarized using fine-tuned variants of BART and PEGASUS designed for resource constrained settings. In parallel, we fine-tune a Longformer Encoder-Decoder (LED) model to directly capture long-range contextual dependencies in financial documents.\n  Model performance is evaluated using standard automatic metrics, including ROUGE, METEOR, MoverScore, and BERTScore, along with domain-specific variants such as SciBERTScore and FinBERTScore. To assess factual accuracy, we further employ entity-level measures based on source-precision and F1-target. The results highlight complementary trade offs between approaches, long context models yield the strongest overall performance, while the hybrid framework achieves competitive results with improved factual consistency under computational constraints. These findings support the development of practical summarization systems for efficiently distilling lengthy financial texts into usable business insights.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "12 pages, 2 figures, 2 tables",
    "pdf_url": "https://arxiv.org/pdf/2601.09729v1",
    "published_date": "2025-12-28 16:25:12 UTC",
    "updated_date": "2025-12-28 16:25:12 UTC"
  },
  {
    "arxiv_id": "2601.00843v1",
    "title": "OmniNeuro: A Multimodal HCI Framework for Explainable BCI Feedback via Generative AI and Sonification",
    "authors": [
      "Ayda Aghaei Nia"
    ],
    "abstract": "While Deep Learning has improved Brain-Computer Interface (BCI) decoding accuracy, clinical adoption is hindered by the \"Black Box\" nature of these algorithms, leading to user frustration and poor neuroplasticity outcomes. We propose OmniNeuro, a novel HCI framework that transforms the BCI from a silent decoder into a transparent feedback partner. OmniNeuro integrates three interpretability engines: (1) Physics (Energy), (2) Chaos (Fractal Complexity), and (3) Quantum-Inspired uncertainty modeling. These metrics drive real-time Neuro-Sonification and Generative AI Clinical Reports. Evaluated on the PhysioNet dataset ($N=109$), the system achieved a mean accuracy of 58.52%, with qualitative pilot studies ($N=3$) confirming that explainable feedback helps users regulate mental effort and reduces the \"trial-and-error\" phase. OmniNeuro is decoder-agnostic, acting as an essential interpretability layer for any state-of-the-art architecture.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "16 pages, 7 figures, 3 tables. Source code and implementation available at: https://github.com/ayda-aghaei/OmniNeuro. Highlights the use of LLMs (Gemini) and Quantum probability formalism for real-time BCI explainability",
    "pdf_url": "https://arxiv.org/pdf/2601.00843v1",
    "published_date": "2025-12-28 16:06:55 UTC",
    "updated_date": "2025-12-28 16:06:55 UTC"
  },
  {
    "arxiv_id": "2512.22953v1",
    "title": "APO: Alpha-Divergence Preference Optimization",
    "authors": [
      "Wang Zixian"
    ],
    "abstract": "Two divergence regimes dominate modern alignment practice. Supervised fine-tuning and many distillation-style objectives implicitly minimize the forward KL divergence KL(q || pi_theta), yielding stable mode-covering updates but often under-exploiting high-reward modes. In contrast, PPO-style online reinforcement learning from human feedback behaves closer to reverse KL divergence KL(pi_theta || q), enabling mode-seeking improvements but risking mode collapse. Recent anchored methods, such as ADPO, show that performing the projection in anchored coordinates can substantially improve stability, yet they typically commit to a single divergence. We introduce Alpha-Divergence Preference Optimization (APO), an anchored framework that uses Csiszar alpha-divergence to continuously interpolate between forward and reverse KL behavior within the same anchored geometry. We derive unified gradient dynamics parameterized by alpha, analyze gradient variance properties, and propose a practical reward-and-confidence-guarded alpha schedule that transitions from coverage to exploitation only when the policy is both improving and confidently calibrated. Experiments on Qwen3-1.7B with math-level3 demonstrate that APO achieves competitive performance with GRPO and GSPO baselines while maintaining training stability.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.22953v1",
    "published_date": "2025-12-28 14:51:03 UTC",
    "updated_date": "2025-12-28 14:51:03 UTC"
  },
  {
    "arxiv_id": "2512.22941v1",
    "title": "Heterogeneity in Multi-Agent Reinforcement Learning",
    "authors": [
      "Tianyi Hu",
      "Zhiqiang Pu",
      "Yuan Wang",
      "Tenghai Qiu",
      "Min Chen",
      "Xin Yu"
    ],
    "abstract": "Heterogeneity is a fundamental property in multi-agent reinforcement learning (MARL), which is closely related not only to the functional differences of agents, but also to policy diversity and environmental interactions. However, the MARL field currently lacks a rigorous definition and deeper understanding of heterogeneity. This paper systematically discusses heterogeneity in MARL from the perspectives of definition, quantification, and utilization. First, based on an agent-level modeling of MARL, we categorize heterogeneity into five types and provide mathematical definitions. Second, we define the concept of heterogeneity distance and propose a practical quantification method. Third, we design a heterogeneity-based multi-agent dynamic parameter sharing algorithm as an example of the application of our methodology. Case studies demonstrate that our method can effectively identify and quantify various types of agent heterogeneity. Experimental results show that the proposed algorithm, compared to other parameter sharing baselines, has better interpretability and stronger adaptability. The proposed methodology will help the MARL community gain a more comprehensive and profound understanding of heterogeneity, and further promote the development of practical algorithms.",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "primary_category": "cs.MA",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.22941v1",
    "published_date": "2025-12-28 14:07:31 UTC",
    "updated_date": "2025-12-28 14:07:31 UTC"
  },
  {
    "arxiv_id": "2512.22933v3",
    "title": "Multimodal Fact-Checking: An Agent-based Approach",
    "authors": [
      "Danni Xu",
      "Shaojing Fan",
      "Harry Cheng",
      "Mohan Kankanhalli"
    ],
    "abstract": "The rapid spread of multimodal misinformation poses a growing challenge for automated fact-checking systems. Existing approaches, including large vision language models (LVLMs) and deep multimodal fusion methods, often fall short due to limited reasoning and shallow evidence utilization. A key bottleneck is the lack of dedicated datasets that provide complete real-world multimodal misinformation instances accompanied by annotated reasoning processes and verifiable evidence. To address this limitation, we introduce RW-Post, a high-quality and explainable dataset for real-world multimodal fact-checking. RW-Post aligns real-world multimodal claims with their original social media posts, preserving the rich contextual information in which the claims are made. In addition, the dataset includes detailed reasoning and explicitly linked evidence, which are derived from human written fact-checking articles via a large language model assisted extraction pipeline, enabling comprehensive verification and explanation. Building upon RW-Post, we propose AgentFact, an agent-based multimodal fact-checking framework designed to emulate the human verification workflow. AgentFact consists of five specialized agents that collaboratively handle key fact-checking subtasks, including strategy planning, high-quality evidence retrieval, visual analysis, reasoning, and explanation generation. These agents are orchestrated through an iterative workflow that alternates between evidence searching and task-aware evidence filtering and reasoning, facilitating strategic decision-making and systematic evidence analysis. Extensive experimental results demonstrate that the synergy between RW-Post and AgentFact substantially improves both the accuracy and interpretability of multimodal fact-checking.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "Code and dataset will be released at https://github.com/xudanni0927/AgentFact",
    "pdf_url": "https://arxiv.org/pdf/2512.22933v3",
    "published_date": "2025-12-28 13:58:33 UTC",
    "updated_date": "2026-01-04 06:59:31 UTC"
  },
  {
    "arxiv_id": "2512.22931v1",
    "title": "Geometric Structural Knowledge Graph Foundation Model",
    "authors": [
      "Ling Xin",
      "Mojtaba Nayyeri",
      "Zahra Makki Nayeri",
      "Steffen Staab"
    ],
    "abstract": "Structural knowledge graph foundation models aim to generalize reasoning to completely new graphs with unseen entities and relations. A key limitation of existing approaches like Ultra is their reliance on a single relational transformation (e.g., element-wise multiplication) in message passing, which can constrain expressiveness and fail to capture diverse relational and structural patterns exhibited on diverse graphs. In this paper, we propose Gamma, a novel foundation model that introduces multi-head geometric attention to knowledge graph reasoning. Gamma replaces the single relational transformation with multiple parallel ones, including real, complex, split-complex, and dual number based transformations, each designed to model different relational structures. A relational conditioned attention fusion mechanism then adaptively fuses them at link level via a lightweight gating with entropy regularization, allowing the model to robustly emphasize the most appropriate relational bias for each triple pattern. We present a full formalization of these algebraic message functions and discuss how their combination increases expressiveness beyond any single space. Comprehensive experiments on 56 diverse knowledge graphs demonstrate that Gamma consistently outperforms Ultra in zero-shot inductive link prediction, with a 5.5% improvement in mean reciprocal rank on the inductive benchmarks and a 4.4% improvement across all benchmarks, highlighting benefits from complementary geometric representations.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Submitted to IEEE TPAMI, under review",
    "pdf_url": "https://arxiv.org/pdf/2512.22931v1",
    "published_date": "2025-12-28 13:53:23 UTC",
    "updated_date": "2025-12-28 13:53:23 UTC"
  },
  {
    "arxiv_id": "2601.09728v1",
    "title": "Eliminating Agentic Workflow for Introduction Generation with Parametric Stage Tokens",
    "authors": [
      "Meicong Zhang",
      "Tiancheng su",
      "Guoxiu He"
    ],
    "abstract": "In recent years, using predefined agentic workflows to guide large language models (LLMs) for literature classification and review has become a research focus. However, writing research introductions is more challenging. It requires rigorous logic, coherent structure, and abstract summarization. Existing workflows often suffer from long reasoning chains, error accumulation, and reduced textual coherence. To address these limitations, we propose eliminating external agentic workflows. Instead, we directly parameterize their logical structure into the LLM. This allows the generation of a complete introduction in a single inference. To this end, we introduce the Stage Token for Introduction Generation (STIG). STIG converts the multiple stages of the original workflow into explicit stage signals. These signals guide the model to follow different logical roles and functions during generation. Through instruction tuning, the model learns the mapping between stage tokens and text functions. It also learns the logical order and transition patterns between stages, encoding this knowledge into the model parameters. Experimental results show that STIG can generate multi-stage text in a single inference. It does not require explicit workflow calls. STIG outperforms traditional agentic workflows and other baselines on metrics of semantic similarity and sentence-level structural rationality. The code is provided in the Supplementary Materials.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2601.09728v1",
    "published_date": "2025-12-28 12:51:36 UTC",
    "updated_date": "2025-12-28 12:51:36 UTC"
  },
  {
    "arxiv_id": "2512.22910v1",
    "title": "Sat-EnQ: Satisficing Ensembles of Weak Q-Learners for Reliable and Compute-Efficient Reinforcement Learning",
    "authors": [
      "Ünver Çiftçi"
    ],
    "abstract": "Deep Q-learning algorithms remain notoriously unstable, especially during early training when the maximization operator amplifies estimation errors. Inspired by bounded rationality theory and developmental learning, we introduce Sat-EnQ, a two-phase framework that first learns to be ``good enough'' before optimizing aggressively. In Phase 1, we train an ensemble of lightweight Q-networks under a satisficing objective that limits early value growth using a dynamic baseline, producing diverse, low-variance estimates while avoiding catastrophic overestimation. In Phase 2, the ensemble is distilled into a larger network and fine-tuned with standard Double DQN. We prove theoretically that satisficing induces bounded updates and cannot increase target variance, with a corollary quantifying conditions for substantial reduction. Empirically, Sat-EnQ achieves 3.8x variance reduction, eliminates catastrophic failures (0% vs 50% for DQN), maintains 79% performance under environmental noise}, and requires 2.5x less compute than bootstrapped ensembles. Our results highlight a principled path toward robust reinforcement learning by embracing satisficing before optimization.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.22910v1",
    "published_date": "2025-12-28 12:41:09 UTC",
    "updated_date": "2025-12-28 12:41:09 UTC"
  },
  {
    "arxiv_id": "2601.09727v1",
    "title": "SciNets: Graph-Constrained Multi-Hop Reasoning for Scientific Literature Synthesis",
    "authors": [
      "Sauhard Dubey"
    ],
    "abstract": "Cross-domain scientific synthesis requires connecting mechanistic explanations across fragmented literature, a capability that remains challenging for both retrieval-based systems and unconstrained language models. While recent work has applied large language models to scientific summarization and question answering, these approaches provide limited control over reasoning depth and structural grounding. We frame mechanistic synthesis as a graph-constrained multi-hop reasoning problem over literature-derived concept graphs. Given a scientific query and a compact, query-local corpus, SciNets constructs a directed concept graph and synthesizes mechanistic explanations by identifying multi-hop reasoning paths that connect concepts that rarely co-occur within individual papers. We systematically compare shortest-path reasoning, k-shortest paths with diversity constraints, stochastic random walks, and a retrieval-augmented language model baseline. Rather than evaluating correctness, which is often indeterminate when synthesizing connections across distributed sources, we introduce a behavioral framework that measures symbolic reasoning depth, mechanistic diversity, and grounding stability. Across machine learning, biology, and climate science tasks, explicit graph constraints enable controllable multi-hop reasoning while revealing a consistent trade-off: deeper and more diverse symbolic reasoning increases grounding instability, whereas shortest-path reasoning remains highly stable but structurally conservative. These findings provide a systematic behavioral characterization of the limits and capabilities of current graph-LLM integration for scientific synthesis.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "19 pages, 2 figures",
    "pdf_url": "https://arxiv.org/pdf/2601.09727v1",
    "published_date": "2025-12-28 12:27:42 UTC",
    "updated_date": "2025-12-28 12:27:42 UTC"
  },
  {
    "arxiv_id": "2512.22901v1",
    "title": "A Neural Network-Based Real-time Casing Collar Recognition System for Downhole Instruments",
    "authors": [
      "Si-Yu Xiao",
      "Xin-Di Zhao",
      "Xiang-Zhan Wang",
      "Tian-Hao Mao",
      "Ying-Kai Liao",
      "Xing-Yu Liao",
      "Yu-Qiao Chen",
      "Jun-Jie Wang",
      "Shuang Liu",
      "Tu-Pei Chen",
      "Yang Liu"
    ],
    "abstract": "Accurate downhole positioning is critical in oil and gas operations but is often compromised by signal degradation in traditional surface-based Casing Collar Locator (CCL) monitoring. To address this, we present an in-situ, real-time collar recognition system using embedded neural network. We introduce lightweight \"Collar Recognition Nets\" (CRNs) optimized for resource-constrained ARM Cortex-M7 microprocessors. By leveraging temporal and depthwise separable convolutions, our most compact model reduces computational complexity to just 8,208 MACs while maintaining an F1 score of 0.972. Hardware validation confirms an average inference latency of 343.2 μs, demonstrating that robust, autonomous signal processing is feasible within the severe power and space limitations of downhole instrumentation.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.LG",
      "eess.SP"
    ],
    "primary_category": "eess.SY",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.22901v1",
    "published_date": "2025-12-28 12:19:36 UTC",
    "updated_date": "2025-12-28 12:19:36 UTC"
  },
  {
    "arxiv_id": "2512.22899v1",
    "title": "HiSciBench: A Hierarchical Multi-disciplinary Benchmark for Scientific Intelligence from Reading to Discovery",
    "authors": [
      "Yaping Zhang",
      "Qixuan Zhang",
      "Xingquan Zhang",
      "Zhiyuan Chen",
      "Wenwen Zhuang",
      "Yupu Liang",
      "Lu Xiang",
      "Yang Zhao",
      "Jiajun Zhang",
      "Yu Zhou",
      "Chengqing Zong"
    ],
    "abstract": "The rapid advancement of large language models (LLMs) and multimodal foundation models has sparked growing interest in their potential for scientific research. However, scientific intelligence encompasses a broad spectrum of abilities ranging from understanding fundamental knowledge to conducting creative discovery, and existing benchmarks remain fragmented. Most focus on narrow tasks and fail to reflect the hierarchical and multi-disciplinary nature of real scientific inquiry. We introduce \\textbf{HiSciBench}, a hierarchical benchmark designed to evaluate foundation models across five levels that mirror the complete scientific workflow: \\textit{Scientific Literacy} (L1), \\textit{Literature Parsing} (L2), \\textit{Literature-based Question Answering} (L3), \\textit{Literature Review Generation} (L4), and \\textit{Scientific Discovery} (L5). HiSciBench contains 8,735 carefully curated instances spanning six major scientific disciplines, including mathematics, physics, chemistry, biology, geography, and astronomy, and supports multimodal inputs including text, equations, figures, and tables, as well as cross-lingual evaluation. Unlike prior benchmarks that assess isolated abilities, HiSciBench provides an integrated, dependency-aware framework that enables detailed diagnosis of model capabilities across different stages of scientific reasoning. Comprehensive evaluations of leading models, including GPT-5, DeepSeek-R1, and several multimodal systems, reveal substantial performance gaps: while models achieve up to 69\\% accuracy on basic literacy tasks, performance declines sharply to 25\\% on discovery-level challenges. HiSciBench establishes a new standard for evaluating scientific Intelligence and offers actionable insights for developing models that are not only more capable but also more reliable. The benchmark will be publicly released to facilitate future research.",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.22899v1",
    "published_date": "2025-12-28 12:08:05 UTC",
    "updated_date": "2025-12-28 12:08:05 UTC"
  },
  {
    "arxiv_id": "2512.22895v1",
    "title": "SAMP-HDRL: Segmented Allocation with Momentum-Adjusted Utility for Multi-agent Portfolio Management via Hierarchical Deep Reinforcement Learning",
    "authors": [
      "Xiaotian Ren",
      "Nuerxiati Abudurexiti",
      "Zhengyong Jiang",
      "Angelos Stefanidis",
      "Hongbin Liu",
      "Jionglong Su"
    ],
    "abstract": "Portfolio optimization in non-stationary markets is challenging due to regime shifts, dynamic correlations, and the limited interpretability of deep reinforcement learning (DRL) policies. We propose a Segmented Allocation with Momentum-Adjusted Utility for Multi-agent Portfolio Management via Hierarchical Deep Reinforcement Learning (SAMP-HDRL). The framework first applies dynamic asset grouping to partition the market into high-quality and ordinary subsets. An upper-level agent extracts global market signals, while lower-level agents perform intra-group allocation under mask constraints. A utility-based capital allocation mechanism integrates risky and risk-free assets, ensuring coherent coordination between global and local decisions. backtests across three market regimes (2019--2021) demonstrate that SAMP-HDRL consistently outperforms nine traditional baselines and nine DRL benchmarks under volatile and oscillating conditions. Compared with the strongest baseline, our method achieves at least 5\\% higher Return, 5\\% higher Sharpe ratio, 5\\% higher Sortino ratio, and 2\\% higher Omega ratio, with substantially larger gains observed in turbulent markets. Ablation studies confirm that upper--lower coordination, dynamic clustering, and capital allocation are indispensable to robustness. SHAP-based interpretability further reveals a complementary ``diversified + concentrated'' mechanism across agents, providing transparent insights into decision-making. Overall, SAMP-HDRL embeds structural market constraints directly into the DRL pipeline, offering improved adaptability, robustness, and interpretability in complex financial environments.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.22895v1",
    "published_date": "2025-12-28 11:56:39 UTC",
    "updated_date": "2025-12-28 11:56:39 UTC"
  },
  {
    "arxiv_id": "2512.22894v1",
    "title": "DECEPTICON: How Dark Patterns Manipulate Web Agents",
    "authors": [
      "Phil Cuvin",
      "Hao Zhu",
      "Diyi Yang"
    ],
    "abstract": "Deceptive UI designs, widely instantiated across the web and commonly known as dark patterns, manipulate users into performing actions misaligned with their goals. In this paper, we show that dark patterns are highly effective in steering agent trajectories, posing a significant risk to agent robustness. To quantify this risk, we introduce DECEPTICON, an environment for testing individual dark patterns in isolation. DECEPTICON includes 700 web navigation tasks with dark patterns -- 600 generated tasks and 100 real-world tasks, designed to measure instruction-following success and dark pattern effectiveness. Across state-of-the-art agents, we find dark patterns successfully steer agent trajectories towards malicious outcomes in over 70% of tested generated and real-world tasks -- compared to a human average of 31%. Moreover, we find that dark pattern effectiveness correlates positively with model size and test-time reasoning, making larger, more capable models more susceptible. Leading countermeasures against adversarial attacks, including in-context prompting and guardrail models, fail to consistently reduce the success rate of dark pattern interventions. Our findings reveal dark patterns as a latent and unmitigated risk to web agents, highlighting the urgent need for robust defenses against manipulative designs.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.22894v1",
    "published_date": "2025-12-28 11:55:20 UTC",
    "updated_date": "2025-12-28 11:55:20 UTC"
  },
  {
    "arxiv_id": "2512.22883v1",
    "title": "Agentic AI for Cyber Resilience: A New Security Paradigm and Its System-Theoretic Foundations",
    "authors": [
      "Tao Li",
      "Quanyan Zhu"
    ],
    "abstract": "Cybersecurity is being fundamentally reshaped by foundation-model-based artificial intelligence. Large language models now enable autonomous planning, tool orchestration, and strategic adaptation at scale, challenging security architectures built on static rules, perimeter defenses, and human-centered workflows. This chapter argues for a shift from prevention-centric security toward agentic cyber resilience. Rather than seeking perfect protection, resilient systems must anticipate disruption, maintain critical functions under attack, recover efficiently, and learn continuously. We situate this shift within the historical evolution of cybersecurity paradigms, culminating in an AI-augmented paradigm where autonomous agents participate directly in sensing, reasoning, action, and adaptation across cyber and cyber-physical systems. We then develop a system-level framework for designing agentic AI workflows. A general agentic architecture is introduced, and attacker and defender workflows are analyzed as coupled adaptive processes, and game-theoretic formulations are shown to provide a unifying design language for autonomy allocation, information flow, and temporal composition. Case studies in automated penetration testing, remediation, and cyber deception illustrate how equilibrium-based design enables system-level resiliency design.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.22883v1",
    "published_date": "2025-12-28 11:17:36 UTC",
    "updated_date": "2025-12-28 11:17:36 UTC"
  },
  {
    "arxiv_id": "2512.22878v1",
    "title": "SwinTF3D: A Lightweight Multimodal Fusion Approach for Text-Guided 3D Medical Image Segmentation",
    "authors": [
      "Hasan Faraz Khan",
      "Noor Fatima",
      "Muzammil Behzad"
    ],
    "abstract": "The recent integration of artificial intelligence into medical imaging has driven remarkable advances in automated organ segmentation. However, most existing 3D segmentation frameworks rely exclusively on visual learning from large annotated datasets restricting their adaptability to new domains and clinical tasks. The lack of semantic understanding in these models makes them ineffective in addressing flexible, user-defined segmentation objectives. To overcome these limitations, we propose SwinTF3D, a lightweight multimodal fusion approach that unifies visual and linguistic representations for text-guided 3D medical image segmentation. The model employs a transformer-based visual encoder to extract volumetric features and integrates them with a compact text encoder via an efficient fusion mechanism. This design allows the system to understand natural-language prompts and correctly align semantic cues with their corresponding spatial structures in medical volumes, while producing accurate, context-aware segmentation results with low computational overhead. Extensive experiments on the BTCV dataset demonstrate that SwinTF3D achieves competitive Dice and IoU scores across multiple organs, despite its compact architecture. The model generalizes well to unseen data and offers significant efficiency gains compared to conventional transformer-based segmentation networks. Bridging visual perception with linguistic understanding, SwinTF3D establishes a practical and interpretable paradigm for interactive, text-driven 3D medical image segmentation, opening perspectives for more adaptive and resource-efficient solutions in clinical imaging.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.22878v1",
    "published_date": "2025-12-28 11:00:05 UTC",
    "updated_date": "2025-12-28 11:00:05 UTC"
  },
  {
    "arxiv_id": "2512.22876v1",
    "title": "Reinforcement Networks: novel framework for collaborative Multi-Agent Reinforcement Learning tasks",
    "authors": [
      "Maksim Kryzhanovskiy",
      "Svetlana Glazyrina",
      "Roman Ischenko",
      "Konstantin Vorontsov"
    ],
    "abstract": "Modern AI systems often comprise multiple learnable components that can be naturally organized as graphs. A central challenge is the end-to-end training of such systems without restrictive architectural or training assumptions. Such tasks fit the theory and approaches of the collaborative Multi-Agent Reinforcement Learning (MARL) field. We introduce Reinforcement Networks, a general framework for MARL that organizes agents as vertices in a directed acyclic graph (DAG). This structure extends hierarchical RL to arbitrary DAGs, enabling flexible credit assignment and scalable coordination while avoiding strict topologies, fully centralized training, and other limitations of current approaches. We formalize training and inference methods for the Reinforcement Networks framework and connect it to the LevelEnv concept to support reproducible construction, training, and evaluation. We demonstrate the effectiveness of our approach on several collaborative MARL setups by developing several Reinforcement Networks models that achieve improved performance over standard MARL baselines. Beyond empirical gains, Reinforcement Networks unify hierarchical, modular, and graph-structured views of MARL, opening a principled path toward designing and training complex multi-agent systems. We conclude with theoretical and practical directions - richer graph morphologies, compositional curricula, and graph-aware exploration. That positions Reinforcement Networks as a foundation for a new line of research in scalable, structured MARL.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.MA",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.22876v1",
    "published_date": "2025-12-28 10:56:20 UTC",
    "updated_date": "2025-12-28 10:56:20 UTC"
  },
  {
    "arxiv_id": "2512.22868v1",
    "title": "The body is not there to compute: Comment on \"Informational embodiment: Computational role of information structure in codes and robots\" by Pitti et al",
    "authors": [
      "Matej Hoffmann"
    ],
    "abstract": "Applying the lens of computation and information has been instrumental in driving the technological progress of our civilization as well as in empowering our understanding of the world around us. The digital computer was and for many still is the leading metaphor for how our mind operates. Information theory (IT) has also been important in our understanding of how nervous systems encode and process information. The target article deploys information and computation to bodies: to understand why they have evolved in particular ways (animal bodies) and to design optimal bodies (robots). In this commentary, I argue that the main role of bodies is not to compute.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "q-bio.NC",
      "q-bio.QM"
    ],
    "primary_category": "cs.RO",
    "comment": "Comment on Pitti, A., Austin, M., Nakajima, K., & Kuniyoshi, Y. (2025). Informational Embodiment: Computational role of information structure in codes and robots. Physics of Life Reviews 53, 262-276. https://doi.org/10.1016/j.plrev.2025.03.018. Also available as arXiv:2408.12950",
    "pdf_url": "https://arxiv.org/pdf/2512.22868v1",
    "published_date": "2025-12-28 10:44:53 UTC",
    "updated_date": "2025-12-28 10:44:53 UTC"
  },
  {
    "arxiv_id": "2601.09726v1",
    "title": "Forgetting as a Feature: Cognitive Alignment of Large Language Models",
    "authors": [
      "Hien Tran",
      "Quinten Steenhuis",
      "Alexandros Christoforos",
      "Chadbourne Davis"
    ],
    "abstract": "Large Language Models (LLMs) are often evaluated against ideals of perfect Bayesian inference, yet growing evidence suggests that their in-context reasoning exhibits systematic forgetting of past information. Rather than viewing this behavior as a limitation, we reinterpret forgetting as a functional cognitive mechanism. Drawing inspiration from human memory dynamics, we model LLM inference as a probabilistic memory process governed by exponential decay. We introduce a benchmark suite that evaluates temporal reasoning, concept drift adaptation, and associative recall, enabling direct comparison between model behavior and human cognitive patterns. Our empirical results reveal that LLMs demonstrate forgetting rates analogous to human memory efficiency trade-offs between stability and adaptability. Building on these observations, we propose probabilistic memory prompting, a lightweight strategy that shapes evidence integration to mimic human-like memory decay, leading to improved long-horizon reasoning performance. Our findings position forgetting not as a failure mode, but as a principled mechanism for adaptive intelligence.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Under submission",
    "pdf_url": "https://arxiv.org/pdf/2601.09726v1",
    "published_date": "2025-12-28 10:43:00 UTC",
    "updated_date": "2025-12-28 10:43:00 UTC"
  },
  {
    "arxiv_id": "2512.22857v1",
    "title": "AutoForge: Automated Environment Synthesis for Agentic Reinforcement Learning",
    "authors": [
      "Shihao Cai",
      "Runnan Fang",
      "Jialong Wu",
      "Baixuan Li",
      "Xinyu Wang",
      "Yong Jiang",
      "Liangcai Su",
      "Liwen Zhang",
      "Wenbiao Yin",
      "Zhen Zhang",
      "Fuli Feng",
      "Pengjun Xie",
      "Xiaobin Wang"
    ],
    "abstract": "Conducting reinforcement learning (RL) in simulated environments offers a cost-effective and highly scalable way to enhance language-based agents. However, previous work has been limited to semi-automated environment synthesis or tasks lacking sufficient difficulty, offering little breadth or depth. In addition, the instability of simulated users integrated into these environments, along with the heterogeneity across simulated environments, poses further challenges for agentic RL. In this work, we propose: (1) a unified pipeline for automated and scalable synthesis of simulated environments associated with high-difficulty but easily verifiable tasks; and (2) an environment level RL algorithm that not only effectively mitigates user instability but also performs advantage estimation at the environment level, thereby improving training efficiency and stability. Comprehensive evaluations on agentic benchmarks, including tau-bench, tau2-Bench, and VitaBench, validate the effectiveness of our proposed method. Further in-depth analyses underscore its out-of-domain generalization.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.22857v1",
    "published_date": "2025-12-28 09:43:11 UTC",
    "updated_date": "2025-12-28 09:43:11 UTC"
  },
  {
    "arxiv_id": "2512.22827v1",
    "title": "FasterPy: An LLM-based Code Execution Efficiency Optimization Framework",
    "authors": [
      "Yue Wu",
      "Minghao Han",
      "Ruiyin Li",
      "Peng Liang",
      "Amjed Tahir",
      "Zengyang Li",
      "Qiong Feng",
      "Mojtaba Shahin"
    ],
    "abstract": "Code often suffers from performance bugs. These bugs necessitate the research and practice of code optimization. Traditional rule-based methods rely on manually designing and maintaining rules for specific performance bugs (e.g., redundant loops, repeated computations), making them labor-intensive and limited in applicability. In recent years, machine learning and deep learning-based methods have emerged as promising alternatives by learning optimization heuristics from annotated code corpora and performance measurements. However, these approaches usually depend on specific program representations and meticulously crafted training datasets, making them costly to develop and difficult to scale. With the booming of Large Language Models (LLMs), their remarkable capabilities in code generation have opened new avenues for automated code optimization. In this work, we proposed FasterPy, a low-cost and efficient framework that adapts LLMs to optimize the execution efficiency of Python code. FasterPy combines Retrieval-Augmented Generation (RAG), supported by a knowledge base constructed from existing performance-improving code pairs and corresponding performance measurements, with Low-Rank Adaptation (LoRA) to enhance code optimization performance. Our experimental results on the Performance Improving Code Edits (PIE) benchmark demonstrate that our method outperforms existing models on multiple metrics. The FasterPy tool and the experimental results are available at https://github.com/WuYue22/fasterpy.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "32 pages, 5 images, 7 tables, Manuscript submitted to a Journal (2025)",
    "pdf_url": "https://arxiv.org/pdf/2512.22827v1",
    "published_date": "2025-12-28 07:43:08 UTC",
    "updated_date": "2025-12-28 07:43:08 UTC"
  },
  {
    "arxiv_id": "2601.06066v1",
    "title": "TEAS: Trusted Educational AI Standard: A Framework for Verifiable, Stable, Auditable, and Pedagogically Sound Learning Systems",
    "authors": [
      "Abu Syed"
    ],
    "abstract": "The rapid integration of AI into education has prioritized capability over trustworthiness, creating significant risks. Real-world deployments reveal that even advanced models are insufficient without extensive architectural scaffolding to ensure reliability. Current evaluation frameworks are fragmented: institutional policies lack technical verification, pedagogical guidelines assume AI reliability, and technical metrics are context-agnostic. This leaves institutions without a unified standard for deployment readiness. This paper introduces TEAS (Trusted Educational AI Standard), an integrated framework built on four interdependent pillars: (1) Verifiability, grounding content in authoritative sources; (2) Stability, ensuring deterministic core knowledge; (3) Auditability, enabling independent institutional validation; and (4) Pedagogical Soundness, enforcing principles of active learning. We argue that trustworthiness stems primarily from systematic architecture, not raw model capability. This insight implies that affordable, open-source models can achieve deployment-grade trust, offering a scalable and equitable path to integrating AI safely into learning environments globally.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "19 pages, 6 tables, accepted at AAAI-26 (DAI Workshop) in Singapore",
    "pdf_url": "https://arxiv.org/pdf/2601.06066v1",
    "published_date": "2025-12-28 07:40:26 UTC",
    "updated_date": "2025-12-28 07:40:26 UTC"
  },
  {
    "arxiv_id": "2512.22808v2",
    "title": "EgoReAct: Egocentric Video-Driven 3D Human Reaction Generation",
    "authors": [
      "Libo Zhang",
      "Zekun Li",
      "Tianyu Li",
      "Zeyu Cao",
      "Rui Xu",
      "Xiaoxiao Long",
      "Wenjia Wang",
      "Jingbo Wang",
      "Yuan Liu",
      "Wenping Wang",
      "Daquan Zhou",
      "Taku Komura",
      "Zhiyang Dou"
    ],
    "abstract": "Humans exhibit adaptive, context-sensitive responses to egocentric visual input. However, faithfully modeling such reactions from egocentric video remains challenging due to the dual requirements of strictly causal generation and precise 3D spatial alignment. To tackle this problem, we first construct the Human Reaction Dataset (HRD) to address data scarcity and misalignment by building a spatially aligned egocentric video-reaction dataset, as existing datasets (e.g., ViMo) suffer from significant spatial inconsistency between the egocentric video and reaction motion, e.g., dynamically moving motions are always paired with fixed-camera videos. Leveraging HRD, we present EgoReAct, the first autoregressive framework that generates 3D-aligned human reaction motions from egocentric video streams in real-time. We first compress the reaction motion into a compact yet expressive latent space via a Vector Quantised-Variational AutoEncoder and then train a Generative Pre-trained Transformer for reaction generation from the visual input. EgoReAct incorporates 3D dynamic features, i.e., metric depth, and head dynamics during the generation, which effectively enhance spatial grounding. Extensive experiments demonstrate that EgoReAct achieves remarkably higher realism, spatial consistency, and generation efficiency compared with prior methods, while maintaining strict causality during generation. We will release code, models, and data upon acceptance.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "12 pages, 9 figures",
    "pdf_url": "https://arxiv.org/pdf/2512.22808v2",
    "published_date": "2025-12-28 06:44:05 UTC",
    "updated_date": "2026-01-03 03:38:31 UTC"
  },
  {
    "arxiv_id": "2512.22804v1",
    "title": "MoR: Mixture Of Representations For Mixed-Precision Training",
    "authors": [
      "Bor-Yiing Su",
      "Peter Dykas",
      "Mike Chrzanowski",
      "Jatin Chhugani"
    ],
    "abstract": "Mixed-precision training is a crucial technique for scaling deep learning models, but successful mixedprecision training requires identifying and applying the right combination of training methods. This paper presents our preliminary study on Mixture-of-Representations (MoR), a novel, per-tensor and sub-tensor level quantization framework that dynamically analyzes a tensor's numerical properties to select between a variety of different representations. Based on the framework, we have proposed and experimented concrete algorithms that choose dynamically between FP8 and BF16 representations for both per-tensor and sub-tensor level granularities. Our universal approach is designed to preserve model quality across various quantization partition strategies and datasets. Our initial findings show that this approach can achieve state-of-the-art results with 98.38% of tensors quantized to the FP8 format. This work highlights the potential of dynamic, property-aware quantization while preserving model quality. We believe this approach can generally improve the robustness of low precision training, as demonstrated by achieving FP8 accuracies that are on par with existing approaches without the need for fine-grain partitioning, or can be used in combination with other training methods to improve the leverage of even lower precision number formats such as NVFP4.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.22804v1",
    "published_date": "2025-12-28 06:28:50 UTC",
    "updated_date": "2025-12-28 06:28:50 UTC"
  },
  {
    "arxiv_id": "2601.10726v1",
    "title": "Building AI Agents to Improve Job Referral Requests to Strangers",
    "authors": [
      "Ross Chu",
      "Yuting Huang"
    ],
    "abstract": "This paper develops AI agents that help job seekers write effective requests for job referrals in a professional online community. The basic workflow consists of an improver agent that rewrites the referral request and an evaluator agent that measures the quality of revisions using a model trained to predict the probability of receiving referrals from other users. Revisions suggested by the LLM (large language model) increase predicted success rates for weaker requests while reducing them for stronger requests. Enhancing the LLM with Retrieval-Augmented Generation (RAG) prevents edits that worsen stronger requests while it amplifies improvements for weaker requests. Overall, using LLM revisions with RAG increases the predicted success rate for weaker requests by 14\\% without degrading performance on stronger requests. Although improvements in model-predicted success do not guarantee more referrals in the real world, they provide low-cost signals for promising features before running higher-stakes experiments on real users.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2601.10726v1",
    "published_date": "2025-12-28 05:59:56 UTC",
    "updated_date": "2025-12-28 05:59:56 UTC"
  },
  {
    "arxiv_id": "2512.22795v1",
    "title": "CNSight: Evaluation of Clinical Note Segmentation Tools",
    "authors": [
      "Risha Surana",
      "Adrian Law",
      "Sunwoo Kim",
      "Rishab Sridhar",
      "Angxiao Han",
      "Peiyu Hong"
    ],
    "abstract": "Clinical notes are often stored in unstructured or semi-structured formats after extraction from electronic medical record (EMR) systems, which complicates their use for secondary analysis and downstream clinical applications. Reliable identification of section boundaries is a key step toward structuring these notes, as sections such as history of present illness, medications, and discharge instructions each provide distinct clinical contexts. In this work, we evaluate rule-based baselines, domain-specific transformer models, and large language models for clinical note segmentation using a curated dataset of 1,000 notes from MIMIC-IV. Our experiments show that large API-based models achieve the best overall performance, with GPT-5-mini reaching a best average F1 of 72.4 across sentence-level and freetext segmentation. Lightweight baselines remain competitive on structured sentence-level tasks but falter on unstructured freetext. Our results provide guidance for method selection and lay the groundwork for downstream tasks such as information extraction, cohort identification, and automated summarization.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.22795v1",
    "published_date": "2025-12-28 05:40:15 UTC",
    "updated_date": "2025-12-28 05:40:15 UTC"
  },
  {
    "arxiv_id": "2601.03277v1",
    "title": "MixRx: Predicting Drug Combination Interactions with LLMs",
    "authors": [
      "Risha Surana",
      "Cameron Saidock",
      "Hugo Chacon"
    ],
    "abstract": "MixRx uses Large Language Models (LLMs) to classify drug combination interactions as Additive, Synergistic, or Antagonistic, given a multi-drug patient history. We evaluate the performance of 4 models, GPT-2, Mistral Instruct 2.0, and the fine-tuned counterparts. Our results showed a potential for such an application, with the Mistral Instruct 2.0 Fine-Tuned model providing an average accuracy score on standard and perturbed datasets of 81.5%. This paper aims to further develop an upcoming area of research that evaluates if LLMs can be used for biological prediction tasks.",
    "categories": [
      "q-bio.OT",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "q-bio.OT",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2601.03277v1",
    "published_date": "2025-12-28 05:37:56 UTC",
    "updated_date": "2025-12-28 05:37:56 UTC"
  },
  {
    "arxiv_id": "2512.22793v1",
    "title": "Reach-Avoid Differential game with Reachability Analysis for UAVs: A decomposition approach",
    "authors": [
      "Minh Bui",
      "Simon Monckton",
      "Mo Chen"
    ],
    "abstract": "Reach-avoid (RA) games have significant applications in security and defense, particularly for unmanned aerial vehicles (UAVs). These problems are inherently challenging due to the need to consider obstacles, consider the adversarial nature of opponents, ensure optimality, and account for nonlinear dynamics. Hamilton-Jacobi (HJ) reachability analysis has emerged as a powerful tool for tackling these challenges; however, while it has been applied to games involving two spatial dimensions, directly extending this approach to three spatial dimensions is impossible due to high dimensionality. On the other hand, alternative approaches for solving RA games lack the generality to consider games with three spatial dimensions involving agents with non-trivial system dynamics. In this work, we propose a novel framework for dimensionality reduction by decomposing the problem into a horizontal RA sub-game and a vertical RA sub-game. We then solve each sub-game using HJ reachability analysis and consider second-order dynamics that account for the defender's acceleration. To reconstruct the solution to the original RA game from the sub-games, we introduce a HJ-based tracking control algorithm in each sub-game that not only guarantees capture of the attacker but also tracking of the attacker thereafter. We prove the conditions under which the capture guarantees are maintained. The effectiveness of our approach is demonstrated via numerical simulations, showing that the decomposition maintains optimality and guarantees in the original problem. Our methods are also validated in a Gazebo physics simulator, achieving successful capture of quadrotors in three spatial dimensions space for the first time to the best of our knowledge.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.GT"
    ],
    "primary_category": "eess.SY",
    "comment": "Paper version accepted to the Journal of Guidance, Control, and Dynamics (JGCD)",
    "pdf_url": "https://arxiv.org/pdf/2512.22793v1",
    "published_date": "2025-12-28 05:34:11 UTC",
    "updated_date": "2025-12-28 05:34:11 UTC"
  },
  {
    "arxiv_id": "2512.22792v2",
    "title": "A Universal and Robust Framework for Multiple Gas Recognition Based-on Spherical Normalization-Coupled Mahalanobis Algorithm",
    "authors": [
      "Shuai Chen",
      "Yang Song",
      "Chen Wang",
      "Ziran Wang"
    ],
    "abstract": "Electronic nose (E-nose) systems face two interconnected challenges in open-set gas recognition: feature distribution shift caused by signal drift and decision boundary failure induced by unknown gas interference. Existing methods predominantly rely on Euclidean distance or conventional classifiers, failing to account for anisotropic feature distributions and dynamic signal intensity variations. To address these issues, this study proposes the Spherical Normalization coupled Mahalanobis (SNM) module, a universal post-processing module for open-set gas recognition. First, it achieves geometric decoupling through cascaded batch and L2 normalization, projecting features onto a unit hypersphere to eliminate signal intensity fluctuations. Second, it utilizes Mahalanobis distance to construct adaptive ellipsoidal decision boundaries that conform to the anisotropic feature geometry. The architecture-agnostic SNM-Module seamlessly integrates with mainstream backbones including Convolutional Neural Network (CNN), Recurrent Neural Network (RNN), and Transformer. Experiments on the public Vergara dataset demonstrate that the Transformer+SNM configuration achieves near-theoretical-limit performance in discriminating among multiple target gases, with an AUROC of 0.9977 and an unknown gas detection rate of 99.57% at 5% false positive rate, significantly outperforming state-of-the-art methods with a 3.0% AUROC improvement and 91.0% standard deviation reduction compared to Class Anchor Clustering (CAC). The module maintains exceptional robustness across five sensor positions, with standard deviations below 0.0028. This work effectively addresses the critical challenge of simultaneously achieving high accuracy and high stability in open-set gas recognition, providing solid support for industrial E-nose deployment.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "comment": "27 pages, 8 figures, 4 tables",
    "pdf_url": "https://arxiv.org/pdf/2512.22792v2",
    "published_date": "2025-12-28 05:33:05 UTC",
    "updated_date": "2026-01-05 13:46:47 UTC"
  },
  {
    "arxiv_id": "2512.22777v1",
    "title": "Adapting, Fast and Slow: Transportable Circuits for Few-Shot Learning",
    "authors": [
      "Kasra Jalaldoust",
      "Elias Bareinboim"
    ],
    "abstract": "Generalization across the domains is not possible without asserting a structure that constrains the unseen target domain w.r.t. the source domain. Building on causal transportability theory, we design an algorithm for zero-shot compositional generalization which relies on access to qualitative domain knowledge in form of a causal graph for intra-domain structure and discrepancies oracle for inter-domain mechanism sharing. \\textit{Circuit-TR} learns a collection of modules (i.e., local predictors) from the source data, and transport/compose them to obtain a circuit for prediction in the target domain if the causal structure licenses. Furthermore, circuit transportability enables us to design a supervised domain adaptation scheme that operates without access to an explicit causal structure, and instead uses limited target data. Our theoretical results characterize classes of few-shot learnable tasks in terms of graphical circuit transportability criteria, and connects few-shot generalizability with the established notion of circuit size complexity; controlled simulations corroborate our theoretical results.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.22777v1",
    "published_date": "2025-12-28 04:38:43 UTC",
    "updated_date": "2025-12-28 04:38:43 UTC"
  },
  {
    "arxiv_id": "2512.22772v1",
    "title": "GRExplainer: A Universal Explanation Method for Temporal Graph Neural Networks",
    "authors": [
      "Xuyan Li",
      "Jie Wang",
      "Zheng Yan"
    ],
    "abstract": "Dynamic graphs are widely used to represent evolving real-world networks. Temporal Graph Neural Networks (TGNNs) have emerged as a powerful tool for processing such graphs, but the lack of transparency and explainability limits their practical adoption. Research on TGNN explainability is still in its early stages and faces several key issues: (i) Current methods are tailored to specific TGNN types, restricting generality. (ii) They suffer from high computational costs, making them unsuitable for large-scale networks. (iii) They often overlook the structural connectivity of explanations and require prior knowledge, reducing user-friendliness. To address these issues, we propose GRExplainer, the first universal, efficient, and user-friendly explanation method for TGNNs. GRExplainer extracts node sequences as a unified feature representation, making it independent of specific input formats and thus applicable to both snapshot-based and event-based TGNNs (the major types of TGNNs). By utilizing breadth-first search and temporal information to construct input node sequences, GRExplainer reduces redundant computation and improves efficiency. To enhance user-friendliness, we design a generative model based on Recurrent Neural Networks (RNNs), enabling automated and continuous explanation generation. Experiments on six real-world datasets with three target TGNNs show that GRExplainer outperforms existing baseline methods in generality, efficiency, and user-friendliness.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.22772v1",
    "published_date": "2025-12-28 04:24:59 UTC",
    "updated_date": "2025-12-28 04:24:59 UTC"
  },
  {
    "arxiv_id": "2512.22771v1",
    "title": "Next Best View Selections for Semantic and Dynamic 3D Gaussian Splatting",
    "authors": [
      "Yiqian Li",
      "Wen Jiang",
      "Kostas Daniilidis"
    ],
    "abstract": "Understanding semantics and dynamics has been crucial for embodied agents in various tasks. Both tasks have much more data redundancy than the static scene understanding task. We formulate the view selection problem as an active learning problem, where the goal is to prioritize frames that provide the greatest information gain for model training. To this end, we propose an active learning algorithm with Fisher Information that quantifies the informativeness of candidate views with respect to both semantic Gaussian parameters and deformation networks. This formulation allows our method to jointly handle semantic reasoning and dynamic scene modeling, providing a principled alternative to heuristic or random strategies. We evaluate our method on large-scale static images and dynamic video datasets by selecting informative frames from multi-camera setups. Experimental results demonstrate that our approach consistently improves rendering quality and semantic segmentation performance, outperforming baseline methods based on random selection and uncertainty-based heuristics.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.22771v1",
    "published_date": "2025-12-28 04:19:25 UTC",
    "updated_date": "2025-12-28 04:19:25 UTC"
  },
  {
    "arxiv_id": "2512.22768v1",
    "title": "Understanding the Mechanisms of Fast Hyperparameter Transfer",
    "authors": [
      "Nikhil Ghosh",
      "Denny Wu",
      "Alberto Bietti"
    ],
    "abstract": "The growing scale of deep learning models has rendered standard hyperparameter (HP) optimization prohibitively expensive. A promising solution is the use of scale-aware hyperparameters, which can enable direct transfer of optimal HPs from small-scale grid searches to large models with minimal performance loss. To understand the principles governing such transfer strategy, we develop a general conceptual framework for reasoning about HP transfer across scale, characterizing transfer as fast when the suboptimality it induces vanishes asymptotically faster than the finite-scale performance gap. We show formally that fast transfer is equivalent to useful transfer for compute-optimal grid search, meaning that transfer is asymptotically more compute-efficient than direct tuning. While empirical work has found that the Maximal Update Parameterization ($μ$P) exhibits fast transfer when scaling model width, the mechanisms remain poorly understood. We show that this property depends critically on problem structure by presenting synthetic settings where transfer either offers provable computational advantage or fails to outperform direct tuning even under $μ$P. To explain the fast transfer observed in practice, we conjecture that decomposing the optimization trajectory reveals two contributions to loss reduction: (1) a width-stable component that determines the optimal HPs, and (2) a width-sensitive component that improves with width but weakly perturbs the HP optimum. We present empirical evidence for this hypothesis across various settings, including large language model pretraining.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "43 pages",
    "pdf_url": "https://arxiv.org/pdf/2512.22768v1",
    "published_date": "2025-12-28 04:13:00 UTC",
    "updated_date": "2025-12-28 04:13:00 UTC"
  },
  {
    "arxiv_id": "2512.22757v1",
    "title": "Active Constraint Learning in High Dimensions from Demonstrations",
    "authors": [
      "Zheng Qiu",
      "Chih-Yuan Chiu",
      "Glen Chou"
    ],
    "abstract": "We present an iterative active constraint learning (ACL) algorithm, within the learning from demonstrations (LfD) paradigm, which intelligently solicits informative demonstration trajectories for inferring an unknown constraint in the demonstrator's environment. Our approach iteratively trains a Gaussian process (GP) on the available demonstration dataset to represent the unknown constraints, uses the resulting GP posterior to query start/goal states, and generates informative demonstrations which are added to the dataset. Across simulation and hardware experiments using high-dimensional nonlinear dynamics and unknown nonlinear constraints, our method outperforms a baseline, random-sampling based method at accurately performing constraint inference from an iteratively generated set of sparse but informative demonstrations.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG",
      "eess.SY",
      "math.OC"
    ],
    "primary_category": "cs.RO",
    "comment": "Under review, 25 pages, 11 figures",
    "pdf_url": "https://arxiv.org/pdf/2512.22757v1",
    "published_date": "2025-12-28 03:06:05 UTC",
    "updated_date": "2025-12-28 03:06:05 UTC"
  },
  {
    "arxiv_id": "2512.22742v1",
    "title": "Robust LLM-based Column Type Annotation via Prompt Augmentation with LoRA Tuning",
    "authors": [
      "Hanze Meng",
      "Jianhao Cao",
      "Rachel Pottinger"
    ],
    "abstract": "Column Type Annotation (CTA) is a fundamental step towards enabling schema alignment and semantic understanding of tabular data. Existing encoder-only language models achieve high accuracy when fine-tuned on labeled columns, but their applicability is limited to in-domain settings, as distribution shifts in tables or label spaces require costly re-training from scratch. Recent work has explored prompting generative large language models (LLMs) by framing CTA as a multiple-choice task, but these approaches face two key challenges: (1) model performance is highly sensitive to subtle changes in prompt wording and structure, and (2) annotation F1 scores remain modest. A natural extension is to fine-tune large language models. However, fully fine-tuning these models incurs prohibitive computational costs due to their scale, and the sensitivity to prompts is not eliminated. In this paper, we present a parameter-efficient framework for CTA that trains models over prompt-augmented data via Low-Rank Adaptation (LoRA). Our approach mitigates sensitivity to prompt variations while drastically reducing the number of necessary trainable parameters, achieving robust performance across datasets and templates. Experimental results on recent benchmarks demonstrate that models fine-tuned with our prompt augmentation strategy maintain stable performance across diverse prompt patterns during inference and yield higher weighted F1 scores than those fine-tuned on a single prompt template. These results highlight the effectiveness of parameter-efficient training and augmentation strategies in developing practical and adaptable CTA systems.",
    "categories": [
      "cs.DB",
      "cs.AI"
    ],
    "primary_category": "cs.DB",
    "comment": "13 pages, 8 figures",
    "pdf_url": "https://arxiv.org/pdf/2512.22742v1",
    "published_date": "2025-12-28 02:04:17 UTC",
    "updated_date": "2025-12-28 02:04:17 UTC"
  },
  {
    "arxiv_id": "2512.22738v1",
    "title": "Harnessing Large Language Models for Biomedical Named Entity Recognition",
    "authors": [
      "Jian Chen",
      "Leilei Su",
      "Cong Sun"
    ],
    "abstract": "Background and Objective: Biomedical Named Entity Recognition (BioNER) is a foundational task in medical informatics, crucial for downstream applications like drug discovery and clinical trial matching. However, adapting general-domain Large Language Models (LLMs) to this task is often hampered by their lack of domain-specific knowledge and the performance degradation caused by low-quality training data. To address these challenges, we introduce BioSelectTune, a highly efficient, data-centric framework for fine-tuning LLMs that prioritizes data quality over quantity. Methods and Results: BioSelectTune reformulates BioNER as a structured JSON generation task and leverages our novel Hybrid Superfiltering strategy, a weak-to-strong data curation method that uses a homologous weak model to distill a compact, high-impact training dataset. Conclusions: Through extensive experiments, we demonstrate that BioSelectTune achieves state-of-the-art (SOTA) performance across multiple BioNER benchmarks. Notably, our model, trained on only 50% of the curated positive data, not only surpasses the fully-trained baseline but also outperforms powerful domain-specialized models like BioMedBERT.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.22738v1",
    "published_date": "2025-12-28 01:34:23 UTC",
    "updated_date": "2025-12-28 01:34:23 UTC"
  },
  {
    "arxiv_id": "2512.22733v1",
    "title": "FoldAct: Efficient and Stable Context Folding for Long-Horizon Search Agents",
    "authors": [
      "Jiaqi Shao",
      "Yufeng Miao",
      "Wei Zhang",
      "Bing Luo"
    ],
    "abstract": "Long-horizon reinforcement learning (RL) for large language models faces critical scalability challenges from unbounded context growth, leading to context folding methods that compress interaction history during task execution. However, existing approaches treat summary actions as standard actions, overlooking that summaries fundamentally modify the agent's future observation space, creating a policy-dependent, non-stationary observation distribution that violates core RL assumptions. This introduces three fundamental challenges: (1) gradient dilution where summary tokens receive insufficient training signal, (2) self-conditioning where policy updates change summary distributions, creating a vicious cycle of training collapse, and (3) computational cost from processing unique contexts at each turn. We introduce \\textbf{FoldAct}\\footnote{https://github.com/SHAO-Jiaqi757/FoldAct}, a framework that explicitly addresses these challenges through three key innovations: separated loss computation for independent gradient signals on summary and action tokens, full context consistency loss to reduce distribution shift, and selective segment training to reduce computational cost. Our method enables stable training of long-horizon search agents with context folding, addressing the non-stationary observation problem while improving training efficiency with 5.19$\\times$ speedup.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.22733v1",
    "published_date": "2025-12-28 00:24:01 UTC",
    "updated_date": "2025-12-28 00:24:01 UTC"
  }
]