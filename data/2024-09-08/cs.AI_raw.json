[
  {
    "arxiv_id": "2409.05242v1",
    "title": "FedFT: Improving Communication Performance for Federated Learning with Frequency Space Transformation",
    "authors": [
      "Chamath Palihawadana",
      "Nirmalie Wiratunga",
      "Anjana Wijekoon",
      "Harsha Kalutarage"
    ],
    "abstract": "Communication efficiency is a widely recognised research problem in Federated\nLearning (FL), with recent work focused on developing techniques for efficient\ncompression, distribution and aggregation of model parameters between clients\nand the server. Particularly within distributed systems, it is important to\nbalance the need for computational cost and communication efficiency. However,\nexisting methods are often constrained to specific applications and are less\ngeneralisable. In this paper, we introduce FedFT (federated frequency-space\ntransformation), a simple yet effective methodology for communicating model\nparameters in a FL setting. FedFT uses Discrete Cosine Transform (DCT) to\nrepresent model parameters in frequency space, enabling efficient compression\nand reducing communication overhead. FedFT is compatible with various existing\nFL methodologies and neural architectures, and its linear property eliminates\nthe need for multiple transformations during federated aggregation. This\nmethodology is vital for distributed solutions, tackling essential challenges\nlike data privacy, interoperability, and energy efficiency inherent to these\nenvironments. We demonstrate the generalisability of the FedFT methodology on\nfour datasets using comparative studies with three state-of-the-art FL\nbaselines (FedAvg, FedProx, FedSim). Our results demonstrate that using FedFT\nto represent the differences in model parameters between communication rounds\nin frequency space results in a more compact representation compared to\nrepresenting the entire model in frequency space. This leads to a reduction in\ncommunication overhead, while keeping accuracy levels comparable and in some\ncases even improving it. Our results suggest that this reduction can range from\n5% to 30% per client, depending on dataset.",
    "categories": [
      "cs.DC",
      "cs.AI"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.05242v1",
    "published_date": "2024-09-08 23:05:35 UTC",
    "updated_date": "2024-09-08 23:05:35 UTC"
  },
  {
    "arxiv_id": "2409.05215v1",
    "title": "Synthetic Tabular Data Generation for Class Imbalance and Fairness: A Comparative Study",
    "authors": [
      "Emmanouil Panagiotou",
      "Arjun Roy",
      "Eirini Ntoutsi"
    ],
    "abstract": "Due to their data-driven nature, Machine Learning (ML) models are susceptible\nto bias inherited from data, especially in classification problems where class\nand group imbalances are prevalent. Class imbalance (in the classification\ntarget) and group imbalance (in protected attributes like sex or race) can\nundermine both ML utility and fairness. Although class and group imbalances\ncommonly coincide in real-world tabular datasets, limited methods address this\nscenario. While most methods use oversampling techniques, like interpolation,\nto mitigate imbalances, recent advancements in synthetic tabular data\ngeneration offer promise but have not been adequately explored for this\npurpose. To this end, this paper conducts a comparative analysis to address\nclass and group imbalances using state-of-the-art models for synthetic tabular\ndata generation and various sampling strategies. Experimental results on four\ndatasets, demonstrate the effectiveness of generative models for bias\nmitigation, creating opportunities for further exploration in this direction.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at the ECML PKDD 2024, 4th Workshop on Bias and Fairness in\n  AI",
    "pdf_url": "http://arxiv.org/pdf/2409.05215v1",
    "published_date": "2024-09-08 20:08:09 UTC",
    "updated_date": "2024-09-08 20:08:09 UTC"
  },
  {
    "arxiv_id": "2409.05211v1",
    "title": "ICML Topological Deep Learning Challenge 2024: Beyond the Graph Domain",
    "authors": [
      "Guillermo Bernárdez",
      "Lev Telyatnikov",
      "Marco Montagna",
      "Federica Baccini",
      "Mathilde Papillon",
      "Miquel Ferriol-Galmés",
      "Mustafa Hajij",
      "Theodore Papamarkou",
      "Maria Sofia Bucarelli",
      "Olga Zaghen",
      "Johan Mathe",
      "Audun Myers",
      "Scott Mahan",
      "Hansen Lillemark",
      "Sharvaree Vadgama",
      "Erik Bekkers",
      "Tim Doster",
      "Tegan Emerson",
      "Henry Kvinge",
      "Katrina Agate",
      "Nesreen K Ahmed",
      "Pengfei Bai",
      "Michael Banf",
      "Claudio Battiloro",
      "Maxim Beketov",
      "Paul Bogdan",
      "Martin Carrasco",
      "Andrea Cavallo",
      "Yun Young Choi",
      "George Dasoulas",
      "Matouš Elphick",
      "Giordan Escalona",
      "Dominik Filipiak",
      "Halley Fritze",
      "Thomas Gebhart",
      "Manel Gil-Sorribes",
      "Salvish Goomanee",
      "Victor Guallar",
      "Liliya Imasheva",
      "Andrei Irimia",
      "Hongwei Jin",
      "Graham Johnson",
      "Nikos Kanakaris",
      "Boshko Koloski",
      "Veljko Kovač",
      "Manuel Lecha",
      "Minho Lee",
      "Pierrick Leroy",
      "Theodore Long",
      "German Magai",
      "Alvaro Martinez",
      "Marissa Masden",
      "Sebastian Mežnar",
      "Bertran Miquel-Oliver",
      "Alexis Molina",
      "Alexander Nikitin",
      "Marco Nurisso",
      "Matt Piekenbrock",
      "Yu Qin",
      "Patryk Rygiel",
      "Alessandro Salatiello",
      "Max Schattauer",
      "Pavel Snopov",
      "Julian Suk",
      "Valentina Sánchez",
      "Mauricio Tec",
      "Francesco Vaccarino",
      "Jonas Verhellen",
      "Frederic Wantiez",
      "Alexander Weers",
      "Patrik Zajec",
      "Blaž Škrlj",
      "Nina Miolane"
    ],
    "abstract": "This paper describes the 2nd edition of the ICML Topological Deep Learning\nChallenge that was hosted within the ICML 2024 ELLIS Workshop on\nGeometry-grounded Representation Learning and Generative Modeling (GRaM). The\nchallenge focused on the problem of representing data in different discrete\ntopological domains in order to bridge the gap between Topological Deep\nLearning (TDL) and other types of structured datasets (e.g. point clouds,\ngraphs). Specifically, participants were asked to design and implement\ntopological liftings, i.e. mappings between different data structures and\ntopological domains --like hypergraphs, or simplicial/cell/combinatorial\ncomplexes. The challenge received 52 submissions satisfying all the\nrequirements. This paper introduces the main scope of the challenge, and\nsummarizes the main results and findings.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Proceedings of the Geometry-grounded Representation Learning and\n  Generative Modeling Workshop (GRaM) at ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2409.05211v1",
    "published_date": "2024-09-08 19:59:53 UTC",
    "updated_date": "2024-09-08 19:59:53 UTC"
  },
  {
    "arxiv_id": "2409.05208v4",
    "title": "Influence-based Attributions can be Manipulated",
    "authors": [
      "Chhavi Yadav",
      "Ruihan Wu",
      "Kamalika Chaudhuri"
    ],
    "abstract": "Influence Functions are a standard tool for attributing predictions to\ntraining data in a principled manner and are widely used in applications such\nas data valuation and fairness. In this work, we present realistic incentives\nto manipulate influence-based attributions and investigate whether these\nattributions can be \\textit{systematically} tampered by an adversary. We show\nthat this is indeed possible for logistic regression models trained on ResNet\nfeature embeddings and standard tabular fairness datasets and provide efficient\nattacks with backward-friendly implementations. Our work raises questions on\nthe reliability of influence-based attributions in adversarial circumstances.\nCode is available at :\n\\url{https://github.com/infinite-pursuits/influence-based-attributions-can-be-manipulated}",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.05208v4",
    "published_date": "2024-09-08 19:52:00 UTC",
    "updated_date": "2024-10-07 03:13:37 UTC"
  },
  {
    "arxiv_id": "2409.05206v1",
    "title": "SEF: A Method for Computing Prediction Intervals by Shifting the Error Function in Neural Networks",
    "authors": [
      "E. V. Aretos",
      "D. G. Sotiropoulos"
    ],
    "abstract": "In today's era, Neural Networks (NN) are applied in various scientific fields\nsuch as robotics, medicine, engineering, etc. However, the predictions of\nneural networks themselves contain a degree of uncertainty that must always be\ntaken into account before any decision is made. This is why many researchers\nhave focused on developing different ways to quantify the uncertainty of neural\nnetwork predictions. Some of these methods are based on generating prediction\nintervals (PI) via neural networks for the requested target values. The SEF\n(Shifting the Error Function) method presented in this paper is a new method\nthat belongs to this category of methods. The proposed approach involves\ntraining a single neural network three times, thus generating an estimate along\nwith the corresponding upper and lower bounds for a given problem. A pivotal\naspect of the method is the calculation of a parameter from the initial\nnetwork's estimates, which is then integrated into the loss functions of the\nother two networks. This innovative process effectively produces PIs, resulting\nin a robust and efficient technique for uncertainty quantification. To evaluate\nthe effectiveness of our method, a comparison in terms of successful PI\ngeneration between the SEF, PI3NN and PIVEN methods was made using two\nsynthetic datasets.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "The paper has been accepted at the 2024 International Conference on\n  Computer and Applications (ICCA24), Cairo, Egypt, December 17-19, 2024.\n  https://icca-conf.info/icca-2024",
    "pdf_url": "http://arxiv.org/pdf/2409.05206v1",
    "published_date": "2024-09-08 19:46:45 UTC",
    "updated_date": "2024-09-08 19:46:45 UTC"
  },
  {
    "arxiv_id": "2409.05202v2",
    "title": "A Survey on Mixup Augmentations and Beyond",
    "authors": [
      "Xin Jin",
      "Hongyu Zhu",
      "Siyuan Li",
      "Zedong Wang",
      "Zicheng Liu",
      "Juanxi Tian",
      "Chang Yu",
      "Huafeng Qin",
      "Stan Z. Li"
    ],
    "abstract": "As Deep Neural Networks have achieved thrilling breakthroughs in the past\ndecade, data augmentations have garnered increasing attention as regularization\ntechniques when massive labeled data are unavailable. Among existing\naugmentations, Mixup and relevant data-mixing methods that convexly combine\nselected samples and the corresponding labels are widely adopted because they\nyield high performances by generating data-dependent virtual data while easily\nmigrating to various domains. This survey presents a comprehensive review of\nfoundational mixup methods and their applications. We first elaborate on the\ntraining pipeline with mixup augmentations as a unified framework containing\nmodules. A reformulated framework could contain various mixup methods and give\nintuitive operational procedures. Then, we systematically investigate the\napplications of mixup augmentations on vision downstream tasks, various data\nmodalities, and some analysis \\& theorems of mixup. Meanwhile, we conclude the\ncurrent status and limitations of mixup research and point out further work for\neffective and efficient mixup augmentations. This survey can provide\nresearchers with the current state of the art in mixup methods and provide some\ninsights and guidance roles in the mixup arena. An online project with this\nsurvey is available at https://github.com/Westlake-AI/Awesome-Mixup.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "Preprint V2 with 30 pages main text. Online project at\n  https://github.com/Westlake-AI/Awesome-Mixup",
    "pdf_url": "http://arxiv.org/pdf/2409.05202v2",
    "published_date": "2024-09-08 19:32:22 UTC",
    "updated_date": "2025-04-23 17:47:35 UTC"
  },
  {
    "arxiv_id": "2409.05197v3",
    "title": "Seemingly Plausible Distractors in Multi-Hop Reasoning: Are Large Language Models Attentive Readers?",
    "authors": [
      "Neeladri Bhuiya",
      "Viktor Schlegel",
      "Stefan Winkler"
    ],
    "abstract": "State-of-the-art Large Language Models (LLMs) are accredited with an\nincreasing number of different capabilities, ranging from reading\ncomprehension, over advanced mathematical and reasoning skills to possessing\nscientific knowledge. In this paper we focus on their multi-hop reasoning\ncapability: the ability to identify and integrate information from multiple\ntextual sources.\n  Given the concerns with the presence of simplifying cues in existing\nmulti-hop reasoning benchmarks, which allow models to circumvent the reasoning\nrequirement, we set out to investigate, whether LLMs are prone to exploiting\nsuch simplifying cues. We find evidence that they indeed circumvent the\nrequirement to perform multi-hop reasoning, but they do so in more subtle ways\nthan what was reported about their fine-tuned pre-trained language model (PLM)\npredecessors. Motivated by this finding, we propose a challenging multi-hop\nreasoning benchmark, by generating seemingly plausible multi-hop reasoning\nchains, which ultimately lead to incorrect answers. We evaluate multiple open\nand proprietary state-of-the-art LLMs, and find that their performance to\nperform multi-hop reasoning is affected, as indicated by up to 45% relative\ndecrease in F1 score when presented with such seemingly plausible alternatives.\nWe conduct a deeper analysis and find evidence that while LLMs tend to ignore\nmisleading lexical cues, misleading reasoning paths indeed present a\nsignificant challenge.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "15 pages, 3 figures, EMNLP 2024 Main Conference",
    "pdf_url": "http://arxiv.org/pdf/2409.05197v3",
    "published_date": "2024-09-08 19:22:58 UTC",
    "updated_date": "2024-10-31 02:19:12 UTC"
  },
  {
    "arxiv_id": "2409.05177v1",
    "title": "Insights from Benchmarking Frontier Language Models on Web App Code Generation",
    "authors": [
      "Yi Cui"
    ],
    "abstract": "This paper presents insights from evaluating 16 frontier large language\nmodels (LLMs) on the WebApp1K benchmark, a test suite designed to assess the\nability of LLMs to generate web application code. The results reveal that while\nall models possess similar underlying knowledge, their performance is\ndifferentiated by the frequency of mistakes they make. By analyzing lines of\ncode (LOC) and failure distributions, we find that writing correct code is more\ncomplex than generating incorrect code. Furthermore, prompt engineering shows\nlimited efficacy in reducing errors beyond specific cases. These findings\nsuggest that further advancements in coding LLM should emphasize on model\nreliability and mistake minimization.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.05177v1",
    "published_date": "2024-09-08 18:24:26 UTC",
    "updated_date": "2024-09-08 18:24:26 UTC"
  },
  {
    "arxiv_id": "2409.12175v1",
    "title": "Expanding Expressivity in Transformer Models with MöbiusAttention",
    "authors": [
      "Anna-Maria Halacheva",
      "Mojtaba Nayyeri",
      "Steffen Staab"
    ],
    "abstract": "Attention mechanisms and Transformer architectures have revolutionized\nNatural Language Processing (NLP) by enabling exceptional modeling of\nlong-range dependencies and capturing intricate linguistic patterns. However,\ntheir inherent reliance on linear operations in the form of matrix\nmultiplications limits their ability to fully capture inter-token relationships\non their own. We propose M\\\"obiusAttention, a novel approach that integrates\nM\\\"obius transformations within the attention mechanism of Transformer-based\nmodels. M\\\"obius transformations are non-linear operations in spaces over\ncomplex numbers with the ability to map between various geometries. By\nincorporating these properties, M\\\"obiusAttention empowers models to learn more\nintricate geometric relationships between tokens and capture a wider range of\ninformation through complex-valued weight vectors. We build and pre-train a\nBERT and a RoFormer version enhanced with M\\\"obiusAttention, which we then\nfinetune on the GLUE benchmark. We evaluate empirically our approach against\nthe baseline BERT and RoFormer models on a range of downstream tasks. Our\napproach compares favorably against the baseline models, even with smaller\nnumber of parameters suggesting the enhanced expressivity of M\\\"obiusAttention.\nThis research paves the way for exploring the potential of M\\\"obius\ntransformations in the complex projective space to enhance the expressivity and\nperformance of foundation models.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.12175v1",
    "published_date": "2024-09-08 16:56:33 UTC",
    "updated_date": "2024-09-08 16:56:33 UTC"
  },
  {
    "arxiv_id": "2409.05152v2",
    "title": "OneGen: Efficient One-Pass Unified Generation and Retrieval for LLMs",
    "authors": [
      "Jintian Zhang",
      "Cheng Peng",
      "Mengshu Sun",
      "Xiang Chen",
      "Lei Liang",
      "Zhiqiang Zhang",
      "Jun Zhou",
      "Huajun Chen",
      "Ningyu Zhang"
    ],
    "abstract": "Despite the recent advancements in Large Language Models (LLMs), which have\nsignificantly enhanced the generative capabilities for various NLP tasks, LLMs\nstill face limitations in directly handling retrieval tasks. However, many\npractical applications demand the seamless integration of both retrieval and\ngeneration. This paper introduces a novel and efficient One-pass Generation and\nretrieval framework (OneGen), designed to improve LLMs' performance on tasks\nthat require both generation and retrieval. The proposed framework bridges the\ntraditionally separate training approaches for generation and retrieval by\nincorporating retrieval tokens generated autoregressively. This enables a\nsingle LLM to handle both tasks simultaneously in a unified forward pass. We\nconduct experiments on two distinct types of composite tasks, RAG and Entity\nLinking, to validate the pluggability, effectiveness, and efficiency of OneGen\nin training and inference. Furthermore, our results show that integrating\ngeneration and retrieval within the same context preserves the generative\ncapabilities of LLMs while improving retrieval performance. To the best of our\nknowledge, OneGen is the first to enable LLMs to conduct vector retrieval\nduring the generation.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.DB",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "EMNLP 2024 Findings; code is available at\n  https://github.com/zjunlp/OneGen",
    "pdf_url": "http://arxiv.org/pdf/2409.05152v2",
    "published_date": "2024-09-08 16:35:19 UTC",
    "updated_date": "2024-10-02 05:02:02 UTC"
  },
  {
    "arxiv_id": "2409.05144v2",
    "title": "QuantFactor REINFORCE: Mining Steady Formulaic Alpha Factors with Variance-bounded REINFORCE",
    "authors": [
      "Junjie Zhao",
      "Chengxi Zhang",
      "Min Qin",
      "Peng Yang"
    ],
    "abstract": "The goal of alpha factor mining is to discover indicative signals of\ninvestment opportunities from the historical financial market data of assets,\nwhich can be used to predict asset returns and gain excess profits. Recently, a\npromising framework is proposed for generating formulaic alpha factors using\ndeep reinforcement learning, and quickly gained research focuses from both\nacademia and industries. This paper first argues that the originally employed\npolicy training method, i.e., Proximal Policy Optimization (PPO), faces several\nimportant issues in the context of alpha factors mining, making it ineffective\nto explore the search space of the formula. Herein, a novel reinforcement\nlearning based on the well-known REINFORCE algorithm is proposed. Given that\nthe underlying state transition function adheres to the Dirac distribution, the\nMarkov Decision Process within this framework exhibit minimal environmental\nvariability, making REINFORCE algorithm more appropriate than PPO. A new\ndedicated baseline is designed to theoretically reduce the commonly suffered\nhigh variance of REINFORCE. Moreover, the information ratio is introduced as a\nreward shaping mechanism to encourage the generation of steady alpha factors\nthat can better adapt to changes in market volatility. Experimental evaluations\non various real assets data show that the proposed algorithm can increase the\ncorrelation with asset returns by 3.83\\%, and a stronger ability to obtain\nexcess returns compared to the latest alpha factors mining methods, which meets\nthe theoretical results well.",
    "categories": [
      "q-fin.CP",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-fin.CP",
    "comment": "16 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.05144v2",
    "published_date": "2024-09-08 15:57:58 UTC",
    "updated_date": "2024-10-08 15:37:54 UTC"
  },
  {
    "arxiv_id": "2409.05921v1",
    "title": "STLLM-DF: A Spatial-Temporal Large Language Model with Diffusion for Enhanced Multi-Mode Traffic System Forecasting",
    "authors": [
      "Zhiqi Shao",
      "Haoning Xi",
      "Haohui Lu",
      "Ze Wang",
      "Michael G. H. Bell",
      "Junbin Gao"
    ],
    "abstract": "The rapid advancement of Intelligent Transportation Systems (ITS) presents\nchallenges, particularly with missing data in multi-modal transportation and\nthe complexity of handling diverse sequential tasks within a centralized\nframework. To address these issues, we propose the Spatial-Temporal Large\nLanguage Model Diffusion (STLLM-DF), an innovative model that leverages\nDenoising Diffusion Probabilistic Models (DDPMs) and Large Language Models\n(LLMs) to improve multi-task transportation prediction. The DDPM's robust\ndenoising capabilities enable it to recover underlying data patterns from noisy\ninputs, making it particularly effective in complex transportation systems.\nMeanwhile, the non-pretrained LLM dynamically adapts to spatial-temporal\nrelationships within multi-modal networks, allowing the system to efficiently\nmanage diverse transportation tasks in both long-term and short-term\npredictions. Extensive experiments demonstrate that STLLM-DF consistently\noutperforms existing models, achieving an average reduction of 2.40\\% in MAE,\n4.50\\% in RMSE, and 1.51\\% in MAPE. This model significantly advances\ncentralized ITS by enhancing predictive accuracy, robustness, and overall\nsystem performance across multiple tasks, thus paving the way for more\neffective spatio-temporal traffic forecasting through the integration of frozen\ntransformer language models and diffusion techniques.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "I.2.7",
      "I.2.1"
    ],
    "primary_category": "cs.LG",
    "comment": "26 pages, 11 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.05921v1",
    "published_date": "2024-09-08 15:29:27 UTC",
    "updated_date": "2024-09-08 15:29:27 UTC"
  },
  {
    "arxiv_id": "2409.05105v1",
    "title": "EdaCSC: Two Easy Data Augmentation Methods for Chinese Spelling Correction",
    "authors": [
      "Lei Sheng",
      "Shuai-Shuai Xu"
    ],
    "abstract": "Chinese Spelling Correction (CSC) aims to detect and correct spelling errors\nin Chinese sentences caused by phonetic or visual similarities. While current\nCSC models integrate pinyin or glyph features and have shown significant\nprogress,they still face challenges when dealing with sentences containing\nmultiple typos and are susceptible to overcorrection in real-world scenarios.\nIn contrast to existing model-centric approaches, we propose two data\naugmentation methods to address these limitations. Firstly, we augment the\ndataset by either splitting long sentences into shorter ones or reducing typos\nin sentences with multiple typos. Subsequently, we employ different training\nprocesses to select the optimal model. Experimental evaluations on the SIGHAN\nbenchmarks demonstrate the superiority of our approach over most existing\nmodels, achieving state-of-the-art performance on the SIGHAN15 test set.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "18 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.05105v1",
    "published_date": "2024-09-08 14:29:10 UTC",
    "updated_date": "2024-09-08 14:29:10 UTC"
  },
  {
    "arxiv_id": "2409.05919v1",
    "title": "KModels: Unlocking AI for Business Applications",
    "authors": [
      "Roy Abitbol",
      "Eyal Cohen",
      "Muhammad Kanaan",
      "Bhavna Agrawal",
      "Yingjie Li",
      "Anuradha Bhamidipaty",
      "Erez Bilgory"
    ],
    "abstract": "As artificial intelligence (AI) continues to rapidly advance, there is a\ngrowing demand to integrate AI capabilities into existing business\napplications. However, a significant gap exists between the rapid progress in\nAI and how slowly AI is being embedded into business environments. Deploying\nwell-performing lab models into production settings, especially in on-premise\nenvironments, often entails specialized expertise and imposes a heavy burden of\nmodel management, creating significant barriers to implementing AI models in\nreal-world applications.\n  KModels leverages proven libraries and platforms (Kubeflow Pipelines, KServe)\nto streamline AI adoption by supporting both AI developers and consumers. It\nallows model developers to focus solely on model development and share models\nas transportable units (Templates), abstracting away complex production\ndeployment concerns. KModels enables AI consumers to eliminate the need for a\ndedicated data scientist, as the templates encapsulate most data science\nconsiderations while providing business-oriented control.\n  This paper presents the architecture of KModels and the key decisions that\nshape it. We outline KModels' main components as well as its interfaces.\nFurthermore, we explain how KModels is highly suited for on-premise deployment\nbut can also be used in cloud environments.\n  The efficacy of KModels is demonstrated through the successful deployment of\nthree AI models within an existing Work Order Management system. These models\noperate in a client's data center and are trained on local data, without data\nscientist intervention. One model improved the accuracy of Failure Code\nspecification for work orders from 46% to 83%, showcasing the substantial\nbenefit of accessible and localized AI solutions.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.05919v1",
    "published_date": "2024-09-08 13:19:12 UTC",
    "updated_date": "2024-09-08 13:19:12 UTC"
  },
  {
    "arxiv_id": "2409.05084v1",
    "title": "Adaptive $k$-nearest neighbor classifier based on the local estimation of the shape operator",
    "authors": [
      "Alexandre Luís Magalhães Levada",
      "Frank Nielsen",
      "Michel Ferreira Cardia Haddad"
    ],
    "abstract": "The $k$-nearest neighbor ($k$-NN) algorithm is one of the most popular\nmethods for nonparametric classification. However, a relevant limitation\nconcerns the definition of the number of neighbors $k$. This parameter exerts a\ndirect impact on several properties of the classifier, such as the\nbias-variance tradeoff, smoothness of decision boundaries, robustness to noise,\nand class imbalance handling. In the present paper, we introduce a new adaptive\n$k$-nearest neighbours ($kK$-NN) algorithm that explores the local curvature at\na sample to adaptively defining the neighborhood size. The rationale is that\npoints with low curvature could have larger neighborhoods (locally, the tangent\nspace approximates well the underlying data shape), whereas points with high\ncurvature could have smaller neighborhoods (locally, the tangent space is a\nloose approximation). We estimate the local Gaussian curvature by computing an\napproximation to the local shape operator in terms of the local covariance\nmatrix as well as the local Hessian matrix. Results on many real-world datasets\nindicate that the new $kK$-NN algorithm yields superior balanced accuracy\ncompared to the established $k$-NN method and also another adaptive $k$-NN\nalgorithm. This is particularly evident when the number of samples in the\ntraining data is limited, suggesting that the $kK$-NN is capable of learning\nmore discriminant functions with less data considering many relevant cases.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.LG",
    "comment": "18 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.05084v1",
    "published_date": "2024-09-08 13:08:45 UTC",
    "updated_date": "2024-09-08 13:08:45 UTC"
  },
  {
    "arxiv_id": "2409.05076v1",
    "title": "PIP: Detecting Adversarial Examples in Large Vision-Language Models via Attention Patterns of Irrelevant Probe Questions",
    "authors": [
      "Yudong Zhang",
      "Ruobing Xie",
      "Jiansheng Chen",
      "Xingwu Sun",
      "Yu Wang"
    ],
    "abstract": "Large Vision-Language Models (LVLMs) have demonstrated their powerful\nmultimodal capabilities. However, they also face serious safety problems, as\nadversaries can induce robustness issues in LVLMs through the use of\nwell-designed adversarial examples. Therefore, LVLMs are in urgent need of\ndetection tools for adversarial examples to prevent incorrect responses. In\nthis work, we first discover that LVLMs exhibit regular attention patterns for\nclean images when presented with probe questions. We propose an unconventional\nmethod named PIP, which utilizes the attention patterns of one randomly\nselected irrelevant probe question (e.g., \"Is there a clock?\") to distinguish\nadversarial examples from clean examples. Regardless of the image to be tested\nand its corresponding question, PIP only needs to perform one additional\ninference of the image to be tested and the probe question, and then achieves\nsuccessful detection of adversarial examples. Even under black-box attacks and\nopen dataset scenarios, our PIP, coupled with a simple SVM, still achieves more\nthan 98% recall and a precision of over 90%. Our PIP is the first attempt to\ndetect adversarial attacks on LVLMs via simple irrelevant probe questions,\nshedding light on deeper understanding and introspection within LVLMs. The code\nis available at https://github.com/btzyd/pip.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by ACM Multimedia 2024 BNI track (Oral)",
    "pdf_url": "http://arxiv.org/pdf/2409.05076v1",
    "published_date": "2024-09-08 12:38:25 UTC",
    "updated_date": "2024-09-08 12:38:25 UTC"
  },
  {
    "arxiv_id": "2409.05061v2",
    "title": "Dynamic Demand Management for Parcel Lockers",
    "authors": [
      "Daniela Sailer",
      "Robert Klein",
      "Claudius Steinhardt"
    ],
    "abstract": "In pursuit of a more sustainable and cost-efficient last mile, parcel lockers\nhave gained a firm foothold in the parcel delivery landscape. To fully exploit\ntheir potential and simultaneously ensure customer satisfaction, successful\nmanagement of the locker's limited capacity is crucial. This is challenging as\nfuture delivery requests and pickup times are stochastic from the provider's\nperspective. In response, we propose to dynamically control whether the locker\nis presented as an available delivery option to each incoming customer with the\ngoal of maximizing the number of served requests weighted by their priority.\nAdditionally, we take different compartment sizes into account, which entails a\nsecond type of decision as parcels scheduled for delivery must be allocated. We\nformalize the problem as an infinite-horizon sequential decision problem and\nfind that exact methods are intractable due to the curses of dimensionality. In\nlight of this, we develop a solution framework that orchestrates multiple\nalgorithmic techniques rooted in Sequential Decision Analytics and\nReinforcement Learning, namely cost function approximation and an offline\ntrained parametric value function approximation together with a truncated\nonline rollout. Our innovative approach to combine these techniques enables us\nto address the strong interrelations between the two decision types. As a\ngeneral methodological contribution, we enhance the training of our value\nfunction approximation with a modified version of experience replay that\nenforces structure in the value function. Our computational study shows that\nour method outperforms a myopic benchmark by 13.7% and an industry-inspired\npolicy by 12.6%.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.05061v2",
    "published_date": "2024-09-08 11:38:48 UTC",
    "updated_date": "2024-09-12 08:19:32 UTC"
  },
  {
    "arxiv_id": "2409.05035v1",
    "title": "Deep Generic Representations for Domain-Generalized Anomalous Sound Detection",
    "authors": [
      "Phurich Saengthong",
      "Takahiro Shinozaki"
    ],
    "abstract": "Developing a reliable anomalous sound detection (ASD) system requires\nrobustness to noise, adaptation to domain shifts, and effective performance\nwith limited training data. Current leading methods rely on extensive labeled\ndata for each target machine type to train feature extractors using\nOutlier-Exposure (OE) techniques, yet their performance on the target domain\nremains sub-optimal. In this paper, we present \\textit{GenRep}, which utilizes\ngeneric feature representations from a robust, large-scale pre-trained feature\nextractor combined with kNN for domain-generalized ASD, without the need for\nfine-tuning. \\textit{GenRep} incorporates MemMixup, a simple approach for\naugmenting the target memory bank using nearest source samples, paired with a\ndomain normalization technique to address the imbalance between source and\ntarget domains. \\textit{GenRep} outperforms the best OE-based approach without\na need for labeled data with an Official Score of 73.79\\% on the DCASE2023T2\nEval set and demonstrates robustness under limited data scenarios. The code is\navailable open-source.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.05035v1",
    "published_date": "2024-09-08 09:20:30 UTC",
    "updated_date": "2024-09-08 09:20:30 UTC"
  },
  {
    "arxiv_id": "2409.05033v2",
    "title": "A Survey on Diffusion Models for Recommender Systems",
    "authors": [
      "Jianghao Lin",
      "Jiaqi Liu",
      "Jiachen Zhu",
      "Yunjia Xi",
      "Chengkai Liu",
      "Yangtian Zhang",
      "Yong Yu",
      "Weinan Zhang"
    ],
    "abstract": "While traditional recommendation techniques have made significant strides in\nthe past decades, they still suffer from limited generalization performance\ncaused by factors like inadequate collaborative signals, weak latent\nrepresentations, and noisy data. In response, diffusion models (DMs) have\nemerged as promising solutions for recommender systems due to their robust\ngenerative capabilities, solid theoretical foundations, and improved training\nstability. To this end, in this paper, we present the first comprehensive\nsurvey on diffusion models for recommendation, and draw a bird's-eye view from\nthe perspective of the whole pipeline in real-world recommender systems. We\nsystematically categorize existing research works into three primary domains:\n(1) diffusion for data engineering & encoding, focusing on data augmentation\nand representation enhancement; (2) diffusion as recommender models, employing\ndiffusion models to directly estimate user preferences and rank items; and (3)\ndiffusion for content presentation, utilizing diffusion models to generate\npersonalized content such as fashion and advertisement creatives. Our taxonomy\nhighlights the unique strengths of diffusion models in capturing complex data\ndistributions and generating high-quality, diverse samples that closely align\nwith user preferences. We also summarize the core characteristics of the\nadapting diffusion models for recommendation, and further identify key areas\nfor future exploration, which helps establish a roadmap for researchers and\npractitioners seeking to advance recommender systems through the innovative\napplication of diffusion models. To further facilitate the research community\nof recommender systems based on diffusion models, we actively maintain a GitHub\nrepository for papers and other related resources in this rising direction\nhttps://github.com/CHIANGEL/Awesome-Diffusion-for-RecSys.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "Under Review",
    "pdf_url": "http://arxiv.org/pdf/2409.05033v2",
    "published_date": "2024-09-08 08:57:12 UTC",
    "updated_date": "2024-09-15 13:29:18 UTC"
  },
  {
    "arxiv_id": "2409.16292v1",
    "title": "Explaining Human Comparisons using Alignment-Importance Heatmaps",
    "authors": [
      "Nhut Truong",
      "Dario Pesenti",
      "Uri Hasson"
    ],
    "abstract": "We present a computational explainability approach for human comparison\ntasks, using Alignment Importance Score (AIS) heatmaps derived from deep-vision\nmodels. The AIS reflects a feature-map's unique contribution to the alignment\nbetween Deep Neural Network's (DNN) representational geometry and that of\nhumans. We first validate the AIS by showing that prediction of out-of-sample\nhuman similarity judgments is improved when constructing representations using\nonly higher-scoring AIS feature maps identified from a training set. We then\ncompute image-specific heatmaps that visually indicate the areas that\ncorrespond to feature-maps with higher AIS scores. These maps provide an\nintuitive explanation of which image areas are more important when it is\ncompared to other images in a cohort. We observe a correspondence between these\nheatmaps and saliency maps produced by a gaze-prediction model. However, in\nsome cases, meaningful differences emerge, as the dimensions relevant for\ncomparison are not necessarily the most visually salient. To conclude,\nAlignment Importance improves prediction of human similarity judgments from DNN\nembeddings, and provides interpretable insights into the relevant information\nin image space.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.16292v1",
    "published_date": "2024-09-08 08:28:09 UTC",
    "updated_date": "2024-09-08 08:28:09 UTC"
  },
  {
    "arxiv_id": "2409.05022v1",
    "title": "Sequential Recommendation via Adaptive Robust Attention with Multi-dimensional Embeddings",
    "authors": [
      "Linsey Pang",
      "Amir Hossein Raffiee",
      "Wei Liu",
      "Keld Lundgaard"
    ],
    "abstract": "Sequential recommendation models have achieved state-of-the-art performance\nusing self-attention mechanism. It has since been found that moving beyond only\nusing item ID and positional embeddings leads to a significant accuracy boost\nwhen predicting the next item. In recent literature, it was reported that a\nmulti-dimensional kernel embedding with temporal contextual kernels to capture\nusers' diverse behavioral patterns results in a substantial performance\nimprovement. In this study, we further improve the sequential recommender\nmodel's robustness and generalization by introducing a mix-attention mechanism\nwith a layer-wise noise injection (LNI) regularization. We refer to our\nproposed model as adaptive robust sequential recommendation framework (ADRRec),\nand demonstrate through extensive experiments that our model outperforms\nexisting self-attention architectures.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.05022v1",
    "published_date": "2024-09-08 08:27:22 UTC",
    "updated_date": "2024-09-08 08:27:22 UTC"
  },
  {
    "arxiv_id": "2409.05007v1",
    "title": "Audio-Guided Fusion Techniques for Multimodal Emotion Analysis",
    "authors": [
      "Pujin Shi",
      "Fei Gao"
    ],
    "abstract": "In this paper, we propose a solution for the semi-supervised learning track\n(MER-SEMI) in MER2024. First, in order to enhance the performance of the\nfeature extractor on sentiment classification tasks,we fine-tuned video and\ntext feature extractors, specifically CLIP-vit-large and Baichuan-13B, using\nlabeled data. This approach effectively preserves the original emotional\ninformation conveyed in the videos. Second, we propose an Audio-Guided\nTransformer (AGT) fusion mechanism, which leverages the robustness of\nHubert-large, showing superior effectiveness in fusing both inter-channel and\nintra-channel information. Third, To enhance the accuracy of the model, we\niteratively apply self-supervised learning by using high-confidence unlabeled\ndata as pseudo-labels. Finally, through black-box probing, we discovered an\nimbalanced data distribution between the training and test sets. Therefore, We\nadopt a prior-knowledge-based voting mechanism. The results demonstrate the\neffectiveness of our strategy, ultimately earning us third place in the\nMER-SEMI track.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.05007v1",
    "published_date": "2024-09-08 07:28:27 UTC",
    "updated_date": "2024-09-08 07:28:27 UTC"
  },
  {
    "arxiv_id": "2409.05001v1",
    "title": "A Pair Programming Framework for Code Generation via Multi-Plan Exploration and Feedback-Driven Refinement",
    "authors": [
      "Huan Zhang",
      "Wei Cheng",
      "Yuhan Wu",
      "Wei Hu"
    ],
    "abstract": "Large language models (LLMs) have achieved impressive performance on code\ngeneration. Although prior studies enhanced LLMs with prompting techniques and\ncode refinement, they still struggle with complex programming problems due to\nrigid solution plans. In this paper, we draw on pair programming practices to\npropose PairCoder, a novel LLM-based framework for code generation. PairCoder\nincorporates two collaborative LLM agents, namely a Navigator agent for\nhigh-level planning and a Driver agent for specific implementation. The\nNavigator is responsible for proposing promising solution plans, selecting the\ncurrent optimal plan, and directing the next iteration round based on execution\nfeedback. The Driver follows the guidance of Navigator to undertake initial\ncode generation, code testing, and refinement. This interleaved and iterative\nworkflow involves multi-plan exploration and feedback-based refinement, which\nmimics the collaboration of pair programmers. We evaluate PairCoder with both\nopen-source and closed-source LLMs on various code generation benchmarks.\nExtensive experimental results demonstrate the superior accuracy of PairCoder,\nachieving relative pass@1 improvements of 12.00%-162.43% compared to prompting\nLLMs directly.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "Accepted in the 39th IEEE/ACM International Conference on Automated\n  Software Engineering (ASE 2024)",
    "pdf_url": "http://arxiv.org/pdf/2409.05001v1",
    "published_date": "2024-09-08 07:22:19 UTC",
    "updated_date": "2024-09-08 07:22:19 UTC"
  },
  {
    "arxiv_id": "2409.09071v1",
    "title": "ELMS: Elasticized Large Language Models On Mobile Devices",
    "authors": [
      "Wangsong Yin",
      "Rongjie Yi",
      "Daliang Xu",
      "Gang Huang",
      "Mengwei Xu",
      "Xuanzhe Liu"
    ],
    "abstract": "On-device Large Language Models (LLMs) are revolutionizing mobile AI,\nenabling applications such as UI automation while addressing privacy concerns.\nCurrently, the standard approach involves deploying a single, robust LLM as a\nuniversal solution for various applications, often referred to as\nLLM-as-a-Service (LLMaaS). However, this approach faces a significant system\nchallenge: existing LLMs lack the flexibility to accommodate the diverse\nService-Level Objectives (SLOs) regarding inference latency across different\napplications. To address this issue, we introduce ELMS, an on-device LLM\nservice designed to provide elasticity in both the model and prompt dimensions\nof an LLMaaS. This system includes: A one-time neuron reordering technique,\nwhich utilizes the inherent permutation consistency within transformer models\nto create high-quality, elastic sub-models with minimal runtime switching\ncosts. A dual-head compact language model, which efficiently refines prompts\nand coordinates the elastic adaptation between the model and the prompt. We\nhave implemented this elastic on-device LLM service on several off-the-shelf\n(COTS) smartphones and evaluate ELMS using both standalone NLP/mobile-agent\ndatasets and synthesized end-to-end traces. Across a range of SLOs, ELMS\nsurpasses four strong baselines by up to 16.83% and 11.04% in absolute accuracy\non average, with less than 1% Time-To-First-Token (TTFT) switching overhead,\ncomparable memory usage, and fewer than 100 offline GPU hours.",
    "categories": [
      "cs.DC",
      "cs.AI"
    ],
    "primary_category": "cs.DC",
    "comment": "Technical Report",
    "pdf_url": "http://arxiv.org/pdf/2409.09071v1",
    "published_date": "2024-09-08 06:32:08 UTC",
    "updated_date": "2024-09-08 06:32:08 UTC"
  },
  {
    "arxiv_id": "2409.04977v1",
    "title": "Enhancing Convolutional Neural Networks with Higher-Order Numerical Difference Methods",
    "authors": [
      "Qi Wang",
      "Zijun Gao",
      "Mingxiu Sui",
      "Taiyuan Mei",
      "Xiaohan Cheng",
      "Iris Li"
    ],
    "abstract": "With the rise of deep learning technology in practical applications,\nConvolutional Neural Networks (CNNs) have been able to assist humans in solving\nmany real-world problems. To enhance the performance of CNNs, numerous network\narchitectures have been explored. Some of these architectures are designed\nbased on the accumulated experience of researchers over time, while others are\ndesigned through neural architecture search methods. The improvements made to\nCNNs by the aforementioned methods are quite significant, but most of the\nimprovement methods are limited in reality by model size and environmental\nconstraints, making it difficult to fully realize the improved performance. In\nrecent years, research has found that many CNN structures can be explained by\nthe discretization of ordinary differential equations. This implies that we can\ndesign theoretically supported deep network structures using higher-order\nnumerical difference methods. It should be noted that most of the previous CNN\nmodel structures are based on low-order numerical methods. Therefore,\nconsidering that the accuracy of linear multi-step numerical difference methods\nis higher than that of the forward Euler method, this paper proposes a stacking\nscheme based on the linear multi-step method. This scheme enhances the\nperformance of ResNet without increasing the model size and compares it with\nthe Runge-Kutta scheme. The experimental results show that the performance of\nthe stacking scheme proposed in this paper is superior to existing stacking\nschemes (ResNet and HO-ResNet), and it has the capability to be extended to\nother types of neural networks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.04977v1",
    "published_date": "2024-09-08 05:13:58 UTC",
    "updated_date": "2024-09-08 05:13:58 UTC"
  },
  {
    "arxiv_id": "2409.04976v1",
    "title": "HYDRA: Hybrid Data Multiplexing and Run-time Layer Configurable DNN Accelerator",
    "authors": [
      "Sonu Kumar",
      "Komal Gupta",
      "Gopal Raut",
      "Mukul Lokhande",
      "Santosh Kumar Vishvakarma"
    ],
    "abstract": "Deep neural networks (DNNs) offer plenty of challenges in executing efficient\ncomputation at edge nodes, primarily due to the huge hardware resource demands.\nThe article proposes HYDRA, hybrid data multiplexing, and runtime layer\nconfigurable DNN accelerators to overcome the drawbacks. The work proposes a\nlayer-multiplexed approach, which further reuses a single activation function\nwithin the execution of a single layer with improved Fused-Multiply-Accumulate\n(FMA). The proposed approach works in iterative mode to reuse the same hardware\nand execute different layers in a configurable fashion. The proposed\narchitectures achieve reductions over 90% of power consumption and resource\nutilization improvements of state-of-the-art works, with 35.21 TOPSW. The\nproposed architecture reduces the area overhead (N-1) times required in\nbandwidth, AF and layer architecture. This work shows HYDRA architecture\nsupports optimal DNN computations while improving performance on\nresource-constrained edge devices.",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.CV",
      "eess.IV"
    ],
    "primary_category": "cs.AR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.04976v1",
    "published_date": "2024-09-08 05:10:02 UTC",
    "updated_date": "2024-09-08 05:10:02 UTC"
  },
  {
    "arxiv_id": "2409.04971v1",
    "title": "Soft Actor-Critic with Beta Policy via Implicit Reparameterization Gradients",
    "authors": [
      "Luca Della Libera"
    ],
    "abstract": "Recent advances in deep reinforcement learning have achieved impressive\nresults in a wide range of complex tasks, but poor sample efficiency remains a\nmajor obstacle to real-world deployment. Soft actor-critic (SAC) mitigates this\nproblem by combining stochastic policy optimization and off-policy learning,\nbut its applicability is restricted to distributions whose gradients can be\ncomputed through the reparameterization trick. This limitation excludes several\nimportant examples such as the beta distribution, which was shown to improve\nthe convergence rate of actor-critic algorithms in high-dimensional continuous\ncontrol problems thanks to its bounded support. To address this issue, we\ninvestigate the use of implicit reparameterization, a powerful technique that\nextends the class of reparameterizable distributions. In particular, we use\nimplicit reparameterization gradients to train SAC with the beta policy on\nsimulated robot locomotion environments and compare its performance with common\nbaselines. Experimental results show that the beta policy is a viable\nalternative, as it outperforms the normal policy and is on par with the\nsquashed normal policy, which is the go-to choice for SAC. The code is\navailable at https://github.com/lucadellalib/sac-beta.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "62M45",
      "I.2.8; I.2.6; I.5.1"
    ],
    "primary_category": "cs.LG",
    "comment": "10 pages",
    "pdf_url": "http://arxiv.org/pdf/2409.04971v1",
    "published_date": "2024-09-08 04:30:51 UTC",
    "updated_date": "2024-09-08 04:30:51 UTC"
  },
  {
    "arxiv_id": "2409.04964v2",
    "title": "Evaluation of Google Translate for Mandarin Chinese translation using sentiment and semantic analysis",
    "authors": [
      "Xuechun Wang",
      "Rodney Beard",
      "Rohitash Chandra"
    ],
    "abstract": "Machine translation using large language models (LLMs) is having a\nsignificant global impact, making communication easier. Mandarin Chinese is the\nofficial language used for communication by the government and media in China.\nIn this study, we provide an automated assessment of translation quality of\nGoogle Translate with human experts using sentiment and semantic analysis. In\norder to demonstrate our framework, we select the classic early\ntwentieth-century novel 'The True Story of Ah Q' with selected Mandarin Chinese\nto English translations. We use Google Translate to translate the given text\ninto English and then conduct a chapter-wise sentiment analysis and semantic\nanalysis to compare the extracted sentiments across the different translations.\nOur results indicate that the precision of Google Translate differs both in\nterms of semantic and sentiment analysis when compared to human expert\ntranslations. We find that Google Translate is unable to translate some of the\nspecific words or phrases in Chinese, such as Chinese traditional allusions.\nThe mistranslations may be due to lack of contextual significance and\nhistorical knowledge of China.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.04964v2",
    "published_date": "2024-09-08 04:03:55 UTC",
    "updated_date": "2024-09-16 10:00:52 UTC"
  },
  {
    "arxiv_id": "2409.04958v1",
    "title": "DDNet: Deformable Convolution and Dense FPN for Surface Defect Detection in Recycled Books",
    "authors": [
      "Jun Yu",
      "WenJian Wang"
    ],
    "abstract": "Recycled and recirculated books, such as ancient texts and reused textbooks,\nhold significant value in the second-hand goods market, with their worth\nlargely dependent on surface preservation. However, accurately assessing\nsurface defects is challenging due to the wide variations in shape, size, and\nthe often imprecise detection of defects. To address these issues, we propose\nDDNet, an innovative detection model designed to enhance defect localization\nand classification. DDNet introduces a surface defect feature extraction module\nbased on a deformable convolution operator (DC) and a densely connected FPN\nmodule (DFPN). The DC module dynamically adjusts the convolution grid to better\nalign with object contours, capturing subtle shape variations and improving\nboundary delineation and prediction accuracy. Meanwhile, DFPN leverages dense\nskip connections to enhance feature fusion, constructing a hierarchical\nstructure that generates multi-resolution, high-fidelity feature maps, thus\neffectively detecting defects of various sizes. In addition to the model, we\npresent a comprehensive dataset specifically curated for surface defect\ndetection in recycled and recirculated books. This dataset encompasses a\ndiverse range of defect types, shapes, and sizes, making it ideal for\nevaluating the robustness and effectiveness of defect detection models. Through\nextensive evaluations, DDNet achieves precise localization and classification\nof surface defects, recording a mAP value of 46.7% on our proprietary dataset -\nan improvement of 14.2% over the baseline model - demonstrating its superior\ndetection capabilities.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.04958v1",
    "published_date": "2024-09-08 03:18:19 UTC",
    "updated_date": "2024-09-08 03:18:19 UTC"
  },
  {
    "arxiv_id": "2409.04953v1",
    "title": "Evaluating Neural Networks Architectures for Spring Reverb Modelling",
    "authors": [
      "Francesco Papaleo",
      "Xavier Lizarraga-Seijas",
      "Frederic Font"
    ],
    "abstract": "Reverberation is a key element in spatial audio perception, historically\nachieved with the use of analogue devices, such as plate and spring reverb, and\nin the last decades with digital signal processing techniques that have allowed\ndifferent approaches for Virtual Analogue Modelling (VAM). The\nelectromechanical functioning of the spring reverb makes it a nonlinear system\nthat is difficult to fully emulate in the digital domain with white-box\nmodelling techniques. In this study, we compare five different neural network\narchitectures, including convolutional and recurrent models, to assess their\neffectiveness in replicating the characteristics of this audio effect. The\nevaluation is conducted on two datasets at sampling rates of 16 kHz and 48 kHz.\nThis paper specifically focuses on neural audio architectures that offer\nparametric control, aiming to advance the boundaries of current black-box\nmodelling techniques in the domain of spring reverberation.",
    "categories": [
      "cs.SD",
      "cs.AI"
    ],
    "primary_category": "cs.SD",
    "comment": "8 pages, 7 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2409.04953v1",
    "published_date": "2024-09-08 02:37:42 UTC",
    "updated_date": "2024-09-08 02:37:42 UTC"
  },
  {
    "arxiv_id": "2409.04949v1",
    "title": "Attention-Based Efficient Breath Sound Removal in Studio Audio Recordings",
    "authors": [
      "Nidula Elgiriyewithana",
      "N. D. Kodikara"
    ],
    "abstract": "In this research, we present an innovative, parameter-efficient model that\nutilizes the attention U-Net architecture for the automatic detection and\neradication of non-speech vocal sounds, specifically breath sounds, in vocal\nrecordings. This task is of paramount importance in the field of sound\nengineering, despite being relatively under-explored. The conventional manual\nprocess for detecting and eliminating these sounds requires significant\nexpertise and is extremely time-intensive. Existing automated detection and\nremoval methods often fall short in terms of efficiency and precision. Our\nproposed model addresses these limitations by offering a streamlined process\nand superior accuracy, achieved through the application of advanced deep\nlearning techniques. A unique dataset, derived from Device and Produced Speech\n(DAPS), was employed for this purpose. The training phase of the model\nemphasizes a log spectrogram and integrates an early stopping mechanism to\nprevent overfitting. Our model not only conserves precious time for sound\nengineers but also enhances the quality and consistency of audio production.\nThis constitutes a significant breakthrough, as evidenced by its comparative\nefficiency, necessitating only 1.9M parameters and a training duration of 3.2\nhours - markedly less than the top-performing models in this domain. The model\nis capable of generating identical outputs as previous models with drastically\nimproved precision, making it an optimal choice.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.04949v1",
    "published_date": "2024-09-08 02:11:33 UTC",
    "updated_date": "2024-09-08 02:11:33 UTC"
  },
  {
    "arxiv_id": "2409.07489v2",
    "title": "RAGent: Retrieval-based Access Control Policy Generation",
    "authors": [
      "Sakuna Harinda Jayasundara",
      "Nalin Asanka Gamagedara Arachchilage",
      "Giovanni Russello"
    ],
    "abstract": "Manually generating access control policies from an organization's high-level\nrequirement specifications poses significant challenges. It requires laborious\nefforts to sift through multiple documents containing such specifications and\ntranslate their access requirements into access control policies. Also, the\ncomplexities and ambiguities of these specifications often result in errors by\nsystem administrators during the translation process, leading to data breaches.\nHowever, the automated policy generation frameworks designed to help\nadministrators in this process are unreliable due to limitations, such as the\nlack of domain adaptation. Therefore, to improve the reliability of access\ncontrol policy generation, we propose RAGent, a novel retrieval-based access\ncontrol policy generation framework based on language models. RAGent identifies\naccess requirements from high-level requirement specifications with an average\nstate-of-the-art F1 score of 87.9%. Through retrieval augmented generation,\nRAGent then translates the identified access requirements into access control\npolicies with an F1 score of 77.9%. Unlike existing frameworks, RAGent\ngenerates policies with complex components like purposes and conditions, in\naddition to subjects, actions, and resources. Moreover, RAGent automatically\nverifies the generated policies and iteratively refines them through a novel\nverification-refinement mechanism, further improving the reliability of the\nprocess by 3%, reaching the F1 score of 80.6%. We also introduce three\nannotated datasets for developing access control policy generation frameworks\nin the future, addressing the data scarcity of the domain.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "Submitted to Usenix 2025",
    "pdf_url": "http://arxiv.org/pdf/2409.07489v2",
    "published_date": "2024-09-08 00:23:37 UTC",
    "updated_date": "2024-09-13 08:26:23 UTC"
  }
]