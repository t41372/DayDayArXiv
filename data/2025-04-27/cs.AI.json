{
  "date": "2025-04-27",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-04-27 的 arXiv 中文 TLDR 快报！今天 arXiv 更新了 53 篇论文，主要聚焦 AI 模型（如 LLM）的创新应用、AI 在工程和医学领域的优化，以及安全和数据处理挑战，其中令人印象深刻的包括 LLM 在火箭设计和医学图像分析中的强化学习增强，以及多模态 AI 的隐私风险评估。\n\n### 重点 AI 和 LLM 应用论文\n这些论文探讨了 LLM 在复杂任务中的潜力，相关主题包括工程优化、数据分析和安全治理，先从这些高话题度文章聊起。\n\n- **LLMs for Engineering: Teaching Models to Design High Powered Rockets（LLM 用于工程：教模型设计高功率火箭）**  \n  这篇论文评估了 LLM 在火箭设计的性能，通过 RocketBench 基准测试发现，标准 LLM 在模拟迭代中落后于人类，但结合强化学习后，一款 7B 参数模型超越了顶级模型和专家，展示了 RL-trained LLMs 在工程优化的潜力。\n\n- **From Inductive to Deductive: LLMs-Based Qualitative Data Analysis in Requirements Engineering（从归纳到演绎：基于 LLM 的定性数据分析在需求工程中）**  \n  作者包括 Syed Tauhid Ullah Shah 等，研究了 LLM（如 GPT-4）在需求工程中的定性分析，显示在演绎任务中 Cohen's Kappa 得分超过 0.7，强调详细提示提升了标注准确性和一致性，潜在应用包括自动要求追踪。\n\n- **SAGA: A Security Architecture for Governing AI Agentic Systems（SAGA：AI 代理系统治理的安全架构）**  \n  作者如 Georgios Syros 和 Alina Oprea 提出 SAGA 框架，用户可通过中央实体管理代理的访问控制和加密机制，实验证明在各种任务中性能开销最小，同时确保安全部署。\n\n- **Doxing via the Lens: Revealing Privacy Leakage in Image Geolocation for Agentic Multi-Modal Large Reasoning Model（通过镜头泄露隐私：代理多模态大推理模型中的图像地理定位隐私风险）**  \n  这篇论文揭示了如 ChatGPT o3 的模型在图像地理定位中泄露隐私，60% 的案例达到街级精度，并通过遮挡实验探索防御机制，强调了多模态 AI 的隐私挑战。\n\n- **Unified Multi-Task Learning & Model Fusion for Efficient Language Model Guardrailing（统一多任务学习和模型融合用于高效语言模型防护）**  \n  作者 James O' Neill 等开发了 MultiTaskGuard 和 UniGuard 方法，通过合成数据和模型合并提升了 LLM 的安全检测，F1 分数比现有方法高出近 30%，适用于资源受限场景。\n\n- **Small Models, Big Tasks: An Exploratory Empirical Study on Small Language Models for Function Calling（小模型，大任务：小语言模型在函数调用的探索性实证研究）**  \n  研究小语言模型在函数调用中的性能，发现微调和少样本学习能提升准确性，但输出格式遵守仍是挑战，适合边缘设备应用。\n\n其他相关 LLM 论文，如 **Anyprefer: An Agentic Framework for Preference Data Synthesis（Anyprefer：用于偏好数据合成的代理框架）** 和 **Adaptive Helpfulness-Harmlessness Alignment with Preference Vectors（基于偏好向量的适应性帮助-无害性对齐）**，快速提一下，它们通过代理游戏和向量融合优化了 LLM 的偏好数据生成和道德对齐，显著提高了模型的鲁棒性。\n\n### 医学和图像处理论文\n这些论文关注 AI 在健康领域的应用，相关主题包括图像分析和隐私保护，先挑出有影响力的。\n\n- **Low-Rank Adaptive Structural Priors for Generalizable Diabetic Retinopathy Grading（低秩自适应结构先验用于糖尿病视网膜病变分级）**  \n  作者如 Hao Chen 提出 LoASP 框架，通过学习血管和病变结构提升模型泛化性，在八个数据集上表现优于基线，实验显示直观的可解释性。\n\n- **MIA-Mind: A Multidimensional Interactive Attention Mechanism Based on MindSpore（MIA-Mind：基于 MindSpore 的多维交互注意力机制）**  \n  这篇论文引入多维注意力融合策略，提升了图像和数据分类的性能，在 CIFAR-10 和 ISBI2012 上准确率达 82.9% 和 78.7%，展示了轻量级模块的潜力。\n\n- **PAD: Phase-Amplitude Decoupling Fusion for Multi-Modal Land Cover Classification（PAD：相位-幅度解耦融合用于多模态土地覆盖分类）**  \n  提出 PAD 框架，通过傅立叶域解耦相位和幅度信息，提升 SAR 和 RGB 图像融合的准确性，在 WHU-OPT-SAR 数据集上达到 SOTA 水平。\n\n其他医学相关，如 **Machine Learning-Based Modeling of the Anode Heel Effect in X-ray Beam Monte Carlo Simulations（基于机器学习的 X 射线束阳极跟腱效应建模）** 和 **Low-Complexity CNN-Based Classification of Electroneurographic Signals（低复杂度 CNN 基于神经电图信号分类）**，它们优化了 X 射线模拟和信号分类的效率，但细节较技术化，这里不展开。\n\n### 其他值得注意的论文\n快速掠过一些硬件、安全和数据处理的论文，只提核心贡献。\n\n- **NSFlow: An End-to-End FPGA Framework with Scalable Dataflow Architecture for Neuro-Symbolic AI（NSFlow：用于神经符号 AI 的端到端 FPGA 框架）**  \n  开发了 NSFlow 框架，支持神经符号 AI 的高效加速，在多种工作负载上比 GPU 快 2 倍以上，适合实时应用。\n\n- **Generative AI for Character Animation: A Comprehensive Survey（生成式 AI 用于角色动画：全面调查）**  \n  这篇综述覆盖了生成 AI 在动画中的技术，如扩散模型和姿态合成，提供未来方向，适合 AI 动画研究者。\n\n剩余论文，如 **Electricity Cost Minimization for Multi-Workflow Allocation（多工作流分配的电力成本最小化）** 和 **Generative Adversarial Network based Voice Conversion（基于 GAN 的语音转换）** 等，涉及优化和生成模型，但影响力较小，这里仅简要提及，它们分别通过强化学习降低了数据中心成本，并提升了语音转换的真实性。\n\n总之，今天的 arXiv 更新突出了 AI 的实用性和挑战，LLM 在工程和安全的创新值得关注，建议读者优先查看这些领域以捕捉前沿动态。更多细节请查阅 arXiv！",
  "papers": [
    {
      "arxiv_id": "2504.19394v2",
      "title": "LLMs for Engineering: Teaching Models to Design High Powered Rockets",
      "title_zh": "翻译失败",
      "authors": [
        "Toby Simonds"
      ],
      "abstract": "Large Language Models (LLMs) have transformed software engineering, but their\napplication to physical engineering domains remains underexplored. This paper\nevaluates LLMs' capabilities in high-powered rocketry design through\nRocketBench, a benchmark connecting LLMs to high-fidelity rocket simulations.\nWe test models on two increasingly complex design tasks: target altitude\noptimization and precision landing challenges. Our findings reveal that while\nstate-of-the-art LLMs demonstrate strong baseline engineering knowledge, they\nstruggle to iterate on their designs when given simulation results and\nultimately plateau below human performance levels. However, when enhanced with\nreinforcement learning (RL), we show that a 7B parameter model outperforms both\nSoTA foundation models and human experts. This research demonstrates that\nRL-trained LLMs can serve as effective tools for complex engineering\noptimization, potentially transforming engineering domains beyond software\ndevelopment.",
      "tldr_zh": "这篇论文评估了大语言模型 (LLMs) 在高功率火箭设计等物理工程领域的应用潜力，通过引入 RocketBench 基准测试，将 LLMs 连接到高保真火箭模拟中。研究测试了 LLMs 在目标高度优化和精确着陆等任务上的表现，发现这些模型虽具备基础工程知识，但无法有效迭代设计并停滞在低于人类水平的性能。令人注目的是，当 LLMs 与强化学习 (RL) 结合时，一个 7B 参数模型超过了最先进的基线模型 (SoTA) 和人类专家。该研究证明，RL 训练的 LLMs 可作为复杂工程优化的有效工具，有望扩展到软件工程以外的领域。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.19394v2",
      "published_date": "2025-04-27 23:59:39 UTC",
      "updated_date": "2025-04-29 22:15:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:05:25.335808"
    },
    {
      "arxiv_id": "2504.19384v1",
      "title": "From Inductive to Deductive: LLMs-Based Qualitative Data Analysis in Requirements Engineering",
      "title_zh": "翻译失败",
      "authors": [
        "Syed Tauhid Ullah Shah",
        "Mohamad Hussein",
        "Ann Barcomb",
        "Mohammad Moshirpour"
      ],
      "abstract": "Requirements Engineering (RE) is essential for developing complex and\nregulated software projects. Given the challenges in transforming stakeholder\ninputs into consistent software designs, Qualitative Data Analysis (QDA)\nprovides a systematic approach to handling free-form data. However, traditional\nQDA methods are time-consuming and heavily reliant on manual effort. In this\npaper, we explore the use of Large Language Models (LLMs), including GPT-4,\nMistral, and LLaMA-2, to improve QDA tasks in RE. Our study evaluates LLMs'\nperformance in inductive (zero-shot) and deductive (one-shot, few-shot)\nannotation tasks, revealing that GPT-4 achieves substantial agreement with\nhuman analysts in deductive settings, with Cohen's Kappa scores exceeding 0.7,\nwhile zero-shot performance remains limited. Detailed, context-rich prompts\nsignificantly improve annotation accuracy and consistency, particularly in\ndeductive scenarios, and GPT-4 demonstrates high reliability across repeated\nruns. These findings highlight the potential of LLMs to support QDA in RE by\nreducing manual effort while maintaining annotation quality. The structured\nlabels automatically provide traceability of requirements and can be directly\nutilized as classes in domain models, facilitating systematic software design.",
      "tldr_zh": "该论文探讨了使用大型语言模型 (LLMs) 如 GPT-4、Mistral 和 LLaMA-2 来提升需求工程 (RE) 中的定性数据分析 (QDA)，以解决传统方法耗时且依赖手动努力的挑战。研究评估了 LLMs 在归纳 (inductive, zero-shot) 和演绎 (deductive, one-shot, few-shot) 标注任务中的性能，发现 GPT-4 在演绎设置中与人类分析师高度一致，Cohen's Kappa 分数超过 0.7，而 zero-shot 性能较为有限。详细的上下文丰富提示显著提高了标注的准确性和一致性，LLMs 展示了高可靠性，并能减少手动工作，同时自动生成结构化标签以提供需求的可追溯性，并直接应用于领域模型中，促进系统软件设计。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.19384v1",
      "published_date": "2025-04-27 23:21:52 UTC",
      "updated_date": "2025-04-27 23:21:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:05:38.035088"
    },
    {
      "arxiv_id": "2504.21034v1",
      "title": "SAGA: A Security Architecture for Governing AI Agentic Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Georgios Syros",
        "Anshuman Suri",
        "Cristina Nita-Rotaru",
        "Alina Oprea"
      ],
      "abstract": "Large Language Model (LLM)-based agents increasingly interact, collaborate,\nand delegate tasks to one another autonomously with minimal human interaction.\nIndustry guidelines for agentic system governance emphasize the need for users\nto maintain comprehensive control over their agents, mitigating potential\ndamage from malicious agents. Several proposed agentic system designs address\nagent identity, authorization, and delegation, but remain purely theoretical,\nwithout concrete implementation and evaluation. Most importantly, they do not\nprovide user-controlled agent management. To address this gap, we propose SAGA,\na Security Architecture for Governing Agentic systems, that offers user\noversight over their agents' lifecycle. In our design, users register their\nagents with a central entity, the Provider, that maintains agents contact\ninformation, user-defined access control policies, and helps agents enforce\nthese policies on inter-agent communication. We introduce a cryptographic\nmechanism for deriving access control tokens, that offers fine-grained control\nover an agent's interaction with other agents, balancing security and\nperformance consideration. We evaluate SAGA on several agentic tasks, using\nagents in different geolocations, and multiple on-device and cloud LLMs,\ndemonstrating minimal performance overhead with no impact on underlying task\nutility in a wide range of conditions. Our architecture enables secure and\ntrustworthy deployment of autonomous agents, accelerating the responsible\nadoption of this technology in sensitive environments.",
      "tldr_zh": "该论文提出 SAGA，一种安全架构，用于管理 AI 代理系统，旨在解决大型语言模型(LLM)代理在自主互动中可能带来的安全风险，并确保用户对代理生命周期的全面控制。SAGA 通过中心实体(Provider)注册代理、维护用户定义的访问控制策略，并引入加密机制生成细粒度访问控制令牌，实现代理间通信的安全性与性能平衡。实验评估显示，在不同地理位置和多种 LLM 的代理任务中，SAGA 只产生最小性能开销，同时不影响任务效用，从而促进自主代理在敏感环境中的可信部署。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.21034v1",
      "published_date": "2025-04-27 23:10:00 UTC",
      "updated_date": "2025-04-27 23:10:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:05:48.697152"
    },
    {
      "arxiv_id": "2504.19374v1",
      "title": "Rethinking Label-specific Features for Label Distribution Learning",
      "title_zh": "重新审视标签特定特征在标签分布学习中的应用",
      "authors": [
        "Suping Xu",
        "Chuyi Dai",
        "Lin Shang",
        "Changbin Shao",
        "Xibei Yang",
        "Witold Pedrycz"
      ],
      "abstract": "Label distribution learning (LDL) is an emerging learning paradigm designed\nto capture the relative importance of labels for each instance. Label-specific\nfeatures (LSFs), constructed by LIFT, have proven effective for learning tasks\nwith label ambiguity by leveraging clustering-based prototypes for each label\nto re-characterize instances. However, directly introducing LIFT into LDL tasks\ncan be suboptimal, as the prototypes it collects primarily reflect\nintra-cluster relationships while neglecting interactions among distinct\nclusters. Additionally, constructing LSFs using multi-perspective information,\nrather than relying solely on Euclidean distance, provides a more robust and\ncomprehensive representation of instances, mitigating noise and bias that may\narise from a single distance perspective. To address these limitations, we\nintroduce Structural Anchor Points (SAPs) to capture inter-cluster\ninteractions. This leads to a novel LSFs construction strategy, LIFT-SAP, which\nenhances LIFT by integrating both distance and direction information of each\ninstance relative to SAPs. Furthermore, we propose a novel LDL algorithm, Label\nDistribution Learning via Label-specifIc FeaTure with SAPs (LDL-LIFT-SAP),\nwhich unifies multiple label description degrees predicted from different LSF\nspaces into a cohesive label distribution. Extensive experiments on 15\nreal-world datasets demonstrate the effectiveness of LIFT-SAP over LIFT, as\nwell as the superiority of LDL-LIFT-SAP compared to seven other\nwell-established algorithms.",
      "tldr_zh": "本研究重新审视了 Label-specific Features (LSFs) 在 Label Distribution Learning (LDL) 中的应用，指出传统 LIFT 方法忽略了不同聚类间的互动，仅依赖欧氏距离导致潜在噪声和偏差。作者引入 Structural Anchor Points (SAPs) 来捕捉聚类间关系，并提出 LIFT-SAP 策略，通过整合距离和方向信息构建更 robust 的 LSFs。进而，开发了 LDL-LIFT-SAP 算法，将多视角 LSF 空间的标签描述统一成 cohesive 的标签分布。在 15 个真实数据集上的实验显示，LIFT-SAP 优于 LIFT，且 LDL-LIFT-SAP 超越了七种基准算法，证明了其有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "11 Pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.19374v1",
      "published_date": "2025-04-27 22:32:46 UTC",
      "updated_date": "2025-04-27 22:32:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:06:00.664334"
    },
    {
      "arxiv_id": "2504.19373v2",
      "title": "Doxing via the Lens: Revealing Privacy Leakage in Image Geolocation for Agentic Multi-Modal Large Reasoning Model",
      "title_zh": "翻译失败",
      "authors": [
        "Weidi Luo",
        "Qiming Zhang",
        "Tianyu Lu",
        "Xiaogeng Liu",
        "Yue Zhao",
        "Zhen Xiang",
        "Chaowei Xiao"
      ],
      "abstract": "The increasing capabilities of agentic multi-modal large reasoning models,\nsuch as ChatGPT o3, have raised critical concerns regarding privacy leakage\nthrough inadvertent image geolocation. In this paper, we conduct the first\nsystematic and controlled study on the potential privacy risks associated with\nvisual reasoning abilities of ChatGPT o3. We manually collect and construct a\ndataset comprising 50 real-world images that feature individuals alongside\nprivacy-relevant environmental elements, capturing realistic and sensitive\nscenarios for analysis. Our experimental evaluation reveals that ChatGPT o3 can\npredict user locations with high precision, achieving street-level accuracy\n(within one mile) in 60% of cases. Through analysis, we identify key visual\ncues, including street layout and front yard design, that significantly\ncontribute to the model inference success. Additionally, targeted occlusion\nexperiments demonstrate that masking critical features effectively mitigates\ngeolocation accuracy, providing insights into potential defense mechanisms. Our\nfindings highlight an urgent need for privacy-aware development for agentic\nmulti-modal large reasoning models, particularly in applications involving\nprivate imagery.",
      "tldr_zh": "本文首次系统研究了代理式多模态大型推理模型（如 ChatGPT o3）在图像地理定位中的隐私泄露风险，通过手动收集50张包含个人和隐私相关环境的真实图像进行实验。结果显示，ChatGPT o3 在60%的案例中能精确预测用户位置到街级（一英里以内），关键视觉线索如街道布局和前院设计是主要因素。针对性遮挡实验证明，掩盖这些关键特征可有效降低地理定位准确性，从而提供潜在防御机制。该研究强调了在涉及私人图像的应用中，开发隐私aware的模型迫在眉睫。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.19373v2",
      "published_date": "2025-04-27 22:26:45 UTC",
      "updated_date": "2025-04-29 12:00:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:06:12.950188"
    },
    {
      "arxiv_id": "2504.19370v1",
      "title": "Mitigating Bias in Facial Recognition Systems: Centroid Fairness Loss Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Jean-Rémy Conti",
        "Stéphan Clémençon"
      ],
      "abstract": "The urging societal demand for fair AI systems has put pressure on the\nresearch community to develop predictive models that are not only globally\naccurate but also meet new fairness criteria, reflecting the lack of disparate\nmistreatment with respect to sensitive attributes ($\\textit{e.g.}$ gender,\nethnicity, age). In particular, the variability of the errors made by certain\nFacial Recognition (FR) systems across specific segments of the population\ncompromises the deployment of the latter, and was judged unacceptable by\nregulatory authorities. Designing fair FR systems is a very challenging\nproblem, mainly due to the complex and functional nature of the performance\nmeasure used in this domain ($\\textit{i.e.}$ ROC curves) and because of the\nhuge heterogeneity of the face image datasets usually available for training.\nIn this paper, we propose a novel post-processing approach to improve the\nfairness of pre-trained FR models by optimizing a regression loss which acts on\ncentroid-based scores. Beyond the computational advantages of the method, we\npresent numerical experiments providing strong empirical evidence of the gain\nin fairness and of the ability to preserve global accuracy.",
      "tldr_zh": "本研究针对面部识别 (Facial Recognition) 系统中的偏差问题，提出了一种后处理方法，通过优化基于质心的回归损失 (centroid fairness loss optimization) 来提升模型的公平性，确保不同群体（如性别、种族、年龄）间的错误率更均衡。方法利用预训练模型，专注于调整质心分数，以应对复杂性能指标如 ROC curves 的挑战，同时利用异质面部图像数据集。实验结果显示，该方法在保持全局准确性的前提下，提高了公平性，提供强有力的实证支持。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at both the AFME and RegML Workshops at NeurIPS 2024. A\n  preliminary version has been accepted for publication by Springer Nature, in\n  the context of the ICPR 2024 conference",
      "pdf_url": "http://arxiv.org/pdf/2504.19370v1",
      "published_date": "2025-04-27 22:17:44 UTC",
      "updated_date": "2025-04-27 22:17:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:06:24.032150"
    },
    {
      "arxiv_id": "2504.19362v1",
      "title": "Low-Rank Adaptive Structural Priors for Generalizable Diabetic Retinopathy Grading",
      "title_zh": "翻译失败",
      "authors": [
        "Yunxuan Wang",
        "Ray Yin",
        "Yumei Tan",
        "Hao Chen",
        "Haiying Xia"
      ],
      "abstract": "Diabetic retinopathy (DR), a serious ocular complication of diabetes, is one\nof the primary causes of vision loss among retinal vascular diseases. Deep\nlearning methods have been extensively applied in the grading of diabetic\nretinopathy (DR). However, their performance declines significantly when\napplied to data outside the training distribution due to domain shifts. Domain\ngeneralization (DG) has emerged as a solution to this challenge. However, most\nexisting DG methods overlook lesion-specific features, resulting in\ninsufficient accuracy. In this paper, we propose a novel approach that enhances\nexisting DG methods by incorporating structural priors, inspired by the\nobservation that DR grading is heavily dependent on vessel and lesion\nstructures. We introduce Low-rank Adaptive Structural Priors (LoASP), a\nplug-and-play framework designed for seamless integration with existing DG\nmodels. LoASP improves generalization by learning adaptive structural\nrepresentations that are finely tuned to the complexities of DR diagnosis.\nExtensive experiments on eight diverse datasets validate its effectiveness in\nboth single-source and multi-source domain scenarios. Furthermore,\nvisualizations reveal that the learned structural priors intuitively align with\nthe intricate architecture of the vessels and lesions, providing compelling\ninsights into their interpretability and diagnostic relevance.",
      "tldr_zh": "本研究针对糖尿病视网膜病变 (DR) 分级问题，指出现有深度学习方法因领域偏移 (Domain Generalization, DG) 而在训练外数据上表现不佳。作者提出 Low-Rank Adaptive Structural Priors (LoASP)，一个可插入的框架，通过学习适应性结构表示（如血管和病变结构）来增强 DG 方法的泛化能力。实验在八个多样化数据集上验证了 LoASP 在单源和多源场景中的有效性，准确性显著提升，且视觉化结果显示其结构先验与实际解剖特征高度一致，提高了诊断的可解释性。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "Accepted by IJCNN 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.19362v1",
      "published_date": "2025-04-27 21:40:02 UTC",
      "updated_date": "2025-04-27 21:40:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:06:37.010812"
    },
    {
      "arxiv_id": "2504.19354v1",
      "title": "Neurosymbolic Association Rule Mining from Tabular Data",
      "title_zh": "翻译失败",
      "authors": [
        "Erkan Karabulut",
        "Paul Groth",
        "Victoria Degeler"
      ],
      "abstract": "Association Rule Mining (ARM) is the task of mining patterns among data\nfeatures in the form of logical rules, with applications across a myriad of\ndomains. However, high-dimensional datasets often result in an excessive number\nof rules, increasing execution time and negatively impacting downstream task\nperformance. Managing this rule explosion remains a central challenge in ARM\nresearch. To address this, we introduce Aerial+, a novel neurosymbolic ARM\nmethod. Aerial+ leverages an under-complete autoencoder to create a neural\nrepresentation of the data, capturing associations between features. It\nextracts rules from this neural representation by exploiting the model's\nreconstruction mechanism. Extensive evaluations on five datasets against seven\nbaselines demonstrate that Aerial+ achieves state-of-the-art results by\nlearning more concise, high-quality rule sets with full data coverage. When\nintegrated into rule-based interpretable machine learning models, Aerial+\nsignificantly reduces execution time while maintaining or improving accuracy.",
      "tldr_zh": "本论文提出了一种新型神经符号方法 Aerial+，用于从表格数据中进行 Association Rule Mining (ARM)，以解决高维数据集导致的规则爆炸问题，提高规则提取的效率和质量。Aerial+ 利用 under-complete autoencoder 创建数据神经表示，捕捉特征间的关联，并通过模型的重建机制提取更简洁、高质量的规则集，确保全数据覆盖。在五个数据集上与七个基线方法比较，Aerial+ 实现了最先进的结果，并在集成到基于规则的可解释机器学习模型中时显著减少执行时间，同时保持或提升准确性。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.19354v1",
      "published_date": "2025-04-27 20:43:33 UTC",
      "updated_date": "2025-04-27 20:43:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:06:48.786159"
    },
    {
      "arxiv_id": "2504.19353v1",
      "title": "Flow Along the K-Amplitude for Generative Modeling",
      "title_zh": "翻译失败",
      "authors": [
        "Weitao Du",
        "Shuning Chang",
        "Jiasheng Tang",
        "Yu Rong",
        "Fan Wang",
        "Shengchao Liu"
      ],
      "abstract": "In this work, we propose a novel generative learning paradigm, K-Flow, an\nalgorithm that flows along the $K$-amplitude. Here, $k$ is a scaling parameter\nthat organizes frequency bands (or projected coefficients), and amplitude\ndescribes the norm of such projected coefficients. By incorporating the\n$K$-amplitude decomposition, K-Flow enables flow matching across the scaling\nparameter as time. We discuss three venues and six properties of K-Flow, from\ntheoretical foundations, energy and temporal dynamics, and practical\napplications, respectively. Specifically, from the practical usage perspective,\nK-Flow allows steerable generation by controlling the information at different\nscales. To demonstrate the effectiveness of K-Flow, we conduct experiments on\nunconditional image generation, class-conditional image generation, and\nmolecule assembly generation. Additionally, we conduct three ablation studies\nto demonstrate how K-Flow steers scaling parameter to effectively control the\nresolution of image generation.",
      "tldr_zh": "本研究提出了一种新型生成学习范式 K-Flow，通过沿 K-amplitude 流动进行建模，其中 K 作为缩放参数组织频率带或投影系数，实现跨缩放参数的流匹配。K-Flow 具备理论基础、能量动态和实际应用的六个属性，允许用户通过控制不同规模的信息来指导生成过程。实验结果显示，该方法在无条件图像生成、类条件图像生成和分子组装生成上表现出色，并通过消融研究证明了 K 参数对图像分辨率的有效控制。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.19353v1",
      "published_date": "2025-04-27 20:38:24 UTC",
      "updated_date": "2025-04-27 20:38:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:06:59.932724"
    },
    {
      "arxiv_id": "2504.19341v1",
      "title": "PolyTouch: A Robust Multi-Modal Tactile Sensor for Contact-rich Manipulation Using Tactile-Diffusion Policies",
      "title_zh": "翻译失败",
      "authors": [
        "Jialiang Zhao",
        "Naveen Kuppuswamy",
        "Siyuan Feng",
        "Benjamin Burchfiel",
        "Edward Adelson"
      ],
      "abstract": "Achieving robust dexterous manipulation in unstructured domestic environments\nremains a significant challenge in robotics. Even with state-of-the-art robot\nlearning methods, haptic-oblivious control strategies (i.e. those relying only\non external vision and/or proprioception) often fall short due to occlusions,\nvisual complexities, and the need for precise contact interaction control. To\naddress these limitations, we introduce PolyTouch, a novel robot finger that\nintegrates camera-based tactile sensing, acoustic sensing, and peripheral\nvisual sensing into a single design that is compact and durable. PolyTouch\nprovides high-resolution tactile feedback across multiple temporal scales,\nwhich is essential for efficiently learning complex manipulation tasks.\nExperiments demonstrate an at least 20-fold increase in lifespan over\ncommercial tactile sensors, with a design that is both easy to manufacture and\nscalable. We then use this multi-modal tactile feedback along with\nvisuo-proprioceptive observations to synthesize a tactile-diffusion policy from\nhuman demonstrations; the resulting contact-aware control policy significantly\noutperforms haptic-oblivious policies in multiple contact-aware manipulation\npolicies. This paper highlights how effectively integrating multi-modal contact\nsensing can hasten the development of effective contact-aware manipulation\npolicies, paving the way for more reliable and versatile domestic robots. More\ninformation can be found at https://polytouch.alanz.info/",
      "tldr_zh": "本研究提出PolyTouch，一种集成相机-based tactile sensing、acoustic sensing和peripheral visual sensing的多模态触觉传感器，用于处理无结构家庭环境中复杂的接触丰富操作任务。PolyTouch的设计紧凑耐用，提供高分辨率的多时间尺度触觉反馈，并通过实验证明其寿命至少比商业传感器长20倍，且易于制造和扩展。研究进一步利用该传感器结合visuo-proprioceptive观察，从人类演示合成tactile-diffusion policy，结果显示这种接触感知策略在多种操作任务中显著优于无触觉策略，从而加速了可靠多功能家庭机器人的发展。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Nominated for the best paper award at ICRA 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.19341v1",
      "published_date": "2025-04-27 19:50:31 UTC",
      "updated_date": "2025-04-27 19:50:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:07:12.522536"
    },
    {
      "arxiv_id": "2504.19339v2",
      "title": "Explanatory Summarization with Discourse-Driven Planning",
      "title_zh": "翻译失败",
      "authors": [
        "Dongqi Liu",
        "Xi Yu",
        "Vera Demberg",
        "Mirella Lapata"
      ],
      "abstract": "Lay summaries for scientific documents typically include explanations to help\nreaders grasp sophisticated concepts or arguments. However, current automatic\nsummarization methods do not explicitly model explanations, which makes it\ndifficult to align the proportion of explanatory content with human-written\nsummaries. In this paper, we present a plan-based approach that leverages\ndiscourse frameworks to organize summary generation and guide explanatory\nsentences by prompting responses to the plan. Specifically, we propose two\ndiscourse-driven planning strategies, where the plan is conditioned as part of\nthe input or part of the output prefix, respectively. Empirical experiments on\nthree lay summarization datasets show that our approach outperforms existing\nstate-of-the-art methods in terms of summary quality, and it enhances model\nrobustness, controllability, and mitigates hallucination.",
      "tldr_zh": "本文提出了一种基于discourse frameworks的计划方法，用于生成科学文档的lay summarization，以更好地处理解释性内容，确保其比例与人工摘要相匹配。该方法包括两种discourse-driven planning策略：将计划作为输入的一部分或作为输出前缀的一部分，来指导解释性句子的生成。在三个lay summarization数据集上的实验表明，该方法在摘要质量上优于现有最先进方法，同时提升了模型的鲁棒性、可控性和减少了hallucination现象。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by the Transactions of the Association for Computational\n  Linguistics (TACL 2025)",
      "pdf_url": "http://arxiv.org/pdf/2504.19339v2",
      "published_date": "2025-04-27 19:47:36 UTC",
      "updated_date": "2025-05-11 09:00:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:07:24.062982"
    },
    {
      "arxiv_id": "2504.19333v2",
      "title": "Unified Multi-Task Learning & Model Fusion for Efficient Language Model Guardrailing",
      "title_zh": "翻译失败",
      "authors": [
        "James O' Neill",
        "Santhosh Subramanian",
        "Eric Lin",
        "Vaikkunth Mugunthan"
      ],
      "abstract": "The trend towards large language models (LLMs) for guardrailing against\nundesired behaviors is increasing and has shown promise for censoring user\ninputs. However, increased latency, memory consumption, hosting expenses and\nnon-structured outputs can make their use prohibitive.\n  In this work, we show that task-specific data generation can lead to\nfine-tuned classifiers that significantly outperform current state of the art\n(SoTA) while being orders of magnitude smaller. Secondly, we show that using a\nsingle model, \\texttt{MultiTaskGuard}, that is pretrained on a large\nsynthetically generated dataset with unique task instructions further improves\ngeneralization. Thirdly, our most performant models, \\texttt{UniGuard}, are\nfound using our proposed search-based model merging approach that finds an\noptimal set of parameters to combine single-policy models and multi-policy\nguardrail models. % On 7 public datasets and 4 guardrail benchmarks we created,\nour efficient guardrail classifiers improve over the best performing SoTA\npublicly available LLMs and 3$^{\\text{rd}}$ party guardrail APIs in detecting\nunsafe and safe behaviors by an average F1 score improvement of \\textbf{29.92}\npoints over Aegis-LlamaGuard and \\textbf{21.62} over \\texttt{gpt-4o},\nrespectively. Lastly, our guardrail synthetic data generation process that uses\ncustom task-specific guardrail poli",
      "tldr_zh": "本文提出了一种高效的语言模型防护框架，通过任务特定数据生成和微调分类器，使模型规模缩小几个数量级，同时显著优于当前SoTA模型。作者开发了MultiTaskGuard，使用单一模型在大型合成数据集上预训练，结合独特任务指令提升泛化能力；同时，通过基于搜索的模型合并方法创建UniGuard，进一步优化参数以结合单策略和多策略防护模型。在7个公共数据集和4个防护基准上，该方法在检测不安全行为时，F1分数比Aegis-LlamaGuard提高了29.92点，比gpt-4o提高了21.62点，为资源高效的LLMs防护提供了可靠解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.19333v2",
      "published_date": "2025-04-27 19:07:58 UTC",
      "updated_date": "2025-04-29 02:42:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:07:37.698973"
    },
    {
      "arxiv_id": "2504.20112v1",
      "title": "Supervised Pretraining for Material Property Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Chowdhury Mohammad Abid Rahman",
        "Aldo H. Romero",
        "Prashnna K. Gyawali"
      ],
      "abstract": "Accurate prediction of material properties facilitates the discovery of novel\nmaterials with tailored functionalities. Deep learning models have recently\nshown superior accuracy and flexibility in capturing structure-property\nrelationships. However, these models often rely on supervised learning, which\nrequires large, well-annotated datasets an expensive and time-consuming\nprocess. Self-supervised learning (SSL) offers a promising alternative by\npretraining on large, unlabeled datasets to develop foundation models that can\nbe fine-tuned for material property prediction. In this work, we propose\nsupervised pretraining, where available class information serves as surrogate\nlabels to guide learning, even when downstream tasks involve unrelated material\nproperties. We evaluate this strategy on two state-of-the-art SSL models and\nintroduce a novel framework for supervised pretraining. To further enhance\nrepresentation learning, we propose a graph-based augmentation technique that\ninjects noise to improve robustness without structurally deforming material\ngraphs. The resulting foundation models are fine-tuned for six challenging\nmaterial property predictions, achieving significant performance gains over\nbaselines, ranging from 2% to 6.67% improvement in mean absolute error (MAE)\nand establishing a new benchmark in material property prediction. This study\nrepresents the first exploration of supervised pertaining with surrogate labels\nin material property prediction, advancing methodology and application in the\nfield.",
      "tldr_zh": "该研究提出了一种 supervised pretraining 方法，用于材料属性预测，通过利用可用的类别信息作为代理标签（surrogate labels），来指导模型学习，即使这些标签与下游任务无关，从而减少对大规模标注数据集的依赖。\n他们评估了这一策略在两个最先进的 self-supervised learning (SSL) 模型上，并引入了一个新框架和基于图的增强技术，通过注入噪声来提升模型的鲁棒性，而不改变材料图的结构。\n实验结果显示，该方法在六种材料属性预测任务上实现了 2% 到 6.67% 的 mean absolute error (MAE) 改善，显著优于基线模型，并为该领域建立了新基准。",
      "categories": [
        "cs.LG",
        "cond-mat.mtrl-sci",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "21 pages, 7 figures, 2 algorithms, 6 tables",
      "pdf_url": "http://arxiv.org/pdf/2504.20112v1",
      "published_date": "2025-04-27 19:00:41 UTC",
      "updated_date": "2025-04-27 19:00:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:07:49.421145"
    },
    {
      "arxiv_id": "2504.19327v1",
      "title": "Platonic Grounding for Efficient Multimodal Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Moulik Choraria",
        "Xinbo Wu",
        "Akhil Bhimaraju",
        "Nitesh Sekhar",
        "Yue Wu",
        "Xu Zhang",
        "Prateek Singhal",
        "Lav R. Varshney"
      ],
      "abstract": "The hyperscaling of data and parameter count in Transformer-based models is\nyielding diminishing performance improvement, especially when weighed against\ntraining costs. Such plateauing indicates the importance of methods for more\nefficient finetuning and inference, while retaining similar performance. This\nis especially relevant for multimodal learning paradigms, where inference costs\nof processing multimodal tokens can determine the model's practical viability.\nAt the same time, research on representations and mechanistic interpretability\nhas improved our understanding of the inner workings of Transformer-based\nmodels; one such line of work reveals an implicit alignment in the deeper\nlayers of pretrained models, across modalities. Taking inspiration from this,\nwe motivate and propose a simple modification to existing multimodal frameworks\nthat rely on aligning pretrained models. We demonstrate that our approach\nmaintains and, in some cases, even improves performance of baseline methods\nwhile achieving significant gains in both training and inference-time compute.\nOur work also has implications for combining pretrained models into larger\nsystems efficiently.",
      "tldr_zh": "该研究指出，Transformer-based 模型的 hyperscaling 导致性能提升 diminishing，且训练成本高，因此需要更高效的 finetuning 和 inference 方法，尤其在多模态学习中处理 multimodal tokens 的成本至关重要。论文提出 Platonic Grounding，一种简单修改，利用预训练模型中更深层隐含的跨模态对齐，应用于现有多模态框架。实验结果显示，该方法维持或提升基线性能，同时显著降低训练和推理计算，并为高效组合预训练模型提供新启示。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.19327v1",
      "published_date": "2025-04-27 18:56:26 UTC",
      "updated_date": "2025-04-27 18:56:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:08:00.454097"
    },
    {
      "arxiv_id": "2504.19323v2",
      "title": "NSFlow: An End-to-End FPGA Framework with Scalable Dataflow Architecture for Neuro-Symbolic AI",
      "title_zh": "翻译失败",
      "authors": [
        "Hanchen Yang",
        "Zishen Wan",
        "Ritik Raj",
        "Joongun Park",
        "Ziwei Li",
        "Ananda Samajdar",
        "Arijit Raychowdhury",
        "Tushar Krishna"
      ],
      "abstract": "Neuro-Symbolic AI (NSAI) is an emerging paradigm that integrates neural\nnetworks with symbolic reasoning to enhance the transparency, reasoning\ncapabilities, and data efficiency of AI systems. Recent NSAI systems have\ngained traction due to their exceptional performance in reasoning tasks and\nhuman-AI collaborative scenarios. Despite these algorithmic advancements,\nexecuting NSAI tasks on existing hardware (e.g., CPUs, GPUs, TPUs) remains\nchallenging, due to their heterogeneous computing kernels, high memory\nintensity, and unique memory access patterns. Moreover, current NSAI algorithms\nexhibit significant variation in operation types and scales, making them\nincompatible with existing ML accelerators. These challenges highlight the need\nfor a versatile and flexible acceleration framework tailored to NSAI workloads.\nIn this paper, we propose NSFlow, an FPGA-based acceleration framework designed\nto achieve high efficiency, scalability, and versatility across NSAI systems.\nNSFlow features a design architecture generator that identifies workload data\ndependencies and creates optimized dataflow architectures, as well as a\nreconfigurable array with flexible compute units, re-organizable memory, and\nmixed-precision capabilities. Evaluating across NSAI workloads, NSFlow achieves\n31x speedup over Jetson TX2, more than 2x over GPU, 8x speedup over TPU-like\nsystolic array, and more than 3x over Xilinx DPU. NSFlow also demonstrates\nenhanced scalability, with only 4x runtime increase when symbolic workloads\nscale by 150x. To the best of our knowledge, NSFlow is the first framework to\nenable real-time generalizable NSAI algorithms acceleration, demonstrating a\npromising solution for next-generation cognitive systems.",
      "tldr_zh": "该论文提出 NSFlow，一种基于 FPGA 的端到端框架，针对 Neuro-Symbolic AI (NSAI) 的异构计算内核、高内存强度和独特内存访问模式等挑战，提供可扩展的数据流架构。NSFlow 包括设计架构生成器（识别工作负载数据依赖并优化架构）和可重配置数组（具备灵活计算单元、可重组内存及混合精度能力），以实现高效的 NSAI 任务加速。实验结果显示，NSFlow 比 Jetson TX2 快 31 倍、比 GPU 快 2 倍、比 TPU-like 阵列快 8 倍，并当符号工作负载规模增加 150 倍时仅运行时间增加 4 倍，作为首个实现实时通用 NSAI 算法加速的框架，为下一代认知系统提供了有前景的解决方案。",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.LG",
        "cs.PF"
      ],
      "primary_category": "cs.AR",
      "comment": "2025 IEEE/ACM Design Automation Conference (DAC)",
      "pdf_url": "http://arxiv.org/pdf/2504.19323v2",
      "published_date": "2025-04-27 18:28:43 UTC",
      "updated_date": "2025-04-29 14:56:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:08:14.337173"
    },
    {
      "arxiv_id": "2505.00029v1",
      "title": "Keep the General, Inject the Specific: Structured Dialogue Fine-Tuning for Knowledge Injection without Catastrophic Forgetting",
      "title_zh": "翻译失败",
      "authors": [
        "Yijie Hong",
        "Xiaofei Yin",
        "Xinzhong Wang",
        "Yi Tu",
        "Ya Guo",
        "Sufeng Duan",
        "Weiqiang Wang",
        "Lingyong Fang",
        "Depeng Wang",
        "Huijia Zhu"
      ],
      "abstract": "Large Vision Language Models have demonstrated impressive versatile\ncapabilities through extensive multimodal pre-training, but face significant\nlimitations when incorporating specialized knowledge domains beyond their\ntraining distribution. These models struggle with a fundamental dilemma: direct\nadaptation approaches that inject domain-specific knowledge often trigger\ncatastrophic forgetting of foundational visual-linguistic abilities. We\nintroduce Structured Dialogue Fine-Tuning (SDFT), an effective approach that\neffectively injects domain-specific knowledge while minimizing catastrophic\nforgetting. Drawing inspiration from supervised fine-tuning in LLMs and\nsubject-driven personalization in text-to-image diffusion models, our method\nemploys a three-phase dialogue structure: Foundation Preservation reinforces\npre-trained visual-linguistic alignment through caption tasks; Contrastive\nDisambiguation introduces carefully designed counterfactual examples to\nmaintain semantic boundaries; and Knowledge Specialization embeds specialized\ninformation through chain-of-thought reasoning. Experimental results across\nmultiple domains confirm SDFT's effectiveness in balancing specialized\nknowledge acquisition with general capability retention. Our key contributions\ninclude a data-centric dialogue template that balances foundational alignment\nwith targeted knowledge integration, a weighted multi-turn supervision\nframework, and comprehensive evaluation across diverse knowledge types.",
      "tldr_zh": "本研究针对 Large Vision Language Models 在注入领域特定知识时面临的 catastrophic forgetting 问题，提出了一种 Structured Dialogue Fine-Tuning (SDFT) 方法，以平衡一般能力和专业知识的保留。SDFT 采用三阶段对话结构：Foundation Preservation 通过标题任务强化预训练的视觉-语言对齐；Contrastive Disambiguation 使用反事实例子维护语义边界；Knowledge Specialization 通过 chain-of-thought reasoning 嵌入专业信息。实验结果显示，该方法在多个领域有效提升了专业知识获取，同时保留了基础能力，其关键贡献包括数据导向的对话模板、加权多轮监督框架，以及对多样知识类型的全面评估。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "13 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.00029v1",
      "published_date": "2025-04-27 18:04:02 UTC",
      "updated_date": "2025-04-27 18:04:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:08:24.497860"
    },
    {
      "arxiv_id": "2504.19320v1",
      "title": "Logic-Based Artificial Intelligence Algorithms Supporting Categorical Semantics",
      "title_zh": "翻译失败",
      "authors": [
        "Ralph Wojtowicz"
      ],
      "abstract": "This paper seeks to apply categorical logic to the design of artificial\nintelligent agents that reason symbolically about objects more richly\nstructured than sets. Using Johnstone's sequent calculus of terms- and\nformulae-in-context, we develop forward chaining and normal form algorithms for\nreasoning about objects in cartesian categories with the rules for Horn logic.\nWe also adapt first-order unification to support multi-sorted theories,\ncontexts, and fragments of first-order logic. The significance of these\nreformulations rests in the fact that they can be applied to reasoning about\nobjects in semantic categories that do not support classical logic or even all\nits connectives.",
      "tldr_zh": "这篇论文应用 categorical logic 来设计人工智能代理，实现对比集合更复杂结构对象的符号推理。作者使用 Johnstone's sequent calculus of terms- and formulae-in-context 开发了 forward chaining 和 normal form algorithms，以处理笛卡尔范畴中的 Horn 逻辑规则，并改编 first-order unification 来支持 multi-sorted theories、上下文和第一阶逻辑的片段。这些创新允许算法应用于不支持经典逻辑或其所有连接词的语义范畴中，提升了 AI 代理的推理灵活性和适用性。",
      "categories": [
        "cs.AI",
        "03, 18",
        "I.1.2"
      ],
      "primary_category": "cs.AI",
      "comment": "31 pages",
      "pdf_url": "http://arxiv.org/pdf/2504.19320v1",
      "published_date": "2025-04-27 18:02:02 UTC",
      "updated_date": "2025-04-27 18:02:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:08:37.148094"
    },
    {
      "arxiv_id": "2504.21033v1",
      "title": "Transcending Dimensions using Generative AI: Real-Time 3D Model Generation in Augmented Reality",
      "title_zh": "使用生成式 AI 超越维度：",
      "authors": [
        "Majid Behravan",
        "Maryam Haghani",
        "Denis Gracanin"
      ],
      "abstract": "Traditional 3D modeling requires technical expertise, specialized software,\nand time-intensive processes, making it inaccessible for many users. Our\nresearch aims to lower these barriers by combining generative AI and augmented\nreality (AR) into a cohesive system that allows users to easily generate,\nmanipulate, and interact with 3D models in real time, directly within AR\nenvironments. Utilizing cutting-edge AI models like Shap-E, we address the\ncomplex challenges of transforming 2D images into 3D representations in AR\nenvironments. Key challenges such as object isolation, handling intricate\nbackgrounds, and achieving seamless user interaction are tackled through\nadvanced object detection methods, such as Mask R-CNN. Evaluation results from\n35 participants reveal an overall System Usability Scale (SUS) score of 69.64,\nwith participants who engaged with AR/VR technologies more frequently rating\nthe system significantly higher, at 80.71. This research is particularly\nrelevant for applications in gaming, education, and AR-based e-commerce,\noffering intuitive, model creation for users without specialized skills.",
      "tldr_zh": "本研究旨在解决传统 3D 建模的复杂性和专业门槛问题，通过整合生成式 AI 和 Augmented Reality (AR)，开发了一个允许用户实时生成、操作和交互 3D 模型的系统。利用 Shap-E 等 AI 模型以及 Mask R-CNN 等高级对象检测技术，该系统有效处理从 2D 图像到 3D 表示的挑战，包括对象隔离、复杂背景和无缝用户交互。用户评估显示，35 名参与者对系统的 System Usability Scale (SUS) 得分达 69.64，尤其是熟悉 AR/VR 技术的用户评分高达 80.71。这一创新适用于游戏、教育和 AR 电子商务等领域，提供直观的 3D 模型创建方式。",
      "categories": [
        "cs.GR",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.GR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.21033v1",
      "published_date": "2025-04-27 17:19:48 UTC",
      "updated_date": "2025-04-27 17:19:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:08:49.983200"
    },
    {
      "arxiv_id": "2504.20109v1",
      "title": "Personalized Artificial General Intelligence (AGI) via Neuroscience-Inspired Continuous Learning Systems",
      "title_zh": "通过神经科学启发的连续学习系统实现个性化的人工通用智能 (AGI)",
      "authors": [
        "Rajeev Gupta",
        "Suhani Gupta",
        "Ronak Parikh",
        "Divya Gupta",
        "Amir Javaheri",
        "Jairaj Singh Shaktawat"
      ],
      "abstract": "Artificial Intelligence has made remarkable advancements in recent years,\nprimarily driven by increasingly large deep learning models. However, achieving\ntrue Artificial General Intelligence (AGI) demands fundamentally new\narchitectures rather than merely scaling up existing models. Current approaches\nlargely depend on expanding model parameters, which improves task-specific\nperformance but falls short in enabling continuous, adaptable, and generalized\nlearning. Achieving AGI capable of continuous learning and personalization on\nresource-constrained edge devices is an even bigger challenge.\n  This paper reviews the state of continual learning and neuroscience-inspired\nAI, and proposes a novel architecture for Personalized AGI that integrates\nbrain-like learning mechanisms for edge deployment. We review literature on\ncontinuous lifelong learning, catastrophic forgetting, and edge AI, and discuss\nkey neuroscience principles of human learning, including Synaptic Pruning,\nHebbian plasticity, Sparse Coding, and Dual Memory Systems, as inspirations for\nAI systems. Building on these insights, we outline an AI architecture that\nfeatures complementary fast-and-slow learning modules, synaptic\nself-optimization, and memory-efficient model updates to support on-device\nlifelong adaptation.\n  Conceptual diagrams of the proposed architecture and learning processes are\nprovided. We address challenges such as catastrophic forgetting, memory\nefficiency, and system scalability, and present application scenarios for\nmobile AI assistants and embodied AI systems like humanoid robots. We conclude\nwith key takeaways and future research directions toward truly continual,\npersonalized AGI on the edge. While the architecture is theoretical, it\nsynthesizes diverse findings and offers a roadmap for future implementation.",
      "tldr_zh": "这篇论文探讨了实现个性化 Artificial General Intelligence (AGI) 的挑战，强调当前深度学习模型通过扩大参数虽能提升特定任务性能，但无法支持真正的连续学习和适应性。作者审视了持续学习、神经科学启发的 AI 文献，并提出了一种新型架构，融合脑部机制如 Synaptic Pruning、Hebbian plasticity、Sparse Coding 和 Dual Memory Systems，包括快速与缓慢学习模块、突触自优化及内存高效更新，以实现边缘设备上的终身适应。实验虽为理论性设计，但通过概念图和应用场景（如移动 AI 助手和人形机器人）展示了解决 catastrophic forgetting 等问题的潜力，并为未来 AGI 实现提供了路线图。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "39 pages, 16 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.20109v1",
      "published_date": "2025-04-27 16:10:17 UTC",
      "updated_date": "2025-04-27 16:10:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:09:00.815191"
    },
    {
      "arxiv_id": "2504.19277v1",
      "title": "Small Models, Big Tasks: An Exploratory Empirical Study on Small Language Models for Function Calling",
      "title_zh": "小模型、大任务：小型语言模型用于函数调用的探索性实证研究",
      "authors": [
        "Ishan Kavathekar",
        "Raghav Donakanti",
        "Ponnurangam Kumaraguru",
        "Karthik Vaidhyanathan"
      ],
      "abstract": "Function calling is a complex task with widespread applications in domains\nsuch as information retrieval, software engineering and automation. For\nexample, a query to book the shortest flight from New York to London on January\n15 requires identifying the correct parameters to generate accurate function\ncalls. Large Language Models (LLMs) can automate this process but are\ncomputationally expensive and impractical in resource-constrained settings. In\ncontrast, Small Language Models (SLMs) can operate efficiently, offering faster\nresponse times, and lower computational demands, making them potential\ncandidates for function calling on edge devices. In this exploratory empirical\nstudy, we evaluate the efficacy of SLMs in generating function calls across\ndiverse domains using zero-shot, few-shot, and fine-tuning approaches, both\nwith and without prompt injection, while also providing the finetuned models to\nfacilitate future applications. Furthermore, we analyze the model responses\nacross a range of metrics, capturing various aspects of function call\ngeneration. Additionally, we perform experiments on an edge device to evaluate\ntheir performance in terms of latency and memory usage, providing useful\ninsights into their practical applicability. Our findings show that while SLMs\nimprove from zero-shot to few-shot and perform best with fine-tuning, they\nstruggle significantly with adhering to the given output format. Prompt\ninjection experiments further indicate that the models are generally robust and\nexhibit only a slight decline in performance. While SLMs demonstrate potential\nfor the function call generation task, our results also highlight areas that\nneed further refinement for real-time functioning.",
      "tldr_zh": "这篇论文通过实证研究探索了 Small Language Models (SLMs) 在功能调用任务中的效能，相比 Large Language Models (LLMs)，SLMs 因其高效性和低资源需求，更适合边缘设备应用。研究采用 zero-shot、few-shot 和 fine-tuning 方法，并评估了模型在不同领域下的响应质量、延迟和内存使用，同时测试了 prompt injection 的影响。结果表明，SLMs 的性能随训练增加而提升，但仍存在输出格式遵守的显著挑战，且整体表现出潜力，需要进一步优化以实现实时功能。",
      "categories": [
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at EASE 2025 AI Models and Data Evaluation track",
      "pdf_url": "http://arxiv.org/pdf/2504.19277v1",
      "published_date": "2025-04-27 15:26:51 UTC",
      "updated_date": "2025-04-27 15:26:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:09:13.190039"
    },
    {
      "arxiv_id": "2504.19276v1",
      "title": "Anyprefer: An Agentic Framework for Preference Data Synthesis",
      "title_zh": "翻译失败",
      "authors": [
        "Yiyang Zhou",
        "Zhaoyang Wang",
        "Tianle Wang",
        "Shangyu Xing",
        "Peng Xia",
        "Bo Li",
        "Kaiyuan Zheng",
        "Zijian Zhang",
        "Zhaorun Chen",
        "Wenhao Zheng",
        "Xuchao Zhang",
        "Chetan Bansal",
        "Weitong Zhang",
        "Ying Wei",
        "Mohit Bansal",
        "Huaxiu Yao"
      ],
      "abstract": "High-quality preference data is essential for aligning foundation models with\nhuman values through preference learning. However, manual annotation of such\ndata is often time-consuming and costly. Recent methods often adopt a\nself-rewarding approach, where the target model generates and annotates its own\npreference data, but this can lead to inaccuracies since the reward model\nshares weights with the target model, thereby amplifying inherent biases. To\naddress these issues, we propose Anyprefer, a framework designed to synthesize\nhigh-quality preference data for aligning the target model. Anyprefer frames\nthe data synthesis process as a cooperative two-player Markov Game, where the\ntarget model and the judge model collaborate together. Here, a series of\nexternal tools are introduced to assist the judge model in accurately rewarding\nthe target model's responses, mitigating biases in the rewarding process. In\naddition, a feedback mechanism is introduced to optimize prompts for both\nmodels, enhancing collaboration and improving data quality. The synthesized\ndata is compiled into a new preference dataset, Anyprefer-V1, consisting of 58K\nhigh-quality preference pairs. Extensive experiments show that Anyprefer\nsignificantly improves model alignment performance across four main\napplications, covering 21 datasets, achieving average improvements of 18.55% in\nfive natural language generation datasets, 3.66% in nine vision-language\nunderstanding datasets, 30.05% in three medical image analysis datasets, and\n16.00% in four visuo-motor control tasks.",
      "tldr_zh": "该研究提出 Anyprefer 框架，一种代理式方法，用于合成高品质偏好数据，以解决手动标注耗时和自奖励方法放大偏见的问题。Anyprefer 将数据合成过程建模为合作的两玩家 Markov Game，其中目标模型和判断模型协作，利用外部工具减少奖励偏见，并通过反馈机制优化提示以提升数据质量。最终，框架生成 Anyprefer-V1 数据集，包含 58K 偏好对，并在四个应用领域（如自然语言生成和视觉语言理解）上的 21 个数据集实验中，实现平均性能提升高达 18.55% 到 30.05%。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.19276v1",
      "published_date": "2025-04-27 15:21:59 UTC",
      "updated_date": "2025-04-27 15:21:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:09:24.479276"
    },
    {
      "arxiv_id": "2504.19275v1",
      "title": "Balancing Creativity and Automation: The Influence of AI on Modern Film Production and Dissemination",
      "title_zh": "平衡创造力和自动化：人工智能对现代电影制作和传播的影响",
      "authors": [
        "Yiren Xu"
      ],
      "abstract": "The integration of Artificial Intelligence(AI) into film production has\nrevolutionized efficiency and creativity, yet it simultaneously raises critical\nethical and practical challenges. This study explores the dual impact of AI on\nmodern cinema through three objectives: defining the optimal human-AI\nrelationship, balancing creativity with automation, and developing ethical\nguidelines. By employing a mixed-method approach combining theoretical\nframeworks (auteur theory, human-technology relations) and case studies (The\nSafe Zone, Fast & Furious 7, The Brutalist), the research reveals that\npositioning AI as an \"embodiment tool\" rather than an independent \"alterity\npartner\" preserves human authorship and artistic integrity. Key findings\nhighlight the risks of surveillance capitalism in AI-driven markets and the\nethical dilemmas of deepfake technology. The study concludes with actionable\nrecommendations, including international regulatory frameworks and a Human\nControl Index (HCI) to quantify AI involvement. These insights aim to guide\nfilmmakers, policymakers, and scholars in navigating the evolving AI-cinema\nlandscape while safeguarding cultural diversity and ethical standards.",
      "tldr_zh": "这篇论文探讨了人工智能（AI）在现代电影制作和传播中的双重影响，包括提升效率和创意的优势，以及潜在的伦理和实际挑战。研究采用混合方法，结合理论框架（如作者理论和人机关系）以及案例研究（如《The Safe Zone》、《Fast & Furious 7》和《The Brutalist》），揭示将 AI 视为“embodiment tool”而非独立“alterity partner”能更好地维护人类作者性和艺术完整性。论文的关键发现包括 AI 驱动市场的监控资本主义风险和 deepfake 技术的伦理困境，并提出 Human Control Index (HCI) 及国际监管框架等可操作建议，以指导电影制作人、政策制定者和学者在 AI-电影领域平衡创新与伦理，确保文化多样性。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "I.5.m"
      ],
      "primary_category": "cs.CY",
      "comment": "19 pages, 1 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2504.19275v1",
      "published_date": "2025-04-27 15:21:38 UTC",
      "updated_date": "2025-04-27 15:21:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:09:37.880059"
    },
    {
      "arxiv_id": "2504.19274v1",
      "title": "TeleSparse: Practical Privacy-Preserving Verification of Deep Neural Networks",
      "title_zh": "TeleSparse：实用的隐私保护深度神经网络验证",
      "authors": [
        "Mohammad M Maheri",
        "Hamed Haddadi",
        "Alex Davidson"
      ],
      "abstract": "Verification of the integrity of deep learning inference is crucial for\nunderstanding whether a model is being applied correctly. However, such\nverification typically requires access to model weights and (potentially\nsensitive or private) training data. So-called Zero-knowledge Succinct\nNon-Interactive Arguments of Knowledge (ZK-SNARKs) would appear to provide the\ncapability to verify model inference without access to such sensitive data.\nHowever, applying ZK-SNARKs to modern neural networks, such as transformers and\nlarge vision models, introduces significant computational overhead.\n  We present TeleSparse, a ZK-friendly post-processing mechanisms to produce\npractical solutions to this problem. TeleSparse tackles two fundamental\nchallenges inherent in applying ZK-SNARKs to modern neural networks: (1)\nReducing circuit constraints: Over-parameterized models result in numerous\nconstraints for ZK-SNARK verification, driving up memory and proof generation\ncosts. We address this by applying sparsification to neural network models,\nenhancing proof efficiency without compromising accuracy or security. (2)\nMinimizing the size of lookup tables required for non-linear functions, by\noptimizing activation ranges through neural teleportation, a novel adaptation\nfor narrowing activation functions' range.\n  TeleSparse reduces prover memory usage by 67% and proof generation time by\n46% on the same model, with an accuracy trade-off of approximately 1%. We\nimplement our framework using the Halo2 proving system and demonstrate its\neffectiveness across multiple architectures (Vision-transformer, ResNet,\nMobileNet) and datasets (ImageNet,CIFAR-10,CIFAR-100). This work opens new\ndirections for ZK-friendly model design, moving toward scalable,\nresource-efficient verifiable deep learning.",
      "tldr_zh": "该研究提出TeleSparse，一种实用的后处理机制，用于在不访问敏感数据的情况下验证深度神经网络的完整性，从而实现隐私保护。TeleSparse通过神经网络稀疏化(sparsification)减少ZK-SNARKs电路约束，以及通过neural teleportation优化激活函数范围来最小化查找表大小，显著降低证明生成开销，同时仅以约1%的准确性损失为代价。实验结果显示，TeleSparse在Vision-transformer、ResNet和MobileNet等架构上，使用Halo2证明系统，减少了证明者内存使用67%和生成时间46%。这项工作为ZK-friendly模型设计开辟了新路径，促进了可扩展的资源高效可验证深度学习。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "This paper has been accepted to the Privacy Enhancing Technologies\n  Symposium (PETS) 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.19274v1",
      "published_date": "2025-04-27 15:14:09 UTC",
      "updated_date": "2025-04-27 15:14:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:09:48.472407"
    },
    {
      "arxiv_id": "2504.19267v2",
      "title": "VIST-GPT: Ushering in the Era of Visual Storytelling with LLMs?",
      "title_zh": "翻译失败",
      "authors": [
        "Mohamed Gado",
        "Towhid Taliee",
        "Muhammad Memon",
        "Dmitry Ignatov",
        "Radu Timofte"
      ],
      "abstract": "Visual storytelling is an interdisciplinary field combining computer vision\nand natural language processing to generate cohesive narratives from sequences\nof images. This paper presents a novel approach that leverages recent\nadvancements in multimodal models, specifically adapting transformer-based\narchitectures and large multimodal models, for the visual storytelling task.\nLeveraging the large-scale Visual Storytelling (VIST) dataset, our VIST-GPT\nmodel produces visually grounded, contextually appropriate narratives. We\naddress the limitations of traditional evaluation metrics, such as BLEU,\nMETEOR, ROUGE, and CIDEr, which are not suitable for this task. Instead, we\nutilize RoViST and GROOVIST, novel reference-free metrics designed to assess\nvisual storytelling, focusing on visual grounding, coherence, and\nnon-redundancy. These metrics provide a more nuanced evaluation of narrative\nquality, aligning closely with human judgment.",
      "tldr_zh": "本论文介绍了 VIST-GPT 模型，这是一种利用大型语言模型 (LLMs) 和基于 transformer 的多模态架构来推进视觉叙事领域的新方法，通过处理图像序列生成视觉基础且上下文合适的叙述。研究者基于 Visual Storytelling (VIST) 数据集开发该模型，以克服传统评估指标如 BLEU、METEOR、ROUGE 和 CIDEr 的局限性，这些指标不适合评估叙事质量。取而代之，他们提出新的无参考指标 RoViST 和 GROOVIST，专注于视觉基础、一致性和非冗余，这些指标更贴近人类判断并提升了叙述评估的精确性。总的来说，VIST-GPT 标志着视觉叙事时代的到来，为生成连贯叙述提供了更可靠的框架。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.19267v2",
      "published_date": "2025-04-27 14:55:51 UTC",
      "updated_date": "2025-05-03 08:32:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:10:01.615279"
    },
    {
      "arxiv_id": "2505.00028v1",
      "title": "Enhancing Speech-to-Speech Dialogue Modeling with End-to-End Retrieval-Augmented Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Pengchao Feng",
        "Ziyang Ma",
        "Wenxi Chen",
        "Yao Li",
        "Sheng Wang",
        "Kai Yu",
        "Xie Chen"
      ],
      "abstract": "In recent years, end-to-end speech-to-speech (S2S) dialogue systems have\ngarnered increasing research attention due to their advantages over traditional\ncascaded systems, including achieving lower latency and more natural\nintegration of nonverbal cues such as emotion and speaker identity. However,\nthese end-to-end systems face key challenges, particularly in incorporating\nexternal knowledge, a capability commonly addressed by Retrieval-Augmented\nGeneration (RAG) in text-based large language models (LLMs). The core\ndifficulty lies in the modality gap between input speech and retrieved textual\nknowledge, which hinders effective integration. To address this issue, we\npropose a novel end-to-end RAG framework that directly retrieves relevant\ntextual knowledge from speech queries, eliminating the need for intermediate\nspeech-to-text conversion via techniques like ASR. Experimental results\ndemonstrate that our method significantly improves the performance of\nend-to-end S2S dialogue systems while achieving higher retrieval efficiency.\nAlthough the overall performance still lags behind cascaded models, our\nframework offers a promising direction for enhancing knowledge integration in\nend-to-end S2S systems. We will release the code and dataset to support\nreproducibility and promote further research in this area.",
      "tldr_zh": "该研究探讨了端到端语音到语音 (S2S) 对话系统的优势，如更低的延迟和更好的非语言线索整合，但强调了其在整合外部知识方面的挑战，特别是与 Retrieval-Augmented Generation (RAG) 在文本模型中的应用相比。作者提出了一种新型端到端 RAG 框架，直接从语音查询中检索相关文本知识， bypass 了 ASR 等中间转换步骤，从而提高了知识整合效率。实验结果显示，该框架显著提升了 S2S 系统的性能和检索效率，尽管整体表现仍落后于级联模型。该框架为未来端到端 S2S 系统的发展提供了有前景的方向，并将发布代码和数据集以支持进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00028v1",
      "published_date": "2025-04-27 14:35:24 UTC",
      "updated_date": "2025-04-27 14:35:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:10:13.964219"
    },
    {
      "arxiv_id": "2504.19255v1",
      "title": "The Convergent Ethics of AI? Analyzing Moral Foundation Priorities in Large Language Models with a Multi-Framework Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Chad Coleman",
        "W. Russell Neuman",
        "Ali Dasdan",
        "Safinah Ali",
        "Manan Shah"
      ],
      "abstract": "As large language models (LLMs) are increasingly deployed in consequential\ndecision-making contexts, systematically assessing their ethical reasoning\ncapabilities becomes a critical imperative. This paper introduces the\nPriorities in Reasoning and Intrinsic Moral Evaluation (PRIME) framework--a\ncomprehensive methodology for analyzing moral priorities across foundational\nethical dimensions including consequentialist-deontological reasoning, moral\nfoundations theory, and Kohlberg's developmental stages. We apply this\nframework to six leading LLMs through a dual-protocol approach combining direct\nquestioning and response analysis to established ethical dilemmas. Our analysis\nreveals striking patterns of convergence: all evaluated models demonstrate\nstrong prioritization of care/harm and fairness/cheating foundations while\nconsistently underweighting authority, loyalty, and sanctity dimensions.\nThrough detailed examination of confidence metrics, response reluctance\npatterns, and reasoning consistency, we establish that contemporary LLMs (1)\nproduce decisive ethical judgments, (2) demonstrate notable cross-model\nalignment in moral decision-making, and (3) generally correspond with\nempirically established human moral preferences. This research contributes a\nscalable, extensible methodology for ethical benchmarking while highlighting\nboth the promising capabilities and systematic limitations in current AI moral\nreasoning architectures--insights critical for responsible development as these\nsystems assume increasingly significant societal roles.",
      "tldr_zh": "本论文引入了 Priorities in Reasoning and Intrinsic Moral Evaluation (PRIME) 框架，通过多框架方法分析大型语言模型 (LLMs) 在道德基础上的优先级，包括 consequentialist-deontological reasoning、moral foundations theory 和 Kohlberg's developmental stages。\n研究采用直接提问和响应分析的双协议方法，对六种领先 LLMs 进行评估，发现所有模型强烈优先考虑 care/harm 和 fairness/cheating 维度，而轻视 authority、loyalty 和 sanctity 方面，并显示出跨模型的一致性与人类道德偏好的对应。\n这项工作提供了一个可扩展的道德基准测试方法，揭示了当前 AI 道德推理的优点（如决定性判断）和局限性（如系统性偏差），为负责任的 AI 开发提供了关键洞见。",
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "25 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.19255v1",
      "published_date": "2025-04-27 14:26:48 UTC",
      "updated_date": "2025-04-27 14:26:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:10:25.698091"
    },
    {
      "arxiv_id": "2504.19254v2",
      "title": "Uncertainty Quantification for Language Models: A Suite of Black-Box, White-Box, LLM Judge, and Ensemble Scorers",
      "title_zh": "语言模型的不确定性量化：一套黑盒、白盒、",
      "authors": [
        "Dylan Bouchard",
        "Mohit Singh Chauhan"
      ],
      "abstract": "Hallucinations are a persistent problem with Large Language Models (LLMs). As\nthese models become increasingly used in high-stakes domains, such as\nhealthcare and finance, the need for effective hallucination detection is\ncrucial. To this end, we propose a versatile framework for zero-resource\nhallucination detection that practitioners can apply to real-world use cases.\nTo achieve this, we adapt a variety of existing uncertainty quantification (UQ)\ntechniques, including black-box UQ, white-box UQ, and LLM-as-a-Judge,\ntransforming them as necessary into standardized response-level confidence\nscores ranging from 0 to 1. To enhance flexibility, we introduce a tunable\nensemble approach that incorporates any combination of the individual\nconfidence scores. This approach enables practitioners to optimize the ensemble\nfor a specific use case for improved performance. To streamline implementation,\nthe full suite of scorers is offered in this paper's companion Python toolkit,\nUQLM. To evaluate the performance of the various scorers, we conduct an\nextensive set of experiments using several LLM question-answering benchmarks.\nWe find that our tunable ensemble typically surpasses its individual components\nand outperforms existing hallucination detection methods. Our results\ndemonstrate the benefits of customized hallucination detection strategies for\nimproving the accuracy and reliability of LLMs.",
      "tldr_zh": "该论文提出了一种不确定性量化 (Uncertainty Quantification, UQ) 框架，用于检测 Large Language Models (LLMs) 的幻觉问题，尤其适用于高风险领域如医疗和金融。框架整合了 Black-Box UQ、White-Box UQ 和 LLM-as-a-Judge 等方法，将它们转化为 0 到 1 的标准化响应级信心分数，并引入可调谐的 Ensemble Scorers 来优化特定用例的性能。实验结果显示，该框架在多个 LLM 问答基准上优于现有幻觉检测方法，提高了模型的准确性和可靠性；同时，提供 Python 工具包 UQLM 以便实际应用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "UQLM repository: https://github.com/cvs-health/uqlm",
      "pdf_url": "http://arxiv.org/pdf/2504.19254v2",
      "published_date": "2025-04-27 14:24:45 UTC",
      "updated_date": "2025-04-30 16:49:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:10:38.067388"
    },
    {
      "arxiv_id": "2504.19223v1",
      "title": "CARL: Camera-Agnostic Representation Learning for Spectral Image Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Alexander Baumann",
        "Leonardo Ayala",
        "Silvia Seidlitz",
        "Jan Sellner",
        "Alexander Studier-Fischer",
        "Berkin Özdemir",
        "Lena Maier-Hein",
        "Slobodan Ilic"
      ],
      "abstract": "Spectral imaging offers promising applications across diverse domains,\nincluding medicine and urban scene understanding, and is already established as\na critical modality in remote sensing. However, variability in channel\ndimensionality and captured wavelengths among spectral cameras impede the\ndevelopment of AI-driven methodologies, leading to camera-specific models with\nlimited generalizability and inadequate cross-camera applicability. To address\nthis bottleneck, we introduce $\\textbf{CARL}$, a model for\n$\\textbf{C}$amera-$\\textbf{A}$gnostic $\\textbf{R}$epresentation\n$\\textbf{L}$earning across RGB, multispectral, and hyperspectral imaging\nmodalities. To enable the conversion of a spectral image with any channel\ndimensionality to a camera-agnostic embedding, we introduce wavelength\npositional encoding and a self-attention-cross-attention mechanism to compress\nspectral information into learned query representations. Spectral-spatial\npre-training is achieved with a novel spectral self-supervised JEPA-inspired\nstrategy tailored to CARL. Large-scale experiments across the domains of\nmedical imaging, autonomous driving, and satellite imaging demonstrate our\nmodel's unique robustness to spectral heterogeneity, outperforming on datasets\nwith simulated and real-world cross-camera spectral variations. The scalability\nand versatility of the proposed approach position our model as a backbone for\nfuture spectral foundation models.",
      "tldr_zh": "本研究提出 CARL 模型（Camera-Agnostic Representation Learning），旨在解决光谱图像分析中不同相机（如 RGB、多光谱和超光谱）间的通道维度和波长变异问题，实现相机无关的表示学习。方法包括引入波长位置编码和自注意力-交叉注意力机制，将光谱信息压缩到通用嵌入，并采用基于 JEPA 的光谱自监督策略进行光谱-空间预训练。实验在医疗成像、自动驾驶和卫星成像领域显示，CARL 在模拟和真实跨相机光谱变异数据集上表现出色，准确率优于基线模型，并为未来光谱基础模型提供可扩展的骨干框架。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.19223v1",
      "published_date": "2025-04-27 13:06:40 UTC",
      "updated_date": "2025-04-27 13:06:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:10:50.321128"
    },
    {
      "arxiv_id": "2505.06241v1",
      "title": "Low-Complexity CNN-Based Classification of Electroneurographic Signals",
      "title_zh": "翻译失败",
      "authors": [
        "Arek Berc Gokdag",
        "Silvia Mura",
        "Antonio Coviello",
        "Michele Zhu",
        "Maurizio Magarini",
        "Umberto Spagnolini"
      ],
      "abstract": "Peripheral nerve interfaces (PNIs) facilitate neural recording and\nstimulation for treating nerve injuries, but real-time classification of\nelectroneurographic (ENG) signals remains challenging due to constraints on\ncomplexity and latency, particularly in implantable devices. This study\nintroduces MobilESCAPE-Net, a lightweight architecture that reduces\ncomputational cost while maintaining and slightly improving classification\nperformance. Compared to the state-of-the-art ESCAPE-Net, MobilESCAPE-Net\nachieves comparable accuracy and F1-score with significantly lower complexity,\nreducing trainable parameters by 99.9\\% and floating point operations per\nsecond by 92.47\\%, enabling faster inference and real-time processing. Its\nefficiency makes it well-suited for low-complexity ENG signal classification in\nresource-constrained environments such as implantable devices.",
      "tldr_zh": "本研究针对外周神经接口(PNIs)中电神经图(ENG)信号的实时分类挑战，提出了一种低复杂度CNN架构MobilESCAPE-Net，以减少计算成本并支持植入式设备。\n相比于现有ESCAPE-Net，MobilESCAPE-Net在准确性和F1-score上保持相当水平，同时将可训练参数减少99.9%和浮点运算减少92.47%，从而实现更快推理和实时处理。\n这种高效设计使它特别适用于资源受限环境，如治疗神经损伤的植入式设备。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.06241v1",
      "published_date": "2025-04-27 12:45:01 UTC",
      "updated_date": "2025-04-27 12:45:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:11:01.053236"
    },
    {
      "arxiv_id": "2504.19212v1",
      "title": "CapsFake: A Multimodal Capsule Network for Detecting Instruction-Guided Deepfakes",
      "title_zh": "CapsFake：用于检测指令引导深度伪造的多模态胶囊网络",
      "authors": [
        "Tuan Nguyen",
        "Naseem Khan",
        "Issa Khalil"
      ],
      "abstract": "The rapid evolution of deepfake technology, particularly in\ninstruction-guided image editing, threatens the integrity of digital images by\nenabling subtle, context-aware manipulations. Generated conditionally from real\nimages and textual prompts, these edits are often imperceptible to both humans\nand existing detection systems, revealing significant limitations in current\ndefenses. We propose a novel multimodal capsule network, CapsFake, designed to\ndetect such deepfake image edits by integrating low-level capsules from visual,\ntextual, and frequency-domain modalities. High-level capsules, predicted\nthrough a competitive routing mechanism, dynamically aggregate local features\nto identify manipulated regions with precision. Evaluated on diverse datasets,\nincluding MagicBrush, Unsplash Edits, Open Images Edits, and Multi-turn Edits,\nCapsFake outperforms state-of-the-art methods by up to 20% in detection\naccuracy. Ablation studies validate its robustness, achieving detection rates\nabove 94% under natural perturbations and 96% against adversarial attacks, with\nexcellent generalization to unseen editing scenarios. This approach establishes\na powerful framework for countering sophisticated image manipulations.",
      "tldr_zh": "本文提出 CapsFake，一种多模态胶囊网络，用于检测基于指令引导的 deepfakes 图像编辑，该方法整合视觉、文本和频率域模态的低级胶囊，通过竞争路由机制动态聚合局部特征以精确识别操纵区域。相比现有方法，CapsFake 在 MagicBrush、Unsplash Edits 等数据集上的检测准确率提升高达 20%。消融研究显示其鲁棒性，在自然扰动下检测率超过 94%，在对抗攻击下超过 96%，并对未见编辑场景具有良好泛化能力，从而为对抗复杂图像操纵建立了一个强大框架。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "20 pages",
      "pdf_url": "http://arxiv.org/pdf/2504.19212v1",
      "published_date": "2025-04-27 12:31:47 UTC",
      "updated_date": "2025-04-27 12:31:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:11:14.090353"
    },
    {
      "arxiv_id": "2504.20106v1",
      "title": "Adaptive Helpfulness-Harmlessness Alignment with Preference Vectors",
      "title_zh": "翻译失败",
      "authors": [
        "Ren-Wei Liang",
        "Chin-Ting Hsu",
        "Chan-Hung Yu",
        "Saransh Agrawal",
        "Shih-Cheng Huang",
        "Shang-Tse Chen",
        "Kuan-Hao Huang",
        "Shao-Hua Sun"
      ],
      "abstract": "Ensuring that large language models (LLMs) are both helpful and harmless is a\ncritical challenge, as overly strict constraints can lead to excessive\nrefusals, while permissive models risk generating harmful content. Existing\napproaches, such as reinforcement learning from human feedback (RLHF) and\ndirect preference optimization (DPO), attempt to balance these trade-offs but\nsuffer from performance conflicts, limited controllability, and poor\nextendability. To address these issues, we propose Preference Vector, a novel\nframework inspired by task arithmetic. Instead of optimizing multiple\npreferences within a single objective, we train separate models on individual\npreferences, extract behavior shifts as preference vectors, and dynamically\nmerge them at test time. This modular approach enables fine-grained,\nuser-controllable preference adjustments and facilitates seamless integration\nof new preferences without retraining. Experiments show that our proposed\nPreference Vector framework improves helpfulness without excessive\nconservatism, allows smooth control over preference trade-offs, and supports\nscalable multi-preference alignment.",
      "tldr_zh": "该研究针对大型语言模型(LLMs)的helpfulness和harmlessness平衡挑战，提出Preference Vector框架，以解决现有方法如RLHF和DPO的性能冲突、控制性差和扩展性不足问题。该框架受task arithmetic启发，通过为每个偏好训练单独模型、提取行为偏移向量，并在测试时动态合并，实现细粒度的用户可控调整和无缝整合新偏好。实验显示，Preference Vector提高了模型的helpfulness而不导致过度保守性，支持平滑的偏好权衡和可扩展的多偏好对齐。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "22 pages, 5 figures, 9 tables",
      "pdf_url": "http://arxiv.org/pdf/2504.20106v1",
      "published_date": "2025-04-27 12:16:51 UTC",
      "updated_date": "2025-04-27 12:16:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:11:25.704118"
    },
    {
      "arxiv_id": "2504.20105v1",
      "title": "Electricity Cost Minimization for Multi-Workflow Allocation in Geo-Distributed Data Centers",
      "title_zh": "翻译失败",
      "authors": [
        "Shuang Wang",
        "He Zhang",
        "Tianxing Wu",
        "Yueyou Zhang",
        "Wei Emma Zhang",
        "Quan Z. Sheng"
      ],
      "abstract": "Worldwide, Geo-distributed Data Centers (GDCs) provide computing and storage\nservices for massive workflow applications, resulting in high electricity costs\nthat vary depending on geographical locations and time. How to reduce\nelectricity costs while satisfying the deadline constraints of workflow\napplications is important in GDCs, which is determined by the execution time of\nservers, power, and electricity price. Determining the completion time of\nworkflows with different server frequencies can be challenging, especially in\nscenarios with heterogeneous computing resources in GDCs. Moreover, the\nelectricity price is also different in geographical locations and may change\ndynamically. To address these challenges, we develop a geo-distributed system\narchitecture and propose an Electricity Cost aware Multiple Workflows\nScheduling algorithm (ECMWS) for servers of GDCs with fixed frequency and\npower. ECMWS comprises four stages, namely workflow sequencing, deadline\npartitioning, task sequencing, and resource allocation where two graph\nembedding models and a policy network are constructed to solve the Markov\nDecision Process (MDP). After statistically calibrating parameters and\nalgorithm components over a comprehensive set of workflow instances, the\nproposed algorithms are compared with the state-of-the-art methods over two\ntypes of workflow instances. The experimental results demonstrate that our\nproposed algorithm significantly outperforms other algorithms, achieving an\nimprovement of over 15\\% while maintaining an acceptable computational time.\nThe source codes are available at\nhttps://gitee.com/public-artifacts/ecmws-experiments.",
      "tldr_zh": "本研究针对地理分布的数据中心（Geo-Distributed Data Centers, GDCs）中多工作流的分配问题，旨在最小化电费成本，同时满足工作流的截止期限约束。作者提出了一种Electricity Cost aware Multiple Workflows Scheduling算法（ECMWS），该算法包括工作流排序、截止期限分区、任务排序和资源分配四个阶段，并利用两个图嵌入模型和一个策略网络来解决Markov Decision Process (MDP)。实验结果表明，ECMWS相较于现有方法提高了超过15%的性能，同时保持了可接受的计算时间。",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "have been accepted by IEEE Transactions on Services Computing",
      "pdf_url": "http://arxiv.org/pdf/2504.20105v1",
      "published_date": "2025-04-27 11:56:48 UTC",
      "updated_date": "2025-04-27 11:56:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:11:38.360099"
    },
    {
      "arxiv_id": "2504.19197v1",
      "title": "Generative Adversarial Network based Voice Conversion: Techniques, Challenges, and Recent Advancements",
      "title_zh": "翻译失败",
      "authors": [
        "Sandipan Dhar",
        "Nanda Dulal Jana",
        "Swagatam Das"
      ],
      "abstract": "Voice conversion (VC) stands as a crucial research area in speech synthesis,\nenabling the transformation of a speaker's vocal characteristics to resemble\nanother while preserving the linguistic content. This technology has broad\napplications, including automated movie dubbing, speech-to-singing conversion,\nand assistive devices for pathological speech rehabilitation. With the\nincreasing demand for high-quality and natural-sounding synthetic voices,\nresearchers have developed a wide range of VC techniques. Among these,\ngenerative adversarial network (GAN)-based approaches have drawn considerable\nattention for their powerful feature-mapping capabilities and potential to\nproduce highly realistic speech. Despite notable advancements, challenges such\nas ensuring training stability, maintaining linguistic consistency, and\nachieving perceptual naturalness continue to hinder progress in GAN-based VC\nsystems. This systematic review presents a comprehensive analysis of the voice\nconversion landscape, highlighting key techniques, key challenges, and the\ntransformative impact of GANs in the field. The survey categorizes existing\nmethods, examines technical obstacles, and critically evaluates recent\ndevelopments in GAN-based VC. By consolidating and synthesizing research\nfindings scattered across the literature, this review provides a structured\nunderstanding of the strengths and limitations of different approaches. The\nsignificance of this survey lies in its ability to guide future research by\nidentifying existing gaps, proposing potential directions, and offering\ninsights for building more robust and efficient VC systems. Overall, this work\nserves as an essential resource for researchers, developers, and practitioners\naiming to advance the state-of-the-art (SOTA) in voice conversion technology.",
      "tldr_zh": "这篇论文系统综述了语音转换 (Voice Conversion, VC) 技术，特别是基于生成对抗网络 (GAN) 的方法，强调其在转换说话者声音特征的同时保留语言内容的应用，如电影配音和病理语音康复。论文分析了 GAN 的优势，包括强大的特征映射能力以生成高度真实语音，以及面临的挑战，如训练稳定性、语言一致性和感知自然性。最终，通过分类现有方法、评估最新进展并识别研究差距，该工作为未来构建更 robust 和 efficient 的 VC 系统提供了宝贵指导和见解。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "19 pages, 12 figures, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2504.19197v1",
      "published_date": "2025-04-27 11:22:21 UTC",
      "updated_date": "2025-04-27 11:22:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:11:50.208438"
    },
    {
      "arxiv_id": "2504.19188v1",
      "title": "Hierarchical Attention Generates Better Proofs",
      "title_zh": "翻译失败",
      "authors": [
        "Jianlong Chen",
        "Chao Li",
        "Yang Yuan",
        "Andrew C Yao"
      ],
      "abstract": "Large language models (LLMs) have shown promise in formal theorem proving,\nbut their token-level processing often fails to capture the inherent\nhierarchical nature of mathematical proofs. We introduce \\textbf{Hierarchical\nAttention}, a regularization method that aligns LLMs' attention mechanisms with\nmathematical reasoning structures. Our approach establishes a five-level\nhierarchy from foundational elements to high-level concepts, ensuring\nstructured information flow in proof generation. Experiments demonstrate that\nour method improves proof success rates by 2.05\\% on miniF2F and 1.69\\% on\nProofNet while reducing proof complexity by 23.81\\% and 16.50\\% respectively.\nThe code is available at https://github.com/Car-pe/HAGBP.",
      "tldr_zh": "大型语言模型 (LLMs) 在形式定理证明中表现出潜力，但其 token 级处理无法有效捕捉数学证明的层次结构。为解决这一问题，本研究提出 Hierarchical Attention，一种正则化方法，将 LLMs 的注意力机制与数学推理结构对齐，并建立五级层次从基础元素到高级概念，以确保证明生成的结构化信息流。实验结果显示，该方法在 miniF2F 上将证明成功率提高了 2.05%，在 ProofNet 上提高了 1.69%，同时分别降低了证明复杂度 23.81% 和 16.50%。代码开源于 https://github.com/Car-pe/HAGBP。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.LO"
      ],
      "primary_category": "cs.LG",
      "comment": "15 pages with 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.19188v1",
      "published_date": "2025-04-27 10:35:05 UTC",
      "updated_date": "2025-04-27 10:35:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:12:04.196426"
    },
    {
      "arxiv_id": "2504.19179v1",
      "title": "A Design Framework for operationalizing Trustworthy Artificial Intelligence in Healthcare: Requirements, Tradeoffs and Challenges for its Clinical Adoption",
      "title_zh": "翻译失败",
      "authors": [
        "Pedro A. Moreno-Sánchez",
        "Javier Del Ser",
        "Mark van Gils",
        "Jussi Hernesniemi"
      ],
      "abstract": "Artificial Intelligence (AI) holds great promise for transforming healthcare,\nparticularly in disease diagnosis, prognosis, and patient care. The increasing\navailability of digital medical data, such as images, omics, biosignals, and\nelectronic health records, combined with advances in computing, has enabled AI\nmodels to approach expert-level performance. However, widespread clinical\nadoption remains limited, primarily due to challenges beyond technical\nperformance, including ethical concerns, regulatory barriers, and lack of\ntrust. To address these issues, AI systems must align with the principles of\nTrustworthy AI (TAI), which emphasize human agency and oversight, algorithmic\nrobustness, privacy and data governance, transparency, bias and discrimination\navoidance, and accountability. Yet, the complexity of healthcare processes\n(e.g., screening, diagnosis, prognosis, and treatment) and the diversity of\nstakeholders (clinicians, patients, providers, regulators) complicate the\nintegration of TAI principles. To bridge the gap between TAI theory and\npractical implementation, this paper proposes a design framework to support\ndevelopers in embedding TAI principles into medical AI systems. Thus, for each\nstakeholder identified across various healthcare processes, we propose a\ndisease-agnostic collection of requirements that medical AI systems should\nincorporate to adhere to the principles of TAI. Additionally, we examine the\nchallenges and tradeoffs that may arise when applying these principles in\npractice. To ground the discussion, we focus on cardiovascular diseases, a\nfield marked by both high prevalence and active AI innovation, and demonstrate\nhow TAI principles have been applied and where key obstacles persist.",
      "tldr_zh": "本论文提出一个设计框架，用于在医疗领域实现Trustworthy AI (TAI)的实际操作化，旨在解决AI在临床采用中的伦理、监管和信任挑战。该框架针对医疗过程（如诊断和治疗）中的不同利益相关者（如临床医生、患者和监管者），制定了疾病无关的要求，包括人类代理、算法鲁棒性、隐私保护、透明度和偏见避免等TAI原则。同时，论文讨论了应用这些原则可能带来的权衡和挑战，并以心血管疾病为例，展示了TAI在实际中的应用障碍和创新潜力，从而为医疗AI系统的可靠部署提供指导。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.19179v1",
      "published_date": "2025-04-27 09:57:35 UTC",
      "updated_date": "2025-04-27 09:57:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:12:13.539158"
    },
    {
      "arxiv_id": "2504.20103v1",
      "title": "Heterogeneous network drug-target interaction prediction model based on graph wavelet transform and multi-level contrastive learning",
      "title_zh": "基于图小波变换和多级对比",
      "authors": [
        "Wenfeng Dai",
        "Yanhong Wang",
        "Shuai Yan",
        "Qingzhi Yu",
        "Xiang Cheng"
      ],
      "abstract": "Drug-target interaction (DTI) prediction is a core task in drug development\nand precision medicine in the biomedical field. However, traditional machine\nlearning methods generally have the black box problem, which makes it difficult\nto reveal the deep correlation between the model decision mechanism and the\ninteraction pattern between biological molecules. This study proposes a\nheterogeneous network drug target interaction prediction framework, integrating\ngraph neural network and multi scale signal processing technology to construct\na model with both efficient prediction and multi level interpretability. Its\ntechnical breakthroughs are mainly reflected in the following three\ndimensions:Local global feature collaborative perception module. Based on\nheterogeneous graph convolutional neural network (HGCN), a multi order neighbor\naggregation strategy is designed.Multi scale graph signal decomposition and\nbiological interpretation module. A deep hierarchical node feature transform\n(GWT) architecture is proposed.Contrastive learning combining multi dimensional\nperspectives and hierarchical representations. By comparing the learning\nmodels, the node representations from the two perspectives of HGCN and GWT are\naligned and fused, so that the model can integrate multi dimensional\ninformation and improve the prediction robustness. Experimental results show\nthat our framework shows excellent prediction performance on all datasets. This\nstudy provides a complete solution for drug target discovery from black box\nprediction to mechanism decoding, and its methodology has important reference\nvalue for modeling complex biomolecular interaction systems.",
      "tldr_zh": "本研究提出了一种基于异构网络的药物靶点交互（Drug-target interaction, DTI）预测模型，整合图神经网络和多尺度信号处理技术，以解决传统机器学习黑箱问题的局限性。该模型包括三个关键模块：局部全局特征协作感知模块，利用异构图卷积神经网络（HGCN）设计多阶邻居聚合策略；多尺度图信号分解和生物解释模块，引入深度分层节点特征变换（Graph wavelet transform, GWT）架构；以及结合多维度视角的分层对比学习（Contrastive learning），通过对 HGCN 和 GWT 表示的对齐融合，提升预测的鲁棒性。实验结果显示，该框架在所有数据集上表现出色，提供从黑箱预测到机制解码的完整解决方案，对复杂生物分子交互系统的建模具有重要参考价值。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.QM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20103v1",
      "published_date": "2025-04-27 09:29:50 UTC",
      "updated_date": "2025-04-27 09:29:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:12:26.174356"
    },
    {
      "arxiv_id": "2504.20102v1",
      "title": "HyboWaveNet: Hyperbolic Graph Neural Networks with Multi-Scale Wavelet Transform for Protein-Protein Interaction Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Qingzhi Yu",
        "Shuai Yan",
        "Wenfeng Dai",
        "Xiang Cheng"
      ],
      "abstract": "Protein-protein interactions (PPIs) are fundamental for deciphering cellular\nfunctions,disease pathways,and drug discovery.Although existing neural networks\nand machine learning methods have achieved high accuracy in PPI\nprediction,their black-box nature leads to a lack of causal interpretation of\nthe prediction results and difficulty in capturing hierarchical geometries and\nmulti-scale dynamic interaction patterns among proteins.To address these\nchallenges, we propose HyboWaveNet,a novel deep learning framework that\ncollaborates with hyperbolic graphical neural networks (HGNNs) and multiscale\ngraphical wavelet transform for robust PPI prediction. Mapping protein features\nto Lorentz space simulates hierarchical topological relationships among\nbiomolecules via a hyperbolic distance metric,enabling node feature\nrepresentations that better fit biological a priori.HyboWaveNet inherently\nsimulates hierarchical and scale-free biological relationships, while the\nintegration of wavelet transforms enables adaptive extraction of local and\nglobal interaction features across different resolutions. Our framework\ngenerates node feature representations via a graph neural network under the\nLorenz model and generates pairs of positive samples under multiple different\nviews for comparative learning, followed by further feature extraction via\nmulti-scale graph wavelet transforms to predict potential PPIs. Experiments on\npublic datasets show that HyboWaveNet improves over both existing\nstate-of-the-art methods. We also demonstrate through ablation experimental\nstudies that the multi-scale graph wavelet transform module improves the\npredictive performance and generalization ability of HyboWaveNet. This work\nlinks geometric deep learning and signal processing to advance PPI prediction,\nproviding a principled approach for analyzing complex biological systems",
      "tldr_zh": "本文提出 HyboWaveNet，一种结合 Hyperbolic Graph Neural Networks (HGNNs) 和多尺度图形小波变换的深度学习框架，用于蛋白质-蛋白质相互作用 (PPIs) 预测，以解决现有方法缺乏因果解释和捕捉分层几何、多尺度动态模式的问题。该框架将蛋白质特征映射到 Lorentz 空间，使用 hyperbolic 距离度量模拟生物分层拓扑关系，并通过图神经网络生成节点特征、多视图对比学习创建正样本对，再利用多尺度图形小波变换提取局部和全局交互特征。实验在公共数据集上显示，HyboWaveNet 优于现有最先进方法，并通过消融实验证明多尺度小波变换模块提升了预测性能和泛化能力。该工作将几何深度学习与信号处理相结合，为分析复杂生物系统提供新的原理性方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.QM"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages",
      "pdf_url": "http://arxiv.org/pdf/2504.20102v1",
      "published_date": "2025-04-27 09:20:50 UTC",
      "updated_date": "2025-04-27 09:20:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:12:39.233474"
    },
    {
      "arxiv_id": "2504.19162v2",
      "title": "SPC: Evolving Self-Play Critic via Adversarial Games for LLM Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Jiaqi Chen",
        "Bang Zhang",
        "Ruotian Ma",
        "Peisong Wang",
        "Xiaodan Liang",
        "Zhaopeng Tu",
        "Xiaolong Li",
        "Kwan-Yee K. Wong"
      ],
      "abstract": "Evaluating the step-by-step reliability of large language model (LLM)\nreasoning, such as Chain-of-Thought, remains challenging due to the difficulty\nand cost of obtaining high-quality step-level supervision. In this paper, we\nintroduce Self-Play Critic (SPC), a novel approach where a critic model evolves\nits ability to assess reasoning steps through adversarial self-play games,\neliminating the need for manual step-level annotation. SPC involves fine-tuning\ntwo copies of a base model to play two roles, namely a \"sneaky generator\" that\ndeliberately produces erroneous steps designed to be difficult to detect, and a\n\"critic\" that analyzes the correctness of reasoning steps. These two models\nengage in an adversarial game in which the generator aims to fool the critic,\nwhile the critic model seeks to identify the generator's errors. Using\nreinforcement learning based on the game outcomes, the models iteratively\nimprove; the winner of each confrontation receives a positive reward and the\nloser receives a negative reward, driving continuous self-evolution.\nExperiments on three reasoning process benchmarks (ProcessBench, PRM800K,\nDeltaBench) demonstrate that our SPC progressively enhances its error detection\ncapabilities (e.g., accuracy increases from 70.8% to 77.7% on ProcessBench) and\nsurpasses strong baselines, including distilled R1 model. Furthermore, SPC can\nguide the test-time search of diverse LLMs and significantly improve their\nmathematical reasoning performance on MATH500 and AIME2024, surpassing those\nguided by state-of-the-art process reward models.",
      "tldr_zh": "本文提出 Self-Play Critic (SPC)，一种通过对抗性自博弈游戏提升大型语言模型 (LLM) 推理可靠性的新方法，无需手动标注步骤级监督。SPC 涉及两个模型：一个“sneaky generator”故意生成难检测的错误步骤，另一个“critic”模型试图识别这些错误，通过强化学习基于游戏结果（如赢家获正奖励）实现迭代优化。实验在 ProcessBench、PRM800K 和 DeltaBench 等基准上显示，SPC 的错误检测准确率显著提升（如 ProcessBench 从 70.8% 提高到 77.7%），并超越基线模型，同时能指导不同 LLM 在 MATH500 和 AIME2024 测试中提升数学推理性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Project webpage: https://chen-judge.github.io/SPC/",
      "pdf_url": "http://arxiv.org/pdf/2504.19162v2",
      "published_date": "2025-04-27 08:45:06 UTC",
      "updated_date": "2025-05-17 14:32:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:12:50.350113"
    },
    {
      "arxiv_id": "2504.19155v1",
      "title": "Machine Learning-Based Modeling of the Anode Heel Effect in X-ray Beam Monte Carlo Simulations",
      "title_zh": "翻译失败",
      "authors": [
        "Hussein Harb",
        "Didier Benoit",
        "Axel Rannou",
        "Chi-Hieu Pham",
        "Valentin Tissot",
        "Bahaa Nasr",
        "Julien Bert"
      ],
      "abstract": "This study enhances Monte Carlo simulation accuracy in X-ray imaging by\ndeveloping an AI-driven model for the anode heel effect, achieving improved\nbeam intensity distribution and dosimetric precision. Through dynamic\nadjustments to beam weights on the anode and cathode sides of the X-ray tube,\nour machine learning model effectively replicates the asymmetry characteristic\nof clinical X-ray beams. Experimental results reveal dose rate increases of up\nto 9.6% on the cathode side and reductions of up to 12.5% on the anode side,\nfor energy levels between 50 and 120 kVp. These experimentally optimized beam\nweights were integrated into the OpenGATE and GGEMS Monte Carlo toolkits,\nsignificantly advancing dosimetric simulation accuracy and the image quality\nwhich closely resembles the clinical imaging. Validation with fluence and dose\nactors demonstrated that the AI-based model closely mirrors clinical beam\nbehavior, providing substantial improvements in dose consistency and accuracy\nover conventional X-ray models. This approach provides a robust framework for\nimproving X-ray dosimetry, with potential applications in dose optimization,\nimaging quality enhancement, and radiation safety in both clinical and research\nsettings.",
      "tldr_zh": "本研究利用机器学习模型模拟 X-ray 束中的 anode heel effect，以提升 Monte Carlo simulations 在 X-ray 成像中的准确性。方法涉及动态调整 beam weights，实现临床 X-ray 束的不对称分布，实验结果显示在 50 到 120 kVp 能量水平下，阴极侧剂量率增加高达 9.6%，阳极侧减少高达 12.5%。该模型被整合到 OpenGATE 和 GGEMS 工具中，通过 fluence 和 dose actors 的验证，显著提高了剂量一致性和图像质量，提供了一个适用于剂量优化、图像质量提升及辐射安全的稳健框架。",
      "categories": [
        "physics.med-ph",
        "cs.AI"
      ],
      "primary_category": "physics.med-ph",
      "comment": "15 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.19155v1",
      "published_date": "2025-04-27 08:19:47 UTC",
      "updated_date": "2025-04-27 08:19:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:13:03.059080"
    },
    {
      "arxiv_id": "2504.21032v1",
      "title": "Selecting the Right LLM for eGov Explanations",
      "title_zh": "为 eGov 解释选择正确的",
      "authors": [
        "Lior Limonad",
        "Fabiana Fournier",
        "Hadar Mulian",
        "George Manias",
        "Spiros Borotis",
        "Danai Kyrkou"
      ],
      "abstract": "The perceived quality of the explanations accompanying e-government services\nis key to gaining trust in these institutions, consequently amplifying further\nusage of these services. Recent advances in generative AI, and concretely in\nLarge Language Models (LLMs) allow the automation of such content\narticulations, eliciting explanations' interpretability and fidelity, and more\ngenerally, adapting content to various audiences. However, selecting the right\nLLM type for this has become a non-trivial task for e-government service\nproviders. In this work, we adapted a previously developed scale to assist with\nthis selection, providing a systematic approach for the comparative analysis of\nthe perceived quality of explanations generated by various LLMs. We further\ndemonstrated its applicability through the tax-return process, using it as an\nexemplar use case that could benefit from employing an LLM to generate\nexplanations about tax refund decisions. This was attained through a user study\nwith 128 survey respondents who were asked to rate different versions of\nLLM-generated explanations about tax refund decisions, providing a\nmethodological basis for selecting the most appropriate LLM. Recognizing the\npractical challenges of conducting such a survey, we also began exploring the\nautomation of this process by attempting to replicate human feedback using a\nselection of cutting-edge predictive techniques.",
      "tldr_zh": "这篇论文探讨了如何为电子政府(eGov)服务选择合适的Large Language Models(LLMs)，以提升解释的质量、解释性和忠实度，从而增强用户信任和服务使用。研究者改编了一个先前开发的评估规模，通过一个用户研究（涉及128名参与者，对税务退税决策的LLM生成解释进行评分）来系统比较不同LLMs的感知质量。结果提供了选择LLMs的可靠方法论基础，并初步探索了使用预测技术自动化反馈过程，以应对实际调研挑战。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "8 pages, 7 figures. ICEDEG 2025, Bern, Switzerland, June 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.21032v1",
      "published_date": "2025-04-27 08:09:12 UTC",
      "updated_date": "2025-04-27 08:09:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:13:13.693030"
    },
    {
      "arxiv_id": "2504.19148v1",
      "title": "A Dynamic Fuzzy Rule and Attribute Management Framework for Fuzzy Inference Systems in High-Dimensional Data",
      "title_zh": "一种动态模糊规则和属性管理框架，用于高维数据中的模糊推理系统",
      "authors": [
        "Ke Liu",
        "Jing Ma",
        "Edmund M-K Lai"
      ],
      "abstract": "This paper presents an Adaptive Dynamic Attribute and Rule (ADAR) framework\ndesigned to address the challenges posed by high-dimensional data in\nneuro-fuzzy inference systems. By integrating dual weighting\nmechanisms-assigning adaptive importance to both attributes and rules-together\nwith automated growth and pruning strategies, ADAR adaptively streamlines\ncomplex fuzzy models without sacrificing performance or interpretability.\nExperimental evaluations on four diverse datasets - Auto MPG (7 variables),\nBeijing PM2.5 (10 variables), Boston Housing (13 variables), and Appliances\nEnergy Consumption (27 variables) show that ADAR-based models achieve\nconsistently lower Root Mean Square Error (RMSE) compared to state-of-the-art\nbaselines. On the Beijing PM2.5 dataset, for instance, ADAR-SOFENN attained an\nRMSE of 56.87 with nine rules, surpassing traditional ANFIS [12] and SOFENN\n[16] models. Similarly, on the high-dimensional Appliances Energy dataset,\nADAR-ANFIS reached an RMSE of 83.25 with nine rules, outperforming established\nfuzzy logic approaches and interpretability-focused methods such as APLR.\nAblation studies further reveal that combining rule-level and attribute-level\nweight assignment significantly reduces model overlap while preserving\nessential features, thereby enhancing explainability. These results highlight\nADAR's effectiveness in dynamically balancing rule complexity and feature\nimportance, paving the way for scalable, high-accuracy, and transparent\nneuro-fuzzy systems applicable to a range of real-world scenarios.",
      "tldr_zh": "本文提出了一种 Adaptive Dynamic Attribute and Rule (ADAR) 框架，用于解决高维数据在神经模糊推理系统中的挑战，通过整合双重加权机制（为属性和规则分配自适应重要性）以及自动增长和修剪策略，来动态简化复杂模糊模型，同时保持性能和可解释性。实验在四个数据集上进行，包括 Auto MPG、Beijing PM2.5、Boston Housing 和 Appliances Energy Consumption，结果显示 ADAR-based 模型的 Root Mean Square Error (RMSE)  consistently 低于现有基准，例如在 Beijing PM2.5 数据集上，ADAR-SOFENN 仅用九个规则就达到 56.87 的 RMSE，优于传统 ANFIS 和 SOFENN。消融研究进一步证明，结合规则级和属性级权重分配显著减少了模型重叠并保留了 essential features，提升了 explainability。这些结果突出了 ADAR 在平衡规则复杂性和特征重要性方面的有效性，为可扩展、高准确性和透明的神经模糊系统提供了新途径。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.19148v1",
      "published_date": "2025-04-27 08:02:10 UTC",
      "updated_date": "2025-04-27 08:02:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:13:27.760941"
    },
    {
      "arxiv_id": "2504.19144v1",
      "title": "ChiseLLM: Unleashing the Power of Reasoning LLMs for Chisel Agile Hardware Development",
      "title_zh": "翻译失败",
      "authors": [
        "Bowei Wang",
        "Jiaran Gao",
        "Yelai Feng",
        "Renzhi Chen",
        "Shanshan Li",
        "Lei Wang"
      ],
      "abstract": "The growing demand for Domain-Specific Architecture (DSA) has driven the\ndevelopment of Agile Hardware Development Methodology (AHDM). Hardware\nConstruction Language (HCL) like Chisel offers high-level abstraction features,\nmaking it an ideal language for HCL-Based AHDM. While Large Language Models\n(LLMs) excel in code generation tasks, they still face challenges with Chisel\ngeneration, particularly regarding syntax correctness and design variability.\nRecent reasoning models have significantly enhanced code generation\ncapabilities through test-time scaling techniques. However, we found that\nreasoning models without domain adaptation cannot bring substantial benefits to\nChisel code generation tasks. This paper presents ChiseLLM, a solution\ncomprising data processing and transformation, prompt-guided reasoning trace\nsynthesis, and domain-adapted model training. We constructed high-quality\ndatasets from public RTL code resources and guided the model to adopt\nstructured thinking patterns through prompt enhancement methods. Experiments\ndemonstrate that our ChiseLLM-7B and ChiseLLM-32B models improved syntax\ncorrectness by 18.85% and 26.32% respectively over base models, while\nincreasing variability design ability by 47.58% compared to baseline reasoning\nmodels. Our datasets and models are publicly available, providing\nhigh-performance, cost-effective models for HCL-Based AHDM, and offering an\neffective baseline for future research. Github repository:\nhttps://github.com/observerw/ChiseLLM",
      "tldr_zh": "这篇论文针对 Domain-Specific Architecture (DSA) 的需求，提出 ChiseLLM 框架，以提升 Large Language Models (LLMs) 在 Chisel 硬件开发中的代码生成能力，特别是解决语法正确性和设计变异性挑战。ChiseLLM 通过数据处理和转换、prompt-guided reasoning trace synthesis 以及 domain-adapted model training 等方法，从公共 RTL 代码资源构建高质量数据集，并引导模型采用结构化思考模式。实验结果显示，ChiseLLM-7B 和 ChiseLLM-32B 模型分别将语法正确性提高了 18.85% 和 26.32%，设计变异性提高了 47.58%。该框架及其数据集已公开可用，为 Hardware Construction Language (HCL)-Based Agile Hardware Development Methodology (AHDM) 提供高效、成本有效的基线，并支持未来研究。",
      "categories": [
        "cs.AI",
        "cs.AR",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.19144v1",
      "published_date": "2025-04-27 07:56:49 UTC",
      "updated_date": "2025-04-27 07:56:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:13:39.666973"
    },
    {
      "arxiv_id": "2504.19142v1",
      "title": "BQSched: A Non-intrusive Scheduler for Batch Concurrent Queries via Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Chenhao Xu",
        "Chunyu Chen",
        "Jinglin Peng",
        "Jiannan Wang",
        "Jun Gao"
      ],
      "abstract": "Most large enterprises build predefined data pipelines and execute them\nperiodically to process operational data using SQL queries for various tasks. A\nkey issue in minimizing the overall makespan of these pipelines is the\nefficient scheduling of concurrent queries within the pipelines. Existing tools\nmainly rely on simple heuristic rules due to the difficulty of expressing the\ncomplex features and mutual influences of queries. The latest reinforcement\nlearning (RL) based methods have the potential to capture these patterns from\nfeedback, but it is non-trivial to apply them directly due to the large\nscheduling space, high sampling cost, and poor sample utilization.\n  Motivated by these challenges, we propose BQSched, a non-intrusive Scheduler\nfor Batch concurrent Queries via reinforcement learning. Specifically, BQSched\ndesigns an attention-based state representation to capture the complex query\npatterns, and proposes IQ-PPO, an auxiliary task-enhanced proximal policy\noptimization (PPO) algorithm, to fully exploit the rich signals of Individual\nQuery completion in logs. Based on the RL framework above, BQSched further\nintroduces three optimization strategies, including adaptive masking to prune\nthe action space, scheduling gain-based query clustering to deal with large\nquery sets, and an incremental simulator to reduce sampling cost. To our\nknowledge, BQSched is the first non-intrusive batch query scheduler via RL.\nExtensive experiments show that BQSched can significantly improve the\nefficiency and stability of batch query scheduling, while also achieving\nremarkable scalability and adaptability in both data and queries. For example,\nacross all DBMSs and scales tested, BQSched reduces the overall makespan of\nbatch queries on TPC-DS benchmark by an average of 34% and 13%, compared with\nthe commonly used heuristic strategy and the adapted RL-based scheduler,\nrespectively.",
      "tldr_zh": "该研究针对企业数据管道中批量并发查询的调度问题，提出BQSched，一种基于Reinforcement Learning的非侵入式调度器，以解决现有启发式规则的局限性和RL应用的挑战。具体而言，BQSched采用attention-based state representation捕捉复杂查询模式，并引入IQ-PPO算法（一种辅助任务增强的Proximal Policy Optimization），结合adaptive masking、scheduling gain-based query clustering和incremental simulator等优化策略，提升效率和样本利用率。实验结果显示，在TPC-DS基准上，BQSched比传统启发式策略减少makespan 34%，并比适应RL调度器减少13%，展示了其在可扩展性和适应性方面的显著优势。",
      "categories": [
        "cs.DB",
        "cs.AI"
      ],
      "primary_category": "cs.DB",
      "comment": "Accepted by ICDE '25",
      "pdf_url": "http://arxiv.org/pdf/2504.19142v1",
      "published_date": "2025-04-27 07:49:01 UTC",
      "updated_date": "2025-04-27 07:49:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:13:51.008822"
    },
    {
      "arxiv_id": "2504.19139v3",
      "title": "Fast and Robust: Task Sampling with Posterior and Diversity Synergies for Adaptive Decision-Makers in Randomized Environments",
      "title_zh": "翻译失败",
      "authors": [
        "Yun Qu",
        "Qi Cheems Wang",
        "Yixiu Mao",
        "Yiqin Lv",
        "Xiangyang Ji"
      ],
      "abstract": "Task robust adaptation is a long-standing pursuit in sequential\ndecision-making. Some risk-averse strategies, e.g., the conditional\nvalue-at-risk principle, are incorporated in domain randomization or meta\nreinforcement learning to prioritize difficult tasks in optimization, which\ndemand costly intensive evaluations. The efficiency issue prompts the\ndevelopment of robust active task sampling to train adaptive policies, where\nrisk-predictive models are used to surrogate policy evaluation. This work\ncharacterizes the optimization pipeline of robust active task sampling as a\nMarkov decision process, posits theoretical and practical insights, and\nconstitutes robustness concepts in risk-averse scenarios. Importantly, we\npropose an easy-to-implement method, referred to as Posterior and Diversity\nSynergized Task Sampling (PDTS), to accommodate fast and robust sequential\ndecision-making. Extensive experiments show that PDTS unlocks the potential of\nrobust active task sampling, significantly improves the zero-shot and few-shot\nadaptation robustness in challenging tasks, and even accelerates the learning\nprocess under certain scenarios. Our project website is at\nhttps://thu-rllab.github.io/PDTS_project_page.",
      "tldr_zh": "本文探讨了顺序决策中任务鲁棒适应的挑战，指出现有风险厌恶策略如 conditional value-at-risk principle 在 domain randomization 和 meta reinforcement learning 中的优化过程需耗费大量评估，导致效率低下。作者将鲁棒主动任务采样建模为 Markov decision process，并提出易于实现的 Posterior and Diversity Synergized Task Sampling (PDTS) 方法，通过后验和多样性协同机制来提升适应性策略的训练效率。实验结果表明，PDTS 显著提高了零样本和少样本适应鲁棒性，并在某些场景下加速了学习过程。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "ICML 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.19139v3",
      "published_date": "2025-04-27 07:27:17 UTC",
      "updated_date": "2025-05-15 01:51:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:14:02.184081"
    },
    {
      "arxiv_id": "2504.19136v1",
      "title": "PAD: Phase-Amplitude Decoupling Fusion for Multi-Modal Land Cover Classification",
      "title_zh": "PAD：相位-幅度解耦融合用于多模态土地覆盖分类",
      "authors": [
        "Huiling Zheng",
        "Xian Zhong",
        "Bin Liu",
        "Yi Xiao",
        "Bihan Wen",
        "Xiaofeng Li"
      ],
      "abstract": "The fusion of Synthetic Aperture Radar (SAR) and RGB imagery for land cover\nclassification remains challenging due to modality heterogeneity and the\nunderutilization of spectral complementarity. Existing methods often fail to\ndecouple shared structural features from modality-specific radiometric\nattributes, leading to feature conflicts and information loss. To address this\nissue, we propose Phase-Amplitude Decoupling (PAD), a frequency-aware framework\nthat separates phase (modality-shared) and amplitude (modality-specific)\ncomponents in the Fourier domain. Specifically, PAD consists of two key\ncomponents: 1) Phase Spectrum Correction (PSC), which aligns cross-modal phase\nfeatures through convolution-guided scaling to enhance geometric consistency,\nand 2) Amplitude Spectrum Fusion (ASF), which dynamically integrates\nhigh-frequency details and low-frequency structures using frequency-adaptive\nmultilayer perceptrons. This approach leverages SAR's sensitivity to\nmorphological features and RGB's spectral richness. Extensive experiments on\nWHU-OPT-SAR and DDHR-SK datasets demonstrate state-of-the-art performance. Our\nwork establishes a new paradigm for physics-aware multi-modal fusion in remote\nsensing. The code will be available at https://github.com/RanFeng2/PAD.",
      "tldr_zh": "该研究针对 SAR 和 RGB 图像在土地覆盖分类中的融合挑战，提出 Phase-Amplitude Decoupling (PAD) 框架，以解决模态异质性和光谱互补性未充分利用的问题。PAD 在 Fourier domain 分离相位（模态共享）和幅度（模态特定）组件，包括 Phase Spectrum Correction (PSC) 通过卷积引导缩放对齐相位特征以提升几何一致性，以及 Amplitude Spectrum Fusion (ASF) 使用频率自适应多层感知器动态整合高频细节和低频结构，从而利用 SAR 的形态敏感性和 RGB 的光谱丰富性。在 WHU-OPT-SAR 和 DDHR-SK 数据集上的实验显示，PAD 实现了最先进性能，并为物理感知的多模态融合在遥感领域建立了新范式。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "13 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.19136v1",
      "published_date": "2025-04-27 07:21:42 UTC",
      "updated_date": "2025-04-27 07:21:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:14:14.349910"
    },
    {
      "arxiv_id": "2504.19120v1",
      "title": "Beyond Levels of Driving Automation: A Triadic Framework of Human-AI Collaboration in On-Road Mobility",
      "title_zh": "翻译失败",
      "authors": [
        "Gaojian Huang",
        "Yantong Jin",
        "Wei-Hsiang Lo"
      ],
      "abstract": "The goal of the current study is to introduce a triadic human-AI\ncollaboration framework for the automated vehicle domain. Previous\nclassifications (e.g., SAE Levels of Automation) focus on defining automation\nlevels based on who controls the vehicle. However, it remains unclear how human\nusers and AI should collaborate in real-time, especially in dynamic driving\ncontexts, where roles can shift frequently. To fill the gap, this study\nproposes a triadic human-AI collaboration framework with three AI roles (i.e.,\nAdvisor, Co-Pilot, and Guardian) that dynamically adapt to human needs.\nOverall, the study lays a foundation for developing adaptive, role-based\nhuman-AI collaboration strategies in automated vehicles.",
      "tldr_zh": "这篇论文提出一个 triadic human-AI collaboration framework，用于自动驾驶车辆领域，以超越传统的 SAE Levels of Automation 分类，该分类仅关注谁控制车辆，而忽略了动态驾驶环境中人类和 AI 的实时协作。框架定义了三个 AI 角色（Advisor、Co-Pilot 和 Guardian），这些角色能根据人类需求动态调整，以应对角色频繁切换的场景。该研究为开发适应性、基于角色的人类-AI 协作策略奠定基础，从而提升道路机动性中的安全性和效率。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.19120v1",
      "published_date": "2025-04-27 06:26:47 UTC",
      "updated_date": "2025-04-27 06:26:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:14:25.835060"
    },
    {
      "arxiv_id": "2504.19099v1",
      "title": "VeriDebug: A Unified LLM for Verilog Debugging via Contrastive Embedding and Guided Correction",
      "title_zh": "翻译失败",
      "authors": [
        "Ning Wang",
        "Bingkun Yao",
        "Jie Zhou",
        "Yuchen Hu",
        "Xi Wang",
        "Nan Guan",
        "Zhe Jiang"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated remarkable potential in\ndebugging for various programming languages. However, the application of LLMs\nto Verilog debugging remains insufficiently explored. Here, we present\nVeriDebug, an approach that integrates contrastive representation and guided\ncorrection capabilities for automated Verilog debugging. Unlike existing\nmethods, VeriDebug employs an embedding-based technique to accurately retrieve\ninternal information, followed by bug-fixing. VeriDebug unifies Verilog bug\ndetection and correction through a shared parameter space. By simultaneously\nlearning bug patterns and fixes, it streamlines debugging via contrastive\nembedding and guided correction. Empirical results show the efficacy of\nVeriDebug in enhancing Verilog debugging. Our VeriDebugLoc, Type model achieves\n64.7 accuracy in bug fixing (Acc1), a significant improvement from the existing\nopen-source SOTAs 11.3. This performance not only outperforms open-source\nalternatives but also exceeds larger closed-source models like GPT-3.5-turbo\n(36.6), offering a more accurate alternative to conventional debugging methods.",
      "tldr_zh": "本文提出VeriDebug，一种统一的LLM方法，用于Verilog调试，通过contrastive embedding和guided correction技术整合bug检测和修正。不同于现有方法，该框架采用嵌入-based技巧准确检索内部信息，并在共享参数空间中同时学习bug模式和修复策略。实验结果显示，VeriDebugLoc, Type模型在bug修复准确率（Acc1）上达到64.7%，比开源SOTA（11.3%）和GPT-3.5-turbo（36.6%）有显著提升，为Verilog调试提供了更高效的替代方案。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.AR"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.19099v1",
      "published_date": "2025-04-27 04:09:48 UTC",
      "updated_date": "2025-04-27 04:09:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:14:37.718466"
    },
    {
      "arxiv_id": "2504.19093v1",
      "title": "CipherBank: Exploring the Boundary of LLM Reasoning Capabilities through Cryptography Challenges",
      "title_zh": "CipherBank: 通过密码学挑战探索LLM推理能力的边界",
      "authors": [
        "Yu Li",
        "Qizhi Pei",
        "Mengyuan Sun",
        "Honglin Lin",
        "Chenlin Ming",
        "Xin Gao",
        "Jiang Wu",
        "Conghui He",
        "Lijun Wu"
      ],
      "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities,\nespecially the recent advancements in reasoning, such as o1 and o3, pushing the\nboundaries of AI. Despite these impressive achievements in mathematics and\ncoding, the reasoning abilities of LLMs in domains requiring cryptographic\nexpertise remain underexplored. In this paper, we introduce CipherBank, a\ncomprehensive benchmark designed to evaluate the reasoning capabilities of LLMs\nin cryptographic decryption tasks. CipherBank comprises 2,358 meticulously\ncrafted problems, covering 262 unique plaintexts across 5 domains and 14\nsubdomains, with a focus on privacy-sensitive and real-world scenarios that\nnecessitate encryption. From a cryptographic perspective, CipherBank\nincorporates 3 major categories of encryption methods, spanning 9 distinct\nalgorithms, ranging from classical ciphers to custom cryptographic techniques.\nWe evaluate state-of-the-art LLMs on CipherBank, e.g., GPT-4o, DeepSeek-V3, and\ncutting-edge reasoning-focused models such as o1 and DeepSeek-R1. Our results\nreveal significant gaps in reasoning abilities not only between general-purpose\nchat LLMs and reasoning-focused LLMs but also in the performance of current\nreasoning-focused models when applied to classical cryptographic decryption\ntasks, highlighting the challenges these models face in understanding and\nmanipulating encrypted data. Through detailed analysis and error\ninvestigations, we provide several key observations that shed light on the\nlimitations and potential improvement areas for LLMs in cryptographic\nreasoning. These findings underscore the need for continuous advancements in\nLLM reasoning capabilities.",
      "tldr_zh": "本研究引入了 CipherBank，这是一个全面基准测试，用于评估大型语言模型 (LLMs) 在密码学解密任务中的推理能力，特别是针对 o1 和 o3 等先进模型的局限性。CipherBank 包含 2,358 个精心设计的问题，覆盖 262 个唯一明文、5 个领域和 14 个子领域，并涉及 3 类加密方法和 9 种算法，从经典密码到自定义技术，聚焦于隐私敏感的真实场景。实验结果显示，状态模型如 GPT-4o 和 DeepSeek-V3 在密码解密中表现远逊于专注于推理的模型，但整体仍存在显著差距，突显了 LLMs 在理解和操作加密数据方面的挑战。通过详细分析，该研究揭示了 LLMs 的潜在改进领域，并强调了持续提升推理能力的必要性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.PF"
      ],
      "primary_category": "cs.CR",
      "comment": "Work in progress",
      "pdf_url": "http://arxiv.org/pdf/2504.19093v1",
      "published_date": "2025-04-27 03:41:17 UTC",
      "updated_date": "2025-04-27 03:41:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:14:50.074017"
    },
    {
      "arxiv_id": "2504.19080v1",
      "title": "MIA-Mind: A Multidimensional Interactive Attention Mechanism Based on MindSpore",
      "title_zh": "MIA-Mind：基于 MindSpore 的多维交互注意机制",
      "authors": [
        "Zhenkai Qin",
        "Jiaquan Liang",
        "Qiao Fang"
      ],
      "abstract": "Attention mechanisms have significantly advanced deep learning by enhancing\nfeature representation through selective focus. However, existing approaches\noften independently model channel importance and spatial saliency, overlooking\ntheir inherent interdependence and limiting their effectiveness. To address\nthis limitation, we propose MIA-Mind, a lightweight and modular\nMultidimensional Interactive Attention Mechanism, built upon the MindSpore\nframework. MIA-Mind jointly models spatial and channel features through a\nunified cross-attentive fusion strategy, enabling fine-grained feature\nrecalibration with minimal computational overhead. Extensive experiments are\nconducted on three representative datasets: on CIFAR-10, MIA-Mind achieves an\naccuracy of 82.9\\%; on ISBI2012, it achieves an accuracy of 78.7\\%; and on\nCIC-IDS2017, it achieves an accuracy of 91.9\\%. These results validate the\nversatility, lightweight design, and generalization ability of MIA-Mind across\nheterogeneous tasks. Future work will explore the extension of MIA-Mind to\nlarge-scale datasets, the development of ada,ptive attention fusion strategies,\nand distributed deployment to further enhance scalability and robustness.",
      "tldr_zh": "本研究指出，现有的Attention Mechanism在建模通道重要性和空间显著性时，常忽略两者间的相互依赖，从而限制了效果。为解决此问题，提出MIA-Mind，一种基于MindSpore的轻量级模块化多维交互注意力机制，通过统一的交叉注意力融合策略联合建模空间和通道特征，实现细粒度特征重新校准，同时保持最小计算开销。在CIFAR-10、ISBI2012和CIC-IDS2017数据集上的实验中，MIA-Mind分别达到82.9%、78.7%和91.9%的准确率，验证了其多功能性、轻量设计和泛化能力。未来工作将扩展到大规模数据集、开发自适应注意力融合策略，并探索分布式部署以提升可伸缩性和鲁棒性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.19080v1",
      "published_date": "2025-04-27 02:27:50 UTC",
      "updated_date": "2025-04-27 02:27:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:15:03.120566"
    },
    {
      "arxiv_id": "2504.19066v1",
      "title": "ClimaEmpact: Domain-Aligned Small Language Models and Datasets for Extreme Weather Analytics",
      "title_zh": "ClimaEmpact：领域对齐的小型语言模型和数据集，用于极端天气分析",
      "authors": [
        "Deeksha Varshney",
        "Keane Ong",
        "Rui Mao",
        "Erik Cambria",
        "Gianmarco Mengaldo"
      ],
      "abstract": "Accurate assessments of extreme weather events are vital for research and\npolicy, yet localized and granular data remain scarce in many parts of the\nworld. This data gap limits our ability to analyze potential outcomes and\nimplications of extreme weather events, hindering effective decision-making.\nLarge Language Models (LLMs) can process vast amounts of unstructured text\ndata, extract meaningful insights, and generate detailed assessments by\nsynthesizing information from multiple sources. Furthermore, LLMs can\nseamlessly transfer their general language understanding to smaller models,\nenabling these models to retain key knowledge while being fine-tuned for\nspecific tasks. In this paper, we propose Extreme Weather Reasoning-Aware\nAlignment (EWRA), a method that enhances small language models (SLMs) by\nincorporating structured reasoning paths derived from LLMs, and\nExtremeWeatherNews, a large dataset of extreme weather event-related news\narticles. EWRA and ExtremeWeatherNews together form the overall framework,\nClimaEmpact, that focuses on addressing three critical extreme-weather tasks:\ncategorization of tangible vulnerabilities/impacts, topic labeling, and emotion\nanalysis. By aligning SLMs with advanced reasoning strategies on\nExtremeWeatherNews (and its derived dataset ExtremeAlign used specifically for\nSLM alignment), EWRA improves the SLMs' ability to generate well-grounded and\ndomain-specific responses for extreme weather analytics. Our results show that\nthe approach proposed guides SLMs to output domain-aligned responses,\nsurpassing the performance of task-specific models and offering enhanced\nreal-world applicability for extreme weather analytics.",
      "tldr_zh": "这篇论文提出了 ClimaEmpact 框架，包括 Extreme Weather Reasoning-Aware Alignment (EWRA) 方法和 ExtremeWeatherNews 数据集，用于提升小语言模型 (SLMs) 在极端天气分析中的性能。EWRA 通过从大型语言模型 (LLMs) 派生的结构化推理路径来增强 SLMs，使其更好地处理三个关键任务：分类有形脆弱性/影响、主题标记和情感分析，同时利用 ExtremeWeatherNews 数据集进行针对性训练。结果显示，该框架使 SLMs 生成更可靠的领域对齐响应，超越任务特定模型，并在实际极端天气事件评估中提供更高的适用性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "physics.ao-ph"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.19066v1",
      "published_date": "2025-04-27 01:15:14 UTC",
      "updated_date": "2025-04-27 01:15:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:15:14.065512"
    },
    {
      "arxiv_id": "2504.20101v2",
      "title": "GenTorrent: Scaling Large Language Model Serving with An Overley Network",
      "title_zh": "翻译失败",
      "authors": [
        "Fei Fang",
        "Yifan Hua",
        "Shengze Wang",
        "Ruilin Zhou",
        "Yi Liu",
        "Chen Qian",
        "Xiaoxue Zhang"
      ],
      "abstract": "While significant progress has been made in research and development on\nopen-source and cost-efficient large-language models (LLMs), serving\nscalability remains a critical challenge, particularly for small organizations\nand individuals seeking to deploy and test their LLM innovations. Inspired by\npeer-to-peer networks that leverage decentralized overlay nodes to increase\nthroughput and availability, we propose GenTorrent, an LLM serving overlay that\nharnesses computing resources from decentralized contributors. We identify four\nkey research problems inherent to enabling such a decentralized infrastructure:\n1) overlay network organization; 2) LLM communication privacy; 3) overlay\nforwarding for resource efficiency; and 4) verification of serving quality.\nThis work presents the first systematic study of these fundamental problems in\nthe context of decentralized LLM serving. Evaluation results from a prototype\nimplemented on a set of decentralized nodes demonstrate that GenTorrent\nachieves a latency reduction of over 50% compared to the baseline design\nwithout overlay forwarding. Furthermore, the security features introduce\nminimal overhead to serving latency and throughput. We believe this work\npioneers a new direction for democratizing and scaling future AI serving\ncapabilities.",
      "tldr_zh": "这篇论文提出 GenTorrent，一种基于 overlay network 的框架，利用点对点网络的理念从分散式贡献者处获取计算资源，以解决开源大型语言模型 (LLMs) 服务的可扩展性挑战，特别是针对小型组织和个人的需求。论文识别并系统研究了四个关键问题：overlay network 组织、LLM 通信隐私、资源效率的 overlay forwarding 以及服务质量验证。原型评估显示，GenTorrent 相较基线设计降低了超过 50% 的延迟，同时安全特性对延迟和吞吐量的影响最小。该工作为民主化和扩展 AI 服务能力开辟了新方向。",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.20101v2",
      "published_date": "2025-04-27 01:08:25 UTC",
      "updated_date": "2025-04-30 21:24:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:15:26.076004"
    },
    {
      "arxiv_id": "2504.19061v1",
      "title": "Hallucinations and Key Information Extraction in Medical Texts: A Comprehensive Assessment of Open-Source Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Anindya Bijoy Das",
        "Shibbir Ahmed",
        "Shahnewaz Karim Sakib"
      ],
      "abstract": "Clinical summarization is crucial in healthcare as it distills complex\nmedical data into digestible information, enhancing patient understanding and\ncare management. Large language models (LLMs) have shown significant potential\nin automating and improving the accuracy of such summarizations due to their\nadvanced natural language understanding capabilities. These models are\nparticularly applicable in the context of summarizing medical/clinical texts,\nwhere precise and concise information transfer is essential. In this paper, we\ninvestigate the effectiveness of open-source LLMs in extracting key events from\ndischarge reports, such as reasons for hospital admission, significant\nin-hospital events, and critical follow-up actions. In addition, we also assess\nthe prevalence of various types of hallucinations in the summaries produced by\nthese models. Detecting hallucinations is vital as it directly influences the\nreliability of the information, potentially affecting patient care and\ntreatment outcomes. We conduct comprehensive numerical simulations to\nrigorously evaluate the performance of these models, further probing the\naccuracy and fidelity of the extracted content in clinical summarization.",
      "tldr_zh": "这篇论文评估了开源大型语言模型(LLMs)在医疗文本关键信息提取中的表现，重点从出院报告中提取入院原因、住院重要事件和后续行动等关键事件。研究同时调查了这些模型生成的总结中各种类型幻觉(hallucinations)的发生率，并强调检测幻觉的重要性，以确保信息可靠性并避免对患者护理的影响。通过全面的数值模拟，论文证明了LLMs在临床总结中的潜力，同时突出了其准确性和忠实度的局限性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.19061v1",
      "published_date": "2025-04-27 00:39:12 UTC",
      "updated_date": "2025-04-27 00:39:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:15:38.046007"
    },
    {
      "arxiv_id": "2504.19056v1",
      "title": "Generative AI for Character Animation: A Comprehensive Survey of Techniques, Applications, and Future Directions",
      "title_zh": "生成式 AI 用于角色动画：技术、应用和未来方向的全面综述",
      "authors": [
        "Mohammad Mahdi Abootorabi",
        "Omid Ghahroodi",
        "Pardis Sadat Zahraei",
        "Hossein Behzadasl",
        "Alireza Mirrokni",
        "Mobina Salimipanah",
        "Arash Rasouli",
        "Bahar Behzadipour",
        "Sara Azarnoush",
        "Benyamin Maleki",
        "Erfan Sadraiye",
        "Kiarash Kiani Feriz",
        "Mahdi Teymouri Nahad",
        "Ali Moghadasi",
        "Abolfazl Eshagh Abianeh",
        "Nizi Nazar",
        "Hamid R. Rabiee",
        "Mahdieh Soleymani Baghshah",
        "Meisam Ahmadi",
        "Ehsaneddin Asgari"
      ],
      "abstract": "Generative AI is reshaping art, gaming, and most notably animation. Recent\nbreakthroughs in foundation and diffusion models have reduced the time and cost\nof producing animated content. Characters are central animation components,\ninvolving motion, emotions, gestures, and facial expressions. The pace and\nbreadth of advances in recent months make it difficult to maintain a coherent\nview of the field, motivating the need for an integrative review. Unlike\nearlier overviews that treat avatars, gestures, or facial animation in\nisolation, this survey offers a single, comprehensive perspective on all the\nmain generative AI applications for character animation. We begin by examining\nthe state-of-the-art in facial animation, expression rendering, image\nsynthesis, avatar creation, gesture modeling, motion synthesis, object\ngeneration, and texture synthesis. We highlight leading research, practical\ndeployments, commonly used datasets, and emerging trends for each area. To\nsupport newcomers, we also provide a comprehensive background section that\nintroduces foundational models and evaluation metrics, equipping readers with\nthe knowledge needed to enter the field. We discuss open challenges and map\nfuture research directions, providing a roadmap to advance AI-driven\ncharacter-animation technologies. This survey is intended as a resource for\nresearchers and developers entering the field of generative AI animation or\nadjacent fields. Resources are available at:\nhttps://github.com/llm-lab-org/Generative-AI-for-Character-Animation-Survey.",
      "tldr_zh": "这篇论文对生成式 AI 在角色动画领域的技术、应用和未来方向进行了全面调查，涵盖面部动画、表情渲染、图像合成、头像创建、手势建模、动作合成、对象生成和纹理合成等关键方面。作者审视了当前领先研究、实际部署、常用数据集以及新兴趋势，并提供了基础模型(diffusion models 等)和评估指标的背景知识，以帮助新手入门。论文指出了现有挑战，如动画生产的效率提升，并为未来研究绘制了路线图，包括AI驱动角色动画的潜在创新，作为研究者和开发者的资源。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "50 main pages, 30 pages appendix, 21 figures, 8 tables, GitHub\n  Repository:\n  https://github.com/llm-lab-org/Generative-AI-for-Character-Animation-Survey",
      "pdf_url": "http://arxiv.org/pdf/2504.19056v1",
      "published_date": "2025-04-27 00:09:31 UTC",
      "updated_date": "2025-04-27 00:09:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T17:15:50.251981"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 53,
  "processed_papers_count": 53,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-24T17:16:09.433846"
}