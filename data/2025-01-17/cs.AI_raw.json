[
  {
    "arxiv_id": "2501.10604v1",
    "title": "When language and vision meet road safety: leveraging multimodal large language models for video-based traffic accident analysis",
    "authors": [
      "Ruixuan Zhang",
      "Beichen Wang",
      "Juexiao Zhang",
      "Zilin Bian",
      "Chen Feng",
      "Kaan Ozbay"
    ],
    "abstract": "The increasing availability of traffic videos functioning on a 24/7/365 time\nscale has the great potential of increasing the spatio-temporal coverage of\ntraffic accidents, which will help improve traffic safety. However, analyzing\nfootage from hundreds, if not thousands, of traffic cameras in a 24/7/365\nworking protocol remains an extremely challenging task, as current vision-based\napproaches primarily focus on extracting raw information, such as vehicle\ntrajectories or individual object detection, but require laborious\npost-processing to derive actionable insights. We propose SeeUnsafe, a new\nframework that integrates Multimodal Large Language Model (MLLM) agents to\ntransform video-based traffic accident analysis from a traditional\nextraction-then-explanation workflow to a more interactive, conversational\napproach. This shift significantly enhances processing throughput by automating\ncomplex tasks like video classification and visual grounding, while improving\nadaptability by enabling seamless adjustments to diverse traffic scenarios and\nuser-defined queries. Our framework employs a severity-based aggregation\nstrategy to handle videos of various lengths and a novel multimodal prompt to\ngenerate structured responses for review and evaluation and enable fine-grained\nvisual grounding. We introduce IMS (Information Matching Score), a new\nMLLM-based metric for aligning structured responses with ground truth. We\nconduct extensive experiments on the Toyota Woven Traffic Safety dataset,\ndemonstrating that SeeUnsafe effectively performs accident-aware video\nclassification and visual grounding by leveraging off-the-shelf MLLMs. Source\ncode will be available at \\url{https://github.com/ai4ce/SeeUnsafe}.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.10604v1",
    "published_date": "2025-01-17 23:35:34 UTC",
    "updated_date": "2025-01-17 23:35:34 UTC"
  },
  {
    "arxiv_id": "2501.13942v1",
    "title": "Prompt-Based Monte Carlo Tree Search for Mitigating Hallucinations in Large Models",
    "authors": [
      "Zhihua Duan",
      "Jialin Wang"
    ],
    "abstract": "With the rapid development of large models in the field of artificial\nintelligence, how to enhance their application capabilities in handling complex\nproblems in the field of scientific research remains a challenging problem to\nbe solved. This study proposes an improved Monte Carlo Tree Search (MCTS)\nmethod based on prompt words. In the simulation search stage, it introduces\ndynamic adjustment of exploration parameters and adaptive selection strategies,\nwhich can better balance exploration and exploitation, thereby reducing the\nhallucination phenomenon. This paper takes the four subsets of the SciEval\ndataset as the test objects, and compares the Glm-4-flash+Improved MCTS method\nwith the methods of several existing models. The results show that the Improved\nMCTS method performs better, providing new ideas and methods for the\napplication of large models in the field of scientific research.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.13942v1",
    "published_date": "2025-01-17 23:06:50 UTC",
    "updated_date": "2025-01-17 23:06:50 UTC"
  },
  {
    "arxiv_id": "2501.10593v1",
    "title": "ColorGrid: A Multi-Agent Non-Stationary Environment for Goal Inference and Assistance",
    "authors": [
      "Andrey Risukhin",
      "Kavel Rao",
      "Ben Caffee",
      "Alan Fan"
    ],
    "abstract": "Autonomous agents' interactions with humans are increasingly focused on\nadapting to their changing preferences in order to improve assistance in\nreal-world tasks. Effective agents must learn to accurately infer human goals,\nwhich are often hidden, to collaborate well. However, existing Multi-Agent\nReinforcement Learning (MARL) environments lack the necessary attributes\nrequired to rigorously evaluate these agents' learning capabilities. To this\nend, we introduce ColorGrid, a novel MARL environment with customizable\nnon-stationarity, asymmetry, and reward structure. We investigate the\nperformance of Independent Proximal Policy Optimization (IPPO), a\nstate-of-the-art (SOTA) MARL algorithm, in ColorGrid and find through extensive\nablations that, particularly with simultaneous non-stationary and asymmetric\ngoals between a ``leader'' agent representing a human and a ``follower''\nassistant agent, ColorGrid is unsolved by IPPO. To support benchmarking future\nMARL algorithms, we release our environment code, model checkpoints, and\ntrajectory visualizations at https://github.com/andreyrisukhin/ColorGrid.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.10593v1",
    "published_date": "2025-01-17 22:55:33 UTC",
    "updated_date": "2025-01-17 22:55:33 UTC"
  },
  {
    "arxiv_id": "2501.13941v1",
    "title": "GaussMark: A Practical Approach for Structural Watermarking of Language Models",
    "authors": [
      "Adam Block",
      "Ayush Sekhari",
      "Alexander Rakhlin"
    ],
    "abstract": "Recent advances in Large Language Models (LLMs) have led to significant\nimprovements in natural language processing tasks, but their ability to\ngenerate human-quality text raises significant ethical and operational concerns\nin settings where it is important to recognize whether or not a given text was\ngenerated by a human. Thus, recent work has focused on developing techniques\nfor watermarking LLM-generated text, i.e., introducing an almost imperceptible\nsignal that allows a provider equipped with a secret key to determine if given\ntext was generated by their model. Current watermarking techniques are often\nnot practical due to concerns with generation latency, detection time,\ndegradation in text quality, or robustness. Many of these drawbacks come from\nthe focus on token-level watermarking, which ignores the inherent structure of\ntext. In this work, we introduce a new scheme, GaussMark, that is simple and\nefficient to implement, has formal statistical guarantees on its efficacy,\ncomes at no cost in generation latency, and embeds the watermark into the\nweights of the model itself, providing a structural watermark. Our approach is\nbased on Gaussian independence testing and is motivated by recent empirical\nobservations that minor additive corruptions to LLM weights can result in\nmodels of identical (or even improved) quality. We show that by adding a small\namount of Gaussian noise to the weights of a given LLM, we can watermark the\nmodel in a way that is statistically detectable by a provider who retains the\nsecret key. We provide formal statistical bounds on the validity and power of\nour procedure. Through an extensive suite of experiments, we demonstrate that\nGaussMark is reliable, efficient, and relatively robust to corruptions such as\ninsertions, deletions, substitutions, and roundtrip translations and can be\ninstantiated with essentially no loss in model quality.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.13941v1",
    "published_date": "2025-01-17 22:30:08 UTC",
    "updated_date": "2025-01-17 22:30:08 UTC"
  },
  {
    "arxiv_id": "2501.10579v1",
    "title": "AI Technicians: Developing Rapid Occupational Training Methods for a Competitive AI Workforce",
    "authors": [
      "Jaromir Savelka",
      "Can Kultur",
      "Arav Agarwal",
      "Christopher Bogart",
      "Heather Burte",
      "Adam Zhang",
      "Majd Sakr"
    ],
    "abstract": "The accelerating pace of developments in Artificial Intelligence~(AI) and the\nincreasing role that technology plays in society necessitates substantial\nchanges in the structure of the workforce. Besides scientists and engineers,\nthere is a need for a very large workforce of competent AI technicians (i.e.,\nmaintainers, integrators) and users~(i.e., operators). As traditional 4-year\nand 2-year degree-based education cannot fill this quickly opening gap,\nalternative training methods have to be developed. We present the results of\nthe first four years of the AI Technicians program which is a unique\ncollaboration between the U.S. Army's Artificial Intelligence Integration\nCenter (AI2C) and Carnegie Mellon University to design, implement and evaluate\nnovel rapid occupational training methods to create a competitive AI workforce\nat the technicians level. Through this multi-year effort we have already\ntrained 59 AI Technicians. A key observation is that ongoing frequent updates\nto the training are necessary as the adoption of AI in the U.S. Army and within\nthe society at large is evolving rapidly. A tight collaboration among the\nstakeholders from the army and the university is essential for successful\ndevelopment and maintenance of the training for the evolving role. Our findings\ncan be leveraged by large organizations that face the challenge of developing a\ncompetent AI workforce as well as educators and researchers engaged in solving\nthe challenge.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.10579v1",
    "published_date": "2025-01-17 22:14:56 UTC",
    "updated_date": "2025-01-17 22:14:56 UTC"
  },
  {
    "arxiv_id": "2501.10576v1",
    "title": "AI Toolkit: Libraries and Essays for Exploring the Technology and Ethics of AI",
    "authors": [
      "Levin Ho",
      "Morgan McErlean",
      "Zehua You",
      "Douglas Blank",
      "Lisa Meeden"
    ],
    "abstract": "In this paper we describe the development and evaluation of AITK, the\nArtificial Intelligence Toolkit. This open-source project contains both Python\nlibraries and computational essays (Jupyter notebooks) that together are\ndesigned to allow a diverse audience with little or no background in AI to\ninteract with a variety of AI tools, exploring in more depth how they function,\nvisualizing their outcomes, and gaining a better understanding of their ethical\nimplications. These notebooks have been piloted at multiple institutions in a\nvariety of humanities courses centered on the theme of responsible AI. In\naddition, we conducted usability testing of AITK. Our pilot studies and\nusability testing results indicate that AITK is easy to navigate and effective\nat helping users gain a better understanding of AI. Our goal, in this time of\nrapid innovations in AI, is for AITK to provide an accessible resource for\nfaculty from any discipline looking to incorporate AI topics into their courses\nand for anyone eager to learn more about AI on their own.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.10576v1",
    "published_date": "2025-01-17 22:08:52 UTC",
    "updated_date": "2025-01-17 22:08:52 UTC"
  },
  {
    "arxiv_id": "2501.10555v1",
    "title": "Towards Data-Centric AI: A Comprehensive Survey of Traditional, Reinforcement, and Generative Approaches for Tabular Data Transformation",
    "authors": [
      "Dongjie Wang",
      "Yanyong Huang",
      "Wangyang Ying",
      "Haoyue Bai",
      "Nanxu Gong",
      "Xinyuan Wang",
      "Sixun Dong",
      "Tao Zhe",
      "Kunpeng Liu",
      "Meng Xiao",
      "Pengfei Wang",
      "Pengyang Wang",
      "Hui Xiong",
      "Yanjie Fu"
    ],
    "abstract": "Tabular data is one of the most widely used formats across industries,\ndriving critical applications in areas such as finance, healthcare, and\nmarketing. In the era of data-centric AI, improving data quality and\nrepresentation has become essential for enhancing model performance,\nparticularly in applications centered around tabular data. This survey examines\nthe key aspects of tabular data-centric AI, emphasizing feature selection and\nfeature generation as essential techniques for data space refinement. We\nprovide a systematic review of feature selection methods, which identify and\nretain the most relevant data attributes, and feature generation approaches,\nwhich create new features to simplify the capture of complex data patterns.\nThis survey offers a comprehensive overview of current methodologies through an\nanalysis of recent advancements, practical applications, and the strengths and\nlimitations of these techniques. Finally, we outline open challenges and\nsuggest future perspectives to inspire continued innovation in this field.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.10555v1",
    "published_date": "2025-01-17 21:05:09 UTC",
    "updated_date": "2025-01-17 21:05:09 UTC"
  },
  {
    "arxiv_id": "2502.10395v1",
    "title": "An Integrated Platform for Studying Learning with Intelligent Tutoring Systems: CTAT+TutorShop",
    "authors": [
      "Vincent Aleven",
      "Conrad Borchers",
      "Yun Huang",
      "Tomohiro Nagashima",
      "Bruce McLaren",
      "Paulo Carvalho",
      "Octav Popescu",
      "Jonathan Sewall",
      "Kenneth Koedinger"
    ],
    "abstract": "Intelligent tutoring systems (ITSs) are effective in helping students learn;\nfurther research could make them even more effective. Particularly desirable is\nresearch into how students learn with these systems, how these systems best\nsupport student learning, and what learning sciences principles are key in\nITSs. CTAT+Tutorshop provides a full stack integrated platform that facilitates\na complete research lifecycle with ITSs, which includes using ITS data to\ndiscover learner challenges, to identify opportunities for system improvements,\nand to conduct experimental studies. The platform includes authoring tools to\nsupport and accelerate development of ITS, which provide automatic data logging\nin a format compatible with DataShop, an independent site that supports the\nanalysis of ed tech log data to study student learnings. Among the many\ntechnology platforms that exist to support learning sciences research,\nCTAT+Tutorshop may be the only one that offers researchers the possibility to\nauthor elements of ITSs, or whole ITSs, as part of designing studies. This\nplatform has been used to develop and conduct an estimated 147 research studies\nwhich have run in a wide variety of laboratory and real-world educational\nsettings, including K-12 and higher education, and have addressed a wide range\nof research questions. This paper presents five case studies of research\nconducted on the CTAT+Tutorshop platform, and summarizes what has been\naccomplished and what is possible for future researchers. We reflect on the\ndistinctive elements of this platform that have made it so effective in\nfacilitating a wide range of ITS research.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CY",
    "comment": "Reviewed for and presented at the Fifth Annual Workshop on\n  Learning@Scale 2024: A/B Testing and Platform-Enabled Learning Research",
    "pdf_url": "http://arxiv.org/pdf/2502.10395v1",
    "published_date": "2025-01-17 20:49:08 UTC",
    "updated_date": "2025-01-17 20:49:08 UTC"
  },
  {
    "arxiv_id": "2501.10546v1",
    "title": "Scalable Machine Learning Training Infrastructure for Online Ads Recommendation and Auction Scoring Modeling at Google",
    "authors": [
      "George Kurian",
      "Somayeh Sardashti",
      "Ryan Sims",
      "Felix Berger",
      "Gary Holt",
      "Yang Li",
      "Jeremiah Willcock",
      "Kaiyuan Wang",
      "Herve Quiroz",
      "Abdulrahman Salem",
      "Julian Grady"
    ],
    "abstract": "Large-scale Ads recommendation and auction scoring models at Google scale\ndemand immense computational resources. While specialized hardware like TPUs\nhave improved linear algebra computations, bottlenecks persist in large-scale\nsystems. This paper proposes solutions for three critical challenges that must\nbe addressed for efficient end-to-end execution in a widely used production\ninfrastructure: (1) Input Generation and Ingestion Pipeline: Efficiently\ntransforming raw features (e.g., \"search query\") into numerical inputs and\nstreaming them to TPUs; (2) Large Embedding Tables: Optimizing conversion of\nsparse features into dense floating-point vectors for neural network\nconsumption; (3) Interruptions and Error Handling: Minimizing resource wastage\nin large-scale shared datacenters. To tackle these challenges, we propose a\nshared input generation technique to reduce computational load of input\ngeneration by amortizing costs across many models. Furthermore, we propose\npartitioning, pipelining, and RPC (Remote Procedure Call) coalescing software\ntechniques to optimize embedding operations. To maintain efficiency at scale,\nwe describe novel preemption notice and training hold mechanisms that minimize\nresource wastage, and ensure prompt error resolution. These techniques have\ndemonstrated significant improvement in Google production, achieving a 116%\nperformance boost and an 18% reduction in training costs across representative\nmodels.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.LG",
      "C.0; C.4; I.2.6"
    ],
    "primary_category": "cs.DC",
    "comment": "13 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.10546v1",
    "published_date": "2025-01-17 20:40:56 UTC",
    "updated_date": "2025-01-17 20:40:56 UTC"
  },
  {
    "arxiv_id": "2501.10543v1",
    "title": "FORLAPS: An Innovative Data-Driven Reinforcement Learning Approach for Prescriptive Process Monitoring",
    "authors": [
      "Mostafa Abbasi",
      "Maziyar Khadivi",
      "Maryam Ahang",
      "Patricia Lasserre",
      "Yves Lucet",
      "Homayoun Najjaran"
    ],
    "abstract": "We present a novel 5-step framework called Fine-Tuned Offline Reinforcement\nLearning Augmented Process Sequence Optimization (FORLAPS), which aims to\nidentify optimal execution paths in business processes using reinforcement\nlearning. We implemented this approach on real-life event logs from our case\nstudy an energy regulator in Canada and other real-life event logs,\ndemonstrating the feasibility of the proposed method. Additionally, to compare\nFORLAPS with the existing models (Permutation Feature Importance and multi-task\nLSTM-Based model), we experimented to evaluate its effectiveness in terms of\nresource savings and process time span reduction. The experimental results on\nreal-life event log validate that FORLAPS achieves 31% savings in resource time\nspent and a 23% reduction in process time span. Using this innovative data\naugmentation technique, we propose a fine-tuned reinforcement learning approach\nthat aims to automatically fine-tune the model by selectively increasing the\naverage estimated Q-value in the sampled batches. The results show that we\nobtained a 44% performance improvement compared to the pre-trained model. This\nstudy introduces an innovative evaluation model, benchmarking its performance\nagainst earlier works using nine publicly available datasets. Robustness is\nensured through experiments utilizing the Damerau-Levenshtein distance as the\nprimary metric. In addition, we discussed the suitability of datasets, taking\ninto account their inherent properties, to evaluate the performance of\ndifferent models. The proposed model, FORLAPS, demonstrated exceptional\nperformance, outperforming existing state-of-the-art approaches in suggesting\nthe most optimal policies or predicting the best next activities within a\nprocess trace.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.10543v1",
    "published_date": "2025-01-17 20:31:35 UTC",
    "updated_date": "2025-01-17 20:31:35 UTC"
  },
  {
    "arxiv_id": "2501.10542v2",
    "title": "Improved IR-based Bug Localization with Intelligent Relevance Feedback",
    "authors": [
      "Asif Mohammed Samir",
      "Mohammad Masudur Rahman"
    ],
    "abstract": "Software bugs pose a significant challenge during development and\nmaintenance, and practitioners spend nearly 50% of their time dealing with\nbugs. Many existing techniques adopt Information Retrieval (IR) to localize a\nreported bug using textual and semantic relevance between bug reports and\nsource code. However, they often struggle to bridge a critical gap between bug\nreports and code that requires in-depth contextual understanding, which goes\nbeyond textual or semantic relevance. In this paper, we present a novel\ntechnique for bug localization - BRaIn - that addresses the contextual gaps by\nassessing the relevance between bug reports and code with Large Language Models\n(LLM). It then leverages the LLM's feedback (a.k.a., Intelligent Relevance\nFeedback) to reformulate queries and re-rank source documents, improving bug\nlocalization. We evaluate BRaIn using a benchmark dataset, Bench4BL, and three\nperformance metrics and compare it against six baseline techniques from the\nliterature. Our experimental results show that BRaIn outperforms baselines by\n87.6%, 89.5%, and 48.8% margins in MAP, MRR, and HIT@K, respectively.\nAdditionally, it can localize approximately 52% of bugs that cannot be\nlocalized by the baseline techniques due to the poor quality of corresponding\nbug reports. By addressing the contextual gaps and introducing Intelligent\nRelevance Feedback, BRaIn advances not only theory but also improves IR-based\nbug localization.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL",
      "F.2.2; I.2.7"
    ],
    "primary_category": "cs.SE",
    "comment": "13 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.10542v2",
    "published_date": "2025-01-17 20:29:38 UTC",
    "updated_date": "2025-03-27 23:51:49 UTC"
  },
  {
    "arxiv_id": "2501.16345v2",
    "title": "Self-Clustering Graph Transformer Approach to Model Resting-State Functional Brain Activity",
    "authors": [
      "Bishal Thapaliya",
      "Esra Akbas",
      "Ram Sapkota",
      "Bhaskar Ray",
      "Vince Calhoun",
      "Jingyu Liu"
    ],
    "abstract": "Resting-state functional magnetic resonance imaging (rs-fMRI) offers valuable\ninsights into the human brain's functional organization and is a powerful tool\nfor investigating the relationship between brain function and cognitive\nprocesses, as it allows for the functional organization of the brain to be\ncaptured without relying on a specific task or stimuli. In this study, we\nintroduce a novel attention mechanism for graphs with subnetworks, named\nSelf-Clustering Graph Transformer (SCGT), designed to handle the issue of\nuniform node updates in graph transformers. By using static functional\nconnectivity (FC) correlation features as input to the transformer model, SCGT\neffectively captures the sub-network structure of the brain by performing\ncluster-specific updates to the nodes, unlike uniform node updates in vanilla\ngraph transformers, further allowing us to learn and interpret the subclusters.\nWe validate our approach on the Adolescent Brain Cognitive Development (ABCD)\ndataset, comprising 7,957 participants, for the prediction of total cognitive\nscore and gender classification. Our results demonstrate that SCGT outperforms\nthe vanilla graph transformer method and other recent models, offering a\npromising tool for modeling brain functional connectivity and interpreting the\nunderlying subnetwork structures.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "5 pages, 2 figures - Accepted under International Symposium on\n  Biomedical Imaging (ISBI 2025) Conference",
    "pdf_url": "http://arxiv.org/pdf/2501.16345v2",
    "published_date": "2025-01-17 20:21:31 UTC",
    "updated_date": "2025-02-07 08:57:37 UTC"
  },
  {
    "arxiv_id": "2501.10534v1",
    "title": "4bit-Quantization in Vector-Embedding for RAG",
    "authors": [
      "Taehee Jeong"
    ],
    "abstract": "Retrieval-augmented generation (RAG) is a promising technique that has shown\ngreat potential in addressing some of the limitations of large language models\n(LLMs). LLMs have two major limitations: they can contain outdated information\ndue to their training data, and they can generate factually inaccurate\nresponses, a phenomenon known as hallucinations. RAG aims to mitigate these\nissues by leveraging a database of relevant documents, which are stored as\nembedding vectors in a high-dimensional space. However, one of the challenges\nof using high-dimensional embeddings is that they require a significant amount\nof memory to store. This can be a major issue, especially when dealing with\nlarge databases of documents. To alleviate this problem, we propose the use of\n4-bit quantization to store the embedding vectors. This involves reducing the\nprecision of the vectors from 32-bit floating-point numbers to 4-bit integers,\nwhich can significantly reduce the memory requirements. Our approach has\nseveral benefits. Firstly, it significantly reduces the memory storage\nrequirements of the high-dimensional vector database, making it more feasible\nto deploy RAG systems in resource-constrained environments. Secondly, it speeds\nup the searching process, as the reduced precision of the vectors allows for\nfaster computation. Our code is available at\nhttps://github.com/taeheej/4bit-Quantization-in-Vector-Embedding-for-RAG",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.10534v1",
    "published_date": "2025-01-17 20:15:11 UTC",
    "updated_date": "2025-01-17 20:15:11 UTC"
  },
  {
    "arxiv_id": "2501.10526v1",
    "title": "Solving Sparse Finite Element Problems on Neuromorphic Hardware",
    "authors": [
      "Bradley H. Theilman",
      "James B. Aimone"
    ],
    "abstract": "We demonstrate that scalable neuromorphic hardware can implement the finite\nelement method, which is a critical numerical method for engineering and\nscientific discovery. Our approach maps the sparse interactions between\nneighboring finite elements to small populations of neurons that dynamically\nupdate according to the governing physics of a desired problem description. We\nshow that for the Poisson equation, which describes many physical systems such\nas gravitational and electrostatic fields, this cortical-inspired neural\ncircuit can achieve comparable levels of numerical accuracy and scaling while\nenabling the use of inherently parallel and energy-efficient neuromorphic\nhardware. We demonstrate that this approach can be used on the Intel Loihi 2\nplatform and illustrate how this approach can be extended to nontrivial mesh\ngeometries and dynamics.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG",
      "cs.NA",
      "math.NA"
    ],
    "primary_category": "cs.NE",
    "comment": "Pre-publication submission",
    "pdf_url": "http://arxiv.org/pdf/2501.10526v1",
    "published_date": "2025-01-17 19:56:43 UTC",
    "updated_date": "2025-01-17 19:56:43 UTC"
  },
  {
    "arxiv_id": "2502.08652v1",
    "title": "LegalScore: Development of a Benchmark for Evaluating AI Models in Legal Career Exams in Brazil",
    "authors": [
      "Roberto Caparroz",
      "Marcelo Roitman",
      "Beatriz G. Chow",
      "Caroline Giusti",
      "Larissa Torhacs",
      "Pedro A. Sola",
      "João H. M. Diogo",
      "Luiza Balby",
      "Carolina D. L. Vasconcelos",
      "Leonardo R. Caparroz",
      "Albano P. Franco"
    ],
    "abstract": "This research introduces LegalScore, a specialized index for assessing how\ngenerative artificial intelligence models perform in a selected range of career\nexams that require a legal background in Brazil. The index evaluates fourteen\ndifferent types of artificial intelligence models' performance, from\nproprietary to open-source models, in answering objective questions applied to\nthese exams. The research uncovers the response of the models when applying\nEnglish-trained large language models to Brazilian legal contexts, leading us\nto reflect on the importance and the need for Brazil-specific training data in\ngenerative artificial intelligence models. Performance analysis shows that\nwhile proprietary and most known models achieved better results overall, local\nand smaller models indicated promising performances due to their Brazilian\ncontext alignment in training. By establishing an evaluation framework with\nmetrics including accuracy, confidence intervals, and normalized scoring,\nLegalScore enables systematic assessment of artificial intelligence performance\nin legal examinations in Brazil. While the study demonstrates artificial\nintelligence's potential value for exam preparation and question development,\nit concludes that significant improvements are needed before AI can match human\nperformance in advanced legal assessments. The benchmark creates a foundation\nfor continued research, highlighting the importance of local adaptation in\nartificial intelligence development.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "Main article 25 pages, Appendices from page 26",
    "pdf_url": "http://arxiv.org/pdf/2502.08652v1",
    "published_date": "2025-01-17 19:38:53 UTC",
    "updated_date": "2025-01-17 19:38:53 UTC"
  },
  {
    "arxiv_id": "2501.10514v1",
    "title": "Real-Time Bus Departure Prediction Using Neural Networks for Smart IoT Public Bus Transit",
    "authors": [
      "Narges Rashvand",
      "Sanaz Sadat Hosseini",
      "Mona Azarbayjani",
      "Hamed Tabkhi"
    ],
    "abstract": "Bus transit plays a vital role in urban public transportation but often\nstruggles to provide accurate and reliable departure times. This leads to\ndelays, passenger dissatisfaction, and decreased ridership, particularly in\ntransit-dependent areas. A major challenge lies in the discrepancy between\nactual and scheduled bus departure times, which disrupts timetables and impacts\noverall operational efficiency. To address these challenges, this paper\npresents a neural network-based approach for real-time bus departure time\nprediction tailored for smart IoT public transit applications. We leverage\nAI-driven models to enhance the accuracy of bus schedules by preprocessing\ndata, engineering relevant features, and implementing a fully connected neural\nnetwork that utilizes historical departure data to predict departure times at\nsubsequent stops. In our case study analyzing bus data from Boston, we observed\nan average deviation of nearly 4 minutes from scheduled times. However, our\nmodel, evaluated across 151 bus routes, demonstrates a significant improvement,\npredicting departure time deviations with an accuracy of under 80 seconds. This\nadvancement not only improves the reliability of bus transit schedules but also\nplays a crucial role in enabling smart bus systems and IoT applications within\npublic transit networks. By providing more accurate real-time predictions, our\napproach can facilitate the integration of IoT devices, such as smart bus stops\nand passenger information systems, that rely on precise data for optimal\nperformance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.10514v1",
    "published_date": "2025-01-17 19:21:51 UTC",
    "updated_date": "2025-01-17 19:21:51 UTC"
  },
  {
    "arxiv_id": "2501.10343v1",
    "title": "3rd Workshop on Maritime Computer Vision (MaCVi) 2025: Challenge Results",
    "authors": [
      "Benjamin Kiefer",
      "Lojze Žust",
      "Jon Muhovič",
      "Matej Kristan",
      "Janez Perš",
      "Matija Teršek",
      "Uma Mudenagudi Chaitra Desai",
      "Arnold Wiliem",
      "Marten Kreis",
      "Nikhil Akalwadi",
      "Yitong Quan",
      "Zhiqiang Zhong",
      "Zhe Zhang",
      "Sujie Liu",
      "Xuran Chen",
      "Yang Yang",
      "Matej Fabijanić",
      "Fausto Ferreira",
      "Seongju Lee",
      "Junseok Lee",
      "Kyoobin Lee",
      "Shanliang Yao",
      "Runwei Guan",
      "Xiaoyu Huang",
      "Yi Ni",
      "Himanshu Kumar",
      "Yuan Feng",
      "Yi-Ching Cheng",
      "Tzu-Yu Lin",
      "Chia-Ming Lee",
      "Chih-Chung Hsu",
      "Jannik Sheikh",
      "Andreas Michel",
      "Wolfgang Gross",
      "Martin Weinmann",
      "Josip Šarić",
      "Yipeng Lin",
      "Xiang Yang",
      "Nan Jiang",
      "Yutang Lu",
      "Fei Feng",
      "Ali Awad",
      "Evan Lucas",
      "Ashraf Saleem",
      "Ching-Heng Cheng",
      "Yu-Fan Lin",
      "Tzu-Yu Lin",
      "Chih-Chung Hsu"
    ],
    "abstract": "The 3rd Workshop on Maritime Computer Vision (MaCVi) 2025 addresses maritime\ncomputer vision for Unmanned Surface Vehicles (USV) and underwater. This report\noffers a comprehensive overview of the findings from the challenges. We provide\nboth statistical and qualitative analyses, evaluating trends from over 700\nsubmissions. All datasets, evaluation code, and the leaderboard are available\nto the public at https://macvi.org/workshop/macvi25.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Part of the MaCVi 2025 workshop",
    "pdf_url": "http://arxiv.org/pdf/2501.10343v1",
    "published_date": "2025-01-17 18:34:47 UTC",
    "updated_date": "2025-01-17 18:34:47 UTC"
  },
  {
    "arxiv_id": "2501.10332v1",
    "title": "Agent4Edu: Generating Learner Response Data by Generative Agents for Intelligent Education Systems",
    "authors": [
      "Weibo Gao",
      "Qi Liu",
      "Linan Yue",
      "Fangzhou Yao",
      "Rui Lv",
      "Zheng Zhang",
      "Hao Wang",
      "Zhenya Huang"
    ],
    "abstract": "Personalized learning represents a promising educational strategy within\nintelligent educational systems, aiming to enhance learners' practice\nefficiency. However, the discrepancy between offline metrics and online\nperformance significantly impedes their progress. To address this challenge, we\nintroduce Agent4Edu, a novel personalized learning simulator leveraging recent\nadvancements in human intelligence through large language models (LLMs).\nAgent4Edu features LLM-powered generative agents equipped with learner profile,\nmemory, and action modules tailored to personalized learning algorithms. The\nlearner profiles are initialized using real-world response data, capturing\npractice styles and cognitive factors. Inspired by human psychology theory, the\nmemory module records practice facts and high-level summaries, integrating\nreflection mechanisms. The action module supports various behaviors, including\nexercise understanding, analysis, and response generation. Each agent can\ninteract with personalized learning algorithms, such as computerized adaptive\ntesting, enabling a multifaceted evaluation and enhancement of customized\nservices. Through a comprehensive assessment, we explore the strengths and\nweaknesses of Agent4Edu, emphasizing the consistency and discrepancies in\nresponses between agents and human learners. The code, data, and appendix are\npublicly available at https://github.com/bigdata-ustc/Agent4Edu.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "Accepted by AAAI2025",
    "pdf_url": "http://arxiv.org/pdf/2501.10332v1",
    "published_date": "2025-01-17 18:05:04 UTC",
    "updated_date": "2025-01-17 18:05:04 UTC"
  },
  {
    "arxiv_id": "2501.10326v1",
    "title": "Large language models for automated scholarly paper review: A survey",
    "authors": [
      "Zhenzhen Zhuang",
      "Jiandong Chen",
      "Hongfeng Xu",
      "Yuwen Jiang",
      "Jialiang Lin"
    ],
    "abstract": "Large language models (LLMs) have significantly impacted human society,\ninfluencing various domains. Among them, academia is not simply a domain\naffected by LLMs, but it is also the pivotal force in the development of LLMs.\nIn academic publications, this phenomenon is represented during the\nincorporation of LLMs into the peer review mechanism for reviewing manuscripts.\nWe proposed the concept of automated scholarly paper review (ASPR) in our\nprevious paper. As the incorporation grows, it now enters the coexistence phase\nof ASPR and peer review, which is described in that paper. LLMs hold\ntransformative potential for the full-scale implementation of ASPR, but they\nalso pose new issues and challenges that need to be addressed. In this survey\npaper, we aim to provide a holistic view of ASPR in the era of LLMs. We begin\nwith a survey to find out which LLMs are used to conduct ASPR. Then, we review\nwhat ASPR-related technological bottlenecks have been solved with the\nincorporation of LLM technology. After that, we move on to explore new methods,\nnew datasets, new source code, and new online systems that come with LLMs for\nASPR. Furthermore, we summarize the performance and issues of LLMs in ASPR, and\ninvestigate the attitudes and reactions of publishers and academia to ASPR.\nLastly, we discuss the challenges associated with the development of LLMs for\nASPR. We hope this survey can serve as an inspirational reference for the\nresearchers and promote the progress of ASPR for its actual implementation.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.DL"
    ],
    "primary_category": "cs.AI",
    "comment": "Work in progress",
    "pdf_url": "http://arxiv.org/pdf/2501.10326v1",
    "published_date": "2025-01-17 17:56:58 UTC",
    "updated_date": "2025-01-17 17:56:58 UTC"
  },
  {
    "arxiv_id": "2501.10322v2",
    "title": "Hierarchical Autoregressive Transformers: Combining Byte- and Word-Level Processing for Robust, Adaptable Language Models",
    "authors": [
      "Pit Neitemeier",
      "Björn Deiseroth",
      "Constantin Eichenberg",
      "Lukas Balles"
    ],
    "abstract": "Tokenization is a fundamental step in natural language processing, breaking\ntext into units that computational models can process. While learned subword\ntokenizers have become the de-facto standard, they present challenges such as\nlarge vocabularies, limited adaptability to new domains or languages, and\nsensitivity to spelling errors and variations. To overcome these limitations,\nwe investigate a hierarchical architecture for autoregressive language\nmodelling that combines character-level and word-level processing. It employs a\nlightweight character-level encoder to convert character sequences into word\nembeddings, which are then processed by a word-level backbone model and decoded\nback into characters via a compact character-level decoder. This method retains\nthe sequence compression benefits of word-level tokenization without relying on\na rigid, predefined vocabulary. We demonstrate, at scales up to 7 billion\nparameters, that hierarchical transformers match the downstream task\nperformance of subword-tokenizer-based models while exhibiting significantly\ngreater robustness to input perturbations. Additionally, during continued\npretraining on an out-of-domain language, our model trains almost twice as\nfast, achieves superior performance on the target language, and retains more of\nits previously learned knowledge. Hierarchical transformers pave the way for\nNLP systems that are more robust, flexible, and generalizable across languages\nand domains.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.10322v2",
    "published_date": "2025-01-17 17:51:53 UTC",
    "updated_date": "2025-01-20 09:33:21 UTC"
  },
  {
    "arxiv_id": "2501.10300v1",
    "title": "An Ontology for Social Determinants of Education (SDoEd) based on Human-AI Collaborative Approach",
    "authors": [
      "Navya Martin Kollapally",
      "James Geller",
      "Patricia Morreale",
      "Daehan Kwak"
    ],
    "abstract": "The use of computational ontologies is well-established in the field of\nMedical Informatics. The topic of Social Determinants of Health (SDoH) has also\nreceived extensive attention. Work at the intersection of ontologies and SDoH\nhas been published. However, a standardized framework for Social Determinants\nof Education (SDoEd) is lacking. In this paper, we are closing the gap by\nintroducing an SDoEd ontology for creating a precise conceptualization of the\ninterplay between life circumstances of students and their possible educational\nachievements. The ontology was developed utilizing suggestions from\nChatGPT-3.5-010422 and validated using peer-reviewed research articles. The\nfirst version of developed ontology was evaluated by human experts in the field\nof education and validated using standard ontology evaluation software. This\nversion of the SDoEd ontology contains 231 domain concepts, 10 object\nproperties, and 24 data properties",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted in CONSORTIUM FOR COMPUTING SCIENCES IN COLLEGES",
    "pdf_url": "http://arxiv.org/pdf/2501.10300v1",
    "published_date": "2025-01-17 16:51:03 UTC",
    "updated_date": "2025-01-17 16:51:03 UTC"
  },
  {
    "arxiv_id": "2501.10273v1",
    "title": "SEANN: A Domain-Informed Neural Network for Epidemiological Insights",
    "authors": [
      "Jean-Baptiste Guimbaud",
      "Marc Plantevit",
      "Léa Maître",
      "Rémy Cazabet"
    ],
    "abstract": "In epidemiology, traditional statistical methods such as logistic regression,\nlinear regression, and other parametric models are commonly employed to\ninvestigate associations between predictors and health outcomes. However,\nnon-parametric machine learning techniques, such as deep neural networks\n(DNNs), coupled with explainable AI (XAI) tools, offer new opportunities for\nthis task. Despite their potential, these methods face challenges due to the\nlimited availability of high-quality, high-quantity data in this field. To\naddress these challenges, we introduce SEANN, a novel approach for informed\nDNNs that leverages a prevalent form of domain-specific knowledge: Pooled\nEffect Sizes (PES). PESs are commonly found in published Meta-Analysis studies,\nin different forms, and represent a quantitative form of a scientific\nconsensus. By direct integration within the learning procedure using a custom\nloss, we experimentally demonstrate significant improvements in the\ngeneralizability of predictive performances and the scientific plausibility of\nextracted relationships compared to a domain-knowledge agnostic neural network\nin a scarce and noisy data setting.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.10273v1",
    "published_date": "2025-01-17 16:01:05 UTC",
    "updated_date": "2025-01-17 16:01:05 UTC"
  },
  {
    "arxiv_id": "2501.10256v1",
    "title": "Unsupervised Rhythm and Voice Conversion of Dysarthric to Healthy Speech for ASR",
    "authors": [
      "Karl El Hajal",
      "Enno Hermann",
      "Ajinkya Kulkarni",
      "Mathew Magimai. -Doss"
    ],
    "abstract": "Automatic speech recognition (ASR) systems are well known to perform poorly\non dysarthric speech. Previous works have addressed this by speaking rate\nmodification to reduce the mismatch with typical speech. Unfortunately, these\napproaches rely on transcribed speech data to estimate speaking rates and\nphoneme durations, which might not be available for unseen speakers. Therefore,\nwe combine unsupervised rhythm and voice conversion methods based on\nself-supervised speech representations to map dysarthric to typical speech. We\nevaluate the outputs with a large ASR model pre-trained on healthy speech\nwithout further fine-tuning and find that the proposed rhythm conversion\nespecially improves performance for speakers of the Torgo corpus with more\nsevere cases of dysarthria. Code and audio samples are available at\nhttps://idiap.github.io/RnV .",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.LG",
      "cs.SD"
    ],
    "primary_category": "eess.AS",
    "comment": "Accepted at ICASSP 2025 Satellite Workshop: Workshop on Speech\n  Pathology Analysis and DEtection (SPADE)",
    "pdf_url": "http://arxiv.org/pdf/2501.10256v1",
    "published_date": "2025-01-17 15:39:21 UTC",
    "updated_date": "2025-01-17 15:39:21 UTC"
  },
  {
    "arxiv_id": "2501.10243v2",
    "title": "Random-Key Algorithms for Optimizing Integrated Operating Room Scheduling",
    "authors": [
      "Bruno Salezze Vieira",
      "Eduardo Machado Silva",
      "Antonio Augusto Chaves"
    ],
    "abstract": "Efficient surgery room scheduling is essential for hospital efficiency,\npatient satisfaction, and resource utilization. This study addresses this\nchallenge by introducing a novel concept of Random-Key Optimizer (RKO),\nrigorously tested on literature and new, real-world inspired instances. Our\ncombinatorial optimization problem incorporates multi-room scheduling,\nequipment scheduling, and complex availability constraints for rooms, patients,\nand surgeons, facilitating rescheduling and enhancing operational flexibility.\nThe RKO approach represents solutions as points in a continuous space, which\nare then mapped in the problem solution space via a deterministic function\nknown as a decoder. The core idea is to operate metaheuristics and heuristics\nin the random-key space, unaware of the original solution space. We design the\nBiased Random-Key Genetic Algorithm with $Q$-Learning, Simulated Annealing, and\nIterated Local Search for use within an RKO framework, employing a single\ndecoder function. The proposed metaheuristics are complemented by lower-bound\nformulations, providing optimal gaps for evaluating the effectiveness of the\nheuristic results. Our results demonstrate significant lower and upper bounds\nimprovements for the literature instances, notably proving one optimal result.\nFurthermore, the best-proposed metaheuristic efficiently generates schedules\nfor the newly introduced instances, even in highly constrained scenarios. This\nresearch offers valuable insights and practical solutions for improving surgery\nscheduling processes, offering tangible benefits to hospitals by optimising\nresource allocation, reducing patient wait times, and enhancing overall\noperational efficiency.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "math.CO",
      "F.2.2; I.2.7; I.2.8"
    ],
    "primary_category": "cs.NE",
    "comment": "38 pages, Preprint submitted to Applied Soft Computing",
    "pdf_url": "http://arxiv.org/pdf/2501.10243v2",
    "published_date": "2025-01-17 15:11:30 UTC",
    "updated_date": "2025-01-24 15:59:16 UTC"
  },
  {
    "arxiv_id": "2501.10240v2",
    "title": "Challenges and recommendations for Electronic Health Records data extraction and preparation for dynamic prediction modelling in hospitalized patients -- a practical guide",
    "authors": [
      "Elena Albu",
      "Shan Gao",
      "Pieter Stijnen",
      "Frank E. Rademakers",
      "Bas C T van Bussel",
      "Taya Collyer",
      "Tina Hernandez-Boussard",
      "Laure Wynants",
      "Ben Van Calster"
    ],
    "abstract": "Dynamic predictive modelling using electronic health record (EHR) data has\ngained significant attention in recent years. The reliability and\ntrustworthiness of such models depend heavily on the quality of the underlying\ndata, which is, in part, determined by the stages preceding the model\ndevelopment: data extraction from EHR systems and data preparation. In this\narticle, we identified over forty challenges encountered during these stages\nand provide actionable recommendations for addressing them. These challenges\nare organized into four categories: cohort definition, outcome definition,\nfeature engineering, and data cleaning. This comprehensive list serves as a\npractical guide for data extraction engineers and researchers, promoting best\npractices and improving the quality and real-world applicability of dynamic\nprediction models in clinical settings.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.10240v2",
    "published_date": "2025-01-17 15:09:57 UTC",
    "updated_date": "2025-03-17 17:29:33 UTC"
  },
  {
    "arxiv_id": "2501.10190v1",
    "title": "Temporal Causal Reasoning with (Non-Recursive) Structural Equation Models",
    "authors": [
      "Maksim Gladyshev",
      "Natasha Alechina",
      "Mehdi Dastani",
      "Dragan Doder",
      "Brian Logan"
    ],
    "abstract": "Structural Equation Models (SEM) are the standard approach to representing\ncausal dependencies between variables in causal models. In this paper we\npropose a new interpretation of SEMs when reasoning about Actual Causality, in\nwhich SEMs are viewed as mechanisms transforming the dynamics of exogenous\nvariables into the dynamics of endogenous variables. This allows us to combine\ncounterfactual causal reasoning with existing temporal logic formalisms, and to\nintroduce a temporal logic, CPLTL, for causal reasoning about such structures.\nWe show that the standard restriction to so-called \\textit{recursive} models\n(with no cycles in the dependency graph) is not necessary in our approach,\nallowing us to reason about mutually dependent processes and feedback loops.\nFinally, we introduce new notions of model equivalence for temporal causal\nmodels, and show that CPLTL has an efficient model-checking procedure.",
    "categories": [
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.10190v1",
    "published_date": "2025-01-17 13:37:58 UTC",
    "updated_date": "2025-01-17 13:37:58 UTC"
  },
  {
    "arxiv_id": "2501.10187v2",
    "title": "Good things come in small packages: Should we build AI clusters with Lite-GPUs?",
    "authors": [
      "Burcu Canakci",
      "Junyi Liu",
      "Xingbo Wu",
      "Nathanaël Cheriere",
      "Paolo Costa",
      "Sergey Legtchenko",
      "Dushyanth Narayanan",
      "Ant Rowstron"
    ],
    "abstract": "To match the blooming demand of generative AI workloads, GPU designers have\nso far been trying to pack more and more compute and memory into single complex\nand expensive packages. However, there is growing uncertainty about the\nscalability of individual GPUs and thus AI clusters, as state-of-the-art GPUs\nare already displaying packaging, yield, and cooling limitations. We propose to\nrethink the design and scaling of AI clusters through efficiently-connected\nlarge clusters of Lite-GPUs, GPUs with single, small dies and a fraction of the\ncapabilities of larger GPUs. We think recent advances in co-packaged optics can\nenable distributing AI workloads onto many Lite-GPUs through high bandwidth and\nefficient communication. In this paper, we present the key benefits of\nLite-GPUs on manufacturing cost, blast radius, yield, and power efficiency; and\ndiscuss systems opportunities and challenges around resource, workload, memory,\nand network management.",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.AR",
    "comment": "HotOS'25",
    "pdf_url": "http://arxiv.org/pdf/2501.10187v2",
    "published_date": "2025-01-17 13:32:28 UTC",
    "updated_date": "2025-04-29 11:20:53 UTC"
  },
  {
    "arxiv_id": "2501.10186v1",
    "title": "Generative Artificial Intelligence: Implications for Biomedical and Health Professions Education",
    "authors": [
      "William Hersh"
    ],
    "abstract": "Generative AI has had a profound impact on biomedicine and health, both in\nprofessional work and in education. Based on large language models (LLMs),\ngenerative AI has been found to perform as well as humans in simulated\nsituations taking medical board exams, answering clinical questions, solving\nclinical cases, applying clinical reasoning, and summarizing information.\nGenerative AI is also being used widely in education, performing well in\nacademic courses and their assessments. This review summarizes the successes of\nLLMs and highlights some of their challenges in the context of education, most\nnotably aspects that may undermines the acquisition of knowledge and skills for\nprofessional work. It then provides recommendations for best practices\novercoming shortcomings for LLM use in education. Although there are challenges\nfor use of generative AI in education, all students and faculty, in biomedicine\nand health and beyond, must have understanding and be competent in its use.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.10186v1",
    "published_date": "2025-01-17 13:32:19 UTC",
    "updated_date": "2025-01-17 13:32:19 UTC"
  },
  {
    "arxiv_id": "2501.10179v1",
    "title": "A Simple but Effective Closed-form Solution for Extreme Multi-label Learning",
    "authors": [
      "Kazuma Onishi",
      "Katsuhiko Hayashi"
    ],
    "abstract": "Extreme multi-label learning (XML) is a task of assigning multiple labels\nfrom an extremely large set of labels to each data instance. Many current\nhigh-performance XML models are composed of a lot of hyperparameters, which\ncomplicates the tuning process. Additionally, the models themselves are adapted\nspecifically to XML, which complicates their reimplementation. To remedy this\nproblem, we propose a simple method based on ridge regression for XML. The\nproposed method not only has a closed-form solution but also is composed of a\nsingle hyperparameter. Since there are no precedents on applying ridge\nregression to XML, this paper verified the performance of the method by using\nvarious XML benchmark datasets. Furthermore, we enhanced the prediction of\nlow-frequency labels in XML, which hold informative content. This prediction is\nessential yet challenging because of the limited amount of data. Here, we\nemployed a simple frequency-based weighting. This approach greatly simplifies\nthe process compared with existing techniques. Experimental results revealed\nthat it can achieve levels of performance comparable to, or even exceeding,\nthose of models with numerous hyperparameters. Additionally, we found that the\nfrequency-based weighting significantly improved the predictive performance for\nlow-frequency labels, while requiring almost no changes in implementation. The\nsource code for the proposed method is available on github at\nhttps://github.com/cars1015/XML-ridge.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "10pages, Accepted at ECIR25",
    "pdf_url": "http://arxiv.org/pdf/2501.10179v1",
    "published_date": "2025-01-17 13:24:13 UTC",
    "updated_date": "2025-01-17 13:24:13 UTC"
  },
  {
    "arxiv_id": "2501.10160v1",
    "title": "CSSDM Ontology to Enable Continuity of Care Data Interoperability",
    "authors": [
      "Subhashis Das",
      "Debashis Naskar",
      "Sara Rodriguez Gonzalez",
      "Pamela Hussey"
    ],
    "abstract": "The rapid advancement of digital technologies and recent global pandemic\nscenarios have led to a growing focus on how these technologies can enhance\nhealthcare service delivery and workflow to address crises. Action plans that\nconsolidate existing digital transformation programs are being reviewed to\nestablish core infrastructure and foundations for sustainable healthcare\nsolutions. Reforming health and social care to personalize home care, for\nexample, can help avoid treatment in overcrowded acute hospital settings and\nimprove the experiences and outcomes for both healthcare professionals and\nservice users. In this information-intensive domain, addressing the\ninteroperability challenge through standards-based roadmaps is crucial for\nenabling effective connections between health and social care services. This\napproach facilitates safe and trustworthy data workflows between different\nhealthcare system providers. In this paper, we present a methodology for\nextracting, transforming, and loading data through a semi-automated process\nusing a Common Semantic Standardized Data Model (CSSDM) to create personalized\nhealthcare knowledge graph (KG). The CSSDM is grounded in the formal ontology\nof ISO 13940 ContSys and incorporates FHIR-based specifications to support\nstructural attributes for generating KGs. We propose that the CSSDM facilitates\ndata harmonization and linking, offering an alternative approach to\ninteroperability. This approach promotes a novel form of collaboration between\ncompanies developing health information systems and cloud-enabled health\nservices. Consequently, it provides multiple stakeholders with access to\nhigh-quality data and information sharing.",
    "categories": [
      "cs.AI",
      "68T27",
      "I.2.4; I.2.1"
    ],
    "primary_category": "cs.AI",
    "comment": "6 pages, 5 figures, Published in: 2024 IEEE International Conference\n  on Bioinformatics and Biomedicine (BIBM)",
    "pdf_url": "http://arxiv.org/pdf/2501.10160v1",
    "published_date": "2025-01-17 12:48:48 UTC",
    "updated_date": "2025-01-17 12:48:48 UTC"
  },
  {
    "arxiv_id": "2501.10153v1",
    "title": "Region-wise stacking ensembles for estimating brain-age using MRI",
    "authors": [
      "Georgios Antonopoulos",
      "Shammi More",
      "Simon B. Eickhoff",
      "Federico Raimondo",
      "Kaustubh R. Patil"
    ],
    "abstract": "Predictive modeling using structural magnetic resonance imaging (MRI) data is\na prominent approach to study brain-aging. Machine learning algorithms and\nfeature extraction methods have been employed to improve predictions and\nexplore healthy and accelerated aging e.g. neurodegenerative and psychiatric\ndisorders. The high-dimensional MRI data pose challenges to building\ngeneralizable and interpretable models as well as for data privacy. Common\npractices are resampling or averaging voxels within predefined parcels, which\nreduces anatomical specificity and biological interpretability as voxels within\na region may differently relate to aging. Effectively, naive fusion by\naveraging can result in information loss and reduced accuracy. We present a\nconceptually novel two-level stacking ensemble (SE) approach. The first level\ncomprises regional models for predicting individuals' age based on voxel-wise\ninformation, fused by a second-level model yielding final predictions. Eight\ndata fusion scenarios were explored using as input Gray matter volume (GMV)\nestimates from four datasets covering the adult lifespan. Performance, measured\nusing mean absolute error (MAE), R2, correlation and prediction bias, showed\nthat SE outperformed the region-wise averages. The best performance was\nobtained when first-level regional predictions were obtained as out-of-sample\npredictions on the application site with second-level models trained on\nindependent and site-specific data (MAE=4.75 vs baseline regional mean GMV\nMAE=5.68). Performance improved as more datasets were used for training.\nFirst-level predictions showed improved and more robust aging signal providing\nnew biological insights and enhanced data privacy. Overall, the SE improves\naccuracy compared to the baseline while preserving or enhancing data privacy.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "version1",
    "pdf_url": "http://arxiv.org/pdf/2501.10153v1",
    "published_date": "2025-01-17 12:24:28 UTC",
    "updated_date": "2025-01-17 12:24:28 UTC"
  },
  {
    "arxiv_id": "2501.10151v1",
    "title": "Topology-Driven Attribute Recovery for Attribute Missing Graph Learning in Social Internet of Things",
    "authors": [
      "Mengran Li",
      "Junzhou Chen",
      "Chenyun Yu",
      "Guanying Jiang",
      "Ronghui Zhang",
      "Yanming Shen",
      "Houbing Herbert Song"
    ],
    "abstract": "With the advancement of information technology, the Social Internet of Things\n(SIoT) has fostered the integration of physical devices and social networks,\ndeepening the study of complex interaction patterns. Text Attribute Graphs\n(TAGs) capture both topological structures and semantic attributes, enhancing\nthe analysis of complex interactions within the SIoT. However, existing graph\nlearning methods are typically designed for complete attributed graphs, and the\ncommon issue of missing attributes in Attribute Missing Graphs (AMGs) increases\nthe difficulty of analysis tasks. To address this, we propose the\nTopology-Driven Attribute Recovery (TDAR) framework, which leverages\ntopological data for AMG learning. TDAR introduces an improved pre-filling\nmethod for initial attribute recovery using native graph topology.\nAdditionally, it dynamically adjusts propagation weights and incorporates\nhomogeneity strategies within the embedding space to suit AMGs' unique\ntopological structures, effectively reducing noise during information\npropagation. Extensive experiments on public datasets demonstrate that TDAR\nsignificantly outperforms state-of-the-art methods in attribute reconstruction\nand downstream tasks, offering a robust solution to the challenges posed by\nAMGs. The code is available at https://github.com/limengran98/TDAR.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted by IEEE Internet of Things Journal",
    "pdf_url": "http://arxiv.org/pdf/2501.10151v1",
    "published_date": "2025-01-17 12:23:42 UTC",
    "updated_date": "2025-01-17 12:23:42 UTC"
  },
  {
    "arxiv_id": "2501.10150v2",
    "title": "Dual Debiasing: Remove Stereotypes and Keep Factual Gender for Fair Language Modeling and Translation",
    "authors": [
      "Tomasz Limisiewicz",
      "David Mareček",
      "Tomáš Musil"
    ],
    "abstract": "Mitigation of biases, such as language models' reliance on gender\nstereotypes, is a crucial endeavor required for the creation of reliable and\nuseful language technology. The crucial aspect of debiasing is to ensure that\nthe models preserve their versatile capabilities, including their ability to\nsolve language tasks and equitably represent various genders. To address this\nissue, we introduce a streamlined Dual Dabiasing Algorithm through Model\nAdaptation (2DAMA). Novel Dual Debiasing enables robust reduction of\nstereotypical bias while preserving desired factual gender information encoded\nby language models. We show that 2DAMA effectively reduces gender bias in\nEnglish and is one of the first approaches facilitating the mitigation of\nstereotypical tendencies in translation. The proposed method's key advantage is\nthe preservation of factual gender cues, which are useful in a wide range of\nnatural language processing tasks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.10150v2",
    "published_date": "2025-01-17 12:23:30 UTC",
    "updated_date": "2025-01-30 20:11:45 UTC"
  },
  {
    "arxiv_id": "2501.10141v1",
    "title": "Enhancing UAV Path Planning Efficiency Through Accelerated Learning",
    "authors": [
      "Joseanne Viana",
      "Boris Galkin",
      "Lester Ho",
      "Holger Claussen"
    ],
    "abstract": "Unmanned Aerial Vehicles (UAVs) are increasingly essential in various fields\nsuch as surveillance, reconnaissance, and telecommunications. This study aims\nto develop a learning algorithm for the path planning of UAV wireless\ncommunication relays, which can reduce storage requirements and accelerate Deep\nReinforcement Learning (DRL) convergence. Assuming the system possesses terrain\nmaps of the area and can estimate user locations using localization algorithms\nor direct GPS reporting, it can input these parameters into the learning\nalgorithms to achieve optimized path planning performance. However, higher\nresolution terrain maps are necessary to extract topological information such\nas terrain height, object distances, and signal blockages. This requirement\nincreases memory and storage demands on UAVs while also lengthening convergence\ntimes in DRL algorithms. Similarly, defining the telecommunication coverage map\nin UAV wireless communication relays using these terrain maps and user position\nestimations demands higher memory and storage utilization for the learning path\nplanning algorithms. Our approach reduces path planning training time by\napplying a dimensionality reduction technique based on Principal Component\nAnalysis (PCA), sample combination, Prioritized Experience Replay (PER), and\nthe combination of Mean Squared Error (MSE) and Mean Absolute Error (MAE) loss\ncalculations in the coverage map estimates, thereby enhancing a Twin Delayed\nDeep Deterministic Policy Gradient (TD3) algorithm. The proposed solution\nreduces the convergence episodes needed for basic training by approximately\nfour times compared to the traditional TD3.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "This paper was accepted in https://camad2024.ieee-camad.org/\n  conference but it is not available from the conference yet",
    "pdf_url": "http://arxiv.org/pdf/2501.10141v1",
    "published_date": "2025-01-17 12:05:24 UTC",
    "updated_date": "2025-01-17 12:05:24 UTC"
  },
  {
    "arxiv_id": "2501.10139v2",
    "title": "Conformal Prediction Sets with Improved Conditional Coverage using Trust Scores",
    "authors": [
      "Jivat Neet Kaur",
      "Michael I. Jordan",
      "Ahmed Alaa"
    ],
    "abstract": "Standard conformal prediction offers a marginal guarantee on coverage, but\nfor prediction sets to be truly useful, they should ideally ensure coverage\nconditional on each test point. Unfortunately, it is impossible to achieve\nexact, distribution-free conditional coverage in finite samples. In this work,\nwe propose an alternative conformal prediction algorithm that targets coverage\nwhere it matters most--in instances where a classifier is overconfident in its\nincorrect predictions. We start by dissecting miscoverage events in\nmarginally-valid conformal prediction, and show that miscoverage rates vary\nbased on the classifier's confidence and its deviation from the Bayes optimal\nclassifier. Motivated by this insight, we develop a variant of conformal\nprediction that targets coverage conditional on a reduced set of two variables:\nthe classifier's confidence in a prediction and a nonparametric trust score\nthat measures its deviation from the Bayes classifier. Empirical evaluation on\nmultiple image datasets shows that our method generally improves conditional\ncoverage properties compared to standard conformal prediction, including\nclass-conditional coverage, coverage over arbitrary subgroups, and coverage\nover demographic groups.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ME",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.10139v2",
    "published_date": "2025-01-17 12:01:56 UTC",
    "updated_date": "2025-02-09 22:05:43 UTC"
  },
  {
    "arxiv_id": "2501.10134v1",
    "title": "Exploring the Impact of Generative Artificial Intelligence in Education: A Thematic Analysis",
    "authors": [
      "Abhishek Kaushik",
      "Sargam Yadav",
      "Andrew Browne",
      "David Lillis",
      "David Williams",
      "Jack Mc Donnell",
      "Peadar Grant",
      "Siobhan Connolly Kernan",
      "Shubham Sharma",
      "Mansi Arora"
    ],
    "abstract": "The recent advancements in Generative Artificial intelligence (GenAI)\ntechnology have been transformative for the field of education. Large Language\nModels (LLMs) such as ChatGPT and Bard can be leveraged to automate boilerplate\ntasks, create content for personalised teaching, and handle repetitive tasks to\nallow more time for creative thinking. However, it is important to develop\nguidelines, policies, and assessment methods in the education sector to ensure\nthe responsible integration of these tools. In this article, thematic analysis\nhas been performed on seven essays obtained from professionals in the education\nsector to understand the advantages and pitfalls of using GenAI models such as\nChatGPT and Bard in education. Exploratory Data Analysis (EDA) has been\nperformed on the essays to extract further insights from the text. The study\nfound several themes which highlight benefits and drawbacks of GenAI tools, as\nwell as suggestions to overcome these limitations and ensure that students are\nusing these tools in a responsible and ethical manner.",
    "categories": [
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.10134v1",
    "published_date": "2025-01-17 11:49:49 UTC",
    "updated_date": "2025-01-17 11:49:49 UTC"
  },
  {
    "arxiv_id": "2501.10129v1",
    "title": "Spatio-temporal Graph Learning on Adaptive Mined Key Frames for High-performance Multi-Object Tracking",
    "authors": [
      "Futian Wang",
      "Fengxiang Liu",
      "Xiao Wang"
    ],
    "abstract": "In the realm of multi-object tracking, the challenge of accurately capturing\nthe spatial and temporal relationships between objects in video sequences\nremains a significant hurdle. This is further complicated by frequent\noccurrences of mutual occlusions among objects, which can lead to tracking\nerrors and reduced performance in existing methods. Motivated by these\nchallenges, we propose a novel adaptive key frame mining strategy that\naddresses the limitations of current tracking approaches. Specifically, we\nintroduce a Key Frame Extraction (KFE) module that leverages reinforcement\nlearning to adaptively segment videos, thereby guiding the tracker to exploit\nthe intrinsic logic of the video content. This approach allows us to capture\nstructured spatial relationships between different objects as well as the\ntemporal relationships of objects across frames. To tackle the issue of object\nocclusions, we have developed an Intra-Frame Feature Fusion (IFF) module.\nUnlike traditional graph-based methods that primarily focus on inter-frame\nfeature fusion, our IFF module uses a Graph Convolutional Network (GCN) to\nfacilitate information exchange between the target and surrounding objects\nwithin a frame. This innovation significantly enhances target\ndistinguishability and mitigates tracking loss and appearance similarity due to\nocclusions. By combining the strengths of both long and short trajectories and\nconsidering the spatial relationships between objects, our proposed tracker\nachieves impressive results on the MOT17 dataset, i.e., 68.6 HOTA, 81.0 IDF1,\n66.6 AssA, and 893 IDS, proving its effectiveness and accuracy.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.10129v1",
    "published_date": "2025-01-17 11:36:38 UTC",
    "updated_date": "2025-01-17 11:36:38 UTC"
  },
  {
    "arxiv_id": "2501.10114v2",
    "title": "Infrastructure for AI Agents",
    "authors": [
      "Alan Chan",
      "Kevin Wei",
      "Sihao Huang",
      "Nitarshan Rajkumar",
      "Elija Perrier",
      "Seth Lazar",
      "Gillian K. Hadfield",
      "Markus Anderljung"
    ],
    "abstract": "AI agents plan and execute interactions in open-ended environments. For\nexample, OpenAI's Operator can use a web browser to do product comparisons and\nbuy online goods. To facilitate beneficial interactions and mitigate harmful\nones, much research focuses on directly modifying agent behaviour. For example,\ndevelopers can train agents to follow user instructions. This focus on direct\nmodifications is useful, but insufficient. We will also need external protocols\nand systems that shape how agents interact with institutions and other actors.\nFor instance, agents will need more efficient protocols to communicate with\neach other and form agreements. In addition, attributing an agent's actions to\na particular human or other legal entity can help to establish trust, and also\ndisincentivize misuse. Given this motivation, we propose the concept of agent\ninfrastructure: technical systems and shared protocols external to agents that\nare designed to mediate and influence their interactions with and impacts on\ntheir environments. Just as the Internet relies on protocols like HTTPS, our\nwork argues that agent infrastructure will be similarly indispensable to\necosystems of agents. We identify three functions for agent infrastructure: 1)\nattributing actions, properties, and other information to specific agents,\ntheir users, or other actors; 2) shaping agents' interactions; and 3) detecting\nand remedying harmful actions from agents. We provide an incomplete catalog of\nresearch directions for such functions. For each direction, we include analysis\nof use cases, infrastructure adoption, relationships to existing (internet)\ninfrastructure, limitations, and open questions. Making progress on agent\ninfrastructure can prepare society for the adoption of more advanced agents.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted to TMLR",
    "pdf_url": "http://arxiv.org/pdf/2501.10114v2",
    "published_date": "2025-01-17 10:58:12 UTC",
    "updated_date": "2025-05-16 08:02:38 UTC"
  },
  {
    "arxiv_id": "2501.10107v1",
    "title": "BBPOS: BERT-based Part-of-Speech Tagging for Uzbek",
    "authors": [
      "Latofat Bobojonova",
      "Arofat Akhundjanova",
      "Phil Ostheimer",
      "Sophie Fellenz"
    ],
    "abstract": "This paper advances NLP research for the low-resource Uzbek language by\nevaluating two previously untested monolingual Uzbek BERT models on the\npart-of-speech (POS) tagging task and introducing the first publicly available\nUPOS-tagged benchmark dataset for Uzbek. Our fine-tuned models achieve 91%\naverage accuracy, outperforming the baseline multi-lingual BERT as well as the\nrule-based tagger. Notably, these models capture intermediate POS changes\nthrough affixes and demonstrate context sensitivity, unlike existing rule-based\ntaggers.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.10107v1",
    "published_date": "2025-01-17 10:50:22 UTC",
    "updated_date": "2025-01-17 10:50:22 UTC"
  },
  {
    "arxiv_id": "2501.10106v1",
    "title": "LLM Reasoner and Automated Planner: A new NPC approach",
    "authors": [
      "Israel Puerta-Merino",
      "Jordi Sabater-Mir"
    ],
    "abstract": "In domains requiring intelligent agents to emulate plausible human-like\nbehaviour, such as formative simulations, traditional techniques like behaviour\ntrees encounter significant challenges. Large Language Models (LLMs), despite\nnot always yielding optimal solutions, usually offer plausible and human-like\nresponses to a given problem. In this paper, we exploit this capability and\npropose a novel architecture that integrates an LLM for decision-making with a\nclassical automated planner that can generate sound plans for that decision.\nThe combination aims to equip an agent with the ability to make decisions in\nvarious situations, even if they were not anticipated during the design phase.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "15 pages, 7 figures, extended version of the homonymous paper\n  submitted to the Catalan Conference on Artificial Intelligent (CCIA) 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.10106v1",
    "published_date": "2025-01-17 10:47:11 UTC",
    "updated_date": "2025-01-17 10:47:11 UTC"
  },
  {
    "arxiv_id": "2501.10105v2",
    "title": "Universal Actions for Enhanced Embodied Foundation Models",
    "authors": [
      "Jinliang Zheng",
      "Jianxiong Li",
      "Dongxiu Liu",
      "Yinan Zheng",
      "Zhihao Wang",
      "Zhonghong Ou",
      "Yu Liu",
      "Jingjing Liu",
      "Ya-Qin Zhang",
      "Xianyuan Zhan"
    ],
    "abstract": "Training on diverse, internet-scale data is a key factor in the success of\nrecent large foundation models. Yet, using the same recipe for building\nembodied agents has faced noticeable difficulties. Despite the availability of\nmany crowd-sourced embodied datasets, their action spaces often exhibit\nsignificant heterogeneity due to distinct physical embodiment and control\ninterfaces for different robots, causing substantial challenges in developing\nembodied foundation models using cross-domain data. In this paper, we introduce\nUniAct, a new embodied foundation modeling framework operating in a Universal\nAction Space. Our learned universal actions capture the generic atomic\nbehaviors across diverse robots by exploiting their shared structural features,\nand enable enhanced cross-domain data utilization and cross-embodiment\ngeneralizations by eliminating the notorious heterogeneity. The universal\nactions can be efficiently translated back to heterogeneous actionable commands\nby simply adding embodiment-specific details, from which fast adaptation to new\nrobots becomes simple and straightforward. Our 0.5B instantiation of UniAct\noutperforms 14X larger SOTA embodied foundation models in extensive evaluations\non various real-world and simulation robots, showcasing exceptional\ncross-embodiment control and adaptation capability, highlighting the crucial\nbenefit of adopting universal actions. Project page:\nhttps://github.com/2toinf/UniAct",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.RO",
    "comment": "CVPR 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.10105v2",
    "published_date": "2025-01-17 10:45:22 UTC",
    "updated_date": "2025-03-08 13:55:48 UTC"
  },
  {
    "arxiv_id": "2501.10100v3",
    "title": "Robotic World Model: A Neural Network Simulator for Robust Policy Optimization in Robotics",
    "authors": [
      "Chenhao Li",
      "Andreas Krause",
      "Marco Hutter"
    ],
    "abstract": "Learning robust and generalizable world models is crucial for enabling\nefficient and scalable robotic control in real-world environments. In this\nwork, we introduce a novel framework for learning world models that accurately\ncapture complex, partially observable, and stochastic dynamics. The proposed\nmethod employs a dual-autoregressive mechanism and self-supervised training to\nachieve reliable long-horizon predictions without relying on domain-specific\ninductive biases, ensuring adaptability across diverse robotic tasks. We\nfurther propose a policy optimization framework that leverages world models for\nefficient training in imagined environments and seamless deployment in\nreal-world systems. This work advances model-based reinforcement learning by\naddressing the challenges of long-horizon prediction, error accumulation, and\nsim-to-real transfer. By providing a scalable and robust framework, the\nintroduced methods pave the way for adaptive and efficient robotic systems in\nreal-world applications.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.10100v3",
    "published_date": "2025-01-17 10:39:09 UTC",
    "updated_date": "2025-04-24 05:33:20 UTC"
  },
  {
    "arxiv_id": "2501.10098v2",
    "title": "landmarker: a Toolkit for Anatomical Landmark Localization in 2D/3D Images",
    "authors": [
      "Jef Jonkers",
      "Luc Duchateau",
      "Glenn Van Wallendael",
      "Sofie Van Hoecke"
    ],
    "abstract": "Anatomical landmark localization in 2D/3D images is a critical task in\nmedical imaging. Although many general-purpose tools exist for landmark\nlocalization in classical computer vision tasks, such as pose estimation, they\nlack the specialized features and modularity necessary for anatomical landmark\nlocalization applications in the medical domain. Therefore, we introduce\nlandmarker, a Python package built on PyTorch. The package provides a\ncomprehensive, flexible toolkit for developing and evaluating landmark\nlocalization algorithms, supporting a range of methodologies, including static\nand adaptive heatmap regression. landmarker enhances the accuracy of landmark\nidentification, streamlines research and development processes, and supports\nvarious image formats and preprocessing pipelines. Its modular design allows\nusers to customize and extend the toolkit for specific datasets and\napplications, accelerating innovation in medical imaging. landmarker addresses\na critical need for precision and customization in landmark localization tasks\nnot adequately met by existing general-purpose pose estimation tools.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "11 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.10098v2",
    "published_date": "2025-01-17 10:35:58 UTC",
    "updated_date": "2025-05-05 15:41:55 UTC"
  },
  {
    "arxiv_id": "2501.10091v2",
    "title": "How Do Programming Students Use Generative AI?",
    "authors": [
      "Christian Rahe",
      "Walid Maalej"
    ],
    "abstract": "Programming students have a widespread access to powerful Generative AI tools\nlike ChatGPT. While this can help understand the learning material and assist\nwith exercises, educators are voicing more and more concerns about an\noverreliance on generated outputs and lack of critical thinking skills. It is\nthus important to understand how students actually use generative AI and what\nimpact this could have on their learning behavior. To this end, we conducted a\nstudy including an exploratory experiment with 37 programming students, giving\nthem monitored access to ChatGPT while solving a code authoring exercise. The\ntask was not directly solvable by ChatGPT and required code comprehension and\nreasoning. While only 23 of the students actually opted to use the chatbot, the\nmajority of those eventually prompted it to simply generate a full solution. We\nobserved two prevalent usage strategies: to seek knowledge about general\nconcepts and to directly generate solutions. Instead of using the bot to\ncomprehend the code and their own mistakes, students often got trapped in a\nvicious cycle of submitting wrong generated code and then asking the bot for a\nfix. Those who self-reported using generative AI regularly were more likely to\nprompt the bot to generate a solution. Our findings indicate that concerns\nabout potential decrease in programmers' agency and productivity with\nGenerative AI are justified. We discuss how researchers and educators can\nrespond to the potential risk of students uncritically over-relying on\nGenerative AI. We also discuss potential modifications to our study design for\nlarge-scale replications.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CY",
      "K.3.2; I.2.1; H.1.2"
    ],
    "primary_category": "cs.HC",
    "comment": "preprint; accepted to ACM International Conference on the Foundations\n  of Software Engineering (FSE) 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.10091v2",
    "published_date": "2025-01-17 10:25:41 UTC",
    "updated_date": "2025-02-21 15:07:21 UTC"
  },
  {
    "arxiv_id": "2501.10075v1",
    "title": "Robust Change Captioning in Remote Sensing: SECOND-CC Dataset and MModalCC Framework",
    "authors": [
      "Ali Can Karaca",
      "M. Enes Ozelbas",
      "Saadettin Berber",
      "Orkhan Karimli",
      "Turabi Yildirim",
      "M. Fatih Amasyali"
    ],
    "abstract": "Remote sensing change captioning (RSICC) aims to describe changes between\nbitemporal images in natural language. Existing methods often fail under\nchallenges like illumination differences, viewpoint changes, blur effects,\nleading to inaccuracies, especially in no-change regions. Moreover, the images\nacquired at different spatial resolutions and have registration errors tend to\naffect the captions. To address these issues, we introduce SECOND-CC, a novel\nRSICC dataset featuring high-resolution RGB image pairs, semantic segmentation\nmaps, and diverse real-world scenarios. SECOND-CC which contains 6,041 pairs of\nbitemporal RS images and 30,205 sentences describing the differences between\nimages. Additionally, we propose MModalCC, a multimodal framework that\nintegrates semantic and visual data using advanced attention mechanisms,\nincluding Cross-Modal Cross Attention (CMCA) and Multimodal Gated Cross\nAttention (MGCA). Detailed ablation studies and attention visualizations\nfurther demonstrate its effectiveness and ability to address RSICC challenges.\nComprehensive experiments show that MModalCC outperforms state-of-the-art RSICC\nmethods, including RSICCformer, Chg2Cap, and PSNet with +4.6% improvement on\nBLEU4 score and +9.6% improvement on CIDEr score. We will make our dataset and\ncodebase publicly available to facilitate future research at\nhttps://github.com/ChangeCapsInRS/SecondCC",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "This work has been submitted to the IEEE Transactions on Geoscience\n  and Remote Sensing journal for possible publication",
    "pdf_url": "http://arxiv.org/pdf/2501.10075v1",
    "published_date": "2025-01-17 09:47:27 UTC",
    "updated_date": "2025-01-17 09:47:27 UTC"
  },
  {
    "arxiv_id": "2501.10074v3",
    "title": "SpatialCoT: Advancing Spatial Reasoning through Coordinate Alignment and Chain-of-Thought for Embodied Task Planning",
    "authors": [
      "Yuecheng Liu",
      "Dafeng Chi",
      "Shiguang Wu",
      "Zhanguang Zhang",
      "Yaochen Hu",
      "Lingfeng Zhang",
      "Yingxue Zhang",
      "Shuang Wu",
      "Tongtong Cao",
      "Guowei Huang",
      "Helong Huang",
      "Guangjian Tian",
      "Weichao Qiu",
      "Xingyue Quan",
      "Jianye Hao",
      "Yuzheng Zhuang"
    ],
    "abstract": "Spatial reasoning is an essential problem in embodied AI research. Efforts to\nenhance spatial reasoning abilities through supplementary spatial data and\nfine-tuning have proven limited and ineffective when addressing complex\nembodied tasks, largely due to their dependence on language-based outputs.\nWhile some approaches have introduced a point-based action space to mitigate\nthis issue, they fall short in managing more intricate tasks within complex\nenvironments. This deficiency arises from their failure to fully exploit the\ninherent thinking and reasoning capabilities that are fundamental strengths of\nVision-Language Models (VLMs). To address these limitations, we propose a novel\napproach named SpatialCoT, specifically designed to bolster the spatial\nreasoning capabilities of VLMs. Our approach comprises two stages: spatial\ncoordinate bi-directional alignment, which aligns vision-language inputs with\nspatial coordinates, and chain-of-thought spatial grounding, which harnesses\nthe reasoning capabilities of language models for advanced spatial reasoning.\nWe evaluate SpatialCoT on challenging navigation and manipulation tasks, both\nin simulation and real-world settings. Experimental results demonstrate that\nour method significantly outperforms previous state-of-the-art approaches in\nboth tasks.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.RO",
    "comment": "Under Review",
    "pdf_url": "http://arxiv.org/pdf/2501.10074v3",
    "published_date": "2025-01-17 09:46:27 UTC",
    "updated_date": "2025-01-23 02:31:25 UTC"
  },
  {
    "arxiv_id": "2501.10069v4",
    "title": "A Survey on LLM Test-Time Compute via Search: Tasks, LLM Profiling, Search Algorithms, and Relevant Frameworks",
    "authors": [
      "Xinzhe Li"
    ],
    "abstract": "LLM test-time compute (or LLM inference) via search has emerged as a\npromising research area with rapid developments. However, current frameworks\noften adopt distinct perspectives on three key aspects: task definition, LLM\nprofiling, and search procedures, making direct comparisons challenging.\nMoreover, the search algorithms employed often diverge from standard\nimplementations, and their specific characteristics are not thoroughly\nspecified. This survey aims to provide a comprehensive but integrated technical\nreview on existing LIS frameworks. Specifically, we unify task definitions\nunder Markov Decision Process (MDP) and provides modular definitions of LLM\nprofiling and search procedures. The definitions enable precise comparisons of\nvarious LLM inference frameworks while highlighting their departures from\nconventional search algorithms. We also discuss the applicability, performance,\nand efficiency of these methods. For ongoing paper updates, please refer to our\nGitHub repository: https://github.com/xinzhel/LLM-Search.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "TMLR (camera-ready). Details on\n  https://openreview.net/forum?id=x9VQFjtOPS",
    "pdf_url": "http://arxiv.org/pdf/2501.10069v4",
    "published_date": "2025-01-17 09:42:48 UTC",
    "updated_date": "2025-04-27 08:55:07 UTC"
  },
  {
    "arxiv_id": "2501.10054v1",
    "title": "Accelerating Large Language Models through Partially Linear Feed-Forward Network",
    "authors": [
      "Gansen Hu",
      "Zhaoguo Wang",
      "Jinglin Wei",
      "Wei Huang",
      "Haibo Chen"
    ],
    "abstract": "Large language models (LLMs) demonstrate remarkable capabilities but face\ndeployment challenges due to their massive parameter counts. While existing\ncompression techniques like pruning can reduce model size, it leads to\nsignificant accuracy degradation under high compression ratios. We present a\nnovel perspective inspired by constant folding in compiler optimization. Our\napproach enables parameter reduction by treating activation functions in LLMs\nas linear functions.\n  However, recent LLMs use complex non-linear activations like GELU that\nprevent direct application of this technique. We propose TARDIS, which enables\noptimization of LLMs with non-linear activations by partially approximating\nthem with linear functions in frequently occurring input ranges. For outlier\ninputs, TARDIS employs an online predictor to dynamically fall back to original\ncomputations.\n  Our experiments demonstrate that TARDIS achieves 80% parameter reduction in\nfeed-forward networks, while significantly outperforming state-of-the-art\npruning methods Wanda and RIA with up to 65% higher accuracy. In practical\ndeployments for a 7B model, TARDIS achieves 1.6x end-to-end inference speedup\nwhen integrated with the vLLM serving system, and 1.4x speedup with the widely\nadopted HuggingFace implementation, while incurring only a 10.9% accuracy\ntrade-off.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "D.4; I.2; D.3.4"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.10054v1",
    "published_date": "2025-01-17 09:20:56 UTC",
    "updated_date": "2025-01-17 09:20:56 UTC"
  },
  {
    "arxiv_id": "2501.10053v2",
    "title": "AirRAG: Activating Intrinsic Reasoning for Retrieval Augmented Generation using Tree-based Search",
    "authors": [
      "Wenfeng Feng",
      "Chuzhan Hao",
      "Yuewei Zhang",
      "Jingyi Song",
      "Hao Wang"
    ],
    "abstract": "Leveraging the autonomous decision-making capabilities of large language\nmodels (LLMs) has demonstrated superior performance in reasoning tasks.\nHowever, despite the success of iterative or recursive retrieval-augmented\ngeneration (RAG) techniques, these methods are often constrained to a single\nsolution space when confronted with complex problems. In this paper, we propose\na novel thinking pattern in RAG that integrates system analysis with efficient\nreasoning actions, significantly activating intrinsic reasoning capabilities\nand expanding the solution space of specific tasks via Monte Carlo Tree Search\n(MCTS), which we refer to as AirRAG. Specifically, our approach designs five\nfundamental reasoning actions, which are expanded to a broad tree-based\nreasoning space using MCTS. The approach also incorporates self-consistency\nverification to explore potential reasoning paths and inference scaling law.\nAdditionally, computationally optimal strategies are employed to allocate more\ninference resources to key actions, thereby enhancing overall performance.\nExperimental results demonstrate the effectiveness of AirRAG, showing\nsignificant performance gains on complex question-answering datasets.\nFurthermore, AirRAG is flexible and lightweight, making it easy to integrate\nwith other advanced technologies.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "17 pages, 14 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.10053v2",
    "published_date": "2025-01-17 09:16:13 UTC",
    "updated_date": "2025-02-14 15:20:47 UTC"
  },
  {
    "arxiv_id": "2501.10048v1",
    "title": "Virtual Nodes Improve Long-term Traffic Prediction",
    "authors": [
      "Xiaoyang Cao",
      "Dingyi Zhuang",
      "Jinhua Zhao",
      "Shenhao Wang"
    ],
    "abstract": "Effective traffic prediction is a cornerstone of intelligent transportation\nsystems, enabling precise forecasts of traffic flow, speed, and congestion.\nWhile traditional spatio-temporal graph neural networks (ST-GNNs) have achieved\nnotable success in short-term traffic forecasting, their performance in\nlong-term predictions remains limited. This challenge arises from\nover-squashing problem, where bottlenecks and limited receptive fields restrict\ninformation flow and hinder the modeling of global dependencies. To address\nthese challenges, this study introduces a novel framework that incorporates\nvirtual nodes, which are additional nodes added to the graph and connected to\nexisting nodes, in order to aggregate information across the entire graph\nwithin a single GNN layer. Our proposed model incorporates virtual nodes by\nconstructing a semi-adaptive adjacency matrix. This matrix integrates\ndistance-based and adaptive adjacency matrices, allowing the model to leverage\ngeographical information while also learning task-specific features from data.\nExperimental results demonstrate that the inclusion of virtual nodes\nsignificantly enhances long-term prediction accuracy while also improving\nlayer-wise sensitivity to mitigate the over-squashing problem. Virtual nodes\nalso offer enhanced explainability by focusing on key intersections and\nhigh-traffic areas, as shown by the visualization of their adjacency matrix\nweights on road network heat maps. Our advanced approach enhances the\nunderstanding and management of urban traffic systems, making it particularly\nwell-suited for real-world applications.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.10048v1",
    "published_date": "2025-01-17 09:09:01 UTC",
    "updated_date": "2025-01-17 09:09:01 UTC"
  },
  {
    "arxiv_id": "2501.10041v1",
    "title": "Spatiotemporal Prediction of Secondary Crashes by Rebalancing Dynamic and Static Data with Generative Adversarial Networks",
    "authors": [
      "Junlan Chen",
      "Yiqun Li",
      "Chenyu Ling",
      "Ziyuan Pu",
      "Xiucheng Guo"
    ],
    "abstract": "Data imbalance is a common issue in analyzing and predicting sudden traffic\nevents. Secondary crashes constitute only a small proportion of all crashes.\nThese secondary crashes, triggered by primary crashes, significantly exacerbate\ntraffic congestion and increase the severity of incidents. However, the severe\nimbalance of secondary crash data poses significant challenges for prediction\nmodels, affecting their generalization ability and prediction accuracy.\nExisting methods fail to fully address the complexity of traffic crash data,\nparticularly the coexistence of dynamic and static features, and often struggle\nto effectively handle data samples of varying lengths. Furthermore, most\ncurrent studies predict the occurrence probability and spatiotemporal\ndistribution of secondary crashes separately, lacking an integrated solution.\nTo address these challenges, this study proposes a hybrid model named\nVarFusiGAN-Transformer, aimed at improving the fidelity of secondary crash data\ngeneration and jointly predicting the occurrence and spatiotemporal\ndistribution of secondary crashes. The VarFusiGAN-Transformer model employs\nLong Short-Term Memory (LSTM) networks to enhance the generation of\nmultivariate long-time series data, incorporating a static data generator and\nan auxiliary discriminator to model the joint distribution of dynamic and\nstatic features. In addition, the model's prediction module achieves\nsimultaneous prediction of both the occurrence and spatiotemporal distribution\nof secondary crashes. Compared to existing methods, the proposed model\ndemonstrates superior performance in generating high-fidelity data and\nimproving prediction accuracy.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.10041v1",
    "published_date": "2025-01-17 08:56:49 UTC",
    "updated_date": "2025-01-17 08:56:49 UTC"
  },
  {
    "arxiv_id": "2501.10487v2",
    "title": "Theme-Explanation Structure for Table Summarization using Large Language Models: A Case Study on Korean Tabular Data",
    "authors": [
      "TaeYoon Kwack",
      "Jisoo Kim",
      "Ki Yong Jung",
      "DongGeon Lee",
      "Heesun Park"
    ],
    "abstract": "This paper proposes the Theme-Explanation Structure-based Table Summarization\n(Tabular-TX) pipeline designed to process tabular data efficiently. Tabular-TX\npreprocesses tabular data by focusing on highlighted cells. It then generates\nsummary sentences following a structured format, where the Theme Part appears\nas an adverbial phrase, and the Explanation Part follows as a predictive\nclause. This approach enables tailored analysis by considering the structural\ncharacteristics of tables and their comparability. Unlike conventional\nfine-tuning approaches that require extensive labeled data and computational\nresources, our method leverages In-Context Learning to dynamically adapt to\ndifferent table structures without additional training, ensuring efficient and\nscalable table interpretation. Experimental results demonstrate that Tabular-TX\nsignificantly outperforms conventional fine-tuning-based methods, particularly\nin low-resource scenarios, by leveraging table structures and metadata more\neffectively through structured prompts. The results confirm that Tabular-TX\nenables more effective processing of complex tabular data. Furthermore, it\nserves as a viable alternative for table-based question answering and\nsummarization tasks in resource-constrained environments.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "6 pages",
    "pdf_url": "http://arxiv.org/pdf/2501.10487v2",
    "published_date": "2025-01-17 08:42:49 UTC",
    "updated_date": "2025-02-26 07:10:17 UTC"
  },
  {
    "arxiv_id": "2501.10024v1",
    "title": "Automatic Speech Recognition for Sanskrit with Transfer Learning",
    "authors": [
      "Bidit Sadhukhan",
      "Swami Punyeshwarananda"
    ],
    "abstract": "Sanskrit, one of humanity's most ancient languages, has a vast collection of\nbooks and manuscripts on diverse topics that have been accumulated over\nmillennia. However, its digital content (audio and text), which is vital for\nthe training of AI systems, is profoundly limited. Furthermore, its intricate\nlinguistics make it hard to develop robust NLP tools for wider accessibility.\nGiven these constraints, we have developed an automatic speech recognition\nmodel for Sanskrit by employing transfer learning mechanism on OpenAI's Whisper\nmodel. After carefully optimising the hyper-parameters, we obtained promising\nresults with our transfer-learned model achieving a word error rate of 15.42%\non Vaksancayah dataset. An online demo of our model is made available for the\nuse of public and to evaluate its performance firsthand thereby paving the way\nfor improved accessibility and technological support for Sanskrit learning in\nthe modern era.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Paper has been accepted at the 4th International Conference on\n  Computer, Communication, Control & Information Technology (C3IT), Hooghly,\n  India, 2024, pp. 1-5",
    "pdf_url": "http://arxiv.org/pdf/2501.10024v1",
    "published_date": "2025-01-17 08:20:32 UTC",
    "updated_date": "2025-01-17 08:20:32 UTC"
  },
  {
    "arxiv_id": "2501.10017v1",
    "title": "Enhancing Crash Frequency Modeling Based on Augmented Multi-Type Data by Hybrid VAE-Diffusion-Based Generative Neural Networks",
    "authors": [
      "Junlan Chen",
      "Qijie He",
      "Pei Liu",
      "Wei Ma",
      "Ziyuan Pu"
    ],
    "abstract": "Crash frequency modelling analyzes the impact of factors like traffic volume,\nroad geometry, and environmental conditions on crash occurrences. Inaccurate\npredictions can distort our understanding of these factors, leading to\nmisguided policies and wasted resources, which jeopardize traffic safety. A key\nchallenge in crash frequency modelling is the prevalence of excessive zero\nobservations, caused by underreporting, the low probability of crashes, and\nhigh data collection costs. These zero observations often reduce model accuracy\nand introduce bias, complicating safety decision making. While existing\napproaches, such as statistical methods, data aggregation, and resampling,\nattempt to address this issue, they either rely on restrictive assumptions or\nresult in significant information loss, distorting crash data. To overcome\nthese limitations, we propose a hybrid VAE-Diffusion neural network, designed\nto reduce zero observations and handle the complexities of multi-type tabular\ncrash data (count, ordinal, nominal, and real-valued variables). We assess the\nsynthetic data quality generated by this model through metrics like similarity,\naccuracy, diversity, and structural consistency, and compare its predictive\nperformance against traditional statistical models. Our findings demonstrate\nthat the hybrid VAE-Diffusion model outperforms baseline models across all\nmetrics, offering a more effective approach to augmenting crash data and\nimproving the accuracy of crash frequency predictions. This study highlights\nthe potential of synthetic data to enhance traffic safety by improving crash\nfrequency modelling and informing better policy decisions.",
    "categories": [
      "cs.AI",
      "cs.DB"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.10017v1",
    "published_date": "2025-01-17 07:53:27 UTC",
    "updated_date": "2025-01-17 07:53:27 UTC"
  },
  {
    "arxiv_id": "2501.10011v1",
    "title": "Mitigating Hallucinations on Object Attributes using Multiview Images and Negative Instructions",
    "authors": [
      "Zhijie Tan",
      "Yuzhi Li",
      "Shengwei Meng",
      "Xiang Yuan",
      "Weiping Li",
      "Tong Mo",
      "Bingce Wang",
      "Xu Chu"
    ],
    "abstract": "Current popular Large Vision-Language Models (LVLMs) are suffering from\nHallucinations on Object Attributes (HoOA), leading to incorrect determination\nof fine-grained attributes in the input images. Leveraging significant\nadvancements in 3D generation from a single image, this paper proposes a novel\nmethod to mitigate HoOA in LVLMs. This method utilizes multiview images sampled\nfrom generated 3D representations as visual prompts for LVLMs, thereby\nproviding more visual information from other viewpoints. Furthermore, we\nobserve the input order of multiple multiview images significantly affects the\nperformance of LVLMs. Consequently, we have devised Multiview Image Augmented\nVLM (MIAVLM), incorporating a Multiview Attributes Perceiver (MAP) submodule\ncapable of simultaneously eliminating the influence of input image order and\naligning visual information from multiview images with Large Language Models\n(LLMs). Besides, we designed and employed negative instructions to mitigate\nLVLMs' bias towards ``Yes\" responses. Comprehensive experiments demonstrate the\neffectiveness of our method.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "2025 IEEE International Conference on Acoustics, Speech, and Signal\n  Processing (ICASSP 2025)",
    "pdf_url": "http://arxiv.org/pdf/2501.10011v1",
    "published_date": "2025-01-17 07:48:37 UTC",
    "updated_date": "2025-01-17 07:48:37 UTC"
  },
  {
    "arxiv_id": "2501.10010v1",
    "title": "Adaptive Spatiotemporal Augmentation for Improving Dynamic Graph Learning",
    "authors": [
      "Xu Chu",
      "Hanlin Xue",
      "Bingce Wang",
      "Xiaoyang Liu",
      "Weiping Li",
      "Tong Mo",
      "Tuoyu Feng",
      "Zhijie Tan"
    ],
    "abstract": "Dynamic graph augmentation is used to improve the performance of dynamic\nGNNs. Most methods assume temporal locality, meaning that recent edges are more\ninfluential than earlier edges. However, for temporal changes in edges caused\nby random noise, overemphasizing recent edges while neglecting earlier ones may\nlead to the model capturing noise. To address this issue, we propose STAA\n(SpatioTemporal Activity-Aware Random Walk Diffusion). STAA identifies nodes\nlikely to have noisy edges in spatiotemporal dimensions. Spatially, it analyzes\ncritical topological positions through graph wavelet coefficients. Temporally,\nit analyzes edge evolution through graph wavelet coefficient change rates.\nThen, random walks are used to reduce the weights of noisy edges, deriving a\ndiffusion matrix containing spatiotemporal information as an augmented\nadjacency matrix for dynamic GNN learning. Experiments on multiple datasets\nshow that STAA outperforms other dynamic graph augmentation methods in node\nclassification and link prediction tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "2025 IEEE International Conference on Acoustics, Speech, and Signal\n  Processing (ICASSP 2025)",
    "pdf_url": "http://arxiv.org/pdf/2501.10010v1",
    "published_date": "2025-01-17 07:48:18 UTC",
    "updated_date": "2025-01-17 07:48:18 UTC"
  },
  {
    "arxiv_id": "2501.09999v1",
    "title": "Deep Learning for Early Alzheimer Disease Detection with MRI Scans",
    "authors": [
      "Mohammad Rafsan",
      "Tamer Oraby",
      "Upal Roy",
      "Sanjeev Kumar",
      "Hansapani Rodrigo"
    ],
    "abstract": "Alzheimer's Disease is a neurodegenerative condition characterized by\ndementia and impairment in neurological function. The study primarily focuses\non the individuals above age 40, affecting their memory, behavior, and\ncognitive processes of the brain. Alzheimer's disease requires diagnosis by a\ndetailed assessment of MRI scans and neuropsychological tests of the patients.\nThis project compares existing deep learning models in the pursuit of enhancing\nthe accuracy and efficiency of AD diagnosis, specifically focusing on the\nConvolutional Neural Network, Bayesian Convolutional Neural Network, and the\nU-net model with the Open Access Series of Imaging Studies brain MRI dataset.\nBesides, to ensure robustness and reliability in the model evaluations, we\naddress the challenge of imbalance in data. We then perform rigorous evaluation\nto determine strengths and weaknesses for each model by considering\nsensitivity, specificity, and computational efficiency. This comparative\nanalysis would shed light on the future role of AI in revolutionizing AD\ndiagnostics but also paved ways for future innovation in medical imaging and\nthe management of neurodegenerative diseases.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.09999v1",
    "published_date": "2025-01-17 07:30:16 UTC",
    "updated_date": "2025-01-17 07:30:16 UTC"
  },
  {
    "arxiv_id": "2501.09997v2",
    "title": "Attention-guided Self-reflection for Zero-shot Hallucination Detection in Large Language Models",
    "authors": [
      "Qiang Liu",
      "Xinlong Chen",
      "Yue Ding",
      "Shizhen Xu",
      "Shu Wu",
      "Liang Wang"
    ],
    "abstract": "Hallucination has emerged as a significant barrier to the effective\napplication of Large Language Models (LLMs). In this work, we introduce a novel\nAttention-Guided SElf-Reflection (AGSER) approach for zero-shot hallucination\ndetection in LLMs. The AGSER method utilizes attention contributions to\ncategorize the input query into attentive and non-attentive queries. Each query\nis then processed separately through the LLMs, allowing us to compute\nconsistency scores between the generated responses and the original answer. The\ndifference between the two consistency scores serves as a hallucination\nestimator. In addition to its efficacy in detecting hallucinations, AGSER\nnotably reduces computational overhead, requiring only three passes through the\nLLM and utilizing two sets of tokens. We have conducted extensive experiments\nwith four widely-used LLMs across three different hallucination benchmarks,\ndemonstrating that our approach significantly outperforms existing methods in\nzero-shot hallucination detection.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.09997v2",
    "published_date": "2025-01-17 07:30:01 UTC",
    "updated_date": "2025-02-12 06:15:17 UTC"
  },
  {
    "arxiv_id": "2501.09996v1",
    "title": "Fast energy-aware OLSR routing in VANETs by means of a parallel evolutionary algorithm",
    "authors": [
      "Jamal Toutouh",
      "Sergio Nesmachnow",
      "Enrique Alba"
    ],
    "abstract": "This work tackles the problem of reducing the power consumption of the OLSR\nrouting protocol in vehicular networks. Nowadays, energy-aware and green\ncommunication protocols are important research topics, specially when deploying\nwireless mobile networks. This article introduces a fast automatic methodology\nto search for energy-efficient OLSR configurations by using a parallel\nevolutionary algorithm. The experimental analysis demonstrates that significant\nimprovements over the standard configuration can be attained in terms of power\nconsumption, with no noteworthy loss in the QoS.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.NI"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.09996v1",
    "published_date": "2025-01-17 07:26:28 UTC",
    "updated_date": "2025-01-17 07:26:28 UTC"
  },
  {
    "arxiv_id": "2501.09994v1",
    "title": "Multi-Modal Attention Networks for Enhanced Segmentation and Depth Estimation of Subsurface Defects in Pulse Thermography",
    "authors": [
      "Mohammed Salah",
      "Naoufel Werghi",
      "Davor Svetinovic",
      "Yusra Abdulrahman"
    ],
    "abstract": "AI-driven pulse thermography (PT) has become a crucial tool in\nnon-destructive testing (NDT), enabling automatic detection of hidden anomalies\nin various industrial components. Current state-of-the-art techniques feed\nsegmentation and depth estimation networks compressed PT sequences using either\nPrincipal Component Analysis (PCA) or Thermographic Signal Reconstruction\n(TSR). However, treating these two modalities independently constrains the\nperformance of PT inspection models as these representations possess\ncomplementary semantic features. To address this limitation, this work proposes\nPT-Fusion, a multi-modal attention-based fusion network that fuses both PCA and\nTSR modalities for defect segmentation and depth estimation of subsurface\ndefects in PT setups. PT-Fusion introduces novel feature fusion modules,\nEncoder Attention Fusion Gate (EAFG) and Attention Enhanced Decoding Block\n(AEDB), to fuse PCA and TSR features for enhanced segmentation and depth\nestimation of subsurface defects. In addition, a novel data augmentation\ntechnique is proposed based on random data sampling from thermographic\nsequences to alleviate the scarcity of PT datasets. The proposed method is\nbenchmarked against state-of-the-art PT inspection models, including U-Net,\nattention U-Net, and 3D-CNN on the Universit\\'e Laval IRT-PVC dataset. The\nresults demonstrate that PT-Fusion outperforms the aforementioned models in\ndefect segmentation and depth estimation accuracies with a margin of 10%.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "Pulse thermography, infrared thermography, defect segmentation,\n  multi-modal networks, attention mechanism",
    "pdf_url": "http://arxiv.org/pdf/2501.09994v1",
    "published_date": "2025-01-17 07:24:58 UTC",
    "updated_date": "2025-01-17 07:24:58 UTC"
  },
  {
    "arxiv_id": "2503.19585v1",
    "title": "A Contradiction-Centered Model for the Emergence of Swarm Intelligence",
    "authors": [
      "Wenpin Jiao"
    ],
    "abstract": "The phenomenon of emergence of swarm intelligence exists widely in nature and\nhuman society. People have been exploring the root cause of emergence of swarm\nintelligence and trying to establish general theories and models for emergence\nof swarm intelligence. However, the existing theories or models do not grasp\nthe essence of swarm intelligence, so they lack generality and are difficult to\nexplain various phenomena of emergence of swarm intelligence. In this paper, a\ncontradiction-centered model for the emergence of swarm intelligence is\nproposed, in which the internal contradictions of individuals determine their\nbehavior and properties, individuals are related and interact within the swarm\nbecause of competing and occupying environmental resources, interactions and\nswarm potential affect the internal contradictions of individuals and their\ndistribution in the swarm, and the swarm intelligence is manifested as the\nspecific distribution of individual contradictions. This model completely\nexplains the conditions, dynamics, pathways, formations and processes of the\nemergence of swarm intelligence. In order to verify the validity of this model,\nseveral swarm intelligence systems are implemented and analyzed in this paper.\nThe experimental results show that the model has good generality and can be\nused to describe the emergence of various swarm intelligence.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "21 pages, in Chinese language",
    "pdf_url": "http://arxiv.org/pdf/2503.19585v1",
    "published_date": "2025-01-17 07:05:08 UTC",
    "updated_date": "2025-01-17 07:05:08 UTC"
  },
  {
    "arxiv_id": "2501.09982v2",
    "title": "RichSpace: Enriching Text-to-Video Prompt Space via Text Embedding Interpolation",
    "authors": [
      "Yuefan Cao",
      "Chengyue Gong",
      "Xiaoyu Li",
      "Yingyu Liang",
      "Zhizhou Sha",
      "Zhenmei Shi",
      "Zhao Song"
    ],
    "abstract": "Text-to-video generation models have made impressive progress, but they still\nstruggle with generating videos with complex features. This limitation often\narises from the inability of the text encoder to produce accurate embeddings,\nwhich hinders the video generation model. In this work, we propose a novel\napproach to overcome this challenge by selecting the optimal text embedding\nthrough interpolation in the embedding space. We demonstrate that this method\nenables the video generation model to produce the desired videos. Additionally,\nwe introduce a simple algorithm using perpendicular foot embeddings and cosine\nsimilarity to identify the optimal interpolation embedding. Our findings\nhighlight the importance of accurate text embeddings and offer a pathway for\nimproving text-to-video generation performance.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.09982v2",
    "published_date": "2025-01-17 06:46:10 UTC",
    "updated_date": "2025-02-02 23:53:56 UTC"
  },
  {
    "arxiv_id": "2501.09980v1",
    "title": "Aneumo: A Large-Scale Comprehensive Synthetic Dataset of Aneurysm Hemodynamics",
    "authors": [
      "Xigui Li",
      "Yuanye Zhou",
      "Feiyang Xiao",
      "Xin Guo",
      "Yichi Zhang",
      "Chen Jiang",
      "Jianchao Ge",
      "Xiansheng Wang",
      "Qimeng Wang",
      "Taiwei Zhang",
      "Chensen Lin",
      "Yuan Cheng",
      "Yuan Qi"
    ],
    "abstract": "Intracranial aneurysm (IA) is a common cerebrovascular disease that is\nusually asymptomatic but may cause severe subarachnoid hemorrhage (SAH) if\nruptured. Although clinical practice is usually based on individual factors and\nmorphological features of the aneurysm, its pathophysiology and hemodynamic\nmechanisms remain controversial. To address the limitations of current\nresearch, this study constructed a comprehensive hemodynamic dataset of\nintracranial aneurysms. The dataset is based on 466 real aneurysm models, and\n10,000 synthetic models were generated by resection and deformation operations,\nincluding 466 aneurysm-free models and 9,534 deformed aneurysm models. The\ndataset also provides medical image-like segmentation mask files to support\ninsightful analysis. In addition, the dataset contains hemodynamic data\nmeasured at eight steady-state flow rates (0.001 to 0.004 kg/s), including\ncritical parameters such as flow velocity, pressure, and wall shear stress,\nproviding a valuable resource for investigating aneurysm pathogenesis and\nclinical prediction. This dataset will help advance the understanding of the\npathologic features and hemodynamic mechanisms of intracranial aneurysms and\nsupport in-depth research in related fields. Dataset hosted at\nhttps://github.com/Xigui-Li/Aneumo.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.09980v1",
    "published_date": "2025-01-17 06:43:03 UTC",
    "updated_date": "2025-01-17 06:43:03 UTC"
  },
  {
    "arxiv_id": "2501.09972v1",
    "title": "GVMGen: A General Video-to-Music Generation Model with Hierarchical Attentions",
    "authors": [
      "Heda Zuo",
      "Weitao You",
      "Junxian Wu",
      "Shihong Ren",
      "Pei Chen",
      "Mingxu Zhou",
      "Yujia Lu",
      "Lingyun Sun"
    ],
    "abstract": "Composing music for video is essential yet challenging, leading to a growing\ninterest in automating music generation for video applications. Existing\napproaches often struggle to achieve robust music-video correspondence and\ngenerative diversity, primarily due to inadequate feature alignment methods and\ninsufficient datasets. In this study, we present General Video-to-Music\nGeneration model (GVMGen), designed for generating high-related music to the\nvideo input. Our model employs hierarchical attentions to extract and align\nvideo features with music in both spatial and temporal dimensions, ensuring the\npreservation of pertinent features while minimizing redundancy. Remarkably, our\nmethod is versatile, capable of generating multi-style music from different\nvideo inputs, even in zero-shot scenarios. We also propose an evaluation model\nalong with two novel objective metrics for assessing video-music alignment.\nAdditionally, we have compiled a large-scale dataset comprising diverse types\nof video-music pairs. Experimental results demonstrate that GVMGen surpasses\nprevious models in terms of music-video correspondence, generative diversity,\nand application universality.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.MM",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Accepted by the 39th AAAI Conference on Artificial Intelligence\n  (AAAI-25)",
    "pdf_url": "http://arxiv.org/pdf/2501.09972v1",
    "published_date": "2025-01-17 06:30:11 UTC",
    "updated_date": "2025-01-17 06:30:11 UTC"
  },
  {
    "arxiv_id": "2501.09967v1",
    "title": "Explainable artificial intelligence (XAI): from inherent explainability to large language models",
    "authors": [
      "Fuseini Mumuni",
      "Alhassan Mumuni"
    ],
    "abstract": "Artificial Intelligence (AI) has continued to achieve tremendous success in\nrecent times. However, the decision logic of these frameworks is often not\ntransparent, making it difficult for stakeholders to understand, interpret or\nexplain their behavior. This limitation hinders trust in machine learning\nsystems and causes a general reluctance towards their adoption in practical\napplications, particularly in mission-critical domains like healthcare and\nautonomous driving. Explainable AI (XAI) techniques facilitate the\nexplainability or interpretability of machine learning models, enabling users\nto discern the basis of the decision and possibly avert undesirable behavior.\nThis comprehensive survey details the advancements of explainable AI methods,\nfrom inherently interpretable models to modern approaches for achieving\ninterpretability of various black box models, including large language models\n(LLMs). Additionally, we review explainable AI techniques that leverage LLM and\nvision-language model (VLM) frameworks to automate or improve the\nexplainability of other machine learning models. The use of LLM and VLM as\ninterpretability methods particularly enables high-level, semantically\nmeaningful explanations of model decisions and behavior. Throughout the paper,\nwe highlight the scientific principles, strengths and weaknesses of\nstate-of-the-art methods and outline different areas of improvement. Where\nappropriate, we also present qualitative and quantitative comparison results of\nvarious methods to show how they compare. Finally, we discuss the key\nchallenges of XAI and directions for future research.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.09967v1",
    "published_date": "2025-01-17 06:16:57 UTC",
    "updated_date": "2025-01-17 06:16:57 UTC"
  },
  {
    "arxiv_id": "2501.10484v1",
    "title": "Bias in Decision-Making for AI's Ethical Dilemmas: A Comparative Study of ChatGPT and Claude",
    "authors": [
      "Yile Yan",
      "Yuqi Zhu",
      "Wentao Xu"
    ],
    "abstract": "Recent advances in Large Language Models (LLMs) have enabled human-like\nresponses across various tasks, raising questions about their ethical\ndecision-making capabilities and potential biases. This study investigates\nprotected attributes in LLMs through systematic evaluation of their responses\nto ethical dilemmas. Using two prominent models - GPT-3.5 Turbo and Claude 3.5\nSonnet - we analyzed their decision-making patterns across multiple protected\nattributes including age, gender, race, appearance, and disability status.\nThrough 11,200 experimental trials involving both single-factor and two-factor\nprotected attribute combinations, we evaluated the models' ethical preferences,\nsensitivity, stability, and clustering of preferences. Our findings reveal\nsignificant protected attributeses in both models, with consistent preferences\nfor certain features (e.g., \"good-looking\") and systematic neglect of others.\nNotably, while GPT-3.5 Turbo showed stronger preferences aligned with\ntraditional power structures, Claude 3.5 Sonnet demonstrated more diverse\nprotected attribute choices. We also found that ethical sensitivity\nsignificantly decreases in more complex scenarios involving multiple protected\nattributes. Additionally, linguistic referents heavily influence the models'\nethical evaluations, as demonstrated by differing responses to racial\ndescriptors (e.g., \"Yellow\" versus \"Asian\"). These findings highlight critical\nconcerns about the potential impact of LLM biases in autonomous decision-making\nsystems and emphasize the need for careful consideration of protected\nattributes in AI development. Our study contributes to the growing body of\nresearch on AI ethics by providing a systematic framework for evaluating\nprotected attributes in LLMs' ethical decision-making capabilities.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.10484v1",
    "published_date": "2025-01-17 05:20:38 UTC",
    "updated_date": "2025-01-17 05:20:38 UTC"
  },
  {
    "arxiv_id": "2501.10483v2",
    "title": "ArxEval: Evaluating Retrieval and Generation in Language Models for Scientific Literature",
    "authors": [
      "Aarush Sinha",
      "Viraj Virk",
      "Dipshikha Chakraborty",
      "P. S. Sreeja"
    ],
    "abstract": "Language Models [LMs] are now playing an increasingly large role in\ninformation generation and synthesis; the representation of scientific\nknowledge in these systems needs to be highly accurate. A prime challenge is\nhallucination; that is, generating apparently plausible but actually false\ninformation, including invented citations and nonexistent research papers. This\nkind of inaccuracy is dangerous in all the domains that require high levels of\nfactual correctness, such as academia and education. This work presents a\npipeline for evaluating the frequency with which language models hallucinate in\ngenerating responses in the scientific literature. We propose ArxEval, an\nevaluation pipeline with two tasks using ArXiv as a repository: Jumbled Titles\nand Mixed Titles. Our evaluation includes fifteen widely used language models\nand provides comparative insights into their reliability in handling scientific\nliterature.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.10483v2",
    "published_date": "2025-01-17 05:19:24 UTC",
    "updated_date": "2025-01-22 04:17:21 UTC"
  },
  {
    "arxiv_id": "2501.09954v1",
    "title": "AIRCHITECT v2: Learning the Hardware Accelerator Design Space through Unified Representations",
    "authors": [
      "Jamin Seo",
      "Akshat Ramachandran",
      "Yu-Chuan Chuang",
      "Anirudh Itagi",
      "Tushar Krishna"
    ],
    "abstract": "Design space exploration (DSE) plays a crucial role in enabling custom\nhardware architectures, particularly for emerging applications like AI, where\noptimized and specialized designs are essential. With the growing complexity of\ndeep neural networks (DNNs) and the introduction of advanced foundational\nmodels (FMs), the design space for DNN accelerators is expanding at an\nexponential rate. Additionally, this space is highly non-uniform and\nnon-convex, making it increasingly difficult to navigate and optimize.\nTraditional DSE techniques rely on search-based methods, which involve\niterative sampling of the design space to find the optimal solution. However,\nthis process is both time-consuming and often fails to converge to the global\noptima for such design spaces. Recently, AIrchitect v1, the first attempt to\naddress the limitations of search-based techniques, transformed DSE into a\nconstant-time classification problem using recommendation networks. In this\nwork, we propose AIrchitect v2, a more accurate and generalizable\nlearning-based DSE technique applicable to large-scale design spaces that\novercomes the shortcomings of earlier approaches. Specifically, we devise an\nencoder-decoder transformer model that (a) encodes the complex design space\ninto a uniform intermediate representation using contrastive learning and (b)\nleverages a novel unified representation blending the advantages of\nclassification and regression to effectively explore the large DSE space\nwithout sacrificing accuracy. Experimental results evaluated on 10^5 real DNN\nworkloads demonstrate that, on average, AIrchitect v2 outperforms existing\ntechniques by 15% in identifying optimal design points. Furthermore, to\ndemonstrate the generalizability of our method, we evaluate performance on\nunseen model workloads (LLMs) and attain a 1.7x improvement in inference\nlatency on the identified hardware architecture.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.AR"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to DATE 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.09954v1",
    "published_date": "2025-01-17 04:57:42 UTC",
    "updated_date": "2025-01-17 04:57:42 UTC"
  },
  {
    "arxiv_id": "2501.09949v1",
    "title": "MultiPruner: Balanced Structure Removal in Foundation Models",
    "authors": [
      "J. Pablo Muñoz",
      "Jinjie Yuan",
      "Nilesh Jain"
    ],
    "abstract": "Recently, state-of-the-art approaches for pruning large pre-trained models\n(LPMs) have demonstrated that the training-free removal of non-critical\nresidual blocks in Transformers is viable for reducing model size, achieving\nresults that outperform previous training-free pruning approaches. Motivated by\nthese findings, we extend BlockPruner (Zhong et al., 2024) and propose\nMultiPruner, a pruning approach that surpasses recent training-free pruning\nmethods by adopting a multidimensional, iterative, fine-grained pruning\nstrategy. In MultiPruner, multidimensional pruning reinstates the structural\nbalance in block-pruned models by sequentially compressing along three\ndimensions: i) residual blocks, ii) channels of multilayer perceptrons (MLP),\nand iii) attention heads. This solution enhances zero-shot accuracy on\ndownstream tasks compared to other techniques while improving model compression\nratios, producing compressed models with fewer computing and memory\nrequirements. Extensive experiments demonstrate the advantages of the proposed\nmethod across various large pre-trained models. The code and pruning\nconfigurations are available at\nhttps://github.com/IntelLabs/Hardware-Aware-Automated-Machine-Learning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "I.2.0"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.09949v1",
    "published_date": "2025-01-17 04:24:31 UTC",
    "updated_date": "2025-01-17 04:24:31 UTC"
  },
  {
    "arxiv_id": "2501.09948v1",
    "title": "AI Explainability for Power Electronics: From a Lipschitz Continuity Perspective",
    "authors": [
      "Xinze Li",
      "Fanfan Lin",
      "Homer Alan Mantooth",
      "Juan José Rodríguez-Andina"
    ],
    "abstract": "Lifecycle management of power converters continues to thrive with emerging\nartificial intelligence (AI) solutions, yet AI mathematical explainability\nremains unexplored in power electronics (PE) community. The lack of theoretical\nrigor challenges adoption in mission-critical applications. Therefore, this\nletter proposes a generic framework to evaluate mathematical explainability,\nhighlighting inference stability and training convergence from a Lipschitz\ncontinuity perspective. Inference stability governs consistent outputs under\ninput perturbations, essential for robust real-time control and fault\ndiagnosis. Training convergence guarantees stable learning dynamics,\nfacilitating accurate modeling in PE contexts. Additionally, a Lipschitz-aware\nlearning rate selection strategy is introduced to accelerate convergence while\nmitigating overshoots and oscillations. The feasibility of the proposed\nLipschitz-oriented framework is demonstrated by validating the mathematical\nexplainability of a state-of-the-art physics-in-architecture neural network,\nand substantiated through empirical case studies on dual-active-bridge\nconverters. This letter serves as a clarion call for the PE community to\nembrace mathematical explainability, heralding a transformative era of\ntrustworthy and explainable AI solutions that potentially redefine the future\nof power electronics.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.SY"
    ],
    "primary_category": "eess.SY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.09948v1",
    "published_date": "2025-01-17 04:20:43 UTC",
    "updated_date": "2025-01-17 04:20:43 UTC"
  },
  {
    "arxiv_id": "2501.09946v1",
    "title": "Client-Centric Federated Adaptive Optimization",
    "authors": [
      "Jianhui Sun",
      "Xidong Wu",
      "Heng Huang",
      "Aidong Zhang"
    ],
    "abstract": "Federated Learning (FL) is a distributed learning paradigm where clients\ncollaboratively train a model while keeping their own data private. With an\nincreasing scale of clients and models, FL encounters two key challenges,\nclient drift due to a high degree of statistical/system heterogeneity, and lack\nof adaptivity. However, most existing FL research is based on unrealistic\nassumptions that virtually ignore system heterogeneity. In this paper, we\npropose Client-Centric Federated Adaptive Optimization, which is a class of\nnovel federated adaptive optimization approaches. We enable several features in\nthis framework such as arbitrary client participation, asynchronous server\naggregation, and heterogeneous local computing, which are ubiquitous in\nreal-world FL systems but are missed in most existing works. We provide a\nrigorous convergence analysis of our proposed framework for general nonconvex\nobjectives, which is shown to converge with the best-known rate. Extensive\nexperiments show that our approaches consistently outperform the baseline by a\nlarge margin across benchmarks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.09946v1",
    "published_date": "2025-01-17 04:00:50 UTC",
    "updated_date": "2025-01-17 04:00:50 UTC"
  },
  {
    "arxiv_id": "2501.12408v1",
    "title": "Control-ITRA: Controlling the Behavior of a Driving Model",
    "authors": [
      "Vasileios Lioutas",
      "Adam Scibior",
      "Matthew Niedoba",
      "Berend Zwartsenberg",
      "Frank Wood"
    ],
    "abstract": "Simulating realistic driving behavior is crucial for developing and testing\nautonomous systems in complex traffic environments. Equally important is the\nability to control the behavior of simulated agents to tailor scenarios to\nspecific research needs and safety considerations. This paper extends the\ngeneral-purpose multi-agent driving behavior model ITRA (Scibior et al., 2021),\nby introducing a method called Control-ITRA to influence agent behavior through\nwaypoint assignment and target speed modulation. By conditioning agents on\nthese two aspects, we provide a mechanism for them to adhere to specific\ntrajectories and indirectly adjust their aggressiveness. We compare different\napproaches for integrating these conditions during training and demonstrate\nthat our method can generate controllable, infraction-free trajectories while\npreserving realism in both seen and unseen locations.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.RO",
      "cs.SY",
      "eess.SY",
      "stat.ML"
    ],
    "primary_category": "cs.AI",
    "comment": "16 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.12408v1",
    "published_date": "2025-01-17 03:35:11 UTC",
    "updated_date": "2025-01-17 03:35:11 UTC"
  },
  {
    "arxiv_id": "2501.09934v1",
    "title": "HEART: Achieving Timely Multi-Model Training for Vehicle-Edge-Cloud-Integrated Hierarchical Federated Learning",
    "authors": [
      "Xiaohong Yang",
      "Minghui Liwang",
      "Xianbin Wang",
      "Zhipeng Cheng",
      "Seyyedali Hosseinalipour",
      "Huaiyu Dai",
      "Zhenzhen Jiao"
    ],
    "abstract": "The rapid growth of AI-enabled Internet of Vehicles (IoV) calls for efficient\nmachine learning (ML) solutions that can handle high vehicular mobility and\ndecentralized data. This has motivated the emergence of Hierarchical Federated\nLearning over vehicle-edge-cloud architectures (VEC-HFL). Nevertheless, one\naspect which is underexplored in the literature on VEC-HFL is that vehicles\noften need to execute multiple ML tasks simultaneously, where this multi-model\ntraining environment introduces crucial challenges. First, improper aggregation\nrules can lead to model obsolescence and prolonged training times. Second,\nvehicular mobility may result in inefficient data utilization by preventing the\nvehicles from returning their models to the network edge. Third, achieving a\nbalanced resource allocation across diverse tasks becomes of paramount\nimportance as it majorly affects the effectiveness of collaborative training.\nWe take one of the first steps towards addressing these challenges via\nproposing a framework for multi-model training in dynamic VEC-HFL with the goal\nof minimizing global training latency while ensuring balanced training across\nvarious tasks-a problem that turns out to be NP-hard. To facilitate timely\nmodel training, we introduce a hybrid synchronous-asynchronous aggregation\nrule. Building on this, we present a novel method called Hybrid Evolutionary\nAnd gReedy allocaTion (HEART). The framework operates in two stages: first, it\nachieves balanced task scheduling through a hybrid heuristic approach that\ncombines improved Particle Swarm Optimization (PSO) and Genetic Algorithms\n(GA); second, it employs a low-complexity greedy algorithm to determine the\ntraining priority of assigned tasks on vehicles. Experiments on real-world\ndatasets demonstrate the superiority of HEART over existing methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "14 pages, 6 figures,",
    "pdf_url": "http://arxiv.org/pdf/2501.09934v1",
    "published_date": "2025-01-17 03:15:03 UTC",
    "updated_date": "2025-01-17 03:15:03 UTC"
  },
  {
    "arxiv_id": "2501.09929v3",
    "title": "Interpretable Steering of Large Language Models with Feature Guided Activation Additions",
    "authors": [
      "Samuel Soo",
      "Chen Guang",
      "Wesley Teng",
      "Chandrasekaran Balaganesh",
      "Tan Guoxian",
      "Yan Ming"
    ],
    "abstract": "Effective and reliable control over large language model (LLM) behavior is a\nsignificant challenge. While activation steering methods, which add steering\nvectors to a model's hidden states, are a promising approach, existing\ntechniques often lack precision and interpretability in how they influence\nmodel outputs. We introduce Feature Guided Activation Additions (FGAA), a novel\nactivation steering method that leverages insights from Contrastive Activation\nAddition (CAA) and Sparse Autoencoder-Targeted Steering (SAE-TS). By operating\nin the latent space of a Sparse Autoencoder (SAE) and employing optimization\ntechniques to select desired SAE features, FGAA constructs precise steering\nvectors that provide better steering effects while maintaining coherence of\nsteered model outputs. In this regard, evaluations on Gemma-2-2B and Gemma-2-9B\nmodels across various steering tasks demonstrate that FGAA outperforms existing\nsteering methods of CAA, SAE decoder steering, and SAE-TS. Our results also\nhighlight important trade-offs between steering scale and general model\ncapabilities that are consistent across all tested steering methods.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "9 maintext pages, 13 appendix pages",
    "pdf_url": "http://arxiv.org/pdf/2501.09929v3",
    "published_date": "2025-01-17 02:55:23 UTC",
    "updated_date": "2025-04-02 13:20:40 UTC"
  },
  {
    "arxiv_id": "2501.09928v1",
    "title": "Dialogue Benchmark Generation from Knowledge Graphs with Cost-Effective Retrieval-Augmented LLMs",
    "authors": [
      "Reham Omar",
      "Omij Mangukiya",
      "Essam Mansour"
    ],
    "abstract": "Dialogue benchmarks are crucial in training and evaluating chatbots engaging\nin domain-specific conversations. Knowledge graphs (KGs) represent semantically\nrich and well-organized data spanning various domains, such as DBLP, DBpedia,\nand YAGO. Traditionally, dialogue benchmarks have been manually created from\ndocuments, neglecting the potential of KGs in automating this process. Some\nquestion-answering benchmarks are automatically generated using extensive\npreprocessing from KGs, but they do not support dialogue generation. This paper\nintroduces Chatty-Gen, a novel multi-stage retrieval-augmented generation\nplatform for automatically generating high-quality dialogue benchmarks tailored\nto a specific domain using a KG. Chatty-Gen decomposes the generation process\ninto manageable stages and uses assertion rules for automatic validation\nbetween stages. Our approach enables control over intermediate results to\nprevent time-consuming restarts due to hallucinations. It also reduces reliance\non costly and more powerful commercial LLMs. Chatty-Gen eliminates upfront\nprocessing of the entire KG using efficient query-based retrieval to find\nrepresentative subgraphs based on the dialogue context. Our experiments with\nseveral real and large KGs demonstrate that Chatty-Gen significantly\noutperforms state-of-the-art systems and ensures consistent model and system\nperformance across multiple LLMs of diverse capabilities, such as GPT-4o,\nGemini 1.5, Llama 3, and Mistral.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "The paper is publsihed in SIGMOD 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.09928v1",
    "published_date": "2025-01-17 02:48:29 UTC",
    "updated_date": "2025-01-17 02:48:29 UTC"
  },
  {
    "arxiv_id": "2501.09927v1",
    "title": "IE-Bench: Advancing the Measurement of Text-Driven Image Editing for Human Perception Alignment",
    "authors": [
      "Shangkun Sun",
      "Bowen Qu",
      "Xiaoyu Liang",
      "Songlin Fan",
      "Wei Gao"
    ],
    "abstract": "Recent advances in text-driven image editing have been significant, yet the\ntask of accurately evaluating these edited images continues to pose a\nconsiderable challenge. Different from the assessment of text-driven image\ngeneration, text-driven image editing is characterized by simultaneously\nconditioning on both text and a source image. The edited images often retain an\nintrinsic connection to the original image, which dynamically change with the\nsemantics of the text. However, previous methods tend to solely focus on\ntext-image alignment or have not aligned with human perception. In this work,\nwe introduce the Text-driven Image Editing Benchmark suite (IE-Bench) to\nenhance the assessment of text-driven edited images. IE-Bench includes a\ndatabase contains diverse source images, various editing prompts and the\ncorresponding results different editing methods, and total 3,010 Mean Opinion\nScores (MOS) provided by 25 human subjects. Furthermore, we introduce IE-QA, a\nmulti-modality source-aware quality assessment method for text-driven image\nediting. To the best of our knowledge, IE-Bench offers the first IQA dataset\nand model tailored for text-driven image editing. Extensive experiments\ndemonstrate IE-QA's superior subjective-alignments on the text-driven image\nediting task compared with previous metrics. We will make all related data and\ncode available to the public.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.09927v1",
    "published_date": "2025-01-17 02:47:25 UTC",
    "updated_date": "2025-01-17 02:47:25 UTC"
  },
  {
    "arxiv_id": "2501.09926v1",
    "title": "ForestProtector: An IoT Architecture Integrating Machine Vision and Deep Reinforcement Learning for Efficient Wildfire Monitoring",
    "authors": [
      "Kenneth Bonilla-Ormachea",
      "Horacio Cuizaga",
      "Edwin Salcedo",
      "Sebastian Castro",
      "Sergio Fernandez-Testa",
      "Misael Mamani"
    ],
    "abstract": "Early detection of forest fires is crucial to minimizing the environmental\nand socioeconomic damage they cause. Indeed, a fire's duration directly\ncorrelates with the difficulty and cost of extinguishing it. For instance, a\nfire burning for 1 minute might require 1 liter of water to extinguish, while a\n2-minute fire could demand 100 liters, and a 10-minute fire might necessitate\n1,000 liters. On the other hand, existing fire detection systems based on novel\ntechnologies (e.g., remote sensing, PTZ cameras, UAVs) are often expensive and\nrequire human intervention, making continuous monitoring of large areas\nimpractical. To address this challenge, this work proposes a low-cost forest\nfire detection system that utilizes a central gateway device with computer\nvision capabilities to monitor a 360{\\deg} field of view for smoke at long\ndistances. A deep reinforcement learning agent enhances surveillance by\ndynamically controlling the camera's orientation, leveraging real-time sensor\ndata (smoke levels, ambient temperature, and humidity) from distributed IoT\ndevices. This approach enables automated wildfire monitoring across expansive\nareas while reducing false positives.",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted for publication in the proceedings of the 11th International\n  Conference on Automation, Robotics, and Applications (ICARA 2025)",
    "pdf_url": "http://arxiv.org/pdf/2501.09926v1",
    "published_date": "2025-01-17 02:47:14 UTC",
    "updated_date": "2025-01-17 02:47:14 UTC"
  },
  {
    "arxiv_id": "2501.09923v1",
    "title": "Study on a Fast Solver for Combined Field Integral Equations of 3D Conducting Bodies Based on Graph Neural Networks",
    "authors": [
      "Tao Shan",
      "Xin Zhang",
      "Di Wu"
    ],
    "abstract": "In this paper, we present a graph neural networks (GNNs)-based fast solver\n(GraphSolver) for solving combined field integral equations (CFIEs) of 3D\nconducting bodies. Rao-Wilton-Glisson (RWG) basis functions are employed to\ndiscretely and accurately represent the geometry of 3D conducting bodies. A\nconcise and informative graph representation is then constructed by treating\neach RWG function as a node in the graph, enabling the flow of current between\nnodes. With the transformed graphs, GraphSolver is developed to directly\npredict real and imaginary parts of the x, y and z components of the surface\ncurrent densities at each node (RWG function). Numerical results demonstrate\nthe efficacy of GraphSolver in solving CFIEs for 3D conducting bodies with\nvarying levels of geometric complexity, including basic 3D targets,\nmissile-shaped targets, and airplane-shaped targets.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NA",
      "math.NA",
      "65M22",
      "I.2"
    ],
    "primary_category": "cs.LG",
    "comment": "10 pages,11 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.09923v1",
    "published_date": "2025-01-17 02:40:04 UTC",
    "updated_date": "2025-01-17 02:40:04 UTC"
  },
  {
    "arxiv_id": "2501.09918v1",
    "title": "GenSC-6G: A Prototype Testbed for Integrated Generative AI, Quantum, and Semantic Communication",
    "authors": [
      "Brian E. Arfeto",
      "Shehbaz Tariq",
      "Uman Khalid",
      "Trung Q. Duong",
      "Hyundong Shin"
    ],
    "abstract": "We introduce a prototyping testbed, GenSC-6G, developed to generate a\ncomprehensive dataset that supports the integration of generative artificial\nintelligence (AI), quantum computing, and semantic communication for emerging\nsixth-generation (6G) applications. The GenSC-6G dataset is designed with\nnoise-augmented synthetic data optimized for semantic decoding, classification,\nand localization tasks, significantly enhancing flexibility for diverse\nAI-driven communication applications. This adaptable prototype supports\nseamless modifications across baseline models, communication modules, and\ngoal-oriented decoders. Case studies demonstrate its application in lightweight\nclassification, semantic upsampling, and edge-based language inference under\nnoise conditions. The GenSC-6G dataset serves as a scalable and robust resource\nfor developing goal-oriented communication systems tailored to the growing\ndemands of 6G networks.",
    "categories": [
      "cs.AI",
      "eess.SP",
      "quant-ph"
    ],
    "primary_category": "cs.AI",
    "comment": "SUBMITTED FOR PUBLICATION IN IEEE COMMUNICATIONS MAGAZINE",
    "pdf_url": "http://arxiv.org/pdf/2501.09918v1",
    "published_date": "2025-01-17 02:20:52 UTC",
    "updated_date": "2025-01-17 02:20:52 UTC"
  },
  {
    "arxiv_id": "2501.09913v1",
    "title": "Towards A Litmus Test for Common Sense",
    "authors": [
      "Hugo Latapie"
    ],
    "abstract": "This paper is the second in a planned series aimed at envisioning a path to\nsafe and beneficial artificial intelligence. Building on the conceptual\ninsights of \"Common Sense Is All You Need,\" we propose a more formal litmus\ntest for common sense, adopting an axiomatic approach that combines minimal\nprior knowledge (MPK) constraints with diagonal or Godel-style arguments to\ncreate tasks beyond the agent's known concept set. We discuss how this approach\napplies to the Abstraction and Reasoning Corpus (ARC), acknowledging\ntraining/test data constraints, physical or virtual embodiment, and large\nlanguage models (LLMs). We also integrate observations regarding emergent\ndeceptive hallucinations, in which more capable AI systems may intentionally\nfabricate plausible yet misleading outputs to disguise knowledge gaps. The\noverarching theme is that scaling AI without ensuring common sense risks\nintensifying such deceptive tendencies, thereby undermining safety and trust.\nAligning with the broader goal of developing beneficial AI without causing\nharm, our axiomatic litmus test not only diagnoses whether an AI can handle\ntruly novel concepts but also provides a stepping stone toward an ethical,\nreliable foundation for future safe, beneficial, and aligned artificial\nintelligence.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.09913v1",
    "published_date": "2025-01-17 02:02:12 UTC",
    "updated_date": "2025-01-17 02:02:12 UTC"
  },
  {
    "arxiv_id": "2501.09905v4",
    "title": "SLIM: Sim-to-Real Legged Instructive Manipulation via Long-Horizon Visuomotor Learning",
    "authors": [
      "Haichao Zhang",
      "Haonan Yu",
      "Le Zhao",
      "Andrew Choi",
      "Qinxun Bai",
      "Break Yang",
      "Wei Xu"
    ],
    "abstract": "We present a low-cost legged mobile manipulation system that solves\nlong-horizon real-world tasks, trained by reinforcement learning purely in\nsimulation. This system is made possible by 1) a hierarchical design of a\nhigh-level policy for visual-mobile manipulation following task instructions,\nand a low-level quadruped locomotion policy, 2) a teacher and student training\npipeline for the high level, which trains a teacher to tackle long-horizon\ntasks using privileged task decomposition and target object information, and\nfurther trains a student for visual-mobile manipulation via RL guided by the\nteacher's behavior, and 3) a suite of techniques for minimizing the sim-to-real\ngap.\n  In contrast to many previous works that use high-end equipments, our system\ndemonstrates effective performance with more accessible hardware --\nspecifically, a Unitree Go1 quadruped, a WidowX-250S arm, and a single\nwrist-mounted RGB camera -- despite the increased challenges of sim-to-real\ntransfer. Trained fully in simulation, a single policy autonomously solves\nlong-horizon tasks involving search, move to, grasp, transport, and drop into,\nachieving nearly 80% real-world success. This performance is comparable to that\nof expert human teleoperation on the same tasks while the robot is more\nefficient, operating at about 1.5x the speed of the teleoperation. Finally, we\nperform extensive ablations on key techniques for efficient RL training and\neffective sim-to-real transfer, and demonstrate effective deployment across\ndiverse indoor and outdoor scenes under various lighting conditions.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.09905v4",
    "published_date": "2025-01-17 01:32:18 UTC",
    "updated_date": "2025-01-29 19:58:23 UTC"
  },
  {
    "arxiv_id": "2501.09891v1",
    "title": "Evolving Deeper LLM Thinking",
    "authors": [
      "Kuang-Huei Lee",
      "Ian Fischer",
      "Yueh-Hua Wu",
      "Dave Marwood",
      "Shumeet Baluja",
      "Dale Schuurmans",
      "Xinyun Chen"
    ],
    "abstract": "We explore an evolutionary search strategy for scaling inference time compute\nin Large Language Models. The proposed approach, Mind Evolution, uses a\nlanguage model to generate, recombine and refine candidate responses. The\nproposed approach avoids the need to formalize the underlying inference problem\nwhenever a solution evaluator is available. Controlling for inference cost, we\nfind that Mind Evolution significantly outperforms other inference strategies\nsuch as Best-of-N and Sequential Revision in natural language planning tasks.\nIn the TravelPlanner and Natural Plan benchmarks, Mind Evolution solves more\nthan 98% of the problem instances using Gemini 1.5 Pro without the use of a\nformal solver.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.09891v1",
    "published_date": "2025-01-17 00:41:44 UTC",
    "updated_date": "2025-01-17 00:41:44 UTC"
  },
  {
    "arxiv_id": "2501.09890v1",
    "title": "Exploring the Implementation of AI in Early Onset Interviews to Help Mitigate Bias",
    "authors": [
      "Nishka Lal",
      "Omar Benkraouda"
    ],
    "abstract": "This paper investigates the application of artificial intelligence (AI) in\nearly-stage recruitment interviews in order to reduce inherent bias,\nspecifically sentiment bias. Traditional interviewers are often subject to\nseveral biases, including interviewer bias, social desirability effects, and\neven confirmation bias. In turn, this leads to non-inclusive hiring practices,\nand a less diverse workforce. This study further analyzes various AI\ninterventions that are present in the marketplace today such as multimodal\nplatforms and interactive candidate assessment tools in order to gauge the\ncurrent market usage of AI in early-stage recruitment. However, this paper aims\nto use a unique AI system that was developed to transcribe and analyze\ninterview dynamics, which emphasize skill and knowledge over emotional\nsentiments. Results indicate that AI effectively minimizes sentiment-driven\nbiases by 41.2%, suggesting its revolutionizing power in companies' recruitment\nprocesses for improved equity and efficiency.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.09890v1",
    "published_date": "2025-01-17 00:40:35 UTC",
    "updated_date": "2025-01-17 00:40:35 UTC"
  }
]