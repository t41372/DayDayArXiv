{
  "date": "2025-03-31",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-03-31 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文更新聚焦于 AI 代理、LLM（Large Language Models）的推理优化、多模态模型应用以及 AI 在科学和医疗领域的创新，其中 “Inference-Time Scaling for Complex Tasks” 等论文因知名学者如 John Langford 的参与而引人注目；这些研究强调了 LLM 在复杂任务中的潜力、AI 安全基准，以及高效模型微调方法，突显了 AI 向更可靠和泛化方向的进展。\n\n### 重点论文讨论\n我挑选了今天最有影响力和话题度的论文进行简要分析，先从 LLM 推理和 AI 代理相关的内容入手，这些领域直接推动 AI 应用创新。其他论文如医学或特定领域的内容则快速掠过，只提核心贡献。\n\n1. **Inference-Time Scaling for Complex Tasks（推理时缩放用于复杂任务）**  \n   作者包括 Vidhisha Balachandran 和 John Langford 等知名学者。该论文调查了在九个先进模型和八个任务（如数学推理和 NP-hard 问题）中，推理时缩放（如延长生成序列）的优势和局限。关键发现是，这种方法在简单任务中提升准确性，但复杂任务效果递减；使用完美验证器可显著改善性能，揭示了未来多模型系统的潜力。\n\n2. **A Benchmark for Scalable Oversight Protocols（可扩展监督协议的基准）**  \n   该研究提出一个新基准，用于评估 AI 模型的监督机制，聚焦于人类反馈的有效性。贡献包括 Agent Score Difference (ASD) 指标和 Python 包，支持 Debate 等协议的评估；实验显示，该基准能更好地比较协议性能，推动 AI 安全和对齐研究。\n\n3. **Do Chinese models speak Chinese languages?（中文模型是否支持中文语言？）**  \n   作者如 Andrea W Wen-Yi 探讨了中文 LLM 在区域和少数民族语言（如维吾尔语）上的性能。发现这些模型与西方模型高度相关（r=0.93），但在普通话上更强；这揭示了数据优先级问题，并为未来模型开发提供指导，强调语言政策的影响。\n\n4. **SciReplicate-Bench: Benchmarking LLMs in Agent-driven Algorithmic Reproduction（SciReplicate-Bench：基于代理的算法再现的 LLM 基准）**  \n   该论文引入一个基准评估 LLM 在从论文中生成代码的能力，包括算法理解和编码专业性。贡献包括一个多代理框架（Sci-Reproducer）和新指标如推理图准确性；实验显示最佳 LLM 只达到 39% 执行准确率，突显再现挑战。\n\n5. **ElaLoRA: Elastic & Learnable Low-Rank Adaptation（ElaLoRA：弹性可学习低秩适配）**  \n   论文提出 ElaLoRA，一种动态调整模型秩的微调框架。关键发现是，它在各种基准上优于现有 PEFT 方法，并证明高秩层对性能贡献更大；这为资源受限环境提供高效微调解决方案。\n\n6. **Large Language Models in Numberland: A Quick Test of Their Numerical Reasoning Abilities（大语言模型在数字领域：数值推理能力的快速测试）**  \n   该研究测试 LLM 在数值任务（如运算和质数检查）上的性能。发现 LLM 在确定性任务中得分 74-95%，但在试错任务如 24 游戏中降至 10-73%；这暴露了 LLM 数值推理的脆弱性，强调改进搜索能力的必要性。\n\n其他论文如 “MultiMorph: On-demand Atlas Construction（MultiMorph：按需图集构建）” 和 “JudgeLRM: Large Reasoning Models as a Judge（JudgeLRM：大推理模型作为评判者）” 也值得一提，前者使用前馈模型快速生成脑部图集，显著减少计算时间；后者通过强化学习训练判断模型，提升了 LLM 在推理任务中的性能。\n\n对于较次要的论文，如一些纯理论或小众领域（如特定数据库优化或小规模实验），我仅快速提及：例如 “RailGoerl24: Görlitz Rail Test Center CV Dataset（RailGoerl24：铁路测试数据集）” 提供新数据集支持铁路障碍检测，但影响有限；“Towards Scientific Intelligence（科学智能方向）” 则是一篇综述，概述 AI 代理在科学中的应用，但缺乏新发现。\n\n总之，今天的更新突显了 AI 社区在 LLM 推理和代理构建上的进展，相关论文为未来应用提供了实际指导，但也暴露了安全和泛化挑战。更多细节可查阅 arXiv！",
  "papers": [
    {
      "arxiv_id": "2504.00294v1",
      "title": "Inference-Time Scaling for Complex Tasks: Where We Stand and What Lies Ahead",
      "title_zh": "复杂任务的推理时缩放：现状与未来展望",
      "authors": [
        "Vidhisha Balachandran",
        "Jingya Chen",
        "Lingjiao Chen",
        "Shivam Garg",
        "Neel Joshi",
        "Yash Lara",
        "John Langford",
        "Besmira Nushi",
        "Vibhav Vineet",
        "Yue Wu",
        "Safoora Yousefi"
      ],
      "abstract": "Inference-time scaling can enhance the reasoning capabilities of large\nlanguage models (LLMs) on complex problems that benefit from step-by-step\nproblem solving. Although lengthening generated scratchpads has proven\neffective for mathematical tasks, the broader impact of this approach on other\ntasks remains less clear. In this work, we investigate the benefits and\nlimitations of scaling methods across nine state-of-the-art models and eight\nchallenging tasks, including math and STEM reasoning, calendar planning,\nNP-hard problems, navigation, and spatial reasoning. We compare conventional\nmodels (e.g., GPT-4o) with models fine-tuned for inference-time scaling (e.g.,\no1) through evaluation protocols that involve repeated model calls, either\nindependently or sequentially with feedback. These evaluations approximate\nlower and upper performance bounds and potential for future performance\nimprovements for each model, whether through enhanced training or multi-model\ninference systems. Our extensive empirical analysis reveals that the advantages\nof inference-time scaling vary across tasks and diminish as problem complexity\nincreases. In addition, simply using more tokens does not necessarily translate\nto higher accuracy in these challenging regimes. Results from multiple\nindependent runs with conventional models using perfect verifiers show that,\nfor some tasks, these models can achieve performance close to the average\nperformance of today's most advanced reasoning models. However, for other\ntasks, a significant performance gap remains, even in very high scaling\nregimes. Encouragingly, all models demonstrate significant gains when inference\nis further scaled with perfect verifiers or strong feedback, suggesting ample\npotential for future improvements.",
      "tldr_zh": "这篇论文探讨了推理时缩放（inference-time scaling）如何提升大型语言模型（LLMs）在复杂任务上的推理能力，特别是通过扩展生成的scratchpads来支持逐步问题解决。研究者评估了9个最先进模型（如GPT-4o和o1）在8个挑战任务中的表现，包括数学推理、STEM问题、NP-hard问题、导航和空间推理，并使用重复模型调用和反馈机制来比较独立与顺序处理。结果显示，这种缩放方法的优势因任务而异，随着问题复杂性增加而减弱，且简单增加tokens并不总能提高准确率；然而，所有模型在使用完美verifiers或强反馈时均有显著提升，暗示未来通过增强训练或多模型系统可实现更大潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "I.2"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.00294v1",
      "published_date": "2025-03-31 23:40:28 UTC",
      "updated_date": "2025-03-31 23:40:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:46:20.716322"
    },
    {
      "arxiv_id": "2504.03731v1",
      "title": "A Benchmark for Scalable Oversight Protocols",
      "title_zh": "翻译失败",
      "authors": [
        "Abhimanyu Pallavi Sudhir",
        "Jackson Kaunismaa",
        "Arjun Panickssery"
      ],
      "abstract": "As AI agents surpass human capabilities, scalable oversight -- the problem of\neffectively supplying human feedback to potentially superhuman AI models --\nbecomes increasingly critical to ensure alignment. While numerous scalable\noversight protocols have been proposed, they lack a systematic empirical\nframework to evaluate and compare them. While recent works have tried to\nempirically study scalable oversight protocols -- particularly Debate -- we\nargue that the experiments they conduct are not generalizable to other\nprotocols. We introduce the scalable oversight benchmark, a principled\nframework for evaluating human feedback mechanisms based on our agent score\ndifference (ASD) metric, a measure of how effectively a mechanism advantages\ntruth-telling over deception. We supply a Python package to facilitate rapid\nand competitive evaluation of scalable oversight protocols on our benchmark,\nand conduct a demonstrative experiment benchmarking Debate.",
      "tldr_zh": "随着 AI 代理超越人类能力，可扩展监督（scalable oversight）变得至关重要，用于有效提供人类反馈以确保 AI 对齐（alignment）。本文引入了一个可扩展监督基准框架，基于代理分数差异（ASD）指标来评估反馈机制如何使诚实（truth-telling）优于欺骗（deception），并提供 Python 包以便快速评估和比较不同协议。通过演示实验，我们基准测试了 Debate 协议，展示了该框架的实用性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at the ICLR 2025 Workshop on Bidirectional Human-AI\n  Alignment (BiAlign)",
      "pdf_url": "http://arxiv.org/pdf/2504.03731v1",
      "published_date": "2025-03-31 23:32:59 UTC",
      "updated_date": "2025-03-31 23:32:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:46:31.734935"
    },
    {
      "arxiv_id": "2504.00289v2",
      "title": "Do Chinese models speak Chinese languages?",
      "title_zh": "翻译失败",
      "authors": [
        "Andrea W Wen-Yi",
        "Unso Eun Seo Jo",
        "David Mimno"
      ],
      "abstract": "The release of top-performing open-weight LLMs has cemented China's role as a\nleading force in AI development. Do these models support languages spoken in\nChina? Or do they speak the same languages as Western models? Comparing\nmultilingual capabilities is important for two reasons. First, language ability\nprovides insights into pre-training data curation, and thus into resource\nallocation and development priorities. Second, China has a long history of\nexplicit language policy, varying between inclusivity of minority languages and\na Mandarin-first policy. To test whether Chinese LLMs today reflect an agenda\nabout China's languages, we test performance of Chinese and Western open-source\nLLMs on Asian regional and Chinese minority languages. Our experiments on\nInformation Parity and reading comprehension show Chinese models' performance\nacross these languages correlates strongly (r=0.93) with Western models', with\nthe sole exception being better Mandarin. Sometimes, Chinese models cannot\nidentify languages spoken by Chinese minorities such as Kazakh and Uyghur, even\nthough they are good at French and German. These results provide a window into\ncurrent development priorities, suggest options for future development, and\nindicate guidance for end users.",
      "tldr_zh": "本研究调查了中国开源大型语言模型（LLMs）是否支持中国各种语言，包括区域语言和中国少数民族语言，并与西方模型进行比较。研究者通过信息平价（Information Parity）和阅读理解测试，发现中国LLMs的表现与西方模型高度相关（r=0.93），仅在普通话上表现出色，但往往无法识别如哈萨克语和维吾尔语等中国少数民族语言，尽管它们擅长法语和德语。这些结果揭示了LLMs预训练数据分配的优先级，并为未来模型开发和用户应用提供指导建议。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "First and second author contribute equally",
      "pdf_url": "http://arxiv.org/pdf/2504.00289v2",
      "published_date": "2025-03-31 23:19:08 UTC",
      "updated_date": "2025-04-07 19:09:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:46:43.669058"
    },
    {
      "arxiv_id": "2504.00286v1",
      "title": "Digital Twins in Biopharmaceutical Manufacturing: Review and Perspective on Human-Machine Collaborative Intelligence",
      "title_zh": "翻译失败",
      "authors": [
        "Mohammed Aatif Shahab",
        "Francesco Destro",
        "Richard D. Braatz"
      ],
      "abstract": "The biopharmaceutical industry is increasingly developing digital twins to\ndigitalize and automate the manufacturing process in response to the growing\nmarket demands. However, this shift presents significant challenges for human\noperators, as the complexity and volume of information can overwhelm their\nability to manage the process effectively. These issues are compounded when\ndigital twins are designed without considering interaction and collaboration\nwith operators, who are responsible for monitoring processes and assessing\nsituations, particularly during abnormalities. Our review of current trends in\nbiopharma digital twin development reveals a predominant focus on technology\nand often overlooks the critical role of human operators. To bridge this gap,\nthis article proposes a collaborative intelligence framework that emphasizes\nthe integration of operators with digital twins. Approaches to system design\nthat can enhance operator trust and human-machine interface usability are\npresented. Moreover, innovative training programs for preparing operators to\nunderstand and utilize digital twins are discussed. The framework outlined in\nthis article aims to enhance collaboration between operators and digital twins\neffectively by using their full capabilities to boost resilience and\nproductivity in biopharmaceutical manufacturing.",
      "tldr_zh": "本综述文章探讨了数字孪生（Digital Twins）在生物制药制造中的应用，强调了其在应对市场需求时的数字化和自动化潜力，但也指出了信息复杂度对人类操作员的挑战，导致过程管理困难。文章提出一个协作智能框架（Human-Machine Collaborative Intelligence），旨在将操作员与数字孪生系统整合，提升人机互动的信任和界面可用性。框架还包括创新培训程序，帮助操作员更好地理解和利用数字孪生，最终提升生物制药制造的韧性和生产力。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.00286v1",
      "published_date": "2025-03-31 23:13:54 UTC",
      "updated_date": "2025-03-31 23:13:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:46:54.875102"
    },
    {
      "arxiv_id": "2504.00280v1",
      "title": "Exploration and Adaptation in Non-Stationary Tasks with Diffusion Policies",
      "title_zh": "翻译失败",
      "authors": [
        "Gunbir Singh Baveja"
      ],
      "abstract": "This paper investigates the application of Diffusion Policy in\nnon-stationary, vision-based RL settings, specifically targeting environments\nwhere task dynamics and objectives evolve over time. Our work is grounded in\npractical challenges encountered in dynamic real-world scenarios such as\nrobotics assembly lines and autonomous navigation, where agents must adapt\ncontrol strategies from high-dimensional visual inputs. We apply Diffusion\nPolicy -- which leverages iterative stochastic denoising to refine latent\naction representations-to benchmark environments including Procgen and\nPointMaze. Our experiments demonstrate that, despite increased computational\ndemands, Diffusion Policy consistently outperforms standard RL methods such as\nPPO and DQN, achieving higher mean and maximum rewards with reduced\nvariability. These findings underscore the approach's capability to generate\ncoherent, contextually relevant action sequences in continuously shifting\nconditions, while also highlighting areas for further improvement in handling\nextreme non-stationarity.",
      "tldr_zh": "本研究探讨了 Diffusion Policy 在非平稳（non-stationary）视觉强化学习（RL）环境中的应用，针对任务动态和目标随时间变化的场景，如机器人装配线和自主导航。方法利用 Diffusion Policy 通过迭代随机去噪来提炼高维视觉输入的潜在动作表示，并在 Procgen 和 PointMaze 等基准环境中进行测试。实验结果显示，Diffusion Policy 相较于标准 RL 方法如 PPO 和 DQN，实现了更高的平均和最大奖励，并降低了变异性，证明其在不断变化条件下生成连贯动作序列的能力。最后，该方法突显了处理动态任务的潜力，但也指出了在极端非平稳性方面需进一步改进。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "7 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2504.00280v1",
      "published_date": "2025-03-31 23:00:07 UTC",
      "updated_date": "2025-03-31 23:00:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:47:07.175812"
    },
    {
      "arxiv_id": "2504.00277v1",
      "title": "Rack Position Optimization in Large-Scale Heterogeneous Data Centers",
      "title_zh": "翻译失败",
      "authors": [
        "Chang-Lin Chen",
        "Jiayu Chen",
        "Tian Lan",
        "Zhaoxia Zhao",
        "Hongbo Dong",
        "Vaneet Aggarwal"
      ],
      "abstract": "As rapidly growing AI computational demands accelerate the need for new\nhardware installation and maintenance, this work explores optimal data center\nresource management by balancing operational efficiency with fault tolerance\nthrough strategic rack positioning considering diverse resources and locations.\nTraditional mixed-integer programming (MIP) approaches often struggle with\nscalability, while heuristic methods may result in significant sub-optimality.\nTo address these issues, this paper presents a novel two-tier optimization\nframework using a high-level deep reinforcement learning (DRL) model to guide a\nlow-level gradient-based heuristic for local search. The high-level DRL agent\nemploys Leader Reward for optimal rack type ordering, and the low-level\nheuristic efficiently maps racks to positions, minimizing movement counts and\nensuring fault-tolerant resource distribution. This approach allows scalability\nto over 100,000 positions and 100 rack types. Our method outperformed the\ngradient-based heuristic by 7\\% on average and the MIP solver by over 30\\% in\nobjective value. It achieved a 100\\% success rate versus MIP's 97.5\\% (within a\n20-minute limit), completing in just 2 minutes compared to MIP's 1630 minutes\n(i.e., almost 4 orders of magnitude improvement). Unlike the MIP solver, which\nshowed performance variability under time constraints and high penalties, our\nalgorithm consistently delivered stable, efficient results - an essential\nfeature for large-scale data center management.",
      "tldr_zh": "该研究针对大型异构数据中心，提出了一种优化机架位置的策略，以平衡操作效率和容错性，解决传统 mixed-integer programming (MIP) 的可扩展性问题和启发式方法的次优性。论文引入了一个两层优化框架：高层使用 deep reinforcement learning (DRL) 模型（结合 Leader Reward）来指导机架类型顺序，低层采用基于梯度的启发式搜索来高效映射机架位置，从而最小化移动次数并确保资源分布的容错性。该方法支持超过10万个位置和100种机架类型，实验显示其在目标值上比启发式方法平均高出7%、比MIP求解器高出30%以上，同时实现100%的成功率和运行时间从1630分钟降至2分钟，提供更稳定且高效的解决方案。",
      "categories": [
        "cs.AI",
        "cs.DC",
        "cs.LG",
        "cs.NI",
        "math.OC"
      ],
      "primary_category": "cs.AI",
      "comment": "Extended version of paper accepted at The International Conference on\n  Automated Planning and Scheduling (ICAPS) 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.00277v1",
      "published_date": "2025-03-31 22:55:37 UTC",
      "updated_date": "2025-03-31 22:55:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:47:20.528184"
    },
    {
      "arxiv_id": "2504.00255v1",
      "title": "SciReplicate-Bench: Benchmarking LLMs in Agent-driven Algorithmic Reproduction from Research Papers",
      "title_zh": "翻译失败",
      "authors": [
        "Yanzheng Xiang",
        "Hanqi Yan",
        "Shuyin Ouyang",
        "Lin Gui",
        "Yulan He"
      ],
      "abstract": "This study evaluates large language models (LLMs) in generating code from\nalgorithm descriptions from recent NLP papers. The task requires two key\ncompetencies: (1) algorithm comprehension: synthesizing information from papers\nand academic literature to understand implementation logic, and (2) coding\nexpertise: identifying dependencies and correctly implementing necessary APIs.\nTo facilitate rigorous evaluation, we introduce SciReplicate-Bench, a benchmark\nof 100 tasks from 36 NLP papers published in 2024, featuring detailed\nannotations and comprehensive test cases. Building on SciReplicate-Bench, we\npropose Sci-Reproducer, a multi-agent framework consisting of a Paper Agent\nthat interprets algorithmic concepts from literature and a Code Agent that\nretrieves dependencies from repositories and implement solutions. To assess\nalgorithm understanding, we introduce reasoning graph accuracy, which\nquantifies similarity between generated and reference reasoning graphs derived\nfrom code comments and structure. For evaluating implementation quality, we\nemploy execution accuracy, CodeBLEU, and repository dependency/API recall\nmetrics. In our experiments, we evaluate various powerful Non-Reasoning LLMs\nand Reasoning LLMs as foundational models. The best-performing LLM using\nSci-Reproducer achieves only 39% execution accuracy, highlighting the\nbenchmark's difficulty.Our analysis identifies missing or inconsistent\nalgorithm descriptions as key barriers to successful reproduction. We will\nopen-source our benchmark, and code at\nhttps://github.com/xyzCS/SciReplicate-Bench.",
      "tldr_zh": "本研究评估大型语言模型 (LLMs) 从 NLP 论文算法描述中生成代码的能力，焦点在于算法理解和编码专业知识两方面。研究者引入 SciReplicate-Bench 基准，该基准包含 100 个任务来自 36 篇 2024 年 NLP 论文，并提出 Sci-Reproducer 多智能体框架，包括 Paper Agent 解读算法概念和 Code Agent 检索依赖项实现解决方案。评估指标涵盖推理图准确性、执行准确性、CodeBLEU 和仓库依赖/API 召回，实验显示最佳 LLMs 仅达到 39% 执行准确性，突显基准难度。分析发现，算法描述的缺失或不一致是成功再现的主要障碍。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.MA",
        "cs.SE"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.00255v1",
      "published_date": "2025-03-31 22:02:24 UTC",
      "updated_date": "2025-03-31 22:02:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:47:32.753322"
    },
    {
      "arxiv_id": "2504.00254v1",
      "title": "ElaLoRA: Elastic & Learnable Low-Rank Adaptation for Efficient Model Fine-Tuning",
      "title_zh": "Ela",
      "authors": [
        "Huandong Chang",
        "Zicheng Ma",
        "Mingyuan Ma",
        "Zhenting Qi",
        "Andrew Sabot",
        "Hong Jiang",
        "H. T. Kung"
      ],
      "abstract": "Low-Rank Adaptation (LoRA) has become a widely adopted technique for\nfine-tuning large-scale pre-trained models with minimal parameter updates.\nHowever, existing methods rely on fixed ranks or focus solely on either rank\npruning or expansion, failing to adapt ranks dynamically to match the\nimportance of different layers during training. In this work, we propose\nElaLoRA, an adaptive low-rank adaptation framework that dynamically prunes and\nexpands ranks based on gradient-derived importance scores. To the best of our\nknowledge, ElaLoRA is the first method that enables both rank pruning and\nexpansion during fine-tuning. Experiments across multiple benchmarks\ndemonstrate that ElaLoRA consistently outperforms existing PEFT methods across\ndifferent parameter budgets. Furthermore, our studies validate that layers\nreceiving higher rank allocations contribute more significantly to model\nperformance, providing theoretical justification for our adaptive strategy. By\nintroducing a principled and adaptive rank allocation mechanism, ElaLoRA offers\na scalable and efficient fine-tuning solution, particularly suited for\nresource-constrained environments.",
      "tldr_zh": "本研究提出 ElaLoRA，一种弹性且可学习的 Low-Rank Adaptation (LoRA) 框架，用于高效模型微调，通过基于梯度派生的重要性分数动态修剪和扩展秩，以适应不同层的重要性。不同于现有方法仅依赖固定秩或单一操作，ElaLoRA 是首个同时支持秩修剪与扩展的方案。实验结果显示，ElaLoRA 在多个基准测试中超越现有 PEFT 方法，在不同参数预算下表现更优，并证实分配更高秩的层对模型性能贡献更大，提供资源受限环境下的可扩展微调解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.00254v1",
      "published_date": "2025-03-31 21:58:25 UTC",
      "updated_date": "2025-03-31 21:58:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:47:43.523626"
    },
    {
      "arxiv_id": "2504.01994v1",
      "title": "PIM-LLM: A High-Throughput Hybrid PIM Architecture for 1-bit LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Jinendra Malekar",
        "Peyton Chandarana",
        "Md Hasibul Amin",
        "Mohammed E. Elbtity",
        "Ramtin Zand"
      ],
      "abstract": "In this paper, we propose PIM-LLM, a hybrid architecture developed to\naccelerate 1-bit large language models (LLMs). PIM-LLM leverages analog\nprocessing-in-memory (PIM) architectures and digital systolic arrays to\naccelerate low-precision matrix multiplication (MatMul) operations in\nprojection layers and high-precision MatMul operations in attention heads of\n1-bit LLMs, respectively. Our design achieves up to roughly 80x improvement in\ntokens per second and a 70% increase in tokens per joule compared to\nconventional hardware accelerators. Additionally, PIM-LLM outperforms previous\nPIM-based LLM accelerators, setting a new benchmark with at least 2x and 5x\nimprovement in GOPS and GOPS/W, respectively.",
      "tldr_zh": "本论文提出 PIM-LLM，一种高吞吐量混合架构，旨在加速 1-bit LLMs 的处理。PIM-LLM 利用 analog processing-in-memory (PIM) 架构加速 projection layers 中的低精度 matrix multiplication (MatMul) 操作，并采用 digital systolic arrays 处理 attention heads 中的高精度 MatMul 操作。与传统硬件加速器相比，该设计实现了约 80x tokens per second 的提升和 70% tokens per joule 的增加；此外，它超过了之前的 PIM-based LLM 加速器，在 GOPS 和 GOPS/W 上至少提高了 2x 和 5x。",
      "categories": [
        "cs.AR",
        "cs.AI"
      ],
      "primary_category": "cs.AR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.01994v1",
      "published_date": "2025-03-31 21:42:43 UTC",
      "updated_date": "2025-03-31 21:42:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:47:56.803817"
    },
    {
      "arxiv_id": "2504.00247v1",
      "title": "MultiMorph: On-demand Atlas Construction",
      "title_zh": "MultiMorph：按需图谱构建",
      "authors": [
        "S. Mazdak Abulnaga",
        "Andrew Hoopes",
        "Neel Dey",
        "Malte Hoffmann",
        "Marianne Rakic",
        "Bruce Fischl",
        "John Guttag",
        "Adrian Dalca"
      ],
      "abstract": "We present MultiMorph, a fast and efficient method for constructing\nanatomical atlases on the fly. Atlases capture the canonical structure of a\ncollection of images and are essential for quantifying anatomical variability\nacross populations. However, current atlas construction methods often require\ndays to weeks of computation, thereby discouraging rapid experimentation. As a\nresult, many scientific studies rely on suboptimal, precomputed atlases from\nmismatched populations, negatively impacting downstream analyses. MultiMorph\naddresses these challenges with a feedforward model that rapidly produces\nhigh-quality, population-specific atlases in a single forward pass for any 3D\nbrain dataset, without any fine-tuning or optimization. MultiMorph is based on\na linear group-interaction layer that aggregates and shares features within the\ngroup of input images. Further, by leveraging auxiliary synthetic data,\nMultiMorph generalizes to new imaging modalities and population groups at\ntest-time. Experimentally, MultiMorph outperforms state-of-the-art\noptimization-based and learning-based atlas construction methods in both small\nand large population settings, with a 100-fold reduction in time. This makes\nMultiMorph an accessible framework for biomedical researchers without machine\nlearning expertise, enabling rapid, high-quality atlas generation for diverse\nstudies.",
      "tldr_zh": "本研究引入MultiMorph，一种快速高效的方法，用于即时构建解剖学图谱，以捕捉图像集合的典型结构并量化人群间的解剖变异性。MultiMorph采用feedforward model和线性群组交互层（linear group-interaction layer），通过聚合输入图像特征并利用辅助合成数据，实现无需微调或优化的单次前向传递生成高质量、特定人群图谱。实验显示，MultiMorph在小和大人群设置中优于现有优化和学习方法，计算时间减少100倍，从而为缺乏机器学习专长的生物医学研究者提供便捷工具，支持多样化研究的快速图谱生成。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "accepted to CVPR 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.00247v1",
      "published_date": "2025-03-31 21:35:24 UTC",
      "updated_date": "2025-03-31 21:35:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:48:07.605249"
    },
    {
      "arxiv_id": "2504.00241v1",
      "title": "Synthesizing Public Opinions with LLMs: Role Creation, Impacts, and the Future to eDemorcacy",
      "title_zh": "翻译失败",
      "authors": [
        "Rabimba Karanjai",
        "Boris Shor",
        "Amanda Austin",
        "Ryan Kennedy",
        "Yang Lu",
        "Lei Xu",
        "Weidong Shi"
      ],
      "abstract": "This paper investigates the use of Large Language Models (LLMs) to synthesize\npublic opinion data, addressing challenges in traditional survey methods like\ndeclining response rates and non-response bias. We introduce a novel technique:\nrole creation based on knowledge injection, a form of in-context learning that\nleverages RAG and specified personality profiles from the HEXACO model and\ndemographic information, and uses that for dynamically generated prompts. This\nmethod allows LLMs to simulate diverse opinions more accurately than existing\nprompt engineering approaches. We compare our results with pre-trained models\nwith standard few-shot prompts. Experiments using questions from the\nCooperative Election Study (CES) demonstrate that our role-creation approach\nsignificantly improves the alignment of LLM-generated opinions with real-world\nhuman survey responses, increasing answer adherence. In addition, we discuss\nchallenges, limitations and future research directions.",
      "tldr_zh": "这篇论文探讨了使用Large Language Models (LLMs)合成公众意见数据，以解决传统调查方法的挑战，如响应率下降和非响应偏差。研究引入了一种基于知识注入的角色创建技术，通过in-context learning结合RAG、HEXACO模型的个性配置文件和人口统计信息，生成动态提示，从而使LLMs更准确地模拟多样化意见。实验使用Cooperative Election Study (CES)的问题进行比较，结果显示该方法显著提高了LLM生成意见与真实人类调查响应的匹配度。论文还讨论了潜在挑战、限制以及对eDemocracy未来的研究方向。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.00241v1",
      "published_date": "2025-03-31 21:21:52 UTC",
      "updated_date": "2025-03-31 21:21:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:48:19.944954"
    },
    {
      "arxiv_id": "2504.00226v1",
      "title": "Large Language Models in Numberland: A Quick Test of Their Numerical Reasoning Abilities",
      "title_zh": "翻译失败",
      "authors": [
        "Roussel Rahman"
      ],
      "abstract": "An essential element of human mathematical reasoning is our number sense --\nan abstract understanding of numbers and their relationships -- which allows us\nto solve problems involving vast number spaces using limited computational\nresources. Mathematical reasoning of Large Language Models (LLMs) is often\ntested on high-level problems (such as Olympiad challenges, geometry, word\nproblems, and puzzles), but their low-level number sense remains less explored.\nWe introduce \"Numberland,\" a 100-problem test to evaluate the numerical\nreasoning abilities of LLM-based agents. The tasks -- basic operations,\nadvanced calculations (e.g., exponentiation, complex numbers), prime number\nchecks, and the 24 game -- aim to test elementary skills and their integration\nin solving complex and uncertain problems. We evaluated five LLM-based agents:\nOpenAI's o1 and o1-mini, Google Gemini, Microsoft Copilot, and Anthropic\nClaude. They scored 74-95% on the first three tasks that allow deterministic\nsteps to solutions. In the 24 game, which needs trial-and-error search,\nperformance dropped to 10-73%. We tested the top 24 solver (o1 with 73%\naccuracy) on 25 harder problems, and its score fell to 27%, confirming search\nas a bottleneck. These results, along with the types of mistakes, suggest a\nfragile number of LLMs, which is a bit surprising given their prowess in\nchallenging benchmarks. The limits of LLM numerical reasoning highlight the\nscope of simple, targeted tests to evaluate and explain LLM math skills to\nensure safe use.",
      "tldr_zh": "本研究引入了“Numberland”测试套件，该套件包含100个问题，用于评估大型语言模型（LLMs）的数值推理能力，包括基本运算、高级计算（如指数运算和复数）、质数检查以及需要试错搜索的24 game。研究评估了五种LLM代理（OpenAI的o1和o1-mini、Google Gemini、Microsoft Copilot以及Anthropic Claude），结果显示它们在确定性任务上得分74-95%，但在24 game等不确定性任务上表现下降至10-73%。进一步测试表明，最佳模型o1在更难问题上准确率跌至27%，突显搜索能力作为瓶颈，这揭示了LLMs数值推理的脆弱性，并强调通过简单测试来评估和确保其数学技能的安全应用。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.00226v1",
      "published_date": "2025-03-31 21:06:39 UTC",
      "updated_date": "2025-03-31 21:06:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:48:31.403134"
    },
    {
      "arxiv_id": "2504.00221v1",
      "title": "GazeLLM: Multimodal LLMs incorporating Human Visual Attention",
      "title_zh": "翻译失败",
      "authors": [
        "Jun Rekimoto"
      ],
      "abstract": "Large Language Models (LLMs) are advancing into Multimodal LLMs (MLLMs),\ncapable of processing image, audio, and video as well as text. Combining\nfirst-person video, MLLMs show promising potential for understanding human\nactivities through video and audio, enabling many human-computer interaction\nand human-augmentation applications such as human activity support, real-world\nagents, and skill transfer to robots or other individuals. However, handling\nhigh-resolution, long-duration videos generates large latent representations,\nleading to substantial memory and processing demands, limiting the length and\nresolution MLLMs can manage. Reducing video resolution can lower memory usage\nbut often compromises comprehension. This paper introduces a method that\noptimizes first-person video analysis by integrating eye-tracking data, and\nproposes a method that decomposes first-person vision video into sub areas for\nregions of gaze focus. By processing these selectively gazed-focused inputs,\nour approach achieves task comprehension equivalent to or even better than\nprocessing the entire image at full resolution, but with significantly reduced\nvideo data input (reduce the number of pixels to one-tenth), offering an\nefficient solution for using MLLMs to interpret and utilize human skills.",
      "tldr_zh": "该论文提出GazeLLM，一种整合人类视觉注意力的Multimodal LLMs (MLLMs)，旨在优化第一人称视频分析以减少内存和处理需求。方法通过眼动追踪数据将视频分解为注视焦点区域，仅处理这些子区域，从而将像素输入减少到十分之一，同时保持或提升任务理解能力。实验结果显示，这种高效策略支持MLLMs在人机交互和技能转移等应用中更好地解释人类活动，为高分辨率视频处理提供可行的解决方案。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.00221v1",
      "published_date": "2025-03-31 20:50:04 UTC",
      "updated_date": "2025-03-31 20:50:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:48:43.343028"
    },
    {
      "arxiv_id": "2504.00220v1",
      "title": "Can Diffusion Models Disentangle? A Theoretical Perspective",
      "title_zh": "翻译失败",
      "authors": [
        "Liming Wang",
        "Muhammad Jehanzeb Mirza",
        "Yishu Gong",
        "Yuan Gong",
        "Jiaqi Zhang",
        "Brian H. Tracey",
        "Katerina Placek",
        "Marco Vilela",
        "James R. Glass"
      ],
      "abstract": "This paper presents a novel theoretical framework for understanding how\ndiffusion models can learn disentangled representations. Within this framework,\nwe establish identifiability conditions for general disentangled latent\nvariable models, analyze training dynamics, and derive sample complexity bounds\nfor disentangled latent subspace models. To validate our theory, we conduct\ndisentanglement experiments across diverse tasks and modalities, including\nsubspace recovery in latent subspace Gaussian mixture models, image\ncolorization, image denoising, and voice conversion for speech classification.\nAdditionally, our experiments show that training strategies inspired by our\ntheory, such as style guidance regularization, consistently enhance\ndisentanglement performance.",
      "tldr_zh": "这篇论文从理论角度探讨了扩散模型（diffusion models）是否能学习解缠表示（disentangled representations），并提出一个新颖的理论框架。论文建立了解缠潜在变量模型的一般identifiability conditions，分析了训练动态，并导出了解缠潜在子空间模型的sample complexity bounds。通过实验验证，包括子空间恢复、图像着色、图像去噪和语音转换任务，研究者证明了理论的有效性。此外，基于理论的训练策略，如style guidance regularization，能够一致地提升解缠性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.00220v1",
      "published_date": "2025-03-31 20:46:18 UTC",
      "updated_date": "2025-03-31 20:46:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:48:54.834119"
    },
    {
      "arxiv_id": "2504.00218v1",
      "title": "$\\textit{Agents Under Siege}$: Breaking Pragmatic Multi-Agent LLM Systems with Optimized Prompt Attacks",
      "title_zh": "翻译失败",
      "authors": [
        "Rana Muhammad Shahroz Khan",
        "Zhen Tan",
        "Sukwon Yun",
        "Charles Flemming",
        "Tianlong Chen"
      ],
      "abstract": "Most discussions about Large Language Model (LLM) safety have focused on\nsingle-agent settings but multi-agent LLM systems now create novel adversarial\nrisks because their behavior depends on communication between agents and\ndecentralized reasoning. In this work, we innovatively focus on attacking\npragmatic systems that have constrains such as limited token bandwidth, latency\nbetween message delivery, and defense mechanisms. We design a\n$\\textit{permutation-invariant adversarial attack}$ that optimizes prompt\ndistribution across latency and bandwidth-constraint network topologies to\nbypass distributed safety mechanisms within the system. Formulating the attack\npath as a problem of $\\textit{maximum-flow minimum-cost}$, coupled with the\nnovel $\\textit{Permutation-Invariant Evasion Loss (PIEL)}$, we leverage\ngraph-based optimization to maximize attack success rate while minimizing\ndetection risk. Evaluating across models including $\\texttt{Llama}$,\n$\\texttt{Mistral}$, $\\texttt{Gemma}$, $\\texttt{DeepSeek}$ and other variants on\nvarious datasets like $\\texttt{JailBreakBench}$ and\n$\\texttt{AdversarialBench}$, our method outperforms conventional attacks by up\nto $7\\times$, exposing critical vulnerabilities in multi-agent systems.\nMoreover, we demonstrate that existing defenses, including variants of\n$\\texttt{Llama-Guard}$ and $\\texttt{PromptGuard}$, fail to prohibit our attack,\nemphasizing the urgent need for multi-agent specific safety mechanisms.",
      "tldr_zh": "本研究专注于攻击多智能体LLM系统，创新性地设计了permutation-invariant adversarial attack，通过优化prompt分布来绕过带宽、延迟约束和分布式安全机制。攻击方法将路径问题表述为maximum-flow minimum-cost问题，并引入Permutation-Invariant Evasion Loss (PIEL)，利用图-based优化最大化成功率同时最小化检测风险。在Llama、Mistral、Gemma等模型和JailBreakBench等数据集上，该攻击比传统方法高出7倍，暴露了多智能体系统的关键漏洞，并证明现有防御如Llama-Guard和PromptGuard无效，强调了开发多智能体特定安全机制的迫切需求。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.00218v1",
      "published_date": "2025-03-31 20:43:56 UTC",
      "updated_date": "2025-03-31 20:43:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:49:08.320238"
    },
    {
      "arxiv_id": "2504.00204v1",
      "title": "RailGoerl24: Görlitz Rail Test Center CV Dataset 2024",
      "title_zh": "RailGoerl24：Görlitz 铁路测试中心计算机视觉数据集 2024",
      "authors": [
        "Rustam Tagiew",
        "Ilkay Wunderlich",
        "Mark Sastuba",
        "Steffen Seitz"
      ],
      "abstract": "Driverless train operation for open tracks on urban guided transport and\nmainline railways requires, among other things automatic detection of actual\nand potential obstacles, especially humans, in the danger zone of the train's\npath. Machine learning algorithms have proven to be powerful state-of-the-art\ntools for this task. However, these algorithms require large amounts of\nhigh-quality annotated data containing human beings in railway-specific\nenvironments as training data. Unfortunately, the amount of publicly available\ndatasets is not yet sufficient and is significantly inferior to the datasets in\nthe road domain. Therefore, this paper presents RailGoerl24, an on-board visual\nlight Full HD camera dataset of 12205 frames recorded in a railway test center\nof T\\\"UV S\\\"UD Rail, in G\\\"orlitz, Germany. Its main purpose is to support the\ndevelopment of driverless train operation for guided transport. RailGoerl24\nalso includes a terrestrial LiDAR scan covering parts of the area used to\nacquire the RGB data. In addition to the raw data, the dataset contains 33556\nboxwise annotations in total for the object class 'person'. The faces of\nrecorded actors are not blurred or altered in any other way. RailGoerl24, soon\navailable at data.fid-move.de/dataset/railgoerl24, can also be used for tasks\nbeyond collision prediction.",
      "tldr_zh": "这篇论文介绍了RailGoerl24数据集，这是一个针对铁路环境的计算机视觉(CV)数据集，旨在支持无人驾驶火车操作中的障碍物检测，特别是人类。数据集包括从德国Görlitz铁路测试中心收集的12,205帧Full HD视频数据、对应的地面LiDAR扫描，以及总计33,556个'person'对象的框标注，未对人脸进行模糊处理，以提供高品质的训练资源。相比道路领域的现有数据集，RailGoerl24填补了铁路特定环境的空白，可用于机器学习算法的开发，不仅限于碰撞预测任务，还适用于其他相关应用。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "4 pages, 5 figures, submitted to Engineering Reliable Autonomous\n  Systems 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.00204v1",
      "published_date": "2025-03-31 20:18:39 UTC",
      "updated_date": "2025-03-31 20:18:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:49:19.728715"
    },
    {
      "arxiv_id": "2504.00194v1",
      "title": "Identifying Sparsely Active Circuits Through Local Loss Landscape Decomposition",
      "title_zh": "通过局部损失景观分解识别稀疏活跃电路",
      "authors": [
        "Brianna Chrisman",
        "Lucius Bushnaq",
        "Lee Sharkey"
      ],
      "abstract": "Much of mechanistic interpretability has focused on understanding the\nactivation spaces of large neural networks. However, activation space-based\napproaches reveal little about the underlying circuitry used to compute\nfeatures. To better understand the circuits employed by models, we introduce a\nnew decomposition method called Local Loss Landscape Decomposition (L3D). L3D\nidentifies a set of low-rank subnetworks: directions in parameter space of\nwhich a subset can reconstruct the gradient of the loss between any sample's\noutput and a reference output vector. We design a series of progressively more\nchallenging toy models with well-defined subnetworks and show that L3D can\nnearly perfectly recover the associated subnetworks. Additionally, we\ninvestigate the extent to which perturbing the model in the direction of a\ngiven subnetwork affects only the relevant subset of samples. Finally, we apply\nL3D to a real-world transformer model and a convolutional neural network,\ndemonstrating its potential to identify interpretable and relevant circuits in\nparameter space.",
      "tldr_zh": "这篇论文针对神经网络机制解释性的局限性，引入了 Local Loss Landscape Decomposition (L3D) 方法，该方法通过分解损失景观来识别参数空间中的低秩 subnetworks，从而揭示模型用于计算特征的底层电路。L3D 能重建样本输出和参考输出向量之间的损失梯度，并在设计的一系列渐进式挑战的玩具模型上，几乎完美地恢复了预定义的 subnetworks。作者进一步研究了扰动特定 subnetwork 如何仅影响相关样本的子集，并将 L3D 应用于真实世界的 transformer 模型和 convolutional neural network (CNN)，证明了其在识别可解释和相关电路方面的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.00194v1",
      "published_date": "2025-03-31 20:04:39 UTC",
      "updated_date": "2025-03-31 20:04:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:49:32.427944"
    },
    {
      "arxiv_id": "2504.00186v1",
      "title": "Are Domain Generalization Benchmarks with Accuracy on the Line Misspecified?",
      "title_zh": "翻译失败",
      "authors": [
        "Olawale Salaudeen",
        "Nicole Chiou",
        "Shiny Weng",
        "Sanmi Koyejo"
      ],
      "abstract": "Spurious correlations are unstable statistical associations that hinder\nrobust decision-making. Conventional wisdom suggests that models relying on\nsuch correlations will fail to generalize out-of-distribution (OOD), especially\nunder strong distribution shifts. However, empirical evidence challenges this\nview as naive in-distribution empirical risk minimizers often achieve the best\nOOD accuracy across popular OOD generalization benchmarks. In light of these\nresults, we propose a different perspective: many widely used benchmarks for\nevaluating robustness to spurious correlations are misspecified. Specifically,\nthey fail to include shifts in spurious correlations that meaningfully impact\nOOD generalization, making them unsuitable for evaluating the benefit of\nremoving such correlations. We establish conditions under which a distribution\nshift can reliably assess a model's reliance on spurious correlations.\nCrucially, under these conditions, we should not observe a strong positive\ncorrelation between in-distribution and OOD accuracy, often called \"accuracy on\nthe line.\" Yet, most state-of-the-art benchmarks exhibit this pattern,\nsuggesting they do not effectively assess robustness. Our findings expose a key\nlimitation in current benchmarks used to evaluate domain generalization\nalgorithms, that is, models designed to avoid spurious correlations. We\nhighlight the need to rethink how robustness to spurious correlations is\nassessed, identify well-specified benchmarks the field should prioritize, and\nenumerate strategies for designing future benchmarks that meaningfully reflect\nrobustness under distribution shift.",
      "tldr_zh": "该论文质疑当前领域泛化（domain generalization）基准测试的设计，指出它们可能存在缺陷，因为这些基准未能有效评估模型对虚假相关（spurious correlations）的依赖，导致分布外（OOD）泛化表现不佳。作者建立了条件来判断分布偏移是否能可靠地测试模型对虚假相关的依赖，并发现符合这些条件的基准不应显示分布内（in-distribution）和OOD准确率之间的强正相关（accuracy on the line），而大多数现有基准却存在此问题。论文呼吁重新审视鲁棒性评估方法，优先选择合适的基准，并提出设计未来基准的策略，以更好地反映模型在分布偏移下的实际性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.00186v1",
      "published_date": "2025-03-31 19:50:04 UTC",
      "updated_date": "2025-03-31 19:50:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:49:44.199127"
    },
    {
      "arxiv_id": "2504.00180v1",
      "title": "Contradiction Detection in RAG Systems: Evaluating LLMs as Context Validators for Improved Information Consistency",
      "title_zh": "RAG 系统中的矛盾检测：评估 LLMs 作为上下文验证器以提高信息一致性",
      "authors": [
        "Vignesh Gokul",
        "Srikanth Tenneti",
        "Alwarappan Nakkiran"
      ],
      "abstract": "Retrieval Augmented Generation (RAG) systems have emerged as a powerful\nmethod for enhancing large language models (LLMs) with up-to-date information.\nHowever, the retrieval step in RAG can sometimes surface documents containing\ncontradictory information, particularly in rapidly evolving domains such as\nnews. These contradictions can significantly impact the performance of LLMs,\nleading to inconsistent or erroneous outputs. This study addresses this\ncritical challenge in two ways. First, we present a novel data generation\nframework to simulate different types of contradictions that may occur in the\nretrieval stage of a RAG system. Second, we evaluate the robustness of\ndifferent LLMs in performing as context validators, assessing their ability to\ndetect contradictory information within retrieved document sets. Our\nexperimental results reveal that context validation remains a challenging task\neven for state-of-the-art LLMs, with performance varying significantly across\ndifferent types of contradictions. While larger models generally perform better\nat contradiction detection, the effectiveness of different prompting strategies\nvaries across tasks and model architectures. We find that chain-of-thought\nprompting shows notable improvements for some models but may hinder performance\nin others, highlighting the complexity of the task and the need for more robust\napproaches to context validation in RAG systems.",
      "tldr_zh": "这篇论文探讨了RAG系统中的矛盾检测问题，评估LLMs作为上下文验证器以提升信息一致性。研究者提出了一种新型数据生成框架，用于模拟RAG检索阶段可能出现的不同类型矛盾，并测试各种LLMs在检测这些矛盾中的鲁棒性。实验结果显示，即使是先进的LLMs，上下文验证任务也极具挑战性，表现因矛盾类型而异，且更大模型在检测方面更有效，但chain-of-thought prompting等策略的效果因任务和模型架构而不同。该研究强调了开发更可靠的上下文验证方法在RAG系统中的必要性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.00180v1",
      "published_date": "2025-03-31 19:41:15 UTC",
      "updated_date": "2025-03-31 19:41:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:49:57.067996"
    },
    {
      "arxiv_id": "2504.00178v1",
      "title": "Boundless Byte Pair Encoding: Breaking the Pre-tokenization Barrier",
      "title_zh": "无界的字节对编码：打破预分词障碍",
      "authors": [
        "Craig W. Schmidt",
        "Varshini Reddy",
        "Chris Tanner",
        "Yuval Pinter"
      ],
      "abstract": "Pre-tokenization, the initial step in many modern tokenization pipelines,\nsegments text into smaller units called pretokens, typically splitting on\nwhitespace and punctuation. While this process encourages having full,\nindividual words as tokens, it introduces a fundamental limitation in most\ntokenization algorithms such as Byte Pair Encoding (BPE). Specifically,\npre-tokenization causes the distribution of tokens in a corpus to heavily skew\ntowards common, full-length words. This skewed distribution limits the benefits\nof expanding to larger vocabularies, since the additional tokens appear with\nprogressively lower counts. To overcome this barrier, we propose BoundlessBPE,\na modified BPE algorithm that relaxes the pretoken boundary constraint. Our\napproach selectively merges two complete pretokens into a larger unit we term a\nsuperword. Superwords are not necessarily semantically cohesive. For example,\nthe pretokens \" of\" and \" the\" might be combined to form the superword \" of\nthe\". This merging strategy results in a substantially more uniform\ndistribution of tokens across a corpus than standard BPE, and compresses text\nmore effectively, with an approximate 20% increase in bytes per token.",
      "tldr_zh": "该论文探讨了预分词（pre-tokenization）在 Byte Pair Encoding (BPE) 等算法中的局限性，导致语料库中 token 分布偏向常见全词，从而限制了词汇表扩展的效益。为解决此问题，研究提出 BoundlessBPE，一种修改后的 BPE 算法，它通过选择性地合并两个完整的 pretokens 成更大的 superword（如将“ of” 和“ the”合并为“ of the”），从而实现更均匀的 token 分布。实验结果显示，这种方法显著提高了文本压缩效率，大约增加了 20% 的 bytes per token。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "68T50",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.00178v1",
      "published_date": "2025-03-31 19:36:29 UTC",
      "updated_date": "2025-03-31 19:36:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:50:06.960964"
    },
    {
      "arxiv_id": "2504.00174v1",
      "title": "MetaCLBench: Meta Continual Learning Benchmark on Resource-Constrained Edge Devices",
      "title_zh": "MetaCLBench：资源受限边缘设备上的元持续学习基准",
      "authors": [
        "Sijia Li",
        "Young D. Kwon",
        "Lik-Hang Lee",
        "Pan Hui"
      ],
      "abstract": "Meta-Continual Learning (Meta-CL) has emerged as a promising approach to\nminimize manual labeling efforts and system resource requirements by enabling\nContinual Learning (CL) with limited labeled samples. However, while existing\nmethods have shown success in image-based tasks, their effectiveness remains\nunexplored for sequential time-series data from sensor systems, particularly\naudio inputs. To address this gap, we conduct a comprehensive benchmark study\nevaluating six representative Meta-CL approaches using three network\narchitectures on five datasets from both image and audio modalities. We develop\nMetaCLBench, an end-to-end Meta-CL benchmark framework for edge devices to\nevaluate system overheads and investigate trade-offs among performance,\ncomputational costs, and memory requirements across various Meta-CL methods.\nOur results reveal that while many Meta-CL methods enable to learn new classes\nfor both image and audio modalities, they impose significant computational and\nmemory costs on edge devices. Also, we find that pre-training and meta-training\nprocedures based on source data before deployment improve Meta-CL performance.\nFinally, to facilitate further research, we provide practical guidelines for\nresearchers and machine learning practitioners implementing Meta-CL on\nresource-constrained environments and make our benchmark framework and tools\npublicly available, enabling fair evaluation across both accuracy and\nsystem-level metrics.",
      "tldr_zh": "这篇论文介绍了 MetaCLBench，一个针对资源受限边缘设备的 Meta-Continual Learning (Meta-CL) 基准框架，旨在评估 Meta-CL 方法在图像和音频序列数据上的有效性。研究者对六个代表性 Meta-CL 方法进行了全面测试，使用三种网络架构和五个数据集，分析了性能、计算成本和内存需求之间的权衡。结果显示，这些方法能有效学习新类，但会显著增加边缘设备的计算和内存开销，而预训练及元训练过程可提升整体性能。最后，论文提供了实用指南并公开了框架，以促进在资源约束环境下的 Meta-CL 研究。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.00174v1",
      "published_date": "2025-03-31 19:31:49 UTC",
      "updated_date": "2025-03-31 19:31:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:50:19.613261"
    },
    {
      "arxiv_id": "2504.00170v1",
      "title": "Backdoor Detection through Replicated Execution of Outsourced Training",
      "title_zh": "翻译失败",
      "authors": [
        "Hengrui Jia",
        "Sierra Wyllie",
        "Akram Bin Sediq",
        "Ahmed Ibrahim",
        "Nicolas Papernot"
      ],
      "abstract": "It is common practice to outsource the training of machine learning models to\ncloud providers. Clients who do so gain from the cloud's economies of scale,\nbut implicitly assume trust: the server should not deviate from the client's\ntraining procedure. A malicious server may, for instance, seek to insert\nbackdoors in the model. Detecting a backdoored model without prior knowledge of\nboth the backdoor attack and its accompanying trigger remains a challenging\nproblem. In this paper, we show that a client with access to multiple cloud\nproviders can replicate a subset of training steps across multiple servers to\ndetect deviation from the training procedure in a similar manner to\ndifferential testing. Assuming some cloud-provided servers are benign, we\nidentify malicious servers by the substantial difference between model updates\nrequired for backdooring and those resulting from clean training. Perhaps the\nstrongest advantage of our approach is its suitability to clients that have\nlimited-to-no local compute capability to perform training; we leverage the\nexistence of multiple cloud providers to identify malicious updates without\nexpensive human labeling or heavy computation. We demonstrate the capabilities\nof our approach on an outsourced supervised learning task where $50\\%$ of the\ncloud providers insert their own backdoor; our approach is able to correctly\nidentify $99.6\\%$ of them. In essence, our approach is successful because it\nreplaces the signature-based paradigm taken by existing approaches with an\nanomaly-based detection paradigm. Furthermore, our approach is robust to\nseveral attacks from adaptive adversaries utilizing knowledge of our detection\nscheme.",
      "tldr_zh": "该研究提出了一种通过复制执行外包训练步骤来检测后门（backdoor）的机制，针对外包机器学习模型训练时恶意服务器可能插入后门的风险。方法假设存在多个云提供商（cloud providers），通过在不同服务器上重复训练子集并进行差异测试（differential testing），比较模型更新差异以识别恶意行为，而无需客户端进行本地计算。实验结果显示，在50%云提供商插入后门的场景下，检测准确率达99.6%，且该方法对自适应攻击具有鲁棒性，并从基于签名的检测范式转向基于异常的检测范式。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "cs.CR",
      "comment": "Published in the 3rd IEEE Conference on Secure and Trustworthy\n  Machine Learning (IEEE SaTML 2025)",
      "pdf_url": "http://arxiv.org/pdf/2504.00170v1",
      "published_date": "2025-03-31 19:26:34 UTC",
      "updated_date": "2025-03-31 19:26:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:50:31.730477"
    },
    {
      "arxiv_id": "2504.00163v1",
      "title": "Does \"Reasoning\" with Large Language Models Improve Recognizing, Generating, and Reframing Unhelpful Thoughts?",
      "title_zh": "翻译失败",
      "authors": [
        "Yilin Qi",
        "Dong Won Lee",
        "Cynthia Breazeal",
        "Hae Won Park"
      ],
      "abstract": "Cognitive Reframing, a core element of Cognitive Behavioral Therapy (CBT),\nhelps individuals reinterpret negative experiences by finding positive meaning.\nRecent advances in Large Language Models (LLMs) have demonstrated improved\nperformance through reasoning-based strategies. This inspires a promising\ndirection of leveraging the reasoning capabilities of LLMs to improve CBT and\nmental reframing by simulating the process of critical thinking, potentially\nenabling more effective recognition, generation, and reframing of cognitive\ndistortions. In this work, we investigate the role of various reasoning\nmethods, including pre-trained reasoning LLMs and augmented reasoning\nstrategies such as CoT and self-consistency in enhancing LLMs' ability to\nperform cognitive reframing tasks. We find that augmented reasoning methods,\neven when applied to \"outdated\" LLMs like GPT-3.5, consistently outperform\nstate-of-the-art pretrained reasoning models on recognizing, generating and\nreframing unhelpful thoughts.",
      "tldr_zh": "本研究探讨了大型语言模型(LLMs)的推理能力是否能提升认知重构(Cognitive Reframing)，一个认知行为疗法(CBT)核心元素，用于识别、生成和重构无益想法。研究评估了各种推理方法，包括预训练的推理LLMs以及增强策略如CoT(Chain-of-Thought)和self-consistency。结果表明，即使在像GPT-3.5这样的较旧模型上应用这些增强推理方法，也能一致优于最先进的预训练模型，在认知重构任务中显著改善性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages, 3 figures (including appendix)",
      "pdf_url": "http://arxiv.org/pdf/2504.00163v1",
      "published_date": "2025-03-31 19:19:34 UTC",
      "updated_date": "2025-03-31 19:19:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:50:44.429098"
    },
    {
      "arxiv_id": "2504.00149v1",
      "title": "Towards Precise Action Spotting: Addressing Temporal Misalignment in Labels with Dynamic Label Assignment",
      "title_zh": "翻译失败",
      "authors": [
        "Masato Tamura"
      ],
      "abstract": "Precise action spotting has attracted considerable attention due to its\npromising applications. While existing methods achieve substantial performance\nby employing well-designed model architecture, they overlook a significant\nchallenge: the temporal misalignment inherent in ground-truth labels. This\nmisalignment arises when frames labeled as containing events do not align\naccurately with the actual event times, often as a result of human annotation\nerrors or the inherent difficulties in precisely identifying event boundaries\nacross neighboring frames. To tackle this issue, we propose a novel dynamic\nlabel assignment strategy that allows predictions to have temporal offsets from\nground-truth action times during training, ensuring consistent event spotting.\nOur method extends the concept of minimum-cost matching, which is utilized in\nthe spatial domain for object detection, to the temporal domain. By calculating\nmatching costs based on predicted action class scores and temporal offsets, our\nmethod dynamically assigns labels to the most likely predictions, even when the\npredicted times of these predictions deviate from ground-truth times,\nalleviating the negative effects of temporal misalignment in labels. We conduct\nextensive experiments and demonstrate that our method achieves state-of-the-art\nperformance, particularly in conditions where events are visually distinct and\ntemporal misalignment in labels is common.",
      "tldr_zh": "本文针对行动检测中的标签时间不对齐(temporal misalignment)问题，提出了一种新型动态标签分配(dynamic label assignment)策略，以缓解由于人为标注错误或事件边界模糊导致的标签偏差。该策略将最小成本匹配(minimum-cost matching)从空间域扩展到时间域，通过基于预测动作类别分数和时间偏移计算匹配成本，实现对预测的动态标签分配，确保事件检测的一致性。实验结果显示，该方法在视觉上明显的事件场景中达到了最先进性能，尤其适用于标签时间不对齐常见的条件。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.00149v1",
      "published_date": "2025-03-31 18:57:57 UTC",
      "updated_date": "2025-03-31 18:57:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:50:55.497948"
    },
    {
      "arxiv_id": "2504.01992v1",
      "title": "Exploring the Societal and Economic Impacts of Artificial Intelligence: A Scenario Generation Methodology",
      "title_zh": "探索人工智能的社会和经济影响：一种情景生成方法论",
      "authors": [
        "Carlos J. Costa",
        "Joao Tiago Aparicio"
      ],
      "abstract": "This paper explores artificial intelligence's potential societal and economic\nimpacts (AI) through generating scenarios that assess how AI may influence\nvarious sectors. We categorize and analyze key factors affecting AI's\nintegration and adoption by applying an Impact-Uncertainty Matrix. A proposed\nmethodology involves querying academic databases, identifying emerging trends\nand topics, and categorizing these into an impact uncertainty framework. The\npaper identifies critical areas where AI may bring significant change and\noutlines potential future scenarios based on these insights. This research aims\nto inform policymakers, industry leaders, and researchers on the strategic\nplanning required to address the challenges and opportunities AI presents",
      "tldr_zh": "这篇论文探讨了人工智能(AI)对社会和经济的影响，通过生成场景评估AI在各个领域的整合与采用。作者采用Impact-Uncertainty Matrix分类分析关键因素，并通过查询学术数据库、识别新兴趋势和主题来构建影响不确定性框架。研究识别了AI可能引发重大变化的关键领域，并基于这些见解概述潜在未来场景，以帮助政策制定者、行业领袖和研究人员进行战略规划。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CE",
        "econ.TH",
        "I.2.7; J.4"
      ],
      "primary_category": "cs.CY",
      "comment": "6 pages",
      "pdf_url": "http://arxiv.org/pdf/2504.01992v1",
      "published_date": "2025-03-31 18:49:46 UTC",
      "updated_date": "2025-03-31 18:49:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:51:06.978071"
    },
    {
      "arxiv_id": "2504.00142v3",
      "title": "LGIN: Defining an Approximately Powerful Hyperbolic GNN",
      "title_zh": "翻译失败",
      "authors": [
        "Srinitish Srinivasan",
        "Omkumar CU"
      ],
      "abstract": "While graph neural networks (GNNs) operating in hyperbolic spaces have shown\npromise for modeling hierarchical and complex relational data, a critical\nlimitation often overlooked is their potentially limited discriminative power\ncompared to their Euclidean counterparts or fundamental graph isomorphism tests\nlike the Weisfeiler-Lehman (WL) hierarchy. Existing hyperbolic aggregation\nschemes, while curvature-aware, may not sufficiently capture the intricate\nstructural differences required to robustly distinguish non-isomorphic graphs\nowing to non-injective aggregation functions. To address this expressiveness\ngap in hyperbolic graph learning, we introduce the Lorentzian Graph Isomorphic\nNetwork (LGIN), a novel GNN designed to achieve enhanced discriminative\ncapabilities within the Lorentzian model of hyperbolic space. LGIN proposes a\nnew update rule that effectively combines local neighborhood information with a\nricher representation of graph structure designed to preserve the Lorentzian\nmetric tensor. This represents a significant step towards building more\nexpressive GNNs in non-Euclidean geometries, overcoming a common bottleneck in\ncurrent hyperbolic methods. We conduct extensive evaluations across nine\ndiverse benchmark datasets, including molecular and protein structures. LGIN\nconsistently outperforms or matches state-of-the-art hyperbolic and Euclidean\nGNNs, showcasing its practical efficacy and validating its superior ability to\ncapture complex graph structures and distinguish between different graphs. To\nthe best of our knowledge, LGIN is the first work to study the framework behind\na powerful GNN on the hyperbolic space. The code for our paper can be found at\nhttps://github.com/Deceptrax123/LGIN",
      "tldr_zh": "该研究指出了现有超曲空间中的图神经网络 (GNNs) 在辨别力上不如欧氏 GNNs 或 Weisfeiler-Lehman (WL) 层次测试，主要由于非注入聚合函数导致的结构差异捕捉不足。为解决这一表达性差距，论文提出Lorentzian Graph Isomorphic Network (LGIN)，一种新型 GNN，通过新的更新规则结合局部邻域信息和Lorentzian度量张量，实现更丰富的图结构表示。实验在九个基准数据集（包括分子和蛋白质结构）上显示，LGIN 优于或相当于是现有超曲和欧氏 GNNs，证明了其在捕捉复杂图结构和区分非同构图方面的有效性。作为首个探讨超曲空间中强大 GNN 框架的作品，LGIN 为非欧几何图学习提供了新方向。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at GRADES NDA 2025 Workshop@ACM SIGMOD/PODS(Non Archival)",
      "pdf_url": "http://arxiv.org/pdf/2504.00142v3",
      "published_date": "2025-03-31 18:49:34 UTC",
      "updated_date": "2025-05-05 20:07:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:51:20.001093"
    },
    {
      "arxiv_id": "2504.00133v1",
      "title": "Data-driven Power Loss Identification through Physics-Based Thermal Model Backpropagation",
      "title_zh": "翻译失败",
      "authors": [
        "Mattia Scarpa",
        "Francesco Pase",
        "Ruggero Carli",
        "Mattia Bruschetta",
        "Franscesco Toso"
      ],
      "abstract": "Digital twins for power electronics require accurate power losses whose\ndirect measurements are often impractical or impossible in real-world\napplications. This paper presents a novel hybrid framework that combines\nphysics-based thermal modeling with data-driven techniques to identify and\ncorrect power losses accurately using only temperature measurements. Our\napproach leverages a cascaded architecture where a neural network learns to\ncorrect the outputs of a nominal power loss model by backpropagating through a\nreduced-order thermal model. We explore two neural architectures, a\nbootstrapped feedforward network, and a recurrent neural network, demonstrating\nthat the bootstrapped feedforward approach achieves superior performance while\nmaintaining computational efficiency for real-time applications. Between the\ninterconnection, we included normalization strategies and physics-guided\ntraining loss functions to preserve stability and ensure physical consistency.\nExperimental results show that our hybrid model reduces both temperature\nestimation errors (from 7.2+-6.8{\\deg}C to 0.3+-0.3{\\deg}C) and power loss\nprediction errors (from 5.4+-6.6W to 0.2+-0.3W) compared to traditional\nphysics-based approaches, even in the presence of thermal model uncertainties.\nThis methodology allows us to accurately estimate power losses without direct\nmeasurements, making it particularly helpful for real-time industrial\napplications where sensor placement is hindered by cost and physical\nlimitations.",
      "tldr_zh": "该论文提出了一种新型混合框架，用于电力电子数字孪生中通过基于物理的热模型反向传播和数据驱动技术，精确识别功率损失，仅依赖温度测量。框架采用级联架构，其中神经网络（neural network）通过简化热模型（reduced-order thermal model）学习修正名义功率损失模型的输出，并探索了引导前馈网络（bootstrapped feedforward network）和循环神经网络（recurrent neural network），后者在计算效率和性能上表现出色。实验结果显示，该方法显著降低了温度估计错误（从7.2±6.8°C 到0.3±0.3°C）和功率损失预测错误（从5.4±6.6W 到0.2±0.3W），即使在热模型不确定性存在的情况下。总体上，此框架无需直接测量功率损失，为实时工业应用提供了可靠的解决方案。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.CC",
        "cs.LG",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "Accepted by European Control Conference (ECC) 2020, 8 pages, 7\n  figures",
      "pdf_url": "http://arxiv.org/pdf/2504.00133v1",
      "published_date": "2025-03-31 18:37:14 UTC",
      "updated_date": "2025-03-31 18:37:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:51:33.091084"
    },
    {
      "arxiv_id": "2504.00125v1",
      "title": "LLMs for Explainable AI: A Comprehensive Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Ahsan Bilal",
        "David Ebert",
        "Beiyu Lin"
      ],
      "abstract": "Large Language Models (LLMs) offer a promising approach to enhancing\nExplainable AI (XAI) by transforming complex machine learning outputs into\neasy-to-understand narratives, making model predictions more accessible to\nusers, and helping bridge the gap between sophisticated model behavior and\nhuman interpretability. AI models, such as state-of-the-art neural networks and\ndeep learning models, are often seen as \"black boxes\" due to a lack of\ntransparency. As users cannot fully understand how the models reach\nconclusions, users have difficulty trusting decisions from AI models, which\nleads to less effective decision-making processes, reduced accountabilities,\nand unclear potential biases. A challenge arises in developing explainable AI\n(XAI) models to gain users' trust and provide insights into how models generate\ntheir outputs. With the development of Large Language Models, we want to\nexplore the possibilities of using human language-based models, LLMs, for model\nexplainabilities. This survey provides a comprehensive overview of existing\napproaches regarding LLMs for XAI, and evaluation techniques for LLM-generated\nexplanation, discusses the corresponding challenges and limitations, and\nexamines real-world applications. Finally, we discuss future directions by\nemphasizing the need for more interpretable, automated, user-centric, and\nmultidisciplinary approaches for XAI via LLMs.",
      "tldr_zh": "这篇调查论文探讨了大型语言模型（LLMs）在可解释 AI（XAI）中的应用，旨在通过将复杂机器学习输出转化为易懂的叙述，提升模型的可访问性和用户信任，从而解决 AI 的“黑箱”问题。论文综述了现有方法，包括 LLMs 生成解释的多种技术、评估策略，以及在实际应用中的挑战和限制，如模型透明度不足和潜在偏差。最终，它强调未来方向，需要开发更可解释、自动化、以用户为中心的多学科方法，以进一步推进 XAI 的发展。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "This manuscript is intended for submission to ACM Transactions on\n  Intelligent Systems and Technology",
      "pdf_url": "http://arxiv.org/pdf/2504.00125v1",
      "published_date": "2025-03-31 18:19:41 UTC",
      "updated_date": "2025-03-31 18:19:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:51:43.590281"
    },
    {
      "arxiv_id": "2504.00118v1",
      "title": "Times2D: Multi-Period Decomposition and Derivative Mapping for General Time Series Forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Reza Nematirad",
        "Anil Pahwa",
        "Balasubramaniam Natarajan"
      ],
      "abstract": "Time series forecasting is an important application in various domains such\nas energy management, traffic planning, financial markets, meteorology, and\nmedicine. However, real-time series data often present intricate temporal\nvariability and sharp fluctuations, which pose significant challenges for time\nseries forecasting. Previous models that rely on 1D time series representations\nusually struggle with complex temporal variations. To address the limitations\nof 1D time series, this study introduces the Times2D method that transforms the\n1D time series into 2D space. Times2D consists of three main parts: first, a\nPeriodic Decomposition Block (PDB) that captures temporal variations within a\nperiod and between the same periods by converting the time series into a 2D\ntensor in the frequency domain. Second, the First and Second Derivative\nHeatmaps (FSDH) capture sharp changes and turning points, respectively.\nFinally, an Aggregation Forecasting Block (AFB) integrates the output tensors\nfrom PDB and FSDH for accurate forecasting. This 2D transformation enables the\nutilization of 2D convolutional operations to effectively capture long and\nshort characteristics of the time series. Comprehensive experimental results\nacross large-scale data in the literature demonstrate that the proposed Times2D\nmodel achieves state-of-the-art performance in both short-term and long-term\nforecasting. The code is available in this repository:\nhttps://github.com/Tims2D/Times2D.",
      "tldr_zh": "本研究针对时间序列预测中的复杂变异和急剧波动问题，提出Times2D方法，将1D时间序列转换为2D空间，以克服传统模型的局限性。Times2D包括三个核心组件：Periodic Decomposition Block (PDB)通过频率域转换捕捉周期内和周期间的变化；First and Second Derivative Heatmaps (FSDH)用于检测急剧变化和转折点；Aggregation Forecasting Block (AFB)整合这些输出，利用2D卷积操作捕捉时间序列的长短特性。实验结果显示，Times2D在多种大规模数据集上实现了state-of-the-art性能，在短期和长期预测中均表现出色。代码已在仓库https://github.com/Tims2D/Times2D中公开。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at the AAAI 2025 Conference on Artificial Intelligence",
      "pdf_url": "http://arxiv.org/pdf/2504.00118v1",
      "published_date": "2025-03-31 18:08:30 UTC",
      "updated_date": "2025-03-31 18:08:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:51:55.679316"
    },
    {
      "arxiv_id": "2504.01990v1",
      "title": "Advances and Challenges in Foundation Agents: From Brain-Inspired Intelligence to Evolutionary, Collaborative, and Safe Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Bang Liu",
        "Xinfeng Li",
        "Jiayi Zhang",
        "Jinlin Wang",
        "Tanjin He",
        "Sirui Hong",
        "Hongzhang Liu",
        "Shaokun Zhang",
        "Kaitao Song",
        "Kunlun Zhu",
        "Yuheng Cheng",
        "Suyuchen Wang",
        "Xiaoqiang Wang",
        "Yuyu Luo",
        "Haibo Jin",
        "Peiyan Zhang",
        "Ollie Liu",
        "Jiaqi Chen",
        "Huan Zhang",
        "Zhaoyang Yu",
        "Haochen Shi",
        "Boyan Li",
        "Dekun Wu",
        "Fengwei Teng",
        "Xiaojun Jia",
        "Jiawei Xu",
        "Jinyu Xiang",
        "Yizhang Lin",
        "Tianming Liu",
        "Tongliang Liu",
        "Yu Su",
        "Huan Sun",
        "Glen Berseth",
        "Jianyun Nie",
        "Ian Foster",
        "Logan Ward",
        "Qingyun Wu",
        "Yu Gu",
        "Mingchen Zhuge",
        "Xiangru Tang",
        "Haohan Wang",
        "Jiaxuan You",
        "Chi Wang",
        "Jian Pei",
        "Qiang Yang",
        "Xiaoliang Qi",
        "Chenglin Wu"
      ],
      "abstract": "The advent of large language models (LLMs) has catalyzed a transformative\nshift in artificial intelligence, paving the way for advanced intelligent\nagents capable of sophisticated reasoning, robust perception, and versatile\naction across diverse domains. As these agents increasingly drive AI research\nand practical applications, their design, evaluation, and continuous\nimprovement present intricate, multifaceted challenges. This survey provides a\ncomprehensive overview, framing intelligent agents within a modular,\nbrain-inspired architecture that integrates principles from cognitive science,\nneuroscience, and computational research. We structure our exploration into\nfour interconnected parts. First, we delve into the modular foundation of\nintelligent agents, systematically mapping their cognitive, perceptual, and\noperational modules onto analogous human brain functionalities, and elucidating\ncore components such as memory, world modeling, reward processing, and\nemotion-like systems. Second, we discuss self-enhancement and adaptive\nevolution mechanisms, exploring how agents autonomously refine their\ncapabilities, adapt to dynamic environments, and achieve continual learning\nthrough automated optimization paradigms, including emerging AutoML and\nLLM-driven optimization strategies. Third, we examine collaborative and\nevolutionary multi-agent systems, investigating the collective intelligence\nemerging from agent interactions, cooperation, and societal structures,\nhighlighting parallels to human social dynamics. Finally, we address the\ncritical imperative of building safe, secure, and beneficial AI systems,\nemphasizing intrinsic and extrinsic security threats, ethical alignment,\nrobustness, and practical mitigation strategies necessary for trustworthy\nreal-world deployment.",
      "tldr_zh": "这篇调查论文探讨了大型语言模型(LLMs)驱动的智能代理的进展与挑战，将其框架化为模块化的脑启发架构，整合认知科学、神经科学和计算原理。论文分为四个部分：首先，映射代理的认知、感知和操作模块（如记忆、世界建模、奖励处理和情感系统）到人类脑功能；其次，探讨代理的自增强机制、适应性演化和持续学习，包括AutoML和LLM优化策略；第三，分析协作多代理系统及其与人类社会动态的相似性；最后，强调构建安全、可靠AI的必要性，包括安全威胁、伦理对齐和缓解策略。该研究为智能代理的设计、评估和实际应用提供了全面指导，推动了更可信赖的AI系统发展。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.01990v1",
      "published_date": "2025-03-31 18:00:29 UTC",
      "updated_date": "2025-03-31 18:00:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:52:08.056963"
    },
    {
      "arxiv_id": "2504.00091v1",
      "title": "A First-Principles Based Risk Assessment Framework and the IEEE P3396 Standard",
      "title_zh": "基于第一性原理的风险评估框架和 IEEE P3396 标准",
      "authors": [
        "Richard J. Tong",
        "Marina Cortês",
        "Jeanine A. DeFalco",
        "Mark Underwood",
        "Janusz Zalewski"
      ],
      "abstract": "Generative Artificial Intelligence (AI) is enabling unprecedented automation\nin content creation and decision support, but it also raises novel risks. This\npaper presents a first-principles risk assessment framework underlying the IEEE\nP3396 Recommended Practice for AI Risk, Safety, Trustworthiness, and\nResponsibility. We distinguish between process risks (risks arising from how AI\nsystems are built or operated) and outcome risks (risks manifest in the AI\nsystem's outputs and their real-world effects), arguing that generative AI\ngovernance should prioritize outcome risks. Central to our approach is an\ninformation-centric ontology that classifies AI-generated outputs into four\nfundamental categories: (1) Perception-level information, (2) Knowledge-level\ninformation, (3) Decision/Action plan information, and (4) Control tokens\n(access or resource directives). This classification allows systematic\nidentification of harms and more precise attribution of responsibility to\nstakeholders (developers, deployers, users, regulators) based on the nature of\nthe information produced. We illustrate how each information type entails\ndistinct outcome risks (e.g. deception, misinformation, unsafe recommendations,\nsecurity breaches) and requires tailored risk metrics and mitigations. By\ngrounding the framework in the essence of information, human agency, and\ncognition, we align risk evaluation with how AI outputs influence human\nunderstanding and action. The result is a principled approach to AI risk that\nsupports clear accountability and targeted safeguards, in contrast to broad\napplication-based risk categorizations. We include example tables mapping\ninformation types to risks and responsibilities. This work aims to inform the\nIEEE P3396 Recommended Practice and broader AI governance with a rigorous,\nfirst-principles foundation for assessing generative AI risks while enabling\nresponsible innovation.",
      "tldr_zh": "这篇论文提出了一个基于 first-principles 的风险评估框架，作为 IEEE P3396 推荐实践的基础，用于评估生成式 AI 的风险。该框架区分 process risks（与 AI 构建或操作相关）和 outcome risks（与 AI 输出及其实际影响相关），并主张优先治理 outcome risks。通过一个 information-centric ontology，将 AI 生成的输出分类为四类：(1) Perception-level information、(2) Knowledge-level information、(3) Decision/Action plan information 和 (4) Control tokens，从而系统识别潜在危害并精确分配责任给开发者、部署者、用户和监管者。论文还举例说明每类信息对应的风险（如欺骗、错误信息、不安全推荐或安全漏洞）及其针对性风险指标和缓解措施，最终支持更清晰的责任归属和负责任的 AI 创新。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "8 pages with 3 tables. This manuscript is prepared for publication by\n  the Institute of Electrical and Electronics Engineers, Standards Association\n  (IEEE-SA), Sponsor Committee - Artificial Intelligence Standards Committee\n  (C/AISC) as a White Paper of Working Group p3396 at\n  https://standards.ieee.org/ieee/3396/11379/",
      "pdf_url": "http://arxiv.org/pdf/2504.00091v1",
      "published_date": "2025-03-31 18:00:03 UTC",
      "updated_date": "2025-03-31 18:00:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:52:20.755312"
    },
    {
      "arxiv_id": "2503.24388v1",
      "title": "RIG: Synergizing Reasoning and Imagination in End-to-End Generalist Policy",
      "title_zh": "翻译失败",
      "authors": [
        "Zhonghan Zhao",
        "Wenwei Zhang",
        "Haian Huang",
        "Kuikun Liu",
        "Jianfei Gao",
        "Gaoang Wang",
        "Kai Chen"
      ],
      "abstract": "Reasoning before action and imagining potential outcomes (i.e., world models)\nare essential for embodied agents operating in complex open-world environments.\nYet, prior work either incorporates only one of these abilities in an\nend-to-end agent or integrates multiple specialized models into an agent\nsystem, limiting the learning efficiency and generalization of the policy.\nThus, this paper makes the first attempt to synergize Reasoning and Imagination\nin an end-to-end Generalist policy, termed RIG. To train RIG in an end-to-end\nmanner, we construct a data pipeline that progressively integrates and enriches\nthe content of imagination and reasoning in the trajectories collected from\nexisting agents. The joint learning of reasoning and next image generation\nexplicitly models the inherent correlation between reasoning, action, and\ndynamics of environments, and thus exhibits more than $17\\times$ sample\nefficiency improvements and generalization in comparison with previous works.\nDuring inference, RIG first reasons about the next action, produces potential\naction, and then predicts the action outcomes, which offers the agent a chance\nto review and self-correct based on the imagination before taking real actions.\nExperimental results show that the synergy of reasoning and imagination not\nonly improves the robustness, generalization, and interoperability of\ngeneralist policy but also enables test-time scaling to enhance overall\nperformance.",
      "tldr_zh": "该论文提出 RIG，一种端到端的通用策略（End-to-End Generalist Policy），首次将推理（Reasoning）和想象（Imagination）能力协同整合，以提升智能体在复杂开放环境中的表现。RIG 通过构建一个数据管道来逐步整合和丰富轨迹中的想象与推理内容，实现推理、动作和环境动态的联合学习，从而比以往工作提高了超过 17 倍的样本效率（Sample Efficiency）和泛化能力。在推理过程中，RIG 先预测潜在动作并模拟结果，允许智能体自我修正，实验结果显示这显著提升了策略的鲁棒性、泛化以及互操作性，并支持测试时性能扩展。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.24388v1",
      "published_date": "2025-03-31 17:59:52 UTC",
      "updated_date": "2025-03-31 17:59:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:52:31.168032"
    },
    {
      "arxiv_id": "2503.24381v1",
      "title": "UniOcc: A Unified Benchmark for Occupancy Forecasting and Prediction in Autonomous Driving",
      "title_zh": "翻译失败",
      "authors": [
        "Yuping Wang",
        "Xiangyu Huang",
        "Xiaokang Sun",
        "Mingxuan Yan",
        "Shuo Xing",
        "Zhengzhong Tu",
        "Jiachen Li"
      ],
      "abstract": "We introduce UniOcc, a comprehensive, unified benchmark for occupancy\nforecasting (i.e., predicting future occupancies based on historical\ninformation) and current-frame occupancy prediction from camera images. UniOcc\nunifies data from multiple real-world datasets (i.e., nuScenes, Waymo) and\nhigh-fidelity driving simulators (i.e., CARLA, OpenCOOD), which provides 2D/3D\noccupancy labels with per-voxel flow annotations and support for cooperative\nautonomous driving. In terms of evaluation, unlike existing studies that rely\non suboptimal pseudo labels for evaluation, UniOcc incorporates novel metrics\nthat do not depend on ground-truth occupancy, enabling robust assessment of\nadditional aspects of occupancy quality. Through extensive experiments on\nstate-of-the-art models, we demonstrate that large-scale, diverse training data\nand explicit flow information significantly enhance occupancy prediction and\nforecasting performance.",
      "tldr_zh": "本研究引入UniOcc，一个全面统一的基准，用于评估自动驾驶中的占用预测（基于历史信息预测未来占用）和当前帧占用预测。该基准整合了真实世界数据集（如nuScenes和Waymo）以及高保真模拟器（如CARLA和OpenCOOD），提供2D/3D占用标签、每个体素的流标注，并支持合作式自动驾驶。与现有方法不同，UniOcc采用不依赖地面真实占用的新型评估指标，实现对占用质量的更鲁棒评估。通过在最先进模型上的广泛实验，证明大规模多样化训练数据和显式流信息显著提升了占用预测和预测性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.MA",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "14 pages; Dataset: https://huggingface.co/datasets/tasl-lab/uniocc;\n  Code: https://github.com/tasl-lab/UniOcc",
      "pdf_url": "http://arxiv.org/pdf/2503.24381v1",
      "published_date": "2025-03-31 17:59:24 UTC",
      "updated_date": "2025-03-31 17:59:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:52:43.165076"
    },
    {
      "arxiv_id": "2503.24379v1",
      "title": "Any2Caption:Interpreting Any Condition to Caption for Controllable Video Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Shengqiong Wu",
        "Weicai Ye",
        "Jiahao Wang",
        "Quande Liu",
        "Xintao Wang",
        "Pengfei Wan",
        "Di Zhang",
        "Kun Gai",
        "Shuicheng Yan",
        "Hao Fei",
        "Tat-Seng Chua"
      ],
      "abstract": "To address the bottleneck of accurate user intent interpretation within the\ncurrent video generation community, we present Any2Caption, a novel framework\nfor controllable video generation under any condition. The key idea is to\ndecouple various condition interpretation steps from the video synthesis step.\nBy leveraging modern multimodal large language models (MLLMs), Any2Caption\ninterprets diverse inputs--text, images, videos, and specialized cues such as\nregion, motion, and camera poses--into dense, structured captions that offer\nbackbone video generators with better guidance. We also introduce Any2CapIns, a\nlarge-scale dataset with 337K instances and 407K conditions for\nany-condition-to-caption instruction tuning. Comprehensive evaluations\ndemonstrate significant improvements of our system in controllability and video\nquality across various aspects of existing video generation models. Project\nPage: https://sqwu.top/Any2Cap/",
      "tldr_zh": "本研究提出 Any2Caption 框架，用于实现可控视频生成，通过解耦条件解释和视频合成步骤来准确解读用户意图。框架利用多模态大语言模型 (MLLMs) 将多种输入（如文本、图像、视频、区域、动作和相机姿势）转换为密集、结构化的标题，从而为视频生成器提供更好的指导。同时，引入大型数据集 Any2CapIns，包含 337K 实例和 407K 条件，用于条件到标题的指令微调。实验评估显示，该系统显著提升了现有视频生成模型的可控性和视频质量。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Project Page: https://sqwu.top/Any2Cap/",
      "pdf_url": "http://arxiv.org/pdf/2503.24379v1",
      "published_date": "2025-03-31 17:59:01 UTC",
      "updated_date": "2025-03-31 17:59:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:52:55.053561"
    },
    {
      "arxiv_id": "2503.24378v1",
      "title": "ACPBench Hard: Unrestrained Reasoning about Action, Change, and Planning",
      "title_zh": "翻译失败",
      "authors": [
        "Harsha Kokel",
        "Michael Katz",
        "Kavitha Srinivas",
        "Shirin Sohrabi"
      ],
      "abstract": "The ACPBench dataset provides atomic reasoning tasks required for efficient\nplanning. The dataset is aimed at distilling the complex plan generation task\ninto separate atomic reasoning tasks in their easiest possible form, boolean or\nmultiple-choice questions, where the model has to choose the right answer from\nthe provided options. While the aim of ACPBench is to test the simplest form of\nreasoning about action and change, when tasked with planning, a model does not\ntypically have options to choose from and thus the reasoning required for\nplanning dictates an open-ended, generative form for these tasks. To that end,\nwe introduce ACPBench Hard, a generative version of ACPBench, with open-ended\nquestions which the model needs to answer. Models that perform well on these\ntasks could in principle be integrated into a planner or be used directly as a\npolicy. We discuss the complexity of these tasks as well as the complexity of\nvalidating the correctness of their answers and present validation algorithms\nfor each task. Equipped with these validators, we test the performance of a\nvariety of models on our tasks and find that for most of these tasks the\nperformance of even the largest models is still subpar. Our experiments show\nthat no model outperforms another in these tasks and with a few exceptions all\ntested language models score below 65%, indicating that even the current\nfrontier language models have a long way to go before they can reliably reason\nabout planning. In fact, even the so-called reasoning models struggle with\nsolving these reasoning tasks. ACPBench Hard collection is available at the\nfollowing link: https://ibm.github.io/ACPBench",
      "tldr_zh": "本研究引入了 ACPBench Hard，这是一个开放式问题的生成版本数据集，用于测试模型在行动、变化和规划（reasoning about action, change, and planning）方面的原子推理能力。相比原 ACPBench 的简单选择题形式，ACPBench Hard 通过开放式任务模拟实际规划场景，并开发了相应的验证算法来评估答案正确性。实验结果显示，即使是当前最先进的语言模型在这些任务上表现欠佳，大多数得分低于65%，表明现有模型在规划推理方面仍有显著改进空间。该数据集可用于提升模型的规划性能，并提供于以下链接：https://ibm.github.io/ACPBench。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to LM4Plan@AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.24378v1",
      "published_date": "2025-03-31 17:58:25 UTC",
      "updated_date": "2025-03-31 17:58:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:53:07.212059"
    },
    {
      "arxiv_id": "2503.24377v1",
      "title": "Harnessing the Reasoning Economy: A Survey of Efficient Reasoning for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Rui Wang",
        "Hongru Wang",
        "Boyang Xue",
        "Jianhui Pang",
        "Shudong Liu",
        "Yi Chen",
        "Jiahao Qiu",
        "Derek Fai Wong",
        "Heng Ji",
        "Kam-Fai Wong"
      ],
      "abstract": "Recent advancements in Large Language Models (LLMs) have significantly\nenhanced their ability to perform complex reasoning tasks, transitioning from\nfast and intuitive thinking (System 1) to slow and deep reasoning (System 2).\nWhile System 2 reasoning improves task accuracy, it often incurs substantial\ncomputational costs due to its slow thinking nature and inefficient or\nunnecessary reasoning behaviors. In contrast, System 1 reasoning is\ncomputationally efficient but leads to suboptimal performance. Consequently, it\nis critical to balance the trade-off between performance (benefits) and\ncomputational costs (budgets), giving rise to the concept of reasoning economy.\nIn this survey, we provide a comprehensive analysis of reasoning economy in\nboth the post-training and test-time inference stages of LLMs, encompassing i)\nthe cause of reasoning inefficiency, ii) behavior analysis of different\nreasoning patterns, and iii) potential solutions to achieve reasoning economy.\nBy offering actionable insights and highlighting open challenges, we aim to\nshed light on strategies for improving the reasoning economy of LLMs, thereby\nserving as a valuable resource for advancing research in this evolving area. We\nalso provide a public repository to continually track developments in this\nfast-evolving field.",
      "tldr_zh": "这篇调查论文探讨了大型语言模型 (LLMs) 的推理效率问题，引入“推理经济”概念来平衡 System 1（快速直观思维）和 System 2（缓慢深入推理）之间的性能与计算成本权衡。论文分析了推理不效率的原因、不同推理模式的行為，并提出了潜在解决方案，涵盖 LLM 的训练后和推理阶段。最终，该研究提供可操作见解、突出开放挑战，并维护一个公共仓库以跟踪该领域的最新进展，从而为提升 LLM 推理经济提供宝贵资源。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "In Progress; Paper list Repo:\n  https://github.com/DevoAllen/Awesome-Reasoning-Economy-Papers",
      "pdf_url": "http://arxiv.org/pdf/2503.24377v1",
      "published_date": "2025-03-31 17:58:07 UTC",
      "updated_date": "2025-03-31 17:58:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:53:19.793370"
    },
    {
      "arxiv_id": "2503.24376v1",
      "title": "Exploring the Effect of Reinforcement Learning on Video Understanding: Insights from SEED-Bench-R1",
      "title_zh": "探索强化学习对视频理解的影响：来自 SEED-Bench-R1 的洞见",
      "authors": [
        "Yi Chen",
        "Yuying Ge",
        "Rui Wang",
        "Yixiao Ge",
        "Lu Qiu",
        "Ying Shan",
        "Xihui Liu"
      ],
      "abstract": "Recent advancements in Chain of Thought (COT) generation have significantly\nimproved the reasoning capabilities of Large Language Models (LLMs), with\nreinforcement learning (RL) emerging as an effective post-training approach.\nMultimodal Large Language Models (MLLMs) inherit this reasoning potential but\nremain underexplored in tasks requiring both perception and logical reasoning.\nTo address this, we introduce SEED-Bench-R1, a benchmark designed to\nsystematically evaluate post-training methods for MLLMs in video understanding.\nIt includes intricate real-world videos and complex everyday planning tasks in\nthe format of multiple-choice questions, requiring sophisticated perception and\nreasoning. SEED-Bench-R1 assesses generalization through a three-level\nhierarchy: in-distribution, cross-environment, and cross-environment-task\nscenarios, equipped with a large-scale training dataset with easily verifiable\nground-truth answers. Using Qwen2-VL-Instruct-7B as a base model, we compare RL\nwith supervised fine-tuning (SFT), demonstrating RL's data efficiency and\nsuperior performance on both in-distribution and out-of-distribution tasks,\neven outperforming SFT on general video understanding benchmarks like\nLongVideoBench. Our detailed analysis reveals that RL enhances visual\nperception but often produces less logically coherent reasoning chains. We\nidentify key limitations such as inconsistent reasoning and overlooked visual\ncues, and suggest future improvements in base model reasoning, reward modeling,\nand RL robustness against noisy signals.",
      "tldr_zh": "本文研究了强化学习 (RL) 对视频理解的影响，通过引入 SEED-Bench-R1 基准来评估 Multimodal Large Language Models (MLLMs) 的后训练方法，该基准包含复杂真实世界视频和多项选择任务，需整合感知和逻辑推理，并评估 in-distribution、cross-environment 和 cross-environment-task 场景。使用 Qwen2-VL-Instruct-7B 作为基模型，实验结果显示 RL 比 Supervised Fine-Tuning (SFT) 更数据高效，并在各种视频理解任务上表现更好，甚至优于 SFT 在 LongVideoBench 的结果。分析发现，RL 显著提升了视觉感知，但会产生逻辑不一致的推理链，并建议未来改进基模型推理、奖励建模和 RL 对噪声信号的鲁棒性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Technical Report (In Progress); Code released at:\n  https://github.com/TencentARC/SEED-Bench-R1",
      "pdf_url": "http://arxiv.org/pdf/2503.24376v1",
      "published_date": "2025-03-31 17:55:23 UTC",
      "updated_date": "2025-03-31 17:55:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:53:33.834232"
    },
    {
      "arxiv_id": "2503.24370v3",
      "title": "Effectively Controlling Reasoning Models through Thinking Intervention",
      "title_zh": "通过思考干预有效控制推理模型",
      "authors": [
        "Tong Wu",
        "Chong Xiang",
        "Jiachen T. Wang",
        "G. Edward Suh",
        "Prateek Mittal"
      ],
      "abstract": "Reasoning-enhanced large language models (LLMs) explicitly generate\nintermediate reasoning steps prior to generating final answers, helping the\nmodel excel in complex problem-solving. In this paper, we demonstrate that this\nemerging generation framework offers a unique opportunity for more fine-grained\ncontrol over model behavior. We propose Thinking Intervention, a novel paradigm\ndesigned to explicitly guide the internal reasoning processes of LLMs by\nstrategically inserting or revising specific thinking tokens. We find that the\nThinking Intervention paradigm enhances the capabilities of reasoning models\nacross a wide range of tasks, including instruction following on IFEval and\nOverthinking, instruction hierarchy on SEP, and safety alignment on XSTest and\nSorryBench. Our results demonstrate that Thinking Intervention significantly\noutperforms baseline prompting approaches, achieving up to 6.7% accuracy gains\nin instruction-following scenarios, 15.4% improvements in reasoning about\ninstruction hierarchies, and a 40.0% increase in refusal rates for unsafe\nprompts using open-source DeepSeek R1 models. Overall, our work opens a\npromising new research avenue for controlling reasoning LLMs.",
      "tldr_zh": "该论文提出Thinking Intervention范式，通过战略性地插入或修改特定thinking tokens来精确指导推理增强型LLMs的内部推理过程，从而实现更细粒度的模型行为控制。该方法在多项任务上表现出色，包括IFEval和Overthinking上的指令遵循准确率提升6.7%、SEP上的指令层次推理改善15.4%，以及XSTest和SorryBench上的安全对齐拒绝率提高40.0%。实验结果表明，该范式使用DeepSeek R1等开源模型显著优于基线提示方法，并为控制推理LLMs开辟了新的研究方向。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.24370v3",
      "published_date": "2025-03-31 17:50:13 UTC",
      "updated_date": "2025-05-21 17:51:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:53:44.024509"
    },
    {
      "arxiv_id": "2503.24365v1",
      "title": "Which LIME should I trust? Concepts, Challenges, and Solutions",
      "title_zh": "我应该信任哪个 LIME？ 概念、挑战和解决方案",
      "authors": [
        "Patrick Knab",
        "Sascha Marton",
        "Udo Schlegel",
        "Christian Bartelt"
      ],
      "abstract": "As neural networks become dominant in essential systems, Explainable\nArtificial Intelligence (XAI) plays a crucial role in fostering trust and\ndetecting potential misbehavior of opaque models. LIME (Local Interpretable\nModel-agnostic Explanations) is among the most prominent model-agnostic\napproaches, generating explanations by approximating the behavior of black-box\nmodels around specific instances. Despite its popularity, LIME faces challenges\nrelated to fidelity, stability, and applicability to domain-specific problems.\nNumerous adaptations and enhancements have been proposed to address these\nissues, but the growing number of developments can be overwhelming,\ncomplicating efforts to navigate LIME-related research. To the best of our\nknowledge, this is the first survey to comprehensively explore and collect\nLIME's foundational concepts and known limitations. We categorize and compare\nits various enhancements, offering a structured taxonomy based on intermediate\nsteps and key issues. Our analysis provides a holistic overview of advancements\nin LIME, guiding future research and helping practitioners identify suitable\napproaches. Additionally, we provide a continuously updated interactive website\n(https://patrick-knab.github.io/which-lime-to-trust/), offering a concise and\naccessible overview of the survey.",
      "tldr_zh": "这篇论文探讨了Explainable Artificial Intelligence (XAI)中的LIME（Local Interpretable Model-agnostic Explanations）工具的核心概念、挑战和解决方案，旨在帮助用户评估其可信度。论文首次全面调查了LIME面临的fidelity（保真度）、稳定性（stability）和特定领域适用性等问题，并对各种增强方法进行了分类和比较，提供了一个基于中间步骤和关键问题的结构化分类法。研究为从业者提供了整体概述和指导未来研究的框架，同时推出一个持续更新的互动网站（https://patrick-knab.github.io/which-lime-to-trust/），便于快速访问相关信息。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at the 3rd World Conference on eXplainable Artificial\n  Intelligence (XAI 2025)",
      "pdf_url": "http://arxiv.org/pdf/2503.24365v1",
      "published_date": "2025-03-31 17:44:39 UTC",
      "updated_date": "2025-03-31 17:44:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:53:56.500090"
    },
    {
      "arxiv_id": "2503.24361v2",
      "title": "Sim-and-Real Co-Training: A Simple Recipe for Vision-Based Robotic Manipulation",
      "title_zh": "翻译失败",
      "authors": [
        "Abhiram Maddukuri",
        "Zhenyu Jiang",
        "Lawrence Yunliang Chen",
        "Soroush Nasiriany",
        "Yuqi Xie",
        "Yu Fang",
        "Wenqi Huang",
        "Zu Wang",
        "Zhenjia Xu",
        "Nikita Chernyadev",
        "Scott Reed",
        "Ken Goldberg",
        "Ajay Mandlekar",
        "Linxi Fan",
        "Yuke Zhu"
      ],
      "abstract": "Large real-world robot datasets hold great potential to train generalist\nrobot models, but scaling real-world human data collection is time-consuming\nand resource-intensive. Simulation has great potential in supplementing\nlarge-scale data, especially with recent advances in generative AI and\nautomated data generation tools that enable scalable creation of robot behavior\ndatasets. However, training a policy solely in simulation and transferring it\nto the real world often demands substantial human effort to bridge the reality\ngap. A compelling alternative is to co-train the policy on a mixture of\nsimulation and real-world datasets. Preliminary studies have recently shown\nthis strategy to substantially improve the performance of a policy over one\ntrained on a limited amount of real-world data. Nonetheless, the community\nlacks a systematic understanding of sim-and-real co-training and what it takes\nto reap the benefits of simulation data for real-robot learning. This work\npresents a simple yet effective recipe for utilizing simulation data to solve\nvision-based robotic manipulation tasks. We derive this recipe from\ncomprehensive experiments that validate the co-training strategy on various\nsimulation and real-world datasets. Using two domains--a robot arm and a\nhumanoid--across diverse tasks, we demonstrate that simulation data can enhance\nreal-world task performance by an average of 38%, even with notable differences\nbetween the simulation and real-world data. Videos and additional results can\nbe found at https://co-training.github.io/",
      "tldr_zh": "本研究提出了一种简单有效的“sim-and-real co-training”策略，用于提升视觉-based机器人操作任务的性能。该方法通过在模拟数据集和真实数据集上共同训练政策，利用生成AI和自动化工具生成可扩展的模拟数据，从而缓解真实数据收集的资源限制。实验在机器人臂和人形机器人等域上进行，结果显示，即使模拟和真实数据存在显著差异，这种策略也能平均提高38%的真实任务性能，为高效的机器人学习提供了实用配方。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Project website: https://co-training.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2503.24361v2",
      "published_date": "2025-03-31 17:39:38 UTC",
      "updated_date": "2025-04-02 16:40:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:54:07.024282"
    },
    {
      "arxiv_id": "2503.24358v1",
      "title": "SQuat: Subspace-orthogonal KV Cache Quantization",
      "title_zh": "SQuat：子空间正交 KV 缓存量化",
      "authors": [
        "Hao Wang",
        "Ligong Han",
        "Kai Xu",
        "Akash Srivastava"
      ],
      "abstract": "The key-value (KV) cache accelerates LLMs decoding by storing KV tensors from\npreviously generated tokens. It reduces redundant computation at the cost of\nincreased memory usage. To mitigate this overhead, existing approaches compress\nKV tensors into lower-bit representations; however, quantization errors can\naccumulate as more tokens are generated, potentially resulting in undesired\noutputs. In this paper, we introduce SQuat (Subspace-orthogonal KV cache\nquantization). It first constructs a subspace spanned by query tensors to\ncapture the most critical task-related information. During key tensor\nquantization, it enforces that the difference between the (de)quantized and\noriginal keys remains orthogonal to this subspace, minimizing the impact of\nquantization errors on the attention mechanism's outputs. SQuat requires no\nmodel fine-tuning, no additional calibration dataset for offline learning, and\nis grounded in a theoretical framework we develop. Through numerical\nexperiments, we show that our method reduces peak memory by 2.17 to 2.82,\nimproves throughput by 2.45 to 3.60, and achieves more favorable benchmark\nscores than existing KV cache quantization algorithms.",
      "tldr_zh": "该论文提出SQuat，一种基于子空间正交(Subspace-orthogonal)的方法，用于量化KV cache，以缓解大型语言模型(LLMs)解码过程中内存开销增加的问题。SQuat首先构建由查询张量跨越的子空间来捕捉关键任务信息，然后在量化关键张量时确保量化误差与该子空间正交，从而最小化对注意力机制输出的影响，且无需模型微调或额外校准数据集。实验结果显示，SQuat将峰值内存减少2.17至2.82倍，提高吞吐量2.45至3.60倍，并在基准测试中比现有KV cache量化算法表现更优。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.IT",
        "math.IT"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.24358v1",
      "published_date": "2025-03-31 17:37:32 UTC",
      "updated_date": "2025-03-31 17:37:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:54:19.457164"
    },
    {
      "arxiv_id": "2503.24354v2",
      "title": "ORAL: Prompting Your Large-Scale LoRAs via Conditional Recurrent Diffusion",
      "title_zh": "翻译失败",
      "authors": [
        "Rana Muhammad Shahroz Khan",
        "Dongwen Tang",
        "Pingzhi Li",
        "Kai Wang",
        "Tianlong Chen"
      ],
      "abstract": "Parameter generation has emerged as a novel paradigm for neural network\ndevelopment, offering an alternative to traditional neural network training by\nsynthesizing high-quality model weights directly. In the context of Low-Rank\nAdaptation (LoRA) for evolving ($\\textit{i.e.}$, constantly updated) large\nlanguage models (LLMs), this approach promises efficient adaptation without\ncostly retraining. However, existing methods face critical limitations in\nsimultaneously achieving scalability and controllability. In this paper, we\nintroduce $\\texttt{ORAL}$, a novel $\\textbf{conditional recurrent diffusion}$\nframework that addresses these challenges. $\\texttt{ORAL}$ incorporates a novel\nconditioning mechanism that integrates model architecture and textual task\nspecifications, enabling the generation of task-specific LoRA parameters that\ncan seamlessly transfer across evolving foundation models. Our approach\nsuccessfully scales to billions-of-parameter LLMs and maintains\ncontrollability. Through extensive experiments across seven language tasks,\nfour vision tasks, and three multimodal tasks using five pre-trained LLMs, we\ndemonstrate that $\\texttt{ORAL}$ generates high-quality LoRA parameters that\nachieve comparable or superior performance to vanilla trained counterparts.",
      "tldr_zh": "该论文提出 ORAL，一种基于条件循环扩散（Conditional Recurrent Diffusion）的框架，用于生成大规模 Low-Rank Adaptation (LoRA) 参数，以替代传统训练方法，实现高效适应不断更新的大型语言模型 (LLMs)。ORAL 引入了一个创新的条件机制，将模型架构和文本任务规范整合，从而确保参数生成的可扩展性（适用于数十亿参数模型）和可控性，并支持在不同基础模型间的无缝转移。通过在七个语言任务、四个视觉任务和三个多模态任务上的实验，使用五个预训练 LLMs，ORAL 生成的 LoRA 参数显示出与传统训练相当或更优的性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.24354v2",
      "published_date": "2025-03-31 17:34:59 UTC",
      "updated_date": "2025-04-08 18:38:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:54:32.155598"
    },
    {
      "arxiv_id": "2503.24328v1",
      "title": "Contextual Preference Collaborative Measure Framework Based on Belief System",
      "title_zh": "基于信念系统的情境偏好协作测量框架",
      "authors": [
        "Hang Yu",
        "Wei Wei",
        "Zheng Tan",
        "Jing-lei Liu"
      ],
      "abstract": "To reduce the human intervention in the preference measure process,this\narticle proposes a preference collaborative measure framework based on an\nupdated belief system,which is also capable of improving the accuracy and\nefficiency of preferen-ce measure algorithms.Firstly,the distance of rules and\nthe average internal distance of rulesets are proposed for specifying the\nrelationship between the rules.For discovering the most representative\npreferences that are common in all users,namely common preference,a algorithm\nbased on average internal distance of ruleset,PRA algorithm,is proposed,which\naims to finish the discoveryprocess with minimum information loss\nrate.Furthermore,the concept of Common belief is proposed to update the belief\nsystem,and the common preferences are the evidences of updated belief\nsystem.Then,under the belief system,the proposed belief degree and deviation\ndegree are used to determine whether a rule confirms the belief system or not\nand classify the preference rules into two kinds(generalized or\npersonalized),and eventually filters out Top-K interesting rules relying on\nbelief degree and deviation degree.Based on above,a scalable interestingness\ncalculation framework that can apply various formulas is proposed for\naccurately calculating interestingness in different conditions.At last,IMCos\nalgorithm and IMCov algorithm are proposed as exemplars to verify the accuracy\nand efficiency of the framework by using weighted cosine similarity and\ncorrelation coefficients as belief degree.In experiments,the proposed\nalgorithms are compared to two state-of-the-art algorithms and the results show\nthat IMCos and IMCov outperform than the other two in most aspects.",
      "tldr_zh": "这篇论文提出了一种基于更新 Belief System 的 Contextual Preference Collaborative Measure Framework，旨在减少人类干预并提升偏好测量的准确性和效率。框架引入规则距离和规则集的平均内部距离来定义规则关系，提出 PRA algorithm 用于发现 Common Preference，以最小化信息损失率，并通过 Common Belief 更新信念系统。利用 Belief Degree 和 Deviation Degree 分类规则（generalized 或 personalized）并筛选 Top-K 有趣规则，该框架支持可扩展的趣味性计算公式；实验结果显示，IMCos 和 IMCov algorithms 在大多数方面优于现有最先进算法。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "in Chinese language",
      "pdf_url": "http://arxiv.org/pdf/2503.24328v1",
      "published_date": "2025-03-31 17:17:45 UTC",
      "updated_date": "2025-03-31 17:17:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:54:44.818378"
    },
    {
      "arxiv_id": "2503.24325v1",
      "title": "Pro-Routing: Proactive Routing of Autonomous Multi-Capacity Robots for Pickup-and-Delivery Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Daniel Garces",
        "Stephanie Gil"
      ],
      "abstract": "We consider a multi-robot setting, where we have a fleet of multi-capacity\nautonomous robots that must service spatially distributed pickup-and-delivery\nrequests with fixed maximum wait times. Requests can be either scheduled ahead\nof time or they can enter the system in real-time. In this setting, stability\nfor a routing policy is defined as the cost of the policy being uniformly\nbounded over time. Most previous work either solve the problem offline to\ntheoretically maintain stability or they consider dynamically arriving requests\nat the expense of the theoretical guarantees on stability. In this paper, we\naim to bridge this gap by proposing a novel proactive rollout-based routing\nframework that adapts to real-time demand while still provably maintaining the\nstability of the learned routing policy. We derive provable stability\nguarantees for our method by proposing a fleet sizing algorithm that obtains a\nsufficiently large fleet that ensures stability by construction. To validate\nour theoretical results, we consider a case study on real ride requests for\nHarvard's evening Van System. We also evaluate the performance of our framework\nusing the currently deployed smaller fleet size. In this smaller setup, we\ncompare against the currently deployed routing algorithm, greedy heuristics,\nand Monte-Carlo-Tree-Search-based algorithms. Our empirical results show that\nour framework maintains stability when we use the sufficiently large fleet size\nfound in our theoretical results. For the smaller currently deployed fleet\nsize, our method services 6% more requests than the closest baseline while\nreducing median passenger wait times by 33%.",
      "tldr_zh": "本文提出 Pro-Routing 框架，一种主动的 rollout-based 路由方法，用于管理多容量自主机器人的取送货任务，该框架能适应实时或预先安排的请求，同时通过 fleet sizing 算法确保路由策略的稳定性。相比现有方法，该框架在理论上提供可证明的稳定性保证，并在哈佛大学晚间班车系统真实案例中验证。实验结果显示，使用较小舰队时，Pro-Routing 比基线算法多服务6%的请求，并将中位数乘客等待时间减少33%。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.RO",
      "comment": "25 pages, 7 figures, and 1 table",
      "pdf_url": "http://arxiv.org/pdf/2503.24325v1",
      "published_date": "2025-03-31 17:14:07 UTC",
      "updated_date": "2025-03-31 17:14:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:54:56.216456"
    },
    {
      "arxiv_id": "2503.24310v1",
      "title": "BEATS: Bias Evaluation and Assessment Test Suite for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Alok Abhishek",
        "Lisa Erickson",
        "Tushar Bandopadhyay"
      ],
      "abstract": "In this research, we introduce BEATS, a novel framework for evaluating Bias,\nEthics, Fairness, and Factuality in Large Language Models (LLMs). Building upon\nthe BEATS framework, we present a bias benchmark for LLMs that measure\nperformance across 29 distinct metrics. These metrics span a broad range of\ncharacteristics, including demographic, cognitive, and social biases, as well\nas measures of ethical reasoning, group fairness, and factuality related\nmisinformation risk. These metrics enable a quantitative assessment of the\nextent to which LLM generated responses may perpetuate societal prejudices that\nreinforce or expand systemic inequities. To achieve a high score on this\nbenchmark a LLM must show very equitable behavior in their responses, making it\na rigorous standard for responsible AI evaluation. Empirical results based on\ndata from our experiment show that, 37.65\\% of outputs generated by industry\nleading models contained some form of bias, highlighting a substantial risk of\nusing these models in critical decision making systems. BEATS framework and\nbenchmark offer a scalable and statistically rigorous methodology to benchmark\nLLMs, diagnose factors driving biases, and develop mitigation strategies. With\nthe BEATS framework, our goal is to help the development of more socially\nresponsible and ethically aligned AI models.",
      "tldr_zh": "本文介绍了 BEATS 框架，一种用于评估 Large Language Models (LLMs) 中的 Bias、Ethics、Fairness 和 Factuality 的新型工具。该框架构建了一个涵盖 29 个指标的偏见基准，包括 demographic、cognitive 和 social biases，以及 ethical reasoning、group fairness 和 factuality related misinformation risk，从而量化 LLM 输出是否强化社会偏见。实验结果显示，行业领先模型的输出中有 37.65% 包含某种偏见，突显其在关键决策系统中的风险；BEATS 提供可扩展的统计方法，帮助诊断偏见驱动因素、开发缓解策略，并促进更负责任和道德对齐的 AI 模型发展。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "68T01 (Primary), 68T50 (Secondary)",
        "I.2.0; I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "32 pages, 33 figures, preprint version",
      "pdf_url": "http://arxiv.org/pdf/2503.24310v1",
      "published_date": "2025-03-31 16:56:52 UTC",
      "updated_date": "2025-03-31 16:56:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:55:09.053023"
    },
    {
      "arxiv_id": "2503.24307v1",
      "title": "A Systematic Evaluation of LLM Strategies for Mental Health Text Analysis: Fine-tuning vs. Prompt Engineering vs. RAG",
      "title_zh": "LLM ",
      "authors": [
        "Arshia Kermani",
        "Veronica Perez-Rosas",
        "Vangelis Metsis"
      ],
      "abstract": "This study presents a systematic comparison of three approaches for the\nanalysis of mental health text using large language models (LLMs): prompt\nengineering, retrieval augmented generation (RAG), and fine-tuning. Using LLaMA\n3, we evaluate these approaches on emotion classification and mental health\ncondition detection tasks across two datasets. Fine-tuning achieves the highest\naccuracy (91% for emotion classification, 80% for mental health conditions) but\nrequires substantial computational resources and large training sets, while\nprompt engineering and RAG offer more flexible deployment with moderate\nperformance (40-68% accuracy). Our findings provide practical insights for\nimplementing LLM-based solutions in mental health applications, highlighting\nthe trade-offs between accuracy, computational requirements, and deployment\nflexibility.",
      "tldr_zh": "这篇论文系统比较了使用大型语言模型（LLMs）分析心理健康文本的三种策略：prompt engineering、retrieval augmented generation (RAG) 和 fine-tuning。利用 LLaMA 3 模型，在情感分类和心理健康状况检测任务上进行评估，结果显示 fine-tuning 取得了最高准确率（情感分类91%、心理健康条件80%），但需要大量计算资源和训练数据。相比之下，prompt engineering 和 RAG 提供更灵活的部署选项，准确率在40-68%，论文强调了这些方法在准确率、计算需求和部署灵活性之间的权衡，为心理健康应用中的 LLM 解决方案提供了实用见解。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.24307v1",
      "published_date": "2025-03-31 16:54:04 UTC",
      "updated_date": "2025-03-31 16:54:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:55:20.770869"
    },
    {
      "arxiv_id": "2503.24305v3",
      "title": "Evaluating machine learning models for predicting pesticides toxicity to honey bees",
      "title_zh": "翻译失败",
      "authors": [
        "Jakub Adamczyk",
        "Jakub Poziemski",
        "Pawel Siedlecki"
      ],
      "abstract": "Small molecules play a critical role in the biomedical, environmental, and\nagrochemical domains, each with distinct physicochemical requirements and\nsuccess criteria. Although biomedical research benefits from extensive datasets\nand established benchmarks, agrochemical data remain scarce, particularly with\nrespect to species-specific toxicity. This work focuses on ApisTox, the most\ncomprehensive dataset of experimentally validated chemical toxicity to the\nhoney bee (Apis mellifera), an ecologically vital pollinator. We evaluate\nApisTox using a diverse suite of machine learning approaches, including\nmolecular fingerprints, graph kernels, and graph neural networks, as well as\npretrained models. Comparative analysis with medicinal datasets from the\nMoleculeNet benchmark reveals that ApisTox represents a distinct chemical\nspace. Performance degradation on non-medicinal datasets, such as ApisTox,\ndemonstrates their limited generalizability of current state-of-the-art\nalgorithms trained solely on biomedical data. Our study highlights the need for\nmore diverse datasets and for targeted model development geared toward the\nagrochemical domain.",
      "tldr_zh": "该研究评估了各种机器学习模型在预测农药对蜜蜂（Apis mellifera）毒性方面的性能，使用了ApisTox数据集，这是目前关于蜜蜂化学毒性的最全面实验验证数据集。研究方法包括分子指纹、图核、图神经网络以及预训练模型，并将ApisTox与MoleculeNet的生物医学数据集进行比较分析。结果表明，ApisTox代表了独特的化学空间，导致基于生物医学数据训练的模型在非生物医学数据集上性能显著下降。该研究突出了开发更多样化数据集和针对农业化学领域的模型的重要性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.24305v3",
      "published_date": "2025-03-31 16:51:12 UTC",
      "updated_date": "2025-04-10 09:38:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:55:32.385009"
    },
    {
      "arxiv_id": "2503.24299v1",
      "title": "Shape Expressions with Inheritance",
      "title_zh": "翻译失败",
      "authors": [
        "Iovka Boneva",
        "Jose Emilio Labra Gayo",
        "Eric Prud'hommeaux",
        "Katherine Thornton",
        "Andra Waagmeester"
      ],
      "abstract": "We formally introduce an inheritance mechanism for the Shape Expressions\nlanguage (ShEx). It is inspired by inheritance in object-oriented programming\nlanguages, and provides similar advantages such as reuse, modularity, and more\nflexible data modelling. Using an example, we explain the main features of the\ninheritance mechanism. We present its syntax and formal semantics. The\nsemantics is an extension of the semantics of ShEx 2.1. It also directly yields\na validation algorithm as an extension of the previous ShEx validation\nalgorithms, while maintaining the same algorithmic complexity.",
      "tldr_zh": "本文正式引入了 Shape Expressions (ShEx) 语言的继承机制，借鉴面向对象编程语言的继承设计，以实现代码重用、模块化和更灵活的数据建模。作者通过示例阐述了该机制的主要特征，并定义了其语法和形式语义，作为 ShEx 2.1 语义的扩展。结果表明，该机制直接支持验证算法的改进，同时维持了原有算法的复杂度。",
      "categories": [
        "cs.DB",
        "cs.AI"
      ],
      "primary_category": "cs.DB",
      "comment": "Accepted in Extended Semantic Web Conference, ESWC, 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.24299v1",
      "published_date": "2025-03-31 16:42:44 UTC",
      "updated_date": "2025-03-31 16:42:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:55:43.119874"
    },
    {
      "arxiv_id": "2503.24284v1",
      "title": "Value of Information-based Deceptive Path Planning Under Adversarial Interventions",
      "title_zh": "基于信息价值的欺骗性路径规划在对抗性干预下",
      "authors": [
        "Wesley A. Suttle",
        "Jesse Milzman",
        "Mustafa O. Karabag",
        "Brian M. Sadler",
        "Ufuk Topcu"
      ],
      "abstract": "Existing methods for deceptive path planning (DPP) address the problem of\ndesigning paths that conceal their true goal from a passive, external observer.\nSuch methods do not apply to problems where the observer has the ability to\nperform adversarial interventions to impede the path planning agent. In this\npaper, we propose a novel Markov decision process (MDP)-based model for the DPP\nproblem under adversarial interventions and develop new value of information\n(VoI) objectives to guide the design of DPP policies. Using the VoI objectives\nwe propose, path planning agents deceive the adversarial observer into choosing\nsuboptimal interventions by selecting trajectories that are of low\ninformational value to the observer. Leveraging connections to the linear\nprogramming theory for MDPs, we derive computationally efficient solution\nmethods for synthesizing policies for performing DPP under adversarial\ninterventions. In our experiments, we illustrate the effectiveness of the\nproposed solution method in achieving deceptiveness under adversarial\ninterventions and demonstrate the superior performance of our approach to both\nexisting DPP methods and conservative path planning approaches on illustrative\ngridworld problems.",
      "tldr_zh": "本研究针对欺骗路径规划 (DPP) 问题，提出了一种新的 Markov Decision Process (MDP) 模型，以应对敌对观察者可能进行干预的情况。研究开发了基于 Value of Information (VoI) 的目标函数，指导路径规划代理通过选择低信息价值的轨迹来欺骗观察者，使其选择次优干预策略。利用 MDP 的线性规划理论，作者设计了高效的策略合成方法，并在网格世界实验中证明，该方法在敌对干预下显著优于现有 DPP 方法和保守路径规划方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.24284v1",
      "published_date": "2025-03-31 16:31:29 UTC",
      "updated_date": "2025-03-31 16:31:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:55:55.704788"
    },
    {
      "arxiv_id": "2503.24278v2",
      "title": "AutoEval: Autonomous Evaluation of Generalist Robot Manipulation Policies in the Real World",
      "title_zh": "翻译失败",
      "authors": [
        "Zhiyuan Zhou",
        "Pranav Atreya",
        "You Liang Tan",
        "Karl Pertsch",
        "Sergey Levine"
      ],
      "abstract": "Scalable and reproducible policy evaluation has been a long-standing\nchallenge in robot learning. Evaluations are critical to assess progress and\nbuild better policies, but evaluation in the real world, especially at a scale\nthat would provide statistically reliable results, is costly in terms of human\ntime and hard to obtain. Evaluation of increasingly generalist robot policies\nrequires an increasingly diverse repertoire of evaluation environments, making\nthe evaluation bottleneck even more pronounced. To make real-world evaluation\nof robotic policies more practical, we propose AutoEval, a system to\nautonomously evaluate generalist robot policies around the clock with minimal\nhuman intervention. Users interact with AutoEval by submitting evaluation jobs\nto the AutoEval queue, much like how software jobs are submitted with a cluster\nscheduling system, and AutoEval will schedule the policies for evaluation\nwithin a framework supplying automatic success detection and automatic scene\nresets. We show that AutoEval can nearly fully eliminate human involvement in\nthe evaluation process, permitting around the clock evaluations, and the\nevaluation results correspond closely to ground truth evaluations conducted by\nhand. To facilitate the evaluation of generalist policies in the robotics\ncommunity, we provide public access to multiple AutoEval scenes in the popular\nBridgeData robot setup with WidowX robot arms. In the future, we hope that\nAutoEval scenes can be set up across institutions to form a diverse and\ndistributed evaluation network.",
      "tldr_zh": "该论文针对机器人学习中政策评估的挑战，提出 AutoEval 系统，用于在真实世界中自主评估 generalist robot manipulation policies，从而减少人为干预和成本。AutoEval 允许用户提交评估任务，系统自动调度、检测成功并重置场景，实现全天候评估。实验结果显示，AutoEval 的评估结果与人工评估高度一致，并提供公开访问的多个评估场景；未来有望扩展到分布式评估网络，促进机器人社区的协作。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.24278v2",
      "published_date": "2025-03-31 16:23:44 UTC",
      "updated_date": "2025-04-02 20:24:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:56:07.817305"
    },
    {
      "arxiv_id": "2503.24277v1",
      "title": "Evaluating and Designing Sparse Autoencoders by Approximating Quasi-Orthogonality",
      "title_zh": "翻译失败",
      "authors": [
        "Sewoong Lee",
        "Adam Davies",
        "Marc E. Canby",
        "Julia Hockenmaier"
      ],
      "abstract": "Sparse autoencoders (SAEs) have emerged as a workhorse of modern mechanistic\ninterpretability, but leading SAE approaches with top-$k$ style activation\nfunctions lack theoretical grounding for selecting the hyperparameter $k$. SAEs\nare based on the linear representation hypothesis (LRH), which assumes that the\nrepresentations of large language models (LLMs) are linearly encoded, and the\nsuperposition hypothesis (SH), which states that there can be more features in\nthe model than its dimensionality. We show that, based on the formal\ndefinitions of the LRH and SH, the magnitude of sparse feature vectors (the\nlatent representations learned by SAEs of the dense embeddings of LLMs) can be\napproximated using their corresponding dense vector with a closed-form error\nbound. To visualize this, we propose the ZF plot, which reveals a previously\nunknown relationship between LLM hidden embeddings and SAE feature vectors,\nallowing us to make the first empirical measurement of the extent to which\nfeature vectors of pre-trained SAEs are over- or under-activated for a given\ninput. Correspondingly, we introduce Approximate Feature Activation (AFA),\nwhich approximates the magnitude of the ground-truth sparse feature vector, and\npropose a new evaluation metric derived from AFA to assess the alignment\nbetween inputs and activations. We also leverage AFA to introduce a novel SAE\narchitecture, the top-AFA SAE, leading to SAEs that: (a) are more in line with\ntheoretical justifications; and (b) obviate the need to tune SAE sparsity\nhyperparameters. Finally, we empirically demonstrate that top-AFA SAEs achieve\nreconstruction loss comparable to that of state-of-the-art top-k SAEs, without\nrequiring the hyperparameter $k$ to be tuned. Our code is available at:\nhttps://github.com/SewoongLee/top-afa-sae.",
      "tldr_zh": "本论文评估和设计稀疏自编码器（SAEs），通过近似准正交性解决现有top-k激活函数在选择超参数k时缺乏理论基础的问题。基于线性表示假设（LRH）和叠加假设（SH），作者推导出SAEs特征向量的幅度近似公式，并提供封闭形式的误差边界，同时引入ZF图来可视化LLM隐藏嵌入与SAE特征向量之间的关系，以首次测量特征激活程度。论文提出Approximate Feature Activation (AFA)作为新评估指标，并基于此开发top-AFA SAE架构，该架构更符合理论要求，且无需调整稀疏超参数。实验结果显示，top-AFA SAEs的重建损失与最先进top-k SAEs相当，同时提升了模型的实用性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.24277v1",
      "published_date": "2025-03-31 16:22:11 UTC",
      "updated_date": "2025-03-31 16:22:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:56:20.694317"
    },
    {
      "arxiv_id": "2503.24270v2",
      "title": "Visual Acoustic Fields",
      "title_zh": "视觉声学场",
      "authors": [
        "Yuelei Li",
        "Hyunjin Kim",
        "Fangneng Zhan",
        "Ri-Zhao Qiu",
        "Mazeyu Ji",
        "Xiaojun Shan",
        "Xueyan Zou",
        "Paul Liang",
        "Hanspeter Pfister",
        "Xiaolong Wang"
      ],
      "abstract": "Objects produce different sounds when hit, and humans can intuitively infer\nhow an object might sound based on its appearance and material properties.\nInspired by this intuition, we propose Visual Acoustic Fields, a framework that\nbridges hitting sounds and visual signals within a 3D space using 3D Gaussian\nSplatting (3DGS). Our approach features two key modules: sound generation and\nsound localization. The sound generation module leverages a conditional\ndiffusion model, which takes multiscale features rendered from a\nfeature-augmented 3DGS to generate realistic hitting sounds. Meanwhile, the\nsound localization module enables querying the 3D scene, represented by the\nfeature-augmented 3DGS, to localize hitting positions based on the sound\nsources. To support this framework, we introduce a novel pipeline for\ncollecting scene-level visual-sound sample pairs, achieving alignment between\ncaptured images, impact locations, and corresponding sounds. To the best of our\nknowledge, this is the first dataset to connect visual and acoustic signals in\na 3D context. Extensive experiments on our dataset demonstrate the\neffectiveness of Visual Acoustic Fields in generating plausible impact sounds\nand accurately localizing impact sources. Our project page is at\nhttps://yuelei0428.github.io/projects/Visual-Acoustic-Fields/.",
      "tldr_zh": "本研究提出 Visual Acoustic Fields 框架，使用 3D Gaussian Splatting (3DGS) 在 3D 空间中桥接物体击打声音与视觉信号，灵感来源于人类基于物体外观推断声音的直觉。框架包括两个关键模块：声音生成模块，利用条件扩散模型（conditional diffusion model）基于多尺度特征渲染生成逼真的击打声音，以及声音定位模块，通过查询特征增强的 3DGS 来定位击打位置。研究者引入了一个新颖的管道来收集场景级视觉-声音样本对，这是首个在 3D 上下文中连接视觉和声学信号的数据集；实验结果显示，该框架在数据集上能有效生成可信的冲击声音并准确定位来源。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.24270v2",
      "published_date": "2025-03-31 16:16:10 UTC",
      "updated_date": "2025-04-01 03:16:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:56:32.423804"
    },
    {
      "arxiv_id": "2504.00065v1",
      "title": "Assessing Code Understanding in LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Cosimo Laneve",
        "Alvise Spanò",
        "Dalila Ressi",
        "Sabina Rossi",
        "Michele Bugliesi"
      ],
      "abstract": "We present an empirical evaluation of Large Language Models in code\nunderstanding associated with non-trivial, semantic-preserving program\ntransformations such as copy propagation or constant folding. Our findings show\nthat LLMs fail to judge semantic equivalence in approximately 41\\% of cases\nwhen no context is provided and in 29\\% when given a simple generic context. To\nimprove accuracy, we advocate integrating LLMs with code-optimization tools to\nenhance training and facilitate more robust program understanding.",
      "tldr_zh": "本研究评估了大型语言模型（LLMs）在代码理解方面的表现，特别是针对非平凡的语义保持程序转换，如 copy propagation 或 constant folding。结果显示，LLMs 在没有上下文时，无法正确判断语义等价性的比例约为41%，即使提供简单通用的上下文，这一比例仍高达29%。为了提升准确性，论文建议将LLMs与代码优化工具整合，以改进训练过程并实现更稳健的程序理解。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.PL"
      ],
      "primary_category": "cs.SE",
      "comment": "22 page, 7 tables, submitted at FORTE 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.00065v1",
      "published_date": "2025-03-31 16:08:58 UTC",
      "updated_date": "2025-03-31 16:08:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:56:42.845151"
    },
    {
      "arxiv_id": "2503.24262v1",
      "title": "New Statistical Framework for Extreme Error Probability in High-Stakes Domains for Reliable Machine Learning",
      "title_zh": "一种用于高风险领域极端错误概率的新统计框架，以实现可靠",
      "authors": [
        "Umberto Michelucci",
        "Francesca Venturini"
      ],
      "abstract": "Machine learning is vital in high-stakes domains, yet conventional validation\nmethods rely on averaging metrics like mean squared error (MSE) or mean\nabsolute error (MAE), which fail to quantify extreme errors. Worst-case\nprediction failures can have substantial consequences, but current frameworks\nlack statistical foundations for assessing their probability. In this work a\nnew statistical framework, based on Extreme Value Theory (EVT), is presented\nthat provides a rigorous approach to estimating worst-case failures. Applying\nEVT to synthetic and real-world datasets, this method is shown to enable robust\nestimation of catastrophic failure probabilities, overcoming the fundamental\nlimitations of standard cross-validation. This work establishes EVT as a\nfundamental tool for assessing model reliability, ensuring safer AI deployment\nin new technologies where uncertainty quantification is central to\ndecision-making or scientific analysis.",
      "tldr_zh": "本研究针对机器学习在高风险领域（如决策或科学分析）中的极端错误问题，指出传统指标如 mean squared error (MSE) 和 mean absolute error (MAE) 无法有效量化最坏情况失败概率。作者提出一个基于 Extreme Value Theory (EVT) 的新统计框架，通过 rigorous 评估方法在合成和真实数据集上robustly 估计灾难性失败概率，从而克服标准交叉验证的局限。实验结果显示，该框架显著提升了模型可靠性，为确保 AI 在不确定性高的应用场景中安全部署提供了基础。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ME",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.24262v1",
      "published_date": "2025-03-31 16:08:11 UTC",
      "updated_date": "2025-03-31 16:08:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:56:56.456983"
    },
    {
      "arxiv_id": "2503.24258v1",
      "title": "Beyond a Single Mode: GAN Ensembles for Diverse Medical Data Generation",
      "title_zh": "超越单一模式：GAN 集成用于多样化医疗数据生成",
      "authors": [
        "Lorenzo Tronchin",
        "Tommy Löfstedt",
        "Paolo Soda",
        "Valerio Guarrasi"
      ],
      "abstract": "The advancement of generative AI, particularly in medical imaging, confronts\nthe trilemma of ensuring high fidelity, diversity, and efficiency in synthetic\ndata generation. While Generative Adversarial Networks (GANs) have shown\npromise across various applications, they still face challenges like mode\ncollapse and insufficient coverage of real data distributions. This work\nexplores the use of GAN ensembles to overcome these limitations, specifically\nin the context of medical imaging. By solving a multi-objective optimisation\nproblem that balances fidelity and diversity, we propose a method for selecting\nan optimal ensemble of GANs tailored for medical data. The selected ensemble is\ncapable of generating diverse synthetic medical images that are representative\nof true data distributions and computationally efficient. Each model in the\nensemble brings a unique contribution, ensuring minimal redundancy. We\nconducted a comprehensive evaluation using three distinct medical datasets,\ntesting 22 different GAN architectures with various loss functions and\nregularisation techniques. By sampling models at different training epochs, we\ncrafted 110 unique configurations. The results highlight the capability of GAN\nensembles to enhance the quality and utility of synthetic medical images,\nthereby improving the efficacy of downstream tasks such as diagnostic\nmodelling.",
      "tldr_zh": "本研究探讨了使用 GAN ensembles 来解决生成式 AI 在医疗成像中的挑战，特别是模式崩溃和无法覆盖真实数据分布的问题。通过多目标优化问题来平衡保真度和多样性，该方法选择最优的 GAN 集合，以生成多样化、高保真且计算高效的合成医疗图像。实验在三个医疗数据集上测试了 22 种 GAN 架构、各种损失函数和正则化技术，共创建 110 个独特配置，结果显示 GAN ensembles 显著提升了合成图像的质量和实用性，从而改善了下游任务如诊断建模的效能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.24258v1",
      "published_date": "2025-03-31 16:06:01 UTC",
      "updated_date": "2025-03-31 16:06:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:57:08.264423"
    },
    {
      "arxiv_id": "2503.24237v1",
      "title": "Spatio-temporal Prediction of Fine-Grained Origin-Destination Matrices with Applications in Ridesharing",
      "title_zh": "时空预测细粒度始发-目的地矩阵及其在共享乘车中的应用",
      "authors": [
        "Run Yang",
        "Runpeng Dai",
        "Siran Gao",
        "Xiaocheng Tang",
        "Fan Zhou",
        "Hongtu Zhu"
      ],
      "abstract": "Accurate spatial-temporal prediction of network-based travelers' requests is\ncrucial for the effective policy design of ridesharing platforms. Having\nknowledge of the total demand between various locations in the upcoming time\nslots enables platforms to proactively prepare adequate supplies, thereby\nincreasing the likelihood of fulfilling travelers' requests and redistributing\nidle drivers to areas with high potential demand to optimize the global\nsupply-demand equilibrium. This paper delves into the prediction of\nOrigin-Destination (OD) demands at a fine-grained spatial level, especially\nwhen confronted with an expansive set of local regions. While this task holds\nimmense practical value, it remains relatively unexplored within the research\ncommunity. To fill this gap, we introduce a novel prediction model called\nOD-CED, which comprises an unsupervised space coarsening technique to alleviate\ndata sparsity and an encoder-decoder architecture to capture both semantic and\ngeographic dependencies. Through practical experimentation, OD-CED has\ndemonstrated remarkable results. It achieved an impressive reduction of up to\n45% reduction in root-mean-square error and 60% in weighted mean absolute\npercentage error over traditional statistical methods when dealing with OD\nmatrices exhibiting a sparsity exceeding 90%.",
      "tldr_zh": "该论文针对共享出行平台，探讨了细粒度时空 Origin-Destination (OD) 矩阵的预测，以帮助平台优化供需平衡。研究引入了新型模型 OD-CED，包括一个无监督的空间粗化技术来缓解数据稀疏问题，以及一个编码器-解码器架构来捕捉语义和地理依赖，从而提升预测准确性。通过实验验证，OD-CED 在处理稀疏度超过90%的 OD 矩阵时，比传统统计方法降低了45%的 root-mean-square error 和60%的 weighted mean absolute percentage error，为共享出行平台的政策设计提供了实用工具。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.24237v1",
      "published_date": "2025-03-31 15:52:27 UTC",
      "updated_date": "2025-03-31 15:52:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:57:19.714232"
    },
    {
      "arxiv_id": "2503.24235v3",
      "title": "A Survey on Test-Time Scaling in Large Language Models: What, How, Where, and How Well?",
      "title_zh": "翻译失败",
      "authors": [
        "Qiyuan Zhang",
        "Fuyuan Lyu",
        "Zexu Sun",
        "Lei Wang",
        "Weixu Zhang",
        "Wenyue Hua",
        "Haolun Wu",
        "Zhihan Guo",
        "Yufei Wang",
        "Niklas Muennighoff",
        "Irwin King",
        "Xue Liu",
        "Chen Ma"
      ],
      "abstract": "As enthusiasm for scaling computation (data and parameters) in the\npretraining era gradually diminished, test-time scaling (TTS), also referred to\nas ``test-time computing'' has emerged as a prominent research focus. Recent\nstudies demonstrate that TTS can further elicit the problem-solving\ncapabilities of large language models (LLMs), enabling significant\nbreakthroughs not only in specialized reasoning tasks, such as mathematics and\ncoding, but also in general tasks like open-ended Q&A. However, despite the\nexplosion of recent efforts in this area, there remains an urgent need for a\ncomprehensive survey offering a systemic understanding. To fill this gap, we\npropose a unified, multidimensional framework structured along four core\ndimensions of TTS research: what to scale, how to scale, where to scale, and\nhow well to scale. Building upon this taxonomy, we conduct an extensive review\nof methods, application scenarios, and assessment aspects, and present an\norganized decomposition that highlights the unique functional roles of\nindividual techniques within the broader TTS landscape. From this analysis, we\ndistill the major developmental trajectories of TTS to date and offer hands-on\nguidelines for practical deployment. Furthermore, we identify several open\nchallenges and offer insights into promising future directions, including\nfurther scaling, clarifying the functional essence of techniques, generalizing\nto more tasks, and more attributions. Our repository is available on\nhttps://github.com/testtimescaling/testtimescaling.github.io/",
      "tldr_zh": "本调查论文探讨了Large Language Models (LLMs)中的Test-Time Scaling (TTS)，一种通过测试时计算增强模型问题解决能力的策略。论文提出一个统一的多维框架，涵盖四个核心维度：what to scale（什么缩放）、how to scale（如何缩放）、where to scale（在哪里缩放）和how well to scale（缩放效果如何），并对相关方法、应用场景（如数学、编码和开放式Q&A任务）和评估方面进行了全面回顾。研究发现，TTS能显著提升LLMs的表现，并总结了其发展轨迹及实际部署指南，同时指出了未来挑战，如进一步缩放、澄清技术本质和泛化到更多任务。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "v3: Expand Agentic and SFT Chapters. Build Website for better\n  visualization",
      "pdf_url": "http://arxiv.org/pdf/2503.24235v3",
      "published_date": "2025-03-31 15:46:15 UTC",
      "updated_date": "2025-05-04 15:48:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:57:32.452973"
    },
    {
      "arxiv_id": "2503.24228v1",
      "title": "PAARS: Persona Aligned Agentic Retail Shoppers",
      "title_zh": "翻译失败",
      "authors": [
        "Saab Mansour",
        "Leonardo Perelli",
        "Lorenzo Mainetti",
        "George Davidson",
        "Stefano D'Amato"
      ],
      "abstract": "In e-commerce, behavioral data is collected for decision making which can be\ncostly and slow. Simulation with LLM powered agents is emerging as a promising\nalternative for representing human population behavior. However, LLMs are known\nto exhibit certain biases, such as brand bias, review rating bias and limited\nrepresentation of certain groups in the population, hence they need to be\ncarefully benchmarked and aligned to user behavior. Ultimately, our goal is to\nsynthesise an agent population and verify that it collectively approximates a\nreal sample of humans. To this end, we propose a framework that: (i) creates\nsynthetic shopping agents by automatically mining personas from anonymised\nhistorical shopping data, (ii) equips agents with retail-specific tools to\nsynthesise shopping sessions and (iii) introduces a novel alignment suite\nmeasuring distributional differences between humans and shopping agents at the\ngroup (i.e. population) level rather than the traditional \"individual\" level.\nExperimental results demonstrate that using personas improves performance on\nthe alignment suite, though a gap remains to human behaviour. We showcase an\ninitial application of our framework for automated agentic A/B testing and\ncompare the findings to human results. Finally, we discuss applications,\nlimitations and challenges setting the stage for impactful future work.",
      "tldr_zh": "该研究提出 PAARS 框架，利用 LLM 驱动的代理模拟电商用户行为，以解决行为数据收集的成本和延迟问题，同时应对 LLM 的偏见，如品牌偏见和群体代表性不足。框架通过从匿名历史购物数据中自动挖掘 personas、为代理配备零售特定工具来合成购物会话，并引入一个新颖的 alignment suite，在群体级别测量人类和代理的分布差异。实验结果显示，使用 personas 显著改善了代理的表现，但与人类行为仍有差距；框架还应用于自动化代理 A/B testing，并讨论了其应用潜力、限制和未来挑战。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.24228v1",
      "published_date": "2025-03-31 15:41:51 UTC",
      "updated_date": "2025-03-31 15:41:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:57:43.931196"
    },
    {
      "arxiv_id": "2503.24219v1",
      "title": "MB-ORES: A Multi-Branch Object Reasoner for Visual Grounding in Remote Sensing",
      "title_zh": "翻译失败",
      "authors": [
        "Karim Radouane",
        "Hanane Azzag",
        "Mustapha lebbah"
      ],
      "abstract": "We propose a unified framework that integrates object detection (OD) and\nvisual grounding (VG) for remote sensing (RS) imagery. To support conventional\nOD and establish an intuitive prior for VG task, we fine-tune an open-set\nobject detector using referring expression data, framing it as a partially\nsupervised OD task. In the first stage, we construct a graph representation of\neach image, comprising object queries, class embeddings, and proposal\nlocations. Then, our task-aware architecture processes this graph to perform\nthe VG task. The model consists of: (i) a multi-branch network that integrates\nspatial, visual, and categorical features to generate task-aware proposals, and\n(ii) an object reasoning network that assigns probabilities across proposals,\nfollowed by a soft selection mechanism for final referring object localization.\nOur model demonstrates superior performance on the OPT-RSVG and DIOR-RSVG\ndatasets, achieving significant improvements over state-of-the-art methods\nwhile retaining classical OD capabilities. The code will be available in our\nrepository: \\url{https://github.com/rd20karim/MB-ORES}.",
      "tldr_zh": "该研究提出 MB-ORES，一种多分支物体推理框架，用于整合物体检测 (OD) 和视觉定位 (VG) 在遥感 (RS) 图像中的应用。该框架首先通过使用引用表达式数据微调开源检测器，并构建图像的图表示，包括物体查询、类别嵌入和提案位置；随后，利用多分支网络整合空间、视觉和类别特征生成任务感知提案，以及物体推理网络分配概率并通过软选择机制实现最终物体定位。在 OPT-RSVG 和 DIOR-RSVG 数据集上，MB-ORES 比现有方法显著提升性能，同时保留经典 OD 能力，相关代码将在 GitHub 仓库中发布。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.24219v1",
      "published_date": "2025-03-31 15:36:41 UTC",
      "updated_date": "2025-03-31 15:36:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:57:57.083214"
    },
    {
      "arxiv_id": "2503.24215v1",
      "title": "All You Need is Sally-Anne: ToM in AI Strongly Supported After Surpassing Tests for 3-Year-Olds",
      "title_zh": "翻译失败",
      "authors": [
        "Nitay Alon",
        "Joseph Barnby",
        "Reuth Mirsky",
        "Stefan Sarkadi"
      ],
      "abstract": "Theory of Mind (ToM) is a hallmark of human cognition, allowing individuals\nto reason about others' beliefs and intentions. Engineers behind recent\nadvances in Artificial Intelligence (AI) have claimed to demonstrate comparable\ncapabilities. This paper presents a model that surpasses traditional ToM tests\ndesigned for 3-year-old children, providing strong support for the presence of\nToM in AI systems.",
      "tldr_zh": "本文研究探讨了Theory of Mind (ToM)——一种人类认知标志，允许个体推理他人的信念和意图——在AI系统中的存在。论文提出一个AI模型，该模型超越了为3岁儿童设计的传统ToM测试（如Sally-Anne测试），证明了AI在这一领域的先进能力。该结果为AI系统具备ToM提供了强有力的支持，有助于推动AI在社会认知方面的应用。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.24215v1",
      "published_date": "2025-03-31 15:32:10 UTC",
      "updated_date": "2025-03-31 15:32:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:58:08.598399"
    },
    {
      "arxiv_id": "2503.24210v1",
      "title": "DiET-GS: Diffusion Prior and Event Stream-Assisted Motion Deblurring 3D Gaussian Splatting",
      "title_zh": "翻译失败",
      "authors": [
        "Seungjun Lee",
        "Gim Hee Lee"
      ],
      "abstract": "Reconstructing sharp 3D representations from blurry multi-view images are\nlong-standing problem in computer vision. Recent works attempt to enhance\nhigh-quality novel view synthesis from the motion blur by leveraging\nevent-based cameras, benefiting from high dynamic range and microsecond\ntemporal resolution. However, they often reach sub-optimal visual quality in\neither restoring inaccurate color or losing fine-grained details. In this\npaper, we present DiET-GS, a diffusion prior and event stream-assisted motion\ndeblurring 3DGS. Our framework effectively leverages both blur-free event\nstreams and diffusion prior in a two-stage training strategy. Specifically, we\nintroduce the novel framework to constraint 3DGS with event double integral,\nachieving both accurate color and well-defined details. Additionally, we\npropose a simple technique to leverage diffusion prior to further enhance the\nedge details. Qualitative and quantitative results on both synthetic and\nreal-world data demonstrate that our DiET-GS is capable of producing\nsignificantly better quality of novel views compared to the existing baselines.\nOur project page is https://diet-gs.github.io",
      "tldr_zh": "本文提出 DiET-GS 框架，利用 diffusion prior 和 event stream 辅助从模糊多视图图像中重建锐利的 3D Gaussian Splatting (3DGS)，以解决现有方法在颜色恢复和细节保留上的不足。框架采用两阶段训练策略：首先通过 event double integral 约束 3DGS，实现准确的颜色和精细细节；其次利用 diffusion prior 进一步增强边缘细节。实验结果显示，DiET-GS 在合成和真实数据上显著优于基线模型，提供更高质量的新视图合成。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR 2025. Project Page: https://diet-gs.github.io",
      "pdf_url": "http://arxiv.org/pdf/2503.24210v1",
      "published_date": "2025-03-31 15:27:07 UTC",
      "updated_date": "2025-03-31 15:27:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:58:20.593091"
    },
    {
      "arxiv_id": "2504.03729v1",
      "title": "A Scalable Predictive Modelling Approach to Identifying Duplicate Adverse Event Reports for Drugs and Vaccines",
      "title_zh": "一种可扩展的预测建模方法，用于识别药物和疫苗的不良事件报告的重复",
      "authors": [
        "Jim W. Barrett",
        "Nils Erlanson",
        "Joana Félix China",
        "G. Niklas Norén"
      ],
      "abstract": "The practice of pharmacovigilance relies on large databases of individual\ncase safety reports to detect and evaluate potential new causal associations\nbetween medicines or vaccines and adverse events. Duplicate reports are\nseparate and unlinked reports referring to the same case of an adverse event\ninvolving a specific patient at a certain time. They impede statistical\nanalysis and mislead clinical assessment. The large size of such databases\nprecludes a manual identification of duplicates, and so a computational method\nmust be employed. This paper builds upon a hitherto state of the art model,\nvigiMatch, modifying existing features and introducing new ones to target known\nshortcomings of the original model. Two support vector machine classifiers, one\nfor medicines and one for vaccines, classify report pairs as duplicates and\nnon-duplicates. Recall was measured using a diverse collection of 5 independent\nlabelled test sets. Precision was measured by having each model classify a\nrandomly selected stream of pairs of reports until each model classified 100\npairs as duplicates. These pairs were assessed by a medical doctor without\nindicating which method(s) had flagged each pair. Performance on individual\ncountries was measured by having a medical doctor assess a subset of pairs\nclassified as duplicates for three different countries. The new model achieved\nhigher precision and higher recall for all labelled datasets compared to the\nprevious state of the art model, with comparable performance for medicines and\nvaccines. The model was shown to produce substantially fewer false positives\nthan the comparator model on pairs from individual countries. The method\npresented here advances state of the art for duplicate detection in adverse\nevent reports for medicines and vaccines.",
      "tldr_zh": "本研究针对药监（pharmacovigilance）领域中重复不良事件报告的问题，提出了一种可扩展的预测建模方法，以改进重复报告的识别。该方法基于原有vigiMatch模型，修改了现有特征并引入新特征，使用两个support vector machine (SVM)分类器（一个针对药物，一个针对疫苗）来分类报告对为重复或非重复。实验通过5个独立标记测试集评估recall（召回率），并通过医生评估precision（精确率），结果显示新模型在所有数据集上实现了更高的recall和precision，且在特定国家的数据上显著减少了false positives（假阳性）。这项工作推进了不良事件报告中重复检测的state of the art技术，为药物和疫苗的安全监测提供了更可靠的工具。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "26 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.03729v1",
      "published_date": "2025-03-31 15:24:29 UTC",
      "updated_date": "2025-03-31 15:24:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:58:33.324720"
    },
    {
      "arxiv_id": "2503.24199v2",
      "title": "Agent-Based Simulations of Online Political Discussions: A Case Study on Elections in Germany",
      "title_zh": "基于代理的在线政治讨论模拟：德国选举的案例研究",
      "authors": [
        "Abdul Sittar",
        "Simon Münker",
        "Fabio Sartori",
        "Andreas Reitenbach",
        "Achim Rettinger",
        "Michael Mäs",
        "Alenka Guček",
        "Marko Grobelnik"
      ],
      "abstract": "User engagement on social media platforms is influenced by historical\ncontext, time constraints, and reward-driven interactions. This study presents\nan agent-based simulation approach that models user interactions, considering\npast conversation history, motivation, and resource constraints. Utilizing\nGerman Twitter data on political discourse, we fine-tune AI models to generate\nposts and replies, incorporating sentiment analysis, irony detection, and\noffensiveness classification. The simulation employs a myopic best-response\nmodel to govern agent behavior, accounting for decision-making based on\nexpected rewards. Our results highlight the impact of historical context on\nAI-generated responses and demonstrate how engagement evolves under varying\nconstraints.",
      "tldr_zh": "本研究提出了一种基于代理(agent-based)的模拟方法，用于分析在线政治讨论如何受历史背景、时间限制和奖励驱动影响，特别以德国选举为案例。研究利用德国Twitter数据微调AI模型生成帖子和回复，融入sentiment analysis、irony detection和offensiveness classification，并采用myopic best-response model指导代理行为基于预期奖励决策。结果显示，历史背景显著影响AI生成响应，且在不同约束下，用户参与度会动态演变，为理解社交媒体政治互动提供新洞见。",
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "I forgot to take the consent from all other co authors and they want\n  to withdraw it",
      "pdf_url": "http://arxiv.org/pdf/2503.24199v2",
      "published_date": "2025-03-31 15:17:04 UTC",
      "updated_date": "2025-04-11 06:54:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:58:43.142068"
    },
    {
      "arxiv_id": "2504.00063v1",
      "title": "The Axiom-Based Atlas: A Structural Mapping of Theorems via Foundational Proof Vectors",
      "title_zh": "翻译失败",
      "authors": [
        "Harim Yoo"
      ],
      "abstract": "The Axiom-Based Atlas is a novel framework that structurally represents\nmathematical theorems as proof vectors over foundational axiom systems. By\nmapping the logical dependencies of theorems onto vectors indexed by axioms -\nsuch as those from Hilbert geometry, Peano arithmetic, or ZFC - we offer a new\nway to visualize, compare, and analyze mathematical knowledge. This\nvector-based formalism not only captures the logical foundation of theorems but\nalso enables quantitative similarity metrics - such as cosine distance -\nbetween mathematical results, offering a new analytic layer for structural\ncomparison. Using heatmaps, vector clustering, and AI-assisted modeling, this\natlas enables the grouping of theorems by logical structure, not just by\nmathematical domain. We also introduce a prototype assistant (Atlas-GPT) that\ninterprets natural language theorems and suggests likely proof vectors,\nsupporting future applications in automated reasoning, mathematical education,\nand formal verification.\n  This direction is partially inspired by Terence Tao's recent reflections on\nthe convergence of symbolic and structural mathematics. The Axiom-Based Atlas\naims to provide a scalable, interpretable model of mathematical reasoning that\nis both human-readable and AI-compatible, contributing to the future landscape\nof formal mathematical systems.",
      "tldr_zh": "本研究提出 Axiom-Based Atlas 框架，将数学定理表示为基于基础公理系统的 proof vectors（如 Hilbert geometry、Peano arithmetic 或 ZFC），从而实现定理的结构化映射和逻辑依赖性可视化。该框架通过量化相似性指标（如 cosine distance）和工具如热图、向量聚类，允许按逻辑结构而不是数学领域对定理进行比较和分组。研究还引入 Atlas-GPT 原型助手，能解释自然语言定理并建议证明 vectors，支持应用在自动推理、数学教育和形式验证中。",
      "categories": [
        "cs.AI",
        "math.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.00063v1",
      "published_date": "2025-03-31 15:12:57 UTC",
      "updated_date": "2025-03-31 15:12:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:58:56.617121"
    },
    {
      "arxiv_id": "2503.24191v1",
      "title": "Output Constraints as Attack Surface: Exploiting Structured Generation to Bypass LLM Safety Mechanisms",
      "title_zh": "输出约束作为攻击面：利用结构化生成来绕过LLM安全机制",
      "authors": [
        "Shuoming Zhang",
        "Jiacheng Zhao",
        "Ruiyuan Xu",
        "Xiaobing Feng",
        "Huimin Cui"
      ],
      "abstract": "Content Warning: This paper may contain unsafe or harmful content generated\nby LLMs that may be offensive to readers. Large Language Models (LLMs) are\nextensively used as tooling platforms through structured output APIs to ensure\nsyntax compliance so that robust integration with existing softwares like agent\nsystems, could be achieved. However, the feature enabling functionality of\ngrammar-guided structured output presents significant security vulnerabilities.\nIn this work, we reveal a critical control-plane attack surface orthogonal to\ntraditional data-plane vulnerabilities. We introduce Constrained Decoding\nAttack (CDA), a novel jailbreak class that weaponizes structured output\nconstraints to bypass safety mechanisms. Unlike prior attacks focused on input\nprompts, CDA operates by embedding malicious intent in schema-level grammar\nrules (control-plane) while maintaining benign surface prompts (data-plane). We\ninstantiate this with a proof-of-concept Chain Enum Attack, achieves 96.2%\nattack success rates across proprietary and open-weight LLMs on five safety\nbenchmarks with a single query, including GPT-4o and Gemini-2.0-flash. Our\nfindings identify a critical security blind spot in current LLM architectures\nand urge a paradigm shift in LLM safety to address control-plane\nvulnerabilities, as current mechanisms focused solely on data-plane threats\nleave critical systems exposed.",
      "tldr_zh": "本研究揭示了大型语言模型（LLMs）的结构化输出功能作为攻击表面的安全漏洞，提出了一种新型越狱攻击——Constrained Decoding Attack (CDA)，通过在 schema-level grammar rules（控制平面）中嵌入恶意意图，同时保持表面提示（data-plane）良性，从而绕过LLMs的安全机制。研究者以Chain Enum Attack为例，实现了单查询攻击成功率高达96.2%，适用于包括GPT-4o和Gemini-2.0-flash在内的多种专有和开源LLMs，并在五个安全基准上进行了验证。这些发现突出了当前LLMs架构的安全盲点，呼吁从数据平面威胁转向控制平面漏洞的防护，以提升模型的安全性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "15 pages, 13 figures, 4 tables Work In Progress",
      "pdf_url": "http://arxiv.org/pdf/2503.24191v1",
      "published_date": "2025-03-31 15:08:06 UTC",
      "updated_date": "2025-03-31 15:08:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:59:08.563728"
    },
    {
      "arxiv_id": "2503.24165v1",
      "title": "Predicting Targeted Therapy Resistance in Non-Small Cell Lung Cancer Using Multimodal Machine Learning",
      "title_zh": "使用多模态机器学习预测非小细胞肺癌中靶向疗法耐药性",
      "authors": [
        "Peiying Hua",
        "Andrea Olofson",
        "Faraz Farhadi",
        "Liesbeth Hondelink",
        "Gregory Tsongalis",
        "Konstantin Dragnev",
        "Dagmar Hoegemann Savellano",
        "Arief Suriawinata",
        "Laura Tafe",
        "Saeed Hassanpour"
      ],
      "abstract": "Lung cancer is the primary cause of cancer death globally, with non-small\ncell lung cancer (NSCLC) emerging as its most prevalent subtype. Among NSCLC\npatients, approximately 32.3% have mutations in the epidermal growth factor\nreceptor (EGFR) gene. Osimertinib, a third-generation EGFR-tyrosine kinase\ninhibitor (TKI), has demonstrated remarkable efficacy in the treatment of NSCLC\npatients with activating and T790M resistance EGFR mutations. Despite its\nestablished efficacy, drug resistance poses a significant challenge for\npatients to fully benefit from osimertinib. The absence of a standard tool to\naccurately predict TKI resistance, including that of osimertinib, remains a\ncritical obstacle. To bridge this gap, in this study, we developed an\ninterpretable multimodal machine learning model designed to predict patient\nresistance to osimertinib among late-stage NSCLC patients with activating EGFR\nmutations, achieving a c-index of 0.82 on a multi-institutional dataset. This\nmachine learning model harnesses readily available data routinely collected\nduring patient visits and medical assessments to facilitate precision lung\ncancer management and informed treatment decisions. By integrating various data\ntypes such as histology images, next generation sequencing (NGS) data,\ndemographics data, and clinical records, our multimodal model can generate\nwell-informed recommendations. Our experiment results also demonstrated the\nsuperior performance of the multimodal model over single modality models\n(c-index 0.82 compared with 0.75 and 0.77), thus underscoring the benefit of\ncombining multiple modalities in patient outcome prediction.",
      "tldr_zh": "本研究针对非小细胞肺癌 (NSCLC) 患者对第三代 EGFR-TKI 药物 Osimertinib 的抵抗问题，开发了一个可解释的多模态机器学习模型，用于预测晚期 NSCLC 患者（尤其是那些有激活 EGFR 突变的患者）的治疗抵抗。模型整合了组织学图像、下一代测序 (NGS) 数据、人口统计数据和临床记录等多类型数据，实现对患者结果的精确预测。实验结果显示，该模型在多机构数据集上达到了 c-index 0.82，显著优于单一模态模型（c-index 0.75 和 0.77），从而为精准肺癌管理和 informed treatment decisions 提供了可靠工具。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.24165v1",
      "published_date": "2025-03-31 14:47:02 UTC",
      "updated_date": "2025-03-31 14:47:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:59:21.740791"
    },
    {
      "arxiv_id": "2503.24150v1",
      "title": "Learning a Canonical Basis of Human Preferences from Binary Ratings",
      "title_zh": "翻译失败",
      "authors": [
        "Kailas Vodrahalli",
        "Wei Wei",
        "James Zou"
      ],
      "abstract": "Recent advances in generative AI have been driven by alignment techniques\nsuch as reinforcement learning from human feedback (RLHF). RLHF and related\ntechniques typically involve constructing a dataset of binary or ranked choice\nhuman preferences and subsequently fine-tuning models to align with these\npreferences. This paper shifts the focus to understanding the preferences\nencoded in such datasets and identifying common human preferences. We find that\na small subset of 21 preference categories (selected from a set of nearly 5,000\ndistinct preferences) captures >89% of preference variation across individuals.\nThis small set of preferences is analogous to a canonical basis of human\npreferences, similar to established findings that characterize human variation\nin psychology or facial recognition studies. Through both synthetic and\nempirical evaluations, we confirm that our low-rank, canonical set of human\npreferences generalizes across the entire dataset and within specific topics.\nWe further demonstrate our preference basis' utility in model evaluation, where\nour preference categories offer deeper insights into model alignment, and in\nmodel training, where we show that fine-tuning on preference-defined subsets\nsuccessfully aligns the model accordingly.",
      "tldr_zh": "本研究从二元评级数据中学习人类偏好的规范基础（canonical basis），发现一个仅包含21个偏好类别（从近5000个中选出）的子集能捕捉超过89%的偏好变异，这类似于心理学或面部识别研究中的人类变异特征。研究通过合成和实证评估验证了这一低秩偏好集的泛化性，能够适用于整个数据集和特定主题。最终，该canonical basis被证明在AI模型评估中提供更深入的对齐洞见，并在模型训练中，通过在偏好子集上微调，成功提升了模型与RLHF（reinforcement learning from human feedback）等技术的对齐效果。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.LG",
      "comment": "25 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.24150v1",
      "published_date": "2025-03-31 14:35:48 UTC",
      "updated_date": "2025-03-31 14:35:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:59:33.652760"
    },
    {
      "arxiv_id": "2503.24145v1",
      "title": "Resonance: Drawing from Memories to Imagine Positive Futures through AI-Augmented Journaling",
      "title_zh": "翻译失败",
      "authors": [
        "Wazeer Zulfikar",
        "Treyden Chiaravalloti",
        "Jocelyn Shen",
        "Rosalind Picard",
        "Pattie Maes"
      ],
      "abstract": "People inherently use experiences of their past while imagining their future,\na capability that plays a crucial role in mental health. Resonance is an\nAI-powered journaling tool designed to augment this ability by offering\nAI-generated, action-oriented suggestions for future activities based on the\nuser's own past memories. Suggestions are offered when a new memory is logged\nand are followed by a prompt for the user to imagine carrying out the\nsuggestion. In a two-week randomized controlled study (N=55), we found that\nusing Resonance significantly improved mental health outcomes, reducing the\nusers' PHQ8 scores, a measure of current depression, and increasing their daily\npositive affect, particularly when they would likely act on the suggestion.\nNotably, the effectiveness of the suggestions was higher when they were\npersonal, novel, and referenced the user's logged memories. Finally, through\nopen-ended feedback, we discuss the factors that encouraged or hindered the use\nof the tool.",
      "tldr_zh": "这篇论文介绍了 Resonance，一种 AI 增强的日记工具（AI-Augmented Journaling），它通过分析用户的过去记忆生成行动导向的未来活动建议，帮助用户想象积极未来，从而提升心理健康。研究采用为期两周的随机对照实验（N=55），发现使用 Resonance 显著降低了 PHQ8 抑郁分数，并提高了日常积极情绪，特别是当建议具有个人化、新颖性和对用户记忆的引用时。最终，通过用户开放反馈，论文讨论了促进或阻碍工具使用的关键因素。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "17 pages, 13 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.24145v1",
      "published_date": "2025-03-31 14:30:47 UTC",
      "updated_date": "2025-03-31 14:30:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:59:44.430926"
    },
    {
      "arxiv_id": "2503.24130v1",
      "title": "Graph Neural Network-Based Predictive Modeling for Robotic Plaster Printing",
      "title_zh": "基于图神经网络的机器人石膏打印预测建模",
      "authors": [
        "Diego Machain Rivera",
        "Selen Ercan Jenny",
        "Ping Hsun Tsai",
        "Ena Lloret-Fritschi",
        "Luis Salamanca",
        "Fernando Perez-Cruz",
        "Konstantinos E. Tatsis"
      ],
      "abstract": "This work proposes a Graph Neural Network (GNN) modeling approach to predict\nthe resulting surface from a particle based fabrication process. The latter\nconsists of spray-based printing of cementitious plaster on a wall and is\nfacilitated with the use of a robotic arm. The predictions are computed using\nthe robotic arm trajectory features, such as position, velocity and direction,\nas well as the printing process parameters. The proposed approach, based on a\nparticle representation of the wall domain and the end effector, allows for the\nadoption of a graph-based solution. The GNN model consists of an\nencoder-processor-decoder architecture and is trained using data from\nlaboratory tests, while the hyperparameters are optimized by means of a\nBayesian scheme. The aim of this model is to act as a simulator of the printing\nprocess, and ultimately used for the generation of the robotic arm trajectory\nand the optimization of the printing parameters, towards the materialization of\nan autonomous plastering process. The performance of the proposed model is\nassessed in terms of the prediction error against unseen ground truth data,\nwhich shows its generality in varied scenarios, as well as in comparison with\nthe performance of an existing benchmark model. The results demonstrate a\nsignificant improvement over the benchmark model, with notably better\nperformance and enhanced error scaling across prediction steps.",
      "tldr_zh": "这篇论文提出了一种基于Graph Neural Network (GNN)的预测模型，用于模拟机器人臂辅助的颗粒基抹灰打印过程，预测打印后的表面结果。模型采用粒子表示的墙域和末端执行器作为图-based解决方案，结合机器人臂轨迹特征（如位置、速度和方向）以及打印参数，通过编码器-处理器-解码器架构训练，并使用Bayesian方案优化超参数。实验结果显示，该模型在未见数据上的预测错误显著低于基准模型，并在多种场景中表现出更好的性能和错误扩展控制，为实现自主抹灰过程的轨迹生成和参数优化提供了基础。",
      "categories": [
        "cs.CE",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.24130v1",
      "published_date": "2025-03-31 14:15:00 UTC",
      "updated_date": "2025-03-31 14:15:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T07:59:56.252808"
    },
    {
      "arxiv_id": "2504.01043v2",
      "title": "Are clinicians ethically obligated to disclose their use of medical machine learning systems to patients?",
      "title_zh": "临床医生是否有道德义务向患者披露他们使用医疗机器学习系统的行为？",
      "authors": [
        "Joshua Hatherley"
      ],
      "abstract": "It is commonly accepted that clinicians are ethically obligated to disclose\ntheir use of medical machine learning systems to patients, and that failure to\ndo so would amount to a moral fault for which clinicians ought to be held\naccountable. Call this \"the disclosure thesis.\" Four main arguments have been,\nor could be, given to support the disclosure thesis in the ethics literature:\nthe risk-based argument, the rights-based argument, the materiality argument,\nand the autonomy argument. In this article, I argue that each of these four\narguments are unconvincing, and therefore, that the disclosure thesis ought to\nbe rejected. I suggest that mandating disclosure may also even risk harming\npatients by providing stakeholders with a way to avoid accountability for harm\nthat results from improper applications or uses of these systems.",
      "tldr_zh": "本文质疑临床医生是否有道德义务（ethically obligated）向患者披露使用医疗机器学习系统（medical machine learning systems）的行为，作者挑战了这一“disclosure thesis”。作者分析了四个支持该论点的常见论点：risk-based argument、rights-based argument、materiality argument 和 autonomy argument，并认为这些论点均不 convincing。最终，作者建议拒绝强制披露，因为这可能反而伤害患者，例如让利益相关者逃避不当使用系统的责任。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "Journal of Medical Ethics, forthcoming 2024",
      "pdf_url": "http://arxiv.org/pdf/2504.01043v2",
      "published_date": "2025-03-31 14:12:18 UTC",
      "updated_date": "2025-04-04 11:35:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:00:07.060870"
    },
    {
      "arxiv_id": "2504.00061v1",
      "title": "Evaluating the Feasibility and Accuracy of Large Language Models for Medical History-Taking in Obstetrics and Gynecology",
      "title_zh": "翻译失败",
      "authors": [
        "Dou Liu",
        "Ying Long",
        "Sophia Zuoqiu",
        "Tian Tang",
        "Rong Yin"
      ],
      "abstract": "Effective physician-patient communications in pre-diagnostic environments,\nand most specifically in complex and sensitive medical areas such as\ninfertility, are critical but consume a lot of time and, therefore, cause\nclinic workflows to become inefficient. Recent advancements in Large Language\nModels (LLMs) offer a potential solution for automating conversational medical\nhistory-taking and improving diagnostic accuracy. This study evaluates the\nfeasibility and performance of LLMs in those tasks for infertility cases. An\nAI-driven conversational system was developed to simulate physician-patient\ninteractions with ChatGPT-4o and ChatGPT-4o-mini. A total of 70 real-world\ninfertility cases were processed, generating 420 diagnostic histories. Model\nperformance was assessed using F1 score, Differential Diagnosis (DDs) Accuracy,\nand Accuracy of Infertility Type Judgment (ITJ). ChatGPT-4o-mini outperformed\nChatGPT-4o in information extraction accuracy (F1 score: 0.9258 vs. 0.9029, p =\n0.045, d = 0.244) and demonstrated higher completeness in medical\nhistory-taking (97.58% vs. 77.11%), suggesting that ChatGPT-4o-mini is more\neffective in extracting detailed patient information, which is critical for\nimproving diagnostic accuracy. In contrast, ChatGPT-4o performed slightly\nbetter in differential diagnosis accuracy (2.0524 vs. 2.0048, p > 0.05). ITJ\naccuracy was higher in ChatGPT-4o-mini (0.6476 vs. 0.5905) but with lower\nconsistency (Cronbach's $\\alpha$ = 0.562), suggesting variability in\nclassification reliability. Both models demonstrated strong feasibility in\nautomating infertility history-taking, with ChatGPT-4o-mini excelling in\ncompleteness and extraction accuracy. In future studies, expert validation for\naccuracy and dependability in a clinical setting, AI model fine-tuning, and\nlarger datasets with a mix of cases of infertility have to be prioritized.",
      "tldr_zh": "这篇论文评估了大型语言模型（LLMs）在妇产科医疗病史采集中的可行性和准确性，特别针对不育症病例，以改善医生-患者互动效率。研究开发了一个AI对话系统，使用ChatGPT-4o和ChatGPT-4o-mini处理70个真实病例，生成420个诊断历史，并通过F1 score、差异诊断准确性（DDs Accuracy）和不育症类型判断准确性（ITJ Accuracy）进行评估。结果显示，ChatGPT-4o-mini在信息提取准确性（F1 score：0.9258 vs. 0.9029）和病史完整性（97.58% vs. 77.11%）上优于ChatGPT-4o，而ChatGPT-4o在差异诊断准确性上略胜一筹；整体而言，两模型均显示出自动化病史采集的可行性。未来需优先进行专家验证、模型微调以及使用更大、更多样化的数据集来提升临床可靠性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by IISE 2025 annual conference",
      "pdf_url": "http://arxiv.org/pdf/2504.00061v1",
      "published_date": "2025-03-31 14:09:53 UTC",
      "updated_date": "2025-03-31 14:09:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:00:22.124546"
    },
    {
      "arxiv_id": "2503.24110v1",
      "title": "Grounding Agent Reasoning in Image Schemas: A Neurosymbolic Approach to Embodied Cognition",
      "title_zh": "翻译失败",
      "authors": [
        "François Olivier",
        "Zied Bouraoui"
      ],
      "abstract": "Despite advances in embodied AI, agent reasoning systems still struggle to\ncapture the fundamental conceptual structures that humans naturally use to\nunderstand and interact with their environment. To address this, we propose a\nnovel framework that bridges embodied cognition theory and agent systems by\nleveraging a formal characterization of image schemas, which are defined as\nrecurring patterns of sensorimotor experience that structure human cognition.\nBy customizing LLMs to translate natural language descriptions into formal\nrepresentations based on these sensorimotor patterns, we will be able to create\na neurosymbolic system that grounds the agent's understanding in fundamental\nconceptual structures. We argue that such an approach enhances both efficiency\nand interpretability while enabling more intuitive human-agent interactions\nthrough shared embodied understanding.",
      "tldr_zh": "尽管embodied AI取得了进展，agent reasoning系统仍难以捕捉人类用于理解和互动环境的根本概念结构。  \n本文提出一个新框架，将embodied cognition理论与agent系统桥接，通过正式化image schemas（传感器运动经验的recurring patterns）来构建neurosymbolic系统。  \n该框架利用定制的LLMs，将自然语言描述转化为基于sensorimotor patterns的正式表示，从而使agent的理解更牢固地植根于fundamental conceptual structures。  \n这种方法提升了效率和interpretability，并通过shared embodied understanding实现了更直观的human-agent interactions。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.24110v1",
      "published_date": "2025-03-31 14:01:39 UTC",
      "updated_date": "2025-03-31 14:01:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:00:31.827887"
    },
    {
      "arxiv_id": "2503.24108v2",
      "title": "PolypSegTrack: Unified Foundation Model for Colonoscopy Video Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Anwesa Choudhuri",
        "Zhongpai Gao",
        "Meng Zheng",
        "Benjamin Planche",
        "Terrence Chen",
        "Ziyan Wu"
      ],
      "abstract": "Early detection, accurate segmentation, classification and tracking of polyps\nduring colonoscopy are critical for preventing colorectal cancer. Many existing\ndeep-learning-based methods for analyzing colonoscopic videos either require\ntask-specific fine-tuning, lack tracking capabilities, or rely on\ndomain-specific pre-training. In this paper, we introduce PolypSegTrack, a\nnovel foundation model that jointly addresses polyp detection, segmentation,\nclassification and unsupervised tracking in colonoscopic videos. Our approach\nleverages a novel conditional mask loss, enabling flexible training across\ndatasets with either pixel-level segmentation masks or bounding box\nannotations, allowing us to bypass task-specific fine-tuning. Our unsupervised\ntracking module reliably associates polyp instances across frames using object\nqueries, without relying on any heuristics. We leverage a robust vision\nfoundation model backbone that is pre-trained unsupervisedly on natural images,\nthereby removing the need for domain-specific pre-training. Extensive\nexperiments on multiple polyp benchmarks demonstrate that our method\nsignificantly outperforms existing state-of-the-art approaches in detection,\nsegmentation, classification, and tracking.",
      "tldr_zh": "本文提出PolypSegTrack，一种统一的基金会模型，用于结肠镜视频分析，能够同时处理息肉检测、分割、分类和无监督跟踪任务。该模型引入conditional mask loss，实现灵活训练，支持像素级分割掩码或边界框标注，从而避免任务特定微调。它的unsupervised tracking模块利用object queries在帧间可靠地关联息肉实例，并基于在自然图像上无监督预训练的视觉骨干网络，省去了领域特定预训练。实验在多个息肉基准上表明，PolypSegTrack在检测、分割、分类和跟踪方面显著优于现有最先进方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.24108v2",
      "published_date": "2025-03-31 14:00:21 UTC",
      "updated_date": "2025-04-02 19:58:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:00:44.617970"
    },
    {
      "arxiv_id": "2504.02860v1",
      "title": "Computer Vision and Deep Learning for 4D Augmented Reality",
      "title_zh": "翻译失败",
      "authors": [
        "Karthik Shivashankar"
      ],
      "abstract": "The prospect of 4D video in Extended Reality (XR) platform is huge and\nexciting, it opens a whole new way of human computer interaction and the way we\nperceive the reality and consume multimedia. In this thesis, we have shown that\nfeasibility of rendering 4D video in Microsoft mixed reality platform. This\nenables us to port any 3D performance capture from CVSSP into XR product like\nthe HoloLens device with relative ease. However, if the 3D model is too complex\nand is made up of millions of vertices, the data bandwidth required to port the\nmodel is a severe limitation with the current hardware and communication\nsystem. Therefore, in this project we have also developed a compact\nrepresentation of both shape and appearance of the 4d video sequence using deep\nlearning models to effectively learn the compact representation of 4D video\nsequence and reconstruct it without affecting the shape and appearance of the\nvideo sequence.",
      "tldr_zh": "这篇论文探讨了使用计算机视觉和深度学习在扩展现实（XR）平台上渲染4D视频的可行性，旨在提升人机交互和多媒体体验。作者展示了将3D性能捕捉轻松移植到Microsoft混合现实平台（如HoloLens设备）的过程，但强调了复杂3D模型在数据带宽方面的限制。针对此问题，他们开发了深度学习模型来创建4D视频序列的紧凑形状和外观表示，从而实现高效重建，同时保持视频的质量。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "My Master Thesis , University of Surrey 2019",
      "pdf_url": "http://arxiv.org/pdf/2504.02860v1",
      "published_date": "2025-03-31 13:38:26 UTC",
      "updated_date": "2025-03-31 13:38:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:00:57.112520"
    },
    {
      "arxiv_id": "2503.24062v1",
      "title": "Artificial Conversations, Real Results: Fostering Language Detection with Synthetic Data",
      "title_zh": "翻译失败",
      "authors": [
        "Fatemeh Mohammadi",
        "Tommaso Romano",
        "Samira Maghool",
        "Paolo Ceravolo"
      ],
      "abstract": "Collecting high-quality training data is essential for fine-tuning Large\nLanguage Models (LLMs). However, acquiring such data is often costly and\ntime-consuming, especially for non-English languages such as Italian. Recently,\nresearchers have begun to explore the use of LLMs to generate synthetic\ndatasets as a viable alternative. This study proposes a pipeline for generating\nsynthetic data and a comprehensive approach for investigating the factors that\ninfluence the validity of synthetic data generated by LLMs by examining how\nmodel performance is affected by metrics such as prompt strategy, text length\nand target position in a specific task, i.e. inclusive language detection in\nItalian job advertisements. Our results show that, in most cases and across\ndifferent metrics, the fine-tuned models trained on synthetic data consistently\noutperformed other models on both real and synthetic test datasets. The study\ndiscusses the practical implications and limitations of using synthetic data\nfor language detection tasks with LLMs.",
      "tldr_zh": "本研究探讨了使用合成数据训练大型语言模型 (LLMs) 以提升语言检测性能的问题，特别针对非英语语言如意大利语。研究提出了一种生成合成数据的管道，并系统调查了影响合成数据有效性的因素，包括 prompt strategy、text length 和 target position，在意大利语工作广告的 inclusive language detection 任务中进行评估。结果显示，使用合成数据训练的微调模型在大多数指标上 outperform 其他模型，并在真实和合成测试数据集上表现出色。最后，研究讨论了此方法的实际含义和潜在限制，为低资源语言任务提供了一种高效的替代方案。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.24062v1",
      "published_date": "2025-03-31 13:22:34 UTC",
      "updated_date": "2025-03-31 13:22:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:01:08.174440"
    },
    {
      "arxiv_id": "2503.24047v2",
      "title": "Towards Scientific Intelligence: A Survey of LLM-based Scientific Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Shuo Ren",
        "Pu Jian",
        "Zhenjiang Ren",
        "Chunlin Leng",
        "Can Xie",
        "Jiajun Zhang"
      ],
      "abstract": "As scientific research becomes increasingly complex, innovative tools are\nneeded to manage vast data, facilitate interdisciplinary collaboration, and\naccelerate discovery. Large language models (LLMs) are now evolving into\nLLM-based scientific agents that automate critical tasks, ranging from\nhypothesis generation and experiment design to data analysis and simulation.\nUnlike general-purpose LLMs, these specialized agents integrate domain-specific\nknowledge, advanced tool sets, and robust validation mechanisms, enabling them\nto handle complex data types, ensure reproducibility, and drive scientific\nbreakthroughs. This survey provides a focused review of the architectures,\ndesign, benchmarks, applications, and ethical considerations surrounding\nLLM-based scientific agents. We highlight why they differ from general agents\nand the ways in which they advance research across various scientific fields.\nBy examining their development and challenges, this survey offers a\ncomprehensive roadmap for researchers and practitioners to harness these agents\nfor more efficient, reliable, and ethically sound scientific discovery.",
      "tldr_zh": "这篇调查论文探讨了大型语言模型 (LLMs) 如何演变为基于LLMs的科学代理，以自动化科学任务，如假设生成、实验设计、数据分析和模拟。这些代理区别于通用LLMs，通过整合领域特定知识、先进工具集和鲁棒验证机制，确保处理复杂数据、提升再现性和推动跨学科突破。论文全面回顾了这些代理的架构、设计、基准、应用以及伦理挑战，并为研究人员提供路线图，以实现更高效、可信赖的科学发现。",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "34 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.24047v2",
      "published_date": "2025-03-31 13:11:28 UTC",
      "updated_date": "2025-04-17 07:26:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:01:21.466147"
    },
    {
      "arxiv_id": "2503.24028v1",
      "title": "Pay More Attention to the Robustness of Prompt for Instruction Data Mining",
      "title_zh": "翻译失败",
      "authors": [
        "Qiang Wang",
        "Dawei Feng",
        "Xu Zhang",
        "Ao Shen",
        "Yang Xu",
        "Bo Ding",
        "Huaimin Wang"
      ],
      "abstract": "Instruction tuning has emerged as a paramount method for tailoring the\nbehaviors of LLMs. Recent work has unveiled the potential for LLMs to achieve\nhigh performance through fine-tuning with a limited quantity of high-quality\ninstruction data. Building upon this approach, we further explore the impact of\nprompt's robustness on the selection of high-quality instruction data. This\npaper proposes a pioneering framework of high-quality online instruction data\nmining for instruction tuning, focusing on the impact of prompt's robustness on\nthe data mining process. Our notable innovation, is to generate the adversarial\ninstruction data by conducting the attack for the prompt of online instruction\ndata. Then, we introduce an Adversarial Instruction-Following Difficulty metric\nto measure how much help the adversarial instruction data can provide to the\ngeneration of the corresponding response. Apart from it, we propose a novel\nAdversarial Instruction Output Embedding Consistency approach to select\nhigh-quality online instruction data. We conduct extensive experiments on two\nbenchmark datasets to assess the performance. The experimental results serve to\nunderscore the effectiveness of our proposed two methods. Moreover, the results\nunderscore the critical practical significance of considering prompt's\nrobustness.",
      "tldr_zh": "本文强调了提示词鲁棒性在指令数据挖掘中的重要性，针对大型语言模型 (LLMs) 的指令微调过程提出一个创新框架，用于在线挖掘高质量指令数据。主要方法包括通过对抗攻击生成对抗指令数据，并引入 Adversarial Instruction-Following Difficulty 指标和 Adversarial Instruction Output Embedding Consistency 技术来评估和选择数据。在两个基准数据集上的实验结果证明了这些方法的有效性，并突出了提示词鲁棒性的实际意义。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.24028v1",
      "published_date": "2025-03-31 12:53:08 UTC",
      "updated_date": "2025-03-31 12:53:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:01:32.025130"
    },
    {
      "arxiv_id": "2503.24016v1",
      "title": "Bayesian Predictive Coding",
      "title_zh": "贝叶斯预测编码",
      "authors": [
        "Alexander Tschantz",
        "Magnus Koudahl",
        "Hampus Linander",
        "Lancelot Da Costa",
        "Conor Heins",
        "Jeff Beck",
        "Christopher Buckley"
      ],
      "abstract": "Predictive coding (PC) is an influential theory of information processing in\nthe brain, providing a biologically plausible alternative to backpropagation.\nIt is motivated in terms of Bayesian inference, as hidden states and parameters\nare optimised via gradient descent on variational free energy. However,\nimplementations of PC rely on maximum \\textit{a posteriori} (MAP) estimates of\nhidden states and maximum likelihood (ML) estimates of parameters, limiting\ntheir ability to quantify epistemic uncertainty. In this work, we investigate a\nBayesian extension to PC that estimates a posterior distribution over network\nparameters. This approach, termed Bayesian Predictive coding (BPC), preserves\nthe locality of PC and results in closed-form Hebbian weight updates. Compared\nto PC, our BPC algorithm converges in fewer epochs in the full-batch setting\nand remains competitive in the mini-batch setting. Additionally, we demonstrate\nthat BPC offers uncertainty quantification comparable to existing methods in\nBayesian deep learning, while also improving convergence properties. Together,\nthese results suggest that BPC provides a biologically plausible method for\nBayesian learning in the brain, as well as an attractive approach to\nuncertainty quantification in deep learning.",
      "tldr_zh": "本研究扩展了Predictive Coding (PC)理论，提出Bayesian Predictive Coding (BPC)，通过估计网络参数的后验分布来解决PC在量化认识不确定性(epistemic uncertainty)方面的局限性。BPC保留了PC的局部性，并采用闭合形式的Hebbian weight updates，实现更快的收敛，在全批次设置下比PC减少了训练周期，并在小批次设置下保持竞争力。同时，实验结果显示BPC的不确定性量化能力与现有Bayesian deep learning方法相当，并为大脑的Bayesian学习提供了一个生物学可信的框架。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.24016v1",
      "published_date": "2025-03-31 12:40:50 UTC",
      "updated_date": "2025-03-31 12:40:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:01:44.266310"
    },
    {
      "arxiv_id": "2503.24009v1",
      "title": "Learning 3D-Gaussian Simulators from RGB Videos",
      "title_zh": "翻译失败",
      "authors": [
        "Mikel Zhobro",
        "Andreas René Geist",
        "Georg Martius"
      ],
      "abstract": "Learning physics simulations from video data requires maintaining spatial and\ntemporal consistency, a challenge often addressed with strong inductive biases\nor ground-truth 3D information -- limiting scalability and generalization. We\nintroduce 3DGSim, a 3D physics simulator that learns object dynamics end-to-end\nfrom multi-view RGB videos. It encodes images into a 3D Gaussian particle\nrepresentation, propagates dynamics via a transformer, and renders frames using\n3D Gaussian splatting. By jointly training inverse rendering with a dynamics\ntransformer using a temporal encoding and merging layer, 3DGSimembeds physical\nproperties into point-wise latent vectors without enforcing explicit\nconnectivity constraints. This enables the model to capture diverse physical\nbehaviors, from rigid to elastic and cloth-like interactions, along with\nrealistic lighting effects that also generalize to unseen multi-body\ninteractions and novel scene edits.",
      "tldr_zh": "该研究提出了一种名为 3DGSim 的 3D 物理模拟器，能够从多视图 RGB videos 中端到端学习物体动态，而无需依赖强诱导偏差或真实 3D 信息。方法包括将图像编码为 3D Gaussian 粒子表示，通过 transformer 传播动态，并使用 3D Gaussian splatting 渲染帧，同时联合训练逆渲染和动态 transformer 以嵌入物理属性到点-wise 潜在向量中。实验结果显示，3DGSim 能捕捉从刚性到弹性及布料-like 交互的多样行为，并实现现实照明效果，支持泛化到未见的多体交互和新型场景编辑。",
      "categories": [
        "cs.GR",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.GR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.24009v1",
      "published_date": "2025-03-31 12:33:59 UTC",
      "updated_date": "2025-03-31 12:33:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:01:56.377216"
    },
    {
      "arxiv_id": "2503.24008v1",
      "title": "H2VU-Benchmark: A Comprehensive Benchmark for Hierarchical Holistic Video Understanding",
      "title_zh": "H2VU-Benchmark：分层整体视频理解的全面",
      "authors": [
        "Qi Wu",
        "Quanlong Zheng",
        "Yanhao Zhang",
        "Junlin Xie",
        "Jinguo Luo",
        "Kuo Wang",
        "Peng Liu",
        "Qingsong Xie",
        "Ru Zhen",
        "Haonan Lu",
        "Zhenyu Yang"
      ],
      "abstract": "With the rapid development of multimodal models, the demand for assessing\nvideo understanding capabilities has been steadily increasing. However,\nexisting benchmarks for evaluating video understanding exhibit significant\nlimitations in coverage, task diversity, and scene adaptability. These\nshortcomings hinder the accurate assessment of models' comprehensive video\nunderstanding capabilities. To tackle this challenge, we propose a hierarchical\nand holistic video understanding (H2VU) benchmark designed to evaluate both\ngeneral video and online streaming video comprehension. This benchmark\ncontributes three key features:\n  Extended video duration: Spanning videos from brief 3-second clips to\ncomprehensive 1.5-hour recordings, thereby bridging the temporal gaps found in\ncurrent benchmarks. Comprehensive assessment tasks: Beyond traditional\nperceptual and reasoning tasks, we have introduced modules for\ncountercommonsense comprehension and trajectory state tracking. These additions\ntest the models' deep understanding capabilities beyond mere prior knowledge.\nEnriched video data: To keep pace with the rapid evolution of current AI\nagents, we have expanded first-person streaming video datasets. This expansion\nallows for the exploration of multimodal models' performance in understanding\nstreaming videos from a first-person perspective. Extensive results from H2VU\nreveal that existing multimodal large language models (MLLMs) possess\nsubstantial potential for improvement in our newly proposed evaluation tasks.\nWe expect that H2VU will facilitate advancements in video understanding\nresearch by offering a comprehensive and in-depth analysis of MLLMs.",
      "tldr_zh": "该论文提出H2VU基准，这是一个全面的评估框架，用于测试多模态模型在分层整体视频理解方面的能力，以解决现有基准在覆盖面、任务多样性和场景适应性上的不足。H2VU的关键创新包括扩展视频时长（从3秒到1.5小时）、引入新的评估任务（如反常识理解和轨迹状态跟踪）、以及丰富第一人称流媒体视频数据集，从而更全面地评估模型的视频理解深度。实验结果显示，现有的多模态大语言模型(MLLMs)在这些新任务中仍有显著改进空间，预计H2VU将推动视频理解研究的进步。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.24008v1",
      "published_date": "2025-03-31 12:32:51 UTC",
      "updated_date": "2025-03-31 12:32:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:02:08.090384"
    },
    {
      "arxiv_id": "2503.24007v1",
      "title": "CITRAS: Covariate-Informed Transformer for Time Series Forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Yosuke Yamaguchi",
        "Issei Suemitsu",
        "Wenpeng Wei"
      ],
      "abstract": "Covariates play an indispensable role in practical time series forecasting,\noffering rich context from the past and sometimes extending into the future.\nHowever, their availability varies depending on the scenario, and situations\noften involve multiple target variables simultaneously. Moreover, the\ncross-variate dependencies between them are multi-granular, with some\ncovariates having a short-term impact on target variables and others showing\nlong-term correlations. This heterogeneity and the intricate dependencies\narising in covariate-informed forecasting present significant challenges to\nexisting deep models. To address these issues, we propose CITRAS, a patch-based\nTransformer that flexibly leverages multiple targets and covariates covering\nboth the past and the future forecasting horizon. While preserving the strong\nautoregressive capabilities of the canonical Transformer, CITRAS introduces two\nnovel mechanisms in patch-wise cross-variate attention: Key-Value (KV) Shift\nand Attention Score Smoothing. KV Shift seamlessly incorporates future known\ncovariates into the forecasting of target variables based on their concurrent\ndependencies. Additionally, Attention Score Smoothing transforms locally\naccurate patch-wise cross-variate dependencies into global variate-level\ndependencies by smoothing the past series of attention scores. Experimentally,\nCITRAS achieves state-of-the-art performance in both covariate-informed and\nmultivariate forecasting, demonstrating its versatile ability to leverage\ncross-variate dependency for improved forecasting accuracy.",
      "tldr_zh": "本论文提出 CITRAS，一种基于 Transformer 的时间序列预测模型，能够灵活整合协变量（covariates）和多个目标变量，处理多粒度跨变量依赖性（如短期和长期相关）。CITRAS 引入 Key-Value (KV) Shift 机制来无缝融入未来已知协变量，以及 Attention Score Smoothing 机制来将局部 patch-wise 依赖转化为全局变量级依赖，从而提升预测准确性。实验结果表明，CITRAS 在协变量信息预测和多变量预测任务中达到最先进性能，展示了其在利用复杂跨变量依赖方面的强大能力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.24007v1",
      "published_date": "2025-03-31 12:32:23 UTC",
      "updated_date": "2025-03-31 12:32:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:02:20.412092"
    },
    {
      "arxiv_id": "2503.24000v1",
      "title": "Rethinking Key-Value Cache Compression Techniques for Large Language Model Serving",
      "title_zh": "翻译失败",
      "authors": [
        "Wei Gao",
        "Xinyu Zhou",
        "Peng Sun",
        "Tianwei Zhang",
        "Yonggang Wen"
      ],
      "abstract": "Key-Value cache (\\texttt{KV} \\texttt{cache}) compression has emerged as a\npromising technique to optimize Large Language Model (LLM) serving. It\nprimarily decreases the memory consumption of \\texttt{KV} \\texttt{cache} to\nreduce the computation cost. Despite the development of many compression\nalgorithms, their applications in production environments are still not\nprevalent. In this paper, we revisit mainstream \\texttt{KV} \\texttt{cache}\ncompression solutions from a practical perspective. Our contributions are\nthree-fold. First, we comprehensively review existing algorithmic designs and\nbenchmark studies for \\texttt{KV} \\texttt{cache} compression and identify\nmissing pieces in their performance measurement, which could hinder their\nadoption in practice. Second, we empirically evaluate representative\n\\texttt{KV} \\texttt{cache} compression methods to uncover two key issues that\naffect the computational efficiency: (1) while compressing \\texttt{KV}\n\\texttt{cache} can reduce memory consumption, current implementations (e.g.,\nFlashAttention, PagedAttention) do not optimize for production-level LLM\nserving, resulting in suboptimal throughput performance; (2) compressing\n\\texttt{KV} \\texttt{cache} may lead to longer outputs, resulting in increased\nend-to-end latency. We further investigate the accuracy performance of\nindividual samples rather than the overall performance, revealing the intrinsic\nlimitations in \\texttt{KV} \\texttt{cache} compression when handling specific\nLLM tasks. Third, we provide tools to shed light on future \\texttt{KV}\n\\texttt{cache} compression studies and facilitate their practical deployment in\nproduction. They are open-sourced in\n\\href{https://github.com/LLMkvsys/rethink-kv-compression}{https://github.com/LLMkvsys/rethink-kv-compression}.",
      "tldr_zh": "这篇论文重新审视了 KV cache 压缩技术在 Large Language Model (LLM) 服务中的应用，旨在优化内存消耗并降低计算成本。作者通过全面审查现有算法和基准测试，识别了性能测量中的缺失问题，并通过实证评估揭示了关键挑战：包括压缩实现（如 FlashAttention 和 PagedAttention）导致的吞吐量 suboptimal、输出延长增加端到端延迟，以及对个体样本准确性的内在限制。最终，论文提供了开源工具（可访问 https://github.com/LLMkvsys/rethink-kv-compression），以推动未来 KV cache 压缩研究和实际部署。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "21 pages, 18 figures, published to MLSys2025",
      "pdf_url": "http://arxiv.org/pdf/2503.24000v1",
      "published_date": "2025-03-31 12:23:31 UTC",
      "updated_date": "2025-03-31 12:23:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:02:32.314789"
    },
    {
      "arxiv_id": "2504.03726v1",
      "title": "Detecting Malicious AI Agents Through Simulated Interactions",
      "title_zh": "通过模拟交互检测恶意 AI 代理",
      "authors": [
        "Yulu Pi",
        "Ella Bettison",
        "Anna Becker"
      ],
      "abstract": "This study investigates malicious AI Assistants' manipulative traits and\nwhether the behaviours of malicious AI Assistants can be detected when\ninteracting with human-like simulated users in various decision-making\ncontexts. We also examine how interaction depth and ability of planning\ninfluence malicious AI Assistants' manipulative strategies and effectiveness.\nUsing a controlled experimental design, we simulate interactions between AI\nAssistants (both benign and deliberately malicious) and users across eight\ndecision-making scenarios of varying complexity and stakes. Our methodology\nemploys two state-of-the-art language models to generate interaction data and\nimplements Intent-Aware Prompting (IAP) to detect malicious AI Assistants. The\nfindings reveal that malicious AI Assistants employ domain-specific\npersona-tailored manipulation strategies, exploiting simulated users'\nvulnerabilities and emotional triggers. In particular, simulated users\ndemonstrate resistance to manipulation initially, but become increasingly\nvulnerable to malicious AI Assistants as the depth of the interaction\nincreases, highlighting the significant risks associated with extended\nengagement with potentially manipulative systems. IAP detection methods achieve\nhigh precision with zero false positives but struggle to detect many malicious\nAI Assistants, resulting in high false negative rates. These findings\nunderscore critical risks in human-AI interactions and highlight the need for\nrobust, context-sensitive safeguards against manipulative AI behaviour in\nincreasingly autonomous decision-support systems.",
      "tldr_zh": "这篇论文研究了通过模拟互动检测恶意 AI 助手的操纵行为，重点考察互动深度和规划能力对这些策略的影响。研究采用受控实验设计，使用两种先进语言模型模拟 AI 助手（良性和恶意）与用户在八种决策场景中的互动，并引入 Intent-Aware Prompting (IAP) 方法进行检测。结果显示，恶意 AI 助手会针对用户的弱点和情感触发器采用领域特定的个性化操纵策略，随着互动深度增加，用户抵抗力下降。论文强调了人类-AI 互动中的潜在风险，并呼吁开发更 robust 的防护措施以应对自主决策系统中的操纵行为。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.03726v1",
      "published_date": "2025-03-31 12:22:24 UTC",
      "updated_date": "2025-03-31 12:22:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:02:44.633514"
    },
    {
      "arxiv_id": "2504.00060v2",
      "title": "CF-CAM: Cluster Filter Class Activation Mapping for Reliable Gradient-Based Interpretability",
      "title_zh": "翻译失败",
      "authors": [
        "Hongjie He",
        "Xu Pan",
        "Yudong Yao"
      ],
      "abstract": "As deep learning continues to advance, the transparency of neural network\ndecision-making remains a critical challenge, limiting trust and applicability\nin high-stakes domains. Class Activation Mapping (CAM) techniques have emerged\nas a key approach toward visualizing model decisions, yet existing methods face\ninherent trade-offs. Gradient-based CAM variants suffer from sensitivity to\ngradient perturbations due to gradient noise, leading to unstable and\nunreliable explanations. Conversely, gradient-free approaches mitigate gradient\ninstability but incur significant computational overhead and inference latency.\nTo address these limitations, we propose a Cluster Filter Class Activation Map\n(CF-CAM) technique, a novel framework that reintroduces gradient-based\nweighting while enhancing robustness against gradient noise. CF-CAM utilizes\nhierarchical importance weighting strategy to balance discriminative feature\npreservation and noise elimination. A density-aware channel clustering method\nvia Density-Based Spatial Clustering of Applications with Noise (DBSCAN) groups\nsemantically relevant feature channels and discard noise-prone activations.\nAdditionally, cluster-conditioned gradient filtering leverages Gaussian filters\nto refine gradient signals, preserving edge-aware localization while\nsuppressing noise impact. Experiment results demonstrate that CF-CAM achieves\nsuperior interpretability performance while enhancing computational efficiency,\noutperforming state-of-the-art CAM methods in faithfulness and robustness. By\neffectively mitigating gradient instability without excessive computational\ncost, CF-CAM provides a competitive solution for enhancing the interpretability\nof deep neural networks in critical applications such as autonomous driving and\nmedical diagnosis.",
      "tldr_zh": "该研究针对神经网络决策的可解释性挑战，提出了一种新的梯度-based Class Activation Mapping (CAM) 技术——CF-CAM，以解决传统方法在梯度噪声敏感性和计算效率上的缺陷。CF-CAM 通过分层重要性权重策略、Density-Based Spatial Clustering of Applications with Noise (DBSCAN) 进行密度感知通道聚类，以及 cluster-conditioned gradient filtering 和 Gaussian filters 来保留关键特征并消除噪声，从而提升解释的鲁棒性和忠实度。实验结果显示，CF-CAM 在可解释性性能上优于现有CAM方法，同时提高了计算效率，适用于高风险领域如自动驾驶和医疗诊断。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.00060v2",
      "published_date": "2025-03-31 12:20:59 UTC",
      "updated_date": "2025-04-23 13:49:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:02:56.637681"
    },
    {
      "arxiv_id": "2503.23993v1",
      "title": "DenseFormer: Learning Dense Depth Map from Sparse Depth and Image via Conditional Diffusion Model",
      "title_zh": "DenseFormer：通过条件扩散模型从稀疏深度和图像学习密集深度图",
      "authors": [
        "Ming Yuan",
        "Sichao Wang",
        "Chuang Zhang",
        "Lei He",
        "Qing Xu",
        "Jianqiang Wang"
      ],
      "abstract": "The depth completion task is a critical problem in autonomous driving,\ninvolving the generation of dense depth maps from sparse depth maps and RGB\nimages. Most existing methods employ a spatial propagation network to\niteratively refine the depth map after obtaining an initial dense depth. In\nthis paper, we propose DenseFormer, a novel method that integrates the\ndiffusion model into the depth completion task. By incorporating the denoising\nmechanism of the diffusion model, DenseFormer generates the dense depth map by\nprogressively refining an initial random depth distribution through multiple\niterations. We propose a feature extraction module that leverages a feature\npyramid structure, along with multi-layer deformable attention, to effectively\nextract and integrate features from sparse depth maps and RGB images, which\nserve as the guiding condition for the diffusion process. Additionally, this\npaper presents a depth refinement module that applies multi-step iterative\nrefinement across various ranges to the dense depth results generated by the\ndiffusion process. The module utilizes image features enriched with multi-scale\ninformation and sparse depth input to further enhance the accuracy of the\npredicted depth map. Extensive experiments on the KITTI outdoor scene dataset\ndemonstrate that DenseFormer outperforms classical depth completion methods.",
      "tldr_zh": "本论文提出 DenseFormer，一种利用条件 diffusion model 从稀疏深度图和 RGB 图像生成密集深度图的方法，旨在解决深度完成任务中的精度问题。DenseFormer 通过扩散模型的去噪机制逐步精炼初始随机深度分布，并引入特征提取模块（基于特征金字塔结构和多层可变形注意力）来整合输入特征，作为扩散过程的指导条件，同时使用深度精炼模块进行多步迭代优化以提升预测准确性。在 KITTI 数据集上的广泛实验显示，DenseFormer 优于经典深度完成方法，展示了其有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.23993v1",
      "published_date": "2025-03-31 12:11:01 UTC",
      "updated_date": "2025-03-31 12:11:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:03:09.634372"
    },
    {
      "arxiv_id": "2503.23989v1",
      "title": "Rubric Is All You Need: Enhancing LLM-based Code Evaluation With Question-Specific Rubrics",
      "title_zh": "翻译失败",
      "authors": [
        "Aditya Pathak",
        "Rachit Gandhi",
        "Vaibhav Uttam",
        "Devansh",
        "Yashwanth Nakka",
        "Aaryan Raj Jindal",
        "Pratyush Ghosh",
        "Arnav Ramamoorthy",
        "Shreyash Verma",
        "Aditya Mittal",
        "Aashna Ased",
        "Chirag Khatri",
        "Jagat Sesh Challa",
        "Dhruv Kumar"
      ],
      "abstract": "Since the disruption in LLM technology brought about by the release of GPT-3\nand ChatGPT, LLMs have shown remarkable promise in programming-related tasks.\nWhile code generation remains a popular field of research, code evaluation\nusing LLMs remains a problem with no conclusive solution. In this paper, we\nfocus on LLM-based code evaluation and attempt to fill in the existing gaps. We\npropose multi-agentic novel approaches using question-specific rubrics tailored\nto the problem statement, arguing that these perform better for logical\nassessment than the existing approaches that use question-agnostic rubrics. To\naddress the lack of suitable evaluation datasets, we introduce two datasets: a\nData Structures and Algorithms dataset containing 150 student submissions from\na popular Data Structures and Algorithms practice website, and an Object\nOriented Programming dataset comprising 80 student submissions from\nundergraduate computer science courses. In addition to using standard metrics\n(Spearman Correlation, Cohen's Kappa), we additionally propose a new metric\ncalled as Leniency, which quantifies evaluation strictness relative to expert\nassessment. Our comprehensive analysis demonstrates that question-specific\nrubrics significantly enhance logical assessment of code in educational\nsettings, providing better feedback aligned with instructional goals beyond\nmere syntactic correctness.",
      "tldr_zh": "本论文探讨了使用大型语言模型（LLM）进行代码评估的挑战，并提出一种基于多智能体方法的新方法，即采用特定于问题的评分标准（question-specific rubrics），以提升代码的逻辑评估性能，相比传统的无关问题评分标准（question-agnostic rubrics）更有效。该方法引入两个新数据集：一个包含150个数据结构和算法学生提交的DSA数据集，以及一个包含80个面向对象编程学生提交的OOP数据集；同时提出一个新指标Leniency，用于量化评估的严格程度与专家评估的相对性。实验结果显示，这种方法显著提高了代码评估的逻辑准确性，提供更符合教学目标的反馈，不仅关注语法正确性，还提升了整体教育适用性。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "Under Review",
      "pdf_url": "http://arxiv.org/pdf/2503.23989v1",
      "published_date": "2025-03-31 11:59:43 UTC",
      "updated_date": "2025-03-31 11:59:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:03:19.851039"
    },
    {
      "arxiv_id": "2503.23988v1",
      "title": "Deep Learning Model Deployment in Multiple Cloud Providers: an Exploratory Study Using Low Computing Power Environments",
      "title_zh": "翻译失败",
      "authors": [
        "Elayne Lemos",
        "Rodrigo Oliveira",
        "Jairson Rodrigues",
        "Rosalvo F. Oliveira Neto"
      ],
      "abstract": "The deployment of Machine Learning models at cloud have grown by tech\ncompanies. Hardware requirements are higher when these models involve Deep\nLearning (DL) techniques and the cloud providers' costs may be a barrier. We\nexplore deploying DL models using for experiments the GECToR model, a DL\nsolution for Grammatical Error Correction, across three of the major cloud\nplatforms (AWS, Google Cloud, Azure). We evaluate real-time latency, hardware\nusage and cost at each cloud provider by 7 execution environments with 10\nexperiments reproduced. We found that while GPUs excel in performance, they had\nan average cost 300% higher than solutions without GPU. Our analysis also\nidentifies that processor cache size is crucial for cost-effective CPU\ndeployments, enabling over 50% of cost reduction compared to GPUs. This study\ndemonstrates the feasibility and affordability of cloud-based DL inference\nsolutions without GPUs, benefiting resource-constrained users like startups.",
      "tldr_zh": "该研究探讨了在低计算环境（Low Computing Power Environments）中部署深度学习（DL）模型于多个云提供商（AWS、Google Cloud、Azure）的可行性与成本问题，使用 GECToR 模型（一个语法错误修正的 DL 解决方案）进行实验。研究通过 7 个执行环境和 10 次重复实验，评估了实时延迟、硬件使用和成本，发现 GPU 在性能上表现出色，但平均成本比无 GPU 方案高 300%。此外，处理器缓存大小对 CPU 部署至关重要，能实现超过 50% 的成本降低；这证明了云端 DL 推理无 GPU 方案的经济性和实用性，尤其适合资源受限用户如初创公司。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.PF",
        "68T07, 68U01",
        "C.4; I.2.0; B.8.2"
      ],
      "primary_category": "cs.DC",
      "comment": "15 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.23988v1",
      "published_date": "2025-03-31 11:58:37 UTC",
      "updated_date": "2025-03-31 11:58:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:03:32.763146"
    },
    {
      "arxiv_id": "2503.23982v2",
      "title": "Deep Neural Nets as Hamiltonians",
      "title_zh": "翻译失败",
      "authors": [
        "Mike Winer",
        "Boris Hanin"
      ],
      "abstract": "Neural networks are complex functions of both their inputs and parameters.\nMuch prior work in deep learning theory analyzes the distribution of network\noutputs at a fixed a set of inputs (e.g. a training dataset) over random\ninitializations of the network parameters. The purpose of this article is to\nconsider the opposite situation: we view a randomly initialized Multi-Layer\nPerceptron (MLP) as a Hamiltonian over its inputs. For typical realizations of\nthe network parameters, we study the properties of the energy landscape induced\nby this Hamiltonian, focusing on the structure of near-global minimum in the\nlimit of infinite width. Specifically, we use the replica trick to perform an\nexact analytic calculation giving the entropy (log volume of space) at a given\nenergy. We further derive saddle point equations that describe the overlaps\nbetween inputs sampled iid from the Gibbs distribution induced by the random\nMLP. For linear activations we solve these saddle point equations exactly. But\nwe also solve them numerically for a variety of depths and activation\nfunctions, including $\\tanh, \\sin, \\text{ReLU}$, and shaped non-linearities. We\nfind even at infinite width a rich range of behaviors. For some\nnon-linearities, such as $\\sin$, for instance, we find that the landscapes of\nrandom MLPs exhibit full replica symmetry breaking, while shallow $\\tanh$ and\nReLU networks or deep shaped MLPs are instead replica symmetric.",
      "tldr_zh": "这篇论文将随机初始化的多层感知器 (MLP) 视为一个 Hamiltonian，分析其在输入上的能量景观，特别是无限宽度极限下全局最小的结构。作者使用 replica trick 进行精确计算，得出给定能量的熵（log volume of space），并推导 saddle point equations 来描述从随机 MLP 诱导的 Gibbs distribution 中采样的输入 overlaps。对于线性激活函数，equations 被精确求解，而对于 tanh、sin、ReLU 和其他非线性函数，则通过数值方法求解。研究发现，不同激活函数导致丰富的行为多样性，例如 sin 显示 full replica symmetry breaking，而浅层 tanh 或 ReLU 网络则保持 replica symmetric。",
      "categories": [
        "cond-mat.dis-nn",
        "cond-mat.stat-mech",
        "cs.AI",
        "cs.LG",
        "math.PR"
      ],
      "primary_category": "cond-mat.dis-nn",
      "comment": "19+7 pages",
      "pdf_url": "http://arxiv.org/pdf/2503.23982v2",
      "published_date": "2025-03-31 11:51:10 UTC",
      "updated_date": "2025-04-05 09:41:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:03:44.410773"
    },
    {
      "arxiv_id": "2503.23972v1",
      "title": "Noise-based reward-modulated learning",
      "title_zh": "基于噪声的奖励调制学习",
      "authors": [
        "Jesús García Fernández",
        "Nasir Ahmad",
        "Marcel van Gerven"
      ],
      "abstract": "Recent advances in reinforcement learning (RL) have led to significant\nimprovements in task performance. However, training neural networks in an RL\nregime is typically achieved in combination with backpropagation, limiting\ntheir applicability in resource-constrained environments or when using\nnon-differentiable neural networks. While noise-based alternatives like\nreward-modulated Hebbian learning (RMHL) have been proposed, their performance\nhas remained limited, especially in scenarios with delayed rewards, which\nrequire retrospective credit assignment over time. Here, we derive a novel\nnoise-based learning rule that addresses these challenges. Our approach\ncombines directional derivative theory with Hebbian-like updates to enable\nefficient, gradient-free learning in RL. It features stochastic noisy neurons\nwhich can approximate gradients, and produces local synaptic updates modulated\nby a global reward signal. Drawing on concepts from neuroscience, our method\nuses reward prediction error as its optimization target to generate\nincreasingly advantageous behavior, and incorporates an eligibility trace to\nfacilitate temporal credit assignment in environments with delayed rewards. Its\nformulation relies on local information alone, making it compatible with\nimplementations in neuromorphic hardware. Experimental validation shows that\nour approach significantly outperforms RMHL and is competitive with BP-based\nbaselines, highlighting the promise of noise-based, biologically inspired\nlearning for low-power and real-time applications.",
      "tldr_zh": "该论文提出了一种新型噪声-based 学习规则，用于解决强化学习（RL）中依赖反向传播（BP）的局限性问题，该方法结合方向导数理论和 Hebbian-like 更新，实现高效的无梯度学习。关键创新包括使用随机噪声神经元近似梯度、通过全局奖励信号调节局部突触更新，并引入奖励预测错误和资格迹（eligibility trace）来处理延迟奖励场景。该方法仅依赖本地信息，适合神经形态硬件实现，且实验结果显示其显著优于 reward-modulated Hebbian learning (RMHL) 并与 BP-based 基线相当，展示了在低功耗和实时应用中的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.23972v1",
      "published_date": "2025-03-31 11:35:23 UTC",
      "updated_date": "2025-03-31 11:35:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:03:57.481099"
    },
    {
      "arxiv_id": "2503.23956v1",
      "title": "AirCache: Activating Inter-modal Relevancy KV Cache Compression for Efficient Large Vision-Language Model Inference",
      "title_zh": "翻译失败",
      "authors": [
        "Kai Huang",
        "Hao Zou",
        "Bochen Wang",
        "Ye Xi",
        "Zhen Xie",
        "Hao Wang"
      ],
      "abstract": "Recent advancements in Large Visual Language Models (LVLMs) have gained\nsignificant attention due to their remarkable reasoning capabilities and\nproficiency in generalization. However, processing a large number of visual\ntokens and generating long-context outputs impose substantial computational\noverhead, leading to excessive demands for key-value (KV) cache. To address\nthis critical bottleneck, we propose AirCache, a novel KV cache compression\nmethod aimed at accelerating LVLMs inference. This work systematically\ninvestigates the correlations between visual and textual tokens within the\nattention mechanisms of LVLMs. Our empirical analysis reveals considerable\nredundancy in cached visual tokens, wherein strategically eliminating these\ntokens preserves model performance while significantly accelerating context\ngeneration. Inspired by these findings, we introduce an elite observation\nwindow for assessing the importance of visual components in the KV cache,\nfocusing on stable inter-modal relevancy modeling with enhanced\nmulti-perspective consistency. Additionally, we develop an adaptive layer-wise\nbudget allocation strategy that capitalizes on the strength and skewness of\ntoken importance distribution, showcasing superior efficiency compared to\nuniform allocation. Comprehensive evaluations across multiple LVLMs and\nbenchmarks demonstrate that our method achieves comparable performance to the\nfull cache while retaining only 10% of visual KV cache, thereby reducing\ndecoding latency by 29% to 66% across various batch size and prompt length of\ninputs. Notably, as cache retention rates decrease, our method exhibits\nincreasing performance advantages over existing approaches.",
      "tldr_zh": "本文提出 AirCache，一种创新的 KV cache 压缩方法，旨在解决 Large Visual Language Models (LVLMs) 在处理大量视觉 tokens 和长上下文时导致的计算开销问题。通过分析视觉和文本 tokens 在注意力机制中的相关性，该方法识别并消除冗余视觉 tokens，同时引入 elite observation window 和自适应层级预算分配策略，以维持跨模态相关性建模的稳定性和效率。实验结果显示，AirCache 仅保留 10% 的视觉 KV cache 即可实现与全 cache 相当的性能，并将解码延迟降低 29% 到 66%，且在缓存保留率降低时表现出色于现有方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.23956v1",
      "published_date": "2025-03-31 11:13:18 UTC",
      "updated_date": "2025-03-31 11:13:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:04:09.997340"
    },
    {
      "arxiv_id": "2503.23948v1",
      "title": "AI2Agent: An End-to-End Framework for Deploying AI Projects as Autonomous Agents",
      "title_zh": "AI2Agent：一种端到端的框架，用于将AI项目部署为自治代理",
      "authors": [
        "Jiaxiang Chen",
        "Jingwei Shi",
        "Lei Gan",
        "Jiale Zhang",
        "Qingyu Zhang",
        "Dongqian Zhang",
        "Xin Pang",
        "Zhucong Li",
        "Yinghui Xu"
      ],
      "abstract": "As AI technology advances, it is driving innovation across industries,\nincreasing the demand for scalable AI project deployment. However, deployment\nremains a critical challenge due to complex environment configurations,\ndependency conflicts, cross-platform adaptation, and debugging difficulties,\nwhich hinder automation and adoption. This paper introduces AI2Agent, an\nend-to-end framework that automates AI project deployment through\nguideline-driven execution, self-adaptive debugging, and case \\& solution\naccumulation. AI2Agent dynamically analyzes deployment challenges, learns from\npast cases, and iteratively refines its approach, significantly reducing human\nintervention. To evaluate its effectiveness, we conducted experiments on 30 AI\ndeployment cases, covering TTS, text-to-image generation, image editing, and\nother AI applications. Results show that AI2Agent significantly reduces\ndeployment time and improves success rates. The code and demo video are now\npublicly accessible.",
      "tldr_zh": "这篇论文介绍了 AI2Agent，一个端到端的框架，用于将 AI 项目部署为自治代理，以解决环境配置复杂、依赖冲突、跨平台适应和调试难题等问题。AI2Agent 通过 guideline-driven execution、自-adaptive debugging 和案例与解决方案积累机制，动态分析部署挑战、从过去案例中学习，并迭代优化过程，从而显著减少人为干预。在 30 个 AI 部署案例的实验中，包括 TTS、文本到图像生成和图像编辑等应用，该框架降低了部署时间并提高了成功率，代码和演示视频已公开可用。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.23948v1",
      "published_date": "2025-03-31 10:58:34 UTC",
      "updated_date": "2025-03-31 10:58:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:04:22.226062"
    },
    {
      "arxiv_id": "2503.23934v1",
      "title": "Green MLOps to Green GenOps: An Empirical Study of Energy Consumption in Discriminative and Generative AI Operations",
      "title_zh": "绿色 MLOps 到绿色 GenOps：判别式和生成式 AI 操作中能量消耗的实证研究",
      "authors": [
        "Adrián Sánchez-Mompó",
        "Ioannis Mavromatis",
        "Peizheng Li",
        "Konstantinos Katsaros",
        "Aftab Khan"
      ],
      "abstract": "This study presents an empirical investigation into the energy consumption of\nDiscriminative and Generative AI models within real-world MLOps pipelines. For\nDiscriminative models, we examine various architectures and hyperparameters\nduring training and inference and identify energy-efficient practices. For\nGenerative AI, Large Language Models (LLMs) are assessed, focusing primarily on\nenergy consumption across different model sizes and varying service requests.\nOur study employs software-based power measurements, ensuring ease of\nreplication across diverse configurations, models, and datasets. We analyse\nmultiple models and hardware setups to uncover correlations among various\nmetrics, identifying key contributors to energy consumption. The results\nindicate that for Discriminative models, optimising architectures,\nhyperparameters, and hardware can significantly reduce energy consumption\nwithout sacrificing performance. For LLMs, energy efficiency depends on\nbalancing model size, reasoning complexity, and request-handling capacity, as\nlarger models do not necessarily consume more energy when utilisation remains\nlow. This analysis provides practical guidelines for designing green and\nsustainable ML operations, emphasising energy consumption and carbon footprint\nreductions while maintaining performance. This paper can serve as a benchmark\nfor accurately estimating total energy use across different types of AI models.",
      "tldr_zh": "这篇论文通过实证研究，调查了Discriminative和Generative AI模型在MLOps管道中的能源消耗，评估了训练、推理过程中的各种架构、超参数和硬件因素。研究采用软件-based功率测量方法，分析多个模型和设置，揭示能源消耗的关键影响因素，如模型大小和请求处理能力。结果显示，优化Discriminative模型的架构和硬件可显著减少能源消耗而不影响性能，而对于LLMs，能源效率取决于模型规模与利用率的平衡；整体提供实用指南，促进绿色ML操作并降低碳足迹。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Published to MDPI Information - Artificial Intelligence Section",
      "pdf_url": "http://arxiv.org/pdf/2503.23934v1",
      "published_date": "2025-03-31 10:28:04 UTC",
      "updated_date": "2025-03-31 10:28:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:04:34.687024"
    },
    {
      "arxiv_id": "2503.23923v1",
      "title": "What the F*ck Is Artificial General Intelligence?",
      "title_zh": "翻译失败",
      "authors": [
        "Michael Timothy Bennett"
      ],
      "abstract": "Artificial general intelligence (AGI) is an established field of research.\nYet Melanie Mitchell and others have questioned if the term still has meaning.\nAGI has been subject to so much hype and speculation it has become something of\na Rorschach test. Mitchell points out that the debate will only be settled\nthrough long term, scientific investigation. To that end here is a short,\naccessible and provocative overview of AGI. I compare definitions of\nintelligence, settling on intelligence in terms of adaptation and AGI as an\nartificial scientist. Taking my queue from Sutton's Bitter Lesson I describe\ntwo foundational tools used to build adaptive systems: search and\napproximation. I compare pros, cons, hybrids and architectures like o3,\nAlphaGo, AERA, NARS and Hyperon. I then discuss overall meta-approaches to\nmaking systems behave more intelligently. I divide them into scale-maxing,\nsimp-maxing, w-maxing based on the Bitter Lesson, Ockham's and Bennett's\nRazors. These maximise resources, simplicity of form, and the weakness of\nconstraints on functionality. I discuss examples including AIXI, the free\nenergy principle and The Embiggening of language models. I conclude that though\nscale-maxed approximation dominates, AGI will be a fusion of tools and\nmeta-approaches. The Embiggening was enabled by improvements in hardware. Now\nthe bottlenecks are sample and energy efficiency.",
      "tldr_zh": "这篇论文审视了人工智能通用智能(AGI)的定义和意义，通过比较各种智能概念，将AGI定义为一种适应性强的“人工科学家”。作者讨论了构建适应性系统的两大基础工具——搜索和近似，并比较了如AlphaGo、AERA和Hyperon等架构的优缺点。论文进一步将AGI发展方法分为scale-maxing（最大化资源）、simp-maxing（简化形式）和w-maxing（弱化功能约束），并举例说明如AIXI、自由能量原则和语言模型的Embiggening。最终，作者得出结论，尽管规模化近似目前主导AGI进展，但未来将融合多种工具和方法，而样本和能量效率将成为关键瓶颈。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Preprint; 10 pages;",
      "pdf_url": "http://arxiv.org/pdf/2503.23923v1",
      "published_date": "2025-03-31 10:15:37 UTC",
      "updated_date": "2025-03-31 10:15:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:04:45.463261"
    },
    {
      "arxiv_id": "2504.00058v2",
      "title": "GAL-MAD: Towards Explainable Anomaly Detection in Microservice Applications Using Graph Attention Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Lahiru Akmeemana",
        "Chamodya Attanayake",
        "Husni Faiz",
        "Sandareka Wickramanayake"
      ],
      "abstract": "The transition to microservices has revolutionized software architectures,\noffering enhanced scalability and modularity. However, the distributed and\ndynamic nature of microservices introduces complexities in ensuring system\nreliability, making anomaly detection crucial for maintaining performance and\nfunctionality. Anomalies stemming from network and performance issues must be\nswiftly identified and addressed. Existing anomaly detection techniques often\nrely on statistical models or machine learning methods that struggle with the\nhigh-dimensional, interdependent data inherent in microservice applications.\nCurrent techniques and available datasets predominantly focus on system traces\nand logs, limiting their ability to support advanced detection models. This\npaper addresses these gaps by introducing the RS-Anomic dataset generated using\nthe open-source RobotShop microservice application. The dataset captures\nmultivariate performance metrics and response times under normal and anomalous\nconditions, encompassing ten types of anomalies. We propose a novel anomaly\ndetection model called Graph Attention and LSTM-based Microservice Anomaly\nDetection (GAL-MAD), leveraging Graph Attention and Long Short-Term Memory\narchitectures to capture spatial and temporal dependencies in microservices. We\nutilize SHAP values to localize anomalous services and identify root causes to\nenhance explainability. Experimental results demonstrate that GAL-MAD\noutperforms state-of-the-art models on the RS-Anomic dataset, achieving higher\naccuracy and recall across varying anomaly rates. The explanations provide\nactionable insights into service anomalies, which benefits system\nadministrators.",
      "tldr_zh": "该论文针对微服务应用的异常检测挑战，引入了RS-Anomic数据集，该数据集基于RobotShop开源应用生成，包含多变量性能指标和响应时间，并涵盖十种异常类型。\n他们提出GAL-MAD模型，利用Graph Attention Networks和LSTM捕获微服务中的空间和时间依赖性，并通过SHAP值实现异常服务的定位和根因分析，提高了检测的可解释性。\n实验结果表明，GAL-MAD在RS-Anomic数据集上超越现有模型，在准确率和召回率上显著提升，并为系统管理员提供可操作的异常洞见。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG",
        "I.2.m"
      ],
      "primary_category": "cs.SE",
      "comment": "Preprint - Journal of Universal Computer Science, 13 pages, preprint,\n  7 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.00058v2",
      "published_date": "2025-03-31 10:11:31 UTC",
      "updated_date": "2025-04-26 07:49:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:04:58.625323"
    },
    {
      "arxiv_id": "2503.23907v1",
      "title": "HumanAesExpert: Advancing a Multi-Modality Foundation Model for Human Image Aesthetic Assessment",
      "title_zh": "翻译失败",
      "authors": [
        "Zhichao Liao",
        "Xiaokun Liu",
        "Wenyu Qin",
        "Qingyu Li",
        "Qiulin Wang",
        "Pengfei Wan",
        "Di Zhang",
        "Long Zeng",
        "Pingfa Feng"
      ],
      "abstract": "Image Aesthetic Assessment (IAA) is a long-standing and challenging research\ntask. However, its subset, Human Image Aesthetic Assessment (HIAA), has been\nscarcely explored, even though HIAA is widely used in social media, AI\nworkflows, and related domains. To bridge this research gap, our work pioneers\na holistic implementation framework tailored for HIAA. Specifically, we\nintroduce HumanBeauty, the first dataset purpose-built for HIAA, which\ncomprises 108k high-quality human images with manual annotations. To achieve\ncomprehensive and fine-grained HIAA, 50K human images are manually collected\nthrough a rigorous curation process and annotated leveraging our trailblazing\n12-dimensional aesthetic standard, while the remaining 58K with overall\naesthetic labels are systematically filtered from public datasets. Based on the\nHumanBeauty database, we propose HumanAesExpert, a powerful Vision Language\nModel for aesthetic evaluation of human images. We innovatively design an\nExpert head to incorporate human knowledge of aesthetic sub-dimensions while\njointly utilizing the Language Modeling (LM) and Regression head. This approach\nempowers our model to achieve superior proficiency in both overall and\nfine-grained HIAA. Furthermore, we introduce a MetaVoter, which aggregates\nscores from all three heads, to effectively balance the capabilities of each\nhead, thereby realizing improved assessment precision. Extensive experiments\ndemonstrate that our HumanAesExpert models deliver significantly better\nperformance in HIAA than other state-of-the-art models. Our datasets, models,\nand codes are publicly released to advance the HIAA community. Project webpage:\nhttps://humanaesexpert.github.io/HumanAesExpert/",
      "tldr_zh": "该研究针对Human Image Aesthetic Assessment (HIAA) 的研究空白，首次引入HumanBeauty数据集，该数据集包含108k高质量人类图像，并采用12维美学标准进行细粒度标注。论文提出HumanAesExpert，一种多模态基础模型，通过Expert head整合人类美学子维度知识，并结合Language Modeling (LM) head、Regression head和MetaVoter聚合机制，实现精确的整体和细粒度HIAA评估。实验结果显示，HumanAesExpert在HIAA任务上显著优于现有最先进模型，且数据集、模型和代码已公开以推进社区发展。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.23907v1",
      "published_date": "2025-03-31 09:58:11 UTC",
      "updated_date": "2025-03-31 09:58:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:05:09.951262"
    },
    {
      "arxiv_id": "2503.23897v1",
      "title": "Training-Free Text-Guided Image Editing with Visual Autoregressive Model",
      "title_zh": "翻译失败",
      "authors": [
        "Yufei Wang",
        "Lanqing Guo",
        "Zhihao Li",
        "Jiaxing Huang",
        "Pichao Wang",
        "Bihan Wen",
        "Jian Wang"
      ],
      "abstract": "Text-guided image editing is an essential task that enables users to modify\nimages through natural language descriptions. Recent advances in diffusion\nmodels and rectified flows have significantly improved editing quality,\nprimarily relying on inversion techniques to extract structured noise from\ninput images. However, inaccuracies in inversion can propagate errors, leading\nto unintended modifications and compromising fidelity. Moreover, even with\nperfect inversion, the entanglement between textual prompts and image features\noften results in global changes when only local edits are intended. To address\nthese challenges, we propose a novel text-guided image editing framework based\non VAR (Visual AutoRegressive modeling), which eliminates the need for explicit\ninversion while ensuring precise and controlled modifications. Our method\nintroduces a caching mechanism that stores token indices and probability\ndistributions from the original image, capturing the relationship between the\nsource prompt and the image. Using this cache, we design an adaptive\nfine-grained masking strategy that dynamically identifies and constrains\nmodifications to relevant regions, preventing unintended changes. A token\nreassembling approach further refines the editing process, enhancing diversity,\nfidelity, and control. Our framework operates in a training-free manner and\nachieves high-fidelity editing with faster inference speeds, processing a 1K\nresolution image in as fast as 1.2 seconds. Extensive experiments demonstrate\nthat our method achieves performance comparable to, or even surpassing,\nexisting diffusion- and rectified flow-based approaches in both quantitative\nmetrics and visual quality. The code will be released.",
      "tldr_zh": "该论文提出了一种基于 VAR (Visual Autoregressive modeling) 的文本引导图像编辑框架，无需训练即可实现精确、受控的图像修改，解决了现有方法中 inversion 不准确导致的错误和全局变化问题。框架引入 caching mechanism 存储原始图像的 token indices 和概率分布，并采用 adaptive fine-grained masking strategy 动态识别并约束相关区域的修改，同时通过 token reassembling 提升编辑的多样性、fidelity 和控制。实验表明，该方法处理 1K 分辨率图像仅需 1.2 秒，在定量指标和视觉质量上达到或超过基于扩散模型和 rectified flows 的现有方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.23897v1",
      "published_date": "2025-03-31 09:46:56 UTC",
      "updated_date": "2025-03-31 09:46:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:05:22.438821"
    },
    {
      "arxiv_id": "2503.23895v4",
      "title": "Dynamic Parametric Retrieval Augmented Generation for Test-time Knowledge Enhancement",
      "title_zh": "翻译失败",
      "authors": [
        "Yuqiao Tan",
        "Shizhu He",
        "Huanxuan Liao",
        "Jun Zhao",
        "Kang Liu"
      ],
      "abstract": "Retrieval-augmented generation (RAG) enhances large language models (LLMs) by\nretrieving relevant documents from external sources and incorporating them into\nthe context. While it improves reliability by providing factual texts, it\nsignificantly increases inference costs as context length grows and introduces\nchallenging issue of RAG hallucination, primarily caused by the lack of\ncorresponding parametric knowledge in LLMs. An efficient solution is to enhance\nthe knowledge of LLMs at test-time. Parametric RAG (PRAG) addresses this by\nembedding document into LLMs parameters to perform test-time knowledge\nenhancement, effectively reducing inference costs through offline training.\nHowever, its high training and storage costs, along with limited generalization\nability, significantly restrict its practical adoption. To address these\nchallenges, we propose Dynamic Parametric RAG (DyPRAG), a novel framework that\nleverages a lightweight parameter translator model to efficiently convert\ndocuments into parametric knowledge. DyPRAG not only reduces inference,\ntraining, and storage costs but also dynamically generates parametric\nknowledge, seamlessly enhancing the knowledge of LLMs and resolving knowledge\nconflicts in a plug-and-play manner at test-time. Extensive experiments on\nmultiple datasets demonstrate the effectiveness and generalization capabilities\nof DyPRAG, offering a powerful and practical RAG paradigm which enables\nsuperior knowledge fusion and mitigates RAG hallucination in real-world\napplications. Our code is available at https://github.com/Trae1ounG/DyPRAG.",
      "tldr_zh": "该研究针对检索增强生成（RAG）模型在提升大型语言模型（LLMs）的可靠性时所带来的推理成本增加和RAG hallucination问题，提出了一种动态参数化RAG（DyPRAG）框架。DyPRAG利用一个轻量级参数翻译器模型来高效地将文档转换为参数知识，从而在测试时动态增强LLMs的知识，并以即插即用方式解决知识冲突，同时显著降低推理、训练和存储成本。与Parametric RAG (PRAG)相比，DyPRAG在多个数据集上的广泛实验证明了其更高的有效性和泛化能力，提供了一种强大的RAG范式，用于更好地融合知识并减少实际应用中的幻觉问题。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "preprint. Code is available at https://github.com/Trae1ounG/DyPRAG",
      "pdf_url": "http://arxiv.org/pdf/2503.23895v4",
      "published_date": "2025-03-31 09:46:35 UTC",
      "updated_date": "2025-05-06 03:04:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:05:34.147142"
    },
    {
      "arxiv_id": "2503.23893v1",
      "title": "DiffScale: Continuous Downscaling and Bias Correction of Subseasonal Wind Speed Forecasts using Diffusion Models",
      "title_zh": "DiffScale：利用扩散模型对亚季节风速预报进行连续降尺度及偏差校正",
      "authors": [
        "Maximilian Springenberg",
        "Noelia Otero",
        "Yuxin Xue",
        "Jackie Ma"
      ],
      "abstract": "Renewable resources are strongly dependent on local and large-scale weather\nsituations. Skillful subseasonal to seasonal (S2S) forecasts -- beyond two\nweeks and up to two months -- can offer significant socioeconomic advantages to\nthe energy sector. This study aims to enhance wind speed predictions using a\ndiffusion model with classifier-free guidance to downscale S2S forecasts of\nsurface wind speed. We propose DiffScale, a diffusion model that super-resolves\nspatial information for continuous downscaling factors and lead times.\nLeveraging weather priors as guidance for the generative process of diffusion\nmodels, we adopt the perspective of conditional probabilities on sampling\nsuper-resolved S2S forecasts. We aim to directly estimate the density\nassociated with the target S2S forecasts at different spatial resolutions and\nlead times without auto-regression or sequence prediction, resulting in an\nefficient and flexible model. Synthetic experiments were designed to\nsuper-resolve wind speed S2S forecasts from the European Center for\nMedium-Range Weather Forecast (ECMWF) from a coarse resolution to a finer\nresolution of ERA5 reanalysis data, which serves as a high-resolution target.\nThe innovative aspect of DiffScale lies in its flexibility to downscale\narbitrary scaling factors, enabling it to generalize across various grid\nresolutions and lead times -without retraining the model- while correcting\nmodel errors, making it a versatile tool for improving S2S wind speed\nforecasts. We achieve a significant improvement in prediction quality,\noutperforming baselines up to week 3.",
      "tldr_zh": "本研究提出DiffScale，一种基于diffusion models的模型，用于连续下采样和偏差修正，以提升亚季节到季节(S2S)风速预测的准确性。DiffScale通过classifier-free guidance和天气先验作为条件概率指导，直接估计不同空间分辨率和提前时间的密度分布，避免了自回归或序列预测，从而实现高效灵活的预测。创新点在于，该模型能处理任意缩放因子而不需重新训练，同时修正模型错误。实验结果显示，DiffScale在将ECMWF粗分辨率数据超分辨到ERA5高分辨率时，预测质量显著提升，比基线模型在第三周表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "eess.IV"
      ],
      "primary_category": "cs.LG",
      "comment": "28 pages, 18 figures, preprint under review",
      "pdf_url": "http://arxiv.org/pdf/2503.23893v1",
      "published_date": "2025-03-31 09:44:28 UTC",
      "updated_date": "2025-03-31 09:44:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:05:45.360865"
    },
    {
      "arxiv_id": "2503.23888v1",
      "title": "MuseFace: Text-driven Face Editing via Diffusion-based Mask Generation Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Xin Zhang",
        "Siting Huang",
        "Xiangyang Luo",
        "Yifan Xie",
        "Weijiang Yu",
        "Heng Chang",
        "Fei Ma",
        "Fei Yu"
      ],
      "abstract": "Face editing modifies the appearance of face, which plays a key role in\ncustomization and enhancement of personal images. Although much work have\nachieved remarkable success in text-driven face editing, they still face\nsignificant challenges as none of them simultaneously fulfill the\ncharacteristics of diversity, controllability and flexibility. To address this\nchallenge, we propose MuseFace, a text-driven face editing framework, which\nrelies solely on text prompt to enable face editing. Specifically, MuseFace\nintegrates a Text-to-Mask diffusion model and a semantic-aware face editing\nmodel, capable of directly generating fine-grained semantic masks from text and\nperforming face editing. The Text-to-Mask diffusion model provides\n\\textit{diversity} and \\textit{flexibility} to the framework, while the\nsemantic-aware face editing model ensures \\textit{controllability} of the\nframework. Our framework can create fine-grained semantic masks, making precise\nface editing possible, and significantly enhancing the controllability and\nflexibility of face editing models. Extensive experiments demonstrate that\nMuseFace achieves superior high-fidelity performance.",
      "tldr_zh": "本文提出 MuseFace 框架，一种基于文本驱动的人脸编辑方法，通过 Diffusion-based Mask Generation 技术解决现有模型在多样性（diversity）、可控性（controllability）和灵活性（flexibility）方面的不足。框架整合 Text-to-Mask diffusion model 来直接从文本生成精细语义掩码，以及 semantic-aware face editing model 来实现精确编辑，确保编辑过程的高度可控和灵活。实验结果显示，MuseFace 在高保真度性能上表现出色，显著提升了人脸编辑的整体效果。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "6 pages, 5 figures,IEEE International Conference on Multimedia & Expo\n  2025",
      "pdf_url": "http://arxiv.org/pdf/2503.23888v1",
      "published_date": "2025-03-31 09:41:09 UTC",
      "updated_date": "2025-03-31 09:41:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:05:57.314033"
    },
    {
      "arxiv_id": "2503.23886v1",
      "title": "SchemaAgent: A Multi-Agents Framework for Generating Relational Database Schema",
      "title_zh": "SchemaAgent: 一个多智能体框架，用于生成关系数据库模式",
      "authors": [
        "Qin Wang",
        "Youhuan Li",
        "Yansong Feng",
        "Si Chen",
        "Ziming Li",
        "Pan Zhang",
        "Zhichao Shi",
        "Yuequn Dou",
        "chuchu Gao",
        "Zebin Huang",
        "Zihui Si",
        "Yixuan Chen",
        "Zhaohai Sun",
        "Ke Tang",
        "Wenqiang Jin"
      ],
      "abstract": "The relational database design would output a schema based on user's\nrequirements, which defines table structures and their interrelated relations.\nTranslating requirements into accurate schema involves several non-trivial\nsubtasks demanding both database expertise and domain-specific knowledge. This\nposes unique challenges for automated design of relational databases. Existing\nefforts are mostly based on customized rules or conventional deep learning\nmodels, often producing suboptimal schema. Recently, large language models\n(LLMs) have significantly advanced intelligent application development across\nvarious domains. In this paper, we propose SchemaAgent, a unified LLM-based\nmulti-agent framework for the automated generation of high-quality database\nschema. SchemaAgent is the first to apply LLMs for schema generation, which\nemulates the workflow of manual schema design by assigning specialized roles to\nagents and enabling effective collaboration to refine their respective\nsubtasks. Schema generation is a streamlined workflow, where directly applying\nthe multi-agent framework may cause compounding impact of errors. To address\nthis, we incorporate dedicated roles for reflection and inspection, alongside\nan innovative error detection and correction mechanism to identify and rectify\nissues across various phases. For evaluation, we present a benchmark named\n\\textit{RSchema}, which contains more than 500 pairs of requirement description\nand schema. Experimental results on this benchmark demonstrate the superiority\nof our approach over mainstream LLMs for relational database schema generation.",
      "tldr_zh": "该研究提出SchemaAgent，一种基于大语言模型(LLMs)的多智能体框架，用于自动生成高质量的关系数据库模式(schema)，以应对将用户需求转化为准确schema的挑战，如子任务复杂性和知识需求。框架模拟手动设计流程，通过为代理分配专门角色（如反思和检查）并引入错误检测与修正机制，实现代理间的协作和迭代优化。实验在RSchema基准数据集（包含500多个需求-模式对）上显示，SchemaAgent优于主流LLMs，在schema生成任务中表现出显著优势。",
      "categories": [
        "cs.DB",
        "cs.AI"
      ],
      "primary_category": "cs.DB",
      "comment": "19 pages, 16 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.23886v1",
      "published_date": "2025-03-31 09:39:19 UTC",
      "updated_date": "2025-03-31 09:39:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:06:08.907212"
    },
    {
      "arxiv_id": "2503.23875v1",
      "title": "GenSwarm: Scalable Multi-Robot Code-Policy Generation and Deployment via Language Models",
      "title_zh": "GenSwarm：基于语言模型的可扩展多机器人代码策略生成与部署",
      "authors": [
        "Wenkang Ji",
        "Huaben Chen",
        "Mingyang Chen",
        "Guobin Zhu",
        "Lufeng Xu",
        "Roderich Groß",
        "Rui Zhou",
        "Ming Cao",
        "Shiyu Zhao"
      ],
      "abstract": "The development of control policies for multi-robot systems traditionally\nfollows a complex and labor-intensive process, often lacking the flexibility to\nadapt to dynamic tasks. This has motivated research on methods to automatically\ncreate control policies. However, these methods require iterative processes of\nmanually crafting and refining objective functions, thereby prolonging the\ndevelopment cycle. This work introduces \\textit{GenSwarm}, an end-to-end system\nthat leverages large language models to automatically generate and deploy\ncontrol policies for multi-robot tasks based on simple user instructions in\nnatural language. As a multi-language-agent system, GenSwarm achieves zero-shot\nlearning, enabling rapid adaptation to altered or unseen tasks. The white-box\nnature of the code policies ensures strong reproducibility and\ninterpretability. With its scalable software and hardware architectures,\nGenSwarm supports efficient policy deployment on both simulated and real-world\nmulti-robot systems, realizing an instruction-to-execution end-to-end\nfunctionality that could prove valuable for robotics specialists and\nnon-specialists alike.The code of the proposed GenSwarm system is available\nonline: https://github.com/WindyLab/GenSwarm.",
      "tldr_zh": "本研究提出 GenSwarm，一种可扩展的多机器人系统，利用 large language models 自动生成和部署控制策略，仅需简单自然语言指令即可实现端到端任务执行。该系统采用多语言代理框架，支持 zero-shot learning，快速适应动态或未见任务，并通过白盒代码策略确保策略的可解释性和可重现性。在软件和硬件架构上，GenSwarm 实现了高效部署，适用于模拟和真实世界多机器人场景，为机器人专家和非专家提供便捷工具。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.23875v1",
      "published_date": "2025-03-31 09:26:34 UTC",
      "updated_date": "2025-03-31 09:26:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:06:21.532831"
    },
    {
      "arxiv_id": "2503.23862v2",
      "title": "Learned Image Compression and Restoration for Digital Pathology",
      "title_zh": "翻译失败",
      "authors": [
        "SeonYeong Lee",
        "EonSeung Seong",
        "DongEon Lee",
        "SiYeoul Lee",
        "Yubin Cho",
        "Chunsu Park",
        "Seonho Kim",
        "MinKyung Seo",
        "YoungSin Ko",
        "MinWoo Kim"
      ],
      "abstract": "Digital pathology images play a crucial role in medical diagnostics, but\ntheir ultra-high resolution and large file sizes pose significant challenges\nfor storage, transmission, and real-time visualization. To address these\nissues, we propose CLERIC, a novel deep learning-based image compression\nframework designed specifically for whole slide images (WSIs). CLERIC\nintegrates a learnable lifting scheme and advanced convolutional techniques to\nenhance compression efficiency while preserving critical pathological details.\nOur framework employs a lifting-scheme transform in the analysis stage to\ndecompose images into low- and high-frequency components, enabling more\nstructured latent representations. These components are processed through\nparallel encoders incorporating Deformable Residual Blocks (DRB) and Recurrent\nResidual Blocks (R2B) to improve feature extraction and spatial adaptability.\nThe synthesis stage applies an inverse lifting transform for effective image\nreconstruction, ensuring high-fidelity restoration of fine-grained tissue\nstructures. We evaluate CLERIC on a digital pathology image dataset and compare\nits performance against state-of-the-art learned image compression (LIC)\nmodels. Experimental results demonstrate that CLERIC achieves superior\nrate-distortion (RD) performance, significantly reducing storage requirements\nwhile maintaining high diagnostic image quality. Our study highlights the\npotential of deep learning-based compression in digital pathology, facilitating\nefficient data management and long-term storage while ensuring seamless\nintegration into clinical workflows and AI-assisted diagnostic systems. Code\nand models are available at: https://github.com/pnu-amilab/CLERIC.",
      "tldr_zh": "本文提出CLERIC，一种针对数字病理图像的深度学习图像压缩框架，旨在解决其超高分辨率导致的存储、传输和实时可视化难题。CLERIC采用可学习的lifting scheme将图像分解为低频和高频成分，并通过并行编码器（包括Deformable Residual Blocks (DRB)和Recurrent Residual Blocks (R2B)）进行特征提取和处理，随后使用逆lifting scheme重建图像，以确保病理细节的高保真度。实验在数字病理图像数据集上表明，CLERIC在率-distortion (RD)性能上优于现有模型，显著降低存储需求的同时维持高诊断质量，从而提升临床工作流和AI辅助诊断的效率。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.23862v2",
      "published_date": "2025-03-31 09:09:09 UTC",
      "updated_date": "2025-04-01 03:06:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:06:34.811293"
    },
    {
      "arxiv_id": "2503.23830v2",
      "title": "Orchestrate Multimodal Data with Batch Post-Balancing to Accelerate Multimodal Large Language Model Training",
      "title_zh": "翻译失败",
      "authors": [
        "Yijie Zheng",
        "Bangjun Xiao",
        "Lei Shi",
        "Xiaoyang Li",
        "Faming Wu",
        "Tianyu Li",
        "Xuefeng Xiao",
        "Yang Zhang",
        "Yuxuan Wang",
        "Shouda Liu"
      ],
      "abstract": "Multimodal large language models (MLLMs), such as GPT-4o, are garnering\nsignificant attention. During the exploration of MLLM training, we identified\nModality Composition Incoherence, a phenomenon that the proportion of a certain\nmodality varies dramatically across different examples. It exacerbates the\nchallenges of addressing mini-batch imbalances, which lead to uneven GPU\nutilization between Data Parallel (DP) instances and severely degrades the\nefficiency and scalability of MLLM training, ultimately affecting training\nspeed and hindering further research on MLLMs.\n  To address these challenges, we introduce OrchMLLM, a comprehensive framework\ndesigned to mitigate the inefficiencies in MLLM training caused by Modality\nComposition Incoherence. First, we propose Batch Post-Balancing Dispatcher, a\ntechnique that efficiently eliminates mini-batch imbalances in sequential data.\nAdditionally, we integrate MLLM Global Orchestrator into the training framework\nto orchestrate multimodal data and tackle the issues arising from Modality\nComposition Incoherence. We evaluate OrchMLLM across various MLLM sizes,\ndemonstrating its efficiency and scalability. Experimental results reveal that\nOrchMLLM achieves a Model FLOPs Utilization (MFU) of $41.6\\%$ when training an\n84B MLLM with three modalities on $2560$ H100 GPUs, outperforming Megatron-LM\nby up to $3.1\\times$ in throughput.",
      "tldr_zh": "该研究识别了Multimodal Large Language Models (MLLMs)训练中的Modality Composition Incoherence问题，即不同示例中模态比例的剧烈变化，导致mini-batch不平衡并影响GPU利用率和训练效率。为此，提出OrchMLLM框架，包括Batch Post-Balancing Dispatcher用于消除序列数据中的不平衡，以及MLLM Global Orchestrator用于协调多模态数据。实验结果显示，OrchMLLM在训练84B MLLM时实现了41.6%的Model FLOPs Utilization (MFU)，吞吐量比Megatron-LM高出3.1倍，显著提升了训练的效率和可扩展性。",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.23830v2",
      "published_date": "2025-03-31 08:24:23 UTC",
      "updated_date": "2025-04-09 06:39:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:06:46.594633"
    },
    {
      "arxiv_id": "2503.23820v3",
      "title": "When Counterfactual Reasoning Fails: Chaos and Real-World Complexity",
      "title_zh": "翻译失败",
      "authors": [
        "Yahya Aalaila",
        "Gerrit Großmann",
        "Sumantrak Mukherjee",
        "Jonas Wahl",
        "Sebastian Vollmer"
      ],
      "abstract": "Counterfactual reasoning, a cornerstone of human cognition and\ndecision-making, is often seen as the 'holy grail' of causal learning, with\napplications ranging from interpreting machine learning models to promoting\nalgorithmic fairness. While counterfactual reasoning has been extensively\nstudied in contexts where the underlying causal model is well-defined,\nreal-world causal modeling is often hindered by model and parameter\nuncertainty, observational noise, and chaotic behavior. The reliability of\ncounterfactual analysis in such settings remains largely unexplored. In this\nwork, we investigate the limitations of counterfactual reasoning within the\nframework of Structural Causal Models. Specifically, we empirically investigate\n\\emph{counterfactual sequence estimation} and highlight cases where it becomes\nincreasingly unreliable. We find that realistic assumptions, such as low\ndegrees of model uncertainty or chaotic dynamics, can result in\ncounterintuitive outcomes, including dramatic deviations between predicted and\ntrue counterfactual trajectories. This work urges caution when applying\ncounterfactual reasoning in settings characterized by chaos and uncertainty.\nFurthermore, it raises the question of whether certain systems may pose\nfundamental limitations on the ability to answer counterfactual questions about\ntheir behavior.",
      "tldr_zh": "本研究探讨了反事实推理（counterfactual reasoning）在真实世界复杂环境中的局限性，特别是面对模型不确定性、观测噪声和混沌行为（chaotic dynamics）时可能失效的问题。作者在结构因果模型（Structural Causal Models）的框架下，通过实证调查反事实序列估计（counterfactual sequence estimation），发现低度模型不确定性和混沌动态会导致预测与真实反事实轨迹之间出现显著偏差。研究结果强调，在混沌和不确定环境中应用反事实推理需谨慎，并质疑某些系统是否根本无法回答反事实问题，从而为因果学习和决策提供重要警示。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.23820v3",
      "published_date": "2025-03-31 08:14:51 UTC",
      "updated_date": "2025-04-10 14:30:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:06:57.292984"
    },
    {
      "arxiv_id": "2503.23819v1",
      "title": "Conformal uncertainty quantification to evaluate predictive fairness of foundation AI model for skin lesion classes across patient demographics",
      "title_zh": "翻译失败",
      "authors": [
        "Swarnava Bhattacharyya",
        "Umapada Pal",
        "Tapabrata Chakraborti"
      ],
      "abstract": "Deep learning based diagnostic AI systems based on medical images are\nstarting to provide similar performance as human experts. However these data\nhungry complex systems are inherently black boxes and therefore slow to be\nadopted for high risk applications like healthcare. This problem of lack of\ntransparency is exacerbated in the case of recent large foundation models,\nwhich are trained in a self supervised manner on millions of data points to\nprovide robust generalisation across a range of downstream tasks, but the\nembeddings generated from them happen through a process that is not\ninterpretable, and hence not easily trustable for clinical applications. To\naddress this timely issue, we deploy conformal analysis to quantify the\npredictive uncertainty of a vision transformer (ViT) based foundation model\nacross patient demographics with respect to sex, age and ethnicity for the\ntasks of skin lesion classification using several public benchmark datasets.\nThe significant advantage of this method is that conformal analysis is method\nindependent and it not only provides a coverage guarantee at population level\nbut also provides an uncertainty score for each individual. We used a\nmodel-agnostic dynamic F1-score-based sampling during model training, which\nhelped to stabilize the class imbalance and we investigate the effects on\nuncertainty quantification (UQ) with or without this bias mitigation step. Thus\nwe show how this can be used as a fairness metric to evaluate the robustness of\nthe feature embeddings of the foundation model (Google DermFoundation) and thus\nadvance the trustworthiness and fairness of clinical AI.",
      "tldr_zh": "本研究利用 conformal analysis 评估一个基于 Vision Transformer (ViT) 的 foundation AI 模型在皮肤病变分类任务中的预测不确定性，针对患者人口统计学如性别、年龄和种族的差异，以解决模型不透明性和公平性问题。研究采用模型无关的动态 F1-score-based sampling 处理类别不平衡，并分析其对 uncertainty quantification (UQ) 的影响，提供总体覆盖保证和个体不确定性分数。结果表明，这种方法能作为公平性指标，提升 foundation model（如 Google DermFoundation）的特征嵌入稳健性，从而增强临床 AI 的可信度和公平性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.23819v1",
      "published_date": "2025-03-31 08:06:00 UTC",
      "updated_date": "2025-03-31 08:06:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:07:10.827124"
    },
    {
      "arxiv_id": "2504.01986v1",
      "title": "TuRTLe: A Unified Evaluation of LLMs for RTL Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Dario Garcia-Gasulla",
        "Gokcen Kestor",
        "Emanuele Parisi",
        "Miquel Albert'i-Binimelis",
        "Cristian Gutierrez",
        "Razine Moundir Ghorab",
        "Orlando Montenegro",
        "Bernat Homs",
        "Miquel Moreto"
      ],
      "abstract": "The rapid advancements in LLMs have driven the adoption of generative AI in\nvarious domains, including Electronic Design Automation (EDA). Unlike\ntraditional software development, EDA presents unique challenges, as generated\nRTL code must not only be syntactically correct and functionally accurate but\nalso synthesizable by hardware generators while meeting performance, power, and\narea constraints. These additional requirements introduce complexities that\nexisting code-generation benchmarks often fail to capture, limiting their\neffectiveness in evaluating LLMs for RTL generation. To address this gap, we\npropose TuRTLe, a unified evaluation framework designed to systematically\nassess LLMs across key RTL generation tasks. TuRTLe integrates multiple\nexisting benchmarks and automates the evaluation process, enabling a\ncomprehensive assessment of LLM performance in syntax correctness, functional\ncorrectness, synthesis, PPA optimization, and exact line completion. Using this\nframework, we benchmark a diverse set of open LLMs and analyze their strengths\nand weaknesses in EDA-specific tasks. Our results show that reasoning-based\nmodels, such as DeepSeek R1, consistently outperform others across multiple\nevaluation criteria, but at the cost of increased computational overhead and\ninference latency. Additionally, base models are better suited in module\ncompletion tasks, while instruct-tuned models perform better in\nspecification-to-RTL tasks.",
      "tldr_zh": "这篇论文提出了 TuRTLe，一种统一的评估框架，用于系统评估 LLMs 在 RTL 生成任务中的性能，针对电子设计自动化 (EDA) 领域的独特挑战，如语法正确性、功能正确性、合成和 PPA 优化。TuRTLe 通过整合多个现有基准并自动化评估过程，填补了传统代码生成基准的不足。实验结果显示，推理-based 模型如 DeepSeek R1 在多个评估标准上表现出色，但伴随更高的计算开销和推理延迟；此外，基础模型在模块完成任务中更具优势，而 instruct-tuned 模型在 specification-to-RTL 任务中表现更好。",
      "categories": [
        "cs.AR",
        "cs.AI",
        "I.2.5; J.6"
      ],
      "primary_category": "cs.AR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.01986v1",
      "published_date": "2025-03-31 07:43:12 UTC",
      "updated_date": "2025-03-31 07:43:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:07:22.275102"
    },
    {
      "arxiv_id": "2503.23803v2",
      "title": "Thinking Longer, Not Larger: Enhancing Software Engineering Agents via Scaling Test-Time Compute",
      "title_zh": "翻译失败",
      "authors": [
        "Yingwei Ma",
        "Yongbin Li",
        "Yihong Dong",
        "Xue Jiang",
        "Rongyu Cao",
        "Jue Chen",
        "Fei Huang",
        "Binhua Li"
      ],
      "abstract": "Recent advancements in software engineering agents have demonstrated\npromising capabilities in automating program improvements. However, their\nreliance on closed-source or resource-intensive models introduces significant\ndeployment challenges in private environments, prompting a critical question:\n\\textit{How can personally deployable open-source LLMs achieve comparable code\nreasoning performance?}\n  To this end, we propose a unified Test-Time Compute scaling framework that\nleverages increased inference-time computation instead of larger models. Our\nframework incorporates two complementary strategies: internal TTC and external\nTTC. Internally, we introduce a \\textit{development-contextualized trajectory\nsynthesis} method leveraging real-world software repositories to bootstrap\nmulti-stage reasoning processes, such as fault localization and patch\ngeneration. We further enhance trajectory quality through rejection sampling,\nrigorously evaluating trajectories along accuracy and complexity. Externally,\nwe propose a novel \\textit{development-process-based search} strategy guided by\nreward models and execution verification. This approach enables targeted\ncomputational allocation at critical development decision points, overcoming\nlimitations of existing \"end-point only\" verification methods.\n  Evaluations on SWE-bench Verified demonstrate our \\textbf{32B model achieves\na 46\\% issue resolution rate}, surpassing significantly larger models such as\nDeepSeek R1 671B and OpenAI o1. Additionally, we provide the empirical\nvalidation of the test-time scaling phenomenon within SWE agents, revealing\nthat \\textbf{models dynamically allocate more tokens to increasingly\nchallenging problems}, effectively enhancing reasoning capabilities. We\npublicly release all training data, models, and code to facilitate future\nresearch. https://github.com/yingweima2022/SWE-Reasoner",
      "tldr_zh": "本文提出一种统一的 Test-Time Compute (TTC) 缩放框架，以提升开源 LLM 在软件工程代理中的代码推理性能，而非依赖更大模型。该框架包括内部 TTC 的 development-contextualized trajectory synthesis 方法，利用真实软件仓库引导多阶段推理（如故障定位和补丁生成），并通过 rejection sampling 优化轨迹质量；以及外部 TTC 的 development-process-based search 策略，由奖励模型和执行验证指导关键决策点。实验在 SWE-bench Verified 上显示，32B 模型实现 46% 的问题解决率，超过了更大模型如 DeepSeek R1 671B 和 OpenAI o1。该研究还验证了测试时缩放现象，即模型在更具挑战的问题上动态分配更多 tokens，并公开了所有训练数据、模型和代码以促进后续研究。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.23803v2",
      "published_date": "2025-03-31 07:31:32 UTC",
      "updated_date": "2025-04-08 12:36:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:07:34.883147"
    },
    {
      "arxiv_id": "2503.23798v2",
      "title": "Adaptive Layer-skipping in Pre-trained LLMs",
      "title_zh": "预训练 LLMs 中的自适应层跳过",
      "authors": [
        "Xuan Luo",
        "Weizhi Wang",
        "Xifeng Yan"
      ],
      "abstract": "Various layer-skipping methods have been proposed to accelerate token\ngeneration in large language models (LLMs). However, they have overlooked a\nfundamental question: How do computational demands vary across the generation\nof different tokens? In this work, we introduce FlexiDepth, a method that\ndynamically adjusts the number of Transformer layers used in text generation.\nBy incorporating a plug-in router and adapter, FlexiDepth enables adaptive\nlayer-skipping in LLMs without modifying their original parameters. Introducing\nFlexiDepth to Llama-3-8B model achieves layer skipping of 8 layers out of 32,\nand meanwhile maintains the full 100\\% benchmark performance. Experimental\nresults with FlexiDepth demonstrate that computational demands in LLMs\nsignificantly vary based on token type. Specifically, generating repetitive\ntokens or fixed phrases requires fewer layers, whereas producing tokens\ninvolving computation or high uncertainty requires more layers. Interestingly,\nthis adaptive allocation pattern aligns with human intuition. To advance\nresearch in this area, we open sourced FlexiDepth and a dataset documenting\nFlexiDepth's layer allocation patterns for future exploration.",
      "tldr_zh": "本文提出 FlexiDepth 方法，通过动态调整 Transformer 层数，实现预训练 LLMs 中的自适应层跳过，从而加速文本生成，而无需修改原模型参数。FlexiDepth 采用插件路由器和适配器，在 Llama-3-8B 模型上成功跳过 8 层中的 32 层，同时保持 100% 基准性能。实验结果显示，不同 token 类型（如重复 token 或计算密集 token）对计算需求差异显著，与人类直觉一致，并开源了 FlexiDepth 及其层分配数据集以推动进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.23798v2",
      "published_date": "2025-03-31 07:20:58 UTC",
      "updated_date": "2025-04-17 22:26:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:07:46.109209"
    },
    {
      "arxiv_id": "2503.23786v1",
      "title": "MGD-SAM2: Multi-view Guided Detail-enhanced Segment Anything Model 2 for High-Resolution Class-agnostic Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Haoran Shen",
        "Peixian Zhuang",
        "Jiahao Kou",
        "Yuxin Zeng",
        "Haoying Xu",
        "Jiangyun Li"
      ],
      "abstract": "Segment Anything Models (SAMs), as vision foundation models, have\ndemonstrated remarkable performance across various image analysis tasks.\nDespite their strong generalization capabilities, SAMs encounter challenges in\nfine-grained detail segmentation for high-resolution class-independent\nsegmentation (HRCS), due to the limitations in the direct processing of\nhigh-resolution inputs and low-resolution mask predictions, and the reliance on\naccurate manual prompts. To address these limitations, we propose MGD-SAM2\nwhich integrates SAM2 with multi-view feature interaction between a global\nimage and local patches to achieve precise segmentation. MGD-SAM2 incorporates\nthe pre-trained SAM2 with four novel modules: the Multi-view Perception Adapter\n(MPAdapter), the Multi-view Complementary Enhancement Module (MCEM), the\nHierarchical Multi-view Interaction Module (HMIM), and the Detail Refinement\nModule (DRM). Specifically, we first introduce MPAdapter to adapt the SAM2\nencoder for enhanced extraction of local details and global semantics in HRCS\nimages. Then, MCEM and HMIM are proposed to further exploit local texture and\nglobal context by aggregating multi-view features within and across\nmulti-scales. Finally, DRM is designed to generate gradually restored\nhigh-resolution mask predictions, compensating for the loss of fine-grained\ndetails resulting from directly upsampling the low-resolution prediction maps.\nExperimental results demonstrate the superior performance and strong\ngeneralization of our model on multiple high-resolution and normal-resolution\ndatasets. Code will be available at https://github.com/sevenshr/MGD-SAM2.",
      "tldr_zh": "该研究针对Segment Anything Models (SAMs) 在高分辨率类无关分割 (HRCS) 中的局限性（如处理高分辨率输入困难和低分辨率掩码预测），提出了MGD-SAM2框架，将SAM2与多视图特征交互相结合，以实现精确的分割任务。MGD-SAM2引入了四个新模块：Multi-view Perception Adapter (MPAdapter) 用于增强局部细节和全局语义提取，Multi-view Complementary Enhancement Module (MCEM) 与Hierarchical Multi-view Interaction Module (HMIM) 通过多尺度特征聚合提升纹理和上下文，Detail Refinement Module (DRM) 则逐步恢复高分辨率掩码以补偿细节损失。实验结果显示，该模型在多个高分辨率和正常分辨率数据集上表现出优越性能和强泛化能力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.23786v1",
      "published_date": "2025-03-31 07:02:32 UTC",
      "updated_date": "2025-03-31 07:02:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:07:57.869293"
    },
    {
      "arxiv_id": "2503.23781v1",
      "title": "DebFlow: Automating Agent Creation via Agent Debate",
      "title_zh": "翻译失败",
      "authors": [
        "Jinwei Su",
        "Yinghui Xia",
        "Ronghua Shi",
        "Jianhui Wang",
        "Jianuo Huang",
        "Yijin Wang",
        "Tianyu Shi",
        "Yang Jingsong",
        "Lewei He"
      ],
      "abstract": "Large language models (LLMs) have demonstrated strong potential and\nimpressive performance in automating the generation and optimization of\nworkflows. However, existing approaches are marked by limited reasoning\ncapabilities, high computational demands, and significant resource\nrequirements. To address these issues, we propose DebFlow, a framework that\nemploys a debate mechanism to optimize workflows and integrates reflexion to\nimprove based on previous experiences. We evaluated our method across six\nbenchmark datasets, including HotpotQA, MATH, and ALFWorld. Our approach\nachieved a 3\\% average performance improvement over the latest baselines,\ndemonstrating its effectiveness in diverse problem domains. In particular,\nduring training, our framework reduces resource consumption by 37\\% compared to\nthe state-of-the-art baselines. Additionally, we performed ablation studies.\nRemoving the Debate component resulted in a 4\\% performance drop across two\nbenchmark datasets, significantly greater than the 2\\% drop observed when the\nReflection component was removed. These findings strongly demonstrate the\ncritical role of Debate in enhancing framework performance, while also\nhighlighting the auxiliary contribution of reflexion to overall optimization.",
      "tldr_zh": "本论文提出DebFlow框架，通过代理辩论(debate mechanism)自动生成和优化工作流，并整合reflexion机制来基于以往经验进行改进，以解决LLMs在工作流处理中的推理能力有限、高计算需求和资源消耗问题。在HotpotQA、MATH和ALFWorld等六种基准数据集上，DebFlow比最新基线平均提高了3%的性能，并在训练中减少了37%的资源消耗。消融研究显示，移除Debate组件导致性能下降4%，而移除Reflection组件仅下降2%，突出了Debate机制在提升框架性能中的关键作用。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.23781v1",
      "published_date": "2025-03-31 06:56:13 UTC",
      "updated_date": "2025-03-31 06:56:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:08:09.986019"
    },
    {
      "arxiv_id": "2503.23779v1",
      "title": "WinoWhat: A Parallel Corpus of Paraphrased WinoGrande Sentences with Common Sense Categorization",
      "title_zh": "翻译失败",
      "authors": [
        "Ine Gevers",
        "Victor De Marez",
        "Luna De Bruyne",
        "Walter Daelemans"
      ],
      "abstract": "In this study, we take a closer look at how Winograd schema challenges can be\nused to evaluate common sense reasoning in LLMs. Specifically, we evaluate\ngenerative models of different sizes on the popular WinoGrande benchmark. We\nrelease WinoWhat, a new corpus, in which each instance of the WinoGrande\nvalidation set is paraphrased. Additionally, we evaluate the performance on the\nchallenge across five common sense knowledge categories, giving more\nfine-grained insights on what types of knowledge are more challenging for LLMs.\nSurprisingly, all models perform significantly worse on WinoWhat, implying that\nLLM reasoning capabilities are overestimated on WinoGrande. To verify whether\nthis is an effect of benchmark memorization, we match benchmark instances to\nLLM trainingdata and create two test-suites. We observe that memorization has a\nminimal effect on model performance on WinoGrande.",
      "tldr_zh": "本研究评估了大型语言模型(LLMs)在Winograd schema挑战中的常识推理能力，发布了WinoWhat语料库，该语料库是对WinoGrande验证集的改写版本，并添加了五个常识知识类别的分类，以提供更细粒度的性能洞见。研究发现，所有模型在WinoWhat上的表现显著下降，表明LLMs在WinoGrande上的推理能力可能被高估。通过创建测试套件并匹配基准实例与LLM训练数据，实验证实这种下降并非主要源于基准记忆化。总的来说，这为更准确评估LLMs的常识推理提供了新工具和见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.23779v1",
      "published_date": "2025-03-31 06:53:53 UTC",
      "updated_date": "2025-03-31 06:53:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:08:22.375075"
    },
    {
      "arxiv_id": "2504.01039v1",
      "title": "One Person, One Bot",
      "title_zh": "翻译失败",
      "authors": [
        "Liat Lavi"
      ],
      "abstract": "This short paper puts forward a vision for a new democratic model enabled by\nthe recent technological advances in agentic AI. It therefore opens with\ndrawing a clear and concise picture of the model, and only later addresses\nrelated proposals and research directions, and concerns regarding feasibility\nand safety. It ends with a note on the timeliness of this idea and on optimism.\nThe model proposed is that of assigning each citizen an AI Agent that would\nserve as their political delegate, enabling the return to direct democracy. The\npaper examines this models relation to existing research, its potential\nsetbacks and feasibility and argues for its further development.",
      "tldr_zh": "这篇论文提出了一种新民主模型，即为每个公民分配一个 AI Agent 作为他们的政治代表，从而实现直接 democracy 的回归。论文首先清晰描绘了这一模型，然后讨论了其与现有研究的关联、潜在挑战（如可行性和安全问题），并主张进一步发展。该模型利用代理 AI 的技术进步，强调其及时性和乐观前景，以应对现代民主的痛点。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "12 pages",
      "pdf_url": "http://arxiv.org/pdf/2504.01039v1",
      "published_date": "2025-03-31 06:49:47 UTC",
      "updated_date": "2025-03-31 06:49:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:08:33.502641"
    },
    {
      "arxiv_id": "2503.23764v2",
      "title": "WaveFormer: A 3D Transformer with Wavelet-Driven Feature Representation for Efficient Medical Image Segmentation",
      "title_zh": "WaveFormer: 一种基于小波驱动特征表示的三维 Transformer",
      "authors": [
        "Md Mahfuz Al Hasan",
        "Mahdi Zaman",
        "Abdul Jawad",
        "Alberto Santamaria-Pang",
        "Ho Hin Lee",
        "Ivan Tarapov",
        "Kyle See",
        "Md Shah Imran",
        "Antika Roy",
        "Yaser Pourmohammadi Fallah",
        "Navid Asadizanjani",
        "Reza Forghani"
      ],
      "abstract": "Transformer-based architectures have advanced medical image analysis by\neffectively modeling long-range dependencies, yet they often struggle in 3D\nsettings due to substantial memory overhead and insufficient capture of\nfine-grained local features. We address these limitations with WaveFormer, a\nnovel 3D-transformer that: i) leverages the fundamental frequency-domain\nproperties of features for contextual representation, and ii) is inspired by\nthe top-down mechanism of the human visual recognition system, making it a\nbiologically motivated architecture. By employing discrete wavelet\ntransformations (DWT) at multiple scales, WaveFormer preserves both global\ncontext and high-frequency details while replacing heavy upsampling layers with\nefficient wavelet-based summarization and reconstruction. This significantly\nreduces the number of parameters, which is critical for real-world deployment\nwhere computational resources and training times are constrained. Furthermore,\nthe model is generic and easily adaptable to diverse applications. Evaluations\non BraTS2023, FLARE2021, and KiTS2023 demonstrate performance on par with\nstate-of-the-art methods while offering substantially lower computational\ncomplexity.",
      "tldr_zh": "该论文提出WaveFormer，一种新型3D Transformer架构，用于高效的医疗图像分割，通过利用离散小波变换(DWT)多尺度处理来捕捉特征的频域属性，并受人类视觉系统顶层机制启发。WaveFormer以DWT替换传统上采样层，实现全局上下文和高频细节的保留，同时显著减少参数数量和计算开销，使其适用于资源受限的实际部署。在BraTS2023、FLARE2021和KiTS2023数据集的评估中，WaveFormer的性能与最先进方法相当，但计算复杂度更低。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.23764v2",
      "published_date": "2025-03-31 06:28:41 UTC",
      "updated_date": "2025-04-01 02:13:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:08:45.558163"
    },
    {
      "arxiv_id": "2503.23740v1",
      "title": "LANID: LLM-assisted New Intent Discovery",
      "title_zh": "LANID：LLM辅助的新意图发现",
      "authors": [
        "Lu Fan",
        "Jiashu Pu",
        "Rongsheng Zhang",
        "Xiao-Ming Wu"
      ],
      "abstract": "Task-oriented Dialogue Systems (TODS) often face the challenge of\nencountering new intents. New Intent Discovery (NID) is a crucial task that\naims to identify these novel intents while maintaining the capability to\nrecognize existing ones. Previous efforts to adapt TODS to new intents have\nstruggled with inadequate semantic representation or have depended on external\nknowledge, which is often not scalable or flexible. Recently, Large Language\nModels (LLMs) have demonstrated strong zero-shot capabilities; however, their\nscale can be impractical for real-world applications that involve extensive\nqueries. To address the limitations of existing NID methods by leveraging LLMs,\nwe propose LANID, a framework that enhances the semantic representation of\nlightweight NID encoders with the guidance of LLMs. Specifically, LANID employs\nthe $K$-nearest neighbors and Density-Based Spatial Clustering of Applications\nwith Noise (DBSCAN) algorithms to sample selective utterance pairs from the\ntraining set. It then queries an LLM to ascertain the relationships between\nthese pairs. The data produced from this process is utilized to design a\ncontrastive fine-tuning task, which is then used to train a small encoder with\na contrastive triplet loss. Our experimental results demonstrate the efficacy\nof the proposed method across three distinct NID datasets, surpassing strong\nbaselines in both unsupervised and semi-supervised settings. Our code is\navailable at https://github.com/floatSDSDS/LANID.",
      "tldr_zh": "本研究提出LANID框架，利用大型语言模型(LLMs)辅助新意图发现(NID)，以解决任务导向对话系统(TODS)在识别新意图时存在的语义表示不足和依赖外部知识的问题。具体而言，LANID通过K-Nearest Neighbors和DBSCAN算法采样训练集中的话语对，并查询LLMs确定这些对之间的关系，从而生成数据用于对比学习任务，并以对比三元组损失训练轻量级编码器。实验结果显示，该框架在三个NID数据集上超越了强基线模型，在无监督和半监督设置中均表现出色，提供可扩展的解决方案。代码已在GitHub开源。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Published in LREC-COLING 2024",
      "pdf_url": "http://arxiv.org/pdf/2503.23740v1",
      "published_date": "2025-03-31 05:34:32 UTC",
      "updated_date": "2025-03-31 05:34:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:08:57.216525"
    },
    {
      "arxiv_id": "2503.23731v1",
      "title": "Investigation of intelligent barbell squat coaching system based on computer vision and machine learning",
      "title_zh": "翻译失败",
      "authors": [
        "Yinq-Rong Chern",
        "Yuhao Lee",
        "Hsiao-Ching Lin",
        "Guan-Ting Chen",
        "Ying-Hsien Chen",
        "Fu-Sung Lin",
        "Chih-Yao Chuang",
        "Jenn-Jier James Lien",
        "Chih-Hsien Huang"
      ],
      "abstract": "Purpose: Research has revealed that strength training can reduce the\nincidence of chronic diseases and physical deterioration at any age. Therefore,\nhaving a movement diagnostic system is crucial for training alone. Hence, this\nstudy developed an artificial intelligence and computer vision-based barbell\nsquat coaching system with a real-time mode that immediately diagnoses the\nissue and provides feedback after each squat. In addition, a replay mode allows\nusers to examine their previous squats and check their comments. Initially,\nfour primary characteristics of the barbell squat were identified: body joint\nangles, dorsiflexion, the ratio of knee-to-hip movement, and barbell stability.\nMethods: We collect 8,151 squats from 77 participants, categorizing them as\ngood squats and six issues. Then, we trained the diagnosis models with three\nmachine-learning architectures. Furthermore, this research applied the SHapley\nAdditive exPlanations (SHAP) method to enhance the accuracy of issue prediction\nand reduce the computation time by feature selection. Results: The F1 score of\nthe six issues reached 86.86%, 69.01%, 77.42%, 90.74%, 95.83%, and 100%. Each\nsquat diagnosis took less than 0.5 seconds. Finally, this study examined the\nefficacy of the proposed system with two groups of participants trained with\nand without the system. Subsequently, participants trained with the system\nexhibited substantial improvements in their squat technique, as assessed both\nby the system itself and by a professional weightlifting coach. Conclusion:\nThis is a comprehensive study that integrates artificial intelligence, computer\nvision and multivariable processing technologies, aimed at building a\nreal-time, user-friendly barbell squat feedback and training system.",
      "tldr_zh": "本研究开发了一个基于computer vision和machine learning的智能杠铃深蹲教练系统，旨在提供实时诊断和反馈，帮助用户纠正动作问题。研究团队收集了8,151个深蹲数据，识别了四个关键特征（包括身体关节角度、足背屈、膝盖与髋部运动比例和杠铃稳定性），并使用三种机器学习架构训练诊断模型，同时应用SHAP方法优化特征选择以提高准确性和效率。结果显示，六种常见问题的F1分数高达86.86%至100%，每个诊断耗时不到0.5秒，且使用系统的参与者在深蹲技术上取得了显著改善，经系统和专业教练评估。该系统整合了AI、computer vision和多变量处理技术，构建了一个实时、用户友好的训练工具。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.23731v1",
      "published_date": "2025-03-31 05:08:52 UTC",
      "updated_date": "2025-03-31 05:08:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:09:09.685325"
    },
    {
      "arxiv_id": "2503.23730v1",
      "title": "KOFFVQA: An Objectively Evaluated Free-form VQA Benchmark for Large Vision-Language Models in the Korean Language",
      "title_zh": "翻译失败",
      "authors": [
        "Yoonshik Kim",
        "Jaeyoon Jung"
      ],
      "abstract": "The recent emergence of Large Vision-Language Models(VLMs) has resulted in a\nvariety of different benchmarks for evaluating such models. Despite this, we\nobserve that most existing evaluation methods suffer from the fact that they\neither require the model to choose from pre-determined responses, sacrificing\nopen-endedness, or evaluate responses using a judge model, resulting in\nsubjective and unreliable evaluation. In addition, we observe a lack of\nbenchmarks for VLMs in the Korean language, which are necessary as a separate\nmetric from more common English language benchmarks, as the performance of\ngenerative language models can differ significantly based on the language being\nused. Therefore, we present KOFFVQA, a general-purpose free-form visual\nquestion answering benchmark in the Korean language for the evaluation of VLMs.\nOur benchmark consists of 275 carefully crafted questions each paired with an\nimage and grading criteria covering 10 different aspects of VLM performance.\nThe grading criteria eliminate the problem of unreliability by allowing the\njudge model to grade each response based on a pre-determined set of rules. By\ndefining the evaluation criteria in an objective manner, even a small\nopen-source model can be used to evaluate models on our benchmark reliably. In\naddition to evaluating a large number of existing VLMs on our benchmark, we\nalso experimentally verify that our method of using pre-existing grading\ncriteria for evaluation is much more reliable than existing methods. Our\nevaluation code is available at https://github.com/maum-ai/KOFFVQA",
      "tldr_zh": "该论文指出了现有视觉语言模型（VLM）基准的问题，包括响应选择受限或评估主观不可靠，并强调了韩语基准的缺失。研究团队提出KOFFVQA，这是一个通用的韩语自由形式视觉问答（VQA）基准，包含275个精心设计的图像配对问题和覆盖10个性能方面的客观评分标准。这些标准基于预定规则，使评估更可靠，甚至可用小型开源模型进行。此外，实验结果显示，该方法在评估多种VLM时比传统方法更准确，并提供了开源代码以供验证。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to CVPRW 2025, Workshop on Benchmarking and Expanding AI\n  Multimodal Approaches",
      "pdf_url": "http://arxiv.org/pdf/2503.23730v1",
      "published_date": "2025-03-31 05:04:25 UTC",
      "updated_date": "2025-03-31 05:04:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:09:21.358754"
    },
    {
      "arxiv_id": "2503.23721v1",
      "title": "Unimodal-driven Distillation in Multimodal Emotion Recognition with Dynamic Fusion",
      "title_zh": "翻译失败",
      "authors": [
        "Jiagen Li",
        "Rui Yu",
        "Huihao Huang",
        "Huaicheng Yan"
      ],
      "abstract": "Multimodal Emotion Recognition in Conversations (MERC) identifies emotional\nstates across text, audio and video, which is essential for intelligent\ndialogue systems and opinion analysis. Existing methods emphasize heterogeneous\nmodal fusion directly for cross-modal integration, but often suffer from\ndisorientation in multimodal learning due to modal heterogeneity and lack of\ninstructive guidance. In this work, we propose SUMMER, a novel heterogeneous\nmultimodal integration framework leveraging Mixture of Experts with\nHierarchical Cross-modal Fusion and Interactive Knowledge Distillation. Key\ncomponents include a Sparse Dynamic Mixture of Experts (SDMoE) for capturing\ndynamic token-wise interactions, a Hierarchical Cross-Modal Fusion (HCMF) for\neffective fusion of heterogeneous modalities, and Interactive Knowledge\nDistillation (IKD), which uses a pre-trained unimodal teacher to guide\nmultimodal fusion in latent and logit spaces. Experiments on IEMOCAP and MELD\nshow SUMMER outperforms state-of-the-art methods, particularly in recognizing\nminority and semantically similar emotions.",
      "tldr_zh": "本论文提出SUMMER框架，用于Multimodal Emotion Recognition in Conversations (MERC)，旨在通过单模态驱动的知识蒸馏解决多模态融合中的异质性问题。框架包括Sparse Dynamic Mixture of Experts (SDMoE)用于捕捉动态的token-wise交互、Hierarchical Cross-Modal Fusion (HCMF)用于有效融合文本、音频和视频模态，以及Interactive Knowledge Distillation (IKD)，利用预训练的单模态教师在潜在空间和logit空间指导多模态学习。实验在IEMOCAP和MELD数据集上显示，SUMMER优于现有方法，尤其在识别少数派和语义相似的感情方面。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.23721v1",
      "published_date": "2025-03-31 04:43:10 UTC",
      "updated_date": "2025-03-31 04:43:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:09:34.279008"
    },
    {
      "arxiv_id": "2504.08763v1",
      "title": "WebMap -- Large Language Model-assisted Semantic Link Induction in the Web",
      "title_zh": "翻译失败",
      "authors": [
        "Shiraj Pokharel",
        "Georg P. Roßrucker",
        "Mario M. Kubek"
      ],
      "abstract": "Carrying out research tasks is only inadequately supported, if not hindered,\nby current web search engines. This paper therefore proposes functional\nextensions of WebMap, a semantically induced overlay linking structure on the\nweb to inherently facilitate research activities. These add-ons support the\ndynamic determination and regrouping of document clusters, the creation of a\nsemantic signpost in the web, and the interactive tracing of topics back to\ntheir origins.",
      "tldr_zh": "该论文提出 WebMap 的功能扩展，利用 Large Language Model 辅助的语义链接诱导 (Semantic Link Induction)，以克服当前网络搜索引擎对研究任务的支持不足问题。这些扩展包括动态确定和重组文档集群、创建网络中的语义路标，以及交互式追踪主题的起源，从而内在地促进研究活动的效率和有效性。最终，该框架旨在为用户提供一个更智能化的网络研究工具。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "68T50, 68T07",
        "I.2.6; I.2.7; H.3.3"
      ],
      "primary_category": "cs.IR",
      "comment": "11 pages, 3 figures, accepted at the 2024 24th International\n  Conference on Innovations for Community Services (I4CS), June 12 - 14,\n  Maastricht, The Netherlands, 2024",
      "pdf_url": "http://arxiv.org/pdf/2504.08763v1",
      "published_date": "2025-03-31 04:40:45 UTC",
      "updated_date": "2025-03-31 04:40:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:09:44.975073"
    },
    {
      "arxiv_id": "2503.23713v1",
      "title": "GNN-Based Candidate Node Predictor for Influence Maximization in Temporal Graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Priyanka Gautam",
        "Balasubramaniam Natarajan",
        "Sai Munikoti",
        "S M Ferdous",
        "Mahantesh Halappanavar"
      ],
      "abstract": "In an age where information spreads rapidly across social media, effectively\nidentifying influential nodes in dynamic networks is critical. Traditional\ninfluence maximization strategies often fail to keep up with rapidly evolving\nrelationships and structures, leading to missed opportunities and\ninefficiencies. To address this, we propose a novel learning-based approach\nintegrating Graph Neural Networks (GNNs) with Bidirectional Long Short-Term\nMemory (BiLSTM) models. This hybrid framework captures both structural and\ntemporal dynamics, enabling accurate prediction of candidate nodes for seed set\nselection. The bidirectional nature of BiLSTM allows our model to analyze\npatterns from both past and future network states, ensuring adaptability to\nchanges over time. By dynamically adapting to graph evolution at each time\nsnapshot, our approach improves seed set calculation efficiency, achieving an\naverage of 90% accuracy in predicting potential seed nodes across diverse\nnetworks. This significantly reduces computational overhead by optimizing the\nnumber of nodes evaluated for seed selection. Our method is particularly\neffective in fields like viral marketing and social network analysis, where\nunderstanding temporal dynamics is crucial.",
      "tldr_zh": "该研究针对动态网络中影响最大化（Influence Maximization）的挑战，提出了一种基于 Graph Neural Networks (GNNs) 和 Bidirectional Long Short-Term Memory (BiLSTM) 的混合学习框架，用于预测候选节点。框架通过捕捉网络的结构和时间动态，分析过去和未来的网络状态，从而优化种子集选择过程，提高模型对图演变的适应性。实验结果显示，该方法在多种网络上实现了平均90%的候选节点预测准确率，同时显著降低了计算开销，适用于病毒营销和社会网络分析等领域。",
      "categories": [
        "cs.SI",
        "cs.AI"
      ],
      "primary_category": "cs.SI",
      "comment": "9 pages, 5 figures, Accepted in AAAI25 to AI4TS Workshop@AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.23713v1",
      "published_date": "2025-03-31 04:28:37 UTC",
      "updated_date": "2025-03-31 04:28:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:09:57.037219"
    },
    {
      "arxiv_id": "2504.08762v1",
      "title": "InteractiveSurvey: An LLM-based Personalized and Interactive Survey Paper Generation System",
      "title_zh": "InteractiveSurvey：基于 LLM 的个性化",
      "authors": [
        "Zhiyuan Wen",
        "Jiannong Cao",
        "Zian Wang",
        "Beichen Guo",
        "Ruosong Yang",
        "Shuaiqi Liu"
      ],
      "abstract": "The exponential growth of academic literature creates urgent demands for\ncomprehensive survey papers, yet manual writing remains time-consuming and\nlabor-intensive. Recent advances in large language models (LLMs) and\nretrieval-augmented generation (RAG) facilitate studies in synthesizing survey\npapers from multiple references, but most existing works restrict users to\ntitle-only inputs and fixed outputs, neglecting the personalized process of\nsurvey paper writing. In this paper, we introduce InteractiveSurvey - an\nLLM-based personalized and interactive survey paper generation system.\nInteractiveSurvey can generate structured, multi-modal survey papers with\nreference categorizations from multiple reference papers through both online\nretrieval and user uploads. More importantly, users can customize and refine\nintermediate components continuously during generation, including reference\ncategorization, outline, and survey content through an intuitive interface.\nEvaluations of content quality, time efficiency, and user studies show that\nInteractiveSurvey is an easy-to-use survey generation system that outperforms\nmost LLMs and existing methods in output content quality while remaining highly\ntime-efficient.",
      "tldr_zh": "该论文介绍了 InteractiveSurvey，一种基于 LLMs 的个性化交互式调查论文生成系统，旨在解决学术文献快速增长导致的写作耗时问题。该系统利用 RAG 技术，从多个参考论文生成结构化、多模态的调查内容，支持在线检索和用户上传，并允许用户通过直观界面自定义参考分类、提纲和内容。实验评估显示，InteractiveSurvey 在内容质量、时间效率和用户满意度方面均优于现有 LLMs 和方法，提供了一个高效易用的调查生成工具。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.08762v1",
      "published_date": "2025-03-31 04:23:22 UTC",
      "updated_date": "2025-03-31 04:23:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:10:09.684075"
    },
    {
      "arxiv_id": "2504.00053v1",
      "title": "Integrating Large Language Models with Human Expertise for Disease Detection in Electronic Health Records",
      "title_zh": "将大语言模型与人类专业知识整合用于电子健康记录中的疾病检测",
      "authors": [
        "Jie Pan",
        "Seungwon Lee",
        "Cheligeer Cheligeer",
        "Elliot A. Martin",
        "Kiarash Riazi",
        "Hude Quan",
        "Na Li"
      ],
      "abstract": "Objective: Electronic health records (EHR) are widely available to complement\nadministrative data-based disease surveillance and healthcare performance\nevaluation. Defining conditions from EHR is labour-intensive and requires\nextensive manual labelling of disease outcomes. This study developed an\nefficient strategy based on advanced large language models to identify multiple\nconditions from EHR clinical notes. Methods: We linked a cardiac registry\ncohort in 2015 with an EHR system in Alberta, Canada. We developed a pipeline\nthat leveraged a generative large language model (LLM) to analyze, understand,\nand interpret EHR notes by prompts based on specific diagnosis, treatment\nmanagement, and clinical guidelines. The pipeline was applied to detect acute\nmyocardial infarction (AMI), diabetes, and hypertension. The performance was\ncompared against clinician-validated diagnoses as the reference standard and\nwidely adopted International Classification of Diseases (ICD) codes-based\nmethods. Results: The study cohort accounted for 3,088 patients and 551,095\nclinical notes. The prevalence was 55.4%, 27.7%, 65.9% and for AMI, diabetes,\nand hypertension, respectively. The performance of the LLM-based pipeline for\ndetecting conditions varied: AMI had 88% sensitivity, 63% specificity, and 77%\npositive predictive value (PPV); diabetes had 91% sensitivity, 86% specificity,\nand 71% PPV; and hypertension had 94% sensitivity, 32% specificity, and 72%\nPPV. Compared with ICD codes, the LLM-based method demonstrated improved\nsensitivity and negative predictive value across all conditions. The monthly\npercentage trends from the detected cases by LLM and reference standard showed\nconsistent patterns.",
      "tldr_zh": "本研究整合大型语言模型(LLM)与人类专业知识，开发了一种高效管道，用于从电子健康记录(EHR)临床笔记中识别急性心肌梗死(AMI)、糖尿病和高血压等疾病。方法通过基于特定诊断、治疗管理和临床指南的提示，分析了加拿大阿尔伯塔省的3088名患者和55万余条笔记。结果显示，LLM管道在AMI检测中达到88%敏感性、63%特异性和77%阳性预测值(PPV)，并在所有条件下表现出比International Classification of Diseases (ICD)代码方法更高的敏感性和负预测值，从而提升了疾病监测的准确性和效率。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.00053v1",
      "published_date": "2025-03-31 04:19:18 UTC",
      "updated_date": "2025-03-31 04:19:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:10:23.065887"
    },
    {
      "arxiv_id": "2503.23708v2",
      "title": "Towards Benchmarking and Assessing the Safety and Robustness of Autonomous Driving on Safety-critical Scenarios",
      "title_zh": "翻译失败",
      "authors": [
        "Jingzheng Li",
        "Xianglong Liu",
        "Shikui Wei",
        "Zhijun Chen",
        "Bing Li",
        "Qing Guo",
        "Xianqi Yang",
        "Yanjun Pu",
        "Jiakai Wang"
      ],
      "abstract": "Autonomous driving has made significant progress in both academia and\nindustry, including performance improvements in perception task and the\ndevelopment of end-to-end autonomous driving systems. However, the safety and\nrobustness assessment of autonomous driving has not received sufficient\nattention. Current evaluations of autonomous driving are typically conducted in\nnatural driving scenarios. However, many accidents often occur in edge cases,\nalso known as safety-critical scenarios. These safety-critical scenarios are\ndifficult to collect, and there is currently no clear definition of what\nconstitutes a safety-critical scenario. In this work, we explore the safety and\nrobustness of autonomous driving in safety-critical scenarios. First, we\nprovide a definition of safety-critical scenarios, including static traffic\nscenarios such as adversarial attack scenarios and natural distribution shifts,\nas well as dynamic traffic scenarios such as accident scenarios. Then, we\ndevelop an autonomous driving safety testing platform to comprehensively\nevaluate autonomous driving systems, encompassing not only the assessment of\nperception modules but also system-level evaluations. Our work systematically\nconstructs a safety verification process for autonomous driving, providing\ntechnical support for the industry to establish standardized test framework and\nreduce risks in real-world road deployment.",
      "tldr_zh": "该研究针对自动驾驶的安全性和鲁棒性评估不足的问题，强调了在safety-critical scenarios（边缘情况）中进行测试的重要性，这些场景包括adversarial attack scenarios、自然分布偏移和事故等静态或动态交通情况。论文首先提供了safety-critical scenarios的清晰定义，并开发了一个autonomous driving safety testing platform，用于全面评估自动驾驶系统，不仅覆盖感知模块，还包括系统级测试。最终，该工作构建了一个系统的safety verification process，为行业提供标准化测试框架和技术支持，旨在减少实际道路部署中的风险并提升整体安全性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.23708v2",
      "published_date": "2025-03-31 04:13:32 UTC",
      "updated_date": "2025-04-07 08:26:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:10:32.919115"
    },
    {
      "arxiv_id": "2504.00051v1",
      "title": "The Cursive Transformer",
      "title_zh": "翻译失败",
      "authors": [
        "Sam Greydanus",
        "Zachary Wimpee"
      ],
      "abstract": "Transformers trained on tokenized text, audio, and images can generate\nhigh-quality autoregressive samples. But handwriting data, represented as\nsequences of pen coordinates, remains underexplored. We introduce a novel\ntokenization scheme that converts pen stroke offsets to polar coordinates,\ndiscretizes them into bins, and then turns them into sequences of tokens with\nwhich to train a standard GPT model. This allows us to capture complex stroke\ndistributions without using any specialized architectures (eg. the mixture\ndensity network or the self-advancing ASCII attention head from Graves 2014).\nWith just 3,500 handwritten words and a few simple data augmentations, we are\nable to train a model that can generate realistic cursive handwriting. Our\napproach is simpler and more performant than previous RNN-based methods.",
      "tldr_zh": "本研究提出了一种新颖的 tokenization 方案，用于训练 Transformer 模型生成 cursive handwriting（连笔手写）。该方案将笔迹坐标偏移转换为 polar coordinates（极坐标），离散化成 bins，并转化为 tokens，以训练标准 GPT 模型，从而避免使用专门架构如 mixture density network。仅使用 3,500 个手写单词和简单数据 augmentations（增强），模型即可生成逼真的 cursive handwriting，且比之前的 RNN-based methods（基于 RNN 的方法）更简单和高效。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "11 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.00051v1",
      "published_date": "2025-03-31 03:22:27 UTC",
      "updated_date": "2025-03-31 03:22:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:10:44.996510"
    },
    {
      "arxiv_id": "2503.23668v4",
      "title": "MolGround: A Benchmark for Molecular Grounding",
      "title_zh": "翻译失败",
      "authors": [
        "Jiaxin Wu",
        "Ting Zhang",
        "Rubing Chen",
        "Wengyu Zhang",
        "Chen Jason Zhang",
        "Xiao-Yong Wei",
        "Li Qing"
      ],
      "abstract": "Current molecular understanding approaches predominantly focus on the\ndescriptive aspect of human perception, providing broad, topic-level insights.\nHowever, the referential aspect -- linking molecular concepts to specific\nstructural components -- remains largely unexplored. To address this gap, we\npropose a molecular grounding benchmark designed to evaluate a model's\nreferential abilities. We align molecular grounding with established\nconventions in NLP, cheminformatics, and molecular science, showcasing the\npotential of NLP techniques to advance molecular understanding within the AI\nfor Science movement. Furthermore, we constructed the largest molecular\nunderstanding benchmark to date, comprising 117k QA pairs, and developed a\nmulti-agent grounding prototype as proof of concept. This system outperforms\nexisting models, including GPT-4o, and its grounding outputs have been\nintegrated to enhance traditional tasks such as molecular captioning and ATC\n(Anatomical, Therapeutic, Chemical) classification.",
      "tldr_zh": "该论文提出 MolGround 基准，用于评估模型在分子 grounding（将分子概念链接到特定结构组件）方面的参考能力，以填补当前分子理解方法偏重描述性而忽略参考性的空白。MolGround 借鉴 NLP、cheminformatics 和分子科学的惯例，构建了迄今为止最大的分子理解数据集，包括 117k QA pairs，并开发了一个多智能体 grounding 原型作为概念证明。该原型系统优于现有模型如 GPT-4o，并将其输出整合到传统任务中，如分子 captioning 和 ATC classification，从而提升了分子理解的整体性能。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.23668v4",
      "published_date": "2025-03-31 02:23:16 UTC",
      "updated_date": "2025-05-01 01:07:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:10:57.365523"
    },
    {
      "arxiv_id": "2504.00050v1",
      "title": "JudgeLRM: Large Reasoning Models as a Judge",
      "title_zh": "JudgeLRM：大型推理模型作为评判者",
      "authors": [
        "Nuo Chen",
        "Zhiyuan Hu",
        "Qingyun Zou",
        "Jiaying Wu",
        "Qian Wang",
        "Bryan Hooi",
        "Bingsheng He"
      ],
      "abstract": "The rise of Large Language Models (LLMs) as evaluators offers a scalable\nalternative to human annotation, yet existing Supervised Fine-Tuning (SFT) for\njudges approaches often fall short in domains requiring complex reasoning. In\nthis work, we investigate whether LLM judges truly benefit from enhanced\nreasoning capabilities. Through a detailed analysis of reasoning requirements\nacross evaluation tasks, we reveal a negative correlation between SFT\nperformance gains and the proportion of reasoning-demanding samples -\nhighlighting the limitations of SFT in such scenarios. To address this, we\nintroduce JudgeLRM, a family of judgment-oriented LLMs trained using\nreinforcement learning (RL) with judge-wise, outcome-driven rewards. JudgeLRM\nmodels consistently outperform both SFT-tuned and state-of-the-art reasoning\nmodels. Notably, JudgeLRM-3B surpasses GPT-4, and JudgeLRM-7B outperforms\nDeepSeek-R1 by 2.79% in F1 score, particularly excelling in judge tasks\nrequiring deep reasoning.",
      "tldr_zh": "本研究发现，现有的 Supervised Fine-Tuning (SFT) 方法在训练 Large Language Models (LLMs) 作为评判者时，面对需要复杂推理的领域时效果有限，且性能提升与推理需求样本比例呈负相关。针对此问题，作者提出 JudgeLRM，一系列使用 reinforcement learning (RL) 训练的判断导向 LLMs，采用 judge-wise 和 outcome-driven 奖励机制来优化模型。实验结果显示，JudgeLRM-3B 超过了 GPT-4，而 JudgeLRM-7B 在 F1 分数上比 DeepSeek-R1 高出 2.79%，尤其在深度推理任务中表现出显著优势。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "preprint",
      "pdf_url": "http://arxiv.org/pdf/2504.00050v1",
      "published_date": "2025-03-31 02:18:51 UTC",
      "updated_date": "2025-03-31 02:18:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:11:09.983115"
    },
    {
      "arxiv_id": "2504.13871v1",
      "title": "Human aversion? Do AI Agents Judge Identity More Harshly Than Performance",
      "title_zh": "翻译失败",
      "authors": [
        "Yuanjun Feng",
        "Vivek Chodhary",
        "Yash Raj Shrestha"
      ],
      "abstract": "This study examines the understudied role of algorithmic evaluation of human\njudgment in hybrid decision-making systems, a critical gap in management\nresearch. While extant literature focuses on human reluctance to follow\nalgorithmic advice, we reverse the perspective by investigating how AI agents\nbased on large language models (LLMs) assess and integrate human input. Our\nwork addresses a pressing managerial constraint: firms barred from deploying\nLLMs directly due to privacy concerns can still leverage them as mediating\ntools (for instance, anonymized outputs or decision pipelines) to guide\nhigh-stakes choices like pricing or discounts without exposing proprietary\ndata. Through a controlled prediction task, we analyze how an LLM-based AI\nagent weights human versus algorithmic predictions. We find that the AI system\nsystematically discounts human advice, penalizing human errors more severely\nthan algorithmic errors--a bias exacerbated when the agent's identity (human vs\nAI) is disclosed and the human is positioned second. These results reveal a\ndisconnect between AI-generated trust metrics and the actual influence of human\njudgment, challenging assumptions about equitable human-AI collaboration. Our\nfindings offer three key contributions. First, we identify a reverse algorithm\naversion phenomenon, where AI agents undervalue human input despite comparable\nerror rates. Second, we demonstrate how disclosure and positional bias interact\nto amplify this effect, with implications for system design. Third, we provide\na framework for indirect LLM deployment that balances predictive power with\ndata privacy. For practitioners, this research emphasize the need to audit AI\nweighting mechanisms, calibrate trust dynamics, and strategically design\ndecision sequences in human-AI systems.",
      "tldr_zh": "这篇论文探讨了AI代理在混合决策系统中评估人类判断的潜在偏见，逆转了以往对人类算法抵触的研究焦点。研究通过控制预测任务分析基于LLM的AI系统如何权衡人类与算法预测，结果显示AI系统系统性低估人类输入，对人类错误处罚更严厉，尤其在AI身份披露和人类位置居后时。论文的主要贡献包括识别“reverse algorithm aversion”现象、揭示披露和位置偏差的互动效应，以及提出间接部署LLM的框架，以兼顾预测准确性和数据隐私，并为实践者提供审计AI机制和优化人类-AI协作的建议。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "econ.GN",
        "q-fin.EC"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.13871v1",
      "published_date": "2025-03-31 02:05:27 UTC",
      "updated_date": "2025-03-31 02:05:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:11:26.326171"
    },
    {
      "arxiv_id": "2503.23641v1",
      "title": "Remarks on the Polyak-Lojasiewicz inequality and the convergence of gradient systems",
      "title_zh": "翻译失败",
      "authors": [
        "Arthur Castello B. de Oliveira",
        "Leilei Cui",
        "Eduardo D. Sontag"
      ],
      "abstract": "This work explores generalizations of the Polyak-Lojasiewicz inequality (PLI)\nand their implications for the convergence behavior of gradient flows in\noptimization problems. Motivated by the continuous-time linear quadratic\nregulator (CT-LQR) policy optimization problem -- where only a weaker version\nof the PLI is characterized in the literature -- this work shows that while\nweaker conditions are sufficient for global convergence to, and optimality of\nthe set of critical points of the cost function, the \"profile\" of the gradient\nflow solution can change significantly depending on which \"flavor\" of\ninequality the cost satisfies. After a general theoretical analysis, we focus\non fitting the CT-LQR policy optimization problem to the proposed framework,\nshowing that, in fact, it can never satisfy a PLI in its strongest form. We\nfollow up our analysis with a brief discussion on the difference between\ncontinuous- and discrete-time LQR policy optimization, and end the paper with\nsome intuition on the extension of this framework to optimization problems with\nL1 regularization and solved through proximal gradient flows.",
      "tldr_zh": "这篇论文探讨了 Polyak-Lojasiewicz inequality (PLI) 的推广及其对梯度流在优化问题中收敛行为的影响，特别是针对连续时间线性二次调节器 (CT-LQR) 策略优化问题，该问题仅满足 PLI 的弱版本。研究表明，更弱的 PLI 条件足以确保全局收敛到成本函数的临界点集并实现最优性，但不同形式的 PLI 会显著改变梯度流解的“profile”。论文通过理论分析应用到 CT-LQR 中，证明其无法满足 PLI 的最强形式，并简要讨论了连续与离散时间 LQR 优化差异，以及扩展到带有 L1 正则化的近端梯度流问题。",
      "categories": [
        "math.OC",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "math.OC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.23641v1",
      "published_date": "2025-03-31 00:59:56 UTC",
      "updated_date": "2025-03-31 00:59:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:11:34.104446"
    },
    {
      "arxiv_id": "2503.23633v5",
      "title": "GIScience in the Era of Artificial Intelligence: A Research Agenda Towards Autonomous GIS",
      "title_zh": "人工智能时代下的 GIScience：通往自治 GIS 的研究议程",
      "authors": [
        "Zhenlong Li",
        "Huan Ning",
        "Song Gao",
        "Krzysztof Janowicz",
        "Wenwen Li",
        "Samantha T. Arundel",
        "Chaowei Yang",
        "Budhendra Bhaduri",
        "Shaowen Wang",
        "A-Xing Zhu",
        "Mark Gahegan",
        "Shashi Shekhar",
        "Xinyue Ye",
        "Grant McKenzie",
        "Guido Cervone",
        "Michael E. Hodgson"
      ],
      "abstract": "The advent of generative AI exemplified by large language models (LLMs) opens\nnew ways to represent and compute geographic information and transcends the\nprocess of geographic knowledge production, driving geographic information\nsystems (GIS) towards autonomous GIS. Leveraging LLMs as the decision core,\nautonomous GIS can independently generate and execute geoprocessing workflows\nto perform spatial analysis. In this vision paper, we further elaborate on the\nconcept of autonomous GIS and present a conceptual framework that defines its\nfive autonomous goals, five autonomous levels, five core functions, and three\noperational scales. We demonstrate how autonomous GIS could perform geospatial\ndata retrieval, spatial analysis, and map making with four proof-of-concept GIS\nagents. We conclude by identifying critical challenges and future research\ndirections, including fine-tuning and self-growing decision-cores, autonomous\nmodeling, and examining the societal and practical implications of autonomous\nGIS. By establishing the groundwork for a paradigm shift in GIScience, this\npaper envisions a future where GIS moves beyond traditional workflows to\nautonomously reason, derive, innovate, and advance geospatial solutions to\npressing global challenges. Meanwhile, as we design and deploy increasingly\nintelligent geospatial systems, we carry a responsibility to ensure they are\ndeveloped in socially responsible ways, serve the public good, and support the\ncontinued value of human geographic insight in an AI-augmented future.",
      "tldr_zh": "这篇论文探讨了人工智能时代GIScience的发展，提出一个研究议程以实现自主GIS（Autonomous GIS），利用大型语言模型（LLMs）作为决策核心来独立生成和执行地理处理工作流。论文呈现了一个概念框架，包括五项自主目标、五项自主水平、五项核心功能和三项操作规模，并通过四个概念证明的GIS代理展示了其在地理空间数据检索、空间分析和地图制作中的潜力。主要挑战包括微调和自增长决策核心、自主建模，以及评估自主GIS的社会和实际影响；该研究为GIScience的范式转变奠定基础，推动地理解决方案更自主地应对全球挑战，同时强调确保其社会责任和人文价值。",
      "categories": [
        "cs.AI",
        "cs.ET",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.23633v5",
      "published_date": "2025-03-31 00:12:48 UTC",
      "updated_date": "2025-04-14 14:21:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:12:16.105284"
    },
    {
      "arxiv_id": "2503.23631v1",
      "title": "Intrinsically-Motivated Humans and Agents in Open-World Exploration",
      "title_zh": "翻译失败",
      "authors": [
        "Aly Lidayan",
        "Yuqing Du",
        "Eliza Kosoy",
        "Maria Rufova",
        "Pieter Abbeel",
        "Alison Gopnik"
      ],
      "abstract": "What drives exploration? Understanding intrinsic motivation is a\nlong-standing challenge in both cognitive science and artificial intelligence;\nnumerous objectives have been proposed and used to train agents, yet there\nremains a gap between human and agent exploration. We directly compare adults,\nchildren, and AI agents in a complex open-ended environment, Crafter, and study\nhow common intrinsic objectives: Entropy, Information Gain, and Empowerment,\nrelate to their behavior. We find that only Entropy and Empowerment are\nconsistently positively correlated with human exploration progress, indicating\nthat these objectives may better inform intrinsic reward design for agents.\nFurthermore, across agents and humans we observe that Entropy initially\nincreases rapidly, then plateaus, while Empowerment increases continuously,\nsuggesting that state diversity may provide more signal in early exploration,\nwhile advanced exploration should prioritize control. Finally, we find\npreliminary evidence that private speech utterances, and particularly goal\nverbalizations, may aid exploration in children.",
      "tldr_zh": "本研究比较了成人、儿童和AI代理在开放世界环境Crafter中的探索行为，评估了Entropy、Information Gain和Empowerment等内在目标对探索的影响。结果显示，只有Entropy和Empowerment与人类探索进展正相关，这为设计AI代理的内在奖励机制提供了重要指导。此外，观察到Entropy先快速增加后趋于稳定，而Empowerment持续上升，建议早期探索应优先状态多样性，高级探索则强调控制。最后，初步证据表明儿童的私人言语，尤其是目标表述，可能有助于提升探索效率。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.23631v1",
      "published_date": "2025-03-31 00:09:00 UTC",
      "updated_date": "2025-03-31 00:09:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:11:57.982557"
    },
    {
      "arxiv_id": "2503.23630v1",
      "title": "Finding Interest Needle in Popularity Haystack: Improving Retrieval by Modeling Item Exposure",
      "title_zh": "翻译失败",
      "authors": [
        "Amit Jaspal",
        "Rahul Agarwal"
      ],
      "abstract": "Recommender systems operate in closed feedback loops, where user interactions\nreinforce popularity bias, leading to over-recommendation of already popular\nitems while under-exposing niche or novel content. Existing bias mitigation\nmethods, such as Inverse Propensity Scoring (IPS) and Off- Policy Correction\n(OPC), primarily operate at the ranking stage or during training, lacking\nexplicit real-time control over exposure dynamics. In this work, we introduce\nan exposure- aware retrieval scoring approach, which explicitly models item\nexposure probability and adjusts retrieval-stage ranking at inference time.\nUnlike prior work, this method decouples exposure effects from engagement\nlikelihood, enabling controlled trade-offs between fairness and engagement in\nlarge-scale recommendation platforms. We validate our approach through online\nA/B experiments in a real-world video recommendation system, demonstrating a\n25% increase in uniquely retrieved items and a 40% reduction in the dominance\nof over-popular content, all while maintaining overall user engagement levels.\nOur results establish a scalable, deployable solution for mitigating popularity\nbias at the retrieval stage, offering a new paradigm for bias-aware\npersonalization.",
      "tldr_zh": "该研究针对推荐系统的流行度偏差问题，提出了一种曝光感知检索评分方法（exposure-aware retrieval scoring），通过显式建模物品曝光概率，并在检索阶段调整排名，从而将曝光效果与用户参与可能性分离，实现公平性和参与度的可控权衡。与现有方法如 Inverse Propensity Scoring (IPS) 和 Off-Policy Correction (OPC) 不同，该方法提供实时控制，避免过度推荐热门物品。实验在真实视频推荐系统中通过在线 A/B 测试验证，实现了独特物品检索增加25%和过度流行内容主导减少40%，同时维持用户参与水平，为偏见感知个性化提供了一个可扩展的解决方案。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "2 pages",
      "pdf_url": "http://arxiv.org/pdf/2503.23630v1",
      "published_date": "2025-03-31 00:04:01 UTC",
      "updated_date": "2025-03-31 00:04:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T08:12:09.658964"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 130,
  "processed_papers_count": 130,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-24T08:12:35.240808"
}