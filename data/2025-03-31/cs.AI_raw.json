[
  {
    "arxiv_id": "2504.00294v1",
    "title": "Inference-Time Scaling for Complex Tasks: Where We Stand and What Lies Ahead",
    "authors": [
      "Vidhisha Balachandran",
      "Jingya Chen",
      "Lingjiao Chen",
      "Shivam Garg",
      "Neel Joshi",
      "Yash Lara",
      "John Langford",
      "Besmira Nushi",
      "Vibhav Vineet",
      "Yue Wu",
      "Safoora Yousefi"
    ],
    "abstract": "Inference-time scaling can enhance the reasoning capabilities of large\nlanguage models (LLMs) on complex problems that benefit from step-by-step\nproblem solving. Although lengthening generated scratchpads has proven\neffective for mathematical tasks, the broader impact of this approach on other\ntasks remains less clear. In this work, we investigate the benefits and\nlimitations of scaling methods across nine state-of-the-art models and eight\nchallenging tasks, including math and STEM reasoning, calendar planning,\nNP-hard problems, navigation, and spatial reasoning. We compare conventional\nmodels (e.g., GPT-4o) with models fine-tuned for inference-time scaling (e.g.,\no1) through evaluation protocols that involve repeated model calls, either\nindependently or sequentially with feedback. These evaluations approximate\nlower and upper performance bounds and potential for future performance\nimprovements for each model, whether through enhanced training or multi-model\ninference systems. Our extensive empirical analysis reveals that the advantages\nof inference-time scaling vary across tasks and diminish as problem complexity\nincreases. In addition, simply using more tokens does not necessarily translate\nto higher accuracy in these challenging regimes. Results from multiple\nindependent runs with conventional models using perfect verifiers show that,\nfor some tasks, these models can achieve performance close to the average\nperformance of today's most advanced reasoning models. However, for other\ntasks, a significant performance gap remains, even in very high scaling\nregimes. Encouragingly, all models demonstrate significant gains when inference\nis further scaled with perfect verifiers or strong feedback, suggesting ample\npotential for future improvements.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "I.2"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.00294v1",
    "published_date": "2025-03-31 23:40:28 UTC",
    "updated_date": "2025-03-31 23:40:28 UTC"
  },
  {
    "arxiv_id": "2504.03731v1",
    "title": "A Benchmark for Scalable Oversight Protocols",
    "authors": [
      "Abhimanyu Pallavi Sudhir",
      "Jackson Kaunismaa",
      "Arjun Panickssery"
    ],
    "abstract": "As AI agents surpass human capabilities, scalable oversight -- the problem of\neffectively supplying human feedback to potentially superhuman AI models --\nbecomes increasingly critical to ensure alignment. While numerous scalable\noversight protocols have been proposed, they lack a systematic empirical\nframework to evaluate and compare them. While recent works have tried to\nempirically study scalable oversight protocols -- particularly Debate -- we\nargue that the experiments they conduct are not generalizable to other\nprotocols. We introduce the scalable oversight benchmark, a principled\nframework for evaluating human feedback mechanisms based on our agent score\ndifference (ASD) metric, a measure of how effectively a mechanism advantages\ntruth-telling over deception. We supply a Python package to facilitate rapid\nand competitive evaluation of scalable oversight protocols on our benchmark,\nand conduct a demonstrative experiment benchmarking Debate.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted at the ICLR 2025 Workshop on Bidirectional Human-AI\n  Alignment (BiAlign)",
    "pdf_url": "http://arxiv.org/pdf/2504.03731v1",
    "published_date": "2025-03-31 23:32:59 UTC",
    "updated_date": "2025-03-31 23:32:59 UTC"
  },
  {
    "arxiv_id": "2504.00289v2",
    "title": "Do Chinese models speak Chinese languages?",
    "authors": [
      "Andrea W Wen-Yi",
      "Unso Eun Seo Jo",
      "David Mimno"
    ],
    "abstract": "The release of top-performing open-weight LLMs has cemented China's role as a\nleading force in AI development. Do these models support languages spoken in\nChina? Or do they speak the same languages as Western models? Comparing\nmultilingual capabilities is important for two reasons. First, language ability\nprovides insights into pre-training data curation, and thus into resource\nallocation and development priorities. Second, China has a long history of\nexplicit language policy, varying between inclusivity of minority languages and\na Mandarin-first policy. To test whether Chinese LLMs today reflect an agenda\nabout China's languages, we test performance of Chinese and Western open-source\nLLMs on Asian regional and Chinese minority languages. Our experiments on\nInformation Parity and reading comprehension show Chinese models' performance\nacross these languages correlates strongly (r=0.93) with Western models', with\nthe sole exception being better Mandarin. Sometimes, Chinese models cannot\nidentify languages spoken by Chinese minorities such as Kazakh and Uyghur, even\nthough they are good at French and German. These results provide a window into\ncurrent development priorities, suggest options for future development, and\nindicate guidance for end users.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL",
    "comment": "First and second author contribute equally",
    "pdf_url": "http://arxiv.org/pdf/2504.00289v2",
    "published_date": "2025-03-31 23:19:08 UTC",
    "updated_date": "2025-04-07 19:09:50 UTC"
  },
  {
    "arxiv_id": "2504.00286v1",
    "title": "Digital Twins in Biopharmaceutical Manufacturing: Review and Perspective on Human-Machine Collaborative Intelligence",
    "authors": [
      "Mohammed Aatif Shahab",
      "Francesco Destro",
      "Richard D. Braatz"
    ],
    "abstract": "The biopharmaceutical industry is increasingly developing digital twins to\ndigitalize and automate the manufacturing process in response to the growing\nmarket demands. However, this shift presents significant challenges for human\noperators, as the complexity and volume of information can overwhelm their\nability to manage the process effectively. These issues are compounded when\ndigital twins are designed without considering interaction and collaboration\nwith operators, who are responsible for monitoring processes and assessing\nsituations, particularly during abnormalities. Our review of current trends in\nbiopharma digital twin development reveals a predominant focus on technology\nand often overlooks the critical role of human operators. To bridge this gap,\nthis article proposes a collaborative intelligence framework that emphasizes\nthe integration of operators with digital twins. Approaches to system design\nthat can enhance operator trust and human-machine interface usability are\npresented. Moreover, innovative training programs for preparing operators to\nunderstand and utilize digital twins are discussed. The framework outlined in\nthis article aims to enhance collaboration between operators and digital twins\neffectively by using their full capabilities to boost resilience and\nproductivity in biopharmaceutical manufacturing.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.00286v1",
    "published_date": "2025-03-31 23:13:54 UTC",
    "updated_date": "2025-03-31 23:13:54 UTC"
  },
  {
    "arxiv_id": "2504.00280v1",
    "title": "Exploration and Adaptation in Non-Stationary Tasks with Diffusion Policies",
    "authors": [
      "Gunbir Singh Baveja"
    ],
    "abstract": "This paper investigates the application of Diffusion Policy in\nnon-stationary, vision-based RL settings, specifically targeting environments\nwhere task dynamics and objectives evolve over time. Our work is grounded in\npractical challenges encountered in dynamic real-world scenarios such as\nrobotics assembly lines and autonomous navigation, where agents must adapt\ncontrol strategies from high-dimensional visual inputs. We apply Diffusion\nPolicy -- which leverages iterative stochastic denoising to refine latent\naction representations-to benchmark environments including Procgen and\nPointMaze. Our experiments demonstrate that, despite increased computational\ndemands, Diffusion Policy consistently outperforms standard RL methods such as\nPPO and DQN, achieving higher mean and maximum rewards with reduced\nvariability. These findings underscore the approach's capability to generate\ncoherent, contextually relevant action sequences in continuously shifting\nconditions, while also highlighting areas for further improvement in handling\nextreme non-stationarity.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "7 pages, 1 figure",
    "pdf_url": "http://arxiv.org/pdf/2504.00280v1",
    "published_date": "2025-03-31 23:00:07 UTC",
    "updated_date": "2025-03-31 23:00:07 UTC"
  },
  {
    "arxiv_id": "2504.00277v1",
    "title": "Rack Position Optimization in Large-Scale Heterogeneous Data Centers",
    "authors": [
      "Chang-Lin Chen",
      "Jiayu Chen",
      "Tian Lan",
      "Zhaoxia Zhao",
      "Hongbo Dong",
      "Vaneet Aggarwal"
    ],
    "abstract": "As rapidly growing AI computational demands accelerate the need for new\nhardware installation and maintenance, this work explores optimal data center\nresource management by balancing operational efficiency with fault tolerance\nthrough strategic rack positioning considering diverse resources and locations.\nTraditional mixed-integer programming (MIP) approaches often struggle with\nscalability, while heuristic methods may result in significant sub-optimality.\nTo address these issues, this paper presents a novel two-tier optimization\nframework using a high-level deep reinforcement learning (DRL) model to guide a\nlow-level gradient-based heuristic for local search. The high-level DRL agent\nemploys Leader Reward for optimal rack type ordering, and the low-level\nheuristic efficiently maps racks to positions, minimizing movement counts and\nensuring fault-tolerant resource distribution. This approach allows scalability\nto over 100,000 positions and 100 rack types. Our method outperformed the\ngradient-based heuristic by 7\\% on average and the MIP solver by over 30\\% in\nobjective value. It achieved a 100\\% success rate versus MIP's 97.5\\% (within a\n20-minute limit), completing in just 2 minutes compared to MIP's 1630 minutes\n(i.e., almost 4 orders of magnitude improvement). Unlike the MIP solver, which\nshowed performance variability under time constraints and high penalties, our\nalgorithm consistently delivered stable, efficient results - an essential\nfeature for large-scale data center management.",
    "categories": [
      "cs.AI",
      "cs.DC",
      "cs.LG",
      "cs.NI",
      "math.OC"
    ],
    "primary_category": "cs.AI",
    "comment": "Extended version of paper accepted at The International Conference on\n  Automated Planning and Scheduling (ICAPS) 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.00277v1",
    "published_date": "2025-03-31 22:55:37 UTC",
    "updated_date": "2025-03-31 22:55:37 UTC"
  },
  {
    "arxiv_id": "2504.00255v1",
    "title": "SciReplicate-Bench: Benchmarking LLMs in Agent-driven Algorithmic Reproduction from Research Papers",
    "authors": [
      "Yanzheng Xiang",
      "Hanqi Yan",
      "Shuyin Ouyang",
      "Lin Gui",
      "Yulan He"
    ],
    "abstract": "This study evaluates large language models (LLMs) in generating code from\nalgorithm descriptions from recent NLP papers. The task requires two key\ncompetencies: (1) algorithm comprehension: synthesizing information from papers\nand academic literature to understand implementation logic, and (2) coding\nexpertise: identifying dependencies and correctly implementing necessary APIs.\nTo facilitate rigorous evaluation, we introduce SciReplicate-Bench, a benchmark\nof 100 tasks from 36 NLP papers published in 2024, featuring detailed\nannotations and comprehensive test cases. Building on SciReplicate-Bench, we\npropose Sci-Reproducer, a multi-agent framework consisting of a Paper Agent\nthat interprets algorithmic concepts from literature and a Code Agent that\nretrieves dependencies from repositories and implement solutions. To assess\nalgorithm understanding, we introduce reasoning graph accuracy, which\nquantifies similarity between generated and reference reasoning graphs derived\nfrom code comments and structure. For evaluating implementation quality, we\nemploy execution accuracy, CodeBLEU, and repository dependency/API recall\nmetrics. In our experiments, we evaluate various powerful Non-Reasoning LLMs\nand Reasoning LLMs as foundational models. The best-performing LLM using\nSci-Reproducer achieves only 39% execution accuracy, highlighting the\nbenchmark's difficulty.Our analysis identifies missing or inconsistent\nalgorithm descriptions as key barriers to successful reproduction. We will\nopen-source our benchmark, and code at\nhttps://github.com/xyzCS/SciReplicate-Bench.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.MA",
      "cs.SE"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.00255v1",
    "published_date": "2025-03-31 22:02:24 UTC",
    "updated_date": "2025-03-31 22:02:24 UTC"
  },
  {
    "arxiv_id": "2504.00254v1",
    "title": "ElaLoRA: Elastic & Learnable Low-Rank Adaptation for Efficient Model Fine-Tuning",
    "authors": [
      "Huandong Chang",
      "Zicheng Ma",
      "Mingyuan Ma",
      "Zhenting Qi",
      "Andrew Sabot",
      "Hong Jiang",
      "H. T. Kung"
    ],
    "abstract": "Low-Rank Adaptation (LoRA) has become a widely adopted technique for\nfine-tuning large-scale pre-trained models with minimal parameter updates.\nHowever, existing methods rely on fixed ranks or focus solely on either rank\npruning or expansion, failing to adapt ranks dynamically to match the\nimportance of different layers during training. In this work, we propose\nElaLoRA, an adaptive low-rank adaptation framework that dynamically prunes and\nexpands ranks based on gradient-derived importance scores. To the best of our\nknowledge, ElaLoRA is the first method that enables both rank pruning and\nexpansion during fine-tuning. Experiments across multiple benchmarks\ndemonstrate that ElaLoRA consistently outperforms existing PEFT methods across\ndifferent parameter budgets. Furthermore, our studies validate that layers\nreceiving higher rank allocations contribute more significantly to model\nperformance, providing theoretical justification for our adaptive strategy. By\nintroducing a principled and adaptive rank allocation mechanism, ElaLoRA offers\na scalable and efficient fine-tuning solution, particularly suited for\nresource-constrained environments.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.00254v1",
    "published_date": "2025-03-31 21:58:25 UTC",
    "updated_date": "2025-03-31 21:58:25 UTC"
  },
  {
    "arxiv_id": "2504.01994v1",
    "title": "PIM-LLM: A High-Throughput Hybrid PIM Architecture for 1-bit LLMs",
    "authors": [
      "Jinendra Malekar",
      "Peyton Chandarana",
      "Md Hasibul Amin",
      "Mohammed E. Elbtity",
      "Ramtin Zand"
    ],
    "abstract": "In this paper, we propose PIM-LLM, a hybrid architecture developed to\naccelerate 1-bit large language models (LLMs). PIM-LLM leverages analog\nprocessing-in-memory (PIM) architectures and digital systolic arrays to\naccelerate low-precision matrix multiplication (MatMul) operations in\nprojection layers and high-precision MatMul operations in attention heads of\n1-bit LLMs, respectively. Our design achieves up to roughly 80x improvement in\ntokens per second and a 70% increase in tokens per joule compared to\nconventional hardware accelerators. Additionally, PIM-LLM outperforms previous\nPIM-based LLM accelerators, setting a new benchmark with at least 2x and 5x\nimprovement in GOPS and GOPS/W, respectively.",
    "categories": [
      "cs.AR",
      "cs.AI"
    ],
    "primary_category": "cs.AR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.01994v1",
    "published_date": "2025-03-31 21:42:43 UTC",
    "updated_date": "2025-03-31 21:42:43 UTC"
  },
  {
    "arxiv_id": "2504.00247v1",
    "title": "MultiMorph: On-demand Atlas Construction",
    "authors": [
      "S. Mazdak Abulnaga",
      "Andrew Hoopes",
      "Neel Dey",
      "Malte Hoffmann",
      "Marianne Rakic",
      "Bruce Fischl",
      "John Guttag",
      "Adrian Dalca"
    ],
    "abstract": "We present MultiMorph, a fast and efficient method for constructing\nanatomical atlases on the fly. Atlases capture the canonical structure of a\ncollection of images and are essential for quantifying anatomical variability\nacross populations. However, current atlas construction methods often require\ndays to weeks of computation, thereby discouraging rapid experimentation. As a\nresult, many scientific studies rely on suboptimal, precomputed atlases from\nmismatched populations, negatively impacting downstream analyses. MultiMorph\naddresses these challenges with a feedforward model that rapidly produces\nhigh-quality, population-specific atlases in a single forward pass for any 3D\nbrain dataset, without any fine-tuning or optimization. MultiMorph is based on\na linear group-interaction layer that aggregates and shares features within the\ngroup of input images. Further, by leveraging auxiliary synthetic data,\nMultiMorph generalizes to new imaging modalities and population groups at\ntest-time. Experimentally, MultiMorph outperforms state-of-the-art\noptimization-based and learning-based atlas construction methods in both small\nand large population settings, with a 100-fold reduction in time. This makes\nMultiMorph an accessible framework for biomedical researchers without machine\nlearning expertise, enabling rapid, high-quality atlas generation for diverse\nstudies.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "accepted to CVPR 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.00247v1",
    "published_date": "2025-03-31 21:35:24 UTC",
    "updated_date": "2025-03-31 21:35:24 UTC"
  },
  {
    "arxiv_id": "2504.00241v1",
    "title": "Synthesizing Public Opinions with LLMs: Role Creation, Impacts, and the Future to eDemorcacy",
    "authors": [
      "Rabimba Karanjai",
      "Boris Shor",
      "Amanda Austin",
      "Ryan Kennedy",
      "Yang Lu",
      "Lei Xu",
      "Weidong Shi"
    ],
    "abstract": "This paper investigates the use of Large Language Models (LLMs) to synthesize\npublic opinion data, addressing challenges in traditional survey methods like\ndeclining response rates and non-response bias. We introduce a novel technique:\nrole creation based on knowledge injection, a form of in-context learning that\nleverages RAG and specified personality profiles from the HEXACO model and\ndemographic information, and uses that for dynamically generated prompts. This\nmethod allows LLMs to simulate diverse opinions more accurately than existing\nprompt engineering approaches. We compare our results with pre-trained models\nwith standard few-shot prompts. Experiments using questions from the\nCooperative Election Study (CES) demonstrate that our role-creation approach\nsignificantly improves the alignment of LLM-generated opinions with real-world\nhuman survey responses, increasing answer adherence. In addition, we discuss\nchallenges, limitations and future research directions.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.00241v1",
    "published_date": "2025-03-31 21:21:52 UTC",
    "updated_date": "2025-03-31 21:21:52 UTC"
  },
  {
    "arxiv_id": "2504.00226v1",
    "title": "Large Language Models in Numberland: A Quick Test of Their Numerical Reasoning Abilities",
    "authors": [
      "Roussel Rahman"
    ],
    "abstract": "An essential element of human mathematical reasoning is our number sense --\nan abstract understanding of numbers and their relationships -- which allows us\nto solve problems involving vast number spaces using limited computational\nresources. Mathematical reasoning of Large Language Models (LLMs) is often\ntested on high-level problems (such as Olympiad challenges, geometry, word\nproblems, and puzzles), but their low-level number sense remains less explored.\nWe introduce \"Numberland,\" a 100-problem test to evaluate the numerical\nreasoning abilities of LLM-based agents. The tasks -- basic operations,\nadvanced calculations (e.g., exponentiation, complex numbers), prime number\nchecks, and the 24 game -- aim to test elementary skills and their integration\nin solving complex and uncertain problems. We evaluated five LLM-based agents:\nOpenAI's o1 and o1-mini, Google Gemini, Microsoft Copilot, and Anthropic\nClaude. They scored 74-95% on the first three tasks that allow deterministic\nsteps to solutions. In the 24 game, which needs trial-and-error search,\nperformance dropped to 10-73%. We tested the top 24 solver (o1 with 73%\naccuracy) on 25 harder problems, and its score fell to 27%, confirming search\nas a bottleneck. These results, along with the types of mistakes, suggest a\nfragile number of LLMs, which is a bit surprising given their prowess in\nchallenging benchmarks. The limits of LLM numerical reasoning highlight the\nscope of simple, targeted tests to evaluate and explain LLM math skills to\nensure safe use.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.00226v1",
    "published_date": "2025-03-31 21:06:39 UTC",
    "updated_date": "2025-03-31 21:06:39 UTC"
  },
  {
    "arxiv_id": "2504.00221v1",
    "title": "GazeLLM: Multimodal LLMs incorporating Human Visual Attention",
    "authors": [
      "Jun Rekimoto"
    ],
    "abstract": "Large Language Models (LLMs) are advancing into Multimodal LLMs (MLLMs),\ncapable of processing image, audio, and video as well as text. Combining\nfirst-person video, MLLMs show promising potential for understanding human\nactivities through video and audio, enabling many human-computer interaction\nand human-augmentation applications such as human activity support, real-world\nagents, and skill transfer to robots or other individuals. However, handling\nhigh-resolution, long-duration videos generates large latent representations,\nleading to substantial memory and processing demands, limiting the length and\nresolution MLLMs can manage. Reducing video resolution can lower memory usage\nbut often compromises comprehension. This paper introduces a method that\noptimizes first-person video analysis by integrating eye-tracking data, and\nproposes a method that decomposes first-person vision video into sub areas for\nregions of gaze focus. By processing these selectively gazed-focused inputs,\nour approach achieves task comprehension equivalent to or even better than\nprocessing the entire image at full resolution, but with significantly reduced\nvideo data input (reduce the number of pixels to one-tenth), offering an\nefficient solution for using MLLMs to interpret and utilize human skills.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.00221v1",
    "published_date": "2025-03-31 20:50:04 UTC",
    "updated_date": "2025-03-31 20:50:04 UTC"
  },
  {
    "arxiv_id": "2504.00220v1",
    "title": "Can Diffusion Models Disentangle? A Theoretical Perspective",
    "authors": [
      "Liming Wang",
      "Muhammad Jehanzeb Mirza",
      "Yishu Gong",
      "Yuan Gong",
      "Jiaqi Zhang",
      "Brian H. Tracey",
      "Katerina Placek",
      "Marco Vilela",
      "James R. Glass"
    ],
    "abstract": "This paper presents a novel theoretical framework for understanding how\ndiffusion models can learn disentangled representations. Within this framework,\nwe establish identifiability conditions for general disentangled latent\nvariable models, analyze training dynamics, and derive sample complexity bounds\nfor disentangled latent subspace models. To validate our theory, we conduct\ndisentanglement experiments across diverse tasks and modalities, including\nsubspace recovery in latent subspace Gaussian mixture models, image\ncolorization, image denoising, and voice conversion for speech classification.\nAdditionally, our experiments show that training strategies inspired by our\ntheory, such as style guidance regularization, consistently enhance\ndisentanglement performance.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.00220v1",
    "published_date": "2025-03-31 20:46:18 UTC",
    "updated_date": "2025-03-31 20:46:18 UTC"
  },
  {
    "arxiv_id": "2504.00218v1",
    "title": "$\\textit{Agents Under Siege}$: Breaking Pragmatic Multi-Agent LLM Systems with Optimized Prompt Attacks",
    "authors": [
      "Rana Muhammad Shahroz Khan",
      "Zhen Tan",
      "Sukwon Yun",
      "Charles Flemming",
      "Tianlong Chen"
    ],
    "abstract": "Most discussions about Large Language Model (LLM) safety have focused on\nsingle-agent settings but multi-agent LLM systems now create novel adversarial\nrisks because their behavior depends on communication between agents and\ndecentralized reasoning. In this work, we innovatively focus on attacking\npragmatic systems that have constrains such as limited token bandwidth, latency\nbetween message delivery, and defense mechanisms. We design a\n$\\textit{permutation-invariant adversarial attack}$ that optimizes prompt\ndistribution across latency and bandwidth-constraint network topologies to\nbypass distributed safety mechanisms within the system. Formulating the attack\npath as a problem of $\\textit{maximum-flow minimum-cost}$, coupled with the\nnovel $\\textit{Permutation-Invariant Evasion Loss (PIEL)}$, we leverage\ngraph-based optimization to maximize attack success rate while minimizing\ndetection risk. Evaluating across models including $\\texttt{Llama}$,\n$\\texttt{Mistral}$, $\\texttt{Gemma}$, $\\texttt{DeepSeek}$ and other variants on\nvarious datasets like $\\texttt{JailBreakBench}$ and\n$\\texttt{AdversarialBench}$, our method outperforms conventional attacks by up\nto $7\\times$, exposing critical vulnerabilities in multi-agent systems.\nMoreover, we demonstrate that existing defenses, including variants of\n$\\texttt{Llama-Guard}$ and $\\texttt{PromptGuard}$, fail to prohibit our attack,\nemphasizing the urgent need for multi-agent specific safety mechanisms.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.MA",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.00218v1",
    "published_date": "2025-03-31 20:43:56 UTC",
    "updated_date": "2025-03-31 20:43:56 UTC"
  },
  {
    "arxiv_id": "2504.00204v1",
    "title": "RailGoerl24: Görlitz Rail Test Center CV Dataset 2024",
    "authors": [
      "Rustam Tagiew",
      "Ilkay Wunderlich",
      "Mark Sastuba",
      "Steffen Seitz"
    ],
    "abstract": "Driverless train operation for open tracks on urban guided transport and\nmainline railways requires, among other things automatic detection of actual\nand potential obstacles, especially humans, in the danger zone of the train's\npath. Machine learning algorithms have proven to be powerful state-of-the-art\ntools for this task. However, these algorithms require large amounts of\nhigh-quality annotated data containing human beings in railway-specific\nenvironments as training data. Unfortunately, the amount of publicly available\ndatasets is not yet sufficient and is significantly inferior to the datasets in\nthe road domain. Therefore, this paper presents RailGoerl24, an on-board visual\nlight Full HD camera dataset of 12205 frames recorded in a railway test center\nof T\\\"UV S\\\"UD Rail, in G\\\"orlitz, Germany. Its main purpose is to support the\ndevelopment of driverless train operation for guided transport. RailGoerl24\nalso includes a terrestrial LiDAR scan covering parts of the area used to\nacquire the RGB data. In addition to the raw data, the dataset contains 33556\nboxwise annotations in total for the object class 'person'. The faces of\nrecorded actors are not blurred or altered in any other way. RailGoerl24, soon\navailable at data.fid-move.de/dataset/railgoerl24, can also be used for tasks\nbeyond collision prediction.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "4 pages, 5 figures, submitted to Engineering Reliable Autonomous\n  Systems 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.00204v1",
    "published_date": "2025-03-31 20:18:39 UTC",
    "updated_date": "2025-03-31 20:18:39 UTC"
  },
  {
    "arxiv_id": "2504.00194v1",
    "title": "Identifying Sparsely Active Circuits Through Local Loss Landscape Decomposition",
    "authors": [
      "Brianna Chrisman",
      "Lucius Bushnaq",
      "Lee Sharkey"
    ],
    "abstract": "Much of mechanistic interpretability has focused on understanding the\nactivation spaces of large neural networks. However, activation space-based\napproaches reveal little about the underlying circuitry used to compute\nfeatures. To better understand the circuits employed by models, we introduce a\nnew decomposition method called Local Loss Landscape Decomposition (L3D). L3D\nidentifies a set of low-rank subnetworks: directions in parameter space of\nwhich a subset can reconstruct the gradient of the loss between any sample's\noutput and a reference output vector. We design a series of progressively more\nchallenging toy models with well-defined subnetworks and show that L3D can\nnearly perfectly recover the associated subnetworks. Additionally, we\ninvestigate the extent to which perturbing the model in the direction of a\ngiven subnetwork affects only the relevant subset of samples. Finally, we apply\nL3D to a real-world transformer model and a convolutional neural network,\ndemonstrating its potential to identify interpretable and relevant circuits in\nparameter space.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.00194v1",
    "published_date": "2025-03-31 20:04:39 UTC",
    "updated_date": "2025-03-31 20:04:39 UTC"
  },
  {
    "arxiv_id": "2504.00186v1",
    "title": "Are Domain Generalization Benchmarks with Accuracy on the Line Misspecified?",
    "authors": [
      "Olawale Salaudeen",
      "Nicole Chiou",
      "Shiny Weng",
      "Sanmi Koyejo"
    ],
    "abstract": "Spurious correlations are unstable statistical associations that hinder\nrobust decision-making. Conventional wisdom suggests that models relying on\nsuch correlations will fail to generalize out-of-distribution (OOD), especially\nunder strong distribution shifts. However, empirical evidence challenges this\nview as naive in-distribution empirical risk minimizers often achieve the best\nOOD accuracy across popular OOD generalization benchmarks. In light of these\nresults, we propose a different perspective: many widely used benchmarks for\nevaluating robustness to spurious correlations are misspecified. Specifically,\nthey fail to include shifts in spurious correlations that meaningfully impact\nOOD generalization, making them unsuitable for evaluating the benefit of\nremoving such correlations. We establish conditions under which a distribution\nshift can reliably assess a model's reliance on spurious correlations.\nCrucially, under these conditions, we should not observe a strong positive\ncorrelation between in-distribution and OOD accuracy, often called \"accuracy on\nthe line.\" Yet, most state-of-the-art benchmarks exhibit this pattern,\nsuggesting they do not effectively assess robustness. Our findings expose a key\nlimitation in current benchmarks used to evaluate domain generalization\nalgorithms, that is, models designed to avoid spurious correlations. We\nhighlight the need to rethink how robustness to spurious correlations is\nassessed, identify well-specified benchmarks the field should prioritize, and\nenumerate strategies for designing future benchmarks that meaningfully reflect\nrobustness under distribution shift.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.00186v1",
    "published_date": "2025-03-31 19:50:04 UTC",
    "updated_date": "2025-03-31 19:50:04 UTC"
  },
  {
    "arxiv_id": "2504.00180v1",
    "title": "Contradiction Detection in RAG Systems: Evaluating LLMs as Context Validators for Improved Information Consistency",
    "authors": [
      "Vignesh Gokul",
      "Srikanth Tenneti",
      "Alwarappan Nakkiran"
    ],
    "abstract": "Retrieval Augmented Generation (RAG) systems have emerged as a powerful\nmethod for enhancing large language models (LLMs) with up-to-date information.\nHowever, the retrieval step in RAG can sometimes surface documents containing\ncontradictory information, particularly in rapidly evolving domains such as\nnews. These contradictions can significantly impact the performance of LLMs,\nleading to inconsistent or erroneous outputs. This study addresses this\ncritical challenge in two ways. First, we present a novel data generation\nframework to simulate different types of contradictions that may occur in the\nretrieval stage of a RAG system. Second, we evaluate the robustness of\ndifferent LLMs in performing as context validators, assessing their ability to\ndetect contradictory information within retrieved document sets. Our\nexperimental results reveal that context validation remains a challenging task\neven for state-of-the-art LLMs, with performance varying significantly across\ndifferent types of contradictions. While larger models generally perform better\nat contradiction detection, the effectiveness of different prompting strategies\nvaries across tasks and model architectures. We find that chain-of-thought\nprompting shows notable improvements for some models but may hinder performance\nin others, highlighting the complexity of the task and the need for more robust\napproaches to context validation in RAG systems.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.00180v1",
    "published_date": "2025-03-31 19:41:15 UTC",
    "updated_date": "2025-03-31 19:41:15 UTC"
  },
  {
    "arxiv_id": "2504.00178v1",
    "title": "Boundless Byte Pair Encoding: Breaking the Pre-tokenization Barrier",
    "authors": [
      "Craig W. Schmidt",
      "Varshini Reddy",
      "Chris Tanner",
      "Yuval Pinter"
    ],
    "abstract": "Pre-tokenization, the initial step in many modern tokenization pipelines,\nsegments text into smaller units called pretokens, typically splitting on\nwhitespace and punctuation. While this process encourages having full,\nindividual words as tokens, it introduces a fundamental limitation in most\ntokenization algorithms such as Byte Pair Encoding (BPE). Specifically,\npre-tokenization causes the distribution of tokens in a corpus to heavily skew\ntowards common, full-length words. This skewed distribution limits the benefits\nof expanding to larger vocabularies, since the additional tokens appear with\nprogressively lower counts. To overcome this barrier, we propose BoundlessBPE,\na modified BPE algorithm that relaxes the pretoken boundary constraint. Our\napproach selectively merges two complete pretokens into a larger unit we term a\nsuperword. Superwords are not necessarily semantically cohesive. For example,\nthe pretokens \" of\" and \" the\" might be combined to form the superword \" of\nthe\". This merging strategy results in a substantially more uniform\ndistribution of tokens across a corpus than standard BPE, and compresses text\nmore effectively, with an approximate 20% increase in bytes per token.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "68T50",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.00178v1",
    "published_date": "2025-03-31 19:36:29 UTC",
    "updated_date": "2025-03-31 19:36:29 UTC"
  },
  {
    "arxiv_id": "2504.00174v1",
    "title": "MetaCLBench: Meta Continual Learning Benchmark on Resource-Constrained Edge Devices",
    "authors": [
      "Sijia Li",
      "Young D. Kwon",
      "Lik-Hang Lee",
      "Pan Hui"
    ],
    "abstract": "Meta-Continual Learning (Meta-CL) has emerged as a promising approach to\nminimize manual labeling efforts and system resource requirements by enabling\nContinual Learning (CL) with limited labeled samples. However, while existing\nmethods have shown success in image-based tasks, their effectiveness remains\nunexplored for sequential time-series data from sensor systems, particularly\naudio inputs. To address this gap, we conduct a comprehensive benchmark study\nevaluating six representative Meta-CL approaches using three network\narchitectures on five datasets from both image and audio modalities. We develop\nMetaCLBench, an end-to-end Meta-CL benchmark framework for edge devices to\nevaluate system overheads and investigate trade-offs among performance,\ncomputational costs, and memory requirements across various Meta-CL methods.\nOur results reveal that while many Meta-CL methods enable to learn new classes\nfor both image and audio modalities, they impose significant computational and\nmemory costs on edge devices. Also, we find that pre-training and meta-training\nprocedures based on source data before deployment improve Meta-CL performance.\nFinally, to facilitate further research, we provide practical guidelines for\nresearchers and machine learning practitioners implementing Meta-CL on\nresource-constrained environments and make our benchmark framework and tools\npublicly available, enabling fair evaluation across both accuracy and\nsystem-level metrics.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.00174v1",
    "published_date": "2025-03-31 19:31:49 UTC",
    "updated_date": "2025-03-31 19:31:49 UTC"
  },
  {
    "arxiv_id": "2504.00170v1",
    "title": "Backdoor Detection through Replicated Execution of Outsourced Training",
    "authors": [
      "Hengrui Jia",
      "Sierra Wyllie",
      "Akram Bin Sediq",
      "Ahmed Ibrahim",
      "Nicolas Papernot"
    ],
    "abstract": "It is common practice to outsource the training of machine learning models to\ncloud providers. Clients who do so gain from the cloud's economies of scale,\nbut implicitly assume trust: the server should not deviate from the client's\ntraining procedure. A malicious server may, for instance, seek to insert\nbackdoors in the model. Detecting a backdoored model without prior knowledge of\nboth the backdoor attack and its accompanying trigger remains a challenging\nproblem. In this paper, we show that a client with access to multiple cloud\nproviders can replicate a subset of training steps across multiple servers to\ndetect deviation from the training procedure in a similar manner to\ndifferential testing. Assuming some cloud-provided servers are benign, we\nidentify malicious servers by the substantial difference between model updates\nrequired for backdooring and those resulting from clean training. Perhaps the\nstrongest advantage of our approach is its suitability to clients that have\nlimited-to-no local compute capability to perform training; we leverage the\nexistence of multiple cloud providers to identify malicious updates without\nexpensive human labeling or heavy computation. We demonstrate the capabilities\nof our approach on an outsourced supervised learning task where $50\\%$ of the\ncloud providers insert their own backdoor; our approach is able to correctly\nidentify $99.6\\%$ of them. In essence, our approach is successful because it\nreplaces the signature-based paradigm taken by existing approaches with an\nanomaly-based detection paradigm. Furthermore, our approach is robust to\nseveral attacks from adaptive adversaries utilizing knowledge of our detection\nscheme.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.CR",
    "comment": "Published in the 3rd IEEE Conference on Secure and Trustworthy\n  Machine Learning (IEEE SaTML 2025)",
    "pdf_url": "http://arxiv.org/pdf/2504.00170v1",
    "published_date": "2025-03-31 19:26:34 UTC",
    "updated_date": "2025-03-31 19:26:34 UTC"
  },
  {
    "arxiv_id": "2504.00163v1",
    "title": "Does \"Reasoning\" with Large Language Models Improve Recognizing, Generating, and Reframing Unhelpful Thoughts?",
    "authors": [
      "Yilin Qi",
      "Dong Won Lee",
      "Cynthia Breazeal",
      "Hae Won Park"
    ],
    "abstract": "Cognitive Reframing, a core element of Cognitive Behavioral Therapy (CBT),\nhelps individuals reinterpret negative experiences by finding positive meaning.\nRecent advances in Large Language Models (LLMs) have demonstrated improved\nperformance through reasoning-based strategies. This inspires a promising\ndirection of leveraging the reasoning capabilities of LLMs to improve CBT and\nmental reframing by simulating the process of critical thinking, potentially\nenabling more effective recognition, generation, and reframing of cognitive\ndistortions. In this work, we investigate the role of various reasoning\nmethods, including pre-trained reasoning LLMs and augmented reasoning\nstrategies such as CoT and self-consistency in enhancing LLMs' ability to\nperform cognitive reframing tasks. We find that augmented reasoning methods,\neven when applied to \"outdated\" LLMs like GPT-3.5, consistently outperform\nstate-of-the-art pretrained reasoning models on recognizing, generating and\nreframing unhelpful thoughts.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "8 pages, 3 figures (including appendix)",
    "pdf_url": "http://arxiv.org/pdf/2504.00163v1",
    "published_date": "2025-03-31 19:19:34 UTC",
    "updated_date": "2025-03-31 19:19:34 UTC"
  },
  {
    "arxiv_id": "2504.00149v1",
    "title": "Towards Precise Action Spotting: Addressing Temporal Misalignment in Labels with Dynamic Label Assignment",
    "authors": [
      "Masato Tamura"
    ],
    "abstract": "Precise action spotting has attracted considerable attention due to its\npromising applications. While existing methods achieve substantial performance\nby employing well-designed model architecture, they overlook a significant\nchallenge: the temporal misalignment inherent in ground-truth labels. This\nmisalignment arises when frames labeled as containing events do not align\naccurately with the actual event times, often as a result of human annotation\nerrors or the inherent difficulties in precisely identifying event boundaries\nacross neighboring frames. To tackle this issue, we propose a novel dynamic\nlabel assignment strategy that allows predictions to have temporal offsets from\nground-truth action times during training, ensuring consistent event spotting.\nOur method extends the concept of minimum-cost matching, which is utilized in\nthe spatial domain for object detection, to the temporal domain. By calculating\nmatching costs based on predicted action class scores and temporal offsets, our\nmethod dynamically assigns labels to the most likely predictions, even when the\npredicted times of these predictions deviate from ground-truth times,\nalleviating the negative effects of temporal misalignment in labels. We conduct\nextensive experiments and demonstrate that our method achieves state-of-the-art\nperformance, particularly in conditions where events are visually distinct and\ntemporal misalignment in labels is common.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.00149v1",
    "published_date": "2025-03-31 18:57:57 UTC",
    "updated_date": "2025-03-31 18:57:57 UTC"
  },
  {
    "arxiv_id": "2504.01992v1",
    "title": "Exploring the Societal and Economic Impacts of Artificial Intelligence: A Scenario Generation Methodology",
    "authors": [
      "Carlos J. Costa",
      "Joao Tiago Aparicio"
    ],
    "abstract": "This paper explores artificial intelligence's potential societal and economic\nimpacts (AI) through generating scenarios that assess how AI may influence\nvarious sectors. We categorize and analyze key factors affecting AI's\nintegration and adoption by applying an Impact-Uncertainty Matrix. A proposed\nmethodology involves querying academic databases, identifying emerging trends\nand topics, and categorizing these into an impact uncertainty framework. The\npaper identifies critical areas where AI may bring significant change and\noutlines potential future scenarios based on these insights. This research aims\nto inform policymakers, industry leaders, and researchers on the strategic\nplanning required to address the challenges and opportunities AI presents",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CE",
      "econ.TH",
      "I.2.7; J.4"
    ],
    "primary_category": "cs.CY",
    "comment": "6 pages",
    "pdf_url": "http://arxiv.org/pdf/2504.01992v1",
    "published_date": "2025-03-31 18:49:46 UTC",
    "updated_date": "2025-03-31 18:49:46 UTC"
  },
  {
    "arxiv_id": "2504.00142v3",
    "title": "LGIN: Defining an Approximately Powerful Hyperbolic GNN",
    "authors": [
      "Srinitish Srinivasan",
      "Omkumar CU"
    ],
    "abstract": "While graph neural networks (GNNs) operating in hyperbolic spaces have shown\npromise for modeling hierarchical and complex relational data, a critical\nlimitation often overlooked is their potentially limited discriminative power\ncompared to their Euclidean counterparts or fundamental graph isomorphism tests\nlike the Weisfeiler-Lehman (WL) hierarchy. Existing hyperbolic aggregation\nschemes, while curvature-aware, may not sufficiently capture the intricate\nstructural differences required to robustly distinguish non-isomorphic graphs\nowing to non-injective aggregation functions. To address this expressiveness\ngap in hyperbolic graph learning, we introduce the Lorentzian Graph Isomorphic\nNetwork (LGIN), a novel GNN designed to achieve enhanced discriminative\ncapabilities within the Lorentzian model of hyperbolic space. LGIN proposes a\nnew update rule that effectively combines local neighborhood information with a\nricher representation of graph structure designed to preserve the Lorentzian\nmetric tensor. This represents a significant step towards building more\nexpressive GNNs in non-Euclidean geometries, overcoming a common bottleneck in\ncurrent hyperbolic methods. We conduct extensive evaluations across nine\ndiverse benchmark datasets, including molecular and protein structures. LGIN\nconsistently outperforms or matches state-of-the-art hyperbolic and Euclidean\nGNNs, showcasing its practical efficacy and validating its superior ability to\ncapture complex graph structures and distinguish between different graphs. To\nthe best of our knowledge, LGIN is the first work to study the framework behind\na powerful GNN on the hyperbolic space. The code for our paper can be found at\nhttps://github.com/Deceptrax123/LGIN",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at GRADES NDA 2025 Workshop@ACM SIGMOD/PODS(Non Archival)",
    "pdf_url": "http://arxiv.org/pdf/2504.00142v3",
    "published_date": "2025-03-31 18:49:34 UTC",
    "updated_date": "2025-05-05 20:07:37 UTC"
  },
  {
    "arxiv_id": "2504.00133v1",
    "title": "Data-driven Power Loss Identification through Physics-Based Thermal Model Backpropagation",
    "authors": [
      "Mattia Scarpa",
      "Francesco Pase",
      "Ruggero Carli",
      "Mattia Bruschetta",
      "Franscesco Toso"
    ],
    "abstract": "Digital twins for power electronics require accurate power losses whose\ndirect measurements are often impractical or impossible in real-world\napplications. This paper presents a novel hybrid framework that combines\nphysics-based thermal modeling with data-driven techniques to identify and\ncorrect power losses accurately using only temperature measurements. Our\napproach leverages a cascaded architecture where a neural network learns to\ncorrect the outputs of a nominal power loss model by backpropagating through a\nreduced-order thermal model. We explore two neural architectures, a\nbootstrapped feedforward network, and a recurrent neural network, demonstrating\nthat the bootstrapped feedforward approach achieves superior performance while\nmaintaining computational efficiency for real-time applications. Between the\ninterconnection, we included normalization strategies and physics-guided\ntraining loss functions to preserve stability and ensure physical consistency.\nExperimental results show that our hybrid model reduces both temperature\nestimation errors (from 7.2+-6.8{\\deg}C to 0.3+-0.3{\\deg}C) and power loss\nprediction errors (from 5.4+-6.6W to 0.2+-0.3W) compared to traditional\nphysics-based approaches, even in the presence of thermal model uncertainties.\nThis methodology allows us to accurately estimate power losses without direct\nmeasurements, making it particularly helpful for real-time industrial\napplications where sensor placement is hindered by cost and physical\nlimitations.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.CC",
      "cs.LG",
      "cs.SY"
    ],
    "primary_category": "eess.SY",
    "comment": "Accepted by European Control Conference (ECC) 2020, 8 pages, 7\n  figures",
    "pdf_url": "http://arxiv.org/pdf/2504.00133v1",
    "published_date": "2025-03-31 18:37:14 UTC",
    "updated_date": "2025-03-31 18:37:14 UTC"
  },
  {
    "arxiv_id": "2504.00125v1",
    "title": "LLMs for Explainable AI: A Comprehensive Survey",
    "authors": [
      "Ahsan Bilal",
      "David Ebert",
      "Beiyu Lin"
    ],
    "abstract": "Large Language Models (LLMs) offer a promising approach to enhancing\nExplainable AI (XAI) by transforming complex machine learning outputs into\neasy-to-understand narratives, making model predictions more accessible to\nusers, and helping bridge the gap between sophisticated model behavior and\nhuman interpretability. AI models, such as state-of-the-art neural networks and\ndeep learning models, are often seen as \"black boxes\" due to a lack of\ntransparency. As users cannot fully understand how the models reach\nconclusions, users have difficulty trusting decisions from AI models, which\nleads to less effective decision-making processes, reduced accountabilities,\nand unclear potential biases. A challenge arises in developing explainable AI\n(XAI) models to gain users' trust and provide insights into how models generate\ntheir outputs. With the development of Large Language Models, we want to\nexplore the possibilities of using human language-based models, LLMs, for model\nexplainabilities. This survey provides a comprehensive overview of existing\napproaches regarding LLMs for XAI, and evaluation techniques for LLM-generated\nexplanation, discusses the corresponding challenges and limitations, and\nexamines real-world applications. Finally, we discuss future directions by\nemphasizing the need for more interpretable, automated, user-centric, and\nmultidisciplinary approaches for XAI via LLMs.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "This manuscript is intended for submission to ACM Transactions on\n  Intelligent Systems and Technology",
    "pdf_url": "http://arxiv.org/pdf/2504.00125v1",
    "published_date": "2025-03-31 18:19:41 UTC",
    "updated_date": "2025-03-31 18:19:41 UTC"
  },
  {
    "arxiv_id": "2504.00118v1",
    "title": "Times2D: Multi-Period Decomposition and Derivative Mapping for General Time Series Forecasting",
    "authors": [
      "Reza Nematirad",
      "Anil Pahwa",
      "Balasubramaniam Natarajan"
    ],
    "abstract": "Time series forecasting is an important application in various domains such\nas energy management, traffic planning, financial markets, meteorology, and\nmedicine. However, real-time series data often present intricate temporal\nvariability and sharp fluctuations, which pose significant challenges for time\nseries forecasting. Previous models that rely on 1D time series representations\nusually struggle with complex temporal variations. To address the limitations\nof 1D time series, this study introduces the Times2D method that transforms the\n1D time series into 2D space. Times2D consists of three main parts: first, a\nPeriodic Decomposition Block (PDB) that captures temporal variations within a\nperiod and between the same periods by converting the time series into a 2D\ntensor in the frequency domain. Second, the First and Second Derivative\nHeatmaps (FSDH) capture sharp changes and turning points, respectively.\nFinally, an Aggregation Forecasting Block (AFB) integrates the output tensors\nfrom PDB and FSDH for accurate forecasting. This 2D transformation enables the\nutilization of 2D convolutional operations to effectively capture long and\nshort characteristics of the time series. Comprehensive experimental results\nacross large-scale data in the literature demonstrate that the proposed Times2D\nmodel achieves state-of-the-art performance in both short-term and long-term\nforecasting. The code is available in this repository:\nhttps://github.com/Tims2D/Times2D.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at the AAAI 2025 Conference on Artificial Intelligence",
    "pdf_url": "http://arxiv.org/pdf/2504.00118v1",
    "published_date": "2025-03-31 18:08:30 UTC",
    "updated_date": "2025-03-31 18:08:30 UTC"
  },
  {
    "arxiv_id": "2504.01990v1",
    "title": "Advances and Challenges in Foundation Agents: From Brain-Inspired Intelligence to Evolutionary, Collaborative, and Safe Systems",
    "authors": [
      "Bang Liu",
      "Xinfeng Li",
      "Jiayi Zhang",
      "Jinlin Wang",
      "Tanjin He",
      "Sirui Hong",
      "Hongzhang Liu",
      "Shaokun Zhang",
      "Kaitao Song",
      "Kunlun Zhu",
      "Yuheng Cheng",
      "Suyuchen Wang",
      "Xiaoqiang Wang",
      "Yuyu Luo",
      "Haibo Jin",
      "Peiyan Zhang",
      "Ollie Liu",
      "Jiaqi Chen",
      "Huan Zhang",
      "Zhaoyang Yu",
      "Haochen Shi",
      "Boyan Li",
      "Dekun Wu",
      "Fengwei Teng",
      "Xiaojun Jia",
      "Jiawei Xu",
      "Jinyu Xiang",
      "Yizhang Lin",
      "Tianming Liu",
      "Tongliang Liu",
      "Yu Su",
      "Huan Sun",
      "Glen Berseth",
      "Jianyun Nie",
      "Ian Foster",
      "Logan Ward",
      "Qingyun Wu",
      "Yu Gu",
      "Mingchen Zhuge",
      "Xiangru Tang",
      "Haohan Wang",
      "Jiaxuan You",
      "Chi Wang",
      "Jian Pei",
      "Qiang Yang",
      "Xiaoliang Qi",
      "Chenglin Wu"
    ],
    "abstract": "The advent of large language models (LLMs) has catalyzed a transformative\nshift in artificial intelligence, paving the way for advanced intelligent\nagents capable of sophisticated reasoning, robust perception, and versatile\naction across diverse domains. As these agents increasingly drive AI research\nand practical applications, their design, evaluation, and continuous\nimprovement present intricate, multifaceted challenges. This survey provides a\ncomprehensive overview, framing intelligent agents within a modular,\nbrain-inspired architecture that integrates principles from cognitive science,\nneuroscience, and computational research. We structure our exploration into\nfour interconnected parts. First, we delve into the modular foundation of\nintelligent agents, systematically mapping their cognitive, perceptual, and\noperational modules onto analogous human brain functionalities, and elucidating\ncore components such as memory, world modeling, reward processing, and\nemotion-like systems. Second, we discuss self-enhancement and adaptive\nevolution mechanisms, exploring how agents autonomously refine their\ncapabilities, adapt to dynamic environments, and achieve continual learning\nthrough automated optimization paradigms, including emerging AutoML and\nLLM-driven optimization strategies. Third, we examine collaborative and\nevolutionary multi-agent systems, investigating the collective intelligence\nemerging from agent interactions, cooperation, and societal structures,\nhighlighting parallels to human social dynamics. Finally, we address the\ncritical imperative of building safe, secure, and beneficial AI systems,\nemphasizing intrinsic and extrinsic security threats, ethical alignment,\nrobustness, and practical mitigation strategies necessary for trustworthy\nreal-world deployment.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.01990v1",
    "published_date": "2025-03-31 18:00:29 UTC",
    "updated_date": "2025-03-31 18:00:29 UTC"
  },
  {
    "arxiv_id": "2504.00091v1",
    "title": "A First-Principles Based Risk Assessment Framework and the IEEE P3396 Standard",
    "authors": [
      "Richard J. Tong",
      "Marina Cortês",
      "Jeanine A. DeFalco",
      "Mark Underwood",
      "Janusz Zalewski"
    ],
    "abstract": "Generative Artificial Intelligence (AI) is enabling unprecedented automation\nin content creation and decision support, but it also raises novel risks. This\npaper presents a first-principles risk assessment framework underlying the IEEE\nP3396 Recommended Practice for AI Risk, Safety, Trustworthiness, and\nResponsibility. We distinguish between process risks (risks arising from how AI\nsystems are built or operated) and outcome risks (risks manifest in the AI\nsystem's outputs and their real-world effects), arguing that generative AI\ngovernance should prioritize outcome risks. Central to our approach is an\ninformation-centric ontology that classifies AI-generated outputs into four\nfundamental categories: (1) Perception-level information, (2) Knowledge-level\ninformation, (3) Decision/Action plan information, and (4) Control tokens\n(access or resource directives). This classification allows systematic\nidentification of harms and more precise attribution of responsibility to\nstakeholders (developers, deployers, users, regulators) based on the nature of\nthe information produced. We illustrate how each information type entails\ndistinct outcome risks (e.g. deception, misinformation, unsafe recommendations,\nsecurity breaches) and requires tailored risk metrics and mitigations. By\ngrounding the framework in the essence of information, human agency, and\ncognition, we align risk evaluation with how AI outputs influence human\nunderstanding and action. The result is a principled approach to AI risk that\nsupports clear accountability and targeted safeguards, in contrast to broad\napplication-based risk categorizations. We include example tables mapping\ninformation types to risks and responsibilities. This work aims to inform the\nIEEE P3396 Recommended Practice and broader AI governance with a rigorous,\nfirst-principles foundation for assessing generative AI risks while enabling\nresponsible innovation.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "8 pages with 3 tables. This manuscript is prepared for publication by\n  the Institute of Electrical and Electronics Engineers, Standards Association\n  (IEEE-SA), Sponsor Committee - Artificial Intelligence Standards Committee\n  (C/AISC) as a White Paper of Working Group p3396 at\n  https://standards.ieee.org/ieee/3396/11379/",
    "pdf_url": "http://arxiv.org/pdf/2504.00091v1",
    "published_date": "2025-03-31 18:00:03 UTC",
    "updated_date": "2025-03-31 18:00:03 UTC"
  },
  {
    "arxiv_id": "2503.24388v1",
    "title": "RIG: Synergizing Reasoning and Imagination in End-to-End Generalist Policy",
    "authors": [
      "Zhonghan Zhao",
      "Wenwei Zhang",
      "Haian Huang",
      "Kuikun Liu",
      "Jianfei Gao",
      "Gaoang Wang",
      "Kai Chen"
    ],
    "abstract": "Reasoning before action and imagining potential outcomes (i.e., world models)\nare essential for embodied agents operating in complex open-world environments.\nYet, prior work either incorporates only one of these abilities in an\nend-to-end agent or integrates multiple specialized models into an agent\nsystem, limiting the learning efficiency and generalization of the policy.\nThus, this paper makes the first attempt to synergize Reasoning and Imagination\nin an end-to-end Generalist policy, termed RIG. To train RIG in an end-to-end\nmanner, we construct a data pipeline that progressively integrates and enriches\nthe content of imagination and reasoning in the trajectories collected from\nexisting agents. The joint learning of reasoning and next image generation\nexplicitly models the inherent correlation between reasoning, action, and\ndynamics of environments, and thus exhibits more than $17\\times$ sample\nefficiency improvements and generalization in comparison with previous works.\nDuring inference, RIG first reasons about the next action, produces potential\naction, and then predicts the action outcomes, which offers the agent a chance\nto review and self-correct based on the imagination before taking real actions.\nExperimental results show that the synergy of reasoning and imagination not\nonly improves the robustness, generalization, and interoperability of\ngeneralist policy but also enables test-time scaling to enhance overall\nperformance.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.24388v1",
    "published_date": "2025-03-31 17:59:52 UTC",
    "updated_date": "2025-03-31 17:59:52 UTC"
  },
  {
    "arxiv_id": "2503.24381v1",
    "title": "UniOcc: A Unified Benchmark for Occupancy Forecasting and Prediction in Autonomous Driving",
    "authors": [
      "Yuping Wang",
      "Xiangyu Huang",
      "Xiaokang Sun",
      "Mingxuan Yan",
      "Shuo Xing",
      "Zhengzhong Tu",
      "Jiachen Li"
    ],
    "abstract": "We introduce UniOcc, a comprehensive, unified benchmark for occupancy\nforecasting (i.e., predicting future occupancies based on historical\ninformation) and current-frame occupancy prediction from camera images. UniOcc\nunifies data from multiple real-world datasets (i.e., nuScenes, Waymo) and\nhigh-fidelity driving simulators (i.e., CARLA, OpenCOOD), which provides 2D/3D\noccupancy labels with per-voxel flow annotations and support for cooperative\nautonomous driving. In terms of evaluation, unlike existing studies that rely\non suboptimal pseudo labels for evaluation, UniOcc incorporates novel metrics\nthat do not depend on ground-truth occupancy, enabling robust assessment of\nadditional aspects of occupancy quality. Through extensive experiments on\nstate-of-the-art models, we demonstrate that large-scale, diverse training data\nand explicit flow information significantly enhance occupancy prediction and\nforecasting performance.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.MA",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "14 pages; Dataset: https://huggingface.co/datasets/tasl-lab/uniocc;\n  Code: https://github.com/tasl-lab/UniOcc",
    "pdf_url": "http://arxiv.org/pdf/2503.24381v1",
    "published_date": "2025-03-31 17:59:24 UTC",
    "updated_date": "2025-03-31 17:59:24 UTC"
  },
  {
    "arxiv_id": "2503.24379v1",
    "title": "Any2Caption:Interpreting Any Condition to Caption for Controllable Video Generation",
    "authors": [
      "Shengqiong Wu",
      "Weicai Ye",
      "Jiahao Wang",
      "Quande Liu",
      "Xintao Wang",
      "Pengfei Wan",
      "Di Zhang",
      "Kun Gai",
      "Shuicheng Yan",
      "Hao Fei",
      "Tat-Seng Chua"
    ],
    "abstract": "To address the bottleneck of accurate user intent interpretation within the\ncurrent video generation community, we present Any2Caption, a novel framework\nfor controllable video generation under any condition. The key idea is to\ndecouple various condition interpretation steps from the video synthesis step.\nBy leveraging modern multimodal large language models (MLLMs), Any2Caption\ninterprets diverse inputs--text, images, videos, and specialized cues such as\nregion, motion, and camera poses--into dense, structured captions that offer\nbackbone video generators with better guidance. We also introduce Any2CapIns, a\nlarge-scale dataset with 337K instances and 407K conditions for\nany-condition-to-caption instruction tuning. Comprehensive evaluations\ndemonstrate significant improvements of our system in controllability and video\nquality across various aspects of existing video generation models. Project\nPage: https://sqwu.top/Any2Cap/",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Project Page: https://sqwu.top/Any2Cap/",
    "pdf_url": "http://arxiv.org/pdf/2503.24379v1",
    "published_date": "2025-03-31 17:59:01 UTC",
    "updated_date": "2025-03-31 17:59:01 UTC"
  },
  {
    "arxiv_id": "2503.24378v1",
    "title": "ACPBench Hard: Unrestrained Reasoning about Action, Change, and Planning",
    "authors": [
      "Harsha Kokel",
      "Michael Katz",
      "Kavitha Srinivas",
      "Shirin Sohrabi"
    ],
    "abstract": "The ACPBench dataset provides atomic reasoning tasks required for efficient\nplanning. The dataset is aimed at distilling the complex plan generation task\ninto separate atomic reasoning tasks in their easiest possible form, boolean or\nmultiple-choice questions, where the model has to choose the right answer from\nthe provided options. While the aim of ACPBench is to test the simplest form of\nreasoning about action and change, when tasked with planning, a model does not\ntypically have options to choose from and thus the reasoning required for\nplanning dictates an open-ended, generative form for these tasks. To that end,\nwe introduce ACPBench Hard, a generative version of ACPBench, with open-ended\nquestions which the model needs to answer. Models that perform well on these\ntasks could in principle be integrated into a planner or be used directly as a\npolicy. We discuss the complexity of these tasks as well as the complexity of\nvalidating the correctness of their answers and present validation algorithms\nfor each task. Equipped with these validators, we test the performance of a\nvariety of models on our tasks and find that for most of these tasks the\nperformance of even the largest models is still subpar. Our experiments show\nthat no model outperforms another in these tasks and with a few exceptions all\ntested language models score below 65%, indicating that even the current\nfrontier language models have a long way to go before they can reliably reason\nabout planning. In fact, even the so-called reasoning models struggle with\nsolving these reasoning tasks. ACPBench Hard collection is available at the\nfollowing link: https://ibm.github.io/ACPBench",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted to LM4Plan@AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.24378v1",
    "published_date": "2025-03-31 17:58:25 UTC",
    "updated_date": "2025-03-31 17:58:25 UTC"
  },
  {
    "arxiv_id": "2503.24377v1",
    "title": "Harnessing the Reasoning Economy: A Survey of Efficient Reasoning for Large Language Models",
    "authors": [
      "Rui Wang",
      "Hongru Wang",
      "Boyang Xue",
      "Jianhui Pang",
      "Shudong Liu",
      "Yi Chen",
      "Jiahao Qiu",
      "Derek Fai Wong",
      "Heng Ji",
      "Kam-Fai Wong"
    ],
    "abstract": "Recent advancements in Large Language Models (LLMs) have significantly\nenhanced their ability to perform complex reasoning tasks, transitioning from\nfast and intuitive thinking (System 1) to slow and deep reasoning (System 2).\nWhile System 2 reasoning improves task accuracy, it often incurs substantial\ncomputational costs due to its slow thinking nature and inefficient or\nunnecessary reasoning behaviors. In contrast, System 1 reasoning is\ncomputationally efficient but leads to suboptimal performance. Consequently, it\nis critical to balance the trade-off between performance (benefits) and\ncomputational costs (budgets), giving rise to the concept of reasoning economy.\nIn this survey, we provide a comprehensive analysis of reasoning economy in\nboth the post-training and test-time inference stages of LLMs, encompassing i)\nthe cause of reasoning inefficiency, ii) behavior analysis of different\nreasoning patterns, and iii) potential solutions to achieve reasoning economy.\nBy offering actionable insights and highlighting open challenges, we aim to\nshed light on strategies for improving the reasoning economy of LLMs, thereby\nserving as a valuable resource for advancing research in this evolving area. We\nalso provide a public repository to continually track developments in this\nfast-evolving field.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "In Progress; Paper list Repo:\n  https://github.com/DevoAllen/Awesome-Reasoning-Economy-Papers",
    "pdf_url": "http://arxiv.org/pdf/2503.24377v1",
    "published_date": "2025-03-31 17:58:07 UTC",
    "updated_date": "2025-03-31 17:58:07 UTC"
  },
  {
    "arxiv_id": "2503.24376v1",
    "title": "Exploring the Effect of Reinforcement Learning on Video Understanding: Insights from SEED-Bench-R1",
    "authors": [
      "Yi Chen",
      "Yuying Ge",
      "Rui Wang",
      "Yixiao Ge",
      "Lu Qiu",
      "Ying Shan",
      "Xihui Liu"
    ],
    "abstract": "Recent advancements in Chain of Thought (COT) generation have significantly\nimproved the reasoning capabilities of Large Language Models (LLMs), with\nreinforcement learning (RL) emerging as an effective post-training approach.\nMultimodal Large Language Models (MLLMs) inherit this reasoning potential but\nremain underexplored in tasks requiring both perception and logical reasoning.\nTo address this, we introduce SEED-Bench-R1, a benchmark designed to\nsystematically evaluate post-training methods for MLLMs in video understanding.\nIt includes intricate real-world videos and complex everyday planning tasks in\nthe format of multiple-choice questions, requiring sophisticated perception and\nreasoning. SEED-Bench-R1 assesses generalization through a three-level\nhierarchy: in-distribution, cross-environment, and cross-environment-task\nscenarios, equipped with a large-scale training dataset with easily verifiable\nground-truth answers. Using Qwen2-VL-Instruct-7B as a base model, we compare RL\nwith supervised fine-tuning (SFT), demonstrating RL's data efficiency and\nsuperior performance on both in-distribution and out-of-distribution tasks,\neven outperforming SFT on general video understanding benchmarks like\nLongVideoBench. Our detailed analysis reveals that RL enhances visual\nperception but often produces less logically coherent reasoning chains. We\nidentify key limitations such as inconsistent reasoning and overlooked visual\ncues, and suggest future improvements in base model reasoning, reward modeling,\nand RL robustness against noisy signals.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Technical Report (In Progress); Code released at:\n  https://github.com/TencentARC/SEED-Bench-R1",
    "pdf_url": "http://arxiv.org/pdf/2503.24376v1",
    "published_date": "2025-03-31 17:55:23 UTC",
    "updated_date": "2025-03-31 17:55:23 UTC"
  },
  {
    "arxiv_id": "2503.24370v3",
    "title": "Effectively Controlling Reasoning Models through Thinking Intervention",
    "authors": [
      "Tong Wu",
      "Chong Xiang",
      "Jiachen T. Wang",
      "G. Edward Suh",
      "Prateek Mittal"
    ],
    "abstract": "Reasoning-enhanced large language models (LLMs) explicitly generate\nintermediate reasoning steps prior to generating final answers, helping the\nmodel excel in complex problem-solving. In this paper, we demonstrate that this\nemerging generation framework offers a unique opportunity for more fine-grained\ncontrol over model behavior. We propose Thinking Intervention, a novel paradigm\ndesigned to explicitly guide the internal reasoning processes of LLMs by\nstrategically inserting or revising specific thinking tokens. We find that the\nThinking Intervention paradigm enhances the capabilities of reasoning models\nacross a wide range of tasks, including instruction following on IFEval and\nOverthinking, instruction hierarchy on SEP, and safety alignment on XSTest and\nSorryBench. Our results demonstrate that Thinking Intervention significantly\noutperforms baseline prompting approaches, achieving up to 6.7% accuracy gains\nin instruction-following scenarios, 15.4% improvements in reasoning about\ninstruction hierarchies, and a 40.0% increase in refusal rates for unsafe\nprompts using open-source DeepSeek R1 models. Overall, our work opens a\npromising new research avenue for controlling reasoning LLMs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.24370v3",
    "published_date": "2025-03-31 17:50:13 UTC",
    "updated_date": "2025-05-21 17:51:27 UTC"
  },
  {
    "arxiv_id": "2503.24365v1",
    "title": "Which LIME should I trust? Concepts, Challenges, and Solutions",
    "authors": [
      "Patrick Knab",
      "Sascha Marton",
      "Udo Schlegel",
      "Christian Bartelt"
    ],
    "abstract": "As neural networks become dominant in essential systems, Explainable\nArtificial Intelligence (XAI) plays a crucial role in fostering trust and\ndetecting potential misbehavior of opaque models. LIME (Local Interpretable\nModel-agnostic Explanations) is among the most prominent model-agnostic\napproaches, generating explanations by approximating the behavior of black-box\nmodels around specific instances. Despite its popularity, LIME faces challenges\nrelated to fidelity, stability, and applicability to domain-specific problems.\nNumerous adaptations and enhancements have been proposed to address these\nissues, but the growing number of developments can be overwhelming,\ncomplicating efforts to navigate LIME-related research. To the best of our\nknowledge, this is the first survey to comprehensively explore and collect\nLIME's foundational concepts and known limitations. We categorize and compare\nits various enhancements, offering a structured taxonomy based on intermediate\nsteps and key issues. Our analysis provides a holistic overview of advancements\nin LIME, guiding future research and helping practitioners identify suitable\napproaches. Additionally, we provide a continuously updated interactive website\n(https://patrick-knab.github.io/which-lime-to-trust/), offering a concise and\naccessible overview of the survey.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at the 3rd World Conference on eXplainable Artificial\n  Intelligence (XAI 2025)",
    "pdf_url": "http://arxiv.org/pdf/2503.24365v1",
    "published_date": "2025-03-31 17:44:39 UTC",
    "updated_date": "2025-03-31 17:44:39 UTC"
  },
  {
    "arxiv_id": "2503.24361v2",
    "title": "Sim-and-Real Co-Training: A Simple Recipe for Vision-Based Robotic Manipulation",
    "authors": [
      "Abhiram Maddukuri",
      "Zhenyu Jiang",
      "Lawrence Yunliang Chen",
      "Soroush Nasiriany",
      "Yuqi Xie",
      "Yu Fang",
      "Wenqi Huang",
      "Zu Wang",
      "Zhenjia Xu",
      "Nikita Chernyadev",
      "Scott Reed",
      "Ken Goldberg",
      "Ajay Mandlekar",
      "Linxi Fan",
      "Yuke Zhu"
    ],
    "abstract": "Large real-world robot datasets hold great potential to train generalist\nrobot models, but scaling real-world human data collection is time-consuming\nand resource-intensive. Simulation has great potential in supplementing\nlarge-scale data, especially with recent advances in generative AI and\nautomated data generation tools that enable scalable creation of robot behavior\ndatasets. However, training a policy solely in simulation and transferring it\nto the real world often demands substantial human effort to bridge the reality\ngap. A compelling alternative is to co-train the policy on a mixture of\nsimulation and real-world datasets. Preliminary studies have recently shown\nthis strategy to substantially improve the performance of a policy over one\ntrained on a limited amount of real-world data. Nonetheless, the community\nlacks a systematic understanding of sim-and-real co-training and what it takes\nto reap the benefits of simulation data for real-robot learning. This work\npresents a simple yet effective recipe for utilizing simulation data to solve\nvision-based robotic manipulation tasks. We derive this recipe from\ncomprehensive experiments that validate the co-training strategy on various\nsimulation and real-world datasets. Using two domains--a robot arm and a\nhumanoid--across diverse tasks, we demonstrate that simulation data can enhance\nreal-world task performance by an average of 38%, even with notable differences\nbetween the simulation and real-world data. Videos and additional results can\nbe found at https://co-training.github.io/",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "Project website: https://co-training.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2503.24361v2",
    "published_date": "2025-03-31 17:39:38 UTC",
    "updated_date": "2025-04-02 16:40:11 UTC"
  },
  {
    "arxiv_id": "2503.24358v1",
    "title": "SQuat: Subspace-orthogonal KV Cache Quantization",
    "authors": [
      "Hao Wang",
      "Ligong Han",
      "Kai Xu",
      "Akash Srivastava"
    ],
    "abstract": "The key-value (KV) cache accelerates LLMs decoding by storing KV tensors from\npreviously generated tokens. It reduces redundant computation at the cost of\nincreased memory usage. To mitigate this overhead, existing approaches compress\nKV tensors into lower-bit representations; however, quantization errors can\naccumulate as more tokens are generated, potentially resulting in undesired\noutputs. In this paper, we introduce SQuat (Subspace-orthogonal KV cache\nquantization). It first constructs a subspace spanned by query tensors to\ncapture the most critical task-related information. During key tensor\nquantization, it enforces that the difference between the (de)quantized and\noriginal keys remains orthogonal to this subspace, minimizing the impact of\nquantization errors on the attention mechanism's outputs. SQuat requires no\nmodel fine-tuning, no additional calibration dataset for offline learning, and\nis grounded in a theoretical framework we develop. Through numerical\nexperiments, we show that our method reduces peak memory by 2.17 to 2.82,\nimproves throughput by 2.45 to 3.60, and achieves more favorable benchmark\nscores than existing KV cache quantization algorithms.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.24358v1",
    "published_date": "2025-03-31 17:37:32 UTC",
    "updated_date": "2025-03-31 17:37:32 UTC"
  },
  {
    "arxiv_id": "2503.24354v2",
    "title": "ORAL: Prompting Your Large-Scale LoRAs via Conditional Recurrent Diffusion",
    "authors": [
      "Rana Muhammad Shahroz Khan",
      "Dongwen Tang",
      "Pingzhi Li",
      "Kai Wang",
      "Tianlong Chen"
    ],
    "abstract": "Parameter generation has emerged as a novel paradigm for neural network\ndevelopment, offering an alternative to traditional neural network training by\nsynthesizing high-quality model weights directly. In the context of Low-Rank\nAdaptation (LoRA) for evolving ($\\textit{i.e.}$, constantly updated) large\nlanguage models (LLMs), this approach promises efficient adaptation without\ncostly retraining. However, existing methods face critical limitations in\nsimultaneously achieving scalability and controllability. In this paper, we\nintroduce $\\texttt{ORAL}$, a novel $\\textbf{conditional recurrent diffusion}$\nframework that addresses these challenges. $\\texttt{ORAL}$ incorporates a novel\nconditioning mechanism that integrates model architecture and textual task\nspecifications, enabling the generation of task-specific LoRA parameters that\ncan seamlessly transfer across evolving foundation models. Our approach\nsuccessfully scales to billions-of-parameter LLMs and maintains\ncontrollability. Through extensive experiments across seven language tasks,\nfour vision tasks, and three multimodal tasks using five pre-trained LLMs, we\ndemonstrate that $\\texttt{ORAL}$ generates high-quality LoRA parameters that\nachieve comparable or superior performance to vanilla trained counterparts.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.24354v2",
    "published_date": "2025-03-31 17:34:59 UTC",
    "updated_date": "2025-04-08 18:38:56 UTC"
  },
  {
    "arxiv_id": "2503.24328v1",
    "title": "Contextual Preference Collaborative Measure Framework Based on Belief System",
    "authors": [
      "Hang Yu",
      "Wei Wei",
      "Zheng Tan",
      "Jing-lei Liu"
    ],
    "abstract": "To reduce the human intervention in the preference measure process,this\narticle proposes a preference collaborative measure framework based on an\nupdated belief system,which is also capable of improving the accuracy and\nefficiency of preferen-ce measure algorithms.Firstly,the distance of rules and\nthe average internal distance of rulesets are proposed for specifying the\nrelationship between the rules.For discovering the most representative\npreferences that are common in all users,namely common preference,a algorithm\nbased on average internal distance of ruleset,PRA algorithm,is proposed,which\naims to finish the discoveryprocess with minimum information loss\nrate.Furthermore,the concept of Common belief is proposed to update the belief\nsystem,and the common preferences are the evidences of updated belief\nsystem.Then,under the belief system,the proposed belief degree and deviation\ndegree are used to determine whether a rule confirms the belief system or not\nand classify the preference rules into two kinds(generalized or\npersonalized),and eventually filters out Top-K interesting rules relying on\nbelief degree and deviation degree.Based on above,a scalable interestingness\ncalculation framework that can apply various formulas is proposed for\naccurately calculating interestingness in different conditions.At last,IMCos\nalgorithm and IMCov algorithm are proposed as exemplars to verify the accuracy\nand efficiency of the framework by using weighted cosine similarity and\ncorrelation coefficients as belief degree.In experiments,the proposed\nalgorithms are compared to two state-of-the-art algorithms and the results show\nthat IMCos and IMCov outperform than the other two in most aspects.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "in Chinese language",
    "pdf_url": "http://arxiv.org/pdf/2503.24328v1",
    "published_date": "2025-03-31 17:17:45 UTC",
    "updated_date": "2025-03-31 17:17:45 UTC"
  },
  {
    "arxiv_id": "2503.24325v1",
    "title": "Pro-Routing: Proactive Routing of Autonomous Multi-Capacity Robots for Pickup-and-Delivery Tasks",
    "authors": [
      "Daniel Garces",
      "Stephanie Gil"
    ],
    "abstract": "We consider a multi-robot setting, where we have a fleet of multi-capacity\nautonomous robots that must service spatially distributed pickup-and-delivery\nrequests with fixed maximum wait times. Requests can be either scheduled ahead\nof time or they can enter the system in real-time. In this setting, stability\nfor a routing policy is defined as the cost of the policy being uniformly\nbounded over time. Most previous work either solve the problem offline to\ntheoretically maintain stability or they consider dynamically arriving requests\nat the expense of the theoretical guarantees on stability. In this paper, we\naim to bridge this gap by proposing a novel proactive rollout-based routing\nframework that adapts to real-time demand while still provably maintaining the\nstability of the learned routing policy. We derive provable stability\nguarantees for our method by proposing a fleet sizing algorithm that obtains a\nsufficiently large fleet that ensures stability by construction. To validate\nour theoretical results, we consider a case study on real ride requests for\nHarvard's evening Van System. We also evaluate the performance of our framework\nusing the currently deployed smaller fleet size. In this smaller setup, we\ncompare against the currently deployed routing algorithm, greedy heuristics,\nand Monte-Carlo-Tree-Search-based algorithms. Our empirical results show that\nour framework maintains stability when we use the sufficiently large fleet size\nfound in our theoretical results. For the smaller currently deployed fleet\nsize, our method services 6% more requests than the closest baseline while\nreducing median passenger wait times by 33%.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.RO",
    "comment": "25 pages, 7 figures, and 1 table",
    "pdf_url": "http://arxiv.org/pdf/2503.24325v1",
    "published_date": "2025-03-31 17:14:07 UTC",
    "updated_date": "2025-03-31 17:14:07 UTC"
  },
  {
    "arxiv_id": "2503.24310v1",
    "title": "BEATS: Bias Evaluation and Assessment Test Suite for Large Language Models",
    "authors": [
      "Alok Abhishek",
      "Lisa Erickson",
      "Tushar Bandopadhyay"
    ],
    "abstract": "In this research, we introduce BEATS, a novel framework for evaluating Bias,\nEthics, Fairness, and Factuality in Large Language Models (LLMs). Building upon\nthe BEATS framework, we present a bias benchmark for LLMs that measure\nperformance across 29 distinct metrics. These metrics span a broad range of\ncharacteristics, including demographic, cognitive, and social biases, as well\nas measures of ethical reasoning, group fairness, and factuality related\nmisinformation risk. These metrics enable a quantitative assessment of the\nextent to which LLM generated responses may perpetuate societal prejudices that\nreinforce or expand systemic inequities. To achieve a high score on this\nbenchmark a LLM must show very equitable behavior in their responses, making it\na rigorous standard for responsible AI evaluation. Empirical results based on\ndata from our experiment show that, 37.65\\% of outputs generated by industry\nleading models contained some form of bias, highlighting a substantial risk of\nusing these models in critical decision making systems. BEATS framework and\nbenchmark offer a scalable and statistically rigorous methodology to benchmark\nLLMs, diagnose factors driving biases, and develop mitigation strategies. With\nthe BEATS framework, our goal is to help the development of more socially\nresponsible and ethically aligned AI models.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "68T01 (Primary), 68T50 (Secondary)",
      "I.2.0; I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "32 pages, 33 figures, preprint version",
    "pdf_url": "http://arxiv.org/pdf/2503.24310v1",
    "published_date": "2025-03-31 16:56:52 UTC",
    "updated_date": "2025-03-31 16:56:52 UTC"
  },
  {
    "arxiv_id": "2503.24307v1",
    "title": "A Systematic Evaluation of LLM Strategies for Mental Health Text Analysis: Fine-tuning vs. Prompt Engineering vs. RAG",
    "authors": [
      "Arshia Kermani",
      "Veronica Perez-Rosas",
      "Vangelis Metsis"
    ],
    "abstract": "This study presents a systematic comparison of three approaches for the\nanalysis of mental health text using large language models (LLMs): prompt\nengineering, retrieval augmented generation (RAG), and fine-tuning. Using LLaMA\n3, we evaluate these approaches on emotion classification and mental health\ncondition detection tasks across two datasets. Fine-tuning achieves the highest\naccuracy (91% for emotion classification, 80% for mental health conditions) but\nrequires substantial computational resources and large training sets, while\nprompt engineering and RAG offer more flexible deployment with moderate\nperformance (40-68% accuracy). Our findings provide practical insights for\nimplementing LLM-based solutions in mental health applications, highlighting\nthe trade-offs between accuracy, computational requirements, and deployment\nflexibility.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.24307v1",
    "published_date": "2025-03-31 16:54:04 UTC",
    "updated_date": "2025-03-31 16:54:04 UTC"
  },
  {
    "arxiv_id": "2503.24305v3",
    "title": "Evaluating machine learning models for predicting pesticides toxicity to honey bees",
    "authors": [
      "Jakub Adamczyk",
      "Jakub Poziemski",
      "Pawel Siedlecki"
    ],
    "abstract": "Small molecules play a critical role in the biomedical, environmental, and\nagrochemical domains, each with distinct physicochemical requirements and\nsuccess criteria. Although biomedical research benefits from extensive datasets\nand established benchmarks, agrochemical data remain scarce, particularly with\nrespect to species-specific toxicity. This work focuses on ApisTox, the most\ncomprehensive dataset of experimentally validated chemical toxicity to the\nhoney bee (Apis mellifera), an ecologically vital pollinator. We evaluate\nApisTox using a diverse suite of machine learning approaches, including\nmolecular fingerprints, graph kernels, and graph neural networks, as well as\npretrained models. Comparative analysis with medicinal datasets from the\nMoleculeNet benchmark reveals that ApisTox represents a distinct chemical\nspace. Performance degradation on non-medicinal datasets, such as ApisTox,\ndemonstrates their limited generalizability of current state-of-the-art\nalgorithms trained solely on biomedical data. Our study highlights the need for\nmore diverse datasets and for targeted model development geared toward the\nagrochemical domain.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.24305v3",
    "published_date": "2025-03-31 16:51:12 UTC",
    "updated_date": "2025-04-10 09:38:53 UTC"
  },
  {
    "arxiv_id": "2503.24299v1",
    "title": "Shape Expressions with Inheritance",
    "authors": [
      "Iovka Boneva",
      "Jose Emilio Labra Gayo",
      "Eric Prud'hommeaux",
      "Katherine Thornton",
      "Andra Waagmeester"
    ],
    "abstract": "We formally introduce an inheritance mechanism for the Shape Expressions\nlanguage (ShEx). It is inspired by inheritance in object-oriented programming\nlanguages, and provides similar advantages such as reuse, modularity, and more\nflexible data modelling. Using an example, we explain the main features of the\ninheritance mechanism. We present its syntax and formal semantics. The\nsemantics is an extension of the semantics of ShEx 2.1. It also directly yields\na validation algorithm as an extension of the previous ShEx validation\nalgorithms, while maintaining the same algorithmic complexity.",
    "categories": [
      "cs.DB",
      "cs.AI"
    ],
    "primary_category": "cs.DB",
    "comment": "Accepted in Extended Semantic Web Conference, ESWC, 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.24299v1",
    "published_date": "2025-03-31 16:42:44 UTC",
    "updated_date": "2025-03-31 16:42:44 UTC"
  },
  {
    "arxiv_id": "2503.24284v1",
    "title": "Value of Information-based Deceptive Path Planning Under Adversarial Interventions",
    "authors": [
      "Wesley A. Suttle",
      "Jesse Milzman",
      "Mustafa O. Karabag",
      "Brian M. Sadler",
      "Ufuk Topcu"
    ],
    "abstract": "Existing methods for deceptive path planning (DPP) address the problem of\ndesigning paths that conceal their true goal from a passive, external observer.\nSuch methods do not apply to problems where the observer has the ability to\nperform adversarial interventions to impede the path planning agent. In this\npaper, we propose a novel Markov decision process (MDP)-based model for the DPP\nproblem under adversarial interventions and develop new value of information\n(VoI) objectives to guide the design of DPP policies. Using the VoI objectives\nwe propose, path planning agents deceive the adversarial observer into choosing\nsuboptimal interventions by selecting trajectories that are of low\ninformational value to the observer. Leveraging connections to the linear\nprogramming theory for MDPs, we derive computationally efficient solution\nmethods for synthesizing policies for performing DPP under adversarial\ninterventions. In our experiments, we illustrate the effectiveness of the\nproposed solution method in achieving deceptiveness under adversarial\ninterventions and demonstrate the superior performance of our approach to both\nexisting DPP methods and conservative path planning approaches on illustrative\ngridworld problems.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC"
    ],
    "primary_category": "cs.LG",
    "comment": "10 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.24284v1",
    "published_date": "2025-03-31 16:31:29 UTC",
    "updated_date": "2025-03-31 16:31:29 UTC"
  },
  {
    "arxiv_id": "2503.24278v2",
    "title": "AutoEval: Autonomous Evaluation of Generalist Robot Manipulation Policies in the Real World",
    "authors": [
      "Zhiyuan Zhou",
      "Pranav Atreya",
      "You Liang Tan",
      "Karl Pertsch",
      "Sergey Levine"
    ],
    "abstract": "Scalable and reproducible policy evaluation has been a long-standing\nchallenge in robot learning. Evaluations are critical to assess progress and\nbuild better policies, but evaluation in the real world, especially at a scale\nthat would provide statistically reliable results, is costly in terms of human\ntime and hard to obtain. Evaluation of increasingly generalist robot policies\nrequires an increasingly diverse repertoire of evaluation environments, making\nthe evaluation bottleneck even more pronounced. To make real-world evaluation\nof robotic policies more practical, we propose AutoEval, a system to\nautonomously evaluate generalist robot policies around the clock with minimal\nhuman intervention. Users interact with AutoEval by submitting evaluation jobs\nto the AutoEval queue, much like how software jobs are submitted with a cluster\nscheduling system, and AutoEval will schedule the policies for evaluation\nwithin a framework supplying automatic success detection and automatic scene\nresets. We show that AutoEval can nearly fully eliminate human involvement in\nthe evaluation process, permitting around the clock evaluations, and the\nevaluation results correspond closely to ground truth evaluations conducted by\nhand. To facilitate the evaluation of generalist policies in the robotics\ncommunity, we provide public access to multiple AutoEval scenes in the popular\nBridgeData robot setup with WidowX robot arms. In the future, we hope that\nAutoEval scenes can be set up across institutions to form a diverse and\ndistributed evaluation network.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.24278v2",
    "published_date": "2025-03-31 16:23:44 UTC",
    "updated_date": "2025-04-02 20:24:22 UTC"
  },
  {
    "arxiv_id": "2503.24277v1",
    "title": "Evaluating and Designing Sparse Autoencoders by Approximating Quasi-Orthogonality",
    "authors": [
      "Sewoong Lee",
      "Adam Davies",
      "Marc E. Canby",
      "Julia Hockenmaier"
    ],
    "abstract": "Sparse autoencoders (SAEs) have emerged as a workhorse of modern mechanistic\ninterpretability, but leading SAE approaches with top-$k$ style activation\nfunctions lack theoretical grounding for selecting the hyperparameter $k$. SAEs\nare based on the linear representation hypothesis (LRH), which assumes that the\nrepresentations of large language models (LLMs) are linearly encoded, and the\nsuperposition hypothesis (SH), which states that there can be more features in\nthe model than its dimensionality. We show that, based on the formal\ndefinitions of the LRH and SH, the magnitude of sparse feature vectors (the\nlatent representations learned by SAEs of the dense embeddings of LLMs) can be\napproximated using their corresponding dense vector with a closed-form error\nbound. To visualize this, we propose the ZF plot, which reveals a previously\nunknown relationship between LLM hidden embeddings and SAE feature vectors,\nallowing us to make the first empirical measurement of the extent to which\nfeature vectors of pre-trained SAEs are over- or under-activated for a given\ninput. Correspondingly, we introduce Approximate Feature Activation (AFA),\nwhich approximates the magnitude of the ground-truth sparse feature vector, and\npropose a new evaluation metric derived from AFA to assess the alignment\nbetween inputs and activations. We also leverage AFA to introduce a novel SAE\narchitecture, the top-AFA SAE, leading to SAEs that: (a) are more in line with\ntheoretical justifications; and (b) obviate the need to tune SAE sparsity\nhyperparameters. Finally, we empirically demonstrate that top-AFA SAEs achieve\nreconstruction loss comparable to that of state-of-the-art top-k SAEs, without\nrequiring the hyperparameter $k$ to be tuned. Our code is available at:\nhttps://github.com/SewoongLee/top-afa-sae.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.24277v1",
    "published_date": "2025-03-31 16:22:11 UTC",
    "updated_date": "2025-03-31 16:22:11 UTC"
  },
  {
    "arxiv_id": "2503.24270v2",
    "title": "Visual Acoustic Fields",
    "authors": [
      "Yuelei Li",
      "Hyunjin Kim",
      "Fangneng Zhan",
      "Ri-Zhao Qiu",
      "Mazeyu Ji",
      "Xiaojun Shan",
      "Xueyan Zou",
      "Paul Liang",
      "Hanspeter Pfister",
      "Xiaolong Wang"
    ],
    "abstract": "Objects produce different sounds when hit, and humans can intuitively infer\nhow an object might sound based on its appearance and material properties.\nInspired by this intuition, we propose Visual Acoustic Fields, a framework that\nbridges hitting sounds and visual signals within a 3D space using 3D Gaussian\nSplatting (3DGS). Our approach features two key modules: sound generation and\nsound localization. The sound generation module leverages a conditional\ndiffusion model, which takes multiscale features rendered from a\nfeature-augmented 3DGS to generate realistic hitting sounds. Meanwhile, the\nsound localization module enables querying the 3D scene, represented by the\nfeature-augmented 3DGS, to localize hitting positions based on the sound\nsources. To support this framework, we introduce a novel pipeline for\ncollecting scene-level visual-sound sample pairs, achieving alignment between\ncaptured images, impact locations, and corresponding sounds. To the best of our\nknowledge, this is the first dataset to connect visual and acoustic signals in\na 3D context. Extensive experiments on our dataset demonstrate the\neffectiveness of Visual Acoustic Fields in generating plausible impact sounds\nand accurately localizing impact sources. Our project page is at\nhttps://yuelei0428.github.io/projects/Visual-Acoustic-Fields/.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.24270v2",
    "published_date": "2025-03-31 16:16:10 UTC",
    "updated_date": "2025-04-01 03:16:38 UTC"
  },
  {
    "arxiv_id": "2504.00065v1",
    "title": "Assessing Code Understanding in LLMs",
    "authors": [
      "Cosimo Laneve",
      "Alvise Spanò",
      "Dalila Ressi",
      "Sabina Rossi",
      "Michele Bugliesi"
    ],
    "abstract": "We present an empirical evaluation of Large Language Models in code\nunderstanding associated with non-trivial, semantic-preserving program\ntransformations such as copy propagation or constant folding. Our findings show\nthat LLMs fail to judge semantic equivalence in approximately 41\\% of cases\nwhen no context is provided and in 29\\% when given a simple generic context. To\nimprove accuracy, we advocate integrating LLMs with code-optimization tools to\nenhance training and facilitate more robust program understanding.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.PL"
    ],
    "primary_category": "cs.SE",
    "comment": "22 page, 7 tables, submitted at FORTE 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.00065v1",
    "published_date": "2025-03-31 16:08:58 UTC",
    "updated_date": "2025-03-31 16:08:58 UTC"
  },
  {
    "arxiv_id": "2503.24262v1",
    "title": "New Statistical Framework for Extreme Error Probability in High-Stakes Domains for Reliable Machine Learning",
    "authors": [
      "Umberto Michelucci",
      "Francesca Venturini"
    ],
    "abstract": "Machine learning is vital in high-stakes domains, yet conventional validation\nmethods rely on averaging metrics like mean squared error (MSE) or mean\nabsolute error (MAE), which fail to quantify extreme errors. Worst-case\nprediction failures can have substantial consequences, but current frameworks\nlack statistical foundations for assessing their probability. In this work a\nnew statistical framework, based on Extreme Value Theory (EVT), is presented\nthat provides a rigorous approach to estimating worst-case failures. Applying\nEVT to synthetic and real-world datasets, this method is shown to enable robust\nestimation of catastrophic failure probabilities, overcoming the fundamental\nlimitations of standard cross-validation. This work establishes EVT as a\nfundamental tool for assessing model reliability, ensuring safer AI deployment\nin new technologies where uncertainty quantification is central to\ndecision-making or scientific analysis.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ME",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.24262v1",
    "published_date": "2025-03-31 16:08:11 UTC",
    "updated_date": "2025-03-31 16:08:11 UTC"
  },
  {
    "arxiv_id": "2503.24258v1",
    "title": "Beyond a Single Mode: GAN Ensembles for Diverse Medical Data Generation",
    "authors": [
      "Lorenzo Tronchin",
      "Tommy Löfstedt",
      "Paolo Soda",
      "Valerio Guarrasi"
    ],
    "abstract": "The advancement of generative AI, particularly in medical imaging, confronts\nthe trilemma of ensuring high fidelity, diversity, and efficiency in synthetic\ndata generation. While Generative Adversarial Networks (GANs) have shown\npromise across various applications, they still face challenges like mode\ncollapse and insufficient coverage of real data distributions. This work\nexplores the use of GAN ensembles to overcome these limitations, specifically\nin the context of medical imaging. By solving a multi-objective optimisation\nproblem that balances fidelity and diversity, we propose a method for selecting\nan optimal ensemble of GANs tailored for medical data. The selected ensemble is\ncapable of generating diverse synthetic medical images that are representative\nof true data distributions and computationally efficient. Each model in the\nensemble brings a unique contribution, ensuring minimal redundancy. We\nconducted a comprehensive evaluation using three distinct medical datasets,\ntesting 22 different GAN architectures with various loss functions and\nregularisation techniques. By sampling models at different training epochs, we\ncrafted 110 unique configurations. The results highlight the capability of GAN\nensembles to enhance the quality and utility of synthetic medical images,\nthereby improving the efficacy of downstream tasks such as diagnostic\nmodelling.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.24258v1",
    "published_date": "2025-03-31 16:06:01 UTC",
    "updated_date": "2025-03-31 16:06:01 UTC"
  },
  {
    "arxiv_id": "2503.24237v1",
    "title": "Spatio-temporal Prediction of Fine-Grained Origin-Destination Matrices with Applications in Ridesharing",
    "authors": [
      "Run Yang",
      "Runpeng Dai",
      "Siran Gao",
      "Xiaocheng Tang",
      "Fan Zhou",
      "Hongtu Zhu"
    ],
    "abstract": "Accurate spatial-temporal prediction of network-based travelers' requests is\ncrucial for the effective policy design of ridesharing platforms. Having\nknowledge of the total demand between various locations in the upcoming time\nslots enables platforms to proactively prepare adequate supplies, thereby\nincreasing the likelihood of fulfilling travelers' requests and redistributing\nidle drivers to areas with high potential demand to optimize the global\nsupply-demand equilibrium. This paper delves into the prediction of\nOrigin-Destination (OD) demands at a fine-grained spatial level, especially\nwhen confronted with an expansive set of local regions. While this task holds\nimmense practical value, it remains relatively unexplored within the research\ncommunity. To fill this gap, we introduce a novel prediction model called\nOD-CED, which comprises an unsupervised space coarsening technique to alleviate\ndata sparsity and an encoder-decoder architecture to capture both semantic and\ngeographic dependencies. Through practical experimentation, OD-CED has\ndemonstrated remarkable results. It achieved an impressive reduction of up to\n45% reduction in root-mean-square error and 60% in weighted mean absolute\npercentage error over traditional statistical methods when dealing with OD\nmatrices exhibiting a sparsity exceeding 90%.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.24237v1",
    "published_date": "2025-03-31 15:52:27 UTC",
    "updated_date": "2025-03-31 15:52:27 UTC"
  },
  {
    "arxiv_id": "2503.24235v3",
    "title": "A Survey on Test-Time Scaling in Large Language Models: What, How, Where, and How Well?",
    "authors": [
      "Qiyuan Zhang",
      "Fuyuan Lyu",
      "Zexu Sun",
      "Lei Wang",
      "Weixu Zhang",
      "Wenyue Hua",
      "Haolun Wu",
      "Zhihan Guo",
      "Yufei Wang",
      "Niklas Muennighoff",
      "Irwin King",
      "Xue Liu",
      "Chen Ma"
    ],
    "abstract": "As enthusiasm for scaling computation (data and parameters) in the\npretraining era gradually diminished, test-time scaling (TTS), also referred to\nas ``test-time computing'' has emerged as a prominent research focus. Recent\nstudies demonstrate that TTS can further elicit the problem-solving\ncapabilities of large language models (LLMs), enabling significant\nbreakthroughs not only in specialized reasoning tasks, such as mathematics and\ncoding, but also in general tasks like open-ended Q&A. However, despite the\nexplosion of recent efforts in this area, there remains an urgent need for a\ncomprehensive survey offering a systemic understanding. To fill this gap, we\npropose a unified, multidimensional framework structured along four core\ndimensions of TTS research: what to scale, how to scale, where to scale, and\nhow well to scale. Building upon this taxonomy, we conduct an extensive review\nof methods, application scenarios, and assessment aspects, and present an\norganized decomposition that highlights the unique functional roles of\nindividual techniques within the broader TTS landscape. From this analysis, we\ndistill the major developmental trajectories of TTS to date and offer hands-on\nguidelines for practical deployment. Furthermore, we identify several open\nchallenges and offer insights into promising future directions, including\nfurther scaling, clarifying the functional essence of techniques, generalizing\nto more tasks, and more attributions. Our repository is available on\nhttps://github.com/testtimescaling/testtimescaling.github.io/",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "v3: Expand Agentic and SFT Chapters. Build Website for better\n  visualization",
    "pdf_url": "http://arxiv.org/pdf/2503.24235v3",
    "published_date": "2025-03-31 15:46:15 UTC",
    "updated_date": "2025-05-04 15:48:08 UTC"
  },
  {
    "arxiv_id": "2503.24228v1",
    "title": "PAARS: Persona Aligned Agentic Retail Shoppers",
    "authors": [
      "Saab Mansour",
      "Leonardo Perelli",
      "Lorenzo Mainetti",
      "George Davidson",
      "Stefano D'Amato"
    ],
    "abstract": "In e-commerce, behavioral data is collected for decision making which can be\ncostly and slow. Simulation with LLM powered agents is emerging as a promising\nalternative for representing human population behavior. However, LLMs are known\nto exhibit certain biases, such as brand bias, review rating bias and limited\nrepresentation of certain groups in the population, hence they need to be\ncarefully benchmarked and aligned to user behavior. Ultimately, our goal is to\nsynthesise an agent population and verify that it collectively approximates a\nreal sample of humans. To this end, we propose a framework that: (i) creates\nsynthetic shopping agents by automatically mining personas from anonymised\nhistorical shopping data, (ii) equips agents with retail-specific tools to\nsynthesise shopping sessions and (iii) introduces a novel alignment suite\nmeasuring distributional differences between humans and shopping agents at the\ngroup (i.e. population) level rather than the traditional \"individual\" level.\nExperimental results demonstrate that using personas improves performance on\nthe alignment suite, though a gap remains to human behaviour. We showcase an\ninitial application of our framework for automated agentic A/B testing and\ncompare the findings to human results. Finally, we discuss applications,\nlimitations and challenges setting the stage for impactful future work.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.24228v1",
    "published_date": "2025-03-31 15:41:51 UTC",
    "updated_date": "2025-03-31 15:41:51 UTC"
  },
  {
    "arxiv_id": "2503.24219v1",
    "title": "MB-ORES: A Multi-Branch Object Reasoner for Visual Grounding in Remote Sensing",
    "authors": [
      "Karim Radouane",
      "Hanane Azzag",
      "Mustapha lebbah"
    ],
    "abstract": "We propose a unified framework that integrates object detection (OD) and\nvisual grounding (VG) for remote sensing (RS) imagery. To support conventional\nOD and establish an intuitive prior for VG task, we fine-tune an open-set\nobject detector using referring expression data, framing it as a partially\nsupervised OD task. In the first stage, we construct a graph representation of\neach image, comprising object queries, class embeddings, and proposal\nlocations. Then, our task-aware architecture processes this graph to perform\nthe VG task. The model consists of: (i) a multi-branch network that integrates\nspatial, visual, and categorical features to generate task-aware proposals, and\n(ii) an object reasoning network that assigns probabilities across proposals,\nfollowed by a soft selection mechanism for final referring object localization.\nOur model demonstrates superior performance on the OPT-RSVG and DIOR-RSVG\ndatasets, achieving significant improvements over state-of-the-art methods\nwhile retaining classical OD capabilities. The code will be available in our\nrepository: \\url{https://github.com/rd20karim/MB-ORES}.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.24219v1",
    "published_date": "2025-03-31 15:36:41 UTC",
    "updated_date": "2025-03-31 15:36:41 UTC"
  },
  {
    "arxiv_id": "2503.24215v1",
    "title": "All You Need is Sally-Anne: ToM in AI Strongly Supported After Surpassing Tests for 3-Year-Olds",
    "authors": [
      "Nitay Alon",
      "Joseph Barnby",
      "Reuth Mirsky",
      "Stefan Sarkadi"
    ],
    "abstract": "Theory of Mind (ToM) is a hallmark of human cognition, allowing individuals\nto reason about others' beliefs and intentions. Engineers behind recent\nadvances in Artificial Intelligence (AI) have claimed to demonstrate comparable\ncapabilities. This paper presents a model that surpasses traditional ToM tests\ndesigned for 3-year-old children, providing strong support for the presence of\nToM in AI systems.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.24215v1",
    "published_date": "2025-03-31 15:32:10 UTC",
    "updated_date": "2025-03-31 15:32:10 UTC"
  },
  {
    "arxiv_id": "2503.24210v1",
    "title": "DiET-GS: Diffusion Prior and Event Stream-Assisted Motion Deblurring 3D Gaussian Splatting",
    "authors": [
      "Seungjun Lee",
      "Gim Hee Lee"
    ],
    "abstract": "Reconstructing sharp 3D representations from blurry multi-view images are\nlong-standing problem in computer vision. Recent works attempt to enhance\nhigh-quality novel view synthesis from the motion blur by leveraging\nevent-based cameras, benefiting from high dynamic range and microsecond\ntemporal resolution. However, they often reach sub-optimal visual quality in\neither restoring inaccurate color or losing fine-grained details. In this\npaper, we present DiET-GS, a diffusion prior and event stream-assisted motion\ndeblurring 3DGS. Our framework effectively leverages both blur-free event\nstreams and diffusion prior in a two-stage training strategy. Specifically, we\nintroduce the novel framework to constraint 3DGS with event double integral,\nachieving both accurate color and well-defined details. Additionally, we\npropose a simple technique to leverage diffusion prior to further enhance the\nedge details. Qualitative and quantitative results on both synthetic and\nreal-world data demonstrate that our DiET-GS is capable of producing\nsignificantly better quality of novel views compared to the existing baselines.\nOur project page is https://diet-gs.github.io",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "CVPR 2025. Project Page: https://diet-gs.github.io",
    "pdf_url": "http://arxiv.org/pdf/2503.24210v1",
    "published_date": "2025-03-31 15:27:07 UTC",
    "updated_date": "2025-03-31 15:27:07 UTC"
  },
  {
    "arxiv_id": "2504.03729v1",
    "title": "A Scalable Predictive Modelling Approach to Identifying Duplicate Adverse Event Reports for Drugs and Vaccines",
    "authors": [
      "Jim W. Barrett",
      "Nils Erlanson",
      "Joana Félix China",
      "G. Niklas Norén"
    ],
    "abstract": "The practice of pharmacovigilance relies on large databases of individual\ncase safety reports to detect and evaluate potential new causal associations\nbetween medicines or vaccines and adverse events. Duplicate reports are\nseparate and unlinked reports referring to the same case of an adverse event\ninvolving a specific patient at a certain time. They impede statistical\nanalysis and mislead clinical assessment. The large size of such databases\nprecludes a manual identification of duplicates, and so a computational method\nmust be employed. This paper builds upon a hitherto state of the art model,\nvigiMatch, modifying existing features and introducing new ones to target known\nshortcomings of the original model. Two support vector machine classifiers, one\nfor medicines and one for vaccines, classify report pairs as duplicates and\nnon-duplicates. Recall was measured using a diverse collection of 5 independent\nlabelled test sets. Precision was measured by having each model classify a\nrandomly selected stream of pairs of reports until each model classified 100\npairs as duplicates. These pairs were assessed by a medical doctor without\nindicating which method(s) had flagged each pair. Performance on individual\ncountries was measured by having a medical doctor assess a subset of pairs\nclassified as duplicates for three different countries. The new model achieved\nhigher precision and higher recall for all labelled datasets compared to the\nprevious state of the art model, with comparable performance for medicines and\nvaccines. The model was shown to produce substantially fewer false positives\nthan the comparator model on pairs from individual countries. The method\npresented here advances state of the art for duplicate detection in adverse\nevent reports for medicines and vaccines.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "26 pages, 11 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.03729v1",
    "published_date": "2025-03-31 15:24:29 UTC",
    "updated_date": "2025-03-31 15:24:29 UTC"
  },
  {
    "arxiv_id": "2503.24199v2",
    "title": "Agent-Based Simulations of Online Political Discussions: A Case Study on Elections in Germany",
    "authors": [
      "Abdul Sittar",
      "Simon Münker",
      "Fabio Sartori",
      "Andreas Reitenbach",
      "Achim Rettinger",
      "Michael Mäs",
      "Alenka Guček",
      "Marko Grobelnik"
    ],
    "abstract": "User engagement on social media platforms is influenced by historical\ncontext, time constraints, and reward-driven interactions. This study presents\nan agent-based simulation approach that models user interactions, considering\npast conversation history, motivation, and resource constraints. Utilizing\nGerman Twitter data on political discourse, we fine-tune AI models to generate\nposts and replies, incorporating sentiment analysis, irony detection, and\noffensiveness classification. The simulation employs a myopic best-response\nmodel to govern agent behavior, accounting for decision-making based on\nexpected rewards. Our results highlight the impact of historical context on\nAI-generated responses and demonstrate how engagement evolves under varying\nconstraints.",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "I forgot to take the consent from all other co authors and they want\n  to withdraw it",
    "pdf_url": "http://arxiv.org/pdf/2503.24199v2",
    "published_date": "2025-03-31 15:17:04 UTC",
    "updated_date": "2025-04-11 06:54:10 UTC"
  },
  {
    "arxiv_id": "2504.00063v1",
    "title": "The Axiom-Based Atlas: A Structural Mapping of Theorems via Foundational Proof Vectors",
    "authors": [
      "Harim Yoo"
    ],
    "abstract": "The Axiom-Based Atlas is a novel framework that structurally represents\nmathematical theorems as proof vectors over foundational axiom systems. By\nmapping the logical dependencies of theorems onto vectors indexed by axioms -\nsuch as those from Hilbert geometry, Peano arithmetic, or ZFC - we offer a new\nway to visualize, compare, and analyze mathematical knowledge. This\nvector-based formalism not only captures the logical foundation of theorems but\nalso enables quantitative similarity metrics - such as cosine distance -\nbetween mathematical results, offering a new analytic layer for structural\ncomparison. Using heatmaps, vector clustering, and AI-assisted modeling, this\natlas enables the grouping of theorems by logical structure, not just by\nmathematical domain. We also introduce a prototype assistant (Atlas-GPT) that\ninterprets natural language theorems and suggests likely proof vectors,\nsupporting future applications in automated reasoning, mathematical education,\nand formal verification.\n  This direction is partially inspired by Terence Tao's recent reflections on\nthe convergence of symbolic and structural mathematics. The Axiom-Based Atlas\naims to provide a scalable, interpretable model of mathematical reasoning that\nis both human-readable and AI-compatible, contributing to the future landscape\nof formal mathematical systems.",
    "categories": [
      "cs.AI",
      "math.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.00063v1",
    "published_date": "2025-03-31 15:12:57 UTC",
    "updated_date": "2025-03-31 15:12:57 UTC"
  },
  {
    "arxiv_id": "2503.24191v1",
    "title": "Output Constraints as Attack Surface: Exploiting Structured Generation to Bypass LLM Safety Mechanisms",
    "authors": [
      "Shuoming Zhang",
      "Jiacheng Zhao",
      "Ruiyuan Xu",
      "Xiaobing Feng",
      "Huimin Cui"
    ],
    "abstract": "Content Warning: This paper may contain unsafe or harmful content generated\nby LLMs that may be offensive to readers. Large Language Models (LLMs) are\nextensively used as tooling platforms through structured output APIs to ensure\nsyntax compliance so that robust integration with existing softwares like agent\nsystems, could be achieved. However, the feature enabling functionality of\ngrammar-guided structured output presents significant security vulnerabilities.\nIn this work, we reveal a critical control-plane attack surface orthogonal to\ntraditional data-plane vulnerabilities. We introduce Constrained Decoding\nAttack (CDA), a novel jailbreak class that weaponizes structured output\nconstraints to bypass safety mechanisms. Unlike prior attacks focused on input\nprompts, CDA operates by embedding malicious intent in schema-level grammar\nrules (control-plane) while maintaining benign surface prompts (data-plane). We\ninstantiate this with a proof-of-concept Chain Enum Attack, achieves 96.2%\nattack success rates across proprietary and open-weight LLMs on five safety\nbenchmarks with a single query, including GPT-4o and Gemini-2.0-flash. Our\nfindings identify a critical security blind spot in current LLM architectures\nand urge a paradigm shift in LLM safety to address control-plane\nvulnerabilities, as current mechanisms focused solely on data-plane threats\nleave critical systems exposed.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "15 pages, 13 figures, 4 tables Work In Progress",
    "pdf_url": "http://arxiv.org/pdf/2503.24191v1",
    "published_date": "2025-03-31 15:08:06 UTC",
    "updated_date": "2025-03-31 15:08:06 UTC"
  },
  {
    "arxiv_id": "2503.24165v1",
    "title": "Predicting Targeted Therapy Resistance in Non-Small Cell Lung Cancer Using Multimodal Machine Learning",
    "authors": [
      "Peiying Hua",
      "Andrea Olofson",
      "Faraz Farhadi",
      "Liesbeth Hondelink",
      "Gregory Tsongalis",
      "Konstantin Dragnev",
      "Dagmar Hoegemann Savellano",
      "Arief Suriawinata",
      "Laura Tafe",
      "Saeed Hassanpour"
    ],
    "abstract": "Lung cancer is the primary cause of cancer death globally, with non-small\ncell lung cancer (NSCLC) emerging as its most prevalent subtype. Among NSCLC\npatients, approximately 32.3% have mutations in the epidermal growth factor\nreceptor (EGFR) gene. Osimertinib, a third-generation EGFR-tyrosine kinase\ninhibitor (TKI), has demonstrated remarkable efficacy in the treatment of NSCLC\npatients with activating and T790M resistance EGFR mutations. Despite its\nestablished efficacy, drug resistance poses a significant challenge for\npatients to fully benefit from osimertinib. The absence of a standard tool to\naccurately predict TKI resistance, including that of osimertinib, remains a\ncritical obstacle. To bridge this gap, in this study, we developed an\ninterpretable multimodal machine learning model designed to predict patient\nresistance to osimertinib among late-stage NSCLC patients with activating EGFR\nmutations, achieving a c-index of 0.82 on a multi-institutional dataset. This\nmachine learning model harnesses readily available data routinely collected\nduring patient visits and medical assessments to facilitate precision lung\ncancer management and informed treatment decisions. By integrating various data\ntypes such as histology images, next generation sequencing (NGS) data,\ndemographics data, and clinical records, our multimodal model can generate\nwell-informed recommendations. Our experiment results also demonstrated the\nsuperior performance of the multimodal model over single modality models\n(c-index 0.82 compared with 0.75 and 0.77), thus underscoring the benefit of\ncombining multiple modalities in patient outcome prediction.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.24165v1",
    "published_date": "2025-03-31 14:47:02 UTC",
    "updated_date": "2025-03-31 14:47:02 UTC"
  },
  {
    "arxiv_id": "2503.24150v1",
    "title": "Learning a Canonical Basis of Human Preferences from Binary Ratings",
    "authors": [
      "Kailas Vodrahalli",
      "Wei Wei",
      "James Zou"
    ],
    "abstract": "Recent advances in generative AI have been driven by alignment techniques\nsuch as reinforcement learning from human feedback (RLHF). RLHF and related\ntechniques typically involve constructing a dataset of binary or ranked choice\nhuman preferences and subsequently fine-tuning models to align with these\npreferences. This paper shifts the focus to understanding the preferences\nencoded in such datasets and identifying common human preferences. We find that\na small subset of 21 preference categories (selected from a set of nearly 5,000\ndistinct preferences) captures >89% of preference variation across individuals.\nThis small set of preferences is analogous to a canonical basis of human\npreferences, similar to established findings that characterize human variation\nin psychology or facial recognition studies. Through both synthetic and\nempirical evaluations, we confirm that our low-rank, canonical set of human\npreferences generalizes across the entire dataset and within specific topics.\nWe further demonstrate our preference basis' utility in model evaluation, where\nour preference categories offer deeper insights into model alignment, and in\nmodel training, where we show that fine-tuning on preference-defined subsets\nsuccessfully aligns the model accordingly.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.LG",
    "comment": "25 pages, 11 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.24150v1",
    "published_date": "2025-03-31 14:35:48 UTC",
    "updated_date": "2025-03-31 14:35:48 UTC"
  },
  {
    "arxiv_id": "2503.24145v1",
    "title": "Resonance: Drawing from Memories to Imagine Positive Futures through AI-Augmented Journaling",
    "authors": [
      "Wazeer Zulfikar",
      "Treyden Chiaravalloti",
      "Jocelyn Shen",
      "Rosalind Picard",
      "Pattie Maes"
    ],
    "abstract": "People inherently use experiences of their past while imagining their future,\na capability that plays a crucial role in mental health. Resonance is an\nAI-powered journaling tool designed to augment this ability by offering\nAI-generated, action-oriented suggestions for future activities based on the\nuser's own past memories. Suggestions are offered when a new memory is logged\nand are followed by a prompt for the user to imagine carrying out the\nsuggestion. In a two-week randomized controlled study (N=55), we found that\nusing Resonance significantly improved mental health outcomes, reducing the\nusers' PHQ8 scores, a measure of current depression, and increasing their daily\npositive affect, particularly when they would likely act on the suggestion.\nNotably, the effectiveness of the suggestions was higher when they were\npersonal, novel, and referenced the user's logged memories. Finally, through\nopen-ended feedback, we discuss the factors that encouraged or hindered the use\nof the tool.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "17 pages, 13 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.24145v1",
    "published_date": "2025-03-31 14:30:47 UTC",
    "updated_date": "2025-03-31 14:30:47 UTC"
  },
  {
    "arxiv_id": "2503.24130v1",
    "title": "Graph Neural Network-Based Predictive Modeling for Robotic Plaster Printing",
    "authors": [
      "Diego Machain Rivera",
      "Selen Ercan Jenny",
      "Ping Hsun Tsai",
      "Ena Lloret-Fritschi",
      "Luis Salamanca",
      "Fernando Perez-Cruz",
      "Konstantinos E. Tatsis"
    ],
    "abstract": "This work proposes a Graph Neural Network (GNN) modeling approach to predict\nthe resulting surface from a particle based fabrication process. The latter\nconsists of spray-based printing of cementitious plaster on a wall and is\nfacilitated with the use of a robotic arm. The predictions are computed using\nthe robotic arm trajectory features, such as position, velocity and direction,\nas well as the printing process parameters. The proposed approach, based on a\nparticle representation of the wall domain and the end effector, allows for the\nadoption of a graph-based solution. The GNN model consists of an\nencoder-processor-decoder architecture and is trained using data from\nlaboratory tests, while the hyperparameters are optimized by means of a\nBayesian scheme. The aim of this model is to act as a simulator of the printing\nprocess, and ultimately used for the generation of the robotic arm trajectory\nand the optimization of the printing parameters, towards the materialization of\nan autonomous plastering process. The performance of the proposed model is\nassessed in terms of the prediction error against unseen ground truth data,\nwhich shows its generality in varied scenarios, as well as in comparison with\nthe performance of an existing benchmark model. The results demonstrate a\nsignificant improvement over the benchmark model, with notably better\nperformance and enhanced error scaling across prediction steps.",
    "categories": [
      "cs.CE",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.CE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.24130v1",
    "published_date": "2025-03-31 14:15:00 UTC",
    "updated_date": "2025-03-31 14:15:00 UTC"
  },
  {
    "arxiv_id": "2504.01043v2",
    "title": "Are clinicians ethically obligated to disclose their use of medical machine learning systems to patients?",
    "authors": [
      "Joshua Hatherley"
    ],
    "abstract": "It is commonly accepted that clinicians are ethically obligated to disclose\ntheir use of medical machine learning systems to patients, and that failure to\ndo so would amount to a moral fault for which clinicians ought to be held\naccountable. Call this \"the disclosure thesis.\" Four main arguments have been,\nor could be, given to support the disclosure thesis in the ethics literature:\nthe risk-based argument, the rights-based argument, the materiality argument,\nand the autonomy argument. In this article, I argue that each of these four\narguments are unconvincing, and therefore, that the disclosure thesis ought to\nbe rejected. I suggest that mandating disclosure may also even risk harming\npatients by providing stakeholders with a way to avoid accountability for harm\nthat results from improper applications or uses of these systems.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "Journal of Medical Ethics, forthcoming 2024",
    "pdf_url": "http://arxiv.org/pdf/2504.01043v2",
    "published_date": "2025-03-31 14:12:18 UTC",
    "updated_date": "2025-04-04 11:35:58 UTC"
  },
  {
    "arxiv_id": "2504.00061v1",
    "title": "Evaluating the Feasibility and Accuracy of Large Language Models for Medical History-Taking in Obstetrics and Gynecology",
    "authors": [
      "Dou Liu",
      "Ying Long",
      "Sophia Zuoqiu",
      "Tian Tang",
      "Rong Yin"
    ],
    "abstract": "Effective physician-patient communications in pre-diagnostic environments,\nand most specifically in complex and sensitive medical areas such as\ninfertility, are critical but consume a lot of time and, therefore, cause\nclinic workflows to become inefficient. Recent advancements in Large Language\nModels (LLMs) offer a potential solution for automating conversational medical\nhistory-taking and improving diagnostic accuracy. This study evaluates the\nfeasibility and performance of LLMs in those tasks for infertility cases. An\nAI-driven conversational system was developed to simulate physician-patient\ninteractions with ChatGPT-4o and ChatGPT-4o-mini. A total of 70 real-world\ninfertility cases were processed, generating 420 diagnostic histories. Model\nperformance was assessed using F1 score, Differential Diagnosis (DDs) Accuracy,\nand Accuracy of Infertility Type Judgment (ITJ). ChatGPT-4o-mini outperformed\nChatGPT-4o in information extraction accuracy (F1 score: 0.9258 vs. 0.9029, p =\n0.045, d = 0.244) and demonstrated higher completeness in medical\nhistory-taking (97.58% vs. 77.11%), suggesting that ChatGPT-4o-mini is more\neffective in extracting detailed patient information, which is critical for\nimproving diagnostic accuracy. In contrast, ChatGPT-4o performed slightly\nbetter in differential diagnosis accuracy (2.0524 vs. 2.0048, p > 0.05). ITJ\naccuracy was higher in ChatGPT-4o-mini (0.6476 vs. 0.5905) but with lower\nconsistency (Cronbach's $\\alpha$ = 0.562), suggesting variability in\nclassification reliability. Both models demonstrated strong feasibility in\nautomating infertility history-taking, with ChatGPT-4o-mini excelling in\ncompleteness and extraction accuracy. In future studies, expert validation for\naccuracy and dependability in a clinical setting, AI model fine-tuning, and\nlarger datasets with a mix of cases of infertility have to be prioritized.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by IISE 2025 annual conference",
    "pdf_url": "http://arxiv.org/pdf/2504.00061v1",
    "published_date": "2025-03-31 14:09:53 UTC",
    "updated_date": "2025-03-31 14:09:53 UTC"
  },
  {
    "arxiv_id": "2503.24110v1",
    "title": "Grounding Agent Reasoning in Image Schemas: A Neurosymbolic Approach to Embodied Cognition",
    "authors": [
      "François Olivier",
      "Zied Bouraoui"
    ],
    "abstract": "Despite advances in embodied AI, agent reasoning systems still struggle to\ncapture the fundamental conceptual structures that humans naturally use to\nunderstand and interact with their environment. To address this, we propose a\nnovel framework that bridges embodied cognition theory and agent systems by\nleveraging a formal characterization of image schemas, which are defined as\nrecurring patterns of sensorimotor experience that structure human cognition.\nBy customizing LLMs to translate natural language descriptions into formal\nrepresentations based on these sensorimotor patterns, we will be able to create\na neurosymbolic system that grounds the agent's understanding in fundamental\nconceptual structures. We argue that such an approach enhances both efficiency\nand interpretability while enabling more intuitive human-agent interactions\nthrough shared embodied understanding.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.24110v1",
    "published_date": "2025-03-31 14:01:39 UTC",
    "updated_date": "2025-03-31 14:01:39 UTC"
  },
  {
    "arxiv_id": "2503.24108v2",
    "title": "PolypSegTrack: Unified Foundation Model for Colonoscopy Video Analysis",
    "authors": [
      "Anwesa Choudhuri",
      "Zhongpai Gao",
      "Meng Zheng",
      "Benjamin Planche",
      "Terrence Chen",
      "Ziyan Wu"
    ],
    "abstract": "Early detection, accurate segmentation, classification and tracking of polyps\nduring colonoscopy are critical for preventing colorectal cancer. Many existing\ndeep-learning-based methods for analyzing colonoscopic videos either require\ntask-specific fine-tuning, lack tracking capabilities, or rely on\ndomain-specific pre-training. In this paper, we introduce PolypSegTrack, a\nnovel foundation model that jointly addresses polyp detection, segmentation,\nclassification and unsupervised tracking in colonoscopic videos. Our approach\nleverages a novel conditional mask loss, enabling flexible training across\ndatasets with either pixel-level segmentation masks or bounding box\nannotations, allowing us to bypass task-specific fine-tuning. Our unsupervised\ntracking module reliably associates polyp instances across frames using object\nqueries, without relying on any heuristics. We leverage a robust vision\nfoundation model backbone that is pre-trained unsupervisedly on natural images,\nthereby removing the need for domain-specific pre-training. Extensive\nexperiments on multiple polyp benchmarks demonstrate that our method\nsignificantly outperforms existing state-of-the-art approaches in detection,\nsegmentation, classification, and tracking.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.24108v2",
    "published_date": "2025-03-31 14:00:21 UTC",
    "updated_date": "2025-04-02 19:58:56 UTC"
  },
  {
    "arxiv_id": "2504.02860v1",
    "title": "Computer Vision and Deep Learning for 4D Augmented Reality",
    "authors": [
      "Karthik Shivashankar"
    ],
    "abstract": "The prospect of 4D video in Extended Reality (XR) platform is huge and\nexciting, it opens a whole new way of human computer interaction and the way we\nperceive the reality and consume multimedia. In this thesis, we have shown that\nfeasibility of rendering 4D video in Microsoft mixed reality platform. This\nenables us to port any 3D performance capture from CVSSP into XR product like\nthe HoloLens device with relative ease. However, if the 3D model is too complex\nand is made up of millions of vertices, the data bandwidth required to port the\nmodel is a severe limitation with the current hardware and communication\nsystem. Therefore, in this project we have also developed a compact\nrepresentation of both shape and appearance of the 4d video sequence using deep\nlearning models to effectively learn the compact representation of 4D video\nsequence and reconstruct it without affecting the shape and appearance of the\nvideo sequence.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "My Master Thesis , University of Surrey 2019",
    "pdf_url": "http://arxiv.org/pdf/2504.02860v1",
    "published_date": "2025-03-31 13:38:26 UTC",
    "updated_date": "2025-03-31 13:38:26 UTC"
  },
  {
    "arxiv_id": "2503.24062v1",
    "title": "Artificial Conversations, Real Results: Fostering Language Detection with Synthetic Data",
    "authors": [
      "Fatemeh Mohammadi",
      "Tommaso Romano",
      "Samira Maghool",
      "Paolo Ceravolo"
    ],
    "abstract": "Collecting high-quality training data is essential for fine-tuning Large\nLanguage Models (LLMs). However, acquiring such data is often costly and\ntime-consuming, especially for non-English languages such as Italian. Recently,\nresearchers have begun to explore the use of LLMs to generate synthetic\ndatasets as a viable alternative. This study proposes a pipeline for generating\nsynthetic data and a comprehensive approach for investigating the factors that\ninfluence the validity of synthetic data generated by LLMs by examining how\nmodel performance is affected by metrics such as prompt strategy, text length\nand target position in a specific task, i.e. inclusive language detection in\nItalian job advertisements. Our results show that, in most cases and across\ndifferent metrics, the fine-tuned models trained on synthetic data consistently\noutperformed other models on both real and synthetic test datasets. The study\ndiscusses the practical implications and limitations of using synthetic data\nfor language detection tasks with LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.24062v1",
    "published_date": "2025-03-31 13:22:34 UTC",
    "updated_date": "2025-03-31 13:22:34 UTC"
  },
  {
    "arxiv_id": "2503.24047v2",
    "title": "Towards Scientific Intelligence: A Survey of LLM-based Scientific Agents",
    "authors": [
      "Shuo Ren",
      "Pu Jian",
      "Zhenjiang Ren",
      "Chunlin Leng",
      "Can Xie",
      "Jiajun Zhang"
    ],
    "abstract": "As scientific research becomes increasingly complex, innovative tools are\nneeded to manage vast data, facilitate interdisciplinary collaboration, and\naccelerate discovery. Large language models (LLMs) are now evolving into\nLLM-based scientific agents that automate critical tasks, ranging from\nhypothesis generation and experiment design to data analysis and simulation.\nUnlike general-purpose LLMs, these specialized agents integrate domain-specific\nknowledge, advanced tool sets, and robust validation mechanisms, enabling them\nto handle complex data types, ensure reproducibility, and drive scientific\nbreakthroughs. This survey provides a focused review of the architectures,\ndesign, benchmarks, applications, and ethical considerations surrounding\nLLM-based scientific agents. We highlight why they differ from general agents\nand the ways in which they advance research across various scientific fields.\nBy examining their development and challenges, this survey offers a\ncomprehensive roadmap for researchers and practitioners to harness these agents\nfor more efficient, reliable, and ethically sound scientific discovery.",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "34 pages, 10 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.24047v2",
    "published_date": "2025-03-31 13:11:28 UTC",
    "updated_date": "2025-04-17 07:26:34 UTC"
  },
  {
    "arxiv_id": "2503.24028v1",
    "title": "Pay More Attention to the Robustness of Prompt for Instruction Data Mining",
    "authors": [
      "Qiang Wang",
      "Dawei Feng",
      "Xu Zhang",
      "Ao Shen",
      "Yang Xu",
      "Bo Ding",
      "Huaimin Wang"
    ],
    "abstract": "Instruction tuning has emerged as a paramount method for tailoring the\nbehaviors of LLMs. Recent work has unveiled the potential for LLMs to achieve\nhigh performance through fine-tuning with a limited quantity of high-quality\ninstruction data. Building upon this approach, we further explore the impact of\nprompt's robustness on the selection of high-quality instruction data. This\npaper proposes a pioneering framework of high-quality online instruction data\nmining for instruction tuning, focusing on the impact of prompt's robustness on\nthe data mining process. Our notable innovation, is to generate the adversarial\ninstruction data by conducting the attack for the prompt of online instruction\ndata. Then, we introduce an Adversarial Instruction-Following Difficulty metric\nto measure how much help the adversarial instruction data can provide to the\ngeneration of the corresponding response. Apart from it, we propose a novel\nAdversarial Instruction Output Embedding Consistency approach to select\nhigh-quality online instruction data. We conduct extensive experiments on two\nbenchmark datasets to assess the performance. The experimental results serve to\nunderscore the effectiveness of our proposed two methods. Moreover, the results\nunderscore the critical practical significance of considering prompt's\nrobustness.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.24028v1",
    "published_date": "2025-03-31 12:53:08 UTC",
    "updated_date": "2025-03-31 12:53:08 UTC"
  },
  {
    "arxiv_id": "2503.24016v1",
    "title": "Bayesian Predictive Coding",
    "authors": [
      "Alexander Tschantz",
      "Magnus Koudahl",
      "Hampus Linander",
      "Lancelot Da Costa",
      "Conor Heins",
      "Jeff Beck",
      "Christopher Buckley"
    ],
    "abstract": "Predictive coding (PC) is an influential theory of information processing in\nthe brain, providing a biologically plausible alternative to backpropagation.\nIt is motivated in terms of Bayesian inference, as hidden states and parameters\nare optimised via gradient descent on variational free energy. However,\nimplementations of PC rely on maximum \\textit{a posteriori} (MAP) estimates of\nhidden states and maximum likelihood (ML) estimates of parameters, limiting\ntheir ability to quantify epistemic uncertainty. In this work, we investigate a\nBayesian extension to PC that estimates a posterior distribution over network\nparameters. This approach, termed Bayesian Predictive coding (BPC), preserves\nthe locality of PC and results in closed-form Hebbian weight updates. Compared\nto PC, our BPC algorithm converges in fewer epochs in the full-batch setting\nand remains competitive in the mini-batch setting. Additionally, we demonstrate\nthat BPC offers uncertainty quantification comparable to existing methods in\nBayesian deep learning, while also improving convergence properties. Together,\nthese results suggest that BPC provides a biologically plausible method for\nBayesian learning in the brain, as well as an attractive approach to\nuncertainty quantification in deep learning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.24016v1",
    "published_date": "2025-03-31 12:40:50 UTC",
    "updated_date": "2025-03-31 12:40:50 UTC"
  },
  {
    "arxiv_id": "2503.24009v1",
    "title": "Learning 3D-Gaussian Simulators from RGB Videos",
    "authors": [
      "Mikel Zhobro",
      "Andreas René Geist",
      "Georg Martius"
    ],
    "abstract": "Learning physics simulations from video data requires maintaining spatial and\ntemporal consistency, a challenge often addressed with strong inductive biases\nor ground-truth 3D information -- limiting scalability and generalization. We\nintroduce 3DGSim, a 3D physics simulator that learns object dynamics end-to-end\nfrom multi-view RGB videos. It encodes images into a 3D Gaussian particle\nrepresentation, propagates dynamics via a transformer, and renders frames using\n3D Gaussian splatting. By jointly training inverse rendering with a dynamics\ntransformer using a temporal encoding and merging layer, 3DGSimembeds physical\nproperties into point-wise latent vectors without enforcing explicit\nconnectivity constraints. This enables the model to capture diverse physical\nbehaviors, from rigid to elastic and cloth-like interactions, along with\nrealistic lighting effects that also generalize to unseen multi-body\ninteractions and novel scene edits.",
    "categories": [
      "cs.GR",
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.GR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.24009v1",
    "published_date": "2025-03-31 12:33:59 UTC",
    "updated_date": "2025-03-31 12:33:59 UTC"
  },
  {
    "arxiv_id": "2503.24008v1",
    "title": "H2VU-Benchmark: A Comprehensive Benchmark for Hierarchical Holistic Video Understanding",
    "authors": [
      "Qi Wu",
      "Quanlong Zheng",
      "Yanhao Zhang",
      "Junlin Xie",
      "Jinguo Luo",
      "Kuo Wang",
      "Peng Liu",
      "Qingsong Xie",
      "Ru Zhen",
      "Haonan Lu",
      "Zhenyu Yang"
    ],
    "abstract": "With the rapid development of multimodal models, the demand for assessing\nvideo understanding capabilities has been steadily increasing. However,\nexisting benchmarks for evaluating video understanding exhibit significant\nlimitations in coverage, task diversity, and scene adaptability. These\nshortcomings hinder the accurate assessment of models' comprehensive video\nunderstanding capabilities. To tackle this challenge, we propose a hierarchical\nand holistic video understanding (H2VU) benchmark designed to evaluate both\ngeneral video and online streaming video comprehension. This benchmark\ncontributes three key features:\n  Extended video duration: Spanning videos from brief 3-second clips to\ncomprehensive 1.5-hour recordings, thereby bridging the temporal gaps found in\ncurrent benchmarks. Comprehensive assessment tasks: Beyond traditional\nperceptual and reasoning tasks, we have introduced modules for\ncountercommonsense comprehension and trajectory state tracking. These additions\ntest the models' deep understanding capabilities beyond mere prior knowledge.\nEnriched video data: To keep pace with the rapid evolution of current AI\nagents, we have expanded first-person streaming video datasets. This expansion\nallows for the exploration of multimodal models' performance in understanding\nstreaming videos from a first-person perspective. Extensive results from H2VU\nreveal that existing multimodal large language models (MLLMs) possess\nsubstantial potential for improvement in our newly proposed evaluation tasks.\nWe expect that H2VU will facilitate advancements in video understanding\nresearch by offering a comprehensive and in-depth analysis of MLLMs.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.24008v1",
    "published_date": "2025-03-31 12:32:51 UTC",
    "updated_date": "2025-03-31 12:32:51 UTC"
  },
  {
    "arxiv_id": "2503.24007v1",
    "title": "CITRAS: Covariate-Informed Transformer for Time Series Forecasting",
    "authors": [
      "Yosuke Yamaguchi",
      "Issei Suemitsu",
      "Wenpeng Wei"
    ],
    "abstract": "Covariates play an indispensable role in practical time series forecasting,\noffering rich context from the past and sometimes extending into the future.\nHowever, their availability varies depending on the scenario, and situations\noften involve multiple target variables simultaneously. Moreover, the\ncross-variate dependencies between them are multi-granular, with some\ncovariates having a short-term impact on target variables and others showing\nlong-term correlations. This heterogeneity and the intricate dependencies\narising in covariate-informed forecasting present significant challenges to\nexisting deep models. To address these issues, we propose CITRAS, a patch-based\nTransformer that flexibly leverages multiple targets and covariates covering\nboth the past and the future forecasting horizon. While preserving the strong\nautoregressive capabilities of the canonical Transformer, CITRAS introduces two\nnovel mechanisms in patch-wise cross-variate attention: Key-Value (KV) Shift\nand Attention Score Smoothing. KV Shift seamlessly incorporates future known\ncovariates into the forecasting of target variables based on their concurrent\ndependencies. Additionally, Attention Score Smoothing transforms locally\naccurate patch-wise cross-variate dependencies into global variate-level\ndependencies by smoothing the past series of attention scores. Experimentally,\nCITRAS achieves state-of-the-art performance in both covariate-informed and\nmultivariate forecasting, demonstrating its versatile ability to leverage\ncross-variate dependency for improved forecasting accuracy.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.24007v1",
    "published_date": "2025-03-31 12:32:23 UTC",
    "updated_date": "2025-03-31 12:32:23 UTC"
  },
  {
    "arxiv_id": "2503.24000v1",
    "title": "Rethinking Key-Value Cache Compression Techniques for Large Language Model Serving",
    "authors": [
      "Wei Gao",
      "Xinyu Zhou",
      "Peng Sun",
      "Tianwei Zhang",
      "Yonggang Wen"
    ],
    "abstract": "Key-Value cache (\\texttt{KV} \\texttt{cache}) compression has emerged as a\npromising technique to optimize Large Language Model (LLM) serving. It\nprimarily decreases the memory consumption of \\texttt{KV} \\texttt{cache} to\nreduce the computation cost. Despite the development of many compression\nalgorithms, their applications in production environments are still not\nprevalent. In this paper, we revisit mainstream \\texttt{KV} \\texttt{cache}\ncompression solutions from a practical perspective. Our contributions are\nthree-fold. First, we comprehensively review existing algorithmic designs and\nbenchmark studies for \\texttt{KV} \\texttt{cache} compression and identify\nmissing pieces in their performance measurement, which could hinder their\nadoption in practice. Second, we empirically evaluate representative\n\\texttt{KV} \\texttt{cache} compression methods to uncover two key issues that\naffect the computational efficiency: (1) while compressing \\texttt{KV}\n\\texttt{cache} can reduce memory consumption, current implementations (e.g.,\nFlashAttention, PagedAttention) do not optimize for production-level LLM\nserving, resulting in suboptimal throughput performance; (2) compressing\n\\texttt{KV} \\texttt{cache} may lead to longer outputs, resulting in increased\nend-to-end latency. We further investigate the accuracy performance of\nindividual samples rather than the overall performance, revealing the intrinsic\nlimitations in \\texttt{KV} \\texttt{cache} compression when handling specific\nLLM tasks. Third, we provide tools to shed light on future \\texttt{KV}\n\\texttt{cache} compression studies and facilitate their practical deployment in\nproduction. They are open-sourced in\n\\href{https://github.com/LLMkvsys/rethink-kv-compression}{https://github.com/LLMkvsys/rethink-kv-compression}.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "21 pages, 18 figures, published to MLSys2025",
    "pdf_url": "http://arxiv.org/pdf/2503.24000v1",
    "published_date": "2025-03-31 12:23:31 UTC",
    "updated_date": "2025-03-31 12:23:31 UTC"
  },
  {
    "arxiv_id": "2504.03726v1",
    "title": "Detecting Malicious AI Agents Through Simulated Interactions",
    "authors": [
      "Yulu Pi",
      "Ella Bettison",
      "Anna Becker"
    ],
    "abstract": "This study investigates malicious AI Assistants' manipulative traits and\nwhether the behaviours of malicious AI Assistants can be detected when\ninteracting with human-like simulated users in various decision-making\ncontexts. We also examine how interaction depth and ability of planning\ninfluence malicious AI Assistants' manipulative strategies and effectiveness.\nUsing a controlled experimental design, we simulate interactions between AI\nAssistants (both benign and deliberately malicious) and users across eight\ndecision-making scenarios of varying complexity and stakes. Our methodology\nemploys two state-of-the-art language models to generate interaction data and\nimplements Intent-Aware Prompting (IAP) to detect malicious AI Assistants. The\nfindings reveal that malicious AI Assistants employ domain-specific\npersona-tailored manipulation strategies, exploiting simulated users'\nvulnerabilities and emotional triggers. In particular, simulated users\ndemonstrate resistance to manipulation initially, but become increasingly\nvulnerable to malicious AI Assistants as the depth of the interaction\nincreases, highlighting the significant risks associated with extended\nengagement with potentially manipulative systems. IAP detection methods achieve\nhigh precision with zero false positives but struggle to detect many malicious\nAI Assistants, resulting in high false negative rates. These findings\nunderscore critical risks in human-AI interactions and highlight the need for\nrobust, context-sensitive safeguards against manipulative AI behaviour in\nincreasingly autonomous decision-support systems.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.03726v1",
    "published_date": "2025-03-31 12:22:24 UTC",
    "updated_date": "2025-03-31 12:22:24 UTC"
  },
  {
    "arxiv_id": "2504.00060v2",
    "title": "CF-CAM: Cluster Filter Class Activation Mapping for Reliable Gradient-Based Interpretability",
    "authors": [
      "Hongjie He",
      "Xu Pan",
      "Yudong Yao"
    ],
    "abstract": "As deep learning continues to advance, the transparency of neural network\ndecision-making remains a critical challenge, limiting trust and applicability\nin high-stakes domains. Class Activation Mapping (CAM) techniques have emerged\nas a key approach toward visualizing model decisions, yet existing methods face\ninherent trade-offs. Gradient-based CAM variants suffer from sensitivity to\ngradient perturbations due to gradient noise, leading to unstable and\nunreliable explanations. Conversely, gradient-free approaches mitigate gradient\ninstability but incur significant computational overhead and inference latency.\nTo address these limitations, we propose a Cluster Filter Class Activation Map\n(CF-CAM) technique, a novel framework that reintroduces gradient-based\nweighting while enhancing robustness against gradient noise. CF-CAM utilizes\nhierarchical importance weighting strategy to balance discriminative feature\npreservation and noise elimination. A density-aware channel clustering method\nvia Density-Based Spatial Clustering of Applications with Noise (DBSCAN) groups\nsemantically relevant feature channels and discard noise-prone activations.\nAdditionally, cluster-conditioned gradient filtering leverages Gaussian filters\nto refine gradient signals, preserving edge-aware localization while\nsuppressing noise impact. Experiment results demonstrate that CF-CAM achieves\nsuperior interpretability performance while enhancing computational efficiency,\noutperforming state-of-the-art CAM methods in faithfulness and robustness. By\neffectively mitigating gradient instability without excessive computational\ncost, CF-CAM provides a competitive solution for enhancing the interpretability\nof deep neural networks in critical applications such as autonomous driving and\nmedical diagnosis.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.00060v2",
    "published_date": "2025-03-31 12:20:59 UTC",
    "updated_date": "2025-04-23 13:49:48 UTC"
  },
  {
    "arxiv_id": "2503.23993v1",
    "title": "DenseFormer: Learning Dense Depth Map from Sparse Depth and Image via Conditional Diffusion Model",
    "authors": [
      "Ming Yuan",
      "Sichao Wang",
      "Chuang Zhang",
      "Lei He",
      "Qing Xu",
      "Jianqiang Wang"
    ],
    "abstract": "The depth completion task is a critical problem in autonomous driving,\ninvolving the generation of dense depth maps from sparse depth maps and RGB\nimages. Most existing methods employ a spatial propagation network to\niteratively refine the depth map after obtaining an initial dense depth. In\nthis paper, we propose DenseFormer, a novel method that integrates the\ndiffusion model into the depth completion task. By incorporating the denoising\nmechanism of the diffusion model, DenseFormer generates the dense depth map by\nprogressively refining an initial random depth distribution through multiple\niterations. We propose a feature extraction module that leverages a feature\npyramid structure, along with multi-layer deformable attention, to effectively\nextract and integrate features from sparse depth maps and RGB images, which\nserve as the guiding condition for the diffusion process. Additionally, this\npaper presents a depth refinement module that applies multi-step iterative\nrefinement across various ranges to the dense depth results generated by the\ndiffusion process. The module utilizes image features enriched with multi-scale\ninformation and sparse depth input to further enhance the accuracy of the\npredicted depth map. Extensive experiments on the KITTI outdoor scene dataset\ndemonstrate that DenseFormer outperforms classical depth completion methods.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.23993v1",
    "published_date": "2025-03-31 12:11:01 UTC",
    "updated_date": "2025-03-31 12:11:01 UTC"
  },
  {
    "arxiv_id": "2503.23989v1",
    "title": "Rubric Is All You Need: Enhancing LLM-based Code Evaluation With Question-Specific Rubrics",
    "authors": [
      "Aditya Pathak",
      "Rachit Gandhi",
      "Vaibhav Uttam",
      "Devansh",
      "Yashwanth Nakka",
      "Aaryan Raj Jindal",
      "Pratyush Ghosh",
      "Arnav Ramamoorthy",
      "Shreyash Verma",
      "Aditya Mittal",
      "Aashna Ased",
      "Chirag Khatri",
      "Jagat Sesh Challa",
      "Dhruv Kumar"
    ],
    "abstract": "Since the disruption in LLM technology brought about by the release of GPT-3\nand ChatGPT, LLMs have shown remarkable promise in programming-related tasks.\nWhile code generation remains a popular field of research, code evaluation\nusing LLMs remains a problem with no conclusive solution. In this paper, we\nfocus on LLM-based code evaluation and attempt to fill in the existing gaps. We\npropose multi-agentic novel approaches using question-specific rubrics tailored\nto the problem statement, arguing that these perform better for logical\nassessment than the existing approaches that use question-agnostic rubrics. To\naddress the lack of suitable evaluation datasets, we introduce two datasets: a\nData Structures and Algorithms dataset containing 150 student submissions from\na popular Data Structures and Algorithms practice website, and an Object\nOriented Programming dataset comprising 80 student submissions from\nundergraduate computer science courses. In addition to using standard metrics\n(Spearman Correlation, Cohen's Kappa), we additionally propose a new metric\ncalled as Leniency, which quantifies evaluation strictness relative to expert\nassessment. Our comprehensive analysis demonstrates that question-specific\nrubrics significantly enhance logical assessment of code in educational\nsettings, providing better feedback aligned with instructional goals beyond\nmere syntactic correctness.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "Under Review",
    "pdf_url": "http://arxiv.org/pdf/2503.23989v1",
    "published_date": "2025-03-31 11:59:43 UTC",
    "updated_date": "2025-03-31 11:59:43 UTC"
  },
  {
    "arxiv_id": "2503.23988v1",
    "title": "Deep Learning Model Deployment in Multiple Cloud Providers: an Exploratory Study Using Low Computing Power Environments",
    "authors": [
      "Elayne Lemos",
      "Rodrigo Oliveira",
      "Jairson Rodrigues",
      "Rosalvo F. Oliveira Neto"
    ],
    "abstract": "The deployment of Machine Learning models at cloud have grown by tech\ncompanies. Hardware requirements are higher when these models involve Deep\nLearning (DL) techniques and the cloud providers' costs may be a barrier. We\nexplore deploying DL models using for experiments the GECToR model, a DL\nsolution for Grammatical Error Correction, across three of the major cloud\nplatforms (AWS, Google Cloud, Azure). We evaluate real-time latency, hardware\nusage and cost at each cloud provider by 7 execution environments with 10\nexperiments reproduced. We found that while GPUs excel in performance, they had\nan average cost 300% higher than solutions without GPU. Our analysis also\nidentifies that processor cache size is crucial for cost-effective CPU\ndeployments, enabling over 50% of cost reduction compared to GPUs. This study\ndemonstrates the feasibility and affordability of cloud-based DL inference\nsolutions without GPUs, benefiting resource-constrained users like startups.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.PF",
      "68T07, 68U01",
      "C.4; I.2.0; B.8.2"
    ],
    "primary_category": "cs.DC",
    "comment": "15 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.23988v1",
    "published_date": "2025-03-31 11:58:37 UTC",
    "updated_date": "2025-03-31 11:58:37 UTC"
  },
  {
    "arxiv_id": "2503.23982v2",
    "title": "Deep Neural Nets as Hamiltonians",
    "authors": [
      "Mike Winer",
      "Boris Hanin"
    ],
    "abstract": "Neural networks are complex functions of both their inputs and parameters.\nMuch prior work in deep learning theory analyzes the distribution of network\noutputs at a fixed a set of inputs (e.g. a training dataset) over random\ninitializations of the network parameters. The purpose of this article is to\nconsider the opposite situation: we view a randomly initialized Multi-Layer\nPerceptron (MLP) as a Hamiltonian over its inputs. For typical realizations of\nthe network parameters, we study the properties of the energy landscape induced\nby this Hamiltonian, focusing on the structure of near-global minimum in the\nlimit of infinite width. Specifically, we use the replica trick to perform an\nexact analytic calculation giving the entropy (log volume of space) at a given\nenergy. We further derive saddle point equations that describe the overlaps\nbetween inputs sampled iid from the Gibbs distribution induced by the random\nMLP. For linear activations we solve these saddle point equations exactly. But\nwe also solve them numerically for a variety of depths and activation\nfunctions, including $\\tanh, \\sin, \\text{ReLU}$, and shaped non-linearities. We\nfind even at infinite width a rich range of behaviors. For some\nnon-linearities, such as $\\sin$, for instance, we find that the landscapes of\nrandom MLPs exhibit full replica symmetry breaking, while shallow $\\tanh$ and\nReLU networks or deep shaped MLPs are instead replica symmetric.",
    "categories": [
      "cond-mat.dis-nn",
      "cond-mat.stat-mech",
      "cs.AI",
      "cs.LG",
      "math.PR"
    ],
    "primary_category": "cond-mat.dis-nn",
    "comment": "19+7 pages",
    "pdf_url": "http://arxiv.org/pdf/2503.23982v2",
    "published_date": "2025-03-31 11:51:10 UTC",
    "updated_date": "2025-04-05 09:41:03 UTC"
  },
  {
    "arxiv_id": "2503.23972v1",
    "title": "Noise-based reward-modulated learning",
    "authors": [
      "Jesús García Fernández",
      "Nasir Ahmad",
      "Marcel van Gerven"
    ],
    "abstract": "Recent advances in reinforcement learning (RL) have led to significant\nimprovements in task performance. However, training neural networks in an RL\nregime is typically achieved in combination with backpropagation, limiting\ntheir applicability in resource-constrained environments or when using\nnon-differentiable neural networks. While noise-based alternatives like\nreward-modulated Hebbian learning (RMHL) have been proposed, their performance\nhas remained limited, especially in scenarios with delayed rewards, which\nrequire retrospective credit assignment over time. Here, we derive a novel\nnoise-based learning rule that addresses these challenges. Our approach\ncombines directional derivative theory with Hebbian-like updates to enable\nefficient, gradient-free learning in RL. It features stochastic noisy neurons\nwhich can approximate gradients, and produces local synaptic updates modulated\nby a global reward signal. Drawing on concepts from neuroscience, our method\nuses reward prediction error as its optimization target to generate\nincreasingly advantageous behavior, and incorporates an eligibility trace to\nfacilitate temporal credit assignment in environments with delayed rewards. Its\nformulation relies on local information alone, making it compatible with\nimplementations in neuromorphic hardware. Experimental validation shows that\nour approach significantly outperforms RMHL and is competitive with BP-based\nbaselines, highlighting the promise of noise-based, biologically inspired\nlearning for low-power and real-time applications.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.23972v1",
    "published_date": "2025-03-31 11:35:23 UTC",
    "updated_date": "2025-03-31 11:35:23 UTC"
  },
  {
    "arxiv_id": "2503.23956v1",
    "title": "AirCache: Activating Inter-modal Relevancy KV Cache Compression for Efficient Large Vision-Language Model Inference",
    "authors": [
      "Kai Huang",
      "Hao Zou",
      "Bochen Wang",
      "Ye Xi",
      "Zhen Xie",
      "Hao Wang"
    ],
    "abstract": "Recent advancements in Large Visual Language Models (LVLMs) have gained\nsignificant attention due to their remarkable reasoning capabilities and\nproficiency in generalization. However, processing a large number of visual\ntokens and generating long-context outputs impose substantial computational\noverhead, leading to excessive demands for key-value (KV) cache. To address\nthis critical bottleneck, we propose AirCache, a novel KV cache compression\nmethod aimed at accelerating LVLMs inference. This work systematically\ninvestigates the correlations between visual and textual tokens within the\nattention mechanisms of LVLMs. Our empirical analysis reveals considerable\nredundancy in cached visual tokens, wherein strategically eliminating these\ntokens preserves model performance while significantly accelerating context\ngeneration. Inspired by these findings, we introduce an elite observation\nwindow for assessing the importance of visual components in the KV cache,\nfocusing on stable inter-modal relevancy modeling with enhanced\nmulti-perspective consistency. Additionally, we develop an adaptive layer-wise\nbudget allocation strategy that capitalizes on the strength and skewness of\ntoken importance distribution, showcasing superior efficiency compared to\nuniform allocation. Comprehensive evaluations across multiple LVLMs and\nbenchmarks demonstrate that our method achieves comparable performance to the\nfull cache while retaining only 10% of visual KV cache, thereby reducing\ndecoding latency by 29% to 66% across various batch size and prompt length of\ninputs. Notably, as cache retention rates decrease, our method exhibits\nincreasing performance advantages over existing approaches.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.23956v1",
    "published_date": "2025-03-31 11:13:18 UTC",
    "updated_date": "2025-03-31 11:13:18 UTC"
  },
  {
    "arxiv_id": "2503.23948v1",
    "title": "AI2Agent: An End-to-End Framework for Deploying AI Projects as Autonomous Agents",
    "authors": [
      "Jiaxiang Chen",
      "Jingwei Shi",
      "Lei Gan",
      "Jiale Zhang",
      "Qingyu Zhang",
      "Dongqian Zhang",
      "Xin Pang",
      "Zhucong Li",
      "Yinghui Xu"
    ],
    "abstract": "As AI technology advances, it is driving innovation across industries,\nincreasing the demand for scalable AI project deployment. However, deployment\nremains a critical challenge due to complex environment configurations,\ndependency conflicts, cross-platform adaptation, and debugging difficulties,\nwhich hinder automation and adoption. This paper introduces AI2Agent, an\nend-to-end framework that automates AI project deployment through\nguideline-driven execution, self-adaptive debugging, and case \\& solution\naccumulation. AI2Agent dynamically analyzes deployment challenges, learns from\npast cases, and iteratively refines its approach, significantly reducing human\nintervention. To evaluate its effectiveness, we conducted experiments on 30 AI\ndeployment cases, covering TTS, text-to-image generation, image editing, and\nother AI applications. Results show that AI2Agent significantly reduces\ndeployment time and improves success rates. The code and demo video are now\npublicly accessible.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.23948v1",
    "published_date": "2025-03-31 10:58:34 UTC",
    "updated_date": "2025-03-31 10:58:34 UTC"
  },
  {
    "arxiv_id": "2503.23934v1",
    "title": "Green MLOps to Green GenOps: An Empirical Study of Energy Consumption in Discriminative and Generative AI Operations",
    "authors": [
      "Adrián Sánchez-Mompó",
      "Ioannis Mavromatis",
      "Peizheng Li",
      "Konstantinos Katsaros",
      "Aftab Khan"
    ],
    "abstract": "This study presents an empirical investigation into the energy consumption of\nDiscriminative and Generative AI models within real-world MLOps pipelines. For\nDiscriminative models, we examine various architectures and hyperparameters\nduring training and inference and identify energy-efficient practices. For\nGenerative AI, Large Language Models (LLMs) are assessed, focusing primarily on\nenergy consumption across different model sizes and varying service requests.\nOur study employs software-based power measurements, ensuring ease of\nreplication across diverse configurations, models, and datasets. We analyse\nmultiple models and hardware setups to uncover correlations among various\nmetrics, identifying key contributors to energy consumption. The results\nindicate that for Discriminative models, optimising architectures,\nhyperparameters, and hardware can significantly reduce energy consumption\nwithout sacrificing performance. For LLMs, energy efficiency depends on\nbalancing model size, reasoning complexity, and request-handling capacity, as\nlarger models do not necessarily consume more energy when utilisation remains\nlow. This analysis provides practical guidelines for designing green and\nsustainable ML operations, emphasising energy consumption and carbon footprint\nreductions while maintaining performance. This paper can serve as a benchmark\nfor accurately estimating total energy use across different types of AI models.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Published to MDPI Information - Artificial Intelligence Section",
    "pdf_url": "http://arxiv.org/pdf/2503.23934v1",
    "published_date": "2025-03-31 10:28:04 UTC",
    "updated_date": "2025-03-31 10:28:04 UTC"
  },
  {
    "arxiv_id": "2503.23923v1",
    "title": "What the F*ck Is Artificial General Intelligence?",
    "authors": [
      "Michael Timothy Bennett"
    ],
    "abstract": "Artificial general intelligence (AGI) is an established field of research.\nYet Melanie Mitchell and others have questioned if the term still has meaning.\nAGI has been subject to so much hype and speculation it has become something of\na Rorschach test. Mitchell points out that the debate will only be settled\nthrough long term, scientific investigation. To that end here is a short,\naccessible and provocative overview of AGI. I compare definitions of\nintelligence, settling on intelligence in terms of adaptation and AGI as an\nartificial scientist. Taking my queue from Sutton's Bitter Lesson I describe\ntwo foundational tools used to build adaptive systems: search and\napproximation. I compare pros, cons, hybrids and architectures like o3,\nAlphaGo, AERA, NARS and Hyperon. I then discuss overall meta-approaches to\nmaking systems behave more intelligently. I divide them into scale-maxing,\nsimp-maxing, w-maxing based on the Bitter Lesson, Ockham's and Bennett's\nRazors. These maximise resources, simplicity of form, and the weakness of\nconstraints on functionality. I discuss examples including AIXI, the free\nenergy principle and The Embiggening of language models. I conclude that though\nscale-maxed approximation dominates, AGI will be a fusion of tools and\nmeta-approaches. The Embiggening was enabled by improvements in hardware. Now\nthe bottlenecks are sample and energy efficiency.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Preprint; 10 pages;",
    "pdf_url": "http://arxiv.org/pdf/2503.23923v1",
    "published_date": "2025-03-31 10:15:37 UTC",
    "updated_date": "2025-03-31 10:15:37 UTC"
  },
  {
    "arxiv_id": "2504.00058v2",
    "title": "GAL-MAD: Towards Explainable Anomaly Detection in Microservice Applications Using Graph Attention Networks",
    "authors": [
      "Lahiru Akmeemana",
      "Chamodya Attanayake",
      "Husni Faiz",
      "Sandareka Wickramanayake"
    ],
    "abstract": "The transition to microservices has revolutionized software architectures,\noffering enhanced scalability and modularity. However, the distributed and\ndynamic nature of microservices introduces complexities in ensuring system\nreliability, making anomaly detection crucial for maintaining performance and\nfunctionality. Anomalies stemming from network and performance issues must be\nswiftly identified and addressed. Existing anomaly detection techniques often\nrely on statistical models or machine learning methods that struggle with the\nhigh-dimensional, interdependent data inherent in microservice applications.\nCurrent techniques and available datasets predominantly focus on system traces\nand logs, limiting their ability to support advanced detection models. This\npaper addresses these gaps by introducing the RS-Anomic dataset generated using\nthe open-source RobotShop microservice application. The dataset captures\nmultivariate performance metrics and response times under normal and anomalous\nconditions, encompassing ten types of anomalies. We propose a novel anomaly\ndetection model called Graph Attention and LSTM-based Microservice Anomaly\nDetection (GAL-MAD), leveraging Graph Attention and Long Short-Term Memory\narchitectures to capture spatial and temporal dependencies in microservices. We\nutilize SHAP values to localize anomalous services and identify root causes to\nenhance explainability. Experimental results demonstrate that GAL-MAD\noutperforms state-of-the-art models on the RS-Anomic dataset, achieving higher\naccuracy and recall across varying anomaly rates. The explanations provide\nactionable insights into service anomalies, which benefits system\nadministrators.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.LG",
      "I.2.m"
    ],
    "primary_category": "cs.SE",
    "comment": "Preprint - Journal of Universal Computer Science, 13 pages, preprint,\n  7 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.00058v2",
    "published_date": "2025-03-31 10:11:31 UTC",
    "updated_date": "2025-04-26 07:49:45 UTC"
  },
  {
    "arxiv_id": "2503.23907v1",
    "title": "HumanAesExpert: Advancing a Multi-Modality Foundation Model for Human Image Aesthetic Assessment",
    "authors": [
      "Zhichao Liao",
      "Xiaokun Liu",
      "Wenyu Qin",
      "Qingyu Li",
      "Qiulin Wang",
      "Pengfei Wan",
      "Di Zhang",
      "Long Zeng",
      "Pingfa Feng"
    ],
    "abstract": "Image Aesthetic Assessment (IAA) is a long-standing and challenging research\ntask. However, its subset, Human Image Aesthetic Assessment (HIAA), has been\nscarcely explored, even though HIAA is widely used in social media, AI\nworkflows, and related domains. To bridge this research gap, our work pioneers\na holistic implementation framework tailored for HIAA. Specifically, we\nintroduce HumanBeauty, the first dataset purpose-built for HIAA, which\ncomprises 108k high-quality human images with manual annotations. To achieve\ncomprehensive and fine-grained HIAA, 50K human images are manually collected\nthrough a rigorous curation process and annotated leveraging our trailblazing\n12-dimensional aesthetic standard, while the remaining 58K with overall\naesthetic labels are systematically filtered from public datasets. Based on the\nHumanBeauty database, we propose HumanAesExpert, a powerful Vision Language\nModel for aesthetic evaluation of human images. We innovatively design an\nExpert head to incorporate human knowledge of aesthetic sub-dimensions while\njointly utilizing the Language Modeling (LM) and Regression head. This approach\nempowers our model to achieve superior proficiency in both overall and\nfine-grained HIAA. Furthermore, we introduce a MetaVoter, which aggregates\nscores from all three heads, to effectively balance the capabilities of each\nhead, thereby realizing improved assessment precision. Extensive experiments\ndemonstrate that our HumanAesExpert models deliver significantly better\nperformance in HIAA than other state-of-the-art models. Our datasets, models,\nand codes are publicly released to advance the HIAA community. Project webpage:\nhttps://humanaesexpert.github.io/HumanAesExpert/",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.23907v1",
    "published_date": "2025-03-31 09:58:11 UTC",
    "updated_date": "2025-03-31 09:58:11 UTC"
  },
  {
    "arxiv_id": "2503.23897v1",
    "title": "Training-Free Text-Guided Image Editing with Visual Autoregressive Model",
    "authors": [
      "Yufei Wang",
      "Lanqing Guo",
      "Zhihao Li",
      "Jiaxing Huang",
      "Pichao Wang",
      "Bihan Wen",
      "Jian Wang"
    ],
    "abstract": "Text-guided image editing is an essential task that enables users to modify\nimages through natural language descriptions. Recent advances in diffusion\nmodels and rectified flows have significantly improved editing quality,\nprimarily relying on inversion techniques to extract structured noise from\ninput images. However, inaccuracies in inversion can propagate errors, leading\nto unintended modifications and compromising fidelity. Moreover, even with\nperfect inversion, the entanglement between textual prompts and image features\noften results in global changes when only local edits are intended. To address\nthese challenges, we propose a novel text-guided image editing framework based\non VAR (Visual AutoRegressive modeling), which eliminates the need for explicit\ninversion while ensuring precise and controlled modifications. Our method\nintroduces a caching mechanism that stores token indices and probability\ndistributions from the original image, capturing the relationship between the\nsource prompt and the image. Using this cache, we design an adaptive\nfine-grained masking strategy that dynamically identifies and constrains\nmodifications to relevant regions, preventing unintended changes. A token\nreassembling approach further refines the editing process, enhancing diversity,\nfidelity, and control. Our framework operates in a training-free manner and\nachieves high-fidelity editing with faster inference speeds, processing a 1K\nresolution image in as fast as 1.2 seconds. Extensive experiments demonstrate\nthat our method achieves performance comparable to, or even surpassing,\nexisting diffusion- and rectified flow-based approaches in both quantitative\nmetrics and visual quality. The code will be released.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.23897v1",
    "published_date": "2025-03-31 09:46:56 UTC",
    "updated_date": "2025-03-31 09:46:56 UTC"
  },
  {
    "arxiv_id": "2503.23895v4",
    "title": "Dynamic Parametric Retrieval Augmented Generation for Test-time Knowledge Enhancement",
    "authors": [
      "Yuqiao Tan",
      "Shizhu He",
      "Huanxuan Liao",
      "Jun Zhao",
      "Kang Liu"
    ],
    "abstract": "Retrieval-augmented generation (RAG) enhances large language models (LLMs) by\nretrieving relevant documents from external sources and incorporating them into\nthe context. While it improves reliability by providing factual texts, it\nsignificantly increases inference costs as context length grows and introduces\nchallenging issue of RAG hallucination, primarily caused by the lack of\ncorresponding parametric knowledge in LLMs. An efficient solution is to enhance\nthe knowledge of LLMs at test-time. Parametric RAG (PRAG) addresses this by\nembedding document into LLMs parameters to perform test-time knowledge\nenhancement, effectively reducing inference costs through offline training.\nHowever, its high training and storage costs, along with limited generalization\nability, significantly restrict its practical adoption. To address these\nchallenges, we propose Dynamic Parametric RAG (DyPRAG), a novel framework that\nleverages a lightweight parameter translator model to efficiently convert\ndocuments into parametric knowledge. DyPRAG not only reduces inference,\ntraining, and storage costs but also dynamically generates parametric\nknowledge, seamlessly enhancing the knowledge of LLMs and resolving knowledge\nconflicts in a plug-and-play manner at test-time. Extensive experiments on\nmultiple datasets demonstrate the effectiveness and generalization capabilities\nof DyPRAG, offering a powerful and practical RAG paradigm which enables\nsuperior knowledge fusion and mitigates RAG hallucination in real-world\napplications. Our code is available at https://github.com/Trae1ounG/DyPRAG.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "preprint. Code is available at https://github.com/Trae1ounG/DyPRAG",
    "pdf_url": "http://arxiv.org/pdf/2503.23895v4",
    "published_date": "2025-03-31 09:46:35 UTC",
    "updated_date": "2025-05-06 03:04:20 UTC"
  },
  {
    "arxiv_id": "2503.23893v1",
    "title": "DiffScale: Continuous Downscaling and Bias Correction of Subseasonal Wind Speed Forecasts using Diffusion Models",
    "authors": [
      "Maximilian Springenberg",
      "Noelia Otero",
      "Yuxin Xue",
      "Jackie Ma"
    ],
    "abstract": "Renewable resources are strongly dependent on local and large-scale weather\nsituations. Skillful subseasonal to seasonal (S2S) forecasts -- beyond two\nweeks and up to two months -- can offer significant socioeconomic advantages to\nthe energy sector. This study aims to enhance wind speed predictions using a\ndiffusion model with classifier-free guidance to downscale S2S forecasts of\nsurface wind speed. We propose DiffScale, a diffusion model that super-resolves\nspatial information for continuous downscaling factors and lead times.\nLeveraging weather priors as guidance for the generative process of diffusion\nmodels, we adopt the perspective of conditional probabilities on sampling\nsuper-resolved S2S forecasts. We aim to directly estimate the density\nassociated with the target S2S forecasts at different spatial resolutions and\nlead times without auto-regression or sequence prediction, resulting in an\nefficient and flexible model. Synthetic experiments were designed to\nsuper-resolve wind speed S2S forecasts from the European Center for\nMedium-Range Weather Forecast (ECMWF) from a coarse resolution to a finer\nresolution of ERA5 reanalysis data, which serves as a high-resolution target.\nThe innovative aspect of DiffScale lies in its flexibility to downscale\narbitrary scaling factors, enabling it to generalize across various grid\nresolutions and lead times -without retraining the model- while correcting\nmodel errors, making it a versatile tool for improving S2S wind speed\nforecasts. We achieve a significant improvement in prediction quality,\noutperforming baselines up to week 3.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "eess.IV"
    ],
    "primary_category": "cs.LG",
    "comment": "28 pages, 18 figures, preprint under review",
    "pdf_url": "http://arxiv.org/pdf/2503.23893v1",
    "published_date": "2025-03-31 09:44:28 UTC",
    "updated_date": "2025-03-31 09:44:28 UTC"
  },
  {
    "arxiv_id": "2503.23888v1",
    "title": "MuseFace: Text-driven Face Editing via Diffusion-based Mask Generation Approach",
    "authors": [
      "Xin Zhang",
      "Siting Huang",
      "Xiangyang Luo",
      "Yifan Xie",
      "Weijiang Yu",
      "Heng Chang",
      "Fei Ma",
      "Fei Yu"
    ],
    "abstract": "Face editing modifies the appearance of face, which plays a key role in\ncustomization and enhancement of personal images. Although much work have\nachieved remarkable success in text-driven face editing, they still face\nsignificant challenges as none of them simultaneously fulfill the\ncharacteristics of diversity, controllability and flexibility. To address this\nchallenge, we propose MuseFace, a text-driven face editing framework, which\nrelies solely on text prompt to enable face editing. Specifically, MuseFace\nintegrates a Text-to-Mask diffusion model and a semantic-aware face editing\nmodel, capable of directly generating fine-grained semantic masks from text and\nperforming face editing. The Text-to-Mask diffusion model provides\n\\textit{diversity} and \\textit{flexibility} to the framework, while the\nsemantic-aware face editing model ensures \\textit{controllability} of the\nframework. Our framework can create fine-grained semantic masks, making precise\nface editing possible, and significantly enhancing the controllability and\nflexibility of face editing models. Extensive experiments demonstrate that\nMuseFace achieves superior high-fidelity performance.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "6 pages, 5 figures,IEEE International Conference on Multimedia & Expo\n  2025",
    "pdf_url": "http://arxiv.org/pdf/2503.23888v1",
    "published_date": "2025-03-31 09:41:09 UTC",
    "updated_date": "2025-03-31 09:41:09 UTC"
  },
  {
    "arxiv_id": "2503.23886v1",
    "title": "SchemaAgent: A Multi-Agents Framework for Generating Relational Database Schema",
    "authors": [
      "Qin Wang",
      "Youhuan Li",
      "Yansong Feng",
      "Si Chen",
      "Ziming Li",
      "Pan Zhang",
      "Zhichao Shi",
      "Yuequn Dou",
      "chuchu Gao",
      "Zebin Huang",
      "Zihui Si",
      "Yixuan Chen",
      "Zhaohai Sun",
      "Ke Tang",
      "Wenqiang Jin"
    ],
    "abstract": "The relational database design would output a schema based on user's\nrequirements, which defines table structures and their interrelated relations.\nTranslating requirements into accurate schema involves several non-trivial\nsubtasks demanding both database expertise and domain-specific knowledge. This\nposes unique challenges for automated design of relational databases. Existing\nefforts are mostly based on customized rules or conventional deep learning\nmodels, often producing suboptimal schema. Recently, large language models\n(LLMs) have significantly advanced intelligent application development across\nvarious domains. In this paper, we propose SchemaAgent, a unified LLM-based\nmulti-agent framework for the automated generation of high-quality database\nschema. SchemaAgent is the first to apply LLMs for schema generation, which\nemulates the workflow of manual schema design by assigning specialized roles to\nagents and enabling effective collaboration to refine their respective\nsubtasks. Schema generation is a streamlined workflow, where directly applying\nthe multi-agent framework may cause compounding impact of errors. To address\nthis, we incorporate dedicated roles for reflection and inspection, alongside\nan innovative error detection and correction mechanism to identify and rectify\nissues across various phases. For evaluation, we present a benchmark named\n\\textit{RSchema}, which contains more than 500 pairs of requirement description\nand schema. Experimental results on this benchmark demonstrate the superiority\nof our approach over mainstream LLMs for relational database schema generation.",
    "categories": [
      "cs.DB",
      "cs.AI"
    ],
    "primary_category": "cs.DB",
    "comment": "19 pages, 16 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.23886v1",
    "published_date": "2025-03-31 09:39:19 UTC",
    "updated_date": "2025-03-31 09:39:19 UTC"
  },
  {
    "arxiv_id": "2503.23875v1",
    "title": "GenSwarm: Scalable Multi-Robot Code-Policy Generation and Deployment via Language Models",
    "authors": [
      "Wenkang Ji",
      "Huaben Chen",
      "Mingyang Chen",
      "Guobin Zhu",
      "Lufeng Xu",
      "Roderich Groß",
      "Rui Zhou",
      "Ming Cao",
      "Shiyu Zhao"
    ],
    "abstract": "The development of control policies for multi-robot systems traditionally\nfollows a complex and labor-intensive process, often lacking the flexibility to\nadapt to dynamic tasks. This has motivated research on methods to automatically\ncreate control policies. However, these methods require iterative processes of\nmanually crafting and refining objective functions, thereby prolonging the\ndevelopment cycle. This work introduces \\textit{GenSwarm}, an end-to-end system\nthat leverages large language models to automatically generate and deploy\ncontrol policies for multi-robot tasks based on simple user instructions in\nnatural language. As a multi-language-agent system, GenSwarm achieves zero-shot\nlearning, enabling rapid adaptation to altered or unseen tasks. The white-box\nnature of the code policies ensures strong reproducibility and\ninterpretability. With its scalable software and hardware architectures,\nGenSwarm supports efficient policy deployment on both simulated and real-world\nmulti-robot systems, realizing an instruction-to-execution end-to-end\nfunctionality that could prove valuable for robotics specialists and\nnon-specialists alike.The code of the proposed GenSwarm system is available\nonline: https://github.com/WindyLab/GenSwarm.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.23875v1",
    "published_date": "2025-03-31 09:26:34 UTC",
    "updated_date": "2025-03-31 09:26:34 UTC"
  },
  {
    "arxiv_id": "2503.23862v2",
    "title": "Learned Image Compression and Restoration for Digital Pathology",
    "authors": [
      "SeonYeong Lee",
      "EonSeung Seong",
      "DongEon Lee",
      "SiYeoul Lee",
      "Yubin Cho",
      "Chunsu Park",
      "Seonho Kim",
      "MinKyung Seo",
      "YoungSin Ko",
      "MinWoo Kim"
    ],
    "abstract": "Digital pathology images play a crucial role in medical diagnostics, but\ntheir ultra-high resolution and large file sizes pose significant challenges\nfor storage, transmission, and real-time visualization. To address these\nissues, we propose CLERIC, a novel deep learning-based image compression\nframework designed specifically for whole slide images (WSIs). CLERIC\nintegrates a learnable lifting scheme and advanced convolutional techniques to\nenhance compression efficiency while preserving critical pathological details.\nOur framework employs a lifting-scheme transform in the analysis stage to\ndecompose images into low- and high-frequency components, enabling more\nstructured latent representations. These components are processed through\nparallel encoders incorporating Deformable Residual Blocks (DRB) and Recurrent\nResidual Blocks (R2B) to improve feature extraction and spatial adaptability.\nThe synthesis stage applies an inverse lifting transform for effective image\nreconstruction, ensuring high-fidelity restoration of fine-grained tissue\nstructures. We evaluate CLERIC on a digital pathology image dataset and compare\nits performance against state-of-the-art learned image compression (LIC)\nmodels. Experimental results demonstrate that CLERIC achieves superior\nrate-distortion (RD) performance, significantly reducing storage requirements\nwhile maintaining high diagnostic image quality. Our study highlights the\npotential of deep learning-based compression in digital pathology, facilitating\nefficient data management and long-term storage while ensuring seamless\nintegration into clinical workflows and AI-assisted diagnostic systems. Code\nand models are available at: https://github.com/pnu-amilab/CLERIC.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.23862v2",
    "published_date": "2025-03-31 09:09:09 UTC",
    "updated_date": "2025-04-01 03:06:51 UTC"
  },
  {
    "arxiv_id": "2503.23830v2",
    "title": "Orchestrate Multimodal Data with Batch Post-Balancing to Accelerate Multimodal Large Language Model Training",
    "authors": [
      "Yijie Zheng",
      "Bangjun Xiao",
      "Lei Shi",
      "Xiaoyang Li",
      "Faming Wu",
      "Tianyu Li",
      "Xuefeng Xiao",
      "Yang Zhang",
      "Yuxuan Wang",
      "Shouda Liu"
    ],
    "abstract": "Multimodal large language models (MLLMs), such as GPT-4o, are garnering\nsignificant attention. During the exploration of MLLM training, we identified\nModality Composition Incoherence, a phenomenon that the proportion of a certain\nmodality varies dramatically across different examples. It exacerbates the\nchallenges of addressing mini-batch imbalances, which lead to uneven GPU\nutilization between Data Parallel (DP) instances and severely degrades the\nefficiency and scalability of MLLM training, ultimately affecting training\nspeed and hindering further research on MLLMs.\n  To address these challenges, we introduce OrchMLLM, a comprehensive framework\ndesigned to mitigate the inefficiencies in MLLM training caused by Modality\nComposition Incoherence. First, we propose Batch Post-Balancing Dispatcher, a\ntechnique that efficiently eliminates mini-batch imbalances in sequential data.\nAdditionally, we integrate MLLM Global Orchestrator into the training framework\nto orchestrate multimodal data and tackle the issues arising from Modality\nComposition Incoherence. We evaluate OrchMLLM across various MLLM sizes,\ndemonstrating its efficiency and scalability. Experimental results reveal that\nOrchMLLM achieves a Model FLOPs Utilization (MFU) of $41.6\\%$ when training an\n84B MLLM with three modalities on $2560$ H100 GPUs, outperforming Megatron-LM\nby up to $3.1\\times$ in throughput.",
    "categories": [
      "cs.DC",
      "cs.AI"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.23830v2",
    "published_date": "2025-03-31 08:24:23 UTC",
    "updated_date": "2025-04-09 06:39:29 UTC"
  },
  {
    "arxiv_id": "2503.23820v3",
    "title": "When Counterfactual Reasoning Fails: Chaos and Real-World Complexity",
    "authors": [
      "Yahya Aalaila",
      "Gerrit Großmann",
      "Sumantrak Mukherjee",
      "Jonas Wahl",
      "Sebastian Vollmer"
    ],
    "abstract": "Counterfactual reasoning, a cornerstone of human cognition and\ndecision-making, is often seen as the 'holy grail' of causal learning, with\napplications ranging from interpreting machine learning models to promoting\nalgorithmic fairness. While counterfactual reasoning has been extensively\nstudied in contexts where the underlying causal model is well-defined,\nreal-world causal modeling is often hindered by model and parameter\nuncertainty, observational noise, and chaotic behavior. The reliability of\ncounterfactual analysis in such settings remains largely unexplored. In this\nwork, we investigate the limitations of counterfactual reasoning within the\nframework of Structural Causal Models. Specifically, we empirically investigate\n\\emph{counterfactual sequence estimation} and highlight cases where it becomes\nincreasingly unreliable. We find that realistic assumptions, such as low\ndegrees of model uncertainty or chaotic dynamics, can result in\ncounterintuitive outcomes, including dramatic deviations between predicted and\ntrue counterfactual trajectories. This work urges caution when applying\ncounterfactual reasoning in settings characterized by chaos and uncertainty.\nFurthermore, it raises the question of whether certain systems may pose\nfundamental limitations on the ability to answer counterfactual questions about\ntheir behavior.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.23820v3",
    "published_date": "2025-03-31 08:14:51 UTC",
    "updated_date": "2025-04-10 14:30:12 UTC"
  },
  {
    "arxiv_id": "2503.23819v1",
    "title": "Conformal uncertainty quantification to evaluate predictive fairness of foundation AI model for skin lesion classes across patient demographics",
    "authors": [
      "Swarnava Bhattacharyya",
      "Umapada Pal",
      "Tapabrata Chakraborti"
    ],
    "abstract": "Deep learning based diagnostic AI systems based on medical images are\nstarting to provide similar performance as human experts. However these data\nhungry complex systems are inherently black boxes and therefore slow to be\nadopted for high risk applications like healthcare. This problem of lack of\ntransparency is exacerbated in the case of recent large foundation models,\nwhich are trained in a self supervised manner on millions of data points to\nprovide robust generalisation across a range of downstream tasks, but the\nembeddings generated from them happen through a process that is not\ninterpretable, and hence not easily trustable for clinical applications. To\naddress this timely issue, we deploy conformal analysis to quantify the\npredictive uncertainty of a vision transformer (ViT) based foundation model\nacross patient demographics with respect to sex, age and ethnicity for the\ntasks of skin lesion classification using several public benchmark datasets.\nThe significant advantage of this method is that conformal analysis is method\nindependent and it not only provides a coverage guarantee at population level\nbut also provides an uncertainty score for each individual. We used a\nmodel-agnostic dynamic F1-score-based sampling during model training, which\nhelped to stabilize the class imbalance and we investigate the effects on\nuncertainty quantification (UQ) with or without this bias mitigation step. Thus\nwe show how this can be used as a fairness metric to evaluate the robustness of\nthe feature embeddings of the foundation model (Google DermFoundation) and thus\nadvance the trustworthiness and fairness of clinical AI.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.23819v1",
    "published_date": "2025-03-31 08:06:00 UTC",
    "updated_date": "2025-03-31 08:06:00 UTC"
  },
  {
    "arxiv_id": "2504.01986v1",
    "title": "TuRTLe: A Unified Evaluation of LLMs for RTL Generation",
    "authors": [
      "Dario Garcia-Gasulla",
      "Gokcen Kestor",
      "Emanuele Parisi",
      "Miquel Albert'i-Binimelis",
      "Cristian Gutierrez",
      "Razine Moundir Ghorab",
      "Orlando Montenegro",
      "Bernat Homs",
      "Miquel Moreto"
    ],
    "abstract": "The rapid advancements in LLMs have driven the adoption of generative AI in\nvarious domains, including Electronic Design Automation (EDA). Unlike\ntraditional software development, EDA presents unique challenges, as generated\nRTL code must not only be syntactically correct and functionally accurate but\nalso synthesizable by hardware generators while meeting performance, power, and\narea constraints. These additional requirements introduce complexities that\nexisting code-generation benchmarks often fail to capture, limiting their\neffectiveness in evaluating LLMs for RTL generation. To address this gap, we\npropose TuRTLe, a unified evaluation framework designed to systematically\nassess LLMs across key RTL generation tasks. TuRTLe integrates multiple\nexisting benchmarks and automates the evaluation process, enabling a\ncomprehensive assessment of LLM performance in syntax correctness, functional\ncorrectness, synthesis, PPA optimization, and exact line completion. Using this\nframework, we benchmark a diverse set of open LLMs and analyze their strengths\nand weaknesses in EDA-specific tasks. Our results show that reasoning-based\nmodels, such as DeepSeek R1, consistently outperform others across multiple\nevaluation criteria, but at the cost of increased computational overhead and\ninference latency. Additionally, base models are better suited in module\ncompletion tasks, while instruct-tuned models perform better in\nspecification-to-RTL tasks.",
    "categories": [
      "cs.AR",
      "cs.AI",
      "I.2.5; J.6"
    ],
    "primary_category": "cs.AR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.01986v1",
    "published_date": "2025-03-31 07:43:12 UTC",
    "updated_date": "2025-03-31 07:43:12 UTC"
  },
  {
    "arxiv_id": "2503.23803v2",
    "title": "Thinking Longer, Not Larger: Enhancing Software Engineering Agents via Scaling Test-Time Compute",
    "authors": [
      "Yingwei Ma",
      "Yongbin Li",
      "Yihong Dong",
      "Xue Jiang",
      "Rongyu Cao",
      "Jue Chen",
      "Fei Huang",
      "Binhua Li"
    ],
    "abstract": "Recent advancements in software engineering agents have demonstrated\npromising capabilities in automating program improvements. However, their\nreliance on closed-source or resource-intensive models introduces significant\ndeployment challenges in private environments, prompting a critical question:\n\\textit{How can personally deployable open-source LLMs achieve comparable code\nreasoning performance?}\n  To this end, we propose a unified Test-Time Compute scaling framework that\nleverages increased inference-time computation instead of larger models. Our\nframework incorporates two complementary strategies: internal TTC and external\nTTC. Internally, we introduce a \\textit{development-contextualized trajectory\nsynthesis} method leveraging real-world software repositories to bootstrap\nmulti-stage reasoning processes, such as fault localization and patch\ngeneration. We further enhance trajectory quality through rejection sampling,\nrigorously evaluating trajectories along accuracy and complexity. Externally,\nwe propose a novel \\textit{development-process-based search} strategy guided by\nreward models and execution verification. This approach enables targeted\ncomputational allocation at critical development decision points, overcoming\nlimitations of existing \"end-point only\" verification methods.\n  Evaluations on SWE-bench Verified demonstrate our \\textbf{32B model achieves\na 46\\% issue resolution rate}, surpassing significantly larger models such as\nDeepSeek R1 671B and OpenAI o1. Additionally, we provide the empirical\nvalidation of the test-time scaling phenomenon within SWE agents, revealing\nthat \\textbf{models dynamically allocate more tokens to increasingly\nchallenging problems}, effectively enhancing reasoning capabilities. We\npublicly release all training data, models, and code to facilitate future\nresearch. https://github.com/yingweima2022/SWE-Reasoner",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.23803v2",
    "published_date": "2025-03-31 07:31:32 UTC",
    "updated_date": "2025-04-08 12:36:08 UTC"
  },
  {
    "arxiv_id": "2503.23798v2",
    "title": "Adaptive Layer-skipping in Pre-trained LLMs",
    "authors": [
      "Xuan Luo",
      "Weizhi Wang",
      "Xifeng Yan"
    ],
    "abstract": "Various layer-skipping methods have been proposed to accelerate token\ngeneration in large language models (LLMs). However, they have overlooked a\nfundamental question: How do computational demands vary across the generation\nof different tokens? In this work, we introduce FlexiDepth, a method that\ndynamically adjusts the number of Transformer layers used in text generation.\nBy incorporating a plug-in router and adapter, FlexiDepth enables adaptive\nlayer-skipping in LLMs without modifying their original parameters. Introducing\nFlexiDepth to Llama-3-8B model achieves layer skipping of 8 layers out of 32,\nand meanwhile maintains the full 100\\% benchmark performance. Experimental\nresults with FlexiDepth demonstrate that computational demands in LLMs\nsignificantly vary based on token type. Specifically, generating repetitive\ntokens or fixed phrases requires fewer layers, whereas producing tokens\ninvolving computation or high uncertainty requires more layers. Interestingly,\nthis adaptive allocation pattern aligns with human intuition. To advance\nresearch in this area, we open sourced FlexiDepth and a dataset documenting\nFlexiDepth's layer allocation patterns for future exploration.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.23798v2",
    "published_date": "2025-03-31 07:20:58 UTC",
    "updated_date": "2025-04-17 22:26:31 UTC"
  },
  {
    "arxiv_id": "2503.23786v1",
    "title": "MGD-SAM2: Multi-view Guided Detail-enhanced Segment Anything Model 2 for High-Resolution Class-agnostic Segmentation",
    "authors": [
      "Haoran Shen",
      "Peixian Zhuang",
      "Jiahao Kou",
      "Yuxin Zeng",
      "Haoying Xu",
      "Jiangyun Li"
    ],
    "abstract": "Segment Anything Models (SAMs), as vision foundation models, have\ndemonstrated remarkable performance across various image analysis tasks.\nDespite their strong generalization capabilities, SAMs encounter challenges in\nfine-grained detail segmentation for high-resolution class-independent\nsegmentation (HRCS), due to the limitations in the direct processing of\nhigh-resolution inputs and low-resolution mask predictions, and the reliance on\naccurate manual prompts. To address these limitations, we propose MGD-SAM2\nwhich integrates SAM2 with multi-view feature interaction between a global\nimage and local patches to achieve precise segmentation. MGD-SAM2 incorporates\nthe pre-trained SAM2 with four novel modules: the Multi-view Perception Adapter\n(MPAdapter), the Multi-view Complementary Enhancement Module (MCEM), the\nHierarchical Multi-view Interaction Module (HMIM), and the Detail Refinement\nModule (DRM). Specifically, we first introduce MPAdapter to adapt the SAM2\nencoder for enhanced extraction of local details and global semantics in HRCS\nimages. Then, MCEM and HMIM are proposed to further exploit local texture and\nglobal context by aggregating multi-view features within and across\nmulti-scales. Finally, DRM is designed to generate gradually restored\nhigh-resolution mask predictions, compensating for the loss of fine-grained\ndetails resulting from directly upsampling the low-resolution prediction maps.\nExperimental results demonstrate the superior performance and strong\ngeneralization of our model on multiple high-resolution and normal-resolution\ndatasets. Code will be available at https://github.com/sevenshr/MGD-SAM2.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.23786v1",
    "published_date": "2025-03-31 07:02:32 UTC",
    "updated_date": "2025-03-31 07:02:32 UTC"
  },
  {
    "arxiv_id": "2503.23781v1",
    "title": "DebFlow: Automating Agent Creation via Agent Debate",
    "authors": [
      "Jinwei Su",
      "Yinghui Xia",
      "Ronghua Shi",
      "Jianhui Wang",
      "Jianuo Huang",
      "Yijin Wang",
      "Tianyu Shi",
      "Yang Jingsong",
      "Lewei He"
    ],
    "abstract": "Large language models (LLMs) have demonstrated strong potential and\nimpressive performance in automating the generation and optimization of\nworkflows. However, existing approaches are marked by limited reasoning\ncapabilities, high computational demands, and significant resource\nrequirements. To address these issues, we propose DebFlow, a framework that\nemploys a debate mechanism to optimize workflows and integrates reflexion to\nimprove based on previous experiences. We evaluated our method across six\nbenchmark datasets, including HotpotQA, MATH, and ALFWorld. Our approach\nachieved a 3\\% average performance improvement over the latest baselines,\ndemonstrating its effectiveness in diverse problem domains. In particular,\nduring training, our framework reduces resource consumption by 37\\% compared to\nthe state-of-the-art baselines. Additionally, we performed ablation studies.\nRemoving the Debate component resulted in a 4\\% performance drop across two\nbenchmark datasets, significantly greater than the 2\\% drop observed when the\nReflection component was removed. These findings strongly demonstrate the\ncritical role of Debate in enhancing framework performance, while also\nhighlighting the auxiliary contribution of reflexion to overall optimization.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.23781v1",
    "published_date": "2025-03-31 06:56:13 UTC",
    "updated_date": "2025-03-31 06:56:13 UTC"
  },
  {
    "arxiv_id": "2503.23779v1",
    "title": "WinoWhat: A Parallel Corpus of Paraphrased WinoGrande Sentences with Common Sense Categorization",
    "authors": [
      "Ine Gevers",
      "Victor De Marez",
      "Luna De Bruyne",
      "Walter Daelemans"
    ],
    "abstract": "In this study, we take a closer look at how Winograd schema challenges can be\nused to evaluate common sense reasoning in LLMs. Specifically, we evaluate\ngenerative models of different sizes on the popular WinoGrande benchmark. We\nrelease WinoWhat, a new corpus, in which each instance of the WinoGrande\nvalidation set is paraphrased. Additionally, we evaluate the performance on the\nchallenge across five common sense knowledge categories, giving more\nfine-grained insights on what types of knowledge are more challenging for LLMs.\nSurprisingly, all models perform significantly worse on WinoWhat, implying that\nLLM reasoning capabilities are overestimated on WinoGrande. To verify whether\nthis is an effect of benchmark memorization, we match benchmark instances to\nLLM trainingdata and create two test-suites. We observe that memorization has a\nminimal effect on model performance on WinoGrande.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.23779v1",
    "published_date": "2025-03-31 06:53:53 UTC",
    "updated_date": "2025-03-31 06:53:53 UTC"
  },
  {
    "arxiv_id": "2504.01039v1",
    "title": "One Person, One Bot",
    "authors": [
      "Liat Lavi"
    ],
    "abstract": "This short paper puts forward a vision for a new democratic model enabled by\nthe recent technological advances in agentic AI. It therefore opens with\ndrawing a clear and concise picture of the model, and only later addresses\nrelated proposals and research directions, and concerns regarding feasibility\nand safety. It ends with a note on the timeliness of this idea and on optimism.\nThe model proposed is that of assigning each citizen an AI Agent that would\nserve as their political delegate, enabling the return to direct democracy. The\npaper examines this models relation to existing research, its potential\nsetbacks and feasibility and argues for its further development.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "12 pages",
    "pdf_url": "http://arxiv.org/pdf/2504.01039v1",
    "published_date": "2025-03-31 06:49:47 UTC",
    "updated_date": "2025-03-31 06:49:47 UTC"
  },
  {
    "arxiv_id": "2503.23764v2",
    "title": "WaveFormer: A 3D Transformer with Wavelet-Driven Feature Representation for Efficient Medical Image Segmentation",
    "authors": [
      "Md Mahfuz Al Hasan",
      "Mahdi Zaman",
      "Abdul Jawad",
      "Alberto Santamaria-Pang",
      "Ho Hin Lee",
      "Ivan Tarapov",
      "Kyle See",
      "Md Shah Imran",
      "Antika Roy",
      "Yaser Pourmohammadi Fallah",
      "Navid Asadizanjani",
      "Reza Forghani"
    ],
    "abstract": "Transformer-based architectures have advanced medical image analysis by\neffectively modeling long-range dependencies, yet they often struggle in 3D\nsettings due to substantial memory overhead and insufficient capture of\nfine-grained local features. We address these limitations with WaveFormer, a\nnovel 3D-transformer that: i) leverages the fundamental frequency-domain\nproperties of features for contextual representation, and ii) is inspired by\nthe top-down mechanism of the human visual recognition system, making it a\nbiologically motivated architecture. By employing discrete wavelet\ntransformations (DWT) at multiple scales, WaveFormer preserves both global\ncontext and high-frequency details while replacing heavy upsampling layers with\nefficient wavelet-based summarization and reconstruction. This significantly\nreduces the number of parameters, which is critical for real-world deployment\nwhere computational resources and training times are constrained. Furthermore,\nthe model is generic and easily adaptable to diverse applications. Evaluations\non BraTS2023, FLARE2021, and KiTS2023 demonstrate performance on par with\nstate-of-the-art methods while offering substantially lower computational\ncomplexity.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.23764v2",
    "published_date": "2025-03-31 06:28:41 UTC",
    "updated_date": "2025-04-01 02:13:23 UTC"
  },
  {
    "arxiv_id": "2503.23740v1",
    "title": "LANID: LLM-assisted New Intent Discovery",
    "authors": [
      "Lu Fan",
      "Jiashu Pu",
      "Rongsheng Zhang",
      "Xiao-Ming Wu"
    ],
    "abstract": "Task-oriented Dialogue Systems (TODS) often face the challenge of\nencountering new intents. New Intent Discovery (NID) is a crucial task that\naims to identify these novel intents while maintaining the capability to\nrecognize existing ones. Previous efforts to adapt TODS to new intents have\nstruggled with inadequate semantic representation or have depended on external\nknowledge, which is often not scalable or flexible. Recently, Large Language\nModels (LLMs) have demonstrated strong zero-shot capabilities; however, their\nscale can be impractical for real-world applications that involve extensive\nqueries. To address the limitations of existing NID methods by leveraging LLMs,\nwe propose LANID, a framework that enhances the semantic representation of\nlightweight NID encoders with the guidance of LLMs. Specifically, LANID employs\nthe $K$-nearest neighbors and Density-Based Spatial Clustering of Applications\nwith Noise (DBSCAN) algorithms to sample selective utterance pairs from the\ntraining set. It then queries an LLM to ascertain the relationships between\nthese pairs. The data produced from this process is utilized to design a\ncontrastive fine-tuning task, which is then used to train a small encoder with\na contrastive triplet loss. Our experimental results demonstrate the efficacy\nof the proposed method across three distinct NID datasets, surpassing strong\nbaselines in both unsupervised and semi-supervised settings. Our code is\navailable at https://github.com/floatSDSDS/LANID.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Published in LREC-COLING 2024",
    "pdf_url": "http://arxiv.org/pdf/2503.23740v1",
    "published_date": "2025-03-31 05:34:32 UTC",
    "updated_date": "2025-03-31 05:34:32 UTC"
  },
  {
    "arxiv_id": "2503.23731v1",
    "title": "Investigation of intelligent barbell squat coaching system based on computer vision and machine learning",
    "authors": [
      "Yinq-Rong Chern",
      "Yuhao Lee",
      "Hsiao-Ching Lin",
      "Guan-Ting Chen",
      "Ying-Hsien Chen",
      "Fu-Sung Lin",
      "Chih-Yao Chuang",
      "Jenn-Jier James Lien",
      "Chih-Hsien Huang"
    ],
    "abstract": "Purpose: Research has revealed that strength training can reduce the\nincidence of chronic diseases and physical deterioration at any age. Therefore,\nhaving a movement diagnostic system is crucial for training alone. Hence, this\nstudy developed an artificial intelligence and computer vision-based barbell\nsquat coaching system with a real-time mode that immediately diagnoses the\nissue and provides feedback after each squat. In addition, a replay mode allows\nusers to examine their previous squats and check their comments. Initially,\nfour primary characteristics of the barbell squat were identified: body joint\nangles, dorsiflexion, the ratio of knee-to-hip movement, and barbell stability.\nMethods: We collect 8,151 squats from 77 participants, categorizing them as\ngood squats and six issues. Then, we trained the diagnosis models with three\nmachine-learning architectures. Furthermore, this research applied the SHapley\nAdditive exPlanations (SHAP) method to enhance the accuracy of issue prediction\nand reduce the computation time by feature selection. Results: The F1 score of\nthe six issues reached 86.86%, 69.01%, 77.42%, 90.74%, 95.83%, and 100%. Each\nsquat diagnosis took less than 0.5 seconds. Finally, this study examined the\nefficacy of the proposed system with two groups of participants trained with\nand without the system. Subsequently, participants trained with the system\nexhibited substantial improvements in their squat technique, as assessed both\nby the system itself and by a professional weightlifting coach. Conclusion:\nThis is a comprehensive study that integrates artificial intelligence, computer\nvision and multivariable processing technologies, aimed at building a\nreal-time, user-friendly barbell squat feedback and training system.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.23731v1",
    "published_date": "2025-03-31 05:08:52 UTC",
    "updated_date": "2025-03-31 05:08:52 UTC"
  },
  {
    "arxiv_id": "2503.23730v1",
    "title": "KOFFVQA: An Objectively Evaluated Free-form VQA Benchmark for Large Vision-Language Models in the Korean Language",
    "authors": [
      "Yoonshik Kim",
      "Jaeyoon Jung"
    ],
    "abstract": "The recent emergence of Large Vision-Language Models(VLMs) has resulted in a\nvariety of different benchmarks for evaluating such models. Despite this, we\nobserve that most existing evaluation methods suffer from the fact that they\neither require the model to choose from pre-determined responses, sacrificing\nopen-endedness, or evaluate responses using a judge model, resulting in\nsubjective and unreliable evaluation. In addition, we observe a lack of\nbenchmarks for VLMs in the Korean language, which are necessary as a separate\nmetric from more common English language benchmarks, as the performance of\ngenerative language models can differ significantly based on the language being\nused. Therefore, we present KOFFVQA, a general-purpose free-form visual\nquestion answering benchmark in the Korean language for the evaluation of VLMs.\nOur benchmark consists of 275 carefully crafted questions each paired with an\nimage and grading criteria covering 10 different aspects of VLM performance.\nThe grading criteria eliminate the problem of unreliability by allowing the\njudge model to grade each response based on a pre-determined set of rules. By\ndefining the evaluation criteria in an objective manner, even a small\nopen-source model can be used to evaluate models on our benchmark reliably. In\naddition to evaluating a large number of existing VLMs on our benchmark, we\nalso experimentally verify that our method of using pre-existing grading\ncriteria for evaluation is much more reliable than existing methods. Our\nevaluation code is available at https://github.com/maum-ai/KOFFVQA",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to CVPRW 2025, Workshop on Benchmarking and Expanding AI\n  Multimodal Approaches",
    "pdf_url": "http://arxiv.org/pdf/2503.23730v1",
    "published_date": "2025-03-31 05:04:25 UTC",
    "updated_date": "2025-03-31 05:04:25 UTC"
  },
  {
    "arxiv_id": "2503.23721v1",
    "title": "Unimodal-driven Distillation in Multimodal Emotion Recognition with Dynamic Fusion",
    "authors": [
      "Jiagen Li",
      "Rui Yu",
      "Huihao Huang",
      "Huaicheng Yan"
    ],
    "abstract": "Multimodal Emotion Recognition in Conversations (MERC) identifies emotional\nstates across text, audio and video, which is essential for intelligent\ndialogue systems and opinion analysis. Existing methods emphasize heterogeneous\nmodal fusion directly for cross-modal integration, but often suffer from\ndisorientation in multimodal learning due to modal heterogeneity and lack of\ninstructive guidance. In this work, we propose SUMMER, a novel heterogeneous\nmultimodal integration framework leveraging Mixture of Experts with\nHierarchical Cross-modal Fusion and Interactive Knowledge Distillation. Key\ncomponents include a Sparse Dynamic Mixture of Experts (SDMoE) for capturing\ndynamic token-wise interactions, a Hierarchical Cross-Modal Fusion (HCMF) for\neffective fusion of heterogeneous modalities, and Interactive Knowledge\nDistillation (IKD), which uses a pre-trained unimodal teacher to guide\nmultimodal fusion in latent and logit spaces. Experiments on IEMOCAP and MELD\nshow SUMMER outperforms state-of-the-art methods, particularly in recognizing\nminority and semantically similar emotions.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.23721v1",
    "published_date": "2025-03-31 04:43:10 UTC",
    "updated_date": "2025-03-31 04:43:10 UTC"
  },
  {
    "arxiv_id": "2504.08763v1",
    "title": "WebMap -- Large Language Model-assisted Semantic Link Induction in the Web",
    "authors": [
      "Shiraj Pokharel",
      "Georg P. Roßrucker",
      "Mario M. Kubek"
    ],
    "abstract": "Carrying out research tasks is only inadequately supported, if not hindered,\nby current web search engines. This paper therefore proposes functional\nextensions of WebMap, a semantically induced overlay linking structure on the\nweb to inherently facilitate research activities. These add-ons support the\ndynamic determination and regrouping of document clusters, the creation of a\nsemantic signpost in the web, and the interactive tracing of topics back to\ntheir origins.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "68T50, 68T07",
      "I.2.6; I.2.7; H.3.3"
    ],
    "primary_category": "cs.IR",
    "comment": "11 pages, 3 figures, accepted at the 2024 24th International\n  Conference on Innovations for Community Services (I4CS), June 12 - 14,\n  Maastricht, The Netherlands, 2024",
    "pdf_url": "http://arxiv.org/pdf/2504.08763v1",
    "published_date": "2025-03-31 04:40:45 UTC",
    "updated_date": "2025-03-31 04:40:45 UTC"
  },
  {
    "arxiv_id": "2503.23713v1",
    "title": "GNN-Based Candidate Node Predictor for Influence Maximization in Temporal Graphs",
    "authors": [
      "Priyanka Gautam",
      "Balasubramaniam Natarajan",
      "Sai Munikoti",
      "S M Ferdous",
      "Mahantesh Halappanavar"
    ],
    "abstract": "In an age where information spreads rapidly across social media, effectively\nidentifying influential nodes in dynamic networks is critical. Traditional\ninfluence maximization strategies often fail to keep up with rapidly evolving\nrelationships and structures, leading to missed opportunities and\ninefficiencies. To address this, we propose a novel learning-based approach\nintegrating Graph Neural Networks (GNNs) with Bidirectional Long Short-Term\nMemory (BiLSTM) models. This hybrid framework captures both structural and\ntemporal dynamics, enabling accurate prediction of candidate nodes for seed set\nselection. The bidirectional nature of BiLSTM allows our model to analyze\npatterns from both past and future network states, ensuring adaptability to\nchanges over time. By dynamically adapting to graph evolution at each time\nsnapshot, our approach improves seed set calculation efficiency, achieving an\naverage of 90% accuracy in predicting potential seed nodes across diverse\nnetworks. This significantly reduces computational overhead by optimizing the\nnumber of nodes evaluated for seed selection. Our method is particularly\neffective in fields like viral marketing and social network analysis, where\nunderstanding temporal dynamics is crucial.",
    "categories": [
      "cs.SI",
      "cs.AI"
    ],
    "primary_category": "cs.SI",
    "comment": "9 pages, 5 figures, Accepted in AAAI25 to AI4TS Workshop@AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.23713v1",
    "published_date": "2025-03-31 04:28:37 UTC",
    "updated_date": "2025-03-31 04:28:37 UTC"
  },
  {
    "arxiv_id": "2504.08762v1",
    "title": "InteractiveSurvey: An LLM-based Personalized and Interactive Survey Paper Generation System",
    "authors": [
      "Zhiyuan Wen",
      "Jiannong Cao",
      "Zian Wang",
      "Beichen Guo",
      "Ruosong Yang",
      "Shuaiqi Liu"
    ],
    "abstract": "The exponential growth of academic literature creates urgent demands for\ncomprehensive survey papers, yet manual writing remains time-consuming and\nlabor-intensive. Recent advances in large language models (LLMs) and\nretrieval-augmented generation (RAG) facilitate studies in synthesizing survey\npapers from multiple references, but most existing works restrict users to\ntitle-only inputs and fixed outputs, neglecting the personalized process of\nsurvey paper writing. In this paper, we introduce InteractiveSurvey - an\nLLM-based personalized and interactive survey paper generation system.\nInteractiveSurvey can generate structured, multi-modal survey papers with\nreference categorizations from multiple reference papers through both online\nretrieval and user uploads. More importantly, users can customize and refine\nintermediate components continuously during generation, including reference\ncategorization, outline, and survey content through an intuitive interface.\nEvaluations of content quality, time efficiency, and user studies show that\nInteractiveSurvey is an easy-to-use survey generation system that outperforms\nmost LLMs and existing methods in output content quality while remaining highly\ntime-efficient.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.08762v1",
    "published_date": "2025-03-31 04:23:22 UTC",
    "updated_date": "2025-03-31 04:23:22 UTC"
  },
  {
    "arxiv_id": "2504.00053v1",
    "title": "Integrating Large Language Models with Human Expertise for Disease Detection in Electronic Health Records",
    "authors": [
      "Jie Pan",
      "Seungwon Lee",
      "Cheligeer Cheligeer",
      "Elliot A. Martin",
      "Kiarash Riazi",
      "Hude Quan",
      "Na Li"
    ],
    "abstract": "Objective: Electronic health records (EHR) are widely available to complement\nadministrative data-based disease surveillance and healthcare performance\nevaluation. Defining conditions from EHR is labour-intensive and requires\nextensive manual labelling of disease outcomes. This study developed an\nefficient strategy based on advanced large language models to identify multiple\nconditions from EHR clinical notes. Methods: We linked a cardiac registry\ncohort in 2015 with an EHR system in Alberta, Canada. We developed a pipeline\nthat leveraged a generative large language model (LLM) to analyze, understand,\nand interpret EHR notes by prompts based on specific diagnosis, treatment\nmanagement, and clinical guidelines. The pipeline was applied to detect acute\nmyocardial infarction (AMI), diabetes, and hypertension. The performance was\ncompared against clinician-validated diagnoses as the reference standard and\nwidely adopted International Classification of Diseases (ICD) codes-based\nmethods. Results: The study cohort accounted for 3,088 patients and 551,095\nclinical notes. The prevalence was 55.4%, 27.7%, 65.9% and for AMI, diabetes,\nand hypertension, respectively. The performance of the LLM-based pipeline for\ndetecting conditions varied: AMI had 88% sensitivity, 63% specificity, and 77%\npositive predictive value (PPV); diabetes had 91% sensitivity, 86% specificity,\nand 71% PPV; and hypertension had 94% sensitivity, 32% specificity, and 72%\nPPV. Compared with ICD codes, the LLM-based method demonstrated improved\nsensitivity and negative predictive value across all conditions. The monthly\npercentage trends from the detected cases by LLM and reference standard showed\nconsistent patterns.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.00053v1",
    "published_date": "2025-03-31 04:19:18 UTC",
    "updated_date": "2025-03-31 04:19:18 UTC"
  },
  {
    "arxiv_id": "2503.23708v2",
    "title": "Towards Benchmarking and Assessing the Safety and Robustness of Autonomous Driving on Safety-critical Scenarios",
    "authors": [
      "Jingzheng Li",
      "Xianglong Liu",
      "Shikui Wei",
      "Zhijun Chen",
      "Bing Li",
      "Qing Guo",
      "Xianqi Yang",
      "Yanjun Pu",
      "Jiakai Wang"
    ],
    "abstract": "Autonomous driving has made significant progress in both academia and\nindustry, including performance improvements in perception task and the\ndevelopment of end-to-end autonomous driving systems. However, the safety and\nrobustness assessment of autonomous driving has not received sufficient\nattention. Current evaluations of autonomous driving are typically conducted in\nnatural driving scenarios. However, many accidents often occur in edge cases,\nalso known as safety-critical scenarios. These safety-critical scenarios are\ndifficult to collect, and there is currently no clear definition of what\nconstitutes a safety-critical scenario. In this work, we explore the safety and\nrobustness of autonomous driving in safety-critical scenarios. First, we\nprovide a definition of safety-critical scenarios, including static traffic\nscenarios such as adversarial attack scenarios and natural distribution shifts,\nas well as dynamic traffic scenarios such as accident scenarios. Then, we\ndevelop an autonomous driving safety testing platform to comprehensively\nevaluate autonomous driving systems, encompassing not only the assessment of\nperception modules but also system-level evaluations. Our work systematically\nconstructs a safety verification process for autonomous driving, providing\ntechnical support for the industry to establish standardized test framework and\nreduce risks in real-world road deployment.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.23708v2",
    "published_date": "2025-03-31 04:13:32 UTC",
    "updated_date": "2025-04-07 08:26:00 UTC"
  },
  {
    "arxiv_id": "2504.00051v1",
    "title": "The Cursive Transformer",
    "authors": [
      "Sam Greydanus",
      "Zachary Wimpee"
    ],
    "abstract": "Transformers trained on tokenized text, audio, and images can generate\nhigh-quality autoregressive samples. But handwriting data, represented as\nsequences of pen coordinates, remains underexplored. We introduce a novel\ntokenization scheme that converts pen stroke offsets to polar coordinates,\ndiscretizes them into bins, and then turns them into sequences of tokens with\nwhich to train a standard GPT model. This allows us to capture complex stroke\ndistributions without using any specialized architectures (eg. the mixture\ndensity network or the self-advancing ASCII attention head from Graves 2014).\nWith just 3,500 handwritten words and a few simple data augmentations, we are\nable to train a model that can generate realistic cursive handwriting. Our\napproach is simpler and more performant than previous RNN-based methods.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "11 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.00051v1",
    "published_date": "2025-03-31 03:22:27 UTC",
    "updated_date": "2025-03-31 03:22:27 UTC"
  },
  {
    "arxiv_id": "2503.23668v4",
    "title": "MolGround: A Benchmark for Molecular Grounding",
    "authors": [
      "Jiaxin Wu",
      "Ting Zhang",
      "Rubing Chen",
      "Wengyu Zhang",
      "Chen Jason Zhang",
      "Xiao-Yong Wei",
      "Li Qing"
    ],
    "abstract": "Current molecular understanding approaches predominantly focus on the\ndescriptive aspect of human perception, providing broad, topic-level insights.\nHowever, the referential aspect -- linking molecular concepts to specific\nstructural components -- remains largely unexplored. To address this gap, we\npropose a molecular grounding benchmark designed to evaluate a model's\nreferential abilities. We align molecular grounding with established\nconventions in NLP, cheminformatics, and molecular science, showcasing the\npotential of NLP techniques to advance molecular understanding within the AI\nfor Science movement. Furthermore, we constructed the largest molecular\nunderstanding benchmark to date, comprising 117k QA pairs, and developed a\nmulti-agent grounding prototype as proof of concept. This system outperforms\nexisting models, including GPT-4o, and its grounding outputs have been\nintegrated to enhance traditional tasks such as molecular captioning and ATC\n(Anatomical, Therapeutic, Chemical) classification.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.23668v4",
    "published_date": "2025-03-31 02:23:16 UTC",
    "updated_date": "2025-05-01 01:07:04 UTC"
  },
  {
    "arxiv_id": "2504.00050v1",
    "title": "JudgeLRM: Large Reasoning Models as a Judge",
    "authors": [
      "Nuo Chen",
      "Zhiyuan Hu",
      "Qingyun Zou",
      "Jiaying Wu",
      "Qian Wang",
      "Bryan Hooi",
      "Bingsheng He"
    ],
    "abstract": "The rise of Large Language Models (LLMs) as evaluators offers a scalable\nalternative to human annotation, yet existing Supervised Fine-Tuning (SFT) for\njudges approaches often fall short in domains requiring complex reasoning. In\nthis work, we investigate whether LLM judges truly benefit from enhanced\nreasoning capabilities. Through a detailed analysis of reasoning requirements\nacross evaluation tasks, we reveal a negative correlation between SFT\nperformance gains and the proportion of reasoning-demanding samples -\nhighlighting the limitations of SFT in such scenarios. To address this, we\nintroduce JudgeLRM, a family of judgment-oriented LLMs trained using\nreinforcement learning (RL) with judge-wise, outcome-driven rewards. JudgeLRM\nmodels consistently outperform both SFT-tuned and state-of-the-art reasoning\nmodels. Notably, JudgeLRM-3B surpasses GPT-4, and JudgeLRM-7B outperforms\nDeepSeek-R1 by 2.79% in F1 score, particularly excelling in judge tasks\nrequiring deep reasoning.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "preprint",
    "pdf_url": "http://arxiv.org/pdf/2504.00050v1",
    "published_date": "2025-03-31 02:18:51 UTC",
    "updated_date": "2025-03-31 02:18:51 UTC"
  },
  {
    "arxiv_id": "2504.13871v1",
    "title": "Human aversion? Do AI Agents Judge Identity More Harshly Than Performance",
    "authors": [
      "Yuanjun Feng",
      "Vivek Chodhary",
      "Yash Raj Shrestha"
    ],
    "abstract": "This study examines the understudied role of algorithmic evaluation of human\njudgment in hybrid decision-making systems, a critical gap in management\nresearch. While extant literature focuses on human reluctance to follow\nalgorithmic advice, we reverse the perspective by investigating how AI agents\nbased on large language models (LLMs) assess and integrate human input. Our\nwork addresses a pressing managerial constraint: firms barred from deploying\nLLMs directly due to privacy concerns can still leverage them as mediating\ntools (for instance, anonymized outputs or decision pipelines) to guide\nhigh-stakes choices like pricing or discounts without exposing proprietary\ndata. Through a controlled prediction task, we analyze how an LLM-based AI\nagent weights human versus algorithmic predictions. We find that the AI system\nsystematically discounts human advice, penalizing human errors more severely\nthan algorithmic errors--a bias exacerbated when the agent's identity (human vs\nAI) is disclosed and the human is positioned second. These results reveal a\ndisconnect between AI-generated trust metrics and the actual influence of human\njudgment, challenging assumptions about equitable human-AI collaboration. Our\nfindings offer three key contributions. First, we identify a reverse algorithm\naversion phenomenon, where AI agents undervalue human input despite comparable\nerror rates. Second, we demonstrate how disclosure and positional bias interact\nto amplify this effect, with implications for system design. Third, we provide\na framework for indirect LLM deployment that balances predictive power with\ndata privacy. For practitioners, this research emphasize the need to audit AI\nweighting mechanisms, calibrate trust dynamics, and strategically design\ndecision sequences in human-AI systems.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "econ.GN",
      "q-fin.EC"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.13871v1",
    "published_date": "2025-03-31 02:05:27 UTC",
    "updated_date": "2025-03-31 02:05:27 UTC"
  },
  {
    "arxiv_id": "2503.23641v1",
    "title": "Remarks on the Polyak-Lojasiewicz inequality and the convergence of gradient systems",
    "authors": [
      "Arthur Castello B. de Oliveira",
      "Leilei Cui",
      "Eduardo D. Sontag"
    ],
    "abstract": "This work explores generalizations of the Polyak-Lojasiewicz inequality (PLI)\nand their implications for the convergence behavior of gradient flows in\noptimization problems. Motivated by the continuous-time linear quadratic\nregulator (CT-LQR) policy optimization problem -- where only a weaker version\nof the PLI is characterized in the literature -- this work shows that while\nweaker conditions are sufficient for global convergence to, and optimality of\nthe set of critical points of the cost function, the \"profile\" of the gradient\nflow solution can change significantly depending on which \"flavor\" of\ninequality the cost satisfies. After a general theoretical analysis, we focus\non fitting the CT-LQR policy optimization problem to the proposed framework,\nshowing that, in fact, it can never satisfy a PLI in its strongest form. We\nfollow up our analysis with a brief discussion on the difference between\ncontinuous- and discrete-time LQR policy optimization, and end the paper with\nsome intuition on the extension of this framework to optimization problems with\nL1 regularization and solved through proximal gradient flows.",
    "categories": [
      "math.OC",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "math.OC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.23641v1",
    "published_date": "2025-03-31 00:59:56 UTC",
    "updated_date": "2025-03-31 00:59:56 UTC"
  },
  {
    "arxiv_id": "2503.23633v5",
    "title": "GIScience in the Era of Artificial Intelligence: A Research Agenda Towards Autonomous GIS",
    "authors": [
      "Zhenlong Li",
      "Huan Ning",
      "Song Gao",
      "Krzysztof Janowicz",
      "Wenwen Li",
      "Samantha T. Arundel",
      "Chaowei Yang",
      "Budhendra Bhaduri",
      "Shaowen Wang",
      "A-Xing Zhu",
      "Mark Gahegan",
      "Shashi Shekhar",
      "Xinyue Ye",
      "Grant McKenzie",
      "Guido Cervone",
      "Michael E. Hodgson"
    ],
    "abstract": "The advent of generative AI exemplified by large language models (LLMs) opens\nnew ways to represent and compute geographic information and transcends the\nprocess of geographic knowledge production, driving geographic information\nsystems (GIS) towards autonomous GIS. Leveraging LLMs as the decision core,\nautonomous GIS can independently generate and execute geoprocessing workflows\nto perform spatial analysis. In this vision paper, we further elaborate on the\nconcept of autonomous GIS and present a conceptual framework that defines its\nfive autonomous goals, five autonomous levels, five core functions, and three\noperational scales. We demonstrate how autonomous GIS could perform geospatial\ndata retrieval, spatial analysis, and map making with four proof-of-concept GIS\nagents. We conclude by identifying critical challenges and future research\ndirections, including fine-tuning and self-growing decision-cores, autonomous\nmodeling, and examining the societal and practical implications of autonomous\nGIS. By establishing the groundwork for a paradigm shift in GIScience, this\npaper envisions a future where GIS moves beyond traditional workflows to\nautonomously reason, derive, innovate, and advance geospatial solutions to\npressing global challenges. Meanwhile, as we design and deploy increasingly\nintelligent geospatial systems, we carry a responsibility to ensure they are\ndeveloped in socially responsible ways, serve the public good, and support the\ncontinued value of human geographic insight in an AI-augmented future.",
    "categories": [
      "cs.AI",
      "cs.ET",
      "cs.SE"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.23633v5",
    "published_date": "2025-03-31 00:12:48 UTC",
    "updated_date": "2025-04-14 14:21:34 UTC"
  },
  {
    "arxiv_id": "2503.23631v1",
    "title": "Intrinsically-Motivated Humans and Agents in Open-World Exploration",
    "authors": [
      "Aly Lidayan",
      "Yuqing Du",
      "Eliza Kosoy",
      "Maria Rufova",
      "Pieter Abbeel",
      "Alison Gopnik"
    ],
    "abstract": "What drives exploration? Understanding intrinsic motivation is a\nlong-standing challenge in both cognitive science and artificial intelligence;\nnumerous objectives have been proposed and used to train agents, yet there\nremains a gap between human and agent exploration. We directly compare adults,\nchildren, and AI agents in a complex open-ended environment, Crafter, and study\nhow common intrinsic objectives: Entropy, Information Gain, and Empowerment,\nrelate to their behavior. We find that only Entropy and Empowerment are\nconsistently positively correlated with human exploration progress, indicating\nthat these objectives may better inform intrinsic reward design for agents.\nFurthermore, across agents and humans we observe that Entropy initially\nincreases rapidly, then plateaus, while Empowerment increases continuously,\nsuggesting that state diversity may provide more signal in early exploration,\nwhile advanced exploration should prioritize control. Finally, we find\npreliminary evidence that private speech utterances, and particularly goal\nverbalizations, may aid exploration in children.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.23631v1",
    "published_date": "2025-03-31 00:09:00 UTC",
    "updated_date": "2025-03-31 00:09:00 UTC"
  },
  {
    "arxiv_id": "2503.23630v1",
    "title": "Finding Interest Needle in Popularity Haystack: Improving Retrieval by Modeling Item Exposure",
    "authors": [
      "Amit Jaspal",
      "Rahul Agarwal"
    ],
    "abstract": "Recommender systems operate in closed feedback loops, where user interactions\nreinforce popularity bias, leading to over-recommendation of already popular\nitems while under-exposing niche or novel content. Existing bias mitigation\nmethods, such as Inverse Propensity Scoring (IPS) and Off- Policy Correction\n(OPC), primarily operate at the ranking stage or during training, lacking\nexplicit real-time control over exposure dynamics. In this work, we introduce\nan exposure- aware retrieval scoring approach, which explicitly models item\nexposure probability and adjusts retrieval-stage ranking at inference time.\nUnlike prior work, this method decouples exposure effects from engagement\nlikelihood, enabling controlled trade-offs between fairness and engagement in\nlarge-scale recommendation platforms. We validate our approach through online\nA/B experiments in a real-world video recommendation system, demonstrating a\n25% increase in uniquely retrieved items and a 40% reduction in the dominance\nof over-popular content, all while maintaining overall user engagement levels.\nOur results establish a scalable, deployable solution for mitigating popularity\nbias at the retrieval stage, offering a new paradigm for bias-aware\npersonalization.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "2 pages",
    "pdf_url": "http://arxiv.org/pdf/2503.23630v1",
    "published_date": "2025-03-31 00:04:01 UTC",
    "updated_date": "2025-03-31 00:04:01 UTC"
  }
]