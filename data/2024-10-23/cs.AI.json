{
  "date": "2024-10-23",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-10-23 的 arXiv 中文 TLDR 快报！今天 arXiv 的论文主要聚焦 AI 和机器学习领域，包括大型语言模型（LLM）的优化、强化学习、图神经网络和多模态处理等创新方向，令人印象深刻的是如 Self-Supervised Learning for Time Series 和 Asynchronous RLHF 等论文，它们展示了高效算法在时间序列预测和 LLM 训练中的潜力，而作者如 Adrian Weller 和 Brian D. Nord 等知名学者参与的文章也值得关注。\n\n下面，我挑选了今天论文中的重点和有话题度的文章进行简要讨论，先从 AI 和 LLM 相关的高影响力论文入手，再快速掠过其他领域的代表性工作。限于篇幅，我会合并相关主题，并对次要论文简略描述，只保留核心学术术语。\n\n### AI 和 LLM 优化\n- **Self-Supervised Learning for Time Series: A Review & Critique of FITS（自监督时间序列学习：对 FITS 的审视与批评）**  \n  这篇论文审视了 FITS 模型在时间序列预测中的表现，发现它在捕捉周期性和季节性模式上表现出色，但对趋势和随机行为较弱。主要贡献是通过结合 DLinear 的混合方法，实现了在多变量回归任务上的最佳开源模型性能，提升了预测准确性。\n\n- **Asynchronous RLHF: Faster and More Efficient Off-Policy RL for Language Models（异步 RLHF：更快速高效的离策略强化学习用于语言模型）**  \n  作者如 Rishabh Agarwal 和 Aaron Courville 参与，论文提出异步强化学习框架，显著加速 LLM 训练（如 LLaMA 3.1 8B 在指令任务上提速 40%），通过离策略数据优化，减少计算开销，同时保持性能。\n\n- **Backdoor in Seconds: Unlocking Vulnerabilities in Large Pre-trained Models via Model Editing（秒级后门攻击：通过模型编辑利用预训练模型漏洞）**  \n  论文引入 EDT 方法，实现无数据污染的后门攻击，核心是编辑-based 代码书注入，仅需轻量级操作即可破坏模型。主要发现是，攻击对 ViT、CLIP 等模型有效，强调了模型安全隐患。\n\n- **Advancing NLP Security by Leveraging LLMs as Adversarial Engines（利用 LLM 作为对抗引擎提升 NLP 安全）**  \n  论文探讨 LLM 在生成对抗样本（如词汇级攻击）上的潜力，扩展到图像和通用攻击。主要贡献是提出更有效的对抗示例生成框架，提升 NLP 系统鲁棒性。\n\n- **Towards Understanding the Fragility of Multilingual LLMs against Fine-Tuning Attacks（理解多语言 LLM 对微调攻击的脆弱性）**  \n  论文揭示多语言 LLM 在微调中易受攻击，导致安全对齐失效。主要发现是通过 Safety Information Localization 定位关键参数，证明微调攻击可跨语言传播。\n\n- **Neural Network Prediction of Strong Lensing Systems with Domain Adaptation and Uncertainty Quantification（使用域适应和不确定性量化的神经网络预测强引力透镜系统）**  \n  作者 Brian D. Nord 参与，论文结合无监督域适应提升预测精度，针对天文数据。主要贡献是改进 Mean-Variance Estimators，提高了天文图像处理中的不确定性校准。\n\n- **Fast Inference for Augmented Large Language Models（增强型 LLM 的快速推理）**  \n  论文提出 LAMPS 框架，优化 LLM 在 API 调用中的调度，减少内存浪费。主要发现是，通过预测策略提升端到端延迟，适用于资源受限的交互应用。\n\n### 强化学习和多模态处理\n- **1-2-3-Go! Policy Synthesis for Parameterized Markov Decision Processes via Decision-Tree Learning and Generalization（1-2-3-Go! 通过决策树学习和泛化合成参数化 Markov 决策过程策略）**  \n  论文使用决策树泛化策略，绕过大规模状态空间爆炸问题。主要贡献是应用于量化验证基准，显著提升策略性能。\n\n- **Human-Agent Coordination in Games under Incomplete Information via Multi-Step Intent（通过多步意图实现人类-代理协调在信息不完备游戏中）**  \n  论文扩展共享控制游戏框架，支持多步意图预测，提升长时任务效率。主要发现是，IntentMCTS 算法在 Gnomes at Night 测试中减少步骤并降低认知负荷。\n\n- **Dynamic Guided and Domain Applicable Safeguards for Enhanced Security in Large Language Models（动态引导和领域适用的安全机制提升 LLM 安全性）**  \n  论文开发 G4D 多代理框架，使用外部信息生成安全响应指导，抵抗越狱攻击。主要贡献是平衡安全性和功能性，实验显示显著提升鲁棒性。\n\n### 图神经网络和知识图谱\n- **GraphTeam: Facilitating Large Language Models in Graph Analysis via Multi-Agent Collaboration（GraphTeam：通过多代理协作促进 LLM 在图分析中的应用）**  \n  论文提出 GraphTeam 系统，使用多代理协作处理图分析任务。主要发现是，结合知识检索和问题求解模块，提升了 LLM 在图任务的准确性。\n\n- **ZIP-FIT: Embedding-Free Data Selection via Compression-Based Alignment（ZIP-FIT：基于压缩对齐的无嵌入数据选择）**  \n  论文使用 gzip 压缩测量任务对齐，实现高效数据选择。主要贡献是在 Autoformalization 和代码生成任务中，显著提升模型学习效率。\n\n### 其他领域快速掠过\n- **Kenyan Sign Language (KSL) Dataset: Using Artificial Intelligence (AI) in Bridging Communication Barrier among the Deaf Learners（肯尼亚手语数据集：使用 AI 桥接聋人学习者的沟通障碍）**  \n  构建 KSL 数据集，支持英语到手语翻译，主要发现是生成 20,000 手语视频，提升聋人包容性。\n\n- **Screw Geometry Meets Bandits: Incremental Acquisition of Demonstrations to Generate Manipulation Plans（螺线几何遇见 Bandits：增量获取演示生成操作计划）**  \n  结合螺线几何和 Bandit 优化，实现机器人增量学习，主要贡献是提升操作计划生成效率。\n\n- **E2E-Swin-Unet++: An Enhanced End-to-End Swin-Unet Architecture With Dual Decoders For PTMC Segmentation（E2E-Swin-Unet++：增强端到端 Swin-Unet 架构用于甲状腺微小癌分割）**  \n  提出双解码器架构，提升超声图像分割精度，主要用于精确肿瘤定位。\n\n其他论文如医学图像处理、机器人控制和物理建模等，虽然有技术创新，但影响力较小，我仅简要提及：如第13篇的 Bayesian 优化用于机器人抓取、第15篇的粗糙集理论扩展，以及第38篇的流域预测等，它们在各自领域提供实用方法，但未涉及核心 AI 趋势，故从略。\n\n总之，今天的论文突显了 AI 领域的快速迭代，重点如 LLM 安全和高效训练方法值得持续关注，助力读者快速把握前沿动态。明天见！",
  "papers": [
    {
      "arxiv_id": "2410.18318v1",
      "title": "Self-Supervised Learning for Time Series: A Review & Critique of FITS",
      "title_zh": "针对时间序列的自监督学习：FITS 的回顾与批评",
      "authors": [
        "Andreas Løvendahl Eefsen",
        "Nicholas Erup Larsen",
        "Oliver Glozmann Bork Hansen",
        "Thor Højhus Avenstrup"
      ],
      "abstract": "Accurate time series forecasting is a highly valuable endeavour with\napplications across many industries. Despite recent deep learning advancements,\nincreased model complexity, and larger model sizes, many state-of-the-art\nmodels often perform worse or on par with simpler models. One of those cases is\na recently proposed model, FITS, claiming competitive performance with\nsignificantly reduced parameter counts. By training a one-layer neural network\nin the complex frequency domain, we are able to replicate these results. Our\nexperiments on a wide range of real-world datasets further reveal that FITS\nespecially excels at capturing periodic and seasonal patterns, but struggles\nwith trending, non-periodic, or random-resembling behavior. With our two novel\nhybrid approaches, where we attempt to remedy the weaknesses of FITS by\ncombining it with DLinear, we achieve the best results of any known open-source\nmodel on multivariate regression and promising results in multiple/linear\nregression on price datasets, on top of vastly improving upon what FITS\nachieves as a standalone model.",
      "tldr_zh": "该论文审视了时间序列自监督学习中的FITS模型，指出尽管深度学习模型日益复杂，但许多先进模型的表现往往不如简单模型。作者通过在复杂频率域训练单层神经网络，复制了FITS的竞争性结果，并发现FITS在捕捉周期性和季节性模式上表现出色，但对趋势、非周期或随机行为处理较弱。作者提出了两种新混合方法，将FITS与DLinear结合，实现了在多变量回归上的最佳开源模型性能，并在价格数据集的多/线性回归上取得了显著改善。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "arXiv:2307.03756v3 45 pages, 36 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.18318v1",
      "published_date": "2024-10-23 23:03:09 UTC",
      "updated_date": "2024-10-23 23:03:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:21:57.464841"
    },
    {
      "arxiv_id": "2410.18312v1",
      "title": "Countering Autonomous Cyber Threats",
      "title_zh": "对抗自治网络威胁",
      "authors": [
        "Kade M. Heckel",
        "Adrian Weller"
      ],
      "abstract": "With the capability to write convincing and fluent natural language and\ngenerate code, Foundation Models present dual-use concerns broadly and within\nthe cyber domain specifically. Generative AI has already begun to impact\ncyberspace through a broad illicit marketplace for assisting malware\ndevelopment and social engineering attacks through hundreds of\nmalicious-AI-as-a-services tools. More alarming is that recent research has\nshown the potential for these advanced models to inform or independently\nexecute offensive cyberspace operations. However, these previous investigations\nprimarily focused on the threats posed by proprietary models due to the until\nrecent lack of strong open-weight model and additionally leave the impacts of\nnetwork defenses or potential countermeasures unexplored. Critically,\nunderstanding the aptitude of downloadable models to function as offensive\ncyber agents is vital given that they are far more difficult to govern and\nprevent their misuse. As such, this work evaluates several state-of-the-art FMs\non their ability to compromise machines in an isolated network and investigates\ndefensive mechanisms to defeat such AI-powered attacks. Using target machines\nfrom a commercial provider, the most recently released downloadable models are\nfound to be on par with a leading proprietary model at conducting simple cyber\nattacks with common hacking tools against known vulnerabilities. To mitigate\nsuch LLM-powered threats, defensive prompt injection (DPI) payloads for\ndisrupting the malicious cyber agent's workflow are demonstrated to be\neffective. From these results, the implications for AI safety and governance\nwith respect to cybersecurity is analyzed.",
      "tldr_zh": "该研究探讨了基础模型（Foundation Models）在网络领域构成的自主威胁，包括生成恶意软件和执行网络攻击的风险。作者评估了最先进的开源模型在入侵隔离网络中的能力，发现这些模型在进行简单攻击时与领先的专有模型相当。针对此类威胁，研究引入了防御性提示注入（Defensive Prompt Injection，DPI）机制，有效地破坏了恶意 AI 代理的工作流程。最终，分析了这些结果对 AI 安全和治理的深远影响，为强化网络防御提供了重要启示。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CR",
      "comment": "76 pages, MPhil Thesis",
      "pdf_url": "http://arxiv.org/pdf/2410.18312v1",
      "published_date": "2024-10-23 22:46:44 UTC",
      "updated_date": "2024-10-23 22:46:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:22:09.601260"
    },
    {
      "arxiv_id": "2410.18295v1",
      "title": "Kenyan Sign Language (KSL) Dataset: Using Artificial Intelligence (AI) in Bridging Communication Barrier among the Deaf Learners",
      "title_zh": "翻译失败",
      "authors": [
        "Lilian Wanzare",
        "Joel Okutoyi",
        "Maurine Kang'ahi",
        "Mildred Ayere"
      ],
      "abstract": "Kenyan Sign Language (KSL) is the primary language used by the deaf community\nin Kenya. It is the medium of instruction from Pre-primary 1 to university\namong deaf learners, facilitating their education and academic achievement.\nKenyan Sign Language is used for social interaction, expression of needs,\nmaking requests and general communication among persons who are deaf in Kenya.\nHowever, there exists a language barrier between the deaf and the hearing\npeople in Kenya. Thus, the innovation on AI4KSL is key in eliminating the\ncommunication barrier. Artificial intelligence for KSL is a two-year research\nproject (2023-2024) that aims to create a digital open-access AI of spontaneous\nand elicited data from a representative sample of the Kenyan deaf community.\nThe purpose of this study is to develop AI assistive technology dataset that\ntranslates English to KSL as a way of fostering inclusion and bridging language\nbarriers among deaf learners in Kenya. Specific objectives are: Build KSL\ndataset for spoken English and video recorded Kenyan Sign Language and to build\ntranscriptions of the KSL signs to a phonetic-level interface of the sign\nlanguage. In this paper, the methodology for building the dataset is described.\nData was collected from 48 teachers and tutors of the deaf learners and 400\nlearners who are Deaf. Participants engaged mainly in sign language elicitation\ntasks through reading and singing. Findings of the dataset consisted of about\n14,000 English sentences with corresponding KSL Gloss derived from a pool of\nabout 4000 words and about 20,000 signed KSL videos that are either signed\nwords or sentences. The second level of data outcomes consisted of 10,000 split\nand segmented KSL videos. The third outcome of the dataset consists of 4,000\ntranscribed words into five articulatory parameters according to HamNoSys\nsystem.",
      "tldr_zh": "本研究构建了Kenyan Sign Language (KSL)数据集，旨在利用Artificial Intelligence (AI)桥接肯尼亚聋哑学习者与听力正常人群的沟通障碍，促进教育和社会互动。研究方法包括从48名教师和400名聋哑学习者收集数据，通过阅读和唱歌等任务获取自发和诱导数据，构建英语句子与KSL视频的对应关系，并将KSL符号转录到语音级接口。数据集成果包括约14,000个英语句子及其KSL Gloss、20,000个签名视频、10,000个分割视频，以及根据HamNoSys系统转录的4,000个单词。这些贡献为开发AI辅助翻译技术提供了基础，支持聋哑社区的包容性发展。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "14 pages, to be published in 3rd International Conference on\n  Artificial Intelligence and Robotics (MIRG-ICAIR 2023)",
      "pdf_url": "http://arxiv.org/pdf/2410.18295v1",
      "published_date": "2024-10-23 22:01:31 UTC",
      "updated_date": "2024-10-23 22:01:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:22:23.761911"
    },
    {
      "arxiv_id": "2410.18293v2",
      "title": "1-2-3-Go! Policy Synthesis for Parameterized Markov Decision Processes via Decision-Tree Learning and Generalization",
      "title_zh": "翻译失败",
      "authors": [
        "Muqsit Azeem",
        "Debraj Chakraborty",
        "Sudeep Kanav",
        "Jan Kretinsky",
        "Mohammadsadegh Mohagheghi",
        "Stefanie Mohr",
        "Maximilian Weininger"
      ],
      "abstract": "Despite the advances in probabilistic model checking, the scalability of the\nverification methods remains limited. In particular, the state space often\nbecomes extremely large when instantiating parameterized Markov decision\nprocesses (MDPs) even with moderate values. Synthesizing policies for such\n\\emph{huge} MDPs is beyond the reach of available tools. We propose a\nlearning-based approach to obtain a reasonable policy for such huge MDPs.\n  The idea is to generalize optimal policies obtained by model-checking small\ninstances to larger ones using decision-tree learning. Consequently, our method\nbypasses the need for explicit state-space exploration of large models,\nproviding a practical solution to the state-space explosion problem. We\ndemonstrate the efficacy of our approach by performing extensive\nexperimentation on the relevant models from the quantitative verification\nbenchmark set. The experimental results indicate that our policies perform\nwell, even when the size of the model is orders of magnitude beyond the reach\nof state-of-the-art analysis tools.",
      "tldr_zh": "本论文针对参数化Markov Decision Processes (MDPs)的策略合成问题，提出了一种基于决策树学习和泛化的方法，以应对状态空间爆炸导致的验证工具可扩展性不足。方法的核心是通过模型检查小实例的优化策略，并将其泛化到大型实例，从而避免显式探索庞大的状态空间。实验结果显示，该方法在量化验证基准集上的表现优异，即使模型规模远超现有工具的处理能力，生成的策略也能保持良好的性能。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.LO",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.AI",
      "comment": "Extended version of the paper accepted at VMCAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.18293v2",
      "published_date": "2024-10-23 21:57:05 UTC",
      "updated_date": "2025-04-01 06:08:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:22:33.551684"
    },
    {
      "arxiv_id": "2410.18275v1",
      "title": "Screw Geometry Meets Bandits: Incremental Acquisition of Demonstrations to Generate Manipulation Plans",
      "title_zh": "翻译失败",
      "authors": [
        "Dibyendu Das",
        "Aditya Patankar",
        "Nilanjan Chakraborty",
        "C. R. Ramakrishnan",
        "I. V. Ramakrishnan"
      ],
      "abstract": "In this paper, we study the problem of methodically obtaining a sufficient\nset of kinesthetic demonstrations, one at a time, such that a robot can be\nconfident of its ability to perform a complex manipulation task in a given\nregion of its workspace. Although Learning from Demonstrations has been an\nactive area of research, the problems of checking whether a set of\ndemonstrations is sufficient, and systematically seeking additional\ndemonstrations have remained open. We present a novel approach to address these\nopen problems using (i) a screw geometric representation to generate\nmanipulation plans from demonstrations, which makes the sufficiency of a set of\ndemonstrations measurable; (ii) a sampling strategy based on PAC-learning from\nmulti-armed bandit optimization to evaluate the robot's ability to generate\nmanipulation plans in a subregion of its task space; and (iii) a heuristic to\nseek additional demonstration from areas of weakness. Thus, we present an\napproach for the robot to incrementally and actively ask for new demonstration\nexamples until the robot can assess with high confidence that it can perform\nthe task successfully. We present experimental results on two example\nmanipulation tasks, namely, pouring and scooping, to illustrate our approach. A\nshort video on the method: https://youtu.be/R-qICICdEos",
      "tldr_zh": "本论文提出了一种新方法，用于系统地获取足够的运动演示，使机器人能够自信地执行复杂操作任务。该方法利用screw geometric representation从演示生成操作计划，从而量化演示的充分性；结合PAC-learning和multi-armed bandit优化的采样策略评估机器人在任务空间子区域的性能；并采用启发式(heuristic)策略从弱点区域主动寻求额外演示，实现增量式演示获取。实验结果显示，该方法在倒水(pouring)和铲取(scooping)任务上有效提升了机器人的任务执行信心和成功率。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "8 pages, 6 figures, under review in IEEE Robotics and Automation\n  Letters",
      "pdf_url": "http://arxiv.org/pdf/2410.18275v1",
      "published_date": "2024-10-23 20:57:56 UTC",
      "updated_date": "2024-10-23 20:57:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:22:46.018900"
    },
    {
      "arxiv_id": "2410.18267v2",
      "title": "Backdoor in Seconds: Unlocking Vulnerabilities in Large Pre-trained Models via Model Editing",
      "title_zh": "后门攻击秒成：通过模型编辑",
      "authors": [
        "Dongliang Guo",
        "Mengxuan Hu",
        "Zihan Guan",
        "Junfeng Guo",
        "Thomas Hartvigsen",
        "Sheng Li"
      ],
      "abstract": "Large pre-trained models have achieved notable success across a range of\ndownstream tasks. However, recent research shows that a type of adversarial\nattack ($\\textit{i.e.,}$ backdoor attack) can manipulate the behavior of\nmachine learning models through contaminating their training dataset, posing\nsignificant threat in the real-world application of large pre-trained model,\nespecially for those customized models. Therefore, addressing the unique\nchallenges for exploring vulnerability of pre-trained models is of paramount\nimportance. Through empirical studies on the capability for performing backdoor\nattack in large pre-trained models ($\\textit{e.g.,}$ ViT), we find the\nfollowing unique challenges of attacking large pre-trained models: 1) the\ninability to manipulate or even access large training datasets, and 2) the\nsubstantial computational resources required for training or fine-tuning these\nmodels. To address these challenges, we establish new standards for an\neffective and feasible backdoor attack in the context of large pre-trained\nmodels. In line with these standards, we introduce our EDT model, an\n\\textbf{E}fficient, \\textbf{D}ata-free, \\textbf{T}raining-free backdoor attack\nmethod. Inspired by model editing techniques, EDT injects an editing-based\nlightweight codebook into the backdoor of large pre-trained models, which\nreplaces the embedding of the poisoned image with the target image without\npoisoning the training dataset or training the victim model. Our experiments,\nconducted across various pre-trained models such as ViT, CLIP, BLIP, and stable\ndiffusion, and on downstream tasks including image classification, image\ncaptioning, and image generation, demonstrate the effectiveness of our method.\nOur code is available in the supplementary material.",
      "tldr_zh": "该研究揭示了大型预训练模型（如 ViT 和 CLIP）在面临 backdoor attack 时存在的漏洞，强调了无法访问训练数据集和高计算资源需求的挑战。作者提出 EDT 方法，这是一种 Efficient、Data-free 和 Training-free 的攻击技术，通过注入基于模型编辑的轻量级代码本来替换中毒图像的嵌入，而无需污染数据集或重新训练模型。在各种下游任务（如图像分类、图像描述和图像生成）上的实验中，EDT 证明了其有效性，为评估预训练模型的安全性提供了新标准。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.18267v2",
      "published_date": "2024-10-23 20:32:14 UTC",
      "updated_date": "2024-10-25 23:13:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:22:58.282201"
    },
    {
      "arxiv_id": "2410.18252v3",
      "title": "Asynchronous RLHF: Faster and More Efficient Off-Policy RL for Language Models",
      "title_zh": "异步 RLHF：更快且更高效的脱策略强化学习用于语言模型",
      "authors": [
        "Michael Noukhovitch",
        "Shengyi Huang",
        "Sophie Xhonneux",
        "Arian Hosseini",
        "Rishabh Agarwal",
        "Aaron Courville"
      ],
      "abstract": "The dominant paradigm for RLHF is online and on-policy RL: synchronously\ngenerating from the large language model (LLM) policy, labelling with a reward\nmodel, and learning using feedback on the LLM's own outputs. While performant,\nthis paradigm is computationally inefficient. Inspired by classical deep RL\nliterature, we propose separating generation and learning in RLHF. This enables\nasynchronous generation of new samples while simultaneously training on old\nsamples, leading to faster training and more compute-optimal scaling. However,\nasynchronous training relies on an underexplored regime, online but off-policy\nRLHF: learning on samples from previous iterations of our model which give a\nworse training signal. We tackle the fundamental challenge in this regime: how\nmuch off-policyness can we tolerate for asynchronous training to speed up\nlearning but maintain performance? Among several RLHF algorithms we test,\nonline DPO is found to be most robust to off-policy data, and robustness\nincreases with the scale of the policy model. We study further compute\noptimizations for asynchronous RLHF but find that they come at a performance\ncost, giving rise to a trade-off. We verify the scalability of asynchronous\nRLHF by training a general-purpose chatbot from LLaMA 3.1 8B on an\ninstruction-following task ~40% faster than a synchronous run while matching\nfinal performance. Finally, we extend our results to math and reasoning to\ndemonstrate asynchronous RL can finetune Rho 1B on GSM8k ~70% faster while\nmatching synchronous accuracy.",
      "tldr_zh": "本研究提出异步 RLHF 方法，通过分离生成和学习过程，实现更快速和高效的 off-policy 强化学习，用于语言模型训练。这种方法允许异步生成新样本，同时在旧样本上进行训练，从而提升计算效率，尽管面临 off-policy 数据带来的训练信号劣化问题。实验发现，online DPO 算法对 off-policy 数据最鲁棒，且模型规模越大鲁棒性越强；在 LLaMA 3.1 8B 上训练聊天机器人比同步方法快约 40% 并匹配性能，在 GSM8k 上训练 Rho 1B 模型则快约 70% 且保持准确率。总体而言，该方法证明了异步 RLHF 在加速训练的同时维持了性能平衡。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "accepted at ICLR 2025, code at\n  https://github.com/mnoukhov/async_rlhf, integrated into the open-instruct\n  library https://github.com/allenai/open-instruct",
      "pdf_url": "http://arxiv.org/pdf/2410.18252v3",
      "published_date": "2024-10-23 19:59:50 UTC",
      "updated_date": "2025-04-26 08:33:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:23:10.185473"
    },
    {
      "arxiv_id": "2411.03334v3",
      "title": "Neural Network Prediction of Strong Lensing Systems with Domain Adaptation and Uncertainty Quantification",
      "title_zh": "翻译失败",
      "authors": [
        "Shrihan Agarwal",
        "Aleksandra Ćiprijanović",
        "Brian D. Nord"
      ],
      "abstract": "Modeling strong gravitational lenses is computationally expensive for the\ncomplex data from modern and next-generation cosmic surveys. Deep learning has\nemerged as a promising approach for finding lenses and predicting lensing\nparameters, such as the Einstein radius. Mean-variance Estimators (MVEs) are a\ncommon approach for obtaining aleatoric (data) uncertainties from a neural\nnetwork prediction. However, neural networks have not been demonstrated to\nperform well on out-of-domain target data successfully - e.g., when trained on\nsimulated data and applied to real, observational data. In this work, we\nperform the first study of the efficacy of MVEs in combination with\nunsupervised domain adaptation (UDA) on strong lensing data. The source domain\ndata is noiseless, and the target domain data has noise mimicking modern\ncosmology surveys. We find that adding UDA to MVE increases the accuracy on the\ntarget data by a factor of about two over an MVE model without UDA. Including\nUDA also permits much more well-calibrated aleatoric uncertainty predictions.\nAdvancements in this approach may enable future applications of MVE models to\nreal observational data.",
      "tldr_zh": "本研究探讨了使用神经网络预测强引力透镜系统的方法，结合Mean-variance Estimators (MVEs)获取aleatoric不确定性，以及Unsupervised Domain Adaptation (UDA)处理模拟数据与真实观测数据间的领域差异。研究首次评估了MVEs与UDA的结合效果，在来源域（无噪声数据）和目标域（模拟现代宇宙学调查噪声的数据）上进行实验。结果显示，添加UDA使目标数据上的预测准确性提高约两倍，并显著改善了aleatoric不确定性的校准度。这种方法为未来将MVEs模型应用于真实观测数据提供了潜在基础。",
      "categories": [
        "astro-ph.IM",
        "astro-ph.CO",
        "astro-ph.GA",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "astro-ph.IM",
      "comment": "Accepted to the Machine Learning for Physical Sciences workshop at\n  NeurIPS 2024; 24 pages, 2 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2411.03334v3",
      "published_date": "2024-10-23 19:56:57 UTC",
      "updated_date": "2025-01-07 03:01:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:23:59.485268"
    },
    {
      "arxiv_id": "2410.18248v2",
      "title": "Fast Inference for Augmented Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Rana Shahout",
        "Cong Liang",
        "Shiji Xin",
        "Qianru Lao",
        "Yong Cui",
        "Minlan Yu",
        "Michael Mitzenmacher"
      ],
      "abstract": "Augmented Large Language Models (LLMs) enhance the capabilities of standalone\nLLMs by integrating external data sources through API calls. In interactive LLM\napplications, efficient scheduling is crucial for maintaining low request\ncompletion times, directly impacting user engagement. However, these\naugmentations introduce scheduling challenges due to the need to manage limited\nmemory for cached information (KV caches). As a result, traditional size-based\nscheduling algorithms, such as Shortest Job First (SJF), become less effective\nat minimizing completion times. Existing work focuses only on handling requests\nduring API calls by preserving, discarding, or swapping memory without\nconsidering how to schedule requests with API calls. In this paper, we propose\nLAMPS, a novel LLM inference framework for augmented LLMs. LAMPS minimizes\nrequest completion time through a unified scheduling approach that considers\nthe total length of requests and their handling strategies during API calls.\nRecognizing that LLM inference is memory-bound, our approach ranks requests\nbased on their consumption of memory over time, which depends on both the\noutput sizes and how a request is managed during its API calls. To implement\nour scheduling, LAMPS predicts the strategy that minimizes memory waste of a\nrequest during its API calls, aligning with but improving upon existing\napproaches. We also propose starvation prevention techniques and optimizations\nto mitigate the overhead of our scheduling. We implement LAMPS on top of vLLM\nand evaluate its performance against baseline LLM inference systems,\ndemonstrating improvements in end-to-end latency by 27%-85% and reductions in\nTTFT by 4%-96% compared to the existing augmented-LLM system, with even greater\ngains over vLLM.",
      "tldr_zh": "该研究针对 Augmented Large Language Models (LLMs)，提出了一种名为 LAMPS 的新型推理框架，以优化交互式应用的请求调度问题。LAMPS 通过统一的调度策略，考虑请求的总长度和 API 调用期间的内存管理（如 KV caches），根据请求对内存的消耗进行排名，从而最小化完成时间和内存浪费，同时整合了防止饥饿的技术和优化措施。实验结果显示，LAMPS 在 vLLM 基础上实现了端到端延迟降低 27%-85% 以及 TTFT 减少 4%-96%，显著优于现有系统。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.18248v2",
      "published_date": "2024-10-23 19:53:30 UTC",
      "updated_date": "2024-10-25 19:18:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:23:34.464917"
    },
    {
      "arxiv_id": "2410.18242v2",
      "title": "Human-Agent Coordination in Games under Incomplete Information via Multi-Step Intent",
      "title_zh": "翻译失败",
      "authors": [
        "Shenghui Chen",
        "Ruihan Zhao",
        "Sandeep Chinchali",
        "Ufuk Topcu"
      ],
      "abstract": "Strategic coordination between autonomous agents and human partners under\nincomplete information can be modeled as turn-based cooperative games. We\nextend a turn-based game under incomplete information, the shared-control game,\nto allow players to take multiple actions per turn rather than a single action.\nThe extension enables the use of multi-step intent, which we hypothesize will\nimprove performance in long-horizon tasks. To synthesize cooperative policies\nfor the agent in this extended game, we propose an approach featuring a memory\nmodule for a running probabilistic belief of the environment dynamics and an\nonline planning algorithm called IntentMCTS. This algorithm strategically\nselects the next action by leveraging any communicated multi-step intent via\nreward augmentation while considering the current belief. Agent-to-agent\nsimulations in the Gnomes at Night testbed demonstrate that IntentMCTS requires\nfewer steps and control switches than baseline methods. A human-agent user\nstudy corroborates these findings, showing an 18.52% higher success rate\ncompared to the heuristic baseline and a 5.56% improvement over the single-step\nprior work. Participants also report lower cognitive load, frustration, and\nhigher satisfaction with the IntentMCTS agent partner.",
      "tldr_zh": "该研究扩展了不完全信息下的共享控制游戏(shared-control game)，允许玩家每回合采取多个动作，以利用多步意图(multi-step intent)提升人-智能体协调在长时域任务中的性能。研究提出了一种合成合作策略的方法，包括一个记忆模块用于维护环境动态的概率信念，以及在线规划算法IntentMCTS，该算法通过奖励增强和当前信念来选择动作，同时考虑传达的多步意图。在Gnomes at Night测试环境中的代理模拟和人机用户研究中，IntentMCTS比基线方法减少了步骤和控制切换，成功率提高了18.52%，并降低了用户的认知负荷和挫败感，同时提升了满意度。",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.18242v2",
      "published_date": "2024-10-23 19:37:19 UTC",
      "updated_date": "2025-02-17 22:35:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:23:45.937248"
    },
    {
      "arxiv_id": "2410.18241v1",
      "title": "Characterising Open Source Co-opetition in Company-hosted Open Source Software Projects: The Cases of PyTorch, TensorFlow, and Transformers",
      "title_zh": "公司托管开源软件项目中开源合作竞争的特征化：PyTorch、TensorFlow 和 Transformers 的案例",
      "authors": [
        "Cailean Osborne",
        "Farbod Daneshyan",
        "Runzhi He",
        "Hengzhi Ye",
        "Yuxia Zhang",
        "Minghui Zhou"
      ],
      "abstract": "Companies, including market rivals, have long collaborated on the development\nof open source software (OSS), resulting in a tangle of co-operation and\ncompetition known as \"open source co-opetition\". While prior work investigates\nopen source co-opetition in OSS projects that are hosted by vendor-neutral\nfoundations, we have a limited understanding thereof in OSS projects that are\nhosted and governed by one company. Given their prevalence, it is timely to\ninvestigate open source co-opetition in such contexts. Towards this end, we\nconduct a mixed-methods analysis of three company-hosted OSS projects in the\nartificial intelligence (AI) industry: Meta's PyTorch (prior to its donation to\nthe Linux Foundation), Google's TensorFlow, and Hugging Face's Transformers. We\ncontribute three key findings. First, while the projects exhibit similar code\nauthorship patterns between host and external companies (80%/20% of commits),\ncollaborations are structured differently (e.g., decentralised vs.\nhub-and-spoke networks). Second, host and external companies engage in\nstrategic, non-strategic, and contractual collaborations, with varying\nincentives and collaboration practices. Some of the observed collaborations are\nspecific to the AI industry (e.g., hardware-software optimizations or AI model\nintegrations), while others are typical of the broader software industry (e.g.,\nbug fixing or task outsourcing). Third, single-vendor governance creates a\npower imbalance that influences open source co-opetition practices and\npossibilities, from the host company's singular decision-making power (e.g.,\nthe risk of license change) to their community involvement strategy (e.g., from\nover-control to over-delegation). We conclude with recommendations for future\nresearch.",
      "tldr_zh": "本研究探讨了公司托管开源软件项目中的开源合作竞争（open source co-opetition），通过混合方法分析 Meta 的 PyTorch、Google 的 TensorFlow 和 Hugging Face 的 Transformers 三个 AI 行业案例。结果显示，这些项目在代码贡献上类似（主机公司占80%，外部20%），但协作结构不同，如去中心化与中心辐射网络，且涉及战略、非战略和合同合作，动机包括 AI 特定优化（如硬件-软件整合）及软件行业常见实践（如修复 bug）。此外，单供应商治理导致权力不平衡，影响合作动态（如许可证变更风险和社区参与策略），并为未来研究提供建议。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.SE",
      "comment": "26 pages, 2 figures, 9 tables",
      "pdf_url": "http://arxiv.org/pdf/2410.18241v1",
      "published_date": "2024-10-23 19:35:41 UTC",
      "updated_date": "2024-10-23 19:35:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:24:11.451834"
    },
    {
      "arxiv_id": "2410.18239v1",
      "title": "E2E-Swin-Unet++: An Enhanced End-to-End Swin-Unet Architecture With Dual Decoders For PTMC Segmentation",
      "title_zh": "E2E-Swin-Unet++：一种增强的端到端 Swin-Unet 架构，带有双解码器，用于 PTMC 分",
      "authors": [
        "Maryam Dialameh",
        "Hossein Rajabzadeh",
        "Moslem Sadeghi-Goughari",
        "Jung Suk Sim",
        "Hyock Ju Kwon"
      ],
      "abstract": "Efficiently managing papillary thyroid microcarcinoma (PTMC) while minimizing\npatient discomfort poses a significant clinical challenge. Radiofrequency\nablation (RFA) offers a less invasive alternative to surgery and radiation\ntherapy for PTMC treatment, characterized by shorter recovery times and reduced\npain. As an image-guided procedure, RFA generates localized heat by delivering\nhigh-frequency electrical currents through electrodes to the targeted area\nunder ultrasound imaging guidance. However, the precision and skill required by\noperators for accurate guidance using current ultrasound B-mode imaging\ntechnologies remain significant challenges. To address these challenges, we\ndevelop a novel AI segmentation model, E2E-Swin-Unet++. This model enhances\nultrasound B-mode imaging by enabling real-time identification and segmentation\nof PTMC tumors and monitoring of the region of interest for precise targeting\nduring treatment. E2E-Swin- Unet++ is an advanced end-to-end extension of the\nSwin-Unet architecture, incorporating thyroid region information to minimize\nthe risk of false PTMC segmentation while providing fast inference\ncapabilities. Experimental results on a real clinical RFA dataset demonstrate\nthe superior performance of E2E-Swin-Unet++ compared to related models. Our\nproposed solution significantly improves the precision and control of RFA\nablation treatment by enabling real-time identification and segmentation of\nPTMC margins during the procedure.",
      "tldr_zh": "该研究针对甲状腺乳头状微小癌 (PTMC) 的射频消融 (RFA) 治疗挑战，提出了一种新型 AI 模型 E2E-Swin-Unet++，以提升超声 B 模式成像的精确性和实时性。E2E-Swin-Unet++ 是 Swin-Unet 架构的增强版本，采用端到端设计和双解码器，整合甲状腺区域信息来减少假分割并提供快速推理能力。在真实临床 RFA 数据集上的实验结果显示，该模型优于相关基线模型，提高了 PTMC 肿瘤的识别和分割精度，从而显著提升 RFA 治疗的精确控制。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.18239v1",
      "published_date": "2024-10-23 19:33:33 UTC",
      "updated_date": "2024-10-23 19:33:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:24:23.691501"
    },
    {
      "arxiv_id": "2410.18237v1",
      "title": "Bayesian optimization for robust robotic grasping using a sensorized compliant hand",
      "title_zh": "基于传感器化柔顺手的鲁棒机器人抓取贝叶斯优化",
      "authors": [
        "Juan G. Lechuz-Sierra",
        "Ana Elvira H. Martin",
        "Ashok M. Sundaram",
        "Ruben Martinez-Cantin",
        "Máximo A. Roa"
      ],
      "abstract": "One of the first tasks we learn as children is to grasp objects based on our\ntactile perception. Incorporating such skill in robots will enable multiple\napplications, such as increasing flexibility in industrial processes or\nproviding assistance to people with physical disabilities. However, the\ndifficulty lies in adapting the grasping strategies to a large variety of tasks\nand objects, which can often be unknown. The brute-force solution is to learn\nnew grasps by trial and error, which is inefficient and ineffective. In\ncontrast, Bayesian optimization applies active learning by adding information\nto the approximation of an optimal grasp. This paper proposes the use of\nBayesian optimization techniques to safely perform robotic grasping. We analyze\ndifferent grasp metrics to provide realistic grasp optimization in a real\nsystem including tactile sensors. An experimental evaluation in the robotic\nsystem shows the usefulness of the method for performing unknown object\ngrasping even in the presence of noise and uncertainty inherent to a real-world\nenvironment.",
      "tldr_zh": "这篇论文提出使用贝叶斯优化（Bayesian optimization）来提升机器人抓取的鲁棒性，特别针对带传感器的顺应手（sensorized compliant hand），以适应各种未知物体和任务。方法通过主动学习和抓取指标分析，避免了低效的试错策略，并在真实系统中整合触觉传感器进行优化。实验评估显示，该技术在噪声和不确定性环境下表现出色，能够有效实现未知物体抓取，为工业应用和辅助残疾人提供灵活解决方案。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.18237v1",
      "published_date": "2024-10-23 19:33:14 UTC",
      "updated_date": "2024-10-23 19:33:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:24:34.592248"
    },
    {
      "arxiv_id": "2410.18221v1",
      "title": "Data Augmentation for Automated Adaptive Rodent Training",
      "title_zh": "翻译失败",
      "authors": [
        "Dibyendu Das",
        "Alfredo Fontanini",
        "Joshua F. Kogan",
        "Haibin Ling",
        "C. R. Ramakrishnan",
        "I. V. Ramakrishnan"
      ],
      "abstract": "Fully optimized automation of behavioral training protocols for lab animals\nlike rodents has long been a coveted goal for researchers. It is an otherwise\nlabor-intensive and time-consuming process that demands close interaction\nbetween the animal and the researcher. In this work, we used a data-driven\napproach to optimize the way rodents are trained in labs. In pursuit of our\ngoal, we looked at data augmentation, a technique that scales well in data-poor\nenvironments. Using data augmentation, we built several artificial rodent\nmodels, which in turn would be used to build an efficient and automatic\ntrainer. Then we developed a novel similarity metric based on the action\nprobability distribution to measure the behavioral resemblance of our models to\nthat of real rodents.",
      "tldr_zh": "该研究旨在优化实验室啮齿动物的行为训练自动化，以减少研究人员的劳动密集型互动。研究采用数据驱动方法，利用 data augmentation 技术构建多个 artificial rodent models，这些模型用于开发高效的自动训练器。同时，论文提出了一种基于 action probability distribution 的 novel similarity metric，用于评估模型行为与真实啮齿动物行为的相似度，从而提升训练过程的适应性和准确性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "5 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.18221v1",
      "published_date": "2024-10-23 18:51:11 UTC",
      "updated_date": "2024-10-23 18:51:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:24:45.932556"
    },
    {
      "arxiv_id": "2411.04133v1",
      "title": "Enhancement of Approximation Spaces by the Use of Primals and Neighborhood",
      "title_zh": "翻译失败",
      "authors": [
        "A. Çaksu Güler"
      ],
      "abstract": "Rough set theory is one of the most widely used and significant approaches\nfor handling incomplete information. It divides the universe in the beginning\nand uses equivalency relations to produce blocks. Numerous generalized rough\nset models have been put out and investigated in an effort to increase\nflexibility and extend the range of possible uses. We introduce four new\ngeneralized rough set models that draw inspiration from \"neighborhoods and\nprimals\" in order to make a contribution to this topic. By minimizing the\nuncertainty regions, these models are intended to assist decision makers in\nmore effectively analyzing and evaluating the provided data. We verify this\ngoal by demonstrating that the existing models outperform certain current\nmethod approaches in terms of improving the approximation operators (upper and\nlower) and accuracy measurements. We claim that the current models can preserve\nnearly all significant aspects associated with the rough set model. Preserving\nthe monotonic property, which enables us to assess data uncertainty and boost\nconfidence in outcomes, is one of the intriguing characterizations derived from\nthe existing models. With the aid of specific instances, we also compare the\nareas of the current approach. Finally, we demonstrate that the new strategy we\ndefine for our everyday health-related problem yields more accurate findings.",
      "tldr_zh": "这篇论文基于Rough set theory，引入了四种新的广义粗糙集模型，通过利用neighborhoods and primals来增强近似空间，从而最小化不确定区域并帮助决策者更有效地分析数据。相比现有方法，这些模型在改善approximation operators（上近似和下近似运算符）以及准确性测量方面表现出色，并保留了monotonic property等关键特性，以评估数据不确定性和提升结果置信度。最后，通过具体例子验证，新策略在日常健康相关问题上产生了更准确的发现。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.04133v1",
      "published_date": "2024-10-23 18:49:13 UTC",
      "updated_date": "2024-10-23 18:49:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:24:58.942933"
    },
    {
      "arxiv_id": "2410.18218v1",
      "title": "Optimizing the role of human evaluation in LLM-based spoken document summarization systems",
      "title_zh": "优化人类评估在基于LLM的口语文档摘要系统中的作用",
      "authors": [
        "Margaret Kroll",
        "Kelsey Kraus"
      ],
      "abstract": "The emergence of powerful LLMs has led to a paradigm shift in abstractive\nsummarization of spoken documents. The properties that make LLMs so valuable\nfor this task -- creativity, ability to produce fluent speech, and ability to\nabstract information from large corpora -- also present new challenges to\nevaluating their content. Quick, cost-effective automatic evaluations such as\nROUGE and BERTScore offer promise, but do not yet show competitive performance\nwhen compared to human evaluations. We draw on methodologies from the social\nsciences to propose an evaluation paradigm for spoken document summarization\nexplicitly tailored for generative AI content. We provide detailed evaluation\ncriteria and best practices guidelines to ensure robustness in the experimental\ndesign, replicability, and trustworthiness of human evaluation studies. We\nadditionally include two case studies that show how these human-in-the-loop\nevaluation methods have been implemented at a major U.S. technology company.",
      "tldr_zh": "这篇论文探讨了在基于LLMs的口头文档总结系统中优化人类评估的作用，强调LLMs的创造力和抽象能力虽提升了总结质量，但也增加了评估挑战。论文借鉴社会科学的Methodology，提出一种专为生成AI内容设计的评估范式，包括详细的评估标准和最佳实践指南，以确保实验设计的稳健性、可复制性和可信度。研究发现，自动评估如ROUGE和BERTScore虽快速且成本有效，但性能不如人类评估；同时，通过两个案例研究，展示了这些人类参与方法在一家主要美国科技公司的实际实施。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.18218v1",
      "published_date": "2024-10-23 18:37:14 UTC",
      "updated_date": "2024-10-23 18:37:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:25:10.742559"
    },
    {
      "arxiv_id": "2410.18216v1",
      "title": "Neural Cover Selection for Image Steganography",
      "title_zh": "翻译失败",
      "authors": [
        "Karl Chahine",
        "Hyeji Kim"
      ],
      "abstract": "In steganography, selecting an optimal cover image, referred to as cover\nselection, is pivotal for effective message concealment. Traditional methods\nhave typically employed exhaustive searches to identify images that conform to\nspecific perceptual or complexity metrics. However, the relationship between\nthese metrics and the actual message hiding efficacy of an image is unclear,\noften yielding less-than-ideal steganographic outcomes. Inspired by recent\nadvancements in generative models, we introduce a novel cover selection\nframework, which involves optimizing within the latent space of pretrained\ngenerative models to identify the most suitable cover images, distinguishing\nitself from traditional exhaustive search methods. Our method shows significant\nadvantages in message recovery and image quality. We also conduct an\ninformation-theoretic analysis of the generated cover images, revealing that\nmessage hiding predominantly occurs in low-variance pixels, reflecting the\nwaterfilling algorithm's principles in parallel Gaussian channels. Our code can\nbe found at:\nhttps://github.com/karlchahine/Neural-Cover-Selection-for-Image-Steganography.",
      "tldr_zh": "这篇论文针对图像隐写术(steganography)中的封面选择(cover selection)问题，提出了一种新框架，通过在预训练生成模型的潜在空间(latent space)中优化图像选择，以取代传统穷举搜索方法，从而提升消息隐藏的有效性。实验结果显示，该方法显著提高了消息恢复和图像质量。作者还进行了信息理论分析，发现消息隐藏主要发生在低方差(variance)像素中，这与水填充算法(waterfilling algorithm)在并行高斯通道中的原理相符。该框架为隐写术应用提供了更高效的解决方案。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.18216v1",
      "published_date": "2024-10-23 18:32:34 UTC",
      "updated_date": "2024-10-23 18:32:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:25:23.039659"
    },
    {
      "arxiv_id": "2410.18215v1",
      "title": "Advancing NLP Security by Leveraging LLMs as Adversarial Engines",
      "title_zh": "翻译失败",
      "authors": [
        "Sudarshan Srinivasan",
        "Maria Mahbub",
        "Amir Sadovnik"
      ],
      "abstract": "This position paper proposes a novel approach to advancing NLP security by\nleveraging Large Language Models (LLMs) as engines for generating diverse\nadversarial attacks. Building upon recent work demonstrating LLMs'\neffectiveness in creating word-level adversarial examples, we argue for\nexpanding this concept to encompass a broader range of attack types, including\nadversarial patches, universal perturbations, and targeted attacks. We posit\nthat LLMs' sophisticated language understanding and generation capabilities can\nproduce more effective, semantically coherent, and human-like adversarial\nexamples across various domains and classifier architectures. This paradigm\nshift in adversarial NLP has far-reaching implications, potentially enhancing\nmodel robustness, uncovering new vulnerabilities, and driving innovation in\ndefense mechanisms. By exploring this new frontier, we aim to contribute to the\ndevelopment of more secure, reliable, and trustworthy NLP systems for critical\napplications.",
      "tldr_zh": "这篇立场论文提出了一种创新方法，通过利用大型语言模型 (LLMs) 作为生成引擎，来推进自然语言处理 (NLP) 安全领域的发展。论文扩展了 LLMs 在创建对抗攻击方面的应用，从传统的词级对抗示例扩展到对抗补丁、通用扰动和针对性攻击，利用 LLMs 的高级语言理解和生成能力来产生更有效、语义连贯且类似人类的对抗示例。这种方法有望提升模型的鲁棒性、揭示新漏洞，并驱动防御机制的创新，从而构建更安全可靠的 NLP 系统。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "5 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.18215v1",
      "published_date": "2024-10-23 18:32:03 UTC",
      "updated_date": "2024-10-23 18:32:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:25:34.289977"
    },
    {
      "arxiv_id": "2410.18210v2",
      "title": "Towards Understanding the Fragility of Multilingual LLMs against Fine-Tuning Attacks",
      "title_zh": "翻译失败",
      "authors": [
        "Samuele Poppi",
        "Zheng-Xin Yong",
        "Yifei He",
        "Bobbie Chern",
        "Han Zhao",
        "Aobo Yang",
        "Jianfeng Chi"
      ],
      "abstract": "Recent advancements in Large Language Models (LLMs) have sparked widespread\nconcerns about their safety. Recent work demonstrates that safety alignment of\nLLMs can be easily removed by fine-tuning with a few adversarially chosen\ninstruction-following examples, i.e., fine-tuning attacks. We take a further\nstep to understand fine-tuning attacks in multilingual LLMs. We first discover\ncross-lingual generalization of fine-tuning attacks: using a few adversarially\nchosen instruction-following examples in one language, multilingual LLMs can\nalso be easily compromised (e.g., multilingual LLMs fail to refuse harmful\nprompts in other languages). Motivated by this finding, we hypothesize that\nsafety-related information is language-agnostic and propose a new method termed\nSafety Information Localization (SIL) to identify the safety-related\ninformation in the model parameter space. Through SIL, we validate this\nhypothesis and find that only changing 20% of weight parameters in fine-tuning\nattacks can break safety alignment across all languages. Furthermore, we\nprovide evidence to the alternative pathways hypothesis for why freezing\nsafety-related parameters does not prevent fine-tuning attacks, and we\ndemonstrate that our attack vector can still jailbreak LLMs adapted to new\nlanguages.",
      "tldr_zh": "该研究揭示了多语言Large Language Models (LLMs)对fine-tuning attacks的脆弱性，发现使用少量一种语言的敌对指令示例即可破坏模型在其他语言的安全对齐，导致LLMs无法拒绝有害提示。作者提出Safety Information Localization (SIL)方法，验证安全相关信息在模型参数空间中是语言无关的，并发现只需改变20%的权重参数即可在所有语言中打破安全对齐。此外，实验证据表明，冻结安全相关参数无法有效防范此类攻击，且攻击方法适用于适应新语言的LLMs。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "15 pages, 6 figures, 7 tables",
      "pdf_url": "http://arxiv.org/pdf/2410.18210v2",
      "published_date": "2024-10-23 18:27:36 UTC",
      "updated_date": "2025-02-27 19:17:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:25:46.810933"
    },
    {
      "arxiv_id": "2410.18202v1",
      "title": "PyTSC: A Unified Platform for Multi-Agent Reinforcement Learning in Traffic Signal Control",
      "title_zh": "翻译失败",
      "authors": [
        "Rohit Bokade",
        "Xiaoning Jin"
      ],
      "abstract": "Multi-Agent Reinforcement Learning (MARL) presents a promising approach for\naddressing the complexity of Traffic Signal Control (TSC) in urban\nenvironments. However, existing platforms for MARL-based TSC research face\nchallenges such as slow simulation speeds and convoluted, difficult-to-maintain\ncodebases. To address these limitations, we introduce PyTSC, a robust and\nflexible simulation environment that facilitates the training and evaluation of\nMARL algorithms for TSC. PyTSC integrates multiple simulators, such as SUMO and\nCityFlow, and offers a streamlined API, empowering researchers to explore a\nbroad spectrum of MARL approaches efficiently. PyTSC accelerates\nexperimentation and provides new opportunities for advancing intelligent\ntraffic management systems in real-world applications.",
      "tldr_zh": "该研究针对多智能体强化学习（MARL）在交通信号控制（TSC）中的应用，指出现有平台存在模拟速度慢和代码维护复杂的问题。论文引入PyTSC，这是一个统一的鲁棒模拟环境，支持MARL算法的训练和评估，并集成了SUMO和CityFlow等模拟器，提供简化的API以提升研究效率。PyTSC通过加速实验过程，为探索智能交通管理系统在真实世界的应用提供了新机遇。",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "13 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.18202v1",
      "published_date": "2024-10-23 18:10:38 UTC",
      "updated_date": "2024-10-23 18:10:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:27:59.244554"
    },
    {
      "arxiv_id": "2410.18194v2",
      "title": "ZIP-FIT: Embedding-Free Data Selection via Compression-Based Alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Elyas Obbad",
        "Iddah Mlauzi",
        "Brando Miranda",
        "Rylan Schaeffer",
        "Kamal Obbad",
        "Suhana Bedi",
        "Sanmi Koyejo"
      ],
      "abstract": "Data selection is crucial for optimizing language model (LM) performance on\nspecific tasks, yet most existing methods fail to effectively consider the\ntarget task distribution.\n  Current approaches either ignore task-specific requirements entirely or rely\non approximations that fail to capture the nuanced patterns needed for tasks\nlike Autoformalization or code generation.\n  Methods that do consider the target distribution often rely on simplistic,\nsometimes noisy, representations, like hashed n-gram features, which can lead\nto collisions and introduce noise.\n  We introduce ZIP-FIT, a data selection framework that uses gzip compression\nto directly measure alignment between potential training data and the target\ntask distribution.\n  In extensive evaluations on Autoformalization and Python code generation,\nZIP-FIT significantly outperforms leading baselines like DSIR and D4.\n  Models trained on ZIP-FIT-selected data achieve their lowest cross-entropy\nloss up to 85.1\\% faster than baselines, demonstrating that better task\nalignment leads to more efficient learning.\n  In addition, ZIP-FIT performs selection up to 65.8\\% faster than DSIR and two\norders of magnitude faster than D4.\n  Notably, ZIP-FIT shows that smaller, well-aligned datasets often outperform\nlarger but less targeted ones, demonstrating that a small amount of higher\nquality data is superior to a large amount of lower quality data.\n  Our results imply that task-aware data selection is crucial for efficient\ndomain adaptation, and that compression offers a principled way to measure task\nalignment.\n  By showing that targeted data selection can dramatically improve\ntask-specific performance, our work provides new insights into the relationship\nbetween data quality, task alignment, and model learning efficiency.",
      "tldr_zh": "该研究提出ZIP-FIT，一种基于gzip压缩的嵌入无关（Embedding-Free）数据选择框架，用于直接测量训练数据与目标任务分布的alignment，从而解决现有方法忽略任务特定模式的问题。  \n在Autoformalization和Python代码生成任务的评估中，ZIP-FIT显著优于DSIR和D4等基线，使模型训练达到最低交叉熵损失快达85.1%，并将选择过程加速至比DSIR快65.8%和比D4快两个数量级。  \n结果表明，更小且更好地对齐的数据集往往优于更大的低质量数据集，这为高效的领域适应提供了新洞见，强调了任务感知数据选择的重要性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.18194v2",
      "published_date": "2024-10-23 18:01:06 UTC",
      "updated_date": "2025-04-12 19:39:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:28:11.222307"
    },
    {
      "arxiv_id": "2410.18164v1",
      "title": "TabDPT: Scaling Tabular Foundation Models",
      "title_zh": "TabDPT：扩展表格基础模型",
      "authors": [
        "Junwei Ma",
        "Valentin Thomas",
        "Rasa Hosseinzadeh",
        "Hamidreza Kamkari",
        "Alex Labach",
        "Jesse C. Cresswell",
        "Keyvan Golestan",
        "Guangwei Yu",
        "Maksims Volkovs",
        "Anthony L. Caterini"
      ],
      "abstract": "The challenges faced by neural networks on tabular data are well-documented\nand have hampered the progress of tabular foundation models. Techniques\nleveraging in-context learning (ICL) have shown promise here, allowing for\ndynamic adaptation to unseen data. ICL can provide predictions for entirely new\ndatasets without further training or hyperparameter tuning, therefore providing\nvery fast inference when encountering a novel task. However, scaling ICL for\ntabular data remains an issue: approaches based on large language models cannot\nefficiently process numeric tables, and tabular-specific techniques have not\nbeen able to effectively harness the power of real data to improve performance\nand generalization. We are able to overcome these challenges by training\ntabular-specific ICL-based architectures on real data with self-supervised\nlearning and retrieval, combining the best of both worlds. Our resulting model\n-- the Tabular Discriminative Pre-trained Transformer (TabDPT) -- achieves\nstate-of-the-art performance on the CC18 (classification) and CTR23\n(regression) benchmarks with no task-specific fine-tuning, demonstrating the\nadapatability and speed of ICL once the model is pre-trained. TabDPT also\ndemonstrates strong scaling as both model size and amount of available data\nincrease, pointing towards future improvements simply through the curation of\nlarger tabular pre-training datasets and training larger models.",
      "tldr_zh": "本文探讨了神经网络在处理表格数据时面临的挑战，特别是阻碍表格基础模型（tabular foundation models）的进展，并提出了一种基于 in-context learning (ICL) 的解决方案。研究团队训练了 Tabular Discriminative Pre-trained Transformer (TabDPT)，通过在真实数据上应用 self-supervised learning 和 retrieval 技术，克服了现有方法的局限性，实现高效处理数值表格和提升泛化能力。TabDPT 在 CC18（分类）和 CTR23（回归）基准上无需任务特定微调就达到了最先进性能，并展示了随着模型规模和数据量增加的强扩展性，为未来更大规模表格模型的发展提供了潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Minimal TabDPT interface to provide predictions on new datasets\n  available at the following link: https://github.com/layer6ai-labs/TabDPT",
      "pdf_url": "http://arxiv.org/pdf/2410.18164v1",
      "published_date": "2024-10-23 18:00:00 UTC",
      "updated_date": "2024-10-23 18:00:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:28:23.017879"
    },
    {
      "arxiv_id": "2410.18077v1",
      "title": "ALTA: Compiler-Based Analysis of Transformers",
      "title_zh": "ALTA：基于编译器的 Transformer 分析",
      "authors": [
        "Peter Shaw",
        "James Cohan",
        "Jacob Eisenstein",
        "Kenton Lee",
        "Jonathan Berant",
        "Kristina Toutanova"
      ],
      "abstract": "We propose a new programming language called ALTA and a compiler that can map\nALTA programs to Transformer weights. ALTA is inspired by RASP, a language\nproposed by Weiss et al. (2021), and Tracr (Lindner et al., 2023), a compiler\nfrom RASP programs to Transformer weights. ALTA complements and extends this\nprior work, offering the ability to express loops and to compile programs to\nUniversal Transformers, among other advantages. ALTA allows us to\nconstructively show how Transformers can represent length-invariant algorithms\nfor computing parity and addition, as well as a solution to the SCAN benchmark\nof compositional generalization tasks, without requiring intermediate\nscratchpad decoding steps. We also propose tools to analyze cases where the\nexpressibility of an algorithm is established, but end-to-end training on a\ngiven training set fails to induce behavior consistent with the desired\nalgorithm. To this end, we explore training from ALTA execution traces as a\nmore fine-grained supervision signal. This enables additional experiments and\ntheoretical analyses relating the learnability of various algorithms to data\navailability and modeling decisions, such as positional encodings. We make the\nALTA framework -- language specification, symbolic interpreter, and weight\ncompiler -- available to the community to enable further applications and\ninsights.",
      "tldr_zh": "本研究提出了一种名为 ALTA 的新编程语言及其编译器，用于将 ALTA 程序映射到 Transformer 权重，从而分析和扩展 Transformer 的功能。ALTA 基于 RASP 和 Tracr 的灵感，增加了对循环的支持，并能编译到 Universal Transformers 等结构，展示了 Transformers 如何实现长度不变的算法，如计算奇偶性、加法，以及解决 SCAN benchmark 的组合泛化任务，而无需中间 scratchpad 解码步骤。该框架还提供工具分析算法的可表达性与训练不一致问题，通过 ALTA 执行痕迹作为精细监督信号，探讨了算法可学习性与数据可用性、位置编码等因素的关系。最终，研究开源了 ALTA 框架，包括语言规范、符号解释器和权重编译器，以促进进一步的应用和洞见。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.18077v1",
      "published_date": "2024-10-23 17:58:49 UTC",
      "updated_date": "2024-10-23 17:58:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:28:35.223276"
    },
    {
      "arxiv_id": "2410.18076v3",
      "title": "Leveraging Skills from Unlabeled Prior Data for Efficient Online Exploration",
      "title_zh": "翻译失败",
      "authors": [
        "Max Wilcoxson",
        "Qiyang Li",
        "Kevin Frans",
        "Sergey Levine"
      ],
      "abstract": "Unsupervised pretraining has been transformative in many supervised domains.\nHowever, applying such ideas to reinforcement learning (RL) presents a unique\nchallenge in that fine-tuning does not involve mimicking task-specific data,\nbut rather exploring and locating the solution through iterative\nself-improvement. In this work, we study how unlabeled offline trajectory data\ncan be leveraged to learn efficient exploration strategies. While prior data\ncan be used to pretrain a set of low-level skills, or as additional off-policy\ndata for online RL, it has been unclear how to combine these ideas effectively\nfor online exploration. Our method SUPE (Skills from Unlabeled Prior data for\nExploration) demonstrates that a careful combination of these ideas compounds\ntheir benefits. Our method first extracts low-level skills using a variational\nautoencoder (VAE), and then pseudo-labels unlabeled trajectories with\noptimistic rewards and high-level action labels, transforming prior data into\nhigh-level, task-relevant examples that encourage novelty-seeking behavior.\nFinally, SUPE uses these transformed examples as additional off-policy data for\nonline RL to learn a high-level policy that composes pretrained low-level\nskills to explore efficiently. In our experiments, SUPE consistently\noutperforms prior strategies across a suite of 42 long-horizon, sparse-reward\ntasks. Code: https://github.com/rail-berkeley/supe.",
      "tldr_zh": "该研究探讨了如何利用无标签离线轨迹数据来提升强化学习（RL）中的在线探索效率，提出了一种名为 SUPE 的方法。SUPE 首先使用变分自编码器（VAE）提取低级技能，然后通过伪标签处理（如乐观奖励和高水平动作标签）将无标签轨迹转化为鼓励新颖行为的高水平相关示例。最终，SUPE 将这些示例作为额外的 off-policy 数据，结合在线 RL 学习高水平策略，以组合预训练的低级技能实现高效探索。在 42 个长horizon、稀疏奖励任务的实验中，SUPE 持续优于现有策略，展示了其在 RL 探索方面的显著优势。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "27 pages, 19 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.18076v3",
      "published_date": "2024-10-23 17:58:45 UTC",
      "updated_date": "2025-02-23 18:58:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:28:46.361688"
    },
    {
      "arxiv_id": "2410.18071v1",
      "title": "TP-Eval: Tap Multimodal LLMs' Potential in Evaluation by Customizing Prompts",
      "title_zh": "翻译失败",
      "authors": [
        "Yuxuan Xie",
        "Tianhua Li",
        "Wenqi Shao",
        "Kaipeng Zhang"
      ],
      "abstract": "Recently, multimodal large language models (MLLMs) have received much\nattention for their impressive capabilities. The evaluation of MLLMs is\nbecoming critical to analyzing attributes of MLLMs and providing valuable\ninsights. However, current benchmarks overlook the problem of prompt\nsensitivity - minor prompt variations may lead to significant performance\nfluctuations. Thus, inappropriate prompts may obscure the models' capabilities,\nunderestimating the models' performance. Moreover, different models have\ndifferent preferences for different prompts, and thus, using the same prompt\nfor all models will cause evaluation bias. This paper analyzes this deficiency\nin existing benchmarks and further introduces a new evaluation framework named\nTP-Eval, which introduces a prompt customization method to reduce evaluation\nbiases and tap models' potential. TP-Eval will rewrite the original prompts to\ndifferent customized prompts for different models. In particular, we propose\nsome well-designed modules for prompt customization tailored to the scenario of\nMLLM evaluation. Extensive experiments demonstrate the effectiveness of our\napproach to uncovering models' capabilities, and TP-Eval should benefit the\ncommunity in developing more comprehensive and convincing MLLM evaluation\nbenchmarks.",
      "tldr_zh": "该论文分析了现有多模态大语言模型 (MLLMs) 评估基准的不足，即提示敏感性问题会导致性能波动和评估偏差，从而低估模型能力或引入偏好差异。针对此，研究引入 TP-Eval 框架，通过定制化提示方法为不同模型重写提示，并设计专属模块以适应 MLLM 评估场景，从而减少偏差并挖掘模型潜力。实验结果证明，TP-Eval 有效揭示了模型能力，并有助于社区开发更全面可靠的 MLLM 评估基准。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.18071v1",
      "published_date": "2024-10-23 17:54:43 UTC",
      "updated_date": "2024-10-23 17:54:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:28:58.803844"
    },
    {
      "arxiv_id": "2410.18070v3",
      "title": "Training Free Guided Flow Matching with Optimal Control",
      "title_zh": "翻译失败",
      "authors": [
        "Luran Wang",
        "Chaoran Cheng",
        "Yizhen Liao",
        "Yanru Qu",
        "Ge Liu"
      ],
      "abstract": "Controlled generation with pre-trained Diffusion and Flow Matching models has\nvast applications. One strategy for guiding ODE-based generative models is\nthrough optimizing a target loss $R(x_1)$ while staying close to the prior\ndistribution. Along this line, some recent work showed the effectiveness of\nguiding flow model by differentiating through its ODE sampling process. Despite\nthe superior performance, the theoretical understanding of this line of methods\nis still preliminary, leaving space for algorithm improvement. Moreover,\nexisting methods predominately focus on Euclidean data manifold, and there is a\ncompelling need for guided flow methods on complex geometries such as SO(3),\nwhich prevails in high-stake scientific applications like protein design. We\npresent OC-Flow, a general and theoretically grounded training-free framework\nfor guided flow matching using optimal control. Building upon advances in\noptimal control theory, we develop effective and practical algorithms for\nsolving optimal control in guided ODE-based generation and provide a systematic\ntheoretical analysis of the convergence guarantee in both Euclidean and SO(3).\nWe show that existing backprop-through-ODE methods can be interpreted as\nspecial cases of Euclidean OC-Flow. OC-Flow achieved superior performance in\nextensive experiments on text-guided image manipulation, conditional molecule\ngeneration, and all-atom peptide design.",
      "tldr_zh": "该研究提出 OC-Flow，一种无需训练的引导流匹配框架，利用最优控制（Optimal Control）理论来优化 ODE-based 生成模型的目标损失，同时保持接近先验分布。框架通过开发有效的算法，并提供欧拉空间和复杂几何如 SO(3) 上的收敛保证理论分析，解决了现有方法的局限性，并将传统 backprop-through-ODE 方法视为其欧拉特例。实验结果显示，OC-Flow 在文本引导图像操作、条件分子生成以及全原子肽设计等任务中表现出优越性能，显著提升了生成质量。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.18070v3",
      "published_date": "2024-10-23 17:53:11 UTC",
      "updated_date": "2025-03-09 03:35:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:29:10.886052"
    },
    {
      "arxiv_id": "2410.18067v3",
      "title": "Beyond Position: the emergence of wavelet-like properties in Transformers",
      "title_zh": "超越位置：Transformer 中小波状属性的涌现",
      "authors": [
        "Valeria Ruscio",
        "Fabrizio Silvestri"
      ],
      "abstract": "This paper studies how transformer models develop robust wavelet-like\nproperties that effectively compensate for the theoretical limitations of\nRotary Position Embeddings (RoPE), providing insights into how these networks\nprocess sequential information across different scales. Through theoretical\nanalysis and empirical validation across models ranging from 1B to 12B\nparameters, we show that attention heads naturally evolve to implement\nmulti-resolution processing analogous to wavelet transforms. Our analysis\nestablishes that attention heads consistently organize into complementary\nfrequency bands with systematic power distribution patterns, and these\nwavelet-like characteristics become more pronounced in larger models. We\nprovide mathematical analysis showing how these properties align with optimal\nsolutions to the fundamental uncertainty principle between positional precision\nand frequency resolution. Our findings suggest that the effectiveness of modern\ntransformer architectures stems significantly from their development of optimal\nmulti-resolution decompositions that naturally address the theoretical\nconstraints of position encoding.",
      "tldr_zh": "本论文研究了Transformer模型中wavelet-like properties的出现，这些特性能有效补偿Rotary Position Embeddings (RoPE)的理论限制，从而提升序列信息的多尺度处理能力。通过理论分析和实证验证（涵盖1B到12B参数的模型），发现attention heads自然演变为类似于小波变换的多分辨率机制，并组织成互补的频率带。研究结果显示，这些wavelet-like特性在更大模型中更显著，并与位置精度和频率分辨率的不确定性原理相符，揭示了Transformer架构高效性的核心原因。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.18067v3",
      "published_date": "2024-10-23 17:48:28 UTC",
      "updated_date": "2025-01-21 17:50:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:29:23.013567"
    },
    {
      "arxiv_id": "2410.18065v1",
      "title": "SPIRE: Synergistic Planning, Imitation, and Reinforcement Learning for Long-Horizon Manipulation",
      "title_zh": "翻译失败",
      "authors": [
        "Zihan Zhou",
        "Animesh Garg",
        "Dieter Fox",
        "Caelan Garrett",
        "Ajay Mandlekar"
      ],
      "abstract": "Robot learning has proven to be a general and effective technique for\nprogramming manipulators. Imitation learning is able to teach robots solely\nfrom human demonstrations but is bottlenecked by the capabilities of the\ndemonstrations. Reinforcement learning uses exploration to discover better\nbehaviors; however, the space of possible improvements can be too large to\nstart from scratch. And for both techniques, the learning difficulty increases\nproportional to the length of the manipulation task. Accounting for this, we\npropose SPIRE, a system that first uses Task and Motion Planning (TAMP) to\ndecompose tasks into smaller learning subproblems and second combines imitation\nand reinforcement learning to maximize their strengths. We develop novel\nstrategies to train learning agents when deployed in the context of a planning\nsystem. We evaluate SPIRE on a suite of long-horizon and contact-rich robot\nmanipulation problems. We find that SPIRE outperforms prior approaches that\nintegrate imitation learning, reinforcement learning, and planning by 35% to\n50% in average task performance, is 6 times more data efficient in the number\nof human demonstrations needed to train proficient agents, and learns to\ncomplete tasks nearly twice as efficiently. View\nhttps://sites.google.com/view/spire-corl-2024 for more details.",
      "tldr_zh": "这篇论文提出了SPIRE系统，它整合了Task and Motion Planning (TAMP)、Imitation Learning和Reinforcement Learning，以解决长时限机器人操作任务的挑战。SPIRE首先使用TAMP将复杂任务分解为更小的子问题，然后结合模仿学习从人类演示中获取初始行为，并通过强化学习探索优化。实验结果显示，SPIRE在接触丰富的机器人操作任务上，比现有整合方法提高了35%到50%的平均性能，且在人类演示数据上效率提升6倍，任务完成效率近乎翻倍。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Conference on Robot Learning (CoRL) 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.18065v1",
      "published_date": "2024-10-23 17:42:07 UTC",
      "updated_date": "2024-10-23 17:42:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:29:34.970270"
    },
    {
      "arxiv_id": "2410.18060v1",
      "title": "Explaining Bayesian Networks in Natural Language using Factor Arguments. Evaluation in the medical domain",
      "title_zh": "翻译失败",
      "authors": [
        "Jaime Sevilla",
        "Nikolay Babakov",
        "Ehud Reiter",
        "Alberto Bugarin"
      ],
      "abstract": "In this paper, we propose a model for building natural language explanations\nfor Bayesian Network Reasoning in terms of factor arguments, which are\nargumentation graphs of flowing evidence, relating the observed evidence to a\ntarget variable we want to learn about. We introduce the notion of factor\nargument independence to address the outstanding question of defining when\narguments should be presented jointly or separately and present an algorithm\nthat, starting from the evidence nodes and a target node, produces a list of\nall independent factor arguments ordered by their strength. Finally, we\nimplemented a scheme to build natural language explanations of Bayesian\nReasoning using this approach. Our proposal has been validated in the medical\ndomain through a human-driven evaluation study where we compare the Bayesian\nNetwork Reasoning explanations obtained using factor arguments with an\nalternative explanation method. Evaluation results indicate that our proposed\nexplanation approach is deemed by users as significantly more useful for\nunderstanding Bayesian Network Reasoning than another existing explanation\nmethod it is compared to.",
      "tldr_zh": "本文提出了一种使用因子论据（factor arguments）构建贝叶斯网络（Bayesian Networks）推理的自然语言解释模型，该模型通过证据流动的论证图将观察证据与目标变量相关联。研究引入了因子论据独立性（factor argument independence）的概念，并开发了一个算法，从证据节点和目标节点出发，生成并按强度排序的所有独立因子论据。最终，在医疗领域的用户评估中，该方法被证明比现有解释方法更有效，帮助用户更好地理解贝叶斯网络推理。",
      "categories": [
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "First Workshop on Explainable Artificial Intelligence for the medical\n  domain - EXPLIMED. THE 27TH EUROPEAN CONFERENCE ON ARTIFICIAL INTELLIGENCE",
      "pdf_url": "http://arxiv.org/pdf/2410.18060v1",
      "published_date": "2024-10-23 17:33:27 UTC",
      "updated_date": "2024-10-23 17:33:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:29:46.800823"
    },
    {
      "arxiv_id": "2410.18040v1",
      "title": "Key Algorithms for Keyphrase Generation: Instruction-Based LLMs for Russian Scientific Keyphrases",
      "title_zh": "翻译失败",
      "authors": [
        "Anna Glazkova",
        "Dmitry Morozov",
        "Timur Garipov"
      ],
      "abstract": "Keyphrase selection is a challenging task in natural language processing that\nhas a wide range of applications. Adapting existing supervised and unsupervised\nsolutions for the Russian language faces several limitations due to the rich\nmorphology of Russian and the limited number of training datasets available.\nRecent studies conducted on English texts show that large language models\n(LLMs) successfully address the task of generating keyphrases. LLMs allow\nachieving impressive results without task-specific fine-tuning, using text\nprompts instead. In this work, we access the performance of prompt-based\nmethods for generating keyphrases for Russian scientific abstracts. First, we\ncompare the performance of zero-shot and few-shot prompt-based methods,\nfine-tuned models, and unsupervised methods. Then we assess strategies for\nselecting keyphrase examples in a few-shot setting. We present the outcomes of\nhuman evaluation of the generated keyphrases and analyze the strengths and\nweaknesses of the models through expert assessment. Our results suggest that\nprompt-based methods can outperform common baselines even using simple text\nprompts.",
      "tldr_zh": "本研究探讨了使用指令-based LLMs 生成俄语科学摘要的关键短语，针对俄语的丰富形态和训练数据集有限的挑战。研究比较了 zero-shot 和 few-shot prompt-based 方法、微调模型以及无监督方法，并评估了少样本设置中关键短语示例选择的策略。结果显示，即使采用简单的文本提示，prompt-based 方法也能超越常见基线，并在人工评估中展现出显著优势，为俄语关键短语生成提供有效解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "68T50",
        "I.2.7; I.7.m; H.3.3"
      ],
      "primary_category": "cs.CL",
      "comment": "The 12th International Conference on Analysis of Images, Social\n  Networks and Texts (AIST'2024)",
      "pdf_url": "http://arxiv.org/pdf/2410.18040v1",
      "published_date": "2024-10-23 17:07:32 UTC",
      "updated_date": "2024-10-23 17:07:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:29:57.876550"
    },
    {
      "arxiv_id": "2410.18032v4",
      "title": "GraphTeam: Facilitating Large Language Model-based Graph Analysis via Multi-Agent Collaboration",
      "title_zh": "GraphTeam：通过多智能体协作促进基于大型语言模型的图分析",
      "authors": [
        "Xin Sky Li",
        "Qizhi Chu",
        "Yubin Chen",
        "Yang Liu",
        "Yaoqi Liu",
        "Zekai Yu",
        "Weize Chen",
        "Chen Qian",
        "Chuan Shi",
        "Cheng Yang"
      ],
      "abstract": "Graphs are widely used for modeling relational data in real-world scenarios,\nsuch as social networks and urban computing. Existing LLM-based graph analysis\napproaches either integrate graph neural networks (GNNs) for specific machine\nlearning tasks, limiting their transferability, or rely solely on LLMs'\ninternal reasoning ability, resulting in suboptimal performance. To address\nthese limitations, we take advantage of recent advances in LLM-based agents,\nwhich have shown capabilities of utilizing external knowledge or tools for\nproblem solving. By simulating human problem-solving strategies such as analogy\nand collaboration, we propose a multi-agent system based on LLMs named\nGraphTeam, for graph analysis. GraphTeam consists of five LLM-based agents from\nthree modules, and the agents with different specialities can collaborate with\neach other to address complex problems. Specifically, (1) input-output\nnormalization module: the question agent extracts and refines four key\narguments from the original question, facilitating the problem understanding,\nand the answer agent organizes the results to meet the output requirement; (2)\nexternal knowledge retrieval module: we first build a knowledge base consisting\nof relevant documentation and experience information, and then the search agent\nretrieves the most relevant entries for each question. (3) problem-solving\nmodule: given the retrieved information from search agent, the coding agent\nuses established algorithms via programming to generate solutions, and in case\nthe coding agent does not work, the reasoning agent will directly compute the\nresults without programming. Extensive experiments on six graph analysis\nbenchmarks demonstrate that GraphTeam achieves state-of-the-art performance\nwith an average 25.85% improvement over the best baseline in terms of accuracy.\nThe code and data are available at https://github.com/BUPT-GAMMA/GraphTeam.",
      "tldr_zh": "该论文提出GraphTeam，一种基于Large Language Models (LLMs)的多智能体系统，用于提升图分析任务的性能，通过模拟人类问题解决策略如类比和协作来解决现有方法（如整合Graph Neural Networks (GNNs)或仅依赖LLMs内部推理）的局限性。GraphTeam包括三个模块：输入输出归一化模块（question agent提取问题关键参数，answer agent组织输出）、外部知识检索模块（构建知识库并由search agent检索相关信息），以及问题解决模块（coding agent通过编程生成解决方案，reasoning agent在必要时直接计算）。实验在六个图分析基准上表明，GraphTeam比最佳基线平均准确率提高了25.85%，实现了最先进性能，并公开了代码和数据以促进进一步研究。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.18032v4",
      "published_date": "2024-10-23 17:02:59 UTC",
      "updated_date": "2025-02-24 06:16:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:30:11.053997"
    },
    {
      "arxiv_id": "2410.18027v2",
      "title": "Cross-lingual Transfer of Reward Models in Multilingual Alignment",
      "title_zh": "跨语言转移的奖励模型在多语言对",
      "authors": [
        "Jiwoo Hong",
        "Noah Lee",
        "Rodrigo Martínez-Castaño",
        "César Rodríguez",
        "James Thorne"
      ],
      "abstract": "Reinforcement learning with human feedback (RLHF) is shown to largely benefit\nfrom precise reward models (RMs). However, recent studies in reward modeling\nschemes are skewed towards English, limiting the applicability of RLHF in\nmultilingual alignments. In this work, we investigate the cross-lingual\ntransfer of RMs trained in diverse languages, primarily from English. Our\nexperimental results demonstrate the strong cross-lingual transfer of English\nRMs, exceeding target language RMs by 3~4% average increase in Multilingual\nRewardBench. Furthermore, we analyze the cross-lingual transfer of RMs through\nthe representation shifts. Finally, we perform multilingual alignment to\nexemplify how cross-lingual transfer in RM propagates to enhanced multilingual\ninstruction-following capability, along with extensive analyses on\noff-the-shelf RMs. We release the code, model, and data.",
      "tldr_zh": "这篇论文探讨了奖励模型（Reward Models, RMs）在多语言对齐中的跨语言转移问题，旨在解决强化学习与人类反馈（RLHF）因英语偏向而限制多语言应用的挑战。研究通过实验证明，从英语RMs向其他语言的转移效果显著，在Multilingual RewardBench上比目标语言RMs平均提高了3~4%。此外，论文分析了表示转移（representation shifts）的机制，并展示了这种转移如何增强多语言指令跟随能力，同时发布了代码、模型和数据以促进进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to NAACL 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.18027v2",
      "published_date": "2024-10-23 17:00:13 UTC",
      "updated_date": "2025-01-23 13:20:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:30:23.431265"
    },
    {
      "arxiv_id": "2410.18001v2",
      "title": "Benchmarking Foundation Models on Exceptional Cases: Dataset Creation and Validation",
      "title_zh": "翻译失败",
      "authors": [
        "Suho Kang",
        "Jungyang Park",
        "Joonseo Ha",
        "SoMin Kim",
        "JinHyeong Kim",
        "Subeen Park",
        "Kyungwoo Song"
      ],
      "abstract": "Foundation models (FMs) have achieved significant success across various\ntasks, leading to research on benchmarks for reasoning abilities. However,\nthere is a lack of studies on FMs performance in exceptional scenarios, which\nwe define as out-of-distribution (OOD) reasoning tasks. This paper is the first\nto address these cases, developing a novel dataset for evaluation of FMs across\nmultiple modalities, including graphic novels, calligraphy, news articles, and\nlyrics. It includes tasks for instance classification, character recognition,\ntoken prediction, and text generation. The paper also proposes prompt\nengineering techniques like Chain-of-Thought (CoT) and CoT+Few-Shot to enhance\nperformance. Validation of FMs using various methods revealed improvements. The\ncode repository is accessible at:\nhttps://github.com/MLAI-Yonsei/ExceptionalBenchmark",
      "tldr_zh": "这篇论文针对基础模型（FMs）在异常场景（out-of-distribution, OOD 推理任务）下的性能问题，首次开发了一个多模态数据集，用于评估 FMs 在图形小说、书法、新闻文章和歌词等领域的表现。数据集包括实例分类、字符识别、标记预测和文本生成等任务，并提出 Chain-of-Thought (CoT) 和 CoT+Few-Shot 等提示工程技术来提升模型性能。通过各种验证方法，论文证明了这些技术带来的改进，并提供了代码仓库（https://github.com/MLAI-Yonsei/ExceptionalBenchmark）。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "EMNLP 2024 Workshop\n  Genbench(https://genbench.org/workshop_programme/)",
      "pdf_url": "http://arxiv.org/pdf/2410.18001v2",
      "published_date": "2024-10-23 16:24:23 UTC",
      "updated_date": "2024-12-05 11:58:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:30:36.292812"
    },
    {
      "arxiv_id": "2411.00809v3",
      "title": "Adaptive Segment-level Reward: Bridging the Gap Between Action and Reward Space in Alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Yanshi Li",
        "Shaopan Xiong",
        "Gengru Chen",
        "Xiaoyang Li",
        "Yijia Luo",
        "Xingyuan Bu",
        "Yingshui Tan",
        "Wenbo Su",
        "Bo Zheng"
      ],
      "abstract": "Reinforcement Learning (RL) has proven highly effective in aligning Large\nLanguage Models (LLMs) with human preferences. Typical RL methods optimize\nunder an overall sequence reward, which can lead to a suboptimal learning\nprocess. This reflects a key credit assignment problem: identifying which\ntokens to reinforce or suppress. To rectify these shortcomings, step-wise and\ntoken-wise methods have been proposed. However, step-wise methods rely on\npunctuation segmentation and still cannot accurately identify the key tokens.\nThe token-level approach is too fine-grained, attending to many unimportant\ntokens and thus introducing a large amount of noise. To assign more accurate\nrewards to different tokens, improving credit assignment, we propose the\n\"Adaptive Segment-wise Reward\" method. We employ semantic meaning, rather than\npunctuation, to adaptively delineate segments. Experiments demonstrate that our\nmethod can be integrated into various training methods. Compared to training\nmethods \\textit{without} our approach, our method improves the success rate on\nadversarial samples by 10\\%, and achieves a 1.3\\% improvement on evaluation\nbenchmarks such as MMLU, GSM8K, HumanEval, etc.",
      "tldr_zh": "该论文针对强化学习（RL）在对齐大语言模型（LLMs）时存在的信用分配问题，提出了一种名为Adaptive Segment-wise Reward的方法，以桥接行动空间和奖励空间的差距。不同于传统的步级方法依赖标点或标记级方法引入噪声，该方法通过语义意义适应性划分段落，从而更准确地识别并强化关键标记。实验结果表明，该方法可集成到各种训练框架中，提高对抗样本的成功率10%，并在MMLU、GSM8K、HumanEval等基准测试上提升1.3%。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.00809v3",
      "published_date": "2024-10-23 16:16:15 UTC",
      "updated_date": "2025-02-25 10:42:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:30:47.230756"
    },
    {
      "arxiv_id": "2410.17991v1",
      "title": "AI driven health recommender",
      "title_zh": "AI 驱动的健康推荐系统",
      "authors": [
        "K. Vignesh",
        "B. Pranavi",
        "Ch. Sreenidhi"
      ],
      "abstract": "As AI emerged as highest valued technology, We used that to create a web\napplication that makes a patient work easier .It detects the disease name based\non the symptoms given by the patient and recommends medication for respective\ndisease, precautions to take, diet to follow and workouts to do, so the disease\ncan be minimized. The web application is made with clean and Realtime data by\nusing Machine learning as root. We used flask to create a user-friendly\nplatform.",
      "tldr_zh": "这篇论文提出了一种AI驱动的健康推荐系统，使用Machine learning作为核心技术，根据患者提供的症状检测疾病，并推荐相应的药物、预防措施、饮食和锻炼，以帮助最小化疾病影响。系统基于实时数据构建了一个用户友好的web应用，通过Flask框架实现简化患者流程。主要贡献在于提升了健康咨询的可访问性和效率，为AI在医疗领域的应用提供了实用示例。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.17991v1",
      "published_date": "2024-10-23 16:08:00 UTC",
      "updated_date": "2024-10-23 16:08:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:30:57.469919"
    },
    {
      "arxiv_id": "2410.17986v1",
      "title": "Federated Transformer: Multi-Party Vertical Federated Learning on Practical Fuzzily Linked Data",
      "title_zh": "翻译失败",
      "authors": [
        "Zhaomin Wu",
        "Junyi Hou",
        "Yiqun Diao",
        "Bingsheng He"
      ],
      "abstract": "Federated Learning (FL) is an evolving paradigm that enables multiple parties\nto collaboratively train models without sharing raw data. Among its variants,\nVertical Federated Learning (VFL) is particularly relevant in real-world,\ncross-organizational collaborations, where distinct features of a shared\ninstance group are contributed by different parties. In these scenarios,\nparties are often linked using fuzzy identifiers, leading to a common practice\ntermed as multi-party fuzzy VFL. Existing models generally address either\nmulti-party VFL or fuzzy VFL between two parties. Extending these models to\npractical multi-party fuzzy VFL typically results in significant performance\ndegradation and increased costs for maintaining privacy. To overcome these\nlimitations, we introduce the Federated Transformer (FeT), a novel framework\nthat supports multi-party VFL with fuzzy identifiers. FeT innovatively encodes\nthese identifiers into data representations and employs a transformer\narchitecture distributed across different parties, incorporating three new\ntechniques to enhance performance. Furthermore, we have developed a multi-party\nprivacy framework for VFL that integrates differential privacy with secure\nmulti-party computation, effectively protecting local representations while\nminimizing associated utility costs. Our experiments demonstrate that the FeT\nsurpasses the baseline models by up to 46\\% in terms of accuracy when scaled to\n50 parties. Additionally, in two-party fuzzy VFL settings, FeT also shows\nimproved performance and privacy over cutting-edge VFL models.",
      "tldr_zh": "该论文提出了 Federated Transformer (FeT)，一个创新框架，用于支持多方 Vertical Federated Learning (VFL) 在模糊链接数据场景下的协作训练，解决了现有模型在扩展到多方模糊 VFL 时性能下降和隐私成本增加的问题。FeT 通过将模糊标识符编码到数据表示中，并采用分布式 Transformer 架构结合三个新技巧，提升了模型的整体性能；同时，引入了一个多方隐私框架，整合差分隐私和安全多方计算，以保护本地数据表示并最小化效用损失。实验结果显示，FeT 在扩展到50方设置下准确率比基线模型提高46%，并在两方模糊 VFL 场景中表现出优越的性能和隐私保护。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.17986v1",
      "published_date": "2024-10-23 16:00:14 UTC",
      "updated_date": "2024-10-23 16:00:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:31:12.361138"
    },
    {
      "arxiv_id": "2410.17980v1",
      "title": "Stick-breaking Attention",
      "title_zh": "翻译失败",
      "authors": [
        "Shawn Tan",
        "Yikang Shen",
        "Songlin Yang",
        "Aaron Courville",
        "Rameswar Panda"
      ],
      "abstract": "The self-attention mechanism traditionally relies on the softmax operator,\nnecessitating positional embeddings like RoPE, or position biases to account\nfor token order. But current methods using still face length generalisation\nchallenges. We propose an alternative attention mechanism based on the\nstick-breaking process: For each token before the current, we determine a break\npoint $\\beta_{i,j}$, which represents the proportion of the remaining stick to\nallocate to the current token. We repeat the process until the stick is fully\nallocated, resulting in a sequence of attention weights. This process naturally\nincorporates recency bias, which has linguistic motivations for grammar parsing\n(Shen et. al., 2017). We study the implications of replacing the conventional\nsoftmax-based attention mechanism with stick-breaking attention. We then\ndiscuss implementation of numerically stable stick-breaking attention and adapt\nFlash Attention to accommodate this mechanism. When used as a drop-in\nreplacement for current softmax+RoPE attention systems, we find that\nstick-breaking attention performs competitively with current methods on length\ngeneralisation and downstream tasks. Stick-breaking also performs well at\nlength generalisation, allowing a model trained with $2^{11}$ context window to\nperform well at $2^{14}$ with perplexity improvements.",
      "tldr_zh": "论文提出了一种基于stick-breaking过程的注意力机制，作为传统softmax注意力的替代方案，以解决长度泛化挑战。该机制通过为每个当前token之前的token确定断点β_{i,j}，动态分配注意力权重序列，并自然融入recency bias，以提升语法解析等任务的性能。论文实现了数值稳定的stick-breaking注意力，并与Flash Attention兼容；实验结果显示，该机制在长度泛化和下游任务上与现有方法（如softmax+RoPE）表现相当，并使训练于2^11上下文窗口的模型在2^14窗口上显著改善perplexity。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.17980v1",
      "published_date": "2024-10-23 15:51:13 UTC",
      "updated_date": "2024-10-23 15:51:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:31:23.193899"
    },
    {
      "arxiv_id": "2410.19865v1",
      "title": "Evaluating Deep Learning Approaches for Predictions in Unmonitored Basins with Continental-scale Stream Temperature Models",
      "title_zh": "利用大陆规模河流温度模型评估深度学习方法在未监测流域中的预测性能",
      "authors": [
        "Jared D. Willard",
        "Fabio Ciulla",
        "Helen Weierbach",
        "Vipin Kumar",
        "Charuleka Varadharajan"
      ],
      "abstract": "The prediction of streamflows and other environmental variables in\nunmonitored basins is a grand challenge in hydrology. Recent machine learning\n(ML) models can harness vast datasets for accurate predictions at large spatial\nscales. However, there are open questions regarding model design and data\nneeded for inputs and training to improve performance. This study explores\nthese questions while demonstrating the ability of deep learning models to make\naccurate stream temperature predictions in unmonitored basins across the\nconterminous United States. First, we compare top-down models that utilize data\nfrom a large number of basins with bottom-up methods that transfer ML models\nbuilt on local sites, reflecting traditional regionalization techniques. We\nalso evaluate an intermediary grouped modeling approach that categorizes sites\nbased on regional co-location or similarity of catchment characteristics.\nSecond, we evaluate trade-offs between model complexity, prediction accuracy,\nand applicability for more target locations by systematically removing inputs.\nWe then examine model performance when additional training data becomes\navailable due to reductions in input requirements. Our results suggest that\ntop-down models significantly outperform bottom-up and grouped models.\nMoreover, it is possible to get acceptable accuracy by reducing both dynamic\nand static inputs enabling predictions for more sites with lower model\ncomplexity and computational needs. From detailed error analysis, we determined\nthat the models are more accurate for sites primarily controlled by air\ntemperatures compared to locations impacted by groundwater and dams. By\naddressing these questions, this research offers a comprehensive perspective on\noptimizing ML model design for accurate predictions in unmonitored regions.",
      "tldr_zh": "这篇论文评估了深度学习方法在未监测流域预测溪流温度的性能，使用大陆规模模型来处理水文学中的关键挑战。研究比较了三种方法：top-down 模型（利用大量流域数据）、bottom-up 方法（转移本地模型）和 grouped modeling 方式（基于区域位置或流域特征相似性分类），并通过系统减少动态和静态输入来权衡模型复杂性、预测准确性和适用性。结果显示，top-down 模型显著优于其他方法，且减少输入后仍能保持可接受的准确性，同时降低计算需求。详细错误分析表明，模型在空气温度主导的站点预测更准确，而受地下水和水坝影响的地点表现较差，为优化 machine learning (ML) 模型设计以适用于未监测区域提供了全面指导。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.ao-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "47 pages, 12 figures, 7 tables, submitted to Water Resources Research",
      "pdf_url": "http://arxiv.org/pdf/2410.19865v1",
      "published_date": "2024-10-23 15:36:59 UTC",
      "updated_date": "2024-10-23 15:36:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:31:36.428054"
    },
    {
      "arxiv_id": "2410.17971v1",
      "title": "Dynamic Spectrum Access for Ambient Backscatter Communication-assisted D2D Systems with Quantum Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Nguyen Van Huynh",
        "Bolun Zhang",
        "Dinh-Hieu Tran",
        "Dinh Thai Hoang",
        "Diep N. Nguyen",
        "Gan Zheng",
        "Dusit Niyato",
        "Quoc-Viet Pham"
      ],
      "abstract": "Spectrum access is an essential problem in device-to-device (D2D)\ncommunications. However, with the recent growth in the number of mobile\ndevices, the wireless spectrum is becoming scarce, resulting in low spectral\nefficiency for D2D communications. To address this problem, this paper aims to\nintegrate the ambient backscatter communication technology into D2D devices to\nallow them to backscatter ambient RF signals to transmit their data when the\nshared spectrum is occupied by mobile users. To obtain the optimal spectrum\naccess policy, i.e., stay idle or access the shared spectrum and perform active\ntransmissions or backscattering ambient RF signals for transmissions, to\nmaximize the average throughput for D2D users, deep reinforcement learning\n(DRL) can be adopted. However, DRL-based solutions may require long training\ntime due to the curse of dimensionality issue as well as complex deep neural\nnetwork architectures. For that, we develop a novel quantum reinforcement\nlearning (RL) algorithm that can achieve a faster convergence rate with fewer\ntraining parameters compared to DRL thanks to the quantum superposition and\nquantum entanglement principles. Specifically, instead of using conventional\ndeep neural networks, the proposed quantum RL algorithm uses a parametrized\nquantum circuit to approximate an optimal policy. Extensive simulations then\ndemonstrate that the proposed solution not only can significantly improve the\naverage throughput of D2D devices when the shared spectrum is busy but also can\nachieve much better performance in terms of convergence rate and learning\ncomplexity compared to existing DRL-based methods.",
      "tldr_zh": "该论文针对D2D通信中频谱资源稀缺导致的低效率问题，提出将ambient backscatter communication技术整合到D2D系统中，让设备在共享频谱被占用时通过回散ambient RF信号进行数据传输，以最大化平均吞吐量。作者开发了一种新型quantum reinforcement learning (RL)算法，使用parametrized quantum circuit来近似最优频谱访问策略，从而利用quantum superposition和quantum entanglement原理实现比传统deep reinforcement learning (DRL)更快的收敛率和更少的训练参数。模拟实验显示，该方案显著提升了D2D设备的平均吞吐量，尤其在频谱繁忙场景下，并在收敛率和学习复杂度上优于现有DRL方法。",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "12 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.17971v1",
      "published_date": "2024-10-23 15:36:43 UTC",
      "updated_date": "2024-10-23 15:36:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:31:47.013011"
    },
    {
      "arxiv_id": "2410.17961v2",
      "title": "Closed-form merging of parameter-efficient modules for Federated Continual Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Riccardo Salami",
        "Pietro Buzzega",
        "Matteo Mosconi",
        "Jacopo Bonato",
        "Luigi Sabetta",
        "Simone Calderara"
      ],
      "abstract": "Model merging has emerged as a crucial technique in Deep Learning, enabling\nthe integration of multiple models into a unified system while preserving\nperfor-mance and scalability. In this respect, the compositional properties of\nlow-rank adaptation techniques (e.g., LoRA) have proven beneficial, as simple\naveraging LoRA modules yields a single model that mostly integrates the\ncapabilities of all individual modules. Building on LoRA, we take a step\nfurther by imposing that the merged model matches the responses of all learned\nmodules. Solving this objective in closed form yields an indeterminate system\nwith A and B as unknown variables, indicating the existence of infinitely many\nclosed-form solutions. To address this challenge, we introduce LoRM, an\nalternating optimization strategy that trains one LoRA matrix at a time. This\nallows solving for each unknown variable individually, thus finding a unique\nsolution. We apply our proposed methodology to Federated Class-Incremental\nLearning (FCIL), ensuring alignment of model responses both between clients and\nacross tasks. Our method demonstrates state-of-the-art performance across a\nrange of FCIL scenarios. The code to reproduce our experiments is available at\ngithub.com/aimagelab/fed-mammoth.",
      "tldr_zh": "本研究提出了一种封闭形式合并参数高效模块的方法，针对联邦持续学习（Federated Continual Learning）问题。作者基于低秩适配技术（LoRA）的组合特性，进一步要求合并后的模型精确匹配所有学习模块的响应，并通过引入LoRM（一种交替优化策略）来逐个训练LoRA矩阵，从而获得唯一解。该方法应用于联邦类增量学习（FCIL），确保模型响应在客户端之间和任务之间对齐，并在多种FCIL场景中实现了最先进性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.17961v2",
      "published_date": "2024-10-23 15:30:13 UTC",
      "updated_date": "2025-03-08 17:15:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:31:58.251758"
    },
    {
      "arxiv_id": "2410.17957v1",
      "title": "MCUBERT: Memory-Efficient BERT Inference on Commodity Microcontrollers",
      "title_zh": "翻译失败",
      "authors": [
        "Zebin Yang",
        "Renze Chen",
        "Taiqiang Wu",
        "Ngai Wong",
        "Yun Liang",
        "Runsheng Wang",
        "Ru Huang",
        "Meng Li"
      ],
      "abstract": "In this paper, we propose MCUBERT to enable language models like BERT on tiny\nmicrocontroller units (MCUs) through network and scheduling co-optimization. We\nobserve the embedding table contributes to the major storage bottleneck for\ntiny BERT models. Hence, at the network level, we propose an MCU-aware\ntwo-stage neural architecture search algorithm based on clustered low-rank\napproximation for embedding compression. To reduce the inference memory\nrequirements, we further propose a novel fine-grained MCU-friendly scheduling\nstrategy. Through careful computation tiling and re-ordering as well as kernel\ndesign, we drastically increase the input sequence lengths supported on MCUs\nwithout any latency or accuracy penalty. MCUBERT reduces the parameter size of\nBERT-tiny and BERT-mini by 5.7$\\times$ and 3.0$\\times$ and the execution memory\nby 3.5$\\times$ and 4.3$\\times$, respectively. MCUBERT also achieves 1.5$\\times$\nlatency reduction. For the first time, MCUBERT enables lightweight BERT models\non commodity MCUs and processing more than 512 tokens with less than 256KB of\nmemory.",
      "tldr_zh": "这篇论文提出了 MCUBERT，一种通过网络和调度优化来在商用微控制器 (MCUs) 上高效运行 BERT 模型的方法，针对嵌入表带来的存储瓶颈问题。核心方法包括基于 clustered low-rank approximation 的两阶段神经架构搜索算法来压缩嵌入，以及细粒度的 MCU-friendly 调度策略，通过计算平铺和重新排序减少推理内存需求。实验结果显示，MCUBERT 将 BERT-tiny 和 BERT-mini 的参数大小分别减少 5.7 倍和 3.0 倍，执行内存减少 3.5 倍和 4.3 倍，同时实现 1.5 倍的延迟降低，从而首次在不到 256KB 内存的 MCUs 上处理超过 512 个 tokens。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ICCAD 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.17957v1",
      "published_date": "2024-10-23 15:27:37 UTC",
      "updated_date": "2024-10-23 15:27:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:32:14.064397"
    },
    {
      "arxiv_id": "2410.17954v1",
      "title": "ExpertFlow: Optimized Expert Activation and Token Allocation for Efficient Mixture-of-Experts Inference",
      "title_zh": "翻译失败",
      "authors": [
        "Xin He",
        "Shunkang Zhang",
        "Yuxin Wang",
        "Haiyan Yin",
        "Zihao Zeng",
        "Shaohuai Shi",
        "Zhenheng Tang",
        "Xiaowen Chu",
        "Ivor Tsang",
        "Ong Yew Soon"
      ],
      "abstract": "Sparse Mixture of Experts (MoE) models, while outperforming dense Large\nLanguage Models (LLMs) in terms of performance, face significant deployment\nchallenges during inference due to their high memory demands. Existing\noffloading techniques, which involve swapping activated and idle experts\nbetween the GPU and CPU, often suffer from rigid expert caching mechanisms.\nThese mechanisms fail to adapt to dynamic routing, leading to inefficient cache\nutilization, or incur prohibitive costs for prediction training. To tackle\nthese inference-specific challenges, we introduce ExpertFlow, a comprehensive\nsystem specifically designed to enhance inference efficiency by accommodating\nflexible routing and enabling efficient expert scheduling between CPU and GPU.\nThis reduces overhead and boosts system performance. Central to our approach is\na predictive routing path-based offloading mechanism that utilizes a\nlightweight predictor to accurately forecast routing paths before computation\nbegins. This proactive strategy allows for real-time error correction in expert\ncaching, significantly increasing cache hit ratios and reducing the frequency\nof expert transfers, thereby minimizing I/O overhead. Additionally, we\nimplement a dynamic token scheduling strategy that optimizes MoE inference by\nrearranging input tokens across different batches. This method not only reduces\nthe number of activated experts per batch but also improves computational\nefficiency. Our extensive experiments demonstrate that ExpertFlow achieves up\nto 93.72\\% GPU memory savings and enhances inference speed by 2 to 10 times\ncompared to baseline methods, highlighting its effectiveness and utility as a\nrobust solution for resource-constrained inference scenarios.",
      "tldr_zh": "本文提出 ExpertFlow 系统，针对 Sparse Mixture of Experts (MoE) 模型在推理阶段的高内存需求和不灵活的专家缓存机制问题，进行优化，以提升整体效率。核心方法包括预测路由路径的卸载机制，使用轻量级预测器预估路由路径，实现实时错误修正，提高缓存命中率并减少专家传输的 I/O 开销。同时，引入动态令牌调度策略，通过重新排列输入令牌，降低每批激活的专家数量并优化计算过程。实验结果显示，ExpertFlow 可节省高达 93.72% 的 GPU 内存，并将推理速度提高 2 到 10 倍，为资源受限的推理场景提供高效解决方案。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Mixture-of-Experts, Inference, Offloading",
      "pdf_url": "http://arxiv.org/pdf/2410.17954v1",
      "published_date": "2024-10-23 15:24:54 UTC",
      "updated_date": "2024-10-23 15:24:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:32:24.272467"
    },
    {
      "arxiv_id": "2410.17952v2",
      "title": "SimRAG: Self-Improving Retrieval-Augmented Generation for Adapting Large Language Models to Specialized Domains",
      "title_zh": "SimRAG：自我改进的检索增强生成，用于将大语言模型适应到",
      "authors": [
        "Ran Xu",
        "Hui Liu",
        "Sreyashi Nag",
        "Zhenwei Dai",
        "Yaochen Xie",
        "Xianfeng Tang",
        "Chen Luo",
        "Yang Li",
        "Joyce C. Ho",
        "Carl Yang",
        "Qi He"
      ],
      "abstract": "Retrieval-augmented generation (RAG) enhances the question-answering (QA)\nabilities of large language models (LLMs) by integrating external knowledge.\nHowever, adapting general-purpose RAG systems to specialized fields such as\nscience and medicine poses unique challenges due to distribution shifts and\nlimited access to domain-specific data. To tackle this, we propose SimRAG, a\nself-training approach that equips the LLM with joint capabilities of question\nanswering and question generation for domain adaptation. Our method first\nfine-tunes the LLM on instruction-following, question-answering, and\nsearch-related data. Then, it prompts the same LLM to generate diverse\ndomain-relevant questions from unlabeled corpora, with an additional filtering\nstrategy to retain high-quality synthetic examples. By leveraging these\nself-generated synthetic examples, the LLM can improve their performance on\ndomain-specific RAG tasks. Experiments on 11 datasets, spanning two backbone\nsizes and three domains, demonstrate that SimRAG outperforms baselines by\n1.2\\%--8.6\\%.",
      "tldr_zh": "该论文提出 SimRAG，一种自改进的检索增强生成（RAG）方法，用于帮助大型语言模型（LLMs）适应专业领域，如科学和医学，以应对分布偏移和数据限制问题。SimRAG 通过先微调 LLM 以实现指令遵循、问答和搜索能力，然后利用同一 LLM 生成多样化领域相关问题并应用过滤策略保留高质量合成示例，从而提升模型在领域特定任务上的性能。实验在 11 个数据集上，涵盖两种模型规模和三个领域，结果显示 SimRAG 比基线模型提升 1.2% 到 8.6%。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to NAACL 2025 main conference",
      "pdf_url": "http://arxiv.org/pdf/2410.17952v2",
      "published_date": "2024-10-23 15:24:16 UTC",
      "updated_date": "2025-01-24 23:45:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:32:35.123706"
    },
    {
      "arxiv_id": "2410.17950v1",
      "title": "Benchmarking Floworks against OpenAI & Anthropic: A Novel Framework for Enhanced LLM Function Calling",
      "title_zh": "翻译失败",
      "authors": [
        "Nirav Bhan",
        "Shival Gupta",
        "Sai Manaswini",
        "Ritik Baba",
        "Narun Yadav",
        "Hillori Desai",
        "Yash Choudhary",
        "Aman Pawar",
        "Sarthak Shrivastava",
        "Sudipta Biswas"
      ],
      "abstract": "Large Language Models (LLMs) have shown remarkable capabilities in various\ndomains, yet their economic impact has been limited by challenges in tool use\nand function calling. This paper introduces ThorV2, a novel architecture that\nsignificantly enhances LLMs' function calling abilities. We develop a\ncomprehensive benchmark focused on HubSpot CRM operations to evaluate ThorV2\nagainst leading models from OpenAI and Anthropic. Our results demonstrate that\nThorV2 outperforms existing models in accuracy, reliability, latency, and cost\nefficiency for both single and multi-API calling tasks. We also show that\nThorV2 is far more reliable and scales better to multistep tasks compared to\ntraditional models. Our work offers the tantalizing possibility of more\naccurate function-calling compared to today's best-performing models using\nsignificantly smaller LLMs. These advancements have significant implications\nfor the development of more capable AI assistants and the broader application\nof LLMs in real-world scenarios.",
      "tldr_zh": "这篇论文介绍了 ThorV2，一种新型架构，旨在提升 Large Language Models (LLMs) 在 function calling 方面的能力，以克服工具使用挑战并扩大其经济影响。研究者开发了一个针对 HubSpot CRM 操作的全面基准，对 ThorV2 与 OpenAI 和 Anthropic 的领先模型进行了比较。结果显示，ThorV2 在准确性、可靠性、延迟和成本效率上均优于现有模型，尤其在单次和多次 API 调用任务中，并更适合多步任务。总体而言，该框架使用更小的 LLMs 即可实现更高性能，为构建更强大的 AI 助手和 LLMs 在现实场景中的应用提供了重要启示。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "15 pages for main paper, 21 pages in total including references and\n  appendix, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.17950v1",
      "published_date": "2024-10-23 15:23:23 UTC",
      "updated_date": "2024-10-23 15:23:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:32:48.952917"
    },
    {
      "arxiv_id": "2410.17943v1",
      "title": "Optimizing Travel Itineraries with AI Algorithms in a Microservices Architecture: Balancing Cost, Time, Preferences, and Sustainability",
      "title_zh": "翻译失败",
      "authors": [
        "Biman Barua",
        "M. Shamim Kaiser"
      ],
      "abstract": "The objective of this research is how an implementation of AI algorithms in\nthe microservices architecture enhances travel itineraries by cost, time, user\npreferences, and environmental sustainability. It uses machine learning models\nfor both cost forecasting and personalization, genetic algorithm for\noptimization of the itinerary, and heuristics for sustainability checking.\nPrimary evaluated parameters consist of latency, ability to satisfy user\npreferences, cost and environmental concern. The experimental results\ndemonstrate an average of 4.5 seconds of response time on 1000 concurrent users\nand 92% of user preferences accuracy. The cost efficiency is proved, with 95%\nof provided trips being within the limits of the budget declared by the user.\nThe system also implements some measures to alleviate negative externalities\nrelated to travel and 60% of offered travel plans had green options\nincorporated, resulting in the average 15% lower carbon emissions than the\ntraditional travel plans offered. The genetic algorithm with time complexity\nO(g.p.f) provides the optimal solution in 100 generations. Every iteration\nimproves the quality of the solution by 5%, thus enabling its effective use in\noptimization problems where time is measured in seconds. Finally, the system is\ndesigned to be fault-tolerant with functional 99.9% availability which allows\nthe provision of services even when requirements are exceeded. Travel\noptimization platform is turned dynamic and efficient by this microservices\nbased architecture which provides enhanced scaling, allows asynchronous\ncommunication and real time changes. Because of the incorporation of Ai, cost\ncontrol and eco-friendliness approaches, the system addresses the different\nuser needs in the present days travel business.",
      "tldr_zh": "本研究探讨了在微服务架构中运用 AI algorithms 优化旅行行程，旨在平衡成本、时间、用户偏好和环境可持续性。方法包括使用机器学习模型进行成本预测和个性化、遗传算法优化行程，以及启发式方法进行可持续性检查。实验结果显示，系统在1000并发用户下平均响应时间为4.5秒，用户偏好准确率达92%，95%的行程符合预算，且60%的计划包含绿色选项，碳排放平均降低15%。整体而言，该框架通过动态扩展和容错设计（99.9%可用性），为现代旅行行业提供高效、生态友好的优化解决方案。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "18 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.17943v1",
      "published_date": "2024-10-23 15:15:56 UTC",
      "updated_date": "2024-10-23 15:15:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:32:59.701923"
    },
    {
      "arxiv_id": "2410.17933v1",
      "title": "Multi-Continental Healthcare Modelling Using Blockchain-Enabled Federated Learning",
      "title_zh": "利用区块链启用的联邦学习进行多洲医疗保健建模",
      "authors": [
        "Rui Sun",
        "Zhipeng Wang",
        "Hengrui Zhang",
        "Ming Jiang",
        "Yizhe Wen",
        "Jiqun Zhang",
        "Jiahao Sun",
        "Shuoying Zhang",
        "Erwu Liu",
        "Kezhi Li"
      ],
      "abstract": "One of the biggest challenges of building artificial intelligence (AI) model\nin healthcare area is the data sharing. Since healthcare data is private,\nsensitive, and heterogeneous, collecting sufficient data for modelling is\nexhausted, costly, and sometimes impossible. In this paper, we propose a\nframework for global healthcare modelling using datasets from multi-continents\n(Europe, North America and Asia) while without sharing the local datasets, and\nchoose glucose management as a study model to verify its effectiveness.\nTechnically, blockchain-enabled federated learning is implemented with adaption\nto make it meet with the privacy and safety requirements of healthcare data,\nmeanwhile rewards honest participation and penalize malicious activities using\nits on-chain incentive mechanism. Experimental results show that the proposed\nframework is effective, efficient, and privacy preserved. Its prediction\naccuracy is much better than the models trained from limited personal data and\nis similar to, and even slightly better than, the results from a centralized\ndataset. This work paves the way for international collaborations on healthcare\nprojects, where additional data is crucial for reducing bias and providing\nbenefits to humanity.",
      "tldr_zh": "该研究针对医疗数据共享的隐私和异构性挑战，提出了一种基于区块链启用的联邦学习（blockchain-enabled federated learning）的框架，用于多洲际（欧洲、北美和亚洲）医疗建模，而无需共享本地数据集，并以葡萄糖管理作为验证案例。该框架通过适应医疗数据的安全需求和链上激励机制，奖励诚实参与并惩罚恶意活动，确保模型的隐私保护和高效性。实验结果显示，该方法在预测准确率上优于仅使用有限个人数据的模型，甚至略优于集中式数据集的性能，从而为国际医疗合作提供新途径，减少偏差并促进人类福祉。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by IEEE Global Blockchain Conference",
      "pdf_url": "http://arxiv.org/pdf/2410.17933v1",
      "published_date": "2024-10-23 14:55:53 UTC",
      "updated_date": "2024-10-23 14:55:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:33:10.740657"
    },
    {
      "arxiv_id": "2410.17922v2",
      "title": "Dynamic Guided and Domain Applicable Safeguards for Enhanced Security in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Weidi Luo",
        "He Cao",
        "Zijing Liu",
        "Yu Wang",
        "Aidan Wong",
        "Bing Feng",
        "Yuan Yao",
        "Yu Li"
      ],
      "abstract": "With the extensive deployment of Large Language Models (LLMs), ensuring their\nsafety has become increasingly critical. However, existing defense methods\noften struggle with two key issues: (i) inadequate defense capabilities,\nparticularly in domain-specific scenarios like chemistry, where a lack of\nspecialized knowledge can lead to the generation of harmful responses to\nmalicious queries. (ii) over-defensiveness, which compromises the general\nutility and responsiveness of LLMs. To mitigate these issues, we introduce a\nmulti-agents-based defense framework, Guide for Defense (G4D), which leverages\naccurate external information to provide an unbiased summary of user intentions\nand analytically grounded safety response guidance. Extensive experiments on\npopular jailbreak attacks and benign datasets show that our G4D can enhance\nLLM's robustness against jailbreak attacks on general and domain-specific\nscenarios without compromising the model's general functionality.",
      "tldr_zh": "该研究针对大型语言模型(LLMs)的安全问题，指出现有防御方法在领域特定场景（如化学）中防御不足且容易过度防御，从而影响模型的通用性。为解决这些问题，论文提出了一种多智能体防御框架Guide for Defense (G4D)，利用准确的外部信息对用户意图进行无偏总结并提供基于分析的安全响应指导。实验结果显示，G4D显著提升了LLMs在一般和领域特定场景下的鲁棒性，能够有效抵御jailbreak attacks，同时保持模型的整体功能性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.17922v2",
      "published_date": "2024-10-23 14:40:37 UTC",
      "updated_date": "2025-02-09 03:34:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:33:22.103760"
    },
    {
      "arxiv_id": "2410.17918v1",
      "title": "Addressing Asynchronicity in Clinical Multimodal Fusion via Individualized Chest X-ray Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Wenfang Yao",
        "Chen Liu",
        "Kejing Yin",
        "William K. Cheung",
        "Jing Qin"
      ],
      "abstract": "Integrating multi-modal clinical data, such as electronic health records\n(EHR) and chest X-ray images (CXR), is particularly beneficial for clinical\nprediction tasks. However, in a temporal setting, multi-modal data are often\ninherently asynchronous. EHR can be continuously collected but CXR is generally\ntaken with a much longer interval due to its high cost and radiation dose. When\nclinical prediction is needed, the last available CXR image might have been\noutdated, leading to suboptimal predictions. To address this challenge, we\npropose DDL-CXR, a method that dynamically generates an up-to-date latent\nrepresentation of the individualized CXR images. Our approach leverages latent\ndiffusion models for patient-specific generation strategically conditioned on a\nprevious CXR image and EHR time series, providing information regarding\nanatomical structures and disease progressions, respectively. In this way, the\ninteraction across modalities could be better captured by the latent CXR\ngeneration process, ultimately improving the prediction performance.\nExperiments using MIMIC datasets show that the proposed model could effectively\naddress asynchronicity in multimodal fusion and consistently outperform\nexisting methods.",
      "tldr_zh": "该论文针对临床多模态融合中的异步问题（如EHR和CXR数据不匹配）提出DDL-CXR方法，通过动态生成个性化的CXR图像潜在表示来解决预测偏差。DDL-CXR利用latent diffusion models，以先前的CXR图像和EHR时间序列作为条件，捕捉模态间的交互并反映解剖结构和疾病进展。实验在MIMIC数据集上显示，该方法有效缓解了异步挑战，并显著优于现有模型的预测性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by NeurIPS-24",
      "pdf_url": "http://arxiv.org/pdf/2410.17918v1",
      "published_date": "2024-10-23 14:34:39 UTC",
      "updated_date": "2024-10-23 14:34:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:33:33.740492"
    },
    {
      "arxiv_id": "2410.17906v1",
      "title": "Leveraging Deep Learning for Time Series Extrinsic Regression in predicting photometric metallicity of Fundamental-mode RR Lyrae Stars",
      "title_zh": "翻译失败",
      "authors": [
        "Lorenzo Monti",
        "Tatiana Muraveva",
        "Gisella Clementini",
        "Alessia Garofalo"
      ],
      "abstract": "Astronomy is entering an unprecedented era of Big Data science, driven by\nmissions like the ESA's Gaia telescope, which aims to map the Milky Way in\nthree dimensions. Gaia's vast dataset presents a monumental challenge for\ntraditional analysis methods. The sheer scale of this data exceeds the\ncapabilities of manual exploration, necessitating the utilization of advanced\ncomputational techniques. In response to this challenge, we developed a novel\napproach leveraging deep learning to estimate the metallicity of fundamental\nmode (ab-type) RR Lyrae stars from their light curves in the Gaia optical\nG-band. Our study explores applying deep learning techniques, particularly\nadvanced neural network architectures, in predicting photometric metallicity\nfrom time-series data. Our deep learning models demonstrated notable predictive\nperformance, with a low mean absolute error (MAE) of 0.0565, the root mean\nsquare error (RMSE) achieved is 0.0765 and a high $R^2$ regression performance\nof 0.9401 measured by cross-validation. The weighted mean absolute error (wMAE)\nis 0.0563, while the weighted root mean square error (wRMSE) is 0.0763. These\nresults showcase the effectiveness of our approach in accurately estimating\nmetallicity values. Our work underscores the importance of deep learning in\nastronomical research, particularly with large datasets from missions like\nGaia. By harnessing the power of deep learning methods, we can provide\nprecision in analyzing vast datasets, contributing to more precise and\ncomprehensive insights into complex astronomical phenomena.",
      "tldr_zh": "这篇论文利用深度学习（deep learning）对时间序列外推回归（time series extrinsic regression）进行研究，旨在从Gaia望远镜的光变曲线（light curves）预测基本模式（Fundamental-mode）RR Lyrae恒星的光度金属丰度（photometric metallicity）。研究开发了一种新方法，采用高级神经网络架构来处理天文学大数据挑战，实现对金属丰度的准确估计。实验结果显示，模型的均绝对误差（MAE）为0.0565、均方根误差（RMSE）为0.0765，以及R²回归性能为0.9401，证明了其高预测精度。该工作强调了深度学习在分析Gaia等大型天文数据集中的关键作用，为复杂天文现象的研究提供了更精确的洞见。",
      "categories": [
        "cs.AI",
        "astro-ph.IM"
      ],
      "primary_category": "cs.AI",
      "comment": "Sensors 2024, 24(16), 5203; (23 pages)",
      "pdf_url": "http://arxiv.org/pdf/2410.17906v1",
      "published_date": "2024-10-23 14:26:35 UTC",
      "updated_date": "2024-10-23 14:26:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:33:47.670848"
    },
    {
      "arxiv_id": "2410.17904v1",
      "title": "Reinforcement Learning under Latent Dynamics: Toward Statistical and Algorithmic Modularity",
      "title_zh": "翻译失败",
      "authors": [
        "Philip Amortila",
        "Dylan J. Foster",
        "Nan Jiang",
        "Akshay Krishnamurthy",
        "Zakaria Mhammedi"
      ],
      "abstract": "Real-world applications of reinforcement learning often involve environments\nwhere agents operate on complex, high-dimensional observations, but the\nunderlying (''latent'') dynamics are comparatively simple. However, outside of\nrestrictive settings such as small latent spaces, the fundamental statistical\nrequirements and algorithmic principles for reinforcement learning under latent\ndynamics are poorly understood.\n  This paper addresses the question of reinforcement learning under\n$\\textit{general}$ latent dynamics from a statistical and algorithmic\nperspective. On the statistical side, our main negative result shows that most\nwell-studied settings for reinforcement learning with function approximation\nbecome intractable when composed with rich observations; we complement this\nwith a positive result, identifying latent pushforward coverability as a\ngeneral condition that enables statistical tractability. Algorithmically, we\ndevelop provably efficient observable-to-latent reductions -- that is,\nreductions that transform an arbitrary algorithm for the latent MDP into an\nalgorithm that can operate on rich observations -- in two settings: one where\nthe agent has access to hindsight observations of the latent dynamics [LADZ23],\nand one where the agent can estimate self-predictive latent models [SAGHCB20].\nTogether, our results serve as a first step toward a unified statistical and\nalgorithmic theory for reinforcement learning under latent dynamics.",
      "tldr_zh": "这篇论文探讨了强化学习在潜在动态（Latent Dynamics）下的统计和算法挑战，强调了代理在复杂高维观察下进行学习时的困难。论文的主要负面结果表明，大多数基于函数逼近的强化学习设置在丰富观察下变得统计上不可行，但它识别了“latent pushforward coverability”作为一种使问题可处理的通用条件。算法方面，论文开发了可证明有效的“observable-to-latent reductions”，包括在后见观察（hindsight observations）场景和估计自预测潜在模型（self-predictive latent models）场景下的方法。这些贡献共同推动了强化学习在潜在动态下的统一理论框架。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.17904v1",
      "published_date": "2024-10-23 14:22:49 UTC",
      "updated_date": "2024-10-23 14:22:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:35:59.321919"
    },
    {
      "arxiv_id": "2410.17885v2",
      "title": "R-CoT: Reverse Chain-of-Thought Problem Generation for Geometric Reasoning in Large Multimodal Models",
      "title_zh": "R-CoT：反向链式思维问题生成用于大型多模态模型中的几何推理",
      "authors": [
        "Linger Deng",
        "Yuliang Liu",
        "Bohan Li",
        "Dongliang Luo",
        "Liang Wu",
        "Chengquan Zhang",
        "Pengyuan Lyu",
        "Ziyang Zhang",
        "Gang Zhang",
        "Errui Ding",
        "Yingying Zhu",
        "Xiang Bai"
      ],
      "abstract": "Existing Large Multimodal Models (LMMs) struggle with mathematical geometric\nreasoning due to a lack of high-quality image-text paired data. Current\ngeometric data generation approaches, which apply preset templates to generate\ngeometric data or use Large Language Models (LLMs) to rephrase questions and\nanswers (Q&A), unavoidably limit data accuracy and diversity. To synthesize\nhigher-quality data, we propose a two-stage Reverse Chain-of-Thought (R-CoT)\ngeometry problem generation pipeline. First, we introduce GeoChain to produce\nhigh-fidelity geometric images and corresponding descriptions highlighting\nrelations among geometric elements. We then design a Reverse A&Q method that\nreasons step-by-step based on the descriptions and generates questions in\nreverse from the reasoning results. Experiments demonstrate that the proposed\nmethod brings significant and consistent improvements on multiple LMM\nbaselines, achieving new performance records in the 2B, 7B, and 8B settings.\nNotably, R-CoT-8B significantly outperforms previous state-of-the-art\nopen-source mathematical models by 16.6% on MathVista and 9.2% on GeoQA, while\nalso surpassing the closed-source model GPT-4o by an average of 13% across both\ndatasets. The code is available at https://github.com/dle666/R-CoT.",
      "tldr_zh": "该研究针对大型多模态模型 (LMMs) 在几何推理中的数据缺失问题，提出了一种两阶段 Reverse Chain-of-Thought (R-CoT) 问题生成管道，以提升数据质量和多样性。\n首先，引入 GeoChain 生成高保真几何图像及其描述，突出元素间关系；随后，采用 Reverse A&Q 方法基于这些描述进行逐步推理，并反向生成问题。\n实验结果显示，R-CoT 方法显著提升了多个 LMM 基线的性能，其中 R-CoT-8B 在 MathVista 上比开源模型高 16.6%、在 GeoQA 上高 9.2%，并平均超过 GPT-4o 13%。",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.17885v2",
      "published_date": "2024-10-23 13:58:39 UTC",
      "updated_date": "2024-10-27 09:02:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:36:11.986038"
    },
    {
      "arxiv_id": "2410.17883v2",
      "title": "Lightweight Neural App Control",
      "title_zh": "翻译失败",
      "authors": [
        "Filippos Christianos",
        "Georgios Papoudakis",
        "Thomas Coste",
        "Jianye Hao",
        "Jun Wang",
        "Kun Shao"
      ],
      "abstract": "This paper introduces a novel mobile phone control architecture, Lightweight\nMulti-modal App Control (LiMAC), for efficient interactions and control across\nvarious Android apps. LiMAC takes as input a textual goal and a sequence of\npast mobile observations, such as screenshots and corresponding UI trees, to\ngenerate precise actions. To address the computational constraints inherent to\nsmartphones, we introduce a small Action Transformer (AcT) integrated with a\nfine-tuned vision-language model (VLM) for real-time decision-making and task\nexecution. We evaluate LiMAC on two open-source mobile control datasets,\ndemonstrating the superior performance of our small-form-factor approach\nagainst fine-tuned versions of open-source VLMs, such as Florence2 and\nQwen2-VL. It also significantly outperforms prompt engineering baselines\nutilising closed-source foundation models like GPT-4o. More specifically, LiMAC\nincreases the overall action accuracy by up to 19% compared to fine-tuned VLMs,\nand up to 42% compared to prompt-engineering baselines.",
      "tldr_zh": "这篇论文提出了 Lightweight Multi-modal App Control (LiMAC)，一种新型架构，用于高效交互和控制各种 Android 应用。它以文本目标和过去观察序列（如截图和 UI 树）作为输入，结合小型 Action Transformer (AcT) 与微调的 vision-language model (VLM)，实现实时决策和精确动作生成，以适应智能手机的计算限制。在两个开源移动控制数据集上评估，LiMAC 的动作准确率比微调的开源 VLM（如 Florence2 和 Qwen2-VL）提高最多 19%，并比基于 GPT-4o 的提示工程基线提高最多 42%。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "ICLR 2025 (spotlight)",
      "pdf_url": "http://arxiv.org/pdf/2410.17883v2",
      "published_date": "2024-10-23 13:57:00 UTC",
      "updated_date": "2025-02-12 17:51:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:36:23.477078"
    },
    {
      "arxiv_id": "2410.17875v3",
      "title": "Understanding Layer Significance in LLM Alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Guangyuan Shi",
        "Zexin Lu",
        "Xiaoyu Dong",
        "Wenlong Zhang",
        "Xuanyu Zhang",
        "Yujie Feng",
        "Xiao-Ming Wu"
      ],
      "abstract": "Aligning large language models (LLMs) through supervised fine-tuning is\nessential for tailoring them to specific applications. Recent studies suggest\nthat alignment primarily adjusts a model's presentation style rather than its\nfoundational knowledge, indicating that only certain components of the model\nare significantly impacted. To uncover how alignment affects model behavior at\na granular level, we propose identifying which layers within LLMs are most\ncritical to the alignment process. Our approach, named ILA, involves learning a\nbinary mask for the parameter changes in each layer during alignment, as an\nindicator of layer significance. Experimental results reveal that, despite\nsubstantial differences in alignment datasets, the important layers of a model\nidentified by ILA exhibit nearly 90\\% overlap, highlighting fundamental\npatterns in LLM alignment. The results also indicate that freezing\nnon-essential layers improves overall model performance, while selectively\ntuning the most critical layers significantly enhances fine-tuning efficiency\nwith minimal performance loss. Finally, we discuss how these findings extend\nfrom LLM alignment to reasoning.",
      "tldr_zh": "本文研究了在LLM对齐过程中层的重要性，提出ILA方法，通过学习每个层的参数变化二进制掩码来识别关键层。实验结果显示，尽管对齐数据集不同，重要层之间有近90%的重叠，揭示了LLM对齐的基本模式。冻结非关键层可提升整体性能，选择性微调关键层则显著提高微调效率，同时保持最小性能损失，并将这些发现扩展到LLM推理领域。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.17875v3",
      "published_date": "2024-10-23 13:47:05 UTC",
      "updated_date": "2025-04-08 09:44:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:36:54.369169"
    },
    {
      "arxiv_id": "2411.05013v1",
      "title": "Enhancing literature review with LLM and NLP methods. Algorithmic trading case",
      "title_zh": "使用 LLM 和 NLP 方法增强文献综述：算法交易案例",
      "authors": [
        "Stanisław Łaniewski",
        "Robert Ślepaczuk"
      ],
      "abstract": "This study utilizes machine learning algorithms to analyze and organize\nknowledge in the field of algorithmic trading. By filtering a dataset of 136\nmillion research papers, we identified 14,342 relevant articles published\nbetween 1956 and Q1 2020. We compare traditional practices-such as\nkeyword-based algorithms and embedding techniques-with state-of-the-art topic\nmodeling methods that employ dimensionality reduction and clustering. This\ncomparison allows us to assess the popularity and evolution of different\napproaches and themes within algorithmic trading. We demonstrate the usefulness\nof Natural Language Processing (NLP) in the automatic extraction of knowledge,\nhighlighting the new possibilities created by the latest iterations of Large\nLanguage Models (LLMs) like ChatGPT. The rationale for focusing on this topic\nstems from our analysis, which reveals that research articles on algorithmic\ntrading are increasing at a faster rate than the overall number of\npublications. While stocks and main indices comprise more than half of all\nassets considered, certain asset classes, such as cryptocurrencies, exhibit a\nmuch stronger growth trend. Machine learning models have become the most\npopular methods in recent years. The study demonstrates the efficacy of LLMs in\nrefining datasets and addressing intricate questions about the analyzed\narticles, such as comparing the efficiency of different models. Our research\nshows that by decomposing tasks into smaller components and incorporating\nreasoning steps, we can effectively tackle complex questions supported by case\nanalyses. This approach contributes to a deeper understanding of algorithmic\ntrading methodologies and underscores the potential of advanced NLP techniques\nin literature reviews.",
      "tldr_zh": "这篇论文利用机器学习、NLP 和 LLM 方法（如 ChatGPT）增强算法交易领域的文献综述，通过从 1.36 亿篇论文中筛选出 14,342 篇相关文章（1956-2020 年），并比较传统关键词和嵌入技术与先进的主题建模方法（包括降维和聚类）。研究评估了不同方法在算法交易主题的流行度和演变，揭示了该领域研究增长率高于整体出版物，且机器学习模型已成为主流。结果表明，LLM 在精炼数据集和处理复杂问题（如模型效率比较）方面表现出色，通过任务分解和推理步骤提升了知识提取效率。该方法深化了对算法交易方法的理解，并突出了高级 NLP 技术在文献综述中的潜力。",
      "categories": [
        "q-fin.ST",
        "cs.AI",
        "cs.LG",
        "q-fin.TR"
      ],
      "primary_category": "q-fin.ST",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.05013v1",
      "published_date": "2024-10-23 13:37:27 UTC",
      "updated_date": "2024-10-23 13:37:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:36:47.898791"
    },
    {
      "arxiv_id": "2410.17859v1",
      "title": "DataTales: A Benchmark for Real-World Intelligent Data Narration",
      "title_zh": "DataTales：真实世界智能数据叙述的基准测试",
      "authors": [
        "Yajing Yang",
        "Qian Liu",
        "Min-Yen Kan"
      ],
      "abstract": "We introduce DataTales, a novel benchmark designed to assess the proficiency\nof language models in data narration, a task crucial for transforming complex\ntabular data into accessible narratives. Existing benchmarks often fall short\nin capturing the requisite analytical complexity for practical applications.\nDataTales addresses this gap by offering 4.9k financial reports paired with\ncorresponding market data, showcasing the demand for models to create clear\nnarratives and analyze large datasets while understanding specialized\nterminology in the field. Our findings highlights the significant challenge\nthat language models face in achieving the necessary precision and analytical\ndepth for proficient data narration, suggesting promising avenues for future\nmodel development and evaluation methodologies.",
      "tldr_zh": "本研究引入了DataTales，一个新的基准，用于评估语言模型在真实世界数据叙述任务中的表现，该任务涉及将复杂表格数据转化为易懂的叙述。DataTales 包含 4.9k 份财务报告及其对应市场数据，强调模型需生成清晰叙述、分析大型数据集并理解专业术语，以弥补现有基准在分析复杂性上的不足。实验结果显示，语言模型在精确性和分析深度方面面临重大挑战，为未来模型开发和评估方法提供了有前景的方向。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.17859v1",
      "published_date": "2024-10-23 13:30:02 UTC",
      "updated_date": "2024-10-23 13:30:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:36:58.291908"
    },
    {
      "arxiv_id": "2410.17856v3",
      "title": "ROCKET-1: Mastering Open-World Interaction with Visual-Temporal Context Prompting",
      "title_zh": "ROCKET-1：通过视觉-时间上下文提示掌握开放世界互动",
      "authors": [
        "Shaofei Cai",
        "Zihao Wang",
        "Kewei Lian",
        "Zhancun Mu",
        "Xiaojian Ma",
        "Anji Liu",
        "Yitao Liang"
      ],
      "abstract": "Vision-language models (VLMs) have excelled in multimodal tasks, but adapting\nthem to embodied decision-making in open-world environments presents\nchallenges. One critical issue is bridging the gap between discrete entities in\nlow-level observations and the abstract concepts required for effective\nplanning. A common solution is building hierarchical agents, where VLMs serve\nas high-level reasoners that break down tasks into executable sub-tasks,\ntypically specified using language. However, language suffers from the\ninability to communicate detailed spatial information. We propose\nvisual-temporal context prompting, a novel communication protocol between VLMs\nand policy models. This protocol leverages object segmentation from past\nobservations to guide policy-environment interactions. Using this approach, we\ntrain ROCKET-1, a low-level policy that predicts actions based on concatenated\nvisual observations and segmentation masks, supported by real-time object\ntracking from SAM-2. Our method unlocks the potential of VLMs, enabling them to\ntackle complex tasks that demand spatial reasoning. Experiments in Minecraft\nshow that our approach enables agents to achieve previously unattainable tasks,\nwith a $\\mathbf{76}\\%$ absolute improvement in open-world interaction\nperformance. Codes and demos are now available on the project page:\nhttps://craftjarvis.github.io/ROCKET-1.",
      "tldr_zh": "该论文探讨了视觉语言模型（VLMs）在开放世界环境中进行具身决策的挑战，特别是语言在传达空间信息方面的局限性。作者提出visual-temporal context prompting协议，利用对象分割和过去观察来桥接VLMs与策略模型的交互，并训练ROCKET-1低级策略模型，该模型基于视觉观察、分割掩码和SAM-2实时对象跟踪来预测动作。实验结果显示，在Minecraft中，该方法使代理性能绝对提升76%，显著增强了VLMs处理空间推理任务的能力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.17856v3",
      "published_date": "2024-10-23 13:26:59 UTC",
      "updated_date": "2025-03-20 11:55:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:37:10.600143"
    },
    {
      "arxiv_id": "2410.17855v1",
      "title": "TAGE: Trustworthy Attribute Group Editing for Stable Few-shot Image Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Ruicheng Zhang",
        "Guoheng Huang",
        "Yejing Huo",
        "Xiaochen Yuan",
        "Zhizhen Zhou",
        "Xuhang Chen",
        "Guo Zhong"
      ],
      "abstract": "Generative Adversarial Networks (GANs) have emerged as a prominent research\nfocus for image editing tasks, leveraging the powerful image generation\ncapabilities of the GAN framework to produce remarkable results.However,\nprevailing approaches are contingent upon extensive training datasets and\nexplicit supervision, presenting a significant challenge in manipulating the\ndiverse attributes of new image classes with limited sample availability. To\nsurmount this hurdle, we introduce TAGE, an innovative image generation network\ncomprising three integral modules: the Codebook Learning Module (CLM), the Code\nPrediction Module (CPM) and the Prompt-driven Semantic Module (PSM). The CPM\nmodule delves into the semantic dimensions of category-agnostic attributes,\nencapsulating them within a discrete codebook. This module is predicated on the\nconcept that images are assemblages of attributes, and thus, by editing these\ncategory-independent attributes, it is theoretically possible to generate\nimages from unseen categories. Subsequently, the CPM module facilitates\nnaturalistic image editing by predicting indices of category-independent\nattribute vectors within the codebook. Additionally, the PSM module generates\nsemantic cues that are seamlessly integrated into the Transformer architecture\nof the CPM, enhancing the model's comprehension of the targeted attributes for\nediting. With these semantic cues, the model can generate images that\naccentuate desired attributes more prominently while maintaining the integrity\nof the original category, even with a limited number of samples. We have\nconducted extensive experiments utilizing the Animal Faces, Flowers, and\nVGGFaces datasets. The results of these experiments demonstrate that our\nproposed method not only achieves superior performance but also exhibits a high\ndegree of stability when compared to other few-shot image generation\ntechniques.",
      "tldr_zh": "本研究提出 TAGE，一种可信赖的属性组编辑框架，用于稳定少样本图像生成，旨在解决传统 GANs 方法依赖大量训练数据和监督的问题。TAGE 包括三个关键模块：Codebook Learning Module (CLM) 用于构建离散代码本、Code Prediction Module (CPM) 通过预测类别无关属性向量实现自然图像编辑，以及 Prompt-driven Semantic Module (PSM) 集成语义提示到 CPM 的 Transformer 架构中，以增强目标属性的理解和生成稳定性。实验在 Animal Faces、Flowers 和 VGGFaces 数据集上表明，TAGE 相较于其他少样本生成技术，表现出色，实现了更高的性能和稳定性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by International Conference on Signal Processing Systems\n  Conference",
      "pdf_url": "http://arxiv.org/pdf/2410.17855v1",
      "published_date": "2024-10-23 13:26:19 UTC",
      "updated_date": "2024-10-23 13:26:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:37:22.713695"
    },
    {
      "arxiv_id": "2410.17851v2",
      "title": "The Probabilistic Tsetlin Machine: A Novel Approach to Uncertainty Quantification",
      "title_zh": "翻译失败",
      "authors": [
        "K. Darshana Abeyrathna",
        "Sara El Mekkaoui",
        "Andreas Hafver",
        "Christian Agrell"
      ],
      "abstract": "Tsetlin Machines (TMs) have emerged as a compelling alternative to\nconventional deep learning methods, offering notable advantages such as smaller\nmemory footprint, faster inference, fault-tolerant properties, and\ninterpretability. Although various adaptations of TMs have expanded their\napplicability across diverse domains, a fundamental gap remains in\nunderstanding how TMs quantify uncertainty in their predictions. In response,\nthis paper introduces the Probabilistic Tsetlin Machine (PTM) framework, aimed\nat providing a robust, reliable, and interpretable approach for uncertainty\nquantification. Unlike the original TM, the PTM learns the probability of\nstaying on each state of each Tsetlin Automaton (TA) across all clauses. These\nprobabilities are updated using the feedback tables that are part of the TM\nframework: Type I and Type II feedback. During inference, TAs decide their\nactions by sampling states based on learned probability distributions, akin to\nBayesian neural networks when generating weight values. In our experimental\nanalysis, we first illustrate the spread of the probabilities across TA states\nfor the noisy-XOR dataset. Then we evaluate the PTM alongside benchmark models\nusing both simulated and real-world datasets. The experiments on the simulated\ndataset reveal the PTM's effectiveness in uncertainty quantification,\nparticularly in delineating decision boundaries and identifying regions of high\nuncertainty. Moreover, when applied to multiclass classification tasks using\nthe Iris dataset, the PTM demonstrates competitive performance in terms of\npredictive entropy and expected calibration error, showcasing its potential as\na reliable tool for uncertainty estimation. Our findings underscore the\nimportance of selecting appropriate models for accurate uncertainty\nquantification in predictive tasks, with the PTM offering a particularly\ninterpretable and effective solution.",
      "tldr_zh": "这篇论文引入了Probabilistic Tsetlin Machine (PTM)，一种新型框架，用于提升Tsetlin Machines (TMs)在不确定性量化方面的鲁棒性、可信性和可解释性。PTM通过学习每个Tsetlin Automaton (TA)状态的概率，并利用Type I and Type II feedback更新这些概率，在推理时通过采样概率分布进行决策，类似于Bayesian neural networks。实验结果显示，PTM在noisy-XOR数据集上有效展示了概率分布，并在模拟和真实数据集（如Iris数据集）上表现出色，能够清晰界定决策边界、高不确定性区域，并与基准模型在预测熵和校准误差方面竞争。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "12 pages, 5 figures, 6 tables, accepted and presented at ICAAI 2024,\n  London",
      "pdf_url": "http://arxiv.org/pdf/2410.17851v2",
      "published_date": "2024-10-23 13:20:42 UTC",
      "updated_date": "2024-11-13 10:01:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:37:35.528580"
    },
    {
      "arxiv_id": "2410.17827v1",
      "title": "RE-tune: Incremental Fine Tuning of Biomedical Vision-Language Models for Multi-label Chest X-ray Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Marco Mistretta",
        "Andrew D. Bagdanov"
      ],
      "abstract": "In this paper we introduce RE-tune, a novel approach for fine-tuning\npre-trained Multimodal Biomedical Vision-Language models (VLMs) in Incremental\nLearning scenarios for multi-label chest disease diagnosis. RE-tune freezes the\nbackbones and only trains simple adaptors on top of the Image and Text encoders\nof the VLM. By engineering positive and negative text prompts for diseases, we\nleverage the ability of Large Language Models to steer the training trajectory.\nWe evaluate RE-tune in three realistic incremental learning scenarios:\nclass-incremental, label-incremental, and data-incremental. Our results\ndemonstrate that Biomedical VLMs are natural continual learners and prevent\ncatastrophic forgetting. RE-tune not only achieves accurate multi-label\nclassification results, but also prioritizes patient privacy and it\ndistinguishes itself through exceptional computational efficiency, rendering it\nhighly suitable for broad adoption in real-world healthcare settings.",
      "tldr_zh": "本文提出 RE-tune 方法，用于在增量学习场景中微调预训练的生物医学视觉语言模型（VLMs），以实现多标签胸部X光疾病诊断。该方法冻结模型骨干网络，仅训练图像和文本编码器的简单适配器，并通过设计正负文本提示来利用大语言模型引导训练轨迹。在类增量、标签增量和数据增量三种场景的评估中，RE-tune 证明了 VLMs 的持续学习能力，防止灾难性遗忘，同时提供准确的分类结果、优先患者隐私并展现出高计算效率，适用于实际医疗环境。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted for publication at Medical Imaging meets NeurIPS (NeurIPS23)",
      "pdf_url": "http://arxiv.org/pdf/2410.17827v1",
      "published_date": "2024-10-23 12:40:33 UTC",
      "updated_date": "2024-10-23 12:40:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:37:47.084927"
    },
    {
      "arxiv_id": "2410.17812v1",
      "title": "PGDiffSeg: Prior-Guided Denoising Diffusion Model with Parameter-Shared Attention for Breast Cancer Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Feiyan Feng",
        "Tianyu Liu",
        "Hong Wang",
        "Jun Zhao",
        "Wei Li",
        "Yanshen Sun"
      ],
      "abstract": "Early detection through imaging and accurate diagnosis is crucial in\nmitigating the high mortality rate associated with breast cancer. However,\nlocating tumors from low-resolution and high-noise medical images is extremely\nchallenging. Therefore, this paper proposes a novel PGDiffSeg (Prior-Guided\nDiffusion Denoising Model with Parameter-Shared Attention) that applies\ndiffusion denoising methods to breast cancer medical image segmentation,\naccurately recovering the affected areas from Gaussian noise. Firstly, we\ndesign a parallel pipeline for noise processing and semantic information\nprocessing and propose a parameter-shared attention module (PSA) in multi-layer\nthat seamlessly integrates these two pipelines. This integration empowers\nPGDiffSeg to incorporate semantic details at multiple levels during the\ndenoising process, producing highly accurate segmentation maps. Secondly, we\nintroduce a guided strategy that leverages prior knowledge to simulate the\ndecision-making process of medical professionals, thereby enhancing the model's\nability to locate tumor positions precisely. Finally, we provide the first-ever\ndiscussion on the interpretability of the generative diffusion model in the\ncontext of breast cancer segmentation. Extensive experiments have demonstrated\nthe superiority of our model over the current state-of-the-art approaches,\nconfirming its effectiveness as a flexible diffusion denoising method suitable\nfor medical image research. Our code will be publicly available later.",
      "tldr_zh": "本论文提出 PGDiffSeg，一种先导引导的去噪扩散模型，用于乳腺癌分割任务，能够从低分辨率和高噪声医疗图像中准确恢复肿瘤区域。模型设计了并行管道处理噪声和语义信息，并引入参数共享注意力模块 (PSA) 在多层中无缝整合这些信息，从而在去噪过程中融入多层次语义细节，提升分割精度。其次，通过先验知识引导策略模拟医疗专业人士的决策过程，并首次讨论生成扩散模型在乳腺癌分割中的可解释性。实验结果表明，PGDiffSeg 优于现有最先进方法，在乳腺癌图像处理中展现出显著优势。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.17812v1",
      "published_date": "2024-10-23 12:17:03 UTC",
      "updated_date": "2024-10-23 12:17:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:37:59.125919"
    },
    {
      "arxiv_id": "2410.17799v2",
      "title": "OmniFlatten: An End-to-end GPT Model for Seamless Voice Conversation",
      "title_zh": "OmniFlatten：一种端到端的 GPT 模型，用于无缝语音对话",
      "authors": [
        "Qinglin Zhang",
        "Luyao Cheng",
        "Chong Deng",
        "Qian Chen",
        "Wen Wang",
        "Siqi Zheng",
        "Jiaqing Liu",
        "Hai Yu",
        "Chaohong Tan",
        "Zhihao Du",
        "Shiliang Zhang"
      ],
      "abstract": "Full-duplex spoken dialogue systems significantly surpass traditional\nturn-based dialogue systems, as they allow simultaneous bidirectional\ncommunication, closely mirroring human-human interactions. However, achieving\nlow latency and natural interactions in full-duplex dialogue systems remains a\nsignificant challenge, especially considering human conversation dynamics such\nas interruptions, backchannels, and overlapping speech. In this paper, we\nintroduce a novel End-to-End GPT-based model OmniFlatten for full-duplex\nconversation, capable of effectively modeling the complex behaviors inherent to\nnatural conversations with low latency. To achieve full-duplex conversation\ncapabilities, we propose a multi-stage post-training scheme that progressively\nadapts a text large language model (LLM) backbone into a speech-text dialogue\nLLM, capable of generating text and speech in real time, without modifying the\narchitecture of the backbone LLM. The training process comprises three stages:\nmodality alignment, half-duplex dialogue learning, and full-duplex dialogue\nlearning. In all training stages, we standardize the data using a flattening\noperation, which enables unifying the training methods and the GPT backbone\nacross different modalities and tasks. Our approach offers a simple modeling\ntechnique and a promising research direction for developing efficient and\nnatural end-to-end full-duplex spoken dialogue systems. Audio samples of\ndialogues generated by OmniFlatten can be found at this web site\n(https://omniflatten.github.io/).",
      "tldr_zh": "该论文提出 OmniFlatten，一种端到端 GPT 模型，用于实现低延迟的全双工语音对话系统，能够有效处理自然对话中的中断、回馈和重叠语音等问题。通过多阶段后训练方案，包括模态对齐、半双工对话学习和全双工对话学习，该模型将文本 LLM 适应为语音-文本对话系统，并使用 flattening 操作统一数据处理和模型架构。实验结果表明，这种方法简化了建模技术，为高效、自然的端到端全双工对话系统提供了新研究方向，并提供了音频样本以展示效果。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "Work in progress",
      "pdf_url": "http://arxiv.org/pdf/2410.17799v2",
      "published_date": "2024-10-23 11:58:58 UTC",
      "updated_date": "2025-01-03 06:15:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:38:10.915202"
    },
    {
      "arxiv_id": "2410.17792v1",
      "title": "Enhancing Federated Learning Convergence with Dynamic Data Queue and Data Entropy-driven Participant Selection",
      "title_zh": "利用动态数据队列和数据",
      "authors": [
        "Charuka Herath",
        "Xiaolan Liu",
        "Sangarapillai Lambotharan",
        "Yogachandran Rahulamathavan"
      ],
      "abstract": "Federated Learning (FL) is a decentralized approach for collaborative model\ntraining on edge devices. This distributed method of model training offers\nadvantages in privacy, security, regulatory compliance, and cost-efficiency.\nOur emphasis in this research lies in addressing statistical complexity in FL,\nespecially when the data stored locally across devices is not identically and\nindependently distributed (non-IID). We have observed an accuracy reduction of\nup to approximately 10\\% to 30\\%, particularly in skewed scenarios where each\nedge device trains with only 1 class of data. This reduction is attributed to\nweight divergence, quantified using the Euclidean distance between device-level\nclass distributions and the population distribution, resulting in a bias term\n(\\(\\delta_k\\)). As a solution, we present a method to improve convergence in FL\nby creating a global subset of data on the server and dynamically distributing\nit across devices using a Dynamic Data queue-driven Federated Learning (DDFL).\nNext, we leverage Data Entropy metrics to observe the process during each\ntraining round and enable reasonable device selection for aggregation.\nFurthermore, we provide a convergence analysis of our proposed DDFL to justify\ntheir viability in practical FL scenarios, aiming for better device selection,\na non-sub-optimal global model, and faster convergence. We observe that our\napproach results in a substantial accuracy boost of approximately 5\\% for the\nMNIST dataset, around 18\\% for CIFAR-10, and 20\\% for CIFAR-100 with a 10\\%\nglobal subset of data, outperforming the state-of-the-art (SOTA) aggregation\nalgorithms.",
      "tldr_zh": "本研究针对联邦学习（Federated Learning, FL）中数据非独立同分布（non-IID）问题导致的准确率下降（最高达10%至30%），提出了一种基于动态数据队列的FL方法（Dynamic Data queue-driven Federated Learning, DDFL）。该方法在服务器上创建全局数据子集并动态分发，同时利用Data Entropy指标监控训练过程并优化设备选择，以减少权重发散（weight divergence）和提升收敛速度。实验结果显示，DDFL在MNIST数据集上准确率提升约5%，CIFAR-10上约18%，CIFAR-100上约20%，并优于现有最先进（SOTA）聚合算法，为FL的实际应用提供了更可靠的框架。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "14J60 (Primary)",
        "I.2.11; I.5.1; I.5.4"
      ],
      "primary_category": "cs.LG",
      "comment": "The Journal is submitted to IEEE Transactions in the Internet of\n  Things",
      "pdf_url": "http://arxiv.org/pdf/2410.17792v1",
      "published_date": "2024-10-23 11:47:04 UTC",
      "updated_date": "2024-10-23 11:47:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:38:23.293032"
    },
    {
      "arxiv_id": "2410.17787v1",
      "title": "Large Language Models Engineer Too Many Simple Features For Tabular Data",
      "title_zh": "大型语言模型为表格数据构建了过多的简单特征",
      "authors": [
        "Jaris Küken",
        "Lennart Purucker",
        "Frank Hutter"
      ],
      "abstract": "Tabular machine learning problems often require time-consuming and\nlabor-intensive feature engineering. Recent efforts have focused on using large\nlanguage models (LLMs) to capitalize on their potential domain knowledge. At\nthe same time, researchers have observed ethically concerning negative biases\nin other LLM-related use cases, such as text generation. These developments\nmotivated us to investigate whether LLMs exhibit a bias that negatively impacts\nthe performance of feature engineering. While not ethically concerning, such a\nbias could hinder practitioners from fully utilizing LLMs for automated data\nscience. Therefore, we propose a method to detect potential biases by detecting\nanomalies in the frequency of operators (e.g., adding two features) suggested\nby LLMs when engineering new features. Our experiments evaluate the bias of\nfour LLMs, two big frontier and two small open-source models, across 27 tabular\ndatasets. Our results indicate that LLMs are biased toward simple operators,\nsuch as addition, and can fail to utilize more complex operators, such as\ngrouping followed by aggregations. Furthermore, the bias can negatively impact\nthe predictive performance when using LLM-generated features. Our results call\nfor mitigating bias when using LLMs for feature engineering.",
      "tldr_zh": "这篇论文揭示了大型语言模型 (LLMs) 在表格数据特征工程中存在偏见问题，即过度使用简单操作（如加法），而忽略复杂操作（如分组后聚合），从而影响模型性能。作者提出了一种检测方法，通过分析 LLMs 建议的操作频率异常来识别这种偏见。实验评估了四个 LLMs（包括两个前沿大模型和两个开源小模型）在 27 个表格数据集上的表现，结果显示这种偏见会导致预测准确性下降。论文呼吁采取措施缓解 LLMs 在特征工程中的偏见，以更好地支持自动化数据科学应用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Preprint",
      "pdf_url": "http://arxiv.org/pdf/2410.17787v1",
      "published_date": "2024-10-23 11:37:20 UTC",
      "updated_date": "2024-10-23 11:37:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:38:34.843041"
    },
    {
      "arxiv_id": "2410.17784v1",
      "title": "Holon Programming Model -- A Software-Defined Approach for System of Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Muhammad Ashfaq",
        "Ahmed R. Sadik",
        "Tommi Mikkonen",
        "Muhammad Waseem",
        "Niko Makitalo"
      ],
      "abstract": "As Systems of Systems evolve into increasingly complex networks, harnessing\ntheir collective potential becomes paramount. Traditional SoS engineering\napproaches lack the necessary programmability to develop third party SoS level\nbehaviors. To address this challenge, we propose a software defined approach to\nenable flexible and adaptive programming of SoS. We introduce the Holon\nProgramming Model, a software-defined framework designed to meet these needs.\nThe Holon Programming Model empowers developers to design and orchestrate\ncomplex system behaviors effectively, as illustrated in our disaster management\nscenario. This research outlines the Holon Programming Model theoretical\nunderpinnings and practical applications, with the aim of driving further\nexploration and advancement in the field of software defined SoS",
      "tldr_zh": "该研究针对 Systems of Systems (SoS) 的日益复杂性，指出传统工程方法缺乏可编程性，无法开发第三方 SoS 级行为。为解决这一挑战，提出 Holon Programming Model，这是一个软件定义的框架，允许开发者灵活设计和编排复杂系统行为，并通过灾难管理场景进行说明。该模型强调理论基础与实际应用的结合，旨在推动软件定义 SoS 领域的创新和发展。",
      "categories": [
        "cs.AI",
        "cs.ET",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.17784v1",
      "published_date": "2024-10-23 11:34:29 UTC",
      "updated_date": "2024-10-23 11:34:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:38:46.691710"
    },
    {
      "arxiv_id": "2410.17781v1",
      "title": "Evaluating Explanations Through LLMs: Beyond Traditional User Studies",
      "title_zh": "通过 LLMs 评估解释：超越传统用户研究",
      "authors": [
        "Francesco Bombassei De Bona",
        "Gabriele Dominici",
        "Tim Miller",
        "Marc Langheinrich",
        "Martin Gjoreski"
      ],
      "abstract": "As AI becomes fundamental in sectors like healthcare, explainable AI (XAI)\ntools are essential for trust and transparency. However, traditional user\nstudies used to evaluate these tools are often costly, time consuming, and\ndifficult to scale. In this paper, we explore the use of Large Language Models\n(LLMs) to replicate human participants to help streamline XAI evaluation. We\nreproduce a user study comparing counterfactual and causal explanations,\nreplicating human participants with seven LLMs under various settings. Our\nresults show that (i) LLMs can replicate most conclusions from the original\nstudy, (ii) different LLMs yield varying levels of alignment in the results,\nand (iii) experimental factors such as LLM memory and output variability affect\nalignment with human responses. These initial findings suggest that LLMs could\nprovide a scalable and cost-effective way to simplify qualitative XAI\nevaluation.",
      "tldr_zh": "本研究探讨了使用大型语言模型（LLMs）来评估可解释AI（XAI）解释，从而取代传统用户研究，以降低成本并提高可扩展性。作者复制了一个比较counterfactual explanations和causal explanations的用户研究，使用七个LLMs在不同设置下模拟人类参与者，结果显示LLMs能复制原研究的大部分结论，但不同LLMs的一致性有所差异，且因素如LLM记忆和输出变异性会影响结果的准确性。这些发现表明，LLMs可能为XAI的定性评估提供一种高效、可信赖的替代方案。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.17781v1",
      "published_date": "2024-10-23 11:31:52 UTC",
      "updated_date": "2024-10-23 11:31:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:38:58.295470"
    },
    {
      "arxiv_id": "2410.17772v2",
      "title": "Scaling Robot Policy Learning via Zero-Shot Labeling with Foundation Models",
      "title_zh": "翻译失败",
      "authors": [
        "Nils Blank",
        "Moritz Reuss",
        "Marcel Rühle",
        "Ömer Erdinç Yağmurlu",
        "Fabian Wenzel",
        "Oier Mees",
        "Rudolf Lioutikov"
      ],
      "abstract": "A central challenge towards developing robots that can relate human language\nto their perception and actions is the scarcity of natural language annotations\nin diverse robot datasets. Moreover, robot policies that follow natural\nlanguage instructions are typically trained on either templated language or\nexpensive human-labeled instructions, hindering their scalability. To this end,\nwe introduce NILS: Natural language Instruction Labeling for Scalability. NILS\nautomatically labels uncurated, long-horizon robot data at scale in a zero-shot\nmanner without any human intervention. NILS combines pretrained vision-language\nfoundation models in order to detect objects in a scene, detect object-centric\nchanges, segment tasks from large datasets of unlabelled interaction data and\nultimately label behavior datasets. Evaluations on BridgeV2, Fractal, and a\nkitchen play dataset show that NILS can autonomously annotate diverse robot\ndemonstrations of unlabeled and unstructured datasets while alleviating several\nshortcomings of crowdsourced human annotations, such as low data quality and\ndiversity. We use NILS to label over 115k trajectories obtained from over 430\nhours of robot data. We open-source our auto-labeling code and generated\nannotations on our website: http://robottasklabeling.github.io.",
      "tldr_zh": "该论文针对机器人策略学习中自然语言注释稀缺的问题，提出了一种零-shot 标注方法 NILS（Natural language Instruction Labeling for Scalability），它利用预训练的 vision-language foundation models 自动检测场景对象、对象中心变化，并从大型无标签交互数据中分割和标注任务，从而实现大规模机器人数据标注。NILS 无需人类干预，能高效处理未整理的长时序数据，并在 BridgeV2、Fractal 和厨房玩耍数据集上评估中展示了优越性，解决了人工标注的低质量和低多样性问题。最终，研究团队标注了超过 115k 轨迹（源自 430 小时机器人数据），并开源了代码和标注资源，以促进机器人政策的可扩展性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Project Website at https://robottasklabeling.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2410.17772v2",
      "published_date": "2024-10-23 11:19:48 UTC",
      "updated_date": "2024-10-26 07:39:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:39:11.774652"
    },
    {
      "arxiv_id": "2410.17764v1",
      "title": "Beyond Backpropagation: Optimization with Multi-Tangent Forward Gradients",
      "title_zh": "超越反向传播：基于多切线前向梯度的优化",
      "authors": [
        "Katharina Flügel",
        "Daniel Coquelin",
        "Marie Weiel",
        "Achim Streit",
        "Markus Götz"
      ],
      "abstract": "The gradients used to train neural networks are typically computed using\nbackpropagation. While an efficient way to obtain exact gradients,\nbackpropagation is computationally expensive, hinders parallelization, and is\nbiologically implausible. Forward gradients are an approach to approximate the\ngradients from directional derivatives along random tangents computed by\nforward-mode automatic differentiation. So far, research has focused on using a\nsingle tangent per step. This paper provides an in-depth analysis of\nmulti-tangent forward gradients and introduces an improved approach to\ncombining the forward gradients from multiple tangents based on orthogonal\nprojections. We demonstrate that increasing the number of tangents improves\nboth approximation quality and optimization performance across various tasks.",
      "tldr_zh": "该论文探讨了超越 backpropagation 的神经网络优化方法，提出使用 multi-tangent forward gradients 作为一种高效替代方案，以解决 backpropagation 的计算开销、并行化困难和生物学不 plausibility 问题。作者通过 in-depth analysis 分析多切线方法，并引入基于 orthogonal projections 的改进策略来结合多个切线的方向导数，从而提升梯度近似质量。实验结果表明，增加切线数量显著提高了优化性能，在各种任务中表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.17764v1",
      "published_date": "2024-10-23 11:02:59 UTC",
      "updated_date": "2024-10-23 11:02:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:39:21.965803"
    },
    {
      "arxiv_id": "2410.17758v2",
      "title": "A Neural Network Alternative to Tree-based Models",
      "title_zh": "翻译失败",
      "authors": [
        "Salvatore Raieli",
        "Nathalie Jeanray",
        "Stéphane Gerart",
        "Sebastien Vachenc",
        "Abdulrahman Altahhan"
      ],
      "abstract": "Tabular datasets are widely used in scientific disciplines such as biology.\nWhile these disciplines have already adopted AI methods to enhance their\nfindings and analysis, they mainly use tree-based methods due to their\ninterpretability. At the same time, artificial neural networks have been shown\nto offer superior flexibility and depth for rich and complex non-tabular\nproblems, but they are falling behind tree-based models for tabular data in\nterms of performance and interpretability. Although sparsity has been shown to\nimprove the interpretability and performance of ANN models for complex\nnon-tabular datasets, enforcing sparsity structurally and formatively for\ntabular data before training the model, remains an open question. To address\nthis question, we establish a method that infuses sparsity in neural networks\nby utilising attention mechanisms to capture the features' importance in\ntabular datasets. We show that our models, Sparse TABular NET or sTAB-Net with\nattention mechanisms, are more effective than tree-based models, reaching the\nstate-of-the-art on biological datasets. They further permit the extraction of\ninsights from these datasets and achieve better performance than post-hoc\nmethods like SHAP.",
      "tldr_zh": "本研究针对表格数据集（如生物学领域），提出了一种神经网络（neural networks）替代树-based 模型的方法，以解决神经网络在性能和可解释性上的不足。作者通过利用注意力机制（attention mechanisms）在训练前结构化注入稀疏性，开发了 Sparse TABular NET（sTAB-Net）模型，该模型能够捕捉特征重要性并提升可解释性。在生物数据集上的实验表明，sTAB-Net 达到了 state-of-the-art 水平，比树-based 模型和后验方法（如 SHAP）表现出色，并能有效提取数据集洞见。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.17758v2",
      "published_date": "2024-10-23 10:50:07 UTC",
      "updated_date": "2025-04-15 12:28:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:39:34.899089"
    },
    {
      "arxiv_id": "2410.19862v1",
      "title": "Real-Time Weapon Detection Using YOLOv8 for Enhanced Safety",
      "title_zh": "基于 YOLOv8 的实时武器检测以提升安全",
      "authors": [
        "Ayush Thakur",
        "Akshat Shrivastav",
        "Rohan Sharma",
        "Triyank Kumar",
        "Kabir Puri"
      ],
      "abstract": "This research paper presents the development of an AI model utilizing YOLOv8\nfor real-time weapon detection, aimed at enhancing safety in public spaces such\nas schools, airports, and public transportation systems. As incidents of\nviolence continue to rise globally, there is an urgent need for effective\nsurveillance technologies that can quickly identify potential threats. Our\napproach focuses on leveraging advanced deep learning techniques to create a\nhighly accurate and efficient system capable of detecting weapons in real-time\nvideo streams. The model was trained on a comprehensive dataset containing\nthousands of images depicting various types of firearms and edged weapons,\nensuring a robust learning process. We evaluated the model's performance using\nkey metrics such as precision, recall, F1-score, and mean Average Precision\n(mAP) across multiple Intersection over Union (IoU) thresholds, revealing a\nsignificant capability to differentiate between weapon and non-weapon classes\nwith minimal error. Furthermore, we assessed the system's operational\nefficiency, demonstrating that it can process frames at high speeds suitable\nfor real-time applications. The findings indicate that our YOLOv8-based weapon\ndetection model not only contributes to the existing body of knowledge in\ncomputer vision but also addresses critical societal needs for improved safety\nmeasures in vulnerable environments. By harnessing the power of artificial\nintelligence, this research lays the groundwork for developing practical\nsolutions that can be deployed in security settings, ultimately enhancing the\nprotective capabilities of law enforcement and public safety agencies.",
      "tldr_zh": "这篇论文开发了一种基于 YOLOv8 的 AI 模型，用于实时检测武器，从而提升学校、机场和公共交通等公共场所的安全。模型通过训练于包含各种火器和刃器图像的大数据集，利用高级深度学习技术，实现对视频流的快速处理。评估结果显示，该模型在精度、recall、F1-score 和 mAP 等指标上表现出色，能够高效区分武器和非武器类别，为计算机视觉领域和公共安全措施提供重要贡献。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "21 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.19862v1",
      "published_date": "2024-10-23 10:35:51 UTC",
      "updated_date": "2024-10-23 10:35:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:39:46.804805"
    },
    {
      "arxiv_id": "2410.17751v2",
      "title": "VISAGE: Video Synthesis using Action Graphs for Surgery",
      "title_zh": "翻译失败",
      "authors": [
        "Yousef Yeganeh",
        "Rachmadio Lazuardi",
        "Amir Shamseddin",
        "Emine Dari",
        "Yash Thirani",
        "Nassir Navab",
        "Azade Farshad"
      ],
      "abstract": "Surgical data science (SDS) is a field that analyzes patient data before,\nduring, and after surgery to improve surgical outcomes and skills. However,\nsurgical data is scarce, heterogeneous, and complex, which limits the\napplicability of existing machine learning methods. In this work, we introduce\nthe novel task of future video generation in laparoscopic surgery. This task\ncan augment and enrich the existing surgical data and enable various\napplications, such as simulation, analysis, and robot-aided surgery.\nUltimately, it involves not only understanding the current state of the\noperation but also accurately predicting the dynamic and often unpredictable\nnature of surgical procedures. Our proposed method, VISAGE (VIdeo Synthesis\nusing Action Graphs for Surgery), leverages the power of action scene graphs to\ncapture the sequential nature of laparoscopic procedures and utilizes diffusion\nmodels to synthesize temporally coherent video sequences. VISAGE predicts the\nfuture frames given only a single initial frame, and the action graph triplets.\nBy incorporating domain-specific knowledge through the action graph, VISAGE\nensures the generated videos adhere to the expected visual and motion patterns\nobserved in real laparoscopic procedures. The results of our experiments\ndemonstrate high-fidelity video generation for laparoscopy procedures, which\nenables various applications in SDS.",
      "tldr_zh": "本文提出未来视频生成任务，用于增强外科数据科学（SDS）中的稀缺数据，支持手术模拟、分析和机器人辅助应用。VISAGE方法利用行动场景图（action scene graphs）捕捉腹腔镜手术的顺序性质，并结合扩散模型（diffusion models）从单个初始帧和行动图三元组预测未来帧，确保生成的视频在视觉和运动上符合真实手术模式。实验结果表明，VISAGE实现了高保真视频合成，为SDS的各种应用提供了有力工具。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at MICCAI 2024 Embodied AI and Robotics for HealTHcare\n  (EARTH) Workshop",
      "pdf_url": "http://arxiv.org/pdf/2410.17751v2",
      "published_date": "2024-10-23 10:28:17 UTC",
      "updated_date": "2024-10-30 10:13:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:39:58.506986"
    },
    {
      "arxiv_id": "2410.17744v2",
      "title": "Learning Versatile Skills with Curriculum Masking",
      "title_zh": "翻译失败",
      "authors": [
        "Yao Tang",
        "Zhihui Xie",
        "Zichuan Lin",
        "Deheng Ye",
        "Shuai Li"
      ],
      "abstract": "Masked prediction has emerged as a promising pretraining paradigm in offline\nreinforcement learning (RL) due to its versatile masking schemes, enabling\nflexible inference across various downstream tasks with a unified model.\nDespite the versatility of masked prediction, it remains unclear how to balance\nthe learning of skills at different levels of complexity. To address this, we\npropose CurrMask, a curriculum masking pretraining paradigm for sequential\ndecision making. Motivated by how humans learn by organizing knowledge in a\ncurriculum, CurrMask adjusts its masking scheme during pretraining for learning\nversatile skills. Through extensive experiments, we show that CurrMask exhibits\nsuperior zero-shot performance on skill prompting tasks, goal-conditioned\nplanning tasks, and competitive finetuning performance on offline RL tasks.\nAdditionally, our analysis of training dynamics reveals that CurrMask gradually\nacquires skills of varying complexity by dynamically adjusting its masking\nscheme.",
      "tldr_zh": "这篇论文提出CurrMask，一种基于课程学习的masked prediction预训练范式，用于离线强化学习（offline RL），以平衡不同复杂度的技能学习。CurrMask通过动态调整masking方案，模拟人类通过课程组织知识的方式，帮助模型获取多样的技能。实验结果显示，CurrMask在零-shot技能提示任务和目标条件规划任务上表现出优越性能，并在offline RL任务上实现竞争力的微调效果。此外，训练动态分析表明，该方法能逐步获取不同复杂度的技能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2024 poster, 21 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.17744v2",
      "published_date": "2024-10-23 10:17:13 UTC",
      "updated_date": "2024-11-04 08:40:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:40:11.024727"
    },
    {
      "arxiv_id": "2410.17740v1",
      "title": "Emotion Recognition with Facial Attention and Objective Activation Functions",
      "title_zh": "翻译失败",
      "authors": [
        "Andrzej Miskow",
        "Abdulrahman Altahhan"
      ],
      "abstract": "In this paper, we study the effect of introducing channel and spatial\nattention mechanisms, namely SEN-Net, ECA-Net, and CBAM, to existing CNN\nvision-based models such as VGGNet, ResNet, and ResNetV2 to perform the Facial\nEmotion Recognition task. We show that not only attention can significantly\nimprove the performance of these models but also that combining them with a\ndifferent activation function can further help increase the performance of\nthese models.",
      "tldr_zh": "本文研究了在现有 CNN 模型（如 VGGNet、ResNet 和 ResNetV2）中引入通道和空间注意力机制（SEN-Net、ECA-Net 和 CBAM），以提升面部情感识别任务的性能。结果显示，这些注意力机制显著提高了模型的准确率，而与不同的激活函数结合后，进一步增强了整体表现。该方法为基于视觉的深度学习模型优化提供了新思路。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.17740v1",
      "published_date": "2024-10-23 10:14:37 UTC",
      "updated_date": "2024-10-23 10:14:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:40:23.137682"
    },
    {
      "arxiv_id": "2410.17735v1",
      "title": "New Insight in Cervical Cancer Diagnosis Using Convolution Neural Network Architecture",
      "title_zh": "使用卷积神经网络架构的宫颈癌诊断新见解",
      "authors": [
        "Ach. Khozaimi",
        "Wayan Firdaus Mahmudy"
      ],
      "abstract": "The Pap smear is a screening method for early cervical cancer diagnosis. The\nselection of the right optimizer in the convolutional neural network (CNN)\nmodel is key to the success of the CNN in image classification, including the\nclassification of cervical cancer Pap smear images. In this study, stochastic\ngradient descent (SGD), RMSprop, Adam, AdaGrad, AdaDelta, Adamax, and Nadam\noptimizers were used to classify cervical cancer Pap smear images from the\nSipakMed dataset. Resnet-18, Resnet-34, and VGG-16 are the CNN architectures\nused in this study, and each architecture uses a transfer-learning model. Based\non the test results, we conclude that the transfer learning model performs\nbetter on all CNNs and optimization techniques and that in the transfer\nlearning model, the optimization has little influence on the training of the\nmodel. Adamax, with accuracy values of 72.8% and 66.8%, had the best accuracy\nfor the VGG-16 and Resnet-18 architectures, respectively. Resnet-34 had 54.0%.\nThis is 0.034% lower than Nadam. Overall, Adamax is a suitable optimizer for\nCNN in cervical cancer classification on Resnet-18, Resnet-34, and VGG-16\narchitectures. This study provides new insights into the configuration of CNN\nmodels for Pap smear image analysis.",
      "tldr_zh": "本研究探讨了使用卷积神经网络 (CNN) 架构诊断宫颈癌 Pap 涂片图像，比较了 SGD、RMSprop、Adam、AdaGrad、AdaDelta、Adamax 和 Nadam 等优化器在 Resnet-18、Resnet-34 和 VGG-16 迁移学习模型上的表现。\n结果显示，迁移学习模型在所有 CNN 架构和优化技术中均表现出色，而优化器对模型训练的影响相对较小。\nAdamax 优化器在 VGG-16 和 Resnet-18 上分别取得了 72.8% 和 66.8% 的最高准确率，在 Resnet-34 上也仅比 Nadam 低 0.034%。\n总体而言，该研究为 Pap 涂片图像分析提供了新见解，推荐 Adamax 作为适合这些 CNN 架构的优化器。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.17735v1",
      "published_date": "2024-10-23 10:11:39 UTC",
      "updated_date": "2024-10-23 10:11:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:40:35.916665"
    },
    {
      "arxiv_id": "2410.17732v1",
      "title": "FuzzWiz -- Fuzzing Framework for Efficient Hardware Coverage",
      "title_zh": "翻译失败",
      "authors": [
        "Deepak Narayan Gadde",
        "Aman Kumar",
        "Djones Lettnin",
        "Sebastian Simon"
      ],
      "abstract": "Ever-increasing design complexity of System-on-Chips (SoCs) led to\nsignificant verification challenges. Unlike software, bugs in hardware design\nare vigorous and eternal i.e., once the hardware is fabricated, it cannot be\nrepaired with any patch. Despite being one of the powerful techniques used in\nverification, the dynamic random approach cannot give confidence to complex\nRegister Transfer Leve (RTL) designs during the pre-silicon design phase. In\nparticular, achieving coverage targets and exposing bugs is a complicated task\nwith random simulations. In this paper, we leverage an existing testing\nsolution available in the software world known as fuzzing and apply it to\nhardware verification in order to achieve coverage targets in quick time. We\ncreated an automated hardware fuzzing framework FuzzWiz using metamodeling and\nPython to achieve coverage goals faster. It includes parsing the RTL design\nmodule, converting it into C/C++ models, creating generic testbench with\nassertions, fuzzer-specific compilation, linking, and fuzzing. Furthermore, it\nis configurable and provides the debug flow if any crash is detected during the\nfuzzing process. The proposed framework is applied on four IP blocks from\nGoogle's OpenTitan chip with various fuzzing engines to show its scalability\nand compatibility. Our benchmarking results show that we could achieve around\n90% of the coverage 10 times faster than traditional simulation regression\nbased approach.",
      "tldr_zh": "这篇论文针对 System-on-Chips (SoCs) 设计的验证挑战，提出 FuzzWiz 框架，将软件领域的模糊测试(fuzzing)技术应用于硬件验证，以加速 Register Transfer Level (RTL) 设计的覆盖目标实现。该框架利用元建模和 Python 自动解析 RTL 模块、转换为 C/C++ 模型、创建通用测试bench 并进行模糊测试，同时提供可配置的调试流程。在 Google's OpenTitan 芯片的四个 IP 块上测试后，结果显示 FuzzWiz 比传统模拟回归方法快 10 倍，实现了约 90% 的覆盖率。",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.AR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.17732v1",
      "published_date": "2024-10-23 10:06:08 UTC",
      "updated_date": "2024-10-23 10:06:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:40:47.302906"
    },
    {
      "arxiv_id": "2410.17714v2",
      "title": "CogSteer: Cognition-Inspired Selective Layer Intervention for Efficiently Steering Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Xintong Wang",
        "Jingheng Pan",
        "Liang Ding",
        "Longyue Wang",
        "Longqin Jiang",
        "Xingshan Li",
        "Chris Biemann"
      ],
      "abstract": "Large Language Models (LLMs) achieve remarkable performance through\npretraining on extensive data. This enables efficient adaptation to diverse\ndownstream tasks. However, the lack of interpretability in their underlying\nmechanisms limits the ability to effectively steer LLMs for specific\napplications. In this work, we investigate the intrinsic mechanisms of LLMs\nfrom a cognitive perspective using eye movement measures. Specifically, we\nanalyze the layer-wise correlation between human cognitive indicators and LLM\nrepresentations. Building on these insights, we propose a heuristic approach\nfor selecting the optimal steering layer to modulate LLM semantics. To this\nend, we introduce an efficient selective layer intervention based on prominent\nparameter-efficient fine-tuning methods, which conventionally adjust either all\nlayers or only the final layer. Additionally, we present an implicit layer\ncontrastive intervention during inference to steer LLMs away from toxic\noutputs. Extensive experiments on natural language understanding, reasoning,\nand generation tasks, conducted on GPT-2, LLaMa2-7B, and Mixtral-7B,\ndemonstrate the effectiveness and efficiency of our approach. As a\nmodel-agnostic framework, it enhances the interpretability of LLMs while\nimproving efficiency for safe deployment.",
      "tldr_zh": "本研究从认知角度（使用eye movement measures）分析Large Language Models (LLMs)的内在机制，探讨层级相关性，以解决LLMs的可解释性不足问题。作者提出CogSteer框架，通过启发式方法选择最佳转向层，并引入高效的选择性层干预（基于parameter-efficient fine-tuning），结合隐式层对比干预来避免有毒输出。实验在GPT-2、LLaMa2-7B和Mixtral-7B模型上验证了该框架在自然语言理解、推理和生成任务中的有效性与效率，提升了LLMs的可解释性和安全部署性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.17714v2",
      "published_date": "2024-10-23 09:40:15 UTC",
      "updated_date": "2025-02-18 10:09:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:40:59.190537"
    },
    {
      "arxiv_id": "2410.17712v1",
      "title": "A Data-Driven Odyssey in Solar Vehicles",
      "title_zh": "翻译失败",
      "authors": [
        "Do Young Kim",
        "Kyunghyun Kim",
        "Gyeongseop Lee",
        "Niloy Das",
        "Seong-Woo Kim"
      ],
      "abstract": "Solar vehicles, which simultaneously produce and consume energy, require\nmeticulous energy management. However, potential users often feel uncertain\nabout their operation compared to conventional vehicles. This study presents a\nsimulator designed to help users understand long-distance travel in solar\nvehicles and recognize the importance of proper energy management. By utilizing\nGoogle Maps data and weather information, the simulator replicates real-world\ndriving conditions and provides a dashboard displaying vehicle status, updated\nhourly based on user-inputted speed. Users can explore various speed policy\nscenarios and receive recommendations for optimal driving strategies. The\nsimulator's effectiveness was validated using the route of the World Solar\nChallenge (WSC). This research enables users to monitor energy dynamics before\na journey, enhancing their understanding of energy management and informing\nappropriate speed decisions.",
      "tldr_zh": "本研究针对太阳能车辆的能量管理不确定性，开发了一个数据驱动模拟器，帮助用户理解长途旅行中的能量动态并提升管理意识。该模拟器利用 Google Maps 数据和天气信息，模拟真实驾驶条件，提供一个每小时更新的仪表盘显示车辆状态，并允许用户探索不同速度策略并获得最佳驾驶推荐。通过 World Solar Challenge (WSC) 路线验证，该模拟器有效提升了用户对能量管理的理解，并在旅行前指导更合理的速度决策。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.17712v1",
      "published_date": "2024-10-23 09:39:26 UTC",
      "updated_date": "2024-10-23 09:39:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:41:09.844576"
    },
    {
      "arxiv_id": "2410.17711v1",
      "title": "Beware of Calibration Data for Pruning Large Language Models",
      "title_zh": "谨防用于剪枝大语言模型的校准数据",
      "authors": [
        "Yixin Ji",
        "Yang Xiang",
        "Juntao Li",
        "Qingrong Xia",
        "Ping Li",
        "Xinyu Duan",
        "Zhefeng Wang",
        "Min Zhang"
      ],
      "abstract": "As large language models (LLMs) are widely applied across various fields,\nmodel compression has become increasingly crucial for reducing costs and\nimproving inference efficiency. Post-training pruning is a promising method\nthat does not require resource-intensive iterative training and only needs a\nsmall amount of calibration data to assess the importance of parameters.\nPrevious research has primarily focused on designing advanced pruning methods,\nwhile different calibration data's impact on pruning performance still lacks\nsystematical exploration. We fill this blank and surprisingly observe that the\neffects of calibration data even value more than designing advanced pruning\nstrategies, especially for high sparsity. Our preliminary exploration also\ndiscloses that using calibration data similar to the training data can yield\nbetter performance. As pre-training data is usually inaccessible for advanced\nLLMs, we further provide a self-generating calibration data synthesis strategy\nto construct feasible calibration data. We conduct experiments on the recent\nstrong open-source LLMs (e.g., DCLM, and LLaMA-3), and the results show that\nthe proposed method outperforms commonly used calibration data and can\neffectively enhance strong pruning methods (e.g., Wanda, OWL).",
      "tldr_zh": "该研究警告在剪枝 Large Language Models (LLMs) 时，校准数据的影响可能超过先进的剪枝策略，尤其在高稀疏度场景下。作者通过系统探索发现，使用与训练数据相似的校准数据能显著提升剪枝性能，并提出了一种自我生成校准数据合成策略，以解决预训练数据不可访问的问题。在实验中，该方法在 DCLM 和 LLaMA-3 等模型上表现出色，优于常见校准数据，并有效增强了如 Wanda 和 OWL 的剪枝方法。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "under review",
      "pdf_url": "http://arxiv.org/pdf/2410.17711v1",
      "published_date": "2024-10-23 09:36:21 UTC",
      "updated_date": "2024-10-23 09:36:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:41:23.102897"
    },
    {
      "arxiv_id": "2410.17700v1",
      "title": "Scalable Random Feature Latent Variable Models",
      "title_zh": "可扩展的随机特征潜在变量模型",
      "authors": [
        "Ying Li",
        "Zhidi Lin",
        "Yuhao Liu",
        "Michael Minyi Zhang",
        "Pablo M. Olmos",
        "Petar M. Djurić"
      ],
      "abstract": "Random feature latent variable models (RFLVMs) represent the state-of-the-art\nin latent variable models, capable of handling non-Gaussian likelihoods and\neffectively uncovering patterns in high-dimensional data. However, their heavy\nreliance on Monte Carlo sampling results in scalability issues which makes it\ndifficult to use these models for datasets with a massive number of\nobservations. To scale up RFLVMs, we turn to the optimization-based variational\nBayesian inference (VBI) algorithm which is known for its scalability compared\nto sampling-based methods. However, implementing VBI for RFLVMs poses\nchallenges, such as the lack of explicit probability distribution functions\n(PDFs) for the Dirichlet process (DP) in the kernel learning component, and the\nincompatibility of existing VBI algorithms with RFLVMs. To address these\nissues, we introduce a stick-breaking construction for DP to obtain an explicit\nPDF and a novel VBI algorithm called ``block coordinate descent variational\ninference\" (BCD-VI). This enables the development of a scalable version of\nRFLVMs, or in short, SRFLVM. Our proposed method shows scalability,\ncomputational efficiency, superior performance in generating informative latent\nrepresentations and the ability of imputing missing data across various\nreal-world datasets, outperforming state-of-the-art competitors.",
      "tldr_zh": "该研究针对随机特征潜变量模型(RFLVMs)存在的可扩展性问题提出了一种可扩展版本SRFLVM，以解决其依赖Monte Carlo采样的局限性，导致难以处理大规模数据集。研究者引入了stick-breaking construction来为Dirichlet process (DP)提供显式概率分布函数(PDFs)，并开发了新型变分贝叶斯推断(VBI)算法“block coordinate descent variational inference”(BCD-VI)，从而实现优化-based的推理过程。实验结果显示，SRFLVM在生成信息丰富的潜表示、缺失数据插值以及计算效率方面表现出色，在多种真实数据集上超越了现有竞争者。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.17700v1",
      "published_date": "2024-10-23 09:22:43 UTC",
      "updated_date": "2024-10-23 09:22:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:41:35.230314"
    },
    {
      "arxiv_id": "2410.17694v1",
      "title": "An Adaptive Framework for Generating Systematic Explanatory Answer in Online Q&A Platforms",
      "title_zh": "翻译失败",
      "authors": [
        "Ziyang Chen",
        "Xiaobin Wang",
        "Yong Jiang",
        "Jinzhi Liao",
        "Pengjun Xie",
        "Fei Huang",
        "Xiang Zhao"
      ],
      "abstract": "Question Answering (QA) systems face challenges in handling complex questions\nthat require multi-domain knowledge synthesis. The naive RAG models, although\neffective in information retrieval, struggle with complex questions that\nrequire comprehensive and in-depth answers. The pioneering task is defined as\nexplanatory answer generation, which entails handling identified challenges\nsuch as the requirement for comprehensive information and logical coherence\nwithin the generated context. To address these issues, we refer to systematic\nthinking theory and propose SynthRAG, an innovative framework designed to\nenhance QA performance. SynthRAG improves on conventional models by employing\nadaptive outlines for dynamic content structuring, generating systematic\ninformation to ensure detailed coverage, and producing customized answers\ntailored to specific user inquiries. This structured approach guarantees\nlogical coherence and thorough integration of information, yielding responses\nthat are both insightful and methodically organized. Empirical evaluations\nunderscore SynthRAG's effectiveness, demonstrating its superiority in handling\ncomplex questions, overcoming the limitations of naive RAG models, and\nsignificantly improving answer quality and depth. Furthermore, an online\ndeployment on the Zhihu platform revealed that SynthRAG's answers achieved\nnotable user engagement, with each response averaging 5.73 upvotes and\nsurpassing the performance of 79.8% of human contributors, highlighting the\npractical relevance and impact of the proposed framework. Our code is available\nat https://github.com/czy1999/SynthRAG .",
      "tldr_zh": "该论文针对在线问答（QA）系统在处理需要多领域知识综合的复杂问题时面临的挑战，提出了一种创新框架SynthRAG。该框架基于systematic thinking theory，通过adaptive outlines动态结构化内容、生成systematic information确保全面覆盖，以及创建customized answers来提升答案的逻辑连贯性和深度。相比传统RAG模型，SynthRAG在实验评估中显著提高了答案质量和深度，尤其在复杂问题上表现出色。在Zhihu平台的实际部署中，SynthRAG的答案平均获得5.73个赞同，并超过了79.8%的用户贡献，证明了其实际应用价值。代码已在https://github.com/czy1999/SynthRAG开源。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.17694v1",
      "published_date": "2024-10-23 09:14:57 UTC",
      "updated_date": "2024-10-23 09:14:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:41:46.870747"
    },
    {
      "arxiv_id": "2410.17661v1",
      "title": "PETAH: Parameter Efficient Task Adaptation for Hybrid Transformers in a resource-limited Context",
      "title_zh": "PETAH：针对资源受限环境的",
      "authors": [
        "Maximilian Augustin",
        "Syed Shakib Sarwar",
        "Mostafa Elhoushi",
        "Sai Qian Zhang",
        "Yuecheng Li",
        "Barbara De Salvo"
      ],
      "abstract": "Following their success in natural language processing (NLP), there has been\na shift towards transformer models in computer vision. While transformers\nperform well and offer promising multi-tasking performance, due to their high\ncompute requirements, many resource-constrained applications still rely on\nconvolutional or hybrid models that combine the benefits of convolution and\nattention layers and achieve the best results in the sub 100M parameter range.\nSimultaneously, task adaptation techniques that allow for the use of one shared\ntransformer backbone for multiple downstream tasks, resulting in great storage\nsavings at negligible cost in performance, have not yet been adopted for hybrid\ntransformers. In this work, we investigate how to achieve the best\ntask-adaptation performance and introduce PETAH: Parameter Efficient Task\nAdaptation for Hybrid Transformers. We further combine PETAH adaptation with\npruning to achieve highly performant and storage friendly models for\nmulti-tasking. In our extensive evaluation on classification and other vision\ntasks, we demonstrate that our PETAH-adapted hybrid models outperform\nestablished task-adaptation techniques for ViTs while requiring fewer\nparameters and being more efficient on mobile hardware.",
      "tldr_zh": "该研究针对资源受限环境，探讨了为混合Transformer模型实现参数高效的任务适应（Parameter Efficient Task Adaptation）。他们引入了PETAH方法，将任务适应技术与修剪（pruning）相结合，允许一个共享的Transformer主干处理多个下游视觉任务，同时显著减少存储和计算需求。在分类和其他视觉任务的广泛评估中，PETAH适配的混合模型 outperform 了ViTs的现有任务适应技术，使用更少的参数，并在移动硬件上更高效。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.17661v1",
      "published_date": "2024-10-23 08:24:47 UTC",
      "updated_date": "2024-10-23 08:24:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:41:58.199962"
    },
    {
      "arxiv_id": "2410.17656v1",
      "title": "AutoRNet: Automatically Optimizing Heuristics for Robust Network Design via Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "He Yu",
        "Jing Liu"
      ],
      "abstract": "Achieving robust networks is a challenging problem due to its NP-hard nature\nand complex solution space. Current methods, from handcrafted feature\nextraction to deep learning, have made progress but remain rigid, requiring\nmanual design and large labeled datasets. To address these issues, we propose\nAutoRNet, a framework that integrates large language models (LLMs) with\nevolutionary algorithms to generate heuristics for robust network design. We\ndesign network optimization strategies to provide domain-specific prompts for\nLLMs, utilizing domain knowledge to generate advanced heuristics. Additionally,\nwe introduce an adaptive fitness function to balance convergence and diversity\nwhile maintaining degree distributions. AutoRNet is evaluated on sparse and\ndense scale-free networks, outperforming current methods by reducing the need\nfor manual design and large datasets.",
      "tldr_zh": "该论文提出 AutoRNet 框架，利用 Large Language Models (LLMs) 与进化算法自动优化鲁棒网络设计的启发式方法，以解决该 NP-hard 问题的复杂性和现有方法的刚性依赖。框架通过设计网络优化策略提供领域特定提示给 LLMs 生成高级启发式，并引入自适应适应度函数来平衡收敛、多样性和度分布。实验结果显示，AutoRNet 在稀疏和密集的规模自由网络上优于当前方法，显著减少了对手动设计和大型标注数据集的需求。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.17656v1",
      "published_date": "2024-10-23 08:18:38 UTC",
      "updated_date": "2024-10-23 08:18:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:42:11.205845"
    },
    {
      "arxiv_id": "2410.17655v1",
      "title": "Mapping the Media Landscape: Predicting Factual Reporting and Political Bias Through Web Interactions",
      "title_zh": "映射媒体景观：通过网络互动预测事实报道和政治偏见",
      "authors": [
        "Dairazalia Sánchez-Cortés",
        "Sergio Burdisso",
        "Esaú Villatoro-Tello",
        "Petr Motlicek"
      ],
      "abstract": "Bias assessment of news sources is paramount for professionals,\norganizations, and researchers who rely on truthful evidence for information\ngathering and reporting. While certain bias indicators are discernible from\ncontent analysis, descriptors like political bias and fake news pose greater\nchallenges. In this paper, we propose an extension to a recently presented news\nmedia reliability estimation method that focuses on modeling outlets and their\nlongitudinal web interactions. Concretely, we assess the classification\nperformance of four reinforcement learning strategies on a large news media\nhyperlink graph. Our experiments, targeting two challenging bias descriptors,\nfactual reporting and political bias, showed a significant performance\nimprovement at the source media level. Additionally, we validate our methods on\nthe CLEF 2023 CheckThat! Lab challenge, outperforming the reported results in\nboth, F1-score and the official MAE metric. Furthermore, we contribute by\nreleasing the largest annotated dataset of news source media, categorized with\nfactual reporting and political bias labels. Our findings suggest that\nprofiling news media sources based on their hyperlink interactions over time is\nfeasible, offering a bird's-eye view of evolving media landscapes.",
      "tldr_zh": "该研究扩展了一种新闻媒体可靠性估计方法，通过建模媒体来源及其纵向网络互动（web interactions），来预测事实报道（factual reporting）和政治偏见（political bias）。他们评估了四个强化学习（reinforcement learning）策略在大型新闻媒体超链接图上的分类性能，实验显示在来源媒体层面显著提升了性能，并在 CLEF 2023 CheckThat! Lab 挑战中超越了报告的 F1-score 和 MAE 指标。论文的主要贡献包括发布最大的标注数据集，并证明基于超链接互动的时间轮廓化新闻媒体来源是可行，提供媒体景观的宏观视角（bird's-eye view）。",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to CLEF 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.17655v1",
      "published_date": "2024-10-23 08:18:26 UTC",
      "updated_date": "2024-10-23 08:18:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:42:23.300021"
    },
    {
      "arxiv_id": "2410.17637v1",
      "title": "MIA-DPO: Multi-Image Augmented Direct Preference Optimization For Large Vision-Language Models",
      "title_zh": "MIA-DPO：多图像增强直接偏好优化用于大型视觉语言模型",
      "authors": [
        "Ziyu Liu",
        "Yuhang Zang",
        "Xiaoyi Dong",
        "Pan Zhang",
        "Yuhang Cao",
        "Haodong Duan",
        "Conghui He",
        "Yuanjun Xiong",
        "Dahua Lin",
        "Jiaqi Wang"
      ],
      "abstract": "Visual preference alignment involves training Large Vision-Language Models\n(LVLMs) to predict human preferences between visual inputs. This is typically\nachieved by using labeled datasets of chosen/rejected pairs and employing\noptimization algorithms like direct preference optimization (DPO). Existing\nvisual alignment methods, primarily designed for single-image scenarios,\nstruggle to effectively handle the complexity of multi-image tasks due to the\nscarcity of diverse training data and the high cost of annotating\nchosen/rejected pairs. We present Multi-Image Augmented Direct Preference\nOptimization (MIA-DPO), a visual preference alignment approach that effectively\nhandles multi-image inputs. MIA-DPO mitigates the scarcity of diverse\nmulti-image training data by extending single-image data with unrelated images\narranged in grid collages or pic-in-pic formats, significantly reducing the\ncosts associated with multi-image data annotations. Our observation reveals\nthat attention values of LVLMs vary considerably across different images. We\nuse attention values to identify and filter out rejected responses the model\nmay have mistakenly focused on. Our attention-aware selection for constructing\nthe chosen/rejected pairs without relying on (i) human annotation, (ii) extra\ndata, and (iii) external models or APIs. MIA-DPO is compatible with various\narchitectures and outperforms existing methods on five multi-image benchmarks,\nachieving an average performance boost of 3.0% on LLaVA-v1.5 and 4.3% on the\nrecent InternLM-XC2.5. Moreover, MIA-DPO has a minimal effect on the model's\nability to understand single images.",
      "tldr_zh": "该论文提出MIA-DPO，一种多图像增强直接偏好优化（Direct Preference Optimization）方法，用于训练大型视觉语言模型（LVLMs），以更好地处理多图像输入的偏好对齐问题。MIA-DPO通过扩展单图像数据生成多图像格式（如网格拼贴或图片-in-图片），并利用注意力值自动过滤和构建chosen/rejected对，从而减少了数据标注成本，而无需依赖人工标注、额外数据或外部模型。在五个多图像基准测试中，该方法显著提升了模型性能，LLaVA-v1.5平均提高3.0%，InternLM-XC2.5提高4.3%，同时对单图像理解能力的影响最小。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Project URL: https://github.com/Liuziyu77/MIA-DPO",
      "pdf_url": "http://arxiv.org/pdf/2410.17637v1",
      "published_date": "2024-10-23 07:56:48 UTC",
      "updated_date": "2024-10-23 07:56:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:42:38.469934"
    },
    {
      "arxiv_id": "2410.18710v3",
      "title": "Uncovering the Genetic Basis of Glioblastoma Heterogeneity through Multimodal Analysis of Whole Slide Images and RNA Sequencing Data",
      "title_zh": "翻译失败",
      "authors": [
        "Ahmad Berjaoui",
        "Louis Roussel",
        "Eduardo Hugo Sanchez",
        "Elizabeth Cohen-Jonathan Moyal"
      ],
      "abstract": "Glioblastoma is a highly aggressive form of brain cancer characterized by\nrapid progression and poor prognosis. Despite advances in treatment, the\nunderlying genetic mechanisms driving this aggressiveness remain poorly\nunderstood. In this study, we employed multimodal deep learning approaches to\ninvestigate glioblastoma heterogeneity using joint image/RNA-seq analysis. Our\nresults reveal novel genes associated with glioblastoma. By leveraging a\ncombination of whole-slide images and RNA-seq, as well as introducing novel\nmethods to encode RNA-seq data, we identified specific genetic profiles that\nmay explain different patterns of glioblastoma progression. These findings\nprovide new insights into the genetic mechanisms underlying glioblastoma\nheterogeneity and highlight potential targets for therapeutic intervention.\nCode and data downloading instructions are available at:\nhttps://github.com/ma3oun/gbheterogeneity.",
      "tldr_zh": "本研究针对胶质母细胞瘤（Glioblastoma）的遗传异质性，使用多模态深度学习方法对全滑片图像（whole-slide images）和 RNA-seq 数据进行联合分析，旨在揭示其侵袭性进展的潜在遗传机制。研究引入了新颖的 RNA-seq 数据编码方法，成功识别出与肿瘤进展相关的全新基因和特定遗传配置文件。这些发现为理解胶质母细胞瘤的遗传基础提供了重要见解，并突出了潜在的治疗干预目标。",
      "categories": [
        "q-bio.QM",
        "cs.AI"
      ],
      "primary_category": "q-bio.QM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.18710v3",
      "published_date": "2024-10-23 07:55:40 UTC",
      "updated_date": "2025-05-19 13:22:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:42:47.149986"
    },
    {
      "arxiv_id": "2410.17635v2",
      "title": "Markov Chain of Thought for Efficient Mathematical Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Wen Yang",
        "Minpeng Liao",
        "Kai Fan"
      ],
      "abstract": "Chain of Thought (CoT) of multi-step benefits from the logical structure of\nthe reasoning steps and task-specific actions, significantly enhancing the\nmathematical reasoning capabilities of large language models. As the prevalence\nof long CoT, the number of reasoning steps exceeds manageable token limits and\nleads to higher computational demands. Inspired by the fundamental logic of\nhuman cognition, \"derive, then reduce\", we conceptualize the standard\nmulti-step CoT as a novel Markov Chain of Thought (MCoT). In this study, we\nconsider the mathematical reasoning task, defining each reasoning step as text\naccompanied by a Python code snippet. To facilitate a longer reasoning path,\nself-correction is enabled through interactions with the code interpreter. Our\nMCoT aims to compress previous reasoning steps into a simplified question,\nenabling efficient next-step inference without relying on a lengthy KV cache.\nIn our experiments, we curate the $\\texttt{MCoTInstruct}$ dataset, and the\nempirical results indicate that MCoT not only significantly enhances efficiency\nbut also maintains comparable accuracy. While much remains to be explored, this\nwork paves the way for exploring the long CoT reasoning abilities of LLMs. The\ncode is available at https://github.com/james-yw/Markov-Chain-of-Thought",
      "tldr_zh": "该论文提出 Markov Chain of Thought (MCoT) 方法，以提升大型语言模型(LLMs)在数学推理任务中的效率，解决传统 Chain of Thought (CoT) 步骤过多导致的 token 限制和计算需求问题。MCoT 受人类认知逻辑“derive, then reduce”启发，将每个推理步骤定义为文本加 Python 代码片段，并通过代码解释器实现自校正和步骤压缩，从而在不依赖 lengthy KV cache 的情况下支持更长推理路径。作者创建了 MCoTInstruct 数据集，实验结果表明该方法显著提高了推理效率，同时保持了与标准 CoT 相当的准确率。该工作为探索 LLMs 的长 CoT 推理能力铺平了道路，并提供了开源代码。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Camera ready version for NAACL 2025 Main",
      "pdf_url": "http://arxiv.org/pdf/2410.17635v2",
      "published_date": "2024-10-23 07:53:29 UTC",
      "updated_date": "2025-03-06 06:39:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:42:59.827588"
    },
    {
      "arxiv_id": "2410.17632v2",
      "title": "LMLPA: Language Model Linguistic Personality Assessment",
      "title_zh": "翻译失败",
      "authors": [
        "Jingyao Zheng",
        "Xian Wang",
        "Simo Hosio",
        "Xiaoxian Xu",
        "Lik-Hang Lee"
      ],
      "abstract": "Large Language Models (LLMs) are increasingly used in everyday life and\nresearch. One of the most common use cases is conversational interactions,\nenabled by the language generation capabilities of LLMs. Just as between two\nhumans, a conversation between an LLM-powered entity and a human depends on the\npersonality of the conversants. However, measuring the personality of a given\nLLM is currently a challenge. This paper introduces the Language Model\nLinguistic Personality Assessment (LMLPA), a system designed to evaluate the\nlinguistic personalities of LLMs. Our system helps to understand LLMs' language\ngeneration capabilities by quantitatively assessing the distinct personality\ntraits reflected in their linguistic outputs. Unlike traditional human-centric\npsychometrics, the LMLPA adapts a personality assessment questionnaire,\nspecifically the Big Five Inventory, to align with the operational capabilities\nof LLMs, and also incorporates the findings from previous language-based\npersonality measurement literature. To mitigate sensitivity to the order of\noptions, our questionnaire is designed to be open-ended, resulting in textual\nanswers. Thus, the AI rater is needed to transform ambiguous personality\ninformation from text responses into clear numerical indicators of personality\ntraits. Utilising Principal Component Analysis and reliability validations, our\nfindings demonstrate that LLMs possess distinct personality traits that can be\neffectively quantified by the LMLPA. This research contributes to\nHuman-Computer Interaction and Human-Centered AI, providing a robust framework\nfor future studies to refine AI personality assessments and expand their\napplications in multiple areas, including education and manufacturing.",
      "tldr_zh": "这篇论文引入了 LMLPA 系统，用于评估大型语言模型 (LLMs) 的语言生成中体现的个性特征，旨在解决当前测量 LLM 个性挑战。LMLPA 基于 Big Five Inventory 进行适应，设计成开放式问卷以获取文本答案，并利用 AI 评估器、Principal Component Analysis 和可靠性验证，将文本转化为可量化的个性指标。研究发现，LLMs 展现出独特的 personality traits，这为 Human-Computer Interaction 和 Human-Centered AI 提供了稳健框架，支持其在教育和制造等领域的应用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.17632v2",
      "published_date": "2024-10-23 07:48:51 UTC",
      "updated_date": "2024-11-11 11:32:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:43:11.329013"
    },
    {
      "arxiv_id": "2410.17629v2",
      "title": "Graph Signal Adaptive Message Passing",
      "title_zh": "图信号自适应消息传递",
      "authors": [
        "Yi Yan",
        "Changran Peng",
        "Ercan Engin Kuruoglu"
      ],
      "abstract": "This paper proposes Graph Signal Adaptive Message Passing (GSAMP), a novel\nmessage passing method that simultaneously conducts online prediction, missing\ndata imputation, and noise removal on time-varying graph signals. Unlike\nconventional Graph Signal Processing methods that apply the same filter to the\nentire graph, the spatiotemporal updates of GSAMP employ a distinct approach\nthat utilizes localized computations at each node. This update is based on an\nadaptive solution obtained from an optimization problem designed to minimize\nthe discrepancy between observed and estimated values. GSAMP effectively\nprocesses real-world, time-varying graph signals under Gaussian and impulsive\nnoise conditions.",
      "tldr_zh": "本文提出 Graph Signal Adaptive Message Passing (GSAMP)，一种新型消息传递方法，用于同时进行在线预测、缺失数据插值和噪声去除，针对时变图信号。不同于传统 Graph Signal Processing 方法，GSAMP 通过每个节点的本地化计算和基于优化问题的自适应解决方案，来最小化观察值与估计值之间的差异。该方法在高斯和脉冲噪声条件下有效处理真实世界图信号，提升了处理效率和准确性。",
      "categories": [
        "eess.SP",
        "cs.AI"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.17629v2",
      "published_date": "2024-10-23 07:44:56 UTC",
      "updated_date": "2024-11-23 10:25:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:45:22.940345"
    },
    {
      "arxiv_id": "2410.17621v2",
      "title": "Process Supervision-Guided Policy Optimization for Code Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Ning Dai",
        "Zheng Wu",
        "Renjie Zheng",
        "Ziyun Wei",
        "Wenlei Shi",
        "Xing Jin",
        "Guanlin Liu",
        "Chen Dun",
        "Liang Huang",
        "Lin Yan"
      ],
      "abstract": "Reinforcement learning (RL) with unit test feedback has enhanced large\nlanguage models' (LLMs) code generation, but relies on sparse rewards provided\nonly after complete code evaluation, limiting learning efficiency and\nincremental improvements. When generated code fails all unit tests, no learning\nsignal is received, hindering progress on complex tasks. To address this, we\npropose a Process Reward Model (PRM) that delivers dense, line-level feedback\non code correctness during generation, mimicking human code refinement and\nproviding immediate guidance. We explore various strategies for training PRMs\nand integrating them into the RL framework, finding that using PRMs both as\ndense rewards and for value function initialization significantly boosts\nperformance. Our experimental results also highlight the effectiveness of PRMs\nin enhancing RL-driven code generation, especially for long-horizon scenarios.",
      "tldr_zh": "这篇论文针对强化学习 (RL) 在代码生成中的稀疏奖励问题，提出 Process Reward Model (PRM)，该模型提供密集的行级别反馈，模拟人类代码细化过程，以提升大型语言模型 (LLMs) 的学习效率和增量改进。作者探索了多种训练 PRM 的策略，并将其整合到 RL 框架中，作为密集奖励和价值函数初始化，从而显著提升了代码生成的性能。实验结果显示，这种方法在长时序场景下特别有效，帮助模型更好地处理复杂任务。",
      "categories": [
        "cs.AI",
        "I.2.7,"
      ],
      "primary_category": "cs.AI",
      "comment": "15 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.17621v2",
      "published_date": "2024-10-23 07:22:33 UTC",
      "updated_date": "2025-02-04 09:24:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:43:34.970879"
    },
    {
      "arxiv_id": "2410.17619v2",
      "title": "From PDFs to Structured Data: Utilizing LLM Analysis in Sports Database Management",
      "title_zh": "翻译失败",
      "authors": [
        "Juhani Merilehto"
      ],
      "abstract": "This study investigates the effectiveness of Large Language Models (LLMs) in\nprocessing semi-structured data from PDF documents into structured formats,\nspecifically examining their application in updating the Finnish Sports Clubs\nDatabase. Through action research methodology, we developed and evaluated an\nAI-assisted approach utilizing OpenAI's GPT-4 and Anthropic's Claude 3 Opus\nmodels to process data from 72 sports federation membership reports. The system\nachieved a 90% success rate in automated processing, successfully handling 65\nof 72 files without errors and converting over 7,900 rows of data. While the\ninitial development time was comparable to traditional manual processing (three\nmonths), the implemented system shows potential for reducing future processing\ntime by approximately 90%. Key challenges included handling multilingual\ncontent, processing multi-page datasets, and managing extraneous information.\nThe findings suggest that while LLMs demonstrate significant potential for\nautomating semi-structured data processing tasks, optimal results are achieved\nthrough a hybrid approach combining AI automation with selective human\noversight. This research contributes to the growing body of literature on\npractical LLM applications in organizational data management and provides\ninsights into the transformation of traditional data processing workflows.",
      "tldr_zh": "这篇论文探讨了使用大型语言模型(LLMs)，如 GPT-4 和 Claude 3 Opus，将 PDF 中的半结构化数据转换为结构化格式，应用于更新芬兰体育俱乐部数据库。研究采用行动研究方法，处理了 72 个体育联合会会员报告，实现了 90% 的成功率，成功转换超过 7,900 行数据，同时未来处理时间可减少约 90%。主要挑战包括处理多语言内容、多页数据集和无关信息，因此建议采用 AI 自动化与人工监督相结合的混合方法。该研究为 LLMs 在组织数据管理中的实际应用提供了重要见解，并推动了传统数据处理工作流的转型。",
      "categories": [
        "cs.CE",
        "cs.AI"
      ],
      "primary_category": "cs.CE",
      "comment": "11 pages, 1 figure; corrected the corresponding authors e-mail",
      "pdf_url": "http://arxiv.org/pdf/2410.17619v2",
      "published_date": "2024-10-23 07:17:31 UTC",
      "updated_date": "2024-10-31 09:45:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:43:47.306634"
    },
    {
      "arxiv_id": "2410.17610v3",
      "title": "ImDy: Human Inverse Dynamics from Imitated Observations",
      "title_zh": "ImDy：基于模仿观察的人类逆动力学",
      "authors": [
        "Xinpeng Liu",
        "Junxuan Liang",
        "Zili Lin",
        "Haowen Hou",
        "Yong-Lu Li",
        "Cewu Lu"
      ],
      "abstract": "Inverse dynamics (ID), which aims at reproducing the driven torques from\nhuman kinematic observations, has been a critical tool for gait analysis.\nHowever, it is hindered from wider application to general motion due to its\nlimited scalability. Conventional optimization-based ID requires expensive\nlaboratory setups, restricting its availability. To alleviate this problem, we\npropose to exploit the recently progressive human motion imitation algorithms\nto learn human inverse dynamics in a data-driven manner. The key insight is\nthat the human ID knowledge is implicitly possessed by motion imitators, though\nnot directly applicable. In light of this, we devise an efficient data\ncollection pipeline with state-of-the-art motion imitation algorithms and\nphysics simulators, resulting in a large-scale human inverse dynamics benchmark\nas Imitated Dynamics (ImDy). ImDy contains over 150 hours of motion with joint\ntorque and full-body ground reaction force data. With ImDy, we train a\ndata-driven human inverse dynamics solver ImDyS(olver) in a fully supervised\nmanner, which conducts ID and ground reaction force estimation simultaneously.\nExperiments on ImDy and real-world data demonstrate the impressive competency\nof ImDyS in human inverse dynamics and ground reaction force estimation.\nMoreover, the potential of ImDy(-S) as a fundamental motion analysis tool is\nexhibited with downstream applications. The project page is\nhttps://foruck.github.io/ImDy/.",
      "tldr_zh": "本研究针对传统逆动力学（Inverse Dynamics, ID）方法依赖昂贵实验室设置的局限性，提出了一种数据驱动的方法，利用先进的动作模仿算法和物理模拟器构建了一个高效的数据收集管道。由此创建了大型基准数据集 ImDy，包含超过150小时的动作数据，包括关节扭矩和全身体地反作用力信息。基于 ImDy，他们训练了 ImDyS 模型，能够同时进行 ID 计算和地反作用力估计，实验在 ImDy 数据集及真实世界数据上展示了其出色性能，并证明了其作为运动分析工具的潜力，包括下游应用。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.GR",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "To appear in ICLR 2025. Yong-Lu Li and Cewu Lu are the corresponding\n  authors",
      "pdf_url": "http://arxiv.org/pdf/2410.17610v3",
      "published_date": "2024-10-23 07:06:08 UTC",
      "updated_date": "2025-02-13 05:15:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:45:52.142787"
    },
    {
      "arxiv_id": "2410.17606v1",
      "title": "Towards Effective Data-Free Knowledge Distillation via Diverse Diffusion Augmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Muquan Li",
        "Dongyang Zhang",
        "Tao He",
        "Xiurui Xie",
        "Yuan-Fang Li",
        "Ke Qin"
      ],
      "abstract": "Data-free knowledge distillation (DFKD) has emerged as a pivotal technique in\nthe domain of model compression, substantially reducing the dependency on the\noriginal training data. Nonetheless, conventional DFKD methods that employ\nsynthesized training data are prone to the limitations of inadequate diversity\nand discrepancies in distribution between the synthesized and original\ndatasets. To address these challenges, this paper introduces an innovative\napproach to DFKD through diverse diffusion augmentation (DDA). Specifically, we\nrevise the paradigm of common data synthesis in DFKD to a composite process\nthrough leveraging diffusion models subsequent to data synthesis for\nself-supervised augmentation, which generates a spectrum of data samples with\nsimilar distributions while retaining controlled variations. Furthermore, to\nmitigate excessive deviation in the embedding space, we introduce an image\nfiltering technique grounded in cosine similarity to maintain fidelity during\nthe knowledge distillation process. Comprehensive experiments conducted on\nCIFAR-10, CIFAR-100, and Tiny-ImageNet datasets showcase the superior\nperformance of our method across various teacher-student network\nconfigurations, outperforming the contemporary state-of-the-art DFKD methods.\nCode will be available at:https://github.com/SLGSP/DDA.",
      "tldr_zh": "本研究针对数据无关知识蒸馏 (DFKD) 在模型压缩中的问题，提出了一种创新方法 Diverse Diffusion Augmentation (DDA)，以解决合成的训练数据缺乏多样性和分布差异的问题。DDA 通过在数据合成后利用扩散模型进行自监督增强，生成分布相似的多样样本，并引入基于余弦相似度的图像过滤技术，以减少嵌入空间的偏差并保持知识蒸馏的保真度。在 CIFAR-10、CIFAR-100 和 Tiny-ImageNet 数据集上的实验表明，该方法在各种教师-学生网络配置下，显著优于现有最先进 DFKD 方法。总的来说，DDA 提升了 DFKD 的有效性，为高效模型压缩提供了新途径。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.17606v1",
      "published_date": "2024-10-23 07:01:16 UTC",
      "updated_date": "2024-10-23 07:01:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:46:03.830033"
    },
    {
      "arxiv_id": "2410.17602v1",
      "title": "Integrating Large Language Models for UAV Control in Simulated Environments: A Modular Interaction Approach",
      "title_zh": "在模拟环境中整合大语言模型用于无人机控制：一种模块化交互方法",
      "authors": [
        "Abhishek Phadke",
        "Alihan Hadimlioglu",
        "Tianxing Chu",
        "Chandra N Sekharan"
      ],
      "abstract": "The intersection of LLMs (Large Language Models) and UAV (Unoccupied Aerial\nVehicles) technology represents a promising field of research with the\npotential to enhance UAV capabilities significantly. This study explores the\napplication of LLMs in UAV control, focusing on the opportunities for\nintegrating advanced natural language processing into autonomous aerial\nsystems. By enabling UAVs to interpret and respond to natural language\ncommands, LLMs simplify the UAV control and usage, making them accessible to a\nbroader user base and facilitating more intuitive human-machine interactions.\nThe paper discusses several key areas where LLMs can impact UAV technology,\nincluding autonomous decision-making, dynamic mission planning, enhanced\nsituational awareness, and improved safety protocols. Through a comprehensive\nreview of current developments and potential future directions, this study aims\nto highlight how LLMs can transform UAV operations, making them more adaptable,\nresponsive, and efficient in complex environments. A template development\nframework for integrating LLMs in UAV control is also described. Proof of\nConcept results that integrate existing LLM models and popular robotic\nsimulation platforms are demonstrated. The findings suggest that while there\nare substantial technical and ethical challenges to address, integrating LLMs\ninto UAV control holds promising implications for advancing autonomous aerial\nsystems.",
      "tldr_zh": "本研究探讨了将 Large Language Models (LLMs) 整合到 UAV (Unoccupied Aerial Vehicles) 控制中的潜力，采用模块化交互方法来简化 UAV 的自然语言命令处理和自主操作。论文提出一个模板开发框架，并通过模拟环境中的 Proof of Concept 实验，展示了 LLMs 在提升自主决策、动态任务规划、situational awareness 和安全协议方面的作用。结果表明，这种整合能使 UAV 更具适应性和响应性，尽管仍需应对技术与伦理挑战，但为先进自主空中系统的发展提供了重要前景。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.17602v1",
      "published_date": "2024-10-23 06:56:53 UTC",
      "updated_date": "2024-10-23 06:56:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:46:14.828582"
    },
    {
      "arxiv_id": "2410.17600v2",
      "title": "Graphusion: A RAG Framework for Knowledge Graph Construction with a Global Perspective",
      "title_zh": "翻译失败",
      "authors": [
        "Rui Yang",
        "Boming Yang",
        "Aosong Feng",
        "Sixun Ouyang",
        "Moritz Blum",
        "Tianwei She",
        "Yuang Jiang",
        "Freddy Lecue",
        "Jinghui Lu",
        "Irene Li"
      ],
      "abstract": "Knowledge Graphs (KGs) are crucial in the field of artificial intelligence\nand are widely used in downstream tasks, such as question-answering (QA). The\nconstruction of KGs typically requires significant effort from domain experts.\nLarge Language Models (LLMs) have recently been used for Knowledge Graph\nConstruction (KGC). However, most existing approaches focus on a local\nperspective, extracting knowledge triplets from individual sentences or\ndocuments, missing a fusion process to combine the knowledge in a global KG.\nThis work introduces Graphusion, a zero-shot KGC framework from free text. It\ncontains three steps: in Step 1, we extract a list of seed entities using topic\nmodeling to guide the final KG includes the most relevant entities; in Step 2,\nwe conduct candidate triplet extraction using LLMs; in Step 3, we design the\nnovel fusion module that provides a global view of the extracted knowledge,\nincorporating entity merging, conflict resolution, and novel triplet discovery.\nResults show that Graphusion achieves scores of 2.92 and 2.37 out of 3 for\nentity extraction and relation recognition, respectively. Moreover, we showcase\nhow Graphusion could be applied to the Natural Language Processing (NLP) domain\nand validate it in an educational scenario. Specifically, we introduce TutorQA,\na new expert-verified benchmark for QA, comprising six tasks and a total of\n1,200 QA pairs. Using the Graphusion-constructed KG, we achieve a significant\nimprovement on the benchmark, for example, a 9.2% accuracy improvement on\nsub-graph completion.",
      "tldr_zh": "这篇论文介绍了Graphusion，一个基于RAG的框架，用于从自由文本构建Knowledge Graphs (KGs)，强调全局视角以解决现有方法局部提取的局限性。框架包括三个步骤：首先使用主题建模提取种子实体，其次利用Large Language Models (LLMs)进行候选三元组提取，最后通过融合模块实现实体合并、冲突解决和新三元组发现。实验结果显示，Graphusion在实体提取和关系识别上分别获得2.92和2.37的高分，并在TutorQA基准测试中实现了9.2%的准确率改善，证明其在Natural Language Processing (NLP)领域和教育场景中的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.CL",
      "comment": "arXiv admin note: substantial text overlap with arXiv:2407.10794",
      "pdf_url": "http://arxiv.org/pdf/2410.17600v2",
      "published_date": "2024-10-23 06:54:03 UTC",
      "updated_date": "2025-02-03 09:48:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:46:28.581204"
    },
    {
      "arxiv_id": "2410.17589v1",
      "title": "Challenge on Sound Scene Synthesis: Evaluating Text-to-Audio Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Junwon Lee",
        "Modan Tailleur",
        "Laurie M. Heller",
        "Keunwoo Choi",
        "Mathieu Lagrange",
        "Brian McFee",
        "Keisuke Imoto",
        "Yuki Okamoto"
      ],
      "abstract": "Despite significant advancements in neural text-to-audio generation,\nchallenges persist in controllability and evaluation. This paper addresses\nthese issues through the Sound Scene Synthesis challenge held as part of the\nDetection and Classification of Acoustic Scenes and Events 2024. We present an\nevaluation protocol combining objective metric, namely Fr\\'echet Audio\nDistance, with perceptual assessments, utilizing a structured prompt format to\nenable diverse captions and effective evaluation. Our analysis reveals varying\nperformance across sound categories and model architectures, with larger models\ngenerally excelling but innovative lightweight approaches also showing promise.\nThe strong correlation between objective metrics and human ratings validates\nour evaluation approach. We discuss outcomes in terms of audio quality,\ncontrollability, and architectural considerations for text-to-audio\nsynthesizers, providing direction for future research.",
      "tldr_zh": "这篇论文通过Sound Scene Synthesis挑战赛，评估了文本到音频生成（text-to-audio generation）的可控性和性能问题，以解决当前领域的关键挑战。研究提出了一种评估协议，结合Fréchet Audio Distance（客观指标）和感知评估，并使用结构化的提示格式来处理多样化音频描述。结果显示，不同声音类别和模型架构的性能存在差异，大型模型整体表现更优，但创新的轻量级方法也显示出潜力，且客观指标与人类评分高度相关。该工作为文本到音频合成器的音频质量、可控性和架构设计提供了宝贵指导方向。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG",
        "cs.MM",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "accepted to NeurIPS 2024 Workshop: Audio Imagination",
      "pdf_url": "http://arxiv.org/pdf/2410.17589v1",
      "published_date": "2024-10-23 06:35:41 UTC",
      "updated_date": "2024-10-23 06:35:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:46:59.724297"
    },
    {
      "arxiv_id": "2410.17584v1",
      "title": "Exploring Tokenization Methods for Multitrack Sheet Music Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Yashan Wang",
        "Shangda Wu",
        "Xingjian Du",
        "Maosong Sun"
      ],
      "abstract": "This study explores the tokenization of multitrack sheet music in ABC\nnotation, introducing two methods--bar-stream and line-stream patching. We\ncompare these methods against existing techniques, including bar patching, byte\npatching, and Byte Pair Encoding (BPE). In terms of both computational\nefficiency and the musicality of the generated compositions, experimental\nresults show that bar-stream patching performs best overall compared to the\nothers, which makes it a promising tokenization strategy for sheet music\ngeneration.",
      "tldr_zh": "这篇论文探讨了多轨乐谱（multitrack sheet music）在 ABC notation 中的标记化方法（tokenization methods），引入了两种新方法：bar-stream patching 和 line-stream patching。研究者将这些方法与现有技术，包括 bar patching、byte patching 和 Byte Pair Encoding (BPE) 进行比较。实验结果显示，bar-stream patching 在计算效率和生成的音乐性方面整体表现最佳，因此被视为乐谱生成的一种有前景的策略。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "3 pages, 1 figure, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2410.17584v1",
      "published_date": "2024-10-23 06:19:48 UTC",
      "updated_date": "2024-10-23 06:19:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:46:51.645359"
    },
    {
      "arxiv_id": "2410.18153v1",
      "title": "Physics-informed Neural Networks for Functional Differential Equations: Cylindrical Approximation and Its Convergence Guarantees",
      "title_zh": "基于物理信息的神经网络用于泛函微分方程：圆柱逼近及其收敛保证",
      "authors": [
        "Taiki Miyagawa",
        "Takeru Yokota"
      ],
      "abstract": "We propose the first learning scheme for functional differential equations\n(FDEs). FDEs play a fundamental role in physics, mathematics, and optimal\ncontrol. However, the numerical analysis of FDEs has faced challenges due to\nits unrealistic computational costs and has been a long standing problem over\ndecades. Thus, numerical approximations of FDEs have been developed, but they\noften oversimplify the solutions. To tackle these two issues, we propose a\nhybrid approach combining physics-informed neural networks (PINNs) with the\n\\textit{cylindrical approximation}. The cylindrical approximation expands\nfunctions and functional derivatives with an orthonormal basis and transforms\nFDEs into high-dimensional PDEs. To validate the reliability of the cylindrical\napproximation for FDE applications, we prove the convergence theorems of\napproximated functional derivatives and solutions. Then, the derived\nhigh-dimensional PDEs are numerically solved with PINNs. Through the\ncapabilities of PINNs, our approach can handle a broader class of functional\nderivatives more efficiently than conventional discretization-based methods,\nimproving the scalability of the cylindrical approximation. As a proof of\nconcept, we conduct experiments on two FDEs and demonstrate that our model can\nsuccessfully achieve typical $L^1$ relative error orders of PINNs $\\sim\n10^{-3}$. Overall, our work provides a strong backbone for physicists,\nmathematicians, and machine learning experts to analyze previously challenging\nFDEs, thereby democratizing their numerical analysis, which has received\nlimited attention. Code is available at\n\\url{https://github.com/TaikiMiyagawa/FunctionalPINN}.",
      "tldr_zh": "本论文提出了首个针对功能微分方程(FDEs)的学习方案，旨在解决其数值分析中高计算成本的问题，通过结合物理信息神经网络(PINNs)和柱状近似(cylindrical approximation)来提高效率。柱状近似使用正交基展开函数和函数导数，将 FDEs 转化为高维偏微分方程(PDEs)，并证明了其收敛性定理。实验在两个 FDEs 上验证了该方法的有效性，实现了典型的 L1 相对误差约 10^{-3}，从而为物理学、数学和机器学习领域更便捷地分析 FDEs 提供了基础。",
      "categories": [
        "math.NA",
        "cond-mat.dis-nn",
        "cs.AI",
        "cs.NA",
        "hep-th",
        "stat.ML"
      ],
      "primary_category": "math.NA",
      "comment": "Accepted at NeurIPS 2024. Both authors contributed equally. Some\n  contents are omitted due to arXiv's storage limit. Please refer to the full\n  paper at OpenReview (NeurIPS 2024) or\n  https://github.com/TaikiMiyagawa/FunctionalPINN",
      "pdf_url": "http://arxiv.org/pdf/2410.18153v1",
      "published_date": "2024-10-23 06:16:35 UTC",
      "updated_date": "2024-10-23 06:16:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:47:04.651934"
    },
    {
      "arxiv_id": "2410.17579v5",
      "title": "Bonsai: Gradient-free Graph Condensation for Node Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Mridul Gupta",
        "Samyak Jain",
        "Vansh Ramani",
        "Hariprasad Kodamana",
        "Sayan Ranu"
      ],
      "abstract": "Graph condensation has emerged as a promising avenue to enable scalable\ntraining of GNNs by compressing the training dataset while preserving essential\ngraph characteristics. Our study uncovers significant shortcomings in current\ngraph condensation techniques. First, the majority of the algorithms\nparadoxically require training on the full dataset to perform condensation.\nSecond, due to their gradient-emulating approach, these methods require fresh\ncondensation for any change in hyperparameters or GNN architecture, limiting\ntheir flexibility and reusability. Finally, they fail to achieve substantial\nsize reduction due to synthesizing fully-connected, edge-weighted graphs. To\naddress these challenges, we present Bonsai, a novel graph condensation method\nempowered by the observation that \\textit{computation trees} form the\nfundamental processing units of message-passing GNNs. Bonsai condenses datasets\nby encoding a careful selection of \\textit{exemplar} trees that maximize the\nrepresentation of all computation trees in the training set. This unique\napproach imparts Bonsai as the first linear-time, model-agnostic graph\ncondensation algorithm for node classification that outperforms existing\nbaselines across $7$ real-world datasets on accuracy, while being $22$ times\nfaster on average. Bonsai is grounded in rigorous mathematical guarantees on\nthe adopted approximation strategies making it robust to GNN architectures,\ndatasets, and parameters.",
      "tldr_zh": "本研究揭示了现有图凝聚(Graph Condensation)技术的缺陷，包括依赖完整数据集训练、需重新凝聚应对超参数或GNN架构变化，以及无法实现显著尺寸缩减。为解决这些问题，提出Bonsai，一种基于计算树(computation trees)的梯度无关方法，通过选择示例树(exemplar trees)来最大化训练集表示，从而实现高效的图凝聚。Bonsai是首个线性时间、模型无关的图凝聚算法，在7个真实数据集上，准确性优于现有基线且平均快22倍，并通过严格数学保证确保对GNN架构、数据集和参数的鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.17579v5",
      "published_date": "2024-10-23 06:08:45 UTC",
      "updated_date": "2025-03-26 05:50:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:47:16.247771"
    },
    {
      "arxiv_id": "2410.17576v1",
      "title": "Real-time Vehicle-to-Vehicle Communication Based Network Cooperative Control System through Distributed Database and Multimodal Perception: Demonstrated in Crossroads",
      "title_zh": "翻译失败",
      "authors": [
        "Xinwen Zhu",
        "Zihao Li",
        "Yuxuan Jiang",
        "Jiazhen Xu",
        "Jie Wang",
        "Xuyang Bai"
      ],
      "abstract": "The autonomous driving industry is rapidly advancing, with Vehicle-to-Vehicle\n(V2V) communication systems highlighting as a key component of enhanced road\nsafety and traffic efficiency. This paper introduces a novel Real-time\nVehicle-to-Vehicle Communication Based Network Cooperative Control System\n(VVCCS), designed to revolutionize macro-scope traffic planning and collision\navoidance in autonomous driving. Implemented on Quanser Car (Qcar) hardware\nplatform, our system integrates the distributed databases into individual\nautonomous vehicles and an optional central server. We also developed a\ncomprehensive multi-modal perception system with multi-objective tracking and\nradar sensing. Through a demonstration within a physical crossroad environment,\nour system showcases its potential to be applied in congested and complex urban\nenvironments.",
      "tldr_zh": "这篇论文引入了实时 Vehicle-to-Vehicle (V2V) 通信为基础的网络合作控制系统 (VVCCS)，旨在提升自动驾驶中的宏观交通规划和碰撞避免。系统整合了分布式数据库、多模态感知系统（包括多目标跟踪和雷达感应），并在 Quanser Car (Qcar) 硬件平台上实现。实验通过在物理十字路口环境的演示，展示了 VVCCS 在拥挤复杂城市环境中的潜在应用潜力。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "ICICT 2024, 18 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.17576v1",
      "published_date": "2024-10-23 05:59:55 UTC",
      "updated_date": "2024-10-23 05:59:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:47:27.532802"
    },
    {
      "arxiv_id": "2411.07243v1",
      "title": "Neuropsychology and Explainability of AI: A Distributional Approach to the Relationship Between Activation Similarity of Neural Categories in Synthetic Cognition",
      "title_zh": "翻译失败",
      "authors": [
        "Michael Pichat",
        "Enola Campoli",
        "William Pogrund",
        "Jourdan Wilson",
        "Michael Veillet-Guillem",
        "Anton Melkozerov",
        "Paloma Pichat",
        "Armanush Gasparian",
        "Samuel Demarchi",
        "Judicael Poumay"
      ],
      "abstract": "We propose a neuropsychological approach to the explainability of artificial\nneural networks, which involves using concepts from human cognitive psychology\nas relevant heuristic references for developing synthetic explanatory\nframeworks that align with human modes of thought. The analogical concepts\nmobilized here, which are intended to create such an epistemological bridge,\nare those of categorization and similarity, as these notions are particularly\nsuited to the categorical \"nature\" of the reconstructive information processing\nperformed by artificial neural networks. Our study aims to reveal a unique\nprocess of synthetic cognition, that of the categorical convergence of highly\nactivated tokens. We attempt to explain this process with the idea that the\ncategorical segment created by a neuron is actually the result of a\nsuperposition of categorical sub-dimensions within its input vector space.",
      "tldr_zh": "该论文提出了一种神经心理学(neuropsychological)方法来提升人工智能(AI)神经网络的可解释性(explainability)，通过借鉴人类认知心理学中的分类(categorization)和相似性(similarity)概念，构建与人类思维模式对齐的合成解释框架。研究重点揭示了合成认知(synthetic cognition)中高度激活标记的分类收敛过程，即神经元创建的分类段实际上是其输入向量空间中分类子维度(categorical sub-dimensions)的叠加(superposition)。这一方法为理解神经网络的重构信息处理提供了新的启发性视角。",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "q-bio.NC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.07243v1",
      "published_date": "2024-10-23 05:27:09 UTC",
      "updated_date": "2024-10-23 05:27:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:47:39.877451"
    },
    {
      "arxiv_id": "2410.17566v1",
      "title": "Differentially Private Learning Needs Better Model Initialization and Self-Distillation",
      "title_zh": "差分隐私学习需要更好的模型初始化和自蒸馏",
      "authors": [
        "Ivoline C. Ngong",
        "Joseph P. Near",
        "Niloofar Mireshghallah"
      ],
      "abstract": "Differentially private SGD (DPSGD) enables privacy-preserving training of\nlanguage models, but often reduces utility, diversity, and linguistic quality.\nWe introduce DPRefine, a three-phase method that initializes a model using data\nsynthesis from a small pre-trained LM with rigorous filtering, applies DP\nfinetuning on private data, and performs self-distillation to refine outputs.\nThis approach significantly outperforms vanilla DPSGD, with AlpacaEval\npreferring DPRefine's generations in 78.4% of cases across all datasets. Our\nanalysis reveals that DPRefine reduces linguistic errors in generated text by\n84.0%, mitigating grammar and spelling errors, commonly associated with DPSGD.\nIt also reduces inconsistencies of non-private models, such as hallucinated\ndetails and misattributed quotes. We find that small models like GPT-2 can be\neffective for initialization and distillation, highlighting their potential in\nenabling scalable and efficient deployment of privacy-preserving language.",
      "tldr_zh": "本论文探讨了差分隐私 SGD (DPSGD) 在语言模型训练中的问题，包括降低效用、多样性和语言质量，并提出 DPRefine 一种三阶段方法：首先使用小预训练模型如 GPT-2 通过严格过滤的数据合成进行初始化，其次在私有数据上应用 DP 微调，最后执行 self-distillation 来精炼输出。实验结果显示，DPRefine 在 AlpacaEval 评估中优于 vanilla DPSGD，在 78.4% 的情况下生成更优文本，并将语言错误（如语法和拼写错误）减少 84.0%。此外，该方法还缓解了非私有模型的 inconsistency 问题，如虚构细节和错误引用，并证明小模型在初始化和蒸馏中的潜力，有助于实现可扩展的隐私保护语言模型部署。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "18 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.17566v1",
      "published_date": "2024-10-23 05:19:51 UTC",
      "updated_date": "2024-10-23 05:19:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:47:52.006462"
    },
    {
      "arxiv_id": "2410.17558v2",
      "title": "CLR-Bench: Evaluating Large Language Models in College-level Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Junnan Dong",
        "Zijin Hong",
        "Yuanchen Bei",
        "Feiran Huang",
        "Xinrun Wang",
        "Xiao Huang"
      ],
      "abstract": "Large language models (LLMs) have demonstrated their remarkable performance\nacross various language understanding tasks. While emerging benchmarks have\nbeen proposed to evaluate LLMs in various domains such as mathematics and\ncomputer science, they merely measure the accuracy in terms of the final\nprediction on multi-choice questions. However, it remains insufficient to\nverify the essential understanding of LLMs given a chosen choice. To fill this\ngap, we present CLR-Bench to comprehensively evaluate the LLMs in complex\ncollege-level reasoning. Specifically, (i) we prioritize 16 challenging college\ndisciplines in computer science and artificial intelligence. The dataset\ncontains 5 types of questions, while each question is associated with detailed\nexplanations from experts. (ii) To quantify a fair evaluation of LLMs'\nreasoning ability, we formalize the criteria with two novel metrics.\nQ$\\rightarrow$A is utilized to measure the performance of direct answer\nprediction, and Q$\\rightarrow$AR effectively considers the joint ability to\nanswer the question and provide rationale simultaneously. Extensive experiments\nare conducted with 40 LLMs over 1,018 discipline-specific questions. The\nresults demonstrate the key insights that LLMs, even the best closed-source\nLLM, i.e., GPT-4 turbo, tend to `guess' the college-level answers. It shows a\ndramatic decrease in accuracy from 63.31% Q$\\rightarrow$A to 39.00%\nQ$\\rightarrow$AR, indicating an unsatisfactory reasoning ability.",
      "tldr_zh": "本文提出 CLR-Bench，这是一个用于评估大型语言模型(LLMs)在大学级复杂推理中的基准，旨在弥补现有评估仅关注最终预测准确性的不足。该基准聚焦 16 个计算机科学和人工智能学科，包含 5 种问题类型，每题附有专家详细解释，并引入 Q→A（直接答案预测）和 Q→AR（同时回答和提供理由）两个新指标来量化 LLMs 的推理能力。在对 40 个 LLMs 的实验中，结果显示即使是 GPT-4 turbo，准确率从 Q→A 的 63.31% 降至 Q→AR 的 39.00%，表明 LLMs 倾向于“猜测”答案，推理能力仍显不足。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "18 pages, 6 figures, dataset and evaluation framework will be\n  opensourced",
      "pdf_url": "http://arxiv.org/pdf/2410.17558v2",
      "published_date": "2024-10-23 04:55:08 UTC",
      "updated_date": "2024-10-25 08:21:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:48:04.491883"
    },
    {
      "arxiv_id": "2410.17555v1",
      "title": "FairDgcl: Fairness-aware Recommendation with Dynamic Graph Contrastive Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Wei Chen",
        "Meng Yuan",
        "Zhao Zhang",
        "Ruobing Xie",
        "Fuzhen Zhuang",
        "Deqing Wang",
        "Rui Liu"
      ],
      "abstract": "As trustworthy AI continues to advance, the fairness issue in recommendations\nhas received increasing attention. A recommender system is considered unfair\nwhen it produces unequal outcomes for different user groups based on\nuser-sensitive attributes (e.g., age, gender). Some researchers have proposed\ndata augmentation-based methods aiming at alleviating user-level unfairness by\naltering the skewed distribution of training data among various user groups.\nDespite yielding promising results, they often rely on fairness-related\nassumptions that may not align with reality, potentially reducing the data\nquality and negatively affecting model effectiveness. To tackle this issue, in\nthis paper, we study how to implement high-quality data augmentation to improve\nrecommendation fairness. Specifically, we propose FairDgcl, a dynamic graph\nadversarial contrastive learning framework aiming at improving fairness in\nrecommender system. First, FairDgcl develops an adversarial contrastive network\nwith a view generator and a view discriminator to learn generating fair\naugmentation strategies in an adversarial style. Then, we propose two dynamic,\nlearnable models to generate contrastive views within contrastive learning\nframework, which automatically fine-tune the augmentation strategies.\nMeanwhile, we theoretically show that FairDgcl can simultaneously generate\nenhanced representations that possess both fairness and accuracy. Lastly,\ncomprehensive experiments conducted on four real-world datasets demonstrate the\neffectiveness of the proposed FairDgcl.",
      "tldr_zh": "该研究针对推荐系统中的用户级不公平问题（如基于年龄或性别的歧视），提出了一种FairDgcl框架，利用动态图对抗对比学习(dynamic graph contrastive learning)来实现高品质数据增强。FairDgcl包括一个对抗对比网络（由视图生成器和视图鉴别器组成），以及两个动态可学习模型，用于生成公平的增强策略并自动微调对比视图，从而同时提升推荐的公平性和准确性。理论分析证明了该框架能产生增强表示，实验在四个真实数据集上验证了其有效性，显著改善了推荐公平性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "12 pages, submitted to TKDE",
      "pdf_url": "http://arxiv.org/pdf/2410.17555v1",
      "published_date": "2024-10-23 04:43:03 UTC",
      "updated_date": "2024-10-23 04:43:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:48:15.420176"
    },
    {
      "arxiv_id": "2410.17546v2",
      "title": "Advancing Interpretability in Text Classification through Prototype Learning",
      "title_zh": "通过原型学习推进文本分类的可解释性",
      "authors": [
        "Bowen Wei",
        "Ziwei Zhu"
      ],
      "abstract": "Deep neural networks have achieved remarkable performance in various\ntext-based tasks but often lack interpretability, making them less suitable for\napplications where transparency is critical. To address this, we propose\nProtoLens, a novel prototype-based model that provides fine-grained,\nsub-sentence level interpretability for text classification. ProtoLens uses a\nPrototype-aware Span Extraction module to identify relevant text spans\nassociated with learned prototypes and a Prototype Alignment mechanism to\nensure prototypes are semantically meaningful throughout training. By aligning\nthe prototype embeddings with human-understandable examples, ProtoLens provides\ninterpretable predictions while maintaining competitive accuracy. Extensive\nexperiments demonstrate that ProtoLens outperforms both prototype-based and\nnon-interpretable baselines on multiple text classification benchmarks. Code\nand data are available at\n\\url{https://anonymous.4open.science/r/ProtoLens-CE0B/}.",
      "tldr_zh": "该研究针对深度神经网络在文本分类任务中缺乏可解释性的问题，提出了一种新型原型-based模型ProtoLens，以提供细粒度的子句子级解释性。ProtoLens 包括 Prototype-aware Span Extraction 模块，用于识别与学到的原型相关的文本跨度，以及 Prototype Alignment 机制，确保原型在训练过程中语义上与人类可理解的例子对齐，从而实现可解释的预测同时保持高准确性。通过广泛实验，ProtoLens 在多个文本分类基准上优于基于原型的和非可解释的基线模型，为透明度要求高的应用提供了有效解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.17546v2",
      "published_date": "2024-10-23 03:53:46 UTC",
      "updated_date": "2024-10-24 04:21:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:48:26.878373"
    },
    {
      "arxiv_id": "2410.17538v1",
      "title": "Primal-Dual Spectral Representation for Off-policy Evaluation",
      "title_zh": "原对偶谱表示用于脱策略评估",
      "authors": [
        "Yang Hu",
        "Tianyi Chen",
        "Na Li",
        "Kai Wang",
        "Bo Dai"
      ],
      "abstract": "Off-policy evaluation (OPE) is one of the most fundamental problems in\nreinforcement learning (RL) to estimate the expected long-term payoff of a\ngiven target policy with only experiences from another behavior policy that is\npotentially unknown. The distribution correction estimation (DICE) family of\nestimators have advanced the state of the art in OPE by breaking the curse of\nhorizon. However, the major bottleneck of applying DICE estimators lies in the\ndifficulty of solving the saddle-point optimization involved, especially with\nneural network implementations. In this paper, we tackle this challenge by\nestablishing a linear representation of value function and stationary\ndistribution correction ratio, i.e., primal and dual variables in the DICE\nframework, using the spectral decomposition of the transition operator. Such\nprimal-dual representation not only bypasses the non-convex non-concave\noptimization in vanilla DICE, therefore enabling an computational efficient\nalgorithm, but also paves the way for more efficient utilization of historical\ndata. We highlight that our algorithm, SpectralDICE, is the first to leverage\nthe linear representation of primal-dual variables that is both computation and\nsample efficient, the performance of which is supported by a rigorous\ntheoretical sample complexity guarantee and a thorough empirical evaluation on\nvarious benchmarks.",
      "tldr_zh": "该论文针对强化学习中的 Off-policy Evaluation (OPE) 问题，提出了一种基于过渡算子的谱分解 (spectral decomposition) 的 primal-dual 表示方法，以线性表示价值函数和静止分布校正比率，从而绕过 DICE (Distribution Correction Estimation) 框架中的非凸非凹优化挑战。SpectralDICE 算法作为创新成果，不仅实现了计算和样本高效的优化，还更有效地利用历史数据。实验结果通过严格的理论样本复杂度保证和多基准测试，证明了该方法的优越性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "29 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.17538v1",
      "published_date": "2024-10-23 03:38:31 UTC",
      "updated_date": "2024-10-23 03:38:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:48:39.550008"
    },
    {
      "arxiv_id": "2410.17532v1",
      "title": "Responsible Multilingual Large Language Models: A Survey of Development, Applications, and Societal Impact",
      "title_zh": "负责任的多语言大型语言模型：发展、应用和社会影响的综述",
      "authors": [
        "Junhua Liu",
        "Bin Fu"
      ],
      "abstract": "Multilingual Large Language Models (MLLMs) represent a pivotal advancement in\ndemocratizing artificial intelligence across linguistic boundaries. While\ntheoretical foundations are well-established, practical implementation\nguidelines remain scattered. This work bridges this gap by providing a\ncomprehensive end-to-end framework for developing and deploying MLLMs in\nproduction environments. We make three distinctive contributions: First, we\npresent an actionable pipeline from data pre-processing through deployment,\nintegrating insights from academic research and industrial applications.\nSecond, using Llama2 as a case study, we provide detailed optimization\nstrategies for enhancing multilingual capabilities, including curriculum\nlearning approaches for balancing high-resource and low-resource languages,\ntokenization strategies, and effective sampling methods. Third, we offer an\ninterdisciplinary analysis that considers technical, linguistic, and cultural\nperspectives in MLLM development. Our findings reveal critical challenges in\nsupporting linguistic diversity, with 88.38% of world languages categorized as\nlow-resource, affecting over a billion speakers. We examine practical solutions\nthrough real-world applications in customer service, search engines, and\nmachine translation. By synthesizing theoretical frameworks with\nproduction-ready implementation strategies, this survey provides essential\nguidance for practitioners and researchers working to develop more inclusive\nand effective multilingual AI systems.",
      "tldr_zh": "这篇调查论文探讨了负责任的多语言大语言模型(MLLMs)的开发、应用和社会影响，提供了一个全面的端到端框架，从数据预处理到部署，整合学术和工业洞见。论文以Llama2为例，介绍了优化策略，包括课程学习(curriculum learning)方法、tokenization strategies和采样技术，以平衡高资源和低资源语言。研究揭示了关键挑战，即88.38%的世界语言被归类为低资源语言，影响超过10亿人，并通过实际应用如客服、搜索引擎和机器翻译，提出实用解决方案。最后，该工作合成理论框架与生产策略，为构建更具包容性和有效性的多语言AI系统提供指导。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.17532v1",
      "published_date": "2024-10-23 03:19:15 UTC",
      "updated_date": "2024-10-23 03:19:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:48:53.117778"
    },
    {
      "arxiv_id": "2410.17517v2",
      "title": "Bridging Swarm Intelligence and Reinforcement Learning",
      "title_zh": "桥接群",
      "authors": [
        "Karthik Soma",
        "Yann Bouteiller",
        "Heiko Hamann",
        "Giovanni Beltrame"
      ],
      "abstract": "Swarm intelligence (SI) explores how large groups of simple individuals\n(e.g., insects, fish, birds) collaborate to produce complex behaviors,\nexemplifying that the whole is greater than the sum of its parts. A fundamental\ntask in SI is Collective Decision-Making (CDM), where a group selects the best\noption among several alternatives, such as choosing an optimal foraging site.\nIn this work, we demonstrate a theoretical and empirical equivalence between\nCDM and single-agent reinforcement learning (RL) in multi-armed bandit\nproblems, utilizing concepts from opinion dynamics, evolutionary game theory,\nand RL. This equivalence bridges the gap between SI and RL and leads us to\nintroduce a novel abstract RL update rule called Maynard-Cross Learning.\nAdditionally, it provides a new population-based perspective on common RL\npractices like learning rate adjustment and batching. Our findings enable\ncross-disciplinary fertilization between RL and SI, allowing techniques from\none field to enhance the understanding and methodologies of the other.",
      "tldr_zh": "本研究探讨了群智能(Swarm Intelligence, SI)中的集体决策(Collective Decision-Making, CDM)与单代理强化学习(Reinforcement Learning, RL)在多臂赌博机(multi-armed bandit)问题中的理论和经验等价性，通过意见动态、进化博弈论和RL概念进行分析。基于这一等价性，论文引入了一个新的抽象RL更新规则——Maynard-Cross Learning，并为RL常见实践如学习率调整和批量处理提供了新的群体视角。这些发现桥接了SI和RL之间的差距，促进了跨学科交流，使一个领域的技术能增强另一个领域的理解和方法。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.GT"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.17517v2",
      "published_date": "2024-10-23 02:49:37 UTC",
      "updated_date": "2025-01-17 21:38:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:49:03.441129"
    },
    {
      "arxiv_id": "2410.17511v1",
      "title": "Time and Frequency Synergy for Source-Free Time-Series Domain Adaptations",
      "title_zh": "时间与频率协同作用用于无源时间序列领域适应",
      "authors": [
        "Muhammad Tanzil Furqon",
        "Mahardhika Pratama",
        "Ary Mazharuddin Shiddiqi",
        "Lin Liu",
        "Habibullah Habibullah",
        "Kutluyil Dogancay"
      ],
      "abstract": "The issue of source-free time-series domain adaptations still gains scarce\nresearch attentions. On the other hand, existing approaches rely solely on\ntime-domain features ignoring frequency components providing complementary\ninformation. This paper proposes Time Frequency Domain Adaptation (TFDA), a\nmethod to cope with the source-free time-series domain adaptation problems.\nTFDA is developed with a dual branch network structure fully utilizing both\ntime and frequency features in delivering final predictions. It induces\npseudo-labels based on a neighborhood concept where predictions of a sample\ngroup are aggregated to generate reliable pseudo labels. The concept of\ncontrastive learning is carried out in both time and frequency domains with\npseudo label information and a negative pair exclusion strategy to make valid\nneighborhood assumptions. In addition, the time-frequency consistency technique\nis proposed using the self-distillation strategy while the uncertainty\nreduction strategy is implemented to alleviate uncertainties due to the domain\nshift problem. Last but not least, the curriculum learning strategy is\nintegrated to combat noisy pseudo labels. Our experiments demonstrate the\nadvantage of our approach over prior arts with noticeable margins in benchmark\nproblems.",
      "tldr_zh": "该论文针对源数据不可用（source-free）的时序数据域适应问题，提出Time Frequency Domain Adaptation (TFDA)方法，通过双分支网络结构同时利用时域和频域特征来提升预测准确性。TFDA引入邻域概念生成伪标签（pseudo-labels），并在时域和频域应用对比学习（contrastive learning），结合负对排除策略、时间-频率一致性技术、自蒸馏策略和不确定性减少策略，以缓解域移问题并处理噪声伪标签。此外，论文整合课程学习策略优化训练过程，实验结果显示TFDA在基准时序适应任务上比现有方法有显著优势，证明了时频协同的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.17511v1",
      "published_date": "2024-10-23 02:29:50 UTC",
      "updated_date": "2024-10-23 02:29:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:49:16.051667"
    },
    {
      "arxiv_id": "2410.17510v1",
      "title": "Congestion Forecast for Trains with Railroad-Graph-based Semi-Supervised Learning using Sparse Passenger Reports",
      "title_zh": "翻译失败",
      "authors": [
        "Soto Anno",
        "Kota Tsubouchi",
        "Masamichi Shimosaka"
      ],
      "abstract": "Forecasting rail congestion is crucial for efficient mobility in transport\nsystems. We present rail congestion forecasting using reports from passengers\ncollected through a transit application. Although reports from passengers have\nreceived attention from researchers, ensuring a sufficient volume of reports is\nchallenging due to passenger's reluctance. The limited number of reports\nresults in the sparsity of the congestion label, which can be an issue in\nbuilding a stable prediction model. To address this issue, we propose a\nsemi-supervised method for congestion forecasting for trains, or SURCONFORT.\nOur key idea is twofold: firstly, we adopt semi-supervised learning to leverage\nsparsely labeled data and many unlabeled data. Secondly, in order to complement\nthe unlabeled data from nearby stations, we design a railway network-oriented\ngraph and apply the graph to semi-supervised graph regularization. Empirical\nexperiments with actual reporting data show that SURCONFORT improved the\nforecasting performance by 14.9% over state-of-the-art methods under the label\nsparsity.",
      "tldr_zh": "该研究针对铁路拥堵预测问题，提出了一种基于半监督学习（semi-supervised learning）的SURCONFORT方法，利用稀疏的乘客报告数据。方法的关键在于结合半监督学习来利用少量标签数据和大量无标签数据，同时设计铁路网络导向的图（railroad-graph）进行图正则化，以补充附近车站的信息。实验结果显示，在实际报告数据下，SURCONFORT 比最先进方法提高了 14.9% 的预测性能，为高效的交通系统管理提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted in ACM SIGSPATIAL 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.17510v1",
      "published_date": "2024-10-23 02:25:53 UTC",
      "updated_date": "2024-10-23 02:25:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:51:27.216281"
    },
    {
      "arxiv_id": "2410.17506v1",
      "title": "Mitigating Graph Covariate Shift via Score-based Out-of-distribution Augmentation",
      "title_zh": "通过基于分数的分布外增强缓解图协变量偏移",
      "authors": [
        "Bohan Wang",
        "Yurui Chang",
        "Lu Lin"
      ],
      "abstract": "Distribution shifts between training and testing datasets significantly\nimpair the model performance on graph learning. A commonly-taken causal view in\ngraph invariant learning suggests that stable predictive features of graphs are\ncausally associated with labels, whereas varying environmental features lead to\ndistribution shifts. In particular, covariate shifts caused by unseen\nenvironments in test graphs underscore the critical need for\nout-of-distribution (OOD) generalization. Existing graph augmentation methods\ndesigned to address the covariate shift often disentangle the stable and\nenvironmental features in the input space, and selectively perturb or mixup the\nenvironmental features. However, such perturbation-based methods heavily rely\non an accurate separation of stable and environmental features, and their\nexploration ability is confined to existing environmental features in the\ntraining distribution. To overcome these limitations, we introduce a novel\napproach using score-based graph generation strategies that synthesize unseen\nenvironmental features while preserving the validity and stable features of\noverall graph patterns. Our comprehensive empirical evaluations demonstrate the\nenhanced effectiveness of our method in improving graph OOD generalization.",
      "tldr_zh": "该研究针对图学习中分布偏移（distribution shifts）问题，特别是协变量偏移（graph covariate shift），提出了一种基于分数生成（score-based）的 out-of-distribution 增强方法。该方法通过合成未见环境特征，同时保留图的稳定特征和整体模式，有效克服现有增强方法对特征分离的依赖和探索局限。实验结果显示，该方法显著提升了图 OOD（out-of-distribution）泛化能力，在全面评估中证明其有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "17 pages, 5 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2410.17506v1",
      "published_date": "2024-10-23 02:09:02 UTC",
      "updated_date": "2024-10-23 02:09:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:49:39.278886"
    },
    {
      "arxiv_id": "2410.17504v1",
      "title": "An Ontology-Enabled Approach For User-Centered and Knowledge-Enabled Explanations of AI Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Shruthi Chari"
      ],
      "abstract": "Explainable Artificial Intelligence (AI) focuses on helping humans understand\nthe working of AI systems or their decisions and has been a cornerstone of AI\nfor decades. Recent research in explainability has focused on explaining the\nworkings of AI models or model explainability. There have also been several\nposition statements and review papers detailing the needs of end-users for\nuser-centered explainability but fewer implementations. Hence, this thesis\nseeks to bridge some gaps between model and user-centered explainability. We\ncreate an explanation ontology (EO) to represent literature-derived explanation\ntypes via their supporting components. We implement a knowledge-augmented\nquestion-answering (QA) pipeline to support contextual explanations in a\nclinical setting. Finally, we are implementing a system to combine explanations\nfrom different AI methods and data modalities. Within the EO, we can represent\nfifteen different explanation types, and we have tested these representations\nin six exemplar use cases. We find that knowledge augmentations improve the\nperformance of base large language models in the contextualized QA, and the\nperformance is variable across disease groups. In the same setting, clinicians\nalso indicated that they prefer to see actionability as one of the main foci in\nexplanations. In our explanations combination method, we plan to use similarity\nmetrics to determine the similarity of explanations in a chronic disease\ndetection setting. Overall, through this thesis, we design methods that can\nsupport knowledge-enabled explanations across different use cases, accounting\nfor the methods in today's AI era that can generate the supporting components\nof these explanations and domain knowledge sources that can enhance them.",
      "tldr_zh": "这篇论文提出了一种基于本体（ontology）的用户中心和知识启用解释方法，旨在桥接Explainable Artificial Intelligence (XAI)中模型解释与用户需求的差距。\n作者开发了解释本体（EO）来表示15种基于文献的解释类型及其支持组件，并实现了知识增强的问答（QA）管道，用于临床环境的上下文解释。\n实验结果显示，知识增强提高了基础大语言模型在QA任务中的性能，但效果因疾病组不同而异；临床医生强调解释应优先聚焦于行动性（actionability）。\n总体上，该方法通过结合不同AI方法和数据模态的解释，支持更全面的知识启用解释，适用于多种用例。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Doctoral dissertation. Some chapters appeared as individual papers -\n  arXiv:2302.05752 is one such chapters",
      "pdf_url": "http://arxiv.org/pdf/2410.17504v1",
      "published_date": "2024-10-23 02:03:49 UTC",
      "updated_date": "2024-10-23 02:03:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:51:45.042838"
    },
    {
      "arxiv_id": "2410.17500v2",
      "title": "Learning Fair and Preferable Allocations through Neural Network",
      "title_zh": "通过神经网络学习公平且可取的分配",
      "authors": [
        "Ryota Maruo",
        "Koh Takeuchi",
        "Hisashi Kashima"
      ],
      "abstract": "The fair allocation of indivisible resources is a fundamental problem.\nExisting research has developed various allocation mechanisms or algorithms to\nsatisfy different fairness notions. For example, round robin (RR) was proposed\nto meet the fairness criterion known as envy-freeness up to one good (EF1).\nExpert algorithms without mathematical formulations are used in real-world\nresource allocation problems to find preferable outcomes for users. Therefore,\nwe aim to design mechanisms that strictly satisfy good properties with\nreplicating expert knowledge. However, this problem is challenging because such\nheuristic rules are often difficult to formalize mathematically, complicating\ntheir integration into theoretical frameworks. Additionally, formal algorithms\nstruggle to find preferable outcomes, and directly replicating these implicit\nrules can result in unfair allocations because human decision-making can\nintroduce biases. In this paper, we aim to learn implicit allocation mechanisms\nfrom examples while strictly satisfying fairness constraints, specifically\nfocusing on learning EF1 allocation mechanisms through supervised learning on\nexamples of reported valuations and corresponding allocation outcomes produced\nby implicit rules. To address this, we developed a neural RR (NRR), a novel\nneural network that parameterizes RR. NRR is built from a differentiable\nrelaxation of RR and can be trained to learn the agent ordering used for RR. We\nconducted experiments to learn EF1 allocation mechanisms from examples,\ndemonstrating that our method outperforms baselines in terms of the proximity\nof predicted allocations and other metrics.",
      "tldr_zh": "本论文探讨了公平分配不可分资源的问题，旨在设计机制满足公平标准如 Envy-Freeness up to one good (EF1)，同时复制专家知识以实现可取的分配结果。面对启发式规则难以形式化和潜在偏见的挑战，作者开发了 Neural RR (NRR)，一个基于神经网络的参数化 Round Robin 框架，通过可微松弛和监督学习从报告的估值和分配例子中学习代理排序。实验结果表明，NRR 在预测分配的接近度和其他指标上优于基线方法，为公平分配提供了更可靠的解决方案。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.17500v2",
      "published_date": "2024-10-23 01:47:55 UTC",
      "updated_date": "2025-05-12 01:43:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:51:57.091906"
    },
    {
      "arxiv_id": "2410.17498v1",
      "title": "Mechanisms of Symbol Processing for In-Context Learning in Transformer Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Paul Smolensky",
        "Roland Fernandez",
        "Zhenghao Herbert Zhou",
        "Mattia Opper",
        "Jianfeng Gao"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated impressive abilities in symbol\nprocessing through in-context learning (ICL). This success flies in the face of\ndecades of predictions that artificial neural networks cannot master abstract\nsymbol manipulation. We seek to understand the mechanisms that can enable\nrobust symbol processing in transformer networks, illuminating both the\nunanticipated success, and the significant limitations, of transformers in\nsymbol processing. Borrowing insights from symbolic AI on the power of\nProduction System architectures, we develop a high-level language, PSL, that\nallows us to write symbolic programs to do complex, abstract symbol processing,\nand create compilers that precisely implement PSL programs in transformer\nnetworks which are, by construction, 100% mechanistically interpretable. We\ndemonstrate that PSL is Turing Universal, so the work can inform the\nunderstanding of transformer ICL in general. The type of transformer\narchitecture that we compile from PSL programs suggests a number of paths for\nenhancing transformers' capabilities at symbol processing. (Note: The first\nsection of the paper gives an extended synopsis of the entire paper.)",
      "tldr_zh": "本研究探讨了大型语言模型 (LLMs) 通过 in-context learning (ICL) 在符号处理方面的机制，挑战了传统观点，即神经网络无法掌握抽象符号操作。作者借鉴符号 AI 的 Production System 架构，开发了一种高水平语言 PSL，用于编写复杂的符号程序，并创建编译器来精确地在 transformer 网络中实现这些程序，确保 100% 机制可解释性。PSL 被证明是 Turing Universal，这有助于阐明 transformer 在符号处理中的成功与局限性，并提出多种路径来增强其能力。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.NE",
        "cs.SC",
        "F.1; I.2"
      ],
      "primary_category": "cs.AI",
      "comment": "101 pages (including 30 pages of Appendices), 18 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.17498v1",
      "published_date": "2024-10-23 01:38:10 UTC",
      "updated_date": "2024-10-23 01:38:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:52:08.200042"
    },
    {
      "arxiv_id": "2410.17489v1",
      "title": "Unsupervised Domain Adaptation for Action Recognition via Self-Ensembling and Conditional Embedding Alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Indrajeet Ghosh",
        "Garvit Chugh",
        "Abu Zaher Md Faridee",
        "Nirmalya Roy"
      ],
      "abstract": "Recent advancements in deep learning-based wearable human action recognition\n(wHAR) have improved the capture and classification of complex motions, but\nadoption remains limited due to the lack of expert annotations and domain\ndiscrepancies from user variations. Limited annotations hinder the model's\nability to generalize to out-of-distribution samples. While data augmentation\ncan improve generalizability, unsupervised augmentation techniques must be\napplied carefully to avoid introducing noise. Unsupervised domain adaptation\n(UDA) addresses domain discrepancies by aligning conditional distributions with\nlabeled target samples, but vanilla pseudo-labeling can lead to error\npropagation. To address these challenges, we propose $\\mu$DAR, a novel joint\noptimization architecture comprised of three functions: (i) consistency\nregularizer between augmented samples to improve model classification\ngeneralizability, (ii) temporal ensemble for robust pseudo-label generation and\n(iii) conditional distribution alignment to improve domain generalizability.\nThe temporal ensemble works by aggregating predictions from past epochs to\nsmooth out noisy pseudo-label predictions, which are then used in the\nconditional distribution alignment module to minimize kernel-based class-wise\nconditional maximum mean discrepancy ($k$CMMD) between the source and target\nfeature space to learn a domain invariant embedding. The\nconsistency-regularized augmentations ensure that multiple augmentations of the\nsame sample share the same labels; this results in (a) strong generalization\nwith limited source domain samples and (b) consistent pseudo-label generation\nin target samples. The novel integration of these three modules in $\\mu$DAR\nresults in a range of $\\approx$ 4-12% average macro-F1 score improvement over\nsix state-of-the-art UDA methods in four benchmark wHAR datasets",
      "tldr_zh": "本研究针对可穿戴设备人类动作识别（wHAR）中的标注不足和域差异问题，提出了一种新型无监督域适应（Unsupervised Domain Adaptation）框架μDAR。该框架整合了三个关键模块：（i）一致性正则化，通过增强样本之间的预测一致性提升模型泛化能力；（ii）时间集成（Self-Ensembling），用于生成鲁棒的伪标签；以及（iii）条件嵌入对齐（Conditional Embedding Alignment），通过最小化基于核的类-wise 条件最大均值差异（kCMMD）来实现源域和目标域特征空间的对齐。实验结果显示，μDAR 在四个基准 wHAR 数据集上，比六种最先进 UDA 方法平均宏 F1 分数提高了约 4-12%，显著改善了模型的泛化性能和鲁棒性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "This work has been accepted to the Proceedings of the IEEE\n  International Conference on Data Mining, 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.17489v1",
      "published_date": "2024-10-23 00:59:27 UTC",
      "updated_date": "2024-10-23 00:59:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:52:22.059625"
    },
    {
      "arxiv_id": "2410.17481v1",
      "title": "AI, Global Governance, and Digital Sovereignty",
      "title_zh": "AI、全球治理和数字主权",
      "authors": [
        "Swati Srivastava",
        "Justin Bullock"
      ],
      "abstract": "This essay examines how Artificial Intelligence (AI) systems are becoming\nmore integral to international affairs by affecting how global governors exert\npower and pursue digital sovereignty. We first introduce a taxonomy of\nmultifaceted AI payoffs for governments and corporations related to\ninstrumental, structural, and discursive power in the domains of violence,\nmarkets, and rights. We next leverage different institutional and practice\nperspectives on sovereignty to assess how digital sovereignty is variously\nimplicated in AI-empowered global governance. States both seek sovereign\ncontrol over AI infrastructures in the institutional approach, while\nestablishing sovereign competence through AI infrastructures in the practice\napproach. Overall, we present the digital sovereignty stakes of AI as related\nto entanglements of public and private power. Rather than foreseeing technology\ncompanies as replacing states, we argue that AI systems will embed in global\ngovernance to create dueling dynamics of public/private cooperation and\ncontestation. We conclude with sketching future directions for IR research on\nAI and global governance.",
      "tldr_zh": "这篇论文探讨了人工智能 (AI) 如何融入国际事务，影响全球治理者和数字主权的追求。首先，作者引入一个分类法 (taxonomy)，分析 AI 为政府和公司带来的多方面收益，包括工具性、结构性和话语权力，在暴力、市场和权利领域发挥作用。其次，通过制度和实践视角评估数字主权，指出国家既寻求对 AI 基础设施的主权控制，也通过 AI 增强主权能力，导致公共和私人权力的合作与竞争。最后，论文认为 AI 不会取代国家，而是嵌入全球治理中，并为国际关系 (IR) 研究提出未来方向。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "21 pages, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2410.17481v1",
      "published_date": "2024-10-23 00:05:33 UTC",
      "updated_date": "2024-10-23 00:05:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:52:32.402828"
    },
    {
      "arxiv_id": "2410.18148v3",
      "title": "Beyond the Kolmogorov Barrier: A Learnable Weighted Hybrid Autoencoder for Model Order Reduction",
      "title_zh": "翻译失败",
      "authors": [
        "Nithin Somasekharan",
        "Shaowu Pan"
      ],
      "abstract": "Representation learning for high-dimensional, complex physical systems aims\nto identify a low-dimensional intrinsic latent space, which is crucial for\nreduced-order modeling and modal analysis. To overcome the well-known\nKolmogorov barrier, deep autoencoders (AEs) have been introduced in recent\nyears, but they often suffer from poor convergence behavior as the rank of the\nlatent space increases. To address this issue, we propose the learnable\nweighted hybrid autoencoder, a hybrid approach that combines the strengths of\nsingular value decomposition (SVD) with deep autoencoders through a learnable\nweighted framework. We find that the introduction of learnable weighting\nparameters is essential -- without them, the resulting model would either\ncollapse into a standard POD or fail to exhibit the desired convergence\nbehavior. Interestingly, we empirically find that our trained model has a\nsharpness thousands of times smaller compared to other models. Our experiments\non classical chaotic PDE systems, including the 1D Kuramoto-Sivashinsky and\nforced isotropic turbulence datasets, demonstrate that our approach\nsignificantly improves generalization performance compared to several competing\nmethods. Additionally, when combining with time series modeling techniques\n(e.g., Koopman operator, LSTM), the proposed technique offers significant\nimprovements for surrogate modeling of high-dimensional multi-scale PDE\nsystems.",
      "tldr_zh": "本研究旨在克服Kolmogorov barrier问题，提出了一种learnable weighted hybrid autoencoder，用于高维复杂物理系统的模型阶减法，通过结合singular value decomposition (SVD)和deep autoencoders的优点来学习低维潜空间。关键创新在于引入可学习权重参数，避免模型退化成标准proper orthogonal decomposition (POD)或收敛失败，并发现训练后的模型锐度（sharpness）比其他模型小数千倍。在实验中，该方法在1D Kuramoto-Sivashinsky和forced isotropic turbulence等混沌PDE数据集上显著提升泛化性能，并与Koopman operator或LSTM等时间序列建模技术结合时，显著改善高维多尺度PDE系统的代理建模。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.comp-ph",
        "stat.ML",
        "68T07, 76F99"
      ],
      "primary_category": "cs.LG",
      "comment": "31 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.18148v3",
      "published_date": "2024-10-23 00:04:26 UTC",
      "updated_date": "2025-02-28 17:12:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T15:52:44.981460"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 115,
  "processed_papers_count": 115,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-20T15:53:12.012558"
}