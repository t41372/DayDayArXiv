[
  {
    "arxiv_id": "2410.18318v1",
    "title": "Self-Supervised Learning for Time Series: A Review & Critique of FITS",
    "authors": [
      "Andreas Løvendahl Eefsen",
      "Nicholas Erup Larsen",
      "Oliver Glozmann Bork Hansen",
      "Thor Højhus Avenstrup"
    ],
    "abstract": "Accurate time series forecasting is a highly valuable endeavour with\napplications across many industries. Despite recent deep learning advancements,\nincreased model complexity, and larger model sizes, many state-of-the-art\nmodels often perform worse or on par with simpler models. One of those cases is\na recently proposed model, FITS, claiming competitive performance with\nsignificantly reduced parameter counts. By training a one-layer neural network\nin the complex frequency domain, we are able to replicate these results. Our\nexperiments on a wide range of real-world datasets further reveal that FITS\nespecially excels at capturing periodic and seasonal patterns, but struggles\nwith trending, non-periodic, or random-resembling behavior. With our two novel\nhybrid approaches, where we attempt to remedy the weaknesses of FITS by\ncombining it with DLinear, we achieve the best results of any known open-source\nmodel on multivariate regression and promising results in multiple/linear\nregression on price datasets, on top of vastly improving upon what FITS\nachieves as a standalone model.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "arXiv:2307.03756v3 45 pages, 36 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.18318v1",
    "published_date": "2024-10-23 23:03:09 UTC",
    "updated_date": "2024-10-23 23:03:09 UTC"
  },
  {
    "arxiv_id": "2410.18312v1",
    "title": "Countering Autonomous Cyber Threats",
    "authors": [
      "Kade M. Heckel",
      "Adrian Weller"
    ],
    "abstract": "With the capability to write convincing and fluent natural language and\ngenerate code, Foundation Models present dual-use concerns broadly and within\nthe cyber domain specifically. Generative AI has already begun to impact\ncyberspace through a broad illicit marketplace for assisting malware\ndevelopment and social engineering attacks through hundreds of\nmalicious-AI-as-a-services tools. More alarming is that recent research has\nshown the potential for these advanced models to inform or independently\nexecute offensive cyberspace operations. However, these previous investigations\nprimarily focused on the threats posed by proprietary models due to the until\nrecent lack of strong open-weight model and additionally leave the impacts of\nnetwork defenses or potential countermeasures unexplored. Critically,\nunderstanding the aptitude of downloadable models to function as offensive\ncyber agents is vital given that they are far more difficult to govern and\nprevent their misuse. As such, this work evaluates several state-of-the-art FMs\non their ability to compromise machines in an isolated network and investigates\ndefensive mechanisms to defeat such AI-powered attacks. Using target machines\nfrom a commercial provider, the most recently released downloadable models are\nfound to be on par with a leading proprietary model at conducting simple cyber\nattacks with common hacking tools against known vulnerabilities. To mitigate\nsuch LLM-powered threats, defensive prompt injection (DPI) payloads for\ndisrupting the malicious cyber agent's workflow are demonstrated to be\neffective. From these results, the implications for AI safety and governance\nwith respect to cybersecurity is analyzed.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CR",
    "comment": "76 pages, MPhil Thesis",
    "pdf_url": "http://arxiv.org/pdf/2410.18312v1",
    "published_date": "2024-10-23 22:46:44 UTC",
    "updated_date": "2024-10-23 22:46:44 UTC"
  },
  {
    "arxiv_id": "2410.18295v1",
    "title": "Kenyan Sign Language (KSL) Dataset: Using Artificial Intelligence (AI) in Bridging Communication Barrier among the Deaf Learners",
    "authors": [
      "Lilian Wanzare",
      "Joel Okutoyi",
      "Maurine Kang'ahi",
      "Mildred Ayere"
    ],
    "abstract": "Kenyan Sign Language (KSL) is the primary language used by the deaf community\nin Kenya. It is the medium of instruction from Pre-primary 1 to university\namong deaf learners, facilitating their education and academic achievement.\nKenyan Sign Language is used for social interaction, expression of needs,\nmaking requests and general communication among persons who are deaf in Kenya.\nHowever, there exists a language barrier between the deaf and the hearing\npeople in Kenya. Thus, the innovation on AI4KSL is key in eliminating the\ncommunication barrier. Artificial intelligence for KSL is a two-year research\nproject (2023-2024) that aims to create a digital open-access AI of spontaneous\nand elicited data from a representative sample of the Kenyan deaf community.\nThe purpose of this study is to develop AI assistive technology dataset that\ntranslates English to KSL as a way of fostering inclusion and bridging language\nbarriers among deaf learners in Kenya. Specific objectives are: Build KSL\ndataset for spoken English and video recorded Kenyan Sign Language and to build\ntranscriptions of the KSL signs to a phonetic-level interface of the sign\nlanguage. In this paper, the methodology for building the dataset is described.\nData was collected from 48 teachers and tutors of the deaf learners and 400\nlearners who are Deaf. Participants engaged mainly in sign language elicitation\ntasks through reading and singing. Findings of the dataset consisted of about\n14,000 English sentences with corresponding KSL Gloss derived from a pool of\nabout 4000 words and about 20,000 signed KSL videos that are either signed\nwords or sentences. The second level of data outcomes consisted of 10,000 split\nand segmented KSL videos. The third outcome of the dataset consists of 4,000\ntranscribed words into five articulatory parameters according to HamNoSys\nsystem.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "14 pages, to be published in 3rd International Conference on\n  Artificial Intelligence and Robotics (MIRG-ICAIR 2023)",
    "pdf_url": "http://arxiv.org/pdf/2410.18295v1",
    "published_date": "2024-10-23 22:01:31 UTC",
    "updated_date": "2024-10-23 22:01:31 UTC"
  },
  {
    "arxiv_id": "2410.18293v2",
    "title": "1-2-3-Go! Policy Synthesis for Parameterized Markov Decision Processes via Decision-Tree Learning and Generalization",
    "authors": [
      "Muqsit Azeem",
      "Debraj Chakraborty",
      "Sudeep Kanav",
      "Jan Kretinsky",
      "Mohammadsadegh Mohagheghi",
      "Stefanie Mohr",
      "Maximilian Weininger"
    ],
    "abstract": "Despite the advances in probabilistic model checking, the scalability of the\nverification methods remains limited. In particular, the state space often\nbecomes extremely large when instantiating parameterized Markov decision\nprocesses (MDPs) even with moderate values. Synthesizing policies for such\n\\emph{huge} MDPs is beyond the reach of available tools. We propose a\nlearning-based approach to obtain a reasonable policy for such huge MDPs.\n  The idea is to generalize optimal policies obtained by model-checking small\ninstances to larger ones using decision-tree learning. Consequently, our method\nbypasses the need for explicit state-space exploration of large models,\nproviding a practical solution to the state-space explosion problem. We\ndemonstrate the efficacy of our approach by performing extensive\nexperimentation on the relevant models from the quantitative verification\nbenchmark set. The experimental results indicate that our policies perform\nwell, even when the size of the model is orders of magnitude beyond the reach\nof state-of-the-art analysis tools.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.LO",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.AI",
    "comment": "Extended version of the paper accepted at VMCAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.18293v2",
    "published_date": "2024-10-23 21:57:05 UTC",
    "updated_date": "2025-04-01 06:08:39 UTC"
  },
  {
    "arxiv_id": "2410.18275v1",
    "title": "Screw Geometry Meets Bandits: Incremental Acquisition of Demonstrations to Generate Manipulation Plans",
    "authors": [
      "Dibyendu Das",
      "Aditya Patankar",
      "Nilanjan Chakraborty",
      "C. R. Ramakrishnan",
      "I. V. Ramakrishnan"
    ],
    "abstract": "In this paper, we study the problem of methodically obtaining a sufficient\nset of kinesthetic demonstrations, one at a time, such that a robot can be\nconfident of its ability to perform a complex manipulation task in a given\nregion of its workspace. Although Learning from Demonstrations has been an\nactive area of research, the problems of checking whether a set of\ndemonstrations is sufficient, and systematically seeking additional\ndemonstrations have remained open. We present a novel approach to address these\nopen problems using (i) a screw geometric representation to generate\nmanipulation plans from demonstrations, which makes the sufficiency of a set of\ndemonstrations measurable; (ii) a sampling strategy based on PAC-learning from\nmulti-armed bandit optimization to evaluate the robot's ability to generate\nmanipulation plans in a subregion of its task space; and (iii) a heuristic to\nseek additional demonstration from areas of weakness. Thus, we present an\napproach for the robot to incrementally and actively ask for new demonstration\nexamples until the robot can assess with high confidence that it can perform\nthe task successfully. We present experimental results on two example\nmanipulation tasks, namely, pouring and scooping, to illustrate our approach. A\nshort video on the method: https://youtu.be/R-qICICdEos",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "8 pages, 6 figures, under review in IEEE Robotics and Automation\n  Letters",
    "pdf_url": "http://arxiv.org/pdf/2410.18275v1",
    "published_date": "2024-10-23 20:57:56 UTC",
    "updated_date": "2024-10-23 20:57:56 UTC"
  },
  {
    "arxiv_id": "2410.18267v2",
    "title": "Backdoor in Seconds: Unlocking Vulnerabilities in Large Pre-trained Models via Model Editing",
    "authors": [
      "Dongliang Guo",
      "Mengxuan Hu",
      "Zihan Guan",
      "Junfeng Guo",
      "Thomas Hartvigsen",
      "Sheng Li"
    ],
    "abstract": "Large pre-trained models have achieved notable success across a range of\ndownstream tasks. However, recent research shows that a type of adversarial\nattack ($\\textit{i.e.,}$ backdoor attack) can manipulate the behavior of\nmachine learning models through contaminating their training dataset, posing\nsignificant threat in the real-world application of large pre-trained model,\nespecially for those customized models. Therefore, addressing the unique\nchallenges for exploring vulnerability of pre-trained models is of paramount\nimportance. Through empirical studies on the capability for performing backdoor\nattack in large pre-trained models ($\\textit{e.g.,}$ ViT), we find the\nfollowing unique challenges of attacking large pre-trained models: 1) the\ninability to manipulate or even access large training datasets, and 2) the\nsubstantial computational resources required for training or fine-tuning these\nmodels. To address these challenges, we establish new standards for an\neffective and feasible backdoor attack in the context of large pre-trained\nmodels. In line with these standards, we introduce our EDT model, an\n\\textbf{E}fficient, \\textbf{D}ata-free, \\textbf{T}raining-free backdoor attack\nmethod. Inspired by model editing techniques, EDT injects an editing-based\nlightweight codebook into the backdoor of large pre-trained models, which\nreplaces the embedding of the poisoned image with the target image without\npoisoning the training dataset or training the victim model. Our experiments,\nconducted across various pre-trained models such as ViT, CLIP, BLIP, and stable\ndiffusion, and on downstream tasks including image classification, image\ncaptioning, and image generation, demonstrate the effectiveness of our method.\nOur code is available in the supplementary material.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.18267v2",
    "published_date": "2024-10-23 20:32:14 UTC",
    "updated_date": "2024-10-25 23:13:32 UTC"
  },
  {
    "arxiv_id": "2410.18252v3",
    "title": "Asynchronous RLHF: Faster and More Efficient Off-Policy RL for Language Models",
    "authors": [
      "Michael Noukhovitch",
      "Shengyi Huang",
      "Sophie Xhonneux",
      "Arian Hosseini",
      "Rishabh Agarwal",
      "Aaron Courville"
    ],
    "abstract": "The dominant paradigm for RLHF is online and on-policy RL: synchronously\ngenerating from the large language model (LLM) policy, labelling with a reward\nmodel, and learning using feedback on the LLM's own outputs. While performant,\nthis paradigm is computationally inefficient. Inspired by classical deep RL\nliterature, we propose separating generation and learning in RLHF. This enables\nasynchronous generation of new samples while simultaneously training on old\nsamples, leading to faster training and more compute-optimal scaling. However,\nasynchronous training relies on an underexplored regime, online but off-policy\nRLHF: learning on samples from previous iterations of our model which give a\nworse training signal. We tackle the fundamental challenge in this regime: how\nmuch off-policyness can we tolerate for asynchronous training to speed up\nlearning but maintain performance? Among several RLHF algorithms we test,\nonline DPO is found to be most robust to off-policy data, and robustness\nincreases with the scale of the policy model. We study further compute\noptimizations for asynchronous RLHF but find that they come at a performance\ncost, giving rise to a trade-off. We verify the scalability of asynchronous\nRLHF by training a general-purpose chatbot from LLaMA 3.1 8B on an\ninstruction-following task ~40% faster than a synchronous run while matching\nfinal performance. Finally, we extend our results to math and reasoning to\ndemonstrate asynchronous RL can finetune Rho 1B on GSM8k ~70% faster while\nmatching synchronous accuracy.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "accepted at ICLR 2025, code at\n  https://github.com/mnoukhov/async_rlhf, integrated into the open-instruct\n  library https://github.com/allenai/open-instruct",
    "pdf_url": "http://arxiv.org/pdf/2410.18252v3",
    "published_date": "2024-10-23 19:59:50 UTC",
    "updated_date": "2025-04-26 08:33:32 UTC"
  },
  {
    "arxiv_id": "2411.03334v3",
    "title": "Neural Network Prediction of Strong Lensing Systems with Domain Adaptation and Uncertainty Quantification",
    "authors": [
      "Shrihan Agarwal",
      "Aleksandra Ćiprijanović",
      "Brian D. Nord"
    ],
    "abstract": "Modeling strong gravitational lenses is computationally expensive for the\ncomplex data from modern and next-generation cosmic surveys. Deep learning has\nemerged as a promising approach for finding lenses and predicting lensing\nparameters, such as the Einstein radius. Mean-variance Estimators (MVEs) are a\ncommon approach for obtaining aleatoric (data) uncertainties from a neural\nnetwork prediction. However, neural networks have not been demonstrated to\nperform well on out-of-domain target data successfully - e.g., when trained on\nsimulated data and applied to real, observational data. In this work, we\nperform the first study of the efficacy of MVEs in combination with\nunsupervised domain adaptation (UDA) on strong lensing data. The source domain\ndata is noiseless, and the target domain data has noise mimicking modern\ncosmology surveys. We find that adding UDA to MVE increases the accuracy on the\ntarget data by a factor of about two over an MVE model without UDA. Including\nUDA also permits much more well-calibrated aleatoric uncertainty predictions.\nAdvancements in this approach may enable future applications of MVE models to\nreal observational data.",
    "categories": [
      "astro-ph.IM",
      "astro-ph.CO",
      "astro-ph.GA",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "astro-ph.IM",
    "comment": "Accepted to the Machine Learning for Physical Sciences workshop at\n  NeurIPS 2024; 24 pages, 2 figures, 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2411.03334v3",
    "published_date": "2024-10-23 19:56:57 UTC",
    "updated_date": "2025-01-07 03:01:49 UTC"
  },
  {
    "arxiv_id": "2410.18248v2",
    "title": "Fast Inference for Augmented Large Language Models",
    "authors": [
      "Rana Shahout",
      "Cong Liang",
      "Shiji Xin",
      "Qianru Lao",
      "Yong Cui",
      "Minlan Yu",
      "Michael Mitzenmacher"
    ],
    "abstract": "Augmented Large Language Models (LLMs) enhance the capabilities of standalone\nLLMs by integrating external data sources through API calls. In interactive LLM\napplications, efficient scheduling is crucial for maintaining low request\ncompletion times, directly impacting user engagement. However, these\naugmentations introduce scheduling challenges due to the need to manage limited\nmemory for cached information (KV caches). As a result, traditional size-based\nscheduling algorithms, such as Shortest Job First (SJF), become less effective\nat minimizing completion times. Existing work focuses only on handling requests\nduring API calls by preserving, discarding, or swapping memory without\nconsidering how to schedule requests with API calls. In this paper, we propose\nLAMPS, a novel LLM inference framework for augmented LLMs. LAMPS minimizes\nrequest completion time through a unified scheduling approach that considers\nthe total length of requests and their handling strategies during API calls.\nRecognizing that LLM inference is memory-bound, our approach ranks requests\nbased on their consumption of memory over time, which depends on both the\noutput sizes and how a request is managed during its API calls. To implement\nour scheduling, LAMPS predicts the strategy that minimizes memory waste of a\nrequest during its API calls, aligning with but improving upon existing\napproaches. We also propose starvation prevention techniques and optimizations\nto mitigate the overhead of our scheduling. We implement LAMPS on top of vLLM\nand evaluate its performance against baseline LLM inference systems,\ndemonstrating improvements in end-to-end latency by 27%-85% and reductions in\nTTFT by 4%-96% compared to the existing augmented-LLM system, with even greater\ngains over vLLM.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.18248v2",
    "published_date": "2024-10-23 19:53:30 UTC",
    "updated_date": "2024-10-25 19:18:00 UTC"
  },
  {
    "arxiv_id": "2410.18242v2",
    "title": "Human-Agent Coordination in Games under Incomplete Information via Multi-Step Intent",
    "authors": [
      "Shenghui Chen",
      "Ruihan Zhao",
      "Sandeep Chinchali",
      "Ufuk Topcu"
    ],
    "abstract": "Strategic coordination between autonomous agents and human partners under\nincomplete information can be modeled as turn-based cooperative games. We\nextend a turn-based game under incomplete information, the shared-control game,\nto allow players to take multiple actions per turn rather than a single action.\nThe extension enables the use of multi-step intent, which we hypothesize will\nimprove performance in long-horizon tasks. To synthesize cooperative policies\nfor the agent in this extended game, we propose an approach featuring a memory\nmodule for a running probabilistic belief of the environment dynamics and an\nonline planning algorithm called IntentMCTS. This algorithm strategically\nselects the next action by leveraging any communicated multi-step intent via\nreward augmentation while considering the current belief. Agent-to-agent\nsimulations in the Gnomes at Night testbed demonstrate that IntentMCTS requires\nfewer steps and control switches than baseline methods. A human-agent user\nstudy corroborates these findings, showing an 18.52% higher success rate\ncompared to the heuristic baseline and a 5.56% improvement over the single-step\nprior work. Participants also report lower cognitive load, frustration, and\nhigher satisfaction with the IntentMCTS agent partner.",
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.18242v2",
    "published_date": "2024-10-23 19:37:19 UTC",
    "updated_date": "2025-02-17 22:35:16 UTC"
  },
  {
    "arxiv_id": "2410.18241v1",
    "title": "Characterising Open Source Co-opetition in Company-hosted Open Source Software Projects: The Cases of PyTorch, TensorFlow, and Transformers",
    "authors": [
      "Cailean Osborne",
      "Farbod Daneshyan",
      "Runzhi He",
      "Hengzhi Ye",
      "Yuxia Zhang",
      "Minghui Zhou"
    ],
    "abstract": "Companies, including market rivals, have long collaborated on the development\nof open source software (OSS), resulting in a tangle of co-operation and\ncompetition known as \"open source co-opetition\". While prior work investigates\nopen source co-opetition in OSS projects that are hosted by vendor-neutral\nfoundations, we have a limited understanding thereof in OSS projects that are\nhosted and governed by one company. Given their prevalence, it is timely to\ninvestigate open source co-opetition in such contexts. Towards this end, we\nconduct a mixed-methods analysis of three company-hosted OSS projects in the\nartificial intelligence (AI) industry: Meta's PyTorch (prior to its donation to\nthe Linux Foundation), Google's TensorFlow, and Hugging Face's Transformers. We\ncontribute three key findings. First, while the projects exhibit similar code\nauthorship patterns between host and external companies (80%/20% of commits),\ncollaborations are structured differently (e.g., decentralised vs.\nhub-and-spoke networks). Second, host and external companies engage in\nstrategic, non-strategic, and contractual collaborations, with varying\nincentives and collaboration practices. Some of the observed collaborations are\nspecific to the AI industry (e.g., hardware-software optimizations or AI model\nintegrations), while others are typical of the broader software industry (e.g.,\nbug fixing or task outsourcing). Third, single-vendor governance creates a\npower imbalance that influences open source co-opetition practices and\npossibilities, from the host company's singular decision-making power (e.g.,\nthe risk of license change) to their community involvement strategy (e.g., from\nover-control to over-delegation). We conclude with recommendations for future\nresearch.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.SE",
    "comment": "26 pages, 2 figures, 9 tables",
    "pdf_url": "http://arxiv.org/pdf/2410.18241v1",
    "published_date": "2024-10-23 19:35:41 UTC",
    "updated_date": "2024-10-23 19:35:41 UTC"
  },
  {
    "arxiv_id": "2410.18239v1",
    "title": "E2E-Swin-Unet++: An Enhanced End-to-End Swin-Unet Architecture With Dual Decoders For PTMC Segmentation",
    "authors": [
      "Maryam Dialameh",
      "Hossein Rajabzadeh",
      "Moslem Sadeghi-Goughari",
      "Jung Suk Sim",
      "Hyock Ju Kwon"
    ],
    "abstract": "Efficiently managing papillary thyroid microcarcinoma (PTMC) while minimizing\npatient discomfort poses a significant clinical challenge. Radiofrequency\nablation (RFA) offers a less invasive alternative to surgery and radiation\ntherapy for PTMC treatment, characterized by shorter recovery times and reduced\npain. As an image-guided procedure, RFA generates localized heat by delivering\nhigh-frequency electrical currents through electrodes to the targeted area\nunder ultrasound imaging guidance. However, the precision and skill required by\noperators for accurate guidance using current ultrasound B-mode imaging\ntechnologies remain significant challenges. To address these challenges, we\ndevelop a novel AI segmentation model, E2E-Swin-Unet++. This model enhances\nultrasound B-mode imaging by enabling real-time identification and segmentation\nof PTMC tumors and monitoring of the region of interest for precise targeting\nduring treatment. E2E-Swin- Unet++ is an advanced end-to-end extension of the\nSwin-Unet architecture, incorporating thyroid region information to minimize\nthe risk of false PTMC segmentation while providing fast inference\ncapabilities. Experimental results on a real clinical RFA dataset demonstrate\nthe superior performance of E2E-Swin-Unet++ compared to related models. Our\nproposed solution significantly improves the precision and control of RFA\nablation treatment by enabling real-time identification and segmentation of\nPTMC margins during the procedure.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.18239v1",
    "published_date": "2024-10-23 19:33:33 UTC",
    "updated_date": "2024-10-23 19:33:33 UTC"
  },
  {
    "arxiv_id": "2410.18237v1",
    "title": "Bayesian optimization for robust robotic grasping using a sensorized compliant hand",
    "authors": [
      "Juan G. Lechuz-Sierra",
      "Ana Elvira H. Martin",
      "Ashok M. Sundaram",
      "Ruben Martinez-Cantin",
      "Máximo A. Roa"
    ],
    "abstract": "One of the first tasks we learn as children is to grasp objects based on our\ntactile perception. Incorporating such skill in robots will enable multiple\napplications, such as increasing flexibility in industrial processes or\nproviding assistance to people with physical disabilities. However, the\ndifficulty lies in adapting the grasping strategies to a large variety of tasks\nand objects, which can often be unknown. The brute-force solution is to learn\nnew grasps by trial and error, which is inefficient and ineffective. In\ncontrast, Bayesian optimization applies active learning by adding information\nto the approximation of an optimal grasp. This paper proposes the use of\nBayesian optimization techniques to safely perform robotic grasping. We analyze\ndifferent grasp metrics to provide realistic grasp optimization in a real\nsystem including tactile sensors. An experimental evaluation in the robotic\nsystem shows the usefulness of the method for performing unknown object\ngrasping even in the presence of noise and uncertainty inherent to a real-world\nenvironment.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.18237v1",
    "published_date": "2024-10-23 19:33:14 UTC",
    "updated_date": "2024-10-23 19:33:14 UTC"
  },
  {
    "arxiv_id": "2410.18221v1",
    "title": "Data Augmentation for Automated Adaptive Rodent Training",
    "authors": [
      "Dibyendu Das",
      "Alfredo Fontanini",
      "Joshua F. Kogan",
      "Haibin Ling",
      "C. R. Ramakrishnan",
      "I. V. Ramakrishnan"
    ],
    "abstract": "Fully optimized automation of behavioral training protocols for lab animals\nlike rodents has long been a coveted goal for researchers. It is an otherwise\nlabor-intensive and time-consuming process that demands close interaction\nbetween the animal and the researcher. In this work, we used a data-driven\napproach to optimize the way rodents are trained in labs. In pursuit of our\ngoal, we looked at data augmentation, a technique that scales well in data-poor\nenvironments. Using data augmentation, we built several artificial rodent\nmodels, which in turn would be used to build an efficient and automatic\ntrainer. Then we developed a novel similarity metric based on the action\nprobability distribution to measure the behavioral resemblance of our models to\nthat of real rodents.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "5 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.18221v1",
    "published_date": "2024-10-23 18:51:11 UTC",
    "updated_date": "2024-10-23 18:51:11 UTC"
  },
  {
    "arxiv_id": "2411.04133v1",
    "title": "Enhancement of Approximation Spaces by the Use of Primals and Neighborhood",
    "authors": [
      "A. Çaksu Güler"
    ],
    "abstract": "Rough set theory is one of the most widely used and significant approaches\nfor handling incomplete information. It divides the universe in the beginning\nand uses equivalency relations to produce blocks. Numerous generalized rough\nset models have been put out and investigated in an effort to increase\nflexibility and extend the range of possible uses. We introduce four new\ngeneralized rough set models that draw inspiration from \"neighborhoods and\nprimals\" in order to make a contribution to this topic. By minimizing the\nuncertainty regions, these models are intended to assist decision makers in\nmore effectively analyzing and evaluating the provided data. We verify this\ngoal by demonstrating that the existing models outperform certain current\nmethod approaches in terms of improving the approximation operators (upper and\nlower) and accuracy measurements. We claim that the current models can preserve\nnearly all significant aspects associated with the rough set model. Preserving\nthe monotonic property, which enables us to assess data uncertainty and boost\nconfidence in outcomes, is one of the intriguing characterizations derived from\nthe existing models. With the aid of specific instances, we also compare the\nareas of the current approach. Finally, we demonstrate that the new strategy we\ndefine for our everyday health-related problem yields more accurate findings.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.04133v1",
    "published_date": "2024-10-23 18:49:13 UTC",
    "updated_date": "2024-10-23 18:49:13 UTC"
  },
  {
    "arxiv_id": "2410.18218v1",
    "title": "Optimizing the role of human evaluation in LLM-based spoken document summarization systems",
    "authors": [
      "Margaret Kroll",
      "Kelsey Kraus"
    ],
    "abstract": "The emergence of powerful LLMs has led to a paradigm shift in abstractive\nsummarization of spoken documents. The properties that make LLMs so valuable\nfor this task -- creativity, ability to produce fluent speech, and ability to\nabstract information from large corpora -- also present new challenges to\nevaluating their content. Quick, cost-effective automatic evaluations such as\nROUGE and BERTScore offer promise, but do not yet show competitive performance\nwhen compared to human evaluations. We draw on methodologies from the social\nsciences to propose an evaluation paradigm for spoken document summarization\nexplicitly tailored for generative AI content. We provide detailed evaluation\ncriteria and best practices guidelines to ensure robustness in the experimental\ndesign, replicability, and trustworthiness of human evaluation studies. We\nadditionally include two case studies that show how these human-in-the-loop\nevaluation methods have been implemented at a major U.S. technology company.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.18218v1",
    "published_date": "2024-10-23 18:37:14 UTC",
    "updated_date": "2024-10-23 18:37:14 UTC"
  },
  {
    "arxiv_id": "2410.18216v1",
    "title": "Neural Cover Selection for Image Steganography",
    "authors": [
      "Karl Chahine",
      "Hyeji Kim"
    ],
    "abstract": "In steganography, selecting an optimal cover image, referred to as cover\nselection, is pivotal for effective message concealment. Traditional methods\nhave typically employed exhaustive searches to identify images that conform to\nspecific perceptual or complexity metrics. However, the relationship between\nthese metrics and the actual message hiding efficacy of an image is unclear,\noften yielding less-than-ideal steganographic outcomes. Inspired by recent\nadvancements in generative models, we introduce a novel cover selection\nframework, which involves optimizing within the latent space of pretrained\ngenerative models to identify the most suitable cover images, distinguishing\nitself from traditional exhaustive search methods. Our method shows significant\nadvantages in message recovery and image quality. We also conduct an\ninformation-theoretic analysis of the generated cover images, revealing that\nmessage hiding predominantly occurs in low-variance pixels, reflecting the\nwaterfilling algorithm's principles in parallel Gaussian channels. Our code can\nbe found at:\nhttps://github.com/karlchahine/Neural-Cover-Selection-for-Image-Steganography.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.18216v1",
    "published_date": "2024-10-23 18:32:34 UTC",
    "updated_date": "2024-10-23 18:32:34 UTC"
  },
  {
    "arxiv_id": "2410.18215v1",
    "title": "Advancing NLP Security by Leveraging LLMs as Adversarial Engines",
    "authors": [
      "Sudarshan Srinivasan",
      "Maria Mahbub",
      "Amir Sadovnik"
    ],
    "abstract": "This position paper proposes a novel approach to advancing NLP security by\nleveraging Large Language Models (LLMs) as engines for generating diverse\nadversarial attacks. Building upon recent work demonstrating LLMs'\neffectiveness in creating word-level adversarial examples, we argue for\nexpanding this concept to encompass a broader range of attack types, including\nadversarial patches, universal perturbations, and targeted attacks. We posit\nthat LLMs' sophisticated language understanding and generation capabilities can\nproduce more effective, semantically coherent, and human-like adversarial\nexamples across various domains and classifier architectures. This paradigm\nshift in adversarial NLP has far-reaching implications, potentially enhancing\nmodel robustness, uncovering new vulnerabilities, and driving innovation in\ndefense mechanisms. By exploring this new frontier, we aim to contribute to the\ndevelopment of more secure, reliable, and trustworthy NLP systems for critical\napplications.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "5 pages",
    "pdf_url": "http://arxiv.org/pdf/2410.18215v1",
    "published_date": "2024-10-23 18:32:03 UTC",
    "updated_date": "2024-10-23 18:32:03 UTC"
  },
  {
    "arxiv_id": "2410.18210v2",
    "title": "Towards Understanding the Fragility of Multilingual LLMs against Fine-Tuning Attacks",
    "authors": [
      "Samuele Poppi",
      "Zheng-Xin Yong",
      "Yifei He",
      "Bobbie Chern",
      "Han Zhao",
      "Aobo Yang",
      "Jianfeng Chi"
    ],
    "abstract": "Recent advancements in Large Language Models (LLMs) have sparked widespread\nconcerns about their safety. Recent work demonstrates that safety alignment of\nLLMs can be easily removed by fine-tuning with a few adversarially chosen\ninstruction-following examples, i.e., fine-tuning attacks. We take a further\nstep to understand fine-tuning attacks in multilingual LLMs. We first discover\ncross-lingual generalization of fine-tuning attacks: using a few adversarially\nchosen instruction-following examples in one language, multilingual LLMs can\nalso be easily compromised (e.g., multilingual LLMs fail to refuse harmful\nprompts in other languages). Motivated by this finding, we hypothesize that\nsafety-related information is language-agnostic and propose a new method termed\nSafety Information Localization (SIL) to identify the safety-related\ninformation in the model parameter space. Through SIL, we validate this\nhypothesis and find that only changing 20% of weight parameters in fine-tuning\nattacks can break safety alignment across all languages. Furthermore, we\nprovide evidence to the alternative pathways hypothesis for why freezing\nsafety-related parameters does not prevent fine-tuning attacks, and we\ndemonstrate that our attack vector can still jailbreak LLMs adapted to new\nlanguages.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "15 pages, 6 figures, 7 tables",
    "pdf_url": "http://arxiv.org/pdf/2410.18210v2",
    "published_date": "2024-10-23 18:27:36 UTC",
    "updated_date": "2025-02-27 19:17:13 UTC"
  },
  {
    "arxiv_id": "2410.18202v1",
    "title": "PyTSC: A Unified Platform for Multi-Agent Reinforcement Learning in Traffic Signal Control",
    "authors": [
      "Rohit Bokade",
      "Xiaoning Jin"
    ],
    "abstract": "Multi-Agent Reinforcement Learning (MARL) presents a promising approach for\naddressing the complexity of Traffic Signal Control (TSC) in urban\nenvironments. However, existing platforms for MARL-based TSC research face\nchallenges such as slow simulation speeds and convoluted, difficult-to-maintain\ncodebases. To address these limitations, we introduce PyTSC, a robust and\nflexible simulation environment that facilitates the training and evaluation of\nMARL algorithms for TSC. PyTSC integrates multiple simulators, such as SUMO and\nCityFlow, and offers a streamlined API, empowering researchers to explore a\nbroad spectrum of MARL approaches efficiently. PyTSC accelerates\nexperimentation and provides new opportunities for advancing intelligent\ntraffic management systems in real-world applications.",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "primary_category": "cs.MA",
    "comment": "13 pages",
    "pdf_url": "http://arxiv.org/pdf/2410.18202v1",
    "published_date": "2024-10-23 18:10:38 UTC",
    "updated_date": "2024-10-23 18:10:38 UTC"
  },
  {
    "arxiv_id": "2410.18194v2",
    "title": "ZIP-FIT: Embedding-Free Data Selection via Compression-Based Alignment",
    "authors": [
      "Elyas Obbad",
      "Iddah Mlauzi",
      "Brando Miranda",
      "Rylan Schaeffer",
      "Kamal Obbad",
      "Suhana Bedi",
      "Sanmi Koyejo"
    ],
    "abstract": "Data selection is crucial for optimizing language model (LM) performance on\nspecific tasks, yet most existing methods fail to effectively consider the\ntarget task distribution.\n  Current approaches either ignore task-specific requirements entirely or rely\non approximations that fail to capture the nuanced patterns needed for tasks\nlike Autoformalization or code generation.\n  Methods that do consider the target distribution often rely on simplistic,\nsometimes noisy, representations, like hashed n-gram features, which can lead\nto collisions and introduce noise.\n  We introduce ZIP-FIT, a data selection framework that uses gzip compression\nto directly measure alignment between potential training data and the target\ntask distribution.\n  In extensive evaluations on Autoformalization and Python code generation,\nZIP-FIT significantly outperforms leading baselines like DSIR and D4.\n  Models trained on ZIP-FIT-selected data achieve their lowest cross-entropy\nloss up to 85.1\\% faster than baselines, demonstrating that better task\nalignment leads to more efficient learning.\n  In addition, ZIP-FIT performs selection up to 65.8\\% faster than DSIR and two\norders of magnitude faster than D4.\n  Notably, ZIP-FIT shows that smaller, well-aligned datasets often outperform\nlarger but less targeted ones, demonstrating that a small amount of higher\nquality data is superior to a large amount of lower quality data.\n  Our results imply that task-aware data selection is crucial for efficient\ndomain adaptation, and that compression offers a principled way to measure task\nalignment.\n  By showing that targeted data selection can dramatically improve\ntask-specific performance, our work provides new insights into the relationship\nbetween data quality, task alignment, and model learning efficiency.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.18194v2",
    "published_date": "2024-10-23 18:01:06 UTC",
    "updated_date": "2025-04-12 19:39:18 UTC"
  },
  {
    "arxiv_id": "2410.18164v1",
    "title": "TabDPT: Scaling Tabular Foundation Models",
    "authors": [
      "Junwei Ma",
      "Valentin Thomas",
      "Rasa Hosseinzadeh",
      "Hamidreza Kamkari",
      "Alex Labach",
      "Jesse C. Cresswell",
      "Keyvan Golestan",
      "Guangwei Yu",
      "Maksims Volkovs",
      "Anthony L. Caterini"
    ],
    "abstract": "The challenges faced by neural networks on tabular data are well-documented\nand have hampered the progress of tabular foundation models. Techniques\nleveraging in-context learning (ICL) have shown promise here, allowing for\ndynamic adaptation to unseen data. ICL can provide predictions for entirely new\ndatasets without further training or hyperparameter tuning, therefore providing\nvery fast inference when encountering a novel task. However, scaling ICL for\ntabular data remains an issue: approaches based on large language models cannot\nefficiently process numeric tables, and tabular-specific techniques have not\nbeen able to effectively harness the power of real data to improve performance\nand generalization. We are able to overcome these challenges by training\ntabular-specific ICL-based architectures on real data with self-supervised\nlearning and retrieval, combining the best of both worlds. Our resulting model\n-- the Tabular Discriminative Pre-trained Transformer (TabDPT) -- achieves\nstate-of-the-art performance on the CC18 (classification) and CTR23\n(regression) benchmarks with no task-specific fine-tuning, demonstrating the\nadapatability and speed of ICL once the model is pre-trained. TabDPT also\ndemonstrates strong scaling as both model size and amount of available data\nincrease, pointing towards future improvements simply through the curation of\nlarger tabular pre-training datasets and training larger models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Minimal TabDPT interface to provide predictions on new datasets\n  available at the following link: https://github.com/layer6ai-labs/TabDPT",
    "pdf_url": "http://arxiv.org/pdf/2410.18164v1",
    "published_date": "2024-10-23 18:00:00 UTC",
    "updated_date": "2024-10-23 18:00:00 UTC"
  },
  {
    "arxiv_id": "2410.18077v1",
    "title": "ALTA: Compiler-Based Analysis of Transformers",
    "authors": [
      "Peter Shaw",
      "James Cohan",
      "Jacob Eisenstein",
      "Kenton Lee",
      "Jonathan Berant",
      "Kristina Toutanova"
    ],
    "abstract": "We propose a new programming language called ALTA and a compiler that can map\nALTA programs to Transformer weights. ALTA is inspired by RASP, a language\nproposed by Weiss et al. (2021), and Tracr (Lindner et al., 2023), a compiler\nfrom RASP programs to Transformer weights. ALTA complements and extends this\nprior work, offering the ability to express loops and to compile programs to\nUniversal Transformers, among other advantages. ALTA allows us to\nconstructively show how Transformers can represent length-invariant algorithms\nfor computing parity and addition, as well as a solution to the SCAN benchmark\nof compositional generalization tasks, without requiring intermediate\nscratchpad decoding steps. We also propose tools to analyze cases where the\nexpressibility of an algorithm is established, but end-to-end training on a\ngiven training set fails to induce behavior consistent with the desired\nalgorithm. To this end, we explore training from ALTA execution traces as a\nmore fine-grained supervision signal. This enables additional experiments and\ntheoretical analyses relating the learnability of various algorithms to data\navailability and modeling decisions, such as positional encodings. We make the\nALTA framework -- language specification, symbolic interpreter, and weight\ncompiler -- available to the community to enable further applications and\ninsights.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.18077v1",
    "published_date": "2024-10-23 17:58:49 UTC",
    "updated_date": "2024-10-23 17:58:49 UTC"
  },
  {
    "arxiv_id": "2410.18076v3",
    "title": "Leveraging Skills from Unlabeled Prior Data for Efficient Online Exploration",
    "authors": [
      "Max Wilcoxson",
      "Qiyang Li",
      "Kevin Frans",
      "Sergey Levine"
    ],
    "abstract": "Unsupervised pretraining has been transformative in many supervised domains.\nHowever, applying such ideas to reinforcement learning (RL) presents a unique\nchallenge in that fine-tuning does not involve mimicking task-specific data,\nbut rather exploring and locating the solution through iterative\nself-improvement. In this work, we study how unlabeled offline trajectory data\ncan be leveraged to learn efficient exploration strategies. While prior data\ncan be used to pretrain a set of low-level skills, or as additional off-policy\ndata for online RL, it has been unclear how to combine these ideas effectively\nfor online exploration. Our method SUPE (Skills from Unlabeled Prior data for\nExploration) demonstrates that a careful combination of these ideas compounds\ntheir benefits. Our method first extracts low-level skills using a variational\nautoencoder (VAE), and then pseudo-labels unlabeled trajectories with\noptimistic rewards and high-level action labels, transforming prior data into\nhigh-level, task-relevant examples that encourage novelty-seeking behavior.\nFinally, SUPE uses these transformed examples as additional off-policy data for\nonline RL to learn a high-level policy that composes pretrained low-level\nskills to explore efficiently. In our experiments, SUPE consistently\noutperforms prior strategies across a suite of 42 long-horizon, sparse-reward\ntasks. Code: https://github.com/rail-berkeley/supe.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "27 pages, 19 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.18076v3",
    "published_date": "2024-10-23 17:58:45 UTC",
    "updated_date": "2025-02-23 18:58:48 UTC"
  },
  {
    "arxiv_id": "2410.18071v1",
    "title": "TP-Eval: Tap Multimodal LLMs' Potential in Evaluation by Customizing Prompts",
    "authors": [
      "Yuxuan Xie",
      "Tianhua Li",
      "Wenqi Shao",
      "Kaipeng Zhang"
    ],
    "abstract": "Recently, multimodal large language models (MLLMs) have received much\nattention for their impressive capabilities. The evaluation of MLLMs is\nbecoming critical to analyzing attributes of MLLMs and providing valuable\ninsights. However, current benchmarks overlook the problem of prompt\nsensitivity - minor prompt variations may lead to significant performance\nfluctuations. Thus, inappropriate prompts may obscure the models' capabilities,\nunderestimating the models' performance. Moreover, different models have\ndifferent preferences for different prompts, and thus, using the same prompt\nfor all models will cause evaluation bias. This paper analyzes this deficiency\nin existing benchmarks and further introduces a new evaluation framework named\nTP-Eval, which introduces a prompt customization method to reduce evaluation\nbiases and tap models' potential. TP-Eval will rewrite the original prompts to\ndifferent customized prompts for different models. In particular, we propose\nsome well-designed modules for prompt customization tailored to the scenario of\nMLLM evaluation. Extensive experiments demonstrate the effectiveness of our\napproach to uncovering models' capabilities, and TP-Eval should benefit the\ncommunity in developing more comprehensive and convincing MLLM evaluation\nbenchmarks.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.18071v1",
    "published_date": "2024-10-23 17:54:43 UTC",
    "updated_date": "2024-10-23 17:54:43 UTC"
  },
  {
    "arxiv_id": "2410.18070v3",
    "title": "Training Free Guided Flow Matching with Optimal Control",
    "authors": [
      "Luran Wang",
      "Chaoran Cheng",
      "Yizhen Liao",
      "Yanru Qu",
      "Ge Liu"
    ],
    "abstract": "Controlled generation with pre-trained Diffusion and Flow Matching models has\nvast applications. One strategy for guiding ODE-based generative models is\nthrough optimizing a target loss $R(x_1)$ while staying close to the prior\ndistribution. Along this line, some recent work showed the effectiveness of\nguiding flow model by differentiating through its ODE sampling process. Despite\nthe superior performance, the theoretical understanding of this line of methods\nis still preliminary, leaving space for algorithm improvement. Moreover,\nexisting methods predominately focus on Euclidean data manifold, and there is a\ncompelling need for guided flow methods on complex geometries such as SO(3),\nwhich prevails in high-stake scientific applications like protein design. We\npresent OC-Flow, a general and theoretically grounded training-free framework\nfor guided flow matching using optimal control. Building upon advances in\noptimal control theory, we develop effective and practical algorithms for\nsolving optimal control in guided ODE-based generation and provide a systematic\ntheoretical analysis of the convergence guarantee in both Euclidean and SO(3).\nWe show that existing backprop-through-ODE methods can be interpreted as\nspecial cases of Euclidean OC-Flow. OC-Flow achieved superior performance in\nextensive experiments on text-guided image manipulation, conditional molecule\ngeneration, and all-atom peptide design.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.18070v3",
    "published_date": "2024-10-23 17:53:11 UTC",
    "updated_date": "2025-03-09 03:35:34 UTC"
  },
  {
    "arxiv_id": "2410.18067v3",
    "title": "Beyond Position: the emergence of wavelet-like properties in Transformers",
    "authors": [
      "Valeria Ruscio",
      "Fabrizio Silvestri"
    ],
    "abstract": "This paper studies how transformer models develop robust wavelet-like\nproperties that effectively compensate for the theoretical limitations of\nRotary Position Embeddings (RoPE), providing insights into how these networks\nprocess sequential information across different scales. Through theoretical\nanalysis and empirical validation across models ranging from 1B to 12B\nparameters, we show that attention heads naturally evolve to implement\nmulti-resolution processing analogous to wavelet transforms. Our analysis\nestablishes that attention heads consistently organize into complementary\nfrequency bands with systematic power distribution patterns, and these\nwavelet-like characteristics become more pronounced in larger models. We\nprovide mathematical analysis showing how these properties align with optimal\nsolutions to the fundamental uncertainty principle between positional precision\nand frequency resolution. Our findings suggest that the effectiveness of modern\ntransformer architectures stems significantly from their development of optimal\nmulti-resolution decompositions that naturally address the theoretical\nconstraints of position encoding.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.18067v3",
    "published_date": "2024-10-23 17:48:28 UTC",
    "updated_date": "2025-01-21 17:50:47 UTC"
  },
  {
    "arxiv_id": "2410.18065v1",
    "title": "SPIRE: Synergistic Planning, Imitation, and Reinforcement Learning for Long-Horizon Manipulation",
    "authors": [
      "Zihan Zhou",
      "Animesh Garg",
      "Dieter Fox",
      "Caelan Garrett",
      "Ajay Mandlekar"
    ],
    "abstract": "Robot learning has proven to be a general and effective technique for\nprogramming manipulators. Imitation learning is able to teach robots solely\nfrom human demonstrations but is bottlenecked by the capabilities of the\ndemonstrations. Reinforcement learning uses exploration to discover better\nbehaviors; however, the space of possible improvements can be too large to\nstart from scratch. And for both techniques, the learning difficulty increases\nproportional to the length of the manipulation task. Accounting for this, we\npropose SPIRE, a system that first uses Task and Motion Planning (TAMP) to\ndecompose tasks into smaller learning subproblems and second combines imitation\nand reinforcement learning to maximize their strengths. We develop novel\nstrategies to train learning agents when deployed in the context of a planning\nsystem. We evaluate SPIRE on a suite of long-horizon and contact-rich robot\nmanipulation problems. We find that SPIRE outperforms prior approaches that\nintegrate imitation learning, reinforcement learning, and planning by 35% to\n50% in average task performance, is 6 times more data efficient in the number\nof human demonstrations needed to train proficient agents, and learns to\ncomplete tasks nearly twice as efficiently. View\nhttps://sites.google.com/view/spire-corl-2024 for more details.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "Conference on Robot Learning (CoRL) 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.18065v1",
    "published_date": "2024-10-23 17:42:07 UTC",
    "updated_date": "2024-10-23 17:42:07 UTC"
  },
  {
    "arxiv_id": "2410.18060v1",
    "title": "Explaining Bayesian Networks in Natural Language using Factor Arguments. Evaluation in the medical domain",
    "authors": [
      "Jaime Sevilla",
      "Nikolay Babakov",
      "Ehud Reiter",
      "Alberto Bugarin"
    ],
    "abstract": "In this paper, we propose a model for building natural language explanations\nfor Bayesian Network Reasoning in terms of factor arguments, which are\nargumentation graphs of flowing evidence, relating the observed evidence to a\ntarget variable we want to learn about. We introduce the notion of factor\nargument independence to address the outstanding question of defining when\narguments should be presented jointly or separately and present an algorithm\nthat, starting from the evidence nodes and a target node, produces a list of\nall independent factor arguments ordered by their strength. Finally, we\nimplemented a scheme to build natural language explanations of Bayesian\nReasoning using this approach. Our proposal has been validated in the medical\ndomain through a human-driven evaluation study where we compare the Bayesian\nNetwork Reasoning explanations obtained using factor arguments with an\nalternative explanation method. Evaluation results indicate that our proposed\nexplanation approach is deemed by users as significantly more useful for\nunderstanding Bayesian Network Reasoning than another existing explanation\nmethod it is compared to.",
    "categories": [
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "First Workshop on Explainable Artificial Intelligence for the medical\n  domain - EXPLIMED. THE 27TH EUROPEAN CONFERENCE ON ARTIFICIAL INTELLIGENCE",
    "pdf_url": "http://arxiv.org/pdf/2410.18060v1",
    "published_date": "2024-10-23 17:33:27 UTC",
    "updated_date": "2024-10-23 17:33:27 UTC"
  },
  {
    "arxiv_id": "2410.18040v1",
    "title": "Key Algorithms for Keyphrase Generation: Instruction-Based LLMs for Russian Scientific Keyphrases",
    "authors": [
      "Anna Glazkova",
      "Dmitry Morozov",
      "Timur Garipov"
    ],
    "abstract": "Keyphrase selection is a challenging task in natural language processing that\nhas a wide range of applications. Adapting existing supervised and unsupervised\nsolutions for the Russian language faces several limitations due to the rich\nmorphology of Russian and the limited number of training datasets available.\nRecent studies conducted on English texts show that large language models\n(LLMs) successfully address the task of generating keyphrases. LLMs allow\nachieving impressive results without task-specific fine-tuning, using text\nprompts instead. In this work, we access the performance of prompt-based\nmethods for generating keyphrases for Russian scientific abstracts. First, we\ncompare the performance of zero-shot and few-shot prompt-based methods,\nfine-tuned models, and unsupervised methods. Then we assess strategies for\nselecting keyphrase examples in a few-shot setting. We present the outcomes of\nhuman evaluation of the generated keyphrases and analyze the strengths and\nweaknesses of the models through expert assessment. Our results suggest that\nprompt-based methods can outperform common baselines even using simple text\nprompts.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "68T50",
      "I.2.7; I.7.m; H.3.3"
    ],
    "primary_category": "cs.CL",
    "comment": "The 12th International Conference on Analysis of Images, Social\n  Networks and Texts (AIST'2024)",
    "pdf_url": "http://arxiv.org/pdf/2410.18040v1",
    "published_date": "2024-10-23 17:07:32 UTC",
    "updated_date": "2024-10-23 17:07:32 UTC"
  },
  {
    "arxiv_id": "2410.18032v4",
    "title": "GraphTeam: Facilitating Large Language Model-based Graph Analysis via Multi-Agent Collaboration",
    "authors": [
      "Xin Sky Li",
      "Qizhi Chu",
      "Yubin Chen",
      "Yang Liu",
      "Yaoqi Liu",
      "Zekai Yu",
      "Weize Chen",
      "Chen Qian",
      "Chuan Shi",
      "Cheng Yang"
    ],
    "abstract": "Graphs are widely used for modeling relational data in real-world scenarios,\nsuch as social networks and urban computing. Existing LLM-based graph analysis\napproaches either integrate graph neural networks (GNNs) for specific machine\nlearning tasks, limiting their transferability, or rely solely on LLMs'\ninternal reasoning ability, resulting in suboptimal performance. To address\nthese limitations, we take advantage of recent advances in LLM-based agents,\nwhich have shown capabilities of utilizing external knowledge or tools for\nproblem solving. By simulating human problem-solving strategies such as analogy\nand collaboration, we propose a multi-agent system based on LLMs named\nGraphTeam, for graph analysis. GraphTeam consists of five LLM-based agents from\nthree modules, and the agents with different specialities can collaborate with\neach other to address complex problems. Specifically, (1) input-output\nnormalization module: the question agent extracts and refines four key\narguments from the original question, facilitating the problem understanding,\nand the answer agent organizes the results to meet the output requirement; (2)\nexternal knowledge retrieval module: we first build a knowledge base consisting\nof relevant documentation and experience information, and then the search agent\nretrieves the most relevant entries for each question. (3) problem-solving\nmodule: given the retrieved information from search agent, the coding agent\nuses established algorithms via programming to generate solutions, and in case\nthe coding agent does not work, the reasoning agent will directly compute the\nresults without programming. Extensive experiments on six graph analysis\nbenchmarks demonstrate that GraphTeam achieves state-of-the-art performance\nwith an average 25.85% improvement over the best baseline in terms of accuracy.\nThe code and data are available at https://github.com/BUPT-GAMMA/GraphTeam.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.18032v4",
    "published_date": "2024-10-23 17:02:59 UTC",
    "updated_date": "2025-02-24 06:16:00 UTC"
  },
  {
    "arxiv_id": "2410.18027v2",
    "title": "Cross-lingual Transfer of Reward Models in Multilingual Alignment",
    "authors": [
      "Jiwoo Hong",
      "Noah Lee",
      "Rodrigo Martínez-Castaño",
      "César Rodríguez",
      "James Thorne"
    ],
    "abstract": "Reinforcement learning with human feedback (RLHF) is shown to largely benefit\nfrom precise reward models (RMs). However, recent studies in reward modeling\nschemes are skewed towards English, limiting the applicability of RLHF in\nmultilingual alignments. In this work, we investigate the cross-lingual\ntransfer of RMs trained in diverse languages, primarily from English. Our\nexperimental results demonstrate the strong cross-lingual transfer of English\nRMs, exceeding target language RMs by 3~4% average increase in Multilingual\nRewardBench. Furthermore, we analyze the cross-lingual transfer of RMs through\nthe representation shifts. Finally, we perform multilingual alignment to\nexemplify how cross-lingual transfer in RM propagates to enhanced multilingual\ninstruction-following capability, along with extensive analyses on\noff-the-shelf RMs. We release the code, model, and data.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to NAACL 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.18027v2",
    "published_date": "2024-10-23 17:00:13 UTC",
    "updated_date": "2025-01-23 13:20:41 UTC"
  },
  {
    "arxiv_id": "2410.18001v2",
    "title": "Benchmarking Foundation Models on Exceptional Cases: Dataset Creation and Validation",
    "authors": [
      "Suho Kang",
      "Jungyang Park",
      "Joonseo Ha",
      "SoMin Kim",
      "JinHyeong Kim",
      "Subeen Park",
      "Kyungwoo Song"
    ],
    "abstract": "Foundation models (FMs) have achieved significant success across various\ntasks, leading to research on benchmarks for reasoning abilities. However,\nthere is a lack of studies on FMs performance in exceptional scenarios, which\nwe define as out-of-distribution (OOD) reasoning tasks. This paper is the first\nto address these cases, developing a novel dataset for evaluation of FMs across\nmultiple modalities, including graphic novels, calligraphy, news articles, and\nlyrics. It includes tasks for instance classification, character recognition,\ntoken prediction, and text generation. The paper also proposes prompt\nengineering techniques like Chain-of-Thought (CoT) and CoT+Few-Shot to enhance\nperformance. Validation of FMs using various methods revealed improvements. The\ncode repository is accessible at:\nhttps://github.com/MLAI-Yonsei/ExceptionalBenchmark",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "EMNLP 2024 Workshop\n  Genbench(https://genbench.org/workshop_programme/)",
    "pdf_url": "http://arxiv.org/pdf/2410.18001v2",
    "published_date": "2024-10-23 16:24:23 UTC",
    "updated_date": "2024-12-05 11:58:07 UTC"
  },
  {
    "arxiv_id": "2411.00809v3",
    "title": "Adaptive Segment-level Reward: Bridging the Gap Between Action and Reward Space in Alignment",
    "authors": [
      "Yanshi Li",
      "Shaopan Xiong",
      "Gengru Chen",
      "Xiaoyang Li",
      "Yijia Luo",
      "Xingyuan Bu",
      "Yingshui Tan",
      "Wenbo Su",
      "Bo Zheng"
    ],
    "abstract": "Reinforcement Learning (RL) has proven highly effective in aligning Large\nLanguage Models (LLMs) with human preferences. Typical RL methods optimize\nunder an overall sequence reward, which can lead to a suboptimal learning\nprocess. This reflects a key credit assignment problem: identifying which\ntokens to reinforce or suppress. To rectify these shortcomings, step-wise and\ntoken-wise methods have been proposed. However, step-wise methods rely on\npunctuation segmentation and still cannot accurately identify the key tokens.\nThe token-level approach is too fine-grained, attending to many unimportant\ntokens and thus introducing a large amount of noise. To assign more accurate\nrewards to different tokens, improving credit assignment, we propose the\n\"Adaptive Segment-wise Reward\" method. We employ semantic meaning, rather than\npunctuation, to adaptively delineate segments. Experiments demonstrate that our\nmethod can be integrated into various training methods. Compared to training\nmethods \\textit{without} our approach, our method improves the success rate on\nadversarial samples by 10\\%, and achieves a 1.3\\% improvement on evaluation\nbenchmarks such as MMLU, GSM8K, HumanEval, etc.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.00809v3",
    "published_date": "2024-10-23 16:16:15 UTC",
    "updated_date": "2025-02-25 10:42:40 UTC"
  },
  {
    "arxiv_id": "2410.17991v1",
    "title": "AI driven health recommender",
    "authors": [
      "K. Vignesh",
      "B. Pranavi",
      "Ch. Sreenidhi"
    ],
    "abstract": "As AI emerged as highest valued technology, We used that to create a web\napplication that makes a patient work easier .It detects the disease name based\non the symptoms given by the patient and recommends medication for respective\ndisease, precautions to take, diet to follow and workouts to do, so the disease\ncan be minimized. The web application is made with clean and Realtime data by\nusing Machine learning as root. We used flask to create a user-friendly\nplatform.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.17991v1",
    "published_date": "2024-10-23 16:08:00 UTC",
    "updated_date": "2024-10-23 16:08:00 UTC"
  },
  {
    "arxiv_id": "2410.17986v1",
    "title": "Federated Transformer: Multi-Party Vertical Federated Learning on Practical Fuzzily Linked Data",
    "authors": [
      "Zhaomin Wu",
      "Junyi Hou",
      "Yiqun Diao",
      "Bingsheng He"
    ],
    "abstract": "Federated Learning (FL) is an evolving paradigm that enables multiple parties\nto collaboratively train models without sharing raw data. Among its variants,\nVertical Federated Learning (VFL) is particularly relevant in real-world,\ncross-organizational collaborations, where distinct features of a shared\ninstance group are contributed by different parties. In these scenarios,\nparties are often linked using fuzzy identifiers, leading to a common practice\ntermed as multi-party fuzzy VFL. Existing models generally address either\nmulti-party VFL or fuzzy VFL between two parties. Extending these models to\npractical multi-party fuzzy VFL typically results in significant performance\ndegradation and increased costs for maintaining privacy. To overcome these\nlimitations, we introduce the Federated Transformer (FeT), a novel framework\nthat supports multi-party VFL with fuzzy identifiers. FeT innovatively encodes\nthese identifiers into data representations and employs a transformer\narchitecture distributed across different parties, incorporating three new\ntechniques to enhance performance. Furthermore, we have developed a multi-party\nprivacy framework for VFL that integrates differential privacy with secure\nmulti-party computation, effectively protecting local representations while\nminimizing associated utility costs. Our experiments demonstrate that the FeT\nsurpasses the baseline models by up to 46\\% in terms of accuracy when scaled to\n50 parties. Additionally, in two-party fuzzy VFL settings, FeT also shows\nimproved performance and privacy over cutting-edge VFL models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.17986v1",
    "published_date": "2024-10-23 16:00:14 UTC",
    "updated_date": "2024-10-23 16:00:14 UTC"
  },
  {
    "arxiv_id": "2410.17980v1",
    "title": "Stick-breaking Attention",
    "authors": [
      "Shawn Tan",
      "Yikang Shen",
      "Songlin Yang",
      "Aaron Courville",
      "Rameswar Panda"
    ],
    "abstract": "The self-attention mechanism traditionally relies on the softmax operator,\nnecessitating positional embeddings like RoPE, or position biases to account\nfor token order. But current methods using still face length generalisation\nchallenges. We propose an alternative attention mechanism based on the\nstick-breaking process: For each token before the current, we determine a break\npoint $\\beta_{i,j}$, which represents the proportion of the remaining stick to\nallocate to the current token. We repeat the process until the stick is fully\nallocated, resulting in a sequence of attention weights. This process naturally\nincorporates recency bias, which has linguistic motivations for grammar parsing\n(Shen et. al., 2017). We study the implications of replacing the conventional\nsoftmax-based attention mechanism with stick-breaking attention. We then\ndiscuss implementation of numerically stable stick-breaking attention and adapt\nFlash Attention to accommodate this mechanism. When used as a drop-in\nreplacement for current softmax+RoPE attention systems, we find that\nstick-breaking attention performs competitively with current methods on length\ngeneralisation and downstream tasks. Stick-breaking also performs well at\nlength generalisation, allowing a model trained with $2^{11}$ context window to\nperform well at $2^{14}$ with perplexity improvements.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.17980v1",
    "published_date": "2024-10-23 15:51:13 UTC",
    "updated_date": "2024-10-23 15:51:13 UTC"
  },
  {
    "arxiv_id": "2410.19865v1",
    "title": "Evaluating Deep Learning Approaches for Predictions in Unmonitored Basins with Continental-scale Stream Temperature Models",
    "authors": [
      "Jared D. Willard",
      "Fabio Ciulla",
      "Helen Weierbach",
      "Vipin Kumar",
      "Charuleka Varadharajan"
    ],
    "abstract": "The prediction of streamflows and other environmental variables in\nunmonitored basins is a grand challenge in hydrology. Recent machine learning\n(ML) models can harness vast datasets for accurate predictions at large spatial\nscales. However, there are open questions regarding model design and data\nneeded for inputs and training to improve performance. This study explores\nthese questions while demonstrating the ability of deep learning models to make\naccurate stream temperature predictions in unmonitored basins across the\nconterminous United States. First, we compare top-down models that utilize data\nfrom a large number of basins with bottom-up methods that transfer ML models\nbuilt on local sites, reflecting traditional regionalization techniques. We\nalso evaluate an intermediary grouped modeling approach that categorizes sites\nbased on regional co-location or similarity of catchment characteristics.\nSecond, we evaluate trade-offs between model complexity, prediction accuracy,\nand applicability for more target locations by systematically removing inputs.\nWe then examine model performance when additional training data becomes\navailable due to reductions in input requirements. Our results suggest that\ntop-down models significantly outperform bottom-up and grouped models.\nMoreover, it is possible to get acceptable accuracy by reducing both dynamic\nand static inputs enabling predictions for more sites with lower model\ncomplexity and computational needs. From detailed error analysis, we determined\nthat the models are more accurate for sites primarily controlled by air\ntemperatures compared to locations impacted by groundwater and dams. By\naddressing these questions, this research offers a comprehensive perspective on\noptimizing ML model design for accurate predictions in unmonitored regions.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.ao-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "47 pages, 12 figures, 7 tables, submitted to Water Resources Research",
    "pdf_url": "http://arxiv.org/pdf/2410.19865v1",
    "published_date": "2024-10-23 15:36:59 UTC",
    "updated_date": "2024-10-23 15:36:59 UTC"
  },
  {
    "arxiv_id": "2410.17971v1",
    "title": "Dynamic Spectrum Access for Ambient Backscatter Communication-assisted D2D Systems with Quantum Reinforcement Learning",
    "authors": [
      "Nguyen Van Huynh",
      "Bolun Zhang",
      "Dinh-Hieu Tran",
      "Dinh Thai Hoang",
      "Diep N. Nguyen",
      "Gan Zheng",
      "Dusit Niyato",
      "Quoc-Viet Pham"
    ],
    "abstract": "Spectrum access is an essential problem in device-to-device (D2D)\ncommunications. However, with the recent growth in the number of mobile\ndevices, the wireless spectrum is becoming scarce, resulting in low spectral\nefficiency for D2D communications. To address this problem, this paper aims to\nintegrate the ambient backscatter communication technology into D2D devices to\nallow them to backscatter ambient RF signals to transmit their data when the\nshared spectrum is occupied by mobile users. To obtain the optimal spectrum\naccess policy, i.e., stay idle or access the shared spectrum and perform active\ntransmissions or backscattering ambient RF signals for transmissions, to\nmaximize the average throughput for D2D users, deep reinforcement learning\n(DRL) can be adopted. However, DRL-based solutions may require long training\ntime due to the curse of dimensionality issue as well as complex deep neural\nnetwork architectures. For that, we develop a novel quantum reinforcement\nlearning (RL) algorithm that can achieve a faster convergence rate with fewer\ntraining parameters compared to DRL thanks to the quantum superposition and\nquantum entanglement principles. Specifically, instead of using conventional\ndeep neural networks, the proposed quantum RL algorithm uses a parametrized\nquantum circuit to approximate an optimal policy. Extensive simulations then\ndemonstrate that the proposed solution not only can significantly improve the\naverage throughput of D2D devices when the shared spectrum is busy but also can\nachieve much better performance in terms of convergence rate and learning\ncomplexity compared to existing DRL-based methods.",
    "categories": [
      "cs.NI",
      "cs.AI"
    ],
    "primary_category": "cs.NI",
    "comment": "12 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.17971v1",
    "published_date": "2024-10-23 15:36:43 UTC",
    "updated_date": "2024-10-23 15:36:43 UTC"
  },
  {
    "arxiv_id": "2410.17961v2",
    "title": "Closed-form merging of parameter-efficient modules for Federated Continual Learning",
    "authors": [
      "Riccardo Salami",
      "Pietro Buzzega",
      "Matteo Mosconi",
      "Jacopo Bonato",
      "Luigi Sabetta",
      "Simone Calderara"
    ],
    "abstract": "Model merging has emerged as a crucial technique in Deep Learning, enabling\nthe integration of multiple models into a unified system while preserving\nperfor-mance and scalability. In this respect, the compositional properties of\nlow-rank adaptation techniques (e.g., LoRA) have proven beneficial, as simple\naveraging LoRA modules yields a single model that mostly integrates the\ncapabilities of all individual modules. Building on LoRA, we take a step\nfurther by imposing that the merged model matches the responses of all learned\nmodules. Solving this objective in closed form yields an indeterminate system\nwith A and B as unknown variables, indicating the existence of infinitely many\nclosed-form solutions. To address this challenge, we introduce LoRM, an\nalternating optimization strategy that trains one LoRA matrix at a time. This\nallows solving for each unknown variable individually, thus finding a unique\nsolution. We apply our proposed methodology to Federated Class-Incremental\nLearning (FCIL), ensuring alignment of model responses both between clients and\nacross tasks. Our method demonstrates state-of-the-art performance across a\nrange of FCIL scenarios. The code to reproduce our experiments is available at\ngithub.com/aimagelab/fed-mammoth.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.17961v2",
    "published_date": "2024-10-23 15:30:13 UTC",
    "updated_date": "2025-03-08 17:15:08 UTC"
  },
  {
    "arxiv_id": "2410.17957v1",
    "title": "MCUBERT: Memory-Efficient BERT Inference on Commodity Microcontrollers",
    "authors": [
      "Zebin Yang",
      "Renze Chen",
      "Taiqiang Wu",
      "Ngai Wong",
      "Yun Liang",
      "Runsheng Wang",
      "Ru Huang",
      "Meng Li"
    ],
    "abstract": "In this paper, we propose MCUBERT to enable language models like BERT on tiny\nmicrocontroller units (MCUs) through network and scheduling co-optimization. We\nobserve the embedding table contributes to the major storage bottleneck for\ntiny BERT models. Hence, at the network level, we propose an MCU-aware\ntwo-stage neural architecture search algorithm based on clustered low-rank\napproximation for embedding compression. To reduce the inference memory\nrequirements, we further propose a novel fine-grained MCU-friendly scheduling\nstrategy. Through careful computation tiling and re-ordering as well as kernel\ndesign, we drastically increase the input sequence lengths supported on MCUs\nwithout any latency or accuracy penalty. MCUBERT reduces the parameter size of\nBERT-tiny and BERT-mini by 5.7$\\times$ and 3.0$\\times$ and the execution memory\nby 3.5$\\times$ and 4.3$\\times$, respectively. MCUBERT also achieves 1.5$\\times$\nlatency reduction. For the first time, MCUBERT enables lightweight BERT models\non commodity MCUs and processing more than 512 tokens with less than 256KB of\nmemory.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "ICCAD 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.17957v1",
    "published_date": "2024-10-23 15:27:37 UTC",
    "updated_date": "2024-10-23 15:27:37 UTC"
  },
  {
    "arxiv_id": "2410.17954v1",
    "title": "ExpertFlow: Optimized Expert Activation and Token Allocation for Efficient Mixture-of-Experts Inference",
    "authors": [
      "Xin He",
      "Shunkang Zhang",
      "Yuxin Wang",
      "Haiyan Yin",
      "Zihao Zeng",
      "Shaohuai Shi",
      "Zhenheng Tang",
      "Xiaowen Chu",
      "Ivor Tsang",
      "Ong Yew Soon"
    ],
    "abstract": "Sparse Mixture of Experts (MoE) models, while outperforming dense Large\nLanguage Models (LLMs) in terms of performance, face significant deployment\nchallenges during inference due to their high memory demands. Existing\noffloading techniques, which involve swapping activated and idle experts\nbetween the GPU and CPU, often suffer from rigid expert caching mechanisms.\nThese mechanisms fail to adapt to dynamic routing, leading to inefficient cache\nutilization, or incur prohibitive costs for prediction training. To tackle\nthese inference-specific challenges, we introduce ExpertFlow, a comprehensive\nsystem specifically designed to enhance inference efficiency by accommodating\nflexible routing and enabling efficient expert scheduling between CPU and GPU.\nThis reduces overhead and boosts system performance. Central to our approach is\na predictive routing path-based offloading mechanism that utilizes a\nlightweight predictor to accurately forecast routing paths before computation\nbegins. This proactive strategy allows for real-time error correction in expert\ncaching, significantly increasing cache hit ratios and reducing the frequency\nof expert transfers, thereby minimizing I/O overhead. Additionally, we\nimplement a dynamic token scheduling strategy that optimizes MoE inference by\nrearranging input tokens across different batches. This method not only reduces\nthe number of activated experts per batch but also improves computational\nefficiency. Our extensive experiments demonstrate that ExpertFlow achieves up\nto 93.72\\% GPU memory savings and enhances inference speed by 2 to 10 times\ncompared to baseline methods, highlighting its effectiveness and utility as a\nrobust solution for resource-constrained inference scenarios.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "Mixture-of-Experts, Inference, Offloading",
    "pdf_url": "http://arxiv.org/pdf/2410.17954v1",
    "published_date": "2024-10-23 15:24:54 UTC",
    "updated_date": "2024-10-23 15:24:54 UTC"
  },
  {
    "arxiv_id": "2410.17952v2",
    "title": "SimRAG: Self-Improving Retrieval-Augmented Generation for Adapting Large Language Models to Specialized Domains",
    "authors": [
      "Ran Xu",
      "Hui Liu",
      "Sreyashi Nag",
      "Zhenwei Dai",
      "Yaochen Xie",
      "Xianfeng Tang",
      "Chen Luo",
      "Yang Li",
      "Joyce C. Ho",
      "Carl Yang",
      "Qi He"
    ],
    "abstract": "Retrieval-augmented generation (RAG) enhances the question-answering (QA)\nabilities of large language models (LLMs) by integrating external knowledge.\nHowever, adapting general-purpose RAG systems to specialized fields such as\nscience and medicine poses unique challenges due to distribution shifts and\nlimited access to domain-specific data. To tackle this, we propose SimRAG, a\nself-training approach that equips the LLM with joint capabilities of question\nanswering and question generation for domain adaptation. Our method first\nfine-tunes the LLM on instruction-following, question-answering, and\nsearch-related data. Then, it prompts the same LLM to generate diverse\ndomain-relevant questions from unlabeled corpora, with an additional filtering\nstrategy to retain high-quality synthetic examples. By leveraging these\nself-generated synthetic examples, the LLM can improve their performance on\ndomain-specific RAG tasks. Experiments on 11 datasets, spanning two backbone\nsizes and three domains, demonstrate that SimRAG outperforms baselines by\n1.2\\%--8.6\\%.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to NAACL 2025 main conference",
    "pdf_url": "http://arxiv.org/pdf/2410.17952v2",
    "published_date": "2024-10-23 15:24:16 UTC",
    "updated_date": "2025-01-24 23:45:11 UTC"
  },
  {
    "arxiv_id": "2410.17950v1",
    "title": "Benchmarking Floworks against OpenAI & Anthropic: A Novel Framework for Enhanced LLM Function Calling",
    "authors": [
      "Nirav Bhan",
      "Shival Gupta",
      "Sai Manaswini",
      "Ritik Baba",
      "Narun Yadav",
      "Hillori Desai",
      "Yash Choudhary",
      "Aman Pawar",
      "Sarthak Shrivastava",
      "Sudipta Biswas"
    ],
    "abstract": "Large Language Models (LLMs) have shown remarkable capabilities in various\ndomains, yet their economic impact has been limited by challenges in tool use\nand function calling. This paper introduces ThorV2, a novel architecture that\nsignificantly enhances LLMs' function calling abilities. We develop a\ncomprehensive benchmark focused on HubSpot CRM operations to evaluate ThorV2\nagainst leading models from OpenAI and Anthropic. Our results demonstrate that\nThorV2 outperforms existing models in accuracy, reliability, latency, and cost\nefficiency for both single and multi-API calling tasks. We also show that\nThorV2 is far more reliable and scales better to multistep tasks compared to\ntraditional models. Our work offers the tantalizing possibility of more\naccurate function-calling compared to today's best-performing models using\nsignificantly smaller LLMs. These advancements have significant implications\nfor the development of more capable AI assistants and the broader application\nof LLMs in real-world scenarios.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "15 pages for main paper, 21 pages in total including references and\n  appendix, 10 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.17950v1",
    "published_date": "2024-10-23 15:23:23 UTC",
    "updated_date": "2024-10-23 15:23:23 UTC"
  },
  {
    "arxiv_id": "2410.17943v1",
    "title": "Optimizing Travel Itineraries with AI Algorithms in a Microservices Architecture: Balancing Cost, Time, Preferences, and Sustainability",
    "authors": [
      "Biman Barua",
      "M. Shamim Kaiser"
    ],
    "abstract": "The objective of this research is how an implementation of AI algorithms in\nthe microservices architecture enhances travel itineraries by cost, time, user\npreferences, and environmental sustainability. It uses machine learning models\nfor both cost forecasting and personalization, genetic algorithm for\noptimization of the itinerary, and heuristics for sustainability checking.\nPrimary evaluated parameters consist of latency, ability to satisfy user\npreferences, cost and environmental concern. The experimental results\ndemonstrate an average of 4.5 seconds of response time on 1000 concurrent users\nand 92% of user preferences accuracy. The cost efficiency is proved, with 95%\nof provided trips being within the limits of the budget declared by the user.\nThe system also implements some measures to alleviate negative externalities\nrelated to travel and 60% of offered travel plans had green options\nincorporated, resulting in the average 15% lower carbon emissions than the\ntraditional travel plans offered. The genetic algorithm with time complexity\nO(g.p.f) provides the optimal solution in 100 generations. Every iteration\nimproves the quality of the solution by 5%, thus enabling its effective use in\noptimization problems where time is measured in seconds. Finally, the system is\ndesigned to be fault-tolerant with functional 99.9% availability which allows\nthe provision of services even when requirements are exceeded. Travel\noptimization platform is turned dynamic and efficient by this microservices\nbased architecture which provides enhanced scaling, allows asynchronous\ncommunication and real time changes. Because of the incorporation of Ai, cost\ncontrol and eco-friendliness approaches, the system addresses the different\nuser needs in the present days travel business.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.SE",
    "comment": "18 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.17943v1",
    "published_date": "2024-10-23 15:15:56 UTC",
    "updated_date": "2024-10-23 15:15:56 UTC"
  },
  {
    "arxiv_id": "2410.17933v1",
    "title": "Multi-Continental Healthcare Modelling Using Blockchain-Enabled Federated Learning",
    "authors": [
      "Rui Sun",
      "Zhipeng Wang",
      "Hengrui Zhang",
      "Ming Jiang",
      "Yizhe Wen",
      "Jiqun Zhang",
      "Jiahao Sun",
      "Shuoying Zhang",
      "Erwu Liu",
      "Kezhi Li"
    ],
    "abstract": "One of the biggest challenges of building artificial intelligence (AI) model\nin healthcare area is the data sharing. Since healthcare data is private,\nsensitive, and heterogeneous, collecting sufficient data for modelling is\nexhausted, costly, and sometimes impossible. In this paper, we propose a\nframework for global healthcare modelling using datasets from multi-continents\n(Europe, North America and Asia) while without sharing the local datasets, and\nchoose glucose management as a study model to verify its effectiveness.\nTechnically, blockchain-enabled federated learning is implemented with adaption\nto make it meet with the privacy and safety requirements of healthcare data,\nmeanwhile rewards honest participation and penalize malicious activities using\nits on-chain incentive mechanism. Experimental results show that the proposed\nframework is effective, efficient, and privacy preserved. Its prediction\naccuracy is much better than the models trained from limited personal data and\nis similar to, and even slightly better than, the results from a centralized\ndataset. This work paves the way for international collaborations on healthcare\nprojects, where additional data is crucial for reducing bias and providing\nbenefits to humanity.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by IEEE Global Blockchain Conference",
    "pdf_url": "http://arxiv.org/pdf/2410.17933v1",
    "published_date": "2024-10-23 14:55:53 UTC",
    "updated_date": "2024-10-23 14:55:53 UTC"
  },
  {
    "arxiv_id": "2410.17922v2",
    "title": "Dynamic Guided and Domain Applicable Safeguards for Enhanced Security in Large Language Models",
    "authors": [
      "Weidi Luo",
      "He Cao",
      "Zijing Liu",
      "Yu Wang",
      "Aidan Wong",
      "Bing Feng",
      "Yuan Yao",
      "Yu Li"
    ],
    "abstract": "With the extensive deployment of Large Language Models (LLMs), ensuring their\nsafety has become increasingly critical. However, existing defense methods\noften struggle with two key issues: (i) inadequate defense capabilities,\nparticularly in domain-specific scenarios like chemistry, where a lack of\nspecialized knowledge can lead to the generation of harmful responses to\nmalicious queries. (ii) over-defensiveness, which compromises the general\nutility and responsiveness of LLMs. To mitigate these issues, we introduce a\nmulti-agents-based defense framework, Guide for Defense (G4D), which leverages\naccurate external information to provide an unbiased summary of user intentions\nand analytically grounded safety response guidance. Extensive experiments on\npopular jailbreak attacks and benign datasets show that our G4D can enhance\nLLM's robustness against jailbreak attacks on general and domain-specific\nscenarios without compromising the model's general functionality.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.17922v2",
    "published_date": "2024-10-23 14:40:37 UTC",
    "updated_date": "2025-02-09 03:34:47 UTC"
  },
  {
    "arxiv_id": "2410.17918v1",
    "title": "Addressing Asynchronicity in Clinical Multimodal Fusion via Individualized Chest X-ray Generation",
    "authors": [
      "Wenfang Yao",
      "Chen Liu",
      "Kejing Yin",
      "William K. Cheung",
      "Jing Qin"
    ],
    "abstract": "Integrating multi-modal clinical data, such as electronic health records\n(EHR) and chest X-ray images (CXR), is particularly beneficial for clinical\nprediction tasks. However, in a temporal setting, multi-modal data are often\ninherently asynchronous. EHR can be continuously collected but CXR is generally\ntaken with a much longer interval due to its high cost and radiation dose. When\nclinical prediction is needed, the last available CXR image might have been\noutdated, leading to suboptimal predictions. To address this challenge, we\npropose DDL-CXR, a method that dynamically generates an up-to-date latent\nrepresentation of the individualized CXR images. Our approach leverages latent\ndiffusion models for patient-specific generation strategically conditioned on a\nprevious CXR image and EHR time series, providing information regarding\nanatomical structures and disease progressions, respectively. In this way, the\ninteraction across modalities could be better captured by the latent CXR\ngeneration process, ultimately improving the prediction performance.\nExperiments using MIMIC datasets show that the proposed model could effectively\naddress asynchronicity in multimodal fusion and consistently outperform\nexisting methods.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by NeurIPS-24",
    "pdf_url": "http://arxiv.org/pdf/2410.17918v1",
    "published_date": "2024-10-23 14:34:39 UTC",
    "updated_date": "2024-10-23 14:34:39 UTC"
  },
  {
    "arxiv_id": "2410.17906v1",
    "title": "Leveraging Deep Learning for Time Series Extrinsic Regression in predicting photometric metallicity of Fundamental-mode RR Lyrae Stars",
    "authors": [
      "Lorenzo Monti",
      "Tatiana Muraveva",
      "Gisella Clementini",
      "Alessia Garofalo"
    ],
    "abstract": "Astronomy is entering an unprecedented era of Big Data science, driven by\nmissions like the ESA's Gaia telescope, which aims to map the Milky Way in\nthree dimensions. Gaia's vast dataset presents a monumental challenge for\ntraditional analysis methods. The sheer scale of this data exceeds the\ncapabilities of manual exploration, necessitating the utilization of advanced\ncomputational techniques. In response to this challenge, we developed a novel\napproach leveraging deep learning to estimate the metallicity of fundamental\nmode (ab-type) RR Lyrae stars from their light curves in the Gaia optical\nG-band. Our study explores applying deep learning techniques, particularly\nadvanced neural network architectures, in predicting photometric metallicity\nfrom time-series data. Our deep learning models demonstrated notable predictive\nperformance, with a low mean absolute error (MAE) of 0.0565, the root mean\nsquare error (RMSE) achieved is 0.0765 and a high $R^2$ regression performance\nof 0.9401 measured by cross-validation. The weighted mean absolute error (wMAE)\nis 0.0563, while the weighted root mean square error (wRMSE) is 0.0763. These\nresults showcase the effectiveness of our approach in accurately estimating\nmetallicity values. Our work underscores the importance of deep learning in\nastronomical research, particularly with large datasets from missions like\nGaia. By harnessing the power of deep learning methods, we can provide\nprecision in analyzing vast datasets, contributing to more precise and\ncomprehensive insights into complex astronomical phenomena.",
    "categories": [
      "cs.AI",
      "astro-ph.IM"
    ],
    "primary_category": "cs.AI",
    "comment": "Sensors 2024, 24(16), 5203; (23 pages)",
    "pdf_url": "http://arxiv.org/pdf/2410.17906v1",
    "published_date": "2024-10-23 14:26:35 UTC",
    "updated_date": "2024-10-23 14:26:35 UTC"
  },
  {
    "arxiv_id": "2410.17904v1",
    "title": "Reinforcement Learning under Latent Dynamics: Toward Statistical and Algorithmic Modularity",
    "authors": [
      "Philip Amortila",
      "Dylan J. Foster",
      "Nan Jiang",
      "Akshay Krishnamurthy",
      "Zakaria Mhammedi"
    ],
    "abstract": "Real-world applications of reinforcement learning often involve environments\nwhere agents operate on complex, high-dimensional observations, but the\nunderlying (''latent'') dynamics are comparatively simple. However, outside of\nrestrictive settings such as small latent spaces, the fundamental statistical\nrequirements and algorithmic principles for reinforcement learning under latent\ndynamics are poorly understood.\n  This paper addresses the question of reinforcement learning under\n$\\textit{general}$ latent dynamics from a statistical and algorithmic\nperspective. On the statistical side, our main negative result shows that most\nwell-studied settings for reinforcement learning with function approximation\nbecome intractable when composed with rich observations; we complement this\nwith a positive result, identifying latent pushforward coverability as a\ngeneral condition that enables statistical tractability. Algorithmically, we\ndevelop provably efficient observable-to-latent reductions -- that is,\nreductions that transform an arbitrary algorithm for the latent MDP into an\nalgorithm that can operate on rich observations -- in two settings: one where\nthe agent has access to hindsight observations of the latent dynamics [LADZ23],\nand one where the agent can estimate self-predictive latent models [SAGHCB20].\nTogether, our results serve as a first step toward a unified statistical and\nalgorithmic theory for reinforcement learning under latent dynamics.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.17904v1",
    "published_date": "2024-10-23 14:22:49 UTC",
    "updated_date": "2024-10-23 14:22:49 UTC"
  },
  {
    "arxiv_id": "2410.17885v2",
    "title": "R-CoT: Reverse Chain-of-Thought Problem Generation for Geometric Reasoning in Large Multimodal Models",
    "authors": [
      "Linger Deng",
      "Yuliang Liu",
      "Bohan Li",
      "Dongliang Luo",
      "Liang Wu",
      "Chengquan Zhang",
      "Pengyuan Lyu",
      "Ziyang Zhang",
      "Gang Zhang",
      "Errui Ding",
      "Yingying Zhu",
      "Xiang Bai"
    ],
    "abstract": "Existing Large Multimodal Models (LMMs) struggle with mathematical geometric\nreasoning due to a lack of high-quality image-text paired data. Current\ngeometric data generation approaches, which apply preset templates to generate\ngeometric data or use Large Language Models (LLMs) to rephrase questions and\nanswers (Q&A), unavoidably limit data accuracy and diversity. To synthesize\nhigher-quality data, we propose a two-stage Reverse Chain-of-Thought (R-CoT)\ngeometry problem generation pipeline. First, we introduce GeoChain to produce\nhigh-fidelity geometric images and corresponding descriptions highlighting\nrelations among geometric elements. We then design a Reverse A&Q method that\nreasons step-by-step based on the descriptions and generates questions in\nreverse from the reasoning results. Experiments demonstrate that the proposed\nmethod brings significant and consistent improvements on multiple LMM\nbaselines, achieving new performance records in the 2B, 7B, and 8B settings.\nNotably, R-CoT-8B significantly outperforms previous state-of-the-art\nopen-source mathematical models by 16.6% on MathVista and 9.2% on GeoQA, while\nalso surpassing the closed-source model GPT-4o by an average of 13% across both\ndatasets. The code is available at https://github.com/dle666/R-CoT.",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.17885v2",
    "published_date": "2024-10-23 13:58:39 UTC",
    "updated_date": "2024-10-27 09:02:01 UTC"
  },
  {
    "arxiv_id": "2410.17883v2",
    "title": "Lightweight Neural App Control",
    "authors": [
      "Filippos Christianos",
      "Georgios Papoudakis",
      "Thomas Coste",
      "Jianye Hao",
      "Jun Wang",
      "Kun Shao"
    ],
    "abstract": "This paper introduces a novel mobile phone control architecture, Lightweight\nMulti-modal App Control (LiMAC), for efficient interactions and control across\nvarious Android apps. LiMAC takes as input a textual goal and a sequence of\npast mobile observations, such as screenshots and corresponding UI trees, to\ngenerate precise actions. To address the computational constraints inherent to\nsmartphones, we introduce a small Action Transformer (AcT) integrated with a\nfine-tuned vision-language model (VLM) for real-time decision-making and task\nexecution. We evaluate LiMAC on two open-source mobile control datasets,\ndemonstrating the superior performance of our small-form-factor approach\nagainst fine-tuned versions of open-source VLMs, such as Florence2 and\nQwen2-VL. It also significantly outperforms prompt engineering baselines\nutilising closed-source foundation models like GPT-4o. More specifically, LiMAC\nincreases the overall action accuracy by up to 19% compared to fine-tuned VLMs,\nand up to 42% compared to prompt-engineering baselines.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "ICLR 2025 (spotlight)",
    "pdf_url": "http://arxiv.org/pdf/2410.17883v2",
    "published_date": "2024-10-23 13:57:00 UTC",
    "updated_date": "2025-02-12 17:51:51 UTC"
  },
  {
    "arxiv_id": "2410.17875v3",
    "title": "Understanding Layer Significance in LLM Alignment",
    "authors": [
      "Guangyuan Shi",
      "Zexin Lu",
      "Xiaoyu Dong",
      "Wenlong Zhang",
      "Xuanyu Zhang",
      "Yujie Feng",
      "Xiao-Ming Wu"
    ],
    "abstract": "Aligning large language models (LLMs) through supervised fine-tuning is\nessential for tailoring them to specific applications. Recent studies suggest\nthat alignment primarily adjusts a model's presentation style rather than its\nfoundational knowledge, indicating that only certain components of the model\nare significantly impacted. To uncover how alignment affects model behavior at\na granular level, we propose identifying which layers within LLMs are most\ncritical to the alignment process. Our approach, named ILA, involves learning a\nbinary mask for the parameter changes in each layer during alignment, as an\nindicator of layer significance. Experimental results reveal that, despite\nsubstantial differences in alignment datasets, the important layers of a model\nidentified by ILA exhibit nearly 90\\% overlap, highlighting fundamental\npatterns in LLM alignment. The results also indicate that freezing\nnon-essential layers improves overall model performance, while selectively\ntuning the most critical layers significantly enhances fine-tuning efficiency\nwith minimal performance loss. Finally, we discuss how these findings extend\nfrom LLM alignment to reasoning.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.17875v3",
    "published_date": "2024-10-23 13:47:05 UTC",
    "updated_date": "2025-04-08 09:44:28 UTC"
  },
  {
    "arxiv_id": "2411.05013v1",
    "title": "Enhancing literature review with LLM and NLP methods. Algorithmic trading case",
    "authors": [
      "Stanisław Łaniewski",
      "Robert Ślepaczuk"
    ],
    "abstract": "This study utilizes machine learning algorithms to analyze and organize\nknowledge in the field of algorithmic trading. By filtering a dataset of 136\nmillion research papers, we identified 14,342 relevant articles published\nbetween 1956 and Q1 2020. We compare traditional practices-such as\nkeyword-based algorithms and embedding techniques-with state-of-the-art topic\nmodeling methods that employ dimensionality reduction and clustering. This\ncomparison allows us to assess the popularity and evolution of different\napproaches and themes within algorithmic trading. We demonstrate the usefulness\nof Natural Language Processing (NLP) in the automatic extraction of knowledge,\nhighlighting the new possibilities created by the latest iterations of Large\nLanguage Models (LLMs) like ChatGPT. The rationale for focusing on this topic\nstems from our analysis, which reveals that research articles on algorithmic\ntrading are increasing at a faster rate than the overall number of\npublications. While stocks and main indices comprise more than half of all\nassets considered, certain asset classes, such as cryptocurrencies, exhibit a\nmuch stronger growth trend. Machine learning models have become the most\npopular methods in recent years. The study demonstrates the efficacy of LLMs in\nrefining datasets and addressing intricate questions about the analyzed\narticles, such as comparing the efficiency of different models. Our research\nshows that by decomposing tasks into smaller components and incorporating\nreasoning steps, we can effectively tackle complex questions supported by case\nanalyses. This approach contributes to a deeper understanding of algorithmic\ntrading methodologies and underscores the potential of advanced NLP techniques\nin literature reviews.",
    "categories": [
      "q-fin.ST",
      "cs.AI",
      "cs.LG",
      "q-fin.TR"
    ],
    "primary_category": "q-fin.ST",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.05013v1",
    "published_date": "2024-10-23 13:37:27 UTC",
    "updated_date": "2024-10-23 13:37:27 UTC"
  },
  {
    "arxiv_id": "2410.17859v1",
    "title": "DataTales: A Benchmark for Real-World Intelligent Data Narration",
    "authors": [
      "Yajing Yang",
      "Qian Liu",
      "Min-Yen Kan"
    ],
    "abstract": "We introduce DataTales, a novel benchmark designed to assess the proficiency\nof language models in data narration, a task crucial for transforming complex\ntabular data into accessible narratives. Existing benchmarks often fall short\nin capturing the requisite analytical complexity for practical applications.\nDataTales addresses this gap by offering 4.9k financial reports paired with\ncorresponding market data, showcasing the demand for models to create clear\nnarratives and analyze large datasets while understanding specialized\nterminology in the field. Our findings highlights the significant challenge\nthat language models face in achieving the necessary precision and analytical\ndepth for proficient data narration, suggesting promising avenues for future\nmodel development and evaluation methodologies.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.17859v1",
    "published_date": "2024-10-23 13:30:02 UTC",
    "updated_date": "2024-10-23 13:30:02 UTC"
  },
  {
    "arxiv_id": "2410.17856v3",
    "title": "ROCKET-1: Mastering Open-World Interaction with Visual-Temporal Context Prompting",
    "authors": [
      "Shaofei Cai",
      "Zihao Wang",
      "Kewei Lian",
      "Zhancun Mu",
      "Xiaojian Ma",
      "Anji Liu",
      "Yitao Liang"
    ],
    "abstract": "Vision-language models (VLMs) have excelled in multimodal tasks, but adapting\nthem to embodied decision-making in open-world environments presents\nchallenges. One critical issue is bridging the gap between discrete entities in\nlow-level observations and the abstract concepts required for effective\nplanning. A common solution is building hierarchical agents, where VLMs serve\nas high-level reasoners that break down tasks into executable sub-tasks,\ntypically specified using language. However, language suffers from the\ninability to communicate detailed spatial information. We propose\nvisual-temporal context prompting, a novel communication protocol between VLMs\nand policy models. This protocol leverages object segmentation from past\nobservations to guide policy-environment interactions. Using this approach, we\ntrain ROCKET-1, a low-level policy that predicts actions based on concatenated\nvisual observations and segmentation masks, supported by real-time object\ntracking from SAM-2. Our method unlocks the potential of VLMs, enabling them to\ntackle complex tasks that demand spatial reasoning. Experiments in Minecraft\nshow that our approach enables agents to achieve previously unattainable tasks,\nwith a $\\mathbf{76}\\%$ absolute improvement in open-world interaction\nperformance. Codes and demos are now available on the project page:\nhttps://craftjarvis.github.io/ROCKET-1.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.17856v3",
    "published_date": "2024-10-23 13:26:59 UTC",
    "updated_date": "2025-03-20 11:55:54 UTC"
  },
  {
    "arxiv_id": "2410.17855v1",
    "title": "TAGE: Trustworthy Attribute Group Editing for Stable Few-shot Image Generation",
    "authors": [
      "Ruicheng Zhang",
      "Guoheng Huang",
      "Yejing Huo",
      "Xiaochen Yuan",
      "Zhizhen Zhou",
      "Xuhang Chen",
      "Guo Zhong"
    ],
    "abstract": "Generative Adversarial Networks (GANs) have emerged as a prominent research\nfocus for image editing tasks, leveraging the powerful image generation\ncapabilities of the GAN framework to produce remarkable results.However,\nprevailing approaches are contingent upon extensive training datasets and\nexplicit supervision, presenting a significant challenge in manipulating the\ndiverse attributes of new image classes with limited sample availability. To\nsurmount this hurdle, we introduce TAGE, an innovative image generation network\ncomprising three integral modules: the Codebook Learning Module (CLM), the Code\nPrediction Module (CPM) and the Prompt-driven Semantic Module (PSM). The CPM\nmodule delves into the semantic dimensions of category-agnostic attributes,\nencapsulating them within a discrete codebook. This module is predicated on the\nconcept that images are assemblages of attributes, and thus, by editing these\ncategory-independent attributes, it is theoretically possible to generate\nimages from unseen categories. Subsequently, the CPM module facilitates\nnaturalistic image editing by predicting indices of category-independent\nattribute vectors within the codebook. Additionally, the PSM module generates\nsemantic cues that are seamlessly integrated into the Transformer architecture\nof the CPM, enhancing the model's comprehension of the targeted attributes for\nediting. With these semantic cues, the model can generate images that\naccentuate desired attributes more prominently while maintaining the integrity\nof the original category, even with a limited number of samples. We have\nconducted extensive experiments utilizing the Animal Faces, Flowers, and\nVGGFaces datasets. The results of these experiments demonstrate that our\nproposed method not only achieves superior performance but also exhibits a high\ndegree of stability when compared to other few-shot image generation\ntechniques.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by International Conference on Signal Processing Systems\n  Conference",
    "pdf_url": "http://arxiv.org/pdf/2410.17855v1",
    "published_date": "2024-10-23 13:26:19 UTC",
    "updated_date": "2024-10-23 13:26:19 UTC"
  },
  {
    "arxiv_id": "2410.17851v2",
    "title": "The Probabilistic Tsetlin Machine: A Novel Approach to Uncertainty Quantification",
    "authors": [
      "K. Darshana Abeyrathna",
      "Sara El Mekkaoui",
      "Andreas Hafver",
      "Christian Agrell"
    ],
    "abstract": "Tsetlin Machines (TMs) have emerged as a compelling alternative to\nconventional deep learning methods, offering notable advantages such as smaller\nmemory footprint, faster inference, fault-tolerant properties, and\ninterpretability. Although various adaptations of TMs have expanded their\napplicability across diverse domains, a fundamental gap remains in\nunderstanding how TMs quantify uncertainty in their predictions. In response,\nthis paper introduces the Probabilistic Tsetlin Machine (PTM) framework, aimed\nat providing a robust, reliable, and interpretable approach for uncertainty\nquantification. Unlike the original TM, the PTM learns the probability of\nstaying on each state of each Tsetlin Automaton (TA) across all clauses. These\nprobabilities are updated using the feedback tables that are part of the TM\nframework: Type I and Type II feedback. During inference, TAs decide their\nactions by sampling states based on learned probability distributions, akin to\nBayesian neural networks when generating weight values. In our experimental\nanalysis, we first illustrate the spread of the probabilities across TA states\nfor the noisy-XOR dataset. Then we evaluate the PTM alongside benchmark models\nusing both simulated and real-world datasets. The experiments on the simulated\ndataset reveal the PTM's effectiveness in uncertainty quantification,\nparticularly in delineating decision boundaries and identifying regions of high\nuncertainty. Moreover, when applied to multiclass classification tasks using\nthe Iris dataset, the PTM demonstrates competitive performance in terms of\npredictive entropy and expected calibration error, showcasing its potential as\na reliable tool for uncertainty estimation. Our findings underscore the\nimportance of selecting appropriate models for accurate uncertainty\nquantification in predictive tasks, with the PTM offering a particularly\ninterpretable and effective solution.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "12 pages, 5 figures, 6 tables, accepted and presented at ICAAI 2024,\n  London",
    "pdf_url": "http://arxiv.org/pdf/2410.17851v2",
    "published_date": "2024-10-23 13:20:42 UTC",
    "updated_date": "2024-11-13 10:01:38 UTC"
  },
  {
    "arxiv_id": "2410.17827v1",
    "title": "RE-tune: Incremental Fine Tuning of Biomedical Vision-Language Models for Multi-label Chest X-ray Classification",
    "authors": [
      "Marco Mistretta",
      "Andrew D. Bagdanov"
    ],
    "abstract": "In this paper we introduce RE-tune, a novel approach for fine-tuning\npre-trained Multimodal Biomedical Vision-Language models (VLMs) in Incremental\nLearning scenarios for multi-label chest disease diagnosis. RE-tune freezes the\nbackbones and only trains simple adaptors on top of the Image and Text encoders\nof the VLM. By engineering positive and negative text prompts for diseases, we\nleverage the ability of Large Language Models to steer the training trajectory.\nWe evaluate RE-tune in three realistic incremental learning scenarios:\nclass-incremental, label-incremental, and data-incremental. Our results\ndemonstrate that Biomedical VLMs are natural continual learners and prevent\ncatastrophic forgetting. RE-tune not only achieves accurate multi-label\nclassification results, but also prioritizes patient privacy and it\ndistinguishes itself through exceptional computational efficiency, rendering it\nhighly suitable for broad adoption in real-world healthcare settings.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted for publication at Medical Imaging meets NeurIPS (NeurIPS23)",
    "pdf_url": "http://arxiv.org/pdf/2410.17827v1",
    "published_date": "2024-10-23 12:40:33 UTC",
    "updated_date": "2024-10-23 12:40:33 UTC"
  },
  {
    "arxiv_id": "2410.17812v1",
    "title": "PGDiffSeg: Prior-Guided Denoising Diffusion Model with Parameter-Shared Attention for Breast Cancer Segmentation",
    "authors": [
      "Feiyan Feng",
      "Tianyu Liu",
      "Hong Wang",
      "Jun Zhao",
      "Wei Li",
      "Yanshen Sun"
    ],
    "abstract": "Early detection through imaging and accurate diagnosis is crucial in\nmitigating the high mortality rate associated with breast cancer. However,\nlocating tumors from low-resolution and high-noise medical images is extremely\nchallenging. Therefore, this paper proposes a novel PGDiffSeg (Prior-Guided\nDiffusion Denoising Model with Parameter-Shared Attention) that applies\ndiffusion denoising methods to breast cancer medical image segmentation,\naccurately recovering the affected areas from Gaussian noise. Firstly, we\ndesign a parallel pipeline for noise processing and semantic information\nprocessing and propose a parameter-shared attention module (PSA) in multi-layer\nthat seamlessly integrates these two pipelines. This integration empowers\nPGDiffSeg to incorporate semantic details at multiple levels during the\ndenoising process, producing highly accurate segmentation maps. Secondly, we\nintroduce a guided strategy that leverages prior knowledge to simulate the\ndecision-making process of medical professionals, thereby enhancing the model's\nability to locate tumor positions precisely. Finally, we provide the first-ever\ndiscussion on the interpretability of the generative diffusion model in the\ncontext of breast cancer segmentation. Extensive experiments have demonstrated\nthe superiority of our model over the current state-of-the-art approaches,\nconfirming its effectiveness as a flexible diffusion denoising method suitable\nfor medical image research. Our code will be publicly available later.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.17812v1",
    "published_date": "2024-10-23 12:17:03 UTC",
    "updated_date": "2024-10-23 12:17:03 UTC"
  },
  {
    "arxiv_id": "2410.17799v2",
    "title": "OmniFlatten: An End-to-end GPT Model for Seamless Voice Conversation",
    "authors": [
      "Qinglin Zhang",
      "Luyao Cheng",
      "Chong Deng",
      "Qian Chen",
      "Wen Wang",
      "Siqi Zheng",
      "Jiaqing Liu",
      "Hai Yu",
      "Chaohong Tan",
      "Zhihao Du",
      "Shiliang Zhang"
    ],
    "abstract": "Full-duplex spoken dialogue systems significantly surpass traditional\nturn-based dialogue systems, as they allow simultaneous bidirectional\ncommunication, closely mirroring human-human interactions. However, achieving\nlow latency and natural interactions in full-duplex dialogue systems remains a\nsignificant challenge, especially considering human conversation dynamics such\nas interruptions, backchannels, and overlapping speech. In this paper, we\nintroduce a novel End-to-End GPT-based model OmniFlatten for full-duplex\nconversation, capable of effectively modeling the complex behaviors inherent to\nnatural conversations with low latency. To achieve full-duplex conversation\ncapabilities, we propose a multi-stage post-training scheme that progressively\nadapts a text large language model (LLM) backbone into a speech-text dialogue\nLLM, capable of generating text and speech in real time, without modifying the\narchitecture of the backbone LLM. The training process comprises three stages:\nmodality alignment, half-duplex dialogue learning, and full-duplex dialogue\nlearning. In all training stages, we standardize the data using a flattening\noperation, which enables unifying the training methods and the GPT backbone\nacross different modalities and tasks. Our approach offers a simple modeling\ntechnique and a promising research direction for developing efficient and\nnatural end-to-end full-duplex spoken dialogue systems. Audio samples of\ndialogues generated by OmniFlatten can be found at this web site\n(https://omniflatten.github.io/).",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL",
    "comment": "Work in progress",
    "pdf_url": "http://arxiv.org/pdf/2410.17799v2",
    "published_date": "2024-10-23 11:58:58 UTC",
    "updated_date": "2025-01-03 06:15:58 UTC"
  },
  {
    "arxiv_id": "2410.17792v1",
    "title": "Enhancing Federated Learning Convergence with Dynamic Data Queue and Data Entropy-driven Participant Selection",
    "authors": [
      "Charuka Herath",
      "Xiaolan Liu",
      "Sangarapillai Lambotharan",
      "Yogachandran Rahulamathavan"
    ],
    "abstract": "Federated Learning (FL) is a decentralized approach for collaborative model\ntraining on edge devices. This distributed method of model training offers\nadvantages in privacy, security, regulatory compliance, and cost-efficiency.\nOur emphasis in this research lies in addressing statistical complexity in FL,\nespecially when the data stored locally across devices is not identically and\nindependently distributed (non-IID). We have observed an accuracy reduction of\nup to approximately 10\\% to 30\\%, particularly in skewed scenarios where each\nedge device trains with only 1 class of data. This reduction is attributed to\nweight divergence, quantified using the Euclidean distance between device-level\nclass distributions and the population distribution, resulting in a bias term\n(\\(\\delta_k\\)). As a solution, we present a method to improve convergence in FL\nby creating a global subset of data on the server and dynamically distributing\nit across devices using a Dynamic Data queue-driven Federated Learning (DDFL).\nNext, we leverage Data Entropy metrics to observe the process during each\ntraining round and enable reasonable device selection for aggregation.\nFurthermore, we provide a convergence analysis of our proposed DDFL to justify\ntheir viability in practical FL scenarios, aiming for better device selection,\na non-sub-optimal global model, and faster convergence. We observe that our\napproach results in a substantial accuracy boost of approximately 5\\% for the\nMNIST dataset, around 18\\% for CIFAR-10, and 20\\% for CIFAR-100 with a 10\\%\nglobal subset of data, outperforming the state-of-the-art (SOTA) aggregation\nalgorithms.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "14J60 (Primary)",
      "I.2.11; I.5.1; I.5.4"
    ],
    "primary_category": "cs.LG",
    "comment": "The Journal is submitted to IEEE Transactions in the Internet of\n  Things",
    "pdf_url": "http://arxiv.org/pdf/2410.17792v1",
    "published_date": "2024-10-23 11:47:04 UTC",
    "updated_date": "2024-10-23 11:47:04 UTC"
  },
  {
    "arxiv_id": "2410.17787v1",
    "title": "Large Language Models Engineer Too Many Simple Features For Tabular Data",
    "authors": [
      "Jaris Küken",
      "Lennart Purucker",
      "Frank Hutter"
    ],
    "abstract": "Tabular machine learning problems often require time-consuming and\nlabor-intensive feature engineering. Recent efforts have focused on using large\nlanguage models (LLMs) to capitalize on their potential domain knowledge. At\nthe same time, researchers have observed ethically concerning negative biases\nin other LLM-related use cases, such as text generation. These developments\nmotivated us to investigate whether LLMs exhibit a bias that negatively impacts\nthe performance of feature engineering. While not ethically concerning, such a\nbias could hinder practitioners from fully utilizing LLMs for automated data\nscience. Therefore, we propose a method to detect potential biases by detecting\nanomalies in the frequency of operators (e.g., adding two features) suggested\nby LLMs when engineering new features. Our experiments evaluate the bias of\nfour LLMs, two big frontier and two small open-source models, across 27 tabular\ndatasets. Our results indicate that LLMs are biased toward simple operators,\nsuch as addition, and can fail to utilize more complex operators, such as\ngrouping followed by aggregations. Furthermore, the bias can negatively impact\nthe predictive performance when using LLM-generated features. Our results call\nfor mitigating bias when using LLMs for feature engineering.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Preprint",
    "pdf_url": "http://arxiv.org/pdf/2410.17787v1",
    "published_date": "2024-10-23 11:37:20 UTC",
    "updated_date": "2024-10-23 11:37:20 UTC"
  },
  {
    "arxiv_id": "2410.17784v1",
    "title": "Holon Programming Model -- A Software-Defined Approach for System of Systems",
    "authors": [
      "Muhammad Ashfaq",
      "Ahmed R. Sadik",
      "Tommi Mikkonen",
      "Muhammad Waseem",
      "Niko Makitalo"
    ],
    "abstract": "As Systems of Systems evolve into increasingly complex networks, harnessing\ntheir collective potential becomes paramount. Traditional SoS engineering\napproaches lack the necessary programmability to develop third party SoS level\nbehaviors. To address this challenge, we propose a software defined approach to\nenable flexible and adaptive programming of SoS. We introduce the Holon\nProgramming Model, a software-defined framework designed to meet these needs.\nThe Holon Programming Model empowers developers to design and orchestrate\ncomplex system behaviors effectively, as illustrated in our disaster management\nscenario. This research outlines the Holon Programming Model theoretical\nunderpinnings and practical applications, with the aim of driving further\nexploration and advancement in the field of software defined SoS",
    "categories": [
      "cs.AI",
      "cs.ET",
      "cs.SE"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.17784v1",
    "published_date": "2024-10-23 11:34:29 UTC",
    "updated_date": "2024-10-23 11:34:29 UTC"
  },
  {
    "arxiv_id": "2410.17781v1",
    "title": "Evaluating Explanations Through LLMs: Beyond Traditional User Studies",
    "authors": [
      "Francesco Bombassei De Bona",
      "Gabriele Dominici",
      "Tim Miller",
      "Marc Langheinrich",
      "Martin Gjoreski"
    ],
    "abstract": "As AI becomes fundamental in sectors like healthcare, explainable AI (XAI)\ntools are essential for trust and transparency. However, traditional user\nstudies used to evaluate these tools are often costly, time consuming, and\ndifficult to scale. In this paper, we explore the use of Large Language Models\n(LLMs) to replicate human participants to help streamline XAI evaluation. We\nreproduce a user study comparing counterfactual and causal explanations,\nreplicating human participants with seven LLMs under various settings. Our\nresults show that (i) LLMs can replicate most conclusions from the original\nstudy, (ii) different LLMs yield varying levels of alignment in the results,\nand (iii) experimental factors such as LLM memory and output variability affect\nalignment with human responses. These initial findings suggest that LLMs could\nprovide a scalable and cost-effective way to simplify qualitative XAI\nevaluation.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.17781v1",
    "published_date": "2024-10-23 11:31:52 UTC",
    "updated_date": "2024-10-23 11:31:52 UTC"
  },
  {
    "arxiv_id": "2410.17772v2",
    "title": "Scaling Robot Policy Learning via Zero-Shot Labeling with Foundation Models",
    "authors": [
      "Nils Blank",
      "Moritz Reuss",
      "Marcel Rühle",
      "Ömer Erdinç Yağmurlu",
      "Fabian Wenzel",
      "Oier Mees",
      "Rudolf Lioutikov"
    ],
    "abstract": "A central challenge towards developing robots that can relate human language\nto their perception and actions is the scarcity of natural language annotations\nin diverse robot datasets. Moreover, robot policies that follow natural\nlanguage instructions are typically trained on either templated language or\nexpensive human-labeled instructions, hindering their scalability. To this end,\nwe introduce NILS: Natural language Instruction Labeling for Scalability. NILS\nautomatically labels uncurated, long-horizon robot data at scale in a zero-shot\nmanner without any human intervention. NILS combines pretrained vision-language\nfoundation models in order to detect objects in a scene, detect object-centric\nchanges, segment tasks from large datasets of unlabelled interaction data and\nultimately label behavior datasets. Evaluations on BridgeV2, Fractal, and a\nkitchen play dataset show that NILS can autonomously annotate diverse robot\ndemonstrations of unlabeled and unstructured datasets while alleviating several\nshortcomings of crowdsourced human annotations, such as low data quality and\ndiversity. We use NILS to label over 115k trajectories obtained from over 430\nhours of robot data. We open-source our auto-labeling code and generated\nannotations on our website: http://robottasklabeling.github.io.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "Project Website at https://robottasklabeling.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2410.17772v2",
    "published_date": "2024-10-23 11:19:48 UTC",
    "updated_date": "2024-10-26 07:39:56 UTC"
  },
  {
    "arxiv_id": "2410.17764v1",
    "title": "Beyond Backpropagation: Optimization with Multi-Tangent Forward Gradients",
    "authors": [
      "Katharina Flügel",
      "Daniel Coquelin",
      "Marie Weiel",
      "Achim Streit",
      "Markus Götz"
    ],
    "abstract": "The gradients used to train neural networks are typically computed using\nbackpropagation. While an efficient way to obtain exact gradients,\nbackpropagation is computationally expensive, hinders parallelization, and is\nbiologically implausible. Forward gradients are an approach to approximate the\ngradients from directional derivatives along random tangents computed by\nforward-mode automatic differentiation. So far, research has focused on using a\nsingle tangent per step. This paper provides an in-depth analysis of\nmulti-tangent forward gradients and introduces an improved approach to\ncombining the forward gradients from multiple tangents based on orthogonal\nprojections. We demonstrate that increasing the number of tangents improves\nboth approximation quality and optimization performance across various tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.17764v1",
    "published_date": "2024-10-23 11:02:59 UTC",
    "updated_date": "2024-10-23 11:02:59 UTC"
  },
  {
    "arxiv_id": "2410.17758v2",
    "title": "A Neural Network Alternative to Tree-based Models",
    "authors": [
      "Salvatore Raieli",
      "Nathalie Jeanray",
      "Stéphane Gerart",
      "Sebastien Vachenc",
      "Abdulrahman Altahhan"
    ],
    "abstract": "Tabular datasets are widely used in scientific disciplines such as biology.\nWhile these disciplines have already adopted AI methods to enhance their\nfindings and analysis, they mainly use tree-based methods due to their\ninterpretability. At the same time, artificial neural networks have been shown\nto offer superior flexibility and depth for rich and complex non-tabular\nproblems, but they are falling behind tree-based models for tabular data in\nterms of performance and interpretability. Although sparsity has been shown to\nimprove the interpretability and performance of ANN models for complex\nnon-tabular datasets, enforcing sparsity structurally and formatively for\ntabular data before training the model, remains an open question. To address\nthis question, we establish a method that infuses sparsity in neural networks\nby utilising attention mechanisms to capture the features' importance in\ntabular datasets. We show that our models, Sparse TABular NET or sTAB-Net with\nattention mechanisms, are more effective than tree-based models, reaching the\nstate-of-the-art on biological datasets. They further permit the extraction of\ninsights from these datasets and achieve better performance than post-hoc\nmethods like SHAP.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.17758v2",
    "published_date": "2024-10-23 10:50:07 UTC",
    "updated_date": "2025-04-15 12:28:35 UTC"
  },
  {
    "arxiv_id": "2410.19862v1",
    "title": "Real-Time Weapon Detection Using YOLOv8 for Enhanced Safety",
    "authors": [
      "Ayush Thakur",
      "Akshat Shrivastav",
      "Rohan Sharma",
      "Triyank Kumar",
      "Kabir Puri"
    ],
    "abstract": "This research paper presents the development of an AI model utilizing YOLOv8\nfor real-time weapon detection, aimed at enhancing safety in public spaces such\nas schools, airports, and public transportation systems. As incidents of\nviolence continue to rise globally, there is an urgent need for effective\nsurveillance technologies that can quickly identify potential threats. Our\napproach focuses on leveraging advanced deep learning techniques to create a\nhighly accurate and efficient system capable of detecting weapons in real-time\nvideo streams. The model was trained on a comprehensive dataset containing\nthousands of images depicting various types of firearms and edged weapons,\nensuring a robust learning process. We evaluated the model's performance using\nkey metrics such as precision, recall, F1-score, and mean Average Precision\n(mAP) across multiple Intersection over Union (IoU) thresholds, revealing a\nsignificant capability to differentiate between weapon and non-weapon classes\nwith minimal error. Furthermore, we assessed the system's operational\nefficiency, demonstrating that it can process frames at high speeds suitable\nfor real-time applications. The findings indicate that our YOLOv8-based weapon\ndetection model not only contributes to the existing body of knowledge in\ncomputer vision but also addresses critical societal needs for improved safety\nmeasures in vulnerable environments. By harnessing the power of artificial\nintelligence, this research lays the groundwork for developing practical\nsolutions that can be deployed in security settings, ultimately enhancing the\nprotective capabilities of law enforcement and public safety agencies.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "21 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.19862v1",
    "published_date": "2024-10-23 10:35:51 UTC",
    "updated_date": "2024-10-23 10:35:51 UTC"
  },
  {
    "arxiv_id": "2410.17751v2",
    "title": "VISAGE: Video Synthesis using Action Graphs for Surgery",
    "authors": [
      "Yousef Yeganeh",
      "Rachmadio Lazuardi",
      "Amir Shamseddin",
      "Emine Dari",
      "Yash Thirani",
      "Nassir Navab",
      "Azade Farshad"
    ],
    "abstract": "Surgical data science (SDS) is a field that analyzes patient data before,\nduring, and after surgery to improve surgical outcomes and skills. However,\nsurgical data is scarce, heterogeneous, and complex, which limits the\napplicability of existing machine learning methods. In this work, we introduce\nthe novel task of future video generation in laparoscopic surgery. This task\ncan augment and enrich the existing surgical data and enable various\napplications, such as simulation, analysis, and robot-aided surgery.\nUltimately, it involves not only understanding the current state of the\noperation but also accurately predicting the dynamic and often unpredictable\nnature of surgical procedures. Our proposed method, VISAGE (VIdeo Synthesis\nusing Action Graphs for Surgery), leverages the power of action scene graphs to\ncapture the sequential nature of laparoscopic procedures and utilizes diffusion\nmodels to synthesize temporally coherent video sequences. VISAGE predicts the\nfuture frames given only a single initial frame, and the action graph triplets.\nBy incorporating domain-specific knowledge through the action graph, VISAGE\nensures the generated videos adhere to the expected visual and motion patterns\nobserved in real laparoscopic procedures. The results of our experiments\ndemonstrate high-fidelity video generation for laparoscopy procedures, which\nenables various applications in SDS.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at MICCAI 2024 Embodied AI and Robotics for HealTHcare\n  (EARTH) Workshop",
    "pdf_url": "http://arxiv.org/pdf/2410.17751v2",
    "published_date": "2024-10-23 10:28:17 UTC",
    "updated_date": "2024-10-30 10:13:18 UTC"
  },
  {
    "arxiv_id": "2410.17744v2",
    "title": "Learning Versatile Skills with Curriculum Masking",
    "authors": [
      "Yao Tang",
      "Zhihui Xie",
      "Zichuan Lin",
      "Deheng Ye",
      "Shuai Li"
    ],
    "abstract": "Masked prediction has emerged as a promising pretraining paradigm in offline\nreinforcement learning (RL) due to its versatile masking schemes, enabling\nflexible inference across various downstream tasks with a unified model.\nDespite the versatility of masked prediction, it remains unclear how to balance\nthe learning of skills at different levels of complexity. To address this, we\npropose CurrMask, a curriculum masking pretraining paradigm for sequential\ndecision making. Motivated by how humans learn by organizing knowledge in a\ncurriculum, CurrMask adjusts its masking scheme during pretraining for learning\nversatile skills. Through extensive experiments, we show that CurrMask exhibits\nsuperior zero-shot performance on skill prompting tasks, goal-conditioned\nplanning tasks, and competitive finetuning performance on offline RL tasks.\nAdditionally, our analysis of training dynamics reveals that CurrMask gradually\nacquires skills of varying complexity by dynamically adjusting its masking\nscheme.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "NeurIPS 2024 poster, 21 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.17744v2",
    "published_date": "2024-10-23 10:17:13 UTC",
    "updated_date": "2024-11-04 08:40:59 UTC"
  },
  {
    "arxiv_id": "2410.17740v1",
    "title": "Emotion Recognition with Facial Attention and Objective Activation Functions",
    "authors": [
      "Andrzej Miskow",
      "Abdulrahman Altahhan"
    ],
    "abstract": "In this paper, we study the effect of introducing channel and spatial\nattention mechanisms, namely SEN-Net, ECA-Net, and CBAM, to existing CNN\nvision-based models such as VGGNet, ResNet, and ResNetV2 to perform the Facial\nEmotion Recognition task. We show that not only attention can significantly\nimprove the performance of these models but also that combining them with a\ndifferent activation function can further help increase the performance of\nthese models.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.17740v1",
    "published_date": "2024-10-23 10:14:37 UTC",
    "updated_date": "2024-10-23 10:14:37 UTC"
  },
  {
    "arxiv_id": "2410.17735v1",
    "title": "New Insight in Cervical Cancer Diagnosis Using Convolution Neural Network Architecture",
    "authors": [
      "Ach. Khozaimi",
      "Wayan Firdaus Mahmudy"
    ],
    "abstract": "The Pap smear is a screening method for early cervical cancer diagnosis. The\nselection of the right optimizer in the convolutional neural network (CNN)\nmodel is key to the success of the CNN in image classification, including the\nclassification of cervical cancer Pap smear images. In this study, stochastic\ngradient descent (SGD), RMSprop, Adam, AdaGrad, AdaDelta, Adamax, and Nadam\noptimizers were used to classify cervical cancer Pap smear images from the\nSipakMed dataset. Resnet-18, Resnet-34, and VGG-16 are the CNN architectures\nused in this study, and each architecture uses a transfer-learning model. Based\non the test results, we conclude that the transfer learning model performs\nbetter on all CNNs and optimization techniques and that in the transfer\nlearning model, the optimization has little influence on the training of the\nmodel. Adamax, with accuracy values of 72.8% and 66.8%, had the best accuracy\nfor the VGG-16 and Resnet-18 architectures, respectively. Resnet-34 had 54.0%.\nThis is 0.034% lower than Nadam. Overall, Adamax is a suitable optimizer for\nCNN in cervical cancer classification on Resnet-18, Resnet-34, and VGG-16\narchitectures. This study provides new insights into the configuration of CNN\nmodels for Pap smear image analysis.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.17735v1",
    "published_date": "2024-10-23 10:11:39 UTC",
    "updated_date": "2024-10-23 10:11:39 UTC"
  },
  {
    "arxiv_id": "2410.17732v1",
    "title": "FuzzWiz -- Fuzzing Framework for Efficient Hardware Coverage",
    "authors": [
      "Deepak Narayan Gadde",
      "Aman Kumar",
      "Djones Lettnin",
      "Sebastian Simon"
    ],
    "abstract": "Ever-increasing design complexity of System-on-Chips (SoCs) led to\nsignificant verification challenges. Unlike software, bugs in hardware design\nare vigorous and eternal i.e., once the hardware is fabricated, it cannot be\nrepaired with any patch. Despite being one of the powerful techniques used in\nverification, the dynamic random approach cannot give confidence to complex\nRegister Transfer Leve (RTL) designs during the pre-silicon design phase. In\nparticular, achieving coverage targets and exposing bugs is a complicated task\nwith random simulations. In this paper, we leverage an existing testing\nsolution available in the software world known as fuzzing and apply it to\nhardware verification in order to achieve coverage targets in quick time. We\ncreated an automated hardware fuzzing framework FuzzWiz using metamodeling and\nPython to achieve coverage goals faster. It includes parsing the RTL design\nmodule, converting it into C/C++ models, creating generic testbench with\nassertions, fuzzer-specific compilation, linking, and fuzzing. Furthermore, it\nis configurable and provides the debug flow if any crash is detected during the\nfuzzing process. The proposed framework is applied on four IP blocks from\nGoogle's OpenTitan chip with various fuzzing engines to show its scalability\nand compatibility. Our benchmarking results show that we could achieve around\n90% of the coverage 10 times faster than traditional simulation regression\nbased approach.",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.AR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.17732v1",
    "published_date": "2024-10-23 10:06:08 UTC",
    "updated_date": "2024-10-23 10:06:08 UTC"
  },
  {
    "arxiv_id": "2410.17714v2",
    "title": "CogSteer: Cognition-Inspired Selective Layer Intervention for Efficiently Steering Large Language Models",
    "authors": [
      "Xintong Wang",
      "Jingheng Pan",
      "Liang Ding",
      "Longyue Wang",
      "Longqin Jiang",
      "Xingshan Li",
      "Chris Biemann"
    ],
    "abstract": "Large Language Models (LLMs) achieve remarkable performance through\npretraining on extensive data. This enables efficient adaptation to diverse\ndownstream tasks. However, the lack of interpretability in their underlying\nmechanisms limits the ability to effectively steer LLMs for specific\napplications. In this work, we investigate the intrinsic mechanisms of LLMs\nfrom a cognitive perspective using eye movement measures. Specifically, we\nanalyze the layer-wise correlation between human cognitive indicators and LLM\nrepresentations. Building on these insights, we propose a heuristic approach\nfor selecting the optimal steering layer to modulate LLM semantics. To this\nend, we introduce an efficient selective layer intervention based on prominent\nparameter-efficient fine-tuning methods, which conventionally adjust either all\nlayers or only the final layer. Additionally, we present an implicit layer\ncontrastive intervention during inference to steer LLMs away from toxic\noutputs. Extensive experiments on natural language understanding, reasoning,\nand generation tasks, conducted on GPT-2, LLaMa2-7B, and Mixtral-7B,\ndemonstrate the effectiveness and efficiency of our approach. As a\nmodel-agnostic framework, it enhances the interpretability of LLMs while\nimproving efficiency for safe deployment.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.17714v2",
    "published_date": "2024-10-23 09:40:15 UTC",
    "updated_date": "2025-02-18 10:09:47 UTC"
  },
  {
    "arxiv_id": "2410.17712v1",
    "title": "A Data-Driven Odyssey in Solar Vehicles",
    "authors": [
      "Do Young Kim",
      "Kyunghyun Kim",
      "Gyeongseop Lee",
      "Niloy Das",
      "Seong-Woo Kim"
    ],
    "abstract": "Solar vehicles, which simultaneously produce and consume energy, require\nmeticulous energy management. However, potential users often feel uncertain\nabout their operation compared to conventional vehicles. This study presents a\nsimulator designed to help users understand long-distance travel in solar\nvehicles and recognize the importance of proper energy management. By utilizing\nGoogle Maps data and weather information, the simulator replicates real-world\ndriving conditions and provides a dashboard displaying vehicle status, updated\nhourly based on user-inputted speed. Users can explore various speed policy\nscenarios and receive recommendations for optimal driving strategies. The\nsimulator's effectiveness was validated using the route of the World Solar\nChallenge (WSC). This research enables users to monitor energy dynamics before\na journey, enhancing their understanding of energy management and informing\nappropriate speed decisions.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.17712v1",
    "published_date": "2024-10-23 09:39:26 UTC",
    "updated_date": "2024-10-23 09:39:26 UTC"
  },
  {
    "arxiv_id": "2410.17711v1",
    "title": "Beware of Calibration Data for Pruning Large Language Models",
    "authors": [
      "Yixin Ji",
      "Yang Xiang",
      "Juntao Li",
      "Qingrong Xia",
      "Ping Li",
      "Xinyu Duan",
      "Zhefeng Wang",
      "Min Zhang"
    ],
    "abstract": "As large language models (LLMs) are widely applied across various fields,\nmodel compression has become increasingly crucial for reducing costs and\nimproving inference efficiency. Post-training pruning is a promising method\nthat does not require resource-intensive iterative training and only needs a\nsmall amount of calibration data to assess the importance of parameters.\nPrevious research has primarily focused on designing advanced pruning methods,\nwhile different calibration data's impact on pruning performance still lacks\nsystematical exploration. We fill this blank and surprisingly observe that the\neffects of calibration data even value more than designing advanced pruning\nstrategies, especially for high sparsity. Our preliminary exploration also\ndiscloses that using calibration data similar to the training data can yield\nbetter performance. As pre-training data is usually inaccessible for advanced\nLLMs, we further provide a self-generating calibration data synthesis strategy\nto construct feasible calibration data. We conduct experiments on the recent\nstrong open-source LLMs (e.g., DCLM, and LLaMA-3), and the results show that\nthe proposed method outperforms commonly used calibration data and can\neffectively enhance strong pruning methods (e.g., Wanda, OWL).",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "under review",
    "pdf_url": "http://arxiv.org/pdf/2410.17711v1",
    "published_date": "2024-10-23 09:36:21 UTC",
    "updated_date": "2024-10-23 09:36:21 UTC"
  },
  {
    "arxiv_id": "2410.17700v1",
    "title": "Scalable Random Feature Latent Variable Models",
    "authors": [
      "Ying Li",
      "Zhidi Lin",
      "Yuhao Liu",
      "Michael Minyi Zhang",
      "Pablo M. Olmos",
      "Petar M. Djurić"
    ],
    "abstract": "Random feature latent variable models (RFLVMs) represent the state-of-the-art\nin latent variable models, capable of handling non-Gaussian likelihoods and\neffectively uncovering patterns in high-dimensional data. However, their heavy\nreliance on Monte Carlo sampling results in scalability issues which makes it\ndifficult to use these models for datasets with a massive number of\nobservations. To scale up RFLVMs, we turn to the optimization-based variational\nBayesian inference (VBI) algorithm which is known for its scalability compared\nto sampling-based methods. However, implementing VBI for RFLVMs poses\nchallenges, such as the lack of explicit probability distribution functions\n(PDFs) for the Dirichlet process (DP) in the kernel learning component, and the\nincompatibility of existing VBI algorithms with RFLVMs. To address these\nissues, we introduce a stick-breaking construction for DP to obtain an explicit\nPDF and a novel VBI algorithm called ``block coordinate descent variational\ninference\" (BCD-VI). This enables the development of a scalable version of\nRFLVMs, or in short, SRFLVM. Our proposed method shows scalability,\ncomputational efficiency, superior performance in generating informative latent\nrepresentations and the ability of imputing missing data across various\nreal-world datasets, outperforming state-of-the-art competitors.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.17700v1",
    "published_date": "2024-10-23 09:22:43 UTC",
    "updated_date": "2024-10-23 09:22:43 UTC"
  },
  {
    "arxiv_id": "2410.17694v1",
    "title": "An Adaptive Framework for Generating Systematic Explanatory Answer in Online Q&A Platforms",
    "authors": [
      "Ziyang Chen",
      "Xiaobin Wang",
      "Yong Jiang",
      "Jinzhi Liao",
      "Pengjun Xie",
      "Fei Huang",
      "Xiang Zhao"
    ],
    "abstract": "Question Answering (QA) systems face challenges in handling complex questions\nthat require multi-domain knowledge synthesis. The naive RAG models, although\neffective in information retrieval, struggle with complex questions that\nrequire comprehensive and in-depth answers. The pioneering task is defined as\nexplanatory answer generation, which entails handling identified challenges\nsuch as the requirement for comprehensive information and logical coherence\nwithin the generated context. To address these issues, we refer to systematic\nthinking theory and propose SynthRAG, an innovative framework designed to\nenhance QA performance. SynthRAG improves on conventional models by employing\nadaptive outlines for dynamic content structuring, generating systematic\ninformation to ensure detailed coverage, and producing customized answers\ntailored to specific user inquiries. This structured approach guarantees\nlogical coherence and thorough integration of information, yielding responses\nthat are both insightful and methodically organized. Empirical evaluations\nunderscore SynthRAG's effectiveness, demonstrating its superiority in handling\ncomplex questions, overcoming the limitations of naive RAG models, and\nsignificantly improving answer quality and depth. Furthermore, an online\ndeployment on the Zhihu platform revealed that SynthRAG's answers achieved\nnotable user engagement, with each response averaging 5.73 upvotes and\nsurpassing the performance of 79.8% of human contributors, highlighting the\npractical relevance and impact of the proposed framework. Our code is available\nat https://github.com/czy1999/SynthRAG .",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "10 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.17694v1",
    "published_date": "2024-10-23 09:14:57 UTC",
    "updated_date": "2024-10-23 09:14:57 UTC"
  },
  {
    "arxiv_id": "2410.17661v1",
    "title": "PETAH: Parameter Efficient Task Adaptation for Hybrid Transformers in a resource-limited Context",
    "authors": [
      "Maximilian Augustin",
      "Syed Shakib Sarwar",
      "Mostafa Elhoushi",
      "Sai Qian Zhang",
      "Yuecheng Li",
      "Barbara De Salvo"
    ],
    "abstract": "Following their success in natural language processing (NLP), there has been\na shift towards transformer models in computer vision. While transformers\nperform well and offer promising multi-tasking performance, due to their high\ncompute requirements, many resource-constrained applications still rely on\nconvolutional or hybrid models that combine the benefits of convolution and\nattention layers and achieve the best results in the sub 100M parameter range.\nSimultaneously, task adaptation techniques that allow for the use of one shared\ntransformer backbone for multiple downstream tasks, resulting in great storage\nsavings at negligible cost in performance, have not yet been adopted for hybrid\ntransformers. In this work, we investigate how to achieve the best\ntask-adaptation performance and introduce PETAH: Parameter Efficient Task\nAdaptation for Hybrid Transformers. We further combine PETAH adaptation with\npruning to achieve highly performant and storage friendly models for\nmulti-tasking. In our extensive evaluation on classification and other vision\ntasks, we demonstrate that our PETAH-adapted hybrid models outperform\nestablished task-adaptation techniques for ViTs while requiring fewer\nparameters and being more efficient on mobile hardware.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.17661v1",
    "published_date": "2024-10-23 08:24:47 UTC",
    "updated_date": "2024-10-23 08:24:47 UTC"
  },
  {
    "arxiv_id": "2410.17656v1",
    "title": "AutoRNet: Automatically Optimizing Heuristics for Robust Network Design via Large Language Models",
    "authors": [
      "He Yu",
      "Jing Liu"
    ],
    "abstract": "Achieving robust networks is a challenging problem due to its NP-hard nature\nand complex solution space. Current methods, from handcrafted feature\nextraction to deep learning, have made progress but remain rigid, requiring\nmanual design and large labeled datasets. To address these issues, we propose\nAutoRNet, a framework that integrates large language models (LLMs) with\nevolutionary algorithms to generate heuristics for robust network design. We\ndesign network optimization strategies to provide domain-specific prompts for\nLLMs, utilizing domain knowledge to generate advanced heuristics. Additionally,\nwe introduce an adaptive fitness function to balance convergence and diversity\nwhile maintaining degree distributions. AutoRNet is evaluated on sparse and\ndense scale-free networks, outperforming current methods by reducing the need\nfor manual design and large datasets.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.17656v1",
    "published_date": "2024-10-23 08:18:38 UTC",
    "updated_date": "2024-10-23 08:18:38 UTC"
  },
  {
    "arxiv_id": "2410.17655v1",
    "title": "Mapping the Media Landscape: Predicting Factual Reporting and Political Bias Through Web Interactions",
    "authors": [
      "Dairazalia Sánchez-Cortés",
      "Sergio Burdisso",
      "Esaú Villatoro-Tello",
      "Petr Motlicek"
    ],
    "abstract": "Bias assessment of news sources is paramount for professionals,\norganizations, and researchers who rely on truthful evidence for information\ngathering and reporting. While certain bias indicators are discernible from\ncontent analysis, descriptors like political bias and fake news pose greater\nchallenges. In this paper, we propose an extension to a recently presented news\nmedia reliability estimation method that focuses on modeling outlets and their\nlongitudinal web interactions. Concretely, we assess the classification\nperformance of four reinforcement learning strategies on a large news media\nhyperlink graph. Our experiments, targeting two challenging bias descriptors,\nfactual reporting and political bias, showed a significant performance\nimprovement at the source media level. Additionally, we validate our methods on\nthe CLEF 2023 CheckThat! Lab challenge, outperforming the reported results in\nboth, F1-score and the official MAE metric. Furthermore, we contribute by\nreleasing the largest annotated dataset of news source media, categorized with\nfactual reporting and political bias labels. Our findings suggest that\nprofiling news media sources based on their hyperlink interactions over time is\nfeasible, offering a bird's-eye view of evolving media landscapes.",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted to CLEF 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.17655v1",
    "published_date": "2024-10-23 08:18:26 UTC",
    "updated_date": "2024-10-23 08:18:26 UTC"
  },
  {
    "arxiv_id": "2410.17637v1",
    "title": "MIA-DPO: Multi-Image Augmented Direct Preference Optimization For Large Vision-Language Models",
    "authors": [
      "Ziyu Liu",
      "Yuhang Zang",
      "Xiaoyi Dong",
      "Pan Zhang",
      "Yuhang Cao",
      "Haodong Duan",
      "Conghui He",
      "Yuanjun Xiong",
      "Dahua Lin",
      "Jiaqi Wang"
    ],
    "abstract": "Visual preference alignment involves training Large Vision-Language Models\n(LVLMs) to predict human preferences between visual inputs. This is typically\nachieved by using labeled datasets of chosen/rejected pairs and employing\noptimization algorithms like direct preference optimization (DPO). Existing\nvisual alignment methods, primarily designed for single-image scenarios,\nstruggle to effectively handle the complexity of multi-image tasks due to the\nscarcity of diverse training data and the high cost of annotating\nchosen/rejected pairs. We present Multi-Image Augmented Direct Preference\nOptimization (MIA-DPO), a visual preference alignment approach that effectively\nhandles multi-image inputs. MIA-DPO mitigates the scarcity of diverse\nmulti-image training data by extending single-image data with unrelated images\narranged in grid collages or pic-in-pic formats, significantly reducing the\ncosts associated with multi-image data annotations. Our observation reveals\nthat attention values of LVLMs vary considerably across different images. We\nuse attention values to identify and filter out rejected responses the model\nmay have mistakenly focused on. Our attention-aware selection for constructing\nthe chosen/rejected pairs without relying on (i) human annotation, (ii) extra\ndata, and (iii) external models or APIs. MIA-DPO is compatible with various\narchitectures and outperforms existing methods on five multi-image benchmarks,\nachieving an average performance boost of 3.0% on LLaVA-v1.5 and 4.3% on the\nrecent InternLM-XC2.5. Moreover, MIA-DPO has a minimal effect on the model's\nability to understand single images.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Project URL: https://github.com/Liuziyu77/MIA-DPO",
    "pdf_url": "http://arxiv.org/pdf/2410.17637v1",
    "published_date": "2024-10-23 07:56:48 UTC",
    "updated_date": "2024-10-23 07:56:48 UTC"
  },
  {
    "arxiv_id": "2410.18710v3",
    "title": "Uncovering the Genetic Basis of Glioblastoma Heterogeneity through Multimodal Analysis of Whole Slide Images and RNA Sequencing Data",
    "authors": [
      "Ahmad Berjaoui",
      "Louis Roussel",
      "Eduardo Hugo Sanchez",
      "Elizabeth Cohen-Jonathan Moyal"
    ],
    "abstract": "Glioblastoma is a highly aggressive form of brain cancer characterized by\nrapid progression and poor prognosis. Despite advances in treatment, the\nunderlying genetic mechanisms driving this aggressiveness remain poorly\nunderstood. In this study, we employed multimodal deep learning approaches to\ninvestigate glioblastoma heterogeneity using joint image/RNA-seq analysis. Our\nresults reveal novel genes associated with glioblastoma. By leveraging a\ncombination of whole-slide images and RNA-seq, as well as introducing novel\nmethods to encode RNA-seq data, we identified specific genetic profiles that\nmay explain different patterns of glioblastoma progression. These findings\nprovide new insights into the genetic mechanisms underlying glioblastoma\nheterogeneity and highlight potential targets for therapeutic intervention.\nCode and data downloading instructions are available at:\nhttps://github.com/ma3oun/gbheterogeneity.",
    "categories": [
      "q-bio.QM",
      "cs.AI"
    ],
    "primary_category": "q-bio.QM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.18710v3",
    "published_date": "2024-10-23 07:55:40 UTC",
    "updated_date": "2025-05-19 13:22:26 UTC"
  },
  {
    "arxiv_id": "2410.17635v2",
    "title": "Markov Chain of Thought for Efficient Mathematical Reasoning",
    "authors": [
      "Wen Yang",
      "Minpeng Liao",
      "Kai Fan"
    ],
    "abstract": "Chain of Thought (CoT) of multi-step benefits from the logical structure of\nthe reasoning steps and task-specific actions, significantly enhancing the\nmathematical reasoning capabilities of large language models. As the prevalence\nof long CoT, the number of reasoning steps exceeds manageable token limits and\nleads to higher computational demands. Inspired by the fundamental logic of\nhuman cognition, \"derive, then reduce\", we conceptualize the standard\nmulti-step CoT as a novel Markov Chain of Thought (MCoT). In this study, we\nconsider the mathematical reasoning task, defining each reasoning step as text\naccompanied by a Python code snippet. To facilitate a longer reasoning path,\nself-correction is enabled through interactions with the code interpreter. Our\nMCoT aims to compress previous reasoning steps into a simplified question,\nenabling efficient next-step inference without relying on a lengthy KV cache.\nIn our experiments, we curate the $\\texttt{MCoTInstruct}$ dataset, and the\nempirical results indicate that MCoT not only significantly enhances efficiency\nbut also maintains comparable accuracy. While much remains to be explored, this\nwork paves the way for exploring the long CoT reasoning abilities of LLMs. The\ncode is available at https://github.com/james-yw/Markov-Chain-of-Thought",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "Camera ready version for NAACL 2025 Main",
    "pdf_url": "http://arxiv.org/pdf/2410.17635v2",
    "published_date": "2024-10-23 07:53:29 UTC",
    "updated_date": "2025-03-06 06:39:56 UTC"
  },
  {
    "arxiv_id": "2410.17632v2",
    "title": "LMLPA: Language Model Linguistic Personality Assessment",
    "authors": [
      "Jingyao Zheng",
      "Xian Wang",
      "Simo Hosio",
      "Xiaoxian Xu",
      "Lik-Hang Lee"
    ],
    "abstract": "Large Language Models (LLMs) are increasingly used in everyday life and\nresearch. One of the most common use cases is conversational interactions,\nenabled by the language generation capabilities of LLMs. Just as between two\nhumans, a conversation between an LLM-powered entity and a human depends on the\npersonality of the conversants. However, measuring the personality of a given\nLLM is currently a challenge. This paper introduces the Language Model\nLinguistic Personality Assessment (LMLPA), a system designed to evaluate the\nlinguistic personalities of LLMs. Our system helps to understand LLMs' language\ngeneration capabilities by quantitatively assessing the distinct personality\ntraits reflected in their linguistic outputs. Unlike traditional human-centric\npsychometrics, the LMLPA adapts a personality assessment questionnaire,\nspecifically the Big Five Inventory, to align with the operational capabilities\nof LLMs, and also incorporates the findings from previous language-based\npersonality measurement literature. To mitigate sensitivity to the order of\noptions, our questionnaire is designed to be open-ended, resulting in textual\nanswers. Thus, the AI rater is needed to transform ambiguous personality\ninformation from text responses into clear numerical indicators of personality\ntraits. Utilising Principal Component Analysis and reliability validations, our\nfindings demonstrate that LLMs possess distinct personality traits that can be\neffectively quantified by the LMLPA. This research contributes to\nHuman-Computer Interaction and Human-Centered AI, providing a robust framework\nfor future studies to refine AI personality assessments and expand their\napplications in multiple areas, including education and manufacturing.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.17632v2",
    "published_date": "2024-10-23 07:48:51 UTC",
    "updated_date": "2024-11-11 11:32:21 UTC"
  },
  {
    "arxiv_id": "2410.17629v2",
    "title": "Graph Signal Adaptive Message Passing",
    "authors": [
      "Yi Yan",
      "Changran Peng",
      "Ercan Engin Kuruoglu"
    ],
    "abstract": "This paper proposes Graph Signal Adaptive Message Passing (GSAMP), a novel\nmessage passing method that simultaneously conducts online prediction, missing\ndata imputation, and noise removal on time-varying graph signals. Unlike\nconventional Graph Signal Processing methods that apply the same filter to the\nentire graph, the spatiotemporal updates of GSAMP employ a distinct approach\nthat utilizes localized computations at each node. This update is based on an\nadaptive solution obtained from an optimization problem designed to minimize\nthe discrepancy between observed and estimated values. GSAMP effectively\nprocesses real-world, time-varying graph signals under Gaussian and impulsive\nnoise conditions.",
    "categories": [
      "eess.SP",
      "cs.AI"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.17629v2",
    "published_date": "2024-10-23 07:44:56 UTC",
    "updated_date": "2024-11-23 10:25:59 UTC"
  },
  {
    "arxiv_id": "2410.17621v2",
    "title": "Process Supervision-Guided Policy Optimization for Code Generation",
    "authors": [
      "Ning Dai",
      "Zheng Wu",
      "Renjie Zheng",
      "Ziyun Wei",
      "Wenlei Shi",
      "Xing Jin",
      "Guanlin Liu",
      "Chen Dun",
      "Liang Huang",
      "Lin Yan"
    ],
    "abstract": "Reinforcement learning (RL) with unit test feedback has enhanced large\nlanguage models' (LLMs) code generation, but relies on sparse rewards provided\nonly after complete code evaluation, limiting learning efficiency and\nincremental improvements. When generated code fails all unit tests, no learning\nsignal is received, hindering progress on complex tasks. To address this, we\npropose a Process Reward Model (PRM) that delivers dense, line-level feedback\non code correctness during generation, mimicking human code refinement and\nproviding immediate guidance. We explore various strategies for training PRMs\nand integrating them into the RL framework, finding that using PRMs both as\ndense rewards and for value function initialization significantly boosts\nperformance. Our experimental results also highlight the effectiveness of PRMs\nin enhancing RL-driven code generation, especially for long-horizon scenarios.",
    "categories": [
      "cs.AI",
      "I.2.7,"
    ],
    "primary_category": "cs.AI",
    "comment": "15 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.17621v2",
    "published_date": "2024-10-23 07:22:33 UTC",
    "updated_date": "2025-02-04 09:24:30 UTC"
  },
  {
    "arxiv_id": "2410.17619v2",
    "title": "From PDFs to Structured Data: Utilizing LLM Analysis in Sports Database Management",
    "authors": [
      "Juhani Merilehto"
    ],
    "abstract": "This study investigates the effectiveness of Large Language Models (LLMs) in\nprocessing semi-structured data from PDF documents into structured formats,\nspecifically examining their application in updating the Finnish Sports Clubs\nDatabase. Through action research methodology, we developed and evaluated an\nAI-assisted approach utilizing OpenAI's GPT-4 and Anthropic's Claude 3 Opus\nmodels to process data from 72 sports federation membership reports. The system\nachieved a 90% success rate in automated processing, successfully handling 65\nof 72 files without errors and converting over 7,900 rows of data. While the\ninitial development time was comparable to traditional manual processing (three\nmonths), the implemented system shows potential for reducing future processing\ntime by approximately 90%. Key challenges included handling multilingual\ncontent, processing multi-page datasets, and managing extraneous information.\nThe findings suggest that while LLMs demonstrate significant potential for\nautomating semi-structured data processing tasks, optimal results are achieved\nthrough a hybrid approach combining AI automation with selective human\noversight. This research contributes to the growing body of literature on\npractical LLM applications in organizational data management and provides\ninsights into the transformation of traditional data processing workflows.",
    "categories": [
      "cs.CE",
      "cs.AI"
    ],
    "primary_category": "cs.CE",
    "comment": "11 pages, 1 figure; corrected the corresponding authors e-mail",
    "pdf_url": "http://arxiv.org/pdf/2410.17619v2",
    "published_date": "2024-10-23 07:17:31 UTC",
    "updated_date": "2024-10-31 09:45:51 UTC"
  },
  {
    "arxiv_id": "2410.17610v3",
    "title": "ImDy: Human Inverse Dynamics from Imitated Observations",
    "authors": [
      "Xinpeng Liu",
      "Junxuan Liang",
      "Zili Lin",
      "Haowen Hou",
      "Yong-Lu Li",
      "Cewu Lu"
    ],
    "abstract": "Inverse dynamics (ID), which aims at reproducing the driven torques from\nhuman kinematic observations, has been a critical tool for gait analysis.\nHowever, it is hindered from wider application to general motion due to its\nlimited scalability. Conventional optimization-based ID requires expensive\nlaboratory setups, restricting its availability. To alleviate this problem, we\npropose to exploit the recently progressive human motion imitation algorithms\nto learn human inverse dynamics in a data-driven manner. The key insight is\nthat the human ID knowledge is implicitly possessed by motion imitators, though\nnot directly applicable. In light of this, we devise an efficient data\ncollection pipeline with state-of-the-art motion imitation algorithms and\nphysics simulators, resulting in a large-scale human inverse dynamics benchmark\nas Imitated Dynamics (ImDy). ImDy contains over 150 hours of motion with joint\ntorque and full-body ground reaction force data. With ImDy, we train a\ndata-driven human inverse dynamics solver ImDyS(olver) in a fully supervised\nmanner, which conducts ID and ground reaction force estimation simultaneously.\nExperiments on ImDy and real-world data demonstrate the impressive competency\nof ImDyS in human inverse dynamics and ground reaction force estimation.\nMoreover, the potential of ImDy(-S) as a fundamental motion analysis tool is\nexhibited with downstream applications. The project page is\nhttps://foruck.github.io/ImDy/.",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.GR",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "To appear in ICLR 2025. Yong-Lu Li and Cewu Lu are the corresponding\n  authors",
    "pdf_url": "http://arxiv.org/pdf/2410.17610v3",
    "published_date": "2024-10-23 07:06:08 UTC",
    "updated_date": "2025-02-13 05:15:07 UTC"
  },
  {
    "arxiv_id": "2410.17606v1",
    "title": "Towards Effective Data-Free Knowledge Distillation via Diverse Diffusion Augmentation",
    "authors": [
      "Muquan Li",
      "Dongyang Zhang",
      "Tao He",
      "Xiurui Xie",
      "Yuan-Fang Li",
      "Ke Qin"
    ],
    "abstract": "Data-free knowledge distillation (DFKD) has emerged as a pivotal technique in\nthe domain of model compression, substantially reducing the dependency on the\noriginal training data. Nonetheless, conventional DFKD methods that employ\nsynthesized training data are prone to the limitations of inadequate diversity\nand discrepancies in distribution between the synthesized and original\ndatasets. To address these challenges, this paper introduces an innovative\napproach to DFKD through diverse diffusion augmentation (DDA). Specifically, we\nrevise the paradigm of common data synthesis in DFKD to a composite process\nthrough leveraging diffusion models subsequent to data synthesis for\nself-supervised augmentation, which generates a spectrum of data samples with\nsimilar distributions while retaining controlled variations. Furthermore, to\nmitigate excessive deviation in the embedding space, we introduce an image\nfiltering technique grounded in cosine similarity to maintain fidelity during\nthe knowledge distillation process. Comprehensive experiments conducted on\nCIFAR-10, CIFAR-100, and Tiny-ImageNet datasets showcase the superior\nperformance of our method across various teacher-student network\nconfigurations, outperforming the contemporary state-of-the-art DFKD methods.\nCode will be available at:https://github.com/SLGSP/DDA.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.17606v1",
    "published_date": "2024-10-23 07:01:16 UTC",
    "updated_date": "2024-10-23 07:01:16 UTC"
  },
  {
    "arxiv_id": "2410.17602v1",
    "title": "Integrating Large Language Models for UAV Control in Simulated Environments: A Modular Interaction Approach",
    "authors": [
      "Abhishek Phadke",
      "Alihan Hadimlioglu",
      "Tianxing Chu",
      "Chandra N Sekharan"
    ],
    "abstract": "The intersection of LLMs (Large Language Models) and UAV (Unoccupied Aerial\nVehicles) technology represents a promising field of research with the\npotential to enhance UAV capabilities significantly. This study explores the\napplication of LLMs in UAV control, focusing on the opportunities for\nintegrating advanced natural language processing into autonomous aerial\nsystems. By enabling UAVs to interpret and respond to natural language\ncommands, LLMs simplify the UAV control and usage, making them accessible to a\nbroader user base and facilitating more intuitive human-machine interactions.\nThe paper discusses several key areas where LLMs can impact UAV technology,\nincluding autonomous decision-making, dynamic mission planning, enhanced\nsituational awareness, and improved safety protocols. Through a comprehensive\nreview of current developments and potential future directions, this study aims\nto highlight how LLMs can transform UAV operations, making them more adaptable,\nresponsive, and efficient in complex environments. A template development\nframework for integrating LLMs in UAV control is also described. Proof of\nConcept results that integrate existing LLM models and popular robotic\nsimulation platforms are demonstrated. The findings suggest that while there\nare substantial technical and ethical challenges to address, integrating LLMs\ninto UAV control holds promising implications for advancing autonomous aerial\nsystems.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.17602v1",
    "published_date": "2024-10-23 06:56:53 UTC",
    "updated_date": "2024-10-23 06:56:53 UTC"
  },
  {
    "arxiv_id": "2410.17600v2",
    "title": "Graphusion: A RAG Framework for Knowledge Graph Construction with a Global Perspective",
    "authors": [
      "Rui Yang",
      "Boming Yang",
      "Aosong Feng",
      "Sixun Ouyang",
      "Moritz Blum",
      "Tianwei She",
      "Yuang Jiang",
      "Freddy Lecue",
      "Jinghui Lu",
      "Irene Li"
    ],
    "abstract": "Knowledge Graphs (KGs) are crucial in the field of artificial intelligence\nand are widely used in downstream tasks, such as question-answering (QA). The\nconstruction of KGs typically requires significant effort from domain experts.\nLarge Language Models (LLMs) have recently been used for Knowledge Graph\nConstruction (KGC). However, most existing approaches focus on a local\nperspective, extracting knowledge triplets from individual sentences or\ndocuments, missing a fusion process to combine the knowledge in a global KG.\nThis work introduces Graphusion, a zero-shot KGC framework from free text. It\ncontains three steps: in Step 1, we extract a list of seed entities using topic\nmodeling to guide the final KG includes the most relevant entities; in Step 2,\nwe conduct candidate triplet extraction using LLMs; in Step 3, we design the\nnovel fusion module that provides a global view of the extracted knowledge,\nincorporating entity merging, conflict resolution, and novel triplet discovery.\nResults show that Graphusion achieves scores of 2.92 and 2.37 out of 3 for\nentity extraction and relation recognition, respectively. Moreover, we showcase\nhow Graphusion could be applied to the Natural Language Processing (NLP) domain\nand validate it in an educational scenario. Specifically, we introduce TutorQA,\na new expert-verified benchmark for QA, comprising six tasks and a total of\n1,200 QA pairs. Using the Graphusion-constructed KG, we achieve a significant\nimprovement on the benchmark, for example, a 9.2% accuracy improvement on\nsub-graph completion.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.DB"
    ],
    "primary_category": "cs.CL",
    "comment": "arXiv admin note: substantial text overlap with arXiv:2407.10794",
    "pdf_url": "http://arxiv.org/pdf/2410.17600v2",
    "published_date": "2024-10-23 06:54:03 UTC",
    "updated_date": "2025-02-03 09:48:26 UTC"
  },
  {
    "arxiv_id": "2410.17589v1",
    "title": "Challenge on Sound Scene Synthesis: Evaluating Text-to-Audio Generation",
    "authors": [
      "Junwon Lee",
      "Modan Tailleur",
      "Laurie M. Heller",
      "Keunwoo Choi",
      "Mathieu Lagrange",
      "Brian McFee",
      "Keisuke Imoto",
      "Yuki Okamoto"
    ],
    "abstract": "Despite significant advancements in neural text-to-audio generation,\nchallenges persist in controllability and evaluation. This paper addresses\nthese issues through the Sound Scene Synthesis challenge held as part of the\nDetection and Classification of Acoustic Scenes and Events 2024. We present an\nevaluation protocol combining objective metric, namely Fr\\'echet Audio\nDistance, with perceptual assessments, utilizing a structured prompt format to\nenable diverse captions and effective evaluation. Our analysis reveals varying\nperformance across sound categories and model architectures, with larger models\ngenerally excelling but innovative lightweight approaches also showing promise.\nThe strong correlation between objective metrics and human ratings validates\nour evaluation approach. We discuss outcomes in terms of audio quality,\ncontrollability, and architectural considerations for text-to-audio\nsynthesizers, providing direction for future research.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "cs.MM",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "accepted to NeurIPS 2024 Workshop: Audio Imagination",
    "pdf_url": "http://arxiv.org/pdf/2410.17589v1",
    "published_date": "2024-10-23 06:35:41 UTC",
    "updated_date": "2024-10-23 06:35:41 UTC"
  },
  {
    "arxiv_id": "2410.17584v1",
    "title": "Exploring Tokenization Methods for Multitrack Sheet Music Generation",
    "authors": [
      "Yashan Wang",
      "Shangda Wu",
      "Xingjian Du",
      "Maosong Sun"
    ],
    "abstract": "This study explores the tokenization of multitrack sheet music in ABC\nnotation, introducing two methods--bar-stream and line-stream patching. We\ncompare these methods against existing techniques, including bar patching, byte\npatching, and Byte Pair Encoding (BPE). In terms of both computational\nefficiency and the musicality of the generated compositions, experimental\nresults show that bar-stream patching performs best overall compared to the\nothers, which makes it a promising tokenization strategy for sheet music\ngeneration.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "3 pages, 1 figure, 1 table",
    "pdf_url": "http://arxiv.org/pdf/2410.17584v1",
    "published_date": "2024-10-23 06:19:48 UTC",
    "updated_date": "2024-10-23 06:19:48 UTC"
  },
  {
    "arxiv_id": "2410.18153v1",
    "title": "Physics-informed Neural Networks for Functional Differential Equations: Cylindrical Approximation and Its Convergence Guarantees",
    "authors": [
      "Taiki Miyagawa",
      "Takeru Yokota"
    ],
    "abstract": "We propose the first learning scheme for functional differential equations\n(FDEs). FDEs play a fundamental role in physics, mathematics, and optimal\ncontrol. However, the numerical analysis of FDEs has faced challenges due to\nits unrealistic computational costs and has been a long standing problem over\ndecades. Thus, numerical approximations of FDEs have been developed, but they\noften oversimplify the solutions. To tackle these two issues, we propose a\nhybrid approach combining physics-informed neural networks (PINNs) with the\n\\textit{cylindrical approximation}. The cylindrical approximation expands\nfunctions and functional derivatives with an orthonormal basis and transforms\nFDEs into high-dimensional PDEs. To validate the reliability of the cylindrical\napproximation for FDE applications, we prove the convergence theorems of\napproximated functional derivatives and solutions. Then, the derived\nhigh-dimensional PDEs are numerically solved with PINNs. Through the\ncapabilities of PINNs, our approach can handle a broader class of functional\nderivatives more efficiently than conventional discretization-based methods,\nimproving the scalability of the cylindrical approximation. As a proof of\nconcept, we conduct experiments on two FDEs and demonstrate that our model can\nsuccessfully achieve typical $L^1$ relative error orders of PINNs $\\sim\n10^{-3}$. Overall, our work provides a strong backbone for physicists,\nmathematicians, and machine learning experts to analyze previously challenging\nFDEs, thereby democratizing their numerical analysis, which has received\nlimited attention. Code is available at\n\\url{https://github.com/TaikiMiyagawa/FunctionalPINN}.",
    "categories": [
      "math.NA",
      "cond-mat.dis-nn",
      "cs.AI",
      "cs.NA",
      "hep-th",
      "stat.ML"
    ],
    "primary_category": "math.NA",
    "comment": "Accepted at NeurIPS 2024. Both authors contributed equally. Some\n  contents are omitted due to arXiv's storage limit. Please refer to the full\n  paper at OpenReview (NeurIPS 2024) or\n  https://github.com/TaikiMiyagawa/FunctionalPINN",
    "pdf_url": "http://arxiv.org/pdf/2410.18153v1",
    "published_date": "2024-10-23 06:16:35 UTC",
    "updated_date": "2024-10-23 06:16:35 UTC"
  },
  {
    "arxiv_id": "2410.17579v5",
    "title": "Bonsai: Gradient-free Graph Condensation for Node Classification",
    "authors": [
      "Mridul Gupta",
      "Samyak Jain",
      "Vansh Ramani",
      "Hariprasad Kodamana",
      "Sayan Ranu"
    ],
    "abstract": "Graph condensation has emerged as a promising avenue to enable scalable\ntraining of GNNs by compressing the training dataset while preserving essential\ngraph characteristics. Our study uncovers significant shortcomings in current\ngraph condensation techniques. First, the majority of the algorithms\nparadoxically require training on the full dataset to perform condensation.\nSecond, due to their gradient-emulating approach, these methods require fresh\ncondensation for any change in hyperparameters or GNN architecture, limiting\ntheir flexibility and reusability. Finally, they fail to achieve substantial\nsize reduction due to synthesizing fully-connected, edge-weighted graphs. To\naddress these challenges, we present Bonsai, a novel graph condensation method\nempowered by the observation that \\textit{computation trees} form the\nfundamental processing units of message-passing GNNs. Bonsai condenses datasets\nby encoding a careful selection of \\textit{exemplar} trees that maximize the\nrepresentation of all computation trees in the training set. This unique\napproach imparts Bonsai as the first linear-time, model-agnostic graph\ncondensation algorithm for node classification that outperforms existing\nbaselines across $7$ real-world datasets on accuracy, while being $22$ times\nfaster on average. Bonsai is grounded in rigorous mathematical guarantees on\nthe adopted approximation strategies making it robust to GNN architectures,\ndatasets, and parameters.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.17579v5",
    "published_date": "2024-10-23 06:08:45 UTC",
    "updated_date": "2025-03-26 05:50:10 UTC"
  },
  {
    "arxiv_id": "2410.17576v1",
    "title": "Real-time Vehicle-to-Vehicle Communication Based Network Cooperative Control System through Distributed Database and Multimodal Perception: Demonstrated in Crossroads",
    "authors": [
      "Xinwen Zhu",
      "Zihao Li",
      "Yuxuan Jiang",
      "Jiazhen Xu",
      "Jie Wang",
      "Xuyang Bai"
    ],
    "abstract": "The autonomous driving industry is rapidly advancing, with Vehicle-to-Vehicle\n(V2V) communication systems highlighting as a key component of enhanced road\nsafety and traffic efficiency. This paper introduces a novel Real-time\nVehicle-to-Vehicle Communication Based Network Cooperative Control System\n(VVCCS), designed to revolutionize macro-scope traffic planning and collision\navoidance in autonomous driving. Implemented on Quanser Car (Qcar) hardware\nplatform, our system integrates the distributed databases into individual\nautonomous vehicles and an optional central server. We also developed a\ncomprehensive multi-modal perception system with multi-objective tracking and\nradar sensing. Through a demonstration within a physical crossroad environment,\nour system showcases its potential to be applied in congested and complex urban\nenvironments.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO",
    "comment": "ICICT 2024, 18 pages",
    "pdf_url": "http://arxiv.org/pdf/2410.17576v1",
    "published_date": "2024-10-23 05:59:55 UTC",
    "updated_date": "2024-10-23 05:59:55 UTC"
  },
  {
    "arxiv_id": "2411.07243v1",
    "title": "Neuropsychology and Explainability of AI: A Distributional Approach to the Relationship Between Activation Similarity of Neural Categories in Synthetic Cognition",
    "authors": [
      "Michael Pichat",
      "Enola Campoli",
      "William Pogrund",
      "Jourdan Wilson",
      "Michael Veillet-Guillem",
      "Anton Melkozerov",
      "Paloma Pichat",
      "Armanush Gasparian",
      "Samuel Demarchi",
      "Judicael Poumay"
    ],
    "abstract": "We propose a neuropsychological approach to the explainability of artificial\nneural networks, which involves using concepts from human cognitive psychology\nas relevant heuristic references for developing synthetic explanatory\nframeworks that align with human modes of thought. The analogical concepts\nmobilized here, which are intended to create such an epistemological bridge,\nare those of categorization and similarity, as these notions are particularly\nsuited to the categorical \"nature\" of the reconstructive information processing\nperformed by artificial neural networks. Our study aims to reveal a unique\nprocess of synthetic cognition, that of the categorical convergence of highly\nactivated tokens. We attempt to explain this process with the idea that the\ncategorical segment created by a neuron is actually the result of a\nsuperposition of categorical sub-dimensions within its input vector space.",
    "categories": [
      "q-bio.NC",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "q-bio.NC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.07243v1",
    "published_date": "2024-10-23 05:27:09 UTC",
    "updated_date": "2024-10-23 05:27:09 UTC"
  },
  {
    "arxiv_id": "2410.17566v1",
    "title": "Differentially Private Learning Needs Better Model Initialization and Self-Distillation",
    "authors": [
      "Ivoline C. Ngong",
      "Joseph P. Near",
      "Niloofar Mireshghallah"
    ],
    "abstract": "Differentially private SGD (DPSGD) enables privacy-preserving training of\nlanguage models, but often reduces utility, diversity, and linguistic quality.\nWe introduce DPRefine, a three-phase method that initializes a model using data\nsynthesis from a small pre-trained LM with rigorous filtering, applies DP\nfinetuning on private data, and performs self-distillation to refine outputs.\nThis approach significantly outperforms vanilla DPSGD, with AlpacaEval\npreferring DPRefine's generations in 78.4% of cases across all datasets. Our\nanalysis reveals that DPRefine reduces linguistic errors in generated text by\n84.0%, mitigating grammar and spelling errors, commonly associated with DPSGD.\nIt also reduces inconsistencies of non-private models, such as hallucinated\ndetails and misattributed quotes. We find that small models like GPT-2 can be\neffective for initialization and distillation, highlighting their potential in\nenabling scalable and efficient deployment of privacy-preserving language.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "18 pages",
    "pdf_url": "http://arxiv.org/pdf/2410.17566v1",
    "published_date": "2024-10-23 05:19:51 UTC",
    "updated_date": "2024-10-23 05:19:51 UTC"
  },
  {
    "arxiv_id": "2410.17558v2",
    "title": "CLR-Bench: Evaluating Large Language Models in College-level Reasoning",
    "authors": [
      "Junnan Dong",
      "Zijin Hong",
      "Yuanchen Bei",
      "Feiran Huang",
      "Xinrun Wang",
      "Xiao Huang"
    ],
    "abstract": "Large language models (LLMs) have demonstrated their remarkable performance\nacross various language understanding tasks. While emerging benchmarks have\nbeen proposed to evaluate LLMs in various domains such as mathematics and\ncomputer science, they merely measure the accuracy in terms of the final\nprediction on multi-choice questions. However, it remains insufficient to\nverify the essential understanding of LLMs given a chosen choice. To fill this\ngap, we present CLR-Bench to comprehensively evaluate the LLMs in complex\ncollege-level reasoning. Specifically, (i) we prioritize 16 challenging college\ndisciplines in computer science and artificial intelligence. The dataset\ncontains 5 types of questions, while each question is associated with detailed\nexplanations from experts. (ii) To quantify a fair evaluation of LLMs'\nreasoning ability, we formalize the criteria with two novel metrics.\nQ$\\rightarrow$A is utilized to measure the performance of direct answer\nprediction, and Q$\\rightarrow$AR effectively considers the joint ability to\nanswer the question and provide rationale simultaneously. Extensive experiments\nare conducted with 40 LLMs over 1,018 discipline-specific questions. The\nresults demonstrate the key insights that LLMs, even the best closed-source\nLLM, i.e., GPT-4 turbo, tend to `guess' the college-level answers. It shows a\ndramatic decrease in accuracy from 63.31% Q$\\rightarrow$A to 39.00%\nQ$\\rightarrow$AR, indicating an unsatisfactory reasoning ability.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "18 pages, 6 figures, dataset and evaluation framework will be\n  opensourced",
    "pdf_url": "http://arxiv.org/pdf/2410.17558v2",
    "published_date": "2024-10-23 04:55:08 UTC",
    "updated_date": "2024-10-25 08:21:59 UTC"
  },
  {
    "arxiv_id": "2410.17555v1",
    "title": "FairDgcl: Fairness-aware Recommendation with Dynamic Graph Contrastive Learning",
    "authors": [
      "Wei Chen",
      "Meng Yuan",
      "Zhao Zhang",
      "Ruobing Xie",
      "Fuzhen Zhuang",
      "Deqing Wang",
      "Rui Liu"
    ],
    "abstract": "As trustworthy AI continues to advance, the fairness issue in recommendations\nhas received increasing attention. A recommender system is considered unfair\nwhen it produces unequal outcomes for different user groups based on\nuser-sensitive attributes (e.g., age, gender). Some researchers have proposed\ndata augmentation-based methods aiming at alleviating user-level unfairness by\naltering the skewed distribution of training data among various user groups.\nDespite yielding promising results, they often rely on fairness-related\nassumptions that may not align with reality, potentially reducing the data\nquality and negatively affecting model effectiveness. To tackle this issue, in\nthis paper, we study how to implement high-quality data augmentation to improve\nrecommendation fairness. Specifically, we propose FairDgcl, a dynamic graph\nadversarial contrastive learning framework aiming at improving fairness in\nrecommender system. First, FairDgcl develops an adversarial contrastive network\nwith a view generator and a view discriminator to learn generating fair\naugmentation strategies in an adversarial style. Then, we propose two dynamic,\nlearnable models to generate contrastive views within contrastive learning\nframework, which automatically fine-tune the augmentation strategies.\nMeanwhile, we theoretically show that FairDgcl can simultaneously generate\nenhanced representations that possess both fairness and accuracy. Lastly,\ncomprehensive experiments conducted on four real-world datasets demonstrate the\neffectiveness of the proposed FairDgcl.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "12 pages, submitted to TKDE",
    "pdf_url": "http://arxiv.org/pdf/2410.17555v1",
    "published_date": "2024-10-23 04:43:03 UTC",
    "updated_date": "2024-10-23 04:43:03 UTC"
  },
  {
    "arxiv_id": "2410.17546v2",
    "title": "Advancing Interpretability in Text Classification through Prototype Learning",
    "authors": [
      "Bowen Wei",
      "Ziwei Zhu"
    ],
    "abstract": "Deep neural networks have achieved remarkable performance in various\ntext-based tasks but often lack interpretability, making them less suitable for\napplications where transparency is critical. To address this, we propose\nProtoLens, a novel prototype-based model that provides fine-grained,\nsub-sentence level interpretability for text classification. ProtoLens uses a\nPrototype-aware Span Extraction module to identify relevant text spans\nassociated with learned prototypes and a Prototype Alignment mechanism to\nensure prototypes are semantically meaningful throughout training. By aligning\nthe prototype embeddings with human-understandable examples, ProtoLens provides\ninterpretable predictions while maintaining competitive accuracy. Extensive\nexperiments demonstrate that ProtoLens outperforms both prototype-based and\nnon-interpretable baselines on multiple text classification benchmarks. Code\nand data are available at\n\\url{https://anonymous.4open.science/r/ProtoLens-CE0B/}.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.17546v2",
    "published_date": "2024-10-23 03:53:46 UTC",
    "updated_date": "2024-10-24 04:21:54 UTC"
  },
  {
    "arxiv_id": "2410.17538v1",
    "title": "Primal-Dual Spectral Representation for Off-policy Evaluation",
    "authors": [
      "Yang Hu",
      "Tianyi Chen",
      "Na Li",
      "Kai Wang",
      "Bo Dai"
    ],
    "abstract": "Off-policy evaluation (OPE) is one of the most fundamental problems in\nreinforcement learning (RL) to estimate the expected long-term payoff of a\ngiven target policy with only experiences from another behavior policy that is\npotentially unknown. The distribution correction estimation (DICE) family of\nestimators have advanced the state of the art in OPE by breaking the curse of\nhorizon. However, the major bottleneck of applying DICE estimators lies in the\ndifficulty of solving the saddle-point optimization involved, especially with\nneural network implementations. In this paper, we tackle this challenge by\nestablishing a linear representation of value function and stationary\ndistribution correction ratio, i.e., primal and dual variables in the DICE\nframework, using the spectral decomposition of the transition operator. Such\nprimal-dual representation not only bypasses the non-convex non-concave\noptimization in vanilla DICE, therefore enabling an computational efficient\nalgorithm, but also paves the way for more efficient utilization of historical\ndata. We highlight that our algorithm, SpectralDICE, is the first to leverage\nthe linear representation of primal-dual variables that is both computation and\nsample efficient, the performance of which is supported by a rigorous\ntheoretical sample complexity guarantee and a thorough empirical evaluation on\nvarious benchmarks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC"
    ],
    "primary_category": "cs.LG",
    "comment": "29 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.17538v1",
    "published_date": "2024-10-23 03:38:31 UTC",
    "updated_date": "2024-10-23 03:38:31 UTC"
  },
  {
    "arxiv_id": "2410.17532v1",
    "title": "Responsible Multilingual Large Language Models: A Survey of Development, Applications, and Societal Impact",
    "authors": [
      "Junhua Liu",
      "Bin Fu"
    ],
    "abstract": "Multilingual Large Language Models (MLLMs) represent a pivotal advancement in\ndemocratizing artificial intelligence across linguistic boundaries. While\ntheoretical foundations are well-established, practical implementation\nguidelines remain scattered. This work bridges this gap by providing a\ncomprehensive end-to-end framework for developing and deploying MLLMs in\nproduction environments. We make three distinctive contributions: First, we\npresent an actionable pipeline from data pre-processing through deployment,\nintegrating insights from academic research and industrial applications.\nSecond, using Llama2 as a case study, we provide detailed optimization\nstrategies for enhancing multilingual capabilities, including curriculum\nlearning approaches for balancing high-resource and low-resource languages,\ntokenization strategies, and effective sampling methods. Third, we offer an\ninterdisciplinary analysis that considers technical, linguistic, and cultural\nperspectives in MLLM development. Our findings reveal critical challenges in\nsupporting linguistic diversity, with 88.38% of world languages categorized as\nlow-resource, affecting over a billion speakers. We examine practical solutions\nthrough real-world applications in customer service, search engines, and\nmachine translation. By synthesizing theoretical frameworks with\nproduction-ready implementation strategies, this survey provides essential\nguidance for practitioners and researchers working to develop more inclusive\nand effective multilingual AI systems.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.17532v1",
    "published_date": "2024-10-23 03:19:15 UTC",
    "updated_date": "2024-10-23 03:19:15 UTC"
  },
  {
    "arxiv_id": "2410.17517v2",
    "title": "Bridging Swarm Intelligence and Reinforcement Learning",
    "authors": [
      "Karthik Soma",
      "Yann Bouteiller",
      "Heiko Hamann",
      "Giovanni Beltrame"
    ],
    "abstract": "Swarm intelligence (SI) explores how large groups of simple individuals\n(e.g., insects, fish, birds) collaborate to produce complex behaviors,\nexemplifying that the whole is greater than the sum of its parts. A fundamental\ntask in SI is Collective Decision-Making (CDM), where a group selects the best\noption among several alternatives, such as choosing an optimal foraging site.\nIn this work, we demonstrate a theoretical and empirical equivalence between\nCDM and single-agent reinforcement learning (RL) in multi-armed bandit\nproblems, utilizing concepts from opinion dynamics, evolutionary game theory,\nand RL. This equivalence bridges the gap between SI and RL and leads us to\nintroduce a novel abstract RL update rule called Maynard-Cross Learning.\nAdditionally, it provides a new population-based perspective on common RL\npractices like learning rate adjustment and batching. Our findings enable\ncross-disciplinary fertilization between RL and SI, allowing techniques from\none field to enhance the understanding and methodologies of the other.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.GT"
    ],
    "primary_category": "cs.MA",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.17517v2",
    "published_date": "2024-10-23 02:49:37 UTC",
    "updated_date": "2025-01-17 21:38:41 UTC"
  },
  {
    "arxiv_id": "2410.17511v1",
    "title": "Time and Frequency Synergy for Source-Free Time-Series Domain Adaptations",
    "authors": [
      "Muhammad Tanzil Furqon",
      "Mahardhika Pratama",
      "Ary Mazharuddin Shiddiqi",
      "Lin Liu",
      "Habibullah Habibullah",
      "Kutluyil Dogancay"
    ],
    "abstract": "The issue of source-free time-series domain adaptations still gains scarce\nresearch attentions. On the other hand, existing approaches rely solely on\ntime-domain features ignoring frequency components providing complementary\ninformation. This paper proposes Time Frequency Domain Adaptation (TFDA), a\nmethod to cope with the source-free time-series domain adaptation problems.\nTFDA is developed with a dual branch network structure fully utilizing both\ntime and frequency features in delivering final predictions. It induces\npseudo-labels based on a neighborhood concept where predictions of a sample\ngroup are aggregated to generate reliable pseudo labels. The concept of\ncontrastive learning is carried out in both time and frequency domains with\npseudo label information and a negative pair exclusion strategy to make valid\nneighborhood assumptions. In addition, the time-frequency consistency technique\nis proposed using the self-distillation strategy while the uncertainty\nreduction strategy is implemented to alleviate uncertainties due to the domain\nshift problem. Last but not least, the curriculum learning strategy is\nintegrated to combat noisy pseudo labels. Our experiments demonstrate the\nadvantage of our approach over prior arts with noticeable margins in benchmark\nproblems.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.17511v1",
    "published_date": "2024-10-23 02:29:50 UTC",
    "updated_date": "2024-10-23 02:29:50 UTC"
  },
  {
    "arxiv_id": "2410.17510v1",
    "title": "Congestion Forecast for Trains with Railroad-Graph-based Semi-Supervised Learning using Sparse Passenger Reports",
    "authors": [
      "Soto Anno",
      "Kota Tsubouchi",
      "Masamichi Shimosaka"
    ],
    "abstract": "Forecasting rail congestion is crucial for efficient mobility in transport\nsystems. We present rail congestion forecasting using reports from passengers\ncollected through a transit application. Although reports from passengers have\nreceived attention from researchers, ensuring a sufficient volume of reports is\nchallenging due to passenger's reluctance. The limited number of reports\nresults in the sparsity of the congestion label, which can be an issue in\nbuilding a stable prediction model. To address this issue, we propose a\nsemi-supervised method for congestion forecasting for trains, or SURCONFORT.\nOur key idea is twofold: firstly, we adopt semi-supervised learning to leverage\nsparsely labeled data and many unlabeled data. Secondly, in order to complement\nthe unlabeled data from nearby stations, we design a railway network-oriented\ngraph and apply the graph to semi-supervised graph regularization. Empirical\nexperiments with actual reporting data show that SURCONFORT improved the\nforecasting performance by 14.9% over state-of-the-art methods under the label\nsparsity.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted in ACM SIGSPATIAL 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.17510v1",
    "published_date": "2024-10-23 02:25:53 UTC",
    "updated_date": "2024-10-23 02:25:53 UTC"
  },
  {
    "arxiv_id": "2410.17506v1",
    "title": "Mitigating Graph Covariate Shift via Score-based Out-of-distribution Augmentation",
    "authors": [
      "Bohan Wang",
      "Yurui Chang",
      "Lu Lin"
    ],
    "abstract": "Distribution shifts between training and testing datasets significantly\nimpair the model performance on graph learning. A commonly-taken causal view in\ngraph invariant learning suggests that stable predictive features of graphs are\ncausally associated with labels, whereas varying environmental features lead to\ndistribution shifts. In particular, covariate shifts caused by unseen\nenvironments in test graphs underscore the critical need for\nout-of-distribution (OOD) generalization. Existing graph augmentation methods\ndesigned to address the covariate shift often disentangle the stable and\nenvironmental features in the input space, and selectively perturb or mixup the\nenvironmental features. However, such perturbation-based methods heavily rely\non an accurate separation of stable and environmental features, and their\nexploration ability is confined to existing environmental features in the\ntraining distribution. To overcome these limitations, we introduce a novel\napproach using score-based graph generation strategies that synthesize unseen\nenvironmental features while preserving the validity and stable features of\noverall graph patterns. Our comprehensive empirical evaluations demonstrate the\nenhanced effectiveness of our method in improving graph OOD generalization.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "17 pages, 5 figures, 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2410.17506v1",
    "published_date": "2024-10-23 02:09:02 UTC",
    "updated_date": "2024-10-23 02:09:02 UTC"
  },
  {
    "arxiv_id": "2410.17504v1",
    "title": "An Ontology-Enabled Approach For User-Centered and Knowledge-Enabled Explanations of AI Systems",
    "authors": [
      "Shruthi Chari"
    ],
    "abstract": "Explainable Artificial Intelligence (AI) focuses on helping humans understand\nthe working of AI systems or their decisions and has been a cornerstone of AI\nfor decades. Recent research in explainability has focused on explaining the\nworkings of AI models or model explainability. There have also been several\nposition statements and review papers detailing the needs of end-users for\nuser-centered explainability but fewer implementations. Hence, this thesis\nseeks to bridge some gaps between model and user-centered explainability. We\ncreate an explanation ontology (EO) to represent literature-derived explanation\ntypes via their supporting components. We implement a knowledge-augmented\nquestion-answering (QA) pipeline to support contextual explanations in a\nclinical setting. Finally, we are implementing a system to combine explanations\nfrom different AI methods and data modalities. Within the EO, we can represent\nfifteen different explanation types, and we have tested these representations\nin six exemplar use cases. We find that knowledge augmentations improve the\nperformance of base large language models in the contextualized QA, and the\nperformance is variable across disease groups. In the same setting, clinicians\nalso indicated that they prefer to see actionability as one of the main foci in\nexplanations. In our explanations combination method, we plan to use similarity\nmetrics to determine the similarity of explanations in a chronic disease\ndetection setting. Overall, through this thesis, we design methods that can\nsupport knowledge-enabled explanations across different use cases, accounting\nfor the methods in today's AI era that can generate the supporting components\nof these explanations and domain knowledge sources that can enhance them.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Doctoral dissertation. Some chapters appeared as individual papers -\n  arXiv:2302.05752 is one such chapters",
    "pdf_url": "http://arxiv.org/pdf/2410.17504v1",
    "published_date": "2024-10-23 02:03:49 UTC",
    "updated_date": "2024-10-23 02:03:49 UTC"
  },
  {
    "arxiv_id": "2410.17500v2",
    "title": "Learning Fair and Preferable Allocations through Neural Network",
    "authors": [
      "Ryota Maruo",
      "Koh Takeuchi",
      "Hisashi Kashima"
    ],
    "abstract": "The fair allocation of indivisible resources is a fundamental problem.\nExisting research has developed various allocation mechanisms or algorithms to\nsatisfy different fairness notions. For example, round robin (RR) was proposed\nto meet the fairness criterion known as envy-freeness up to one good (EF1).\nExpert algorithms without mathematical formulations are used in real-world\nresource allocation problems to find preferable outcomes for users. Therefore,\nwe aim to design mechanisms that strictly satisfy good properties with\nreplicating expert knowledge. However, this problem is challenging because such\nheuristic rules are often difficult to formalize mathematically, complicating\ntheir integration into theoretical frameworks. Additionally, formal algorithms\nstruggle to find preferable outcomes, and directly replicating these implicit\nrules can result in unfair allocations because human decision-making can\nintroduce biases. In this paper, we aim to learn implicit allocation mechanisms\nfrom examples while strictly satisfying fairness constraints, specifically\nfocusing on learning EF1 allocation mechanisms through supervised learning on\nexamples of reported valuations and corresponding allocation outcomes produced\nby implicit rules. To address this, we developed a neural RR (NRR), a novel\nneural network that parameterizes RR. NRR is built from a differentiable\nrelaxation of RR and can be trained to learn the agent ordering used for RR. We\nconducted experiments to learn EF1 allocation mechanisms from examples,\ndemonstrating that our method outperforms baselines in terms of the proximity\nof predicted allocations and other metrics.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.17500v2",
    "published_date": "2024-10-23 01:47:55 UTC",
    "updated_date": "2025-05-12 01:43:06 UTC"
  },
  {
    "arxiv_id": "2410.17498v1",
    "title": "Mechanisms of Symbol Processing for In-Context Learning in Transformer Networks",
    "authors": [
      "Paul Smolensky",
      "Roland Fernandez",
      "Zhenghao Herbert Zhou",
      "Mattia Opper",
      "Jianfeng Gao"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated impressive abilities in symbol\nprocessing through in-context learning (ICL). This success flies in the face of\ndecades of predictions that artificial neural networks cannot master abstract\nsymbol manipulation. We seek to understand the mechanisms that can enable\nrobust symbol processing in transformer networks, illuminating both the\nunanticipated success, and the significant limitations, of transformers in\nsymbol processing. Borrowing insights from symbolic AI on the power of\nProduction System architectures, we develop a high-level language, PSL, that\nallows us to write symbolic programs to do complex, abstract symbol processing,\nand create compilers that precisely implement PSL programs in transformer\nnetworks which are, by construction, 100% mechanistically interpretable. We\ndemonstrate that PSL is Turing Universal, so the work can inform the\nunderstanding of transformer ICL in general. The type of transformer\narchitecture that we compile from PSL programs suggests a number of paths for\nenhancing transformers' capabilities at symbol processing. (Note: The first\nsection of the paper gives an extended synopsis of the entire paper.)",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.NE",
      "cs.SC",
      "F.1; I.2"
    ],
    "primary_category": "cs.AI",
    "comment": "101 pages (including 30 pages of Appendices), 18 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.17498v1",
    "published_date": "2024-10-23 01:38:10 UTC",
    "updated_date": "2024-10-23 01:38:10 UTC"
  },
  {
    "arxiv_id": "2410.17489v1",
    "title": "Unsupervised Domain Adaptation for Action Recognition via Self-Ensembling and Conditional Embedding Alignment",
    "authors": [
      "Indrajeet Ghosh",
      "Garvit Chugh",
      "Abu Zaher Md Faridee",
      "Nirmalya Roy"
    ],
    "abstract": "Recent advancements in deep learning-based wearable human action recognition\n(wHAR) have improved the capture and classification of complex motions, but\nadoption remains limited due to the lack of expert annotations and domain\ndiscrepancies from user variations. Limited annotations hinder the model's\nability to generalize to out-of-distribution samples. While data augmentation\ncan improve generalizability, unsupervised augmentation techniques must be\napplied carefully to avoid introducing noise. Unsupervised domain adaptation\n(UDA) addresses domain discrepancies by aligning conditional distributions with\nlabeled target samples, but vanilla pseudo-labeling can lead to error\npropagation. To address these challenges, we propose $\\mu$DAR, a novel joint\noptimization architecture comprised of three functions: (i) consistency\nregularizer between augmented samples to improve model classification\ngeneralizability, (ii) temporal ensemble for robust pseudo-label generation and\n(iii) conditional distribution alignment to improve domain generalizability.\nThe temporal ensemble works by aggregating predictions from past epochs to\nsmooth out noisy pseudo-label predictions, which are then used in the\nconditional distribution alignment module to minimize kernel-based class-wise\nconditional maximum mean discrepancy ($k$CMMD) between the source and target\nfeature space to learn a domain invariant embedding. The\nconsistency-regularized augmentations ensure that multiple augmentations of the\nsame sample share the same labels; this results in (a) strong generalization\nwith limited source domain samples and (b) consistent pseudo-label generation\nin target samples. The novel integration of these three modules in $\\mu$DAR\nresults in a range of $\\approx$ 4-12% average macro-F1 score improvement over\nsix state-of-the-art UDA methods in four benchmark wHAR datasets",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "This work has been accepted to the Proceedings of the IEEE\n  International Conference on Data Mining, 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.17489v1",
    "published_date": "2024-10-23 00:59:27 UTC",
    "updated_date": "2024-10-23 00:59:27 UTC"
  },
  {
    "arxiv_id": "2410.17481v1",
    "title": "AI, Global Governance, and Digital Sovereignty",
    "authors": [
      "Swati Srivastava",
      "Justin Bullock"
    ],
    "abstract": "This essay examines how Artificial Intelligence (AI) systems are becoming\nmore integral to international affairs by affecting how global governors exert\npower and pursue digital sovereignty. We first introduce a taxonomy of\nmultifaceted AI payoffs for governments and corporations related to\ninstrumental, structural, and discursive power in the domains of violence,\nmarkets, and rights. We next leverage different institutional and practice\nperspectives on sovereignty to assess how digital sovereignty is variously\nimplicated in AI-empowered global governance. States both seek sovereign\ncontrol over AI infrastructures in the institutional approach, while\nestablishing sovereign competence through AI infrastructures in the practice\napproach. Overall, we present the digital sovereignty stakes of AI as related\nto entanglements of public and private power. Rather than foreseeing technology\ncompanies as replacing states, we argue that AI systems will embed in global\ngovernance to create dueling dynamics of public/private cooperation and\ncontestation. We conclude with sketching future directions for IR research on\nAI and global governance.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "21 pages, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2410.17481v1",
    "published_date": "2024-10-23 00:05:33 UTC",
    "updated_date": "2024-10-23 00:05:33 UTC"
  },
  {
    "arxiv_id": "2410.18148v3",
    "title": "Beyond the Kolmogorov Barrier: A Learnable Weighted Hybrid Autoencoder for Model Order Reduction",
    "authors": [
      "Nithin Somasekharan",
      "Shaowu Pan"
    ],
    "abstract": "Representation learning for high-dimensional, complex physical systems aims\nto identify a low-dimensional intrinsic latent space, which is crucial for\nreduced-order modeling and modal analysis. To overcome the well-known\nKolmogorov barrier, deep autoencoders (AEs) have been introduced in recent\nyears, but they often suffer from poor convergence behavior as the rank of the\nlatent space increases. To address this issue, we propose the learnable\nweighted hybrid autoencoder, a hybrid approach that combines the strengths of\nsingular value decomposition (SVD) with deep autoencoders through a learnable\nweighted framework. We find that the introduction of learnable weighting\nparameters is essential -- without them, the resulting model would either\ncollapse into a standard POD or fail to exhibit the desired convergence\nbehavior. Interestingly, we empirically find that our trained model has a\nsharpness thousands of times smaller compared to other models. Our experiments\non classical chaotic PDE systems, including the 1D Kuramoto-Sivashinsky and\nforced isotropic turbulence datasets, demonstrate that our approach\nsignificantly improves generalization performance compared to several competing\nmethods. Additionally, when combining with time series modeling techniques\n(e.g., Koopman operator, LSTM), the proposed technique offers significant\nimprovements for surrogate modeling of high-dimensional multi-scale PDE\nsystems.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.comp-ph",
      "stat.ML",
      "68T07, 76F99"
    ],
    "primary_category": "cs.LG",
    "comment": "31 pages",
    "pdf_url": "http://arxiv.org/pdf/2410.18148v3",
    "published_date": "2024-10-23 00:04:26 UTC",
    "updated_date": "2025-02-28 17:12:31 UTC"
  }
]