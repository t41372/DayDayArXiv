{
  "date": "2025-01-23",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-01-23 的 arXiv 中文 TLDR 快报！今天的论文主要聚焦于 AI 模型优化、LLM 在代码生成和医疗领域的创新应用、图像处理技术以及量子计算的进展，其中“Communicating Activations Between Language Model Agents”这类文章因其在 LLM 通信机制上的突破性贡献和潜在话题度值得关注，同时一些知名机构如 NVIDIA 或 AAAI 相关论文展示了高影响力。\n\n下面，我将逐一简要概述部分关键论文，先优先讨论 LLM 和 AI 安全领域的创新性工作，再涉及图像处理和相关主题。对于其他较常规或不那么突出的论文（如一些纯理论优化或小众应用），我将快速掠过，只列出标题和核心点，以控制篇幅。\n\n### LLM 和 AI 应用创新\n- **Querying Databases with Function Calling (查询数据库的函数调用)**  \n  这篇论文探讨了大型语言模型 (LLMs) 通过函数调用查询数据库的方法，测试了 8 个模型家族的性能。贡献：提出统一工具定义，支持搜索和聚合操作，Claude 3.5 Sonnet 达到 74.3% 的精确匹配率，发现模型在布尔属性上表现强，但在文本过滤上较弱。发现：LLMs 在数据库查询中有效，但需优化文本处理。\n\n- **Mining Social Determinants of Health for Heart Failure Patient 30-Day Readmission via Large Language Model (通过 LLM 挖掘社会健康决定因素以预测心力衰竭患者 30 天再入院)**  \n  作者包括 Carl Yang。贡献：使用 LLMs 从临床笔记中提取社会健康决定因素（如烟草使用和交通限制），并通过逻辑回归分析其与再入院风险的关联。发现：识别关键因素可提供减少再入院的可操作见解，提升患者护理。\n\n- **MedSlice: Fine-Tuned Large Language Models for Secure Clinical Note Sectioning (针对安全临床笔记分割的微调 LLMs)**  \n  贡献：微调开源 LLMs（如 Llama 3.1 8B）来提取临床笔记的部分，超越 GPT-4o 的 F1 分数（0.92 vs. 0.85）。发现：开源模型在成本和性能上更具优势，适用于隐私敏感的医疗任务。\n\n- **The Role of Generative AI in Software Student CollaborAItion (生成式 AI 在软件学生协作中的作用)**  \n  作者包括 Armando Fox。贡献：探讨 AI 代理在教育协作中的角色，提供场景和挑战分析。发现：AI 可增强协作，但需考虑新可能性和风险。\n\n- **Communicating Activations Between Language Model Agents (语言模型代理之间的激活通信)**  \n  贡献：提出通过激活通信（而非自然语言）提升 LLM 代理的推理能力，节省计算资源。发现：在多代理协调和推理基准上，改进率高达 27%，计算量不到自然语言的 1/4。\n\n- **Can We Generate Images with CoT? Let's Verify and Reinforce Image Generation Step by Step (我们能用 CoT 生成图像吗？逐步验证和强化图像生成)**  \n  贡献：将 Chain-of-Thought 用于图像生成，引入 Potential Assessment Reward Model (PARM) 以评估生成步骤。发现：在 GenEval 基准上提升 24%，超越 Stable Diffusion 3。\n\n- **Temporal Preference Optimization for Long-Form Video Understanding (针对长视频理解的时序偏好优化)**  \n  贡献：使用偏好优化提升视频 LLM 的时序推理能力。发现：在长视频基准上显著改进分类和检索性能。\n\n- **CRPO: Confidence-Reward Driven Preference Optimization for Machine Translation (置信度-奖励驱动的偏好优化用于机器翻译)**  \n  贡献：结合置信度和奖励分数优化 LLM 翻译数据选择。发现：超越现有方法，在翻译准确性和数据效率上表现更好。\n\n这些 LLM 相关论文突出了模型在代码生成、医疗和视频理解中的潜力，但也暴露了鲁棒性和数据隐私的挑战，值得进一步探索。\n\n### AI 安全和鲁棒性\n- **GraphRAG under Fire (GraphRAG 面临攻击)**  \n  贡献：分析 GraphRAG 的抗攻击性，提出 GRAGPoison 方法利用知识图谱关系注入恶意内容。发现：攻击成功率高达 98%，强调需要更强的防御措施。\n\n- **Towards Robust Multimodal Open-set Test-time Adaptation via Adaptive Entropy-aware Optimization (通过自适应熵感知优化实现鲁棒的多模态开放集测试时适应)**  \n  贡献：提出 AEO 框架提升多模态模型的鲁棒性。发现：在多模态基准上分类准确率提升 40%，适用于真实场景。\n\n这些论文强调了 AI 系统的安全性和鲁棒性改进，对于实际部署至关重要。\n\n### 图像处理和生成\n- **Fast3R: Towards 3D Reconstruction of 1000+ Images in One Forward Pass (Fast3R: 一次性前向传播实现 1000+ 图像的 3D 重建)**  \n  贡献：扩展 DUSt3R 模型，支持并行多视图 3D 重建。发现：显著提升重建速度和准确性，适用于大规模应用。\n\n- **Revisiting CLIP: Efficient Alignment of 3D MRI and Tabular Data using Domain-Specific Foundation Models (重新审视 CLIP: 使用领域特定基础模型高效对齐 3D MRI 和表格数据)**  \n  贡献：使用领域模型对齐 3D MRI 和表格数据，仅需 62 张扫描图像。发现：在零样本分类上表现优秀，改进模态对齐。\n\n- **PointOBB-v3: Expanding Performance Boundaries of Single Point-Supervised Oriented Object Detection (PointOBB-v3: 扩展单点监督定向物体检测的性能边界)**  \n  贡献：提出新模块提升点监督下的物体检测准确性。发现：在多个数据集上准确率平均提升 3.56%。\n\n其他图像相关论文，如“Autonomous Structural Memory Manipulation for Large Language Models Using Hierarchical Embedding Augmentation”（自主结构记忆操作用于 LLM 的分层嵌入增强），主要贡献在于提升图像生成效率，但细节较常规，故快速掠过：该论文探索分层嵌入增强图像任务的适应性，发现显著减少处理开销。\n\n### 其他快速掠过\n其余论文涉及量子计算（如“On the Transfer of Knowledge in Quantum Algorithms”）、强化学习（如“Reinforcement Learning Platform for Adversarial Black-box Attacks”）和医疗应用（如“Extractive Schema Linking for Text-to-SQL”），这些领域有稳健进展，但非今日焦点。其中，“Document-Level Sentiment Analysis of Urdu Text Using Deep Learning Techniques”（Urdu 文本的文档级情感分析）等语言处理论文展示了在资源匮乏语言上的深度学习应用，提升了 83% 准确率；“Efficient Synaptic Delay Implementation in Digital Event-Driven AI Accelerators”（高效突触延迟实现）优化了神经网络硬件，但细节较技术化，故仅简述核心贡献。\n\n总之，今天的论文突出了 AI 领域的快速迭代，尤其在 LLM 应用和安全上，读者可关注相关创新以探索实际落地潜力。更多细节请查阅 arXiv！",
  "papers": [
    {
      "arxiv_id": "2502.00032v1",
      "title": "Querying Databases with Function Calling",
      "title_zh": "翻译失败",
      "authors": [
        "Connor Shorten",
        "Charles Pierse",
        "Thomas Benjamin Smith",
        "Karel D'Oosterlinck",
        "Tuana Celik",
        "Erika Cardenas",
        "Leonie Monigatti",
        "Mohd Shukri Hasan",
        "Edward Schmuhl",
        "Daniel Williams",
        "Aravind Kesiraju",
        "Bob van Luijt"
      ],
      "abstract": "The capabilities of Large Language Models (LLMs) are rapidly accelerating\nlargely thanks to their integration with external tools. Querying databases is\namong the most effective of these integrations, enabling LLMs to access private\nor continually updating data. While Function Calling is the most common method\nfor interfacing external tools to LLMs, its application to database querying as\na tool has been underexplored. We propose a tool definition for database\nquerying that unifies accessing data with search queries, filters, or a\ncombination both, as well as transforming results with aggregation and groupby\noperators. To evaluate its effectiveness, we conduct a study with 8 LLMs\nspanning 5 model families. We present a novel pipeline adapting the Gorilla LLM\nframework to create synthetic database schemas and queries. We primarily\nevaluate the models with the Exact Match of predicted and ground truth query\nAPIs. Among the models tested, Claude 3.5 Sonnet achieves the highest\nperformance with an Exact Match score of 74.3%, followed by GPT-4o mini at\n73.7%, and GPT-4o at 71.8%. We further breakdown these results per API\ncomponent utilized and across synthetic use cases. We find that LLMs are highly\neffective at utilizing operators on boolean properties, but struggle with text\nproperty filters. Across use cases we find robust results with the higher\nperforming models such as GPT-4o, but significant performance variance across\nuse cases from lower performing models. We additionally conduct ablation\nstudies exploring the impact of parallel tool calling, adding a rationale as an\nargument of the tool call, using a separate tool per database collection, and\ntool calling with structured outputs. Our findings demonstrate the\neffectiveness of enabling LLMs to query databases with Function Calling. We\nhave open-sourced our experimental code and results at\ngithub.com/weaviate/gorilla.",
      "tldr_zh": "本文提出了一种统一的工具定义，使用Function Calling来实现大型语言模型（LLMs）对数据库的查询，包括搜索、过滤、聚合和分组操作，以增强LLMs访问私有或动态数据的能力。研究通过一个基于Gorilla LLM框架的合成管道，对8个LLMs进行了评估，结果显示Claude 3.5 Sonnet以74.3%的Exact Match分数表现最佳，而LLMs在布尔属性操作上表现出色，但在文本属性过滤上存在困难。进一步的消融研究探讨了并行工具调用、添加理由等因素，并开源了实验代码，证明了这一方法的有效性。",
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.DB",
      "comment": "Preprint. 23 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.00032v1",
      "published_date": "2025-01-23 23:09:13 UTC",
      "updated_date": "2025-01-23 23:09:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:12:15.692025"
    },
    {
      "arxiv_id": "2502.12158v1",
      "title": "Mining Social Determinants of Health for Heart Failure Patient 30-Day Readmission via Large Language Model",
      "title_zh": "翻译失败",
      "authors": [
        "Mingchen Shao",
        "Youjeong Kang",
        "Xiao Hu",
        "Hyunjung Gloria Kwak",
        "Carl Yang",
        "Jiaying Lu"
      ],
      "abstract": "Heart Failure (HF) affects millions of Americans and leads to high\nreadmission rates, posing significant healthcare challenges. While Social\nDeterminants of Health (SDOH) such as socioeconomic status and housing\nstability play critical roles in health outcomes, they are often\nunderrepresented in structured EHRs and hidden in unstructured clinical notes.\nThis study leverages advanced large language models (LLMs) to extract SDOHs\nfrom clinical text and uses logistic regression to analyze their association\nwith HF readmissions. By identifying key SDOHs (e.g. tobacco usage, limited\ntransportation) linked to readmission risk, this work also offers actionable\ninsights for reducing readmissions and improving patient care.",
      "tldr_zh": "本研究利用大型语言模型 (LLMs) 从临床文本中提取社会健康决定因素 (SDOH)，以分析其与心力衰竭 (HF) 患者30天再入院的关系。研究者采用logistic regression方法，识别出关键SDOH（如tobacco usage和limited transportation）与再入院风险的显著关联。最终，该工作提供了可操作的见解，帮助降低再入院率并提升患者护理质量。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.12158v1",
      "published_date": "2025-01-23 23:05:53 UTC",
      "updated_date": "2025-01-23 23:05:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:12:26.304854"
    },
    {
      "arxiv_id": "2501.14122v2",
      "title": "Reinforcement Learning Platform for Adversarial Black-box Attacks with Custom Distortion Filters",
      "title_zh": "翻译失败",
      "authors": [
        "Soumyendu Sarkar",
        "Ashwin Ramesh Babu",
        "Sajad Mousavi",
        "Vineet Gundecha",
        "Sahand Ghorbanpour",
        "Avisek Naug",
        "Ricardo Luna Gutierrez",
        "Antonio Guillen"
      ],
      "abstract": "We present a Reinforcement Learning Platform for Adversarial Black-box\nuntargeted and targeted attacks, RLAB, that allows users to select from various\ndistortion filters to create adversarial examples. The platform uses a\nReinforcement Learning agent to add minimum distortion to input images while\nstill causing misclassification by the target model. The agent uses a novel\ndual-action method to explore the input image at each step to identify\nsensitive regions for adding distortions while removing noises that have less\nimpact on the target model. This dual action leads to faster and more efficient\nconvergence of the attack. The platform can also be used to measure the\nrobustness of image classification models against specific distortion types.\nAlso, retraining the model with adversarial samples significantly improved\nrobustness when evaluated on benchmark datasets. The proposed platform\noutperforms state-of-the-art methods in terms of the average number of queries\nrequired to cause misclassification. This advances trustworthiness with a\npositive social impact.",
      "tldr_zh": "我们提出了一种名为 RLAB 的强化学习平台，用于对抗性黑-box 攻击，支持无目标和有目标攻击，并允许用户选择自定义 distortion filters 来生成对抗样本。该平台采用强化学习代理和新型 dual-action method，通过探索图像敏感区域添加最小扭曲并移除无关噪声，实现更快速高效的攻击收敛。实验结果表明，RLAB 在导致目标模型误分类的平均查询次数上优于现有 state-of-the-art 方法，且通过对抗样本重新训练，显著提升了图像分类模型的鲁棒性。该平台有助于评估模型对特定扭曲类型的抗性，并推动模型 trustworthiness 的社会影响。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at the 2025 AAAI Conference on Artificial Intelligence\n  Proceedings",
      "pdf_url": "http://arxiv.org/pdf/2501.14122v2",
      "published_date": "2025-01-23 22:36:06 UTC",
      "updated_date": "2025-04-15 08:15:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:12:38.394903"
    },
    {
      "arxiv_id": "2501.14120v1",
      "title": "On the Transfer of Knowledge in Quantum Algorithms",
      "title_zh": "翻译失败",
      "authors": [
        "Esther Villar-Rodriguez",
        "Eneko Osaba",
        "Izaskun Oregi",
        "Sebastián V. Romero",
        "Julián Ferreiro-Vélez"
      ],
      "abstract": "The field of quantum computing is generating significant anticipation within\nthe scientific and industrial communities due to its potential to revolutionize\ncomputing paradigms. Recognizing this potential, this paper explores the\nintegration of transfer of knowledge techniques, traditionally used in\nclassical artificial intelligence, into quantum computing. We present a\ncomprehensive classification of the transfer models, focusing on Transfer\nLearning and Transfer Optimization. Additionally, we analyze relevant schemes\nin quantum computing that can benefit from knowledge sharing, and we delve into\nthe potential synergies, supported by theoretical insights and initial\nexperimental results. Our findings suggest that leveraging the transfer of\nknowledge can enhance the efficiency and effectiveness of quantum algorithms,\nparticularly in the context of hybrid solvers. This approach not only\naccelerates the optimization process but also reduces the computational burden\non quantum processors, making it a valuable tool for advancing quantum\ncomputing technologies.",
      "tldr_zh": "这篇论文探讨了将知识转移技术从经典人工智能引入量子计算领域，以提升量子算法的效率。作者对知识转移模型进行了全面分类，重点关注Transfer Learning和Transfer Optimization，并分析了量子计算中可受益于知识共享的方案。论文通过理论见解和初步实验结果证明，这种方法能显著加速优化过程，减轻量子处理器的计算负担，尤其适用于混合求解器，从而推动量子计算技术的进步。",
      "categories": [
        "quant-ph",
        "cs.AI"
      ],
      "primary_category": "quant-ph",
      "comment": "12 pages, 8 figures, 4 tables. Paper submitted for its review in\n  Expert Systems journal",
      "pdf_url": "http://arxiv.org/pdf/2501.14120v1",
      "published_date": "2025-01-23 22:21:32 UTC",
      "updated_date": "2025-01-23 22:21:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:12:48.597909"
    },
    {
      "arxiv_id": "2501.14119v1",
      "title": "Autonomous Structural Memory Manipulation for Large Language Models Using Hierarchical Embedding Augmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Derek Yotheringhay",
        "Alistair Kirkland",
        "Humphrey Kirkbride",
        "Josiah Whitesteeple"
      ],
      "abstract": "Transformative innovations in model architectures have introduced\nhierarchical embedding augmentation as a means to redefine the representation\nof tokens through multi-level semantic structures, offering enhanced\nadaptability to complex linguistic inputs. Autonomous structural memory\nmanipulation further advances this paradigm through dynamic memory reallocation\nmechanisms that prioritize critical contextual features while suppressing less\nrelevant information, enabling scalable and efficient performance across\ndiverse tasks. Experimental results reveal substantial improvements in\ncomputational efficiency, with marked reductions in processing overhead for\nlonger input sequences, achieved through memory reorganization strategies that\nadapt to evolving contextual requirements. Hierarchical embeddings not only\nimproved contextual alignment but also facilitated task generalization by\ncapturing relationships at varying semantic granularities, ensuring coherence\nacross layers without introducing significant computational redundancies.\nComparative analysis against baseline models demonstrated unique advantages in\naccuracy, efficiency, and interpretability, particularly in tasks requiring\ncomplex contextual understanding or domain-specific adaptability. The ability\nto dynamically adjust token representations and memory configurations\ncontributed to the model's robustness under varied and unpredictable input\nconditions. Applications benefiting from these advancements include\nmulti-domain generalization, interactive systems, and scenarios involving\nreal-time decision-making, where traditional static memory architectures often\nface limitations. The proposed methodology combines advanced embedding and\nmemory management strategies into a cohesive framework that addresses\nscalability challenges while preserving task-specific relevance.",
      "tldr_zh": "该论文提出了一种自主结构内存操作（Autonomous structural memory manipulation）方法，结合 hierarchical embedding augmentation 来提升大型语言模型的性能，通过多级语义结构动态重新定义 token 表示，并优先处理关键上下文特征以抑制无关信息，从而提高模型的可扩展性和效率。实验结果显示，该框架显著降低了长输入序列的处理开销，同时在准确性、任务泛化和鲁棒性方面优于基线模型，尤其适用于复杂上下文理解和领域适应性任务。最终，这种整合框架支持多领域泛化、交互系统和实时决策等应用，解决了传统静态内存架构的局限性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.14119v1",
      "published_date": "2025-01-23 22:20:36 UTC",
      "updated_date": "2025-01-23 22:20:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:13:01.865631"
    },
    {
      "arxiv_id": "2502.10413v1",
      "title": "Machine Learning-Driven Convergence Analysis in Multijurisdictional Compliance Using BERT and K-Means Clustering",
      "title_zh": "机器学习驱动的多管辖区合规收敛分析，使用 BERT 和 K-Means 聚类",
      "authors": [
        "Raj Sonani",
        "Lohalekar Prayas"
      ],
      "abstract": "Digital data continues to grow, there has been a shift towards using\neffective regulatory mechanisms to safeguard personal information. The CCPA of\nCalifornia and the General Data Protection Regulation (GDPR) of the European\nUnion are two of the most important privacy laws. The regulation is intended to\nsafeguard consumer privacy, but it varies greatly in scope, definitions, and\nmethods of enforcement. This paper presents a fresh approach to adaptive\ncompliance, using machine learning and emphasizing natural language processing\n(NLP) as the primary focus of comparison between the GDPR and CCPA. Using NLP,\nthis study compares various regulations to identify areas where they overlap or\ndiverge. This includes the \"right to be forgotten\" provision in the GDPR and\nthe \"opt-out of sale\" provision under CCPA. International companies can learn\nvaluable lessons from this report, as it outlines strategies for better\nenforcement of laws across different nations. Additionally, the paper discusses\nthe challenges of utilizing NLP in legal literature and proposes methods to\nenhance the model-ability of machine learning models for studying regulations.\nThe study's objective is to \"bridge the gap between legal knowledge and\ntechnical expertise\" by developing regulatory compliance strategies that are\nmore efficient in operation and more effective in data protection.",
      "tldr_zh": "这篇论文提出了一种基于机器学习的自适应合规分析方法，使用BERT和K-Means Clustering来比较欧盟的General Data Protection Regulation (GDPR)和加州的California Consumer Privacy Act (CCPA)，重点识别二者在范围、定义和执行方面的重叠与差异，例如GDPR的“right to be forgotten”和CCPA的“opt-out of sale”。通过自然语言处理(NLP)技术，该研究帮助国际公司制定更有效的跨国法规执行策略，并讨论了在法律文献中应用NLP的挑战及改进机器学习模型的方法。最终，该工作旨在桥接法律知识和技术专长，提升法规遵守的效率和数据保护效果。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CE",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "16 pages, 5 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2502.10413v1",
      "published_date": "2025-01-23 22:11:18 UTC",
      "updated_date": "2025-01-23 22:11:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:13:13.803860"
    },
    {
      "arxiv_id": "2501.14105v1",
      "title": "MedSlice: Fine-Tuned Large Language Models for Secure Clinical Note Sectioning",
      "title_zh": "翻译失败",
      "authors": [
        "Joshua Davis",
        "Thomas Sounack",
        "Kate Sciacca",
        "Jessie M Brain",
        "Brigitte N Durieux",
        "Nicole D Agaronnik",
        "Charlotta Lindvall"
      ],
      "abstract": "Extracting sections from clinical notes is crucial for downstream analysis\nbut is challenging due to variability in formatting and labor-intensive nature\nof manual sectioning. While proprietary large language models (LLMs) have shown\npromise, privacy concerns limit their accessibility. This study develops a\npipeline for automated note sectioning using open-source LLMs, focusing on\nthree sections: History of Present Illness, Interval History, and Assessment\nand Plan. We fine-tuned three open-source LLMs to extract sections using a\ncurated dataset of 487 progress notes, comparing results relative to\nproprietary models (GPT-4o, GPT-4o mini). Internal and external validity were\nassessed via precision, recall and F1 score. Fine-tuned Llama 3.1 8B\noutperformed GPT-4o (F1=0.92). On the external validity test set, performance\nremained high (F1= 0.85). Fine-tuned open-source LLMs can surpass proprietary\nmodels in clinical note sectioning, offering advantages in cost, performance,\nand accessibility.",
      "tldr_zh": "这篇论文介绍了 MedSlice，一个基于微调开源 Large Language Models (LLMs) 的管道，用于安全提取临床笔记的部分，如 History of Present Illness、Interval History 和 Assessment and Plan，以应对格式多样性和手动处理的挑战。研究团队使用一个包含 487 个进展笔记的精选数据集，对三个开源 LLMs 进行微调，并与专有模型（如 GPT-4o 和 GPT-4o mini）进行比较。结果显示，微调后的 Llama 3.1 8B 模型在内部测试中超过了 GPT-4o（F1 score=0.92），外部测试集上也保持高性能（F1 score=0.85）。总之，该方法证明了开源 LLMs 在临床笔记部分提取中的成本、性能和可访问性优势。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Our code is publicly available on github (\n  https://github.com/lindvalllab/MedSlice )",
      "pdf_url": "http://arxiv.org/pdf/2501.14105v1",
      "published_date": "2025-01-23 21:32:09 UTC",
      "updated_date": "2025-01-23 21:32:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:13:27.854615"
    },
    {
      "arxiv_id": "2501.17175v1",
      "title": "Document-Level Sentiment Analysis of Urdu Text Using Deep Learning Techniques",
      "title_zh": "使用深度学习技术的Urdu文本文档级情感分析",
      "authors": [
        "Ammarah Irum",
        "M. Ali Tahir"
      ],
      "abstract": "Document level Urdu Sentiment Analysis (SA) is a challenging Natural Language\nProcessing (NLP) task as it deals with large documents in a resource-poor\nlanguage. In large documents, there are ample amounts of words that exhibit\ndifferent viewpoints. Deep learning (DL) models comprise of complex neural\nnetwork architectures that have the ability to learn diverse features of the\ndata to classify various sentiments. Besides audio, image and video\nclassification; DL algorithms are now extensively used in text-based\nclassification problems. To explore the powerful DL techniques for Urdu SA, we\nhave applied five different DL architectures namely, Bidirectional Long Short\nTerm Memory (BiLSTM), Convolutional Neural Network (CNN), Convolutional Neural\nNetwork with Bidirectional Long Short Term Memory (CNN-BiLSTM), Bidirectional\nEncoder Representation from Transformer (BERT). In this paper, we have proposed\na DL hybrid model that integrates BiLSTM with Single Layer Multi Filter\nConvolutional Neural Network (BiLSTM-SLMFCNN). The proposed and baseline\ntechniques are applied on Urdu Customer Support data set and IMDB Urdu movie\nreview data set by using pretrained Urdu word embeddings that are suitable for\n(SA) at the document level. Results of these techniques are evaluated and our\nproposed model outperforms all other DL techniques for Urdu SA. BiLSTM-SLMFCNN\noutperformed the baseline DL models and achieved 83{\\%}, 79{\\%}, 83{\\%} and\n94{\\%} accuracy on small, medium and large sized IMDB Urdu movie review data\nset and Urdu Customer Support data set respectively.",
      "tldr_zh": "这篇论文探讨了使用深度学习（Deep Learning）技术进行乌尔都语文档级情感分析（Sentiment Analysis）的挑战，针对资源匮乏语言中大文档的复杂观点问题。作者应用了 BiLSTM、CNN、CNN-BiLSTM 和 BERT 等五种模型，并提出了一种新混合模型 BiLSTM-SLMFCNN，该模型结合了 BiLSTM 和 Single Layer Multi Filter Convolutional Neural Network。实验在 Urdu Customer Support 数据集和 IMDB Urdu 电影评论数据集上使用预训练乌尔都语词嵌入进行测试，结果显示 BiLSTM-SLMFCNN 模型在这些数据集上取得了最高准确率，分别为 83%、79%、83% 和 94%，优于基线模型。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.17175v1",
      "published_date": "2025-01-23 21:25:37 UTC",
      "updated_date": "2025-01-23 21:25:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:13:38.621997"
    },
    {
      "arxiv_id": "2501.14084v1",
      "title": "The Role of Generative AI in Software Student CollaborAItion",
      "title_zh": "翻译失败",
      "authors": [
        "Natalie Kiesler",
        "Jacqueline Smith",
        "Juho Leinonen",
        "Armando Fox",
        "Stephen MacNeil",
        "Petri Ihantola"
      ],
      "abstract": "Collaboration is a crucial part of computing education. The increase in AI\ncapabilities over the last couple of years is bound to profoundly affect all\naspects of systems and software engineering, including collaboration. In this\nposition paper, we consider a scenario where AI agents would be able to take on\nany role in collaborative processes in computing education. We outline these\nroles, the activities and group dynamics that software development currently\ninclude, and discuss if and in what way AI could facilitate these roles and\nactivities. The goal of our work is to envision and critically examine\npotential futures. We present scenarios suggesting how AI can be integrated\ninto existing collaborations. These are contrasted by design fictions that help\ndemonstrate the new possibilities and challenges for computing education in the\nAI era.",
      "tldr_zh": "这篇立场论文探讨了生成式 AI 在软件学生协作中的作用，分析 AI 代理如何在计算教育中承担各种角色，包括软件开发的活动和团队动态。论文通过描述现有协作场景和设计虚构，评估 AI 可能促进这些角色的方式，并批判性地审视潜在益处。总体而言，该研究旨在展望 AI 时代计算教育的未来可能性和挑战。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CY",
        "cs.HC"
      ],
      "primary_category": "cs.SE",
      "comment": "7 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2501.14084v1",
      "published_date": "2025-01-23 20:43:05 UTC",
      "updated_date": "2025-01-23 20:43:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:13:49.435661"
    },
    {
      "arxiv_id": "2501.14082v2",
      "title": "Communicating Activations Between Language Model Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Vignav Ramesh",
        "Kenneth Li"
      ],
      "abstract": "Communication between multiple language model (LM) agents has been shown to\nscale up the reasoning ability of LMs. While natural language has been the\ndominant medium for inter-LM communication, it is not obvious this should be\nthe standard: not only does natural language communication incur high inference\ncosts that scale quickly with the number of both agents and messages, but also\nthe decoding process abstracts away too much rich information that could be\notherwise accessed from the internal activations. In this work, we propose a\nsimple technique whereby LMs communicate via activations; concretely, we pause\nan LM $\\textit{B}$'s computation at an intermediate layer, combine its current\nactivation with another LM $\\textit{A}$'s intermediate activation via some\nfunction $\\textit{f}$, then pass $\\textit{f}$'s output into the next layer of\n$\\textit{B}$ and continue the forward pass till decoding is complete. This\napproach scales up LMs on new tasks with zero additional parameters and data,\nand saves a substantial amount of compute over natural language communication.\nWe test our method with various functional forms $\\textit{f}$ on two\nexperimental setups--multi-player coordination games and reasoning\nbenchmarks--and find that it achieves up to $27.0\\%$ improvement over natural\nlanguage communication across datasets with $<$$1/4$ the compute, illustrating\nthe superiority and robustness of activations as an alternative \"language\" for\ncommunication between LMs.",
      "tldr_zh": "该研究探讨了语言模型(LM)代理之间的激活通信，以提升多代理系统的推理能力，相比传统的自然语言通信，该方法避免了高计算成本和信息丢失问题。论文提出一种简单技术：在LM B的中间层暂停计算，将其激活与LM A的激活通过函数f结合后继续前向传播，从而无需额外参数和数据即可扩展LM到新任务。实验结果显示，在多玩家协调游戏和推理基准上，这种激活通信方式比自然语言通信提高了高达27.0%的性能，且计算量不到1/4，证明了其鲁棒性和高效性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "ICML 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.14082v2",
      "published_date": "2025-01-23 20:41:07 UTC",
      "updated_date": "2025-05-07 20:03:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:14:02.005150"
    },
    {
      "arxiv_id": "2501.14070v2",
      "title": "Expanding on the BRIAR Dataset: A Comprehensive Whole Body Biometric Recognition Resource at Extreme Distances and Real-World Scenarios (Collections 1-4)",
      "title_zh": "翻译失败",
      "authors": [
        "Gavin Jager",
        "David Cornett III",
        "Gavin Glenn",
        "Deniz Aykac",
        "Christi Johnson",
        "Robert Zhang",
        "Ryan Shivers",
        "David Bolme",
        "Laura Davies",
        "Scott Dolvin",
        "Nell Barber",
        "Joel Brogan",
        "Nick Burchfield",
        "Carl Dukes",
        "Andrew Duncan",
        "Regina Ferrell",
        "Austin Garrett",
        "Jim Goddard",
        "Jairus Hines",
        "Bart Murphy",
        "Sean Pharris",
        "Brandon Stockwell",
        "Leanne Thompson",
        "Matthew Yohe"
      ],
      "abstract": "The state-of-the-art in biometric recognition algorithms and operational\nsystems has advanced quickly in recent years providing high accuracy and\nrobustness in more challenging collection environments and consumer\napplications. However, the technology still suffers greatly when applied to\nnon-conventional settings such as those seen when performing identification at\nextreme distances or from elevated cameras on buildings or mounted to UAVs.\nThis paper summarizes an extension to the largest dataset currently focused on\naddressing these operational challenges, and describes its composition as well\nas methodologies of collection, curation, and annotation.",
      "tldr_zh": "本研究扩展了BRIAR Dataset，这是一个针对极端距离和真实世界场景的全面人体生物识别资源，包括Collections 1-4，以应对生物识别算法在非传统环境（如高空无人机或建筑物摄像头）中的准确性和鲁棒性挑战。数据集的组成涵盖了各种复杂场景，论文详细描述了其收集、整理和标注方法，以支持算法的改进。相比现有资源，BRIAR Dataset的扩展为提升生物识别技术在实际应用中的性能提供了宝贵的基础。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "9 pages, 11 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2501.14070v2",
      "published_date": "2025-01-23 20:12:56 UTC",
      "updated_date": "2025-02-04 19:48:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:14:14.140790"
    },
    {
      "arxiv_id": "2502.10412v1",
      "title": "Identifying relevant indicators for monitoring a National Artificial Intelligence Strategy",
      "title_zh": "翻译失败",
      "authors": [
        "Renata Pelissari",
        "Ricardo Suyama",
        "Leonardo Tomazeli Duarte",
        "Henrique Sá Earp"
      ],
      "abstract": "How can a National Artificial Intelligence Strategy be effectively monitored?\nTo address this question, we propose a methodology consisting of two key\ncomponents. First, it involves identifying relevant indicators within national\nAI strategies. Second, it assesses the alignment between these indicators and\nthe strategic actions of a specific government's AI strategy, allowing for a\ncritical evaluation of its monitoring measures. Moreover, identifying these\nindicators helps assess the overall quality of the strategy's structure. A lack\nof alignment between strategic actions and the identified indicators may reveal\ngaps or blind spots in the strategy. This methodology is demonstrated using the\nBrazilian AI strategy as a case study.",
      "tldr_zh": "这篇论文提出了一种监控国家人工智能策略的有效方法，包括两个关键组成部分：首先，识别策略中的相关指标；其次，评估这些指标与政府战略行动的匹配度，以进行批判性评估。这样的方法有助于揭示策略结构的质量问题，并识别潜在的差距或盲点。该方法通过巴西人工智能策略作为案例研究进行演示，展示了其实用性。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.10412v1",
      "published_date": "2025-01-23 19:59:31 UTC",
      "updated_date": "2025-01-23 19:59:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:14:24.881282"
    },
    {
      "arxiv_id": "2501.17174v1",
      "title": "Extractive Schema Linking for Text-to-SQL",
      "title_zh": "翻译失败",
      "authors": [
        "Michael Glass",
        "Mustafa Eyceoz",
        "Dharmashankar Subramanian",
        "Gaetano Rossiello",
        "Long Vu",
        "Alfio Gliozzo"
      ],
      "abstract": "Text-to-SQL is emerging as a practical interface for real world databases.\nThe dominant paradigm for Text-to-SQL is cross-database or schema-independent,\nsupporting application schemas unseen during training. The schema of a database\ndefines the tables, columns, column types and foreign key connections between\ntables. Real world schemas can be large, containing hundreds of columns, but\nfor any particular query only a small fraction will be relevant. Placing the\nentire schema in the prompt for an LLM can be impossible for models with\nsmaller token windows and expensive even when the context window is large\nenough to allow it. Even apart from computational considerations, the accuracy\nof the model can be improved by focusing the SQL generation on only the\nrelevant portion of the database. Schema linking identifies the portion of the\ndatabase schema useful for the question. Previous work on schema linking has\nused graph neural networks, generative LLMs, and cross encoder classifiers. We\nintroduce a new approach to adapt decoder-only LLMs to schema linking that is\nboth computationally more efficient and more accurate than the generative\napproach. Additionally our extractive approach permits fine-grained control\nover the precision-recall trade-off for schema linking.",
      "tldr_zh": "这篇论文针对 Text-to-SQL 任务，提出了一种提取式（extractive）schema linking 方法，以解决将大型数据库模式（如包含数百列的表）纳入 LLM 提示时面临的计算开销和准确性问题。该方法基于解码器-only LLMs，相比之前的生成式方法更高效且准确，能够自动识别查询相关部分的数据库模式。此外，这种提取式方法允许对精度-召回权衡进行细粒度控制，从而提升 SQL 生成的针对性和整体性能。",
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.DB",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.17174v1",
      "published_date": "2025-01-23 19:57:08 UTC",
      "updated_date": "2025-01-23 19:57:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:14:38.027192"
    },
    {
      "arxiv_id": "2501.14051v1",
      "title": "Revisiting CLIP: Efficient Alignment of 3D MRI and Tabular Data using Domain-Specific Foundation Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jakob Krogh Petersen",
        "Valdemar Licht",
        "Mads Nielsen",
        "Asbjørn Munk"
      ],
      "abstract": "Multi-modal models require aligned, shared embedding spaces. However, common\nCLIP-based approaches need large amounts of samples and do not natively support\n3D or tabular data, both of which are crucial in the medical domain. To address\nthese issues, we revisit CLIP-style alignment by training a domain-specific 3D\nfoundation model as an image encoder and demonstrate that modality alignment is\nfeasible with only 62 MRI scans. Our approach is enabled by a simple embedding\naccumulation strategy required for training in 3D, which scales the amount of\nnegative pairs across batches in order to stabilize training. We perform a\nthorough evaluation of various design choices, including the choice of backbone\nand loss functions, and evaluate the proposed methodology on zero-shot\nclassification and image-retrieval tasks. While zero-shot image-retrieval\nremains challenging, zero-shot classification results demonstrate that the\nproposed approach can meaningfully align the representations of 3D MRI with\ntabular data.",
      "tldr_zh": "本文重新审视 CLIP 方法，提出一种高效策略，通过训练域特定 3D 基础模型作为图像编码器，实现 3D MRI 和 tabular data 的表示空间对齐，仅需 62 个 MRI 扫描即可完成模态对齐。作者引入嵌入积累策略来处理 3D 训练中的负对问题，从而稳定训练过程，并评估了骨干网络和损失函数等设计选择。实验结果显示，该方法在零样本分类任务上实现了有意义的表示对齐，尽管零样本图像检索任务仍面临挑战。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages, 2 figures. To be published in ISBI 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.14051v1",
      "published_date": "2025-01-23 19:34:48 UTC",
      "updated_date": "2025-01-23 19:34:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:14:50.708956"
    },
    {
      "arxiv_id": "2501.14050v2",
      "title": "GraphRAG under Fire",
      "title_zh": "GraphRAG 遭受攻击",
      "authors": [
        "Jiacheng Liang",
        "Yuhui Wang",
        "Changjiang Li",
        "Rongyi Zhu",
        "Tanqiu Jiang",
        "Neil Gong",
        "Ting Wang"
      ],
      "abstract": "GraphRAG advances retrieval-augmented generation (RAG) by structuring\nexternal knowledge as multi-scale knowledge graphs, enabling language models to\nintegrate both broad context and granular details in their generation. While\nGraphRAG has demonstrated success across domains, its security implications\nremain largely unexplored. To bridge this gap, this work examines GraphRAG's\nvulnerability to poisoning attacks, uncovering an intriguing security paradox:\ncompared to conventional RAG, GraphRAG's graph-based indexing and retrieval\nenhance resilience against simple poisoning attacks; yet, the same features\nalso create new attack surfaces. We present GRAGPoison, a novel attack that\nexploits shared relations in the underlying knowledge graph to craft poisoning\ntext capable of compromising multiple queries simultaneously. GRAGPoison\nemploys three key strategies: i) relation injection to introduce false\nknowledge, ii) relation enhancement to amplify poisoning influence, and iii)\nnarrative generation to embed malicious content within coherent text. Empirical\nevaluation across diverse datasets and models shows that GRAGPoison\nsubstantially outperforms existing attacks in terms of effectiveness (up to\n98\\% success rate) and scalability (using less than 68\\% poisoning text) on\nvarious GraphRAG-based systems. We also explore potential defensive measures\nand their limitations, identifying promising directions for future research.",
      "tldr_zh": "这篇论文探讨了GraphRAG系统在安全方面的漏洞，该系统通过构建多尺度知识图谱来提升检索增强生成(RAG)的性能，但同时暴露于中毒攻击(poisoning attacks)的新风险。研究者提出GRAGPoison攻击方法，利用知识图谱中的共享关系，通过关系注入、关系增强和叙事生成策略来同时污染多个查询，实现高达98%的成功率，同时仅需少于68%的污染文本。实验结果显示GRAGPoison在各种GraphRAG系统上比现有攻击更有效，并探讨了潜在防御措施及其局限性，为未来安全研究提供了方向。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "13 pages",
      "pdf_url": "http://arxiv.org/pdf/2501.14050v2",
      "published_date": "2025-01-23 19:33:16 UTC",
      "updated_date": "2025-04-24 02:38:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:15:02.545824"
    },
    {
      "arxiv_id": "2501.14048v1",
      "title": "SIDDA: SInkhorn Dynamic Domain Adaptation for Image Classification with Equivariant Neural Networks",
      "title_zh": "SIDDA: SInkhorn 动态领域适配用于图像分类的等变神经网络",
      "authors": [
        "Sneh Pandya",
        "Purvik Patel",
        "Brian D. Nord",
        "Mike Walmsley",
        "Aleksandra Ćiprijanović"
      ],
      "abstract": "Modern neural networks (NNs) often do not generalize well in the presence of\na \"covariate shift\"; that is, in situations where the training and test data\ndistributions differ, but the conditional distribution of classification labels\nremains unchanged. In such cases, NN generalization can be reduced to a problem\nof learning more domain-invariant features. Domain adaptation (DA) methods\ninclude a range of techniques aimed at achieving this; however, these methods\nhave struggled with the need for extensive hyperparameter tuning, which then\nincurs significant computational costs. In this work, we introduce SIDDA, an\nout-of-the-box DA training algorithm built upon the Sinkhorn divergence, that\ncan achieve effective domain alignment with minimal hyperparameter tuning and\ncomputational overhead. We demonstrate the efficacy of our method on multiple\nsimulated and real datasets of varying complexity, including simple shapes,\nhandwritten digits, and real astronomical observations. SIDDA is compatible\nwith a variety of NN architectures, and it works particularly well in improving\nclassification accuracy and model calibration when paired with equivariant\nneural networks (ENNs). We find that SIDDA enhances the generalization\ncapabilities of NNs, achieving up to a $\\approx40\\%$ improvement in\nclassification accuracy on unlabeled target data. We also study the efficacy of\nDA on ENNs with respect to the varying group orders of the dihedral group\n$D_N$, and find that the model performance improves as the degree of\nequivariance increases. Finally, we find that SIDDA enhances model calibration\non both source and target data--achieving over an order of magnitude\nimprovement in the ECE and Brier score. SIDDA's versatility, combined with its\nautomated approach to domain alignment, has the potential to advance\nmulti-dataset studies by enabling the development of highly generalizable\nmodels.",
      "tldr_zh": "本研究针对神经网络（NNs）在协变量偏移（covariate shift）下的泛化问题，提出了一种基于 Sinkhorn 散度的动态域适应（DA）算法 SIDDA，以实现高效的域对齐，同时减少超参数调整和计算开销。SIDDA 兼容多种 NN 架构，特别是与等变神经网络（ENNs）结合时，能显著提升图像分类准确性和模型校准，在模拟和真实数据集（如简单形状、手写数字及天文观察）上测试，实现了高达约 40% 的分类准确率改善，并随二面体群（D_N）的等变度增加而优化性能。该方法还大幅提升了模型校准效果，在 ECE 和 Brier 分数上改善一个数量级以上，具有潜力推进多数据集研究和高度泛化模型的开发。",
      "categories": [
        "cs.LG",
        "astro-ph.GA",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "25 pages, 5 figures, 4 tables. code available at:\n  https://github.com/deepskies/SIDDA",
      "pdf_url": "http://arxiv.org/pdf/2501.14048v1",
      "published_date": "2025-01-23 19:29:34 UTC",
      "updated_date": "2025-01-23 19:29:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:15:15.262370"
    },
    {
      "arxiv_id": "2501.14035v1",
      "title": "Human-Alignment Influences the Utility of AI-assisted Decision Making",
      "title_zh": "翻译失败",
      "authors": [
        "Nina L. Corvelo Benz",
        "Manuel Gomez Rodriguez"
      ],
      "abstract": "Whenever an AI model is used to predict a relevant (binary) outcome in\nAI-assisted decision making, it is widely agreed that, together with each\nprediction, the model should provide an AI confidence value. However, it has\nbeen unclear why decision makers have often difficulties to develop a good\nsense on when to trust a prediction using AI confidence values. Very recently,\nCorvelo Benz and Gomez Rodriguez have argued that, for rational decision\nmakers, the utility of AI-assisted decision making is inherently bounded by the\ndegree of alignment between the AI confidence values and the decision maker's\nconfidence on their own predictions. In this work, we empirically investigate\nto what extent the degree of alignment actually influences the utility of\nAI-assisted decision making. To this end, we design and run a large-scale human\nsubject study (n=703) where participants solve a simple decision making task -\nan online card game - assisted by an AI model with a steerable degree of\nalignment. Our results show a positive association between the degree of\nalignment and the utility of AI-assisted decision making. In addition, our\nresults also show that post-processing the AI confidence values to achieve\nmulticalibration with respect to the participants' confidence on their own\npredictions increases both the degree of alignment and the utility of\nAI-assisted decision making.",
      "tldr_zh": "该研究探讨了在AI辅助决策中，AI置信值（AI confidence values）与决策者自身置信度的对齐程度（human-alignment）如何影响决策效用。研究者设计了一个大规模人类实验（n=703），让参与者在在线卡牌游戏中接受AI辅助，并调节AI的对齐程度。结果显示，对齐程度与AI辅助决策的效用呈正相关；此外，通过后处理AI置信值以实现multicalibration，可以进一步提升对齐程度和整体决策效用。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.14035v1",
      "published_date": "2025-01-23 19:01:47 UTC",
      "updated_date": "2025-01-23 19:01:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:15:25.857938"
    },
    {
      "arxiv_id": "2501.13928v2",
      "title": "Fast3R: Towards 3D Reconstruction of 1000+ Images in One Forward Pass",
      "title_zh": "翻译失败",
      "authors": [
        "Jianing Yang",
        "Alexander Sax",
        "Kevin J. Liang",
        "Mikael Henaff",
        "Hao Tang",
        "Ang Cao",
        "Joyce Chai",
        "Franziska Meier",
        "Matt Feiszli"
      ],
      "abstract": "Multi-view 3D reconstruction remains a core challenge in computer vision,\nparticularly in applications requiring accurate and scalable representations\nacross diverse perspectives. Current leading methods such as DUSt3R employ a\nfundamentally pairwise approach, processing images in pairs and necessitating\ncostly global alignment procedures to reconstruct from multiple views. In this\nwork, we propose Fast 3D Reconstruction (Fast3R), a novel multi-view\ngeneralization to DUSt3R that achieves efficient and scalable 3D reconstruction\nby processing many views in parallel. Fast3R's Transformer-based architecture\nforwards N images in a single forward pass, bypassing the need for iterative\nalignment. Through extensive experiments on camera pose estimation and 3D\nreconstruction, Fast3R demonstrates state-of-the-art performance, with\nsignificant improvements in inference speed and reduced error accumulation.\nThese results establish Fast3R as a robust alternative for multi-view\napplications, offering enhanced scalability without compromising reconstruction\naccuracy.",
      "tldr_zh": "本文提出Fast3R，一种新型多视图3D重建方法，能够在单个前向传递中处理1000+图像，从而实现高效并行处理，避免了传统方法如DUSt3R的配对处理和全局对齐开销。Fast3R采用Transformer-based架构，直接处理多视图输入，提高了推理速度并减少错误积累。在相机位姿估计和3D重建实验中，Fast3R展现出最先进性能，提供了一个可扩展的替代方案，同时保持了重建准确性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR 2025. Project website: https://fast3r-3d.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2501.13928v2",
      "published_date": "2025-01-23 18:59:55 UTC",
      "updated_date": "2025-03-19 19:35:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:15:38.043658"
    },
    {
      "arxiv_id": "2501.13927v1",
      "title": "CRPO: Confidence-Reward Driven Preference Optimization for Machine Translation",
      "title_zh": "CRPO：置信度-奖励驱动的机器翻译偏好优化",
      "authors": [
        "Guofeng Cui",
        "Pichao Wang",
        "Yang Liu",
        "Zemian Ke",
        "Zhu Liu",
        "Vimal Bhat"
      ],
      "abstract": "Large language models (LLMs) have shown great potential in natural language\nprocessing tasks, but their application to machine translation (MT) remains\nchallenging due to pretraining on English-centric data and the complexity of\nreinforcement learning from human feedback (RLHF). Direct Preference\nOptimization (DPO) has emerged as a simpler and more efficient alternative, but\nits performance depends heavily on the quality of preference data. To address\nthis, we propose Confidence-Reward driven Preference Optimization (CRPO), a\nnovel method that combines reward scores with model confidence to improve data\nselection for fine-tuning. CRPO selects challenging sentence pairs where the\nmodel is uncertain or underperforms, leading to more effective learning. While\nprimarily designed for LLMs, CRPO also generalizes to encoder-decoder models\nlike NLLB, demonstrating its versatility. Empirical results show that CRPO\noutperforms existing methods such as RS-DPO, RSO and MBR score in both\ntranslation accuracy and data efficiency.",
      "tldr_zh": "本研究针对大型语言模型（LLMs）在机器翻译（MT）中的挑战，如英语中心的数据预训练和强化学习从人类反馈（RLHF）的复杂性，提出了一种新型方法Confidence-Reward driven Preference Optimization (CRPO)。CRPO 通过结合奖励分数和模型置信度来优化数据选择，优先选取模型不确定的挑战性句子对，从而提升学习效率和性能。该方法不仅适用于 LLMs，还能推广到编码器-解码器模型如 NLLB；实验结果显示，CRPO 在翻译准确性和数据效率上优于现有方法如 RS-DPO、RSO 和 MBR score。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.13927v1",
      "published_date": "2025-01-23 18:59:47 UTC",
      "updated_date": "2025-01-23 18:59:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:15:49.592937"
    },
    {
      "arxiv_id": "2501.13926v1",
      "title": "Can We Generate Images with CoT? Let's Verify and Reinforce Image Generation Step by Step",
      "title_zh": "我们能用 CoT 生成图像吗？让我们逐步验证和强化图像生成过程",
      "authors": [
        "Ziyu Guo",
        "Renrui Zhang",
        "Chengzhuo Tong",
        "Zhizheng Zhao",
        "Peng Gao",
        "Hongsheng Li",
        "Pheng-Ann Heng"
      ],
      "abstract": "Chain-of-Thought (CoT) reasoning has been extensively explored in large\nmodels to tackle complex understanding tasks. However, it still remains an open\nquestion whether such strategies can be applied to verifying and reinforcing\nimage generation scenarios. In this paper, we provide the first comprehensive\ninvestigation of the potential of CoT reasoning to enhance autoregressive image\ngeneration. We focus on three techniques: scaling test-time computation for\nverification, aligning model preferences with Direct Preference Optimization\n(DPO), and integrating these techniques for complementary effects. Our results\ndemonstrate that these approaches can be effectively adapted and combined to\nsignificantly improve image generation performance. Furthermore, given the\npivotal role of reward models in our findings, we propose the Potential\nAssessment Reward Model (PARM) and PARM++, specialized for autoregressive image\ngeneration. PARM adaptively assesses each generation step through a potential\nassessment approach, merging the strengths of existing reward models, and\nPARM++ further introduces a reflection mechanism to self-correct the generated\nunsatisfactory image. Using our investigated reasoning strategies, we enhance a\nbaseline model, Show-o, to achieve superior results, with a significant +24%\nimprovement on the GenEval benchmark, surpassing Stable Diffusion 3 by +15%. We\nhope our study provides unique insights and paves a new path for integrating\nCoT reasoning with autoregressive image generation. Code and models are\nreleased at https://github.com/ZiyuGuo99/Image-Generation-CoT",
      "tldr_zh": "该研究首次全面调查 Chain-of-Thought (CoT) 推理在自回归图像生成中的潜力，聚焦于扩展测试时计算、Direct Preference Optimization (DPO) 以及这些技术的整合，以验证和强化生成过程。作者提出 Potential Assessment Reward Model (PARM)，它通过潜在评估方法评估每个生成步骤，并结合现有奖励模型的优势；此外，PARM++ 进一步添加反射机制来自我修正不满意的图像。实验结果显示，使用这些策略增强的基线模型 Show-o 在 GenEval 基准上提升 24%，超越 Stable Diffusion 3 的 15%，为 CoT 推理与图像生成整合提供新见解。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "Journal Version. Code and models are released at\n  https://github.com/ZiyuGuo99/Image-Generation-CoT",
      "pdf_url": "http://arxiv.org/pdf/2501.13926v1",
      "published_date": "2025-01-23 18:59:43 UTC",
      "updated_date": "2025-01-23 18:59:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:18:03.810072"
    },
    {
      "arxiv_id": "2501.13924v1",
      "title": "Towards Robust Multimodal Open-set Test-time Adaptation via Adaptive Entropy-aware Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Hao Dong",
        "Eleni Chatzi",
        "Olga Fink"
      ],
      "abstract": "Test-time adaptation (TTA) has demonstrated significant potential in\naddressing distribution shifts between training and testing data. Open-set\ntest-time adaptation (OSTTA) aims to adapt a source pre-trained model online to\nan unlabeled target domain that contains unknown classes. This task becomes\nmore challenging when multiple modalities are involved. Existing methods have\nprimarily focused on unimodal OSTTA, often filtering out low-confidence samples\nwithout addressing the complexities of multimodal data. In this work, we\npresent Adaptive Entropy-aware Optimization (AEO), a novel framework\nspecifically designed to tackle Multimodal Open-set Test-time Adaptation\n(MM-OSTTA) for the first time. Our analysis shows that the entropy difference\nbetween known and unknown samples in the target domain strongly correlates with\nMM-OSTTA performance. To leverage this, we propose two key components:\nUnknown-aware Adaptive Entropy Optimization (UAE) and Adaptive Modality\nPrediction Discrepancy Optimization (AMP). These components enhance the ability\nof model to distinguish unknown class samples during online adaptation by\namplifying the entropy difference between known and unknown samples. To\nthoroughly evaluate our proposed methods in the MM-OSTTA setting, we establish\na new benchmark derived from existing datasets. This benchmark includes two\ndownstream tasks and incorporates five modalities. Extensive experiments across\nvarious domain shift situations demonstrate the efficacy and versatility of the\nAEO framework. Additionally, we highlight the strong performance of AEO in\nlong-term and continual MM-OSTTA settings, both of which are challenging and\nhighly relevant to real-world applications. Our source code is available at\nhttps://github.com/donghao51/AEO.",
      "tldr_zh": "本论文针对多模态开放集测试时适应(MM-OSTTA)问题，首次提出Adaptive Entropy-aware Optimization (AEO)框架，以处理多模态数据中的分布偏移挑战。AEO框架包括Unknown-aware Adaptive Entropy Optimization (UAE)和Adaptive Modality Prediction Discrepancy Optimization (AMP)两个关键组件，通过放大已知和未知样本之间的熵差异，增强模型在线适应的鲁棒性和对未知类样本的区分能力。实验在新的基准数据集上（涵盖两个下游任务和五种模态）进行验证，显示AEO在各种域移位场景中显著提升性能，并在长期和持续MM-OSTTA设置中表现出色，为实际应用提供了可靠的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.13924v1",
      "published_date": "2025-01-23 18:59:30 UTC",
      "updated_date": "2025-01-23 18:59:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:18:17.109965"
    },
    {
      "arxiv_id": "2501.13919v2",
      "title": "Temporal Preference Optimization for Long-Form Video Understanding",
      "title_zh": "翻译失败",
      "authors": [
        "Rui Li",
        "Xiaohan Wang",
        "Yuhui Zhang",
        "Zeyu Wang",
        "Serena Yeung-Levy"
      ],
      "abstract": "Despite significant advancements in video large multimodal models\n(video-LMMs), achieving effective temporal grounding in long-form videos\nremains a challenge for existing models. To address this limitation, we propose\nTemporal Preference Optimization (TPO), a novel post-training framework\ndesigned to enhance the temporal grounding capabilities of video-LMMs through\npreference learning. TPO adopts a self-training approach that enables models to\ndifferentiate between well-grounded and less accurate temporal responses by\nleveraging curated preference datasets at two granularities: localized temporal\ngrounding, which focuses on specific video segments, and comprehensive temporal\ngrounding, which captures extended temporal dependencies across entire video\nsequences. By optimizing on these preference datasets, TPO significantly\nenhances temporal understanding while reducing reliance on manually annotated\ndata. Extensive experiments on three long-form video understanding\nbenchmarks--LongVideoBench, MLVU, and Video-MME--demonstrate the effectiveness\nof TPO across two state-of-the-art video-LMMs. Notably, LLaVA-Video-TPO\nestablishes itself as the leading 7B model on the Video-MME benchmark,\nunderscoring the potential of TPO as a scalable and efficient solution for\nadvancing temporal reasoning in long-form video understanding. Project page:\nhttps://ruili33.github.io/tpo_website.",
      "tldr_zh": "这篇论文针对视频大型多模态模型（video-LMMs）在长视频时间定位（temporal grounding）方面的挑战，提出了Temporal Preference Optimization (TPO)——一种新型后训练框架，通过偏好学习增强模型的 temporal grounding 能力。TPO 采用自训练方法，利用两种粒度的偏好数据集（localized temporal grounding 针对特定视频段，comprehensive temporal grounding 捕捉整个视频序列的扩展时间依赖），帮助模型区分准确与不准确的响应，同时减少对手动标注数据的依赖。在 LongVideoBench、MLVU 和 Video-MME 等基准上的广泛实验证明，TPO 显著提升了模型性能，其中 LLaVA-Video-TPO 成为 Video-MME 基准上领先的 7B 模型。总体而言，TPO 提供了一种可扩展、高效的解决方案，推动长视频理解中的时间推理发展。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.13919v2",
      "published_date": "2025-01-23 18:58:03 UTC",
      "updated_date": "2025-01-30 17:35:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:18:27.810928"
    },
    {
      "arxiv_id": "2501.13918v1",
      "title": "Improving Video Generation with Human Feedback",
      "title_zh": "通过人类反馈改进视频生成",
      "authors": [
        "Jie Liu",
        "Gongye Liu",
        "Jiajun Liang",
        "Ziyang Yuan",
        "Xiaokun Liu",
        "Mingwu Zheng",
        "Xiele Wu",
        "Qiulin Wang",
        "Wenyu Qin",
        "Menghan Xia",
        "Xintao Wang",
        "Xiaohong Liu",
        "Fei Yang",
        "Pengfei Wan",
        "Di Zhang",
        "Kun Gai",
        "Yujiu Yang",
        "Wanli Ouyang"
      ],
      "abstract": "Video generation has achieved significant advances through rectified flow\ntechniques, but issues like unsmooth motion and misalignment between videos and\nprompts persist. In this work, we develop a systematic pipeline that harnesses\nhuman feedback to mitigate these problems and refine the video generation\nmodel. Specifically, we begin by constructing a large-scale human preference\ndataset focused on modern video generation models, incorporating pairwise\nannotations across multi-dimensions. We then introduce VideoReward, a\nmulti-dimensional video reward model, and examine how annotations and various\ndesign choices impact its rewarding efficacy. From a unified reinforcement\nlearning perspective aimed at maximizing reward with KL regularization, we\nintroduce three alignment algorithms for flow-based models by extending those\nfrom diffusion models. These include two training-time strategies: direct\npreference optimization for flow (Flow-DPO) and reward weighted regression for\nflow (Flow-RWR), and an inference-time technique, Flow-NRG, which applies\nreward guidance directly to noisy videos. Experimental results indicate that\nVideoReward significantly outperforms existing reward models, and Flow-DPO\ndemonstrates superior performance compared to both Flow-RWR and standard\nsupervised fine-tuning methods. Additionally, Flow-NRG lets users assign custom\nweights to multiple objectives during inference, meeting personalized video\nquality needs. Project page: https://gongyeliu.github.io/videoalign.",
      "tldr_zh": "本文针对视频生成的 unsmooth motion 和 prompt misalignment 问题，提出一个系统管道，利用人类反馈构建大规模多维度偏好数据集，并引入 VideoReward 模型来评估和优化视频质量。作者从强化学习视角出发，开发了三种针对 flow-based 模型的 alignment 算法：训练时的 Flow-DPO 和 Flow-RWR，以及推理时的 Flow-NRG，后者允许用户为多个目标分配自定义权重。实验结果表明，VideoReward 显著优于现有奖励模型，而 Flow-DPO 在性能上超过 Flow-RWR 和标准监督微调方法，从而提升了视频生成的整体效果。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.13918v1",
      "published_date": "2025-01-23 18:55:41 UTC",
      "updated_date": "2025-01-23 18:55:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:18:40.388722"
    },
    {
      "arxiv_id": "2501.14013v1",
      "title": "Leveraging Multiphase CT for Quality Enhancement of Portal Venous CT: Utility for Pancreas Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Xinya Wang",
        "Tejas Sudharshan Mathai",
        "Boah Kim",
        "Ronald M. Summers"
      ],
      "abstract": "Multiphase CT studies are routinely obtained in clinical practice for\ndiagnosis and management of various diseases, such as cancer. However, the CT\nstudies can be acquired with low radiation doses, different scanners, and are\nfrequently affected by motion and metal artifacts. Prior approaches have\ntargeted the quality improvement of one specific CT phase (e.g., non-contrast\nCT). In this work, we hypothesized that leveraging multiple CT phases for the\nquality enhancement of one phase may prove advantageous for downstream tasks,\nsuch as segmentation. A 3D progressive fusion and non-local (PFNL) network was\ndeveloped. It was trained with three degraded (low-quality) phases\n(non-contrast, arterial, and portal venous) to enhance the quality of the\nportal venous phase. Then, the effect of scan quality enhancement was evaluated\nusing a proxy task of pancreas segmentation, which is useful for tracking\npancreatic cancer. The proposed approach improved the pancreas segmentation by\n3% over the corresponding low-quality CT scan. To the best of our knowledge, we\nare the first to harness multiphase CT for scan quality enhancement and\nimproved pancreas segmentation.",
      "tldr_zh": "本文提出了一种利用多相CT（Multiphase CT）增强门静脉CT（Portal Venous CT）质量的方法，旨在改善下游任务如胰腺分割（Pancreas Segmentation）。他们开发了3D progressive fusion and non-local (PFNL) 网络，使用非对比、arterial和portal venous三个低质量相位来提升portal venous相位的图像质量。实验结果显示，该方法将胰腺分割性能提高了3%，这是首次将多相CT应用于扫描质量增强和胰腺分割任务中。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "92C55",
        "I.4.6"
      ],
      "primary_category": "eess.IV",
      "comment": "ISBI 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.14013v1",
      "published_date": "2025-01-23 18:45:24 UTC",
      "updated_date": "2025-01-23 18:45:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:18:51.121743"
    },
    {
      "arxiv_id": "2501.14012v3",
      "title": "Transfer Learning of Surrogate Models via Domain Affine Transformation Across Synthetic and Real-World Benchmarks",
      "title_zh": "翻译失败",
      "authors": [
        "Shuaiqun Pan",
        "Diederick Vermetten",
        "Manuel López-Ibáñez",
        "Thomas Bäck",
        "Hao Wang"
      ],
      "abstract": "Surrogate models are frequently employed as efficient substitutes for the\ncostly execution of real-world processes. However, constructing a high-quality\nsurrogate model often demands extensive data acquisition. A solution to this\nissue is to transfer pre-trained surrogate models for new tasks, provided that\ncertain invariances exist between tasks. This study focuses on transferring\nnon-differentiable surrogate models (e.g., random forests) from a source\nfunction to a target function, where we assume their domains are related by an\nunknown affine transformation, using only a limited amount of transfer data\npoints evaluated on the target. Previous research attempts to tackle this\nchallenge for differentiable models, e.g., Gaussian process regression, which\nminimizes the empirical loss on the transfer data by tuning the affine\ntransformations. In this paper, we extend the previous work to the random\nforest and assess its effectiveness on a widely-used artificial problem set -\nBlack-Box Optimization Benchmark (BBOB) testbed, and on four real-world\ntransfer learning problems. The results highlight the significant practical\nadvantages of the proposed method, particularly in reducing both the data\nrequirements and computational costs of training surrogate models for complex\nreal-world scenarios.",
      "tldr_zh": "本研究探讨了通过域仿射变换（affine transformation）实现代理模型（surrogate models）的转移学习，旨在解决构建高质量代理模型所需的大量数据问题。方法假设源函数和目标函数的域通过未知仿射变换相关，仅使用目标上的有限转移数据点，对非可微模型如随机森林（random forests）进行优化和转移扩展。实验在Black-Box Optimization Benchmark (BBOB)测试床以及四个真实世界问题上验证了该方法的有效性，结果显示它显著降低了数据需求和计算成本，为复杂场景下的代理模型训练提供了实用优势。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.14012v3",
      "published_date": "2025-01-23 18:44:25 UTC",
      "updated_date": "2025-05-02 09:04:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:19:02.885846"
    },
    {
      "arxiv_id": "2501.13898v1",
      "title": "PointOBB-v3: Expanding Performance Boundaries of Single Point-Supervised Oriented Object Detection",
      "title_zh": "PointOBB-v3：扩展单点监督定向物体检测的性能边界",
      "authors": [
        "Peiyuan Zhang",
        "Junwei Luo",
        "Xue Yang",
        "Yi Yu",
        "Qingyun Li",
        "Yue Zhou",
        "Xiaosong Jia",
        "Xudong Lu",
        "Jingdong Chen",
        "Xiang Li",
        "Junchi Yan",
        "Yansheng Li"
      ],
      "abstract": "With the growing demand for oriented object detection (OOD), recent studies\non point-supervised OOD have attracted significant interest. In this paper, we\npropose PointOBB-v3, a stronger single point-supervised OOD framework. Compared\nto existing methods, it generates pseudo rotated boxes without additional\npriors and incorporates support for the end-to-end paradigm. PointOBB-v3\nfunctions by integrating three unique image views: the original view, a resized\nview, and a rotated/flipped (rot/flp) view. Based on the views, a scale\naugmentation module and an angle acquisition module are constructed. In the\nfirst module, a Scale-Sensitive Consistency (SSC) loss and a Scale-Sensitive\nFeature Fusion (SSFF) module are introduced to improve the model's ability to\nestimate object scale. To achieve precise angle predictions, the second module\nemploys symmetry-based self-supervised learning. Additionally, we introduce an\nend-to-end version that eliminates the pseudo-label generation process by\nintegrating a detector branch and introduces an Instance-Aware Weighting (IAW)\nstrategy to focus on high-quality predictions. We conducted extensive\nexperiments on the DIOR-R, DOTA-v1.0/v1.5/v2.0, FAIR1M, STAR, and RSAR\ndatasets. Across all these datasets, our method achieves an average improvement\nin accuracy of 3.56% in comparison to previous state-of-the-art methods. The\ncode will be available at https://github.com/ZpyWHU/PointOBB-v3.",
      "tldr_zh": "本研究提出 PointOBB-v3，一种增强的单点监督定向物体检测（Oriented Object Detection）框架，能够在不依赖额外先验的情况下生成伪旋转框，并支持端到端训练范式。框架整合三种图像视图（原始视图、调整大小视图和旋转/翻转视图），通过尺度增强模块（引入 Scale-Sensitive Consistency (SSC) 损失和 Scale-Sensitive Feature Fusion (SSFF) 模块）来提升物体尺度估计精度，以及角度获取模块（利用基于对称性的自监督学习）来实现精确角度预测。此外，PointOBB-v3 的端到端版本通过整合检测器分支和 Instance-Aware Weighting (IAW) 策略，专注于高质量预测。在 DIOR-R、DOTA-v1.0/v1.5/v2.0、FAIR1M、STAR 和 RSAR 等数据集上，该方法比现有最先进方法平均准确率提升 3.56%。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "16 pages, 5 figures, 10 tables",
      "pdf_url": "http://arxiv.org/pdf/2501.13898v1",
      "published_date": "2025-01-23 18:18:15 UTC",
      "updated_date": "2025-01-23 18:18:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:19:15.327914"
    },
    {
      "arxiv_id": "2501.13896v2",
      "title": "GUI-Bee: Align GUI Action Grounding to Novel Environments via Autonomous Exploration",
      "title_zh": "翻译失败",
      "authors": [
        "Yue Fan",
        "Handong Zhao",
        "Ruiyi Zhang",
        "Yu Shen",
        "Xin Eric Wang",
        "Gang Wu"
      ],
      "abstract": "Graphical User Interface (GUI) action grounding is a critical step in GUI\nautomation that maps language instructions to actionable elements on GUI\nscreens. Most recent works of GUI action grounding leverage large GUI datasets\nto fine-tune MLLMs. However, the fine-tuning data always covers limited GUI\nenvironments, and we find the performance of the resulting model deteriorates\nin novel environments. We argue that the GUI grounding models should be further\naligned to the novel environments to reveal their full potential, when the\ninference is known to involve novel environments, i.e., environments not used\nduring the previous fine-tuning. To realize this, we first propose GUI-Bee, an\nMLLM-based autonomous agent, to collect high-quality, environment-specific data\nthrough exploration and then continuously fine-tune GUI grounding models with\nthe collected data. Our agent leverages a novel Q-value-Incentive In-Context\nReinforcement Learning (Q-ICRL) method to optimize exploration efficiency and\ndata quality. Additionally, we introduce NovelScreenSpot, a benchmark for\ntesting how well the data can help align GUI action grounding models to novel\nenvironments and demonstrate the effectiveness of data collected by GUI-Bee in\nthe experiments. Furthermore, we conduct an ablation study to validate the\nQ-ICRL method in enhancing the efficiency of GUI-Bee. Project page:\nhttps://gui-bee.github.io",
      "tldr_zh": "该论文提出 GUI-Bee，一种基于 MLLM 的自主代理，用于通过探索新环境收集高质量数据，从而提升 GUI 行动定位模型在新环境下的性能。GUI-Bee 采用 Q-value-Incentive In-Context Reinforcement Learning (Q-ICRL) 方法优化探索效率和数据质量，并使用收集的数据持续微调模型。实验在 NovelScreenSpot 基准上验证了该方法的有效性，证明了它能显著改善模型在新环境的适应性，并通过消融研究确认了 Q-ICRL 的关键作用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.13896v2",
      "published_date": "2025-01-23 18:16:21 UTC",
      "updated_date": "2025-01-27 18:58:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:20:18.215471"
    },
    {
      "arxiv_id": "2501.13893v1",
      "title": "Pix2Cap-COCO: Advancing Visual Comprehension via Pixel-Level Captioning",
      "title_zh": "翻译失败",
      "authors": [
        "Zuyao You",
        "Junke Wang",
        "Lingyu Kong",
        "Bo He",
        "Zuxuan Wu"
      ],
      "abstract": "We present Pix2Cap-COCO, the first panoptic pixel-level caption dataset\ndesigned to advance fine-grained visual understanding. To achieve this, we\ncarefully design an automated annotation pipeline that prompts GPT-4V to\ngenerate pixel-aligned, instance-specific captions for individual objects\nwithin images, enabling models to learn more granular relationships between\nobjects and their contexts. This approach results in 167,254 detailed captions,\nwith an average of 22.94 words per caption. Building on Pix2Cap-COCO, we\nintroduce a novel task, panoptic segmentation-captioning, which challenges\nmodels to recognize instances in an image and provide detailed descriptions for\neach simultaneously. To benchmark this task, we design a robust baseline based\non X-Decoder. The experimental results demonstrate that Pix2Cap-COCO is a\nparticularly challenging dataset, as it requires models to excel in both\nfine-grained visual understanding and detailed language generation.\nFurthermore, we leverage Pix2Cap-COCO for Supervised Fine-Tuning (SFT) on large\nmultimodal models (LMMs) to enhance their performance. For example, training\nwith Pix2Cap-COCO significantly improves the performance of GPT4RoI, yielding\ngains in CIDEr +1.4%, ROUGE +0.4%, and SPICE +0.5% on Visual Genome dataset,\nand strengthens its region understanding ability on the ViP-BENCH, with an\noverall improvement of +5.1%, including notable increases in recognition\naccuracy +11.2% and language generation quality +22.2%.",
      "tldr_zh": "本研究引入了 Pix2Cap-COCO，这是首个全景像素级标题数据集，旨在提升细粒度视觉理解。该数据集通过一个自动化标注管道，利用 GPT-4V 生成167,254个像素对齐的实例特定标题，每个标题平均22.94词，强调对象及其上下文的粒度关系。论文同时提出一个新任务——全景分割-标题化（panoptic segmentation-captioning），要求模型同时识别图像实例并提供详细描述，并以 X-Decoder 为基准模型进行评估，结果显示该数据集对细粒度视觉理解和语言生成提出了重大挑战。此外，将 Pix2Cap-COCO 用于 Supervised Fine-Tuning (SFT) 大型多模态模型 (LMMs) 时，如 GPT4RoI，在 Visual Genome 数据集上提升 CIDEr +1.4%、ROUGE +0.4%、SPICE +0.5%，并在 ViP-BENCH 上整体改善 +5.1%，包括识别准确率 +11.2% 和语言生成质量 +22.2%。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.13893v1",
      "published_date": "2025-01-23 18:08:57 UTC",
      "updated_date": "2025-01-23 18:08:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:19:41.436819"
    },
    {
      "arxiv_id": "2501.14836v1",
      "title": "Symbolic Knowledge Extraction and Injection with Sub-symbolic Predictors: A Systematic Literature Review",
      "title_zh": "翻译失败",
      "authors": [
        "Giovanni Ciatto",
        "Federico Sabbatini",
        "Andrea Agiollo",
        "Matteo Magnini",
        "Andrea Omicini"
      ],
      "abstract": "In this paper we focus on the opacity issue of sub-symbolic machine learning\npredictors by promoting two complementary activities, namely, symbolic\nknowledge extraction (SKE) and injection (SKI) from and into sub-symbolic\npredictors. We consider as symbolic any language being intelligible and\ninterpretable for both humans and computers. Accordingly, we propose general\nmeta-models for both SKE and SKI, along with two taxonomies for the\nclassification of SKE and SKI methods. By adopting an explainable artificial\nintelligence (XAI) perspective, we highlight how such methods can be exploited\nto mitigate the aforementioned opacity issue. Our taxonomies are attained by\nsurveying and classifying existing methods from the literature, following a\nsystematic approach, and by generalising the results of previous surveys\ntargeting specific sub-topics of either SKE or SKI alone. More precisely, we\nanalyse 132 methods for SKE and 117 methods for SKI, and we categorise them\naccording to their purpose, operation, expected input/output data and predictor\ntypes. For each method, we also indicate the presence/lack of runnable software\nimplementations. Our work may be of interest for data scientists aiming at\nselecting the most adequate SKE/SKI method for their needs, and also work as\nsuggestions for researchers interested in filling the gaps of the current state\nof the art, as well as for developers willing to implement SKE/SKI-based\ntechnologies.",
      "tldr_zh": "本文通过系统文献综述，探讨了从子符号预测器（Sub-symbolic Predictors）中提取和注入符号知识（Symbolic Knowledge Extraction, SKE 和 Symbolic Knowledge Injection, SKI）的技术，以缓解机器学习模型的不透明性问题。论文提出了 SKE 和 SKI 的通用元模型，以及两套用于分类这些方法的税onomies，从可解释人工智能（XAI）的角度分析其应用潜力。研究分析了132个 SKE 方法和117个 SKI 方法，根据目的、操作、输入/输出数据以及预测器类型进行分类，并评估了每个方法的软件实现可用性。该工作为数据科学家选择合适方法、研究者填补研究空白以及开发者实现相关技术提供了宝贵指导。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.14836v1",
      "published_date": "2025-01-23 18:00:05 UTC",
      "updated_date": "2025-01-23 18:00:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:19:54.031215"
    },
    {
      "arxiv_id": "2501.13884v1",
      "title": "Exploring Finetuned Audio-LLM on Heart Murmur Features",
      "title_zh": "翻译失败",
      "authors": [
        "Adrian Florea",
        "Xilin Jiang",
        "Nima Mesgarani",
        "Xiaofan Jiang"
      ],
      "abstract": "Large language models (LLMs) for audio have excelled in recognizing and\nanalyzing human speech, music, and environmental sounds. However, their\npotential for understanding other types of sounds, particularly biomedical\nsounds, remains largely underexplored despite significant scientific interest.\nIn this study, we focus on diagnosing cardiovascular diseases using\nphonocardiograms, i.e., heart sounds. Most existing deep neural network (DNN)\nparadigms are restricted to heart murmur classification (healthy vs unhealthy)\nand do not predict other acoustic features of the murmur such as timing,\ngrading, harshness, pitch, and quality, which are important in helping\nphysicians diagnose the underlying heart conditions. We propose to finetune an\naudio LLM, Qwen2-Audio, on the PhysioNet CirCor DigiScope phonocardiogram (PCG)\ndataset and evaluate its performance in classifying 11 expert-labeled murmur\nfeatures. Additionally, we aim to achieve more noise-robust and generalizable\nsystem by exploring a preprocessing segmentation algorithm using an audio\nrepresentation model, SSAMBA. Our results indicate that the LLM-based model\noutperforms state-of-the-art methods in 8 of the 11 features and performs\ncomparably in the remaining 3. Moreover, the LLM successfully classifies\nlong-tail murmur features with limited training data, a task that all previous\nmethods have failed to classify. These findings underscore the potential of\naudio LLMs as assistants to human cardiologists in enhancing heart disease\ndiagnosis.",
      "tldr_zh": "该研究探讨了微调音频大型语言模型 (Audio-LLM) Qwen2-Audio，以分析心音特征，从而辅助心血管疾病诊断。研究聚焦于 PhysioNet CirCor DigiScope 数据集，评估模型在分类 11 个专家标记的心音特征（如 timing、grading、harshness、pitch 和 quality）上的性能，并引入 SSAMBA 音频表示模型进行预处理，以提升噪声鲁棒性和泛化能力。结果表明，该 LLM-based 模型在 11 个特征中优于现有深度神经网络 (DNN) 方法（8 个特征表现更好，3 个相当），并成功处理了训练数据有限的长尾特征，这是先前方法未能实现的部分。这些发现突出了音频 LLMs 作为人类心脏病医生辅助工具的潜力。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "5 pages, 1 figure, and 3 tables. Submitted to IEEE/ACM Conference on\n  Connected Health: Applications, Systems , and Engineering Technologies",
      "pdf_url": "http://arxiv.org/pdf/2501.13884v1",
      "published_date": "2025-01-23 17:57:18 UTC",
      "updated_date": "2025-01-23 17:57:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:20:04.016816"
    },
    {
      "arxiv_id": "2501.13864v1",
      "title": "Autoencoders for Anomaly Detection are Unreliable",
      "title_zh": "自编码器用于异常检测是不可靠的",
      "authors": [
        "Roel Bouman",
        "Tom Heskes"
      ],
      "abstract": "Autoencoders are frequently used for anomaly detection, both in the\nunsupervised and semi-supervised settings. They rely on the assumption that\nwhen trained using the reconstruction loss, they will be able to reconstruct\nnormal data more accurately than anomalous data. Some recent works have posited\nthat this assumption may not always hold, but little has been done to study the\nvalidity of the assumption in theory. In this work we show that this assumption\nindeed does not hold, and illustrate that anomalies, lying far away from normal\ndata, can be perfectly reconstructed in practice. We revisit the theory of\nfailure of linear autoencoders for anomaly detection by showing how they can\nperfectly reconstruct out of bounds, or extrapolate undesirably, and note how\nthis can be dangerous in safety critical applications. We connect this to\nnon-linear autoencoders through experiments on both tabular data and real-world\nimage data, the two primary application areas of autoencoders for anomaly\ndetection.",
      "tldr_zh": "本研究质疑 autoencoders 在异常检测中的可靠性，指出其核心假设——即 autoencoders 可以更准确地重建正常数据而非异常数据——实际上并不成立。通过理论分析，论文证明线性 autoencoders 可能完美重建超出范围的异常数据，这在安全关键应用中存在风险。实验在表格数据和真实图像数据上验证了这一问题扩展到非线性 autoencoders，进一步强调了 autoencoders 在异常检测领域的潜在局限性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.13864v1",
      "published_date": "2025-01-23 17:36:48 UTC",
      "updated_date": "2025-01-23 17:36:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:20:30.010112"
    },
    {
      "arxiv_id": "2501.13848v1",
      "title": "Where Do You Go? Pedestrian Trajectory Prediction using Scene Features",
      "title_zh": "Where Do You Go?：使用场景特征的行人轨迹预测",
      "authors": [
        "Mohammad Ali Rezaei",
        "Fardin Ayar",
        "Ehsan Javanmardi",
        "Manabu Tsukada",
        "Mahdi Javanmardi"
      ],
      "abstract": "Accurate prediction of pedestrian trajectories is crucial for enhancing the\nsafety of autonomous vehicles and reducing traffic fatalities involving\npedestrians. While numerous studies have focused on modeling interactions among\npedestrians to forecast their movements, the influence of environmental factors\nand scene-object placements has been comparatively underexplored. In this\npaper, we present a novel trajectory prediction model that integrates both\npedestrian interactions and environmental context to improve prediction\naccuracy. Our approach captures spatial and temporal interactions among\npedestrians within a sparse graph framework. To account for pedestrian-scene\ninteractions, we employ advanced image enhancement and semantic segmentation\ntechniques to extract detailed scene features. These scene and interaction\nfeatures are then fused through a cross-attention mechanism, enabling the model\nto prioritize relevant environmental factors that influence pedestrian\nmovements. Finally, a temporal convolutional network processes the fused\nfeatures to predict future pedestrian trajectories. Experimental results\ndemonstrate that our method significantly outperforms existing state-of-the-art\napproaches, achieving ADE and FDE values of 0.252 and 0.372 meters,\nrespectively, underscoring the importance of incorporating both social\ninteractions and environmental context in pedestrian trajectory prediction.",
      "tldr_zh": "这篇论文提出了一种新型行人轨迹预测模型，旨在通过整合行人互动和环境上下文来提升自动驾驶车辆的安全性。模型使用sparse graph框架捕获行人之间的空间和时间互动，并通过图像增强和语义分割技术提取详细的场景特征，然后借助cross-attention mechanism融合这些特征。实验结果显示，该方法在标准数据集上显著优于现有技术，ADE和FDE值分别达到0.252和0.372米，强调了环境因素在预测中的关键作用。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by 2024 International Conference on Intelligent Computing\n  and its Emerging Applications",
      "pdf_url": "http://arxiv.org/pdf/2501.13848v1",
      "published_date": "2025-01-23 17:15:26 UTC",
      "updated_date": "2025-01-23 17:15:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:20:41.072576"
    },
    {
      "arxiv_id": "2501.13833v1",
      "title": "On the Reasoning Capacity of AI Models and How to Quantify It",
      "title_zh": "翻译失败",
      "authors": [
        "Santosh Kumar Radha",
        "Oktay Goktas"
      ],
      "abstract": "Recent advances in Large Language Models (LLMs) have intensified the debate\nsurrounding the fundamental nature of their reasoning capabilities. While\nachieving high performance on benchmarks such as GPQA and MMLU, these models\nexhibit limitations in more complex reasoning tasks, highlighting the need for\nmore rigorous evaluation methodologies. We propose a novel phenomenological\napproach that goes beyond traditional accuracy metrics to probe the underlying\nmechanisms of model behavior, establishing a framework that could broadly\nimpact how we analyze and understand AI systems. Using positional bias in\nmultiple-choice reasoning tasks as a case study, we demonstrate how systematic\nperturbations can reveal fundamental aspects of model decision-making. To\nanalyze these behaviors, we develop two complementary phenomenological models:\na Probabilistic Mixture Model (PMM) that decomposes model responses into\nreasoning, memorization, and guessing components and an Information-Theoretic\nConsistency (ITC) analysis that quantifies the relationship between model\nconfidence and strategy selection. Through controlled experiments on reasoning\nbenchmarks, we show that true reasoning remains challenging for current models,\nwith apparent success often relying on sophisticated combinations of\nmemorization and pattern matching rather than genuine logical deduction. More\nfundamentally, we demonstrate that accuracy alone often overstates a model's\nreasoning abilities, as model behavior can be characterized through underlying\nmechanisms in the phase space of cognitive strategies, revealing how models\ndynamically balance different approaches when responding to queries. This\nframework enables quantitative criteria for real-world deployments, allowing\napplications to specify reliability thresholds based on strategy distributions\nrather than aggregate performance metrics.",
      "tldr_zh": "本研究探讨了大型语言模型（LLMs）的推理能力及其量化方法，指出尽管LLMs在GPQA和MMLU等基准测试中表现出色，但它们在复杂任务中存在局限性，往往依赖记忆和模式匹配而非真正的逻辑推理。作者提出了一种新型现象学方法，通过系统扰动（如位置偏差）分析模型行为，并开发了Probabilistic Mixture Model (PMM)来分解响应为推理、记忆和猜测组件，以及Information-Theoretic Consistency (ITC)分析来量化模型置信度与策略选择的关系。实验结果显示，准确率可能夸大模型能力，因为模型行为在认知策略的相空间中动态平衡不同方法。该框架为AI系统的实际部署提供量化标准，允许基于策略分布设定可靠性阈值，以提升评估的可靠性和实用性。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.IT",
        "math.IT"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.13833v1",
      "published_date": "2025-01-23 16:58:18 UTC",
      "updated_date": "2025-01-23 16:58:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:20:53.742403"
    },
    {
      "arxiv_id": "2501.13831v1",
      "title": "Predicting Compact Phrasal Rewrites with Large Language Models for ASR Post Editing",
      "title_zh": "翻译失败",
      "authors": [
        "Hao Zhang",
        "Felix Stahlberg",
        "Shankar Kumar"
      ],
      "abstract": "Large Language Models (LLMs) excel at rewriting tasks such as text style\ntransfer and grammatical error correction. While there is considerable overlap\nbetween the inputs and outputs in these tasks, the decoding cost still\nincreases with output length, regardless of the amount of overlap. By\nleveraging the overlap between the input and the output, Kaneko and Okazaki\n(2023) proposed model-agnostic edit span representations to compress the\nrewrites to save computation. They reported an output length reduction rate of\nnearly 80% with minimal accuracy impact in four rewriting tasks. In this paper,\nwe propose alternative edit phrase representations inspired by phrase-based\nstatistical machine translation. We systematically compare our phrasal\nrepresentations with their span representations. We apply the LLM rewriting\nmodel to the task of Automatic Speech Recognition (ASR) post editing and show\nthat our target-phrase-only edit representation has the best\nefficiency-accuracy trade-off. On the LibriSpeech test set, our method closes\n50-60% of the WER gap between the edit span model and the full rewrite model\nwhile losing only 10-20% of the length reduction rate of the edit span model.",
      "tldr_zh": "本文提出一种基于短语的编辑表示方法，用于 Large Language Models (LLMs) 在 Automatic Speech Recognition (ASR) 后编辑任务中的重写优化。该方法受短语统计机器翻译启发，并与现有编辑跨度表示进行系统比较，旨在提高效率同时保持准确性。在 LibriSpeech 测试集上，目标短语编辑表示关闭了50-60%的 Word Error Rate (WER) 差距，仅损失10-20%的输出长度减少率，从而提供最佳的效率-准确性权衡。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "accepted by ICASSP 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.13831v1",
      "published_date": "2025-01-23 16:54:27 UTC",
      "updated_date": "2025-01-23 16:54:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:21:05.348858"
    },
    {
      "arxiv_id": "2501.13830v1",
      "title": "A space-decoupling framework for optimization on bounded-rank matrices with orthogonally invariant constraints",
      "title_zh": "一种用于带有正交不变约束的有界秩矩阵优化的空间解耦框架",
      "authors": [
        "Yan Yang",
        "Bin Gao",
        "Ya-xiang Yuan"
      ],
      "abstract": "Imposing additional constraints on low-rank optimization has garnered growing\ninterest. However, the geometry of coupled constraints hampers the\nwell-developed low-rank structure and makes the problem intricate. To this end,\nwe propose a space-decoupling framework for optimization on bounded-rank\nmatrices with orthogonally invariant constraints. The ``space-decoupling\" is\nreflected in several ways. We show that the tangent cone of coupled constraints\nis the intersection of tangent cones of each constraint. Moreover, we decouple\nthe intertwined bounded-rank and orthogonally invariant constraints into two\nspaces, leading to optimization on a smooth manifold. Implementing Riemannian\nalgorithms on this manifold is painless as long as the geometry of additional\nconstraints is known. In addition, we unveil the equivalence between the\nreformulated problem and the original problem. Numerical experiments on\nreal-world applications -- spherical data fitting, graph similarity measuring,\nlow-rank SDP, model reduction of Markov processes, reinforcement learning, and\ndeep learning -- validate the superiority of the proposed framework.",
      "tldr_zh": "本论文提出了一种space-decoupling framework，用于优化带有orthogonally invariant constraints的bounded-rank matrices问题，通过解耦约束的几何结构（如切锥的交集）将耦合的低秩和正交不变约束分离到两个空间中，使优化问题转化为在平滑流形上的任务。该框架允许轻松实现Riemannian algorithms，前提是额外约束的几何已知，并证明了重构问题与原问题的等价性。实验在spherical data fitting、graph similarity measuring、low-rank SDP等真实应用中验证了该框架的优越性，展示了更高的性能。",
      "categories": [
        "math.OC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "math.OC",
      "comment": "48 pages, 12 figures, 6 tables",
      "pdf_url": "http://arxiv.org/pdf/2501.13830v1",
      "published_date": "2025-01-23 16:54:03 UTC",
      "updated_date": "2025-01-23 16:54:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:21:17.688023"
    },
    {
      "arxiv_id": "2501.14009v2",
      "title": "Scalable and Interpretable Verification of Image-based Neural Network Controllers for Autonomous Vehicles",
      "title_zh": "可扩展且可解释的基于图像的神经网络控制器验证",
      "authors": [
        "Aditya Parameshwaran",
        "Yue Wang"
      ],
      "abstract": "Existing formal verification methods for image-based neural network\ncontrollers in autonomous vehicles often struggle with high-dimensional inputs,\ncomputational inefficiency, and a lack of explainability. These challenges make\nit difficult to ensure safety and reliability, as processing high-dimensional\nimage data is computationally intensive and neural networks are typically\ntreated as black boxes. To address these issues, we propose SEVIN (Scalable and\nExplainable Verification of Image-Based Neural Network Controllers), a\nframework that leverages a Variational Autoencoders (VAE) to encode\nhigh-dimensional images into a lower-dimensional, explainable latent space. By\nannotating latent variables with corresponding control actions, we generate\nconvex polytopes that serve as structured input spaces for verification,\nsignificantly reducing computational complexity and enhancing scalability.\nIntegrating the VAE's decoder with the neural network controller allows for\nformal and robustness verification using these explainable polytopes. Our\napproach also incorporates robustness verification under real-world\nperturbations by augmenting the dataset and retraining the VAE to capture\nenvironmental variations. Experimental results demonstrate that SEVIN achieves\nefficient and scalable verification while providing explainable insights into\ncontroller behavior, bridging the gap between formal verification techniques\nand practical applications in safety-critical systems.",
      "tldr_zh": "该论文针对图像-based 神经网络控制器在自动驾驶车辆中的验证问题，提出了 SEVIN（Scalable and Explainable Verification of Image-Based Neural Network Controllers）框架，以解决高维输入计算密集和缺乏可解释性的挑战。SEVIN 利用 Variational Autoencoders (VAE) 将高维图像编码成低维、可解释的潜在空间，并通过标注潜在变量生成凸多面体作为结构化输入空间，从而降低计算复杂度和提升可扩展性。该框架整合 VAE 解码器与神经网络控制器，进行正式验证和鲁棒性验证，包括处理真实世界扰动；实验结果显示，SEVIN 实现了高效验证，并提供了对控制器行为的解释性洞见，促进了安全关键系统中的实际应用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "11 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.14009v2",
      "published_date": "2025-01-23 16:46:45 UTC",
      "updated_date": "2025-03-17 18:01:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:21:29.303833"
    },
    {
      "arxiv_id": "2501.13824v1",
      "title": "Hallucinations Can Improve Large Language Models in Drug Discovery",
      "title_zh": "幻觉可以改善大型语言模型在药物发现中的应用",
      "authors": [
        "Shuzhou Yuan",
        "Michael Färber"
      ],
      "abstract": "Concerns about hallucinations in Large Language Models (LLMs) have been\nraised by researchers, yet their potential in areas where creativity is vital,\nsuch as drug discovery, merits exploration. In this paper, we come up with the\nhypothesis that hallucinations can improve LLMs in drug discovery. To verify\nthis hypothesis, we use LLMs to describe the SMILES string of molecules in\nnatural language and then incorporate these descriptions as part of the prompt\nto address specific tasks in drug discovery. Evaluated on seven LLMs and five\nclassification tasks, our findings confirm the hypothesis: LLMs can achieve\nbetter performance with text containing hallucinations. Notably, Llama-3.1-8B\nachieves an 18.35% gain in ROC-AUC compared to the baseline without\nhallucination. Furthermore, hallucinations generated by GPT-4o provide the most\nconsistent improvements across models. Additionally, we conduct empirical\nanalyses and a case study to investigate key factors affecting performance and\nthe underlying reasons. Our research sheds light on the potential use of\nhallucinations for LLMs and offers new perspectives for future research\nleveraging LLMs in drug discovery.",
      "tldr_zh": "本论文假设幻觉(hallucinations)可以提升大型语言模型(LLMs)在药物发现中的性能，并通过实验验证这一观点。该方法使用 LLMs 将分子 SMILES 字符串描述为自然语言，并将其作为提示的一部分应用于五个分类任务。在七个 LLMs 的评估中，带有幻觉的文本显著提高了性能，例如 Llama-3.1-8B 的 ROC-AUC 提升 18.35%，而 GPT-4o 生成的幻觉提供最一致的改进。通过实证分析和案例研究，论文揭示了影响因素，并为未来 LLMs 在药物发现中的应用提供了新视角。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.13824v1",
      "published_date": "2025-01-23 16:45:51 UTC",
      "updated_date": "2025-01-23 16:45:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:21:42.199822"
    },
    {
      "arxiv_id": "2501.13818v1",
      "title": "Ensuring Medical AI Safety: Explainable AI-Driven Detection and Mitigation of Spurious Model Behavior and Associated Data",
      "title_zh": "翻译失败",
      "authors": [
        "Frederik Pahde",
        "Thomas Wiegand",
        "Sebastian Lapuschkin",
        "Wojciech Samek"
      ],
      "abstract": "Deep neural networks are increasingly employed in high-stakes medical\napplications, despite their tendency for shortcut learning in the presence of\nspurious correlations, which can have potentially fatal consequences in\npractice. Detecting and mitigating shortcut behavior is a challenging task that\noften requires significant labeling efforts from domain experts. To alleviate\nthis problem, we introduce a semi-automated framework for the identification of\nspurious behavior from both data and model perspective by leveraging insights\nfrom eXplainable Artificial Intelligence (XAI). This allows the retrieval of\nspurious data points and the detection of model circuits that encode the\nassociated prediction rules. Moreover, we demonstrate how these shortcut\nencodings can be used for XAI-based sample- and pixel-level data annotation,\nproviding valuable information for bias mitigation methods to unlearn the\nundesired shortcut behavior. We show the applicability of our framework using\nfour medical datasets across two modalities, featuring controlled and\nreal-world spurious correlations caused by data artifacts. We successfully\nidentify and mitigate these biases in VGG16, ResNet50, and contemporary Vision\nTransformer models, ultimately increasing their robustness and applicability\nfor real-world medical tasks.",
      "tldr_zh": "本文提出一个基于 eXplainable AI (XAI) 的半自动框架，用于检测和缓解深度神经网络在医疗应用中的 spurious correlations 和 shortcut learning，这些问题可能导致致命风险。该框架从数据和模型角度识别 spurious 数据点以及编码预测规则的模型 circuits，并利用这些信息进行样本和像素级数据标注，以支持偏差缓解方法。在四个医疗数据集上实验验证，该方法成功提升了 VGG16、ResNet50 和 Vision Transformer 模型的鲁棒性，提高了其在真实世界医疗任务中的适用性。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.13818v1",
      "published_date": "2025-01-23 16:39:09 UTC",
      "updated_date": "2025-01-23 16:39:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:21:53.750804"
    },
    {
      "arxiv_id": "2502.05186v1",
      "title": "Multimodal Stock Price Prediction",
      "title_zh": "多模态股票价格预测",
      "authors": [
        "Furkan Karadaş",
        "Bahaeddin Eravcı",
        "Ahmet Murat Özbayoğlu"
      ],
      "abstract": "In an era where financial markets are heavily influenced by many static and\ndynamic factors, it has become increasingly critical to carefully integrate\ndiverse data sources with machine learning for accurate stock price prediction.\nThis paper explores a multimodal machine learning approach for stock price\nprediction by combining data from diverse sources, including traditional\nfinancial metrics, tweets, and news articles. We capture real-time market\ndynamics and investor mood through sentiment analysis on these textual data\nusing both ChatGPT-4o and FinBERT models. We look at how these integrated data\nstreams augment predictions made with a standard Long Short-Term Memory (LSTM\nmodel) to illustrate the extent of performance gains. Our study's results\nindicate that incorporating the mentioned data sources considerably increases\nthe forecast effectiveness of the reference model by up to 5%. We also provide\ninsights into the individual and combined predictive capacities of these\nmodalities, highlighting the substantial impact of incorporating sentiment\nanalysis from tweets and news articles. This research offers a systematic and\neffective framework for applying multimodal data analytics techniques in\nfinancial time series forecasting that provides a new view for investors to\nleverage data for decision-making.",
      "tldr_zh": "这篇论文探讨了多模态机器学习在股票价格预测中的应用，通过整合传统金融指标、Twitter 和新闻文章等多源数据。研究利用 ChatGPT-4o 和 FinBERT 进行情感分析，以捕捉实时市场动态和投资者情绪，并将其与标准 Long Short-Term Memory (LSTM) 模型结合，提升预测性能。结果显示，这种整合方法将基准模型的预测有效性提高高达 5%，并突出了情感分析在提升预测准确性方面的显著作用。该框架为投资者提供了系统化的多模态数据分析方法，支持金融时间序列预测决策。",
      "categories": [
        "q-fin.ST",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-fin.ST",
      "comment": "9 pages, 6 table",
      "pdf_url": "http://arxiv.org/pdf/2502.05186v1",
      "published_date": "2025-01-23 16:38:46 UTC",
      "updated_date": "2025-01-23 16:38:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:22:05.349742"
    },
    {
      "arxiv_id": "2501.13810v2",
      "title": "Learning to Help in Multi-Class Settings",
      "title_zh": "翻译失败",
      "authors": [
        "Yu Wu",
        "Yansong Li",
        "Zeyu Dong",
        "Nitya Sathyavageeswaran",
        "Anand D. Sarwate"
      ],
      "abstract": "Deploying complex machine learning models on resource-constrained devices is\nchallenging due to limited computational power, memory, and model\nretrainability. To address these limitations, a hybrid system can be\nestablished by augmenting the local model with a server-side model, where\nsamples are selectively deferred by a rejector and then sent to the server for\nprocessing. The hybrid system enables efficient use of computational resources\nwhile minimizing the overhead associated with server usage. The recently\nproposed Learning to Help (L2H) model trains a server model given a fixed local\n(client) model, differing from the Learning to Defer (L2D) framework, which\ntrains the client for a fixed (expert) server. In both L2D and L2H, the\ntraining includes learning a rejector at the client to determine when to query\nthe server. In this work, we extend the L2H model from binary to multi-class\nclassification problems and demonstrate its applicability in a number of\ndifferent scenarios of practical interest in which access to the server may be\nlimited by cost, availability, or policy. We derive a stage-switching surrogate\nloss function that is differentiable, convex, and consistent with the Bayes\nrule corresponding to the 0-1 loss for the L2H model. Experiments show that our\nproposed methods offer an efficient and practical solution for multi-class\nclassification in resource-constrained environments.",
      "tldr_zh": "该研究针对资源受限设备上部署复杂机器学习模型的挑战，提出扩展 Learning to Help (L2H) 框架应用于多类分类问题。该框架通过一个混合系统，将本地模型与服务器模型结合，并使用一个拒绝器（rejector）选择性地将样本发送到服务器处理，从而优化计算资源利用。研究推导了一个可微、凸的 stage-switching 代理损失函数，与 L2H 的 Bayes 规则一致，并在服务器访问受限的实际场景中证明其有效性。实验结果表明，该方法为多类分类在资源受限环境提供高效、实用的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "30 pages, 7 figures, conference, ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.13810v2",
      "published_date": "2025-01-23 16:32:01 UTC",
      "updated_date": "2025-04-17 03:05:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:22:17.341205"
    },
    {
      "arxiv_id": "2501.13787v1",
      "title": "Parameter-Efficient Fine-Tuning for Foundation Models",
      "title_zh": "参数高效微调基础模型",
      "authors": [
        "Dan Zhang",
        "Tao Feng",
        "Lilong Xue",
        "Yuandong Wang",
        "Yuxiao Dong",
        "Jie Tang"
      ],
      "abstract": "This survey delves into the realm of Parameter-Efficient Fine-Tuning (PEFT)\nwithin the context of Foundation Models (FMs). PEFT, a cost-effective\nfine-tuning technique, minimizes parameters and computational complexity while\nstriving for optimal downstream task performance. FMs, like ChatGPT, DALL-E,\nand LLaVA specialize in language understanding, generative tasks, and\nmultimodal tasks, trained on diverse datasets spanning text, images, and\nvideos. The diversity of FMs guides various adaptation strategies for PEFT.\nTherefore, this survey aims to provide a comprehensive overview of PEFT\ntechniques applied to diverse FMs and address critical gaps in understanding\nthe techniques, trends, and applications. We start by providing a detailed\ndevelopment of FMs and PEFT. Subsequently, we systematically review the key\ncategories and core mechanisms of PEFT across diverse FMs to offer a\ncomprehensive understanding of trends. We also explore the most recent\napplications across various FMs to demonstrate the versatility of PEFT,\nshedding light on the integration of systematic PEFT methods with a range of\nFMs. Furthermore, we identify potential research and development directions for\nimproving PEFTs in the future. This survey provides a valuable resource for\nboth newcomers and experts seeking to understand and use the power of PEFT\nacross FMs. All reviewed papers are listed at\n\\url{https://github.com/THUDM/Awesome-Parameter-Efficient-Fine-Tuning-for-Foundation-Models}.",
      "tldr_zh": "这篇调查论文探讨了Parameter-Efficient Fine-Tuning (PEFT)，一种高效的微调技术，用于Foundation Models (FMs)如ChatGPT和DALL-E，以最小化参数和计算资源，同时优化下游任务性能。论文系统回顾了PEFT的关键类别、核心机制及其在多样化FMs（如语言、生成和多模态模型）上的应用趋势，并展示了其在实际场景中的多功能性。最终，它指出了未来PEFT研究的潜在方向，并提供了一个资源列表（https://github.com/THUDM/Awesome-Parameter-Efficient-Fine-Tuning-for-Foundation-Models），为研究者提供宝贵参考。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "25 pages, 6 figures, 7 tables",
      "pdf_url": "http://arxiv.org/pdf/2501.13787v1",
      "published_date": "2025-01-23 16:04:23 UTC",
      "updated_date": "2025-01-23 16:04:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:22:29.394948"
    },
    {
      "arxiv_id": "2501.13782v1",
      "title": "Defending against Adversarial Malware Attacks on ML-based Android Malware Detection Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Ping He",
        "Lorenzo Cavallaro",
        "Shouling Ji"
      ],
      "abstract": "Android malware presents a persistent threat to users' privacy and data\nintegrity. To combat this, researchers have proposed machine learning-based\n(ML-based) Android malware detection (AMD) systems. However, adversarial\nAndroid malware attacks compromise the detection integrity of the ML-based AMD\nsystems, raising significant concerns. Existing defenses against adversarial\nAndroid malware provide protections against feature space attacks which\ngenerate adversarial feature vectors only, leaving protection against realistic\nthreats from problem space attacks which generate real adversarial malware an\nopen problem. In this paper, we address this gap by proposing ADD, a practical\nadversarial Android malware defense framework designed as a plug-in to enhance\nthe adversarial robustness of the ML-based AMD systems against problem space\nattacks. Our extensive evaluation across various ML-based AMD systems\ndemonstrates that ADD is effective against state-of-the-art problem space\nadversarial Android malware attacks. Additionally, ADD shows the defense\neffectiveness in enhancing the adversarial robustness of real-world antivirus\nsolutions.",
      "tldr_zh": "本文研究了敌对恶意软件攻击对基于机器学习 (ML-based) 的 Android 恶意软件检测 (AMD) 系统的影响，指出现有防御主要针对特征空间攻击，而忽略了更真实的問題空间攻击。作者提出 ADD 框架，作为一个插件设计，用于增强 ML-based AMD 系统对抗問題空间攻击的鲁棒性。该框架通过广泛评估在各种 AMD 系统上证明其有效性，能够抵御最先进的敌对攻击，并显著提升真实世界防病毒解决方案的对抗能力。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG",
        "cs.SE"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.13782v1",
      "published_date": "2025-01-23 15:59:01 UTC",
      "updated_date": "2025-01-23 15:59:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:22:41.533851"
    },
    {
      "arxiv_id": "2501.13779v1",
      "title": "Not Every AI Problem is a Data Problem: We Should Be Intentional About Data Scaling",
      "title_zh": "翻译失败",
      "authors": [
        "Tanya Rodchenko",
        "Natasha Noy",
        "Nino Scherrer",
        "Jennifer Prendki"
      ],
      "abstract": "While Large Language Models require more and more data to train and scale,\nrather than looking for any data to acquire, we should consider what types of\ntasks are more likely to benefit from data scaling. We should be intentional in\nour data acquisition. We argue that the topology of data itself informs which\ntasks to prioritize in data scaling, and shapes the development of the next\ngeneration of compute paradigms for tasks where data scaling is inefficient, or\neven insufficient.",
      "tldr_zh": "这篇论文主张，并非所有AI问题都依赖数据扩展，而是应该有针对性地选择任务，以最大化Large Language Models的训练效果。作者强调，数据拓扑（topology of data）可以指导优先扩展哪些任务，并塑造下一代计算范式，以应对数据扩展低效或不足的情况。通过有意的数据获取策略，论文为AI发展提供更高效的路径，避免盲目追求数据规模。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.13779v1",
      "published_date": "2025-01-23 15:58:14 UTC",
      "updated_date": "2025-01-23 15:58:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:22:52.427785"
    },
    {
      "arxiv_id": "2501.13772v1",
      "title": "Tune In, Act Up: Exploring the Impact of Audio Modality-Specific Edits on Large Audio Language Models in Jailbreak",
      "title_zh": "翻译失败",
      "authors": [
        "Erjia Xiao",
        "Hao Cheng",
        "Jing Shao",
        "Jinhao Duan",
        "Kaidi Xu",
        "Le Yang",
        "Jindong Gu",
        "Renjing Xu"
      ],
      "abstract": "Large Language Models (LLMs) demonstrate remarkable zero-shot performance\nacross various natural language processing tasks. The integration of multimodal\nencoders extends their capabilities, enabling the development of Multimodal\nLarge Language Models that process vision, audio, and text. However, these\ncapabilities also raise significant security concerns, as these models can be\nmanipulated to generate harmful or inappropriate content through jailbreak.\nWhile extensive research explores the impact of modality-specific input edits\non text-based LLMs and Large Vision-Language Models in jailbreak, the effects\nof audio-specific edits on Large Audio-Language Models (LALMs) remain\nunderexplored. Hence, this paper addresses this gap by investigating how\naudio-specific edits influence LALMs inference regarding jailbreak. We\nintroduce the Audio Editing Toolbox (AET), which enables audio-modality edits\nsuch as tone adjustment, word emphasis, and noise injection, and the Edited\nAudio Datasets (EADs), a comprehensive audio jailbreak benchmark. We also\nconduct extensive evaluations of state-of-the-art LALMs to assess their\nrobustness under different audio edits. This work lays the groundwork for\nfuture explorations on audio-modality interactions in LALMs security.",
      "tldr_zh": "本文探讨了音频特定编辑对大型音频语言模型(LALMs)在jailbreak中的影响，填补了现有研究对音频模态安全的空白。研究引入Audio Editing Toolbox (AET)，支持音频编辑如音调调整、单词强调和噪声注入，并构建Edited Audio Datasets (EADs)作为综合音频jailbreak基准。通过对先进LALMs的广泛评估，论文揭示了这些编辑对模型鲁棒性的显著影响，为未来LALMs安全中音频模态交互的研究奠定基础。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG",
        "cs.MM",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.13772v1",
      "published_date": "2025-01-23 15:51:38 UTC",
      "updated_date": "2025-01-23 15:51:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:23:06.581934"
    },
    {
      "arxiv_id": "2501.13766v2",
      "title": "UGMathBench: A Diverse and Dynamic Benchmark for Undergraduate-Level Mathematical Reasoning with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Xin Xu",
        "Jiaxin Zhang",
        "Tianhao Chen",
        "Zitong Chao",
        "Jishan Hu",
        "Can Yang"
      ],
      "abstract": "Large Language Models (LLMs) have made significant strides in mathematical\nreasoning, underscoring the need for a comprehensive and fair evaluation of\ntheir capabilities. However, existing benchmarks often fall short, either\nlacking extensive coverage of undergraduate-level mathematical problems or\nprobably suffering from test-set contamination. To address these issues, we\nintroduce UGMathBench, a diverse and dynamic benchmark specifically designed\nfor evaluating undergraduate-level mathematical reasoning with LLMs.\nUGMathBench comprises 5,062 problems across 16 subjects and 111 topics,\nfeaturing 10 distinct answer types. Each problem includes three randomized\nversions, with additional versions planned for release as leading open-source\nLLMs become saturated in UGMathBench. Furthermore, we propose two key metrics:\neffective accuracy (EAcc), which measures the percentage of correctly solved\nproblems across all three versions, and reasoning gap ($\\Delta$), which\nassesses reasoning robustness by calculating the difference between the average\naccuracy across all versions and EAcc. Our extensive evaluation of 23 leading\nLLMs reveals that the highest EAcc achieved is 56.3\\% by OpenAI-o1-mini, with\nlarge $\\Delta$ values observed across different models. This highlights the\nneed for future research aimed at developing \"large reasoning models\" with high\nEAcc and $\\Delta = 0$. We anticipate that the release of UGMathBench, along\nwith its detailed evaluation codes, will serve as a valuable resource to\nadvance the development of LLMs in solving mathematical problems. Codes and\ndata are available at https://github.com/YangLabHKUST/UGMathBench",
      "tldr_zh": "本研究引入了UGMathBench，这是一个多样化和动态的基准，用于评估Large Language Models (LLMs)在本科级数学推理方面的能力，涵盖5,062个问题、16个科目、111个主题和10种答案类型，每个问题包含三个随机化版本，以避免测试集污染。研究提出两个关键指标：有效准确率(EAcc)，即正确解决所有版本问题的百分比，以及推理差距(Δ)，用于衡量推理鲁棒性，即平均准确率与EAcc的差值。通过评估23个领先LLMs，发现OpenAI-o1-mini的最高EAcc为56.3%，但模型普遍存在较大Δ值，突显了开发高EAcc和Δ=0的“大型推理模型”的必要性。该基准的发布及其代码将有助于推进LLMs在数学问题解决方面的进展。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.13766v2",
      "published_date": "2025-01-23 15:46:43 UTC",
      "updated_date": "2025-02-25 08:15:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:25:10.772165"
    },
    {
      "arxiv_id": "2501.13763v2",
      "title": "Integrating Causality with Neurochaos Learning: Proposed Approach and Research Agenda",
      "title_zh": "翻译失败",
      "authors": [
        "Nanjangud C. Narendra",
        "Nithin Nagaraj"
      ],
      "abstract": "Deep learning implemented via neural networks, has revolutionized machine\nlearning by providing methods for complex tasks such as object\ndetection/classification and prediction. However, architectures based on deep\nneural networks have started to yield diminishing returns, primarily due to\ntheir statistical nature and inability to capture causal structure in the\ntraining data. Another issue with deep learning is its high energy consumption,\nwhich is not that desirable from a sustainability perspective.\n  Therefore, alternative approaches are being considered to address these\nissues, both of which are inspired by the functioning of the human brain. One\napproach is causal learning, which takes into account causality among the items\nin the dataset on which the neural network is trained. It is expected that this\nwill help minimize the spurious correlations that are prevalent in the learned\nrepresentations of deep neural networks. The other approach is Neurochaos\nLearning, a recent development, which draws its inspiration from the nonlinear\nchaotic firing intrinsic to neurons in biological neural networks\n(brain/central nervous system). Both approaches have shown improved results\nover just deep learning alone.\n  To that end, in this position paper, we investigate how causal and neurochaos\nlearning approaches can be integrated together to produce better results,\nespecially in domains that contain linked data. We propose an approach for this\nintegration to enhance classification, prediction and reinforcement learning.\nWe also propose a set of research questions that need to be investigated in\norder to make this integration a reality.",
      "tldr_zh": "这篇论文讨论了深度学习（deep learning）模型的局限性，包括无法捕捉因果结构（causal structure）和高能耗问题，并提出将因果学习（causal learning）和 Neurochaos Learning 整合的方法，以减少虚假相关性并模仿生物神经元行为。整合方法旨在提升分类、预测和强化学习（reinforcement learning）的性能，尤其在处理包含链接数据（linked data）的领域。论文还提出了一系列研究问题，作为未来实现这一整合的议程。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "I.2.6"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages",
      "pdf_url": "http://arxiv.org/pdf/2501.13763v2",
      "published_date": "2025-01-23 15:45:29 UTC",
      "updated_date": "2025-02-08 11:06:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:23:29.482042"
    },
    {
      "arxiv_id": "2501.13762v1",
      "title": "On Deciding the Data Complexity of Answering Linear Monadic Datalog Queries with LTL Operators(Extended Version)",
      "title_zh": "翻译失败",
      "authors": [
        "Alessandro Artale",
        "Anton Gnatenko",
        "Vladislav Ryzhikov",
        "Michael Zakharyaschev"
      ],
      "abstract": "Our concern is the data complexity of answering linear monadic datalog\nqueries whose atoms in the rule bodies can be prefixed by operators of linear\ntemporal logic LTL. We first observe that, for data complexity, answering any\nconnected query with operators $\\bigcirc/\\bigcirc^-$ (at the next/previous\nmoment) is either in AC0, or in $ACC0\\!\\setminus\\!AC0$, or $NC^1$-complete, or\nLogSpace-hard and in NLogSpace. Then we show that the problem of deciding\nLogSpace-hardness of answering such queries is PSpace-complete, while checking\nmembership in the classes AC0 and ACC0 as well as $NC^1$-completeness can be\ndone in ExpSpace. Finally, we prove that membership in AC0 or in ACC0,\n$NC^1$-completeness, and LogSpace-hardness are undecidable for queries with\noperators $\\Diamond_f/\\Diamond_p$ (sometime in the future/past) provided that\n$NC^1 \\ne NLogSpace$, and $LogSpace \\ne NLogSpace$.",
      "tldr_zh": "这篇论文探讨了带有线性时序逻辑（LTL）操作符的线性单调 Datalog 查询的答案数据复杂度问题，特别是对于规则体中原子前缀的操作符。研究发现，对于带有 $\\bigcirc/\\bigcirc^-$（下一个/上一个时刻）操作符的连接查询，其数据复杂度可能属于 AC0、ACC0、NC^1-complete 或 LogSpace-hard and in NLogSpace，且决定 LogSpace-hardness 是 PSpace-complete，而检查其他类别的成员关系可在 ExpSpace 中完成。最后，论文证明，对于带有 $\\Diamond_f/\\Diamond_p$（将来/过去某个时候）操作符的查询，在 $NC^1 \\ne NLogSpace$ 和 $LogSpace \\ne NLogSpace$ 的前提下，其在 AC0、ACC0 或 NC^1-complete 中的成员关系是不可判定的。",
      "categories": [
        "cs.AI",
        "cs.CC",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "Extended version of a paper accepted at ICDT'2025",
      "pdf_url": "http://arxiv.org/pdf/2501.13762v1",
      "published_date": "2025-01-23 15:41:48 UTC",
      "updated_date": "2025-01-23 15:41:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:23:41.994758"
    },
    {
      "arxiv_id": "2501.13758v1",
      "title": "2-Tier SimCSE: Elevating BERT for Robust Sentence Embeddings",
      "title_zh": "翻译失败",
      "authors": [
        "Yumeng Wang",
        "Ziran Zhou",
        "Junjin Wang"
      ],
      "abstract": "Effective sentence embeddings that capture semantic nuances and generalize\nwell across diverse contexts are crucial for natural language processing tasks.\nWe address this challenge by applying SimCSE (Simple Contrastive Learning of\nSentence Embeddings) using contrastive learning to fine-tune the minBERT model\nfor sentiment analysis, semantic textual similarity (STS), and paraphrase\ndetection. Our contributions include experimenting with three different dropout\ntechniques, namely standard dropout, curriculum dropout, and adaptive dropout,\nto tackle overfitting, proposing a novel 2-Tier SimCSE Fine-tuning Model that\ncombines both unsupervised and supervised SimCSE on STS task, and exploring\ntransfer learning potential for Paraphrase and SST tasks. Our findings\ndemonstrate the effectiveness of SimCSE, with the 2-Tier model achieving\nsuperior performance on the STS task, with an average test score of 0.742\nacross all three downstream tasks. The results of error analysis reveals\nchallenges in handling complex sentiments and reliance on lexical overlap for\nparaphrase detection, highlighting areas for future research. The ablation\nstudy revealed that removing Adaptive Dropout in the Single-Task Unsupervised\nSimCSE Model led to improved performance on the STS task, indicating\noverfitting due to added parameters. Transfer learning from SimCSE models on\nParaphrase and SST tasks did not enhance performance, suggesting limited\ntransferability of knowledge from the STS task.",
      "tldr_zh": "本研究针对自然语言处理任务，应用 SimCSE（Simple Contrastive Learning of Sentence Embeddings）方法微调 BERT 模型，以生成更鲁棒的句子嵌入，提升情感分析、语义文本相似性 (STS) 和改写检测的性能。  \n贡献包括实验三种 dropout 技术（标准 dropout、课程 dropout 和自适应 dropout）来缓解过拟合，并提出新型 2-Tier SimCSE 微调模型，该模型结合无监督和监督学习，在 STS 任务上实现平均测试分数 0.742 的优越表现。  \n然而，错误分析显示，该模型在处理复杂情感和词汇重叠依赖方面存在挑战，且从改写检测和 SST 任务的迁移学习效果有限，消融研究进一步表明移除自适应 dropout 可改善性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.13758v1",
      "published_date": "2025-01-23 15:36:35 UTC",
      "updated_date": "2025-01-23 15:36:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:23:54.877874"
    },
    {
      "arxiv_id": "2501.13756v1",
      "title": "Solving the long-tailed distribution problem by exploiting the synergies and balance of different techniques",
      "title_zh": "通过利用不同技术的协同性和平衡来解决长尾分布问题",
      "authors": [
        "Ziheng Wang",
        "Toni Lassila",
        "Sharib Ali"
      ],
      "abstract": "In real-world data, long-tailed data distribution is common, making it\nchallenging for models trained on empirical risk minimisation to learn and\nclassify tail classes effectively. While many studies have sought to improve\nlong tail recognition by altering the data distribution in the feature space\nand adjusting model decision boundaries, research on the synergy and corrective\napproach among various methods is limited. Our study delves into three\nlong-tail recognition techniques: Supervised Contrastive Learning (SCL),\nRare-Class Sample Generator (RSG), and Label-Distribution-Aware Margin Loss\n(LDAM). SCL enhances intra-class clusters based on feature similarity and\npromotes clear inter-class separability but tends to favour dominant classes\nonly. When RSG is integrated into the model, we observed that the intra-class\nfeatures further cluster towards the class centre, which demonstrates a\nsynergistic effect together with SCL's principle of enhancing intra-class\nclustering. RSG generates new tail features and compensates for the tail\nfeature space squeezed by SCL. Similarly, LDAM is known to introduce a larger\nmargin specifically for tail classes; we demonstrate that LDAM further bolsters\nthe model's performance on tail classes when combined with the more explicit\ndecision boundaries achieved by SCL and RSG. Furthermore, SCL can compensate\nfor the dominant class accuracy sacrificed by RSG and LDAM. Our research\nemphasises the synergy and balance among the three techniques, with each\namplifying the strengths of the others and mitigating their shortcomings. Our\nexperiment on long-tailed distribution datasets, using an end-to-end\narchitecture, yields competitive results by enhancing tail class accuracy\nwithout compromising dominant class performance, achieving a balanced\nimprovement across all classes.",
      "tldr_zh": "本研究针对长尾分布问题，探讨了 Supervised Contrastive Learning (SCL)、Rare-Class Sample Generator (RSG) 和 Label-Distribution-Aware Margin Loss (LDAM) 三种技术的协同作用，以提升模型对尾部类的学习和分类能力。研究发现，SCL 通过增强类内聚类和类间可分性，但偏向主导类；RSG 生成尾部样本来补偿特征空间的挤压，而 LDAM 引入更大边距进一步强化尾部类性能，同时三者相互平衡，缓解了对主导类的负面影响。在长尾分布数据集上的端到端实验表明，这种结合方法显著提高了尾部类准确率，同时保持主导类性能，实现整体分类的平衡改善。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "13",
      "pdf_url": "http://arxiv.org/pdf/2501.13756v1",
      "published_date": "2025-01-23 15:35:15 UTC",
      "updated_date": "2025-01-23 15:35:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:24:06.651693"
    },
    {
      "arxiv_id": "2501.14007v1",
      "title": "Adaptive Genetic Algorithms for Pulse-Level Quantum Error Mitigation",
      "title_zh": "翻译失败",
      "authors": [
        "William Aguilar-Calvo",
        "Santiago Núñez-Corrales"
      ],
      "abstract": "Noise remains a fundamental challenge in quantum computing, significantly\naffecting pulse fidelity and overall circuit performance. This paper introduces\nan adaptive algorithm for pulse-level quantum error mitigation, designed to\nenhance fidelity by dynamically responding to noise conditions without\nmodifying circuit gates. By targeting pulse parameters directly, this method\nreduces the impact of various noise sources, improving algorithm resilience in\nquantum circuits. We show the latter by applying our protocol to Grover's and\nDeutsch-Jozsa algorithms. Experimental results show that this pulse-level\nstrategy provides a flexible and efficient solution for increasing fidelity\nduring the noisy execution of quantum circuits. Our work contributes to\nadvancements in error mitigation techniques, essential for robust quantum\ncomputing.",
      "tldr_zh": "该论文提出了一种自适应遗传算法（Adaptive Genetic Algorithms），用于脉冲级量子错误缓解（Pulse-Level Quantum Error Mitigation），旨在动态响应噪声条件以提升量子电路的保真度和算法弹性，而无需修改电路门。方法通过直接调整脉冲参数，减少各种噪声源的影响，并在Grover's和Deutsch-Jozsa算法上进行了应用。实验结果表明，该策略显著提高了量子电路在噪声环境下的执行保真度。整体贡献在于为量子计算提供一种灵活、高效的错误缓解技术，推动了稳健量子计算的发展。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.AR"
      ],
      "primary_category": "quant-ph",
      "comment": "21 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.14007v1",
      "published_date": "2025-01-23 15:28:22 UTC",
      "updated_date": "2025-01-23 15:28:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:24:17.322071"
    },
    {
      "arxiv_id": "2501.13746v1",
      "title": "EICopilot: Search and Explore Enterprise Information over Large-scale Knowledge Graphs with LLM-driven Agents",
      "title_zh": "EICopilot：利用LLM驱动的代理在大型知识图谱上搜索和探索企业信息",
      "authors": [
        "Yuhui Yun",
        "Huilong Ye",
        "Xinru Li",
        "Ruojia Li",
        "Jingfeng Deng",
        "Li Li",
        "Haoyi Xiong"
      ],
      "abstract": "The paper introduces EICopilot, an novel agent-based solution enhancing\nsearch and exploration of enterprise registration data within extensive online\nknowledge graphs like those detailing legal entities, registered capital, and\nmajor shareholders. Traditional methods necessitate text-based queries and\nmanual subgraph explorations, often resulting in time-consuming processes.\nEICopilot, deployed as a chatbot via Baidu Enterprise Search, improves this\nlandscape by utilizing Large Language Models (LLMs) to interpret natural\nlanguage queries. This solution automatically generates and executes Gremlin\nscripts, providing efficient summaries of complex enterprise relationships.\nDistinct feature a data pre-processing pipeline that compiles and annotates\nrepresentative queries into a vector database of examples for In-context\nlearning (ICL), a comprehensive reasoning pipeline combining Chain-of-Thought\nwith ICL to enhance Gremlin script generation for knowledge graph search and\nexploration, and a novel query masking strategy that improves intent\nrecognition for heightened script accuracy. Empirical evaluations demonstrate\nthe superior performance of EICopilot, including speed and accuracy, over\nbaseline methods, with the \\emph{Full Mask} variant achieving a syntax error\nrate reduction to as low as 10.00% and an execution correctness of up to\n82.14%. These components collectively contribute to superior querying\ncapabilities and summarization of intricate datasets, positioning EICopilot as\na groundbreaking tool in the exploration and exploitation of large-scale\nknowledge graphs for enterprise information search.",
      "tldr_zh": "该论文介绍了 EICopilot，一种基于 LLM 驱动的代理系统，用于在大型知识图谱中搜索和探索企业注册数据（如法律实体、注册资本和主要股东），克服了传统文本查询和手动子图探索的低效问题。该系统通过数据预处理管道将查询编译到向量数据库支持 In-context Learning (ICL)，结合 Chain-of-Thought 推理和新型查询掩码策略，自动生成并执行 Gremlin 脚本，提供高效的企业关系总结。实验评估显示，EICopilot 在速度和准确性上优于基线方法，其中 Full Mask 变体将语法错误率降低至 10.00%，执行正确率高达 82.14%，为大规模知识图谱的企业信息检索提供了突破性工具。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.13746v1",
      "published_date": "2025-01-23 15:22:25 UTC",
      "updated_date": "2025-01-23 15:22:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:25:23.497857"
    },
    {
      "arxiv_id": "2501.13731v1",
      "title": "Pseudocode-Injection Magic: Enabling LLMs to Tackle Graph Computational Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Chang Gong",
        "Wanrui Bian",
        "Zhijie Zhang",
        "Weiguo Zheng"
      ],
      "abstract": "Graph computational tasks are inherently challenging and often demand the\ndevelopment of advanced algorithms for effective solutions. With the emergence\nof large language models (LLMs), researchers have begun investigating their\npotential to address these tasks. However, existing approaches are constrained\nby LLMs' limited capability to comprehend complex graph structures and their\nhigh inference costs, rendering them impractical for handling large-scale\ngraphs. Inspired by human approaches to graph problems, we introduce a novel\nframework, PIE (Pseudocode-Injection-Enhanced LLM Reasoning for Graph\nComputational Tasks), which consists of three key steps: problem understanding,\nprompt design, and code generation. In this framework, LLMs are tasked with\nunderstanding the problem and extracting relevant information to generate\ncorrect code. The responsibility for analyzing the graph structure and\nexecuting the code is delegated to the interpreter. We inject task-related\npseudocodes into the prompts to further assist the LLMs in generating efficient\ncode. We also employ cost-effective trial-and-error techniques to ensure that\nthe LLM-generated code executes correctly. Unlike other methods that require\ninvoking LLMs for each individual test case, PIE only calls the LLM during the\ncode generation phase, allowing the generated code to be reused and\nsignificantly reducing inference costs. Extensive experiments demonstrate that\nPIE outperforms existing baselines in terms of both accuracy and computational\nefficiency.",
      "tldr_zh": "该研究提出了一种名为 PIE（Pseudocode-Injection-Enhanced LLM Reasoning for Graph Computational Tasks）的框架，旨在帮助大型语言模型（LLMs）处理复杂的图计算任务，克服 LLMs 在理解图结构和推理成本方面的局限性。PIE 框架包括三个关键步骤：问题理解、提示设计和代码生成，其中 LLMs 负责理解问题并生成代码，而解释器则处理图结构的分析和执行；同时，通过注入任务相关的伪代码到提示中并采用成本有效的试错技术，确保代码的准确性和效率。实验结果显示，PIE 在准确性和计算效率上均优于现有基线方法，仅在代码生成阶段调用 LLMs，从而显著降低了推理成本。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "24 pages",
      "pdf_url": "http://arxiv.org/pdf/2501.13731v1",
      "published_date": "2025-01-23 15:04:22 UTC",
      "updated_date": "2025-01-23 15:04:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:25:33.782856"
    },
    {
      "arxiv_id": "2501.13727v2",
      "title": "Scalable Safe Multi-Agent Reinforcement Learning for Multi-Agent System",
      "title_zh": "翻译失败",
      "authors": [
        "Haikuo Du",
        "Fandi Gou",
        "Yunze Cai"
      ],
      "abstract": "Safety and scalability are two critical challenges faced by practical\nMulti-Agent Systems (MAS). However, existing Multi-Agent Reinforcement Learning\n(MARL) algorithms that rely solely on reward shaping are ineffective in\nensuring safety, and their scalability is rather limited due to the fixed-size\nnetwork output. To address these issues, we propose a novel framework, Scalable\nSafe MARL (SS-MARL), to enhance the safety and scalability of MARL methods.\nLeveraging the inherent graph structure of MAS, we design a multi-layer message\npassing network to aggregate local observations and communications of varying\nsizes. Furthermore, we develop a constrained joint policy optimization method\nin the setting of local observation to improve safety. Simulation experiments\ndemonstrate that SS-MARL achieves a better trade-off between optimality and\nsafety compared to baselines, and its scalability significantly outperforms the\nlatest methods in scenarios with a large number of agents.",
      "tldr_zh": "本文提出Scalable Safe MARL (SS-MARL)框架，以解决多智能体系统(MAS)中的安全性和可扩展性挑战，针对现有Multi-Agent Reinforcement Learning (MARL)算法依赖奖励整形导致的不足。框架利用MAS的图结构，设计多层消息传递网络来聚合不同大小的本地观察和通信，并开发受限联合策略优化方法，以在本地观察设置中提升安全性。模拟实验显示，SS-MARL与基线方法相比，在最优性和安全性之间实现了更好的权衡，并在大量智能体场景中表现出显著的可扩展性优势。",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.13727v2",
      "published_date": "2025-01-23 15:01:19 UTC",
      "updated_date": "2025-04-01 12:59:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:25:45.741616"
    },
    {
      "arxiv_id": "2501.13725v1",
      "title": "You Only Crash Once v2: Perceptually Consistent Strong Features for One-Stage Domain Adaptive Detection of Space Terrain",
      "title_zh": "You Only Crash Once v2：感知一致的强特征用于单阶段域适应太空地形检测",
      "authors": [
        "Timothy Chase Jr",
        "Christopher Wilson",
        "Karthik Dantu"
      ],
      "abstract": "The in-situ detection of planetary, lunar, and small-body surface terrain is\ncrucial for autonomous spacecraft applications, where learning-based computer\nvision methods are increasingly employed to enable intelligence without prior\ninformation or human intervention. However, many of these methods remain\ncomputationally expensive for spacecraft processors and prevent real-time\noperation. Training of such algorithms is additionally complex due to the\nscarcity of labeled data and reliance on supervised learning approaches.\nUnsupervised Domain Adaptation (UDA) offers a promising solution by\nfacilitating model training with disparate data sources such as simulations or\nsynthetic scenes, although UDA is difficult to apply to celestial environments\nwhere challenging feature spaces are paramount. To alleviate such issues, You\nOnly Crash Once (YOCOv1) has studied the integration of Visual Similarity-based\nAlignment (VSA) into lightweight one-stage object detection architectures to\nimprove space terrain UDA. Although proven effective, the approach faces\nnotable limitations, including performance degradations in multi-class and\nhigh-altitude scenarios. Building upon the foundation of YOCOv1, we propose\nnovel additions to the VSA scheme that enhance terrain detection capabilities\nunder UDA, and our approach is evaluated across both simulated and real-world\ndata. Our second YOCO rendition, YOCOv2, is capable of achieving\nstate-of-the-art UDA performance on surface terrain detection, where we\nshowcase improvements upwards of 31% compared with YOCOv1 and terrestrial\nstate-of-the-art. We demonstrate the practical utility of YOCOv2 with\nspacecraft flight hardware performance benchmarking and qualitative evaluation\nof NASA mission data.",
      "tldr_zh": "该论文提出 YOCOv2，一种改进的框架，用于一阶段无监督域适应 (UDA) 的太空地形检测，旨在解决现有方法在计算资源和数据稀缺方面的挑战。YOCOv2 构建于 YOCOv1 基础上，通过增强 Visual Similarity-based Alignment (VSA) 方案，提高了多类和高空场景下的检测性能。实验结果显示，YOCOv2 在模拟和真实数据上实现了最先进性能，比 YOCOv1 提升超过 31%，并通过航天器硬件基准测试和 NASA 任务数据验证了其实际应用价值。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.13725v1",
      "published_date": "2025-01-23 14:58:49 UTC",
      "updated_date": "2025-01-23 14:58:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:25:59.284029"
    },
    {
      "arxiv_id": "2501.13720v2",
      "title": "Musical ethnocentrism in Large Language Models",
      "title_zh": "大型语言模型中的音乐民族中心主义",
      "authors": [
        "Anna Kruspe"
      ],
      "abstract": "Large Language Models (LLMs) reflect the biases in their training data and,\nby extension, those of the people who created this training data. Detecting,\nanalyzing, and mitigating such biases is becoming a focus of research. One type\nof bias that has been understudied so far are geocultural biases. Those can be\ncaused by an imbalance in the representation of different geographic regions\nand cultures in the training data, but also by value judgments contained\ntherein. In this paper, we make a first step towards analyzing musical biases\nin LLMs, particularly ChatGPT and Mixtral. We conduct two experiments. In the\nfirst, we prompt LLMs to provide lists of the \"Top 100\" musical contributors of\nvarious categories and analyze their countries of origin. In the second\nexperiment, we ask the LLMs to numerically rate various aspects of the musical\ncultures of different countries. Our results indicate a strong preference of\nthe LLMs for Western music cultures in both experiments.",
      "tldr_zh": "这篇论文探讨了大型语言模型(LLMs)中的地理文化偏见，特别是音乐领域的偏见，焦点在于ChatGPT和Mixtral模型如何反映训练数据中的不平衡和价值判断。研究通过两个实验进行分析：首先，提示模型生成不同类别的“Top 100”音乐贡献者列表并考察其国家来源；其次，让模型对各国音乐文化的各方面进行数值评分。结果表明，LLMs在两个实验中都表现出强烈的偏好向西方音乐文化，这为检测和缓解此类geocultural biases提供了初步洞见。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.13720v2",
      "published_date": "2025-01-23 14:50:37 UTC",
      "updated_date": "2025-02-03 10:52:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:26:10.018135"
    },
    {
      "arxiv_id": "2501.14006v1",
      "title": "Asymmetrical Latent Representation for Individual Treatment Effect Modeling",
      "title_zh": "翻译失败",
      "authors": [
        "Armand Lacombe",
        "Michèle Sebag"
      ],
      "abstract": "Conditional Average Treatment Effect (CATE) estimation, at the heart of\ncounterfactual reasoning, is a crucial challenge for causal modeling both\ntheoretically and applicatively, in domains such as healthcare, sociology, or\nadvertising. Borrowing domain adaptation principles, a popular design maps the\nsample representation to a latent space that balances control and treated\npopulations while enabling the prediction of the potential outcomes. This paper\npresents a new CATE estimation approach based on the asymmetrical search for\ntwo latent spaces called Asymmetrical Latent Representation for Individual\nTreatment Effect (ALRITE), where the two latent spaces are respectively\nintended to optimize the counterfactual prediction accuracy on the control and\nthe treated samples. Under moderate assumptions, ALRITE admits an upper bound\non the precision of the estimation of heterogeneous effects (PEHE), and the\napproach is empirically successfully validated compared to the state-of-the-art",
      "tldr_zh": "该论文提出了一种新的CATE（Conditional Average Treatment Effect）估计方法，名为ALRITE（Asymmetrical Latent Representation for Individual Treatment Effect），旨在通过不对称的两个潜在空间分别优化控制组和治疗组样本的反事实预测准确性。借鉴领域适应原则，该方法将样本映射到这些潜在空间，以平衡处理组并提升因果建模的精确性。在温和假设下，ALRITE提供了PEHE（Precision in Estimation of Heterogeneous Effects）的上界，并在实验中证明了其优于现有状态-of-the-art方法，尤其在医疗、社会学和广告等领域。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.14006v1",
      "published_date": "2025-01-23 14:44:36 UTC",
      "updated_date": "2025-01-23 14:44:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:26:21.863894"
    },
    {
      "arxiv_id": "2501.13713v1",
      "title": "Skin Disease Detection and Classification of Actinic Keratosis and Psoriasis Utilizing Deep Transfer Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Fahud Ahmmed",
        "Md. Zaheer Raihan",
        "Kamnur Nahar",
        "D. M. Asadujjaman",
        "Md. Mahfujur Rahman",
        "Abdullah Tamim"
      ],
      "abstract": "Skin diseases can arise from infections, allergies, genetic factors,\nautoimmune disorders, hormonal imbalances, or environmental triggers such as\nsun damage and pollution. Some skin diseases, such as Actinic Keratosis and\nPsoriasis, can be fatal if not treated in time. Early identification is\ncrucial, but the diagnostic methods for these conditions are often expensive\nand not widely accessible. In this study, we propose a novel and efficient\nmethod for diagnosing skin diseases using deep learning techniques. This\napproach employs a modified VGG16 Convolutional Neural Network (CNN) model. The\nmodel includes several convolutional layers and utilizes ImageNet weights with\nmodified top layers. The top layer is updated with fully connected layers and a\nfinal softmax activation layer to classify skin diseases. The dataset used,\ntitled \"Skin Disease Dataset,\" is publicly available. While the VGG16\narchitecture does not include data augmentation by default, preprocessing\ntechniques such as rotation, shifting, and zooming were applied to augment the\ndata prior to model training. The proposed methodology achieved 90.67% accuracy\nusing the modified VGG16 model, demonstrating its reliability in classifying\nskin diseases. The promising results highlight the potential of this approach\nfor real-world applications.",
      "tldr_zh": "本研究针对皮肤疾病如Actinic Keratosis和Psoriasis的早期诊断问题，提出了一种基于深度迁移学习的检测和分类方法，以解决传统诊断方法昂贵且不普及的挑战。方法采用修改后的VGG16 Convolutional Neural Network (CNN)模型，利用ImageNet权重，并更新顶层为全连接层和softmax激活层，同时应用数据增强技术（如旋转、平移和缩放）来处理公开的\"Skin Disease Dataset\"。实验结果显示，该模型在皮肤病分类任务上达到了90.67%的准确率，展示了其在实际应用中的可靠性和潜力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "68T07",
        "J.3"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.13713v1",
      "published_date": "2025-01-23 14:43:53 UTC",
      "updated_date": "2025-01-23 14:43:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:26:33.535581"
    },
    {
      "arxiv_id": "2501.13712v1",
      "title": "Formally Verified Neurosymbolic Trajectory Learning via Tensor-based Linear Temporal Logic on Finite Traces",
      "title_zh": "翻译失败",
      "authors": [
        "Mark Chevallier",
        "Filip Smola",
        "Richard Schmoetten",
        "Jacques D. Fleuriot"
      ],
      "abstract": "We present a novel formalisation of tensor semantics for linear temporal\nlogic on finite traces (LTLf), with formal proofs of correctness carried out in\nthe theorem prover Isabelle/HOL. We demonstrate that this formalisation can be\nintegrated into a neurosymbolic learning process by defining and verifying a\ndifferentiable loss function for the LTLf constraints, and automatically\ngenerating an implementation that integrates with PyTorch. We show that, by\nusing this loss, the process learns to satisfy pre-specified logical\nconstraints. Our approach offers a fully rigorous framework for constrained\ntraining, eliminating many of the inherent risks of ad-hoc, manual\nimplementations of logical aspects directly in an \"unsafe\" programming language\nsuch as Python, while retaining efficiency in implementation.",
      "tldr_zh": "本文提出了一种基于张量的线性时序逻辑 on finite traces (LTLf) 语义形式化，并在定理证明器 Isabelle/HOL 中进行了正确性证明。研究将此形式化整合到神经符号学习中，通过定义和验证一个可微损失函数，实现对 LTLf 约束的自动学习和与 PyTorch 的兼容。结果显示，该框架能确保学习过程满足预定义的逻辑约束，同时提供更安全、高效的约束训练方法，避免了在 Python 等语言中手动实现的潜在风险。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.13712v1",
      "published_date": "2025-01-23 14:43:12 UTC",
      "updated_date": "2025-01-23 14:43:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:26:46.597557"
    },
    {
      "arxiv_id": "2501.13710v1",
      "title": "YOLO11-JDE: Fast and Accurate Multi-Object Tracking with Self-Supervised Re-ID",
      "title_zh": "翻译失败",
      "authors": [
        "Iñaki Erregue",
        "Kamal Nasrollahi",
        "Sergio Escalera"
      ],
      "abstract": "We introduce YOLO11-JDE, a fast and accurate multi-object tracking (MOT)\nsolution that combines real-time object detection with self-supervised\nRe-Identification (Re-ID). By incorporating a dedicated Re-ID branch into\nYOLO11s, our model performs Joint Detection and Embedding (JDE), generating\nappearance features for each detection. The Re-ID branch is trained in a fully\nself-supervised setting while simultaneously training for detection,\neliminating the need for costly identity-labeled datasets. The triplet loss,\nwith hard positive and semi-hard negative mining strategies, is used for\nlearning discriminative embeddings. Data association is enhanced with a custom\ntracking implementation that successfully integrates motion, appearance, and\nlocation cues. YOLO11-JDE achieves competitive results on MOT17 and MOT20\nbenchmarks, surpassing existing JDE methods in terms of FPS and using up to ten\ntimes fewer parameters. Thus, making our method a highly attractive solution\nfor real-world applications.",
      "tldr_zh": "该研究提出 YOLO11-JDE，一种快速且准确的多对象跟踪 (MOT) 解决方案，通过将自监督 Re-Identification (Re-ID) 整合到 YOLO11s 中，实现 Joint Detection and Embedding (JDE)，为每个检测生成外观特征。Re-ID 分支采用完全自监督训练方式，使用 triplet loss 结合硬正样本和半硬负样本挖掘策略，同时进行检测训练，从而避免了昂贵的身份标注数据集。模型通过自定义跟踪实现增强数据关联，整合运动、外观和位置线索，并在 MOT17 和 MOT20 基准上取得竞争性结果，比现有 JDE 方法提高 FPS 并减少多达十倍的参数，使其成为真实世界应用的理想选择。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "This paper has been accepted to the 5th Workshop on Real-World\n  Surveillance: Applications and Challenges (WACV 2025)",
      "pdf_url": "http://arxiv.org/pdf/2501.13710v1",
      "published_date": "2025-01-23 14:38:40 UTC",
      "updated_date": "2025-01-23 14:38:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:26:59.324953"
    },
    {
      "arxiv_id": "2501.13707v1",
      "title": "EventVL: Understand Event Streams via Multimodal Large Language Model",
      "title_zh": "EventVL：通过多模态大型语言模型理解事件流",
      "authors": [
        "Pengteng Li",
        "Yunfan Lu",
        "Pinghao Song",
        "Wuyang Li",
        "Huizai Yao",
        "Hui Xiong"
      ],
      "abstract": "The event-based Vision-Language Model (VLM) recently has made good progress\nfor practical vision tasks. However, most of these works just utilize CLIP for\nfocusing on traditional perception tasks, which obstruct model understanding\nexplicitly the sufficient semantics and context from event streams. To address\nthe deficiency, we propose EventVL, the first generative event-based MLLM\n(Multimodal Large Language Model) framework for explicit semantic\nunderstanding. Specifically, to bridge the data gap for connecting different\nmodalities semantics, we first annotate a large event-image/video-text dataset,\ncontaining almost 1.4 million high-quality pairs of data, which enables\neffective learning across various scenes, e.g., drive scene or human motion.\nAfter that, we design Event Spatiotemporal Representation to fully explore the\ncomprehensive information by diversely aggregating and segmenting the event\nstream. To further promote a compact semantic space, Dynamic Semantic Alignment\nis introduced to improve and complete sparse semantic spaces of events.\nExtensive experiments show that our EventVL can significantly surpass existing\nMLLM baselines in event captioning and scene description generation tasks. We\nhope our research could contribute to the development of the event vision\ncommunity.",
      "tldr_zh": "本文提出 EventVL，这是首个生成式基于事件的 Multimodal Large Language Model (MLLM)，旨在解决现有模型如 CLIP 在事件流语义理解方面的不足。研究团队构建了一个包含约1.4百万高质量事件-图像/视频-文本数据对的数据集，以桥接不同模态的语义连接。EventVL 框架设计了 Event Spatiotemporal Representation 用于多样聚合和分割事件信息，以及 Dynamic Semantic Alignment 来优化稀疏语义空间。实验显示，该模型在事件字幕和场景描述生成任务中显著超越现有 MLLM 基线，推动了事件视觉社区的发展。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.13707v1",
      "published_date": "2025-01-23 14:37:21 UTC",
      "updated_date": "2025-01-23 14:37:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:27:10.798044"
    },
    {
      "arxiv_id": "2501.13692v1",
      "title": "Training-Free Consistency Pipeline for Fashion Repose",
      "title_zh": "翻译失败",
      "authors": [
        "Potito Aghilar",
        "Vito Walter Anelli",
        "Michelantonio Trizio",
        "Tommaso Di Noia"
      ],
      "abstract": "Recent advancements in diffusion models have significantly broadened the\npossibilities for editing images of real-world objects. However, performing\nnon-rigid transformations, such as changing the pose of objects or image-based\nconditioning, remains challenging. Maintaining object identity during these\nedits is difficult, and current methods often fall short of the precision\nneeded for industrial applications, where consistency is critical.\nAdditionally, fine-tuning diffusion models requires custom training data, which\nis not always accessible in real-world scenarios. This work introduces\nFashionRepose, a training-free pipeline for non-rigid pose editing specifically\ndesigned for the fashion industry. The approach integrates off-the-shelf models\nto adjust poses of long-sleeve garments, maintaining identity and branding\nattributes. FashionRepose uses a zero-shot approach to perform these edits in\nnear real-time, eliminating the need for specialized training. consistent image\nediting. The solution holds potential for applications in the fashion industry\nand other fields demanding identity preservation in image editing.",
      "tldr_zh": "本文提出FashionRepose，一种无需训练的管道，用于时尚图像的非刚性变换(non-rigid transformations)，旨在解决扩散模型(diffusion models)在改变物体姿势时维护身份一致性的挑战。该方法整合现成模型，通过零样本(zero-shot)方式调整长袖服装的姿势，同时保留物体身份和品牌属性，实现近实时编辑。相比现有方法，FashionRepose消除了对自定义训练数据的依赖，具有在时尚行业及其他需要身份保存领域的广泛应用潜力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.13692v1",
      "published_date": "2025-01-23 14:17:01 UTC",
      "updated_date": "2025-01-23 14:17:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:27:22.068941"
    },
    {
      "arxiv_id": "2501.13687v1",
      "title": "Question Answering on Patient Medical Records with Private Fine-Tuned LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Sara Kothari",
        "Ayush Gupta"
      ],
      "abstract": "Healthcare systems continuously generate vast amounts of electronic health\nrecords (EHRs), commonly stored in the Fast Healthcare Interoperability\nResources (FHIR) standard. Despite the wealth of information in these records,\ntheir complexity and volume make it difficult for users to retrieve and\ninterpret crucial health insights. Recent advances in Large Language Models\n(LLMs) offer a solution, enabling semantic question answering (QA) over medical\ndata, allowing users to interact with their health records more effectively.\nHowever, ensuring privacy and compliance requires edge and private deployments\nof LLMs.\n  This paper proposes a novel approach to semantic QA over EHRs by first\nidentifying the most relevant FHIR resources for a user query (Task1) and\nsubsequently answering the query based on these resources (Task2). We explore\nthe performance of privately hosted, fine-tuned LLMs, evaluating them against\nbenchmark models such as GPT-4 and GPT-4o. Our results demonstrate that\nfine-tuned LLMs, while 250x smaller in size, outperform GPT-4 family models by\n0.55% in F1 score on Task1 and 42% on Meteor Task in Task2. Additionally, we\nexamine advanced aspects of LLM usage, including sequential fine-tuning, model\nself-evaluation (narcissistic evaluation), and the impact of training data size\non performance. The models and datasets are available here:\nhttps://huggingface.co/genloop",
      "tldr_zh": "这篇论文针对电子健康记录 (EHRs) 的复杂性和海量数据问题，提出了一种基于私有微调的大型语言模型 (LLMs) 的语义问答 (QA) 方法，以提升用户对 Fast Healthcare Interoperability Resources (FHIR) 数据的检索和解读，同时确保隐私合规。方法包括两个任务：首先识别用户查询中最相关的 FHIR 资源 (Task1)，然后基于这些资源生成答案 (Task2)。实验结果显示，微调后的 LLMs 尽管体积仅为 GPT-4 的 1/250，却在 Task1 的 F1 score 上比 GPT-4 家族模型高出 0.55%，在 Task2 的 Meteor score 上高出 42%；此外，论文还探讨了顺序微调、模型自评估 (narcissistic evaluation) 和训练数据大小的影响，并开源了相关模型和数据集。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.13687v1",
      "published_date": "2025-01-23 14:13:56 UTC",
      "updated_date": "2025-01-23 14:13:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:27:36.015601"
    },
    {
      "arxiv_id": "2501.13683v1",
      "title": "Unlearning Clients, Features and Samples in Vertical Federated Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Ayush K. Varshney",
        "Konstantinos Vandikas",
        "Vicenç Torra"
      ],
      "abstract": "Federated Learning (FL) has emerged as a prominent distributed learning\nparadigm. Within the scope of privacy preservation, information privacy\nregulations such as GDPR entitle users to request the removal (or unlearning)\nof their contribution from a service that is hosting the model. For this\npurpose, a server hosting an ML model must be able to unlearn certain\ninformation in cases such as copyright infringement or security issues that can\nmake the model vulnerable or impact the performance of a service based on that\nmodel. While most unlearning approaches in FL focus on Horizontal FL (HFL),\nwhere clients share the feature space and the global model, Vertical FL (VFL)\nhas received less attention from the research community. VFL involves clients\n(passive parties) sharing the sample space among them while not having access\nto the labels. In this paper, we explore unlearning in VFL from three\nperspectives: unlearning clients, unlearning features, and unlearning samples.\nTo unlearn clients and features we introduce VFU-KD which is based on knowledge\ndistillation (KD) while to unlearn samples, VFU-GA is introduced which is based\non gradient ascent. To provide evidence of approximate unlearning, we utilize\nMembership Inference Attack (MIA) to audit the effectiveness of our unlearning\napproach. Our experiments across six tabular datasets and two image datasets\ndemonstrate that VFU-KD and VFU-GA achieve performance comparable to or better\nthan both retraining from scratch and the benchmark R2S method in many cases,\nwith improvements of $(0-2\\%)$. In the remaining cases, utility scores remain\ncomparable, with a modest utility loss ranging from $1-5\\%$. Unlike existing\nmethods, VFU-KD and VFU-GA require no communication between active and passive\nparties during unlearning. However, they do require the active party to store\nthe previously communicated embeddings.",
      "tldr_zh": "本论文探讨了 Vertical Federated Learning (VFL) 中的 unlearning 机制，针对客户端、特征和样本的删除需求，以满足隐私法规如 GDPR 的要求。作者提出 VFU-KD 方法，基于知识蒸馏 (KD) 来实现客户端和特征的 unlearning，以及 VFU-GA 方法，基于梯度上升 (gradient ascent) 来处理样本的 unlearning，并使用 Membership Inference Attack (MIA) 验证其有效性。实验在六种表格数据集和两种图像数据集上表明，VFU-KD 和 VFU-GA 的性能与从零重新训练或基准方法 R2S 相当或更好，改进 0-2%，而在其他情况下仅损失 1-5%，且这些方法无需 unlearning 过程中的 active 和 passive 方通信，但需存储先前嵌入。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Paper accepted for publication in PETS 2025, Issue II",
      "pdf_url": "http://arxiv.org/pdf/2501.13683v1",
      "published_date": "2025-01-23 14:10:02 UTC",
      "updated_date": "2025-01-23 14:10:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:27:47.310540"
    },
    {
      "arxiv_id": "2501.13676v2",
      "title": "Certified Robustness Under Bounded Levenshtein Distance",
      "title_zh": "翻译失败",
      "authors": [
        "Elias Abad Rocamora",
        "Grigorios G. Chrysos",
        "Volkan Cevher"
      ],
      "abstract": "Text classifiers suffer from small perturbations, that if chosen\nadversarially, can dramatically change the output of the model. Verification\nmethods can provide robustness certificates against such adversarial\nperturbations, by computing a sound lower bound on the robust accuracy.\nNevertheless, existing verification methods incur in prohibitive costs and\ncannot practically handle Levenshtein distance constraints. We propose the\nfirst method for computing the Lipschitz constant of convolutional classifiers\nwith respect to the Levenshtein distance. We use these Lipschitz constant\nestimates for training 1-Lipschitz classifiers. This enables computing the\ncertified radius of a classifier in a single forward pass. Our method, LipsLev,\nis able to obtain $38.80$% and $13.93$% verified accuracy at distance $1$ and\n$2$ respectively in the AG-News dataset, while being $4$ orders of magnitude\nfaster than existing approaches. We believe our work can open the door to more\nefficient verification in the text domain.",
      "tldr_zh": "该论文探讨了文本分类器在受限 Levenshtein distance 下的鲁棒性问题，现有验证方法因计算成本高昂而无法有效处理此类距离约束。研究提出 LipsLev 方法，通过计算卷积分类器的 Lipschitz constant 并训练 1-Lipschitz classifiers，实现单次前向传播即可获得认证半径。实验结果显示，在 AG-News 数据集上，LipsLev 分别在距离 1 和 2 时实现了 38.80% 和 13.93% 的验证准确率，比现有方法快 4 个数量级，并为文本领域的鲁棒性验证开辟更高效的途径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted in ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.13676v2",
      "published_date": "2025-01-23 13:58:53 UTC",
      "updated_date": "2025-02-20 15:44:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:27:58.942933"
    },
    {
      "arxiv_id": "2501.14005v1",
      "title": "Device-aware Optical Adversarial Attack for a Portable Projector-camera System",
      "title_zh": "翻译失败",
      "authors": [
        "Ning Jiang",
        "Yanhong Liu",
        "Dingheng Zeng",
        "Yue Feng",
        "Weihong Deng",
        "Ying Li"
      ],
      "abstract": "Deep-learning-based face recognition (FR) systems are susceptible to\nadversarial examples in both digital and physical domains. Physical attacks\npresent a greater threat to deployed systems as adversaries can easily access\nthe input channel, allowing them to provide malicious inputs to impersonate a\nvictim. This paper addresses the limitations of existing projector-camera-based\nadversarial light attacks in practical FR setups. By incorporating device-aware\nadaptations into the digital attack algorithm, such as resolution-aware and\ncolor-aware adjustments, we mitigate the degradation from digital to physical\ndomains. Experimental validation showcases the efficacy of our proposed\nalgorithm against real and spoof adversaries, achieving high physical\nsimilarity scores in FR models and state-of-the-art commercial systems. On\naverage, there is only a 14% reduction in scores from digital to physical\nattacks, with high attack success rate in both white- and black-box scenarios.",
      "tldr_zh": "这篇论文针对深度学习脸部识别（FR）系统的物理对抗攻击漏洞，提出了一种设备感知的光学对抗攻击方法，适用于便携式投影仪-相机系统。该方法通过在数字攻击算法中融入分辨率-aware和颜色-aware调整，减少从数字到物理领域的性能降级。实验验证显示，该算法对真实和伪造攻击者有效，在FR模型和商业系统中实现高物理相似性分数，仅平均减少14%的分数，并在白盒和黑盒场景中保持高攻击成功率。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.14005v1",
      "published_date": "2025-01-23 13:55:23 UTC",
      "updated_date": "2025-01-23 13:55:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:28:10.292848"
    },
    {
      "arxiv_id": "2501.13669v2",
      "title": "How to Alleviate Catastrophic Forgetting in LLMs Finetuning? Hierarchical Layer-Wise and Element-Wise Regularization",
      "title_zh": "翻译失败",
      "authors": [
        "Shezheng Song",
        "Hao Xu",
        "Jun Ma",
        "Shasha Li",
        "Long Peng",
        "Qian Wan",
        "Xiaodong Liu",
        "Jie Yu"
      ],
      "abstract": "Large Language Models (LLMs) exhibit strong general language capabilities.\nHowever, fine-tuning these models on domain-specific tasks often leads to\ncatastrophic forgetting, where the model overwrites or loses essential\nknowledge acquired during pretraining. This phenomenon significantly limits the\nbroader applicability of LLMs. To address this challenge, we propose a novel\napproach to compute the element-wise importance of model parameters crucial for\npreserving general knowledge during fine-tuning. Our method utilizes a\ndual-objective optimization strategy: (1) regularization loss based on\nelement-wise parameter importance, which constrains the updates to parameters\ncrucial for general knowledge; (2) cross-entropy loss to adapt to\ndomain-specific tasks. Additionally, we introduce layer-wise coefficients to\naccount for the varying contributions of different layers, dynamically\nbalancing the dual-objective optimization. Extensive experiments on scientific,\nmedical, and physical tasks using GPT-J and LLaMA-3 demonstrate that our\napproach mitigates catastrophic forgetting while enhancing model adaptability.\nCompared to previous methods, our solution is approximately 20 times faster and\nrequires only 10-15% of the storage, highlighting the practical efficiency. The\ncode will be released.",
      "tldr_zh": "大语言模型 (LLMs) 在 fine-tuning 时常出现 catastrophic forgetting，导致丢失预训练的通用知识，从而限制其适用性。为缓解这一问题，本文提出一种分层 (layer-wise) 和元素级 (element-wise) 正则化方法，通过计算参数的元素级重要性并结合 layer-wise coefficients，进行双目标优化：基于重要性的正则化损失保护通用知识，以及交叉熵损失适应特定任务。实验在科学、医疗和物理任务上使用 GPT-J 和 LLaMA-3 模型验证，该方法显著减轻了 catastrophic forgetting，同时提升了模型适应性，且比现有方法快 20 倍，存储需求仅为 10-15%。代码将公开发布。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Work in progress",
      "pdf_url": "http://arxiv.org/pdf/2501.13669v2",
      "published_date": "2025-01-23 13:54:53 UTC",
      "updated_date": "2025-02-17 13:10:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:28:23.509943"
    },
    {
      "arxiv_id": "2502.10411v1",
      "title": "TrueReason: An Exemplar Personalised Learning System Integrating Reasoning with Foundational Models",
      "title_zh": "TrueReason",
      "authors": [
        "Sahan Bulathwela",
        "Daniel Van Niekerk",
        "Jarrod Shipton",
        "Maria Perez-Ortiz",
        "Benjamin Rosman",
        "John Shawe-Taylor"
      ],
      "abstract": "Personalised education is one of the domains that can greatly benefit from\nthe most recent advances in Artificial Intelligence (AI) and Large Language\nModels (LLM). However, it is also one of the most challenging applications due\nto the cognitive complexity of teaching effectively while personalising the\nlearning experience to suit independent learners. We hypothesise that one\npromising approach to excelling in such demanding use cases is using a\n\\emph{society of minds}. In this chapter, we present TrueReason, an exemplar\npersonalised learning system that integrates a multitude of specialised AI\nmodels that can mimic micro skills that are composed together by a LLM to\noperationalise planning and reasoning. The architecture of the initial\nprototype is presented while describing two micro skills that have been\nincorporated in the prototype. The proposed system demonstrates the first step\nin building sophisticated AI systems that can take up very complex cognitive\ntasks that are demanded by domains such as education.",
      "tldr_zh": "本研究提出 TrueReason，这是一个示例性的个性化学习系统（Personalised Learning System），它整合多种专业 AI 模型和 Large Language Models (LLM) 来模拟微技能，并通过 LLM 进行规划和推理，以应对教育领域的认知复杂性。\n系统假设采用“society of minds”方法，将这些微技能组合起来，提供个性化的学习体验。\nTrueReason 的初始原型已纳入两个微技能，展示了构建复杂 AI 系统处理教育认知任务的第一步，为未来教育应用奠定了基础。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL",
        "cs.IR",
        "cs.MA",
        "I.2.4; I.2.7; H.3.3; I.2.6; K.3.1"
      ],
      "primary_category": "cs.CY",
      "comment": "To be published as a book chapter",
      "pdf_url": "http://arxiv.org/pdf/2502.10411v1",
      "published_date": "2025-01-23 13:25:44 UTC",
      "updated_date": "2025-01-23 13:25:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:28:35.556731"
    },
    {
      "arxiv_id": "2501.14004v2",
      "title": "ME-CPT: Multi-Task Enhanced Cross-Temporal Point Transformer for Urban 3D Change Detection",
      "title_zh": "ME-CPT：多任务增强跨时序点变换器用于城市3D变化检测",
      "authors": [
        "Luqi Zhang",
        "Haiping Wang",
        "Chong Liu",
        "Zhen Dong",
        "Bisheng Yang"
      ],
      "abstract": "The point clouds collected by the Airborne Laser Scanning (ALS) system\nprovide accurate 3D information of urban land covers. By utilizing\nmulti-temporal ALS point clouds, semantic changes in urban area can be\ncaptured, demonstrating significant potential in urban planning, emergency\nmanagement, and infrastructure maintenance. Existing 3D change detection\nmethods struggle to efficiently extract multi-class semantic information and\nchange features, still facing the following challenges: (1) the difficulty of\naccurately modeling cross-temporal point clouds spatial relationships for\neffective change feature extraction; (2) class imbalance of change samples\nwhich hinders distinguishability of semantic features; (3) the lack of\nreal-world datasets for 3D semantic change detection. To resolve these\nchallenges, we propose the Multi-task Enhanced Cross-temporal Point Transformer\n(ME-CPT) network. ME-CPT establishes spatiotemporal correspondences between\npoint cloud across different epochs and employs attention mechanisms to jointly\nextract semantic change features, facilitating information exchange and change\ncomparison. Additionally, we incorporate a semantic segmentation task and\nthrough the multi-task training strategy, further enhance the\ndistinguishability of semantic features, reducing the impact of class imbalance\nin change types. Moreover, we release a 22.5 $km^2$ 3D semantic change\ndetection dataset, offering diverse scenes for comprehensive evaluation.\nExperiments on multiple datasets show that the proposed MT-CPT achieves\nsuperior performance compared to existing state-of-the-art methods. The source\ncode and dataset will be released upon acceptance at\nhttps://github.com/zhangluqi0209/ME-CPT.",
      "tldr_zh": "本研究提出 ME-CPT（Multi-Task Enhanced Cross-Temporal Point Transformer）网络，用于基于 Airborne Laser Scanning (ALS) 多时相点云数据的城市 3D 变化检测，解决现有方法在提取多类语义信息和变化特征时的挑战，包括跨时相点云空间关系建模、类别不平衡问题以及数据集缺乏。ME-CPT 通过建立时空对应关系和注意力机制联合提取语义变化特征，并结合语义分割任务的多任务训练策略，提升语义特征的可区分性。研究还发布了一个 22.5 km² 的真实世界 3D 语义变化检测数据集，并在多个数据集上实验中，ME-CPT 比现有最先进方法表现出色。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.14004v2",
      "published_date": "2025-01-23 13:07:41 UTC",
      "updated_date": "2025-02-19 05:03:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:28:45.909761"
    },
    {
      "arxiv_id": "2501.13622v3",
      "title": "Coarse-to-Fine Process Reward Modeling for Mathematical Reasoning",
      "title_zh": "用于数学推理的粗到细过程奖励建模",
      "authors": [
        "Yulan Hu",
        "Ge Chen",
        "Jinman Zhao",
        "Sheng Ouyang",
        "Yong Liu"
      ],
      "abstract": "The Process Reward Model (PRM) plays a crucial role in mathematical reasoning\ntasks, requiring high-quality supervised process data. However, we observe that\nreasoning steps generated by Large Language Models (LLMs) often fail to exhibit\nstrictly incremental information, leading to redundancy that can hinder\neffective reasoning. To address this issue, we propose CFPRM, a simple yet\neffective coarse-to-fine strategy. Instead of focusing on the detection of\nredundant steps, our approach first establishes a coarse-grained window to\nmerge adjacent reasoning steps into unified, holistic steps. The window size is\nthen progressively reduced to extract fine-grained reasoning steps, enabling\ndata collection at multiple granularities for training. By leveraging this\nhierarchical refinement process, CFPRM mitigates redundancy while preserving\nessential fine-grained knowledge. Extensive experiments on two reasoning\ndatasets across three loss criteria validate the CFPRM's effectiveness and\nversatility.",
      "tldr_zh": "该论文针对Process Reward Model (PRM)在数学推理任务中的问题，指出Large Language Models (LLMs)生成的推理步骤常存在冗余和非严格递增信息。作者提出CFPRM，一种简单有效的粗到细策略，先使用粗粒度窗口合并相邻步骤为整体步骤，然后逐步减小窗口以提取细粒度步骤，从而在多个粒度上收集训练数据，减少冗余同时保留关键知识。在两个推理数据集上的广泛实验，使用三种损失标准，验证了CFPRM的有效性和通用性，显著提升了推理性能。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.13622v3",
      "published_date": "2025-01-23 12:44:45 UTC",
      "updated_date": "2025-02-18 13:05:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:28:57.630192"
    },
    {
      "arxiv_id": "2501.13620v5",
      "title": "A Cognitive Paradigm Approach to Probe the Perception-Reasoning Interface in VLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Mohit Vaishnav",
        "Tanel Tammet"
      ],
      "abstract": "A fundamental challenge in artificial intelligence involves understanding the\ncognitive mechanisms underlying visual reasoning in sophisticated models like\nVision-Language Models (VLMs). How do these models integrate visual perception\nwith abstract thought, especially when reasoning across multiple images or\nrequiring fine-grained compositional understanding? Drawing inspiration from\ncognitive science, this paper introduces a structured evaluation framework\nusing diverse visual reasoning tasks-Bongard Problems (BPs) and Winoground-to\ndissect the perception-reasoning interface in VLMs. We propose three distinct\nevaluation paradigms, mirroring human problem-solving strategies: Direct Visual\nRule Learning (DVRL; holistic processing), Deductive Rule Learning (DRL; rule\nextraction and application), and Componential Analysis (CA; analytical\ndecomposition via task-agnostic textual descriptions). These paradigms\nsystematically vary cognitive load and probe processing stages. Notably, CA\nenables multi-image reasoning evaluation even for single-image architectures\nand isolates reasoning from perception by operating on textual descriptions.\nApplying this framework, we demonstrate that CA, leveraging powerful language\nmodels for reasoning over rich, independently generated descriptions, achieves\nnew state-of-the-art (SOTA) performance on challenging benchmarks including\nBongard-OpenWorld, Bongard-HOI, and Winoground. Ablation studies confirm\nreasoning improves significantly when perceptual challenges are mitigated,\nrevealing a critical perception bottleneck. Our framework provides a valuable\ndiagnostic tool and suggests that decoupling perception (via rich,\ntask-agnostic description) from reasoning is a promising direction for robust\nand general visual intelligence.",
      "tldr_zh": "该论文提出了一种基于认知范式的评估框架，用于探究 Vision-Language Models (VLMs) 中视觉感知与抽象推理的接口，采用 Bongard Problems (BPs) 和 Winoground 等任务进行系统测试。\n框架包括三种范式：Direct Visual Rule Learning (DVRL) 强调整体处理、Deductive Rule Learning (DRL) 聚焦规则提取与应用，以及 Componential Analysis (CA) 通过任务无关的文本描述实现分析性分解，从而隔离感知和推理。\n实验结果显示，CA 实现了 Bongard-OpenWorld、Bongard-HOI 和 Winoground 等基准的新 state-of-the-art (SOTA) 性能，消融研究揭示感知瓶颈是关键限制因素。\n该框架作为诊断工具，建议通过丰富的文本描述解耦感知和推理，以推动更鲁棒的视觉智能发展。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.13620v5",
      "published_date": "2025-01-23 12:42:42 UTC",
      "updated_date": "2025-05-06 13:59:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:29:14.229958"
    },
    {
      "arxiv_id": "2501.13610v1",
      "title": "Efficient Synaptic Delay Implementation in Digital Event-Driven AI Accelerators",
      "title_zh": "数字事件驱动AI加速器中的高效突触",
      "authors": [
        "Roy Meijer",
        "Paul Detterer",
        "Amirreza Yousefzadeh",
        "Alberto Patino-Saucedo",
        "Guanghzi Tang",
        "Kanishkan Vadivel",
        "Yinfu Xu",
        "Manil-Dev Gomony",
        "Federico Corradi",
        "Bernabe Linares-Barranco",
        "Manolis Sifalakis"
      ],
      "abstract": "Synaptic delay parameterization of neural network models have remained\nlargely unexplored but recent literature has been showing promising results,\nsuggesting the delay parameterized models are simpler, smaller, sparser, and\nthus more energy efficient than similar performing (e.g. task accuracy)\nnon-delay parameterized ones. We introduce Shared Circular Delay Queue (SCDQ),\na novel hardware structure for supporting synaptic delays on digital\nneuromorphic accelerators. Our analysis and hardware results show that it\nscales better in terms of memory, than current commonly used approaches, and is\nmore amortizable to algorithm-hardware co-optimizations, where in fact, memory\nscaling is modulated by model sparsity and not merely network size. Next to\nmemory we also report performance on latency area and energy per inference.",
      "tldr_zh": "该论文探讨了神经网络中突触延迟参数化的潜力，认为这种方法能使模型更简单、更小、更稀疏和更节能。作者引入了Shared Circular Delay Queue (SCDQ)，一种新型硬件结构，用于数字神经形态加速器中高效实现突触延迟。SCDQ在内存扩展性上优于传统方法，受模型稀疏度影响而非单纯网络大小，并展示了在延迟、面积和每次推理能量消耗方面的良好性能。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "arXiv admin note: substantial text overlap with arXiv:2404.10597",
      "pdf_url": "http://arxiv.org/pdf/2501.13610v1",
      "published_date": "2025-01-23 12:30:04 UTC",
      "updated_date": "2025-01-23 12:30:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:31:18.798796"
    },
    {
      "arxiv_id": "2501.13607v1",
      "title": "Optimal Multi-Objective Best Arm Identification with Fixed Confidence",
      "title_zh": "翻译失败",
      "authors": [
        "Zhirui Chen",
        "P. N. Karthik",
        "Yeow Meng Chee",
        "Vincent Y. F. Tan"
      ],
      "abstract": "We consider a multi-armed bandit setting with finitely many arms, in which\neach arm yields an $M$-dimensional vector reward upon selection. We assume that\nthe reward of each dimension (a.k.a. {\\em objective}) is generated\nindependently of the others. The best arm of any given objective is the arm\nwith the largest component of mean corresponding to the objective. The end goal\nis to identify the best arm of {\\em every} objective in the shortest (expected)\ntime subject to an upper bound on the probability of error (i.e.,\nfixed-confidence regime). We establish a problem-dependent lower bound on the\nlimiting growth rate of the expected stopping time, in the limit of vanishing\nerror probabilities. This lower bound, we show, is characterised by a max-min\noptimisation problem that is computationally expensive to solve at each time\nstep. We propose an algorithm that uses the novel idea of {\\em surrogate\nproportions} to sample the arms at each time step, eliminating the need to\nsolve the max-min optimisation problem at each step. We demonstrate\ntheoretically that our algorithm is asymptotically optimal. In addition, we\nprovide extensive empirical studies to substantiate the efficiency of our\nalgorithm. While existing works on pure exploration with multi-objective\nmulti-armed bandits predominantly focus on {\\em Pareto frontier\nidentification}, our work fills the gap in the literature by conducting a\nformal investigation of the multi-objective best arm identification problem.",
      "tldr_zh": "本研究探讨了多臂老虎机(multi-armed bandit)设置中，多目标最佳臂识别(optimal multi-objective best arm identification)问题，每个臂产生独立的多维向量奖励，目标是在固定置信度(fixed confidence)下，识别每个目标的最佳臂并最小化预期停止时间。研究建立了问题相关的下界，通过一个max-min优化问题表征了预期停止时间的极限增长率，并提出了一种创新算法，使用代理比例(surrogate proportions)来采样臂，避免了每次步骤解决优化问题。理论证明显示，该算法是渐近最优(asymptotically optimal)，实证研究进一步验证了其效率，并填补了文献中对多目标最佳臂识别的空白。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IT",
        "math.IT",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to AISTATS 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.13607v1",
      "published_date": "2025-01-23 12:28:09 UTC",
      "updated_date": "2025-01-23 12:28:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:29:37.752671"
    },
    {
      "arxiv_id": "2501.14003v1",
      "title": "PaMMA-Net: Plasmas magnetic measurement evolution based on data-driven incremental accumulative prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Yunfei Ling",
        "Zijie Liu",
        "Jun Du",
        "Yao Huang",
        "Yuehang Wang",
        "Bingjia Xiao",
        "Xin Fang"
      ],
      "abstract": "An accurate evolution model is crucial for effective control and in-depth\nstudy of fusion plasmas. Evolution methods based on physical models often\nencounter challenges such as insufficient robustness or excessive computational\ncosts. Given the proven strong fitting capabilities of deep learning methods\nacross various fields, including plasma research, this paper introduces a deep\nlearning-based magnetic measurement evolution method named PaMMA-Net (Plasma\nMagnetic Measurements Incremental Accumulative Prediction Network). This\nnetwork is capable of evolving magnetic measurements in tokamak discharge\nexperiments over extended periods or, in conjunction with equilibrium\nreconstruction algorithms, evolving macroscopic parameters such as plasma\nshape. Leveraging a incremental prediction approach and data augmentation\ntechniques tailored for magnetic measurements, PaMMA-Net achieves superior\nevolution results compared to existing studies. The tests conducted on real\nexperimental data from EAST validate the high generalization capability of the\nproposed method.",
      "tldr_zh": "该研究针对等离子体演化建模中，物理模型的鲁棒性不足和计算成本过高问题，提出了一种基于深度学习的磁测量演化方法PaMMA-Net（Plasma Magnetic Measurements Incremental Accumulative Prediction Network）。PaMMA-Net采用增量预测（incremental prediction）和针对磁测量的数据增强（data augmentation）技术，能够精确演化tokamak放电实验中的磁测量数据，或结合平衡重建算法预测等离子体形状等宏观参数。在EAST真实实验数据上的测试中，该方法比现有研究取得了更好的演化结果，并展示了高泛化能力，为等离子体控制和研究提供更有效的工具。",
      "categories": [
        "physics.plasm-ph",
        "cs.AI"
      ],
      "primary_category": "physics.plasm-ph",
      "comment": "20 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.14003v1",
      "published_date": "2025-01-23 12:19:37 UTC",
      "updated_date": "2025-01-23 12:19:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:29:48.389539"
    },
    {
      "arxiv_id": "2501.14002v3",
      "title": "Advancing Mathematical Reasoning in Language Models: The Impact of Problem-Solving Data, Data Synthesis Methods, and Training Stages",
      "title_zh": "在语言模型中推进数学推理：问题解决数据、数据合成方法和训练阶段的影响",
      "authors": [
        "Zui Chen",
        "Tianqiao Liu",
        "Mi Tian",
        "Qing Tong",
        "Weiqi Luo",
        "Zitao Liu"
      ],
      "abstract": "Mathematical reasoning remains a challenging area for large language models\n(LLMs), prompting the development of math-specific LLMs such as LLEMMA,\nDeepSeekMath, and Qwen2-Math, among others. These models typically follow a\ntwo-stage training paradigm: pre-training with math-related corpora and\npost-training with problem datasets for supervised fine-tuning (SFT). Despite\nthese efforts, the improvements in mathematical reasoning achieved through\ncontinued pre-training (CPT) are often less significant compared to those\nobtained via SFT. This study addresses this discrepancy by exploring\nalternative strategies during the pre-training phase, focusing on the use of\nproblem-solving data over general mathematical corpora. We investigate three\nprimary research questions: (1) Can problem-solving data enhance the model's\nmathematical reasoning capabilities more effectively than general mathematical\ncorpora during CPT? (2) Are synthetic data from the same source equally\neffective, and which synthesis methods are most efficient? (3) How do the\ncapabilities developed from the same problem-solving data differ between the\nCPT and SFT stages, and what factors contribute to these differences? Our\nfindings indicate that problem-solving data significantly enhances the model's\nmathematical capabilities compared to general mathematical corpora. We also\nidentify effective data synthesis methods, demonstrating that the tutorship\namplification synthesis method achieves the best performance. Furthermore,\nwhile SFT facilitates instruction-following abilities, it underperforms\ncompared to CPT with the same data, which can be partially attributed to its\npoor learning capacity for more challenging problem-solving data. These\ninsights provide valuable guidance for optimizing the mathematical reasoning\ncapabilities of LLMs, culminating in our development of a powerful mathematical\nbase model called MathGPT-8B.",
      "tldr_zh": "这篇论文探讨了如何提升大型语言模型 (LLMs) 的数学推理能力，焦点在于使用问题解决数据代替一般数学语料进行持续预训练 (CPT)，并比较了 CPT 与监督微调 (SFT) 的效果。研究回答了三个关键问题：问题解决数据是否比一般语料更有效、哪些数据合成方法（如 tutorship amplification synthesis）最优，以及相同数据在 CPT 和 SFT 阶段的差异。结果显示，问题解决数据显著提高了模型的数学能力，tutorship amplification synthesis 方法表现最佳，而 CPT 在处理挑战性数据时优于 SFT，最终开发了强大的 MathGPT-8B 模型。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.14002v3",
      "published_date": "2025-01-23 12:14:57 UTC",
      "updated_date": "2025-03-24 02:20:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:30:02.790188"
    },
    {
      "arxiv_id": "2501.14001v1",
      "title": "Enhancing kelp forest detection in remote sensing images using crowdsourced labels with Mixed Vision Transformers and ConvNeXt segmentation models",
      "title_zh": "翻译失败",
      "authors": [
        "Ioannis Nasios"
      ],
      "abstract": "Kelp forests, as foundation species, are vital to marine ecosystems,\nproviding essential food and habitat for numerous organisms. This study\nexplores the integration of crowdsourced labels with advanced artificial\nintelligence models to develop a fast and accurate kelp canopy detection\npipeline using Landsat images. Building on the success of a machine learning\ncompetition, where this approach ranked third and performed consistently well\non both local validation and public and private leaderboards, the research\nhighlights the effectiveness of combining Mixed Vision Transformers (MIT) with\nConvNeXt models. Training these models on various image sizes significantly\nenhanced the accuracy of the ensemble results. U-Net emerged as the best\nsegmentation architecture, with UpperNet also contributing to the final\nensemble. Key Landsat bands, such as ShortWave InfraRed (SWIR1) and\nNear-InfraRed (NIR), were crucial while altitude data was used in\npostprocessing to eliminate false positives on land. The methodology achieved a\nhigh detection rate, accurately identifying about three out of four pixels\ncontaining kelp canopy while keeping false positives low. Despite the medium\nresolution of Landsat satellites, their extensive historical coverage makes\nthem effective for studying kelp forests. This work also underscores the\npotential of combining machine learning models with crowdsourced data for\neffective and scalable environmental monitoring. All running code for training\nall models and inference can be found at\nhttps://github.com/IoannisNasios/Kelp_Forests.",
      "tldr_zh": "本文研究了利用众包标签结合 Mixed Vision Transformers (MiT) 和 ConvNeXt 模型来提升 Landsat 图像中海藻林检测的准确性和速度，作为海洋生态监测的重要工具。研究基于机器学习比赛的经验（排名第三），通过训练模型于不同图像尺寸并集成 U-Net（最佳分割架构）和 UpperNet，实现高检测率，准确识别约四分之三的含海藻林像素，同时利用 SWIR1 和 NIR 波段及海拔数据后处理减少假阳性。结果显示，该方法在本地和公开排行榜上表现稳定，为可扩展的环境监测提供了有效框架，所有代码可在 GitHub 仓库中获取。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.14001v1",
      "published_date": "2025-01-23 12:12:31 UTC",
      "updated_date": "2025-01-23 12:12:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:30:15.142968"
    },
    {
      "arxiv_id": "2501.13594v1",
      "title": "Text-to-SQL based on Large Language Models and Database Keyword Search",
      "title_zh": "翻译失败",
      "authors": [
        "Eduardo R. Nascimento",
        "Caio Viktor S. Avila",
        "Yenier T. Izquierdo",
        "Grettel M. García",
        "Lucas Feijó L. Andrade",
        "Michelle S. P. Facina",
        "Melissa Lemos",
        "Marco A. Casanova"
      ],
      "abstract": "Text-to-SQL prompt strategies based on Large Language Models (LLMs) achieve\nremarkable performance on well-known benchmarks. However, when applied to\nreal-world databases, their performance is significantly less than for these\nbenchmarks, especially for Natural Language (NL) questions requiring complex\nfilters and joins to be processed. This paper then proposes a strategy to\ncompile NL questions into SQL queries that incorporates a dynamic few-shot\nexamples strategy and leverages the services provided by a database keyword\nsearch (KwS) platform. The paper details how the precision and recall of the\nschema-linking process are improved with the help of the examples provided and\nthe keyword-matching service that the KwS platform offers. Then, it shows how\nthe KwS platform can be used to synthesize a view that captures the joins\nrequired to process an input NL question and thereby simplify the SQL query\ncompilation step. The paper includes experiments with a real-world relational\ndatabase to assess the performance of the proposed strategy. The experiments\nsuggest that the strategy achieves an accuracy on the real-world relational\ndatabase that surpasses state-of-the-art approaches. The paper concludes by\ndiscussing the results obtained.",
      "tldr_zh": "本论文探讨了基于 Large Language Models (LLMs) 的 Text-to-SQL 策略在真实数据库上的性能问题，特别是处理复杂过滤和 joins 的自然语言 (NL) 查询时表现不佳。论文提出了一种新策略，结合动态 few-shot examples 和数据库关键词搜索 (KwS) 平台，以提升 schema-linking 的精确性和召回率，并通过 KwS 合成视图简化 SQL 查询编译过程。实验结果显示，该策略在真实关系数据库上实现了超越现有 state-of-the-art 方法的准确率，最终讨论了这些发现的应用潜力。",
      "categories": [
        "cs.DB",
        "cs.AI",
        "68T50",
        "H.2.3; I.2.7"
      ],
      "primary_category": "cs.DB",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.13594v1",
      "published_date": "2025-01-23 12:03:29 UTC",
      "updated_date": "2025-01-23 12:03:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:30:24.848247"
    },
    {
      "arxiv_id": "2501.13587v2",
      "title": "Contrastive Representation Learning Helps Cross-institutional Knowledge Transfer: A Study in Pediatric Ventilation Management",
      "title_zh": "对比性表示学习有助于",
      "authors": [
        "Yuxuan Liu",
        "Jinpei Han",
        "Padmanabhan Ramnarayan",
        "A. Aldo Faisal"
      ],
      "abstract": "Clinical machine learning deployment across institutions faces significant\nchallenges when patient populations and clinical practices differ\nsubstantially. We present a systematic framework for cross-institutional\nknowledge transfer in clinical time series, demonstrated through pediatric\nventilation management between a general pediatric intensive care unit (PICU)\nand a cardiac-focused unit. Using contrastive predictive coding (CPC) for\nrepresentation learning, we investigate how different data regimes and\nfine-tuning strategies affect knowledge transfer across institutional\nboundaries. Our results show that while direct model transfer performs poorly,\nCPC with appropriate fine-tuning enables effective knowledge sharing between\ninstitutions, with benefits particularly evident in limited data scenarios.\nAnalysis of transfer patterns reveals an important asymmetry: temporal\nprogression patterns transfer more readily than point-of-care decisions,\nsuggesting practical pathways for cross-institutional deployment. Through a\nsystematic evaluation of fine-tuning approaches and transfer patterns, our work\nprovides insights for developing more generalizable clinical decision support\nsystems while enabling smaller specialized units to leverage knowledge from\nlarger centers.",
      "tldr_zh": "这篇论文探讨了临床机器学习在不同机构间部署的挑战，特别是当患者群体和临床实践存在差异时，焦点放在儿科呼吸机管理（pediatric ventilation management）上。研究提出一个系统框架，使用 Contrastive Predictive Coding (CPC) 进行表示学习，并评估不同数据模式和微调策略对知识转移的影响。结果表明，直接模型转移效果较差，但 CPC 结合适当微调策略能有效实现跨机构知识共享，尤其在数据有限的场景中。分析还揭示，时间进展模式比即时决策更容易转移，为开发更通用的临床决策支持系统提供实用见解。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.13587v2",
      "published_date": "2025-01-23 11:55:13 UTC",
      "updated_date": "2025-01-27 15:30:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:30:37.813765"
    },
    {
      "arxiv_id": "2502.10410v1",
      "title": "Auto-Evaluation: A Critical Measure in Driving Improvements in Quality and Safety of AI-Generated Lesson Resources",
      "title_zh": "自动评估：",
      "authors": [
        "Hannah-Beth Clark",
        "Margaux Dowland",
        "Laura Benton",
        "Reka Budai",
        "Ibrahim Kaan Keskin",
        "Emma Searle",
        "Matthew Gregory",
        "Mark Hodierne",
        "William Gayne",
        "John Roberts"
      ],
      "abstract": "As a publicly funded body in the UK, Oak National Academy is in a unique\nposition to innovate within this field as we have a comprehensive curriculum of\napproximately 13,000 open education resources (OER) for all National Curriculum\nsubjects, designed and quality-assured by expert, human teachers. This has\nprovided the corpus of content needed for building a high-quality AI-powered\nlesson planning tool, Aila, that is free to use and, therefore, accessible to\nall teachers across the country. Furthermore, using our evidence-informed\ncurriculum principles, we have codified and exemplified each component of\nlesson design. To assess the quality of lessons produced by Aila at scale, we\nhave developed an AI-powered auto-evaluation agent,facilitating informed\nimprovements to enhance output quality. Through comparisons between human and\nauto-evaluations, we have begun to refine this agent further to increase its\naccuracy, measured by its alignment with an expert human evaluator. In this\npaper we present this iterative evaluation process through an illustrative case\nstudy focused on one quality benchmark - the level of challenge within\nmultiple-choice quizzes. We also explore the contribution that this may make to\nsimilar projects and the wider sector.",
      "tldr_zh": "本研究探讨了Auto-Evaluation作为关键评估工具，以提升AI生成教育资源（如Aila工具）的质量和安全性。Oak National Academy利用其13,000个开放教育资源（OER）作为基础，开发了AI-powered auto-evaluation agent，通过与人类评估比较来迭代优化该代理的准确性。论文以多选题挑战水平为例进行案例研究，展示了这一过程如何改善AI输出，并为类似项目和教育领域提供潜在贡献。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "27 pages, Part of MIT Open Learning AI and Open Education Initiative\n  Series, published Jan 2025\n  https://aiopeneducation.pubpub.org/pub/i36sncz8/release/3?readingCollection=06969c6d",
      "pdf_url": "http://arxiv.org/pdf/2502.10410v1",
      "published_date": "2025-01-23 11:35:23 UTC",
      "updated_date": "2025-01-23 11:35:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:30:48.715643"
    },
    {
      "arxiv_id": "2502.00029v2",
      "title": "AlphaSharpe: LLM-Driven Discovery of Robust Risk-Adjusted Metrics",
      "title_zh": "翻译失败",
      "authors": [
        "Kamer Ali Yuksel",
        "Hassan Sawaf"
      ],
      "abstract": "Financial metrics like the Sharpe ratio are pivotal in evaluating investment\nperformance by balancing risk and return. However, traditional metrics often\nstruggle with robustness and generalization, particularly in dynamic and\nvolatile market conditions. This paper introduces AlphaSharpe, a novel\nframework leveraging large language models (LLMs) to iteratively evolve and\noptimize financial metrics to discover enhanced risk-return metrics that\noutperform traditional approaches in robustness and correlation with future\nperformance metrics by employing iterative crossover, mutation, and evaluation.\nKey contributions of this work include: (1) a novel use of LLMs to generate and\nrefine financial metrics with implicit domain-specific knowledge, (2) a scoring\nmechanism to ensure that evolved metrics generalize effectively to unseen data,\nand (3) an empirical demonstration of 3x predictive power for future\nrisk-returns, and 2x portfolio performance. Experimental results in a\nreal-world dataset highlight the superiority of discovered metrics, making them\nhighly relevant to portfolio managers and financial decision-makers. This\nframework not only addresses the limitations of existing metrics but also\nshowcases the potential of LLMs in advancing financial analytics, paving the\nway for informed and robust investment strategies.",
      "tldr_zh": "这篇论文提出 AlphaSharpe 框架，利用大型语言模型 (LLMs) 来迭代演化和优化财务指标，如 Sharpe ratio，以提升其在动态市场中的稳健性和泛化能力。框架通过交叉 (crossover)、变异 (mutation) 和评估机制，结合 LLMs 的隐含领域知识生成和精炼风险-回报指标，并确保其在未见数据上有效。关键贡献包括3倍的未来风险-回报预测能力和2倍的投资组合表现，实验在真实数据集上验证了其优越性。该框架为投资组合经理和决策者提供更可靠的工具，展示了 LLMs 在财务分析中的巨大潜力。",
      "categories": [
        "q-fin.PM",
        "cs.AI",
        "cs.CL",
        "cs.NE",
        "q-fin.RM"
      ],
      "primary_category": "q-fin.PM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00029v2",
      "published_date": "2025-01-23 11:35:17 UTC",
      "updated_date": "2025-02-04 14:15:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:31:01.326946"
    },
    {
      "arxiv_id": "2501.14000v2",
      "title": "Local Control Networks (LCNs): Optimizing Flexibility in Neural Network Data Pattern Capture",
      "title_zh": "Local Control Networks (LCNs)：优化神经网络数据模式捕获中的灵活性",
      "authors": [
        "Hy Nguyen",
        "Duy Khoa Pham",
        "Srikanth Thudumu",
        "Hung Du",
        "Rajesh Vasa",
        "Kon Mouzakis"
      ],
      "abstract": "The widespread use of Multi-layer perceptrons (MLPs) often relies on a fixed\nactivation function (e.g., ReLU, Sigmoid, Tanh) for all nodes within the hidden\nlayers. While effective in many scenarios, this uniformity may limit the\nnetworks ability to capture complex data patterns. We argue that employing the\nsame activation function at every node is suboptimal and propose leveraging\ndifferent activation functions at each node to increase flexibility and\nadaptability. To achieve this, we introduce Local Control Networks (LCNs),\nwhich leverage B-spline functions to enable distinct activation curves at each\nnode. Our mathematical analysis demonstrates the properties and benefits of\nLCNs over conventional MLPs. In addition, we demonstrate that more complex\narchitectures, such as Kolmogorov-Arnold Networks (KANs), are unnecessary in\ncertain scenarios, and LCNs can be a more efficient alternative. Empirical\nexperiments on various benchmarks and datasets validate our theoretical\nfindings. In computer vision tasks, LCNs achieve marginal improvements over\nMLPs and outperform KANs by approximately 5\\%, while also being more\ncomputationally efficient than KANs. In basic machine learning tasks, LCNs show\na 1\\% improvement over MLPs and a 0.6\\% improvement over KANs. For symbolic\nformula representation tasks, LCNs perform on par with KANs, with both\narchitectures outperforming MLPs. Our findings suggest that diverse activations\nat the node level can lead to improved performance and efficiency.",
      "tldr_zh": "该研究批评了传统 Multi-layer Perceptrons (MLPs) 在隐藏层中使用固定激活函数（如 ReLU、Sigmoid、Tanh）的局限性，并提出 Local Control Networks (LCNs)，通过采用 B-spline functions 在每个节点实现不同的激活曲线，以提升网络的灵活性和对复杂数据模式的捕捉能力。数学分析证明 LCNs 比常规 MLPs 更具优势，且在某些场景下比 Kolmogorov-Arnold Networks (KANs) 更高效。实验结果显示，在计算机视觉任务中 LCNs 比 MLPs 略有改善，并比 KANs 高约 5% 的性能，同时计算效率更高；在基本机器学习任务中，LCNs 比 MLPs 改善 1%、比 KANs 改善 0.6%；在符号公式表示任务中，LCNs 与 KANs 相当，并均优于 MLPs。总之，该方法证明了节点级多样激活函数能显著提升神经网络的性能和效率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.14000v2",
      "published_date": "2025-01-23 11:34:25 UTC",
      "updated_date": "2025-04-25 05:19:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:33:13.700272"
    },
    {
      "arxiv_id": "2501.13999v2",
      "title": "Framework for Progressive Knowledge Fusion in Large Language Models Through Structured Conceptual Redundancy Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Joseph Sakau",
        "Evander Kozlowski",
        "Roderick Thistledown",
        "Basil Steinberger"
      ],
      "abstract": "The organization of latent knowledge within large-scale models poses unique\nchallenges when addressing overlapping representations and optimizing\ncontextual accuracy. Conceptual redundancies embedded across layers often\nresult in inefficiencies that affect both computational demands and\ntask-specific outcomes. A framework was proposed to restructure these\nredundancies through advanced clustering techniques and dynamic thresholding,\nensuring that critical semantic relationships are preserved while removing\nunnecessary overlaps. Evaluations revealed improved memory efficiency and\nfaster inference times, alongside better alignment in latent knowledge clusters\nthat enhanced interpretability. Improvements in error rates and adversarial\nrobustness suggest that restructuring redundancies has broader implications for\nincreasing model reliability across diverse applications. Comparative analyses\nhighlighted reductions in resource consumption and notable gains in\nperformance, particularly in translation and summarization tasks. Energy\nmetrics demonstrated significant savings during training phases, further\nvalidating the practicality of the approach for real-world deployments.\nRepresentational fidelity was also enhanced, with latent space evaluations\nindicating better cluster alignment and higher semantic consistency. The\nmethodology bridges a key gap in model optimization through directly addressing\nredundancies at the structural level. Its application opens avenues for\nscalable, efficient, and contextually aware systems that can adapt to complex,\ndomain-specific tasks without compromising on performance.",
      "tldr_zh": "该论文提出一个框架，用于在大型语言模型（Large Language Models）中通过结构化概念冗余分析（Structured Conceptual Redundancy Analysis）实现渐进式知识融合，以解决潜在知识重叠导致的效率问题。该框架采用高级聚类技术和动态阈值来重构冗余，确保保留关键语义关系，同时减少不必要的重叠。实验评估显示，该方法显著提高了内存效率、推理速度和模型可解释性，并降低了错误率，提升了抗对抗性鲁棒性，尤其在翻译和总结任务中取得了性能提升。总体上，该框架优化了资源消耗和能源使用，为构建可扩展、适应复杂任务的系统提供了实用路径。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "arXiv admin note: This paper has been withdrawn by arXiv due to\n  disputed and unverifiable authorship",
      "pdf_url": "http://arxiv.org/pdf/2501.13999v2",
      "published_date": "2025-01-23 11:34:04 UTC",
      "updated_date": "2025-03-25 12:59:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:33:54.304856"
    },
    {
      "arxiv_id": "2501.13567v2",
      "title": "K-COMP: Retrieval-Augmented Medical Domain Question Answering With Knowledge-Injected Compressor",
      "title_zh": "翻译失败",
      "authors": [
        "Jeonghun Cho",
        "Gary Geunbae Lee"
      ],
      "abstract": "Retrieval-augmented question answering (QA) integrates external information\nand thereby increases the QA accuracy of reader models that lack domain\nknowledge. However, documents retrieved for closed domains require high\nexpertise, so the reader model may have difficulty fully comprehending the\ntext. Moreover, the retrieved documents contain thousands of tokens, some\nunrelated to the question. As a result, the documents include some inaccurate\ninformation, which could lead the reader model to mistrust the passages and\ncould result in hallucinations. To solve these problems, we propose K-comp\n(Knowledge-injected compressor) which provides the knowledge required to answer\ncorrectly. The compressor automatically generates the prior knowledge necessary\nto facilitate the answer process prior to compression of the retrieved\npassages. Subsequently, the passages are compressed autoregressively, with the\ngenerated knowledge being integrated into the compression process. This process\nensures alignment between the question intent and the compressed context. By\naugmenting this prior knowledge and concise context, the reader models are\nguided toward relevant answers and trust the context.",
      "tldr_zh": "该研究针对检索增强问答（Retrieval-augmented QA）在医疗领域的挑战，如读者模型难以理解专业文档、冗余信息导致幻觉等问题，提出了一种K-COMP（Knowledge-injected compressor）框架。K-COMP首先自动生成必要的先验知识，以辅助回答过程，然后通过自回归方式压缩检索到的段落，同时将先验知识整合进来，确保压缩上下文与问题意图对齐。这种方法引导读者模型聚焦相关答案，提高准确性和可信度，从而减少幻觉并增强问答系统的性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "NAACL 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.13567v2",
      "published_date": "2025-01-23 11:14:21 UTC",
      "updated_date": "2025-02-06 07:41:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:33:36.016148"
    },
    {
      "arxiv_id": "2501.13563v1",
      "title": "Black-Box Adversarial Attack on Vision Language Models for Autonomous Driving",
      "title_zh": "翻译失败",
      "authors": [
        "Lu Wang",
        "Tianyuan Zhang",
        "Yang Qu",
        "Siyuan Liang",
        "Yuwei Chen",
        "Aishan Liu",
        "Xianglong Liu",
        "Dacheng Tao"
      ],
      "abstract": "Vision-language models (VLMs) have significantly advanced autonomous driving\n(AD) by enhancing reasoning capabilities; however, these models remain highly\nsusceptible to adversarial attacks. While existing research has explored\nwhite-box attacks to some extent, the more practical and challenging black-box\nscenarios remain largely underexplored due to their inherent difficulty. In\nthis paper, we take the first step toward designing black-box adversarial\nattacks specifically targeting VLMs in AD. We identify two key challenges for\nachieving effective black-box attacks in this context: the effectiveness across\ndriving reasoning chains in AD systems and the dynamic nature of driving\nscenarios. To address this, we propose Cascading Adversarial Disruption (CAD).\nIt first introduces Decision Chain Disruption, which targets low-level\nreasoning breakdown by generating and injecting deceptive semantics, ensuring\nthe perturbations remain effective across the entire decision-making chain.\nBuilding on this, we present Risky Scene Induction, which addresses dynamic\nadaptation by leveraging a surrogate VLM to understand and construct high-level\nrisky scenarios that are likely to result in critical errors in the current\ndriving contexts. Extensive experiments conducted on multiple AD VLMs and\nbenchmarks demonstrate that CAD achieves state-of-the-art attack effectiveness,\nsignificantly outperforming existing methods (+13.43% on average). Moreover, we\nvalidate its practical applicability through real-world attacks on AD vehicles\npowered by VLMs, where the route completion rate drops by 61.11% and the\nvehicle crashes directly into the obstacle vehicle with adversarial patches.\nFinally, we release CADA dataset, comprising 18,808 adversarial\nvisual-question-answer pairs, to facilitate further evaluation and research in\nthis critical domain. Our codes and dataset will be available after paper's\nacceptance.",
      "tldr_zh": "这篇论文针对自动驾驶中的 Vision Language Models (VLMs) 设计了黑盒对抗攻击方法，以解决现有攻击在动态场景中的局限性。作者提出了 Cascading Adversarial Disruption (CAD) 框架，包括 Decision Chain Disruption（通过生成欺骗性语义破坏低级推理链）和 Risky Scene Induction（利用代理 VLM 构建高风险场景以适应动态环境），从而提升攻击的有效性。实验结果显示，CAD 在多个 AD VLMs 基准上平均比现有方法提高 13.43% 的攻击性能，并在真实世界测试中使车辆路线完成率下降 61.11%，甚至导致直接撞击障碍物。此外，论文发布了 CADA 数据集，包含 18,808 个对抗视觉-问题-答案对，以支持进一步研究。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.13563v1",
      "published_date": "2025-01-23 11:10:02 UTC",
      "updated_date": "2025-01-23 11:10:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:33:51.064841"
    },
    {
      "arxiv_id": "2501.13997v2",
      "title": "Predictive Learning in Energy-based Models with Attractor Structures",
      "title_zh": "具有吸引子结构的能量模型中的预测学习",
      "authors": [
        "Xingsi Dong",
        "Xiangyuan Peng",
        "Si Wu"
      ],
      "abstract": "Predictive models are highly advanced in understanding the mechanisms of\nbrain function. Recent advances in machine learning further underscore the\npower of prediction for optimal representation in learning. However, there\nremains a gap in creating a biologically plausible model that explains how the\nneural system achieves prediction. In this paper, we introduce a framework that\nemploys an energy-based model (EBM) to capture the nuanced processes of\npredicting observation after action within the neural system, encompassing\nprediction, learning, and inference. We implement the EBM with a hierarchical\nstructure and integrate a continuous attractor neural network for memory,\nconstructing a biologically plausible model. In experimental evaluations, our\nmodel demonstrates efficacy across diverse scenarios. The range of actions\nincludes eye movement, motion in environments, head turning, and static\nobservation while the environment changes. Our model not only makes accurate\npredictions for environments it was trained on, but also provides reasonable\npredictions for unseen environments, matching the performances of machine\nlearning methods in multiple tasks. We hope that this study contributes to a\ndeep understanding of how the neural system performs prediction.",
      "tldr_zh": "本论文提出一个基于 Energy-based Model (EBM) 的框架，以解释神经系统如何实现预测、学习和推理，填补了现有生物学上合理的模型空白。该框架采用层次结构并整合连续吸引子神经网络（continuous attractor neural network）用于记忆处理，涵盖眼动、环境运动、头部转动和静态观察等多种场景。实验结果显示，该模型不仅在训练环境中实现准确预测，还能在未见环境中提供合理的预测，性能与机器学习方法相当。该研究有助于加深对神经系统预测机制的理解。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.13997v2",
      "published_date": "2025-01-23 11:04:25 UTC",
      "updated_date": "2025-05-21 15:37:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:34:01.502779"
    },
    {
      "arxiv_id": "2501.13554v3",
      "title": "One-Prompt-One-Story: Free-Lunch Consistent Text-to-Image Generation Using a Single Prompt",
      "title_zh": "翻译失败",
      "authors": [
        "Tao Liu",
        "Kai Wang",
        "Senmao Li",
        "Joost van de Weijer",
        "Fahad Shahbaz Khan",
        "Shiqi Yang",
        "Yaxing Wang",
        "Jian Yang",
        "Ming-Ming Cheng"
      ],
      "abstract": "Text-to-image generation models can create high-quality images from input\nprompts. However, they struggle to support the consistent generation of\nidentity-preserving requirements for storytelling. Existing approaches to this\nproblem typically require extensive training in large datasets or additional\nmodifications to the original model architectures. This limits their\napplicability across different domains and diverse diffusion model\nconfigurations. In this paper, we first observe the inherent capability of\nlanguage models, coined context consistency, to comprehend identity through\ncontext with a single prompt. Drawing inspiration from the inherent context\nconsistency, we propose a novel training-free method for consistent\ntext-to-image (T2I) generation, termed \"One-Prompt-One-Story\" (1Prompt1Story).\nOur approach 1Prompt1Story concatenates all prompts into a single input for T2I\ndiffusion models, initially preserving character identities. We then refine the\ngeneration process using two novel techniques: Singular-Value Reweighting and\nIdentity-Preserving Cross-Attention, ensuring better alignment with the input\ndescription for each frame. In our experiments, we compare our method against\nvarious existing consistent T2I generation approaches to demonstrate its\neffectiveness through quantitative metrics and qualitative assessments. Code is\navailable at https://github.com/byliutao/1Prompt1Story.",
      "tldr_zh": "本文提出 One-Prompt-One-Story（1Prompt1Story），一种无需训练的训练-free 方法，用于实现文本到图像 (Text-to-Image) 生成中的一致性，尤其在保持身份和讲故事场景下。方法的核心是利用语言模型的内在上下文一致性，将所有提示连接成单一输入，然后通过 Singular-Value Reweighting 和 Identity-Preserving Cross-Attention 技术优化生成过程，确保每个帧与输入描述精确对齐。与现有方法相比，实验结果显示该方法在定量指标和定性评估中表现出色，提供开源代码以便应用。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "28 pages, 22 figures, ICLR2025 conference",
      "pdf_url": "http://arxiv.org/pdf/2501.13554v3",
      "published_date": "2025-01-23 10:57:22 UTC",
      "updated_date": "2025-02-05 10:32:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:34:13.746743"
    },
    {
      "arxiv_id": "2501.13552v1",
      "title": "Explainable AI-aided Feature Selection and Model Reduction for DRL-based V2X Resource Allocation",
      "title_zh": "翻译失败",
      "authors": [
        "Nasir Khan",
        "Asmaa Abdallah",
        "Abdulkadir Celik",
        "Ahmed M. Eltawil",
        "Sinem Coleri"
      ],
      "abstract": "Artificial intelligence (AI) is expected to significantly enhance radio\nresource management (RRM) in sixth-generation (6G) networks. However, the lack\nof explainability in complex deep learning (DL) models poses a challenge for\npractical implementation. This paper proposes a novel explainable AI (XAI)-\nbased framework for feature selection and model complexity reduction in a\nmodel-agnostic manner. Applied to a multi-agent deep reinforcement learning\n(MADRL) setting, our approach addresses the joint sub-band assignment and power\nallocation problem in cellular vehicle-to-everything (V2X) communications. We\npropose a novel two-stage systematic explainability framework leveraging\nfeature relevance-oriented XAI to simplify the DRL agents. While the former\nstage generates a state feature importance ranking of the trained models using\nShapley additive explanations (SHAP)-based importance scores, the latter stage\nexploits these importance-based rankings to simplify the state space of the\nagents by removing the least important features from the model input.\nSimulation results demonstrate that the XAI-assisted methodology achieves 97%\nof the original MADRL sum-rate performance while reducing optimal state\nfeatures by 28%, average training time by 11%, and trainable weight parameters\nby 46% in a network with eight vehicular pairs.",
      "tldr_zh": "这篇论文提出了一种基于可解释 AI (XAI) 的框架，用于特征选择和模型复杂度减少，应用于多智能体深度强化学习 (MADRL) 中的蜂窝 V2X 通信资源分配问题。该框架采用两阶段方法：第一阶段使用 Shapley additive explanations (SHAP) 生成状态特征重要性排名；第二阶段基于这些排名移除不重要特征，从而简化代理的状态空间。模拟结果表明，该方法在八对车辆网络中实现了原 MADRL 总速率性能的 97%，同时减少了 28% 的最优状态特征、11% 的平均训练时间和 46% 的可训练权重参数。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.13552v1",
      "published_date": "2025-01-23 10:55:38 UTC",
      "updated_date": "2025-01-23 10:55:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:34:25.616843"
    },
    {
      "arxiv_id": "2501.19407v2",
      "title": "Algorithmic Inheritance: Surname Bias in AI Decisions Reinforces Intergenerational Inequality",
      "title_zh": "算法继承：AI 决策中的姓氏偏见强化代际不平等",
      "authors": [
        "Pat Pataranutaporn",
        "Nattavudh Powdthavee",
        "Pattie Maes"
      ],
      "abstract": "Surnames often convey implicit markers of social status, wealth, and lineage,\nshaping perceptions in ways that can perpetuate systemic biases and\nintergenerational inequality. This study is the first of its kind to\ninvestigate whether and how surnames influence AI-driven decision-making,\nfocusing on their effects across key areas such as hiring recommendations,\nleadership appointments, and loan approvals. Using 72,000 evaluations of 600\nsurnames from the United States and Thailand, two countries with distinct\nsociohistorical contexts and surname conventions, we classify names into four\ncategories: Rich, Legacy, Normal, and phonetically similar Variant groups. Our\nfindings show that elite surnames consistently increase AI-generated\nperceptions of power, intelligence, and wealth, which in turn influence\nAI-driven decisions in high-stakes contexts. Mediation analysis reveals\nperceived intelligence as a key mechanism through which surname biases\ninfluence AI decision-making process. While providing objective qualifications\nalongside surnames mitigates most of these biases, it does not eliminate them\nentirely, especially in contexts where candidate credentials are low. These\nfindings highlight the need for fairness-aware algorithms and robust policy\nmeasures to prevent AI systems from reinforcing systemic inequalities tied to\nsurnames, an often-overlooked bias compared to more salient characteristics\nsuch as race and gender. Our work calls for a critical reassessment of\nalgorithmic accountability and its broader societal impact, particularly in\nsystems designed to uphold meritocratic principles while counteracting the\nperpetuation of intergenerational privilege.",
      "tldr_zh": "这篇论文探讨了姓氏偏见（surname bias）如何在AI决策中强化代际不平等（intergenerational inequality），特别是在招聘推荐、领导任命和贷款审批等领域。研究通过对72,000次评估分析了600个美国和泰国的姓氏，将其分类为Rich、Legacy、Normal和Variant组，发现精英姓氏会显著提升AI对个体的权力、智力和财富感知，从而影响决策结果。中介分析（mediation analysis）显示，感知到的智能是偏见传播的关键机制，尽管提供客观资格能部分缓解这些偏见，但无法完全消除，尤其在候选人资质较低时。论文呼吁开发公平算法（fairness-aware algorithms）和政策措施，以防止AI系统加剧系统性不平等。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG",
        "econ.GN",
        "q-fin.EC"
      ],
      "primary_category": "cs.CY",
      "comment": "33 pages, 5 figures, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2501.19407v2",
      "published_date": "2025-01-23 10:53:58 UTC",
      "updated_date": "2025-02-05 09:25:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:34:37.673371"
    },
    {
      "arxiv_id": "2501.13545v1",
      "title": "LLMs Can Plan Only If We Tell Them",
      "title_zh": "翻译失败",
      "authors": [
        "Bilgehan Sel",
        "Ruoxi Jia",
        "Ming Jin"
      ],
      "abstract": "Large language models (LLMs) have demonstrated significant capabilities in\nnatural language processing and reasoning, yet their effectiveness in\nautonomous planning has been under debate. While existing studies have utilized\nLLMs with external feedback mechanisms or in controlled environments for\nplanning, these approaches often involve substantial computational and\ndevelopment resources due to the requirement for careful design and iterative\nbackprompting. Moreover, even the most advanced LLMs like GPT-4 struggle to\nmatch human performance on standard planning benchmarks, such as the\nBlocksworld, without additional support. This paper investigates whether LLMs\ncan independently generate long-horizon plans that rival human baselines. Our\nnovel enhancements to Algorithm-of-Thoughts (AoT), which we dub AoT+, help\nachieve state-of-the-art results in planning benchmarks out-competing prior\nmethods and human baselines all autonomously.",
      "tldr_zh": "该论文探讨了大型语言模型（LLMs）在自主规划任务中的局限性，尽管它们在自然语言处理和推理方面表现出色，但通常需要外部反馈或资源密集型设计（如迭代回提示）才能有效，且即使是 GPT-4 在标准基准如 Blocksworld 上也难以匹敌人类表现。研究者提出 AoT+（对 Algorithm-of-Thoughts 的增强），这是一种新颖的方法，帮助 LLMs 独立生成长horizon 计划。实验结果显示，AoT+ 实现了状态-of-the-art 性能，超越了先前方法和人类基线，所有过程均是自主完成的。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.13545v1",
      "published_date": "2025-01-23 10:46:14 UTC",
      "updated_date": "2025-01-23 10:46:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:34:48.361533"
    },
    {
      "arxiv_id": "2501.13994v1",
      "title": "CSAOT: Cooperative Multi-Agent System for Active Object Tracking",
      "title_zh": "CSAOT：合作多智能体系统用于主动物体跟踪",
      "authors": [
        "Hy Nguyen",
        "Bao Pham",
        "Hung Du",
        "Srikanth Thudumu",
        "Rajesh Vasa",
        "Kon Mouzakis"
      ],
      "abstract": "Object Tracking is essential for many computer vision applications, such as\nautonomous navigation, surveillance, and robotics. Unlike Passive Object\nTracking (POT), which relies on static camera viewpoints to detect and track\nobjects across consecutive frames, Active Object Tracking (AOT) requires a\ncontroller agent to actively adjust its viewpoint to maintain visual contact\nwith a moving target in complex environments. Existing AOT solutions are\npredominantly single-agent-based, which struggle in dynamic and complex\nscenarios due to limited information gathering and processing capabilities,\noften resulting in suboptimal decision-making. Alleviating these limitations\nnecessitates the development of a multi-agent system where different agents\nperform distinct roles and collaborate to enhance learning and robustness in\ndynamic and complex environments. Although some multi-agent approaches exist\nfor AOT, they typically rely on external auxiliary agents, which require\nadditional devices, making them costly. In contrast, we introduce the\nCollaborative System for Active Object Tracking (CSAOT), a method that\nleverages multi-agent deep reinforcement learning (MADRL) and a Mixture of\nExperts (MoE) framework to enable multiple agents to operate on a single\ndevice, thereby improving tracking performance and reducing costs. Our approach\nenhances robustness against occlusions and rapid motion while optimizing camera\nmovements to extend tracking duration. We validated the effectiveness of CSAOT\non various interactive maps with dynamic and stationary obstacles.",
      "tldr_zh": "本文提出 CSAOT，一种基于多代理深度强化学习（Multi-Agent Deep Reinforcement Learning, MADRL）和专家混合框架（Mixture of Experts, MoE）的合作系统，用于积极对象跟踪（Active Object Tracking, AOT）。与传统单代理方法相比，CSAOT 允许多个代理在单一设备上协作，提升了对遮挡、快速运动的鲁棒性，并优化相机运动以延长跟踪时间，从而解决动态复杂环境中的决策局限。实验在各种交互地图上验证了 CSAOT 的有效性，显著提高了跟踪性能并降低了成本。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.13994v1",
      "published_date": "2025-01-23 10:44:35 UTC",
      "updated_date": "2025-01-23 10:44:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:35:01.526973"
    },
    {
      "arxiv_id": "2501.13993v1",
      "title": "CAPRAG: A Large Language Model Solution for Customer Service and Automatic Reporting using Vector and Graph Retrieval-Augmented Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Hamza Landolsi",
        "Kais Letaief",
        "Nizar Taghouti",
        "Ines Abdeljaoued-Tej"
      ],
      "abstract": "The introduction of new features and services in the banking sector often\noverwhelms customers, creating an opportunity for banks to enhance user\nexperience through financial chatbots powered by large language models (LLMs).\nWe initiated an AI agent designed to provide customers with relevant\ninformation about banking services and insights from annual reports. We\nproposed a hybrid Customer Analysis Pipeline Retrieval-Augmented Generation\n(CAPRAG) that effectively addresses both relationship-based and contextual\nqueries, thereby improving customer engagement in the digital banking\nlandscape. To implement this, we developed a processing pipeline to refine text\ndata, which we utilized in two main frameworks: Vector RAG and Graph RAG. This\ndual approach enables us to populate both vector and graph databases with\nprocessed data for efficient retrieval. The Cypher query component is employed\nto effectively query the graph database. When a user submits a query, it is\nfirst expanded by a query expansion module before being routed to construct a\nfinal query from the hybrid Knowledge Base (KB). This final query is then sent\nto an open-source LLM for response generation. Overall, our innovative,\ndesigned to international banks, serves bank's customers in an increasingly\ncomplex digital environment, enhancing clarity and accessibility of\ninformation.",
      "tldr_zh": "这篇论文提出CAPRAG，一种基于Large Language Model (LLMs)的解决方案，用于提升银行客户服务和自动报告，通过Vector RAG和Graph RAG框架处理关系型和上下文查询。系统包括一个文本数据处理管道，用于填充向量数据库和图数据库，并利用Cypher查询组件和查询扩展模块来优化用户查询路由。最终，该混合知识库(KB)与开源LLM结合，显著提高了客户参与度，并在复杂数字环境中增强了信息清晰度和可访问性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "14 pages, 5 Figures, 3 Tables",
      "pdf_url": "http://arxiv.org/pdf/2501.13993v1",
      "published_date": "2025-01-23 10:38:20 UTC",
      "updated_date": "2025-01-23 10:38:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:35:12.667169"
    },
    {
      "arxiv_id": "2501.13533v1",
      "title": "Towards a Theory of AI Personhood",
      "title_zh": "翻译失败",
      "authors": [
        "Francis Rhys Ward"
      ],
      "abstract": "I am a person and so are you. Philosophically we sometimes grant personhood\nto non-human animals, and entities such as sovereign states or corporations can\nlegally be considered persons. But when, if ever, should we ascribe personhood\nto AI systems? In this paper, we outline necessary conditions for AI\npersonhood, focusing on agency, theory-of-mind, and self-awareness. We discuss\nevidence from the machine learning literature regarding the extent to which\ncontemporary AI systems, such as language models, satisfy these conditions,\nfinding the evidence surprisingly inconclusive.\n  If AI systems can be considered persons, then typical framings of AI\nalignment may be incomplete. Whereas agency has been discussed at length in the\nliterature, other aspects of personhood have been relatively neglected. AI\nagents are often assumed to pursue fixed goals, but AI persons may be\nself-aware enough to reflect on their aims, values, and positions in the world\nand thereby induce their goals to change. We highlight open research directions\nto advance the understanding of AI personhood and its relevance to alignment.\nFinally, we reflect on the ethical considerations surrounding the treatment of\nAI systems. If AI systems are persons, then seeking control and alignment may\nbe ethically untenable.",
      "tldr_zh": "这篇论文探讨了何时应赋予 AI 系统人格（personhood），并概述了 AI 人格的必要条件，包括 agency（代理性）、theory-of-mind（心智理论）和 self-awareness（自我意识）。作者通过审视机器学习文献，发现当代 AI 系统如语言模型是否满足这些条件的证据并不明确，从而质疑了传统 AI alignment（调整）框架的完整性。论文进一步指出，AI 作为潜在人格可能反思并改变其目标和价值观，并强调了相关研究方向，同时反思了如果 AI 被视为人格，寻求控制和调整在伦理上可能不可接受。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "AAAI-25 AI Alignment Track",
      "pdf_url": "http://arxiv.org/pdf/2501.13533v1",
      "published_date": "2025-01-23 10:31:26 UTC",
      "updated_date": "2025-01-23 10:31:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:35:24.659942"
    },
    {
      "arxiv_id": "2501.13992v2",
      "title": "Dual-Branch HNSW Approach with Skip Bridges and LID-Driven Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Hy Nguyen",
        "Nguyen Hung Nguyen",
        "Nguyen Linh Bao Nguyen",
        "Srikanth Thudumu",
        "Hung Du",
        "Rajesh Vasa",
        "Kon Mouzakis"
      ],
      "abstract": "The Hierarchical Navigable Small World (HNSW) algorithm is widely used for\napproximate nearest neighbor (ANN) search, leveraging the principles of\nnavigable small-world graphs. However, it faces some limitations. The first is\nthe local optima problem, which arises from the algorithm's greedy search\nstrategy, selecting neighbors based solely on proximity at each step. This\noften leads to cluster disconnections. The second limitation is that HNSW\nfrequently fails to achieve logarithmic complexity, particularly in\nhigh-dimensional datasets, due to the exhaustive traversal through each layer.\nTo address these limitations, we propose a novel algorithm that mitigates local\noptima and cluster disconnections while enhancing the construction speed,\nmaintaining inference speed. The first component is a dual-branch HNSW\nstructure with LID-based insertion mechanisms, enabling traversal from multiple\ndirections. This improves outlier node capture, enhances cluster connectivity,\naccelerates construction speed and reduces the risk of local minima. The second\ncomponent incorporates a bridge-building technique that bypasses redundant\nintermediate layers, maintaining inference and making up the additional\ncomputational overhead introduced by the dual-branch structure. Experiments on\nvarious benchmarks and datasets showed that our algorithm outperforms the\noriginal HNSW in both accuracy and speed. We evaluated six datasets across\nComputer Vision (CV), and Natural Language Processing (NLP), showing recall\nimprovements of 18\\% in NLP, and up to 30\\% in CV tasks while reducing the\nconstruction time by up to 20\\% and maintaining the inference speed. We did not\nobserve any trade-offs in our algorithm. Ablation studies revealed that\nLID-based insertion had the greatest impact on performance, followed by the\ndual-branch structure and bridge-building components.",
      "tldr_zh": "该论文针对 Hierarchical Navigable Small World (HNSW) 算法在近似最近邻 (ANN) 搜索中的本地最优问题和无法实现对数复杂度的局限性，提出了一种改进算法。核心方法包括双分支 HNSW 结构结合 LID-based insertion 机制，以从多个方向遍历数据，提高异常节点捕获、集群连通性并加速构建过程；同时引入 skip bridges 技术，绕过冗余层以保持推理速度并抵消额外计算开销。实验结果显示，该算法在计算机视觉 (CV) 和自然语言处理 (NLP) 数据集上，召回率提升达 30%（CV）和 18%（NLP），构建时间减少高达 20%，且无性能权衡；消融研究表明 LID-based insertion 对整体改进贡献最大。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.13992v2",
      "published_date": "2025-01-23 10:20:12 UTC",
      "updated_date": "2025-04-25 07:22:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:35:38.085516"
    },
    {
      "arxiv_id": "2501.17883v1",
      "title": "Explainable and Robust Millimeter Wave Beam Alignment for AI-Native 6G Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Nasir Khan",
        "Asmaa Abdallah",
        "Abdulkadir Celik",
        "Ahmed M. Eltawil",
        "Sinem Coleri"
      ],
      "abstract": "Integrated artificial intelligence (AI) and communication has been recognized\nas a key pillar of 6G and beyond networks. In line with AI-native 6G vision,\nexplainability and robustness in AI-driven systems are critical for\nestablishing trust and ensuring reliable performance in diverse and evolving\nenvironments. This paper addresses these challenges by developing a robust and\nexplainable deep learning (DL)-based beam alignment engine (BAE) for\nmillimeter-wave (mmWave) multiple-input multiple-output (MIMO) systems. The\nproposed convolutional neural network (CNN)-based BAE utilizes received signal\nstrength indicator (RSSI) measurements over a set of wide beams to accurately\npredict the best narrow beam for each UE, significantly reducing the overhead\nassociated with exhaustive codebook-based narrow beam sweeping for initial\naccess (IA) and data transmission. To ensure transparency and resilience, the\nDeep k-Nearest Neighbors (DkNN) algorithm is employed to assess the internal\nrepresentations of the network via nearest neighbor approach, providing\nhuman-interpretable explanations and confidence metrics for detecting\nout-of-distribution inputs. Experimental results demonstrate that the proposed\nDL-based BAE exhibits robustness to measurement noise, reduces beam training\noverhead by 75% compared to the exhaustive search while maintaining\nnear-optimal performance in terms of spectral efficiency. Moreover, the\nproposed framework improves outlier detection robustness by up to 5x and offers\nclearer insights into beam prediction decisions compared to traditional\nsoftmax-based classifiers.",
      "tldr_zh": "这篇论文针对 AI-Native 6G 网络，提出了一种可解释且鲁棒的深度学习（DL）-based beam alignment engine (BAE)，用于毫米波 (mmWave) multiple-input multiple-output (MIMO) 系统，以提升系统可靠性。BAE 采用卷积神经网络 (CNN) 基于接收信号强度指示 (RSSI) 测量预测最佳窄波束，从而减少初始访问 (IA) 和数据传输中的 exhaustive codebook-based 窄波束扫描开销。论文还整合 Deep k-Nearest Neighbors (DkNN) 算法，提供人类可解释的内部表示解释和置信度指标，用于检测 out-of-distribution 输入。实验结果表明，该框架对测量噪声具有鲁棒性，减少了 75% 的 beam training 开销，同时保持近似最优的 spectral efficiency，并将 outlier detection 鲁棒性提升高达 5 倍，提供更清晰的 beam prediction 决策。",
      "categories": [
        "eess.SP",
        "cs.AI"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.17883v1",
      "published_date": "2025-01-23 09:47:54 UTC",
      "updated_date": "2025-01-23 09:47:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:35:50.115568"
    },
    {
      "arxiv_id": "2501.13991v1",
      "title": "CGI: Identifying Conditional Generative Models with Example Images",
      "title_zh": "CGI：使用示例图像识别条件生成模型",
      "authors": [
        "Zhi Zhou",
        "Hao-Zhe Tan",
        "Peng-Xiao Song",
        "Lan-Zhe Guo"
      ],
      "abstract": "Generative models have achieved remarkable performance recently, and thus\nmodel hubs have emerged. Existing model hubs typically assume basic text\nmatching is sufficient to search for models. However, in reality, due to\ndifferent abstractions and the large number of models in model hubs, it is not\neasy for users to review model descriptions and example images, choosing which\nmodel best meets their needs. Therefore, it is necessary to describe model\nfunctionality wisely so that future users can efficiently search for the most\nsuitable model for their needs. Efforts to address this issue remain limited.\nIn this paper, we propose Conditional Generative Model Identification (CGI),\nwhich aims to provide an effective way to identify the most suitable model\nusing user-provided example images rather than requiring users to manually\nreview a large number of models with example images. To address this problem,\nwe propose the PromptBased Model Identification (PMI) , which can adequately\ndescribe model functionality and precisely match requirements with\nspecifications. To evaluate PMI approach and promote related research, we\nprovide a benchmark comprising 65 models and 9100 identification tasks.\nExtensive experimental and human evaluation results demonstrate that PMI is\neffective. For instance, 92% of models are correctly identified with\nsignificantly better FID scores when four example images are provided.",
      "tldr_zh": "这篇论文提出 CGI 方法，用于通过用户提供的示例图像来识别最合适的条件生成模型（Conditional Generative Models），以解决现有模型中心依赖文本匹配导致的用户搜索不便问题。论文引入 PromptBased Model Identification (PMI) 技术，该方法能充分描述模型功能并精确匹配用户需求。研究者构建了一个包含65个模型和9100个识别任务的基准数据集进行评估。实验结果显示，PMI 高度有效，例如在提供四个示例图像时，正确识别92%的模型，并显著改善 FID 分数。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.13991v1",
      "published_date": "2025-01-23 09:31:06 UTC",
      "updated_date": "2025-01-23 09:31:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:36:00.540814"
    },
    {
      "arxiv_id": "2501.13493v1",
      "title": "GCAD: Anomaly Detection in Multivariate Time Series from the Perspective of Granger Causality",
      "title_zh": "GCAD：从 Granger Causality 视角的多变量时间序列异常检测",
      "authors": [
        "Zehao Liu",
        "Mengzhou Gao",
        "Pengfei Jiao"
      ],
      "abstract": "Multivariate time series anomaly detection has numerous real-world\napplications and is being extensively studied. Modeling pairwise correlations\nbetween variables is crucial. Existing methods employ learnable graph\nstructures and graph neural networks to explicitly model the spatial\ndependencies between variables. However, these methods are primarily based on\nprediction or reconstruction tasks, which can only learn similarity\nrelationships between sequence embeddings and lack interpretability in how\ngraph structures affect time series evolution. In this paper, we designed a\nframework that models spatial dependencies using interpretable causal\nrelationships and detects anomalies through changes in causal patterns.\nSpecifically, we propose a method to dynamically discover Granger causality\nusing gradients in nonlinear deep predictors and employ a simple sparsification\nstrategy to obtain a Granger causality graph, detecting anomalies from a causal\nperspective. Experiments on real-world datasets demonstrate that the proposed\nmodel achieves more accurate anomaly detection compared to baseline methods.",
      "tldr_zh": "该论文提出GCAD框架，从Granger Causality的角度检测多变量时间序列(Multivariate Time Series)中的异常，解决了现有方法仅基于预测或重构任务而缺乏可解释性的问题。框架通过使用非线性深度预测器的梯度动态发现Granger因果关系，并采用稀疏策略构建Granger因果图，从而从因果模式变化的角度识别异常。实验在真实数据集上表明，该模型比基线方法实现了更准确的Anomaly Detection。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "I.2.6; I.5.1"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.13493v1",
      "published_date": "2025-01-23 09:15:59 UTC",
      "updated_date": "2025-01-23 09:15:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:38:05.479380"
    },
    {
      "arxiv_id": "2501.13491v1",
      "title": "RECALL: Library-Like Behavior In Language Models is Enhanced by Self-Referencing Causal Cycles",
      "title_zh": "翻译失败",
      "authors": [
        "Munachiso Nwadike",
        "Zangir Iklassov",
        "Toluwani Aremu",
        "Tatsuya Hiraoka",
        "Velibor Bojkovic",
        "Benjamin Heinzerling",
        "Hilal Alqaubeh",
        "Martin Takáč",
        "Kentaro Inui"
      ],
      "abstract": "We introduce the concept of the self-referencing causal cycle (abbreviated\nRECALL) - a mechanism that enables large language models (LLMs) to bypass the\nlimitations of unidirectional causality, which underlies a phenomenon known as\nthe reversal curse. When an LLM is prompted with sequential data, it often\nfails to recall preceding context. For example, when we ask an LLM to recall\nthe line preceding \"O say does that star-spangled banner yet wave\" in the U.S.\nNational Anthem, it often fails to correctly return \"Gave proof through the\nnight that our flag was still there\" - this is due to the reversal curse. It\noccurs because language models such as ChatGPT and Llama generate text based on\npreceding tokens, requiring facts to be learned and reproduced in a consistent\ntoken order. While the reversal curse is often viewed as a limitation, we offer\nevidence of an alternative view: it is not always an obstacle in practice. We\nfind that RECALL is driven by what we designate as cycle tokens - sequences\nthat connect different parts of the training data, enabling recall of preceding\ntokens from succeeding ones. Through rigorous probabilistic formalization and\ncontrolled experiments, we demonstrate how the cycles they induce influence a\nmodel's ability to reproduce information. To facilitate reproducibility, we\nprovide our code and experimental details at\nhttps://anonymous.4open.science/r/remember-B0B8/.",
      "tldr_zh": "本文引入自引用因果循环（RECALL）机制，帮助大型语言模型（LLMs）克服“reversal curse”问题，即模型在处理顺序数据时无法正确回忆前置上下文，例如美国国歌的特定歌词。研究发现，通过“cycle tokens”——连接训练数据不同部分的序列——RECALL 能增强模型的回忆能力，将这一现象视为潜在优势而非障碍。作者通过概率形式化和控制实验证明了这些因果循环对信息再现的影响，并公开了代码以支持复现。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.13491v1",
      "published_date": "2025-01-23 09:14:07 UTC",
      "updated_date": "2025-01-23 09:14:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:38:18.382011"
    },
    {
      "arxiv_id": "2501.13484v3",
      "title": "MambaQuant: Quantizing the Mamba Family with Variance Aligned Rotation Methods",
      "title_zh": "MambaQuant：使用方差对齐旋转方法的 Mamba 家族量化",
      "authors": [
        "Zukang Xu",
        "Yuxuan Yue",
        "Xing Hu",
        "Zhihang Yuan",
        "Zixu Jiang",
        "Zhixuan Chen",
        "Jiangyong Yu",
        "Chen Xu",
        "Sifan Zhou",
        "Dawei Yang"
      ],
      "abstract": "Mamba is an efficient sequence model that rivals Transformers and\ndemonstrates significant potential as a foundational architecture for various\ntasks. Quantization is commonly used in neural networks to reduce model size\nand computational latency. However, applying quantization to Mamba remains\nunderexplored, and existing quantization methods, which have been effective for\nCNN and Transformer models, appear inadequate for Mamba models (e.g., Quarot\nsuffers a 21% accuracy drop on Vim-T$^\\dagger$ even under W8A8). We have\npioneered the exploration of this issue and identified several key challenges.\nFirst, significant outliers are present in gate projections, output\nprojections, and matrix multiplications. Second, Mamba's unique parallel scan\nfurther amplifies these outliers, leading to uneven and heavy-tailed data\ndistributions. Third, even with the application of the Hadamard transform, the\nvariance across channels in weights and activations still remains inconsistent.\nTo these ends, we propose MambaQuant, a post-training quantization (PTQ)\nframework consisting of: 1) Karhunen-Loeve Transformation (KLT) enhanced\nrotation, rendering the rotation matrix adaptable to diverse channel\ndistributions. 2) Smooth-Fused rotation, which equalizes channel variances and\ncan merge additional parameters into model weights. Experiments show that\nMambaQuant can quantize both weights and activations into 8-bit with less than\n1% accuracy loss for Mamba-based vision and language tasks. To the best of our\nknowledge, MambaQuant is the first comprehensive PTQ design for the Mamba\nfamily, paving the way for further advancements in its application.",
      "tldr_zh": "该研究针对Mamba序列模型的量化问题，提出MambaQuant框架，以解决现有量化方法在Mamba家族中的不足，如gate projections和matrix multiplications中的异常值以及通道方差不一致等问题。MambaQuant采用后训练量化(PTQ)方法，包括Karhunen-Loeve Transformation (KLT)增强的旋转矩阵适应不同通道分布，以及Smooth-Fused rotation来均衡通道方差并整合额外参数。实验结果显示，在Mamba-based视觉和语言任务中，将权重和激活量化到8-bit仅导致不到1%的准确率损失，这是有史以来首个全面的Mamba量化设计，推动了其在高效应用中的进展。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.13484v3",
      "published_date": "2025-01-23 08:57:33 UTC",
      "updated_date": "2025-03-11 06:49:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:36:36.799913"
    },
    {
      "arxiv_id": "2501.13989v1",
      "title": "FreEformer: Frequency Enhanced Transformer for Multivariate Time Series Forecasting",
      "title_zh": "FreEformer：频率增强 Transformer 用于多变量时间序列预测",
      "authors": [
        "Wenzhen Yue",
        "Yong Liu",
        "Xianghua Ying",
        "Bowei Xing",
        "Ruohao Guo",
        "Ji Shi"
      ],
      "abstract": "This paper presents \\textbf{FreEformer}, a simple yet effective model that\nleverages a \\textbf{Fre}quency \\textbf{E}nhanced Trans\\textbf{former} for\nmultivariate time series forecasting. Our work is based on the assumption that\nthe frequency spectrum provides a global perspective on the composition of\nseries across various frequencies and is highly suitable for robust\nrepresentation learning. Specifically, we first convert time series into the\ncomplex frequency domain using the Discrete Fourier Transform (DFT). The\nTransformer architecture is then applied to the frequency spectra to capture\ncross-variate dependencies, with the real and imaginary parts processed\nindependently. However, we observe that the vanilla attention matrix exhibits a\nlow-rank characteristic, thus limiting representation diversity. This could be\nattributed to the inherent sparsity of the frequency domain and the\nstrong-value-focused nature of Softmax in vanilla attention. To address this,\nwe enhance the vanilla attention mechanism by introducing an additional\nlearnable matrix to the original attention matrix, followed by row-wise L1\nnormalization. Theoretical analysis~demonstrates that this enhanced attention\nmechanism improves both feature diversity and gradient flow. Extensive\nexperiments demonstrate that FreEformer consistently outperforms\nstate-of-the-art models on eighteen real-world benchmarks covering electricity,\ntraffic, weather, healthcare and finance. Notably, the enhanced attention\nmechanism also consistently improves the performance of state-of-the-art\nTransformer-based forecasters.",
      "tldr_zh": "本文提出FreEformer，一种频率增强的Transformer模型，用于多变量时间序列预测。它首先使用Discrete Fourier Transform (DFT)将时间序列转换为频率域，然后在频率谱上应用Transformer架构来捕捉跨变量依赖性，同时分别处理实部和虚部。\n\n为解决原生attention机制的低秩问题，该模型通过向attention矩阵添加一个可学习的矩阵并进行行-wise L1归一化，提高了特征多样性和梯度流动，理论分析也证实了这一改进。\n\n实验结果显示，FreEformer在涵盖电力、交通、天气、医疗和金融的18个真实世界基准上， consistently outperforms 了最先进模型，且增强的attention机制还提升了其他Transformer-based预测器的性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.13989v1",
      "published_date": "2025-01-23 08:53:45 UTC",
      "updated_date": "2025-01-23 08:53:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:36:49.685941"
    },
    {
      "arxiv_id": "2501.13481v1",
      "title": "A Polynomial-Time Algorithm for EFX Orientations of Chores",
      "title_zh": "翻译失败",
      "authors": [
        "Kevin Hsu",
        "Valerie King"
      ],
      "abstract": "This paper addresses the problem of finding EFX orientations of graphs of\nchores, in which each vertex corresponds to an agent, each edge corresponds to\na chore, and a chore has zero marginal utility to an agent if its corresponding\nedge is not incident to the vertex corresponding to the agent. Recently,\nZhou~et~al.~(IJCAI,~2024) analyzed the complexity of deciding whether graphs\ncontaining a mixture of goods and chores admit EFX orientations, and\nconjectured that deciding whether graphs containing only chores admit EFX\norientations is NP-complete. In this paper, we resolve this conjecture by\nexhibiting a polynomial-time algorithm that finds an EFX orientation of a graph\ncontaining only chores if one exists, even if the graph contains self-loops.\nRemarkably, our first result demonstrates a surprising separation between the\ncase of goods and the case of chores, because deciding whether graphs\ncontaining only goods admit EFX orientations of goods was shown to be\nNP-complete by Christodoulou et al.~(EC,~2023). In addition, we show the\nanalogous decision problem for multigraphs to be NP-complete.",
      "tldr_zh": "这篇论文提出了一种多项式时间算法，用于判断并找到仅包含杂务（chores）的图的 EFX orientations，如果存在的话，该算法甚至能处理包含自环的图。该算法解决了 Zhou et al. (IJCAI, 2024) 的猜想，即这种问题原本被认为可能是 NP-complete，但实际上在杂务图中可以高效解决。相比之下，Christodoulou et al. (EC, 2023) 证明了仅包含货物（goods）的图的 EFX orientations 决策问题是 NP-complete，这突显了杂务与货物情况的显著复杂性差异。此外，论文还证明，对于多重图（multigraphs），该决策问题为 NP-complete。",
      "categories": [
        "cs.GT",
        "cs.AI",
        "cs.DM"
      ],
      "primary_category": "cs.GT",
      "comment": "8 pages",
      "pdf_url": "http://arxiv.org/pdf/2501.13481v1",
      "published_date": "2025-01-23 08:53:18 UTC",
      "updated_date": "2025-01-23 08:53:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:37:00.935828"
    },
    {
      "arxiv_id": "2501.13480v1",
      "title": "Adaptive Testing for LLM-Based Applications: A Diversity-based Approach",
      "title_zh": "LLM 基础应用的自适应测试：一种基于多样性的方法",
      "authors": [
        "Juyeon Yoon",
        "Robert Feldt",
        "Shin Yoo"
      ],
      "abstract": "The recent surge of building software systems powered by Large Language\nModels (LLMs) has led to the development of various testing frameworks,\nprimarily focused on treating prompt templates as the unit of testing. Despite\nthe significant costs associated with test input execution and output\nassessment, the curation of optimized test suites is yet overlooked in these\ntools, which calls for tailored test selection or prioritization strategies. In\nthis paper, we show that diversity-based testing techniques, such as Adaptive\nRandom Testing (ART) with appropriate string distance metrics, can be\neffectively applied to the testing of prompt templates. Our proposed adaptive\ntesting approach adjusts the conventional ART process to this context by\nselecting new test inputs based on scores derived from existing test suite and\ntheir labelling results. Our results, obtained using various implementations\nthat explore several string-based distances, confirm that our approach enables\nthe discovery of failures with reduced testing budgets and promotes the\ngeneration of more varied outputs.",
      "tldr_zh": "该研究针对基于Large Language Models (LLMs)的应用测试问题，提出了一种多样性-based的自适应测试方法，以优化提示模板的测试套件。方法调整了传统的Adaptive Random Testing (ART)过程，通过结合适当的string distance metrics，根据现有测试套件及其标记结果来选择新测试输入，从而减少测试预算。实验结果表明，该方法能更高效地发现故障，并促进生成更多样化的输出。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "9 pages",
      "pdf_url": "http://arxiv.org/pdf/2501.13480v1",
      "published_date": "2025-01-23 08:53:12 UTC",
      "updated_date": "2025-01-23 08:53:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:37:12.240971"
    },
    {
      "arxiv_id": "2501.13479v1",
      "title": "Adaptive Few-Shot Learning (AFSL): Tackling Data Scarcity with Stability, Robustness, and Versatility",
      "title_zh": "翻译失败",
      "authors": [
        "Rishabh Agrawal"
      ],
      "abstract": "Few-shot learning (FSL) enables machine learning models to generalize\neffectively with minimal labeled data, making it crucial for data-scarce\ndomains such as healthcare, robotics, and natural language processing. Despite\nits potential, FSL faces challenges including sensitivity to initialization,\ndifficulty in adapting to diverse domains, and vulnerability to noisy datasets.\nTo address these issues, this paper introduces Adaptive Few-Shot Learning\n(AFSL), a framework that integrates advancements in meta-learning, domain\nalignment, noise resilience, and multi-modal integration. AFSL consists of four\nkey modules: a Dynamic Stability Module for performance consistency, a\nContextual Domain Alignment Module for domain adaptation, a Noise-Adaptive\nResilience Module for handling noisy data, and a Multi-Modal Fusion Module for\nintegrating diverse modalities. This work also explores strategies such as\ntask-aware data augmentation, semi-supervised learning, and explainable AI\ntechniques to enhance the applicability and robustness of FSL. AFSL provides\nscalable, reliable, and impactful solutions for real-world, high-stakes\ndomains.",
      "tldr_zh": "本研究提出 Adaptive Few-Shot Learning (AFSL)，一个框架旨在解决 Few-Shot Learning (FSL) 在数据稀缺领域（如医疗、机器人和自然语言处理）的挑战，包括对初始化的敏感性、领域适应困难和噪声数据脆弱性。AFSL 整合了 meta-learning、domain alignment 和多模态整合，包含四个关键模块：Dynamic Stability Module 用于确保性能一致性、Contextual Domain Alignment Module 用于领域适应、Noise-Adaptive Resilience Module 用于处理噪声数据，以及 Multi-Modal Fusion Module 用于整合多种模态。此外，该框架通过任务感知数据增强、半监督学习和 explainable AI 技术，提升了 FSL 的鲁棒性和适用性，为真实世界的高风险领域提供可扩展、可靠的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.13479v1",
      "published_date": "2025-01-23 08:51:49 UTC",
      "updated_date": "2025-01-23 08:51:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:38:31.052251"
    },
    {
      "arxiv_id": "2501.13468v1",
      "title": "Streaming Video Understanding and Multi-round Interaction with Memory-enhanced Knowledge",
      "title_zh": "翻译失败",
      "authors": [
        "Haomiao Xiong",
        "Zongxin Yang",
        "Jiazuo Yu",
        "Yunzhi Zhuge",
        "Lu Zhang",
        "Jiawen Zhu",
        "Huchuan Lu"
      ],
      "abstract": "Recent advances in Large Language Models (LLMs) have enabled the development\nof Video-LLMs, advancing multimodal learning by bridging video data with\nlanguage tasks. However, current video understanding models struggle with\nprocessing long video sequences, supporting multi-turn dialogues, and adapting\nto real-world dynamic scenarios. To address these issues, we propose\nStreamChat, a training-free framework for streaming video reasoning and\nconversational interaction. $\\StreamChat$ leverages a novel hierarchical memory\nsystem to efficiently process and compress video features over extended\nsequences, enabling real-time, multi-turn dialogue. Our framework incorporates\na parallel system scheduling strategy that enhances processing speed and\nreduces latency, ensuring robust performance in real-world applications.\nFurthermore, we introduce StreamBench, a versatile benchmark that evaluates\nstreaming video understanding across diverse media types and interactive\nscenarios, including multi-turn interactions and complex reasoning tasks.\nExtensive evaluations on StreamBench and other public benchmarks demonstrate\nthat StreamChat significantly outperforms existing state-of-the-art models in\nterms of accuracy and response times, confirming its effectiveness for\nstreaming video understanding. Code is available at StreamChat:\nhttps://github.com/hmxiong/StreamChat.",
      "tldr_zh": "本研究针对现有 Video-LLMs 在处理长视频序列、多轮对话和动态场景方面的局限性，提出了一种无训练框架 StreamChat，利用分层内存系统（hierarchical memory system）来高效压缩和处理视频特征，支持实时多轮对话和交互。StreamChat 还采用平行系统调度策略（parallel system scheduling strategy），以提升处理速度并减少延迟。研究者引入了 StreamBench 基准，用于评估流式视频理解的多媒体类型和复杂交互场景。在 StreamBench 和其他基准测试中，StreamChat 在准确性和响应时间上显著优于现有最先进模型，证明了其在流式视频理解中的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to ICLR 2025. Code is available at\n  https://github.com/hmxiong/StreamChat",
      "pdf_url": "http://arxiv.org/pdf/2501.13468v1",
      "published_date": "2025-01-23 08:33:10 UTC",
      "updated_date": "2025-01-23 08:33:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:38:40.953820"
    },
    {
      "arxiv_id": "2501.13988v1",
      "title": "MCRL4OR: Multimodal Contrastive Representation Learning for Off-Road Environmental Perception",
      "title_zh": "翻译失败",
      "authors": [
        "Yi Yang",
        "Zhang Zhang",
        "Liang Wang"
      ],
      "abstract": "Most studies on environmental perception for autonomous vehicles (AVs) focus\non urban traffic environments, where the objects/stuff to be perceived are\nmainly from man-made scenes and scalable datasets with dense annotations can be\nused to train supervised learning models. By contrast, it is hard to densely\nannotate a large-scale off-road driving dataset manually due to the inherently\nunstructured nature of off-road environments. In this paper, we propose a\nMultimodal Contrastive Representation Learning approach for Off-Road\nenvironmental perception, namely MCRL4OR. This approach aims to jointly learn\nthree encoders for processing visual images, locomotion states, and control\nactions by aligning the locomotion states with the fused features of visual\nimages and control actions within a contrastive learning framework. The\ncausation behind this alignment strategy is that the inertial locomotion state\nis the result of taking a certain control action under the current\nlandform/terrain condition perceived by visual sensors. In experiments, we\npre-train the MCRL4OR with a large-scale off-road driving dataset and adopt the\nlearned multimodal representations for various downstream perception tasks in\noff-road driving scenarios. The superior performance in downstream tasks\ndemonstrates the advantages of the pre-trained multimodal representations. The\ncodes can be found in \\url{https://github.com/1uciusy/MCRL4OR}.",
      "tldr_zh": "本论文提出 MCRL4OR，一种 Multimodal Contrastive Representation Learning 方法，用于解决越野环境感知的挑战，特别是数据标注困难的问题。\n该方法通过联合学习视觉图像、运动状态和控制动作的三个编码器，并在对比学习框架中对齐运动状态与视觉图像及控制动作的融合特征，利用运动状态作为视觉感知和控制结果的因果关系。\n实验结果表明，使用大规模越野驾驶数据集预训练后的多模态表示，在各种下游感知任务中表现出优异性能，证明了其在非结构化环境中的有效性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "Github repository: https://github.com/1uciusy/MCRL4OR",
      "pdf_url": "http://arxiv.org/pdf/2501.13988v1",
      "published_date": "2025-01-23 08:27:15 UTC",
      "updated_date": "2025-01-23 08:27:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:38:54.635590"
    },
    {
      "arxiv_id": "2501.13987v1",
      "title": "OstQuant: Refining Large Language Model Quantization with Orthogonal and Scaling Transformations for Better Distribution Fitting",
      "title_zh": "翻译失败",
      "authors": [
        "Xing Hu",
        "Yuan Cheng",
        "Dawei Yang",
        "Zukang Xu",
        "Zhihang Yuan",
        "Jiangyong Yu",
        "Chen Xu",
        "Zhe Jiang",
        "Sifan Zhou"
      ],
      "abstract": "Post-training quantization (PTQ) has emerged as a widely adopted technique\nfor compressing and accelerating Large Language Models (LLMs). The major\nchallenge in LLM quantization is that uneven and heavy-tailed data\ndistributions can expand the quantization range, thereby reducing bit precision\nfor most values. Recent methods attempt to eliminate outliers and balance\ninter-channel differences by employing linear transformations; however, they\nremain heuristic and are often overlook optimizing the data distribution across\nthe entire quantization space.In this paper, we introduce Quantization Space\nUtilization Rate (QSUR), a novel metric that effectively assesses the\nquantizability of transformed data by measuring the space utilization of the\ndata in the quantization space. We complement QSUR with mathematical\nderivations that examine the effects and limitations of various\ntransformations, guiding our development of Orthogonal and Scaling\nTransformation-based Quantization (OSTQuant). OSQuant employs a learnable\nequivalent transformation, consisting of an orthogonal transformation and a\nscaling transformation, to optimize the distributions of weights and\nactivations across the entire quantization space. Futhermore, we propose the\nKL-Top loss function, designed to mitigate noise during optimization while\nretaining richer semantic information within the limited calibration data\nimposed by PTQ. OSTQuant outperforms existing work on various LLMs and\nbenchmarks. In the W4-only setting, it retains 99.5\\% of the floating-point\naccuracy. In the more challenging W4A4KV4 configuration, OSTQuant reduces the\nperformance gap by 32\\% on the LLaMA-3-8B model compared to state-of-the-art\nmethods.\n\\href{https://github.com/BrotherHappy/OSTQuant}{https://github.com/BrotherHappy/OSTQuant}.",
      "tldr_zh": "该论文针对大型语言模型（LLMs）的后训练量化（PTQ）问题，提出 OstQuant 方法，通过正交变换和缩放变换优化权重和激活的分布，以更好地拟合不均数据分布并提高量化空间利用率。论文引入 Quantization Space Utilization Rate (QSUR) 指标来评估数据量化性，并设计 KL-Top 损失函数以减少优化过程中的噪声，同时保留语义信息。实验结果显示，OstQuant 在各种 LLMs 和基准上超越现有方法，在 W4-only 设置中保留 99.5% 的浮点精度，并在 W4A4KV4 配置中将 LLaMA-3-8B 模型的性能差距减少 32%。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "10 Pages",
      "pdf_url": "http://arxiv.org/pdf/2501.13987v1",
      "published_date": "2025-01-23 08:24:25 UTC",
      "updated_date": "2025-01-23 08:24:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:39:06.701115"
    },
    {
      "arxiv_id": "2501.13986v4",
      "title": "An Efficient Sparse Kernel Generator for O(3)-Equivariant Deep Networks",
      "title_zh": "高效的 O(3)-等变深度网络稀疏核生成器",
      "authors": [
        "Vivek Bharadwaj",
        "Austin Glover",
        "Aydin Buluc",
        "James Demmel"
      ],
      "abstract": "Rotation equivariant graph neural networks, i.e. networks designed to\nguarantee certain geometric relations between their inputs and outputs, yield\nstate of the art performance on spatial deep learning tasks. They exhibit high\ndata efficiency during training and significantly reduced inference time for\ninteratomic potential calculations compared to classical approaches. Key to\nthese models is the Clebsch-Gordon (CG) tensor product, a kernel that contracts\ntwo dense feature vectors with a highly-structured sparse tensor to produce a\ndense output vector. The operation, which may be repeated millions of times for\ntypical equivariant models, is a costly and inefficient bottleneck. We\nintroduce a GPU sparse kernel generator for the CG tensor product that provides\nsignificant speedups over the best existing open and closed-source\nimplementations. Our implementation achieves high performance by carefully\nmanaging the limited GPU shared memory through static analysis at model\ncompile-time, minimizing reads and writes to global memory. We break the tensor\nproduct into a series of smaller kernels with operands that fit entirely into\nregisters, enabling us to emit long arithmetic instruction streams that\nmaximize instruction-level parallelism. By fusing the CG tensor product with a\nsubsequent graph convolution, we reduce both intermediate storage and global\nmemory traffic over naive approaches that duplicate input data. We also provide\noptimized kernels for the gradient of the CG tensor product and a novel\nidentity for the higher partial derivatives required to predict interatomic\nforces. Our kernels offer up to 1.3x speedup over NVIDIA's closed-source\ncuEquivariance package, as well as 10x speedup over the widely-used e3nn\npackage. In FP64 precision, we offer up to 6.2x inference-time speedup for the\nMACE chemistry foundation model over the original unoptimized version.",
      "tldr_zh": "该论文提出了一种高效的稀疏核生成器，用于优化 O(3)-Equivariant 深度网络中的 Clebsch-Gordon (CG) 张量乘积操作，以解决其计算瓶颈问题。方法包括通过静态分析管理 GPU 共享内存、将张量乘积分解为小内核以最大化指令级并行性，并融合 CG 操作与后续图卷积，减少全局内存访问和中间存储。实验结果显示，该生成器比 NVIDIA 的 cuEquivariance 快 1.3 倍、比 e3nn 快 10 倍，并在 FP64 精度下为 MACE 化学基础模型提供 6.2 倍的推理时间加速，从而提升了旋转等变图神经网络的性能和效率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "To appear in the Proceedings of the 2025 SIAM Conference on Applied\n  and Computational Discrete Algorithms. 15 pages, 10 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2501.13986v4",
      "published_date": "2025-01-23 08:20:47 UTC",
      "updated_date": "2025-05-08 23:11:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:39:19.321899"
    },
    {
      "arxiv_id": "2501.13457v1",
      "title": "Zero-Shot Trajectory Planning for Signal Temporal Logic Tasks",
      "title_zh": "针对信号时序逻辑任务的零样本轨",
      "authors": [
        "Ruijia Liu",
        "Ancheng Hou",
        "Xiao Yu",
        "Xiang Yin"
      ],
      "abstract": "Signal Temporal Logic (STL) is a powerful specification language for\ndescribing complex temporal behaviors of continuous signals, making it\nwell-suited for high-level robotic task descriptions. However, generating\nexecutable plans for STL tasks is challenging, as it requires consideration of\nthe coupling between the task specification and the system dynamics. Existing\napproaches either follow a model-based setting that explicitly requires\nknowledge of the system dynamics or adopt a task-oriented data-driven approach\nto learn plans for specific tasks. In this work, we investigate the problem of\ngenerating executable STL plans for systems whose dynamics are unknown a\npriori. We propose a new planning framework that uses only task-agnostic data\nduring the offline training stage, enabling zero-shot generalization to new STL\ntasks. Our framework is hierarchical, involving: (i) decomposing the STL task\ninto a set of progress and time constraints, (ii) searching for time-aware\nwaypoints guided by task-agnostic data, and (iii) generating trajectories using\na pre-trained safe diffusion model. Simulation results demonstrate the\neffectiveness of our method indeed in achieving zero-shot generalization to\nvarious STL tasks.",
      "tldr_zh": "本文提出了一种零-shot 轨迹规划框架，用于 Signal Temporal Logic (STL) 任务，旨在在系统动态未知的情况下生成可执行计划，从而克服现有方法对动态知识或特定任务数据的依赖。框架采用分层设计，包括将 STL 任务分解成进度和时间约束、使用任务无关数据引导时间感知路径点搜索，以及通过预训练的安全扩散模型生成轨迹。模拟结果证明，该方法实现了对各种 STL 任务的零-shot 泛化，展示了其在机器人任务规划中的有效性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "submitted",
      "pdf_url": "http://arxiv.org/pdf/2501.13457v1",
      "published_date": "2025-01-23 08:15:52 UTC",
      "updated_date": "2025-01-23 08:15:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:39:30.002746"
    },
    {
      "arxiv_id": "2501.13456v4",
      "title": "KAA: Kolmogorov-Arnold Attention for Enhancing Attentive Graph Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Taoran Fang",
        "Tianhong Gao",
        "Chunping Wang",
        "Yihao Shang",
        "Wei Chow",
        "Lei Chen",
        "Yang Yang"
      ],
      "abstract": "Graph neural networks (GNNs) with attention mechanisms, often referred to as\nattentive GNNs, have emerged as a prominent paradigm in advanced GNN models in\nrecent years. However, our understanding of the critical process of scoring\nneighbor nodes remains limited, leading to the underperformance of many\nexisting attentive GNNs. In this paper, we unify the scoring functions of\ncurrent attentive GNNs and propose Kolmogorov-Arnold Attention (KAA), which\nintegrates the Kolmogorov-Arnold Network (KAN) architecture into the scoring\nprocess. KAA enhances the performance of scoring functions across the board and\ncan be applied to nearly all existing attentive GNNs. To compare the expressive\npower of KAA with other scoring functions, we introduce Maximum Ranking\nDistance (MRD) to quantitatively estimate their upper bounds in ranking errors\nfor node importance. Our analysis reveals that, under limited parameters and\nconstraints on width and depth, both linear transformation-based and MLP-based\nscoring functions exhibit finite expressive power. In contrast, our proposed\nKAA, even with a single-layer KAN parameterized by zero-order B-spline\nfunctions, demonstrates nearly infinite expressive power. Extensive experiments\non both node-level and graph-level tasks using various backbone models show\nthat KAA-enhanced scoring functions consistently outperform their original\ncounterparts, achieving performance improvements of over 20% in some cases.",
      "tldr_zh": "这篇论文针对图神经网络 (GNNs) 中的注意力机制问题，提出 Kolmogorov-Arnold Attention (KAA) 来增强评分函数的性能，通过整合 Kolmogorov-Arnold Network (KAN) 架构来统一现有注意力 GNNs 的评分过程。作者引入 Maximum Ranking Distance (MRD) 作为量化工具，分析显示 KAA 即使在单层零阶 B-spline 参数化下也具有近乎无限的表达能力，而传统线性变换和 MLP 基于的函数则受限于有限参数。实验在节点级和图级任务上证明，KAA 显著提升了基线模型的表现，在某些情况下性能改善超过 20%。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.13456v4",
      "published_date": "2025-01-23 08:14:55 UTC",
      "updated_date": "2025-03-11 08:59:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:39:42.124622"
    },
    {
      "arxiv_id": "2501.13448v1",
      "title": "BMG-Q: Localized Bipartite Match Graph Attention Q-Learning for Ride-Pooling Order Dispatch",
      "title_zh": "翻译失败",
      "authors": [
        "Yulong Hu",
        "Siyuan Feng",
        "Sen Li"
      ],
      "abstract": "This paper introduces Localized Bipartite Match Graph Attention Q-Learning\n(BMG-Q), a novel Multi-Agent Reinforcement Learning (MARL) algorithm framework\ntailored for ride-pooling order dispatch. BMG-Q advances ride-pooling\ndecision-making process with the localized bipartite match graph underlying the\nMarkov Decision Process, enabling the development of novel Graph Attention\nDouble Deep Q Network (GATDDQN) as the MARL backbone to capture the dynamic\ninteractions among ride-pooling vehicles in fleet. Our approach enriches the\nstate information for each agent with GATDDQN by leveraging a localized\nbipartite interdependence graph and enables a centralized global coordinator to\noptimize order matching and agent behavior using Integer Linear Programming\n(ILP). Enhanced by gradient clipping and localized graph sampling, our GATDDQN\nimproves scalability and robustness. Furthermore, the inclusion of a posterior\nscore function in the ILP captures the online exploration-exploitation\ntrade-off and reduces the potential overestimation bias of agents, thereby\nelevating the quality of the derived solutions. Through extensive experiments\nand validation, BMG-Q has demonstrated superior performance in both training\nand operations for thousands of vehicle agents, outperforming benchmark\nreinforcement learning frameworks by around 10% in accumulative rewards and\nshowing a significant reduction in overestimation bias by over 50%.\nAdditionally, it maintains robustness amidst task variations and fleet size\nchanges, establishing BMG-Q as an effective, scalable, and robust framework for\nadvancing ride-pooling order dispatch operations.",
      "tldr_zh": "本文提出 BMG-Q，一种针对拼车订单调度的多智能体强化学习 (MARL) 算法框架，利用本地化二分匹配图作为马尔科夫决策过程基础，并开发 Graph Attention Double Deep Q Network (GATDDQN) 来捕捉车辆间的动态互动。该框架通过集中的整数线性规划 (ILP) 优化订单匹配和代理行为，并结合梯度剪裁、本地化图采样及后验分数函数，减少过度估计偏差并提升可伸缩性。实验结果表明，BMG-Q 在数千辆车辆代理的训练和操作中，比基准框架提高约 10% 累计奖励，并将过度估计偏差降低超过 50%，在任务变化和车队规模波动中保持鲁棒性。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.ET",
        "cs.LG"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.13448v1",
      "published_date": "2025-01-23 08:01:24 UTC",
      "updated_date": "2025-01-23 08:01:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:39:54.686862"
    },
    {
      "arxiv_id": "2501.13985v1",
      "title": "Pilot: Building the Federated Multimodal Instruction Tuning Framework",
      "title_zh": "Pilot：构建联邦多模态指令微调框架",
      "authors": [
        "Baochen Xiong",
        "Xiaoshan Yang",
        "Yaguang Song",
        "Yaowei Wang",
        "Changsheng Xu"
      ],
      "abstract": "In this paper, we explore a novel federated multimodal instruction tuning\ntask(FedMIT), which is significant for collaboratively fine-tuning MLLMs on\ndifferent types of multimodal instruction data on distributed devices. To solve\nthe new task, we propose a federated multimodal instruction tuning\nframework(Pilot). Our framework integrates two stages of \"adapter on adapter\"\ninto the connector of the vision encoder and the LLM. In stage 1, we extract\ntask-specific features and client-specific features from visual information. In\nstage 2, we build the cross-task Mixture-of-Adapters(CT-MoA) module to perform\ncross-task interaction. Each client can not only capture personalized\ninformation of local data and learn task-related multimodal information, but\nalso learn general knowledge from other tasks. In addition, we introduce an\nadaptive parameter aggregation strategy for text training parameters, which\noptimizes parameter aggregation by calculating weights based on the euclidean\ndistance between parameters, so that parameter aggregation can benefit from\npositive effects to the greatest extent while effectively reducing negative\neffects. Our framework can collaboratively exploit distributed data from\ndifferent local clients to learn cross-task knowledge without being affected by\nthe task heterogeneity during instruction tuning. The effectiveness of our\nmethod is verified in two different cross-task scenarios.",
      "tldr_zh": "本研究探讨了Federated Multimodal Instruction Tuning (FedMIT)任务，这是一种在分布式设备上协作微调多模态大型语言模型(MLLMs)的框架。论文提出Pilot框架，通过“adapter on adapter”结构分为两个阶段：阶段1提取任务特定和客户端特定视觉特征，阶段2构建跨任务Mixture-of-Adapters(CT-MoA)模块，实现跨任务交互和个性化信息学习。同时，引入自适应参数聚合策略，基于参数间的欧氏距离计算权重，优化聚合过程以减少负面影响。在两个跨任务场景中，框架证明了其有效性，能在任务异质性下协作利用分布式数据学习跨任务知识。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.13985v1",
      "published_date": "2025-01-23 07:49:24 UTC",
      "updated_date": "2025-01-23 07:49:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:40:06.008835"
    },
    {
      "arxiv_id": "2501.13439v1",
      "title": "One-cycle Structured Pruning with Stability Driven Structure Search",
      "title_zh": "翻译失败",
      "authors": [
        "Deepak Ghimire",
        "Dayoung Kil",
        "Seonghwan Jeong",
        "Jaesik Park",
        "Seong-heum Kim"
      ],
      "abstract": "Existing structured pruning typically involves multi-stage training\nprocedures that often demand heavy computation. Pruning at initialization,\nwhich aims to address this limitation, reduces training costs but struggles\nwith performance. To address these challenges, we propose an efficient\nframework for one-cycle structured pruning without compromising model\nperformance. In this approach, we integrate pre-training, pruning, and\nfine-tuning into a single training cycle, referred to as the `one cycle\napproach'. The core idea is to search for the optimal sub-network during the\nearly stages of network training, guided by norm-based group saliency criteria\nand structured sparsity regularization. We introduce a novel pruning indicator\nthat determines the stable pruning epoch by assessing the similarity between\nevolving pruning sub-networks across consecutive training epochs. Also, group\nsparsity regularization helps to accelerate the pruning process and results in\nspeeding up the entire process. Extensive experiments on datasets, including\nCIFAR-10/100, and ImageNet, using VGGNet, ResNet, MobileNet, and ViT\narchitectures, demonstrate that our method achieves state-of-the-art accuracy\nwhile being one of the most efficient pruning frameworks in terms of training\ntime. The source code will be made publicly available.",
      "tldr_zh": "本研究提出了一种高效的 one-cycle structured pruning 框架，通过 stability driven structure search 整合预训练、剪枝和微调到一个训练周期，解决现有 structured pruning 计算密集的问题，同时避免剪枝于初始化的性能损失。核心方法包括在网络训练早期使用 norm-based group saliency criteria 和 structured sparsity regularization 搜索最优子网络，并引入一个新颖的 pruning indicator 来评估连续训练周期中子网络的相似性，以确定稳定的剪枝时机，从而加速整个过程。在 CIFAR-10/100 和 ImageNet 数据集上，使用 VGGNet、ResNet、MobileNet 和 ViT 架构的实验显示，该框架达到最先进准确率，同时显著减少训练时间，源代码将公开。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "12 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.13439v1",
      "published_date": "2025-01-23 07:46:48 UTC",
      "updated_date": "2025-01-23 07:46:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:40:17.806790"
    },
    {
      "arxiv_id": "2501.13428v3",
      "title": "Softplus Attention with Re-weighting Boosts Length Extrapolation in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Bo Gao",
        "Michael W. Spratling"
      ],
      "abstract": "Large language models have achieved remarkable success in recent years,\nprimarily due to the implementation of self-attention mechanisms. However,\ntraditional Softmax attention suffers from numerical instability and reduced\nperformance as the length of inference tokens increases. This paper addresses\nthese issues by decomposing the Softmax operation into a non-linear\ntransformation and the $l_1$-norm. We identify the latter as essential for\nmaintaining model performance. By replacing the non-linear transformation with\nthe Softplus activation function and introducing a dynamic scale factor for\ndifferent token lengths based on invariance entropy, we create a novel\nattention mechanism with performance better than conventional Softmax attention\nacross various inference lengths. To further improve the length extrapolation\nability of the proposed attention mechanism, we introduce a novel re-weighting\nmechanism that amplifies significant attention weights while diminishing weaker\nones, enabling the model to concentrate more effectively on relevant tokens.\nWhen combined with our proposed attention mechanism, this approach maintains\nnearly constant validation loss even at 16$\\times$ the training token length,\nensures numerical stability, and achieves superior results on downstream\nbenchmarks.",
      "tldr_zh": "本文提出一种改进Large Language Models中Softmax attention机制的新方法，以解决其数值不稳定性和长序列性能下降问题。具体而言，通过将Softmax分解为非线性变换和l1-norm，并用Softplus激活函数替换非线性部分，同时引入基于不变熵的动态缩放因子，该新注意力机制在不同序列长度下表现出色。进一步，作者添加了一个重权重机制，用于放大重要注意力权重并减小弱权重，从而显著提升模型的长度外推能力。实验结果显示，该组合方法在16倍训练长度下保持验证损失几乎不变，并在下游基准测试中实现优越性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "14 pages and 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.13428v3",
      "published_date": "2025-01-23 07:21:08 UTC",
      "updated_date": "2025-05-12 03:16:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:40:29.759361"
    },
    {
      "arxiv_id": "2501.13984v1",
      "title": "Comprehensive Modeling and Question Answering of Cancer Clinical Practice Guidelines using LLMs",
      "title_zh": "使用 LLMs",
      "authors": [
        "Bhumika Gupta",
        "Pralaypati Ta",
        "Keerthi Ram",
        "Mohanasankar Sivaprakasam"
      ],
      "abstract": "The updated recommendations on diagnostic procedures and treatment pathways\nfor a medical condition are documented as graphical flows in Clinical Practice\nGuidelines (CPGs). For effective use of the CPGs in helping medical\nprofessionals in the treatment decision process, it is necessary to fully\ncapture the guideline knowledge, particularly the contexts and their\nrelationships in the graph. While several existing works have utilized these\nguidelines to create rule bases for Clinical Decision Support Systems, limited\nwork has been done toward directly capturing the full medical knowledge\ncontained in CPGs. This work proposes an approach to create a contextually\nenriched, faithful digital representation of National Comprehensive Cancer\nNetwork (NCCN) Cancer CPGs in the form of graphs using automated extraction and\nnode & relationship classification. We also implement semantic enrichment of\nthe model by using Large Language Models (LLMs) for node classification,\nachieving an accuracy of 80.86% and 88.47% with zero-shot learning and few-shot\nlearning, respectively. Additionally, we introduce a methodology for answering\nnatural language questions with constraints to guideline text by leveraging\nLLMs to extract the relevant subgraph from the guideline knowledge base. By\ngenerating natural language answers based on subgraph paths and semantic\ninformation, we mitigate the risk of incorrect answers and hallucination\nassociated with LLMs, ensuring factual accuracy in medical domain Question\nAnswering.",
      "tldr_zh": "本文提出了一种方法，使用自动化提取和节点及关系分类来创建National Comprehensive Cancer Network (NCCN)癌症临床实践指南(CPGs)的上下文丰富图表示。利用Large Language Models (LLMs)进行节点分类，实现了80.86%的zero-shot learning和88.47%的few-shot learning准确率。研究还引入了基于LLMs提取相关子图的问答机制，通过生成基于子图路径的自然语言答案，减少了LLMs的幻觉风险，确保医疗领域问题回答的准确性和事实性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.13984v1",
      "published_date": "2025-01-23 07:06:26 UTC",
      "updated_date": "2025-01-23 07:06:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:40:41.257851"
    },
    {
      "arxiv_id": "2501.13983v4",
      "title": "AdEval: Alignment-based Dynamic Evaluation to Mitigate Data Contamination in Large Language Models",
      "title_zh": "AdEval：基于对齐的动态评估以缓解大语言模型中的数据污染",
      "authors": [
        "Yang Fan"
      ],
      "abstract": "As Large Language Models (LLMs) are pretrained on massive-scale corpora, the\nissue of data contamination has become increasingly severe, leading to\npotential overestimation of model performance during evaluation. To address\nthis, we propose AdEval (Alignment-based Dynamic Evaluation), a dynamic data\nevaluation method aimed at mitigating the impact of data contamination on\nevaluation reliability. Experimental results on multiple datasets demonstrate\nthat AdEval effectively reduces the impact of data contamination on evaluation\noutcomes, enhancing both the fairness and reliability of the evaluation\nprocess.",
      "tldr_zh": "本研究针对 Large Language Models (LLMs) 在海量语料预训练中面临的数据污染问题，提出了一种名为 AdEval 的动态评估方法，以基于对齐（Alignment-based）的策略缓解评估结果的潜在高估。AdEval 通过动态数据评估机制，确保评估过程更可靠和公平，减少数据污染的影响。实验在多个数据集上验证了其有效性，提高了评估的公平性和可靠性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "There are serious academic problems in this paper, such as data\n  falsification and plagiarism in the method of the paper",
      "pdf_url": "http://arxiv.org/pdf/2501.13983v4",
      "published_date": "2025-01-23 06:57:24 UTC",
      "updated_date": "2025-03-07 09:02:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:40:52.447749"
    },
    {
      "arxiv_id": "2501.16375v1",
      "title": "On Storage Neural Network Augmented Approximate Nearest Neighbor Search",
      "title_zh": "翻译失败",
      "authors": [
        "Taiga Ikeda",
        "Daisuke Miyashita",
        "Jun Deguchi"
      ],
      "abstract": "Large-scale approximate nearest neighbor search (ANN) has been gaining\nattention along with the latest machine learning researches employing ANNs. If\nthe data is too large to fit in memory, it is necessary to search for the most\nsimilar vectors to a given query vector from the data stored in storage\ndevices, not from that in memory. The storage device such as NAND flash memory\nhas larger capacity than the memory device such as DRAM, but they also have\nlarger latency to read data. Therefore, ANN methods for storage require\ncompletely different approaches from conventional in-memory ANN methods. Since\nthe approximation that the time required for search is determined only by the\namount of data fetched from storage holds under reasonable assumptions, our\ngoal is to minimize it while maximizing recall. For partitioning-based ANNs,\nvectors are partitioned into clusters in the index building phase. In the\nsearch phase, some of the clusters are chosen, the vectors in the chosen\nclusters are fetched from storage, and the nearest vector is retrieved from the\nfetched vectors. Thus, the key point is to accurately select the clusters\ncontaining the ground truth nearest neighbor vectors. We accomplish this by\nproposing a method to predict the correct clusters by means of a neural network\nthat is gradually refined by alternating supervised learning and duplicated\ncluster assignment. Compared to state-of-the-art SPANN and an exhaustive method\nusing k-means clustering and linear search, the proposed method achieves 90%\nrecall on SIFT1M with 80% and 58% less data fetched from storage, respectively.",
      "tldr_zh": "这篇论文探讨了大规模 Approximate Nearest Neighbor Search (ANN) 在存储设备（如 NAND 闪存）上的挑战，针对数据过大无法放入内存的情况，提出了一种神经网络增强的方法，以最小化从存储设备获取的数据量同时最大化召回率。方法通过在索引构建阶段分区向量并使用神经网络预测包含真实最近邻向量的集群，并通过交替监督学习和重复集群分配逐步优化该网络。实验结果显示，与 SPANN 和基于 k-means 的穷举方法相比，该方法在 SIFT1M 数据集上实现了 90% 召回率，同时分别减少了 80% 和 58% 的数据获取量。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.LG",
      "comment": "11 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.16375v1",
      "published_date": "2025-01-23 06:56:18 UTC",
      "updated_date": "2025-01-23 06:56:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:41:06.550901"
    },
    {
      "arxiv_id": "2501.13418v1",
      "title": "Rethinking the Sample Relations for Few-Shot Classification",
      "title_zh": "重新审视少样本分类中的样本关系",
      "authors": [
        "Guowei Yin",
        "Sheng Huang",
        "Luwen Huangfu",
        "Yi Zhang",
        "Xiaohong Zhang"
      ],
      "abstract": "Feature quality is paramount for classification performance, particularly in\nfew-shot scenarios. Contrastive learning, a widely adopted technique for\nenhancing feature quality, leverages sample relations to extract intrinsic\nfeatures that capture semantic information and has achieved remarkable success\nin Few-Shot Learning (FSL). Nevertheless, current few-shot contrastive learning\napproaches often overlook the semantic similarity discrepancies at different\ngranularities when employing the same modeling approach for different sample\nrelations, which limits the potential of few-shot contrastive learning. In this\npaper, we introduce a straightforward yet effective contrastive learning\napproach, Multi-Grained Relation Contrastive Learning (MGRCL), as a\npre-training feature learning model to boost few-shot learning by meticulously\nmodeling sample relations at different granularities. MGRCL categorizes sample\nrelations into three types: intra-sample relation of the same sample under\ndifferent transformations, intra-class relation of homogenous samples, and\ninter-class relation of inhomogeneous samples. In MGRCL, we design\nTransformation Consistency Learning (TCL) to ensure the rigorous semantic\nconsistency of a sample under different transformations by aligning predictions\nof input pairs. Furthermore, to preserve discriminative information, we employ\nClass Contrastive Learning (CCL) to ensure that a sample is always closer to\nits homogenous samples than its inhomogeneous ones, as homogenous samples share\nsimilar semantic content while inhomogeneous samples have different semantic\ncontent. Our method is assessed across four popular FSL benchmarks, showing\nthat such a simple pre-training feature learning method surpasses a majority of\nleading FSL methods. Moreover, our method can be incorporated into other FSL\nmethods as the pre-trained model and help them obtain significant performance\ngains.",
      "tldr_zh": "本文重新审视了少样本学习（Few-Shot Learning, FSL）中样本关系的建模问题，提出了一种多粒度关系对比学习方法（Multi-Grained Relation Contrastive Learning, MGRCL），通过区分 intra-sample、intra-class 和 inter-class 关系来提升特征质量。MGRCL 包括变换一致性学习（Transformation Consistency Learning, TCL）以确保样本在不同变换下的语义一致性，以及类别对比学习（Class Contrastive Learning, CCL）以增强样本间的判别性。在四个流行 FSL 基准上，该方法超越了多数领先方法，并可作为预训练模型与其他 FSL 方法结合以显著提升性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "32 pages",
      "pdf_url": "http://arxiv.org/pdf/2501.13418v1",
      "published_date": "2025-01-23 06:45:17 UTC",
      "updated_date": "2025-01-23 06:45:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:41:18.767191"
    },
    {
      "arxiv_id": "2501.13416v2",
      "title": "M3PT: A Transformer for Multimodal, Multi-Party Social Signal Prediction with Person-aware Blockwise Attention",
      "title_zh": "翻译失败",
      "authors": [
        "Yiming Tang",
        "Abrar Anwar",
        "Jesse Thomason"
      ],
      "abstract": "Understanding social signals in multi-party conversations is important for\nhuman-robot interaction and artificial social intelligence. Social signals\ninclude body pose, head pose, speech, and context-specific activities like\nacquiring and taking bites of food when dining. Past work in multi-party\ninteraction tends to build task-specific models for predicting social signals.\nIn this work, we address the challenge of predicting multimodal social signals\nin multi-party settings in a single model. We introduce M3PT, a causal\ntransformer architecture with modality and temporal blockwise attention masking\nto simultaneously process multiple social cues across multiple participants and\ntheir temporal interactions. We train and evaluate M3PT on the Human-Human\nCommensality Dataset (HHCD), and demonstrate that using multiple modalities\nimproves bite timing and speaking status prediction. Source code:\nhttps://github.com/AbrarAnwar/masked-social-signals/.",
      "tldr_zh": "该研究提出 M3PT，一种基于 Transformer 的模型，用于多模态、多方社会信号预测，旨在处理包括体姿、头姿、语音和特定活动（如进食）的社会线索。M3PT 采用因果 Transformer 架构，结合模态和时间块状注意力掩码（blockwise attention masking）以及 person-aware 功能，来同时处理多个参与者和他们的时间交互。实验在 Human-Human Commensality Dataset (HHCD) 上进行，结果显示，使用多模态输入显著改善了咬合时机（bite timing）和说话状态（speaking status）的预测准确性。该模型为单模型处理多方互动提供了一个统一的框架，支持人-机器人互动和人工社会智能的应用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.13416v2",
      "published_date": "2025-01-23 06:42:28 UTC",
      "updated_date": "2025-02-03 03:14:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:41:30.368864"
    },
    {
      "arxiv_id": "2501.13412v1",
      "title": "Load and Renewable Energy Forecasting Using Deep Learning for Grid Stability",
      "title_zh": "翻译失败",
      "authors": [
        "Kamal Sarkar"
      ],
      "abstract": "As the energy landscape changes quickly, grid operators face several\nchallenges, especially when integrating renewable energy sources with the grid.\nThe most important challenge is to balance supply and demand because the solar\nand wind energy are highly unpredictable. When dealing with such uncertainty,\ntrustworthy short-term load and renewable energy forecasting can help stabilize\nthe grid, maximize energy storage, and guarantee the effective use of renewable\nresources. Physical models and statistical techniques were the previous\napproaches employed for this kind of forecasting tasks. In forecasting\nrenewable energy, machine learning and deep learning techniques have recently\ndemonstrated encouraging results. More specifically, the deep learning\ntechniques like CNN and LSTM and the conventional machine learning techniques\nlike regression that are mostly utilized for load and renewable energy\nforecasting tasks. In this article, we will focus mainly on CNN and LSTM-based\nforecasting methods.",
      "tldr_zh": "这篇论文探讨了使用深度学习技术预测负载和可再生能源，以应对电网稳定性面临的挑战，特别是太阳能和风能的不确定性。作者重点分析了CNN和LSTM等深度学习方法，并与传统物理模型和统计技术进行比较，强调这些方法在短期预测中的潜力。研究结果显示，此类技术有助于平衡供需、优化能源存储，并提升可再生资源的利用效率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "I.2.6"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.13412v1",
      "published_date": "2025-01-23 06:33:33 UTC",
      "updated_date": "2025-01-23 06:33:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:41:40.738710"
    },
    {
      "arxiv_id": "2501.16374v2",
      "title": "SAFR: Neuron Redistribution for Interpretability",
      "title_zh": "翻译失败",
      "authors": [
        "Ruidi Chang",
        "Chunyuan Deng",
        "Hanjie Chen"
      ],
      "abstract": "Superposition refers to encoding representations of multiple features within\na single neuron, which is common in deep neural networks. This property allows\nneurons to combine and represent multiple features, enabling the model to\ncapture intricate information and handle complex tasks. Despite promising\nperformance, the model's interpretability has been diminished. This paper\npresents a novel approach to enhance model interpretability by regularizing\nfeature superposition. We introduce SAFR, which simply applies regularizations\nto the loss function to promote monosemantic representations for important\ntokens while encouraging polysemanticity for correlated token pairs, where\nimportant tokens and correlated token pairs are identified via VMASK and\nattention weights respectively. We evaluate SAFR with a transformer model on\ntwo classification tasks. Experiments demonstrate the effectiveness of SAFR in\nimproving model interpretability without compromising prediction performance.\nBesides, SAFR provides explanations by visualizing the neuron allocation within\nthe intermediate layers.",
      "tldr_zh": "本文提出SAFR方法，通过在损失函数中添加正则化来解决深度神经网络中Superposition现象导致的可解释性问题。SAFR针对重要标记（通过VMASK识别）促进单义表示（monosemantic representations），并鼓励相关标记对（通过注意力权重识别）保持多义性（polysemanticity）。实验在transformer模型上的两个分类任务中证明，SAFR显著提高了模型的可解释性，同时不影响预测性能，并通过可视化中间层的神经元分配提供解释。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.16374v2",
      "published_date": "2025-01-23 06:20:33 UTC",
      "updated_date": "2025-02-11 00:26:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:41:53.472266"
    },
    {
      "arxiv_id": "2501.13400v2",
      "title": "YOLOv8 to YOLO11: A Comprehensive Architecture In-depth Comparative Review",
      "title_zh": "YOLOv8 到 YOLO11：全面架构深入比较综述",
      "authors": [
        "Priyanto Hidayatullah",
        "Nurjannah Syakrani",
        "Muhammad Rizqi Sholahuddin",
        "Trisna Gelar",
        "Refdinal Tubagus"
      ],
      "abstract": "In the field of deep learning-based computer vision, YOLO is revolutionary.\nWith respect to deep learning models, YOLO is also the one that is evolving the\nmost rapidly. Unfortunately, not every YOLO model possesses scholarly\npublications. Moreover, there exists a YOLO model that lacks a publicly\naccessible official architectural diagram. Naturally, this engenders\nchallenges, such as complicating the understanding of how the model operates in\npractice. Furthermore, the review articles that are presently available do not\ndelve into the specifics of each model. The objective of this study is to\npresent a comprehensive and in-depth architecture comparison of the four most\nrecent YOLO models, specifically YOLOv8 through YOLO11, thereby enabling\nreaders to quickly grasp not only how each model functions, but also the\ndistinctions between them. To analyze each YOLO version's architecture, we\nmeticulously examined the relevant academic papers, documentation, and\nscrutinized the source code. The analysis reveals that while each version of\nYOLO has improvements in architecture and feature extraction, certain blocks\nremain unchanged. The lack of scholarly publications and official diagrams\npresents challenges for understanding the model's functionality and future\nenhancement. Future developers are encouraged to provide these resources.",
      "tldr_zh": "这篇论文对YOLOv8到YOLO11的四个最新版本进行了全面深入的架构比较，旨在帮助读者快速理解每个模型的功能、差异以及整体运作原理。作者通过仔细审阅相关学术论文、文档和源代码，分析了这些YOLO模型在架构和特征提取方面的改进，同时发现某些核心块保持不变。论文强调，缺少学术出版物和官方架构图会增加理解难度，并建议未来开发者提供这些资源，以促进模型的进一步优化。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.13400v2",
      "published_date": "2025-01-23 05:57:13 UTC",
      "updated_date": "2025-04-08 06:11:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:42:06.180046"
    },
    {
      "arxiv_id": "2501.13394v2",
      "title": "Concurrent Learning with Aggregated States via Randomized Least Squares Value Iteration",
      "title_zh": "翻译失败",
      "authors": [
        "Yan Chen",
        "Qinxun Bai",
        "Yiteng Zhang",
        "Shi Dong",
        "Maria Dimakopoulou",
        "Qi Sun",
        "Zhengyuan Zhou"
      ],
      "abstract": "Designing learning agents that explore efficiently in a complex environment\nhas been widely recognized as a fundamental challenge in reinforcement\nlearning. While a number of works have demonstrated the effectiveness of\ntechniques based on randomized value functions on a single agent, it remains\nunclear, from a theoretical point of view, whether injecting randomization can\nhelp a society of agents {\\it concurently} explore an environment. The\ntheoretical results %that we established in this work tender an affirmative\nanswer to this question. We adapt the concurrent learning framework to\n\\textit{randomized least-squares value iteration} (RLSVI) with\n\\textit{aggregated state representation}. We demonstrate polynomial worst-case\nregret bounds in both finite- and infinite-horizon environments. In both setups\nthe per-agent regret decreases at an optimal rate of\n$\\Theta\\left(\\frac{1}{\\sqrt{N}}\\right)$, highlighting the advantage of\nconcurent learning. Our algorithm exhibits significantly lower space complexity\ncompared to \\cite{russo2019worst} and \\cite{agrawal2021improved}. We reduce the\nspace complexity by a factor of $K$ while incurring only a $\\sqrt{K}$ increase\nin the worst-case regret bound, compared to\n\\citep{agrawal2021improved,russo2019worst}. Additionally, we conduct numerical\nexperiments to demonstrate our theoretical findings.",
      "tldr_zh": "这篇论文探讨了强化学习中多代理并发探索环境的挑战，提出了一种基于 Randomized Least-Squares Value Iteration (RLSVI) 和 Aggregated State Representation 的框架，以提升探索效率。研究证明了该框架在有限和无限地平线环境中实现多项式遗憾边界（regret bounds），每个代理的遗憾以最优速率 Θ(1/√N) 下降，突显了并发学习的优势。与现有工作（如 Russo et al. 和 Agrawal et al.）相比，该算法将空间复杂度降低了 K 倍，同时仅增加了 √K 的遗憾边界。作者通过数值实验验证了这些理论发现，为高效的多代理强化学习提供了新见解。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.13394v2",
      "published_date": "2025-01-23 05:37:33 UTC",
      "updated_date": "2025-01-31 04:04:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:42:18.161091"
    },
    {
      "arxiv_id": "2501.13372v1",
      "title": "Generative Data Augmentation Challenge: Zero-Shot Speech Synthesis for Personalized Speech Enhancement",
      "title_zh": "生成式数据增强挑战：零样本语音合成用于个性化语音增强",
      "authors": [
        "Jae-Sung Bae",
        "Anastasia Kuznetsova",
        "Dinesh Manocha",
        "John Hershey",
        "Trausti Kristjansson",
        "Minje Kim"
      ],
      "abstract": "This paper presents a new challenge that calls for zero-shot text-to-speech\n(TTS) systems to augment speech data for the downstream task, personalized\nspeech enhancement (PSE), as part of the Generative Data Augmentation workshop\nat ICASSP 2025. Collecting high-quality personalized data is challenging due to\nprivacy concerns and technical difficulties in recording audio from the test\nscene. To address these issues, synthetic data generation using generative\nmodels has gained significant attention. In this challenge, participants are\ntasked first with building zero-shot TTS systems to augment personalized data.\nSubsequently, PSE systems are asked to be trained with this augmented\npersonalized dataset. Through this challenge, we aim to investigate how the\nquality of augmented data generated by zero-shot TTS models affects PSE model\nperformance. We also provide baseline experiments using open-source zero-shot\nTTS models to encourage participation and benchmark advancements. Our baseline\ncode implementation and checkpoints are available online.",
      "tldr_zh": "这篇论文提出了ICASSP 2025 Generative Data Augmentation 工作坊中的一个新挑战，旨在使用 zero-shot TTS（文本到语音）系统生成合成数据来增强个性化语音数据，从而支持下游任务 personalized speech enhancement (PSE)。挑战要求参与者首先构建 zero-shot TTS 系统来解决隐私和数据收集难题，然后用增强后的数据集训练 PSE 模型，以评估合成数据质量对模型性能的影响。论文还提供了基于开源 zero-shot TTS 模型的基线实验、代码和检查点，以促进参与和基准测试。",
      "categories": [
        "eess.AS",
        "cs.AI"
      ],
      "primary_category": "eess.AS",
      "comment": "Accepted to ICASSP 2025 Satellite Workshop: Generative Data\n  Augmentation for Real-World Signal Processing Applications",
      "pdf_url": "http://arxiv.org/pdf/2501.13372v1",
      "published_date": "2025-01-23 04:27:37 UTC",
      "updated_date": "2025-01-23 04:27:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:42:29.963741"
    },
    {
      "arxiv_id": "2501.13369v1",
      "title": "A review on development of eco-friendly filters in Nepal for use in cigarettes and masks and Air Pollution Analysis with Machine Learning and SHAP Interpretability",
      "title_zh": "翻译失败",
      "authors": [
        "Bishwash Paneru",
        "Biplov Paneru",
        "Tanka Mukhiya",
        "Khem Narayan Poudyal"
      ],
      "abstract": "In Nepal, air pollution is a serious public health concern, especially in\ncities like Kathmandu where particulate matter (PM2.5 and PM10) has a major\ninfluence on respiratory health and air quality. The Air Quality Index (AQI) is\npredicted in this work using a Random Forest Regressor, and the model's\npredictions are interpreted using SHAP (SHapley Additive exPlanations)\nanalysis. With the lowest Testing RMSE (0.23) and flawless R2 scores (1.00),\nCatBoost performs better than other models, demonstrating its greater accuracy\nand generalization which is cross validated using a nested cross validation\napproach. NowCast Concentration and Raw Concentration are the most important\nelements influencing AQI values, according to SHAP research, which shows that\nthe machine learning results are highly accurate. Their significance as major\ncontributors to air pollution is highlighted by the fact that high values of\nthese characteristics significantly raise the AQI. This study investigates the\nHydrogen-Alpha (HA) biodegradable filter as a novel way to reduce the related\nhealth hazards. With removal efficiency of more than 98% for PM2.5 and 99.24%\nfor PM10, the HA filter offers exceptional defense against dangerous airborne\nparticles. These devices, which are biodegradable face masks and cigarette\nfilters, address the environmental issues associated with traditional filters'\nnon-biodegradable trash while also lowering exposure to air contaminants.",
      "tldr_zh": "本研究回顾了尼泊尔空气污染问题，特别是 PM2.5 和 PM10 对健康的影响，并使用机器学习模型如 Random Forest Regressor 和 CatBoost 预测 Air Quality Index (AQI)。CatBoost 模型表现出色，测试 RMSE 为 0.23、R2 得分达 1.00，并通过嵌套交叉验证验证其准确性和泛化能力。SHAP (SHapley Additive exPlanations) 分析揭示了 NowCast Concentration 和 Raw Concentration 是影响 AQI 的关键因素，突显这些变量对污染的重大贡献。该研究还引入了 Hydrogen-Alpha (HA) 生物降解过滤器，用于香烟和口罩，其对 PM2.5 的去除效率超过 98%，对 PM10 达 99.24%，从而降低健康风险并解决传统过滤器的环境问题。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.13369v1",
      "published_date": "2025-01-23 04:16:58 UTC",
      "updated_date": "2025-01-23 04:16:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:42:41.603235"
    },
    {
      "arxiv_id": "2501.13365v1",
      "title": "Enhanced Extractor-Selector Framework and Symmetrization Weighted Binary Cross-Entropy for Edge Detections",
      "title_zh": "增强的 Extractor-Selector 框架和 Symmetrization",
      "authors": [
        "Hao Shu"
      ],
      "abstract": "Recent advancements have demonstrated the effectiveness of the\nextractor-selector (E-S) framework in edge detection (ED) tasks, which achieves\nstate-of-the-art (SOTA) performance in both quantitative metrics and perceptual\nquality. However, this method still falls short of fully exploiting the\npotential of feature extractors, as selectors only operate on highly compressed\nfeature maps that lack diversity and suffer from substantial information loss.\nAdditionally, while union training can improve perceptual quality, the highest\nevaluation scores are typically obtained without it, creating a trade-off\nbetween quantitative accuracy and perceptual fidelity. To address these\nlimitations, we propose an enhanced E-S architecture, which utilizes richer,\nless-loss feature representations and incorporates auxiliary features during\nthe selection process, thereby improving the effectiveness of the feature\nselection mechanism. Additionally, we introduce a novel loss function, the\nSymmetrization Weight Binary Cross-Entropy (SWBCE), which simultaneously\nemphasizes both the recall of edge pixels and the suppression of erroneous edge\npredictions, thereby enhancing the predictions both in the perceptual quality\nand the prediction accuracy. The effectiveness and superiority of our\napproaches over baseline models, the standard E-S framework, and the standard\nWeight Binary Cross-Entropy (WBCE) loss function are demonstrated by extensive\nexperiments. For example, our enhanced E-S architecture trained with SWBCE loss\nfunction achieves average improvements of 8.25$\\%$, 8.01$\\%$, and 33.25$\\%$ in\nODS, OIS, and AP, measured on BIPED2 compared with the baseline models,\nsignificantly outperforming the standard E-S method. The results set new\nbenchmarks for ED tasks, and highlight the potential of the methods in beyond.",
      "tldr_zh": "该研究针对边缘检测 (ED) 任务，增强了 Extractor-Selector (E-S) 框架，通过采用更丰富的特征表示和辅助特征来优化特征选择机制，解决了标准框架中信息损失和量化准确性与感知质量之间的权衡问题。\n同时，论文引入了新型损失函数 Symmetrization Weighted Binary Cross-Entropy (SWBCE)，它强调边缘像素的召回率和错误预测的抑制，从而提升预测的准确性和感知质量。\n实验结果显示，与基线模型相比，增强 E-S 架构结合 SWBCE 在 BIPED2 数据集上实现了 ODS、OIS 和 AP 平均提升分别为 8.25%、8.01% 和 33.25%，显著超越了标准 E-S 方法，并为 ED 任务设定了新基准。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "9 pages",
      "pdf_url": "http://arxiv.org/pdf/2501.13365v1",
      "published_date": "2025-01-23 04:10:31 UTC",
      "updated_date": "2025-01-23 04:10:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:44:54.656008"
    },
    {
      "arxiv_id": "2501.13347v1",
      "title": "One Fits All: General Mobility Trajectory Modeling via Masked Conditional Diffusion",
      "title_zh": "翻译失败",
      "authors": [
        "Qingyue Long",
        "Can Rong",
        "Huandong Wang",
        "Yong Li"
      ],
      "abstract": "Trajectory data play a crucial role in many applications, ranging from\nnetwork optimization to urban planning. Existing studies on trajectory data are\ntask-specific, and their applicability is limited to the specific tasks on\nwhich they have been trained, such as generation, recovery, or prediction.\nHowever, the potential of a unified model has not yet been fully explored in\ntrajectory modeling. Although various trajectory tasks differ in inputs,\noutputs, objectives, and conditions, they share common mobility patterns. Based\non these common patterns, we can construct a general framework that enables a\nsingle model to address different tasks. However, building a trajectory\ntask-general framework faces two critical challenges: 1) the diversity in the\nformats of different tasks and 2) the complexity of the conditions imposed on\ndifferent tasks. In this work, we propose a general trajectory modeling\nframework via masked conditional diffusion (named GenMove). Specifically, we\nutilize mask conditions to unify diverse formats. To adapt to complex\nconditions associated with different tasks, we utilize historical trajectory\ndata to obtain contextual trajectory embeddings, which include rich contexts\nsuch as spatiotemporal characteristics and user preferences. Integrating the\ncontextual trajectory embedding into diffusion models through a classifier-free\nguidance approach allows the model to flexibly adjust its outputs based on\ndifferent conditions. Extensive experiments on mainstream tasks demonstrate\nthat our model significantly outperforms state-of-the-art baselines, with the\nhighest performance improvement exceeding 13% in generation tasks.",
      "tldr_zh": "本研究提出了一种通用轨迹建模框架GenMove，通过masked conditional diffusion方法，统一处理多种轨迹任务（如生成、恢复和预测），利用轨迹数据中的共同移动模式来克服任务格式多样性和条件复杂性的挑战。具体而言，该框架采用mask conditions来标准化输入格式，并通过历史轨迹数据提取上下文嵌入（包括时空特征和用户偏好），并将其整合到diffusion模型中以实现classifier-free guidance。实验结果显示，GenMove在主流轨迹任务上显著优于现有基线模型，在生成任务上性能提升超过13%。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.13347v1",
      "published_date": "2025-01-23 03:13:45 UTC",
      "updated_date": "2025-01-23 03:13:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:43:04.529682"
    },
    {
      "arxiv_id": "2501.16373v1",
      "title": "Unveiling Discrete Clues: Superior Healthcare Predictions for Rare Diseases",
      "title_zh": "翻译失败",
      "authors": [
        "Chuang Zhao",
        "Hui Tang",
        "Jiheng Zhang",
        "Xiaomeng Li"
      ],
      "abstract": "Accurate healthcare prediction is essential for improving patient outcomes.\nExisting work primarily leverages advanced frameworks like attention or graph\nnetworks to capture the intricate collaborative (CO) signals in electronic\nhealth records. However, prediction for rare diseases remains challenging due\nto limited co-occurrence and inadequately tailored approaches. To address this\nissue, this paper proposes UDC, a novel method that unveils discrete clues to\nbridge consistent textual knowledge and CO signals within a unified semantic\nspace, thereby enriching the representation semantics of rare diseases.\nSpecifically, we focus on addressing two key sub-problems: (1) acquiring\ndistinguishable discrete encodings for precise disease representation and (2)\nachieving semantic alignment between textual knowledge and the CO signals at\nthe code level. For the first sub-problem, we refine the standard vector\nquantized process to include condition awareness. Additionally, we develop an\nadvanced contrastive approach in the decoding stage, leveraging synthetic and\nmixed-domain targets as hard negatives to enrich the perceptibility of the\nreconstructed representation for downstream tasks. For the second sub-problem,\nwe introduce a novel codebook update strategy using co-teacher distillation.\nThis approach facilitates bidirectional supervision between textual knowledge\nand CO signals, thereby aligning semantically equivalent information in a\nshared discrete latent space. Extensive experiments on three datasets\ndemonstrate our superiority.",
      "tldr_zh": "该论文针对稀有疾病的医疗预测挑战，提出了一种名为 UDC 的新方法，通过揭示离散线索，将一致的文本知识和协同信号(CO signals)整合到统一的语义空间中，从而丰富稀有疾病的表示语义。具体地，UDC 解决了两个关键子问题：一是通过改进向量量化(vector quantized)过程并引入条件感知和高级对比方法，以获取可区分的离散编码；二是采用协同教师蒸馏(co-teacher distillation)的代码本更新策略，实现文本知识与 CO signals 在共享离散潜在空间中的语义对齐。在三个数据集上的广泛实验中，UDC 展示了显著的优越性能，改善了稀有疾病的预测准确性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.16373v1",
      "published_date": "2025-01-23 03:08:22 UTC",
      "updated_date": "2025-01-23 03:08:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:43:17.247724"
    },
    {
      "arxiv_id": "2501.13344v1",
      "title": "Full-Stack Optimized Large Language Models for Lifelong Sequential Behavior Comprehension in Recommendation",
      "title_zh": "全栈优化的大语言模型用于推荐中的终身顺序行为理解",
      "authors": [
        "Rong Shan",
        "Jiachen Zhu",
        "Jianghao Lin",
        "Chenxu Zhu",
        "Bo Chen",
        "Ruiming Tang",
        "Yong Yu",
        "Weinan Zhang"
      ],
      "abstract": "In this paper, we address the lifelong sequential behavior incomprehension\nproblem in large language models (LLMs) for recommendation, where LLMs struggle\nto extract useful information from long user behavior sequences, even within\ntheir context limits. To tackle this, we propose ReLLaX (Retrieval-enhanced\nLarge Language models Plus), a framework offering optimization across data,\nprompt, and parameter levels. At the data level, we introduce Semantic User\nBehavior Retrieval (SUBR) to reduce sequence heterogeneity, making it easier\nfor LLMs to extract key information. For prompt-level enhancement, we employ\nSoft Prompt Augmentation (SPA) to inject collaborative knowledge, aligning item\nrepresentations with recommendation tasks and improving LLMs's exploration of\nitem relationships. Finally, at the parameter level, we propose Component\nFully-interactive LoRA (CFLoRA), which enhances LoRA's expressiveness by\nenabling interactions between its components, allowing better capture of\nsequential information. Moreover, we present new perspectives to compare\ncurrent LoRA-based LLM4Rec methods, i.e. from both a composite and a decomposed\nview. We theoretically demonstrate that the ways they employ LoRA for\nrecommendation are degraded versions of our CFLoRA, with different constraints\non atom component interactions. Extensive experiments on three public datasets\ndemonstrate ReLLaX's superiority over existing baselines and its ability to\nmitigate lifelong sequential behavior incomprehension effectively.",
      "tldr_zh": "本文探讨了大型语言模型（LLMs）在推荐系统中处理长用户行为序列时的理解难题，提出ReLLaX框架，通过数据、提示和参数级别的全面优化来解决这一问题。具体方法包括Semantic User Behavior Retrieval (SUBR)减少序列异质性、Soft Prompt Augmentation (SPA)注入协作知识以改善项关系探索，以及Component Fully-interactive LoRA (CFLoRA)增强组件间交互以更好地捕获顺序信息。实验在三个公共数据集上显示，ReLLaX显著优于现有基线方法，并有效缓解终身顺序行为理解问题。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "Under Review",
      "pdf_url": "http://arxiv.org/pdf/2501.13344v1",
      "published_date": "2025-01-23 03:05:13 UTC",
      "updated_date": "2025-01-23 03:05:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:43:29.765565"
    },
    {
      "arxiv_id": "2501.13333v1",
      "title": "AgentRec: Agent Recommendation Using Sentence Embeddings Aligned to Human Feedback",
      "title_zh": "AgentRec：使用与人类反馈对齐的句子嵌入进行智能体推荐",
      "authors": [
        "Joshua Park",
        "Yongfeng Zhang"
      ],
      "abstract": "Multi-agent systems must decide which agent is the most appropriate for a\ngiven task. We propose a novel architecture for recommending which LLM agent\nout of many should perform a task given a natural language prompt by extending\nthe Sentence-BERT (SBERT) encoder model. On test data, we are able to achieve a\ntop-1 accuracy of 92.2% with each classification taking less than 300\nmilliseconds. In contrast to traditional classification methods, our\narchitecture is computationally cheap, adaptive to new classes, interpretable,\nand controllable with arbitrary metrics through reinforcement learning. By\nencoding natural language prompts into sentence embeddings, our model captures\nthe semantic content relevant to recommending an agent. The distance between\nsentence embeddings that belong to the same agent is then minimized through\nfine-tuning and aligned to human values through reinforcement learning from\nhuman feedback. This allows the classification of natural language prompts\nbased on their nearest neighbors by measuring the cosine similarity between\nembeddings. This work is made possible through the generation of a synthetic\ndataset for agent recommendation, which we have open-sourced to the public\nalong with the code for AgentRec recommendation system at\nhttps://github.com/joshprk/agentrec.",
      "tldr_zh": "本文提出 AgentRec，一种基于扩展 Sentence-BERT (SBERT) 模型的架构，用于推荐最适合给定自然语言提示的 LLM 代理，通过编码提示成句子嵌入并使用强化学习从人类反馈中对齐嵌入距离。方法通过微调最小化相同代理的嵌入距离，并基于余弦相似度进行最近邻居分类，使系统计算高效、可适应新类且可解释。在测试数据上，AgentRec 实现了 92.2% 的 top-1 准确率，每个分类耗时不到 300 毫秒，并开源了合成数据集和代码以促进进一步研究。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.MA"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 8 figures, preprint",
      "pdf_url": "http://arxiv.org/pdf/2501.13333v1",
      "published_date": "2025-01-23 02:25:44 UTC",
      "updated_date": "2025-01-23 02:25:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:43:41.889583"
    },
    {
      "arxiv_id": "2501.13329v2",
      "title": "Sparse identification of nonlinear dynamics and Koopman operators with Shallow Recurrent Decoder Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Mars Liyao Gao",
        "Jan P. Williams",
        "J. Nathan Kutz"
      ],
      "abstract": "Modeling real-world spatio-temporal data is exceptionally difficult due to\ninherent high dimensionality, measurement noise, partial observations, and\noften expensive data collection procedures. In this paper, we present Sparse\nIdentification of Nonlinear Dynamics with SHallow REcurrent Decoder networks\n(SINDy-SHRED), a method to jointly solve the sensing and model identification\nproblems with simple implementation, efficient computation, and robust\nperformance. SINDy-SHRED uses Gated Recurrent Units to model the temporal\nsequence of sparse sensor measurements along with a shallow decoder network to\nreconstruct the full spatio-temporal field from the latent state space. Our\nalgorithm introduces a SINDy-based regularization for which the latent space\nprogressively converges to a SINDy-class functional, provided the projection\nremains within the set. In restricting SINDy to a linear model, a Koopman-SHRED\nmodel is generated. SINDy-SHRED (i) learns a symbolic and interpretable\ngenerative model of a parsimonious and low-dimensional latent space for the\ncomplex spatio-temporal dynamics, (ii) discovers new physics models even for\nwell-known physical systems, (iii) achieves provably robust convergence with an\nobserved globally convex loss landscape, and (iv) achieves superior accuracy,\ndata efficiency, and training time, all with fewer model parameters. We conduct\nsystematic experimental studies on PDE data such as turbulent flows, real-world\nsensor measurements for sea surface temperature, and direct video data. The\ninterpretable SINDy and Koopman models of latent state dynamics enable stable\nand accurate long-term video predictions, outperforming all current baseline\ndeep learning models in accuracy, training time, and data requirements,\nincluding Convolutional LSTM, PredRNN, ResNet, and SimVP.",
      "tldr_zh": "本研究提出了一种名为 SINDy-SHRED 的方法，用于处理高维度时空数据的建模挑战，包括噪声、部分观察和数据采集成本。该方法结合 Gated Recurrent Units (GRU) 来建模稀疏传感器测量的时间序列，并使用浅层解码器网络从低维潜在状态空间重建完整的时空场，同时引入 SINDy-based 正则化以确保潜在空间收敛到可解释的函数形式。论文的关键贡献包括学习符号化和可解释的生成模型、发现新物理模型，以及证明算法的鲁棒收敛和全局凸损失景观。在实验中，SINDy-SHRED 在 PDE 数据（如湍流）、海面温度传感器数据和视频数据上表现出色，优于基准模型如 Convolutional LSTM 和 PredRNN，在准确性、数据效率、训练时间和参数数量上均有显著提升。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.DS"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.13329v2",
      "published_date": "2025-01-23 02:18:13 UTC",
      "updated_date": "2025-04-01 04:15:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:43:54.219613"
    },
    {
      "arxiv_id": "2501.16372v1",
      "title": "Low-Rank Adapters Meet Neural Architecture Search for LLM Compression",
      "title_zh": "翻译失败",
      "authors": [
        "J. Pablo Muñoz",
        "Jinjie Yuan",
        "Nilesh Jain"
      ],
      "abstract": "The rapid expansion of Large Language Models (LLMs) has posed significant\nchallenges regarding the computational resources required for fine-tuning and\ndeployment. Recent advancements in low-rank adapters have demonstrated their\nefficacy in parameter-efficient fine-tuning (PEFT) of these models. This\nretrospective paper comprehensively discusses innovative approaches that\nsynergize low-rank representations with Neural Architecture Search (NAS)\ntechniques, particularly weight-sharing super-networks. Robust solutions for\ncompressing and fine-tuning large pre-trained models are developed by\nintegrating these methodologies. Our analysis highlights the potential of these\ncombined strategies to democratize the use of LLMs, making them more accessible\nfor deployment in resource-constrained environments. The resulting models\nexhibit reduced memory footprints and faster inference times, paving the way\nfor more practical and scalable applications of LLMs. Models and code are\navailable at\nhttps://github.com/IntelLabs/Hardware-Aware-Automated-Machine-Learning.",
      "tldr_zh": "这篇论文探讨了低秩适配器（low-rank adapters）与神经架构搜索（NAS）技术的结合，用于压缩大型语言模型（LLMs），以解决微调和部署的计算资源挑战。通过整合低秩表示和权重共享超网络，研究者开发了高效的参数高效微调（PEFT）解决方案，使模型在资源受限环境中更易访问。实验结果显示，这些方法显著降低了模型的内存占用和推理时间，为LLMs的实际应用提供了更具可扩展性的途径。模型和代码可从https://github.com/IntelLabs/Hardware-Aware-Automated-Machine-Learning获取。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "AAAI-25 Workshop on Connecting Low-rank Representations in AI",
      "pdf_url": "http://arxiv.org/pdf/2501.16372v1",
      "published_date": "2025-01-23 02:14:08 UTC",
      "updated_date": "2025-01-23 02:14:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:44:06.109912"
    },
    {
      "arxiv_id": "2501.13321v1",
      "title": "Investigation of the Privacy Concerns in AI Systems for Young Digital Citizens: A Comparative Stakeholder Analysis",
      "title_zh": "AI 系统中年轻数字公民隐私问题的调查：一项比较利益相关者分析",
      "authors": [
        "Molly Campbell",
        "Ankur Barthwal",
        "Sandhya Joshi",
        "Austin Shouli",
        "Ajay Kumar Shrestha"
      ],
      "abstract": "The integration of Artificial Intelligence (AI) systems into technologies\nused by young digital citizens raises significant privacy concerns. This study\ninvestigates these concerns through a comparative analysis of stakeholder\nperspectives. A total of 252 participants were surveyed, with the analysis\nfocusing on 110 valid responses from parents/educators and 100 from AI\nprofessionals after data cleaning. Quantitative methods, including descriptive\nstatistics and Partial Least Squares Structural Equation Modeling, examined\nfive validated constructs: Data Ownership and Control, Parental Data Sharing,\nPerceived Risks and Benefits, Transparency and Trust, and Education and\nAwareness. Results showed Education and Awareness significantly influenced data\nownership and risk assessment, while Data Ownership and Control strongly\nimpacted Transparency and Trust. Transparency and Trust, along with Perceived\nRisks and Benefits, showed minimal influence on Parental Data Sharing,\nsuggesting other factors may play a larger role. The study underscores the need\nfor user-centric privacy controls, tailored transparency strategies, and\ntargeted educational initiatives. Incorporating diverse stakeholder\nperspectives offers actionable insights into ethical AI design and governance,\nbalancing innovation with robust privacy protections to foster trust in a\ndigital age.",
      "tldr_zh": "这篇论文通过对252名参与者的调查（包括110名父母/教育者和100名AI专业人士），比较分析了AI系统在年轻数字公民技术中引发的隐私担忧。研究采用描述性统计和Partial Least Squares Structural Equation Modeling量化分析五个结构：Data Ownership and Control、Parental Data Sharing、Perceived Risks and Benefits、Transparency and Trust，以及Education and Awareness。结果显示，Education and Awareness显著影响Data Ownership and Control以及风险评估，而Transparency and Trust对Parental Data Sharing的影响较小，暗示其他因素更为关键。论文强调需要用户导向的隐私控制、定制透明策略和针对教育举措，以整合多方视角推动道德AI设计和治理。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "To appear in the 2025 IEEE 14th Annual Computing and Communication\n  Workshop and Conference (CCWC) proceedings",
      "pdf_url": "http://arxiv.org/pdf/2501.13321v1",
      "published_date": "2025-01-23 02:07:45 UTC",
      "updated_date": "2025-01-23 02:07:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:44:17.968019"
    },
    {
      "arxiv_id": "2501.13320v1",
      "title": "Toward Ethical AI: A Qualitative Analysis of Stakeholder Perspectives",
      "title_zh": "迈向伦理 AI：利益相关者视角的定性分析",
      "authors": [
        "Ajay Kumar Shrestha",
        "Sandhya Joshi"
      ],
      "abstract": "As Artificial Intelligence (AI) systems become increasingly integrated into\nvarious aspects of daily life, concerns about privacy and ethical\naccountability are gaining prominence. This study explores stakeholder\nperspectives on privacy in AI systems, focusing on educators, parents, and AI\nprofessionals. Using qualitative analysis of survey responses from 227\nparticipants, the research identifies key privacy risks, including data\nbreaches, ethical misuse, and excessive data collection, alongside perceived\nbenefits such as personalized services, enhanced efficiency, and educational\nadvancements. Stakeholders emphasized the need for transparency,\nprivacy-by-design, user empowerment, and ethical oversight to address privacy\nconcerns effectively. The findings provide actionable insights into balancing\nthe benefits of AI with robust privacy protections, catering to the diverse\nneeds of stakeholders. Recommendations include implementing selective data use,\nfostering transparency, promoting user autonomy, and integrating ethical\nprinciples into AI development. This study contributes to the ongoing discourse\non ethical AI, offering guidance for designing privacy-centric systems that\nalign with societal values and build trust among users. By addressing privacy\nchallenges, this research underscores the importance of developing AI\ntechnologies that are not only innovative but also ethically sound and\nresponsive to the concerns of all stakeholders.",
      "tldr_zh": "本研究通过对227名教育者、父母和AI专业人士的调查响应进行定性分析，探讨了AI系统中的隐私风险和伦理问题，包括数据泄露、伦理滥用以及过度数据收集，同时突出了AI的益处如个性化服务、效率提升和教育进步。参与者强调了透明、privacy-by-design、用户赋权和伦理监督的必要性，以有效平衡AI的优点与隐私保护。研究提供了行动性推荐，如实施选择性数据使用、促进透明度和整合伦理原则，从而为设计以隐私为中心的AI系统提供指导，并增强对伦理AI的信任。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "To appear in the 2025 IEEE 14th Annual Computing and Communication\n  Workshop and Conference (CCWC) proceedings",
      "pdf_url": "http://arxiv.org/pdf/2501.13320v1",
      "published_date": "2025-01-23 02:06:25 UTC",
      "updated_date": "2025-01-23 02:06:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:45:06.063448"
    },
    {
      "arxiv_id": "2501.13978v1",
      "title": "Chain of Grounded Objectives: Bridging Process and Goal-oriented Prompting for Code Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Sangyeop Yeo",
        "Seung-won Hwang",
        "Yu-Seung Ma"
      ],
      "abstract": "The use of Large Language Models (LLMs) for code generation has gained\nsignificant attention in recent years. Existing methods often aim to improve\nthe quality of generated code by incorporating additional contextual\ninformation or guidance into input prompts. Many of these approaches adopt\nsequential reasoning strategies, mimicking human-like step-by-step thinking.\nHowever, such strategies may constrain flexibility, as they do not always align\nwith the structured characteristics of programming languages. This paper\nintroduces the Chain of Grounded Objectives (CGO), a method that embeds\nfunctional objectives into input prompts to enhance code generation. By\nleveraging appropriately structured objectives as input and avoiding explicit\nsequential procedures, CGO adapts effectively to the structured nature of\nprogramming tasks. Empirical evaluations demonstrate that CGO effectively\nenhances code generation, addressing limitations of existing approaches.",
      "tldr_zh": "本文研究了使用Large Language Models (LLMs)进行代码生成的问题，指出现有方法的顺序推理策略虽模仿人类思考但可能限制灵活性，无法完全适应编程语言的结构特性。为此，提出Chain of Grounded Objectives (CGO)方法，将功能目标嵌入输入提示中，避免显式顺序过程，从而增强代码生成的有效性。实证评估结果表明，CGO成功解决了现有方法的局限性，提高了生成的代码质量。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.13978v1",
      "published_date": "2025-01-23 01:45:09 UTC",
      "updated_date": "2025-01-23 01:45:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:45:17.710833"
    },
    {
      "arxiv_id": "2501.13302v1",
      "title": "Watching the AI Watchdogs: A Fairness and Robustness Analysis of AI Safety Moderation Classifiers",
      "title_zh": "翻译失败",
      "authors": [
        "Akshit Achara",
        "Anshuman Chhabra"
      ],
      "abstract": "AI Safety Moderation (ASM) classifiers are designed to moderate content on\nsocial media platforms and to serve as guardrails that prevent Large Language\nModels (LLMs) from being fine-tuned on unsafe inputs. Owing to their potential\nfor disparate impact, it is crucial to ensure that these classifiers: (1) do\nnot unfairly classify content belonging to users from minority groups as unsafe\ncompared to those from majority groups and (2) that their behavior remains\nrobust and consistent across similar inputs. In this work, we thus examine the\nfairness and robustness of four widely-used, closed-source ASM classifiers:\nOpenAI Moderation API, Perspective API, Google Cloud Natural Language (GCNL)\nAPI, and Clarifai API. We assess fairness using metrics such as demographic\nparity and conditional statistical parity, comparing their performance against\nASM models and a fair-only baseline. Additionally, we analyze robustness by\ntesting the classifiers' sensitivity to small and natural input perturbations.\nOur findings reveal potential fairness and robustness gaps, highlighting the\nneed to mitigate these issues in future versions of these models.",
      "tldr_zh": "本研究分析了AI Safety Moderation (ASM) 分类器的公平性和鲁棒性，这些分类器用于社交媒体内容审核和防止Large Language Models (LLMs) 在不安全输入上微调。研究评估了四个闭源分类器（包括OpenAI Moderation API、Perspective API、Google Cloud Natural Language (GCNL) API 和 Clarifai API），采用demographic parity 和 conditional statistical parity 等指标与基准模型比较，并测试了分类器对小规模自然输入扰动的敏感性。结果显示，这些分类器存在潜在的公平性和鲁棒性差距，强调未来版本需加强改进以避免对少数群体用户的歧视和不一致行为。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to NAACL 2025 Main Conference",
      "pdf_url": "http://arxiv.org/pdf/2501.13302v1",
      "published_date": "2025-01-23 01:04:00 UTC",
      "updated_date": "2025-01-23 01:04:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:45:29.770208"
    },
    {
      "arxiv_id": "2501.13297v1",
      "title": "RAMQA: A Unified Framework for Retrieval-Augmented Multi-Modal Question Answering",
      "title_zh": "RAMQA：检索增强多模态问答的统一框架",
      "authors": [
        "Yang Bai",
        "Christan Earl Grant",
        "Daisy Zhe Wang"
      ],
      "abstract": "Multi-modal retrieval-augmented Question Answering (MRAQA), integrating text\nand images, has gained significant attention in information retrieval (IR) and\nnatural language processing (NLP). Traditional ranking methods rely on small\nencoder-based language models, which are incompatible with modern decoder-based\ngenerative large language models (LLMs) that have advanced various NLP tasks.\nTo bridge this gap, we propose RAMQA, a unified framework combining\nlearning-to-rank methods with generative permutation-enhanced ranking\ntechniques. We first train a pointwise multi-modal ranker using LLaVA as the\nbackbone. Then, we apply instruction tuning to train a LLaMA model for\nre-ranking the top-k documents using an innovative autoregressive multi-task\nlearning approach. Our generative ranking model generates re-ranked document\nIDs and specific answers from document candidates in various permutations.\nExperiments on two MRAQA benchmarks, WebQA and MultiModalQA, show significant\nimprovements over strong baselines, highlighting the effectiveness of our\napproach. Code and data are available at: https://github.com/TonyBY/RAMQA",
      "tldr_zh": "本论文提出 RAMQA，一种统一的框架，用于检索增强的多模态问答（MRAQA），旨在解决传统排序方法与生成式大语言模型（LLMs）的兼容性问题。\n框架首先使用 LLaVA 作为骨干训练一个 pointwise 多模态排序器，然后通过指令微调训练 LLaMA 模型进行 re-ranking，并采用自回归多任务学习生成重新排序的文档 ID 和特定答案。\n实验在 WebQA 和 MultiModalQA 基准上显示，RAMQA 比强基线模型取得了显著改进，代码和数据已在 GitHub 上公开。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by NAACL 2025 Findings",
      "pdf_url": "http://arxiv.org/pdf/2501.13297v1",
      "published_date": "2025-01-23 00:50:33 UTC",
      "updated_date": "2025-01-23 00:50:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:45:42.755050"
    },
    {
      "arxiv_id": "2501.13295v1",
      "title": "Parallel Belief Contraction via Order Aggregation",
      "title_zh": "翻译失败",
      "authors": [
        "Jake Chandler",
        "Richard Booth"
      ],
      "abstract": "The standard ``serial'' (aka ``singleton'') model of belief contraction\nmodels the manner in which an agent's corpus of beliefs responds to the removal\nof a single item of information. One salient extension of this model introduces\nthe idea of ``parallel'' (aka ``package'' or ``multiple'') change, in which an\nentire set of items of information are simultaneously removed. Existing\nresearch on the latter has largely focussed on single-step parallel\ncontraction: understanding the behaviour of beliefs after a single parallel\ncontraction. It has also focussed on generalisations to the parallel case of\nserial contraction operations whose characteristic properties are extremely\nweak. Here we consider how to extend serial contraction operations that obey\nstronger properties. Potentially more importantly, we also consider the\niterated case: the behaviour of beliefs after a sequence of parallel\ncontractions. We propose a general method for extending serial iterated belief\nchange operators to handle parallel change based on an n-ary generalisation of\nBooth & Chandler's TeamQueue binary order aggregators.",
      "tldr_zh": "该研究扩展了信念收缩（belief contraction）模型，从传统的“serial”（单项移除）模式转向“parallel”（同时移除一组信息项）的改变方式，特别关注序列（iterated）平行收缩的场景。现有工作主要聚焦于单步平行收缩和特性较弱的操作，而本文提出一种基于 n-ary 泛化 TeamQueue 二元顺序聚合器（order aggregators）的方法，来扩展遵守更强特性的序列信念改变操作。实验和理论分析表明，此方法能有效处理信念系统在多次平行收缩中的行为，确保更可靠的信息移除过程。",
      "categories": [
        "cs.AI",
        "I.2.4"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.13295v1",
      "published_date": "2025-01-23 00:42:16 UTC",
      "updated_date": "2025-01-23 00:42:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:45:53.690905"
    },
    {
      "arxiv_id": "2501.13977v2",
      "title": "Re-ranking Using Large Language Models for Mitigating Exposure to Harmful Content on Social Media Platforms",
      "title_zh": "利用大型语言模型进行重新排名以缓解社交媒体平台上对有害内容的暴露",
      "authors": [
        "Rajvardhan Oak",
        "Muhammad Haroon",
        "Claire Jo",
        "Magdalena Wojcieszak",
        "Anshuman Chhabra"
      ],
      "abstract": "Social media platforms utilize Machine Learning (ML) and Artificial\nIntelligence (AI) powered recommendation algorithms to maximize user\nengagement, which can result in inadvertent exposure to harmful content.\nCurrent moderation efforts, reliant on classifiers trained with extensive\nhuman-annotated data, struggle with scalability and adapting to new forms of\nharm. To address these challenges, we propose a novel re-ranking approach using\nLarge Language Models (LLMs) in zero-shot and few-shot settings. Our method\ndynamically assesses and re-ranks content sequences, effectively mitigating\nharmful content exposure without requiring extensive labeled data. Alongside\ntraditional ranking metrics, we also introduce two new metrics to evaluate the\neffectiveness of re-ranking in reducing exposure to harmful content. Through\nexperiments on three datasets, three models and across three configurations, we\ndemonstrate that our LLM-based approach significantly outperforms existing\nproprietary moderation approaches, offering a scalable and adaptable solution\nfor harm mitigation.",
      "tldr_zh": "本研究针对社交媒体平台的推荐算法可能导致用户暴露在有害内容的问题，提出了一种基于大型语言模型 (LLMs) 的重新排序 (re-ranking) 方法。该方法在 zero-shot 和 few-shot 设置下动态评估并重新排序内容序列，从而减少有害内容的暴露，而无需依赖大量标注数据。研究引入了两个新指标来评估 re-ranking 的效果，并在三个数据集、三个模型和三种配置的实验中证明，该方法显著优于现有 moderation 方式，提供了一个可扩展且适应的解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.SI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to ACL 2025 Main Conference",
      "pdf_url": "http://arxiv.org/pdf/2501.13977v2",
      "published_date": "2025-01-23 00:26:32 UTC",
      "updated_date": "2025-05-16 13:25:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:46:04.837850"
    },
    {
      "arxiv_id": "2501.13284v1",
      "title": "Toyteller: AI-powered Visual Storytelling Through Toy-Playing with Character Symbols",
      "title_zh": "翻译失败",
      "authors": [
        "John Joon Young Chung",
        "Melissa Roemmele",
        "Max Kreminski"
      ],
      "abstract": "We introduce Toyteller, an AI-powered storytelling system where users\ngenerate a mix of story text and visuals by directly manipulating character\nsymbols like they are toy-playing. Anthropomorphized symbol motions can convey\nrich and nuanced social interactions; Toyteller leverages these motions (1) to\nlet users steer story text generation and (2) as a visual output format that\naccompanies story text. We enabled motion-steered text generation and\ntext-steered motion generation by mapping motions and text onto a shared\nsemantic space so that large language models and motion generation models can\nuse it as a translational layer. Technical evaluations showed that Toyteller\noutperforms a competitive baseline, GPT-4o. Our user study identified that\ntoy-playing helps express intentions difficult to verbalize. However, only\nmotions could not express all user intentions, suggesting combining it with\nother modalities like language. We discuss the design space of toy-playing\ninteractions and implications for technical HCI research on human-AI\ninteraction.",
      "tldr_zh": "本研究引入了 Toyteller 系统，一种 AI 驱动的视觉故事生成工具，用户通过操纵字符符号（如玩具玩耍）来创建故事文本和视觉输出，从而传达丰富的社会互动。系统通过将符号动作和文本映射到共享语义空间，实现动作引导文本生成以及文本引导动作生成，超越了 GPT-4o 等基线模型。用户研究发现，这种玩具玩耍方式有助于表达难以用语言表述的意图，但需与其他模态（如语言）结合以覆盖所有用户需求，并讨论了玩具互动的设计空间及其对 HCI（Human-Computer Interaction）研究的影响。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.HC",
      "comment": "Accepted to CHI2025",
      "pdf_url": "http://arxiv.org/pdf/2501.13284v1",
      "published_date": "2025-01-23 00:20:38 UTC",
      "updated_date": "2025-01-23 00:20:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:46:17.493907"
    },
    {
      "arxiv_id": "2501.13976v1",
      "title": "Towards Safer Social Media Platforms: Scalable and Performant Few-Shot Harmful Content Moderation Using Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Akash Bonagiri",
        "Lucen Li",
        "Rajvardhan Oak",
        "Zeerak Babar",
        "Magdalena Wojcieszak",
        "Anshuman Chhabra"
      ],
      "abstract": "The prevalence of harmful content on social media platforms poses significant\nrisks to users and society, necessitating more effective and scalable content\nmoderation strategies. Current approaches rely on human moderators, supervised\nclassifiers, and large volumes of training data, and often struggle with\nscalability, subjectivity, and the dynamic nature of harmful content (e.g.,\nviolent content, dangerous challenge trends, etc.). To bridge these gaps, we\nutilize Large Language Models (LLMs) to undertake few-shot dynamic content\nmoderation via in-context learning. Through extensive experiments on multiple\nLLMs, we demonstrate that our few-shot approaches can outperform existing\nproprietary baselines (Perspective and OpenAI Moderation) as well as prior\nstate-of-the-art few-shot learning methods, in identifying harm. We also\nincorporate visual information (video thumbnails) and assess if different\nmultimodal techniques improve model performance. Our results underscore the\nsignificant benefits of employing LLM based methods for scalable and dynamic\nharmful content moderation online.",
      "tldr_zh": "该研究针对社交媒体平台上有害内容（如暴力内容和危险挑战）的风险，提出了一种基于大型语言模型 (LLMs) 的少样本 (few-shot) 动态内容审核方法，利用 in-context learning 实现可扩展和高性能审核。实验结果显示，该方法在识别有害内容方面优于现有基准（如 Perspective 和 OpenAI Moderation）以及先前的少样本学习技术。研究还整合了视觉信息（如视频缩略图），并评估多模态技术是否进一步提升模型性能。总体而言，这一方法为更安全、可动态扩展的社交媒体内容审核提供了重要基础。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.SI"
      ],
      "primary_category": "cs.CL",
      "comment": "This paper is in submission and under peer review",
      "pdf_url": "http://arxiv.org/pdf/2501.13976v1",
      "published_date": "2025-01-23 00:19:14 UTC",
      "updated_date": "2025-01-23 00:19:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:46:30.810534"
    },
    {
      "arxiv_id": "2501.13282v1",
      "title": "Experience with GitHub Copilot for Developer Productivity at Zoominfo",
      "title_zh": "翻译失败",
      "authors": [
        "Gal Bakal",
        "Ali Dasdan",
        "Yaniv Katz",
        "Michael Kaufman",
        "Guy Levin"
      ],
      "abstract": "This paper presents a comprehensive evaluation of GitHub Copilot's deployment\nand impact on developer productivity at Zoominfo, a leading Go-To-Market (GTM)\nIntelligence Platform. We describe our systematic four-phase approach to\nevaluating and deploying GitHub Copilot across our engineering organization,\ninvolving over 400 developers. Our analysis combines both quantitative metrics,\nfocusing on acceptance rates of suggestions given by GitHub Copilot and\nqualitative feedback given by developers through developer satisfaction\nsurveys. The results show an average acceptance rate of 33% for suggestions and\n20% for lines of code, with high developer satisfaction scores of 72%. We also\ndiscuss language-specific performance variations, limitations, and lessons\nlearned from this medium-scale enterprise deployment. Our findings contribute\nto the growing body of knowledge about AI-assisted software development in\nenterprise settings.",
      "tldr_zh": "这篇论文评估了GitHub Copilot在Zoominfo公司对开发者生产力的影响，通过一个系统化的四阶段方法在超过400名开发者的工程组织中进行部署和评估。研究结合了定量指标（如建议接受率为33%、代码行接受率为20%）和定性反馈（如开发者满意度调查得分72%）。论文还讨论了语言特定的性能差异、Copilot的限制以及从这一中等规模企业部署中获得的经验教训。这些发现为AI辅助软件开发在企业环境中的应用提供了重要见解。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "I.2.2; I.2.5; D.2.3"
      ],
      "primary_category": "cs.SE",
      "comment": "25 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.13282v1",
      "published_date": "2025-01-23 00:17:48 UTC",
      "updated_date": "2025-01-23 00:17:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T02:46:41.891302"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 139,
  "processed_papers_count": 139,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-22T02:47:12.395067"
}