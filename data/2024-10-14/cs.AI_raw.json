[
  {
    "arxiv_id": "2410.11143v1",
    "title": "LLM Unlearning via Loss Adjustment with Only Forget Data",
    "authors": [
      "Yaxuan Wang",
      "Jiaheng Wei",
      "Chris Yuhao Liu",
      "Jinlong Pang",
      "Quan Liu",
      "Ankit Parag Shah",
      "Yujia Bao",
      "Yang Liu",
      "Wei Wei"
    ],
    "abstract": "Unlearning in Large Language Models (LLMs) is essential for ensuring ethical\nand responsible AI use, especially in addressing privacy leak, bias, safety,\nand evolving regulations. Existing approaches to LLM unlearning often rely on\nretain data or a reference LLM, yet they struggle to adequately balance\nunlearning performance with overall model utility. This challenge arises\nbecause leveraging explicit retain data or implicit knowledge of retain data\nfrom a reference LLM to fine-tune the model tends to blur the boundaries\nbetween the forgotten and retain data, as different queries often elicit\nsimilar responses. In this work, we propose eliminating the need to retain data\nor the reference LLM for response calibration in LLM unlearning. Recognizing\nthat directly applying gradient ascent on the forget data often leads to\noptimization instability and poor performance, our method guides the LLM on\nwhat not to respond to, and importantly, how to respond, based on the forget\ndata. Hence, we introduce Forget data only Loss AjustmenT (FLAT), a \"flat\" loss\nadjustment approach which addresses these issues by maximizing f-divergence\nbetween the available template answer and the forget answer only w.r.t. the\nforget data. The variational form of the defined f-divergence theoretically\nprovides a way of loss adjustment by assigning different importance weights for\nthe learning w.r.t. template responses and the forgetting of responses subject\nto unlearning. Empirical results demonstrate that our approach not only\nachieves superior unlearning performance compared to existing methods but also\nminimizes the impact on the model's retained capabilities, ensuring high\nutility across diverse tasks, including copyrighted content unlearning on Harry\nPotter dataset and MUSE Benchmark, and entity unlearning on the TOFU dataset.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Paper under review",
    "pdf_url": "http://arxiv.org/pdf/2410.11143v1",
    "published_date": "2024-10-14 23:43:33 UTC",
    "updated_date": "2024-10-14 23:43:33 UTC"
  },
  {
    "arxiv_id": "2410.11141v1",
    "title": "Can Structured Data Reduce Epistemic Uncertainty?",
    "authors": [
      "Shriram M S",
      "Sushmitha S",
      "Gayathri K S",
      "Shahina A"
    ],
    "abstract": "In this work, we present a framework that utilizes ontology alignment to\nimprove the learning process of deep learning models. With this approach we\nshow that models fine-tuned using ontologies learn a downstream task at a\nhigher rate with better performance on a sequential classification task\ncompared to the native version of the model. Additionally, we extend our work\nto showcase how subsumption mappings retrieved during the process of ontology\nalignment can help enhance Retrieval-Augmented Generation in Large Language\nModels. The results show that the responses obtained by using subsumption\nmappings show an increase of 8.97% in contextual similarity and a 1% increase\nin factual accuracy. We also use these scores to define our Hallucination Index\nand show that this approach reduces hallucination in LLMs by 4.847%.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Presented at NeLaMKRR@KR, 2024 (arXiv:2410.05339)",
    "pdf_url": "http://arxiv.org/pdf/2410.11141v1",
    "published_date": "2024-10-14 23:38:51 UTC",
    "updated_date": "2024-10-14 23:38:51 UTC"
  },
  {
    "arxiv_id": "2410.11905v1",
    "title": "A Scalable Communication Protocol for Networks of Large Language Models",
    "authors": [
      "Samuele Marro",
      "Emanuele La Malfa",
      "Jesse Wright",
      "Guohao Li",
      "Nigel Shadbolt",
      "Michael Wooldridge",
      "Philip Torr"
    ],
    "abstract": "Communication is a prerequisite for collaboration. When scaling networks of\nAI-powered agents, communication must be versatile, efficient, and portable.\nThese requisites, which we refer to as the Agent Communication Trilemma, are\nhard to achieve in large networks of agents. We introduce Agora, a meta\nprotocol that leverages existing communication standards to make LLM-powered\nagents solve complex problems efficiently. In Agora, agents typically use\nstandardised routines for frequent communications, natural language for rare\ncommunications, and LLM-written routines for everything in between. Agora\nsidesteps the Agent Communication Trilemma and robustly handles changes in\ninterfaces and members, allowing unprecedented scalability with full\ndecentralisation and minimal involvement of human beings. On large Agora\nnetworks, we observe the emergence of self-organising, fully automated\nprotocols that achieve complex goals without human intervention.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "I.2.11; I.2.7"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.11905v1",
    "published_date": "2024-10-14 23:25:13 UTC",
    "updated_date": "2024-10-14 23:25:13 UTC"
  },
  {
    "arxiv_id": "2410.11133v1",
    "title": "3D-Prover: Diversity Driven Theorem Proving With Determinantal Point Processes",
    "authors": [
      "Sean Lamont",
      "Christian Walder",
      "Amir Dezfouli",
      "Paul Montague",
      "Michael Norrish"
    ],
    "abstract": "A key challenge in automated formal reasoning is the intractable search\nspace, which grows exponentially with the depth of the proof. This branching is\ncaused by the large number of candidate proof tactics which can be applied to a\ngiven goal. Nonetheless, many of these tactics are semantically similar or lead\nto an execution error, wasting valuable resources in both cases. We address the\nproblem of effectively pruning this search, using only synthetic data generated\nfrom previous proof attempts. We first demonstrate that it is possible to\ngenerate semantically aware tactic representations which capture the effect on\nthe proving environment, likelihood of success and execution time. We then\npropose a novel filtering mechanism which leverages these representations to\nselect semantically diverse and high quality tactics, using Determinantal Point\nProcesses. Our approach, 3D-Prover, is designed to be general, and to augment\nany underlying tactic generator. We demonstrate the effectiveness of 3D-Prover\non the miniF2F-valid and miniF2F-test benchmarks by augmenting the ReProver\nLLM. We show that our approach leads to an increase in the overall proof rate,\nas well as a significant improvement in the tactic success rate, execution time\nand diversity.",
    "categories": [
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.11133v1",
    "published_date": "2024-10-14 23:13:53 UTC",
    "updated_date": "2024-10-14 23:13:53 UTC"
  },
  {
    "arxiv_id": "2410.11904v1",
    "title": "Personalised Feedback Framework for Online Education Programmes Using Generative AI",
    "authors": [
      "Ievgeniia Kuzminykh",
      "Tareita Nawaz",
      "Shihao Shenzhang",
      "Bogdan Ghita",
      "Jeffery Raphael",
      "Hannan Xiao"
    ],
    "abstract": "AI tools, particularly large language modules, have recently proven their\neffectiveness within learning management systems and online education\nprogrammes. As feedback continues to play a crucial role in learning and\nassessment in schools, educators must carefully customise the use of AI tools\nin order to optimally support students in their learning journey. Efforts to\nimprove educational feedback systems have seen numerous attempts reflected in\nthe research studies but mostly have been focusing on qualitatively\nbenchmarking AI feedback against human-generated feedback. This paper presents\nan exploration of an alternative feedback framework which extends the\ncapabilities of ChatGPT by integrating embeddings, enabling a more nuanced\nunderstanding of educational materials and facilitating topic-targeted feedback\nfor quiz-based assessments. As part of the study, we proposed and developed a\nproof of concept solution, achieving an efficacy rate of 90% and 100% for\nopen-ended and multiple-choice questions, respectively. The results showed that\nour framework not only surpasses expectations but also rivals human narratives,\nhighlighting the potential of AI in revolutionising educational feedback\nmechanisms.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.HC",
    "comment": "Submitted to journal",
    "pdf_url": "http://arxiv.org/pdf/2410.11904v1",
    "published_date": "2024-10-14 22:35:40 UTC",
    "updated_date": "2024-10-14 22:35:40 UTC"
  },
  {
    "arxiv_id": "2410.11120v1",
    "title": "Audio-based Kinship Verification Using Age Domain Conversion",
    "authors": [
      "Qiyang Sun",
      "Alican Akman",
      "Xin Jing",
      "Manuel Milling",
      "Björn W. Schuller"
    ],
    "abstract": "Audio-based kinship verification (AKV) is important in many domains, such as\nhome security monitoring, forensic identification, and social network analysis.\nA key challenge in the task arises from differences in age across samples from\ndifferent individuals, which can be interpreted as a domain bias in a\ncross-domain verification task. To address this issue, we design the notion of\nan \"age-standardised domain\" wherein we utilise the optimised CycleGAN-VC3\nnetwork to perform age-audio conversion to generate the in-domain audio. The\ngenerated audio dataset is employed to extract a range of features, which are\nthen fed into a metric learning architecture to verify kinship. Experiments are\nconducted on the KAN_AV audio dataset, which contains age and kinship labels.\nThe results demonstrate that the method markedly enhances the accuracy of\nkinship verification, while also offering novel insights for future kinship\nverification research.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS",
      "68T10",
      "I.5.4; I.2.6"
    ],
    "primary_category": "cs.SD",
    "comment": "4 pages, 2 figures, submitted to IEEE Signal Processing Letters",
    "pdf_url": "http://arxiv.org/pdf/2410.11120v1",
    "published_date": "2024-10-14 22:08:57 UTC",
    "updated_date": "2024-10-14 22:08:57 UTC"
  },
  {
    "arxiv_id": "2410.11118v1",
    "title": "MoonMetaSync: Lunar Image Registration Analysis",
    "authors": [
      "Ashutosh Kumar",
      "Sarthak Kaushal",
      "Shiv Vignesh Murthy"
    ],
    "abstract": "This paper compares scale-invariant (SIFT) and scale-variant (ORB) feature\ndetection methods, alongside our novel feature detector, IntFeat, specifically\napplied to lunar imagery. We evaluate these methods using low (128x128) and\nhigh-resolution (1024x1024) lunar image patches, providing insights into their\nperformance across scales in challenging extraterrestrial environments. IntFeat\ncombines high-level features from SIFT and low-level features from ORB into a\nsingle vector space for robust lunar image registration. We introduce\nSyncVision, a Python package that compares lunar images using various\nregistration methods, including SIFT, ORB, and IntFeat. Our analysis includes\nupscaling low-resolution lunar images using bi-linear and bi-cubic\ninterpolation, offering a unique perspective on registration effectiveness\nacross scales and feature detectors in lunar landscapes. This research\ncontributes to computer vision and planetary science by comparing feature\ndetection methods for lunar imagery and introducing a versatile tool for lunar\nimage registration and evaluation, with implications for multi-resolution image\nanalysis in space exploration applications.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "math.AG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.11118v1",
    "published_date": "2024-10-14 22:05:48 UTC",
    "updated_date": "2024-10-14 22:05:48 UTC"
  },
  {
    "arxiv_id": "2410.11112v5",
    "title": "Differentiable Weightless Neural Networks",
    "authors": [
      "Alan T. L. Bacellar",
      "Zachary Susskind",
      "Mauricio Breternitz Jr.",
      "Eugene John",
      "Lizy K. John",
      "Priscila M. V. Lima",
      "Felipe M. G. França"
    ],
    "abstract": "We introduce the Differentiable Weightless Neural Network (DWN), a model\nbased on interconnected lookup tables. Training of DWNs is enabled by a novel\nExtended Finite Difference technique for approximate differentiation of binary\nvalues. We propose Learnable Mapping, Learnable Reduction, and Spectral\nRegularization to further improve the accuracy and efficiency of these models.\nWe evaluate DWNs in three edge computing contexts: (1) an FPGA-based hardware\naccelerator, where they demonstrate superior latency, throughput, energy\nefficiency, and model area compared to state-of-the-art solutions, (2) a\nlow-power microcontroller, where they achieve preferable accuracy to XGBoost\nwhile subject to stringent memory constraints, and (3) ultra-low-cost chips,\nwhere they consistently outperform small models in both accuracy and projected\nhardware area. DWNs also compare favorably against leading approaches for\ntabular datasets, with higher average rank. Overall, our work positions DWNs as\na pioneering solution for edge-compatible high-throughput neural networks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.11112v5",
    "published_date": "2024-10-14 21:43:48 UTC",
    "updated_date": "2025-03-02 17:48:06 UTC"
  },
  {
    "arxiv_id": "2410.14721v2",
    "title": "The Representation of Meaningful Precision, and Accuracy",
    "authors": [
      "A Mani"
    ],
    "abstract": "The concepts of precision, and accuracy are domain and problem dependent. The\nsimplified numeric hard and soft measures used in the fields of statistical\nlearning, many types of machine learning, and binary or multiclass\nclassification problems are known to be of limited use for understanding the\nmeaningfulness of models or their relevance. Arguably, they are neither of\npatterns nor proofs. Further, there are no good measures or representations for\nanalogous concepts in the cognition domain. In this research, the key issues\nare reflected upon, and a compositional knowledge representation approach in a\nminimalist general rough framework is proposed for the problem contexts. The\nlatter is general enough to cover most application contexts, and may be\napplicable in the light of improved computational tools available.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.LO",
      "68T30, 68T37, 03G25"
    ],
    "primary_category": "cs.AI",
    "comment": "16 Pages",
    "pdf_url": "http://arxiv.org/pdf/2410.14721v2",
    "published_date": "2024-10-14 21:33:38 UTC",
    "updated_date": "2024-10-25 08:58:27 UTC"
  },
  {
    "arxiv_id": "2410.11097v2",
    "title": "DMOSpeech: Direct Metric Optimization via Distilled Diffusion Model in Zero-Shot Speech Synthesis",
    "authors": [
      "Yingahao Aaron Li",
      "Rithesh Kumar",
      "Zeyu Jin"
    ],
    "abstract": "Diffusion models have demonstrated significant potential in speech synthesis\ntasks, including text-to-speech (TTS) and voice cloning. However, their\niterative denoising processes are computationally intensive, and previous\ndistillation attempts have shown consistent quality degradation. Moreover,\nexisting TTS approaches are limited by non-differentiable components or\niterative sampling that prevent true end-to-end optimization with perceptual\nmetrics. We introduce DMOSpeech, a distilled diffusion-based TTS model that\nuniquely achieves both faster inference and superior performance compared to\nits teacher model. By enabling direct gradient pathways to all model\ncomponents, we demonstrate the first successful end-to-end optimization of\ndifferentiable metrics in TTS, incorporating Connectionist Temporal\nClassification (CTC) loss and Speaker Verification (SV) loss. Our comprehensive\nexperiments, validated through extensive human evaluation, show significant\nimprovements in naturalness, intelligibility, and speaker similarity while\nreducing inference time by orders of magnitude. This work establishes a new\nframework for aligning speech synthesis with human auditory preferences through\ndirect metric optimization. The audio samples are available at\nhttps://dmospeech.github.io/.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.SD"
    ],
    "primary_category": "eess.AS",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.11097v2",
    "published_date": "2024-10-14 21:17:58 UTC",
    "updated_date": "2025-02-20 02:07:55 UTC"
  },
  {
    "arxiv_id": "2410.11096v1",
    "title": "SecCodePLT: A Unified Platform for Evaluating the Security of Code GenAI",
    "authors": [
      "Yu Yang",
      "Yuzhou Nie",
      "Zhun Wang",
      "Yuheng Tang",
      "Wenbo Guo",
      "Bo Li",
      "Dawn Song"
    ],
    "abstract": "Existing works have established multiple benchmarks to highlight the security\nrisks associated with Code GenAI. These risks are primarily reflected in two\nareas: a model potential to generate insecure code (insecure coding) and its\nutility in cyberattacks (cyberattack helpfulness). While these benchmarks have\nmade significant strides, there remain opportunities for further improvement.\nFor instance, many current benchmarks tend to focus more on a model ability to\nprovide attack suggestions rather than its capacity to generate executable\nattacks. Additionally, most benchmarks rely heavily on static evaluation\nmetrics, which may not be as precise as dynamic metrics such as passing test\ncases. Conversely, expert-verified benchmarks, while offering high-quality\ndata, often operate at a smaller scale. To address these gaps, we develop\nSecCodePLT, a unified and comprehensive evaluation platform for code GenAIs'\nrisks. For insecure code, we introduce a new methodology for data creation that\ncombines experts with automatic generation. Our methodology ensures the data\nquality while enabling large-scale generation. We also associate samples with\ntest cases to conduct code-related dynamic evaluation. For cyberattack\nhelpfulness, we set up a real environment and construct samples to prompt a\nmodel to generate actual attacks, along with dynamic metrics in our\nenvironment. We conduct extensive experiments and show that SecCodePLT\noutperforms the state-of-the-art (SOTA) benchmark CyberSecEval in security\nrelevance. Furthermore, it better identifies the security risks of SOTA models\nin insecure coding and cyberattack helpfulness. Finally, we apply SecCodePLT to\nthe SOTA code agent, Cursor, and, for the first time, identify non-trivial\nsecurity risks in this advanced coding agent.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.11096v1",
    "published_date": "2024-10-14 21:17:22 UTC",
    "updated_date": "2024-10-14 21:17:22 UTC"
  },
  {
    "arxiv_id": "2410.11092v3",
    "title": "EchoApex: A General-Purpose Vision Foundation Model for Echocardiography",
    "authors": [
      "Abdoul Aziz Amadou",
      "Yue Zhang",
      "Sebastien Piat",
      "Paul Klein",
      "Ingo Schmuecking",
      "Tiziano Passerini",
      "Puneet Sharma"
    ],
    "abstract": "Quantitative evaluation of echocardiography is essential for precise\nassessment of cardiac condition, monitoring disease progression, and guiding\ntreatment decisions. The diverse nature of echo images, including variations in\nprobe types, manufacturers, and pathologies, poses challenges for developing\nartificial intelligent models that can generalize across different clinical\npractice. We introduce EchoApex, the first general-purpose vision foundation\nmodel echocardiography with applications on a variety of clinical practice.\nLeveraging self-supervised learning, EchoApex is pretrained on over 20 million\necho images from 11 clinical centres. By incorporating task-specific decoders\nand adapter modules, we demonstrate the effectiveness of EchoApex on 4\ndifferent kind of clinical applications with 28 sub-tasks, including view\nclassification, interactive structure segmentation, left ventricle hypertrophy\ndetection and automated ejection fraction estimation from view sequences.\nCompared to state-of-the-art task-specific models, EchoApex attains improved\nperformance with a unified image encoding architecture, demonstrating the\nbenefits of model pretraining at scale with in-domain data. Furthermore,\nEchoApex illustrates the potential for developing a general-purpose vision\nfoundation model tailored specifically for echocardiography, capable of\naddressing a diverse range of clinical applications with high efficiency and\nefficacy.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.11092v3",
    "published_date": "2024-10-14 21:10:56 UTC",
    "updated_date": "2024-10-24 20:57:00 UTC"
  },
  {
    "arxiv_id": "2410.11080v1",
    "title": "Few-shot Novel View Synthesis using Depth Aware 3D Gaussian Splatting",
    "authors": [
      "Raja Kumar",
      "Vanshika Vats"
    ],
    "abstract": "3D Gaussian splatting has surpassed neural radiance field methods in novel\nview synthesis by achieving lower computational costs and real-time\nhigh-quality rendering. Although it produces a high-quality rendering with a\nlot of input views, its performance drops significantly when only a few views\nare available. In this work, we address this by proposing a depth-aware\nGaussian splatting method for few-shot novel view synthesis. We use monocular\ndepth prediction as a prior, along with a scale-invariant depth loss, to\nconstrain the 3D shape under just a few input views. We also model color using\nlower-order spherical harmonics to avoid overfitting. Further, we observe that\nremoving splats with lower opacity periodically, as performed in the original\nwork, leads to a very sparse point cloud and, hence, a lower-quality rendering.\nTo mitigate this, we retain all the splats, leading to a better reconstruction\nin a few view settings. Experimental results show that our method outperforms\nthe traditional 3D Gaussian splatting methods by achieving improvements of\n10.5% in peak signal-to-noise ratio, 6% in structural similarity index, and\n14.1% in perceptual similarity, thereby validating the effectiveness of our\napproach. The code will be made available at:\nhttps://github.com/raja-kumar/depth-aware-3DGS",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR"
    ],
    "primary_category": "cs.CV",
    "comment": "Presented in ECCV 2024 workshop S3DSGR",
    "pdf_url": "http://arxiv.org/pdf/2410.11080v1",
    "published_date": "2024-10-14 20:42:30 UTC",
    "updated_date": "2024-10-14 20:42:30 UTC"
  },
  {
    "arxiv_id": "2410.11079v1",
    "title": "Code-Mixer Ya Nahi: Novel Approaches to Measuring Multilingual LLMs' Code-Mixing Capabilities",
    "authors": [
      "Ayushman Gupta",
      "Akhil Bhogal",
      "Kripabandhu Ghosh"
    ],
    "abstract": "Multilingual Large Language Models (LLMs) have demonstrated exceptional\nperformance in Machine Translation (MT) tasks. However, their MT abilities in\nthe context of code-switching (the practice of mixing two or more languages in\nan utterance) remain under-explored. In this paper, we introduce Rule-Based\nPrompting, a novel prompting technique to generate code-mixed sentences. We\nmeasure and compare the code-mixed MT abilities of 3 popular multilingual LLMs:\nGPT-3.5-turbo, GPT-4, and Gemini Pro across five language pairs:\nEnglish-{Hindi, Bengali, Gujarati, French, Spanish} using $k$-shot prompting\n($k\\in\\{0, 1, 10, 20\\}$) and Rule-Based Prompting. Our findings suggest that\nthough $k$-shot prompting often leads to the best results, Rule-Based prompting\nshows promise in generating unique code-mixed sentences that vary in their\nstyle of code-mixing. We also use $k$-shot prompting to gauge the code-mixed to\nEnglish translation abilities of multilingual LLMs. For this purpose, we create\na gold-standard code-mixed dataset spanning five language pairs:\nEnglish-{Hindi, Bengali, Gujarati, French, Spanish}. As a real-world\napplication of our work, we create a code-mixed chatbot.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Manuscript submitted to COLING 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.11079v1",
    "published_date": "2024-10-14 20:40:36 UTC",
    "updated_date": "2024-10-14 20:40:36 UTC"
  },
  {
    "arxiv_id": "2410.11076v1",
    "title": "PRACTIQ: A Practical Conversational Text-to-SQL dataset with Ambiguous and Unanswerable Queries",
    "authors": [
      "Mingwen Dong",
      "Nischal Ashok Kumar",
      "Yiqun Hu",
      "Anuj Chauhan",
      "Chung-Wei Hang",
      "Shuaichen Chang",
      "Lin Pan",
      "Wuwei Lan",
      "Henghui Zhu",
      "Jiarong Jiang",
      "Patrick Ng",
      "Zhiguo Wang"
    ],
    "abstract": "Previous text-to-SQL datasets and systems have primarily focused on user\nquestions with clear intentions that can be answered. However, real user\nquestions can often be ambiguous with multiple interpretations or unanswerable\ndue to a lack of relevant data. In this work, we construct a practical\nconversational text-to-SQL dataset called PRACTIQ, consisting of ambiguous and\nunanswerable questions inspired by real-world user questions. We first\nidentified four categories of ambiguous questions and four categories of\nunanswerable questions by studying existing text-to-SQL datasets. Then, we\ngenerate conversations with four turns: the initial user question, an assistant\nresponse seeking clarification, the user's clarification, and the assistant's\nclarified SQL response with the natural language explanation of the execution\nresults. For some ambiguous queries, we also directly generate helpful SQL\nresponses, that consider multiple aspects of ambiguity, instead of requesting\nuser clarification. To benchmark the performance on ambiguous, unanswerable,\nand answerable questions, we implemented large language model (LLM)-based\nbaselines using various LLMs. Our approach involves two steps: question\ncategory classification and clarification SQL prediction. Our experiments\nreveal that state-of-the-art systems struggle to handle ambiguous and\nunanswerable questions effectively. We will release our code for data\ngeneration and experiments on GitHub.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.11076v1",
    "published_date": "2024-10-14 20:36:35 UTC",
    "updated_date": "2024-10-14 20:36:35 UTC"
  },
  {
    "arxiv_id": "2410.11064v2",
    "title": "Parsing altered brain connectivity in neurodevelopmental disorders by integrating graph-based normative modeling and deep generative networks",
    "authors": [
      "Rui Sherry Shen",
      "Yusuf Osmanlıoğlu",
      "Drew Parker",
      "Darien Aunapu",
      "Benjamin E. Yerys",
      "Birkan Tunç",
      "Ragini Verma"
    ],
    "abstract": "Divergent brain connectivity is thought to underlie the behavioral and\ncognitive symptoms observed in many neurodevelopmental disorders. Quantifying\ndivergence from neurotypical connectivity patterns offers a promising pathway\nto inform diagnosis and therapeutic interventions. While advanced neuroimaging\ntechniques, such as diffusion MRI (dMRI), have facilitated the mapping of\nbrain's structural connectome, the challenge lies in accurately modeling\ndevelopmental trajectories within these complex networked structures to create\nrobust neurodivergence markers. In this work, we present the Brain\nRepresentation via Individualized Deep Generative Embedding (BRIDGE) framework,\nwhich integrates normative modeling with a bio-inspired deep generative model\nto create a reference trajectory of connectivity transformation as part of\nneurotypical development. This will enable the assessment of neurodivergence by\ncomparing individuals to the established neurotypical trajectory. BRIDGE\nprovides a global neurodivergence score based on the difference between\nconnectivity-based brain age and chronological age, along with region-wise\nneurodivergence maps that highlight localized connectivity differences.\nApplication of BRIDGE to a large cohort of children with autism spectrum\ndisorder demonstrates that the global neurodivergence score correlates with\nclinical assessments in autism, and the regional map offers insights into the\nheterogeneity at the individual level in neurodevelopmental disorders.\nTogether, the neurodivergence score and map form powerful tools for quantifying\ndevelopmental divergence in connectivity patterns, advancing the development of\nimaging markers for personalized diagnosis and intervention in various clinical\ncontexts.",
    "categories": [
      "q-bio.NC",
      "cs.AI",
      "q-bio.QM"
    ],
    "primary_category": "q-bio.NC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.11064v2",
    "published_date": "2024-10-14 20:21:11 UTC",
    "updated_date": "2024-11-18 15:29:05 UTC"
  },
  {
    "arxiv_id": "2410.11063v1",
    "title": "Towards the methodology for solving the minimum enclosing ball and related problems",
    "authors": [
      "Michael N. Vrahatis"
    ],
    "abstract": "Methodology is provided towards the solution of the minimum enclosing ball\nproblem. This problem concerns the determination of the unique spherical\nsurface of smallest radius enclosing a given bounded set in the d-dimensional\nEuclidean space. Mathematical formulation and typical methods for solving this\nproblem are presented. Also, the paper is focused on areas that are related to\nthis problem, namely: (a) promise problems and property testing, (b) theorems\nfor partitioning and enclosing (covering) a set, and (c) computation of the\ndiameter of a set.",
    "categories": [
      "cs.CG",
      "cs.AI",
      "math.GT"
    ],
    "primary_category": "cs.CG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.11063v1",
    "published_date": "2024-10-14 20:20:04 UTC",
    "updated_date": "2024-10-14 20:20:04 UTC"
  },
  {
    "arxiv_id": "2410.11062v2",
    "title": "CleanUMamba: A Compact Mamba Network for Speech Denoising using Channel Pruning",
    "authors": [
      "Sjoerd Groot",
      "Qinyu Chen",
      "Jan C. van Gemert",
      "Chang Gao"
    ],
    "abstract": "This paper presents CleanUMamba, a time-domain neural network architecture\ndesigned for real-time causal audio denoising directly applied to raw\nwaveforms. CleanUMamba leverages a U-Net encoder-decoder structure,\nincorporating the Mamba state-space model in the bottleneck layer. By replacing\nconventional self-attention and LSTM mechanisms with Mamba, our architecture\noffers superior denoising performance while maintaining a constant memory\nfootprint, enabling streaming operation. To enhance efficiency, we applied\nstructured channel pruning, achieving an 8X reduction in model size without\ncompromising audio quality. Our model demonstrates strong results in the\nInterspeech 2020 Deep Noise Suppression challenge. Specifically, CleanUMamba\nachieves a PESQ score of 2.42 and STOI of 95.1% with only 442K parameters and\n468M MACs, matching or outperforming larger models in real-time performance.\nCode will be available at: https://github.com/lab-emi/CleanUMamba",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CV",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "This paper has been accepted to be presented at the 2025\n  International Symposium on Circuits and Systems (ISCAS)",
    "pdf_url": "http://arxiv.org/pdf/2410.11062v2",
    "published_date": "2024-10-14 20:18:03 UTC",
    "updated_date": "2025-02-10 18:07:54 UTC"
  },
  {
    "arxiv_id": "2410.11059v1",
    "title": "Assessing Bias in Metric Models for LLM Open-Ended Generation Bias Benchmarks",
    "authors": [
      "Nathaniel Demchak",
      "Xin Guan",
      "Zekun Wu",
      "Ziyi Xu",
      "Adriano Koshiyama",
      "Emre Kazim"
    ],
    "abstract": "Open-generation bias benchmarks evaluate social biases in Large Language\nModels (LLMs) by analyzing their outputs. However, the classifiers used in\nanalysis often have inherent biases, leading to unfair conclusions. This study\nexamines such biases in open-generation benchmarks like BOLD and SAGED. Using\nthe MGSD dataset, we conduct two experiments. The first uses counterfactuals to\nmeasure prediction variations across demographic groups by altering\nstereotype-related prefixes. The second applies explainability tools (SHAP) to\nvalidate that the observed biases stem from these counterfactuals. Results\nreveal unequal treatment of demographic descriptors, calling for more robust\nbias metric models.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "NeurIPS 2024 EvalEval Workshop",
    "pdf_url": "http://arxiv.org/pdf/2410.11059v1",
    "published_date": "2024-10-14 20:08:40 UTC",
    "updated_date": "2024-10-14 20:08:40 UTC"
  },
  {
    "arxiv_id": "2410.11055v1",
    "title": "Varying Shades of Wrong: Aligning LLMs with Wrong Answers Only",
    "authors": [
      "Jihan Yao",
      "Wenxuan Ding",
      "Shangbin Feng",
      "Lucy Lu Wang",
      "Yulia Tsvetkov"
    ],
    "abstract": "In the absence of abundant reliable annotations for challenging tasks and\ncontexts, how can we expand the frontier of LLM capabilities with potentially\nwrong answers? We focus on two research questions: (1) Can LLMs generate\nreliable preferences among wrong options? And if so, (2) Would alignment with\nsuch wrong-over-wrong preferences be helpful? We employ methods based on\nself-consistency, token probabilities, and LLM-as-a-judge to elicit\nwrong-over-wrong preferences, and fine-tune language models with preference\noptimization approaches using these synthesized preferences. Extensive\nexperiments with seven LLMs and eight datasets demonstrate that (1) LLMs do\nhave preliminary capability in distinguishing various shades of wrong,\nachieving up to 20.9% higher performance than random guess; (2) Alignment with\nwrong-over-wrong preferences helps LLMs to produce less wrong and sometimes\neven outright correct answers, while overall improving model calibration.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.11055v1",
    "published_date": "2024-10-14 20:01:52 UTC",
    "updated_date": "2024-10-14 20:01:52 UTC"
  },
  {
    "arxiv_id": "2410.11900v4",
    "title": "FLARE: Faithful Logic-Aided Reasoning and Exploration",
    "authors": [
      "Erik Arakelyan",
      "Pasquale Minervini",
      "Pat Verga",
      "Patrick Lewis",
      "Isabelle Augenstein"
    ],
    "abstract": "Modern Question Answering (QA) and Reasoning approaches based on Large\nLanguage Models (LLMs) commonly use prompting techniques, such as\nChain-of-Thought (CoT), assuming the resulting generation will have a more\ngranular exploration and reasoning over the question space and scope. However,\nsuch methods struggle with generating outputs that are faithful to the\nintermediate chain of reasoning produced by the model. On the other end of the\nspectrum, neuro-symbolic methods such as Faithful CoT (F-CoT) propose to\ncombine LLMs with external symbolic solvers. While such approaches boast a high\ndegree of faithfulness, they usually require a model trained for code\ngeneration and struggle with tasks that are ambiguous or hard to formalise\nstrictly. We introduce $\\textbf{F}$aithful $\\textbf{L}$ogic-$\\textbf{A}$ided\n$\\textbf{R}$easoning and $\\textbf{E}$xploration ($\\textbf{FLARE}$), a novel\ninterpretable approach for traversing the problem space using task\ndecompositions. We use the LLM to plan a solution, soft-formalise the query\ninto facts and predicates using a logic programming code and simulate that code\nexecution using an exhaustive multi-hop search over the defined space. Our\nmethod allows us to compute the faithfulness of the reasoning process w.r.t.\nthe generated code and analyse the steps of the multi-hop search without\nrelying on external solvers. Our methods achieve SOTA results on $\\mathbf{7}$\nout of $\\mathbf{9}$ diverse reasoning benchmarks. We also show that model\nfaithfulness positively correlates with overall performance and further\ndemonstrate that $\\textbf{FLARE}$ allows pinpointing the decisive factors\nsufficient for and leading to the correct answer with optimal reasoning during\nthe multi-hop search.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.11900v4",
    "published_date": "2024-10-14 19:39:11 UTC",
    "updated_date": "2025-01-21 14:57:22 UTC"
  },
  {
    "arxiv_id": "2410.11038v1",
    "title": "Towards a More Complete Theory of Function Preserving Transforms",
    "authors": [
      "Michael Painter"
    ],
    "abstract": "In this paper, we develop novel techniques that can be used to alter the\narchitecture of a neural network, while maintaining the function it represents.\nSuch operations are known as function preserving transforms and have proven\nuseful in transferring knowledge between networks to evaluate architectures\nquickly, thus having applications in efficient architectures searches. Our\nmethods allow the integration of residual connections into function preserving\ntransforms, so we call them R2R. We provide a derivation for R2R and show that\nit yields competitive performance with other function preserving transforms,\nthereby decreasing the restrictions on deep learning architectures that can be\nextended through function preserving transforms. We perform a comparative\nanalysis with other function preserving transforms such as Net2Net and Network\nMorphisms, where we shed light on their differences and individual use cases.\nFinally, we show the effectiveness of R2R to train models quickly, as well as\nits ability to learn a more diverse set of filters on image classification\ntasks compared to Net2Net and Network Morphisms.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.11038v1",
    "published_date": "2024-10-14 19:37:45 UTC",
    "updated_date": "2024-10-14 19:37:45 UTC"
  },
  {
    "arxiv_id": "2410.11031v2",
    "title": "NAR-*ICP: Neural Execution of Classical ICP-based Pointcloud Registration Algorithms",
    "authors": [
      "Efimia Panagiotaki",
      "Daniele De Martini",
      "Lars Kunze",
      "Petar Veličković"
    ],
    "abstract": "This study explores the intersection of neural networks and classical\nrobotics algorithms through the Neural Algorithmic Reasoning (NAR) framework,\nallowing to train neural networks to effectively reason like classical robotics\nalgorithms by learning to execute them. Algorithms are integral to robotics and\nsafety-critical applications due to their predictable and consistent\nperformance through logical and mathematical principles. In contrast, while\nneural networks are highly adaptable, handling complex, high-dimensional data\nand generalising across tasks, they often lack interpretability and\ntransparency in their internal computations. We propose a Graph Neural Network\n(GNN)-based learning framework, NAR-*ICP, which learns the intermediate\nalgorithmic steps of classical ICP-based pointcloud registration algorithms,\nand extend the CLRS Algorithmic Reasoning Benchmark with classical robotics\nperception algorithms. We evaluate our approach across diverse datasets, from\nreal-world to synthetic, demonstrating its flexibility in handling complex and\nnoisy inputs, along with its potential to be used as part of a larger learning\nsystem. Our results indicate that our method achieves superior performance\nacross all benchmarks and datasets, consistently surpassing even the algorithms\nit has been trained on, further demonstrating its ability to generalise beyond\nthe capabilities of traditional algorithms.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "17 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.11031v2",
    "published_date": "2024-10-14 19:33:46 UTC",
    "updated_date": "2024-10-16 14:05:57 UTC"
  },
  {
    "arxiv_id": "2410.11020v3",
    "title": "Improving the Language Understanding Capabilities of Large Language Models Using Reinforcement Learning",
    "authors": [
      "Bokai Hu",
      "Sai Ashish Somayajula",
      "Xin Pan",
      "Zihan Huang",
      "Pengtao Xie"
    ],
    "abstract": "Large language models (LLMs), built on decoder-only transformers, excel in\nnatural language generation and adapt to diverse tasks using zero-shot and\nfew-shot prompting. However, these prompting methods often struggle on natural\nlanguage understanding (NLU) tasks, where encoder-only models like BERT-base\noutperform LLMs on benchmarks like GLUE and SuperGLUE. This paper explores two\napproaches-supervised fine-tuning (SFT) and proximal policy optimization\n(PPO)-to enhance LLMs' NLU abilities. To reduce the cost of full-model\nfine-tuning, we integrate low-rank adaptation (LoRA) layers, limiting updates\nto these layers during both SFT and PPO. In SFT, task-specific prompts are\nconcatenated with input queries and ground-truth labels, optimizing with\nnext-token prediction. Despite this, LLMs still underperform compared to models\nlike BERT-base on several NLU tasks. To close this gap, we apply PPO, a\nreinforcement learning technique that treats each token generation as an action\nand uses a reward function based on alignment with ground-truth answers. PPO\nthen updates the model to maximize these rewards, aligning outputs with correct\nlabels. Our experiments with LLAMA2-7B show that PPO improves performance, with\na 6.3-point gain over SFT on GLUE. PPO exceeds zero-shot by 38.7 points and\nfew-shot by 26.1 points on GLUE, while surpassing these by 28.8 and 28.5 points\non SuperGLUE. Additionally, PPO outperforms BERT-large by 2.7 points on GLUE\nand 9.3 points on SuperGLUE. The improvements are consistent across models like\nQwen2.5-7B and MPT-7B, highlighting PPO's robustness in enhancing LLMs' NLU\ncapabilities.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.11020v3",
    "published_date": "2024-10-14 19:16:56 UTC",
    "updated_date": "2024-10-22 00:42:39 UTC"
  },
  {
    "arxiv_id": "2410.13894v1",
    "title": "Deep Learning Based XIoT Malware Analysis: A Comprehensive Survey, Taxonomy, and Research Challenges",
    "authors": [
      "Rami Darwish",
      "Mahmoud Abdelsalam",
      "Sajad Khorsandroo"
    ],
    "abstract": "The Internet of Things (IoT) is one of the fastest-growing computing\nindustries. By the end of 2027, more than 29 billion devices are expected to be\nconnected. These smart devices can communicate with each other with and without\nhuman intervention. This rapid growth has led to the emergence of new types of\nmalware. However, traditional malware detection methods, such as\nsignature-based and heuristic-based techniques, are becoming increasingly\nineffective against these new types of malware. Therefore, it has become\nindispensable to find practical solutions for detecting IoT malware. Machine\nLearning (ML) and Deep Learning (DL) approaches have proven effective in\ndealing with these new IoT malware variants, exhibiting high detection rates.\nIn this paper, we bridge the gap in research between the IoT malware analysis\nand the wide adoption of deep learning in tackling the problems in this domain.\nAs such, we provide a comprehensive review on deep learning based malware\nanalysis across various categories of the IoT domain (i.e. Extended Internet of\nThings (XIoT)), including Industrial IoT (IIoT), Internet of Medical Things\n(IoMT), Internet of Vehicles (IoV), and Internet of Battlefield Things (IoBT).",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.13894v1",
    "published_date": "2024-10-14 19:04:43 UTC",
    "updated_date": "2024-10-14 19:04:43 UTC"
  },
  {
    "arxiv_id": "2410.11009v1",
    "title": "Enhancing AI Assisted Writing with One-Shot Implicit Negative Feedback",
    "authors": [
      "Benjamin Towle",
      "Ke Zhou"
    ],
    "abstract": "AI-mediated communication enables users to communicate more quickly and\nefficiently. Various systems have been proposed such as smart reply and\nAI-assisted writing. Yet, the heterogeneity of the forms of inputs and\narchitectures often renders it challenging to combine insights from user\nbehaviour in one system to improve performance in another. In this work, we\nconsider the case where the user does not select any of the suggested replies\nfrom a smart reply system, and how this can be used as one-shot implicit\nnegative feedback to enhance the accuracy of an AI writing model. We introduce\nNifty, an approach that uses classifier guidance to controllably integrate\nimplicit user feedback into the text generation process. Empirically, we find\nup to 34% improvement in Rouge-L, 89% improvement in generating the correct\nintent, and an 86% win-rate according to human evaluators compared to a vanilla\nAI writing system on the MultiWOZ and Schema-Guided Dialog datasets.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to appear at EMNLP 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.11009v1",
    "published_date": "2024-10-14 18:50:28 UTC",
    "updated_date": "2024-10-14 18:50:28 UTC"
  },
  {
    "arxiv_id": "2410.11001v1",
    "title": "Graph of Records: Boosting Retrieval Augmented Generation for Long-context Summarization with Graphs",
    "authors": [
      "Haozhen Zhang",
      "Tao Feng",
      "Jiaxuan You"
    ],
    "abstract": "Retrieval-augmented generation (RAG) has revitalized Large Language Models\n(LLMs) by injecting non-parametric factual knowledge. Compared with\nlong-context LLMs, RAG is considered an effective summarization tool in a more\nconcise and lightweight manner, which can interact with LLMs multiple times\nusing diverse queries to get comprehensive responses. However, the\nLLM-generated historical responses, which contain potentially insightful\ninformation, are largely neglected and discarded by existing approaches,\nleading to suboptimal results. In this paper, we propose \\textit{graph of\nrecords} (\\textbf{GoR}), which leverages historical responses generated by LLMs\nto enhance RAG for long-context global summarization. Inspired by the\n\\textit{retrieve-then-generate} paradigm of RAG, we construct a graph by\nestablishing an edge between the retrieved text chunks and the corresponding\nLLM-generated response. To further uncover the intricate correlations between\nthem, GoR further features a \\textit{graph neural network} and an elaborately\ndesigned \\textit{BERTScore}-based objective for self-supervised model training,\nenabling seamless supervision signal backpropagation between reference\nsummaries and node embeddings. We comprehensively compare GoR with 12 baselines\nacross four long-context summarization datasets, and the results indicate that\nour proposed method reaches the best performance e.g., 15\\%, 8\\%, and 19\\%\nimprovement over retrievers w.r.t. Rouge-L, Rouge-1, and Rouge-2 on the WCEP\ndataset). Extensive experiments further demonstrate the effectiveness of GoR.\nCode is available at https://github.com/ulab-uiuc/GoR",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.11001v1",
    "published_date": "2024-10-14 18:34:29 UTC",
    "updated_date": "2024-10-14 18:34:29 UTC"
  },
  {
    "arxiv_id": "2410.11000v1",
    "title": "Generating Global and Local Explanations for Tree-Ensemble Learning Methods by Answer Set Programming",
    "authors": [
      "Akihiro Takemura",
      "Katsumi Inoue"
    ],
    "abstract": "We propose a method for generating rule sets as global and local explanations\nfor tree-ensemble learning methods using Answer Set Programming (ASP). To this\nend, we adopt a decompositional approach where the split structures of the base\ndecision trees are exploited in the construction of rules, which in turn are\nassessed using pattern mining methods encoded in ASP to extract explanatory\nrules. For global explanations, candidate rules are chosen from the entire\ntrained tree-ensemble models, whereas for local explanations, candidate rules\nare selected by only considering rules that are relevant to the particular\npredicted instance. We show how user-defined constraints and preferences can be\nrepresented declaratively in ASP to allow for transparent and flexible rule set\ngeneration, and how rules can be used as explanations to help the user better\nunderstand the models. Experimental evaluation with real-world datasets and\npopular tree-ensemble algorithms demonstrates that our approach is applicable\nto a wide range of classification tasks. Under consideration in Theory and\nPractice of Logic Programming (TPLP).",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Under consideration in Theory and Practice of Logic Programming\n  (TPLP). Some parts of this paper were presented at ICLP 2021, and published\n  in EPTCS 345, 2021, pp. 127-140, arXiv:2109.08290",
    "pdf_url": "http://arxiv.org/pdf/2410.11000v1",
    "published_date": "2024-10-14 18:32:29 UTC",
    "updated_date": "2024-10-14 18:32:29 UTC"
  },
  {
    "arxiv_id": "2410.10998v1",
    "title": "WILT: A Multi-Turn, Memorization-Robust Inductive Logic Benchmark for LLMs",
    "authors": [
      "Eryk Banatt",
      "Jonathan Cheng",
      "Skanda Vaidyanath",
      "Tiffany Hwu"
    ],
    "abstract": "While large language models have shown impressive capabilities across a wide\nrange of domains, they still encounter significant challenges in reasoning\ntasks that require gathering evidence over multiple turns and drawing logical\nconclusions. These challenges present significant obstacles for LLM chat user\ninterfaces, which rely on multi-turn interactions to facilitate effective\ncollaboration. This limitation leads to real-world issues; for example, service\nchatbots must gather necessary information from customers over multiple turns\nto diagnose and resolve problems effectively. Despite the multi-turn nature of\nmany real-world LLM use cases, most existing benchmarks rely on carefully\ncurated single-turn tests, which often blur the line between memorization and\ngenuine reasoning. To address this, we introduce the Wason Inductive Logic Test\n(WILT), a simple yet challenging multi-turn reasoning benchmark designed to\nresist memorization. WILT is inspired by the Wason 2-4-6 task, where\nparticipants must infer a boolean function involving three variables (e.g., $x\n< y < z$) by proposing test cases (such as $(2, 4, 6)$). In WILT, each test\nstarts from a clean slate, with only the initial instructions provided,\npreventing models from relying on pre-learned responses. Over several turns,\nmodels must interact with the environment by suggesting test cases to narrow\nthe possible hypotheses and ultimately infer the hidden function based on the\noutcomes. Our findings reveal that LLMs struggle with this task, exhibiting\ndistinct strengths and weaknesses: some are better at narrowing down the\nhypothesis space by proposing valuable test cases, while others are more adept\nat deducing the hidden function from observed cases. Despite these variations,\nthe best-performing model achieves only 28% accuracy, highlighting a\nsignificant gap in LLM performance on complex multi-turn reasoning tasks.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Submitted to ICLR 2025. Preprint version 1",
    "pdf_url": "http://arxiv.org/pdf/2410.10998v1",
    "published_date": "2024-10-14 18:29:13 UTC",
    "updated_date": "2024-10-14 18:29:13 UTC"
  },
  {
    "arxiv_id": "2410.10989v3",
    "title": "Liger Kernel: Efficient Triton Kernels for LLM Training",
    "authors": [
      "Pin-Lun Hsu",
      "Yun Dai",
      "Vignesh Kothapalli",
      "Qingquan Song",
      "Shao Tang",
      "Siyu Zhu",
      "Steven Shimizu",
      "Shivam Sahni",
      "Haowen Ning",
      "Yanning Chen"
    ],
    "abstract": "Training Large Language Models (LLMs) efficiently at scale presents a\nformidable challenge, driven by their ever-increasing computational demands and\nthe need for enhanced performance. In this work, we introduce Liger-Kernel, an\nopen-sourced set of Triton kernels developed specifically for LLM training.\nWith kernel optimization techniques like kernel operation fusing and input\nchunking, our kernels achieve on average a 20% increase in training throughput\nand a 60% reduction in GPU memory usage for popular LLMs compared to\nHuggingFace implementations. In addition, Liger-Kernel is designed with\nmodularity, accessibility, and adaptability in mind, catering to both casual\nand expert users. Comprehensive benchmarks and integration tests are built in\nto ensure compatibility, performance, correctness, and convergence across\ndiverse computing environments and model architectures.\n  The source code is available under a permissive license at:\ngithub.com/linkedin/Liger-Kernel.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "17 pages, 12 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.10989v3",
    "published_date": "2024-10-14 18:17:01 UTC",
    "updated_date": "2025-01-24 00:14:55 UTC"
  },
  {
    "arxiv_id": "2410.10818v2",
    "title": "TemporalBench: Benchmarking Fine-grained Temporal Understanding for Multimodal Video Models",
    "authors": [
      "Mu Cai",
      "Reuben Tan",
      "Jianrui Zhang",
      "Bocheng Zou",
      "Kai Zhang",
      "Feng Yao",
      "Fangrui Zhu",
      "Jing Gu",
      "Yiwu Zhong",
      "Yuzhang Shang",
      "Yao Dou",
      "Jaden Park",
      "Jianfeng Gao",
      "Yong Jae Lee",
      "Jianwei Yang"
    ],
    "abstract": "Understanding fine-grained temporal dynamics is crucial for multimodal video\ncomprehension and generation. Due to the lack of fine-grained temporal\nannotations, existing video benchmarks mostly resemble static image benchmarks\nand are incompetent at evaluating models for temporal understanding. In this\npaper, we introduce TemporalBench, a new benchmark dedicated to evaluating\nfine-grained temporal understanding in videos. TemporalBench consists of ~10K\nvideo question-answer pairs, derived from ~2K high-quality human annotations\ndetailing the temporal dynamics in video clips. As a result, our benchmark\nprovides a unique testbed for evaluating various temporal understanding and\nreasoning abilities such as action frequency, motion magnitude, event order,\netc. Moreover, it enables evaluations on various tasks like both video question\nanswering and captioning, both short and long video understanding, as well as\ndifferent models such as multimodal video embedding models and text generation\nmodels. Results show that state-of-the-art models like GPT-4o achieve only\n38.5% question answering accuracy on TemporalBench, demonstrating a significant\ngap (~30%) between humans and AI in temporal understanding. Furthermore, we\nnotice a critical pitfall for multi-choice QA where LLMs can detect the subtle\nchanges in negative captions and find a centralized description as a cue for\nits prediction, where we propose Multiple Binary Accuracy (MBA) to correct such\nbias. We hope that TemporalBench can foster research on improving models'\ntemporal reasoning capabilities. Both dataset and evaluation code will be made\navailable.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Project Page: https://temporalbench.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2410.10818v2",
    "published_date": "2024-10-14 17:59:58 UTC",
    "updated_date": "2024-10-15 17:55:46 UTC"
  },
  {
    "arxiv_id": "2410.10816v1",
    "title": "LVD-2M: A Long-take Video Dataset with Temporally Dense Captions",
    "authors": [
      "Tianwei Xiong",
      "Yuqing Wang",
      "Daquan Zhou",
      "Zhijie Lin",
      "Jiashi Feng",
      "Xihui Liu"
    ],
    "abstract": "The efficacy of video generation models heavily depends on the quality of\ntheir training datasets. Most previous video generation models are trained on\nshort video clips, while recently there has been increasing interest in\ntraining long video generation models directly on longer videos. However, the\nlack of such high-quality long videos impedes the advancement of long video\ngeneration. To promote research in long video generation, we desire a new\ndataset with four key features essential for training long video generation\nmodels: (1) long videos covering at least 10 seconds, (2) long-take videos\nwithout cuts, (3) large motion and diverse contents, and (4) temporally dense\ncaptions. To achieve this, we introduce a new pipeline for selecting\nhigh-quality long-take videos and generating temporally dense captions.\nSpecifically, we define a set of metrics to quantitatively assess video quality\nincluding scene cuts, dynamic degrees, and semantic-level quality, enabling us\nto filter high-quality long-take videos from a large amount of source videos.\nSubsequently, we develop a hierarchical video captioning pipeline to annotate\nlong videos with temporally-dense captions. With this pipeline, we curate the\nfirst long-take video dataset, LVD-2M, comprising 2 million long-take videos,\neach covering more than 10 seconds and annotated with temporally dense\ncaptions. We further validate the effectiveness of LVD-2M by fine-tuning video\ngeneration models to generate long videos with dynamic motions. We believe our\nwork will significantly contribute to future research in long video generation.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "NeurIPS 2024 Dataset and Benchmark Track. Project page:\n  https://silentview.github.io/LVD-2M/ . Code:\n  https://github.com/SilentView/LVD-2M",
    "pdf_url": "http://arxiv.org/pdf/2410.10816v1",
    "published_date": "2024-10-14 17:59:56 UTC",
    "updated_date": "2024-10-14 17:59:56 UTC"
  },
  {
    "arxiv_id": "2410.10815v2",
    "title": "Depth Any Video with Scalable Synthetic Data",
    "authors": [
      "Honghui Yang",
      "Di Huang",
      "Wei Yin",
      "Chunhua Shen",
      "Haifeng Liu",
      "Xiaofei He",
      "Binbin Lin",
      "Wanli Ouyang",
      "Tong He"
    ],
    "abstract": "Video depth estimation has long been hindered by the scarcity of consistent\nand scalable ground truth data, leading to inconsistent and unreliable results.\nIn this paper, we introduce Depth Any Video, a model that tackles the challenge\nthrough two key innovations. First, we develop a scalable synthetic data\npipeline, capturing real-time video depth data from diverse virtual\nenvironments, yielding 40,000 video clips of 5-second duration, each with\nprecise depth annotations. Second, we leverage the powerful priors of\ngenerative video diffusion models to handle real-world videos effectively,\nintegrating advanced techniques such as rotary position encoding and flow\nmatching to further enhance flexibility and efficiency. Unlike previous models,\nwhich are limited to fixed-length video sequences, our approach introduces a\nnovel mixed-duration training strategy that handles videos of varying lengths\nand performs robustly across different frame rates-even on single frames. At\ninference, we propose a depth interpolation method that enables our model to\ninfer high-resolution video depth across sequences of up to 150 frames. Our\nmodel outperforms all previous generative depth models in terms of spatial\naccuracy and temporal consistency. The code and model weights are open-sourced.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Project Page: https://depthanyvideo.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2410.10815v2",
    "published_date": "2024-10-14 17:59:46 UTC",
    "updated_date": "2025-03-12 09:16:59 UTC"
  },
  {
    "arxiv_id": "2410.10812v1",
    "title": "HART: Efficient Visual Generation with Hybrid Autoregressive Transformer",
    "authors": [
      "Haotian Tang",
      "Yecheng Wu",
      "Shang Yang",
      "Enze Xie",
      "Junsong Chen",
      "Junyu Chen",
      "Zhuoyang Zhang",
      "Han Cai",
      "Yao Lu",
      "Song Han"
    ],
    "abstract": "We introduce Hybrid Autoregressive Transformer (HART), an autoregressive (AR)\nvisual generation model capable of directly generating 1024x1024 images,\nrivaling diffusion models in image generation quality. Existing AR models face\nlimitations due to the poor image reconstruction quality of their discrete\ntokenizers and the prohibitive training costs associated with generating 1024px\nimages. To address these challenges, we present the hybrid tokenizer, which\ndecomposes the continuous latents from the autoencoder into two components:\ndiscrete tokens representing the big picture and continuous tokens representing\nthe residual components that cannot be represented by the discrete tokens. The\ndiscrete component is modeled by a scalable-resolution discrete AR model, while\nthe continuous component is learned with a lightweight residual diffusion\nmodule with only 37M parameters. Compared with the discrete-only VAR tokenizer,\nour hybrid approach improves reconstruction FID from 2.11 to 0.30 on MJHQ-30K,\nleading to a 31% generation FID improvement from 7.85 to 5.38. HART also\noutperforms state-of-the-art diffusion models in both FID and CLIP score, with\n4.5-7.7x higher throughput and 6.9-13.4x lower MACs. Our code is open sourced\nat https://github.com/mit-han-lab/hart.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Demo: https://hart.mit.edu. The first two authors contributed equally\n  to this work",
    "pdf_url": "http://arxiv.org/pdf/2410.10812v1",
    "published_date": "2024-10-14 17:59:42 UTC",
    "updated_date": "2024-10-14 17:59:42 UTC"
  },
  {
    "arxiv_id": "2410.10807v2",
    "title": "Hard-Constrained Neural Networks with Universal Approximation Guarantees",
    "authors": [
      "Youngjae Min",
      "Navid Azizan"
    ],
    "abstract": "Incorporating prior knowledge or specifications of input-output relationships\ninto machine learning models has gained significant attention, as it enhances\ngeneralization from limited data and leads to conforming outputs. However, most\nexisting approaches use soft constraints by penalizing violations through\nregularization, which offers no guarantee of constraint satisfaction--an\nessential requirement in safety-critical applications. On the other hand,\nimposing hard constraints on neural networks may hinder their representational\npower, adversely affecting performance. To address this, we propose HardNet, a\npractical framework for constructing neural networks that inherently satisfy\nhard constraints without sacrificing model capacity. Unlike approaches that\nmodify outputs only at inference time, HardNet enables end-to-end training with\nhard constraint guarantees, leading to improved performance. To the best of our\nknowledge, HardNet is the first method with an efficient forward pass to\nenforce more than one input-dependent inequality constraint. It allows\nunconstrained optimization of the network parameters using standard algorithms\nby appending a differentiable closed-form enforcement layer to the network's\noutput. Furthermore, we show that HardNet retains the universal approximation\ncapabilities of neural networks. We demonstrate the versatility and\neffectiveness of HardNet across various applications: learning with piecewise\nconstraints, learning optimization solvers, optimizing control policies in\nsafety-critical systems, and learning safe decision logic for aircraft systems.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.10807v2",
    "published_date": "2024-10-14 17:59:24 UTC",
    "updated_date": "2025-05-05 17:58:28 UTC"
  },
  {
    "arxiv_id": "2410.10802v1",
    "title": "Boosting Camera Motion Control for Video Diffusion Transformers",
    "authors": [
      "Soon Yau Cheong",
      "Duygu Ceylan",
      "Armin Mustafa",
      "Andrew Gilbert",
      "Chun-Hao Paul Huang"
    ],
    "abstract": "Recent advancements in diffusion models have significantly enhanced the\nquality of video generation. However, fine-grained control over camera pose\nremains a challenge. While U-Net-based models have shown promising results for\ncamera control, transformer-based diffusion models (DiT)-the preferred\narchitecture for large-scale video generation - suffer from severe degradation\nin camera motion accuracy. In this paper, we investigate the underlying causes\nof this issue and propose solutions tailored to DiT architectures. Our study\nreveals that camera control performance depends heavily on the choice of\nconditioning methods rather than camera pose representations that is commonly\nbelieved. To address the persistent motion degradation in DiT, we introduce\nCamera Motion Guidance (CMG), based on classifier-free guidance, which boosts\ncamera control by over 400%. Additionally, we present a sparse camera control\npipeline, significantly simplifying the process of specifying camera poses for\nlong videos. Our method universally applies to both U-Net and DiT models,\noffering improved camera control for video generation tasks.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.10802v1",
    "published_date": "2024-10-14 17:58:07 UTC",
    "updated_date": "2024-10-14 17:58:07 UTC"
  },
  {
    "arxiv_id": "2410.10934v2",
    "title": "Agent-as-a-Judge: Evaluate Agents with Agents",
    "authors": [
      "Mingchen Zhuge",
      "Changsheng Zhao",
      "Dylan Ashley",
      "Wenyi Wang",
      "Dmitrii Khizbullin",
      "Yunyang Xiong",
      "Zechun Liu",
      "Ernie Chang",
      "Raghuraman Krishnamoorthi",
      "Yuandong Tian",
      "Yangyang Shi",
      "Vikas Chandra",
      "Jürgen Schmidhuber"
    ],
    "abstract": "Contemporary evaluation techniques are inadequate for agentic systems. These\napproaches either focus exclusively on final outcomes -- ignoring the\nstep-by-step nature of agentic systems, or require excessive manual labour. To\naddress this, we introduce the Agent-as-a-Judge framework, wherein agentic\nsystems are used to evaluate agentic systems. This is an organic extension of\nthe LLM-as-a-Judge framework, incorporating agentic features that enable\nintermediate feedback for the entire task-solving process. We apply the\nAgent-as-a-Judge to the task of code generation. To overcome issues with\nexisting benchmarks and provide a proof-of-concept testbed for\nAgent-as-a-Judge, we present DevAI, a new benchmark of 55 realistic automated\nAI development tasks. It includes rich manual annotations, like a total of 365\nhierarchical user requirements. We benchmark three of the popular agentic\nsystems using Agent-as-a-Judge and find it dramatically outperforms\nLLM-as-a-Judge and is as reliable as our human evaluation baseline. Altogether,\nwe believe that Agent-as-a-Judge marks a concrete step forward for modern\nagentic systems -- by providing rich and reliable reward signals necessary for\ndynamic and scalable self-improvement.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "The project can be found at\n  https://github.com/metauto-ai/agent-as-a-judge. The dataset is released at\n  https://huggingface.co/DEVAI-benchmark",
    "pdf_url": "http://arxiv.org/pdf/2410.10934v2",
    "published_date": "2024-10-14 17:57:02 UTC",
    "updated_date": "2024-10-16 17:54:12 UTC"
  },
  {
    "arxiv_id": "2410.10786v1",
    "title": "On Information-Theoretic Measures of Predictive Uncertainty",
    "authors": [
      "Kajetan Schweighofer",
      "Lukas Aichberger",
      "Mykyta Ielanskyi",
      "Sepp Hochreiter"
    ],
    "abstract": "Reliable estimation of predictive uncertainty is crucial for machine learning\napplications, particularly in high-stakes scenarios where hedging against risks\nis essential. Despite its significance, a consensus on the correct measurement\nof predictive uncertainty remains elusive. In this work, we return to first\nprinciples to develop a fundamental framework of information-theoretic\npredictive uncertainty measures. Our proposed framework categorizes predictive\nuncertainty measures according to two factors: (I) The predicting model (II)\nThe approximation of the true predictive distribution. Examining all possible\ncombinations of these two factors, we derive a set of predictive uncertainty\nmeasures that includes both known and newly introduced ones. We empirically\nevaluate these measures in typical uncertainty estimation settings, such as\nmisclassification detection, selective prediction, and out-of-distribution\ndetection. The results show that no single measure is universal, but the\neffectiveness depends on the specific setting. Thus, our work provides clarity\nabout the suitability of predictive uncertainty measures by clarifying their\nimplicit assumptions and relationships.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.10786v1",
    "published_date": "2024-10-14 17:52:18 UTC",
    "updated_date": "2024-10-14 17:52:18 UTC"
  },
  {
    "arxiv_id": "2410.10781v2",
    "title": "When Attention Sink Emerges in Language Models: An Empirical View",
    "authors": [
      "Xiangming Gu",
      "Tianyu Pang",
      "Chao Du",
      "Qian Liu",
      "Fengzhuo Zhang",
      "Cunxiao Du",
      "Ye Wang",
      "Min Lin"
    ],
    "abstract": "Language Models (LMs) assign significant attention to the first token, even\nif it is not semantically important, which is known as attention sink. This\nphenomenon has been widely adopted in applications such as streaming/long\ncontext generation, KV cache optimization, inference acceleration, model\nquantization, and others. Despite its widespread use, a deep understanding of\nattention sink in LMs is still lacking. In this work, we first demonstrate that\nattention sinks exist universally in LMs with various inputs, even in small\nmodels. Furthermore, attention sink is observed to emerge during the LM\npre-training, motivating us to investigate how optimization, data distribution,\nloss function, and model architecture in LM pre-training influence its\nemergence. We highlight that attention sink emerges after effective\noptimization on sufficient training data. The sink position is highly\ncorrelated with the loss function and data distribution. Most importantly, we\nfind that attention sink acts more like key biases, storing extra attention\nscores, which could be non-informative and not contribute to the value\ncomputation. We also observe that this phenomenon (at least partially) stems\nfrom tokens' inner dependence on attention scores as a result of softmax\nnormalization. After relaxing such dependence by replacing softmax attention\nwith other attention operations, such as sigmoid attention without\nnormalization, attention sinks do not emerge in LMs up to 1B parameters. The\ncode is available at https://github.com/sail-sg/Attention-Sink.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "ICLR 2025 (Spotlight)",
    "pdf_url": "http://arxiv.org/pdf/2410.10781v2",
    "published_date": "2024-10-14 17:50:28 UTC",
    "updated_date": "2025-03-02 14:37:53 UTC"
  },
  {
    "arxiv_id": "2410.10779v1",
    "title": "Focused ReAct: Improving ReAct through Reiterate and Early Stop",
    "authors": [
      "Shuoqiu Li",
      "Han Xu",
      "Haipeng Chen"
    ],
    "abstract": "Large language models (LLMs) have significantly improved their reasoning and\ndecision-making capabilities, as seen in methods like ReAct. However, despite\nits effectiveness in tackling complex tasks, ReAct faces two main challenges:\nlosing focus on the original question and becoming stuck in action loops. To\naddress these issues, we introduce Focused ReAct, an enhanced version of the\nReAct paradigm that incorporates reiteration and early stop mechanisms. These\nimprovements help the model stay focused on the original query and avoid\nrepetitive behaviors. Experimental results show accuracy gains of 18% to 530%\nand a runtime reduction of up to 34% compared to the original ReAct method.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "The Eighth Widening NLP Workshop (WiNLP 2024)",
    "pdf_url": "http://arxiv.org/pdf/2410.10779v1",
    "published_date": "2024-10-14 17:49:54 UTC",
    "updated_date": "2024-10-14 17:49:54 UTC"
  },
  {
    "arxiv_id": "2410.10766v1",
    "title": "Adaptive Diffusion Terrain Generator for Autonomous Uneven Terrain Navigation",
    "authors": [
      "Youwei Yu",
      "Junhong Xu",
      "Lantao Liu"
    ],
    "abstract": "Model-free reinforcement learning has emerged as a powerful method for\ndeveloping robust robot control policies capable of navigating through complex\nand unstructured terrains. The effectiveness of these methods hinges on two\nessential elements: (1) the use of massively parallel physics simulations to\nexpedite policy training, and (2) an environment generator tasked with crafting\nsufficiently challenging yet attainable terrains to facilitate continuous\npolicy improvement. Existing methods of environment generation often rely on\nheuristics constrained by a set of parameters, limiting the diversity and\nrealism. In this work, we introduce the Adaptive Diffusion Terrain Generator\n(ADTG), a novel method that leverages Denoising Diffusion Probabilistic Models\nto dynamically expand existing training environments by adding more diverse and\ncomplex terrains adaptive to the current policy. ADTG guides the diffusion\nmodel's generation process through initial noise optimization, blending\nnoise-corrupted terrains from existing training environments weighted by the\npolicy's performance in each corresponding environment. By manipulating the\nnoise corruption level, ADTG seamlessly transitions between generating similar\nterrains for policy fine-tuning and novel ones to expand training diversity.\nOur experiments show that the policy trained by ADTG outperforms both\nprocedural generated and natural environments, along with popular navigation\nmethods.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.10766v1",
    "published_date": "2024-10-14 17:42:37 UTC",
    "updated_date": "2024-10-14 17:42:37 UTC"
  },
  {
    "arxiv_id": "2410.10762v4",
    "title": "AFlow: Automating Agentic Workflow Generation",
    "authors": [
      "Jiayi Zhang",
      "Jinyu Xiang",
      "Zhaoyang Yu",
      "Fengwei Teng",
      "Xionghui Chen",
      "Jiaqi Chen",
      "Mingchen Zhuge",
      "Xin Cheng",
      "Sirui Hong",
      "Jinlin Wang",
      "Bingnan Zheng",
      "Bang Liu",
      "Yuyu Luo",
      "Chenglin Wu"
    ],
    "abstract": "Large language models (LLMs) have demonstrated remarkable potential in\nsolving complex tasks across diverse domains, typically by employing agentic\nworkflows that follow detailed instructions and operational sequences. However,\nconstructing these workflows requires significant human effort, limiting\nscalability and generalizability. Recent research has sought to automate the\ngeneration and optimization of these workflows, but existing methods still rely\non initial manual setup and fall short of achieving fully automated and\neffective workflow generation. To address this challenge, we reformulate\nworkflow optimization as a search problem over code-represented workflows,\nwhere LLM-invoking nodes are connected by edges. We introduce AFlow, an\nautomated framework that efficiently explores this space using Monte Carlo Tree\nSearch, iteratively refining workflows through code modification,\ntree-structured experience, and execution feedback. Empirical evaluations\nacross six benchmark datasets demonstrate AFlow's efficacy, yielding a 5.7%\naverage improvement over state-of-the-art baselines. Furthermore, AFlow enables\nsmaller models to outperform GPT-4o on specific tasks at 4.55% of its inference\ncost in dollars. The code is available at\nhttps://github.com/FoundationAgents/AFlow.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.SE"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.10762v4",
    "published_date": "2024-10-14 17:40:40 UTC",
    "updated_date": "2025-04-15 02:44:55 UTC"
  },
  {
    "arxiv_id": "2410.10758v4",
    "title": "Arrhythmia Classification Using Graph Neural Networks Based on Correlation Matrix",
    "authors": [
      "Seungwoo Han"
    ],
    "abstract": "With the advancements in graph neural network, there has been increasing\ninterest in applying this network to ECG signal analysis. In this study, we\ngenerated an adjacency matrix using correlation matrix of extracted features\nand applied a graph neural network to classify arrhythmias. The proposed model\nwas compared with existing approaches from the literature. The results\ndemonstrated that precision and recall for all arrhythmia classes exceeded 50%,\nsuggesting that this method can be considered an approach for arrhythmia\nclassification.",
    "categories": [
      "eess.SP",
      "cs.AI"
    ],
    "primary_category": "eess.SP",
    "comment": "Corrected typos",
    "pdf_url": "http://arxiv.org/pdf/2410.10758v4",
    "published_date": "2024-10-14 17:38:37 UTC",
    "updated_date": "2025-02-10 14:40:49 UTC"
  },
  {
    "arxiv_id": "2410.10745v1",
    "title": "FlexGen: Flexible Multi-View Generation from Text and Image Inputs",
    "authors": [
      "Xinli Xu",
      "Wenhang Ge",
      "Jiantao Lin",
      "Jiawei Feng",
      "Lie Xu",
      "HanFeng Zhao",
      "Shunsi Zhang",
      "Ying-Cong Chen"
    ],
    "abstract": "In this work, we introduce FlexGen, a flexible framework designed to generate\ncontrollable and consistent multi-view images, conditioned on a single-view\nimage, or a text prompt, or both. FlexGen tackles the challenges of\ncontrollable multi-view synthesis through additional conditioning on 3D-aware\ntext annotations. We utilize the strong reasoning capabilities of GPT-4V to\ngenerate 3D-aware text annotations. By analyzing four orthogonal views of an\nobject arranged as tiled multi-view images, GPT-4V can produce text annotations\nthat include 3D-aware information with spatial relationship. By integrating the\ncontrol signal with proposed adaptive dual-control module, our model can\ngenerate multi-view images that correspond to the specified text. FlexGen\nsupports multiple controllable capabilities, allowing users to modify text\nprompts to generate reasonable and corresponding unseen parts. Additionally,\nusers can influence attributes such as appearance and material properties,\nincluding metallic and roughness. Extensive experiments demonstrate that our\napproach offers enhanced multiple controllability, marking a significant\nadvancement over existing multi-view diffusion models. This work has\nsubstantial implications for fields requiring rapid and flexible 3D content\ncreation, including game development, animation, and virtual reality. Project\npage: https://xxu068.github.io/flexgen.github.io/.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "16 pages, 13 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.10745v1",
    "published_date": "2024-10-14 17:23:13 UTC",
    "updated_date": "2024-10-14 17:23:13 UTC"
  },
  {
    "arxiv_id": "2410.10743v1",
    "title": "NT-LLM: A Novel Node Tokenizer for Integrating Graph Structure into Large Language Models",
    "authors": [
      "Yanbiao Ji",
      "Chang Liu",
      "Xin Chen",
      "Yue Ding",
      "Dan Luo",
      "Mei Li",
      "Wenqing Lin",
      "Hongtao Lu"
    ],
    "abstract": "Graphs are a fundamental data structure for representing relationships in\nreal-world scenarios. With the success of Large Language Models (LLMs) across\nvarious natural language processing (NLP) tasks, there has been growing\ninterest in integrating LLMs for graph learning. However, applying LLMs to\ngraph-related tasks poses significant challenges, as these models are not\ninherently designed to capture the complex structural information present in\ngraphs. Existing approaches address this challenge through two strategies: the\nchain of tasks approach, which uses Graph Neural Networks (GNNs) to encode the\ngraph structure so that LLMs are relieved from understanding spatial positions;\nand Graph-to-Text Conversion, which translates graph structures into semantic\ntext representations that LLMs can process. Despite their progress, these\nmethods often struggle to fully preserve the topological information of graphs\nor require extensive computational resources, limiting their practical\napplicability.\n  In this work, we introduce Node Tokenizer for Large Language Models (NT-LLM),\na novel framework that efficiently encodes graph structures by selecting key\nnodes as anchors and representing each node based on its relative distance to\nthese anchors. This position-anchored encoding effectively captures the graph\ntopology, enabling enhanced reasoning capabilities in LLMs over graph data.\nAdditionally, we implement a task-specific tuning procedure to further improve\nstructural understanding within LLMs. Through extensive empirical evaluations,\nNT-LLM demonstrates significant performance improvements across a variety of\ngraph-related tasks.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.10743v1",
    "published_date": "2024-10-14 17:21:57 UTC",
    "updated_date": "2024-10-14 17:21:57 UTC"
  },
  {
    "arxiv_id": "2410.10741v3",
    "title": "SensorBench: Benchmarking LLMs in Coding-Based Sensor Processing",
    "authors": [
      "Pengrui Quan",
      "Xiaomin Ouyang",
      "Jeya Vikranth Jeyakumar",
      "Ziqi Wang",
      "Yang Xing",
      "Mani Srivastava"
    ],
    "abstract": "Effective processing, interpretation, and management of sensor data have\nemerged as a critical component of cyber-physical systems. Traditionally,\nprocessing sensor data requires profound theoretical knowledge and proficiency\nin signal-processing tools. However, recent works show that Large Language\nModels (LLMs) have promising capabilities in processing sensory data,\nsuggesting their potential as copilots for developing sensing systems.\n  To explore this potential, we construct a comprehensive benchmark,\nSensorBench, to establish a quantifiable objective. The benchmark incorporates\ndiverse real-world sensor datasets for various tasks. The results show that\nwhile LLMs exhibit considerable proficiency in simpler tasks, they face\ninherent challenges in processing compositional tasks with parameter selections\ncompared to engineering experts. Additionally, we investigate four prompting\nstrategies for sensor processing and show that self-verification can outperform\nall other baselines in 48% of tasks. Our study provides a comprehensive\nbenchmark and prompting analysis for future developments, paving the way toward\nan LLM-based sensor processing copilot.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "eess.SP"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.10741v3",
    "published_date": "2024-10-14 17:21:39 UTC",
    "updated_date": "2025-03-28 18:42:25 UTC"
  },
  {
    "arxiv_id": "2410.10738v1",
    "title": "DrivingDojo Dataset: Advancing Interactive and Knowledge-Enriched Driving World Model",
    "authors": [
      "Yuqi Wang",
      "Ke Cheng",
      "Jiawei He",
      "Qitai Wang",
      "Hengchen Dai",
      "Yuntao Chen",
      "Fei Xia",
      "Zhaoxiang Zhang"
    ],
    "abstract": "Driving world models have gained increasing attention due to their ability to\nmodel complex physical dynamics. However, their superb modeling capability is\nyet to be fully unleashed due to the limited video diversity in current driving\ndatasets. We introduce DrivingDojo, the first dataset tailor-made for training\ninteractive world models with complex driving dynamics. Our dataset features\nvideo clips with a complete set of driving maneuvers, diverse multi-agent\ninterplay, and rich open-world driving knowledge, laying a stepping stone for\nfuture world model development. We further define an action instruction\nfollowing (AIF) benchmark for world models and demonstrate the superiority of\nthe proposed dataset for generating action-controlled future predictions.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to NeurIPS 2024. Project page:\n  https://drivingdojo.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2410.10738v1",
    "published_date": "2024-10-14 17:19:23 UTC",
    "updated_date": "2024-10-14 17:19:23 UTC"
  },
  {
    "arxiv_id": "2410.10735v2",
    "title": "Embedding Self-Correction as an Inherent Ability in Large Language Models for Enhanced Mathematical Reasoning",
    "authors": [
      "Kuofeng Gao",
      "Huanqia Cai",
      "Qingyao Shuai",
      "Dihong Gong",
      "Zhifeng Li"
    ],
    "abstract": "Accurate mathematical reasoning with Large Language Models (LLMs) is crucial\nin revolutionizing domains that heavily rely on such reasoning. However, LLMs\noften encounter difficulties in certain aspects of mathematical reasoning,\nleading to flawed reasoning and erroneous results. To mitigate these issues, we\nintroduce a novel mechanism, the Chain of Self-Correction (CoSC), specifically\ndesigned to embed self-correction as an inherent ability in LLMs, enabling them\nto validate and rectify their own results. The CoSC mechanism operates through\na sequence of self-correction stages. In each stage, the LLMs generate a\nprogram to address a given problem, execute this program using program-based\ntools to obtain an output, subsequently verify this output. Based on the\nverification, the LLMs either proceed to the next correction stage or finalize\nthe answer. This iterative self-correction process allows the LLMs to refine\nits reasoning steps and improve the accuracy of its mathematical reasoning. We\nimplement CoSC using a two-phase fine-tuning approach. First, LLMs are trained\nwith a relatively small volume of seeding data generated from GPT-4. Then, we\nenhance CoSC by training with a larger volume of self-generated data, without\nrelying on GPT-4. Experiments show that CoSC significantly boosts performance\non standard mathematical datasets compared to existing open-source LLMs.\nNotably, our CoSC-Code-34B model achieved a 53.5% score on the challenging MATH\ndataset, outperforming models like ChatGPT, GPT-4, and multi-modal LLMs such as\nGPT-4V and Gemini-1.0. Importantly, CoSC operates in a zero-shot manner without\nrequiring demonstrations.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.10735v2",
    "published_date": "2024-10-14 17:16:44 UTC",
    "updated_date": "2025-02-08 11:45:10 UTC"
  },
  {
    "arxiv_id": "2410.10733v8",
    "title": "Deep Compression Autoencoder for Efficient High-Resolution Diffusion Models",
    "authors": [
      "Junyu Chen",
      "Han Cai",
      "Junsong Chen",
      "Enze Xie",
      "Shang Yang",
      "Haotian Tang",
      "Muyang Li",
      "Yao Lu",
      "Song Han"
    ],
    "abstract": "We present Deep Compression Autoencoder (DC-AE), a new family of autoencoder\nmodels for accelerating high-resolution diffusion models. Existing autoencoder\nmodels have demonstrated impressive results at a moderate spatial compression\nratio (e.g., 8x), but fail to maintain satisfactory reconstruction accuracy for\nhigh spatial compression ratios (e.g., 64x). We address this challenge by\nintroducing two key techniques: (1) Residual Autoencoding, where we design our\nmodels to learn residuals based on the space-to-channel transformed features to\nalleviate the optimization difficulty of high spatial-compression autoencoders;\n(2) Decoupled High-Resolution Adaptation, an efficient decoupled three-phases\ntraining strategy for mitigating the generalization penalty of high\nspatial-compression autoencoders. With these designs, we improve the\nautoencoder's spatial compression ratio up to 128 while maintaining the\nreconstruction quality. Applying our DC-AE to latent diffusion models, we\nachieve significant speedup without accuracy drop. For example, on ImageNet\n512x512, our DC-AE provides 19.1x inference speedup and 17.9x training speedup\non H100 GPU for UViT-H while achieving a better FID, compared with the widely\nused SD-VAE-f8 autoencoder. Our code is available at\nhttps://github.com/mit-han-lab/efficientvit.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "ICLR 2025. The first two authors contributed equally to this work.\n  Fix Typo",
    "pdf_url": "http://arxiv.org/pdf/2410.10733v8",
    "published_date": "2024-10-14 17:15:07 UTC",
    "updated_date": "2025-05-18 21:17:22 UTC"
  },
  {
    "arxiv_id": "2410.10728v1",
    "title": "Towards LLM-guided Efficient and Interpretable Multi-linear Tensor Network Rank Selection",
    "authors": [
      "Giorgos Iacovides",
      "Wuyang Zhou",
      "Danilo Mandic"
    ],
    "abstract": "We propose a novel framework that leverages large language models (LLMs) to\nguide the rank selection in tensor network models for higher-order data\nanalysis. By utilising the intrinsic reasoning capabilities and domain\nknowledge of LLMs, our approach offers enhanced interpretability of the rank\nchoices and can effectively optimise the objective function. This framework\nenables users without specialised domain expertise to utilise tensor network\ndecompositions and understand the underlying rationale within the rank\nselection process. Experimental results validate our method on financial\nhigher-order datasets, demonstrating interpretable reasoning, strong\ngeneralisation to unseen test data, and its potential for self-enhancement over\nsuccessive iterations. This work is placed at the intersection of large\nlanguage models and higher-order data analysis.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.10728v1",
    "published_date": "2024-10-14 17:09:14 UTC",
    "updated_date": "2024-10-14 17:09:14 UTC"
  },
  {
    "arxiv_id": "2410.10714v2",
    "title": "SeedLM: Compressing LLM Weights into Seeds of Pseudo-Random Generators",
    "authors": [
      "Rasoul Shafipour",
      "David Harrison",
      "Maxwell Horton",
      "Jeffrey Marker",
      "Houman Bedayat",
      "Sachin Mehta",
      "Mohammad Rastegari",
      "Mahyar Najibi",
      "Saman Naderiparizi"
    ],
    "abstract": "Large Language Models (LLMs) have transformed natural language processing,\nbut face significant challenges in widespread deployment due to their high\nruntime cost. In this paper, we introduce SeedLM, a novel post-training\ncompression method that uses seeds of pseudo-random generators to encode and\ncompress model weights. Specifically, for each block of weights, we find a seed\nthat is fed into a Linear Feedback Shift Register (LFSR) during inference to\nefficiently generate a random matrix. This matrix is then linearly combined\nwith compressed coefficients to reconstruct the weight block. SeedLM reduces\nmemory access and leverages idle compute cycles during inference, effectively\nspeeding up memory-bound tasks by trading compute for fewer memory accesses.\nUnlike state-of-the-art compression methods that rely on calibration data, our\napproach is data-free and generalizes well across diverse tasks. Our\nexperiments with Llama 3 70B, which is particularly challenging to compress,\nshow that SeedLM achieves significantly better zero-shot accuracy retention at\n4- and 3-bit than state-of-the-art techniques, while maintaining performance\ncomparable to FP16 baselines. Additionally, FPGA-based tests demonstrate that\n4-bit SeedLM, as model size increases to 70B, approaches a 4x speed-up over an\nFP16 Llama 2/3 baseline.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.10714v2",
    "published_date": "2024-10-14 16:57:23 UTC",
    "updated_date": "2024-10-16 00:11:57 UTC"
  },
  {
    "arxiv_id": "2410.10701v2",
    "title": "Early Diagnosis of Acute Lymphoblastic Leukemia Using YOLOv8 and YOLOv11 Deep Learning Models",
    "authors": [
      "Alaa Awad",
      "Salah A. Aly"
    ],
    "abstract": "Leukemia, a severe form of blood cancer, claims thousands of lives each year.\nThis study focuses on the detection of Acute Lymphoblastic Leukemia (ALL) using\nadvanced image processing and deep learning techniques. By leveraging recent\nadvancements in artificial intelligence, the research evaluates the reliability\nof these methods in practical, real-world scenarios. Specifically, it examines\nthe performance of state-of-the-art YOLO models, including YOLOv8 and YOLOv11,\nto distinguish between malignant and benign white blood cells and accurately\nidentify different stages of ALL, including early stages. Moreover, the models\ndemonstrate the ability to detect hematogones, which are frequently\nmisclassified as ALL. With accuracy rates reaching 98.8%, this study highlights\nthe potential of these algorithms to provide robust and precise leukemia\ndetection across diverse datasets and conditions.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "6 pages, 7 figures, 2 tables, JAC-ECC2024",
    "pdf_url": "http://arxiv.org/pdf/2410.10701v2",
    "published_date": "2024-10-14 16:42:07 UTC",
    "updated_date": "2025-01-11 08:02:18 UTC"
  },
  {
    "arxiv_id": "2410.10700v1",
    "title": "Derail Yourself: Multi-turn LLM Jailbreak Attack through Self-discovered Clues",
    "authors": [
      "Qibing Ren",
      "Hao Li",
      "Dongrui Liu",
      "Zhanxu Xie",
      "Xiaoya Lu",
      "Yu Qiao",
      "Lei Sha",
      "Junchi Yan",
      "Lizhuang Ma",
      "Jing Shao"
    ],
    "abstract": "This study exposes the safety vulnerabilities of Large Language Models (LLMs)\nin multi-turn interactions, where malicious users can obscure harmful intents\nacross several queries. We introduce ActorAttack, a novel multi-turn attack\nmethod inspired by actor-network theory, which models a network of semantically\nlinked actors as attack clues to generate diverse and effective attack paths\ntoward harmful targets. ActorAttack addresses two main challenges in multi-turn\nattacks: (1) concealing harmful intents by creating an innocuous conversation\ntopic about the actor, and (2) uncovering diverse attack paths towards the same\nharmful target by leveraging LLMs' knowledge to specify the correlated actors\nas various attack clues. In this way, ActorAttack outperforms existing\nsingle-turn and multi-turn attack methods across advanced aligned LLMs, even\nfor GPT-o1. We will publish a dataset called SafeMTData, which includes\nmulti-turn adversarial prompts and safety alignment data, generated by\nActorAttack. We demonstrate that models safety-tuned using our safety dataset\nare more robust to multi-turn attacks. Code is available at\nhttps://github.com/renqibing/ActorAttack.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.10700v1",
    "published_date": "2024-10-14 16:41:49 UTC",
    "updated_date": "2024-10-14 16:41:49 UTC"
  },
  {
    "arxiv_id": "2410.10929v7",
    "title": "ASTM :Autonomous Smart Traffic Management System Using Artificial Intelligence CNN and LSTM",
    "authors": [
      "Christofel Rio Goenawan"
    ],
    "abstract": "In the modern world, the development of Artificial Intelligence (AI) has\ncontributed to improvements in various areas, including automation, computer\nvision, fraud detection, and more. AI can be leveraged to enhance the\nefficiency of Autonomous Smart Traffic Management (ASTM) systems and reduce\ntraffic congestion rates. This paper presents an Autonomous Smart Traffic\nManagement (STM) system that uses AI to improve traffic flow rates. The system\nemploys the YOLO V5 Convolutional Neural Network to detect vehicles in traffic\nmanagement images. Additionally, it predicts the number of vehicles for the\nnext 12 hours using a Recurrent Neural Network with Long Short-Term Memory\n(RNN-LSTM). The Smart Traffic Management Cycle Length Analysis manages the\ntraffic cycle length based on these vehicle predictions, aided by AI. From the\nresults of the RNN-LSTM model for predicting vehicle numbers over the next 12\nhours, we observe that the model predicts traffic with a Mean Squared Error\n(MSE) of 4.521 vehicles and a Root Mean Squared Error (RMSE) of 2.232 vehicles.\nAfter simulating the STM system in the CARLA simulation environment, we found\nthat the Traffic Management Congestion Flow Rate with ASTM (21 vehicles per\nminute) is 50\\% higher than the rate without STM (around 15 vehicles per\nminute). Additionally, the Traffic Management Vehicle Pass Delay with STM (5\nseconds per vehicle) is 70\\% lower than without STM (around 12 seconds per\nvehicle). These results demonstrate that the STM system using AI can increase\ntraffic flow by 50\\% and reduce vehicle pass delays by 70\\%.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "Novel Autonomous Smart Traffic Management System using End-to-End\n  Artificial Intelligence",
    "pdf_url": "http://arxiv.org/pdf/2410.10929v7",
    "published_date": "2024-10-14 16:35:27 UTC",
    "updated_date": "2025-02-10 12:09:23 UTC"
  },
  {
    "arxiv_id": "2410.10687v1",
    "title": "Building a Multivariate Time Series Benchmarking Datasets Inspired by Natural Language Processing (NLP)",
    "authors": [
      "Mohammad Asif Ibna Mustafa",
      "Ferdinand Heinrich"
    ],
    "abstract": "Time series analysis has become increasingly important in various domains,\nand developing effective models relies heavily on high-quality benchmark\ndatasets. Inspired by the success of Natural Language Processing (NLP)\nbenchmark datasets in advancing pre-trained models, we propose a new approach\nto create a comprehensive benchmark dataset for time series analysis. This\npaper explores the methodologies used in NLP benchmark dataset creation and\nadapts them to the unique challenges of time series data. We discuss the\nprocess of curating diverse, representative, and challenging time series\ndatasets, highlighting the importance of domain relevance and data complexity.\nAdditionally, we investigate multi-task learning strategies that leverage the\nbenchmark dataset to enhance the performance of time series models. This\nresearch contributes to the broader goal of advancing the state-of-the-art in\ntime series modeling by adopting successful strategies from the NLP domain.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.10687v1",
    "published_date": "2024-10-14 16:25:54 UTC",
    "updated_date": "2024-10-14 16:25:54 UTC"
  },
  {
    "arxiv_id": "2410.12872v1",
    "title": "Beyond Right and Wrong: Mitigating Cold Start in Knowledge Tracing Using Large Language Model and Option Weight",
    "authors": [
      "JongWoo Kim",
      "SeongYeub Chu",
      "Bryan Wong",
      "Mun Yi"
    ],
    "abstract": "Knowledge Tracing (KT) is vital in educational data mining, enabling\npersonalized learning by tracking learners' knowledge states and forecasting\ntheir academic outcomes. This study introduces the LOKT (Large Language Model\nOption-weighted Knowledge Tracing) model to address the cold start problem\nwhere limited historical data available using large language models (LLMs).\nWhile traditional KT models have incorporated option weights, our research\nextends this by integrating these weights into an LLM-based KT framework.\nMoving beyond the binary classification of correct and incorrect responses, we\nemphasize that different types of incorrect answers offer valuable insights\ninto a learner's knowledge state. By converting these responses into text-based\nordinal categories, we enable LLMs to assess learner understanding with greater\nclarity, although our approach focuses on the final knowledge state rather than\nthe progression of learning over time. Using five public datasets, we\ndemonstrate that the LOKT model sustains high predictive accuracy even with\nlimited data, effectively addressing both \"learner cold-start\" and \"system\ncold-start\" scenarios. These findings showcase LOKT's potential to enhance\nLLM-based learning tools and support early-stage personalization.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "11 pages",
    "pdf_url": "http://arxiv.org/pdf/2410.12872v1",
    "published_date": "2024-10-14 16:25:48 UTC",
    "updated_date": "2024-10-14 16:25:48 UTC"
  },
  {
    "arxiv_id": "2410.10679v1",
    "title": "Combinatorial Multi-armed Bandits: Arm Selection via Group Testing",
    "authors": [
      "Arpan Mukherjee",
      "Shashanka Ubaru",
      "Keerthiram Murugesan",
      "Karthikeyan Shanmugam",
      "Ali Tajer"
    ],
    "abstract": "This paper considers the problem of combinatorial multi-armed bandits with\nsemi-bandit feedback and a cardinality constraint on the super-arm size.\nExisting algorithms for solving this problem typically involve two key\nsub-routines: (1) a parameter estimation routine that sequentially estimates a\nset of base-arm parameters, and (2) a super-arm selection policy for selecting\na subset of base arms deemed optimal based on these parameters.\nState-of-the-art algorithms assume access to an exact oracle for super-arm\nselection with unbounded computational power. At each instance, this oracle\nevaluates a list of score functions, the number of which grows as low as\nlinearly and as high as exponentially with the number of arms. This can be\nprohibitive in the regime of a large number of arms. This paper introduces a\nnovel realistic alternative to the perfect oracle. This algorithm uses a\ncombination of group-testing for selecting the super arms and quantized\nThompson sampling for parameter estimation. Under a general separability\nassumption on the reward function, the proposed algorithm reduces the\ncomplexity of the super-arm-selection oracle to be logarithmic in the number of\nbase arms while achieving the same regret order as the state-of-the-art\nalgorithms that use exact oracles. This translates to at least an exponential\nreduction in complexity compared to the oracle-based approaches.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IT",
      "math.IT",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "26 pages",
    "pdf_url": "http://arxiv.org/pdf/2410.10679v1",
    "published_date": "2024-10-14 16:19:57 UTC",
    "updated_date": "2024-10-14 16:19:57 UTC"
  },
  {
    "arxiv_id": "2410.10674v2",
    "title": "Enhancing Robustness in Deep Reinforcement Learning: A Lyapunov Exponent Approach",
    "authors": [
      "Rory Young",
      "Nicolas Pugeault"
    ],
    "abstract": "Deep reinforcement learning agents achieve state-of-the-art performance in a\nwide range of simulated control tasks. However, successful applications to\nreal-world problems remain limited. One reason for this dichotomy is because\nthe learnt policies are not robust to observation noise or adversarial attacks.\nIn this paper, we investigate the robustness of deep RL policies to a single\nsmall state perturbation in deterministic continuous control tasks. We\ndemonstrate that RL policies can be deterministically chaotic, as small\nperturbations to the system state have a large impact on subsequent state and\nreward trajectories. This unstable non-linear behaviour has two consequences:\nfirst, inaccuracies in sensor readings, or adversarial attacks, can cause\nsignificant performance degradation; second, even policies that show robust\nperformance in terms of rewards may have unpredictable behaviour in practice.\nThese two facets of chaos in RL policies drastically restrict the application\nof deep RL to real-world problems. To address this issue, we propose an\nimprovement on the successful Dreamer V3 architecture, implementing Maximal\nLyapunov Exponent regularisation. This new approach reduces the chaotic state\ndynamics, rendering the learnt policies more resilient to sensor noise or\nadversarial attacks and thereby improving the suitability of deep reinforcement\nlearning for real-world applications.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.10674v2",
    "published_date": "2024-10-14 16:16:43 UTC",
    "updated_date": "2024-11-26 16:10:08 UTC"
  },
  {
    "arxiv_id": "2410.10665v1",
    "title": "Double Jeopardy and Climate Impact in the Use of Large Language Models: Socio-economic Disparities and Reduced Utility for Non-English Speakers",
    "authors": [
      "Aivin V. Solatorio",
      "Gabriel Stefanini Vicente",
      "Holly Krambeck",
      "Olivier Dupriez"
    ],
    "abstract": "Artificial Intelligence (AI), particularly large language models (LLMs),\nholds the potential to bridge language and information gaps, which can benefit\nthe economies of developing nations. However, our analysis of FLORES-200,\nFLORES+, Ethnologue, and World Development Indicators data reveals that these\nbenefits largely favor English speakers. Speakers of languages in low-income\nand lower-middle-income countries face higher costs when using OpenAI's GPT\nmodels via APIs because of how the system processes the input -- tokenization.\nAround 1.5 billion people, speaking languages primarily from\nlower-middle-income countries, could incur costs that are 4 to 6 times higher\nthan those faced by English speakers. Disparities in LLM performance are\nsignificant, and tokenization in models priced per token amplifies inequalities\nin access, cost, and utility. Moreover, using the quality of translation tasks\nas a proxy measure, we show that LLMs perform poorly in low-resource languages,\npresenting a ``double jeopardy\" of higher costs and poor performance for these\nusers. We also discuss the direct impact of fragmentation in tokenizing\nlow-resource languages on climate. This underscores the need for fairer\nalgorithm development to benefit all linguistic groups.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "econ.GN",
      "q-fin.EC"
    ],
    "primary_category": "cs.CL",
    "comment": "Project GitHub repository at\n  https://github.com/worldbank/double-jeopardy-in-llms",
    "pdf_url": "http://arxiv.org/pdf/2410.10665v1",
    "published_date": "2024-10-14 16:11:04 UTC",
    "updated_date": "2024-10-14 16:11:04 UTC"
  },
  {
    "arxiv_id": "2410.10660v1",
    "title": "Transforming Game Play: A Comparative Study of DCQN and DTQN Architectures in Reinforcement Learning",
    "authors": [
      "William A. Stigall"
    ],
    "abstract": "In this study, we investigate the performance of Deep Q-Networks utilizing\nConvolutional Neural Networks (CNNs) and Transformer architectures across three\ndifferent Atari games. The advent of DQNs has significantly advanced\nReinforcement Learning, enabling agents to directly learn optimal policies from\nhigh-dimensional sensory inputs from pixel or RAM data. While CNN-based DQNs\nhave been extensively studied and deployed in various domains,\nTransformer-based DQNs are relatively unexplored. Our research aims to fill\nthis gap by benchmarking the performance of both DCQNs and DTQNs across the\nAtari games Asteroids, Space Invaders, and Centipede. We find that in the 35-40\nmillion parameter range, the DCQN outperforms the DTQN in speed across both ViT\nand Projection Architectures. We also find the DCQN outperforms the DTQN in all\ngames except for Centipede.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "KSU C-Day Spring 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.10660v1",
    "published_date": "2024-10-14 16:08:15 UTC",
    "updated_date": "2024-10-14 16:08:15 UTC"
  },
  {
    "arxiv_id": "2410.10650v1",
    "title": "Generative AI and Its Impact on Personalized Intelligent Tutoring Systems",
    "authors": [
      "Subhankar Maity",
      "Aniket Deroy"
    ],
    "abstract": "Generative Artificial Intelligence (AI) is revolutionizing educational\ntechnology by enabling highly personalized and adaptive learning environments\nwithin Intelligent Tutoring Systems (ITS). This report delves into the\nintegration of Generative AI, particularly large language models (LLMs) like\nGPT-4, into ITS to enhance personalized education through dynamic content\ngeneration, real-time feedback, and adaptive learning pathways. We explore key\napplications such as automated question generation, customized feedback\nmechanisms, and interactive dialogue systems that respond to individual learner\nneeds. The report also addresses significant challenges, including ensuring\npedagogical accuracy, mitigating inherent biases in AI models, and maintaining\nlearner engagement. Future directions highlight the potential advancements in\nmultimodal AI integration, emotional intelligence in tutoring systems, and the\nethical implications of AI-driven education. By synthesizing current research\nand practical implementations, this report underscores the transformative\npotential of Generative AI in creating more effective, equitable, and engaging\neducational experiences.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Scientific Report (Under Review)",
    "pdf_url": "http://arxiv.org/pdf/2410.10650v1",
    "published_date": "2024-10-14 16:01:01 UTC",
    "updated_date": "2024-10-14 16:01:01 UTC"
  },
  {
    "arxiv_id": "2410.10646v2",
    "title": "DR-MPC: Deep Residual Model Predictive Control for Real-world Social Navigation",
    "authors": [
      "James R. Han",
      "Hugues Thomas",
      "Jian Zhang",
      "Nicholas Rhinehart",
      "Timothy D. Barfoot"
    ],
    "abstract": "How can a robot safely navigate around people with complex motion patterns?\nDeep Reinforcement Learning (DRL) in simulation holds some promise, but much\nprior work relies on simulators that fail to capture the nuances of real human\nmotion. Thus, we propose Deep Residual Model Predictive Control (DR-MPC) to\nenable robots to quickly and safely perform DRL from real-world crowd\nnavigation data. By blending MPC with model-free DRL, DR-MPC overcomes the DRL\nchallenges of large data requirements and unsafe initial behavior. DR-MPC is\ninitialized with MPC-based path tracking, and gradually learns to interact more\neffectively with humans. To further accelerate learning, a safety component\nestimates out-of-distribution states to guide the robot away from likely\ncollisions. In simulation, we show that DR-MPC substantially outperforms prior\nwork, including traditional DRL and residual DRL models. Hardware experiments\nshow our approach successfully enables a robot to navigate a variety of crowded\nsituations with few errors using less than 4 hours of training data.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "8 pages, 8 figures, accepted to IEEE Robotics and Automation Letters\n  (RA-L) February 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.10646v2",
    "published_date": "2024-10-14 15:56:43 UTC",
    "updated_date": "2025-02-14 02:14:35 UTC"
  },
  {
    "arxiv_id": "2410.10636v2",
    "title": "Adapt-$\\infty$: Scalable Continual Multimodal Instruction Tuning via Dynamic Data Selection",
    "authors": [
      "Adyasha Maharana",
      "Jaehong Yoon",
      "Tianlong Chen",
      "Mohit Bansal"
    ],
    "abstract": "Visual instruction datasets from various distributors are released at\ndifferent times and often contain a significant number of semantically\nredundant text-image pairs, depending on their task compositions (i.e., skills)\nor reference sources. This redundancy greatly limits the efficient deployment\nof continually adaptable multimodal large language models, hindering their\nability to refine existing skills and acquire new competencies over time. We\nreframe the problem of lifelong Instruction Tuning (LiIT) via data selection,\nwhere the model automatically selects beneficial samples to learn from earlier\nand new datasets based on the current state of acquired knowledge in the model.\nWe propose Adapt-$\\infty$, a new multi-way and adaptive data selection approach\nthat dynamically balances sample efficiency and effectiveness during LiIT. We\nfirst construct pseudo-skill clusters by grouping gradient-based sample\nvectors. Next, we select the best-performing data selector for each skill\ncluster from a pool of selector experts, including our newly proposed scoring\nfunction, Image Grounding score. This data selector samples a subset of the\nmost important samples from each skill cluster for training. To prevent the\ncontinuous increase in the size of the dataset pool during LiIT, we introduce a\ncluster-wise permanent data pruning strategy to remove the most semantically\nredundant samples from each cluster, keeping computational requirements\nmanageable. We validate the effectiveness and efficiency of Adapt-$\\infty$ over\na sequence of multimodal instruction tuning datasets with various tasks,\nincluding (Knowledge) VQA, multilingual, grounding, reasoning, language-only,\nand multi-image comprehension. Training with samples selected by Adapt-$\\infty$\nalleviates catastrophic forgetting, especially for rare tasks, and promotes\nforward transfer across the continuum using only a fraction of the original\ndata.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "First two authors contributed equally. Code:\n  https://github.com/adymaharana/adapt-inf",
    "pdf_url": "http://arxiv.org/pdf/2410.10636v2",
    "published_date": "2024-10-14 15:48:09 UTC",
    "updated_date": "2025-03-24 09:17:13 UTC"
  },
  {
    "arxiv_id": "2410.10927v1",
    "title": "Cultural Heritage 3D Reconstruction with Diffusion Networks",
    "authors": [
      "Pablo Jaramillo",
      "Ivan Sipiran"
    ],
    "abstract": "This article explores the use of recent generative AI algorithms for\nrepairing cultural heritage objects, leveraging a conditional diffusion model\ndesigned to reconstruct 3D point clouds effectively. Our study evaluates the\nmodel's performance across general and cultural heritage-specific settings.\nResults indicate that, with considerations for object variability, the\ndiffusion model can accurately reproduce cultural heritage geometries. Despite\nencountering challenges like data diversity and outlier sensitivity, the model\ndemonstrates significant potential in artifact restoration research. This work\nlays groundwork for advancing restoration methodologies for ancient artifacts\nusing AI technologies.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by the workshop VISART for ECCV 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.10927v1",
    "published_date": "2024-10-14 15:43:40 UTC",
    "updated_date": "2024-10-14 15:43:40 UTC"
  },
  {
    "arxiv_id": "2410.10630v1",
    "title": "Thinking LLMs: General Instruction Following with Thought Generation",
    "authors": [
      "Tianhao Wu",
      "Janice Lan",
      "Weizhe Yuan",
      "Jiantao Jiao",
      "Jason Weston",
      "Sainbayar Sukhbaatar"
    ],
    "abstract": "LLMs are typically trained to answer user questions or follow instructions\nsimilarly to how human experts respond. However, in the standard alignment\nframework they lack the basic ability of explicit thinking before answering.\nThinking is important for complex questions that require reasoning and planning\n-- but can be applied to any task. We propose a training method for equipping\nexisting LLMs with such thinking abilities for general instruction following\nwithout use of additional human data. We achieve this by an iterative search\nand optimization procedure that explores the space of possible thought\ngenerations, allowing the model to learn how to think without direct\nsupervision. For each instruction, the thought candidates are scored using a\njudge model to evaluate their responses only, and then optimized via preference\noptimization. We show that this procedure leads to superior performance on\nAlpacaEval and Arena-Hard, and shows gains from thinking on non-reasoning\ncategories such as marketing, health and general knowledge, in addition to more\ntraditional reasoning & problem-solving tasks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.10630v1",
    "published_date": "2024-10-14 15:38:56 UTC",
    "updated_date": "2024-10-14 15:38:56 UTC"
  },
  {
    "arxiv_id": "2410.10614v1",
    "title": "Modeling News Interactions and Influence for Financial Market Prediction",
    "authors": [
      "Mengyu Wang",
      "Shay B. Cohen",
      "Tiejun Ma"
    ],
    "abstract": "The diffusion of financial news into market prices is a complex process,\nmaking it challenging to evaluate the connections between news events and\nmarket movements. This paper introduces FININ (Financial Interconnected News\nInfluence Network), a novel market prediction model that captures not only the\nlinks between news and prices but also the interactions among news items\nthemselves. FININ effectively integrates multi-modal information from both\nmarket data and news articles. We conduct extensive experiments on two\ndatasets, encompassing the S&P 500 and NASDAQ 100 indices over a 15-year period\nand over 2.7 million news articles. The results demonstrate FININ's\neffectiveness, outperforming advanced market prediction models with an\nimprovement of 0.429 and 0.341 in the daily Sharpe ratio for the two markets\nrespectively. Moreover, our results reveal insights into the financial news,\nincluding the delayed market pricing of news, the long memory effect of news,\nand the limitations of financial sentiment analysis in fully extracting\npredictive power from news data.",
    "categories": [
      "cs.CE",
      "cs.AI",
      "cs.CL",
      "q-fin.CP"
    ],
    "primary_category": "cs.CE",
    "comment": "Accepted by EMNLP 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.10614v1",
    "published_date": "2024-10-14 15:19:49 UTC",
    "updated_date": "2024-10-14 15:19:49 UTC"
  },
  {
    "arxiv_id": "2410.10610v1",
    "title": "Intelligent prospector v2.0: exploration drill planning under epistemic model uncertainty",
    "authors": [
      "John Mern",
      "Anthony Corso",
      "Damian Burch",
      "Kurt House",
      "Jef Caers"
    ],
    "abstract": "Optimal Bayesian decision making on what geoscientific data to acquire\nrequires stating a prior model of uncertainty. Data acquisition is then\noptimized by reducing uncertainty on some property of interest maximally, and\non average. In the context of exploration, very few, sometimes no data at all,\nis available prior to data acquisition planning. The prior model therefore\nneeds to include human interpretations on the nature of spatial variability, or\non analogue data deemed relevant for the area being explored. In mineral\nexploration, for example, humans may rely on conceptual models on the genesis\nof the mineralization to define multiple hypotheses, each representing a\nspecific spatial variability of mineralization. More often than not, after the\ndata is acquired, all of the stated hypotheses may be proven incorrect, i.e.\nfalsified, hence prior hypotheses need to be revised, or additional hypotheses\ngenerated. Planning data acquisition under wrong geological priors is likely to\nbe inefficient since the estimated uncertainty on the target property is\nincorrect, hence uncertainty may not be reduced at all. In this paper, we\ndevelop an intelligent agent based on partially observable Markov decision\nprocesses that plans optimally in the case of multiple geological or\ngeoscientific hypotheses on the nature of spatial variability. Additionally,\nthe artificial intelligence is equipped with a method that allows detecting,\nearly on, whether the human stated hypotheses are incorrect, thereby saving\nconsiderable expense in data acquisition. Our approach is tested on a\nsediment-hosted copper deposit, and the algorithm presented has aided in the\ncharacterization of an ultra high-grade deposit in Zambia in 2023.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.10610v1",
    "published_date": "2024-10-14 15:17:29 UTC",
    "updated_date": "2024-10-14 15:17:29 UTC"
  },
  {
    "arxiv_id": "2410.10604v2",
    "title": "Multi-modal Vision Pre-training for Medical Image Analysis",
    "authors": [
      "Shaohao Rui",
      "Lingzhi Chen",
      "Zhenyu Tang",
      "Lilong Wang",
      "Mianxin Liu",
      "Shaoting Zhang",
      "Xiaosong Wang"
    ],
    "abstract": "Self-supervised learning has greatly facilitated medical image analysis by\nsuppressing the training data requirement for real-world applications. Current\nparadigms predominantly rely on self-supervision within uni-modal image data,\nthereby neglecting the inter-modal correlations essential for effective\nlearning of cross-modal image representations. This limitation is particularly\nsignificant for naturally grouped multi-modal data, e.g., multi-parametric MRI\nscans for a patient undergoing various functional imaging protocols in the same\nstudy. To bridge this gap, we conduct a novel multi-modal image pre-training\nwith three proxy tasks to facilitate the learning of cross-modality\nrepresentations and correlations using multi-modal brain MRI scans (over 2.4\nmillion images in 16,022 scans of 3,755 patients), i.e., cross-modal image\nreconstruction, modality-aware contrastive learning, and modality template\ndistillation. To demonstrate the generalizability of our pre-trained model, we\nconduct extensive experiments on various benchmarks with ten downstream tasks.\nThe superior performance of our method is reported in comparison to\nstate-of-the-art pre-training methods, with Dice Score improvement of\n0.28\\%-14.47\\% across six segmentation benchmarks and a consistent accuracy\nboost of 0.65\\%-18.07\\% in four individual image classification tasks.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.10604v2",
    "published_date": "2024-10-14 15:12:16 UTC",
    "updated_date": "2025-03-14 14:32:09 UTC"
  },
  {
    "arxiv_id": "2410.10596v2",
    "title": "Neural networks that overcome classic challenges through practice",
    "authors": [
      "Kazuki Irie",
      "Brenden M. Lake"
    ],
    "abstract": "Since the earliest proposals for neural network models of the mind and brain,\ncritics have pointed out key weaknesses in these models compared to human\ncognitive abilities. Here we review recent work that uses metalearning to\novercome several classic challenges by addressing the Problem of Incentive and\nPractice -- that is, providing machines with both incentives to improve\nspecific skills and opportunities to practice those skills. This explicit\noptimization contrasts with more conventional approaches that hope the desired\nbehavior will emerge through optimizing related but different objectives. We\nreview applications of this principle to addressing four classic challenges for\nneural networks: systematic generalization, catastrophic forgetting, few-shot\nlearning and multi-step reasoning. We also discuss the prospects for\nunderstanding aspects of human development through this framework, and whether\nnatural environments provide the right incentives and practice for learning how\nto make challenging generalizations.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "q-bio.NC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.10596v2",
    "published_date": "2024-10-14 15:07:37 UTC",
    "updated_date": "2024-12-15 20:26:27 UTC"
  },
  {
    "arxiv_id": "2410.10926v1",
    "title": "Federated Data-Efficient Instruction Tuning for Large Language Models",
    "authors": [
      "Zhen Qin",
      "Zhaomin Wu",
      "Bingsheng He",
      "Shuiguang Deng"
    ],
    "abstract": "Instruction tuning helps improve pretrained large language models (LLMs) in\nterms of the responsiveness to human instructions, which is benefited from\ndiversified instruction data. Federated learning extends the sources of\ninstruction data by exploiting the diversified client-side data, making it\nincreasingly popular for tuning LLMs. Existing approaches of federated LLM\ntuning typically traverse all local data during local training, bringing\nexcessive computation overhead and posing a risk of overfitting local data.\nThus, a federated data-efficient instruction tuning approach, which consumes\nrelatively little data from the entire dataset, is needed. In response, this\nwork introduces an approach of federated data-efficient instruction tuning for\nLLMs, FedHDS, which utilizes a representative subset of edge-side data,\ncoreset, to tune the LLM. It reduces the redundancy of data samples at both\nintra-client and inter-client levels through a hierarchical data selection\nframework performed by jointly selecting a small number of representative data\nsamples for local training without sharing the raw data. Extensive experiments\nconducted across six scenarios with various LLMs, datasets and data partitions\ndemonstrate that FedHDS significantly reduces the amount of data required for\nfine-tuning while improving the responsiveness of the instruction-tuned LLMs to\nunseen tasks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "11 pages. Ongoing work",
    "pdf_url": "http://arxiv.org/pdf/2410.10926v1",
    "published_date": "2024-10-14 15:05:51 UTC",
    "updated_date": "2024-10-14 15:05:51 UTC"
  },
  {
    "arxiv_id": "2410.10594v2",
    "title": "VisRAG: Vision-based Retrieval-augmented Generation on Multi-modality Documents",
    "authors": [
      "Shi Yu",
      "Chaoyue Tang",
      "Bokai Xu",
      "Junbo Cui",
      "Junhao Ran",
      "Yukun Yan",
      "Zhenghao Liu",
      "Shuo Wang",
      "Xu Han",
      "Zhiyuan Liu",
      "Maosong Sun"
    ],
    "abstract": "Retrieval-augmented generation (RAG) is an effective technique that enables\nlarge language models (LLMs) to utilize external knowledge sources for\ngeneration. However, current RAG systems are solely based on text, rendering it\nimpossible to utilize vision information like layout and images that play\ncrucial roles in real-world multi-modality documents. In this paper, we\nintroduce VisRAG, which tackles this issue by establishing a vision-language\nmodel (VLM)-based RAG pipeline. In this pipeline, instead of first parsing the\ndocument to obtain text, the document is directly embedded using a VLM as an\nimage and then retrieved to enhance the generation of a VLM. Compared to\ntraditional text-based RAG, VisRAG maximizes the retention and utilization of\nthe data information in the original documents, eliminating the information\nloss introduced during the parsing process. We collect both open-source and\nsynthetic data to train the retriever in VisRAG and explore a variety of\ngeneration methods. Experiments demonstrate that VisRAG outperforms traditional\nRAG in both the retrieval and generation stages, achieving a 20--40% end-to-end\nperformance gain over traditional text-based RAG pipeline. Further analysis\nreveals that VisRAG is efficient in utilizing training data and demonstrates\nstrong generalization capability, positioning it as a promising solution for\nRAG on multi-modality documents. Our code and data are available at\nhttps://github.com/openbmb/visrag.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.10594v2",
    "published_date": "2024-10-14 15:04:18 UTC",
    "updated_date": "2025-03-02 01:19:51 UTC"
  },
  {
    "arxiv_id": "2410.10588v1",
    "title": "TRESTLE: A Model of Concept Formation in Structured Domains",
    "authors": [
      "Christopher J. MacLellan",
      "Erik Harpstead",
      "Vincent Aleven",
      "Kenneth R. Koedinger"
    ],
    "abstract": "The literature on concept formation has demonstrated that humans are capable\nof learning concepts incrementally, with a variety of attribute types, and in\nboth supervised and unsupervised settings. Many models of concept formation\nfocus on a subset of these characteristics, but none account for all of them.\nIn this paper, we present TRESTLE, an incremental account of probabilistic\nconcept formation in structured domains that unifies prior concept learning\nmodels. TRESTLE works by creating a hierarchical categorization tree that can\nbe used to predict missing attribute values and cluster sets of examples into\nconceptually meaningful groups. It updates its knowledge by partially matching\nnovel structures and sorting them into its categorization tree. Finally, the\nsystem supports mixed-data representations, including nominal, numeric,\nrelational, and component attributes. We evaluate TRESTLE's performance on a\nsupervised learning task and an unsupervised clustering task. For both tasks,\nwe compare it to a nonincremental model and to human participants. We find that\nthis new categorization model is competitive with the nonincremental approach\nand more closely approximates human behavior on both tasks. These results serve\nas an initial demonstration of TRESTLE's capabilities and show that, by taking\nkey characteristics of human learning into account, it can better model\nbehavior than approaches that ignore them.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "20 pages, 6 figures, 1 table",
    "pdf_url": "http://arxiv.org/pdf/2410.10588v1",
    "published_date": "2024-10-14 15:00:43 UTC",
    "updated_date": "2024-10-14 15:00:43 UTC"
  },
  {
    "arxiv_id": "2410.12871v1",
    "title": "AI-Driven Autonomous Control of Proton-Boron Fusion Reactors Using Backpropagation Neural Networks",
    "authors": [
      "Michele Laurelli"
    ],
    "abstract": "Proton-boron (p-11B) fusion presents a promising path towards sustainable,\nneutron-free energy generation. However, its implementation is hindered by\nextreme operational conditions, such as plasma temperatures exceeding billions\nof degrees and the complexity of controlling high-energy particles. Traditional\ncontrol systems face significant challenges in managing the highly dynamic and\nnon-linear behavior of the plasma. In this paper, we propose a novel approach\nutilizing backpropagation-based neural networks to autonomously control key\nparameters in a proton-boron fusion reactor. Our method leverages real-time\nfeedback and learning from physical data to adapt to changing plasma\nconditions, offering a potential breakthrough in stable and efficient p-11B\nfusion. Furthermore, we expand on the scalability and generalization of our\napproach to other fusion systems and future AI technologies.",
    "categories": [
      "physics.plasm-ph",
      "cs.AI",
      "cs.LG",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "physics.plasm-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.12871v1",
    "published_date": "2024-10-14 14:58:43 UTC",
    "updated_date": "2024-10-14 14:58:43 UTC"
  },
  {
    "arxiv_id": "2410.10584v1",
    "title": "STACKFEED: Structured Textual Actor-Critic Knowledge Base Editing with FeedBack",
    "authors": [
      "Naman Gupta",
      "Shashank Kirtania",
      "Priyanshu Gupta",
      "Krishna Kariya",
      "Sumit Gulwani",
      "Arun Iyer",
      "Suresh Parthasarathy",
      "Arjun Radhakrishna",
      "Sriram K. Rajamani",
      "Gustavo Soares"
    ],
    "abstract": "Large Language Models (LLMs) often generate incorrect or outdated\ninformation, especially in low-resource settings or when dealing with private\ndata. To address this, Retrieval-Augmented Generation (RAG) uses external\nknowledge bases (KBs), but these can also suffer from inaccuracies. We\nintroduce STACKFEED, a novel Structured Textual Actor-Critic Knowledge base\nediting with FEEDback approach that iteratively refines the KB based on expert\nfeedback using a multi-actor, centralized critic reinforcement learning\nframework. Each document is assigned to an actor, modeled as a ReACT agent,\nwhich performs structured edits based on document-specific targeted\ninstructions from a centralized critic. Experimental results show that\nSTACKFEED significantly improves KB quality and RAG system performance,\nenhancing accuracy by up to 8% over baselines.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.10584v1",
    "published_date": "2024-10-14 14:56:01 UTC",
    "updated_date": "2024-10-14 14:56:01 UTC"
  },
  {
    "arxiv_id": "2410.10580v1",
    "title": "Multilingual Controlled Generation And Gold-Standard-Agnostic Evaluation of Code-Mixed Sentences",
    "authors": [
      "Ayushman Gupta",
      "Akhil Bhogal",
      "Kripabandhu Ghosh"
    ],
    "abstract": "Code-mixing, the practice of alternating between two or more languages in an\nutterance, is a common phenomenon in multilingual communities. Due to the\ncolloquial nature of code-mixing, there is no singular correct way to translate\nan English sentence into a code-mixed sentence. For this reason, standard\nn-gram-based MT evaluation metrics such as the BLEU score are not appropriate\nfor code-mixed evaluation. To demonstrate this, we propose a novel method for\ncode-mixed text generation: Controlled Generation, which parameterizes the\ncode-mixing degree (CMD) and enables the generation of multiple semantically\nequivalent code-mixed sentences from a given English sentence. We introduce a\nrobust new evaluation metric: GAME: A Gold-Standard Agnostic Measure for\nEvaluation of Code-Mixed Sentences. GAME is both language-agnostic and\ngold-standard-agnostic, i.e. unlike other metrics, GAME does not require\ngold-standard code-mixed sentences for evaluation, thus eliminating the need\nfor human annotators in the code-mixed evaluation process. When used to\nevaluate semantically equivalent code-mixed sentences, we find that GAME scores\nhave a lower standard deviation than BLEU scores. Further, we create and\nrelease a dataset containing gold-standard code-mixed sentences across 4\nlanguage pairs: English-{Hindi, Bengali, French, Spanish} to encourage more\ncomputational research on code-mixing.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Manuscript submitted to COLING 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.10580v1",
    "published_date": "2024-10-14 14:54:05 UTC",
    "updated_date": "2024-10-14 14:54:05 UTC"
  },
  {
    "arxiv_id": "2410.10578v9",
    "title": "Burning RED: Unlocking Subtask-Driven Reinforcement Learning and Risk-Awareness in Average-Reward Markov Decision Processes",
    "authors": [
      "Juan Sebastian Rojas",
      "Chi-Guhn Lee"
    ],
    "abstract": "Average-reward Markov decision processes (MDPs) provide a foundational\nframework for sequential decision-making under uncertainty. However,\naverage-reward MDPs have remained largely unexplored in reinforcement learning\n(RL) settings, with the majority of RL-based efforts having been allocated to\ndiscounted MDPs. In this work, we study a unique structural property of\naverage-reward MDPs and utilize it to introduce Reward-Extended Differential\n(or RED) reinforcement learning: a novel RL framework that can be used to\neffectively and efficiently solve various learning objectives, or subtasks,\nsimultaneously in the average-reward setting. We introduce a family of RED\nlearning algorithms for prediction and control, including proven-convergent\nalgorithms for the tabular case. We then showcase the power of these algorithms\nby demonstrating how they can be used to learn a policy that optimizes, for the\nfirst time, the well-known conditional value-at-risk (CVaR) risk measure in a\nfully-online manner, without the use of an explicit bi-level optimization\nscheme or an augmented state-space.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.10578v9",
    "published_date": "2024-10-14 14:52:23 UTC",
    "updated_date": "2025-02-24 19:53:06 UTC"
  },
  {
    "arxiv_id": "2410.10567v1",
    "title": "When Precedents Clash",
    "authors": [
      "Cecilia Di Florio",
      "Huimin Dong",
      "Antonino Rotolo"
    ],
    "abstract": "Consistency of case bases is a way to avoid the problem of retrieving\nconflicting constraining precedents for new cases to be decided. However, in\nlegal practice the consistency requirements for case bases may not be\nsatisfied. As pointed out in (Broughton 2019), a model of precedential\nconstraint should take into account the hierarchical structure of the specific\nlegal system under consideration and the temporal dimension of cases. This\narticle continues the research initiated in (Liu et al. 2022; Di Florio et al.\n2023), which established a connection between Boolean classifiers and legal\ncase-based reasoning. On this basis, we enrich the classifier models with an\norganisational structure that takes into account both the hierarchy of courts\nand which courts issue decisions that are binding/constraining on subsequent\ncases. We focus on common law systems. We also introduce a temporal relation\nbetween cases. Within this enriched framework, we can formalise the notions of\noverruled cases and cases decided per incuriam: such cases are not to be\nconsidered binding on later cases. Finally, we show under which condition\nprinciples based on the hierarchical structure and on the temporal dimension\ncan provide an unambiguous decision-making process for new cases in the\npresence of conflicting binding precedents.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "13 pages. Extended version with proofs of a paper accepted at JURIX\n  2024",
    "pdf_url": "http://arxiv.org/pdf/2410.10567v1",
    "published_date": "2024-10-14 14:45:47 UTC",
    "updated_date": "2024-10-14 14:45:47 UTC"
  },
  {
    "arxiv_id": "2410.10554v1",
    "title": "ROSAR: An Adversarial Re-Training Framework for Robust Side-Scan Sonar Object Detection",
    "authors": [
      "Martin Aubard",
      "László Antal",
      "Ana Madureira",
      "Luis F. Teixeira",
      "Erika Ábrahám"
    ],
    "abstract": "This paper introduces ROSAR, a novel framework enhancing the robustness of\ndeep learning object detection models tailored for side-scan sonar (SSS)\nimages, generated by autonomous underwater vehicles using sonar sensors. By\nextending our prior work on knowledge distillation (KD), this framework\nintegrates KD with adversarial retraining to address the dual challenges of\nmodel efficiency and robustness against SSS noises. We introduce three novel,\npublicly available SSS datasets, capturing different sonar setups and noise\nconditions. We propose and formalize two SSS safety properties and utilize them\nto generate adversarial datasets for retraining. Through a comparative analysis\nof projected gradient descent (PGD) and patch-based adversarial attacks, ROSAR\ndemonstrates significant improvements in model robustness and detection\naccuracy under SSS-specific conditions, enhancing the model's robustness by up\nto 1.85%. ROSAR is available at\nhttps://github.com/remaro-network/ROSAR-framework.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.10554v1",
    "published_date": "2024-10-14 14:33:14 UTC",
    "updated_date": "2024-10-14 14:33:14 UTC"
  },
  {
    "arxiv_id": "2410.10553v1",
    "title": "SLaNC: Static LayerNorm Calibration",
    "authors": [
      "Mahsa Salmani",
      "Nikita Trukhanov",
      "Ilya Soloveychik"
    ],
    "abstract": "The ever increasing sizes of Large Language Models (LLMs) beyond hundreds of\nbillions of parameters have generated enormous pressure on the manufacturers of\ndedicated hardware accelerators and made the innovative design of the latter\none of the most rapidly expanding fields of the AI industry. Various approaches\nhave been explored to enable efficient and accurate processing of LLMs on the\navailable accelerators given their computational and storage limitations. Among\nthese, various quantization techniques have become the main focus of the\ncommunity as a means of reducing the compute, communication and storage\nrequirements. Quantization to lower precision formats naturally poses a number\nof challenges caused by the limited range of the available value\nrepresentations. When it comes to processing the popular Transformer models on\nhardware, one of the main issues becomes calculation of the LayerNorm simply\nbecause accumulation of the variance requires a much wider dynamic range than\nthe hardware enables. In this article, we address this matter and propose a\ncomputationally-efficient scaling technique that can be easily applied to\nTransformer models during inference. Our method suggests a straightforward way\nof scaling the LayerNorm inputs based on the static weights of the immediately\npreceding linear layers. The scaling factors are computed offline, based solely\non the linear layer weights, hence no latency or computational overhead is\nadded during inference. Most importantly, our technique ensures that no\nnumerical issues such as overflow or underflow could happen during the compute.\nThis approach offers smooth, accurate and resource-effective inference across a\nwide range of hardware architectures. The article provides theoretical\njustification as well as supporting numerical simulations.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "9 pages, 3 figures, NeurIPS 2024 MLNCP Workshop",
    "pdf_url": "http://arxiv.org/pdf/2410.10553v1",
    "published_date": "2024-10-14 14:32:55 UTC",
    "updated_date": "2024-10-14 14:32:55 UTC"
  },
  {
    "arxiv_id": "2410.10547v1",
    "title": "Hybrid Transformer for Early Alzheimer's Detection: Integration of Handwriting-Based 2D Images and 1D Signal Features",
    "authors": [
      "Changqing Gong",
      "Huafeng Qin",
      "Mounîm A. El-Yacoubi"
    ],
    "abstract": "Alzheimer's Disease (AD) is a prevalent neurodegenerative condition where\nearly detection is vital. Handwriting, often affected early in AD, offers a\nnon-invasive and cost-effective way to capture subtle motor changes.\nState-of-the-art research on handwriting, mostly online, based AD detection has\npredominantly relied on manually extracted features, fed as input to shallow\nmachine learning models. Some recent works have proposed deep learning\n(DL)-based models, either 1D-CNN or 2D-CNN architectures, with performance\ncomparing favorably to handcrafted schemes. These approaches, however, overlook\nthe intrinsic relationship between the 2D spatial patterns of handwriting\nstrokes and their 1D dynamic characteristics, thus limiting their capacity to\ncapture the multimodal nature of handwriting data. Moreover, the application of\nTransformer models remains basically unexplored. To address these limitations,\nwe propose a novel approach for AD detection, consisting of a learnable\nmultimodal hybrid attention model that integrates simultaneously 2D handwriting\nimages with 1D dynamic handwriting signals. Our model leverages a gated\nmechanism to combine similarity and difference attention, blending the two\nmodalities and learning robust features by incorporating information at\ndifferent scales. Our model achieved state-of-the-art performance on the DARWIN\ndataset, with an F1-score of 90.32\\% and accuracy of 90.91\\% in Task 8 ('L'\nwriting), surpassing the previous best by 4.61% and 6.06% respectively.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.10547v1",
    "published_date": "2024-10-14 14:26:52 UTC",
    "updated_date": "2024-10-14 14:26:52 UTC"
  },
  {
    "arxiv_id": "2410.10924v1",
    "title": "A Benchmark Suite for Evaluating Neural Mutual Information Estimators on Unstructured Datasets",
    "authors": [
      "Kyungeun Lee",
      "Wonjong Rhee"
    ],
    "abstract": "Mutual Information (MI) is a fundamental metric for quantifying dependency\nbetween two random variables. When we can access only the samples, but not the\nunderlying distribution functions, we can evaluate MI using sample-based\nestimators. Assessment of such MI estimators, however, has almost always relied\non analytical datasets including Gaussian multivariates. Such datasets allow\nanalytical calculations of the true MI values, but they are limited in that\nthey do not reflect the complexities of real-world datasets. This study\nintroduces a comprehensive benchmark suite for evaluating neural MI estimators\non unstructured datasets, specifically focusing on images and texts. By\nleveraging same-class sampling for positive pairing and introducing a binary\nsymmetric channel trick, we show that we can accurately manipulate true MI\nvalues of real-world datasets. Using the benchmark suite, we investigate seven\nchallenging scenarios, shedding light on the reliability of neural MI\nestimators for unstructured datasets.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "stat.ML",
    "comment": "NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.10924v1",
    "published_date": "2024-10-14 14:22:38 UTC",
    "updated_date": "2024-10-14 14:22:38 UTC"
  },
  {
    "arxiv_id": "2410.10542v1",
    "title": "Rethinking Legal Judgement Prediction in a Realistic Scenario in the Era of Large Language Models",
    "authors": [
      "Shubham Kumar Nigam",
      "Aniket Deroy",
      "Subhankar Maity",
      "Arnab Bhattacharya"
    ],
    "abstract": "This study investigates judgment prediction in a realistic scenario within\nthe context of Indian judgments, utilizing a range of transformer-based models,\nincluding InLegalBERT, BERT, and XLNet, alongside LLMs such as Llama-2 and\nGPT-3.5 Turbo. In this realistic scenario, we simulate how judgments are\npredicted at the point when a case is presented for a decision in court, using\nonly the information available at that time, such as the facts of the case,\nstatutes, precedents, and arguments. This approach mimics real-world\nconditions, where decisions must be made without the benefit of hindsight,\nunlike retrospective analyses often found in previous studies. For transformer\nmodels, we experiment with hierarchical transformers and the summarization of\njudgment facts to optimize input for these models. Our experiments with LLMs\nreveal that GPT-3.5 Turbo excels in realistic scenarios, demonstrating robust\nperformance in judgment prediction. Furthermore, incorporating additional legal\ninformation, such as statutes and precedents, significantly improves the\noutcome of the prediction task. The LLMs also provide explanations for their\npredictions. To evaluate the quality of these predictions and explanations, we\nintroduce two human evaluation metrics: Clarity and Linking. Our findings from\nboth automatic and human evaluations indicate that, despite advancements in\nLLMs, they are yet to achieve expert-level performance in judgment prediction\nand explanation tasks.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted on NLLP at EMNLP 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.10542v1",
    "published_date": "2024-10-14 14:22:12 UTC",
    "updated_date": "2024-10-14 14:22:12 UTC"
  },
  {
    "arxiv_id": "2410.10537v3",
    "title": "Reproducible Machine Learning-based Voice Pathology Detection: Introducing the Pitch Difference Feature",
    "authors": [
      "Jan Vrba",
      "Jakub Steinbach",
      "Tomáš Jirsa",
      "Laura Verde",
      "Roberta De Fazio",
      "Yuwen Zeng",
      "Kei Ichiji",
      "Lukáš Hájek",
      "Zuzana Sedláková",
      "Zuzana Urbániová",
      "Martin Chovanec",
      "Jan Mareš",
      "Noriyasu Homma"
    ],
    "abstract": "Purpose: We introduce a novel methodology for voice pathology detection using\nthe publicly available Saarbr\\\"ucken Voice Database (SVD) and a robust feature\nset combining commonly used acoustic handcrafted features with two novel ones:\npitch difference (relative variation in fundamental frequency) and NaN feature\n(failed fundamental frequency estimation).\n  Methods: We evaluate six machine learning (ML) algorithms -- support vector\nmachine, k-nearest neighbors, naive Bayes, decision tree, random forest, and\nAdaBoost -- using grid search for feasible hyperparameters and 20480 different\nfeature subsets. Top 1000 classification models -- feature subset combinations\nfor each ML algorithm are validated with repeated stratified cross-validation.\nTo address class imbalance, we apply K-Means SMOTE to augment the training\ndata.\n  Results: Our approach achieves 85.61%, 84.69% and 85.22% unweighted average\nrecall (UAR) for females, males and combined results respectively. We\nintentionally omit accuracy as it is a highly biased metric for imbalanced\ndata.\n  Conclusion: Our study demonstrates that by following the proposed methodology\nand feature engineering, there is a potential in detection of various voice\npathologies using ML models applied to the simplest vocal task, a sustained\nutterance of the vowel /a:/. To enable easier use of our methodology and to\nsupport our claims, we provide a publicly available GitHub repository with DOI\n10.5281/zenodo.13771573. Finally, we provide a REFORMS checklist to enhance\nreadability, reproducibility and justification of our approach",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Code repository:\n  https://github.com/aailab-uct/Automated-Robust-and-Reproducible-Voice-Pathology-Detection,\n  Supplementary materials: https://doi.org/10.5281/zenodo.14793017",
    "pdf_url": "http://arxiv.org/pdf/2410.10537v3",
    "published_date": "2024-10-14 14:17:52 UTC",
    "updated_date": "2025-03-14 13:47:31 UTC"
  },
  {
    "arxiv_id": "2410.10524v2",
    "title": "Get Rid of Isolation: A Continuous Multi-task Spatio-Temporal Learning Framework",
    "authors": [
      "Zhongchao Yi",
      "Zhengyang Zhou",
      "Qihe Huang",
      "Yanjiang Chen",
      "Liheng Yu",
      "Xu Wang",
      "Yang Wang"
    ],
    "abstract": "Spatiotemporal learning has become a pivotal technique to enable urban\nintelligence. Traditional spatiotemporal models mostly focus on a specific task\nby assuming a same distribution between training and testing sets. However,\ngiven that urban systems are usually dynamic, multi-sourced with imbalanced\ndata distributions, current specific task-specific models fail to generalize to\nnew urban conditions and adapt to new domains without explicitly modeling\ninterdependencies across various dimensions and types of urban data. To this\nend, we argue that there is an essential to propose a Continuous Multi-task\nSpatio-Temporal learning framework (CMuST) to empower collective urban\nintelligence, which reforms the urban spatiotemporal learning from\nsingle-domain to cooperatively multi-dimensional and multi-task learning.\nSpecifically, CMuST proposes a new multi-dimensional spatiotemporal interaction\nnetwork (MSTI) to allow cross-interactions between context and main\nobservations as well as self-interactions within spatial and temporal aspects\nto be exposed, which is also the core for capturing task-level commonality and\npersonalization. To ensure continuous task learning, a novel Rolling Adaptation\ntraining scheme (RoAda) is devised, which not only preserves task uniqueness by\nconstructing data summarization-driven task prompts, but also harnesses\ncorrelated patterns among tasks by iterative model behavior modeling. We\nfurther establish a benchmark of three cities for multi-task spatiotemporal\nlearning, and empirically demonstrate the superiority of CMuST via extensive\nevaluations on these datasets. The impressive improvements on both few-shot\nstreaming data and new domain tasks against existing SOAT methods are achieved.\nCode is available at https://github.com/DILab-USTCSZ/CMuST.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.10524v2",
    "published_date": "2024-10-14 14:04:36 UTC",
    "updated_date": "2025-01-15 09:17:01 UTC"
  },
  {
    "arxiv_id": "2410.11896v1",
    "title": "Study on the Helpfulness of Explainable Artificial Intelligence",
    "authors": [
      "Tobias Labarta",
      "Elizaveta Kulicheva",
      "Ronja Froelian",
      "Christian Geißler",
      "Xenia Melman",
      "Julian von Klitzing"
    ],
    "abstract": "Explainable Artificial Intelligence (XAI) is essential for building advanced\nmachine learning-powered applications, especially in critical domains such as\nmedical diagnostics or autonomous driving. Legal, business, and ethical\nrequirements motivate using effective XAI, but the increasing number of\ndifferent methods makes it challenging to pick the right ones. Further, as\nexplanations are highly context-dependent, measuring the effectiveness of XAI\nmethods without users can only reveal a limited amount of information,\nexcluding human factors such as the ability to understand it. We propose to\nevaluate XAI methods via the user's ability to successfully perform a proxy\ntask, designed such that a good performance is an indicator for the explanation\nto provide helpful information. In other words, we address the helpfulness of\nXAI for human decision-making. Further, a user study on state-of-the-art\nmethods was conducted, showing differences in their ability to generate trust\nand skepticism and the ability to judge the rightfulness of an AI decision\ncorrectly. Based on the results, we highly recommend using and extending this\napproach for more objective-based human-centered user studies to measure XAI\nperformance in an end-to-end fashion.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "68T37, 91E99",
      "I.2.0; I.2.3; H.5.2; H.1.2; K.4.2"
    ],
    "primary_category": "cs.HC",
    "comment": "World Conference on Explainable Artificial Intelligence",
    "pdf_url": "http://arxiv.org/pdf/2410.11896v1",
    "published_date": "2024-10-14 14:03:52 UTC",
    "updated_date": "2024-10-14 14:03:52 UTC"
  },
  {
    "arxiv_id": "2410.10521v1",
    "title": "Continual Deep Reinforcement Learning to Prevent Catastrophic Forgetting in Jamming Mitigation",
    "authors": [
      "Kemal Davaslioglu",
      "Sastry Kompella",
      "Tugba Erpek",
      "Yalin E. Sagduyu"
    ],
    "abstract": "Deep Reinforcement Learning (DRL) has been highly effective in learning from\nand adapting to RF environments and thus detecting and mitigating jamming\neffects to facilitate reliable wireless communications. However, traditional\nDRL methods are susceptible to catastrophic forgetting (namely forgetting old\ntasks when learning new ones), especially in dynamic wireless environments\nwhere jammer patterns change over time. This paper considers an anti-jamming\nsystem and addresses the challenge of catastrophic forgetting in DRL applied to\njammer detection and mitigation. First, we demonstrate the impact of\ncatastrophic forgetting in DRL when applied to jammer detection and mitigation\ntasks, where the network forgets previously learned jammer patterns while\nadapting to new ones. This catastrophic interference undermines the\neffectiveness of the system, particularly in scenarios where the environment is\nnon-stationary. We present a method that enables the network to retain\nknowledge of old jammer patterns while learning to handle new ones. Our\napproach substantially reduces catastrophic forgetting, allowing the\nanti-jamming system to learn new tasks without compromising its ability to\nperform previously learned tasks effectively. Furthermore, we introduce a\nsystematic methodology for sequentially learning tasks in the anti-jamming\nframework. By leveraging continual DRL techniques based on PackNet, we achieve\nsuperior anti-jamming performance compared to standard DRL methods. Our\nproposed approach not only addresses catastrophic forgetting but also enhances\nthe adaptability and robustness of the system in dynamic jamming environments.\nWe demonstrate the efficacy of our method in preserving knowledge of past\njammer patterns, learning new tasks efficiently, and achieving superior\nanti-jamming performance compared to traditional DRL approaches.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NI"
    ],
    "primary_category": "cs.LG",
    "comment": "IEEE MILCOM 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.10521v1",
    "published_date": "2024-10-14 14:00:32 UTC",
    "updated_date": "2024-10-14 14:00:32 UTC"
  },
  {
    "arxiv_id": "2410.10516v3",
    "title": "UniGEM: A Unified Approach to Generation and Property Prediction for Molecules",
    "authors": [
      "Shikun Feng",
      "Yuyan Ni",
      "Yan Lu",
      "Zhi-Ming Ma",
      "Wei-Ying Ma",
      "Yanyan Lan"
    ],
    "abstract": "Molecular generation and molecular property prediction are both crucial for\ndrug discovery, but they are often developed independently. Inspired by recent\nstudies, which demonstrate that diffusion model, a prominent generative\napproach, can learn meaningful data representations that enhance predictive\ntasks, we explore the potential for developing a unified generative model in\nthe molecular domain that effectively addresses both molecular generation and\nproperty prediction tasks. However, the integration of these tasks is\nchallenging due to inherent inconsistencies, making simple multi-task learning\nineffective. To address this, we propose UniGEM, the first unified model to\nsuccessfully integrate molecular generation and property prediction, delivering\nsuperior performance in both tasks. Our key innovation lies in a novel\ntwo-phase generative process, where predictive tasks are activated in the later\nstages, after the molecular scaffold is formed. We further enhance task balance\nthrough innovative training strategies. Rigorous theoretical analysis and\ncomprehensive experiments demonstrate our significant improvements in both\ntasks. The principles behind UniGEM hold promise for broader applications,\nincluding natural language processing and computer vision.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.BM"
    ],
    "primary_category": "cs.LG",
    "comment": "11 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.10516v3",
    "published_date": "2024-10-14 13:58:13 UTC",
    "updated_date": "2025-04-04 07:57:36 UTC"
  },
  {
    "arxiv_id": "2410.10502v1",
    "title": "A Practical Approach to Causal Inference over Time",
    "authors": [
      "Martina Cinquini",
      "Isacco Beretta",
      "Salvatore Ruggieri",
      "Isabel Valera"
    ],
    "abstract": "In this paper, we focus on estimating the causal effect of an intervention\nover time on a dynamical system. To that end, we formally define causal\ninterventions and their effects over time on discrete-time stochastic processes\n(DSPs). Then, we show under which conditions the equilibrium states of a DSP,\nboth before and after a causal intervention, can be captured by a structural\ncausal model (SCM). With such an equivalence at hand, we provide an explicit\nmapping from vector autoregressive models (VARs), broadly applied in\neconometrics, to linear, but potentially cyclic and/or affected by unmeasured\nconfounders, SCMs. The resulting causal VAR framework allows us to perform\ncausal inference over time from observational time series data. Our experiments\non synthetic and real-world datasets show that the proposed framework achieves\nstrong performance in terms of observational forecasting while enabling\naccurate estimation of the causal effect of interventions on dynamical systems.\nWe demonstrate, through a case study, the potential practical questions that\ncan be addressed using the proposed causal VAR framework.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.NA",
      "math.NA"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.10502v1",
    "published_date": "2024-10-14 13:45:20 UTC",
    "updated_date": "2024-10-14 13:45:20 UTC"
  },
  {
    "arxiv_id": "2410.10489v1",
    "title": "Cultural Fidelity in Large-Language Models: An Evaluation of Online Language Resources as a Driver of Model Performance in Value Representation",
    "authors": [
      "Sharif Kazemi",
      "Gloria Gerhardt",
      "Jonty Katz",
      "Caroline Ida Kuria",
      "Estelle Pan",
      "Umang Prabhakar"
    ],
    "abstract": "The training data for LLMs embeds societal values, increasing their\nfamiliarity with the language's culture. Our analysis found that 44% of the\nvariance in the ability of GPT-4o to reflect the societal values of a country,\nas measured by the World Values Survey, correlates with the availability of\ndigital resources in that language. Notably, the error rate was more than five\ntimes higher for the languages of the lowest resource compared to the languages\nof the highest resource. For GPT-4-turbo, this correlation rose to 72%,\nsuggesting efforts to improve the familiarity with the non-English language\nbeyond the web-scraped data. Our study developed one of the largest and most\nrobust datasets in this topic area with 21 country-language pairs, each of\nwhich contain 94 survey questions verified by native speakers. Our results\nhighlight the link between LLM performance and digital data availability in\ntarget languages. Weaker performance in low-resource languages, especially\nprominent in the Global South, may worsen digital divides. We discuss\nstrategies proposed to address this, including developing multilingual LLMs\nfrom the ground up and enhancing fine-tuning on diverse linguistic datasets, as\nseen in African language initiatives.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.10489v1",
    "published_date": "2024-10-14 13:33:00 UTC",
    "updated_date": "2024-10-14 13:33:00 UTC"
  },
  {
    "arxiv_id": "2410.10923v1",
    "title": "ATLAS: Adapter-Based Multi-Modal Continual Learning with a Two-Stage Learning Strategy",
    "authors": [
      "Hong Li",
      "Zhiquan Tan",
      "Xingyu Li",
      "Weiran Huang"
    ],
    "abstract": "While vision-and-language models significantly advance in many fields, the\nchallenge of continual learning is unsolved. Parameter-efficient modules like\nadapters and prompts present a promising way to alleviate catastrophic\nforgetting. However, existing works usually learn individual adapters for each\ntask, which may result in redundant knowledge among adapters. Moreover, they\ncontinue to use the original pre-trained model to initialize the downstream\nmodel, leading to negligible changes in the model's generalization compared to\nthe original model. In addition, there is still a lack of research\ninvestigating the consequences of integrating a multi-modal model into the\nupdating procedure for both uni-modal and multi-modal tasks and the subsequent\nimpacts it has on downstream tasks. In this paper, we propose an adapter-based\ntwo-stage learning paradigm, a multi-modal continual learning scheme that\nconsists of experience-based learning and novel knowledge expansion, which\nhelps the model fully use experience knowledge and compensate for novel\nknowledge. Extensive experiments demonstrate that our method is proficient for\ncontinual learning. It expands the distribution of representation upstream\nwhile also minimizing the negative impact of forgetting previous tasks.\nAdditionally, it enhances the generalization capability for downstream tasks.\nFurthermore, we incorporate both multi-modal and uni-modal tasks into upstream\ncontinual learning. We observe that learning from upstream tasks can help with\ndownstream tasks. Our code will be available at:\nhttps://github.com/lihong2303/ATLAS.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.10923v1",
    "published_date": "2024-10-14 13:29:42 UTC",
    "updated_date": "2024-10-14 13:29:42 UTC"
  },
  {
    "arxiv_id": "2410.10483v1",
    "title": "Advancing Newborn Care: Precise Birth Time Detection Using AI-Driven Thermal Imaging with Adaptive Normalization",
    "authors": [
      "Jorge García-Torres",
      "Øyvind Meinich-Bache",
      "Anders Johannessen",
      "Siren Rettedal",
      "Vilde Kolstad",
      "Kjersti Engan"
    ],
    "abstract": "Around 5-10\\% of newborns need assistance to start breathing. Currently,\nthere is a lack of evidence-based research, objective data collection, and\nopportunities for learning from real newborn resuscitation emergency events.\nGenerating and evaluating automated newborn resuscitation algorithm activity\ntimelines relative to the Time of Birth (ToB) offers a promising opportunity to\nenhance newborn care practices. Given the importance of prompt resuscitation\ninterventions within the \"golden minute\" after birth, having an accurate ToB\nwith second precision is essential for effective subsequent analysis of newborn\nresuscitation episodes. Instead, ToB is generally registered manually, often\nwith minute precision, making the process inefficient and susceptible to error\nand imprecision. In this work, we explore the fusion of Artificial Intelligence\n(AI) and thermal imaging to develop the first AI-driven ToB detector. The use\nof temperature information offers a promising alternative to detect the newborn\nwhile respecting the privacy of healthcare providers and mothers. However, the\nfrequent inconsistencies in thermal measurements, especially in a multi-camera\nsetup, make normalization strategies critical. Our methodology involves a\nthree-step process: first, we propose an adaptive normalization method based on\nGaussian mixture models (GMM) to mitigate issues related to temperature\nvariations; second, we implement and deploy an AI model to detect the presence\nof the newborn within the thermal video frames; and third, we evaluate and\npost-process the model's predictions to estimate the ToB. A precision of 88.1\\%\nand a recall of 89.3\\% are reported in the detection of the newborn within\nthermal frames during performance evaluation. Our approach achieves an absolute\nmedian deviation of 2.7 seconds in estimating the ToB relative to the manual\nannotations.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Paper submitted to Computer in Biology and Medicine, ELSEVIER",
    "pdf_url": "http://arxiv.org/pdf/2410.10483v1",
    "published_date": "2024-10-14 13:20:51 UTC",
    "updated_date": "2024-10-14 13:20:51 UTC"
  },
  {
    "arxiv_id": "2410.10481v2",
    "title": "Model-Based Privacy-Preserving Knowledge Transfer for Large Language Models",
    "authors": [
      "Zhaomin Wu",
      "Jizhou Guo",
      "Junyi Hou",
      "Bingsheng He",
      "Lixin Fan",
      "Qiang Yang"
    ],
    "abstract": "As large language models (LLMs) become more prevalent, effectively utilizing\ndomain-specific knowledge while ensuring privacy has become critical. Existing\nmethods often struggle to balance utility and privacy. For instance,\nretrieval-augmented generation (RAG) enables LLMs to access domain-specific\nknowledge but compromises the privacy of sensitive data. On the other hand,\ndifferentially private data synthesis techniques offer strong privacy\nguarantees but often result in poor utility. To address this challenge, we\npropose Llamdex, a novel framework that enhances LLMs using only models trained\non domain-specific data, integrated into LLMs through carefully designed\nconnection modules. Our approach significantly enhances the accuracy of\ndomain-specific tasks, achieving up to a 26% accuracy improvement compared to\nstate-of-the-art data synthesis methods under the same differential privacy\nconstraints. Experimental results show that Llamdex not only improves the\naccuracy of LLM responses but also maintains comparable inference efficiency to\nthe original LLM, highlighting its potential for real applications.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.10481v2",
    "published_date": "2024-10-14 13:18:20 UTC",
    "updated_date": "2025-02-14 09:47:42 UTC"
  },
  {
    "arxiv_id": "2410.10479v1",
    "title": "TMGBench: A Systematic Game Benchmark for Evaluating Strategic Reasoning Abilities of LLMs",
    "authors": [
      "Haochuan Wang",
      "Xiachong Feng",
      "Lei Li",
      "Zhanyue Qin",
      "Dianbo Sui",
      "Lingpeng Kong"
    ],
    "abstract": "The rapid advancement of large language models (LLMs) has accelerated their\napplication in reasoning, with strategic reasoning drawing increasing\nattention. To evaluate LLMs' strategic reasoning capabilities, game theory,\nwith its concise structure, has become a preferred approach. However, current\nresearch focuses on a limited selection of games, resulting in low coverage.\nClassic game scenarios risk data leakage, and existing benchmarks often lack\nextensibility, making them inadequate for evaluating state-of-the-art models.\nTo address these challenges, we propose TMGBench, a benchmark with\ncomprehensive game type coverage, novel scenarios, and flexible organization.\nSpecifically, we incorporate all 144 game types summarized by the\nRobinson-Goforth topology of 2x2 games, constructed as classic games. We also\nemploy synthetic data generation to create diverse, higher-quality scenarios\nthrough topic guidance and human inspection, referred to as story-based games.\nLastly, we provide a sustainable framework for increasingly powerful LLMs by\ntreating these games as atomic units and organizing them into more complex\nforms via sequential, parallel, and nested structures. Our comprehensive\nevaluation of mainstream LLMs covers tests on rational reasoning, robustness,\nTheory-of-Mind (ToM), and reasoning in complex forms. Results reveal flaws in\naccuracy, consistency, and varying mastery of ToM. Additionally, o1-mini,\nOpenAI's latest reasoning model, achieved accuracy rates of 66.6%, 60.0%, and\n70.0% on sequential, parallel, and nested games, highlighting TMGBench's\nchallenges.",
    "categories": [
      "cs.AI",
      "cs.GT"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.10479v1",
    "published_date": "2024-10-14 13:15:34 UTC",
    "updated_date": "2024-10-14 13:15:34 UTC"
  },
  {
    "arxiv_id": "2410.10476v2",
    "title": "Will LLMs Replace the Encoder-Only Models in Temporal Relation Classification?",
    "authors": [
      "Gabriel Roccabruna",
      "Massimo Rizzoli",
      "Giuseppe Riccardi"
    ],
    "abstract": "The automatic detection of temporal relations among events has been mainly\ninvestigated with encoder-only models such as RoBERTa. Large Language Models\n(LLM) have recently shown promising performance in temporal reasoning tasks\nsuch as temporal question answering. Nevertheless, recent studies have tested\nthe LLMs' performance in detecting temporal relations of closed-source models\nonly, limiting the interpretability of those results. In this work, we\ninvestigate LLMs' performance and decision process in the Temporal Relation\nClassification task. First, we assess the performance of seven open and\nclosed-sourced LLMs experimenting with in-context learning and lightweight\nfine-tuning approaches. Results show that LLMs with in-context learning\nsignificantly underperform smaller encoder-only models based on RoBERTa. Then,\nwe delve into the possible reasons for this gap by applying explainable\nmethods. The outcome suggests a limitation of LLMs in this task due to their\nautoregressive nature, which causes them to focus only on the last part of the\nsequence. Additionally, we evaluate the word embeddings of these two models to\nbetter understand their pre-training differences. The code and the fine-tuned\nmodels can be found respectively on GitHub.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.10476v2",
    "published_date": "2024-10-14 13:10:45 UTC",
    "updated_date": "2024-10-31 14:15:49 UTC"
  },
  {
    "arxiv_id": "2410.10463v1",
    "title": "TABCF: Counterfactual Explanations for Tabular Data Using a Transformer-Based VAE",
    "authors": [
      "Emmanouil Panagiotou",
      "Manuel Heurich",
      "Tim Landgraf",
      "Eirini Ntoutsi"
    ],
    "abstract": "In the field of Explainable AI (XAI), counterfactual (CF) explanations are\none prominent method to interpret a black-box model by suggesting changes to\nthe input that would alter a prediction. In real-world applications, the input\nis predominantly in tabular form and comprised of mixed data types and complex\nfeature interdependencies. These unique data characteristics are difficult to\nmodel, and we empirically show that they lead to bias towards specific feature\ntypes when generating CFs. To overcome this issue, we introduce TABCF, a CF\nexplanation method that leverages a transformer-based Variational Autoencoder\n(VAE) tailored for modeling tabular data. Our approach uses transformers to\nlearn a continuous latent space and a novel Gumbel-Softmax detokenizer that\nenables precise categorical reconstruction while preserving end-to-end\ndifferentiability. Extensive quantitative evaluation on five financial datasets\ndemonstrates that TABCF does not exhibit bias toward specific feature types,\nand outperforms existing methods in producing effective CFs that align with\ncommon CF desiderata.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "Paper accepted at ICAIF '24: 5th ACM International Conference on AI\n  in Finance, Brooklyn, NY, USA, November 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.10463v1",
    "published_date": "2024-10-14 12:55:41 UTC",
    "updated_date": "2024-10-14 12:55:41 UTC"
  },
  {
    "arxiv_id": "2410.10460v1",
    "title": "Compositional Shielding and Reinforcement Learning for Multi-Agent Systems",
    "authors": [
      "Asger Horn Brorholt",
      "Kim Guldstrand Larsen",
      "Christian Schilling"
    ],
    "abstract": "Deep reinforcement learning has emerged as a powerful tool for obtaining\nhigh-performance policies. However, the safety of these policies has been a\nlong-standing issue. One promising paradigm to guarantee safety is a shield,\nwhich shields a policy from making unsafe actions. However, computing a shield\nscales exponentially in the number of state variables. This is a particular\nconcern in multi-agent systems with many agents. In this work, we propose a\nnovel approach for multi-agent shielding. We address scalability by computing\nindividual shields for each agent. The challenge is that typical safety\nspecifications are global properties, but the shields of individual agents only\nensure local properties. Our key to overcome this challenge is to apply\nassume-guarantee reasoning. Specifically, we present a sound proof rule that\ndecomposes a (global, complex) safety specification into (local, simple)\nobligations for the shields of the individual agents. Moreover, we show that\napplying the shields during reinforcement learning significantly improves the\nquality of the policies obtained for a given training budget. We demonstrate\nthe effectiveness and scalability of our multi-agent shielding framework in two\ncase studies, reducing the computation time from hours to seconds and achieving\nfast learning convergence.",
    "categories": [
      "cs.LO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.LO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.10460v1",
    "published_date": "2024-10-14 12:52:48 UTC",
    "updated_date": "2024-10-14 12:52:48 UTC"
  },
  {
    "arxiv_id": "2410.12870v1",
    "title": "Skill Learning Using Process Mining for Large Language Model Plan Generation",
    "authors": [
      "Andrei Cosmin Redis",
      "Mohammadreza Fani Sani",
      "Bahram Zarrin",
      "Andrea Burattin"
    ],
    "abstract": "Large language models (LLMs) hold promise for generating plans for complex\ntasks, but their effectiveness is limited by sequential execution, lack of\ncontrol flow models, and difficulties in skill retrieval. Addressing these\nissues is crucial for improving the efficiency and interpretability of plan\ngeneration as LLMs become more central to automation and decision-making. We\nintroduce a novel approach to skill learning in LLMs by integrating process\nmining techniques, leveraging process discovery for skill acquisition, process\nmodels for skill storage, and conformance checking for skill retrieval. Our\nmethods enhance text-based plan generation by enabling flexible skill\ndiscovery, parallel execution, and improved interpretability. Experimental\nresults suggest the effectiveness of our approach, with our skill retrieval\nmethod surpassing state-of-the-art accuracy baselines under specific\nconditions.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.DB",
      "cs.ET",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "12 pages, 5 figures, 2 tables, accepted at ICPM 2024'",
    "pdf_url": "http://arxiv.org/pdf/2410.12870v1",
    "published_date": "2024-10-14 12:48:42 UTC",
    "updated_date": "2024-10-14 12:48:42 UTC"
  },
  {
    "arxiv_id": "2410.10451v2",
    "title": "Mobility-Aware Federated Learning: Multi-Armed Bandit Based Selection in Vehicular Network",
    "authors": [
      "Haoyu Tu",
      "Lin Chen",
      "Zuguang Li",
      "Xiaopei Chen",
      "Wen Wu"
    ],
    "abstract": "In this paper, we study a vehicle selection problem for federated learning\n(FL) over vehicular networks. Specifically, we design a mobility-aware\nvehicular federated learning (MAVFL) scheme in which vehicles drive through a\nroad segment to perform FL. Some vehicles may drive out of the segment which\nleads to unsuccessful training. In the proposed scheme, the real-time\nsuccessful training participation ratio is utilized to implement vehicle\nselection. We conduct the convergence analysis to indicate the influence of\nvehicle mobility on training loss. Furthermore, we propose a multi-armed\nbandit-based vehicle selection algorithm to minimize the utility function\nconsidering training loss and delay. The simulation results show that compared\nwith baselines, the proposed algorithm can achieve better training performance\nwith approximately 28\\% faster convergence.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by 2024 IEEE Globecom Workshops (GC Wkshps)",
    "pdf_url": "http://arxiv.org/pdf/2410.10451v2",
    "published_date": "2024-10-14 12:45:15 UTC",
    "updated_date": "2024-10-15 03:16:09 UTC"
  },
  {
    "arxiv_id": "2410.10450v2",
    "title": "KBLaM: Knowledge Base augmented Language Model",
    "authors": [
      "Xi Wang",
      "Taketomo Isazawa",
      "Liana Mikaelyan",
      "James Hensman"
    ],
    "abstract": "In this paper, we propose Knowledge Base augmented Language Model (KBLaM), a\nnew method for augmenting Large Language Models (LLMs) with external knowledge.\nKBLaM works with a knowledge base (KB) constructed from a corpus of documents,\ntransforming each piece of knowledge in the KB into continuous key-value vector\npairs via pre-trained sentence encoders with linear adapters and integrating\nthem into pre-trained LLMs via a specialized rectangular attention mechanism.\nUnlike Retrieval-Augmented Generation, KBLaM eliminates external retrieval\nmodules, and unlike in-context learning, its computational overhead scales\nlinearly with KB size rather than quadratically. Our approach enables\nintegrating a large KB of more than 10K triples into an 8B pre-trained LLM of\nonly 8K context window on one single A100 80GB GPU and allows for dynamic\nupdates without model fine-tuning or retraining. Experiments demonstrate\nKBLaM's effectiveness in various tasks, including question-answering and\nopen-ended reasoning, while providing interpretable insights into its use of\nthe augmented knowledge. Code and datasets are available at\nhttps://github.com/microsoft/KBLaM/",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.10450v2",
    "published_date": "2024-10-14 12:45:10 UTC",
    "updated_date": "2025-02-09 04:45:43 UTC"
  },
  {
    "arxiv_id": "2410.10441v2",
    "title": "Free Video-LLM: Prompt-guided Visual Perception for Efficient Training-free Video LLMs",
    "authors": [
      "Kai Han",
      "Jianyuan Guo",
      "Yehui Tang",
      "Wei He",
      "Enhua Wu",
      "Yunhe Wang"
    ],
    "abstract": "Vision-language large models have achieved remarkable success in various\nmulti-modal tasks, yet applying them to video understanding remains challenging\ndue to the inherent complexity and computational demands of video data. While\ntraining-based video-LLMs deliver high performance, they often require\nsubstantial resources for training and inference. Conversely, training-free\napproaches offer a more efficient alternative by adapting pre-trained\nimage-LLMs models for video tasks without additional training, but they face\ninference efficiency bottlenecks due to the large number of visual tokens\ngenerated from video frames. In this work, we present a novel prompt-guided\nvisual perception framework (abbreviated as Free Video-LLM) for efficient\ninference of training-free video LLMs. The proposed framework decouples\nspatial-temporal dimension and performs temporal frame sampling and spatial RoI\ncropping respectively based on task-specific prompts. Our method effectively\nreduces the number of visual tokens while maintaining high performance across\nmultiple video question-answering benchmarks. Extensive experiments demonstrate\nthat our approach achieves competitive results with significantly fewer tokens,\noffering an optimal trade-off between accuracy and computational efficiency\ncompared to state-of-the-art video LLMs. The code will be available at\nhttps://github.com/contrastive/FreeVideoLLM.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Tech report",
    "pdf_url": "http://arxiv.org/pdf/2410.10441v2",
    "published_date": "2024-10-14 12:35:12 UTC",
    "updated_date": "2024-10-16 09:45:06 UTC"
  },
  {
    "arxiv_id": "2410.10433v1",
    "title": "LKASeg:Remote-Sensing Image Semantic Segmentation with Large Kernel Attention and Full-Scale Skip Connections",
    "authors": [
      "Xuezhi Xiang",
      "Yibo Ning",
      "Lei Zhang",
      "Denis Ombati",
      "Himaloy Himu",
      "Xiantong Zhen"
    ],
    "abstract": "Semantic segmentation of remote sensing images is a fundamental task in\ngeospatial research. However, widely used Convolutional Neural Networks (CNNs)\nand Transformers have notable drawbacks: CNNs may be limited by insufficient\nremote sensing modeling capability, while Transformers face challenges due to\ncomputational complexity. In this paper, we propose a remote-sensing image\nsemantic segmentation network named LKASeg, which combines Large Kernel\nAttention(LSKA) and Full-Scale Skip Connections(FSC). Specifically, we propose\na decoder based on Large Kernel Attention (LKA), which extract global features\nwhile avoiding the computational overhead of self-attention and providing\nchannel adaptability. To achieve full-scale feature learning and fusion, we\napply Full-Scale Skip Connections (FSC) between the encoder and decoder. We\nconducted experiments by combining the LKA-based decoder with FSC. On the ISPRS\nVaihingen dataset, the mF1 and mIoU scores achieved 90.33% and 82.77%.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "The paper is under consideration at 2025 IEEE International\n  Conference on Acoustics, Speech, and Signal Processing (ICASSP 2025)",
    "pdf_url": "http://arxiv.org/pdf/2410.10433v1",
    "published_date": "2024-10-14 12:25:48 UTC",
    "updated_date": "2024-10-14 12:25:48 UTC"
  },
  {
    "arxiv_id": "2410.10398v2",
    "title": "FairMindSim: Alignment of Behavior, Emotion, and Belief in Humans and LLM Agents Amid Ethical Dilemmas",
    "authors": [
      "Yu Lei",
      "Hao Liu",
      "Chengxing Xie",
      "Songjia Liu",
      "Zhiyu Yin",
      "Canyu Chen",
      "Guohao Li",
      "Philip Torr",
      "Zhen Wu"
    ],
    "abstract": "AI alignment is a pivotal issue concerning AI control and safety. It should\nconsider not only value-neutral human preferences but also moral and ethical\nconsiderations. In this study, we introduced FairMindSim, which simulates the\nmoral dilemma through a series of unfair scenarios. We used LLM agents to\nsimulate human behavior, ensuring alignment across various stages. To explore\nthe various socioeconomic motivations, which we refer to as beliefs, that drive\nboth humans and LLM agents as bystanders to intervene in unjust situations\ninvolving others, and how these beliefs interact to influence individual\nbehavior, we incorporated knowledge from relevant sociological fields and\nproposed the Belief-Reward Alignment Behavior Evolution Model (BREM) based on\nthe recursive reward model (RRM). Our findings indicate that, behaviorally,\nGPT-4o exhibits a stronger sense of social justice, while humans display a\nricher range of emotions. Additionally, we discussed the potential impact of\nemotions on behavior. This study provides a theoretical foundation for\napplications in aligning LLMs with altruistic values.",
    "categories": [
      "cs.CE",
      "cs.AI"
    ],
    "primary_category": "cs.CE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.10398v2",
    "published_date": "2024-10-14 11:39:05 UTC",
    "updated_date": "2024-10-17 15:02:31 UTC"
  },
  {
    "arxiv_id": "2410.10394v2",
    "title": "PIVOT-R: Primitive-Driven Waypoint-Aware World Model for Robotic Manipulation",
    "authors": [
      "Kaidong Zhang",
      "Pengzhen Ren",
      "Bingqian Lin",
      "Junfan Lin",
      "Shikui Ma",
      "Hang Xu",
      "Xiaodan Liang"
    ],
    "abstract": "Language-guided robotic manipulation is a challenging task that requires an\nembodied agent to follow abstract user instructions to accomplish various\ncomplex manipulation tasks. Previous work trivially fitting the data without\nrevealing the relation between instruction and low-level executable actions,\nthese models are prone to memorizing the surficial pattern of the data instead\nof acquiring the transferable knowledge, and thus are fragile to dynamic\nenvironment changes. To address this issue, we propose a PrIrmitive-driVen\nwaypOinT-aware world model for Robotic manipulation (PIVOT-R) that focuses\nsolely on the prediction of task-relevant waypoints. Specifically, PIVOT-R\nconsists of a Waypoint-aware World Model (WAWM) and a lightweight action\nprediction module. The former performs primitive action parsing and\nprimitive-driven waypoint prediction, while the latter focuses on decoding\nlow-level actions. Additionally, we also design an asynchronous hierarchical\nexecutor (AHE), which can use different execution frequencies for different\nmodules of the model, thereby helping the model reduce computational redundancy\nand improve model execution efficiency. Our PIVOT-R outperforms\nstate-of-the-art (SoTA) open-source models on the SeaWave benchmark, achieving\nan average relative improvement of 19.45% across four levels of instruction\ntasks. Moreover, compared to the synchronously executed PIVOT-R, the execution\nefficiency of PIVOT-R with AHE is increased by 28-fold, with only a 2.9% drop\nin performance. These results provide compelling evidence that our PIVOT-R can\nsignificantly improve both the performance and efficiency of robotic\nmanipulation.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted to NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.10394v2",
    "published_date": "2024-10-14 11:30:18 UTC",
    "updated_date": "2024-10-16 08:20:44 UTC"
  },
  {
    "arxiv_id": "2410.10392v1",
    "title": "Optimizing Instruction Synthesis: Effective Exploration of Evolutionary Space with Tree Search",
    "authors": [
      "Chenglin Li",
      "Qianglong Chen",
      "Zhi Li",
      "Feng Tao",
      "Yicheng Li",
      "Hao Chen",
      "Fei Yu",
      "Yin Zhang"
    ],
    "abstract": "Instruction tuning is a crucial technique for aligning language models with\nhumans' actual goals in the real world. Extensive research has highlighted the\nquality of instruction data is essential for the success of this alignment.\nHowever, creating high-quality data manually is labor-intensive and\ntime-consuming, which leads researchers to explore using LLMs to synthesize\ndata. Recent studies have focused on using a stronger LLM to iteratively\nenhance existing instruction data, showing promising results. Nevertheless,\nprevious work often lacks control over the evolution direction, resulting in\nhigh uncertainty in the data synthesis process and low-quality instructions. In\nthis paper, we introduce a general and scalable framework, IDEA-MCTS\n(Instruction Data Enhancement using Monte Carlo Tree Search), a scalable\nframework for efficiently synthesizing instructions. With tree search and\nevaluation models, it can efficiently guide each instruction to evolve into a\nhigh-quality form, aiding in instruction fine-tuning. Experimental results show\nthat IDEA-MCTS significantly enhances the seed instruction data, raising the\naverage evaluation scores of quality, diversity, and complexity from 2.19 to\n3.81. Furthermore, in open-domain benchmarks, experimental results show that\nIDEA-MCTS improves the accuracy of real-world instruction-following skills in\nLLMs by an average of 5\\% in low-resource settings.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.10392v1",
    "published_date": "2024-10-14 11:28:30 UTC",
    "updated_date": "2024-10-14 11:28:30 UTC"
  },
  {
    "arxiv_id": "2410.10390v1",
    "title": "Stein Variational Evolution Strategies",
    "authors": [
      "Cornelius V. Braun",
      "Robert T. Lange",
      "Marc Toussaint"
    ],
    "abstract": "Stein Variational Gradient Descent (SVGD) is a highly efficient method to\nsample from an unnormalized probability distribution. However, the SVGD update\nrelies on gradients of the log-density, which may not always be available.\nExisting gradient-free versions of SVGD make use of simple Monte Carlo\napproximations or gradients from surrogate distributions, both with\nlimitations. To improve gradient-free Stein variational inference, we combine\nSVGD steps with evolution strategy (ES) updates. Our results demonstrate that\nthe resulting algorithm generates high-quality samples from unnormalized target\ndensities without requiring gradient information. Compared to prior\ngradient-free SVGD methods, we find that the integration of the ES update in\nSVGD significantly improves the performance on multiple challenging benchmark\nproblems.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.10390v1",
    "published_date": "2024-10-14 11:24:41 UTC",
    "updated_date": "2024-10-14 11:24:41 UTC"
  },
  {
    "arxiv_id": "2410.10372v1",
    "title": "BookWorm: A Dataset for Character Description and Analysis",
    "authors": [
      "Argyrios Papoudakis",
      "Mirella Lapata",
      "Frank Keller"
    ],
    "abstract": "Characters are at the heart of every story, driving the plot and engaging\nreaders. In this study, we explore the understanding of characters in\nfull-length books, which contain complex narratives and numerous interacting\ncharacters. We define two tasks: character description, which generates a brief\nfactual profile, and character analysis, which offers an in-depth\ninterpretation, including character development, personality, and social\ncontext. We introduce the BookWorm dataset, pairing books from the Gutenberg\nProject with human-written descriptions and analyses. Using this dataset, we\nevaluate state-of-the-art long-context models in zero-shot and fine-tuning\nsettings, utilizing both retrieval-based and hierarchical processing for\nbook-length inputs. Our findings show that retrieval-based approaches\noutperform hierarchical ones in both tasks. Additionally, fine-tuned models\nusing coreference-based retrieval produce the most factual descriptions, as\nmeasured by fact- and entailment-based metrics. We hope our dataset,\nexperiments, and analysis will inspire further research in character-based\nnarrative understanding.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "30 pages, 2 figures, EMNLP 2024 Findings",
    "pdf_url": "http://arxiv.org/pdf/2410.10372v1",
    "published_date": "2024-10-14 10:55:58 UTC",
    "updated_date": "2024-10-14 10:55:58 UTC"
  },
  {
    "arxiv_id": "2410.10370v2",
    "title": "Innovative Thinking, Infinite Humor: Humor Research of Large Language Models through Structured Thought Leaps",
    "authors": [
      "Han Wang",
      "Yilin Zhao",
      "Dian Li",
      "Xiaohan Wang",
      "Gang Liu",
      "Xuguang Lan",
      "Hui Wang"
    ],
    "abstract": "Humor is previously regarded as a gift exclusive to humans for the following\nreasons. Humor is a culturally nuanced aspect of human language, presenting\nchallenges for its understanding and generation. Humor generation necessitates\na multi-hop reasoning process, with each hop founded on proper rationales.\nAlthough many studies, such as those related to GPT-o1, focus on logical\nreasoning with reflection and correction, they still fall short in humor\ngeneration. Due to the sparsity of the knowledge graph in creative thinking, it\nis arduous to achieve multi-hop reasoning. Consequently, in this paper, we\npropose a more robust framework for addressing the humor reasoning task, named\nLoL. LoL aims to inject external information to mitigate the sparsity of the\nknowledge graph, thereby enabling multi-hop reasoning. In the first stage of\nLoL, we put forward an automatic instruction-evolution method to incorporate\nthe deeper and broader thinking processes underlying humor. Judgment-oriented\ninstructions are devised to enhance the model's judgment capability,\ndynamically supplementing and updating the sparse knowledge graph.\nSubsequently, through reinforcement learning, the reasoning logic for each\nonline-generated response is extracted using GPT-4o. In this process, external\nknowledge is re-introduced to aid the model in logical reasoning and the\nlearning of human preferences. Finally, experimental results indicate that the\ncombination of these two processes can enhance both the model's judgment\nability and its generative capacity. These findings deepen our comprehension of\nthe creative capabilities of large language models (LLMs) and offer approaches\nto boost LLMs' creative abilities for cross-domain innovative applications.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.10370v2",
    "published_date": "2024-10-14 10:50:16 UTC",
    "updated_date": "2025-04-11 01:52:15 UTC"
  },
  {
    "arxiv_id": "2410.10366v1",
    "title": "Affinity-Graph-Guided Contractive Learning for Pretext-Free Medical Image Segmentation with Minimal Annotation",
    "authors": [
      "Zehua Cheng",
      "Di Yuan",
      "Thomas Lukasiewicz"
    ],
    "abstract": "The combination of semi-supervised learning (SemiSL) and contrastive learning\n(CL) has been successful in medical image segmentation with limited\nannotations. However, these works often rely on pretext tasks that lack the\nspecificity required for pixel-level segmentation, and still face overfitting\nissues due to insufficient supervision signals resulting from too few\nannotations. Therefore, this paper proposes an affinity-graph-guided\nsemi-supervised contrastive learning framework (Semi-AGCL) by establishing\nadditional affinity-graph-based supervision signals between the student and\nteacher network, to achieve medical image segmentation with minimal annotations\nwithout pretext. The framework first designs an average-patch-entropy-driven\ninter-patch sampling method, which can provide a robust initial feature space\nwithout relying on pretext tasks. Furthermore, the framework designs an\naffinity-graph-guided loss function, which can improve the quality of the\nlearned representation and the model generalization ability by exploiting the\ninherent structure of the data, thus mitigating overfitting. Our experiments\nindicate that with merely 10% of the complete annotation set, our model\napproaches the accuracy of the fully annotated baseline, manifesting a marginal\ndeviation of only 2.52%. Under the stringent conditions where only 5% of the\nannotations are employed, our model exhibits a significant enhancement in\nperformance surpassing the second best baseline by 23.09% on the dice metric\nand achieving an improvement of 26.57% on the notably arduous CRAG and ACDC\ndatasets.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "BIBM 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.10366v1",
    "published_date": "2024-10-14 10:44:47 UTC",
    "updated_date": "2024-10-14 10:44:47 UTC"
  },
  {
    "arxiv_id": "2410.10365v1",
    "title": "SpeGCL: Self-supervised Graph Spectrum Contrastive Learning without Positive Samples",
    "authors": [
      "Yuntao Shou",
      "Xiangyong Cao",
      "Deyu Meng"
    ],
    "abstract": "Graph Contrastive Learning (GCL) excels at managing noise and fluctuations in\ninput data, making it popular in various fields (e.g., social networks, and\nknowledge graphs). Our study finds that the difference in high-frequency\ninformation between augmented graphs is greater than that in low-frequency\ninformation. However, most existing GCL methods focus mainly on the time domain\n(low-frequency information) for node feature representations and cannot make\ngood use of high-frequency information to speed up model convergence.\nFurthermore, existing GCL paradigms optimize graph embedding representations by\npulling the distance between positive sample pairs closer and pushing the\ndistance between positive and negative sample pairs farther away, but our\ntheoretical analysis shows that graph contrastive learning benefits from\npushing negative pairs farther away rather than pulling positive pairs closer.\nTo solve the above-mentioned problems, we propose a novel spectral GCL\nframework without positive samples, named SpeGCL. Specifically, to solve the\nproblem that existing GCL methods cannot utilize high-frequency information,\nSpeGCL uses a Fourier transform to extract high-frequency and low-frequency\ninformation of node features, and constructs a contrastive learning mechanism\nin a Fourier space to obtain better node feature representation. Furthermore,\nSpeGCL relies entirely on negative samples to refine the graph embedding. We\nalso provide a theoretical justification for the efficacy of using only\nnegative samples in SpeGCL. Extensive experiments on un-supervised learning,\ntransfer learning, and semi-supervised learning have validated the superiority\nof our SpeGCL framework over the state-of-the-art GCL methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "13 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.10365v1",
    "published_date": "2024-10-14 10:39:38 UTC",
    "updated_date": "2024-10-14 10:39:38 UTC"
  },
  {
    "arxiv_id": "2410.11580v1",
    "title": "LCD-Net: A Lightweight Remote Sensing Change Detection Network Combining Feature Fusion and Gating Mechanism",
    "authors": [
      "Wenyu Liu",
      "Jindong Li",
      "Haoji Wang",
      "Run Tan",
      "Yali Fu",
      "Qichuan Tian"
    ],
    "abstract": "Remote sensing image change detection (RSCD) is crucial for monitoring\ndynamic surface changes, with applications ranging from environmental\nmonitoring to disaster assessment. While traditional CNN-based methods have\nimproved detection accuracy, they often suffer from high computational\ncomplexity and large parameter counts, limiting their use in\nresource-constrained environments. To address these challenges, we propose a\nLightweight remote sensing Change Detection Network (LCD-Net in short) that\nreduces model size and computational cost while maintaining high detection\nperformance. LCD-Net employs MobileNetV2 as the encoder to efficiently extract\nfeatures from bitemporal images. A Temporal Interaction and Fusion Module (TIF)\nenhances the interaction between bitemporal features, improving temporal\ncontext awareness. Additionally, the Feature Fusion Module (FFM) aggregates\nmultiscale features to better capture subtle changes while suppressing\nbackground noise. The Gated Mechanism Module (GMM) in the decoder further\nenhances feature learning by dynamically adjusting channel weights, emphasizing\nkey change regions. Experiments on LEVIR-CD+, SYSU, and S2Looking datasets show\nthat LCD-Net achieves competitive performance with just 2.56M parameters and\n4.45G FLOPs, making it well-suited for real-time applications in\nresource-limited settings. The code is available at\nhttps://github.com/WenyuLiu6/LCD-Net.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.11580v1",
    "published_date": "2024-10-14 10:33:30 UTC",
    "updated_date": "2024-10-14 10:33:30 UTC"
  },
  {
    "arxiv_id": "2410.10336v1",
    "title": "CoMAT: Chain of Mathematically Annotated Thought Improves Mathematical Reasoning",
    "authors": [
      "Joshua Ong Jun Leang",
      "Aryo Pradipta Gema",
      "Shay B. Cohen"
    ],
    "abstract": "Mathematical reasoning remains a significant challenge for large language\nmodels (LLMs), despite progress in prompting techniques such as\nChain-of-Thought (CoT). We present Chain of Mathematically Annotated Thought\n(CoMAT), which enhances reasoning through two stages: Symbolic Conversion\n(converting natural language queries into symbolic form) and Reasoning\nExecution (deriving answers from symbolic representations). CoMAT operates\nentirely with a single LLM and without external solvers. Across four LLMs,\nCoMAT outperforms traditional CoT on six out of seven benchmarks, achieving\ngains of 4.48% on MMLU-Redux (MATH) and 4.58% on GaoKao MCQ. In addition to\nimproved performance, CoMAT ensures faithfulness and verifiability, offering a\ntransparent reasoning process for complex mathematical tasks",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.SC"
    ],
    "primary_category": "cs.AI",
    "comment": "8 pages, 12 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.10336v1",
    "published_date": "2024-10-14 09:48:41 UTC",
    "updated_date": "2024-10-14 09:48:41 UTC"
  },
  {
    "arxiv_id": "2410.10332v1",
    "title": "Disentangling Hate Across Target Identities",
    "authors": [
      "Yiping Jin",
      "Leo Wanner",
      "Aneesh Moideen Koya"
    ],
    "abstract": "Hate speech (HS) classifiers do not perform equally well in detecting hateful\nexpressions towards different target identities. They also demonstrate\nsystematic biases in predicted hatefulness scores. Tapping on two recently\nproposed functionality test datasets for HS detection, we quantitatively\nanalyze the impact of different factors on HS prediction. Experiments on\npopular industrial and academic models demonstrate that HS detectors assign a\nhigher hatefulness score merely based on the mention of specific target\nidentities. Besides, models often confuse hatefulness and the polarity of\nemotions. This result is worrisome as the effort to build HS detectors might\nharm the vulnerable identity groups we wish to protect: posts expressing anger\nor disapproval of hate expressions might be flagged as hateful themselves. We\nalso carry out a study inspired by social psychology theory, which reveals that\nthe accuracy of hatefulness prediction correlates strongly with the intensity\nof the stereotype.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.10332v1",
    "published_date": "2024-10-14 09:43:08 UTC",
    "updated_date": "2024-10-14 09:43:08 UTC"
  },
  {
    "arxiv_id": "2410.10329v4",
    "title": "GraphCLIP: Enhancing Transferability in Graph Foundation Models for Text-Attributed Graphs",
    "authors": [
      "Yun Zhu",
      "Haizhou Shi",
      "Xiaotang Wang",
      "Yongchao Liu",
      "Yaoke Wang",
      "Boci Peng",
      "Chuntao Hong",
      "Siliang Tang"
    ],
    "abstract": "Recently, research on Text-Attributed Graphs (TAGs) has gained significant\nattention due to the prevalence of free-text node features in real-world\napplications and the advancements in Large Language Models (LLMs) that bolster\nTAG methodologies. However, current TAG approaches face two primary challenges:\n(i) Heavy reliance on label information and (ii) Limited cross-domain\nzero/few-shot transferability. These issues constrain the scaling of both data\nand model size, owing to high labor costs and scaling laws, complicating the\ndevelopment of graph foundation models with strong transferability. In this\nwork, we propose the GraphCLIP framework to address these challenges by\nlearning graph foundation models with strong cross-domain zero/few-shot\ntransferability through a self-supervised contrastive graph-summary pretraining\nmethod. Specifically, we generate and curate large-scale graph-summary pair\ndata with the assistance of LLMs, and introduce a novel graph-summary\npretraining method, combined with invariant learning, to enhance graph\nfoundation models with strong cross-domain zero-shot transferability. For\nfew-shot learning, we propose a novel graph prompt tuning technique aligned\nwith our pretraining objective to mitigate catastrophic forgetting and minimize\nlearning costs. Extensive experiments show the superiority of GraphCLIP in both\nzero-shot and few-shot settings, while evaluations across various downstream\ntasks confirm the versatility of GraphCLIP. Our code is available at:\nhttps://github.com/ZhuYun97/GraphCLIP",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to WWW'25",
    "pdf_url": "http://arxiv.org/pdf/2410.10329v4",
    "published_date": "2024-10-14 09:40:52 UTC",
    "updated_date": "2025-02-24 09:34:38 UTC"
  },
  {
    "arxiv_id": "2410.10320v1",
    "title": "DiRW: Path-Aware Digraph Learning for Heterophily",
    "authors": [
      "Daohan Su",
      "Xunkai Li",
      "Zhenjun Li",
      "Yinping Liao",
      "Rong-Hua Li",
      "Guoren Wang"
    ],
    "abstract": "Recently, graph neural network (GNN) has emerged as a powerful representation\nlearning tool for graph-structured data. However, most approaches are tailored\nfor undirected graphs, neglecting the abundant information embedded in the\nedges of directed graphs (digraphs). In fact, digraphs are widely applied in\nthe real world (e.g., social networks and recommendations) and are also\nconfirmed to offer a new perspective for addressing topological heterophily\nchallenges (i.e., connected nodes have complex patterns of feature distribution\nor labels). Despite recent significant advancements in DiGNNs, existing\nspatial- and spectral-based methods have inherent limitations due to the\ncomplex learning mechanisms and reliance on high-quality topology, leading to\nlow efficiency and unstable performance. To address these issues, we propose\nDirected Random Walk (DiRW), which can be viewed as a plug-and-play strategy or\nan innovative neural architecture that provides a guidance or new learning\nparadigm for most spatial-based methods or digraphs. Specifically, DiRW\nincorporates a direction-aware path sampler optimized from the perspectives of\nwalk probability, length, and number in a weight-free manner by considering\nnode profiles and topological structure. Building upon this, DiRW utilizes a\nnode-wise learnable path aggregator for generalized messages obtained by our\nproposed adaptive walkers to represent the current node. Extensive experiments\non 9 datasets demonstrate that DiRW: (1) enhances most spatial-based methods as\na plug-and-play strategy; (2) achieves SOTA performance as a new digraph\nlearning paradigm.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Under Review",
    "pdf_url": "http://arxiv.org/pdf/2410.10320v1",
    "published_date": "2024-10-14 09:26:56 UTC",
    "updated_date": "2024-10-14 09:26:56 UTC"
  },
  {
    "arxiv_id": "2410.10315v2",
    "title": "EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations",
    "authors": [
      "Zhangchi Feng",
      "Dongdong Kuang",
      "Zhongyuan Wang",
      "Zhijie Nie",
      "Yaowei Zheng",
      "Richong Zhang"
    ],
    "abstract": "This paper presents EasyRAG, a simple, lightweight, and efficient\nretrieval-augmented generation framework for automated network operations. Our\nframework has three advantages. The first is accurate question answering. We\ndesigned a straightforward RAG scheme based on (1) a specific data processing\nworkflow (2) dual-route sparse retrieval for coarse ranking (3) LLM Reranker\nfor reranking (4) LLM answer generation and optimization. This approach\nachieved first place in the GLM4 track in the preliminary round and second\nplace in the GLM4 track in the semifinals. The second is simple deployment. Our\nmethod primarily consists of BM25 retrieval and BGE-reranker reranking,\nrequiring no fine-tuning of any models, occupying minimal VRAM, easy to deploy,\nand highly scalable; we provide a flexible code library with various search and\ngeneration strategies, facilitating custom process implementation. The last one\nis efficient inference. We designed an efficient inference acceleration scheme\nfor the entire coarse ranking, reranking, and generation process that\nsignificantly reduces the inference latency of RAG while maintaining a good\nlevel of accuracy; each acceleration scheme can be plug-and-play into any\ncomponent of the RAG process, consistently enhancing the efficiency of the RAG\nsystem. Our code and data are released at\n\\url{https://github.com/BUAADreamer/EasyRAG}.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "10 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.10315v2",
    "published_date": "2024-10-14 09:17:43 UTC",
    "updated_date": "2024-10-15 02:21:27 UTC"
  },
  {
    "arxiv_id": "2410.10291v4",
    "title": "Evaluating Semantic Variation in Text-to-Image Synthesis: A Causal Perspective",
    "authors": [
      "Xiangru Zhu",
      "Penglei Sun",
      "Yaoxian Song",
      "Yanghua Xiao",
      "Zhixu Li",
      "Chengyu Wang",
      "Jun Huang",
      "Bei Yang",
      "Xiaoxiao Xu"
    ],
    "abstract": "Accurate interpretation and visualization of human instructions are crucial\nfor text-to-image (T2I) synthesis. However, current models struggle to capture\nsemantic variations from word order changes, and existing evaluations, relying\non indirect metrics like text-image similarity, fail to reliably assess these\nchallenges. This often obscures poor performance on complex or uncommon\nlinguistic patterns by the focus on frequent word combinations. To address\nthese deficiencies, we propose a novel metric called SemVarEffect and a\nbenchmark named SemVarBench, designed to evaluate the causality between\nsemantic variations in inputs and outputs in T2I synthesis. Semantic variations\nare achieved through two types of linguistic permutations, while avoiding\neasily predictable literal variations. Experiments reveal that the\nCogView-3-Plus and Ideogram 2 performed the best, achieving a score of 0.2/1.\nSemantic variations in object relations are less understood than attributes,\nscoring 0.07/1 compared to 0.17-0.19/1. We found that cross-modal alignment in\nUNet or Transformers plays a crucial role in handling semantic variations, a\nfactor previously overlooked by a focus on textual encoders. Our work\nestablishes an effective evaluation framework that advances the T2I synthesis\ncommunity's exploration of human instruction understanding. Our benchmark and\ncode are available at https://github.com/zhuxiangru/SemVarBench .",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "cs.MM"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.10291v4",
    "published_date": "2024-10-14 08:45:35 UTC",
    "updated_date": "2025-04-17 08:31:14 UTC"
  },
  {
    "arxiv_id": "2410.10285v2",
    "title": "ABBA-VSM: Time Series Classification using Symbolic Representation on the Edge",
    "authors": [
      "Meerzhan Kanatbekova",
      "Shashikant Ilager",
      "Ivona Brandic"
    ],
    "abstract": "In recent years, Edge AI has become more prevalent with applications across\nvarious industries, from environmental monitoring to smart city management.\nEdge AI facilitates the processing of Internet of Things (IoT) data and\nprovides privacy-enabled and latency-sensitive services to application users\nusing Machine Learning (ML) algorithms, e.g., Time Series Classification (TSC).\nHowever, existing TSC algorithms require access to full raw data and demand\nsubstantial computing resources to train and use them effectively in runtime.\nThis makes them impractical for deployment in resource-constrained Edge\nenvironments. To address this, in this paper, we propose an Adaptive Brownian\nBridge-based Symbolic Aggregation Vector Space Model (ABBA-VSM). It is a new\nTSC model designed for classification services on Edge. Here, we first\nadaptively compress the raw time series into symbolic representations, thus\ncapturing the changing trends of data. Subsequently, we train the\nclassification model directly on these symbols. ABBA-VSM reduces communication\ndata between IoT and Edge devices, as well as computation cycles, in the\ndevelopment of resource-efficient TSC services on Edge. We evaluate our\nsolution with extensive experiments using datasets from the UCR time series\nclassification archive. The results demonstrate that the ABBA-VSM achieves up\nto 80% compression ratio and 90-100% accuracy for binary classification.\nWhereas, for non-binary classification, it achieves an average compression\nratio of 60% and accuracy ranging from 60-80%.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "15 pages with references, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.10285v2",
    "published_date": "2024-10-14 08:37:40 UTC",
    "updated_date": "2024-11-05 09:43:49 UTC"
  },
  {
    "arxiv_id": "2410.10284v3",
    "title": "Trust or Bust: Ensuring Trustworthiness in Autonomous Weapon Systems",
    "authors": [
      "Kasper Cools",
      "Clara Maathuis"
    ],
    "abstract": "The integration of Autonomous Weapon Systems (AWS) into military operations\npresents both significant opportunities and challenges. This paper explores the\nmultifaceted nature of trust in AWS, emphasising the necessity of establishing\nreliable and transparent systems to mitigate risks associated with bias,\noperational failures, and accountability. Despite advancements in Artificial\nIntelligence (AI), the trustworthiness of these systems, especially in\nhigh-stakes military applications, remains a critical issue. Through a\nsystematic review of existing literature, this research identifies gaps in the\nunderstanding of trust dynamics during the development and deployment phases of\nAWS. It advocates for a collaborative approach that includes technologists,\nethicists, and military strategists to address these ongoing challenges. The\nfindings underscore the importance of Human-Machine teaming and enhancing\nsystem intelligibility to ensure accountability and adherence to International\nHumanitarian Law. Ultimately, this paper aims to contribute to the ongoing\ndiscourse on the ethical implications of AWS and the imperative for trustworthy\nAI in defense contexts.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CY",
    "comment": "Accepted as a workshop paper at MILCOM 2024, 8 pages",
    "pdf_url": "http://arxiv.org/pdf/2410.10284v3",
    "published_date": "2024-10-14 08:36:06 UTC",
    "updated_date": "2024-10-21 05:22:13 UTC"
  },
  {
    "arxiv_id": "2410.10270v3",
    "title": "QUIS: Question-guided Insights Generation for Automated Exploratory Data Analysis",
    "authors": [
      "Abhijit Manatkar",
      "Ashlesha Akella",
      "Parthivi Gupta",
      "Krishnasuri Narayanam"
    ],
    "abstract": "Discovering meaningful insights from a large dataset, known as Exploratory\nData Analysis (EDA), is a challenging task that requires thorough exploration\nand analysis of the data. Automated Data Exploration (ADE) systems use\ngoal-oriented methods with Large Language Models and Reinforcement Learning\ntowards full automation. However, these methods require human involvement to\nanticipate goals that may limit insight extraction, while fully automated\nsystems demand significant computational resources and retraining for new\ndatasets. We introduce QUIS, a fully automated EDA system that operates in two\nstages: insight generation (ISGen) driven by question generation (QUGen). The\nQUGen module generates questions in iterations, refining them from previous\niterations to enhance coverage without human intervention or manually curated\nexamples. The ISGen module analyzes data to produce multiple relevant insights\nin response to each question, requiring no prior training and enabling QUIS to\nadapt to new datasets.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.DB",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted for EMNLP 2024 Industry Track",
    "pdf_url": "http://arxiv.org/pdf/2410.10270v3",
    "published_date": "2024-10-14 08:21:25 UTC",
    "updated_date": "2024-10-21 08:13:45 UTC"
  },
  {
    "arxiv_id": "2410.10254v3",
    "title": "LoLCATs: On Low-Rank Linearizing of Large Language Models",
    "authors": [
      "Michael Zhang",
      "Simran Arora",
      "Rahul Chalamala",
      "Alan Wu",
      "Benjamin Spector",
      "Aaryan Singhal",
      "Krithik Ramesh",
      "Christopher Ré"
    ],
    "abstract": "Recent works show we can linearize large language models (LLMs) -- swapping\nthe quadratic attentions of popular Transformer-based LLMs with subquadratic\nanalogs, such as linear attention -- avoiding the expensive pretraining costs.\nHowever, linearizing LLMs often significantly degrades model quality, still\nrequires training over billions of tokens, and remains limited to smaller 1.3B\nto 7B LLMs. We thus propose Low-rank Linear Conversion via Attention Transfer\n(LoLCATs), a simple two-step method that improves LLM linearizing quality with\norders of magnitudes less memory and compute. We base these steps on two\nfindings. First, we can replace an LLM's softmax attentions with\nclosely-approximating linear attentions, simply by training the linear\nattentions to match their softmax counterparts with an output MSE loss\n(\"attention transfer\"). Then, this enables adjusting for approximation errors\nand recovering LLM quality simply with low-rank adaptation (LoRA). LoLCATs\nsignificantly improves linearizing quality, training efficiency, and\nscalability. We significantly reduce the linearizing quality gap and produce\nstate-of-the-art subquadratic LLMs from Llama 3 8B and Mistral 7B v0.1, leading\nto 20+ points of improvement on 5-shot MMLU. Furthermore, LoLCATs does so with\nonly 0.2% of past methods' model parameters and 0.4% of their training tokens.\nFinally, we apply LoLCATs to create the first linearized 70B and 405B LLMs (50x\nlarger than prior work). When compared with prior approaches under the same\ncompute budgets, LoLCATs significantly improves linearizing quality, closing\nthe gap between linearized and original Llama 3.1 70B and 405B LLMs by 77.8%\nand 78.1% on 5-shot MMLU.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "58 pages, 25 figures, 26 tables, ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.10254v3",
    "published_date": "2024-10-14 08:10:34 UTC",
    "updated_date": "2025-03-05 21:57:04 UTC"
  },
  {
    "arxiv_id": "2410.10253v3",
    "title": "Feedback Favors the Generalization of Neural ODEs",
    "authors": [
      "Jindou Jia",
      "Zihan Yang",
      "Meng Wang",
      "Kexin Guo",
      "Jianfei Yang",
      "Xiang Yu",
      "Lei Guo"
    ],
    "abstract": "The well-known generalization problem hinders the application of artificial\nneural networks in continuous-time prediction tasks with varying latent\ndynamics. In sharp contrast, biological systems can neatly adapt to evolving\nenvironments benefiting from real-time feedback mechanisms. Inspired by the\nfeedback philosophy, we present feedback neural networks, showing that a\nfeedback loop can flexibly correct the learned latent dynamics of neural\nordinary differential equations (neural ODEs), leading to a prominent\ngeneralization improvement. The feedback neural network is a novel two-DOF\nneural network, which possesses robust performance in unseen scenarios with no\nloss of accuracy performance on previous tasks.} A linear feedback form is\npresented to correct the learned latent dynamics firstly, with a convergence\nguarantee. Then, domain randomization is utilized to learn a nonlinear neural\nfeedback form. Finally, extensive tests including trajectory prediction of a\nreal irregular object and model predictive control of a quadrotor with various\nuncertainties, are implemented, indicating significant improvements over\nstate-of-the-art model-based and learning-based methods.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "27 pages, 23 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.10253v3",
    "published_date": "2024-10-14 08:09:45 UTC",
    "updated_date": "2025-03-07 02:53:18 UTC"
  },
  {
    "arxiv_id": "2410.10247v2",
    "title": "LOBG:Less Overfitting for Better Generalization in Vision-Language Model",
    "authors": [
      "Chenhao Ding",
      "Xinyuan Gao",
      "Songlin Dong",
      "Yuhang He",
      "Qiang Wang",
      "Alex Kot",
      "Yihong Gong"
    ],
    "abstract": "Existing prompt learning methods in Vision-Language Models (VLM) have\neffectively enhanced the transfer capability of VLM to downstream tasks, but\nthey suffer from a significant decline in generalization due to severe\noverfitting. To address this issue, we propose a framework named LOBG for\nvision-language models. Specifically, we use CLIP to filter out fine-grained\nforeground information that might cause overfitting, thereby guiding prompts\nwith basic visual concepts. To further mitigate overfitting, we devel oped a\nstructural topology preservation (STP) loss at the feature level, which endows\nthe feature space with overall plasticity, allowing effective reshaping of the\nfeature space during optimization. Additionally, we employed hierarchical logit\ndistilation (HLD) at the output level to constrain outputs, complementing STP\nat the output end. Extensive experimental results demonstrate that our method\nsignificantly improves generalization capability and alleviates overfitting\ncompared to state-of-the-art approaches.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.10247v2",
    "published_date": "2024-10-14 08:06:21 UTC",
    "updated_date": "2024-10-27 10:40:39 UTC"
  },
  {
    "arxiv_id": "2410.10241v1",
    "title": "Revisiting and Benchmarking Graph Autoencoders: A Contrastive Learning Perspective",
    "authors": [
      "Jintang Li",
      "Ruofan Wu",
      "Yuchang Zhu",
      "Huizhe Zhang",
      "Xinzhou Jin",
      "Guibin Zhang",
      "Zulun Zhu",
      "Zibin Zheng",
      "Liang Chen"
    ],
    "abstract": "Graph autoencoders (GAEs) are self-supervised learning models that can learn\nmeaningful representations of graph-structured data by reconstructing the input\ngraph from a low-dimensional latent space. Over the past few years, GAEs have\ngained significant attention in academia and industry. In particular, the\nrecent advent of GAEs with masked autoencoding schemes marks a significant\nadvancement in graph self-supervised learning research. While numerous GAEs\nhave been proposed, the underlying mechanisms of GAEs are not well understood,\nand a comprehensive benchmark for GAEs is still lacking. In this work, we\nbridge the gap between GAEs and contrastive learning by establishing conceptual\nand methodological connections. We revisit the GAEs studied in previous works\nand demonstrate how contrastive learning principles can be applied to GAEs.\nMotivated by these insights, we introduce lrGAE (left-right GAE), a general and\npowerful GAE framework that leverages contrastive learning principles to learn\nmeaningful representations. Our proposed lrGAE not only facilitates a deeper\nunderstanding of GAEs but also sets a new benchmark for GAEs across diverse\ngraph-based learning tasks. The source code for lrGAE, including the baselines\nand all the code for reproducing the results, is publicly available at\nhttps://github.com/EdisonLeeeee/lrGAE.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Preprint, under review",
    "pdf_url": "http://arxiv.org/pdf/2410.10241v1",
    "published_date": "2024-10-14 07:59:30 UTC",
    "updated_date": "2024-10-14 07:59:30 UTC"
  },
  {
    "arxiv_id": "2410.10238v2",
    "title": "ForgeryGPT: Multimodal Large Language Model For Explainable Image Forgery Detection and Localization",
    "authors": [
      "Jiawei Liu",
      "Fanrui Zhang",
      "Jiaying Zhu",
      "Esther Sun",
      "Qiang Zhang",
      "Zheng-Jun Zha"
    ],
    "abstract": "Multimodal Large Language Models (MLLMs), such as GPT4o, have shown strong\ncapabilities in visual reasoning and explanation generation. However, despite\nthese strengths, they face significant challenges in the increasingly critical\ntask of Image Forgery Detection and Localization (IFDL). Moreover, existing\nIFDL methods are typically limited to the learning of low-level\nsemantic-agnostic clues and merely provide a single outcome judgment. To tackle\nthese issues, we propose ForgeryGPT, a novel framework that advances the IFDL\ntask by capturing high-order forensics knowledge correlations of forged images\nfrom diverse linguistic feature spaces, while enabling explainable generation\nand interactive dialogue through a newly customized Large Language Model (LLM)\narchitecture. Specifically, ForgeryGPT enhances traditional LLMs by integrating\nthe Mask-Aware Forgery Extractor, which enables the excavating of precise\nforgery mask information from input images and facilitating pixel-level\nunderstanding of tampering artifacts. The Mask-Aware Forgery Extractor consists\nof a Forgery Localization Expert (FL-Expert) and a Mask Encoder, where the\nFL-Expert is augmented with an Object-agnostic Forgery Prompt and a\nVocabulary-enhanced Vision Encoder, allowing for effectively capturing of\nmulti-scale fine-grained forgery details. To enhance its performance, we\nimplement a three-stage training strategy, supported by our designed Mask-Text\nAlignment and IFDL Task-Specific Instruction Tuning datasets, which align\nvision-language modalities and improve forgery detection and\ninstruction-following capabilities. Extensive experiments demonstrate the\neffectiveness of the proposed method.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "16 pages, 14 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.10238v2",
    "published_date": "2024-10-14 07:56:51 UTC",
    "updated_date": "2025-01-06 07:39:41 UTC"
  },
  {
    "arxiv_id": "2410.10229v1",
    "title": "BanglaQuAD: A Bengali Open-domain Question Answering Dataset",
    "authors": [
      "Md Rashad Al Hasan Rony",
      "Sudipto Kumar Shaha",
      "Rakib Al Hasan",
      "Sumon Kanti Dey",
      "Amzad Hossain Rafi",
      "Amzad Hossain Rafi",
      "Ashraf Hasan Sirajee",
      "Jens Lehmann"
    ],
    "abstract": "Bengali is the seventh most spoken language on earth, yet considered a\nlow-resource language in the field of natural language processing (NLP).\nQuestion answering over unstructured text is a challenging NLP task as it\nrequires understanding both question and passage. Very few researchers\nattempted to perform question answering over Bengali (natively pronounced as\nBangla) text. Typically, existing approaches construct the dataset by directly\ntranslating them from English to Bengali, which produces noisy and improper\nsentence structures. Furthermore, they lack topics and terminologies related to\nthe Bengali language and people. This paper introduces BanglaQuAD, a Bengali\nquestion answering dataset, containing 30,808 question-answer pairs constructed\nfrom Bengali Wikipedia articles by native speakers. Additionally, we propose an\nannotation tool that facilitates question-answering dataset construction on a\nlocal machine. A qualitative analysis demonstrates the quality of our proposed\ndataset.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted into LREC-COLING 2024, Turin, Italy",
    "pdf_url": "http://arxiv.org/pdf/2410.10229v1",
    "published_date": "2024-10-14 07:39:59 UTC",
    "updated_date": "2024-10-14 07:39:59 UTC"
  },
  {
    "arxiv_id": "2410.10228v1",
    "title": "QE-EBM: Using Quality Estimators as Energy Loss for Machine Translation",
    "authors": [
      "Gahyun Yoo",
      "Jay Yoon Lee"
    ],
    "abstract": "Reinforcement learning has shown great promise in aligning language models\nwith human preferences in a variety of text generation tasks, including machine\ntranslation. For translation tasks, rewards can easily be obtained from quality\nestimation (QE) models which can generate rewards for unlabeled data. Despite\nits usefulness, reinforcement learning cannot exploit the gradients with\nrespect to the QE score. We propose QE-EBM, a method of employing quality\nestimators as trainable loss networks that can directly backpropagate to the\nNMT model. We examine our method on several low and high resource target\nlanguages with English as the source language. QE-EBM outperforms strong\nbaselines such as REINFORCE and proximal policy optimization (PPO) as well as\nsupervised fine-tuning for all target languages, especially low-resource target\nlanguages. Most notably, for English-to-Mongolian translation, our method\nachieves improvements of 2.5 BLEU, 7.1 COMET-KIWI, 5.3 COMET, and 6.4 XCOMET\nrelative to the supervised baseline.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.10228v1",
    "published_date": "2024-10-14 07:39:33 UTC",
    "updated_date": "2024-10-14 07:39:33 UTC"
  },
  {
    "arxiv_id": "2410.10212v2",
    "title": "Large Language Model-Enhanced Reinforcement Learning for Generic Bus Holding Control Strategies",
    "authors": [
      "Jiajie Yu",
      "Yuhong Wang",
      "Wei Ma"
    ],
    "abstract": "Bus holding control is a widely-adopted strategy for maintaining stability\nand improving the operational efficiency of bus systems. Traditional\nmodel-based methods often face challenges with the low accuracy of bus state\nprediction and passenger demand estimation. In contrast, Reinforcement Learning\n(RL), as a data-driven approach, has demonstrated great potential in\nformulating bus holding strategies. RL determines the optimal control\nstrategies in order to maximize the cumulative reward, which reflects the\noverall control goals. However, translating sparse and delayed control goals in\nreal-world tasks into dense and real-time rewards for RL is challenging,\nnormally requiring extensive manual trial-and-error. In view of this, this\nstudy introduces an automatic reward generation paradigm by leveraging the\nin-context learning and reasoning capabilities of Large Language Models (LLMs).\nThis new paradigm, termed the LLM-enhanced RL, comprises several LLM-based\nmodules: reward initializer, reward modifier, performance analyzer, and reward\nrefiner. These modules cooperate to initialize and iteratively improve the\nreward function according to the feedback from training and test results for\nthe specified RL-based task. Ineffective reward functions generated by the LLM\nare filtered out to ensure the stable evolution of the RL agents' performance\nover iterations. To evaluate the feasibility of the proposed LLM-enhanced RL\nparadigm, it is applied to extensive bus holding control scenarios that vary in\nthe number of bus lines, stops, and passenger demand. The results demonstrate\nthe superiority, generalization capability, and robustness of the proposed\nparadigm compared to vanilla RL strategies, the LLM-based controller,\nphysics-based feedback controllers, and optimization-based controllers. This\nstudy sheds light on the great potential of utilizing LLMs in various smart\nmobility applications.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "51 pages, 19 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.10212v2",
    "published_date": "2024-10-14 07:10:16 UTC",
    "updated_date": "2025-04-13 14:17:56 UTC"
  },
  {
    "arxiv_id": "2410.19777v1",
    "title": "Deep Learning-driven Mobile Traffic Measurement Collection and Analysis",
    "authors": [
      "Yini Fang"
    ],
    "abstract": "Modelling dynamic traffic patterns and especially the continuously changing\ndependencies between different base stations, which previous studies overlook,\nis challenging. Traditional algorithms struggle to process large volumes of\ndata and to extract deep insights that help elucidate mobile traffic demands\nwith fine granularity, as well as how these demands will evolve in the future.\nTherefore, in this thesis we harness the powerful hierarchical feature learning\nabilities of Deep Learning (DL) techniques in both spatial and temporal domains\nand develop solutions for precise city-scale mobile traffic analysis and\nforecasting. Firstly, we design Spider, a mobile traffic measurement collection\nand reconstruction framework with a view to reducing the cost of measurement\ncollection and inferring traffic consumption with high accuracy, despite\nworking with sparse information. In particular, we train a reinforcement\nlearning agent to selectively sample subsets of target mobile coverage areas\nand tackle the large action space problem specific to this setting. We then\nintroduce a lightweight neural network model to reconstruct the traffic\nconsumption based on historical sparse measurements. Our proposed framework\noutperforms existing solutions on a real-world mobile traffic dataset.\nSecondly, we design SDGNet, a handover-aware graph neural network model for\nlong-term mobile traffic forecasting. We model the cellular network as a graph,\nand leverage handover frequency to capture the dependencies between base\nstations across time. Handover information reflects user mobility such as daily\ncommute, which helps in increasing the accuracy of the forecasts made. We\nproposed dynamic graph convolution to extract features from both traffic\nconsumption and handover data, showing that our model outperforms other\nbenchmark graph models on a mobile traffic dataset collected by a major network\noperator.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "MPhil thesis",
    "pdf_url": "http://arxiv.org/pdf/2410.19777v1",
    "published_date": "2024-10-14 06:53:45 UTC",
    "updated_date": "2024-10-14 06:53:45 UTC"
  },
  {
    "arxiv_id": "2410.10190v2",
    "title": "Predicting from Strings: Language Model Embeddings for Bayesian Optimization",
    "authors": [
      "Tung Nguyen",
      "Qiuyi Zhang",
      "Bangding Yang",
      "Chansoo Lee",
      "Jorg Bornschein",
      "Yingjie Miao",
      "Sagi Perel",
      "Yutian Chen",
      "Xingyou Song"
    ],
    "abstract": "Bayesian Optimization is ubiquitous in the field of experimental design and\nblackbox optimization for improving search efficiency, but has been\ntraditionally restricted to regression models which are only applicable to\nfixed search spaces and tabular input features. We propose Embed-then-Regress,\na paradigm for applying in-context regression over string inputs, through the\nuse of string embedding capabilities of pretrained language models. By\nexpressing all inputs as strings, we are able to perform general-purpose\nregression for Bayesian Optimization over various domains including synthetic,\ncombinatorial, and hyperparameter optimization, obtaining comparable results to\nstate-of-the-art Gaussian Process-based algorithms. Code can be found at\nhttps://github.com/google-research/optformer/tree/main/optformer/embed_then_regress.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.10190v2",
    "published_date": "2024-10-14 06:22:11 UTC",
    "updated_date": "2024-10-15 17:23:08 UTC"
  },
  {
    "arxiv_id": "2410.10184v1",
    "title": "Eliminating the Language Bias for Visual Question Answering with fine-grained Causal Intervention",
    "authors": [
      "Ying Liu",
      "Ge Bai",
      "Chenji Lu",
      "Shilong Li",
      "Zhang Zhang",
      "Ruifang Liu",
      "Wenbin Guo"
    ],
    "abstract": "Despite the remarkable advancements in Visual Question Answering (VQA), the\nchallenge of mitigating the language bias introduced by textual information\nremains unresolved. Previous approaches capture language bias from a\ncoarse-grained perspective. However, the finer-grained information within a\nsentence, such as context and keywords, can result in different biases. Due to\nthe ignorance of fine-grained information, most existing methods fail to\nsufficiently capture language bias. In this paper, we propose a novel causal\nintervention training scheme named CIBi to eliminate language bias from a\nfiner-grained perspective. Specifically, we divide the language bias into\ncontext bias and keyword bias. We employ causal intervention and contrastive\nlearning to eliminate context bias and improve the multi-modal representation.\nAdditionally, we design a new question-only branch based on counterfactual\ngeneration to distill and eliminate keyword bias. Experimental results\nillustrate that CIBi is applicable to various VQA models, yielding competitive\nperformance.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.10184v1",
    "published_date": "2024-10-14 06:09:16 UTC",
    "updated_date": "2024-10-14 06:09:16 UTC"
  },
  {
    "arxiv_id": "2410.10181v2",
    "title": "Scalable Multi-Domain Adaptation of Language Models using Modular Experts",
    "authors": [
      "Peter Schafhalter",
      "Shun Liao",
      "Yanqi Zhou",
      "Chih-Kuan Yeh",
      "Arun Kandoor",
      "James Laudon"
    ],
    "abstract": "Domain-specific adaptation is critical to maximizing the performance of\npre-trained language models (PLMs) on one or multiple targeted tasks,\nespecially under resource-constrained use cases, such as edge devices. However,\nexisting methods often struggle to balance domain-specific performance,\nretention of general knowledge, and efficiency for training and inference. To\naddress these challenges, we propose Modular Domain Experts (MoDE). MoDE is a\nmixture-of-experts architecture that augments a general PLMs with modular,\ndomain-specialized experts. These experts are trained independently and\ncomposed together via a lightweight training process. In contrast to standard\nlow-rank adaptation methods, each MoDE expert consists of several transformer\nlayers which scale better with more training examples and larger parameter\ncounts. Our evaluation demonstrates that MoDE achieves comparable target\nperformances to full parameter fine-tuning while achieving 1.65% better\nretention performance. Moreover, MoDE's architecture enables flexible sharding\nconfigurations and improves training speeds by up to 38% over state-of-the-art\ndistributed training configurations.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "14 pages, 5 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2410.10181v2",
    "published_date": "2024-10-14 06:02:56 UTC",
    "updated_date": "2024-10-24 05:04:57 UTC"
  },
  {
    "arxiv_id": "2410.13893v1",
    "title": "Can LLMs be Scammed? A Baseline Measurement Study",
    "authors": [
      "Udari Madhushani Sehwag",
      "Kelly Patel",
      "Francesca Mosca",
      "Vineeth Ravi",
      "Jessica Staddon"
    ],
    "abstract": "Despite the importance of developing generative AI models that can\neffectively resist scams, current literature lacks a structured framework for\nevaluating their vulnerability to such threats. In this work, we address this\ngap by constructing a benchmark based on the FINRA taxonomy and systematically\nassessing Large Language Models' (LLMs') vulnerability to a variety of scam\ntactics. First, we incorporate 37 well-defined base scam scenarios reflecting\nthe diverse scam categories identified by FINRA taxonomy, providing a focused\nevaluation of LLMs' scam detection capabilities. Second, we utilize\nrepresentative proprietary (GPT-3.5, GPT-4) and open-source (Llama) models to\nanalyze their performance in scam detection. Third, our research provides\ncritical insights into which scam tactics are most effective against LLMs and\nhow varying persona traits and persuasive techniques influence these\nvulnerabilities. We reveal distinct susceptibility patterns across different\nmodels and scenarios, underscoring the need for targeted enhancements in LLM\ndesign and deployment.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.13893v1",
    "published_date": "2024-10-14 05:22:27 UTC",
    "updated_date": "2024-10-14 05:22:27 UTC"
  },
  {
    "arxiv_id": "2410.10166v2",
    "title": "Automated Filtering of Human Feedback Data for Aligning Text-to-Image Diffusion Models",
    "authors": [
      "Yongjin Yang",
      "Sihyeon Kim",
      "Hojung Jung",
      "Sangmin Bae",
      "SangMook Kim",
      "Se-Young Yun",
      "Kimin Lee"
    ],
    "abstract": "Fine-tuning text-to-image diffusion models with human feedback is an\neffective method for aligning model behavior with human intentions. However,\nthis alignment process often suffers from slow convergence due to the large\nsize and noise present in human feedback datasets. In this work, we propose\nFiFA, a novel automated data filtering algorithm designed to enhance the\nfine-tuning of diffusion models using human feedback datasets with direct\npreference optimization (DPO). Specifically, our approach selects data by\nsolving an optimization problem to maximize three components: preference\nmargin, text quality, and text diversity. The concept of preference margin is\nused to identify samples that are highly informative in addressing the noisy\nnature of feedback dataset, which is calculated using a proxy reward model.\nAdditionally, we incorporate text quality, assessed by large language models to\nprevent harmful contents, and consider text diversity through a k-nearest\nneighbor entropy estimator to improve generalization. Finally, we integrate all\nthese components into an optimization process, with approximating the solution\nby assigning importance score to each data pair and selecting the most\nimportant ones. As a result, our method efficiently filters data automatically,\nwithout the need for manual intervention, and can be applied to any large-scale\ndataset. Experimental results show that FiFA significantly enhances training\nstability and achieves better performance, being preferred by humans 17% more,\nwhile using less than 0.5% of the full data and thus 1% of the GPU hours\ncompared to utilizing full human feedback datasets.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "ICLR 2025; Project Page available at :\n  https://sprain02.github.io/FiFA/",
    "pdf_url": "http://arxiv.org/pdf/2410.10166v2",
    "published_date": "2024-10-14 05:18:07 UTC",
    "updated_date": "2025-04-02 08:25:01 UTC"
  },
  {
    "arxiv_id": "2410.10165v2",
    "title": "HSR-Enhanced Sparse Attention Acceleration",
    "authors": [
      "Bo Chen",
      "Yingyu Liang",
      "Zhizhou Sha",
      "Zhenmei Shi",
      "Zhao Song"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities across\nvarious applications, but their performance on long-context tasks is often\nlimited by the computational complexity of attention mechanisms. We introduce a\nnovel approach to accelerate attention computation in LLMs, particularly for\nlong-context scenarios. We leverage the inherent sparsity within attention\nmechanisms, both in conventional Softmax attention and ReLU attention (with\n$\\mathsf{ReLU}^\\alpha$ activation, $\\alpha \\in \\mathbb{N}_+$), to significantly\nreduce the running time complexity. Our method employs a Half-Space Reporting\n(HSR) data structure to identify non-zero or ``massively activated'' entries in\nthe attention matrix. We present theoretical analyses for two key scenarios:\ngeneration decoding and prompt prefilling. Our approach achieves a running time\nof $O(mn^{4/5})$ significantly faster than the naive approach $O(mn)$ for\ngeneration decoding, where $n$ is the context length, $m$ is the query length,\nand $d$ is the hidden dimension. We can also reduce the running time for prompt\nprefilling from $O(mn)$ to $O(mn^{1 - 1 / \\lfloor d/2\\rfloor} + mn^{4/5})$. Our\nmethod introduces only provably negligible error for Softmax attention. This\nwork represents a significant step towards enabling efficient long-context\nprocessing in LLMs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "CPAL 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.10165v2",
    "published_date": "2024-10-14 05:18:02 UTC",
    "updated_date": "2025-02-24 08:42:25 UTC"
  },
  {
    "arxiv_id": "2410.10913v2",
    "title": "Audio Captioning RAG via Generative Pair-to-Pair Retrieval with Refined Knowledge Base",
    "authors": [
      "Choi Changin",
      "Lim Sungjun",
      "Rhee Wonjong"
    ],
    "abstract": "Recent advances in audio understanding tasks leverage the reasoning\ncapabilities of LLMs. However, adapting LLMs to learn audio concepts requires\nmassive training data and substantial computational resources. To address these\nchallenges, Retrieval-Augmented Generation (RAG) retrieves audio-text pairs\nfrom a knowledge base (KB) and augments them with query audio to generate\naccurate textual responses. In RAG, the relevance of the retrieved information\nplays a crucial role in effectively processing the input. In this paper, we\nanalyze how different retrieval methods and knowledge bases impact the\nrelevance of audio-text pairs and the performance of audio captioning with RAG.\nWe propose generative pair-to-pair retrieval, which uses the generated caption\nas a text query to accurately find relevant audio-text pairs to the query\naudio, thereby improving the relevance and accuracy of retrieved information.\nAdditionally, we refine the large-scale knowledge base to retain only\naudio-text pairs that align with the contextualized intents. Our approach\nachieves state-of-the-art results on benchmarks including AudioCaps, Clotho,\nand Auto-ACD, with detailed ablation studies validating the effectiveness of\nour retrieval and KB construction methods.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.10913v2",
    "published_date": "2024-10-14 04:57:32 UTC",
    "updated_date": "2024-12-19 00:34:45 UTC"
  },
  {
    "arxiv_id": "2410.10150v1",
    "title": "Jailbreak Instruction-Tuned LLMs via end-of-sentence MLP Re-weighting",
    "authors": [
      "Yifan Luo",
      "Zhennan Zhou",
      "Meitan Wang",
      "Bin Dong"
    ],
    "abstract": "In this paper, we investigate the safety mechanisms of instruction fine-tuned\nlarge language models (LLMs). We discover that re-weighting MLP neurons can\nsignificantly compromise a model's safety, especially for MLPs in\nend-of-sentence inferences. We hypothesize that LLMs evaluate the harmfulness\nof prompts during end-of-sentence inferences, and MLP layers plays a critical\nrole in this process. Based on this hypothesis, we develop 2 novel white-box\njailbreak methods: a prompt-specific method and a prompt-general method. The\nprompt-specific method targets individual prompts and optimizes the attack on\nthe fly, while the prompt-general method is pre-trained offline and can\ngeneralize to unseen harmful prompts. Our methods demonstrate robust\nperformance across 7 popular open-source LLMs, size ranging from 2B to 72B.\nFurthermore, our study provides insights into vulnerabilities of\ninstruction-tuned LLM's safety and deepens the understanding of the internal\nmechanisms of LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.10150v1",
    "published_date": "2024-10-14 04:32:22 UTC",
    "updated_date": "2024-10-14 04:32:22 UTC"
  },
  {
    "arxiv_id": "2410.10148v3",
    "title": "$α$-DPO: Adaptive Reward Margin is What Direct Preference Optimization Needs",
    "authors": [
      "Junkang Wu",
      "Xue Wang",
      "Zhengyi Yang",
      "Jiancan Wu",
      "Jinyang Gao",
      "Bolin Ding",
      "Xiang Wang",
      "Xiangnan He"
    ],
    "abstract": "Aligning large language models (LLMs) with human values and intentions is\ncrucial for their utility, honesty, and safety. Reinforcement learning from\nhuman feedback (RLHF) is a popular approach to achieve this alignment, but it\nfaces challenges in computational efficiency and training stability. Recent\nmethods like Direct Preference Optimization (DPO) and Simple Preference\nOptimization (SimPO) have proposed offline alternatives to RLHF, simplifying\nthe process by reparameterizing the reward function. However, DPO depends on a\npotentially suboptimal reference model, and SimPO's assumption of a fixed\ntarget reward margin may lead to suboptimal decisions in diverse data settings.\nIn this work, we propose $\\alpha$-DPO, an adaptive preference optimization\nalgorithm designed to address these limitations by introducing a dynamic reward\nmargin. Specifically, $\\alpha$-DPO employs an adaptive preference distribution,\nbalancing the policy model and the reference model to achieve personalized\nreward margins. We provide theoretical guarantees for $\\alpha$-DPO,\ndemonstrating its effectiveness as a surrogate optimization objective and its\nability to balance alignment and diversity through KL divergence control.\nEmpirical evaluations on AlpacaEval 2 and Arena-Hard show that $\\alpha$-DPO\nconsistently outperforms DPO and SimPO across various model settings,\nestablishing it as a robust approach for fine-tuning LLMs. Our method achieves\nsignificant improvements in win rates, highlighting its potential as a powerful\ntool for LLM alignment. The code is available at\nhttps://github.com/junkangwu/alpha-DPO",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.10148v3",
    "published_date": "2024-10-14 04:29:57 UTC",
    "updated_date": "2024-10-19 11:28:34 UTC"
  },
  {
    "arxiv_id": "2410.10144v1",
    "title": "Unified Representation of Genomic and Biomedical Concepts through Multi-Task, Multi-Source Contrastive Learning",
    "authors": [
      "Hongyi Yuan",
      "Suqi Liu",
      "Kelly Cho",
      "Katherine Liao",
      "Alexandre Pereira",
      "Tianxi Cai"
    ],
    "abstract": "We introduce GENomic Encoding REpresentation with Language Model (GENEREL), a\nframework designed to bridge genetic and biomedical knowledge bases. What sets\nGENEREL apart is its ability to fine-tune language models to infuse biological\nknowledge behind clinical concepts such as diseases and medications. This\nfine-tuning enables the model to capture complex biomedical relationships more\neffectively, enriching the understanding of how genomic data connects to\nclinical outcomes. By constructing a unified embedding space for biomedical\nconcepts and a wide range of common SNPs from sources such as patient-level\ndata, biomedical knowledge graphs, and GWAS summaries, GENEREL aligns the\nembeddings of SNPs and clinical concepts through multi-task contrastive\nlearning. This allows the model to adapt to diverse natural language\nrepresentations of biomedical concepts while bypassing the limitations of\ntraditional code mapping systems across different data sources. Our experiments\ndemonstrate GENEREL's ability to effectively capture the nuanced relationships\nbetween SNPs and clinical concepts. GENEREL also emerges to discern the degree\nof relatedness, potentially allowing for a more refined identification of\nconcepts. This pioneering approach in constructing a unified embedding system\nfor both SNPs and biomedical concepts enhances the potential for data\nintegration and discovery in biomedical research.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "stat.AP"
    ],
    "primary_category": "cs.LG",
    "comment": "15 pages, 2 figures, 5 tables",
    "pdf_url": "http://arxiv.org/pdf/2410.10144v1",
    "published_date": "2024-10-14 04:19:52 UTC",
    "updated_date": "2024-10-14 04:19:52 UTC"
  },
  {
    "arxiv_id": "2410.10136v1",
    "title": "Beyond-RAG: Question Identification and Answer Generation in Real-Time Conversations",
    "authors": [
      "Garima Agrawal",
      "Sashank Gummuluri",
      "Cosimo Spera"
    ],
    "abstract": "In customer contact centers, human agents often struggle with long average\nhandling times (AHT) due to the need to manually interpret queries and retrieve\nrelevant knowledge base (KB) articles. While retrieval augmented generation\n(RAG) systems using large language models (LLMs) have been widely adopted in\nindustry to assist with such tasks, RAG faces challenges in real-time\nconversations, such as inaccurate query formulation and redundant retrieval of\nfrequently asked questions (FAQs). To address these limitations, we propose a\ndecision support system that can look beyond RAG by first identifying customer\nquestions in real time. If the query matches an FAQ, the system retrieves the\nanswer directly from the FAQ database; otherwise, it generates answers via RAG.\nOur approach reduces reliance on manual queries, providing responses to agents\nwithin 2 seconds. Deployed in AI-powered human-agent assist solution at Minerva\nCQ, this system improves efficiency, reduces AHT, and lowers operational costs.\nWe also introduce an automated LLM-agentic workflow to identify FAQs from\nhistorical transcripts when no predefined FAQs exist.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.10136v1",
    "published_date": "2024-10-14 04:06:22 UTC",
    "updated_date": "2024-10-14 04:06:22 UTC"
  },
  {
    "arxiv_id": "2410.10135v1",
    "title": "FormalAlign: Automated Alignment Evaluation for Autoformalization",
    "authors": [
      "Jianqiao Lu",
      "Yingjia Wan",
      "Yinya Huang",
      "Jing Xiong",
      "Zhengying Liu",
      "Zhijiang Guo"
    ],
    "abstract": "Autoformalization aims to convert informal mathematical proofs into\nmachine-verifiable formats, bridging the gap between natural and formal\nlanguages. However, ensuring semantic alignment between the informal and\nformalized statements remains challenging. Existing approaches heavily rely on\nmanual verification, hindering scalability. To address this, we introduce\n\\textsc{FormalAlign}, the first automated framework designed for evaluating the\nalignment between natural and formal languages in autoformalization.\n\\textsc{FormalAlign} trains on both the autoformalization sequence generation\ntask and the representational alignment between input and output, employing a\ndual loss that combines a pair of mutually enhancing autoformalization and\nalignment tasks. Evaluated across four benchmarks augmented by our proposed\nmisalignment strategies, \\textsc{FormalAlign} demonstrates superior\nperformance. In our experiments, \\textsc{FormalAlign} outperforms GPT-4,\nachieving an Alignment-Selection Score 11.58\\% higher on \\forml-Basic (99.21\\%\nvs. 88.91\\%) and 3.19\\% higher on MiniF2F-Valid (66.39\\% vs. 64.34\\%). This\neffective alignment evaluation significantly reduces the need for manual\nverification. Both the dataset and code can be accessed\nvia~\\url{https://github.com/rookie-joe/FormalAlign}.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.FL",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "23 pages, 13 tables, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.10135v1",
    "published_date": "2024-10-14 03:58:35 UTC",
    "updated_date": "2024-10-14 03:58:35 UTC"
  },
  {
    "arxiv_id": "2410.10101v2",
    "title": "Learning Linear Attention in Polynomial Time",
    "authors": [
      "Morris Yau",
      "Ekin Akyürek",
      "Jiayuan Mao",
      "Joshua B. Tenenbaum",
      "Stefanie Jegelka",
      "Jacob Andreas"
    ],
    "abstract": "Previous research has explored the computational expressivity of Transformer\nmodels in simulating Boolean circuits or Turing machines. However, the\nlearnability of these simulators from observational data has remained an open\nquestion. Our study addresses this gap by providing the first polynomial-time\nlearnability results (specifically strong, agnostic PAC learning) for\nsingle-layer Transformers with linear attention. We show that linear attention\nmay be viewed as a linear predictor in a suitably defined RKHS. As a\nconsequence, the problem of learning any linear transformer may be converted\ninto the problem of learning an ordinary linear predictor in an expanded\nfeature space, and any such predictor may be converted back into a multiheaded\nlinear transformer. Moving to generalization, we show how to efficiently\nidentify training datasets for which every empirical risk minimizer is\nequivalent (up to trivial symmetries) to the linear Transformer that generated\nthe data, thereby guaranteeing the learned model will correctly generalize\nacross all inputs. Finally, we provide examples of computations expressible via\nlinear attention and therefore polynomial-time learnable, including associative\nmemories, finite automata, and a class of Universal Turing Machine (UTMs) with\npolynomially bounded computation histories. We empirically validate our\ntheoretical findings on three tasks: learning random linear attention networks,\nkey--value associations, and learning to execute finite automata. Our findings\nbridge a critical gap between theoretical expressivity and learnability of\nTransformers, and show that flexible and general models of computation are\nefficiently learnable.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.DS"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.10101v2",
    "published_date": "2024-10-14 02:41:01 UTC",
    "updated_date": "2024-10-18 17:15:09 UTC"
  },
  {
    "arxiv_id": "2410.10097v1",
    "title": "REHRSeg: Unleashing the Power of Self-Supervised Super-Resolution for Resource-Efficient 3D MRI Segmentation",
    "authors": [
      "Zhiyun Song",
      "Yinjie Zhao",
      "Xiaomin Li",
      "Manman Fei",
      "Xiangyu Zhao",
      "Mengjun Liu",
      "Cunjian Chen",
      "Chung-Hsing Yeh",
      "Qian Wang",
      "Guoyan Zheng",
      "Songtao Ai",
      "Lichi Zhang"
    ],
    "abstract": "High-resolution (HR) 3D magnetic resonance imaging (MRI) can provide detailed\nanatomical structural information, enabling precise segmentation of regions of\ninterest for various medical image analysis tasks. Due to the high demands of\nacquisition device, collection of HR images with their annotations is always\nimpractical in clinical scenarios. Consequently, segmentation results based on\nlow-resolution (LR) images with large slice thickness are often unsatisfactory\nfor subsequent tasks. In this paper, we propose a novel Resource-Efficient\nHigh-Resolution Segmentation framework (REHRSeg) to address the above-mentioned\nchallenges in real-world applications, which can achieve HR segmentation while\nonly employing the LR images as input. REHRSeg is designed to leverage\nself-supervised super-resolution (self-SR) to provide pseudo supervision,\ntherefore the relatively easier-to-acquire LR annotated images generated by 2D\nscanning protocols can be directly used for model training. The main\ncontribution to ensure the effectiveness in self-SR for enhancing segmentation\nis three-fold: (1) We mitigate the data scarcity problem in the medical field\nby using pseudo-data for training the segmentation model. (2) We design an\nuncertainty-aware super-resolution (UASR) head in self-SR to raise the\nawareness of segmentation uncertainty as commonly appeared on the ROI\nboundaries. (3) We align the spatial features for self-SR and segmentation\nthrough structural knowledge distillation to enable a better capture of region\ncorrelations. Experimental results demonstrate that REHRSeg achieves\nhigh-quality HR segmentation without intensive supervision, while also\nsignificantly improving the baseline performance for LR segmentation.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.10097v1",
    "published_date": "2024-10-14 02:28:18 UTC",
    "updated_date": "2024-10-14 02:28:18 UTC"
  },
  {
    "arxiv_id": "2410.10089v1",
    "title": "PromptGCN: Bridging Subgraph Gaps in Lightweight GCNs",
    "authors": [
      "Shengwei Ji",
      "Yujie Tian",
      "Fei Liu",
      "Xinlu Li",
      "Le Wu"
    ],
    "abstract": "Graph Convolutional Networks (GCNs) are widely used in graph-based\napplications, such as social networks and recommendation systems. Nevertheless,\nlarge-scale graphs or deep aggregation layers in full-batch GCNs consume\nsignificant GPU memory, causing out of memory (OOM) errors on mainstream GPUs\n(e.g., 29GB memory consumption on the Ogbnproducts graph with 5 layers). The\nsubgraph sampling methods reduce memory consumption to achieve lightweight GCNs\nby partitioning the graph into multiple subgraphs and sequentially training\nGCNs on each subgraph. However, these methods yield gaps among subgraphs, i.e.,\nGCNs can only be trained based on subgraphs instead of global graph\ninformation, which reduces the accuracy of GCNs. In this paper, we propose\nPromptGCN, a novel prompt-based lightweight GCN model to bridge the gaps among\nsubgraphs. First, the learnable prompt embeddings are designed to obtain global\ninformation. Then, the prompts are attached into each subgraph to transfer the\nglobal information among subgraphs. Extensive experimental results on seven\nlargescale graphs demonstrate that PromptGCN exhibits superior performance\ncompared to baselines. Notably, PromptGCN improves the accuracy of subgraph\nsampling methods by up to 5.48% on the Flickr dataset. Overall, PromptGCN can\nbe easily combined with any subgraph sampling method to obtain a lightweight\nGCN model with higher accuracy.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.10089v1",
    "published_date": "2024-10-14 02:07:02 UTC",
    "updated_date": "2024-10-14 02:07:02 UTC"
  },
  {
    "arxiv_id": "2410.10088v1",
    "title": "The Ingredients for Robotic Diffusion Transformers",
    "authors": [
      "Sudeep Dasari",
      "Oier Mees",
      "Sebastian Zhao",
      "Mohan Kumar Srirama",
      "Sergey Levine"
    ],
    "abstract": "In recent years roboticists have achieved remarkable progress in solving\nincreasingly general tasks on dexterous robotic hardware by leveraging high\ncapacity Transformer network architectures and generative diffusion models.\nUnfortunately, combining these two orthogonal improvements has proven\nsurprisingly difficult, since there is no clear and well-understood process for\nmaking important design choices. In this paper, we identify, study and improve\nkey architectural design decisions for high-capacity diffusion transformer\npolicies. The resulting models can efficiently solve diverse tasks on multiple\nrobot embodiments, without the excruciating pain of per-setup hyper-parameter\ntuning. By combining the results of our investigation with our improved model\ncomponents, we are able to present a novel architecture, named \\method, that\nsignificantly outperforms the state of the art in solving long-horizon ($1500+$\ntime-steps) dexterous tasks on a bi-manual ALOHA robot. In addition, we find\nthat our policies show improved scaling performance when trained on 10 hours of\nhighly multi-modal, language annotated ALOHA demonstration data. We hope this\nwork will open the door for future robot learning techniques that leverage the\nefficiency of generative diffusion modeling with the scalability of large scale\ntransformer architectures. Code, robot dataset, and videos are available at:\nhttps://dit-policy.github.io",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.10088v1",
    "published_date": "2024-10-14 02:02:54 UTC",
    "updated_date": "2024-10-14 02:02:54 UTC"
  },
  {
    "arxiv_id": "2410.12869v3",
    "title": "Language Model Preference Evaluation with Multiple Weak Evaluators",
    "authors": [
      "Zhengyu Hu",
      "Jieyu Zhang",
      "Zhihan Xiong",
      "Alexander Ratner",
      "Hui Xiong",
      "Ranjay Krishna"
    ],
    "abstract": "Despite the remarkable success of Large Language Models (LLMs), evaluating\ntheir outputs' quality regarding *preference* remains a critical challenge.\nExisting works usually leverage an LLM as the judge for comparing LLMs' output\npairwisely, yet such model-based evaluator is *weak evaluator* due to\n*conflicting preference*, i.e., output A is better than B, B than C, but C than\nA, causing contradictory evaluation results. To address this, we introduce GED\n(Preference Graph Ensemble and Denoise), a novel approach that leverages\nmultiple model-based evaluators to construct preference graphs, and then\nensemble and denoise these graphs for better, non-contradictory evaluation\nresults. In particular, our method consists of two primary stages: aggregating\nevaluations into a unified graph and applying a denoising process to eliminate\ncyclic inconsistencies, ensuring a directed acyclic graph (DAG) structure. We\nprovide theoretical guarantees for our framework, demonstrating its efficacy in\nrecovering the ground truth preference structure. Extensive experiments on ten\nbenchmarks demonstrate GED's superiority in three applications: model ranking,\nresponse selection, and model alignment tasks. Notably, GED combines small LLM\nevaluators (e.g., Llama3-8B, Mistral-7B, Qwen2-7B) to outperform stronger ones\n(e.g., Qwen2-72B), showcasing its effectiveness in enhancing evaluation\nreliability and improving model performance.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.12869v3",
    "published_date": "2024-10-14 01:57:25 UTC",
    "updated_date": "2025-02-01 19:08:49 UTC"
  },
  {
    "arxiv_id": "2410.10083v2",
    "title": "Beyond Graphs: Can Large Language Models Comprehend Hypergraphs?",
    "authors": [
      "Yifan Feng",
      "Chengwu Yang",
      "Xingliang Hou",
      "Shaoyi Du",
      "Shihui Ying",
      "Zongze Wu",
      "Yue Gao"
    ],
    "abstract": "Existing benchmarks like NLGraph and GraphQA evaluate LLMs on graphs by\nfocusing mainly on pairwise relationships, overlooking the high-order\ncorrelations found in real-world data. Hypergraphs, which can model complex\nbeyond-pairwise relationships, offer a more robust framework but are still\nunderexplored in the context of LLMs. To address this gap, we introduce\nLLM4Hypergraph, the first comprehensive benchmark comprising 21,500 problems\nacross eight low-order, five high-order, and two isomorphism tasks, utilizing\nboth synthetic and real-world hypergraphs from citation networks and protein\nstructures. We evaluate six prominent LLMs, including GPT-4o, demonstrating our\nbenchmark's effectiveness in identifying model strengths and weaknesses. Our\nspecialized prompting framework incorporates seven hypergraph languages and\nintroduces two novel techniques, Hyper-BAG and Hyper-COT, which enhance\nhigh-order reasoning and achieve an average 4% (up to 9%) performance\nimprovement on structure classification tasks. This work establishes a\nfoundational testbed for integrating hypergraph computational capabilities into\nLLMs, advancing their comprehension. The source codes are at\nhttps://github.com/iMoonLab/LLM4Hypergraph.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.10083v2",
    "published_date": "2024-10-14 01:55:02 UTC",
    "updated_date": "2024-10-16 07:33:06 UTC"
  },
  {
    "arxiv_id": "2410.19775v1",
    "title": "Gender Bias of LLM in Economics: An Existentialism Perspective",
    "authors": [
      "Hui Zhong",
      "Songsheng Chen",
      "Mian Liang"
    ],
    "abstract": "Large Language Models (LLMs), such as GPT-4 and BERT, have rapidly gained\ntraction in natural language processing (NLP) and are now integral to financial\ndecision-making. However, their deployment introduces critical challenges,\nparticularly in perpetuating gender biases that can distort decision-making\noutcomes in high-stakes economic environments. This paper investigates gender\nbias in LLMs through both mathematical proofs and empirical experiments using\nthe Word Embedding Association Test (WEAT), demonstrating that LLMs inherently\nreinforce gender stereotypes even without explicit gender markers. By comparing\nthe decision-making processes of humans and LLMs, we reveal fundamental\ndifferences: while humans can override biases through ethical reasoning and\nindividualized understanding, LLMs maintain bias as a rational outcome of their\nmathematical optimization on biased data. Our analysis proves that bias in LLMs\nis not an unintended flaw but a systematic result of their rational processing,\nwhich tends to preserve and amplify existing societal biases encoded in\ntraining data. Drawing on existentialist theory, we argue that LLM-generated\nbias reflects entrenched societal structures and highlights the limitations of\npurely technical debiasing methods. This research underscores the need for new\ntheoretical frameworks and interdisciplinary methodologies that address the\nethical implications of integrating LLMs into economic and financial\ndecision-making. We advocate for a reconceptualization of how LLMs influence\neconomic decisions, emphasizing the importance of incorporating human-like\nethical considerations into AI governance to ensure fairness and equity in\nAI-driven financial systems.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "Gender Bias, Large Language Models, Decision-Making",
    "pdf_url": "http://arxiv.org/pdf/2410.19775v1",
    "published_date": "2024-10-14 01:42:01 UTC",
    "updated_date": "2024-10-14 01:42:01 UTC"
  },
  {
    "arxiv_id": "2410.10076v3",
    "title": "VideoAgent: Self-Improving Video Generation",
    "authors": [
      "Achint Soni",
      "Sreyas Venkataraman",
      "Abhranil Chandra",
      "Sebastian Fischmeister",
      "Percy Liang",
      "Bo Dai",
      "Sherry Yang"
    ],
    "abstract": "Video generation has been used to generate visual plans for controlling\nrobotic systems. Given an image observation and a language instruction,\nprevious work has generated video plans which are then converted to robot\ncontrols to be executed. However, a major bottleneck in leveraging video\ngeneration for control lies in the quality of the generated videos, which often\nsuffer from hallucinatory content and unrealistic physics, resulting in low\ntask success when control actions are extracted from the generated videos.\nWhile scaling up dataset and model size provides a partial solution,\nintegrating external feedback is both natural and essential for grounding video\ngeneration in the real world. With this observation, we propose VideoAgent for\nself-improving generated video plans based on external feedback. Instead of\ndirectly executing the generated video plan, VideoAgent first refines the\ngenerated video plans using a novel procedure which we call self-conditioning\nconsistency, allowing inference-time compute to be turned into better generated\nvideo plans. As the refined video plan is being executed, VideoAgent can\ncollect additional data from the environment to further improve video plan\ngeneration. Experiments in simulated robotic manipulation from MetaWorld and\niTHOR show that VideoAgent drastically reduces hallucination, thereby boosting\nsuccess rate of downstream manipulation tasks. We further illustrate that\nVideoAgent can effectively refine real-robot videos, providing an early\nindicator that robots can be an effective tool in grounding video generation in\nthe physical world. Video demos and code can be found at\nhttps://video-as-agent.github.io.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.10076v3",
    "published_date": "2024-10-14 01:39:56 UTC",
    "updated_date": "2025-02-09 05:57:42 UTC"
  },
  {
    "arxiv_id": "2410.19774v2",
    "title": "Copula-Linked Parallel ICA: A Method for Coupling Structural and Functional MRI brain Networks",
    "authors": [
      "Oktay Agcaoglu",
      "Rogers F. Silva",
      "Deniz Alacam",
      "Sergey Plis",
      "Tulay Adali",
      "Vince Calhoun"
    ],
    "abstract": "Different brain imaging modalities offer unique insights into brain function\nand structure. Combining them enhances our understanding of neural mechanisms.\nPrior multimodal studies fusing functional MRI (fMRI) and structural MRI (sMRI)\nhave shown the benefits of this approach. Since sMRI lacks temporal data,\nexisting fusion methods often compress fMRI temporal information into summary\nmeasures, sacrificing rich temporal dynamics. Motivated by the observation that\ncovarying networks are identified in both sMRI and resting-state fMRI, we\ndeveloped a novel fusion method, by combining deep learning frameworks, copulas\nand independent component analysis (ICA), named copula linked parallel ICA\n(CLiP-ICA). This method estimates independent sources for each modality and\nlinks the spatial sources of fMRI and sMRI using a copula-based model for more\nflexible integration of temporal and spatial data. We tested CLiP-ICA using\ndata from the Alzheimer's Disease Neuroimaging Initiative (ADNI). Our results\nshowed that CLiP-ICA effectively captures both strongly and weakly linked sMRI\nand fMRI networks, including the cerebellum, sensorimotor, visual, cognitive\ncontrol, and default mode networks. It revealed more meaningful components and\nfewer artifacts, addressing the long-standing issue of optimal model order in\nICA. CLiP-ICA also detected complex functional connectivity patterns across\nstages of cognitive decline, with cognitively normal subjects generally showing\nhigher connectivity in sensorimotor and visual networks compared to patients\nwith Alzheimer, along with patterns suggesting potential compensatory\nmechanisms.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "math.PR",
      "stat.CO"
    ],
    "primary_category": "cs.CV",
    "comment": "25 pages, 10 figures, journal article",
    "pdf_url": "http://arxiv.org/pdf/2410.19774v2",
    "published_date": "2024-10-14 01:35:41 UTC",
    "updated_date": "2024-11-19 19:56:20 UTC"
  },
  {
    "arxiv_id": "2410.10074v1",
    "title": "Divide, Reweight, and Conquer: A Logit Arithmetic Approach for In-Context Learning",
    "authors": [
      "Chengsong Huang",
      "Langlin Huang",
      "Jiaxin Huang"
    ],
    "abstract": "In-Context Learning (ICL) emerges as a key feature for Large Language Models\n(LLMs), allowing them to adapt to new tasks by leveraging task-specific\nexamples without updating model parameters. However, ICL faces challenges with\nincreasing numbers of examples due to performance degradation and quadratic\ncomputational costs. In this paper, we propose Logit Arithmetic Reweighting\nApproach (LARA), a novel framework that enhances ICL by using logit-based\nensembling of multiple demonstrations. Our approach divides long input\ndemonstrations into parallelizable shorter inputs to significantly reduce\nmemory requirements, and then effectively aggregate the information by\nreweighting logits of each group via a non-gradient optimization approach. We\nfurther introduce Binary LARA (B-LARA), a variant that constrains weights to\nbinary values to simplify the search space and reduces memory usage by\nfiltering out less informative demonstration groups. Experiments on BBH and\nMMLU demonstrate that LARA and B-LARA outperform all baseline methods in both\naccuracy and memory efficiency. We also conduct extensive analysis to show that\nLARA generalizes well to scenarios of varying numbers of examples from limited\nto many-shot demonstrations.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.10074v1",
    "published_date": "2024-10-14 01:34:16 UTC",
    "updated_date": "2024-10-14 01:34:16 UTC"
  },
  {
    "arxiv_id": "2410.10063v1",
    "title": "Ukrainian-to-English folktale corpus: Parallel corpus creation and augmentation for machine translation in low-resource languages",
    "authors": [
      "Olena Burda-Lassen"
    ],
    "abstract": "Folktales are linguistically very rich and culturally significant in\nunderstanding the source language. Historically, only human translation has\nbeen used for translating folklore. Therefore, the number of translated texts\nis very sparse, which limits access to knowledge about cultural traditions and\ncustoms. We have created a new Ukrainian-To-English parallel corpus of familiar\nUkrainian folktales based on available English translations and suggested\nseveral new ones. We offer a combined domain-specific approach to building and\naugmenting this corpus, considering the nature of the domain and differences in\nthe purpose of human versus machine translation. Our corpus is word and\nsentence-aligned, allowing for the best curation of meaning, specifically\ntailored for use as training data for machine translation models.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.10063v1",
    "published_date": "2024-10-14 01:00:53 UTC",
    "updated_date": "2024-10-14 01:00:53 UTC"
  },
  {
    "arxiv_id": "2410.10062v1",
    "title": "Dreaming to Assist: Learning to Align with Human Objectives for Shared Control in High-Speed Racing",
    "authors": [
      "Jonathan DeCastro",
      "Andrew Silva",
      "Deepak Gopinath",
      "Emily Sumner",
      "Thomas M. Balch",
      "Laporsha Dees",
      "Guy Rosman"
    ],
    "abstract": "Tight coordination is required for effective human-robot teams in domains\ninvolving fast dynamics and tactical decisions, such as multi-car racing. In\nsuch settings, robot teammates must react to cues of a human teammate's\ntactical objective to assist in a way that is consistent with the objective\n(e.g., navigating left or right around an obstacle). To address this challenge,\nwe present Dream2Assist, a framework that combines a rich world model able to\ninfer human objectives and value functions, and an assistive agent that\nprovides appropriate expert assistance to a given human teammate. Our approach\nbuilds on a recurrent state space model to explicitly infer human intents,\nenabling the assistive agent to select actions that align with the human and\nenabling a fluid teaming interaction. We demonstrate our approach in a\nhigh-speed racing domain with a population of synthetic human drivers pursuing\nmutually exclusive objectives, such as \"stay-behind\" and \"overtake\". We show\nthat the combined human-robot team, when blending its actions with those of the\nhuman, outperforms the synthetic humans alone as well as several baseline\nassistance strategies, and that intent-conditioning enables adherence to human\npreferences during task execution, leading to improved performance while\nsatisfying the human's objective.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted to CoRL 2024, Munich, Germany",
    "pdf_url": "http://arxiv.org/pdf/2410.10062v1",
    "published_date": "2024-10-14 01:00:46 UTC",
    "updated_date": "2024-10-14 01:00:46 UTC"
  },
  {
    "arxiv_id": "2410.10056v1",
    "title": "The Epochal Sawtooth Effect: Unveiling Training Loss Oscillations in Adam and Other Optimizers",
    "authors": [
      "Qi Liu",
      "Wanjing Ma"
    ],
    "abstract": "In this paper, we identify and analyze a recurring training loss pattern,\nwhich we term the \\textit{Epochal Sawtooth Effect (ESE)}, commonly observed\nduring training with adaptive gradient-based optimizers, particularly Adam\noptimizer. This pattern is characterized by a sharp drop in loss at the\nbeginning of each epoch, followed by a gradual increase, resulting in a\nsawtooth-shaped loss curve. Through empirical observations, we demonstrate that\nwhile this effect is most pronounced with Adam, it persists, although less\nseverely, with other optimizers such as RMSProp.\n  We provide an in-depth explanation of the underlying mechanisms that lead to\nthe Epochal Sawtooth Effect. The influences of factors like \\(\\beta\\), batch\nsize, data shuffling on this pattern have been studied. We quantify the\ninfluence of \\(\\beta_2\\) on the shape of the loss curve, showing that higher\nvalues of \\(\\beta_2\\) result in a nearly linear increase in loss, while lower\nvalues create a concave upward trend. Our analysis reveals that this behavior\nstems from the adaptive learning rate controlled by the second moment estimate,\nwith \\(\\beta_1\\) playing a minimal role when \\(\\beta_2\\) is large.\n  To support our analysis, we replicate this phenomenon through a controlled\nquadratic minimization task. By incrementally solving a series of quadratic\noptimization problems using Adam, we demonstrate that the Epochal Sawtooth\nEffect can emerge even in simple optimization scenarios, reinforcing the\ngenerality of this pattern. This paper provides both theoretical insights and\nquantitative analysis, offering a comprehensive understanding of this\nubiquitous phenomenon in modern optimization techniques.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "15 pages, 21 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.10056v1",
    "published_date": "2024-10-14 00:51:21 UTC",
    "updated_date": "2024-10-14 00:51:21 UTC"
  },
  {
    "arxiv_id": "2410.10050v1",
    "title": "XAI-based Feature Selection for Improved Network Intrusion Detection Systems",
    "authors": [
      "Osvaldo Arreche",
      "Tanish Guntur",
      "Mustafa Abdallah"
    ],
    "abstract": "Explainability and evaluation of AI models are crucial parts of the security\nof modern intrusion detection systems (IDS) in the network security field, yet\nthey are lacking. Accordingly, feature selection is essential for such parts in\nIDS because it identifies the most paramount features, enhancing attack\ndetection and its description. In this work, we tackle the feature selection\nproblem for IDS by suggesting new ways of applying eXplainable AI (XAI) methods\nfor this problem. We identify the crucial attributes originated by distinct AI\nmethods in tandem with the novel five attribute selection methods. We then\ncompare many state-of-the-art feature selection strategies with our XAI-based\nfeature selection methods, showing that most AI models perform better when\nusing the XAI-based approach proposed in this work. By providing novel feature\nselection techniques and establishing the foundation for several XAI-based\nstrategies, this research aids security analysts in the AI decision-making\nreasoning of IDS by providing them with a better grasp of critical intrusion\ntraits. Furthermore, we make the source codes available so that the community\nmay develop additional models on top of our foundational XAI-based feature\nselection framework.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "24 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.10050v1",
    "published_date": "2024-10-14 00:24:59 UTC",
    "updated_date": "2024-10-14 00:24:59 UTC"
  }
]