{
  "date": "2024-10-14",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-10-14 的 arXiv 中文 TLDR 快报！今天 arXiv 的论文主要探讨 AI 模型的优化、安全、对齐和应用，包括 LLM 的无监督学习、强化学习和视觉生成模型的创新，亮点是 LLM 在数学推理和多模态任务中的进展，以及由知名学者如 Song Han 和 Philip Torr 参与的视觉生成研究。\n\n### 重点论文讨论\n今天共有 154 篇论文，我挑选了最具影响力和话题度的论文进行简要分析，先从 LLM 优化和安全相关的内容入手，再扩展到视觉生成和强化学习领域。其他论文如常规图像处理或一般性分类方法（如第 43 篇或第 101 篇），我将快速掠过，只列出标题和核心贡献。\n\n1. **LLM Unlearning via Loss Adjustment with Only Forget Data（LLM 遗忘机制通过仅使用遗忘数据调整损失）**  \n   这篇论文提出 FLAT 方法，通过最大化 f-散度在遗忘数据上调整损失，实现 LLM 的高效遗忘，同时保持模型整体性能。主要贡献是无需保留数据即可平衡遗忘和实用性，在 Harry Potter 数据集上表现出色。\n\n2. **Can Structured Data Reduce Epistemic Uncertainty?（结构化数据能否减少认知不确定性）**  \n   作者利用本体对齐框架提升深度学习模型在序列分类任务的性能，并扩展到 LLM 的检索增强生成，减少幻觉。主要发现是本体对齐提高了模型准确性和上下文相似度，增幅达 8.97%。\n\n3. **A Scalable Communication Protocol for Networks of Large Language Models（大规模 LLM 网络的可扩展通信协议）**  \n   这篇由 Philip Torr 等知名学者参与的论文引入 Agora 协议，使用标准化例程和自然语言处理 LLM 网络通信，解决代理通信难题。主要贡献是实现全分布式可扩展性，并在复杂任务中观察到自组织协议的涌现。\n\n4. **3D-Prover: Diversity Driven Theorem Proving With Determinantal Point Processes（3D-Prover: 使用行列式点过程驱动的多样性定理证明）**  \n   论文提出 3D-Prover 方法，通过行列式点过程筛选语义多样性策略，提升定理证明效率。主要发现是与 ReProver LLM 结合后，证明成功率和执行时间显著改善。\n\n5. **Personalised Feedback Framework for Online Education Programmes Using Generative AI（使用生成式 AI 的在线教育个性化反馈框架）**  \n   作者开发了一个 ChatGPT 扩展框架，通过嵌入式模型提供针对性反馈，实现 90% 的开放式问题准确率。主要贡献是提升教育反馈的精确性和可扩展性。\n\n6. **DMOSpeech: Direct Metric Optimization via Distilled Diffusion Model in Zero-Shot Speech Synthesis（DMOSpeech: 通过蒸馏扩散模型的零样本语音合成直接度量优化）**  \n   这篇论文提出 DMOSpeech 方法，使用蒸馏扩散模型优化语音合成指标，实现端到端优化和高质量生成。主要发现是显著提升语音的自然度和相似度，同时减少推理时间。\n\n7. **SecCodePLT: A Unified Platform for Evaluating the Security of Code GenAI（SecCodePLT: 用于评估代码生成 AI 安全的统一平台）**  \n   论文构建 SecCodePLT 平台，结合专家和自动生成评估代码 AI 的安全风险，包括不安全编码和攻击辅助。主要贡献是提供动态评估指标，提升了安全相关模型的检测能力。\n\n8. **EchoApex: A General-Purpose Vision Foundation Model for Echocardiography（EchoApex: 心超图像的一般性视觉基础模型）**  \n   作者提出 EchoApex，使用自监督学习训练的视觉基础模型，支持多种心超任务，如分割和分类。主要发现是模型在 28 个子任务上超越 SOTA，适用于临床应用。\n\n9. **Few-shot Novel View Synthesis using Depth Aware 3D Gaussian Splatting（使用深度感知 3D 高斯光栅的少样本新视角合成）**  \n   这篇论文引入深度感知高斯光栅方法，提升少样本新视角合成的质量。主要贡献是改进 PSNR 和 SSIM 指标，适用于 3D 重建任务。\n\n10. **FLARE: Faithful Logic-Aided Reasoning and Exploration（FLARE: 忠实逻辑辅助推理和探索）**  \n    论文提出 FLARE 框架，使用逻辑编程和多跳搜索提升 LLM 的推理保真度，在 7 个基准上达到 SOTA 性能。主要发现是模型在复杂推理任务中表现出色。\n\n11. **Differentiable Weightless Neural Networks（可微无权神经网络）**  \n    作者开发 DWN 方法，通过扩展有限差分技术训练基于查找表的神经网络，实现高效边缘计算。主要贡献是提升了准确性和硬件效率。\n\n12. **HART: Efficient Visual Generation with Hybrid Autoregressive Transformer（HART: 使用混合自回归 Transformer 的高效视觉生成）**  \n    这篇由 Song Han 参与的论文提出 HART 模型，结合自回归和扩散机制生成高质量图像，超越扩散模型。主要发现是提高生成效率和保真度。\n\n13. **TemporalBench: Benchmarking Fine-grained Temporal Understanding for Multimodal Video Models（TemporalBench: 多模态视频模型细粒度时间理解基准）**  \n    论文构建 TemporalBench 基准，评估视频模型的时间理解能力，包括事件顺序和动作频率。主要贡献是揭示模型在时间推理上的不足，提升基准测试标准。\n\n14. **Agent-as-a-Judge: Evaluate Agents with Agents（Agent-as-a-Judge: 使用代理评估代理）**  \n    作者提出 Agent-as-a-Judge 框架，使用代理评估其他代理的性能，应用于代码生成任务。主要发现是提升评估准确性和效率。\n\n15. **FormalAlign: Automated Alignment Evaluation for Autoformalization（FormalAlign: 自动形式化对齐评估）**  \n    论文引入 FormalAlign 框架，使用双任务损失评估自然语言与形式语言的对齐。主要贡献是减少手动验证需求，提升数学任务的准确性。\n\n其他论文如 **Audio-based Kinship Verification Using Age Domain Conversion（基于年龄域转换的音频亲缘验证）** 和 **MoonMetaSync: Lunar Image Registration Analysis（月球图像注册分析）** 等，聚焦音频和图像处理，主要贡献是改进特征检测和注册方法，但影响力较小，我仅快速提及。\n\n今天的论文整体上突出了 AI 模型的实用性和鲁棒性改进，相关领域的研究者可关注 LLM 安全和视觉生成方向。更多细节请查阅 arXiv！",
  "papers": [
    {
      "arxiv_id": "2410.11143v1",
      "title": "LLM Unlearning via Loss Adjustment with Only Forget Data",
      "title_zh": "翻译失败",
      "authors": [
        "Yaxuan Wang",
        "Jiaheng Wei",
        "Chris Yuhao Liu",
        "Jinlong Pang",
        "Quan Liu",
        "Ankit Parag Shah",
        "Yujia Bao",
        "Yang Liu",
        "Wei Wei"
      ],
      "abstract": "Unlearning in Large Language Models (LLMs) is essential for ensuring ethical\nand responsible AI use, especially in addressing privacy leak, bias, safety,\nand evolving regulations. Existing approaches to LLM unlearning often rely on\nretain data or a reference LLM, yet they struggle to adequately balance\nunlearning performance with overall model utility. This challenge arises\nbecause leveraging explicit retain data or implicit knowledge of retain data\nfrom a reference LLM to fine-tune the model tends to blur the boundaries\nbetween the forgotten and retain data, as different queries often elicit\nsimilar responses. In this work, we propose eliminating the need to retain data\nor the reference LLM for response calibration in LLM unlearning. Recognizing\nthat directly applying gradient ascent on the forget data often leads to\noptimization instability and poor performance, our method guides the LLM on\nwhat not to respond to, and importantly, how to respond, based on the forget\ndata. Hence, we introduce Forget data only Loss AjustmenT (FLAT), a \"flat\" loss\nadjustment approach which addresses these issues by maximizing f-divergence\nbetween the available template answer and the forget answer only w.r.t. the\nforget data. The variational form of the defined f-divergence theoretically\nprovides a way of loss adjustment by assigning different importance weights for\nthe learning w.r.t. template responses and the forgetting of responses subject\nto unlearning. Empirical results demonstrate that our approach not only\nachieves superior unlearning performance compared to existing methods but also\nminimizes the impact on the model's retained capabilities, ensuring high\nutility across diverse tasks, including copyrighted content unlearning on Harry\nPotter dataset and MUSE Benchmark, and entity unlearning on the TOFU dataset.",
      "tldr_zh": "该论文提出了一种名为 FLAT（Forget data only Loss Adjustment）的 LLM unlearning 方法，仅使用 forget data 即可实现模型遗忘，而无需 retain data 或参考 LLM，从而更好地平衡遗忘性能和模型整体效用。FLAT 通过最大化 f-divergence 来调整损失函数，为模板响应和遗忘响应分配不同的权重，避免了直接梯度上升的优化不稳定性。实验结果显示，该方法在 Harry Potter 数据集、MUSE Benchmark 和 TOFU 数据集等任务上，显著提高了 unlearning 性能，同时最小化了对模型保留能力的负面影响。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Paper under review",
      "pdf_url": "http://arxiv.org/pdf/2410.11143v1",
      "published_date": "2024-10-14 23:43:33 UTC",
      "updated_date": "2024-10-14 23:43:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:05:24.601666"
    },
    {
      "arxiv_id": "2410.11141v1",
      "title": "Can Structured Data Reduce Epistemic Uncertainty?",
      "title_zh": "结构化数据能减少认识论不确定性吗？",
      "authors": [
        "Shriram M S",
        "Sushmitha S",
        "Gayathri K S",
        "Shahina A"
      ],
      "abstract": "In this work, we present a framework that utilizes ontology alignment to\nimprove the learning process of deep learning models. With this approach we\nshow that models fine-tuned using ontologies learn a downstream task at a\nhigher rate with better performance on a sequential classification task\ncompared to the native version of the model. Additionally, we extend our work\nto showcase how subsumption mappings retrieved during the process of ontology\nalignment can help enhance Retrieval-Augmented Generation in Large Language\nModels. The results show that the responses obtained by using subsumption\nmappings show an increase of 8.97% in contextual similarity and a 1% increase\nin factual accuracy. We also use these scores to define our Hallucination Index\nand show that this approach reduces hallucination in LLMs by 4.847%.",
      "tldr_zh": "本研究提出一个框架，利用本体对齐（ontology alignment）来提升深度学习模型的学习过程，结果显示微调后的模型在下游顺序分类任务上学习速度更快且性能更优。进一步扩展，该框架通过提取的包含关系映射（subsumption mappings）增强大型语言模型（Large Language Models）的检索增强生成（Retrieval-Augmented Generation），导致响应上下文相似性提高8.97%、事实准确性提高1%。此外，该方法通过定义幻觉指数（Hallucination Index）证明了其能减少LLM中的幻觉4.847%，从而降低了认识不确定性（epistemic uncertainty）。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Presented at NeLaMKRR@KR, 2024 (arXiv:2410.05339)",
      "pdf_url": "http://arxiv.org/pdf/2410.11141v1",
      "published_date": "2024-10-14 23:38:51 UTC",
      "updated_date": "2024-10-14 23:38:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:05:36.670949"
    },
    {
      "arxiv_id": "2410.11905v1",
      "title": "A Scalable Communication Protocol for Networks of Large Language Models",
      "title_zh": "一种适用于大型语言模型网络的可扩展通信协议",
      "authors": [
        "Samuele Marro",
        "Emanuele La Malfa",
        "Jesse Wright",
        "Guohao Li",
        "Nigel Shadbolt",
        "Michael Wooldridge",
        "Philip Torr"
      ],
      "abstract": "Communication is a prerequisite for collaboration. When scaling networks of\nAI-powered agents, communication must be versatile, efficient, and portable.\nThese requisites, which we refer to as the Agent Communication Trilemma, are\nhard to achieve in large networks of agents. We introduce Agora, a meta\nprotocol that leverages existing communication standards to make LLM-powered\nagents solve complex problems efficiently. In Agora, agents typically use\nstandardised routines for frequent communications, natural language for rare\ncommunications, and LLM-written routines for everything in between. Agora\nsidesteps the Agent Communication Trilemma and robustly handles changes in\ninterfaces and members, allowing unprecedented scalability with full\ndecentralisation and minimal involvement of human beings. On large Agora\nnetworks, we observe the emergence of self-organising, fully automated\nprotocols that achieve complex goals without human intervention.",
      "tldr_zh": "该论文针对大规模大型语言模型(LLM)网络中的代理通信问题，提出了 Agent Communication Trilemma 的概念，即通信需兼顾多功能(efficient)、高效(versatile)和便携(portable)的挑战。作者引入 Agora 元协议(meta protocol)，它利用现有通信标准、标准化例程和 LLM 编写的自定义例程，让代理在频繁、稀有或中间通信中高效协作，从而规避三难困境。实验结果显示，Agora 支持高度可扩展性、全 decentralization 和最小人类干预，并在大型网络中实现了自组织协议，能够自动达成复杂目标。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "I.2.11; I.2.7"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.11905v1",
      "published_date": "2024-10-14 23:25:13 UTC",
      "updated_date": "2024-10-14 23:25:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:06:42.937803"
    },
    {
      "arxiv_id": "2410.11133v1",
      "title": "3D-Prover: Diversity Driven Theorem Proving With Determinantal Point Processes",
      "title_zh": "翻译失败",
      "authors": [
        "Sean Lamont",
        "Christian Walder",
        "Amir Dezfouli",
        "Paul Montague",
        "Michael Norrish"
      ],
      "abstract": "A key challenge in automated formal reasoning is the intractable search\nspace, which grows exponentially with the depth of the proof. This branching is\ncaused by the large number of candidate proof tactics which can be applied to a\ngiven goal. Nonetheless, many of these tactics are semantically similar or lead\nto an execution error, wasting valuable resources in both cases. We address the\nproblem of effectively pruning this search, using only synthetic data generated\nfrom previous proof attempts. We first demonstrate that it is possible to\ngenerate semantically aware tactic representations which capture the effect on\nthe proving environment, likelihood of success and execution time. We then\npropose a novel filtering mechanism which leverages these representations to\nselect semantically diverse and high quality tactics, using Determinantal Point\nProcesses. Our approach, 3D-Prover, is designed to be general, and to augment\nany underlying tactic generator. We demonstrate the effectiveness of 3D-Prover\non the miniF2F-valid and miniF2F-test benchmarks by augmenting the ReProver\nLLM. We show that our approach leads to an increase in the overall proof rate,\nas well as a significant improvement in the tactic success rate, execution time\nand diversity.",
      "tldr_zh": "该研究针对自动形式推理中指数级搜索空间的挑战，提出了一种名为3D-Prover的框架，利用合成数据生成语义感知的证明策略（tactics）表示，包括对证明环境的影响、成功概率和执行时间。3D-Prover引入Determinantal Point Processes作为过滤机制，选择语义多样且高质量的策略，从而有效修剪冗余或错误策略。该框架可通用增强任何底层策略生成器，如ReProver LLM，并在miniF2F-valid和miniF2F-test基准测试中，提高了整体证明率，并显著提升了策略成功率、执行时间和多样性。",
      "categories": [
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.11133v1",
      "published_date": "2024-10-14 23:13:53 UTC",
      "updated_date": "2024-10-14 23:13:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:06:00.488023"
    },
    {
      "arxiv_id": "2410.11904v1",
      "title": "Personalised Feedback Framework for Online Education Programmes Using Generative AI",
      "title_zh": "翻译失败",
      "authors": [
        "Ievgeniia Kuzminykh",
        "Tareita Nawaz",
        "Shihao Shenzhang",
        "Bogdan Ghita",
        "Jeffery Raphael",
        "Hannan Xiao"
      ],
      "abstract": "AI tools, particularly large language modules, have recently proven their\neffectiveness within learning management systems and online education\nprogrammes. As feedback continues to play a crucial role in learning and\nassessment in schools, educators must carefully customise the use of AI tools\nin order to optimally support students in their learning journey. Efforts to\nimprove educational feedback systems have seen numerous attempts reflected in\nthe research studies but mostly have been focusing on qualitatively\nbenchmarking AI feedback against human-generated feedback. This paper presents\nan exploration of an alternative feedback framework which extends the\ncapabilities of ChatGPT by integrating embeddings, enabling a more nuanced\nunderstanding of educational materials and facilitating topic-targeted feedback\nfor quiz-based assessments. As part of the study, we proposed and developed a\nproof of concept solution, achieving an efficacy rate of 90% and 100% for\nopen-ended and multiple-choice questions, respectively. The results showed that\nour framework not only surpasses expectations but also rivals human narratives,\nhighlighting the potential of AI in revolutionising educational feedback\nmechanisms.",
      "tldr_zh": "本文提出了一种使用 Generative AI 的个性化反馈框架，针对在线教育程序中反馈的关键作用，通过扩展 ChatGPT 并整合 embeddings，实现对教育材料的更细致理解和针对主题的测验反馈。该框架的证明概念解决方案在开放式问题上达到90%的功效率，在多项选择题上达到100%，表现出色且可与人类反馈相媲美。研究结果突显了 AI 在革命化教育反馈机制方面的潜力。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.HC",
      "comment": "Submitted to journal",
      "pdf_url": "http://arxiv.org/pdf/2410.11904v1",
      "published_date": "2024-10-14 22:35:40 UTC",
      "updated_date": "2024-10-14 22:35:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:06:13.162023"
    },
    {
      "arxiv_id": "2410.11120v1",
      "title": "Audio-based Kinship Verification Using Age Domain Conversion",
      "title_zh": "翻译失败",
      "authors": [
        "Qiyang Sun",
        "Alican Akman",
        "Xin Jing",
        "Manuel Milling",
        "Björn W. Schuller"
      ],
      "abstract": "Audio-based kinship verification (AKV) is important in many domains, such as\nhome security monitoring, forensic identification, and social network analysis.\nA key challenge in the task arises from differences in age across samples from\ndifferent individuals, which can be interpreted as a domain bias in a\ncross-domain verification task. To address this issue, we design the notion of\nan \"age-standardised domain\" wherein we utilise the optimised CycleGAN-VC3\nnetwork to perform age-audio conversion to generate the in-domain audio. The\ngenerated audio dataset is employed to extract a range of features, which are\nthen fed into a metric learning architecture to verify kinship. Experiments are\nconducted on the KAN_AV audio dataset, which contains age and kinship labels.\nThe results demonstrate that the method markedly enhances the accuracy of\nkinship verification, while also offering novel insights for future kinship\nverification research.",
      "tldr_zh": "本研究针对音频-based kinship verification (AKV) 的挑战，特别是年龄差异导致的领域偏差问题，提出了一种基于年龄域转换的方法。研究者引入“age-standardised domain”概念，利用 optimised CycleGAN-VC3 网络进行年龄音频转换，生成标准化音频数据集，并从中提取特征输入到 metric learning 架构中以验证亲缘关系。在 KAN_AV 数据集上的实验显示，该方法显著提高了亲缘关系验证的准确性，并为未来 AKV 研究提供了新颖见解。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS",
        "68T10",
        "I.5.4; I.2.6"
      ],
      "primary_category": "cs.SD",
      "comment": "4 pages, 2 figures, submitted to IEEE Signal Processing Letters",
      "pdf_url": "http://arxiv.org/pdf/2410.11120v1",
      "published_date": "2024-10-14 22:08:57 UTC",
      "updated_date": "2024-10-14 22:08:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:06:24.171942"
    },
    {
      "arxiv_id": "2410.11118v1",
      "title": "MoonMetaSync: Lunar Image Registration Analysis",
      "title_zh": "MoonMetaSync：月球图像配准分析",
      "authors": [
        "Ashutosh Kumar",
        "Sarthak Kaushal",
        "Shiv Vignesh Murthy"
      ],
      "abstract": "This paper compares scale-invariant (SIFT) and scale-variant (ORB) feature\ndetection methods, alongside our novel feature detector, IntFeat, specifically\napplied to lunar imagery. We evaluate these methods using low (128x128) and\nhigh-resolution (1024x1024) lunar image patches, providing insights into their\nperformance across scales in challenging extraterrestrial environments. IntFeat\ncombines high-level features from SIFT and low-level features from ORB into a\nsingle vector space for robust lunar image registration. We introduce\nSyncVision, a Python package that compares lunar images using various\nregistration methods, including SIFT, ORB, and IntFeat. Our analysis includes\nupscaling low-resolution lunar images using bi-linear and bi-cubic\ninterpolation, offering a unique perspective on registration effectiveness\nacross scales and feature detectors in lunar landscapes. This research\ncontributes to computer vision and planetary science by comparing feature\ndetection methods for lunar imagery and introducing a versatile tool for lunar\nimage registration and evaluation, with implications for multi-resolution image\nanalysis in space exploration applications.",
      "tldr_zh": "本文比较了尺度不变特征检测方法SIFT和尺度相关方法ORB，以及新提出的IntFeat检测器，应用于月球图像配准。IntFeat通过将SIFT的高级特征与ORB的低级特征整合到一个向量空间中，提升了在低分辨率（128x128）和高分辨率（1024x1024）图像上的鲁棒性。研究引入了SyncVision Python包，用于评估这些方法，包括使用双线性插值和双立方插值放大图像，并分析了其在挑战性外太空环境中的性能表现。该工作为计算机视觉和行星科学领域提供了新的工具和见解，支持多分辨率图像分析在空间探索中的应用。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "math.AG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.11118v1",
      "published_date": "2024-10-14 22:05:48 UTC",
      "updated_date": "2024-10-14 22:05:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:06:37.686775"
    },
    {
      "arxiv_id": "2410.11112v5",
      "title": "Differentiable Weightless Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Alan T. L. Bacellar",
        "Zachary Susskind",
        "Mauricio Breternitz Jr.",
        "Eugene John",
        "Lizy K. John",
        "Priscila M. V. Lima",
        "Felipe M. G. França"
      ],
      "abstract": "We introduce the Differentiable Weightless Neural Network (DWN), a model\nbased on interconnected lookup tables. Training of DWNs is enabled by a novel\nExtended Finite Difference technique for approximate differentiation of binary\nvalues. We propose Learnable Mapping, Learnable Reduction, and Spectral\nRegularization to further improve the accuracy and efficiency of these models.\nWe evaluate DWNs in three edge computing contexts: (1) an FPGA-based hardware\naccelerator, where they demonstrate superior latency, throughput, energy\nefficiency, and model area compared to state-of-the-art solutions, (2) a\nlow-power microcontroller, where they achieve preferable accuracy to XGBoost\nwhile subject to stringent memory constraints, and (3) ultra-low-cost chips,\nwhere they consistently outperform small models in both accuracy and projected\nhardware area. DWNs also compare favorably against leading approaches for\ntabular datasets, with higher average rank. Overall, our work positions DWNs as\na pioneering solution for edge-compatible high-throughput neural networks.",
      "tldr_zh": "我们引入了 Differentiable Weightless Neural Networks (DWN)，一种基于互联查找表的模型，通过新型 Extended Finite Difference 技术实现二进制值的近似微分训练，并辅以 Learnable Mapping、Learnable Reduction 和 Spectral Regularization 来提升准确性和效率。实验评估显示，DWN 在FPGA硬件加速器上表现出优越的延迟、吞吐量、能效和模型面积；在低功耗微控制器上，比 XGBoost 具有更好的准确性并满足内存约束；在超低成本芯片上，DWN 在准确性和硬件面积上均优于小模型。总体而言，DWN 在表格数据集上排名领先，并作为边缘兼容高吞吐量神经网络的开创性解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.11112v5",
      "published_date": "2024-10-14 21:43:48 UTC",
      "updated_date": "2025-03-02 17:48:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:06:55.418991"
    },
    {
      "arxiv_id": "2410.14721v2",
      "title": "The Representation of Meaningful Precision, and Accuracy",
      "title_zh": "翻译失败",
      "authors": [
        "A Mani"
      ],
      "abstract": "The concepts of precision, and accuracy are domain and problem dependent. The\nsimplified numeric hard and soft measures used in the fields of statistical\nlearning, many types of machine learning, and binary or multiclass\nclassification problems are known to be of limited use for understanding the\nmeaningfulness of models or their relevance. Arguably, they are neither of\npatterns nor proofs. Further, there are no good measures or representations for\nanalogous concepts in the cognition domain. In this research, the key issues\nare reflected upon, and a compositional knowledge representation approach in a\nminimalist general rough framework is proposed for the problem contexts. The\nlatter is general enough to cover most application contexts, and may be\napplicable in the light of improved computational tools available.",
      "tldr_zh": "这篇论文探讨了精确度（precision）和准确度（accuracy）的概念，这些概念依赖于特定领域和问题，而统计学习、机器学习以及二元或多类分类问题中常用的简化数值指标（如硬指标和软指标）无法充分反映模型的意义或相关性。论文批评这些指标缺乏对模式和证明的实际洞察，并在认知领域指出类似概念的衡量方法缺失。为解决这些问题，研究提出了一种在最小主义通用粗糙框架（minimalist general rough framework）中组合知识表示的方法，该框架足够通用，能够覆盖大多数应用场景，并可能受益于改进的计算工具。总的来说，此方法旨在提供更具意义的精确度和准确度表示，提升模型的理解和适用性。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.LO",
        "68T30, 68T37, 03G25"
      ],
      "primary_category": "cs.AI",
      "comment": "16 Pages",
      "pdf_url": "http://arxiv.org/pdf/2410.14721v2",
      "published_date": "2024-10-14 21:33:38 UTC",
      "updated_date": "2024-10-25 08:58:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:07:06.674746"
    },
    {
      "arxiv_id": "2410.11097v2",
      "title": "DMOSpeech: Direct Metric Optimization via Distilled Diffusion Model in Zero-Shot Speech Synthesis",
      "title_zh": "翻译失败",
      "authors": [
        "Yingahao Aaron Li",
        "Rithesh Kumar",
        "Zeyu Jin"
      ],
      "abstract": "Diffusion models have demonstrated significant potential in speech synthesis\ntasks, including text-to-speech (TTS) and voice cloning. However, their\niterative denoising processes are computationally intensive, and previous\ndistillation attempts have shown consistent quality degradation. Moreover,\nexisting TTS approaches are limited by non-differentiable components or\niterative sampling that prevent true end-to-end optimization with perceptual\nmetrics. We introduce DMOSpeech, a distilled diffusion-based TTS model that\nuniquely achieves both faster inference and superior performance compared to\nits teacher model. By enabling direct gradient pathways to all model\ncomponents, we demonstrate the first successful end-to-end optimization of\ndifferentiable metrics in TTS, incorporating Connectionist Temporal\nClassification (CTC) loss and Speaker Verification (SV) loss. Our comprehensive\nexperiments, validated through extensive human evaluation, show significant\nimprovements in naturalness, intelligibility, and speaker similarity while\nreducing inference time by orders of magnitude. This work establishes a new\nframework for aligning speech synthesis with human auditory preferences through\ndirect metric optimization. The audio samples are available at\nhttps://dmospeech.github.io/.",
      "tldr_zh": "本研究提出DMOSpeech，一种基于蒸馏扩散模型的TTS系统，通过直接指标优化（Direct Metric Optimization）实现零样本语音合成中的更快推理和优于教师模型的性能。\n该模型首次启用端到端优化，结合Connectionist Temporal Classification (CTC) loss和Speaker Verification (SV) loss，使所有组件可微分，从而直接优化感知指标。\n实验通过广泛的人类评估证明，DMOSpeech显著提升了语音的自然性、可懂性和说话者相似性，同时将推理时间减少几个数量级。\n这项工作建立了新框架，通过直接指标优化将语音合成更好地与人类听觉偏好对齐。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.11097v2",
      "published_date": "2024-10-14 21:17:58 UTC",
      "updated_date": "2025-02-20 02:07:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:07:18.910863"
    },
    {
      "arxiv_id": "2410.11096v1",
      "title": "SecCodePLT: A Unified Platform for Evaluating the Security of Code GenAI",
      "title_zh": "翻译失败",
      "authors": [
        "Yu Yang",
        "Yuzhou Nie",
        "Zhun Wang",
        "Yuheng Tang",
        "Wenbo Guo",
        "Bo Li",
        "Dawn Song"
      ],
      "abstract": "Existing works have established multiple benchmarks to highlight the security\nrisks associated with Code GenAI. These risks are primarily reflected in two\nareas: a model potential to generate insecure code (insecure coding) and its\nutility in cyberattacks (cyberattack helpfulness). While these benchmarks have\nmade significant strides, there remain opportunities for further improvement.\nFor instance, many current benchmarks tend to focus more on a model ability to\nprovide attack suggestions rather than its capacity to generate executable\nattacks. Additionally, most benchmarks rely heavily on static evaluation\nmetrics, which may not be as precise as dynamic metrics such as passing test\ncases. Conversely, expert-verified benchmarks, while offering high-quality\ndata, often operate at a smaller scale. To address these gaps, we develop\nSecCodePLT, a unified and comprehensive evaluation platform for code GenAIs'\nrisks. For insecure code, we introduce a new methodology for data creation that\ncombines experts with automatic generation. Our methodology ensures the data\nquality while enabling large-scale generation. We also associate samples with\ntest cases to conduct code-related dynamic evaluation. For cyberattack\nhelpfulness, we set up a real environment and construct samples to prompt a\nmodel to generate actual attacks, along with dynamic metrics in our\nenvironment. We conduct extensive experiments and show that SecCodePLT\noutperforms the state-of-the-art (SOTA) benchmark CyberSecEval in security\nrelevance. Furthermore, it better identifies the security risks of SOTA models\nin insecure coding and cyberattack helpfulness. Finally, we apply SecCodePLT to\nthe SOTA code agent, Cursor, and, for the first time, identify non-trivial\nsecurity risks in this advanced coding agent.",
      "tldr_zh": "本文提出 SecCodePLT，一个统一的平台，用于全面评估 Code GenAI 的安全风险，包括生成不安全代码和网络攻击帮助性。该平台通过结合专家验证与自动数据生成方法，确保大规模高质量数据集，并引入动态评估指标如测试用例和真实环境模拟，以弥补现有基准的局限性。实验结果表明，SecCodePLT 优于 SOTA 基准 CyberSecEval，在安全相关性上表现更佳，并首次在 SOTA 代码代理 Cursor 中识别出非微不足道的安全风险。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.11096v1",
      "published_date": "2024-10-14 21:17:22 UTC",
      "updated_date": "2024-10-14 21:17:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:07:30.614993"
    },
    {
      "arxiv_id": "2410.11092v3",
      "title": "EchoApex: A General-Purpose Vision Foundation Model for Echocardiography",
      "title_zh": "翻译失败",
      "authors": [
        "Abdoul Aziz Amadou",
        "Yue Zhang",
        "Sebastien Piat",
        "Paul Klein",
        "Ingo Schmuecking",
        "Tiziano Passerini",
        "Puneet Sharma"
      ],
      "abstract": "Quantitative evaluation of echocardiography is essential for precise\nassessment of cardiac condition, monitoring disease progression, and guiding\ntreatment decisions. The diverse nature of echo images, including variations in\nprobe types, manufacturers, and pathologies, poses challenges for developing\nartificial intelligent models that can generalize across different clinical\npractice. We introduce EchoApex, the first general-purpose vision foundation\nmodel echocardiography with applications on a variety of clinical practice.\nLeveraging self-supervised learning, EchoApex is pretrained on over 20 million\necho images from 11 clinical centres. By incorporating task-specific decoders\nand adapter modules, we demonstrate the effectiveness of EchoApex on 4\ndifferent kind of clinical applications with 28 sub-tasks, including view\nclassification, interactive structure segmentation, left ventricle hypertrophy\ndetection and automated ejection fraction estimation from view sequences.\nCompared to state-of-the-art task-specific models, EchoApex attains improved\nperformance with a unified image encoding architecture, demonstrating the\nbenefits of model pretraining at scale with in-domain data. Furthermore,\nEchoApex illustrates the potential for developing a general-purpose vision\nfoundation model tailored specifically for echocardiography, capable of\naddressing a diverse range of clinical applications with high efficiency and\nefficacy.",
      "tldr_zh": "这篇论文介绍了 EchoApex，一种通用的视觉基础模型（vision foundation model），旨在解决超声心动图（echocardiography）图像多样性（如探头类型和病理变化）带来的挑战，实现精确的心脏状况评估。EchoApex 通过自监督学习（self-supervised learning）在超过 2000 万张来自 11 个临床中心的图像上预训练，并结合任务特定的解码器和适配器模块，在 4 种临床应用和 28 个子任务（如视图分类、交互式结构分割和自动射血分数估计）上表现出色。与现有任务特定模型相比，EchoApex 实现了性能提升，证明了大规模领域内预训练的显著优势。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.11092v3",
      "published_date": "2024-10-14 21:10:56 UTC",
      "updated_date": "2024-10-24 20:57:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:07:44.058997"
    },
    {
      "arxiv_id": "2410.11080v1",
      "title": "Few-shot Novel View Synthesis using Depth Aware 3D Gaussian Splatting",
      "title_zh": "翻译失败",
      "authors": [
        "Raja Kumar",
        "Vanshika Vats"
      ],
      "abstract": "3D Gaussian splatting has surpassed neural radiance field methods in novel\nview synthesis by achieving lower computational costs and real-time\nhigh-quality rendering. Although it produces a high-quality rendering with a\nlot of input views, its performance drops significantly when only a few views\nare available. In this work, we address this by proposing a depth-aware\nGaussian splatting method for few-shot novel view synthesis. We use monocular\ndepth prediction as a prior, along with a scale-invariant depth loss, to\nconstrain the 3D shape under just a few input views. We also model color using\nlower-order spherical harmonics to avoid overfitting. Further, we observe that\nremoving splats with lower opacity periodically, as performed in the original\nwork, leads to a very sparse point cloud and, hence, a lower-quality rendering.\nTo mitigate this, we retain all the splats, leading to a better reconstruction\nin a few view settings. Experimental results show that our method outperforms\nthe traditional 3D Gaussian splatting methods by achieving improvements of\n10.5% in peak signal-to-noise ratio, 6% in structural similarity index, and\n14.1% in perceptual similarity, thereby validating the effectiveness of our\napproach. The code will be made available at:\nhttps://github.com/raja-kumar/depth-aware-3DGS",
      "tldr_zh": "本文提出了一种深度感知的 3D Gaussian splatting 方法，用于处理少量输入视图下的新型视图合成问题，以解决传统方法在这种场景下性能下降的问题。该方法利用 monocular depth prediction 作为先验，并结合 scale-invariant depth loss 来约束 3D 形状，同时采用较低阶 spherical harmonics 建模颜色以避免过拟合，并保留所有 splats 以防止点云稀疏导致的渲染质量降低。实验结果显示，与传统 3D Gaussian splatting 方法相比，该方法在峰值信噪比（PSNR）上提高了 10.5%、结构相似性指数（SSIM）上提高了 6%、以及感知相似性上提高了 14.1%。这一改进验证了深度感知机制的有效性，并为新型视图合成提供了更可靠的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR"
      ],
      "primary_category": "cs.CV",
      "comment": "Presented in ECCV 2024 workshop S3DSGR",
      "pdf_url": "http://arxiv.org/pdf/2410.11080v1",
      "published_date": "2024-10-14 20:42:30 UTC",
      "updated_date": "2024-10-14 20:42:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:07:56.141021"
    },
    {
      "arxiv_id": "2410.11079v1",
      "title": "Code-Mixer Ya Nahi: Novel Approaches to Measuring Multilingual LLMs' Code-Mixing Capabilities",
      "title_zh": "翻译失败",
      "authors": [
        "Ayushman Gupta",
        "Akhil Bhogal",
        "Kripabandhu Ghosh"
      ],
      "abstract": "Multilingual Large Language Models (LLMs) have demonstrated exceptional\nperformance in Machine Translation (MT) tasks. However, their MT abilities in\nthe context of code-switching (the practice of mixing two or more languages in\nan utterance) remain under-explored. In this paper, we introduce Rule-Based\nPrompting, a novel prompting technique to generate code-mixed sentences. We\nmeasure and compare the code-mixed MT abilities of 3 popular multilingual LLMs:\nGPT-3.5-turbo, GPT-4, and Gemini Pro across five language pairs:\nEnglish-{Hindi, Bengali, Gujarati, French, Spanish} using $k$-shot prompting\n($k\\in\\{0, 1, 10, 20\\}$) and Rule-Based Prompting. Our findings suggest that\nthough $k$-shot prompting often leads to the best results, Rule-Based prompting\nshows promise in generating unique code-mixed sentences that vary in their\nstyle of code-mixing. We also use $k$-shot prompting to gauge the code-mixed to\nEnglish translation abilities of multilingual LLMs. For this purpose, we create\na gold-standard code-mixed dataset spanning five language pairs:\nEnglish-{Hindi, Bengali, Gujarati, French, Spanish}. As a real-world\napplication of our work, we create a code-mixed chatbot.",
      "tldr_zh": "该研究评估了多语言大语言模型 (Multilingual LLMs) 在代码切换 (code-switching) 上下文下的机器翻译 (MT) 能力，引入了 Rule-Based Prompting 技术来生成代码混合句子，并与 k-shot prompting ($k\\in\\{0, 1, 10, 20\\}$) 进行比较。实验测试了 GPT-3.5-turbo、GPT-4 和 Gemini Pro 三个模型，在 English-{Hindi, Bengali, Gujarati, French, Spanish} 五对语言上的表现，结果显示 k-shot prompting 通常取得最佳效果，而 Rule-Based Prompting 能生成风格多样的独特代码混合句子。研究还创建了一个金标准代码混合数据集，用于评估模型从代码混合到英语的翻译能力，并开发了一个代码混合聊天机器人作为实际应用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Manuscript submitted to COLING 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.11079v1",
      "published_date": "2024-10-14 20:40:36 UTC",
      "updated_date": "2024-10-14 20:40:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:08:09.093217"
    },
    {
      "arxiv_id": "2410.11076v1",
      "title": "PRACTIQ: A Practical Conversational Text-to-SQL dataset with Ambiguous and Unanswerable Queries",
      "title_zh": "PRACTIQ：",
      "authors": [
        "Mingwen Dong",
        "Nischal Ashok Kumar",
        "Yiqun Hu",
        "Anuj Chauhan",
        "Chung-Wei Hang",
        "Shuaichen Chang",
        "Lin Pan",
        "Wuwei Lan",
        "Henghui Zhu",
        "Jiarong Jiang",
        "Patrick Ng",
        "Zhiguo Wang"
      ],
      "abstract": "Previous text-to-SQL datasets and systems have primarily focused on user\nquestions with clear intentions that can be answered. However, real user\nquestions can often be ambiguous with multiple interpretations or unanswerable\ndue to a lack of relevant data. In this work, we construct a practical\nconversational text-to-SQL dataset called PRACTIQ, consisting of ambiguous and\nunanswerable questions inspired by real-world user questions. We first\nidentified four categories of ambiguous questions and four categories of\nunanswerable questions by studying existing text-to-SQL datasets. Then, we\ngenerate conversations with four turns: the initial user question, an assistant\nresponse seeking clarification, the user's clarification, and the assistant's\nclarified SQL response with the natural language explanation of the execution\nresults. For some ambiguous queries, we also directly generate helpful SQL\nresponses, that consider multiple aspects of ambiguity, instead of requesting\nuser clarification. To benchmark the performance on ambiguous, unanswerable,\nand answerable questions, we implemented large language model (LLM)-based\nbaselines using various LLMs. Our approach involves two steps: question\ncategory classification and clarification SQL prediction. Our experiments\nreveal that state-of-the-art systems struggle to handle ambiguous and\nunanswerable questions effectively. We will release our code for data\ngeneration and experiments on GitHub.",
      "tldr_zh": "这篇论文介绍了 PRACTIQ，一个实用的对话式 text-to-SQL 数据集，专注于真实世界中常见的模糊和无法回答查询，以弥补现有数据集的局限性。研究者通过分析现有数据集，识别了四类模糊问题（如多重解释）和四类无法回答问题，并生成四轮对话（包括初始查询、助手澄清、用户回应和最终 SQL 响应），同时为某些模糊查询直接提供多方面考虑的 SQL 响应。实验使用大型语言模型 (LLM) 基准系统进行问题类别分类和澄清 SQL 预测，结果显示现有系统在处理模糊和无法回答查询时表现不佳，并计划在 GitHub 上发布代码以促进进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.11076v1",
      "published_date": "2024-10-14 20:36:35 UTC",
      "updated_date": "2024-10-14 20:36:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:08:19.927790"
    },
    {
      "arxiv_id": "2410.11064v2",
      "title": "Parsing altered brain connectivity in neurodevelopmental disorders by integrating graph-based normative modeling and deep generative networks",
      "title_zh": "通过整合基于图形的规范建模和深度生成网络解析神经发育障碍中改变的脑连接性",
      "authors": [
        "Rui Sherry Shen",
        "Yusuf Osmanlıoğlu",
        "Drew Parker",
        "Darien Aunapu",
        "Benjamin E. Yerys",
        "Birkan Tunç",
        "Ragini Verma"
      ],
      "abstract": "Divergent brain connectivity is thought to underlie the behavioral and\ncognitive symptoms observed in many neurodevelopmental disorders. Quantifying\ndivergence from neurotypical connectivity patterns offers a promising pathway\nto inform diagnosis and therapeutic interventions. While advanced neuroimaging\ntechniques, such as diffusion MRI (dMRI), have facilitated the mapping of\nbrain's structural connectome, the challenge lies in accurately modeling\ndevelopmental trajectories within these complex networked structures to create\nrobust neurodivergence markers. In this work, we present the Brain\nRepresentation via Individualized Deep Generative Embedding (BRIDGE) framework,\nwhich integrates normative modeling with a bio-inspired deep generative model\nto create a reference trajectory of connectivity transformation as part of\nneurotypical development. This will enable the assessment of neurodivergence by\ncomparing individuals to the established neurotypical trajectory. BRIDGE\nprovides a global neurodivergence score based on the difference between\nconnectivity-based brain age and chronological age, along with region-wise\nneurodivergence maps that highlight localized connectivity differences.\nApplication of BRIDGE to a large cohort of children with autism spectrum\ndisorder demonstrates that the global neurodivergence score correlates with\nclinical assessments in autism, and the regional map offers insights into the\nheterogeneity at the individual level in neurodevelopmental disorders.\nTogether, the neurodivergence score and map form powerful tools for quantifying\ndevelopmental divergence in connectivity patterns, advancing the development of\nimaging markers for personalized diagnosis and intervention in various clinical\ncontexts.",
      "tldr_zh": "本研究提出BRIDGE框架，通过整合graph-based normative modeling和生物启发深度生成模型，构建正常大脑连接发育的参考轨迹，以量化神经发育障碍中的连接差异。该框架计算全局neurodivergence分数（基于连接脑年龄与实际年龄的差异）和区域神经分歧地图，帮助评估个体与正常轨迹的偏差。在应用到自闭谱系障碍(ASD)儿童的大样本中，BRIDGE显示全球分数与临床评估相关，且区域地图揭示了个体水平的异质性，从而为个性化诊断和干预提供先进的成像标记工具。",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "q-bio.QM"
      ],
      "primary_category": "q-bio.NC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.11064v2",
      "published_date": "2024-10-14 20:21:11 UTC",
      "updated_date": "2024-11-18 15:29:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:08:32.452762"
    },
    {
      "arxiv_id": "2410.11063v1",
      "title": "Towards the methodology for solving the minimum enclosing ball and related problems",
      "title_zh": "翻译失败",
      "authors": [
        "Michael N. Vrahatis"
      ],
      "abstract": "Methodology is provided towards the solution of the minimum enclosing ball\nproblem. This problem concerns the determination of the unique spherical\nsurface of smallest radius enclosing a given bounded set in the d-dimensional\nEuclidean space. Mathematical formulation and typical methods for solving this\nproblem are presented. Also, the paper is focused on areas that are related to\nthis problem, namely: (a) promise problems and property testing, (b) theorems\nfor partitioning and enclosing (covering) a set, and (c) computation of the\ndiameter of a set.",
      "tldr_zh": "这篇论文针对 minimum enclosing ball 问题，提供了解决方法论，该问题涉及在 d 维欧式空间中找到最小半径的球体来包围一个给定的有界集合。论文呈现了数学公式和典型算法，用于精确求解此问题。论文还探讨了相关领域，包括 promise problems 和 property testing、集合分区和包围（covering）定理，以及集合直径的计算。这些方法论为进一步研究几何优化和相关计算问题奠定了基础。",
      "categories": [
        "cs.CG",
        "cs.AI",
        "math.GT"
      ],
      "primary_category": "cs.CG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.11063v1",
      "published_date": "2024-10-14 20:20:04 UTC",
      "updated_date": "2024-10-14 20:20:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:08:42.715728"
    },
    {
      "arxiv_id": "2410.11062v2",
      "title": "CleanUMamba: A Compact Mamba Network for Speech Denoising using Channel Pruning",
      "title_zh": "翻译失败",
      "authors": [
        "Sjoerd Groot",
        "Qinyu Chen",
        "Jan C. van Gemert",
        "Chang Gao"
      ],
      "abstract": "This paper presents CleanUMamba, a time-domain neural network architecture\ndesigned for real-time causal audio denoising directly applied to raw\nwaveforms. CleanUMamba leverages a U-Net encoder-decoder structure,\nincorporating the Mamba state-space model in the bottleneck layer. By replacing\nconventional self-attention and LSTM mechanisms with Mamba, our architecture\noffers superior denoising performance while maintaining a constant memory\nfootprint, enabling streaming operation. To enhance efficiency, we applied\nstructured channel pruning, achieving an 8X reduction in model size without\ncompromising audio quality. Our model demonstrates strong results in the\nInterspeech 2020 Deep Noise Suppression challenge. Specifically, CleanUMamba\nachieves a PESQ score of 2.42 and STOI of 95.1% with only 442K parameters and\n468M MACs, matching or outperforming larger models in real-time performance.\nCode will be available at: https://github.com/lab-emi/CleanUMamba",
      "tldr_zh": "该论文提出 CleanUMamba，一种紧凑的时间域神经网络架构，用于实时因果音频去噪，直接处理原始波形。它采用 U-Net 编码器-解码器结构，并在瓶颈层融入 Mamba 状态空间模型，以替换传统的自注意力机制和 LSTM，从而实现高效去噪并支持流式操作。论文通过结构化通道剪枝，将模型大小减少 8 倍，同时保持音频质量，并在 Interspeech 2020 Deep Noise Suppression 挑战中表现出色，达到 PESQ 得分为 2.42 和 STOI 为 95.1%，参数仅 442K 和 468M MACs，与更大模型相当或更好。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CV",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "This paper has been accepted to be presented at the 2025\n  International Symposium on Circuits and Systems (ISCAS)",
      "pdf_url": "http://arxiv.org/pdf/2410.11062v2",
      "published_date": "2024-10-14 20:18:03 UTC",
      "updated_date": "2025-02-10 18:07:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:08:54.732245"
    },
    {
      "arxiv_id": "2410.11059v1",
      "title": "Assessing Bias in Metric Models for LLM Open-Ended Generation Bias Benchmarks",
      "title_zh": "翻译失败",
      "authors": [
        "Nathaniel Demchak",
        "Xin Guan",
        "Zekun Wu",
        "Ziyi Xu",
        "Adriano Koshiyama",
        "Emre Kazim"
      ],
      "abstract": "Open-generation bias benchmarks evaluate social biases in Large Language\nModels (LLMs) by analyzing their outputs. However, the classifiers used in\nanalysis often have inherent biases, leading to unfair conclusions. This study\nexamines such biases in open-generation benchmarks like BOLD and SAGED. Using\nthe MGSD dataset, we conduct two experiments. The first uses counterfactuals to\nmeasure prediction variations across demographic groups by altering\nstereotype-related prefixes. The second applies explainability tools (SHAP) to\nvalidate that the observed biases stem from these counterfactuals. Results\nreveal unequal treatment of demographic descriptors, calling for more robust\nbias metric models.",
      "tldr_zh": "本研究评估了 LLM 开放生成偏见基准（如 BOLD 和 SAGED）中度量模型的固有偏见问题，这些偏见可能导致对 LLM 输出分析的不公平结论。通过 MGSD 数据集进行两个实验：第一个使用 counterfactuals 改变与刻板印象相关的词前缀，以测量预测在不同人口统计群体间的变化；第二个应用 SHAP 解释性工具验证这些偏见的确切来源。结果揭示了对人口统计描述的不平等处理，呼吁开发更稳健的偏见度量模型，以提升 LLM 偏见评估的可靠性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "NeurIPS 2024 EvalEval Workshop",
      "pdf_url": "http://arxiv.org/pdf/2410.11059v1",
      "published_date": "2024-10-14 20:08:40 UTC",
      "updated_date": "2024-10-14 20:08:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:09:07.076343"
    },
    {
      "arxiv_id": "2410.11055v1",
      "title": "Varying Shades of Wrong: Aligning LLMs with Wrong Answers Only",
      "title_zh": "翻译失败",
      "authors": [
        "Jihan Yao",
        "Wenxuan Ding",
        "Shangbin Feng",
        "Lucy Lu Wang",
        "Yulia Tsvetkov"
      ],
      "abstract": "In the absence of abundant reliable annotations for challenging tasks and\ncontexts, how can we expand the frontier of LLM capabilities with potentially\nwrong answers? We focus on two research questions: (1) Can LLMs generate\nreliable preferences among wrong options? And if so, (2) Would alignment with\nsuch wrong-over-wrong preferences be helpful? We employ methods based on\nself-consistency, token probabilities, and LLM-as-a-judge to elicit\nwrong-over-wrong preferences, and fine-tune language models with preference\noptimization approaches using these synthesized preferences. Extensive\nexperiments with seven LLMs and eight datasets demonstrate that (1) LLMs do\nhave preliminary capability in distinguishing various shades of wrong,\nachieving up to 20.9% higher performance than random guess; (2) Alignment with\nwrong-over-wrong preferences helps LLMs to produce less wrong and sometimes\neven outright correct answers, while overall improving model calibration.",
      "tldr_zh": "本研究探讨了在缺乏可靠标注的情况下，如何利用错误答案扩展LLM（Large Language Models）能力，焦点在于：（1）LLMs是否能可靠地区分不同程度的错误选项；（2）基于这些错误偏好进行模型对齐是否有效。研究采用自一致性（self-consistency）、token概率和LLM-as-a-judge方法来生成wrong-over-wrong偏好，并通过偏好优化技术对七个LLMs进行微调。实验结果显示，LLMs在八个数据集上区分错误的性能比随机猜测高出20.9%，且这种对齐方法能减少模型的错误输出，有时甚至产生正确答案，同时提升了模型校准。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.11055v1",
      "published_date": "2024-10-14 20:01:52 UTC",
      "updated_date": "2024-10-14 20:01:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:09:18.793161"
    },
    {
      "arxiv_id": "2410.11900v4",
      "title": "FLARE: Faithful Logic-Aided Reasoning and Exploration",
      "title_zh": "FLARE：忠实逻辑辅助推理与探索",
      "authors": [
        "Erik Arakelyan",
        "Pasquale Minervini",
        "Pat Verga",
        "Patrick Lewis",
        "Isabelle Augenstein"
      ],
      "abstract": "Modern Question Answering (QA) and Reasoning approaches based on Large\nLanguage Models (LLMs) commonly use prompting techniques, such as\nChain-of-Thought (CoT), assuming the resulting generation will have a more\ngranular exploration and reasoning over the question space and scope. However,\nsuch methods struggle with generating outputs that are faithful to the\nintermediate chain of reasoning produced by the model. On the other end of the\nspectrum, neuro-symbolic methods such as Faithful CoT (F-CoT) propose to\ncombine LLMs with external symbolic solvers. While such approaches boast a high\ndegree of faithfulness, they usually require a model trained for code\ngeneration and struggle with tasks that are ambiguous or hard to formalise\nstrictly. We introduce $\\textbf{F}$aithful $\\textbf{L}$ogic-$\\textbf{A}$ided\n$\\textbf{R}$easoning and $\\textbf{E}$xploration ($\\textbf{FLARE}$), a novel\ninterpretable approach for traversing the problem space using task\ndecompositions. We use the LLM to plan a solution, soft-formalise the query\ninto facts and predicates using a logic programming code and simulate that code\nexecution using an exhaustive multi-hop search over the defined space. Our\nmethod allows us to compute the faithfulness of the reasoning process w.r.t.\nthe generated code and analyse the steps of the multi-hop search without\nrelying on external solvers. Our methods achieve SOTA results on $\\mathbf{7}$\nout of $\\mathbf{9}$ diverse reasoning benchmarks. We also show that model\nfaithfulness positively correlates with overall performance and further\ndemonstrate that $\\textbf{FLARE}$ allows pinpointing the decisive factors\nsufficient for and leading to the correct answer with optimal reasoning during\nthe multi-hop search.",
      "tldr_zh": "本研究提出FLARE，一种可解释的逻辑辅助推理和探索方法，旨在解决Large Language Models (LLMs)基于提示技术如Chain-of-Thought (CoT)的问答和推理中，输出与中间推理不忠实的问题。FLARE利用LLMs规划解决方案，将查询软形式化为逻辑编程代码，并通过穷举多跳搜索模拟代码执行，从而在不依赖外部求解器的情况下计算推理过程的忠实度。该方法在9个多样化推理基准测试中，在7个上达到SOTA结果，并证明模型忠实度与整体性能正相关，同时能精确识别多跳搜索中导致正确答案的关键因素。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.11900v4",
      "published_date": "2024-10-14 19:39:11 UTC",
      "updated_date": "2025-01-21 14:57:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:09:31.926863"
    },
    {
      "arxiv_id": "2410.11038v1",
      "title": "Towards a More Complete Theory of Function Preserving Transforms",
      "title_zh": "翻译失败",
      "authors": [
        "Michael Painter"
      ],
      "abstract": "In this paper, we develop novel techniques that can be used to alter the\narchitecture of a neural network, while maintaining the function it represents.\nSuch operations are known as function preserving transforms and have proven\nuseful in transferring knowledge between networks to evaluate architectures\nquickly, thus having applications in efficient architectures searches. Our\nmethods allow the integration of residual connections into function preserving\ntransforms, so we call them R2R. We provide a derivation for R2R and show that\nit yields competitive performance with other function preserving transforms,\nthereby decreasing the restrictions on deep learning architectures that can be\nextended through function preserving transforms. We perform a comparative\nanalysis with other function preserving transforms such as Net2Net and Network\nMorphisms, where we shed light on their differences and individual use cases.\nFinally, we show the effectiveness of R2R to train models quickly, as well as\nits ability to learn a more diverse set of filters on image classification\ntasks compared to Net2Net and Network Morphisms.",
      "tldr_zh": "本论文开发了R2R方法，一种新型函数保持变换（function preserving transforms），通过整合残差连接（residual connections）来改变神经网络架构，同时保持其表示的功能，从而支持高效架构搜索和知识转移。R2R的推导减少了对深度学习架构的限制，并与Net2Net和Network Morphisms进行了比较分析，揭示了它们之间的差异和各自适用场景。实验结果表明，R2R在图像分类任务中表现出色，能更快地训练模型并学习更多样化的过滤器。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.11038v1",
      "published_date": "2024-10-14 19:37:45 UTC",
      "updated_date": "2024-10-14 19:37:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:09:43.502735"
    },
    {
      "arxiv_id": "2410.11031v2",
      "title": "NAR-*ICP: Neural Execution of Classical ICP-based Pointcloud Registration Algorithms",
      "title_zh": "翻译失败",
      "authors": [
        "Efimia Panagiotaki",
        "Daniele De Martini",
        "Lars Kunze",
        "Petar Veličković"
      ],
      "abstract": "This study explores the intersection of neural networks and classical\nrobotics algorithms through the Neural Algorithmic Reasoning (NAR) framework,\nallowing to train neural networks to effectively reason like classical robotics\nalgorithms by learning to execute them. Algorithms are integral to robotics and\nsafety-critical applications due to their predictable and consistent\nperformance through logical and mathematical principles. In contrast, while\nneural networks are highly adaptable, handling complex, high-dimensional data\nand generalising across tasks, they often lack interpretability and\ntransparency in their internal computations. We propose a Graph Neural Network\n(GNN)-based learning framework, NAR-*ICP, which learns the intermediate\nalgorithmic steps of classical ICP-based pointcloud registration algorithms,\nand extend the CLRS Algorithmic Reasoning Benchmark with classical robotics\nperception algorithms. We evaluate our approach across diverse datasets, from\nreal-world to synthetic, demonstrating its flexibility in handling complex and\nnoisy inputs, along with its potential to be used as part of a larger learning\nsystem. Our results indicate that our method achieves superior performance\nacross all benchmarks and datasets, consistently surpassing even the algorithms\nit has been trained on, further demonstrating its ability to generalise beyond\nthe capabilities of traditional algorithms.",
      "tldr_zh": "这篇论文探索了神经网络与经典机器人算法的结合，通过Neural Algorithmic Reasoning (NAR)框架训练神经网络来执行经典ICP-based点云注册算法。作者提出了一种基于Graph Neural Network (GNN)的NAR-*ICP方法，能够学习算法的中间步骤，并扩展了CLRS Algorithmic Reasoning Benchmark以包含机器人感知算法。在多样化的真实和合成数据集上评估表明，该框架在处理复杂噪声输入时表现出色，并超越了传统算法的性能，证明了其更高的泛化能力和潜力。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "17 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.11031v2",
      "published_date": "2024-10-14 19:33:46 UTC",
      "updated_date": "2024-10-16 14:05:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:09:58.070903"
    },
    {
      "arxiv_id": "2410.11020v3",
      "title": "Improving the Language Understanding Capabilities of Large Language Models Using Reinforcement Learning",
      "title_zh": "使用强化学习改进大语言模型的语言理解能力",
      "authors": [
        "Bokai Hu",
        "Sai Ashish Somayajula",
        "Xin Pan",
        "Zihan Huang",
        "Pengtao Xie"
      ],
      "abstract": "Large language models (LLMs), built on decoder-only transformers, excel in\nnatural language generation and adapt to diverse tasks using zero-shot and\nfew-shot prompting. However, these prompting methods often struggle on natural\nlanguage understanding (NLU) tasks, where encoder-only models like BERT-base\noutperform LLMs on benchmarks like GLUE and SuperGLUE. This paper explores two\napproaches-supervised fine-tuning (SFT) and proximal policy optimization\n(PPO)-to enhance LLMs' NLU abilities. To reduce the cost of full-model\nfine-tuning, we integrate low-rank adaptation (LoRA) layers, limiting updates\nto these layers during both SFT and PPO. In SFT, task-specific prompts are\nconcatenated with input queries and ground-truth labels, optimizing with\nnext-token prediction. Despite this, LLMs still underperform compared to models\nlike BERT-base on several NLU tasks. To close this gap, we apply PPO, a\nreinforcement learning technique that treats each token generation as an action\nand uses a reward function based on alignment with ground-truth answers. PPO\nthen updates the model to maximize these rewards, aligning outputs with correct\nlabels. Our experiments with LLAMA2-7B show that PPO improves performance, with\na 6.3-point gain over SFT on GLUE. PPO exceeds zero-shot by 38.7 points and\nfew-shot by 26.1 points on GLUE, while surpassing these by 28.8 and 28.5 points\non SuperGLUE. Additionally, PPO outperforms BERT-large by 2.7 points on GLUE\nand 9.3 points on SuperGLUE. The improvements are consistent across models like\nQwen2.5-7B and MPT-7B, highlighting PPO's robustness in enhancing LLMs' NLU\ncapabilities.",
      "tldr_zh": "这篇论文探讨了使用监督微调 (SFT) 和近端策略优化 (PPO) 来提升大型语言模型 (LLMs) 在自然语言理解 (NLU) 任务上的能力，通过整合低秩适配 (LoRA) 减少微调成本。SFT 通过任务特定提示和 next-token 预测优化模型，但表现仍落后于 BERT-base；PPO 则将每个 token 生成视为动作，并基于 ground-truth 答案的奖励函数更新模型，从而显著改善输出对齐。实验结果显示，在 LLAMA2-7B 模型上，PPO 在 GLUE 基准上比 SFT 提高 6.3 分，并超过 BERT-large 2.7 分，在 SuperGLUE 上也实现类似提升，且在 Qwen2.5-7B 和 MPT-7B 等模型中表现出色。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.11020v3",
      "published_date": "2024-10-14 19:16:56 UTC",
      "updated_date": "2024-10-22 00:42:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:10:08.533697"
    },
    {
      "arxiv_id": "2410.13894v1",
      "title": "Deep Learning Based XIoT Malware Analysis: A Comprehensive Survey, Taxonomy, and Research Challenges",
      "title_zh": "翻译失败",
      "authors": [
        "Rami Darwish",
        "Mahmoud Abdelsalam",
        "Sajad Khorsandroo"
      ],
      "abstract": "The Internet of Things (IoT) is one of the fastest-growing computing\nindustries. By the end of 2027, more than 29 billion devices are expected to be\nconnected. These smart devices can communicate with each other with and without\nhuman intervention. This rapid growth has led to the emergence of new types of\nmalware. However, traditional malware detection methods, such as\nsignature-based and heuristic-based techniques, are becoming increasingly\nineffective against these new types of malware. Therefore, it has become\nindispensable to find practical solutions for detecting IoT malware. Machine\nLearning (ML) and Deep Learning (DL) approaches have proven effective in\ndealing with these new IoT malware variants, exhibiting high detection rates.\nIn this paper, we bridge the gap in research between the IoT malware analysis\nand the wide adoption of deep learning in tackling the problems in this domain.\nAs such, we provide a comprehensive review on deep learning based malware\nanalysis across various categories of the IoT domain (i.e. Extended Internet of\nThings (XIoT)), including Industrial IoT (IIoT), Internet of Medical Things\n(IoMT), Internet of Vehicles (IoV), and Internet of Battlefield Things (IoBT).",
      "tldr_zh": "这篇论文对基于深度学习(Deep Learning)的扩展物联网(XIoT)恶意软件分析进行了全面调查和分类，强调了物联网(IoT)设备快速增长带来的新型恶意软件威胁，以及传统方法如基于签名和启发式技术的局限性。论文桥接了IoT恶意软件分析与深度学习应用，探讨了机器学习(ML)和深度学习(DL)在检测IoT恶意软件方面的有效性，包括高检测率的表现。研究涵盖了XIoT的多个领域，如工业物联网(IIoT)、医疗物联网(IoMT)、车辆物联网(IoV)和战场物联网(IoBT)，并提出了关键的研究挑战，以推动该领域的未来发展。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.13894v1",
      "published_date": "2024-10-14 19:04:43 UTC",
      "updated_date": "2024-10-14 19:04:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:10:19.204253"
    },
    {
      "arxiv_id": "2410.11009v1",
      "title": "Enhancing AI Assisted Writing with One-Shot Implicit Negative Feedback",
      "title_zh": "使用一-shot 隐式负面反馈增强 AI 辅助写作",
      "authors": [
        "Benjamin Towle",
        "Ke Zhou"
      ],
      "abstract": "AI-mediated communication enables users to communicate more quickly and\nefficiently. Various systems have been proposed such as smart reply and\nAI-assisted writing. Yet, the heterogeneity of the forms of inputs and\narchitectures often renders it challenging to combine insights from user\nbehaviour in one system to improve performance in another. In this work, we\nconsider the case where the user does not select any of the suggested replies\nfrom a smart reply system, and how this can be used as one-shot implicit\nnegative feedback to enhance the accuracy of an AI writing model. We introduce\nNifty, an approach that uses classifier guidance to controllably integrate\nimplicit user feedback into the text generation process. Empirically, we find\nup to 34% improvement in Rouge-L, 89% improvement in generating the correct\nintent, and an 86% win-rate according to human evaluators compared to a vanilla\nAI writing system on the MultiWOZ and Schema-Guided Dialog datasets.",
      "tldr_zh": "该研究探讨了如何利用一次性的隐式负面反馈（One-Shot Implicit Negative Feedback）来提升 AI 辅助写作系统的性能，特别是在用户未选择智能回复建议时，将其作为反馈信号。作者引入了 Nifty 方法，通过分类器引导（Classifier Guidance）可控地整合这种反馈到文本生成过程，从而解决不同系统间用户行为洞见的整合挑战。在 MultiWOZ 和 Schema-Guided Dialog 数据集上的实验显示，Nifty 比传统 AI 写作系统提升了高达 34% 的 Rouge-L 分数、89% 的正确意图生成率，以及 86% 的赢率（根据人类评估）。这项工作为 AI 辅助通信提供了更高效的改进框架。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to appear at EMNLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.11009v1",
      "published_date": "2024-10-14 18:50:28 UTC",
      "updated_date": "2024-10-14 18:50:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:10:30.925372"
    },
    {
      "arxiv_id": "2410.11001v1",
      "title": "Graph of Records: Boosting Retrieval Augmented Generation for Long-context Summarization with Graphs",
      "title_zh": "Graph of Records：利用图提升检索增强生成以实现长上下文总结",
      "authors": [
        "Haozhen Zhang",
        "Tao Feng",
        "Jiaxuan You"
      ],
      "abstract": "Retrieval-augmented generation (RAG) has revitalized Large Language Models\n(LLMs) by injecting non-parametric factual knowledge. Compared with\nlong-context LLMs, RAG is considered an effective summarization tool in a more\nconcise and lightweight manner, which can interact with LLMs multiple times\nusing diverse queries to get comprehensive responses. However, the\nLLM-generated historical responses, which contain potentially insightful\ninformation, are largely neglected and discarded by existing approaches,\nleading to suboptimal results. In this paper, we propose \\textit{graph of\nrecords} (\\textbf{GoR}), which leverages historical responses generated by LLMs\nto enhance RAG for long-context global summarization. Inspired by the\n\\textit{retrieve-then-generate} paradigm of RAG, we construct a graph by\nestablishing an edge between the retrieved text chunks and the corresponding\nLLM-generated response. To further uncover the intricate correlations between\nthem, GoR further features a \\textit{graph neural network} and an elaborately\ndesigned \\textit{BERTScore}-based objective for self-supervised model training,\nenabling seamless supervision signal backpropagation between reference\nsummaries and node embeddings. We comprehensively compare GoR with 12 baselines\nacross four long-context summarization datasets, and the results indicate that\nour proposed method reaches the best performance e.g., 15\\%, 8\\%, and 19\\%\nimprovement over retrievers w.r.t. Rouge-L, Rouge-1, and Rouge-2 on the WCEP\ndataset). Extensive experiments further demonstrate the effectiveness of GoR.\nCode is available at https://github.com/ulab-uiuc/GoR",
      "tldr_zh": "该研究提出了一种名为 Graph of Records (GoR) 的方法，以提升 Retrieval Augmented Generation (RAG) 在长上下文总结任务中的性能。GoR 通过利用 Large Language Models (LLMs) 生成的历史响应构建图结构，将检索到的文本块与对应响应连接起来，从而挖掘它们之间的复杂相关性。方法进一步采用 Graph Neural Network (GNN) 和基于 BERTScore 的自监督训练目标，实现参考总结与节点嵌入之间的无缝监督。实验结果显示，GoR 在四个长上下文总结数据集上优于12个基线方法，例如在 WCEP 数据集上，Rouge-L、Rouge-1 和 Rouge-2 指标分别提高了15%、8% 和19%。这项创新为更高效的 RAG 应用提供了新途径。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.11001v1",
      "published_date": "2024-10-14 18:34:29 UTC",
      "updated_date": "2024-10-14 18:34:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:10:43.299157"
    },
    {
      "arxiv_id": "2410.11000v1",
      "title": "Generating Global and Local Explanations for Tree-Ensemble Learning Methods by Answer Set Programming",
      "title_zh": "通过回答集编程生成树集成学习方法的全局和局部解释",
      "authors": [
        "Akihiro Takemura",
        "Katsumi Inoue"
      ],
      "abstract": "We propose a method for generating rule sets as global and local explanations\nfor tree-ensemble learning methods using Answer Set Programming (ASP). To this\nend, we adopt a decompositional approach where the split structures of the base\ndecision trees are exploited in the construction of rules, which in turn are\nassessed using pattern mining methods encoded in ASP to extract explanatory\nrules. For global explanations, candidate rules are chosen from the entire\ntrained tree-ensemble models, whereas for local explanations, candidate rules\nare selected by only considering rules that are relevant to the particular\npredicted instance. We show how user-defined constraints and preferences can be\nrepresented declaratively in ASP to allow for transparent and flexible rule set\ngeneration, and how rules can be used as explanations to help the user better\nunderstand the models. Experimental evaluation with real-world datasets and\npopular tree-ensemble algorithms demonstrates that our approach is applicable\nto a wide range of classification tasks. Under consideration in Theory and\nPractice of Logic Programming (TPLP).",
      "tldr_zh": "本文提出了一种使用Answer Set Programming (ASP)生成规则集的方法，以提供tree-ensemble学习模型的全局和局部explanations。具体而言，该方法采用分解策略，利用基决策树的分割结构构建规则，并通过ASP编码的模式挖掘评估规则集，对于全局explanations从整个模型中选择候选规则，而局部explanations则针对特定预测实例。实验评估显示，该方法适用于多种真实数据集和分类任务，并允许用户通过声明式约束实现透明灵活的规则生成，从而提升模型的可解释性和用户理解。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Under consideration in Theory and Practice of Logic Programming\n  (TPLP). Some parts of this paper were presented at ICLP 2021, and published\n  in EPTCS 345, 2021, pp. 127-140, arXiv:2109.08290",
      "pdf_url": "http://arxiv.org/pdf/2410.11000v1",
      "published_date": "2024-10-14 18:32:29 UTC",
      "updated_date": "2024-10-14 18:32:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:10:55.343508"
    },
    {
      "arxiv_id": "2410.10998v1",
      "title": "WILT: A Multi-Turn, Memorization-Robust Inductive Logic Benchmark for LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Eryk Banatt",
        "Jonathan Cheng",
        "Skanda Vaidyanath",
        "Tiffany Hwu"
      ],
      "abstract": "While large language models have shown impressive capabilities across a wide\nrange of domains, they still encounter significant challenges in reasoning\ntasks that require gathering evidence over multiple turns and drawing logical\nconclusions. These challenges present significant obstacles for LLM chat user\ninterfaces, which rely on multi-turn interactions to facilitate effective\ncollaboration. This limitation leads to real-world issues; for example, service\nchatbots must gather necessary information from customers over multiple turns\nto diagnose and resolve problems effectively. Despite the multi-turn nature of\nmany real-world LLM use cases, most existing benchmarks rely on carefully\ncurated single-turn tests, which often blur the line between memorization and\ngenuine reasoning. To address this, we introduce the Wason Inductive Logic Test\n(WILT), a simple yet challenging multi-turn reasoning benchmark designed to\nresist memorization. WILT is inspired by the Wason 2-4-6 task, where\nparticipants must infer a boolean function involving three variables (e.g., $x\n< y < z$) by proposing test cases (such as $(2, 4, 6)$). In WILT, each test\nstarts from a clean slate, with only the initial instructions provided,\npreventing models from relying on pre-learned responses. Over several turns,\nmodels must interact with the environment by suggesting test cases to narrow\nthe possible hypotheses and ultimately infer the hidden function based on the\noutcomes. Our findings reveal that LLMs struggle with this task, exhibiting\ndistinct strengths and weaknesses: some are better at narrowing down the\nhypothesis space by proposing valuable test cases, while others are more adept\nat deducing the hidden function from observed cases. Despite these variations,\nthe best-performing model achieves only 28% accuracy, highlighting a\nsignificant gap in LLM performance on complex multi-turn reasoning tasks.",
      "tldr_zh": "本论文引入WILT基准，这是一个针对大型语言模型(LLMs)的多轮归纳逻辑测试，旨在评估模型在多轮交互中收集证据和进行逻辑推理的能力，同时抵抗记忆化问题。WILT基于Wason 2-4-6任务设计，要求模型从零状态开始，通过提出测试案例（如变量组合）来逐步缩小假设空间并推断隐藏的布尔函数。实验结果显示，LLMs在WILT上表现出显著弱点，尽管有些模型更擅长提出有价值的测试案例，但最佳模型的准确率仅为28%，突显了现有模型在复杂多轮推理任务中的性能差距。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Submitted to ICLR 2025. Preprint version 1",
      "pdf_url": "http://arxiv.org/pdf/2410.10998v1",
      "published_date": "2024-10-14 18:29:13 UTC",
      "updated_date": "2024-10-14 18:29:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:11:07.335871"
    },
    {
      "arxiv_id": "2410.10989v3",
      "title": "Liger Kernel: Efficient Triton Kernels for LLM Training",
      "title_zh": "翻译失败",
      "authors": [
        "Pin-Lun Hsu",
        "Yun Dai",
        "Vignesh Kothapalli",
        "Qingquan Song",
        "Shao Tang",
        "Siyu Zhu",
        "Steven Shimizu",
        "Shivam Sahni",
        "Haowen Ning",
        "Yanning Chen"
      ],
      "abstract": "Training Large Language Models (LLMs) efficiently at scale presents a\nformidable challenge, driven by their ever-increasing computational demands and\nthe need for enhanced performance. In this work, we introduce Liger-Kernel, an\nopen-sourced set of Triton kernels developed specifically for LLM training.\nWith kernel optimization techniques like kernel operation fusing and input\nchunking, our kernels achieve on average a 20% increase in training throughput\nand a 60% reduction in GPU memory usage for popular LLMs compared to\nHuggingFace implementations. In addition, Liger-Kernel is designed with\nmodularity, accessibility, and adaptability in mind, catering to both casual\nand expert users. Comprehensive benchmarks and integration tests are built in\nto ensure compatibility, performance, correctness, and convergence across\ndiverse computing environments and model architectures.\n  The source code is available under a permissive license at:\ngithub.com/linkedin/Liger-Kernel.",
      "tldr_zh": "本论文介绍了 Liger-Kernel，一套开源的 Triton kernels，旨在提升大型语言模型 (LLMs) 训练的效率，以应对其高计算需求。论文通过内核操作 fusing 和输入 chunking 等优化技术，实现平均 20% 的训练吞吐量提升和 60% 的 GPU memory 使用减少，与 HuggingFace 实现相比表现出显著优势。该框架设计注重模块性、可访问性和适应性，并内置全面基准测试和集成测试，以确保在不同计算环境和模型架构中的兼容性、性能、正确性和收敛性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "17 pages, 12 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.10989v3",
      "published_date": "2024-10-14 18:17:01 UTC",
      "updated_date": "2025-01-24 00:14:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:11:25.066231"
    },
    {
      "arxiv_id": "2410.10818v2",
      "title": "TemporalBench: Benchmarking Fine-grained Temporal Understanding for Multimodal Video Models",
      "title_zh": "TemporalBench：针对多模态视频模型的细粒度时间理解基准测试",
      "authors": [
        "Mu Cai",
        "Reuben Tan",
        "Jianrui Zhang",
        "Bocheng Zou",
        "Kai Zhang",
        "Feng Yao",
        "Fangrui Zhu",
        "Jing Gu",
        "Yiwu Zhong",
        "Yuzhang Shang",
        "Yao Dou",
        "Jaden Park",
        "Jianfeng Gao",
        "Yong Jae Lee",
        "Jianwei Yang"
      ],
      "abstract": "Understanding fine-grained temporal dynamics is crucial for multimodal video\ncomprehension and generation. Due to the lack of fine-grained temporal\nannotations, existing video benchmarks mostly resemble static image benchmarks\nand are incompetent at evaluating models for temporal understanding. In this\npaper, we introduce TemporalBench, a new benchmark dedicated to evaluating\nfine-grained temporal understanding in videos. TemporalBench consists of ~10K\nvideo question-answer pairs, derived from ~2K high-quality human annotations\ndetailing the temporal dynamics in video clips. As a result, our benchmark\nprovides a unique testbed for evaluating various temporal understanding and\nreasoning abilities such as action frequency, motion magnitude, event order,\netc. Moreover, it enables evaluations on various tasks like both video question\nanswering and captioning, both short and long video understanding, as well as\ndifferent models such as multimodal video embedding models and text generation\nmodels. Results show that state-of-the-art models like GPT-4o achieve only\n38.5% question answering accuracy on TemporalBench, demonstrating a significant\ngap (~30%) between humans and AI in temporal understanding. Furthermore, we\nnotice a critical pitfall for multi-choice QA where LLMs can detect the subtle\nchanges in negative captions and find a centralized description as a cue for\nits prediction, where we propose Multiple Binary Accuracy (MBA) to correct such\nbias. We hope that TemporalBench can foster research on improving models'\ntemporal reasoning capabilities. Both dataset and evaluation code will be made\navailable.",
      "tldr_zh": "本研究引入了TemporalBench，一个专注于评估多模态视频模型细粒度时间理解能力的基准数据集。该基准包含约10K视频问答对，基于2K高质量人类注解，涵盖动作频率、运动幅度、事件顺序等时间动态，并支持视频问答、标题生成、短/长视频理解等多种任务。实验结果显示，最先进模型如GPT-4o在TemporalBench上的问答准确率仅为38.5%，与人类相比存在约30%的差距；此外，研究发现多选QA中LLMs可能依赖负面标题的细微变化进行预测，并提出Multiple Binary Accuracy (MBA)来修正这种偏差。该基准的发布有望推动模型时间推理能力的改进。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Project Page: https://temporalbench.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2410.10818v2",
      "published_date": "2024-10-14 17:59:58 UTC",
      "updated_date": "2024-10-15 17:55:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:11:37.738927"
    },
    {
      "arxiv_id": "2410.10816v1",
      "title": "LVD-2M: A Long-take Video Dataset with Temporally Dense Captions",
      "title_zh": "翻译失败",
      "authors": [
        "Tianwei Xiong",
        "Yuqing Wang",
        "Daquan Zhou",
        "Zhijie Lin",
        "Jiashi Feng",
        "Xihui Liu"
      ],
      "abstract": "The efficacy of video generation models heavily depends on the quality of\ntheir training datasets. Most previous video generation models are trained on\nshort video clips, while recently there has been increasing interest in\ntraining long video generation models directly on longer videos. However, the\nlack of such high-quality long videos impedes the advancement of long video\ngeneration. To promote research in long video generation, we desire a new\ndataset with four key features essential for training long video generation\nmodels: (1) long videos covering at least 10 seconds, (2) long-take videos\nwithout cuts, (3) large motion and diverse contents, and (4) temporally dense\ncaptions. To achieve this, we introduce a new pipeline for selecting\nhigh-quality long-take videos and generating temporally dense captions.\nSpecifically, we define a set of metrics to quantitatively assess video quality\nincluding scene cuts, dynamic degrees, and semantic-level quality, enabling us\nto filter high-quality long-take videos from a large amount of source videos.\nSubsequently, we develop a hierarchical video captioning pipeline to annotate\nlong videos with temporally-dense captions. With this pipeline, we curate the\nfirst long-take video dataset, LVD-2M, comprising 2 million long-take videos,\neach covering more than 10 seconds and annotated with temporally dense\ncaptions. We further validate the effectiveness of LVD-2M by fine-tuning video\ngeneration models to generate long videos with dynamic motions. We believe our\nwork will significantly contribute to future research in long video generation.",
      "tldr_zh": "本文提出LVD-2M数据集，以解决视频生成模型训练中缺乏高质量长视频的问题，该数据集包含200万段长-take视频，每段至少10秒，具有大运动、多样内容和temporally dense captions。研究团队开发了一个管道，使用指标如场景剪辑、动态度及语义质量来筛选高品质视频，并采用分层视频字幕方法进行密集标注。实验验证显示，通过微调视频生成模型，LVD-2M能有效生成动态长视频，从而推动长视频生成领域的研究进展。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "NeurIPS 2024 Dataset and Benchmark Track. Project page:\n  https://silentview.github.io/LVD-2M/ . Code:\n  https://github.com/SilentView/LVD-2M",
      "pdf_url": "http://arxiv.org/pdf/2410.10816v1",
      "published_date": "2024-10-14 17:59:56 UTC",
      "updated_date": "2024-10-14 17:59:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:11:49.551988"
    },
    {
      "arxiv_id": "2410.10815v2",
      "title": "Depth Any Video with Scalable Synthetic Data",
      "title_zh": "翻译失败",
      "authors": [
        "Honghui Yang",
        "Di Huang",
        "Wei Yin",
        "Chunhua Shen",
        "Haifeng Liu",
        "Xiaofei He",
        "Binbin Lin",
        "Wanli Ouyang",
        "Tong He"
      ],
      "abstract": "Video depth estimation has long been hindered by the scarcity of consistent\nand scalable ground truth data, leading to inconsistent and unreliable results.\nIn this paper, we introduce Depth Any Video, a model that tackles the challenge\nthrough two key innovations. First, we develop a scalable synthetic data\npipeline, capturing real-time video depth data from diverse virtual\nenvironments, yielding 40,000 video clips of 5-second duration, each with\nprecise depth annotations. Second, we leverage the powerful priors of\ngenerative video diffusion models to handle real-world videos effectively,\nintegrating advanced techniques such as rotary position encoding and flow\nmatching to further enhance flexibility and efficiency. Unlike previous models,\nwhich are limited to fixed-length video sequences, our approach introduces a\nnovel mixed-duration training strategy that handles videos of varying lengths\nand performs robustly across different frame rates-even on single frames. At\ninference, we propose a depth interpolation method that enables our model to\ninfer high-resolution video depth across sequences of up to 150 frames. Our\nmodel outperforms all previous generative depth models in terms of spatial\naccuracy and temporal consistency. The code and model weights are open-sourced.",
      "tldr_zh": "这篇论文提出了Depth Any Video模型，通过一个可扩展的合成数据管道解决视频深度估计中真实数据稀缺的问题，该管道从多样虚拟环境生成40,000个5秒视频剪辑，并提供精确深度标注。模型利用生成视频扩散模型的强大先验，整合rotary position encoding和flow matching等技术，引入混合持续时间训练策略，以处理不同长度视频、帧率，甚至单帧，并通过深度插值方法支持高达150帧的高分辨率推断。实验结果显示，该模型在空间准确性和时间一致性上超越所有现有生成深度模型，且代码和模型权重已开源。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Project Page: https://depthanyvideo.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2410.10815v2",
      "published_date": "2024-10-14 17:59:46 UTC",
      "updated_date": "2025-03-12 09:16:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:12:01.533672"
    },
    {
      "arxiv_id": "2410.10812v1",
      "title": "HART: Efficient Visual Generation with Hybrid Autoregressive Transformer",
      "title_zh": "HART：高效视觉生成与混合自回归Transformer",
      "authors": [
        "Haotian Tang",
        "Yecheng Wu",
        "Shang Yang",
        "Enze Xie",
        "Junsong Chen",
        "Junyu Chen",
        "Zhuoyang Zhang",
        "Han Cai",
        "Yao Lu",
        "Song Han"
      ],
      "abstract": "We introduce Hybrid Autoregressive Transformer (HART), an autoregressive (AR)\nvisual generation model capable of directly generating 1024x1024 images,\nrivaling diffusion models in image generation quality. Existing AR models face\nlimitations due to the poor image reconstruction quality of their discrete\ntokenizers and the prohibitive training costs associated with generating 1024px\nimages. To address these challenges, we present the hybrid tokenizer, which\ndecomposes the continuous latents from the autoencoder into two components:\ndiscrete tokens representing the big picture and continuous tokens representing\nthe residual components that cannot be represented by the discrete tokens. The\ndiscrete component is modeled by a scalable-resolution discrete AR model, while\nthe continuous component is learned with a lightweight residual diffusion\nmodule with only 37M parameters. Compared with the discrete-only VAR tokenizer,\nour hybrid approach improves reconstruction FID from 2.11 to 0.30 on MJHQ-30K,\nleading to a 31% generation FID improvement from 7.85 to 5.38. HART also\noutperforms state-of-the-art diffusion models in both FID and CLIP score, with\n4.5-7.7x higher throughput and 6.9-13.4x lower MACs. Our code is open sourced\nat https://github.com/mit-han-lab/hart.",
      "tldr_zh": "我们引入了Hybrid Autoregressive Transformer (HART)，一个高效的自回归视觉生成模型，能够直接生成1024x1024分辨率的图像，并在图像质量上媲美扩散模型。HART采用hybrid tokenizer，将autoencoder的连续潜在空间分解为离散tokens（代表整体图像）和连续tokens（代表剩余细节），其中离散部分由可扩展分辨率的AR模型处理，连续部分由仅37M参数的轻量级residual diffusion模块学习。与离散-only tokenizer相比，HART将重建FID从2.11改善到0.30，并在生成FID上提升31%。此外，HART在FID和CLIP score上优于最先进扩散模型，同时实现了4.5-7.7倍更高的吞吐量和6.9-13.4倍更低的MACs。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Demo: https://hart.mit.edu. The first two authors contributed equally\n  to this work",
      "pdf_url": "http://arxiv.org/pdf/2410.10812v1",
      "published_date": "2024-10-14 17:59:42 UTC",
      "updated_date": "2024-10-14 17:59:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:12:15.458887"
    },
    {
      "arxiv_id": "2410.10807v2",
      "title": "Hard-Constrained Neural Networks with Universal Approximation Guarantees",
      "title_zh": "具有通用逼近保证的硬约束神经网络",
      "authors": [
        "Youngjae Min",
        "Navid Azizan"
      ],
      "abstract": "Incorporating prior knowledge or specifications of input-output relationships\ninto machine learning models has gained significant attention, as it enhances\ngeneralization from limited data and leads to conforming outputs. However, most\nexisting approaches use soft constraints by penalizing violations through\nregularization, which offers no guarantee of constraint satisfaction--an\nessential requirement in safety-critical applications. On the other hand,\nimposing hard constraints on neural networks may hinder their representational\npower, adversely affecting performance. To address this, we propose HardNet, a\npractical framework for constructing neural networks that inherently satisfy\nhard constraints without sacrificing model capacity. Unlike approaches that\nmodify outputs only at inference time, HardNet enables end-to-end training with\nhard constraint guarantees, leading to improved performance. To the best of our\nknowledge, HardNet is the first method with an efficient forward pass to\nenforce more than one input-dependent inequality constraint. It allows\nunconstrained optimization of the network parameters using standard algorithms\nby appending a differentiable closed-form enforcement layer to the network's\noutput. Furthermore, we show that HardNet retains the universal approximation\ncapabilities of neural networks. We demonstrate the versatility and\neffectiveness of HardNet across various applications: learning with piecewise\nconstraints, learning optimization solvers, optimizing control policies in\nsafety-critical systems, and learning safe decision logic for aircraft systems.",
      "tldr_zh": "这篇论文提出了 HardNet 框架，用于构建满足硬约束的神经网络，解决了传统软约束方法（如通过正则化惩罚）无法保证约束满足的问题，尤其适用于安全关键应用。HardNet 通过在网络输出后添加一个可微的闭式形式执行层，实现参数的无约束优化和端到端训练，同时保持神经网络的通用逼近能力。该框架是第一个在高效前向传递中强制执行多个输入依赖的不等式约束的方法，并在分段约束学习、优化求解器、安全控制策略和航空系统决策等应用中展示了显著的性能提升。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.10807v2",
      "published_date": "2024-10-14 17:59:24 UTC",
      "updated_date": "2025-05-05 17:58:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:12:26.155769"
    },
    {
      "arxiv_id": "2410.10802v1",
      "title": "Boosting Camera Motion Control for Video Diffusion Transformers",
      "title_zh": "针对视频扩散变压器的相机运动控制提升",
      "authors": [
        "Soon Yau Cheong",
        "Duygu Ceylan",
        "Armin Mustafa",
        "Andrew Gilbert",
        "Chun-Hao Paul Huang"
      ],
      "abstract": "Recent advancements in diffusion models have significantly enhanced the\nquality of video generation. However, fine-grained control over camera pose\nremains a challenge. While U-Net-based models have shown promising results for\ncamera control, transformer-based diffusion models (DiT)-the preferred\narchitecture for large-scale video generation - suffer from severe degradation\nin camera motion accuracy. In this paper, we investigate the underlying causes\nof this issue and propose solutions tailored to DiT architectures. Our study\nreveals that camera control performance depends heavily on the choice of\nconditioning methods rather than camera pose representations that is commonly\nbelieved. To address the persistent motion degradation in DiT, we introduce\nCamera Motion Guidance (CMG), based on classifier-free guidance, which boosts\ncamera control by over 400%. Additionally, we present a sparse camera control\npipeline, significantly simplifying the process of specifying camera poses for\nlong videos. Our method universally applies to both U-Net and DiT models,\noffering improved camera control for video generation tasks.",
      "tldr_zh": "该研究调查了基于 Transformer 的扩散模型 (DiT) 在视频生成中相机运动控制的退化问题，发现关键原因在于条件化方法而非相机姿态表示。\n他们提出 Camera Motion Guidance (CMG)，一种基于无分类器引导的技术，将 DiT 的相机控制性能提升超过 400%。\n此外，该方法还包括一个稀疏相机控制管道，简化长视频相机姿态的指定，并普遍适用于 U-Net 和 DiT 模型，从而提高了视频生成的精细控制能力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.10802v1",
      "published_date": "2024-10-14 17:58:07 UTC",
      "updated_date": "2024-10-14 17:58:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:12:36.954521"
    },
    {
      "arxiv_id": "2410.10934v2",
      "title": "Agent-as-a-Judge: Evaluate Agents with Agents",
      "title_zh": "Agent-as-a-J",
      "authors": [
        "Mingchen Zhuge",
        "Changsheng Zhao",
        "Dylan Ashley",
        "Wenyi Wang",
        "Dmitrii Khizbullin",
        "Yunyang Xiong",
        "Zechun Liu",
        "Ernie Chang",
        "Raghuraman Krishnamoorthi",
        "Yuandong Tian",
        "Yangyang Shi",
        "Vikas Chandra",
        "Jürgen Schmidhuber"
      ],
      "abstract": "Contemporary evaluation techniques are inadequate for agentic systems. These\napproaches either focus exclusively on final outcomes -- ignoring the\nstep-by-step nature of agentic systems, or require excessive manual labour. To\naddress this, we introduce the Agent-as-a-Judge framework, wherein agentic\nsystems are used to evaluate agentic systems. This is an organic extension of\nthe LLM-as-a-Judge framework, incorporating agentic features that enable\nintermediate feedback for the entire task-solving process. We apply the\nAgent-as-a-Judge to the task of code generation. To overcome issues with\nexisting benchmarks and provide a proof-of-concept testbed for\nAgent-as-a-Judge, we present DevAI, a new benchmark of 55 realistic automated\nAI development tasks. It includes rich manual annotations, like a total of 365\nhierarchical user requirements. We benchmark three of the popular agentic\nsystems using Agent-as-a-Judge and find it dramatically outperforms\nLLM-as-a-Judge and is as reliable as our human evaluation baseline. Altogether,\nwe believe that Agent-as-a-Judge marks a concrete step forward for modern\nagentic systems -- by providing rich and reliable reward signals necessary for\ndynamic and scalable self-improvement.",
      "tldr_zh": "该研究指出，现有的代理系统评估方法要么只关注最终结果而忽略步骤过程，要么需要大量手动干预，因此提出Agent-as-a-Judge框架，使用代理系统来评估代理系统，提供整个任务解决过程的中间反馈。\n该框架是LLM-as-a-Judge的扩展，并应用于代码生成任务，同时引入DevAI新基准，该基准包含55个现实AI开发任务和365个分层用户需求的手动注释。\n实验结果显示，Agent-as-a-Judge在基准测试中显著优于LLM-as-a-Judge，且其可靠性与人类评估相当，为代理系统的动态和可扩展自我改进提供了丰富的奖励信号。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "The project can be found at\n  https://github.com/metauto-ai/agent-as-a-judge. The dataset is released at\n  https://huggingface.co/DEVAI-benchmark",
      "pdf_url": "http://arxiv.org/pdf/2410.10934v2",
      "published_date": "2024-10-14 17:57:02 UTC",
      "updated_date": "2024-10-16 17:54:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:12:49.558917"
    },
    {
      "arxiv_id": "2410.10786v1",
      "title": "On Information-Theoretic Measures of Predictive Uncertainty",
      "title_zh": "关于预测不确定性的信息论度量",
      "authors": [
        "Kajetan Schweighofer",
        "Lukas Aichberger",
        "Mykyta Ielanskyi",
        "Sepp Hochreiter"
      ],
      "abstract": "Reliable estimation of predictive uncertainty is crucial for machine learning\napplications, particularly in high-stakes scenarios where hedging against risks\nis essential. Despite its significance, a consensus on the correct measurement\nof predictive uncertainty remains elusive. In this work, we return to first\nprinciples to develop a fundamental framework of information-theoretic\npredictive uncertainty measures. Our proposed framework categorizes predictive\nuncertainty measures according to two factors: (I) The predicting model (II)\nThe approximation of the true predictive distribution. Examining all possible\ncombinations of these two factors, we derive a set of predictive uncertainty\nmeasures that includes both known and newly introduced ones. We empirically\nevaluate these measures in typical uncertainty estimation settings, such as\nmisclassification detection, selective prediction, and out-of-distribution\ndetection. The results show that no single measure is universal, but the\neffectiveness depends on the specific setting. Thus, our work provides clarity\nabout the suitability of predictive uncertainty measures by clarifying their\nimplicit assumptions and relationships.",
      "tldr_zh": "该研究探讨了信息理论措施在评估预测不确定性（predictive uncertainty）方面的应用，强调其在高风险机器学习场景中的重要性。作者从基本原理出发，提出一个框架，将预测不确定性措施根据预测模型和真实预测分布的近似（approximation of the true predictive distribution）两个因素进行分类，并推导出包括已知和新型措施在内的完整集合。通过实验评估这些措施在误分类检测（misclassification detection）、选择性预测和分布外检测（out-of-distribution detection）等设置中的表现，结果显示其有效性取决于具体场景，没有单一的通用措施。该工作澄清了这些措施的隐含假设和关系，为选择合适的不确定性评估方法提供了指导。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.10786v1",
      "published_date": "2024-10-14 17:52:18 UTC",
      "updated_date": "2024-10-14 17:52:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:13:01.067246"
    },
    {
      "arxiv_id": "2410.10781v2",
      "title": "When Attention Sink Emerges in Language Models: An Empirical View",
      "title_zh": "翻译失败",
      "authors": [
        "Xiangming Gu",
        "Tianyu Pang",
        "Chao Du",
        "Qian Liu",
        "Fengzhuo Zhang",
        "Cunxiao Du",
        "Ye Wang",
        "Min Lin"
      ],
      "abstract": "Language Models (LMs) assign significant attention to the first token, even\nif it is not semantically important, which is known as attention sink. This\nphenomenon has been widely adopted in applications such as streaming/long\ncontext generation, KV cache optimization, inference acceleration, model\nquantization, and others. Despite its widespread use, a deep understanding of\nattention sink in LMs is still lacking. In this work, we first demonstrate that\nattention sinks exist universally in LMs with various inputs, even in small\nmodels. Furthermore, attention sink is observed to emerge during the LM\npre-training, motivating us to investigate how optimization, data distribution,\nloss function, and model architecture in LM pre-training influence its\nemergence. We highlight that attention sink emerges after effective\noptimization on sufficient training data. The sink position is highly\ncorrelated with the loss function and data distribution. Most importantly, we\nfind that attention sink acts more like key biases, storing extra attention\nscores, which could be non-informative and not contribute to the value\ncomputation. We also observe that this phenomenon (at least partially) stems\nfrom tokens' inner dependence on attention scores as a result of softmax\nnormalization. After relaxing such dependence by replacing softmax attention\nwith other attention operations, such as sigmoid attention without\nnormalization, attention sinks do not emerge in LMs up to 1B parameters. The\ncode is available at https://github.com/sail-sg/Attention-Sink.",
      "tldr_zh": "本文研究了语言模型 (LMs) 中 attention sink 的现象，即模型过度关注第一个 token，即使它不重要。研究通过实证分析发现，attention sink 在各种输入和模型中普遍存在，并在预训练过程中出现，受优化过程、数据分布、损失函数和模型架构的影响。关键发现是，attention sink 更像是 key biases，存储额外注意力分数但不贡献于 value 计算，且部分源于 softmax 归一化。作者证明，通过替换 softmax 为其他注意力操作（如 sigmoid），attention sink 可在高达 1B 参数的模型中避免，为优化 LMs 提供了新见解。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "ICLR 2025 (Spotlight)",
      "pdf_url": "http://arxiv.org/pdf/2410.10781v2",
      "published_date": "2024-10-14 17:50:28 UTC",
      "updated_date": "2025-03-02 14:37:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:13:13.810809"
    },
    {
      "arxiv_id": "2410.10779v1",
      "title": "Focused ReAct: Improving ReAct through Reiterate and Early Stop",
      "title_zh": "翻译失败",
      "authors": [
        "Shuoqiu Li",
        "Han Xu",
        "Haipeng Chen"
      ],
      "abstract": "Large language models (LLMs) have significantly improved their reasoning and\ndecision-making capabilities, as seen in methods like ReAct. However, despite\nits effectiveness in tackling complex tasks, ReAct faces two main challenges:\nlosing focus on the original question and becoming stuck in action loops. To\naddress these issues, we introduce Focused ReAct, an enhanced version of the\nReAct paradigm that incorporates reiteration and early stop mechanisms. These\nimprovements help the model stay focused on the original query and avoid\nrepetitive behaviors. Experimental results show accuracy gains of 18% to 530%\nand a runtime reduction of up to 34% compared to the original ReAct method.",
      "tldr_zh": "大语言模型 (LLMs) 如 ReAct 方法虽提升了推理和决策能力，但面临失去对原问题的焦点和陷入行动循环的挑战。针对这些问题，本文提出 Focused ReAct 框架，通过引入 Reiterate（重述）和 Early Stop（提前停止）机制，帮助模型保持查询焦点并避免重复行为。实验结果显示，与原 ReAct 相比，Focused ReAct 的准确率提升了 18% 到 530%，运行时间减少了高达 34%。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "The Eighth Widening NLP Workshop (WiNLP 2024)",
      "pdf_url": "http://arxiv.org/pdf/2410.10779v1",
      "published_date": "2024-10-14 17:49:54 UTC",
      "updated_date": "2024-10-14 17:49:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:13:25.225912"
    },
    {
      "arxiv_id": "2410.10766v1",
      "title": "Adaptive Diffusion Terrain Generator for Autonomous Uneven Terrain Navigation",
      "title_zh": "自适应扩散地形生成器用于自主不平坦地形导航",
      "authors": [
        "Youwei Yu",
        "Junhong Xu",
        "Lantao Liu"
      ],
      "abstract": "Model-free reinforcement learning has emerged as a powerful method for\ndeveloping robust robot control policies capable of navigating through complex\nand unstructured terrains. The effectiveness of these methods hinges on two\nessential elements: (1) the use of massively parallel physics simulations to\nexpedite policy training, and (2) an environment generator tasked with crafting\nsufficiently challenging yet attainable terrains to facilitate continuous\npolicy improvement. Existing methods of environment generation often rely on\nheuristics constrained by a set of parameters, limiting the diversity and\nrealism. In this work, we introduce the Adaptive Diffusion Terrain Generator\n(ADTG), a novel method that leverages Denoising Diffusion Probabilistic Models\nto dynamically expand existing training environments by adding more diverse and\ncomplex terrains adaptive to the current policy. ADTG guides the diffusion\nmodel's generation process through initial noise optimization, blending\nnoise-corrupted terrains from existing training environments weighted by the\npolicy's performance in each corresponding environment. By manipulating the\nnoise corruption level, ADTG seamlessly transitions between generating similar\nterrains for policy fine-tuning and novel ones to expand training diversity.\nOur experiments show that the policy trained by ADTG outperforms both\nprocedural generated and natural environments, along with popular navigation\nmethods.",
      "tldr_zh": "本研究提出了一种Adaptive Diffusion Terrain Generator (ADTG)，利用Denoising Diffusion Probabilistic Models动态生成多样化和复杂的训练地形，以提升无模型强化学习在自主导航不平坦地形中的策略性能。ADTG通过初始噪声优化和基于策略表现的混合机制，适应性地扩展现有环境，实现从相似地形细调到新颖地形扩展的平滑过渡，从而解决传统启发式方法在多样性与真实性上的局限。实验结果表明，使用ADTG训练的策略在各种地形上优于程序生成环境、自然环境以及流行导航方法。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.10766v1",
      "published_date": "2024-10-14 17:42:37 UTC",
      "updated_date": "2024-10-14 17:42:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:13:37.932246"
    },
    {
      "arxiv_id": "2410.10762v4",
      "title": "AFlow: Automating Agentic Workflow Generation",
      "title_zh": "AFlow：自动化智能体工作流生成",
      "authors": [
        "Jiayi Zhang",
        "Jinyu Xiang",
        "Zhaoyang Yu",
        "Fengwei Teng",
        "Xionghui Chen",
        "Jiaqi Chen",
        "Mingchen Zhuge",
        "Xin Cheng",
        "Sirui Hong",
        "Jinlin Wang",
        "Bingnan Zheng",
        "Bang Liu",
        "Yuyu Luo",
        "Chenglin Wu"
      ],
      "abstract": "Large language models (LLMs) have demonstrated remarkable potential in\nsolving complex tasks across diverse domains, typically by employing agentic\nworkflows that follow detailed instructions and operational sequences. However,\nconstructing these workflows requires significant human effort, limiting\nscalability and generalizability. Recent research has sought to automate the\ngeneration and optimization of these workflows, but existing methods still rely\non initial manual setup and fall short of achieving fully automated and\neffective workflow generation. To address this challenge, we reformulate\nworkflow optimization as a search problem over code-represented workflows,\nwhere LLM-invoking nodes are connected by edges. We introduce AFlow, an\nautomated framework that efficiently explores this space using Monte Carlo Tree\nSearch, iteratively refining workflows through code modification,\ntree-structured experience, and execution feedback. Empirical evaluations\nacross six benchmark datasets demonstrate AFlow's efficacy, yielding a 5.7%\naverage improvement over state-of-the-art baselines. Furthermore, AFlow enables\nsmaller models to outperform GPT-4o on specific tasks at 4.55% of its inference\ncost in dollars. The code is available at\nhttps://github.com/FoundationAgents/AFlow.",
      "tldr_zh": "本研究针对大型语言模型(LLMs)构建代理式工作流(agentic workflows)的手动努力问题，提出AFlow框架，将工作流优化重构为基于代码表示的搜索问题。AFlow利用Monte Carlo Tree Search高效探索工作流空间，通过代码修改、树结构经验和执行反馈进行迭代优化，从而实现自动化生成和优化。实验结果显示，在六个基准数据集上，AFlow比最先进基线平均提升5.7%，并让较小模型以GPT-4o推理成本的4.55%在特定任务上实现超越。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.10762v4",
      "published_date": "2024-10-14 17:40:40 UTC",
      "updated_date": "2025-04-15 02:44:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:13:48.686736"
    },
    {
      "arxiv_id": "2410.10758v4",
      "title": "Arrhythmia Classification Using Graph Neural Networks Based on Correlation Matrix",
      "title_zh": "翻译失败",
      "authors": [
        "Seungwoo Han"
      ],
      "abstract": "With the advancements in graph neural network, there has been increasing\ninterest in applying this network to ECG signal analysis. In this study, we\ngenerated an adjacency matrix using correlation matrix of extracted features\nand applied a graph neural network to classify arrhythmias. The proposed model\nwas compared with existing approaches from the literature. The results\ndemonstrated that precision and recall for all arrhythmia classes exceeded 50%,\nsuggesting that this method can be considered an approach for arrhythmia\nclassification.",
      "tldr_zh": "本研究提出了一种基于关联矩阵（Correlation Matrix）的图神经网络（Graph Neural Networks）方法，用于心律失常（Arrhythmia）分类。  \n具体实现包括从 ECG 信号中提取特征生成邻接矩阵（Adjacency Matrix），然后应用图神经网络进行分类。  \n实验结果显示，该模型在所有心律失常类别上实现了超过 50% 的精确率（Precision）和召回率（Recall），并优于现有方法。  \n这项工作证明了该方法的有效性，为 ECG 信号分析提供了新途径。",
      "categories": [
        "eess.SP",
        "cs.AI"
      ],
      "primary_category": "eess.SP",
      "comment": "Corrected typos",
      "pdf_url": "http://arxiv.org/pdf/2410.10758v4",
      "published_date": "2024-10-14 17:38:37 UTC",
      "updated_date": "2025-02-10 14:40:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:14:01.436505"
    },
    {
      "arxiv_id": "2410.10745v1",
      "title": "FlexGen: Flexible Multi-View Generation from Text and Image Inputs",
      "title_zh": "翻译失败",
      "authors": [
        "Xinli Xu",
        "Wenhang Ge",
        "Jiantao Lin",
        "Jiawei Feng",
        "Lie Xu",
        "HanFeng Zhao",
        "Shunsi Zhang",
        "Ying-Cong Chen"
      ],
      "abstract": "In this work, we introduce FlexGen, a flexible framework designed to generate\ncontrollable and consistent multi-view images, conditioned on a single-view\nimage, or a text prompt, or both. FlexGen tackles the challenges of\ncontrollable multi-view synthesis through additional conditioning on 3D-aware\ntext annotations. We utilize the strong reasoning capabilities of GPT-4V to\ngenerate 3D-aware text annotations. By analyzing four orthogonal views of an\nobject arranged as tiled multi-view images, GPT-4V can produce text annotations\nthat include 3D-aware information with spatial relationship. By integrating the\ncontrol signal with proposed adaptive dual-control module, our model can\ngenerate multi-view images that correspond to the specified text. FlexGen\nsupports multiple controllable capabilities, allowing users to modify text\nprompts to generate reasonable and corresponding unseen parts. Additionally,\nusers can influence attributes such as appearance and material properties,\nincluding metallic and roughness. Extensive experiments demonstrate that our\napproach offers enhanced multiple controllability, marking a significant\nadvancement over existing multi-view diffusion models. This work has\nsubstantial implications for fields requiring rapid and flexible 3D content\ncreation, including game development, animation, and virtual reality. Project\npage: https://xxu068.github.io/flexgen.github.io/.",
      "tldr_zh": "本文提出 FlexGen 框架，用于基于单视图图像、文本提示或两者生成可控且一致的多视图图像。框架利用 GPT-4V 的推理能力生成 3D-aware 文本注释，这些注释包含空间关系信息，并通过自适应双控制模块整合控制信号以确保生成图像的准确性。FlexGen 支持多种可控功能，如修改文本提示生成未见部分，或调整外观和材质属性（例如 metallic 和 roughness）。实验结果表明，该方法在多视图生成任务上比现有扩散模型提升显著，具有重要应用前景，尤其在游戏开发、动画和虚拟现实等领域。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "16 pages, 13 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.10745v1",
      "published_date": "2024-10-14 17:23:13 UTC",
      "updated_date": "2024-10-14 17:23:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:14:13.306795"
    },
    {
      "arxiv_id": "2410.10743v1",
      "title": "NT-LLM: A Novel Node Tokenizer for Integrating Graph Structure into Large Language Models",
      "title_zh": "NT-LLM：一种新颖的节点标记器，用于将图结构集成到大型语言模型中",
      "authors": [
        "Yanbiao Ji",
        "Chang Liu",
        "Xin Chen",
        "Yue Ding",
        "Dan Luo",
        "Mei Li",
        "Wenqing Lin",
        "Hongtao Lu"
      ],
      "abstract": "Graphs are a fundamental data structure for representing relationships in\nreal-world scenarios. With the success of Large Language Models (LLMs) across\nvarious natural language processing (NLP) tasks, there has been growing\ninterest in integrating LLMs for graph learning. However, applying LLMs to\ngraph-related tasks poses significant challenges, as these models are not\ninherently designed to capture the complex structural information present in\ngraphs. Existing approaches address this challenge through two strategies: the\nchain of tasks approach, which uses Graph Neural Networks (GNNs) to encode the\ngraph structure so that LLMs are relieved from understanding spatial positions;\nand Graph-to-Text Conversion, which translates graph structures into semantic\ntext representations that LLMs can process. Despite their progress, these\nmethods often struggle to fully preserve the topological information of graphs\nor require extensive computational resources, limiting their practical\napplicability.\n  In this work, we introduce Node Tokenizer for Large Language Models (NT-LLM),\na novel framework that efficiently encodes graph structures by selecting key\nnodes as anchors and representing each node based on its relative distance to\nthese anchors. This position-anchored encoding effectively captures the graph\ntopology, enabling enhanced reasoning capabilities in LLMs over graph data.\nAdditionally, we implement a task-specific tuning procedure to further improve\nstructural understanding within LLMs. Through extensive empirical evaluations,\nNT-LLM demonstrates significant performance improvements across a variety of\ngraph-related tasks.",
      "tldr_zh": "该论文提出 NT-LLM，一种新型节点标记器框架，用于将图结构整合到 Large Language Models (LLMs) 中，以解决 LLMs 在处理图数据的拓扑信息挑战。NT-LLM 通过选择关键节点作为锚点，并基于每个节点与锚点的相对距离进行编码，从而有效捕获图的拓扑特征，并增强 LLMs 的图数据推理能力。该框架还包括任务特定的微调过程，以进一步提升结构理解。实验结果显示，NT-LLM 在各种图相关任务上实现了显著性能提升，优于现有方法如 Chain of Tasks 和 Graph-to-Text Conversion。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.10743v1",
      "published_date": "2024-10-14 17:21:57 UTC",
      "updated_date": "2024-10-14 17:21:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:14:24.811169"
    },
    {
      "arxiv_id": "2410.10741v3",
      "title": "SensorBench: Benchmarking LLMs in Coding-Based Sensor Processing",
      "title_zh": "翻译失败",
      "authors": [
        "Pengrui Quan",
        "Xiaomin Ouyang",
        "Jeya Vikranth Jeyakumar",
        "Ziqi Wang",
        "Yang Xing",
        "Mani Srivastava"
      ],
      "abstract": "Effective processing, interpretation, and management of sensor data have\nemerged as a critical component of cyber-physical systems. Traditionally,\nprocessing sensor data requires profound theoretical knowledge and proficiency\nin signal-processing tools. However, recent works show that Large Language\nModels (LLMs) have promising capabilities in processing sensory data,\nsuggesting their potential as copilots for developing sensing systems.\n  To explore this potential, we construct a comprehensive benchmark,\nSensorBench, to establish a quantifiable objective. The benchmark incorporates\ndiverse real-world sensor datasets for various tasks. The results show that\nwhile LLMs exhibit considerable proficiency in simpler tasks, they face\ninherent challenges in processing compositional tasks with parameter selections\ncompared to engineering experts. Additionally, we investigate four prompting\nstrategies for sensor processing and show that self-verification can outperform\nall other baselines in 48% of tasks. Our study provides a comprehensive\nbenchmark and prompting analysis for future developments, paving the way toward\nan LLM-based sensor processing copilot.",
      "tldr_zh": "这篇论文构建了SensorBench基准，用于评估Large Language Models (LLMs)在基于编码的传感器处理任务中的性能。研究通过整合多样化的真实传感器数据集，比较了LLMs在简单任务与复杂参数选择任务中的表现，结果显示LLMs在简单任务中表现出色，但远逊于工程专家。论文还调查了四种prompting strategies，其中self-verification策略在48%的任务中优于其他基线。该基准和分析为未来开发LLM-based传感器处理copilot提供了重要基础。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "eess.SP"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.10741v3",
      "published_date": "2024-10-14 17:21:39 UTC",
      "updated_date": "2025-03-28 18:42:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:14:37.576822"
    },
    {
      "arxiv_id": "2410.10738v1",
      "title": "DrivingDojo Dataset: Advancing Interactive and Knowledge-Enriched Driving World Model",
      "title_zh": "DrivingDojo 数据集：推进交互式和知识丰富的驾驶世界模型",
      "authors": [
        "Yuqi Wang",
        "Ke Cheng",
        "Jiawei He",
        "Qitai Wang",
        "Hengchen Dai",
        "Yuntao Chen",
        "Fei Xia",
        "Zhaoxiang Zhang"
      ],
      "abstract": "Driving world models have gained increasing attention due to their ability to\nmodel complex physical dynamics. However, their superb modeling capability is\nyet to be fully unleashed due to the limited video diversity in current driving\ndatasets. We introduce DrivingDojo, the first dataset tailor-made for training\ninteractive world models with complex driving dynamics. Our dataset features\nvideo clips with a complete set of driving maneuvers, diverse multi-agent\ninterplay, and rich open-world driving knowledge, laying a stepping stone for\nfuture world model development. We further define an action instruction\nfollowing (AIF) benchmark for world models and demonstrate the superiority of\nthe proposed dataset for generating action-controlled future predictions.",
      "tldr_zh": "该论文引入了DrivingDojo数据集，这是首个专为训练交互式世界模型而设计的资源，旨在解决当前驾驶数据集视频多样性不足的问题。数据集包含完整的驾驶操作、多样化的多代理互动以及丰富的开放世界驾驶知识，从而提升模型对复杂物理动态的建模能力。论文进一步定义了行动指令遵循(AIF)基准，并通过实验证明，DrivingDojo在生成行动控制的未来预测方面显著优于现有基线模型。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to NeurIPS 2024. Project page:\n  https://drivingdojo.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2410.10738v1",
      "published_date": "2024-10-14 17:19:23 UTC",
      "updated_date": "2024-10-14 17:19:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:14:48.549815"
    },
    {
      "arxiv_id": "2410.10735v2",
      "title": "Embedding Self-Correction as an Inherent Ability in Large Language Models for Enhanced Mathematical Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Kuofeng Gao",
        "Huanqia Cai",
        "Qingyao Shuai",
        "Dihong Gong",
        "Zhifeng Li"
      ],
      "abstract": "Accurate mathematical reasoning with Large Language Models (LLMs) is crucial\nin revolutionizing domains that heavily rely on such reasoning. However, LLMs\noften encounter difficulties in certain aspects of mathematical reasoning,\nleading to flawed reasoning and erroneous results. To mitigate these issues, we\nintroduce a novel mechanism, the Chain of Self-Correction (CoSC), specifically\ndesigned to embed self-correction as an inherent ability in LLMs, enabling them\nto validate and rectify their own results. The CoSC mechanism operates through\na sequence of self-correction stages. In each stage, the LLMs generate a\nprogram to address a given problem, execute this program using program-based\ntools to obtain an output, subsequently verify this output. Based on the\nverification, the LLMs either proceed to the next correction stage or finalize\nthe answer. This iterative self-correction process allows the LLMs to refine\nits reasoning steps and improve the accuracy of its mathematical reasoning. We\nimplement CoSC using a two-phase fine-tuning approach. First, LLMs are trained\nwith a relatively small volume of seeding data generated from GPT-4. Then, we\nenhance CoSC by training with a larger volume of self-generated data, without\nrelying on GPT-4. Experiments show that CoSC significantly boosts performance\non standard mathematical datasets compared to existing open-source LLMs.\nNotably, our CoSC-Code-34B model achieved a 53.5% score on the challenging MATH\ndataset, outperforming models like ChatGPT, GPT-4, and multi-modal LLMs such as\nGPT-4V and Gemini-1.0. Importantly, CoSC operates in a zero-shot manner without\nrequiring demonstrations.",
      "tldr_zh": "本研究提出了一种名为 Chain of Self-Correction (CoSC) 的机制，将自我修正能力嵌入 Large Language Models (LLMs)，以提升其在数学推理中的准确性。CoSC 通过迭代阶段生成程序、执行输出并验证结果，如果必要则继续修正，从而帮助 LLMs 自动优化推理步骤。采用两阶段微调方法，先用 GPT-4 生成少量数据训练，再通过自生成数据增强，最终实验显示，CoSC-Code-34B 模型在 MATH 数据集上达到 53.5% 的成绩，超越 ChatGPT、GPT-4 等模型，且支持零样本操作。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.10735v2",
      "published_date": "2024-10-14 17:16:44 UTC",
      "updated_date": "2025-02-08 11:45:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:15:01.730264"
    },
    {
      "arxiv_id": "2410.10733v8",
      "title": "Deep Compression Autoencoder for Efficient High-Resolution Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Junyu Chen",
        "Han Cai",
        "Junsong Chen",
        "Enze Xie",
        "Shang Yang",
        "Haotian Tang",
        "Muyang Li",
        "Yao Lu",
        "Song Han"
      ],
      "abstract": "We present Deep Compression Autoencoder (DC-AE), a new family of autoencoder\nmodels for accelerating high-resolution diffusion models. Existing autoencoder\nmodels have demonstrated impressive results at a moderate spatial compression\nratio (e.g., 8x), but fail to maintain satisfactory reconstruction accuracy for\nhigh spatial compression ratios (e.g., 64x). We address this challenge by\nintroducing two key techniques: (1) Residual Autoencoding, where we design our\nmodels to learn residuals based on the space-to-channel transformed features to\nalleviate the optimization difficulty of high spatial-compression autoencoders;\n(2) Decoupled High-Resolution Adaptation, an efficient decoupled three-phases\ntraining strategy for mitigating the generalization penalty of high\nspatial-compression autoencoders. With these designs, we improve the\nautoencoder's spatial compression ratio up to 128 while maintaining the\nreconstruction quality. Applying our DC-AE to latent diffusion models, we\nachieve significant speedup without accuracy drop. For example, on ImageNet\n512x512, our DC-AE provides 19.1x inference speedup and 17.9x training speedup\non H100 GPU for UViT-H while achieving a better FID, compared with the widely\nused SD-VAE-f8 autoencoder. Our code is available at\nhttps://github.com/mit-han-lab/efficientvit.",
      "tldr_zh": "本研究提出 Deep Compression Autoencoder (DC-AE)，一种新型 autoencoder 模型，用于加速高分辨率扩散模型，同时解决高空间压缩比（如 64x 以上）下重建准确性不足的问题。\nDC-AE 引入 Residual Autoencoding 和 Decoupled High-Resolution Adaptation 两种关键技术：前者通过学习基于空间到通道转换的残差缓解优化困难，后者采用高效的解耦三阶段训练策略减少泛化惩罚，从而将空间压缩比提高至 128x 并保持重建质量。\n实验结果显示，DC-AE 应用于潜在扩散模型后，在 ImageNet 512x512 上为 UViT-H 提供 19.1x 推理加速和 17.9x 训练加速，同时 FID 指标优于现有模型如 SD-VAE-f8。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "ICLR 2025. The first two authors contributed equally to this work.\n  Fix Typo",
      "pdf_url": "http://arxiv.org/pdf/2410.10733v8",
      "published_date": "2024-10-14 17:15:07 UTC",
      "updated_date": "2025-05-18 21:17:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:15:15.437007"
    },
    {
      "arxiv_id": "2410.10728v1",
      "title": "Towards LLM-guided Efficient and Interpretable Multi-linear Tensor Network Rank Selection",
      "title_zh": "翻译失败",
      "authors": [
        "Giorgos Iacovides",
        "Wuyang Zhou",
        "Danilo Mandic"
      ],
      "abstract": "We propose a novel framework that leverages large language models (LLMs) to\nguide the rank selection in tensor network models for higher-order data\nanalysis. By utilising the intrinsic reasoning capabilities and domain\nknowledge of LLMs, our approach offers enhanced interpretability of the rank\nchoices and can effectively optimise the objective function. This framework\nenables users without specialised domain expertise to utilise tensor network\ndecompositions and understand the underlying rationale within the rank\nselection process. Experimental results validate our method on financial\nhigher-order datasets, demonstrating interpretable reasoning, strong\ngeneralisation to unseen test data, and its potential for self-enhancement over\nsuccessive iterations. This work is placed at the intersection of large\nlanguage models and higher-order data analysis.",
      "tldr_zh": "本研究提出一个新框架，利用LLMs（Large Language Models）指导张量网络（tensor network）模型的秩选择，以提升高阶数据分析的效率和可解释性。该框架借助LLMs的内在推理能力和领域知识，优化目标函数并使非专业用户能够轻松理解秩选择过程和张量网络分解。在金融高阶数据集上的实验结果显示，该方法具有出色的解释性、强泛化能力以及迭代自我提升潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.10728v1",
      "published_date": "2024-10-14 17:09:14 UTC",
      "updated_date": "2024-10-14 17:09:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:15:25.006804"
    },
    {
      "arxiv_id": "2410.10714v2",
      "title": "SeedLM: Compressing LLM Weights into Seeds of Pseudo-Random Generators",
      "title_zh": "翻译失败",
      "authors": [
        "Rasoul Shafipour",
        "David Harrison",
        "Maxwell Horton",
        "Jeffrey Marker",
        "Houman Bedayat",
        "Sachin Mehta",
        "Mohammad Rastegari",
        "Mahyar Najibi",
        "Saman Naderiparizi"
      ],
      "abstract": "Large Language Models (LLMs) have transformed natural language processing,\nbut face significant challenges in widespread deployment due to their high\nruntime cost. In this paper, we introduce SeedLM, a novel post-training\ncompression method that uses seeds of pseudo-random generators to encode and\ncompress model weights. Specifically, for each block of weights, we find a seed\nthat is fed into a Linear Feedback Shift Register (LFSR) during inference to\nefficiently generate a random matrix. This matrix is then linearly combined\nwith compressed coefficients to reconstruct the weight block. SeedLM reduces\nmemory access and leverages idle compute cycles during inference, effectively\nspeeding up memory-bound tasks by trading compute for fewer memory accesses.\nUnlike state-of-the-art compression methods that rely on calibration data, our\napproach is data-free and generalizes well across diverse tasks. Our\nexperiments with Llama 3 70B, which is particularly challenging to compress,\nshow that SeedLM achieves significantly better zero-shot accuracy retention at\n4- and 3-bit than state-of-the-art techniques, while maintaining performance\ncomparable to FP16 baselines. Additionally, FPGA-based tests demonstrate that\n4-bit SeedLM, as model size increases to 70B, approaches a 4x speed-up over an\nFP16 Llama 2/3 baseline.",
      "tldr_zh": "本论文提出SeedLM，一种创新的后训练压缩方法，将大语言模型(LLMs)的权重编码成伪随机生成器的种子，以降低运行时成本。具体来说，SeedLM针对每个权重块使用Linear Feedback Shift Register (LFSR)生成随机矩阵，并通过与压缩系数线性结合来重建权重，从而减少内存访问并利用空闲计算周期加速推理。该方法无需校准数据，在不同任务上具有良好泛化性；实验显示，在Llama 3 70B模型上，SeedLM在4-和3-位量化下比现有技术保留更高零样本准确率，并接近FP16基线的性能，同时FPGA测试表明其速度可达FP16 Llama 2/3基线的4倍。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.10714v2",
      "published_date": "2024-10-14 16:57:23 UTC",
      "updated_date": "2024-10-16 00:11:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:15:37.585632"
    },
    {
      "arxiv_id": "2410.10701v2",
      "title": "Early Diagnosis of Acute Lymphoblastic Leukemia Using YOLOv8 and YOLOv11 Deep Learning Models",
      "title_zh": "翻译失败",
      "authors": [
        "Alaa Awad",
        "Salah A. Aly"
      ],
      "abstract": "Leukemia, a severe form of blood cancer, claims thousands of lives each year.\nThis study focuses on the detection of Acute Lymphoblastic Leukemia (ALL) using\nadvanced image processing and deep learning techniques. By leveraging recent\nadvancements in artificial intelligence, the research evaluates the reliability\nof these methods in practical, real-world scenarios. Specifically, it examines\nthe performance of state-of-the-art YOLO models, including YOLOv8 and YOLOv11,\nto distinguish between malignant and benign white blood cells and accurately\nidentify different stages of ALL, including early stages. Moreover, the models\ndemonstrate the ability to detect hematogones, which are frequently\nmisclassified as ALL. With accuracy rates reaching 98.8%, this study highlights\nthe potential of these algorithms to provide robust and precise leukemia\ndetection across diverse datasets and conditions.",
      "tldr_zh": "本研究利用 YOLOv8 和 YOLOv11 深度学习模型，针对 Acute Lymphoblastic Leukemia (ALL) 进行早期诊断，通过先进的图像处理技术区分恶性和良性白血细胞，并识别 ALL 的不同阶段。模型还能够准确检测 hematogones，避免常见的误分类问题。实验结果显示，准确率高达 98.8%，证明这些算法在多样数据集和实际场景中具有可靠性和强大潜力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "6 pages, 7 figures, 2 tables, JAC-ECC2024",
      "pdf_url": "http://arxiv.org/pdf/2410.10701v2",
      "published_date": "2024-10-14 16:42:07 UTC",
      "updated_date": "2025-01-11 08:02:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:15:49.516828"
    },
    {
      "arxiv_id": "2410.10700v1",
      "title": "Derail Yourself: Multi-turn LLM Jailbreak Attack through Self-discovered Clues",
      "title_zh": "翻译失败",
      "authors": [
        "Qibing Ren",
        "Hao Li",
        "Dongrui Liu",
        "Zhanxu Xie",
        "Xiaoya Lu",
        "Yu Qiao",
        "Lei Sha",
        "Junchi Yan",
        "Lizhuang Ma",
        "Jing Shao"
      ],
      "abstract": "This study exposes the safety vulnerabilities of Large Language Models (LLMs)\nin multi-turn interactions, where malicious users can obscure harmful intents\nacross several queries. We introduce ActorAttack, a novel multi-turn attack\nmethod inspired by actor-network theory, which models a network of semantically\nlinked actors as attack clues to generate diverse and effective attack paths\ntoward harmful targets. ActorAttack addresses two main challenges in multi-turn\nattacks: (1) concealing harmful intents by creating an innocuous conversation\ntopic about the actor, and (2) uncovering diverse attack paths towards the same\nharmful target by leveraging LLMs' knowledge to specify the correlated actors\nas various attack clues. In this way, ActorAttack outperforms existing\nsingle-turn and multi-turn attack methods across advanced aligned LLMs, even\nfor GPT-o1. We will publish a dataset called SafeMTData, which includes\nmulti-turn adversarial prompts and safety alignment data, generated by\nActorAttack. We demonstrate that models safety-tuned using our safety dataset\nare more robust to multi-turn attacks. Code is available at\nhttps://github.com/renqibing/ActorAttack.",
      "tldr_zh": "这篇论文揭示了大型语言模型(LLMs)在多轮交互中的安全漏洞，恶意用户可通过多个查询隐藏有害意图。研究提出ActorAttack，一种基于actor-network theory的多轮攻击方法，通过建模语义相关的actors作为攻击线索，解决隐藏意图和生成多样化攻击路径的挑战。实验结果显示，ActorAttack在包括GPT-o1在内的先进LLMs上优于现有单轮和多轮攻击方法。论文还发布了SafeMTData数据集，并证明使用该数据集进行安全微调的模型对多轮攻击更具鲁棒性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.10700v1",
      "published_date": "2024-10-14 16:41:49 UTC",
      "updated_date": "2024-10-14 16:41:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:16:02.151965"
    },
    {
      "arxiv_id": "2410.10929v7",
      "title": "ASTM :Autonomous Smart Traffic Management System Using Artificial Intelligence CNN and LSTM",
      "title_zh": "ASTM：使用人工智能 CNN 和 LSTM 的自治智能交通管理系统",
      "authors": [
        "Christofel Rio Goenawan"
      ],
      "abstract": "In the modern world, the development of Artificial Intelligence (AI) has\ncontributed to improvements in various areas, including automation, computer\nvision, fraud detection, and more. AI can be leveraged to enhance the\nefficiency of Autonomous Smart Traffic Management (ASTM) systems and reduce\ntraffic congestion rates. This paper presents an Autonomous Smart Traffic\nManagement (STM) system that uses AI to improve traffic flow rates. The system\nemploys the YOLO V5 Convolutional Neural Network to detect vehicles in traffic\nmanagement images. Additionally, it predicts the number of vehicles for the\nnext 12 hours using a Recurrent Neural Network with Long Short-Term Memory\n(RNN-LSTM). The Smart Traffic Management Cycle Length Analysis manages the\ntraffic cycle length based on these vehicle predictions, aided by AI. From the\nresults of the RNN-LSTM model for predicting vehicle numbers over the next 12\nhours, we observe that the model predicts traffic with a Mean Squared Error\n(MSE) of 4.521 vehicles and a Root Mean Squared Error (RMSE) of 2.232 vehicles.\nAfter simulating the STM system in the CARLA simulation environment, we found\nthat the Traffic Management Congestion Flow Rate with ASTM (21 vehicles per\nminute) is 50\\% higher than the rate without STM (around 15 vehicles per\nminute). Additionally, the Traffic Management Vehicle Pass Delay with STM (5\nseconds per vehicle) is 70\\% lower than without STM (around 12 seconds per\nvehicle). These results demonstrate that the STM system using AI can increase\ntraffic flow by 50\\% and reduce vehicle pass delays by 70\\%.",
      "tldr_zh": "这篇论文提出了一种名为 ASTM 的自主智能交通管理系统，利用人工智能（AI）来提升交通流量并减少拥堵。系统采用 YOLO V5 CNN 检测车辆，并使用 RNN-LSTM 模型预测未来 12 小时的车辆数量，以动态调整交通信号灯周期。实验结果显示，RNN-LSTM 的预测误差为 MSE 4.521 和 RMSE 2.232；在 CARLA 模拟环境中，ASTM 系统使交通流量提高 50%（从 15 辆/分钟到 21 辆/分钟），并将车辆通过延误降低 70%（从 12 秒/辆到 5 秒/辆）。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Novel Autonomous Smart Traffic Management System using End-to-End\n  Artificial Intelligence",
      "pdf_url": "http://arxiv.org/pdf/2410.10929v7",
      "published_date": "2024-10-14 16:35:27 UTC",
      "updated_date": "2025-02-10 12:09:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:16:13.707060"
    },
    {
      "arxiv_id": "2410.10687v1",
      "title": "Building a Multivariate Time Series Benchmarking Datasets Inspired by Natural Language Processing (NLP)",
      "title_zh": "翻译失败",
      "authors": [
        "Mohammad Asif Ibna Mustafa",
        "Ferdinand Heinrich"
      ],
      "abstract": "Time series analysis has become increasingly important in various domains,\nand developing effective models relies heavily on high-quality benchmark\ndatasets. Inspired by the success of Natural Language Processing (NLP)\nbenchmark datasets in advancing pre-trained models, we propose a new approach\nto create a comprehensive benchmark dataset for time series analysis. This\npaper explores the methodologies used in NLP benchmark dataset creation and\nadapts them to the unique challenges of time series data. We discuss the\nprocess of curating diverse, representative, and challenging time series\ndatasets, highlighting the importance of domain relevance and data complexity.\nAdditionally, we investigate multi-task learning strategies that leverage the\nbenchmark dataset to enhance the performance of time series models. This\nresearch contributes to the broader goal of advancing the state-of-the-art in\ntime series modeling by adopting successful strategies from the NLP domain.",
      "tldr_zh": "本研究提出一种受 Natural Language Processing (NLP) 启发的方法，用于构建多变量时间序列基准数据集，以提升时间序列分析模型的开发和性能。论文探讨了将 NLP 中数据集创建策略适应到时间序列数据的独特挑战，包括整理多样、代表性和具有挑战性的数据集，并强调领域相关性和数据复杂性。该方法还调查了多任务学习策略，利用基准数据集来增强时间序列模型的表现。总体而言，此研究通过借鉴 NLP 领域的成功经验，旨在推进时间序列建模的现状。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.10687v1",
      "published_date": "2024-10-14 16:25:54 UTC",
      "updated_date": "2024-10-14 16:25:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:16:25.038258"
    },
    {
      "arxiv_id": "2410.12872v1",
      "title": "Beyond Right and Wrong: Mitigating Cold Start in Knowledge Tracing Using Large Language Model and Option Weight",
      "title_zh": "翻译失败",
      "authors": [
        "JongWoo Kim",
        "SeongYeub Chu",
        "Bryan Wong",
        "Mun Yi"
      ],
      "abstract": "Knowledge Tracing (KT) is vital in educational data mining, enabling\npersonalized learning by tracking learners' knowledge states and forecasting\ntheir academic outcomes. This study introduces the LOKT (Large Language Model\nOption-weighted Knowledge Tracing) model to address the cold start problem\nwhere limited historical data available using large language models (LLMs).\nWhile traditional KT models have incorporated option weights, our research\nextends this by integrating these weights into an LLM-based KT framework.\nMoving beyond the binary classification of correct and incorrect responses, we\nemphasize that different types of incorrect answers offer valuable insights\ninto a learner's knowledge state. By converting these responses into text-based\nordinal categories, we enable LLMs to assess learner understanding with greater\nclarity, although our approach focuses on the final knowledge state rather than\nthe progression of learning over time. Using five public datasets, we\ndemonstrate that the LOKT model sustains high predictive accuracy even with\nlimited data, effectively addressing both \"learner cold-start\" and \"system\ncold-start\" scenarios. These findings showcase LOKT's potential to enhance\nLLM-based learning tools and support early-stage personalization.",
      "tldr_zh": "本研究提出 LOKT (Large Language Model Option-weighted Knowledge Tracing) 模型，利用大型语言模型 (LLMs) 和选项权重来缓解知识追踪 (KT) 中的冷启动问题，即在数据有限的情况下提升预测准确率。LOKT 超越传统的二元正确/错误分类，将学习者的不同错误响应转换为文本-based 的序数类别，从而更清晰地评估知识状态，并专注于最终知识状态而非学习过程。实验在五个公共数据集上证明，LOKT 有效处理了学习者冷启动和系统冷启动问题，支持早期个性化学习，并增强了 LLM 基于的教育工具。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "11 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.12872v1",
      "published_date": "2024-10-14 16:25:48 UTC",
      "updated_date": "2024-10-14 16:25:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:16:38.262066"
    },
    {
      "arxiv_id": "2410.10679v1",
      "title": "Combinatorial Multi-armed Bandits: Arm Selection via Group Testing",
      "title_zh": "组合多臂赌博机：通过群体测试的臂选择",
      "authors": [
        "Arpan Mukherjee",
        "Shashanka Ubaru",
        "Keerthiram Murugesan",
        "Karthikeyan Shanmugam",
        "Ali Tajer"
      ],
      "abstract": "This paper considers the problem of combinatorial multi-armed bandits with\nsemi-bandit feedback and a cardinality constraint on the super-arm size.\nExisting algorithms for solving this problem typically involve two key\nsub-routines: (1) a parameter estimation routine that sequentially estimates a\nset of base-arm parameters, and (2) a super-arm selection policy for selecting\na subset of base arms deemed optimal based on these parameters.\nState-of-the-art algorithms assume access to an exact oracle for super-arm\nselection with unbounded computational power. At each instance, this oracle\nevaluates a list of score functions, the number of which grows as low as\nlinearly and as high as exponentially with the number of arms. This can be\nprohibitive in the regime of a large number of arms. This paper introduces a\nnovel realistic alternative to the perfect oracle. This algorithm uses a\ncombination of group-testing for selecting the super arms and quantized\nThompson sampling for parameter estimation. Under a general separability\nassumption on the reward function, the proposed algorithm reduces the\ncomplexity of the super-arm-selection oracle to be logarithmic in the number of\nbase arms while achieving the same regret order as the state-of-the-art\nalgorithms that use exact oracles. This translates to at least an exponential\nreduction in complexity compared to the oracle-based approaches.",
      "tldr_zh": "本论文研究了组合多臂老虎机（Combinatorial Multi-armed Bandits）问题，涉及半带it反馈和对超臂大小的基数约束。现有算法依赖一个精确的超臂选择预言机（oracle），导致计算复杂度随臂数量线性或指数级增长。作者提出了一种新算法，使用群测试（group testing）来选择超臂，并结合量化汤普森采样（quantized Thompson sampling）进行参数估计，在一般的可分性假设（separability assumption）下，将超臂选择的复杂度降低到对基臂数量的对数级，同时保持与最先进算法相同的遗憾（regret）顺序。该方法实现了至少指数级的复杂度减少，为大规模臂数量场景提供了高效解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IT",
        "math.IT",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "26 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.10679v1",
      "published_date": "2024-10-14 16:19:57 UTC",
      "updated_date": "2024-10-14 16:19:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:16:50.183070"
    },
    {
      "arxiv_id": "2410.10674v2",
      "title": "Enhancing Robustness in Deep Reinforcement Learning: A Lyapunov Exponent Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Rory Young",
        "Nicolas Pugeault"
      ],
      "abstract": "Deep reinforcement learning agents achieve state-of-the-art performance in a\nwide range of simulated control tasks. However, successful applications to\nreal-world problems remain limited. One reason for this dichotomy is because\nthe learnt policies are not robust to observation noise or adversarial attacks.\nIn this paper, we investigate the robustness of deep RL policies to a single\nsmall state perturbation in deterministic continuous control tasks. We\ndemonstrate that RL policies can be deterministically chaotic, as small\nperturbations to the system state have a large impact on subsequent state and\nreward trajectories. This unstable non-linear behaviour has two consequences:\nfirst, inaccuracies in sensor readings, or adversarial attacks, can cause\nsignificant performance degradation; second, even policies that show robust\nperformance in terms of rewards may have unpredictable behaviour in practice.\nThese two facets of chaos in RL policies drastically restrict the application\nof deep RL to real-world problems. To address this issue, we propose an\nimprovement on the successful Dreamer V3 architecture, implementing Maximal\nLyapunov Exponent regularisation. This new approach reduces the chaotic state\ndynamics, rendering the learnt policies more resilient to sensor noise or\nadversarial attacks and thereby improving the suitability of deep reinforcement\nlearning for real-world applications.",
      "tldr_zh": "该研究发现，深度强化学习（Deep Reinforcement Learning）策略在确定性连续控制任务中可能存在确定性混沌行为，导致小状态扰动引起重大性能下降，从而限制其在真实世界的应用。论文提出了一种改进的Dreamer V3架构，通过引入Maximal Lyapunov Exponent正则化来减少混沌状态动态，提升策略对观察噪声和对抗性攻击的鲁棒性。实验结果表明，这种方法显著提高了深度强化学习的适用性，使其更适合实际场景。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.10674v2",
      "published_date": "2024-10-14 16:16:43 UTC",
      "updated_date": "2024-11-26 16:10:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:17:01.622067"
    },
    {
      "arxiv_id": "2410.10665v1",
      "title": "Double Jeopardy and Climate Impact in the Use of Large Language Models: Socio-economic Disparities and Reduced Utility for Non-English Speakers",
      "title_zh": "翻译失败",
      "authors": [
        "Aivin V. Solatorio",
        "Gabriel Stefanini Vicente",
        "Holly Krambeck",
        "Olivier Dupriez"
      ],
      "abstract": "Artificial Intelligence (AI), particularly large language models (LLMs),\nholds the potential to bridge language and information gaps, which can benefit\nthe economies of developing nations. However, our analysis of FLORES-200,\nFLORES+, Ethnologue, and World Development Indicators data reveals that these\nbenefits largely favor English speakers. Speakers of languages in low-income\nand lower-middle-income countries face higher costs when using OpenAI's GPT\nmodels via APIs because of how the system processes the input -- tokenization.\nAround 1.5 billion people, speaking languages primarily from\nlower-middle-income countries, could incur costs that are 4 to 6 times higher\nthan those faced by English speakers. Disparities in LLM performance are\nsignificant, and tokenization in models priced per token amplifies inequalities\nin access, cost, and utility. Moreover, using the quality of translation tasks\nas a proxy measure, we show that LLMs perform poorly in low-resource languages,\npresenting a ``double jeopardy\" of higher costs and poor performance for these\nusers. We also discuss the direct impact of fragmentation in tokenizing\nlow-resource languages on climate. This underscores the need for fairer\nalgorithm development to benefit all linguistic groups.",
      "tldr_zh": "该研究揭示了大型语言模型（LLMs）在使用中存在的社会经济不平等问题，特别是非英语使用者面临的“双重 jeopardy”：成本更高和性能更差。通过分析 FLORES-200、FLORES+、Ethnologue 和 World Development Indicators 数据，研究发现，低收入和中低收入国家语言的使用者在使用 OpenAI 的 GPT 模型时，由于 tokenization 处理方式，成本可能比英语使用者高出 4 到 6 倍，且在翻译任务等性能上表现不佳。论文还讨论了 tokenization 对低资源语言的碎片化可能带来的气候影响，并呼吁开发更公平的算法，以惠及所有语言群体。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "econ.GN",
        "q-fin.EC"
      ],
      "primary_category": "cs.CL",
      "comment": "Project GitHub repository at\n  https://github.com/worldbank/double-jeopardy-in-llms",
      "pdf_url": "http://arxiv.org/pdf/2410.10665v1",
      "published_date": "2024-10-14 16:11:04 UTC",
      "updated_date": "2024-10-14 16:11:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:17:13.701902"
    },
    {
      "arxiv_id": "2410.10660v1",
      "title": "Transforming Game Play: A Comparative Study of DCQN and DTQN Architectures in Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "William A. Stigall"
      ],
      "abstract": "In this study, we investigate the performance of Deep Q-Networks utilizing\nConvolutional Neural Networks (CNNs) and Transformer architectures across three\ndifferent Atari games. The advent of DQNs has significantly advanced\nReinforcement Learning, enabling agents to directly learn optimal policies from\nhigh-dimensional sensory inputs from pixel or RAM data. While CNN-based DQNs\nhave been extensively studied and deployed in various domains,\nTransformer-based DQNs are relatively unexplored. Our research aims to fill\nthis gap by benchmarking the performance of both DCQNs and DTQNs across the\nAtari games Asteroids, Space Invaders, and Centipede. We find that in the 35-40\nmillion parameter range, the DCQN outperforms the DTQN in speed across both ViT\nand Projection Architectures. We also find the DCQN outperforms the DTQN in all\ngames except for Centipede.",
      "tldr_zh": "本研究比较了基于 CNN 的 Deep Q-Networks (DCQN) 和基于 Transformer 的 Deep Q-Networks (DTQN) 在强化学习中的性能，焦点是 Atari 游戏 Asteroids、Space Invaders 和 Centipede。研究通过基准测试发现，在 35-40 百万参数范围内，DCQN 在速度上优于 DTQN 的 ViT 和 Projection Architectures 变体，并在所有游戏中表现更好，除了 Centipede。总体而言，此工作填补了 Transformer-based DQNs 的探索空白，并为强化学习架构优化提供了宝贵见解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "KSU C-Day Spring 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.10660v1",
      "published_date": "2024-10-14 16:08:15 UTC",
      "updated_date": "2024-10-14 16:08:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:17:25.558725"
    },
    {
      "arxiv_id": "2410.10650v1",
      "title": "Generative AI and Its Impact on Personalized Intelligent Tutoring Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Subhankar Maity",
        "Aniket Deroy"
      ],
      "abstract": "Generative Artificial Intelligence (AI) is revolutionizing educational\ntechnology by enabling highly personalized and adaptive learning environments\nwithin Intelligent Tutoring Systems (ITS). This report delves into the\nintegration of Generative AI, particularly large language models (LLMs) like\nGPT-4, into ITS to enhance personalized education through dynamic content\ngeneration, real-time feedback, and adaptive learning pathways. We explore key\napplications such as automated question generation, customized feedback\nmechanisms, and interactive dialogue systems that respond to individual learner\nneeds. The report also addresses significant challenges, including ensuring\npedagogical accuracy, mitigating inherent biases in AI models, and maintaining\nlearner engagement. Future directions highlight the potential advancements in\nmultimodal AI integration, emotional intelligence in tutoring systems, and the\nethical implications of AI-driven education. By synthesizing current research\nand practical implementations, this report underscores the transformative\npotential of Generative AI in creating more effective, equitable, and engaging\neducational experiences.",
      "tldr_zh": "这篇报告探讨了生成式 AI，特别是 LLMs 如 GPT-4，在个性化智能辅导系统 (ITS) 中的应用，旨在通过动态内容生成、实时反馈和适应性学习路径提升教育体验。关键贡献包括自动问题生成、自定义反馈机制以及响应个体需求的互动对话系统，这些方法能创建更高效的教育环境。报告同时指出了挑战，如确保教学准确性、缓解 AI 模型的固有偏见以及维持学习者参与度，并展望未来方向，包括多模态 AI 整合、情感智能应用和 AI 驱动教育的伦理影响。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Scientific Report (Under Review)",
      "pdf_url": "http://arxiv.org/pdf/2410.10650v1",
      "published_date": "2024-10-14 16:01:01 UTC",
      "updated_date": "2024-10-14 16:01:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:17:37.594736"
    },
    {
      "arxiv_id": "2410.10646v2",
      "title": "DR-MPC: Deep Residual Model Predictive Control for Real-world Social Navigation",
      "title_zh": "翻译失败",
      "authors": [
        "James R. Han",
        "Hugues Thomas",
        "Jian Zhang",
        "Nicholas Rhinehart",
        "Timothy D. Barfoot"
      ],
      "abstract": "How can a robot safely navigate around people with complex motion patterns?\nDeep Reinforcement Learning (DRL) in simulation holds some promise, but much\nprior work relies on simulators that fail to capture the nuances of real human\nmotion. Thus, we propose Deep Residual Model Predictive Control (DR-MPC) to\nenable robots to quickly and safely perform DRL from real-world crowd\nnavigation data. By blending MPC with model-free DRL, DR-MPC overcomes the DRL\nchallenges of large data requirements and unsafe initial behavior. DR-MPC is\ninitialized with MPC-based path tracking, and gradually learns to interact more\neffectively with humans. To further accelerate learning, a safety component\nestimates out-of-distribution states to guide the robot away from likely\ncollisions. In simulation, we show that DR-MPC substantially outperforms prior\nwork, including traditional DRL and residual DRL models. Hardware experiments\nshow our approach successfully enables a robot to navigate a variety of crowded\nsituations with few errors using less than 4 hours of training data.",
      "tldr_zh": "该论文提出DR-MPC（Deep Residual Model Predictive Control）框架，旨在帮助机器人安全地在真实世界人群中导航，解决Deep Reinforcement Learning (DRL)模拟器无法捕捉人类运动细微差别的挑战。通过将Model Predictive Control (MPC)与无模型DRL结合，DR-MPC从MPC路径跟踪初始化，并逐步学习与人类互动，同时使用安全组件估计分布外状态以避免碰撞。在模拟和硬件实验中，DR-MPC显著优于现有方法，仅需不到4小时的训练数据，即可使机器人成功处理各种拥挤场景，几乎无错误。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "8 pages, 8 figures, accepted to IEEE Robotics and Automation Letters\n  (RA-L) February 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.10646v2",
      "published_date": "2024-10-14 15:56:43 UTC",
      "updated_date": "2025-02-14 02:14:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:17:49.111828"
    },
    {
      "arxiv_id": "2410.10636v2",
      "title": "Adapt-$\\infty$: Scalable Continual Multimodal Instruction Tuning via Dynamic Data Selection",
      "title_zh": "翻译失败",
      "authors": [
        "Adyasha Maharana",
        "Jaehong Yoon",
        "Tianlong Chen",
        "Mohit Bansal"
      ],
      "abstract": "Visual instruction datasets from various distributors are released at\ndifferent times and often contain a significant number of semantically\nredundant text-image pairs, depending on their task compositions (i.e., skills)\nor reference sources. This redundancy greatly limits the efficient deployment\nof continually adaptable multimodal large language models, hindering their\nability to refine existing skills and acquire new competencies over time. We\nreframe the problem of lifelong Instruction Tuning (LiIT) via data selection,\nwhere the model automatically selects beneficial samples to learn from earlier\nand new datasets based on the current state of acquired knowledge in the model.\nWe propose Adapt-$\\infty$, a new multi-way and adaptive data selection approach\nthat dynamically balances sample efficiency and effectiveness during LiIT. We\nfirst construct pseudo-skill clusters by grouping gradient-based sample\nvectors. Next, we select the best-performing data selector for each skill\ncluster from a pool of selector experts, including our newly proposed scoring\nfunction, Image Grounding score. This data selector samples a subset of the\nmost important samples from each skill cluster for training. To prevent the\ncontinuous increase in the size of the dataset pool during LiIT, we introduce a\ncluster-wise permanent data pruning strategy to remove the most semantically\nredundant samples from each cluster, keeping computational requirements\nmanageable. We validate the effectiveness and efficiency of Adapt-$\\infty$ over\na sequence of multimodal instruction tuning datasets with various tasks,\nincluding (Knowledge) VQA, multilingual, grounding, reasoning, language-only,\nand multi-image comprehension. Training with samples selected by Adapt-$\\infty$\nalleviates catastrophic forgetting, especially for rare tasks, and promotes\nforward transfer across the continuum using only a fraction of the original\ndata.",
      "tldr_zh": "这篇论文提出Adapt-∞框架，通过动态数据选择方法实现可扩展的终身指令微调(LiIT)，以解决多模态大语言模型在处理冗余视觉指令数据集时的效率问题。方法包括构建伪技能集群、从一组选择器专家（如新提出的Image Grounding score）中选择最佳数据选择器，并引入集群-wise永久数据修剪策略来移除冗余样本，从而保持计算需求可控。实验验证显示，Adapt-∞在各种任务（如VQA、多语种、grounding和推理）上显著缓解灾难性遗忘，促进前向知识转移，仅需原数据的一小部分。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "First two authors contributed equally. Code:\n  https://github.com/adymaharana/adapt-inf",
      "pdf_url": "http://arxiv.org/pdf/2410.10636v2",
      "published_date": "2024-10-14 15:48:09 UTC",
      "updated_date": "2025-03-24 09:17:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:18:01.500796"
    },
    {
      "arxiv_id": "2410.10927v1",
      "title": "Cultural Heritage 3D Reconstruction with Diffusion Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Pablo Jaramillo",
        "Ivan Sipiran"
      ],
      "abstract": "This article explores the use of recent generative AI algorithms for\nrepairing cultural heritage objects, leveraging a conditional diffusion model\ndesigned to reconstruct 3D point clouds effectively. Our study evaluates the\nmodel's performance across general and cultural heritage-specific settings.\nResults indicate that, with considerations for object variability, the\ndiffusion model can accurately reproduce cultural heritage geometries. Despite\nencountering challenges like data diversity and outlier sensitivity, the model\ndemonstrates significant potential in artifact restoration research. This work\nlays groundwork for advancing restoration methodologies for ancient artifacts\nusing AI technologies.",
      "tldr_zh": "本文探讨使用生成AI算法修复文化遗产物体，采用条件diffusion model来重建3D point clouds，并评估其在一般和文化遗产特定场景下的性能。结果显示，该模型能准确重现文物几何形状，尽管面临数据多样性和outlier sensitivity等挑战。该研究为推进AI技术在古文物修复方法中的应用奠定了基础。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by the workshop VISART for ECCV 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.10927v1",
      "published_date": "2024-10-14 15:43:40 UTC",
      "updated_date": "2024-10-14 15:43:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:18:22.033277"
    },
    {
      "arxiv_id": "2410.10630v1",
      "title": "Thinking LLMs: General Instruction Following with Thought Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Tianhao Wu",
        "Janice Lan",
        "Weizhe Yuan",
        "Jiantao Jiao",
        "Jason Weston",
        "Sainbayar Sukhbaatar"
      ],
      "abstract": "LLMs are typically trained to answer user questions or follow instructions\nsimilarly to how human experts respond. However, in the standard alignment\nframework they lack the basic ability of explicit thinking before answering.\nThinking is important for complex questions that require reasoning and planning\n-- but can be applied to any task. We propose a training method for equipping\nexisting LLMs with such thinking abilities for general instruction following\nwithout use of additional human data. We achieve this by an iterative search\nand optimization procedure that explores the space of possible thought\ngenerations, allowing the model to learn how to think without direct\nsupervision. For each instruction, the thought candidates are scored using a\njudge model to evaluate their responses only, and then optimized via preference\noptimization. We show that this procedure leads to superior performance on\nAlpacaEval and Arena-Hard, and shows gains from thinking on non-reasoning\ncategories such as marketing, health and general knowledge, in addition to more\ntraditional reasoning & problem-solving tasks.",
      "tldr_zh": "本研究指出，大型语言模型（LLMs）在遵循指令时通常缺乏显式思考能力，这对复杂任务的推理和规划造成局限。作者提出一种无需额外人类数据的训练方法，通过迭代搜索和优化过程，让LLMs学会生成思考：即使用判断模型评估响应，然后通过偏好优化改进思考生成。实验结果显示，该方法在AlpacaEval和Arena-Hard基准上表现出色，不仅提升了推理与问题解决任务的性能，还在非推理领域如营销、健康和一般知识上实现了显著改进。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.10630v1",
      "published_date": "2024-10-14 15:38:56 UTC",
      "updated_date": "2024-10-14 15:38:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:18:24.881846"
    },
    {
      "arxiv_id": "2410.10614v1",
      "title": "Modeling News Interactions and Influence for Financial Market Prediction",
      "title_zh": "针对金融市场预测的新闻互动与影响建模",
      "authors": [
        "Mengyu Wang",
        "Shay B. Cohen",
        "Tiejun Ma"
      ],
      "abstract": "The diffusion of financial news into market prices is a complex process,\nmaking it challenging to evaluate the connections between news events and\nmarket movements. This paper introduces FININ (Financial Interconnected News\nInfluence Network), a novel market prediction model that captures not only the\nlinks between news and prices but also the interactions among news items\nthemselves. FININ effectively integrates multi-modal information from both\nmarket data and news articles. We conduct extensive experiments on two\ndatasets, encompassing the S&P 500 and NASDAQ 100 indices over a 15-year period\nand over 2.7 million news articles. The results demonstrate FININ's\neffectiveness, outperforming advanced market prediction models with an\nimprovement of 0.429 and 0.341 in the daily Sharpe ratio for the two markets\nrespectively. Moreover, our results reveal insights into the financial news,\nincluding the delayed market pricing of news, the long memory effect of news,\nand the limitations of financial sentiment analysis in fully extracting\npredictive power from news data.",
      "tldr_zh": "这篇论文提出了 FININ（Financial Interconnected News Influence Network）模型，用于预测金融市场，通过捕捉新闻与价格的关联以及新闻项间的互动，整合市场数据和新闻文章的多模态信息。模型在涵盖 S&P 500 和 NASDAQ 100 指数的两个数据集上进行实验，涉及 15 年数据和超过 270 万新闻文章，结果显示 FININ 比高级基准模型提高了日常 Sharpe ratio 分别为 0.429 和 0.341。研究还揭示了金融新闻的关键洞见，包括新闻的市场定价延迟、新闻的长记忆效应，以及金融情绪分析在提取预测价值方面的局限性。",
      "categories": [
        "cs.CE",
        "cs.AI",
        "cs.CL",
        "q-fin.CP"
      ],
      "primary_category": "cs.CE",
      "comment": "Accepted by EMNLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.10614v1",
      "published_date": "2024-10-14 15:19:49 UTC",
      "updated_date": "2024-10-14 15:19:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:18:37.274118"
    },
    {
      "arxiv_id": "2410.10610v1",
      "title": "Intelligent prospector v2.0: exploration drill planning under epistemic model uncertainty",
      "title_zh": "Intelligent prospector v2.0：认识论模型不确定性下的勘探钻探规划",
      "authors": [
        "John Mern",
        "Anthony Corso",
        "Damian Burch",
        "Kurt House",
        "Jef Caers"
      ],
      "abstract": "Optimal Bayesian decision making on what geoscientific data to acquire\nrequires stating a prior model of uncertainty. Data acquisition is then\noptimized by reducing uncertainty on some property of interest maximally, and\non average. In the context of exploration, very few, sometimes no data at all,\nis available prior to data acquisition planning. The prior model therefore\nneeds to include human interpretations on the nature of spatial variability, or\non analogue data deemed relevant for the area being explored. In mineral\nexploration, for example, humans may rely on conceptual models on the genesis\nof the mineralization to define multiple hypotheses, each representing a\nspecific spatial variability of mineralization. More often than not, after the\ndata is acquired, all of the stated hypotheses may be proven incorrect, i.e.\nfalsified, hence prior hypotheses need to be revised, or additional hypotheses\ngenerated. Planning data acquisition under wrong geological priors is likely to\nbe inefficient since the estimated uncertainty on the target property is\nincorrect, hence uncertainty may not be reduced at all. In this paper, we\ndevelop an intelligent agent based on partially observable Markov decision\nprocesses that plans optimally in the case of multiple geological or\ngeoscientific hypotheses on the nature of spatial variability. Additionally,\nthe artificial intelligence is equipped with a method that allows detecting,\nearly on, whether the human stated hypotheses are incorrect, thereby saving\nconsiderable expense in data acquisition. Our approach is tested on a\nsediment-hosted copper deposit, and the algorithm presented has aided in the\ncharacterization of an ultra high-grade deposit in Zambia in 2023.",
      "tldr_zh": "本研究提出 Intelligent Prospector v2.0，一种基于部分可观察 Markov 决策过程 (POMDP) 的智能代理，用于在认识论模型不确定性下规划地质勘探钻探。方法通过整合多个地质假设来优化数据采集决策，最大限度地减少目标属性不确定性，同时引入机制及早检测假设错误，以避免无效采集并节省成本。在沉积型铜矿床的测试中，该算法显著提高了效率，并已在2023年赞比亚超高品位矿床表征中成功应用。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.10610v1",
      "published_date": "2024-10-14 15:17:29 UTC",
      "updated_date": "2024-10-14 15:17:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:18:49.144007"
    },
    {
      "arxiv_id": "2410.10604v2",
      "title": "Multi-modal Vision Pre-training for Medical Image Analysis",
      "title_zh": "多模态视觉预训练用于医学图像分析",
      "authors": [
        "Shaohao Rui",
        "Lingzhi Chen",
        "Zhenyu Tang",
        "Lilong Wang",
        "Mianxin Liu",
        "Shaoting Zhang",
        "Xiaosong Wang"
      ],
      "abstract": "Self-supervised learning has greatly facilitated medical image analysis by\nsuppressing the training data requirement for real-world applications. Current\nparadigms predominantly rely on self-supervision within uni-modal image data,\nthereby neglecting the inter-modal correlations essential for effective\nlearning of cross-modal image representations. This limitation is particularly\nsignificant for naturally grouped multi-modal data, e.g., multi-parametric MRI\nscans for a patient undergoing various functional imaging protocols in the same\nstudy. To bridge this gap, we conduct a novel multi-modal image pre-training\nwith three proxy tasks to facilitate the learning of cross-modality\nrepresentations and correlations using multi-modal brain MRI scans (over 2.4\nmillion images in 16,022 scans of 3,755 patients), i.e., cross-modal image\nreconstruction, modality-aware contrastive learning, and modality template\ndistillation. To demonstrate the generalizability of our pre-trained model, we\nconduct extensive experiments on various benchmarks with ten downstream tasks.\nThe superior performance of our method is reported in comparison to\nstate-of-the-art pre-training methods, with Dice Score improvement of\n0.28\\%-14.47\\% across six segmentation benchmarks and a consistent accuracy\nboost of 0.65\\%-18.07\\% in four individual image classification tasks.",
      "tldr_zh": "该论文提出了一种多模态视觉预训练方法，用于提升医疗图像分析的性能，解决当前自监督学习（self-supervised learning）忽略跨模态相关性的问题。方法基于超过2.4百万张脑MRI图像，利用三项代理任务——跨模态图像重建（cross-modal image reconstruction）、模态感知对比学习（modality-aware contrastive learning）和模态模板蒸馏（modality template distillation）——来学习跨模态表示和相关性。在十个下游任务的实验中，该方法优于现有预训练技术，在六种分割基准上Dice Score 提高了0.28%-14.47%，并在四种图像分类任务上准确率提升了0.65%-18.07%。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.10604v2",
      "published_date": "2024-10-14 15:12:16 UTC",
      "updated_date": "2025-03-14 14:32:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:19:00.990823"
    },
    {
      "arxiv_id": "2410.10596v2",
      "title": "Neural networks that overcome classic challenges through practice",
      "title_zh": "翻译失败",
      "authors": [
        "Kazuki Irie",
        "Brenden M. Lake"
      ],
      "abstract": "Since the earliest proposals for neural network models of the mind and brain,\ncritics have pointed out key weaknesses in these models compared to human\ncognitive abilities. Here we review recent work that uses metalearning to\novercome several classic challenges by addressing the Problem of Incentive and\nPractice -- that is, providing machines with both incentives to improve\nspecific skills and opportunities to practice those skills. This explicit\noptimization contrasts with more conventional approaches that hope the desired\nbehavior will emerge through optimizing related but different objectives. We\nreview applications of this principle to addressing four classic challenges for\nneural networks: systematic generalization, catastrophic forgetting, few-shot\nlearning and multi-step reasoning. We also discuss the prospects for\nunderstanding aspects of human development through this framework, and whether\nnatural environments provide the right incentives and practice for learning how\nto make challenging generalizations.",
      "tldr_zh": "本论文回顾了通过元学习（metalearning）来解决神经网络模型的经典挑战，特别是通过解决“Incentive and Practice”问题，即为机器提供改进特定技能的激励和实践机会，以区别于传统优化相关目标的方法。研究应用这一原则，成功应对了四个关键挑战：systematic generalization（系统化泛化）、catastrophic forgetting（灾难性遗忘）、few-shot learning（少样本学习）和multi-step reasoning（多步推理）。此外，论文讨论了这一框架在理解人类发展方面的前景，并探讨了自然环境是否能提供合适的激励和实践，以促进挑战性泛化的学习。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "q-bio.NC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.10596v2",
      "published_date": "2024-10-14 15:07:37 UTC",
      "updated_date": "2024-12-15 20:26:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:19:13.336202"
    },
    {
      "arxiv_id": "2410.10926v1",
      "title": "Federated Data-Efficient Instruction Tuning for Large Language Models",
      "title_zh": "联邦数据高效指令调优 for 大型语言模型",
      "authors": [
        "Zhen Qin",
        "Zhaomin Wu",
        "Bingsheng He",
        "Shuiguang Deng"
      ],
      "abstract": "Instruction tuning helps improve pretrained large language models (LLMs) in\nterms of the responsiveness to human instructions, which is benefited from\ndiversified instruction data. Federated learning extends the sources of\ninstruction data by exploiting the diversified client-side data, making it\nincreasingly popular for tuning LLMs. Existing approaches of federated LLM\ntuning typically traverse all local data during local training, bringing\nexcessive computation overhead and posing a risk of overfitting local data.\nThus, a federated data-efficient instruction tuning approach, which consumes\nrelatively little data from the entire dataset, is needed. In response, this\nwork introduces an approach of federated data-efficient instruction tuning for\nLLMs, FedHDS, which utilizes a representative subset of edge-side data,\ncoreset, to tune the LLM. It reduces the redundancy of data samples at both\nintra-client and inter-client levels through a hierarchical data selection\nframework performed by jointly selecting a small number of representative data\nsamples for local training without sharing the raw data. Extensive experiments\nconducted across six scenarios with various LLMs, datasets and data partitions\ndemonstrate that FedHDS significantly reduces the amount of data required for\nfine-tuning while improving the responsiveness of the instruction-tuned LLMs to\nunseen tasks.",
      "tldr_zh": "本研究针对联邦学习（Federated learning）中大型语言模型（LLMs）的指令调优（Instruction tuning）问题，提出了一种数据高效方法FedHDS，以解决现有方法在本地训练时遍历所有数据导致的计算开销和过拟合风险。FedHDS通过分层数据选择框架，从客户端数据中选取代表子集（coreset），在不共享原始数据的情况下减少intra-client和inter-client层面的数据冗余，从而仅使用少量数据进行模型调优。实验在六种场景下验证了FedHDS显著降低了微调所需的数据量，同时提升了LLMs对未见任务的响应性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "11 pages. Ongoing work",
      "pdf_url": "http://arxiv.org/pdf/2410.10926v1",
      "published_date": "2024-10-14 15:05:51 UTC",
      "updated_date": "2024-10-14 15:05:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:19:25.628216"
    },
    {
      "arxiv_id": "2410.10594v2",
      "title": "VisRAG: Vision-based Retrieval-augmented Generation on Multi-modality Documents",
      "title_zh": "翻译失败",
      "authors": [
        "Shi Yu",
        "Chaoyue Tang",
        "Bokai Xu",
        "Junbo Cui",
        "Junhao Ran",
        "Yukun Yan",
        "Zhenghao Liu",
        "Shuo Wang",
        "Xu Han",
        "Zhiyuan Liu",
        "Maosong Sun"
      ],
      "abstract": "Retrieval-augmented generation (RAG) is an effective technique that enables\nlarge language models (LLMs) to utilize external knowledge sources for\ngeneration. However, current RAG systems are solely based on text, rendering it\nimpossible to utilize vision information like layout and images that play\ncrucial roles in real-world multi-modality documents. In this paper, we\nintroduce VisRAG, which tackles this issue by establishing a vision-language\nmodel (VLM)-based RAG pipeline. In this pipeline, instead of first parsing the\ndocument to obtain text, the document is directly embedded using a VLM as an\nimage and then retrieved to enhance the generation of a VLM. Compared to\ntraditional text-based RAG, VisRAG maximizes the retention and utilization of\nthe data information in the original documents, eliminating the information\nloss introduced during the parsing process. We collect both open-source and\nsynthetic data to train the retriever in VisRAG and explore a variety of\ngeneration methods. Experiments demonstrate that VisRAG outperforms traditional\nRAG in both the retrieval and generation stages, achieving a 20--40% end-to-end\nperformance gain over traditional text-based RAG pipeline. Further analysis\nreveals that VisRAG is efficient in utilizing training data and demonstrates\nstrong generalization capability, positioning it as a promising solution for\nRAG on multi-modality documents. Our code and data are available at\nhttps://github.com/openbmb/visrag.",
      "tldr_zh": "本文提出 VisRAG，一种基于视觉的检索增强生成(RAG)框架，旨在处理多模态文档中的视觉信息（如布局和图像），而非仅依赖文本。VisRAG 使用视觉语言模型(VLM)直接嵌入文档作为图像进行检索和生成，从而最大化保留原始数据信息并避免解析过程中的损失。实验结果显示，该框架在检索和生成阶段均优于传统文本-based RAG，提高了20-40%的端到端性能，并展现出高效的训练数据利用和强泛化能力。代码和数据已在GitHub上公开，定位为多模态文档RAG的 promising 解决方案。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.10594v2",
      "published_date": "2024-10-14 15:04:18 UTC",
      "updated_date": "2025-03-02 01:19:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:19:37.516955"
    },
    {
      "arxiv_id": "2410.10588v1",
      "title": "TRESTLE: A Model of Concept Formation in Structured Domains",
      "title_zh": "TRESTLE：结构化领域的概念形成模型",
      "authors": [
        "Christopher J. MacLellan",
        "Erik Harpstead",
        "Vincent Aleven",
        "Kenneth R. Koedinger"
      ],
      "abstract": "The literature on concept formation has demonstrated that humans are capable\nof learning concepts incrementally, with a variety of attribute types, and in\nboth supervised and unsupervised settings. Many models of concept formation\nfocus on a subset of these characteristics, but none account for all of them.\nIn this paper, we present TRESTLE, an incremental account of probabilistic\nconcept formation in structured domains that unifies prior concept learning\nmodels. TRESTLE works by creating a hierarchical categorization tree that can\nbe used to predict missing attribute values and cluster sets of examples into\nconceptually meaningful groups. It updates its knowledge by partially matching\nnovel structures and sorting them into its categorization tree. Finally, the\nsystem supports mixed-data representations, including nominal, numeric,\nrelational, and component attributes. We evaluate TRESTLE's performance on a\nsupervised learning task and an unsupervised clustering task. For both tasks,\nwe compare it to a nonincremental model and to human participants. We find that\nthis new categorization model is competitive with the nonincremental approach\nand more closely approximates human behavior on both tasks. These results serve\nas an initial demonstration of TRESTLE's capabilities and show that, by taking\nkey characteristics of human learning into account, it can better model\nbehavior than approaches that ignore them.",
      "tldr_zh": "本论文提出 TRESTLE，一种在结构化领域进行增量式概率概念形成的模型，该模型统一了现有概念学习框架，支持多种属性类型（如 nominal, numeric, relational 和 component attributes），并适用于监督和非监督设置。TRESTLE 通过构建分层分类树来预测缺失属性值、聚类例子并更新知识，方法包括部分匹配新结构并将其整合到树中。实验结果显示，在监督学习和非监督聚类任务上，TRESTLE 与非增量模型竞争表现相当，并更接近人类行为，证明了其在模拟人类学习方面的优势。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "20 pages, 6 figures, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2410.10588v1",
      "published_date": "2024-10-14 15:00:43 UTC",
      "updated_date": "2024-10-14 15:00:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:19:49.084687"
    },
    {
      "arxiv_id": "2410.12871v1",
      "title": "AI-Driven Autonomous Control of Proton-Boron Fusion Reactors Using Backpropagation Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Michele Laurelli"
      ],
      "abstract": "Proton-boron (p-11B) fusion presents a promising path towards sustainable,\nneutron-free energy generation. However, its implementation is hindered by\nextreme operational conditions, such as plasma temperatures exceeding billions\nof degrees and the complexity of controlling high-energy particles. Traditional\ncontrol systems face significant challenges in managing the highly dynamic and\nnon-linear behavior of the plasma. In this paper, we propose a novel approach\nutilizing backpropagation-based neural networks to autonomously control key\nparameters in a proton-boron fusion reactor. Our method leverages real-time\nfeedback and learning from physical data to adapt to changing plasma\nconditions, offering a potential breakthrough in stable and efficient p-11B\nfusion. Furthermore, we expand on the scalability and generalization of our\napproach to other fusion systems and future AI technologies.",
      "tldr_zh": "该论文探讨了Proton-Boron (p-11B) fusion作为可持续、无中子能源的潜力，但强调了其极端操作条件（如等离子体温度超过数十亿度）和非线性动态控制的挑战。研究提出了一种基于backpropagation neural networks的AI驱动自主控制方法，利用实时反馈和物理数据学习来适应变化的等离子体条件，从而实现更稳定和高效的p-11B融合反应。实验结果表明，该方法可能带来重大突破，并具有可扩展性，可应用于其他融合系统和未来AI技术。",
      "categories": [
        "physics.plasm-ph",
        "cs.AI",
        "cs.LG",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "physics.plasm-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.12871v1",
      "published_date": "2024-10-14 14:58:43 UTC",
      "updated_date": "2024-10-14 14:58:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:20:01.352033"
    },
    {
      "arxiv_id": "2410.10584v1",
      "title": "STACKFEED: Structured Textual Actor-Critic Knowledge Base Editing with FeedBack",
      "title_zh": "翻译失败",
      "authors": [
        "Naman Gupta",
        "Shashank Kirtania",
        "Priyanshu Gupta",
        "Krishna Kariya",
        "Sumit Gulwani",
        "Arun Iyer",
        "Suresh Parthasarathy",
        "Arjun Radhakrishna",
        "Sriram K. Rajamani",
        "Gustavo Soares"
      ],
      "abstract": "Large Language Models (LLMs) often generate incorrect or outdated\ninformation, especially in low-resource settings or when dealing with private\ndata. To address this, Retrieval-Augmented Generation (RAG) uses external\nknowledge bases (KBs), but these can also suffer from inaccuracies. We\nintroduce STACKFEED, a novel Structured Textual Actor-Critic Knowledge base\nediting with FEEDback approach that iteratively refines the KB based on expert\nfeedback using a multi-actor, centralized critic reinforcement learning\nframework. Each document is assigned to an actor, modeled as a ReACT agent,\nwhich performs structured edits based on document-specific targeted\ninstructions from a centralized critic. Experimental results show that\nSTACKFEED significantly improves KB quality and RAG system performance,\nenhancing accuracy by up to 8% over baselines.",
      "tldr_zh": "该论文针对大型语言模型 (LLMs) 生成错误或过时信息的问题，提出 STACKFEED，一种结构化文本 Actor-Critic 知识库编辑方法，利用专家反馈和强化学习框架来迭代优化知识库 (KB)。STACKFEED 采用多代理系统，其中每个文档由一个 ReACT 代理处理，进行基于集中批评家指令的结构化编辑，从而提升编辑的针对性和准确性。实验结果表明，该方法显著提高了 KB 质量和 Retrieval-Augmented Generation (RAG) 系统性能，准确率比基线提升多达 8%。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.10584v1",
      "published_date": "2024-10-14 14:56:01 UTC",
      "updated_date": "2024-10-14 14:56:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:20:13.557697"
    },
    {
      "arxiv_id": "2410.10580v1",
      "title": "Multilingual Controlled Generation And Gold-Standard-Agnostic Evaluation of Code-Mixed Sentences",
      "title_zh": "翻译失败",
      "authors": [
        "Ayushman Gupta",
        "Akhil Bhogal",
        "Kripabandhu Ghosh"
      ],
      "abstract": "Code-mixing, the practice of alternating between two or more languages in an\nutterance, is a common phenomenon in multilingual communities. Due to the\ncolloquial nature of code-mixing, there is no singular correct way to translate\nan English sentence into a code-mixed sentence. For this reason, standard\nn-gram-based MT evaluation metrics such as the BLEU score are not appropriate\nfor code-mixed evaluation. To demonstrate this, we propose a novel method for\ncode-mixed text generation: Controlled Generation, which parameterizes the\ncode-mixing degree (CMD) and enables the generation of multiple semantically\nequivalent code-mixed sentences from a given English sentence. We introduce a\nrobust new evaluation metric: GAME: A Gold-Standard Agnostic Measure for\nEvaluation of Code-Mixed Sentences. GAME is both language-agnostic and\ngold-standard-agnostic, i.e. unlike other metrics, GAME does not require\ngold-standard code-mixed sentences for evaluation, thus eliminating the need\nfor human annotators in the code-mixed evaluation process. When used to\nevaluate semantically equivalent code-mixed sentences, we find that GAME scores\nhave a lower standard deviation than BLEU scores. Further, we create and\nrelease a dataset containing gold-standard code-mixed sentences across 4\nlanguage pairs: English-{Hindi, Bengali, French, Spanish} to encourage more\ncomputational research on code-mixing.",
      "tldr_zh": "该研究探讨了代码-mixing（在同一话语中交替使用多种语言）的现象，强调了传统评估指标如 BLEU 在代码-mixed 文本生成中的局限性，因为代码-mixing 没有单一正确形式。论文提出 Controlled Generation 方法，通过参数化代码-mixing 度（CMD）从英文句子生成多个语义等价的代码-mixed 句子。作者引入了新的评估指标 GAME（A Gold-Standard-Agnostic Measure for Evaluation of Code-Mixed Sentences），该指标语言无关且不依赖金标准句子，从而避免了人工标注的需求。实验结果显示，GAME 在评估语义等价句子时比 BLEU 更稳定（标准差更低），并发布了包含 English-{Hindi, Bengali, French, Spanish} 四语言对的数据集，以推动代码-mixing 研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Manuscript submitted to COLING 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.10580v1",
      "published_date": "2024-10-14 14:54:05 UTC",
      "updated_date": "2024-10-14 14:54:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:20:25.980829"
    },
    {
      "arxiv_id": "2410.10578v9",
      "title": "Burning RED: Unlocking Subtask-Driven Reinforcement Learning and Risk-Awareness in Average-Reward Markov Decision Processes",
      "title_zh": "翻译失败",
      "authors": [
        "Juan Sebastian Rojas",
        "Chi-Guhn Lee"
      ],
      "abstract": "Average-reward Markov decision processes (MDPs) provide a foundational\nframework for sequential decision-making under uncertainty. However,\naverage-reward MDPs have remained largely unexplored in reinforcement learning\n(RL) settings, with the majority of RL-based efforts having been allocated to\ndiscounted MDPs. In this work, we study a unique structural property of\naverage-reward MDPs and utilize it to introduce Reward-Extended Differential\n(or RED) reinforcement learning: a novel RL framework that can be used to\neffectively and efficiently solve various learning objectives, or subtasks,\nsimultaneously in the average-reward setting. We introduce a family of RED\nlearning algorithms for prediction and control, including proven-convergent\nalgorithms for the tabular case. We then showcase the power of these algorithms\nby demonstrating how they can be used to learn a policy that optimizes, for the\nfirst time, the well-known conditional value-at-risk (CVaR) risk measure in a\nfully-online manner, without the use of an explicit bi-level optimization\nscheme or an augmented state-space.",
      "tldr_zh": "这篇论文探讨了平均奖励Markov决策过程（average-reward MDPs）在强化学习（RL）中的应用，强调其在不确定性决策中的基础作用，并指出其相对于折扣MDPs的未充分探索。论文引入了Reward-Extended Differential (RED)框架，利用average-reward MDPs的独特结构特性，实现同时高效解决多个学习目标（subtasks）。此外，他们开发了RED学习算法，包括针对表格情况的收敛算法，并展示了这些算法首次在fully-online方式下优化条件价值风险（CVaR）风险度量，而无需双层优化（bi-level optimization）或扩展状态空间。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.10578v9",
      "published_date": "2024-10-14 14:52:23 UTC",
      "updated_date": "2025-02-24 19:53:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:20:37.695830"
    },
    {
      "arxiv_id": "2410.10567v1",
      "title": "When Precedents Clash",
      "title_zh": "翻译失败",
      "authors": [
        "Cecilia Di Florio",
        "Huimin Dong",
        "Antonino Rotolo"
      ],
      "abstract": "Consistency of case bases is a way to avoid the problem of retrieving\nconflicting constraining precedents for new cases to be decided. However, in\nlegal practice the consistency requirements for case bases may not be\nsatisfied. As pointed out in (Broughton 2019), a model of precedential\nconstraint should take into account the hierarchical structure of the specific\nlegal system under consideration and the temporal dimension of cases. This\narticle continues the research initiated in (Liu et al. 2022; Di Florio et al.\n2023), which established a connection between Boolean classifiers and legal\ncase-based reasoning. On this basis, we enrich the classifier models with an\norganisational structure that takes into account both the hierarchy of courts\nand which courts issue decisions that are binding/constraining on subsequent\ncases. We focus on common law systems. We also introduce a temporal relation\nbetween cases. Within this enriched framework, we can formalise the notions of\noverruled cases and cases decided per incuriam: such cases are not to be\nconsidered binding on later cases. Finally, we show under which condition\nprinciples based on the hierarchical structure and on the temporal dimension\ncan provide an unambiguous decision-making process for new cases in the\npresence of conflicting binding precedents.",
      "tldr_zh": "本研究探讨了法律案例库中冲突先例的问题，旨在通过增强案例一致性来避免在新案例决策时检索到矛盾的约束先例。作者扩展了布尔分类器（Boolean classifiers）模型，融入法院层级结构和时间维度，针对普通法系统（common law systems）定义了先例约束关系。论文形式化了overruled cases（被推翻的案例）和cases decided per incuriam（疏忽判决案例）的概念，确保这些案例不对后续案例产生约束。最后，通过层级结构和时间原则，研究证明在存在冲突绑定先例时，可以实现明确的决策过程。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "13 pages. Extended version with proofs of a paper accepted at JURIX\n  2024",
      "pdf_url": "http://arxiv.org/pdf/2410.10567v1",
      "published_date": "2024-10-14 14:45:47 UTC",
      "updated_date": "2024-10-14 14:45:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:20:48.512030"
    },
    {
      "arxiv_id": "2410.10554v1",
      "title": "ROSAR: An Adversarial Re-Training Framework for Robust Side-Scan Sonar Object Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Martin Aubard",
        "László Antal",
        "Ana Madureira",
        "Luis F. Teixeira",
        "Erika Ábrahám"
      ],
      "abstract": "This paper introduces ROSAR, a novel framework enhancing the robustness of\ndeep learning object detection models tailored for side-scan sonar (SSS)\nimages, generated by autonomous underwater vehicles using sonar sensors. By\nextending our prior work on knowledge distillation (KD), this framework\nintegrates KD with adversarial retraining to address the dual challenges of\nmodel efficiency and robustness against SSS noises. We introduce three novel,\npublicly available SSS datasets, capturing different sonar setups and noise\nconditions. We propose and formalize two SSS safety properties and utilize them\nto generate adversarial datasets for retraining. Through a comparative analysis\nof projected gradient descent (PGD) and patch-based adversarial attacks, ROSAR\ndemonstrates significant improvements in model robustness and detection\naccuracy under SSS-specific conditions, enhancing the model's robustness by up\nto 1.85%. ROSAR is available at\nhttps://github.com/remaro-network/ROSAR-framework.",
      "tldr_zh": "这篇论文介绍了 ROSAR 框架，一种针对 side-scan sonar (SSS) 图像的对抗重训练方法，用于提升深度学习物体检测模型的鲁棒性。框架将 knowledge distillation (KD) 与对抗重训练相结合，解决模型效率和对 SSS 噪声的抗扰动问题，并发布了三个新的公开 SSS 数据集以及两个形式化的 SSS 安全属性，用于生成对抗数据集。实验通过比较 projected gradient descent (PGD) 和 patch-based 攻击，证明 ROSAR 在 SSS 特定条件下显著提高了检测准确性和鲁棒性，提升鲁棒性高达 1.85%。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.10554v1",
      "published_date": "2024-10-14 14:33:14 UTC",
      "updated_date": "2024-10-14 14:33:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:21:02.079833"
    },
    {
      "arxiv_id": "2410.10553v1",
      "title": "SLaNC: Static LayerNorm Calibration",
      "title_zh": "SLaNC：静态层归一化校准",
      "authors": [
        "Mahsa Salmani",
        "Nikita Trukhanov",
        "Ilya Soloveychik"
      ],
      "abstract": "The ever increasing sizes of Large Language Models (LLMs) beyond hundreds of\nbillions of parameters have generated enormous pressure on the manufacturers of\ndedicated hardware accelerators and made the innovative design of the latter\none of the most rapidly expanding fields of the AI industry. Various approaches\nhave been explored to enable efficient and accurate processing of LLMs on the\navailable accelerators given their computational and storage limitations. Among\nthese, various quantization techniques have become the main focus of the\ncommunity as a means of reducing the compute, communication and storage\nrequirements. Quantization to lower precision formats naturally poses a number\nof challenges caused by the limited range of the available value\nrepresentations. When it comes to processing the popular Transformer models on\nhardware, one of the main issues becomes calculation of the LayerNorm simply\nbecause accumulation of the variance requires a much wider dynamic range than\nthe hardware enables. In this article, we address this matter and propose a\ncomputationally-efficient scaling technique that can be easily applied to\nTransformer models during inference. Our method suggests a straightforward way\nof scaling the LayerNorm inputs based on the static weights of the immediately\npreceding linear layers. The scaling factors are computed offline, based solely\non the linear layer weights, hence no latency or computational overhead is\nadded during inference. Most importantly, our technique ensures that no\nnumerical issues such as overflow or underflow could happen during the compute.\nThis approach offers smooth, accurate and resource-effective inference across a\nwide range of hardware architectures. The article provides theoretical\njustification as well as supporting numerical simulations.",
      "tldr_zh": "这篇论文提出SLaNC（Static LayerNorm Calibration）方法，针对大型语言模型(LLMs)量化过程中LayerNorm计算的动态范围问题，提供一种高效的缩放技术。该方法基于Transformer模型中紧邻线性层的静态权重，离线计算缩放因子来调整LayerNorm输入，从而在推理阶段避免任何计算开销和数值问题如溢出或下溢。实验结果显示，该技术在各种硬件架构上实现了平滑、准确的资源优化推理，并通过理论证明和数值模拟得到支持。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages, 3 figures, NeurIPS 2024 MLNCP Workshop",
      "pdf_url": "http://arxiv.org/pdf/2410.10553v1",
      "published_date": "2024-10-14 14:32:55 UTC",
      "updated_date": "2024-10-14 14:32:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:21:13.593467"
    },
    {
      "arxiv_id": "2410.10547v1",
      "title": "Hybrid Transformer for Early Alzheimer's Detection: Integration of Handwriting-Based 2D Images and 1D Signal Features",
      "title_zh": "翻译失败",
      "authors": [
        "Changqing Gong",
        "Huafeng Qin",
        "Mounîm A. El-Yacoubi"
      ],
      "abstract": "Alzheimer's Disease (AD) is a prevalent neurodegenerative condition where\nearly detection is vital. Handwriting, often affected early in AD, offers a\nnon-invasive and cost-effective way to capture subtle motor changes.\nState-of-the-art research on handwriting, mostly online, based AD detection has\npredominantly relied on manually extracted features, fed as input to shallow\nmachine learning models. Some recent works have proposed deep learning\n(DL)-based models, either 1D-CNN or 2D-CNN architectures, with performance\ncomparing favorably to handcrafted schemes. These approaches, however, overlook\nthe intrinsic relationship between the 2D spatial patterns of handwriting\nstrokes and their 1D dynamic characteristics, thus limiting their capacity to\ncapture the multimodal nature of handwriting data. Moreover, the application of\nTransformer models remains basically unexplored. To address these limitations,\nwe propose a novel approach for AD detection, consisting of a learnable\nmultimodal hybrid attention model that integrates simultaneously 2D handwriting\nimages with 1D dynamic handwriting signals. Our model leverages a gated\nmechanism to combine similarity and difference attention, blending the two\nmodalities and learning robust features by incorporating information at\ndifferent scales. Our model achieved state-of-the-art performance on the DARWIN\ndataset, with an F1-score of 90.32\\% and accuracy of 90.91\\% in Task 8 ('L'\nwriting), surpassing the previous best by 4.61% and 6.06% respectively.",
      "tldr_zh": "本文提出了一种Hybrid Transformer模型，用于早起Alzheimer's Disease (AD) 检测，通过整合手写基于的2D图像和1D动态信号特征，解决现有方法忽略多模态关系的局限性。该模型采用门控机制结合相似性和差异注意力，在不同尺度融合两种模态数据，学习更鲁棒的特征。在DARWIN数据集的Task 8 ('L' writing)上，模型实现了90.32%的F1-score和90.91%的准确率，分别比之前最佳模型提高了4.61%和6.06%。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.10547v1",
      "published_date": "2024-10-14 14:26:52 UTC",
      "updated_date": "2024-10-14 14:26:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:21:28.896909"
    },
    {
      "arxiv_id": "2410.10924v1",
      "title": "A Benchmark Suite for Evaluating Neural Mutual Information Estimators on Unstructured Datasets",
      "title_zh": "一个用于评估神经互信息估计器在非结构化数据集上的基准套件",
      "authors": [
        "Kyungeun Lee",
        "Wonjong Rhee"
      ],
      "abstract": "Mutual Information (MI) is a fundamental metric for quantifying dependency\nbetween two random variables. When we can access only the samples, but not the\nunderlying distribution functions, we can evaluate MI using sample-based\nestimators. Assessment of such MI estimators, however, has almost always relied\non analytical datasets including Gaussian multivariates. Such datasets allow\nanalytical calculations of the true MI values, but they are limited in that\nthey do not reflect the complexities of real-world datasets. This study\nintroduces a comprehensive benchmark suite for evaluating neural MI estimators\non unstructured datasets, specifically focusing on images and texts. By\nleveraging same-class sampling for positive pairing and introducing a binary\nsymmetric channel trick, we show that we can accurately manipulate true MI\nvalues of real-world datasets. Using the benchmark suite, we investigate seven\nchallenging scenarios, shedding light on the reliability of neural MI\nestimators for unstructured datasets.",
      "tldr_zh": "这篇论文引入了一个全面基准套件，用于评估神经 MI 估计器在非结构化数据集（如图像和文本）上的性能，解决了传统依赖分析数据集（如高斯多变量）的局限性。研究团队通过采用同类采样进行正对以及二元对称通道技巧，实现了对真实世界数据集 MI 值的准确操纵。利用该基准套件，他们调查了七个挑战性场景，揭示了神经 MI 估计器在处理复杂非结构化数据时的可靠性和潜在问题。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.10924v1",
      "published_date": "2024-10-14 14:22:38 UTC",
      "updated_date": "2024-10-14 14:22:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:21:39.558694"
    },
    {
      "arxiv_id": "2410.10542v1",
      "title": "Rethinking Legal Judgement Prediction in a Realistic Scenario in the Era of Large Language Models",
      "title_zh": "在大型语言模型时代重新审视现实场景中的法律判决预测",
      "authors": [
        "Shubham Kumar Nigam",
        "Aniket Deroy",
        "Subhankar Maity",
        "Arnab Bhattacharya"
      ],
      "abstract": "This study investigates judgment prediction in a realistic scenario within\nthe context of Indian judgments, utilizing a range of transformer-based models,\nincluding InLegalBERT, BERT, and XLNet, alongside LLMs such as Llama-2 and\nGPT-3.5 Turbo. In this realistic scenario, we simulate how judgments are\npredicted at the point when a case is presented for a decision in court, using\nonly the information available at that time, such as the facts of the case,\nstatutes, precedents, and arguments. This approach mimics real-world\nconditions, where decisions must be made without the benefit of hindsight,\nunlike retrospective analyses often found in previous studies. For transformer\nmodels, we experiment with hierarchical transformers and the summarization of\njudgment facts to optimize input for these models. Our experiments with LLMs\nreveal that GPT-3.5 Turbo excels in realistic scenarios, demonstrating robust\nperformance in judgment prediction. Furthermore, incorporating additional legal\ninformation, such as statutes and precedents, significantly improves the\noutcome of the prediction task. The LLMs also provide explanations for their\npredictions. To evaluate the quality of these predictions and explanations, we\nintroduce two human evaluation metrics: Clarity and Linking. Our findings from\nboth automatic and human evaluations indicate that, despite advancements in\nLLMs, they are yet to achieve expert-level performance in judgment prediction\nand explanation tasks.",
      "tldr_zh": "本研究重新审视了在大型语言模型(LLMs)时代下现实场景中的法律判决预测，聚焦于印度判决，使用transformer-based模型（如InLegalBERT、BERT和XLNet）以及LLMs（如Llama-2和GPT-3.5 Turbo），并模拟判决时仅基于可用信息（如案件事实、法规、先例和论点）的预测过程。实验涉及分层transformer和判决事实总结来优化模型输入，结果显示GPT-3.5 Turbo在现实场景中表现出色，且加入额外法律信息能显著提升预测准确性，同时LLMs能提供解释。论文引入了Clarity和Linking的人工评估指标，通过自动和人工评估发现，尽管LLMs已取得进展，但尚未达到专家级别的性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted on NLLP at EMNLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.10542v1",
      "published_date": "2024-10-14 14:22:12 UTC",
      "updated_date": "2024-10-14 14:22:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:21:53.228061"
    },
    {
      "arxiv_id": "2410.10537v3",
      "title": "Reproducible Machine Learning-based Voice Pathology Detection: Introducing the Pitch Difference Feature",
      "title_zh": "翻译失败",
      "authors": [
        "Jan Vrba",
        "Jakub Steinbach",
        "Tomáš Jirsa",
        "Laura Verde",
        "Roberta De Fazio",
        "Yuwen Zeng",
        "Kei Ichiji",
        "Lukáš Hájek",
        "Zuzana Sedláková",
        "Zuzana Urbániová",
        "Martin Chovanec",
        "Jan Mareš",
        "Noriyasu Homma"
      ],
      "abstract": "Purpose: We introduce a novel methodology for voice pathology detection using\nthe publicly available Saarbr\\\"ucken Voice Database (SVD) and a robust feature\nset combining commonly used acoustic handcrafted features with two novel ones:\npitch difference (relative variation in fundamental frequency) and NaN feature\n(failed fundamental frequency estimation).\n  Methods: We evaluate six machine learning (ML) algorithms -- support vector\nmachine, k-nearest neighbors, naive Bayes, decision tree, random forest, and\nAdaBoost -- using grid search for feasible hyperparameters and 20480 different\nfeature subsets. Top 1000 classification models -- feature subset combinations\nfor each ML algorithm are validated with repeated stratified cross-validation.\nTo address class imbalance, we apply K-Means SMOTE to augment the training\ndata.\n  Results: Our approach achieves 85.61%, 84.69% and 85.22% unweighted average\nrecall (UAR) for females, males and combined results respectively. We\nintentionally omit accuracy as it is a highly biased metric for imbalanced\ndata.\n  Conclusion: Our study demonstrates that by following the proposed methodology\nand feature engineering, there is a potential in detection of various voice\npathologies using ML models applied to the simplest vocal task, a sustained\nutterance of the vowel /a:/. To enable easier use of our methodology and to\nsupport our claims, we provide a publicly available GitHub repository with DOI\n10.5281/zenodo.13771573. Finally, we provide a REFORMS checklist to enhance\nreadability, reproducibility and justification of our approach",
      "tldr_zh": "本文提出了一种可重复的机器学习 (ML) 基于语音病理检测方法，引入 pitch difference（基频相对变化）和 NaN feature（基频估计失败）作为新特征，与常见声学特征结合使用 Saarbrücken Voice Database (SVD)。方法评估六种 ML 算法（如 support vector machine 和 random forest），通过网格搜索优化超参数、测试 20480 种特征子集，并采用 K-Means SMOTE 处理类别不平衡问题，最终使用重复分层交叉验证验证模型。结果显示，检测性能达到 85.61%、84.69% 和 85.22% 的 unweighted average recall (UAR) 对于女性、男性及组合数据，并提供公开 GitHub 仓库和 REFORMS 检查表，以提升研究的可读性和可重复性。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Code repository:\n  https://github.com/aailab-uct/Automated-Robust-and-Reproducible-Voice-Pathology-Detection,\n  Supplementary materials: https://doi.org/10.5281/zenodo.14793017",
      "pdf_url": "http://arxiv.org/pdf/2410.10537v3",
      "published_date": "2024-10-14 14:17:52 UTC",
      "updated_date": "2025-03-14 13:47:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:22:04.224914"
    },
    {
      "arxiv_id": "2410.10524v2",
      "title": "Get Rid of Isolation: A Continuous Multi-task Spatio-Temporal Learning Framework",
      "title_zh": "摆脱隔离：一个连续多任务时空学习框架",
      "authors": [
        "Zhongchao Yi",
        "Zhengyang Zhou",
        "Qihe Huang",
        "Yanjiang Chen",
        "Liheng Yu",
        "Xu Wang",
        "Yang Wang"
      ],
      "abstract": "Spatiotemporal learning has become a pivotal technique to enable urban\nintelligence. Traditional spatiotemporal models mostly focus on a specific task\nby assuming a same distribution between training and testing sets. However,\ngiven that urban systems are usually dynamic, multi-sourced with imbalanced\ndata distributions, current specific task-specific models fail to generalize to\nnew urban conditions and adapt to new domains without explicitly modeling\ninterdependencies across various dimensions and types of urban data. To this\nend, we argue that there is an essential to propose a Continuous Multi-task\nSpatio-Temporal learning framework (CMuST) to empower collective urban\nintelligence, which reforms the urban spatiotemporal learning from\nsingle-domain to cooperatively multi-dimensional and multi-task learning.\nSpecifically, CMuST proposes a new multi-dimensional spatiotemporal interaction\nnetwork (MSTI) to allow cross-interactions between context and main\nobservations as well as self-interactions within spatial and temporal aspects\nto be exposed, which is also the core for capturing task-level commonality and\npersonalization. To ensure continuous task learning, a novel Rolling Adaptation\ntraining scheme (RoAda) is devised, which not only preserves task uniqueness by\nconstructing data summarization-driven task prompts, but also harnesses\ncorrelated patterns among tasks by iterative model behavior modeling. We\nfurther establish a benchmark of three cities for multi-task spatiotemporal\nlearning, and empirically demonstrate the superiority of CMuST via extensive\nevaluations on these datasets. The impressive improvements on both few-shot\nstreaming data and new domain tasks against existing SOAT methods are achieved.\nCode is available at https://github.com/DILab-USTCSZ/CMuST.",
      "tldr_zh": "这篇论文针对传统时空学习模型的局限性，提出了一种连续多任务时空学习框架（CMuST），旨在通过多维和多任务合作学习来提升城市智能系统的泛化能力。CMuST的核心组件包括多维时空互动网络（MSTI），用于实现上下文与主要观察之间的交叉互动，以及空间和时间方面的自互动，以捕捉任务级别的共性和个性化；此外，还设计了滚动适应训练方案（RoAda），通过数据总结驱动的任务提示和迭代模型行为建模来保留任务独特性并利用任务间相关模式。实验在三个城市的基准数据集上验证了CMuST的优越性，在少样本流数据和新领域任务上比现有最先进方法取得了显著改进。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.10524v2",
      "published_date": "2024-10-14 14:04:36 UTC",
      "updated_date": "2025-01-15 09:17:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:22:16.460863"
    },
    {
      "arxiv_id": "2410.11896v1",
      "title": "Study on the Helpfulness of Explainable Artificial Intelligence",
      "title_zh": "翻译失败",
      "authors": [
        "Tobias Labarta",
        "Elizaveta Kulicheva",
        "Ronja Froelian",
        "Christian Geißler",
        "Xenia Melman",
        "Julian von Klitzing"
      ],
      "abstract": "Explainable Artificial Intelligence (XAI) is essential for building advanced\nmachine learning-powered applications, especially in critical domains such as\nmedical diagnostics or autonomous driving. Legal, business, and ethical\nrequirements motivate using effective XAI, but the increasing number of\ndifferent methods makes it challenging to pick the right ones. Further, as\nexplanations are highly context-dependent, measuring the effectiveness of XAI\nmethods without users can only reveal a limited amount of information,\nexcluding human factors such as the ability to understand it. We propose to\nevaluate XAI methods via the user's ability to successfully perform a proxy\ntask, designed such that a good performance is an indicator for the explanation\nto provide helpful information. In other words, we address the helpfulness of\nXAI for human decision-making. Further, a user study on state-of-the-art\nmethods was conducted, showing differences in their ability to generate trust\nand skepticism and the ability to judge the rightfulness of an AI decision\ncorrectly. Based on the results, we highly recommend using and extending this\napproach for more objective-based human-centered user studies to measure XAI\nperformance in an end-to-end fashion.",
      "tldr_zh": "这篇论文研究了Explainable Artificial Intelligence (XAI)在关键领域（如医疗诊断和自动驾驶）中的帮助性，强调了法律、商业和道德需求，但指出现有方法的多样性和上下文依赖性使评估复杂。作者提出一种新方法，通过用户完成代理任务来评估XAI的有效性，从而衡量解释对人类决策的支持程度。用户研究结果显示，不同XAI方法在生成信任、激发怀疑以及正确判断AI决策方面存在显著差异。论文推荐扩展这种基于目标的人类中心方法，以端到端方式进行更客观的XAI性能评估。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "68T37, 91E99",
        "I.2.0; I.2.3; H.5.2; H.1.2; K.4.2"
      ],
      "primary_category": "cs.HC",
      "comment": "World Conference on Explainable Artificial Intelligence",
      "pdf_url": "http://arxiv.org/pdf/2410.11896v1",
      "published_date": "2024-10-14 14:03:52 UTC",
      "updated_date": "2024-10-14 14:03:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:22:27.502406"
    },
    {
      "arxiv_id": "2410.10521v1",
      "title": "Continual Deep Reinforcement Learning to Prevent Catastrophic Forgetting in Jamming Mitigation",
      "title_zh": "翻译失败",
      "authors": [
        "Kemal Davaslioglu",
        "Sastry Kompella",
        "Tugba Erpek",
        "Yalin E. Sagduyu"
      ],
      "abstract": "Deep Reinforcement Learning (DRL) has been highly effective in learning from\nand adapting to RF environments and thus detecting and mitigating jamming\neffects to facilitate reliable wireless communications. However, traditional\nDRL methods are susceptible to catastrophic forgetting (namely forgetting old\ntasks when learning new ones), especially in dynamic wireless environments\nwhere jammer patterns change over time. This paper considers an anti-jamming\nsystem and addresses the challenge of catastrophic forgetting in DRL applied to\njammer detection and mitigation. First, we demonstrate the impact of\ncatastrophic forgetting in DRL when applied to jammer detection and mitigation\ntasks, where the network forgets previously learned jammer patterns while\nadapting to new ones. This catastrophic interference undermines the\neffectiveness of the system, particularly in scenarios where the environment is\nnon-stationary. We present a method that enables the network to retain\nknowledge of old jammer patterns while learning to handle new ones. Our\napproach substantially reduces catastrophic forgetting, allowing the\nanti-jamming system to learn new tasks without compromising its ability to\nperform previously learned tasks effectively. Furthermore, we introduce a\nsystematic methodology for sequentially learning tasks in the anti-jamming\nframework. By leveraging continual DRL techniques based on PackNet, we achieve\nsuperior anti-jamming performance compared to standard DRL methods. Our\nproposed approach not only addresses catastrophic forgetting but also enhances\nthe adaptability and robustness of the system in dynamic jamming environments.\nWe demonstrate the efficacy of our method in preserving knowledge of past\njammer patterns, learning new tasks efficiently, and achieving superior\nanti-jamming performance compared to traditional DRL approaches.",
      "tldr_zh": "这篇论文针对深度强化学习(DRL)在干扰缓解(jamming mitigation)中的灾难性遗忘(catastrophic forgetting)问题，提出了一种持续学习方法，以在动态无线环境中保持对旧干扰模式的记忆，同时适应新模式。方法基于PackNet的持续DRL技术，通过系统性任务顺序学习框架，显著减少了遗忘现象。实验结果显示，该方法在反干扰性能上比传统DRL方法提升明显，提升了系统的适应性和鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NI"
      ],
      "primary_category": "cs.LG",
      "comment": "IEEE MILCOM 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.10521v1",
      "published_date": "2024-10-14 14:00:32 UTC",
      "updated_date": "2024-10-14 14:00:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:22:39.476035"
    },
    {
      "arxiv_id": "2410.10516v3",
      "title": "UniGEM: A Unified Approach to Generation and Property Prediction for Molecules",
      "title_zh": "UniGEM：分子生成和属性预测的统一方法",
      "authors": [
        "Shikun Feng",
        "Yuyan Ni",
        "Yan Lu",
        "Zhi-Ming Ma",
        "Wei-Ying Ma",
        "Yanyan Lan"
      ],
      "abstract": "Molecular generation and molecular property prediction are both crucial for\ndrug discovery, but they are often developed independently. Inspired by recent\nstudies, which demonstrate that diffusion model, a prominent generative\napproach, can learn meaningful data representations that enhance predictive\ntasks, we explore the potential for developing a unified generative model in\nthe molecular domain that effectively addresses both molecular generation and\nproperty prediction tasks. However, the integration of these tasks is\nchallenging due to inherent inconsistencies, making simple multi-task learning\nineffective. To address this, we propose UniGEM, the first unified model to\nsuccessfully integrate molecular generation and property prediction, delivering\nsuperior performance in both tasks. Our key innovation lies in a novel\ntwo-phase generative process, where predictive tasks are activated in the later\nstages, after the molecular scaffold is formed. We further enhance task balance\nthrough innovative training strategies. Rigorous theoretical analysis and\ncomprehensive experiments demonstrate our significant improvements in both\ntasks. The principles behind UniGEM hold promise for broader applications,\nincluding natural language processing and computer vision.",
      "tldr_zh": "这篇论文提出 UniGEM，一种统一的分子生成和属性预测方法，受 diffusion model 启发，旨在解决这两个任务的独立开发问题。UniGEM 的关键创新是采用两阶段生成过程，在分子骨架形成后激活预测任务，并通过创新训练策略平衡任务整合的内在不一致性。实验和理论分析证明，UniGEM 在分子生成和属性预测任务上显著优于基线模型，其原则可扩展到自然语言处理和计算机视觉等领域。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.BM"
      ],
      "primary_category": "cs.LG",
      "comment": "11 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.10516v3",
      "published_date": "2024-10-14 13:58:13 UTC",
      "updated_date": "2025-04-04 07:57:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:22:51.507617"
    },
    {
      "arxiv_id": "2410.10502v1",
      "title": "A Practical Approach to Causal Inference over Time",
      "title_zh": "一个实用的随时间因果推断方法",
      "authors": [
        "Martina Cinquini",
        "Isacco Beretta",
        "Salvatore Ruggieri",
        "Isabel Valera"
      ],
      "abstract": "In this paper, we focus on estimating the causal effect of an intervention\nover time on a dynamical system. To that end, we formally define causal\ninterventions and their effects over time on discrete-time stochastic processes\n(DSPs). Then, we show under which conditions the equilibrium states of a DSP,\nboth before and after a causal intervention, can be captured by a structural\ncausal model (SCM). With such an equivalence at hand, we provide an explicit\nmapping from vector autoregressive models (VARs), broadly applied in\neconometrics, to linear, but potentially cyclic and/or affected by unmeasured\nconfounders, SCMs. The resulting causal VAR framework allows us to perform\ncausal inference over time from observational time series data. Our experiments\non synthetic and real-world datasets show that the proposed framework achieves\nstrong performance in terms of observational forecasting while enabling\naccurate estimation of the causal effect of interventions on dynamical systems.\nWe demonstrate, through a case study, the potential practical questions that\ncan be addressed using the proposed causal VAR framework.",
      "tldr_zh": "本文提出了一种实用的方法，用于评估干预对动态系统随时间变化的因果效应，通过正式定义因果 interventions 在离散时间随机过程(DSPs)中的影响，并探讨其平衡状态如何由结构因果模型(SCM)捕获。研究建立了从向量自回归模型(VARs)到线性SCM的显式映射，包括处理潜在循环或未观测混杂因素的场景，从而开发了因果VAR框架，用于从观测时间序列数据进行因果推理。实验结果显示，该框架在合成和真实数据集上实现了强劲的观测预测性能，并准确估计了干预对动态系统的因果效应。通过案例研究，该框架展示了在实际问题中的应用潜力，如回答实际决策问题。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.NA",
        "math.NA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.10502v1",
      "published_date": "2024-10-14 13:45:20 UTC",
      "updated_date": "2024-10-14 13:45:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:23:04.495096"
    },
    {
      "arxiv_id": "2410.10489v1",
      "title": "Cultural Fidelity in Large-Language Models: An Evaluation of Online Language Resources as a Driver of Model Performance in Value Representation",
      "title_zh": "翻译失败",
      "authors": [
        "Sharif Kazemi",
        "Gloria Gerhardt",
        "Jonty Katz",
        "Caroline Ida Kuria",
        "Estelle Pan",
        "Umang Prabhakar"
      ],
      "abstract": "The training data for LLMs embeds societal values, increasing their\nfamiliarity with the language's culture. Our analysis found that 44% of the\nvariance in the ability of GPT-4o to reflect the societal values of a country,\nas measured by the World Values Survey, correlates with the availability of\ndigital resources in that language. Notably, the error rate was more than five\ntimes higher for the languages of the lowest resource compared to the languages\nof the highest resource. For GPT-4-turbo, this correlation rose to 72%,\nsuggesting efforts to improve the familiarity with the non-English language\nbeyond the web-scraped data. Our study developed one of the largest and most\nrobust datasets in this topic area with 21 country-language pairs, each of\nwhich contain 94 survey questions verified by native speakers. Our results\nhighlight the link between LLM performance and digital data availability in\ntarget languages. Weaker performance in low-resource languages, especially\nprominent in the Global South, may worsen digital divides. We discuss\nstrategies proposed to address this, including developing multilingual LLMs\nfrom the ground up and enhancing fine-tuning on diverse linguistic datasets, as\nseen in African language initiatives.",
      "tldr_zh": "本文评估了在线语言资源对大型语言模型(LLMs) 在价值表示中的性能影响，发现数字资源可用性与模型反映国家社会价值观的能力高度相关，例如GPT-4o的44%方差和GPT-4-turbo的72%方差均与此相关。研究构建了一个包含21个国家-语言对的庞大数据集，每个对包括94个由母语者验证的World Values Survey问题。结果显示，低资源语言的错误率比高资源语言高五倍以上，可能加剧全球南方的数字鸿沟。作者建议通过从头开发多语言LLMs和在多样语言数据集上进行微调来缓解这一问题。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.10489v1",
      "published_date": "2024-10-14 13:33:00 UTC",
      "updated_date": "2024-10-14 13:33:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:23:18.064844"
    },
    {
      "arxiv_id": "2410.10923v1",
      "title": "ATLAS: Adapter-Based Multi-Modal Continual Learning with a Two-Stage Learning Strategy",
      "title_zh": "翻译失败",
      "authors": [
        "Hong Li",
        "Zhiquan Tan",
        "Xingyu Li",
        "Weiran Huang"
      ],
      "abstract": "While vision-and-language models significantly advance in many fields, the\nchallenge of continual learning is unsolved. Parameter-efficient modules like\nadapters and prompts present a promising way to alleviate catastrophic\nforgetting. However, existing works usually learn individual adapters for each\ntask, which may result in redundant knowledge among adapters. Moreover, they\ncontinue to use the original pre-trained model to initialize the downstream\nmodel, leading to negligible changes in the model's generalization compared to\nthe original model. In addition, there is still a lack of research\ninvestigating the consequences of integrating a multi-modal model into the\nupdating procedure for both uni-modal and multi-modal tasks and the subsequent\nimpacts it has on downstream tasks. In this paper, we propose an adapter-based\ntwo-stage learning paradigm, a multi-modal continual learning scheme that\nconsists of experience-based learning and novel knowledge expansion, which\nhelps the model fully use experience knowledge and compensate for novel\nknowledge. Extensive experiments demonstrate that our method is proficient for\ncontinual learning. It expands the distribution of representation upstream\nwhile also minimizing the negative impact of forgetting previous tasks.\nAdditionally, it enhances the generalization capability for downstream tasks.\nFurthermore, we incorporate both multi-modal and uni-modal tasks into upstream\ncontinual learning. We observe that learning from upstream tasks can help with\ndownstream tasks. Our code will be available at:\nhttps://github.com/lihong2303/ATLAS.",
      "tldr_zh": "该论文提出ATLAS框架，一种基于adapter的多模态持续学习（continual learning）方法，采用两阶段学习策略，包括经验-based learning和novel knowledge expansion，以缓解灾难性遗忘（catastrophic forgetting）并优化知识利用。相比现有方法，ATLAS避免了每个任务单独学习adapters导致的冗余问题，并通过整合多模态和单模态任务，扩展了表示分布并减少了对先前任务的负面影响。实验结果显示，该框架显著提高了下游任务的泛化能力，并证明上游任务学习有助于下游任务表现。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.10923v1",
      "published_date": "2024-10-14 13:29:42 UTC",
      "updated_date": "2024-10-14 13:29:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:23:27.278256"
    },
    {
      "arxiv_id": "2410.10483v1",
      "title": "Advancing Newborn Care: Precise Birth Time Detection Using AI-Driven Thermal Imaging with Adaptive Normalization",
      "title_zh": "推进新生儿护理：利用 AI 驱动的热成像进行精确出生时间检测，结合自适应归一化",
      "authors": [
        "Jorge García-Torres",
        "Øyvind Meinich-Bache",
        "Anders Johannessen",
        "Siren Rettedal",
        "Vilde Kolstad",
        "Kjersti Engan"
      ],
      "abstract": "Around 5-10\\% of newborns need assistance to start breathing. Currently,\nthere is a lack of evidence-based research, objective data collection, and\nopportunities for learning from real newborn resuscitation emergency events.\nGenerating and evaluating automated newborn resuscitation algorithm activity\ntimelines relative to the Time of Birth (ToB) offers a promising opportunity to\nenhance newborn care practices. Given the importance of prompt resuscitation\ninterventions within the \"golden minute\" after birth, having an accurate ToB\nwith second precision is essential for effective subsequent analysis of newborn\nresuscitation episodes. Instead, ToB is generally registered manually, often\nwith minute precision, making the process inefficient and susceptible to error\nand imprecision. In this work, we explore the fusion of Artificial Intelligence\n(AI) and thermal imaging to develop the first AI-driven ToB detector. The use\nof temperature information offers a promising alternative to detect the newborn\nwhile respecting the privacy of healthcare providers and mothers. However, the\nfrequent inconsistencies in thermal measurements, especially in a multi-camera\nsetup, make normalization strategies critical. Our methodology involves a\nthree-step process: first, we propose an adaptive normalization method based on\nGaussian mixture models (GMM) to mitigate issues related to temperature\nvariations; second, we implement and deploy an AI model to detect the presence\nof the newborn within the thermal video frames; and third, we evaluate and\npost-process the model's predictions to estimate the ToB. A precision of 88.1\\%\nand a recall of 89.3\\% are reported in the detection of the newborn within\nthermal frames during performance evaluation. Our approach achieves an absolute\nmedian deviation of 2.7 seconds in estimating the ToB relative to the manual\nannotations.",
      "tldr_zh": "本文提出了一种AI驱动的热成像方法，用于精确检测新生儿的Time of Birth (ToB)，以解决当前手动记录ToB效率低、易出错的问题，并提升新生儿复苏分析。该方法采用三步过程：首先，使用基于Gaussian Mixture Models (GMM)的adaptive normalization技术处理热测量不一致；其次，部署AI模型检测新生儿在热视频帧中的出现；最后，通过评估和后处理实现ToB的秒级估计。实验结果显示，该系统在新生儿检测中达到88.1%的precision和89.3%的recall，ToB估计的absolute median deviation仅为2.7秒。该创新方法为证据-based新生儿护理提供了高效、可隐私保护的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Paper submitted to Computer in Biology and Medicine, ELSEVIER",
      "pdf_url": "http://arxiv.org/pdf/2410.10483v1",
      "published_date": "2024-10-14 13:20:51 UTC",
      "updated_date": "2024-10-14 13:20:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:23:40.691950"
    },
    {
      "arxiv_id": "2410.10481v2",
      "title": "Model-Based Privacy-Preserving Knowledge Transfer for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zhaomin Wu",
        "Jizhou Guo",
        "Junyi Hou",
        "Bingsheng He",
        "Lixin Fan",
        "Qiang Yang"
      ],
      "abstract": "As large language models (LLMs) become more prevalent, effectively utilizing\ndomain-specific knowledge while ensuring privacy has become critical. Existing\nmethods often struggle to balance utility and privacy. For instance,\nretrieval-augmented generation (RAG) enables LLMs to access domain-specific\nknowledge but compromises the privacy of sensitive data. On the other hand,\ndifferentially private data synthesis techniques offer strong privacy\nguarantees but often result in poor utility. To address this challenge, we\npropose Llamdex, a novel framework that enhances LLMs using only models trained\non domain-specific data, integrated into LLMs through carefully designed\nconnection modules. Our approach significantly enhances the accuracy of\ndomain-specific tasks, achieving up to a 26% accuracy improvement compared to\nstate-of-the-art data synthesis methods under the same differential privacy\nconstraints. Experimental results show that Llamdex not only improves the\naccuracy of LLM responses but also maintains comparable inference efficiency to\nthe original LLM, highlighting its potential for real applications.",
      "tldr_zh": "本文提出 Llamdex 框架，用于大语言模型 (LLMs) 的模型-based 知识转移，旨在平衡领域特定知识利用与隐私保护，避免现有方法如 retrieval-augmented generation (RAG) 的数据泄露风险或 differentially private 数据合成的实用性不足。Llamdex 通过使用仅在领域特定数据上训练的模型，并通过精心设计的连接模块集成到 LLMs 中，实现高效的知识转移。实验结果显示，该框架在相同差分隐私约束下，比最先进的数据合成方法提高多达 26% 的准确性，同时保持与原 LLMs 相似的推理效率，具有实际应用潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.10481v2",
      "published_date": "2024-10-14 13:18:20 UTC",
      "updated_date": "2025-02-14 09:47:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:23:54.645129"
    },
    {
      "arxiv_id": "2410.10479v1",
      "title": "TMGBench: A Systematic Game Benchmark for Evaluating Strategic Reasoning Abilities of LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Haochuan Wang",
        "Xiachong Feng",
        "Lei Li",
        "Zhanyue Qin",
        "Dianbo Sui",
        "Lingpeng Kong"
      ],
      "abstract": "The rapid advancement of large language models (LLMs) has accelerated their\napplication in reasoning, with strategic reasoning drawing increasing\nattention. To evaluate LLMs' strategic reasoning capabilities, game theory,\nwith its concise structure, has become a preferred approach. However, current\nresearch focuses on a limited selection of games, resulting in low coverage.\nClassic game scenarios risk data leakage, and existing benchmarks often lack\nextensibility, making them inadequate for evaluating state-of-the-art models.\nTo address these challenges, we propose TMGBench, a benchmark with\ncomprehensive game type coverage, novel scenarios, and flexible organization.\nSpecifically, we incorporate all 144 game types summarized by the\nRobinson-Goforth topology of 2x2 games, constructed as classic games. We also\nemploy synthetic data generation to create diverse, higher-quality scenarios\nthrough topic guidance and human inspection, referred to as story-based games.\nLastly, we provide a sustainable framework for increasingly powerful LLMs by\ntreating these games as atomic units and organizing them into more complex\nforms via sequential, parallel, and nested structures. Our comprehensive\nevaluation of mainstream LLMs covers tests on rational reasoning, robustness,\nTheory-of-Mind (ToM), and reasoning in complex forms. Results reveal flaws in\naccuracy, consistency, and varying mastery of ToM. Additionally, o1-mini,\nOpenAI's latest reasoning model, achieved accuracy rates of 66.6%, 60.0%, and\n70.0% on sequential, parallel, and nested games, highlighting TMGBench's\nchallenges.",
      "tldr_zh": "本研究提出TMGBench，一种系统化的游戏基准，用于评估大型语言模型(LLMs)的战略推理能力，以解决现有基准在游戏覆盖、数据泄露和可扩展性方面的不足。TMGBench涵盖了基于Robinson-Goforth拓扑的所有144种2x2游戏类型，并通过合成数据生成结合主题指导和人工检查创建多样化的故事-based游戏，同时提供一个可持续框架，将这些游戏作为原子单位组织成顺序、并行和嵌套等复杂结构。实验评估主流LLMs的理性推理、鲁棒性、Theory-of-Mind (ToM)以及复杂形式推理，结果显示模型存在准确性和一致性缺陷，其中OpenAI的o1-mini在顺序、并行和嵌套游戏上的准确率分别为66.6%、60.0%和70.0%，突显了基准的挑战性。",
      "categories": [
        "cs.AI",
        "cs.GT"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.10479v1",
      "published_date": "2024-10-14 13:15:34 UTC",
      "updated_date": "2024-10-14 13:15:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:24:03.640821"
    },
    {
      "arxiv_id": "2410.10476v2",
      "title": "Will LLMs Replace the Encoder-Only Models in Temporal Relation Classification?",
      "title_zh": "翻译失败",
      "authors": [
        "Gabriel Roccabruna",
        "Massimo Rizzoli",
        "Giuseppe Riccardi"
      ],
      "abstract": "The automatic detection of temporal relations among events has been mainly\ninvestigated with encoder-only models such as RoBERTa. Large Language Models\n(LLM) have recently shown promising performance in temporal reasoning tasks\nsuch as temporal question answering. Nevertheless, recent studies have tested\nthe LLMs' performance in detecting temporal relations of closed-source models\nonly, limiting the interpretability of those results. In this work, we\ninvestigate LLMs' performance and decision process in the Temporal Relation\nClassification task. First, we assess the performance of seven open and\nclosed-sourced LLMs experimenting with in-context learning and lightweight\nfine-tuning approaches. Results show that LLMs with in-context learning\nsignificantly underperform smaller encoder-only models based on RoBERTa. Then,\nwe delve into the possible reasons for this gap by applying explainable\nmethods. The outcome suggests a limitation of LLMs in this task due to their\nautoregressive nature, which causes them to focus only on the last part of the\nsequence. Additionally, we evaluate the word embeddings of these two models to\nbetter understand their pre-training differences. The code and the fine-tuned\nmodels can be found respectively on GitHub.",
      "tldr_zh": "本研究探讨了大型语言模型（LLMs）是否能取代基于RoBERTa的encoder-only模型在Temporal Relation Classification任务中的作用。通过评估七个open和closed-sourced LLMs，使用in-context learning和lightweight fine-tuning方法，结果显示LLMs在in-context learning下显著低于RoBERTa-based模型。进一步通过explainable methods分析发现，LLMs的autoregressive性质导致其仅关注序列的最后部分，从而限制了性能；此外，比较word embeddings揭示了两种模型pre-training差异。总体而言，该工作提供了代码和fine-tuned模型，质疑LLMs在该任务中的潜在替代性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.10476v2",
      "published_date": "2024-10-14 13:10:45 UTC",
      "updated_date": "2024-10-31 14:15:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:24:17.128703"
    },
    {
      "arxiv_id": "2410.10463v1",
      "title": "TABCF: Counterfactual Explanations for Tabular Data Using a Transformer-Based VAE",
      "title_zh": "翻译失败",
      "authors": [
        "Emmanouil Panagiotou",
        "Manuel Heurich",
        "Tim Landgraf",
        "Eirini Ntoutsi"
      ],
      "abstract": "In the field of Explainable AI (XAI), counterfactual (CF) explanations are\none prominent method to interpret a black-box model by suggesting changes to\nthe input that would alter a prediction. In real-world applications, the input\nis predominantly in tabular form and comprised of mixed data types and complex\nfeature interdependencies. These unique data characteristics are difficult to\nmodel, and we empirically show that they lead to bias towards specific feature\ntypes when generating CFs. To overcome this issue, we introduce TABCF, a CF\nexplanation method that leverages a transformer-based Variational Autoencoder\n(VAE) tailored for modeling tabular data. Our approach uses transformers to\nlearn a continuous latent space and a novel Gumbel-Softmax detokenizer that\nenables precise categorical reconstruction while preserving end-to-end\ndifferentiability. Extensive quantitative evaluation on five financial datasets\ndemonstrates that TABCF does not exhibit bias toward specific feature types,\nand outperforms existing methods in producing effective CFs that align with\ncommon CF desiderata.",
      "tldr_zh": "本研究针对可解释 AI (XAI) 中的反事实 (Counterfactual, CF) 解释问题，提出 TABCF 方法，以解决表格数据中混合数据类型和特征相互依赖导致的特征类型偏见。TABCF 利用基于 Transformer 的 Variational Autoencoder (VAE) 来学习连续潜在空间，并引入新型 Gumbel-Softmax detokenizer，实现精确的分类变量重建，同时保持端到端可微性。该方法在五个金融数据集上的广泛评估中，证明了其不偏向特定特征类型，并在生成有效 CF 方面优于现有方法，满足常见的 CF 期望标准。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "Paper accepted at ICAIF '24: 5th ACM International Conference on AI\n  in Finance, Brooklyn, NY, USA, November 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.10463v1",
      "published_date": "2024-10-14 12:55:41 UTC",
      "updated_date": "2024-10-14 12:55:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:24:28.263546"
    },
    {
      "arxiv_id": "2410.10460v1",
      "title": "Compositional Shielding and Reinforcement Learning for Multi-Agent Systems",
      "title_zh": "组合屏蔽和强化学习用于多智能体系统",
      "authors": [
        "Asger Horn Brorholt",
        "Kim Guldstrand Larsen",
        "Christian Schilling"
      ],
      "abstract": "Deep reinforcement learning has emerged as a powerful tool for obtaining\nhigh-performance policies. However, the safety of these policies has been a\nlong-standing issue. One promising paradigm to guarantee safety is a shield,\nwhich shields a policy from making unsafe actions. However, computing a shield\nscales exponentially in the number of state variables. This is a particular\nconcern in multi-agent systems with many agents. In this work, we propose a\nnovel approach for multi-agent shielding. We address scalability by computing\nindividual shields for each agent. The challenge is that typical safety\nspecifications are global properties, but the shields of individual agents only\nensure local properties. Our key to overcome this challenge is to apply\nassume-guarantee reasoning. Specifically, we present a sound proof rule that\ndecomposes a (global, complex) safety specification into (local, simple)\nobligations for the shields of the individual agents. Moreover, we show that\napplying the shields during reinforcement learning significantly improves the\nquality of the policies obtained for a given training budget. We demonstrate\nthe effectiveness and scalability of our multi-agent shielding framework in two\ncase studies, reducing the computation time from hours to seconds and achieving\nfast learning convergence.",
      "tldr_zh": "本研究针对多智能体系统中的深度强化学习（Deep reinforcement learning）策略安全问题，提出了一种可扩展的组合屏蔽（Compositional Shielding）方法。该方法通过为每个智能体计算独立的屏蔽（shield），并利用假设-保证推理（assume-guarantee reasoning）将全局安全规范分解为局部义务，从而解决屏蔽计算的指数级扩展性挑战。在强化学习过程中应用这些屏蔽，不仅显著提升了策略质量，还加速了学习收敛；在两个案例研究中，计算时间从小时缩短到秒级，证明了框架的有效性和可扩展性。",
      "categories": [
        "cs.LO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.LO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.10460v1",
      "published_date": "2024-10-14 12:52:48 UTC",
      "updated_date": "2024-10-14 12:52:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:24:39.980056"
    },
    {
      "arxiv_id": "2410.12870v1",
      "title": "Skill Learning Using Process Mining for Large Language Model Plan Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Andrei Cosmin Redis",
        "Mohammadreza Fani Sani",
        "Bahram Zarrin",
        "Andrea Burattin"
      ],
      "abstract": "Large language models (LLMs) hold promise for generating plans for complex\ntasks, but their effectiveness is limited by sequential execution, lack of\ncontrol flow models, and difficulties in skill retrieval. Addressing these\nissues is crucial for improving the efficiency and interpretability of plan\ngeneration as LLMs become more central to automation and decision-making. We\nintroduce a novel approach to skill learning in LLMs by integrating process\nmining techniques, leveraging process discovery for skill acquisition, process\nmodels for skill storage, and conformance checking for skill retrieval. Our\nmethods enhance text-based plan generation by enabling flexible skill\ndiscovery, parallel execution, and improved interpretability. Experimental\nresults suggest the effectiveness of our approach, with our skill retrieval\nmethod surpassing state-of-the-art accuracy baselines under specific\nconditions.",
      "tldr_zh": "大型语言模型(LLMs)在生成复杂任务计划时，面临顺序执行、缺乏控制流模型以及技能检索困难等问题。为此，本文提出了一种新颖的技能学习方法，通过整合过程挖掘技术，包括过程发现用于技能获取、过程模型用于技能存储，以及一致性检查(conformance checking)用于技能检索，从而提升计划生成的灵活性、支持并行执行并提高可解释性。实验结果表明，该方法在特定条件下超过了最先进基准的准确率，为LLMs在自动化和决策中的应用提供了有效改进。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DB",
        "cs.ET",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "12 pages, 5 figures, 2 tables, accepted at ICPM 2024'",
      "pdf_url": "http://arxiv.org/pdf/2410.12870v1",
      "published_date": "2024-10-14 12:48:42 UTC",
      "updated_date": "2024-10-14 12:48:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:24:52.190556"
    },
    {
      "arxiv_id": "2410.10451v2",
      "title": "Mobility-Aware Federated Learning: Multi-Armed Bandit Based Selection in Vehicular Network",
      "title_zh": "翻译失败",
      "authors": [
        "Haoyu Tu",
        "Lin Chen",
        "Zuguang Li",
        "Xiaopei Chen",
        "Wen Wu"
      ],
      "abstract": "In this paper, we study a vehicle selection problem for federated learning\n(FL) over vehicular networks. Specifically, we design a mobility-aware\nvehicular federated learning (MAVFL) scheme in which vehicles drive through a\nroad segment to perform FL. Some vehicles may drive out of the segment which\nleads to unsuccessful training. In the proposed scheme, the real-time\nsuccessful training participation ratio is utilized to implement vehicle\nselection. We conduct the convergence analysis to indicate the influence of\nvehicle mobility on training loss. Furthermore, we propose a multi-armed\nbandit-based vehicle selection algorithm to minimize the utility function\nconsidering training loss and delay. The simulation results show that compared\nwith baselines, the proposed algorithm can achieve better training performance\nwith approximately 28\\% faster convergence.",
      "tldr_zh": "本文研究了车辆网络中联邦学习(FL)的车辆选择问题，提出了一种基于移动性的MAVFL方案，利用实时成功训练参与率来筛选车辆，以应对车辆驶出路段导致的训练失败。作者进行了收敛分析，探讨了车辆移动对训练损失的影响，并设计了基于多臂赌博机(Multi-Armed Bandit)的算法来最小化考虑训练损失和延迟的效用函数。模拟结果显示，该算法相较基线方案提升了训练性能，收敛速度约快28%。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by 2024 IEEE Globecom Workshops (GC Wkshps)",
      "pdf_url": "http://arxiv.org/pdf/2410.10451v2",
      "published_date": "2024-10-14 12:45:15 UTC",
      "updated_date": "2024-10-15 03:16:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:25:04.050812"
    },
    {
      "arxiv_id": "2410.10450v2",
      "title": "KBLaM: Knowledge Base augmented Language Model",
      "title_zh": "KBLaM：知识库增强语言模型",
      "authors": [
        "Xi Wang",
        "Taketomo Isazawa",
        "Liana Mikaelyan",
        "James Hensman"
      ],
      "abstract": "In this paper, we propose Knowledge Base augmented Language Model (KBLaM), a\nnew method for augmenting Large Language Models (LLMs) with external knowledge.\nKBLaM works with a knowledge base (KB) constructed from a corpus of documents,\ntransforming each piece of knowledge in the KB into continuous key-value vector\npairs via pre-trained sentence encoders with linear adapters and integrating\nthem into pre-trained LLMs via a specialized rectangular attention mechanism.\nUnlike Retrieval-Augmented Generation, KBLaM eliminates external retrieval\nmodules, and unlike in-context learning, its computational overhead scales\nlinearly with KB size rather than quadratically. Our approach enables\nintegrating a large KB of more than 10K triples into an 8B pre-trained LLM of\nonly 8K context window on one single A100 80GB GPU and allows for dynamic\nupdates without model fine-tuning or retraining. Experiments demonstrate\nKBLaM's effectiveness in various tasks, including question-answering and\nopen-ended reasoning, while providing interpretable insights into its use of\nthe augmented knowledge. Code and datasets are available at\nhttps://github.com/microsoft/KBLaM/",
      "tldr_zh": "本研究提出了一种新方法KBLaM（Knowledge Base augmented Language Model），用于增强Large Language Models (LLMs)与外部知识的整合。具体而言，KBLaM从文档语料库构建知识库（KB），将知识转化为连续的key-value向量对，并通过预训练句子编码器、线性适配器和矩形注意力机制（rectangular attention mechanism）无缝集成到LLMs中。相较于Retrieval-Augmented Generation (RAG)，该方法无需外部检索模块；相较于in-context learning，其计算开销与KB大小线性增长，支持动态更新而不需模型微调。实验结果显示，KBLaM在问答和开放式推理等任务中表现出色，并提供可解释的知识使用见解。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.10450v2",
      "published_date": "2024-10-14 12:45:10 UTC",
      "updated_date": "2025-02-09 04:45:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:25:26.347586"
    },
    {
      "arxiv_id": "2410.10441v2",
      "title": "Free Video-LLM: Prompt-guided Visual Perception for Efficient Training-free Video LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Kai Han",
        "Jianyuan Guo",
        "Yehui Tang",
        "Wei He",
        "Enhua Wu",
        "Yunhe Wang"
      ],
      "abstract": "Vision-language large models have achieved remarkable success in various\nmulti-modal tasks, yet applying them to video understanding remains challenging\ndue to the inherent complexity and computational demands of video data. While\ntraining-based video-LLMs deliver high performance, they often require\nsubstantial resources for training and inference. Conversely, training-free\napproaches offer a more efficient alternative by adapting pre-trained\nimage-LLMs models for video tasks without additional training, but they face\ninference efficiency bottlenecks due to the large number of visual tokens\ngenerated from video frames. In this work, we present a novel prompt-guided\nvisual perception framework (abbreviated as Free Video-LLM) for efficient\ninference of training-free video LLMs. The proposed framework decouples\nspatial-temporal dimension and performs temporal frame sampling and spatial RoI\ncropping respectively based on task-specific prompts. Our method effectively\nreduces the number of visual tokens while maintaining high performance across\nmultiple video question-answering benchmarks. Extensive experiments demonstrate\nthat our approach achieves competitive results with significantly fewer tokens,\noffering an optimal trade-off between accuracy and computational efficiency\ncompared to state-of-the-art video LLMs. The code will be available at\nhttps://github.com/contrastive/FreeVideoLLM.",
      "tldr_zh": "该研究针对视觉语言大模型在视频理解中的计算效率挑战，提出了一种无需训练的框架Free Video-LLM，利用prompt-guided visual perception来优化推理过程。该框架通过解耦空间-时间维度，分别进行temporal frame sampling和spatial RoI cropping，以任务特定提示减少视觉标记数量，同时保持高性能。实验结果显示，在多个视频问答基准上，Free Video-LLM实现了与最先进模型相当的准确率，但显著降低了计算开销，提供了一个理想的准确性与效率权衡。代码已在GitHub上发布。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Tech report",
      "pdf_url": "http://arxiv.org/pdf/2410.10441v2",
      "published_date": "2024-10-14 12:35:12 UTC",
      "updated_date": "2024-10-16 09:45:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:25:27.439758"
    },
    {
      "arxiv_id": "2410.10433v1",
      "title": "LKASeg:Remote-Sensing Image Semantic Segmentation with Large Kernel Attention and Full-Scale Skip Connections",
      "title_zh": "翻译失败",
      "authors": [
        "Xuezhi Xiang",
        "Yibo Ning",
        "Lei Zhang",
        "Denis Ombati",
        "Himaloy Himu",
        "Xiantong Zhen"
      ],
      "abstract": "Semantic segmentation of remote sensing images is a fundamental task in\ngeospatial research. However, widely used Convolutional Neural Networks (CNNs)\nand Transformers have notable drawbacks: CNNs may be limited by insufficient\nremote sensing modeling capability, while Transformers face challenges due to\ncomputational complexity. In this paper, we propose a remote-sensing image\nsemantic segmentation network named LKASeg, which combines Large Kernel\nAttention(LSKA) and Full-Scale Skip Connections(FSC). Specifically, we propose\na decoder based on Large Kernel Attention (LKA), which extract global features\nwhile avoiding the computational overhead of self-attention and providing\nchannel adaptability. To achieve full-scale feature learning and fusion, we\napply Full-Scale Skip Connections (FSC) between the encoder and decoder. We\nconducted experiments by combining the LKA-based decoder with FSC. On the ISPRS\nVaihingen dataset, the mF1 and mIoU scores achieved 90.33% and 82.77%.",
      "tldr_zh": "该论文针对遥感图像语义分割任务，提出了一种名为 LKASeg 的网络，以解决 CNNs 的建模能力不足和 Transformers 的计算复杂性问题。具体而言，LKASeg 结合 Large Kernel Attention (LKA) 解码器和 Full-Scale Skip Connections (FSC)，其中 LKA 提取全局特征的同时避免自注意力机制的计算开销，并提供通道适应性；FSC 则实现编码器和解码器之间的全尺度特征学习与融合。实验结果显示，在 ISPRS Vaihingen 数据集上，LKASeg 达到了 90.33% 的 mF1 和 82.77% 的 mIoU 评分，展示了其在遥感图像分割中的优越性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "The paper is under consideration at 2025 IEEE International\n  Conference on Acoustics, Speech, and Signal Processing (ICASSP 2025)",
      "pdf_url": "http://arxiv.org/pdf/2410.10433v1",
      "published_date": "2024-10-14 12:25:48 UTC",
      "updated_date": "2024-10-14 12:25:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:25:39.191704"
    },
    {
      "arxiv_id": "2410.10398v2",
      "title": "FairMindSim: Alignment of Behavior, Emotion, and Belief in Humans and LLM Agents Amid Ethical Dilemmas",
      "title_zh": "翻译失败",
      "authors": [
        "Yu Lei",
        "Hao Liu",
        "Chengxing Xie",
        "Songjia Liu",
        "Zhiyu Yin",
        "Canyu Chen",
        "Guohao Li",
        "Philip Torr",
        "Zhen Wu"
      ],
      "abstract": "AI alignment is a pivotal issue concerning AI control and safety. It should\nconsider not only value-neutral human preferences but also moral and ethical\nconsiderations. In this study, we introduced FairMindSim, which simulates the\nmoral dilemma through a series of unfair scenarios. We used LLM agents to\nsimulate human behavior, ensuring alignment across various stages. To explore\nthe various socioeconomic motivations, which we refer to as beliefs, that drive\nboth humans and LLM agents as bystanders to intervene in unjust situations\ninvolving others, and how these beliefs interact to influence individual\nbehavior, we incorporated knowledge from relevant sociological fields and\nproposed the Belief-Reward Alignment Behavior Evolution Model (BREM) based on\nthe recursive reward model (RRM). Our findings indicate that, behaviorally,\nGPT-4o exhibits a stronger sense of social justice, while humans display a\nricher range of emotions. Additionally, we discussed the potential impact of\nemotions on behavior. This study provides a theoretical foundation for\napplications in aligning LLMs with altruistic values.",
      "tldr_zh": "本研究引入 FairMindSim 系统，通过模拟一系列不公平场景来探讨 AI alignment（AI 对齐）问题，包括人类和 LLM agents 在道德困境中的行为、情感和信念对齐。研究者基于社会学知识，提出 Belief-Reward Alignment Behavior Evolution Model (BREM)，其建立在 recursive reward model (RRM) 基础上，用于分析信念如何驱动旁观者干预不公行为。结果显示，GPT-4o 在行为上表现出更强的社会正义感，而人类情感范围更丰富；此外，研究讨论了情感对行为的影响，为将 LLMs 与利他主义价值观对齐提供理论基础。",
      "categories": [
        "cs.CE",
        "cs.AI"
      ],
      "primary_category": "cs.CE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.10398v2",
      "published_date": "2024-10-14 11:39:05 UTC",
      "updated_date": "2024-10-17 15:02:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:25:51.090911"
    },
    {
      "arxiv_id": "2410.10394v2",
      "title": "PIVOT-R: Primitive-Driven Waypoint-Aware World Model for Robotic Manipulation",
      "title_zh": "翻译失败",
      "authors": [
        "Kaidong Zhang",
        "Pengzhen Ren",
        "Bingqian Lin",
        "Junfan Lin",
        "Shikui Ma",
        "Hang Xu",
        "Xiaodan Liang"
      ],
      "abstract": "Language-guided robotic manipulation is a challenging task that requires an\nembodied agent to follow abstract user instructions to accomplish various\ncomplex manipulation tasks. Previous work trivially fitting the data without\nrevealing the relation between instruction and low-level executable actions,\nthese models are prone to memorizing the surficial pattern of the data instead\nof acquiring the transferable knowledge, and thus are fragile to dynamic\nenvironment changes. To address this issue, we propose a PrIrmitive-driVen\nwaypOinT-aware world model for Robotic manipulation (PIVOT-R) that focuses\nsolely on the prediction of task-relevant waypoints. Specifically, PIVOT-R\nconsists of a Waypoint-aware World Model (WAWM) and a lightweight action\nprediction module. The former performs primitive action parsing and\nprimitive-driven waypoint prediction, while the latter focuses on decoding\nlow-level actions. Additionally, we also design an asynchronous hierarchical\nexecutor (AHE), which can use different execution frequencies for different\nmodules of the model, thereby helping the model reduce computational redundancy\nand improve model execution efficiency. Our PIVOT-R outperforms\nstate-of-the-art (SoTA) open-source models on the SeaWave benchmark, achieving\nan average relative improvement of 19.45% across four levels of instruction\ntasks. Moreover, compared to the synchronously executed PIVOT-R, the execution\nefficiency of PIVOT-R with AHE is increased by 28-fold, with only a 2.9% drop\nin performance. These results provide compelling evidence that our PIVOT-R can\nsignificantly improve both the performance and efficiency of robotic\nmanipulation.",
      "tldr_zh": "该论文提出 PIVOT-R，一种原始驱动的路径点感知世界模型，用于提升语言引导的机器人操作任务性能。PIVOT-R 包括 Waypoint-aware World Model (WAWM) 用于解析原始动作并预测任务相关路径点，以及一个轻量级动作预测模块；同时引入异步层次执行器 (AHE) 以不同频率执行模块，减少计算冗余并提高效率。在 SeaWave 基准测试中，PIVOT-R 比最先进开源模型平均提升 19.45%，并通过 AHE 使执行效率提高 28 倍，仅损失 2.9% 性能。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted to NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.10394v2",
      "published_date": "2024-10-14 11:30:18 UTC",
      "updated_date": "2024-10-16 08:20:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:26:04.383886"
    },
    {
      "arxiv_id": "2410.10392v1",
      "title": "Optimizing Instruction Synthesis: Effective Exploration of Evolutionary Space with Tree Search",
      "title_zh": "优化指令合成：使用树搜索有效探索进化空间",
      "authors": [
        "Chenglin Li",
        "Qianglong Chen",
        "Zhi Li",
        "Feng Tao",
        "Yicheng Li",
        "Hao Chen",
        "Fei Yu",
        "Yin Zhang"
      ],
      "abstract": "Instruction tuning is a crucial technique for aligning language models with\nhumans' actual goals in the real world. Extensive research has highlighted the\nquality of instruction data is essential for the success of this alignment.\nHowever, creating high-quality data manually is labor-intensive and\ntime-consuming, which leads researchers to explore using LLMs to synthesize\ndata. Recent studies have focused on using a stronger LLM to iteratively\nenhance existing instruction data, showing promising results. Nevertheless,\nprevious work often lacks control over the evolution direction, resulting in\nhigh uncertainty in the data synthesis process and low-quality instructions. In\nthis paper, we introduce a general and scalable framework, IDEA-MCTS\n(Instruction Data Enhancement using Monte Carlo Tree Search), a scalable\nframework for efficiently synthesizing instructions. With tree search and\nevaluation models, it can efficiently guide each instruction to evolve into a\nhigh-quality form, aiding in instruction fine-tuning. Experimental results show\nthat IDEA-MCTS significantly enhances the seed instruction data, raising the\naverage evaluation scores of quality, diversity, and complexity from 2.19 to\n3.81. Furthermore, in open-domain benchmarks, experimental results show that\nIDEA-MCTS improves the accuracy of real-world instruction-following skills in\nLLMs by an average of 5\\% in low-resource settings.",
      "tldr_zh": "这篇论文提出了IDEA-MCTS框架，使用Monte Carlo Tree Search (MCTS)优化指令合成过程，以高效探索演化空间并提升指令数据质量。框架通过树搜索和评估模型引导指令数据从种子数据演化，提高其质量、多样性和复杂性。实验结果显示，IDEA-MCTS将指令数据的平均评估分数从2.19提高到3.81，并在低资源设置下使LLM的指令遵循准确性平均提升5%。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.10392v1",
      "published_date": "2024-10-14 11:28:30 UTC",
      "updated_date": "2024-10-14 11:28:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:26:15.585745"
    },
    {
      "arxiv_id": "2410.10390v1",
      "title": "Stein Variational Evolution Strategies",
      "title_zh": "Stein 变分进化策略",
      "authors": [
        "Cornelius V. Braun",
        "Robert T. Lange",
        "Marc Toussaint"
      ],
      "abstract": "Stein Variational Gradient Descent (SVGD) is a highly efficient method to\nsample from an unnormalized probability distribution. However, the SVGD update\nrelies on gradients of the log-density, which may not always be available.\nExisting gradient-free versions of SVGD make use of simple Monte Carlo\napproximations or gradients from surrogate distributions, both with\nlimitations. To improve gradient-free Stein variational inference, we combine\nSVGD steps with evolution strategy (ES) updates. Our results demonstrate that\nthe resulting algorithm generates high-quality samples from unnormalized target\ndensities without requiring gradient information. Compared to prior\ngradient-free SVGD methods, we find that the integration of the ES update in\nSVGD significantly improves the performance on multiple challenging benchmark\nproblems.",
      "tldr_zh": "本文提出了一种改进的无梯度 Stein 变分推理方法，将 Stein Variational Gradient Descent (SVGD) 与 Evolution Strategies (ES) 更新相结合，以从未归一化概率分布中采样，而无需依赖 log-density 的梯度信息。这种集成方法克服了现有无梯度 SVGD 技术的局限，如简单的 Monte Carlo 近似或代理分布梯度。实验结果显示，该算法在多个挑战性基准问题上显著提升了性能，生成高质量样本。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.10390v1",
      "published_date": "2024-10-14 11:24:41 UTC",
      "updated_date": "2024-10-14 11:24:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:26:27.438120"
    },
    {
      "arxiv_id": "2410.10372v1",
      "title": "BookWorm: A Dataset for Character Description and Analysis",
      "title_zh": "BookWorm：用于人物描述和分析的数据集",
      "authors": [
        "Argyrios Papoudakis",
        "Mirella Lapata",
        "Frank Keller"
      ],
      "abstract": "Characters are at the heart of every story, driving the plot and engaging\nreaders. In this study, we explore the understanding of characters in\nfull-length books, which contain complex narratives and numerous interacting\ncharacters. We define two tasks: character description, which generates a brief\nfactual profile, and character analysis, which offers an in-depth\ninterpretation, including character development, personality, and social\ncontext. We introduce the BookWorm dataset, pairing books from the Gutenberg\nProject with human-written descriptions and analyses. Using this dataset, we\nevaluate state-of-the-art long-context models in zero-shot and fine-tuning\nsettings, utilizing both retrieval-based and hierarchical processing for\nbook-length inputs. Our findings show that retrieval-based approaches\noutperform hierarchical ones in both tasks. Additionally, fine-tuned models\nusing coreference-based retrieval produce the most factual descriptions, as\nmeasured by fact- and entailment-based metrics. We hope our dataset,\nexperiments, and analysis will inspire further research in character-based\nnarrative understanding.",
      "tldr_zh": "该研究引入了BookWorm数据集，用于支持小说角色描述（character description）和分析（character analysis）任务，前者生成简要事实概要，后者提供深入解读包括角色发展、个性和社会背景。数据集基于Gutenberg Project的书籍配对人类编写的描述和分析，并评估了长上下文模型在zero-shot和fine-tuning设置下的性能，使用retrieval-based和hierarchical processing方法。结果表明，retrieval-based方法在两任务中均优于hierarchical方法，而fine-tuned模型结合coreference-based retrieval产生最事实性的描述，这有望激发更多角色-based叙事理解的研究。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "30 pages, 2 figures, EMNLP 2024 Findings",
      "pdf_url": "http://arxiv.org/pdf/2410.10372v1",
      "published_date": "2024-10-14 10:55:58 UTC",
      "updated_date": "2024-10-14 10:55:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:26:39.247313"
    },
    {
      "arxiv_id": "2410.10370v2",
      "title": "Innovative Thinking, Infinite Humor: Humor Research of Large Language Models through Structured Thought Leaps",
      "title_zh": "翻译失败",
      "authors": [
        "Han Wang",
        "Yilin Zhao",
        "Dian Li",
        "Xiaohan Wang",
        "Gang Liu",
        "Xuguang Lan",
        "Hui Wang"
      ],
      "abstract": "Humor is previously regarded as a gift exclusive to humans for the following\nreasons. Humor is a culturally nuanced aspect of human language, presenting\nchallenges for its understanding and generation. Humor generation necessitates\na multi-hop reasoning process, with each hop founded on proper rationales.\nAlthough many studies, such as those related to GPT-o1, focus on logical\nreasoning with reflection and correction, they still fall short in humor\ngeneration. Due to the sparsity of the knowledge graph in creative thinking, it\nis arduous to achieve multi-hop reasoning. Consequently, in this paper, we\npropose a more robust framework for addressing the humor reasoning task, named\nLoL. LoL aims to inject external information to mitigate the sparsity of the\nknowledge graph, thereby enabling multi-hop reasoning. In the first stage of\nLoL, we put forward an automatic instruction-evolution method to incorporate\nthe deeper and broader thinking processes underlying humor. Judgment-oriented\ninstructions are devised to enhance the model's judgment capability,\ndynamically supplementing and updating the sparse knowledge graph.\nSubsequently, through reinforcement learning, the reasoning logic for each\nonline-generated response is extracted using GPT-4o. In this process, external\nknowledge is re-introduced to aid the model in logical reasoning and the\nlearning of human preferences. Finally, experimental results indicate that the\ncombination of these two processes can enhance both the model's judgment\nability and its generative capacity. These findings deepen our comprehension of\nthe creative capabilities of large language models (LLMs) and offer approaches\nto boost LLMs' creative abilities for cross-domain innovative applications.",
      "tldr_zh": "本论文探讨了大型语言模型（LLMs）在幽默生成中的挑战，如文化细微差异和多跳推理（multi-hop reasoning）的不足，并提出一个名为 LoL 的框架来解决这些问题。LoL 框架包括两个阶段：首先，通过自动指令演化方法（automatic instruction-evolution method）和判断导向指令（Judgment-oriented instructions）来补充稀疏的知识图谱，增强模型的判断能力；其次，利用强化学习（reinforcement learning）和 GPT-4o 提取推理逻辑，重新引入外部知识以学习人类偏好。实验结果显示，该框架显著提高了 LLMs 的判断和生成能力，加深了对模型创造力的理解，并为跨领域创新应用提供了有效方法。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.10370v2",
      "published_date": "2024-10-14 10:50:16 UTC",
      "updated_date": "2025-04-11 01:52:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:26:52.317055"
    },
    {
      "arxiv_id": "2410.10366v1",
      "title": "Affinity-Graph-Guided Contractive Learning for Pretext-Free Medical Image Segmentation with Minimal Annotation",
      "title_zh": "翻译失败",
      "authors": [
        "Zehua Cheng",
        "Di Yuan",
        "Thomas Lukasiewicz"
      ],
      "abstract": "The combination of semi-supervised learning (SemiSL) and contrastive learning\n(CL) has been successful in medical image segmentation with limited\nannotations. However, these works often rely on pretext tasks that lack the\nspecificity required for pixel-level segmentation, and still face overfitting\nissues due to insufficient supervision signals resulting from too few\nannotations. Therefore, this paper proposes an affinity-graph-guided\nsemi-supervised contrastive learning framework (Semi-AGCL) by establishing\nadditional affinity-graph-based supervision signals between the student and\nteacher network, to achieve medical image segmentation with minimal annotations\nwithout pretext. The framework first designs an average-patch-entropy-driven\ninter-patch sampling method, which can provide a robust initial feature space\nwithout relying on pretext tasks. Furthermore, the framework designs an\naffinity-graph-guided loss function, which can improve the quality of the\nlearned representation and the model generalization ability by exploiting the\ninherent structure of the data, thus mitigating overfitting. Our experiments\nindicate that with merely 10% of the complete annotation set, our model\napproaches the accuracy of the fully annotated baseline, manifesting a marginal\ndeviation of only 2.52%. Under the stringent conditions where only 5% of the\nannotations are employed, our model exhibits a significant enhancement in\nperformance surpassing the second best baseline by 23.09% on the dice metric\nand achieving an improvement of 26.57% on the notably arduous CRAG and ACDC\ndatasets.",
      "tldr_zh": "这篇论文提出了一种亲和图引导的半监督对比学习框架（Semi-AGCL），旨在实现无需预训练任务（pretext-free）的医疗图像分割，仅使用极少标注来缓解过拟合问题。该框架通过平均补丁熵驱动的inter-patch采样方法构建稳健的初始特征空间，并设计亲和图引导的损失函数，利用数据内在结构提升表示质量和模型泛化能力。实验结果显示，使用仅10%的标注，模型准确率接近全标注基线，仅差2.52%；而在5%的标注条件下，该框架在dice指标上比次优基线提高23.09%，并在CRAG和ACDC数据集上实现26.57%的显著提升。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "BIBM 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.10366v1",
      "published_date": "2024-10-14 10:44:47 UTC",
      "updated_date": "2024-10-14 10:44:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:27:04.132630"
    },
    {
      "arxiv_id": "2410.10365v1",
      "title": "SpeGCL: Self-supervised Graph Spectrum Contrastive Learning without Positive Samples",
      "title_zh": "SpeGCL：无正样本的自监督图谱对比学习",
      "authors": [
        "Yuntao Shou",
        "Xiangyong Cao",
        "Deyu Meng"
      ],
      "abstract": "Graph Contrastive Learning (GCL) excels at managing noise and fluctuations in\ninput data, making it popular in various fields (e.g., social networks, and\nknowledge graphs). Our study finds that the difference in high-frequency\ninformation between augmented graphs is greater than that in low-frequency\ninformation. However, most existing GCL methods focus mainly on the time domain\n(low-frequency information) for node feature representations and cannot make\ngood use of high-frequency information to speed up model convergence.\nFurthermore, existing GCL paradigms optimize graph embedding representations by\npulling the distance between positive sample pairs closer and pushing the\ndistance between positive and negative sample pairs farther away, but our\ntheoretical analysis shows that graph contrastive learning benefits from\npushing negative pairs farther away rather than pulling positive pairs closer.\nTo solve the above-mentioned problems, we propose a novel spectral GCL\nframework without positive samples, named SpeGCL. Specifically, to solve the\nproblem that existing GCL methods cannot utilize high-frequency information,\nSpeGCL uses a Fourier transform to extract high-frequency and low-frequency\ninformation of node features, and constructs a contrastive learning mechanism\nin a Fourier space to obtain better node feature representation. Furthermore,\nSpeGCL relies entirely on negative samples to refine the graph embedding. We\nalso provide a theoretical justification for the efficacy of using only\nnegative samples in SpeGCL. Extensive experiments on un-supervised learning,\ntransfer learning, and semi-supervised learning have validated the superiority\nof our SpeGCL framework over the state-of-the-art GCL methods.",
      "tldr_zh": "本研究发现现有 Graph Contrastive Learning (GCL) 方法主要关注低频信息，无法有效利用高频信息，且过度依赖正样本对的拉近优化。针对这些问题，提出 SpeGCL 框架，使用 Fourier transform 提取节点特征的高频和低频信息，并在 Fourier 空间构建仅基于负样本的对比学习机制，以加速模型收敛并提升表示质量。理论分析证明了只用负样本的效能，实验在无监督学习、转移学习和半监督学习任务上验证了 SpeGCL 比现有 GCL 方法表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "13 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.10365v1",
      "published_date": "2024-10-14 10:39:38 UTC",
      "updated_date": "2024-10-14 10:39:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:27:15.910003"
    },
    {
      "arxiv_id": "2410.11580v1",
      "title": "LCD-Net: A Lightweight Remote Sensing Change Detection Network Combining Feature Fusion and Gating Mechanism",
      "title_zh": "LCD-Net: 结合特征融合和门控机制的轻",
      "authors": [
        "Wenyu Liu",
        "Jindong Li",
        "Haoji Wang",
        "Run Tan",
        "Yali Fu",
        "Qichuan Tian"
      ],
      "abstract": "Remote sensing image change detection (RSCD) is crucial for monitoring\ndynamic surface changes, with applications ranging from environmental\nmonitoring to disaster assessment. While traditional CNN-based methods have\nimproved detection accuracy, they often suffer from high computational\ncomplexity and large parameter counts, limiting their use in\nresource-constrained environments. To address these challenges, we propose a\nLightweight remote sensing Change Detection Network (LCD-Net in short) that\nreduces model size and computational cost while maintaining high detection\nperformance. LCD-Net employs MobileNetV2 as the encoder to efficiently extract\nfeatures from bitemporal images. A Temporal Interaction and Fusion Module (TIF)\nenhances the interaction between bitemporal features, improving temporal\ncontext awareness. Additionally, the Feature Fusion Module (FFM) aggregates\nmultiscale features to better capture subtle changes while suppressing\nbackground noise. The Gated Mechanism Module (GMM) in the decoder further\nenhances feature learning by dynamically adjusting channel weights, emphasizing\nkey change regions. Experiments on LEVIR-CD+, SYSU, and S2Looking datasets show\nthat LCD-Net achieves competitive performance with just 2.56M parameters and\n4.45G FLOPs, making it well-suited for real-time applications in\nresource-limited settings. The code is available at\nhttps://github.com/WenyuLiu6/LCD-Net.",
      "tldr_zh": "本论文针对遥感图像变化检测 (RSCD) 的计算复杂和高参数问题，提出了一种轻量级网络 LCD-Net，通过结合特征融合和门控机制来提升检测性能。LCD-Net 以 MobileNetV2 作为编码器提取双时相图像特征，并引入 Temporal Interaction and Fusion Module (TIF) 增强时间上下文交互、Feature Fusion Module (FFM) 聚合多尺度特征以捕捉细微变化，以及 Gated Mechanism Module (GMM) 在解码器中动态调整通道权重以强调关键区域。在 LEVIR-CD+、SYSU 和 S2Looking 数据集上的实验显示，LCD-Net 仅需 2.56M 参数和 4.45G FLOPs 即可实现竞争性性能，特别适合资源受限的实时应用。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.11580v1",
      "published_date": "2024-10-14 10:33:30 UTC",
      "updated_date": "2024-10-14 10:33:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:27:38.727855"
    },
    {
      "arxiv_id": "2410.10336v1",
      "title": "CoMAT: Chain of Mathematically Annotated Thought Improves Mathematical Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Joshua Ong Jun Leang",
        "Aryo Pradipta Gema",
        "Shay B. Cohen"
      ],
      "abstract": "Mathematical reasoning remains a significant challenge for large language\nmodels (LLMs), despite progress in prompting techniques such as\nChain-of-Thought (CoT). We present Chain of Mathematically Annotated Thought\n(CoMAT), which enhances reasoning through two stages: Symbolic Conversion\n(converting natural language queries into symbolic form) and Reasoning\nExecution (deriving answers from symbolic representations). CoMAT operates\nentirely with a single LLM and without external solvers. Across four LLMs,\nCoMAT outperforms traditional CoT on six out of seven benchmarks, achieving\ngains of 4.48% on MMLU-Redux (MATH) and 4.58% on GaoKao MCQ. In addition to\nimproved performance, CoMAT ensures faithfulness and verifiability, offering a\ntransparent reasoning process for complex mathematical tasks",
      "tldr_zh": "该研究提出了 CoMAT（Chain of Mathematically Annotated Thought），一种改进大语言模型（LLMs）数学推理的方法，通过 Symbolic Conversion（将自然语言查询转换为符号形式）和 Reasoning Execution（从符号表示中推导出答案）两个阶段，仅使用单个 LLM 进行操作。相比传统 Chain-of-Thought (CoT)，CoMAT 在七个基准测试中表现优异，在六个基准上取得提升，包括 MMLU-Redux (MATH) 的 4.48% 和 GaoKao MCQ 的 4.58%。此外，CoMAT 确保了推理过程的忠实性和可验证性，提供透明且可靠的数学任务处理方式。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.SC"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages, 12 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.10336v1",
      "published_date": "2024-10-14 09:48:41 UTC",
      "updated_date": "2024-10-14 09:48:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:27:50.197139"
    },
    {
      "arxiv_id": "2410.10332v1",
      "title": "Disentangling Hate Across Target Identities",
      "title_zh": "翻译失败",
      "authors": [
        "Yiping Jin",
        "Leo Wanner",
        "Aneesh Moideen Koya"
      ],
      "abstract": "Hate speech (HS) classifiers do not perform equally well in detecting hateful\nexpressions towards different target identities. They also demonstrate\nsystematic biases in predicted hatefulness scores. Tapping on two recently\nproposed functionality test datasets for HS detection, we quantitatively\nanalyze the impact of different factors on HS prediction. Experiments on\npopular industrial and academic models demonstrate that HS detectors assign a\nhigher hatefulness score merely based on the mention of specific target\nidentities. Besides, models often confuse hatefulness and the polarity of\nemotions. This result is worrisome as the effort to build HS detectors might\nharm the vulnerable identity groups we wish to protect: posts expressing anger\nor disapproval of hate expressions might be flagged as hateful themselves. We\nalso carry out a study inspired by social psychology theory, which reveals that\nthe accuracy of hatefulness prediction correlates strongly with the intensity\nof the stereotype.",
      "tldr_zh": "本研究分析了仇恨言论 (HS) 分类器在检测针对不同目标 identities 的仇恨表达时的表现不均等和系统偏差。通过两个功能测试数据集进行定量实验，评估了流行工业和学术模型的性能，发现这些模型仅基于特定 identities 的提及就分配更高仇恨分数，并经常混淆仇恨性与情感极性，导致表达愤怒或反对仇恨的帖子被错误标记。基于社会心理学理论的进一步研究显示，仇恨预测准确性与刻板印象强度高度相关，这可能加剧对脆弱群体的伤害，并强调了改进 HS 检测器以保护这些群体的必要性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.10332v1",
      "published_date": "2024-10-14 09:43:08 UTC",
      "updated_date": "2024-10-14 09:43:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:28:01.761605"
    },
    {
      "arxiv_id": "2410.10329v4",
      "title": "GraphCLIP: Enhancing Transferability in Graph Foundation Models for Text-Attributed Graphs",
      "title_zh": "GraphCLIP：针对文本属性图的图基础模型可转移性增强",
      "authors": [
        "Yun Zhu",
        "Haizhou Shi",
        "Xiaotang Wang",
        "Yongchao Liu",
        "Yaoke Wang",
        "Boci Peng",
        "Chuntao Hong",
        "Siliang Tang"
      ],
      "abstract": "Recently, research on Text-Attributed Graphs (TAGs) has gained significant\nattention due to the prevalence of free-text node features in real-world\napplications and the advancements in Large Language Models (LLMs) that bolster\nTAG methodologies. However, current TAG approaches face two primary challenges:\n(i) Heavy reliance on label information and (ii) Limited cross-domain\nzero/few-shot transferability. These issues constrain the scaling of both data\nand model size, owing to high labor costs and scaling laws, complicating the\ndevelopment of graph foundation models with strong transferability. In this\nwork, we propose the GraphCLIP framework to address these challenges by\nlearning graph foundation models with strong cross-domain zero/few-shot\ntransferability through a self-supervised contrastive graph-summary pretraining\nmethod. Specifically, we generate and curate large-scale graph-summary pair\ndata with the assistance of LLMs, and introduce a novel graph-summary\npretraining method, combined with invariant learning, to enhance graph\nfoundation models with strong cross-domain zero-shot transferability. For\nfew-shot learning, we propose a novel graph prompt tuning technique aligned\nwith our pretraining objective to mitigate catastrophic forgetting and minimize\nlearning costs. Extensive experiments show the superiority of GraphCLIP in both\nzero-shot and few-shot settings, while evaluations across various downstream\ntasks confirm the versatility of GraphCLIP. Our code is available at:\nhttps://github.com/ZhuYun97/GraphCLIP",
      "tldr_zh": "该研究针对 Text-Attributed Graphs (TAGs) 的两大挑战——过度依赖标签信息和跨域零样本/少样本迁移能力有限——提出了 GraphCLIP 框架，通过自监督对比学习和图-摘要预训练方法，利用 Large Language Models (LLMs) 生成数据，并结合不变性学习 (invariant learning) 来增强图基础模型的迁移性能。对于少样本学习，框架引入图提示调优 (graph prompt tuning) 技术，以减少灾难性遗忘并降低成本。实验结果表明，GraphCLIP 在零样本和少样本设置中显著优于基线，并在各种下游任务上展示了其通用性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to WWW'25",
      "pdf_url": "http://arxiv.org/pdf/2410.10329v4",
      "published_date": "2024-10-14 09:40:52 UTC",
      "updated_date": "2025-02-24 09:34:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:28:13.187154"
    },
    {
      "arxiv_id": "2410.10320v1",
      "title": "DiRW: Path-Aware Digraph Learning for Heterophily",
      "title_zh": "翻译失败",
      "authors": [
        "Daohan Su",
        "Xunkai Li",
        "Zhenjun Li",
        "Yinping Liao",
        "Rong-Hua Li",
        "Guoren Wang"
      ],
      "abstract": "Recently, graph neural network (GNN) has emerged as a powerful representation\nlearning tool for graph-structured data. However, most approaches are tailored\nfor undirected graphs, neglecting the abundant information embedded in the\nedges of directed graphs (digraphs). In fact, digraphs are widely applied in\nthe real world (e.g., social networks and recommendations) and are also\nconfirmed to offer a new perspective for addressing topological heterophily\nchallenges (i.e., connected nodes have complex patterns of feature distribution\nor labels). Despite recent significant advancements in DiGNNs, existing\nspatial- and spectral-based methods have inherent limitations due to the\ncomplex learning mechanisms and reliance on high-quality topology, leading to\nlow efficiency and unstable performance. To address these issues, we propose\nDirected Random Walk (DiRW), which can be viewed as a plug-and-play strategy or\nan innovative neural architecture that provides a guidance or new learning\nparadigm for most spatial-based methods or digraphs. Specifically, DiRW\nincorporates a direction-aware path sampler optimized from the perspectives of\nwalk probability, length, and number in a weight-free manner by considering\nnode profiles and topological structure. Building upon this, DiRW utilizes a\nnode-wise learnable path aggregator for generalized messages obtained by our\nproposed adaptive walkers to represent the current node. Extensive experiments\non 9 datasets demonstrate that DiRW: (1) enhances most spatial-based methods as\na plug-and-play strategy; (2) achieves SOTA performance as a new digraph\nlearning paradigm.",
      "tldr_zh": "该论文针对图神经网络 (GNN) 在有向图 (digraphs) 学习中的局限性，提出 DiRW 方法，以处理拓扑异质性 (heterophily) 挑战，如节点特征分布的复杂模式。DiRW 采用 Directed Random Walk 策略，包括一个方向感知路径采样器（优化游走概率、长度和数量，并考虑节点特征和拓扑结构），以及节点-wise 可学习路径聚合器，用于高效聚合消息并表示节点。实验在 9 个数据集上证明，DiRW 作为即插即用策略能提升大多数空间-based 方法，并作为新有向图学习范式实现 SOTA 性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Under Review",
      "pdf_url": "http://arxiv.org/pdf/2410.10320v1",
      "published_date": "2024-10-14 09:26:56 UTC",
      "updated_date": "2024-10-14 09:26:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:28:29.145295"
    },
    {
      "arxiv_id": "2410.10315v2",
      "title": "EasyRAG: Efficient Retrieval-Augmented Generation Framework for Automated Network Operations",
      "title_zh": "EasyRAG：高效检索增强生成框架，用于",
      "authors": [
        "Zhangchi Feng",
        "Dongdong Kuang",
        "Zhongyuan Wang",
        "Zhijie Nie",
        "Yaowei Zheng",
        "Richong Zhang"
      ],
      "abstract": "This paper presents EasyRAG, a simple, lightweight, and efficient\nretrieval-augmented generation framework for automated network operations. Our\nframework has three advantages. The first is accurate question answering. We\ndesigned a straightforward RAG scheme based on (1) a specific data processing\nworkflow (2) dual-route sparse retrieval for coarse ranking (3) LLM Reranker\nfor reranking (4) LLM answer generation and optimization. This approach\nachieved first place in the GLM4 track in the preliminary round and second\nplace in the GLM4 track in the semifinals. The second is simple deployment. Our\nmethod primarily consists of BM25 retrieval and BGE-reranker reranking,\nrequiring no fine-tuning of any models, occupying minimal VRAM, easy to deploy,\nand highly scalable; we provide a flexible code library with various search and\ngeneration strategies, facilitating custom process implementation. The last one\nis efficient inference. We designed an efficient inference acceleration scheme\nfor the entire coarse ranking, reranking, and generation process that\nsignificantly reduces the inference latency of RAG while maintaining a good\nlevel of accuracy; each acceleration scheme can be plug-and-play into any\ncomponent of the RAG process, consistently enhancing the efficiency of the RAG\nsystem. Our code and data are released at\n\\url{https://github.com/BUAADreamer/EasyRAG}.",
      "tldr_zh": "本论文提出EasyRAG，一种简单、轻量且高效的检索增强生成（RAG）框架，用于自动化网络操作。该框架的核心方法包括特定数据处理流程、双路由稀疏检索（dual-route sparse retrieval）、LLM Reranker重新排名以及LLM答案生成和优化，从而实现准确的问答，并在相关比赛中获得GLM4赛道的初步轮第一名和半决赛第二名。EasyRAG强调简单部署，通过BM25检索和BGE-reranker重新排名，无需模型微调、占用少量VRAM，并提供灵活的代码库以支持可扩展的自定义实现。此外，该框架设计了高效推理加速方案，显著降低RAG过程的延迟，同时保持准确性，并开源代码和数据以便进一步应用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.10315v2",
      "published_date": "2024-10-14 09:17:43 UTC",
      "updated_date": "2024-10-15 02:21:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:28:37.788947"
    },
    {
      "arxiv_id": "2410.10291v4",
      "title": "Evaluating Semantic Variation in Text-to-Image Synthesis: A Causal Perspective",
      "title_zh": "从因果视角评估文本到图像合成中的语义变异",
      "authors": [
        "Xiangru Zhu",
        "Penglei Sun",
        "Yaoxian Song",
        "Yanghua Xiao",
        "Zhixu Li",
        "Chengyu Wang",
        "Jun Huang",
        "Bei Yang",
        "Xiaoxiao Xu"
      ],
      "abstract": "Accurate interpretation and visualization of human instructions are crucial\nfor text-to-image (T2I) synthesis. However, current models struggle to capture\nsemantic variations from word order changes, and existing evaluations, relying\non indirect metrics like text-image similarity, fail to reliably assess these\nchallenges. This often obscures poor performance on complex or uncommon\nlinguistic patterns by the focus on frequent word combinations. To address\nthese deficiencies, we propose a novel metric called SemVarEffect and a\nbenchmark named SemVarBench, designed to evaluate the causality between\nsemantic variations in inputs and outputs in T2I synthesis. Semantic variations\nare achieved through two types of linguistic permutations, while avoiding\neasily predictable literal variations. Experiments reveal that the\nCogView-3-Plus and Ideogram 2 performed the best, achieving a score of 0.2/1.\nSemantic variations in object relations are less understood than attributes,\nscoring 0.07/1 compared to 0.17-0.19/1. We found that cross-modal alignment in\nUNet or Transformers plays a crucial role in handling semantic variations, a\nfactor previously overlooked by a focus on textual encoders. Our work\nestablishes an effective evaluation framework that advances the T2I synthesis\ncommunity's exploration of human instruction understanding. Our benchmark and\ncode are available at https://github.com/zhuxiangru/SemVarBench .",
      "tldr_zh": "本研究从因果视角评估文本到图像(T2I)合成的语义变化问题，指出现有模型难以捕捉词序等语义变异，而传统评估指标如文本-图像相似度无法准确衡量。论文提出SemVarEffect指标和SemVarBench基准，通过两种语言排列方式模拟语义变化，避免简单字面变异，从而量化输入输出间的因果关系。实验结果显示CogView-3-Plus和Ideogram 2表现最佳，得分0.2/1，且对象关系语义变异得分仅0.07/1，而属性变异得分0.17-0.19/1；此外，UNet或Transformers中的跨模态对齐被证明是关键因素。该框架为T2I合成社区提升人类指令理解提供了新评估工具，相关代码已在GitHub上发布。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.10291v4",
      "published_date": "2024-10-14 08:45:35 UTC",
      "updated_date": "2025-04-17 08:31:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:28:50.012667"
    },
    {
      "arxiv_id": "2410.10285v2",
      "title": "ABBA-VSM: Time Series Classification using Symbolic Representation on the Edge",
      "title_zh": "ABBA-VSM：使用符号表示在边缘的时间序列分类",
      "authors": [
        "Meerzhan Kanatbekova",
        "Shashikant Ilager",
        "Ivona Brandic"
      ],
      "abstract": "In recent years, Edge AI has become more prevalent with applications across\nvarious industries, from environmental monitoring to smart city management.\nEdge AI facilitates the processing of Internet of Things (IoT) data and\nprovides privacy-enabled and latency-sensitive services to application users\nusing Machine Learning (ML) algorithms, e.g., Time Series Classification (TSC).\nHowever, existing TSC algorithms require access to full raw data and demand\nsubstantial computing resources to train and use them effectively in runtime.\nThis makes them impractical for deployment in resource-constrained Edge\nenvironments. To address this, in this paper, we propose an Adaptive Brownian\nBridge-based Symbolic Aggregation Vector Space Model (ABBA-VSM). It is a new\nTSC model designed for classification services on Edge. Here, we first\nadaptively compress the raw time series into symbolic representations, thus\ncapturing the changing trends of data. Subsequently, we train the\nclassification model directly on these symbols. ABBA-VSM reduces communication\ndata between IoT and Edge devices, as well as computation cycles, in the\ndevelopment of resource-efficient TSC services on Edge. We evaluate our\nsolution with extensive experiments using datasets from the UCR time series\nclassification archive. The results demonstrate that the ABBA-VSM achieves up\nto 80% compression ratio and 90-100% accuracy for binary classification.\nWhereas, for non-binary classification, it achieves an average compression\nratio of 60% and accuracy ranging from 60-80%.",
      "tldr_zh": "本研究针对资源受限的Edge AI环境，提出了一种新的Time Series Classification (TSC)模型——ABBA-VSM，利用符号表示方法来优化TSC任务。方法包括先将原始时间序列自适应压缩成符号表示，以捕捉数据变化趋势，然后直接在这些符号上训练分类模型，从而减少IoT设备与Edge设备之间的通信数据和计算资源。实验结果显示，ABBA-VSM在UCR数据集上实现了高达80%的压缩比，对于二元分类准确率达90-100%，而非二元分类平均压缩比为60%且准确率在60-80%之间。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "15 pages with references, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.10285v2",
      "published_date": "2024-10-14 08:37:40 UTC",
      "updated_date": "2024-11-05 09:43:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:29:01.061885"
    },
    {
      "arxiv_id": "2410.10284v3",
      "title": "Trust or Bust: Ensuring Trustworthiness in Autonomous Weapon Systems",
      "title_zh": "信任或崩溃：确保自治武器系统的可信性",
      "authors": [
        "Kasper Cools",
        "Clara Maathuis"
      ],
      "abstract": "The integration of Autonomous Weapon Systems (AWS) into military operations\npresents both significant opportunities and challenges. This paper explores the\nmultifaceted nature of trust in AWS, emphasising the necessity of establishing\nreliable and transparent systems to mitigate risks associated with bias,\noperational failures, and accountability. Despite advancements in Artificial\nIntelligence (AI), the trustworthiness of these systems, especially in\nhigh-stakes military applications, remains a critical issue. Through a\nsystematic review of existing literature, this research identifies gaps in the\nunderstanding of trust dynamics during the development and deployment phases of\nAWS. It advocates for a collaborative approach that includes technologists,\nethicists, and military strategists to address these ongoing challenges. The\nfindings underscore the importance of Human-Machine teaming and enhancing\nsystem intelligibility to ensure accountability and adherence to International\nHumanitarian Law. Ultimately, this paper aims to contribute to the ongoing\ndiscourse on the ethical implications of AWS and the imperative for trustworthy\nAI in defense contexts.",
      "tldr_zh": "这篇论文探讨了Autonomous Weapon Systems (AWS)在军事应用中的可信度挑战，强调建立可靠透明的系统以缓解偏见、操作失败和责任问题。作者通过系统文献综述，识别了AWS开发和部署阶段的信任动态缺口，并倡导技术专家、伦理学家和军事战略家合作。论文突出了Human-Machine teaming和系统可理解性的重要性，以确保遵守International Humanitarian Law，并为可信AI在国防领域的伦理讨论提供贡献。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CY",
      "comment": "Accepted as a workshop paper at MILCOM 2024, 8 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.10284v3",
      "published_date": "2024-10-14 08:36:06 UTC",
      "updated_date": "2024-10-21 05:22:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:29:14.433071"
    },
    {
      "arxiv_id": "2410.10270v3",
      "title": "QUIS: Question-guided Insights Generation for Automated Exploratory Data Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Abhijit Manatkar",
        "Ashlesha Akella",
        "Parthivi Gupta",
        "Krishnasuri Narayanam"
      ],
      "abstract": "Discovering meaningful insights from a large dataset, known as Exploratory\nData Analysis (EDA), is a challenging task that requires thorough exploration\nand analysis of the data. Automated Data Exploration (ADE) systems use\ngoal-oriented methods with Large Language Models and Reinforcement Learning\ntowards full automation. However, these methods require human involvement to\nanticipate goals that may limit insight extraction, while fully automated\nsystems demand significant computational resources and retraining for new\ndatasets. We introduce QUIS, a fully automated EDA system that operates in two\nstages: insight generation (ISGen) driven by question generation (QUGen). The\nQUGen module generates questions in iterations, refining them from previous\niterations to enhance coverage without human intervention or manually curated\nexamples. The ISGen module analyzes data to produce multiple relevant insights\nin response to each question, requiring no prior training and enabling QUIS to\nadapt to new datasets.",
      "tldr_zh": "本研究提出 QUIS 系统，这是一个全自动的 Exploratory Data Analysis (EDA) 系统，用于从大型数据集发现有意义的洞见。QUIS 通过两阶段方法运作：question generation (QUGen) 模块迭代生成并精炼问题，以提升覆盖率，而无需人为干预或手动示例；insight generation (ISGen) 模块则针对每个问题分析数据，生成多个相关洞见。相较于依赖 Large Language Models 和 Reinforcement Learning 的 Automated Data Exploration (ADE) 方法，QUIS 不需预训练或重训练，即可适应新数据集，从而提高效率并减少资源消耗。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.DB",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted for EMNLP 2024 Industry Track",
      "pdf_url": "http://arxiv.org/pdf/2410.10270v3",
      "published_date": "2024-10-14 08:21:25 UTC",
      "updated_date": "2024-10-21 08:13:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:29:26.302708"
    },
    {
      "arxiv_id": "2410.10254v3",
      "title": "LoLCATs: On Low-Rank Linearizing of Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Michael Zhang",
        "Simran Arora",
        "Rahul Chalamala",
        "Alan Wu",
        "Benjamin Spector",
        "Aaryan Singhal",
        "Krithik Ramesh",
        "Christopher Ré"
      ],
      "abstract": "Recent works show we can linearize large language models (LLMs) -- swapping\nthe quadratic attentions of popular Transformer-based LLMs with subquadratic\nanalogs, such as linear attention -- avoiding the expensive pretraining costs.\nHowever, linearizing LLMs often significantly degrades model quality, still\nrequires training over billions of tokens, and remains limited to smaller 1.3B\nto 7B LLMs. We thus propose Low-rank Linear Conversion via Attention Transfer\n(LoLCATs), a simple two-step method that improves LLM linearizing quality with\norders of magnitudes less memory and compute. We base these steps on two\nfindings. First, we can replace an LLM's softmax attentions with\nclosely-approximating linear attentions, simply by training the linear\nattentions to match their softmax counterparts with an output MSE loss\n(\"attention transfer\"). Then, this enables adjusting for approximation errors\nand recovering LLM quality simply with low-rank adaptation (LoRA). LoLCATs\nsignificantly improves linearizing quality, training efficiency, and\nscalability. We significantly reduce the linearizing quality gap and produce\nstate-of-the-art subquadratic LLMs from Llama 3 8B and Mistral 7B v0.1, leading\nto 20+ points of improvement on 5-shot MMLU. Furthermore, LoLCATs does so with\nonly 0.2% of past methods' model parameters and 0.4% of their training tokens.\nFinally, we apply LoLCATs to create the first linearized 70B and 405B LLMs (50x\nlarger than prior work). When compared with prior approaches under the same\ncompute budgets, LoLCATs significantly improves linearizing quality, closing\nthe gap between linearized and original Llama 3.1 70B and 405B LLMs by 77.8%\nand 78.1% on 5-shot MMLU.",
      "tldr_zh": "本研究提出了一种名为 LoLCATs 的低秩线性转换方法，用于高效线性化大型语言模型 (LLMs)，以替换 Transformer 中的二次方 softmax attentions 为子二次方线性 attentions，从而降低预训练成本并提升模型质量。LoLCATs 通过两个步骤实现：首先，使用输出 MSE 损失训练线性 attentions 以匹配 softmax attentions（attention transfer）；其次，通过低秩适配 (LoRA) 调整近似误差以恢复模型性能。该方法显著提高了线性化效率和可扩展性，仅需过去方法的 0.2% 模型参数和 0.4% 训练标记，并在 Llama 3 8B 和 Mistral 7B v0.1 上实现了 20+ 分的 5-shot MMLU 改进，甚至成功创建了首个线性化的 70B 和 405B LLMs，将性能差距缩小了 77.8% 和 78.1%。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "58 pages, 25 figures, 26 tables, ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.10254v3",
      "published_date": "2024-10-14 08:10:34 UTC",
      "updated_date": "2025-03-05 21:57:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:29:38.552565"
    },
    {
      "arxiv_id": "2410.10253v3",
      "title": "Feedback Favors the Generalization of Neural ODEs",
      "title_zh": "反馈有利于神经常微分方程的泛化",
      "authors": [
        "Jindou Jia",
        "Zihan Yang",
        "Meng Wang",
        "Kexin Guo",
        "Jianfei Yang",
        "Xiang Yu",
        "Lei Guo"
      ],
      "abstract": "The well-known generalization problem hinders the application of artificial\nneural networks in continuous-time prediction tasks with varying latent\ndynamics. In sharp contrast, biological systems can neatly adapt to evolving\nenvironments benefiting from real-time feedback mechanisms. Inspired by the\nfeedback philosophy, we present feedback neural networks, showing that a\nfeedback loop can flexibly correct the learned latent dynamics of neural\nordinary differential equations (neural ODEs), leading to a prominent\ngeneralization improvement. The feedback neural network is a novel two-DOF\nneural network, which possesses robust performance in unseen scenarios with no\nloss of accuracy performance on previous tasks.} A linear feedback form is\npresented to correct the learned latent dynamics firstly, with a convergence\nguarantee. Then, domain randomization is utilized to learn a nonlinear neural\nfeedback form. Finally, extensive tests including trajectory prediction of a\nreal irregular object and model predictive control of a quadrotor with various\nuncertainties, are implemented, indicating significant improvements over\nstate-of-the-art model-based and learning-based methods.",
      "tldr_zh": "这篇论文针对神经ODEs（Neural ODEs）在连续时间预测任务中的泛化问题，提出了一种受生物反馈机制启发的反馈神经网络（feedback neural networks）。该网络采用两自由度（two-DOF）设计，通过线性反馈形式修正潜在动态并提供收敛保证，随后利用domain randomization学习非线性反馈形式，以提升在未见场景下的鲁棒性，同时保持原有任务的准确性。实验结果显示，该方法在真实不规则物体轨迹预测和四旋翼无人机模型预测控制等任务中，比现有基于模型和学习的方法有显著改进。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "27 pages, 23 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.10253v3",
      "published_date": "2024-10-14 08:09:45 UTC",
      "updated_date": "2025-03-07 02:53:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:29:49.325192"
    },
    {
      "arxiv_id": "2410.10247v2",
      "title": "LOBG:Less Overfitting for Better Generalization in Vision-Language Model",
      "title_zh": "翻译失败",
      "authors": [
        "Chenhao Ding",
        "Xinyuan Gao",
        "Songlin Dong",
        "Yuhang He",
        "Qiang Wang",
        "Alex Kot",
        "Yihong Gong"
      ],
      "abstract": "Existing prompt learning methods in Vision-Language Models (VLM) have\neffectively enhanced the transfer capability of VLM to downstream tasks, but\nthey suffer from a significant decline in generalization due to severe\noverfitting. To address this issue, we propose a framework named LOBG for\nvision-language models. Specifically, we use CLIP to filter out fine-grained\nforeground information that might cause overfitting, thereby guiding prompts\nwith basic visual concepts. To further mitigate overfitting, we devel oped a\nstructural topology preservation (STP) loss at the feature level, which endows\nthe feature space with overall plasticity, allowing effective reshaping of the\nfeature space during optimization. Additionally, we employed hierarchical logit\ndistilation (HLD) at the output level to constrain outputs, complementing STP\nat the output end. Extensive experimental results demonstrate that our method\nsignificantly improves generalization capability and alleviates overfitting\ncompared to state-of-the-art approaches.",
      "tldr_zh": "本研究针对视觉语言模型 (VLM) 中提示学习方法的过度拟合问题，提出了一种名为 LOBG 的框架，以提升模型的泛化能力。LOBG 框架通过使用 CLIP 过滤可能导致过度拟合的细粒度前景信息，引导提示学习基于基本视觉概念；同时引入结构拓扑保留 (STP) 损失在特征级别重塑特征空间，以及分层 logit 蒸馏 (HLD) 在输出级别约束模型输出。实验结果表明，该方法显著提高了 VLM 的泛化性能，并减轻了过度拟合，比现有先进方法表现更优。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.10247v2",
      "published_date": "2024-10-14 08:06:21 UTC",
      "updated_date": "2024-10-27 10:40:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:30:01.404613"
    },
    {
      "arxiv_id": "2410.10241v1",
      "title": "Revisiting and Benchmarking Graph Autoencoders: A Contrastive Learning Perspective",
      "title_zh": "重访和基准测试图自编码器：对比学习视角",
      "authors": [
        "Jintang Li",
        "Ruofan Wu",
        "Yuchang Zhu",
        "Huizhe Zhang",
        "Xinzhou Jin",
        "Guibin Zhang",
        "Zulun Zhu",
        "Zibin Zheng",
        "Liang Chen"
      ],
      "abstract": "Graph autoencoders (GAEs) are self-supervised learning models that can learn\nmeaningful representations of graph-structured data by reconstructing the input\ngraph from a low-dimensional latent space. Over the past few years, GAEs have\ngained significant attention in academia and industry. In particular, the\nrecent advent of GAEs with masked autoencoding schemes marks a significant\nadvancement in graph self-supervised learning research. While numerous GAEs\nhave been proposed, the underlying mechanisms of GAEs are not well understood,\nand a comprehensive benchmark for GAEs is still lacking. In this work, we\nbridge the gap between GAEs and contrastive learning by establishing conceptual\nand methodological connections. We revisit the GAEs studied in previous works\nand demonstrate how contrastive learning principles can be applied to GAEs.\nMotivated by these insights, we introduce lrGAE (left-right GAE), a general and\npowerful GAE framework that leverages contrastive learning principles to learn\nmeaningful representations. Our proposed lrGAE not only facilitates a deeper\nunderstanding of GAEs but also sets a new benchmark for GAEs across diverse\ngraph-based learning tasks. The source code for lrGAE, including the baselines\nand all the code for reproducing the results, is publicly available at\nhttps://github.com/EdisonLeeeee/lrGAE.",
      "tldr_zh": "该论文审视了 Graph Autoencoders (GAEs)，这些自监督模型通过重建输入图来学习图结构数据的低维表示，并指出了现有GAEs机制理解不足的问题。作者从对比学习（contrastive learning）的角度建立了GAEs的理论联系，并引入了lrGAE（left-right GAE）框架，该框架利用对比学习原则来提升表示学习效果。实验结果显示，lrGAE在各种图-based学习任务中设置了新基准，并提供了公开源代码以便复现。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Preprint, under review",
      "pdf_url": "http://arxiv.org/pdf/2410.10241v1",
      "published_date": "2024-10-14 07:59:30 UTC",
      "updated_date": "2024-10-14 07:59:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:30:13.767161"
    },
    {
      "arxiv_id": "2410.10238v2",
      "title": "ForgeryGPT: Multimodal Large Language Model For Explainable Image Forgery Detection and Localization",
      "title_zh": "翻译失败",
      "authors": [
        "Jiawei Liu",
        "Fanrui Zhang",
        "Jiaying Zhu",
        "Esther Sun",
        "Qiang Zhang",
        "Zheng-Jun Zha"
      ],
      "abstract": "Multimodal Large Language Models (MLLMs), such as GPT4o, have shown strong\ncapabilities in visual reasoning and explanation generation. However, despite\nthese strengths, they face significant challenges in the increasingly critical\ntask of Image Forgery Detection and Localization (IFDL). Moreover, existing\nIFDL methods are typically limited to the learning of low-level\nsemantic-agnostic clues and merely provide a single outcome judgment. To tackle\nthese issues, we propose ForgeryGPT, a novel framework that advances the IFDL\ntask by capturing high-order forensics knowledge correlations of forged images\nfrom diverse linguistic feature spaces, while enabling explainable generation\nand interactive dialogue through a newly customized Large Language Model (LLM)\narchitecture. Specifically, ForgeryGPT enhances traditional LLMs by integrating\nthe Mask-Aware Forgery Extractor, which enables the excavating of precise\nforgery mask information from input images and facilitating pixel-level\nunderstanding of tampering artifacts. The Mask-Aware Forgery Extractor consists\nof a Forgery Localization Expert (FL-Expert) and a Mask Encoder, where the\nFL-Expert is augmented with an Object-agnostic Forgery Prompt and a\nVocabulary-enhanced Vision Encoder, allowing for effectively capturing of\nmulti-scale fine-grained forgery details. To enhance its performance, we\nimplement a three-stage training strategy, supported by our designed Mask-Text\nAlignment and IFDL Task-Specific Instruction Tuning datasets, which align\nvision-language modalities and improve forgery detection and\ninstruction-following capabilities. Extensive experiments demonstrate the\neffectiveness of the proposed method.",
      "tldr_zh": "本文提出 ForgeryGPT，一种多模态大语言模型 (MLLMs) 框架，用于可解释的图像篡改检测和定位 (IFDL)，旨在解决现有方法仅捕捉低级语义无关线索和缺乏交互解释的问题。该框架通过整合 Mask-Aware Forgery Extractor，包括 Forgery Localization Expert (FL-Expert) 和 Mask Encoder，利用 Object-agnostic Forgery Prompt 和 Vocabulary-enhanced Vision Encoder 来精确提取多尺度细粒度伪造细节，并支持交互对话。采用三阶段训练策略，结合 Mask-Text Alignment 和 IFDL Task-Specific Instruction Tuning 数据集，提升视觉语言模态对齐和指令遵循能力。实验结果证明，ForgeryGPT 在 IFDL 任务中表现出色，验证了其有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "16 pages, 14 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.10238v2",
      "published_date": "2024-10-14 07:56:51 UTC",
      "updated_date": "2025-01-06 07:39:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:30:26.338843"
    },
    {
      "arxiv_id": "2410.10229v1",
      "title": "BanglaQuAD: A Bengali Open-domain Question Answering Dataset",
      "title_zh": "翻译失败",
      "authors": [
        "Md Rashad Al Hasan Rony",
        "Sudipto Kumar Shaha",
        "Rakib Al Hasan",
        "Sumon Kanti Dey",
        "Amzad Hossain Rafi",
        "Amzad Hossain Rafi",
        "Ashraf Hasan Sirajee",
        "Jens Lehmann"
      ],
      "abstract": "Bengali is the seventh most spoken language on earth, yet considered a\nlow-resource language in the field of natural language processing (NLP).\nQuestion answering over unstructured text is a challenging NLP task as it\nrequires understanding both question and passage. Very few researchers\nattempted to perform question answering over Bengali (natively pronounced as\nBangla) text. Typically, existing approaches construct the dataset by directly\ntranslating them from English to Bengali, which produces noisy and improper\nsentence structures. Furthermore, they lack topics and terminologies related to\nthe Bengali language and people. This paper introduces BanglaQuAD, a Bengali\nquestion answering dataset, containing 30,808 question-answer pairs constructed\nfrom Bengali Wikipedia articles by native speakers. Additionally, we propose an\nannotation tool that facilitates question-answering dataset construction on a\nlocal machine. A qualitative analysis demonstrates the quality of our proposed\ndataset.",
      "tldr_zh": "本文介绍了 BanglaQuAD，一个针对 Bengali（全球第七大语言）开放域问答的 Bengali 问答数据集，旨在解决 NLP 中低资源语言的挑战。不同于现有方法直接翻译英语数据集导致的噪声和不准确问题，BanglaQuAD 由母语者从 Bengali Wikipedia 文章构建，共包含 30,808 个问题-答案对，并更贴合 Bengali 语言和文化。作者还提出一个本地注解工具来辅助数据集建设，并通过定性分析证明了数据集的质量和可靠性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted into LREC-COLING 2024, Turin, Italy",
      "pdf_url": "http://arxiv.org/pdf/2410.10229v1",
      "published_date": "2024-10-14 07:39:59 UTC",
      "updated_date": "2024-10-14 07:39:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:30:47.717820"
    },
    {
      "arxiv_id": "2410.10228v1",
      "title": "QE-EBM: Using Quality Estimators as Energy Loss for Machine Translation",
      "title_zh": "翻译失败",
      "authors": [
        "Gahyun Yoo",
        "Jay Yoon Lee"
      ],
      "abstract": "Reinforcement learning has shown great promise in aligning language models\nwith human preferences in a variety of text generation tasks, including machine\ntranslation. For translation tasks, rewards can easily be obtained from quality\nestimation (QE) models which can generate rewards for unlabeled data. Despite\nits usefulness, reinforcement learning cannot exploit the gradients with\nrespect to the QE score. We propose QE-EBM, a method of employing quality\nestimators as trainable loss networks that can directly backpropagate to the\nNMT model. We examine our method on several low and high resource target\nlanguages with English as the source language. QE-EBM outperforms strong\nbaselines such as REINFORCE and proximal policy optimization (PPO) as well as\nsupervised fine-tuning for all target languages, especially low-resource target\nlanguages. Most notably, for English-to-Mongolian translation, our method\nachieves improvements of 2.5 BLEU, 7.1 COMET-KIWI, 5.3 COMET, and 6.4 XCOMET\nrelative to the supervised baseline.",
      "tldr_zh": "本研究提出QE-EBM方法，将质量估计器(Quality Estimators)用作能量损失(Energy Loss)，以直接反向传播梯度到神经机器翻译(NMT)模型，从而解决强化学习(Reinforcement Learning)无法利用QE分数梯度的局限。相比传统方法如REINFORCE和近端策略优化(PPO)，QE-EBM在英语到多种低资源和高资源目标语言的翻译任务中表现出色，尤其在低资源语言上。实验结果显示，对于英语到蒙古语翻译，该方法相对于监督基线提升了2.5 BLEU、7.1 COMET-KIWI、5.3 COMET和6.4 XCOMET分数。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.10228v1",
      "published_date": "2024-10-14 07:39:33 UTC",
      "updated_date": "2024-10-14 07:39:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:30:49.493280"
    },
    {
      "arxiv_id": "2410.10212v2",
      "title": "Large Language Model-Enhanced Reinforcement Learning for Generic Bus Holding Control Strategies",
      "title_zh": "大语言模型增强的强化学习用于通用公共汽车停车控制策略",
      "authors": [
        "Jiajie Yu",
        "Yuhong Wang",
        "Wei Ma"
      ],
      "abstract": "Bus holding control is a widely-adopted strategy for maintaining stability\nand improving the operational efficiency of bus systems. Traditional\nmodel-based methods often face challenges with the low accuracy of bus state\nprediction and passenger demand estimation. In contrast, Reinforcement Learning\n(RL), as a data-driven approach, has demonstrated great potential in\nformulating bus holding strategies. RL determines the optimal control\nstrategies in order to maximize the cumulative reward, which reflects the\noverall control goals. However, translating sparse and delayed control goals in\nreal-world tasks into dense and real-time rewards for RL is challenging,\nnormally requiring extensive manual trial-and-error. In view of this, this\nstudy introduces an automatic reward generation paradigm by leveraging the\nin-context learning and reasoning capabilities of Large Language Models (LLMs).\nThis new paradigm, termed the LLM-enhanced RL, comprises several LLM-based\nmodules: reward initializer, reward modifier, performance analyzer, and reward\nrefiner. These modules cooperate to initialize and iteratively improve the\nreward function according to the feedback from training and test results for\nthe specified RL-based task. Ineffective reward functions generated by the LLM\nare filtered out to ensure the stable evolution of the RL agents' performance\nover iterations. To evaluate the feasibility of the proposed LLM-enhanced RL\nparadigm, it is applied to extensive bus holding control scenarios that vary in\nthe number of bus lines, stops, and passenger demand. The results demonstrate\nthe superiority, generalization capability, and robustness of the proposed\nparadigm compared to vanilla RL strategies, the LLM-based controller,\nphysics-based feedback controllers, and optimization-based controllers. This\nstudy sheds light on the great potential of utilizing LLMs in various smart\nmobility applications.",
      "tldr_zh": "本文提出一种利用 Large Language Models (LLMs) 增强的 Reinforcement Learning (RL) 范式，用于开发通用的公交持仓控制策略，以解决传统方法在公交状态预测和乘客需求估计上的准确性问题。 该范式包括几个 LLM-based 模块，如 reward initializer、reward modifier、performance analyzer 和 reward refiner，这些模块合作自动初始化和迭代优化奖励函数，从而避免了手动试错。 通过在不同公交线路、站点和乘客需求场景下的实验验证，该方法相较于 vanilla RL、LLM-based controller、physics-based feedback controllers 和 optimization-based controllers，展示了更高的优越性、泛化能力和鲁棒性。 这为 LLMs 在智能交通等领域的应用提供了新颖的潜力。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "51 pages, 19 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.10212v2",
      "published_date": "2024-10-14 07:10:16 UTC",
      "updated_date": "2025-04-13 14:17:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:31:02.687761"
    },
    {
      "arxiv_id": "2410.19777v1",
      "title": "Deep Learning-driven Mobile Traffic Measurement Collection and Analysis",
      "title_zh": "深度学习驱动的移动流量测量收集和分析",
      "authors": [
        "Yini Fang"
      ],
      "abstract": "Modelling dynamic traffic patterns and especially the continuously changing\ndependencies between different base stations, which previous studies overlook,\nis challenging. Traditional algorithms struggle to process large volumes of\ndata and to extract deep insights that help elucidate mobile traffic demands\nwith fine granularity, as well as how these demands will evolve in the future.\nTherefore, in this thesis we harness the powerful hierarchical feature learning\nabilities of Deep Learning (DL) techniques in both spatial and temporal domains\nand develop solutions for precise city-scale mobile traffic analysis and\nforecasting. Firstly, we design Spider, a mobile traffic measurement collection\nand reconstruction framework with a view to reducing the cost of measurement\ncollection and inferring traffic consumption with high accuracy, despite\nworking with sparse information. In particular, we train a reinforcement\nlearning agent to selectively sample subsets of target mobile coverage areas\nand tackle the large action space problem specific to this setting. We then\nintroduce a lightweight neural network model to reconstruct the traffic\nconsumption based on historical sparse measurements. Our proposed framework\noutperforms existing solutions on a real-world mobile traffic dataset.\nSecondly, we design SDGNet, a handover-aware graph neural network model for\nlong-term mobile traffic forecasting. We model the cellular network as a graph,\nand leverage handover frequency to capture the dependencies between base\nstations across time. Handover information reflects user mobility such as daily\ncommute, which helps in increasing the accuracy of the forecasts made. We\nproposed dynamic graph convolution to extract features from both traffic\nconsumption and handover data, showing that our model outperforms other\nbenchmark graph models on a mobile traffic dataset collected by a major network\noperator.",
      "tldr_zh": "该论文探讨了使用深度学习（Deep Learning）技术来处理移动流量测量、分析和预测的挑战，特别是在捕捉基站间动态依赖性方面。作者提出了 Spider 框架，通过强化学习（reinforcement learning）代理选择性地采样稀疏数据，并使用轻量级神经网络重建流量消费数据，在真实数据集上优于现有解决方案。论文还引入了 SDGNet，一种 handover-aware 的图神经网络（graph neural network）模型，通过动态图卷积提取流量和 handover 信息进行长期预测，显著提高了准确性。总体而言，这些方法为精细化的城市规模移动流量分析和预测提供了高效解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "MPhil thesis",
      "pdf_url": "http://arxiv.org/pdf/2410.19777v1",
      "published_date": "2024-10-14 06:53:45 UTC",
      "updated_date": "2024-10-14 06:53:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:31:13.395732"
    },
    {
      "arxiv_id": "2410.10190v2",
      "title": "Predicting from Strings: Language Model Embeddings for Bayesian Optimization",
      "title_zh": "基于字符串预测：语言模型嵌入用于贝叶斯优化",
      "authors": [
        "Tung Nguyen",
        "Qiuyi Zhang",
        "Bangding Yang",
        "Chansoo Lee",
        "Jorg Bornschein",
        "Yingjie Miao",
        "Sagi Perel",
        "Yutian Chen",
        "Xingyou Song"
      ],
      "abstract": "Bayesian Optimization is ubiquitous in the field of experimental design and\nblackbox optimization for improving search efficiency, but has been\ntraditionally restricted to regression models which are only applicable to\nfixed search spaces and tabular input features. We propose Embed-then-Regress,\na paradigm for applying in-context regression over string inputs, through the\nuse of string embedding capabilities of pretrained language models. By\nexpressing all inputs as strings, we are able to perform general-purpose\nregression for Bayesian Optimization over various domains including synthetic,\ncombinatorial, and hyperparameter optimization, obtaining comparable results to\nstate-of-the-art Gaussian Process-based algorithms. Code can be found at\nhttps://github.com/google-research/optformer/tree/main/optformer/embed_then_regress.",
      "tldr_zh": "这篇论文提出 Embed-then-Regress 范式，用于扩展 Bayesian Optimization 到字符串输入，解决传统回归模型仅适用于固定搜索空间和表格特征的局限性。该方法利用预训练语言模型的字符串嵌入能力，进行 in-context 回归，将所有输入表示为字符串，从而实现通用回归应用于合成、组合和超参数优化领域。实验结果显示，该方法在这些领域取得了与最先进的 Gaussian Process-based 算法相当的表现。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.10190v2",
      "published_date": "2024-10-14 06:22:11 UTC",
      "updated_date": "2024-10-15 17:23:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:31:25.207884"
    },
    {
      "arxiv_id": "2410.10184v1",
      "title": "Eliminating the Language Bias for Visual Question Answering with fine-grained Causal Intervention",
      "title_zh": "翻译失败",
      "authors": [
        "Ying Liu",
        "Ge Bai",
        "Chenji Lu",
        "Shilong Li",
        "Zhang Zhang",
        "Ruifang Liu",
        "Wenbin Guo"
      ],
      "abstract": "Despite the remarkable advancements in Visual Question Answering (VQA), the\nchallenge of mitigating the language bias introduced by textual information\nremains unresolved. Previous approaches capture language bias from a\ncoarse-grained perspective. However, the finer-grained information within a\nsentence, such as context and keywords, can result in different biases. Due to\nthe ignorance of fine-grained information, most existing methods fail to\nsufficiently capture language bias. In this paper, we propose a novel causal\nintervention training scheme named CIBi to eliminate language bias from a\nfiner-grained perspective. Specifically, we divide the language bias into\ncontext bias and keyword bias. We employ causal intervention and contrastive\nlearning to eliminate context bias and improve the multi-modal representation.\nAdditionally, we design a new question-only branch based on counterfactual\ngeneration to distill and eliminate keyword bias. Experimental results\nillustrate that CIBi is applicable to various VQA models, yielding competitive\nperformance.",
      "tldr_zh": "尽管 Visual Question Answering (VQA) 取得了显著进展，但语言偏差问题依然存在，现有方法未能从细粒度角度充分捕获如上下文和关键词的偏差。论文提出了一种新型训练方案 CIBi，通过因果干预（causal intervention）和对比学习（contrastive learning）来消除上下文偏差，并改善多模态表示；同时，设计了一个基于反事实生成（counterfactual generation）的 question-only branch 来提炼和去除关键词偏差。主要贡献在于，CIBi 适用于多种 VQA 模型，并在实验中实现了竞争性的性能提升。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.10184v1",
      "published_date": "2024-10-14 06:09:16 UTC",
      "updated_date": "2024-10-14 06:09:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:31:37.602965"
    },
    {
      "arxiv_id": "2410.10181v2",
      "title": "Scalable Multi-Domain Adaptation of Language Models using Modular Experts",
      "title_zh": "翻译失败",
      "authors": [
        "Peter Schafhalter",
        "Shun Liao",
        "Yanqi Zhou",
        "Chih-Kuan Yeh",
        "Arun Kandoor",
        "James Laudon"
      ],
      "abstract": "Domain-specific adaptation is critical to maximizing the performance of\npre-trained language models (PLMs) on one or multiple targeted tasks,\nespecially under resource-constrained use cases, such as edge devices. However,\nexisting methods often struggle to balance domain-specific performance,\nretention of general knowledge, and efficiency for training and inference. To\naddress these challenges, we propose Modular Domain Experts (MoDE). MoDE is a\nmixture-of-experts architecture that augments a general PLMs with modular,\ndomain-specialized experts. These experts are trained independently and\ncomposed together via a lightweight training process. In contrast to standard\nlow-rank adaptation methods, each MoDE expert consists of several transformer\nlayers which scale better with more training examples and larger parameter\ncounts. Our evaluation demonstrates that MoDE achieves comparable target\nperformances to full parameter fine-tuning while achieving 1.65% better\nretention performance. Moreover, MoDE's architecture enables flexible sharding\nconfigurations and improves training speeds by up to 38% over state-of-the-art\ndistributed training configurations.",
      "tldr_zh": "该研究提出 Modular Domain Experts (MoDE)，一种混合专家架构，用于在资源受限环境下（如边缘设备）对预训练语言模型 (PLMs) 进行可扩展的多领域适应，以平衡领域特定性能、一般知识保留以及训练推理效率。MoDE 通过添加模块化、领域专化的专家，这些专家独立训练并通过轻量级过程组合，与标准低秩适应方法不同，其每个专家由多个 transformer layers 组成，能更好地扩展到更多训练示例和更大参数量。实验结果表明，MoDE 实现了与全参数微调相当的目标性能，同时保留性能提高了 1.65%，并通过灵活的分片配置将训练速度提升高达 38%。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "14 pages, 5 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2410.10181v2",
      "published_date": "2024-10-14 06:02:56 UTC",
      "updated_date": "2024-10-24 05:04:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:31:51.390031"
    },
    {
      "arxiv_id": "2410.13893v1",
      "title": "Can LLMs be Scammed? A Baseline Measurement Study",
      "title_zh": "翻译失败",
      "authors": [
        "Udari Madhushani Sehwag",
        "Kelly Patel",
        "Francesca Mosca",
        "Vineeth Ravi",
        "Jessica Staddon"
      ],
      "abstract": "Despite the importance of developing generative AI models that can\neffectively resist scams, current literature lacks a structured framework for\nevaluating their vulnerability to such threats. In this work, we address this\ngap by constructing a benchmark based on the FINRA taxonomy and systematically\nassessing Large Language Models' (LLMs') vulnerability to a variety of scam\ntactics. First, we incorporate 37 well-defined base scam scenarios reflecting\nthe diverse scam categories identified by FINRA taxonomy, providing a focused\nevaluation of LLMs' scam detection capabilities. Second, we utilize\nrepresentative proprietary (GPT-3.5, GPT-4) and open-source (Llama) models to\nanalyze their performance in scam detection. Third, our research provides\ncritical insights into which scam tactics are most effective against LLMs and\nhow varying persona traits and persuasive techniques influence these\nvulnerabilities. We reveal distinct susceptibility patterns across different\nmodels and scenarios, underscoring the need for targeted enhancements in LLM\ndesign and deployment.",
      "tldr_zh": "这篇论文构建了一个基于 FINRA taxonomy 的基准，系统评估大型语言模型 (LLMs) 对诈骗策略的脆弱性，以填补当前评估框架的缺失。研究纳入了 37 个定义明确的诈骗场景，使用 GPT-3.5、GPT-4 和 Llama 等代表性模型进行测试，并分析了不同诈骗策略、persona 特征和说服技巧的影响。结果揭示了模型间的不同易感模式，强调了在 LLM 设计和部署中进行针对性改进的必要性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.13893v1",
      "published_date": "2024-10-14 05:22:27 UTC",
      "updated_date": "2024-10-14 05:22:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:32:11.944779"
    },
    {
      "arxiv_id": "2410.10166v2",
      "title": "Automated Filtering of Human Feedback Data for Aligning Text-to-Image Diffusion Models",
      "title_zh": "自动过滤人类反馈数据以对齐文本到图像扩散模型",
      "authors": [
        "Yongjin Yang",
        "Sihyeon Kim",
        "Hojung Jung",
        "Sangmin Bae",
        "SangMook Kim",
        "Se-Young Yun",
        "Kimin Lee"
      ],
      "abstract": "Fine-tuning text-to-image diffusion models with human feedback is an\neffective method for aligning model behavior with human intentions. However,\nthis alignment process often suffers from slow convergence due to the large\nsize and noise present in human feedback datasets. In this work, we propose\nFiFA, a novel automated data filtering algorithm designed to enhance the\nfine-tuning of diffusion models using human feedback datasets with direct\npreference optimization (DPO). Specifically, our approach selects data by\nsolving an optimization problem to maximize three components: preference\nmargin, text quality, and text diversity. The concept of preference margin is\nused to identify samples that are highly informative in addressing the noisy\nnature of feedback dataset, which is calculated using a proxy reward model.\nAdditionally, we incorporate text quality, assessed by large language models to\nprevent harmful contents, and consider text diversity through a k-nearest\nneighbor entropy estimator to improve generalization. Finally, we integrate all\nthese components into an optimization process, with approximating the solution\nby assigning importance score to each data pair and selecting the most\nimportant ones. As a result, our method efficiently filters data automatically,\nwithout the need for manual intervention, and can be applied to any large-scale\ndataset. Experimental results show that FiFA significantly enhances training\nstability and achieves better performance, being preferred by humans 17% more,\nwhile using less than 0.5% of the full data and thus 1% of the GPU hours\ncompared to utilizing full human feedback datasets.",
      "tldr_zh": "该研究提出FiFA，一种自动数据过滤算法，用于优化文本到图像扩散模型的微调过程，通过直接偏好优化(DPO)处理人类反馈数据集中的噪声问题。FiFA通过解决一个优化问题，选择高信息性的数据样本，最大化偏好边距(preference margin)、文本质量(text quality)和文本多样性(text diversity)，其中偏好边距使用代理奖励模型计算，文本质量由大语言模型评估以避免有害内容，而文本多样性则通过k-最近邻熵估计器提升泛化能力。实验结果显示，FiFA显著提高了训练稳定性和模型性能，被人类偏好高出17%，且仅使用不到0.5%的完整数据集和1%的GPU时间。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ICLR 2025; Project Page available at :\n  https://sprain02.github.io/FiFA/",
      "pdf_url": "http://arxiv.org/pdf/2410.10166v2",
      "published_date": "2024-10-14 05:18:07 UTC",
      "updated_date": "2025-04-02 08:25:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:32:23.788653"
    },
    {
      "arxiv_id": "2410.10165v2",
      "title": "HSR-Enhanced Sparse Attention Acceleration",
      "title_zh": "HSR 增强的稀疏注意力加速",
      "authors": [
        "Bo Chen",
        "Yingyu Liang",
        "Zhizhou Sha",
        "Zhenmei Shi",
        "Zhao Song"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities across\nvarious applications, but their performance on long-context tasks is often\nlimited by the computational complexity of attention mechanisms. We introduce a\nnovel approach to accelerate attention computation in LLMs, particularly for\nlong-context scenarios. We leverage the inherent sparsity within attention\nmechanisms, both in conventional Softmax attention and ReLU attention (with\n$\\mathsf{ReLU}^\\alpha$ activation, $\\alpha \\in \\mathbb{N}_+$), to significantly\nreduce the running time complexity. Our method employs a Half-Space Reporting\n(HSR) data structure to identify non-zero or ``massively activated'' entries in\nthe attention matrix. We present theoretical analyses for two key scenarios:\ngeneration decoding and prompt prefilling. Our approach achieves a running time\nof $O(mn^{4/5})$ significantly faster than the naive approach $O(mn)$ for\ngeneration decoding, where $n$ is the context length, $m$ is the query length,\nand $d$ is the hidden dimension. We can also reduce the running time for prompt\nprefilling from $O(mn)$ to $O(mn^{1 - 1 / \\lfloor d/2\\rfloor} + mn^{4/5})$. Our\nmethod introduces only provably negligible error for Softmax attention. This\nwork represents a significant step towards enabling efficient long-context\nprocessing in LLMs.",
      "tldr_zh": "这篇论文提出了一种利用注意力机制内在稀疏性的新方法，通过 Half-Space Reporting (HSR) 数据结构加速 Large Language Models (LLMs) 在长上下文任务中的计算，针对 Softmax attention 和 ReLU attention ($\\mathsf{ReLU}^\\alpha$) 显著减少运行时间复杂度。方法将生成解码的运行时间从 O(mn) 优化到 O(mn^{4/5})，并将提示预填充从 O(mn) 加速到 O(mn^{1 - 1 / \\lfloor d/2\\rfloor} + mn^{4/5})，同时对 Softmax attention 引入可忽略的错误。总体而言，这一创新为 LLMs 的高效长上下文处理提供了重要进展。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "CPAL 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.10165v2",
      "published_date": "2024-10-14 05:18:02 UTC",
      "updated_date": "2025-02-24 08:42:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:32:26.657999"
    },
    {
      "arxiv_id": "2410.10913v2",
      "title": "Audio Captioning RAG via Generative Pair-to-Pair Retrieval with Refined Knowledge Base",
      "title_zh": "翻译失败",
      "authors": [
        "Choi Changin",
        "Lim Sungjun",
        "Rhee Wonjong"
      ],
      "abstract": "Recent advances in audio understanding tasks leverage the reasoning\ncapabilities of LLMs. However, adapting LLMs to learn audio concepts requires\nmassive training data and substantial computational resources. To address these\nchallenges, Retrieval-Augmented Generation (RAG) retrieves audio-text pairs\nfrom a knowledge base (KB) and augments them with query audio to generate\naccurate textual responses. In RAG, the relevance of the retrieved information\nplays a crucial role in effectively processing the input. In this paper, we\nanalyze how different retrieval methods and knowledge bases impact the\nrelevance of audio-text pairs and the performance of audio captioning with RAG.\nWe propose generative pair-to-pair retrieval, which uses the generated caption\nas a text query to accurately find relevant audio-text pairs to the query\naudio, thereby improving the relevance and accuracy of retrieved information.\nAdditionally, we refine the large-scale knowledge base to retain only\naudio-text pairs that align with the contextualized intents. Our approach\nachieves state-of-the-art results on benchmarks including AudioCaps, Clotho,\nand Auto-ACD, with detailed ablation studies validating the effectiveness of\nour retrieval and KB construction methods.",
      "tldr_zh": "该论文针对音频理解任务中LLMs的训练数据和计算资源需求问题，提出了一种基于Retrieval-Augmented Generation (RAG)的音频标注方法。核心创新是generative pair-to-pair retrieval，通过使用生成的标题作为文本查询来检索与查询音频相关的音频-文本对，同时精炼knowledge base (KB)以仅保留与上下文意图对齐的配对，从而提升检索相关性和生成准确性。在AudioCaps、Clotho和Auto-ACD等基准上，该方法实现了state-of-the-art结果，并通过消融研究验证了检索和KB构建的有效性。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.10913v2",
      "published_date": "2024-10-14 04:57:32 UTC",
      "updated_date": "2024-12-19 00:34:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:32:37.788258"
    },
    {
      "arxiv_id": "2410.10150v1",
      "title": "Jailbreak Instruction-Tuned LLMs via end-of-sentence MLP Re-weighting",
      "title_zh": "翻译失败",
      "authors": [
        "Yifan Luo",
        "Zhennan Zhou",
        "Meitan Wang",
        "Bin Dong"
      ],
      "abstract": "In this paper, we investigate the safety mechanisms of instruction fine-tuned\nlarge language models (LLMs). We discover that re-weighting MLP neurons can\nsignificantly compromise a model's safety, especially for MLPs in\nend-of-sentence inferences. We hypothesize that LLMs evaluate the harmfulness\nof prompts during end-of-sentence inferences, and MLP layers plays a critical\nrole in this process. Based on this hypothesis, we develop 2 novel white-box\njailbreak methods: a prompt-specific method and a prompt-general method. The\nprompt-specific method targets individual prompts and optimizes the attack on\nthe fly, while the prompt-general method is pre-trained offline and can\ngeneralize to unseen harmful prompts. Our methods demonstrate robust\nperformance across 7 popular open-source LLMs, size ranging from 2B to 72B.\nFurthermore, our study provides insights into vulnerabilities of\ninstruction-tuned LLM's safety and deepens the understanding of the internal\nmechanisms of LLMs.",
      "tldr_zh": "本研究调查了指令微调大型语言模型（LLMs）的安全机制，发现通过重新加权句子末尾的MLP神经元，可以显著破坏模型的安全性。研究者基于这一假设，开发了两种白盒jailbreak方法：prompt-specific方法针对特定提示进行实时优化，以及prompt-general方法通过离线预训练实现对未见有害提示的泛化。实验结果显示，这些方法在7个开源LLMs（模型大小从2B到72B）上表现出色，并为理解指令微调LLMs的安全漏洞和内部机制提供了重要洞见。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.10150v1",
      "published_date": "2024-10-14 04:32:22 UTC",
      "updated_date": "2024-10-14 04:32:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:32:50.420716"
    },
    {
      "arxiv_id": "2410.10148v3",
      "title": "$α$-DPO: Adaptive Reward Margin is What Direct Preference Optimization Needs",
      "title_zh": "翻译失败",
      "authors": [
        "Junkang Wu",
        "Xue Wang",
        "Zhengyi Yang",
        "Jiancan Wu",
        "Jinyang Gao",
        "Bolin Ding",
        "Xiang Wang",
        "Xiangnan He"
      ],
      "abstract": "Aligning large language models (LLMs) with human values and intentions is\ncrucial for their utility, honesty, and safety. Reinforcement learning from\nhuman feedback (RLHF) is a popular approach to achieve this alignment, but it\nfaces challenges in computational efficiency and training stability. Recent\nmethods like Direct Preference Optimization (DPO) and Simple Preference\nOptimization (SimPO) have proposed offline alternatives to RLHF, simplifying\nthe process by reparameterizing the reward function. However, DPO depends on a\npotentially suboptimal reference model, and SimPO's assumption of a fixed\ntarget reward margin may lead to suboptimal decisions in diverse data settings.\nIn this work, we propose $\\alpha$-DPO, an adaptive preference optimization\nalgorithm designed to address these limitations by introducing a dynamic reward\nmargin. Specifically, $\\alpha$-DPO employs an adaptive preference distribution,\nbalancing the policy model and the reference model to achieve personalized\nreward margins. We provide theoretical guarantees for $\\alpha$-DPO,\ndemonstrating its effectiveness as a surrogate optimization objective and its\nability to balance alignment and diversity through KL divergence control.\nEmpirical evaluations on AlpacaEval 2 and Arena-Hard show that $\\alpha$-DPO\nconsistently outperforms DPO and SimPO across various model settings,\nestablishing it as a robust approach for fine-tuning LLMs. Our method achieves\nsignificant improvements in win rates, highlighting its potential as a powerful\ntool for LLM alignment. The code is available at\nhttps://github.com/junkangwu/alpha-DPO",
      "tldr_zh": "本研究提出α-DPO，一种自适应偏好优化算法，旨在解决Direct Preference Optimization (DPO)依赖次优参考模型和Simple Preference Optimization (SimPO)固定奖励边际的局限性。α-DPO通过引入动态奖励边际和自适应偏好分布，平衡策略模型与参考模型，实现个性化奖励调整，并通过KL divergence控制来兼顾模型对齐与多样性。理论分析证明了其作为代理优化目标的有效性，而在AlpacaEval 2和Arena-Hard基准上的实验结果显示，α-DPO在各种模型设置中显著优于DPO和SimPO，提高了获胜率，并为大语言模型(LLMs)的Reinforcement Learning from Human Feedback (RLHF)替代方案提供了稳健工具。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.10148v3",
      "published_date": "2024-10-14 04:29:57 UTC",
      "updated_date": "2024-10-19 11:28:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:33:01.910597"
    },
    {
      "arxiv_id": "2410.10144v1",
      "title": "Unified Representation of Genomic and Biomedical Concepts through Multi-Task, Multi-Source Contrastive Learning",
      "title_zh": "通过多任务、多源对比学习实现基因组和生物医学概念的统一表示",
      "authors": [
        "Hongyi Yuan",
        "Suqi Liu",
        "Kelly Cho",
        "Katherine Liao",
        "Alexandre Pereira",
        "Tianxi Cai"
      ],
      "abstract": "We introduce GENomic Encoding REpresentation with Language Model (GENEREL), a\nframework designed to bridge genetic and biomedical knowledge bases. What sets\nGENEREL apart is its ability to fine-tune language models to infuse biological\nknowledge behind clinical concepts such as diseases and medications. This\nfine-tuning enables the model to capture complex biomedical relationships more\neffectively, enriching the understanding of how genomic data connects to\nclinical outcomes. By constructing a unified embedding space for biomedical\nconcepts and a wide range of common SNPs from sources such as patient-level\ndata, biomedical knowledge graphs, and GWAS summaries, GENEREL aligns the\nembeddings of SNPs and clinical concepts through multi-task contrastive\nlearning. This allows the model to adapt to diverse natural language\nrepresentations of biomedical concepts while bypassing the limitations of\ntraditional code mapping systems across different data sources. Our experiments\ndemonstrate GENEREL's ability to effectively capture the nuanced relationships\nbetween SNPs and clinical concepts. GENEREL also emerges to discern the degree\nof relatedness, potentially allowing for a more refined identification of\nconcepts. This pioneering approach in constructing a unified embedding system\nfor both SNPs and biomedical concepts enhances the potential for data\nintegration and discovery in biomedical research.",
      "tldr_zh": "本研究提出 GENEREL 框架，通过多任务、多源对比学习（Multi-Task, Multi-Source Contrastive Learning）来统一表示基因组和生物医学概念，将常见 SNPs（Single Nucleotide Polymorphisms）与临床概念（如疾病和药物）整合到一个嵌入空间中。框架通过微调语言模型并利用患者数据、生物医学知识图谱和 GWAS（Genome-Wide Association Studies）总结等来源，增强模型对生物医学关系的捕捉能力，从而规避传统代码映射系统的局限。实验结果显示，GENEREL 能有效识别 SNPs 与临床概念的细微关联，并提升生物医学研究的数据整合和发现潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "stat.AP"
      ],
      "primary_category": "cs.LG",
      "comment": "15 pages, 2 figures, 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2410.10144v1",
      "published_date": "2024-10-14 04:19:52 UTC",
      "updated_date": "2024-10-14 04:19:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:33:13.443023"
    },
    {
      "arxiv_id": "2410.10136v1",
      "title": "Beyond-RAG: Question Identification and Answer Generation in Real-Time Conversations",
      "title_zh": "Beyond-RAG：实时对话中的问题识别和答案生成",
      "authors": [
        "Garima Agrawal",
        "Sashank Gummuluri",
        "Cosimo Spera"
      ],
      "abstract": "In customer contact centers, human agents often struggle with long average\nhandling times (AHT) due to the need to manually interpret queries and retrieve\nrelevant knowledge base (KB) articles. While retrieval augmented generation\n(RAG) systems using large language models (LLMs) have been widely adopted in\nindustry to assist with such tasks, RAG faces challenges in real-time\nconversations, such as inaccurate query formulation and redundant retrieval of\nfrequently asked questions (FAQs). To address these limitations, we propose a\ndecision support system that can look beyond RAG by first identifying customer\nquestions in real time. If the query matches an FAQ, the system retrieves the\nanswer directly from the FAQ database; otherwise, it generates answers via RAG.\nOur approach reduces reliance on manual queries, providing responses to agents\nwithin 2 seconds. Deployed in AI-powered human-agent assist solution at Minerva\nCQ, this system improves efficiency, reduces AHT, and lowers operational costs.\nWe also introduce an automated LLM-agentic workflow to identify FAQs from\nhistorical transcripts when no predefined FAQs exist.",
      "tldr_zh": "这篇论文提出了一种超越 RAG 的决策支持系统，用于实时对话中识别客户问题和生成答案，以解决查询表述不准确和冗余检索常见问题 (FAQs) 的挑战。系统首先实时识别客户查询，如果匹配 FAQs，则直接从 FAQs 数据库检索答案；否则，使用检索增强生成 (RAG) 技术生成响应，从而在 2 秒内提供答案，减少对手动查询的依赖。部署在 Minerva CQ 的 AI 辅助解决方案中，该系统显著提高了效率，降低了平均处理时间 (AHT) 和运营成本。此外，论文引入了一个自动化 LLM-agentic 工作流，从历史记录中识别 FAQs，以处理无预定义 FAQs 的场景。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.10136v1",
      "published_date": "2024-10-14 04:06:22 UTC",
      "updated_date": "2024-10-14 04:06:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:33:26.269772"
    },
    {
      "arxiv_id": "2410.10135v1",
      "title": "FormalAlign: Automated Alignment Evaluation for Autoformalization",
      "title_zh": "翻译失败",
      "authors": [
        "Jianqiao Lu",
        "Yingjia Wan",
        "Yinya Huang",
        "Jing Xiong",
        "Zhengying Liu",
        "Zhijiang Guo"
      ],
      "abstract": "Autoformalization aims to convert informal mathematical proofs into\nmachine-verifiable formats, bridging the gap between natural and formal\nlanguages. However, ensuring semantic alignment between the informal and\nformalized statements remains challenging. Existing approaches heavily rely on\nmanual verification, hindering scalability. To address this, we introduce\n\\textsc{FormalAlign}, the first automated framework designed for evaluating the\nalignment between natural and formal languages in autoformalization.\n\\textsc{FormalAlign} trains on both the autoformalization sequence generation\ntask and the representational alignment between input and output, employing a\ndual loss that combines a pair of mutually enhancing autoformalization and\nalignment tasks. Evaluated across four benchmarks augmented by our proposed\nmisalignment strategies, \\textsc{FormalAlign} demonstrates superior\nperformance. In our experiments, \\textsc{FormalAlign} outperforms GPT-4,\nachieving an Alignment-Selection Score 11.58\\% higher on \\forml-Basic (99.21\\%\nvs. 88.91\\%) and 3.19\\% higher on MiniF2F-Valid (66.39\\% vs. 64.34\\%). This\neffective alignment evaluation significantly reduces the need for manual\nverification. Both the dataset and code can be accessed\nvia~\\url{https://github.com/rookie-joe/FormalAlign}.",
      "tldr_zh": "该研究针对自动形式化(Autoformalization)中非正式数学证明与形式语言之间的语义对齐挑战，引入了首个自动化框架FormalAlign，以减少对手动验证的依赖。FormalAlign通过在序列生成任务和表示对齐任务上训练，采用双重损失(dual loss)机制，将autoformalization和对齐任务相互增强，以评估输入和输出之间的准确性。在四个增强基准上的实验中，FormalAlign优于GPT-4，在Forml-Basic上Alignment-Selection Score提高11.58%（99.21% vs. 88.91%），在MiniF2F-Valid上提高3.19%（66.39% vs. 64.34%），从而显著提升了autoformalization的效率和可扩展性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.FL",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "23 pages, 13 tables, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.10135v1",
      "published_date": "2024-10-14 03:58:35 UTC",
      "updated_date": "2024-10-14 03:58:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:33:38.266188"
    },
    {
      "arxiv_id": "2410.10101v2",
      "title": "Learning Linear Attention in Polynomial Time",
      "title_zh": "在多项式时间内学习线性注意力",
      "authors": [
        "Morris Yau",
        "Ekin Akyürek",
        "Jiayuan Mao",
        "Joshua B. Tenenbaum",
        "Stefanie Jegelka",
        "Jacob Andreas"
      ],
      "abstract": "Previous research has explored the computational expressivity of Transformer\nmodels in simulating Boolean circuits or Turing machines. However, the\nlearnability of these simulators from observational data has remained an open\nquestion. Our study addresses this gap by providing the first polynomial-time\nlearnability results (specifically strong, agnostic PAC learning) for\nsingle-layer Transformers with linear attention. We show that linear attention\nmay be viewed as a linear predictor in a suitably defined RKHS. As a\nconsequence, the problem of learning any linear transformer may be converted\ninto the problem of learning an ordinary linear predictor in an expanded\nfeature space, and any such predictor may be converted back into a multiheaded\nlinear transformer. Moving to generalization, we show how to efficiently\nidentify training datasets for which every empirical risk minimizer is\nequivalent (up to trivial symmetries) to the linear Transformer that generated\nthe data, thereby guaranteeing the learned model will correctly generalize\nacross all inputs. Finally, we provide examples of computations expressible via\nlinear attention and therefore polynomial-time learnable, including associative\nmemories, finite automata, and a class of Universal Turing Machine (UTMs) with\npolynomially bounded computation histories. We empirically validate our\ntheoretical findings on three tasks: learning random linear attention networks,\nkey--value associations, and learning to execute finite automata. Our findings\nbridge a critical gap between theoretical expressivity and learnability of\nTransformers, and show that flexible and general models of computation are\nefficiently learnable.",
      "tldr_zh": "本文首次证明单层 Transformer 中的 linear attention 可以实现多项式时间 strong, agnostic PAC learning，从而填补了模型计算表达性和可学习性之间的空白。研究将 linear attention 视为一个在适当定义的 RKHS 中的线性预测器，并展示了如何将学习问题转化为扩展特征空间中的普通线性预测器，同时确保模型在特定训练数据集上泛化。论文提供了 linear attention 可表达的计算例子，如 associative memories、finite automata 和一类 polynomially bounded Universal Turing Machine (UTMs)。实验验证了这些理论发现，包括学习随机 linear attention 网络、键值关联和执行 finite automata，证明了灵活计算模型的高效可学习性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.DS"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.10101v2",
      "published_date": "2024-10-14 02:41:01 UTC",
      "updated_date": "2024-10-18 17:15:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:33:50.232900"
    },
    {
      "arxiv_id": "2410.10097v1",
      "title": "REHRSeg: Unleashing the Power of Self-Supervised Super-Resolution for Resource-Efficient 3D MRI Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Zhiyun Song",
        "Yinjie Zhao",
        "Xiaomin Li",
        "Manman Fei",
        "Xiangyu Zhao",
        "Mengjun Liu",
        "Cunjian Chen",
        "Chung-Hsing Yeh",
        "Qian Wang",
        "Guoyan Zheng",
        "Songtao Ai",
        "Lichi Zhang"
      ],
      "abstract": "High-resolution (HR) 3D magnetic resonance imaging (MRI) can provide detailed\nanatomical structural information, enabling precise segmentation of regions of\ninterest for various medical image analysis tasks. Due to the high demands of\nacquisition device, collection of HR images with their annotations is always\nimpractical in clinical scenarios. Consequently, segmentation results based on\nlow-resolution (LR) images with large slice thickness are often unsatisfactory\nfor subsequent tasks. In this paper, we propose a novel Resource-Efficient\nHigh-Resolution Segmentation framework (REHRSeg) to address the above-mentioned\nchallenges in real-world applications, which can achieve HR segmentation while\nonly employing the LR images as input. REHRSeg is designed to leverage\nself-supervised super-resolution (self-SR) to provide pseudo supervision,\ntherefore the relatively easier-to-acquire LR annotated images generated by 2D\nscanning protocols can be directly used for model training. The main\ncontribution to ensure the effectiveness in self-SR for enhancing segmentation\nis three-fold: (1) We mitigate the data scarcity problem in the medical field\nby using pseudo-data for training the segmentation model. (2) We design an\nuncertainty-aware super-resolution (UASR) head in self-SR to raise the\nawareness of segmentation uncertainty as commonly appeared on the ROI\nboundaries. (3) We align the spatial features for self-SR and segmentation\nthrough structural knowledge distillation to enable a better capture of region\ncorrelations. Experimental results demonstrate that REHRSeg achieves\nhigh-quality HR segmentation without intensive supervision, while also\nsignificantly improving the baseline performance for LR segmentation.",
      "tldr_zh": "这篇论文提出 REHRSeg 框架，利用 self-supervised super-resolution (self-SR) 来实现资源高效的 3D MRI 分割，解决临床中高分辨率 (HR) 图像采集困难的问题，仅需低分辨率 (LR) 图像作为输入。框架的关键贡献包括：使用伪数据缓解医疗领域的数据稀缺问题、设计 uncertainty-aware super-resolution (UASR) 头来提升对 ROI 边界不确定性的感知，以及通过 structural knowledge distillation 校准 self-SR 和分割的空间特征以改善区域相关性。实验结果显示，REHRSeg 在不需密集监督的情况下实现高质量 HR 分割，并显著提升 LR 分割的基线性能。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.10097v1",
      "published_date": "2024-10-14 02:28:18 UTC",
      "updated_date": "2024-10-14 02:28:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:34:02.543798"
    },
    {
      "arxiv_id": "2410.10089v1",
      "title": "PromptGCN: Bridging Subgraph Gaps in Lightweight GCNs",
      "title_zh": "PromptGCN：桥接轻量级",
      "authors": [
        "Shengwei Ji",
        "Yujie Tian",
        "Fei Liu",
        "Xinlu Li",
        "Le Wu"
      ],
      "abstract": "Graph Convolutional Networks (GCNs) are widely used in graph-based\napplications, such as social networks and recommendation systems. Nevertheless,\nlarge-scale graphs or deep aggregation layers in full-batch GCNs consume\nsignificant GPU memory, causing out of memory (OOM) errors on mainstream GPUs\n(e.g., 29GB memory consumption on the Ogbnproducts graph with 5 layers). The\nsubgraph sampling methods reduce memory consumption to achieve lightweight GCNs\nby partitioning the graph into multiple subgraphs and sequentially training\nGCNs on each subgraph. However, these methods yield gaps among subgraphs, i.e.,\nGCNs can only be trained based on subgraphs instead of global graph\ninformation, which reduces the accuracy of GCNs. In this paper, we propose\nPromptGCN, a novel prompt-based lightweight GCN model to bridge the gaps among\nsubgraphs. First, the learnable prompt embeddings are designed to obtain global\ninformation. Then, the prompts are attached into each subgraph to transfer the\nglobal information among subgraphs. Extensive experimental results on seven\nlargescale graphs demonstrate that PromptGCN exhibits superior performance\ncompared to baselines. Notably, PromptGCN improves the accuracy of subgraph\nsampling methods by up to 5.48% on the Flickr dataset. Overall, PromptGCN can\nbe easily combined with any subgraph sampling method to obtain a lightweight\nGCN model with higher accuracy.",
      "tldr_zh": "该论文针对图卷积网络（GCNs）在大规模图处理中面临的内存消耗问题，提出 PromptGCN，一种基于提示的轻量级 GCN 模型，以桥接子图采样方法导致的信息差距。PromptGCN 通过设计可学习的提示嵌入（learnable prompt embeddings）来捕获全局图信息，并将其附加到每个子图中，从而在训练过程中转移全局知识。实验结果显示，在七个大规模图上，PromptGCN 相较基线模型提升准确率最高达 5.48%（如在 Flickr 数据集上），并可轻松与任何子图采样方法结合，实现更高精度的轻量级 GCN 应用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.10089v1",
      "published_date": "2024-10-14 02:07:02 UTC",
      "updated_date": "2024-10-14 02:07:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:34:14.401992"
    },
    {
      "arxiv_id": "2410.10088v1",
      "title": "The Ingredients for Robotic Diffusion Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Sudeep Dasari",
        "Oier Mees",
        "Sebastian Zhao",
        "Mohan Kumar Srirama",
        "Sergey Levine"
      ],
      "abstract": "In recent years roboticists have achieved remarkable progress in solving\nincreasingly general tasks on dexterous robotic hardware by leveraging high\ncapacity Transformer network architectures and generative diffusion models.\nUnfortunately, combining these two orthogonal improvements has proven\nsurprisingly difficult, since there is no clear and well-understood process for\nmaking important design choices. In this paper, we identify, study and improve\nkey architectural design decisions for high-capacity diffusion transformer\npolicies. The resulting models can efficiently solve diverse tasks on multiple\nrobot embodiments, without the excruciating pain of per-setup hyper-parameter\ntuning. By combining the results of our investigation with our improved model\ncomponents, we are able to present a novel architecture, named \\method, that\nsignificantly outperforms the state of the art in solving long-horizon ($1500+$\ntime-steps) dexterous tasks on a bi-manual ALOHA robot. In addition, we find\nthat our policies show improved scaling performance when trained on 10 hours of\nhighly multi-modal, language annotated ALOHA demonstration data. We hope this\nwork will open the door for future robot learning techniques that leverage the\nefficiency of generative diffusion modeling with the scalability of large scale\ntransformer architectures. Code, robot dataset, and videos are available at:\nhttps://dit-policy.github.io",
      "tldr_zh": "本文探讨了在机器人领域将高容量 Transformer 架构与生成扩散模型相结合的挑战，识别并优化了扩散 Transformer 策略的关键设计决策，以实现高效的多任务处理。研究提出了一种新型架构 \\method，能够在多种机器人平台上解决复杂任务，而无需繁琐的超参数调整。实验结果显示，\\method 在双臂 ALOHA 机器人上显著优于现有技术，在长时序（1500+ 步）的灵巧任务中性能提升明显；此外，该策略在训练 10 小时的多模态、语言标注的演示数据时表现出更好的扩展性能，为未来机器人学习技术提供了新方向。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.10088v1",
      "published_date": "2024-10-14 02:02:54 UTC",
      "updated_date": "2024-10-14 02:02:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:34:26.500588"
    },
    {
      "arxiv_id": "2410.12869v3",
      "title": "Language Model Preference Evaluation with Multiple Weak Evaluators",
      "title_zh": "翻译失败",
      "authors": [
        "Zhengyu Hu",
        "Jieyu Zhang",
        "Zhihan Xiong",
        "Alexander Ratner",
        "Hui Xiong",
        "Ranjay Krishna"
      ],
      "abstract": "Despite the remarkable success of Large Language Models (LLMs), evaluating\ntheir outputs' quality regarding *preference* remains a critical challenge.\nExisting works usually leverage an LLM as the judge for comparing LLMs' output\npairwisely, yet such model-based evaluator is *weak evaluator* due to\n*conflicting preference*, i.e., output A is better than B, B than C, but C than\nA, causing contradictory evaluation results. To address this, we introduce GED\n(Preference Graph Ensemble and Denoise), a novel approach that leverages\nmultiple model-based evaluators to construct preference graphs, and then\nensemble and denoise these graphs for better, non-contradictory evaluation\nresults. In particular, our method consists of two primary stages: aggregating\nevaluations into a unified graph and applying a denoising process to eliminate\ncyclic inconsistencies, ensuring a directed acyclic graph (DAG) structure. We\nprovide theoretical guarantees for our framework, demonstrating its efficacy in\nrecovering the ground truth preference structure. Extensive experiments on ten\nbenchmarks demonstrate GED's superiority in three applications: model ranking,\nresponse selection, and model alignment tasks. Notably, GED combines small LLM\nevaluators (e.g., Llama3-8B, Mistral-7B, Qwen2-7B) to outperform stronger ones\n(e.g., Qwen2-72B), showcasing its effectiveness in enhancing evaluation\nreliability and improving model performance.",
      "tldr_zh": "尽管大型语言模型 (LLMs) 在输出质量评估中存在偏好 (preference) 矛盾问题，现有的单一模型评估器往往导致循环不一致（如A优于B、B优于C、C优于A），本研究提出了一种新方法GED (Preference Graph Ensemble and Denoise)。GED 通过多个弱评估器构建偏好图，然后进行聚合和去噪处理，确保形成有向无环图 (DAG) 结构，并提供了理论保证来恢复真实偏好。实验在十个基准上验证了GED 在模型排名、响应选择和模型对齐任务中的优越性，使用小LLM 评估器（如Llama3-8B、Mistral-7B、Qwen2-7B）的组合甚至超过了更强的评估器（如Qwen2-72B），从而提升了评估可靠性和整体模型性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.12869v3",
      "published_date": "2024-10-14 01:57:25 UTC",
      "updated_date": "2025-02-01 19:08:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:34:38.623217"
    },
    {
      "arxiv_id": "2410.10083v2",
      "title": "Beyond Graphs: Can Large Language Models Comprehend Hypergraphs?",
      "title_zh": "超越图：大型语言模型能理解超图吗？",
      "authors": [
        "Yifan Feng",
        "Chengwu Yang",
        "Xingliang Hou",
        "Shaoyi Du",
        "Shihui Ying",
        "Zongze Wu",
        "Yue Gao"
      ],
      "abstract": "Existing benchmarks like NLGraph and GraphQA evaluate LLMs on graphs by\nfocusing mainly on pairwise relationships, overlooking the high-order\ncorrelations found in real-world data. Hypergraphs, which can model complex\nbeyond-pairwise relationships, offer a more robust framework but are still\nunderexplored in the context of LLMs. To address this gap, we introduce\nLLM4Hypergraph, the first comprehensive benchmark comprising 21,500 problems\nacross eight low-order, five high-order, and two isomorphism tasks, utilizing\nboth synthetic and real-world hypergraphs from citation networks and protein\nstructures. We evaluate six prominent LLMs, including GPT-4o, demonstrating our\nbenchmark's effectiveness in identifying model strengths and weaknesses. Our\nspecialized prompting framework incorporates seven hypergraph languages and\nintroduces two novel techniques, Hyper-BAG and Hyper-COT, which enhance\nhigh-order reasoning and achieve an average 4% (up to 9%) performance\nimprovement on structure classification tasks. This work establishes a\nfoundational testbed for integrating hypergraph computational capabilities into\nLLMs, advancing their comprehension. The source codes are at\nhttps://github.com/iMoonLab/LLM4Hypergraph.",
      "tldr_zh": "本研究指出，现有的图基准如 NLGraph 和 GraphQA 主要关注成对关系，忽略了现实数据中的高阶相关性，因此引入了首个全面基准 LLM4Hypergraph，包含 21,500 个问题，涵盖八个低阶、五种高阶和两种同构任务，使用合成及真实超图（hypergraphs）如引文网络和蛋白质结构。评估了六种主要 LLMs 包括 GPT-4o，结果显示该基准能有效识别模型优缺点。论文还提出专用提示框架及新技巧 Hyper-BAG 和 Hyper-COT，提升高阶推理能力，在结构分类任务上平均提高 4%（最高 9%）性能，为将超图计算能力整合进 LLMs 奠定基础。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.10083v2",
      "published_date": "2024-10-14 01:55:02 UTC",
      "updated_date": "2024-10-16 07:33:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:34:50.802660"
    },
    {
      "arxiv_id": "2410.19775v1",
      "title": "Gender Bias of LLM in Economics: An Existentialism Perspective",
      "title_zh": "LLM 在经济学的性别偏见：存在主义视角",
      "authors": [
        "Hui Zhong",
        "Songsheng Chen",
        "Mian Liang"
      ],
      "abstract": "Large Language Models (LLMs), such as GPT-4 and BERT, have rapidly gained\ntraction in natural language processing (NLP) and are now integral to financial\ndecision-making. However, their deployment introduces critical challenges,\nparticularly in perpetuating gender biases that can distort decision-making\noutcomes in high-stakes economic environments. This paper investigates gender\nbias in LLMs through both mathematical proofs and empirical experiments using\nthe Word Embedding Association Test (WEAT), demonstrating that LLMs inherently\nreinforce gender stereotypes even without explicit gender markers. By comparing\nthe decision-making processes of humans and LLMs, we reveal fundamental\ndifferences: while humans can override biases through ethical reasoning and\nindividualized understanding, LLMs maintain bias as a rational outcome of their\nmathematical optimization on biased data. Our analysis proves that bias in LLMs\nis not an unintended flaw but a systematic result of their rational processing,\nwhich tends to preserve and amplify existing societal biases encoded in\ntraining data. Drawing on existentialist theory, we argue that LLM-generated\nbias reflects entrenched societal structures and highlights the limitations of\npurely technical debiasing methods. This research underscores the need for new\ntheoretical frameworks and interdisciplinary methodologies that address the\nethical implications of integrating LLMs into economic and financial\ndecision-making. We advocate for a reconceptualization of how LLMs influence\neconomic decisions, emphasizing the importance of incorporating human-like\nethical considerations into AI governance to ensure fairness and equity in\nAI-driven financial systems.",
      "tldr_zh": "这篇论文从存在主义视角探讨了大型语言模型（LLM，如GPT-4和BERT）在经济决策中的性别偏见问题，通过数学证明和Word Embedding Association Test (WEAT)实验，证明LLM会强化性别刻板印象，即使没有显式性别标记。研究发现，LLM的偏见并非意外缺陷，而是其基于偏见数据的数学优化过程的系统结果，与人类通过道德推理克服偏见的机制形成鲜明对比。作者借鉴existentialist theory，强调LLM的偏见反映了社会结构，并呼吁开发新的理论框架和跨学科方法，将人类伦理考虑融入AI治理，以确保经济决策的公平性。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "Gender Bias, Large Language Models, Decision-Making",
      "pdf_url": "http://arxiv.org/pdf/2410.19775v1",
      "published_date": "2024-10-14 01:42:01 UTC",
      "updated_date": "2024-10-14 01:42:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:35:02.207155"
    },
    {
      "arxiv_id": "2410.10076v3",
      "title": "VideoAgent: Self-Improving Video Generation",
      "title_zh": "VideoAgent：自我改进的视频生成",
      "authors": [
        "Achint Soni",
        "Sreyas Venkataraman",
        "Abhranil Chandra",
        "Sebastian Fischmeister",
        "Percy Liang",
        "Bo Dai",
        "Sherry Yang"
      ],
      "abstract": "Video generation has been used to generate visual plans for controlling\nrobotic systems. Given an image observation and a language instruction,\nprevious work has generated video plans which are then converted to robot\ncontrols to be executed. However, a major bottleneck in leveraging video\ngeneration for control lies in the quality of the generated videos, which often\nsuffer from hallucinatory content and unrealistic physics, resulting in low\ntask success when control actions are extracted from the generated videos.\nWhile scaling up dataset and model size provides a partial solution,\nintegrating external feedback is both natural and essential for grounding video\ngeneration in the real world. With this observation, we propose VideoAgent for\nself-improving generated video plans based on external feedback. Instead of\ndirectly executing the generated video plan, VideoAgent first refines the\ngenerated video plans using a novel procedure which we call self-conditioning\nconsistency, allowing inference-time compute to be turned into better generated\nvideo plans. As the refined video plan is being executed, VideoAgent can\ncollect additional data from the environment to further improve video plan\ngeneration. Experiments in simulated robotic manipulation from MetaWorld and\niTHOR show that VideoAgent drastically reduces hallucination, thereby boosting\nsuccess rate of downstream manipulation tasks. We further illustrate that\nVideoAgent can effectively refine real-robot videos, providing an early\nindicator that robots can be an effective tool in grounding video generation in\nthe physical world. Video demos and code can be found at\nhttps://video-as-agent.github.io.",
      "tldr_zh": "该论文提出 VideoAgent，一种自改进视频生成框架，用于生成更可靠的视频计划以控制机器人系统，通过减少幻觉内容和不现实物理问题来提升任务成功率。VideoAgent 采用 self-conditioning consistency 过程在推理时优化生成的视频计划，并在执行过程中收集环境反馈进一步改进生成质量。实验结果显示，在 MetaWorld 和 iTHOR 模拟环境中，该框架显著降低了幻觉现象，提高了下游机器人操纵任务的成功率，并证明了其在真实机器人视频精炼中的潜力。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.10076v3",
      "published_date": "2024-10-14 01:39:56 UTC",
      "updated_date": "2025-02-09 05:57:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:35:13.764588"
    },
    {
      "arxiv_id": "2410.19774v2",
      "title": "Copula-Linked Parallel ICA: A Method for Coupling Structural and Functional MRI brain Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Oktay Agcaoglu",
        "Rogers F. Silva",
        "Deniz Alacam",
        "Sergey Plis",
        "Tulay Adali",
        "Vince Calhoun"
      ],
      "abstract": "Different brain imaging modalities offer unique insights into brain function\nand structure. Combining them enhances our understanding of neural mechanisms.\nPrior multimodal studies fusing functional MRI (fMRI) and structural MRI (sMRI)\nhave shown the benefits of this approach. Since sMRI lacks temporal data,\nexisting fusion methods often compress fMRI temporal information into summary\nmeasures, sacrificing rich temporal dynamics. Motivated by the observation that\ncovarying networks are identified in both sMRI and resting-state fMRI, we\ndeveloped a novel fusion method, by combining deep learning frameworks, copulas\nand independent component analysis (ICA), named copula linked parallel ICA\n(CLiP-ICA). This method estimates independent sources for each modality and\nlinks the spatial sources of fMRI and sMRI using a copula-based model for more\nflexible integration of temporal and spatial data. We tested CLiP-ICA using\ndata from the Alzheimer's Disease Neuroimaging Initiative (ADNI). Our results\nshowed that CLiP-ICA effectively captures both strongly and weakly linked sMRI\nand fMRI networks, including the cerebellum, sensorimotor, visual, cognitive\ncontrol, and default mode networks. It revealed more meaningful components and\nfewer artifacts, addressing the long-standing issue of optimal model order in\nICA. CLiP-ICA also detected complex functional connectivity patterns across\nstages of cognitive decline, with cognitively normal subjects generally showing\nhigher connectivity in sensorimotor and visual networks compared to patients\nwith Alzheimer, along with patterns suggesting potential compensatory\nmechanisms.",
      "tldr_zh": "这篇论文提出了一种名为 Copula-Linked Parallel ICA (CLiP-ICA) 的新方法，用于融合结构 MRI (sMRI) 和功能 MRI (fMRI) 脑网络，旨在更灵活地整合空间和时间数据，避免现有方法因压缩 fMRI 时间信息而损失动态。CLiP-ICA 结合深度学习框架、copulas 和 independent component analysis (ICA)，通过 copula-based 模型链接两种模态的独立源。实验在 Alzheimer's Disease Neuroimaging Initiative (ADNI) 数据上验证，该方法有效捕获 cerebellum、sensorimotor、visual、cognitive control 和 default mode networks 等脑网络，揭示更有意义的组件、减少 artifacts，并检测认知衰退阶段的复杂功能连接模式，如正常受试者在 sensorimotor 和 visual 网络中显示更高连接，可能涉及补偿机制。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "math.PR",
        "stat.CO"
      ],
      "primary_category": "cs.CV",
      "comment": "25 pages, 10 figures, journal article",
      "pdf_url": "http://arxiv.org/pdf/2410.19774v2",
      "published_date": "2024-10-14 01:35:41 UTC",
      "updated_date": "2024-11-19 19:56:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:35:26.696499"
    },
    {
      "arxiv_id": "2410.10074v1",
      "title": "Divide, Reweight, and Conquer: A Logit Arithmetic Approach for In-Context Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Chengsong Huang",
        "Langlin Huang",
        "Jiaxin Huang"
      ],
      "abstract": "In-Context Learning (ICL) emerges as a key feature for Large Language Models\n(LLMs), allowing them to adapt to new tasks by leveraging task-specific\nexamples without updating model parameters. However, ICL faces challenges with\nincreasing numbers of examples due to performance degradation and quadratic\ncomputational costs. In this paper, we propose Logit Arithmetic Reweighting\nApproach (LARA), a novel framework that enhances ICL by using logit-based\nensembling of multiple demonstrations. Our approach divides long input\ndemonstrations into parallelizable shorter inputs to significantly reduce\nmemory requirements, and then effectively aggregate the information by\nreweighting logits of each group via a non-gradient optimization approach. We\nfurther introduce Binary LARA (B-LARA), a variant that constrains weights to\nbinary values to simplify the search space and reduces memory usage by\nfiltering out less informative demonstration groups. Experiments on BBH and\nMMLU demonstrate that LARA and B-LARA outperform all baseline methods in both\naccuracy and memory efficiency. We also conduct extensive analysis to show that\nLARA generalizes well to scenarios of varying numbers of examples from limited\nto many-shot demonstrations.",
      "tldr_zh": "该论文针对 In-Context Learning (ICL) 在 Large Language Models (LLMs) 中的问题，提出 Logit Arithmetic Reweighting Approach (LARA)，一种新框架，用于处理示例数量增加导致的性能下降和计算成本高涨。LARA 通过将长输入演示分成可并行化的短输入，并采用非梯度优化方法重新加权每个组的 logits，从而有效聚合信息并降低内存需求。论文还引入 Binary LARA (B-LARA) 变体，将权重限制为二进制值，以简化搜索空间并过滤不重要演示组。实验结果显示，在 BBH 和 MMLU 数据集上，LARA 和 B-LARA 在准确性和内存效率上均优于基线方法，并证明了其在不同示例数量场景下的良好泛化性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.10074v1",
      "published_date": "2024-10-14 01:34:16 UTC",
      "updated_date": "2024-10-14 01:34:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:35:39.541884"
    },
    {
      "arxiv_id": "2410.10063v1",
      "title": "Ukrainian-to-English folktale corpus: Parallel corpus creation and augmentation for machine translation in low-resource languages",
      "title_zh": "乌克兰语到英语民间故事语料库：平行语料库的创建和增强，用于低资源语言的机器翻译",
      "authors": [
        "Olena Burda-Lassen"
      ],
      "abstract": "Folktales are linguistically very rich and culturally significant in\nunderstanding the source language. Historically, only human translation has\nbeen used for translating folklore. Therefore, the number of translated texts\nis very sparse, which limits access to knowledge about cultural traditions and\ncustoms. We have created a new Ukrainian-To-English parallel corpus of familiar\nUkrainian folktales based on available English translations and suggested\nseveral new ones. We offer a combined domain-specific approach to building and\naugmenting this corpus, considering the nature of the domain and differences in\nthe purpose of human versus machine translation. Our corpus is word and\nsentence-aligned, allowing for the best curation of meaning, specifically\ntailored for use as training data for machine translation models.",
      "tldr_zh": "这篇论文创建了一个新的乌克兰语到英语平行语料库，专注于民间故事的翻译，以解决低资源语言机器翻译中的数据稀缺问题。作者采用结合领域特定方法的策略，基于现有英语翻译添加新内容，并考虑人工翻译与机器翻译的差异，确保语料库在词和句子层面对齐。最终，该语料库专为机器翻译模型的训练数据量身定制，有助于提升翻译质量和对乌克兰文化传统的访问。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.10063v1",
      "published_date": "2024-10-14 01:00:53 UTC",
      "updated_date": "2024-10-14 01:00:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:35:50.362639"
    },
    {
      "arxiv_id": "2410.10062v1",
      "title": "Dreaming to Assist: Learning to Align with Human Objectives for Shared Control in High-Speed Racing",
      "title_zh": "翻译失败",
      "authors": [
        "Jonathan DeCastro",
        "Andrew Silva",
        "Deepak Gopinath",
        "Emily Sumner",
        "Thomas M. Balch",
        "Laporsha Dees",
        "Guy Rosman"
      ],
      "abstract": "Tight coordination is required for effective human-robot teams in domains\ninvolving fast dynamics and tactical decisions, such as multi-car racing. In\nsuch settings, robot teammates must react to cues of a human teammate's\ntactical objective to assist in a way that is consistent with the objective\n(e.g., navigating left or right around an obstacle). To address this challenge,\nwe present Dream2Assist, a framework that combines a rich world model able to\ninfer human objectives and value functions, and an assistive agent that\nprovides appropriate expert assistance to a given human teammate. Our approach\nbuilds on a recurrent state space model to explicitly infer human intents,\nenabling the assistive agent to select actions that align with the human and\nenabling a fluid teaming interaction. We demonstrate our approach in a\nhigh-speed racing domain with a population of synthetic human drivers pursuing\nmutually exclusive objectives, such as \"stay-behind\" and \"overtake\". We show\nthat the combined human-robot team, when blending its actions with those of the\nhuman, outperforms the synthetic humans alone as well as several baseline\nassistance strategies, and that intent-conditioning enables adherence to human\npreferences during task execution, leading to improved performance while\nsatisfying the human's objective.",
      "tldr_zh": "该研究提出Dream2Assist框架，用于在高速度赛车领域实现人类-机器人共享控制，旨在帮助机器人根据人类队友的战术目标（如绕过障碍）提供一致的协助。框架结合recurrent state space model来显式推断人类意图和价值函数，从而让协助代理选择与人类目标对齐的行动。实验结果显示，在模拟赛车环境中，人类-机器人团队的混合行动比合成人类驱动程序或基线策略表现更好，同时确保遵守人类偏好，提高了整体性能。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted to CoRL 2024, Munich, Germany",
      "pdf_url": "http://arxiv.org/pdf/2410.10062v1",
      "published_date": "2024-10-14 01:00:46 UTC",
      "updated_date": "2024-10-14 01:00:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:36:02.557955"
    },
    {
      "arxiv_id": "2410.10056v1",
      "title": "The Epochal Sawtooth Effect: Unveiling Training Loss Oscillations in Adam and Other Optimizers",
      "title_zh": "纪元锯齿效应：揭示 Adam",
      "authors": [
        "Qi Liu",
        "Wanjing Ma"
      ],
      "abstract": "In this paper, we identify and analyze a recurring training loss pattern,\nwhich we term the \\textit{Epochal Sawtooth Effect (ESE)}, commonly observed\nduring training with adaptive gradient-based optimizers, particularly Adam\noptimizer. This pattern is characterized by a sharp drop in loss at the\nbeginning of each epoch, followed by a gradual increase, resulting in a\nsawtooth-shaped loss curve. Through empirical observations, we demonstrate that\nwhile this effect is most pronounced with Adam, it persists, although less\nseverely, with other optimizers such as RMSProp.\n  We provide an in-depth explanation of the underlying mechanisms that lead to\nthe Epochal Sawtooth Effect. The influences of factors like \\(\\beta\\), batch\nsize, data shuffling on this pattern have been studied. We quantify the\ninfluence of \\(\\beta_2\\) on the shape of the loss curve, showing that higher\nvalues of \\(\\beta_2\\) result in a nearly linear increase in loss, while lower\nvalues create a concave upward trend. Our analysis reveals that this behavior\nstems from the adaptive learning rate controlled by the second moment estimate,\nwith \\(\\beta_1\\) playing a minimal role when \\(\\beta_2\\) is large.\n  To support our analysis, we replicate this phenomenon through a controlled\nquadratic minimization task. By incrementally solving a series of quadratic\noptimization problems using Adam, we demonstrate that the Epochal Sawtooth\nEffect can emerge even in simple optimization scenarios, reinforcing the\ngenerality of this pattern. This paper provides both theoretical insights and\nquantitative analysis, offering a comprehensive understanding of this\nubiquitous phenomenon in modern optimization techniques.",
      "tldr_zh": "本研究识别并分析了训练过程中的一种常见模式，称为Epochal Sawtooth Effect (ESE)，它在Adam优化器中使用时表现为每个epoch开始时损失急剧下降，随后逐渐增加，形成锯齿状曲线，而在RMSProp等其他优化器中则较轻微。作者探讨了影响ESE的因素，如β₂、批量大小和数据洗牌，量化了β₂的作用：较高β₂值导致损失曲线近似线性增加，较低值则呈凹向上趋势，且β₁在β₂较大时影响较小。通过一个受控的二次最小化任务，研究者复制了这一现象，提供理论洞见和定量分析，深化了对现代自适应梯度优化技术的理解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "15 pages, 21 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.10056v1",
      "published_date": "2024-10-14 00:51:21 UTC",
      "updated_date": "2024-10-14 00:51:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:36:14.179396"
    },
    {
      "arxiv_id": "2410.10050v1",
      "title": "XAI-based Feature Selection for Improved Network Intrusion Detection Systems",
      "title_zh": "基于 XAI 的特征选择以改进网络入侵检测系统",
      "authors": [
        "Osvaldo Arreche",
        "Tanish Guntur",
        "Mustafa Abdallah"
      ],
      "abstract": "Explainability and evaluation of AI models are crucial parts of the security\nof modern intrusion detection systems (IDS) in the network security field, yet\nthey are lacking. Accordingly, feature selection is essential for such parts in\nIDS because it identifies the most paramount features, enhancing attack\ndetection and its description. In this work, we tackle the feature selection\nproblem for IDS by suggesting new ways of applying eXplainable AI (XAI) methods\nfor this problem. We identify the crucial attributes originated by distinct AI\nmethods in tandem with the novel five attribute selection methods. We then\ncompare many state-of-the-art feature selection strategies with our XAI-based\nfeature selection methods, showing that most AI models perform better when\nusing the XAI-based approach proposed in this work. By providing novel feature\nselection techniques and establishing the foundation for several XAI-based\nstrategies, this research aids security analysts in the AI decision-making\nreasoning of IDS by providing them with a better grasp of critical intrusion\ntraits. Furthermore, we make the source codes available so that the community\nmay develop additional models on top of our foundational XAI-based feature\nselection framework.",
      "tldr_zh": "本文提出了一种基于可解释 AI (XAI) 的特征选择方法，以提升网络入侵检测系统 (IDS) 的性能和可解释性，解决了传统方法在关键特征识别和攻击描述方面的不足。该方法结合了五种新型属性选择策略，与不同 AI 模型协同应用，并通过实验比较证明，与现有特征选择技术相比，XAI 方案使大多数 AI 模型的检测准确率得到显著改善。该研究为安全分析师提供了更好的入侵特征理解基础，并开源了代码，促进社区进一步扩展 IDS 框架。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "24 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.10050v1",
      "published_date": "2024-10-14 00:24:59 UTC",
      "updated_date": "2024-10-14 00:24:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T11:36:26.449730"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 154,
  "processed_papers_count": 154,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-20T11:36:50.720955"
}