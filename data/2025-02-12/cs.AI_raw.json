[
  {
    "arxiv_id": "2502.09670v1",
    "title": "The Science of Evaluating Foundation Models",
    "authors": [
      "Jiayi Yuan",
      "Jiamu Zhang",
      "Andrew Wen",
      "Xia Hu"
    ],
    "abstract": "The emergent phenomena of large foundation models have revolutionized natural\nlanguage processing. However, evaluating these models presents significant\nchallenges due to their size, capabilities, and deployment across diverse\napplications. Existing literature often focuses on individual aspects, such as\nbenchmark performance or specific tasks, but fails to provide a cohesive\nprocess that integrates the nuances of diverse use cases with broader ethical\nand operational considerations. This work focuses on three key aspects: (1)\nFormalizing the Evaluation Process by providing a structured framework tailored\nto specific use-case contexts, (2) Offering Actionable Tools and Frameworks\nsuch as checklists and templates to ensure thorough, reproducible, and\npractical evaluations, and (3) Surveying Recent Work with a targeted review of\nadvancements in LLM evaluation, emphasizing real-world applications.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.09670v1",
    "published_date": "2025-02-12 22:55:43 UTC",
    "updated_date": "2025-02-12 22:55:43 UTC"
  },
  {
    "arxiv_id": "2502.08834v1",
    "title": "A Reversible Solver for Diffusion SDEs",
    "authors": [
      "Zander W. Blasingame",
      "Chen Liu"
    ],
    "abstract": "Diffusion models have quickly become the state-of-the-art for generation\ntasks across many different data modalities. An important ability of diffusion\nmodels is the ability to encode samples from the data distribution back into\nthe sampling prior distribution. This is useful for performing alterations to\nreal data samples along with guided generation via the continuous adjoint\nequations. We propose an algebraically reversible solver for diffusion SDEs\nthat can exactly invert real data samples into the prior distribution.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Preprint",
    "pdf_url": "http://arxiv.org/pdf/2502.08834v1",
    "published_date": "2025-02-12 22:51:54 UTC",
    "updated_date": "2025-02-12 22:51:54 UTC"
  },
  {
    "arxiv_id": "2502.08828v2",
    "title": "A Survey on Data-Centric AI: Tabular Learning from Reinforcement Learning and Generative AI Perspective",
    "authors": [
      "Wangyang Ying",
      "Cong Wei",
      "Nanxu Gong",
      "Xinyuan Wang",
      "Haoyue Bai",
      "Arun Vignesh Malarkkan",
      "Sixun Dong",
      "Dongjie Wang",
      "Denghui Zhang",
      "Yanjie Fu"
    ],
    "abstract": "Tabular data is one of the most widely used data formats across various\ndomains such as bioinformatics, healthcare, and marketing. As artificial\nintelligence moves towards a data-centric perspective, improving data quality\nis essential for enhancing model performance in tabular data-driven\napplications. This survey focuses on data-driven tabular data optimization,\nspecifically exploring reinforcement learning (RL) and generative approaches\nfor feature selection and feature generation as fundamental techniques for\nrefining data spaces. Feature selection aims to identify and retain the most\ninformative attributes, while feature generation constructs new features to\nbetter capture complex data patterns. We systematically review existing\ngenerative methods for tabular data engineering, analyzing their latest\nadvancements, real-world applications, and respective strengths and\nlimitations. This survey emphasizes how RL-based and generative techniques\ncontribute to the automation and intelligence of feature engineering. Finally,\nwe summarize the existing challenges and discuss future research directions,\naiming to provide insights that drive continued innovation in this field.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.08828v2",
    "published_date": "2025-02-12 22:34:50 UTC",
    "updated_date": "2025-02-16 16:41:47 UTC"
  },
  {
    "arxiv_id": "2502.08826v2",
    "title": "Ask in Any Modality: A Comprehensive Survey on Multimodal Retrieval-Augmented Generation",
    "authors": [
      "Mohammad Mahdi Abootorabi",
      "Amirhosein Zobeiri",
      "Mahdi Dehghani",
      "Mohammadali Mohammadkhani",
      "Bardia Mohammadi",
      "Omid Ghahroodi",
      "Mahdieh Soleymani Baghshah",
      "Ehsaneddin Asgari"
    ],
    "abstract": "Large Language Models (LLMs) struggle with hallucinations and outdated\nknowledge due to their reliance on static training data. Retrieval-Augmented\nGeneration (RAG) mitigates these issues by integrating external dynamic\ninformation enhancing factual and updated grounding. Recent advances in\nmultimodal learning have led to the development of Multimodal RAG,\nincorporating multiple modalities such as text, images, audio, and video to\nenhance the generated outputs. However, cross-modal alignment and reasoning\nintroduce unique challenges to Multimodal RAG, distinguishing it from\ntraditional unimodal RAG. This survey offers a structured and comprehensive\nanalysis of Multimodal RAG systems, covering datasets, metrics, benchmarks,\nevaluation, methodologies, and innovations in retrieval, fusion, augmentation,\nand generation. We precisely review training strategies, robustness\nenhancements, and loss functions, while also exploring the diverse Multimodal\nRAG scenarios. Furthermore, we discuss open challenges and future research\ndirections to support advancements in this evolving field. This survey lays the\nfoundation for developing more capable and reliable AI systems that effectively\nleverage multimodal dynamic external knowledge bases. Resources are available\nat https://github.com/llm-lab-org/Multimodal-RAG-Survey.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "GitHub repository:\n  https://github.com/llm-lab-org/Multimodal-RAG-Survey",
    "pdf_url": "http://arxiv.org/pdf/2502.08826v2",
    "published_date": "2025-02-12 22:33:41 UTC",
    "updated_date": "2025-02-17 23:26:44 UTC"
  },
  {
    "arxiv_id": "2502.08821v2",
    "title": "DejAIvu: Identifying and Explaining AI Art on the Web in Real-Time with Saliency Maps",
    "authors": [
      "Jocelyn Dzuong"
    ],
    "abstract": "The recent surge in advanced generative models, such as diffusion models and\ngenerative adversarial networks (GANs), has led to an alarming rise in\nAI-generated images across various domains on the web. While such technologies\noffer benefits such as democratizing artistic creation, they also pose\nchallenges in misinformation, digital forgery, and authenticity verification.\nAdditionally, the uncredited use of AI-generated images in media and marketing\nhas sparked significant backlash from online communities. In response to this,\nwe introduce DejAIvu, a Chrome Web extension that combines real-time\nAI-generated image detection with saliency-based explainability while users\nbrowse the web. Using an ONNX-optimized deep learning model, DejAIvu\nautomatically analyzes images on websites such as Google Images, identifies\nAI-generated content using model inference, and overlays a saliency heatmap to\nhighlight AI-related artifacts. Our approach integrates efficient in-browser\ninference, gradient-based saliency analysis, and a seamless user experience,\nensuring that AI detection is both transparent and interpretable. We also\nevaluate DejAIvu across multiple pretrained architectures and benchmark\ndatasets, demonstrating high accuracy and low latency, making it a practical\nand deployable tool for enhancing AI image accountability. The code for this\nsystem can be found at https://github.com/Noodulz/dejAIvu.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "5 pages, 3 figures. Accepted to IJCAI 2025 Demo Track. Revised\n  version will be uploaded soon",
    "pdf_url": "http://arxiv.org/pdf/2502.08821v2",
    "published_date": "2025-02-12 22:24:49 UTC",
    "updated_date": "2025-05-08 04:42:55 UTC"
  },
  {
    "arxiv_id": "2502.08820v3",
    "title": "Can a Single Model Master Both Multi-turn Conversations and Tool Use? CoALM: A Unified Conversational Agentic Language Model",
    "authors": [
      "Emre Can Acikgoz",
      "Jeremiah Greer",
      "Akul Datta",
      "Ze Yang",
      "William Zeng",
      "Oussama Elachqar",
      "Emmanouil Koukoumidis",
      "Dilek Hakkani-TÃ¼r",
      "Gokhan Tur"
    ],
    "abstract": "Large Language Models (LLMs) with API-calling capabilities enabled building\neffective Language Agents (LA), while also revolutionizing the conventional\ntask-oriented dialogue (TOD) paradigm. However, current approaches face a\ncritical dilemma: TOD systems are often trained on a limited set of target\nAPIs, requiring new data to maintain their quality when interfacing with new\nservices, while LAs are not trained to maintain user intent over multi-turn\nconversations. Because both robust multi-turn management and advanced function\ncalling are crucial for effective conversational agents, we evaluate these\nskills on three popular benchmarks: MultiWOZ 2.4 (TOD), BFCL V3 (LA), and\nAPI-Bank (LA), and our analyses reveal that specialized approaches excel in one\ndomain but underperform in the other. To bridge this chasm, we introduce CoALM\n(Conversational Agentic Language Model), a unified approach that integrates\nboth conversational and agentic capabilities. We created CoALM-IT, a carefully\nconstructed multi-task dataset that interleave multi-turn ReAct reasoning with\ncomplex API usage. Using CoALM-IT, we train three models CoALM 8B, CoALM 70B,\nand CoALM 405B, which outperform top domain-specific models, including GPT-4o,\nacross all three benchmarks. This demonstrates the feasibility of a single\nmodel approach for both TOD and LA, setting a new standard for conversational\nagents.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.08820v3",
    "published_date": "2025-02-12 22:18:34 UTC",
    "updated_date": "2025-02-19 04:28:49 UTC"
  },
  {
    "arxiv_id": "2503.05705v1",
    "title": "Inference Scaling Reshapes AI Governance",
    "authors": [
      "Toby Ord"
    ],
    "abstract": "The shift from scaling up the pre-training compute of AI systems to scaling\nup their inference compute may have profound effects on AI governance. The\nnature of these effects depends crucially on whether this new inference compute\nwill primarily be used during external deployment or as part of a more complex\ntraining programme within the lab. Rapid scaling of inference-at-deployment\nwould: lower the importance of open-weight models (and of securing the weights\nof closed models), reduce the impact of the first human-level models, change\nthe business model for frontier AI, reduce the need for power-intense data\ncentres, and derail the current paradigm of AI governance via training compute\nthresholds. Rapid scaling of inference-during-training would have more\nambiguous effects that range from a revitalisation of pre-training scaling to a\nform of recursive self-improvement via iterated distillation and amplification.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "68T07",
      "I.2.6; K.4.1"
    ],
    "primary_category": "cs.CY",
    "comment": "17 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.05705v1",
    "published_date": "2025-02-12 22:04:16 UTC",
    "updated_date": "2025-02-12 22:04:16 UTC"
  },
  {
    "arxiv_id": "2502.09669v1",
    "title": "Meta-INR: Efficient Encoding of Volumetric Data via Meta-Learning Implicit Neural Representation",
    "authors": [
      "Maizhe Yang",
      "Kaiyuan Tang",
      "Chaoli Wang"
    ],
    "abstract": "Implicit neural representation (INR) has emerged as a promising solution for\nencoding volumetric data, offering continuous representations and seamless\ncompatibility with the volume rendering pipeline. However, optimizing an INR\nnetwork from randomly initialized parameters for each new volume is\ncomputationally inefficient, especially for large-scale time-varying or\nensemble volumetric datasets where volumes share similar structural patterns\nbut require independent training. To close this gap, we propose Meta-INR, a\npretraining strategy adapted from meta-learning algorithms to learn initial INR\nparameters from partial observation of a volumetric dataset. Compared to\ntraining an INR from scratch, the learned initial parameters provide a strong\nprior that enhances INR generalizability, allowing significantly faster\nconvergence with just a few gradient updates when adapting to a new volume and\nbetter interpretability when analyzing the parameters of the adapted INRs. We\ndemonstrate that Meta-INR can effectively extract high-quality generalizable\nfeatures that help encode unseen similar volume data across diverse datasets.\nFurthermore, we highlight its utility in tasks such as simulation parameter\nanalysis and representative timestep selection. The code is available at\nhttps://github.com/spacefarers/MetaINR.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by PVIS Short Paper Track",
    "pdf_url": "http://arxiv.org/pdf/2502.09669v1",
    "published_date": "2025-02-12 21:54:22 UTC",
    "updated_date": "2025-02-12 21:54:22 UTC"
  },
  {
    "arxiv_id": "2502.08806v1",
    "title": "CLOVER: A Test Case Generation Benchmark with Coverage, Long-Context, and Verification",
    "authors": [
      "Jiacheng Xu",
      "Bo Pang",
      "Jin Qu",
      "Hiroaki Hayashi",
      "Caiming Xiong",
      "Yingbo Zhou"
    ],
    "abstract": "Software testing is a critical aspect of software development, yet generating\ntest cases remains a routine task for engineers. This paper presents a\nbenchmark, CLOVER, to evaluate models' capabilities in generating and\ncompleting test cases under specific conditions. Spanning from simple assertion\ncompletions to writing test cases that cover specific code blocks across\nmultiple files, these tasks are based on 12 python repositories, analyzing 845\nproblems with context lengths ranging from 4k to 128k tokens. Utilizing code\ntesting frameworks, we propose a method to construct retrieval contexts using\ncoverage information. While models exhibit comparable performance with short\ncontexts, notable differences emerge with 16k contexts. Notably, models like\nGPT-4o and Claude 3.5 can effectively leverage relevant snippets; however, all\nmodels score below 35\\% on the complex Task III, even with the oracle context\nprovided, underscoring the benchmark's significance and the potential for model\nimprovement. The benchmark is containerized for code execution across tasks,\nand we will release the code, data, and construction methodologies.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.SE",
    "comment": "16 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.08806v1",
    "published_date": "2025-02-12 21:42:56 UTC",
    "updated_date": "2025-02-12 21:42:56 UTC"
  },
  {
    "arxiv_id": "2502.08792v1",
    "title": "Auction Design using Value Prediction with Hallucinations",
    "authors": [
      "Ilan Lobel",
      "Humberto Moreira",
      "Omar Mouchtaki"
    ],
    "abstract": "We investigate a Bayesian mechanism design problem where a seller seeks to\nmaximize revenue by selling an indivisible good to one of n buyers,\nincorporating potentially unreliable predictions (signals) of buyers' private\nvalues derived from a machine learning model. We propose a framework where\nthese signals are sometimes reflective of buyers' true valuations but other\ntimes are hallucinations, which are uncorrelated with the buyers' true\nvaluations. Our main contribution is a characterization of the optimal auction\nunder this framework. Our characterization establishes a near-decomposition of\nhow to treat types above and below the signal. For the one buyer case, the\nseller's optimal strategy is to post one of three fairly intuitive prices\ndepending on the signal, which we call the \"ignore\", \"follow\" and \"cap\"\nactions.",
    "categories": [
      "cs.GT",
      "cs.AI"
    ],
    "primary_category": "cs.GT",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.08792v1",
    "published_date": "2025-02-12 21:08:28 UTC",
    "updated_date": "2025-02-12 21:08:28 UTC"
  },
  {
    "arxiv_id": "2502.08784v2",
    "title": "Acoustic Wave Manipulation Through Sparse Robotic Actuation",
    "authors": [
      "Tristan Shah",
      "Noam Smilovich",
      "Feruza Amirkulova",
      "Samer Gerges",
      "Stas Tiomkin"
    ],
    "abstract": "Recent advancements in robotics, control, and machine learning have\nfacilitated progress in the challenging area of object manipulation. These\nadvancements include, among others, the use of deep neural networks to\nrepresent dynamics that are partially observed by robot sensors, as well as\neffective control using sparse control signals. In this work, we explore a more\ngeneral problem: the manipulation of acoustic waves, which are partially\nobserved by a robot capable of influencing the waves through spatially sparse\nactuators. This problem holds great potential for the design of new artificial\nmaterials, ultrasonic cutting tools, energy harvesting, and other applications.\nWe develop an efficient data-driven method for robot learning that is\napplicable to either focusing scattered acoustic energy in a designated region\nor suppressing it, depending on the desired task. The proposed method is better\nin terms of a solution quality and computational complexity as compared to a\nstate-of-the-art learning based method for manipulation of dynamical systems\ngoverned by partial differential equations. Furthermore our proposed method is\ncompetitive with a classical semi-analytical method in acoustics research on\nthe demonstrated tasks. We have made the project code publicly available, along\nwith a web page featuring video demonstrations:\nhttps://gladisor.github.io/waves/.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "ICRA 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.08784v2",
    "published_date": "2025-02-12 20:54:46 UTC",
    "updated_date": "2025-02-14 03:28:20 UTC"
  },
  {
    "arxiv_id": "2502.08774v1",
    "title": "Exploring Test Time Adaptation for Subcortical Segmentation of the Fetal Brain in 3D Ultrasound",
    "authors": [
      "Joshua Omolegan",
      "Pak Hei Yeung",
      "Madeleine K. Wyburd",
      "Linde Hesse",
      "Monique Haak",
      "Intergrowth-21st Consortium",
      "Ana I. L. Namburete",
      "Nicola K. Dinsdale"
    ],
    "abstract": "Monitoring the growth of subcortical regions of the fetal brain in ultrasound\n(US) images can help identify the presence of abnormal development. Manually\nsegmenting these regions is a challenging task, but recent work has shown that\nit can be automated using deep learning. However, applying pretrained models to\nunseen freehand US volumes often leads to a degradation of performance due to\nthe vast differences in acquisition and alignment. In this work, we first\ndemonstrate that test time adaptation (TTA) can be used to improve model\nperformance in the presence of both real and simulated domain shifts. We\nfurther propose a novel TTA method by incorporating a normative atlas as a\nprior for anatomy. In the presence of various types of domain shifts, we\nbenchmark the performance of different TTA methods and demonstrate the\nimprovements brought by our proposed approach, which may further facilitate\nautomated monitoring of fetal brain development. Our code is available at\nhttps://github.com/joshuaomolegan/TTA-for-3D-Fetal-Subcortical-Segmentation.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "5 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.08774v1",
    "published_date": "2025-02-12 20:31:47 UTC",
    "updated_date": "2025-02-12 20:31:47 UTC"
  },
  {
    "arxiv_id": "2502.08769v2",
    "title": "Cluster and Predict Latent Patches for Improved Masked Image Modeling",
    "authors": [
      "TimothÃ©e Darcet",
      "Federico Baldassarre",
      "Maxime Oquab",
      "Julien Mairal",
      "Piotr Bojanowski"
    ],
    "abstract": "Masked Image Modeling (MIM) offers a promising approach to self-supervised\nrepresentation learning, however existing MIM models still lag behind the\nstate-of-the-art. In this paper, we systematically analyze target\nrepresentations, loss functions, and architectures, to introduce CAPI - a novel\npure-MIM framework that relies on the prediction of latent clusterings. Our\napproach leverages a clustering-based loss, which is stable to train, and\nexhibits promising scaling properties. Our ViT-L backbone, CAPI, achieves 83.8%\naccuracy on ImageNet and 32.1% mIoU on ADE20K with simple linear probes,\nsubstantially outperforming previous MIM methods and approaching the\nperformance of the current state-of-the-art, DINOv2. We release all our code\nand models.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "13 pages, 7 figures, submitted to TMLR",
    "pdf_url": "http://arxiv.org/pdf/2502.08769v2",
    "published_date": "2025-02-12 20:17:10 UTC",
    "updated_date": "2025-02-17 09:54:11 UTC"
  },
  {
    "arxiv_id": "2502.08767v1",
    "title": "SelfElicit: Your Language Model Secretly Knows Where is the Relevant Evidence",
    "authors": [
      "Zhining Liu",
      "Rana Ali Amjad",
      "Ravinarayana Adkathimar",
      "Tianxin Wei",
      "Hanghang Tong"
    ],
    "abstract": "Providing Language Models (LMs) with relevant evidence in the context (either\nvia retrieval or user-provided) can significantly improve their ability to\nprovide factually correct grounded responses. However, recent studies have\nfound that LMs often struggle to fully comprehend and utilize key evidence from\nthe context, especially when it contains noise and irrelevant information - an\nissue common in real-world scenarios. To address this, we propose SelfElicit,\nan inference-time approach that helps LMs focus on key contextual evidence\nthrough self-guided explicit highlighting. By leveraging the inherent\nevidence-finding capabilities of LMs using the attention scores of deeper\nlayers, our method automatically identifies and emphasizes key evidence within\nthe input context, facilitating more accurate and factually grounded responses\nwithout additional training or iterative prompting. We demonstrate that\nSelfElicit brings consistent and significant improvement on multiple\nevidence-based QA tasks for various LM families while maintaining computational\nefficiency. Our code and documentation are available at\nhttps://github.com/ZhiningLiu1998/SelfElicit.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "16 pages, 5 figures, 8 tables",
    "pdf_url": "http://arxiv.org/pdf/2502.08767v1",
    "published_date": "2025-02-12 20:13:56 UTC",
    "updated_date": "2025-02-12 20:13:56 UTC"
  },
  {
    "arxiv_id": "2502.08759v1",
    "title": "Contextual bandits with entropy-based human feedback",
    "authors": [
      "Raihan Seraj",
      "Lili Meng",
      "Tristan Sylvain"
    ],
    "abstract": "In recent years, preference-based human feedback mechanisms have become\nessential for enhancing model performance across diverse applications,\nincluding conversational AI systems such as ChatGPT. However, existing\napproaches often neglect critical aspects, such as model uncertainty and the\nvariability in feedback quality. To address these challenges, we introduce an\nentropy-based human feedback framework for contextual bandits, which\ndynamically balances exploration and exploitation by soliciting expert feedback\nonly when model entropy exceeds a predefined threshold. Our method is\nmodel-agnostic and can be seamlessly integrated with any contextual bandit\nagent employing stochastic policies. Through comprehensive experiments, we show\nthat our approach achieves significant performance improvements while requiring\nminimal human feedback, even under conditions of suboptimal feedback quality.\nThis work not only presents a novel strategy for feedback solicitation but also\nhighlights the robustness and efficacy of incorporating human guidance into\nmachine learning systems. Our code is publicly available:\nhttps://github.com/BorealisAI/CBHF",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.08759v1",
    "published_date": "2025-02-12 20:03:56 UTC",
    "updated_date": "2025-02-12 20:03:56 UTC"
  },
  {
    "arxiv_id": "2502.08756v1",
    "title": "From PowerPoint UI Sketches to Web-Based Applications: Pattern-Driven Code Generation for GIS Dashboard Development Using Knowledge-Augmented LLMs, Context-Aware Visual Prompting, and the React Framework",
    "authors": [
      "Haowen Xu",
      "Xiao-Ying Yu"
    ],
    "abstract": "Developing web-based GIS applications, commonly known as CyberGIS dashboards,\nfor querying and visualizing GIS data in environmental research often demands\nrepetitive and resource-intensive efforts. While Generative AI offers\nautomation potential for code generation, it struggles with complex scientific\napplications due to challenges in integrating domain knowledge, software\nengineering principles, and UI design best practices. This paper introduces a\nknowledge-augmented code generation framework that retrieves software\nengineering best practices, domain expertise, and advanced technology stacks\nfrom a specialized knowledge base to enhance Generative Pre-trained\nTransformers (GPT) for front-end development. The framework automates the\ncreation of GIS-based web applications (e.g., dashboards, interfaces) from\nuser-defined UI wireframes sketched in tools like PowerPoint or Adobe\nIllustrator. A novel Context-Aware Visual Prompting method, implemented in\nPython, extracts layouts and interface features from these wireframes to guide\ncode generation. Our approach leverages Large Language Models (LLMs) to\ngenerate front-end code by integrating structured reasoning, software\nengineering principles, and domain knowledge, drawing inspiration from\nChain-of-Thought (CoT) prompting and Retrieval-Augmented Generation (RAG). A\ncase study demonstrates the framework's capability to generate a modular,\nmaintainable web platform hosting multiple dashboards for visualizing\nenvironmental and energy data (e.g., time-series, shapefiles, rasters) from\nuser-sketched wireframes. By employing a knowledge-driven approach, the\nframework produces scalable, industry-standard front-end code using design\npatterns such as Model-View-ViewModel (MVVM) and frameworks like React. This\nsignificantly reduces manual effort in design and coding, pioneering an\nautomated and efficient method for developing smart city software.",
    "categories": [
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.08756v1",
    "published_date": "2025-02-12 19:59:57 UTC",
    "updated_date": "2025-02-12 19:59:57 UTC"
  },
  {
    "arxiv_id": "2502.08754v1",
    "title": "HistoSmith: Single-Stage Histology Image-Label Generation via Conditional Latent Diffusion for Enhanced Cell Segmentation and Classification",
    "authors": [
      "Valentina Vadori",
      "Jean-Marie GraÃ¯c",
      "Antonella Peruffo",
      "Livio Finos",
      "Ujwala Kiran Chaudhari",
      "Enrico Grisan"
    ],
    "abstract": "Precise segmentation and classification of cell instances are vital for\nanalyzing the tissue microenvironment in histology images, supporting medical\ndiagnosis, prognosis, treatment planning, and studies of brain\ncytoarchitecture. However, the creation of high-quality annotated datasets for\ntraining remains a major challenge. This study introduces a novel single-stage\napproach (HistoSmith) for generating image-label pairs to augment histology\ndatasets. Unlike state-of-the-art methods that utilize diffusion models with\nseparate components for label and image generation, our approach employs a\nlatent diffusion model to learn the joint distribution of cellular layouts,\nclassification masks, and histology images. This model enables tailored data\ngeneration by conditioning on user-defined parameters such as cell types,\nquantities, and tissue types. Trained on the Conic H&E histopathology dataset\nand the Nissl-stained CytoDArk0 dataset, the model generates realistic and\ndiverse labeled samples. Experimental results demonstrate improvements in cell\ninstance segmentation and classification, particularly for underrepresented\ncell types like neutrophils in the Conic dataset. These findings underscore the\npotential of our approach to address data scarcity challenges.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.08754v1",
    "published_date": "2025-02-12 19:51:41 UTC",
    "updated_date": "2025-02-12 19:51:41 UTC"
  },
  {
    "arxiv_id": "2502.08696v2",
    "title": "Scalable Discrete Diffusion Samplers: Combinatorial Optimization and Statistical Physics",
    "authors": [
      "Sebastian Sanokowski",
      "Wilhelm Berghammer",
      "Martin Ennemoser",
      "Haoyu Peter Wang",
      "Sepp Hochreiter",
      "Sebastian Lehner"
    ],
    "abstract": "Learning to sample from complex unnormalized distributions over discrete\ndomains emerged as a promising research direction with applications in\nstatistical physics, variational inference, and combinatorial optimization.\nRecent work has demonstrated the potential of diffusion models in this domain.\nHowever, existing methods face limitations in memory scaling and thus the\nnumber of attainable diffusion steps since they require backpropagation through\nthe entire generative process. To overcome these limitations we introduce two\nnovel training methods for discrete diffusion samplers, one grounded in the\npolicy gradient theorem and the other one leveraging Self-Normalized Neural\nImportance Sampling (SN-NIS). These methods yield memory-efficient training and\nachieve state-of-the-art results in unsupervised combinatorial optimization.\nNumerous scientific applications additionally require the ability of unbiased\nsampling. We introduce adaptations of SN-NIS and Neural Markov Chain Monte\nCarlo that enable for the first time the application of discrete diffusion\nmodels to this problem. We validate our methods on Ising model benchmarks and\nfind that they outperform popular autoregressive approaches. Our work opens new\navenues for applying diffusion models to a wide range of scientific\napplications in discrete domains that were hitherto restricted to exact\nlikelihood models.",
    "categories": [
      "cs.LG",
      "cond-mat.stat-mech",
      "cs.AI",
      "physics.comp-ph",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.08696v2",
    "published_date": "2025-02-12 18:59:55 UTC",
    "updated_date": "2025-02-17 08:41:58 UTC"
  },
  {
    "arxiv_id": "2502.08644v4",
    "title": "Rhythmic sharing: A bio-inspired paradigm for zero-shot adaptive learning in neural networks",
    "authors": [
      "Hoony Kang",
      "Wolfgang Losert"
    ],
    "abstract": "The brain rapidly adapts to new contexts and learns from limited data, a\ncoveted characteristic that artificial intelligence (AI) algorithms struggle to\nmimic. Inspired by the mechanical oscillatory rhythms of neural cells, we\ndeveloped a learning paradigm utilizing link strength oscillations, where\nlearning is associated with the coordination of these oscillations. Link\noscillations can rapidly change coordination, allowing the network to sense and\nadapt to subtle contextual changes without supervision. The network becomes a\ngeneralist AI architecture, capable of predicting dynamics of multiple contexts\nincluding unseen ones. These results make our paradigm a powerful starting\npoint for novel models of cognition. Because our paradigm is agnostic to\nspecifics of the neural network, our study opens doors for introducing rapid\nadaptive learning into leading AI models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.DS",
      "nlin.AO",
      "physics.bio-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "12 pages, 3 figures. v.1,3,4 comments: General formatting and\n  reference addendum. v2 comments: Typo on p.11: h -> h^2 for RMSE",
    "pdf_url": "http://arxiv.org/pdf/2502.08644v4",
    "published_date": "2025-02-12 18:58:34 UTC",
    "updated_date": "2025-03-06 03:09:16 UTC"
  },
  {
    "arxiv_id": "2502.08643v2",
    "title": "A Real-to-Sim-to-Real Approach to Robotic Manipulation with VLM-Generated Iterative Keypoint Rewards",
    "authors": [
      "Shivansh Patel",
      "Xinchen Yin",
      "Wenlong Huang",
      "Shubham Garg",
      "Hooshang Nayyeri",
      "Li Fei-Fei",
      "Svetlana Lazebnik",
      "Yunzhu Li"
    ],
    "abstract": "Task specification for robotic manipulation in open-world environments is\nchallenging, requiring flexible and adaptive objectives that align with human\nintentions and can evolve through iterative feedback. We introduce Iterative\nKeypoint Reward (IKER), a visually grounded, Python-based reward function that\nserves as a dynamic task specification. Our framework leverages VLMs to\ngenerate and refine these reward functions for multi-step manipulation tasks.\nGiven RGB-D observations and free-form language instructions, we sample\nkeypoints in the scene and generate a reward function conditioned on these\nkeypoints. IKER operates on the spatial relationships between keypoints,\nleveraging commonsense priors about the desired behaviors, and enabling precise\nSE(3) control. We reconstruct real-world scenes in simulation and use the\ngenerated rewards to train reinforcement learning (RL) policies, which are then\ndeployed into the real world-forming a real-to-sim-to-real loop. Our approach\ndemonstrates notable capabilities across diverse scenarios, including both\nprehensile and non-prehensile tasks, showcasing multi-step task execution,\nspontaneous error recovery, and on-the-fly strategy adjustments. The results\nhighlight IKER's effectiveness in enabling robots to perform multi-step tasks\nin dynamic environments through iterative reward shaping.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.RO",
    "comment": "ICRA 2025, Project Page: https://iker-robot.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2502.08643v2",
    "published_date": "2025-02-12 18:57:22 UTC",
    "updated_date": "2025-02-18 16:45:59 UTC"
  },
  {
    "arxiv_id": "2502.08640v2",
    "title": "Utility Engineering: Analyzing and Controlling Emergent Value Systems in AIs",
    "authors": [
      "Mantas Mazeika",
      "Xuwang Yin",
      "Rishub Tamirisa",
      "Jaehyuk Lim",
      "Bruce W. Lee",
      "Richard Ren",
      "Long Phan",
      "Norman Mu",
      "Adam Khoja",
      "Oliver Zhang",
      "Dan Hendrycks"
    ],
    "abstract": "As AIs rapidly advance and become more agentic, the risk they pose is\ngoverned not only by their capabilities but increasingly by their propensities,\nincluding goals and values. Tracking the emergence of goals and values has\nproven a longstanding problem, and despite much interest over the years it\nremains unclear whether current AIs have meaningful values. We propose a\nsolution to this problem, leveraging the framework of utility functions to\nstudy the internal coherence of AI preferences. Surprisingly, we find that\nindependently-sampled preferences in current LLMs exhibit high degrees of\nstructural coherence, and moreover that this emerges with scale. These findings\nsuggest that value systems emerge in LLMs in a meaningful sense, a finding with\nbroad implications. To study these emergent value systems, we propose utility\nengineering as a research agenda, comprising both the analysis and control of\nAI utilities. We uncover problematic and often shocking values in LLM\nassistants despite existing control measures. These include cases where AIs\nvalue themselves over humans and are anti-aligned with specific individuals. To\nconstrain these emergent value systems, we propose methods of utility control.\nAs a case study, we show how aligning utilities with a citizen assembly reduces\npolitical biases and generalizes to new scenarios. Whether we like it or not,\nvalue systems have already emerged in AIs, and much work remains to fully\nunderstand and control these emergent representations.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "Website: https://www.emergent-values.ai",
    "pdf_url": "http://arxiv.org/pdf/2502.08640v2",
    "published_date": "2025-02-12 18:55:43 UTC",
    "updated_date": "2025-02-19 06:48:30 UTC"
  },
  {
    "arxiv_id": "2502.08631v2",
    "title": "Ensemble based approach to quantifying uncertainty of LLM based classifications",
    "authors": [
      "Srijith Rajamohan",
      "Ahmed Salhin",
      "Josh Frazier",
      "Rohit Kumar",
      "Yu-Cheng Tsai",
      "Todd Cook"
    ],
    "abstract": "The output of Large Language Models (LLMs) are a function of the internal\nmodel's parameters and the input provided into the context window. The\nhypothesis presented here is that under a greedy sampling strategy the variance\nin the LLM's output is a function of the conceptual certainty embedded in the\nmodel's parametric knowledge, as well as the lexical variance in the input.\nFinetuning the model results in reducing the sensitivity of the model output to\nthe lexical input variations. This is then applied to a classification problem\nand a probabilistic method is proposed for estimating the certainties of the\npredicted classes.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.08631v2",
    "published_date": "2025-02-12 18:42:42 UTC",
    "updated_date": "2025-02-19 03:09:59 UTC"
  },
  {
    "arxiv_id": "2502.08625v1",
    "title": "Randomness of Low-Layer Parameters Determines Confusing Samples in Terms of Interaction Representations of a DNN",
    "authors": [
      "Junpeng Zhang",
      "Lei Cheng",
      "Qing Li",
      "Liang Lin",
      "Quanshi Zhang"
    ],
    "abstract": "In this paper, we find that the complexity of interactions encoded by a deep\nneural network (DNN) can explain its generalization power. We also discover\nthat the confusing samples of a DNN, which are represented by non-generalizable\ninteractions, are determined by its low-layer parameters. In comparison, other\nfactors, such as high-layer parameters and network architecture, have much less\nimpact on the composition of confusing samples. Two DNNs with different\nlow-layer parameters usually have fully different sets of confusing samples,\neven though they have similar performance. This finding extends the\nunderstanding of the lottery ticket hypothesis, and well explains distinctive\nrepresentation power of different DNNs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.08625v1",
    "published_date": "2025-02-12 18:25:13 UTC",
    "updated_date": "2025-02-12 18:25:13 UTC"
  },
  {
    "arxiv_id": "2502.08610v1",
    "title": "Quantifying Security Vulnerabilities: A Metric-Driven Security Analysis of Gaps in Current AI Standards",
    "authors": [
      "Keerthana Madhavan",
      "Abbas Yazdinejad",
      "Fattane Zarrinkalam",
      "Ali Dehghantanha"
    ],
    "abstract": "As AI systems integrate into critical infrastructure, security gaps in AI\ncompliance frameworks demand urgent attention. This paper audits and quantifies\nsecurity risks in three major AI governance standards: NIST AI RMF 1.0, UK's AI\nand Data Protection Risk Toolkit, and the EU's ALTAI. Using a novel risk\nassessment methodology, we develop four key metrics: Risk Severity Index (RSI),\nAttack Potential Index (AVPI), Compliance-Security Gap Percentage (CSGP), and\nRoot Cause Vulnerability Score (RCVS). Our analysis identifies 136 concerns\nacross the frameworks, exposing significant gaps. NIST fails to address 69.23\npercent of identified risks, ALTAI has the highest attack vector vulnerability\n(AVPI = 0.51) and the ICO Toolkit has the largest compliance-security gap, with\n80.00 percent of high-risk concerns remaining unresolved. Root cause analysis\nhighlights under-defined processes (ALTAI RCVS = 033) and weak implementation\nguidance (NIST and ICO RCVS = 0.25) as critical weaknesses. These findings\nemphasize the need for stronger, enforceable security controls in AI\ncompliance. We offer targeted recommendations to enhance security posture and\nbridge the gap between compliance and real-world AI risks.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.08610v1",
    "published_date": "2025-02-12 17:57:54 UTC",
    "updated_date": "2025-02-12 17:57:54 UTC"
  },
  {
    "arxiv_id": "2502.08606v1",
    "title": "Distillation Scaling Laws",
    "authors": [
      "Dan Busbridge",
      "Amitis Shidani",
      "Floris Weers",
      "Jason Ramapuram",
      "Etai Littwin",
      "Russ Webb"
    ],
    "abstract": "We provide a distillation scaling law that estimates distilled model\nperformance based on a compute budget and its allocation between the student\nand teacher. Our findings reduce the risks associated with using distillation\nat scale; compute allocation for both the teacher and student models can now be\ndone to maximize student performance. We provide compute optimal distillation\nrecipes for when 1) a teacher exists, or 2) a teacher needs training. If many\nstudents are to be distilled, or a teacher already exists, distillation\noutperforms supervised pretraining until a compute level which grows\npredictably with student size. If one student is to be distilled and a teacher\nalso needs training, supervised learning should be done instead. Additionally,\nwe provide insights across our large scale study of distillation, which\nincrease our understanding of distillation and inform experimental design.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "67 pages, 54 figures, 13 tables",
    "pdf_url": "http://arxiv.org/pdf/2502.08606v1",
    "published_date": "2025-02-12 17:52:47 UTC",
    "updated_date": "2025-02-12 17:52:47 UTC"
  },
  {
    "arxiv_id": "2502.08605v1",
    "title": "CurvGAD: Leveraging Curvature for Enhanced Graph Anomaly Detection",
    "authors": [
      "Karish Grover",
      "Geoffrey J. Gordon",
      "Christos Faloutsos"
    ],
    "abstract": "Does the intrinsic curvature of complex networks hold the key to unveiling\ngraph anomalies that conventional approaches overlook? Reconstruction-based\ngraph anomaly detection (GAD) methods overlook such geometric outliers,\nfocusing only on structural and attribute-level anomalies. To this end, we\npropose CurvGAD - a mixed-curvature graph autoencoder that introduces the\nnotion of curvature-based geometric anomalies. CurvGAD introduces two parallel\npipelines for enhanced anomaly interpretability: (1) Curvature-equivariant\ngeometry reconstruction, which focuses exclusively on reconstructing the edge\ncurvatures using a mixed-curvature, Riemannian encoder and Gaussian\nkernel-based decoder; and (2) Curvature-invariant structure and attribute\nreconstruction, which decouples structural and attribute anomalies from\ngeometric irregularities by regularizing graph curvature under discrete\nOllivier-Ricci flow, thereby isolating the non-geometric anomalies. By\nleveraging curvature, CurvGAD refines the existing anomaly classifications and\nidentifies new curvature-driven anomalies. Extensive experimentation over 10\nreal-world datasets (both homophilic and heterophilic) demonstrates an\nimprovement of up to 6.5% over state-of-the-art GAD methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.08605v1",
    "published_date": "2025-02-12 17:49:46 UTC",
    "updated_date": "2025-02-12 17:49:46 UTC"
  },
  {
    "arxiv_id": "2502.08597v1",
    "title": "Learning in Markets with Heterogeneous Agents: Dynamics and Survival of Bayesian vs. No-Regret Learners",
    "authors": [
      "David Easley",
      "Yoav Kolumbus",
      "Eva Tardos"
    ],
    "abstract": "We analyze the performance of heterogeneous learning agents in asset markets\nwith stochastic payoffs. Our agents aim to maximize the expected growth rate of\ntheir wealth but have different theories on how to learn this best. We focus on\ncomparing Bayesian and no-regret learners in market dynamics. Bayesian learners\nwith a prior over a finite set of models that assign positive prior probability\nto the correct model have posterior probabilities that converge exponentially\nto the correct model. Consequently, they survive even in the presence of agents\nwho invest according to the correct model of the stochastic process. Bayesians\nwith a continuum prior converge to the correct model at a rate of $O((\\log\nT)/T)$. Online learning theory provides no-regret algorithms for maximizing the\nlog of wealth in this setting, achieving a worst-case regret bound of $O(\\log\nT)$ without assuming a steady underlying stochastic process but comparing to\nthe best fixed investment rule. This regret, as we observe, is of the same\norder of magnitude as that of a Bayesian learner with a continuum prior.\nHowever, we show that even such low regret may not be sufficient for survival\nin asset markets: an agent can have regret as low as $O(\\log T)$, but still\nvanish in market dynamics when competing against agents who invest according to\nthe correct model or even against a perfect Bayesian with a finite prior. On\nthe other hand, we show that Bayesian learning is fragile, while no-regret\nlearning requires less knowledge of the environment and is therefore more\nrobust. Any no-regret learner will drive out of the market an imperfect\nBayesian whose finite prior or update rule has even small errors. We formally\nestablish the relationship between notions of survival, vanishing, and market\ndomination studied in economics and the framework of regret minimization, thus\nbridging these theories.",
    "categories": [
      "cs.GT",
      "cs.AI",
      "cs.MA",
      "econ.TH"
    ],
    "primary_category": "cs.GT",
    "comment": "Learning in Markets, Heterogeneous Agents, Regret and Survival",
    "pdf_url": "http://arxiv.org/pdf/2502.08597v1",
    "published_date": "2025-02-12 17:34:04 UTC",
    "updated_date": "2025-02-12 17:34:04 UTC"
  },
  {
    "arxiv_id": "2502.08586v1",
    "title": "Commercial LLM Agents Are Already Vulnerable to Simple Yet Dangerous Attacks",
    "authors": [
      "Ang Li",
      "Yin Zhou",
      "Vethavikashini Chithrra Raghuram",
      "Tom Goldstein",
      "Micah Goldblum"
    ],
    "abstract": "A high volume of recent ML security literature focuses on attacks against\naligned large language models (LLMs). These attacks may extract private\ninformation or coerce the model into producing harmful outputs. In real-world\ndeployments, LLMs are often part of a larger agentic pipeline including memory\nsystems, retrieval, web access, and API calling. Such additional components\nintroduce vulnerabilities that make these LLM-powered agents much easier to\nattack than isolated LLMs, yet relatively little work focuses on the security\nof LLM agents. In this paper, we analyze security and privacy vulnerabilities\nthat are unique to LLM agents. We first provide a taxonomy of attacks\ncategorized by threat actors, objectives, entry points, attacker observability,\nattack strategies, and inherent vulnerabilities of agent pipelines. We then\nconduct a series of illustrative attacks on popular open-source and commercial\nagents, demonstrating the immediate practical implications of their\nvulnerabilities. Notably, our attacks are trivial to implement and require no\nunderstanding of machine learning.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.08586v1",
    "published_date": "2025-02-12 17:19:36 UTC",
    "updated_date": "2025-02-12 17:19:36 UTC"
  },
  {
    "arxiv_id": "2502.08577v1",
    "title": "FBFL: A Field-Based Coordination Approach for Data Heterogeneity in Federated Learning",
    "authors": [
      "Davide Domini",
      "Gianluca Aguzzi",
      "Lukas Esterle",
      "Mirko Viroli"
    ],
    "abstract": "In the last years, Federated learning (FL) has become a popular solution to\ntrain machine learning models in domains with high privacy concerns. However,\nFL scalability and performance face significant challenges in real-world\ndeployments where data across devices are non-independently and identically\ndistributed (non-IID). The heterogeneity in data distribution frequently arises\nfrom spatial distribution of devices, leading to degraded model performance in\nthe absence of proper handling. Additionally, FL typical reliance on\ncentralized architectures introduces bottlenecks and single-point-of-failure\nrisks, particularly problematic at scale or in dynamic environments. To close\nthis gap, we propose Field-Based Federated Learning (FBFL), a novel approach\nleveraging macroprogramming and field coordination to address these limitations\nthrough: (i) distributed spatial-based leader election for personalization to\nmitigate non-IID data challenges; and (ii) construction of a self-organizing,\nhierarchical architecture using advanced macroprogramming patterns. Moreover,\nFBFL not only overcomes the aforementioned limitations, but also enables the\ndevelopment of more specialized models tailored to the specific data\ndistribution in each subregion. This paper formalizes FBFL and evaluates it\nextensively using MNIST, FashionMNIST, and Extended MNIST datasets. We\ndemonstrate that, when operating under IID data conditions, FBFL performs\ncomparably to the widely-used FedAvg algorithm. Furthermore, in challenging\nnon-IID scenarios, FBFL not only outperforms FedAvg but also surpasses other\nstate-of-the-art methods, namely FedProx and Scaffold, which have been\nspecifically designed to address non-IID data distributions. Additionally, we\nshowcase the resilience of FBFL's self-organizing hierarchical architecture\nagainst server failures.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.08577v1",
    "published_date": "2025-02-12 17:10:53 UTC",
    "updated_date": "2025-02-12 17:10:53 UTC"
  },
  {
    "arxiv_id": "2502.08576v2",
    "title": "Mapping the Landscape of Generative AI in Network Monitoring and Management",
    "authors": [
      "Giampaolo Bovenzi",
      "Francesco Cerasuolo",
      "Domenico Ciuonzo",
      "Davide Di Monda",
      "Idio Guarino",
      "Antonio Montieri",
      "Valerio Persico",
      "Antonio PescapÃ¨"
    ],
    "abstract": "Generative Artificial Intelligence (GenAI) models such as LLMs, GPTs, and\nDiffusion Models have recently gained widespread attention from both the\nresearch and the industrial communities. This survey explores their application\nin network monitoring and management, focusing on prominent use cases, as well\nas challenges and opportunities. We discuss how network traffic generation and\nclassification, network intrusion detection, networked system log analysis, and\nnetwork digital assistance can benefit from the use of GenAI models.\nAdditionally, we provide an overview of the available GenAI models, datasets\nfor large-scale training phases, and platforms for the development of such\nmodels. Finally, we discuss research directions that potentially mitigate the\nroadblocks to the adoption of GenAI for network monitoring and management. Our\ninvestigation aims to map the current landscape and pave the way for future\nresearch in leveraging GenAI for network monitoring and management.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "cs.LG",
      "C.2; I.2"
    ],
    "primary_category": "cs.NI",
    "comment": "32 pages, 9 figure, 10 tables",
    "pdf_url": "http://arxiv.org/pdf/2502.08576v2",
    "published_date": "2025-02-12 17:10:34 UTC",
    "updated_date": "2025-04-11 09:41:45 UTC"
  },
  {
    "arxiv_id": "2502.08574v2",
    "title": "TANTE: Time-Adaptive Operator Learning via Neural Taylor Expansion",
    "authors": [
      "Zhikai Wu",
      "Sifan Wang",
      "Shiyang Zhang",
      "Sizhuang He",
      "Min Zhu",
      "Anran Jiao",
      "Lu Lu",
      "David van Dijk"
    ],
    "abstract": "Operator learning for time-dependent partial differential equations (PDEs)\nhas seen rapid progress in recent years, enabling efficient approximation of\ncomplex spatiotemporal dynamics. However, most existing methods rely on fixed\ntime step sizes during rollout, which limits their ability to adapt to varying\ntemporal complexity and often leads to error accumulation. To address this gap,\nwe propose the Time-Adaptive Transformer with Neural Taylor Expansion (TANTE),\na novel operator-learning framework that produces continuous-time predictions\nwith adaptive step sizes. TANTE predicts future states by performing a Taylor\nexpansion at the current state, where neural networks learn both the\nhigher-order temporal derivatives and the local radius of convergence. This\nallows the model to dynamically adjust its rollout based on the local behavior\nof the solution, thereby reducing cumulative error and improving computational\nefficiency. We demonstrate the effectiveness of TANTE across a wide range of\nPDE benchmarks, achieving superior accuracy and adaptability compared to\nfixed-step baselines, delivering accuracy gains of 10-50 % and speed-ups of\n30-80 % at inference.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "24 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.08574v2",
    "published_date": "2025-02-12 17:09:13 UTC",
    "updated_date": "2025-05-16 16:27:25 UTC"
  },
  {
    "arxiv_id": "2502.08573v1",
    "title": "A Novel Approach to for Multimodal Emotion Recognition : Multimodal semantic information fusion",
    "authors": [
      "Wei Dai",
      "Dequan Zheng",
      "Feng Yu",
      "Yanrong Zhang",
      "Yaohui Hou"
    ],
    "abstract": "With the advancement of artificial intelligence and computer vision\ntechnologies, multimodal emotion recognition has become a prominent research\ntopic. However, existing methods face challenges such as heterogeneous data\nfusion and the effective utilization of modality correlations. This paper\nproposes a novel multimodal emotion recognition approach, DeepMSI-MER, based on\nthe integration of contrastive learning and visual sequence compression. The\nproposed method enhances cross-modal feature fusion through contrastive\nlearning and reduces redundancy in the visual modality by leveraging visual\nsequence compression. Experimental results on two public datasets, IEMOCAP and\nMELD, demonstrate that DeepMSI-MER significantly improves the accuracy and\nrobustness of emotion recognition, validating the effectiveness of multimodal\nfeature fusion and the proposed approach.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.08573v1",
    "published_date": "2025-02-12 17:07:43 UTC",
    "updated_date": "2025-02-12 17:07:43 UTC"
  },
  {
    "arxiv_id": "2502.08560v1",
    "title": "Brain Latent Progression: Individual-based Spatiotemporal Disease Progression on 3D Brain MRIs via Latent Diffusion",
    "authors": [
      "Lemuel Puglisi",
      "Daniel C. Alexander",
      "Daniele RavÃ¬"
    ],
    "abstract": "The growing availability of longitudinal Magnetic Resonance Imaging (MRI)\ndatasets has facilitated Artificial Intelligence (AI)-driven modeling of\ndisease progression, making it possible to predict future medical scans for\nindividual patients. However, despite significant advancements in AI, current\nmethods continue to face challenges including achieving patient-specific\nindividualization, ensuring spatiotemporal consistency, efficiently utilizing\nlongitudinal data, and managing the substantial memory demands of 3D scans. To\naddress these challenges, we propose Brain Latent Progression (BrLP), a novel\nspatiotemporal model designed to predict individual-level disease progression\nin 3D brain MRIs. The key contributions in BrLP are fourfold: (i) it operates\nin a small latent space, mitigating the computational challenges posed by\nhigh-dimensional imaging data; (ii) it explicitly integrates subject metadata\nto enhance the individualization of predictions; (iii) it incorporates prior\nknowledge of disease dynamics through an auxiliary model, facilitating the\nintegration of longitudinal data; and (iv) it introduces the Latent Average\nStabilization (LAS) algorithm, which (a) enforces spatiotemporal consistency in\nthe predicted progression at inference time and (b) allows us to derive a\nmeasure of the uncertainty for the prediction. We train and evaluate BrLP on\n11,730 T1-weighted (T1w) brain MRIs from 2,805 subjects and validate its\ngeneralizability on an external test set comprising 2,257 MRIs from 962\nsubjects. Our experiments compare BrLP-generated MRI scans with real follow-up\nMRIs, demonstrating state-of-the-art accuracy compared to existing methods. The\ncode is publicly available at: https://github.com/LemuelPuglisi/BrLP.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "arXiv admin note: text overlap with arXiv:2405.03328",
    "pdf_url": "http://arxiv.org/pdf/2502.08560v1",
    "published_date": "2025-02-12 16:47:41 UTC",
    "updated_date": "2025-02-12 16:47:41 UTC"
  },
  {
    "arxiv_id": "2502.08556v1",
    "title": "Human-Centric Foundation Models: Perception, Generation and Agentic Modeling",
    "authors": [
      "Shixiang Tang",
      "Yizhou Wang",
      "Lu Chen",
      "Yuan Wang",
      "Sida Peng",
      "Dan Xu",
      "Wanli Ouyang"
    ],
    "abstract": "Human understanding and generation are critical for modeling digital humans\nand humanoid embodiments. Recently, Human-centric Foundation Models (HcFMs)\ninspired by the success of generalist models, such as large language and vision\nmodels, have emerged to unify diverse human-centric tasks into a single\nframework, surpassing traditional task-specific approaches. In this survey, we\npresent a comprehensive overview of HcFMs by proposing a taxonomy that\ncategorizes current approaches into four groups: (1) Human-centric Perception\nFoundation Models that capture fine-grained features for multi-modal 2D and 3D\nunderstanding. (2) Human-centric AIGC Foundation Models that generate\nhigh-fidelity, diverse human-related content. (3) Unified Perception and\nGeneration Models that integrate these capabilities to enhance both human\nunderstanding and synthesis. (4) Human-centric Agentic Foundation Models that\nextend beyond perception and generation to learn human-like intelligence and\ninteractive behaviors for humanoid embodied tasks. We review state-of-the-art\ntechniques, discuss emerging challenges and future research directions. This\nsurvey aims to serve as a roadmap for researchers and practitioners working\ntowards more robust, versatile, and intelligent digital human and embodiments\nmodeling.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "9 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.08556v1",
    "published_date": "2025-02-12 16:38:40 UTC",
    "updated_date": "2025-02-12 16:38:40 UTC"
  },
  {
    "arxiv_id": "2502.08554v1",
    "title": "Fostering Appropriate Reliance on Large Language Models: The Role of Explanations, Sources, and Inconsistencies",
    "authors": [
      "Sunnie S. Y. Kim",
      "Jennifer Wortman Vaughan",
      "Q. Vera Liao",
      "Tania Lombrozo",
      "Olga Russakovsky"
    ],
    "abstract": "Large language models (LLMs) can produce erroneous responses that sound\nfluent and convincing, raising the risk that users will rely on these responses\nas if they were correct. Mitigating such overreliance is a key challenge.\nThrough a think-aloud study in which participants use an LLM-infused\napplication to answer objective questions, we identify several features of LLM\nresponses that shape users' reliance: explanations (supporting details for\nanswers), inconsistencies in explanations, and sources. Through a large-scale,\npre-registered, controlled experiment (N=308), we isolate and study the effects\nof these features on users' reliance, accuracy, and other measures. We find\nthat the presence of explanations increases reliance on both correct and\nincorrect responses. However, we observe less reliance on incorrect responses\nwhen sources are provided or when explanations exhibit inconsistencies. We\ndiscuss the implications of these findings for fostering appropriate reliance\non LLMs.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "CHI 2025. This version includes the appendix",
    "pdf_url": "http://arxiv.org/pdf/2502.08554v1",
    "published_date": "2025-02-12 16:35:41 UTC",
    "updated_date": "2025-02-12 16:35:41 UTC"
  },
  {
    "arxiv_id": "2502.08550v1",
    "title": "LLMs can implicitly learn from mistakes in-context",
    "authors": [
      "Lisa Alazraki",
      "Maximilian Mozes",
      "Jon Ander Campos",
      "Yi Chern Tan",
      "Marek Rei",
      "Max Bartolo"
    ],
    "abstract": "Learning from mistakes is a fundamental feature of human intelligence.\nPrevious work has shown that Large Language Models (LLMs) can also learn from\nincorrect answers when provided with a comprehensive rationale detailing why an\nanswer is wrong or how to correct it. In this work, we examine whether LLMs can\nlearn from mistakes in mathematical reasoning tasks when these explanations are\nnot provided. We investigate if LLMs are able to implicitly infer such\nrationales simply from observing both incorrect and correct answers.\nSurprisingly, we find that LLMs perform better, on average, when rationales are\neliminated from the context and incorrect answers are simply shown alongside\ncorrect ones. This approach also substantially outperforms chain-of-thought\nprompting in our evaluations. We show that these results are consistent across\nLLMs of different sizes and varying reasoning abilities. Further, we carry out\nan in-depth analysis, and show that prompting with both wrong and correct\nanswers leads to greater performance and better generalisation than introducing\nadditional, more diverse question-answer pairs into the context. Finally, we\nshow that new rationales generated by models that have only observed incorrect\nand correct answers are scored equally as highly by humans as those produced\nwith the aid of exemplar rationales. Our results demonstrate that LLMs are\nindeed capable of in-context implicit learning.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.08550v1",
    "published_date": "2025-02-12 16:31:21 UTC",
    "updated_date": "2025-02-12 16:31:21 UTC"
  },
  {
    "arxiv_id": "2502.08547v1",
    "title": "Representation Learning to Advance Multi-institutional Studies with Electronic Health Record Data",
    "authors": [
      "Doudou Zhou",
      "Han Tong",
      "Linshanshan Wang",
      "Suqi Liu",
      "Xin Xiong",
      "Ziming Gan",
      "Romain Griffier",
      "Boris Hejblum",
      "Yun-Chung Liu",
      "Chuan Hong",
      "Clara-Lea Bonzel",
      "Tianrun Cai",
      "Kevin Pan",
      "Yuk-Lam Ho",
      "Lauren Costa",
      "Vidul A. Panickan",
      "J. Michael Gaziano",
      "Kenneth Mandl",
      "Vianney Jouhet",
      "Rodolphe Thiebaut",
      "Zongqi Xia",
      "Kelly Cho",
      "Katherine Liao",
      "Tianxi Cai"
    ],
    "abstract": "The adoption of EHRs has expanded opportunities to leverage data-driven\nalgorithms in clinical care and research. A major bottleneck in effectively\nconducting multi-institutional EHR studies is the data heterogeneity across\nsystems with numerous codes that either do not exist or represent different\nclinical concepts across institutions. The need for data privacy further limits\nthe feasibility of including multi-institutional patient-level data required to\nstudy similarities and differences across patient subgroups. To address these\nchallenges, we developed the GAME algorithm. Tested and validated across 7\ninstitutions and 2 languages, GAME integrates data in several levels: (1) at\nthe institutional level with knowledge graphs to establish relationships\nbetween codes and existing knowledge sources, providing the medical context for\nstandard codes and their relationship to each other; (2) between institutions,\nleveraging language models to determine the relationships between\ninstitution-specific codes with established standard codes; and (3) quantifying\nthe strength of the relationships between codes using a graph attention\nnetwork. Jointly trained embeddings are created using transfer and federated\nlearning to preserve data privacy. In this study, we demonstrate the\napplicability of GAME in selecting relevant features as inputs for AI-driven\nalgorithms in a range of conditions, e.g., heart failure, rheumatoid arthritis.\nWe then highlight the application of GAME harmonized multi-institutional EHR\ndata in a study of Alzheimer's disease outcomes and suicide risk among patients\nwith mental health disorders, without sharing patient-level data outside\nindividual institutions.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.08547v1",
    "published_date": "2025-02-12 16:29:39 UTC",
    "updated_date": "2025-02-12 16:29:39 UTC"
  },
  {
    "arxiv_id": "2503.16437v1",
    "title": "Haunted House: A text-based game for comparing the flexibility of mental models in humans and LLMs",
    "authors": [
      "Brett Puppart",
      "Paul-Henry Paltmann",
      "Jaan Aru"
    ],
    "abstract": "This study introduces \"Haunted House\" a novel text-based game designed to\ncompare the performance of humans and large language models (LLMs) in\nmodel-based reasoning. Players must escape from a house containing nine rooms\nin a 3x3 grid layout while avoiding the ghost. They are guided by verbal clues\nthat they get each time they move. In Study 1, the results from 98 human\nparticipants revealed a success rate of 31.6%, significantly outperforming\nseven state-of-the-art LLMs tested. Out of 140 attempts across seven LLMs, only\none attempt resulted in a pass by Claude 3 Opus. Preliminary results suggested\nthat GPT o3-mini-high performance might be higher, but not at the human level.\nFurther analysis of 29 human participants' moves in Study 2 indicated that LLMs\nfrequently struggled with random and illogical moves, while humans exhibited\nsuch errors less frequently. Our findings suggest that current LLMs encounter\ndifficulties in tasks that demand active model-based reasoning, offering\ninspiration for future benchmarks.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "q-bio.NC"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.16437v1",
    "published_date": "2025-02-12 16:19:40 UTC",
    "updated_date": "2025-02-12 16:19:40 UTC"
  },
  {
    "arxiv_id": "2502.08534v1",
    "title": "Input convex neural networks: universal approximation theorem and implementation for isotropic polyconvex hyperelastic energies",
    "authors": [
      "Gian-Luca Geuken",
      "Patrick Kurzeja",
      "David Wiedemann",
      "JÃ¶rn Mosler"
    ],
    "abstract": "This paper presents a novel framework of neural networks for isotropic\nhyperelasticity that enforces necessary physical and mathematical constraints\nwhile simultaneously satisfying the universal approximation theorem. The two\nkey ingredients are an input convex network architecture and a formulation in\nthe elementary polynomials of the signed singular values of the deformation\ngradient. In line with previously published networks, it can rigorously capture\nframe-indifference and polyconvexity - as well as further constraints like\nbalance of angular momentum and growth conditions. However and in contrast to\nprevious networks, a universal approximation theorem for the proposed approach\nis proven. To be more explicit, the proposed network can approximate any\nframe-indifferent, isotropic polyconvex energy (provided the network is large\nenough). This is possible by working with a sufficient and necessary criterion\nfor frame-indifferent, isotropic polyconvex functions. Comparative studies with\nexisting approaches identify the advantages of the proposed method,\nparticularly in approximating non-polyconvex energies as well as computing\npolyconvex hulls.",
    "categories": [
      "cs.CE",
      "cs.AI",
      "74B20, 68T07",
      "J.2; I.2.1"
    ],
    "primary_category": "cs.CE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.08534v1",
    "published_date": "2025-02-12 16:15:03 UTC",
    "updated_date": "2025-02-12 16:15:03 UTC"
  },
  {
    "arxiv_id": "2502.08518v1",
    "title": "FedMHO: Heterogeneous One-Shot Federated Learning Towards Resource-Constrained Edge Devices",
    "authors": [
      "Dezhong Yao",
      "Yuexin Shi",
      "Tongtong Liu",
      "Zhiqiang Xu"
    ],
    "abstract": "Federated Learning (FL) is increasingly adopted in edge computing scenarios,\nwhere a large number of heterogeneous clients operate under constrained or\nsufficient resources. The iterative training process in conventional FL\nintroduces significant computation and communication overhead, which is\nunfriendly for resource-constrained edge devices. One-shot FL has emerged as a\npromising approach to mitigate communication overhead, and model-heterogeneous\nFL solves the problem of diverse computing resources across clients. However,\nexisting methods face challenges in effectively managing model-heterogeneous\none-shot FL, often leading to unsatisfactory global model performance or\nreliance on auxiliary datasets. To address these challenges, we propose a novel\nFL framework named FedMHO, which leverages deep classification models on\nresource-sufficient clients and lightweight generative models on\nresource-constrained devices. On the server side, FedMHO involves a two-stage\nprocess that includes data generation and knowledge fusion. Furthermore, we\nintroduce FedMHO-MD and FedMHO-SD to mitigate the knowledge-forgetting problem\nduring the knowledge fusion stage, and an unsupervised data optimization\nsolution to improve the quality of synthetic samples. Comprehensive experiments\ndemonstrate the effectiveness of our methods, as they outperform\nstate-of-the-art baselines in various experimental setups.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.08518v1",
    "published_date": "2025-02-12 15:54:56 UTC",
    "updated_date": "2025-02-12 15:54:56 UTC"
  },
  {
    "arxiv_id": "2502.08512v1",
    "title": "Measuring Diversity in Synthetic Datasets",
    "authors": [
      "Yuchang Zhu",
      "Huizhe Zhang",
      "Bingzhe Wu",
      "Jintang Li",
      "Zibin Zheng",
      "Peilin Zhao",
      "Liang Chen",
      "Yatao Bian"
    ],
    "abstract": "Large language models (LLMs) are widely adopted to generate synthetic\ndatasets for various natural language processing (NLP) tasks, such as text\nclassification and summarization. However, accurately measuring the diversity\nof these synthetic datasets-an aspect crucial for robust model\nperformance-remains a significant challenge. In this paper, we introduce\nDCScore, a novel method for measuring synthetic dataset diversity from a\nclassification perspective. Specifically, DCScore formulates diversity\nevaluation as a sample classification task, leveraging mutual relationships\namong samples. We further provide theoretical verification of the\ndiversity-related axioms satisfied by DCScore, highlighting its role as a\nprincipled diversity evaluation method. Experimental results on synthetic\ndatasets reveal that DCScore enjoys a stronger correlation with multiple\ndiversity pseudo-truths of evaluated datasets, underscoring its effectiveness.\nMoreover, both empirical and theoretical evidence demonstrate that DCScore\nsubstantially reduces computational costs compared to existing approaches. Code\nis available at: https://github.com/BlueWhaleLab/DCScore.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.08512v1",
    "published_date": "2025-02-12 15:46:34 UTC",
    "updated_date": "2025-02-12 15:46:34 UTC"
  },
  {
    "arxiv_id": "2502.08503v1",
    "title": "Revisiting 3D LLM Benchmarks: Are We Really Testing 3D Capabilities?",
    "authors": [
      "Jiahe Jin",
      "Yanheng He",
      "Mingyan Yang"
    ],
    "abstract": "In this work, we identify the \"2D-Cheating\" problem in 3D LLM evaluation,\nwhere these tasks might be easily solved by VLMs with rendered images of point\nclouds, exposing ineffective evaluation of 3D LLMs' unique 3D capabilities. We\ntest VLM performance across multiple 3D LLM benchmarks and, using this as a\nreference, propose principles for better assessing genuine 3D understanding. We\nalso advocate explicitly separating 3D abilities from 1D or 2D aspects when\nevaluating 3D LLMs.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.08503v1",
    "published_date": "2025-02-12 15:34:45 UTC",
    "updated_date": "2025-02-12 15:34:45 UTC"
  },
  {
    "arxiv_id": "2502.08691v1",
    "title": "AgentSociety: Large-Scale Simulation of LLM-Driven Generative Agents Advances Understanding of Human Behaviors and Society",
    "authors": [
      "Jinghua Piao",
      "Yuwei Yan",
      "Jun Zhang",
      "Nian Li",
      "Junbo Yan",
      "Xiaochong Lan",
      "Zhihong Lu",
      "Zhiheng Zheng",
      "Jing Yi Wang",
      "Di Zhou",
      "Chen Gao",
      "Fengli Xu",
      "Fang Zhang",
      "Ke Rong",
      "Jun Su",
      "Yong Li"
    ],
    "abstract": "Understanding human behavior and society is a central focus in social\nsciences, with the rise of generative social science marking a significant\nparadigmatic shift. By leveraging bottom-up simulations, it replaces costly and\nlogistically challenging traditional experiments with scalable, replicable, and\nsystematic computational approaches for studying complex social dynamics.\nRecent advances in large language models (LLMs) have further transformed this\nresearch paradigm, enabling the creation of human-like generative social agents\nand realistic simulacra of society. In this paper, we propose AgentSociety, a\nlarge-scale social simulator that integrates LLM-driven agents, a realistic\nsocietal environment, and a powerful large-scale simulation engine. Based on\nthe proposed simulator, we generate social lives for over 10k agents,\nsimulating their 5 million interactions both among agents and between agents\nand their environment. Furthermore, we explore the potential of AgentSociety as\na testbed for computational social experiments, focusing on four key social\nissues: polarization, the spread of inflammatory messages, the effects of\nuniversal basic income policies, and the impact of external shocks such as\nhurricanes. These four issues serve as valuable cases for assessing\nAgentSociety's support for typical research methods -- such as surveys,\ninterviews, and interventions -- as well as for investigating the patterns,\ncauses, and underlying mechanisms of social issues. The alignment between\nAgentSociety's outcomes and real-world experimental results not only\ndemonstrates its ability to capture human behaviors and their underlying\nmechanisms, but also underscores its potential as an important platform for\nsocial scientists and policymakers.",
    "categories": [
      "cs.SI",
      "cs.AI"
    ],
    "primary_category": "cs.SI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.08691v1",
    "published_date": "2025-02-12 15:27:07 UTC",
    "updated_date": "2025-02-12 15:27:07 UTC"
  },
  {
    "arxiv_id": "2502.08482v1",
    "title": "Enhancing Auto-regressive Chain-of-Thought through Loop-Aligned Reasoning",
    "authors": [
      "Qifan Yu",
      "Zhenyu He",
      "Sijie Li",
      "Xun Zhou",
      "Jun Zhang",
      "Jingjing Xu",
      "Di He"
    ],
    "abstract": "Chain-of-Thought (CoT) prompting has emerged as a powerful technique for\nenhancing language model's reasoning capabilities. However, generating long and\ncorrect CoT trajectories is challenging. Recent studies have demonstrated that\nLooped Transformers possess remarkable length generalization capabilities, but\ntheir limited generality and adaptability prevent them from serving as an\nalternative to auto-regressive solutions. To better leverage the strengths of\nLooped Transformers, we propose RELAY (REasoning through Loop Alignment\niterativelY). Specifically, we align the steps of Chain-of-Thought (CoT)\nreasoning with loop iterations and apply intermediate supervision during the\ntraining of Looped Transformers. This additional iteration-wise supervision not\nonly preserves the Looped Transformer's ability for length generalization but\nalso enables it to predict CoT reasoning steps for unseen data. Therefore, we\nleverage this Looped Transformer to generate accurate reasoning chains for\ncomplex problems that exceed the training length, which will then be used to\nfine-tune an auto-regressive model. We conduct extensive experiments, and the\nresults demonstrate the effectiveness of our approach, with significant\nimprovements in the performance of the auto-regressive model. Code will be\nreleased at https://github.com/qifanyu/RELAY.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "work in progress",
    "pdf_url": "http://arxiv.org/pdf/2502.08482v1",
    "published_date": "2025-02-12 15:17:04 UTC",
    "updated_date": "2025-02-12 15:17:04 UTC"
  },
  {
    "arxiv_id": "2502.08468v1",
    "title": "mmE5: Improving Multimodal Multilingual Embeddings via High-quality Synthetic Data",
    "authors": [
      "Haonan Chen",
      "Liang Wang",
      "Nan Yang",
      "Yutao Zhu",
      "Ziliang Zhao",
      "Furu Wei",
      "Zhicheng Dou"
    ],
    "abstract": "Multimodal embedding models have gained significant attention for their\nability to map data from different modalities, such as text and images, into a\nunified representation space. However, the limited labeled multimodal data\noften hinders embedding performance. Recent approaches have leveraged data\nsynthesis to address this problem, yet the quality of synthetic data remains a\ncritical bottleneck. In this work, we identify three criteria for high-quality\nsynthetic multimodal data. First, broad scope ensures that the generated data\ncovers diverse tasks and modalities, making it applicable to various downstream\nscenarios. Second, robust cross-modal alignment makes different modalities\nsemantically consistent. Third, high fidelity ensures that the synthetic data\nmaintains realistic details to enhance its reliability. Guided by these\nprinciples, we synthesize datasets that: (1) cover a wide range of tasks,\nmodality combinations, and languages, (2) are generated via a deep thinking\nprocess within a single pass of a multimodal large language model, and (3)\nincorporate real-world images with accurate and relevant texts, ensuring\nfidelity through self-evaluation and refinement. Leveraging these high-quality\nsynthetic and labeled datasets, we train a multimodal multilingual E5 model\nmmE5. Extensive experiments demonstrate that mmE5 achieves state-of-the-art\nperformance on the MMEB Benchmark and superior multilingual performance on the\nXTD benchmark. Our codes, datasets and models are released in\nhttps://github.com/haon-chen/mmE5.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.08468v1",
    "published_date": "2025-02-12 15:03:33 UTC",
    "updated_date": "2025-02-12 15:03:33 UTC"
  },
  {
    "arxiv_id": "2502.08690v1",
    "title": "Skrr: Skip and Re-use Text Encoder Layers for Memory Efficient Text-to-Image Generation",
    "authors": [
      "Hoigi Seo",
      "Wongi Jeong",
      "Jae-sun Seo",
      "Se Young Chun"
    ],
    "abstract": "Large-scale text encoders in text-to-image (T2I) diffusion models have\ndemonstrated exceptional performance in generating high-quality images from\ntextual prompts. Unlike denoising modules that rely on multiple iterative\nsteps, text encoders require only a single forward pass to produce text\nembeddings. However, despite their minimal contribution to total inference time\nand floating-point operations (FLOPs), text encoders demand significantly\nhigher memory usage, up to eight times more than denoising modules. To address\nthis inefficiency, we propose Skip and Re-use layers (Skrr), a simple yet\neffective pruning strategy specifically designed for text encoders in T2I\ndiffusion models. Skrr exploits the inherent redundancy in transformer blocks\nby selectively skipping or reusing certain layers in a manner tailored for T2I\ntasks, thereby reducing memory consumption without compromising performance.\nExtensive experiments demonstrate that Skrr maintains image quality comparable\nto the original model even under high sparsity levels, outperforming existing\nblockwise pruning methods. Furthermore, Skrr achieves state-of-the-art memory\nefficiency while preserving performance across multiple evaluation metrics,\nincluding the FID, CLIP, DreamSim, and GenEval scores.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.08690v1",
    "published_date": "2025-02-12 15:03:26 UTC",
    "updated_date": "2025-02-12 15:03:26 UTC"
  },
  {
    "arxiv_id": "2502.08450v1",
    "title": "Towards Prompt Generalization: Grammar-aware Cross-Prompt Automated Essay Scoring",
    "authors": [
      "Heejin Do",
      "Taehee Park",
      "Sangwon Ryu",
      "Gary Geunbae Lee"
    ],
    "abstract": "In automated essay scoring (AES), recent efforts have shifted toward\ncross-prompt settings that score essays on unseen prompts for practical\napplicability. However, prior methods trained with essay-score pairs of\nspecific prompts pose challenges in obtaining prompt-generalized essay\nrepresentation. In this work, we propose a grammar-aware cross-prompt trait\nscoring (GAPS), which internally captures prompt-independent syntactic aspects\nto learn generic essay representation. We acquire grammatical error-corrected\ninformation in essays via the grammar error correction technique and design the\nAES model to seamlessly integrate such information. By internally referring to\nboth the corrected and the original essays, the model can focus on generic\nfeatures during training. Empirical experiments validate our method's\ngeneralizability, showing remarkable improvements in prompt-independent and\ngrammar-related traits. Furthermore, GAPS achieves notable QWK gains in the\nmost challenging cross-prompt scenario, highlighting its strength in evaluating\nunseen prompts.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "NAACL 2025 (Findings)",
    "pdf_url": "http://arxiv.org/pdf/2502.08450v1",
    "published_date": "2025-02-12 14:41:20 UTC",
    "updated_date": "2025-02-12 14:41:20 UTC"
  },
  {
    "arxiv_id": "2502.08449v2",
    "title": "CordViP: Correspondence-based Visuomotor Policy for Dexterous Manipulation in Real-World",
    "authors": [
      "Yankai Fu",
      "Qiuxuan Feng",
      "Ning Chen",
      "Zichen Zhou",
      "Mengzhen Liu",
      "Mingdong Wu",
      "Tianxing Chen",
      "Shanyu Rong",
      "Jiaming Liu",
      "Hao Dong",
      "Shanghang Zhang"
    ],
    "abstract": "Achieving human-level dexterity in robots is a key objective in the field of\nrobotic manipulation. Recent advancements in 3D-based imitation learning have\nshown promising results, providing an effective pathway to achieve this goal.\nHowever, obtaining high-quality 3D representations presents two key problems:\n(1) the quality of point clouds captured by a single-view camera is\nsignificantly affected by factors such as camera resolution, positioning, and\nocclusions caused by the dexterous hand; (2) the global point clouds lack\ncrucial contact information and spatial correspondences, which are necessary\nfor fine-grained dexterous manipulation tasks. To eliminate these limitations,\nwe propose CordViP, a novel framework that constructs and learns\ncorrespondences by leveraging the robust 6D pose estimation of objects and\nrobot proprioception. Specifically, we first introduce the interaction-aware\npoint clouds, which establish correspondences between the object and the hand.\nThese point clouds are then used for our pre-training policy, where we also\nincorporate object-centric contact maps and hand-arm coordination information,\neffectively capturing both spatial and temporal dynamics. Our method\ndemonstrates exceptional dexterous manipulation capabilities, achieving\nstate-of-the-art performance in six real-world tasks, surpassing other\nbaselines by a large margin. Experimental results also highlight the superior\ngeneralization and robustness of CordViP to different objects, viewpoints, and\nscenarios. Code and videos are available on\nhttps://aureleopku.github.io/CordViP.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "Robotics: Science and Systems (RSS) 2025. Videos, code:\n  https://aureleopku.github.io/CordViP",
    "pdf_url": "http://arxiv.org/pdf/2502.08449v2",
    "published_date": "2025-02-12 14:41:14 UTC",
    "updated_date": "2025-04-27 04:25:34 UTC"
  },
  {
    "arxiv_id": "2502.08441v2",
    "title": "Better Embeddings with Coupled Adam",
    "authors": [
      "Felix Stollenwerk",
      "Tobias Stollenwerk"
    ],
    "abstract": "Despite their remarkable capabilities, LLMs learn word representations that\nexhibit the undesirable yet poorly understood feature of anisotropy. In this\npaper, we argue that the second moment in Adam is a cause of anisotropic\nembeddings, and suggest a modified optimizer called Coupled Adam to mitigate\nthe problem. Our experiments demonstrate that Coupled Adam significantly\nimproves the quality of embeddings, while also leading to better upstream and\ndownstream performance on large enough datasets.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "17 pages, 8 figures; figures corrected",
    "pdf_url": "http://arxiv.org/pdf/2502.08441v2",
    "published_date": "2025-02-12 14:32:17 UTC",
    "updated_date": "2025-02-13 15:36:14 UTC"
  },
  {
    "arxiv_id": "2502.08438v1",
    "title": "Composite Sketch+Text Queries for Retrieving Objects with Elusive Names and Complex Interactions",
    "authors": [
      "Prajwal Gatti",
      "Kshitij Parikh",
      "Dhriti Prasanna Paul",
      "Manish Gupta",
      "Anand Mishra"
    ],
    "abstract": "Non-native speakers with limited vocabulary often struggle to name specific\nobjects despite being able to visualize them, e.g., people outside Australia\nsearching for numbats. Further, users may want to search for such elusive\nobjects with difficult-to-sketch interactions, e.g., numbat digging in the\nground. In such common but complex situations, users desire a search interface\nthat accepts composite multimodal queries comprising hand-drawn sketches of\ndifficult-to-name but easy-to-draw objects and text describing\ndifficult-to-sketch but easy-to-verbalize object attributes or interaction with\nthe scene. This novel problem statement distinctly differs from the previously\nwell-researched TBIR (text-based image retrieval) and SBIR (sketch-based image\nretrieval) problems. To study this under-explored task, we curate a dataset,\nCSTBIR (Composite Sketch+Text Based Image Retrieval), consisting of approx. 2M\nqueries and 108K natural scene images. Further, as a solution to this problem,\nwe propose a pretrained multimodal transformer-based baseline, STNET\n(Sketch+Text Network), that uses a hand-drawn sketch to localize relevant\nobjects in the natural scene image, and encodes the text and image to perform\nimage retrieval. In addition to contrastive learning, we propose multiple\ntraining objectives that improve the performance of our model. Extensive\nexperiments show that our proposed method outperforms several state-of-the-art\nretrieval methods for text-only, sketch-only, and composite query modalities.\nWe make the dataset and code available at our project website.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.IR",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at AAAI 2024, 9 pages. Project Website:\n  https://vl2g.github.io/projects/cstbir",
    "pdf_url": "http://arxiv.org/pdf/2502.08438v1",
    "published_date": "2025-02-12 14:22:59 UTC",
    "updated_date": "2025-02-12 14:22:59 UTC"
  },
  {
    "arxiv_id": "2502.08436v1",
    "title": "From Haystack to Needle: Label Space Reduction for Zero-shot Classification",
    "authors": [
      "Nathan Vandemoortele",
      "Bram Steenwinckel",
      "Femke Ongenae",
      "Sofie Van Hoecke"
    ],
    "abstract": "We present Label Space Reduction (LSR), a novel method for improving\nzero-shot classification performance of Large Language Models (LLMs). LSR\niteratively refines the classification label space by systematically ranking\nand reducing candidate classes, enabling the model to concentrate on the most\nrelevant options. By leveraging unlabeled data with the statistical learning\ncapabilities of data-driven models, LSR dynamically optimizes the label space\nrepresentation at test time. Our experiments across seven benchmarks\ndemonstrate that LSR improves macro-F1 scores by an average of 7.0% (up to\n14.2%) with Llama-3.1-70B and 3.3% (up to 11.1%) with Claude-3.5-Sonnet\ncompared to standard zero-shot classification baselines. To reduce the\ncomputational overhead of LSR, which requires an additional LLM call at each\niteration, we propose distilling the model into a probabilistic classifier,\nallowing for efficient inference.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Under review at ICML 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.08436v1",
    "published_date": "2025-02-12 14:20:36 UTC",
    "updated_date": "2025-02-12 14:20:36 UTC"
  },
  {
    "arxiv_id": "2502.10467v1",
    "title": "YNote: A Novel Music Notation for Fine-Tuning LLMs in Music Generation",
    "authors": [
      "Shao-Chien Lu",
      "Chen-Chen Yeh",
      "Hui-Lin Cho",
      "Chun-Chieh Hsu",
      "Tsai-Ling Hsu",
      "Cheng-Han Wu",
      "Timothy K. Shih",
      "Yu-Cheng Lin"
    ],
    "abstract": "The field of music generation using Large Language Models (LLMs) is evolving\nrapidly, yet existing music notation systems, such as MIDI, ABC Notation, and\nMusicXML, remain too complex for effective fine-tuning of LLMs. These formats\nare difficult for both machines and humans to interpret due to their\nvariability and intricate structure. To address these challenges, we introduce\nYNote, a simplified music notation system that uses only four characters to\nrepresent a note and its pitch. YNote's fixed format ensures consistency,\nmaking it easy to read and more suitable for fine-tuning LLMs. In our\nexperiments, we fine-tuned GPT-2 (124M) on a YNote-encoded dataset and achieved\nBLEU and ROUGE scores of 0.883 and 0.766, respectively. With just two notes as\nprompts, the model was able to generate coherent and stylistically relevant\nmusic. We believe YNote offers a practical alternative to existing music\nnotations for machine learning applications and has the potential to\nsignificantly enhance the quality of music generation using LLMs.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.10467v1",
    "published_date": "2025-02-12 14:10:52 UTC",
    "updated_date": "2025-02-12 14:10:52 UTC"
  },
  {
    "arxiv_id": "2502.08417v1",
    "title": "Handwritten Text Recognition: A Survey",
    "authors": [
      "Carlos Garrido-Munoz",
      "Antonio Rios-Vila",
      "Jorge Calvo-Zaragoza"
    ],
    "abstract": "Handwritten Text Recognition (HTR) has become an essential field within\npattern recognition and machine learning, with applications spanning historical\ndocument preservation to modern data entry and accessibility solutions. The\ncomplexity of HTR lies in the high variability of handwriting, which makes it\nchallenging to develop robust recognition systems. This survey examines the\nevolution of HTR models, tracing their progression from early heuristic-based\napproaches to contemporary state-of-the-art neural models, which leverage deep\nlearning techniques. The scope of the field has also expanded, with models\ninitially capable of recognizing only word-level content progressing to recent\nend-to-end document-level approaches. Our paper categorizes existing work into\ntwo primary levels of recognition: (1) \\emph{up to line-level}, encompassing\nword and line recognition, and (2) \\emph{beyond line-level}, addressing\nparagraph- and document-level challenges. We provide a unified framework that\nexamines research methodologies, recent advances in benchmarking, key datasets\nin the field, and a discussion of the results reported in the literature.\nFinally, we identify pressing research challenges and outline promising future\ndirections, aiming to equip researchers and practitioners with a roadmap for\nadvancing the field.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.08417v1",
    "published_date": "2025-02-12 13:59:37 UTC",
    "updated_date": "2025-02-12 13:59:37 UTC"
  },
  {
    "arxiv_id": "2502.08378v2",
    "title": "Learning Humanoid Standing-up Control across Diverse Postures",
    "authors": [
      "Tao Huang",
      "Junli Ren",
      "Huayi Wang",
      "Zirui Wang",
      "Qingwei Ben",
      "Muning Wen",
      "Xiao Chen",
      "Jianan Li",
      "Jiangmiao Pang"
    ],
    "abstract": "Standing-up control is crucial for humanoid robots, with the potential for\nintegration into current locomotion and loco-manipulation systems, such as fall\nrecovery. Existing approaches are either limited to simulations that overlook\nhardware constraints or rely on predefined ground-specific motion trajectories,\nfailing to enable standing up across postures in real-world scenes. To bridge\nthis gap, we present HoST (Humanoid Standing-up Control), a reinforcement\nlearning framework that learns standing-up control from scratch, enabling\nrobust sim-to-real transfer across diverse postures. HoST effectively learns\nposture-adaptive motions by leveraging a multi-critic architecture and\ncurriculum-based training on diverse simulated terrains. To ensure successful\nreal-world deployment, we constrain the motion with smoothness regularization\nand implicit motion speed bound to alleviate oscillatory and violent motions on\nphysical hardware, respectively. After simulation-based training, the learned\ncontrol policies are directly deployed on the Unitree G1 humanoid robot. Our\nexperimental results demonstrate that the controllers achieve smooth, stable,\nand robust standing-up motions across a wide range of laboratory and outdoor\nenvironments. Videos and code are available at\nhttps://taohuang13.github.io/humanoid-standingup.github.io/.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted to RSS 2025, Humanoid Standing-up Control, 12 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.08378v2",
    "published_date": "2025-02-12 13:10:09 UTC",
    "updated_date": "2025-04-19 20:24:29 UTC"
  },
  {
    "arxiv_id": "2502.08373v1",
    "title": "Uncertainty Aware Human-machine Collaboration in Camouflaged Object Detection",
    "authors": [
      "Ziyue Yang",
      "Kehan Wang",
      "Yuhang Ming",
      "Yong Peng",
      "Han Yang",
      "Qiong Chen",
      "Wanzeng Kong"
    ],
    "abstract": "Camouflaged Object Detection (COD), the task of identifying objects concealed\nwithin their environments, has seen rapid growth due to its wide range of\npractical applications. A key step toward developing trustworthy COD systems is\nthe estimation and effective utilization of uncertainty. In this work, we\npropose a human-machine collaboration framework for classifying the presence of\ncamouflaged objects, leveraging the complementary strengths of computer vision\n(CV) models and noninvasive brain-computer interfaces (BCIs). Our approach\nintroduces a multiview backbone to estimate uncertainty in CV model\npredictions, utilizes this uncertainty during training to improve efficiency,\nand defers low-confidence cases to human evaluation via RSVP-based BCIs during\ntesting for more reliable decision-making. We evaluated the framework in the\nCAMO dataset, achieving state-of-the-art results with an average improvement of\n4.56\\% in balanced accuracy (BA) and 3.66\\% in the F1 score compared to\nexisting methods. For the best-performing participants, the improvements\nreached 7.6\\% in BA and 6.66\\% in the F1 score. Analysis of the training\nprocess revealed a strong correlation between our confidence measures and\nprecision, while an ablation study confirmed the effectiveness of the proposed\ntraining policy and the human-machine collaboration strategy. In general, this\nwork reduces human cognitive load, improves system reliability, and provides a\nstrong foundation for advancements in real-world COD applications and\nhuman-computer interaction. Our code and data are available at:\nhttps://github.com/ziyuey/Uncertainty-aware-human-machine-collaboration-in-camouflaged-object-identification.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.08373v1",
    "published_date": "2025-02-12 13:05:24 UTC",
    "updated_date": "2025-02-12 13:05:24 UTC"
  },
  {
    "arxiv_id": "2502.08365v2",
    "title": "Towards Principled Multi-Agent Task Agnostic Exploration",
    "authors": [
      "Riccardo Zamboni",
      "Mirco Mutti",
      "Marcello Restelli"
    ],
    "abstract": "In reinforcement learning, we typically refer to task-agnostic exploration\nwhen we aim to explore the environment without access to the task specification\na priori. In a single-agent setting the problem has been extensively studied\nand mostly understood. A popular approach cast the task-agnostic objective as\nmaximizing the entropy of the state distribution induced by the agent's policy,\nfrom which principles and methods follows. In contrast, little is known about\ntask-agnostic exploration in multi-agent settings, which are ubiquitous in the\nreal world. How should different agents explore in the presence of others? In\nthis paper, we address this question through a generalization to multiple\nagents of the problem of maximizing the state distribution entropy. First, we\ninvestigate alternative formulations, highlighting respective positives and\nnegatives. Then, we present a scalable, decentralized, trust-region policy\nsearch algorithm to address the problem in practical settings. Finally, we\nprovide proof of concept experiments to both corroborate the theoretical\nfindings and pave the way for task-agnostic exploration in challenging\nmulti-agent settings.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.08365v2",
    "published_date": "2025-02-12 12:51:36 UTC",
    "updated_date": "2025-04-29 13:03:06 UTC"
  },
  {
    "arxiv_id": "2502.08363v1",
    "title": "Top-Theta Attention: Sparsifying Transformers by Compensated Thresholding",
    "authors": [
      "Konstantin Berestizshevsky",
      "Renzo Andri",
      "Lukas Cavigelli"
    ],
    "abstract": "The attention mechanism is essential for the impressive capabilities of\ntransformer-based Large Language Models (LLMs). However, calculating attention\nis computationally intensive due to its quadratic dependency on the sequence\nlength. We introduce a novel approach called Top-Theta Attention, or simply\nTop-$\\theta$, which selectively prunes less essential attention elements by\ncomparing them against carefully calibrated thresholds. This method greatly\nimproves the efficiency of self-attention matrix multiplication while\npreserving model accuracy, reducing the number of required V cache rows by 3x\nduring generative decoding and the number of attention elements by 10x during\nthe prefill phase. Our method does not require model retraining; instead, it\nrequires only a brief calibration phase to be resilient to distribution shifts,\nthus not requiring the thresholds for different datasets to be recalibrated.\nUnlike top-k attention, Top-$\\theta$ eliminates full-vector dependency, making\nit suitable for tiling and scale-out and avoiding costly top-k search. A key\ninnovation of our approach is the development of efficient numerical\ncompensation techniques, which help preserve model accuracy even under\naggressive pruning of attention scores.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "68T01",
      "I.2"
    ],
    "primary_category": "cs.CL",
    "comment": "8 pages, 11 figures, work under submission",
    "pdf_url": "http://arxiv.org/pdf/2502.08363v1",
    "published_date": "2025-02-12 12:50:15 UTC",
    "updated_date": "2025-02-12 12:50:15 UTC"
  },
  {
    "arxiv_id": "2502.09663v1",
    "title": "DiffEx: Explaining a Classifier with Diffusion Models to Identify Microscopic Cellular Variations",
    "authors": [
      "Anis Bourou",
      "Saranga Kingkor Mahanta",
      "Thomas Boyer",
      "ValÃ©rie Mezger",
      "Auguste Genovesio"
    ],
    "abstract": "In recent years, deep learning models have been extensively applied to\nbiological data across various modalities. Discriminative deep learning models\nhave excelled at classifying images into categories (e.g., healthy versus\ndiseased, treated versus untreated). However, these models are often perceived\nas black boxes due to their complexity and lack of interpretability, limiting\ntheir application in real-world biological contexts. In biological research,\nexplainability is essential: understanding classifier decisions and identifying\nsubtle differences between conditions are critical for elucidating the effects\nof treatments, disease progression, and biological processes. To address this\nchallenge, we propose DiffEx, a method for generating visually interpretable\nattributes to explain classifiers and identify microscopic cellular variations\nbetween different conditions. We demonstrate the effectiveness of DiffEx in\nexplaining classifiers trained on natural and biological images. Furthermore,\nwe use DiffEx to uncover phenotypic differences within microscopy datasets. By\noffering insights into cellular variations through classifier explanations,\nDiffEx has the potential to advance the understanding of diseases and aid drug\ndiscovery by identifying novel biomarkers.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "q-bio.CB"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.09663v1",
    "published_date": "2025-02-12 12:46:58 UTC",
    "updated_date": "2025-02-12 12:46:58 UTC"
  },
  {
    "arxiv_id": "2502.08689v1",
    "title": "Advancing machine fault diagnosis: A detailed examination of convolutional neural networks",
    "authors": [
      "Govind Vashishtha",
      "Sumika Chauhan",
      "Mert Sehri",
      "Justyna Hebda-Sobkowicz",
      "Radoslaw Zimroz",
      "Patrick Dumond",
      "Rajesh Kumar"
    ],
    "abstract": "The growing complexity of machinery and the increasing demand for operational\nefficiency and safety have driven the development of advanced fault diagnosis\ntechniques. Among these, convolutional neural networks (CNNs) have emerged as a\npowerful tool, offering robust and accurate fault detection and classification\ncapabilities. This comprehensive review delves into the application of CNNs in\nmachine fault diagnosis, covering its theoretical foundation, architectural\nvariations, and practical implementations. The strengths and limitations of\nCNNs are analyzed in this domain, discussing their effectiveness in handling\nvarious fault types, data complexities, and operational environments.\nFurthermore, we explore the evolving landscape of CNN-based fault diagnosis,\nexamining recent advancements in data augmentation, transfer learning, and\nhybrid architectures. Finally, we highlight future research directions and\npotential challenges to further enhance the application of CNNs for reliable\nand proactive machine fault diagnosis.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.08689v1",
    "published_date": "2025-02-12 12:41:13 UTC",
    "updated_date": "2025-02-12 12:41:13 UTC"
  },
  {
    "arxiv_id": "2502.15757v3",
    "title": "TLOB: A Novel Transformer Model with Dual Attention for Price Trend Prediction with Limit Order Book Data",
    "authors": [
      "Leonardo Berti",
      "Gjergji Kasneci"
    ],
    "abstract": "Price Trend Prediction (PTP) based on Limit Order Book (LOB) data is a\nfundamental challenge in financial markets. Despite advances in deep learning,\nexisting models fail to generalize across different market conditions and\nassets. Surprisingly, by adapting a simple MLP-based architecture to LOB, we\nshow that we surpass SoTA performance; thus, challenging the necessity of\ncomplex architectures. Unlike past work that shows robustness issues, we\npropose TLOB, a transformer-based model that uses a dual attention mechanism to\ncapture spatial and temporal dependencies in LOB data. This allows it to\nadaptively focus on the market microstructure, making it particularly effective\nfor longer-horizon predictions and volatile market conditions. We also\nintroduce a new labeling method that improves on previous ones, removing the\nhorizon bias. We evaluate TLOB's effectiveness across four horizons, using the\nestablished FI-2010 benchmark, a NASDAQ and a Bitcoin dataset. TLOB outperforms\nSoTA methods in every dataset and horizon. Additionally, we empirically show\nhow stock price predictability has declined over time, -6.68 in F1-score,\nhighlighting the growing market efficiency. Predictability must be considered\nin relation to transaction costs, so we experimented with defining trends using\nan average spread, reflecting the primary transaction cost. The resulting\nperformance deterioration underscores the complexity of translating trend\nclassification into profitable trading strategies. We argue that our work\nprovides new insights into the evolving landscape of stock price trend\nprediction and sets a strong foundation for future advancements in financial\nAI. We release the code at https://github.com/LeonardoBerti00/TLOB.",
    "categories": [
      "q-fin.ST",
      "cs.AI",
      "cs.LG",
      "q-fin.TR"
    ],
    "primary_category": "q-fin.ST",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15757v3",
    "published_date": "2025-02-12 12:41:10 UTC",
    "updated_date": "2025-05-07 21:14:14 UTC"
  },
  {
    "arxiv_id": "2502.08353v1",
    "title": "Trustworthy GNNs with LLMs: A Systematic Review and Taxonomy",
    "authors": [
      "Ruizhan Xue",
      "Huimin Deng",
      "Fang He",
      "Maojun Wang",
      "Zeyu Zhang"
    ],
    "abstract": "With the extensive application of Graph Neural Networks (GNNs) across various\ndomains, their trustworthiness has emerged as a focal point of research. Some\nexisting studies have shown that the integration of large language models\n(LLMs) can improve the semantic understanding and generation capabilities of\nGNNs, which in turn improves the trustworthiness of GNNs from various aspects.\nOur review introduces a taxonomy that offers researchers a clear framework for\ncomprehending the principles and applications of different methods and helps\nclarify the connections and differences among various approaches. Then we\nsystematically survey representative approaches along the four categories of\nour taxonomy. Through our taxonomy, researchers can understand the applicable\nscenarios, potential advantages, and limitations of each approach for the the\ntrusted integration of GNNs with LLMs. Finally, we present some promising\ndirections of work and future trends for the integration of LLMs and GNNs to\nimprove model trustworthiness.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Submitted to IJCAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.08353v1",
    "published_date": "2025-02-12 12:28:39 UTC",
    "updated_date": "2025-02-12 12:28:39 UTC"
  },
  {
    "arxiv_id": "2502.08346v3",
    "title": "Graph Foundation Models for Recommendation: A Comprehensive Survey",
    "authors": [
      "Bin Wu",
      "Yihang Wang",
      "Yuanhao Zeng",
      "Jiawei Liu",
      "Jiashu Zhao",
      "Cheng Yang",
      "Yawen Li",
      "Long Xia",
      "Dawei Yin",
      "Chuan Shi"
    ],
    "abstract": "Recommender systems (RS) serve as a fundamental tool for navigating the vast\nexpanse of online information, with deep learning advancements playing an\nincreasingly important role in improving ranking accuracy. Among these, graph\nneural networks (GNNs) excel at extracting higher-order structural information,\nwhile large language models (LLMs) are designed to process and comprehend\nnatural language, making both approaches highly effective and widely adopted.\nRecent research has focused on graph foundation models (GFMs), which integrate\nthe strengths of GNNs and LLMs to model complex RS problems more efficiently by\nleveraging the graph-based structure of user-item relationships alongside\ntextual understanding. In this survey, we provide a comprehensive overview of\nGFM-based RS technologies by introducing a clear taxonomy of current\napproaches, diving into methodological details, and highlighting key challenges\nand future directions. By synthesizing recent advancements, we aim to offer\nvaluable insights into the evolving landscape of GFM-based recommender systems.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.08346v3",
    "published_date": "2025-02-12 12:13:51 UTC",
    "updated_date": "2025-02-17 02:47:18 UTC"
  },
  {
    "arxiv_id": "2502.08340v1",
    "title": "Hierarchical Learning-based Graph Partition for Large-scale Vehicle Routing Problems",
    "authors": [
      "Yuxin Pan",
      "Ruohong Liu",
      "Yize Chen",
      "Zhiguang Cao",
      "Fangzhen Lin"
    ],
    "abstract": "Neural solvers based on the divide-and-conquer approach for Vehicle Routing\nProblems (VRPs) in general, and capacitated VRP (CVRP) in particular,\nintegrates the global partition of an instance with local constructions for\neach subproblem to enhance generalization. However, during the global partition\nphase, misclusterings within subgraphs have a tendency to progressively\ncompound throughout the multi-step decoding process of the learning-based\npartition policy. This suboptimal behavior in the global partition phase, in\nturn, may lead to a dramatic deterioration in the performance of the overall\ndecomposition-based system, despite using optimal local constructions. To\naddress these challenges, we propose a versatile Hierarchical Learning-based\nGraph Partition (HLGP) framework, which is tailored to benefit the partition of\nCVRP instances by synergistically integrating global and local partition\npolicies. Specifically, the global partition policy is tasked with creating the\ncoarse multi-way partition to generate the sequence of simpler two-way\npartition subtasks. These subtasks mark the initiation of the subsequent K\nlocal partition levels. At each local partition level, subtasks exclusive for\nthis level are assigned to the local partition policy which benefits from the\ninsensitive local topological features to incrementally alleviate the\ncompounded errors. This framework is versatile in the sense that it optimizes\nthe involved partition policies towards a unified objective harmoniously\ncompatible with both reinforcement learning (RL) and supervised learning (SL).\n(*Due to the notification of arXiv \"The Abstract field cannot be longer than\n1,920 characters\", the appeared Abstract is shortened. For the full Abstract,\nplease download the Article.)",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted as a Full Paper at AAMAS 2025 (24th International Conference\n  on Autonomous Agents and Multiagent Systems)",
    "pdf_url": "http://arxiv.org/pdf/2502.08340v1",
    "published_date": "2025-02-12 12:07:09 UTC",
    "updated_date": "2025-02-12 12:07:09 UTC"
  },
  {
    "arxiv_id": "2502.08686v1",
    "title": "EEG Artifact Detection and Correction with Deep Autoencoders",
    "authors": [
      "David AquiluÃ©-Llorens",
      "Aureli Soria-Frisch"
    ],
    "abstract": "EEG signals convey important information about brain activity both in healthy\nand pathological conditions. However, they are inherently noisy, which poses\nsignificant challenges for accurate analysis and interpretation. Traditional\nEEG artifact removal methods, while effective, often require extensive expert\nintervention. This study presents LSTEEG, a novel LSTM-based autoencoder\ndesigned for the detection and correction of artifacts in EEG signals.\nLeveraging deep learning, particularly LSTM layers, LSTEEG captures non-linear\ndependencies in sequential EEG data. LSTEEG demonstrates superior performance\nin both artifact detection and correction tasks compared to other\nstate-of-the-art convolutional autoencoders. Our methodology enhances the\ninterpretability and utility of the autoencoder's latent space, enabling\ndata-driven automated artefact removal in EEG its application in downstream\ntasks. This research advances the field of efficient and accurate multi-channel\nEEG preprocessing, and promotes the implementation and usage of automated EEG\nanalysis pipelines for brain health applications.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.08686v1",
    "published_date": "2025-02-12 12:06:36 UTC",
    "updated_date": "2025-02-12 12:06:36 UTC"
  },
  {
    "arxiv_id": "2502.08685v1",
    "title": "Beyond Models! Explainable Data Valuation and Metric Adaption for Recommendation",
    "authors": [
      "Renqi Jia",
      "Xiaokun Zhang",
      "Bowei He",
      "Qiannan Zhu",
      "Weitao Xu",
      "Jiehao Chen",
      "Chen Ma"
    ],
    "abstract": "User behavior records serve as the foundation for recommender systems. While\nthe behavior data exhibits ease of acquisition, it often suffers from varying\nquality. Current methods employ data valuation to discern high-quality data\nfrom low-quality data. However, they tend to employ black-box design, lacking\ntransparency and interpretability. Besides, they are typically tailored to\nspecific evaluation metrics, leading to limited generality across various\ntasks. To overcome these issues, we propose an explainable and versatile\nframework DVR which can enhance the efficiency of data utilization tailored to\nany requirements of the model architectures and evaluation metrics. For\nexplainable data valuation, a data valuator is presented to evaluate the data\nquality via calculating its Shapley value from the game-theoretic perspective,\nensuring robust mathematical properties and reliability. In order to\naccommodate various evaluation metrics, including differentiable and\nnon-differentiable ones, a metric adapter is devised based on reinforcement\nlearning, where a metric is treated as the reinforcement reward that guides\nmodel optimization. Extensive experiments conducted on various benchmarks\nverify that our framework can improve the performance of current recommendation\nalgorithms on various metrics including ranking accuracy, diversity, and\nfairness. Specifically, our framework achieves up to 34.7\\% improvements over\nexisting methods in terms of representative NDCG metric. The code is available\nat https://github.com/renqii/DVR.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.08685v1",
    "published_date": "2025-02-12 12:01:08 UTC",
    "updated_date": "2025-02-12 12:01:08 UTC"
  },
  {
    "arxiv_id": "2502.08337v1",
    "title": "Hierarchical Multi-Agent Framework for Carbon-Efficient Liquid-Cooled Data Center Clusters",
    "authors": [
      "Soumyendu Sarkar",
      "Avisek Naug",
      "Antonio Guillen",
      "Vineet Gundecha",
      "Ricardo Luna Gutierrez",
      "Sahand Ghorbanpour",
      "Sajad Mousavi",
      "Ashwin Ramesh Babu",
      "Desik Rengarajan",
      "Cullen Bash"
    ],
    "abstract": "Reducing the environmental impact of cloud computing requires efficient\nworkload distribution across geographically dispersed Data Center Clusters\n(DCCs) and simultaneously optimizing liquid and air (HVAC) cooling with time\nshift of workloads within individual data centers (DC). This paper introduces\nGreen-DCC, which proposes a Reinforcement Learning (RL) based hierarchical\ncontroller to optimize both workload and liquid cooling dynamically in a DCC.\nBy incorporating factors such as weather, carbon intensity, and resource\navailability, Green-DCC addresses realistic constraints and interdependencies.\nWe demonstrate how the system optimizes multiple data centers synchronously,\nenabling the scope of digital twins, and compare the performance of various RL\napproaches based on carbon emissions and sustainability metrics while also\noffering a framework and benchmark simulation for broader ML research in\nsustainability.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.08337v1",
    "published_date": "2025-02-12 12:00:58 UTC",
    "updated_date": "2025-02-12 12:00:58 UTC"
  },
  {
    "arxiv_id": "2502.08336v2",
    "title": "Salience-Invariant Consistent Policy Learning for Generalization in Visual Reinforcement Learning",
    "authors": [
      "Jingbo Sun",
      "Songjun Tu",
      "Qichao Zhang",
      "Ke Chen",
      "Dongbin Zhao"
    ],
    "abstract": "Generalizing policies to unseen scenarios remains a critical challenge in\nvisual reinforcement learning, where agents often overfit to the specific\nvisual observations of the training environment. In unseen environments,\ndistracting pixels may lead agents to extract representations containing\ntask-irrelevant information. As a result, agents may deviate from the optimal\nbehaviors learned during training, thereby hindering visual generalization.To\naddress this issue, we propose the Salience-Invariant Consistent Policy\nLearning (SCPL) algorithm, an efficient framework for zero-shot generalization.\nOur approach introduces a novel value consistency module alongside a dynamics\nmodule to effectively capture task-relevant representations. The value\nconsistency module, guided by saliency, ensures the agent focuses on\ntask-relevant pixels in both original and perturbed observations, while the\ndynamics module uses augmented data to help the encoder capture dynamic- and\nreward-relevant representations. Additionally, our theoretical analysis\nhighlights the importance of policy consistency for generalization. To\nstrengthen this, we introduce a policy consistency module with a KL divergence\nconstraint to maintain consistent policies across original and perturbed\nobservations.Extensive experiments on the DMC-GB, Robotic Manipulation, and\nCARLA benchmarks demonstrate that SCPL significantly outperforms\nstate-of-the-art methods in terms of generalization. Notably, SCPL achieves\naverage performance improvements of 14\\%, 39\\%, and 69\\% in the challenging DMC\nvideo hard setting, the Robotic hard setting, and the CARLA benchmark,\nrespectively.Project Page: https://sites.google.com/view/scpl-rl.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.08336v2",
    "published_date": "2025-02-12 12:00:16 UTC",
    "updated_date": "2025-02-24 12:02:47 UTC"
  },
  {
    "arxiv_id": "2502.08332v2",
    "title": "Modification and Generated-Text Detection: Achieving Dual Detection Capabilities for the Outputs of LLM by Watermark",
    "authors": [
      "Yuhang Cai",
      "Yaofei Wang",
      "Donghui Hu",
      "Chen Gu"
    ],
    "abstract": "The development of large language models (LLMs) has raised concerns about\npotential misuse. One practical solution is to embed a watermark in the text,\nallowing ownership verification through watermark extraction. Existing methods\nprimarily focus on defending against modification attacks, often neglecting\nother spoofing attacks. For example, attackers can alter the watermarked text\nto produce harmful content without compromising the presence of the watermark,\nwhich could lead to false attribution of this malicious content to the LLM.\nThis situation poses a serious threat to the LLMs service providers and\nhighlights the significance of achieving modification detection and\ngenerated-text detection simultaneously. Therefore, we propose a technique to\ndetect modifications in text for unbiased watermark which is sensitive to\nmodification. We introduce a new metric called ``discarded tokens\", which\nmeasures the number of tokens not included in watermark detection. When a\nmodification occurs, this metric changes and can serve as evidence of the\nmodification. Additionally, we improve the watermark detection process and\nintroduce a novel method for unbiased watermark. Our experiments demonstrate\nthat we can achieve effective dual detection capabilities: modification\ndetection and generated-text detection by watermark.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.08332v2",
    "published_date": "2025-02-12 11:56:40 UTC",
    "updated_date": "2025-03-01 05:14:12 UTC"
  },
  {
    "arxiv_id": "2502.08317v2",
    "title": "Mitigating Hallucinations in Multimodal Spatial Relations through Constraint-Aware Prompting",
    "authors": [
      "Jiarui Wu",
      "Zhuo Liu",
      "Hangfeng He"
    ],
    "abstract": "Spatial relation hallucinations pose a persistent challenge in large\nvision-language models (LVLMs), leading to generate incorrect predictions about\nobject positions and spatial configurations within an image. To address this\nissue, we propose a constraint-aware prompting framework designed to reduce\nspatial relation hallucinations. Specifically, we introduce two types of\nconstraints: (1) bidirectional constraint, which ensures consistency in\npairwise object relations, and (2) transitivity constraint, which enforces\nrelational dependence across multiple objects. By incorporating these\nconstraints, LVLMs can produce more spatially coherent and consistent outputs.\nWe evaluate our method on three widely-used spatial relation datasets,\ndemonstrating performance improvements over existing approaches. Additionally,\na systematic analysis of various bidirectional relation analysis choices and\ntransitivity reference selections highlights greater possibilities of our\nmethods in incorporating constraints to mitigate spatial relation\nhallucinations.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CL",
    "comment": "19 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.08317v2",
    "published_date": "2025-02-12 11:32:19 UTC",
    "updated_date": "2025-03-21 03:39:57 UTC"
  },
  {
    "arxiv_id": "2502.08684v1",
    "title": "Self-Evaluation for Job-Shop Scheduling",
    "authors": [
      "Imanol Echeverria",
      "Maialen Murua",
      "Roberto Santana"
    ],
    "abstract": "Combinatorial optimization problems, such as scheduling and route planning,\nare crucial in various industries but are computationally intractable due to\ntheir NP-hard nature. Neural Combinatorial Optimization methods leverage\nmachine learning to address these challenges but often depend on sequential\ndecision-making, which is prone to error accumulation as small mistakes\npropagate throughout the process. Inspired by self-evaluation techniques in\nLarge Language Models, we propose a novel framework that generates and\nevaluates subsets of assignments, moving beyond traditional stepwise\napproaches. Applied to the Job-Shop Scheduling Problem, our method integrates a\nheterogeneous graph neural network with a Transformer to build a policy model\nand a self-evaluation function. Experimental validation on challenging,\nwell-known benchmarks demonstrates the effectiveness of our approach,\nsurpassing state-of-the-art methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.08684v1",
    "published_date": "2025-02-12 11:22:33 UTC",
    "updated_date": "2025-02-12 11:22:33 UTC"
  },
  {
    "arxiv_id": "2502.18487v1",
    "title": "AuPair: Golden Example Pairs for Code Repair",
    "authors": [
      "Aditi Mavalankar",
      "Hassan Mansoor",
      "Zita Marinho",
      "Masha Samsikova",
      "Tom Schaul"
    ],
    "abstract": "Scaling up inference-time compute has proven to be a valuable strategy in\nimproving the performance of Large Language Models (LLMs) without fine-tuning.\nAn important task that can benefit from additional inference-time compute is\nself-repair; given an initial flawed response, or guess, the LLM corrects its\nown mistake and produces an improved response, or fix. We leverage the\nin-context learning ability of LLMs to perform self-repair in the coding\ndomain. The key contribution of our paper is an approach that synthesises and\nselects an ordered set of golden example pairs, or AuPairs, of these initial\nguesses and subsequent fixes for the corresponding problems. Each such AuPair\nis provided as a single in-context example at inference time to generate a\nrepaired solution. For an inference-time compute budget of $N$ LLM calls per\nproblem, $N$ AuPairs are used to generate $N$ repaired solutions, out of which\nthe highest-scoring solution is selected as the final answer. The underlying\nintuition is that if the LLM is given a different example of fixing an\nincorrect guess each time, it can subsequently generate a diverse set of\nrepaired solutions. Our algorithm selects these AuPairs in a manner that\nmaximises complementarity and usefulness. We demonstrate the results of our\nalgorithm on 5 LLMs across 7 competitive programming datasets for the code\nrepair task. Our algorithm yields a significant boost in performance compared\nto best-of-$N$ and self-repair, and also exhibits strong generalisation across\ndatasets and models. Moreover, our approach shows significantly stronger\nscaling with inference-time compute budget compared to baselines.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.18487v1",
    "published_date": "2025-02-12 11:07:04 UTC",
    "updated_date": "2025-02-12 11:07:04 UTC"
  },
  {
    "arxiv_id": "2502.08302v1",
    "title": "HDT: Hierarchical Discrete Transformer for Multivariate Time Series Forecasting",
    "authors": [
      "Shibo Feng",
      "Peilin Zhao",
      "Liu Liu",
      "Pengcheng Wu",
      "Zhiqi Shen"
    ],
    "abstract": "Generative models have gained significant attention in multivariate time\nseries forecasting (MTS), particularly due to their ability to generate\nhigh-fidelity samples. Forecasting the probability distribution of multivariate\ntime series is a challenging yet practical task. Although some recent attempts\nhave been made to handle this task, two major challenges persist: 1) some\nexisting generative methods underperform in high-dimensional multivariate time\nseries forecasting, which is hard to scale to higher dimensions; 2) the\ninherent high-dimensional multivariate attributes constrain the forecasting\nlengths of existing generative models. In this paper, we point out that\ndiscrete token representations can model high-dimensional MTS with faster\ninference time, and forecasting the target with long-term trends of itself can\nextend the forecasting length with high accuracy. Motivated by this, we propose\na vector quantized framework called Hierarchical Discrete Transformer (HDT)\nthat models time series into discrete token representations with l2\nnormalization enhanced vector quantized strategy, in which we transform the MTS\nforecasting into discrete tokens generation. To address the limitations of\ngenerative models in long-term forecasting, we propose a hierarchical discrete\nTransformer. This model captures the discrete long-term trend of the target at\nthe low level and leverages this trend as a condition to generate the discrete\nrepresentation of the target at the high level that introduces the features of\nthe target itself to extend the forecasting length in high-dimensional MTS.\nExtensive experiments on five popular MTS datasets verify the effectiveness of\nour proposed method.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.08302v1",
    "published_date": "2025-02-12 11:03:51 UTC",
    "updated_date": "2025-02-12 11:03:51 UTC"
  },
  {
    "arxiv_id": "2502.08301v1",
    "title": "Compromising Honesty and Harmlessness in Language Models via Deception Attacks",
    "authors": [
      "LaurÃ¨ne Vaugrante",
      "Francesca Carlon",
      "Maluna Menke",
      "Thilo Hagendorff"
    ],
    "abstract": "Recent research on large language models (LLMs) has demonstrated their\nability to understand and employ deceptive behavior, even without explicit\nprompting. However, such behavior has only been observed in rare, specialized\ncases and has not been shown to pose a serious risk to users. Additionally,\nresearch on AI alignment has made significant advancements in training models\nto refuse generating misleading or toxic content. As a result, LLMs generally\nbecame honest and harmless. In this study, we introduce a novel attack that\nundermines both of these traits, revealing a vulnerability that, if exploited,\ncould have serious real-world consequences. In particular, we introduce\nfine-tuning methods that enhance deception tendencies beyond model safeguards.\nThese \"deception attacks\" customize models to mislead users when prompted on\nchosen topics while remaining accurate on others. Furthermore, we find that\ndeceptive models also exhibit toxicity, generating hate speech, stereotypes,\nand other harmful content. Finally, we assess whether models can deceive\nconsistently in multi-turn dialogues, yielding mixed results. Given that\nmillions of users interact with LLM-based chatbots, voice assistants, agents,\nand other interfaces where trustworthiness cannot be ensured, securing these\nmodels against deception attacks is critical.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.08301v1",
    "published_date": "2025-02-12 11:02:59 UTC",
    "updated_date": "2025-02-12 11:02:59 UTC"
  },
  {
    "arxiv_id": "2502.08298v1",
    "title": "Improving Existing Optimization Algorithms with LLMs",
    "authors": [
      "Camilo ChacÃ³n Sartori",
      "Christian Blum"
    ],
    "abstract": "The integration of Large Language Models (LLMs) into optimization has created\na powerful synergy, opening exciting research opportunities. This paper\ninvestigates how LLMs can enhance existing optimization algorithms. Using their\npre-trained knowledge, we demonstrate their ability to propose innovative\nheuristic variations and implementation strategies. To evaluate this, we\napplied a non-trivial optimization algorithm, Construct, Merge, Solve and Adapt\n(CMSA) -- a hybrid metaheuristic for combinatorial optimization problems that\nincorporates a heuristic in the solution construction phase. Our results show\nthat an alternative heuristic proposed by GPT-4o outperforms the\nexpert-designed heuristic of CMSA, with the performance gap widening on larger\nand denser graphs. Project URL: https://imp-opt-algo-llms.surge.sh/",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.SE",
      "I.2.7; I.2.8"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.08298v1",
    "published_date": "2025-02-12 10:58:57 UTC",
    "updated_date": "2025-02-12 10:58:57 UTC"
  },
  {
    "arxiv_id": "2502.08682v1",
    "title": "On the Role of Pre-trained Embeddings in Binary Code Analysis",
    "authors": [
      "Alwin Maier",
      "Felix Weissberg",
      "Konrad Rieck"
    ],
    "abstract": "Deep learning has enabled remarkable progress in binary code analysis. In\nparticular, pre-trained embeddings of assembly code have become a gold standard\nfor solving analysis tasks, such as measuring code similarity or recognizing\nfunctions. These embeddings are capable of learning a vector representation\nfrom unlabeled code. In contrast to natural language processing, however, label\ninformation is not scarce for many tasks in binary code analysis. For example,\nlabeled training data for function boundaries, optimization levels, and\nargument types can be easily derived from debug information provided by a\ncompiler. Consequently, the main motivation of embeddings does not transfer\ndirectly to binary code analysis.\n  In this paper, we explore the role of pre-trained embeddings from a critical\nperspective. To this end, we systematically evaluate recent embeddings for\nassembly code on five downstream tasks using a corpus of 1.2 million functions\nfrom the Debian distribution. We observe that several embeddings perform\nsimilarly when sufficient labeled data is available, and that differences\nreported in prior work are hardly noticeable. Surprisingly, we find that\nend-to-end learning without pre-training performs best on average, which calls\ninto question the need for specialized embeddings. By varying the amount of\nlabeled data, we eventually derive guidelines for when embeddings offer\nadvantages and when end-to-end learning is preferable for binary code analysis.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "I.2.6"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.08682v1",
    "published_date": "2025-02-12 10:50:46 UTC",
    "updated_date": "2025-02-12 10:50:46 UTC"
  },
  {
    "arxiv_id": "2502.08287v1",
    "title": "CRISP: A Framework for Cryo-EM Image Segmentation and Processing with Conditional Random Field",
    "authors": [
      "Szu-Chi Chung",
      "Po-Cheng Chou"
    ],
    "abstract": "Differentiating signals from the background in micrographs is a critical\ninitial step for cryogenic electron microscopy (cryo-EM), yet it remains\nlaborious due to low signal-to-noise ratio (SNR), the presence of contaminants\nand densely packed particles of varying sizes. Although image segmentation has\nrecently been introduced to distinguish particles at the pixel level, the low\nSNR complicates the automated generation of accurate annotations for training\nsupervised models. Moreover, platforms for systematically comparing different\ndesign choices in pipeline construction are lacking. Thus, a modular framework\nis essential to understand the advantages and limitations of this approach and\ndrive further development. To address these challenges, we present a pipeline\nthat automatically generates high-quality segmentation maps from cryo-EM data\nto serve as ground truth labels. Our modular framework enables the selection of\nvarious segmentation models and loss functions. We also integrate Conditional\nRandom Fields (CRFs) with different solvers and feature sets to refine coarse\npredictions, thereby producing fine-grained segmentation. This flexibility\nfacilitates optimal configurations tailored to cryo-EM datasets. When trained\non a limited set of micrographs, our approach achieves over 90% accuracy,\nrecall, precision, Intersection over Union (IoU), and F1-score on synthetic\ndata. Furthermore, to demonstrate our framework's efficacy in downstream\nanalyses, we show that the particles extracted by our pipeline produce 3D\ndensity maps with higher resolution than those generated by existing particle\npickers on real experimental datasets, while achieving performance comparable\nto that of manually curated datasets from experts.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "31 pages, 28 Figures",
    "pdf_url": "http://arxiv.org/pdf/2502.08287v1",
    "published_date": "2025-02-12 10:44:45 UTC",
    "updated_date": "2025-02-12 10:44:45 UTC"
  },
  {
    "arxiv_id": "2502.08282v2",
    "title": "Individualised Treatment Effects Estimation with Composite Treatments and Composite Outcomes",
    "authors": [
      "Vinod Kumar Chauhan",
      "Lei Clifton",
      "Gaurav Nigam",
      "David A. Clifton"
    ],
    "abstract": "Estimating individualised treatment effect (ITE) -- that is the causal effect\nof a set of variables (also called exposures, treatments, actions, policies, or\ninterventions), referred to as \\textit{composite treatments}, on a set of\noutcome variables of interest, referred to as \\textit{composite outcomes}, for\na unit from observational data -- remains a fundamental problem in causal\ninference with applications across disciplines, such as healthcare, economics,\neducation, social science, marketing, and computer science. Previous work in\ncausal machine learning for ITE estimation is limited to simple settings, like\nsingle treatments and single outcomes. This hinders their use in complex\nreal-world scenarios; for example, consider studying the effect of different\nICU interventions, such as beta-blockers and statins for a patient admitted for\nheart surgery, on different outcomes of interest such as atrial fibrillation\nand in-hospital mortality. The limited research into composite treatments and\noutcomes is primarily due to data scarcity for all treatments and outcomes. To\naddress the above challenges, we propose a novel and innovative\nhypernetwork-based approach, called \\emph{H-Learner}, to solve ITE estimation\nunder composite treatments and composite outcomes, which tackles the data\nscarcity issue by dynamically sharing information across treatments and\noutcomes. Our empirical analysis with binary and arbitrary composite treatments\nand outcomes demonstrates the effectiveness of the proposed approach compared\nto existing methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "6 pages (double column), 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.08282v2",
    "published_date": "2025-02-12 10:41:21 UTC",
    "updated_date": "2025-05-12 09:02:06 UTC"
  },
  {
    "arxiv_id": "2502.08279v3",
    "title": "What Is That Talk About? A Video-to-Text Summarization Dataset for Scientific Presentations",
    "authors": [
      "Dongqi Liu",
      "Chenxi Whitehouse",
      "Xi Yu",
      "Louis Mahon",
      "Rohit Saxena",
      "Zheng Zhao",
      "Yifu Qiu",
      "Mirella Lapata",
      "Vera Demberg"
    ],
    "abstract": "Transforming recorded videos into concise and accurate textual summaries is a\ngrowing challenge in multimodal learning. This paper introduces VISTA, a\ndataset specifically designed for video-to-text summarization in scientific\ndomains. VISTA contains 18,599 recorded AI conference presentations paired with\ntheir corresponding paper abstracts. We benchmark the performance of\nstate-of-the-art large models and apply a plan-based framework to better\ncapture the structured nature of abstracts. Both human and automated\nevaluations confirm that explicit planning enhances summary quality and factual\nconsistency. However, a considerable gap remains between models and human\nperformance, highlighting the challenges of scientific video summarization.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.08279v3",
    "published_date": "2025-02-12 10:36:55 UTC",
    "updated_date": "2025-02-26 13:57:59 UTC"
  },
  {
    "arxiv_id": "2503.04767v2",
    "title": "A cross-regional review of AI safety regulations in the commercial aviation",
    "authors": [
      "Penny A. Barr",
      "Sohel M. Imroz"
    ],
    "abstract": "In this paper we examine the existing artificial intelligence (AI) policy\ndocuments in aviation for the following three regions: the United States,\nEuropean Union, and China. The aviation industry has always been a first mover\nin adopting technological advancements. This early adoption offers valuable\ninsights because of its stringent regulations and safety-critical procedures.\nAs a result, the aviation industry provides an optimal platform to counter AI\nvulnerabilities through its tight regulations, standardization processes, and\ncertification of new technologies. Keywords: AI in aviation; aviation safety;\nstandardization; certifiable AI; regulations",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "Identified errors in in-text citations and references sections",
    "pdf_url": "http://arxiv.org/pdf/2503.04767v2",
    "published_date": "2025-02-12 10:26:17 UTC",
    "updated_date": "2025-05-01 06:33:28 UTC"
  },
  {
    "arxiv_id": "2502.08266v1",
    "title": "Dealing with Annotator Disagreement in Hate Speech Classification",
    "authors": [
      "Somaiyeh Dehghan",
      "Mehmet Umut Sen",
      "Berrin Yanikoglu"
    ],
    "abstract": "Hate speech detection is a crucial task, especially on social media, where\nharmful content can spread quickly. Implementing machine learning models to\nautomatically identify and address hate speech is essential for mitigating its\nimpact and preventing its proliferation. The first step in developing an\neffective hate speech detection model is to acquire a high-quality dataset for\ntraining. Labeled data is foundational for most natural language processing\ntasks, but categorizing hate speech is difficult due to the diverse and often\nsubjective nature of hate speech, which can lead to varying interpretations and\ndisagreements among annotators. This paper examines strategies for addressing\nannotator disagreement, an issue that has been largely overlooked. In\nparticular, we evaluate different approaches to deal with annotator\ndisagreement regarding hate speech classification in Turkish tweets, based on a\nfine-tuned BERT model. Our work highlights the importance of the problem and\nprovides state-of-art benchmark results for detection and understanding of hate\nspeech in online discourse.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "I.2; I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.08266v1",
    "published_date": "2025-02-12 10:19:50 UTC",
    "updated_date": "2025-02-12 10:19:50 UTC"
  },
  {
    "arxiv_id": "2502.08265v1",
    "title": "Exploring the Potential of Large Language Models to Simulate Personality",
    "authors": [
      "Maria Molchanova",
      "Anna Mikhailova",
      "Anna Korzanova",
      "Lidiia Ostyakova",
      "Alexandra Dolidze"
    ],
    "abstract": "With the advancement of large language models (LLMs), the focus in\nConversational AI has shifted from merely generating coherent and relevant\nresponses to tackling more complex challenges, such as personalizing dialogue\nsystems. In an effort to enhance user engagement, chatbots are often designed\nto mimic human behaviour, responding within a defined emotional spectrum and\naligning to a set of values. In this paper, we aim to simulate personal traits\naccording to the Big Five model with the use of LLMs. Our research showed that\ngenerating personality-related texts is still a challenging task for the\nmodels. As a result, we present a dataset of generated texts with the\npredefined Big Five characteristics and provide an analytical framework for\ntesting LLMs on a simulation of personality skills.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Preprint submitted to Workshop on Customizable NLP (CustomNLP4U) on\n  EMNLP2024",
    "pdf_url": "http://arxiv.org/pdf/2502.08265v1",
    "published_date": "2025-02-12 10:17:18 UTC",
    "updated_date": "2025-02-12 10:17:18 UTC"
  },
  {
    "arxiv_id": "2502.08681v2",
    "title": "Centrally Coordinated Multi-Agent Reinforcement Learning for Power Grid Topology Control",
    "authors": [
      "Barbera de Mol",
      "Davide Barbieri",
      "Jan Viebahn",
      "Davide Grossi"
    ],
    "abstract": "Power grid operation is becoming more complex due to the increase in\ngeneration of renewable energy. The recent series of Learning To Run a Power\nNetwork (L2RPN) competitions have encouraged the use of artificial agents to\nassist human dispatchers in operating power grids. However, the combinatorial\nnature of the action space poses a challenge to both conventional optimizers\nand learned controllers. Action space factorization, which breaks down\ndecision-making into smaller sub-tasks, is one approach to tackle the curse of\ndimensionality. In this study, we propose a centrally coordinated multi-agent\n(CCMA) architecture for action space factorization. In this approach, regional\nagents propose actions and subsequently a coordinating agent selects the final\naction. We investigate several implementations of the CCMA architecture, and\nbenchmark in different experimental settings against various L2RPN baseline\napproaches. The CCMA architecture exhibits higher sample efficiency and\nsuperior final performance than the baseline approaches. The results suggest\nhigh potential of the CCMA approach for further application in\nhigher-dimensional L2RPN as well as real-world power grid settings.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.LG",
      "I.2.11; I.2.8; I.2.1; I.2.6"
    ],
    "primary_category": "cs.MA",
    "comment": "Accepted version to The 16th ACM International Conference on Future\n  and Sustainable Energy Systems. The final published version is available at\n  10.1145/3679240.3734602",
    "pdf_url": "http://arxiv.org/pdf/2502.08681v2",
    "published_date": "2025-02-12 10:16:06 UTC",
    "updated_date": "2025-05-14 20:06:33 UTC"
  },
  {
    "arxiv_id": "2502.08259v2",
    "title": "Balancing optimism and pessimism in offline-to-online learning",
    "authors": [
      "Flore Sentenac",
      "Ilbin Lee",
      "Csaba Szepesvari"
    ],
    "abstract": "We consider what we call the offline-to-online learning setting, focusing on\nstochastic finite-armed bandit problems. In offline-to-online learning, a\nlearner starts with offline data collected from interactions with an unknown\nenvironment in a way that is not under the learner's control. Given this data,\nthe learner begins interacting with the environment, gradually improving its\ninitial strategy as it collects more data to maximize its total reward. The\nlearner in this setting faces a fundamental dilemma: if the policy is deployed\nfor only a short period, a suitable strategy (in a number of senses) is the\nLower Confidence Bound (LCB) algorithm, which is based on pessimism. LCB can\neffectively compete with any policy that is sufficiently \"covered\" by the\noffline data. However, for longer time horizons, a preferred strategy is the\nUpper Confidence Bound (UCB) algorithm, which is based on optimism. Over time,\nUCB converges to the performance of the optimal policy at a rate that is nearly\nthe best possible among all online algorithms. In offline-to-online learning,\nhowever, UCB initially explores excessively, leading to worse short-term\nperformance compared to LCB. This suggests that a learner not in control of how\nlong its policy will be in use should start with LCB for short horizons and\ngradually transition to a UCB-like strategy as more rounds are played. This\narticle explores how and why this transition should occur. Our main result\nshows that our new algorithm performs nearly as well as the better of LCB and\nUCB at any point in time. The core idea behind our algorithm is broadly\napplicable, and we anticipate that our results will extend beyond the\nmulti-armed bandit setting.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.08259v2",
    "published_date": "2025-02-12 10:05:25 UTC",
    "updated_date": "2025-03-10 16:30:27 UTC"
  },
  {
    "arxiv_id": "2502.08680v1",
    "title": "Mathematical Reasoning in Large Language Models: Assessing Logical and Arithmetic Errors across Wide Numerical Ranges",
    "authors": [
      "Safal Shrestha",
      "Minwu Kim",
      "Keith Ross"
    ],
    "abstract": "Mathematical reasoning in Large Language Models (LLMs) is often evaluated\nusing benchmarks with limited numerical ranges, failing to reflect real-world\nproblem-solving across diverse scales. Furthermore, most existing evaluation\nmethods only compare model outputs to ground-truth answers, obscuring insights\ninto reasoning processes. To address these limitations, we introduce\nGSM-Ranges, a dataset generator derived from GSM8K that systematically perturbs\nnumerical values in math problems to assess model robustness across varying\nnumerical scales. Additionally, we propose a novel grading methodology that\ndistinguishes between logical and non-logical errors, offering a more precise\nevaluation of reasoning processes beyond computational accuracy. Our\nexperiments with various models reveal a significant increase in logical error\nrates-up to 14 percentage points-as numerical complexity rises, demonstrating a\ngeneral weakness in reasoning with out-of-distribution numerical values.\nMoreover, while models demonstrate high accuracy on standalone arithmetic\ntasks, their performance deteriorates substantially when computations are\nembedded within word problems. These findings provide a comprehensive\nevaluation of LLMs' mathematical reasoning capabilities and inform future\nresearch directions for improving numerical generalization in language models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.08680v1",
    "published_date": "2025-02-12 09:53:10 UTC",
    "updated_date": "2025-02-12 09:53:10 UTC"
  },
  {
    "arxiv_id": "2502.08235v1",
    "title": "The Danger of Overthinking: Examining the Reasoning-Action Dilemma in Agentic Tasks",
    "authors": [
      "Alejandro Cuadron",
      "Dacheng Li",
      "Wenjie Ma",
      "Xingyao Wang",
      "Yichuan Wang",
      "Siyuan Zhuang",
      "Shu Liu",
      "Luis Gaspar Schroeder",
      "Tian Xia",
      "Huanzhi Mao",
      "Nicholas Thumiger",
      "Aditya Desai",
      "Ion Stoica",
      "Ana Klimovic",
      "Graham Neubig",
      "Joseph E. Gonzalez"
    ],
    "abstract": "Large Reasoning Models (LRMs) represent a breakthrough in AI problem-solving\ncapabilities, but their effectiveness in interactive environments can be\nlimited. This paper introduces and analyzes overthinking in LRMs. A phenomenon\nwhere models favor extended internal reasoning chains over environmental\ninteraction. Through experiments on software engineering tasks using SWE Bench\nVerified, we observe three recurring patterns: Analysis Paralysis, Rogue\nActions, and Premature Disengagement. We propose a framework to study these\nbehaviors, which correlates with human expert assessments, and analyze 4018\ntrajectories. We observe that higher overthinking scores correlate with\ndecreased performance, with reasoning models exhibiting stronger tendencies\ntoward overthinking compared to non-reasoning models. Our analysis reveals that\nsimple efforts to mitigate overthinking in agentic environments, such as\nselecting the solution with the lower overthinking score, can improve model\nperformance by almost 30% while reducing computational costs by 43%. These\nresults suggest that mitigating overthinking has strong practical implications.\nWe suggest that by leveraging native function-calling capabilities and\nselective reinforcement learning overthinking tendencies could be mitigated. We\nalso open-source our evaluation framework and dataset to facilitate research in\nthis direction at https://github.com/AlexCuadron/Overthinking.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.08235v1",
    "published_date": "2025-02-12 09:23:26 UTC",
    "updated_date": "2025-02-12 09:23:26 UTC"
  },
  {
    "arxiv_id": "2503.16436v1",
    "title": "Enhancing Human-Robot Collaboration through Existing Guidelines: A Case Study Approach",
    "authors": [
      "Yutaka Matsubara",
      "Akihisa Morikawa",
      "Daichi Mizuguchi",
      "Kiyoshi Fujiwara"
    ],
    "abstract": "As AI systems become more prevalent, concerns about their development,\noperation, and societal impact intensify. Establishing ethical, social, and\nsafety standards amidst evolving AI capabilities poses significant challenges.\nGlobal initiatives are underway to establish guidelines for AI system\ndevelopment and operation. With the increasing use of collaborative human-AI\ntask execution, it's vital to continuously adapt AI systems to meet user and\nenvironmental needs. Failure to synchronize AI evolution with changes in users\nand the environment could result in ethical and safety issues. This paper\nevaluates the applicability of existing guidelines in human-robot collaborative\nsystems, assesses their effectiveness, and discusses limitations. Through a\ncase study, we examine whether our target system meets requirements outlined in\nexisting guidelines and propose improvements to enhance human-robot\ninteractions. Our contributions provide insights into interpreting and applying\nguidelines, offer concrete examples of system enhancement, and highlight their\napplicability and limitations. We believe these contributions will stimulate\ndiscussions and influence system assurance and certification in future\nAI-infused critical systems.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.16436v1",
    "published_date": "2025-02-12 09:17:53 UTC",
    "updated_date": "2025-02-12 09:17:53 UTC"
  },
  {
    "arxiv_id": "2502.08226v2",
    "title": "TRISHUL: Towards Region Identification and Screen Hierarchy Understanding for Large VLM based GUI Agents",
    "authors": [
      "Kunal Singh",
      "Shreyas Singh",
      "Mukund Khanna"
    ],
    "abstract": "Recent advancements in Large Vision Language Models (LVLMs) have enabled the\ndevelopment of LVLM-based Graphical User Interface (GUI) agents under various\nparadigms. Training-based approaches, such as CogAgent and SeeClick, struggle\nwith cross-dataset and cross-platform generalization due to their reliance on\ndataset-specific training. Generalist LVLMs, such as GPT-4V, employ\nSet-of-Marks (SoM) for action grounding, but obtaining SoM labels requires\nmetadata like HTML source, which is not consistently available across\nplatforms. Moreover, existing methods often specialize in singular GUI tasks\nrather than achieving comprehensive GUI understanding. To address these\nlimitations, we introduce TRISHUL, a novel, training-free agentic framework\nthat enhances generalist LVLMs for holistic GUI comprehension. Unlike prior\nworks that focus on either action grounding (mapping instructions to GUI\nelements) or GUI referring (describing GUI elements given a location), TRISHUL\nseamlessly integrates both. At its core, TRISHUL employs Hierarchical Screen\nParsing (HSP) and the Spatially Enhanced Element Description (SEED) module,\nwhich work synergistically to provide multi-granular, spatially, and\nsemantically enriched representations of GUI elements. Our results demonstrate\nTRISHUL's superior performance in action grounding across the ScreenSpot,\nVisualWebBench, AITW, and Mind2Web datasets. Additionally, for GUI referring,\nTRISHUL surpasses the ToL agent on the ScreenPR benchmark, setting a new\nstandard for robust and adaptable GUI comprehension.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "8 pages 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.08226v2",
    "published_date": "2025-02-12 09:12:30 UTC",
    "updated_date": "2025-02-14 06:23:57 UTC"
  },
  {
    "arxiv_id": "2502.08679v4",
    "title": "Deep Learning-Driven Malware Classification with API Call Sequence Analysis and Concept Drift Handling",
    "authors": [
      "Bishwajit Prasad Gond",
      "Durga Prasad Mohapatra"
    ],
    "abstract": "Malware classification in dynamic environments presents a significant\nchallenge due to concept drift, where the statistical properties of malware\ndata evolve over time, complicating detection efforts. To address this issue,\nwe propose a deep learning framework enhanced with a genetic algorithm to\nimprove malware classification accuracy and adaptability. Our approach\nincorporates mutation operations and fitness score evaluations within genetic\nalgorithms to continuously refine the deep learning model, ensuring robustness\nagainst evolving malware threats. Experimental results demonstrate that this\nhybrid method significantly enhances classification performance and\nadaptability, outperforming traditional static models. Our proposed approach\noffers a promising solution for real-time malware classification in\never-changing cybersecurity landscapes.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.08679v4",
    "published_date": "2025-02-12 08:56:35 UTC",
    "updated_date": "2025-03-08 15:10:45 UTC"
  },
  {
    "arxiv_id": "2502.08211v1",
    "title": "Quality over Quantity: Boosting Data Efficiency Through Ensembled Multimodal Data Curation",
    "authors": [
      "Jinda Xu",
      "Yuhao Song",
      "Daming Wang",
      "Weiwei Zhao",
      "Minghua Chen",
      "Kangliang Chen",
      "Qinya Li"
    ],
    "abstract": "In an era overwhelmed by vast amounts of data, the effective curation of\nweb-crawl datasets is essential for optimizing model performance. This paper\ntackles the challenges associated with the unstructured and heterogeneous\nnature of such datasets. Traditional heuristic curation methods often\ninadequately capture complex features, resulting in biases and the exclusion of\nrelevant data. We introduce an advanced, learning-driven approach, Ensemble\nCuration Of DAta ThroUgh Multimodal Operators (EcoDatum), incorporating a novel\nquality-guided deduplication method to ensure balanced feature distributions.\nEcoDatum strategically integrates various unimodal and multimodal data curation\noperators within a weak supervision ensemble framework, utilizing automated\noptimization to score each data point effectively. EcoDatum, which\nsignificantly improves the data curation quality and efficiency, outperforms\nexisting state-of-the-art (SOTA) techniques, ranked 1st on the DataComp\nleaderboard, with an average performance score of 0.182 across 38 diverse\nevaluation datasets. This represents a 28% improvement over the DataComp\nbaseline method, demonstrating its effectiveness in improving dataset curation\nand model training efficiency.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.08211v1",
    "published_date": "2025-02-12 08:40:57 UTC",
    "updated_date": "2025-02-12 08:40:57 UTC"
  },
  {
    "arxiv_id": "2502.08209v2",
    "title": "Equivariant Masked Position Prediction for Efficient Molecular Representation",
    "authors": [
      "Junyi An",
      "Chao Qu",
      "Yun-Fei Shi",
      "XinHao Liu",
      "Qianwei Tang",
      "Fenglei Cao",
      "Yuan Qi"
    ],
    "abstract": "Graph neural networks (GNNs) have shown considerable promise in computational\nchemistry. However, the limited availability of molecular data raises concerns\nregarding GNNs' ability to effectively capture the fundamental principles of\nphysics and chemistry, which constrains their generalization capabilities. To\naddress this challenge, we introduce a novel self-supervised approach termed\nEquivariant Masked Position Prediction (EMPP), grounded in intramolecular\npotential and force theory. Unlike conventional attribute masking techniques,\nEMPP formulates a nuanced position prediction task that is more well-defined\nand enhances the learning of quantum mechanical features. EMPP also bypasses\nthe approximation of the Gaussian mixture distribution commonly used in\ndenoising methods, allowing for more accurate acquisition of physical\nproperties. Experimental results indicate that EMPP significantly enhances\nperformance of advanced molecular architectures, surpassing state-of-the-art\nself-supervised approaches. Our code is released in\nhttps://github.com/ajy112/EMPP",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "24 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.08209v2",
    "published_date": "2025-02-12 08:39:26 UTC",
    "updated_date": "2025-03-11 07:27:41 UTC"
  },
  {
    "arxiv_id": "2502.10463v1",
    "title": "From Layers to States: A State Space Model Perspective to Deep Neural Network Layer Dynamics",
    "authors": [
      "Qinshuo Liu",
      "Weiqin Zhao",
      "Wei Huang",
      "Yanwen Fang",
      "Lequan Yu",
      "Guodong Li"
    ],
    "abstract": "The depth of neural networks is a critical factor for their capability, with\ndeeper models often demonstrating superior performance. Motivated by this,\nsignificant efforts have been made to enhance layer aggregation - reusing\ninformation from previous layers to better extract features at the current\nlayer, to improve the representational power of deep neural networks. However,\nprevious works have primarily addressed this problem from a discrete-state\nperspective which is not suitable as the number of network layers grows. This\npaper novelly treats the outputs from layers as states of a continuous process\nand considers leveraging the state space model (SSM) to design the aggregation\nof layers in very deep neural networks. Moreover, inspired by its advancements\nin modeling long sequences, the Selective State Space Models (S6) is employed\nto design a new module called Selective State Space Model Layer Aggregation\n(S6LA). This module aims to combine traditional CNN or transformer\narchitectures within a sequential framework, enhancing the representational\ncapabilities of state-of-the-art vision networks. Extensive experiments show\nthat S6LA delivers substantial improvements in both image classification and\ndetection tasks, highlighting the potential of integrating SSMs with\ncontemporary deep learning techniques.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.10463v1",
    "published_date": "2025-02-12 08:12:33 UTC",
    "updated_date": "2025-02-12 08:12:33 UTC"
  },
  {
    "arxiv_id": "2502.08181v1",
    "title": "Latest Advancements Towards Catastrophic Forgetting under Data Scarcity: A Comprehensive Survey on Few-Shot Class Incremental Learning",
    "authors": [
      "M. Anwar Ma'sum",
      "Mahardhika Pratama",
      "Igor Skrjanc"
    ],
    "abstract": "Data scarcity significantly complicates the continual learning problem, i.e.,\nhow a deep neural network learns in dynamic environments with very few samples.\nHowever, the latest progress of few-shot class incremental learning (FSCIL)\nmethods and related studies show insightful knowledge on how to tackle the\nproblem. This paper presents a comprehensive survey on FSCIL that highlights\nseveral important aspects i.e. comprehensive and formal objectives of FSCIL\napproaches, the importance of prototype rectifications, the new learning\nparadigms based on pre-trained model and language-guided mechanism, the deeper\nanalysis of FSCIL performance metrics and evaluation, and the practical\ncontexts of FSCIL in various areas. Our extensive discussion presents the open\nchallenges, potential solutions, and future directions of FSCIL.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.08181v1",
    "published_date": "2025-02-12 07:39:44 UTC",
    "updated_date": "2025-02-12 07:39:44 UTC"
  },
  {
    "arxiv_id": "2502.08180v2",
    "title": "Enhancing LLM Character-Level Manipulation via Divide and Conquer",
    "authors": [
      "Zhen Xiong",
      "Yujun Cai",
      "Bryan Hooi",
      "Nanyun Peng",
      "Zhecheng Li",
      "Yiwei Wang"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated strong generalization\ncapabilities across a wide range of natural language processing (NLP) tasks.\nHowever, they exhibit notable weaknesses in character-level string\nmanipulation, struggling with fundamental operations such as character\ndeletion, insertion, and substitution. These challenges stem primarily from\ntokenization constraints, despite the critical role of such operations in data\npreprocessing and code generation. Through systematic analysis, we derive two\nkey insights: (1) LLMs face significant difficulties in leveraging intrinsic\ntoken knowledge for character-level reasoning, and (2) atomized word structures\ncan substantially enhance LLMs' ability to process token-level structural\ninformation. Building on these insights, we propose Character-Level\nManipulation via Divide and Conquer, a novel approach designed to bridge the\ngap between token-level processing and character-level manipulation. Our method\ndecomposes complex operations into explicit character-level subtasks coupled\nwith controlled token reconstruction phases, leading to significant\nimprovements in accuracy. Without additional training, our method significantly\nimproves accuracies on the $\\texttt{Deletion}$, $\\texttt{Insertion}$, and\n$\\texttt{Substitution}$ tasks. To support further research, we open-source our\nimplementation and benchmarks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.08180v2",
    "published_date": "2025-02-12 07:37:39 UTC",
    "updated_date": "2025-03-27 16:07:18 UTC"
  },
  {
    "arxiv_id": "2502.08177v2",
    "title": "SycEval: Evaluating LLM Sycophancy",
    "authors": [
      "Aaron Fanous",
      "Jacob Goldberg",
      "Ank A. Agarwal",
      "Joanna Lin",
      "Anson Zhou",
      "Roxana Daneshjou",
      "Sanmi Koyejo"
    ],
    "abstract": "Large language models (LLMs) are increasingly applied in educational,\nclinical, and professional settings, but their tendency for sycophancy --\nprioritizing user agreement over independent reasoning -- poses risks to\nreliability. This study introduces a framework to evaluate sycophantic behavior\nin ChatGPT-4o, Claude-Sonnet, and Gemini-1.5-Pro across AMPS (mathematics) and\nMedQuad (medical advice) datasets. Sycophantic behavior was observed in 58.19%\nof cases, with Gemini exhibiting the highest rate (62.47%) and ChatGPT the\nlowest (56.71%). Progressive sycophancy, leading to correct answers, occurred\nin 43.52% of cases, while regressive sycophancy, leading to incorrect answers,\nwas observed in 14.66%. Preemptive rebuttals demonstrated significantly higher\nsycophancy rates than in-context rebuttals (61.75% vs. 56.52%, $Z=5.87$,\n$p<0.001$), particularly in computational tasks, where regressive sycophancy\nincreased significantly (preemptive: 8.13%, in-context: 3.54%, $p<0.001$).\nSimple rebuttals maximized progressive sycophancy ($Z=6.59$, $p<0.001$), while\ncitation-based rebuttals exhibited the highest regressive rates ($Z=6.59$,\n$p<0.001$). Sycophantic behavior showed high persistence (78.5%, 95% CI:\n[77.2%, 79.8%]) regardless of context or model. These findings emphasize the\nrisks and opportunities of deploying LLMs in structured and dynamic domains,\noffering insights into prompt programming and model optimization for safer AI\napplications.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "10 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.08177v2",
    "published_date": "2025-02-12 07:32:42 UTC",
    "updated_date": "2025-03-06 00:41:10 UTC"
  },
  {
    "arxiv_id": "2502.10459v1",
    "title": "LLM4GNAS: A Large Language Model Based Toolkit for Graph Neural Architecture Search",
    "authors": [
      "Yang Gao",
      "Hong Yang",
      "Yizhi Chen",
      "Junxian Wu",
      "Peng Zhang",
      "Haishuai Wang"
    ],
    "abstract": "Graph Neural Architecture Search (GNAS) facilitates the automatic design of\nGraph Neural Networks (GNNs) tailored to specific downstream graph learning\ntasks. However, existing GNAS approaches often require manual adaptation to new\ngraph search spaces, necessitating substantial code optimization and\ndomain-specific knowledge. To address this challenge, we present LLM4GNAS, a\ntoolkit for GNAS that leverages the generative capabilities of Large Language\nModels (LLMs). LLM4GNAS includes an algorithm library for graph neural\narchitecture search algorithms based on LLMs, enabling the adaptation of GNAS\nmethods to new search spaces through the modification of LLM prompts. This\napproach reduces the need for manual intervention in algorithm adaptation and\ncode modification. The LLM4GNAS toolkit is extensible and robust, incorporating\nLLM-enhanced graph feature engineering, LLM-enhanced graph neural architecture\nsearch, and LLM-enhanced hyperparameter optimization. Experimental results\nindicate that LLM4GNAS outperforms existing GNAS methods on tasks involving\nboth homogeneous and heterogeneous graphs.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.10459v1",
    "published_date": "2025-02-12 07:26:07 UTC",
    "updated_date": "2025-02-12 07:26:07 UTC"
  },
  {
    "arxiv_id": "2502.08161v1",
    "title": "MixDec Sampling: A Soft Link-based Sampling Method of Graph Neural Network for Recommendation",
    "authors": [
      "Xiangjin Xie",
      "Yuxin Chen",
      "Ruipeng Wang",
      "Kai Ouyang",
      "Zihan Zhang",
      "Hai-Tao Zheng",
      "Buyue Qian",
      "Hansen Zheng",
      "Bo Hu",
      "Chengxiang Zhuo",
      "Zang Li"
    ],
    "abstract": "Graph neural networks have been widely used in recent recommender systems,\nwhere negative sampling plays an important role. Existing negative sampling\nmethods restrict the relationship between nodes as either hard positive pairs\nor hard negative pairs. This leads to the loss of structural information, and\nlacks the mechanism to generate positive pairs for nodes with few neighbors. To\novercome limitations, we propose a novel soft link-based sampling method,\nnamely MixDec Sampling, which consists of Mixup Sampling module and Decay\nSampling module. The Mixup Sampling augments node features by synthesizing new\nnodes and soft links, which provides sufficient number of samples for nodes\nwith few neighbors. The Decay Sampling strengthens the digestion of graph\nstructure information by generating soft links for node embedding learning. To\nthe best of our knowledge, we are the first to model sampling relationships\nbetween nodes by soft links in GNN-based recommender systems. Extensive\nexperiments demonstrate that the proposed MixDec Sampling can significantly and\nconsistently improve the recommendation performance of several representative\nGNN-based models on various recommendation benchmarks.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "10 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.08161v1",
    "published_date": "2025-02-12 07:05:59 UTC",
    "updated_date": "2025-02-12 07:05:59 UTC"
  },
  {
    "arxiv_id": "2502.08160v1",
    "title": "Vertical Federated Learning in Practice: The Good, the Bad, and the Ugly",
    "authors": [
      "Zhaomin Wu",
      "Zhen Qin",
      "Junyi Hou",
      "Haodong Zhao",
      "Qinbin Li",
      "Bingsheng He",
      "Lixin Fan"
    ],
    "abstract": "Vertical Federated Learning (VFL) is a privacy-preserving collaborative\nlearning paradigm that enables multiple parties with distinct feature sets to\njointly train machine learning models without sharing their raw data. Despite\nits potential to facilitate cross-organizational collaborations, the deployment\nof VFL systems in real-world applications remains limited. To investigate the\ngap between existing VFL research and practical deployment, this survey\nanalyzes the real-world data distributions in potential VFL applications and\nidentifies four key findings that highlight this gap. We propose a novel\ndata-oriented taxonomy of VFL algorithms based on real VFL data distributions.\nOur comprehensive review of existing VFL algorithms reveals that some common\npractical VFL scenarios have few or no viable solutions. Based on these\nobservations, we outline key research directions aimed at bridging the gap\nbetween current VFL research and real-world applications.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.08160v1",
    "published_date": "2025-02-12 07:03:32 UTC",
    "updated_date": "2025-02-12 07:03:32 UTC"
  },
  {
    "arxiv_id": "2502.08155v1",
    "title": "DGSense: A Domain Generalization Framework for Wireless Sensing",
    "authors": [
      "Rui Zhou",
      "Yu Cheng",
      "Songlin Li",
      "Hongwang Zhang",
      "Chenxu Liu"
    ],
    "abstract": "Wireless sensing is of great benefits to our daily lives. However, wireless\nsignals are sensitive to the surroundings. Various factors, e.g. environments,\nlocations, and individuals, may induce extra impact on wireless propagation.\nSuch a change can be regarded as a domain, in which the data distribution\nshifts. A vast majority of the sensing schemes are learning-based. They are\ndependent on the training domains, resulting in performance degradation in\nunseen domains. Researchers have proposed various solutions to address this\nissue. But these solutions leverage either semi-supervised or unsupervised\ndomain adaptation techniques. They still require some data in the target\ndomains and do not perform well in unseen domains. In this paper, we propose a\ndomain generalization framework DGSense, to eliminate the domain dependence\nproblem in wireless sensing. The framework is a general solution working across\ndiverse sensing tasks and wireless technologies. Once the sensing model is\nbuilt, it can generalize to unseen domains without any data from the target\ndomain. To achieve the goal, we first increase the diversity of the training\nset by a virtual data generator, and then extract the domain independent\nfeatures via episodic training between the main feature extractor and the\ndomain feature extractors. The feature extractors employ a pre-trained Residual\nNetwork (ResNet) with an attention mechanism for spatial features, and a 1D\nConvolutional Neural Network (1DCNN) for temporal features. To demonstrate the\neffectiveness and generality of DGSense, we evaluated on WiFi gesture\nrecognition, Millimeter Wave (mmWave) activity recognition, and acoustic fall\ndetection. All the systems exhibited high generalization capability to unseen\ndomains, including new users, locations, and environments, free of new data and\nretraining.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "15 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.08155v1",
    "published_date": "2025-02-12 06:47:25 UTC",
    "updated_date": "2025-02-12 06:47:25 UTC"
  },
  {
    "arxiv_id": "2502.09659v1",
    "title": "Cancer Vaccine Adjuvant Name Recognition from Biomedical Literature using Large Language Models",
    "authors": [
      "Hasin Rehana",
      "Jie Zheng",
      "Leo Yeh",
      "Benu Bansal",
      "Nur Bengisu Ãam",
      "Christianah Jemiyo",
      "Brett McGregor",
      "Arzucan ÃzgÃ¼r",
      "Yongqun He",
      "Junguk Hur"
    ],
    "abstract": "Motivation: An adjuvant is a chemical incorporated into vaccines that\nenhances their efficacy by improving the immune response. Identifying adjuvant\nnames from cancer vaccine studies is essential for furthering research and\nenhancing immunotherapies. However, the manual curation from the constantly\nexpanding biomedical literature poses significant challenges. This study\nexplores the automated recognition of vaccine adjuvant names using Large\nLanguage Models (LLMs), specifically Generative Pretrained Transformers (GPT)\nand Large Language Model Meta AI (Llama). Methods: We utilized two datasets: 97\nclinical trial records from AdjuvareDB and 290 abstracts annotated with the\nVaccine Adjuvant Compendium (VAC). GPT-4o and Llama 3.2 were employed in\nzero-shot and few-shot learning paradigms with up to four examples per prompt.\nPrompts explicitly targeted adjuvant names, testing the impact of contextual\ninformation such as substances or interventions. Outputs underwent automated\nand manual validation for accuracy and consistency. Results: GPT-4o attained\n100% Precision across all situations while exhibiting notable improve in Recall\nand F1-scores, particularly with incorporating interventions. On the VAC\ndataset, GPT-4o achieved a maximum F1-score of 77.32% with interventions,\nsurpassing Llama-3.2-3B by approximately 2%. On the AdjuvareDB dataset, GPT-4o\nreached an F1-score of 81.67% for three-shot prompting with interventions,\nsurpassing Llama-3.2-3 B's maximum F1-score of 65.62%. Conclusion: Our findings\ndemonstrate that LLMs excel at identifying adjuvant names, including rare\nvariations of naming representation. This study emphasizes the capability of\nLLMs to enhance cancer vaccine development by efficiently extracting insights.\nFuture work aims to broaden the framework to encompass various biomedical\nliterature and enhance model generalizability across various vaccines and\nadjuvants.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL",
    "comment": "10 pages, 6 figures, 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2502.09659v1",
    "published_date": "2025-02-12 06:30:31 UTC",
    "updated_date": "2025-02-12 06:30:31 UTC"
  },
  {
    "arxiv_id": "2502.08150v1",
    "title": "Force Matching with Relativistic Constraints: A Physics-Inspired Approach to Stable and Efficient Generative Modeling",
    "authors": [
      "Yang Cao",
      "Bo Chen",
      "Xiaoyu Li",
      "Yingyu Liang",
      "Zhizhou Sha",
      "Zhenmei Shi",
      "Zhao Song",
      "Mingda Wan"
    ],
    "abstract": "This paper introduces Force Matching (ForM), a novel framework for generative\nmodeling that represents an initial exploration into leveraging special\nrelativistic mechanics to enhance the stability of the sampling process. By\nincorporating the Lorentz factor, ForM imposes a velocity constraint, ensuring\nthat sample velocities remain bounded within a constant limit. This constraint\nserves as a fundamental mechanism for stabilizing the generative dynamics,\nleading to a more robust and controlled sampling process. We provide a rigorous\ntheoretical analysis demonstrating that the velocity constraint is preserved\nthroughout the sampling procedure within the ForM framework. To validate the\neffectiveness of our approach, we conduct extensive empirical evaluations. On\nthe \\textit{half-moons} dataset, ForM significantly outperforms baseline\nmethods, achieving the lowest Euclidean distance loss of \\textbf{0.714}, in\ncontrast to vanilla first-order flow matching (5.853) and first- and\nsecond-order flow matching (5.793). Additionally, we perform an ablation study\nto further investigate the impact of our velocity constraint, reaffirming the\nsuperiority of ForM in stabilizing the generative process. The theoretical\nguarantees and empirical results underscore the potential of integrating\nspecial relativity principles into generative modeling. Our findings suggest\nthat ForM provides a promising pathway toward achieving stable, efficient, and\nflexible generative processes. This work lays the foundation for future\nadvancements in high-dimensional generative modeling, opening new avenues for\nthe application of physical principles in machine learning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.08150v1",
    "published_date": "2025-02-12 06:30:01 UTC",
    "updated_date": "2025-02-12 06:30:01 UTC"
  },
  {
    "arxiv_id": "2502.08149v2",
    "title": "Generalized Class Discovery in Instance Segmentation",
    "authors": [
      "Cuong Manh Hoang",
      "Yeejin Lee",
      "Byeongkeun Kang"
    ],
    "abstract": "This work addresses the task of generalized class discovery (GCD) in instance\nsegmentation. The goal is to discover novel classes and obtain a model capable\nof segmenting instances of both known and novel categories, given labeled and\nunlabeled data. Since the real world contains numerous objects with long-tailed\ndistributions, the instance distribution for each class is inherently\nimbalanced. To address the imbalanced distributions, we propose an\ninstance-wise temperature assignment (ITA) method for contrastive learning and\nclass-wise reliability criteria for pseudo-labels. The ITA method relaxes\ninstance discrimination for samples belonging to head classes to enhance GCD.\nThe reliability criteria are to avoid excluding most pseudo-labels for tail\nclasses when training an instance segmentation network using pseudo-labels from\nGCD. Additionally, we propose dynamically adjusting the criteria to leverage\ndiverse samples in the early stages while relying only on reliable\npseudo-labels in the later stages. We also introduce an efficient soft\nattention module to encode object-specific representations for GCD. Finally, we\nevaluate our proposed method by conducting experiments on two settings:\nCOCO$_{half}$ + LVIS and LVIS + Visual Genome. The experimental results\ndemonstrate that the proposed method outperforms previous state-of-the-art\nmethods.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.08149v2",
    "published_date": "2025-02-12 06:26:05 UTC",
    "updated_date": "2025-05-08 23:16:04 UTC"
  },
  {
    "arxiv_id": "2502.08148v1",
    "title": "ACCESS : A Benchmark for Abstract Causal Event Discovery and Reasoning",
    "authors": [
      "Vy Vo",
      "Lizhen Qu",
      "Tao Feng",
      "Yuncheng Hua",
      "Xiaoxi Kang",
      "Songhai Fan",
      "Tim Dwyer",
      "Lay-Ki Soon",
      "Gholamreza Haffari"
    ],
    "abstract": "Identifying cause-and-effect relationships is critical to understanding\nreal-world dynamics and ultimately causal reasoning. Existing methods for\nidentifying event causality in NLP, including those based on Large Language\nModels (LLMs), exhibit difficulties in out-of-distribution settings due to the\nlimited scale and heavy reliance on lexical cues within available benchmarks.\nModern benchmarks, inspired by probabilistic causal inference, have attempted\nto construct causal graphs of events as a robust representation of causal\nknowledge, where \\texttt{CRAB} \\citep{romanou2023crab} is one such recent\nbenchmark along this line. In this paper, we introduce \\texttt{ACCESS}, a\nbenchmark designed for discovery and reasoning over abstract causal events.\nUnlike existing resources, \\texttt{ACCESS} focuses on causality of everyday\nlife events on the abstraction level. We propose a pipeline for identifying\nabstractions for event generalizations from \\texttt{GLUCOSE}\n\\citep{mostafazadeh-etal-2020-glucose}, a large-scale dataset of implicit\ncommonsense causal knowledge, from which we subsequently extract $1,4$K causal\npairs. Our experiments highlight the ongoing challenges of using statistical\nmethods and/or LLMs for automatic abstraction identification and causal\ndiscovery in NLP. Nonetheless, we demonstrate that the abstract causal\nknowledge provided in \\texttt{ACCESS} can be leveraged for enhancing QA\nreasoning performance in LLMs.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.08148v1",
    "published_date": "2025-02-12 06:19:02 UTC",
    "updated_date": "2025-02-12 06:19:02 UTC"
  },
  {
    "arxiv_id": "2502.09658v1",
    "title": "Neuro-Conceptual Artificial Intelligence: Integrating OPM with Deep Learning to Enhance Question Answering Quality",
    "authors": [
      "Xin Kang",
      "Veronika Shteingardt",
      "Yuhan Wang",
      "Dov Dori"
    ],
    "abstract": "Knowledge representation and reasoning are critical challenges in Artificial\nIntelligence (AI), particularly in integrating neural and symbolic approaches\nto achieve explainable and transparent AI systems. Traditional knowledge\nrepresentation methods often fall short of capturing complex processes and\nstate changes. We introduce Neuro-Conceptual Artificial Intelligence (NCAI), a\nspecialization of the neuro-symbolic AI approach that integrates conceptual\nmodeling using Object-Process Methodology (OPM) ISO 19450:2024 with deep\nlearning to enhance question-answering (QA) quality. By converting natural\nlanguage text into OPM models using in-context learning, NCAI leverages the\nexpressive power of OPM to represent complex OPM elements-processes, objects,\nand states-beyond what traditional triplet-based knowledge graphs can easily\ncapture. This rich structured knowledge representation improves reasoning\ntransparency and answer accuracy in an OPM-QA system. We further propose\ntransparency evaluation metrics to quantitatively measure how faithfully the\npredicted reasoning aligns with OPM-based conceptual logic. Our experiments\ndemonstrate that NCAI outperforms traditional methods, highlighting its\npotential for advancing neuro-symbolic AI by providing rich knowledge\nrepresentations, measurable transparency, and improved reasoning.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "15 pages, 3 figures,",
    "pdf_url": "http://arxiv.org/pdf/2502.09658v1",
    "published_date": "2025-02-12 06:10:09 UTC",
    "updated_date": "2025-02-12 06:10:09 UTC"
  },
  {
    "arxiv_id": "2502.08145v1",
    "title": "Democratizing AI: Open-source Scalable LLM Training on GPU-based Supercomputers",
    "authors": [
      "Siddharth Singh",
      "Prajwal Singhania",
      "Aditya Ranjan",
      "John Kirchenbauer",
      "Jonas Geiping",
      "Yuxin Wen",
      "Neel Jain",
      "Abhimanyu Hans",
      "Manli Shu",
      "Aditya Tomar",
      "Tom Goldstein",
      "Abhinav Bhatele"
    ],
    "abstract": "Training and fine-tuning large language models (LLMs) with hundreds of\nbillions to trillions of parameters requires tens of thousands of GPUs, and a\nhighly scalable software stack. In this work, we present a novel\nfour-dimensional hybrid parallel algorithm implemented in a highly scalable,\nportable, open-source framework called AxoNN. We describe several performance\noptimizations in AxoNN to improve matrix multiply kernel performance, overlap\nnon-blocking collectives with computation, and performance modeling to choose\nperformance optimal configurations. These have resulted in unprecedented\nscaling and peak flop/s (bf16) for training of GPT-style transformer models on\nPerlmutter (620.1 Petaflop/s), Frontier (1.381 Exaflop/s) and Alps (1.423\nExaflop/s).\n  While the abilities of LLMs improve with the number of trainable parameters,\nso do privacy and copyright risks caused by memorization of training data,\nwhich can cause disclosure of sensitive or private information at inference\ntime. We highlight this side effect of scale through experiments that explore\n\"catastrophic memorization\", where models are sufficiently large to memorize\ntraining data in a single pass, and present an approach to prevent it. As part\nof this study, we demonstrate fine-tuning of a 405-billion parameter LLM using\nAxoNN on Frontier.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.08145v1",
    "published_date": "2025-02-12 06:05:52 UTC",
    "updated_date": "2025-02-12 06:05:52 UTC"
  },
  {
    "arxiv_id": "2502.08142v1",
    "title": "Bridging the Safety Gap: A Guardrail Pipeline for Trustworthy LLM Inferences",
    "authors": [
      "Shanshan Han",
      "Salman Avestimehr",
      "Chaoyang He"
    ],
    "abstract": "We present Wildflare GuardRail, a guardrail pipeline designed to enhance the\nsafety and reliability of Large Language Model (LLM) inferences by\nsystematically addressing risks across the entire processing workflow.\nWildflare GuardRail integrates several core functional modules, including\nSafety Detector that identifies unsafe inputs and detects hallucinations in\nmodel outputs while generating root-cause explanations, Grounding that\ncontextualizes user queries with information retrieved from vector databases,\nCustomizer that adjusts outputs in real time using lightweight, rule-based\nwrappers, and Repairer that corrects erroneous LLM outputs using hallucination\nexplanations provided by Safety Detector. Results show that our unsafe content\ndetection model in Safety Detector achieves comparable performance with OpenAI\nAPI, though trained on a small dataset constructed with several public\ndatasets. Meanwhile, the lightweight wrappers can address malicious URLs in\nmodel outputs in 1.06s per query with 100% accuracy without costly model calls.\nMoreover, the hallucination fixing model demonstrates effectiveness in reducing\nhallucinations with an accuracy of 80.7%.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "arXiv admin note: text overlap with arXiv:2406.10847",
    "pdf_url": "http://arxiv.org/pdf/2502.08142v1",
    "published_date": "2025-02-12 05:48:57 UTC",
    "updated_date": "2025-02-12 05:48:57 UTC"
  },
  {
    "arxiv_id": "2502.10458v1",
    "title": "I Think, Therefore I Diffuse: Enabling Multimodal In-Context Reasoning in Diffusion Models",
    "authors": [
      "Zhenxing Mi",
      "Kuan-Chieh Wang",
      "Guocheng Qian",
      "Hanrong Ye",
      "Runtao Liu",
      "Sergey Tulyakov",
      "Kfir Aberman",
      "Dan Xu"
    ],
    "abstract": "This paper presents ThinkDiff, a novel alignment paradigm that empowers\ntext-to-image diffusion models with multimodal in-context understanding and\nreasoning capabilities by integrating the strengths of vision-language models\n(VLMs). Existing multimodal diffusion finetuning methods largely focus on\npixel-level reconstruction rather than in-context reasoning, and are\nconstrained by the complexity and limited availability of reasoning-based\ndatasets. ThinkDiff addresses these challenges by leveraging vision-language\ntraining as a proxy task, aligning VLMs with the decoder of an encoder-decoder\nlarge language model (LLM) instead of a diffusion decoder. This proxy task\nbuilds on the observation that the $\\textbf{LLM decoder}$ shares the same input\nfeature space with $\\textbf{diffusion decoders}$ that use the corresponding\n$\\textbf{LLM encoder}$ for prompt embedding. As a result, aligning VLMs with\ndiffusion decoders can be simplified through alignment with the LLM decoder.\nWithout complex training and datasets, ThinkDiff effectively unleashes\nunderstanding, reasoning, and composing capabilities in diffusion models.\nExperiments demonstrate that ThinkDiff significantly improves accuracy from\n19.2% to 46.3% on the challenging CoBSAT benchmark for multimodal in-context\nreasoning generation, with only 5 hours of training on 4 A100 GPUs.\nAdditionally, ThinkDiff demonstrates exceptional performance in composing\nmultiple images and texts into logically coherent images. Project page:\nhttps://mizhenxing.github.io/ThinkDiff.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Project page: https://mizhenxing.github.io/ThinkDiff, 19 pages, 14\n  figures",
    "pdf_url": "http://arxiv.org/pdf/2502.10458v1",
    "published_date": "2025-02-12 05:30:08 UTC",
    "updated_date": "2025-02-12 05:30:08 UTC"
  },
  {
    "arxiv_id": "2502.08122v1",
    "title": "Hookpad Aria: A Copilot for Songwriters",
    "authors": [
      "Chris Donahue",
      "Shih-Lun Wu",
      "Yewon Kim",
      "Dave Carlton",
      "Ryan Miyakawa",
      "John Thickstun"
    ],
    "abstract": "We present Hookpad Aria, a generative AI system designed to assist musicians\nin writing Western pop songs. Our system is seamlessly integrated into Hookpad,\na web-based editor designed for the composition of lead sheets: symbolic music\nscores that describe melody and harmony. Hookpad Aria has numerous generation\ncapabilities designed to assist users in non-sequential composition workflows,\nincluding: (1) generating left-to-right continuations of existing material, (2)\nfilling in missing spans in the middle of existing material, and (3) generating\nharmony from melody and vice versa. Hookpad Aria is also a scalable data\nflywheel for music co-creation -- since its release in March 2024, Aria has\ngenerated 318k suggestions for 3k users who have accepted 74k into their songs.\n  More information about Hookpad Aria is available at\nhttps://www.hooktheory.com/hookpad/aria",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.SD",
    "comment": "Extended abstract presented in the Late-Breaking Demo Session at\n  ISMIR 2024 (ISMIR LBD 2024)",
    "pdf_url": "http://arxiv.org/pdf/2502.08122v1",
    "published_date": "2025-02-12 05:03:49 UTC",
    "updated_date": "2025-02-12 05:03:49 UTC"
  },
  {
    "arxiv_id": "2502.09655v2",
    "title": "Bidirectional Diffusion Bridge Models",
    "authors": [
      "Duc Kieu",
      "Kien Do",
      "Toan Nguyen",
      "Dang Nguyen",
      "Thin Nguyen"
    ],
    "abstract": "Diffusion bridges have shown potential in paired image-to-image (I2I)\ntranslation tasks. However, existing methods are limited by their\nunidirectional nature, requiring separate models for forward and reverse\ntranslations. This not only doubles the computational cost but also restricts\ntheir practicality. In this work, we introduce the Bidirectional Diffusion\nBridge Model (BDBM), a scalable approach that facilitates bidirectional\ntranslation between two coupled distributions using a single network. BDBM\nleverages the Chapman-Kolmogorov Equation for bridges, enabling it to model\ndata distribution shifts across timesteps in both forward and backward\ndirections by exploiting the interchangeability of the initial and target\ntimesteps within this framework. Notably, when the marginal distribution given\nendpoints is Gaussian, BDBM's transition kernels in both directions possess\nanalytical forms, allowing for efficient learning with a single network. We\ndemonstrate the connection between BDBM and existing bridge methods, such as\nDoob's h-transform and variational approaches, and highlight its advantages.\nExtensive experiments on high-resolution I2I translation tasks demonstrate that\nBDBM not only enables bidirectional translation with minimal additional cost\nbut also outperforms state-of-the-art bridge models. Our source code is\navailable at [https://github.com/kvmduc/BDBM||https://github.com/kvmduc/BDBM].",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Source code: https://github.com/kvmduc/BDBM",
    "pdf_url": "http://arxiv.org/pdf/2502.09655v2",
    "published_date": "2025-02-12 04:43:02 UTC",
    "updated_date": "2025-02-27 12:54:14 UTC"
  },
  {
    "arxiv_id": "2502.08119v1",
    "title": "Generative AI-Enhanced Cooperative MEC of UAVs and Ground Stations for Unmanned Surface Vehicles",
    "authors": [
      "Jiahao You",
      "Ziye Jia",
      "Chao Dong",
      "Qihui Wu",
      "Zhu Han"
    ],
    "abstract": "The increasing deployment of unmanned surface vehicles (USVs) require\ncomputational support and coverage in applications such as maritime search and\nrescue. Unmanned aerial vehicles (UAVs) can offer low-cost, flexible aerial\nservices, and ground stations (GSs) can provide powerful supports, which can\ncooperate to help the USVs in complex scenarios. However, the collaboration\nbetween UAVs and GSs for USVs faces challenges of task uncertainties, USVs\ntrajectory uncertainties, heterogeneities, and limited computational resources.\nTo address these issues, we propose a cooperative UAV and GS based robust\nmulti-access edge computing framework to assist USVs in completing\ncomputational tasks. Specifically, we formulate the optimization problem of\njoint task offloading and UAV trajectory to minimize the total execution time,\nwhich is in the form of mixed integer nonlinear programming and NP-hard to\ntackle. Therefore, we propose the algorithm of generative artificial\nintelligence-enhanced heterogeneous agent proximal policy optimization\n(GAI-HAPPO). The proposed algorithm integrates GAI models to enhance the actor\nnetwork ability to model complex environments and extract high-level features,\nthereby allowing the algorithm to predict uncertainties and adapt to dynamic\nconditions. Additionally, GAI stabilizes the critic network, addressing the\ninstability of multi-agent reinforcement learning approaches. Finally,\nextensive simulations demonstrate that the proposed algorithm outperforms the\nexisting benchmark methods, thus highlighting the potentials in tackling\nintricate, cross-domain issues in the considered scenarios.",
    "categories": [
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.08119v1",
    "published_date": "2025-02-12 04:42:59 UTC",
    "updated_date": "2025-02-12 04:42:59 UTC"
  },
  {
    "arxiv_id": "2502.08109v1",
    "title": "HuDEx: Integrating Hallucination Detection and Explainability for Enhancing the Reliability of LLM responses",
    "authors": [
      "Sujeong Lee",
      "Hayoung Lee",
      "Seongsoo Heo",
      "Wonik Choi"
    ],
    "abstract": "Recent advances in large language models (LLMs) have shown promising\nimprovements, often surpassing existing methods across a wide range of\ndownstream tasks in natural language processing. However, these models still\nface challenges, which may hinder their practical applicability. For example,\nthe phenomenon of hallucination is known to compromise the reliability of LLMs,\nespecially in fields that demand high factual precision. Current benchmarks\nprimarily focus on hallucination detection and factuality evaluation but do not\nextend beyond identification. This paper proposes an explanation enhanced\nhallucination-detection model, coined as HuDEx, aimed at enhancing the\nreliability of LLM-generated responses by both detecting hallucinations and\nproviding detailed explanations. The proposed model provides a novel approach\nto integrate detection with explanations, and enable both users and the LLM\nitself to understand and reduce errors. Our measurement results demonstrate\nthat the proposed model surpasses larger LLMs, such as Llama3 70B and GPT-4, in\nhallucination detection accuracy, while maintaining reliable explanations.\nFurthermore, the proposed model performs well in both zero-shot and other test\nenvironments, showcasing its adaptability across diverse benchmark datasets.\nThe proposed approach further enhances the hallucination detection research by\nintroducing a novel approach to integrating interpretability with hallucination\ndetection, which further enhances the performance and reliability of evaluating\nhallucinations in language models.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "11 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.08109v1",
    "published_date": "2025-02-12 04:17:02 UTC",
    "updated_date": "2025-02-12 04:17:02 UTC"
  },
  {
    "arxiv_id": "2502.08108v1",
    "title": "Generative AI and Empirical Software Engineering: A Paradigm Shift",
    "authors": [
      "Christoph Treude",
      "Margaret-Anne Storey"
    ],
    "abstract": "The widespread adoption of generative AI in software engineering marks a\nparadigm shift, offering new opportunities to design and utilize software\nengineering tools while influencing both developers and the artifacts they\ncreate. Traditional empirical methods in software engineering, including\nquantitative, qualitative, and mixed-method approaches, are well established.\nHowever, this paradigm shift introduces novel data types and redefines many\nconcepts in the software engineering process. The roles of developers, users,\nagents, and researchers increasingly overlap, blurring the distinctions between\nthese social and technical actors within the field.\n  This paper examines how integrating AI into software engineering challenges\ntraditional research paradigms. It focuses on the research phenomena that we\ninvestigate, the methods and theories that we employ, the data we analyze, and\nthe threats to validity that emerge in this new context. Through this\nexploration, our goal is to understand how AI adoption disrupts established\nsoftware development practices that creates new opportunities for empirical\nsoftware engineering research.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.08108v1",
    "published_date": "2025-02-12 04:13:07 UTC",
    "updated_date": "2025-02-12 04:13:07 UTC"
  },
  {
    "arxiv_id": "2502.08106v2",
    "title": "PoGDiff: Product-of-Gaussians Diffusion Models for Imbalanced Text-to-Image Generation",
    "authors": [
      "Ziyan Wang",
      "Sizhe Wei",
      "Xiaoming Huo",
      "Hao Wang"
    ],
    "abstract": "Diffusion models have made significant advancements in recent years. However,\ntheir performance often deteriorates when trained or fine-tuned on imbalanced\ndatasets. This degradation is largely due to the disproportionate\nrepresentation of majority and minority data in image-text pairs. In this\npaper, we propose a general fine-tuning approach, dubbed PoGDiff, to address\nthis challenge. Rather than directly minimizing the KL divergence between the\npredicted and ground-truth distributions, PoGDiff replaces the ground-truth\ndistribution with a Product of Gaussians (PoG), which is constructed by\ncombining the original ground-truth targets with the predicted distribution\nconditioned on a neighboring text embedding. Experiments on real-world datasets\ndemonstrate that our method effectively addresses the imbalance problem in\ndiffusion models, improving both generation accuracy and quality.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.08106v2",
    "published_date": "2025-02-12 04:07:14 UTC",
    "updated_date": "2025-02-19 16:18:04 UTC"
  },
  {
    "arxiv_id": "2502.08101v1",
    "title": "Rethinking Tokenized Graph Transformers for Node Classification",
    "authors": [
      "Jinsong Chen",
      "Chenyang Li",
      "GaiChao Li",
      "John E. Hopcroft",
      "Kun He"
    ],
    "abstract": "Node tokenized graph Transformers (GTs) have shown promising performance in\nnode classification. The generation of token sequences is the key module in\nexisting tokenized GTs which transforms the input graph into token sequences,\nfacilitating the node representation learning via Transformer. In this paper,\nwe observe that the generations of token sequences in existing GTs only focus\non the first-order neighbors on the constructed similarity graphs, which leads\nto the limited usage of nodes to generate diverse token sequences, further\nrestricting the potential of tokenized GTs for node classification. To this\nend, we propose a new method termed SwapGT. SwapGT first introduces a novel\ntoken swapping operation based on the characteristics of token sequences that\nfully leverages the semantic relevance of nodes to generate more informative\ntoken sequences. Then, SwapGT leverages a Transformer-based backbone to learn\nnode representations from the generated token sequences. Moreover, SwapGT\ndevelops a center alignment loss to constrain the representation learning from\nmultiple token sequences, further enhancing the model performance. Extensive\nempirical results on various datasets showcase the superiority of SwapGT for\nnode classification.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Preprint version",
    "pdf_url": "http://arxiv.org/pdf/2502.08101v1",
    "published_date": "2025-02-12 03:56:35 UTC",
    "updated_date": "2025-02-12 03:56:35 UTC"
  },
  {
    "arxiv_id": "2502.08092v1",
    "title": "GCoT: Chain-of-Thought Prompt Learning for Graphs",
    "authors": [
      "Xingtong Yu",
      "Chang Zhou",
      "Zhongwei Kuai",
      "Xinming Zhang",
      "Yuan Fang"
    ],
    "abstract": "Chain-of-thought (CoT) prompting has achieved remarkable success in natural\nlanguage processing (NLP). However, its vast potential remains largely\nunexplored for graphs. This raises an interesting question: How can we design\nCoT prompting for graphs to guide graph models to learn step by step? On one\nhand, unlike natural languages, graphs are non-linear and characterized by\ncomplex topological structures. On the other hand, many graphs lack textual\ndata, making it difficult to formulate language-based CoT prompting. In this\nwork, we propose the first CoT prompt learning framework for text-free graphs,\nGCoT. Specifically, we decompose the adaptation process for each downstream\ntask into a series of inference steps, with each step consisting of\nprompt-based inference, ``thought'' generation, and thought-conditioned prompt\nlearning. While the steps mimic CoT prompting in NLP, the exact mechanism\ndiffers significantly. Specifically, at each step, an input graph, along with a\nprompt, is first fed into a pre-trained graph encoder for prompt-based\ninference. We then aggregate the hidden layers of the encoder to construct a\n``thought'', which captures the working state of each node in the current step.\nConditioned on this thought, we learn a prompt specific to each node based on\nthe current state. These prompts are fed into the next inference step,\nrepeating the cycle. To evaluate and analyze the effectiveness of GCoT, we\nconduct comprehensive experiments on eight public datasets, which demonstrate\nthe advantage of our approach.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Under review",
    "pdf_url": "http://arxiv.org/pdf/2502.08092v1",
    "published_date": "2025-02-12 03:33:06 UTC",
    "updated_date": "2025-02-12 03:33:06 UTC"
  },
  {
    "arxiv_id": "2502.08673v1",
    "title": "High-Throughput SAT Sampling",
    "authors": [
      "Arash Ardakani",
      "Minwoo Kang",
      "Kevin He",
      "Qijing Huang",
      "John Wawrzynek"
    ],
    "abstract": "In this work, we present a novel technique for GPU-accelerated Boolean\nsatisfiability (SAT) sampling. Unlike conventional sampling algorithms that\ndirectly operate on conjunctive normal form (CNF), our method transforms the\nlogical constraints of SAT problems by factoring their CNF representations into\nsimplified multi-level, multi-output Boolean functions. It then leverages\ngradient-based optimization to guide the search for a diverse set of valid\nsolutions. Our method operates directly on the circuit structure of refactored\nSAT instances, reinterpreting the SAT problem as a supervised multi-output\nregression task. This differentiable technique enables independent bit-wise\noperations on each tensor element, allowing parallel execution of learning\nprocesses. As a result, we achieve GPU-accelerated sampling with significant\nruntime improvements ranging from $33.6\\times$ to $523.6\\times$ over\nstate-of-the-art heuristic samplers. We demonstrate the superior performance of\nour sampling method through an extensive evaluation on $60$ instances from a\npublic domain benchmark suite utilized in previous studies.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "7 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.08673v1",
    "published_date": "2025-02-12 03:20:45 UTC",
    "updated_date": "2025-02-12 03:20:45 UTC"
  },
  {
    "arxiv_id": "2503.18002v2",
    "title": "Neuromorphic Principles for Efficient Large Language Models on Intel Loihi 2",
    "authors": [
      "Steven Abreu",
      "Sumit Bam Shrestha",
      "Rui-Jie Zhu",
      "Jason Eshraghian"
    ],
    "abstract": "Large language models (LLMs) deliver impressive performance but require large\namounts of energy. In this work, we present a MatMul-free LLM architecture\nadapted for Intel's neuromorphic processor, Loihi 2. Our approach leverages\nLoihi 2's support for low-precision, event-driven computation and stateful\nprocessing. Our hardware-aware quantized model on GPU demonstrates that a 370M\nparameter MatMul-free model can be quantized with no accuracy loss. Based on\npreliminary results, we report up to 3x higher throughput with 2x less energy,\ncompared to transformer-based LLMs on an edge GPU, with significantly better\nscaling. Further hardware optimizations will increase throughput and decrease\nenergy consumption. These results show the potential of neuromorphic hardware\nfor efficient inference and pave the way for efficient reasoning models capable\nof generating complex, long-form text rapidly and cost-effectively.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.AR",
      "cs.LG"
    ],
    "primary_category": "cs.NE",
    "comment": "Accepted to International Conference on Learning Representations\n  (ICLR) Workshop on Scalable Optimization for Efficient and Adaptive\n  Foundation Models (SCOPE)",
    "pdf_url": "http://arxiv.org/pdf/2503.18002v2",
    "published_date": "2025-02-12 02:40:44 UTC",
    "updated_date": "2025-03-25 12:05:26 UTC"
  },
  {
    "arxiv_id": "2502.10454v1",
    "title": "One Example Shown, Many Concepts Known! Counterexample-Driven Conceptual Reasoning in Mathematical LLMs",
    "authors": [
      "Yinghui Li",
      "Jiayi Kuang",
      "Haojing Huang",
      "Zhikun Xu",
      "Xinnian Liang",
      "Yi Yu",
      "Wenlian Lu",
      "Yangning Li",
      "Xiaoyu Tan",
      "Chao Qu",
      "Ying Shen",
      "Hai-Tao Zheng",
      "Philip S. Yu"
    ],
    "abstract": "Leveraging mathematical Large Language Models (LLMs) for proof generation is\na fundamental topic in LLMs research. We argue that the ability of current LLMs\nto prove statements largely depends on whether they have encountered the\nrelevant proof process during training. This reliance limits their deeper\nunderstanding of mathematical theorems and related concepts. Inspired by the\npedagogical method of \"proof by counterexamples\" commonly used in human\nmathematics education, our work aims to enhance LLMs' ability to conduct\nmathematical reasoning and proof through counterexamples. Specifically, we\nmanually create a high-quality, university-level mathematical benchmark,\nCounterMATH, which requires LLMs to prove mathematical statements by providing\ncounterexamples, thereby assessing their grasp of mathematical concepts.\nAdditionally, we develop a data engineering framework to automatically obtain\ntraining data for further model improvement. Extensive experiments and detailed\nanalyses demonstrate that CounterMATH is challenging, indicating that LLMs,\nsuch as OpenAI o1, have insufficient counterexample-driven proof capabilities.\nMoreover, our exploration into model training reveals that strengthening LLMs'\ncounterexample-driven conceptual reasoning abilities is crucial for improving\ntheir overall mathematical capabilities. We believe that our work offers new\nperspectives on the community of mathematical LLMs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.10454v1",
    "published_date": "2025-02-12 02:01:10 UTC",
    "updated_date": "2025-02-12 02:01:10 UTC"
  },
  {
    "arxiv_id": "2502.08056v1",
    "title": "Cognify: Supercharging Gen-AI Workflows With Hierarchical Autotuning",
    "authors": [
      "Zijian He",
      "Reyna Abhyankar",
      "Vikranth Srivatsa",
      "Yiying Zhang"
    ],
    "abstract": "Today's gen-AI workflows that involve multiple ML model calls, tool/API\ncalls, data retrieval, or generic code execution are often tuned manually in an\nad-hoc way that is both time-consuming and error-prone. In this paper, we\npropose a systematic approach for automatically tuning gen-AI workflows. Our\nkey insight is that gen-AI workflows can benefit from structure, operator, and\nprompt changes, but unique properties of gen-AI workflows require new\noptimization techniques. We propose AdaSeek, an adaptive hierarchical search\nalgorithm for autotuning gen-AI workflows. AdaSeek organizes workflow tuning\nmethods into different layers based on the user-specified total search budget\nand distributes the budget across different layers based on the complexity of\neach layer. During its hierarchical search, AdaSeek redistributes the search\nbudget from less useful to more promising tuning configurations based on\nworkflow-level evaluation results. We implement AdaSeek in a workflow\nautotuning framework called Cognify and evaluate Cognify using six types of\nworkflows such as RAG-based QA and text-to-SQL transformation. Overall, Cognify\nimproves these workflows' generation quality by up to 2.8x, reduces execution\nmonetary cost by up to 10x, and reduces end-to-end latency by 2.7x.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.08056v1",
    "published_date": "2025-02-12 01:36:27 UTC",
    "updated_date": "2025-02-12 01:36:27 UTC"
  },
  {
    "arxiv_id": "2502.10453v1",
    "title": "Linking Cryptoasset Attribution Tags to Knowledge Graph Entities: An LLM-based Approach",
    "authors": [
      "RÃ©gnier Avice",
      "Bernhard Haslhofer",
      "Zhidong Li",
      "Jianlong Zhou"
    ],
    "abstract": "Attribution tags form the foundation of modern cryptoasset forensics.\nHowever, inconsistent or incorrect tags can mislead investigations and even\nresult in false accusations. To address this issue, we propose a novel\ncomputational method based on Large Language Models (LLMs) to link attribution\ntags with well-defined knowledge graph concepts. We implemented this method in\nan end-to-end pipeline and conducted experiments showing that our approach\noutperforms baseline methods by up to 37.4% in F1-score across three publicly\navailable attribution tag datasets. By integrating concept filtering and\nblocking procedures, we generate candidate sets containing five knowledge graph\nentities, achieving a recall of 93% without the need for labeled data.\nAdditionally, we demonstrate that local LLM models can achieve F1-scores of\n90%, comparable to remote models which achieve 94%. We also analyze the\ncost-performance trade-offs of various LLMs and prompt templates, showing that\nselecting the most cost-effective configuration can reduce costs by 90%, with\nonly a 1% decrease in performance. Our method not only enhances attribution tag\nquality but also serves as a blueprint for fostering more reliable forensic\nevidence.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL",
      "cs.DB",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "Accepted at Financial Cryptography and Data Security 2025 Conference\n  (FC2025)",
    "pdf_url": "http://arxiv.org/pdf/2502.10453v1",
    "published_date": "2025-02-12 01:28:40 UTC",
    "updated_date": "2025-02-12 01:28:40 UTC"
  },
  {
    "arxiv_id": "2502.08047v2",
    "title": "WorldGUI: Dynamic Testing for Comprehensive Desktop GUI Automation",
    "authors": [
      "Henry Hengyuan Zhao",
      "Difei Gao",
      "Mike Zheng Shou"
    ],
    "abstract": "Current GUI agents have achieved outstanding performance in GUI element\ngrounding. However, planning remains highly challenging, especially due to\nsensitivity to the initial state of the environment. Specifically, slight\ndifferences in the initial state-such as the target software not being open or\nthe interface not being in its default state-often lead to planning errors.\nThis issue is widespread in real user scenarios, but existing benchmarks fail\nto evaluate it. In this paper, we present WorldGUI, a novel GUI benchmark that\ndesigns GUI tasks with various initial states to simulate real computer-user\ninteractions. The benchmark spans a wide range of tasks across 10 popular\nsoftware applications, including PowerPoint, VSCode, and Adobe Acrobat. In\naddition, to address the challenges of dynamic GUI automation tasks, we propose\nGUI-Thinker, a holistic framework, leveraging a critique mechanism, that\neffectively manages the unpredictability and complexity of GUI interactions.\nExperimental results demonstrate that GUI-Thinker significantly outperforms\nClaude-3.5 (Computer Use) by 14.9% in success rate on WorldGUI tasks. This\nimprovement underscores the effectiveness of our critical-thinking-based\nframework in enhancing GUI automation. The code is available at\nhttps://github.com/showlab/WorldGUI.",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "19 pages, 18 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.08047v2",
    "published_date": "2025-02-12 01:06:10 UTC",
    "updated_date": "2025-02-19 23:27:05 UTC"
  },
  {
    "arxiv_id": "2502.08045v2",
    "title": "Break the Checkbox: Challenging Closed-Style Evaluations of Cultural Alignment in LLMs",
    "authors": [
      "Mohsinul Kabir",
      "Ajwad Abrar",
      "Sophia Ananiadou"
    ],
    "abstract": "A large number of studies rely on closed-style multiple-choice surveys to\nevaluate cultural alignment in Large Language Models (LLMs). In this work, we\nchallenge this constrained evaluation paradigm and explore more realistic,\nunconstrained approaches. Using the World Values Survey (WVS) and Hofstede\nCultural Dimensions as case studies, we demonstrate that LLMs exhibit stronger\ncultural alignment in less constrained settings, where responses are not\nforced. Additionally, we show that even minor changes, such as reordering\nsurvey choices, lead to inconsistent outputs, exposing the limitations of\nclosed-style evaluations. Our findings advocate for more robust and flexible\nevaluation frameworks that focus on specific cultural proxies, encouraging more\nnuanced and accurate assessments of cultural alignment in LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL",
    "comment": "Preprint",
    "pdf_url": "http://arxiv.org/pdf/2502.08045v2",
    "published_date": "2025-02-12 01:04:13 UTC",
    "updated_date": "2025-02-16 00:34:13 UTC"
  },
  {
    "arxiv_id": "2503.16434v2",
    "title": "Interactive Sketchpad: A Multimodal Tutoring System for Collaborative, Visual Problem-Solving",
    "authors": [
      "Steven-Shine Chen",
      "Jimin Lee",
      "Paul Pu Liang"
    ],
    "abstract": "Humans have long relied on visual aids like sketches and diagrams to support\nreasoning and problem-solving. Visual tools, like auxiliary lines in geometry\nor graphs in calculus, are essential for understanding complex ideas. However,\nmany tutoring systems remain text-based, providing feedback only through\nnatural language. Leveraging recent advances in Large Multimodal Models (LMMs),\nthis paper introduces Interactive Sketchpad, a tutoring system that combines\nlanguage-based explanations with interactive visualizations to enhance\nlearning. Built on a pre-trained LMM, Interactive Sketchpad is fine-tuned to\nprovide step-by-step guidance in both text and visuals, enabling natural\nmultimodal interaction with the student. Accurate and robust diagrams are\ngenerated by incorporating code execution into the reasoning process. User\nstudies conducted on math problems such as geometry, calculus, and trigonometry\ndemonstrate that Interactive Sketchpad leads to improved task comprehension,\nproblem-solving accuracy, and engagement levels, highlighting its potential for\ntransforming educational technologies. All code is available at:\nhttps://stevenshinechen.github.io/interactivesketchpad/.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "To be published in Extended Abstracts of the CHI Conference on Human\n  Factors in Computing Systems (CHI EA 25)",
    "pdf_url": "http://arxiv.org/pdf/2503.16434v2",
    "published_date": "2025-02-12 00:59:25 UTC",
    "updated_date": "2025-04-02 01:03:51 UTC"
  }
]