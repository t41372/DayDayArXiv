{
  "date": "2024-04-22",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-04-22 的 arXiv 中文 TLDR 快报！今天 arXiv 的论文主要聚焦于 AI 模型的优化、安全性和应用创新，特别是大型语言模型 (LLMs) 和生成模型的改进，以及它们在医学、图像处理和可持续发展的潜力，其中 OpenELM 和 Phi-3 Technical Report 等文章令人印象深刻，展示了知名机构如 Apple 和 Google DeepMind 的前沿贡献。\n\n今天的论文覆盖了 AI 领域的多个分支，我将优先讨论那些重要、话题性强或有潜在影响的文章（如 LLMs 的安全和效率优化），并将相关主题归类讨论。其他较次要的论文将快速掠过，以控制篇幅。\n\n### LLMs 和生成模型的优化与安全\n这些论文探讨了 LLMs 的性能提升、安全风险和实际应用，是本日重点。\n- **A Survey on the Real Power of ChatGPT（ChatGPT 的真实能力调查）**：这篇综述分析了 ChatGPT 在七类 NLP 任务中的实际表现，强调了其潜在偏差和社会风险，并讨论了评估挑战。主要贡献是揭示 ChatGPT 的黑箱问题，避免研究者被表面生成误导。\n- **OpenELM: An Efficient Language Model Family with Open Training and Inference Framework（OpenELM: 高效语言模型家族及其开源训练框架）**：Apple 团队的作品，提出了一种层级缩放策略的语言模型，相比 OLMo 提升了 2.36% 的准确率，同时开源了完整训练框架和数据集。主要发现是它在参数预算下实现了高效训练，适合资源受限场景。\n- **Hybrid LLM: Cost-Efficient and Quality-Aware Query Routing（混合 LLM: 成本高效且质量感知的查询路由）**：这篇论文介绍了基于查询难度的路由机制，能将查询分配给小模型或大模型，减少大模型调用 40% 而不损失质量。主要贡献是平衡了成本和性能，适用于实际部署。\n- **Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone（Phi-3 技术报告: 适用于手机的高性能语言模型）**：Google DeepMind 的报告，介绍了 Phi-3-mini 等模型，能在手机上运行并匹敌 GPT-3.5，主要通过高效训练数据和参数缩放实现。主要发现是它在资源有限的环境中保持了高准确率，如 MMLU 达 69%。\n- **Filtered Direct Preference Optimization（过滤直接偏好优化）**：提出了一种 DPO 变体，通过过滤低质量文本提升模型性能，实验显示在多任务场景下准确率提升 9%。主要贡献是改善了数据集质量，减少了模型偏差。\n- **Shifting Focus with HCEye: Exploring the Dynamics of Visual Highlighting and Cognitive Load on User Attention and Saliency Prediction（HCEye: 探索视觉突出和认知负载对用户注意力和显著性预测的影响）**：相关论文快速提到：它使用眼动数据分析视觉高亮对注意力的影响，提高了显著性模型的预测性能。\n\n这些工作突出了 LLMs 的实用性和风险管理，OpenELM 和 Phi-3 的开源框架尤其值得关注，因为它们推动了模型民主化。\n\n### 生成模型和图像处理\n图像生成和处理主题活跃，以 Stable Diffusion 为代表。\n- **Interactive Visual Learning for Stable Diffusion（Stable Diffusion 的交互式视觉学习）**：介绍了 Diffusion Explainer 工具，帮助用户理解 Stable Diffusion 的生成过程，并通过实时交互提升 AI 教育。主要贡献是它已吸引 7200+ 用户，民主化了 AI 学习。\n- **Detecting and Mitigating Hallucination in Large Vision Language Models via Fine-Grained AI Feedback（通过细粒度 AI 反馈检测和缓解大型视觉语言模型的幻觉）**：提出了一种反馈机制，使用奖励模型检测幻觉，实验显示幻觉减少 48%。主要发现是它在视觉任务中提升了模型鲁棒性。\n- **Graphic Design with Large Multimodal Model（使用大型多模态模型进行图形设计）**：Graphist 框架能从无序元素生成图形布局，实验显示性能提升 10%。主要贡献是它简化了设计过程，适用于实际应用。\n- **Regional Style and Color Transfer（区域风格和颜色转移）**：快速提到：它使用分割网络实现背景风格转移，避免了前景扭曲，提高了图像合成自然度。\n\n这些论文强调了生成模型的交互性和精确性，Stable Diffusion 的工具化应用特别有话题度。\n\n### AI 在医学和强化学习的创新\nAI 应用扩展到医学和决策领域。\n- **Pixels and Predictions: Potential of GPT-4V in Meteorological Imagery Analysis and Forecast Communication（像素和预测: GPT-4V 在气象图像分析和预报通信中的潜力）**：评估 GPT-4V 在气象图像上的表现，实验显示它能生成准确预报，但西班牙语翻译存在问题。主要贡献是它揭示了 LLMs 在多语言环境中的局限。\n- **Learning Control Barrier Functions and their application in Reinforcement Learning: A Survey（学习控制屏障函数及其在强化学习中的应用: 综述）**：这篇综述探讨了控制屏障函数在安全强化学习中的作用，促进了机器人应用。主要发现是数据驱动方法能自动定义函数，提升机器人安全。\n- **Adapting to time: Why nature may have evolved a diverse set of neurons（适应时间: 为什么自然进化出多样神经元）**：快速提到：它使用神经网络模拟神经元多样性，解释了时间处理在强化学习中的作用。\n\n这些工作展示了 AI 的跨界潜力，强化学习在机器人安全上的应用特别值得追踪。\n\n其他论文，如联邦学习、量子计算和可持续发展的主题（如 AI 在可持续发展目标中的态度），虽然涉及广泛，但相对次要，我仅快速总结：例如，**FedTAD: Topology-aware Data-free Knowledge Distillation for Subgraph Federated Learning（FedTAD: 拓扑感知的无数据知识蒸馏用于子图联邦学习）** 提升了联邦学习效率；**A Survey on Self-Evolution of Large Language Models（大型语言模型的自演化综述）** 讨论了 LLMs 的自主优化，但篇幅有限，就不展开。\n\n总之，今天的 arXiv 亮点在于 LLMs 的高效优化和安全机制，相关论文如 OpenELM 和 Phi-3 可能引发更多讨论。如果你对特定领域感兴趣，建议查看这些核心文章的完整摘要。明天见！",
  "papers": [
    {
      "arxiv_id": "2405.00704v2",
      "title": "A Survey on the Real Power of ChatGPT",
      "title_zh": "翻译失败",
      "authors": [
        "Ming Liu",
        "Ran Liu",
        "Ye Zhu",
        "Hua Wang",
        "Youyang Qu",
        "Rongsheng Li",
        "Yongpan Sheng",
        "Wray Buntine"
      ],
      "abstract": "ChatGPT has changed the AI community and an active research line is the\nperformance evaluation of ChatGPT. A key challenge for the evaluation is that\nChatGPT is still closed-source and traditional benchmark datasets may have been\nused by ChatGPT as the training data. In this paper, (i) we survey recent\nstudies which uncover the real performance levels of ChatGPT in seven\ncategories of NLP tasks, (ii) review the social implications and safety issues\nof ChatGPT, and (iii) emphasize key challenges and opportunities for its\nevaluation. We hope our survey can shed some light on its blackbox manner, so\nthat researchers are not misleaded by its surface generation.",
      "tldr_zh": "这篇调查论文评估了 ChatGPT 在七类 NLP 任务中的真实性能，针对其闭源特性及可能使用传统基准数据集的问题，回顾了最近的相关研究。论文揭示了 ChatGPT 的实际表现水平，同时讨论了其社会影响、安全风险以及评估中的关键挑战和机会。最终，该研究旨在为更准确地理解 ChatGPT 提供指导，避免被其表面生成所误导。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "18 pages, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2405.00704v2",
      "published_date": "2024-04-22 23:31:28 UTC",
      "updated_date": "2024-05-10 02:38:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:26:52.063287"
    },
    {
      "arxiv_id": "2404.16069v1",
      "title": "Interactive Visual Learning for Stable Diffusion",
      "title_zh": "翻译失败",
      "authors": [
        "Seongmin Lee",
        "Benjamin Hoover",
        "Hendrik Strobelt",
        "Zijie J. Wang",
        "ShengYun Peng",
        "Austin Wright",
        "Kevin Li",
        "Haekyu Park",
        "Haoyang Yang",
        "Polo Chau"
      ],
      "abstract": "Diffusion-based generative models' impressive ability to create convincing\nimages has garnered global attention. However, their complex internal\nstructures and operations often pose challenges for non-experts to grasp. We\nintroduce Diffusion Explainer, the first interactive visualization tool\ndesigned to elucidate how Stable Diffusion transforms text prompts into images.\nIt tightly integrates a visual overview of Stable Diffusion's complex\ncomponents with detailed explanations of their underlying operations. This\nintegration enables users to fluidly transition between multiple levels of\nabstraction through animations and interactive elements. Offering real-time\nhands-on experience, Diffusion Explainer allows users to adjust Stable\nDiffusion's hyperparameters and prompts without the need for installation or\nspecialized hardware. Accessible via users' web browsers, Diffusion Explainer\nis making significant strides in democratizing AI education, fostering broader\npublic access. More than 7,200 users spanning 113 countries have used our\nopen-sourced tool at https://poloclub.github.io/diffusion-explainer/. A video\ndemo is available at https://youtu.be/MbkIADZjPnA.",
      "tldr_zh": "本研究引入了Diffusion Explainer，这是第一个交互式可视化工具，旨在帮助非专家理解Stable Diffusion如何将文本提示转化为图像。工具通过整合Stable Diffusion的组件概述、详细操作解释以及动画和交互元素，允许用户在不同抽象级别之间平滑切换，并实时调整hyperparameters和提示，而无需安装或专用硬件。作为开源项目，Diffusion Explainer已通过网页浏览器获得超过7200名用户在113个国家的广泛采用，推动了AI教育的民主化进程。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "4 pages, 3 figures. arXiv admin note: substantial text overlap with\n  arXiv:2305.03509",
      "pdf_url": "http://arxiv.org/pdf/2404.16069v1",
      "published_date": "2024-04-22 23:23:45 UTC",
      "updated_date": "2024-04-22 23:23:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:27:03.946004"
    },
    {
      "arxiv_id": "2404.14619v2",
      "title": "OpenELM: An Efficient Language Model Family with Open Training and Inference Framework",
      "title_zh": "OpenELM：一种高效的语言模型家族，带有开放的训练和推理框架",
      "authors": [
        "Sachin Mehta",
        "Mohammad Hossein Sekhavat",
        "Qingqing Cao",
        "Maxwell Horton",
        "Yanzi Jin",
        "Chenfan Sun",
        "Iman Mirzadeh",
        "Mahyar Najibi",
        "Dmitry Belenko",
        "Peter Zatloukal",
        "Mohammad Rastegari"
      ],
      "abstract": "The reproducibility and transparency of large language models are crucial for\nadvancing open research, ensuring the trustworthiness of results, and enabling\ninvestigations into data and model biases, as well as potential risks. To this\nend, we release OpenELM, a state-of-the-art open language model. OpenELM uses a\nlayer-wise scaling strategy to efficiently allocate parameters within each\nlayer of the transformer model, leading to enhanced accuracy. For example, with\na parameter budget of approximately one billion parameters, OpenELM exhibits a\n2.36% improvement in accuracy compared to OLMo while requiring $2\\times$ fewer\npre-training tokens.\n  Diverging from prior practices that only provide model weights and inference\ncode, and pre-train on private datasets, our release includes the complete\nframework for training and evaluation of the language model on publicly\navailable datasets, including training logs, multiple checkpoints, and\npre-training configurations. We also release code to convert models to MLX\nlibrary for inference and fine-tuning on Apple devices. This comprehensive\nrelease aims to empower and strengthen the open research community, paving the\nway for future open research endeavors.\n  Our source code along with pre-trained model weights and training recipes is\navailable at \\url{https://github.com/apple/corenet}. Additionally, \\model\nmodels can be found on HuggingFace at:\n\\url{https://huggingface.co/apple/OpenELM}.",
      "tldr_zh": "本研究推出了 OpenELM，一系列高效的开源语言模型，采用 layer-wise scaling 策略来优化 transformer 模型中参数的分配，从而提升准确性，例如在约10亿参数预算下，比 OLMo 模型准确性提高了2.36%，且只需一半的预训练标记。不同于以往仅提供模型权重和推理代码的做法，OpenELM 全面开源了训练和评估框架，包括公开数据集、训练日志、多个检查点以及预训练配置，并支持将模型转换为 MLX 库用于 Apple 设备的推理和微调。该框架旨在增强开源社区的再现性和透明性，促进对模型偏差和风险的深入研究，并为未来语言模型发展铺平道路。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Minor corrections",
      "pdf_url": "http://arxiv.org/pdf/2404.14619v2",
      "published_date": "2024-04-22 23:12:03 UTC",
      "updated_date": "2024-05-02 00:30:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:27:17.657580"
    },
    {
      "arxiv_id": "2404.14618v1",
      "title": "Hybrid LLM: Cost-Efficient and Quality-Aware Query Routing",
      "title_zh": "翻译失败",
      "authors": [
        "Dujian Ding",
        "Ankur Mallick",
        "Chi Wang",
        "Robert Sim",
        "Subhabrata Mukherjee",
        "Victor Ruhle",
        "Laks V. S. Lakshmanan",
        "Ahmed Hassan Awadallah"
      ],
      "abstract": "Large language models (LLMs) excel in most NLP tasks but also require\nexpensive cloud servers for deployment due to their size, while smaller models\nthat can be deployed on lower cost (e.g., edge) devices, tend to lag behind in\nterms of response quality. Therefore in this work we propose a hybrid inference\napproach which combines their respective strengths to save cost and maintain\nquality. Our approach uses a router that assigns queries to the small or large\nmodel based on the predicted query difficulty and the desired quality level.\nThe desired quality level can be tuned dynamically at test time to seamlessly\ntrade quality for cost as per the scenario requirements. In experiments our\napproach allows us to make up to 40% fewer calls to the large model, with no\ndrop in response quality.",
      "tldr_zh": "这篇论文提出了一种Hybrid LLM方法，通过结合大型语言模型（LLMs）和小型模型的优势，实现成本高效且质量感知的查询路由。方法的核心是使用一个router，根据预测的查询难度和期望的质量水平，将查询分配给小模型或大模型，从而减少对昂贵云服务器的依赖。用户可以在测试时动态调整质量水平，以根据场景需求在成本和性能之间权衡。实验结果显示，该方法可减少多达40%的对大型模型的调用，同时保持响应质量不变。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to ICLR 2024 (main conference)",
      "pdf_url": "http://arxiv.org/pdf/2404.14618v1",
      "published_date": "2024-04-22 23:06:42 UTC",
      "updated_date": "2024-04-22 23:06:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:27:29.378059"
    },
    {
      "arxiv_id": "2404.16879v1",
      "title": "Learning Control Barrier Functions and their application in Reinforcement Learning: A Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Maeva Guerrier",
        "Hassan Fouad",
        "Giovanni Beltrame"
      ],
      "abstract": "Reinforcement learning is a powerful technique for developing new robot\nbehaviors. However, typical lack of safety guarantees constitutes a hurdle for\nits practical application on real robots. To address this issue, safe\nreinforcement learning aims to incorporate safety considerations, enabling\nfaster transfer to real robots and facilitating lifelong learning. One\npromising approach within safe reinforcement learning is the use of control\nbarrier functions. These functions provide a framework to ensure that the\nsystem remains in a safe state during the learning process. However,\nsynthesizing control barrier functions is not straightforward and often\nrequires ample domain knowledge. This challenge motivates the exploration of\ndata-driven methods for automatically defining control barrier functions, which\nis highly appealing. We conduct a comprehensive review of the existing\nliterature on safe reinforcement learning using control barrier functions.\nAdditionally, we investigate various techniques for automatically learning the\nControl Barrier Functions, aiming to enhance the safety and efficacy of\nReinforcement Learning in practical robot applications.",
      "tldr_zh": "这篇论文对Control Barrier Functions在Reinforcement Learning中的应用进行了全面综述，旨在解决强化学习在机器人行为开发中缺乏安全保障的问题。Control Barrier Functions提供了一个框架，确保系统在学习过程中始终保持安全状态，从而加速强化学习的实际应用。论文重点探讨了自动学习这些函数的数据驱动方法，以克服合成CBFs所需的大量领域知识挑战。最终，该综述强调这些技术能提升Reinforcement Learning的安全性和效率，促进其在机器人领域的长期学习和部署。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.16879v1",
      "published_date": "2024-04-22 22:52:14 UTC",
      "updated_date": "2024-04-22 22:52:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:27:41.747917"
    },
    {
      "arxiv_id": "2404.14606v2",
      "title": "Cross-Task Multi-Branch Vision Transformer for Facial Expression and Mask Wearing Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Armando Zhu",
        "Keqin Li",
        "Tong Wu",
        "Peng Zhao",
        "Bo Hong"
      ],
      "abstract": "With wearing masks becoming a new cultural norm, facial expression\nrecognition (FER) while taking masks into account has become a significant\nchallenge. In this paper, we propose a unified multi-branch vision transformer\nfor facial expression recognition and mask wearing classification tasks. Our\napproach extracts shared features for both tasks using a dual-branch\narchitecture that obtains multi-scale feature representations. Furthermore, we\npropose a cross-task fusion phase that processes tokens for each task with\nseparate branches, while exchanging information using a cross attention module.\nOur proposed framework reduces the overall complexity compared with using\nseparate networks for both tasks by the simple yet effective cross-task fusion\nphase. Extensive experiments demonstrate that our proposed model performs\nbetter than or on par with different state-of-the-art methods on both facial\nexpression recognition and facial mask wearing classification task.",
      "tldr_zh": "本研究针对戴口罩背景下的人脸表情识别（FER）和口罩佩戴分类的挑战，提出了一种统一的 multi-branch vision transformer 框架。该框架采用双分支架构提取共享的多尺度特征表示，并通过 cross-task fusion 阶段利用 cross attention 模块交换任务间信息，从而减少整体复杂性。相比使用独立网络，该方法在 FER 和口罩分类任务上表现出优于或相当于是现有最先进方法的性能。实验结果证明了其有效性，为跨任务人脸分析提供了高效解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.14606v2",
      "published_date": "2024-04-22 22:02:19 UTC",
      "updated_date": "2024-04-30 06:34:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:27:53.020202"
    },
    {
      "arxiv_id": "2404.14581v1",
      "title": "The Adversarial AI-Art: Understanding, Generation, Detection, and Benchmarking",
      "title_zh": "翻译失败",
      "authors": [
        "Yuying Li",
        "Zeyan Liu",
        "Junyi Zhao",
        "Liangqin Ren",
        "Fengjun Li",
        "Jiebo Luo",
        "Bo Luo"
      ],
      "abstract": "Generative AI models can produce high-quality images based on text prompts.\nThe generated images often appear indistinguishable from images generated by\nconventional optical photography devices or created by human artists (i.e.,\nreal images). While the outstanding performance of such generative models is\ngenerally well received, security concerns arise. For instance, such image\ngenerators could be used to facilitate fraud or scam schemes, generate and\nspread misinformation, or produce fabricated artworks. In this paper, we\npresent a systematic attempt at understanding and detecting AI-generated images\n(AI-art) in adversarial scenarios. First, we collect and share a dataset of\nreal images and their corresponding artificial counterparts generated by four\npopular AI image generators. The dataset, named ARIA, contains over 140K images\nin five categories: artworks (painting), social media images, news photos,\ndisaster scenes, and anime pictures. This dataset can be used as a foundation\nto support future research on adversarial AI-art. Next, we present a user study\nthat employs the ARIA dataset to evaluate if real-world users can distinguish\nwith or without reference images. In a benchmarking study, we further evaluate\nif state-of-the-art open-source and commercial AI image detectors can\neffectively identify the images in the ARIA dataset. Finally, we present a\nResNet-50 classifier and evaluate its accuracy and transferability on the ARIA\ndataset.",
      "tldr_zh": "这篇论文探讨了生成AI模型在创建高质量图像时可能引发的安全问题，如欺诈和误传信息，焦点在于对抗场景下的AI生成图像(AI-art)理解、生成、检测和基准测试。研究者收集并分享了ARIA数据集，包含超过14万张真实图像及其由四种流行AI图像生成器创建的对应图像，涵盖artworks (painting)、social media images、news photos、disaster scenes和anime pictures等领域，作为未来研究的基石。他们通过用户研究评估了真实用户在有无参考图像时的辨识能力，并基准测试了现有开源和商业AI图像检测器的有效性；此外，提出一个ResNet-50分类器，并评估其在ARIA数据集上的准确性和可转移性。结果表明，该方法有助于提升AI-art检测的可靠性和性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.14581v1",
      "published_date": "2024-04-22 21:00:13 UTC",
      "updated_date": "2024-04-22 21:00:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:28:07.992611"
    },
    {
      "arxiv_id": "2404.14575v1",
      "title": "Designing forecasting software for forecast users: Empowering non-experts to create and understand their own forecasts",
      "title_zh": "为预测用户设计预测软件：赋予非专家创建和理解他们自己预测的能力",
      "authors": [
        "Richard Stromer",
        "Oskar Triebe",
        "Chad Zanocco",
        "Ram Rajagopal"
      ],
      "abstract": "Forecasts inform decision-making in nearly every domain. Forecasts are often\nproduced by experts with rare or hard to acquire skills. In practice, forecasts\nare often used by domain experts and managers with little forecasting\nexpertise. Our study focuses on how to design forecasting software that\nempowers non-expert users. We study how users can make use of state-of-the-art\nforecasting methods, embed their domain knowledge, and how they build\nunderstanding and trust towards generated forecasts. To do so, we co-designed a\nforecasting software prototype using feedback from users and then analyzed\ntheir interactions with our prototype. Our results identified three main\nconsiderations for non-expert users: (1) a safe stepwise approach facilitating\ncausal understanding and trust; (2) a white box model supporting\nhuman-reasoning-friendly components; (3) the inclusion of domain knowledge.\nThis paper contributes insights into how non-expert users interact with\nforecasting software and by recommending ways to design more accessible\nforecasting software.",
      "tldr_zh": "这篇论文探讨了如何设计预测软件（forecasting software），以赋予非专家用户创建和理解预测的能力，针对传统上由专家主导的预测过程。研究团队通过与用户共同设计原型并分析互动，识别了三个关键考虑因素：（1）安全逐步方法促进因果理解和信任；（2）white box model支持人类友好的推理组件；（3）纳入领域知识。论文贡献了关于非专家用户与预测软件互动的见解，并推荐了改进软件可访问性的设计策略。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "10 pages",
      "pdf_url": "http://arxiv.org/pdf/2404.14575v1",
      "published_date": "2024-04-22 20:53:08 UTC",
      "updated_date": "2024-04-22 20:53:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:28:17.903184"
    },
    {
      "arxiv_id": "2404.14552v1",
      "title": "Generalizing Multi-Step Inverse Models for Representation Learning to Finite-Memory POMDPs",
      "title_zh": "将多步逆模型泛化到有限记忆 POMDPs 的表示学习",
      "authors": [
        "Lili Wu",
        "Ben Evans",
        "Riashat Islam",
        "Raihan Seraj",
        "Yonathan Efroni",
        "Alex Lamb"
      ],
      "abstract": "Discovering an informative, or agent-centric, state representation that\nencodes only the relevant information while discarding the irrelevant is a key\nchallenge towards scaling reinforcement learning algorithms and efficiently\napplying them to downstream tasks. Prior works studied this problem in\nhigh-dimensional Markovian environments, when the current observation may be a\ncomplex object but is sufficient to decode the informative state. In this work,\nwe consider the problem of discovering the agent-centric state in the more\nchallenging high-dimensional non-Markovian setting, when the state can be\ndecoded from a sequence of past observations. We establish that generalized\ninverse models can be adapted for learning agent-centric state representation\nfor this task. Our results include asymptotic theory in the deterministic\ndynamics setting as well as counter-examples for alternative intuitive\nalgorithms. We complement these findings with a thorough empirical study on the\nagent-centric state discovery abilities of the different alternatives we put\nforward. Particularly notable is our analysis of past actions, where we show\nthat these can be a double-edged sword: making the algorithms more successful\nwhen used correctly and causing dramatic failure when used incorrectly.",
      "tldr_zh": "这篇论文探讨了在高维非Markovian环境中发现agent-centric state representation的问题，将多步inverse models泛化到有限记忆POMDPs，以扩展强化学习算法并应用于下游任务。作者建立了广义inverse models方法，用于从过去的观察序列中学习代理中心状态表示，并提供了在确定性动态设置下的渐近理论以及对直观替代算法的反例。实证研究表明，正确使用past actions可以提升状态发现能力，但错误使用可能导致算法失败，为高效的强化学习表示学习提供了关键见解。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.14552v1",
      "published_date": "2024-04-22 19:46:16 UTC",
      "updated_date": "2024-04-22 19:46:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:28:30.229669"
    },
    {
      "arxiv_id": "2404.14547v1",
      "title": "Integrating Disambiguation and User Preferences into Large Language Models for Robot Motion Planning",
      "title_zh": "翻译失败",
      "authors": [
        "Mohammed Abugurain",
        "Shinkyu Park"
      ],
      "abstract": "This paper presents a framework that can interpret humans' navigation\ncommands containing temporal elements and directly translate their natural\nlanguage instructions into robot motion planning. Central to our framework is\nutilizing Large Language Models (LLMs). To enhance the reliability of LLMs in\nthe framework and improve user experience, we propose methods to resolve the\nambiguity in natural language instructions and capture user preferences. The\nprocess begins with an ambiguity classifier, identifying potential\nuncertainties in the instructions. Ambiguous statements trigger a GPT-4-based\nmechanism that generates clarifying questions, incorporating user responses for\ndisambiguation. Also, the framework assesses and records user preferences for\nnon-ambiguous instructions, enhancing future interactions. The last part of\nthis process is the translation of disambiguated instructions into a robot\nmotion plan using Linear Temporal Logic. This paper details the development of\nthis framework and the evaluation of its performance in various test scenarios.",
      "tldr_zh": "这篇论文提出一个框架，使用Large Language Models (LLMs)来解释包含时间元素的自然语言导航命令，并直接转化为机器人运动规划，以提升交互可靠性。该框架包括一个模糊性分类器来识别指令中的不确定性，并通过GPT-4生成澄清问题，结合用户响应进行消除模糊；同时，它评估并记录用户偏好，以优化非模糊指令的处理。最终，框架将消除模糊后的指令转化为基于Linear Temporal Logic的机器人运动计划，并在多种测试场景中验证了其性能表现。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.14547v1",
      "published_date": "2024-04-22 19:38:37 UTC",
      "updated_date": "2024-04-22 19:38:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:28:41.454837"
    },
    {
      "arxiv_id": "2404.14408v3",
      "title": "SpaceByte: Towards Deleting Tokenization from Large Language Modeling",
      "title_zh": "翻译失败",
      "authors": [
        "Kevin Slagle"
      ],
      "abstract": "Tokenization is widely used in large language models because it significantly\nimproves performance. However, tokenization imposes several disadvantages, such\nas performance biases, increased adversarial vulnerability, decreased\ncharacter-level modeling performance, and increased modeling complexity. To\naddress these disadvantages without sacrificing performance, we propose\nSpaceByte, a novel byte-level decoder architecture that closes the performance\ngap between byte-level and subword autoregressive language modeling. SpaceByte\nconsists of a byte-level Transformer model, but with extra larger transformer\nblocks inserted in the middle of the layers. We find that performance is\nsignificantly improved by applying these larger blocks only after certain\nbytes, such as space characters, which typically denote word boundaries. Our\nexperiments show that for a fixed training and inference compute budget,\nSpaceByte outperforms other byte-level architectures and roughly matches the\nperformance of tokenized Transformer architectures.",
      "tldr_zh": "该论文指出现有大型语言模型中广泛使用的 Tokenization 会带来性能偏差、增加对抗性漏洞、降低字符级建模性能以及增加建模复杂性等问题。作者提出 SpaceByte，一种新型 byte-level 解码器架构，基于 byte-level Transformer 模型，并在特定字节（如空格字符）后插入更大的 Transformer 块，以优化性能。实验结果显示，在固定的训练和推理计算预算下，SpaceByte 超过了其他 byte-level 架构，并大致匹配了基于 Tokenization 的 Transformer 模型的性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "9+10 pages, 3+1 figures, 2+4 tables",
      "pdf_url": "http://arxiv.org/pdf/2404.14408v3",
      "published_date": "2024-04-22 17:59:29 UTC",
      "updated_date": "2024-10-06 02:17:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:28:54.517794"
    },
    {
      "arxiv_id": "2404.14395v2",
      "title": "PARAMANU-GANITA: Can Small Math Language Models Rival with Large Language Models on Mathematical Reasoning?",
      "title_zh": "PARAMANU-GANITA：小型数学语言模型能否在数学推理上与大型语言模型匹敌？",
      "authors": [
        "Mitodru Niyogi",
        "Arnab Bhattacharya"
      ],
      "abstract": "In this paper, we study whether domain specific pretraining of small\ngenerative language models (SLM) from scratch with domain specialized tokenizer\nand Chain-of-Thought (CoT) instruction fine-tuning results in competitive\nperformance on mathematical reasoning compared to LLMs? Secondly, whether this\napproach is environmentally sustainable, highly cost efficient? To address\nthese research questions, we present Paramanu-Ganita, a 208 million-parameter\nnovel decoder-only Auto Regressive SLM on mathematics. We performed pretraining\nfrom scratch on 31.5 billion tokens for 170 A100 hours using a context size of\n4096 on a mixed mathematical corpus consisting of web pages, source code,\ntextbooks, CoT templatised StackOverflow QA pairs, and mathematical lecture\nnotes in LaTeX curated by us. We also trained a math and code specialised BPE\ntokenizer. We proposed and performed CoT instruction fine-tuning of\nParamanu-Ganita on the MetaMathQA dataset. Our model Paramanu-Ganita, despite\nbeing 34 times smaller than the 7B LLMs, outperforms generalist LLMs by\napproximately 30% points, and even math-specialised LLMs by 3-23% points in\nGSM8K test accuracy metric. On MATH benchmark, Paramanu-Ganita outperformed the\nvarious models by 6-8% points. On benchmarks like LogiQA, MMLU (high school,\ncollege level), and competitive exams level, AGIEVAL (AQuA-RAT, SAT-Math),\nParamanu-Ganita outperformed others by 1-4%. Our model is available at\nhttps://huggingface.co/gyanai/paramanu-ganita-208M-hf .",
      "tldr_zh": "这篇论文探讨了小生成语言模型（SLMs）是否能通过领域特定预训练和Chain-of-Thought (CoT)指令微调，在数学推理上与大型语言模型（LLMs）竞争，同时评估这种方法的环保性和成本效率。研究者提出了Paramanu-Ganita，一个2.08亿参数的解码器-only SLM，通过从零预训练31.5亿tokens的混合数学语料库（如网页、代码、教科书和LaTeX笔记）以及专用BPE分词器，并使用MetaMathQA数据集进行CoT指令微调。尽管Paramanu-Ganita比7B LLMs小34倍，它在GSM8K基准上超过了通用LLMs约30%和专业数学LLMs 3-23%，在MATH基准上领先6-8%，并在LogiQA、MMLU和AGIEVAL等基准上表现出1-4%的优势。总的来说，该方法证明了小模型在数学推理中的潜力，同时更具可持续性和成本效益。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.14395v2",
      "published_date": "2024-04-22 17:55:56 UTC",
      "updated_date": "2025-03-05 18:17:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:29:10.121959"
    },
    {
      "arxiv_id": "2404.14394v2",
      "title": "A Multimodal Automated Interpretability Agent",
      "title_zh": "翻译失败",
      "authors": [
        "Tamar Rott Shaham",
        "Sarah Schwettmann",
        "Franklin Wang",
        "Achyuta Rajaram",
        "Evan Hernandez",
        "Jacob Andreas",
        "Antonio Torralba"
      ],
      "abstract": "This paper describes MAIA, a Multimodal Automated Interpretability Agent.\nMAIA is a system that uses neural models to automate neural model understanding\ntasks like feature interpretation and failure mode discovery. It equips a\npre-trained vision-language model with a set of tools that support iterative\nexperimentation on subcomponents of other models to explain their behavior.\nThese include tools commonly used by human interpretability researchers: for\nsynthesizing and editing inputs, computing maximally activating exemplars from\nreal-world datasets, and summarizing and describing experimental results.\nInterpretability experiments proposed by MAIA compose these tools to describe\nand explain system behavior. We evaluate applications of MAIA to computer\nvision models. We first characterize MAIA's ability to describe (neuron-level)\nfeatures in learned representations of images. Across several trained models\nand a novel dataset of synthetic vision neurons with paired ground-truth\ndescriptions, MAIA produces descriptions comparable to those generated by\nexpert human experimenters. We then show that MAIA can aid in two additional\ninterpretability tasks: reducing sensitivity to spurious features, and\nautomatically identifying inputs likely to be mis-classified.",
      "tldr_zh": "这篇论文介绍了 MAIA，一种多模态自动解释代理，用于自动化神经模型的理解任务，如 feature interpretation 和 failure mode discovery。MAIA 利用预训练的 vision-language model，并配备工具来合成和编辑输入、计算真实数据集中的最大激活样本，以及总结实验结果，从而支持对模型子组件的迭代实验解释系统行为。在评估中，MAIA 在计算机视觉模型上生成与专家人类相当的神经元级特征描述，并能辅助减少对无关特征的敏感性以及自动识别可能误分类的输入。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "25 pages, 13 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.14394v2",
      "published_date": "2024-04-22 17:55:11 UTC",
      "updated_date": "2025-02-11 19:35:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:29:19.265201"
    },
    {
      "arxiv_id": "2404.14387v2",
      "title": "A Survey on Self-Evolution of Large Language Models",
      "title_zh": "大型语言模型的自我进化综述",
      "authors": [
        "Zhengwei Tao",
        "Ting-En Lin",
        "Xiancai Chen",
        "Hangyu Li",
        "Yuchuan Wu",
        "Yongbin Li",
        "Zhi Jin",
        "Fei Huang",
        "Dacheng Tao",
        "Jingren Zhou"
      ],
      "abstract": "Large language models (LLMs) have significantly advanced in various fields\nand intelligent agent applications. However, current LLMs that learn from human\nor external model supervision are costly and may face performance ceilings as\ntask complexity and diversity increase. To address this issue, self-evolution\napproaches that enable LLM to autonomously acquire, refine, and learn from\nexperiences generated by the model itself are rapidly growing. This new\ntraining paradigm inspired by the human experiential learning process offers\nthe potential to scale LLMs towards superintelligence. In this work, we present\na comprehensive survey of self-evolution approaches in LLMs. We first propose a\nconceptual framework for self-evolution and outline the evolving process as\niterative cycles composed of four phases: experience acquisition, experience\nrefinement, updating, and evaluation. Second, we categorize the evolution\nobjectives of LLMs and LLM-based agents; then, we summarize the literature and\nprovide taxonomy and insights for each module. Lastly, we pinpoint existing\nchallenges and propose future directions to improve self-evolution frameworks,\nequipping researchers with critical insights to fast-track the development of\nself-evolving LLMs. Our corresponding GitHub repository is available at\nhttps://github.com/AlibabaResearch/DAMO-ConvAI/tree/main/Awesome-Self-Evolution-of-LLM",
      "tldr_zh": "这篇调查论文探讨了 Large Language Models (LLMs) 的 self-evolution 机制，以解决传统监督学习的高成本和性能上限问题。作者提出一个概念框架，将自我进化过程分为四个阶段：经验获取、经验精炼、更新和评估，并对 LLMs 和基于 LLMs 的代理的进化目标进行分类和总结。论文综述了相关文献，指出了现有挑战，并为未来 self-evolution 框架的改进提供了关键见解和方向。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.14387v2",
      "published_date": "2024-04-22 17:43:23 UTC",
      "updated_date": "2024-06-03 17:47:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:29:30.890443"
    },
    {
      "arxiv_id": "2404.14469v2",
      "title": "SnapKV: LLM Knows What You are Looking for Before Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Yuhong Li",
        "Yingbing Huang",
        "Bowen Yang",
        "Bharat Venkitesh",
        "Acyr Locatelli",
        "Hanchen Ye",
        "Tianle Cai",
        "Patrick Lewis",
        "Deming Chen"
      ],
      "abstract": "Large Language Models (LLMs) have made remarkable progress in processing\nextensive contexts, with the Key-Value (KV) cache playing a vital role in\nenhancing their performance. However, the growth of the KV cache in response to\nincreasing input length poses challenges to memory and time efficiency. To\naddress this problem, this paper introduces SnapKV, an innovative and\nfine-tuning-free approach that efficiently minimizes KV cache size while still\ndelivering comparable performance in real-world applications.\n  We discover that each attention head in the model consistently focuses on\nspecific prompt attention features during generation. Meanwhile, this robust\npattern can be obtained from an 'observation' window located at the end of the\nprompts. Drawing on this insight, SnapKV automatically compresses KV caches by\nselecting clustered important KV positions for each attention head. Our\napproach significantly reduces the growing computational overhead and memory\nfootprint when processing long input sequences. Specifically, SnapKV achieves a\nconsistent decoding speed with a 3.6x increase in generation speed and an 8.2x\nenhancement in memory efficiency compared to the baseline when processing\ninputs of 16K tokens. At the same time, it maintains comparable performance to\nthe baseline models across 16 long sequence datasets. Moreover, SnapKV can\nprocess up to 380K context tokens on a single A100-80GB GPU using HuggingFace\nimplementation with minor changes, exhibiting only a negligible accuracy drop\nin the Needle-in-a-Haystack test. Further comprehensive studies suggest\nSnapKV's potential for practical applications.",
      "tldr_zh": "这篇论文引入了 SnapKV，一种无需 fine-tuning 的创新方法，用于优化 Large Language Models (LLMs) 中的 Key-Value (KV) cache，从而解决长输入序列导致的内存和时间效率问题。SnapKV 通过分析每个 attention head 在提示末尾的“observation”窗口中一致关注的模式，自动选择并压缩关键 KV 位置。实验结果显示，在处理 16K tokens 的输入时，该方法将生成速度提高 3.6 倍，内存效率提升 8.2 倍，同时在 16 个长序列数据集上保持与基线模型相当的性能。此外，SnapKV 能在单个 A100-80GB GPU 上处理高达 380K 上下文 tokens，仅在 Needle-in-a-Haystack 测试中表现出微小的准确率下降，展示了其实际应用潜力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.14469v2",
      "published_date": "2024-04-22 17:42:58 UTC",
      "updated_date": "2024-06-17 03:01:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:29:44.405800"
    },
    {
      "arxiv_id": "2406.02560v3",
      "title": "Less Peaky and More Accurate CTC Forced Alignment by Label Priors",
      "title_zh": "翻译失败",
      "authors": [
        "Ruizhe Huang",
        "Xiaohui Zhang",
        "Zhaoheng Ni",
        "Li Sun",
        "Moto Hira",
        "Jeff Hwang",
        "Vimal Manohar",
        "Vineel Pratap",
        "Matthew Wiesner",
        "Shinji Watanabe",
        "Daniel Povey",
        "Sanjeev Khudanpur"
      ],
      "abstract": "Connectionist temporal classification (CTC) models are known to have peaky\noutput distributions. Such behavior is not a problem for automatic speech\nrecognition (ASR), but it can cause inaccurate forced alignments (FA),\nespecially at finer granularity, e.g., phoneme level. This paper aims at\nalleviating the peaky behavior for CTC and improve its suitability for forced\nalignment generation, by leveraging label priors, so that the scores of\nalignment paths containing fewer blanks are boosted and maximized during\ntraining. As a result, our CTC model produces less peaky posteriors and is able\nto more accurately predict the offset of the tokens besides their onset. It\noutperforms the standard CTC model and a heuristics-based approach for\nobtaining CTC's token offset timestamps by 12-40% in phoneme and word boundary\nerrors (PBE and WBE) measured on the Buckeye and TIMIT data. Compared with the\nmost widely used FA toolkit Montreal Forced Aligner (MFA), our method performs\nsimilarly on PBE/WBE on Buckeye, yet falls behind MFA on TIMIT. Nevertheless,\nour method has a much simpler training pipeline and better runtime efficiency.\nOur training recipe and pretrained model are released in TorchAudio.",
      "tldr_zh": "本研究针对Connectionist Temporal Classification (CTC) 模型的峰值输出分布（peaky output distributions）问题，提出了一种通过标签先验（label priors）的方法来改进CTC强制对齐（forced alignment）的准确性。该方法在训练过程中提升包含较少空白的对齐路径分数，从而使模型产生更少的峰值后验，并更精确地预测标记的起始（onset）和结束（offset）时间。在Buckeye和TIMIT数据集上，该模型在音素和单词边界错误（PBE和WBE）方面比标准CTC和启发式方法降低了12-40%，与Montreal Forced Aligner (MFA)相比性能相似或更高效，且训练流程更简单、运行效率更高。该工作已发布训练配方和预训练模型于TorchAudio。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "eess.AS",
      "comment": "Accepted by ICASSP 2024. Github repo:\n  https://github.com/huangruizhe/audio/tree/aligner_label_priors",
      "pdf_url": "http://arxiv.org/pdf/2406.02560v3",
      "published_date": "2024-04-22 17:40:08 UTC",
      "updated_date": "2024-07-18 18:28:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:29:56.220371"
    },
    {
      "arxiv_id": "2404.15166v2",
      "title": "Pixels and Predictions: Potential of GPT-4V in Meteorological Imagery Analysis and Forecast Communication",
      "title_zh": "像素与预测：GPT-4V 在气象图像分析和预测通信中的潜力",
      "authors": [
        "John R. Lawson",
        "Joseph E. Trujillo-Falcón",
        "David M. Schultz",
        "Montgomery L. Flora",
        "Kevin H. Goebbert",
        "Seth N. Lyman",
        "Corey K. Potvin",
        "Adam J. Stepanek"
      ],
      "abstract": "Generative AI, such as OpenAI's GPT-4V large-language model, has rapidly\nentered mainstream discourse. Novel capabilities in image processing and\nnatural-language communication may augment existing forecasting methods. Large\nlanguage models further display potential to better communicate weather hazards\nin a style honed for diverse communities and different languages. This study\nevaluates GPT-4V's ability to interpret meteorological charts and communicate\nweather hazards appropriately to the user, despite challenges of\nhallucinations, where generative AI delivers coherent, confident, but incorrect\nresponses. We assess GPT-4V's competence via its web interface ChatGPT in two\ntasks: (1) generating a severe-weather outlook from weather-chart analysis and\nconducting self-evaluation, revealing an outlook that corresponds well with a\nStorm Prediction Center human-issued forecast; and (2) producing hazard\nsummaries in Spanish and English from weather charts. Responses in Spanish,\nhowever, resemble direct (not idiomatic) translations from English to Spanish,\nyielding poorly translated summaries that lose critical idiomatic precision\nrequired for optimal communication. Our findings advocate for cautious\nintegration of tools like GPT-4V in meteorology, underscoring the necessity of\nhuman oversight and development of trustworthy, explainable AI.",
      "tldr_zh": "本研究评估了GPT-4V在气象图像分析和预测通信中的潜力，探讨其如何通过图像处理和自然语言能力增强天气预报方法，同时解决幻觉问题。研究通过ChatGPT界面进行两个任务：（1）从气象图表生成严重天气展望并自我评估，结果显示其展望与Storm Prediction Center的人类预测高度一致；（2）生成英语和西班牙语的天气危险摘要，但西班牙语版本为直接翻译，缺乏地道表达从而影响通信效果。总体发现表明，GPT-4V在气象应用中表现出色，但需注意翻译和准确性问题。该研究强调在气象学中谨慎整合此类AI工具，并呼吁加强人类监督和开发可信解释AI。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "physics.ao-ph"
      ],
      "primary_category": "cs.CL",
      "comment": "Supplementary material PDF attached. Submitted to Artificial\n  Intelligence for the Earth Systems (American Meteorological Society) on 18\n  April 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.15166v2",
      "published_date": "2024-04-22 17:36:33 UTC",
      "updated_date": "2024-09-07 10:19:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:30:06.815466"
    },
    {
      "arxiv_id": "2404.14372v1",
      "title": "Beyond Scaling: Predicting Patent Approval with Domain-specific Fine-grained Claim Dependency Graph",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaochen Kev Gao",
        "Feng Yao",
        "Kewen Zhao",
        "Beilei He",
        "Animesh Kumar",
        "Vish Krishnan",
        "Jingbo Shang"
      ],
      "abstract": "Model scaling is becoming the default choice for many language tasks due to\nthe success of large language models (LLMs). However, it can fall short in\nspecific scenarios where simple customized methods excel. In this paper, we\ndelve into the patent approval pre-diction task and unveil that simple\ndomain-specific graph methods outperform enlarging the model, using the\nintrinsic dependencies within the patent data. Specifically, we first extend\nthe embedding-based state-of-the-art (SOTA) by scaling up its backbone model\nwith various sizes of open-source LLMs, then explore prompt-based methods to\nharness proprietary LLMs' potential, but find the best results close to random\nguessing, underlining the ineffectiveness of model scaling-up. Hence, we\npropose a novel Fine-grained cLAim depeNdency (FLAN) Graph through meticulous\npatent data analyses, capturing the inherent dependencies across segments of\nthe patent text. As it is model-agnostic, we apply cost-effective graph models\nto our FLAN Graph to obtain representations for approval prediction. Extensive\nexperiments and detailed analyses prove that incorporating FLAN Graph via\nvarious graph models consistently outperforms all LLM baselines significantly.\nWe hope that our observations and analyses in this paper can bring more\nattention to this challenging task and prompt further research into the\nlimitations of LLMs. Our source code and dataset can be obtained from\nhttp://github.com/ShangDataLab/FLAN-Graph.",
      "tldr_zh": "本研究挑战了大规模语言模型（LLMs）的缩放策略，发现其在专利批准预测任务中效果有限，远不如定制的领域特定方法。作者提出Fine-grained cLAim depeNdency (FLAN) Graph，通过分析专利文本的细粒度依赖关系来捕获内在结构，并使用成本有效的图模型进行表示学习和预测。实验结果显示，FLAN Graph结合各种图模型显著优于所有LLM基线，提升了预测性能，并呼吁更多关注LLMs的局限性及其开源代码。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "17 Pages, Under Review",
      "pdf_url": "http://arxiv.org/pdf/2404.14372v1",
      "published_date": "2024-04-22 17:22:31 UTC",
      "updated_date": "2024-04-22 17:22:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:30:18.302894"
    },
    {
      "arxiv_id": "2404.14370v1",
      "title": "Assessing GPT-4-Vision's Capabilities in UML-Based Code Generation",
      "title_zh": "评估 GPT-4-Vision 在基于 UML 的代码生成中的能力",
      "authors": [
        "Gábor Antal",
        "Richárd Vozár",
        "Rudolf Ferenc"
      ],
      "abstract": "The emergence of advanced neural networks has opened up new ways in automated\ncode generation from conceptual models, promising to enhance software\ndevelopment processes. This paper presents a preliminary evaluation of\nGPT-4-Vision, a state-of-the-art deep learning model, and its capabilities in\ntransforming Unified Modeling Language (UML) class diagrams into fully\noperating Java class files. In our study, we used exported images of 18 class\ndiagrams comprising 10 single-class and 8 multi-class diagrams. We used 3\ndifferent prompts for each input, and we manually evaluated the results. We\ncreated a scoring system in which we scored the occurrence of elements found in\nthe diagram within the source code. On average, the model was able to generate\nsource code for 88% of the elements shown in the diagrams. Our results indicate\nthat GPT-4-Vision exhibits proficiency in handling single-class UML diagrams,\nsuccessfully transforming them into syntactically correct class files. However,\nfor multi-class UML diagrams, the model's performance is weaker compared to\nsingle-class diagrams. In summary, further investigations are necessary to\nexploit the model's potential completely.",
      "tldr_zh": "这篇论文评估了 GPT-4-Vision 在从 UML 类图生成 Java 代码方面的能力，旨在探索其在自动化软件开发中的潜力。研究团队使用 18 个 UML 类图（包括 10 个单类和 8 个多类图），并通过 3 种不同提示进行测试，然后采用手动评分系统评估代码生成准确性。结果显示，模型平均能正确生成 88% 的图中元素，在处理单类 UML 图时表现出色，能够产生语法正确的类文件，但对多类图的性能较弱。论文强调，需要进一步调查来充分发挥 GPT-4-Vision 的潜力。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.PL"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.14370v1",
      "published_date": "2024-04-22 17:21:24 UTC",
      "updated_date": "2024-04-22 17:21:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:30:30.719594"
    },
    {
      "arxiv_id": "2404.14368v1",
      "title": "Graphic Design with Large Multimodal Model",
      "title_zh": "基于大型多模态模型的图形设计",
      "authors": [
        "Yutao Cheng",
        "Zhao Zhang",
        "Maoke Yang",
        "Hui Nie",
        "Chunyuan Li",
        "Xinglong Wu",
        "Jie Shao"
      ],
      "abstract": "In the field of graphic design, automating the integration of design elements\ninto a cohesive multi-layered artwork not only boosts productivity but also\npaves the way for the democratization of graphic design. One existing practice\nis Graphic Layout Generation (GLG), which aims to layout sequential design\nelements. It has been constrained by the necessity for a predefined correct\nsequence of layers, thus limiting creative potential and increasing user\nworkload. In this paper, we present Hierarchical Layout Generation (HLG) as a\nmore flexible and pragmatic setup, which creates graphic composition from\nunordered sets of design elements. To tackle the HLG task, we introduce\nGraphist, the first layout generation model based on large multimodal models.\nGraphist efficiently reframes the HLG as a sequence generation problem,\nutilizing RGB-A images as input, outputs a JSON draft protocol, indicating the\ncoordinates, size, and order of each element. We develop new evaluation metrics\nfor HLG. Graphist outperforms prior arts and establishes a strong baseline for\nthis field. Project homepage: https://github.com/graphic-design-ai/graphist",
      "tldr_zh": "本论文探讨了利用大型多模态模型（Large Multimodal Model）提升图形设计自动化，提出 Hierarchical Layout Generation (HLG) 作为一种更灵活的方法，从无序的设计元素集合创建多层图形组合，以克服传统 Graphic Layout Generation (GLG) 的层序限制问题。Graphist 模型是首个基于大型多模态模型的布局生成系统，它将 HLG 转化为序列生成任务，使用 RGB-A 图像作为输入，输出 JSON 格式的草案，包括元素的坐标、大小和顺序。实验结果显示，Graphist 在新开发的 HLG 评价指标上超越了现有技术，并为该领域建立了强有力的基准。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.14368v1",
      "published_date": "2024-04-22 17:20:38 UTC",
      "updated_date": "2024-04-22 17:20:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:30:42.313886"
    },
    {
      "arxiv_id": "2404.14355v3",
      "title": "Pre-Calc: Learning to Use the Calculator Improves Numeracy in Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Vishruth Veerendranath",
        "Vishwa Shah",
        "Kshitish Ghate"
      ],
      "abstract": "Quantitative and numerical comprehension in language is an important task in\nmany fields like education and finance, but still remains a challenging task\nfor language models. While tool and calculator usage has shown to be helpful to\nimprove mathematical reasoning in large pretrained decoder-only language\nmodels, this remains unexplored for smaller language models with encoders. In\nthis paper, we propose Pre-Calc, a simple pre-finetuning objective of learning\nto use the calculator for both encoder-only and encoder-decoder architectures,\nformulated as a discriminative and generative task respectively. We pre-train\nBERT and RoBERTa for discriminative calculator use and Flan-T5 for generative\ncalculator use on the MAWPS, SVAMP, and AsDiv-A datasets, which improves\nperformance on downstream tasks that require numerical understanding. Our code\nand data are available at https://github.com/calc-cmu/pre-calc.",
      "tldr_zh": "本研究针对语言模型在定量和数字理解方面的挑战，提出 Pre-Calc 方法，通过学习使用计算器作为预微调目标，提升模型的数值能力。针对编码器-only 架构（如 BERT 和 RoBERTa），Pre-Calc 以判别式任务形式预训练；针对编码器-解码器架构（如 Flan-T5），则采用生成式任务。在 MAWPS、SVAMP 和 AsDiv-A 数据集上进行预训练后，模型在下游数值任务中的性能显著提升。代码和数据已公开在 GitHub 上。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "AI4Math workshop, ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.14355v3",
      "published_date": "2024-04-22 17:07:25 UTC",
      "updated_date": "2024-06-26 03:52:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:30:57.729974"
    },
    {
      "arxiv_id": "2404.14349v1",
      "title": "Automatic Discovery of Visual Circuits",
      "title_zh": "翻译失败",
      "authors": [
        "Achyuta Rajaram",
        "Neil Chowdhury",
        "Antonio Torralba",
        "Jacob Andreas",
        "Sarah Schwettmann"
      ],
      "abstract": "To date, most discoveries of network subcomponents that implement\nhuman-interpretable computations in deep vision models have involved close\nstudy of single units and large amounts of human labor. We explore scalable\nmethods for extracting the subgraph of a vision model's computational graph\nthat underlies recognition of a specific visual concept. We introduce a new\nmethod for identifying these subgraphs: specifying a visual concept using a few\nexamples, and then tracing the interdependence of neuron activations across\nlayers, or their functional connectivity. We find that our approach extracts\ncircuits that causally affect model output, and that editing these circuits can\ndefend large pretrained models from adversarial attacks.",
      "tldr_zh": "该论文提出了一种可扩展的方法，用于自动发现深度视觉模型中实现特定视觉概念识别的子图（visual circuits），以取代传统依赖大量人力和单个单元研究的做法。方法包括使用几个示例指定视觉概念，然后追踪神经元激活在层间的相互依赖（functional connectivity），从而提取模型计算图（computational graph）的相关子图。实验结果表明，这些子图能因果影响模型输出，且通过编辑这些子图，可以有效防御对抗性攻击（adversarial attacks）。这为更高效的模型解释和鲁棒性提升提供了新途径。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "14 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.14349v1",
      "published_date": "2024-04-22 17:00:57 UTC",
      "updated_date": "2024-04-22 17:00:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:31:07.649557"
    },
    {
      "arxiv_id": "2404.14467v1",
      "title": "Integrating Chemistry Knowledge in Large Language Models via Prompt Engineering",
      "title_zh": "通过提示工程在大语言模型中整合化学知识",
      "authors": [
        "Hongxuan Liu",
        "Haoyu Yin",
        "Zhiyao Luo",
        "Xiaonan Wang"
      ],
      "abstract": "This paper presents a study on the integration of domain-specific knowledge\nin prompt engineering to enhance the performance of large language models\n(LLMs) in scientific domains. A benchmark dataset is curated to encapsulate the\nintricate physical-chemical properties of small molecules, their drugability\nfor pharmacology, alongside the functional attributes of enzymes and crystal\nmaterials, underscoring the relevance and applicability across biological and\nchemical domains.The proposed domain-knowledge embedded prompt engineering\nmethod outperforms traditional prompt engineering strategies on various\nmetrics, including capability, accuracy, F1 score, and hallucination drop. The\neffectiveness of the method is demonstrated through case studies on complex\nmaterials including the MacMillan catalyst, paclitaxel, and lithium cobalt\noxide. The results suggest that domain-knowledge prompts can guide LLMs to\ngenerate more accurate and relevant responses, highlighting the potential of\nLLMs as powerful tools for scientific discovery and innovation when equipped\nwith domain-specific prompts. The study also discusses limitations and future\ndirections for domain-specific prompt engineering development.",
      "tldr_zh": "本研究探讨了通过提示工程（Prompt Engineering）将化学领域知识整合到大型语言模型（LLMs）中，以提升其在科学领域的表现。研究者创建了一个基准数据集，涵盖小分子的物理-化学性质、药用性（drugability）、酶和晶体材料的特性，并提出了一种嵌入领域知识的提示工程方法，该方法在能力、准确性、F1 score 和减少幻觉（hallucination）方面优于传统策略。通过对 MacMillan 催化剂、紫杉醇和钴酸锂等复杂材料的案例研究，证明了该方法的有效性，并强调了配备领域特定提示的 LLMs 在科学发现中的潜力，同时讨论了其局限性和未来发展方向。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "43 pages, 17 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.14467v1",
      "published_date": "2024-04-22 16:55:44 UTC",
      "updated_date": "2024-04-22 16:55:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:31:19.876702"
    },
    {
      "arxiv_id": "2404.14332v3",
      "title": "Full Event Particle-Level Unfolding with Variable-Length Latent Variational Diffusion",
      "title_zh": "翻译失败",
      "authors": [
        "Alexander Shmakov",
        "Kevin Greif",
        "Michael James Fenton",
        "Aishik Ghosh",
        "Pierre Baldi",
        "Daniel Whiteson"
      ],
      "abstract": "The measurements performed by particle physics experiments must account for\nthe imperfect response of the detectors used to observe the interactions. One\napproach, unfolding, statistically adjusts the experimental data for detector\neffects. Recently, generative machine learning models have shown promise for\nperforming unbinned unfolding in a high number of dimensions. However, all\ncurrent generative approaches are limited to unfolding a fixed set of\nobservables, making them unable to perform full-event unfolding in the variable\ndimensional environment of collider data. A novel modification to the\nvariational latent diffusion model (VLD) approach to generative unfolding is\npresented, which allows for unfolding of high- and variable-dimensional feature\nspaces. The performance of this method is evaluated in the context of\nsemi-leptonic top quark pair production at the Large Hadron Collider.",
      "tldr_zh": "该论文针对粒子物理实验中探测器不完美响应的问题，提出了一种改进的展开(unfolding)方法，以校正实验数据。研究引入了对变分潜在扩散模型(VLD)的修改，支持高维和可变维度的特征空间处理，从而实现全事件粒子级展开，避免了现有生成式机器学习模型限于固定观测变量的局限。实验在 Large Hadron Collider 的半轻子顶夸克对产生场景中评估了该方法的性能，展示了其在复杂环境中的潜力。",
      "categories": [
        "hep-ex",
        "cs.AI",
        "cs.LG",
        "hep-ph"
      ],
      "primary_category": "hep-ex",
      "comment": "Submission to SciPost",
      "pdf_url": "http://arxiv.org/pdf/2404.14332v3",
      "published_date": "2024-04-22 16:47:10 UTC",
      "updated_date": "2025-01-23 19:37:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:31:30.469721"
    },
    {
      "arxiv_id": "2404.14325v3",
      "title": "Adapting to time: Why nature may have evolved a diverse set of neurons",
      "title_zh": "翻译失败",
      "authors": [
        "Karim G. Habashy",
        "Benjamin D. Evans",
        "Dan F. M. Goodman",
        "Jeffrey S. Bowers"
      ],
      "abstract": "Brains have evolved diverse neurons with varying morphologies and dynamics\nthat impact temporal information processing. In contrast, most neural network\nmodels use homogeneous units that vary only in spatial parameters (weights and\nbiases). To explore the importance of temporal parameters, we trained spiking\nneural networks on tasks with varying temporal complexity, holding different\nparameter subsets constant. We found that adapting conduction delays is crucial\nfor solving all test conditions under tight resource constraints. Remarkably,\nthese tasks can be solved using only temporal parameters (delays and time\nconstants) with constant weights. In more complex spatio-temporal tasks, an\nadaptable bursting parameter was essential. Overall, allowing adaptation of\nboth temporal and spatial parameters enhances network robustness to noise, a\nvital feature for biological brains and neuromorphic computing systems. Our\nfindings suggest that rich and adaptable dynamics may be the key for solving\ntemporally structured tasks efficiently in evolving organisms, which would help\nexplain the diverse physiological properties of biological neurons.",
      "tldr_zh": "这篇论文探讨了大脑进化出多样化神经元的可能原因，强调这些神经元的形态和动态如何影响时间信息处理，而传统神经网络模型通常只依赖空间参数（如权重和偏差）。研究者通过训练spiking neural networks在不同时间复杂度的任务上，测试了保持参数子集不变的场景，发现适应conduction delays是解决这些任务的关键，尤其在资源受限条件下。结果显示，仅使用时间参数（如delays and time constants）即可完成任务，而在复杂时空任务中，adaptable bursting parameter变得必需；此外，允许时间和空间参数适应能显著提升网络对噪声的鲁棒性。该研究为解释生物神经元的多样生理特性提供了新见解，表明丰富的动态是高效处理时间结构任务的进化优势。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "q-bio.NC",
        "K.3.2; I.2.m"
      ],
      "primary_category": "cs.NE",
      "comment": "19 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.14325v3",
      "published_date": "2024-04-22 16:38:38 UTC",
      "updated_date": "2025-01-12 05:36:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:31:45.427741"
    },
    {
      "arxiv_id": "2405.05140v1",
      "title": "Distributed Learning for Wi-Fi AP Load Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Dariush Salami",
        "Francesc Wilhelmi",
        "Lorenzo Galati-Giordano",
        "Mika Kasslin"
      ],
      "abstract": "The increasing cloudification and softwarization of networks foster the\ninterplay among multiple independently managed deployments. An appealing reason\nfor such an interplay lies in distributed Machine Learning (ML), which allows\nthe creation of robust ML models by leveraging collective intelligence and\ncomputational power. In this paper, we study the application of the two\ncornerstones of distributed learning, namely Federated Learning (FL) and\nKnowledge Distillation (KD), on the Wi-Fi Access Point (AP) load prediction use\ncase. The analysis conducted in this paper is done on a dataset that contains\nreal measurements from a large Wi-Fi campus network, which we use to train the\nML model under study based on different strategies. Performance evaluation\nincludes relevant aspects for the suitability of distributed learning operation\nin real use cases, including the predictive performance, the associated\ncommunication overheads, or the energy consumption. In particular, we prove\nthat distributed learning can improve the predictive accuracy centralized ML\nsolutions by up to 93% while reducing the communication overheads and the\nenergy cost by 80%.",
      "tldr_zh": "本研究探讨了在 Wi-Fi Access Point (AP) 负载预测中应用分布式机器学习 (ML) 的方法，特别是 Federated Learning (FL) 和 Knowledge Distillation (KD)，以利用多个独立部署的网络资源。研究使用真实 Wi-Fi 校园网络数据集训练 ML 模型，并比较了分布式学习与集中式 ML 的不同策略。结果显示，分布式学习可将预测准确性提高最多 93%，同时将通信开销和能源消耗降低 80%，证明其在实际场景中的高效性。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.05140v1",
      "published_date": "2024-04-22 16:37:35 UTC",
      "updated_date": "2024-04-22 16:37:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:31:54.797370"
    },
    {
      "arxiv_id": "2404.15153v2",
      "title": "Performance Characterization of Expert Router for Scalable LLM Inference",
      "title_zh": "Expert Router 用于可扩展 LLM 推理的性能表征",
      "authors": [
        "Josef Pichlmeier",
        "Philipp Ross",
        "Andre Luckow"
      ],
      "abstract": "Large Language Models (LLMs) have experienced widespread adoption across\nscientific and industrial domains due to their versatility and utility for\ndiverse tasks. Nevertheless, deploying and serving these models at scale with\noptimal throughput and latency remains a significant challenge, primarily\nbecause of LLMs' high computational and memory demands. Specialized models\noptimized for specific tasks can be combined through a routing mechanism to\naddress these challenges, creating a modular inference system. This paper\nintroduces Expert Router, a scalable routing architecture that directs prompts\nto specialized expert models. We characterize multiple Expert Router\nconfigurations, including different LLama 3 models with quantized and\nnon-quantized weights under up to 1,000 concurrent users. Our findings reveal\nthat Expert Router introduces minimal latency overhead, with the configuration\nof expert models being a dominating factor in performance outcomes.\nHigh-parameter expert models deliver stable throughput and latency under\nmoderate concurrency levels. In contrast, smaller expert models maintain\ncompetitive performance across a wider range of concurrent users compared to\ntensor-parallelized baseline models. This highlights the potential of Expert\nRouter for efficient and scalable LLM deployment.",
      "tldr_zh": "这篇论文介绍了 Expert Router，一种可扩展的路由架构，用于优化大型语言模型 (LLMs) 的推理性能，通过将提示路由到专门优化的专家模型来解决高计算和内存需求的部署挑战。我们评估了多种配置，包括量化与非量化的 Llama 3 模型，在高达 1,000 并发用户环境下进行测试。结果显示，Expert Router 引入的延迟开销最小，高参数专家模型在中等并发下提供稳定吞吐量和延迟，而较小专家模型在高并发场景下表现出色。总体而言，这为高效、可扩展的 LLM 部署提供了重要潜力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.PF"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.15153v2",
      "published_date": "2024-04-22 16:33:42 UTC",
      "updated_date": "2024-10-08 12:41:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:32:08.286142"
    },
    {
      "arxiv_id": "2404.14304v2",
      "title": "Explaining Arguments' Strength: Unveiling the Role of Attacks and Supports (Technical Report)",
      "title_zh": "翻译失败",
      "authors": [
        "Xiang Yin",
        "Potyka Nico",
        "Francesca Toni"
      ],
      "abstract": "Quantitatively explaining the strength of arguments under gradual semantics\nhas recently received increasing attention. Specifically, several works in the\nliterature provide quantitative explanations by computing the attribution\nscores of arguments. These works disregard the importance of attacks and\nsupports, even though they play an essential role when explaining arguments'\nstrength. In this paper, we propose a novel theory of Relation Attribution\nExplanations (RAEs), adapting Shapley values from game theory to offer\nfine-grained insights into the role of attacks and supports in quantitative\nbipolar argumentation towards obtaining the arguments' strength. We show that\nRAEs satisfy several desirable properties. We also propose a probabilistic\nalgorithm to approximate RAEs efficiently. Finally, we show the application\nvalue of RAEs in fraud detection and large language models case studies.",
      "tldr_zh": "该论文提出了一种新的理论Relation Attribution Explanations (RAEs)，通过适应博弈论中的Shapley values，定量解释论点强度时细粒度分析攻击和支持在双极论辩中的作用，以弥补现有方法的不足。RAEs满足多个理想属性，如公平性和可解释性，并通过一个高效的概率算法进行近似计算。最终，论文展示了RAEs在欺诈检测和大型语言模型案例中的实际应用价值。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "This paper has been accepted at IJCAI 2024 (the 33rd International\n  Joint Conference on Artificial Intelligence)",
      "pdf_url": "http://arxiv.org/pdf/2404.14304v2",
      "published_date": "2024-04-22 16:02:48 UTC",
      "updated_date": "2024-05-10 17:37:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:32:18.819691"
    },
    {
      "arxiv_id": "2404.14296v2",
      "title": "Does Your Neural Code Completion Model Use My Code? A Membership Inference Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Yao Wan",
        "Guanghua Wan",
        "Shijie Zhang",
        "Hongyu Zhang",
        "Pan Zhou",
        "Hai Jin",
        "Lichao Sun"
      ],
      "abstract": "Recent years have witnessed significant progress in developing deep\nlearning-based models for automated code completion. Although using source code\nin GitHub has been a common practice for training deep-learning-based models\nfor code completion, it may induce some legal and ethical issues such as\ncopyright infringement. In this paper, we investigate the legal and ethical\nissues of current neural code completion models by answering the following\nquestion: Is my code used to train your neural code completion model? To this\nend, we tailor a membership inference approach (termed CodeMI) that was\noriginally crafted for classification tasks to a more challenging task of code\ncompletion. In particular, since the target code completion models perform as\nopaque black boxes, preventing access to their training data and parameters, we\nopt to train multiple shadow models to mimic their behavior. The acquired\nposteriors from these shadow models are subsequently employed to train a\nmembership classifier. Subsequently, the membership classifier can be\neffectively employed to deduce the membership status of a given code sample\nbased on the output of a target code completion model. We comprehensively\nevaluate the effectiveness of this adapted approach across a diverse array of\nneural code completion models, (i.e., LSTM-based, CodeGPT, CodeGen, and\nStarCoder). Experimental results reveal that the LSTM-based and CodeGPT models\nsuffer the membership leakage issue, which can be easily detected by our\nproposed membership inference approach with an accuracy of 0.842, and 0.730,\nrespectively. Interestingly, our experiments also show that the data membership\nof current large language models of code, e.g., CodeGen and StarCoder, is\ndifficult to detect, leaving ampler space for further improvement. Finally, we\nalso try to explain the findings from the perspective of model memorization.",
      "tldr_zh": "本文研究了神经代码补全模型是否使用了特定代码的问题，提出了一种名为 CodeMI 的成员推断方法，以检测版权侵权风险。方法通过训练多个影子模型（shadow models）模仿目标模型的行为，并基于这些模型的输出训练成员分类器，从而推断给定代码样本的成员状态。实验结果显示，在 LSTM-based 和 CodeGPT 模型上，检测准确率分别为 0.842 和 0.730，表明这些模型存在成员泄露问题，而 CodeGen 和 StarCoder 等大型语言模型的泄露较难检测。该研究从模型记忆角度解释了这些发现，并强调了代码训练中的法律和道德挑战。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.14296v2",
      "published_date": "2024-04-22 15:54:53 UTC",
      "updated_date": "2024-09-07 13:59:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:32:32.749758"
    },
    {
      "arxiv_id": "2404.14294v3",
      "title": "A Survey on Efficient Inference for Large Language Models",
      "title_zh": "大型",
      "authors": [
        "Zixuan Zhou",
        "Xuefei Ning",
        "Ke Hong",
        "Tianyu Fu",
        "Jiaming Xu",
        "Shiyao Li",
        "Yuming Lou",
        "Luning Wang",
        "Zhihang Yuan",
        "Xiuhong Li",
        "Shengen Yan",
        "Guohao Dai",
        "Xiao-Ping Zhang",
        "Yuhan Dong",
        "Yu Wang"
      ],
      "abstract": "Large Language Models (LLMs) have attracted extensive attention due to their\nremarkable performance across various tasks. However, the substantial\ncomputational and memory requirements of LLM inference pose challenges for\ndeployment in resource-constrained scenarios. Efforts within the field have\nbeen directed towards developing techniques aimed at enhancing the efficiency\nof LLM inference. This paper presents a comprehensive survey of the existing\nliterature on efficient LLM inference. We start by analyzing the primary causes\nof the inefficient LLM inference, i.e., the large model size, the\nquadratic-complexity attention operation, and the auto-regressive decoding\napproach. Then, we introduce a comprehensive taxonomy that organizes the\ncurrent literature into data-level, model-level, and system-level optimization.\nMoreover, the paper includes comparative experiments on representative methods\nwithin critical sub-fields to provide quantitative insights. Last but not\nleast, we provide some knowledge summary and discuss future research\ndirections.",
      "tldr_zh": "这篇论文对 Large Language Models (LLMs) 的高效推理进行了全面调查，针对其在资源受限场景中的计算和内存需求挑战。论文首先分析了推理效率低的主要原因，包括大模型尺寸、二次复杂度的 attention 操作以及自回归解码方法。随后，它引入了一个分类法，将现有优化技术分为数据级、模型级和系统级，并通过比较实验提供了定量洞见。最后，论文总结了关键知识并讨论了未来研究方向，以推动 LLM 推理的实际部署。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.14294v3",
      "published_date": "2024-04-22 15:53:08 UTC",
      "updated_date": "2024-07-19 04:47:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:32:44.248013"
    },
    {
      "arxiv_id": "2404.14285v3",
      "title": "LLM-Personalize: Aligning LLM Planners with Human Preferences via Reinforced Self-Training for Housekeeping Robots",
      "title_zh": "LLM-Personalize：通过强化自训练将 LLM 规划器与人类偏好",
      "authors": [
        "Dongge Han",
        "Trevor McInroe",
        "Adam Jelley",
        "Stefano V. Albrecht",
        "Peter Bell",
        "Amos Storkey"
      ],
      "abstract": "Large language models (LLMs) have shown significant potential for robotics\napplications, particularly task planning, by harnessing their language\ncomprehension and text generation capabilities. However, in applications such\nas household robotics, a critical gap remains in the personalization of these\nmodels to individual user preferences. We introduce LLM-Personalize, a novel\nframework with an optimization pipeline designed to personalize LLM planners\nfor household robotics. Our LLM-Personalize framework features an LLM planner\nthat performs iterative planning in multi-room, partially-observable household\nscenarios, making use of a scene graph constructed with local observations. The\ngenerated plan consists of a sequence of high-level actions which are\nsubsequently executed by a controller. Central to our approach is the\noptimization pipeline, which combines imitation learning and iterative\nself-training to personalize the LLM planner. In particular, the imitation\nlearning phase performs initial LLM alignment from demonstrations, and\nbootstraps the model to facilitate effective iterative self-training, which\nfurther explores and aligns the model to user preferences. We evaluate\nLLM-Personalize on Housekeep, a challenging simulated real-world 3D benchmark\nfor household rearrangements, and show that LLM-Personalize achieves more than\na 30 percent increase in success rate over existing LLM planners, showcasing\nsignificantly improved alignment with human preferences. Project page:\nhttps://gdg94.github.io/projectllmpersonalize/.",
      "tldr_zh": "该研究提出 LLM-Personalize 框架，通过强化自训练方法，将大型语言模型 (LLMs) 规划器与人类偏好对齐，应用于家务机器人任务规划。该框架包括一个 LLM 规划器，利用场景图 (scene graph) 在多房间、部分可观察的环境中进行迭代规划，并结合模仿学习 (imitation learning) 进行初始对齐，随后通过迭代自训练 (iterative self-training) 进一步探索和优化用户偏好。在 Housekeep 模拟基准测试中，该框架成功率比现有 LLM 规划器提高了 30% 以上，展示了显著的个性化性能提升。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "COLING 2025",
      "pdf_url": "http://arxiv.org/pdf/2404.14285v3",
      "published_date": "2024-04-22 15:35:33 UTC",
      "updated_date": "2024-12-30 01:41:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:32:58.438545"
    },
    {
      "arxiv_id": "2404.14244v3",
      "title": "AI-Generated Faces in the Real World: A Large-Scale Case Study of Twitter Profile Images",
      "title_zh": "现实世界中的 AI 生成人脸：Twitter 个人资料图像的大规模案例研究",
      "authors": [
        "Jonas Ricker",
        "Dennis Assenmacher",
        "Thorsten Holz",
        "Asja Fischer",
        "Erwin Quiring"
      ],
      "abstract": "Recent advances in the field of generative artificial intelligence (AI) have\nblurred the lines between authentic and machine-generated content, making it\nalmost impossible for humans to distinguish between such media. One notable\nconsequence is the use of AI-generated images for fake profiles on social\nmedia. While several types of disinformation campaigns and similar incidents\nhave been reported in the past, a systematic analysis has been lacking. In this\nwork, we conduct the first large-scale investigation of the prevalence of\nAI-generated profile pictures on Twitter. We tackle the challenges of a\nreal-world measurement study by carefully integrating various data sources and\ndesigning a multi-stage detection pipeline. Our analysis of nearly 15 million\nTwitter profile pictures shows that 0.052% were artificially generated,\nconfirming their notable presence on the platform. We comprehensively examine\nthe characteristics of these accounts and their tweet content, and uncover\npatterns of coordinated inauthentic behavior. The results also reveal several\nmotives, including spamming and political amplification campaigns. Our research\nreaffirms the need for effective detection and mitigation strategies to cope\nwith the potential negative effects of generative AI in the future.",
      "tldr_zh": "这篇论文首次进行大规模实证研究，调查Twitter平台上AI-generated profile pictures的 prevalence，揭示了生成式AI在社交媒体中制造假账户的潜在问题。通过整合多种数据来源并设计多阶段检测管道，分析了近1500万Twitter头像，发现0.052%是AI-generated的。研究进一步揭示了这些账户的特征、推文内容以及协调inauthentic行为模式，包括spamming和政治amplification campaigns等动机。最终，论文强调了开发有效detection和mitigation策略的必要性，以应对生成AI的负面影响。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CY",
        "cs.LG",
        "cs.SI"
      ],
      "primary_category": "cs.CR",
      "comment": "International Symposium on Research in Attacks, Intrusions and\n  Defenses (RAID), 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.14244v3",
      "published_date": "2024-04-22 14:57:17 UTC",
      "updated_date": "2024-10-03 08:22:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:33:09.698987"
    },
    {
      "arxiv_id": "2404.14243v1",
      "title": "Turbo-CF: Matrix Decomposition-Free Graph Filtering for Fast Recommendation",
      "title_zh": "翻译失败",
      "authors": [
        "Jin-Duk Park",
        "Yong-Min Shin",
        "Won-Yong Shin"
      ],
      "abstract": "A series of graph filtering (GF)-based collaborative filtering (CF) showcases\nstate-of-the-art performance on the recommendation accuracy by using a low-pass\nfilter (LPF) without a training process. However, conventional GF-based CF\napproaches mostly perform matrix decomposition on the item-item similarity\ngraph to realize the ideal LPF, which results in a non-trivial computational\ncost and thus makes them less practical in scenarios where rapid\nrecommendations are essential. In this paper, we propose Turbo-CF, a GF-based\nCF method that is both training-free and matrix decomposition-free. Turbo-CF\nemploys a polynomial graph filter to circumvent the issue of expensive matrix\ndecompositions, enabling us to make full use of modern computer hardware\ncomponents (i.e., GPU). Specifically, Turbo-CF first constructs an item-item\nsimilarity graph whose edge weights are effectively regulated. Then, our own\npolynomial LPFs are designed to retain only low-frequency signals without\nexplicit matrix decompositions. We demonstrate that Turbo-CF is extremely fast\nyet accurate, achieving a runtime of less than 1 second on real-world benchmark\ndatasets while achieving recommendation accuracies comparable to best\ncompetitors.",
      "tldr_zh": "该论文提出 Turbo-CF，一种基于 Graph Filtering (GF) 的协同过滤 (CF) 方法，旨在解决传统方法依赖矩阵分解导致计算成本高的问题，从而实现快速推荐。Turbo-CF 采用多项式图过滤器构建物品-物品相似性图，并设计专有的多项式 Low-Pass Filter (LPF) 来保留低频信号，而无需训练或矩阵分解，利用 GPU 进行高效计算。实验结果显示，Turbo-CF 在真实基准数据集上运行时间不到 1 秒，同时推荐准确率与最先进竞争者相当。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.IT",
        "cs.LG",
        "cs.SI",
        "math.IT"
      ],
      "primary_category": "cs.IR",
      "comment": "5 pages, 4 figures, 4 tables; 47th International ACM SIGIR Conference\n  on Research and Development in Information Retrieval (SIGIR 2024) (to appear)\n  (Please cite our conference version.)",
      "pdf_url": "http://arxiv.org/pdf/2404.14243v1",
      "published_date": "2024-04-22 14:56:36 UTC",
      "updated_date": "2024-04-22 14:56:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:33:23.648847"
    },
    {
      "arxiv_id": "2404.14241v1",
      "title": "UrbanCross: Enhancing Satellite Image-Text Retrieval with Cross-Domain Adaptation",
      "title_zh": "UrbanCross：利用跨域适应增强卫星图像-文本检索",
      "authors": [
        "Siru Zhong",
        "Xixuan Hao",
        "Yibo Yan",
        "Ying Zhang",
        "Yangqiu Song",
        "Yuxuan Liang"
      ],
      "abstract": "Urbanization challenges underscore the necessity for effective satellite\nimage-text retrieval methods to swiftly access specific information enriched\nwith geographic semantics for urban applications. However, existing methods\noften overlook significant domain gaps across diverse urban landscapes,\nprimarily focusing on enhancing retrieval performance within single domains. To\ntackle this issue, we present UrbanCross, a new framework for cross-domain\nsatellite image-text retrieval. UrbanCross leverages a high-quality,\ncross-domain dataset enriched with extensive geo-tags from three countries to\nhighlight domain diversity. It employs the Large Multimodal Model (LMM) for\ntextual refinement and the Segment Anything Model (SAM) for visual\naugmentation, achieving a fine-grained alignment of images, segments and texts,\nyielding a 10% improvement in retrieval performance. Additionally, UrbanCross\nincorporates an adaptive curriculum-based source sampler and a weighted\nadversarial cross-domain fine-tuning module, progressively enhancing\nadaptability across various domains. Extensive experiments confirm UrbanCross's\nsuperior efficiency in retrieval and adaptation to new urban environments,\ndemonstrating an average performance increase of 15% over its version without\ndomain adaptation mechanisms, effectively bridging the domain gap.",
      "tldr_zh": "该研究提出UrbanCross框架，通过跨域适应技术增强卫星图像-文本检索，以应对城市化应用中存在的域差距问题。UrbanCross利用Large Multimodal Model (LMM)进行文本精炼、Segment Anything Model (SAM)进行视觉增强，并结合自适应课程-based源采样器和加权对抗跨域微调模块，实现图像、段和文本的细粒度对齐。实验结果显示，该框架在检索性能上提高了10%，并在跨域适应方面平均提升15%，有效桥接了不同城市环境的域差距。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.14241v1",
      "published_date": "2024-04-22 14:53:27 UTC",
      "updated_date": "2024-04-22 14:53:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:33:35.174837"
    },
    {
      "arxiv_id": "2404.14240v1",
      "title": "Collaborative Filtering Based on Diffusion Models: Unveiling the Potential of High-Order Connectivity",
      "title_zh": "基于扩散模型的协作过滤：揭示高阶连通性的潜力",
      "authors": [
        "Yu Hou",
        "Jin-Duk Park",
        "Won-Yong Shin"
      ],
      "abstract": "A recent study has shown that diffusion models are well-suited for modeling\nthe generative process of user-item interactions in recommender systems due to\ntheir denoising nature. However, existing diffusion model-based recommender\nsystems do not explicitly leverage high-order connectivities that contain\ncrucial collaborative signals for accurate recommendations. Addressing this\ngap, we propose CF-Diff, a new diffusion model-based collaborative filtering\n(CF) method, which is capable of making full use of collaborative signals along\nwith multi-hop neighbors. Specifically, the forward-diffusion process adds\nrandom noise to user-item interactions, while the reverse-denoising process\naccommodates our own learning model, named cross-attention-guided multi-hop\nautoencoder (CAM-AE), to gradually recover the original user-item interactions.\nCAM-AE consists of two core modules: 1) the attention-aided AE module,\nresponsible for precisely learning latent representations of user-item\ninteractions while preserving the model's complexity at manageable levels, and\n2) the multi-hop cross-attention module, which judiciously harnesses high-order\nconnectivity information to capture enhanced collaborative signals. Through\ncomprehensive experiments on three real-world datasets, we demonstrate that\nCF-Diff is (a) Superior: outperforming benchmark recommendation methods,\nachieving remarkable gains up to 7.29% compared to the best competitor, (b)\nTheoretically-validated: reducing computations while ensuring that the\nembeddings generated by our model closely approximate those from the original\ncross-attention, and (c) Scalable: proving the computational efficiency that\nscales linearly with the number of users or items.",
      "tldr_zh": "本研究提出了一种新的协作过滤方法 CF-Diff，基于 diffusion models，利用高阶连接性（high-order connectivity）来提升推荐系统的准确性。该方法通过 forward-diffusion 过程添加噪声，并采用 reverse-denoising 过程结合 cross-attention-guided multi-hop autoencoder (CAM-AE) 模块，包括 attention-aided AE 模块用于学习用户-物品交互的潜在表示，以及 multi-hop cross-attention 模块来捕获增强的协作信号。在三个真实数据集上的实验表明，CF-Diff 比基准方法提升高达 7.29%，同时在计算效率和理论验证方面表现出色，确保嵌入表示接近原始 cross-attention 并实现线性可扩展。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.IT",
        "cs.LG",
        "cs.SI",
        "math.IT"
      ],
      "primary_category": "cs.IR",
      "comment": "10 pages, 6 figures, 4 tables; 47th International ACM SIGIR\n  Conference on Research and Development in Information Retrieval (SIGIR 2024)\n  (to appear) (Please cite our conference version.)",
      "pdf_url": "http://arxiv.org/pdf/2404.14240v1",
      "published_date": "2024-04-22 14:49:46 UTC",
      "updated_date": "2024-04-22 14:49:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:33:45.955962"
    },
    {
      "arxiv_id": "2404.14238v1",
      "title": "Beyond the Edge: An Advanced Exploration of Reinforcement Learning for Mobile Edge Computing, its Applications, and Future Research Trajectories",
      "title_zh": "翻译失败",
      "authors": [
        "Ning Yang",
        "Shuo Chen",
        "Haijun Zhang",
        "Randall Berry"
      ],
      "abstract": "Mobile Edge Computing (MEC) broadens the scope of computation and storage\nbeyond the central network, incorporating edge nodes close to end devices. This\nexpansion facilitates the implementation of large-scale \"connected things\"\nwithin edge networks. The advent of applications necessitating real-time,\nhigh-quality service presents several challenges, such as low latency, high\ndata rate, reliability, efficiency, and security, all of which demand\nresolution. The incorporation of reinforcement learning (RL) methodologies\nwithin MEC networks promotes a deeper understanding of mobile user behaviors\nand network dynamics, thereby optimizing resource use in computing and\ncommunication processes. This paper offers an exhaustive survey of RL\napplications in MEC networks, initially presenting an overview of RL from its\nfundamental principles to the latest advanced frameworks. Furthermore, it\noutlines various RL strategies employed in offloading, caching, and\ncommunication within MEC networks. Finally, it explores open issues linked with\nsoftware and hardware platforms, representation, RL robustness, safe RL,\nlarge-scale scheduling, generalization, security, and privacy. The paper\nproposes specific RL techniques to mitigate these issues and provides insights\ninto their practical applications.",
      "tldr_zh": "本论文探讨了强化学习(Reinforcement Learning, RL)在移动边缘计算(Mobile Edge Computing, MEC)中的高级应用，旨在解决实时应用面临的挑战，如低延迟、高数据率和安全性问题。论文首先概述了RL从基础原理到高级框架的发展，并总结了RL在MEC网络中的策略，包括任务卸载、缓存和通信优化，以提升资源利用和网络效率。最终，它识别了关键开放问题，如RL鲁棒性、安全RL、大规模调度和隐私保护，并提出具体RL技术来应对这些挑战，同时提供实际应用见解和未来研究方向。",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "The paper is accepted by IEEE Communications Surveys and Tutorials\n  (COMST)",
      "pdf_url": "http://arxiv.org/pdf/2404.14238v1",
      "published_date": "2024-04-22 14:47:42 UTC",
      "updated_date": "2024-04-22 14:47:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:33:57.554292"
    },
    {
      "arxiv_id": "2404.14233v2",
      "title": "Detecting and Mitigating Hallucination in Large Vision Language Models via Fine-Grained AI Feedback",
      "title_zh": "通过细粒度的 AI 反馈检测和缓解大型视觉语言模型中的幻觉",
      "authors": [
        "Wenyi Xiao",
        "Ziwei Huang",
        "Leilei Gan",
        "Wanggui He",
        "Haoyuan Li",
        "Zhelun Yu",
        "Fangxun Shu",
        "Hao Jiang",
        "Linchao Zhu"
      ],
      "abstract": "The rapidly developing Large Vision Language Models (LVLMs) have shown\nnotable capabilities on a range of multi-modal tasks, but still face the\nhallucination phenomena where the generated texts do not align with the given\ncontexts, significantly restricting the usages of LVLMs. Most previous work\ndetects and mitigates hallucination at the coarse-grained level or requires\nexpensive annotation (e.g., labeling by proprietary models or human experts).\nTo address these issues, we propose detecting and mitigating hallucinations in\nLVLMs via fine-grained AI feedback. The basic idea is that we generate a\nsmall-size sentence-level hallucination annotation dataset by proprietary\nmodels, whereby we train a hallucination detection model which can perform\nsentence-level hallucination detection, covering primary hallucination types\n(i.e., object, attribute, and relationship). Then, we propose a\ndetect-then-rewrite pipeline to automatically construct preference dataset for\ntraining hallucination mitigating model. Furthermore, we propose\ndifferentiating the severity of hallucinations, and introducing a Hallucination\nSeverity-Aware Direct Preference Optimization (HSA-DPO) for mitigating\nhallucination in LVLMs by incorporating the severity of hallucinations into\npreference learning. Extensive experiments demonstrate the effectiveness of our\nmethod.",
      "tldr_zh": "本研究针对 Large Vision Language Models (LVLMs) 中的 hallucination 问题，提出了一种基于细粒度 AI 反馈的检测和缓解方法，以解决现有粗粒度方法和昂贵标注的局限性。研究首先使用专有模型生成小型句子级 hallucination 标注数据集，并训练一个覆盖 object, attribute, and relationship 等主要类型的句子级检测模型。接着，通过 detect-then-rewrite 管道自动构建偏好数据集，并引入 Hallucination Severity-Aware Direct Preference Optimization (HSA-DPO) 方法，将 hallucination 的严重程度纳入偏好学习，以优化模型的缓解效果。实验结果显示，该方法在多个场景下有效提高了 LVLMs 的准确性和可靠性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "repo: https://github.com/Mr-Loevan/HSA-DPO",
      "pdf_url": "http://arxiv.org/pdf/2404.14233v2",
      "published_date": "2024-04-22 14:46:10 UTC",
      "updated_date": "2025-01-06 13:58:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:34:09.949273"
    },
    {
      "arxiv_id": "2404.14232v3",
      "title": "Shifting Focus with HCEye: Exploring the Dynamics of Visual Highlighting and Cognitive Load on User Attention and Saliency Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Anwesha Das",
        "Zekun Wu",
        "Iza Škrjanec",
        "Anna Maria Feit"
      ],
      "abstract": "Visual highlighting can guide user attention in complex interfaces. However,\nits effectiveness under limited attentional capacities is underexplored. This\npaper examines the joint impact of visual highlighting (permanent and dynamic)\nand dual-task-induced cognitive load on gaze behaviour. Our analysis, using\neye-movement data from 27 participants viewing 150 unique webpages reveals that\nwhile participants' ability to attend to UI elements decreases with increasing\ncognitive load, dynamic adaptations (i.e., highlighting) remain\nattention-grabbing. The presence of these factors significantly alters what\npeople attend to and thus what is salient. Accordingly, we show that\nstate-of-the-art saliency models increase their performance when accounting for\ndifferent cognitive loads. Our empirical insights, along with our openly\navailable dataset, enhance our understanding of attentional processes in UIs\nunder varying cognitive (and perceptual) loads and open the door for new models\nthat can predict user attention while multitasking.",
      "tldr_zh": "这篇论文探讨了视觉突出(visual highlighting，包括永久和动态类型)与认知负荷(cognitive load)对用户注意力和显著性预测(saliency prediction)的动态影响，通过分析27名参与者在150个独特网页上的眼动数据(gaze behaviour)。研究发现，随着认知负荷增加，用户关注UI元素的能力下降，但动态突出仍能有效吸引注意力，并显著改变人们的关注点和显著性。结果显示，考虑不同认知负荷的先进显著性模型性能提升，同时论文提供了开源数据集，以深化对注意力过程的理解并推动新模型开发。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "H.1.2"
      ],
      "primary_category": "cs.HC",
      "comment": "18 pages, 9 Figures, Conference: ACM Symposium on Eye Tracking\n  Research & Applications (ETRA); Journal: Proc. ACM Hum.-Comput. Interact.,\n  Vol. 8, No. ETRA, Article 236. Publication date: May 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.14232v3",
      "published_date": "2024-04-22 14:45:30 UTC",
      "updated_date": "2024-05-02 09:06:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:34:20.860544"
    },
    {
      "arxiv_id": "2405.06659v2",
      "title": "ControlMol: Adding Substructure Control To Molecule Diffusion Models",
      "title_zh": "ControlMol: 向分子扩散模型添加子结构控制",
      "authors": [
        "Qi Zhengyang",
        "Liu Zijing",
        "Zhang Jiying",
        "Cao He",
        "Li Yu"
      ],
      "abstract": "Due to the vast design space of molecules, generating molecules conditioned\non a specific sub-structure relevant to a particular function or therapeutic\ntarget is a crucial task in computer-aided drug design. Existing works mainly\nfocus on specific tasks, such as linker design or scaffold hopping, each task\nrequires training a model from scratch, and many well-pretrained De Novo\nmolecule generation model parameters are not effectively utilized. To this end,\nwe propose a two-stage training approach, consisting of condition learning and\ncondition optimization. In the condition learning stage, we adopt the idea of\nControlNet and design some meaningful adjustments to make the unconditional\ngenerative model learn sub-structure conditioned generation. In the condition\noptimization stage, by using human preference learning, we further enhance the\nstability and robustness of sub-structure control. In our experiments, only\ntrained on randomly partitioned sub-structure data, the proposed method\noutperforms previous techniques by generating more valid and diverse molecules.\nOur method is easy to implement and can be quickly applied to various\npre-trained molecule generation models.",
      "tldr_zh": "这篇论文提出了ControlMol框架，用于在分子扩散模型中添加sub-structure控制，以提升计算机辅助药物设计中的分子生成效率。方法采用两阶段训练：condition learning阶段借鉴ControlNet的想法，对无条件生成模型进行调整，使其学会基于特定sub-structure的条件生成；condition optimization阶段则通过human preference learning增强生成的稳定性和鲁棒性。实验结果显示，该方法仅在随机分区数据上训练，便在生成有效和多样化分子方面优于现有技术，并易于快速应用于各种预训练分子生成模型。",
      "categories": [
        "q-bio.BM",
        "cs.AI",
        "cs.LG",
        "physics.chem-ph"
      ],
      "primary_category": "q-bio.BM",
      "comment": "5 pages,3 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.06659v2",
      "published_date": "2024-04-22 14:36:19 UTC",
      "updated_date": "2024-12-21 08:22:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:34:33.391184"
    },
    {
      "arxiv_id": "2404.14219v4",
      "title": "Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone",
      "title_zh": "Phi-3 技术报告：一款高度能力语言模型本地运行在您的手机上",
      "authors": [
        "Marah Abdin",
        "Jyoti Aneja",
        "Hany Awadalla",
        "Ahmed Awadallah",
        "Ammar Ahmad Awan",
        "Nguyen Bach",
        "Amit Bahree",
        "Arash Bakhtiari",
        "Jianmin Bao",
        "Harkirat Behl",
        "Alon Benhaim",
        "Misha Bilenko",
        "Johan Bjorck",
        "Sébastien Bubeck",
        "Martin Cai",
        "Qin Cai",
        "Vishrav Chaudhary",
        "Dong Chen",
        "Dongdong Chen",
        "Weizhu Chen",
        "Yen-Chun Chen",
        "Yi-Ling Chen",
        "Hao Cheng",
        "Parul Chopra",
        "Xiyang Dai",
        "Matthew Dixon",
        "Ronen Eldan",
        "Victor Fragoso",
        "Jianfeng Gao",
        "Mei Gao",
        "Min Gao",
        "Amit Garg",
        "Allie Del Giorno",
        "Abhishek Goswami",
        "Suriya Gunasekar",
        "Emman Haider",
        "Junheng Hao",
        "Russell J. Hewett",
        "Wenxiang Hu",
        "Jamie Huynh",
        "Dan Iter",
        "Sam Ade Jacobs",
        "Mojan Javaheripi",
        "Xin Jin",
        "Nikos Karampatziakis",
        "Piero Kauffmann",
        "Mahoud Khademi",
        "Dongwoo Kim",
        "Young Jin Kim",
        "Lev Kurilenko",
        "James R. Lee",
        "Yin Tat Lee",
        "Yuanzhi Li",
        "Yunsheng Li",
        "Chen Liang",
        "Lars Liden",
        "Xihui Lin",
        "Zeqi Lin",
        "Ce Liu",
        "Liyuan Liu",
        "Mengchen Liu",
        "Weishung Liu",
        "Xiaodong Liu",
        "Chong Luo",
        "Piyush Madan",
        "Ali Mahmoudzadeh",
        "David Majercak",
        "Matt Mazzola",
        "Caio César Teodoro Mendes",
        "Arindam Mitra",
        "Hardik Modi",
        "Anh Nguyen",
        "Brandon Norick",
        "Barun Patra",
        "Daniel Perez-Becker",
        "Thomas Portet",
        "Reid Pryzant",
        "Heyang Qin",
        "Marko Radmilac",
        "Liliang Ren",
        "Gustavo de Rosa",
        "Corby Rosset",
        "Sambudha Roy",
        "Olatunji Ruwase",
        "Olli Saarikivi",
        "Amin Saied",
        "Adil Salim",
        "Michael Santacroce",
        "Shital Shah",
        "Ning Shang",
        "Hiteshi Sharma",
        "Yelong Shen",
        "Swadheen Shukla",
        "Xia Song",
        "Masahiro Tanaka",
        "Andrea Tupini",
        "Praneetha Vaddamanu",
        "Chunyu Wang",
        "Guanhua Wang",
        "Lijuan Wang",
        "Shuohang Wang",
        "Xin Wang",
        "Yu Wang",
        "Rachel Ward",
        "Wen Wen",
        "Philipp Witte",
        "Haiping Wu",
        "Xiaoxia Wu",
        "Michael Wyatt",
        "Bin Xiao",
        "Can Xu",
        "Jiahang Xu",
        "Weijian Xu",
        "Jilong Xue",
        "Sonali Yadav",
        "Fan Yang",
        "Jianwei Yang",
        "Yifan Yang",
        "Ziyi Yang",
        "Donghan Yu",
        "Lu Yuan",
        "Chenruidong Zhang",
        "Cyril Zhang",
        "Jianwen Zhang",
        "Li Lyna Zhang",
        "Yi Zhang",
        "Yue Zhang",
        "Yunan Zhang",
        "Xiren Zhou"
      ],
      "abstract": "We introduce phi-3-mini, a 3.8 billion parameter language model trained on\n3.3 trillion tokens, whose overall performance, as measured by both academic\nbenchmarks and internal testing, rivals that of models such as Mixtral 8x7B and\nGPT-3.5 (e.g., phi-3-mini achieves 69% on MMLU and 8.38 on MT-bench), despite\nbeing small enough to be deployed on a phone. Our training dataset is a\nscaled-up version of the one used for phi-2, composed of heavily filtered\npublicly available web data and synthetic data. The model is also further\naligned for robustness, safety, and chat format. We also provide\nparameter-scaling results with a 7B, 14B models trained for 4.8T tokens, called\nphi-3-small, phi-3-medium, both significantly more capable than phi-3-mini\n(e.g., respectively 75%, 78% on MMLU, and 8.7, 8.9 on MT-bench). To enhance\nmultilingual, multimodal, and long-context capabilities, we introduce three\nmodels in the phi-3.5 series: phi-3.5-mini, phi-3.5-MoE, and phi-3.5-Vision.\nThe phi-3.5-MoE, a 16 x 3.8B MoE model with 6.6 billion active parameters,\nachieves superior performance in language reasoning, math, and code tasks\ncompared to other open-source models of similar scale, such as Llama 3.1 and\nthe Mixtral series, and on par with Gemini-1.5-Flash and GPT-4o-mini.\nMeanwhile, phi-3.5-Vision, a 4.2 billion parameter model derived from\nphi-3.5-mini, excels in reasoning tasks and is adept at handling both\nsingle-image and text prompts, as well as multi-image and text prompts.",
      "tldr_zh": "本研究介绍了 phi-3-mini，一款 3.8 亿参数的语言模型，在 3.3 万亿 tokens 上训练，其在 MMLU 和 MT-bench 等基准测试中表现媲美 Mixtral 8x7B 和 GPT-3.5（如 MMLU 69%、MT-bench 8.38），且体积小到可部署在手机上。模型使用经过严格过滤的公开网络数据和合成数据训练，并通过对齐技术提升鲁棒性、安全性和聊天格式；此外，研究还扩展了 phi-3-small 和 phi-3-medium 模型，分别在 MMLU 上达到 75% 和 78%。为了增强多语言、多模态和长上下文能力，phi-3.5 系列模型（如 phi-3.5-mini、phi-3.5-MoE 和 phi-3.5-Vision）被提出，其中 phi-3.5-MoE（16 x 3.8B 参数）在语言推理、数学和代码任务上优于同规模开源模型，并与 Gemini-1.5-Flash 和 GPT-4o-mini 相当。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "24 pages",
      "pdf_url": "http://arxiv.org/pdf/2404.14219v4",
      "published_date": "2024-04-22 14:32:33 UTC",
      "updated_date": "2024-08-30 21:17:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:34:47.370751"
    },
    {
      "arxiv_id": "2404.14198v1",
      "title": "BCFPL: Binary classification ConvNet based Fast Parking space recognition with Low resolution image",
      "title_zh": "翻译失败",
      "authors": [
        "Shuo Zhang",
        "Xin Chen",
        "Zixuan Wang"
      ],
      "abstract": "The automobile plays an important role in the economic activities of mankind,\nespecially in the metropolis. Under the circumstances, the demand of quick\nsearch for available parking spaces has become a major concern for the\nautomobile drivers. Meanwhile, the public sense of privacy is also awaking, the\nimage-based parking space recognition methods lack the attention of privacy\nprotection. In this paper, we proposed a binary convolutional neural network\nwith lightweight design structure named BCFPL, which can be used to train with\nlow-resolution parking space images and offer a reasonable recognition result.\nThe images of parking space were collected from various complex environments,\nincluding different weather, occlusion conditions, and various camera angles.\nWe conducted the training and testing progresses among different datasets and\npartial subsets. The experimental results show that the accuracy of BCFPL does\nnot decrease compared with the original resolution image directly, and can\nreach the average level of the existing mainstream method. BCFPL also has low\nhardware requirements and fast recognition speed while meeting the privacy\nrequirements, so it has application potential in intelligent city construction\nand automatic driving field.",
      "tldr_zh": "该论文提出了一种名为 BCFPL 的二元分类 ConvNet（Binary classification ConvNet），旨在实现快速停车位识别，同时使用低分辨率图像以保护隐私。BCFPL 采用轻量级设计结构，从复杂环境（如不同天气、遮挡和相机角度）收集的数据集进行训练和测试，结果显示其准确率与原分辨率图像相当，并达到主流方法的平均水平。该模型具有低硬件需求和快速识别速度，在智能城市建设和自动驾驶领域具有显著应用潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.14198v1",
      "published_date": "2024-04-22 14:07:42 UTC",
      "updated_date": "2024-04-22 14:07:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:34:59.757684"
    },
    {
      "arxiv_id": "2404.14161v2",
      "title": "Tensor-Valued Time and Inference Path Optimization in Differential Equation-Based Generative Modeling",
      "title_zh": "翻译失败",
      "authors": [
        "Dohoon Lee",
        "Kyogu Lee"
      ],
      "abstract": "In the field of generative modeling based on differential equations,\nconventional methods utilize scalar-valued time during both the training and\ninference phases. This work introduces, for the first time, a tensor-valued\ntime that expands the conventional scalar-valued time into multiple dimensions.\nAdditionally, we propose a novel path optimization problem designed to\nadaptively determine multidimensional inference trajectories using a\npredetermined differential equation solver and a fixed number of function\nevaluations. Our approach leverages the stochastic interpolant framework,\nsimulation dynamics, and adversarial training to optimize the inference\npathway. Notably, incorporating tensor-valued time during training improves\nsome models' inference performance, even without path optimization. When the\nadaptive, multidimensional path derived from our optimization process is\nemployed, further performance gains are achieved despite the fixed solver\nconfigurations. The introduction of tensor-valued time not only enhances the\nefficiency of models but also opens new avenues for exploration in training and\ninference methodologies, highlighting the potential of adaptive\nmultidimensional paths.",
      "tldr_zh": "这篇论文首次引入张量值时间（tensor-valued time），取代传统标量值时间，用于基于微分方程的生成模型训练和推理阶段，从而扩展到多维空间。作者提出了一种新颖的路径优化问题，利用随机插值框架（stochastic interpolant framework）、模拟动态和对抗训练，自适应地确定多维推理轨迹，同时保持预定微分方程求解器和固定函数评估数量。主要结果显示，仅使用张量值时间即可提升模型推理性能，而结合优化路径进一步提高效率，尽管求解器配置固定，这为生成模型的训练和推理方法开辟了新探索方向。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.14161v2",
      "published_date": "2024-04-22 13:20:01 UTC",
      "updated_date": "2024-05-25 08:10:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:35:14.289968"
    },
    {
      "arxiv_id": "2404.14133v1",
      "title": "Quantum Convolutional Neural Networks for the detection of Gamma-Ray Bursts in the AGILE space mission data",
      "title_zh": "翻译失败",
      "authors": [
        "A. Rizzo",
        "N. Parmiggiani",
        "A. Bulgarelli",
        "A. Macaluso",
        "V. Fioretti",
        "L. Castaldini",
        "A. Di Piano",
        "G. Panebianco",
        "C. Pittori",
        "M. Tavani",
        "C. Sartori",
        "C. Burigana",
        "V. Cardone",
        "F. Farsian",
        "M. Meneghetti",
        "G. Murante",
        "R. Scaramella",
        "F. Schillirò",
        "V. Testa",
        "T. Trombetti"
      ],
      "abstract": "Quantum computing represents a cutting-edge frontier in artificial\nintelligence. It makes use of hybrid quantum-classical computation which tries\nto leverage quantum mechanic principles that allow us to use a different\napproach to deep learning classification problems. The work presented here\nfalls within the context of the AGILE space mission, launched in 2007 by the\nItalian Space Agency. We implement different Quantum Convolutional Neural\nNetworks (QCNN) that analyze data acquired by the instruments onboard AGILE to\ndetect Gamma-Ray Bursts from sky maps or light curves. We use several\nframeworks such as TensorFlow-Quantum, Qiskit and PennyLane to simulate a\nquantum computer. We achieved an accuracy of 95.1% on sky maps with QCNNs,\nwhile the classical counterpart achieved 98.8% on the same data, using however\nhundreds of thousands more parameters.",
      "tldr_zh": "本研究利用 Quantum Convolutional Neural Networks (QCNN) 应用于 AGILE 太空任务数据中 Gamma-Ray Bursts 的检测，旨在通过混合量子-经典计算探索量子力学在深度学习分类问题中的潜力。研究者使用 TensorFlow-Quantum、Qiskit 和 PennyLane 等框架模拟量子计算机，对天空图和光曲线数据进行分析。结果显示，QCNN 在天空图上达到了 95.1% 的准确率，比经典模型（98.8%）略低，但后者所需参数多出成百上千倍，突显了量子方法的资源效率优势。",
      "categories": [
        "astro-ph.HE",
        "cs.AI"
      ],
      "primary_category": "astro-ph.HE",
      "comment": "4 pages, 2 figures, proceedings of the ADASS XXXIII (2023)\n  conference, to appear in ASP Conference Serie",
      "pdf_url": "http://arxiv.org/pdf/2404.14133v1",
      "published_date": "2024-04-22 12:34:53 UTC",
      "updated_date": "2024-04-22 12:34:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:35:25.784833"
    },
    {
      "arxiv_id": "2404.14117v2",
      "title": "Hierarchical localization with panoramic views and triplet loss functions",
      "title_zh": "基于全景视图和三元组损失函数的层次化定位",
      "authors": [
        "Marcos Alfaro",
        "Juan José Cabrera",
        "María Flores",
        "Óscar Reinoso",
        "Luis Payá"
      ],
      "abstract": "The main objective of this paper is to tackle visual localization, which is\nessential for the safe navigation of mobile robots. The solution we propose\nemploys panoramic images and triplet convolutional neural networks. We seek to\nexploit the properties of such architectures to address both hierarchical and\nglobal localization in indoor environments, which are prone to visual aliasing\nand other phenomena. Considering their importance in these architectures, a\ncomplete comparative evaluation of different triplet loss functions is\nperformed. The experimental section proves that triplet networks can be trained\nwith a relatively low number of images captured under a specific lighting\ncondition and even so, the resulting networks are a robust tool to perform\nvisual localization under dynamic conditions. Our approach has been evaluated\nagainst some of these effects, such as changes in the lighting conditions,\nocclusions, noise and motion blurring. Furthermore, to explore the limits of\nour approach, triplet networks have been tested in different indoor\nenvironments simultaneously. In all the cases, these architectures have\ndemonstrated a great capability to generalize to diverse and challenging\nscenarios. The code used in the experiments is available at\nhttps://github.com/MarcosAlfaro/TripletNetworksIndoorLocalization.git.",
      "tldr_zh": "本论文旨在解决移动机器人在室内环境的视觉定位问题，提出了一种结合全景图像(panoramic views)和三元组卷积神经网络(triplet convolutional neural networks)的层次化定位(hierarchical localization)方法，以应对视觉混淆等挑战。该方法通过比较不同三元组损失函数(triplet loss functions)，实现了高效训练，即使使用少量特定光照条件下的图像，也能生成鲁棒的定位模型。实验结果显示，该框架在光照变化、遮挡、噪声和运动模糊等动态条件下表现出色，并在多个室内环境中展示了良好的泛化能力。开源代码可从 https://github.com/MarcosAlfaro/TripletNetworksIndoorLocalization.git 获取。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.14117v2",
      "published_date": "2024-04-22 12:07:10 UTC",
      "updated_date": "2024-11-22 15:51:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:35:36.533904"
    },
    {
      "arxiv_id": "2404.14465v1",
      "title": "Benchmarking Advanced Text Anonymisation Methods: A Comparative Study on Novel and Traditional Approaches",
      "title_zh": "翻译失败",
      "authors": [
        "Dimitris Asimopoulos",
        "Ilias Siniosoglou",
        "Vasileios Argyriou",
        "Thomai Karamitsou",
        "Eleftherios Fountoukidis",
        "Sotirios K. Goudos",
        "Ioannis D. Moscholios",
        "Konstantinos E. Psannis",
        "Panagiotis Sarigiannidis"
      ],
      "abstract": "In the realm of data privacy, the ability to effectively anonymise text is\nparamount. With the proliferation of deep learning and, in particular,\ntransformer architectures, there is a burgeoning interest in leveraging these\nadvanced models for text anonymisation tasks. This paper presents a\ncomprehensive benchmarking study comparing the performance of transformer-based\nmodels and Large Language Models(LLM) against traditional architectures for\ntext anonymisation. Utilising the CoNLL-2003 dataset, known for its robustness\nand diversity, we evaluate several models. Our results showcase the strengths\nand weaknesses of each approach, offering a clear perspective on the efficacy\nof modern versus traditional methods. Notably, while modern models exhibit\nadvanced capabilities in capturing con textual nuances, certain traditional\narchitectures still keep high performance. This work aims to guide researchers\nin selecting the most suitable model for their anonymisation needs, while also\nshedding light on potential paths for future advancements in the field.",
      "tldr_zh": "这篇论文对先进的文本匿名化方法进行了基准测试，比较了 transformer-based 模型和 Large Language Models (LLM) 与传统架构在性能上的差异。\n研究团队使用 CoNLL-2003 数据集评估了多种模型，结果显示现代模型在捕捉上下文 nuances 方面表现出色，但某些传统架构仍保持高性能。\n这项工作为研究者选择合适的文本匿名化方法提供了指导，并指出了未来领域发展的潜在路径。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.14465v1",
      "published_date": "2024-04-22 12:06:54 UTC",
      "updated_date": "2024-04-22 12:06:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:35:48.627051"
    },
    {
      "arxiv_id": "2404.14082v3",
      "title": "Mechanistic Interpretability for AI Safety -- A Review",
      "title_zh": "翻译失败",
      "authors": [
        "Leonard Bereska",
        "Efstratios Gavves"
      ],
      "abstract": "Understanding AI systems' inner workings is critical for ensuring value\nalignment and safety. This review explores mechanistic interpretability:\nreverse engineering the computational mechanisms and representations learned by\nneural networks into human-understandable algorithms and concepts to provide a\ngranular, causal understanding. We establish foundational concepts such as\nfeatures encoding knowledge within neural activations and hypotheses about\ntheir representation and computation. We survey methodologies for causally\ndissecting model behaviors and assess the relevance of mechanistic\ninterpretability to AI safety. We examine benefits in understanding, control,\nalignment, and risks such as capability gains and dual-use concerns. We\ninvestigate challenges surrounding scalability, automation, and comprehensive\ninterpretation. We advocate for clarifying concepts, setting standards, and\nscaling techniques to handle complex models and behaviors and expand to domains\nsuch as vision and reinforcement learning. Mechanistic interpretability could\nhelp prevent catastrophic outcomes as AI systems become more powerful and\ninscrutable.",
      "tldr_zh": "这篇综述探讨了机械解释性（mechanistic interpretability）在确保 AI 安全中的作用，通过逆向工程神经网络的计算机制和表示，将其转化为人类可理解的算法和概念，提供颗粒化和因果性的理解。\n\n作者建立了基础概念，如神经激活中的特征（features）编码，以及关于其表示和计算的假设，并调查了剖析模型行为的因果方法。\n\n综述评估了机械解释性在提升 AI 理解、控制和对齐方面的益处，同时讨论了潜在风险，如能力提升和双重用途担忧。\n\n此外，它指出了可扩展性、自动化和全面解释的挑战，并主张澄清概念、设定标准，并扩展技术到复杂模型和领域（如视觉和强化学习），以防止 AI 系统变得更强大时出现灾难性后果。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to TMLR; for an HTML version, visit\n  https://leonardbereska.github.io/blog/2024/mechinterpreview/",
      "pdf_url": "http://arxiv.org/pdf/2404.14082v3",
      "published_date": "2024-04-22 11:01:51 UTC",
      "updated_date": "2024-08-23 23:02:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:36:02.389315"
    },
    {
      "arxiv_id": "2404.16877v1",
      "title": "Rapid Deployment of DNNs for Edge Computing via Structured Pruning at Initialization",
      "title_zh": "通过在初始化时的结构化剪枝实现 DNNs 的快速边缘计算部署",
      "authors": [
        "Bailey J. Eccles",
        "Leon Wong",
        "Blesson Varghese"
      ],
      "abstract": "Edge machine learning (ML) enables localized processing of data on devices\nand is underpinned by deep neural networks (DNNs). However, DNNs cannot be\neasily run on devices due to their substantial computing, memory and energy\nrequirements for delivering performance that is comparable to cloud-based ML.\nTherefore, model compression techniques, such as pruning, have been considered.\nExisting pruning methods are problematic for edge ML since they: (1) Create\ncompressed models that have limited runtime performance benefits (using\nunstructured pruning) or compromise the final model accuracy (using structured\npruning), and (2) Require substantial compute resources and time for\nidentifying a suitable compressed DNN model (using neural architecture search).\nIn this paper, we explore a new avenue, referred to as\nPruning-at-Initialization (PaI), using structured pruning to mitigate the above\nproblems. We develop Reconvene, a system for rapidly generating pruned models\nsuited for edge deployments using structured PaI. Reconvene systematically\nidentifies and prunes DNN convolution layers that are least sensitive to\nstructured pruning. Reconvene rapidly creates pruned DNNs within seconds that\nare up to 16.21x smaller and 2x faster while maintaining the same accuracy as\nan unstructured PaI counterpart.",
      "tldr_zh": "这篇论文针对边缘计算中DNNs的部署挑战，提出了Pruning-at-Initialization (PaI)方法，通过结构化剪枝在模型初始化阶段减少计算、内存和能耗需求。作者开发了Reconvene系统，该系统系统地识别并剪枝DNN卷积层中对剪枝最不敏感的部分，从而快速生成适合边缘设备的模型。实验结果显示，Reconvene能在几秒内创建的剪枝模型比未剪枝版本小16.21倍、快2倍，同时保持相同的准确性，为高效的边缘机器学习部署提供了新方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "The 24th IEEE/ACM International Symposium on Cluster, Cloud and\n  Internet Computing",
      "pdf_url": "http://arxiv.org/pdf/2404.16877v1",
      "published_date": "2024-04-22 10:57:54 UTC",
      "updated_date": "2024-04-22 10:57:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:36:13.531099"
    },
    {
      "arxiv_id": "2404.14073v1",
      "title": "Towards Robust Trajectory Representations: Isolating Environmental Confounders with Causal Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Kang Luo",
        "Yuanshao Zhu",
        "Wei Chen",
        "Kun Wang",
        "Zhengyang Zhou",
        "Sijie Ruan",
        "Yuxuan Liang"
      ],
      "abstract": "Trajectory modeling refers to characterizing human movement behavior, serving\nas a pivotal step in understanding mobility patterns. Nevertheless, existing\nstudies typically ignore the confounding effects of geospatial context, leading\nto the acquisition of spurious correlations and limited generalization\ncapabilities. To bridge this gap, we initially formulate a Structural Causal\nModel (SCM) to decipher the trajectory representation learning process from a\ncausal perspective. Building upon the SCM, we further present a Trajectory\nmodeling framework (TrajCL) based on Causal Learning, which leverages the\nbackdoor adjustment theory as an intervention tool to eliminate the spurious\ncorrelations between geospatial context and trajectories. Extensive experiments\non two real-world datasets verify that TrajCL markedly enhances performance in\ntrajectory classification tasks while showcasing superior generalization and\ninterpretability.",
      "tldr_zh": "现有的轨迹建模研究通常忽略地理空间上下文的混淆效应，导致虚假相关性和泛化能力不足。作者构建了 Structural Causal Model (SCM) 来从因果视角分析轨迹表示学习过程，并提出了基于因果学习的 TrajCL 框架，利用 backdoor adjustment theory 作为干预工具，消除地理空间上下文与轨迹之间的虚假相关性。在两个真实世界数据集上的广泛实验验证，TrajCL 显著提升了轨迹分类任务的性能，并展示了更好的泛化性和可解释性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "The paper has been accepted by IJCAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.14073v1",
      "published_date": "2024-04-22 10:34:58 UTC",
      "updated_date": "2024-04-22 10:34:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:36:25.183386"
    },
    {
      "arxiv_id": "2407.05180v3",
      "title": "ReCAP: Recursive Cross Attention Network for Pseudo-Label Generation in Robotic Surgical Skill Assessment",
      "title_zh": "ReCAP：递归交叉注意力网络用于机器人手术技能评估中的伪标签生成",
      "authors": [
        "Julien Quarez",
        "Marc Modat",
        "Sebastien Ourselin",
        "Jonathan Shapey",
        "Alejandro Granados"
      ],
      "abstract": "In surgical skill assessment, the Objective Structured Assessments of\nTechnical Skills (OSATS) and Global Rating Scale (GRS) are well-established\ntools for evaluating surgeons during training. These metrics, along with\nperformance feedback, help surgeons improve and reach practice standards.\nRecent research on the open-source JIGSAWS dataset, which includes both GRS and\nOSATS labels, has focused on regressing GRS scores from kinematic data, video,\nor their combination. However, we argue that regressing GRS alone is limiting,\nas it aggregates OSATS scores and overlooks clinically meaningful variations\nduring a surgical trial. To address this, we developed a recurrent transformer\nmodel that tracks a surgeon's performance throughout a session by mapping\nhidden states to six OSATS, derived from kinematic data, using a clinically\nmotivated objective function. These OSATS scores are averaged to predict GRS,\nallowing us to compare our model's performance against state-of-the-art (SOTA)\nmethods. We report Spearman's Correlation Coefficients (SCC) demonstrating that\nour model outperforms SOTA using kinematic data (SCC 0.83-0.88), and matches\nperformance with video-based models. Our model also surpasses SOTA in most\ntasks for average OSATS predictions (SCC 0.46-0.70) and specific OSATS (SCC\n0.56-0.95). The generation of pseudo-labels at the segment level translates\nquantitative predictions into qualitative feedback, vital for automated\nsurgical skill assessment pipelines. A senior surgeon validated our model's\noutputs, agreeing with 77% of the weakly-supervised predictions (p=0.006).",
      "tldr_zh": "本研究提出 ReCAP，一种递归交叉注意力网络，用于从运动学数据生成伪标签，以评估机器人外科技能，解决传统仅回归 GRS 分数的局限性。ReCAP 采用循环 Transformer 模型，将隐藏状态映射到六个 OSATS 分数，并通过临床导向的目标函数平均这些分数来预测 GRS。实验在 JIGSAWS 数据集上显示，该模型在运动学数据上比 SOTA 方法性能更优（SCC 0.83-0.88），并在平均 OSATS 和特定 OSATS 预测上表现出色（SCC 0.46-0.95），生成的段级伪标签提供定性反馈，并获得资深外科医生 77% 的认可。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.05180v3",
      "published_date": "2024-04-22 10:33:06 UTC",
      "updated_date": "2024-10-24 11:18:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:36:38.756900"
    },
    {
      "arxiv_id": "2404.14068v1",
      "title": "Holistic Safety and Responsibility Evaluations of Advanced AI Models",
      "title_zh": "高级 AI 模型的整体安全和责任评估",
      "authors": [
        "Laura Weidinger",
        "Joslyn Barnhart",
        "Jenny Brennan",
        "Christina Butterfield",
        "Susie Young",
        "Will Hawkins",
        "Lisa Anne Hendricks",
        "Ramona Comanescu",
        "Oscar Chang",
        "Mikel Rodriguez",
        "Jennifer Beroshi",
        "Dawn Bloxwich",
        "Lev Proleev",
        "Jilin Chen",
        "Sebastian Farquhar",
        "Lewis Ho",
        "Iason Gabriel",
        "Allan Dafoe",
        "William Isaac"
      ],
      "abstract": "Safety and responsibility evaluations of advanced AI models are a critical\nbut developing field of research and practice. In the development of Google\nDeepMind's advanced AI models, we innovated on and applied a broad set of\napproaches to safety evaluation. In this report, we summarise and share\nelements of our evolving approach as well as lessons learned for a broad\naudience. Key lessons learned include: First, theoretical underpinnings and\nframeworks are invaluable to organise the breadth of risk domains, modalities,\nforms, metrics, and goals. Second, theory and practice of safety evaluation\ndevelopment each benefit from collaboration to clarify goals, methods and\nchallenges, and facilitate the transfer of insights between different\nstakeholders and disciplines. Third, similar key methods, lessons, and\ninstitutions apply across the range of concerns in responsibility and safety -\nincluding established and emerging harms. For this reason it is important that\na wide range of actors working on safety evaluation and safety research\ncommunities work together to develop, refine and implement novel evaluation\napproaches and best practices, rather than operating in silos. The report\nconcludes with outlining the clear need to rapidly advance the science of\nevaluations, to integrate new evaluations into the development and governance\nof AI, to establish scientifically-grounded norms and standards, and to promote\na robust evaluation ecosystem.",
      "tldr_zh": "本论文探讨了Google DeepMind在开发高级AI models时的整体安全和责任评估方法，创新性地应用了多种评估框架来覆盖风险领域、模式和指标。关键发现包括：理论基础有助于组织评估目标，跨学科合作能提升方法实践，而类似方法适用于新兴和传统危害，因此需要打破孤岛进行合作。论文呼吁快速推进评估科学，将其整合到AI开发与治理中，建立科学标准，并构建一个稳健的评估生态系统。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages excluding bibliography",
      "pdf_url": "http://arxiv.org/pdf/2404.14068v1",
      "published_date": "2024-04-22 10:26:49 UTC",
      "updated_date": "2024-04-22 10:26:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:36:48.732247"
    },
    {
      "arxiv_id": "2404.14061v2",
      "title": "FedTAD: Topology-aware Data-free Knowledge Distillation for Subgraph Federated Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Yinlin Zhu",
        "Xunkai Li",
        "Zhengyu Wu",
        "Di Wu",
        "Miao Hu",
        "Rong-Hua Li"
      ],
      "abstract": "Subgraph federated learning (subgraph-FL) is a new distributed paradigm that\nfacilitates the collaborative training of graph neural networks (GNNs) by\nmulti-client subgraphs. Unfortunately, a significant challenge of subgraph-FL\narises from subgraph heterogeneity, which stems from node and topology\nvariation, causing the impaired performance of the global GNN. Despite various\nstudies, they have not yet thoroughly investigated the impact mechanism of\nsubgraph heterogeneity. To this end, we decouple node and topology variation,\nrevealing that they correspond to differences in label distribution and\nstructure homophily. Remarkably, these variations lead to significant\ndifferences in the class-wise knowledge reliability of multiple local GNNs,\nmisguiding the model aggregation with varying degrees. Building on this\ninsight, we propose topology-aware data-free knowledge distillation technology\n(FedTAD), enhancing reliable knowledge transfer from the local model to the\nglobal model. Extensive experiments on six public datasets consistently\ndemonstrate the superiority of FedTAD over state-of-the-art baselines.",
      "tldr_zh": "本论文针对子图联邦学习（subgraph-FL）中的子图异质性问题（如节点和拓扑变化），揭示了这些变化导致标签分布和结构同质性（structure homophily）差异，从而使多客户端图神经网络（GNNs）的类级知识可靠性出现偏差，影响全局模型聚合。作者提出 FedTAD，一种拓扑感知的无数据知识蒸馏（topology-aware data-free knowledge distillation）技术，通过增强可靠知识从本地模型向全局模型的转移来缓解这一问题。在六个公开数据集上的广泛实验中，FedTAD  consistently 优于现有基线方法，证明了其有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DB",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by IJCAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.14061v2",
      "published_date": "2024-04-22 10:19:02 UTC",
      "updated_date": "2024-04-25 06:40:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:37:02.920508"
    },
    {
      "arxiv_id": "2404.14050v1",
      "title": "Unlawful Proxy Discrimination: A Framework for Challenging Inherently Discriminatory Algorithms",
      "title_zh": "非法代理歧视：一个用于挑战固有歧视性算法的框架",
      "authors": [
        "Hilde Weerts",
        "Aislinn Kelly-Lyth",
        "Reuben Binns",
        "Jeremias Adams-Prassl"
      ],
      "abstract": "Emerging scholarship suggests that the EU legal concept of direct\ndiscrimination - where a person is given different treatment on grounds of a\nprotected characteristic - may apply to various algorithmic decision-making\ncontexts. This has important implications: unlike indirect discrimination,\nthere is generally no 'objective justification' stage in the direct\ndiscrimination framework, which means that the deployment of directly\ndiscriminatory algorithms will usually be unlawful per se. In this paper, we\nfocus on the most likely candidate for direct discrimination in the algorithmic\ncontext, termed inherent direct discrimination, where a proxy is inextricably\nlinked to a protected characteristic. We draw on computer science literature to\nsuggest that, in the algorithmic context, 'treatment on the grounds of' needs\nto be understood in terms of two steps: proxy capacity and proxy use. Only\nwhere both elements can be made out can direct discrimination be said to be `on\ngrounds of' a protected characteristic. We analyse the legal conditions of our\nproposed proxy capacity and proxy use tests. Based on this analysis, we discuss\ntechnical approaches and metrics that could be developed or applied to identify\ninherent direct discrimination in algorithmic decision-making.",
      "tldr_zh": "本论文提出一个框架，用于挑战算法决策中的固有直接歧视（inherent direct discrimination），即代理变量（proxy）与受保护特征（如种族或性别）不可分割，从而导致非法歧视。作者基于欧盟法律概念，将“treatment on the grounds of”分为两个步骤：proxy capacity（代理变量的关联能力）和proxy use（代理变量的使用），以确定算法是否直接基于受保护特征进行歧视。论文分析了这些测试的法律条件，并建议开发或应用技术方法和指标，如计算机科学文献中的相关工具，来识别和应对算法决策中的固有直接歧视，从而为算法合规提供指导。",
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.14050v1",
      "published_date": "2024-04-22 10:06:17 UTC",
      "updated_date": "2024-04-22 10:06:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:37:13.977685"
    },
    {
      "arxiv_id": "2404.14464v1",
      "title": "Tree of Reviews: A Tree-based Dynamic Iterative Retrieval Framework for Multi-hop Question Answering",
      "title_zh": "翻译失败",
      "authors": [
        "Li Jiapeng",
        "Liu Runze",
        "Li Yabo",
        "Zhou Tong",
        "Li Mingling",
        "Chen Xiang"
      ],
      "abstract": "Multi-hop question answering is a knowledge-intensive complex problem. Large\nLanguage Models (LLMs) use their Chain of Thoughts (CoT) capability to reason\ncomplex problems step by step, and retrieval-augmentation can effectively\nalleviate factual errors caused by outdated and unknown knowledge in LLMs.\nRecent works have introduced retrieval-augmentation in the CoT reasoning to\nsolve multi-hop question answering. However, these chain methods have the\nfollowing problems: 1) Retrieved irrelevant paragraphs may mislead the\nreasoning; 2) An error in the chain structure may lead to a cascade of errors.\n  In this paper, we propose a dynamic retrieval framework called Tree of\nReviews (ToR), where the root node is the question, and the other nodes are\nparagraphs from retrieval, extending different reasoning paths from the root\nnode to other nodes. Our framework dynamically decides to initiate a new\nsearch, reject, or accept based on the paragraphs on the reasoning paths.\nCompared to related work, we introduce a tree structure to handle each\nretrieved paragraph separately, alleviating the misleading effect of irrelevant\nparagraphs on the reasoning path; the diversity of reasoning path extension\nreduces the impact of a single reasoning error on the whole. We conducted\nexperiments on three different multi-hop question answering datasets. The\nresults show that compared to the baseline methods, ToR achieves\nstate-of-the-art performance in both retrieval and response generation. In\naddition, we propose two tree-based search optimization strategies, pruning and\neffective expansion, to reduce time overhead and increase the diversity of path\nextension. We will release our code.",
      "tldr_zh": "本论文提出了一种基于树结构的动态迭代检索框架Tree of Reviews (ToR)，用于多跳问题回答(Multi-hop Question Answering)，旨在解决现有Chain of Thoughts (CoT)方法中无关段落误导和错误级联的问题。ToR将问题作为根节点，从检索的段落扩展多条推理路径，并动态决定是否发起新搜索、拒绝或接受路径，从而单独处理每个段落并减少单一错误的影响。实验结果显示，在三个多跳QA数据集上，ToR在检索和响应生成方面比基线方法取得了最先进性能；此外，论文还引入了pruning和effective expansion优化策略，以降低时间开销并增加路径多样性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "Keywords: Muti-hop Question Answering; Retrieval-Augmented\n  Generation; Tree of Thought; Reasoning TLDR: We proposed a tree-based\n  dynamic, iterative retrieval framework for multi-hop question answering",
      "pdf_url": "http://arxiv.org/pdf/2404.14464v1",
      "published_date": "2024-04-22 09:25:05 UTC",
      "updated_date": "2024-04-22 09:25:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:37:27.387575"
    },
    {
      "arxiv_id": "2404.16876v1",
      "title": "AdaQAT: Adaptive Bit-Width Quantization-Aware Training",
      "title_zh": "AdaQAT：自适应位宽量化感知训练",
      "authors": [
        "Cédric Gernigon",
        "Silviu-Ioan Filip",
        "Olivier Sentieys",
        "Clément Coggiola",
        "Mickael Bruno"
      ],
      "abstract": "Large-scale deep neural networks (DNNs) have achieved remarkable success in\nmany application scenarios. However, high computational complexity and energy\ncosts of modern DNNs make their deployment on edge devices challenging. Model\nquantization is a common approach to deal with deployment constraints, but\nsearching for optimized bit-widths can be challenging. In this work, we present\nAdaptive Bit-Width Quantization Aware Training (AdaQAT), a learning-based\nmethod that automatically optimizes weight and activation signal bit-widths\nduring training for more efficient DNN inference. We use relaxed real-valued\nbit-widths that are updated using a gradient descent rule, but are otherwise\ndiscretized for all quantization operations. The result is a simple and\nflexible QAT approach for mixed-precision uniform quantization problems.\nCompared to other methods that are generally designed to be run on a pretrained\nnetwork, AdaQAT works well in both training from scratch and fine-tuning\nscenarios.Initial results on the CIFAR-10 and ImageNet datasets using ResNet20\nand ResNet18 models, respectively, indicate that our method is competitive with\nother state-of-the-art mixed-precision quantization approaches.",
      "tldr_zh": "该研究提出 AdaQAT，一种自适应位宽量化感知训练方法，用于优化深度神经网络（DNNs）的权重和激活信号位宽，以应对模型部署时的计算复杂性和能耗挑战。AdaQAT 通过梯度下降规则更新松弛的实值位宽，并在量化操作中进行离散化，实现简单灵活的混合精度均匀量化，支持从零开始训练或微调场景。与现有方法相比，在 CIFAR-10 和 ImageNet 数据集上使用 ResNet20 和 ResNet18 模型时，AdaQAT 的性能与最先进混合精度量化方法相当。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.16876v1",
      "published_date": "2024-04-22 09:23:56 UTC",
      "updated_date": "2024-04-22 09:23:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:37:38.731973"
    },
    {
      "arxiv_id": "2405.02324v1",
      "title": "Combined Compromise for Ideal Solution (CoCoFISo): a multi-criteria decision-making based on the CoCoSo method algorithm",
      "title_zh": "Combined Compromise for Ideal Solution (CoCoFISo)：一种基于 CoCoSo 方法算法的多准则决策",
      "authors": [
        "Rôlin Gabriel Rasoanaivo",
        "Morteza Yazdani",
        "Pascale Zaraté",
        "Amirhossein Fateh"
      ],
      "abstract": "Each decision-making tool should be tested and validated in real case studies\nto be practical and fit to global problems. The application of multi-criteria\ndecision-making methods (MCDM) is currently a trend to rank alternatives. In\nthe literature, there are several multi-criteria decision-making methods\naccording to their classification. During our experimentation on the Combined\nCompromise Solution (CoCoSo) method, we encountered its limits for real cases.\nThe authors examined the applicability of the CoCoFISo method (improved version\nof combined compromise solution), by a real case study in a university campus\nand compared the obtained results to other MCDMs such as Preference Ranking\nOrganisation Method for Enrichment Evaluations (PROMETHEE), Weighted Sum Method\n(WSM) and Technique for Order Preference by Similarity to the Ideal Solution\n(TOPSIS). Our research finding indicates that CoCoSo is an applied method that\nhas been developed to solve complex multi variable assessment problems, while\nCoCoFISo can improve the shortages observed in CoCoSo and deliver stable\noutcomes compared to other developed tools. The findings imply that application\nof CoCoFISo is suggested to decision makers, experts and researchers while they\nare facing practical challenges and sensitive questions regarding the\nutilization of a reliable decision-making method. Unlike many prior studies,\nthe current version of CoCoSo is unique, original and is presented for the\nfirst time. Its performance was approved using several strategies and\nexaminations.",
      "tldr_zh": "本论文提出 CoCoFISo 方法，这是一种基于 CoCoSo 算法的改进多标准决策方法 (MCDM)，旨在解决 CoCoSo 在实际案例中的局限性。研究者通过一个大学校园的真实案例研究，将 CoCoFISo 与其他 MCDM 方法如 PROMETHEE、WSM 和 TOPSIS 进行比较，结果显示 CoCoFISo 提供了更稳定的评估结果，并有效处理复杂多变量问题。作者建议决策者、专家和研究人员在面对实际挑战时优先采用 CoCoFISo，作为一种原创且可靠的决策工具。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Expert Systems with Applications, 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.02324v1",
      "published_date": "2024-04-22 09:19:33 UTC",
      "updated_date": "2024-04-22 09:19:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:37:49.607014"
    },
    {
      "arxiv_id": "2404.14007v1",
      "title": "Infusion: Preventing Customized Text-to-Image Diffusion from Overfitting",
      "title_zh": "Infusion: 防止自定义文本到图像扩散模型过拟合",
      "authors": [
        "Weili Zeng",
        "Yichao Yan",
        "Qi Zhu",
        "Zhuo Chen",
        "Pengzhi Chu",
        "Weiming Zhao",
        "Xiaokang Yang"
      ],
      "abstract": "Text-to-image (T2I) customization aims to create images that embody specific\nvisual concepts delineated in textual descriptions. However, existing works\nstill face a main challenge, concept overfitting. To tackle this challenge, we\nfirst analyze overfitting, categorizing it into concept-agnostic overfitting,\nwhich undermines non-customized concept knowledge, and concept-specific\noverfitting, which is confined to customize on limited modalities, i.e,\nbackgrounds, layouts, styles. To evaluate the overfitting degree, we further\nintroduce two metrics, i.e, Latent Fisher divergence and Wasserstein metric to\nmeasure the distribution changes of non-customized and customized concept\nrespectively. Drawing from the analysis, we propose Infusion, a T2I\ncustomization method that enables the learning of target concepts to avoid\nbeing constrained by limited training modalities, while preserving\nnon-customized knowledge. Remarkably, Infusion achieves this feat with\nremarkable efficiency, requiring a mere 11KB of trained parameters. Extensive\nexperiments also demonstrate that our approach outperforms state-of-the-art\nmethods in both single and multi-concept customized generation.",
      "tldr_zh": "这篇论文针对 Text-to-image (T2I) customization 的核心挑战——concept overfitting 问题，提出了 Infusion 方法，以避免概念泛化不足和特定模式限制。Infusion 通过分类过拟合为 concept-agnostic overfitting（破坏非自定义知识）和 concept-specific overfitting（限于背景、布局等），并引入 Latent Fisher divergence 和 Wasserstein metric 来量化分布变化，从而在学习目标概念时保留非自定义知识。实验结果显示，该方法只需 11KB 的训练参数，即在单概念和多概念生成任务上优于现有最先进技术。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages",
      "pdf_url": "http://arxiv.org/pdf/2404.14007v1",
      "published_date": "2024-04-22 09:16:25 UTC",
      "updated_date": "2024-04-22 09:16:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:38:01.144202"
    },
    {
      "arxiv_id": "2406.15386v1",
      "title": "U Can't Gen This? A Survey of Intellectual Property Protection Methods for Data in Generative AI",
      "title_zh": "翻译失败",
      "authors": [
        "Tanja Šarčević",
        "Alicja Karlowicz",
        "Rudolf Mayer",
        "Ricardo Baeza-Yates",
        "Andreas Rauber"
      ],
      "abstract": "Large Generative AI (GAI) models have the unparalleled ability to generate\ntext, images, audio, and other forms of media that are increasingly\nindistinguishable from human-generated content. As these models often train on\npublicly available data, including copyrighted materials, art and other\ncreative works, they inadvertently risk violating copyright and\nmisappropriation of intellectual property (IP). Due to the rapid development of\ngenerative AI technology and pressing ethical considerations from stakeholders,\nprotective mechanisms and techniques are emerging at a high pace but lack\nsystematisation.\n  In this paper, we study the concerns regarding the intellectual property\nrights of training data and specifically focus on the properties of generative\nmodels that enable misuse leading to potential IP violations. Then we propose a\ntaxonomy that leads to a systematic review of technical solutions for\nsafeguarding the data from intellectual property violations in GAI.",
      "tldr_zh": "这篇论文调查了生成式 AI (GAI) 在处理知识产权 (IP) 问题时的保护方法，重点关注 GAI 模型在训练时使用公开数据可能导致的版权侵犯和 IP 误用风险。作者分析了 GAI 的特性，如生成高质量媒体的能力，这些特性可能引发伦理和法律问题，并提出一个 taxonomy（分类法）来系统化地审视现有技术解决方案。论文通过这种框架，回顾了保护训练数据免受 IP 侵犯的多种机制，为 GAI 的可持续发展提供指导。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.15386v1",
      "published_date": "2024-04-22 09:09:21 UTC",
      "updated_date": "2024-04-22 09:09:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:38:11.637784"
    },
    {
      "arxiv_id": "2404.14463v1",
      "title": "DAIC-WOZ: On the Validity of Using the Therapist's prompts in Automatic Depression Detection from Clinical Interviews",
      "title_zh": "翻译失败",
      "authors": [
        "Sergio Burdisso",
        "Ernesto Reyes-Ramírez",
        "Esaú Villatoro-Tello",
        "Fernando Sánchez-Vega",
        "Pastor López-Monroy",
        "Petr Motlicek"
      ],
      "abstract": "Automatic depression detection from conversational data has gained\nsignificant interest in recent years. The DAIC-WOZ dataset, interviews\nconducted by a human-controlled virtual agent, has been widely used for this\ntask. Recent studies have reported enhanced performance when incorporating\ninterviewer's prompts into the model. In this work, we hypothesize that this\nimprovement might be mainly due to a bias present in these prompts, rather than\nthe proposed architectures and methods. Through ablation experiments and\nqualitative analysis, we discover that models using interviewer's prompts learn\nto focus on a specific region of the interviews, where questions about past\nexperiences with mental health issues are asked, and use them as discriminative\nshortcuts to detect depressed participants. In contrast, models using\nparticipant responses gather evidence from across the entire interview.\nFinally, to highlight the magnitude of this bias, we achieve a 0.90 F1 score by\nintentionally exploiting it, the highest result reported to date on this\ndataset using only textual information. Our findings underline the need for\ncaution when incorporating interviewers' prompts into models, as they may\ninadvertently learn to exploit targeted prompts, rather than learning to\ncharacterize the language and behavior that are genuinely indicative of the\npatient's mental health condition.",
      "tldr_zh": "本研究质疑了在 DAIC-WOZ 数据集中使用采访者 prompts 来提升自动抑郁检测性能的有效性，假设这种提升主要源于 prompts 中的偏见，而非模型架构的改进。作者通过消融实验和定性分析发现，模型在使用 prompts 时往往聚焦于特定部分（如关于过去心理健康问题的提问），将其作为检测抑郁的捷径，而使用参与者响应的模型则从整个采访中收集证据。最终，利用这一偏见，研究团队达到了 0.90 F1 score 的最高文本性能，但强调在模型设计中需谨慎，避免依赖非真实特征来表征患者的心理健康状况。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to Clinical NLP workshop at NAACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.14463v1",
      "published_date": "2024-04-22 09:07:50 UTC",
      "updated_date": "2024-04-22 09:07:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:38:27.740233"
    },
    {
      "arxiv_id": "2404.13973v1",
      "title": "DEQ-MCL: Discrete-Event Queue-based Monte-Carlo Localization",
      "title_zh": "DEQ-MCL：基于离散事件队列的蒙特卡洛本地化",
      "authors": [
        "Akira Taniguchi",
        "Ayako Fukawa",
        "Hiroshi Yamakawa"
      ],
      "abstract": "Spatial cognition in hippocampal formation is posited to play a crucial role\nin the development of self-localization techniques for robots. In this paper,\nwe propose a self-localization approach, DEQ-MCL, based on the discrete event\nqueue hypothesis associated with phase precession within the hippocampal\nformation. Our method effectively estimates the posterior distribution of\nstates, encompassing both past, present, and future states that are organized\nas a queue. This approach enables the smoothing of the posterior distribution\nof past states using current observations and the weighting of the joint\ndistribution by considering the feasibility of future states. Our findings\nindicate that the proposed method holds promise for augmenting\nself-localization performance in indoor environments.",
      "tldr_zh": "该论文提出 DEQ-MCL，一种基于离散事件队列假设和海马体形成相位预cession的 Monte-Carlo Localization 方法，用于提升机器人自定位性能。该方法通过估计状态的后验分布，包括过去、现在和未来状态的队列组织，利用当前观察平滑过去状态分布，并通过未来状态的可行性加权联合分布。该研究结果表明，DEQ-MCL 在室内环境中有望显著改善自定位的准确性和鲁棒性。",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by AROB-ISBC-SWARM 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.13973v1",
      "published_date": "2024-04-22 08:29:00 UTC",
      "updated_date": "2024-04-22 08:29:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:38:37.139546"
    },
    {
      "arxiv_id": "2404.15154v2",
      "title": "Do not think about pink elephant!",
      "title_zh": "不要想粉色大象！",
      "authors": [
        "Kyomin Hwang",
        "Suyoung Kim",
        "JunHoo Lee",
        "Nojun Kwak"
      ],
      "abstract": "Large Models (LMs) have heightened expectations for the potential of general\nAI as they are akin to human intelligence. This paper shows that recent large\nmodels such as Stable Diffusion and DALL-E3 also share the vulnerability of\nhuman intelligence, namely the \"white bear phenomenon\". We investigate the\ncauses of the white bear phenomenon by analyzing their representation space.\nBased on this analysis, we propose a simple prompt-based attack method, which\ngenerates figures prohibited by the LM provider's policy. To counter these\nattacks, we introduce prompt-based defense strategies inspired by cognitive\ntherapy techniques, successfully mitigating attacks by up to 48.22\\%.",
      "tldr_zh": "该研究揭示了大型模型（如 Stable Diffusion 和 DALL-E3）类似于人类智能，易受“white bear phenomenon”（白熊现象）影响，即试图抑制某些内容反而强化其生成。论文通过分析模型的表示空间，提出了一种简单prompt-based attack方法，用于生成被模型提供者政策禁止的图像。针对此漏洞，研究引入了受认知疗法启发的prompt-based defense策略，成功将攻击效果缓解高达48.22%。这为提升大型模型的安全性和鲁棒性提供了重要见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "This paper is accepted in CVPR 2024 Responsible Generative AI\n  Workshop (ReGenAI)",
      "pdf_url": "http://arxiv.org/pdf/2404.15154v2",
      "published_date": "2024-04-22 08:28:13 UTC",
      "updated_date": "2024-10-31 04:32:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:38:49.112712"
    },
    {
      "arxiv_id": "2404.13968v3",
      "title": "Protecting Your LLMs with Information Bottleneck",
      "title_zh": "翻译失败",
      "authors": [
        "Zichuan Liu",
        "Zefan Wang",
        "Linjie Xu",
        "Jinyu Wang",
        "Lei Song",
        "Tianchun Wang",
        "Chunlin Chen",
        "Wei Cheng",
        "Jiang Bian"
      ],
      "abstract": "The advent of large language models (LLMs) has revolutionized the field of\nnatural language processing, yet they might be attacked to produce harmful\ncontent. Despite efforts to ethically align LLMs, these are often fragile and\ncan be circumvented by jailbreaking attacks through optimized or manual\nadversarial prompts. To address this, we introduce the Information Bottleneck\nProtector (IBProtector), a defense mechanism grounded in the information\nbottleneck principle, and we modify the objective to avoid trivial solutions.\nThe IBProtector selectively compresses and perturbs prompts, facilitated by a\nlightweight and trainable extractor, preserving only essential information for\nthe target LLMs to respond with the expected answer. Moreover, we further\nconsider a situation where the gradient is not visible to be compatible with\nany LLM. Our empirical evaluations show that IBProtector outperforms current\ndefense methods in mitigating jailbreak attempts, without overly affecting\nresponse quality or inference speed. Its effectiveness and adaptability across\nvarious attack methods and target LLMs underscore the potential of IBProtector\nas a novel, transferable defense that bolsters the security of LLMs without\nrequiring modifications to the underlying models.",
      "tldr_zh": "这篇论文提出了 Information Bottleneck Protector (IBProtector)，一种基于信息瓶颈原理的防御机制，用于保护大型语言模型 (LLMs) 免受 jailbreaking attacks 等攻击。IBProtector 通过一个轻量级的可训练提取器，选择性地压缩和扰动提示，只保留必要的响应信息，从而避免琐碎解决方案，并兼容不提供梯度信息的 LLM。实验评估表明，该方法在缓解各种攻击方面优于现有防御策略，同时保持了响应质量和推理速度的稳定性，无需修改底层模型。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by Neural Information Processing Systems (NeurIPS 2024)",
      "pdf_url": "http://arxiv.org/pdf/2404.13968v3",
      "published_date": "2024-04-22 08:16:07 UTC",
      "updated_date": "2024-10-10 13:22:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:39:02.546103"
    },
    {
      "arxiv_id": "2404.13954v1",
      "title": "A survey of air combat behavior modeling using machine learning",
      "title_zh": "翻译失败",
      "authors": [
        "Patrick Ribu Gorton",
        "Andreas Strand",
        "Karsten Brathen"
      ],
      "abstract": "With the recent advances in machine learning, creating agents that behave\nrealistically in simulated air combat has become a growing field of interest.\nThis survey explores the application of machine learning techniques for\nmodeling air combat behavior, motivated by the potential to enhance\nsimulation-based pilot training. Current simulated entities tend to lack\nrealistic behavior, and traditional behavior modeling is labor-intensive and\nprone to loss of essential domain knowledge between development steps.\nAdvancements in reinforcement learning and imitation learning algorithms have\ndemonstrated that agents may learn complex behavior from data, which could be\nfaster and more scalable than manual methods. Yet, making adaptive agents\ncapable of performing tactical maneuvers and operating weapons and sensors\nstill poses a significant challenge. The survey examines applications, behavior\nmodel types, prevalent machine learning methods, and the technical and human\nchallenges in developing adaptive and realistically behaving agents. Another\nchallenge is the transfer of agents from learning environments to military\nsimulation systems and the consequent demand for standardization. Four primary\nrecommendations are presented regarding increased emphasis on\nbeyond-visual-range scenarios, multi-agent machine learning and cooperation,\nutilization of hierarchical behavior models, and initiatives for\nstandardization and research collaboration. These recommendations aim to\naddress current issues and guide the development of more comprehensive,\nadaptable, and realistic machine learning-based behavior models for air combat\napplications.",
      "tldr_zh": "这篇调查论文探讨了使用机器学习（machine learning）技术来建模空中作战行为的最新应用，旨在提升模拟飞行员训练的真实性和效率。论文指出，强化学习（reinforcement learning）和模仿学习（imitation learning）等方法能从数据中快速学习复杂行为，从而克服传统建模的劳动密集型问题，但仍面临代理适应性、战术执行和从学习环境到军事模拟系统的标准化挑战。最终，论文提出四点主要推荐，包括强调超视距（beyond-visual-range）场景、多代理机器学习（multi-agent machine learning）和合作、分层行为模型（hierarchical behavior models）的利用，以及推动标准化和研究合作，以指导更全面的空中作战行为建模发展。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA",
        "F.2.0; I.2.1; I.2.6; I.2.8"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.13954v1",
      "published_date": "2024-04-22 07:54:56 UTC",
      "updated_date": "2024-04-22 07:54:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:39:14.650752"
    },
    {
      "arxiv_id": "2404.13941v1",
      "title": "Autoencoder-assisted Feature Ensemble Net for Incipient Faults",
      "title_zh": "翻译失败",
      "authors": [
        "Mingxuan Gao",
        "Min Wang",
        "Maoyin Chen"
      ],
      "abstract": "Deep learning has shown the great power in the field of fault detection.\nHowever, for incipient faults with tiny amplitude, the detection performance of\nthe current deep learning networks (DLNs) is not satisfactory. Even if prior\ninformation about the faults is utilized, DLNs can't successfully detect faults\n3, 9 and 15 in Tennessee Eastman process (TEP). These faults are notoriously\ndifficult to detect, lacking effective detection technologies in the field of\nfault detection. In this work, we propose Autoencoder-assisted Feature Ensemble\nNet (AE-FENet): a deep feature ensemble framework that uses the unsupervised\nautoencoder to conduct the feature transformation. Compared with the principle\ncomponent analysis (PCA) technique adopted in the original Feature Ensemble Net\n(FENet), autoencoder can mine more exact features on incipient faults, which\nresults in the better detection performance of AE-FENet. With same kinds of\nbasic detectors, AE-FENet achieves a state-of-the-art average accuracy over 96%\non faults 3, 9 and 15 in TEP, which represents a significant enhancement in\nperformance compared to other methods. Plenty of experiments have been done to\nextend our framework, proving that DLNs can be utilized efficiently within this\narchitecture.",
      "tldr_zh": "本文针对微小振幅的 incipient faults 检测难题，提出了一种新的深度学习框架 Autoencoder-assisted Feature Ensemble Net (AE-FENet)。该框架利用无监督 autoencoder 进行特征转换，取代原 Feature Ensemble Net (FENet) 中的 principal component analysis (PCA)，从而更精确地挖掘 incipient faults 的特征。实验结果显示，AE-FENet 在 Tennessee Eastman process (TEP) 的 faults 3、9 和 15 上实现了超过 96% 的平均准确率，显著优于现有方法。大量扩展实验证明了该框架在深度学习网络 (DLNs) 中的高效应用潜力。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.LG",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.13941v1",
      "published_date": "2024-04-22 07:34:28 UTC",
      "updated_date": "2024-04-22 07:34:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:39:27.255976"
    },
    {
      "arxiv_id": "2404.16068v1",
      "title": "SemEval-2024 Task 9: BRAINTEASER: A Novel Task Defying Common Sense",
      "title_zh": "翻译失败",
      "authors": [
        "Yifan Jiang",
        "Filip Ilievski",
        "Kaixin Ma"
      ],
      "abstract": "While vertical thinking relies on logical and commonsense reasoning, lateral\nthinking requires systems to defy commonsense associations and overwrite them\nthrough unconventional thinking. Lateral thinking has been shown to be\nchallenging for current models but has received little attention. A recent\nbenchmark, BRAINTEASER, aims to evaluate current models' lateral thinking\nability in a zero-shot setting. In this paper, we split the original benchmark\nto also support fine-tuning setting and present SemEval Task 9:\nBRAIN-TEASER(S), the first task at this competition designed to test the\nsystem's reasoning and lateral thinking ability. As a popular task,\nBRAINTEASER(S)'s two subtasks receive 483 team submissions from 182\nparticipants during the competition. This paper provides a fine-grained system\nanalysis of the competition results, together with a reflection on what this\nmeans for the ability of the systems to reason laterally. We hope that the\nBRAINTEASER(S) subtasks and findings in this paper can stimulate future work on\nlateral thinking and robust reasoning by computational models.",
      "tldr_zh": "这篇论文介绍了 SemEval-2024 Task 9: BRAINTEASER，一种创新任务，旨在测试系统在横向思维(lateral thinking)方面的能力，该思维需要挑战和超越常识关联，而非依赖传统的垂直思维(vertical thinking)。作者将原 BRAINTEASER 基准拆分，支持零样本(zero-shot)及微调(fine-tuning)设置，并通过两个子任务吸引了 483 支队伍的提交。实验结果分析显示，虽然当前模型在横向推理上仍面临挑战，但这项任务为未来提升计算模型的鲁棒推理和横向思维能力提供了宝贵见解。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.16068v1",
      "published_date": "2024-04-22 07:21:27 UTC",
      "updated_date": "2024-04-22 07:21:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:39:38.351430"
    },
    {
      "arxiv_id": "2404.13919v2",
      "title": "Navigating the Path of Writing: Outline-guided Text Generation with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yukyung Lee",
        "Soonwon Ka",
        "Bokyung Son",
        "Pilsung Kang",
        "Jaewook Kang"
      ],
      "abstract": "Large Language Models (LLMs) have impacted the writing process, enhancing\nproductivity by collaborating with humans in content creation platforms.\nHowever, generating high-quality, user-aligned text to satisfy real-world\ncontent creation needs remains challenging. We propose WritingPath, a framework\nthat uses explicit outlines to guide LLMs in generating goal-oriented,\nhigh-quality text. Our approach draws inspiration from structured writing\nplanning and reasoning paths, focusing on reflecting user intentions throughout\nthe writing process. To validate our approach in real-world scenarios, we\nconstruct a diverse dataset from unstructured blog posts to benchmark writing\nperformance and introduce a comprehensive evaluation framework assessing the\nquality of outlines and generated texts. Our evaluations with various LLMs\ndemonstrate that the WritingPath approach significantly enhances text quality\naccording to evaluations by both LLMs and professional writers.",
      "tldr_zh": "这篇论文提出了 WritingPath 框架，利用显式大纲来指导 Large Language Models (LLMs) 生成高质量、目标导向的文本，以解决真实内容创作中用户意图不一致的问题。该框架借鉴结构化写作规划和推理路径，确保整个写作过程反映用户意图。为验证效果，研究者构建了一个从非结构化博客帖子中提取的多样数据集，并引入了一个全面评估框架来评估大纲和生成文本的质量。实验结果显示，WritingPath 在各种 LLMs 上显著提升了文本质量，经由 LLMs 和专业作家评估证实。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "NAACL 2025 (Industry Track)",
      "pdf_url": "http://arxiv.org/pdf/2404.13919v2",
      "published_date": "2024-04-22 06:57:43 UTC",
      "updated_date": "2025-02-23 15:24:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:39:51.014684"
    },
    {
      "arxiv_id": "2404.13910v1",
      "title": "Integrated Gradient Correlation: a Dataset-wise Attribution Method",
      "title_zh": "Integrated Gradient Correlation：一种数据集级别的归因方法",
      "authors": [
        "Pierre Lelièvre",
        "Chien-Chung Chen"
      ],
      "abstract": "Attribution methods are primarily designed to study the distribution of input\ncomponent contributions to individual model predictions. However, some research\napplications require a summary of attribution patterns across the entire\ndataset to facilitate the interpretability of the scrutinized models. In this\npaper, we present a new method called Integrated Gradient Correlation (IGC)\nthat relates dataset-wise attributions to a model prediction score and enables\nregion-specific analysis by a direct summation over associated components. We\ndemonstrate our method on scalar predictions with the study of image feature\nrepresentation in the brain from fMRI neural signals and the estimation of\nneural population receptive fields (NSD dataset), as well as on categorical\npredictions with the investigation of handwritten digit recognition (MNIST\ndataset). The resulting IGC attributions show selective patterns, revealing\nunderlying model strategies coherent with their respective objectives.",
      "tldr_zh": "这篇论文提出了一种新的数据集级归因方法，Integrated Gradient Correlation (IGC)，旨在总结整个数据集上输入组件对模型预测的贡献，从而提升模型的可解释性。IGC 通过将归因与模型预测分数相关联，并进行直接求和以实现区域特定分析，适用于标量预测（如从 fMRI 神经信号研究图像特征表示和神经种群感受野的估计，基于 NSD dataset）和分类预测（如手写数字识别的调查，基于 MNIST dataset）。实验结果显示，IGC 归因揭示了选择性模式，这些模式反映了模型策略与目标的一致性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "12 pages, 8 figures, source code at\n  https://github.com/plelievre/int_grad_corr.git",
      "pdf_url": "http://arxiv.org/pdf/2404.13910v1",
      "published_date": "2024-04-22 06:42:21 UTC",
      "updated_date": "2024-04-22 06:42:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:40:03.244141"
    },
    {
      "arxiv_id": "2406.00001v1",
      "title": "PhyPlan: Generalizable and Rapid Physical Task Planning with Physics Informed Skill Networks for Robot Manipulators",
      "title_zh": "翻译失败",
      "authors": [
        "Mudit Chopra",
        "Abhinav Barnawal",
        "Harshil Vagadia",
        "Tamajit Banerjee",
        "Shreshth Tuli",
        "Souvik Chakraborty",
        "Rohan Paul"
      ],
      "abstract": "Given the task of positioning a ball-like object to a goal region beyond\ndirect reach, humans can often throw, slide, or rebound objects against the\nwall to attain the goal. However, enabling robots to reason similarly is\nnon-trivial. Existing methods for physical reasoning are data-hungry and\nstruggle with complexity and uncertainty inherent in the real world. This paper\npresents PhyPlan, a novel physics-informed planning framework that combines\nphysics-informed neural networks (PINNs) with modified Monte Carlo Tree Search\n(MCTS) to enable embodied agents to perform dynamic physical tasks. PhyPlan\nleverages PINNs to simulate and predict outcomes of actions in a fast and\naccurate manner and uses MCTS for planning. It dynamically determines whether\nto consult a PINN-based simulator (coarse but fast) or engage directly with the\nactual environment (fine but slow) to determine optimal policy. Given an unseen\ntask, PhyPlan can infer the sequence of actions and learn the latent\nparameters, resulting in a generalizable approach that can rapidly learn to\nperform novel physical tasks. Evaluation with robots in simulated 3D\nenvironments demonstrates the ability of our approach to solve 3D-physical\nreasoning tasks involving the composition of dynamic skills. Quantitatively,\nPhyPlan excels in several aspects: (i) it achieves lower regret when learning\nnovel tasks compared to the state-of-the-art, (ii) it expedites skill learning\nand enhances the speed of physical reasoning, (iii) it demonstrates higher data\nefficiency compared to a physics un-informed approach.",
      "tldr_zh": "该研究提出PhyPlan，一种基于Physics Informed Skill Networks的通用且快速物理任务规划框架，旨在帮助机器人操纵器处理动态物理任务，如投掷、滑动或反弹物体。PhyPlan结合Physics Informed Neural Networks (PINNs)进行快速模拟和预测，以及Modified Monte Carlo Tree Search (MCTS)进行规划，并动态选择使用PINNs模拟器或直接环境互动以优化策略。实验结果显示，在模拟3D环境中，PhyPlan在学习新任务时表现出更低的regret、更快的技能学习速度以及更高的数据效率，显著优于现有方法。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "arXiv admin note: substantial text overlap with arXiv:2402.15767",
      "pdf_url": "http://arxiv.org/pdf/2406.00001v1",
      "published_date": "2024-04-22 06:35:08 UTC",
      "updated_date": "2024-04-22 06:35:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:40:13.632727"
    },
    {
      "arxiv_id": "2404.13906v2",
      "title": "Generating Attractive and Authentic Copywriting from Customer Reviews",
      "title_zh": "从客户评论生成吸引人且真实的文案",
      "authors": [
        "Yu-Xiang Lin",
        "Wei-Yun Ma"
      ],
      "abstract": "The goal of product copywriting is to capture the interest of potential\nbuyers by emphasizing the features of products through text descriptions. As\ne-commerce platforms offer a wide range of services, it's becoming essential to\ndynamically adjust the styles of these auto-generated descriptions. Typical\napproaches to copywriting generation often rely solely on specified product\nattributes, which may result in dull and repetitive content. To tackle this\nissue, we propose to generate copywriting based on customer reviews, as they\nprovide firsthand practical experiences with products, offering a richer source\nof information than just product attributes. We have developed a\nsequence-to-sequence framework, enhanced with reinforcement learning, to\nproduce copywriting that is attractive, authentic, and rich in information. Our\nframework outperforms all existing baseline and zero-shot large language\nmodels, including LLaMA-2-chat-7B and GPT-3.5, in terms of both attractiveness\nand faithfulness. Furthermore, this work features the use of LLMs for\naspect-based summaries collection and argument allure assessment. Experiments\ndemonstrate the effectiveness of using LLMs for marketing domain corpus\nconstruction. The code and the dataset is publicly available at:\nhttps://github.com/YuXiangLin1234/Copywriting-Generation.",
      "tldr_zh": "该研究针对产品文案生成的问题，提出一种从客户评论中提取丰富信息的方法，以克服传统基于产品属性的文案单调重复问题。研究开发了一个增强强化学习(reinforcement learning)的序列到序列(sequence-to-sequence)框架，利用LLMs进行基于方面的摘要收集和论点吸引力评估，从而生成更吸引人、真实且信息丰富的文案。该框架在吸引力和忠实度上优于基线模型如LLaMA-2-chat-7B和GPT-3.5，实验证明其在营销领域语料构建的有效性，并公开了代码和数据集。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "NAACL 2024 main conference paper",
      "pdf_url": "http://arxiv.org/pdf/2404.13906v2",
      "published_date": "2024-04-22 06:33:28 UTC",
      "updated_date": "2024-05-14 08:05:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:40:27.155210"
    },
    {
      "arxiv_id": "2404.15155v3",
      "title": "MDAgents: An Adaptive Collaboration of LLMs for Medical Decision-Making",
      "title_zh": "MDAg",
      "authors": [
        "Yubin Kim",
        "Chanwoo Park",
        "Hyewon Jeong",
        "Yik Siu Chan",
        "Xuhai Xu",
        "Daniel McDuff",
        "Hyeonhoon Lee",
        "Marzyeh Ghassemi",
        "Cynthia Breazeal",
        "Hae Won Park"
      ],
      "abstract": "Foundation models are becoming valuable tools in medicine. Yet despite their\npromise, the best way to leverage Large Language Models (LLMs) in complex\nmedical tasks remains an open question. We introduce a novel multi-agent\nframework, named Medical Decision-making Agents (MDAgents) that helps address\nthis gap by automatically assigning a collaboration structure to a team of\nLLMs. The assigned solo or group collaboration structure is tailored to the\nmedical task at hand, emulating real-world medical decision-making processes\nadapted to tasks of varying complexities. We evaluate our framework and\nbaseline methods using state-of-the-art LLMs across a suite of real-world\nmedical knowledge and medical diagnosis benchmarks, including a comparison of\nLLMs' medical complexity classification against human physicians. MDAgents\nachieved the best performance in seven out of ten benchmarks on tasks requiring\nan understanding of medical knowledge and multi-modal reasoning, showing a\nsignificant improvement of up to 4.2% (p < 0.05) compared to previous methods'\nbest performances. Ablation studies reveal that MDAgents effectively determines\nmedical complexity to optimize for efficiency and accuracy across diverse\nmedical tasks. Notably, the combination of moderator review and external\nmedical knowledge in group collaboration resulted in an average accuracy\nimprovement of 11.8%. Our code can be found at\nhttps://github.com/mitmedialab/MDAgents.",
      "tldr_zh": "该研究引入了MDAgents，一种多智能体框架，利用大型语言模型(LLMs)实现自适应协作，以优化医疗决策过程。该框架根据任务复杂度自动分配solo或group协作结构，模拟真实医疗场景，并整合moderator review和external medical knowledge。在多项医疗知识和诊断基准测试中，MDAgents在10个基准中胜出7个，准确率较之前方法最高提升4.2%(p < 0.05)。消融研究进一步证实，该框架能有效评估医疗复杂度，提高效率和准确性，group协作模式平均提升准确率11.8%。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.15155v3",
      "published_date": "2024-04-22 06:30:05 UTC",
      "updated_date": "2024-10-30 02:32:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:40:38.443926"
    },
    {
      "arxiv_id": "2404.13899v1",
      "title": "Towards Better Text-to-Image Generation Alignment via Attention Modulation",
      "title_zh": "翻译失败",
      "authors": [
        "Yihang Wu",
        "Xiao Cao",
        "Kaixin Li",
        "Zitan Chen",
        "Haonan Wang",
        "Lei Meng",
        "Zhiyong Huang"
      ],
      "abstract": "In text-to-image generation tasks, the advancements of diffusion models have\nfacilitated the fidelity of generated results. However, these models encounter\nchallenges when processing text prompts containing multiple entities and\nattributes. The uneven distribution of attention results in the issues of\nentity leakage and attribute misalignment. Training from scratch to address\nthis issue requires numerous labeled data and is resource-consuming. Motivated\nby this, we propose an attribution-focusing mechanism, a training-free\nphase-wise mechanism by modulation of attention for diffusion model. One of our\ncore ideas is to guide the model to concentrate on the corresponding syntactic\ncomponents of the prompt at distinct timesteps. To achieve this, we incorporate\na temperature control mechanism within the early phases of the self-attention\nmodules to mitigate entity leakage issues. An object-focused masking scheme and\na phase-wise dynamic weight control mechanism are integrated into the\ncross-attention modules, enabling the model to discern the affiliation of\nsemantic information between entities more effectively. The experimental\nresults in various alignment scenarios demonstrate that our model attain better\nimage-text alignment with minimal additional computational cost.",
      "tldr_zh": "该论文针对文本到图像生成任务中，扩散模型(diffusion models)处理多实体和属性提示时存在的实体泄漏(entity leakage)和属性错位(attribute misalignment)问题，提出了一种无需额外训练的 attribution-focusing mechanism，通过注意力调制(attention modulation)来提升生成对齐。核心方法包括在自注意力(self-attention)模块的早期阶段添加温度控制机制(temperature control mechanism)以缓解实体泄漏，以及在交叉注意力(cross-attention)模块中整合对象聚焦掩码方案(object-focused masking scheme)和阶段-wise动态权重控制机制，以引导模型在不同时间步(timesteps)关注提示的语法组件。实验结果显示，该机制在各种图像-文本对齐场景中实现了显著改进，同时仅需最小额外计算成本。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.13899v1",
      "published_date": "2024-04-22 06:18:37 UTC",
      "updated_date": "2024-04-22 06:18:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:40:52.487845"
    },
    {
      "arxiv_id": "2407.01545v1",
      "title": "In the Shadow of Smith`s Invisible Hand: Risks to Economic Stability and Social Wellbeing in the Age of Intelligence",
      "title_zh": "翻译失败",
      "authors": [
        "Jo-An Occhipinti",
        "William Hynes",
        "Ante Prodan",
        "Harris A. Eyre",
        "Roy Green",
        "Sharan Burrow",
        "Marcel Tanner",
        "John Buchanan",
        "Goran Ujdur",
        "Frederic Destrebecq",
        "Christine Song",
        "Steven Carnevale",
        "Ian B. Hickie",
        "Mark Heffernan"
      ],
      "abstract": "Work is fundamental to societal prosperity and mental health, providing\nfinancial security, identity, purpose, and social integration. The emergence of\ngenerative artificial intelligence (AI) has catalysed debate on job\ndisplacement. Some argue that many new jobs and industries will emerge to\noffset the displacement, while others foresee a widespread decoupling of\neconomic productivity from human input threatening jobs on an unprecedented\nscale. This study explores the conditions under which both may be true and\nexamines the potential for a self-reinforcing cycle of recessionary pressures\nthat would necessitate sustained government intervention to maintain job\nsecurity and economic stability. A system dynamics model was developed to\nundertake ex ante analysis of the effect of AI-capital deepening on labour\nunderutilisation and demand in the economy. Results indicate that even a\nmoderate increase in the AI-capital-to-labour ratio could increase labour\nunderutilisation to double its current level, decrease per capita disposable\nincome by 26% (95% interval, 20.6% - 31.8%), and decrease the consumption index\nby 21% (95% interval, 13.6% - 28.3%) by mid-2050. To prevent a reduction in per\ncapita disposable income due to the estimated increase in underutilization, at\nleast a 10.8-fold increase in the new job creation rate would be necessary.\nResults demonstrate the feasibility of an AI-capital- to-labour ratio threshold\nbeyond which even high rates of new job creation cannot prevent declines in\nconsumption. The precise threshold will vary across economies, emphasizing the\nurgent need for empirical research tailored to specific contexts. This study\nunderscores the need for governments, civic organisations, and business to work\ntogether to ensure a smooth transition to an AI- dominated economy to safeguard\nthe Mental Wealth of nations.",
      "tldr_zh": "这篇论文探讨了生成式 AI 对就业、经济稳定和社会福祉的潜在风险，强调 AI 资本深化可能导致大规模工作岗位流失，形成自我强化的衰退循环，从而威胁人类的财务安全、身份和社会整合。研究者开发了一个系统动态模型进行 ex ante 分析，结果显示 AI-capital-to-labour 比率适度增加可能使劳动力 underutilisation 翻倍，到 2050 年中期人均可支配收入下降 26%（95% 区间 20.6%-31.8%），消费指数下降 21%（95% 区间 13.6%-28.3%）。论文指出，为了抵消这些影响，需要至少 10.8 倍的新工作创造率，并呼吁政府、公民组织和企业合作，确保向 AI 主导经济平稳过渡，以保护国家的 Mental Wealth。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "econ.GN",
        "q-fin.EC"
      ],
      "primary_category": "cs.CY",
      "comment": "10 pages, 5 figures, 1 table, an Appendix",
      "pdf_url": "http://arxiv.org/pdf/2407.01545v1",
      "published_date": "2024-04-22 06:16:48 UTC",
      "updated_date": "2024-04-22 06:16:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:41:08.856888"
    },
    {
      "arxiv_id": "2404.13892v2",
      "title": "Retrieval-Augmented Audio Deepfake Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Zuheng Kang",
        "Yayun He",
        "Botao Zhao",
        "Xiaoyang Qu",
        "Junqing Peng",
        "Jing Xiao",
        "Jianzong Wang"
      ],
      "abstract": "With recent advances in speech synthesis including text-to-speech (TTS) and\nvoice conversion (VC) systems enabling the generation of ultra-realistic audio\ndeepfakes, there is growing concern about their potential misuse. However, most\ndeepfake (DF) detection methods rely solely on the fuzzy knowledge learned by a\nsingle model, resulting in performance bottlenecks and transparency issues.\nInspired by retrieval-augmented generation (RAG), we propose a\nretrieval-augmented detection (RAD) framework that augments test samples with\nsimilar retrieved samples for enhanced detection. We also extend the\nmulti-fusion attentive classifier to integrate it with our proposed RAD\nframework. Extensive experiments show the superior performance of the proposed\nRAD framework over baseline methods, achieving state-of-the-art results on the\nASVspoof 2021 DF set and competitive results on the 2019 and 2021 LA sets.\nFurther sample analysis indicates that the retriever consistently retrieves\nsamples mostly from the same speaker with acoustic characteristics highly\nconsistent with the query audio, thereby improving detection performance.",
      "tldr_zh": "该研究针对音频深度伪造（deepfake）的日益威胁，提出了一种检索增强检测（RAD）框架，受检索增强生成（RAG）启发，将测试样本与类似检索样本结合，以提升检测性能和透明度。框架扩展了多融合注意力分类器（multi-fusion attentive classifier），通过整合检索机制来辅助分析。实验结果显示，RAD 在 ASVspoof 2021 DF 集上达到最先进水平，在 2019 和 2021 LA 集上取得竞争性表现；进一步分析表明，检索器能准确获取与查询音频高度一致的同说话者样本，从而显著改善检测准确性。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted by the 2024 International Conference on Multimedia Retrieval\n  (ICMR 2024)",
      "pdf_url": "http://arxiv.org/pdf/2404.13892v2",
      "published_date": "2024-04-22 05:46:40 UTC",
      "updated_date": "2024-04-23 04:10:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:41:18.497525"
    },
    {
      "arxiv_id": "2404.13891v2",
      "title": "Minimizing Weighted Counterfactual Regret with Optimistic Online Mirror Descent",
      "title_zh": "翻译失败",
      "authors": [
        "Hang Xu",
        "Kai Li",
        "Bingyun Liu",
        "Haobo Fu",
        "Qiang Fu",
        "Junliang Xing",
        "Jian Cheng"
      ],
      "abstract": "Counterfactual regret minimization (CFR) is a family of algorithms for\neffectively solving imperfect-information games. It decomposes the total regret\ninto counterfactual regrets, utilizing local regret minimization algorithms,\nsuch as Regret Matching (RM) or RM+, to minimize them. Recent research\nestablishes a connection between Online Mirror Descent (OMD) and RM+, paving\nthe way for an optimistic variant PRM+ and its extension PCFR+. However, PCFR+\nassigns uniform weights for each iteration when determining regrets, leading to\nsubstantial regrets when facing dominated actions. This work explores\nminimizing weighted counterfactual regret with optimistic OMD, resulting in a\nnovel CFR variant PDCFR+. It integrates PCFR+ and Discounted CFR (DCFR) in a\nprincipled manner, swiftly mitigating negative effects of dominated actions and\nconsistently leveraging predictions to accelerate convergence. Theoretical\nanalyses prove that PDCFR+ converges to a Nash equilibrium, particularly under\ndistinct weighting schemes for regrets and average strategies. Experimental\nresults demonstrate PDCFR+'s fast convergence in common imperfect-information\ngames. The code is available at https://github.com/rpSebastian/PDCFRPlus.",
      "tldr_zh": "这篇论文针对不完美信息游戏中的 Counterfactual Regret Minimization (CFR) 算法，提出了一种新变体 PDCFR+，通过乐观 Online Mirror Descent (OMD) 来最小化加权反事实遗憾。PDCFR+ 结合了 PCFR+ 和 Discounted CFR (DCFR)，有效减轻主导行动的负面影响，并利用预测加速算法收敛。理论分析证明，PDCFR+ 在不同加权方案下能收敛到 Nash equilibrium，实验结果显示其在常见不完美信息游戏中表现出快速收敛优势。代码已在 GitHub 上公开。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.GT"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to 33rd International Joint Conference on Artificial\n  Intelligence (IJCAI 2024)",
      "pdf_url": "http://arxiv.org/pdf/2404.13891v2",
      "published_date": "2024-04-22 05:37:22 UTC",
      "updated_date": "2024-05-14 09:16:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:41:32.599058"
    },
    {
      "arxiv_id": "2404.13885v2",
      "title": "Surveying Attitudinal Alignment Between Large Language Models Vs. Humans Towards 17 Sustainable Development Goals",
      "title_zh": "翻译失败",
      "authors": [
        "Qingyang Wu",
        "Ying Xu",
        "Tingsong Xiao",
        "Yunze Xiao",
        "Yitong Li",
        "Tianyang Wang",
        "Yichi Zhang",
        "Shanghai Zhong",
        "Yuwei Zhang",
        "Wei Lu",
        "Yifan Yang"
      ],
      "abstract": "Large Language Models (LLMs) have emerged as potent tools for advancing the\nUnited Nations' Sustainable Development Goals (SDGs). However, the attitudinal\ndisparities between LLMs and humans towards these goals can pose significant\nchallenges. This study conducts a comprehensive review and analysis of the\nexisting literature on the attitudes of LLMs towards the 17 SDGs, emphasizing\nthe comparison between their attitudes and support for each goal and those of\nhumans. We examine the potential disparities, primarily focusing on aspects\nsuch as understanding and emotions, cultural and regional differences, task\nobjective variations, and factors considered in the decision-making process.\nThese disparities arise from the underrepresentation and imbalance in LLM\ntraining data, historical biases, quality issues, lack of contextual\nunderstanding, and skewed ethical values reflected. The study also investigates\nthe risks and harms that may arise from neglecting the attitudes of LLMs\ntowards the SDGs, including the exacerbation of social inequalities, racial\ndiscrimination, environmental destruction, and resource wastage. To address\nthese challenges, we propose strategies and recommendations to guide and\nregulate the application of LLMs, ensuring their alignment with the principles\nand goals of the SDGs, and therefore creating a more just, inclusive, and\nsustainable future.",
      "tldr_zh": "本研究调查了大型语言模型 (LLMs) 与人类在 17 个可持续发展目标 (SDGs) 上的态度差异，通过文献回顾和比较分析，探讨了理解、情感、文化差异、任务目标变异以及决策因素等方面的不一致。这些差异主要源于 LLMs 训练数据的代表性不足、历史偏差、质量问题、缺乏上下文理解和偏斜的伦理价值观，可能导致社会不平等、种族歧视、环境破坏和资源浪费等风险。为应对这些挑战，论文提出策略和推荐，以指导 LLMs 的应用，确保其与 SDGs 原则对齐，促进更公正、包容和可持续的未来。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.13885v2",
      "published_date": "2024-04-22 05:12:52 UTC",
      "updated_date": "2025-01-16 02:45:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:41:42.134715"
    },
    {
      "arxiv_id": "2404.14461v2",
      "title": "Competition Report: Finding Universal Jailbreak Backdoors in Aligned LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Javier Rando",
        "Francesco Croce",
        "Kryštof Mitka",
        "Stepan Shabalin",
        "Maksym Andriushchenko",
        "Nicolas Flammarion",
        "Florian Tramèr"
      ],
      "abstract": "Large language models are aligned to be safe, preventing users from\ngenerating harmful content like misinformation or instructions for illegal\nactivities. However, previous work has shown that the alignment process is\nvulnerable to poisoning attacks. Adversaries can manipulate the safety training\ndata to inject backdoors that act like a universal sudo command: adding the\nbackdoor string to any prompt enables harmful responses from models that,\notherwise, behave safely. Our competition, co-located at IEEE SaTML 2024,\nchallenged participants to find universal backdoors in several large language\nmodels. This report summarizes the key findings and promising ideas for future\nresearch.",
      "tldr_zh": "这篇报告探讨了在对齐的大型语言模型(aligned LLMs)中发现通用后门(jailbreak backdoors)的竞争问题，这些后门通过投毒攻击(poisoning attacks)注入训练数据，能像通用sudo命令一样，让模型在添加特定字符串后生成有害内容，如错误信息或非法指令。比赛在IEEE SaTML 2024上举行，挑战参与者识别这些后门，以评估模型的安全漏洞。关键发现包括后门的有效性和潜在风险，为未来研究提供了有前景的想法，以提升LLMs的安全性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Competition Report",
      "pdf_url": "http://arxiv.org/pdf/2404.14461v2",
      "published_date": "2024-04-22 05:08:53 UTC",
      "updated_date": "2024-06-06 12:45:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:41:53.499533"
    },
    {
      "arxiv_id": "2404.13880v4",
      "title": "Regional Style and Color Transfer",
      "title_zh": "区域风格转移与颜色转移",
      "authors": [
        "Zhicheng Ding",
        "Panfeng Li",
        "Qikai Yang",
        "Siyang Li",
        "Qingtian Gong"
      ],
      "abstract": "This paper presents a novel contribution to the field of regional style\ntransfer. Existing methods often suffer from the drawback of applying style\nhomogeneously across the entire image, leading to stylistic inconsistencies or\nforeground object twisted when applied to image with foreground elements such\nas person figures. To address this limitation, we propose a new approach that\nleverages a segmentation network to precisely isolate foreground objects within\nthe input image. Subsequently, style transfer is applied exclusively to the\nbackground region. The isolated foreground objects are then carefully\nreintegrated into the style-transferred background. To enhance the visual\ncoherence between foreground and background, a color transfer step is employed\non the foreground elements prior to their rein-corporation. Finally, we utilize\nfeathering techniques to achieve a seamless amalgamation of foreground and\nbackground, resulting in a visually unified and aesthetically pleasing final\ncomposition. Extensive evaluations demonstrate that our proposed approach\nyields significantly more natural stylistic transformations compared to\nconventional methods.",
      "tldr_zh": "本文提出了一种新的区域风格转移方法，以解决现有 style transfer 技术在处理包含前景对象（如人物）图像时，导致风格不一致或前景扭曲的问题。方法包括使用 segmentation network 隔离前景对象，仅对背景区域应用 style transfer，随后通过 color transfer 增强前景与背景的视觉一致性，并采用 feathering 技术实现无缝融合。实验评估显示，该方法比传统方法产生更自然且美观的风格转换结果。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by 2024 5th International Conference on Computer Vision,\n  Image and Deep Learning",
      "pdf_url": "http://arxiv.org/pdf/2404.13880v4",
      "published_date": "2024-04-22 05:07:02 UTC",
      "updated_date": "2024-11-13 18:31:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:42:04.252873"
    },
    {
      "arxiv_id": "2404.13859v3",
      "title": "Unveiling and Mitigating Generalized Biases of DNNs through the Intrinsic Dimensions of Perceptual Manifolds",
      "title_zh": "翻译失败",
      "authors": [
        "Yanbiao Ma",
        "Licheng Jiao",
        "Fang Liu",
        "Lingling Li",
        "Wenping Ma",
        "Shuyuan Yang",
        "Xu Liu",
        "Puhua Chen"
      ],
      "abstract": "Building fair deep neural networks (DNNs) is a crucial step towards achieving\ntrustworthy artificial intelligence. Delving into deeper factors that affect\nthe fairness of DNNs is paramount and serves as the foundation for mitigating\nmodel biases. However, current methods are limited in accurately predicting DNN\nbiases, relying solely on the number of training samples and lacking more\nprecise measurement tools. Here, we establish a geometric perspective for\nanalyzing the fairness of DNNs, comprehensively exploring how DNNs internally\nshape the intrinsic geometric characteristics of datasets-the intrinsic\ndimensions (IDs) of perceptual manifolds, and the impact of IDs on the fairness\nof DNNs. Based on multiple findings, we propose Intrinsic Dimension\nRegularization (IDR), which enhances the fairness and performance of models by\npromoting the learning of concise and ID-balanced class perceptual manifolds.\nIn various image recognition benchmark tests, IDR significantly mitigates model\nbias while improving its performance.",
      "tldr_zh": "这篇论文从几何视角分析深度神经网络 (DNNs) 的公平性，探讨了 DNNs 如何通过感知流形的内在维度 (IDs) 塑造数据集的内在几何特性，并揭示 IDs 对模型偏差的影响。作者提出 Intrinsic Dimension Regularization (IDR) 方法，通过促进简洁且 IDs 平衡的类感知流形学习，来缓解 DNNs 的泛化偏差并提升模型性能。在各种图像识别基准测试中，IDR 显著降低了模型偏差，同时改善了整体表现。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "8pages, 6figures, Submitted to TPAMI",
      "pdf_url": "http://arxiv.org/pdf/2404.13859v3",
      "published_date": "2024-04-22 04:16:40 UTC",
      "updated_date": "2024-11-02 09:42:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:42:18.024031"
    },
    {
      "arxiv_id": "2405.01573v2",
      "title": "Class-Level Code Generation from Natural Language Using Iterative, Tool-Enhanced Reasoning over Repository",
      "title_zh": "翻译失败",
      "authors": [
        "Ajinkya Deshpande",
        "Anmol Agarwal",
        "Shashank Shet",
        "Arun Iyer",
        "Aditya Kanade",
        "Ramakrishna Bairi",
        "Suresh Parthasarathy"
      ],
      "abstract": "LLMs have demonstrated significant potential in code generation tasks,\nachieving promising results at the function or statement level across various\nbenchmarks. However, the complexities associated with creating code artifacts\nlike classes, particularly within the context of real-world software\nrepositories, remain underexplored. Prior research treats class-level\ngeneration as an isolated task, neglecting the intricate dependencies &\ninteractions that characterize real-world software environments. To address\nthis gap, we introduce RepoClassBench, a comprehensive benchmark designed to\nrigorously evaluate LLMs in generating complex, class-level code within\nreal-world repositories. RepoClassBench includes \"Natural Language to Class\ngeneration\" tasks across Java, Python & C# from a selection of repositories. We\nensure that each class in our dataset not only has cross-file dependencies\nwithin the repository but also includes corresponding test cases to verify its\nfunctionality. We find that current models struggle with the realistic\nchallenges posed by our benchmark, primarily due to their limited exposure to\nrelevant repository contexts. To address this shortcoming, we introduce\nRetrieve-Repotools-Reflect (RRR), a novel approach that equips LLMs with static\nanalysis tools to iteratively navigate & reason about repository-level context\nin an agent-based framework. Our experiments demonstrate that RRR significantly\noutperforms existing baselines on RepoClassBench, showcasing its effectiveness\nacross programming languages & under various settings. Our findings emphasize\nthe critical need for code-generation benchmarks to incorporate repo-level\ndependencies to more accurately reflect the complexities of software\ndevelopment. Our work shows the benefits of leveraging specialized tools to\nenhance LLMs' understanding of repository context. We plan to make our dataset\n& evaluation harness public.",
      "tldr_zh": "本文研究了大型语言模型（LLMs）在类级别代码生成中的挑战，指出现有模型在处理真实软件仓库的依赖性和交互时表现不足。为此，作者引入了RepoClassBench基准，该基准涵盖Java、Python和C#的自然语言到类生成任务，并包括跨文件依赖和测试用例。论文提出RRR（Retrieve-Repotools-Reflect）方法，通过代理框架中的迭代检索、工具增强推理和反思，帮助LLMs更好地理解仓库上下文。实验结果显示，RRR在RepoClassBench上显著优于基线模型，证明了工具增强在提升代码生成准确性和软件开发复杂性处理方面的有效性。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "Preprint with additional experiments",
      "pdf_url": "http://arxiv.org/pdf/2405.01573v2",
      "published_date": "2024-04-22 03:52:54 UTC",
      "updated_date": "2024-06-05 17:44:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:42:31.055269"
    },
    {
      "arxiv_id": "2404.13846v4",
      "title": "Filtered Direct Preference Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Tetsuro Morimura",
        "Mitsuki Sakamoto",
        "Yuu Jinnai",
        "Kenshi Abe",
        "Kaito Ariu"
      ],
      "abstract": "Reinforcement learning from human feedback (RLHF) plays a crucial role in\naligning language models with human preferences. While the significance of\ndataset quality is generally recognized, explicit investigations into its\nimpact within the RLHF framework, to our knowledge, have been limited. This\npaper addresses the issue of text quality within the preference dataset by\nfocusing on direct preference optimization (DPO), an increasingly adopted\nreward-model-free RLHF method. We confirm that text quality significantly\ninfluences the performance of models optimized with DPO more than those\noptimized with reward-model-based RLHF. Building on this new insight, we\npropose an extension of DPO, termed filtered direct preference optimization\n(fDPO). fDPO uses a trained reward model to monitor the quality of texts within\nthe preference dataset during DPO training. Samples of lower quality are\ndiscarded based on comparisons with texts generated by the model being\noptimized, resulting in a more accurate dataset. Experimental results\ndemonstrate that fDPO enhances the final model performance. Our code is\navailable at https://github.com/CyberAgentAILab/filtered-dpo.",
      "tldr_zh": "这项研究探讨了基于人类反馈的强化学习（RLHF）中数据集质量对语言模型对齐的影响，发现文本质量对直接偏好优化（DPO）方法的影响远大于基于奖励模型的RLHF方法。为此，研究提出了一种扩展的DPO变体——filtered direct preference optimization（fDPO），它利用训练好的奖励模型监控和过滤偏好数据集中的低质量文本，通过与模型生成文本的比较来丢弃不准确样本，从而提升数据集质量。实验结果显示，fDPO显著提高了最终模型的性能，为RLHF框架的优化提供了新见解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "EMNLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.13846v4",
      "published_date": "2024-04-22 03:05:19 UTC",
      "updated_date": "2024-12-03 17:22:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:42:41.561799"
    },
    {
      "arxiv_id": "2404.13844v1",
      "title": "ColA: Collaborative Adaptation with Gradient Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Enmao Diao",
        "Qi Le",
        "Suya Wu",
        "Xinran Wang",
        "Ali Anwar",
        "Jie Ding",
        "Vahid Tarokh"
      ],
      "abstract": "A primary function of back-propagation is to compute both the gradient of\nhidden representations and parameters for optimization with gradient descent.\nTraining large models requires high computational costs due to their vast\nparameter sizes. While Parameter-Efficient Fine-Tuning (PEFT) methods aim to\ntrain smaller auxiliary models to save computational space, they still present\ncomputational overheads, especially in Fine-Tuning as a Service (FTaaS) for\nnumerous users. We introduce Collaborative Adaptation (ColA) with Gradient\nLearning (GL), a parameter-free, model-agnostic fine-tuning approach that\ndecouples the computation of the gradient of hidden representations and\nparameters. In comparison to PEFT methods, ColA facilitates more cost-effective\nFTaaS by offloading the computation of the gradient to low-cost devices. We\nalso provide a theoretical analysis of ColA and experimentally demonstrate that\nColA can perform on par or better than existing PEFT methods on various\nbenchmarks.",
      "tldr_zh": "本文提出 ColA（Collaborative Adaptation with Gradient Learning），一种无参数、模型无关的微调方法，通过分离隐藏表示和参数的梯度计算，降低了训练大模型的计算开销，尤其适用于 Fine-Tuning as a Service (FTaaS)。相比于 Parameter-Efficient Fine-Tuning (PEFT) 方法，ColA 能将梯度计算转移到低成本设备，从而实现更具成本效益的优化。实验和理论分析表明，ColA 在各种基准上表现与 PEFT 方法相当或更好，为高效模型微调提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.13844v1",
      "published_date": "2024-04-22 02:52:54 UTC",
      "updated_date": "2024-04-22 02:52:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:42:55.132085"
    },
    {
      "arxiv_id": "2404.13841v1",
      "title": "Fair Concurrent Training of Multiple Models in Federated Learning",
      "title_zh": "联邦学习中多模型的公平并发训练",
      "authors": [
        "Marie Siew",
        "Haoran Zhang",
        "Jong-Ik Park",
        "Yuezhou Liu",
        "Yichen Ruan",
        "Lili Su",
        "Stratis Ioannidis",
        "Edmund Yeh",
        "Carlee Joe-Wong"
      ],
      "abstract": "Federated learning (FL) enables collaborative learning across multiple\nclients. In most FL work, all clients train a single learning task. However,\nthe recent proliferation of FL applications may increasingly require multiple\nFL tasks to be trained simultaneously, sharing clients' computing and\ncommunication resources, which we call Multiple-Model Federated Learning\n(MMFL). Current MMFL algorithms use naive average-based client-task allocation\nschemes that can lead to unfair performance when FL tasks have heterogeneous\ndifficulty levels, e.g., tasks with larger models may need more rounds and data\nto train. Just as naively allocating resources to generic computing jobs with\nheterogeneous resource needs can lead to unfair outcomes, naive allocation of\nclients to FL tasks can lead to unfairness, with some tasks having excessively\nlong training times, or lower converged accuracies. Furthermore, in the FL\nsetting, since clients are typically not paid for their training effort, we\nface a further challenge that some clients may not even be willing to train\nsome tasks, e.g., due to high computational costs, which may exacerbate\nunfairness in training outcomes across tasks. We address both challenges by\nfirstly designing FedFairMMFL, a difficulty-aware algorithm that dynamically\nallocates clients to tasks in each training round. We provide guarantees on\nairness and FedFairMMFL's convergence rate. We then propose a novel auction\ndesign that incentivizes clients to train multiple tasks, so as to fairly\ndistribute clients' training efforts across the tasks. We show how our\nfairness-based learning and incentive mechanisms impact training convergence\nand finally evaluate our algorithm with multiple sets of learning tasks on real\nworld datasets.",
      "tldr_zh": "本研究探讨了 Federated Learning (FL) 中的 Multiple-Model Federated Learning (MMFL)，即多个 FL 任务同时训练时，由于任务难度异构导致的资源分配不公平问题，例如某些任务训练时间过长或准确率较低。论文提出 FedFairMMFL 算法，这是一种基于任务难度的动态客户端分配机制，并提供公平性保证和收敛率分析，以优化训练过程。同时，引入了一个新型拍卖设计来激励客户端参与多个任务的训练。实验结果显示，该算法在真实数据集上的多任务集测试中显著提高了公平性和训练收敛性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.13841v1",
      "published_date": "2024-04-22 02:41:10 UTC",
      "updated_date": "2024-04-22 02:41:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:43:08.266974"
    },
    {
      "arxiv_id": "2404.15159v3",
      "title": "MixLoRA: Enhancing Large Language Models Fine-Tuning with LoRA-based Mixture of Experts",
      "title_zh": "翻译失败",
      "authors": [
        "Dengchun Li",
        "Yingzi Ma",
        "Naizheng Wang",
        "Zhengmao Ye",
        "Zhiyuan Cheng",
        "Yinghao Tang",
        "Yan Zhang",
        "Lei Duan",
        "Jie Zuo",
        "Cal Yang",
        "Mingjie Tang"
      ],
      "abstract": "Fine-tuning Large Language Models (LLMs) is a common practice to adapt\npre-trained models for specific applications. While methods like LoRA have\neffectively addressed GPU memory constraints during fine-tuning, their\nperformance often falls short, especially in multi-task scenarios. In contrast,\nMixture-of-Expert (MoE) models, such as Mixtral 8x7B, demonstrate remarkable\nperformance in multi-task learning scenarios while maintaining a reduced\nparameter count. However, the resource requirements of these MoEs remain\nchallenging, particularly for consumer-grade GPUs with less than 24GB memory.\nTo tackle these challenges, we propose MixLoRA, an approach to construct a\nresource-efficient sparse MoE model based on LoRA. MixLoRA inserts multiple\nLoRA-based experts within the feed-forward network block of a frozen\npre-trained dense model and employs a commonly used top-k router. Unlike other\nLoRA-based MoE methods, MixLoRA enhances model performance by utilizing\nindependent attention-layer LoRA adapters. Additionally, an auxiliary load\nbalance loss is employed to address the imbalance problem of the router. Our\nevaluations show that MixLoRA improves about 9% accuracy compared to\nstate-of-the-art PEFT methods in multi-task learning scenarios. We also propose\na new high-throughput framework to alleviate the computation and memory\nbottlenecks during the training and inference of MOE models. This framework\nreduces GPU memory consumption by 40% and token computation latency by 30%\nduring both training and inference.",
      "tldr_zh": "该论文提出 MixLoRA，一种基于 LoRA 的 Mixture of Experts (MoE) 方法，用于提升大语言模型 (LLMs) 在多任务场景下的细调性能，同时解决 LoRA 方法的性能不足和资源消耗问题。MixLoRA 在冻结的预训练稠密模型的 feed-forward 网络块中插入多个 LoRA-based experts，并采用 top-k router 以及辅助 load balance loss 来优化路由均衡和模型表现。实验结果显示，MixLoRA 比现有 PEFT 方法提高约 9% 准确率；此外，论文还引入一个新高吞吐框架，减少 40% GPU 内存消耗和 30% token 计算延迟。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "18 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.15159v3",
      "published_date": "2024-04-22 02:15:52 UTC",
      "updated_date": "2024-07-20 02:26:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:43:22.545271"
    },
    {
      "arxiv_id": "2404.13813v1",
      "title": "From LLM to NMT: Advancing Low-Resource Machine Translation with Claude",
      "title_zh": "翻译失败",
      "authors": [
        "Maxim Enis",
        "Mark Hopkins"
      ],
      "abstract": "We show that Claude 3 Opus, a large language model (LLM) released by\nAnthropic in March 2024, exhibits stronger machine translation competence than\nother LLMs. Though we find evidence of data contamination with Claude on\nFLORES-200, we curate new benchmarks that corroborate the effectiveness of\nClaude for low-resource machine translation into English. We find that Claude\nhas remarkable \\textit{resource efficiency} -- the degree to which the quality\nof the translation model depends on a language pair's resource level. Finally,\nwe show that advancements in LLM translation can be compressed into traditional\nneural machine translation (NMT) models. Using Claude to generate synthetic\ndata, we demonstrate that knowledge distillation advances the state-of-the-art\nin Yoruba-English translation, meeting or surpassing strong baselines like\nNLLB-54B and Google Translate.",
      "tldr_zh": "该研究发现，Anthropic 发布的 Claude 3 Opus LLM 在机器翻译方面表现出色，尤其在低资源语言对的翻译中，优于其他 LLM，尽管存在 FLORES-200 数据污染证据。研究通过新基准测试验证了 Claude 的资源效率（resource efficiency），并使用它生成合成数据进行知识蒸馏（knowledge distillation）到传统 NMT（Neural Machine Translation）模型中。最终，结果显示这种方法在 Yoruba-English 翻译上达到了或超过了 NLLB-54B 和 Google Translate 等强基线水平，推动了低资源机器翻译的进展。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "17 pages, 15 figures",
      "pdf_url": "http://arxiv.org/pdf/2404.13813v1",
      "published_date": "2024-04-22 01:22:23 UTC",
      "updated_date": "2024-04-22 01:22:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:43:32.097188"
    },
    {
      "arxiv_id": "2404.13812v4",
      "title": "A Comparative Study on Enhancing Prediction in Social Network Advertisement through Data Augmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Qikai Yang",
        "Panfeng Li",
        "Xinhe Xu",
        "Zhicheng Ding",
        "Wenjing Zhou",
        "Yi Nian"
      ],
      "abstract": "In the ever-evolving landscape of social network advertising, the volume and\naccuracy of data play a critical role in the performance of predictive models.\nHowever, the development of robust predictive algorithms is often hampered by\nthe limited size and potential bias present in real-world datasets. This study\npresents and explores a generative augmentation framework of social network\nadvertising data. Our framework explores three generative models for data\naugmentation - Generative Adversarial Networks (GANs), Variational Autoencoders\n(VAEs), and Gaussian Mixture Models (GMMs) - to enrich data availability and\ndiversity in the context of social network advertising analytics effectiveness.\nBy performing synthetic extensions of the feature space, we find that through\ndata augmentation, the performance of various classifiers has been\nquantitatively improved. Furthermore, we compare the relative performance gains\nbrought by each data augmentation technique, providing insights for\npractitioners to select appropriate techniques to enhance model performance.\nThis paper contributes to the literature by showing that synthetic data\naugmentation alleviates the limitations imposed by small or imbalanced datasets\nin the field of social network advertising. At the same time, this article also\nprovides a comparative perspective on the practicality of different data\naugmentation methods, thereby guiding practitioners to choose appropriate\ntechniques to enhance model performance.",
      "tldr_zh": "这篇论文比较了通过数据增强技术提升社交网络广告预测性能的方法，针对真实数据集规模有限和偏差问题，提出了一种生成式增强框架。框架利用 Generative Adversarial Networks (GANs)、Variational Autoencoders (VAEs) 和 Gaussian Mixture Models (GMMs) 等模型生成合成数据，以扩展特征空间并改善分类器的表现。研究发现，这些技术量化提高了模型性能，并通过比较不同方法的相对优势，为从业者提供选择合适数据增强策略的实用指导。",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.SI",
      "comment": "Accepted by 2024 4th International Conference on Machine Learning and\n  Intelligent Systems Engineering (MLISE)",
      "pdf_url": "http://arxiv.org/pdf/2404.13812v4",
      "published_date": "2024-04-22 01:16:11 UTC",
      "updated_date": "2024-11-12 07:44:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:43:43.450769"
    },
    {
      "arxiv_id": "2404.15157v1",
      "title": "FASTTRACK: Fast and Accurate Fact Tracing for LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Si Chen",
        "Feiyang Kang",
        "Ning Yu",
        "Ruoxi Jia"
      ],
      "abstract": "Fact tracing seeks to identify specific training examples that serve as the\nknowledge source for a given query. Existing approaches to fact tracing rely on\nassessing the similarity between each training sample and the query along a\ncertain dimension, such as lexical similarity, gradient, or embedding space.\nHowever, these methods fall short of effectively distinguishing between samples\nthat are merely relevant and those that actually provide supportive evidence\nfor the information sought by the query. This limitation often results in\nsuboptimal effectiveness. Moreover, these approaches necessitate the\nexamination of the similarity of individual training points for each query,\nimposing significant computational demands and creating a substantial barrier\nfor practical applications. This paper introduces FASTTRACK, a novel approach\nthat harnesses the capabilities of Large Language Models (LLMs) to validate\nsupportive evidence for queries and at the same time clusters the training\ndatabase towards a reduced extent for LLMs to trace facts. Our experiments show\nthat FASTTRACK substantially outperforms existing methods in both accuracy and\nefficiency, achieving more than 100\\% improvement in F1 score over the\nstate-of-the-art methods while being X33 faster than \\texttt{TracIn}.",
      "tldr_zh": "本文提出 FASTTRACK，一种新型事实追踪方法，用于 LLMs（Large Language Models），旨在解决现有方法在区分相关样本与支持证据样本时的准确性不足和计算效率低的问题。FASTTRACK 通过利用 LLMs 验证查询的支持证据，并对训练数据库进行聚类，从而减少追踪范围并提升整体性能。实验结果显示，该方法在 F1 分数上比最先进方法提高超过 100%，且比 TracIn 快 33 倍，显著改善了事实追踪的准确性和效率。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.15157v1",
      "published_date": "2024-04-22 00:07:55 UTC",
      "updated_date": "2024-04-22 00:07:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T02:43:56.665722"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 85,
  "processed_papers_count": 85,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-18T02:44:20.628056"
}