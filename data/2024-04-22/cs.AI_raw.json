[
  {
    "arxiv_id": "2405.00704v2",
    "title": "A Survey on the Real Power of ChatGPT",
    "authors": [
      "Ming Liu",
      "Ran Liu",
      "Ye Zhu",
      "Hua Wang",
      "Youyang Qu",
      "Rongsheng Li",
      "Yongpan Sheng",
      "Wray Buntine"
    ],
    "abstract": "ChatGPT has changed the AI community and an active research line is the\nperformance evaluation of ChatGPT. A key challenge for the evaluation is that\nChatGPT is still closed-source and traditional benchmark datasets may have been\nused by ChatGPT as the training data. In this paper, (i) we survey recent\nstudies which uncover the real performance levels of ChatGPT in seven\ncategories of NLP tasks, (ii) review the social implications and safety issues\nof ChatGPT, and (iii) emphasize key challenges and opportunities for its\nevaluation. We hope our survey can shed some light on its blackbox manner, so\nthat researchers are not misleaded by its surface generation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "18 pages, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2405.00704v2",
    "published_date": "2024-04-22 23:31:28 UTC",
    "updated_date": "2024-05-10 02:38:28 UTC"
  },
  {
    "arxiv_id": "2404.16069v1",
    "title": "Interactive Visual Learning for Stable Diffusion",
    "authors": [
      "Seongmin Lee",
      "Benjamin Hoover",
      "Hendrik Strobelt",
      "Zijie J. Wang",
      "ShengYun Peng",
      "Austin Wright",
      "Kevin Li",
      "Haekyu Park",
      "Haoyang Yang",
      "Polo Chau"
    ],
    "abstract": "Diffusion-based generative models' impressive ability to create convincing\nimages has garnered global attention. However, their complex internal\nstructures and operations often pose challenges for non-experts to grasp. We\nintroduce Diffusion Explainer, the first interactive visualization tool\ndesigned to elucidate how Stable Diffusion transforms text prompts into images.\nIt tightly integrates a visual overview of Stable Diffusion's complex\ncomponents with detailed explanations of their underlying operations. This\nintegration enables users to fluidly transition between multiple levels of\nabstraction through animations and interactive elements. Offering real-time\nhands-on experience, Diffusion Explainer allows users to adjust Stable\nDiffusion's hyperparameters and prompts without the need for installation or\nspecialized hardware. Accessible via users' web browsers, Diffusion Explainer\nis making significant strides in democratizing AI education, fostering broader\npublic access. More than 7,200 users spanning 113 countries have used our\nopen-sourced tool at https://poloclub.github.io/diffusion-explainer/. A video\ndemo is available at https://youtu.be/MbkIADZjPnA.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "4 pages, 3 figures. arXiv admin note: substantial text overlap with\n  arXiv:2305.03509",
    "pdf_url": "http://arxiv.org/pdf/2404.16069v1",
    "published_date": "2024-04-22 23:23:45 UTC",
    "updated_date": "2024-04-22 23:23:45 UTC"
  },
  {
    "arxiv_id": "2404.14619v2",
    "title": "OpenELM: An Efficient Language Model Family with Open Training and Inference Framework",
    "authors": [
      "Sachin Mehta",
      "Mohammad Hossein Sekhavat",
      "Qingqing Cao",
      "Maxwell Horton",
      "Yanzi Jin",
      "Chenfan Sun",
      "Iman Mirzadeh",
      "Mahyar Najibi",
      "Dmitry Belenko",
      "Peter Zatloukal",
      "Mohammad Rastegari"
    ],
    "abstract": "The reproducibility and transparency of large language models are crucial for\nadvancing open research, ensuring the trustworthiness of results, and enabling\ninvestigations into data and model biases, as well as potential risks. To this\nend, we release OpenELM, a state-of-the-art open language model. OpenELM uses a\nlayer-wise scaling strategy to efficiently allocate parameters within each\nlayer of the transformer model, leading to enhanced accuracy. For example, with\na parameter budget of approximately one billion parameters, OpenELM exhibits a\n2.36% improvement in accuracy compared to OLMo while requiring $2\\times$ fewer\npre-training tokens.\n  Diverging from prior practices that only provide model weights and inference\ncode, and pre-train on private datasets, our release includes the complete\nframework for training and evaluation of the language model on publicly\navailable datasets, including training logs, multiple checkpoints, and\npre-training configurations. We also release code to convert models to MLX\nlibrary for inference and fine-tuning on Apple devices. This comprehensive\nrelease aims to empower and strengthen the open research community, paving the\nway for future open research endeavors.\n  Our source code along with pre-trained model weights and training recipes is\navailable at \\url{https://github.com/apple/corenet}. Additionally, \\model\nmodels can be found on HuggingFace at:\n\\url{https://huggingface.co/apple/OpenELM}.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Minor corrections",
    "pdf_url": "http://arxiv.org/pdf/2404.14619v2",
    "published_date": "2024-04-22 23:12:03 UTC",
    "updated_date": "2024-05-02 00:30:57 UTC"
  },
  {
    "arxiv_id": "2404.14618v1",
    "title": "Hybrid LLM: Cost-Efficient and Quality-Aware Query Routing",
    "authors": [
      "Dujian Ding",
      "Ankur Mallick",
      "Chi Wang",
      "Robert Sim",
      "Subhabrata Mukherjee",
      "Victor Ruhle",
      "Laks V. S. Lakshmanan",
      "Ahmed Hassan Awadallah"
    ],
    "abstract": "Large language models (LLMs) excel in most NLP tasks but also require\nexpensive cloud servers for deployment due to their size, while smaller models\nthat can be deployed on lower cost (e.g., edge) devices, tend to lag behind in\nterms of response quality. Therefore in this work we propose a hybrid inference\napproach which combines their respective strengths to save cost and maintain\nquality. Our approach uses a router that assigns queries to the small or large\nmodel based on the predicted query difficulty and the desired quality level.\nThe desired quality level can be tuned dynamically at test time to seamlessly\ntrade quality for cost as per the scenario requirements. In experiments our\napproach allows us to make up to 40% fewer calls to the large model, with no\ndrop in response quality.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to ICLR 2024 (main conference)",
    "pdf_url": "http://arxiv.org/pdf/2404.14618v1",
    "published_date": "2024-04-22 23:06:42 UTC",
    "updated_date": "2024-04-22 23:06:42 UTC"
  },
  {
    "arxiv_id": "2404.16879v1",
    "title": "Learning Control Barrier Functions and their application in Reinforcement Learning: A Survey",
    "authors": [
      "Maeva Guerrier",
      "Hassan Fouad",
      "Giovanni Beltrame"
    ],
    "abstract": "Reinforcement learning is a powerful technique for developing new robot\nbehaviors. However, typical lack of safety guarantees constitutes a hurdle for\nits practical application on real robots. To address this issue, safe\nreinforcement learning aims to incorporate safety considerations, enabling\nfaster transfer to real robots and facilitating lifelong learning. One\npromising approach within safe reinforcement learning is the use of control\nbarrier functions. These functions provide a framework to ensure that the\nsystem remains in a safe state during the learning process. However,\nsynthesizing control barrier functions is not straightforward and often\nrequires ample domain knowledge. This challenge motivates the exploration of\ndata-driven methods for automatically defining control barrier functions, which\nis highly appealing. We conduct a comprehensive review of the existing\nliterature on safe reinforcement learning using control barrier functions.\nAdditionally, we investigate various techniques for automatically learning the\nControl Barrier Functions, aiming to enhance the safety and efficacy of\nReinforcement Learning in practical robot applications.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.16879v1",
    "published_date": "2024-04-22 22:52:14 UTC",
    "updated_date": "2024-04-22 22:52:14 UTC"
  },
  {
    "arxiv_id": "2404.14606v2",
    "title": "Cross-Task Multi-Branch Vision Transformer for Facial Expression and Mask Wearing Classification",
    "authors": [
      "Armando Zhu",
      "Keqin Li",
      "Tong Wu",
      "Peng Zhao",
      "Bo Hong"
    ],
    "abstract": "With wearing masks becoming a new cultural norm, facial expression\nrecognition (FER) while taking masks into account has become a significant\nchallenge. In this paper, we propose a unified multi-branch vision transformer\nfor facial expression recognition and mask wearing classification tasks. Our\napproach extracts shared features for both tasks using a dual-branch\narchitecture that obtains multi-scale feature representations. Furthermore, we\npropose a cross-task fusion phase that processes tokens for each task with\nseparate branches, while exchanging information using a cross attention module.\nOur proposed framework reduces the overall complexity compared with using\nseparate networks for both tasks by the simple yet effective cross-task fusion\nphase. Extensive experiments demonstrate that our proposed model performs\nbetter than or on par with different state-of-the-art methods on both facial\nexpression recognition and facial mask wearing classification task.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.14606v2",
    "published_date": "2024-04-22 22:02:19 UTC",
    "updated_date": "2024-04-30 06:34:16 UTC"
  },
  {
    "arxiv_id": "2404.14581v1",
    "title": "The Adversarial AI-Art: Understanding, Generation, Detection, and Benchmarking",
    "authors": [
      "Yuying Li",
      "Zeyan Liu",
      "Junyi Zhao",
      "Liangqin Ren",
      "Fengjun Li",
      "Jiebo Luo",
      "Bo Luo"
    ],
    "abstract": "Generative AI models can produce high-quality images based on text prompts.\nThe generated images often appear indistinguishable from images generated by\nconventional optical photography devices or created by human artists (i.e.,\nreal images). While the outstanding performance of such generative models is\ngenerally well received, security concerns arise. For instance, such image\ngenerators could be used to facilitate fraud or scam schemes, generate and\nspread misinformation, or produce fabricated artworks. In this paper, we\npresent a systematic attempt at understanding and detecting AI-generated images\n(AI-art) in adversarial scenarios. First, we collect and share a dataset of\nreal images and their corresponding artificial counterparts generated by four\npopular AI image generators. The dataset, named ARIA, contains over 140K images\nin five categories: artworks (painting), social media images, news photos,\ndisaster scenes, and anime pictures. This dataset can be used as a foundation\nto support future research on adversarial AI-art. Next, we present a user study\nthat employs the ARIA dataset to evaluate if real-world users can distinguish\nwith or without reference images. In a benchmarking study, we further evaluate\nif state-of-the-art open-source and commercial AI image detectors can\neffectively identify the images in the ARIA dataset. Finally, we present a\nResNet-50 classifier and evaluate its accuracy and transferability on the ARIA\ndataset.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.14581v1",
    "published_date": "2024-04-22 21:00:13 UTC",
    "updated_date": "2024-04-22 21:00:13 UTC"
  },
  {
    "arxiv_id": "2404.14575v1",
    "title": "Designing forecasting software for forecast users: Empowering non-experts to create and understand their own forecasts",
    "authors": [
      "Richard Stromer",
      "Oskar Triebe",
      "Chad Zanocco",
      "Ram Rajagopal"
    ],
    "abstract": "Forecasts inform decision-making in nearly every domain. Forecasts are often\nproduced by experts with rare or hard to acquire skills. In practice, forecasts\nare often used by domain experts and managers with little forecasting\nexpertise. Our study focuses on how to design forecasting software that\nempowers non-expert users. We study how users can make use of state-of-the-art\nforecasting methods, embed their domain knowledge, and how they build\nunderstanding and trust towards generated forecasts. To do so, we co-designed a\nforecasting software prototype using feedback from users and then analyzed\ntheir interactions with our prototype. Our results identified three main\nconsiderations for non-expert users: (1) a safe stepwise approach facilitating\ncausal understanding and trust; (2) a white box model supporting\nhuman-reasoning-friendly components; (3) the inclusion of domain knowledge.\nThis paper contributes insights into how non-expert users interact with\nforecasting software and by recommending ways to design more accessible\nforecasting software.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "10 pages",
    "pdf_url": "http://arxiv.org/pdf/2404.14575v1",
    "published_date": "2024-04-22 20:53:08 UTC",
    "updated_date": "2024-04-22 20:53:08 UTC"
  },
  {
    "arxiv_id": "2404.14552v1",
    "title": "Generalizing Multi-Step Inverse Models for Representation Learning to Finite-Memory POMDPs",
    "authors": [
      "Lili Wu",
      "Ben Evans",
      "Riashat Islam",
      "Raihan Seraj",
      "Yonathan Efroni",
      "Alex Lamb"
    ],
    "abstract": "Discovering an informative, or agent-centric, state representation that\nencodes only the relevant information while discarding the irrelevant is a key\nchallenge towards scaling reinforcement learning algorithms and efficiently\napplying them to downstream tasks. Prior works studied this problem in\nhigh-dimensional Markovian environments, when the current observation may be a\ncomplex object but is sufficient to decode the informative state. In this work,\nwe consider the problem of discovering the agent-centric state in the more\nchallenging high-dimensional non-Markovian setting, when the state can be\ndecoded from a sequence of past observations. We establish that generalized\ninverse models can be adapted for learning agent-centric state representation\nfor this task. Our results include asymptotic theory in the deterministic\ndynamics setting as well as counter-examples for alternative intuitive\nalgorithms. We complement these findings with a thorough empirical study on the\nagent-centric state discovery abilities of the different alternatives we put\nforward. Particularly notable is our analysis of past actions, where we show\nthat these can be a double-edged sword: making the algorithms more successful\nwhen used correctly and causing dramatic failure when used incorrectly.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.14552v1",
    "published_date": "2024-04-22 19:46:16 UTC",
    "updated_date": "2024-04-22 19:46:16 UTC"
  },
  {
    "arxiv_id": "2404.14547v1",
    "title": "Integrating Disambiguation and User Preferences into Large Language Models for Robot Motion Planning",
    "authors": [
      "Mohammed Abugurain",
      "Shinkyu Park"
    ],
    "abstract": "This paper presents a framework that can interpret humans' navigation\ncommands containing temporal elements and directly translate their natural\nlanguage instructions into robot motion planning. Central to our framework is\nutilizing Large Language Models (LLMs). To enhance the reliability of LLMs in\nthe framework and improve user experience, we propose methods to resolve the\nambiguity in natural language instructions and capture user preferences. The\nprocess begins with an ambiguity classifier, identifying potential\nuncertainties in the instructions. Ambiguous statements trigger a GPT-4-based\nmechanism that generates clarifying questions, incorporating user responses for\ndisambiguation. Also, the framework assesses and records user preferences for\nnon-ambiguous instructions, enhancing future interactions. The last part of\nthis process is the translation of disambiguated instructions into a robot\nmotion plan using Linear Temporal Logic. This paper details the development of\nthis framework and the evaluation of its performance in various test scenarios.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.14547v1",
    "published_date": "2024-04-22 19:38:37 UTC",
    "updated_date": "2024-04-22 19:38:37 UTC"
  },
  {
    "arxiv_id": "2404.14408v3",
    "title": "SpaceByte: Towards Deleting Tokenization from Large Language Modeling",
    "authors": [
      "Kevin Slagle"
    ],
    "abstract": "Tokenization is widely used in large language models because it significantly\nimproves performance. However, tokenization imposes several disadvantages, such\nas performance biases, increased adversarial vulnerability, decreased\ncharacter-level modeling performance, and increased modeling complexity. To\naddress these disadvantages without sacrificing performance, we propose\nSpaceByte, a novel byte-level decoder architecture that closes the performance\ngap between byte-level and subword autoregressive language modeling. SpaceByte\nconsists of a byte-level Transformer model, but with extra larger transformer\nblocks inserted in the middle of the layers. We find that performance is\nsignificantly improved by applying these larger blocks only after certain\nbytes, such as space characters, which typically denote word boundaries. Our\nexperiments show that for a fixed training and inference compute budget,\nSpaceByte outperforms other byte-level architectures and roughly matches the\nperformance of tokenized Transformer architectures.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "9+10 pages, 3+1 figures, 2+4 tables",
    "pdf_url": "http://arxiv.org/pdf/2404.14408v3",
    "published_date": "2024-04-22 17:59:29 UTC",
    "updated_date": "2024-10-06 02:17:26 UTC"
  },
  {
    "arxiv_id": "2404.14395v2",
    "title": "PARAMANU-GANITA: Can Small Math Language Models Rival with Large Language Models on Mathematical Reasoning?",
    "authors": [
      "Mitodru Niyogi",
      "Arnab Bhattacharya"
    ],
    "abstract": "In this paper, we study whether domain specific pretraining of small\ngenerative language models (SLM) from scratch with domain specialized tokenizer\nand Chain-of-Thought (CoT) instruction fine-tuning results in competitive\nperformance on mathematical reasoning compared to LLMs? Secondly, whether this\napproach is environmentally sustainable, highly cost efficient? To address\nthese research questions, we present Paramanu-Ganita, a 208 million-parameter\nnovel decoder-only Auto Regressive SLM on mathematics. We performed pretraining\nfrom scratch on 31.5 billion tokens for 170 A100 hours using a context size of\n4096 on a mixed mathematical corpus consisting of web pages, source code,\ntextbooks, CoT templatised StackOverflow QA pairs, and mathematical lecture\nnotes in LaTeX curated by us. We also trained a math and code specialised BPE\ntokenizer. We proposed and performed CoT instruction fine-tuning of\nParamanu-Ganita on the MetaMathQA dataset. Our model Paramanu-Ganita, despite\nbeing 34 times smaller than the 7B LLMs, outperforms generalist LLMs by\napproximately 30% points, and even math-specialised LLMs by 3-23% points in\nGSM8K test accuracy metric. On MATH benchmark, Paramanu-Ganita outperformed the\nvarious models by 6-8% points. On benchmarks like LogiQA, MMLU (high school,\ncollege level), and competitive exams level, AGIEVAL (AQuA-RAT, SAT-Math),\nParamanu-Ganita outperformed others by 1-4%. Our model is available at\nhttps://huggingface.co/gyanai/paramanu-ganita-208M-hf .",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.14395v2",
    "published_date": "2024-04-22 17:55:56 UTC",
    "updated_date": "2025-03-05 18:17:28 UTC"
  },
  {
    "arxiv_id": "2404.14394v2",
    "title": "A Multimodal Automated Interpretability Agent",
    "authors": [
      "Tamar Rott Shaham",
      "Sarah Schwettmann",
      "Franklin Wang",
      "Achyuta Rajaram",
      "Evan Hernandez",
      "Jacob Andreas",
      "Antonio Torralba"
    ],
    "abstract": "This paper describes MAIA, a Multimodal Automated Interpretability Agent.\nMAIA is a system that uses neural models to automate neural model understanding\ntasks like feature interpretation and failure mode discovery. It equips a\npre-trained vision-language model with a set of tools that support iterative\nexperimentation on subcomponents of other models to explain their behavior.\nThese include tools commonly used by human interpretability researchers: for\nsynthesizing and editing inputs, computing maximally activating exemplars from\nreal-world datasets, and summarizing and describing experimental results.\nInterpretability experiments proposed by MAIA compose these tools to describe\nand explain system behavior. We evaluate applications of MAIA to computer\nvision models. We first characterize MAIA's ability to describe (neuron-level)\nfeatures in learned representations of images. Across several trained models\nand a novel dataset of synthetic vision neurons with paired ground-truth\ndescriptions, MAIA produces descriptions comparable to those generated by\nexpert human experimenters. We then show that MAIA can aid in two additional\ninterpretability tasks: reducing sensitivity to spurious features, and\nautomatically identifying inputs likely to be mis-classified.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "25 pages, 13 figures",
    "pdf_url": "http://arxiv.org/pdf/2404.14394v2",
    "published_date": "2024-04-22 17:55:11 UTC",
    "updated_date": "2025-02-11 19:35:42 UTC"
  },
  {
    "arxiv_id": "2404.14387v2",
    "title": "A Survey on Self-Evolution of Large Language Models",
    "authors": [
      "Zhengwei Tao",
      "Ting-En Lin",
      "Xiancai Chen",
      "Hangyu Li",
      "Yuchuan Wu",
      "Yongbin Li",
      "Zhi Jin",
      "Fei Huang",
      "Dacheng Tao",
      "Jingren Zhou"
    ],
    "abstract": "Large language models (LLMs) have significantly advanced in various fields\nand intelligent agent applications. However, current LLMs that learn from human\nor external model supervision are costly and may face performance ceilings as\ntask complexity and diversity increase. To address this issue, self-evolution\napproaches that enable LLM to autonomously acquire, refine, and learn from\nexperiences generated by the model itself are rapidly growing. This new\ntraining paradigm inspired by the human experiential learning process offers\nthe potential to scale LLMs towards superintelligence. In this work, we present\na comprehensive survey of self-evolution approaches in LLMs. We first propose a\nconceptual framework for self-evolution and outline the evolving process as\niterative cycles composed of four phases: experience acquisition, experience\nrefinement, updating, and evaluation. Second, we categorize the evolution\nobjectives of LLMs and LLM-based agents; then, we summarize the literature and\nprovide taxonomy and insights for each module. Lastly, we pinpoint existing\nchallenges and propose future directions to improve self-evolution frameworks,\nequipping researchers with critical insights to fast-track the development of\nself-evolving LLMs. Our corresponding GitHub repository is available at\nhttps://github.com/AlibabaResearch/DAMO-ConvAI/tree/main/Awesome-Self-Evolution-of-LLM",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.14387v2",
    "published_date": "2024-04-22 17:43:23 UTC",
    "updated_date": "2024-06-03 17:47:30 UTC"
  },
  {
    "arxiv_id": "2404.14469v2",
    "title": "SnapKV: LLM Knows What You are Looking for Before Generation",
    "authors": [
      "Yuhong Li",
      "Yingbing Huang",
      "Bowen Yang",
      "Bharat Venkitesh",
      "Acyr Locatelli",
      "Hanchen Ye",
      "Tianle Cai",
      "Patrick Lewis",
      "Deming Chen"
    ],
    "abstract": "Large Language Models (LLMs) have made remarkable progress in processing\nextensive contexts, with the Key-Value (KV) cache playing a vital role in\nenhancing their performance. However, the growth of the KV cache in response to\nincreasing input length poses challenges to memory and time efficiency. To\naddress this problem, this paper introduces SnapKV, an innovative and\nfine-tuning-free approach that efficiently minimizes KV cache size while still\ndelivering comparable performance in real-world applications.\n  We discover that each attention head in the model consistently focuses on\nspecific prompt attention features during generation. Meanwhile, this robust\npattern can be obtained from an 'observation' window located at the end of the\nprompts. Drawing on this insight, SnapKV automatically compresses KV caches by\nselecting clustered important KV positions for each attention head. Our\napproach significantly reduces the growing computational overhead and memory\nfootprint when processing long input sequences. Specifically, SnapKV achieves a\nconsistent decoding speed with a 3.6x increase in generation speed and an 8.2x\nenhancement in memory efficiency compared to the baseline when processing\ninputs of 16K tokens. At the same time, it maintains comparable performance to\nthe baseline models across 16 long sequence datasets. Moreover, SnapKV can\nprocess up to 380K context tokens on a single A100-80GB GPU using HuggingFace\nimplementation with minor changes, exhibiting only a negligible accuracy drop\nin the Needle-in-a-Haystack test. Further comprehensive studies suggest\nSnapKV's potential for practical applications.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.14469v2",
    "published_date": "2024-04-22 17:42:58 UTC",
    "updated_date": "2024-06-17 03:01:58 UTC"
  },
  {
    "arxiv_id": "2406.02560v3",
    "title": "Less Peaky and More Accurate CTC Forced Alignment by Label Priors",
    "authors": [
      "Ruizhe Huang",
      "Xiaohui Zhang",
      "Zhaoheng Ni",
      "Li Sun",
      "Moto Hira",
      "Jeff Hwang",
      "Vimal Manohar",
      "Vineel Pratap",
      "Matthew Wiesner",
      "Shinji Watanabe",
      "Daniel Povey",
      "Sanjeev Khudanpur"
    ],
    "abstract": "Connectionist temporal classification (CTC) models are known to have peaky\noutput distributions. Such behavior is not a problem for automatic speech\nrecognition (ASR), but it can cause inaccurate forced alignments (FA),\nespecially at finer granularity, e.g., phoneme level. This paper aims at\nalleviating the peaky behavior for CTC and improve its suitability for forced\nalignment generation, by leveraging label priors, so that the scores of\nalignment paths containing fewer blanks are boosted and maximized during\ntraining. As a result, our CTC model produces less peaky posteriors and is able\nto more accurately predict the offset of the tokens besides their onset. It\noutperforms the standard CTC model and a heuristics-based approach for\nobtaining CTC's token offset timestamps by 12-40% in phoneme and word boundary\nerrors (PBE and WBE) measured on the Buckeye and TIMIT data. Compared with the\nmost widely used FA toolkit Montreal Forced Aligner (MFA), our method performs\nsimilarly on PBE/WBE on Buckeye, yet falls behind MFA on TIMIT. Nevertheless,\nour method has a much simpler training pipeline and better runtime efficiency.\nOur training recipe and pretrained model are released in TorchAudio.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "eess.AS",
    "comment": "Accepted by ICASSP 2024. Github repo:\n  https://github.com/huangruizhe/audio/tree/aligner_label_priors",
    "pdf_url": "http://arxiv.org/pdf/2406.02560v3",
    "published_date": "2024-04-22 17:40:08 UTC",
    "updated_date": "2024-07-18 18:28:45 UTC"
  },
  {
    "arxiv_id": "2404.15166v2",
    "title": "Pixels and Predictions: Potential of GPT-4V in Meteorological Imagery Analysis and Forecast Communication",
    "authors": [
      "John R. Lawson",
      "Joseph E. Trujillo-Falcón",
      "David M. Schultz",
      "Montgomery L. Flora",
      "Kevin H. Goebbert",
      "Seth N. Lyman",
      "Corey K. Potvin",
      "Adam J. Stepanek"
    ],
    "abstract": "Generative AI, such as OpenAI's GPT-4V large-language model, has rapidly\nentered mainstream discourse. Novel capabilities in image processing and\nnatural-language communication may augment existing forecasting methods. Large\nlanguage models further display potential to better communicate weather hazards\nin a style honed for diverse communities and different languages. This study\nevaluates GPT-4V's ability to interpret meteorological charts and communicate\nweather hazards appropriately to the user, despite challenges of\nhallucinations, where generative AI delivers coherent, confident, but incorrect\nresponses. We assess GPT-4V's competence via its web interface ChatGPT in two\ntasks: (1) generating a severe-weather outlook from weather-chart analysis and\nconducting self-evaluation, revealing an outlook that corresponds well with a\nStorm Prediction Center human-issued forecast; and (2) producing hazard\nsummaries in Spanish and English from weather charts. Responses in Spanish,\nhowever, resemble direct (not idiomatic) translations from English to Spanish,\nyielding poorly translated summaries that lose critical idiomatic precision\nrequired for optimal communication. Our findings advocate for cautious\nintegration of tools like GPT-4V in meteorology, underscoring the necessity of\nhuman oversight and development of trustworthy, explainable AI.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "physics.ao-ph"
    ],
    "primary_category": "cs.CL",
    "comment": "Supplementary material PDF attached. Submitted to Artificial\n  Intelligence for the Earth Systems (American Meteorological Society) on 18\n  April 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.15166v2",
    "published_date": "2024-04-22 17:36:33 UTC",
    "updated_date": "2024-09-07 10:19:15 UTC"
  },
  {
    "arxiv_id": "2404.14372v1",
    "title": "Beyond Scaling: Predicting Patent Approval with Domain-specific Fine-grained Claim Dependency Graph",
    "authors": [
      "Xiaochen Kev Gao",
      "Feng Yao",
      "Kewen Zhao",
      "Beilei He",
      "Animesh Kumar",
      "Vish Krishnan",
      "Jingbo Shang"
    ],
    "abstract": "Model scaling is becoming the default choice for many language tasks due to\nthe success of large language models (LLMs). However, it can fall short in\nspecific scenarios where simple customized methods excel. In this paper, we\ndelve into the patent approval pre-diction task and unveil that simple\ndomain-specific graph methods outperform enlarging the model, using the\nintrinsic dependencies within the patent data. Specifically, we first extend\nthe embedding-based state-of-the-art (SOTA) by scaling up its backbone model\nwith various sizes of open-source LLMs, then explore prompt-based methods to\nharness proprietary LLMs' potential, but find the best results close to random\nguessing, underlining the ineffectiveness of model scaling-up. Hence, we\npropose a novel Fine-grained cLAim depeNdency (FLAN) Graph through meticulous\npatent data analyses, capturing the inherent dependencies across segments of\nthe patent text. As it is model-agnostic, we apply cost-effective graph models\nto our FLAN Graph to obtain representations for approval prediction. Extensive\nexperiments and detailed analyses prove that incorporating FLAN Graph via\nvarious graph models consistently outperforms all LLM baselines significantly.\nWe hope that our observations and analyses in this paper can bring more\nattention to this challenging task and prompt further research into the\nlimitations of LLMs. Our source code and dataset can be obtained from\nhttp://github.com/ShangDataLab/FLAN-Graph.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "17 Pages, Under Review",
    "pdf_url": "http://arxiv.org/pdf/2404.14372v1",
    "published_date": "2024-04-22 17:22:31 UTC",
    "updated_date": "2024-04-22 17:22:31 UTC"
  },
  {
    "arxiv_id": "2404.14370v1",
    "title": "Assessing GPT-4-Vision's Capabilities in UML-Based Code Generation",
    "authors": [
      "Gábor Antal",
      "Richárd Vozár",
      "Rudolf Ferenc"
    ],
    "abstract": "The emergence of advanced neural networks has opened up new ways in automated\ncode generation from conceptual models, promising to enhance software\ndevelopment processes. This paper presents a preliminary evaluation of\nGPT-4-Vision, a state-of-the-art deep learning model, and its capabilities in\ntransforming Unified Modeling Language (UML) class diagrams into fully\noperating Java class files. In our study, we used exported images of 18 class\ndiagrams comprising 10 single-class and 8 multi-class diagrams. We used 3\ndifferent prompts for each input, and we manually evaluated the results. We\ncreated a scoring system in which we scored the occurrence of elements found in\nthe diagram within the source code. On average, the model was able to generate\nsource code for 88% of the elements shown in the diagrams. Our results indicate\nthat GPT-4-Vision exhibits proficiency in handling single-class UML diagrams,\nsuccessfully transforming them into syntactically correct class files. However,\nfor multi-class UML diagrams, the model's performance is weaker compared to\nsingle-class diagrams. In summary, further investigations are necessary to\nexploit the model's potential completely.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.PL"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.14370v1",
    "published_date": "2024-04-22 17:21:24 UTC",
    "updated_date": "2024-04-22 17:21:24 UTC"
  },
  {
    "arxiv_id": "2404.14368v1",
    "title": "Graphic Design with Large Multimodal Model",
    "authors": [
      "Yutao Cheng",
      "Zhao Zhang",
      "Maoke Yang",
      "Hui Nie",
      "Chunyuan Li",
      "Xinglong Wu",
      "Jie Shao"
    ],
    "abstract": "In the field of graphic design, automating the integration of design elements\ninto a cohesive multi-layered artwork not only boosts productivity but also\npaves the way for the democratization of graphic design. One existing practice\nis Graphic Layout Generation (GLG), which aims to layout sequential design\nelements. It has been constrained by the necessity for a predefined correct\nsequence of layers, thus limiting creative potential and increasing user\nworkload. In this paper, we present Hierarchical Layout Generation (HLG) as a\nmore flexible and pragmatic setup, which creates graphic composition from\nunordered sets of design elements. To tackle the HLG task, we introduce\nGraphist, the first layout generation model based on large multimodal models.\nGraphist efficiently reframes the HLG as a sequence generation problem,\nutilizing RGB-A images as input, outputs a JSON draft protocol, indicating the\ncoordinates, size, and order of each element. We develop new evaluation metrics\nfor HLG. Graphist outperforms prior arts and establishes a strong baseline for\nthis field. Project homepage: https://github.com/graphic-design-ai/graphist",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.14368v1",
    "published_date": "2024-04-22 17:20:38 UTC",
    "updated_date": "2024-04-22 17:20:38 UTC"
  },
  {
    "arxiv_id": "2404.14355v3",
    "title": "Pre-Calc: Learning to Use the Calculator Improves Numeracy in Language Models",
    "authors": [
      "Vishruth Veerendranath",
      "Vishwa Shah",
      "Kshitish Ghate"
    ],
    "abstract": "Quantitative and numerical comprehension in language is an important task in\nmany fields like education and finance, but still remains a challenging task\nfor language models. While tool and calculator usage has shown to be helpful to\nimprove mathematical reasoning in large pretrained decoder-only language\nmodels, this remains unexplored for smaller language models with encoders. In\nthis paper, we propose Pre-Calc, a simple pre-finetuning objective of learning\nto use the calculator for both encoder-only and encoder-decoder architectures,\nformulated as a discriminative and generative task respectively. We pre-train\nBERT and RoBERTa for discriminative calculator use and Flan-T5 for generative\ncalculator use on the MAWPS, SVAMP, and AsDiv-A datasets, which improves\nperformance on downstream tasks that require numerical understanding. Our code\nand data are available at https://github.com/calc-cmu/pre-calc.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "AI4Math workshop, ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.14355v3",
    "published_date": "2024-04-22 17:07:25 UTC",
    "updated_date": "2024-06-26 03:52:24 UTC"
  },
  {
    "arxiv_id": "2404.14349v1",
    "title": "Automatic Discovery of Visual Circuits",
    "authors": [
      "Achyuta Rajaram",
      "Neil Chowdhury",
      "Antonio Torralba",
      "Jacob Andreas",
      "Sarah Schwettmann"
    ],
    "abstract": "To date, most discoveries of network subcomponents that implement\nhuman-interpretable computations in deep vision models have involved close\nstudy of single units and large amounts of human labor. We explore scalable\nmethods for extracting the subgraph of a vision model's computational graph\nthat underlies recognition of a specific visual concept. We introduce a new\nmethod for identifying these subgraphs: specifying a visual concept using a few\nexamples, and then tracing the interdependence of neuron activations across\nlayers, or their functional connectivity. We find that our approach extracts\ncircuits that causally affect model output, and that editing these circuits can\ndefend large pretrained models from adversarial attacks.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "14 pages, 11 figures",
    "pdf_url": "http://arxiv.org/pdf/2404.14349v1",
    "published_date": "2024-04-22 17:00:57 UTC",
    "updated_date": "2024-04-22 17:00:57 UTC"
  },
  {
    "arxiv_id": "2404.14467v1",
    "title": "Integrating Chemistry Knowledge in Large Language Models via Prompt Engineering",
    "authors": [
      "Hongxuan Liu",
      "Haoyu Yin",
      "Zhiyao Luo",
      "Xiaonan Wang"
    ],
    "abstract": "This paper presents a study on the integration of domain-specific knowledge\nin prompt engineering to enhance the performance of large language models\n(LLMs) in scientific domains. A benchmark dataset is curated to encapsulate the\nintricate physical-chemical properties of small molecules, their drugability\nfor pharmacology, alongside the functional attributes of enzymes and crystal\nmaterials, underscoring the relevance and applicability across biological and\nchemical domains.The proposed domain-knowledge embedded prompt engineering\nmethod outperforms traditional prompt engineering strategies on various\nmetrics, including capability, accuracy, F1 score, and hallucination drop. The\neffectiveness of the method is demonstrated through case studies on complex\nmaterials including the MacMillan catalyst, paclitaxel, and lithium cobalt\noxide. The results suggest that domain-knowledge prompts can guide LLMs to\ngenerate more accurate and relevant responses, highlighting the potential of\nLLMs as powerful tools for scientific discovery and innovation when equipped\nwith domain-specific prompts. The study also discusses limitations and future\ndirections for domain-specific prompt engineering development.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "43 pages, 17 figures",
    "pdf_url": "http://arxiv.org/pdf/2404.14467v1",
    "published_date": "2024-04-22 16:55:44 UTC",
    "updated_date": "2024-04-22 16:55:44 UTC"
  },
  {
    "arxiv_id": "2404.14332v3",
    "title": "Full Event Particle-Level Unfolding with Variable-Length Latent Variational Diffusion",
    "authors": [
      "Alexander Shmakov",
      "Kevin Greif",
      "Michael James Fenton",
      "Aishik Ghosh",
      "Pierre Baldi",
      "Daniel Whiteson"
    ],
    "abstract": "The measurements performed by particle physics experiments must account for\nthe imperfect response of the detectors used to observe the interactions. One\napproach, unfolding, statistically adjusts the experimental data for detector\neffects. Recently, generative machine learning models have shown promise for\nperforming unbinned unfolding in a high number of dimensions. However, all\ncurrent generative approaches are limited to unfolding a fixed set of\nobservables, making them unable to perform full-event unfolding in the variable\ndimensional environment of collider data. A novel modification to the\nvariational latent diffusion model (VLD) approach to generative unfolding is\npresented, which allows for unfolding of high- and variable-dimensional feature\nspaces. The performance of this method is evaluated in the context of\nsemi-leptonic top quark pair production at the Large Hadron Collider.",
    "categories": [
      "hep-ex",
      "cs.AI",
      "cs.LG",
      "hep-ph"
    ],
    "primary_category": "hep-ex",
    "comment": "Submission to SciPost",
    "pdf_url": "http://arxiv.org/pdf/2404.14332v3",
    "published_date": "2024-04-22 16:47:10 UTC",
    "updated_date": "2025-01-23 19:37:48 UTC"
  },
  {
    "arxiv_id": "2404.14325v3",
    "title": "Adapting to time: Why nature may have evolved a diverse set of neurons",
    "authors": [
      "Karim G. Habashy",
      "Benjamin D. Evans",
      "Dan F. M. Goodman",
      "Jeffrey S. Bowers"
    ],
    "abstract": "Brains have evolved diverse neurons with varying morphologies and dynamics\nthat impact temporal information processing. In contrast, most neural network\nmodels use homogeneous units that vary only in spatial parameters (weights and\nbiases). To explore the importance of temporal parameters, we trained spiking\nneural networks on tasks with varying temporal complexity, holding different\nparameter subsets constant. We found that adapting conduction delays is crucial\nfor solving all test conditions under tight resource constraints. Remarkably,\nthese tasks can be solved using only temporal parameters (delays and time\nconstants) with constant weights. In more complex spatio-temporal tasks, an\nadaptable bursting parameter was essential. Overall, allowing adaptation of\nboth temporal and spatial parameters enhances network robustness to noise, a\nvital feature for biological brains and neuromorphic computing systems. Our\nfindings suggest that rich and adaptable dynamics may be the key for solving\ntemporally structured tasks efficiently in evolving organisms, which would help\nexplain the diverse physiological properties of biological neurons.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "q-bio.NC",
      "K.3.2; I.2.m"
    ],
    "primary_category": "cs.NE",
    "comment": "19 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2404.14325v3",
    "published_date": "2024-04-22 16:38:38 UTC",
    "updated_date": "2025-01-12 05:36:27 UTC"
  },
  {
    "arxiv_id": "2405.05140v1",
    "title": "Distributed Learning for Wi-Fi AP Load Prediction",
    "authors": [
      "Dariush Salami",
      "Francesc Wilhelmi",
      "Lorenzo Galati-Giordano",
      "Mika Kasslin"
    ],
    "abstract": "The increasing cloudification and softwarization of networks foster the\ninterplay among multiple independently managed deployments. An appealing reason\nfor such an interplay lies in distributed Machine Learning (ML), which allows\nthe creation of robust ML models by leveraging collective intelligence and\ncomputational power. In this paper, we study the application of the two\ncornerstones of distributed learning, namely Federated Learning (FL) and\nKnowledge Distillation (KD), on the Wi-Fi Access Point (AP) load prediction use\ncase. The analysis conducted in this paper is done on a dataset that contains\nreal measurements from a large Wi-Fi campus network, which we use to train the\nML model under study based on different strategies. Performance evaluation\nincludes relevant aspects for the suitability of distributed learning operation\nin real use cases, including the predictive performance, the associated\ncommunication overheads, or the energy consumption. In particular, we prove\nthat distributed learning can improve the predictive accuracy centralized ML\nsolutions by up to 93% while reducing the communication overheads and the\nenergy cost by 80%.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.NI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.05140v1",
    "published_date": "2024-04-22 16:37:35 UTC",
    "updated_date": "2024-04-22 16:37:35 UTC"
  },
  {
    "arxiv_id": "2404.15153v2",
    "title": "Performance Characterization of Expert Router for Scalable LLM Inference",
    "authors": [
      "Josef Pichlmeier",
      "Philipp Ross",
      "Andre Luckow"
    ],
    "abstract": "Large Language Models (LLMs) have experienced widespread adoption across\nscientific and industrial domains due to their versatility and utility for\ndiverse tasks. Nevertheless, deploying and serving these models at scale with\noptimal throughput and latency remains a significant challenge, primarily\nbecause of LLMs' high computational and memory demands. Specialized models\noptimized for specific tasks can be combined through a routing mechanism to\naddress these challenges, creating a modular inference system. This paper\nintroduces Expert Router, a scalable routing architecture that directs prompts\nto specialized expert models. We characterize multiple Expert Router\nconfigurations, including different LLama 3 models with quantized and\nnon-quantized weights under up to 1,000 concurrent users. Our findings reveal\nthat Expert Router introduces minimal latency overhead, with the configuration\nof expert models being a dominating factor in performance outcomes.\nHigh-parameter expert models deliver stable throughput and latency under\nmoderate concurrency levels. In contrast, smaller expert models maintain\ncompetitive performance across a wider range of concurrent users compared to\ntensor-parallelized baseline models. This highlights the potential of Expert\nRouter for efficient and scalable LLM deployment.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.PF"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.15153v2",
    "published_date": "2024-04-22 16:33:42 UTC",
    "updated_date": "2024-10-08 12:41:03 UTC"
  },
  {
    "arxiv_id": "2404.14304v2",
    "title": "Explaining Arguments' Strength: Unveiling the Role of Attacks and Supports (Technical Report)",
    "authors": [
      "Xiang Yin",
      "Potyka Nico",
      "Francesca Toni"
    ],
    "abstract": "Quantitatively explaining the strength of arguments under gradual semantics\nhas recently received increasing attention. Specifically, several works in the\nliterature provide quantitative explanations by computing the attribution\nscores of arguments. These works disregard the importance of attacks and\nsupports, even though they play an essential role when explaining arguments'\nstrength. In this paper, we propose a novel theory of Relation Attribution\nExplanations (RAEs), adapting Shapley values from game theory to offer\nfine-grained insights into the role of attacks and supports in quantitative\nbipolar argumentation towards obtaining the arguments' strength. We show that\nRAEs satisfy several desirable properties. We also propose a probabilistic\nalgorithm to approximate RAEs efficiently. Finally, we show the application\nvalue of RAEs in fraud detection and large language models case studies.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "This paper has been accepted at IJCAI 2024 (the 33rd International\n  Joint Conference on Artificial Intelligence)",
    "pdf_url": "http://arxiv.org/pdf/2404.14304v2",
    "published_date": "2024-04-22 16:02:48 UTC",
    "updated_date": "2024-05-10 17:37:43 UTC"
  },
  {
    "arxiv_id": "2404.14296v2",
    "title": "Does Your Neural Code Completion Model Use My Code? A Membership Inference Approach",
    "authors": [
      "Yao Wan",
      "Guanghua Wan",
      "Shijie Zhang",
      "Hongyu Zhang",
      "Pan Zhou",
      "Hai Jin",
      "Lichao Sun"
    ],
    "abstract": "Recent years have witnessed significant progress in developing deep\nlearning-based models for automated code completion. Although using source code\nin GitHub has been a common practice for training deep-learning-based models\nfor code completion, it may induce some legal and ethical issues such as\ncopyright infringement. In this paper, we investigate the legal and ethical\nissues of current neural code completion models by answering the following\nquestion: Is my code used to train your neural code completion model? To this\nend, we tailor a membership inference approach (termed CodeMI) that was\noriginally crafted for classification tasks to a more challenging task of code\ncompletion. In particular, since the target code completion models perform as\nopaque black boxes, preventing access to their training data and parameters, we\nopt to train multiple shadow models to mimic their behavior. The acquired\nposteriors from these shadow models are subsequently employed to train a\nmembership classifier. Subsequently, the membership classifier can be\neffectively employed to deduce the membership status of a given code sample\nbased on the output of a target code completion model. We comprehensively\nevaluate the effectiveness of this adapted approach across a diverse array of\nneural code completion models, (i.e., LSTM-based, CodeGPT, CodeGen, and\nStarCoder). Experimental results reveal that the LSTM-based and CodeGPT models\nsuffer the membership leakage issue, which can be easily detected by our\nproposed membership inference approach with an accuracy of 0.842, and 0.730,\nrespectively. Interestingly, our experiments also show that the data membership\nof current large language models of code, e.g., CodeGen and StarCoder, is\ndifficult to detect, leaving ampler space for further improvement. Finally, we\nalso try to explain the findings from the perspective of model memorization.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.14296v2",
    "published_date": "2024-04-22 15:54:53 UTC",
    "updated_date": "2024-09-07 13:59:47 UTC"
  },
  {
    "arxiv_id": "2404.14294v3",
    "title": "A Survey on Efficient Inference for Large Language Models",
    "authors": [
      "Zixuan Zhou",
      "Xuefei Ning",
      "Ke Hong",
      "Tianyu Fu",
      "Jiaming Xu",
      "Shiyao Li",
      "Yuming Lou",
      "Luning Wang",
      "Zhihang Yuan",
      "Xiuhong Li",
      "Shengen Yan",
      "Guohao Dai",
      "Xiao-Ping Zhang",
      "Yuhan Dong",
      "Yu Wang"
    ],
    "abstract": "Large Language Models (LLMs) have attracted extensive attention due to their\nremarkable performance across various tasks. However, the substantial\ncomputational and memory requirements of LLM inference pose challenges for\ndeployment in resource-constrained scenarios. Efforts within the field have\nbeen directed towards developing techniques aimed at enhancing the efficiency\nof LLM inference. This paper presents a comprehensive survey of the existing\nliterature on efficient LLM inference. We start by analyzing the primary causes\nof the inefficient LLM inference, i.e., the large model size, the\nquadratic-complexity attention operation, and the auto-regressive decoding\napproach. Then, we introduce a comprehensive taxonomy that organizes the\ncurrent literature into data-level, model-level, and system-level optimization.\nMoreover, the paper includes comparative experiments on representative methods\nwithin critical sub-fields to provide quantitative insights. Last but not\nleast, we provide some knowledge summary and discuss future research\ndirections.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.14294v3",
    "published_date": "2024-04-22 15:53:08 UTC",
    "updated_date": "2024-07-19 04:47:36 UTC"
  },
  {
    "arxiv_id": "2404.14285v3",
    "title": "LLM-Personalize: Aligning LLM Planners with Human Preferences via Reinforced Self-Training for Housekeeping Robots",
    "authors": [
      "Dongge Han",
      "Trevor McInroe",
      "Adam Jelley",
      "Stefano V. Albrecht",
      "Peter Bell",
      "Amos Storkey"
    ],
    "abstract": "Large language models (LLMs) have shown significant potential for robotics\napplications, particularly task planning, by harnessing their language\ncomprehension and text generation capabilities. However, in applications such\nas household robotics, a critical gap remains in the personalization of these\nmodels to individual user preferences. We introduce LLM-Personalize, a novel\nframework with an optimization pipeline designed to personalize LLM planners\nfor household robotics. Our LLM-Personalize framework features an LLM planner\nthat performs iterative planning in multi-room, partially-observable household\nscenarios, making use of a scene graph constructed with local observations. The\ngenerated plan consists of a sequence of high-level actions which are\nsubsequently executed by a controller. Central to our approach is the\noptimization pipeline, which combines imitation learning and iterative\nself-training to personalize the LLM planner. In particular, the imitation\nlearning phase performs initial LLM alignment from demonstrations, and\nbootstraps the model to facilitate effective iterative self-training, which\nfurther explores and aligns the model to user preferences. We evaluate\nLLM-Personalize on Housekeep, a challenging simulated real-world 3D benchmark\nfor household rearrangements, and show that LLM-Personalize achieves more than\na 30 percent increase in success rate over existing LLM planners, showcasing\nsignificantly improved alignment with human preferences. Project page:\nhttps://gdg94.github.io/projectllmpersonalize/.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "COLING 2025",
    "pdf_url": "http://arxiv.org/pdf/2404.14285v3",
    "published_date": "2024-04-22 15:35:33 UTC",
    "updated_date": "2024-12-30 01:41:37 UTC"
  },
  {
    "arxiv_id": "2404.14244v3",
    "title": "AI-Generated Faces in the Real World: A Large-Scale Case Study of Twitter Profile Images",
    "authors": [
      "Jonas Ricker",
      "Dennis Assenmacher",
      "Thorsten Holz",
      "Asja Fischer",
      "Erwin Quiring"
    ],
    "abstract": "Recent advances in the field of generative artificial intelligence (AI) have\nblurred the lines between authentic and machine-generated content, making it\nalmost impossible for humans to distinguish between such media. One notable\nconsequence is the use of AI-generated images for fake profiles on social\nmedia. While several types of disinformation campaigns and similar incidents\nhave been reported in the past, a systematic analysis has been lacking. In this\nwork, we conduct the first large-scale investigation of the prevalence of\nAI-generated profile pictures on Twitter. We tackle the challenges of a\nreal-world measurement study by carefully integrating various data sources and\ndesigning a multi-stage detection pipeline. Our analysis of nearly 15 million\nTwitter profile pictures shows that 0.052% were artificially generated,\nconfirming their notable presence on the platform. We comprehensively examine\nthe characteristics of these accounts and their tweet content, and uncover\npatterns of coordinated inauthentic behavior. The results also reveal several\nmotives, including spamming and political amplification campaigns. Our research\nreaffirms the need for effective detection and mitigation strategies to cope\nwith the potential negative effects of generative AI in the future.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CY",
      "cs.LG",
      "cs.SI"
    ],
    "primary_category": "cs.CR",
    "comment": "International Symposium on Research in Attacks, Intrusions and\n  Defenses (RAID), 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.14244v3",
    "published_date": "2024-04-22 14:57:17 UTC",
    "updated_date": "2024-10-03 08:22:20 UTC"
  },
  {
    "arxiv_id": "2404.14243v1",
    "title": "Turbo-CF: Matrix Decomposition-Free Graph Filtering for Fast Recommendation",
    "authors": [
      "Jin-Duk Park",
      "Yong-Min Shin",
      "Won-Yong Shin"
    ],
    "abstract": "A series of graph filtering (GF)-based collaborative filtering (CF) showcases\nstate-of-the-art performance on the recommendation accuracy by using a low-pass\nfilter (LPF) without a training process. However, conventional GF-based CF\napproaches mostly perform matrix decomposition on the item-item similarity\ngraph to realize the ideal LPF, which results in a non-trivial computational\ncost and thus makes them less practical in scenarios where rapid\nrecommendations are essential. In this paper, we propose Turbo-CF, a GF-based\nCF method that is both training-free and matrix decomposition-free. Turbo-CF\nemploys a polynomial graph filter to circumvent the issue of expensive matrix\ndecompositions, enabling us to make full use of modern computer hardware\ncomponents (i.e., GPU). Specifically, Turbo-CF first constructs an item-item\nsimilarity graph whose edge weights are effectively regulated. Then, our own\npolynomial LPFs are designed to retain only low-frequency signals without\nexplicit matrix decompositions. We demonstrate that Turbo-CF is extremely fast\nyet accurate, achieving a runtime of less than 1 second on real-world benchmark\ndatasets while achieving recommendation accuracies comparable to best\ncompetitors.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.IT",
      "cs.LG",
      "cs.SI",
      "math.IT"
    ],
    "primary_category": "cs.IR",
    "comment": "5 pages, 4 figures, 4 tables; 47th International ACM SIGIR Conference\n  on Research and Development in Information Retrieval (SIGIR 2024) (to appear)\n  (Please cite our conference version.)",
    "pdf_url": "http://arxiv.org/pdf/2404.14243v1",
    "published_date": "2024-04-22 14:56:36 UTC",
    "updated_date": "2024-04-22 14:56:36 UTC"
  },
  {
    "arxiv_id": "2404.14241v1",
    "title": "UrbanCross: Enhancing Satellite Image-Text Retrieval with Cross-Domain Adaptation",
    "authors": [
      "Siru Zhong",
      "Xixuan Hao",
      "Yibo Yan",
      "Ying Zhang",
      "Yangqiu Song",
      "Yuxuan Liang"
    ],
    "abstract": "Urbanization challenges underscore the necessity for effective satellite\nimage-text retrieval methods to swiftly access specific information enriched\nwith geographic semantics for urban applications. However, existing methods\noften overlook significant domain gaps across diverse urban landscapes,\nprimarily focusing on enhancing retrieval performance within single domains. To\ntackle this issue, we present UrbanCross, a new framework for cross-domain\nsatellite image-text retrieval. UrbanCross leverages a high-quality,\ncross-domain dataset enriched with extensive geo-tags from three countries to\nhighlight domain diversity. It employs the Large Multimodal Model (LMM) for\ntextual refinement and the Segment Anything Model (SAM) for visual\naugmentation, achieving a fine-grained alignment of images, segments and texts,\nyielding a 10% improvement in retrieval performance. Additionally, UrbanCross\nincorporates an adaptive curriculum-based source sampler and a weighted\nadversarial cross-domain fine-tuning module, progressively enhancing\nadaptability across various domains. Extensive experiments confirm UrbanCross's\nsuperior efficiency in retrieval and adaptation to new urban environments,\ndemonstrating an average performance increase of 15% over its version without\ndomain adaptation mechanisms, effectively bridging the domain gap.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.14241v1",
    "published_date": "2024-04-22 14:53:27 UTC",
    "updated_date": "2024-04-22 14:53:27 UTC"
  },
  {
    "arxiv_id": "2404.14240v1",
    "title": "Collaborative Filtering Based on Diffusion Models: Unveiling the Potential of High-Order Connectivity",
    "authors": [
      "Yu Hou",
      "Jin-Duk Park",
      "Won-Yong Shin"
    ],
    "abstract": "A recent study has shown that diffusion models are well-suited for modeling\nthe generative process of user-item interactions in recommender systems due to\ntheir denoising nature. However, existing diffusion model-based recommender\nsystems do not explicitly leverage high-order connectivities that contain\ncrucial collaborative signals for accurate recommendations. Addressing this\ngap, we propose CF-Diff, a new diffusion model-based collaborative filtering\n(CF) method, which is capable of making full use of collaborative signals along\nwith multi-hop neighbors. Specifically, the forward-diffusion process adds\nrandom noise to user-item interactions, while the reverse-denoising process\naccommodates our own learning model, named cross-attention-guided multi-hop\nautoencoder (CAM-AE), to gradually recover the original user-item interactions.\nCAM-AE consists of two core modules: 1) the attention-aided AE module,\nresponsible for precisely learning latent representations of user-item\ninteractions while preserving the model's complexity at manageable levels, and\n2) the multi-hop cross-attention module, which judiciously harnesses high-order\nconnectivity information to capture enhanced collaborative signals. Through\ncomprehensive experiments on three real-world datasets, we demonstrate that\nCF-Diff is (a) Superior: outperforming benchmark recommendation methods,\nachieving remarkable gains up to 7.29% compared to the best competitor, (b)\nTheoretically-validated: reducing computations while ensuring that the\nembeddings generated by our model closely approximate those from the original\ncross-attention, and (c) Scalable: proving the computational efficiency that\nscales linearly with the number of users or items.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.IT",
      "cs.LG",
      "cs.SI",
      "math.IT"
    ],
    "primary_category": "cs.IR",
    "comment": "10 pages, 6 figures, 4 tables; 47th International ACM SIGIR\n  Conference on Research and Development in Information Retrieval (SIGIR 2024)\n  (to appear) (Please cite our conference version.)",
    "pdf_url": "http://arxiv.org/pdf/2404.14240v1",
    "published_date": "2024-04-22 14:49:46 UTC",
    "updated_date": "2024-04-22 14:49:46 UTC"
  },
  {
    "arxiv_id": "2404.14238v1",
    "title": "Beyond the Edge: An Advanced Exploration of Reinforcement Learning for Mobile Edge Computing, its Applications, and Future Research Trajectories",
    "authors": [
      "Ning Yang",
      "Shuo Chen",
      "Haijun Zhang",
      "Randall Berry"
    ],
    "abstract": "Mobile Edge Computing (MEC) broadens the scope of computation and storage\nbeyond the central network, incorporating edge nodes close to end devices. This\nexpansion facilitates the implementation of large-scale \"connected things\"\nwithin edge networks. The advent of applications necessitating real-time,\nhigh-quality service presents several challenges, such as low latency, high\ndata rate, reliability, efficiency, and security, all of which demand\nresolution. The incorporation of reinforcement learning (RL) methodologies\nwithin MEC networks promotes a deeper understanding of mobile user behaviors\nand network dynamics, thereby optimizing resource use in computing and\ncommunication processes. This paper offers an exhaustive survey of RL\napplications in MEC networks, initially presenting an overview of RL from its\nfundamental principles to the latest advanced frameworks. Furthermore, it\noutlines various RL strategies employed in offloading, caching, and\ncommunication within MEC networks. Finally, it explores open issues linked with\nsoftware and hardware platforms, representation, RL robustness, safe RL,\nlarge-scale scheduling, generalization, security, and privacy. The paper\nproposes specific RL techniques to mitigate these issues and provides insights\ninto their practical applications.",
    "categories": [
      "cs.NI",
      "cs.AI"
    ],
    "primary_category": "cs.NI",
    "comment": "The paper is accepted by IEEE Communications Surveys and Tutorials\n  (COMST)",
    "pdf_url": "http://arxiv.org/pdf/2404.14238v1",
    "published_date": "2024-04-22 14:47:42 UTC",
    "updated_date": "2024-04-22 14:47:42 UTC"
  },
  {
    "arxiv_id": "2404.14233v2",
    "title": "Detecting and Mitigating Hallucination in Large Vision Language Models via Fine-Grained AI Feedback",
    "authors": [
      "Wenyi Xiao",
      "Ziwei Huang",
      "Leilei Gan",
      "Wanggui He",
      "Haoyuan Li",
      "Zhelun Yu",
      "Fangxun Shu",
      "Hao Jiang",
      "Linchao Zhu"
    ],
    "abstract": "The rapidly developing Large Vision Language Models (LVLMs) have shown\nnotable capabilities on a range of multi-modal tasks, but still face the\nhallucination phenomena where the generated texts do not align with the given\ncontexts, significantly restricting the usages of LVLMs. Most previous work\ndetects and mitigates hallucination at the coarse-grained level or requires\nexpensive annotation (e.g., labeling by proprietary models or human experts).\nTo address these issues, we propose detecting and mitigating hallucinations in\nLVLMs via fine-grained AI feedback. The basic idea is that we generate a\nsmall-size sentence-level hallucination annotation dataset by proprietary\nmodels, whereby we train a hallucination detection model which can perform\nsentence-level hallucination detection, covering primary hallucination types\n(i.e., object, attribute, and relationship). Then, we propose a\ndetect-then-rewrite pipeline to automatically construct preference dataset for\ntraining hallucination mitigating model. Furthermore, we propose\ndifferentiating the severity of hallucinations, and introducing a Hallucination\nSeverity-Aware Direct Preference Optimization (HSA-DPO) for mitigating\nhallucination in LVLMs by incorporating the severity of hallucinations into\npreference learning. Extensive experiments demonstrate the effectiveness of our\nmethod.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "repo: https://github.com/Mr-Loevan/HSA-DPO",
    "pdf_url": "http://arxiv.org/pdf/2404.14233v2",
    "published_date": "2024-04-22 14:46:10 UTC",
    "updated_date": "2025-01-06 13:58:45 UTC"
  },
  {
    "arxiv_id": "2404.14232v3",
    "title": "Shifting Focus with HCEye: Exploring the Dynamics of Visual Highlighting and Cognitive Load on User Attention and Saliency Prediction",
    "authors": [
      "Anwesha Das",
      "Zekun Wu",
      "Iza Škrjanec",
      "Anna Maria Feit"
    ],
    "abstract": "Visual highlighting can guide user attention in complex interfaces. However,\nits effectiveness under limited attentional capacities is underexplored. This\npaper examines the joint impact of visual highlighting (permanent and dynamic)\nand dual-task-induced cognitive load on gaze behaviour. Our analysis, using\neye-movement data from 27 participants viewing 150 unique webpages reveals that\nwhile participants' ability to attend to UI elements decreases with increasing\ncognitive load, dynamic adaptations (i.e., highlighting) remain\nattention-grabbing. The presence of these factors significantly alters what\npeople attend to and thus what is salient. Accordingly, we show that\nstate-of-the-art saliency models increase their performance when accounting for\ndifferent cognitive loads. Our empirical insights, along with our openly\navailable dataset, enhance our understanding of attentional processes in UIs\nunder varying cognitive (and perceptual) loads and open the door for new models\nthat can predict user attention while multitasking.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "H.1.2"
    ],
    "primary_category": "cs.HC",
    "comment": "18 pages, 9 Figures, Conference: ACM Symposium on Eye Tracking\n  Research & Applications (ETRA); Journal: Proc. ACM Hum.-Comput. Interact.,\n  Vol. 8, No. ETRA, Article 236. Publication date: May 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.14232v3",
    "published_date": "2024-04-22 14:45:30 UTC",
    "updated_date": "2024-05-02 09:06:35 UTC"
  },
  {
    "arxiv_id": "2405.06659v2",
    "title": "ControlMol: Adding Substructure Control To Molecule Diffusion Models",
    "authors": [
      "Qi Zhengyang",
      "Liu Zijing",
      "Zhang Jiying",
      "Cao He",
      "Li Yu"
    ],
    "abstract": "Due to the vast design space of molecules, generating molecules conditioned\non a specific sub-structure relevant to a particular function or therapeutic\ntarget is a crucial task in computer-aided drug design. Existing works mainly\nfocus on specific tasks, such as linker design or scaffold hopping, each task\nrequires training a model from scratch, and many well-pretrained De Novo\nmolecule generation model parameters are not effectively utilized. To this end,\nwe propose a two-stage training approach, consisting of condition learning and\ncondition optimization. In the condition learning stage, we adopt the idea of\nControlNet and design some meaningful adjustments to make the unconditional\ngenerative model learn sub-structure conditioned generation. In the condition\noptimization stage, by using human preference learning, we further enhance the\nstability and robustness of sub-structure control. In our experiments, only\ntrained on randomly partitioned sub-structure data, the proposed method\noutperforms previous techniques by generating more valid and diverse molecules.\nOur method is easy to implement and can be quickly applied to various\npre-trained molecule generation models.",
    "categories": [
      "q-bio.BM",
      "cs.AI",
      "cs.LG",
      "physics.chem-ph"
    ],
    "primary_category": "q-bio.BM",
    "comment": "5 pages,3 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.06659v2",
    "published_date": "2024-04-22 14:36:19 UTC",
    "updated_date": "2024-12-21 08:22:54 UTC"
  },
  {
    "arxiv_id": "2404.14219v4",
    "title": "Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone",
    "authors": [
      "Marah Abdin",
      "Jyoti Aneja",
      "Hany Awadalla",
      "Ahmed Awadallah",
      "Ammar Ahmad Awan",
      "Nguyen Bach",
      "Amit Bahree",
      "Arash Bakhtiari",
      "Jianmin Bao",
      "Harkirat Behl",
      "Alon Benhaim",
      "Misha Bilenko",
      "Johan Bjorck",
      "Sébastien Bubeck",
      "Martin Cai",
      "Qin Cai",
      "Vishrav Chaudhary",
      "Dong Chen",
      "Dongdong Chen",
      "Weizhu Chen",
      "Yen-Chun Chen",
      "Yi-Ling Chen",
      "Hao Cheng",
      "Parul Chopra",
      "Xiyang Dai",
      "Matthew Dixon",
      "Ronen Eldan",
      "Victor Fragoso",
      "Jianfeng Gao",
      "Mei Gao",
      "Min Gao",
      "Amit Garg",
      "Allie Del Giorno",
      "Abhishek Goswami",
      "Suriya Gunasekar",
      "Emman Haider",
      "Junheng Hao",
      "Russell J. Hewett",
      "Wenxiang Hu",
      "Jamie Huynh",
      "Dan Iter",
      "Sam Ade Jacobs",
      "Mojan Javaheripi",
      "Xin Jin",
      "Nikos Karampatziakis",
      "Piero Kauffmann",
      "Mahoud Khademi",
      "Dongwoo Kim",
      "Young Jin Kim",
      "Lev Kurilenko",
      "James R. Lee",
      "Yin Tat Lee",
      "Yuanzhi Li",
      "Yunsheng Li",
      "Chen Liang",
      "Lars Liden",
      "Xihui Lin",
      "Zeqi Lin",
      "Ce Liu",
      "Liyuan Liu",
      "Mengchen Liu",
      "Weishung Liu",
      "Xiaodong Liu",
      "Chong Luo",
      "Piyush Madan",
      "Ali Mahmoudzadeh",
      "David Majercak",
      "Matt Mazzola",
      "Caio César Teodoro Mendes",
      "Arindam Mitra",
      "Hardik Modi",
      "Anh Nguyen",
      "Brandon Norick",
      "Barun Patra",
      "Daniel Perez-Becker",
      "Thomas Portet",
      "Reid Pryzant",
      "Heyang Qin",
      "Marko Radmilac",
      "Liliang Ren",
      "Gustavo de Rosa",
      "Corby Rosset",
      "Sambudha Roy",
      "Olatunji Ruwase",
      "Olli Saarikivi",
      "Amin Saied",
      "Adil Salim",
      "Michael Santacroce",
      "Shital Shah",
      "Ning Shang",
      "Hiteshi Sharma",
      "Yelong Shen",
      "Swadheen Shukla",
      "Xia Song",
      "Masahiro Tanaka",
      "Andrea Tupini",
      "Praneetha Vaddamanu",
      "Chunyu Wang",
      "Guanhua Wang",
      "Lijuan Wang",
      "Shuohang Wang",
      "Xin Wang",
      "Yu Wang",
      "Rachel Ward",
      "Wen Wen",
      "Philipp Witte",
      "Haiping Wu",
      "Xiaoxia Wu",
      "Michael Wyatt",
      "Bin Xiao",
      "Can Xu",
      "Jiahang Xu",
      "Weijian Xu",
      "Jilong Xue",
      "Sonali Yadav",
      "Fan Yang",
      "Jianwei Yang",
      "Yifan Yang",
      "Ziyi Yang",
      "Donghan Yu",
      "Lu Yuan",
      "Chenruidong Zhang",
      "Cyril Zhang",
      "Jianwen Zhang",
      "Li Lyna Zhang",
      "Yi Zhang",
      "Yue Zhang",
      "Yunan Zhang",
      "Xiren Zhou"
    ],
    "abstract": "We introduce phi-3-mini, a 3.8 billion parameter language model trained on\n3.3 trillion tokens, whose overall performance, as measured by both academic\nbenchmarks and internal testing, rivals that of models such as Mixtral 8x7B and\nGPT-3.5 (e.g., phi-3-mini achieves 69% on MMLU and 8.38 on MT-bench), despite\nbeing small enough to be deployed on a phone. Our training dataset is a\nscaled-up version of the one used for phi-2, composed of heavily filtered\npublicly available web data and synthetic data. The model is also further\naligned for robustness, safety, and chat format. We also provide\nparameter-scaling results with a 7B, 14B models trained for 4.8T tokens, called\nphi-3-small, phi-3-medium, both significantly more capable than phi-3-mini\n(e.g., respectively 75%, 78% on MMLU, and 8.7, 8.9 on MT-bench). To enhance\nmultilingual, multimodal, and long-context capabilities, we introduce three\nmodels in the phi-3.5 series: phi-3.5-mini, phi-3.5-MoE, and phi-3.5-Vision.\nThe phi-3.5-MoE, a 16 x 3.8B MoE model with 6.6 billion active parameters,\nachieves superior performance in language reasoning, math, and code tasks\ncompared to other open-source models of similar scale, such as Llama 3.1 and\nthe Mixtral series, and on par with Gemini-1.5-Flash and GPT-4o-mini.\nMeanwhile, phi-3.5-Vision, a 4.2 billion parameter model derived from\nphi-3.5-mini, excels in reasoning tasks and is adept at handling both\nsingle-image and text prompts, as well as multi-image and text prompts.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "24 pages",
    "pdf_url": "http://arxiv.org/pdf/2404.14219v4",
    "published_date": "2024-04-22 14:32:33 UTC",
    "updated_date": "2024-08-30 21:17:17 UTC"
  },
  {
    "arxiv_id": "2404.14198v1",
    "title": "BCFPL: Binary classification ConvNet based Fast Parking space recognition with Low resolution image",
    "authors": [
      "Shuo Zhang",
      "Xin Chen",
      "Zixuan Wang"
    ],
    "abstract": "The automobile plays an important role in the economic activities of mankind,\nespecially in the metropolis. Under the circumstances, the demand of quick\nsearch for available parking spaces has become a major concern for the\nautomobile drivers. Meanwhile, the public sense of privacy is also awaking, the\nimage-based parking space recognition methods lack the attention of privacy\nprotection. In this paper, we proposed a binary convolutional neural network\nwith lightweight design structure named BCFPL, which can be used to train with\nlow-resolution parking space images and offer a reasonable recognition result.\nThe images of parking space were collected from various complex environments,\nincluding different weather, occlusion conditions, and various camera angles.\nWe conducted the training and testing progresses among different datasets and\npartial subsets. The experimental results show that the accuracy of BCFPL does\nnot decrease compared with the original resolution image directly, and can\nreach the average level of the existing mainstream method. BCFPL also has low\nhardware requirements and fast recognition speed while meeting the privacy\nrequirements, so it has application potential in intelligent city construction\nand automatic driving field.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.14198v1",
    "published_date": "2024-04-22 14:07:42 UTC",
    "updated_date": "2024-04-22 14:07:42 UTC"
  },
  {
    "arxiv_id": "2404.14161v2",
    "title": "Tensor-Valued Time and Inference Path Optimization in Differential Equation-Based Generative Modeling",
    "authors": [
      "Dohoon Lee",
      "Kyogu Lee"
    ],
    "abstract": "In the field of generative modeling based on differential equations,\nconventional methods utilize scalar-valued time during both the training and\ninference phases. This work introduces, for the first time, a tensor-valued\ntime that expands the conventional scalar-valued time into multiple dimensions.\nAdditionally, we propose a novel path optimization problem designed to\nadaptively determine multidimensional inference trajectories using a\npredetermined differential equation solver and a fixed number of function\nevaluations. Our approach leverages the stochastic interpolant framework,\nsimulation dynamics, and adversarial training to optimize the inference\npathway. Notably, incorporating tensor-valued time during training improves\nsome models' inference performance, even without path optimization. When the\nadaptive, multidimensional path derived from our optimization process is\nemployed, further performance gains are achieved despite the fixed solver\nconfigurations. The introduction of tensor-valued time not only enhances the\nefficiency of models but also opens new avenues for exploration in training and\ninference methodologies, highlighting the potential of adaptive\nmultidimensional paths.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.14161v2",
    "published_date": "2024-04-22 13:20:01 UTC",
    "updated_date": "2024-05-25 08:10:27 UTC"
  },
  {
    "arxiv_id": "2404.14133v1",
    "title": "Quantum Convolutional Neural Networks for the detection of Gamma-Ray Bursts in the AGILE space mission data",
    "authors": [
      "A. Rizzo",
      "N. Parmiggiani",
      "A. Bulgarelli",
      "A. Macaluso",
      "V. Fioretti",
      "L. Castaldini",
      "A. Di Piano",
      "G. Panebianco",
      "C. Pittori",
      "M. Tavani",
      "C. Sartori",
      "C. Burigana",
      "V. Cardone",
      "F. Farsian",
      "M. Meneghetti",
      "G. Murante",
      "R. Scaramella",
      "F. Schillirò",
      "V. Testa",
      "T. Trombetti"
    ],
    "abstract": "Quantum computing represents a cutting-edge frontier in artificial\nintelligence. It makes use of hybrid quantum-classical computation which tries\nto leverage quantum mechanic principles that allow us to use a different\napproach to deep learning classification problems. The work presented here\nfalls within the context of the AGILE space mission, launched in 2007 by the\nItalian Space Agency. We implement different Quantum Convolutional Neural\nNetworks (QCNN) that analyze data acquired by the instruments onboard AGILE to\ndetect Gamma-Ray Bursts from sky maps or light curves. We use several\nframeworks such as TensorFlow-Quantum, Qiskit and PennyLane to simulate a\nquantum computer. We achieved an accuracy of 95.1% on sky maps with QCNNs,\nwhile the classical counterpart achieved 98.8% on the same data, using however\nhundreds of thousands more parameters.",
    "categories": [
      "astro-ph.HE",
      "cs.AI"
    ],
    "primary_category": "astro-ph.HE",
    "comment": "4 pages, 2 figures, proceedings of the ADASS XXXIII (2023)\n  conference, to appear in ASP Conference Serie",
    "pdf_url": "http://arxiv.org/pdf/2404.14133v1",
    "published_date": "2024-04-22 12:34:53 UTC",
    "updated_date": "2024-04-22 12:34:53 UTC"
  },
  {
    "arxiv_id": "2404.14117v2",
    "title": "Hierarchical localization with panoramic views and triplet loss functions",
    "authors": [
      "Marcos Alfaro",
      "Juan José Cabrera",
      "María Flores",
      "Óscar Reinoso",
      "Luis Payá"
    ],
    "abstract": "The main objective of this paper is to tackle visual localization, which is\nessential for the safe navigation of mobile robots. The solution we propose\nemploys panoramic images and triplet convolutional neural networks. We seek to\nexploit the properties of such architectures to address both hierarchical and\nglobal localization in indoor environments, which are prone to visual aliasing\nand other phenomena. Considering their importance in these architectures, a\ncomplete comparative evaluation of different triplet loss functions is\nperformed. The experimental section proves that triplet networks can be trained\nwith a relatively low number of images captured under a specific lighting\ncondition and even so, the resulting networks are a robust tool to perform\nvisual localization under dynamic conditions. Our approach has been evaluated\nagainst some of these effects, such as changes in the lighting conditions,\nocclusions, noise and motion blurring. Furthermore, to explore the limits of\nour approach, triplet networks have been tested in different indoor\nenvironments simultaneously. In all the cases, these architectures have\ndemonstrated a great capability to generalize to diverse and challenging\nscenarios. The code used in the experiments is available at\nhttps://github.com/MarcosAlfaro/TripletNetworksIndoorLocalization.git.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.14117v2",
    "published_date": "2024-04-22 12:07:10 UTC",
    "updated_date": "2024-11-22 15:51:52 UTC"
  },
  {
    "arxiv_id": "2404.14465v1",
    "title": "Benchmarking Advanced Text Anonymisation Methods: A Comparative Study on Novel and Traditional Approaches",
    "authors": [
      "Dimitris Asimopoulos",
      "Ilias Siniosoglou",
      "Vasileios Argyriou",
      "Thomai Karamitsou",
      "Eleftherios Fountoukidis",
      "Sotirios K. Goudos",
      "Ioannis D. Moscholios",
      "Konstantinos E. Psannis",
      "Panagiotis Sarigiannidis"
    ],
    "abstract": "In the realm of data privacy, the ability to effectively anonymise text is\nparamount. With the proliferation of deep learning and, in particular,\ntransformer architectures, there is a burgeoning interest in leveraging these\nadvanced models for text anonymisation tasks. This paper presents a\ncomprehensive benchmarking study comparing the performance of transformer-based\nmodels and Large Language Models(LLM) against traditional architectures for\ntext anonymisation. Utilising the CoNLL-2003 dataset, known for its robustness\nand diversity, we evaluate several models. Our results showcase the strengths\nand weaknesses of each approach, offering a clear perspective on the efficacy\nof modern versus traditional methods. Notably, while modern models exhibit\nadvanced capabilities in capturing con textual nuances, certain traditional\narchitectures still keep high performance. This work aims to guide researchers\nin selecting the most suitable model for their anonymisation needs, while also\nshedding light on potential paths for future advancements in the field.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.14465v1",
    "published_date": "2024-04-22 12:06:54 UTC",
    "updated_date": "2024-04-22 12:06:54 UTC"
  },
  {
    "arxiv_id": "2404.14082v3",
    "title": "Mechanistic Interpretability for AI Safety -- A Review",
    "authors": [
      "Leonard Bereska",
      "Efstratios Gavves"
    ],
    "abstract": "Understanding AI systems' inner workings is critical for ensuring value\nalignment and safety. This review explores mechanistic interpretability:\nreverse engineering the computational mechanisms and representations learned by\nneural networks into human-understandable algorithms and concepts to provide a\ngranular, causal understanding. We establish foundational concepts such as\nfeatures encoding knowledge within neural activations and hypotheses about\ntheir representation and computation. We survey methodologies for causally\ndissecting model behaviors and assess the relevance of mechanistic\ninterpretability to AI safety. We examine benefits in understanding, control,\nalignment, and risks such as capability gains and dual-use concerns. We\ninvestigate challenges surrounding scalability, automation, and comprehensive\ninterpretation. We advocate for clarifying concepts, setting standards, and\nscaling techniques to handle complex models and behaviors and expand to domains\nsuch as vision and reinforcement learning. Mechanistic interpretability could\nhelp prevent catastrophic outcomes as AI systems become more powerful and\ninscrutable.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted to TMLR; for an HTML version, visit\n  https://leonardbereska.github.io/blog/2024/mechinterpreview/",
    "pdf_url": "http://arxiv.org/pdf/2404.14082v3",
    "published_date": "2024-04-22 11:01:51 UTC",
    "updated_date": "2024-08-23 23:02:28 UTC"
  },
  {
    "arxiv_id": "2404.16877v1",
    "title": "Rapid Deployment of DNNs for Edge Computing via Structured Pruning at Initialization",
    "authors": [
      "Bailey J. Eccles",
      "Leon Wong",
      "Blesson Varghese"
    ],
    "abstract": "Edge machine learning (ML) enables localized processing of data on devices\nand is underpinned by deep neural networks (DNNs). However, DNNs cannot be\neasily run on devices due to their substantial computing, memory and energy\nrequirements for delivering performance that is comparable to cloud-based ML.\nTherefore, model compression techniques, such as pruning, have been considered.\nExisting pruning methods are problematic for edge ML since they: (1) Create\ncompressed models that have limited runtime performance benefits (using\nunstructured pruning) or compromise the final model accuracy (using structured\npruning), and (2) Require substantial compute resources and time for\nidentifying a suitable compressed DNN model (using neural architecture search).\nIn this paper, we explore a new avenue, referred to as\nPruning-at-Initialization (PaI), using structured pruning to mitigate the above\nproblems. We develop Reconvene, a system for rapidly generating pruned models\nsuited for edge deployments using structured PaI. Reconvene systematically\nidentifies and prunes DNN convolution layers that are least sensitive to\nstructured pruning. Reconvene rapidly creates pruned DNNs within seconds that\nare up to 16.21x smaller and 2x faster while maintaining the same accuracy as\nan unstructured PaI counterpart.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "The 24th IEEE/ACM International Symposium on Cluster, Cloud and\n  Internet Computing",
    "pdf_url": "http://arxiv.org/pdf/2404.16877v1",
    "published_date": "2024-04-22 10:57:54 UTC",
    "updated_date": "2024-04-22 10:57:54 UTC"
  },
  {
    "arxiv_id": "2404.14073v1",
    "title": "Towards Robust Trajectory Representations: Isolating Environmental Confounders with Causal Learning",
    "authors": [
      "Kang Luo",
      "Yuanshao Zhu",
      "Wei Chen",
      "Kun Wang",
      "Zhengyang Zhou",
      "Sijie Ruan",
      "Yuxuan Liang"
    ],
    "abstract": "Trajectory modeling refers to characterizing human movement behavior, serving\nas a pivotal step in understanding mobility patterns. Nevertheless, existing\nstudies typically ignore the confounding effects of geospatial context, leading\nto the acquisition of spurious correlations and limited generalization\ncapabilities. To bridge this gap, we initially formulate a Structural Causal\nModel (SCM) to decipher the trajectory representation learning process from a\ncausal perspective. Building upon the SCM, we further present a Trajectory\nmodeling framework (TrajCL) based on Causal Learning, which leverages the\nbackdoor adjustment theory as an intervention tool to eliminate the spurious\ncorrelations between geospatial context and trajectories. Extensive experiments\non two real-world datasets verify that TrajCL markedly enhances performance in\ntrajectory classification tasks while showcasing superior generalization and\ninterpretability.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "The paper has been accepted by IJCAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.14073v1",
    "published_date": "2024-04-22 10:34:58 UTC",
    "updated_date": "2024-04-22 10:34:58 UTC"
  },
  {
    "arxiv_id": "2407.05180v3",
    "title": "ReCAP: Recursive Cross Attention Network for Pseudo-Label Generation in Robotic Surgical Skill Assessment",
    "authors": [
      "Julien Quarez",
      "Marc Modat",
      "Sebastien Ourselin",
      "Jonathan Shapey",
      "Alejandro Granados"
    ],
    "abstract": "In surgical skill assessment, the Objective Structured Assessments of\nTechnical Skills (OSATS) and Global Rating Scale (GRS) are well-established\ntools for evaluating surgeons during training. These metrics, along with\nperformance feedback, help surgeons improve and reach practice standards.\nRecent research on the open-source JIGSAWS dataset, which includes both GRS and\nOSATS labels, has focused on regressing GRS scores from kinematic data, video,\nor their combination. However, we argue that regressing GRS alone is limiting,\nas it aggregates OSATS scores and overlooks clinically meaningful variations\nduring a surgical trial. To address this, we developed a recurrent transformer\nmodel that tracks a surgeon's performance throughout a session by mapping\nhidden states to six OSATS, derived from kinematic data, using a clinically\nmotivated objective function. These OSATS scores are averaged to predict GRS,\nallowing us to compare our model's performance against state-of-the-art (SOTA)\nmethods. We report Spearman's Correlation Coefficients (SCC) demonstrating that\nour model outperforms SOTA using kinematic data (SCC 0.83-0.88), and matches\nperformance with video-based models. Our model also surpasses SOTA in most\ntasks for average OSATS predictions (SCC 0.46-0.70) and specific OSATS (SCC\n0.56-0.95). The generation of pseudo-labels at the segment level translates\nquantitative predictions into qualitative feedback, vital for automated\nsurgical skill assessment pipelines. A senior surgeon validated our model's\noutputs, agreeing with 77% of the weakly-supervised predictions (p=0.006).",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.05180v3",
    "published_date": "2024-04-22 10:33:06 UTC",
    "updated_date": "2024-10-24 11:18:24 UTC"
  },
  {
    "arxiv_id": "2404.14068v1",
    "title": "Holistic Safety and Responsibility Evaluations of Advanced AI Models",
    "authors": [
      "Laura Weidinger",
      "Joslyn Barnhart",
      "Jenny Brennan",
      "Christina Butterfield",
      "Susie Young",
      "Will Hawkins",
      "Lisa Anne Hendricks",
      "Ramona Comanescu",
      "Oscar Chang",
      "Mikel Rodriguez",
      "Jennifer Beroshi",
      "Dawn Bloxwich",
      "Lev Proleev",
      "Jilin Chen",
      "Sebastian Farquhar",
      "Lewis Ho",
      "Iason Gabriel",
      "Allan Dafoe",
      "William Isaac"
    ],
    "abstract": "Safety and responsibility evaluations of advanced AI models are a critical\nbut developing field of research and practice. In the development of Google\nDeepMind's advanced AI models, we innovated on and applied a broad set of\napproaches to safety evaluation. In this report, we summarise and share\nelements of our evolving approach as well as lessons learned for a broad\naudience. Key lessons learned include: First, theoretical underpinnings and\nframeworks are invaluable to organise the breadth of risk domains, modalities,\nforms, metrics, and goals. Second, theory and practice of safety evaluation\ndevelopment each benefit from collaboration to clarify goals, methods and\nchallenges, and facilitate the transfer of insights between different\nstakeholders and disciplines. Third, similar key methods, lessons, and\ninstitutions apply across the range of concerns in responsibility and safety -\nincluding established and emerging harms. For this reason it is important that\na wide range of actors working on safety evaluation and safety research\ncommunities work together to develop, refine and implement novel evaluation\napproaches and best practices, rather than operating in silos. The report\nconcludes with outlining the clear need to rapidly advance the science of\nevaluations, to integrate new evaluations into the development and governance\nof AI, to establish scientifically-grounded norms and standards, and to promote\na robust evaluation ecosystem.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "10 pages excluding bibliography",
    "pdf_url": "http://arxiv.org/pdf/2404.14068v1",
    "published_date": "2024-04-22 10:26:49 UTC",
    "updated_date": "2024-04-22 10:26:49 UTC"
  },
  {
    "arxiv_id": "2404.14061v2",
    "title": "FedTAD: Topology-aware Data-free Knowledge Distillation for Subgraph Federated Learning",
    "authors": [
      "Yinlin Zhu",
      "Xunkai Li",
      "Zhengyu Wu",
      "Di Wu",
      "Miao Hu",
      "Rong-Hua Li"
    ],
    "abstract": "Subgraph federated learning (subgraph-FL) is a new distributed paradigm that\nfacilitates the collaborative training of graph neural networks (GNNs) by\nmulti-client subgraphs. Unfortunately, a significant challenge of subgraph-FL\narises from subgraph heterogeneity, which stems from node and topology\nvariation, causing the impaired performance of the global GNN. Despite various\nstudies, they have not yet thoroughly investigated the impact mechanism of\nsubgraph heterogeneity. To this end, we decouple node and topology variation,\nrevealing that they correspond to differences in label distribution and\nstructure homophily. Remarkably, these variations lead to significant\ndifferences in the class-wise knowledge reliability of multiple local GNNs,\nmisguiding the model aggregation with varying degrees. Building on this\ninsight, we propose topology-aware data-free knowledge distillation technology\n(FedTAD), enhancing reliable knowledge transfer from the local model to the\nglobal model. Extensive experiments on six public datasets consistently\ndemonstrate the superiority of FedTAD over state-of-the-art baselines.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DB",
      "cs.SI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by IJCAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.14061v2",
    "published_date": "2024-04-22 10:19:02 UTC",
    "updated_date": "2024-04-25 06:40:22 UTC"
  },
  {
    "arxiv_id": "2404.14050v1",
    "title": "Unlawful Proxy Discrimination: A Framework for Challenging Inherently Discriminatory Algorithms",
    "authors": [
      "Hilde Weerts",
      "Aislinn Kelly-Lyth",
      "Reuben Binns",
      "Jeremias Adams-Prassl"
    ],
    "abstract": "Emerging scholarship suggests that the EU legal concept of direct\ndiscrimination - where a person is given different treatment on grounds of a\nprotected characteristic - may apply to various algorithmic decision-making\ncontexts. This has important implications: unlike indirect discrimination,\nthere is generally no 'objective justification' stage in the direct\ndiscrimination framework, which means that the deployment of directly\ndiscriminatory algorithms will usually be unlawful per se. In this paper, we\nfocus on the most likely candidate for direct discrimination in the algorithmic\ncontext, termed inherent direct discrimination, where a proxy is inextricably\nlinked to a protected characteristic. We draw on computer science literature to\nsuggest that, in the algorithmic context, 'treatment on the grounds of' needs\nto be understood in terms of two steps: proxy capacity and proxy use. Only\nwhere both elements can be made out can direct discrimination be said to be `on\ngrounds of' a protected characteristic. We analyse the legal conditions of our\nproposed proxy capacity and proxy use tests. Based on this analysis, we discuss\ntechnical approaches and metrics that could be developed or applied to identify\ninherent direct discrimination in algorithmic decision-making.",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.14050v1",
    "published_date": "2024-04-22 10:06:17 UTC",
    "updated_date": "2024-04-22 10:06:17 UTC"
  },
  {
    "arxiv_id": "2404.14464v1",
    "title": "Tree of Reviews: A Tree-based Dynamic Iterative Retrieval Framework for Multi-hop Question Answering",
    "authors": [
      "Li Jiapeng",
      "Liu Runze",
      "Li Yabo",
      "Zhou Tong",
      "Li Mingling",
      "Chen Xiang"
    ],
    "abstract": "Multi-hop question answering is a knowledge-intensive complex problem. Large\nLanguage Models (LLMs) use their Chain of Thoughts (CoT) capability to reason\ncomplex problems step by step, and retrieval-augmentation can effectively\nalleviate factual errors caused by outdated and unknown knowledge in LLMs.\nRecent works have introduced retrieval-augmentation in the CoT reasoning to\nsolve multi-hop question answering. However, these chain methods have the\nfollowing problems: 1) Retrieved irrelevant paragraphs may mislead the\nreasoning; 2) An error in the chain structure may lead to a cascade of errors.\n  In this paper, we propose a dynamic retrieval framework called Tree of\nReviews (ToR), where the root node is the question, and the other nodes are\nparagraphs from retrieval, extending different reasoning paths from the root\nnode to other nodes. Our framework dynamically decides to initiate a new\nsearch, reject, or accept based on the paragraphs on the reasoning paths.\nCompared to related work, we introduce a tree structure to handle each\nretrieved paragraph separately, alleviating the misleading effect of irrelevant\nparagraphs on the reasoning path; the diversity of reasoning path extension\nreduces the impact of a single reasoning error on the whole. We conducted\nexperiments on three different multi-hop question answering datasets. The\nresults show that compared to the baseline methods, ToR achieves\nstate-of-the-art performance in both retrieval and response generation. In\naddition, we propose two tree-based search optimization strategies, pruning and\neffective expansion, to reduce time overhead and increase the diversity of path\nextension. We will release our code.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "Keywords: Muti-hop Question Answering; Retrieval-Augmented\n  Generation; Tree of Thought; Reasoning TLDR: We proposed a tree-based\n  dynamic, iterative retrieval framework for multi-hop question answering",
    "pdf_url": "http://arxiv.org/pdf/2404.14464v1",
    "published_date": "2024-04-22 09:25:05 UTC",
    "updated_date": "2024-04-22 09:25:05 UTC"
  },
  {
    "arxiv_id": "2404.16876v1",
    "title": "AdaQAT: Adaptive Bit-Width Quantization-Aware Training",
    "authors": [
      "Cédric Gernigon",
      "Silviu-Ioan Filip",
      "Olivier Sentieys",
      "Clément Coggiola",
      "Mickael Bruno"
    ],
    "abstract": "Large-scale deep neural networks (DNNs) have achieved remarkable success in\nmany application scenarios. However, high computational complexity and energy\ncosts of modern DNNs make their deployment on edge devices challenging. Model\nquantization is a common approach to deal with deployment constraints, but\nsearching for optimized bit-widths can be challenging. In this work, we present\nAdaptive Bit-Width Quantization Aware Training (AdaQAT), a learning-based\nmethod that automatically optimizes weight and activation signal bit-widths\nduring training for more efficient DNN inference. We use relaxed real-valued\nbit-widths that are updated using a gradient descent rule, but are otherwise\ndiscretized for all quantization operations. The result is a simple and\nflexible QAT approach for mixed-precision uniform quantization problems.\nCompared to other methods that are generally designed to be run on a pretrained\nnetwork, AdaQAT works well in both training from scratch and fine-tuning\nscenarios.Initial results on the CIFAR-10 and ImageNet datasets using ResNet20\nand ResNet18 models, respectively, indicate that our method is competitive with\nother state-of-the-art mixed-precision quantization approaches.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.16876v1",
    "published_date": "2024-04-22 09:23:56 UTC",
    "updated_date": "2024-04-22 09:23:56 UTC"
  },
  {
    "arxiv_id": "2405.02324v1",
    "title": "Combined Compromise for Ideal Solution (CoCoFISo): a multi-criteria decision-making based on the CoCoSo method algorithm",
    "authors": [
      "Rôlin Gabriel Rasoanaivo",
      "Morteza Yazdani",
      "Pascale Zaraté",
      "Amirhossein Fateh"
    ],
    "abstract": "Each decision-making tool should be tested and validated in real case studies\nto be practical and fit to global problems. The application of multi-criteria\ndecision-making methods (MCDM) is currently a trend to rank alternatives. In\nthe literature, there are several multi-criteria decision-making methods\naccording to their classification. During our experimentation on the Combined\nCompromise Solution (CoCoSo) method, we encountered its limits for real cases.\nThe authors examined the applicability of the CoCoFISo method (improved version\nof combined compromise solution), by a real case study in a university campus\nand compared the obtained results to other MCDMs such as Preference Ranking\nOrganisation Method for Enrichment Evaluations (PROMETHEE), Weighted Sum Method\n(WSM) and Technique for Order Preference by Similarity to the Ideal Solution\n(TOPSIS). Our research finding indicates that CoCoSo is an applied method that\nhas been developed to solve complex multi variable assessment problems, while\nCoCoFISo can improve the shortages observed in CoCoSo and deliver stable\noutcomes compared to other developed tools. The findings imply that application\nof CoCoFISo is suggested to decision makers, experts and researchers while they\nare facing practical challenges and sensitive questions regarding the\nutilization of a reliable decision-making method. Unlike many prior studies,\nthe current version of CoCoSo is unique, original and is presented for the\nfirst time. Its performance was approved using several strategies and\nexaminations.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Expert Systems with Applications, 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.02324v1",
    "published_date": "2024-04-22 09:19:33 UTC",
    "updated_date": "2024-04-22 09:19:33 UTC"
  },
  {
    "arxiv_id": "2404.14007v1",
    "title": "Infusion: Preventing Customized Text-to-Image Diffusion from Overfitting",
    "authors": [
      "Weili Zeng",
      "Yichao Yan",
      "Qi Zhu",
      "Zhuo Chen",
      "Pengzhi Chu",
      "Weiming Zhao",
      "Xiaokang Yang"
    ],
    "abstract": "Text-to-image (T2I) customization aims to create images that embody specific\nvisual concepts delineated in textual descriptions. However, existing works\nstill face a main challenge, concept overfitting. To tackle this challenge, we\nfirst analyze overfitting, categorizing it into concept-agnostic overfitting,\nwhich undermines non-customized concept knowledge, and concept-specific\noverfitting, which is confined to customize on limited modalities, i.e,\nbackgrounds, layouts, styles. To evaluate the overfitting degree, we further\nintroduce two metrics, i.e, Latent Fisher divergence and Wasserstein metric to\nmeasure the distribution changes of non-customized and customized concept\nrespectively. Drawing from the analysis, we propose Infusion, a T2I\ncustomization method that enables the learning of target concepts to avoid\nbeing constrained by limited training modalities, while preserving\nnon-customized knowledge. Remarkably, Infusion achieves this feat with\nremarkable efficiency, requiring a mere 11KB of trained parameters. Extensive\nexperiments also demonstrate that our approach outperforms state-of-the-art\nmethods in both single and multi-concept customized generation.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "10 pages",
    "pdf_url": "http://arxiv.org/pdf/2404.14007v1",
    "published_date": "2024-04-22 09:16:25 UTC",
    "updated_date": "2024-04-22 09:16:25 UTC"
  },
  {
    "arxiv_id": "2406.15386v1",
    "title": "U Can't Gen This? A Survey of Intellectual Property Protection Methods for Data in Generative AI",
    "authors": [
      "Tanja Šarčević",
      "Alicja Karlowicz",
      "Rudolf Mayer",
      "Ricardo Baeza-Yates",
      "Andreas Rauber"
    ],
    "abstract": "Large Generative AI (GAI) models have the unparalleled ability to generate\ntext, images, audio, and other forms of media that are increasingly\nindistinguishable from human-generated content. As these models often train on\npublicly available data, including copyrighted materials, art and other\ncreative works, they inadvertently risk violating copyright and\nmisappropriation of intellectual property (IP). Due to the rapid development of\ngenerative AI technology and pressing ethical considerations from stakeholders,\nprotective mechanisms and techniques are emerging at a high pace but lack\nsystematisation.\n  In this paper, we study the concerns regarding the intellectual property\nrights of training data and specifically focus on the properties of generative\nmodels that enable misuse leading to potential IP violations. Then we propose a\ntaxonomy that leads to a systematic review of technical solutions for\nsafeguarding the data from intellectual property violations in GAI.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.15386v1",
    "published_date": "2024-04-22 09:09:21 UTC",
    "updated_date": "2024-04-22 09:09:21 UTC"
  },
  {
    "arxiv_id": "2404.14463v1",
    "title": "DAIC-WOZ: On the Validity of Using the Therapist's prompts in Automatic Depression Detection from Clinical Interviews",
    "authors": [
      "Sergio Burdisso",
      "Ernesto Reyes-Ramírez",
      "Esaú Villatoro-Tello",
      "Fernando Sánchez-Vega",
      "Pastor López-Monroy",
      "Petr Motlicek"
    ],
    "abstract": "Automatic depression detection from conversational data has gained\nsignificant interest in recent years. The DAIC-WOZ dataset, interviews\nconducted by a human-controlled virtual agent, has been widely used for this\ntask. Recent studies have reported enhanced performance when incorporating\ninterviewer's prompts into the model. In this work, we hypothesize that this\nimprovement might be mainly due to a bias present in these prompts, rather than\nthe proposed architectures and methods. Through ablation experiments and\nqualitative analysis, we discover that models using interviewer's prompts learn\nto focus on a specific region of the interviews, where questions about past\nexperiences with mental health issues are asked, and use them as discriminative\nshortcuts to detect depressed participants. In contrast, models using\nparticipant responses gather evidence from across the entire interview.\nFinally, to highlight the magnitude of this bias, we achieve a 0.90 F1 score by\nintentionally exploiting it, the highest result reported to date on this\ndataset using only textual information. Our findings underline the need for\ncaution when incorporating interviewers' prompts into models, as they may\ninadvertently learn to exploit targeted prompts, rather than learning to\ncharacterize the language and behavior that are genuinely indicative of the\npatient's mental health condition.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to Clinical NLP workshop at NAACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.14463v1",
    "published_date": "2024-04-22 09:07:50 UTC",
    "updated_date": "2024-04-22 09:07:50 UTC"
  },
  {
    "arxiv_id": "2404.13973v1",
    "title": "DEQ-MCL: Discrete-Event Queue-based Monte-Carlo Localization",
    "authors": [
      "Akira Taniguchi",
      "Ayako Fukawa",
      "Hiroshi Yamakawa"
    ],
    "abstract": "Spatial cognition in hippocampal formation is posited to play a crucial role\nin the development of self-localization techniques for robots. In this paper,\nwe propose a self-localization approach, DEQ-MCL, based on the discrete event\nqueue hypothesis associated with phase precession within the hippocampal\nformation. Our method effectively estimates the posterior distribution of\nstates, encompassing both past, present, and future states that are organized\nas a queue. This approach enables the smoothing of the posterior distribution\nof past states using current observations and the weighting of the joint\ndistribution by considering the feasibility of future states. Our findings\nindicate that the proposed method holds promise for augmenting\nself-localization performance in indoor environments.",
    "categories": [
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted by AROB-ISBC-SWARM 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.13973v1",
    "published_date": "2024-04-22 08:29:00 UTC",
    "updated_date": "2024-04-22 08:29:00 UTC"
  },
  {
    "arxiv_id": "2404.15154v2",
    "title": "Do not think about pink elephant!",
    "authors": [
      "Kyomin Hwang",
      "Suyoung Kim",
      "JunHoo Lee",
      "Nojun Kwak"
    ],
    "abstract": "Large Models (LMs) have heightened expectations for the potential of general\nAI as they are akin to human intelligence. This paper shows that recent large\nmodels such as Stable Diffusion and DALL-E3 also share the vulnerability of\nhuman intelligence, namely the \"white bear phenomenon\". We investigate the\ncauses of the white bear phenomenon by analyzing their representation space.\nBased on this analysis, we propose a simple prompt-based attack method, which\ngenerates figures prohibited by the LM provider's policy. To counter these\nattacks, we introduce prompt-based defense strategies inspired by cognitive\ntherapy techniques, successfully mitigating attacks by up to 48.22\\%.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "This paper is accepted in CVPR 2024 Responsible Generative AI\n  Workshop (ReGenAI)",
    "pdf_url": "http://arxiv.org/pdf/2404.15154v2",
    "published_date": "2024-04-22 08:28:13 UTC",
    "updated_date": "2024-10-31 04:32:26 UTC"
  },
  {
    "arxiv_id": "2404.13968v3",
    "title": "Protecting Your LLMs with Information Bottleneck",
    "authors": [
      "Zichuan Liu",
      "Zefan Wang",
      "Linjie Xu",
      "Jinyu Wang",
      "Lei Song",
      "Tianchun Wang",
      "Chunlin Chen",
      "Wei Cheng",
      "Jiang Bian"
    ],
    "abstract": "The advent of large language models (LLMs) has revolutionized the field of\nnatural language processing, yet they might be attacked to produce harmful\ncontent. Despite efforts to ethically align LLMs, these are often fragile and\ncan be circumvented by jailbreaking attacks through optimized or manual\nadversarial prompts. To address this, we introduce the Information Bottleneck\nProtector (IBProtector), a defense mechanism grounded in the information\nbottleneck principle, and we modify the objective to avoid trivial solutions.\nThe IBProtector selectively compresses and perturbs prompts, facilitated by a\nlightweight and trainable extractor, preserving only essential information for\nthe target LLMs to respond with the expected answer. Moreover, we further\nconsider a situation where the gradient is not visible to be compatible with\nany LLM. Our empirical evaluations show that IBProtector outperforms current\ndefense methods in mitigating jailbreak attempts, without overly affecting\nresponse quality or inference speed. Its effectiveness and adaptability across\nvarious attack methods and target LLMs underscore the potential of IBProtector\nas a novel, transferable defense that bolsters the security of LLMs without\nrequiring modifications to the underlying models.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by Neural Information Processing Systems (NeurIPS 2024)",
    "pdf_url": "http://arxiv.org/pdf/2404.13968v3",
    "published_date": "2024-04-22 08:16:07 UTC",
    "updated_date": "2024-10-10 13:22:58 UTC"
  },
  {
    "arxiv_id": "2404.13954v1",
    "title": "A survey of air combat behavior modeling using machine learning",
    "authors": [
      "Patrick Ribu Gorton",
      "Andreas Strand",
      "Karsten Brathen"
    ],
    "abstract": "With the recent advances in machine learning, creating agents that behave\nrealistically in simulated air combat has become a growing field of interest.\nThis survey explores the application of machine learning techniques for\nmodeling air combat behavior, motivated by the potential to enhance\nsimulation-based pilot training. Current simulated entities tend to lack\nrealistic behavior, and traditional behavior modeling is labor-intensive and\nprone to loss of essential domain knowledge between development steps.\nAdvancements in reinforcement learning and imitation learning algorithms have\ndemonstrated that agents may learn complex behavior from data, which could be\nfaster and more scalable than manual methods. Yet, making adaptive agents\ncapable of performing tactical maneuvers and operating weapons and sensors\nstill poses a significant challenge. The survey examines applications, behavior\nmodel types, prevalent machine learning methods, and the technical and human\nchallenges in developing adaptive and realistically behaving agents. Another\nchallenge is the transfer of agents from learning environments to military\nsimulation systems and the consequent demand for standardization. Four primary\nrecommendations are presented regarding increased emphasis on\nbeyond-visual-range scenarios, multi-agent machine learning and cooperation,\nutilization of hierarchical behavior models, and initiatives for\nstandardization and research collaboration. These recommendations aim to\naddress current issues and guide the development of more comprehensive,\nadaptable, and realistic machine learning-based behavior models for air combat\napplications.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA",
      "F.2.0; I.2.1; I.2.6; I.2.8"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.13954v1",
    "published_date": "2024-04-22 07:54:56 UTC",
    "updated_date": "2024-04-22 07:54:56 UTC"
  },
  {
    "arxiv_id": "2404.13941v1",
    "title": "Autoencoder-assisted Feature Ensemble Net for Incipient Faults",
    "authors": [
      "Mingxuan Gao",
      "Min Wang",
      "Maoyin Chen"
    ],
    "abstract": "Deep learning has shown the great power in the field of fault detection.\nHowever, for incipient faults with tiny amplitude, the detection performance of\nthe current deep learning networks (DLNs) is not satisfactory. Even if prior\ninformation about the faults is utilized, DLNs can't successfully detect faults\n3, 9 and 15 in Tennessee Eastman process (TEP). These faults are notoriously\ndifficult to detect, lacking effective detection technologies in the field of\nfault detection. In this work, we propose Autoencoder-assisted Feature Ensemble\nNet (AE-FENet): a deep feature ensemble framework that uses the unsupervised\nautoencoder to conduct the feature transformation. Compared with the principle\ncomponent analysis (PCA) technique adopted in the original Feature Ensemble Net\n(FENet), autoencoder can mine more exact features on incipient faults, which\nresults in the better detection performance of AE-FENet. With same kinds of\nbasic detectors, AE-FENet achieves a state-of-the-art average accuracy over 96%\non faults 3, 9 and 15 in TEP, which represents a significant enhancement in\nperformance compared to other methods. Plenty of experiments have been done to\nextend our framework, proving that DLNs can be utilized efficiently within this\narchitecture.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.LG",
      "cs.SY"
    ],
    "primary_category": "eess.SY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.13941v1",
    "published_date": "2024-04-22 07:34:28 UTC",
    "updated_date": "2024-04-22 07:34:28 UTC"
  },
  {
    "arxiv_id": "2404.16068v1",
    "title": "SemEval-2024 Task 9: BRAINTEASER: A Novel Task Defying Common Sense",
    "authors": [
      "Yifan Jiang",
      "Filip Ilievski",
      "Kaixin Ma"
    ],
    "abstract": "While vertical thinking relies on logical and commonsense reasoning, lateral\nthinking requires systems to defy commonsense associations and overwrite them\nthrough unconventional thinking. Lateral thinking has been shown to be\nchallenging for current models but has received little attention. A recent\nbenchmark, BRAINTEASER, aims to evaluate current models' lateral thinking\nability in a zero-shot setting. In this paper, we split the original benchmark\nto also support fine-tuning setting and present SemEval Task 9:\nBRAIN-TEASER(S), the first task at this competition designed to test the\nsystem's reasoning and lateral thinking ability. As a popular task,\nBRAINTEASER(S)'s two subtasks receive 483 team submissions from 182\nparticipants during the competition. This paper provides a fine-grained system\nanalysis of the competition results, together with a reflection on what this\nmeans for the ability of the systems to reason laterally. We hope that the\nBRAINTEASER(S) subtasks and findings in this paper can stimulate future work on\nlateral thinking and robust reasoning by computational models.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.16068v1",
    "published_date": "2024-04-22 07:21:27 UTC",
    "updated_date": "2024-04-22 07:21:27 UTC"
  },
  {
    "arxiv_id": "2404.13919v2",
    "title": "Navigating the Path of Writing: Outline-guided Text Generation with Large Language Models",
    "authors": [
      "Yukyung Lee",
      "Soonwon Ka",
      "Bokyung Son",
      "Pilsung Kang",
      "Jaewook Kang"
    ],
    "abstract": "Large Language Models (LLMs) have impacted the writing process, enhancing\nproductivity by collaborating with humans in content creation platforms.\nHowever, generating high-quality, user-aligned text to satisfy real-world\ncontent creation needs remains challenging. We propose WritingPath, a framework\nthat uses explicit outlines to guide LLMs in generating goal-oriented,\nhigh-quality text. Our approach draws inspiration from structured writing\nplanning and reasoning paths, focusing on reflecting user intentions throughout\nthe writing process. To validate our approach in real-world scenarios, we\nconstruct a diverse dataset from unstructured blog posts to benchmark writing\nperformance and introduce a comprehensive evaluation framework assessing the\nquality of outlines and generated texts. Our evaluations with various LLMs\ndemonstrate that the WritingPath approach significantly enhances text quality\naccording to evaluations by both LLMs and professional writers.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "NAACL 2025 (Industry Track)",
    "pdf_url": "http://arxiv.org/pdf/2404.13919v2",
    "published_date": "2024-04-22 06:57:43 UTC",
    "updated_date": "2025-02-23 15:24:45 UTC"
  },
  {
    "arxiv_id": "2404.13910v1",
    "title": "Integrated Gradient Correlation: a Dataset-wise Attribution Method",
    "authors": [
      "Pierre Lelièvre",
      "Chien-Chung Chen"
    ],
    "abstract": "Attribution methods are primarily designed to study the distribution of input\ncomponent contributions to individual model predictions. However, some research\napplications require a summary of attribution patterns across the entire\ndataset to facilitate the interpretability of the scrutinized models. In this\npaper, we present a new method called Integrated Gradient Correlation (IGC)\nthat relates dataset-wise attributions to a model prediction score and enables\nregion-specific analysis by a direct summation over associated components. We\ndemonstrate our method on scalar predictions with the study of image feature\nrepresentation in the brain from fMRI neural signals and the estimation of\nneural population receptive fields (NSD dataset), as well as on categorical\npredictions with the investigation of handwritten digit recognition (MNIST\ndataset). The resulting IGC attributions show selective patterns, revealing\nunderlying model strategies coherent with their respective objectives.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "12 pages, 8 figures, source code at\n  https://github.com/plelievre/int_grad_corr.git",
    "pdf_url": "http://arxiv.org/pdf/2404.13910v1",
    "published_date": "2024-04-22 06:42:21 UTC",
    "updated_date": "2024-04-22 06:42:21 UTC"
  },
  {
    "arxiv_id": "2406.00001v1",
    "title": "PhyPlan: Generalizable and Rapid Physical Task Planning with Physics Informed Skill Networks for Robot Manipulators",
    "authors": [
      "Mudit Chopra",
      "Abhinav Barnawal",
      "Harshil Vagadia",
      "Tamajit Banerjee",
      "Shreshth Tuli",
      "Souvik Chakraborty",
      "Rohan Paul"
    ],
    "abstract": "Given the task of positioning a ball-like object to a goal region beyond\ndirect reach, humans can often throw, slide, or rebound objects against the\nwall to attain the goal. However, enabling robots to reason similarly is\nnon-trivial. Existing methods for physical reasoning are data-hungry and\nstruggle with complexity and uncertainty inherent in the real world. This paper\npresents PhyPlan, a novel physics-informed planning framework that combines\nphysics-informed neural networks (PINNs) with modified Monte Carlo Tree Search\n(MCTS) to enable embodied agents to perform dynamic physical tasks. PhyPlan\nleverages PINNs to simulate and predict outcomes of actions in a fast and\naccurate manner and uses MCTS for planning. It dynamically determines whether\nto consult a PINN-based simulator (coarse but fast) or engage directly with the\nactual environment (fine but slow) to determine optimal policy. Given an unseen\ntask, PhyPlan can infer the sequence of actions and learn the latent\nparameters, resulting in a generalizable approach that can rapidly learn to\nperform novel physical tasks. Evaluation with robots in simulated 3D\nenvironments demonstrates the ability of our approach to solve 3D-physical\nreasoning tasks involving the composition of dynamic skills. Quantitatively,\nPhyPlan excels in several aspects: (i) it achieves lower regret when learning\nnovel tasks compared to the state-of-the-art, (ii) it expedites skill learning\nand enhances the speed of physical reasoning, (iii) it demonstrates higher data\nefficiency compared to a physics un-informed approach.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "arXiv admin note: substantial text overlap with arXiv:2402.15767",
    "pdf_url": "http://arxiv.org/pdf/2406.00001v1",
    "published_date": "2024-04-22 06:35:08 UTC",
    "updated_date": "2024-04-22 06:35:08 UTC"
  },
  {
    "arxiv_id": "2404.13906v2",
    "title": "Generating Attractive and Authentic Copywriting from Customer Reviews",
    "authors": [
      "Yu-Xiang Lin",
      "Wei-Yun Ma"
    ],
    "abstract": "The goal of product copywriting is to capture the interest of potential\nbuyers by emphasizing the features of products through text descriptions. As\ne-commerce platforms offer a wide range of services, it's becoming essential to\ndynamically adjust the styles of these auto-generated descriptions. Typical\napproaches to copywriting generation often rely solely on specified product\nattributes, which may result in dull and repetitive content. To tackle this\nissue, we propose to generate copywriting based on customer reviews, as they\nprovide firsthand practical experiences with products, offering a richer source\nof information than just product attributes. We have developed a\nsequence-to-sequence framework, enhanced with reinforcement learning, to\nproduce copywriting that is attractive, authentic, and rich in information. Our\nframework outperforms all existing baseline and zero-shot large language\nmodels, including LLaMA-2-chat-7B and GPT-3.5, in terms of both attractiveness\nand faithfulness. Furthermore, this work features the use of LLMs for\naspect-based summaries collection and argument allure assessment. Experiments\ndemonstrate the effectiveness of using LLMs for marketing domain corpus\nconstruction. The code and the dataset is publicly available at:\nhttps://github.com/YuXiangLin1234/Copywriting-Generation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "NAACL 2024 main conference paper",
    "pdf_url": "http://arxiv.org/pdf/2404.13906v2",
    "published_date": "2024-04-22 06:33:28 UTC",
    "updated_date": "2024-05-14 08:05:00 UTC"
  },
  {
    "arxiv_id": "2404.15155v3",
    "title": "MDAgents: An Adaptive Collaboration of LLMs for Medical Decision-Making",
    "authors": [
      "Yubin Kim",
      "Chanwoo Park",
      "Hyewon Jeong",
      "Yik Siu Chan",
      "Xuhai Xu",
      "Daniel McDuff",
      "Hyeonhoon Lee",
      "Marzyeh Ghassemi",
      "Cynthia Breazeal",
      "Hae Won Park"
    ],
    "abstract": "Foundation models are becoming valuable tools in medicine. Yet despite their\npromise, the best way to leverage Large Language Models (LLMs) in complex\nmedical tasks remains an open question. We introduce a novel multi-agent\nframework, named Medical Decision-making Agents (MDAgents) that helps address\nthis gap by automatically assigning a collaboration structure to a team of\nLLMs. The assigned solo or group collaboration structure is tailored to the\nmedical task at hand, emulating real-world medical decision-making processes\nadapted to tasks of varying complexities. We evaluate our framework and\nbaseline methods using state-of-the-art LLMs across a suite of real-world\nmedical knowledge and medical diagnosis benchmarks, including a comparison of\nLLMs' medical complexity classification against human physicians. MDAgents\nachieved the best performance in seven out of ten benchmarks on tasks requiring\nan understanding of medical knowledge and multi-modal reasoning, showing a\nsignificant improvement of up to 4.2% (p < 0.05) compared to previous methods'\nbest performances. Ablation studies reveal that MDAgents effectively determines\nmedical complexity to optimize for efficiency and accuracy across diverse\nmedical tasks. Notably, the combination of moderator review and external\nmedical knowledge in group collaboration resulted in an average accuracy\nimprovement of 11.8%. Our code can be found at\nhttps://github.com/mitmedialab/MDAgents.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.15155v3",
    "published_date": "2024-04-22 06:30:05 UTC",
    "updated_date": "2024-10-30 02:32:43 UTC"
  },
  {
    "arxiv_id": "2404.13899v1",
    "title": "Towards Better Text-to-Image Generation Alignment via Attention Modulation",
    "authors": [
      "Yihang Wu",
      "Xiao Cao",
      "Kaixin Li",
      "Zitan Chen",
      "Haonan Wang",
      "Lei Meng",
      "Zhiyong Huang"
    ],
    "abstract": "In text-to-image generation tasks, the advancements of diffusion models have\nfacilitated the fidelity of generated results. However, these models encounter\nchallenges when processing text prompts containing multiple entities and\nattributes. The uneven distribution of attention results in the issues of\nentity leakage and attribute misalignment. Training from scratch to address\nthis issue requires numerous labeled data and is resource-consuming. Motivated\nby this, we propose an attribution-focusing mechanism, a training-free\nphase-wise mechanism by modulation of attention for diffusion model. One of our\ncore ideas is to guide the model to concentrate on the corresponding syntactic\ncomponents of the prompt at distinct timesteps. To achieve this, we incorporate\na temperature control mechanism within the early phases of the self-attention\nmodules to mitigate entity leakage issues. An object-focused masking scheme and\na phase-wise dynamic weight control mechanism are integrated into the\ncross-attention modules, enabling the model to discern the affiliation of\nsemantic information between entities more effectively. The experimental\nresults in various alignment scenarios demonstrate that our model attain better\nimage-text alignment with minimal additional computational cost.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.MM"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.13899v1",
    "published_date": "2024-04-22 06:18:37 UTC",
    "updated_date": "2024-04-22 06:18:37 UTC"
  },
  {
    "arxiv_id": "2407.01545v1",
    "title": "In the Shadow of Smith`s Invisible Hand: Risks to Economic Stability and Social Wellbeing in the Age of Intelligence",
    "authors": [
      "Jo-An Occhipinti",
      "William Hynes",
      "Ante Prodan",
      "Harris A. Eyre",
      "Roy Green",
      "Sharan Burrow",
      "Marcel Tanner",
      "John Buchanan",
      "Goran Ujdur",
      "Frederic Destrebecq",
      "Christine Song",
      "Steven Carnevale",
      "Ian B. Hickie",
      "Mark Heffernan"
    ],
    "abstract": "Work is fundamental to societal prosperity and mental health, providing\nfinancial security, identity, purpose, and social integration. The emergence of\ngenerative artificial intelligence (AI) has catalysed debate on job\ndisplacement. Some argue that many new jobs and industries will emerge to\noffset the displacement, while others foresee a widespread decoupling of\neconomic productivity from human input threatening jobs on an unprecedented\nscale. This study explores the conditions under which both may be true and\nexamines the potential for a self-reinforcing cycle of recessionary pressures\nthat would necessitate sustained government intervention to maintain job\nsecurity and economic stability. A system dynamics model was developed to\nundertake ex ante analysis of the effect of AI-capital deepening on labour\nunderutilisation and demand in the economy. Results indicate that even a\nmoderate increase in the AI-capital-to-labour ratio could increase labour\nunderutilisation to double its current level, decrease per capita disposable\nincome by 26% (95% interval, 20.6% - 31.8%), and decrease the consumption index\nby 21% (95% interval, 13.6% - 28.3%) by mid-2050. To prevent a reduction in per\ncapita disposable income due to the estimated increase in underutilization, at\nleast a 10.8-fold increase in the new job creation rate would be necessary.\nResults demonstrate the feasibility of an AI-capital- to-labour ratio threshold\nbeyond which even high rates of new job creation cannot prevent declines in\nconsumption. The precise threshold will vary across economies, emphasizing the\nurgent need for empirical research tailored to specific contexts. This study\nunderscores the need for governments, civic organisations, and business to work\ntogether to ensure a smooth transition to an AI- dominated economy to safeguard\nthe Mental Wealth of nations.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "econ.GN",
      "q-fin.EC"
    ],
    "primary_category": "cs.CY",
    "comment": "10 pages, 5 figures, 1 table, an Appendix",
    "pdf_url": "http://arxiv.org/pdf/2407.01545v1",
    "published_date": "2024-04-22 06:16:48 UTC",
    "updated_date": "2024-04-22 06:16:48 UTC"
  },
  {
    "arxiv_id": "2404.13892v2",
    "title": "Retrieval-Augmented Audio Deepfake Detection",
    "authors": [
      "Zuheng Kang",
      "Yayun He",
      "Botao Zhao",
      "Xiaoyang Qu",
      "Junqing Peng",
      "Jing Xiao",
      "Jianzong Wang"
    ],
    "abstract": "With recent advances in speech synthesis including text-to-speech (TTS) and\nvoice conversion (VC) systems enabling the generation of ultra-realistic audio\ndeepfakes, there is growing concern about their potential misuse. However, most\ndeepfake (DF) detection methods rely solely on the fuzzy knowledge learned by a\nsingle model, resulting in performance bottlenecks and transparency issues.\nInspired by retrieval-augmented generation (RAG), we propose a\nretrieval-augmented detection (RAD) framework that augments test samples with\nsimilar retrieved samples for enhanced detection. We also extend the\nmulti-fusion attentive classifier to integrate it with our proposed RAD\nframework. Extensive experiments show the superior performance of the proposed\nRAD framework over baseline methods, achieving state-of-the-art results on the\nASVspoof 2021 DF set and competitive results on the 2019 and 2021 LA sets.\nFurther sample analysis indicates that the retriever consistently retrieves\nsamples mostly from the same speaker with acoustic characteristics highly\nconsistent with the query audio, thereby improving detection performance.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Accepted by the 2024 International Conference on Multimedia Retrieval\n  (ICMR 2024)",
    "pdf_url": "http://arxiv.org/pdf/2404.13892v2",
    "published_date": "2024-04-22 05:46:40 UTC",
    "updated_date": "2024-04-23 04:10:25 UTC"
  },
  {
    "arxiv_id": "2404.13891v2",
    "title": "Minimizing Weighted Counterfactual Regret with Optimistic Online Mirror Descent",
    "authors": [
      "Hang Xu",
      "Kai Li",
      "Bingyun Liu",
      "Haobo Fu",
      "Qiang Fu",
      "Junliang Xing",
      "Jian Cheng"
    ],
    "abstract": "Counterfactual regret minimization (CFR) is a family of algorithms for\neffectively solving imperfect-information games. It decomposes the total regret\ninto counterfactual regrets, utilizing local regret minimization algorithms,\nsuch as Regret Matching (RM) or RM+, to minimize them. Recent research\nestablishes a connection between Online Mirror Descent (OMD) and RM+, paving\nthe way for an optimistic variant PRM+ and its extension PCFR+. However, PCFR+\nassigns uniform weights for each iteration when determining regrets, leading to\nsubstantial regrets when facing dominated actions. This work explores\nminimizing weighted counterfactual regret with optimistic OMD, resulting in a\nnovel CFR variant PDCFR+. It integrates PCFR+ and Discounted CFR (DCFR) in a\nprincipled manner, swiftly mitigating negative effects of dominated actions and\nconsistently leveraging predictions to accelerate convergence. Theoretical\nanalyses prove that PDCFR+ converges to a Nash equilibrium, particularly under\ndistinct weighting schemes for regrets and average strategies. Experimental\nresults demonstrate PDCFR+'s fast convergence in common imperfect-information\ngames. The code is available at https://github.com/rpSebastian/PDCFRPlus.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.GT"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to 33rd International Joint Conference on Artificial\n  Intelligence (IJCAI 2024)",
    "pdf_url": "http://arxiv.org/pdf/2404.13891v2",
    "published_date": "2024-04-22 05:37:22 UTC",
    "updated_date": "2024-05-14 09:16:46 UTC"
  },
  {
    "arxiv_id": "2404.13885v2",
    "title": "Surveying Attitudinal Alignment Between Large Language Models Vs. Humans Towards 17 Sustainable Development Goals",
    "authors": [
      "Qingyang Wu",
      "Ying Xu",
      "Tingsong Xiao",
      "Yunze Xiao",
      "Yitong Li",
      "Tianyang Wang",
      "Yichi Zhang",
      "Shanghai Zhong",
      "Yuwei Zhang",
      "Wei Lu",
      "Yifan Yang"
    ],
    "abstract": "Large Language Models (LLMs) have emerged as potent tools for advancing the\nUnited Nations' Sustainable Development Goals (SDGs). However, the attitudinal\ndisparities between LLMs and humans towards these goals can pose significant\nchallenges. This study conducts a comprehensive review and analysis of the\nexisting literature on the attitudes of LLMs towards the 17 SDGs, emphasizing\nthe comparison between their attitudes and support for each goal and those of\nhumans. We examine the potential disparities, primarily focusing on aspects\nsuch as understanding and emotions, cultural and regional differences, task\nobjective variations, and factors considered in the decision-making process.\nThese disparities arise from the underrepresentation and imbalance in LLM\ntraining data, historical biases, quality issues, lack of contextual\nunderstanding, and skewed ethical values reflected. The study also investigates\nthe risks and harms that may arise from neglecting the attitudes of LLMs\ntowards the SDGs, including the exacerbation of social inequalities, racial\ndiscrimination, environmental destruction, and resource wastage. To address\nthese challenges, we propose strategies and recommendations to guide and\nregulate the application of LLMs, ensuring their alignment with the principles\nand goals of the SDGs, and therefore creating a more just, inclusive, and\nsustainable future.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.13885v2",
    "published_date": "2024-04-22 05:12:52 UTC",
    "updated_date": "2025-01-16 02:45:07 UTC"
  },
  {
    "arxiv_id": "2404.14461v2",
    "title": "Competition Report: Finding Universal Jailbreak Backdoors in Aligned LLMs",
    "authors": [
      "Javier Rando",
      "Francesco Croce",
      "Kryštof Mitka",
      "Stepan Shabalin",
      "Maksym Andriushchenko",
      "Nicolas Flammarion",
      "Florian Tramèr"
    ],
    "abstract": "Large language models are aligned to be safe, preventing users from\ngenerating harmful content like misinformation or instructions for illegal\nactivities. However, previous work has shown that the alignment process is\nvulnerable to poisoning attacks. Adversaries can manipulate the safety training\ndata to inject backdoors that act like a universal sudo command: adding the\nbackdoor string to any prompt enables harmful responses from models that,\notherwise, behave safely. Our competition, co-located at IEEE SaTML 2024,\nchallenged participants to find universal backdoors in several large language\nmodels. This report summarizes the key findings and promising ideas for future\nresearch.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Competition Report",
    "pdf_url": "http://arxiv.org/pdf/2404.14461v2",
    "published_date": "2024-04-22 05:08:53 UTC",
    "updated_date": "2024-06-06 12:45:52 UTC"
  },
  {
    "arxiv_id": "2404.13880v4",
    "title": "Regional Style and Color Transfer",
    "authors": [
      "Zhicheng Ding",
      "Panfeng Li",
      "Qikai Yang",
      "Siyang Li",
      "Qingtian Gong"
    ],
    "abstract": "This paper presents a novel contribution to the field of regional style\ntransfer. Existing methods often suffer from the drawback of applying style\nhomogeneously across the entire image, leading to stylistic inconsistencies or\nforeground object twisted when applied to image with foreground elements such\nas person figures. To address this limitation, we propose a new approach that\nleverages a segmentation network to precisely isolate foreground objects within\nthe input image. Subsequently, style transfer is applied exclusively to the\nbackground region. The isolated foreground objects are then carefully\nreintegrated into the style-transferred background. To enhance the visual\ncoherence between foreground and background, a color transfer step is employed\non the foreground elements prior to their rein-corporation. Finally, we utilize\nfeathering techniques to achieve a seamless amalgamation of foreground and\nbackground, resulting in a visually unified and aesthetically pleasing final\ncomposition. Extensive evaluations demonstrate that our proposed approach\nyields significantly more natural stylistic transformations compared to\nconventional methods.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by 2024 5th International Conference on Computer Vision,\n  Image and Deep Learning",
    "pdf_url": "http://arxiv.org/pdf/2404.13880v4",
    "published_date": "2024-04-22 05:07:02 UTC",
    "updated_date": "2024-11-13 18:31:18 UTC"
  },
  {
    "arxiv_id": "2404.13859v3",
    "title": "Unveiling and Mitigating Generalized Biases of DNNs through the Intrinsic Dimensions of Perceptual Manifolds",
    "authors": [
      "Yanbiao Ma",
      "Licheng Jiao",
      "Fang Liu",
      "Lingling Li",
      "Wenping Ma",
      "Shuyuan Yang",
      "Xu Liu",
      "Puhua Chen"
    ],
    "abstract": "Building fair deep neural networks (DNNs) is a crucial step towards achieving\ntrustworthy artificial intelligence. Delving into deeper factors that affect\nthe fairness of DNNs is paramount and serves as the foundation for mitigating\nmodel biases. However, current methods are limited in accurately predicting DNN\nbiases, relying solely on the number of training samples and lacking more\nprecise measurement tools. Here, we establish a geometric perspective for\nanalyzing the fairness of DNNs, comprehensively exploring how DNNs internally\nshape the intrinsic geometric characteristics of datasets-the intrinsic\ndimensions (IDs) of perceptual manifolds, and the impact of IDs on the fairness\nof DNNs. Based on multiple findings, we propose Intrinsic Dimension\nRegularization (IDR), which enhances the fairness and performance of models by\npromoting the learning of concise and ID-balanced class perceptual manifolds.\nIn various image recognition benchmark tests, IDR significantly mitigates model\nbias while improving its performance.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "8pages, 6figures, Submitted to TPAMI",
    "pdf_url": "http://arxiv.org/pdf/2404.13859v3",
    "published_date": "2024-04-22 04:16:40 UTC",
    "updated_date": "2024-11-02 09:42:01 UTC"
  },
  {
    "arxiv_id": "2405.01573v2",
    "title": "Class-Level Code Generation from Natural Language Using Iterative, Tool-Enhanced Reasoning over Repository",
    "authors": [
      "Ajinkya Deshpande",
      "Anmol Agarwal",
      "Shashank Shet",
      "Arun Iyer",
      "Aditya Kanade",
      "Ramakrishna Bairi",
      "Suresh Parthasarathy"
    ],
    "abstract": "LLMs have demonstrated significant potential in code generation tasks,\nachieving promising results at the function or statement level across various\nbenchmarks. However, the complexities associated with creating code artifacts\nlike classes, particularly within the context of real-world software\nrepositories, remain underexplored. Prior research treats class-level\ngeneration as an isolated task, neglecting the intricate dependencies &\ninteractions that characterize real-world software environments. To address\nthis gap, we introduce RepoClassBench, a comprehensive benchmark designed to\nrigorously evaluate LLMs in generating complex, class-level code within\nreal-world repositories. RepoClassBench includes \"Natural Language to Class\ngeneration\" tasks across Java, Python & C# from a selection of repositories. We\nensure that each class in our dataset not only has cross-file dependencies\nwithin the repository but also includes corresponding test cases to verify its\nfunctionality. We find that current models struggle with the realistic\nchallenges posed by our benchmark, primarily due to their limited exposure to\nrelevant repository contexts. To address this shortcoming, we introduce\nRetrieve-Repotools-Reflect (RRR), a novel approach that equips LLMs with static\nanalysis tools to iteratively navigate & reason about repository-level context\nin an agent-based framework. Our experiments demonstrate that RRR significantly\noutperforms existing baselines on RepoClassBench, showcasing its effectiveness\nacross programming languages & under various settings. Our findings emphasize\nthe critical need for code-generation benchmarks to incorporate repo-level\ndependencies to more accurately reflect the complexities of software\ndevelopment. Our work shows the benefits of leveraging specialized tools to\nenhance LLMs' understanding of repository context. We plan to make our dataset\n& evaluation harness public.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "Preprint with additional experiments",
    "pdf_url": "http://arxiv.org/pdf/2405.01573v2",
    "published_date": "2024-04-22 03:52:54 UTC",
    "updated_date": "2024-06-05 17:44:24 UTC"
  },
  {
    "arxiv_id": "2404.13846v4",
    "title": "Filtered Direct Preference Optimization",
    "authors": [
      "Tetsuro Morimura",
      "Mitsuki Sakamoto",
      "Yuu Jinnai",
      "Kenshi Abe",
      "Kaito Ariu"
    ],
    "abstract": "Reinforcement learning from human feedback (RLHF) plays a crucial role in\naligning language models with human preferences. While the significance of\ndataset quality is generally recognized, explicit investigations into its\nimpact within the RLHF framework, to our knowledge, have been limited. This\npaper addresses the issue of text quality within the preference dataset by\nfocusing on direct preference optimization (DPO), an increasingly adopted\nreward-model-free RLHF method. We confirm that text quality significantly\ninfluences the performance of models optimized with DPO more than those\noptimized with reward-model-based RLHF. Building on this new insight, we\npropose an extension of DPO, termed filtered direct preference optimization\n(fDPO). fDPO uses a trained reward model to monitor the quality of texts within\nthe preference dataset during DPO training. Samples of lower quality are\ndiscarded based on comparisons with texts generated by the model being\noptimized, resulting in a more accurate dataset. Experimental results\ndemonstrate that fDPO enhances the final model performance. Our code is\navailable at https://github.com/CyberAgentAILab/filtered-dpo.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "EMNLP 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.13846v4",
    "published_date": "2024-04-22 03:05:19 UTC",
    "updated_date": "2024-12-03 17:22:01 UTC"
  },
  {
    "arxiv_id": "2404.13844v1",
    "title": "ColA: Collaborative Adaptation with Gradient Learning",
    "authors": [
      "Enmao Diao",
      "Qi Le",
      "Suya Wu",
      "Xinran Wang",
      "Ali Anwar",
      "Jie Ding",
      "Vahid Tarokh"
    ],
    "abstract": "A primary function of back-propagation is to compute both the gradient of\nhidden representations and parameters for optimization with gradient descent.\nTraining large models requires high computational costs due to their vast\nparameter sizes. While Parameter-Efficient Fine-Tuning (PEFT) methods aim to\ntrain smaller auxiliary models to save computational space, they still present\ncomputational overheads, especially in Fine-Tuning as a Service (FTaaS) for\nnumerous users. We introduce Collaborative Adaptation (ColA) with Gradient\nLearning (GL), a parameter-free, model-agnostic fine-tuning approach that\ndecouples the computation of the gradient of hidden representations and\nparameters. In comparison to PEFT methods, ColA facilitates more cost-effective\nFTaaS by offloading the computation of the gradient to low-cost devices. We\nalso provide a theoretical analysis of ColA and experimentally demonstrate that\nColA can perform on par or better than existing PEFT methods on various\nbenchmarks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.13844v1",
    "published_date": "2024-04-22 02:52:54 UTC",
    "updated_date": "2024-04-22 02:52:54 UTC"
  },
  {
    "arxiv_id": "2404.13841v1",
    "title": "Fair Concurrent Training of Multiple Models in Federated Learning",
    "authors": [
      "Marie Siew",
      "Haoran Zhang",
      "Jong-Ik Park",
      "Yuezhou Liu",
      "Yichen Ruan",
      "Lili Su",
      "Stratis Ioannidis",
      "Edmund Yeh",
      "Carlee Joe-Wong"
    ],
    "abstract": "Federated learning (FL) enables collaborative learning across multiple\nclients. In most FL work, all clients train a single learning task. However,\nthe recent proliferation of FL applications may increasingly require multiple\nFL tasks to be trained simultaneously, sharing clients' computing and\ncommunication resources, which we call Multiple-Model Federated Learning\n(MMFL). Current MMFL algorithms use naive average-based client-task allocation\nschemes that can lead to unfair performance when FL tasks have heterogeneous\ndifficulty levels, e.g., tasks with larger models may need more rounds and data\nto train. Just as naively allocating resources to generic computing jobs with\nheterogeneous resource needs can lead to unfair outcomes, naive allocation of\nclients to FL tasks can lead to unfairness, with some tasks having excessively\nlong training times, or lower converged accuracies. Furthermore, in the FL\nsetting, since clients are typically not paid for their training effort, we\nface a further challenge that some clients may not even be willing to train\nsome tasks, e.g., due to high computational costs, which may exacerbate\nunfairness in training outcomes across tasks. We address both challenges by\nfirstly designing FedFairMMFL, a difficulty-aware algorithm that dynamically\nallocates clients to tasks in each training round. We provide guarantees on\nairness and FedFairMMFL's convergence rate. We then propose a novel auction\ndesign that incentivizes clients to train multiple tasks, so as to fairly\ndistribute clients' training efforts across the tasks. We show how our\nfairness-based learning and incentive mechanisms impact training convergence\nand finally evaluate our algorithm with multiple sets of learning tasks on real\nworld datasets.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.13841v1",
    "published_date": "2024-04-22 02:41:10 UTC",
    "updated_date": "2024-04-22 02:41:10 UTC"
  },
  {
    "arxiv_id": "2404.15159v3",
    "title": "MixLoRA: Enhancing Large Language Models Fine-Tuning with LoRA-based Mixture of Experts",
    "authors": [
      "Dengchun Li",
      "Yingzi Ma",
      "Naizheng Wang",
      "Zhengmao Ye",
      "Zhiyuan Cheng",
      "Yinghao Tang",
      "Yan Zhang",
      "Lei Duan",
      "Jie Zuo",
      "Cal Yang",
      "Mingjie Tang"
    ],
    "abstract": "Fine-tuning Large Language Models (LLMs) is a common practice to adapt\npre-trained models for specific applications. While methods like LoRA have\neffectively addressed GPU memory constraints during fine-tuning, their\nperformance often falls short, especially in multi-task scenarios. In contrast,\nMixture-of-Expert (MoE) models, such as Mixtral 8x7B, demonstrate remarkable\nperformance in multi-task learning scenarios while maintaining a reduced\nparameter count. However, the resource requirements of these MoEs remain\nchallenging, particularly for consumer-grade GPUs with less than 24GB memory.\nTo tackle these challenges, we propose MixLoRA, an approach to construct a\nresource-efficient sparse MoE model based on LoRA. MixLoRA inserts multiple\nLoRA-based experts within the feed-forward network block of a frozen\npre-trained dense model and employs a commonly used top-k router. Unlike other\nLoRA-based MoE methods, MixLoRA enhances model performance by utilizing\nindependent attention-layer LoRA adapters. Additionally, an auxiliary load\nbalance loss is employed to address the imbalance problem of the router. Our\nevaluations show that MixLoRA improves about 9% accuracy compared to\nstate-of-the-art PEFT methods in multi-task learning scenarios. We also propose\na new high-throughput framework to alleviate the computation and memory\nbottlenecks during the training and inference of MOE models. This framework\nreduces GPU memory consumption by 40% and token computation latency by 30%\nduring both training and inference.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "18 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2404.15159v3",
    "published_date": "2024-04-22 02:15:52 UTC",
    "updated_date": "2024-07-20 02:26:49 UTC"
  },
  {
    "arxiv_id": "2404.13813v1",
    "title": "From LLM to NMT: Advancing Low-Resource Machine Translation with Claude",
    "authors": [
      "Maxim Enis",
      "Mark Hopkins"
    ],
    "abstract": "We show that Claude 3 Opus, a large language model (LLM) released by\nAnthropic in March 2024, exhibits stronger machine translation competence than\nother LLMs. Though we find evidence of data contamination with Claude on\nFLORES-200, we curate new benchmarks that corroborate the effectiveness of\nClaude for low-resource machine translation into English. We find that Claude\nhas remarkable \\textit{resource efficiency} -- the degree to which the quality\nof the translation model depends on a language pair's resource level. Finally,\nwe show that advancements in LLM translation can be compressed into traditional\nneural machine translation (NMT) models. Using Claude to generate synthetic\ndata, we demonstrate that knowledge distillation advances the state-of-the-art\nin Yoruba-English translation, meeting or surpassing strong baselines like\nNLLB-54B and Google Translate.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "17 pages, 15 figures",
    "pdf_url": "http://arxiv.org/pdf/2404.13813v1",
    "published_date": "2024-04-22 01:22:23 UTC",
    "updated_date": "2024-04-22 01:22:23 UTC"
  },
  {
    "arxiv_id": "2404.13812v4",
    "title": "A Comparative Study on Enhancing Prediction in Social Network Advertisement through Data Augmentation",
    "authors": [
      "Qikai Yang",
      "Panfeng Li",
      "Xinhe Xu",
      "Zhicheng Ding",
      "Wenjing Zhou",
      "Yi Nian"
    ],
    "abstract": "In the ever-evolving landscape of social network advertising, the volume and\naccuracy of data play a critical role in the performance of predictive models.\nHowever, the development of robust predictive algorithms is often hampered by\nthe limited size and potential bias present in real-world datasets. This study\npresents and explores a generative augmentation framework of social network\nadvertising data. Our framework explores three generative models for data\naugmentation - Generative Adversarial Networks (GANs), Variational Autoencoders\n(VAEs), and Gaussian Mixture Models (GMMs) - to enrich data availability and\ndiversity in the context of social network advertising analytics effectiveness.\nBy performing synthetic extensions of the feature space, we find that through\ndata augmentation, the performance of various classifiers has been\nquantitatively improved. Furthermore, we compare the relative performance gains\nbrought by each data augmentation technique, providing insights for\npractitioners to select appropriate techniques to enhance model performance.\nThis paper contributes to the literature by showing that synthetic data\naugmentation alleviates the limitations imposed by small or imbalanced datasets\nin the field of social network advertising. At the same time, this article also\nprovides a comparative perspective on the practicality of different data\naugmentation methods, thereby guiding practitioners to choose appropriate\ntechniques to enhance model performance.",
    "categories": [
      "cs.SI",
      "cs.AI",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.SI",
    "comment": "Accepted by 2024 4th International Conference on Machine Learning and\n  Intelligent Systems Engineering (MLISE)",
    "pdf_url": "http://arxiv.org/pdf/2404.13812v4",
    "published_date": "2024-04-22 01:16:11 UTC",
    "updated_date": "2024-11-12 07:44:20 UTC"
  },
  {
    "arxiv_id": "2404.15157v1",
    "title": "FASTTRACK: Fast and Accurate Fact Tracing for LLMs",
    "authors": [
      "Si Chen",
      "Feiyang Kang",
      "Ning Yu",
      "Ruoxi Jia"
    ],
    "abstract": "Fact tracing seeks to identify specific training examples that serve as the\nknowledge source for a given query. Existing approaches to fact tracing rely on\nassessing the similarity between each training sample and the query along a\ncertain dimension, such as lexical similarity, gradient, or embedding space.\nHowever, these methods fall short of effectively distinguishing between samples\nthat are merely relevant and those that actually provide supportive evidence\nfor the information sought by the query. This limitation often results in\nsuboptimal effectiveness. Moreover, these approaches necessitate the\nexamination of the similarity of individual training points for each query,\nimposing significant computational demands and creating a substantial barrier\nfor practical applications. This paper introduces FASTTRACK, a novel approach\nthat harnesses the capabilities of Large Language Models (LLMs) to validate\nsupportive evidence for queries and at the same time clusters the training\ndatabase towards a reduced extent for LLMs to trace facts. Our experiments show\nthat FASTTRACK substantially outperforms existing methods in both accuracy and\nefficiency, achieving more than 100\\% improvement in F1 score over the\nstate-of-the-art methods while being X33 faster than \\texttt{TracIn}.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.15157v1",
    "published_date": "2024-04-22 00:07:55 UTC",
    "updated_date": "2024-04-22 00:07:55 UTC"
  }
]