{
  "date": "2024-03-12",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-03-12 的 arXiv 中文 TLDR 快报！今天 arXiv 更新了大量论文，主要聚焦于 AI 模型优化（如 LLM 微调和对齐）、视觉语言模型、强化学习和图像处理等领域，重点包括高效的 LLM 知识编辑和时间序列预测方法（如 Chronos），以及一些鲁棒性增强工作；令人印象深刻的文章有 Chronos 和 ORPO，涉及知名学者如 Andrew Gordon Wilson 和 Ya-Qiu Jin。\n\n以下是今日论文的精选摘要，我将相关主题归类，先讨论 AI 和 LLM 相关的高影响力论文，再简要覆盖视觉处理、强化学习和其他领域。核心学术术语保留，描述力求简洁明了。\n\n### AI 和 LLM 优化（重点领域，影响力高）\n- **Chronos: Learning the Language of Time Series**（中文：Chronos：学习时间序列的语言）  \n  这篇论文提出了一种基于预训练的概率时间序列模型 Chronos，使用变分自编码器对时间序列进行标记化训练。贡献在于提升了时间序列预测的准确性和泛化能力，在多个数据集上超越了传统方法，适用于气象和公共健康等应用。\n\n- **ORPO: Monolithic Preference Optimization without Reference Model**（中文：ORPO：无需参考模型的单体偏好优化）  \n  作者 Jiwoo Hong 等开发了 ORPO 算法，通过直接优化偏好数据来对齐 LLM。发现它在 GLUE 和 MT-Bench 等基准上显著提升性能（如 7.43 分），无需额外阶段，相比 DPO 方法更高效。\n\n- **CodeAttack: Revealing Safety Generalization Challenges of Large Language Models via Code Completion**（中文：CodeAttack：通过代码补全揭示大语言模型的安全泛化挑战）  \n  这篇工作使用代码输入测试 LLM 的安全漏洞，提出 CodeAttack 框架。贡献是发现 LLM 在代码域的安全防护不足（如 80% 绕过率），并讨论了潜在缓解策略。\n\n- **Curry-DPO: Enhancing Alignment using Curriculum Learning & Ranked Preferences**（中文：Curry-DPO：使用课程学习和排名偏好增强对齐）  \n  作者 Pulkit Pattnaik 等扩展了 DPO，通过课程学习和多对偏好数据优化 LLM 对齐。发现它在 MT-Bench 和 Vicuna 等任务中提升了 7% 的胜率，适用于偏好建模。\n\n其他 LLM 相关论文如 **VLKEB: A Large Vision-Language Model Knowledge Editing Benchmark**（中文：VLKEB：大视觉语言模型知识编辑基准），提出新基准评估知识编辑，贡献在于提升 LVLMs 的鲁棒性，但细节较常规，快速掠过。\n\n### 视觉和图像处理（应用广泛，部分有创新）\n- **FluoroSAM: A Language-aligned Foundation Model for X-ray Image Segmentation**（中文：FluoroSAM：用于 X 射线图像分割的语言对齐基础模型）  \n  这篇论文引入 FluoroSAM 模型，通过合成数据训练实现 X 射线图像分割。贡献是提升了零样本泛化（如 Dice 系数 0.51），适用于医疗诊断。\n\n- **Synth²: Boosting Visual-Language Models with Synthetic Captions and Image Embeddings**（中文：Synth²：使用合成标题和图像嵌入提升视觉语言模型）  \n  作者 Sahand Sharifzadeh 等使用合成数据训练 VLM，显著提高了图像生成质量。发现它在无标注数据上与人类标注相当，适用于多模态任务。\n\n其他视觉论文如 **LKM-UNet: Large Kernel Vision Mamba UNet for Medical Image Segmentation**（中文：LKM-UNet：大核 Vision Mamba UNet 用于医疗图像分割），优化了医疗图像分割效率，但影响力一般，简要提及其在 CNN 和 Transformer 上的改进。\n\n### 强化学习和机器学习（技术深度高）\n- **A2PO: Towards Effective Offline Reinforcement Learning from an Advantage-aware Perspective**（中文：A2PO：从优势感知视角实现有效的离线强化学习）  \n  这篇工作提出 A2PO 算法，通过优势感知优化离线 RL。贡献是提升了样本效率和泛化（如 D4RL 基准上 74% 性能提升），适用于资源有限的环境。\n\n- **DeepCDCL: An CDCL-based Neural Network Verification Framework**（中文：DeepCDCL：基于 CDCL 的神经网络验证框架）  \n  作者 Zongxin Liu 等开发了 DeepCDCL 框架，用于神经网络验证。发现它在 ACAS Xu 数据集上加速了验证过程，适用于安全关键系统。\n\n其他 RL 论文如 **NavCoT: Boosting LLM-Based Vision-and-Language Navigation via Learning Disentangled Reasoning**（中文：NavCoT：通过解耦推理提升基于 LLM 的视觉语言导航），提升了导航鲁棒性，但整体主题较窄，快速掠过。\n\n### 其他领域（快速概述，选重点）\n- **Mechanics of Next Token Prediction with Self-Attention**（中文：自注意力机制下的下一个标记预测机制）  \n  这篇论文分析了 Transformer 的自注意力在序列预测中的机制。贡献是证明了梯度下降能隐式学习图结构，适用于 NLP 优化。\n\n- **A Review of Cybersecurity Incidents in the Food and Agriculture Sector**（中文：食品和农业领域网络安全事件的回顾）  \n  回顾了食品行业安全事件，提出 FCAI 框架增强 AI 保障，但主题较为应用导向，简要提及其对食品安全的影响。\n\n其余论文如量子计算、图数据压缩等（如 **Simulating Weighted Automata over Sequences and Trees with Transformers**），贡献在于扩展 Transformer 的应用，但不为核心热点，限于篇幅快速掠过。\n\n总之，今天的论文突显了 AI 领域的创新潜力，特别是在 LLM 优化和鲁棒性提升上。感兴趣的读者可关注 Chronos 和 ORPO 等工作，以探索实际应用。明天的快报见！",
  "papers": [
    {
      "arxiv_id": "2403.08137v1",
      "title": "From Paper to Card: Transforming Design Implications with Generative AI",
      "title_zh": "翻译失败",
      "authors": [
        "Donghoon Shin",
        "Lucy Lu Wang",
        "Gary Hsieh"
      ],
      "abstract": "Communicating design implications is common within the HCI community when\npublishing academic papers, yet these papers are rarely read and used by\ndesigners. One solution is to use design cards as a form of translational\nresource that communicates valuable insights from papers in a more digestible\nand accessible format to assist in design processes. However, creating design\ncards can be time-consuming, and authors may lack the resources/know-how to\nproduce cards. Through an iterative design process, we built a system that\nhelps create design cards from academic papers using an LLM and text-to-image\nmodel. Our evaluation with designers (N=21) and authors of selected papers\n(N=12) revealed that designers perceived the design implications from our\ndesign cards as more inspiring and generative, compared to reading original\npaper texts, and the authors viewed our system as an effective way of\ncommunicating their design implications. We also propose future enhancements\nfor AI-generated design cards.",
      "tldr_zh": "本文提出了一种利用 Generative AI 将 HCI 学术论文的设计含义转化为设计 cards 的方法，以解决论文内容不易被设计师阅读和应用的问题。研究团队通过迭代设计过程，构建了一个系统，使用 LLM 和 text-to-image model 从论文中自动生成设计 cards，从而节省时间并提升可访问性。在评估中，设计师（N=21）认为这些设计 cards 更具启发性和生成性，而论文作者（N=12）视其为有效沟通工具；此外，论文还建议了 AI 生成设计 cards 的未来改进方向。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL",
        "H.5.2; I.2.7"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.08137v1",
      "published_date": "2024-03-12 23:47:28 UTC",
      "updated_date": "2024-03-12 23:47:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:30:57.425255"
    },
    {
      "arxiv_id": "2403.08136v1",
      "title": "RoboCertProb: Property Specification for Probabilistic RoboChart Models",
      "title_zh": "翻译失败",
      "authors": [
        "Kangfeng Ye",
        "Jim Woodcock"
      ],
      "abstract": "RoboChart is a core notation in the RoboStar framework which brings modern\nmodelling and formal verification technologies into software engineering for\nrobotics. It is a timed and probabilistic domain-specific language for robotics\nand provides a UML-like architectural and state machine modelling. This work\npresents RoboCertProb for specifying quantitative properties of probabilistic\nrobotic systems modelled in RoboChart. RoboCertProb's semantics is based on\nPCTL*. To interpret RoboCertProb over RoboChart models, we give a Markov\nsemantics (DTMCs and MDPs) to RoboChart, derived from its existing\ntransformation semantics to the PRISM language. In addition to property\nspecification, RoboCertProb also entitles us to configure loose constants and\nunspecified functions and operations in RoboChart models. It allows us to set\nup environmental inputs to verify reactive probabilistic systems not directly\nsupported in probabilistic model checkers like PRISM because they employ a\nclosed-world assumption. We implement RoboCertProb in an accompanying tool of\nRoboChart, RoboTool, for specifying properties and automatically generating\nPRISM properties from them to formally verify RoboChart models using PRISM. We\nhave used it to analyse the behaviour of software controllers for two real\nrobots: an industrial painting robot and an agricultural robot for treating\nplants with UV lights.",
      "tldr_zh": "本研究引入了RoboCertProb，一种用于指定概率RoboChart模型中定量属性的语言，RoboChart本身是一个定时和概率化的机器人建模语言，类似于UML的架构和状态机。RoboCertProb的语义基于PCTL*，并为RoboChart提供Markov语义（包括DTMCs和MDPs），通过从现有转换语义到PRISM语言派生而来，这允许配置模型中的松散常量、未指定函数，并处理反应式概率系统的环境输入。研究在RoboTool工具中实现了RoboCertProb，用于自动生成PRISM属性进行形式验证，并成功应用于分析真实机器人控制器，如工业喷漆机器人和农业UV灯处理机器人。",
      "categories": [
        "cs.LO",
        "cs.AI"
      ],
      "primary_category": "cs.LO",
      "comment": "24 pages, 10 figures, 4 tables, submitted to the International\n  Journal on Software and Systems Modeling (SoSyM)",
      "pdf_url": "http://arxiv.org/pdf/2403.08136v1",
      "published_date": "2024-03-12 23:47:00 UTC",
      "updated_date": "2024-03-12 23:47:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:31:08.766191"
    },
    {
      "arxiv_id": "2403.08133v1",
      "title": "Physics-Inspired Deep Learning Anti-Aliasing Framework in Efficient Channel State Feedback",
      "title_zh": "翻译失败",
      "authors": [
        "Yu-Chien Lin",
        "Yan Xin",
        "Ta-Sung Lee",
        "Charlie",
        "Zhang",
        "Zhi Ding"
      ],
      "abstract": "Acquiring downlink channel state information (CSI) at the base station is\nvital for optimizing performance in massive Multiple input multiple output\n(MIMO) Frequency-Division Duplexing (FDD) systems. While deep learning\narchitectures have been successful in facilitating UE-side CSI feedback and\ngNB-side recovery, the undersampling issue prior to CSI feedback is often\noverlooked. This issue, which arises from low density pilot placement in\ncurrent standards, results in significant aliasing effects in outdoor channels\nand consequently limits CSI recovery performance. To this end, this work\nintroduces a new CSI upsampling framework at the gNB as a post-processing\nsolution to address the gaps caused by undersampling. Leveraging the physical\nprinciples of discrete Fourier transform shifting theorem and multipath\nreciprocity, our framework effectively uses uplink CSI to mitigate aliasing\neffects. We further develop a learning-based method that integrates the\nproposed algorithm with the Iterative Shrinkage-Thresholding Algorithm Net\n(ISTA-Net) architecture, enhancing our approach for non-uniform sampling\nrecovery. Our numerical results show that both our rule-based and deep learning\nmethods significantly outperform traditional interpolation techniques and\ncurrent state-of-the-art approaches in terms of performance.",
      "tldr_zh": "本研究针对大规模 MIMO FDD 系统中的下行链路 CSI 反馈问题，指出欠采样导致的别名效应会显著影响 CSI 恢复性能。作者提出一个受物理启发的 CSI 上采样框架，作为 gNB 侧的后处理解决方案，利用离散傅立叶变换移位定理和多径互易性结合上行链路 CSI 来缓解别名效应，并将其与 ISTA-Net 架构整合为基于学习的非均匀采样恢复方法。实验结果显示，该框架的规则-based 和深度学习方法在性能上均优于传统插值技术和现有最先进方法。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.IT",
        "math.IT"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.08133v1",
      "published_date": "2024-03-12 23:40:51 UTC",
      "updated_date": "2024-03-12 23:40:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:31:20.809509"
    },
    {
      "arxiv_id": "2403.08124v1",
      "title": "Towards Independence Criterion in Machine Unlearning of Features and Labels",
      "title_zh": "翻译失败",
      "authors": [
        "Ling Han",
        "Nanqing Luo",
        "Hao Huang",
        "Jing Chen",
        "Mary-Anne Hartley"
      ],
      "abstract": "This work delves into the complexities of machine unlearning in the face of\ndistributional shifts, particularly focusing on the challenges posed by\nnon-uniform feature and label removal. With the advent of regulations like the\nGDPR emphasizing data privacy and the right to be forgotten, machine learning\nmodels face the daunting task of unlearning sensitive information without\ncompromising their integrity or performance. Our research introduces a novel\napproach that leverages influence functions and principles of distributional\nindependence to address these challenges. By proposing a comprehensive\nframework for machine unlearning, we aim to ensure privacy protection while\nmaintaining model performance and adaptability across varying distributions.\nOur method not only facilitates efficient data removal but also dynamically\nadjusts the model to preserve its generalization capabilities. Through\nextensive experimentation, we demonstrate the efficacy of our approach in\nscenarios characterized by significant distributional shifts, making\nsubstantial contributions to the field of machine unlearning. This research\npaves the way for developing more resilient and adaptable unlearning\ntechniques, ensuring models remain robust and accurate in the dynamic landscape\nof data privacy and machine learning.",
      "tldr_zh": "本研究探讨了机器遗忘（machine unlearning）在面对分布偏移时的挑战，特别是非均匀特征和标签移除问题，背景是GDPR等法规对数据隐私和被遗忘权的要求。作者提出了一种新框架，利用influence functions和distributional independence原则，实现高效数据移除，同时动态调整模型以维护其性能和泛化能力。该方法通过广泛实验验证，在显著分布偏移的场景中表现出色，为机器遗忘领域提供了更具弹性和适应的技术，促进模型在数据隐私动态环境中的鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "I.2.6"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2403.08124v1",
      "published_date": "2024-03-12 23:21:09 UTC",
      "updated_date": "2024-03-12 23:21:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:31:30.995792"
    },
    {
      "arxiv_id": "2403.08118v1",
      "title": "Characterising harmful data sources when constructing multi-fidelity surrogate models",
      "title_zh": "翻译失败",
      "authors": [
        "Nicolau Andrés-Thió",
        "Mario Andrés Muñoz",
        "Kate Smith-Miles"
      ],
      "abstract": "Surrogate modelling techniques have seen growing attention in recent years\nwhen applied to both modelling and optimisation of industrial design problems.\nThese techniques are highly relevant when assessing the performance of a\nparticular design carries a high cost, as the overall cost can be mitigated via\nthe construction of a model to be queried in lieu of the available high-cost\nsource. The construction of these models can sometimes employ other sources of\ninformation which are both cheaper and less accurate. The existence of these\nsources however poses the question of which sources should be used when\nconstructing a model. Recent studies have attempted to characterise harmful\ndata sources to guide practitioners in choosing when to ignore a certain\nsource. These studies have done so in a synthetic setting, characterising\nsources using a large amount of data that is not available in practice. Some of\nthese studies have also been shown to potentially suffer from bias in the\nbenchmarks used in the analysis. In this study, we present a characterisation\nof harmful low-fidelity sources using only the limited data available to train\na surrogate model. We employ recently developed benchmark filtering techniques\nto conduct a bias-free assessment, providing objectively varied benchmark\nsuites of different sizes for future research. Analysing one of these benchmark\nsuites with the technique known as Instance Space Analysis, we provide an\nintuitive visualisation of when a low-fidelity source should be used and use\nthis analysis to provide guidelines that can be used in an applied industrial\nsetting.",
      "tldr_zh": "本研究探讨了在构建多保真度代理模型（multi-fidelity surrogate models）时，如何识别和表征有害的低保真度数据源（low-fidelity sources），以优化工业设计建模和优化过程。作者提出了一种基于有限可用数据的表征方法，使用基准过滤技术（benchmark filtering techniques）来避免现有研究的偏差问题，并创建了不同规模的客观基准套件。利用实例空间分析（Instance Space Analysis），他们提供了直观的视觉化结果，指导何时使用低保真度源，并为实际工业应用提供了实用指南。实验结果表明，这种方法能有效识别有害源，提升模型构建的可靠性和效率。",
      "categories": [
        "stat.ME",
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "stat.ME",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.08118v1",
      "published_date": "2024-03-12 22:57:53 UTC",
      "updated_date": "2024-03-12 22:57:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:31:44.077870"
    },
    {
      "arxiv_id": "2403.08115v2",
      "title": "Legally Binding but Unfair? Towards Assessing Fairness of Privacy Policies",
      "title_zh": "翻译失败",
      "authors": [
        "Vincent Freiberger",
        "Erik Buchmann"
      ],
      "abstract": "Privacy policies are expected to inform data subjects about their data\nprotection rights and should explain the data controller's data management\npractices. Privacy policies only fulfill their purpose, if they are correctly\ninterpreted, understood, and trusted by the data subject. This implies that a\nprivacy policy is written in a fair way, e.g., it does not use polarizing\nterms, does not require a certain education, or does not assume a particular\nsocial background. We outline our approach to assessing fairness in privacy\npolicies. We identify from fundamental legal sources and fairness research, how\nthe dimensions informational fairness, representational fairness and ethics /\nmorality are related to privacy policies. We propose options to automatically\nassess policies in these fairness dimensions, based on text statistics,\nlinguistic methods and artificial intelligence. We conduct initial experiments\nwith German privacy policies to provide evidence that our approach is\napplicable. Our experiments indicate that there are issues in all three\ndimensions of fairness. This is important, as future privacy policies may be\nused in a corpus for legal artificial intelligence models.",
      "tldr_zh": "本研究探讨了隐私政策的公平性评估问题，强调政策需以公平方式撰写以确保数据主体正确理解和信任，如避免使用偏激术语或假设特定教育背景。作者从法律来源和公平性研究中识别出三个关键维度：informational fairness（信息公平）、representational fairness（代表性公平）和ethics/morality（伦理/道德），并提出基于文本统计、语言学方法和人工智能的自动评估选项。初步实验分析了德国隐私政策，发现所有三个维度均存在问题，这对未来用于legal artificial intelligence模型的隐私政策语料库具有重要影响。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL",
        "K.4.m"
      ],
      "primary_category": "cs.CY",
      "comment": "Accepted at IWSPA 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.08115v2",
      "published_date": "2024-03-12 22:53:32 UTC",
      "updated_date": "2024-05-08 14:47:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:31:55.918591"
    },
    {
      "arxiv_id": "2403.14682v1",
      "title": "Deep Generative Domain Adaptation with Temporal Relation Knowledge for Cross-User Activity Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaozhou Ye",
        "Kevin I-Kai Wang"
      ],
      "abstract": "In human activity recognition (HAR), the assumption that training and testing\ndata are independent and identically distributed (i.i.d.) often fails,\nparticularly in cross-user scenarios where data distributions vary\nsignificantly. This discrepancy highlights the limitations of conventional\ndomain adaptation methods in HAR, which typically overlook the inherent\ntemporal relations in time-series data. To bridge this gap, our study\nintroduces a Conditional Variational Autoencoder with Universal Sequence\nMapping (CVAE-USM) approach, which addresses the unique challenges of\ntime-series domain adaptation in HAR by relaxing the i.i.d. assumption and\nleveraging temporal relations to align data distributions effectively across\ndifferent users. This method combines the strengths of Variational Autoencoder\n(VAE) and Universal Sequence Mapping (USM) to capture and utilize common\ntemporal patterns between users for improved activity recognition. Our results,\nevaluated on two public HAR datasets (OPPT and PAMAP2), demonstrate that\nCVAE-USM outperforms existing state-of-the-art methods, offering a more\naccurate and generalizable solution for cross-user activity recognition.",
      "tldr_zh": "这项研究针对人类活动识别(HAR)中的跨用户场景，解决了训练和测试数据并非独立同分布(i.i.d.)的问题，并强调了传统域适应方法忽略时间序列数据的temporal relations。作者提出了一种Conditional Variational Autoencoder with Universal Sequence Mapping (CVAE-USM)方法，该方法结合Variational Autoencoder (VAE)和Universal Sequence Mapping (USM)，通过利用用户间的共同temporal patterns来对齐数据分布，提高活动识别的准确性。实验结果显示，CVAE-USM在OPPT和PAMAP2公共数据集上优于现有最先进方法，提供了一个更具泛化性的跨用户HAR解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.14682v1",
      "published_date": "2024-03-12 22:48:23 UTC",
      "updated_date": "2024-03-12 22:48:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:32:07.438771"
    },
    {
      "arxiv_id": "2403.17958v1",
      "title": "Deep Generative Domain Adaptation with Temporal Attention for Cross-User Activity Recognition",
      "title_zh": "深度生成领域适应，结合时间注意力，用于跨用户活动识别",
      "authors": [
        "Xiaozhou Ye",
        "Kevin I-Kai Wang"
      ],
      "abstract": "In Human Activity Recognition (HAR), a predominant assumption is that the\ndata utilized for training and evaluation purposes are drawn from the same\ndistribution. It is also assumed that all data samples are independent and\nidentically distributed ($\\displaystyle i.i.d.$). Contrarily, practical\nimplementations often challenge this notion, manifesting data distribution\ndiscrepancies, especially in scenarios such as cross-user HAR. Domain\nadaptation is the promising approach to address these challenges inherent in\ncross-user HAR tasks. However, a clear gap in domain adaptation techniques is\nthe neglect of the temporal relation embedded within time series data during\nthe phase of aligning data distributions. Addressing this oversight, our\nresearch presents the Deep Generative Domain Adaptation with Temporal Attention\n(DGDATA) method. This novel method uniquely recognises and integrates temporal\nrelations during the domain adaptation process. By synergizing the capabilities\nof generative models with the Temporal Relation Attention mechanism, our method\nimproves the classification performance in cross-user HAR. A comprehensive\nevaluation has been conducted on three public sensor-based HAR datasets\ntargeting different scenarios and applications to demonstrate the efficacy of\nthe proposed DGDATA method.",
      "tldr_zh": "本研究针对人类活动识别(HAR)中的跨用户场景，指出现有方法忽略了数据分布差异和时间序列数据的时间关系问题。论文提出Deep Generative Domain Adaptation with Temporal Attention (DGDATA)方法，该方法结合生成模型和Temporal Relation Attention机制，在领域适应过程中整合时间关系，从而提升分类性能。在三个公共传感器-based HAR数据集上的全面评估显示，DGDATA显著提高了跨用户HAR的准确性和有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.HC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.17958v1",
      "published_date": "2024-03-12 22:45:05 UTC",
      "updated_date": "2024-03-12 22:45:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:32:19.312669"
    },
    {
      "arxiv_id": "2403.15424v1",
      "title": "Cross-user activity recognition using deep domain adaptation with temporal relation information",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaozhou Ye",
        "Waleed H. Abdulla",
        "Nirmal Nair",
        "Kevin I-Kai Wang"
      ],
      "abstract": "Human Activity Recognition (HAR) is a cornerstone of ubiquitous computing,\nwith promising applications in diverse fields such as health monitoring and\nambient assisted living. Despite significant advancements, sensor-based HAR\nmethods often operate under the assumption that training and testing data have\nidentical distributions. However, in many real-world scenarios, particularly in\nsensor-based HAR, this assumption is invalidated by out-of-distribution\n($\\displaystyle o.o.d.$) challenges, including differences from heterogeneous\nsensors, change over time, and individual behavioural variability. This paper\ncentres on the latter, exploring the cross-user HAR problem where behavioural\nvariability across individuals results in differing data distributions. To\naddress this challenge, we introduce the Deep Temporal State Domain Adaptation\n(DTSDA) model, an innovative approach tailored for time series domain\nadaptation in cross-user HAR. Contrary to the common assumption of sample\nindependence in existing domain adaptation approaches, DTSDA recognizes and\nharnesses the inherent temporal relations in the data. Therefore, we introduce\n'Temporal State', a concept that defined the different sub-activities within an\nactivity, consistent across different users. We ensure these sub-activities\nfollow a logical time sequence through 'Temporal Consistency' property and\npropose the 'Pseudo Temporal State Labeling' method to identify the\nuser-invariant temporal relations. Moreover, the design principle of DTSDA\nintegrates adversarial learning for better domain adaptation. Comprehensive\nevaluations on three HAR datasets demonstrate DTSDA's superior performance in\ncross-user HAR applications by briding individual behavioral variability using\ntemporal relations across sub-activities.",
      "tldr_zh": "这项研究针对人类活动识别(HAR)中的跨用户问题，解决个体行为变异导致的数据分布差异，提出Deep Temporal State Domain Adaptation (DTSDA)模型，以改善时间序列域适应。DTSDA通过引入'Temporal State'概念来捕捉活动内的子活动及其逻辑时间序列，并利用'Temporal Consistency'和'Pseudo Temporal State Labeling'方法识别用户不变的时间关系，同时整合对抗学习以增强域适应效果。在三个HAR数据集上的评估显示，该模型显著提升了跨用户HAR的性能，通过桥接子活动的时间关系有效缓解行为变异挑战。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.CV",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.15424v1",
      "published_date": "2024-03-12 22:38:09 UTC",
      "updated_date": "2024-03-12 22:38:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:32:32.967819"
    },
    {
      "arxiv_id": "2403.08111v1",
      "title": "AI-Assisted Causal Pathway Diagram for Human-Centered Design",
      "title_zh": "翻译失败",
      "authors": [
        "Ruican Zhong",
        "Donghoon Shin",
        "Rosemary Meza",
        "Predrag Klasnja",
        "Lucas Colusso",
        "Gary Hsieh"
      ],
      "abstract": "This paper explores the integration of causal pathway diagrams (CPD) into\nhuman-centered design (HCD), investigating how these diagrams can enhance the\nearly stages of the design process. A dedicated CPD plugin for the online\ncollaborative whiteboard platform Miro was developed to streamline diagram\ncreation and offer real-time AI-driven guidance. Through a user study with\ndesigners (N=20), we found that CPD's branching and its emphasis on causal\nconnections supported both divergent and convergent processes during design.\nCPD can also facilitate communication among stakeholders. Additionally, we\nfound our plugin significantly reduces designers' cognitive workload and\nincreases their creativity during brainstorming, highlighting the implications\nof AI-assisted tools in supporting creative work and evidence-based designs.",
      "tldr_zh": "这篇论文探讨了将因果路径图 (CPD) 整合到以人为本的设计 (HCD) 中，以提升设计过程的早期阶段。研究团队开发了一个专用的 CPD 插件，用于在线协作白板平台 Miro，提供实时 AI 驱动指导，帮助简化图表创建。用户研究 (N=20) 显示，CPD 的分支结构和因果连接强调，支持了设计的发散和收敛过程，并促进了利益相关者之间的沟通。该插件显著降低了设计者的认知负担，并提高了他们的脑力激荡创造力，突显了 AI-assisted 工具在支持创意工作和基于证据的设计中的潜力。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL",
        "H.5.2; I.2.7"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.08111v1",
      "published_date": "2024-03-12 22:36:27 UTC",
      "updated_date": "2024-03-12 22:36:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:32:45.015313"
    },
    {
      "arxiv_id": "2403.15423v1",
      "title": "Cross-user activity recognition via temporal relation optimal transport",
      "title_zh": "基于时间关系最优传输的跨用户活动识别",
      "authors": [
        "Xiaozhou Ye",
        "Kevin I-Kai Wang"
      ],
      "abstract": "Current research on human activity recognition (HAR) mainly assumes that\ntraining and testing data are drawn from the same distribution to achieve a\ngeneralised model, which means all the data are considered to be independent\nand identically distributed $\\displaystyle (i.i.d.) $. In many real-world\napplications, this assumption does not hold, and collected training and target\ntesting datasets have non-uniform distribution, such as in the case of\ncross-user HAR. Domain adaptation is a promising approach for cross-user HAR\ntasks. Existing domain adaptation works based on the assumption that samples in\neach domain are $\\displaystyle i.i.d. $ and do not consider the knowledge of\ntemporal relation hidden in time series data for aligning data distribution.\nThis strong assumption of $\\displaystyle i.i.d. $ may not be suitable for time\nseries-related domain adaptation methods because the samples formed by time\nseries segmentation and feature extraction techniques are only coarse\napproximations to $\\displaystyle i.i.d. $ assumption in each domain. In this\npaper, we propose the temporal relation optimal transport (TROT) method to\nutilise temporal relation and relax the $\\displaystyle i.i.d. $ assumption for\nthe samples in each domain for accurate and efficient knowledge transfer. We\nobtain the temporal relation representation and implement temporal relation\nalignment of activities via the Hidden Markov model (HMM) and optimal transport\n(OT) techniques. Besides, a new regularisation term that preserves temporal\nrelation order information for an improved optimal transport mapping is\nproposed to enhance the domain adaptation performance. Comprehensive\nexperiments are conducted on three public activity recognition datasets (i.e.\nOPPT, PAMAP2 and DSADS), demonstrating that TROT outperforms other\nstate-of-the-art methods.",
      "tldr_zh": "本研究针对人类活动识别（HAR）中的跨用户场景，指出传统方法假设数据独立同分布（i.i.d.）不适用于时间序列数据，导致知识转移效率低下。论文提出 temporal relation optimal transport (TROT) 方法，通过 Hidden Markov model (HMM) 和 optimal transport (OT) 技术提取并对齐活动的时间关系表示，放松 i.i.d. 假设，并引入一个新正则化项来保留时间顺序信息，从而提升域适应性能。在 OPPT、PAMAP2 和 DSADS 等三个公开数据集上的实验显示，TROT 优于现有最先进方法，实现了更准确和高效的跨用户活动识别。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.CV",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.15423v1",
      "published_date": "2024-03-12 22:33:56 UTC",
      "updated_date": "2024-03-12 22:33:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:32:57.517682"
    },
    {
      "arxiv_id": "2403.08103v2",
      "title": "Contextual Clarity: Generating Sentences with Transformer Models using Context-Reverso Data",
      "title_zh": "翻译失败",
      "authors": [
        "Ruslan Musaev"
      ],
      "abstract": "In the age of information abundance, the ability to provide users with\ncontextually relevant and concise information is crucial. Keyword in Context\n(KIC) generation is a task that plays a vital role in and generation\napplications, such as search engines, personal assistants, and content\nsummarization. In this paper, we present a novel approach to generating\nunambiguous and brief sentence-contexts for given keywords using the T5\ntransformer model, leveraging data obtained from the Context-Reverso API. The\ncode is available at https://github.com/Rusamus/word2context/tree/main .",
      "tldr_zh": "在信息泛滥时代，论文针对 Keyword in Context (KIC) 生成任务，提出了一种新方法，以提供上下文相关且简洁的信息。该方法利用 T5 transformer 模型和从 Context-Reverso API 获取的数据，生成无歧义的句子上下文，从而提升搜索引擎、个人助理和内容摘要等应用的效率。代码已开源在 GitHub 上（https://github.com/Rusamus/word2context/tree/main），便于进一步研究和应用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.08103v2",
      "published_date": "2024-03-12 22:23:08 UTC",
      "updated_date": "2024-03-14 10:47:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:33:09.580803"
    },
    {
      "arxiv_id": "2403.15422v1",
      "title": "Machine Learning Techniques for Sensor-based Human Activity Recognition with Data Heterogeneity -- A Review",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaozhou Ye",
        "Kouichi Sakurai",
        "Nirmal Nair",
        "Kevin I-Kai Wang"
      ],
      "abstract": "Sensor-based Human Activity Recognition (HAR) is crucial in ubiquitous\ncomputing, analysing behaviours through multi-dimensional observations. Despite\nresearch progress, HAR confronts challenges, particularly in data distribution\nassumptions. Most studies often assume uniform data distributions across\ndatasets, contrasting with the varied nature of practical sensor data in human\nactivities. Addressing data heterogeneity issues can improve performance,\nreduce computational costs, and aid in developing personalized, adaptive models\nwith less annotated data. This review investigates how machine learning\naddresses data heterogeneity in HAR, by categorizing data heterogeneity types,\napplying corresponding suitable machine learning methods, summarizing available\ndatasets, and discussing future challenges.",
      "tldr_zh": "这篇综述探讨了基于传感器的Human Activity Recognition (HAR)面临的data heterogeneity问题，即实际传感器数据分布不均匀，与研究假设相悖。论文通过分类data heterogeneity的类型（如数据分布差异），应用合适的machine learning方法来提升HAR性能，减少计算成本，并支持开发个性化适应模型，同时减少标注数据的需求。综述还总结了可用数据集，并讨论了未来挑战，如进一步优化算法以应对复杂现实场景。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.15422v1",
      "published_date": "2024-03-12 22:22:14 UTC",
      "updated_date": "2024-03-12 22:22:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:33:21.074117"
    },
    {
      "arxiv_id": "2403.09728v1",
      "title": "Simulating Weighted Automata over Sequences and Trees with Transformers",
      "title_zh": "使用 Transformer 模拟序列和树上的加权自动机",
      "authors": [
        "Michael Rizvi",
        "Maude Lizaire",
        "Clara Lacroce",
        "Guillaume Rabusseau"
      ],
      "abstract": "Transformers are ubiquitous models in the natural language processing (NLP)\ncommunity and have shown impressive empirical successes in the past few years.\nHowever, little is understood about how they reason and the limits of their\ncomputational capabilities. These models do not process data sequentially, and\nyet outperform sequential neural models such as RNNs. Recent work has shown\nthat these models can compactly simulate the sequential reasoning abilities of\ndeterministic finite automata (DFAs). This leads to the following question: can\ntransformers simulate the reasoning of more complex finite state machines? In\nthis work, we show that transformers can simulate weighted finite automata\n(WFAs), a class of models which subsumes DFAs, as well as weighted tree\nautomata (WTA), a generalization of weighted automata to tree structured\ninputs. We prove these claims formally and provide upper bounds on the sizes of\nthe transformer models needed as a function of the number of states the target\nautomata. Empirically, we perform synthetic experiments showing that\ntransformers are able to learn these compact solutions via standard\ngradient-based training.",
      "tldr_zh": "本文研究探讨了 Transformers 是否能够模拟更复杂的有限状态机模型，包括加权有限自动机 (WFAs) 和加权树自动机 (WTAs)，以扩展其推理能力。作者通过形式化证明表明，Transformers 可以紧凑地模拟这些模型，并提供了所需模型大小的上界，依赖于目标自动机的状态数。实验结果显示，通过标准梯度训练，Transformers 在合成任务中成功学习了这些模拟方案，验证了其超越传统顺序模型如 RNNs 的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CC"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.09728v1",
      "published_date": "2024-03-12 21:54:34 UTC",
      "updated_date": "2024-03-12 21:54:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:33:33.391145"
    },
    {
      "arxiv_id": "2403.14681v1",
      "title": "AI Ethics: A Bibliometric Analysis, Critical Issues, and Key Gaps",
      "title_zh": "翻译失败",
      "authors": [
        "Di Kevin Gao",
        "Andrew Haverly",
        "Sudip Mittal",
        "Jiming Wu",
        "Jingdao Chen"
      ],
      "abstract": "Artificial intelligence (AI) ethics has emerged as a burgeoning yet pivotal\narea of scholarly research. This study conducts a comprehensive bibliometric\nanalysis of the AI ethics literature over the past two decades. The analysis\nreveals a discernible tripartite progression, characterized by an incubation\nphase, followed by a subsequent phase focused on imbuing AI with human-like\nattributes, culminating in a third phase emphasizing the development of\nhuman-centric AI systems. After that, they present seven key AI ethics issues,\nencompassing the Collingridge dilemma, the AI status debate, challenges\nassociated with AI transparency and explainability, privacy protection\ncomplications, considerations of justice and fairness, concerns about algocracy\nand human enfeeblement, and the issue of superintelligence. Finally, they\nidentify two notable research gaps in AI ethics regarding the large ethics\nmodel (LEM) and AI identification and extend an invitation for further\nscholarly research.",
      "tldr_zh": "这篇论文通过文献计量分析(bibliometric analysis)对过去二十年AI伦理研究进行全面审视，揭示了其三阶段发展：从孵化阶段，到赋予AI人类属性阶段，再到以人为中心AI系统的发展。论文讨论了七个关键AI伦理问题，包括Collingridge dilemma、AI status debate、AI透明性和可解释性(challenges associated with AI transparency and explainability)、隐私保护(privacy protection)、公正与公平(justice and fairness)、算法统治和人类虚弱(algocracy and human enfeeblement)，以及超级智能(superintelligence)问题。最终，论文指出了large ethics model (LEM)和AI identification两个主要研究空白，并呼吁学者进行更多深入探讨。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.14681v1",
      "published_date": "2024-03-12 21:43:21 UTC",
      "updated_date": "2024-03-12 21:43:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:33:48.589560"
    },
    {
      "arxiv_id": "2403.08081v1",
      "title": "Mechanics of Next Token Prediction with Self-Attention",
      "title_zh": "翻译失败",
      "authors": [
        "Yingcong Li",
        "Yixiao Huang",
        "M. Emrullah Ildiz",
        "Ankit Singh Rawat",
        "Samet Oymak"
      ],
      "abstract": "Transformer-based language models are trained on large datasets to predict\nthe next token given an input sequence. Despite this simple training objective,\nthey have led to revolutionary advances in natural language processing.\nUnderlying this success is the self-attention mechanism. In this work, we ask:\n$\\textit{What}$ $\\textit{does}$ $\\textit{a}$ $\\textit{single}$\n$\\textit{self-attention}$ $\\textit{layer}$ $\\textit{learn}$ $\\textit{from}$\n$\\textit{next-token}$ $\\textit{prediction?}$ We show that training\nself-attention with gradient descent learns an automaton which generates the\nnext token in two distinct steps: $\\textbf{(1)}$ $\\textbf{Hard}$\n$\\textbf{retrieval:}$ Given input sequence, self-attention precisely selects\nthe $\\textit{high-priority}$ $\\textit{input}$ $\\textit{tokens}$ associated with\nthe last input token. $\\textbf{(2)}$ $\\textbf{Soft}$ $\\textbf{composition:}$ It\nthen creates a convex combination of the high-priority tokens from which the\nnext token can be sampled. Under suitable conditions, we rigorously\ncharacterize these mechanics through a directed graph over tokens extracted\nfrom the training data. We prove that gradient descent implicitly discovers the\nstrongly-connected components (SCC) of this graph and self-attention learns to\nretrieve the tokens that belong to the highest-priority SCC available in the\ncontext window. Our theory relies on decomposing the model weights into a\ndirectional component and a finite component that correspond to hard retrieval\nand soft composition steps respectively. This also formalizes a related\nimplicit bias formula conjectured in [Tarzanagh et al. 2023]. We hope that\nthese findings shed light on how self-attention processes sequential data and\npave the path toward demystifying more complex architectures.",
      "tldr_zh": "这篇论文探讨了Transformer模型中self-attention机制在next-token prediction中的运作机制，揭示了self-attention层通过梯度下降训练学习一个自动机（automaton），以两步过程生成下一个token：hard retrieval（精确选择与最后一个输入token相关的高优先级token）和soft composition（对这些token进行凸组合以采样输出）。作者通过从训练数据提取的directed graph进行理论分析，证明了gradient descent会隐式发现图中的strongly-connected components (SCC)，并优先检索最高优先级SCC中的token，从而正式化了[Tarzanagh et al. 2023]中的隐式偏差公式。这些发现有助于阐明self-attention如何处理序列数据，并为理解更复杂架构提供基础。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to AISTATS 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.08081v1",
      "published_date": "2024-03-12 21:15:38 UTC",
      "updated_date": "2024-03-12 21:15:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:34:00.522794"
    },
    {
      "arxiv_id": "2403.09727v1",
      "title": "Investigating the performance of Retrieval-Augmented Generation and fine-tuning for the development of AI-driven knowledge-based systems",
      "title_zh": "探究检索增强生成和微调在开发AI驱动知识系统的性能",
      "authors": [
        "Robert Lakatos",
        "Peter Pollner",
        "Andras Hajdu",
        "Tamas Joo"
      ],
      "abstract": "The development of generative large language models (G-LLM) opened up new\nopportunities for the development of new types of knowledge-based systems\nsimilar to ChatGPT, Bing, or Gemini. Fine-tuning (FN) and Retrieval-Augmented\nGeneration (RAG) are the techniques that can be used to implement domain\nadaptation for the development of G-LLM-based knowledge systems. In our study,\nusing ROUGE, BLEU, METEOR scores, and cosine similarity, we compare and examine\nthe performance of RAG and FN for the GPT-J-6B, OPT-6.7B, LlaMA, LlaMA-2\nlanguage models. Based on measurements shown on different datasets, we\ndemonstrate that RAG-based constructions are more efficient than models\nproduced with FN. We point out that connecting RAG and FN is not trivial,\nbecause connecting FN models with RAG can cause a decrease in performance.\nFurthermore, we outline a simple RAG-based architecture which, on average,\noutperforms the FN models by 16% in terms of the ROGUE score, 15% in the case\nof the BLEU score, and 53% based on the cosine similarity. This shows the\nsignificant advantage of RAG over FN in terms of hallucination, which is not\noffset by the fact that the average 8% better METEOR score of FN models\nindicates greater creativity compared to RAG.",
      "tldr_zh": "本研究调查了 Retrieval-Augmented Generation (RAG) 和 Fine-tuning (FN) 在开发基于生成性大型语言模型 (G-LLM) 的 AI 驱动知识系统中的性能表现。研究者使用 ROUGE、BLEU、METEOR 分数以及余弦相似度指标，对 GPT-J-6B、OPT-6.7B、LlaMA 和 LlaMA-2 等模型进行了比较，结果显示 RAG 架构平均在 ROUGE 分数上超出 FN 16%、BLEU 分数超出 15%、余弦相似度超出 53%，并在减少幻觉方面表现出显著优势。儘管 FN 在 METEOR 分数上高出 8% 表示更高的创造性，但直接结合 RAG 和 FN 可能导致性能下降，因此研究提出了一种简单的 RAG 架构作为更高效的选择。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.09727v1",
      "published_date": "2024-03-12 21:06:31 UTC",
      "updated_date": "2024-03-12 21:06:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:34:12.465835"
    },
    {
      "arxiv_id": "2403.08077v1",
      "title": "A Multimodal Intermediate Fusion Network with Manifold Learning for Stress Detection",
      "title_zh": "一种基于流形学习的压力检测多模态中间融合网络",
      "authors": [
        "Morteza Bodaghi",
        "Majid Hosseini",
        "Raju Gottumukkala"
      ],
      "abstract": "Multimodal deep learning methods capture synergistic features from multiple\nmodalities and have the potential to improve accuracy for stress detection\ncompared to unimodal methods. However, this accuracy gain typically comes from\nhigh computational cost due to the high-dimensional feature spaces, especially\nfor intermediate fusion. Dimensionality reduction is one way to optimize\nmultimodal learning by simplifying data and making the features more amenable\nto processing and analysis, thereby reducing computational complexity. This\npaper introduces an intermediate multimodal fusion network with manifold\nlearning-based dimensionality reduction. The multimodal network generates\nindependent representations from biometric signals and facial landmarks through\n1D-CNN and 2D-CNN. Finally, these features are fused and fed to another 1D-CNN\nlayer, followed by a fully connected dense layer. We compared various\ndimensionality reduction techniques for different variations of unimodal and\nmultimodal networks. We observe that the intermediate-level fusion with the\nMulti-Dimensional Scaling (MDS) manifold method showed promising results with\nan accuracy of 96.00\\% in a Leave-One-Subject-Out Cross-Validation (LOSO-CV)\nparadigm over other dimensional reduction methods. MDS had the highest\ncomputational cost among manifold learning methods. However, while\noutperforming other networks, it managed to reduce the computational cost of\nthe proposed networks by 25\\% when compared to six well-known conventional\nfeature selection methods used in the preprocessing step.",
      "tldr_zh": "本文提出了一种基于流形学习的中间多模态融合网络，用于压力检测，以捕捉生物信号和面部landmarks的多模态协同特征，同时通过降维技术降低计算成本。该网络利用1D-CNN处理生物信号、2D-CNN处理面部landmarks，并将特征融合后应用Multi-Dimensional Scaling (MDS)进行降维优化。实验结果显示，该方法在Leave-One-Subject-Out Cross-Validation (LOSO-CV)中达到96.00%的准确率，比其他降维技术表现更优，并将计算成本比传统特征选择方法降低了25%。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "This work was accepted to The 3rd International Conference on\n  Computing and Machine Intelligence (ICMI 2024)",
      "pdf_url": "http://arxiv.org/pdf/2403.08077v1",
      "published_date": "2024-03-12 21:06:19 UTC",
      "updated_date": "2024-03-12 21:06:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:34:23.001928"
    },
    {
      "arxiv_id": "2403.14680v3",
      "title": "Trust in AI: Progress, Challenges, and Future Directions",
      "title_zh": "AI 的信任：进展、挑战与未来方向",
      "authors": [
        "Saleh Afroogh",
        "Ali Akbari",
        "Evan Malone",
        "Mohammadali Kargar",
        "Hananeh Alambeigi"
      ],
      "abstract": "The increasing use of artificial intelligence (AI) systems in our daily life\nthrough various applications, services, and products explains the significance\nof trust/distrust in AI from a user perspective. AI-driven systems (as opposed\nto other technologies) have ubiquitously diffused in our life not only as some\nbeneficial tools to be used by human agents but also are going to be\nsubstitutive agents on our behalf, or manipulative minds that would influence\nhuman thought, decision, and agency. Trust/distrust in AI plays the role of a\nregulator and could significantly control the level of this diffusion, as trust\ncan increase, and distrust may reduce the rate of adoption of AI. Recently,\nvarieties of studies have paid attention to the variant dimension of\ntrust/distrust in AI, and its relevant considerations. In this systematic\nliterature review, after conceptualization of trust in the current AI\nliterature review, we will investigate trust in different types of\nhuman-Machine interaction, and its impact on technology acceptance in different\ndomains. In addition to that, we propose a taxonomy of technical (i.e., safety,\naccuracy, robustness) and non-technical axiological (i.e., ethical, legal, and\nmixed) trustworthiness metrics, and some trustworthy measurements. Moreover, we\nexamine some major trust-breakers in AI (e.g., autonomy and dignity threat),\nand trust makers; and propose some future directions and probable solutions for\nthe transition to a trustworthy AI.",
      "tldr_zh": "这篇论文通过系统文献综述探讨了AI中的信任（Trust in AI），强调信任/不信任如何影响AI的采用率，尤其在AI作为替代或影响人类决策的背景下。作者调查了不同类型的人机交互（human-Machine interaction）对技术接受的影响，并提出一个分类，包括技术指标（如safety、accuracy、robustness）和非技术指标（如ethical、legal因素）的trustworthiness metrics。最终，论文识别了信任破坏者（如autonomy和dignity威胁），并为实现可信AI提出未来方向和解决方案。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.14680v3",
      "published_date": "2024-03-12 20:26:49 UTC",
      "updated_date": "2024-04-04 15:34:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:34:33.000018"
    },
    {
      "arxiv_id": "2403.08059v2",
      "title": "FluoroSAM: A Language-aligned Foundation Model for X-ray Image Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Benjamin D. Killeen",
        "Liam J. Wang",
        "Han Zhang",
        "Mehran Armand",
        "Russell H. Taylor",
        "Dave Dreizin",
        "Greg Osgood",
        "Mathias Unberath"
      ],
      "abstract": "Automated X-ray image segmentation would accelerate research and development\nin diagnostic and interventional precision medicine. Prior efforts have\ncontributed task-specific models capable of solving specific image analysis\nproblems, but the utility of these models is restricted to their particular\ntask domain, and expanding to broader use requires additional data, labels, and\nretraining efforts. Recently, foundation models (FMs) -- machine learning\nmodels trained on large amounts of highly variable data thus enabling broad\napplicability -- have emerged as promising tools for automated image analysis.\nExisting FMs for medical image analysis focus on scenarios and modalities where\nobjects are clearly defined by visually apparent boundaries, such as surgical\ntool segmentation in endoscopy. X-ray imaging, by contrast, does not generally\noffer such clearly delineated boundaries or structure priors. During X-ray\nimage formation, complex 3D structures are projected in transmission onto the\nimaging plane, resulting in overlapping features of varying opacity and shape.\nTo pave the way toward an FM for comprehensive and automated analysis of\narbitrary medical X-ray images, we develop FluoroSAM, a language-aligned\nvariant of the Segment-Anything Model, trained from scratch on 1.6M synthetic\nX-ray images. FluoroSAM is trained on data including masks for 128 organ types\nand 464 non-anatomical objects, such as tools and implants. In real X-ray\nimages of cadaveric specimens, FluoroSAM is able to segment bony anatomical\nstructures based on text-only prompting with 0.51 and 0.79 DICE with\npoint-based refinement, outperforming competing SAM variants for all\nstructures. FluoroSAM is also capable of zero-shot generalization to segmenting\nclasses beyond the training set thanks to its language alignment, which we\ndemonstrate for full lung segmentation on real chest X-rays.",
      "tldr_zh": "这篇论文介绍了 FluoroSAM，一种语言对齐的 Foundation Model，旨在实现 X-ray 图像的全面自动化分割，以加速诊断和介入性精准医学的研究。FluoroSAM 基于 Segment-Anything Model 的变体，从零训练于 1.6M 合成 X-ray 图像，包括 128 种器官和 464 种非解剖对象，如工具和植入物。实验结果显示，在真实尸体 X-ray 图像上，FluoroSAM 通过文本提示和点-based 精炼，实现了骨骼结构分割的 DICE 分数分别为 0.51 和 0.79，优于其他 SAM 变体。该模型还展示了 zero-shot generalization 的能力，能扩展到训练集外的任务，如肺部分割。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.08059v2",
      "published_date": "2024-03-12 20:11:38 UTC",
      "updated_date": "2024-03-28 00:59:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:34:47.034297"
    },
    {
      "arxiv_id": "2403.08049v1",
      "title": "TutoAI: A Cross-domain Framework for AI-assisted Mixed-media Tutorial Creation on Physical Tasks",
      "title_zh": "TutoAI：一种用于 AI 辅助混合媒体教程创建的跨领域框架（针对物理任务）",
      "authors": [
        "Yuexi Chen",
        "Vlad I. Morariu",
        "Anh Truong",
        "Zhicheng Liu"
      ],
      "abstract": "Mixed-media tutorials, which integrate videos, images, text, and diagrams to\nteach procedural skills, offer more browsable alternatives than timeline-based\nvideos. However, manually creating such tutorials is tedious, and existing\nautomated solutions are often restricted to a particular domain. While AI\nmodels hold promise, it is unclear how to effectively harness their powers,\ngiven the multi-modal data involved and the vast landscape of models. We\npresent TutoAI, a cross-domain framework for AI-assisted mixed-media tutorial\ncreation on physical tasks. First, we distill common tutorial components by\nsurveying existing work; then, we present an approach to identify, assemble,\nand evaluate AI models for component extraction; finally, we propose guidelines\nfor designing user interfaces (UI) that support tutorial creation based on\nAI-generated components. We show that TutoAI has achieved higher or similar\nquality compared to a baseline model in preliminary user studies.",
      "tldr_zh": "本文提出 TutoAI，一个跨域框架，用于 AI-assisted 混合媒体教程的创建，旨在简化教学物理任务技能的过程，如整合视频、图像、文本和图表。框架首先通过调查现有工作提炼常见教程组件，然后开发方法识别、组装和评估 AI 模型以提取这些组件，并提供用户界面 (UI) 设计指南以支持教程生成。初步用户研究显示，TutoAI 在教程质量上高于或类似于基线模型。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.HC",
      "comment": "CHI 2024, supplementary materials:\n  https://hdi.cs.umd.edu/papers/TutoAI_CHI24_Supp.pdf",
      "pdf_url": "http://arxiv.org/pdf/2403.08049v1",
      "published_date": "2024-03-12 19:46:59 UTC",
      "updated_date": "2024-03-12 19:46:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:34:59.820621"
    },
    {
      "arxiv_id": "2403.08036v1",
      "title": "A Review of Cybersecurity Incidents in the Food and Agriculture Sector",
      "title_zh": "食品和农业部门的网络安全事件综述",
      "authors": [
        "Ajay Kulkarni",
        "Yingjie Wang",
        "Munisamy Gopinath",
        "Dan Sobien",
        "Abdul Rahman",
        "Feras A. Batarseh"
      ],
      "abstract": "The increasing utilization of emerging technologies in the Food & Agriculture\n(FA) sector has heightened the need for security to minimize cyber risks.\nConsidering this aspect, this manuscript reviews disclosed and documented\ncybersecurity incidents in the FA sector. For this purpose, thirty\ncybersecurity incidents were identified, which took place between July 2011 and\nApril 2023. The details of these incidents are reported from multiple sources\nsuch as: the private industry and flash notifications generated by the Federal\nBureau of Investigation (FBI), internal reports from the affected\norganizations, and available media sources. Considering the available\ninformation, a brief description of the security threat, ransom amount, and\nimpact on the organization are discussed for each incident. This review reports\nan increased frequency of cybersecurity threats to the FA sector. To minimize\nthese cyber risks, popular cybersecurity frameworks and recent\nagriculture-specific cybersecurity solutions are also discussed. Further, the\nneed for AI assurance in the FA sector is explained, and the Farmer-Centered AI\n(FCAI) framework is proposed. The main aim of the FCAI framework is to support\nfarmers in decision-making for agricultural production, by incorporating AI\nassurance. Lastly, the effects of the reported cyber incidents on other\ncritical infrastructures, food security, and the economy are noted, along with\nspecifying the open issues for future development.",
      "tldr_zh": "这篇论文回顾了2011年7月至2023年4月间Food & Agriculture (FA) 部门发生的30起已公开网络安全事件，通过FBI报告、私人行业数据和媒体来源分析了每起事件的威胁细节、赎金金额及对组织的影响。研究发现，这些网络安全威胁的频率显著增加，并讨论了流行网络安全框架以及针对农业的特定解决方案，以降低风险。论文强调了AI assurance在FA部门的重要性，并提出了Farmer-Centered AI (FCAI)框架，以支持农民在农业生产中的决策。最终，它探讨了这些事件对关键基础设施、食品安全和经济的影响，并指出了未来研究的开放问题。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CR",
      "comment": "Preprint. Submitted for journal publication",
      "pdf_url": "http://arxiv.org/pdf/2403.08036v1",
      "published_date": "2024-03-12 19:15:20 UTC",
      "updated_date": "2024-03-12 19:15:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:35:13.359152"
    },
    {
      "arxiv_id": "2403.08035v1",
      "title": "Harnessing Artificial Intelligence to Combat Online Hate: Exploring the Challenges and Opportunities of Large Language Models in Hate Speech Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Tharindu Kumarage",
        "Amrita Bhattacharjee",
        "Joshua Garland"
      ],
      "abstract": "Large language models (LLMs) excel in many diverse applications beyond\nlanguage generation, e.g., translation, summarization, and sentiment analysis.\nOne intriguing application is in text classification. This becomes pertinent in\nthe realm of identifying hateful or toxic speech -- a domain fraught with\nchallenges and ethical dilemmas. In our study, we have two objectives: firstly,\nto offer a literature review revolving around LLMs as classifiers, emphasizing\ntheir role in detecting and classifying hateful or toxic content. Subsequently,\nwe explore the efficacy of several LLMs in classifying hate speech: identifying\nwhich LLMs excel in this task as well as their underlying attributes and\ntraining. Providing insight into the factors that contribute to an LLM\nproficiency (or lack thereof) in discerning hateful content. By combining a\ncomprehensive literature review with an empirical analysis, our paper strives\nto shed light on the capabilities and constraints of LLMs in the crucial domain\nof hate speech detection.",
      "tldr_zh": "本研究探讨了利用大型语言模型（LLMs）来对抗在线仇恨言论的挑战与机遇，焦点在于LLMs在仇恨言论检测中的文本分类应用。论文首先进行文献回顾，总结了LLMs作为分类器的作用及其在识别仇恨或毒性内容方面的表现。接着，通过实证分析评估多个LLMs的效能，分析其优势、训练因素以及在仇恨言论识别中的能力和限制，为未来改进提供见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.08035v1",
      "published_date": "2024-03-12 19:12:28 UTC",
      "updated_date": "2024-03-12 19:12:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:35:23.410546"
    },
    {
      "arxiv_id": "2403.08032v1",
      "title": "LG-Traj: LLM Guided Pedestrian Trajectory Prediction",
      "title_zh": "LG-Traj：LLM 引导的行人",
      "authors": [
        "Pranav Singh Chib",
        "Pravendra Singh"
      ],
      "abstract": "Accurate pedestrian trajectory prediction is crucial for various\napplications, and it requires a deep understanding of pedestrian motion\npatterns in dynamic environments. However, existing pedestrian trajectory\nprediction methods still need more exploration to fully leverage these motion\npatterns. This paper investigates the possibilities of using Large Language\nModels (LLMs) to improve pedestrian trajectory prediction tasks by inducing\nmotion cues. We introduce LG-Traj, a novel approach incorporating LLMs to\ngenerate motion cues present in pedestrian past/observed trajectories. Our\napproach also incorporates motion cues present in pedestrian future\ntrajectories by clustering future trajectories of training data using a mixture\nof Gaussians. These motion cues, along with pedestrian coordinates, facilitate\na better understanding of the underlying representation. Furthermore, we\nutilize singular value decomposition to augment the observed trajectories,\nincorporating them into the model learning process to further enhance\nrepresentation learning. Our method employs a transformer-based architecture\ncomprising a motion encoder to model motion patterns and a social decoder to\ncapture social interactions among pedestrians. We demonstrate the effectiveness\nof our approach on popular pedestrian trajectory prediction benchmarks, namely\nETH-UCY and SDD, and present various ablation experiments to validate our\napproach.",
      "tldr_zh": "该论文提出 LG-Traj 方法，利用 Large Language Models (LLMs) 来指导行人轨迹预测，通过生成观察轨迹和未来轨迹的运动线索，增强对动态环境运动模式的理解。方法包括使用高斯混合模型聚类未来轨迹、奇异值分解 (SVD) 增强观察轨迹，并采用基于 Transformer 的架构，包含运动编码器建模运动模式和社会解码器捕捉行人社交互动。实验在 ETH-UCY 和 SDD 数据集上验证了方法的有效性，并通过消融实验证明了各组件的贡献。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Under Review",
      "pdf_url": "http://arxiv.org/pdf/2403.08032v1",
      "published_date": "2024-03-12 19:06:23 UTC",
      "updated_date": "2024-03-12 19:06:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:35:37.470768"
    },
    {
      "arxiv_id": "2403.08017v2",
      "title": "Red Teaming Models for Hyperspectral Image Analysis Using Explainable AI",
      "title_zh": "翻译失败",
      "authors": [
        "Vladimir Zaigrajew",
        "Hubert Baniecki",
        "Lukasz Tulczyjew",
        "Agata M. Wijata",
        "Jakub Nalepa",
        "Nicolas Longépé",
        "Przemyslaw Biecek"
      ],
      "abstract": "Remote sensing (RS) applications in the space domain demand machine learning\n(ML) models that are reliable, robust, and quality-assured, making red teaming\na vital approach for identifying and exposing potential flaws and biases. Since\nboth fields advance independently, there is a notable gap in integrating red\nteaming strategies into RS. This paper introduces a methodology for examining\nML models operating on hyperspectral images within the HYPERVIEW challenge,\nfocusing on soil parameters' estimation. We use post-hoc explanation methods\nfrom the Explainable AI (XAI) domain to critically assess the best performing\nmodel that won the HYPERVIEW challenge and served as an inspiration for the\nmodel deployed on board the INTUITION-1 hyperspectral mission. Our approach\neffectively red teams the model by pinpointing and validating key shortcomings,\nconstructing a model that achieves comparable performance using just 1% of the\ninput features and a mere up to 5% performance loss. Additionally, we propose a\nnovel way of visualizing explanations that integrate domain-specific\ninformation about hyperspectral bands (wavelengths) and data transformations to\nbetter suit interpreting models for hyperspectral image analysis.",
      "tldr_zh": "这篇论文介绍了使用Explainable AI (XAI)进行高光谱图像分析模型的Red Teaming方法，旨在识别遥感应用中机器学习(ML)模型的潜在缺陷和偏差。研究者通过后验解释方法评估了HYPERVIEW挑战赛的获胜模型，发现其关键不足，并构建了一个仅使用1%输入特征的新模型，性能损失不超过5%。此外，论文提出了一种新型可视化解释技术，整合高光谱波段（wavelengths）和数据转换信息，以提升对高光谱图像模型的解读和可靠性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "14 pages, 9 figures, ICLR 2024 Machine Learning for Remote Sensing\n  (ML4RS) Workshop",
      "pdf_url": "http://arxiv.org/pdf/2403.08017v2",
      "published_date": "2024-03-12 18:28:32 UTC",
      "updated_date": "2024-03-14 18:40:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:35:47.479679"
    },
    {
      "arxiv_id": "2403.08011v1",
      "title": "Gujarati-English Code-Switching Speech Recognition using ensemble prediction of spoken language",
      "title_zh": "翻译失败",
      "authors": [
        "Yash Sharma",
        "Basil Abraham",
        "Preethi Jyothi"
      ],
      "abstract": "An important and difficult task in code-switched speech recognition is to\nrecognize the language, as lots of words in two languages can sound similar,\nespecially in some accents. We focus on improving performance of end-to-end\nAutomatic Speech Recognition models by conditioning transformer layers on\nlanguage ID of words and character in the output in an per layer supervised\nmanner. To this end, we propose two methods of introducing language specific\nparameters and explainability in the multi-head attention mechanism, and\nimplement a Temporal Loss that helps maintain continuity in input alignment.\nDespite being unable to reduce WER significantly, our method shows promise in\npredicting the correct language from just spoken data. We introduce\nregularization in the language prediction by dropping LID in the sequence,\nwhich helps align long repeated output sequences.",
      "tldr_zh": "该研究针对Gujarati-English Code-Switching语音识别中的语言识别挑战，提出了一种在Transformer层中引入语言ID（LID）监督的方法，以改进端到端Automatic Speech Recognition（ASR）模型的性能。方法包括在多头注意力机制中添加语言特定参数和可解释性，以及实现Temporal Loss来确保输入对齐的连续性，同时通过序列中删除LID进行正则化以处理长重复输出。实验结果显示，虽然未显著降低Word Error Rate（WER），但该方法在从语音数据中准确预测语言方面表现出潜力，为代码切换场景的语音识别提供了新思路。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Bachelor's thesis, 28 pages, includes appendix",
      "pdf_url": "http://arxiv.org/pdf/2403.08011v1",
      "published_date": "2024-03-12 18:21:20 UTC",
      "updated_date": "2024-03-12 18:21:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:35:59.837886"
    },
    {
      "arxiv_id": "2403.08004v2",
      "title": "Leveraging LLMs for On-the-Fly Instruction Guided Image Editing",
      "title_zh": "翻译失败",
      "authors": [
        "Rodrigo Santos",
        "João Silva",
        "António Branco"
      ],
      "abstract": "The combination of language processing and image processing keeps attracting\nincreased interest given recent impressive advances that leverage the combined\nstrengths of both domains of research. Among these advances, the task of\nediting an image on the basis solely of a natural language instruction stands\nout as a most challenging endeavour. While recent approaches for this task\nresort, in one way or other, to some form of preliminary preparation, training\nor fine-tuning, this paper explores a novel approach: We propose a\npreparation-free method that permits instruction-guided image editing on the\nfly. This approach is organized along three steps properly orchestrated that\nresort to image captioning and DDIM inversion, followed by obtaining the edit\ndirection embedding, followed by image editing proper. While dispensing with\npreliminary preparation, our approach demonstrates to be effective and\ncompetitive, outperforming recent, state of the art models for this task when\nevaluated on the MAGICBRUSH dataset.",
      "tldr_zh": "本研究探讨了利用大型语言模型(LLMs)实现即时(On-the-Fly)指令引导图像编辑，针对基于自然语言指令的图像编辑这一挑战性任务。不同于现有方法，该方法无需预训练或微调，而是通过三个关键步骤——图像描述(image captioning)和DDIM inversion、获取编辑方向嵌入(edit direction embedding)，以及实际图像编辑——来实现高效编辑。在MAGICBRUSH数据集上的评估显示，该方法优于现有最先进模型，证明了其有效性和竞争力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.08004v2",
      "published_date": "2024-03-12 18:12:50 UTC",
      "updated_date": "2024-12-04 10:35:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:36:10.961039"
    },
    {
      "arxiv_id": "2403.07979v1",
      "title": "Do Agents Dream of Electric Sheep?: Improving Generalization in Reinforcement Learning through Generative Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Giorgio Franceschelli",
        "Mirco Musolesi"
      ],
      "abstract": "The Overfitted Brain hypothesis suggests dreams happen to allow\ngeneralization in the human brain. Here, we ask if the same is true for\nreinforcement learning agents as well. Given limited experience in a real\nenvironment, we use imagination-based reinforcement learning to train a policy\non dream-like episodes, where non-imaginative, predicted trajectories are\nmodified through generative augmentations. Experiments on four ProcGen\nenvironments show that, compared to classic imagination and offline training on\ncollected experience, our method can reach a higher level of generalization\nwhen dealing with sparsely rewarded environments.",
      "tldr_zh": "该论文受 Overfitted Brain 假设启发，探讨强化学习(Reinforcement Learning)代理是否能通过生成式学习(Generative Learning)提升泛化能力，类似于人类梦想的作用。方法包括使用 imagination-based reinforcement learning，在真实环境经验有限时，通过生成式增强修改预测轨迹来训练策略。实验结果显示，在四个 ProcGen 环境中，该方法在稀疏奖励场景下比经典想象和离线训练实现了更高的泛化水平。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.07979v1",
      "published_date": "2024-03-12 18:00:02 UTC",
      "updated_date": "2024-03-12 18:00:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:36:23.455965"
    },
    {
      "arxiv_id": "2403.07869v2",
      "title": "TeleMoMa: A Modular and Versatile Teleoperation System for Mobile Manipulation",
      "title_zh": "翻译失败",
      "authors": [
        "Shivin Dass",
        "Wensi Ai",
        "Yuqian Jiang",
        "Samik Singh",
        "Jiaheng Hu",
        "Ruohan Zhang",
        "Peter Stone",
        "Ben Abbatematteo",
        "Roberto Martín-Martín"
      ],
      "abstract": "A critical bottleneck limiting imitation learning in robotics is the lack of\ndata. This problem is more severe in mobile manipulation, where collecting\ndemonstrations is harder than in stationary manipulation due to the lack of\navailable and easy-to-use teleoperation interfaces. In this work, we\ndemonstrate TeleMoMa, a general and modular interface for whole-body\nteleoperation of mobile manipulators. TeleMoMa unifies multiple human\ninterfaces including RGB and depth cameras, virtual reality controllers,\nkeyboard, joysticks, etc., and any combination thereof. In its more accessible\nversion, TeleMoMa works using simply vision (e.g., an RGB-D camera), lowering\nthe entry bar for humans to provide mobile manipulation demonstrations. We\ndemonstrate the versatility of TeleMoMa by teleoperating several existing\nmobile manipulators - PAL Tiago++, Toyota HSR, and Fetch - in simulation and\nthe real world. We demonstrate the quality of the demonstrations collected with\nTeleMoMa by training imitation learning policies for mobile manipulation tasks\ninvolving synchronized whole-body motion. Finally, we also show that TeleMoMa's\nteleoperation channel enables teleoperation on site, looking at the robot, or\nremote, sending commands and observations through a computer network, and\nperform user studies to evaluate how easy it is for novice users to learn to\ncollect demonstrations with different combinations of human interfaces enabled\nby our system. We hope TeleMoMa becomes a helpful tool for the community\nenabling researchers to collect whole-body mobile manipulation demonstrations.\nFor more information and video results,\nhttps://robin-lab.cs.utexas.edu/telemoma-web.",
      "tldr_zh": "这篇论文介绍了 TeleMoMa，一种模块化和多功能的遥操作系统，旨在解决机器人移动操作中数据缺乏的问题，特别是通过易用的接口简化演示收集。TeleMoMa 整合多种人类接口，如 RGB 和深度相机、VR 控制器、键盘和手柄等，甚至只需 RGB-D 相机即可实现全身体遥操作。实验在模拟和真实环境中展示了其对 PAL Tiago++、Toyota HSR 和 Fetch 等机器人的适用性，并使用收集的演示训练模仿学习策略，成功处理同步全身体动任务。用户研究表明，TeleMoMa 支持现场和远程操作，且易于新手学习，有望成为机器人社区的实用工具。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.07869v2",
      "published_date": "2024-03-12 17:58:01 UTC",
      "updated_date": "2024-03-21 19:57:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:36:36.582041"
    },
    {
      "arxiv_id": "2403.07865v5",
      "title": "CodeAttack: Revealing Safety Generalization Challenges of Large Language Models via Code Completion",
      "title_zh": "CodeAttack: 通过代码补全揭示大型语言模型的安全泛化挑战",
      "authors": [
        "Qibing Ren",
        "Chang Gao",
        "Jing Shao",
        "Junchi Yan",
        "Xin Tan",
        "Wai Lam",
        "Lizhuang Ma"
      ],
      "abstract": "The rapid advancement of Large Language Models (LLMs) has brought about\nremarkable generative capabilities but also raised concerns about their\npotential misuse. While strategies like supervised fine-tuning and\nreinforcement learning from human feedback have enhanced their safety, these\nmethods primarily focus on natural languages, which may not generalize to other\ndomains. This paper introduces CodeAttack, a framework that transforms natural\nlanguage inputs into code inputs, presenting a novel environment for testing\nthe safety generalization of LLMs. Our comprehensive studies on\nstate-of-the-art LLMs including GPT-4, Claude-2, and Llama-2 series reveal a\nnew and universal safety vulnerability of these models against code input:\nCodeAttack bypasses the safety guardrails of all models more than 80\\% of the\ntime. We find that a larger distribution gap between CodeAttack and natural\nlanguage leads to weaker safety generalization, such as encoding natural\nlanguage input with data structures. Furthermore, we give our hypotheses about\nthe success of CodeAttack: the misaligned bias acquired by LLMs during code\ntraining, prioritizing code completion over avoiding the potential safety risk.\nFinally, we analyze potential mitigation measures. These findings highlight new\nsafety risks in the code domain and the need for more robust safety alignment\nalgorithms to match the code capabilities of LLMs.",
      "tldr_zh": "本论文引入 CodeAttack 框架，将自然语言输入转化为代码输入，以测试 Large Language Models (LLMs) 的安全泛化能力。研究发现，CodeAttack 能成功绕过 GPT-4、Claude-2 和 Llama-2 等模型的安全防护，成功率超过 80%，这主要是由于代码输入与自然语言的分布差距导致的安全弱点，以及 LLMs 在代码训练中获得的偏差优先代码完成而忽略风险。最终，论文分析了潜在缓解措施，并强调了在代码域中开发更 robust 的安全对齐算法的必要性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR",
        "cs.LG",
        "cs.SE"
      ],
      "primary_category": "cs.CL",
      "comment": "ACL Findings 2024, Code is available at\n  https://github.com/renqibing/CodeAttack",
      "pdf_url": "http://arxiv.org/pdf/2403.07865v5",
      "published_date": "2024-03-12 17:55:38 UTC",
      "updated_date": "2024-09-14 11:41:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:36:48.882734"
    },
    {
      "arxiv_id": "2403.09725v1",
      "title": "RAD-PHI2: Instruction Tuning PHI-2 for Radiology",
      "title_zh": "翻译失败",
      "authors": [
        "Mercy Ranjit",
        "Gopinath Ganapathy",
        "Shaury Srivastav",
        "Tanuja Ganu",
        "Srujana Oruganti"
      ],
      "abstract": "Small Language Models (SLMs) have shown remarkable performance in general\ndomain language understanding, reasoning and coding tasks, but their\ncapabilities in the medical domain, particularly concerning radiology text, is\nless explored. In this study, we investigate the application of SLMs for\ngeneral radiology knowledge specifically question answering related to\nunderstanding of symptoms, radiological appearances of findings, differential\ndiagnosis, assessing prognosis, and suggesting treatments w.r.t diseases\npertaining to different organ systems. Additionally, we explore the utility of\nSLMs in handling text-related tasks with respect to radiology reports within\nAI-driven radiology workflows. We fine-tune Phi-2, a SLM with 2.7 billion\nparameters using high-quality educational content from Radiopaedia, a\ncollaborative online radiology resource. The resulting language model,\nRadPhi-2-Base, exhibits the ability to address general radiology queries across\nvarious systems (e.g., chest, cardiac). Furthermore, we investigate Phi-2 for\ninstruction tuning, enabling it to perform specific tasks. By fine-tuning Phi-2\non both general domain tasks and radiology-specific tasks related to chest\nX-ray reports, we create Rad-Phi2. Our empirical results reveal that Rad-Phi2\nBase and Rad-Phi2 perform comparably or even outperform larger models such as\nMistral-7B-Instruct-v0.2 and GPT-4 providing concise and precise answers. In\nsummary, our work demonstrates the feasibility and effectiveness of utilizing\nSLMs in radiology workflows both for knowledge related queries as well as for\nperforming specific tasks related to radiology reports thereby opening up new\navenues for enhancing the quality and efficiency of radiology practice.",
      "tldr_zh": "本研究探讨了小语言模型 (SLMs) 在放射学领域的应用，特别是针对放射学文本的问答和报告处理。研究者通过微调 Phi-2 模型（2.7 亿参数）使用 Radiopaedia 的高质量教育内容，开发出 RadPhi-2-Base 模型，能够有效处理各种系统（如胸部、心脏）的放射学查询。进一步进行 Instruction Tuning，将 Phi-2 应用于放射学特定任务（如胸部 X 光报告分析），创建了 Rad-Phi2 模型。实验结果显示，RadPhi-2-Base 和 Rad-Phi2 与更大模型如 Mistral-7B-Instruct-v0.2 和 GPT-4 相比，提供更简洁精确的答案，并证明 SLMs 可提升放射学工作流的效率和质量。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "J.3"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.09725v1",
      "published_date": "2024-03-12 17:27:22 UTC",
      "updated_date": "2024-03-12 17:27:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:37:02.828701"
    },
    {
      "arxiv_id": "2403.07839v1",
      "title": "MoPE-CLIP: Structured Pruning for Efficient Vision-Language Models with Module-wise Pruning Error Metric",
      "title_zh": "翻译失败",
      "authors": [
        "Haokun Lin",
        "Haoli Bai",
        "Zhili Liu",
        "Lu Hou",
        "Muyi Sun",
        "Linqi Song",
        "Ying Wei",
        "Zhenan Sun"
      ],
      "abstract": "Vision-language pre-trained models have achieved impressive performance on\nvarious downstream tasks. However, their large model sizes hinder their\nutilization on platforms with limited computational resources. We find that\ndirectly using smaller pre-trained models and applying magnitude-based pruning\non CLIP models leads to inflexibility and inferior performance. Recent efforts\nfor VLP compression either adopt uni-modal compression metrics resulting in\nlimited performance or involve costly mask-search processes with learnable\nmasks. In this paper, we first propose the Module-wise Pruning Error (MoPE)\nmetric, accurately assessing CLIP module importance by performance decline on\ncross-modal tasks. Using the MoPE metric, we introduce a unified pruning\nframework applicable to both pre-training and task-specific fine-tuning\ncompression stages. For pre-training, MoPE-CLIP effectively leverages knowledge\nfrom the teacher model, significantly reducing pre-training costs while\nmaintaining strong zero-shot capabilities. For fine-tuning, consecutive pruning\nfrom width to depth yields highly competitive task-specific models. Extensive\nexperiments in two stages demonstrate the effectiveness of the MoPE metric, and\nMoPE-CLIP outperforms previous state-of-the-art VLP compression methods.",
      "tldr_zh": "该论文针对视觉语言模型(Vision-Language Models)的规模问题，提出MoPE-CLIP框架，使用Module-wise Pruning Error (MoPE)指标来评估CLIP模型模块的重要性，通过测量跨模态任务上的性能下降实现精确剪枝。\nMoPE指标支持一个统一的剪枝框架，可应用于预训练阶段（从教师模型获取知识，减少计算成本并保持零样本能力）和任务特定微调阶段（通过宽度到深度的连续剪枝优化模型）。\n实验结果表明，MoPE-CLIP在预训练和微调任务中均优于现有状态-of-the-art方法，提供更高效的模型压缩方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "18 pages, 8 figures, Published in CVPR2024",
      "pdf_url": "http://arxiv.org/pdf/2403.07839v1",
      "published_date": "2024-03-12 17:24:26 UTC",
      "updated_date": "2024-03-12 17:24:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:37:15.987839"
    },
    {
      "arxiv_id": "2403.07818v2",
      "title": "Label Dropout: Improved Deep Learning Echocardiography Segmentation Using Multiple Datasets With Domain Shift and Partial Labelling",
      "title_zh": "翻译失败",
      "authors": [
        "Iman Islam",
        "Esther Puyol-Antón",
        "Bram Ruijsink",
        "Andrew J. Reader",
        "Andrew P. King"
      ],
      "abstract": "Echocardiography (echo) is the first imaging modality used when assessing\ncardiac function. The measurement of functional biomarkers from echo relies\nupon the segmentation of cardiac structures and deep learning models have been\nproposed to automate the segmentation process. However, in order to translate\nthese tools to widespread clinical use it is important that the segmentation\nmodels are robust to a wide variety of images (e.g. acquired from different\nscanners, by operators with different levels of expertise etc.). To achieve\nthis level of robustness it is necessary that the models are trained with\nmultiple diverse datasets. A significant challenge faced when training with\nmultiple diverse datasets is the variation in label presence, i.e. the combined\ndata are often partially-labelled. Adaptations of the cross entropy loss\nfunction have been proposed to deal with partially labelled data. In this paper\nwe show that training naively with such a loss function and multiple diverse\ndatasets can lead to a form of shortcut learning, where the model associates\nlabel presence with domain characteristics, leading to a drop in performance.\nTo address this problem, we propose a novel label dropout scheme to break the\nlink between domain characteristics and the presence or absence of labels. We\ndemonstrate that label dropout improves echo segmentation Dice score by 62% and\n25% on two cardiac structures when training using multiple diverse partially\nlabelled datasets.",
      "tldr_zh": "这篇论文针对使用多个多样数据集（存在领域偏移和部分标注）训练的深度学习模型在超声心动图（Echocardiography）分割中出现的问题，指出传统交叉熵损失函数可能导致捷径学习（shortcut learning），即模型将标签存在与领域特征关联，从而降低性能。作者提出了一种新型Label Dropout方案，通过随机丢弃标签来打破这种关联，确保模型在部分标注数据上更鲁棒。实验结果显示，该方法显著提高了分割准确性，使Dice score在两个心脏结构上分别提升62%和25%。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages, 5 figures, ASMUS 2024, Held in Conjunction with MICCAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.07818v2",
      "published_date": "2024-03-12 16:57:56 UTC",
      "updated_date": "2024-08-15 11:51:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:37:26.273197"
    },
    {
      "arxiv_id": "2403.07816v1",
      "title": "Branch-Train-MiX: Mixing Expert LLMs into a Mixture-of-Experts LLM",
      "title_zh": "Branch-Train-MiX：将专家LL",
      "authors": [
        "Sainbayar Sukhbaatar",
        "Olga Golovneva",
        "Vasu Sharma",
        "Hu Xu",
        "Xi Victoria Lin",
        "Baptiste Rozière",
        "Jacob Kahn",
        "Daniel Li",
        "Wen-tau Yih",
        "Jason Weston",
        "Xian Li"
      ],
      "abstract": "We investigate efficient methods for training Large Language Models (LLMs) to\npossess capabilities in multiple specialized domains, such as coding, math\nreasoning and world knowledge. Our method, named Branch-Train-MiX (BTX), starts\nfrom a seed model, which is branched to train experts in embarrassingly\nparallel fashion with high throughput and reduced communication cost. After\nindividual experts are asynchronously trained, BTX brings together their\nfeedforward parameters as experts in Mixture-of-Expert (MoE) layers and\naverages the remaining parameters, followed by an MoE-finetuning stage to learn\ntoken-level routing. BTX generalizes two special cases, the Branch-Train-Merge\nmethod, which does not have the MoE finetuning stage to learn routing, and\nsparse upcycling, which omits the stage of training experts asynchronously.\nCompared to alternative approaches, BTX achieves the best accuracy-efficiency\ntradeoff.",
      "tldr_zh": "本研究提出了一种名为 Branch-Train-MiX (BTX) 的方法，用于高效训练 Large Language Models (LLMs)，使它们在多个专业领域（如编码、数学推理和世界知识）中具备能力。BTX 从一个种子模型开始，将其分支为多个专家模型，并行异步训练以提高吞吐量并降低通信成本；训练后，将专家的 feedforward 参数整合到 Mixture-of-Experts (MoE) 层中，并平均其他参数，随后进行 MoE 微调以学习 token-level 路由。该方法推广了 Branch-Train-Merge 和 sparse upcycling 等特例，并在准确性-效率权衡上优于其他方法。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.07816v1",
      "published_date": "2024-03-12 16:54:58 UTC",
      "updated_date": "2024-03-12 16:54:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:37:39.467054"
    },
    {
      "arxiv_id": "2403.07815v3",
      "title": "Chronos: Learning the Language of Time Series",
      "title_zh": "Chronos：学习时间序列的语言",
      "authors": [
        "Abdul Fatir Ansari",
        "Lorenzo Stella",
        "Caner Turkmen",
        "Xiyuan Zhang",
        "Pedro Mercado",
        "Huibin Shen",
        "Oleksandr Shchur",
        "Syama Sundar Rangapuram",
        "Sebastian Pineda Arango",
        "Shubham Kapoor",
        "Jasper Zschiegner",
        "Danielle C. Maddix",
        "Hao Wang",
        "Michael W. Mahoney",
        "Kari Torkkola",
        "Andrew Gordon Wilson",
        "Michael Bohlke-Schneider",
        "Yuyang Wang"
      ],
      "abstract": "We introduce Chronos, a simple yet effective framework for pretrained\nprobabilistic time series models. Chronos tokenizes time series values using\nscaling and quantization into a fixed vocabulary and trains existing\ntransformer-based language model architectures on these tokenized time series\nvia the cross-entropy loss. We pretrained Chronos models based on the T5 family\n(ranging from 20M to 710M parameters) on a large collection of publicly\navailable datasets, complemented by a synthetic dataset that we generated via\nGaussian processes to improve generalization. In a comprehensive benchmark\nconsisting of 42 datasets, and comprising both classical local models and deep\nlearning methods, we show that Chronos models: (a) significantly outperform\nother methods on datasets that were part of the training corpus; and (b) have\ncomparable and occasionally superior zero-shot performance on new datasets,\nrelative to methods that were trained specifically on them. Our results\ndemonstrate that Chronos models can leverage time series data from diverse\ndomains to improve zero-shot accuracy on unseen forecasting tasks, positioning\npretrained models as a viable tool to greatly simplify forecasting pipelines.",
      "tldr_zh": "该研究提出 Chronos 框架，这是一种简单有效的预训练概率时间序列模型，通过 scaling and quantization 将时间序列值标记化为固定词汇表，并使用基于 Transformer 的 T5 模型（如 20M 到 710M 参数）通过 cross-entropy loss 进行训练。模型在大量公开数据集和高斯过程生成的合成数据集上预训练，以提升泛化能力。在包含 42 个数据集的基准测试中，Chronos 显著优于其他方法，尤其在训练语料数据集上，同时在零样本（zero-shot）任务上与专门训练模型相当或更优，从而简化了时间序列预测管道。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Code and model checkpoints available at\n  https://github.com/amazon-science/chronos-forecasting",
      "pdf_url": "http://arxiv.org/pdf/2403.07815v3",
      "published_date": "2024-03-12 16:53:54 UTC",
      "updated_date": "2024-11-04 17:42:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:37:50.788617"
    },
    {
      "arxiv_id": "2403.07805v3",
      "title": "Beyond Memorization: The Challenge of Random Memory Access in Language Models",
      "title_zh": "超越记忆：语言模型中随机内存访问的挑战",
      "authors": [
        "Tongyao Zhu",
        "Qian Liu",
        "Liang Pang",
        "Zhengbao Jiang",
        "Min-Yen Kan",
        "Min Lin"
      ],
      "abstract": "Recent developments in Language Models (LMs) have shown their effectiveness\nin NLP tasks, particularly in knowledge-intensive tasks. However, the\nmechanisms underlying knowledge storage and memory access within their\nparameters remain elusive. In this paper, we investigate whether a generative\nLM (e.g., GPT-2) is able to access its memory sequentially or randomly. Through\ncarefully-designed synthetic tasks, covering the scenarios of full recitation,\nselective recitation and grounded question answering, we reveal that LMs manage\nto sequentially access their memory while encountering challenges in randomly\naccessing memorized content. We find that techniques including recitation and\npermutation improve the random memory access capability of LMs. Furthermore, by\napplying this intervention to realistic scenarios of open-domain question\nanswering, we validate that enhancing random access by recitation leads to\nnotable improvements in question answering. The code to reproduce our\nexperiments can be found at https://github.com/sail-sg/lm-random-memory-access.",
      "tldr_zh": "本文研究了Language Models (LMs) 在知识存储和记忆访问中的机制，焦点在于LMs（如GPT-2）是否能顺序或随机访问内存，通过合成任务（如完整背诵、选择性背诵和基于事实的问题回答）发现，LMs 擅长顺序访问但在随机访问上存在挑战。研究提出背诵和排列等技术可改善随机内存访问能力，并在实际开放域问答场景中验证了这些干预方法显著提升了问答性能。该工作为理解和优化LMs 的内存机制提供了新见解，并附带了实验代码。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "9 pages, 4 figures; accepted by ACL 2024 (oral)",
      "pdf_url": "http://arxiv.org/pdf/2403.07805v3",
      "published_date": "2024-03-12 16:42:44 UTC",
      "updated_date": "2024-07-22 15:29:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:38:02.143514"
    },
    {
      "arxiv_id": "2403.07797v1",
      "title": "Joint Selection: Adaptively Incorporating Public Information for Private Synthetic Data",
      "title_zh": "翻译失败",
      "authors": [
        "Miguel Fuentes",
        "Brett Mullins",
        "Ryan McKenna",
        "Gerome Miklau",
        "Daniel Sheldon"
      ],
      "abstract": "Mechanisms for generating differentially private synthetic data based on\nmarginals and graphical models have been successful in a wide range of\nsettings. However, one limitation of these methods is their inability to\nincorporate public data. Initializing a data generating model by pre-training\non public data has shown to improve the quality of synthetic data, but this\ntechnique is not applicable when model structure is not determined a priori. We\ndevelop the mechanism jam-pgm, which expands the adaptive measurements\nframework to jointly select between measuring public data and private data.\nThis technique allows for public data to be included in a graphical-model-based\nmechanism. We show that jam-pgm is able to outperform both publicly assisted\nand non publicly assisted synthetic data generation mechanisms even when the\npublic data distribution is biased.",
      "tldr_zh": "该论文解决了基于边际(marginals)和图形模型(graphical models)生成差分隐私(differentially private)合成数据(synthetic data)的方法无法有效整合公共数据的问题。作者开发了jam-pgm机制，通过扩展自适应测量框架(adaptive measurements framework)，实现联合选择测量公共数据和私有数据，从而允许公共数据融入图形模型-based机制中。即使公共数据分布有偏差，实验结果显示jam-pgm机制在合成数据生成质量上优于既有使用或不使用公共数据的基准方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.07797v1",
      "published_date": "2024-03-12 16:34:07 UTC",
      "updated_date": "2024-03-12 16:34:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:38:12.888987"
    },
    {
      "arxiv_id": "2403.13000v2",
      "title": "Duwak: Dual Watermarks in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Chaoyi Zhu",
        "Jeroen Galjaard",
        "Pin-Yu Chen",
        "Lydia Y. Chen"
      ],
      "abstract": "As large language models (LLM) are increasingly used for text generation\ntasks, it is critical to audit their usages, govern their applications, and\nmitigate their potential harms. Existing watermark techniques are shown\neffective in embedding single human-imperceptible and machine-detectable\npatterns without significantly affecting generated text quality and semantics.\nHowever, the efficiency in detecting watermarks, i.e., the minimum number of\ntokens required to assert detection with significance and robustness against\npost-editing, is still debatable. In this paper, we propose, Duwak, to\nfundamentally enhance the efficiency and quality of watermarking by embedding\ndual secret patterns in both token probability distribution and sampling\nschemes. To mitigate expression degradation caused by biasing toward certain\ntokens, we design a contrastive search to watermark the sampling scheme, which\nminimizes the token repetition and enhances the diversity. We theoretically\nexplain the interdependency of the two watermarks within Duwak. We evaluate\nDuwak extensively on Llama2 under various post-editing attacks, against four\nstate-of-the-art watermarking techniques and combinations of them. Our results\nshow that Duwak marked text achieves the highest watermarked text quality at\nthe lowest required token count for detection, up to 70% tokens less than\nexisting approaches, especially under post paraphrasing.",
      "tldr_zh": "本论文提出 Duwak，一种在大型语言模型(LLM)中嵌入双重水印的技术，旨在提升水印检测效率、鲁棒性和文本生成质量，同时缓解潜在风险。\nDuwak 通过在 token 概率分布和采样方案中嵌入秘密模式，并采用对比搜索方法来最小化 token 重复并增强文本多样性，同时理论上解释了两个水印的相互依赖性。\n实验在 Llama2 模型上评估显示，Duwak 标记的文本在各种后编辑攻击下需要比现有方法少达 70% 的 token 即可实现检测，且保持最高文本质量。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.13000v2",
      "published_date": "2024-03-12 16:25:38 UTC",
      "updated_date": "2024-08-08 13:33:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:38:26.686185"
    },
    {
      "arxiv_id": "2403.07788v2",
      "title": "DexCap: Scalable and Portable Mocap Data Collection System for Dexterous Manipulation",
      "title_zh": "翻译失败",
      "authors": [
        "Chen Wang",
        "Haochen Shi",
        "Weizhuo Wang",
        "Ruohan Zhang",
        "Li Fei-Fei",
        "C. Karen Liu"
      ],
      "abstract": "Imitation learning from human hand motion data presents a promising avenue\nfor imbuing robots with human-like dexterity in real-world manipulation tasks.\nDespite this potential, substantial challenges persist, particularly with the\nportability of existing hand motion capture (mocap) systems and the complexity\nof translating mocap data into effective robotic policies. To tackle these\nissues, we introduce DexCap, a portable hand motion capture system, alongside\nDexIL, a novel imitation algorithm for training dexterous robot skills directly\nfrom human hand mocap data. DexCap offers precise, occlusion-resistant tracking\nof wrist and finger motions based on SLAM and electromagnetic field together\nwith 3D observations of the environment. Utilizing this rich dataset, DexIL\nemploys inverse kinematics and point cloud-based imitation learning to\nseamlessly replicate human actions with robot hands. Beyond direct learning\nfrom human motion, DexCap also offers an optional human-in-the-loop correction\nmechanism during policy rollouts to refine and further improve task\nperformance. Through extensive evaluation across six challenging dexterous\nmanipulation tasks, our approach not only demonstrates superior performance but\nalso showcases the system's capability to effectively learn from in-the-wild\nmocap data, paving the way for future data collection methods in the pursuit of\nhuman-level robot dexterity. More details can be found at\nhttps://dex-cap.github.io",
      "tldr_zh": "该论文介绍了 DexCap，一种可扩展且便携的 mocap 数据收集系统，旨在解决从人类手部动作数据中进行 imitation learning 的便携性和数据转换挑战。DexCap 通过 SLAM 和电磁场技术实现对手腕和手指动作的精确、抵抗遮挡追踪，并结合环境的 3D 观察；同时，DexIL 算法利用逆运动学和 point cloud-based 模仿学习，直接从人类 mocap 数据训练机器人技能，并提供可选的人在循环中的修正机制以优化性能。在六个挑战性的灵巧操作任务中，系统表现出色，能够有效从野外数据中学习，推动机器人实现人类级别的灵巧性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.07788v2",
      "published_date": "2024-03-12 16:23:49 UTC",
      "updated_date": "2024-07-04 04:35:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:38:38.658210"
    },
    {
      "arxiv_id": "2403.07769v3",
      "title": "Transforming Competition into Collaboration: The Revolutionary Role of Multi-Agent Systems and Language Models in Modern Organizations",
      "title_zh": "翻译失败",
      "authors": [
        "Carlos Jose Xavier Cruz"
      ],
      "abstract": "This article explores the dynamic influence of computational entities based\non multi-agent systems theory (SMA) combined with large language models (LLM),\nwhich are characterized by their ability to simulate complex human\ninteractions, as a possibility to revolutionize human user interaction from the\nuse of specialized artificial agents to support everything from operational\norganizational processes to strategic decision making based on applied\nknowledge and human orchestration. Previous investigations reveal that there\nare limitations, particularly in the autonomous approach of artificial agents,\nespecially when dealing with new challenges and pragmatic tasks such as\ninducing logical reasoning and problem solving. It is also considered that\ntraditional techniques, such as the stimulation of chains of thoughts, require\nexplicit human guidance. In our approach we employ agents developed from large\nlanguage models (LLM), each with distinct prototyping that considers behavioral\nelements, driven by strategies that stimulate the generation of knowledge based\non the use case proposed in the scenario (role-play) business, using a\ndiscussion approach between agents (guided conversation). We demonstrate the\npotential of developing agents useful for organizational strategies, based on\nmulti-agent system theories (SMA) and innovative uses based on large language\nmodels (LLM based), offering a differentiated and adaptable experiment to\ndifferent applications, complexities, domains, and capabilities from LLM.",
      "tldr_zh": "本文探讨了多智能体系统(SMA)与大型语言模型(LLM)的结合，如何将竞争转化为合作，革命性地提升组织从操作流程到战略决策的人机互动。该方法解决了传统代理的局限性，如自主性不足和对逻辑推理的依赖于人工指导，通过开发基于LLM的代理进行角色扮演和代理间引导对话来生成知识。相比传统技术如Chain-of-Thought，该框架无需显式人类干预，并展示了其在不同应用、复杂度和领域的适应性潜力，为现代组织提供更高效的知识驱动策略。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CY",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.07769v3",
      "published_date": "2024-03-12 15:56:10 UTC",
      "updated_date": "2024-03-15 11:44:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:38:49.875843"
    },
    {
      "arxiv_id": "2403.07750v2",
      "title": "Synth$^2$: Boosting Visual-Language Models with Synthetic Captions and Image Embeddings",
      "title_zh": "翻译失败",
      "authors": [
        "Sahand Sharifzadeh",
        "Christos Kaplanis",
        "Shreya Pathak",
        "Dharshan Kumaran",
        "Anastasija Ilic",
        "Jovana Mitrovic",
        "Charles Blundell",
        "Andrea Banino"
      ],
      "abstract": "The creation of high-quality human-labeled image-caption datasets presents a\nsignificant bottleneck in the development of Visual-Language Models (VLMs). In\nthis work, we investigate an approach that leverages the strengths of Large\nLanguage Models (LLMs) and image generation models to create synthetic\nimage-text pairs for efficient and effective VLM training. Our method employs a\npretrained text-to-image model to synthesize image embeddings from captions\ngenerated by an LLM. Despite the text-to-image model and VLM initially being\ntrained on the same data, our approach leverages the image generator's ability\nto create novel compositions, resulting in synthetic image embeddings that\nexpand beyond the limitations of the original dataset. Extensive experiments\ndemonstrate that our VLM, finetuned on synthetic data achieves comparable\nperformance to models trained solely on human-annotated data, while requiring\nsignificantly less data. Furthermore, we perform a set of analyses on captions\nwhich reveals that semantic diversity and balance are key aspects for better\ndownstream performance. Finally, we show that synthesizing images in the image\nembedding space is 25\\% faster than in the pixel space. We believe our work not\nonly addresses a significant challenge in VLM training but also opens up\npromising avenues for the development of self-improving multi-modal models.",
      "tldr_zh": "该论文提出了一种名为 Synth² 的方法，利用 Large Language Models (LLMs) 生成合成标题，并通过预训练的文本到图像模型合成图像 embeddings，以提升 Visual-Language Models (VLMs) 的训练效率。该方法利用图像生成器的创新组合能力，扩展了原数据集的限制，使合成数据在性能上可与人类标注数据媲美，同时显著减少所需数据量。实验结果显示，语义多样性和平衡是提升下游任务性能的关键因素，且在图像 embedding 空间合成图像比像素空间快 25%。这项工作解决了 VLM 训练中的数据瓶颈，并为自提升多模态模型的发展开辟了新路径。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "9 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.07750v2",
      "published_date": "2024-03-12 15:36:42 UTC",
      "updated_date": "2024-06-07 12:10:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:39:03.206805"
    },
    {
      "arxiv_id": "2403.07748v2",
      "title": "Ariadne and Theseus: Exploration and Rendezvous with Two Mobile Agents in an Unknown Graph",
      "title_zh": "翻译失败",
      "authors": [
        "Romain Cosson"
      ],
      "abstract": "We investigate two fundamental problems in mobile computing: exploration and\nrendezvous, with two distinct mobile agents in an unknown graph. The agents may\ncommunicate by reading and writing information on whiteboards that are located\nat all nodes. They both move along one adjacent edge at every time-step. In the\nexploration problem, the agents start from the same arbitrary node and must\ntraverse all the edges. We present an algorithm achieving collective\nexploration in $m$ time-steps, where $m$ is the number of edges of the graph.\nThis improves over the guarantee of depth-first search, which requires $2m$\ntime-steps. In the rendezvous problem, the agents start from different nodes of\nthe graph and must meet as fast as possible. We present an algorithm\nguaranteeing rendezvous in at most $\\frac{3}{2}m$ time-steps. This improves\nover the so-called `wait for Mommy' algorithm which is based on depth-first\nsearch and which also requires $2m$ time-steps. Importantly, all our guarantees\nare derived from a more general asynchronous setting in which the speeds of the\nagents are controlled by an adversary at all times. Our guarantees generalize\nto weighted graphs, when replacing the number of edges $m$ with the sum of all\nedge lengths. We show that our guarantees are met with matching lower-bounds in\nthe asynchronous setting.",
      "tldr_zh": "这篇论文研究了两个mobile agents在unknown graph中进行的exploration（探索）和rendezvous（会合）问题，代理通过节点上的whiteboards进行通信，并在每个时间步沿一条相邻边移动。针对exploration问题，论文提出了一种算法，使两个代理从同一节点出发在m个时间步内遍历所有边，优于depth-first search的2m时间步。针对rendezvous问题，该算法确保代理从不同节点开始在最多1.5m时间步内会合，改善了基于depth-first search的'wait for Mommy'算法的2m时间步需求。这些保证基于asynchronous setting（异步设置），并扩展到weighted graphs（加权图），与相应的lower-bounds（下界）相匹配。",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.07748v2",
      "published_date": "2024-03-12 15:33:09 UTC",
      "updated_date": "2024-07-04 15:40:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:39:16.946255"
    },
    {
      "arxiv_id": "2403.07747v2",
      "title": "FineMath: A Fine-Grained Mathematical Evaluation Benchmark for Chinese Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yan Liu",
        "Renren Jin",
        "Ling Shi",
        "Zheng Yao",
        "Deyi Xiong"
      ],
      "abstract": "To thoroughly assess the mathematical reasoning abilities of Large Language\nModels (LLMs), we need to carefully curate evaluation datasets covering diverse\nmathematical concepts and mathematical problems at different difficulty levels.\nIn pursuit of this objective, we propose FineMath in this paper, a fine-grained\nmathematical evaluation benchmark dataset for assessing Chinese LLMs. FineMath\nis created to cover the major key mathematical concepts taught in elementary\nschool math, which are further divided into 17 categories of math word\nproblems, enabling in-depth analysis of mathematical reasoning abilities of\nLLMs. All the 17 categories of math word problems are manually annotated with\ntheir difficulty levels according to the number of reasoning steps required to\nsolve these problems. We conduct extensive experiments on a wide range of LLMs\non FineMath and find that there is still considerable room for improvements in\nterms of mathematical reasoning capability of Chinese LLMs. We also carry out\nan in-depth analysis on the evaluation process and methods that have been\noverlooked previously. These two factors significantly influence the model\nresults and our understanding of their mathematical reasoning capabilities. The\ndataset will be publicly available soon.",
      "tldr_zh": "本文提出 FineMath，这是一个细粒度的数学评估基准数据集，旨在评估中文 Large Language Models (LLMs) 的数学推理能力。FineMath 覆盖小学数学的主要概念，分为 17 类数学文字问题，并根据解决问题的推理步骤手动标注难度水平，以支持深入分析。实验结果显示，中文 LLMs 在数学推理方面仍有较大改进空间，同时强调评估过程和方法对模型性能和理解的影响。该数据集即将公开可用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.07747v2",
      "published_date": "2024-03-12 15:32:39 UTC",
      "updated_date": "2024-09-06 10:19:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:39:25.907767"
    },
    {
      "arxiv_id": "2403.07745v1",
      "title": "Probabilistic Easy Variational Causal Effect",
      "title_zh": "翻译失败",
      "authors": [
        "Usef Faghihi",
        "Amir Saki"
      ],
      "abstract": "Let $X$ and $Z$ be random vectors, and $Y=g(X,Z)$. In this paper, on the one\nhand, for the case that $X$ and $Z$ are continuous, by using the ideas from the\ntotal variation and the flux of $g$, we develop a point of view in causal\ninference capable of dealing with a broad domain of causal problems. Indeed, we\nfocus on a function, called Probabilistic Easy Variational Causal Effect\n(PEACE), which can measure the direct causal effect of $X$ on $Y$ with respect\nto continuously and interventionally changing the values of $X$ while keeping\nthe value of $Z$ constant. PEACE is a function of $d\\ge 0$, which is a degree\nmanaging the strengths of probability density values $f(x|z)$. On the other\nhand, we generalize the above idea for the discrete case and show its\ncompatibility with the continuous case. Further, we investigate some properties\nof PEACE using measure theoretical concepts. Furthermore, we provide some\nidentifiability criteria and several examples showing the generic capability of\nPEACE. We note that PEACE can deal with the causal problems for which\nmicro-level or just macro-level changes in the value of the input variables are\nimportant. Finally, PEACE is stable under small changes in $\\partial\ng_{in}/\\partial x$ and the joint distribution of $X$ and $Z$, where $g_{in}$ is\nobtained from $g$ by removing all functional relationships defining $X$ and\n$Z$.",
      "tldr_zh": "本文提出了一种名为 Probabilistic Easy Variational Causal Effect (PEACE) 的函数，用于量化变量 X 对 Y 的直接因果效应，其中 Y = g(X, Z)。通过借鉴 total variation 和 g 的 flux 概念，PEACE 可以处理连续变量的情景，并通过干预性改变 X 的值来测量其影响，同时保持 Z 常量；它还扩展到离散变量，并证明了其兼容性。论文探讨了 PEACE 的测度理论属性、可识别性标准，并展示了其在处理微观或宏观级别的因果问题时的稳定性和通用能力，例如在 g_in 的偏导数和小分布变化下保持鲁棒性。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG",
        "26A45, 6008, 68T37, 68T20, 68T27, 68U99, 46N30, 62R10",
        "G.3; I.2.3"
      ],
      "primary_category": "stat.ML",
      "comment": "45 pages, 9 Figures",
      "pdf_url": "http://arxiv.org/pdf/2403.07745v1",
      "published_date": "2024-03-12 15:28:21 UTC",
      "updated_date": "2024-03-12 15:28:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:39:40.139545"
    },
    {
      "arxiv_id": "2403.07743v3",
      "title": "Equipping Computational Pathology Systems with Artifact Processing Pipelines: A Showcase for Computation and Performance Trade-offs",
      "title_zh": "为计算病理学系统配备工件处理管道：计算和性能权衡的展示案例",
      "authors": [
        "Neel Kanwal",
        "Farbod Khoraminia",
        "Umay Kiraz",
        "Andres Mosquera-Zamudio",
        "Carlos Monteagudo",
        "Emiel A. M. Janssen",
        "Tahlita C. M. Zuiverloon",
        "Chunmig Rong",
        "Kjersti Engan"
      ],
      "abstract": "Histopathology is a gold standard for cancer diagnosis under a microscopic\nexamination. However, histological tissue processing procedures result in\nartifacts, which are ultimately transferred to the digitized version of glass\nslides, known as whole slide images (WSIs). Artifacts are diagnostically\nirrelevant areas and may result in wrong deep learning (DL) algorithms\npredictions. Therefore, detecting and excluding artifacts in the computational\npathology (CPATH) system is essential for reliable automated diagnosis. In this\npaper, we propose a mixture of experts (MoE) scheme for detecting five notable\nartifacts, including damaged tissue, blur, folded tissue, air bubbles, and\nhistologically irrelevant blood from WSIs. First, we train independent binary\nDL models as experts to capture particular artifact morphology. Then, we\nensemble their predictions using a fusion mechanism. We apply probabilistic\nthresholding over the final probability distribution to improve the sensitivity\nof the MoE. We developed DL pipelines using two MoEs and two multiclass models\nof state-of-the-art deep convolutional neural networks (DCNNs) and vision\ntransformers (ViTs). DCNNs-based MoE and ViTs-based MoE schemes outperformed\nsimpler multiclass models and were tested on datasets from different hospitals\nand cancer types, where MoE using DCNNs yielded the best results. The proposed\nMoE yields 86.15% F1 and 97.93% sensitivity scores on unseen data, retaining\nless computational cost for inference than MoE using ViTs. This best\nperformance of MoEs comes with relatively higher computational trade-offs than\nmulticlass models. The proposed artifact detection pipeline will not only\nensure reliable CPATH predictions but may also provide quality control.",
      "tldr_zh": "本研究针对组织病理学中，处理过程中产生的 artifacts（如损坏组织、模糊等）可能导致深度学习（DL）算法预测错误的问题，提出了一种 Mixture of Experts (MoE) 方案，用于检测五种常见 artifacts 于 whole slide images (WSIs)。该方案通过训练独立的二元 DL 模型作为专家，并使用融合机制和概率阈值整合预测，开发了基于 deep convolutional neural networks (DCNNs) 和 vision transformers (ViTs) 的 MoE 管道。实验结果显示，DCNNs-based MoE 在不同医院和癌症类型的数据上表现出色，达到 86.15% F1 分数和 97.93% 敏感性，同时比多类模型更可靠，但伴随较高的计算权衡。该方法不仅提升了 computational pathology (CPATH) 系统的预测准确性，还为质量控制提供了新途径。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "Submitted to BMC Medical Informatics and Decision Making Journal",
      "pdf_url": "http://arxiv.org/pdf/2403.07743v3",
      "published_date": "2024-03-12 15:22:05 UTC",
      "updated_date": "2024-05-23 09:10:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:39:52.102709"
    },
    {
      "arxiv_id": "2403.07741v2",
      "title": "Uncertainty Quantification with Deep Ensembles for 6D Object Pose Estimation",
      "title_zh": "翻译失败",
      "authors": [
        "Kira Wursthorn",
        "Markus Hillemann",
        "Markus Ulrich"
      ],
      "abstract": "The estimation of 6D object poses is a fundamental task in many computer\nvision applications. Particularly, in high risk scenarios such as human-robot\ninteraction, industrial inspection, and automation, reliable pose estimates are\ncrucial. In the last years, increasingly accurate and robust\ndeep-learning-based approaches for 6D object pose estimation have been\nproposed. Many top-performing methods are not end-to-end trainable but consist\nof multiple stages. In the context of deep uncertainty quantification, deep\nensembles are considered as state of the art since they have been proven to\nproduce well-calibrated and robust uncertainty estimates. However, deep\nensembles can only be applied to methods that can be trained end-to-end. In\nthis work, we propose a method to quantify the uncertainty of multi-stage 6D\nobject pose estimation approaches with deep ensembles. For the implementation,\nwe choose SurfEmb as representative, since it is one of the top-performing 6D\nobject pose estimation approaches in the BOP Challenge 2022. We apply\nestablished metrics and concepts for deep uncertainty quantification to\nevaluate the results. Furthermore, we propose a novel uncertainty calibration\nscore for regression tasks to quantify the quality of the estimated\nuncertainty.",
      "tldr_zh": "这篇论文针对6D object pose estimation的不确定性量化问题，提出了一种使用deep ensembles的方法，以提升高风险应用（如人机交互和工业自动化）中的姿态估计可靠性和校准。作者扩展了deep ensembles到多阶段方法上，以SurfEmb（BOP Challenge 2022中的顶级方法）作为代表，实现端到端的训练和不确定性评估。论文应用了现有的deep uncertainty quantification指标，并引入了一个新颖的uncertainty calibration score，用于量化回归任务中不确定性估计的质量，从而为更鲁棒的物体姿态估计提供基础。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "8 pages",
      "pdf_url": "http://arxiv.org/pdf/2403.07741v2",
      "published_date": "2024-03-12 15:19:25 UTC",
      "updated_date": "2024-05-02 09:00:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:40:03.864026"
    },
    {
      "arxiv_id": "2403.07733v4",
      "title": "Beyond Pixels: Enhancing LIME with Hierarchical Features and Segmentation Foundation Models",
      "title_zh": "翻译失败",
      "authors": [
        "Patrick Knab",
        "Sascha Marton",
        "Christian Bartelt"
      ],
      "abstract": "LIME (Local Interpretable Model-agnostic Explanations) is a popular XAI\nframework for unraveling decision-making processes in vision machine-learning\nmodels. The technique utilizes image segmentation methods to identify fixed\nregions for calculating feature importance scores as explanations. Therefore,\npoor segmentation can weaken the explanation and reduce the importance of\nsegments, ultimately affecting the overall clarity of interpretation. To\naddress these challenges, we introduce the DSEG-LIME (Data-Driven Segmentation\nLIME) framework, featuring: i) a data-driven segmentation for human-recognized\nfeature generation by foundation model integration, and ii) a user-steered\ngranularity in the hierarchical segmentation procedure through composition. Our\nfindings demonstrate that DSEG outperforms on several XAI metrics on\npre-trained ImageNet models and improves the alignment of explanations with\nhuman-recognized concepts. The code is available under: https://github.\ncom/patrick-knab/DSEG-LIME",
      "tldr_zh": "该研究针对LIME（Local Interpretable Model-agnostic Explanations）框架在视觉机器学习模型解释中的问题，即图像分割不佳导致解释模糊和特征重要性降低，提出了DSEG-LIME框架。DSEG-LIME通过整合foundation models实现基于数据的分割，生成人类可识别的特征，并支持用户导向的层次化分割粒度调整，以提升解释的准确性和清晰度。实验结果显示，DSEG-LIME在多个XAI指标上优于预训练的ImageNet模型，并显著提高了解释与人类概念的对齐度。代码已在GitHub上开源。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.07733v4",
      "published_date": "2024-03-12 15:13:12 UTC",
      "updated_date": "2025-02-03 10:44:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:40:14.707925"
    },
    {
      "arxiv_id": "2403.07724v1",
      "title": "Balancing Fairness and Accuracy in Data-Restricted Binary Classification",
      "title_zh": "在数据受限的二元分类中平衡公平性和准确性",
      "authors": [
        "Zachary McBride Lazri",
        "Danial Dervovic",
        "Antigoni Polychroniadou",
        "Ivan Brugere",
        "Dana Dachman-Soled",
        "Min Wu"
      ],
      "abstract": "Applications that deal with sensitive information may have restrictions\nplaced on the data available to a machine learning (ML) classifier. For\nexample, in some applications, a classifier may not have direct access to\nsensitive attributes, affecting its ability to produce accurate and fair\ndecisions. This paper proposes a framework that models the trade-off between\naccuracy and fairness under four practical scenarios that dictate the type of\ndata available for analysis. Prior works examine this trade-off by analyzing\nthe outputs of a scoring function that has been trained to implicitly learn the\nunderlying distribution of the feature vector, class label, and sensitive\nattribute of a dataset. In contrast, our framework directly analyzes the\nbehavior of the optimal Bayesian classifier on this underlying distribution by\nconstructing a discrete approximation it from the dataset itself. This approach\nenables us to formulate multiple convex optimization problems, which allow us\nto answer the question: How is the accuracy of a Bayesian classifier affected\nin different data restricting scenarios when constrained to be fair? Analysis\nis performed on a set of fairness definitions that include group and individual\nfairness. Experiments on three datasets demonstrate the utility of the proposed\nframework as a tool for quantifying the trade-offs among different fairness\nnotions and their distributional dependencies.",
      "tldr_zh": "这篇论文提出一个框架，用于在数据受限的二元分类中平衡准确性和公平性，针对四种实际场景，其中分类器可能无法访问敏感属性。框架通过直接分析最优Bayesian classifier在底层分布上的行为，并构建数据集的离散近似，形式化为多个凸优化问题，以量化公平性约束对准确性的影响。实验在三个数据集上验证了该框架的效用，展示了group fairness和individual fairness等公平定义之间的权衡及其分布依赖。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.07724v1",
      "published_date": "2024-03-12 15:01:27 UTC",
      "updated_date": "2024-03-12 15:01:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:40:27.108533"
    },
    {
      "arxiv_id": "2403.07720v2",
      "title": "Multi-modal Auto-regressive Modeling via Visual Words",
      "title_zh": "翻译失败",
      "authors": [
        "Tianshuo Peng",
        "Zuchao Li",
        "Lefei Zhang",
        "Hai Zhao",
        "Ping Wang",
        "Bo Du"
      ],
      "abstract": "Large Language Models (LLMs), benefiting from the auto-regressive modelling\napproach performed on massive unannotated texts corpora, demonstrates powerful\nperceptual and reasoning capabilities. However, as for extending\nauto-regressive modelling to multi-modal scenarios to build Large Multi-modal\nModels (LMMs), there lies a great difficulty that the image information is\nprocessed in the LMM as continuous visual embeddings, which cannot obtain\ndiscrete supervised labels for classification.In this paper, we successfully\nperform multi-modal auto-regressive modeling with a unified objective for the\nfirst time.Specifically, we propose the concept of visual tokens, which maps\nthe visual features to probability distributions over LLM's vocabulary,\nproviding supervision information for visual modelling.We further explore the\ndistribution of visual features in the semantic space within LMM and the\npossibility of using text embeddings to represent visual\ninformation.Experimental results and ablation studies on 5 VQA tasks and 4\nbenchmark toolkits validate the powerful performance of our proposed approach.",
      "tldr_zh": "这篇论文提出了通过“visual tokens”实现多模态自回归建模的方法，旨在解决 Large Multi-modal Models (LMMs) 中图像信息作为连续视觉嵌入难以获得离散监督标签的问题。论文首次实现了统一的 multi-modal auto-regressive modeling，将视觉特征映射到 Large Language Models (LLMs) 词汇表的概率分布，提供有效的监督信息，并探索了使用文本嵌入表示视觉信息的可能性。在5个 Visual Question Answering (VQA) 任务和4个基准工具包上的实验结果验证了该方法的强大性能，展示了其在提升多模态感知和推理能力方面的优势。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "ACM MM 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.07720v2",
      "published_date": "2024-03-12 14:58:52 UTC",
      "updated_date": "2024-09-23 08:51:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:40:39.402627"
    },
    {
      "arxiv_id": "2403.07718v5",
      "title": "WorkArena: How Capable Are Web Agents at Solving Common Knowledge Work Tasks?",
      "title_zh": "翻译失败",
      "authors": [
        "Alexandre Drouin",
        "Maxime Gasse",
        "Massimo Caccia",
        "Issam H. Laradji",
        "Manuel Del Verme",
        "Tom Marty",
        "Léo Boisvert",
        "Megh Thakkar",
        "Quentin Cappart",
        "David Vazquez",
        "Nicolas Chapados",
        "Alexandre Lacoste"
      ],
      "abstract": "We study the use of large language model-based agents for interacting with\nsoftware via web browsers. Unlike prior work, we focus on measuring the agents'\nability to perform tasks that span the typical daily work of knowledge workers\nutilizing enterprise software systems. To this end, we propose WorkArena, a\nremote-hosted benchmark of 33 tasks based on the widely-used ServiceNow\nplatform. We also introduce BrowserGym, an environment for the design and\nevaluation of such agents, offering a rich set of actions as well as multimodal\nobservations. Our empirical evaluation reveals that while current agents show\npromise on WorkArena, there remains a considerable gap towards achieving full\ntask automation. Notably, our analysis uncovers a significant performance\ndisparity between open and closed-source LLMs, highlighting a critical area for\nfuture exploration and development in the field.",
      "tldr_zh": "本研究评估了基于大型语言模型(LLMs)的网络代理在处理知识工作者日常任务（如企业软件交互）方面的能力。研究者提出WorkArena基准，这是一个基于ServiceNow平台的远程托管环境，包含33个任务，并引入BrowserGym环境，提供丰富的动作和多模态观察以设计和评估代理。实验结果显示，当前代理在WorkArena上显示出潜力，但仍存在显著差距，无法实现完全任务自动化；同时，开源和闭源LLMs在性能上存在明显差异，这为未来发展指出了关键方向。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "21 pages, 11 figures, preprint",
      "pdf_url": "http://arxiv.org/pdf/2403.07718v5",
      "published_date": "2024-03-12 14:58:45 UTC",
      "updated_date": "2024-07-23 06:19:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:40:50.742950"
    },
    {
      "arxiv_id": "2403.07969v2",
      "title": "KnowCoder: Coding Structured Knowledge into LLMs for Universal Information Extraction",
      "title_zh": "翻译失败",
      "authors": [
        "Zixuan Li",
        "Yutao Zeng",
        "Yuxin Zuo",
        "Weicheng Ren",
        "Wenxuan Liu",
        "Miao Su",
        "Yucan Guo",
        "Yantao Liu",
        "Xiang Li",
        "Zhilei Hu",
        "Long Bai",
        "Wei Li",
        "Yidan Liu",
        "Pan Yang",
        "Xiaolong Jin",
        "Jiafeng Guo",
        "Xueqi Cheng"
      ],
      "abstract": "In this paper, we propose KnowCoder, a Large Language Model (LLM) to conduct\nUniversal Information Extraction (UIE) via code generation. KnowCoder aims to\ndevelop a kind of unified schema representation that LLMs can easily understand\nand an effective learning framework that encourages LLMs to follow schemas and\nextract structured knowledge accurately. To achieve these, KnowCoder introduces\na code-style schema representation method to uniformly transform different\nschemas into Python classes, with which complex schema information, such as\nconstraints among tasks in UIE, can be captured in an LLM-friendly manner. We\nfurther construct a code-style schema library covering over $\\textbf{30,000}$\ntypes of knowledge, which is the largest one for UIE, to the best of our\nknowledge. To ease the learning process of LLMs, KnowCoder contains a two-phase\nlearning framework that enhances its schema understanding ability via code\npretraining and its schema following ability via instruction tuning. After code\npretraining on around $1.5$B automatically constructed data, KnowCoder already\nattains remarkable generalization ability and achieves relative improvements by\n$\\textbf{49.8%}$ F1, compared to LLaMA2, under the few-shot setting. After\ninstruction tuning, KnowCoder further exhibits strong generalization ability on\nunseen schemas and achieves up to $\\textbf{12.5%}$ and $\\textbf{21.9%}$,\ncompared to sota baselines, under the zero-shot setting and the low resource\nsetting, respectively. Additionally, based on our unified schema\nrepresentations, various human-annotated datasets can simultaneously be\nutilized to refine KnowCoder, which achieves significant improvements up to\n$\\textbf{7.5%}$ under the supervised setting.",
      "tldr_zh": "本研究提出KnowCoder，一种将结构化知识编码到大语言模型(LLMs)中的框架，用于实现通用信息提取(UIE)，通过代码生成统一schema表示，将不同schema转化为Python classes，从而便于LLMs理解复杂任务约束，并构建了覆盖超过30,000种知识类型的最大schema库。KnowCoder采用两阶段学习框架，包括代码预训练以提升schema理解能力，以及指令微调以增强schema遵循能力。实验结果显示，在少样本设置下，KnowCoder较LLaMA2提升49.8% F1分数；在零样本和低资源设置下，分别比最先进基线提升12.5%和21.9%；在监督设置下，通过多数据集微调，实现高达7.5%的性能改进。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.07969v2",
      "published_date": "2024-03-12 14:56:34 UTC",
      "updated_date": "2024-03-14 02:47:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:41:04.835850"
    },
    {
      "arxiv_id": "2403.07711v4",
      "title": "SSM Meets Video Diffusion Models: Efficient Long-Term Video Generation with Structured State Spaces",
      "title_zh": "翻译失败",
      "authors": [
        "Yuta Oshima",
        "Shohei Taniguchi",
        "Masahiro Suzuki",
        "Yutaka Matsuo"
      ],
      "abstract": "Given the remarkable achievements in image generation through diffusion\nmodels, the research community has shown increasing interest in extending these\nmodels to video generation. Recent diffusion models for video generation have\npredominantly utilized attention layers to extract temporal features. However,\nattention layers are limited by their computational costs, which increase\nquadratically with the sequence length. This limitation presents significant\nchallenges when generating longer video sequences using diffusion models. To\novercome this challenge, we propose leveraging state-space models (SSMs) as\ntemporal feature extractors. SSMs (e.g., Mamba) have recently gained attention\nas promising alternatives due to their linear-time memory consumption relative\nto sequence length. In line with previous research suggesting that using\nbidirectional SSMs is effective for understanding spatial features in image\ngeneration, we found that bidirectionality is also beneficial for capturing\ntemporal features in video data, rather than relying on traditional\nunidirectional SSMs. We conducted comprehensive evaluations on multiple\nlong-term video datasets, such as MineRL Navigate, across various model sizes.\nFor sequences up to 256 frames, SSM-based models require less memory to achieve\nthe same FVD as attention-based models. Moreover, SSM-based models often\ndeliver better performance with comparable GPU memory usage. Our codes are\navailable at https://github.com/shim0114/SSM-Meets-Video-Diffusion-Models.",
      "tldr_zh": "该研究探讨了如何将扩散模型应用于视频生成，指出传统使用注意力层提取时间特征的方法计算成本随序列长度平方增长，导致生成长视频效率低下。为解决此问题，作者提出使用状态空间模型(SSMs)，如 Mamba，作为时间特征提取器，利用其线性时间复杂度，并发现双向 SSMs 在捕获视频时间特征上更有效。实验在多个长视频数据集（如 MineRL Navigate）上评估显示，SSMs-based 模型在生成高达 256 帧的序列时，使用更少内存即可达到与注意力模型相同的 FVD 指标，并在相同 GPU 内存下表现出色，从而提升了视频生成的效率和性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted as a workshop paper at ICLR 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.07711v4",
      "published_date": "2024-03-12 14:53:56 UTC",
      "updated_date": "2024-09-03 09:24:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:41:15.778711"
    },
    {
      "arxiv_id": "2403.07708v2",
      "title": "Improving Reinforcement Learning from Human Feedback Using Contrastive Rewards",
      "title_zh": "使用对比奖励改进基于人类反馈的强化学习",
      "authors": [
        "Wei Shen",
        "Xiaoying Zhang",
        "Yuanshun Yao",
        "Rui Zheng",
        "Hongyi Guo",
        "Yang Liu"
      ],
      "abstract": "Reinforcement learning from human feedback (RLHF) is the mainstream paradigm\nused to align large language models (LLMs) with human preferences. Yet existing\nRLHF heavily relies on accurate and informative reward models, which are\nvulnerable and sensitive to noise from various sources, e.g. human labeling\nerrors, making the pipeline fragile. In this work, we improve the effectiveness\nof the reward model by introducing a penalty term on the reward, named as\n\\textit{contrastive rewards}. %Contrastive rewards Our approach involves two\nsteps: (1) an offline sampling step to obtain responses to prompts that serve\nas baseline calculation and (2) a contrastive reward calculated using the\nbaseline responses and used in the Proximal Policy Optimization (PPO) step. We\nshow that contrastive rewards enable the LLM to penalize reward uncertainty,\nimprove robustness, encourage improvement over baselines, calibrate according\nto task difficulty, and reduce variance in PPO. We show empirically contrastive\nrewards can improve RLHF substantially, evaluated by both GPTs and humans, and\nour method consistently outperforms strong baselines.",
      "tldr_zh": "这篇论文针对强化学习从人类反馈（RLHF）中奖励模型易受噪音（如人类标注错误）影响的问题，提出了一种改进方法，使用 contrastive rewards 作为惩罚项来提升模型鲁棒性。该方法包括离线采样步骤获取基线响应，并在 Proximal Policy Optimization (PPO) 中应用 contrastive rewards，以减少奖励不确定性、鼓励相对于基线的改进，并降低方差。实验结果表明，这种方法显著提升了 LLMs 与人类偏好的对齐效果，通过 GPTs 和人类评估，性能优于现有基线。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.07708v2",
      "published_date": "2024-03-12 14:51:57 UTC",
      "updated_date": "2024-03-14 02:02:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:41:28.115817"
    },
    {
      "arxiv_id": "2403.07704v1",
      "title": "Symmetric Q-learning: Reducing Skewness of Bellman Error in Online Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Motoki Omura",
        "Takayuki Osa",
        "Yusuke Mukuta",
        "Tatsuya Harada"
      ],
      "abstract": "In deep reinforcement learning, estimating the value function to evaluate the\nquality of states and actions is essential. The value function is often trained\nusing the least squares method, which implicitly assumes a Gaussian error\ndistribution. However, a recent study suggested that the error distribution for\ntraining the value function is often skewed because of the properties of the\nBellman operator, and violates the implicit assumption of normal error\ndistribution in the least squares method. To address this, we proposed a method\ncalled Symmetric Q-learning, in which the synthetic noise generated from a\nzero-mean distribution is added to the target values to generate a Gaussian\nerror distribution. We evaluated the proposed method on continuous control\nbenchmark tasks in MuJoCo. It improved the sample efficiency of a\nstate-of-the-art reinforcement learning method by reducing the skewness of the\nerror distribution.",
      "tldr_zh": "本研究针对深度强化学习中价值函数训练的问题，指出Bellman Error的偏斜分布违反了最小二乘法的高斯错误假设，导致训练效率低下。作者提出Symmetric Q-learning方法，通过向目标值添加零均值分布的合成噪声，生成更接近高斯分布的错误分布，从而减少偏斜。实验在MuJoCo的连续控制基准任务上显示，该方法显著提高了最先进强化学习算法的样本效率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at AAAI 2024: The 38th Annual AAAI Conference on Artificial\n  Intelligence (Main Tech Track)",
      "pdf_url": "http://arxiv.org/pdf/2403.07704v1",
      "published_date": "2024-03-12 14:49:19 UTC",
      "updated_date": "2024-03-12 14:49:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:41:38.513815"
    },
    {
      "arxiv_id": "2403.07693v2",
      "title": "Large, Small or Both: A Novel Data Augmentation Framework Based on Language Models for Debiasing Opinion Summarization",
      "title_zh": "翻译失败",
      "authors": [
        "Yanyue Zhang",
        "Pengfei Li",
        "Yilong Lai",
        "Deyu Zhou",
        "Yulan He"
      ],
      "abstract": "As more than 70$\\%$ of reviews in the existing opinion summary data set are\npositive, current opinion summarization approaches are reluctant to generate\nnegative summaries given the input of negative texts. To address such sentiment\nbias, a direct approach without the over-reliance on a specific framework is to\ngenerate additional data based on large language models to balance the\nemotional distribution of the dataset. However, data augmentation based on\nlarge language models faces two disadvantages: 1) the potential issues or\ntoxicity in the augmented data; 2) the expensive costs. Therefore, in this\npaper, we propose a novel data augmentation framework based on both large and\nsmall language models for debiasing opinion summarization. In specific, a small\nsize of synthesized negative reviews is obtained by rewriting the positive text\nvia a large language model. Then, a disentangle reconstruction model is trained\nbased on the generated data. After training, a large amount of synthetic data\ncan be obtained by decoding the new representation obtained from the\ncombination of different sample representations and filtering based on\nconfusion degree and sentiment classification. Experiments have proved that our\nframework can effectively alleviate emotional bias same as using only large\nmodels, but more economically.",
      "tldr_zh": "该研究针对意见总结中的情感偏差问题（如数据集70%以上为积极评论，导致模型偏向生成积极总结），提出了一种新型数据增强框架，结合Large Language Models和Small Language Models进行处理。框架首先利用Large Language Models改写积极文本生成少量合成负面评论，然后训练一个Disentangle Reconstruction Model，并通过组合样本表示、过滤混淆度和情感分类来生成大量合成数据。实验结果表明，该框架能有效缓解情感偏差，与仅使用大型模型的效果相当，但成本更低，从而更经济地实现数据集平衡。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.07693v2",
      "published_date": "2024-03-12 14:37:03 UTC",
      "updated_date": "2024-03-19 19:20:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:41:51.609890"
    },
    {
      "arxiv_id": "2403.07691v2",
      "title": "ORPO: Monolithic Preference Optimization without Reference Model",
      "title_zh": "ORPO：无需参考模型的单体偏好优化",
      "authors": [
        "Jiwoo Hong",
        "Noah Lee",
        "James Thorne"
      ],
      "abstract": "While recent preference alignment algorithms for language models have\ndemonstrated promising results, supervised fine-tuning (SFT) remains imperative\nfor achieving successful convergence. In this paper, we study the crucial role\nof SFT within the context of preference alignment, emphasizing that a minor\npenalty for the disfavored generation style is sufficient for\npreference-aligned SFT. Building on this foundation, we introduce a\nstraightforward and innovative reference model-free monolithic odds ratio\npreference optimization algorithm, ORPO, eliminating the necessity for an\nadditional preference alignment phase. We demonstrate, both empirically and\ntheoretically, that the odds ratio is a sensible choice for contrasting favored\nand disfavored styles during SFT across the diverse sizes from 125M to 7B.\nSpecifically, fine-tuning Phi-2 (2.7B), Llama-2 (7B), and Mistral (7B) with\nORPO on the UltraFeedback alone surpasses the performance of state-of-the-art\nlanguage models with more than 7B and 13B parameters: achieving up to 12.20% on\n$\\text{AlpacaEval}_{2.0}$ (Figure 1), 66.19% on IFEval (instruction-level\nloose, Table 6), and 7.32 in MT-Bench (Figure 12). We release code and model\ncheckpoints for Mistral-ORPO-$\\alpha$ (7B) and Mistral-ORPO-$\\beta$ (7B).",
      "tldr_zh": "本文提出 ORPO，一种无需参考模型的单体偏好优化算法，用于语言模型的偏好对齐，强调监督微调 (SFT) 中只需轻微惩罚非优选生成风格即可。ORPO 通过 odds ratio 对比优选和非优选风格，在 SFT 过程中实现高效优化，并在理论和实验上证明其有效性。实验结果显示，在 UltraFeedback 数据集上微调 Phi-2 (2.7B)、Llama-2 (7B) 和 Mistral (7B) 模型后，其性能超过了7B和13B参数的 SOTA 模型，在 AlpacaEval 2.0 上达12.20%、IFEval 上达66.19%、MT-Bench 上达7.32。作者发布了 Mistral-ORPO-α 和 Mistral-ORPO-β 的代码及模型检查点。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Preprint",
      "pdf_url": "http://arxiv.org/pdf/2403.07691v2",
      "published_date": "2024-03-12 14:34:08 UTC",
      "updated_date": "2024-03-14 07:47:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:42:06.471516"
    },
    {
      "arxiv_id": "2403.07688v1",
      "title": "Maxwell's Demon at Work: Efficient Pruning by Leveraging Saturation of Neurons",
      "title_zh": "翻译失败",
      "authors": [
        "Simon Dufort-Labbé",
        "Pierluca D'Oro",
        "Evgenii Nikishin",
        "Razvan Pascanu",
        "Pierre-Luc Bacon",
        "Aristide Baratin"
      ],
      "abstract": "When training deep neural networks, the phenomenon of $\\textit{dying\nneurons}$ $\\unicode{x2013}$units that become inactive or saturated, output zero\nduring training$\\unicode{x2013}$ has traditionally been viewed as undesirable,\nlinked with optimization challenges, and contributing to plasticity loss in\ncontinual learning scenarios. In this paper, we reassess this phenomenon,\nfocusing on sparsity and pruning. By systematically exploring the impact of\nvarious hyperparameter configurations on dying neurons, we unveil their\npotential to facilitate simple yet effective structured pruning algorithms. We\nintroduce $\\textit{Demon Pruning}$ (DemP), a method that controls the\nproliferation of dead neurons, dynamically leading to network sparsity.\nAchieved through a combination of noise injection on active units and a\none-cycled schedule regularization strategy, DemP stands out for its simplicity\nand broad applicability. Experiments on CIFAR10 and ImageNet datasets\ndemonstrate that DemP surpasses existing structured pruning techniques,\nshowcasing superior accuracy-sparsity tradeoffs and training speedups. These\nfindings suggest a novel perspective on dying neurons as a valuable resource\nfor efficient model compression and optimization.",
      "tldr_zh": "本文重新审视了神经网络中dying neurons（神经元饱和）现象，认为其可作为实现高效模型剪枝的资源，而不是单纯的负面影响。作者提出了Demon Pruning (DemP)方法，通过在活跃单位注入噪声并采用一个周期的调度正则化策略，动态控制dead neurons的产生以实现网络稀疏性。在CIFAR10和ImageNet数据集上的实验显示，DemP超过了现有结构化剪枝技术，提供更优的准确性-稀疏性权衡并提升训练速度。这些发现为模型压缩和优化提供了新颖视角。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.07688v1",
      "published_date": "2024-03-12 14:28:06 UTC",
      "updated_date": "2024-03-12 14:28:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:42:16.753150"
    },
    {
      "arxiv_id": "2403.07687v1",
      "title": "Annotations on a Budget: Leveraging Geo-Data Similarity to Balance Model Performance and Annotation Cost",
      "title_zh": "翻译失败",
      "authors": [
        "Oana Ignat",
        "Longju Bai",
        "Joan Nwatu",
        "Rada Mihalcea"
      ],
      "abstract": "Current foundation models have shown impressive performance across various\ntasks. However, several studies have revealed that these models are not\neffective for everyone due to the imbalanced geographical and economic\nrepresentation of the data used in the training process. Most of this data\ncomes from Western countries, leading to poor results for underrepresented\ncountries. To address this issue, more data needs to be collected from these\ncountries, but the cost of annotation can be a significant bottleneck. In this\npaper, we propose methods to identify the data to be annotated to balance model\nperformance and annotation costs. Our approach first involves finding the\ncountries with images of topics (objects and actions) most visually distinct\nfrom those already in the training datasets used by current large\nvision-language foundation models. Next, we identify countries with higher\nvisual similarity for these topics and show that using data from these\ncountries to supplement the training data improves model performance and\nreduces annotation costs. The resulting lists of countries and corresponding\ntopics are made available at\nhttps://github.com/MichiganNLP/visual_diversity_budget.",
      "tldr_zh": "该论文针对 foundation models 训练数据地理分布不均衡的问题，指出这些模型在欠代表国家（如非西方地区）表现不佳，导致模型性能不足。作者提出利用 Geo-Data Similarity 方法，首先识别图像主题（如对象和动作）视觉上最不同的国家，然后选择视觉相似度高的国家补充数据，以优化标注过程并降低成本。结果表明，这种策略能有效提升模型性能，同时减少标注开支，并公开了国家列表和对应主题的资源（https://github.com/MichiganNLP/visual_diversity_budget）。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "accepted at COLING 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.07687v1",
      "published_date": "2024-03-12 14:27:17 UTC",
      "updated_date": "2024-03-12 14:27:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:42:27.578823"
    },
    {
      "arxiv_id": "2403.07968v2",
      "title": "Do Deep Neural Network Solutions Form a Star Domain?",
      "title_zh": "深度神经网络的解是否形成星形域？",
      "authors": [
        "Ankit Sonthalia",
        "Alexander Rubinstein",
        "Ehsan Abbasnejad",
        "Seong Joon Oh"
      ],
      "abstract": "It has recently been conjectured that neural network solution sets reachable\nvia stochastic gradient descent (SGD) are convex, considering permutation\ninvariances (Entezari et al., 2022). This means that a linear path can connect\ntwo independent solutions with low loss, given the weights of one of the models\nare appropriately permuted. However, current methods to test this theory often\nrequire very wide networks to succeed. In this work, we conjecture that more\ngenerally, the SGD solution set is a \"star domain\" that contains a \"star model\"\nthat is linearly connected to all the other solutions via paths with low loss\nvalues, modulo permutations. We propose the Starlight algorithm that finds a\nstar model of a given learning task. We validate our claim by showing that this\nstar model is linearly connected with other independently found solutions. As\nan additional benefit of our study, we demonstrate better uncertainty estimates\non the Bayesian Model Averaging over the obtained star domain. Further, we\ndemonstrate star models as potential substitutes for model ensembles. Our code\nis available at https://github.com/aktsonthalia/starlight.",
      "tldr_zh": "该论文探讨了通过随机梯度下降 (SGD) 训练得到的深度神经网络解集是否形成一个“星域”，即存在一个“星模型”能通过低损失线性路径连接其他解，同时考虑排列不变性。作者提出 Starlight 算法，用于识别这一星模型，并通过实验验证其与独立训练的解之间线性连接的可能性。研究结果显示，这种星域结构不仅改善了 Bayesian Model Averaging 的不确定性估计，还能作为模型集成 (model ensembles) 的潜在替代方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.07968v2",
      "published_date": "2024-03-12 13:59:23 UTC",
      "updated_date": "2024-06-09 11:51:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:42:39.533719"
    },
    {
      "arxiv_id": "2405.09549v1",
      "title": "Deep-learning-based clustering of OCT images for biomarker discovery in age-related macular degeneration (Pinnacle study report 4)",
      "title_zh": "翻译失败",
      "authors": [
        "Robbie Holland",
        "Rebecca Kaye",
        "Ahmed M. Hagag",
        "Oliver Leingang",
        "Thomas R. P. Taylor",
        "Hrvoje Bogunović",
        "Ursula Schmidt-Erfurth",
        "Hendrik P. N. Scholl",
        "Daniel Rueckert",
        "Andrew J. Lotery",
        "Sobha Sivaprasad",
        "Martin J. Menten"
      ],
      "abstract": "Diseases are currently managed by grading systems, where patients are\nstratified by grading systems into stages that indicate patient risk and guide\nclinical management. However, these broad categories typically lack prognostic\nvalue, and proposals for new biomarkers are currently limited to anecdotal\nobservations. In this work, we introduce a deep-learning-based biomarker\nproposal system for the purpose of accelerating biomarker discovery in\nage-related macular degeneration (AMD). It works by first training a neural\nnetwork using self-supervised contrastive learning to discover, without any\nclinical annotations, features relating to both known and unknown AMD\nbiomarkers present in 46,496 retinal optical coherence tomography (OCT) images.\nTo interpret the discovered biomarkers, we partition the images into 30\nsubsets, termed clusters, that contain similar features. We then conduct two\nparallel 1.5-hour semi-structured interviews with two independent teams of\nretinal specialists that describe each cluster in clinical language. Overall,\nboth teams independently identified clearly distinct characteristics in 27 of\n30 clusters, of which 23 were related to AMD. Seven were recognised as known\nbiomarkers already used in established grading systems and 16 depicted\nbiomarker combinations or subtypes that are either not yet used in grading\nsystems, were only recently proposed, or were unknown. Clusters separated\nincomplete from complete retinal atrophy, intraretinal from subretinal fluid\nand thick from thin choroids, and in simulation outperformed clinically-used\ngrading systems in prognostic value. Overall, contrastive learning enabled the\nautomatic proposal of AMD biomarkers that go beyond the set used by clinically\nestablished grading systems. Ultimately, we envision that equipping clinicians\nwith discovery-oriented deep-learning tools can accelerate discovery of novel\nprognostic biomarkers.",
      "tldr_zh": "本研究提出了一种基于深度学习的系统，用于加速年龄相关性黄斑变性 (AMD) 生物标志物的发现，通过分析 46,496 张视网膜光学相干断层扫描 (OCT) 图像。系统首先利用自监督对比学习 (self-supervised contrastive learning) 训练神经网络，自动识别已知和未知的 AMD 生物标志物，然后将图像分为 30 个 clusters，经视网膜专家访谈确认其中 27 个显示出独特特征，包括 7 个已知生物标志物和 16 个新组合或亚型。结果表明，这些 clusters 在模拟中比临床分级系统提供更好的预后价值，最终有望通过深度学习工具加速新型预后生物标志物的发现。",
      "categories": [
        "eess.IV",
        "cs.AI"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.09549v1",
      "published_date": "2024-03-12 13:48:17 UTC",
      "updated_date": "2024-03-12 13:48:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:42:52.346990"
    },
    {
      "arxiv_id": "2403.07657v3",
      "title": "Scalable Spatiotemporal Prediction with Bayesian Neural Fields",
      "title_zh": "翻译失败",
      "authors": [
        "Feras Saad",
        "Jacob Burnim",
        "Colin Carroll",
        "Brian Patton",
        "Urs Köster",
        "Rif A. Saurous",
        "Matthew Hoffman"
      ],
      "abstract": "Spatiotemporal datasets, which consist of spatially-referenced time series,\nare ubiquitous in diverse applications, such as air pollution monitoring,\ndisease tracking, and cloud-demand forecasting. As the scale of modern datasets\nincreases, there is a growing need for statistical methods that are flexible\nenough to capture complex spatiotemporal dynamics and scalable enough to handle\nmany observations. This article introduces the Bayesian Neural Field (BayesNF),\na domain-general statistical model that infers rich spatiotemporal probability\ndistributions for data-analysis tasks including forecasting, interpolation, and\nvariography. BayesNF integrates a deep neural network architecture for\nhigh-capacity function estimation with hierarchical Bayesian inference for\nrobust predictive uncertainty quantification. Evaluations against prominent\nbaselines show that BayesNF delivers improvements on prediction problems from\nclimate and public health data containing tens to hundreds of thousands of\nmeasurements. Accompanying the paper is an open-source software package\n(https://github.com/google/bayesnf) that runs on GPU and TPU accelerators\nthrough the JAX machine learning platform.",
      "tldr_zh": "本文研究提出Bayesian Neural Field (BayesNF)，一个通用的统计模型，用于处理大规模时空数据集，如空气污染监测和疾病追踪，提供灵活的预测、插值和变异图分析。BayesNF 结合深度神经网络架构实现高容量函数估计，并采用层次化Bayesian inference进行鲁棒的预测不确定性量化。实验结果显示，该模型在气候和公共健康数据上比基准方法提升预测性能，可处理数万到数十万测量，并提供开源软件包（https://github.com/google/bayesnf）支持GPU和TPU加速。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.AP",
        "stat.ME"
      ],
      "primary_category": "cs.LG",
      "comment": "29 pages, 7 figures, 2 tables, 1 listing",
      "pdf_url": "http://arxiv.org/pdf/2403.07657v3",
      "published_date": "2024-03-12 13:47:50 UTC",
      "updated_date": "2024-11-26 21:26:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:43:04.517234"
    },
    {
      "arxiv_id": "2403.07630v1",
      "title": "Hunting Attributes: Context Prototype-Aware Learning for Weakly Supervised Semantic Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Feilong Tang",
        "Zhongxing Xu",
        "Zhaojun Qu",
        "Wei Feng",
        "Xingjian Jiang",
        "Zongyuan Ge"
      ],
      "abstract": "Recent weakly supervised semantic segmentation (WSSS) methods strive to\nincorporate contextual knowledge to improve the completeness of class\nactivation maps (CAM). In this work, we argue that the knowledge bias between\ninstances and contexts affects the capability of the prototype to sufficiently\nunderstand instance semantics. Inspired by prototype learning theory, we\npropose leveraging prototype awareness to capture diverse and fine-grained\nfeature attributes of instances. The hypothesis is that contextual prototypes\nmight erroneously activate similar and frequently co-occurring object\ncategories due to this knowledge bias. Therefore, we propose to enhance the\nprototype representation ability by mitigating the bias to better capture\nspatial coverage in semantic object regions. With this goal, we present a\nContext Prototype-Aware Learning (CPAL) strategy, which leverages semantic\ncontext to enrich instance comprehension. The core of this method is to\naccurately capture intra-class variations in object features through\ncontext-aware prototypes, facilitating the adaptation to the semantic\nattributes of various instances. We design feature distribution alignment to\noptimize prototype awareness, aligning instance feature distributions with\ndense features. In addition, a unified training framework is proposed to\ncombine label-guided classification supervision and prototypes-guided\nself-supervision. Experimental results on PASCAL VOC 2012 and MS COCO 2014 show\nthat CPAL significantly improves off-the-shelf methods and achieves\nstate-of-the-art performance. The project is available at\nhttps://github.com/Barrett-python/CPAL.",
      "tldr_zh": "本论文针对弱监督语义分割 (WSSS) 中的知识偏差问题，提出了一种 Context Prototype-Aware Learning (CPAL) 策略，以提升类激活映射 (CAM) 的完整性和实例语义理解能力。CPAL 通过上下文原型捕捉实例的多样化细粒度特征属性，并通过特征分布对齐优化原型感知，从而缓解实例与上下文间的偏差影响，实现对对象区域更精确的空间覆盖。论文还设计了一个统一的训练框架，结合标签引导的分类监督和原型引导的自监督训练，在 PASCAL VOC 2012 和 MS COCO 2014 数据集上，CPAL 显著提升了现有方法的性能，并达到了 state-of-the-art 水平。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.07630v1",
      "published_date": "2024-03-12 13:11:58 UTC",
      "updated_date": "2024-03-12 13:11:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:43:17.813812"
    },
    {
      "arxiv_id": "2403.07622v1",
      "title": "Multiple Latent Space Mapping for Compressed Dark Image Enhancement",
      "title_zh": "多重潜在空间映射用于压缩暗图像增强",
      "authors": [
        "Yi Zeng",
        "Zhengning Wang",
        "Yuxuan Liu",
        "Tianjiao Zeng",
        "Xuhang Liu",
        "Xinglong Luo",
        "Shuaicheng Liu",
        "Shuyuan Zhu",
        "Bing Zeng"
      ],
      "abstract": "Dark image enhancement aims at converting dark images to normal-light images.\nExisting dark image enhancement methods take uncompressed dark images as inputs\nand achieve great performance. However, in practice, dark images are often\ncompressed before storage or transmission over the Internet. Current methods\nget poor performance when processing compressed dark images. Artifacts hidden\nin the dark regions are amplified by current methods, which results in\nuncomfortable visual effects for observers. Based on this observation, this\nstudy aims at enhancing compressed dark images while avoiding compression\nartifacts amplification. Since texture details intertwine with compression\nartifacts in compressed dark images, detail enhancement and blocking artifacts\nsuppression contradict each other in image space. Therefore, we handle the task\nin latent space. To this end, we propose a novel latent mapping network based\non variational auto-encoder (VAE). Firstly, different from previous VAE-based\nmethods with single-resolution features only, we exploit multiple latent spaces\nwith multi-resolution features, to reduce the detail blur and improve image\nfidelity. Specifically, we train two multi-level VAEs to project compressed\ndark images and normal-light images into their latent spaces respectively.\nSecondly, we leverage a latent mapping network to transform features from\ncompressed dark space to normal-light space. Specifically, since the\ndegradation models of darkness and compression are different from each other,\nthe latent mapping process is divided mapping into enlightening branch and\ndeblocking branch. Comprehensive experiments demonstrate that the proposed\nmethod achieves state-of-the-art performance in compressed dark image\nenhancement.",
      "tldr_zh": "本研究针对压缩暗图像增强问题，指出现有方法虽在未压缩图像上表现良好，但会放大暗区中的压缩伪影，导致视觉不适。作者提出一种基于 Variational Auto-Encoder (VAE) 的新型潜在映射网络，利用多分辨率特征的多重潜在空间，将压缩暗图像和正常光图像分别投影到各自的潜在空间中，并通过 enlightening branch 和 deblocking branch 分别处理照明增强和去块效应抑制。实验结果表明，该方法在压缩暗图像增强任务中实现了最先进性能，显著减少细节模糊并提高了图像保真度。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.07622v1",
      "published_date": "2024-03-12 13:05:51 UTC",
      "updated_date": "2024-03-12 13:05:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:43:29.655016"
    },
    {
      "arxiv_id": "2403.07611v1",
      "title": "Efficient Knowledge Deletion from Trained Models through Layer-wise Partial Machine Unlearning",
      "title_zh": "翻译失败",
      "authors": [
        "Vinay Chakravarthi Gogineni",
        "Esmaeil S. Nadimi"
      ],
      "abstract": "Machine unlearning has garnered significant attention due to its ability to\nselectively erase knowledge obtained from specific training data samples in an\nalready trained machine learning model. This capability enables data holders to\nadhere strictly to data protection regulations. However, existing unlearning\ntechniques face practical constraints, often causing performance degradation,\ndemanding brief fine-tuning post unlearning, and requiring significant storage.\nIn response, this paper introduces a novel class of machine unlearning\nalgorithms. First method is partial amnesiac unlearning, integration of\nlayer-wise pruning with amnesiac unlearning. In this method, updates made to\nthe model during training are pruned and stored, subsequently used to forget\nspecific data from trained model. The second method assimilates layer-wise\npartial-updates into label-flipping and optimization-based unlearning to\nmitigate the adverse effects of data deletion on model efficacy. Through a\ndetailed experimental evaluation, we showcase the effectiveness of proposed\nunlearning methods. Experimental results highlight that the partial amnesiac\nunlearning not only preserves model efficacy but also eliminates the necessity\nfor brief post fine-tuning, unlike conventional amnesiac unlearning. Moreover,\nemploying layer-wise partial updates in label-flipping and optimization-based\nunlearning techniques demonstrates superiority in preserving model efficacy\ncompared to their naive counterparts.",
      "tldr_zh": "这篇论文提出了一种高效的机器遗忘（machine unlearning）方法，通过层级部分更新（layer-wise partial updates）来选择性地从已训练模型中删除特定训练数据知识，从而遵守数据保护法规，同时减少性能下降和存储需求。论文引入了两种新算法：partial amnesiac unlearning，将层级修剪（layer-wise pruning）与amnesiac unlearning整合，在训练更新中修剪和存储信息以实现精确遗忘；以及将层级部分更新融入label-flipping和optimization-based unlearning中，以最小化数据删除对模型效能的负面影响。实验结果表明，这些方法不仅维持了模型效能，还消除了传统amnesiac unlearning所需的后续微调，并在与基线方法的比较中表现出显著优势。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "16pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.07611v1",
      "published_date": "2024-03-12 12:49:47 UTC",
      "updated_date": "2024-03-12 12:49:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:43:44.973757"
    },
    {
      "arxiv_id": "2403.07608v1",
      "title": "Couler: Unified Machine Learning Workflow Optimization in Cloud",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaoda Wang",
        "Yuan Tang",
        "Tengda Guo",
        "Bo Sang",
        "Jingji Wu",
        "Jian Sha",
        "Ke Zhang",
        "Jiang Qian",
        "Mingjie Tang"
      ],
      "abstract": "Machine Learning (ML) has become ubiquitous, fueling data-driven applications\nacross various organizations. Contrary to the traditional perception of ML in\nresearch, ML workflows can be complex, resource-intensive, and time-consuming.\nExpanding an ML workflow to encompass a wider range of data infrastructure and\ndata types may lead to larger workloads and increased deployment costs.\nCurrently, numerous workflow engines are available (with over ten being widely\nrecognized). This variety poses a challenge for end-users in terms of mastering\ndifferent engine APIs. While efforts have primarily focused on optimizing ML\nOperations (MLOps) for a specific workflow engine, current methods largely\noverlook workflow optimization across different engines.\n  In this work, we design and implement Couler, a system designed for unified\nML workflow optimization in the cloud. Our main insight lies in the ability to\ngenerate an ML workflow using natural language (NL) descriptions. We integrate\nLarge Language Models (LLMs) into workflow generation, and provide a unified\nprogramming interface for various workflow engines. This approach alleviates\nthe need to understand various workflow engines' APIs. Moreover, Couler\nenhances workflow computation efficiency by introducing automated caching at\nmultiple stages, enabling large workflow auto-parallelization and automatic\nhyperparameters tuning. These enhancements minimize redundant computational\ncosts and improve fault tolerance during deep learning workflow training.\nCouler is extensively deployed in real-world production scenarios at Ant Group,\nhandling approximately 22k workflows daily, and has successfully improved the\nCPU/Memory utilization by more than 15% and the workflow completion rate by\naround 17%.",
      "tldr_zh": "该论文提出Couler系统，用于统一优化云端Machine Learning (ML)工作流，解决多种workflow engines API复杂性和跨引擎优化不足的问题。Couler利用自然语言 (NL)描述和Large Language Models (LLMs)生成工作流，提供统一的编程接口，并引入自动化缓存、多级自动并行化和自动超参数调优，以减少冗余计算并提升容错性。在Ant Group的实际部署中，Couler每天处理约22k工作流，提高CPU/Memory利用率超过15%和工作流完成率约17%。这为高效的ML Operations (MLOps)提供了实用框架。",
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.DB",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.07608v1",
      "published_date": "2024-03-12 12:47:32 UTC",
      "updated_date": "2024-03-12 12:47:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:43:52.765305"
    },
    {
      "arxiv_id": "2403.07605v3",
      "title": "Optimizing Negative Prompts for Enhanced Aesthetics and Fidelity in Text-To-Image Generation",
      "title_zh": "优化负面提示以增强文本到图像生成的审美性和保真度",
      "authors": [
        "Michael Ogezi",
        "Ning Shi"
      ],
      "abstract": "In text-to-image generation, using negative prompts, which describe\nundesirable image characteristics, can significantly boost image quality.\nHowever, producing good negative prompts is manual and tedious. To address\nthis, we propose NegOpt, a novel method for optimizing negative prompt\ngeneration toward enhanced image generation, using supervised fine-tuning and\nreinforcement learning. Our combined approach results in a substantial increase\nof 25% in Inception Score compared to other approaches and surpasses\nground-truth negative prompts from the test set. Furthermore, with NegOpt we\ncan preferentially optimize the metrics most important to us. Finally, we\nconstruct Negative Prompts DB\n(https://huggingface.co/datasets/mikeogezi/negopt_full), a publicly available\ndataset of negative prompts.",
      "tldr_zh": "这篇论文提出了一种名为 NegOpt 的新方法，通过 supervised fine-tuning 和 reinforcement learning 优化 negative prompts 的生成，以提升文本到图像生成的图像美学和保真度。相比其他方法，NegOpt 使 Inception Score 提高了 25%，并超过了测试集的真实 negative prompts，同时允许用户优先优化最重要的指标。该方法还构建了公开数据集 Negative Prompts DB（https://huggingface.co/datasets/mikeogezi/negopt_full），以支持进一步研究。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.07605v3",
      "published_date": "2024-03-12 12:44:34 UTC",
      "updated_date": "2024-11-05 01:11:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:44:04.365786"
    },
    {
      "arxiv_id": "2403.07587v1",
      "title": "Perennial Semantic Data Terms of Use for Decentralized Web",
      "title_zh": "翻译失败",
      "authors": [
        "Rui Zhao",
        "Jun Zhao"
      ],
      "abstract": "In today's digital landscape, the Web has become increasingly centralized,\nraising concerns about user privacy violations. Decentralized Web\narchitectures, such as Solid, offer a promising solution by empowering users\nwith better control over their data in their personal `Pods'. However, a\nsignificant challenge remains: users must navigate numerous applications to\ndecide which application can be trusted with access to their data Pods. This\noften involves reading lengthy and complex Terms of Use agreements, a process\nthat users often find daunting or simply ignore. This compromises user autonomy\nand impedes detection of data misuse. We propose a novel formal description of\nData Terms of Use (DToU), along with a DToU reasoner. Users and applications\nspecify their own parts of the DToU policy with local knowledge, covering\npermissions, requirements, prohibitions and obligations. Automated reasoning\nverifies compliance, and also derives policies for output data. This\nconstitutes a ``perennial'' DToU language, where the policy authoring only\noccurs once, and we can conduct ongoing automated checks across users,\napplications and activity cycles. Our solution is built on Turtle, Notation 3\nand RDF Surfaces, for the language and the reasoning engine. It ensures\nseamless integration with other semantic tools for enhanced interoperability.\nWe have successfully integrated this language into the Solid framework, and\nconducted performance benchmark. We believe this work demonstrates a\npracticality of a perennial DToU language and the potential of a paradigm shift\nto how users interact with data and applications in a decentralized Web,\noffering both improved privacy and usability.",
      "tldr_zh": "本研究针对去中心化 Web（如 Solid）中的用户隐私挑战，提出了一种“perennial” Semantic Data Terms of Use (DToU) 语言，允许用户和应用仅需一次指定权限、要求、禁止和义务，即可进行持续的自动化合规检查。DToU 基于 Turtle、Notation 3 和 RDF Surfaces 构建，实现了与语义工具的无缝集成，并为输出数据衍生政策，以提升数据隐私和互操作性。研究已在 Solid 框架中成功集成，并通过性能基准测试证明了其实用性，有望改变用户与数据应用的交互方式，提供更好的隐私保护和可用性。",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "This paper is accepted by International World Wide Web Conference\n  2024 (WWW 2024 / The Web Conf 2024)",
      "pdf_url": "http://arxiv.org/pdf/2403.07587v1",
      "published_date": "2024-03-12 12:18:20 UTC",
      "updated_date": "2024-03-12 12:18:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:44:20.546952"
    },
    {
      "arxiv_id": "2403.07586v1",
      "title": "Federated Learning of Socially Appropriate Agent Behaviours in Simulated Home Environments",
      "title_zh": "翻译失败",
      "authors": [
        "Saksham Checker",
        "Nikhil Churamani",
        "Hatice Gunes"
      ],
      "abstract": "As social robots become increasingly integrated into daily life, ensuring\ntheir behaviours align with social norms is crucial. For their widespread\nopen-world application, it is important to explore Federated Learning (FL)\nsettings where individual robots can learn about their unique environments\nwhile also learning from each others' experiences. In this paper, we present a\nnovel FL benchmark that evaluates different strategies, using multi-label\nregression objectives, where each client individually learns to predict the\nsocial appropriateness of different robot actions while also sharing their\nlearning with others. Furthermore, splitting the training data by different\ncontexts such that each client incrementally learns across contexts, we present\na novel Federated Continual Learning (FCL) benchmark that adapts FL-based\nmethods to use state-of-the-art Continual Learning (CL) methods to continually\nlearn socially appropriate agent behaviours under different contextual\nsettings. Federated Averaging (FedAvg) of weights emerges as a robust FL\nstrategy while rehearsal-based FCL enables incrementally learning the social\nappropriateness of robot actions, across contextual splits.",
      "tldr_zh": "该论文探讨了在模拟家庭环境中，使用 Federated Learning (FL) 训练社交机器人，使其行为符合社会规范，从而适应开放世界的应用。研究提出一个新的 FL 基准，通过多标签回归目标，让每个客户端独立预测机器人动作的社会适宜性，同时与其他客户端共享学习经验；此外，还引入 Federated Continual Learning (FCL) 基准，将 Continual Learning (CL) 方法应用于不同上下文的增量学习。结果表明，Federated Averaging (FedAvg) 作为一种稳健策略表现突出，而基于回放的 FCL 方法能有效实现跨上下文的持续学习社交行为。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at the Workshop on Lifelong Learning and Personalization in\n  Long-Term Human-Robot Interaction (LEAP-HRI) at the 19th ACM/IEEE\n  International Conference on Human-Robot Interaction (HRI), 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.07586v1",
      "published_date": "2024-03-12 12:16:40 UTC",
      "updated_date": "2024-03-12 12:16:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:44:30.599022"
    },
    {
      "arxiv_id": "2403.07573v3",
      "title": "Towards a Dynamic Future with Adaptable Computing and Network Convergence (ACNC)",
      "title_zh": "迈向动态未来：通过可适应计算与网络融合 (ACNC)",
      "authors": [
        "Masoud Shokrnezhad",
        "Hao Yu",
        "Tarik Taleb",
        "Richard Li",
        "Kyunghan Lee",
        "Jaeseung Song",
        "Cedric Westphal"
      ],
      "abstract": "In the context of advancing 6G, a substantial paradigm shift is anticipated,\nhighlighting comprehensive everything-to-everything interactions characterized\nby numerous connections and stringent adherence to Quality of\nService/Experience (QoS/E) prerequisites. The imminent challenge stems from\nresource scarcity, prompting a deliberate transition to Computing-Network\nConvergence (CNC) as an auspicious approach for joint resource orchestration.\nWhile CNC-based mechanisms have garnered attention, their effectiveness in\nrealizing future services, particularly in use cases like the Metaverse, may\nencounter limitations due to the continually changing nature of users,\nservices, and resources. Hence, this paper presents the concept of Adaptable\nCNC (ACNC) as an autonomous Machine Learning (ML)-aided mechanism crafted for\nthe joint orchestration of computing and network resources, catering to dynamic\nand voluminous user requests with stringent requirements. ACNC encompasses two\nprimary functionalities: state recognition and context detection. Given the\nintricate nature of the user-service-computing-network space, the paper employs\ndimension reduction to generate live, holistic, abstract system states in a\nhierarchical structure. To address the challenges posed by dynamic changes,\nContinual Learning (CL) is employed, classifying the system state into contexts\ncontrolled by dedicated ML agents, enabling them to operate efficiently. These\ntwo functionalities are intricately linked within a closed loop overseen by the\nEnd-to-End (E2E) orchestrator to allocate resources. The paper introduces the\ncomponents of ACNC, proposes a Metaverse scenario to exemplify ACNC's role in\nresource provisioning with Segment Routing v6 (SRv6), outlines ACNC's workflow,\ndetails a numerical analysis for efficiency assessment, and concludes with\ndiscussions on relevant challenges and potential avenues for future research.",
      "tldr_zh": "本文针对6G时代万物互联的需求和资源稀缺挑战，提出Adaptable Computing and Network Convergence (ACNC)，这是一种基于Machine Learning (ML)的自主机制，用于动态联合编排计算和网络资源，以满足严格的QoS/E要求。ACNC的核心功能包括状态识别（通过维度减少生成分层系统状态）和上下文检测（采用Continual Learning (CL)分类系统状态，由专用ML代理控制），这些在End-to-End (E2E)编排器的闭环中实现高效资源分配。论文以Metaverse场景为例，结合Segment Routing v6 (SRv6)，描述了ACNC的工作流程，并通过数值分析证明其效率，讨论了潜在挑战和未来研究方向。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.DC",
        "cs.ET",
        "cs.LG"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.07573v3",
      "published_date": "2024-03-12 12:03:16 UTC",
      "updated_date": "2024-12-18 05:54:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:44:43.852731"
    },
    {
      "arxiv_id": "2403.07965v2",
      "title": "Conditional computation in neural networks: principles and research trends",
      "title_zh": "神经网络中的条件计算：原则和研究趋势",
      "authors": [
        "Simone Scardapane",
        "Alessandro Baiocchi",
        "Alessio Devoto",
        "Valerio Marsocci",
        "Pasquale Minervini",
        "Jary Pomponi"
      ],
      "abstract": "This article summarizes principles and ideas from the emerging area of\napplying \\textit{conditional computation} methods to the design of neural\nnetworks. In particular, we focus on neural networks that can dynamically\nactivate or de-activate parts of their computational graph conditionally on\ntheir input. Examples include the dynamic selection of, e.g., input tokens,\nlayers (or sets of layers), and sub-modules inside each layer (e.g., channels\nin a convolutional filter). We first provide a general formalism to describe\nthese techniques in an uniform way. Then, we introduce three notable\nimplementations of these principles: mixture-of-experts (MoEs) networks, token\nselection mechanisms, and early-exit neural networks. The paper aims to provide\na tutorial-like introduction to this growing field. To this end, we analyze the\nbenefits of these modular designs in terms of efficiency, explainability, and\ntransfer learning, with a focus on emerging applicative areas ranging from\nautomated scientific discovery to semantic communication.",
      "tldr_zh": "这篇论文总结了条件计算（conditional computation）在神经网络设计中的原则和趋势，重点探讨神经网络如何根据输入动态激活或停用部分计算图，例如选择输入标记、层或层内子模块。作者提供了一个统一的正式框架来描述这些技术，并介绍了三种关键实现：混合专家（Mixture-of-Experts, MoEs）网络、标记选择机制和早期退出神经网络。论文通过分析这些模块化设计，突出了其在效率、可解释性和迁移学习方面的优势，并探讨了在自动科学发现和语义通信等新兴应用领域的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.07965v2",
      "published_date": "2024-03-12 11:56:38 UTC",
      "updated_date": "2024-07-08 09:21:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:44:53.338290"
    },
    {
      "arxiv_id": "2403.07566v2",
      "title": "An Improved Strategy for Blood Glucose Control Using Multi-Step Deep Reinforcement Learning",
      "title_zh": "一种基于多步深度强化学习的血糖控制改进策略",
      "authors": [
        "Weiwei Gu",
        "Senquan Wang"
      ],
      "abstract": "Blood Glucose (BG) control involves keeping an individual's BG within a\nhealthy range through extracorporeal insulin injections is an important task\nfor people with type 1 diabetes. However,traditional patient self-management is\ncumbersome and risky. Recent research has been devoted to exploring\nindividualized and automated BG control approaches, among which Deep\nReinforcement Learning (DRL) shows potential as an emerging approach. In this\npaper, we use an exponential decay model of drug concentration to convert the\nformalization of the BG control problem, which takes into account the delay and\nprolongedness of drug effects, from a PAE-POMDP (Prolonged Action\nEffect-Partially Observable Markov Decision Process) to a MDP, and we propose a\nnovel multi-step DRL-based algorithm to solve the problem. The Prioritized\nExperience Replay (PER) sampling method is also used in it. Compared to\nsingle-step bootstrapped updates, multi-step learning is more efficient and\nreduces the influence from biasing targets. Our proposed method converges\nfaster and achieves higher cumulative rewards compared to the benchmark in the\nsame training environment, and improves the time-in-range (TIR), the percentage\nof time the patient's BG is within the target range, in the evaluation phase.\nOur work validates the effectiveness of multi-step reinforcement learning in BG\ncontrol, which may help to explore the optimal glycemic control measure and\nimprove the survival of diabetic patients.",
      "tldr_zh": "这篇论文针对1型糖尿病患者的血糖控制问题，提出了一种改进策略，通过指数衰减模型将问题从PAE-POMDP（Prolonged Action Effect-Partially Observable Markov Decision Process）转换为MDP（Markov Decision Process），并开发了一种新型多步Deep Reinforcement Learning (DRL)算法，结合Prioritized Experience Replay (PER)来减少偏差并提升效率。相比单步DRL方法，该算法在训练环境中收敛更快，获得更高累积奖励，并在评估阶段显著提高了time-in-range (TIR)，即患者血糖维持在目标范围的时间比例。研究验证了多步强化学习在血糖控制中的有效性，有望帮助探索最佳血糖管理措施并改善患者生存率。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.07566v2",
      "published_date": "2024-03-12 11:53:00 UTC",
      "updated_date": "2024-03-15 09:48:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:45:07.707953"
    },
    {
      "arxiv_id": "2403.07964v2",
      "title": "Optimal Design and Implementation of an Open-source Emulation Platform for User-Centric Shared E-mobility Services",
      "title_zh": "翻译失败",
      "authors": [
        "Maqsood Hussain Shah",
        "Yue Ding",
        "Shaoshu Zhu",
        "Yingqi Gu",
        "Mingming Liu"
      ],
      "abstract": "With the rising concern over transportation emissions and pollution on a\nglobal scale, shared electric mobility services like E-cars, E-bikes, and\nE-scooters have emerged as promising solutions to mitigate these pressing\nchallenges. However, existing shared E-mobility services exhibit critical\ndesign deficiencies, including insufficient service integration, imprecise\nenergy consumption forecasting, limited scalability and geographical coverage,\nand a notable absence of a user-centric perspective, particularly in the\ncontext of multi-modal transportation. More importantly, there is no\nconsolidated open-source platform which could benefit the E-mobility research\ncommunity. This paper aims to bridge this gap by providing an open-source\nplatform for shared E-mobility. The proposed platform, with an\nagent-in-the-loop approach and modular architecture, is tailored to diverse\nuser preferences and offers enhanced customization. We demonstrate the\nviability of this platform by providing a comprehensive analysis for integrated\nmulti-modal route-optimization in diverse scenarios of energy availability,\nuser preferences and E-mobility tools placement for which we use modified Ant\nColony Optimization algorithm so called Multi-Model Energy Constrained ACO\n(MMEC-ACO) and Q-Learning algorithms. Our findings demonstrate that Q-learning\nachieves significantly better performance in terms of travel time cost for more\nthan 90\\% of the instances as compared to MMEC-ACO for different scenarios\nincluding energy availability, user preference and E-mobility tools\ndistribution. For a fixed (O, D) pair, the average execution time to achieve\noptimal time cost solution for MMEC-ACO is less than 2 seconds, while\nQ-learning reaches an optimal time cost in 20 seconds on average. For a\nrun-time of 2 seconds, Q-learning still achieves a better optimal time cost\nwith a 20\\% reduction over MMEC-ACO's time cost.",
      "tldr_zh": "本论文针对共享电动交通（E-mobility）服务的设计缺陷（如服务整合不足、能源消耗预测不准确以及缺乏用户中心视角）提出一个开源仿真平台，该平台采用 agent-in-the-loop approach 和 modular architecture，以支持多模式交通的定制化和可扩展性。平台通过 Multi-Model Energy Constrained ACO (MMEC-ACO) 和 Q-Learning 算法进行集成多模式路线优化，针对不同能源可用性、用户偏好和工具分布场景进行分析。实验结果显示，Q-Learning 在90%以上的实例中比 MMEC-ACO 提供更好的旅行时间成本优化，且在运行时间为2秒时仍能将时间成本降低20%；然而，MMEC-ACO 的平均执行时间不到2秒，适合快速计算需求。整体而言，这一平台为 E-mobility 研究社区提供了统一的开源工具，促进用户中心服务的创新和部署。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "15 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.07964v2",
      "published_date": "2024-03-12 11:51:30 UTC",
      "updated_date": "2024-07-01 18:46:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:45:19.089649"
    },
    {
      "arxiv_id": "2403.07559v2",
      "title": "Ensembling Prioritized Hybrid Policies for Multi-agent Pathfinding",
      "title_zh": "翻译失败",
      "authors": [
        "Huijie Tang",
        "Federico Berto",
        "Jinkyoo Park"
      ],
      "abstract": "Multi-Agent Reinforcement Learning (MARL) based Multi-Agent Path Finding\n(MAPF) has recently gained attention due to its efficiency and scalability.\nSeveral MARL-MAPF methods choose to use communication to enrich the information\none agent can perceive. However, existing works still struggle in structured\nenvironments with high obstacle density and a high number of agents. To further\nimprove the performance of the communication-based MARL-MAPF solvers, we\npropose a new method, Ensembling Prioritized Hybrid Policies (EPH). We first\npropose a selective communication block to gather richer information for better\nagent coordination within multi-agent environments and train the model with a Q\nlearning-based algorithm. We further introduce three advanced inference\nstrategies aimed at bolstering performance during the execution phase. First,\nwe hybridize the neural policy with single-agent expert guidance for navigating\nconflict-free zones. Secondly, we propose Q value-based methods for prioritized\nresolution of conflicts as well as deadlock situations. Finally, we introduce a\nrobust ensemble method that can efficiently collect the best out of multiple\npossible solutions. We empirically evaluate EPH in complex multi-agent\nenvironments and demonstrate competitive performance against state-of-the-art\nneural methods for MAPF. We open-source our code at\nhttps://github.com/ai4co/eph-mapf.",
      "tldr_zh": "本研究针对多代理路径规划(MAPF)中的挑战，提出了一种基于多代理强化学习(MARL)的创新方法Ensembling Prioritized Hybrid Policies (EPH)，以提升代理在高障碍密度和多代理环境下的协调性能。EPH 包括一个 selective communication block 用于收集更丰富的代理信息，并结合 Q learning 算法训练；同时引入三种高级推理策略：将神经策略与单代理专家指导混合处理无冲突区域、基于 Q 值优先级解决冲突和死锁，以及一个鲁棒的集成方法来选择最佳解决方案。实验结果显示，EPH 在复杂多代理环境中表现出色，优于现有状态-of-the-art 神经方法，并已开源代码以供进一步研究。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.MA",
      "comment": "Accepted to 2024 IEEE/RSJ International Conference on Intelligent\n  Robots and Systems (IROS 2024)",
      "pdf_url": "http://arxiv.org/pdf/2403.07559v2",
      "published_date": "2024-03-12 11:47:12 UTC",
      "updated_date": "2024-07-10 08:36:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:45:30.207096"
    },
    {
      "arxiv_id": "2403.07553v1",
      "title": "The future of document indexing: GPT and Donut revolutionize table of content processing",
      "title_zh": "翻译失败",
      "authors": [
        "Degaga Wolde Feyisa",
        "Haylemicheal Berihun",
        "Amanuel Zewdu",
        "Mahsa Najimoghadam",
        "Marzieh Zare"
      ],
      "abstract": "Industrial projects rely heavily on lengthy, complex specification documents,\nmaking tedious manual extraction of structured information a major bottleneck.\nThis paper introduces an innovative approach to automate this process,\nleveraging the capabilities of two cutting-edge AI models: Donut, a model that\nextracts information directly from scanned documents without OCR, and OpenAI\nGPT-3.5 Turbo, a robust large language model. The proposed methodology is\ninitiated by acquiring the table of contents (ToCs) from construction\nspecification documents and subsequently structuring the ToCs text into JSON\ndata. Remarkable accuracy is achieved, with Donut reaching 85% and GPT-3.5\nTurbo reaching 89% in effectively organizing the ToCs. This landmark\nachievement represents a significant leap forward in document indexing,\ndemonstrating the immense potential of AI to automate information extraction\ntasks across diverse document types, boosting efficiency and liberating\ncritical resources in various industries.",
      "tldr_zh": "这篇论文提出了一种创新方法，使用 Donut 和 GPT-3.5 Turbo 模型来自动化提取和结构化工业规范文档的目录（ToCs），以解决手动信息提取的低效问题。Donut 模型能够直接从扫描文档中获取信息，而无需 OCR，并结合 GPT-3.5 Turbo 将 ToCs 文本转化为 JSON 格式。实验结果显示，Donut 的准确率达到 85%，GPT-3.5 Turbo 的准确率达到 89%，显著提升了文档索引的效率。该方法标志着 AI 在信息提取领域的重大进展，有望在各种行业中解放资源并提高生产力。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.IR",
      "comment": "Document AI, Document Classification, Information extraction, Large\n  Language Models, OCR Models, Visual Document Understanding",
      "pdf_url": "http://arxiv.org/pdf/2403.07553v1",
      "published_date": "2024-03-12 11:39:18 UTC",
      "updated_date": "2024-03-12 11:39:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:45:43.006636"
    },
    {
      "arxiv_id": "2403.07548v2",
      "title": "Online Continual Learning For Interactive Instruction Following Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Byeonghwi Kim",
        "Minhyuk Seo",
        "Jonghyun Choi"
      ],
      "abstract": "In learning an embodied agent executing daily tasks via language directives,\nthe literature largely assumes that the agent learns all training data at the\nbeginning. We argue that such a learning scenario is less realistic since a\nrobotic agent is supposed to learn the world continuously as it explores and\nperceives it. To take a step towards a more realistic embodied agent learning\nscenario, we propose two continual learning setups for embodied agents;\nlearning new behaviors (Behavior Incremental Learning, Behavior-IL) and new\nenvironments (Environment Incremental Learning, Environment-IL) For the tasks,\nprevious 'data prior' based continual learning methods maintain logits for the\npast tasks. However, the stored information is often insufficiently learned\ninformation and requires task boundary information, which might not always be\navailable. Here, we propose to update them based on confidence scores without\ntask boundary information during training (i.e., task-free) in a moving average\nfashion, named Confidence-Aware Moving Average (CAMA). In the proposed\nBehavior-IL and Environment-IL setups, our simple CAMA outperforms prior state\nof the art in our empirical validations by noticeable margins. The project page\nincluding codes is https://github.com/snumprlab/cl-alfred.",
      "tldr_zh": "这篇论文探讨了交互式指令遵循智能体的在线持续学习（Online Continual Learning），强调机器人应在探索过程中持续学习新行为和新环境，而非一次性学习所有数据。作者提出两种持续学习设置：Behavior Incremental Learning (Behavior-IL) 用于学习新行为，以及 Environment Incremental Learning (Environment-IL) 用于适应新环境。针对现有方法的不足，他们引入了 Confidence-Aware Moving Average (CAMA) 技术，通过置信度分数在训练中无任务边界地更新模型（task-free）。实验验证显示，CAMA 在这些设置中显著优于现有最先进方法，提供了一个更现实的智能体学习框架。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "ICLR 2024 (Project page:\n  https://bhkim94.github.io/projects/CL-ALFRED)",
      "pdf_url": "http://arxiv.org/pdf/2403.07548v2",
      "published_date": "2024-03-12 11:33:48 UTC",
      "updated_date": "2024-03-13 02:31:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:45:55.433726"
    },
    {
      "arxiv_id": "2403.07540v2",
      "title": "WannaLaugh: A Configurable Ransomware Emulator -- Learning to Mimic Malicious Storage Traces",
      "title_zh": "W",
      "authors": [
        "Dionysios Diamantopoulos",
        "Roman Pletka",
        "Slavisa Sarafijanovic",
        "A. L. Narasimha Reddy",
        "Haris Pozidis"
      ],
      "abstract": "Ransomware, a fearsome and rapidly evolving cybersecurity threat, continues\nto inflict severe consequences on individuals and organizations worldwide.\nTraditional detection methods, reliant on static signatures and application\nbehavioral patterns, are challenged by the dynamic nature of these threats.\nThis paper introduces three primary contributions to address this challenge.\nFirst, we introduce a ransomware emulator. This tool is designed to safely\nmimic ransomware attacks without causing actual harm or spreading malware,\nmaking it a unique solution for studying ransomware behavior. Second, we\ndemonstrate how we use this emulator to create storage I/O traces. These traces\nare then utilized to train machine-learning models. Our results show that these\nmodels are effective in detecting ransomware, highlighting the practical\napplication of our emulator in developing responsible cybersecurity tools.\nThird, we show how our emulator can be used to mimic the I/O behavior of\nexisting ransomware thereby enabling safe trace collection. Both the emulator\nand its application represent significant steps forward in ransomware detection\nin the era of machine-learning-driven cybersecurity.",
      "tldr_zh": "这篇论文针对勒索软件（Ransomware）的动态威胁和传统检测方法的局限性，提出了三个主要贡献。首先，引入了一个可配置的勒索软件仿真器（emulator），能够安全模仿攻击行为而不造成实际伤害。其次，利用该仿真器生成存储 I/O 痕迹（storage I/O traces），并以此训练机器学习模型，结果显示这些模型在检测勒索软件方面表现出色。第三，展示了仿真器如何模仿现有勒索软件的 I/O 行为，从而实现安全的痕迹收集，这些进展为机器学习驱动的网络安全时代提供了可靠的工具。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.07540v2",
      "published_date": "2024-03-12 11:26:58 UTC",
      "updated_date": "2024-06-12 14:52:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:46:07.731698"
    },
    {
      "arxiv_id": "2404.15284v1",
      "title": "Global 4D Ionospheric STEC Prediction based on DeepONet for GNSS Rays",
      "title_zh": "翻译失败",
      "authors": [
        "Dijia Cai",
        "Zenghui Shi",
        "Haiyang Fu",
        "Huan Liu",
        "Hongyi Qian",
        "Yun Sui",
        "Feng Xu",
        "Ya-Qiu Jin"
      ],
      "abstract": "The ionosphere is a vitally dynamic charged particle region in the Earth's\nupper atmosphere, playing a crucial role in applications such as radio\ncommunication and satellite navigation. The Slant Total Electron Contents\n(STEC) is an important parameter for characterizing wave propagation,\nrepresenting the integrated electron density along the ray of radio signals\npassing through the ionosphere. The accurate prediction of STEC is essential\nfor mitigating the ionospheric impact particularly on Global Navigation\nSatellite Systems (GNSS). In this work, we propose a high-precision STEC\nprediction model named DeepONet-STEC, which learns nonlinear operators to\npredict the 4D temporal-spatial integrated parameter for specified ground\nstation - satellite ray path globally. As a demonstration, we validate the\nperformance of the model based on GNSS observation data for global and US-CORS\nregimes under ionospheric quiet and storm conditions. The DeepONet-STEC model\nresults show that the three-day 72 hour prediction in quiet periods could\nachieve high accuracy using observation data by the Precise Point Positioning\n(PPP) with temporal resolution 30s. Under active solar magnetic storm periods,\nthe DeepONet-STEC also demonstrated its robustness and superiority than\ntraditional deep learning methods. This work presents a neural operator\nregression architecture for predicting the 4D temporal-spatial ionospheric\nparameter for satellite navigation system performance, which may be further\nextended for various space applications and beyond.",
      "tldr_zh": "该研究针对电离层对全球导航卫星系统(GNSS)的影响，提出了一种高精度STEC(Slant Total Electron Content)预测模型DeepONet-STEC。模型利用DeepONet神经算子学习非线性算子，实现全球指定地面站-卫星射线路径的4D时空整合参数预测，并基于GNSS观测数据在全球和US-CORS区域进行验证。实验结果显示，在电离层平静期，三天72小时预测可达高准确性（使用Precise Point Positioning, PPP数据，时间分辨率30秒），而在太阳磁暴活跃期，DeepONet-STEC比传统深度学习方法更具鲁棒性。该框架为提升卫星导航性能提供了新架构，并可扩展至其他空间应用。",
      "categories": [
        "eess.SP",
        "cs.AI"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.15284v1",
      "published_date": "2024-03-12 10:51:38 UTC",
      "updated_date": "2024-03-12 10:51:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:46:18.334717"
    },
    {
      "arxiv_id": "2403.07510v1",
      "title": "Relevance Score: A Landmark-Like Heuristic for Planning",
      "title_zh": "翻译失败",
      "authors": [
        "Oliver Kim",
        "Mohan Sridharan"
      ],
      "abstract": "Landmarks are facts or actions that appear in all valid solutions of a\nplanning problem. They have been used successfully to calculate heuristics that\nguide the search for a plan. We investigate an extension to this concept by\ndefining a novel \"relevance score\" that helps identify facts or actions that\nappear in most but not all plans to achieve any given goal. We describe an\napproach to compute this relevance score and use it as a heuristic in the\nsearch for a plan. We experimentally compare the performance of our approach\nwith that of a state of the art landmark-based heuristic planning approach\nusing benchmark planning problems. While the original landmark-based heuristic\nleads to better performance on problems with well-defined landmarks, our\napproach substantially improves performance on problems that lack non-trivial\nlandmarks.",
      "tldr_zh": "该论文引入了“relevance score”作为一种类似于landmarks的启发式方法，用于识别在大多数但非所有规划解决方案中出现的事实或动作，从而提升规划搜索效率。研究者描述了计算relevance score的算法，并将其作为heuristic应用于规划问题。实验结果显示，与现有的landmark-based heuristic相比，该方法在缺乏非平凡landmarks的基准问题上显著提高了性能，尽管在有明确landmarks的问题上原方法更占优势。",
      "categories": [
        "cs.AI",
        "I.2.8"
      ],
      "primary_category": "cs.AI",
      "comment": "12 Pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.07510v1",
      "published_date": "2024-03-12 10:45:45 UTC",
      "updated_date": "2024-03-12 10:45:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:46:29.752960"
    },
    {
      "arxiv_id": "2403.07500v1",
      "title": "Block-wise LoRA: Revisiting Fine-grained LoRA for Effective Personalization and Stylization in Text-to-Image Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Likun Li",
        "Haoqi Zeng",
        "Changpeng Yang",
        "Haozhe Jia",
        "Di Xu"
      ],
      "abstract": "The objective of personalization and stylization in text-to-image is to\ninstruct a pre-trained diffusion model to analyze new concepts introduced by\nusers and incorporate them into expected styles. Recently, parameter-efficient\nfine-tuning (PEFT) approaches have been widely adopted to address this task and\nhave greatly propelled the development of this field. Despite their popularity,\nexisting efficient fine-tuning methods still struggle to achieve effective\npersonalization and stylization in T2I generation. To address this issue, we\npropose block-wise Low-Rank Adaptation (LoRA) to perform fine-grained\nfine-tuning for different blocks of SD, which can generate images faithful to\ninput prompts and target identity and also with desired style. Extensive\nexperiments demonstrate the effectiveness of the proposed method.",
      "tldr_zh": "该论文针对文本到图像（T2I）生成中的个性化（personalization）和风格化（stylization）挑战，提出了一种改进的参数高效微调（PEFT）方法，即 block-wise Low-Rank Adaptation (LoRA)。该方法通过对 Stable Diffusion (SD) 的不同块进行细粒度微调，确保生成的图像忠实于输入提示、目标身份和期望风格。实验结果表明，该方法在提升图像生成质量方面比现有方法更有效。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.07500v1",
      "published_date": "2024-03-12 10:38:03 UTC",
      "updated_date": "2024-03-12 10:38:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:46:42.379882"
    },
    {
      "arxiv_id": "2403.07483v2",
      "title": "DiabetesNet: A Deep Learning Approach to Diabetes Diagnosis",
      "title_zh": "DiabetesNet: 一种深度学习方法用于糖尿病诊断",
      "authors": [
        "Zeyu Zhang",
        "Khandaker Asif Ahmed",
        "Md Rakibul Hasan",
        "Tom Gedeon",
        "Md Zakir Hossain"
      ],
      "abstract": "Diabetes, resulting from inadequate insulin production or utilization, causes\nextensive harm to the body. Existing diagnostic methods are often invasive and\ncome with drawbacks, such as cost constraints. Although there are machine\nlearning models like Classwise k Nearest Neighbor (CkNN) and General Regression\nNeural Network (GRNN), they struggle with imbalanced data and result in\nunder-performance. Leveraging advancements in sensor technology and machine\nlearning, we propose a non-invasive diabetes diagnosis using a Back Propagation\nNeural Network (BPNN) with batch normalization, incorporating data re-sampling\nand normalization for class balancing. Our method addresses existing challenges\nsuch as limited performance associated with traditional machine learning.\nExperimental results on three datasets show significant improvements in overall\naccuracy, sensitivity, and specificity compared to traditional methods.\nNotably, we achieve accuracies of 89.81% in Pima diabetes dataset, 75.49% in\nCDC BRFSS2015 dataset, and 95.28% in Mesra Diabetes dataset. This underscores\nthe potential of deep learning models for robust diabetes diagnosis. See\nproject website https://steve-zeyu-zhang.github.io/DiabetesDiagnosis/",
      "tldr_zh": "这篇论文提出了一种名为 DiabetesNet 的深度学习方法，用于非侵入式糖尿病诊断，以解决传统方法的侵入性、成本高和处理不平衡数据（如 CkNN 和 GRNN 模型的不足）的问题。方法基于 Back Propagation Neural Network (BPNN)，结合 batch normalization、数据重采样和归一化来平衡类别并提升性能。在三个数据集上的实验结果显示，准确率显著提高：Pima 糖尿病数据集达 89.81%，CDC BRFSS2015 数据集达 75.49%，Mesra Diabetes 数据集达 95.28%，并在整体准确率、敏感性和特异性方面优于传统方法。这突显了深度学习模型在糖尿病诊断中的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to ACIIDS 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.07483v2",
      "published_date": "2024-03-12 10:18:59 UTC",
      "updated_date": "2024-09-21 06:40:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:46:56.546757"
    },
    {
      "arxiv_id": "2403.07440v3",
      "title": "Matrix-Transformation Based Low-Rank Adaptation (MTLoRA): A Brain-Inspired Method for Parameter-Efficient Fine-Tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Yao Liang",
        "Yuwei Wang",
        "Yang Li",
        "Yi Zeng"
      ],
      "abstract": "Fine-tuning techniques based on Large Pretrained Language Models (LPLMs) have\nbeen proven to significantly enhance model performance on a variety of\ndownstream tasks and effectively control the output behaviors of LPLMs. Recent\nstudies have proposed numerous methods for fine-tuning a small number of\nparameters based on open-source LPLMs, reducing the demand for computational\nand storage resources. Among these, reparameterization fine-tuning methods\nrepresented by LoRA (Low-Rank Adaptation) have gained popularity. We find that\nalthough these methods perform well in many aspects, there is still\nconsiderable room for improvement in terms of complex task adaptability,\nperformance, stability, and algorithm complexity. In response to this, inspired\nby the idea that the functions of the brain are shaped by its geometric\nstructure, this paper integrates this idea into LoRA technology and proposes a\nnew matrix transformation-based reparameterization method for efficient\nfine-tuning, named Matrix-Transformation based Low-Rank Adaptation (MTLoRA).\nMTLoRA aims to dynamically alter its spatial geometric structure by applying a\ntransformation-matrix T to perform linear transformations, such as rotation,\nscaling, and translation, on the task-specific parameter matrix, generating new\nmatrix feature patterns (eigenvectors) to mimic the fundamental influence of\ncomplex geometric structure feature patterns in the brain on functions, thereby\nenhancing the model's performance in downstream tasks. In Natural Language\nUnderstanding (NLU) tasks, it is evaluated using the GLUE benchmark test, and\nthe results reveal that MTLoRA achieves an overall performance increase of\nabout 1.0% across eight tasks; in Natural Language Generation (NLG) tasks,\nMTLoRA improves performance by an average of 0.95% and 0.56% in the DART and\nWebNLG tasks, respectively.",
      "tldr_zh": "本论文提出了一种受脑几何结构启发的参数高效微调方法，名为 Matrix-Transformation based Low-Rank Adaptation (MTLoRA)，旨在改进现有 LoRA (Low-Rank Adaptation) 技术，以提升大型预训练语言模型 (LPLMs) 在下游任务中的性能和稳定性。MTLoRA 通过应用变换矩阵 T 对任务特定参数矩阵进行线性变换（如旋转、缩放和平移），动态改变其空间几何结构，生成新的矩阵特征模式 (eigenvectors)，从而更好地模拟脑功能的复杂性。实验结果显示，在 Natural Language Understanding (NLU) 任务上，MTLoRA 在 GLUE 基准测试的八个任务中整体性能提升约 1.0%；在 Natural Language Generation (NLG) 任务上，在 DART 和 WebNLG 任务中分别提升 0.95% 和 0.56%。这一方法显著提高了模型在复杂任务的适应性和算法效率，为资源受限的微调场景提供了新途径。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.07440v3",
      "published_date": "2024-03-12 09:32:25 UTC",
      "updated_date": "2024-03-30 04:36:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:47:11.969831"
    },
    {
      "arxiv_id": "2403.09722v2",
      "title": "Enhancing Readmission Prediction with Deep Learning: Extracting Biomedical Concepts from Clinical Texts",
      "title_zh": "使用深度学习提升",
      "authors": [
        "Rasoul Samani",
        "Mohammad Dehghani",
        "Fahime Shahrokh"
      ],
      "abstract": "Hospital readmission, defined as patients being re-hospitalized shortly after\ndischarge, is a critical concern as it impacts patient outcomes and healthcare\ncosts. Identifying patients at risk of readmission allows for timely\ninterventions, reducing re-hospitalization rates and overall treatment costs.\nThis study focuses on predicting patient readmission within less than 30 days\nusing text mining techniques applied to discharge report texts from electronic\nhealth records (EHR). Various machine learning and deep learning methods were\nemployed to develop a classification model for this purpose. A novel aspect of\nthis research involves leveraging the Bio-Discharge Summary Bert (BDSS) model\nalong with principal component analysis (PCA) feature extraction to preprocess\ndata for deep learning model input. Our analysis of the MIMIC-III dataset\nindicates that our approach, which combines the BDSS model with a multilayer\nperceptron (MLP), outperforms state-of-the-art methods. This model achieved a\nrecall of 94% and an area under the curve (AUC) of 75%, showcasing its\neffectiveness in predicting patient readmissions. This study contributes to the\nadvancement of predictive modeling in healthcare by integrating text mining\ntechniques with deep learning algorithms to improve patient outcomes and\noptimize resource allocation.",
      "tldr_zh": "这项研究针对医院患者在出院后不到30天内再次入院的预测问题，旨在通过文本挖掘技术分析电子健康记录(EHR)中的出院报告文本，以识别高风险患者并降低医疗成本。研究采用Bio-Discharge Summary Bert (BDSS)模型结合主成分分析(PCA)进行数据预处理，然后使用多层感知器(MLP)构建分类模型。实验结果显示，在MIMIC-III数据集上，该方法优于现有基准模型，实现了94%的recall和75%的AUC。总体而言，此工作推进了医疗预测建模，通过整合文本挖掘和深度学习算法改善患者结果并优化资源分配。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.09722v2",
      "published_date": "2024-03-12 09:03:44 UTC",
      "updated_date": "2024-04-06 10:39:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:47:22.313958"
    },
    {
      "arxiv_id": "2403.07959v2",
      "title": "An Interpretable Generalization Mechanism for Accurately Detecting Anomaly and Identifying Networking Intrusion Techniques",
      "title_zh": "可解释的泛化机制，用于准确检测异常并识别网络入侵技术",
      "authors": [
        "Hao-Ting Pai",
        "Yu-Hsuan Kang",
        "Wen-Cheng Chung"
      ],
      "abstract": "Recent advancements in Intrusion Detection Systems (IDS), integrating\nExplainable AI (XAI) methodologies, have led to notable improvements in system\nperformance via precise feature selection. However, a thorough understanding of\ncyber-attacks requires inherently explainable decision-making processes within\nIDS. In this paper, we present the Interpretable Generalization Mechanism (IG),\npoised to revolutionize IDS capabilities. IG discerns coherent patterns, making\nit interpretable in distinguishing between normal and anomalous network\ntraffic. Further, the synthesis of coherent patterns sheds light on intricate\nintrusion pathways, providing essential insights for cybersecurity forensics.\nBy experiments with real-world datasets NSL-KDD, UNSW-NB15, and UKM-IDS20, IG\nis accurate even at a low ratio of training-to-test. With 10%-to-90%, IG\nachieves Precision (PRE)=0.93, Recall (REC)=0.94, and Area Under Curve\n(AUC)=0.94 in NSL-KDD; PRE=0.98, REC=0.99, and AUC=0.99 in UNSW-NB15; and\nPRE=0.98, REC=0.98, and AUC=0.99 in UKM-IDS20. Notably, in UNSW-NB15, IG\nachieves REC=1.0 and at least PRE=0.98 since 40%-to-60%; in UKM-IDS20, IG\nachieves REC=1.0 and at least PRE=0.88 since 20%-to-80%. Importantly, in\nUKM-IDS20, IG successfully identifies all three anomalous instances without\nprior exposure, demonstrating its generalization capabilities. These results\nand inferences are reproducible. In sum, IG showcases superior generalization\nby consistently performing well across diverse datasets and training-to-test\nratios (from 10%-to-90% to 90%-to-10%), and excels in identifying novel\nanomalies without prior exposure. Its interpretability is enhanced by coherent\nevidence that accurately distinguishes both normal and anomalous activities,\nsignificantly improving detection accuracy and reducing false alarms, thereby\nstrengthening IDS reliability and trustworthiness.",
      "tldr_zh": "本文提出 Interpretable Generalization Mechanism (IG)，一个可解释的机制，用于提升 Intrusion Detection Systems (IDS) 的准确性和 Explainable AI (XAI) 能力，通过识别连贯模式来区分正常与异常网络流量，并揭示入侵路径。IG 在真实数据集 NSL-KDD、UNSW-NB15 和 UKM-IDS20 上实验显示，即使在低训练比（如 10%-to-90%）下，也表现出色，例如 NSL-KDD 的 Precision (PRE)=0.93, Recall (REC)=0.94, 和 Area Under Curve (AUC)=0.94。关键发现包括 IG 的强大泛化能力，能识别未见过的异常（如在 UKM-IDS20 上实现 REC=1.0），从而显著降低误报率并增强 IDS 的可靠性和可信度。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.07959v2",
      "published_date": "2024-03-12 09:01:04 UTC",
      "updated_date": "2024-11-05 07:14:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:47:35.855759"
    },
    {
      "arxiv_id": "2403.09721v1",
      "title": "A Semantic Mention Graph Augmented Model for Document-Level Event Argument Extraction",
      "title_zh": "语义提及图增强模型用于文档级事件参数提取",
      "authors": [
        "Jian Zhang",
        "Changlin Yang",
        "Haiping Zhu",
        "Qika Lin",
        "Fangzhi Xu",
        "Jun Liu"
      ],
      "abstract": "Document-level Event Argument Extraction (DEAE) aims to identify arguments\nand their specific roles from an unstructured document. The advanced approaches\non DEAE utilize prompt-based methods to guide pre-trained language models\n(PLMs) in extracting arguments from input documents. They mainly concentrate on\nestablishing relations between triggers and entity mentions within documents,\nleaving two unresolved problems: a) independent modeling of entity mentions; b)\ndocument-prompt isolation. To this end, we propose a semantic mention Graph\nAugmented Model (GAM) to address these two problems in this paper. Firstly, GAM\nconstructs a semantic mention graph that captures relations within and between\ndocuments and prompts, encompassing co-existence, co-reference and co-type\nrelations. Furthermore, we introduce an ensembled graph transformer module to\naddress mentions and their three semantic relations effectively. Later, the\ngraph-augmented encoder-decoder module incorporates the relation-specific graph\ninto the input embedding of PLMs and optimizes the encoder section with\ntopology information, enhancing the relations comprehensively. Extensive\nexperiments on the RAMS and WikiEvents datasets demonstrate the effectiveness\nof our approach, surpassing baseline methods and achieving a new\nstate-of-the-art performance.",
      "tldr_zh": "本研究针对文档级事件参数抽取(Document-Level Event Argument Extraction, DEAE)的问题，提出了一种语义提及图增强模型(Semantic Mention Graph Augmented Model, GAM)，以解决实体提及的独立建模和文档-提示隔离的不足。GAM 通过构建语义提及图来捕捉文档和提示间的共存(co-existence)、共指(co-reference)和共类型(co-type)关系，并引入集成图变换器模块(ensembled graph transformer module)以及图增强的编码器-解码器模块(graph-augmented encoder-decoder module)，从而优化预训练语言模型(PLMs)的输入嵌入和拓扑信息。在 RAMS 和 WikiEvents 数据集上的广泛实验表明，该方法超越了基线模型，实现了新的最先进性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted By Coling 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.09721v1",
      "published_date": "2024-03-12 08:58:07 UTC",
      "updated_date": "2024-03-12 08:58:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:47:46.694821"
    },
    {
      "arxiv_id": "2403.09720v1",
      "title": "Fine-tuning vs Prompting, Can Language Models Understand Human Values?",
      "title_zh": "翻译失败",
      "authors": [
        "Pingwei Sun"
      ],
      "abstract": "Accurately handling the underlying support values in sentences is crucial for\nunderstanding the speaker's tendencies, yet it poses a challenging task in\nnatural language understanding (NLU). In this article, we explore the potential\nof fine-tuning and prompt tuning in this downstream task, using the Human Value\nDetection 2023. Additionally, we attempt to validate whether models can\neffectively solve the problem based on the knowledge acquired during the\npre-training stage. Simultaneously, our interest lies in the capabilities of\nlarge language models (LLMs) aligned with RLHF in this task, and some\npreliminary attempts are presented.",
      "tldr_zh": "本研究探讨了语言模型是否能理解人类价值观，特别是处理句子中底层支持值（underlying support values）以把握说话者倾向性的挑战。作者比较了 fine-tuning 和 prompt tuning 在 Human Value Detection 2023 数据集上的表现，并验证了模型是否能依赖预训练阶段的知识来解决问题。同时，研究评估了与 RLHF 对齐的大型语言模型 (LLMs) 在此任务中的能力，并进行了初步尝试，以揭示语言模型的潜在局限性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.09720v1",
      "published_date": "2024-03-12 08:49:31 UTC",
      "updated_date": "2024-03-12 08:49:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:47:58.570904"
    },
    {
      "arxiv_id": "2403.09719v1",
      "title": "Mevaker: Conclusion Extraction and Allocation Resources for the Hebrew Language",
      "title_zh": "翻译失败",
      "authors": [
        "Vitaly Shalumov",
        "Harel Haskey",
        "Yuval Solaz"
      ],
      "abstract": "In this paper, we introduce summarization MevakerSumm and conclusion\nextraction MevakerConc datasets for the Hebrew language based on the State\nComptroller and Ombudsman of Israel reports, along with two auxiliary datasets.\nWe accompany these datasets with models for conclusion extraction (HeConE,\nHeConEspc) and conclusion allocation (HeCross). All of the code, datasets, and\nmodel checkpoints used in this work are publicly available.",
      "tldr_zh": "本论文为希伯来语(Hebrew)引入了MevakerSumm数据集（用于摘要）和MevakerConc数据集（用于结论提取），这些数据集基于以色列国家审计长和监察员报告，并附带两个辅助数据集。论文还开发了相应的模型，包括HeConE和HeConEspc用于结论提取，以及HeCross用于结论分配。所有代码、数据集和模型检查点均公开可用，以支持希伯来语自然语言处理研究的进一步发展。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.09719v1",
      "published_date": "2024-03-12 08:40:44 UTC",
      "updated_date": "2024-03-12 08:40:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:48:09.916049"
    },
    {
      "arxiv_id": "2403.07404v3",
      "title": "Improving Continual Learning Performance and Efficiency with Auxiliary Classifiers",
      "title_zh": "通过辅助分类器提升持续学习的性能和效率",
      "authors": [
        "Filip Szatkowski",
        "Yaoyue Zheng",
        "Fei Yang",
        "Bartłomiej Twardowski",
        "Tomasz Trzciński",
        "Joost van de Weijer"
      ],
      "abstract": "Continual learning is crucial for applying machine learning in challenging,\ndynamic, and often resource-constrained environments. However, catastrophic\nforgetting - overwriting previously learned knowledge when new information is\nacquired - remains a major challenge. In this work, we examine the intermediate\nrepresentations in neural network layers during continual learning and find\nthat such representations are less prone to forgetting, highlighting their\npotential to accelerate computation. Motivated by these findings, we propose to\nuse auxiliary classifiers(ACs) to enhance performance and demonstrate that\nintegrating ACs into various continual learning methods consistently improves\naccuracy across diverse evaluation settings, yielding an average 10% relative\ngain. We also leverage the ACs to reduce the average cost of the inference by\n10-60% without compromising accuracy, enabling the model to return the\npredictions before computing all the layers. Our approach provides a scalable\nand efficient solution for continual learning.",
      "tldr_zh": "本研究针对持续学习（continual learning）中的灾难性遗忘（catastrophic forgetting）问题，通过分析神经网络中间表示层，发现这些层不易遗忘，从而提出使用辅助分类器（auxiliary classifiers, ACs）来提升性能和效率。作者将 ACs 整合到各种持续学习方法中，实验结果显示在不同评估设置下准确率平均提高 10%。此外，该方法还能将推理成本降低 10-60%，在不牺牲准确性的前提下，提供了一个可扩展且高效的持续学习解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ICML 2025",
      "pdf_url": "http://arxiv.org/pdf/2403.07404v3",
      "published_date": "2024-03-12 08:33:26 UTC",
      "updated_date": "2025-05-02 14:03:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:48:22.029694"
    },
    {
      "arxiv_id": "2403.07403v1",
      "title": "From Canteen Food to Daily Meals: Generalizing Food Recognition to More Practical Scenarios",
      "title_zh": "翻译失败",
      "authors": [
        "Guoshan Liu",
        "Yang Jiao",
        "Jingjing Chen",
        "Bin Zhu",
        "Yu-Gang Jiang"
      ],
      "abstract": "The precise recognition of food categories plays a pivotal role for\nintelligent health management, attracting significant research attention in\nrecent years. Prominent benchmarks, such as Food-101 and VIREO Food-172,\nprovide abundant food image resources that catalyze the prosperity of research\nin this field. Nevertheless, these datasets are well-curated from canteen\nscenarios and thus deviate from food appearances in daily life. This\ndiscrepancy poses great challenges in effectively transferring classifiers\ntrained on these canteen datasets to broader daily-life scenarios encountered\nby humans. Toward this end, we present two new benchmarks, namely DailyFood-172\nand DailyFood-16, specifically designed to curate food images from everyday\nmeals. These two datasets are used to evaluate the transferability of\napproaches from the well-curated food image domain to the everyday-life food\nimage domain. In addition, we also propose a simple yet effective baseline\nmethod named Multi-Cluster Reference Learning (MCRL) to tackle the\naforementioned domain gap. MCRL is motivated by the observation that food\nimages in daily-life scenarios exhibit greater intra-class appearance variance\ncompared with those in well-curated benchmarks. Notably, MCRL can be seamlessly\ncoupled with existing approaches, yielding non-trivial performance\nenhancements. We hope our new benchmarks can inspire the community to explore\nthe transferability of food recognition models trained on well-curated datasets\ntoward practical real-life applications.",
      "tldr_zh": "该研究指出，现有的食物识别基准数据集（如 Food-101 和 VIREO Food-172）主要基于餐厅场景，无法有效泛化到日常生活中的食物图像，导致模型转移挑战。论文引入两个新数据集，DailyFood-172 和 DailyFood-16，用于评估从整理良好领域到日常领域的转移能力，并提出了一种简单有效的基线方法 Multi-Cluster Reference Learning (MCRL)，该方法针对日常食物图像的更大内部类变异性，通过多聚类参考学习桥接领域差距。实验结果显示，MCRL 可与现有方法无缝结合，显著提升性能，并有望激励社区探索食物识别模型在实际应用的推广。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.07403v1",
      "published_date": "2024-03-12 08:32:23 UTC",
      "updated_date": "2024-03-12 08:32:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:48:34.707874"
    },
    {
      "arxiv_id": "2403.07958v1",
      "title": "Temporal Decisions: Leveraging Temporal Correlation for Efficient Decisions in Early Exit Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Max Sponner",
        "Lorenzo Servadei",
        "Bernd Waschneck",
        "Robert Wille",
        "Akash Kumar"
      ],
      "abstract": "Deep Learning is becoming increasingly relevant in Embedded and\nInternet-of-things applications. However, deploying models on embedded devices\nposes a challenge due to their resource limitations. This can impact the\nmodel's inference accuracy and latency. One potential solution are Early Exit\nNeural Networks, which adjust model depth dynamically through additional\nclassifiers attached between their hidden layers. However, the real-time\ntermination decision mechanism is critical for the system's efficiency,\nlatency, and sustained accuracy.\n  This paper introduces Difference Detection and Temporal Patience as decision\nmechanisms for Early Exit Neural Networks. They leverage the temporal\ncorrelation present in sensor data streams to efficiently terminate the\ninference. We evaluate their effectiveness in health monitoring, image\nclassification, and wake-word detection tasks. Our novel contributions were\nable to reduce the computational footprint compared to established decision\nmechanisms significantly while maintaining higher accuracy scores. We achieved\na reduction of mean operations per inference by up to 80% while maintaining\naccuracy levels within 5% of the original model.\n  These findings highlight the importance of considering temporal correlation\nin sensor data to improve the termination decision.",
      "tldr_zh": "本文提出了一种名为 Temporal Decisions 的方法，用于优化 Early Exit Neural Networks 的决策机制，通过利用传感器数据流中的 Temporal Correlation 来提高推理效率。具体而言，该方法引入 Difference Detection 和 Temporal Patience 机制，帮助动态终止推理过程，从而减少计算开销。实验在健康监测、图像分类和唤醒词检测任务上验证了其有效性，与现有机制相比，平均操作量减少高达80%，同时保持准确性在原模型的5%以内。这些发现强调了时间相关性在提升嵌入式设备上模型性能的重要性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.07958v1",
      "published_date": "2024-03-12 08:28:27 UTC",
      "updated_date": "2024-03-12 08:28:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:48:45.609374"
    },
    {
      "arxiv_id": "2403.07957v1",
      "title": "Efficient Post-Training Augmentation for Adaptive Inference in Heterogeneous and Distributed IoT Environments",
      "title_zh": "翻译失败",
      "authors": [
        "Max Sponner",
        "Lorenzo Servadei",
        "Bernd Waschneck",
        "Robert Wille",
        "Akash Kumar"
      ],
      "abstract": "Early Exit Neural Networks (EENNs) present a solution to enhance the\nefficiency of neural network deployments. However, creating EENNs is\nchallenging and requires specialized domain knowledge, due to the large amount\nof additional design choices. To address this issue, we propose an automated\naugmentation flow that focuses on converting an existing model into an EENN. It\nperforms all required design decisions for the deployment to heterogeneous or\ndistributed hardware targets: Our framework constructs the EENN architecture,\nmaps its subgraphs to the hardware targets, and configures its decision\nmechanism. To the best of our knowledge, it is the first framework that is able\nto perform all of these steps.\n  We evaluated our approach on a collection of Internet-of-Things and standard\nimage classification use cases. For a speech command detection task, our\nsolution was able to reduce the mean operations per inference by 59.67%. For an\nECG classification task, it was able to terminate all samples early, reducing\nthe mean inference energy by 74.9% and computations by 78.3%. On CIFAR-10, our\nsolution was able to achieve up to a 58.75% reduction in computations.\n  The search on a ResNet-152 base model for CIFAR-10 took less than nine hours\non a laptop CPU. Our proposed approach enables the creation of EENN optimized\nfor IoT environments and can reduce the inference cost of Deep Learning\napplications on embedded and fog platforms, while also significantly reducing\nthe search cost - making it more accessible for scientists and engineers in\nindustry and research. The low search cost improves the accessibility of EENNs,\nwith the potential to improve the efficiency of neural networks in a wide range\nof practical applications.",
      "tldr_zh": "该论文提出了一种高效的后训练增强框架，用于在异构和分布式 IoT 环境中的自适应推理，旨在简化 Early Exit Neural Networks (EENNs) 的创建过程。该框架自动处理模型转换，包括 EENN 架构构建、子图映射到硬件目标以及决策机制配置，是首个能全面完成这些步骤的系统。实验结果显示，在语音检测任务中平均操作减少59.67%，在ECG分类任务中推理能量减少74.9%和计算减少78.3%，而在CIFAR-10上计算量减少58.75%，搜索时间仅需不到九小时。该方法显著降低了深度学习应用的推理成本，提高了在嵌入式和雾计算平台的实用性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.07957v1",
      "published_date": "2024-03-12 08:27:53 UTC",
      "updated_date": "2024-03-12 08:27:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:48:59.070563"
    },
    {
      "arxiv_id": "2404.00012v1",
      "title": "Stress index strategy enhanced with financial news sentiment analysis for the equity markets",
      "title_zh": "翻译失败",
      "authors": [
        "Baptiste Lefort",
        "Eric Benhamou",
        "Jean-Jacques Ohana",
        "David Saltiel",
        "Beatrice Guez",
        "Thomas Jacquot"
      ],
      "abstract": "This paper introduces a new risk-on risk-off strategy for the stock market,\nwhich combines a financial stress indicator with a sentiment analysis done by\nChatGPT reading and interpreting Bloomberg daily market summaries. Forecasts of\nmarket stress derived from volatility and credit spreads are enhanced when\ncombined with the financial news sentiment derived from GPT-4. As a result, the\nstrategy shows improved performance, evidenced by higher Sharpe ratio and\nreduced maximum drawdowns. The improved performance is consistent across the\nNASDAQ, the S&P 500 and the six major equity markets, indicating that the\nmethod generalises across equities markets.",
      "tldr_zh": "这篇论文提出了一种新的风险开/风险关（risk-on risk-off）策略，将金融压力指标（如波动性和信用利差）与ChatGPT对Bloomberg每日市场总结的情绪分析相结合，使用GPT-4增强新闻情绪预测。结果表明，该策略显著提升了市场压力预测的性能，表现为更高的Sharpe ratio和更低的最大回撤。改进效果在NASDAQ、S&P 500和六大主要股票市场中一致，证明了该方法的通用性。",
      "categories": [
        "q-fin.ST",
        "cs.AI",
        "cs.CL",
        "q-fin.RM"
      ],
      "primary_category": "q-fin.ST",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.00012v1",
      "published_date": "2024-03-12 08:23:30 UTC",
      "updated_date": "2024-03-12 08:23:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:49:11.932884"
    },
    {
      "arxiv_id": "2403.07398v2",
      "title": "Complex Reasoning over Logical Queries on Commonsense Knowledge Graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Tianqing Fang",
        "Zeming Chen",
        "Yangqiu Song",
        "Antoine Bosselut"
      ],
      "abstract": "Event commonsense reasoning requires the ability to reason about the\nrelationship between events, as well as infer implicit context underlying that\nrelationship. However, data scarcity makes it challenging for language models\nto learn to generate commonsense inferences for contexts and questions\ninvolving interactions between complex events. To address this demand, we\npresent COM2 (COMplex COMmonsense), a new dataset created by sampling multi-hop\nlogical queries (e.g., the joint effect or cause of both event A and B, or the\neffect of the effect of event C) from an existing commonsense knowledge graph\n(CSKG), and verbalizing them using handcrafted rules and large language models\ninto multiple-choice and text generation questions. Our experiments show that\nlanguage models trained on COM2 exhibit significant improvements in complex\nreasoning ability, resulting in enhanced zero-shot performance in both\nin-domain and out-of-domain tasks for question answering and generative\ncommonsense reasoning, without expensive human annotations. Code and data are\navailable at https://github.com/tqfang/complex-commonsense-reasoning.",
      "tldr_zh": "该研究针对事件常识推理的挑战，提出了一种处理多跳逻辑查询的方法，以克服数据稀缺和复杂事件交互的问题。研究者创建了新数据集 COM2，通过从 Commonsense Knowledge Graphs (CSKG) 中采样多跳逻辑查询（如事件 A 和 B 的联合效果），并使用手工规则和 Large Language Models (LLMs) 将其转化为多项选择和文本生成问题。实验结果显示，在 COM2 上训练的语言模型显著提升了复杂推理能力，实现零-shot 性能在问答和生成性常识推理任务上的改进，且无需昂贵的人工标注。代码和数据可从指定 GitHub 仓库获取。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "ACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.07398v2",
      "published_date": "2024-03-12 08:13:52 UTC",
      "updated_date": "2024-06-22 17:32:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:49:23.345668"
    },
    {
      "arxiv_id": "2403.07956v1",
      "title": "DeepCDCL: An CDCL-based Neural Network Verification Framework",
      "title_zh": "翻译失败",
      "authors": [
        "Zongxin Liu",
        "Pengfei Yang",
        "Lijun Zhang",
        "Xiaowei Huang"
      ],
      "abstract": "Neural networks in safety-critical applications face increasing safety and\nsecurity concerns due to their susceptibility to little disturbance. In this\npaper, we propose DeepCDCL, a novel neural network verification framework based\non the Conflict-Driven Clause Learning (CDCL) algorithm. We introduce an\nasynchronous clause learning and management structure, reducing redundant time\nconsumption compared to the direct application of the CDCL framework.\nFurthermore, we also provide a detailed evaluation of the performance of our\napproach on the ACAS Xu and MNIST datasets, showing that a significant speed-up\nis achieved in most cases.",
      "tldr_zh": "该研究针对神经网络在安全关键应用中易受小干扰的影响，提出了一种基于 CDCL (Conflict-Driven Clause Learning) 算法的验证框架 DeepCDCL。\nDeepCDCL 引入异步子句学习和管理结构，以减少冗余时间消耗并提升效率。\n实验在 ACAS Xu 和 MNIST 数据集上进行，结果显示该框架在大多数情况下实现了显著的速度提升。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.07956v1",
      "published_date": "2024-03-12 08:07:06 UTC",
      "updated_date": "2024-03-12 08:07:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:49:35.038805"
    },
    {
      "arxiv_id": "2403.07389v2",
      "title": "Auxiliary CycleGAN-guidance for Task-Aware Domain Translation from Duplex to Monoplex IHC Images",
      "title_zh": "翻译失败",
      "authors": [
        "Nicolas Brieu",
        "Nicolas Triltsch",
        "Philipp Wortmann",
        "Dominik Winter",
        "Shashank Saran",
        "Marlon Rebelatto",
        "Günter Schmidt"
      ],
      "abstract": "Generative models enable the translation from a source image domain where\nreadily trained models are available to a target domain unseen during training.\nWhile Cycle Generative Adversarial Networks (GANs) are well established, the\nassociated cycle consistency constrain relies on that an invertible mapping\nexists between the two domains. This is, however, not the case for the\ntranslation between images stained with chromogenic monoplex and duplex\nimmunohistochemistry (IHC) assays. Focusing on the translation from the latter\nto the first, we propose - through the introduction of a novel training design,\nan alternative constrain leveraging a set of immunofluorescence (IF) images as\nan auxiliary unpaired image domain. Quantitative and qualitative results on a\ndownstream segmentation task show the benefit of the proposed method in\ncomparison to baseline approaches.",
      "tldr_zh": "该论文针对从染色双重免疫组织化学(IHC)图像到单重IHC图像的域翻译问题，提出了一种基于辅助CycleGAN引导的新型训练设计，以克服传统CycleGAN的循环一致性约束（依赖于可逆映射）的局限性。该方法引入一组免疫荧光(IF)图像作为辅助非配对域，提供替代约束，从而实现任务感知的域翻译。在下游分割任务上的定量和定性结果表明，该方法比基线方法表现出显著优势，提高了翻译的准确性和适用性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV",
        "I.2.10, J.3, I.4.6"
      ],
      "primary_category": "cs.CV",
      "comment": "5 pages",
      "pdf_url": "http://arxiv.org/pdf/2403.07389v2",
      "published_date": "2024-03-12 07:57:33 UTC",
      "updated_date": "2024-10-22 14:07:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:49:47.232972"
    },
    {
      "arxiv_id": "2403.07384v2",
      "title": "SmallToLarge (S2L): Scalable Data Selection for Fine-tuning Large Language Models by Summarizing Training Trajectories of Small Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yu Yang",
        "Siddhartha Mishra",
        "Jeffrey N Chiang",
        "Baharan Mirzasoleiman"
      ],
      "abstract": "Despite the effectiveness of data selection for large language models (LLMs)\nduring pretraining and instruction fine-tuning phases, improving data\nefficiency in supervised fine-tuning (SFT) for specialized domains poses\nsignificant challenges due to the complexity of fine-tuning data. To bridge\nthis gap, we introduce an effective and scalable data selection method for SFT,\nSmallToLarge (S2L), which leverages training trajectories from small models to\nguide the data selection for larger models. We demonstrate through extensive\nexperiments that S2L significantly improves data efficiency in SFT for\nmathematical problem-solving, reducing the training data to just 11% of the\noriginal MathInstruct dataset (Yue et al., 2023) to match full dataset\nperformance while outperforming state-of-the-art data selection algorithms by\nan average of 4.7% across 6 in- and out-domain evaluation datasets. Remarkably,\nselecting only 50K data for SFT, S2L achieves a 32.7% accuracy on the most\nchallenging MATH (Hendrycks et al., 2021) benchmark, improving Phi-2 (Li et\nal., 2023b) by 16.6%. In clinical text summarization on the MIMIC-III dataset\n(Johnson et al., 2016), S2L again outperforms training on the full dataset\nusing only 50% of the data. Notably, S2L can perform data selection using a\nreference model 40x smaller than the target model, proportionally reducing the\ncost of data selection.",
      "tldr_zh": "本文提出 SmallToLarge (S2L) 方法，这是一种可扩展的数据选择技术，用于大型语言模型 (LLMs) 的监督微调 (SFT)，通过总结小模型的训练轨迹来指导数据选择，从而提高数据效率。S2L 在数学问题解决任务中，仅使用 11% 的 MathInstruct 数据集就达到全数据集性能，并平均比现有算法在 6 个评估数据集上高出 4.7%。在 MATH 基准测试中，使用仅 50K 数据，S2L 实现 32.7% 的准确率，比 Phi-2 提升 16.6%。此外，在 MIMIC-III 临床文本总结任务上，S2L 仅需 50% 数据就超过全数据集表现，并能使用比目标模型小 40 倍的参考模型，显著降低数据选择成本。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.07384v2",
      "published_date": "2024-03-12 07:45:33 UTC",
      "updated_date": "2024-12-05 18:47:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:50:02.510157"
    },
    {
      "arxiv_id": "2403.07380v1",
      "title": "Gabor-guided transformer for single image deraining",
      "title_zh": "翻译失败",
      "authors": [
        "Sijin He",
        "Guangfeng Lin"
      ],
      "abstract": "Image deraining have have gained a great deal of attention in order to\naddress the challenges posed by the effects of harsh weather conditions on\nvisual tasks. While convolutional neural networks (CNNs) are popular, their\nlimitations in capturing global information may result in ineffective rain\nremoval. Transformer-based methods with self-attention mechanisms have\nimproved, but they tend to distort high-frequency details that are crucial for\nimage fidelity. To solve this problem, we propose the Gabor-guided tranformer\n(Gabformer) for single image deraining. The focus on local texture features is\nenhanced by incorporating the information processed by the Gabor filter into\nthe query vector, which also improves the robustness of the model to noise due\nto the properties of the filter. Extensive experiments on the benchmarks\ndemonstrate that our method outperforms state-of-the-art approaches.",
      "tldr_zh": "本研究针对图像去雨（single image deraining）问题，指出传统 CNNs 在捕获全局信息方面存在局限，而 Transformer-based 方法则易扭曲高频细节。论文提出 Gabor-guided Transformer（Gabformer），通过将 Gabor filter 处理的信息融入查询向量，增强对局部纹理特征的关注并提升模型对噪声的鲁棒性。该方法在基准实验中表现出色，超越了现有最先进方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.07380v1",
      "published_date": "2024-03-12 07:41:51 UTC",
      "updated_date": "2024-03-12 07:41:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:50:11.865737"
    },
    {
      "arxiv_id": "2403.07376v2",
      "title": "NavCoT: Boosting LLM-Based Vision-and-Language Navigation via Learning Disentangled Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Bingqian Lin",
        "Yunshuang Nie",
        "Ziming Wei",
        "Jiaqi Chen",
        "Shikui Ma",
        "Jianhua Han",
        "Hang Xu",
        "Xiaojun Chang",
        "Xiaodan Liang"
      ],
      "abstract": "Vision-and-Language Navigation (VLN), as a crucial research problem of\nEmbodied AI, requires an embodied agent to navigate through complex 3D\nenvironments following natural language instructions. Recent research has\nhighlighted the promising capacity of large language models (LLMs) in VLN by\nimproving navigational reasoning accuracy and interpretability. However, their\npredominant use in an offline manner usually suffers from substantial domain\ngap between the VLN task and the LLM training corpus. This paper introduces a\nnovel strategy called Navigational Chain-of-Thought (NavCoT), where we fulfill\nparameter-efficient in-domain training to enable self-guided navigational\ndecision, leading to a significant mitigation of the domain gap in a\ncost-effective manner. Specifically, at each timestep, the LLM is prompted to\nforecast the navigational chain-of-thought by: 1) acting as a world model to\nimagine the next observation according to the instruction, 2) selecting the\ncandidate observation that best aligns with the imagination, and 3) determining\nthe action based on the reasoning from the prior steps. Through constructing\nformalized labels for training, the LLM can learn to generate desired and\nreasonable chain-of-thought outputs for improving the action decision.\nExperimental results across various training settings and popular VLN\nbenchmarks (e.g., Room-to-Room (R2R), Room-across-Room (RxR), Room-for-Room\n(R4R)) show the significant superiority of NavCoT over the direct action\nprediction variants. Through simple parameter-efficient finetuning, our NavCoT\noutperforms a recent GPT4-based approach with ~7% relative improvement on the\nR2R dataset. We believe that NavCoT will help unlock more task-adaptive and\nscalable LLM-based embodied agents, which are helpful for developing real-world\nrobotics applications. Code is available at\nhttps://github.com/expectorlin/NavCoT.",
      "tldr_zh": "本论文提出NavCoT，一种通过学习分离推理（Learning Disentangled Reasoning）来提升LLM-based Vision-and-Language Navigation (VLN)性能的策略，以缓解LLM在VLN任务中的领域差距问题。NavCoT采用参数高效的在域训练方法，在每个时间步引导LLM进行链式思维：首先作为世界模型想象下一个观察、其次选择与想象最匹配的候选观察、最后基于推理决定行动，从而生成更合理的推理输出并改善导航决策。在多个VLN基准测试（如R2R、RxR、R4R）中，NavCoT显著优于直接行动预测方法，通过简单微调在R2R数据集上较GPT4-based方法提升约7%，为开发任务适应性和可扩展的LLM-based embodied agents提供新路径，支持真实世界机器人应用。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by TPAMI 2025",
      "pdf_url": "http://arxiv.org/pdf/2403.07376v2",
      "published_date": "2024-03-12 07:27:02 UTC",
      "updated_date": "2025-03-22 11:04:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:50:25.199126"
    },
    {
      "arxiv_id": "2403.09718v1",
      "title": "Comprehensive Implementation of TextCNN for Enhanced Collaboration between Natural Language Processing and System Recommendation",
      "title_zh": "TextCNN 的全面实施，用于增强自然语言",
      "authors": [
        "Xiaonan Xu",
        "Zheng Xu",
        "Zhipeng Ling",
        "Zhengyu Jin",
        "ShuQian Du"
      ],
      "abstract": "Natural Language Processing (NLP) is an important branch of artificial\nintelligence that studies how to enable computers to understand, process, and\ngenerate human language. Text classification is a fundamental task in NLP,\nwhich aims to classify text into different predefined categories. Text\nclassification is the most basic and classic task in natural language\nprocessing, and most of the tasks in natural language processing can be\nregarded as classification tasks. In recent years, deep learning has achieved\ngreat success in many research fields, and today, it has also become a standard\ntechnology in the field of NLP, which is widely integrated into text\nclassification tasks. Unlike numbers and images, text processing emphasizes\nfine-grained processing ability. Traditional text classification methods\ngenerally require preprocessing the input model's text data. Additionally, they\nalso need to obtain good sample features through manual annotation and then use\nclassical machine learning algorithms for classification. Therefore, this paper\nanalyzes the application status of deep learning in the three core tasks of NLP\n(including text representation, word order modeling, and knowledge\nrepresentation). This content explores the improvement and synergy achieved\nthrough natural language processing in the context of text classification,\nwhile also taking into account the challenges posed by adversarial techniques\nin text generation, text classification, and semantic parsing. An empirical\nstudy on text classification tasks demonstrates the effectiveness of\ninteractive integration training, particularly in conjunction with TextCNN,\nhighlighting the significance of these advancements in text classification\naugmentation and enhancement.",
      "tldr_zh": "该论文探讨了深度学习在自然语言处理(NLP)中的应用，特别是TextCNN模型的全面实现，以提升NLP与系统推荐之间的协作。论文分析了深度学习在文本表示、词序建模和知识表示等核心任务中的作用，并讨论了对抗技术对文本分类、生成和语义解析带来的挑战。通过经验研究，证明了TextCNN结合交互式集成训练的有效性，能够显著增强文本分类任务的性能和准确性。总的来说，此工作为NLP领域的改进提供了新见解，促进了更高效的系统推荐整合。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.09718v1",
      "published_date": "2024-03-12 07:25:53 UTC",
      "updated_date": "2024-03-12 07:25:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:50:36.325883"
    },
    {
      "arxiv_id": "2403.07955v2",
      "title": "Towards Faithful Explanations: Boosting Rationalization with Shortcuts Discovery",
      "title_zh": "翻译失败",
      "authors": [
        "Linan Yue",
        "Qi Liu",
        "Yichao Du",
        "Li Wang",
        "Weibo Gao",
        "Yanqing An"
      ],
      "abstract": "The remarkable success in neural networks provokes the selective\nrationalization. It explains the prediction results by identifying a small\nsubset of the inputs sufficient to support them. Since existing methods still\nsuffer from adopting the shortcuts in data to compose rationales and limited\nlarge-scale annotated rationales by human, in this paper, we propose a\nShortcuts-fused Selective Rationalization (SSR) method, which boosts the\nrationalization by discovering and exploiting potential shortcuts.\nSpecifically, SSR first designs a shortcuts discovery approach to detect\nseveral potential shortcuts. Then, by introducing the identified shortcuts, we\npropose two strategies to mitigate the problem of utilizing shortcuts to\ncompose rationales. Finally, we develop two data augmentations methods to close\nthe gap in the number of annotated rationales. Extensive experimental results\non real-world datasets clearly validate the effectiveness of our proposed\nmethod.",
      "tldr_zh": "该论文针对神经网络中的选择性理性化（selective rationalization）问题，提出了一种Shortcuts-fused Selective Rationalization (SSR) 方法，以提升解释的忠实度。SSR 通过设计捷径发现（shortcuts discovery）机制来检测潜在捷径，并引入两种策略来缓解利用捷径组成理性化（rationales）的风险，同时开发两种数据增强方法以弥补大规模人工标注理性化的不足。实验结果在真实数据集上证明了该方法的有效性，显著改善了理性化的准确性和可靠性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to ICLR 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.07955v2",
      "published_date": "2024-03-12 07:24:17 UTC",
      "updated_date": "2024-07-19 04:31:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:50:47.923227"
    },
    {
      "arxiv_id": "2403.09717v1",
      "title": "Enhancing Depression-Diagnosis-Oriented Chat with Psychological State Tracking",
      "title_zh": "通过心理状态跟踪增强面向抑郁症诊断的聊天",
      "authors": [
        "Yiyang Gu",
        "Yougen Zhou",
        "Qin Chen",
        "Ningning Zhou",
        "Jie Zhou",
        "Aimin Zhou",
        "Liang He"
      ],
      "abstract": "Depression-diagnosis-oriented chat aims to guide patients in self-expression\nto collect key symptoms for depression detection. Recent work focuses on\ncombining task-oriented dialogue and chitchat to simulate the interview-based\ndepression diagnosis. Whereas, these methods can not well capture the changing\ninformation, feelings, or symptoms of the patient during dialogues. Moreover,\nno explicit framework has been explored to guide the dialogue, which results in\nsome useless communications that affect the experience. In this paper, we\npropose to integrate Psychological State Tracking (POST) within the large\nlanguage model (LLM) to explicitly guide depression-diagnosis-oriented chat.\nSpecifically, the state is adapted from a psychological theoretical model,\nwhich consists of four components, namely Stage, Information, Summary and Next.\nWe fine-tune an LLM model to generate the dynamic psychological state, which is\nfurther used to assist response generation at each turn to simulate the\npsychiatrist. Experimental results on the existing benchmark show that our\nproposed method boosts the performance of all subtasks in\ndepression-diagnosis-oriented chat.",
      "tldr_zh": "这篇论文针对抑郁症诊断聊天存在的不足，如无法捕捉患者动态信息和感受，以及缺少明确指导框架，提出将 Psychological State Tracking (POST) 整合到 Large Language Model (LLM) 中。POST 基于心理理论模型，包括 Stage, Information, Summary 和 Next 四个组件，通过微调 LLM 生成动态心理状态，并用于辅助每个对话回合的响应生成，以模拟精神科医生的行为。实验结果显示，该方法在现有基准测试中显著提升了所有子任务的性能。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.09717v1",
      "published_date": "2024-03-12 07:17:01 UTC",
      "updated_date": "2024-03-12 07:17:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:50:59.866892"
    },
    {
      "arxiv_id": "2403.07363v2",
      "title": "A New Random Forest Ensemble of Intuitionistic Fuzzy Decision Trees",
      "title_zh": "一种新的直觉模糊决策树随机森林集成",
      "authors": [
        "Yingtao Ren",
        "Xiaomin Zhu",
        "Kaiyuan Bai",
        "Runtong Zhang"
      ],
      "abstract": "Classification is essential to the applications in the field of data mining,\nartificial intelligence, and fault detection. There exists a strong need in\ndeveloping accurate, suitable, and efficient classification methods and\nalgorithms with broad applicability. Random forest is a general algorithm that\nis often used for classification under complex conditions. Although it has been\nwidely adopted, its combination with diverse fuzzy theory is still worth\nexploring. In this paper, we propose the intuitionistic fuzzy random forest\n(IFRF), a new random forest ensemble of intuitionistic fuzzy decision trees\n(IFDT). Such trees in forest use intuitionistic fuzzy information gain to\nselect features and consider hesitation in information transmission. The\nproposed method enjoys the power of the randomness from bootstrapped sampling\nand feature selection, the flexibility of fuzzy logic and fuzzy sets, and the\nrobustness of multiple classifier systems. Extensive experiments demonstrate\nthat the IFRF has competitative and superior performance compared to other\nstate-of-the-art fuzzy and ensemble algorithms. IFDT is more suitable for\nensemble learning with outstanding classification accuracy. This study is the\nfirst to propose a random forest ensemble based on the intuitionistic fuzzy\ntheory.",
      "tldr_zh": "本研究提出了一种新的随机森林集成方法，称为 Intuitionistic Fuzzy Random Forest (IFRF)，旨在提升分类任务在数据挖掘、人工智能和故障检测等领域的准确性和适用性。IFRF 由 Intuitionistic Fuzzy Decision Trees (IFDT) 组成，这些决策树使用 Intuitionistic Fuzzy Information Gain 选择特征，并考虑 hesitation in information transmission，同时利用 bootstrapped sampling 和 feature selection 的随机性。实验结果显示，IFRF 在分类准确性上比其他状态-of-the-art 模糊和集成算法更具竞争力和优越性，且 IFDT 特别适合集成学习；这是首个基于 Intuitionistic Fuzzy Theory 的随机森林集成方法。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.07363v2",
      "published_date": "2024-03-12 06:52:24 UTC",
      "updated_date": "2024-03-17 11:08:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:51:12.453800"
    },
    {
      "arxiv_id": "2403.07362v4",
      "title": "Challenging Forgets: Unveiling the Worst-Case Forget Sets in Machine Unlearning",
      "title_zh": "翻译失败",
      "authors": [
        "Chongyu Fan",
        "Jiancheng Liu",
        "Alfred Hero",
        "Sijia Liu"
      ],
      "abstract": "The trustworthy machine learning (ML) community is increasingly recognizing\nthe crucial need for models capable of selectively 'unlearning' data points\nafter training. This leads to the problem of machine unlearning (MU), aiming to\neliminate the influence of chosen data points on model performance, while still\nmaintaining the model's utility post-unlearning. Despite various MU methods for\ndata influence erasure, evaluations have largely focused on random data\nforgetting, ignoring the vital inquiry into which subset should be chosen to\ntruly gauge the authenticity of unlearning performance. To tackle this issue,\nwe introduce a new evaluative angle for MU from an adversarial viewpoint. We\npropose identifying the data subset that presents the most significant\nchallenge for influence erasure, i.e., pinpointing the worst-case forget set.\nUtilizing a bi-level optimization principle, we amplify unlearning challenges\nat the upper optimization level to emulate worst-case scenarios, while\nsimultaneously engaging in standard training and unlearning at the lower level,\nachieving a balance between data influence erasure and model utility. Our\nproposal offers a worst-case evaluation of MU's resilience and effectiveness.\nThrough extensive experiments across different datasets (including CIFAR-10,\n100, CelebA, Tiny ImageNet, and ImageNet) and models (including both image\nclassifiers and generative models), we expose critical pros and cons in\nexisting (approximate) unlearning strategies. Our results illuminate the\ncomplex challenges of MU in practice, guiding the future development of more\naccurate and robust unlearning algorithms. The code is available at\nhttps://github.com/OPTML-Group/Unlearn-WorstCase.",
      "tldr_zh": "该论文探讨了机器取消学习（Machine Unlearning, MU）中的关键挑战，提出从对抗视角评估模型删除特定数据点的影响，着重识别最难处理的子集，即 worst-case forget set。作者采用双层优化（bi-level optimization）方法，在上层放大 unlearning 的挑战以模拟极端场景，同时在下层维持标准训练和模型效用平衡。实验在多种数据集（如 CIFAR-10、CIFAR-100、CelebA 和 ImageNet）及模型上进行，揭示了现有 MU 策略的优缺点，并暴露了实际应用中的复杂问题。该研究为开发更准确和鲁棒的 unlearning 算法提供了重要指导。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by ECCV 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.07362v4",
      "published_date": "2024-03-12 06:50:32 UTC",
      "updated_date": "2024-07-09 03:59:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:51:25.278955"
    },
    {
      "arxiv_id": "2403.07355v2",
      "title": "Vector Quantization for Deep-Learning-Based CSI Feedback in Massive MIMO Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Junyong Shin",
        "Yujin Kang",
        "Yo-Seb Jeon"
      ],
      "abstract": "This paper presents a finite-rate deep-learning (DL)-based channel state\ninformation (CSI) feedback method for massive multiple-input multiple-output\n(MIMO) systems. The presented method provides a finite-bit representation of\nthe latent vector based on a vector-quantized variational autoencoder (VQ-VAE)\nframework while reducing its computational complexity based on shape-gain\nvector quantization. In this method, the magnitude of the latent vector is\nquantized using a non-uniform scalar codebook with a proper transformation\nfunction, while the direction of the latent vector is quantized using a\ntrainable Grassmannian codebook. A multi-rate codebook design strategy is also\ndeveloped by introducing a codeword selection rule for a nested codebook along\nwith the design of a loss function. Simulation results demonstrate that the\nproposed method reduces the computational complexity associated with VQ-VAE\nwhile improving CSI reconstruction performance under a given feedback overhead.",
      "tldr_zh": "这篇论文提出了一种基于深度学习的有限速率信道状态信息（CSI）反馈方法，适用于大规模多输入多输出（Massive MIMO）系统，通过Vector Quantized Variational Autoencoder（VQ-VAE）框架提供潜在向量的有限位表示，并利用形状-增益向量量化减少计算复杂度。具体而言，该方法使用非均匀标量码本量化潜在向量的幅度，并采用可训练的Grassmannian码本量化其方向，同时开发了多速率码本设计策略，包括嵌套码本的码字选择规则和损失函数优化。模拟结果表明，该方法在给定反馈开销下显著降低了VQ-VAE的计算复杂度，同时提升了CSI重建性能。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.07355v2",
      "published_date": "2024-03-12 06:28:41 UTC",
      "updated_date": "2024-03-13 02:29:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:51:37.555240"
    },
    {
      "arxiv_id": "2403.07953v2",
      "title": "Abstracting Sparse DNN Acceleration via Structured Sparse Tensor Decomposition",
      "title_zh": "翻译失败",
      "authors": [
        "Geonhwa Jeong",
        "Po-An Tsai",
        "Abhimanyu R. Bambhaniya",
        "Stephen W. Keckler",
        "Tushar Krishna"
      ],
      "abstract": "Exploiting sparsity in deep neural networks (DNNs) has been a promising area\nto meet the growing computation need of modern DNNs. However, in practice,\nsparse DNN acceleration still faces a key challenge. To minimize the overhead\nof sparse acceleration, hardware designers have proposed structured sparse\nhardware support recently, which provides limited flexibility and requires\nextra model fine-tuning. Moreover, any sparse model fine-tuned for certain\nstructured sparse hardware cannot be accelerated by other structured hardware.\nTo bridge the gap between sparse DNN models and hardware, this paper proposes\ntensor approximation via structured decomposition (TASD), which leverages the\ndistributive property in linear algebra to turn any sparse tensor into a series\nof structured sparse tensors. Next, we develop a software framework, TASDER, to\naccelerate DNNs by searching layer-wise, high-quality structured decomposition\nfor both weight and activation tensors so that they can be accelerated by any\nsystems with structured sparse hardware support. Evaluation results show that,\nby exploiting prior structured sparse hardware baselines, our method can\naccelerate off-the-shelf dense and sparse DNNs without fine-tuning and improves\nenergy-delay-product by up to 83% and 74% on average.",
      "tldr_zh": "本论文针对深度神经网络 (DNNs) 中的稀疏性加速问题，提出了一种结构化稀疏张量分解方法，即 tensor approximation via structured decomposition (TASD)，利用线性代数的分配属性将任意稀疏张量转化为一系列结构化稀疏张量，以桥接模型与硬件的差距。论文随后开发了 TASDER 软件框架，通过层级搜索的高质量结构分解来加速 DNNs 的权重和激活张量，使其能够在各种结构化稀疏硬件上运行，而无需额外模型微调。实验结果显示，该方法在基于现有硬件基线的评估中，能提升现有密集和稀疏 DNNs 的能量延迟乘积 (energy-delay-product) 平均高达 74% 到 83%。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.AR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.07953v2",
      "published_date": "2024-03-12 06:25:47 UTC",
      "updated_date": "2024-03-31 23:47:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:51:48.339839"
    },
    {
      "arxiv_id": "2403.07350v3",
      "title": "VLKEB: A Large Vision-Language Model Knowledge Editing Benchmark",
      "title_zh": "VLKEB：大型视觉语言模型知识编辑基准",
      "authors": [
        "Han Huang",
        "Haitian Zhong",
        "Tao Yu",
        "Qiang Liu",
        "Shu Wu",
        "Liang Wang",
        "Tieniu Tan"
      ],
      "abstract": "Recently, knowledge editing on large language models (LLMs) has received\nconsiderable attention. Compared to this, editing Large Vision-Language Models\n(LVLMs) faces extra challenges from diverse data modalities and complicated\nmodel components, and data for LVLMs editing are limited. The existing LVLM\nediting benchmark, which comprises three metrics (Reliability, Locality, and\nGenerality), falls short in the quality of synthesized evaluation images and\ncannot assess whether models apply edited knowledge in relevant content.\nTherefore, we employ more reliable data collection methods to construct a new\nLarge $\\textbf{V}$ision-$\\textbf{L}$anguage Model $\\textbf{K}$nowledge\n$\\textbf{E}$diting $\\textbf{B}$enchmark, $\\textbf{VLKEB}$, and extend the\nPortability metric for more comprehensive evaluation. Leveraging a multi-modal\nknowledge graph, our image data are bound with knowledge entities. This can be\nfurther used to extract entity-related knowledge, which constitutes the base of\nediting data. We conduct experiments of different editing methods on five\nLVLMs, and thoroughly analyze how do they impact the models. The results reveal\nstrengths and deficiencies of these methods and hopefully provide insights for\nfuture research. The codes and dataset are available at:\nhttps://github.com/VLKEB/VLKEB.",
      "tldr_zh": "该研究构建了VLKEB，一种新的Large Vision-Language Model (LVLM)知识编辑基准，以解决现有基准在图像质量和知识应用评估方面的不足。VLKEB采用多模态知识图谱收集可靠数据，并扩展了评估指标，包括Reliability、Locality、Generality和新增的Portability，以更全面地评估LVLM的知识编辑效果。实验在五个LVLM上测试了不同编辑方法，结果揭示了这些方法的优势和缺陷，并为未来研究提供了宝贵见解。代码和数据集可从https://github.com/VLKEB/VLKEB获取。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "comment": "NeurIPS 2024, Datasets and Benchmarks Track",
      "pdf_url": "http://arxiv.org/pdf/2403.07350v3",
      "published_date": "2024-03-12 06:16:33 UTC",
      "updated_date": "2024-10-29 09:31:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:52:00.878823"
    },
    {
      "arxiv_id": "2403.07342v2",
      "title": "Rethinking ASTE: A Minimalist Tagging Scheme Alongside Contrastive Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Qiao Sun",
        "Liujia Yang",
        "Minghao Ma",
        "Nanyang Ye",
        "Qinying Gu"
      ],
      "abstract": "Aspect Sentiment Triplet Extraction (ASTE) is a burgeoning subtask of\nfine-grained sentiment analysis, aiming to extract structured sentiment\ntriplets from unstructured textual data. Existing approaches to ASTE often\ncomplicate the task with additional structures or external data. In this\nresearch, we propose a novel tagging scheme and employ a contrastive learning\napproach to mitigate these challenges. The proposed approach demonstrates\ncomparable or superior performance in comparison to state-of-the-art\ntechniques, while featuring a more compact design and reduced computational\noverhead. Notably, even in the era of Large Language Models (LLMs), our method\nexhibits superior efficacy compared to GPT 3.5 and GPT 4 in a few-shot learning\nscenarios. This study also provides valuable insights for the advancement of\nASTE techniques within the paradigm of large language models.",
      "tldr_zh": "本文重新审视 ASTE（Aspect Sentiment Triplet Extraction），提出一个极简标记方案（minimalist tagging scheme）并结合对比学习（contrastive learning），以简化从非结构化文本中提取情感三元组的任务，同时减少额外结构和外部数据的依赖。实验结果显示，该方法在性能上与最先进技术相当或优越，且计算开销更低。在少样本学习场景下，它甚至优于 GPT-3.5 和 GPT-4，为 ASTE 技术在 Large Language Models (LLMs) 范式下的发展提供了宝贵见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.07342v2",
      "published_date": "2024-03-12 06:01:04 UTC",
      "updated_date": "2024-04-14 20:53:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:52:14.716017"
    },
    {
      "arxiv_id": "2403.07332v2",
      "title": "LKM-UNet: Large Kernel Vision Mamba UNet for Medical Image Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Jinhong Wang",
        "Jintai Chen",
        "Danny Chen",
        "Jian Wu"
      ],
      "abstract": "In clinical practice, medical image segmentation provides useful information\non the contours and dimensions of target organs or tissues, facilitating\nimproved diagnosis, analysis, and treatment. In the past few years,\nconvolutional neural networks (CNNs) and Transformers have dominated this area,\nbut they still suffer from either limited receptive fields or costly long-range\nmodeling. Mamba, a State Space Sequence Model (SSM), recently emerged as a\npromising paradigm for long-range dependency modeling with linear complexity.\nIn this paper, we introduce a Large Kernel Vision Mamba U-shape Network, or\nLKM-UNet, for medical image segmentation. A distinguishing feature of our\nLKM-UNet is its utilization of large Mamba kernels, excelling in locally\nspatial modeling compared to small kernel-based CNNs and Transformers, while\nmaintaining superior efficiency in global modeling compared to self-attention\nwith quadratic complexity. Additionally, we design a novel hierarchical and\nbidirectional Mamba block to further enhance Mamba's global and neighborhood\nspatial modeling capability for vision inputs. Comprehensive experiments\ndemonstrate the feasibility and the effectiveness of using large-size Mamba\nkernels to achieve large receptive fields. Codes are available at\nhttps://github.com/wjh892521292/LKM-UNet.",
      "tldr_zh": "本研究提出LKM-UNet，一种基于Large Kernel Vision Mamba的U-shape网络，用于医疗图像分割，以克服CNNs的局部感受野限制和Transformers的高计算成本。LKM-UNet利用大型Mamba内核在局部空间建模上优于小内核模型，同时在全局建模中保持线性复杂度的高效性；此外，设计了新型的hierarchical and bidirectional Mamba block，以增强全局和邻域空间建模能力。实验结果证明，该框架在医疗图像分割任务中实现了更大的感受野，并展示了显著的可行性和有效性，代码已在GitHub上公开。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by MICCAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.07332v2",
      "published_date": "2024-03-12 05:34:51 UTC",
      "updated_date": "2024-06-25 03:37:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:52:24.919831"
    },
    {
      "arxiv_id": "2403.07322v3",
      "title": "A Question-centric Multi-experts Contrastive Learning Framework for Improving the Accuracy and Interpretability of Deep Sequential Knowledge Tracing Models",
      "title_zh": "翻译失败",
      "authors": [
        "Hengyuan Zhang",
        "Zitao Liu",
        "Chenming Shang",
        "Dawei Li",
        "Yong Jiang"
      ],
      "abstract": "Knowledge tracing (KT) plays a crucial role in predicting students' future\nperformance by analyzing their historical learning processes. Deep neural\nnetworks (DNNs) have shown great potential in solving the KT problem. However,\nthere still exist some important challenges when applying deep learning\ntechniques to model the KT process. The first challenge lies in taking the\nindividual information of the question into modeling. This is crucial because,\ndespite questions sharing the same knowledge component (KC), students'\nknowledge acquisition on homogeneous questions can vary significantly. The\nsecond challenge lies in interpreting the prediction results from existing deep\nlearning-based KT models. In real-world applications, while it may not be\nnecessary to have complete transparency and interpretability of the model\nparameters, it is crucial to present the model's prediction results in a manner\nthat teachers find interpretable. This makes teachers accept the rationale\nbehind the prediction results and utilize them to design teaching activities\nand tailored learning strategies for students. However, the inherent black-box\nnature of deep learning techniques often poses a hurdle for teachers to fully\nembrace the model's prediction results. To address these challenges, we propose\na Question-centric Multi-experts Contrastive Learning framework for KT called\nQ-MCKT. We have provided all the datasets and code on our website at\nhttps://github.com/rattlesnakey/Q-MCKT.",
      "tldr_zh": "知识追踪（KT）是预测学生学习表现的关键技术，但现有深度神经网络（DNNs）模型面临两大挑战：一是未充分考虑问题个体信息，导致对共享知识组件（KC）的同类问题学生掌握程度评估不准；二是模型预测结果的可解释性不足，阻碍教师应用。针对这些问题，本文提出了一种以问题为中心的多专家对比学习框架 Q-MCKT，通过整合问题特定信息和对比学习机制，提升 KT 模型的准确性和可解释性。该框架使教师能更好地理解预测结果，从而设计更有效的教学活动和个性化学习策略。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "25 pages, 9 figures, Accepted by TKDD",
      "pdf_url": "http://arxiv.org/pdf/2403.07322v3",
      "published_date": "2024-03-12 05:15:42 UTC",
      "updated_date": "2024-07-05 16:11:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:52:37.122135"
    },
    {
      "arxiv_id": "2403.07309v1",
      "title": "Reinforced Sequential Decision-Making for Sepsis Treatment: The POSNEGDM Framework with Mortality Classifier and Transformer",
      "title_zh": "翻译失败",
      "authors": [
        "Dipesh Tamboli",
        "Jiayu Chen",
        "Kiran Pranesh Jotheeswaran",
        "Denny Yu",
        "Vaneet Aggarwal"
      ],
      "abstract": "Sepsis, a life-threatening condition triggered by the body's exaggerated\nresponse to infection, demands urgent intervention to prevent severe\ncomplications. Existing machine learning methods for managing sepsis struggle\nin offline scenarios, exhibiting suboptimal performance with survival rates\nbelow 50%. This paper introduces the POSNEGDM -- ``Reinforcement Learning with\nPositive and Negative Demonstrations for Sequential Decision-Making\" framework\nutilizing an innovative transformer-based model and a feedback reinforcer to\nreplicate expert actions while considering individual patient characteristics.\nA mortality classifier with 96.7\\% accuracy guides treatment decisions towards\npositive outcomes. The POSNEGDM framework significantly improves patient\nsurvival, saving 97.39% of patients, outperforming established machine learning\nalgorithms (Decision Transformer and Behavioral Cloning) with survival rates of\n33.4% and 43.5%, respectively. Additionally, ablation studies underscore the\ncritical role of the transformer-based decision maker and the integration of a\nmortality classifier in enhancing overall survival rates. In summary, our\nproposed approach presents a promising avenue for enhancing sepsis treatment\noutcomes, contributing to improved patient care and reduced healthcare costs.",
      "tldr_zh": "本论文针对脓毒症治疗提出POSNEGDM框架，这是一种强化学习方法，利用正负演示（Positive and Negative Demonstrations）结合Transformer-based模型和反馈强化器，来模拟专家决策并考虑患者个体特征。框架中整合了一个准确率96.7%的死亡率分类器（Mortality Classifier），以指导治疗决策并提升患者存活率。实验结果显示，POSNEGDM将患者存活率提高至97.39%，显著优于Decision Transformer（33.4%）和Behavioral Cloning（43.5%）。此外，消融研究强调了Transformer-based决策模型和死亡率分类器的关键作用，为改善脓毒症治疗效果、降低医疗成本提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to IEEE Journal of Biomedical and Health Informatics, Mar\n  2024",
      "pdf_url": "http://arxiv.org/pdf/2403.07309v1",
      "published_date": "2024-03-12 04:36:41 UTC",
      "updated_date": "2024-03-12 04:36:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:52:50.102542"
    },
    {
      "arxiv_id": "2403.07308v1",
      "title": "Verification-Aided Learning of Neural Network Barrier Functions with Termination Guarantees",
      "title_zh": "带有终止保证的神经网络屏障函数验证辅助学习",
      "authors": [
        "Shaoru Chen",
        "Lekan Molu",
        "Mahyar Fazlyab"
      ],
      "abstract": "Barrier functions are a general framework for establishing a safety guarantee\nfor a system. However, there is no general method for finding these functions.\nTo address this shortcoming, recent approaches use self-supervised learning\ntechniques to learn these functions using training data that are periodically\ngenerated by a verification procedure, leading to a verification-aided learning\nframework. Despite its immense potential in automating barrier function\nsynthesis, the verification-aided learning framework does not have termination\nguarantees and may suffer from a low success rate of finding a valid barrier\nfunction in practice. In this paper, we propose a holistic approach to address\nthese drawbacks. With a convex formulation of the barrier function synthesis,\nwe propose to first learn an empirically well-behaved NN basis function and\nthen apply a fine-tuning algorithm that exploits the convexity and\ncounterexamples from the verification failure to find a valid barrier function\nwith finite-step termination guarantees: if there exist valid barrier\nfunctions, the fine-tuning algorithm is guaranteed to find one in a finite\nnumber of iterations. We demonstrate that our fine-tuning method can\nsignificantly boost the performance of the verification-aided learning\nframework on examples of different scales and using various neural network\nverifiers.",
      "tldr_zh": "本研究针对 barrier functions 在系统安全验证中的应用，提出了一种改进的 verification-aided learning 框架，以解决现有方法缺乏终止保证和成功率低的问题。方法包括先通过凸优化形式化 barrier function 合成，学习一个经验上表现良好的 neural network basis function，然后应用微调算法，利用验证失败的 counterexamples 来精确调整。该微调算法具有有限步终止保证：如果存在有效的 barrier functions，它将在有限迭代中找到一个。实验结果显示，该方法显著提升了框架的性能，在不同规模的示例和各种 neural network verifiers 上取得了更好的效果。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "This is an online extended version of the same paper accepted to\n  American Control Conference 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.07308v1",
      "published_date": "2024-03-12 04:29:43 UTC",
      "updated_date": "2024-03-12 04:29:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:53:00.521951"
    },
    {
      "arxiv_id": "2403.07294v2",
      "title": "Graph Data Condensation via Self-expressive Graph Structure Reconstruction",
      "title_zh": "通过自表达图结构重建的图数据浓缩",
      "authors": [
        "Zhanyu Liu",
        "Chaolv Zeng",
        "Guanjie Zheng"
      ],
      "abstract": "With the increasing demands of training graph neural networks (GNNs) on\nlarge-scale graphs, graph data condensation has emerged as a critical technique\nto relieve the storage and time costs during the training phase. It aims to\ncondense the original large-scale graph to a much smaller synthetic graph while\npreserving the essential information necessary for efficiently training a\ndownstream GNN. However, existing methods concentrate either on optimizing node\nfeatures exclusively or endeavor to independently learn node features and the\ngraph structure generator. They could not explicitly leverage the information\nof the original graph structure and failed to construct an interpretable graph\nstructure for the synthetic dataset. To address these issues, we introduce a\nnovel framework named \\textbf{G}raph Data \\textbf{C}ondensation via\n\\textbf{S}elf-expressive Graph Structure \\textbf{R}econstruction\n(\\textbf{GCSR}). Our method stands out by (1) explicitly incorporating the\noriginal graph structure into the condensing process and (2) capturing the\nnuanced interdependencies between the condensed nodes by reconstructing an\ninterpretable self-expressive graph structure. Extensive experiments and\ncomprehensive analysis validate the efficacy of the proposed method across\ndiverse GNN models and datasets. Our code is available at\n\\url{https://github.com/zclzcl0223/GCSR}.",
      "tldr_zh": "该研究针对训练图神经网络（GNNs）时的大规模图数据问题，提出了一种名为 GCSR 的新型框架，用于图数据浓缩（Graph Data Condensation）。GCSR 通过显式整合原始图结构并重建可解释的自表达图结构（Self-expressive Graph Structure Reconstruction），来捕捉浓缩节点之间的细微相互依赖，从而保留了关键信息并提高了效率。与现有方法相比，该框架在各种 GNN 模型和数据集上进行了广泛实验，验证了其有效性，并在代码仓库中公开了实现细节。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.07294v2",
      "published_date": "2024-03-12 03:54:25 UTC",
      "updated_date": "2024-06-07 04:36:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:53:13.134004"
    },
    {
      "arxiv_id": "2403.07292v1",
      "title": "Continual All-in-One Adverse Weather Removal with Knowledge Replay on a Unified Network Structure",
      "title_zh": "翻译失败",
      "authors": [
        "De Cheng",
        "Yanling Ji",
        "Dong Gong",
        "Yan Li",
        "Nannan Wang",
        "Junwei Han",
        "Dingwen Zhang"
      ],
      "abstract": "In real-world applications, image degeneration caused by adverse weather is\nalways complex and changes with different weather conditions from days and\nseasons. Systems in real-world environments constantly encounter adverse\nweather conditions that are not previously observed. Therefore, it practically\nrequires adverse weather removal models to continually learn from incrementally\ncollected data reflecting various degeneration types. Existing adverse weather\nremoval approaches, for either single or multiple adverse weathers, are mainly\ndesigned for a static learning paradigm, which assumes that the data of all\ntypes of degenerations to handle can be finely collected at one time before a\nsingle-phase learning process. They thus cannot directly handle the incremental\nlearning requirements. To address this issue, we made the earliest effort to\ninvestigate the continual all-in-one adverse weather removal task, in a setting\ncloser to real-world applications. Specifically, we develop a novel continual\nlearning framework with effective knowledge replay (KR) on a unified network\nstructure. Equipped with a principal component projection and an effective\nknowledge distillation mechanism, the proposed KR techniques are tailored for\nthe all-in-one weather removal task. It considers the characteristics of the\nimage restoration task with multiple degenerations in continual learning, and\nthe knowledge for different degenerations can be shared and accumulated in the\nunified network structure. Extensive experimental results demonstrate the\neffectiveness of the proposed method to deal with this challenging task, which\nperforms competitively to existing dedicated or joint training image\nrestoration methods. Our code is available at\nhttps://github.com/xiaojihh/CL_all-in-one.",
      "tldr_zh": "本论文首次探讨了持续全合一恶劣天气移除任务，针对现实场景中天气变化导致的图像退化问题，提出一种基于统一网络结构的持续学习框架。该框架利用知识重放（Knowledge Replay）技术，包括主成分投影和知识蒸馏机制，实现不同退化类型的知识共享和累积。实验结果显示，该方法在处理增量数据时表现优异，与现有的专属或联合训练图像恢复方法竞争。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.07292v1",
      "published_date": "2024-03-12 03:50:57 UTC",
      "updated_date": "2024-03-12 03:50:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:53:24.287765"
    },
    {
      "arxiv_id": "2403.07277v2",
      "title": "A Bayesian Approach to OOD Robustness in Image Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Prakhar Kaushik",
        "Adam Kortylewski",
        "Alan Yuille"
      ],
      "abstract": "An important and unsolved problem in computer vision is to ensure that the\nalgorithms are robust to changes in image domains. We address this problem in\nthe scenario where we have access to images from the target domains but no\nannotations. Motivated by the challenges of the OOD-CV benchmark where we\nencounter real world Out-of-Domain (OOD) nuisances and occlusion, we introduce\na novel Bayesian approach to OOD robustness for object classification. Our work\nextends Compositional Neural Networks (CompNets), which have been shown to be\nrobust to occlusion but degrade badly when tested on OOD data. We exploit the\nfact that CompNets contain a generative head defined over feature vectors\nrepresented by von Mises-Fisher (vMF) kernels, which correspond roughly to\nobject parts, and can be learned without supervision. We obverse that some vMF\nkernels are similar between different domains, while others are not. This\nenables us to learn a transitional dictionary of vMF kernels that are\nintermediate between the source and target domains and train the generative\nmodel on this dictionary using the annotations on the source domain, followed\nby iterative refinement. This approach, termed Unsupervised Generative\nTransition (UGT), performs very well in OOD scenarios even when occlusion is\npresent. UGT is evaluated on different OOD benchmarks including the OOD-CV\ndataset, several popular datasets (e.g., ImageNet-C [9]), artificial image\ncorruptions (including adding occluders), and synthetic-to-real domain\ntransfer, and does well in all scenarios outperforming SOTA alternatives (e.g.\nup to 10% top-1 accuracy on Occluded OOD-CV dataset).",
      "tldr_zh": "这篇论文提出了一种Bayesian方法来提升图像分类算法的OOD（Out-of-Domain）鲁棒性，针对无标注目标域图像的场景。方法扩展了Compositional Neural Networks (CompNets)，通过观察von Mises-Fisher (vMF) kernels在不同域间的相似性，学习一个过渡字典并使用Unsupervised Generative Transition (UGT)进行无监督训练和迭代精炼，从而处理真实世界干扰和遮挡问题。实验结果显示，UGT在OOD-CV、ImageNet-C等基准上表现出色，超越SOTA方法，例如在Occluded OOD-CV数据集上top-1准确率提高10%。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.07277v2",
      "published_date": "2024-03-12 03:15:08 UTC",
      "updated_date": "2025-02-07 06:35:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:53:39.114585"
    },
    {
      "arxiv_id": "2403.07271v1",
      "title": "Anderson acceleration for iteratively reweighted $\\ell_1$ algorithm",
      "title_zh": "翻译失败",
      "authors": [
        "Kexin Li"
      ],
      "abstract": "Iteratively reweighted L1 (IRL1) algorithm is a common algorithm for solving\nsparse optimization problems with nonconvex and nonsmooth regularization. The\ndevelopment of its acceleration algorithm, often employing Nesterov\nacceleration, has sparked significant interest. Nevertheless, the convergence\nand complexity analysis of these acceleration algorithms consistently poses\nsubstantial challenges. Recently, Anderson acceleration has gained prominence\nowing to its exceptional performance for speeding up fixed-point iteration,\nwith numerous recent studies applying it to gradient-based algorithms.\nMotivated by the powerful impact of Anderson acceleration, we propose an\nAnderson-accelerated IRL1 algorithm and establish its local linear convergence\nrate. We extend this convergence result, typically observed in smooth settings,\nto a nonsmooth scenario. Importantly, our theoretical results do not depend on\nthe Kurdyka-Lojasiewicz condition, a necessary condition in existing Nesterov\nacceleration-based algorithms. Furthermore, to ensure global convergence, we\nintroduce a globally convergent Anderson accelerated IRL1 algorithm by\nincorporating a classical nonmonotone line search condition. Experimental\nresults indicate that our algorithm outperforms existing Nesterov\nacceleration-based algorithms.",
      "tldr_zh": "本研究提出了一种基于 Anderson acceleration 的 Iteratively Reweighted ℓ1 (IRL1) 算法，用于加速解决非凸和非光滑的稀疏优化问题。论文建立了该算法的局部线性收敛率，并首次将 Anderson acceleration 从平滑场景扩展到非光滑场景，而不依赖于 Kurdyka-Lojasiewicz 条件。为了确保全局收敛，该算法整合了经典的非单调线搜索机制。实验结果显示，该方法在性能上优于现有的 Nesterov acceleration 算法。",
      "categories": [
        "math.OC",
        "cs.AI",
        "cs.LG",
        "eess.SP"
      ],
      "primary_category": "math.OC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.07271v1",
      "published_date": "2024-03-12 03:00:15 UTC",
      "updated_date": "2024-03-12 03:00:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:53:49.594726"
    },
    {
      "arxiv_id": "2403.07262v4",
      "title": "A2PO: Towards Effective Offline Reinforcement Learning from an Advantage-aware Perspective",
      "title_zh": "A2PO：基于优势感知视角的有效离线强化学习",
      "authors": [
        "Yunpeng Qing",
        "Shunyu liu",
        "Jingyuan Cong",
        "Kaixuan Chen",
        "Yihe Zhou",
        "Mingli Song"
      ],
      "abstract": "Offline reinforcement learning endeavors to leverage offline datasets to\ncraft effective agent policy without online interaction, which imposes proper\nconservative constraints with the support of behavior policies to tackle the\nout-of-distribution problem. However, existing works often suffer from the\nconstraint conflict issue when offline datasets are collected from multiple\nbehavior policies, i.e., different behavior policies may exhibit inconsistent\nactions with distinct returns across the state space. To remedy this issue,\nrecent advantage-weighted methods prioritize samples with high advantage values\nfor agent training while inevitably ignoring the diversity of behavior policy.\nIn this paper, we introduce a novel Advantage-Aware Policy Optimization (A2PO)\nmethod to explicitly construct advantage-aware policy constraints for offline\nlearning under mixed-quality datasets. Specifically, A2PO employs a conditional\nvariational auto-encoder to disentangle the action distributions of intertwined\nbehavior policies by modeling the advantage values of all training data as\nconditional variables. Then the agent can follow such disentangled action\ndistribution constraints to optimize the advantage-aware policy towards high\nadvantage values. Extensive experiments conducted on both the single-quality\nand mixed-quality datasets of the D4RL benchmark demonstrate that A2PO yields\nresults superior to the counterparts. Our code is available at\nhttps://github.com/Plankson/A2PO",
      "tldr_zh": "本文提出 A2PO（Advantage-Aware Policy Optimization），一种针对多行为策略数据集的离线强化学习方法，旨在解决现有方法在约束冲突问题上的不足，通过优先考虑高优势值样本同时保持行为策略多样性。A2PO 使用条件变分自编码器（conditional variational auto-encoder）来分离交织行为策略的动作分布，将优势值作为条件变量构建显式约束，从而优化代理策略朝向高优势方向。实验在 D4RL 基准上的单质量和混合质量数据集显示，A2PO 比现有方法表现出色，提供更有效的离线学习框架。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.07262v4",
      "published_date": "2024-03-12 02:43:41 UTC",
      "updated_date": "2024-11-11 10:59:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:54:01.457197"
    },
    {
      "arxiv_id": "2403.07261v1",
      "title": "Disentangling Policy from Offline Task Representation Learning via Adversarial Data Augmentation",
      "title_zh": "通过对抗数据增强从离线任务表示",
      "authors": [
        "Chengxing Jia",
        "Fuxiang Zhang",
        "Yi-Chen Li",
        "Chen-Xiao Gao",
        "Xu-Hui Liu",
        "Lei Yuan",
        "Zongzhang Zhang",
        "Yang Yu"
      ],
      "abstract": "Offline meta-reinforcement learning (OMRL) proficiently allows an agent to\ntackle novel tasks while solely relying on a static dataset. For precise and\nefficient task identification, existing OMRL research suggests learning\nseparate task representations that be incorporated with policy input, thus\nforming a context-based meta-policy. A major approach to train task\nrepresentations is to adopt contrastive learning using multi-task offline data.\nThe dataset typically encompasses interactions from various policies (i.e., the\nbehavior policies), thus providing a plethora of contextual information\nregarding different tasks. Nonetheless, amassing data from a substantial number\nof policies is not only impractical but also often unattainable in realistic\nsettings. Instead, we resort to a more constrained yet practical scenario,\nwhere multi-task data collection occurs with a limited number of policies. We\nobserved that learned task representations from previous OMRL methods tend to\ncorrelate spuriously with the behavior policy instead of reflecting the\nessential characteristics of the task, resulting in unfavorable\nout-of-distribution generalization. To alleviate this issue, we introduce a\nnovel algorithm to disentangle the impact of behavior policy from task\nrepresentation learning through a process called adversarial data augmentation.\nSpecifically, the objective of adversarial data augmentation is not merely to\ngenerate data analogous to offline data distribution; instead, it aims to\ncreate adversarial examples designed to confound learned task representations\nand lead to incorrect task identification. Our experiments show that learning\nfrom such adversarial samples significantly enhances the robustness and\neffectiveness of the task identification process and realizes satisfactory\nout-of-distribution generalization.",
      "tldr_zh": "这篇论文解决了离线元强化学习 (OMRL) 中任务表示学习的问题，即现有方法在有限行为策略数据下，任务表示容易与策略相关联，导致分布外泛化能力不足。作者引入了一种新算法，通过对抗数据增强 (adversarial data augmentation) 生成旨在混淆任务表示的对抗样本，从而分离行为策略的影响，并采用对比学习 (contrastive learning) 优化任务识别。实验结果表明，该方法显著提升了任务识别的鲁棒性和有效性，实现更好的出分布泛化性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.07261v1",
      "published_date": "2024-03-12 02:38:36 UTC",
      "updated_date": "2024-03-12 02:38:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:54:13.629946"
    },
    {
      "arxiv_id": "2403.07952v1",
      "title": "AesopAgent: Agent-driven Evolutionary System on Story-to-Video Production",
      "title_zh": "翻译失败",
      "authors": [
        "Jiuniu Wang",
        "Zehua Du",
        "Yuyuan Zhao",
        "Bo Yuan",
        "Kexiang Wang",
        "Jian Liang",
        "Yaxi Zhao",
        "Yihen Lu",
        "Gengliang Li",
        "Junlong Gao",
        "Xin Tu",
        "Zhenyu Guo"
      ],
      "abstract": "The Agent and AIGC (Artificial Intelligence Generated Content) technologies\nhave recently made significant progress. We propose AesopAgent, an Agent-driven\nEvolutionary System on Story-to-Video Production. AesopAgent is a practical\napplication of agent technology for multimodal content generation. The system\nintegrates multiple generative capabilities within a unified framework, so that\nindividual users can leverage these modules easily. This innovative system\nwould convert user story proposals into scripts, images, and audio, and then\nintegrate these multimodal contents into videos. Additionally, the animating\nunits (e.g., Gen-2 and Sora) could make the videos more infectious. The\nAesopAgent system could orchestrate task workflow for video generation,\nensuring that the generated video is both rich in content and coherent. This\nsystem mainly contains two layers, i.e., the Horizontal Layer and the Utility\nLayer. In the Horizontal Layer, we introduce a novel RAG-based evolutionary\nsystem that optimizes the whole video generation workflow and the steps within\nthe workflow. It continuously evolves and iteratively optimizes workflow by\naccumulating expert experience and professional knowledge, including optimizing\nthe LLM prompts and utilities usage. The Utility Layer provides multiple\nutilities, leading to consistent image generation that is visually coherent in\nterms of composition, characters, and style. Meanwhile, it provides audio and\nspecial effects, integrating them into expressive and logically arranged\nvideos. Overall, our AesopAgent achieves state-of-the-art performance compared\nwith many previous works in visual storytelling. Our AesopAgent is designed for\nconvenient service for individual users, which is available on the following\npage: https://aesopai.github.io/.",
      "tldr_zh": "本文提出 AesopAgent，一种 Agent-driven 的进化系统，用于将用户故事转化为脚本、图像、音频并整合成连贯视频，显著提升多模态内容生成效率。系统由 Horizontal Layer 的 RAG-based 优化机制负责迭代改进工作流和 LLM prompts，以及 Utility Layer 提供一致的图像生成、音频和特效支持，如 Gen-2 和 Sora 动画单位。实验结果显示，AesopAgent 在视觉叙事任务中达到 state-of-the-art 性能，并作为便捷服务提供给个人用户。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "22 pages, 13 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.07952v1",
      "published_date": "2024-03-12 02:30:50 UTC",
      "updated_date": "2024-03-12 02:30:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:54:26.558816"
    },
    {
      "arxiv_id": "2403.07255v1",
      "title": "Deep Learning-Assisted Parallel Interference Cancellation for Grant-Free NOMA in Machine-Type Communication",
      "title_zh": "翻译失败",
      "authors": [
        "Yongjeong Oh",
        "Jaehong Jo",
        "Byonghyo Shim",
        "Yo-Seb Jeon"
      ],
      "abstract": "In this paper, we present a novel approach for joint activity detection (AD),\nchannel estimation (CE), and data detection (DD) in uplink grant-free\nnon-orthogonal multiple access (NOMA) systems. Our approach employs an\niterative and parallel interference removal strategy inspired by parallel\ninterference cancellation (PIC), enhanced with deep learning to jointly tackle\nthe AD, CE, and DD problems. Based on this approach, we develop three PIC\nframeworks, each of which is designed for either coherent or non-coherence\nschemes. The first framework performs joint AD and CE using received pilot\nsignals in the coherent scheme. Building upon this framework, the second\nframework utilizes both the received pilot and data signals for CE, further\nenhancing the performances of AD, CE, and DD in the coherent scheme. The third\nframework is designed to accommodate the non-coherent scheme involving a small\nnumber of data bits, which simultaneously performs AD and DD. Through joint\nloss functions and interference cancellation modules, our approach supports\nend-to-end training, contributing to enhanced performances of AD, CE, and DD\nfor both coherent and non-coherent schemes. Simulation results demonstrate the\nsuperiority of our approach over traditional techniques, exhibiting enhanced\nperformances of AD, CE, and DD while maintaining lower computational\ncomplexity.",
      "tldr_zh": "该论文提出了一种结合深度学习和并行干扰消除（Parallel Interference Cancellation, PIC）的创新方法，用于无授权非正交多址接入（Grant-Free NOMA）系统中的联合活动检测（Joint Activity Detection, AD）、信道估计（Channel Estimation, CE）和数据检测（Data Detection, DD）。该方法开发了三个PIC框架，分别针对相干方案（使用导频信号进行AD和CE，或结合数据信号进一步优化）和非相干方案（同时处理AD和DD以适应少量数据位），并通过联合损失函数和干扰消除模块实现端到端训练。模拟结果显示，该方法在AD、CE和DD的性能上比传统技术提升显著，同时保持较低的计算复杂度。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.07255v1",
      "published_date": "2024-03-12 02:24:37 UTC",
      "updated_date": "2024-03-12 02:24:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:54:38.445994"
    },
    {
      "arxiv_id": "2403.10547v1",
      "title": "Robust Second-Order Nonconvex Optimization and Its Application to Low Rank Matrix Sensing",
      "title_zh": "鲁棒的二阶非凸优化及其在低秩矩阵感知中的应用",
      "authors": [
        "Shuyao Li",
        "Yu Cheng",
        "Ilias Diakonikolas",
        "Jelena Diakonikolas",
        "Rong Ge",
        "Stephen J. Wright"
      ],
      "abstract": "Finding an approximate second-order stationary point (SOSP) is a well-studied\nand fundamental problem in stochastic nonconvex optimization with many\napplications in machine learning. However, this problem is poorly understood in\nthe presence of outliers, limiting the use of existing nonconvex algorithms in\nadversarial settings.\n  In this paper, we study the problem of finding SOSPs in the strong\ncontamination model, where a constant fraction of datapoints are arbitrarily\ncorrupted. We introduce a general framework for efficiently finding an\napproximate SOSP with \\emph{dimension-independent} accuracy guarantees, using\n$\\widetilde{O}({D^2}/{\\epsilon})$ samples where $D$ is the ambient dimension\nand $\\epsilon$ is the fraction of corrupted datapoints.\n  As a concrete application of our framework, we apply it to the problem of low\nrank matrix sensing, developing efficient and provably robust algorithms that\ncan tolerate corruptions in both the sensing matrices and the measurements. In\naddition, we establish a Statistical Query lower bound providing evidence that\nthe quadratic dependence on $D$ in the sample complexity is necessary for\ncomputationally efficient algorithms.",
      "tldr_zh": "这篇论文研究了在存在异常值的随机非凸优化中找到近似二阶静止点 (SOSP) 的问题，提出一个通用框架，能够在强污染模型下高效实现维度无关的准确性保证，使用 \\(\\widetilde{O}(D^2 / \\epsilon)\\) 样本，其中 \\(D\\) 为环境维度，\\(\\epsilon\\) 为污染数据分数。框架应用于低秩矩阵感知，开发了高效鲁棒算法，能容忍传感矩阵和测量中的异常值。作为理论贡献，论文建立了统计查询下界，表明样本复杂度的二次依赖于 \\(D\\) 对于计算高效算法是必要的。",
      "categories": [
        "math.OC",
        "cs.AI",
        "cs.DS",
        "cs.LG"
      ],
      "primary_category": "math.OC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.10547v1",
      "published_date": "2024-03-12 01:27:44 UTC",
      "updated_date": "2024-03-12 01:27:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:54:49.932242"
    },
    {
      "arxiv_id": "2403.07230v2",
      "title": "Curry-DPO: Enhancing Alignment using Curriculum Learning & Ranked Preferences",
      "title_zh": "翻译失败",
      "authors": [
        "Pulkit Pattnaik",
        "Rishabh Maheshwary",
        "Kelechi Ogueji",
        "Vikas Yadav",
        "Sathwik Tejaswi Madhusudhan"
      ],
      "abstract": "Direct Preference Optimization (DPO) is an effective technique that leverages\npairwise preference data (usually one chosen and rejected response pair per\nuser prompt) to align LLMs to human preferences. In practice, multiple\nresponses can exist for a given prompt with varying quality relative to each\nother. With availability of such quality ratings for multiple responses, we\npropose utilizing these responses to create multiple preference pairs for a\ngiven prompt. Our work focuses on systematically using the constructed multiple\npreference pair in DPO training via curriculum learning methodology. In\nparticular, we order these multiple pairs of preference data from easy to hard\n(emulating curriculum training) according to various criteria. We show detailed\ncomparisons of our proposed approach to the standard single-pair DPO setting.\nOur method, which we call Curry-DPO consistently shows increased performance\ngains on MTbench, Vicuna, WizardLM, and the UltraFeedback test set,\nhighlighting its effectiveness. More specifically, Curry-DPO achieves a score\nof 7.43 on MT-bench with Zephy-7B model outperforming majority of existing LLMs\nwith similar parameter size. Curry-DPO also achieves the highest adjusted win\nrates on Vicuna, WizardLM, and UltraFeedback test datasets (90.7%, 87.1%, and\n87.9% respectively) in our experiments, with notable gains of upto 7.5% when\ncompared to standard DPO technique. We release the preference pairs used in\nalignment at:\nhttps://huggingface.co/datasets/ServiceNow-AI/Curriculum_DPO_preferences",
      "tldr_zh": "该研究提出了一种名为 Curry-DPO 的方法，用于提升大型语言模型（LLMs）的偏好对齐，通过利用课程学习（curriculum learning）和排序偏好数据来优化 Direct Preference Optimization (DPO)。与标准 DPO 不同，Curry-DPO 从每个提示的多个响应中创建偏好对，并按从简单到困难的顺序进行训练，从而更好地处理响应质量差异。实验结果显示，该方法在 MTbench、Vicuna、WizardLM 和 UltraFeedback 测试集上表现出色，使用 Zephy-7B 模型在 MT-bench 上达到 7.43 分，并分别在 Vicuna、WizardLM 和 UltraFeedback 上获得 90.7%、87.1% 和 87.9% 的调整胜率，比标准 DPO 提升高达 7.5%。作者发布了相关偏好对数据集，以促进进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Published at EMNLP 2024 as long (findings) conference paper",
      "pdf_url": "http://arxiv.org/pdf/2403.07230v2",
      "published_date": "2024-03-12 00:58:19 UTC",
      "updated_date": "2024-11-08 08:55:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T14:55:02.627305"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 120,
  "processed_papers_count": 120,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-17T14:55:26.815149"
}