[
  {
    "arxiv_id": "2403.08137v1",
    "title": "From Paper to Card: Transforming Design Implications with Generative AI",
    "authors": [
      "Donghoon Shin",
      "Lucy Lu Wang",
      "Gary Hsieh"
    ],
    "abstract": "Communicating design implications is common within the HCI community when\npublishing academic papers, yet these papers are rarely read and used by\ndesigners. One solution is to use design cards as a form of translational\nresource that communicates valuable insights from papers in a more digestible\nand accessible format to assist in design processes. However, creating design\ncards can be time-consuming, and authors may lack the resources/know-how to\nproduce cards. Through an iterative design process, we built a system that\nhelps create design cards from academic papers using an LLM and text-to-image\nmodel. Our evaluation with designers (N=21) and authors of selected papers\n(N=12) revealed that designers perceived the design implications from our\ndesign cards as more inspiring and generative, compared to reading original\npaper texts, and the authors viewed our system as an effective way of\ncommunicating their design implications. We also propose future enhancements\nfor AI-generated design cards.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CL",
      "H.5.2; I.2.7"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.08137v1",
    "published_date": "2024-03-12 23:47:28 UTC",
    "updated_date": "2024-03-12 23:47:28 UTC"
  },
  {
    "arxiv_id": "2403.08136v1",
    "title": "RoboCertProb: Property Specification for Probabilistic RoboChart Models",
    "authors": [
      "Kangfeng Ye",
      "Jim Woodcock"
    ],
    "abstract": "RoboChart is a core notation in the RoboStar framework which brings modern\nmodelling and formal verification technologies into software engineering for\nrobotics. It is a timed and probabilistic domain-specific language for robotics\nand provides a UML-like architectural and state machine modelling. This work\npresents RoboCertProb for specifying quantitative properties of probabilistic\nrobotic systems modelled in RoboChart. RoboCertProb's semantics is based on\nPCTL*. To interpret RoboCertProb over RoboChart models, we give a Markov\nsemantics (DTMCs and MDPs) to RoboChart, derived from its existing\ntransformation semantics to the PRISM language. In addition to property\nspecification, RoboCertProb also entitles us to configure loose constants and\nunspecified functions and operations in RoboChart models. It allows us to set\nup environmental inputs to verify reactive probabilistic systems not directly\nsupported in probabilistic model checkers like PRISM because they employ a\nclosed-world assumption. We implement RoboCertProb in an accompanying tool of\nRoboChart, RoboTool, for specifying properties and automatically generating\nPRISM properties from them to formally verify RoboChart models using PRISM. We\nhave used it to analyse the behaviour of software controllers for two real\nrobots: an industrial painting robot and an agricultural robot for treating\nplants with UV lights.",
    "categories": [
      "cs.LO",
      "cs.AI"
    ],
    "primary_category": "cs.LO",
    "comment": "24 pages, 10 figures, 4 tables, submitted to the International\n  Journal on Software and Systems Modeling (SoSyM)",
    "pdf_url": "http://arxiv.org/pdf/2403.08136v1",
    "published_date": "2024-03-12 23:47:00 UTC",
    "updated_date": "2024-03-12 23:47:00 UTC"
  },
  {
    "arxiv_id": "2403.08133v1",
    "title": "Physics-Inspired Deep Learning Anti-Aliasing Framework in Efficient Channel State Feedback",
    "authors": [
      "Yu-Chien Lin",
      "Yan Xin",
      "Ta-Sung Lee",
      "Charlie",
      "Zhang",
      "Zhi Ding"
    ],
    "abstract": "Acquiring downlink channel state information (CSI) at the base station is\nvital for optimizing performance in massive Multiple input multiple output\n(MIMO) Frequency-Division Duplexing (FDD) systems. While deep learning\narchitectures have been successful in facilitating UE-side CSI feedback and\ngNB-side recovery, the undersampling issue prior to CSI feedback is often\noverlooked. This issue, which arises from low density pilot placement in\ncurrent standards, results in significant aliasing effects in outdoor channels\nand consequently limits CSI recovery performance. To this end, this work\nintroduces a new CSI upsampling framework at the gNB as a post-processing\nsolution to address the gaps caused by undersampling. Leveraging the physical\nprinciples of discrete Fourier transform shifting theorem and multipath\nreciprocity, our framework effectively uses uplink CSI to mitigate aliasing\neffects. We further develop a learning-based method that integrates the\nproposed algorithm with the Iterative Shrinkage-Thresholding Algorithm Net\n(ISTA-Net) architecture, enhancing our approach for non-uniform sampling\nrecovery. Our numerical results show that both our rule-based and deep learning\nmethods significantly outperform traditional interpolation techniques and\ncurrent state-of-the-art approaches in terms of performance.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.08133v1",
    "published_date": "2024-03-12 23:40:51 UTC",
    "updated_date": "2024-03-12 23:40:51 UTC"
  },
  {
    "arxiv_id": "2403.08124v1",
    "title": "Towards Independence Criterion in Machine Unlearning of Features and Labels",
    "authors": [
      "Ling Han",
      "Nanqing Luo",
      "Hao Huang",
      "Jing Chen",
      "Mary-Anne Hartley"
    ],
    "abstract": "This work delves into the complexities of machine unlearning in the face of\ndistributional shifts, particularly focusing on the challenges posed by\nnon-uniform feature and label removal. With the advent of regulations like the\nGDPR emphasizing data privacy and the right to be forgotten, machine learning\nmodels face the daunting task of unlearning sensitive information without\ncompromising their integrity or performance. Our research introduces a novel\napproach that leverages influence functions and principles of distributional\nindependence to address these challenges. By proposing a comprehensive\nframework for machine unlearning, we aim to ensure privacy protection while\nmaintaining model performance and adaptability across varying distributions.\nOur method not only facilitates efficient data removal but also dynamically\nadjusts the model to preserve its generalization capabilities. Through\nextensive experimentation, we demonstrate the efficacy of our approach in\nscenarios characterized by significant distributional shifts, making\nsubstantial contributions to the field of machine unlearning. This research\npaves the way for developing more resilient and adaptable unlearning\ntechniques, ensuring models remain robust and accurate in the dynamic landscape\nof data privacy and machine learning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "I.2.6"
    ],
    "primary_category": "cs.LG",
    "comment": "10 pages, 1 figure",
    "pdf_url": "http://arxiv.org/pdf/2403.08124v1",
    "published_date": "2024-03-12 23:21:09 UTC",
    "updated_date": "2024-03-12 23:21:09 UTC"
  },
  {
    "arxiv_id": "2403.08118v1",
    "title": "Characterising harmful data sources when constructing multi-fidelity surrogate models",
    "authors": [
      "Nicolau Andrés-Thió",
      "Mario Andrés Muñoz",
      "Kate Smith-Miles"
    ],
    "abstract": "Surrogate modelling techniques have seen growing attention in recent years\nwhen applied to both modelling and optimisation of industrial design problems.\nThese techniques are highly relevant when assessing the performance of a\nparticular design carries a high cost, as the overall cost can be mitigated via\nthe construction of a model to be queried in lieu of the available high-cost\nsource. The construction of these models can sometimes employ other sources of\ninformation which are both cheaper and less accurate. The existence of these\nsources however poses the question of which sources should be used when\nconstructing a model. Recent studies have attempted to characterise harmful\ndata sources to guide practitioners in choosing when to ignore a certain\nsource. These studies have done so in a synthetic setting, characterising\nsources using a large amount of data that is not available in practice. Some of\nthese studies have also been shown to potentially suffer from bias in the\nbenchmarks used in the analysis. In this study, we present a characterisation\nof harmful low-fidelity sources using only the limited data available to train\na surrogate model. We employ recently developed benchmark filtering techniques\nto conduct a bias-free assessment, providing objectively varied benchmark\nsuites of different sizes for future research. Analysing one of these benchmark\nsuites with the technique known as Instance Space Analysis, we provide an\nintuitive visualisation of when a low-fidelity source should be used and use\nthis analysis to provide guidelines that can be used in an applied industrial\nsetting.",
    "categories": [
      "stat.ME",
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "stat.ME",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.08118v1",
    "published_date": "2024-03-12 22:57:53 UTC",
    "updated_date": "2024-03-12 22:57:53 UTC"
  },
  {
    "arxiv_id": "2403.08115v2",
    "title": "Legally Binding but Unfair? Towards Assessing Fairness of Privacy Policies",
    "authors": [
      "Vincent Freiberger",
      "Erik Buchmann"
    ],
    "abstract": "Privacy policies are expected to inform data subjects about their data\nprotection rights and should explain the data controller's data management\npractices. Privacy policies only fulfill their purpose, if they are correctly\ninterpreted, understood, and trusted by the data subject. This implies that a\nprivacy policy is written in a fair way, e.g., it does not use polarizing\nterms, does not require a certain education, or does not assume a particular\nsocial background. We outline our approach to assessing fairness in privacy\npolicies. We identify from fundamental legal sources and fairness research, how\nthe dimensions informational fairness, representational fairness and ethics /\nmorality are related to privacy policies. We propose options to automatically\nassess policies in these fairness dimensions, based on text statistics,\nlinguistic methods and artificial intelligence. We conduct initial experiments\nwith German privacy policies to provide evidence that our approach is\napplicable. Our experiments indicate that there are issues in all three\ndimensions of fairness. This is important, as future privacy policies may be\nused in a corpus for legal artificial intelligence models.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL",
      "K.4.m"
    ],
    "primary_category": "cs.CY",
    "comment": "Accepted at IWSPA 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.08115v2",
    "published_date": "2024-03-12 22:53:32 UTC",
    "updated_date": "2024-05-08 14:47:39 UTC"
  },
  {
    "arxiv_id": "2403.14682v1",
    "title": "Deep Generative Domain Adaptation with Temporal Relation Knowledge for Cross-User Activity Recognition",
    "authors": [
      "Xiaozhou Ye",
      "Kevin I-Kai Wang"
    ],
    "abstract": "In human activity recognition (HAR), the assumption that training and testing\ndata are independent and identically distributed (i.i.d.) often fails,\nparticularly in cross-user scenarios where data distributions vary\nsignificantly. This discrepancy highlights the limitations of conventional\ndomain adaptation methods in HAR, which typically overlook the inherent\ntemporal relations in time-series data. To bridge this gap, our study\nintroduces a Conditional Variational Autoencoder with Universal Sequence\nMapping (CVAE-USM) approach, which addresses the unique challenges of\ntime-series domain adaptation in HAR by relaxing the i.i.d. assumption and\nleveraging temporal relations to align data distributions effectively across\ndifferent users. This method combines the strengths of Variational Autoencoder\n(VAE) and Universal Sequence Mapping (USM) to capture and utilize common\ntemporal patterns between users for improved activity recognition. Our results,\nevaluated on two public HAR datasets (OPPT and PAMAP2), demonstrate that\nCVAE-USM outperforms existing state-of-the-art methods, offering a more\naccurate and generalizable solution for cross-user activity recognition.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.14682v1",
    "published_date": "2024-03-12 22:48:23 UTC",
    "updated_date": "2024-03-12 22:48:23 UTC"
  },
  {
    "arxiv_id": "2403.17958v1",
    "title": "Deep Generative Domain Adaptation with Temporal Attention for Cross-User Activity Recognition",
    "authors": [
      "Xiaozhou Ye",
      "Kevin I-Kai Wang"
    ],
    "abstract": "In Human Activity Recognition (HAR), a predominant assumption is that the\ndata utilized for training and evaluation purposes are drawn from the same\ndistribution. It is also assumed that all data samples are independent and\nidentically distributed ($\\displaystyle i.i.d.$). Contrarily, practical\nimplementations often challenge this notion, manifesting data distribution\ndiscrepancies, especially in scenarios such as cross-user HAR. Domain\nadaptation is the promising approach to address these challenges inherent in\ncross-user HAR tasks. However, a clear gap in domain adaptation techniques is\nthe neglect of the temporal relation embedded within time series data during\nthe phase of aligning data distributions. Addressing this oversight, our\nresearch presents the Deep Generative Domain Adaptation with Temporal Attention\n(DGDATA) method. This novel method uniquely recognises and integrates temporal\nrelations during the domain adaptation process. By synergizing the capabilities\nof generative models with the Temporal Relation Attention mechanism, our method\nimproves the classification performance in cross-user HAR. A comprehensive\nevaluation has been conducted on three public sensor-based HAR datasets\ntargeting different scenarios and applications to demonstrate the efficacy of\nthe proposed DGDATA method.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.HC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.17958v1",
    "published_date": "2024-03-12 22:45:05 UTC",
    "updated_date": "2024-03-12 22:45:05 UTC"
  },
  {
    "arxiv_id": "2403.15424v1",
    "title": "Cross-user activity recognition using deep domain adaptation with temporal relation information",
    "authors": [
      "Xiaozhou Ye",
      "Waleed H. Abdulla",
      "Nirmal Nair",
      "Kevin I-Kai Wang"
    ],
    "abstract": "Human Activity Recognition (HAR) is a cornerstone of ubiquitous computing,\nwith promising applications in diverse fields such as health monitoring and\nambient assisted living. Despite significant advancements, sensor-based HAR\nmethods often operate under the assumption that training and testing data have\nidentical distributions. However, in many real-world scenarios, particularly in\nsensor-based HAR, this assumption is invalidated by out-of-distribution\n($\\displaystyle o.o.d.$) challenges, including differences from heterogeneous\nsensors, change over time, and individual behavioural variability. This paper\ncentres on the latter, exploring the cross-user HAR problem where behavioural\nvariability across individuals results in differing data distributions. To\naddress this challenge, we introduce the Deep Temporal State Domain Adaptation\n(DTSDA) model, an innovative approach tailored for time series domain\nadaptation in cross-user HAR. Contrary to the common assumption of sample\nindependence in existing domain adaptation approaches, DTSDA recognizes and\nharnesses the inherent temporal relations in the data. Therefore, we introduce\n'Temporal State', a concept that defined the different sub-activities within an\nactivity, consistent across different users. We ensure these sub-activities\nfollow a logical time sequence through 'Temporal Consistency' property and\npropose the 'Pseudo Temporal State Labeling' method to identify the\nuser-invariant temporal relations. Moreover, the design principle of DTSDA\nintegrates adversarial learning for better domain adaptation. Comprehensive\nevaluations on three HAR datasets demonstrate DTSDA's superior performance in\ncross-user HAR applications by briding individual behavioral variability using\ntemporal relations across sub-activities.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.CV",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.15424v1",
    "published_date": "2024-03-12 22:38:09 UTC",
    "updated_date": "2024-03-12 22:38:09 UTC"
  },
  {
    "arxiv_id": "2403.08111v1",
    "title": "AI-Assisted Causal Pathway Diagram for Human-Centered Design",
    "authors": [
      "Ruican Zhong",
      "Donghoon Shin",
      "Rosemary Meza",
      "Predrag Klasnja",
      "Lucas Colusso",
      "Gary Hsieh"
    ],
    "abstract": "This paper explores the integration of causal pathway diagrams (CPD) into\nhuman-centered design (HCD), investigating how these diagrams can enhance the\nearly stages of the design process. A dedicated CPD plugin for the online\ncollaborative whiteboard platform Miro was developed to streamline diagram\ncreation and offer real-time AI-driven guidance. Through a user study with\ndesigners (N=20), we found that CPD's branching and its emphasis on causal\nconnections supported both divergent and convergent processes during design.\nCPD can also facilitate communication among stakeholders. Additionally, we\nfound our plugin significantly reduces designers' cognitive workload and\nincreases their creativity during brainstorming, highlighting the implications\nof AI-assisted tools in supporting creative work and evidence-based designs.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CL",
      "H.5.2; I.2.7"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.08111v1",
    "published_date": "2024-03-12 22:36:27 UTC",
    "updated_date": "2024-03-12 22:36:27 UTC"
  },
  {
    "arxiv_id": "2403.15423v1",
    "title": "Cross-user activity recognition via temporal relation optimal transport",
    "authors": [
      "Xiaozhou Ye",
      "Kevin I-Kai Wang"
    ],
    "abstract": "Current research on human activity recognition (HAR) mainly assumes that\ntraining and testing data are drawn from the same distribution to achieve a\ngeneralised model, which means all the data are considered to be independent\nand identically distributed $\\displaystyle (i.i.d.) $. In many real-world\napplications, this assumption does not hold, and collected training and target\ntesting datasets have non-uniform distribution, such as in the case of\ncross-user HAR. Domain adaptation is a promising approach for cross-user HAR\ntasks. Existing domain adaptation works based on the assumption that samples in\neach domain are $\\displaystyle i.i.d. $ and do not consider the knowledge of\ntemporal relation hidden in time series data for aligning data distribution.\nThis strong assumption of $\\displaystyle i.i.d. $ may not be suitable for time\nseries-related domain adaptation methods because the samples formed by time\nseries segmentation and feature extraction techniques are only coarse\napproximations to $\\displaystyle i.i.d. $ assumption in each domain. In this\npaper, we propose the temporal relation optimal transport (TROT) method to\nutilise temporal relation and relax the $\\displaystyle i.i.d. $ assumption for\nthe samples in each domain for accurate and efficient knowledge transfer. We\nobtain the temporal relation representation and implement temporal relation\nalignment of activities via the Hidden Markov model (HMM) and optimal transport\n(OT) techniques. Besides, a new regularisation term that preserves temporal\nrelation order information for an improved optimal transport mapping is\nproposed to enhance the domain adaptation performance. Comprehensive\nexperiments are conducted on three public activity recognition datasets (i.e.\nOPPT, PAMAP2 and DSADS), demonstrating that TROT outperforms other\nstate-of-the-art methods.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.CV",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.15423v1",
    "published_date": "2024-03-12 22:33:56 UTC",
    "updated_date": "2024-03-12 22:33:56 UTC"
  },
  {
    "arxiv_id": "2403.08103v2",
    "title": "Contextual Clarity: Generating Sentences with Transformer Models using Context-Reverso Data",
    "authors": [
      "Ruslan Musaev"
    ],
    "abstract": "In the age of information abundance, the ability to provide users with\ncontextually relevant and concise information is crucial. Keyword in Context\n(KIC) generation is a task that plays a vital role in and generation\napplications, such as search engines, personal assistants, and content\nsummarization. In this paper, we present a novel approach to generating\nunambiguous and brief sentence-contexts for given keywords using the T5\ntransformer model, leveraging data obtained from the Context-Reverso API. The\ncode is available at https://github.com/Rusamus/word2context/tree/main .",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.08103v2",
    "published_date": "2024-03-12 22:23:08 UTC",
    "updated_date": "2024-03-14 10:47:32 UTC"
  },
  {
    "arxiv_id": "2403.15422v1",
    "title": "Machine Learning Techniques for Sensor-based Human Activity Recognition with Data Heterogeneity -- A Review",
    "authors": [
      "Xiaozhou Ye",
      "Kouichi Sakurai",
      "Nirmal Nair",
      "Kevin I-Kai Wang"
    ],
    "abstract": "Sensor-based Human Activity Recognition (HAR) is crucial in ubiquitous\ncomputing, analysing behaviours through multi-dimensional observations. Despite\nresearch progress, HAR confronts challenges, particularly in data distribution\nassumptions. Most studies often assume uniform data distributions across\ndatasets, contrasting with the varied nature of practical sensor data in human\nactivities. Addressing data heterogeneity issues can improve performance,\nreduce computational costs, and aid in developing personalized, adaptive models\nwith less annotated data. This review investigates how machine learning\naddresses data heterogeneity in HAR, by categorizing data heterogeneity types,\napplying corresponding suitable machine learning methods, summarizing available\ndatasets, and discussing future challenges.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.15422v1",
    "published_date": "2024-03-12 22:22:14 UTC",
    "updated_date": "2024-03-12 22:22:14 UTC"
  },
  {
    "arxiv_id": "2403.09728v1",
    "title": "Simulating Weighted Automata over Sequences and Trees with Transformers",
    "authors": [
      "Michael Rizvi",
      "Maude Lizaire",
      "Clara Lacroce",
      "Guillaume Rabusseau"
    ],
    "abstract": "Transformers are ubiquitous models in the natural language processing (NLP)\ncommunity and have shown impressive empirical successes in the past few years.\nHowever, little is understood about how they reason and the limits of their\ncomputational capabilities. These models do not process data sequentially, and\nyet outperform sequential neural models such as RNNs. Recent work has shown\nthat these models can compactly simulate the sequential reasoning abilities of\ndeterministic finite automata (DFAs). This leads to the following question: can\ntransformers simulate the reasoning of more complex finite state machines? In\nthis work, we show that transformers can simulate weighted finite automata\n(WFAs), a class of models which subsumes DFAs, as well as weighted tree\nautomata (WTA), a generalization of weighted automata to tree structured\ninputs. We prove these claims formally and provide upper bounds on the sizes of\nthe transformer models needed as a function of the number of states the target\nautomata. Empirically, we perform synthetic experiments showing that\ntransformers are able to learn these compact solutions via standard\ngradient-based training.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CC"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.09728v1",
    "published_date": "2024-03-12 21:54:34 UTC",
    "updated_date": "2024-03-12 21:54:34 UTC"
  },
  {
    "arxiv_id": "2403.14681v1",
    "title": "AI Ethics: A Bibliometric Analysis, Critical Issues, and Key Gaps",
    "authors": [
      "Di Kevin Gao",
      "Andrew Haverly",
      "Sudip Mittal",
      "Jiming Wu",
      "Jingdao Chen"
    ],
    "abstract": "Artificial intelligence (AI) ethics has emerged as a burgeoning yet pivotal\narea of scholarly research. This study conducts a comprehensive bibliometric\nanalysis of the AI ethics literature over the past two decades. The analysis\nreveals a discernible tripartite progression, characterized by an incubation\nphase, followed by a subsequent phase focused on imbuing AI with human-like\nattributes, culminating in a third phase emphasizing the development of\nhuman-centric AI systems. After that, they present seven key AI ethics issues,\nencompassing the Collingridge dilemma, the AI status debate, challenges\nassociated with AI transparency and explainability, privacy protection\ncomplications, considerations of justice and fairness, concerns about algocracy\nand human enfeeblement, and the issue of superintelligence. Finally, they\nidentify two notable research gaps in AI ethics regarding the large ethics\nmodel (LEM) and AI identification and extend an invitation for further\nscholarly research.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.14681v1",
    "published_date": "2024-03-12 21:43:21 UTC",
    "updated_date": "2024-03-12 21:43:21 UTC"
  },
  {
    "arxiv_id": "2403.08081v1",
    "title": "Mechanics of Next Token Prediction with Self-Attention",
    "authors": [
      "Yingcong Li",
      "Yixiao Huang",
      "M. Emrullah Ildiz",
      "Ankit Singh Rawat",
      "Samet Oymak"
    ],
    "abstract": "Transformer-based language models are trained on large datasets to predict\nthe next token given an input sequence. Despite this simple training objective,\nthey have led to revolutionary advances in natural language processing.\nUnderlying this success is the self-attention mechanism. In this work, we ask:\n$\\textit{What}$ $\\textit{does}$ $\\textit{a}$ $\\textit{single}$\n$\\textit{self-attention}$ $\\textit{layer}$ $\\textit{learn}$ $\\textit{from}$\n$\\textit{next-token}$ $\\textit{prediction?}$ We show that training\nself-attention with gradient descent learns an automaton which generates the\nnext token in two distinct steps: $\\textbf{(1)}$ $\\textbf{Hard}$\n$\\textbf{retrieval:}$ Given input sequence, self-attention precisely selects\nthe $\\textit{high-priority}$ $\\textit{input}$ $\\textit{tokens}$ associated with\nthe last input token. $\\textbf{(2)}$ $\\textbf{Soft}$ $\\textbf{composition:}$ It\nthen creates a convex combination of the high-priority tokens from which the\nnext token can be sampled. Under suitable conditions, we rigorously\ncharacterize these mechanics through a directed graph over tokens extracted\nfrom the training data. We prove that gradient descent implicitly discovers the\nstrongly-connected components (SCC) of this graph and self-attention learns to\nretrieve the tokens that belong to the highest-priority SCC available in the\ncontext window. Our theory relies on decomposing the model weights into a\ndirectional component and a finite component that correspond to hard retrieval\nand soft composition steps respectively. This also formalizes a related\nimplicit bias formula conjectured in [Tarzanagh et al. 2023]. We hope that\nthese findings shed light on how self-attention processes sequential data and\npave the path toward demystifying more complex architectures.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "math.OC"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to AISTATS 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.08081v1",
    "published_date": "2024-03-12 21:15:38 UTC",
    "updated_date": "2024-03-12 21:15:38 UTC"
  },
  {
    "arxiv_id": "2403.09727v1",
    "title": "Investigating the performance of Retrieval-Augmented Generation and fine-tuning for the development of AI-driven knowledge-based systems",
    "authors": [
      "Robert Lakatos",
      "Peter Pollner",
      "Andras Hajdu",
      "Tamas Joo"
    ],
    "abstract": "The development of generative large language models (G-LLM) opened up new\nopportunities for the development of new types of knowledge-based systems\nsimilar to ChatGPT, Bing, or Gemini. Fine-tuning (FN) and Retrieval-Augmented\nGeneration (RAG) are the techniques that can be used to implement domain\nadaptation for the development of G-LLM-based knowledge systems. In our study,\nusing ROUGE, BLEU, METEOR scores, and cosine similarity, we compare and examine\nthe performance of RAG and FN for the GPT-J-6B, OPT-6.7B, LlaMA, LlaMA-2\nlanguage models. Based on measurements shown on different datasets, we\ndemonstrate that RAG-based constructions are more efficient than models\nproduced with FN. We point out that connecting RAG and FN is not trivial,\nbecause connecting FN models with RAG can cause a decrease in performance.\nFurthermore, we outline a simple RAG-based architecture which, on average,\noutperforms the FN models by 16% in terms of the ROGUE score, 15% in the case\nof the BLEU score, and 53% based on the cosine similarity. This shows the\nsignificant advantage of RAG over FN in terms of hallucination, which is not\noffset by the fact that the average 8% better METEOR score of FN models\nindicates greater creativity compared to RAG.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.09727v1",
    "published_date": "2024-03-12 21:06:31 UTC",
    "updated_date": "2024-03-12 21:06:31 UTC"
  },
  {
    "arxiv_id": "2403.08077v1",
    "title": "A Multimodal Intermediate Fusion Network with Manifold Learning for Stress Detection",
    "authors": [
      "Morteza Bodaghi",
      "Majid Hosseini",
      "Raju Gottumukkala"
    ],
    "abstract": "Multimodal deep learning methods capture synergistic features from multiple\nmodalities and have the potential to improve accuracy for stress detection\ncompared to unimodal methods. However, this accuracy gain typically comes from\nhigh computational cost due to the high-dimensional feature spaces, especially\nfor intermediate fusion. Dimensionality reduction is one way to optimize\nmultimodal learning by simplifying data and making the features more amenable\nto processing and analysis, thereby reducing computational complexity. This\npaper introduces an intermediate multimodal fusion network with manifold\nlearning-based dimensionality reduction. The multimodal network generates\nindependent representations from biometric signals and facial landmarks through\n1D-CNN and 2D-CNN. Finally, these features are fused and fed to another 1D-CNN\nlayer, followed by a fully connected dense layer. We compared various\ndimensionality reduction techniques for different variations of unimodal and\nmultimodal networks. We observe that the intermediate-level fusion with the\nMulti-Dimensional Scaling (MDS) manifold method showed promising results with\nan accuracy of 96.00\\% in a Leave-One-Subject-Out Cross-Validation (LOSO-CV)\nparadigm over other dimensional reduction methods. MDS had the highest\ncomputational cost among manifold learning methods. However, while\noutperforming other networks, it managed to reduce the computational cost of\nthe proposed networks by 25\\% when compared to six well-known conventional\nfeature selection methods used in the preprocessing step.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "This work was accepted to The 3rd International Conference on\n  Computing and Machine Intelligence (ICMI 2024)",
    "pdf_url": "http://arxiv.org/pdf/2403.08077v1",
    "published_date": "2024-03-12 21:06:19 UTC",
    "updated_date": "2024-03-12 21:06:19 UTC"
  },
  {
    "arxiv_id": "2403.14680v3",
    "title": "Trust in AI: Progress, Challenges, and Future Directions",
    "authors": [
      "Saleh Afroogh",
      "Ali Akbari",
      "Evan Malone",
      "Mohammadali Kargar",
      "Hananeh Alambeigi"
    ],
    "abstract": "The increasing use of artificial intelligence (AI) systems in our daily life\nthrough various applications, services, and products explains the significance\nof trust/distrust in AI from a user perspective. AI-driven systems (as opposed\nto other technologies) have ubiquitously diffused in our life not only as some\nbeneficial tools to be used by human agents but also are going to be\nsubstitutive agents on our behalf, or manipulative minds that would influence\nhuman thought, decision, and agency. Trust/distrust in AI plays the role of a\nregulator and could significantly control the level of this diffusion, as trust\ncan increase, and distrust may reduce the rate of adoption of AI. Recently,\nvarieties of studies have paid attention to the variant dimension of\ntrust/distrust in AI, and its relevant considerations. In this systematic\nliterature review, after conceptualization of trust in the current AI\nliterature review, we will investigate trust in different types of\nhuman-Machine interaction, and its impact on technology acceptance in different\ndomains. In addition to that, we propose a taxonomy of technical (i.e., safety,\naccuracy, robustness) and non-technical axiological (i.e., ethical, legal, and\nmixed) trustworthiness metrics, and some trustworthy measurements. Moreover, we\nexamine some major trust-breakers in AI (e.g., autonomy and dignity threat),\nand trust makers; and propose some future directions and probable solutions for\nthe transition to a trustworthy AI.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.14680v3",
    "published_date": "2024-03-12 20:26:49 UTC",
    "updated_date": "2024-04-04 15:34:37 UTC"
  },
  {
    "arxiv_id": "2403.08059v2",
    "title": "FluoroSAM: A Language-aligned Foundation Model for X-ray Image Segmentation",
    "authors": [
      "Benjamin D. Killeen",
      "Liam J. Wang",
      "Han Zhang",
      "Mehran Armand",
      "Russell H. Taylor",
      "Dave Dreizin",
      "Greg Osgood",
      "Mathias Unberath"
    ],
    "abstract": "Automated X-ray image segmentation would accelerate research and development\nin diagnostic and interventional precision medicine. Prior efforts have\ncontributed task-specific models capable of solving specific image analysis\nproblems, but the utility of these models is restricted to their particular\ntask domain, and expanding to broader use requires additional data, labels, and\nretraining efforts. Recently, foundation models (FMs) -- machine learning\nmodels trained on large amounts of highly variable data thus enabling broad\napplicability -- have emerged as promising tools for automated image analysis.\nExisting FMs for medical image analysis focus on scenarios and modalities where\nobjects are clearly defined by visually apparent boundaries, such as surgical\ntool segmentation in endoscopy. X-ray imaging, by contrast, does not generally\noffer such clearly delineated boundaries or structure priors. During X-ray\nimage formation, complex 3D structures are projected in transmission onto the\nimaging plane, resulting in overlapping features of varying opacity and shape.\nTo pave the way toward an FM for comprehensive and automated analysis of\narbitrary medical X-ray images, we develop FluoroSAM, a language-aligned\nvariant of the Segment-Anything Model, trained from scratch on 1.6M synthetic\nX-ray images. FluoroSAM is trained on data including masks for 128 organ types\nand 464 non-anatomical objects, such as tools and implants. In real X-ray\nimages of cadaveric specimens, FluoroSAM is able to segment bony anatomical\nstructures based on text-only prompting with 0.51 and 0.79 DICE with\npoint-based refinement, outperforming competing SAM variants for all\nstructures. FluoroSAM is also capable of zero-shot generalization to segmenting\nclasses beyond the training set thanks to its language alignment, which we\ndemonstrate for full lung segmentation on real chest X-rays.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.08059v2",
    "published_date": "2024-03-12 20:11:38 UTC",
    "updated_date": "2024-03-28 00:59:37 UTC"
  },
  {
    "arxiv_id": "2403.08049v1",
    "title": "TutoAI: A Cross-domain Framework for AI-assisted Mixed-media Tutorial Creation on Physical Tasks",
    "authors": [
      "Yuexi Chen",
      "Vlad I. Morariu",
      "Anh Truong",
      "Zhicheng Liu"
    ],
    "abstract": "Mixed-media tutorials, which integrate videos, images, text, and diagrams to\nteach procedural skills, offer more browsable alternatives than timeline-based\nvideos. However, manually creating such tutorials is tedious, and existing\nautomated solutions are often restricted to a particular domain. While AI\nmodels hold promise, it is unclear how to effectively harness their powers,\ngiven the multi-modal data involved and the vast landscape of models. We\npresent TutoAI, a cross-domain framework for AI-assisted mixed-media tutorial\ncreation on physical tasks. First, we distill common tutorial components by\nsurveying existing work; then, we present an approach to identify, assemble,\nand evaluate AI models for component extraction; finally, we propose guidelines\nfor designing user interfaces (UI) that support tutorial creation based on\nAI-generated components. We show that TutoAI has achieved higher or similar\nquality compared to a baseline model in preliminary user studies.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.HC",
    "comment": "CHI 2024, supplementary materials:\n  https://hdi.cs.umd.edu/papers/TutoAI_CHI24_Supp.pdf",
    "pdf_url": "http://arxiv.org/pdf/2403.08049v1",
    "published_date": "2024-03-12 19:46:59 UTC",
    "updated_date": "2024-03-12 19:46:59 UTC"
  },
  {
    "arxiv_id": "2403.08036v1",
    "title": "A Review of Cybersecurity Incidents in the Food and Agriculture Sector",
    "authors": [
      "Ajay Kulkarni",
      "Yingjie Wang",
      "Munisamy Gopinath",
      "Dan Sobien",
      "Abdul Rahman",
      "Feras A. Batarseh"
    ],
    "abstract": "The increasing utilization of emerging technologies in the Food & Agriculture\n(FA) sector has heightened the need for security to minimize cyber risks.\nConsidering this aspect, this manuscript reviews disclosed and documented\ncybersecurity incidents in the FA sector. For this purpose, thirty\ncybersecurity incidents were identified, which took place between July 2011 and\nApril 2023. The details of these incidents are reported from multiple sources\nsuch as: the private industry and flash notifications generated by the Federal\nBureau of Investigation (FBI), internal reports from the affected\norganizations, and available media sources. Considering the available\ninformation, a brief description of the security threat, ransom amount, and\nimpact on the organization are discussed for each incident. This review reports\nan increased frequency of cybersecurity threats to the FA sector. To minimize\nthese cyber risks, popular cybersecurity frameworks and recent\nagriculture-specific cybersecurity solutions are also discussed. Further, the\nneed for AI assurance in the FA sector is explained, and the Farmer-Centered AI\n(FCAI) framework is proposed. The main aim of the FCAI framework is to support\nfarmers in decision-making for agricultural production, by incorporating AI\nassurance. Lastly, the effects of the reported cyber incidents on other\ncritical infrastructures, food security, and the economy are noted, along with\nspecifying the open issues for future development.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CR",
    "comment": "Preprint. Submitted for journal publication",
    "pdf_url": "http://arxiv.org/pdf/2403.08036v1",
    "published_date": "2024-03-12 19:15:20 UTC",
    "updated_date": "2024-03-12 19:15:20 UTC"
  },
  {
    "arxiv_id": "2403.08035v1",
    "title": "Harnessing Artificial Intelligence to Combat Online Hate: Exploring the Challenges and Opportunities of Large Language Models in Hate Speech Detection",
    "authors": [
      "Tharindu Kumarage",
      "Amrita Bhattacharjee",
      "Joshua Garland"
    ],
    "abstract": "Large language models (LLMs) excel in many diverse applications beyond\nlanguage generation, e.g., translation, summarization, and sentiment analysis.\nOne intriguing application is in text classification. This becomes pertinent in\nthe realm of identifying hateful or toxic speech -- a domain fraught with\nchallenges and ethical dilemmas. In our study, we have two objectives: firstly,\nto offer a literature review revolving around LLMs as classifiers, emphasizing\ntheir role in detecting and classifying hateful or toxic content. Subsequently,\nwe explore the efficacy of several LLMs in classifying hate speech: identifying\nwhich LLMs excel in this task as well as their underlying attributes and\ntraining. Providing insight into the factors that contribute to an LLM\nproficiency (or lack thereof) in discerning hateful content. By combining a\ncomprehensive literature review with an empirical analysis, our paper strives\nto shed light on the capabilities and constraints of LLMs in the crucial domain\nof hate speech detection.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.08035v1",
    "published_date": "2024-03-12 19:12:28 UTC",
    "updated_date": "2024-03-12 19:12:28 UTC"
  },
  {
    "arxiv_id": "2403.08032v1",
    "title": "LG-Traj: LLM Guided Pedestrian Trajectory Prediction",
    "authors": [
      "Pranav Singh Chib",
      "Pravendra Singh"
    ],
    "abstract": "Accurate pedestrian trajectory prediction is crucial for various\napplications, and it requires a deep understanding of pedestrian motion\npatterns in dynamic environments. However, existing pedestrian trajectory\nprediction methods still need more exploration to fully leverage these motion\npatterns. This paper investigates the possibilities of using Large Language\nModels (LLMs) to improve pedestrian trajectory prediction tasks by inducing\nmotion cues. We introduce LG-Traj, a novel approach incorporating LLMs to\ngenerate motion cues present in pedestrian past/observed trajectories. Our\napproach also incorporates motion cues present in pedestrian future\ntrajectories by clustering future trajectories of training data using a mixture\nof Gaussians. These motion cues, along with pedestrian coordinates, facilitate\na better understanding of the underlying representation. Furthermore, we\nutilize singular value decomposition to augment the observed trajectories,\nincorporating them into the model learning process to further enhance\nrepresentation learning. Our method employs a transformer-based architecture\ncomprising a motion encoder to model motion patterns and a social decoder to\ncapture social interactions among pedestrians. We demonstrate the effectiveness\nof our approach on popular pedestrian trajectory prediction benchmarks, namely\nETH-UCY and SDD, and present various ablation experiments to validate our\napproach.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Under Review",
    "pdf_url": "http://arxiv.org/pdf/2403.08032v1",
    "published_date": "2024-03-12 19:06:23 UTC",
    "updated_date": "2024-03-12 19:06:23 UTC"
  },
  {
    "arxiv_id": "2403.08017v2",
    "title": "Red Teaming Models for Hyperspectral Image Analysis Using Explainable AI",
    "authors": [
      "Vladimir Zaigrajew",
      "Hubert Baniecki",
      "Lukasz Tulczyjew",
      "Agata M. Wijata",
      "Jakub Nalepa",
      "Nicolas Longépé",
      "Przemyslaw Biecek"
    ],
    "abstract": "Remote sensing (RS) applications in the space domain demand machine learning\n(ML) models that are reliable, robust, and quality-assured, making red teaming\na vital approach for identifying and exposing potential flaws and biases. Since\nboth fields advance independently, there is a notable gap in integrating red\nteaming strategies into RS. This paper introduces a methodology for examining\nML models operating on hyperspectral images within the HYPERVIEW challenge,\nfocusing on soil parameters' estimation. We use post-hoc explanation methods\nfrom the Explainable AI (XAI) domain to critically assess the best performing\nmodel that won the HYPERVIEW challenge and served as an inspiration for the\nmodel deployed on board the INTUITION-1 hyperspectral mission. Our approach\neffectively red teams the model by pinpointing and validating key shortcomings,\nconstructing a model that achieves comparable performance using just 1% of the\ninput features and a mere up to 5% performance loss. Additionally, we propose a\nnovel way of visualizing explanations that integrate domain-specific\ninformation about hyperspectral bands (wavelengths) and data transformations to\nbetter suit interpreting models for hyperspectral image analysis.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "14 pages, 9 figures, ICLR 2024 Machine Learning for Remote Sensing\n  (ML4RS) Workshop",
    "pdf_url": "http://arxiv.org/pdf/2403.08017v2",
    "published_date": "2024-03-12 18:28:32 UTC",
    "updated_date": "2024-03-14 18:40:34 UTC"
  },
  {
    "arxiv_id": "2403.08011v1",
    "title": "Gujarati-English Code-Switching Speech Recognition using ensemble prediction of spoken language",
    "authors": [
      "Yash Sharma",
      "Basil Abraham",
      "Preethi Jyothi"
    ],
    "abstract": "An important and difficult task in code-switched speech recognition is to\nrecognize the language, as lots of words in two languages can sound similar,\nespecially in some accents. We focus on improving performance of end-to-end\nAutomatic Speech Recognition models by conditioning transformer layers on\nlanguage ID of words and character in the output in an per layer supervised\nmanner. To this end, we propose two methods of introducing language specific\nparameters and explainability in the multi-head attention mechanism, and\nimplement a Temporal Loss that helps maintain continuity in input alignment.\nDespite being unable to reduce WER significantly, our method shows promise in\npredicting the correct language from just spoken data. We introduce\nregularization in the language prediction by dropping LID in the sequence,\nwhich helps align long repeated output sequences.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Bachelor's thesis, 28 pages, includes appendix",
    "pdf_url": "http://arxiv.org/pdf/2403.08011v1",
    "published_date": "2024-03-12 18:21:20 UTC",
    "updated_date": "2024-03-12 18:21:20 UTC"
  },
  {
    "arxiv_id": "2403.08004v2",
    "title": "Leveraging LLMs for On-the-Fly Instruction Guided Image Editing",
    "authors": [
      "Rodrigo Santos",
      "João Silva",
      "António Branco"
    ],
    "abstract": "The combination of language processing and image processing keeps attracting\nincreased interest given recent impressive advances that leverage the combined\nstrengths of both domains of research. Among these advances, the task of\nediting an image on the basis solely of a natural language instruction stands\nout as a most challenging endeavour. While recent approaches for this task\nresort, in one way or other, to some form of preliminary preparation, training\nor fine-tuning, this paper explores a novel approach: We propose a\npreparation-free method that permits instruction-guided image editing on the\nfly. This approach is organized along three steps properly orchestrated that\nresort to image captioning and DDIM inversion, followed by obtaining the edit\ndirection embedding, followed by image editing proper. While dispensing with\npreliminary preparation, our approach demonstrates to be effective and\ncompetitive, outperforming recent, state of the art models for this task when\nevaluated on the MAGICBRUSH dataset.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.08004v2",
    "published_date": "2024-03-12 18:12:50 UTC",
    "updated_date": "2024-12-04 10:35:25 UTC"
  },
  {
    "arxiv_id": "2403.07979v1",
    "title": "Do Agents Dream of Electric Sheep?: Improving Generalization in Reinforcement Learning through Generative Learning",
    "authors": [
      "Giorgio Franceschelli",
      "Mirco Musolesi"
    ],
    "abstract": "The Overfitted Brain hypothesis suggests dreams happen to allow\ngeneralization in the human brain. Here, we ask if the same is true for\nreinforcement learning agents as well. Given limited experience in a real\nenvironment, we use imagination-based reinforcement learning to train a policy\non dream-like episodes, where non-imaginative, predicted trajectories are\nmodified through generative augmentations. Experiments on four ProcGen\nenvironments show that, compared to classic imagination and offline training on\ncollected experience, our method can reach a higher level of generalization\nwhen dealing with sparsely rewarded environments.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.07979v1",
    "published_date": "2024-03-12 18:00:02 UTC",
    "updated_date": "2024-03-12 18:00:02 UTC"
  },
  {
    "arxiv_id": "2403.07869v2",
    "title": "TeleMoMa: A Modular and Versatile Teleoperation System for Mobile Manipulation",
    "authors": [
      "Shivin Dass",
      "Wensi Ai",
      "Yuqian Jiang",
      "Samik Singh",
      "Jiaheng Hu",
      "Ruohan Zhang",
      "Peter Stone",
      "Ben Abbatematteo",
      "Roberto Martín-Martín"
    ],
    "abstract": "A critical bottleneck limiting imitation learning in robotics is the lack of\ndata. This problem is more severe in mobile manipulation, where collecting\ndemonstrations is harder than in stationary manipulation due to the lack of\navailable and easy-to-use teleoperation interfaces. In this work, we\ndemonstrate TeleMoMa, a general and modular interface for whole-body\nteleoperation of mobile manipulators. TeleMoMa unifies multiple human\ninterfaces including RGB and depth cameras, virtual reality controllers,\nkeyboard, joysticks, etc., and any combination thereof. In its more accessible\nversion, TeleMoMa works using simply vision (e.g., an RGB-D camera), lowering\nthe entry bar for humans to provide mobile manipulation demonstrations. We\ndemonstrate the versatility of TeleMoMa by teleoperating several existing\nmobile manipulators - PAL Tiago++, Toyota HSR, and Fetch - in simulation and\nthe real world. We demonstrate the quality of the demonstrations collected with\nTeleMoMa by training imitation learning policies for mobile manipulation tasks\ninvolving synchronized whole-body motion. Finally, we also show that TeleMoMa's\nteleoperation channel enables teleoperation on site, looking at the robot, or\nremote, sending commands and observations through a computer network, and\nperform user studies to evaluate how easy it is for novice users to learn to\ncollect demonstrations with different combinations of human interfaces enabled\nby our system. We hope TeleMoMa becomes a helpful tool for the community\nenabling researchers to collect whole-body mobile manipulation demonstrations.\nFor more information and video results,\nhttps://robin-lab.cs.utexas.edu/telemoma-web.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.07869v2",
    "published_date": "2024-03-12 17:58:01 UTC",
    "updated_date": "2024-03-21 19:57:46 UTC"
  },
  {
    "arxiv_id": "2403.07865v5",
    "title": "CodeAttack: Revealing Safety Generalization Challenges of Large Language Models via Code Completion",
    "authors": [
      "Qibing Ren",
      "Chang Gao",
      "Jing Shao",
      "Junchi Yan",
      "Xin Tan",
      "Wai Lam",
      "Lizhuang Ma"
    ],
    "abstract": "The rapid advancement of Large Language Models (LLMs) has brought about\nremarkable generative capabilities but also raised concerns about their\npotential misuse. While strategies like supervised fine-tuning and\nreinforcement learning from human feedback have enhanced their safety, these\nmethods primarily focus on natural languages, which may not generalize to other\ndomains. This paper introduces CodeAttack, a framework that transforms natural\nlanguage inputs into code inputs, presenting a novel environment for testing\nthe safety generalization of LLMs. Our comprehensive studies on\nstate-of-the-art LLMs including GPT-4, Claude-2, and Llama-2 series reveal a\nnew and universal safety vulnerability of these models against code input:\nCodeAttack bypasses the safety guardrails of all models more than 80\\% of the\ntime. We find that a larger distribution gap between CodeAttack and natural\nlanguage leads to weaker safety generalization, such as encoding natural\nlanguage input with data structures. Furthermore, we give our hypotheses about\nthe success of CodeAttack: the misaligned bias acquired by LLMs during code\ntraining, prioritizing code completion over avoiding the potential safety risk.\nFinally, we analyze potential mitigation measures. These findings highlight new\nsafety risks in the code domain and the need for more robust safety alignment\nalgorithms to match the code capabilities of LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CR",
      "cs.LG",
      "cs.SE"
    ],
    "primary_category": "cs.CL",
    "comment": "ACL Findings 2024, Code is available at\n  https://github.com/renqibing/CodeAttack",
    "pdf_url": "http://arxiv.org/pdf/2403.07865v5",
    "published_date": "2024-03-12 17:55:38 UTC",
    "updated_date": "2024-09-14 11:41:49 UTC"
  },
  {
    "arxiv_id": "2403.09725v1",
    "title": "RAD-PHI2: Instruction Tuning PHI-2 for Radiology",
    "authors": [
      "Mercy Ranjit",
      "Gopinath Ganapathy",
      "Shaury Srivastav",
      "Tanuja Ganu",
      "Srujana Oruganti"
    ],
    "abstract": "Small Language Models (SLMs) have shown remarkable performance in general\ndomain language understanding, reasoning and coding tasks, but their\ncapabilities in the medical domain, particularly concerning radiology text, is\nless explored. In this study, we investigate the application of SLMs for\ngeneral radiology knowledge specifically question answering related to\nunderstanding of symptoms, radiological appearances of findings, differential\ndiagnosis, assessing prognosis, and suggesting treatments w.r.t diseases\npertaining to different organ systems. Additionally, we explore the utility of\nSLMs in handling text-related tasks with respect to radiology reports within\nAI-driven radiology workflows. We fine-tune Phi-2, a SLM with 2.7 billion\nparameters using high-quality educational content from Radiopaedia, a\ncollaborative online radiology resource. The resulting language model,\nRadPhi-2-Base, exhibits the ability to address general radiology queries across\nvarious systems (e.g., chest, cardiac). Furthermore, we investigate Phi-2 for\ninstruction tuning, enabling it to perform specific tasks. By fine-tuning Phi-2\non both general domain tasks and radiology-specific tasks related to chest\nX-ray reports, we create Rad-Phi2. Our empirical results reveal that Rad-Phi2\nBase and Rad-Phi2 perform comparably or even outperform larger models such as\nMistral-7B-Instruct-v0.2 and GPT-4 providing concise and precise answers. In\nsummary, our work demonstrates the feasibility and effectiveness of utilizing\nSLMs in radiology workflows both for knowledge related queries as well as for\nperforming specific tasks related to radiology reports thereby opening up new\navenues for enhancing the quality and efficiency of radiology practice.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "J.3"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.09725v1",
    "published_date": "2024-03-12 17:27:22 UTC",
    "updated_date": "2024-03-12 17:27:22 UTC"
  },
  {
    "arxiv_id": "2403.07839v1",
    "title": "MoPE-CLIP: Structured Pruning for Efficient Vision-Language Models with Module-wise Pruning Error Metric",
    "authors": [
      "Haokun Lin",
      "Haoli Bai",
      "Zhili Liu",
      "Lu Hou",
      "Muyi Sun",
      "Linqi Song",
      "Ying Wei",
      "Zhenan Sun"
    ],
    "abstract": "Vision-language pre-trained models have achieved impressive performance on\nvarious downstream tasks. However, their large model sizes hinder their\nutilization on platforms with limited computational resources. We find that\ndirectly using smaller pre-trained models and applying magnitude-based pruning\non CLIP models leads to inflexibility and inferior performance. Recent efforts\nfor VLP compression either adopt uni-modal compression metrics resulting in\nlimited performance or involve costly mask-search processes with learnable\nmasks. In this paper, we first propose the Module-wise Pruning Error (MoPE)\nmetric, accurately assessing CLIP module importance by performance decline on\ncross-modal tasks. Using the MoPE metric, we introduce a unified pruning\nframework applicable to both pre-training and task-specific fine-tuning\ncompression stages. For pre-training, MoPE-CLIP effectively leverages knowledge\nfrom the teacher model, significantly reducing pre-training costs while\nmaintaining strong zero-shot capabilities. For fine-tuning, consecutive pruning\nfrom width to depth yields highly competitive task-specific models. Extensive\nexperiments in two stages demonstrate the effectiveness of the MoPE metric, and\nMoPE-CLIP outperforms previous state-of-the-art VLP compression methods.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "18 pages, 8 figures, Published in CVPR2024",
    "pdf_url": "http://arxiv.org/pdf/2403.07839v1",
    "published_date": "2024-03-12 17:24:26 UTC",
    "updated_date": "2024-03-12 17:24:26 UTC"
  },
  {
    "arxiv_id": "2403.07818v2",
    "title": "Label Dropout: Improved Deep Learning Echocardiography Segmentation Using Multiple Datasets With Domain Shift and Partial Labelling",
    "authors": [
      "Iman Islam",
      "Esther Puyol-Antón",
      "Bram Ruijsink",
      "Andrew J. Reader",
      "Andrew P. King"
    ],
    "abstract": "Echocardiography (echo) is the first imaging modality used when assessing\ncardiac function. The measurement of functional biomarkers from echo relies\nupon the segmentation of cardiac structures and deep learning models have been\nproposed to automate the segmentation process. However, in order to translate\nthese tools to widespread clinical use it is important that the segmentation\nmodels are robust to a wide variety of images (e.g. acquired from different\nscanners, by operators with different levels of expertise etc.). To achieve\nthis level of robustness it is necessary that the models are trained with\nmultiple diverse datasets. A significant challenge faced when training with\nmultiple diverse datasets is the variation in label presence, i.e. the combined\ndata are often partially-labelled. Adaptations of the cross entropy loss\nfunction have been proposed to deal with partially labelled data. In this paper\nwe show that training naively with such a loss function and multiple diverse\ndatasets can lead to a form of shortcut learning, where the model associates\nlabel presence with domain characteristics, leading to a drop in performance.\nTo address this problem, we propose a novel label dropout scheme to break the\nlink between domain characteristics and the presence or absence of labels. We\ndemonstrate that label dropout improves echo segmentation Dice score by 62% and\n25% on two cardiac structures when training using multiple diverse partially\nlabelled datasets.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "10 pages, 5 figures, ASMUS 2024, Held in Conjunction with MICCAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.07818v2",
    "published_date": "2024-03-12 16:57:56 UTC",
    "updated_date": "2024-08-15 11:51:57 UTC"
  },
  {
    "arxiv_id": "2403.07816v1",
    "title": "Branch-Train-MiX: Mixing Expert LLMs into a Mixture-of-Experts LLM",
    "authors": [
      "Sainbayar Sukhbaatar",
      "Olga Golovneva",
      "Vasu Sharma",
      "Hu Xu",
      "Xi Victoria Lin",
      "Baptiste Rozière",
      "Jacob Kahn",
      "Daniel Li",
      "Wen-tau Yih",
      "Jason Weston",
      "Xian Li"
    ],
    "abstract": "We investigate efficient methods for training Large Language Models (LLMs) to\npossess capabilities in multiple specialized domains, such as coding, math\nreasoning and world knowledge. Our method, named Branch-Train-MiX (BTX), starts\nfrom a seed model, which is branched to train experts in embarrassingly\nparallel fashion with high throughput and reduced communication cost. After\nindividual experts are asynchronously trained, BTX brings together their\nfeedforward parameters as experts in Mixture-of-Expert (MoE) layers and\naverages the remaining parameters, followed by an MoE-finetuning stage to learn\ntoken-level routing. BTX generalizes two special cases, the Branch-Train-Merge\nmethod, which does not have the MoE finetuning stage to learn routing, and\nsparse upcycling, which omits the stage of training experts asynchronously.\nCompared to alternative approaches, BTX achieves the best accuracy-efficiency\ntradeoff.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.07816v1",
    "published_date": "2024-03-12 16:54:58 UTC",
    "updated_date": "2024-03-12 16:54:58 UTC"
  },
  {
    "arxiv_id": "2403.07815v3",
    "title": "Chronos: Learning the Language of Time Series",
    "authors": [
      "Abdul Fatir Ansari",
      "Lorenzo Stella",
      "Caner Turkmen",
      "Xiyuan Zhang",
      "Pedro Mercado",
      "Huibin Shen",
      "Oleksandr Shchur",
      "Syama Sundar Rangapuram",
      "Sebastian Pineda Arango",
      "Shubham Kapoor",
      "Jasper Zschiegner",
      "Danielle C. Maddix",
      "Hao Wang",
      "Michael W. Mahoney",
      "Kari Torkkola",
      "Andrew Gordon Wilson",
      "Michael Bohlke-Schneider",
      "Yuyang Wang"
    ],
    "abstract": "We introduce Chronos, a simple yet effective framework for pretrained\nprobabilistic time series models. Chronos tokenizes time series values using\nscaling and quantization into a fixed vocabulary and trains existing\ntransformer-based language model architectures on these tokenized time series\nvia the cross-entropy loss. We pretrained Chronos models based on the T5 family\n(ranging from 20M to 710M parameters) on a large collection of publicly\navailable datasets, complemented by a synthetic dataset that we generated via\nGaussian processes to improve generalization. In a comprehensive benchmark\nconsisting of 42 datasets, and comprising both classical local models and deep\nlearning methods, we show that Chronos models: (a) significantly outperform\nother methods on datasets that were part of the training corpus; and (b) have\ncomparable and occasionally superior zero-shot performance on new datasets,\nrelative to methods that were trained specifically on them. Our results\ndemonstrate that Chronos models can leverage time series data from diverse\ndomains to improve zero-shot accuracy on unseen forecasting tasks, positioning\npretrained models as a viable tool to greatly simplify forecasting pipelines.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Code and model checkpoints available at\n  https://github.com/amazon-science/chronos-forecasting",
    "pdf_url": "http://arxiv.org/pdf/2403.07815v3",
    "published_date": "2024-03-12 16:53:54 UTC",
    "updated_date": "2024-11-04 17:42:45 UTC"
  },
  {
    "arxiv_id": "2403.07805v3",
    "title": "Beyond Memorization: The Challenge of Random Memory Access in Language Models",
    "authors": [
      "Tongyao Zhu",
      "Qian Liu",
      "Liang Pang",
      "Zhengbao Jiang",
      "Min-Yen Kan",
      "Min Lin"
    ],
    "abstract": "Recent developments in Language Models (LMs) have shown their effectiveness\nin NLP tasks, particularly in knowledge-intensive tasks. However, the\nmechanisms underlying knowledge storage and memory access within their\nparameters remain elusive. In this paper, we investigate whether a generative\nLM (e.g., GPT-2) is able to access its memory sequentially or randomly. Through\ncarefully-designed synthetic tasks, covering the scenarios of full recitation,\nselective recitation and grounded question answering, we reveal that LMs manage\nto sequentially access their memory while encountering challenges in randomly\naccessing memorized content. We find that techniques including recitation and\npermutation improve the random memory access capability of LMs. Furthermore, by\napplying this intervention to realistic scenarios of open-domain question\nanswering, we validate that enhancing random access by recitation leads to\nnotable improvements in question answering. The code to reproduce our\nexperiments can be found at https://github.com/sail-sg/lm-random-memory-access.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "9 pages, 4 figures; accepted by ACL 2024 (oral)",
    "pdf_url": "http://arxiv.org/pdf/2403.07805v3",
    "published_date": "2024-03-12 16:42:44 UTC",
    "updated_date": "2024-07-22 15:29:00 UTC"
  },
  {
    "arxiv_id": "2403.07797v1",
    "title": "Joint Selection: Adaptively Incorporating Public Information for Private Synthetic Data",
    "authors": [
      "Miguel Fuentes",
      "Brett Mullins",
      "Ryan McKenna",
      "Gerome Miklau",
      "Daniel Sheldon"
    ],
    "abstract": "Mechanisms for generating differentially private synthetic data based on\nmarginals and graphical models have been successful in a wide range of\nsettings. However, one limitation of these methods is their inability to\nincorporate public data. Initializing a data generating model by pre-training\non public data has shown to improve the quality of synthetic data, but this\ntechnique is not applicable when model structure is not determined a priori. We\ndevelop the mechanism jam-pgm, which expands the adaptive measurements\nframework to jointly select between measuring public data and private data.\nThis technique allows for public data to be included in a graphical-model-based\nmechanism. We show that jam-pgm is able to outperform both publicly assisted\nand non publicly assisted synthetic data generation mechanisms even when the\npublic data distribution is biased.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.07797v1",
    "published_date": "2024-03-12 16:34:07 UTC",
    "updated_date": "2024-03-12 16:34:07 UTC"
  },
  {
    "arxiv_id": "2403.13000v2",
    "title": "Duwak: Dual Watermarks in Large Language Models",
    "authors": [
      "Chaoyi Zhu",
      "Jeroen Galjaard",
      "Pin-Yu Chen",
      "Lydia Y. Chen"
    ],
    "abstract": "As large language models (LLM) are increasingly used for text generation\ntasks, it is critical to audit their usages, govern their applications, and\nmitigate their potential harms. Existing watermark techniques are shown\neffective in embedding single human-imperceptible and machine-detectable\npatterns without significantly affecting generated text quality and semantics.\nHowever, the efficiency in detecting watermarks, i.e., the minimum number of\ntokens required to assert detection with significance and robustness against\npost-editing, is still debatable. In this paper, we propose, Duwak, to\nfundamentally enhance the efficiency and quality of watermarking by embedding\ndual secret patterns in both token probability distribution and sampling\nschemes. To mitigate expression degradation caused by biasing toward certain\ntokens, we design a contrastive search to watermark the sampling scheme, which\nminimizes the token repetition and enhances the diversity. We theoretically\nexplain the interdependency of the two watermarks within Duwak. We evaluate\nDuwak extensively on Llama2 under various post-editing attacks, against four\nstate-of-the-art watermarking techniques and combinations of them. Our results\nshow that Duwak marked text achieves the highest watermarked text quality at\nthe lowest required token count for detection, up to 70% tokens less than\nexisting approaches, especially under post paraphrasing.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.13000v2",
    "published_date": "2024-03-12 16:25:38 UTC",
    "updated_date": "2024-08-08 13:33:12 UTC"
  },
  {
    "arxiv_id": "2403.07788v2",
    "title": "DexCap: Scalable and Portable Mocap Data Collection System for Dexterous Manipulation",
    "authors": [
      "Chen Wang",
      "Haochen Shi",
      "Weizhuo Wang",
      "Ruohan Zhang",
      "Li Fei-Fei",
      "C. Karen Liu"
    ],
    "abstract": "Imitation learning from human hand motion data presents a promising avenue\nfor imbuing robots with human-like dexterity in real-world manipulation tasks.\nDespite this potential, substantial challenges persist, particularly with the\nportability of existing hand motion capture (mocap) systems and the complexity\nof translating mocap data into effective robotic policies. To tackle these\nissues, we introduce DexCap, a portable hand motion capture system, alongside\nDexIL, a novel imitation algorithm for training dexterous robot skills directly\nfrom human hand mocap data. DexCap offers precise, occlusion-resistant tracking\nof wrist and finger motions based on SLAM and electromagnetic field together\nwith 3D observations of the environment. Utilizing this rich dataset, DexIL\nemploys inverse kinematics and point cloud-based imitation learning to\nseamlessly replicate human actions with robot hands. Beyond direct learning\nfrom human motion, DexCap also offers an optional human-in-the-loop correction\nmechanism during policy rollouts to refine and further improve task\nperformance. Through extensive evaluation across six challenging dexterous\nmanipulation tasks, our approach not only demonstrates superior performance but\nalso showcases the system's capability to effectively learn from in-the-wild\nmocap data, paving the way for future data collection methods in the pursuit of\nhuman-level robot dexterity. More details can be found at\nhttps://dex-cap.github.io",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.07788v2",
    "published_date": "2024-03-12 16:23:49 UTC",
    "updated_date": "2024-07-04 04:35:04 UTC"
  },
  {
    "arxiv_id": "2403.07769v3",
    "title": "Transforming Competition into Collaboration: The Revolutionary Role of Multi-Agent Systems and Language Models in Modern Organizations",
    "authors": [
      "Carlos Jose Xavier Cruz"
    ],
    "abstract": "This article explores the dynamic influence of computational entities based\non multi-agent systems theory (SMA) combined with large language models (LLM),\nwhich are characterized by their ability to simulate complex human\ninteractions, as a possibility to revolutionize human user interaction from the\nuse of specialized artificial agents to support everything from operational\norganizational processes to strategic decision making based on applied\nknowledge and human orchestration. Previous investigations reveal that there\nare limitations, particularly in the autonomous approach of artificial agents,\nespecially when dealing with new challenges and pragmatic tasks such as\ninducing logical reasoning and problem solving. It is also considered that\ntraditional techniques, such as the stimulation of chains of thoughts, require\nexplicit human guidance. In our approach we employ agents developed from large\nlanguage models (LLM), each with distinct prototyping that considers behavioral\nelements, driven by strategies that stimulate the generation of knowledge based\non the use case proposed in the scenario (role-play) business, using a\ndiscussion approach between agents (guided conversation). We demonstrate the\npotential of developing agents useful for organizational strategies, based on\nmulti-agent system theories (SMA) and innovative uses based on large language\nmodels (LLM based), offering a differentiated and adaptable experiment to\ndifferent applications, complexities, domains, and capabilities from LLM.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CY",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.07769v3",
    "published_date": "2024-03-12 15:56:10 UTC",
    "updated_date": "2024-03-15 11:44:51 UTC"
  },
  {
    "arxiv_id": "2403.07750v2",
    "title": "Synth$^2$: Boosting Visual-Language Models with Synthetic Captions and Image Embeddings",
    "authors": [
      "Sahand Sharifzadeh",
      "Christos Kaplanis",
      "Shreya Pathak",
      "Dharshan Kumaran",
      "Anastasija Ilic",
      "Jovana Mitrovic",
      "Charles Blundell",
      "Andrea Banino"
    ],
    "abstract": "The creation of high-quality human-labeled image-caption datasets presents a\nsignificant bottleneck in the development of Visual-Language Models (VLMs). In\nthis work, we investigate an approach that leverages the strengths of Large\nLanguage Models (LLMs) and image generation models to create synthetic\nimage-text pairs for efficient and effective VLM training. Our method employs a\npretrained text-to-image model to synthesize image embeddings from captions\ngenerated by an LLM. Despite the text-to-image model and VLM initially being\ntrained on the same data, our approach leverages the image generator's ability\nto create novel compositions, resulting in synthetic image embeddings that\nexpand beyond the limitations of the original dataset. Extensive experiments\ndemonstrate that our VLM, finetuned on synthetic data achieves comparable\nperformance to models trained solely on human-annotated data, while requiring\nsignificantly less data. Furthermore, we perform a set of analyses on captions\nwhich reveals that semantic diversity and balance are key aspects for better\ndownstream performance. Finally, we show that synthesizing images in the image\nembedding space is 25\\% faster than in the pixel space. We believe our work not\nonly addresses a significant challenge in VLM training but also opens up\npromising avenues for the development of self-improving multi-modal models.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "9 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.07750v2",
    "published_date": "2024-03-12 15:36:42 UTC",
    "updated_date": "2024-06-07 12:10:47 UTC"
  },
  {
    "arxiv_id": "2403.07748v2",
    "title": "Ariadne and Theseus: Exploration and Rendezvous with Two Mobile Agents in an Unknown Graph",
    "authors": [
      "Romain Cosson"
    ],
    "abstract": "We investigate two fundamental problems in mobile computing: exploration and\nrendezvous, with two distinct mobile agents in an unknown graph. The agents may\ncommunicate by reading and writing information on whiteboards that are located\nat all nodes. They both move along one adjacent edge at every time-step. In the\nexploration problem, the agents start from the same arbitrary node and must\ntraverse all the edges. We present an algorithm achieving collective\nexploration in $m$ time-steps, where $m$ is the number of edges of the graph.\nThis improves over the guarantee of depth-first search, which requires $2m$\ntime-steps. In the rendezvous problem, the agents start from different nodes of\nthe graph and must meet as fast as possible. We present an algorithm\nguaranteeing rendezvous in at most $\\frac{3}{2}m$ time-steps. This improves\nover the so-called `wait for Mommy' algorithm which is based on depth-first\nsearch and which also requires $2m$ time-steps. Importantly, all our guarantees\nare derived from a more general asynchronous setting in which the speeds of the\nagents are controlled by an adversary at all times. Our guarantees generalize\nto weighted graphs, when replacing the number of edges $m$ with the sum of all\nedge lengths. We show that our guarantees are met with matching lower-bounds in\nthe asynchronous setting.",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "primary_category": "cs.MA",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.07748v2",
    "published_date": "2024-03-12 15:33:09 UTC",
    "updated_date": "2024-07-04 15:40:49 UTC"
  },
  {
    "arxiv_id": "2403.07747v2",
    "title": "FineMath: A Fine-Grained Mathematical Evaluation Benchmark for Chinese Large Language Models",
    "authors": [
      "Yan Liu",
      "Renren Jin",
      "Ling Shi",
      "Zheng Yao",
      "Deyi Xiong"
    ],
    "abstract": "To thoroughly assess the mathematical reasoning abilities of Large Language\nModels (LLMs), we need to carefully curate evaluation datasets covering diverse\nmathematical concepts and mathematical problems at different difficulty levels.\nIn pursuit of this objective, we propose FineMath in this paper, a fine-grained\nmathematical evaluation benchmark dataset for assessing Chinese LLMs. FineMath\nis created to cover the major key mathematical concepts taught in elementary\nschool math, which are further divided into 17 categories of math word\nproblems, enabling in-depth analysis of mathematical reasoning abilities of\nLLMs. All the 17 categories of math word problems are manually annotated with\ntheir difficulty levels according to the number of reasoning steps required to\nsolve these problems. We conduct extensive experiments on a wide range of LLMs\non FineMath and find that there is still considerable room for improvements in\nterms of mathematical reasoning capability of Chinese LLMs. We also carry out\nan in-depth analysis on the evaluation process and methods that have been\noverlooked previously. These two factors significantly influence the model\nresults and our understanding of their mathematical reasoning capabilities. The\ndataset will be publicly available soon.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.07747v2",
    "published_date": "2024-03-12 15:32:39 UTC",
    "updated_date": "2024-09-06 10:19:10 UTC"
  },
  {
    "arxiv_id": "2403.07745v1",
    "title": "Probabilistic Easy Variational Causal Effect",
    "authors": [
      "Usef Faghihi",
      "Amir Saki"
    ],
    "abstract": "Let $X$ and $Z$ be random vectors, and $Y=g(X,Z)$. In this paper, on the one\nhand, for the case that $X$ and $Z$ are continuous, by using the ideas from the\ntotal variation and the flux of $g$, we develop a point of view in causal\ninference capable of dealing with a broad domain of causal problems. Indeed, we\nfocus on a function, called Probabilistic Easy Variational Causal Effect\n(PEACE), which can measure the direct causal effect of $X$ on $Y$ with respect\nto continuously and interventionally changing the values of $X$ while keeping\nthe value of $Z$ constant. PEACE is a function of $d\\ge 0$, which is a degree\nmanaging the strengths of probability density values $f(x|z)$. On the other\nhand, we generalize the above idea for the discrete case and show its\ncompatibility with the continuous case. Further, we investigate some properties\nof PEACE using measure theoretical concepts. Furthermore, we provide some\nidentifiability criteria and several examples showing the generic capability of\nPEACE. We note that PEACE can deal with the causal problems for which\nmicro-level or just macro-level changes in the value of the input variables are\nimportant. Finally, PEACE is stable under small changes in $\\partial\ng_{in}/\\partial x$ and the joint distribution of $X$ and $Z$, where $g_{in}$ is\nobtained from $g$ by removing all functional relationships defining $X$ and\n$Z$.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG",
      "26A45, 6008, 68T37, 68T20, 68T27, 68U99, 46N30, 62R10",
      "G.3; I.2.3"
    ],
    "primary_category": "stat.ML",
    "comment": "45 pages, 9 Figures",
    "pdf_url": "http://arxiv.org/pdf/2403.07745v1",
    "published_date": "2024-03-12 15:28:21 UTC",
    "updated_date": "2024-03-12 15:28:21 UTC"
  },
  {
    "arxiv_id": "2403.07743v3",
    "title": "Equipping Computational Pathology Systems with Artifact Processing Pipelines: A Showcase for Computation and Performance Trade-offs",
    "authors": [
      "Neel Kanwal",
      "Farbod Khoraminia",
      "Umay Kiraz",
      "Andres Mosquera-Zamudio",
      "Carlos Monteagudo",
      "Emiel A. M. Janssen",
      "Tahlita C. M. Zuiverloon",
      "Chunmig Rong",
      "Kjersti Engan"
    ],
    "abstract": "Histopathology is a gold standard for cancer diagnosis under a microscopic\nexamination. However, histological tissue processing procedures result in\nartifacts, which are ultimately transferred to the digitized version of glass\nslides, known as whole slide images (WSIs). Artifacts are diagnostically\nirrelevant areas and may result in wrong deep learning (DL) algorithms\npredictions. Therefore, detecting and excluding artifacts in the computational\npathology (CPATH) system is essential for reliable automated diagnosis. In this\npaper, we propose a mixture of experts (MoE) scheme for detecting five notable\nartifacts, including damaged tissue, blur, folded tissue, air bubbles, and\nhistologically irrelevant blood from WSIs. First, we train independent binary\nDL models as experts to capture particular artifact morphology. Then, we\nensemble their predictions using a fusion mechanism. We apply probabilistic\nthresholding over the final probability distribution to improve the sensitivity\nof the MoE. We developed DL pipelines using two MoEs and two multiclass models\nof state-of-the-art deep convolutional neural networks (DCNNs) and vision\ntransformers (ViTs). DCNNs-based MoE and ViTs-based MoE schemes outperformed\nsimpler multiclass models and were tested on datasets from different hospitals\nand cancer types, where MoE using DCNNs yielded the best results. The proposed\nMoE yields 86.15% F1 and 97.93% sensitivity scores on unseen data, retaining\nless computational cost for inference than MoE using ViTs. This best\nperformance of MoEs comes with relatively higher computational trade-offs than\nmulticlass models. The proposed artifact detection pipeline will not only\nensure reliable CPATH predictions but may also provide quality control.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "eess.IV",
    "comment": "Submitted to BMC Medical Informatics and Decision Making Journal",
    "pdf_url": "http://arxiv.org/pdf/2403.07743v3",
    "published_date": "2024-03-12 15:22:05 UTC",
    "updated_date": "2024-05-23 09:10:49 UTC"
  },
  {
    "arxiv_id": "2403.07741v2",
    "title": "Uncertainty Quantification with Deep Ensembles for 6D Object Pose Estimation",
    "authors": [
      "Kira Wursthorn",
      "Markus Hillemann",
      "Markus Ulrich"
    ],
    "abstract": "The estimation of 6D object poses is a fundamental task in many computer\nvision applications. Particularly, in high risk scenarios such as human-robot\ninteraction, industrial inspection, and automation, reliable pose estimates are\ncrucial. In the last years, increasingly accurate and robust\ndeep-learning-based approaches for 6D object pose estimation have been\nproposed. Many top-performing methods are not end-to-end trainable but consist\nof multiple stages. In the context of deep uncertainty quantification, deep\nensembles are considered as state of the art since they have been proven to\nproduce well-calibrated and robust uncertainty estimates. However, deep\nensembles can only be applied to methods that can be trained end-to-end. In\nthis work, we propose a method to quantify the uncertainty of multi-stage 6D\nobject pose estimation approaches with deep ensembles. For the implementation,\nwe choose SurfEmb as representative, since it is one of the top-performing 6D\nobject pose estimation approaches in the BOP Challenge 2022. We apply\nestablished metrics and concepts for deep uncertainty quantification to\nevaluate the results. Furthermore, we propose a novel uncertainty calibration\nscore for regression tasks to quantify the quality of the estimated\nuncertainty.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "8 pages",
    "pdf_url": "http://arxiv.org/pdf/2403.07741v2",
    "published_date": "2024-03-12 15:19:25 UTC",
    "updated_date": "2024-05-02 09:00:21 UTC"
  },
  {
    "arxiv_id": "2403.07733v4",
    "title": "Beyond Pixels: Enhancing LIME with Hierarchical Features and Segmentation Foundation Models",
    "authors": [
      "Patrick Knab",
      "Sascha Marton",
      "Christian Bartelt"
    ],
    "abstract": "LIME (Local Interpretable Model-agnostic Explanations) is a popular XAI\nframework for unraveling decision-making processes in vision machine-learning\nmodels. The technique utilizes image segmentation methods to identify fixed\nregions for calculating feature importance scores as explanations. Therefore,\npoor segmentation can weaken the explanation and reduce the importance of\nsegments, ultimately affecting the overall clarity of interpretation. To\naddress these challenges, we introduce the DSEG-LIME (Data-Driven Segmentation\nLIME) framework, featuring: i) a data-driven segmentation for human-recognized\nfeature generation by foundation model integration, and ii) a user-steered\ngranularity in the hierarchical segmentation procedure through composition. Our\nfindings demonstrate that DSEG outperforms on several XAI metrics on\npre-trained ImageNet models and improves the alignment of explanations with\nhuman-recognized concepts. The code is available under: https://github.\ncom/patrick-knab/DSEG-LIME",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.07733v4",
    "published_date": "2024-03-12 15:13:12 UTC",
    "updated_date": "2025-02-03 10:44:34 UTC"
  },
  {
    "arxiv_id": "2403.07724v1",
    "title": "Balancing Fairness and Accuracy in Data-Restricted Binary Classification",
    "authors": [
      "Zachary McBride Lazri",
      "Danial Dervovic",
      "Antigoni Polychroniadou",
      "Ivan Brugere",
      "Dana Dachman-Soled",
      "Min Wu"
    ],
    "abstract": "Applications that deal with sensitive information may have restrictions\nplaced on the data available to a machine learning (ML) classifier. For\nexample, in some applications, a classifier may not have direct access to\nsensitive attributes, affecting its ability to produce accurate and fair\ndecisions. This paper proposes a framework that models the trade-off between\naccuracy and fairness under four practical scenarios that dictate the type of\ndata available for analysis. Prior works examine this trade-off by analyzing\nthe outputs of a scoring function that has been trained to implicitly learn the\nunderlying distribution of the feature vector, class label, and sensitive\nattribute of a dataset. In contrast, our framework directly analyzes the\nbehavior of the optimal Bayesian classifier on this underlying distribution by\nconstructing a discrete approximation it from the dataset itself. This approach\nenables us to formulate multiple convex optimization problems, which allow us\nto answer the question: How is the accuracy of a Bayesian classifier affected\nin different data restricting scenarios when constrained to be fair? Analysis\nis performed on a set of fairness definitions that include group and individual\nfairness. Experiments on three datasets demonstrate the utility of the proposed\nframework as a tool for quantifying the trade-offs among different fairness\nnotions and their distributional dependencies.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.07724v1",
    "published_date": "2024-03-12 15:01:27 UTC",
    "updated_date": "2024-03-12 15:01:27 UTC"
  },
  {
    "arxiv_id": "2403.07720v2",
    "title": "Multi-modal Auto-regressive Modeling via Visual Words",
    "authors": [
      "Tianshuo Peng",
      "Zuchao Li",
      "Lefei Zhang",
      "Hai Zhao",
      "Ping Wang",
      "Bo Du"
    ],
    "abstract": "Large Language Models (LLMs), benefiting from the auto-regressive modelling\napproach performed on massive unannotated texts corpora, demonstrates powerful\nperceptual and reasoning capabilities. However, as for extending\nauto-regressive modelling to multi-modal scenarios to build Large Multi-modal\nModels (LMMs), there lies a great difficulty that the image information is\nprocessed in the LMM as continuous visual embeddings, which cannot obtain\ndiscrete supervised labels for classification.In this paper, we successfully\nperform multi-modal auto-regressive modeling with a unified objective for the\nfirst time.Specifically, we propose the concept of visual tokens, which maps\nthe visual features to probability distributions over LLM's vocabulary,\nproviding supervision information for visual modelling.We further explore the\ndistribution of visual features in the semantic space within LMM and the\npossibility of using text embeddings to represent visual\ninformation.Experimental results and ablation studies on 5 VQA tasks and 4\nbenchmark toolkits validate the powerful performance of our proposed approach.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "ACM MM 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.07720v2",
    "published_date": "2024-03-12 14:58:52 UTC",
    "updated_date": "2024-09-23 08:51:01 UTC"
  },
  {
    "arxiv_id": "2403.07718v5",
    "title": "WorkArena: How Capable Are Web Agents at Solving Common Knowledge Work Tasks?",
    "authors": [
      "Alexandre Drouin",
      "Maxime Gasse",
      "Massimo Caccia",
      "Issam H. Laradji",
      "Manuel Del Verme",
      "Tom Marty",
      "Léo Boisvert",
      "Megh Thakkar",
      "Quentin Cappart",
      "David Vazquez",
      "Nicolas Chapados",
      "Alexandre Lacoste"
    ],
    "abstract": "We study the use of large language model-based agents for interacting with\nsoftware via web browsers. Unlike prior work, we focus on measuring the agents'\nability to perform tasks that span the typical daily work of knowledge workers\nutilizing enterprise software systems. To this end, we propose WorkArena, a\nremote-hosted benchmark of 33 tasks based on the widely-used ServiceNow\nplatform. We also introduce BrowserGym, an environment for the design and\nevaluation of such agents, offering a rich set of actions as well as multimodal\nobservations. Our empirical evaluation reveals that while current agents show\npromise on WorkArena, there remains a considerable gap towards achieving full\ntask automation. Notably, our analysis uncovers a significant performance\ndisparity between open and closed-source LLMs, highlighting a critical area for\nfuture exploration and development in the field.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "21 pages, 11 figures, preprint",
    "pdf_url": "http://arxiv.org/pdf/2403.07718v5",
    "published_date": "2024-03-12 14:58:45 UTC",
    "updated_date": "2024-07-23 06:19:28 UTC"
  },
  {
    "arxiv_id": "2403.07969v2",
    "title": "KnowCoder: Coding Structured Knowledge into LLMs for Universal Information Extraction",
    "authors": [
      "Zixuan Li",
      "Yutao Zeng",
      "Yuxin Zuo",
      "Weicheng Ren",
      "Wenxuan Liu",
      "Miao Su",
      "Yucan Guo",
      "Yantao Liu",
      "Xiang Li",
      "Zhilei Hu",
      "Long Bai",
      "Wei Li",
      "Yidan Liu",
      "Pan Yang",
      "Xiaolong Jin",
      "Jiafeng Guo",
      "Xueqi Cheng"
    ],
    "abstract": "In this paper, we propose KnowCoder, a Large Language Model (LLM) to conduct\nUniversal Information Extraction (UIE) via code generation. KnowCoder aims to\ndevelop a kind of unified schema representation that LLMs can easily understand\nand an effective learning framework that encourages LLMs to follow schemas and\nextract structured knowledge accurately. To achieve these, KnowCoder introduces\na code-style schema representation method to uniformly transform different\nschemas into Python classes, with which complex schema information, such as\nconstraints among tasks in UIE, can be captured in an LLM-friendly manner. We\nfurther construct a code-style schema library covering over $\\textbf{30,000}$\ntypes of knowledge, which is the largest one for UIE, to the best of our\nknowledge. To ease the learning process of LLMs, KnowCoder contains a two-phase\nlearning framework that enhances its schema understanding ability via code\npretraining and its schema following ability via instruction tuning. After code\npretraining on around $1.5$B automatically constructed data, KnowCoder already\nattains remarkable generalization ability and achieves relative improvements by\n$\\textbf{49.8%}$ F1, compared to LLaMA2, under the few-shot setting. After\ninstruction tuning, KnowCoder further exhibits strong generalization ability on\nunseen schemas and achieves up to $\\textbf{12.5%}$ and $\\textbf{21.9%}$,\ncompared to sota baselines, under the zero-shot setting and the low resource\nsetting, respectively. Additionally, based on our unified schema\nrepresentations, various human-annotated datasets can simultaneously be\nutilized to refine KnowCoder, which achieves significant improvements up to\n$\\textbf{7.5%}$ under the supervised setting.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.07969v2",
    "published_date": "2024-03-12 14:56:34 UTC",
    "updated_date": "2024-03-14 02:47:41 UTC"
  },
  {
    "arxiv_id": "2403.07711v4",
    "title": "SSM Meets Video Diffusion Models: Efficient Long-Term Video Generation with Structured State Spaces",
    "authors": [
      "Yuta Oshima",
      "Shohei Taniguchi",
      "Masahiro Suzuki",
      "Yutaka Matsuo"
    ],
    "abstract": "Given the remarkable achievements in image generation through diffusion\nmodels, the research community has shown increasing interest in extending these\nmodels to video generation. Recent diffusion models for video generation have\npredominantly utilized attention layers to extract temporal features. However,\nattention layers are limited by their computational costs, which increase\nquadratically with the sequence length. This limitation presents significant\nchallenges when generating longer video sequences using diffusion models. To\novercome this challenge, we propose leveraging state-space models (SSMs) as\ntemporal feature extractors. SSMs (e.g., Mamba) have recently gained attention\nas promising alternatives due to their linear-time memory consumption relative\nto sequence length. In line with previous research suggesting that using\nbidirectional SSMs is effective for understanding spatial features in image\ngeneration, we found that bidirectionality is also beneficial for capturing\ntemporal features in video data, rather than relying on traditional\nunidirectional SSMs. We conducted comprehensive evaluations on multiple\nlong-term video datasets, such as MineRL Navigate, across various model sizes.\nFor sequences up to 256 frames, SSM-based models require less memory to achieve\nthe same FVD as attention-based models. Moreover, SSM-based models often\ndeliver better performance with comparable GPU memory usage. Our codes are\navailable at https://github.com/shim0114/SSM-Meets-Video-Diffusion-Models.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted as a workshop paper at ICLR 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.07711v4",
    "published_date": "2024-03-12 14:53:56 UTC",
    "updated_date": "2024-09-03 09:24:20 UTC"
  },
  {
    "arxiv_id": "2403.07708v2",
    "title": "Improving Reinforcement Learning from Human Feedback Using Contrastive Rewards",
    "authors": [
      "Wei Shen",
      "Xiaoying Zhang",
      "Yuanshun Yao",
      "Rui Zheng",
      "Hongyi Guo",
      "Yang Liu"
    ],
    "abstract": "Reinforcement learning from human feedback (RLHF) is the mainstream paradigm\nused to align large language models (LLMs) with human preferences. Yet existing\nRLHF heavily relies on accurate and informative reward models, which are\nvulnerable and sensitive to noise from various sources, e.g. human labeling\nerrors, making the pipeline fragile. In this work, we improve the effectiveness\nof the reward model by introducing a penalty term on the reward, named as\n\\textit{contrastive rewards}. %Contrastive rewards Our approach involves two\nsteps: (1) an offline sampling step to obtain responses to prompts that serve\nas baseline calculation and (2) a contrastive reward calculated using the\nbaseline responses and used in the Proximal Policy Optimization (PPO) step. We\nshow that contrastive rewards enable the LLM to penalize reward uncertainty,\nimprove robustness, encourage improvement over baselines, calibrate according\nto task difficulty, and reduce variance in PPO. We show empirically contrastive\nrewards can improve RLHF substantially, evaluated by both GPTs and humans, and\nour method consistently outperforms strong baselines.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.07708v2",
    "published_date": "2024-03-12 14:51:57 UTC",
    "updated_date": "2024-03-14 02:02:31 UTC"
  },
  {
    "arxiv_id": "2403.07704v1",
    "title": "Symmetric Q-learning: Reducing Skewness of Bellman Error in Online Reinforcement Learning",
    "authors": [
      "Motoki Omura",
      "Takayuki Osa",
      "Yusuke Mukuta",
      "Tatsuya Harada"
    ],
    "abstract": "In deep reinforcement learning, estimating the value function to evaluate the\nquality of states and actions is essential. The value function is often trained\nusing the least squares method, which implicitly assumes a Gaussian error\ndistribution. However, a recent study suggested that the error distribution for\ntraining the value function is often skewed because of the properties of the\nBellman operator, and violates the implicit assumption of normal error\ndistribution in the least squares method. To address this, we proposed a method\ncalled Symmetric Q-learning, in which the synthetic noise generated from a\nzero-mean distribution is added to the target values to generate a Gaussian\nerror distribution. We evaluated the proposed method on continuous control\nbenchmark tasks in MuJoCo. It improved the sample efficiency of a\nstate-of-the-art reinforcement learning method by reducing the skewness of the\nerror distribution.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at AAAI 2024: The 38th Annual AAAI Conference on Artificial\n  Intelligence (Main Tech Track)",
    "pdf_url": "http://arxiv.org/pdf/2403.07704v1",
    "published_date": "2024-03-12 14:49:19 UTC",
    "updated_date": "2024-03-12 14:49:19 UTC"
  },
  {
    "arxiv_id": "2403.07693v2",
    "title": "Large, Small or Both: A Novel Data Augmentation Framework Based on Language Models for Debiasing Opinion Summarization",
    "authors": [
      "Yanyue Zhang",
      "Pengfei Li",
      "Yilong Lai",
      "Deyu Zhou",
      "Yulan He"
    ],
    "abstract": "As more than 70$\\%$ of reviews in the existing opinion summary data set are\npositive, current opinion summarization approaches are reluctant to generate\nnegative summaries given the input of negative texts. To address such sentiment\nbias, a direct approach without the over-reliance on a specific framework is to\ngenerate additional data based on large language models to balance the\nemotional distribution of the dataset. However, data augmentation based on\nlarge language models faces two disadvantages: 1) the potential issues or\ntoxicity in the augmented data; 2) the expensive costs. Therefore, in this\npaper, we propose a novel data augmentation framework based on both large and\nsmall language models for debiasing opinion summarization. In specific, a small\nsize of synthesized negative reviews is obtained by rewriting the positive text\nvia a large language model. Then, a disentangle reconstruction model is trained\nbased on the generated data. After training, a large amount of synthetic data\ncan be obtained by decoding the new representation obtained from the\ncombination of different sample representations and filtering based on\nconfusion degree and sentiment classification. Experiments have proved that our\nframework can effectively alleviate emotional bias same as using only large\nmodels, but more economically.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.07693v2",
    "published_date": "2024-03-12 14:37:03 UTC",
    "updated_date": "2024-03-19 19:20:05 UTC"
  },
  {
    "arxiv_id": "2403.07691v2",
    "title": "ORPO: Monolithic Preference Optimization without Reference Model",
    "authors": [
      "Jiwoo Hong",
      "Noah Lee",
      "James Thorne"
    ],
    "abstract": "While recent preference alignment algorithms for language models have\ndemonstrated promising results, supervised fine-tuning (SFT) remains imperative\nfor achieving successful convergence. In this paper, we study the crucial role\nof SFT within the context of preference alignment, emphasizing that a minor\npenalty for the disfavored generation style is sufficient for\npreference-aligned SFT. Building on this foundation, we introduce a\nstraightforward and innovative reference model-free monolithic odds ratio\npreference optimization algorithm, ORPO, eliminating the necessity for an\nadditional preference alignment phase. We demonstrate, both empirically and\ntheoretically, that the odds ratio is a sensible choice for contrasting favored\nand disfavored styles during SFT across the diverse sizes from 125M to 7B.\nSpecifically, fine-tuning Phi-2 (2.7B), Llama-2 (7B), and Mistral (7B) with\nORPO on the UltraFeedback alone surpasses the performance of state-of-the-art\nlanguage models with more than 7B and 13B parameters: achieving up to 12.20% on\n$\\text{AlpacaEval}_{2.0}$ (Figure 1), 66.19% on IFEval (instruction-level\nloose, Table 6), and 7.32 in MT-Bench (Figure 12). We release code and model\ncheckpoints for Mistral-ORPO-$\\alpha$ (7B) and Mistral-ORPO-$\\beta$ (7B).",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Preprint",
    "pdf_url": "http://arxiv.org/pdf/2403.07691v2",
    "published_date": "2024-03-12 14:34:08 UTC",
    "updated_date": "2024-03-14 07:47:08 UTC"
  },
  {
    "arxiv_id": "2403.07688v1",
    "title": "Maxwell's Demon at Work: Efficient Pruning by Leveraging Saturation of Neurons",
    "authors": [
      "Simon Dufort-Labbé",
      "Pierluca D'Oro",
      "Evgenii Nikishin",
      "Razvan Pascanu",
      "Pierre-Luc Bacon",
      "Aristide Baratin"
    ],
    "abstract": "When training deep neural networks, the phenomenon of $\\textit{dying\nneurons}$ $\\unicode{x2013}$units that become inactive or saturated, output zero\nduring training$\\unicode{x2013}$ has traditionally been viewed as undesirable,\nlinked with optimization challenges, and contributing to plasticity loss in\ncontinual learning scenarios. In this paper, we reassess this phenomenon,\nfocusing on sparsity and pruning. By systematically exploring the impact of\nvarious hyperparameter configurations on dying neurons, we unveil their\npotential to facilitate simple yet effective structured pruning algorithms. We\nintroduce $\\textit{Demon Pruning}$ (DemP), a method that controls the\nproliferation of dead neurons, dynamically leading to network sparsity.\nAchieved through a combination of noise injection on active units and a\none-cycled schedule regularization strategy, DemP stands out for its simplicity\nand broad applicability. Experiments on CIFAR10 and ImageNet datasets\ndemonstrate that DemP surpasses existing structured pruning techniques,\nshowcasing superior accuracy-sparsity tradeoffs and training speedups. These\nfindings suggest a novel perspective on dying neurons as a valuable resource\nfor efficient model compression and optimization.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.07688v1",
    "published_date": "2024-03-12 14:28:06 UTC",
    "updated_date": "2024-03-12 14:28:06 UTC"
  },
  {
    "arxiv_id": "2403.07687v1",
    "title": "Annotations on a Budget: Leveraging Geo-Data Similarity to Balance Model Performance and Annotation Cost",
    "authors": [
      "Oana Ignat",
      "Longju Bai",
      "Joan Nwatu",
      "Rada Mihalcea"
    ],
    "abstract": "Current foundation models have shown impressive performance across various\ntasks. However, several studies have revealed that these models are not\neffective for everyone due to the imbalanced geographical and economic\nrepresentation of the data used in the training process. Most of this data\ncomes from Western countries, leading to poor results for underrepresented\ncountries. To address this issue, more data needs to be collected from these\ncountries, but the cost of annotation can be a significant bottleneck. In this\npaper, we propose methods to identify the data to be annotated to balance model\nperformance and annotation costs. Our approach first involves finding the\ncountries with images of topics (objects and actions) most visually distinct\nfrom those already in the training datasets used by current large\nvision-language foundation models. Next, we identify countries with higher\nvisual similarity for these topics and show that using data from these\ncountries to supplement the training data improves model performance and\nreduces annotation costs. The resulting lists of countries and corresponding\ntopics are made available at\nhttps://github.com/MichiganNLP/visual_diversity_budget.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "accepted at COLING 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.07687v1",
    "published_date": "2024-03-12 14:27:17 UTC",
    "updated_date": "2024-03-12 14:27:17 UTC"
  },
  {
    "arxiv_id": "2403.07968v2",
    "title": "Do Deep Neural Network Solutions Form a Star Domain?",
    "authors": [
      "Ankit Sonthalia",
      "Alexander Rubinstein",
      "Ehsan Abbasnejad",
      "Seong Joon Oh"
    ],
    "abstract": "It has recently been conjectured that neural network solution sets reachable\nvia stochastic gradient descent (SGD) are convex, considering permutation\ninvariances (Entezari et al., 2022). This means that a linear path can connect\ntwo independent solutions with low loss, given the weights of one of the models\nare appropriately permuted. However, current methods to test this theory often\nrequire very wide networks to succeed. In this work, we conjecture that more\ngenerally, the SGD solution set is a \"star domain\" that contains a \"star model\"\nthat is linearly connected to all the other solutions via paths with low loss\nvalues, modulo permutations. We propose the Starlight algorithm that finds a\nstar model of a given learning task. We validate our claim by showing that this\nstar model is linearly connected with other independently found solutions. As\nan additional benefit of our study, we demonstrate better uncertainty estimates\non the Bayesian Model Averaging over the obtained star domain. Further, we\ndemonstrate star models as potential substitutes for model ensembles. Our code\nis available at https://github.com/aktsonthalia/starlight.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.07968v2",
    "published_date": "2024-03-12 13:59:23 UTC",
    "updated_date": "2024-06-09 11:51:03 UTC"
  },
  {
    "arxiv_id": "2405.09549v1",
    "title": "Deep-learning-based clustering of OCT images for biomarker discovery in age-related macular degeneration (Pinnacle study report 4)",
    "authors": [
      "Robbie Holland",
      "Rebecca Kaye",
      "Ahmed M. Hagag",
      "Oliver Leingang",
      "Thomas R. P. Taylor",
      "Hrvoje Bogunović",
      "Ursula Schmidt-Erfurth",
      "Hendrik P. N. Scholl",
      "Daniel Rueckert",
      "Andrew J. Lotery",
      "Sobha Sivaprasad",
      "Martin J. Menten"
    ],
    "abstract": "Diseases are currently managed by grading systems, where patients are\nstratified by grading systems into stages that indicate patient risk and guide\nclinical management. However, these broad categories typically lack prognostic\nvalue, and proposals for new biomarkers are currently limited to anecdotal\nobservations. In this work, we introduce a deep-learning-based biomarker\nproposal system for the purpose of accelerating biomarker discovery in\nage-related macular degeneration (AMD). It works by first training a neural\nnetwork using self-supervised contrastive learning to discover, without any\nclinical annotations, features relating to both known and unknown AMD\nbiomarkers present in 46,496 retinal optical coherence tomography (OCT) images.\nTo interpret the discovered biomarkers, we partition the images into 30\nsubsets, termed clusters, that contain similar features. We then conduct two\nparallel 1.5-hour semi-structured interviews with two independent teams of\nretinal specialists that describe each cluster in clinical language. Overall,\nboth teams independently identified clearly distinct characteristics in 27 of\n30 clusters, of which 23 were related to AMD. Seven were recognised as known\nbiomarkers already used in established grading systems and 16 depicted\nbiomarker combinations or subtypes that are either not yet used in grading\nsystems, were only recently proposed, or were unknown. Clusters separated\nincomplete from complete retinal atrophy, intraretinal from subretinal fluid\nand thick from thin choroids, and in simulation outperformed clinically-used\ngrading systems in prognostic value. Overall, contrastive learning enabled the\nautomatic proposal of AMD biomarkers that go beyond the set used by clinically\nestablished grading systems. Ultimately, we envision that equipping clinicians\nwith discovery-oriented deep-learning tools can accelerate discovery of novel\nprognostic biomarkers.",
    "categories": [
      "eess.IV",
      "cs.AI"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.09549v1",
    "published_date": "2024-03-12 13:48:17 UTC",
    "updated_date": "2024-03-12 13:48:17 UTC"
  },
  {
    "arxiv_id": "2403.07657v3",
    "title": "Scalable Spatiotemporal Prediction with Bayesian Neural Fields",
    "authors": [
      "Feras Saad",
      "Jacob Burnim",
      "Colin Carroll",
      "Brian Patton",
      "Urs Köster",
      "Rif A. Saurous",
      "Matthew Hoffman"
    ],
    "abstract": "Spatiotemporal datasets, which consist of spatially-referenced time series,\nare ubiquitous in diverse applications, such as air pollution monitoring,\ndisease tracking, and cloud-demand forecasting. As the scale of modern datasets\nincreases, there is a growing need for statistical methods that are flexible\nenough to capture complex spatiotemporal dynamics and scalable enough to handle\nmany observations. This article introduces the Bayesian Neural Field (BayesNF),\na domain-general statistical model that infers rich spatiotemporal probability\ndistributions for data-analysis tasks including forecasting, interpolation, and\nvariography. BayesNF integrates a deep neural network architecture for\nhigh-capacity function estimation with hierarchical Bayesian inference for\nrobust predictive uncertainty quantification. Evaluations against prominent\nbaselines show that BayesNF delivers improvements on prediction problems from\nclimate and public health data containing tens to hundreds of thousands of\nmeasurements. Accompanying the paper is an open-source software package\n(https://github.com/google/bayesnf) that runs on GPU and TPU accelerators\nthrough the JAX machine learning platform.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.AP",
      "stat.ME"
    ],
    "primary_category": "cs.LG",
    "comment": "29 pages, 7 figures, 2 tables, 1 listing",
    "pdf_url": "http://arxiv.org/pdf/2403.07657v3",
    "published_date": "2024-03-12 13:47:50 UTC",
    "updated_date": "2024-11-26 21:26:10 UTC"
  },
  {
    "arxiv_id": "2403.07630v1",
    "title": "Hunting Attributes: Context Prototype-Aware Learning for Weakly Supervised Semantic Segmentation",
    "authors": [
      "Feilong Tang",
      "Zhongxing Xu",
      "Zhaojun Qu",
      "Wei Feng",
      "Xingjian Jiang",
      "Zongyuan Ge"
    ],
    "abstract": "Recent weakly supervised semantic segmentation (WSSS) methods strive to\nincorporate contextual knowledge to improve the completeness of class\nactivation maps (CAM). In this work, we argue that the knowledge bias between\ninstances and contexts affects the capability of the prototype to sufficiently\nunderstand instance semantics. Inspired by prototype learning theory, we\npropose leveraging prototype awareness to capture diverse and fine-grained\nfeature attributes of instances. The hypothesis is that contextual prototypes\nmight erroneously activate similar and frequently co-occurring object\ncategories due to this knowledge bias. Therefore, we propose to enhance the\nprototype representation ability by mitigating the bias to better capture\nspatial coverage in semantic object regions. With this goal, we present a\nContext Prototype-Aware Learning (CPAL) strategy, which leverages semantic\ncontext to enrich instance comprehension. The core of this method is to\naccurately capture intra-class variations in object features through\ncontext-aware prototypes, facilitating the adaptation to the semantic\nattributes of various instances. We design feature distribution alignment to\noptimize prototype awareness, aligning instance feature distributions with\ndense features. In addition, a unified training framework is proposed to\ncombine label-guided classification supervision and prototypes-guided\nself-supervision. Experimental results on PASCAL VOC 2012 and MS COCO 2014 show\nthat CPAL significantly improves off-the-shelf methods and achieves\nstate-of-the-art performance. The project is available at\nhttps://github.com/Barrett-python/CPAL.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.07630v1",
    "published_date": "2024-03-12 13:11:58 UTC",
    "updated_date": "2024-03-12 13:11:58 UTC"
  },
  {
    "arxiv_id": "2403.07622v1",
    "title": "Multiple Latent Space Mapping for Compressed Dark Image Enhancement",
    "authors": [
      "Yi Zeng",
      "Zhengning Wang",
      "Yuxuan Liu",
      "Tianjiao Zeng",
      "Xuhang Liu",
      "Xinglong Luo",
      "Shuaicheng Liu",
      "Shuyuan Zhu",
      "Bing Zeng"
    ],
    "abstract": "Dark image enhancement aims at converting dark images to normal-light images.\nExisting dark image enhancement methods take uncompressed dark images as inputs\nand achieve great performance. However, in practice, dark images are often\ncompressed before storage or transmission over the Internet. Current methods\nget poor performance when processing compressed dark images. Artifacts hidden\nin the dark regions are amplified by current methods, which results in\nuncomfortable visual effects for observers. Based on this observation, this\nstudy aims at enhancing compressed dark images while avoiding compression\nartifacts amplification. Since texture details intertwine with compression\nartifacts in compressed dark images, detail enhancement and blocking artifacts\nsuppression contradict each other in image space. Therefore, we handle the task\nin latent space. To this end, we propose a novel latent mapping network based\non variational auto-encoder (VAE). Firstly, different from previous VAE-based\nmethods with single-resolution features only, we exploit multiple latent spaces\nwith multi-resolution features, to reduce the detail blur and improve image\nfidelity. Specifically, we train two multi-level VAEs to project compressed\ndark images and normal-light images into their latent spaces respectively.\nSecondly, we leverage a latent mapping network to transform features from\ncompressed dark space to normal-light space. Specifically, since the\ndegradation models of darkness and compression are different from each other,\nthe latent mapping process is divided mapping into enlightening branch and\ndeblocking branch. Comprehensive experiments demonstrate that the proposed\nmethod achieves state-of-the-art performance in compressed dark image\nenhancement.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.07622v1",
    "published_date": "2024-03-12 13:05:51 UTC",
    "updated_date": "2024-03-12 13:05:51 UTC"
  },
  {
    "arxiv_id": "2403.07611v1",
    "title": "Efficient Knowledge Deletion from Trained Models through Layer-wise Partial Machine Unlearning",
    "authors": [
      "Vinay Chakravarthi Gogineni",
      "Esmaeil S. Nadimi"
    ],
    "abstract": "Machine unlearning has garnered significant attention due to its ability to\nselectively erase knowledge obtained from specific training data samples in an\nalready trained machine learning model. This capability enables data holders to\nadhere strictly to data protection regulations. However, existing unlearning\ntechniques face practical constraints, often causing performance degradation,\ndemanding brief fine-tuning post unlearning, and requiring significant storage.\nIn response, this paper introduces a novel class of machine unlearning\nalgorithms. First method is partial amnesiac unlearning, integration of\nlayer-wise pruning with amnesiac unlearning. In this method, updates made to\nthe model during training are pruned and stored, subsequently used to forget\nspecific data from trained model. The second method assimilates layer-wise\npartial-updates into label-flipping and optimization-based unlearning to\nmitigate the adverse effects of data deletion on model efficacy. Through a\ndetailed experimental evaluation, we showcase the effectiveness of proposed\nunlearning methods. Experimental results highlight that the partial amnesiac\nunlearning not only preserves model efficacy but also eliminates the necessity\nfor brief post fine-tuning, unlike conventional amnesiac unlearning. Moreover,\nemploying layer-wise partial updates in label-flipping and optimization-based\nunlearning techniques demonstrates superiority in preserving model efficacy\ncompared to their naive counterparts.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "16pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.07611v1",
    "published_date": "2024-03-12 12:49:47 UTC",
    "updated_date": "2024-03-12 12:49:47 UTC"
  },
  {
    "arxiv_id": "2403.07608v1",
    "title": "Couler: Unified Machine Learning Workflow Optimization in Cloud",
    "authors": [
      "Xiaoda Wang",
      "Yuan Tang",
      "Tengda Guo",
      "Bo Sang",
      "Jingji Wu",
      "Jian Sha",
      "Ke Zhang",
      "Jiang Qian",
      "Mingjie Tang"
    ],
    "abstract": "Machine Learning (ML) has become ubiquitous, fueling data-driven applications\nacross various organizations. Contrary to the traditional perception of ML in\nresearch, ML workflows can be complex, resource-intensive, and time-consuming.\nExpanding an ML workflow to encompass a wider range of data infrastructure and\ndata types may lead to larger workloads and increased deployment costs.\nCurrently, numerous workflow engines are available (with over ten being widely\nrecognized). This variety poses a challenge for end-users in terms of mastering\ndifferent engine APIs. While efforts have primarily focused on optimizing ML\nOperations (MLOps) for a specific workflow engine, current methods largely\noverlook workflow optimization across different engines.\n  In this work, we design and implement Couler, a system designed for unified\nML workflow optimization in the cloud. Our main insight lies in the ability to\ngenerate an ML workflow using natural language (NL) descriptions. We integrate\nLarge Language Models (LLMs) into workflow generation, and provide a unified\nprogramming interface for various workflow engines. This approach alleviates\nthe need to understand various workflow engines' APIs. Moreover, Couler\nenhances workflow computation efficiency by introducing automated caching at\nmultiple stages, enabling large workflow auto-parallelization and automatic\nhyperparameters tuning. These enhancements minimize redundant computational\ncosts and improve fault tolerance during deep learning workflow training.\nCouler is extensively deployed in real-world production scenarios at Ant Group,\nhandling approximately 22k workflows daily, and has successfully improved the\nCPU/Memory utilization by more than 15% and the workflow completion rate by\naround 17%.",
    "categories": [
      "cs.DB",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.DB",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.07608v1",
    "published_date": "2024-03-12 12:47:32 UTC",
    "updated_date": "2024-03-12 12:47:32 UTC"
  },
  {
    "arxiv_id": "2403.07605v3",
    "title": "Optimizing Negative Prompts for Enhanced Aesthetics and Fidelity in Text-To-Image Generation",
    "authors": [
      "Michael Ogezi",
      "Ning Shi"
    ],
    "abstract": "In text-to-image generation, using negative prompts, which describe\nundesirable image characteristics, can significantly boost image quality.\nHowever, producing good negative prompts is manual and tedious. To address\nthis, we propose NegOpt, a novel method for optimizing negative prompt\ngeneration toward enhanced image generation, using supervised fine-tuning and\nreinforcement learning. Our combined approach results in a substantial increase\nof 25% in Inception Score compared to other approaches and surpasses\nground-truth negative prompts from the test set. Furthermore, with NegOpt we\ncan preferentially optimize the metrics most important to us. Finally, we\nconstruct Negative Prompts DB\n(https://huggingface.co/datasets/mikeogezi/negopt_full), a publicly available\ndataset of negative prompts.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.07605v3",
    "published_date": "2024-03-12 12:44:34 UTC",
    "updated_date": "2024-11-05 01:11:08 UTC"
  },
  {
    "arxiv_id": "2403.07587v1",
    "title": "Perennial Semantic Data Terms of Use for Decentralized Web",
    "authors": [
      "Rui Zhao",
      "Jun Zhao"
    ],
    "abstract": "In today's digital landscape, the Web has become increasingly centralized,\nraising concerns about user privacy violations. Decentralized Web\narchitectures, such as Solid, offer a promising solution by empowering users\nwith better control over their data in their personal `Pods'. However, a\nsignificant challenge remains: users must navigate numerous applications to\ndecide which application can be trusted with access to their data Pods. This\noften involves reading lengthy and complex Terms of Use agreements, a process\nthat users often find daunting or simply ignore. This compromises user autonomy\nand impedes detection of data misuse. We propose a novel formal description of\nData Terms of Use (DToU), along with a DToU reasoner. Users and applications\nspecify their own parts of the DToU policy with local knowledge, covering\npermissions, requirements, prohibitions and obligations. Automated reasoning\nverifies compliance, and also derives policies for output data. This\nconstitutes a ``perennial'' DToU language, where the policy authoring only\noccurs once, and we can conduct ongoing automated checks across users,\napplications and activity cycles. Our solution is built on Turtle, Notation 3\nand RDF Surfaces, for the language and the reasoning engine. It ensures\nseamless integration with other semantic tools for enhanced interoperability.\nWe have successfully integrated this language into the Solid framework, and\nconducted performance benchmark. We believe this work demonstrates a\npracticality of a perennial DToU language and the potential of a paradigm shift\nto how users interact with data and applications in a decentralized Web,\noffering both improved privacy and usability.",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "This paper is accepted by International World Wide Web Conference\n  2024 (WWW 2024 / The Web Conf 2024)",
    "pdf_url": "http://arxiv.org/pdf/2403.07587v1",
    "published_date": "2024-03-12 12:18:20 UTC",
    "updated_date": "2024-03-12 12:18:20 UTC"
  },
  {
    "arxiv_id": "2403.07586v1",
    "title": "Federated Learning of Socially Appropriate Agent Behaviours in Simulated Home Environments",
    "authors": [
      "Saksham Checker",
      "Nikhil Churamani",
      "Hatice Gunes"
    ],
    "abstract": "As social robots become increasingly integrated into daily life, ensuring\ntheir behaviours align with social norms is crucial. For their widespread\nopen-world application, it is important to explore Federated Learning (FL)\nsettings where individual robots can learn about their unique environments\nwhile also learning from each others' experiences. In this paper, we present a\nnovel FL benchmark that evaluates different strategies, using multi-label\nregression objectives, where each client individually learns to predict the\nsocial appropriateness of different robot actions while also sharing their\nlearning with others. Furthermore, splitting the training data by different\ncontexts such that each client incrementally learns across contexts, we present\na novel Federated Continual Learning (FCL) benchmark that adapts FL-based\nmethods to use state-of-the-art Continual Learning (CL) methods to continually\nlearn socially appropriate agent behaviours under different contextual\nsettings. Federated Averaging (FedAvg) of weights emerges as a robust FL\nstrategy while rehearsal-based FCL enables incrementally learning the social\nappropriateness of robot actions, across contextual splits.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at the Workshop on Lifelong Learning and Personalization in\n  Long-Term Human-Robot Interaction (LEAP-HRI) at the 19th ACM/IEEE\n  International Conference on Human-Robot Interaction (HRI), 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.07586v1",
    "published_date": "2024-03-12 12:16:40 UTC",
    "updated_date": "2024-03-12 12:16:40 UTC"
  },
  {
    "arxiv_id": "2403.07573v3",
    "title": "Towards a Dynamic Future with Adaptable Computing and Network Convergence (ACNC)",
    "authors": [
      "Masoud Shokrnezhad",
      "Hao Yu",
      "Tarik Taleb",
      "Richard Li",
      "Kyunghan Lee",
      "Jaeseung Song",
      "Cedric Westphal"
    ],
    "abstract": "In the context of advancing 6G, a substantial paradigm shift is anticipated,\nhighlighting comprehensive everything-to-everything interactions characterized\nby numerous connections and stringent adherence to Quality of\nService/Experience (QoS/E) prerequisites. The imminent challenge stems from\nresource scarcity, prompting a deliberate transition to Computing-Network\nConvergence (CNC) as an auspicious approach for joint resource orchestration.\nWhile CNC-based mechanisms have garnered attention, their effectiveness in\nrealizing future services, particularly in use cases like the Metaverse, may\nencounter limitations due to the continually changing nature of users,\nservices, and resources. Hence, this paper presents the concept of Adaptable\nCNC (ACNC) as an autonomous Machine Learning (ML)-aided mechanism crafted for\nthe joint orchestration of computing and network resources, catering to dynamic\nand voluminous user requests with stringent requirements. ACNC encompasses two\nprimary functionalities: state recognition and context detection. Given the\nintricate nature of the user-service-computing-network space, the paper employs\ndimension reduction to generate live, holistic, abstract system states in a\nhierarchical structure. To address the challenges posed by dynamic changes,\nContinual Learning (CL) is employed, classifying the system state into contexts\ncontrolled by dedicated ML agents, enabling them to operate efficiently. These\ntwo functionalities are intricately linked within a closed loop overseen by the\nEnd-to-End (E2E) orchestrator to allocate resources. The paper introduces the\ncomponents of ACNC, proposes a Metaverse scenario to exemplify ACNC's role in\nresource provisioning with Segment Routing v6 (SRv6), outlines ACNC's workflow,\ndetails a numerical analysis for efficiency assessment, and concludes with\ndiscussions on relevant challenges and potential avenues for future research.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "cs.DC",
      "cs.ET",
      "cs.LG"
    ],
    "primary_category": "cs.NI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.07573v3",
    "published_date": "2024-03-12 12:03:16 UTC",
    "updated_date": "2024-12-18 05:54:46 UTC"
  },
  {
    "arxiv_id": "2403.07965v2",
    "title": "Conditional computation in neural networks: principles and research trends",
    "authors": [
      "Simone Scardapane",
      "Alessandro Baiocchi",
      "Alessio Devoto",
      "Valerio Marsocci",
      "Pasquale Minervini",
      "Jary Pomponi"
    ],
    "abstract": "This article summarizes principles and ideas from the emerging area of\napplying \\textit{conditional computation} methods to the design of neural\nnetworks. In particular, we focus on neural networks that can dynamically\nactivate or de-activate parts of their computational graph conditionally on\ntheir input. Examples include the dynamic selection of, e.g., input tokens,\nlayers (or sets of layers), and sub-modules inside each layer (e.g., channels\nin a convolutional filter). We first provide a general formalism to describe\nthese techniques in an uniform way. Then, we introduce three notable\nimplementations of these principles: mixture-of-experts (MoEs) networks, token\nselection mechanisms, and early-exit neural networks. The paper aims to provide\na tutorial-like introduction to this growing field. To this end, we analyze the\nbenefits of these modular designs in terms of efficiency, explainability, and\ntransfer learning, with a focus on emerging applicative areas ranging from\nautomated scientific discovery to semantic communication.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.07965v2",
    "published_date": "2024-03-12 11:56:38 UTC",
    "updated_date": "2024-07-08 09:21:00 UTC"
  },
  {
    "arxiv_id": "2403.07566v2",
    "title": "An Improved Strategy for Blood Glucose Control Using Multi-Step Deep Reinforcement Learning",
    "authors": [
      "Weiwei Gu",
      "Senquan Wang"
    ],
    "abstract": "Blood Glucose (BG) control involves keeping an individual's BG within a\nhealthy range through extracorporeal insulin injections is an important task\nfor people with type 1 diabetes. However,traditional patient self-management is\ncumbersome and risky. Recent research has been devoted to exploring\nindividualized and automated BG control approaches, among which Deep\nReinforcement Learning (DRL) shows potential as an emerging approach. In this\npaper, we use an exponential decay model of drug concentration to convert the\nformalization of the BG control problem, which takes into account the delay and\nprolongedness of drug effects, from a PAE-POMDP (Prolonged Action\nEffect-Partially Observable Markov Decision Process) to a MDP, and we propose a\nnovel multi-step DRL-based algorithm to solve the problem. The Prioritized\nExperience Replay (PER) sampling method is also used in it. Compared to\nsingle-step bootstrapped updates, multi-step learning is more efficient and\nreduces the influence from biasing targets. Our proposed method converges\nfaster and achieves higher cumulative rewards compared to the benchmark in the\nsame training environment, and improves the time-in-range (TIR), the percentage\nof time the patient's BG is within the target range, in the evaluation phase.\nOur work validates the effectiveness of multi-step reinforcement learning in BG\ncontrol, which may help to explore the optimal glycemic control measure and\nimprove the survival of diabetic patients.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.07566v2",
    "published_date": "2024-03-12 11:53:00 UTC",
    "updated_date": "2024-03-15 09:48:34 UTC"
  },
  {
    "arxiv_id": "2403.07964v2",
    "title": "Optimal Design and Implementation of an Open-source Emulation Platform for User-Centric Shared E-mobility Services",
    "authors": [
      "Maqsood Hussain Shah",
      "Yue Ding",
      "Shaoshu Zhu",
      "Yingqi Gu",
      "Mingming Liu"
    ],
    "abstract": "With the rising concern over transportation emissions and pollution on a\nglobal scale, shared electric mobility services like E-cars, E-bikes, and\nE-scooters have emerged as promising solutions to mitigate these pressing\nchallenges. However, existing shared E-mobility services exhibit critical\ndesign deficiencies, including insufficient service integration, imprecise\nenergy consumption forecasting, limited scalability and geographical coverage,\nand a notable absence of a user-centric perspective, particularly in the\ncontext of multi-modal transportation. More importantly, there is no\nconsolidated open-source platform which could benefit the E-mobility research\ncommunity. This paper aims to bridge this gap by providing an open-source\nplatform for shared E-mobility. The proposed platform, with an\nagent-in-the-loop approach and modular architecture, is tailored to diverse\nuser preferences and offers enhanced customization. We demonstrate the\nviability of this platform by providing a comprehensive analysis for integrated\nmulti-modal route-optimization in diverse scenarios of energy availability,\nuser preferences and E-mobility tools placement for which we use modified Ant\nColony Optimization algorithm so called Multi-Model Energy Constrained ACO\n(MMEC-ACO) and Q-Learning algorithms. Our findings demonstrate that Q-learning\nachieves significantly better performance in terms of travel time cost for more\nthan 90\\% of the instances as compared to MMEC-ACO for different scenarios\nincluding energy availability, user preference and E-mobility tools\ndistribution. For a fixed (O, D) pair, the average execution time to achieve\noptimal time cost solution for MMEC-ACO is less than 2 seconds, while\nQ-learning reaches an optimal time cost in 20 seconds on average. For a\nrun-time of 2 seconds, Q-learning still achieves a better optimal time cost\nwith a 20\\% reduction over MMEC-ACO's time cost.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "15 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.07964v2",
    "published_date": "2024-03-12 11:51:30 UTC",
    "updated_date": "2024-07-01 18:46:52 UTC"
  },
  {
    "arxiv_id": "2403.07559v2",
    "title": "Ensembling Prioritized Hybrid Policies for Multi-agent Pathfinding",
    "authors": [
      "Huijie Tang",
      "Federico Berto",
      "Jinkyoo Park"
    ],
    "abstract": "Multi-Agent Reinforcement Learning (MARL) based Multi-Agent Path Finding\n(MAPF) has recently gained attention due to its efficiency and scalability.\nSeveral MARL-MAPF methods choose to use communication to enrich the information\none agent can perceive. However, existing works still struggle in structured\nenvironments with high obstacle density and a high number of agents. To further\nimprove the performance of the communication-based MARL-MAPF solvers, we\npropose a new method, Ensembling Prioritized Hybrid Policies (EPH). We first\npropose a selective communication block to gather richer information for better\nagent coordination within multi-agent environments and train the model with a Q\nlearning-based algorithm. We further introduce three advanced inference\nstrategies aimed at bolstering performance during the execution phase. First,\nwe hybridize the neural policy with single-agent expert guidance for navigating\nconflict-free zones. Secondly, we propose Q value-based methods for prioritized\nresolution of conflicts as well as deadlock situations. Finally, we introduce a\nrobust ensemble method that can efficiently collect the best out of multiple\npossible solutions. We empirically evaluate EPH in complex multi-agent\nenvironments and demonstrate competitive performance against state-of-the-art\nneural methods for MAPF. We open-source our code at\nhttps://github.com/ai4co/eph-mapf.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.MA",
    "comment": "Accepted to 2024 IEEE/RSJ International Conference on Intelligent\n  Robots and Systems (IROS 2024)",
    "pdf_url": "http://arxiv.org/pdf/2403.07559v2",
    "published_date": "2024-03-12 11:47:12 UTC",
    "updated_date": "2024-07-10 08:36:48 UTC"
  },
  {
    "arxiv_id": "2403.07553v1",
    "title": "The future of document indexing: GPT and Donut revolutionize table of content processing",
    "authors": [
      "Degaga Wolde Feyisa",
      "Haylemicheal Berihun",
      "Amanuel Zewdu",
      "Mahsa Najimoghadam",
      "Marzieh Zare"
    ],
    "abstract": "Industrial projects rely heavily on lengthy, complex specification documents,\nmaking tedious manual extraction of structured information a major bottleneck.\nThis paper introduces an innovative approach to automate this process,\nleveraging the capabilities of two cutting-edge AI models: Donut, a model that\nextracts information directly from scanned documents without OCR, and OpenAI\nGPT-3.5 Turbo, a robust large language model. The proposed methodology is\ninitiated by acquiring the table of contents (ToCs) from construction\nspecification documents and subsequently structuring the ToCs text into JSON\ndata. Remarkable accuracy is achieved, with Donut reaching 85% and GPT-3.5\nTurbo reaching 89% in effectively organizing the ToCs. This landmark\nachievement represents a significant leap forward in document indexing,\ndemonstrating the immense potential of AI to automate information extraction\ntasks across diverse document types, boosting efficiency and liberating\ncritical resources in various industries.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.IR",
    "comment": "Document AI, Document Classification, Information extraction, Large\n  Language Models, OCR Models, Visual Document Understanding",
    "pdf_url": "http://arxiv.org/pdf/2403.07553v1",
    "published_date": "2024-03-12 11:39:18 UTC",
    "updated_date": "2024-03-12 11:39:18 UTC"
  },
  {
    "arxiv_id": "2403.07548v2",
    "title": "Online Continual Learning For Interactive Instruction Following Agents",
    "authors": [
      "Byeonghwi Kim",
      "Minhyuk Seo",
      "Jonghyun Choi"
    ],
    "abstract": "In learning an embodied agent executing daily tasks via language directives,\nthe literature largely assumes that the agent learns all training data at the\nbeginning. We argue that such a learning scenario is less realistic since a\nrobotic agent is supposed to learn the world continuously as it explores and\nperceives it. To take a step towards a more realistic embodied agent learning\nscenario, we propose two continual learning setups for embodied agents;\nlearning new behaviors (Behavior Incremental Learning, Behavior-IL) and new\nenvironments (Environment Incremental Learning, Environment-IL) For the tasks,\nprevious 'data prior' based continual learning methods maintain logits for the\npast tasks. However, the stored information is often insufficiently learned\ninformation and requires task boundary information, which might not always be\navailable. Here, we propose to update them based on confidence scores without\ntask boundary information during training (i.e., task-free) in a moving average\nfashion, named Confidence-Aware Moving Average (CAMA). In the proposed\nBehavior-IL and Environment-IL setups, our simple CAMA outperforms prior state\nof the art in our empirical validations by noticeable margins. The project page\nincluding codes is https://github.com/snumprlab/cl-alfred.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "ICLR 2024 (Project page:\n  https://bhkim94.github.io/projects/CL-ALFRED)",
    "pdf_url": "http://arxiv.org/pdf/2403.07548v2",
    "published_date": "2024-03-12 11:33:48 UTC",
    "updated_date": "2024-03-13 02:31:47 UTC"
  },
  {
    "arxiv_id": "2403.07540v2",
    "title": "WannaLaugh: A Configurable Ransomware Emulator -- Learning to Mimic Malicious Storage Traces",
    "authors": [
      "Dionysios Diamantopoulos",
      "Roman Pletka",
      "Slavisa Sarafijanovic",
      "A. L. Narasimha Reddy",
      "Haris Pozidis"
    ],
    "abstract": "Ransomware, a fearsome and rapidly evolving cybersecurity threat, continues\nto inflict severe consequences on individuals and organizations worldwide.\nTraditional detection methods, reliant on static signatures and application\nbehavioral patterns, are challenged by the dynamic nature of these threats.\nThis paper introduces three primary contributions to address this challenge.\nFirst, we introduce a ransomware emulator. This tool is designed to safely\nmimic ransomware attacks without causing actual harm or spreading malware,\nmaking it a unique solution for studying ransomware behavior. Second, we\ndemonstrate how we use this emulator to create storage I/O traces. These traces\nare then utilized to train machine-learning models. Our results show that these\nmodels are effective in detecting ransomware, highlighting the practical\napplication of our emulator in developing responsible cybersecurity tools.\nThird, we show how our emulator can be used to mimic the I/O behavior of\nexisting ransomware thereby enabling safe trace collection. Both the emulator\nand its application represent significant steps forward in ransomware detection\nin the era of machine-learning-driven cybersecurity.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.07540v2",
    "published_date": "2024-03-12 11:26:58 UTC",
    "updated_date": "2024-06-12 14:52:51 UTC"
  },
  {
    "arxiv_id": "2404.15284v1",
    "title": "Global 4D Ionospheric STEC Prediction based on DeepONet for GNSS Rays",
    "authors": [
      "Dijia Cai",
      "Zenghui Shi",
      "Haiyang Fu",
      "Huan Liu",
      "Hongyi Qian",
      "Yun Sui",
      "Feng Xu",
      "Ya-Qiu Jin"
    ],
    "abstract": "The ionosphere is a vitally dynamic charged particle region in the Earth's\nupper atmosphere, playing a crucial role in applications such as radio\ncommunication and satellite navigation. The Slant Total Electron Contents\n(STEC) is an important parameter for characterizing wave propagation,\nrepresenting the integrated electron density along the ray of radio signals\npassing through the ionosphere. The accurate prediction of STEC is essential\nfor mitigating the ionospheric impact particularly on Global Navigation\nSatellite Systems (GNSS). In this work, we propose a high-precision STEC\nprediction model named DeepONet-STEC, which learns nonlinear operators to\npredict the 4D temporal-spatial integrated parameter for specified ground\nstation - satellite ray path globally. As a demonstration, we validate the\nperformance of the model based on GNSS observation data for global and US-CORS\nregimes under ionospheric quiet and storm conditions. The DeepONet-STEC model\nresults show that the three-day 72 hour prediction in quiet periods could\nachieve high accuracy using observation data by the Precise Point Positioning\n(PPP) with temporal resolution 30s. Under active solar magnetic storm periods,\nthe DeepONet-STEC also demonstrated its robustness and superiority than\ntraditional deep learning methods. This work presents a neural operator\nregression architecture for predicting the 4D temporal-spatial ionospheric\nparameter for satellite navigation system performance, which may be further\nextended for various space applications and beyond.",
    "categories": [
      "eess.SP",
      "cs.AI"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.15284v1",
    "published_date": "2024-03-12 10:51:38 UTC",
    "updated_date": "2024-03-12 10:51:38 UTC"
  },
  {
    "arxiv_id": "2403.07510v1",
    "title": "Relevance Score: A Landmark-Like Heuristic for Planning",
    "authors": [
      "Oliver Kim",
      "Mohan Sridharan"
    ],
    "abstract": "Landmarks are facts or actions that appear in all valid solutions of a\nplanning problem. They have been used successfully to calculate heuristics that\nguide the search for a plan. We investigate an extension to this concept by\ndefining a novel \"relevance score\" that helps identify facts or actions that\nappear in most but not all plans to achieve any given goal. We describe an\napproach to compute this relevance score and use it as a heuristic in the\nsearch for a plan. We experimentally compare the performance of our approach\nwith that of a state of the art landmark-based heuristic planning approach\nusing benchmark planning problems. While the original landmark-based heuristic\nleads to better performance on problems with well-defined landmarks, our\napproach substantially improves performance on problems that lack non-trivial\nlandmarks.",
    "categories": [
      "cs.AI",
      "I.2.8"
    ],
    "primary_category": "cs.AI",
    "comment": "12 Pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.07510v1",
    "published_date": "2024-03-12 10:45:45 UTC",
    "updated_date": "2024-03-12 10:45:45 UTC"
  },
  {
    "arxiv_id": "2403.07500v1",
    "title": "Block-wise LoRA: Revisiting Fine-grained LoRA for Effective Personalization and Stylization in Text-to-Image Generation",
    "authors": [
      "Likun Li",
      "Haoqi Zeng",
      "Changpeng Yang",
      "Haozhe Jia",
      "Di Xu"
    ],
    "abstract": "The objective of personalization and stylization in text-to-image is to\ninstruct a pre-trained diffusion model to analyze new concepts introduced by\nusers and incorporate them into expected styles. Recently, parameter-efficient\nfine-tuning (PEFT) approaches have been widely adopted to address this task and\nhave greatly propelled the development of this field. Despite their popularity,\nexisting efficient fine-tuning methods still struggle to achieve effective\npersonalization and stylization in T2I generation. To address this issue, we\npropose block-wise Low-Rank Adaptation (LoRA) to perform fine-grained\nfine-tuning for different blocks of SD, which can generate images faithful to\ninput prompts and target identity and also with desired style. Extensive\nexperiments demonstrate the effectiveness of the proposed method.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.07500v1",
    "published_date": "2024-03-12 10:38:03 UTC",
    "updated_date": "2024-03-12 10:38:03 UTC"
  },
  {
    "arxiv_id": "2403.07483v2",
    "title": "DiabetesNet: A Deep Learning Approach to Diabetes Diagnosis",
    "authors": [
      "Zeyu Zhang",
      "Khandaker Asif Ahmed",
      "Md Rakibul Hasan",
      "Tom Gedeon",
      "Md Zakir Hossain"
    ],
    "abstract": "Diabetes, resulting from inadequate insulin production or utilization, causes\nextensive harm to the body. Existing diagnostic methods are often invasive and\ncome with drawbacks, such as cost constraints. Although there are machine\nlearning models like Classwise k Nearest Neighbor (CkNN) and General Regression\nNeural Network (GRNN), they struggle with imbalanced data and result in\nunder-performance. Leveraging advancements in sensor technology and machine\nlearning, we propose a non-invasive diabetes diagnosis using a Back Propagation\nNeural Network (BPNN) with batch normalization, incorporating data re-sampling\nand normalization for class balancing. Our method addresses existing challenges\nsuch as limited performance associated with traditional machine learning.\nExperimental results on three datasets show significant improvements in overall\naccuracy, sensitivity, and specificity compared to traditional methods.\nNotably, we achieve accuracies of 89.81% in Pima diabetes dataset, 75.49% in\nCDC BRFSS2015 dataset, and 95.28% in Mesra Diabetes dataset. This underscores\nthe potential of deep learning models for robust diabetes diagnosis. See\nproject website https://steve-zeyu-zhang.github.io/DiabetesDiagnosis/",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to ACIIDS 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.07483v2",
    "published_date": "2024-03-12 10:18:59 UTC",
    "updated_date": "2024-09-21 06:40:49 UTC"
  },
  {
    "arxiv_id": "2403.07440v3",
    "title": "Matrix-Transformation Based Low-Rank Adaptation (MTLoRA): A Brain-Inspired Method for Parameter-Efficient Fine-Tuning",
    "authors": [
      "Yao Liang",
      "Yuwei Wang",
      "Yang Li",
      "Yi Zeng"
    ],
    "abstract": "Fine-tuning techniques based on Large Pretrained Language Models (LPLMs) have\nbeen proven to significantly enhance model performance on a variety of\ndownstream tasks and effectively control the output behaviors of LPLMs. Recent\nstudies have proposed numerous methods for fine-tuning a small number of\nparameters based on open-source LPLMs, reducing the demand for computational\nand storage resources. Among these, reparameterization fine-tuning methods\nrepresented by LoRA (Low-Rank Adaptation) have gained popularity. We find that\nalthough these methods perform well in many aspects, there is still\nconsiderable room for improvement in terms of complex task adaptability,\nperformance, stability, and algorithm complexity. In response to this, inspired\nby the idea that the functions of the brain are shaped by its geometric\nstructure, this paper integrates this idea into LoRA technology and proposes a\nnew matrix transformation-based reparameterization method for efficient\nfine-tuning, named Matrix-Transformation based Low-Rank Adaptation (MTLoRA).\nMTLoRA aims to dynamically alter its spatial geometric structure by applying a\ntransformation-matrix T to perform linear transformations, such as rotation,\nscaling, and translation, on the task-specific parameter matrix, generating new\nmatrix feature patterns (eigenvectors) to mimic the fundamental influence of\ncomplex geometric structure feature patterns in the brain on functions, thereby\nenhancing the model's performance in downstream tasks. In Natural Language\nUnderstanding (NLU) tasks, it is evaluated using the GLUE benchmark test, and\nthe results reveal that MTLoRA achieves an overall performance increase of\nabout 1.0% across eight tasks; in Natural Language Generation (NLG) tasks,\nMTLoRA improves performance by an average of 0.95% and 0.56% in the DART and\nWebNLG tasks, respectively.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.07440v3",
    "published_date": "2024-03-12 09:32:25 UTC",
    "updated_date": "2024-03-30 04:36:54 UTC"
  },
  {
    "arxiv_id": "2403.09722v2",
    "title": "Enhancing Readmission Prediction with Deep Learning: Extracting Biomedical Concepts from Clinical Texts",
    "authors": [
      "Rasoul Samani",
      "Mohammad Dehghani",
      "Fahime Shahrokh"
    ],
    "abstract": "Hospital readmission, defined as patients being re-hospitalized shortly after\ndischarge, is a critical concern as it impacts patient outcomes and healthcare\ncosts. Identifying patients at risk of readmission allows for timely\ninterventions, reducing re-hospitalization rates and overall treatment costs.\nThis study focuses on predicting patient readmission within less than 30 days\nusing text mining techniques applied to discharge report texts from electronic\nhealth records (EHR). Various machine learning and deep learning methods were\nemployed to develop a classification model for this purpose. A novel aspect of\nthis research involves leveraging the Bio-Discharge Summary Bert (BDSS) model\nalong with principal component analysis (PCA) feature extraction to preprocess\ndata for deep learning model input. Our analysis of the MIMIC-III dataset\nindicates that our approach, which combines the BDSS model with a multilayer\nperceptron (MLP), outperforms state-of-the-art methods. This model achieved a\nrecall of 94% and an area under the curve (AUC) of 75%, showcasing its\neffectiveness in predicting patient readmissions. This study contributes to the\nadvancement of predictive modeling in healthcare by integrating text mining\ntechniques with deep learning algorithms to improve patient outcomes and\noptimize resource allocation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.09722v2",
    "published_date": "2024-03-12 09:03:44 UTC",
    "updated_date": "2024-04-06 10:39:02 UTC"
  },
  {
    "arxiv_id": "2403.07959v2",
    "title": "An Interpretable Generalization Mechanism for Accurately Detecting Anomaly and Identifying Networking Intrusion Techniques",
    "authors": [
      "Hao-Ting Pai",
      "Yu-Hsuan Kang",
      "Wen-Cheng Chung"
    ],
    "abstract": "Recent advancements in Intrusion Detection Systems (IDS), integrating\nExplainable AI (XAI) methodologies, have led to notable improvements in system\nperformance via precise feature selection. However, a thorough understanding of\ncyber-attacks requires inherently explainable decision-making processes within\nIDS. In this paper, we present the Interpretable Generalization Mechanism (IG),\npoised to revolutionize IDS capabilities. IG discerns coherent patterns, making\nit interpretable in distinguishing between normal and anomalous network\ntraffic. Further, the synthesis of coherent patterns sheds light on intricate\nintrusion pathways, providing essential insights for cybersecurity forensics.\nBy experiments with real-world datasets NSL-KDD, UNSW-NB15, and UKM-IDS20, IG\nis accurate even at a low ratio of training-to-test. With 10%-to-90%, IG\nachieves Precision (PRE)=0.93, Recall (REC)=0.94, and Area Under Curve\n(AUC)=0.94 in NSL-KDD; PRE=0.98, REC=0.99, and AUC=0.99 in UNSW-NB15; and\nPRE=0.98, REC=0.98, and AUC=0.99 in UKM-IDS20. Notably, in UNSW-NB15, IG\nachieves REC=1.0 and at least PRE=0.98 since 40%-to-60%; in UKM-IDS20, IG\nachieves REC=1.0 and at least PRE=0.88 since 20%-to-80%. Importantly, in\nUKM-IDS20, IG successfully identifies all three anomalous instances without\nprior exposure, demonstrating its generalization capabilities. These results\nand inferences are reproducible. In sum, IG showcases superior generalization\nby consistently performing well across diverse datasets and training-to-test\nratios (from 10%-to-90% to 90%-to-10%), and excels in identifying novel\nanomalies without prior exposure. Its interpretability is enhanced by coherent\nevidence that accurately distinguishes both normal and anomalous activities,\nsignificantly improving detection accuracy and reducing false alarms, thereby\nstrengthening IDS reliability and trustworthiness.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.07959v2",
    "published_date": "2024-03-12 09:01:04 UTC",
    "updated_date": "2024-11-05 07:14:25 UTC"
  },
  {
    "arxiv_id": "2403.09721v1",
    "title": "A Semantic Mention Graph Augmented Model for Document-Level Event Argument Extraction",
    "authors": [
      "Jian Zhang",
      "Changlin Yang",
      "Haiping Zhu",
      "Qika Lin",
      "Fangzhi Xu",
      "Jun Liu"
    ],
    "abstract": "Document-level Event Argument Extraction (DEAE) aims to identify arguments\nand their specific roles from an unstructured document. The advanced approaches\non DEAE utilize prompt-based methods to guide pre-trained language models\n(PLMs) in extracting arguments from input documents. They mainly concentrate on\nestablishing relations between triggers and entity mentions within documents,\nleaving two unresolved problems: a) independent modeling of entity mentions; b)\ndocument-prompt isolation. To this end, we propose a semantic mention Graph\nAugmented Model (GAM) to address these two problems in this paper. Firstly, GAM\nconstructs a semantic mention graph that captures relations within and between\ndocuments and prompts, encompassing co-existence, co-reference and co-type\nrelations. Furthermore, we introduce an ensembled graph transformer module to\naddress mentions and their three semantic relations effectively. Later, the\ngraph-augmented encoder-decoder module incorporates the relation-specific graph\ninto the input embedding of PLMs and optimizes the encoder section with\ntopology information, enhancing the relations comprehensively. Extensive\nexperiments on the RAMS and WikiEvents datasets demonstrate the effectiveness\nof our approach, surpassing baseline methods and achieving a new\nstate-of-the-art performance.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted By Coling 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.09721v1",
    "published_date": "2024-03-12 08:58:07 UTC",
    "updated_date": "2024-03-12 08:58:07 UTC"
  },
  {
    "arxiv_id": "2403.09720v1",
    "title": "Fine-tuning vs Prompting, Can Language Models Understand Human Values?",
    "authors": [
      "Pingwei Sun"
    ],
    "abstract": "Accurately handling the underlying support values in sentences is crucial for\nunderstanding the speaker's tendencies, yet it poses a challenging task in\nnatural language understanding (NLU). In this article, we explore the potential\nof fine-tuning and prompt tuning in this downstream task, using the Human Value\nDetection 2023. Additionally, we attempt to validate whether models can\neffectively solve the problem based on the knowledge acquired during the\npre-training stage. Simultaneously, our interest lies in the capabilities of\nlarge language models (LLMs) aligned with RLHF in this task, and some\npreliminary attempts are presented.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.09720v1",
    "published_date": "2024-03-12 08:49:31 UTC",
    "updated_date": "2024-03-12 08:49:31 UTC"
  },
  {
    "arxiv_id": "2403.09719v1",
    "title": "Mevaker: Conclusion Extraction and Allocation Resources for the Hebrew Language",
    "authors": [
      "Vitaly Shalumov",
      "Harel Haskey",
      "Yuval Solaz"
    ],
    "abstract": "In this paper, we introduce summarization MevakerSumm and conclusion\nextraction MevakerConc datasets for the Hebrew language based on the State\nComptroller and Ombudsman of Israel reports, along with two auxiliary datasets.\nWe accompany these datasets with models for conclusion extraction (HeConE,\nHeConEspc) and conclusion allocation (HeCross). All of the code, datasets, and\nmodel checkpoints used in this work are publicly available.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.09719v1",
    "published_date": "2024-03-12 08:40:44 UTC",
    "updated_date": "2024-03-12 08:40:44 UTC"
  },
  {
    "arxiv_id": "2403.07404v3",
    "title": "Improving Continual Learning Performance and Efficiency with Auxiliary Classifiers",
    "authors": [
      "Filip Szatkowski",
      "Yaoyue Zheng",
      "Fei Yang",
      "Bartłomiej Twardowski",
      "Tomasz Trzciński",
      "Joost van de Weijer"
    ],
    "abstract": "Continual learning is crucial for applying machine learning in challenging,\ndynamic, and often resource-constrained environments. However, catastrophic\nforgetting - overwriting previously learned knowledge when new information is\nacquired - remains a major challenge. In this work, we examine the intermediate\nrepresentations in neural network layers during continual learning and find\nthat such representations are less prone to forgetting, highlighting their\npotential to accelerate computation. Motivated by these findings, we propose to\nuse auxiliary classifiers(ACs) to enhance performance and demonstrate that\nintegrating ACs into various continual learning methods consistently improves\naccuracy across diverse evaluation settings, yielding an average 10% relative\ngain. We also leverage the ACs to reduce the average cost of the inference by\n10-60% without compromising accuracy, enabling the model to return the\npredictions before computing all the layers. Our approach provides a scalable\nand efficient solution for continual learning.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "ICML 2025",
    "pdf_url": "http://arxiv.org/pdf/2403.07404v3",
    "published_date": "2024-03-12 08:33:26 UTC",
    "updated_date": "2025-05-02 14:03:34 UTC"
  },
  {
    "arxiv_id": "2403.07403v1",
    "title": "From Canteen Food to Daily Meals: Generalizing Food Recognition to More Practical Scenarios",
    "authors": [
      "Guoshan Liu",
      "Yang Jiao",
      "Jingjing Chen",
      "Bin Zhu",
      "Yu-Gang Jiang"
    ],
    "abstract": "The precise recognition of food categories plays a pivotal role for\nintelligent health management, attracting significant research attention in\nrecent years. Prominent benchmarks, such as Food-101 and VIREO Food-172,\nprovide abundant food image resources that catalyze the prosperity of research\nin this field. Nevertheless, these datasets are well-curated from canteen\nscenarios and thus deviate from food appearances in daily life. This\ndiscrepancy poses great challenges in effectively transferring classifiers\ntrained on these canteen datasets to broader daily-life scenarios encountered\nby humans. Toward this end, we present two new benchmarks, namely DailyFood-172\nand DailyFood-16, specifically designed to curate food images from everyday\nmeals. These two datasets are used to evaluate the transferability of\napproaches from the well-curated food image domain to the everyday-life food\nimage domain. In addition, we also propose a simple yet effective baseline\nmethod named Multi-Cluster Reference Learning (MCRL) to tackle the\naforementioned domain gap. MCRL is motivated by the observation that food\nimages in daily-life scenarios exhibit greater intra-class appearance variance\ncompared with those in well-curated benchmarks. Notably, MCRL can be seamlessly\ncoupled with existing approaches, yielding non-trivial performance\nenhancements. We hope our new benchmarks can inspire the community to explore\nthe transferability of food recognition models trained on well-curated datasets\ntoward practical real-life applications.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.07403v1",
    "published_date": "2024-03-12 08:32:23 UTC",
    "updated_date": "2024-03-12 08:32:23 UTC"
  },
  {
    "arxiv_id": "2403.07958v1",
    "title": "Temporal Decisions: Leveraging Temporal Correlation for Efficient Decisions in Early Exit Neural Networks",
    "authors": [
      "Max Sponner",
      "Lorenzo Servadei",
      "Bernd Waschneck",
      "Robert Wille",
      "Akash Kumar"
    ],
    "abstract": "Deep Learning is becoming increasingly relevant in Embedded and\nInternet-of-things applications. However, deploying models on embedded devices\nposes a challenge due to their resource limitations. This can impact the\nmodel's inference accuracy and latency. One potential solution are Early Exit\nNeural Networks, which adjust model depth dynamically through additional\nclassifiers attached between their hidden layers. However, the real-time\ntermination decision mechanism is critical for the system's efficiency,\nlatency, and sustained accuracy.\n  This paper introduces Difference Detection and Temporal Patience as decision\nmechanisms for Early Exit Neural Networks. They leverage the temporal\ncorrelation present in sensor data streams to efficiently terminate the\ninference. We evaluate their effectiveness in health monitoring, image\nclassification, and wake-word detection tasks. Our novel contributions were\nable to reduce the computational footprint compared to established decision\nmechanisms significantly while maintaining higher accuracy scores. We achieved\na reduction of mean operations per inference by up to 80% while maintaining\naccuracy levels within 5% of the original model.\n  These findings highlight the importance of considering temporal correlation\nin sensor data to improve the termination decision.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.07958v1",
    "published_date": "2024-03-12 08:28:27 UTC",
    "updated_date": "2024-03-12 08:28:27 UTC"
  },
  {
    "arxiv_id": "2403.07957v1",
    "title": "Efficient Post-Training Augmentation for Adaptive Inference in Heterogeneous and Distributed IoT Environments",
    "authors": [
      "Max Sponner",
      "Lorenzo Servadei",
      "Bernd Waschneck",
      "Robert Wille",
      "Akash Kumar"
    ],
    "abstract": "Early Exit Neural Networks (EENNs) present a solution to enhance the\nefficiency of neural network deployments. However, creating EENNs is\nchallenging and requires specialized domain knowledge, due to the large amount\nof additional design choices. To address this issue, we propose an automated\naugmentation flow that focuses on converting an existing model into an EENN. It\nperforms all required design decisions for the deployment to heterogeneous or\ndistributed hardware targets: Our framework constructs the EENN architecture,\nmaps its subgraphs to the hardware targets, and configures its decision\nmechanism. To the best of our knowledge, it is the first framework that is able\nto perform all of these steps.\n  We evaluated our approach on a collection of Internet-of-Things and standard\nimage classification use cases. For a speech command detection task, our\nsolution was able to reduce the mean operations per inference by 59.67%. For an\nECG classification task, it was able to terminate all samples early, reducing\nthe mean inference energy by 74.9% and computations by 78.3%. On CIFAR-10, our\nsolution was able to achieve up to a 58.75% reduction in computations.\n  The search on a ResNet-152 base model for CIFAR-10 took less than nine hours\non a laptop CPU. Our proposed approach enables the creation of EENN optimized\nfor IoT environments and can reduce the inference cost of Deep Learning\napplications on embedded and fog platforms, while also significantly reducing\nthe search cost - making it more accessible for scientists and engineers in\nindustry and research. The low search cost improves the accessibility of EENNs,\nwith the potential to improve the efficiency of neural networks in a wide range\nof practical applications.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.07957v1",
    "published_date": "2024-03-12 08:27:53 UTC",
    "updated_date": "2024-03-12 08:27:53 UTC"
  },
  {
    "arxiv_id": "2404.00012v1",
    "title": "Stress index strategy enhanced with financial news sentiment analysis for the equity markets",
    "authors": [
      "Baptiste Lefort",
      "Eric Benhamou",
      "Jean-Jacques Ohana",
      "David Saltiel",
      "Beatrice Guez",
      "Thomas Jacquot"
    ],
    "abstract": "This paper introduces a new risk-on risk-off strategy for the stock market,\nwhich combines a financial stress indicator with a sentiment analysis done by\nChatGPT reading and interpreting Bloomberg daily market summaries. Forecasts of\nmarket stress derived from volatility and credit spreads are enhanced when\ncombined with the financial news sentiment derived from GPT-4. As a result, the\nstrategy shows improved performance, evidenced by higher Sharpe ratio and\nreduced maximum drawdowns. The improved performance is consistent across the\nNASDAQ, the S&P 500 and the six major equity markets, indicating that the\nmethod generalises across equities markets.",
    "categories": [
      "q-fin.ST",
      "cs.AI",
      "cs.CL",
      "q-fin.RM"
    ],
    "primary_category": "q-fin.ST",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.00012v1",
    "published_date": "2024-03-12 08:23:30 UTC",
    "updated_date": "2024-03-12 08:23:30 UTC"
  },
  {
    "arxiv_id": "2403.07398v2",
    "title": "Complex Reasoning over Logical Queries on Commonsense Knowledge Graphs",
    "authors": [
      "Tianqing Fang",
      "Zeming Chen",
      "Yangqiu Song",
      "Antoine Bosselut"
    ],
    "abstract": "Event commonsense reasoning requires the ability to reason about the\nrelationship between events, as well as infer implicit context underlying that\nrelationship. However, data scarcity makes it challenging for language models\nto learn to generate commonsense inferences for contexts and questions\ninvolving interactions between complex events. To address this demand, we\npresent COM2 (COMplex COMmonsense), a new dataset created by sampling multi-hop\nlogical queries (e.g., the joint effect or cause of both event A and B, or the\neffect of the effect of event C) from an existing commonsense knowledge graph\n(CSKG), and verbalizing them using handcrafted rules and large language models\ninto multiple-choice and text generation questions. Our experiments show that\nlanguage models trained on COM2 exhibit significant improvements in complex\nreasoning ability, resulting in enhanced zero-shot performance in both\nin-domain and out-of-domain tasks for question answering and generative\ncommonsense reasoning, without expensive human annotations. Code and data are\navailable at https://github.com/tqfang/complex-commonsense-reasoning.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "ACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.07398v2",
    "published_date": "2024-03-12 08:13:52 UTC",
    "updated_date": "2024-06-22 17:32:05 UTC"
  },
  {
    "arxiv_id": "2403.07956v1",
    "title": "DeepCDCL: An CDCL-based Neural Network Verification Framework",
    "authors": [
      "Zongxin Liu",
      "Pengfei Yang",
      "Lijun Zhang",
      "Xiaowei Huang"
    ],
    "abstract": "Neural networks in safety-critical applications face increasing safety and\nsecurity concerns due to their susceptibility to little disturbance. In this\npaper, we propose DeepCDCL, a novel neural network verification framework based\non the Conflict-Driven Clause Learning (CDCL) algorithm. We introduce an\nasynchronous clause learning and management structure, reducing redundant time\nconsumption compared to the direct application of the CDCL framework.\nFurthermore, we also provide a detailed evaluation of the performance of our\napproach on the ACAS Xu and MNIST datasets, showing that a significant speed-up\nis achieved in most cases.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.07956v1",
    "published_date": "2024-03-12 08:07:06 UTC",
    "updated_date": "2024-03-12 08:07:06 UTC"
  },
  {
    "arxiv_id": "2403.07389v2",
    "title": "Auxiliary CycleGAN-guidance for Task-Aware Domain Translation from Duplex to Monoplex IHC Images",
    "authors": [
      "Nicolas Brieu",
      "Nicolas Triltsch",
      "Philipp Wortmann",
      "Dominik Winter",
      "Shashank Saran",
      "Marlon Rebelatto",
      "Günter Schmidt"
    ],
    "abstract": "Generative models enable the translation from a source image domain where\nreadily trained models are available to a target domain unseen during training.\nWhile Cycle Generative Adversarial Networks (GANs) are well established, the\nassociated cycle consistency constrain relies on that an invertible mapping\nexists between the two domains. This is, however, not the case for the\ntranslation between images stained with chromogenic monoplex and duplex\nimmunohistochemistry (IHC) assays. Focusing on the translation from the latter\nto the first, we propose - through the introduction of a novel training design,\nan alternative constrain leveraging a set of immunofluorescence (IF) images as\nan auxiliary unpaired image domain. Quantitative and qualitative results on a\ndownstream segmentation task show the benefit of the proposed method in\ncomparison to baseline approaches.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV",
      "I.2.10, J.3, I.4.6"
    ],
    "primary_category": "cs.CV",
    "comment": "5 pages",
    "pdf_url": "http://arxiv.org/pdf/2403.07389v2",
    "published_date": "2024-03-12 07:57:33 UTC",
    "updated_date": "2024-10-22 14:07:54 UTC"
  },
  {
    "arxiv_id": "2403.07384v2",
    "title": "SmallToLarge (S2L): Scalable Data Selection for Fine-tuning Large Language Models by Summarizing Training Trajectories of Small Models",
    "authors": [
      "Yu Yang",
      "Siddhartha Mishra",
      "Jeffrey N Chiang",
      "Baharan Mirzasoleiman"
    ],
    "abstract": "Despite the effectiveness of data selection for large language models (LLMs)\nduring pretraining and instruction fine-tuning phases, improving data\nefficiency in supervised fine-tuning (SFT) for specialized domains poses\nsignificant challenges due to the complexity of fine-tuning data. To bridge\nthis gap, we introduce an effective and scalable data selection method for SFT,\nSmallToLarge (S2L), which leverages training trajectories from small models to\nguide the data selection for larger models. We demonstrate through extensive\nexperiments that S2L significantly improves data efficiency in SFT for\nmathematical problem-solving, reducing the training data to just 11% of the\noriginal MathInstruct dataset (Yue et al., 2023) to match full dataset\nperformance while outperforming state-of-the-art data selection algorithms by\nan average of 4.7% across 6 in- and out-domain evaluation datasets. Remarkably,\nselecting only 50K data for SFT, S2L achieves a 32.7% accuracy on the most\nchallenging MATH (Hendrycks et al., 2021) benchmark, improving Phi-2 (Li et\nal., 2023b) by 16.6%. In clinical text summarization on the MIMIC-III dataset\n(Johnson et al., 2016), S2L again outperforms training on the full dataset\nusing only 50% of the data. Notably, S2L can perform data selection using a\nreference model 40x smaller than the target model, proportionally reducing the\ncost of data selection.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.07384v2",
    "published_date": "2024-03-12 07:45:33 UTC",
    "updated_date": "2024-12-05 18:47:47 UTC"
  },
  {
    "arxiv_id": "2403.07380v1",
    "title": "Gabor-guided transformer for single image deraining",
    "authors": [
      "Sijin He",
      "Guangfeng Lin"
    ],
    "abstract": "Image deraining have have gained a great deal of attention in order to\naddress the challenges posed by the effects of harsh weather conditions on\nvisual tasks. While convolutional neural networks (CNNs) are popular, their\nlimitations in capturing global information may result in ineffective rain\nremoval. Transformer-based methods with self-attention mechanisms have\nimproved, but they tend to distort high-frequency details that are crucial for\nimage fidelity. To solve this problem, we propose the Gabor-guided tranformer\n(Gabformer) for single image deraining. The focus on local texture features is\nenhanced by incorporating the information processed by the Gabor filter into\nthe query vector, which also improves the robustness of the model to noise due\nto the properties of the filter. Extensive experiments on the benchmarks\ndemonstrate that our method outperforms state-of-the-art approaches.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.07380v1",
    "published_date": "2024-03-12 07:41:51 UTC",
    "updated_date": "2024-03-12 07:41:51 UTC"
  },
  {
    "arxiv_id": "2403.07376v2",
    "title": "NavCoT: Boosting LLM-Based Vision-and-Language Navigation via Learning Disentangled Reasoning",
    "authors": [
      "Bingqian Lin",
      "Yunshuang Nie",
      "Ziming Wei",
      "Jiaqi Chen",
      "Shikui Ma",
      "Jianhua Han",
      "Hang Xu",
      "Xiaojun Chang",
      "Xiaodan Liang"
    ],
    "abstract": "Vision-and-Language Navigation (VLN), as a crucial research problem of\nEmbodied AI, requires an embodied agent to navigate through complex 3D\nenvironments following natural language instructions. Recent research has\nhighlighted the promising capacity of large language models (LLMs) in VLN by\nimproving navigational reasoning accuracy and interpretability. However, their\npredominant use in an offline manner usually suffers from substantial domain\ngap between the VLN task and the LLM training corpus. This paper introduces a\nnovel strategy called Navigational Chain-of-Thought (NavCoT), where we fulfill\nparameter-efficient in-domain training to enable self-guided navigational\ndecision, leading to a significant mitigation of the domain gap in a\ncost-effective manner. Specifically, at each timestep, the LLM is prompted to\nforecast the navigational chain-of-thought by: 1) acting as a world model to\nimagine the next observation according to the instruction, 2) selecting the\ncandidate observation that best aligns with the imagination, and 3) determining\nthe action based on the reasoning from the prior steps. Through constructing\nformalized labels for training, the LLM can learn to generate desired and\nreasonable chain-of-thought outputs for improving the action decision.\nExperimental results across various training settings and popular VLN\nbenchmarks (e.g., Room-to-Room (R2R), Room-across-Room (RxR), Room-for-Room\n(R4R)) show the significant superiority of NavCoT over the direct action\nprediction variants. Through simple parameter-efficient finetuning, our NavCoT\noutperforms a recent GPT4-based approach with ~7% relative improvement on the\nR2R dataset. We believe that NavCoT will help unlock more task-adaptive and\nscalable LLM-based embodied agents, which are helpful for developing real-world\nrobotics applications. Code is available at\nhttps://github.com/expectorlin/NavCoT.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by TPAMI 2025",
    "pdf_url": "http://arxiv.org/pdf/2403.07376v2",
    "published_date": "2024-03-12 07:27:02 UTC",
    "updated_date": "2025-03-22 11:04:36 UTC"
  },
  {
    "arxiv_id": "2403.09718v1",
    "title": "Comprehensive Implementation of TextCNN for Enhanced Collaboration between Natural Language Processing and System Recommendation",
    "authors": [
      "Xiaonan Xu",
      "Zheng Xu",
      "Zhipeng Ling",
      "Zhengyu Jin",
      "ShuQian Du"
    ],
    "abstract": "Natural Language Processing (NLP) is an important branch of artificial\nintelligence that studies how to enable computers to understand, process, and\ngenerate human language. Text classification is a fundamental task in NLP,\nwhich aims to classify text into different predefined categories. Text\nclassification is the most basic and classic task in natural language\nprocessing, and most of the tasks in natural language processing can be\nregarded as classification tasks. In recent years, deep learning has achieved\ngreat success in many research fields, and today, it has also become a standard\ntechnology in the field of NLP, which is widely integrated into text\nclassification tasks. Unlike numbers and images, text processing emphasizes\nfine-grained processing ability. Traditional text classification methods\ngenerally require preprocessing the input model's text data. Additionally, they\nalso need to obtain good sample features through manual annotation and then use\nclassical machine learning algorithms for classification. Therefore, this paper\nanalyzes the application status of deep learning in the three core tasks of NLP\n(including text representation, word order modeling, and knowledge\nrepresentation). This content explores the improvement and synergy achieved\nthrough natural language processing in the context of text classification,\nwhile also taking into account the challenges posed by adversarial techniques\nin text generation, text classification, and semantic parsing. An empirical\nstudy on text classification tasks demonstrates the effectiveness of\ninteractive integration training, particularly in conjunction with TextCNN,\nhighlighting the significance of these advancements in text classification\naugmentation and enhancement.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.09718v1",
    "published_date": "2024-03-12 07:25:53 UTC",
    "updated_date": "2024-03-12 07:25:53 UTC"
  },
  {
    "arxiv_id": "2403.07955v2",
    "title": "Towards Faithful Explanations: Boosting Rationalization with Shortcuts Discovery",
    "authors": [
      "Linan Yue",
      "Qi Liu",
      "Yichao Du",
      "Li Wang",
      "Weibo Gao",
      "Yanqing An"
    ],
    "abstract": "The remarkable success in neural networks provokes the selective\nrationalization. It explains the prediction results by identifying a small\nsubset of the inputs sufficient to support them. Since existing methods still\nsuffer from adopting the shortcuts in data to compose rationales and limited\nlarge-scale annotated rationales by human, in this paper, we propose a\nShortcuts-fused Selective Rationalization (SSR) method, which boosts the\nrationalization by discovering and exploiting potential shortcuts.\nSpecifically, SSR first designs a shortcuts discovery approach to detect\nseveral potential shortcuts. Then, by introducing the identified shortcuts, we\npropose two strategies to mitigate the problem of utilizing shortcuts to\ncompose rationales. Finally, we develop two data augmentations methods to close\nthe gap in the number of annotated rationales. Extensive experimental results\non real-world datasets clearly validate the effectiveness of our proposed\nmethod.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to ICLR 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.07955v2",
    "published_date": "2024-03-12 07:24:17 UTC",
    "updated_date": "2024-07-19 04:31:38 UTC"
  },
  {
    "arxiv_id": "2403.09717v1",
    "title": "Enhancing Depression-Diagnosis-Oriented Chat with Psychological State Tracking",
    "authors": [
      "Yiyang Gu",
      "Yougen Zhou",
      "Qin Chen",
      "Ningning Zhou",
      "Jie Zhou",
      "Aimin Zhou",
      "Liang He"
    ],
    "abstract": "Depression-diagnosis-oriented chat aims to guide patients in self-expression\nto collect key symptoms for depression detection. Recent work focuses on\ncombining task-oriented dialogue and chitchat to simulate the interview-based\ndepression diagnosis. Whereas, these methods can not well capture the changing\ninformation, feelings, or symptoms of the patient during dialogues. Moreover,\nno explicit framework has been explored to guide the dialogue, which results in\nsome useless communications that affect the experience. In this paper, we\npropose to integrate Psychological State Tracking (POST) within the large\nlanguage model (LLM) to explicitly guide depression-diagnosis-oriented chat.\nSpecifically, the state is adapted from a psychological theoretical model,\nwhich consists of four components, namely Stage, Information, Summary and Next.\nWe fine-tune an LLM model to generate the dynamic psychological state, which is\nfurther used to assist response generation at each turn to simulate the\npsychiatrist. Experimental results on the existing benchmark show that our\nproposed method boosts the performance of all subtasks in\ndepression-diagnosis-oriented chat.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CL",
      "cs.CY"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.09717v1",
    "published_date": "2024-03-12 07:17:01 UTC",
    "updated_date": "2024-03-12 07:17:01 UTC"
  },
  {
    "arxiv_id": "2403.07363v2",
    "title": "A New Random Forest Ensemble of Intuitionistic Fuzzy Decision Trees",
    "authors": [
      "Yingtao Ren",
      "Xiaomin Zhu",
      "Kaiyuan Bai",
      "Runtong Zhang"
    ],
    "abstract": "Classification is essential to the applications in the field of data mining,\nartificial intelligence, and fault detection. There exists a strong need in\ndeveloping accurate, suitable, and efficient classification methods and\nalgorithms with broad applicability. Random forest is a general algorithm that\nis often used for classification under complex conditions. Although it has been\nwidely adopted, its combination with diverse fuzzy theory is still worth\nexploring. In this paper, we propose the intuitionistic fuzzy random forest\n(IFRF), a new random forest ensemble of intuitionistic fuzzy decision trees\n(IFDT). Such trees in forest use intuitionistic fuzzy information gain to\nselect features and consider hesitation in information transmission. The\nproposed method enjoys the power of the randomness from bootstrapped sampling\nand feature selection, the flexibility of fuzzy logic and fuzzy sets, and the\nrobustness of multiple classifier systems. Extensive experiments demonstrate\nthat the IFRF has competitative and superior performance compared to other\nstate-of-the-art fuzzy and ensemble algorithms. IFDT is more suitable for\nensemble learning with outstanding classification accuracy. This study is the\nfirst to propose a random forest ensemble based on the intuitionistic fuzzy\ntheory.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.07363v2",
    "published_date": "2024-03-12 06:52:24 UTC",
    "updated_date": "2024-03-17 11:08:15 UTC"
  },
  {
    "arxiv_id": "2403.07362v4",
    "title": "Challenging Forgets: Unveiling the Worst-Case Forget Sets in Machine Unlearning",
    "authors": [
      "Chongyu Fan",
      "Jiancheng Liu",
      "Alfred Hero",
      "Sijia Liu"
    ],
    "abstract": "The trustworthy machine learning (ML) community is increasingly recognizing\nthe crucial need for models capable of selectively 'unlearning' data points\nafter training. This leads to the problem of machine unlearning (MU), aiming to\neliminate the influence of chosen data points on model performance, while still\nmaintaining the model's utility post-unlearning. Despite various MU methods for\ndata influence erasure, evaluations have largely focused on random data\nforgetting, ignoring the vital inquiry into which subset should be chosen to\ntruly gauge the authenticity of unlearning performance. To tackle this issue,\nwe introduce a new evaluative angle for MU from an adversarial viewpoint. We\npropose identifying the data subset that presents the most significant\nchallenge for influence erasure, i.e., pinpointing the worst-case forget set.\nUtilizing a bi-level optimization principle, we amplify unlearning challenges\nat the upper optimization level to emulate worst-case scenarios, while\nsimultaneously engaging in standard training and unlearning at the lower level,\nachieving a balance between data influence erasure and model utility. Our\nproposal offers a worst-case evaluation of MU's resilience and effectiveness.\nThrough extensive experiments across different datasets (including CIFAR-10,\n100, CelebA, Tiny ImageNet, and ImageNet) and models (including both image\nclassifiers and generative models), we expose critical pros and cons in\nexisting (approximate) unlearning strategies. Our results illuminate the\ncomplex challenges of MU in practice, guiding the future development of more\naccurate and robust unlearning algorithms. The code is available at\nhttps://github.com/OPTML-Group/Unlearn-WorstCase.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by ECCV 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.07362v4",
    "published_date": "2024-03-12 06:50:32 UTC",
    "updated_date": "2024-07-09 03:59:01 UTC"
  },
  {
    "arxiv_id": "2403.07355v2",
    "title": "Vector Quantization for Deep-Learning-Based CSI Feedback in Massive MIMO Systems",
    "authors": [
      "Junyong Shin",
      "Yujin Kang",
      "Yo-Seb Jeon"
    ],
    "abstract": "This paper presents a finite-rate deep-learning (DL)-based channel state\ninformation (CSI) feedback method for massive multiple-input multiple-output\n(MIMO) systems. The presented method provides a finite-bit representation of\nthe latent vector based on a vector-quantized variational autoencoder (VQ-VAE)\nframework while reducing its computational complexity based on shape-gain\nvector quantization. In this method, the magnitude of the latent vector is\nquantized using a non-uniform scalar codebook with a proper transformation\nfunction, while the direction of the latent vector is quantized using a\ntrainable Grassmannian codebook. A multi-rate codebook design strategy is also\ndeveloped by introducing a codeword selection rule for a nested codebook along\nwith the design of a loss function. Simulation results demonstrate that the\nproposed method reduces the computational complexity associated with VQ-VAE\nwhile improving CSI reconstruction performance under a given feedback overhead.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.07355v2",
    "published_date": "2024-03-12 06:28:41 UTC",
    "updated_date": "2024-03-13 02:29:29 UTC"
  },
  {
    "arxiv_id": "2403.07953v2",
    "title": "Abstracting Sparse DNN Acceleration via Structured Sparse Tensor Decomposition",
    "authors": [
      "Geonhwa Jeong",
      "Po-An Tsai",
      "Abhimanyu R. Bambhaniya",
      "Stephen W. Keckler",
      "Tushar Krishna"
    ],
    "abstract": "Exploiting sparsity in deep neural networks (DNNs) has been a promising area\nto meet the growing computation need of modern DNNs. However, in practice,\nsparse DNN acceleration still faces a key challenge. To minimize the overhead\nof sparse acceleration, hardware designers have proposed structured sparse\nhardware support recently, which provides limited flexibility and requires\nextra model fine-tuning. Moreover, any sparse model fine-tuned for certain\nstructured sparse hardware cannot be accelerated by other structured hardware.\nTo bridge the gap between sparse DNN models and hardware, this paper proposes\ntensor approximation via structured decomposition (TASD), which leverages the\ndistributive property in linear algebra to turn any sparse tensor into a series\nof structured sparse tensors. Next, we develop a software framework, TASDER, to\naccelerate DNNs by searching layer-wise, high-quality structured decomposition\nfor both weight and activation tensors so that they can be accelerated by any\nsystems with structured sparse hardware support. Evaluation results show that,\nby exploiting prior structured sparse hardware baselines, our method can\naccelerate off-the-shelf dense and sparse DNNs without fine-tuning and improves\nenergy-delay-product by up to 83% and 74% on average.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.AR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.07953v2",
    "published_date": "2024-03-12 06:25:47 UTC",
    "updated_date": "2024-03-31 23:47:47 UTC"
  },
  {
    "arxiv_id": "2403.07350v3",
    "title": "VLKEB: A Large Vision-Language Model Knowledge Editing Benchmark",
    "authors": [
      "Han Huang",
      "Haitian Zhong",
      "Tao Yu",
      "Qiang Liu",
      "Shu Wu",
      "Liang Wang",
      "Tieniu Tan"
    ],
    "abstract": "Recently, knowledge editing on large language models (LLMs) has received\nconsiderable attention. Compared to this, editing Large Vision-Language Models\n(LVLMs) faces extra challenges from diverse data modalities and complicated\nmodel components, and data for LVLMs editing are limited. The existing LVLM\nediting benchmark, which comprises three metrics (Reliability, Locality, and\nGenerality), falls short in the quality of synthesized evaluation images and\ncannot assess whether models apply edited knowledge in relevant content.\nTherefore, we employ more reliable data collection methods to construct a new\nLarge $\\textbf{V}$ision-$\\textbf{L}$anguage Model $\\textbf{K}$nowledge\n$\\textbf{E}$diting $\\textbf{B}$enchmark, $\\textbf{VLKEB}$, and extend the\nPortability metric for more comprehensive evaluation. Leveraging a multi-modal\nknowledge graph, our image data are bound with knowledge entities. This can be\nfurther used to extract entity-related knowledge, which constitutes the base of\nediting data. We conduct experiments of different editing methods on five\nLVLMs, and thoroughly analyze how do they impact the models. The results reveal\nstrengths and deficiencies of these methods and hopefully provide insights for\nfuture research. The codes and dataset are available at:\nhttps://github.com/VLKEB/VLKEB.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CL",
    "comment": "NeurIPS 2024, Datasets and Benchmarks Track",
    "pdf_url": "http://arxiv.org/pdf/2403.07350v3",
    "published_date": "2024-03-12 06:16:33 UTC",
    "updated_date": "2024-10-29 09:31:22 UTC"
  },
  {
    "arxiv_id": "2403.07342v2",
    "title": "Rethinking ASTE: A Minimalist Tagging Scheme Alongside Contrastive Learning",
    "authors": [
      "Qiao Sun",
      "Liujia Yang",
      "Minghao Ma",
      "Nanyang Ye",
      "Qinying Gu"
    ],
    "abstract": "Aspect Sentiment Triplet Extraction (ASTE) is a burgeoning subtask of\nfine-grained sentiment analysis, aiming to extract structured sentiment\ntriplets from unstructured textual data. Existing approaches to ASTE often\ncomplicate the task with additional structures or external data. In this\nresearch, we propose a novel tagging scheme and employ a contrastive learning\napproach to mitigate these challenges. The proposed approach demonstrates\ncomparable or superior performance in comparison to state-of-the-art\ntechniques, while featuring a more compact design and reduced computational\noverhead. Notably, even in the era of Large Language Models (LLMs), our method\nexhibits superior efficacy compared to GPT 3.5 and GPT 4 in a few-shot learning\nscenarios. This study also provides valuable insights for the advancement of\nASTE techniques within the paradigm of large language models.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.07342v2",
    "published_date": "2024-03-12 06:01:04 UTC",
    "updated_date": "2024-04-14 20:53:02 UTC"
  },
  {
    "arxiv_id": "2403.07332v2",
    "title": "LKM-UNet: Large Kernel Vision Mamba UNet for Medical Image Segmentation",
    "authors": [
      "Jinhong Wang",
      "Jintai Chen",
      "Danny Chen",
      "Jian Wu"
    ],
    "abstract": "In clinical practice, medical image segmentation provides useful information\non the contours and dimensions of target organs or tissues, facilitating\nimproved diagnosis, analysis, and treatment. In the past few years,\nconvolutional neural networks (CNNs) and Transformers have dominated this area,\nbut they still suffer from either limited receptive fields or costly long-range\nmodeling. Mamba, a State Space Sequence Model (SSM), recently emerged as a\npromising paradigm for long-range dependency modeling with linear complexity.\nIn this paper, we introduce a Large Kernel Vision Mamba U-shape Network, or\nLKM-UNet, for medical image segmentation. A distinguishing feature of our\nLKM-UNet is its utilization of large Mamba kernels, excelling in locally\nspatial modeling compared to small kernel-based CNNs and Transformers, while\nmaintaining superior efficiency in global modeling compared to self-attention\nwith quadratic complexity. Additionally, we design a novel hierarchical and\nbidirectional Mamba block to further enhance Mamba's global and neighborhood\nspatial modeling capability for vision inputs. Comprehensive experiments\ndemonstrate the feasibility and the effectiveness of using large-size Mamba\nkernels to achieve large receptive fields. Codes are available at\nhttps://github.com/wjh892521292/LKM-UNet.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by MICCAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.07332v2",
    "published_date": "2024-03-12 05:34:51 UTC",
    "updated_date": "2024-06-25 03:37:26 UTC"
  },
  {
    "arxiv_id": "2403.07322v3",
    "title": "A Question-centric Multi-experts Contrastive Learning Framework for Improving the Accuracy and Interpretability of Deep Sequential Knowledge Tracing Models",
    "authors": [
      "Hengyuan Zhang",
      "Zitao Liu",
      "Chenming Shang",
      "Dawei Li",
      "Yong Jiang"
    ],
    "abstract": "Knowledge tracing (KT) plays a crucial role in predicting students' future\nperformance by analyzing their historical learning processes. Deep neural\nnetworks (DNNs) have shown great potential in solving the KT problem. However,\nthere still exist some important challenges when applying deep learning\ntechniques to model the KT process. The first challenge lies in taking the\nindividual information of the question into modeling. This is crucial because,\ndespite questions sharing the same knowledge component (KC), students'\nknowledge acquisition on homogeneous questions can vary significantly. The\nsecond challenge lies in interpreting the prediction results from existing deep\nlearning-based KT models. In real-world applications, while it may not be\nnecessary to have complete transparency and interpretability of the model\nparameters, it is crucial to present the model's prediction results in a manner\nthat teachers find interpretable. This makes teachers accept the rationale\nbehind the prediction results and utilize them to design teaching activities\nand tailored learning strategies for students. However, the inherent black-box\nnature of deep learning techniques often poses a hurdle for teachers to fully\nembrace the model's prediction results. To address these challenges, we propose\na Question-centric Multi-experts Contrastive Learning framework for KT called\nQ-MCKT. We have provided all the datasets and code on our website at\nhttps://github.com/rattlesnakey/Q-MCKT.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "25 pages, 9 figures, Accepted by TKDD",
    "pdf_url": "http://arxiv.org/pdf/2403.07322v3",
    "published_date": "2024-03-12 05:15:42 UTC",
    "updated_date": "2024-07-05 16:11:43 UTC"
  },
  {
    "arxiv_id": "2403.07309v1",
    "title": "Reinforced Sequential Decision-Making for Sepsis Treatment: The POSNEGDM Framework with Mortality Classifier and Transformer",
    "authors": [
      "Dipesh Tamboli",
      "Jiayu Chen",
      "Kiran Pranesh Jotheeswaran",
      "Denny Yu",
      "Vaneet Aggarwal"
    ],
    "abstract": "Sepsis, a life-threatening condition triggered by the body's exaggerated\nresponse to infection, demands urgent intervention to prevent severe\ncomplications. Existing machine learning methods for managing sepsis struggle\nin offline scenarios, exhibiting suboptimal performance with survival rates\nbelow 50%. This paper introduces the POSNEGDM -- ``Reinforcement Learning with\nPositive and Negative Demonstrations for Sequential Decision-Making\" framework\nutilizing an innovative transformer-based model and a feedback reinforcer to\nreplicate expert actions while considering individual patient characteristics.\nA mortality classifier with 96.7\\% accuracy guides treatment decisions towards\npositive outcomes. The POSNEGDM framework significantly improves patient\nsurvival, saving 97.39% of patients, outperforming established machine learning\nalgorithms (Decision Transformer and Behavioral Cloning) with survival rates of\n33.4% and 43.5%, respectively. Additionally, ablation studies underscore the\ncritical role of the transformer-based decision maker and the integration of a\nmortality classifier in enhancing overall survival rates. In summary, our\nproposed approach presents a promising avenue for enhancing sepsis treatment\noutcomes, contributing to improved patient care and reduced healthcare costs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to IEEE Journal of Biomedical and Health Informatics, Mar\n  2024",
    "pdf_url": "http://arxiv.org/pdf/2403.07309v1",
    "published_date": "2024-03-12 04:36:41 UTC",
    "updated_date": "2024-03-12 04:36:41 UTC"
  },
  {
    "arxiv_id": "2403.07308v1",
    "title": "Verification-Aided Learning of Neural Network Barrier Functions with Termination Guarantees",
    "authors": [
      "Shaoru Chen",
      "Lekan Molu",
      "Mahyar Fazlyab"
    ],
    "abstract": "Barrier functions are a general framework for establishing a safety guarantee\nfor a system. However, there is no general method for finding these functions.\nTo address this shortcoming, recent approaches use self-supervised learning\ntechniques to learn these functions using training data that are periodically\ngenerated by a verification procedure, leading to a verification-aided learning\nframework. Despite its immense potential in automating barrier function\nsynthesis, the verification-aided learning framework does not have termination\nguarantees and may suffer from a low success rate of finding a valid barrier\nfunction in practice. In this paper, we propose a holistic approach to address\nthese drawbacks. With a convex formulation of the barrier function synthesis,\nwe propose to first learn an empirically well-behaved NN basis function and\nthen apply a fine-tuning algorithm that exploits the convexity and\ncounterexamples from the verification failure to find a valid barrier function\nwith finite-step termination guarantees: if there exist valid barrier\nfunctions, the fine-tuning algorithm is guaranteed to find one in a finite\nnumber of iterations. We demonstrate that our fine-tuning method can\nsignificantly boost the performance of the verification-aided learning\nframework on examples of different scales and using various neural network\nverifiers.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.LG",
    "comment": "This is an online extended version of the same paper accepted to\n  American Control Conference 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.07308v1",
    "published_date": "2024-03-12 04:29:43 UTC",
    "updated_date": "2024-03-12 04:29:43 UTC"
  },
  {
    "arxiv_id": "2403.07294v2",
    "title": "Graph Data Condensation via Self-expressive Graph Structure Reconstruction",
    "authors": [
      "Zhanyu Liu",
      "Chaolv Zeng",
      "Guanjie Zheng"
    ],
    "abstract": "With the increasing demands of training graph neural networks (GNNs) on\nlarge-scale graphs, graph data condensation has emerged as a critical technique\nto relieve the storage and time costs during the training phase. It aims to\ncondense the original large-scale graph to a much smaller synthetic graph while\npreserving the essential information necessary for efficiently training a\ndownstream GNN. However, existing methods concentrate either on optimizing node\nfeatures exclusively or endeavor to independently learn node features and the\ngraph structure generator. They could not explicitly leverage the information\nof the original graph structure and failed to construct an interpretable graph\nstructure for the synthetic dataset. To address these issues, we introduce a\nnovel framework named \\textbf{G}raph Data \\textbf{C}ondensation via\n\\textbf{S}elf-expressive Graph Structure \\textbf{R}econstruction\n(\\textbf{GCSR}). Our method stands out by (1) explicitly incorporating the\noriginal graph structure into the condensing process and (2) capturing the\nnuanced interdependencies between the condensed nodes by reconstructing an\ninterpretable self-expressive graph structure. Extensive experiments and\ncomprehensive analysis validate the efficacy of the proposed method across\ndiverse GNN models and datasets. Our code is available at\n\\url{https://github.com/zclzcl0223/GCSR}.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.07294v2",
    "published_date": "2024-03-12 03:54:25 UTC",
    "updated_date": "2024-06-07 04:36:34 UTC"
  },
  {
    "arxiv_id": "2403.07292v1",
    "title": "Continual All-in-One Adverse Weather Removal with Knowledge Replay on a Unified Network Structure",
    "authors": [
      "De Cheng",
      "Yanling Ji",
      "Dong Gong",
      "Yan Li",
      "Nannan Wang",
      "Junwei Han",
      "Dingwen Zhang"
    ],
    "abstract": "In real-world applications, image degeneration caused by adverse weather is\nalways complex and changes with different weather conditions from days and\nseasons. Systems in real-world environments constantly encounter adverse\nweather conditions that are not previously observed. Therefore, it practically\nrequires adverse weather removal models to continually learn from incrementally\ncollected data reflecting various degeneration types. Existing adverse weather\nremoval approaches, for either single or multiple adverse weathers, are mainly\ndesigned for a static learning paradigm, which assumes that the data of all\ntypes of degenerations to handle can be finely collected at one time before a\nsingle-phase learning process. They thus cannot directly handle the incremental\nlearning requirements. To address this issue, we made the earliest effort to\ninvestigate the continual all-in-one adverse weather removal task, in a setting\ncloser to real-world applications. Specifically, we develop a novel continual\nlearning framework with effective knowledge replay (KR) on a unified network\nstructure. Equipped with a principal component projection and an effective\nknowledge distillation mechanism, the proposed KR techniques are tailored for\nthe all-in-one weather removal task. It considers the characteristics of the\nimage restoration task with multiple degenerations in continual learning, and\nthe knowledge for different degenerations can be shared and accumulated in the\nunified network structure. Extensive experimental results demonstrate the\neffectiveness of the proposed method to deal with this challenging task, which\nperforms competitively to existing dedicated or joint training image\nrestoration methods. Our code is available at\nhttps://github.com/xiaojihh/CL_all-in-one.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.07292v1",
    "published_date": "2024-03-12 03:50:57 UTC",
    "updated_date": "2024-03-12 03:50:57 UTC"
  },
  {
    "arxiv_id": "2403.07277v2",
    "title": "A Bayesian Approach to OOD Robustness in Image Classification",
    "authors": [
      "Prakhar Kaushik",
      "Adam Kortylewski",
      "Alan Yuille"
    ],
    "abstract": "An important and unsolved problem in computer vision is to ensure that the\nalgorithms are robust to changes in image domains. We address this problem in\nthe scenario where we have access to images from the target domains but no\nannotations. Motivated by the challenges of the OOD-CV benchmark where we\nencounter real world Out-of-Domain (OOD) nuisances and occlusion, we introduce\na novel Bayesian approach to OOD robustness for object classification. Our work\nextends Compositional Neural Networks (CompNets), which have been shown to be\nrobust to occlusion but degrade badly when tested on OOD data. We exploit the\nfact that CompNets contain a generative head defined over feature vectors\nrepresented by von Mises-Fisher (vMF) kernels, which correspond roughly to\nobject parts, and can be learned without supervision. We obverse that some vMF\nkernels are similar between different domains, while others are not. This\nenables us to learn a transitional dictionary of vMF kernels that are\nintermediate between the source and target domains and train the generative\nmodel on this dictionary using the annotations on the source domain, followed\nby iterative refinement. This approach, termed Unsupervised Generative\nTransition (UGT), performs very well in OOD scenarios even when occlusion is\npresent. UGT is evaluated on different OOD benchmarks including the OOD-CV\ndataset, several popular datasets (e.g., ImageNet-C [9]), artificial image\ncorruptions (including adding occluders), and synthetic-to-real domain\ntransfer, and does well in all scenarios outperforming SOTA alternatives (e.g.\nup to 10% top-1 accuracy on Occluded OOD-CV dataset).",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.07277v2",
    "published_date": "2024-03-12 03:15:08 UTC",
    "updated_date": "2025-02-07 06:35:05 UTC"
  },
  {
    "arxiv_id": "2403.07271v1",
    "title": "Anderson acceleration for iteratively reweighted $\\ell_1$ algorithm",
    "authors": [
      "Kexin Li"
    ],
    "abstract": "Iteratively reweighted L1 (IRL1) algorithm is a common algorithm for solving\nsparse optimization problems with nonconvex and nonsmooth regularization. The\ndevelopment of its acceleration algorithm, often employing Nesterov\nacceleration, has sparked significant interest. Nevertheless, the convergence\nand complexity analysis of these acceleration algorithms consistently poses\nsubstantial challenges. Recently, Anderson acceleration has gained prominence\nowing to its exceptional performance for speeding up fixed-point iteration,\nwith numerous recent studies applying it to gradient-based algorithms.\nMotivated by the powerful impact of Anderson acceleration, we propose an\nAnderson-accelerated IRL1 algorithm and establish its local linear convergence\nrate. We extend this convergence result, typically observed in smooth settings,\nto a nonsmooth scenario. Importantly, our theoretical results do not depend on\nthe Kurdyka-Lojasiewicz condition, a necessary condition in existing Nesterov\nacceleration-based algorithms. Furthermore, to ensure global convergence, we\nintroduce a globally convergent Anderson accelerated IRL1 algorithm by\nincorporating a classical nonmonotone line search condition. Experimental\nresults indicate that our algorithm outperforms existing Nesterov\nacceleration-based algorithms.",
    "categories": [
      "math.OC",
      "cs.AI",
      "cs.LG",
      "eess.SP"
    ],
    "primary_category": "math.OC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.07271v1",
    "published_date": "2024-03-12 03:00:15 UTC",
    "updated_date": "2024-03-12 03:00:15 UTC"
  },
  {
    "arxiv_id": "2403.07262v4",
    "title": "A2PO: Towards Effective Offline Reinforcement Learning from an Advantage-aware Perspective",
    "authors": [
      "Yunpeng Qing",
      "Shunyu liu",
      "Jingyuan Cong",
      "Kaixuan Chen",
      "Yihe Zhou",
      "Mingli Song"
    ],
    "abstract": "Offline reinforcement learning endeavors to leverage offline datasets to\ncraft effective agent policy without online interaction, which imposes proper\nconservative constraints with the support of behavior policies to tackle the\nout-of-distribution problem. However, existing works often suffer from the\nconstraint conflict issue when offline datasets are collected from multiple\nbehavior policies, i.e., different behavior policies may exhibit inconsistent\nactions with distinct returns across the state space. To remedy this issue,\nrecent advantage-weighted methods prioritize samples with high advantage values\nfor agent training while inevitably ignoring the diversity of behavior policy.\nIn this paper, we introduce a novel Advantage-Aware Policy Optimization (A2PO)\nmethod to explicitly construct advantage-aware policy constraints for offline\nlearning under mixed-quality datasets. Specifically, A2PO employs a conditional\nvariational auto-encoder to disentangle the action distributions of intertwined\nbehavior policies by modeling the advantage values of all training data as\nconditional variables. Then the agent can follow such disentangled action\ndistribution constraints to optimize the advantage-aware policy towards high\nadvantage values. Extensive experiments conducted on both the single-quality\nand mixed-quality datasets of the D4RL benchmark demonstrate that A2PO yields\nresults superior to the counterparts. Our code is available at\nhttps://github.com/Plankson/A2PO",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.07262v4",
    "published_date": "2024-03-12 02:43:41 UTC",
    "updated_date": "2024-11-11 10:59:52 UTC"
  },
  {
    "arxiv_id": "2403.07261v1",
    "title": "Disentangling Policy from Offline Task Representation Learning via Adversarial Data Augmentation",
    "authors": [
      "Chengxing Jia",
      "Fuxiang Zhang",
      "Yi-Chen Li",
      "Chen-Xiao Gao",
      "Xu-Hui Liu",
      "Lei Yuan",
      "Zongzhang Zhang",
      "Yang Yu"
    ],
    "abstract": "Offline meta-reinforcement learning (OMRL) proficiently allows an agent to\ntackle novel tasks while solely relying on a static dataset. For precise and\nefficient task identification, existing OMRL research suggests learning\nseparate task representations that be incorporated with policy input, thus\nforming a context-based meta-policy. A major approach to train task\nrepresentations is to adopt contrastive learning using multi-task offline data.\nThe dataset typically encompasses interactions from various policies (i.e., the\nbehavior policies), thus providing a plethora of contextual information\nregarding different tasks. Nonetheless, amassing data from a substantial number\nof policies is not only impractical but also often unattainable in realistic\nsettings. Instead, we resort to a more constrained yet practical scenario,\nwhere multi-task data collection occurs with a limited number of policies. We\nobserved that learned task representations from previous OMRL methods tend to\ncorrelate spuriously with the behavior policy instead of reflecting the\nessential characteristics of the task, resulting in unfavorable\nout-of-distribution generalization. To alleviate this issue, we introduce a\nnovel algorithm to disentangle the impact of behavior policy from task\nrepresentation learning through a process called adversarial data augmentation.\nSpecifically, the objective of adversarial data augmentation is not merely to\ngenerate data analogous to offline data distribution; instead, it aims to\ncreate adversarial examples designed to confound learned task representations\nand lead to incorrect task identification. Our experiments show that learning\nfrom such adversarial samples significantly enhances the robustness and\neffectiveness of the task identification process and realizes satisfactory\nout-of-distribution generalization.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.07261v1",
    "published_date": "2024-03-12 02:38:36 UTC",
    "updated_date": "2024-03-12 02:38:36 UTC"
  },
  {
    "arxiv_id": "2403.07952v1",
    "title": "AesopAgent: Agent-driven Evolutionary System on Story-to-Video Production",
    "authors": [
      "Jiuniu Wang",
      "Zehua Du",
      "Yuyuan Zhao",
      "Bo Yuan",
      "Kexiang Wang",
      "Jian Liang",
      "Yaxi Zhao",
      "Yihen Lu",
      "Gengliang Li",
      "Junlong Gao",
      "Xin Tu",
      "Zhenyu Guo"
    ],
    "abstract": "The Agent and AIGC (Artificial Intelligence Generated Content) technologies\nhave recently made significant progress. We propose AesopAgent, an Agent-driven\nEvolutionary System on Story-to-Video Production. AesopAgent is a practical\napplication of agent technology for multimodal content generation. The system\nintegrates multiple generative capabilities within a unified framework, so that\nindividual users can leverage these modules easily. This innovative system\nwould convert user story proposals into scripts, images, and audio, and then\nintegrate these multimodal contents into videos. Additionally, the animating\nunits (e.g., Gen-2 and Sora) could make the videos more infectious. The\nAesopAgent system could orchestrate task workflow for video generation,\nensuring that the generated video is both rich in content and coherent. This\nsystem mainly contains two layers, i.e., the Horizontal Layer and the Utility\nLayer. In the Horizontal Layer, we introduce a novel RAG-based evolutionary\nsystem that optimizes the whole video generation workflow and the steps within\nthe workflow. It continuously evolves and iteratively optimizes workflow by\naccumulating expert experience and professional knowledge, including optimizing\nthe LLM prompts and utilities usage. The Utility Layer provides multiple\nutilities, leading to consistent image generation that is visually coherent in\nterms of composition, characters, and style. Meanwhile, it provides audio and\nspecial effects, integrating them into expressive and logically arranged\nvideos. Overall, our AesopAgent achieves state-of-the-art performance compared\nwith many previous works in visual storytelling. Our AesopAgent is designed for\nconvenient service for individual users, which is available on the following\npage: https://aesopai.github.io/.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "22 pages, 13 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.07952v1",
    "published_date": "2024-03-12 02:30:50 UTC",
    "updated_date": "2024-03-12 02:30:50 UTC"
  },
  {
    "arxiv_id": "2403.07255v1",
    "title": "Deep Learning-Assisted Parallel Interference Cancellation for Grant-Free NOMA in Machine-Type Communication",
    "authors": [
      "Yongjeong Oh",
      "Jaehong Jo",
      "Byonghyo Shim",
      "Yo-Seb Jeon"
    ],
    "abstract": "In this paper, we present a novel approach for joint activity detection (AD),\nchannel estimation (CE), and data detection (DD) in uplink grant-free\nnon-orthogonal multiple access (NOMA) systems. Our approach employs an\niterative and parallel interference removal strategy inspired by parallel\ninterference cancellation (PIC), enhanced with deep learning to jointly tackle\nthe AD, CE, and DD problems. Based on this approach, we develop three PIC\nframeworks, each of which is designed for either coherent or non-coherence\nschemes. The first framework performs joint AD and CE using received pilot\nsignals in the coherent scheme. Building upon this framework, the second\nframework utilizes both the received pilot and data signals for CE, further\nenhancing the performances of AD, CE, and DD in the coherent scheme. The third\nframework is designed to accommodate the non-coherent scheme involving a small\nnumber of data bits, which simultaneously performs AD and DD. Through joint\nloss functions and interference cancellation modules, our approach supports\nend-to-end training, contributing to enhanced performances of AD, CE, and DD\nfor both coherent and non-coherent schemes. Simulation results demonstrate the\nsuperiority of our approach over traditional techniques, exhibiting enhanced\nperformances of AD, CE, and DD while maintaining lower computational\ncomplexity.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.07255v1",
    "published_date": "2024-03-12 02:24:37 UTC",
    "updated_date": "2024-03-12 02:24:37 UTC"
  },
  {
    "arxiv_id": "2403.10547v1",
    "title": "Robust Second-Order Nonconvex Optimization and Its Application to Low Rank Matrix Sensing",
    "authors": [
      "Shuyao Li",
      "Yu Cheng",
      "Ilias Diakonikolas",
      "Jelena Diakonikolas",
      "Rong Ge",
      "Stephen J. Wright"
    ],
    "abstract": "Finding an approximate second-order stationary point (SOSP) is a well-studied\nand fundamental problem in stochastic nonconvex optimization with many\napplications in machine learning. However, this problem is poorly understood in\nthe presence of outliers, limiting the use of existing nonconvex algorithms in\nadversarial settings.\n  In this paper, we study the problem of finding SOSPs in the strong\ncontamination model, where a constant fraction of datapoints are arbitrarily\ncorrupted. We introduce a general framework for efficiently finding an\napproximate SOSP with \\emph{dimension-independent} accuracy guarantees, using\n$\\widetilde{O}({D^2}/{\\epsilon})$ samples where $D$ is the ambient dimension\nand $\\epsilon$ is the fraction of corrupted datapoints.\n  As a concrete application of our framework, we apply it to the problem of low\nrank matrix sensing, developing efficient and provably robust algorithms that\ncan tolerate corruptions in both the sensing matrices and the measurements. In\naddition, we establish a Statistical Query lower bound providing evidence that\nthe quadratic dependence on $D$ in the sample complexity is necessary for\ncomputationally efficient algorithms.",
    "categories": [
      "math.OC",
      "cs.AI",
      "cs.DS",
      "cs.LG"
    ],
    "primary_category": "math.OC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.10547v1",
    "published_date": "2024-03-12 01:27:44 UTC",
    "updated_date": "2024-03-12 01:27:44 UTC"
  },
  {
    "arxiv_id": "2403.07230v2",
    "title": "Curry-DPO: Enhancing Alignment using Curriculum Learning & Ranked Preferences",
    "authors": [
      "Pulkit Pattnaik",
      "Rishabh Maheshwary",
      "Kelechi Ogueji",
      "Vikas Yadav",
      "Sathwik Tejaswi Madhusudhan"
    ],
    "abstract": "Direct Preference Optimization (DPO) is an effective technique that leverages\npairwise preference data (usually one chosen and rejected response pair per\nuser prompt) to align LLMs to human preferences. In practice, multiple\nresponses can exist for a given prompt with varying quality relative to each\nother. With availability of such quality ratings for multiple responses, we\npropose utilizing these responses to create multiple preference pairs for a\ngiven prompt. Our work focuses on systematically using the constructed multiple\npreference pair in DPO training via curriculum learning methodology. In\nparticular, we order these multiple pairs of preference data from easy to hard\n(emulating curriculum training) according to various criteria. We show detailed\ncomparisons of our proposed approach to the standard single-pair DPO setting.\nOur method, which we call Curry-DPO consistently shows increased performance\ngains on MTbench, Vicuna, WizardLM, and the UltraFeedback test set,\nhighlighting its effectiveness. More specifically, Curry-DPO achieves a score\nof 7.43 on MT-bench with Zephy-7B model outperforming majority of existing LLMs\nwith similar parameter size. Curry-DPO also achieves the highest adjusted win\nrates on Vicuna, WizardLM, and UltraFeedback test datasets (90.7%, 87.1%, and\n87.9% respectively) in our experiments, with notable gains of upto 7.5% when\ncompared to standard DPO technique. We release the preference pairs used in\nalignment at:\nhttps://huggingface.co/datasets/ServiceNow-AI/Curriculum_DPO_preferences",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Published at EMNLP 2024 as long (findings) conference paper",
    "pdf_url": "http://arxiv.org/pdf/2403.07230v2",
    "published_date": "2024-03-12 00:58:19 UTC",
    "updated_date": "2024-11-08 08:55:00 UTC"
  }
]