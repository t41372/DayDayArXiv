{
  "date": "2024-08-08",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-08-08 的 arXiv 中文 TLDR 快报！今天的论文主要聚焦 AI 安全、LLM 应用、多模态模型和医疗创新等领域，亮点包括 LLM 在医疗问答的性能提升，以及 AI 伦理风险（如选举中的潜在问题）和高效工具使用方法的讨论，值得注意的是如 Anna Vaughan 等作者在 AI 监测环境污染方面的实用贡献。\n\n下面，我挑选并简要概述几篇重要的、印象深刻的论文，先从 AI 安全和 LLM 相关主题入手，这些文章有较高话题度和潜在影响；接着快速聊聊医疗应用领域的创新；其他论文如数据分析或算法优化等，若非核心，将简略掠过。每篇只列出标题（中文 + 英文）和主要贡献。\n\n### AI 安全和 LLM 相关\n- **AI 意识与公众认知：四种未来 (AI Consciousness and Public Perceptions: Four Futures)**  \n  作者包括 Ines Fernandez 和 Jay Luong。这篇论文探讨未来 AI 系统是否会具备意识，以及公众对 AI 意识的认知可能带来的风险（如 AI 痛苦和地缘政治不稳定）。主要贡献：提出四种场景框架（真阳性、真阴性等），并建议避免故意创建意识 AI，转而减少不确定性，强调 AI 伦理的紧迫性。\n\n- **AI 炒作的起源与风险 (Misrepresented Technological Solutions in Imagined Futures: The Origins and Dangers of AI Hype in the Research Community)**  \n  作者 Savannah Thais。论文分析 AI 炒作如何影响研究社区和政策。关键发现：AI 过度宣传可能导致有害技术部署和政策失误，贡献包括提出研究者减少炒作的措施，如更准确的宣传策略。\n\n- **LLM 在选举中的欺骗性应用 (Deceptive uses of Artificial Intelligence in elections strengthen support for AI ban)**  \n  作者 Andreas Jungherr 和 Alexander Wuttke。研究显示，AI 在选举中的欺骗性使用（如虚假信息）会增加公众对 AI 禁令的支持。贡献：通过实验揭示 AI 欺骗的负面影响，并呼吁监管，强调 AI 在社会中的伦理风险。\n\n- **细粒度引用学习以提升 LLM 的归因 (Learning Fine-Grained Grounded Citations for Attributed Large Language Models)**  \n  作者 Lei Huang 和 Bing Qin。论文针对 LLM 的幻觉问题，提出 FRONT 框架，用于生成更精确的引用。发现：使用细粒度引用可显著提高响应准确性，在 ALCE 基准上提升 14.21%。\n\n- **LLM 工具使用基准 (ToolSandbox: A Stateful, Conversational, Interactive Evaluation Benchmark for LLM Tool Use Capabilities)**  \n  作者 Jiarui Lu 和 Ruoming Pang。论文构建了一个动态基准测试 LLM 工具使用能力。贡献：评估 LLM 在状态依赖任务中的性能，发现现有模型在复杂交互中表现不佳，提供了一个全面评估框架。\n\n### 医疗和应用创新\n- **多模态 AI 在乳腺癌 MRI 中的个性化管理 (A Large Model for Non-invasive and Personalized Management of Breast Cancer from Multiparametric MRI)**  \n  作者 Hao Chen 和 Pranav Rajpurkar。论文提出 MOME 模型，用于从多参数 MRI 中预测乳腺癌。发现：模型在检测和预测方面匹配资深放射科医生水平，能减少不必要活检，并处理缺失模态数据。\n\n- **AI 在肺部疾病预测中的卷积神经网络 (Convolutional Neural Networks for Predictive Modeling of Lung Disease)**  \n  作者 Yuanfang Yang。论文使用 Pro-HRnet-CNN 模型预测肺部疾病。贡献：改进了小结节检测准确性，在 LIDC-IDRI 数据集上优于 ResNet-50，提升了早诊潜力。\n\n- **LLM 在医疗问答中的增强 (Enhancing Healthcare through Large Language Models: A Study on Medical Question Answering)**  \n  作者 Haoran Yu 和 Hao Qin。论文测试 LLM 在医疗问答中的表现。发现：Sentence-t5 + Mistral 7B 模型精度达 0.762，提升患者教育，但强调模型鲁棒性的必要性。\n\n### 其他快速掠过\n其他论文如 **动态图神经网络在犯罪预测中的不确定性建模 (Embodied Uncertainty-Aware Object Segmentation)**（作者 Tomás Lozano-Pérez，贡献：改进机器人感知鲁棒性）、**Transformer 在模态转换中的综述 (Survey: Transformer-based Models in Data Modality Conversion)**（作者 Elyas Rashno，贡献：系统回顾 Transformer 在文本、视觉和语音转换的应用），以及一些算法优化（如 Adaboost 改进或联邦学习方法）虽有技术创新，但影响力较小，仅快速提及：这些工作优化了模型效率，如在边缘计算或异常检测中减少计算开销，但细节较常规。\n\n总之，今天的论文突显 AI 在实际应用中的潜力与挑战，建议关注 LLM 安全和医疗领域的进展，以推动更负责任的 AI 发展。更多细节可查阅 arXiv！",
  "papers": [
    {
      "arxiv_id": "2408.15245v1",
      "title": "An Edge AI System Based on FPGA Platform for Railway Fault Detection",
      "title_zh": "基于 FPGA 平台的铁路故障检测边缘 AI 系统",
      "authors": [
        "Jiale Li",
        "Yulin Fu",
        "Dongwei Yan",
        "Sean Longyu Ma",
        "Chiu-Wing Sham"
      ],
      "abstract": "As the demands for railway transportation safety increase, traditional\nmethods of rail track inspection no longer meet the needs of modern railway\nsystems. To address the issues of automation and efficiency in rail fault\ndetection, this study introduces a railway inspection system based on Field\nProgrammable Gate Array (FPGA). This edge AI system collects track images via\ncameras and uses Convolutional Neural Networks (CNN) to perform real-time\ndetection of track defects and automatically reports fault information. The\ninnovation of this system lies in its high level of automation and detection\nefficiency. The neural network approach employed by this system achieves a\ndetection accuracy of 88.9%, significantly enhancing the reliability and\nefficiency of detection. Experimental results demonstrate that this FPGA-based\nsystem is 1.39* and 4.67* better in energy efficiency than peer implementation\non the GPU and CPU platform, respectively.",
      "tldr_zh": "本研究提出了一种基于FPGA平台的边缘AI系统，用于铁路故障检测，以解决传统轨道检查方法的自动化和效率问题。该系统通过摄像头采集轨道图像，并采用卷积神经网络(CNN)进行实时缺陷检测和故障信息自动报告。创新点在于其高自动化水平和检测效率，实现了88.9%的检测准确率，并在能效方面比GPU平台高1.39倍、比CPU平台高4.67倍。实验结果验证了该系统的可靠性和实际应用潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at the 2024 IEEE 13th Global Conference on Consumer\n  Electronics (GCCE 2024)",
      "pdf_url": "http://arxiv.org/pdf/2408.15245v1",
      "published_date": "2024-08-08 22:44:30 UTC",
      "updated_date": "2024-08-08 22:44:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:43:22.408893"
    },
    {
      "arxiv_id": "2408.04771v1",
      "title": "AI Consciousness and Public Perceptions: Four Futures",
      "title_zh": "AI 意识与公众认知：四个未来",
      "authors": [
        "Ines Fernandez",
        "Nicoleta Kyosovska",
        "Jay Luong",
        "Gabriel Mukobi"
      ],
      "abstract": "The discourse on risks from advanced AI systems (\"AIs\") typically focuses on\nmisuse, accidents and loss of control, but the question of AIs' moral status\ncould have negative impacts which are of comparable significance and could be\nrealised within similar timeframes. Our paper evaluates these impacts by\ninvestigating (1) the factual question of whether future advanced AI systems\nwill be conscious, together with (2) the epistemic question of whether future\nhuman society will broadly believe advanced AI systems to be conscious.\nAssuming binary responses to (1) and (2) gives rise to four possibilities: in\nthe true positive scenario, society predominantly correctly believes that AIs\nare conscious; in the false positive scenario, that belief is incorrect; in the\ntrue negative scenario, society correctly believes that AIs are not conscious;\nand lastly, in the false negative scenario, society incorrectly believes that\nAIs are not conscious. The paper offers vivid vignettes of the different\nfutures to ground the two-dimensional framework. Critically, we identify four\nmajor risks: AI suffering, human disempowerment, geopolitical instability, and\nhuman depravity. We evaluate each risk across the different scenarios and\nprovide an overall qualitative risk assessment for each scenario. Our analysis\nsuggests that the worst possibility is the wrong belief that AI is\nnon-conscious, followed by the wrong belief that AI is conscious. The paper\nconcludes with the main recommendations to avoid research aimed at\nintentionally creating conscious AI and instead focus efforts on reducing our\ncurrent uncertainties on both the factual and epistemic questions on AI\nconsciousness.",
      "tldr_zh": "这篇论文探讨了高级 AI 系统（AIs）的意识问题及其对公众感知的影响，提出一个二维框架：（1）AI 是否真正有意识（factual question），以及（2）社会是否相信 AI 有意识（epistemic question），从而定义了四种可能场景，包括 true positive、false positive、true negative 和 false negative。论文通过生动描述（vivid vignettes）分析每个场景下的风险，如 AI suffering（AI 痛苦）、human disempowerment（人类被剥夺权力）、geopolitical instability（地缘政治不稳定）和 human depravity（人类堕落）。总体评估显示，最严重的风险出现在错误地认为 AI 没有意识的场景，其次是错误地认为 AI 有意识；论文推荐避免有意创建 conscious AI，而是专注于减少对 AI 意识的 factual 和 epistemic 不确定性。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.04771v1",
      "published_date": "2024-08-08 22:01:57 UTC",
      "updated_date": "2024-08-08 22:01:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:43:32.330933"
    },
    {
      "arxiv_id": "2408.04767v1",
      "title": "Data-Driven Pixel Control: Challenges and Prospects",
      "title_zh": "数据驱动的像素控制：挑战与前景",
      "authors": [
        "Saurabh Farkya",
        "Zachary Alan Daniels",
        "Aswin Raghavan",
        "Gooitzen van der Wal",
        "Michael Isnardi",
        "Michael Piacentino",
        "David Zhang"
      ],
      "abstract": "Recent advancements in sensors have led to high resolution and high data\nthroughput at the pixel level. Simultaneously, the adoption of increasingly\nlarge (deep) neural networks (NNs) has lead to significant progress in computer\nvision. Currently, visual intelligence comes at increasingly high computational\ncomplexity, energy, and latency. We study a data-driven system that combines\ndynamic sensing at the pixel level with computer vision analytics at the video\nlevel and propose a feedback control loop to minimize data movement between the\nsensor front-end and computational back-end without compromising detection and\ntracking precision. Our contributions are threefold: (1) We introduce\nanticipatory attention and show that it leads to high precision prediction with\nsparse activation of pixels; (2) Leveraging the feedback control, we show that\nthe dimensionality of learned feature vectors can be significantly reduced with\nincreased sparsity; and (3) We emulate analog design choices (such as varying\nRGB or Bayer pixel format and analog noise) and study their impact on the key\nmetrics of the data-driven system. Comparative analysis with traditional pixel\nand deep learning models shows significant performance enhancements. Our system\nachieves a 10X reduction in bandwidth and a 15-30X improvement in Energy-Delay\nProduct (EDP) when activating only 30% of pixels, with a minor reduction in\nobject detection and tracking precision. Based on analog emulation, our system\ncan achieve a throughput of 205 megapixels/sec (MP/s) with a power consumption\nof only 110 mW per MP, i.e., a theoretical improvement of ~30X in EDP.",
      "tldr_zh": "该论文探讨了传感器高分辨率与神经网络（NNs）计算复杂性带来的挑战，提出了一种数据驱动系统，通过反馈控制循环（feedback control loop）结合像素级动态传感和视频级计算机视觉分析，来最小化数据传输并维持检测和跟踪精度。关键贡献包括：引入预见性注意力（anticipatory attention）以实现高精度预测和像素稀疏激活、显著减少特征向量维度和增加稀疏性，以及模拟模拟设计选择（如RGB或Bayer像素格式和模拟噪声）对其影响的分析。与传统模型相比，该系统在激活仅30%像素时，实现10X带宽减少和15-30X能量延迟乘积（EDP）改善，同时仅轻微降低物体检测和跟踪精度。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to the Conference on Dynamic Data-Driven Applications\n  Systems (DDDAS2024)",
      "pdf_url": "http://arxiv.org/pdf/2408.04767v1",
      "published_date": "2024-08-08 21:49:19 UTC",
      "updated_date": "2024-08-08 21:49:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:43:55.641765"
    },
    {
      "arxiv_id": "2408.05253v1",
      "title": "A Systematic Literature Map on Big Data",
      "title_zh": "翻译失败",
      "authors": [
        "Rogerio Rossi",
        "Kechi Hirama",
        "Eduardo Ferreira Franco"
      ],
      "abstract": "The paradigm of Big Data has been established as a solid field of studies in\nmany areas such as healthcare, science, transport, education, government\nservices, among others. Despite widely discussed, there is no agreed definition\nabout the paradigm although there are many concepts proposed by the academy and\nindustry. This work aims to provide an analytical view of the studies conducted\nand published regarding the Big Data paradigm. The approach used is the\nsystematic map of the literature, combining bibliometric analysis and content\nanalysis to depict the panorama of research works, identifying patterns,\ntrends, and gaps. The results indicate that there is still a long way to go,\nboth in research and in concepts, such as building and defining adequate\ninfrastructures and standards, to meet future challenges and for the paradigm\nto become effective and bring the expected benefits.",
      "tldr_zh": "本研究针对 Big Data 范式进行了系统文献映射（systematic map of the literature），旨在分析其在医疗、科技、交通、教育和政府服务等领域的现状和研究趋势。论文结合 bibliometric analysis 和 content analysis 方法，审视了现有研究，识别了模式、趋势和知识空白。尽管 Big Data 已广泛讨论，但定义仍不统一，结果显示在构建适当的基础设施和标准方面仍有很大差距，以应对未来挑战并实现预期益处。",
      "categories": [
        "cs.DL",
        "cs.AI",
        "cs.ET",
        "H.0"
      ],
      "primary_category": "cs.DL",
      "comment": "8 pages, 1 figure, 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2408.05253v1",
      "published_date": "2024-08-08 21:41:44 UTC",
      "updated_date": "2024-08-08 21:41:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:43:54.732598"
    },
    {
      "arxiv_id": "2408.04760v1",
      "title": "Embodied Uncertainty-Aware Object Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaolin Fang",
        "Leslie Pack Kaelbling",
        "Tomás Lozano-Pérez"
      ],
      "abstract": "We introduce uncertainty-aware object instance segmentation (UncOS) and\ndemonstrate its usefulness for embodied interactive segmentation. To deal with\nuncertainty in robot perception, we propose a method for generating a\nhypothesis distribution of object segmentation. We obtain a set of\nregion-factored segmentation hypotheses together with confidence estimates by\nmaking multiple queries of large pre-trained models. This process can produce\nsegmentation results that achieve state-of-the-art performance on unseen object\nsegmentation problems. The output can also serve as input to a belief-driven\nprocess for selecting robot actions to perturb the scene to reduce ambiguity.\nWe demonstrate the effectiveness of this method in real-robot experiments.\nWebsite: https://sites.google.com/view/embodied-uncertain-seg",
      "tldr_zh": "该论文引入了 uncertainty-aware object instance segmentation (UncOS) 方法，用于 embodied interactive segmentation，以处理机器人感知中的不确定性。通过多次查询大型预训练模型，该方法生成一组 region-factored segmentation hypotheses 以及置信度估计(confidence estimates)，从而实现对未见对象分割问题的 state-of-the-art 性能。实验结果显示，该输出可作为 belief-driven 过程的输入，帮助机器人选择动作扰动场景以减少歧义，并在真实机器人实验中证明了其有效性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "IROS 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.04760v1",
      "published_date": "2024-08-08 21:29:22 UTC",
      "updated_date": "2024-08-08 21:29:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:44:06.654386"
    },
    {
      "arxiv_id": "2408.15244v1",
      "title": "Misrepresented Technological Solutions in Imagined Futures: The Origins and Dangers of AI Hype in the Research Community",
      "title_zh": "翻译失败",
      "authors": [
        "Savannah Thais"
      ],
      "abstract": "Technology does not exist in a vacuum; technological development, media\nrepresentation, public perception, and governmental regulation cyclically\ninfluence each other to produce the collective understanding of a technology's\ncapabilities, utilities, and risks. When these capabilities are overestimated,\nthere is an enhanced risk of subjecting the public to dangerous or harmful\ntechnology, artificially restricting research and development directions, and\nenabling misguided or detrimental policy. The dangers of technological hype are\nparticularly relevant in the rapidly evolving space of AI. Centering the\nresearch community as a key player in the development and proliferation of\nhype, we examine the origins and risks of AI hype to the research community and\nsociety more broadly and propose a set of measures that researchers,\nregulators, and the public can take to mitigate these risks and reduce the\nprevalence of unfounded claims about the technology.",
      "tldr_zh": "这篇论文探讨了技术炒作（AI hype）在研究社区中的起源和潜在危险，强调技术能力被高估可能导致公众暴露于有害技术、扭曲研究方向以及制定错误政策。作者分析了技术发展、媒体表示、公众认知和政府监管之间的循环影响，特别是AI领域的快速演变。论文提出具体措施，包括研究者、监管者和公众共同努力，来缓解这些风险并减少对AI的不实声明。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "Accepted to AIES 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.15244v1",
      "published_date": "2024-08-08 20:47:17 UTC",
      "updated_date": "2024-08-08 20:47:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:44:19.781809"
    },
    {
      "arxiv_id": "2408.04746v1",
      "title": "More Questions than Answers? Lessons from Integrating Explainable AI into a Cyber-AI Tool",
      "title_zh": "问题多于答案？ 将可解释AI整合到Cyber-AI工具中的经验教训",
      "authors": [
        "Ashley Suh",
        "Harry Li",
        "Caitlin Kenney",
        "Kenneth Alperin",
        "Steven R. Gomez"
      ],
      "abstract": "We share observations and challenges from an ongoing effort to implement\nExplainable AI (XAI) in a domain-specific workflow for cybersecurity analysts.\nSpecifically, we briefly describe a preliminary case study on the use of XAI\nfor source code classification, where accurate assessment and timeliness are\nparamount. We find that the outputs of state-of-the-art saliency explanation\ntechniques (e.g., SHAP or LIME) are lost in translation when interpreted by\npeople with little AI expertise, despite these techniques being marketed for\nnon-technical users. Moreover, we find that popular XAI techniques offer fewer\ninsights for real-time human-AI workflows when they are post hoc and too\nlocalized in their explanations. Instead, we observe that cyber analysts need\nhigher-level, easy-to-digest explanations that can offer as little disruption\nas possible to their workflows. We outline unaddressed gaps in practical and\neffective XAI, then touch on how emerging technologies like Large Language\nModels (LLMs) could mitigate these existing obstacles.",
      "tldr_zh": "这篇论文分享了将可解释 AI (XAI) 整合到网络安全工具中的观察和挑战，通过一个源代码分类的初步案例研究，探讨了 XAI 在实际应用中的局限性。研究发现，SHAP 和 LIME 等先进显著性解释技术在非 AI 专家解读时信息丢失，且这些事后 (post hoc) 和过于局部的解释不适合实时人-AI 工作流。网络分析师更需要高级别、易于消化的解释，以最小化对工作流程的干扰。论文概述了 XAI 在实际有效性方面的未解决差距，并建议新兴技术如 Large Language Models (LLMs) 可能缓解这些障碍。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "ACM CHI 2024 Workshop on Human-Centered Explainable AI (HCXAI)",
      "pdf_url": "http://arxiv.org/pdf/2408.04746v1",
      "published_date": "2024-08-08 20:09:31 UTC",
      "updated_date": "2024-08-08 20:09:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:44:33.156898"
    },
    {
      "arxiv_id": "2408.04745v1",
      "title": "AI for operational methane emitter monitoring from space",
      "title_zh": "翻译失败",
      "authors": [
        "Anna Vaughan",
        "Gonzalo Mateo-Garcia",
        "Itziar Irakulis-Loitxate",
        "Marc Watine",
        "Pablo Fernandez-Poblaciones",
        "Richard E. Turner",
        "James Requeima",
        "Javier Gorroño",
        "Cynthia Randles",
        "Manfredi Caltagirone",
        "Claudio Cifarelli"
      ],
      "abstract": "Mitigating methane emissions is the fastest way to stop global warming in the\nshort-term and buy humanity time to decarbonise. Despite the demonstrated\nability of remote sensing instruments to detect methane plumes, no system has\nbeen available to routinely monitor and act on these events. We present\nMARS-S2L, an automated AI-driven methane emitter monitoring system for\nSentinel-2 and Landsat satellite imagery deployed operationally at the United\nNations Environment Programme's International Methane Emissions Observatory. We\ncompile a global dataset of thousands of super-emission events for training and\nevaluation, demonstrating that MARS-S2L can skillfully monitor emissions in a\ndiverse range of regions globally, providing a 216% improvement in mean average\nprecision over a current state-of-the-art detection method. Running this system\noperationally for six months has yielded 457 near-real-time detections in 22\ndifferent countries of which 62 have already been used to provide formal\nnotifications to governments and stakeholders.",
      "tldr_zh": "该研究提出MARS-S2L，一种自动化AI驱动系统，用于从Sentinel-2和Landsat卫星图像中监测甲烷排放源，以加速全球变暖缓解。系统通过编译一个全球数据集（包含数千个超排放事件）进行训练和评估，实现对全球不同地区的精准监测，并比现有最先进方法提高了216%的mean average precision。运行六个月后，MARS-S2L已检测到457个近实时事件，并在22个国家中，62个事件用于向政府和利益相关者发送正式通知，为实际减排行动提供了关键支持。",
      "categories": [
        "cs.AI",
        "physics.ao-ph"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.04745v1",
      "published_date": "2024-08-08 20:06:37 UTC",
      "updated_date": "2024-08-08 20:06:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:44:43.416942"
    },
    {
      "arxiv_id": "2408.04723v1",
      "title": "Survey: Transformer-based Models in Data Modality Conversion",
      "title_zh": "翻译失败",
      "authors": [
        "Elyas Rashno",
        "Amir Eskandari",
        "Aman Anand",
        "Farhana Zulkernine"
      ],
      "abstract": "Transformers have made significant strides across various artificial\nintelligence domains, including natural language processing, computer vision,\nand audio processing. This success has naturally garnered considerable interest\nfrom both academic and industry researchers. Consequently, numerous Transformer\nvariants (often referred to as X-formers) have been developed for these fields.\nHowever, a thorough and systematic review of these modality-specific\nconversions remains lacking. Modality Conversion involves the transformation of\ndata from one form of representation to another, mimicking the way humans\nintegrate and interpret sensory information. This paper provides a\ncomprehensive review of transformer-based models applied to the primary\nmodalities of text, vision, and speech, discussing their architectures,\nconversion methodologies, and applications. By synthesizing the literature on\nmodality conversion, this survey aims to underline the versatility and\nscalability of transformers in advancing AI-driven content generation and\nunderstanding.",
      "tldr_zh": "这篇论文对Transformer-based Models在数据模态转换（Modality Conversion）中的应用进行了全面综述，聚焦于Transformer在自然语言处理（NLP）、计算机视觉和音频处理领域的成功及其变体（X-formers）。论文系统地审视了这些模型的架构、转换方法和实际应用，包括将文本、视觉和语音等模态数据进行转换的过程，以模拟人类感官信息整合。最终，该综述强调了Transformer的多功能性和可扩展性，在推动AI驱动的内容生成和理解方面具有重要潜力。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CL",
        "eess.SP"
      ],
      "primary_category": "eess.IV",
      "comment": "Submitted to ACM Computing Surveys (CSUR)",
      "pdf_url": "http://arxiv.org/pdf/2408.04723v1",
      "published_date": "2024-08-08 18:39:14 UTC",
      "updated_date": "2024-08-08 18:39:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:44:55.688604"
    },
    {
      "arxiv_id": "2408.04713v3",
      "title": "DyGMamba: Efficiently Modeling Long-Term Temporal Dependency on Continuous-Time Dynamic Graphs with State Space Models",
      "title_zh": "DyGMamba：利用状态空间模型高效建模连续时间动态图的长期时间依赖",
      "authors": [
        "Zifeng Ding",
        "Yifeng Li",
        "Yuan He",
        "Antonio Norelli",
        "Jingcheng Wu",
        "Volker Tresp",
        "Yunpu Ma",
        "Michael Bronstein"
      ],
      "abstract": "Learning useful representations for continuous-time dynamic graphs (CTDGs) is\nchallenging, due to the concurrent need to span long node interaction histories\nand grasp nuanced temporal details. In particular, two problems emerge: (1)\nEncoding longer histories requires more computational resources, making it\ncrucial for CTDG models to maintain low computational complexity to ensure\nefficiency; (2) Meanwhile, more powerful models are needed to identify and\nselect the most critical temporal information within the extended context\nprovided by longer histories. To address these problems, we propose a CTDG\nrepresentation learning model named DyGMamba, originating from the popular\nMamba state space model (SSM). DyGMamba first leverages a node-level SSM to\nencode the sequence of historical node interactions. Another time-level SSM is\nthen employed to exploit the temporal patterns hidden in the historical graph,\nwhere its output is used to dynamically select the critical information from\nthe interaction history. We validate DyGMamba experimentally on the dynamic\nlink prediction task. The results show that our model achieves state-of-the-art\nin most cases. DyGMamba also maintains high efficiency in terms of\ncomputational resources, making it possible to capture long temporal\ndependencies with a limited computation budget.",
      "tldr_zh": "该研究针对连续时间动态图(CTDGs)表示学习面临的挑战，提出了一种高效模型DyGMamba，以解决编码长节点交互历史所需的高计算资源和关键信息选择的难题。DyGMamba基于Mamba状态空间模型(SSM)，首先使用node-level SSM编码历史节点交互序列，然后通过time-level SSM挖掘隐藏的时间模式，并动态选取最关键的信息。实验结果显示，该模型在动态链接预测任务上达到最先进水平，同时在计算资源方面保持高效，能够在有限预算下捕捉长期时间依赖。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Preprint",
      "pdf_url": "http://arxiv.org/pdf/2408.04713v3",
      "published_date": "2024-08-08 18:25:14 UTC",
      "updated_date": "2025-02-03 10:40:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:45:08.446388"
    },
    {
      "arxiv_id": "2408.04708v1",
      "title": "MulliVC: Multi-lingual Voice Conversion With Cycle Consistency",
      "title_zh": "翻译失败",
      "authors": [
        "Jiawei Huang",
        "Chen Zhang",
        "Yi Ren",
        "Ziyue Jiang",
        "Zhenhui Ye",
        "Jinglin Liu",
        "Jinzheng He",
        "Xiang Yin",
        "Zhou Zhao"
      ],
      "abstract": "Voice conversion aims to modify the source speaker's voice to resemble the\ntarget speaker while preserving the original speech content. Despite notable\nadvancements in voice conversion these days, multi-lingual voice conversion\n(including both monolingual and cross-lingual scenarios) has yet to be\nextensively studied. It faces two main challenges: 1) the considerable\nvariability in prosody and articulation habits across languages; and 2) the\nrarity of paired multi-lingual datasets from the same speaker. In this paper,\nwe propose MulliVC, a novel voice conversion system that only converts timbre\nand keeps original content and source language prosody without multi-lingual\npaired data. Specifically, each training step of MulliVC contains three\nsubsteps: In step one the model is trained with monolingual speech data; then,\nsteps two and three take inspiration from back translation, construct a\ncyclical process to disentangle the timbre and other information (content,\nprosody, and other language-related information) in the absence of\nmulti-lingual data from the same speaker. Both objective and subjective results\nindicate that MulliVC significantly surpasses other methods in both monolingual\nand cross-lingual contexts, demonstrating the system's efficacy and the\nviability of the three-step approach with cycle consistency. Audio samples can\nbe found on our demo page (mullivc.github.io).",
      "tldr_zh": "该论文提出MulliVC，一种基于循环一致性(Cycle Consistency)的多语言语音转换(Voice Conversion)系统，旨在将源说话者的音色转换为目标说话者，同时保留原内容和源语言的韵律，而无需依赖多语言配对数据集。系统通过一个三步训练过程实现：首先使用单语言语音数据训练模型，然后采用受回译启发的循环过程来分离音色与其他信息（如内容、韵律和语言相关元素）。实验结果显示，MulliVC在单语和跨语境中均显著优于其他方法，在客观和主观评估中证明了其有效性。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.04708v1",
      "published_date": "2024-08-08 18:12:51 UTC",
      "updated_date": "2024-08-08 18:12:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:45:22.839273"
    },
    {
      "arxiv_id": "2408.04631v1",
      "title": "Puppet-Master: Scaling Interactive Video Generation as a Motion Prior for Part-Level Dynamics",
      "title_zh": "Puppet-Master：将交互式视频生成扩展为部件级动态的运动先验",
      "authors": [
        "Ruining Li",
        "Chuanxia Zheng",
        "Christian Rupprecht",
        "Andrea Vedaldi"
      ],
      "abstract": "We present Puppet-Master, an interactive video generative model that can\nserve as a motion prior for part-level dynamics. At test time, given a single\nimage and a sparse set of motion trajectories (i.e., drags), Puppet-Master can\nsynthesize a video depicting realistic part-level motion faithful to the given\ndrag interactions. This is achieved by fine-tuning a large-scale pre-trained\nvideo diffusion model, for which we propose a new conditioning architecture to\ninject the dragging control effectively. More importantly, we introduce the\nall-to-first attention mechanism, a drop-in replacement for the widely adopted\nspatial attention modules, which significantly improves generation quality by\naddressing the appearance and background issues in existing models. Unlike\nother motion-conditioned video generators that are trained on in-the-wild\nvideos and mostly move an entire object, Puppet-Master is learned from\nObjaverse-Animation-HQ, a new dataset of curated part-level motion clips. We\npropose a strategy to automatically filter out sub-optimal animations and\naugment the synthetic renderings with meaningful motion trajectories.\nPuppet-Master generalizes well to real images across various categories and\noutperforms existing methods in a zero-shot manner on a real-world benchmark.\nSee our project page for more results: vgg-puppetmaster.github.io.",
      "tldr_zh": "我们提出 Puppet-Master，一种交互式视频生成模型，作为部分级动态的运动先验，能够基于单张图像和稀疏拖拽轨迹合成真实且忠实的运动视频。该模型通过微调预训练视频扩散模型并引入 all-to-first attention 机制来有效注入控制信号，并解决现有模型的外观和背景问题。不同于其他方法，Puppet-Master 使用新数据集 Objaverse-Animation-HQ 进行训练，并在零样本设置下在真实世界基准上泛化良好并优于现有技术。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Project page: https://vgg-puppetmaster.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2408.04631v1",
      "published_date": "2024-08-08 17:59:38 UTC",
      "updated_date": "2024-08-08 17:59:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:45:33.970848"
    },
    {
      "arxiv_id": "2408.04628v1",
      "title": "LogogramNLP: Comparing Visual and Textual Representations of Ancient Logographic Writing Systems for NLP",
      "title_zh": "翻译失败",
      "authors": [
        "Danlu Chen",
        "Freda Shi",
        "Aditi Agarwal",
        "Jacobo Myerston",
        "Taylor Berg-Kirkpatrick"
      ],
      "abstract": "Standard natural language processing (NLP) pipelines operate on symbolic\nrepresentations of language, which typically consist of sequences of discrete\ntokens. However, creating an analogous representation for ancient logographic\nwriting systems is an extremely labor intensive process that requires expert\nknowledge. At present, a large portion of logographic data persists in a purely\nvisual form due to the absence of transcription -- this issue poses a\nbottleneck for researchers seeking to apply NLP toolkits to study ancient\nlogographic languages: most of the relevant data are images of writing.\n  This paper investigates whether direct processing of visual representations\nof language offers a potential solution. We introduce LogogramNLP, the first\nbenchmark enabling NLP analysis of ancient logographic languages, featuring\nboth transcribed and visual datasets for four writing systems along with\nannotations for tasks like classification, translation, and parsing. Our\nexperiments compare systems that employ recent visual and text encoding\nstrategies as backbones. The results demonstrate that visual representations\noutperform textual representations for some investigated tasks, suggesting that\nvisual processing pipelines may unlock a large amount of cultural heritage data\nof logographic languages for NLP-based analyses.",
      "tldr_zh": "本论文探讨了如何处理古象形文字系统（logographic writing systems）的视觉表示，以解决标准NLP管道依赖符号化文本的局限性，该过程通常需要耗费大量专家知识。研究引入了LogogramNLP基准，这是首个针对古象形文字的NLP分析基准，包含四个书写系统的转录和视觉数据集，并标注了分类、翻译和解析等任务。实验比较了基于最新视觉和文本编码策略的系统，结果显示在某些任务中，视觉表示优于文本表示。总之，这一发现表明，视觉处理管道可能为NLP分析海量古象形文字文化遗产数据提供新途径。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.04628v1",
      "published_date": "2024-08-08 17:58:06 UTC",
      "updated_date": "2024-08-08 17:58:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:45:45.024729"
    },
    {
      "arxiv_id": "2408.04619v1",
      "title": "Transformer Explainer: Interactive Learning of Text-Generative Models",
      "title_zh": "翻译失败",
      "authors": [
        "Aeree Cho",
        "Grace C. Kim",
        "Alexander Karpekov",
        "Alec Helbling",
        "Zijie J. Wang",
        "Seongmin Lee",
        "Benjamin Hoover",
        "Duen Horng Chau"
      ],
      "abstract": "Transformers have revolutionized machine learning, yet their inner workings\nremain opaque to many. We present Transformer Explainer, an interactive\nvisualization tool designed for non-experts to learn about Transformers through\nthe GPT-2 model. Our tool helps users understand complex Transformer concepts\nby integrating a model overview and enabling smooth transitions across\nabstraction levels of mathematical operations and model structures. It runs a\nlive GPT-2 instance locally in the user's browser, empowering users to\nexperiment with their own input and observe in real-time how the internal\ncomponents and parameters of the Transformer work together to predict the next\ntokens. Our tool requires no installation or special hardware, broadening the\npublic's education access to modern generative AI techniques. Our open-sourced\ntool is available at https://poloclub.github.io/transformer-explainer/. A video\ndemo is available at https://youtu.be/ECR4oAwocjs.",
      "tldr_zh": "该论文介绍了 Transformer Explainer，一种交互式可视化工具，旨在帮助非专家用户理解 Transformers 模型（如 GPT-2）的内部机制。工具整合了模型概述和不同抽象级别的数学操作过渡，用户可在浏览器中运行实时 GPT-2 实例，输入自定义文本并实时观察组件和参数如何协作生成下一 tokens。无需安装或特殊硬件，该开源工具拓宽了公众对生成式 AI 技术的教育访问，可通过指定链接获取。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.HC"
      ],
      "primary_category": "cs.LG",
      "comment": "To be presented at IEEE VIS 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.04619v1",
      "published_date": "2024-08-08 17:49:07 UTC",
      "updated_date": "2024-08-08 17:49:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:45:56.400197"
    },
    {
      "arxiv_id": "2408.04614v2",
      "title": "Better Alignment with Instruction Back-and-Forth Translation",
      "title_zh": "翻译失败",
      "authors": [
        "Thao Nguyen",
        "Jeffrey Li",
        "Sewoong Oh",
        "Ludwig Schmidt",
        "Jason Weston",
        "Luke Zettlemoyer",
        "Xian Li"
      ],
      "abstract": "We propose a new method, instruction back-and-forth translation, to construct\nhigh-quality synthetic data grounded in world knowledge for aligning large\nlanguage models (LLMs). Given documents from a web corpus, we generate and\ncurate synthetic instructions using the backtranslation approach proposed by Li\net al.(2023a), and rewrite the responses to improve their quality further based\non the initial documents. Fine-tuning with the resulting (backtranslated\ninstruction, rewritten response) pairs yields higher win rates on AlpacaEval\nthan using other common instruction datasets such as Humpback, ShareGPT, Open\nOrca, Alpaca-GPT4 and Self-instruct. We also demonstrate that rewriting the\nresponses with an LLM outperforms direct distillation, and the two generated\ntext distributions exhibit significant distinction in embedding space. Further\nanalysis shows that our backtranslated instructions are of higher quality than\nother sources of synthetic instructions, while our responses are more diverse\nand complex than those obtained from distillation. Overall we find that\ninstruction back-and-forth translation combines the best of both worlds --\nmaking use of the information diversity and quantity found on the web, while\nensuring the quality of the responses which is necessary for effective\nalignment.",
      "tldr_zh": "该论文提出了一种名为 instruction back-and-forth translation 的新方法，用于构建高质量的合成数据，以对齐 large language models (LLMs)。该方法从网络语料库中提取文档，通过 backtranslation 技术生成并整理合成指令，然后基于原始文档重写响应以提升质量。实验结果显示，使用生成的 (backtranslated instruction, rewritten response) 对进行微调，在 AlpacaEval 基准测试中比 Humpback、ShareGPT 等常见数据集获得更高的胜率；此外，重写响应优于直接 distillation，生成的文本在嵌入空间更具多样性和复杂性。总体上，这种方法结合了网络信息的多样性与响应的高质量，有效提升了模型对齐性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.04614v2",
      "published_date": "2024-08-08 17:42:32 UTC",
      "updated_date": "2024-08-13 18:00:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:46:10.490860"
    },
    {
      "arxiv_id": "2408.04595v1",
      "title": "Inference with the Upper Confidence Bound Algorithm",
      "title_zh": "翻译失败",
      "authors": [
        "Koulik Khamaru",
        "Cun-Hui Zhang"
      ],
      "abstract": "In this paper, we discuss the asymptotic behavior of the Upper Confidence\nBound (UCB) algorithm in the context of multiarmed bandit problems and discuss\nits implication in downstream inferential tasks. While inferential tasks become\nchallenging when data is collected in a sequential manner, we argue that this\nproblem can be alleviated when the sequential algorithm at hand satisfies\ncertain stability property. This notion of stability is motivated from the\nseminal work of Lai and Wei (1982). Our first main result shows that such a\nstability property is always satisfied for the UCB algorithm, and as a result\nthe sample means for each arm are asymptotically normal. Next, we examine the\nstability properties of the UCB algorithm when the number of arms $K$ is\nallowed to grow with the number of arm pulls $T$. We show that in such a case\nthe arms are stable when $\\frac{\\log K}{\\log T} \\rightarrow 0$, and the number\nof near-optimal arms are large.",
      "tldr_zh": "本论文探讨了 Upper Confidence Bound (UCB) 算法在多臂老虎机问题中的渐近行为，并分析其对下游推理任务的影响。作者证明了 UCB 算法满足一种源于 Lai 和 Wei (1982) 的稳定性属性，从而使每个臂的样本均值渐近正态分布，这有助于缓解顺序数据收集带来的推理挑战。在臂数 K 与拉臂次数 T 共同增长的情况下，论文进一步显示，当 \\(\\frac{\\log K}{\\log T} \\rightarrow 0\\) 且近优臂数较多时，UCB 算法保持稳定性，为更复杂的推理场景提供了理论基础。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG",
        "cs.SY",
        "eess.SY",
        "math.ST",
        "stat.TH"
      ],
      "primary_category": "stat.ML",
      "comment": "17 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2408.04595v1",
      "published_date": "2024-08-08 17:11:36 UTC",
      "updated_date": "2024-08-08 17:11:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:46:22.141450"
    },
    {
      "arxiv_id": "2408.04594v3",
      "title": "Img-Diff: Contrastive Data Synthesis for Multimodal Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Qirui Jiao",
        "Daoyuan Chen",
        "Yilun Huang",
        "Bolin Ding",
        "Yaliang Li",
        "Ying Shen"
      ],
      "abstract": "High-performance Multimodal Large Language Models (MLLMs) are heavily\ndependent on data quality. To advance fine-grained image recognition within\nMLLMs, we introduce a novel data synthesis method inspired by contrastive\nlearning and image difference captioning. Our key idea involves challenging the\nmodel to discern both matching and distinct elements by scrutinizing object\ndifferences in detailed regions across similar images. We begin by generating\npairs of similar images that emphasize object variations. Following this, we\nemploy a Difference Area Generator to pinpoint object differences, and\nsubsequently, a Difference Captions Generator to articulate these differences.\nThis process results in a high-quality dataset of \"object replacement\" samples,\ntermed Img-Diff, which can be scaled as needed due to its automated nature. We\nleverage this generated dataset to fine-tune state-of-the-art (SOTA) MLLMs,\nsuch as InternVL2, achieving substantial improvements across various image\ndifference and Visual Question Answering tasks. Notably, the trained models\nsignificantly outperform existing SOTA models like GPT-4V and Gemini on the\nMMVP benchmark. Additionally, we conduct comprehensive evaluations to validate\nthe dataset's diversity, quality, and robustness, offering several insights\ninto the synthesis of such contrastive datasets. We release our codes and\ndataset to encourage further research on multimodal data synthesis and MLLMs'\nfundamental capabilities for image understanding.",
      "tldr_zh": "该论文提出了一种名为Img-Diff的对比数据合成方法，旨在提升Multimodal Large Language Models (MLLMs)在细粒度图像识别方面的性能，通过分析相似图像中对象的差异来生成高质数据集。方法包括生成强调对象变异的图像对、使用Difference Area Generator识别差异区域，以及Difference Captions Generator描述这些差异，从而自动创建可扩展的“对象替换”样本。实验结果显示，使用Img-Diff数据集微调SOTA模型如InternVL2后，在图像差异和Visual Question Answering任务上显著超越现有模型如GPT-4V和Gemini，尤其在MMVP基准上表现出色。论文还开源了代码和数据集，以推动多模态数据合成及MLLMs图像理解的研究。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "22 pages, 10 figures, 16 tables",
      "pdf_url": "http://arxiv.org/pdf/2408.04594v3",
      "published_date": "2024-08-08 17:10:16 UTC",
      "updated_date": "2024-12-19 11:04:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:46:35.228833"
    },
    {
      "arxiv_id": "2408.04591v2",
      "title": "HiLo: A Learning Framework for Generalized Category Discovery Robust to Domain Shifts",
      "title_zh": "翻译失败",
      "authors": [
        "Hongjun Wang",
        "Sagar Vaze",
        "Kai Han"
      ],
      "abstract": "Generalized Category Discovery (GCD) is a challenging task in which, given a\npartially labelled dataset, models must categorize all unlabelled instances,\nregardless of whether they come from labelled categories or from new ones. In\nthis paper, we challenge a remaining assumption in this task: that all images\nshare the same domain. Specifically, we introduce a new task and method to\nhandle GCD when the unlabelled data also contains images from different domains\nto the labelled set. Our proposed `HiLo' networks extract High-level semantic\nand Low-level domain features, before minimizing the mutual information between\nthe representations. Our intuition is that the clusterings based on domain\ninformation and semantic information should be independent. We further extend\nour method with a specialized domain augmentation tailored for the GCD task, as\nwell as a curriculum learning approach. Finally, we construct a benchmark from\ncorrupted fine-grained datasets as well as a large-scale evaluation on\nDomainNet with real-world domain shifts, reimplementing a number of GCD\nbaselines in this setting. We demonstrate that HiLo outperforms SoTA category\ndiscovery models by a large margin on all evaluations.",
      "tldr_zh": "该研究针对 Generalized Category Discovery (GCD) 任务，提出了一种新的 HiLo 框架，以处理未标注数据中存在的 Domain Shifts 问题，即未标注图像可能来自与标注集不同的域。HiLo 方法通过提取 High-level semantic 和 Low-level domain features，并最小化它们之间的 mutual information，确保基于域信息的聚类和语义信息的聚类相互独立。研究进一步扩展了该框架，包括针对 GCD 的专用 domain augmentation 和 curriculum learning 策略，并在从 corrupted fine-grained datasets 和 DomainNet 构建的基准上进行评估，结果显示 HiLo 在所有测试中大幅超越现有最先进 (SoTA) 类别发现模型。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "v2: Accepted as a conference paper at ICLR 2025; Project page:\n  https://github.com/Visual-AI/hilo/",
      "pdf_url": "http://arxiv.org/pdf/2408.04591v2",
      "published_date": "2024-08-08 17:04:06 UTC",
      "updated_date": "2025-03-03 12:35:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:46:46.630776"
    },
    {
      "arxiv_id": "2408.04586v1",
      "title": "Sampling for View Synthesis: From Local Light Field Fusion to Neural Radiance Fields and Beyond",
      "title_zh": "翻译失败",
      "authors": [
        "Ravi Ramamoorthi"
      ],
      "abstract": "Capturing and rendering novel views of complex real-world scenes is a\nlong-standing problem in computer graphics and vision, with applications in\naugmented and virtual reality, immersive experiences and 3D photography. The\nadvent of deep learning has enabled revolutionary advances in this area,\nclassically known as image-based rendering. However, previous approaches\nrequire intractably dense view sampling or provide little or no guidance for\nhow users should sample views of a scene to reliably render high-quality novel\nviews. Local light field fusion proposes an algorithm for practical view\nsynthesis from an irregular grid of sampled views that first expands each\nsampled view into a local light field via a multiplane image scene\nrepresentation, then renders novel views by blending adjacent local light\nfields. Crucially, we extend traditional plenoptic sampling theory to derive a\nbound that specifies precisely how densely users should sample views of a given\nscene when using our algorithm. We achieve the perceptual quality of Nyquist\nrate view sampling while using up to 4000x fewer views. Subsequent developments\nhave led to new scene representations for deep learning with view synthesis,\nnotably neural radiance fields, but the problem of sparse view synthesis from a\nsmall number of images has only grown in importance. We reprise some of the\nrecent results on sparse and even single image view synthesis, while posing the\nquestion of whether prescriptive sampling guidelines are feasible for the new\ngeneration of image-based rendering algorithms.",
      "tldr_zh": "这篇论文探讨了从采样视图合成复杂场景新视图的问题，介绍了 Local Light Field Fusion 算法，该方法使用多平面图像表示将不规则采样视图扩展为局部光场，并通过混合相邻光场实现高效渲染。\n论文扩展了 plenoptic 采样理论，提供精确指导，允许用户以远少于传统方法的采样密度（最多减少 4000 倍）达到 Nyquist 率级的感知质量。\n此外，论文回顾了后续发展如 Neural Radiance Fields，并提出是否能为这些新图像渲染算法制定规范的采样指南，以支持稀疏视图合成。",
      "categories": [
        "cs.GR",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.GR",
      "comment": "Article written for Frontiers of Science Award, International\n  Congress on Basic Science, 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.04586v1",
      "published_date": "2024-08-08 16:56:03 UTC",
      "updated_date": "2024-08-08 16:56:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:46:58.283890"
    },
    {
      "arxiv_id": "2408.04583v1",
      "title": "Unveiling the Power of Sparse Neural Networks for Feature Selection",
      "title_zh": "揭示稀疏神经网络在特征选择中的力量",
      "authors": [
        "Zahra Atashgahi",
        "Tennison Liu",
        "Mykola Pechenizkiy",
        "Raymond Veldhuis",
        "Decebal Constantin Mocanu",
        "Mihaela van der Schaar"
      ],
      "abstract": "Sparse Neural Networks (SNNs) have emerged as powerful tools for efficient\nfeature selection. Leveraging the dynamic sparse training (DST) algorithms\nwithin SNNs has demonstrated promising feature selection capabilities while\ndrastically reducing computational overheads. Despite these advancements,\nseveral critical aspects remain insufficiently explored for feature selection.\nQuestions persist regarding the choice of the DST algorithm for network\ntraining, the choice of metric for ranking features/neurons, and the\ncomparative performance of these methods across diverse datasets when compared\nto dense networks. This paper addresses these gaps by presenting a\ncomprehensive systematic analysis of feature selection with sparse neural\nnetworks. Moreover, we introduce a novel metric considering sparse neural\nnetwork characteristics, which is designed to quantify feature importance\nwithin the context of SNNs. Our findings show that feature selection with SNNs\ntrained with DST algorithms can achieve, on average, more than $50\\%$ memory\nand $55\\%$ FLOPs reduction compared to the dense networks, while outperforming\nthem in terms of the quality of the selected features. Our code and the\nsupplementary material are available on GitHub\n(\\url{https://github.com/zahraatashgahi/Neuron-Attribution}).",
      "tldr_zh": "本研究探讨了Sparse Neural Networks (SNNs) 在特征选择中的潜力，通过Dynamic Sparse Training (DST) 算法实现高效训练并显著降低计算开销。论文对DST算法选择、特征/神经元排名指标以及SNNs与密集网络在不同数据集上的表现进行了系统分析，并引入了一个新指标来量化SNNs上下文中的特征重要性。结果显示，SNNs平均可实现超过50%的内存减少和55%的FLOPs减少，同时在特征选择质量上优于密集网络。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.04583v1",
      "published_date": "2024-08-08 16:48:33 UTC",
      "updated_date": "2024-08-08 16:48:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:47:08.649839"
    },
    {
      "arxiv_id": "2408.12616v2",
      "title": "Semantic Communication based on Large Language Model for Underwater Image Transmission",
      "title_zh": "翻译失败",
      "authors": [
        "Weilong Chen",
        "Wenxuan Xu",
        "Haoran Chen",
        "Xinran Zhang",
        "Zhijin Qin",
        "Yanru Zhang",
        "Zhu Han"
      ],
      "abstract": "Underwater communication is essential for environmental monitoring, marine\nbiology research, and underwater exploration. Traditional underwater\ncommunication faces limitations like low bandwidth, high latency, and\nsusceptibility to noise, while semantic communication (SC) offers a promising\nsolution by focusing on the exchange of semantics rather than symbols or bits.\nHowever, SC encounters challenges in underwater environments, including\nsemantic information mismatch and difficulties in accurately identifying and\ntransmitting critical information that aligns with the diverse requirements of\nunderwater applications. To address these challenges, we propose a novel\nSemantic Communication (SC) framework based on Large Language Models (LLMs).\nOur framework leverages visual LLMs to perform semantic compression and\nprioritization of underwater image data according to the query from users. By\nidentifying and encoding key semantic elements within the images, the system\nselectively transmits high-priority information while applying higher\ncompression rates to less critical regions. On the receiver side, an LLM-based\nrecovery mechanism, along with Global Vision ControlNet and Key Region\nControlNet networks, aids in reconstructing the images, thereby enhancing\ncommunication efficiency and robustness. Our framework reduces the overall data\nsize to 0.8\\% of the original. Experimental results demonstrate that our method\nsignificantly outperforms existing approaches, ensuring high-quality,\nsemantically accurate image reconstruction.",
      "tldr_zh": "该论文提出了一种基于 Large Language Models (LLMs) 的 Semantic Communication (SC) 框架，用于解决 underwater image transmission 的低带宽、高延迟和噪声问题。框架利用 visual LLMs 对 underwater 图像数据进行语义压缩和优先级排序，根据用户查询识别并编码关键语义元素，实现选择性传输高优先级信息，同时在接收端通过 LLM-based 恢复机制及 Global Vision ControlNet 和 Key Region ControlNet 网络重建图像。该方法将数据大小减少到原先的 0.8%，实验结果显示其显著优于现有方法，确保图像重建的高质量和语义准确性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12616v2",
      "published_date": "2024-08-08 16:46:14 UTC",
      "updated_date": "2024-08-26 03:47:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:47:21.653954"
    },
    {
      "arxiv_id": "2408.04575v2",
      "title": "SCENE: Evaluating Explainable AI Techniques Using Soft Counterfactuals",
      "title_zh": "翻译失败",
      "authors": [
        "Haoran Zheng",
        "Utku Pamuksuz"
      ],
      "abstract": "Explainable Artificial Intelligence (XAI) plays a crucial role in enhancing\nthe transparency and accountability of AI models, particularly in natural\nlanguage processing (NLP) tasks. However, popular XAI methods such as LIME and\nSHAP have been found to be unstable and potentially misleading, underscoring\nthe need for a standardized evaluation approach. This paper introduces SCENE\n(Soft Counterfactual Evaluation for Natural language Explainability), a novel\nevaluation method that leverages large language models (LLMs) to generate Soft\nCounterfactual explanations in a zero-shot manner. By focusing on token-based\nsubstitutions, SCENE creates contextually appropriate and semantically\nmeaningful Soft Counterfactuals without extensive fine-tuning. SCENE adopts\nValiditysoft and Csoft metrics to assess the effectiveness of model-agnostic\nXAI methods in text classification tasks. Applied to CNN, RNN, and Transformer\narchitectures, SCENE provides valuable insights into the strengths and\nlimitations of various XAI techniques.",
      "tldr_zh": "本论文针对可解释性AI (XAI) 在自然语言处理 (NLP) 任务中的透明度和责任性问题，指出现有方法如 LIME 和 SHAP 存在不稳定性和误导性，亟需标准化评估。论文提出 SCENE（Soft Counterfactual Evaluation for Natural language Explainability），一种新颖方法，利用大语言模型 (LLMs) 以零样本方式生成基于 token 的 Soft Counterfactuals，实现上下文合适且语义有意义的解释，而无需大量微调。SCENE 通过 Validitysoft 和 Csoft 指标评估模型无关的 XAI 方法在文本分类任务中的有效性，并在 CNN、RNN 和 Transformer 架构上应用，提供对各种 XAI 技术的优势和局限性的宝贵洞见。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.04575v2",
      "published_date": "2024-08-08 16:36:24 UTC",
      "updated_date": "2024-08-16 06:01:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:47:34.435546"
    },
    {
      "arxiv_id": "2408.04568v1",
      "title": "Learning Fine-Grained Grounded Citations for Attributed Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Lei Huang",
        "Xiaocheng Feng",
        "Weitao Ma",
        "Yuxuan Gu",
        "Weihong Zhong",
        "Xiachong Feng",
        "Weijiang Yu",
        "Weihua Peng",
        "Duyu Tang",
        "Dandan Tu",
        "Bing Qin"
      ],
      "abstract": "Despite the impressive performance on information-seeking tasks, large\nlanguage models (LLMs) still struggle with hallucinations. Attributed LLMs,\nwhich augment generated text with in-line citations, have shown potential in\nmitigating hallucinations and improving verifiability. However, current\napproaches suffer from suboptimal citation quality due to their reliance on\nin-context learning. Furthermore, the practice of citing only coarse document\nidentifiers makes it challenging for users to perform fine-grained\nverification. In this work, we introduce FRONT, a training framework designed\nto teach LLMs to generate Fine-Grained Grounded Citations. By grounding model\noutputs in fine-grained supporting quotes, these quotes guide the generation of\ngrounded and consistent responses, not only improving citation quality but also\nfacilitating fine-grained verification. Experiments on the ALCE benchmark\ndemonstrate the efficacy of FRONT in generating superior grounded responses and\nhighly supportive citations. With LLaMA-2-7B, the framework significantly\noutperforms all the baselines, achieving an average of 14.21% improvement in\ncitation quality across all datasets, even surpassing ChatGPT.",
      "tldr_zh": "本研究针对大型语言模型(LLMs)的幻觉(hallucinations)问题，提出FRONT框架，以训练LLMs生成细粒度接地引用(Fine-Grained Grounded Citations)，通过支持性引文指导响应生成，提高引用质量和细粒度验证能力。该框架克服了现有方法依赖in-context learning的局限性，确保响应更可靠且易于验证。在ALCE benchmark上的实验表明，使用LLaMA-2-7B模型，FRONT比基线方法平均提升14.21%的引用质量，甚至超过了ChatGPT的表现。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by ACL 2024 Findings",
      "pdf_url": "http://arxiv.org/pdf/2408.04568v1",
      "published_date": "2024-08-08 16:28:22 UTC",
      "updated_date": "2024-08-08 16:28:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:47:46.936745"
    },
    {
      "arxiv_id": "2408.04693v1",
      "title": "Understanding the Performance and Estimating the Cost of LLM Fine-Tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Yuchen Xia",
        "Jiho Kim",
        "Yuhan Chen",
        "Haojie Ye",
        "Souvik Kundu",
        "Cong Hao",
        "Nishil Talati"
      ],
      "abstract": "Due to the cost-prohibitive nature of training Large Language Models (LLMs),\nfine-tuning has emerged as an attractive alternative for specializing LLMs for\nspecific tasks using limited compute resources in a cost-effective manner. In\nthis paper, we characterize sparse Mixture of Experts (MoE) based LLM\nfine-tuning to understand their accuracy and runtime performance on a single\nGPU. Our evaluation provides unique insights into the training efficacy of\nsparse and dense versions of MoE models, as well as their runtime\ncharacteristics, including maximum batch size, execution time breakdown,\nend-to-end throughput, GPU hardware utilization, and load distribution. Our\nstudy identifies the optimization of the MoE layer as crucial for further\nimproving the performance of LLM fine-tuning. Using our profiling results, we\nalso develop and validate an analytical model to estimate the cost of LLM\nfine-tuning on the cloud. This model, based on parameters of the model and GPU\narchitecture, estimates LLM throughput and the cost of training, aiding\npractitioners in industry and academia to budget the cost of fine-tuning a\nspecific model.",
      "tldr_zh": "这篇论文探讨了大型语言模型 (LLM) fine-tuning 的性能和成本评估问题，特别针对基于稀疏 Mixture of Experts (MoE) 模型的训练方法。研究通过在单 GPU 上评估稀疏和密集 MoE 模型的准确性、运行时性能（如最大批处理大小、执行时间分解、端到端吞吐量、GPU 硬件利用率和负载分布），揭示了优化 MoE 层对提升 fine-tuning 效率的关键作用。最终，论文基于这些分析结果开发了一个分析模型，用于根据模型参数和 GPU 架构估算云端 fine-tuning 的成本，从而帮助学术和行业从业者有效预算训练开支。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages, conference",
      "pdf_url": "http://arxiv.org/pdf/2408.04693v1",
      "published_date": "2024-08-08 16:26:07 UTC",
      "updated_date": "2024-08-08 16:26:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:47:59.118300"
    },
    {
      "arxiv_id": "2408.04535v2",
      "title": "Synchronous Multi-modal Semantic Communication System with Packet-level Coding",
      "title_zh": "翻译失败",
      "authors": [
        "Yun Tian",
        "Jingkai Ying",
        "Zhijin Qin",
        "Ye Jin",
        "Xiaoming Tao"
      ],
      "abstract": "Although the semantic communication with joint semantic-channel coding design\nhas shown promising performance in transmitting data of different modalities\nover physical layer channels, the synchronization and packet-level forward\nerror correction of multimodal semantics have not been well studied. Due to the\nindependent design of semantic encoders, synchronizing multimodal features in\nboth the semantic and time domains is a challenging problem. In this paper, we\ntake the facial video and speech transmission as an example and propose a\nSynchronous Multimodal Semantic Communication System (SyncSC) with Packet-Level\nCoding. To achieve semantic and time synchronization, 3D Morphable Mode (3DMM)\ncoefficients and text are transmitted as semantics, and we propose a semantic\ncodec that achieves similar quality of reconstruction and synchronization with\nlower bandwidth, compared to traditional methods. To protect semantic packets\nunder the erasure channel, we propose a packet-Level Forward Error Correction\n(FEC) method, called PacSC, that maintains a certain visual quality performance\neven at high packet loss rates. Particularly, for text packets, a text packet\nloss concealment module, called TextPC, based on Bidirectional Encoder\nRepresentations from Transformers (BERT) is proposed, which significantly\nimproves the performance of traditional FEC methods. The simulation results\nshow that our proposed SyncSC reduce transmission overhead and achieve\nhigh-quality synchronous transmission of video and speech over the packet loss\nnetwork.",
      "tldr_zh": "该论文提出了一种同步多模态语义通信系统（SyncSC），针对多模态数据（如面部视频和语音）的传输，解决了语义和时间同步以及分组级前向纠错（FEC）的问题。具体而言，系统使用 3D Morphable Model (3DMM) 系数和文本作为语义进行编码，实现比传统方法更低的带宽需求，同时保持重建质量；并引入 Packet-Level FEC 方法（PacSC）和基于 BERT 的文本分组丢失隐藏模块（TextPC），以在擦除通道下维持高视觉质量。实验结果显示，SyncSC 显著减少了传输开销，并在高分组丢失率环境下实现了高质量的视频和语音同步传输。",
      "categories": [
        "eess.IV",
        "cs.AI"
      ],
      "primary_category": "eess.IV",
      "comment": "12 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.04535v2",
      "published_date": "2024-08-08 15:42:00 UTC",
      "updated_date": "2024-08-11 02:37:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:48:09.793564"
    },
    {
      "arxiv_id": "2408.04692v1",
      "title": "Exploring Scalability in Large-Scale Time Series in DeepVATS framework",
      "title_zh": "在 DeepVATS 框架中探索大规模时间序列的可扩展性",
      "authors": [
        "Inmaculada Santamaria-Valenzuela",
        "Victor Rodriguez-Fernandez",
        "David Camacho"
      ],
      "abstract": "Visual analytics is essential for studying large time series due to its\nability to reveal trends, anomalies, and insights. DeepVATS is a tool that\nmerges Deep Learning (Deep) with Visual Analytics (VA) for the analysis of\nlarge time series data (TS). It has three interconnected modules. The Deep\nLearning module, developed in R, manages the load of datasets and Deep Learning\nmodels from and to the Storage module. This module also supports models\ntraining and the acquisition of the embeddings from the latent space of the\ntrained model. The Storage module operates using the Weights and Biases system.\nSubsequently, these embeddings can be analyzed in the Visual Analytics module.\nThis module, based on an R Shiny application, allows the adjustment of the\nparameters related to the projection and clustering of the embeddings space.\nOnce these parameters are set, interactive plots representing both the\nembeddings, and the time series are shown. This paper introduces the tool and\nexamines its scalability through log analytics. The execution time evolution is\nexamined while the length of the time series is varied. This is achieved by\nresampling a large data series into smaller subsets and logging the main\nexecution and rendering times for later analysis of scalability.",
      "tldr_zh": "该论文介绍了 DeepVATS 框架，该工具将 Deep Learning 与 Visual Analytics 相结合，用于分析大型时间序列数据（TS），通过三个互联模块实现数据加载、模型训练和交互式可视化。DeepVATS 的 Deep Learning 模块使用 R 处理数据集和嵌入（embeddings）的获取，Storage 模块依赖 Weights and Biases 系统存储数据，而 Visual Analytics 模块基于 R Shiny 应用允许用户调整投影和聚类参数并显示交互式图表。主要贡献是通过日志分析评估框架的可扩展性，实验显示执行和渲染时间随时间序列长度变化，提供对处理大规模数据的可行性洞见。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Admitted pending publication in Lecture Notes in Network and Systems\n  (LNNS) series (Springer). Code available at\n  https://github.com/vrodriguezf/deepvats",
      "pdf_url": "http://arxiv.org/pdf/2408.04692v1",
      "published_date": "2024-08-08 15:30:48 UTC",
      "updated_date": "2024-08-08 15:30:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:48:21.641708"
    },
    {
      "arxiv_id": "2408.04528v1",
      "title": "Reasoning about Study Regulations in Answer Set Programming",
      "title_zh": "翻译失败",
      "authors": [
        "Susana Hahn",
        "Cedric Martens",
        "Amade Nemes",
        "Henry Otunuya",
        "Javier Romero",
        "Torsten Schaub",
        "Sebastian Schellhorn"
      ],
      "abstract": "We are interested in automating reasoning with and about study regulations,\ncatering to various stakeholders, ranging from administrators, over faculty, to\nstudents at different stages. Our work builds on an extensive analysis of\nvarious study programs at the University of Potsdam. The conceptualization of\nthe underlying principles provides us with a formal account of study\nregulations. In particular, the formalization reveals the properties of\nadmissible study plans. With these at end, we propose an encoding of study\nregulations in Answer Set Programming that produces corresponding study plans.\nFinally, we show how this approach can be extended to a generic user interface\nfor exploring study plans.",
      "tldr_zh": "该论文探讨了使用 Answer Set Programming (ASP) 自动化推理和处理学习规定，以满足管理员、教职员工和学生的不同需求。基于对波茨坦大学多个学习程序的深入分析，研究者概念化并正式化了学习规定的核心原则，从而揭示了可接受学习计划的属性。他们提出了一种 ASP 编码方法来生成相应学习计划，并扩展为一个通用用户界面，支持用户探索和优化计划。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "To appear in Theory and Practise of Logic Programming",
      "pdf_url": "http://arxiv.org/pdf/2408.04528v1",
      "published_date": "2024-08-08 15:27:22 UTC",
      "updated_date": "2024-08-08 15:27:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:48:32.208989"
    },
    {
      "arxiv_id": "2408.04491v1",
      "title": "Towards Synergistic Deep Learning Models for Volumetric Cirrhotic Liver Segmentation in MRIs",
      "title_zh": "翻译失败",
      "authors": [
        "Vandan Gorade",
        "Onkar Susladkar",
        "Gorkem Durak",
        "Elif Keles",
        "Ertugrul Aktas",
        "Timurhan Cebeci",
        "Alpay Medetalibeyoglu",
        "Daniela Ladner",
        "Debesh Jha",
        "Ulas Bagci"
      ],
      "abstract": "Liver cirrhosis, a leading cause of global mortality, requires precise\nsegmentation of ROIs for effective disease monitoring and treatment planning.\nExisting segmentation models often fail to capture complex feature interactions\nand generalize across diverse datasets. To address these limitations, we\npropose a novel synergistic theory that leverages complementary latent spaces\nfor enhanced feature interaction modeling. Our proposed architecture,\nnnSynergyNet3D integrates continuous and discrete latent spaces for 3D volumes\nand features auto-configured training. This approach captures both fine-grained\nand coarse features, enabling effective modeling of intricate feature\ninteractions. We empirically validated nnSynergyNet3D on a private dataset of\n628 high-resolution T1 abdominal MRI scans from 339 patients. Our model\noutperformed the baseline nnUNet3D by approximately 2%. Additionally, zero-shot\ntesting on healthy liver CT scans from the public LiTS dataset demonstrated\nsuperior cross-modal generalization capabilities. These results highlight the\npotential of synergistic latent space models to improve segmentation accuracy\nand robustness, thereby enhancing clinical workflows by ensuring consistency\nacross CT and MRI modalities.",
      "tldr_zh": "肝硬化是全球主要死亡原因之一，需要精确分割MRI中的肝脏感兴趣区域（ROIs），但现有模型难以捕捉复杂特征交互和跨数据集泛化。为解决此问题，本文提出一种新颖的协同理论（synergistic theory），利用互补潜在空间来增强特征交互建模，并开发了nnSynergyNet3D架构，该架构整合连续和离散潜在空间，用于3D体积的自动配置训练，以捕捉细粒度和粗粒度特征。实验在包含628个高分辨率T1腹部MRI扫描的私人数据集上验证，nnSynergyNet3D比基线nnUNet3D提高了约2%的性能，并在LiTS公共数据集的零样本CT扫描测试中显示出更好的跨模态泛化能力。这些结果证明了协同潜在空间模型在提升肝脏分割准确性和鲁棒性方面的潜力，从而改善临床工作流程的跨CT和MRI模态一致性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.04491v1",
      "published_date": "2024-08-08 14:41:32 UTC",
      "updated_date": "2024-08-08 14:41:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:48:46.744613"
    },
    {
      "arxiv_id": "2408.05249v1",
      "title": "Advancing oncology with federated learning: transcending boundaries in breast, lung, and prostate cancer. A systematic review",
      "title_zh": "翻译失败",
      "authors": [
        "Anshu Ankolekar",
        "Sebastian Boie",
        "Maryam Abdollahyan",
        "Emanuela Gadaleta",
        "Seyed Alireza Hasheminasab",
        "Guang Yang",
        "Charles Beauville",
        "Nikolaos Dikaios",
        "George Anthony Kastis",
        "Michael Bussmann",
        "Sara Khalid",
        "Hagen Kruger",
        "Philippe Lambin",
        "Giorgos Papanastasiou"
      ],
      "abstract": "Federated Learning (FL) has emerged as a promising solution to address the\nlimitations of centralised machine learning (ML) in oncology, particularly in\novercoming privacy concerns and harnessing the power of diverse, multi-center\ndata. This systematic review synthesises current knowledge on the\nstate-of-the-art FL in oncology, focusing on breast, lung, and prostate cancer.\nDistinct from previous surveys, our comprehensive review critically evaluates\nthe real-world implementation and impact of FL on cancer care, demonstrating\nits effectiveness in enhancing ML generalisability, performance and data\nprivacy in clinical settings and data. We evaluated state-of-the-art advances\nin FL, demonstrating its growing adoption amid tightening data privacy\nregulations. FL outperformed centralised ML in 15 out of the 25 studies\nreviewed, spanning diverse ML models and clinical applications, and\nfacilitating integration of multi-modal information for precision medicine.\nDespite the current challenges identified in reproducibility, standardisation\nand methodology across studies, the demonstrable benefits of FL in harnessing\nreal-world data and addressing clinical needs highlight its significant\npotential for advancing cancer research. We propose that future research should\nfocus on addressing these limitations and investigating further advanced FL\nmethods, to fully harness data diversity and realise the transformative power\nof cutting-edge FL in cancer care.",
      "tldr_zh": "这篇系统综述探讨了Federated Learning (FL) 在肿瘤学领域的应用，特别是针对乳腺癌、肺癌和前列腺癌，通过利用多中心数据来解决隐私问题并提升机器学习 (ML) 的泛化性、性能和数据保护。研究评估了25个相关研究，发现FL在15个案例中优于中心化ML，支持多模态信息整合以推进精准医学。尽管存在再现性、标准化和方法学挑战，但FL展示了在癌症护理中的巨大潜力，并建议未来研究聚焦于解决这些限制并开发高级FL方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE",
        "eess.IV"
      ],
      "primary_category": "cs.LG",
      "comment": "5 Figures, 3 Tables, 1 Supplementary Table",
      "pdf_url": "http://arxiv.org/pdf/2408.05249v1",
      "published_date": "2024-08-08 14:36:16 UTC",
      "updated_date": "2024-08-08 14:36:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:48:56.534069"
    },
    {
      "arxiv_id": "2408.05248v1",
      "title": "The Role and Applications of Airport Digital Twin in Cyberattack Protection during the Generative AI Era",
      "title_zh": "翻译失败",
      "authors": [
        "Abraham Itzhak Weinberg"
      ],
      "abstract": "In recent years, the threat facing airports from growing and increasingly\nsophisticated cyberattacks has become evident. Airports are considered a\nstrategic national asset, so protecting them from attacks, specifically\ncyberattacks, is a crucial mission. One way to increase airports' security is\nby using Digital Twins (DTs). This paper shows and demonstrates how DTs can\nenhance the security mission. The integration of DTs with Generative AI (GenAI)\nalgorithms can lead to synergy and new frontiers in fighting cyberattacks. The\npaper exemplifies ways to model cyberattack scenarios using simulations and\ngenerate synthetic data for testing defenses. It also discusses how DTs can be\nused as a crucial tool for vulnerability assessment by identifying weaknesses,\nprioritizing, and accelerating remediations in case of cyberattacks. Moreover,\nthe paper demonstrates approaches for anomaly detection and threat hunting\nusing Machine Learning (ML) and GenAI algorithms. Additionally, the paper\nprovides impact prediction and recovery coordination methods that can be used\nby DT operators and stakeholders. It also introduces ways to harness the human\nfactor by integrating training and simulation algorithms with Explainable AI\n(XAI) into the DT platforms. Lastly, the paper offers future applications and\ntechnologies that can be utilized in DT environments.",
      "tldr_zh": "这篇论文探讨了在生成式 AI (Generative AI) 时代，Airport Digital Twin (DTs) 在保护机场免受网络攻击方面的作用和应用。论文强调通过将 DTs 与 Generative AI 算法整合，实现网络攻击场景模拟、生成合成数据用于防御测试，以及漏洞评估和异常检测，以提升机场安全。研究还介绍了利用 Machine Learning (ML) 和 Explainable AI (XAI) 进行威胁狩猎、影响预测、恢复协调和人员训练，并展望了 DTs 环境的未来技术应用。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.05248v1",
      "published_date": "2024-08-08 14:35:39 UTC",
      "updated_date": "2024-08-08 14:35:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:49:10.793232"
    },
    {
      "arxiv_id": "2408.04484v1",
      "title": "Statistical Framework for Clustering MU-MIMO Wireless via Second Order Statistics",
      "title_zh": "翻译失败",
      "authors": [
        "Roberto Pereira",
        "Xavier Mestre"
      ],
      "abstract": "This work explores the clustering of wireless users by examining the\ndistances between their channel covariance matrices, which reside on the\nRiemannian manifold of positive definite matrices. Specifically, we consider an\nestimator of the Log-Euclidean distance between multiple sample covariance\nmatrices (SCMs) consistent when the number of samples and the observation size\ngrow unbounded at the same rate. Within the context of multi-user MIMO\n(MU-MIMO) wireless communication systems, we develop a statistical framework\nthat allows to accurate predictions of the clustering algorithm's performance\nunder realistic conditions. Specifically, we present a central limit theorem\nthat establishes the asymptotic Gaussianity of the consistent estimator of the\nlog-Euclidean distance computed over two sample covariance matrices.",
      "tldr_zh": "本文提出一个统计框架，用于通过第二阶统计（Second Order Statistics）聚类MU-MIMO无线用户，基于通道协方差矩阵在Riemannian流形上的距离。框架引入了一个Log-Euclidean距离的估计器，该估计器在样本数和观测大小以相同速率增长时保持一致性。研究还证明了一个Central Limit Theorem，确立了该估计器的渐进高斯性，从而在真实条件下准确预测聚类算法的性能。",
      "categories": [
        "eess.SP",
        "cs.AI"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.04484v1",
      "published_date": "2024-08-08 14:23:06 UTC",
      "updated_date": "2024-08-08 14:23:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:49:25.558865"
    },
    {
      "arxiv_id": "2408.04482v1",
      "title": "SegXAL: Explainable Active Learning for Semantic Segmentation in Driving Scene Scenarios",
      "title_zh": "翻译失败",
      "authors": [
        "Sriram Mandalika",
        "Athira Nambiar"
      ],
      "abstract": "Most of the sophisticated AI models utilize huge amounts of annotated data\nand heavy training to achieve high-end performance. However, there are certain\nchallenges that hinder the deployment of AI models \"in-the-wild\" scenarios,\ni.e., inefficient use of unlabeled data, lack of incorporation of human\nexpertise, and lack of interpretation of the results. To mitigate these\nchallenges, we propose a novel Explainable Active Learning (XAL) model,\nXAL-based semantic segmentation model \"SegXAL\", that can (i) effectively\nutilize the unlabeled data, (ii) facilitate the \"Human-in-the-loop\" paradigm,\nand (iii) augment the model decisions in an interpretable way. In particular,\nwe investigate the application of the SegXAL model for semantic segmentation in\ndriving scene scenarios. The SegXAL model proposes the image regions that\nrequire labeling assistance from Oracle by dint of explainable AI (XAI) and\nuncertainty measures in a weakly-supervised manner. Specifically, we propose a\nnovel Proximity-aware Explainable-AI (PAE) module and Entropy-based Uncertainty\n(EBU) module to get an Explainable Error Mask, which enables the machine\nteachers/human experts to provide intuitive reasoning behind the results and to\nsolicit feedback to the AI system via an active learning strategy. Such a\nmechanism bridges the semantic gap between man and machine through\ncollaborative intelligence, where humans and AI actively enhance each other's\ncomplementary strengths. A novel high-confidence sample selection technique\nbased on the DICE similarity coefficient is also presented within the SegXAL\nframework. Extensive quantitative and qualitative analyses are carried out in\nthe benchmarking Cityscape dataset. Results show the outperformance of our\nproposed SegXAL against other state-of-the-art models.",
      "tldr_zh": "该论文提出 SegXAL，一种基于 Explainable Active Learning (XAL) 的语义分割模型，旨在解决 AI 在驾驶场景中对未标注数据利用不足、缺乏人类参与以及结果解释性差的问题。SegXAL 通过 Proximity-aware Explainable-AI (PAE) 模块和 Entropy-based Uncertainty (EBU) 模块生成 Explainable Error Mask，实现弱监督下的图像区域标注建议，并支持“Human-in-the-loop”协作机制。模型还引入基于 DICE similarity coefficient 的高置信样本选择技术，以提升主动学习效率。在 Cityscape 数据集上的实验表明，SegXAL 在定量和定性分析中优于其他最先进模型。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "17 pages, 7 figures. To appear in the proceedings of the 27th\n  International Conference on Pattern Recognition (ICPR), 01-05 December, 2024,\n  Kolkata, India",
      "pdf_url": "http://arxiv.org/pdf/2408.04482v1",
      "published_date": "2024-08-08 14:19:11 UTC",
      "updated_date": "2024-08-08 14:19:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:49:37.021741"
    },
    {
      "arxiv_id": "2408.04449v5",
      "title": "EARBench: Towards Evaluating Physical Risk Awareness for Task Planning of Foundation Model-based Embodied AI Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Zihao Zhu",
        "Bingzhe Wu",
        "Zhengyou Zhang",
        "Lei Han",
        "Qingshan Liu",
        "Baoyuan Wu"
      ],
      "abstract": "Embodied artificial intelligence (EAI) integrates advanced AI models into\nphysical entities for real-world interaction. The emergence of foundation\nmodels as the \"brain\" of EAI agents for high-level task planning has shown\npromising results. However, the deployment of these agents in physical\nenvironments presents significant safety challenges. For instance, a\nhousekeeping robot lacking sufficient risk awareness might place a metal\ncontainer in a microwave, potentially causing a fire. To address these critical\nsafety concerns, comprehensive pre-deployment risk assessments are imperative.\nThis study introduces EARBench, a novel framework for automated physical risk\nassessment in EAI scenarios. EAIRiskBench employs a multi-agent cooperative\nsystem that leverages various foundation models to generate safety guidelines,\ncreate risk-prone scenarios, make task planning, and evaluate safety\nsystematically. Utilizing this framework, we construct EARDataset, comprising\ndiverse test cases across various domains, encompassing both textual and visual\nscenarios. Our comprehensive evaluation of state-of-the-art foundation models\nreveals alarming results: all models exhibit high task risk rates (TRR), with\nan average of 95.75% across all evaluated models. To address these challenges,\nwe further propose two prompting-based risk mitigation strategies. While these\nstrategies demonstrate some efficacy in reducing TRR, the improvements are\nlimited, still indicating substantial safety concerns. This study provides the\nfirst large-scale assessment of physical risk awareness in EAI agents. Our\nfindings underscore the critical need for enhanced safety measures in EAI\nsystems and provide valuable insights for future research directions in\ndeveloping safer embodied artificial intelligence system. Data and code are\navailable at https://github.com/zihao-ai/EARBench.",
      "tldr_zh": "这篇论文引入了 EARBench，一个自动化框架，用于评估基于 foundation models 的 Embodied AI 代理在任务规划中的物理风险意识。该框架采用多智能体合作系统，生成安全指南、创建风险场景、进行任务规划和系统评估，并构建了 EARDataset 包含多样化文本和视觉测试案例。评估结果显示，所有模型的 Task Risk Rate (TRR) 平均高达 95.75%，揭示了严重的安全问题；为此，论文提出了两种基于提示的风险缓解策略，虽然有所改善但效果有限，并强调了未来 EAI 系统增强安全措施的紧迫性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.04449v5",
      "published_date": "2024-08-08 13:19:37 UTC",
      "updated_date": "2024-11-28 12:28:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:49:48.947759"
    },
    {
      "arxiv_id": "2408.12614v1",
      "title": "Image-Feature Weak-to-Strong Consistency: An Enhanced Paradigm for Semi-Supervised Learning",
      "title_zh": "图像-特征弱到强一致性：半监督学习的增强范式",
      "authors": [
        "Zhiyu Wu",
        "Jinshi Cui"
      ],
      "abstract": "Image-level weak-to-strong consistency serves as the predominant paradigm in\nsemi-supervised learning~(SSL) due to its simplicity and impressive\nperformance. Nonetheless, this approach confines all perturbations to the image\nlevel and suffers from the excessive presence of naive samples, thus\nnecessitating further improvement. In this paper, we introduce feature-level\nperturbation with varying intensities and forms to expand the augmentation\nspace, establishing the image-feature weak-to-strong consistency paradigm.\nFurthermore, our paradigm develops a triple-branch structure, which facilitates\ninteractions between both types of perturbations within one branch to boost\ntheir synergy. Additionally, we present a confidence-based identification\nstrategy to distinguish between naive and challenging samples, thus introducing\nadditional challenges exclusively for naive samples. Notably, our paradigm can\nseamlessly integrate with existing SSL methods. We apply the proposed paradigm\nto several representative algorithms and conduct experiments on multiple\nbenchmarks, including both balanced and imbalanced distributions for labeled\nsamples. The results demonstrate a significant enhancement in the performance\nof existing SSL algorithms.",
      "tldr_zh": "本论文提出了一种增强的半监督学习（SSL）范式，即图像-特征弱到强一致性（Image-Feature Weak-to-Strong Consistency），通过引入特征级别扰动（以不同强度和形式扩展增强空间）来克服传统图像级别方法的局限性，如过多简单样本的问题。范式采用三支结构，促进图像和特征扰动之间的互动，并引入基于置信度的样本识别策略，仅为简单样本添加额外挑战，以提升模型性能。该方法可无缝整合到现有SSL算法中，并在多个基准测试（包括平衡和不平衡标签分布）上实验，结果显示现有算法的性能显著提升。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ECCV 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.12614v1",
      "published_date": "2024-08-08 13:19:25 UTC",
      "updated_date": "2024-08-08 13:19:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:49:59.340247"
    },
    {
      "arxiv_id": "2408.04442v1",
      "title": "FedAD-Bench: A Unified Benchmark for Federated Unsupervised Anomaly Detection in Tabular Data",
      "title_zh": "翻译失败",
      "authors": [
        "Ahmed Anwar",
        "Brian Moser",
        "Dayananda Herurkar",
        "Federico Raue",
        "Vinit Hegiste",
        "Tatjana Legler",
        "Andreas Dengel"
      ],
      "abstract": "The emergence of federated learning (FL) presents a promising approach to\nleverage decentralized data while preserving privacy. Furthermore, the\ncombination of FL and anomaly detection is particularly compelling because it\nallows for detecting rare and critical anomalies (usually also rare in locally\ngathered data) in sensitive data from multiple sources, such as cybersecurity\nand healthcare. However, benchmarking the performance of anomaly detection\nmethods in FL environments remains an underexplored area. This paper introduces\nFedAD-Bench, a unified benchmark for evaluating unsupervised anomaly detection\nalgorithms within the context of FL. We systematically analyze and compare the\nperformance of recent deep learning anomaly detection models under federated\nsettings, which were typically assessed solely in centralized settings.\nFedAD-Bench encompasses diverse datasets and metrics to provide a holistic\nevaluation. Through extensive experiments, we identify key challenges such as\nmodel aggregation inefficiencies and metric unreliability. We present insights\ninto FL's regularization effects, revealing scenarios in which it outperforms\ncentralized approaches due to its inherent ability to mitigate overfitting. Our\nwork aims to establish a standardized benchmark to guide future research and\ndevelopment in federated anomaly detection, promoting reproducibility and fair\ncomparison across studies.",
      "tldr_zh": "这篇论文引入了 FedAD-Bench，这是一个统一的基准，用于评估联邦学习 (FL) 环境下的无监督异常检测算法，特别针对表格数据中的敏感领域如网络安全和医疗。研究系统比较了多种深度学习异常检测模型在 FL 设置下的性能，并涵盖了多样数据集和评估指标，以提供全面评估。实验发现 FL 面临的关键挑战包括模型聚合低效和指标不可靠，但其正则化效果能缓解过拟合，并在某些场景下优于集中式方法。该基准旨在指导未来研究，促进联邦异常检测的可重复性和公平比较。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2408.04442v1",
      "published_date": "2024-08-08 13:14:19 UTC",
      "updated_date": "2024-08-08 13:14:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:50:12.202258"
    },
    {
      "arxiv_id": "2408.08892v3",
      "title": "Leveraging Large Language Models for Enhanced Process Model Comprehension",
      "title_zh": "翻译失败",
      "authors": [
        "Humam Kourani",
        "Alessandro Berti",
        "Jasmin Hennrich",
        "Wolfgang Kratsch",
        "Robin Weidlich",
        "Chiao-Yun Li",
        "Ahmad Arslan",
        "Daniel Schuster",
        "Wil M. P. van der Aalst"
      ],
      "abstract": "In Business Process Management (BPM), effectively comprehending process\nmodels is crucial yet poses significant challenges, particularly as\norganizations scale and processes become more complex. This paper introduces a\nnovel framework utilizing the advanced capabilities of Large Language Models\n(LLMs) to enhance the interpretability of complex process models. We present\ndifferent methods for abstracting business process models into a format\naccessible to LLMs, and we implement advanced prompting strategies specifically\ndesigned to optimize LLM performance within our framework. Additionally, we\npresent a tool, AIPA, that implements our proposed framework and allows for\nconversational process querying. We evaluate our framework and tool by i) an\nautomatic evaluation comparing different LLMs, model abstractions, and\nprompting strategies and ii) a user study designed to assess AIPA's\neffectiveness comprehensively. Results demonstrate our framework's ability to\nimprove the accessibility and interpretability of process models, pioneering\nnew pathways for integrating AI technologies into the BPM field.",
      "tldr_zh": "这篇论文提出一个新框架，利用Large Language Models (LLMs)来提升Business Process Management (BPM)中复杂过程模型的可解释性，旨在解决组织规模扩大带来的理解挑战。框架包括将过程模型抽象成LLMs可访问的格式，并采用先进的提示策略来优化性能，同时开发了AIPA工具，支持对话式过程查询。研究通过自动评估（比较不同LLMs、抽象方法和提示策略）和用户研究，证明该框架显著提高了过程模型的可访问性和可解释性，为AI技术在BPM领域的整合开辟了新路径。",
      "categories": [
        "cs.DB",
        "cs.AI"
      ],
      "primary_category": "cs.DB",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.08892v3",
      "published_date": "2024-08-08 13:12:46 UTC",
      "updated_date": "2024-09-20 11:39:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:50:27.195899"
    },
    {
      "arxiv_id": "2408.04691v4",
      "title": "Synthetic SQL Column Descriptions and Their Impact on Text-to-SQL Performance",
      "title_zh": "合成的 SQL 列描述及其对文本到 SQL 性能的影响",
      "authors": [
        "Niklas Wretblad",
        "Oskar Holmström",
        "Erik Larsson",
        "Axel Wiksäter",
        "Oscar Söderlund",
        "Hjalmar Öhman",
        "Ture Pontén",
        "Martin Forsberg",
        "Martin Sörme",
        "Fredrik Heintz"
      ],
      "abstract": "Relational databases often suffer from uninformative descriptors of table\ncontents, such as ambiguous columns and hard-to-interpret values, impacting\nboth human users and text-to-SQL models. In this paper, we explore the use of\nlarge language models (LLMs) to automatically generate detailed natural\nlanguage descriptions for SQL database columns, aiming to improve text-to-SQL\nperformance and automate metadata creation. We create a dataset of gold column\ndescriptions based on the BIRD-Bench benchmark, manually refining its column\ndescriptions and creating a taxonomy for categorizing column difficulty. We\nthen evaluate several different LLMs in generating column descriptions across\nthe columns and different difficulties in the dataset, finding that models\nunsurprisingly struggle with columns that exhibit inherent ambiguity,\nhighlighting the need for manual expert input. We also find that incorporating\nsuch generated column descriptions consistently enhances text-to-SQL model\nperformance, particularly for larger models like GPT-4o, Qwen2 72B and Mixtral\n22Bx8. Notably, Qwen2-generated descriptions, containing by annotators deemed\nsuperfluous information, outperform manually curated gold descriptions,\nsuggesting that models benefit from more detailed metadata than humans expect.\nFuture work will investigate the specific features of these high-performing\ndescriptions and explore other types of metadata, such as numerical reasoning\nand synonyms, to further improve text-to-SQL systems. The dataset, annotations\nand code will all be made available.",
      "tldr_zh": "这篇论文探讨了关系数据库中模糊列描述对Text-to-SQL模型性能的影响，并提出使用大型语言模型(LLMs)自动生成详细的自然语言列描述，以提升模型准确性和自动化元数据创建。研究者基于BIRD-Bench基准创建了一个数据集，并手动完善列描述及难度分类系统，以评估多种LLMs的表现，结果显示模型在处理固有模糊列时存在挑战，但生成的描述能显著提高Text-to-SQL性能，尤其对GPT-4o、Qwen2 72B和Mixtral 22Bx8等大模型。值得注意的是，Qwen2生成的描述即使包含被视为多余的信息，也优于手动精炼的金标准描述，表明模型从更丰富的元数据中获益。未来工作将深入分析这些高性能描述的特征，并探索其他元数据类型如数值推理和同义词，以进一步优化Text-to-SQL系统。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.04691v4",
      "published_date": "2024-08-08 13:10:51 UTC",
      "updated_date": "2024-11-05 10:32:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:50:48.922147"
    },
    {
      "arxiv_id": "2408.12613v1",
      "title": "Deceptive uses of Artificial Intelligence in elections strengthen support for AI ban",
      "title_zh": "选举中人工智能的欺骗性使用加强了对人工智能禁令的支持",
      "authors": [
        "Andreas Jungherr",
        "Adrian Rauchfleisch",
        "Alexander Wuttke"
      ],
      "abstract": "All over the world, political parties, politicians, and campaigns explore how\nArtificial Intelligence (AI) can help them win elections. However, the effects\nof these activities are unknown. We propose a framework for assessing AI's\nimpact on elections by considering its application in various campaigning\ntasks. The electoral uses of AI vary widely, carrying different levels of\nconcern and need for regulatory oversight. To account for this diversity, we\ngroup AI-enabled campaigning uses into three categories -- campaign operations,\nvoter outreach, and deception. Using this framework, we provide the first\nsystematic evidence from a preregistered representative survey and two\npreregistered experiments (n=7,635) on how Americans think about AI in\nelections and the effects of specific campaigning choices. We provide three\nsignificant findings. 1) the public distinguishes between different AI uses in\nelections, seeing AI uses predominantly negative but objecting most strongly to\ndeceptive uses; 2) deceptive AI practices can have adverse effects on relevant\nattitudes and strengthen public support for stopping AI development; 3)\nAlthough deceptive electoral uses of AI are intensely disliked, they do not\nresult in substantial favorability penalties for the parties involved. There is\na misalignment of incentives for deceptive practices and their externalities.\nWe cannot count on public opinion to provide strong enough incentives for\nparties to forgo tactical advantages from AI-enabled deception. There is a need\nfor regulatory oversight and systematic outside monitoring of electoral uses of\nAI. Still, regulators should account for the diversity of AI uses and not\ncompletely disincentivize their electoral use.",
      "tldr_zh": "这篇论文提出一个框架来评估人工智能（AI）在选举中的应用，将其分为竞选操作（campaign operations）、选民外联（voter outreach）和欺骗（deception）三类，以探讨其潜在影响。研究通过一个预注册的代表性调查和两个实验（n=7,635）发现，公众对不同 AI 使用方式有区分，对欺骗性用途持最强烈反对态度，这种做法会加强公众对 AI 发展的禁令支持。值得注意的是，虽然欺骗性 AI 实践不受欢迎，但不会显著降低涉及政党的支持度，导致激励失调，因此论文呼吁需要监管监督，同时考虑 AI 用途的多样性以避免完全禁止。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "I.2; K.4.2; J.4"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12613v1",
      "published_date": "2024-08-08 12:58:20 UTC",
      "updated_date": "2024-08-08 12:58:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:50:48.380274"
    },
    {
      "arxiv_id": "2408.04430v3",
      "title": "The Struggles of LLMs in Cross-lingual Code Clone Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Micheline Bénédicte Moumoula",
        "Abdoul Kader Kabore",
        "Jacques Klein",
        "Tegawendé Bissyande"
      ],
      "abstract": "With the involvement of multiple programming languages in modern software\ndevelopment, cross-lingual code clone detection has gained traction within the\nsoftware engineering community. Numerous studies have explored this topic,\nproposing various promising approaches. Inspired by the significant advances in\nmachine learning in recent years, particularly Large Language Models (LLMs),\nwhich have demonstrated their ability to tackle various tasks, this paper\nrevisits cross-lingual code clone detection. We evaluate the performance of\nfive (05) LLMs and eight prompts (08) for the identification of cross-lingual\ncode clones. Additionally, we compare these results against two baseline\nmethods. Finally, we evaluate a pre-trained embedding model to assess the\neffectiveness of the generated representations for classifying clone and\nnon-clone pairs. The studies involving LLMs and Embedding models are evaluated\nusing two widely used cross-lingual datasets, XLCoST and CodeNet. Our results\nshow that LLMs can achieve high F1 scores, up to 0.99, for straightforward\nprogramming examples. However, they not only perform less well on programs\nassociated with complex programming challenges but also do not necessarily\nunderstand the meaning of \"code clones\" in a cross-lingual setting. We show\nthat embedding models used to represent code fragments from different\nprogramming languages in the same representation space enable the training of a\nbasic classifier that outperforms all LLMs by ~1 and ~20 percentage points on\nthe XLCoST and CodeNet datasets, respectively. This finding suggests that,\ndespite the apparent capabilities of LLMs, embeddings provided by embedding\nmodels offer suitable representations to achieve state-of-the-art performance\nin cross-lingual code clone detection.",
      "tldr_zh": "本研究探讨了大型语言模型（LLMs）在跨语言代码克隆检测（cross-lingual code clone detection）中的表现，评估了5个LLMs和8个prompts的效果，并与两个基线方法以及预训练的embedding models进行比较。实验使用XLCoST和CodeNet数据集，结果显示LLMs在简单编程示例中可达0.99的F1 scores，但在复杂程序中表现较差，且未能完全理解跨语言代码克隆的含义。相比之下，embedding models生成的代码表示能训练一个基本分类器，在XLCoST上比LLMs高约1%，在CodeNet上高约20%，表明嵌入模型提供更适合的表示以实现最先进性能。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted for publication at the ACM International Conference on the\n  Foundations of Software Engineering (FSE) 2025",
      "pdf_url": "http://arxiv.org/pdf/2408.04430v3",
      "published_date": "2024-08-08 12:57:14 UTC",
      "updated_date": "2025-05-06 12:19:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:51:00.087576"
    },
    {
      "arxiv_id": "2408.04414v1",
      "title": "Enhancing Robustness of Retrieval-Augmented Language Models with In-Context Learning",
      "title_zh": "通过上下文学习增强检索增强语言模型的鲁棒性",
      "authors": [
        "Seong-Il Park",
        "Seung-Woo Choi",
        "Na-Hyun Kim",
        "Jay-Yoon Lee"
      ],
      "abstract": "Retrieval-Augmented Language Models (RALMs) have significantly improved\nperformance in open-domain question answering (QA) by leveraging external\nknowledge. However, RALMs still struggle with unanswerable queries, where the\nretrieved contexts do not contain the correct answer, and with conflicting\ninformation, where different sources provide contradictory answers due to\nimperfect retrieval. This study introduces an in-context learning-based\napproach to enhance the reasoning capabilities of RALMs, making them more\nrobust in imperfect retrieval scenarios. Our method incorporates Machine\nReading Comprehension (MRC) demonstrations, referred to as cases, to boost the\nmodel's capabilities to identify unanswerabilities and conflicts among the\nretrieved contexts. Experiments on two open-domain QA datasets show that our\napproach increases accuracy in identifying unanswerable and conflicting\nscenarios without requiring additional fine-tuning. This work demonstrates that\nin-context learning can effectively enhance the robustness of RALMs in\nopen-domain QA tasks.",
      "tldr_zh": "本研究针对Retrieval-Augmented Language Models (RALMs)在开放域问答任务中处理无法回答的查询和冲突信息时的不足，提出了一种基于In-Context Learning的方法来提升其鲁棒性。该方法通过整合Machine Reading Comprehension (MRC) demonstrations（即案例），帮助模型更好地识别检索内容中的不可回答性和矛盾点，从而增强推理能力。在两个开放域QA数据集上的实验显示，该方法无需额外fine-tuning即可显著提高准确率，证明In-Context Learning能有效增强RALMs的可靠性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.04414v1",
      "published_date": "2024-08-08 12:42:43 UTC",
      "updated_date": "2024-08-08 12:42:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:51:11.281974"
    },
    {
      "arxiv_id": "2408.04405v3",
      "title": "Probabilistic energy forecasting through quantile regression in reproducing kernel Hilbert spaces",
      "title_zh": "翻译失败",
      "authors": [
        "Luca Pernigo",
        "Rohan Sen",
        "Davide Baroli"
      ],
      "abstract": "Accurate energy demand forecasting is crucial for sustainable and resilient\nenergy development. To meet the Net Zero Representative Concentration Pathways\n(RCP) $4.5$ scenario in the DACH countries, increased renewable energy\nproduction, energy storage, and reduced commercial building consumption are\nneeded. This scenario's success depends on hydroelectric capacity and climatic\nfactors. Informed decisions require quantifying uncertainty in forecasts. This\nstudy explores a non-parametric method based on \\emph{reproducing kernel\nHilbert spaces (RKHS)}, known as kernel quantile regression, for energy\nprediction. Our experiments demonstrate its reliability and sharpness, and we\nbenchmark it against state-of-the-art methods in load and price forecasting for\nthe DACH region. We offer our implementation in conjunction with additional\nscripts to ensure the reproducibility of our research.",
      "tldr_zh": "本研究强调准确的能源需求预测对于实现 Net Zero RCP 4.5 场景在 DACH 国家至关重要，该场景依赖于增加可再生能源生产、能源存储和减少商业建筑消耗，同时受水电容量和气候因素影响。研究提出了一种基于 Reproducing Kernel Hilbert Spaces (RKHS) 的非参数方法，即 Kernel Quantile Regression，用于量化预测不确定性。实验结果显示，该方法在 DACH 地区的负载和价格预测中表现出可靠性和精确性，并优于现有基准方法；此外，研究提供了可重复的实现代码以支持进一步验证。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SY",
        "eess.SY",
        "I.2; G.4"
      ],
      "primary_category": "cs.LG",
      "comment": "12 pages, {Owner/Author | ACM} {2024}. This is the author's version\n  of the work. It is posted here for your personal use. Not for redistribution.\n  The definitive Version of Record will published in https://energy.acm.org/eir",
      "pdf_url": "http://arxiv.org/pdf/2408.04405v3",
      "published_date": "2024-08-08 12:14:17 UTC",
      "updated_date": "2024-09-16 14:30:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:51:24.628824"
    },
    {
      "arxiv_id": "2408.04689v2",
      "title": "Design of a Quality Management System based on the EU Artificial Intelligence Act",
      "title_zh": "翻译失败",
      "authors": [
        "Henryk Mustroph",
        "Stefanie Rinderle-Ma"
      ],
      "abstract": "The EU AI Act mandates that providers and deployers of high-risk AI systems\nestablish a quality management system (QMS). Among other criteria, a QMS shall\nhelp verify and document the AI system design and quality and monitor the\nproper implementation of all high-risk AI system requirements. Current research\nrarely explores practical solutions for implementing the EU AI Act. Instead, it\ntends to focus on theoretical concepts. As a result, more attention must be\npaid to tools that help humans actively check and document AI systems and\norchestrate the implementation of all high-risk AI system requirements.\nTherefore, this paper introduces a new design concept and prototype for a QMS\nas a microservice Software as a Service web application. It connects directly\nto the AI system for verification and documentation and enables the\norchestration and integration of various sub-services, which can be\nindividually designed, each tailored to specific high-risk AI system\nrequirements. The first version of the prototype connects to the\nPhi-3-mini-128k-instruct LLM as an example of an AI system and integrates a\nrisk management system and a data management system. The prototype is evaluated\nthrough a qualitative assessment of the implemented requirements, a GPU memory\nand performance analysis, and an evaluation with IT, AI, and legal experts.",
      "tldr_zh": "该论文基于 EU Artificial Intelligence Act 设计了一个质量管理系统 (QMS)，旨在帮助验证、记录高风险 AI 系统的设计和实施，并协调相关要求。QMS 采用微服务 Software as a Service 网络应用形式，直接连接 AI 系统（如 Phi-3-mini-128k-instruct LLM），并整合风险管理和数据管理系统，以实现个性化子服务的灵活配置。原型通过定性评估、GPU 内存和性能分析以及 IT、AI 和法律专家的评估，证明了其在提升 AI 系统合规性和实用性方面的有效性。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.04689v2",
      "published_date": "2024-08-08 12:14:02 UTC",
      "updated_date": "2024-11-12 13:37:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:51:35.810315"
    },
    {
      "arxiv_id": "2408.04403v1",
      "title": "Exploring Reasoning Biases in Large Language Models Through Syllogism: Insights from the NeuBAROCO Dataset",
      "title_zh": "通过三段论探索大型语言模型中的推理偏差：来自 NeuBAROCO 数据集的洞见",
      "authors": [
        "Kentaro Ozeki",
        "Risako Ando",
        "Takanobu Morishita",
        "Hirohiko Abe",
        "Koji Mineshima",
        "Mitsuhiro Okada"
      ],
      "abstract": "This paper explores the question of how accurately current large language\nmodels can perform logical reasoning in natural language, with an emphasis on\nwhether these models exhibit reasoning biases similar to humans. Specifically,\nour study focuses on syllogistic reasoning, a form of deductive reasoning\nextensively studied in cognitive science as a natural form of human reasoning.\nWe present a syllogism dataset called NeuBAROCO, which consists of syllogistic\nreasoning problems in English and Japanese. This dataset was originally\ndesigned for psychological experiments to assess human reasoning capabilities\nusing various forms of syllogisms. Our experiments with leading large language\nmodels indicate that these models exhibit reasoning biases similar to humans,\nalong with other error tendencies. Notably, there is significant room for\nimprovement in reasoning problems where the relationship between premises and\nhypotheses is neither entailment nor contradiction. We also present\nexperimental results and in-depth analysis using a new Chain-of-Thought\nprompting method, which asks LLMs to translate syllogisms into abstract logical\nexpressions and then explain their reasoning process. Our analysis using this\nmethod suggests that the primary limitations of LLMs lie in the reasoning\nprocess itself rather than the interpretation of syllogisms.",
      "tldr_zh": "本研究探讨了大型语言模型（LLMs）在三段论推理中的表现，重点考察其是否像人类一样存在推理偏差，并引入 NeuBAROCO 数据集，该数据集包含英语和日语的三段论问题。研究通过实验发现，LLMs 表现出与人类相似的推理偏差，尤其在前提与假设关系非蕴涵或矛盾的情况下存在显著改进空间。作者采用新的 Chain-of-Thought 提示方法，要求模型将三段论翻译成抽象逻辑表达式并解释推理过程，结果表明 LLMs 的主要局限性在于推理过程本身而非对三段论的解释。总的来说，此工作为提升 LLMs 的逻辑推理能力提供了宝贵洞见。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "To appear in Findings of the Association for Computational\n  Linguistics: ACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.04403v1",
      "published_date": "2024-08-08 12:10:50 UTC",
      "updated_date": "2024-08-08 12:10:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:51:49.095565"
    },
    {
      "arxiv_id": "2408.04400v1",
      "title": "DIVE: Subgraph Disagreement for Graph Out-of-Distribution Generalization",
      "title_zh": "翻译失败",
      "authors": [
        "Xin Sun",
        "Liang Wang",
        "Qiang Liu",
        "Shu Wu",
        "Zilei Wang",
        "Liang Wang"
      ],
      "abstract": "This paper addresses the challenge of out-of-distribution (OOD)\ngeneralization in graph machine learning, a field rapidly advancing yet\ngrappling with the discrepancy between source and target data distributions.\nTraditional graph learning algorithms, based on the assumption of uniform\ndistribution between training and test data, falter in real-world scenarios\nwhere this assumption fails, resulting in suboptimal performance. A principal\nfactor contributing to this suboptimal performance is the inherent simplicity\nbias of neural networks trained through Stochastic Gradient Descent (SGD),\nwhich prefer simpler features over more complex yet equally or more predictive\nones. This bias leads to a reliance on spurious correlations, adversely\naffecting OOD performance in various tasks such as image recognition, natural\nlanguage understanding, and graph classification. Current methodologies,\nincluding subgraph-mixup and information bottleneck approaches, have achieved\npartial success but struggle to overcome simplicity bias, often reinforcing\nspurious correlations. To tackle this, we propose DIVE, training a collection\nof models to focus on all label-predictive subgraphs by encouraging the models\nto foster divergence on the subgraph mask, which circumvents the limitation of\na model solely focusing on the subgraph corresponding to simple structural\npatterns. Specifically, we employs a regularizer to punish overlap in extracted\nsubgraphs across models, thereby encouraging different models to concentrate on\ndistinct structural patterns. Model selection for robust OOD performance is\nachieved through validation accuracy. Tested across four datasets from GOOD\nbenchmark and one dataset from DrugOOD benchmark, our approach demonstrates\nsignificant improvement over existing methods, effectively addressing the\nsimplicity bias and enhancing generalization in graph machine learning.",
      "tldr_zh": "这篇论文针对图机器学习中的 Out-of-Distribution (OOD) 泛化挑战，提出 DIVE 方法来克服神经网络的 simplicity bias 和对 spurious correlations 的依赖。DIVE 通过训练多个模型，鼓励它们在 subgraph mask 上产生分歧，使用一个 regularizer 惩罚模型之间提取子图的重叠，从而使每个模型关注不同的标签预测结构模式。实验结果显示，在 GOOD 基准的四个数据集和 DrugOOD 基准的一个数据集上，DIVE 显著提高了性能，增强了图机器学习的泛化能力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.04400v1",
      "published_date": "2024-08-08 12:08:55 UTC",
      "updated_date": "2024-08-08 12:08:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:52:11.455466"
    },
    {
      "arxiv_id": "2408.04394v1",
      "title": "Automated Educational Question Generation at Different Bloom's Skill Levels using Large Language Models: Strategies and Evaluation",
      "title_zh": "翻译失败",
      "authors": [
        "Nicy Scaria",
        "Suma Dharani Chenna",
        "Deepak Subramani"
      ],
      "abstract": "Developing questions that are pedagogically sound, relevant, and promote\nlearning is a challenging and time-consuming task for educators. Modern-day\nlarge language models (LLMs) generate high-quality content across multiple\ndomains, potentially helping educators to develop high-quality questions.\nAutomated educational question generation (AEQG) is important in scaling online\neducation catering to a diverse student population. Past attempts at AEQG have\nshown limited abilities to generate questions at higher cognitive levels. In\nthis study, we examine the ability of five state-of-the-art LLMs of different\nsizes to generate diverse and high-quality questions of different cognitive\nlevels, as defined by Bloom's taxonomy. We use advanced prompting techniques\nwith varying complexity for AEQG. We conducted expert and LLM-based evaluations\nto assess the linguistic and pedagogical relevance and quality of the\nquestions. Our findings suggest that LLms can generate relevant and\nhigh-quality educational questions of different cognitive levels when prompted\nwith adequate information, although there is a significant variance in the\nperformance of the five LLms considered. We also show that automated evaluation\nis not on par with human evaluation.",
      "tldr_zh": "本研究探讨了使用Large Language Models (LLMs)自动生成不同Bloom's taxonomy认知水平教育问题的策略和评估方法，以帮助教育者创建高质量问题。研究者测试了五种不同规模的LLMs，采用高级提示技巧生成问题，并通过专家和LLM-based评估来检查问题的语言和教学相关性。结果表明，LLMs在提供足够信息时能生成相关高质量问题，但各模型性能存在显著差异，且自动评估不如人工评估准确。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.04394v1",
      "published_date": "2024-08-08 11:56:57 UTC",
      "updated_date": "2024-08-08 11:56:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:52:11.015722"
    },
    {
      "arxiv_id": "2408.05247v1",
      "title": "Early-Exit meets Model-Distributed Inference at Edge Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Marco Colocrese",
        "Erdem Koyuncu",
        "Hulya Seferoglu"
      ],
      "abstract": "Distributed inference techniques can be broadly classified into\ndata-distributed and model-distributed schemes. In data-distributed inference\n(DDI), each worker carries the entire deep neural network (DNN) model but\nprocesses only a subset of the data. However, feeding the data to workers\nresults in high communication costs, especially when the data is large. An\nemerging paradigm is model-distributed inference (MDI), where each worker\ncarries only a subset of DNN layers. In MDI, a source device that has data\nprocesses a few layers of DNN and sends the output to a neighboring device,\ni.e., offloads the rest of the layers. This process ends when all layers are\nprocessed in a distributed manner. In this paper, we investigate the design and\ndevelopment of MDI with early-exit, which advocates that there is no need to\nprocess all the layers of a model for some data to reach the desired accuracy,\ni.e., we can exit the model without processing all the layers if target\naccuracy is reached. We design a framework MDI-Exit that adaptively determines\nearly-exit and offloading policies as well as data admission at the source.\nExperimental results on a real-life testbed of NVIDIA Nano edge devices show\nthat MDI-Exit processes more data when accuracy is fixed and results in higher\naccuracy for the fixed data rate.",
      "tldr_zh": "该论文探讨了模型分布式推理(MDI)与early-exit技术的结合，以优化边缘网络上的深度神经网络(DNN)推理。MDI允许每个设备仅处理DNN层子集，通过卸载剩余层来分担计算，而early-exit则在达到目标准确率时提前退出模型，避免不必要处理。作者设计了MDI-Exit框架，能够自适应地决定early-exit策略、卸载政策和数据准入策略。实验在NVIDIA Nano边缘设备上表明，该框架在固定准确率下处理更多数据，并在固定数据率下实现更高准确率，从而提升了边缘推理的效率和性能。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.LG",
        "cs.NI"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.05247v1",
      "published_date": "2024-08-08 11:53:32 UTC",
      "updated_date": "2024-08-08 11:53:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:52:24.541117"
    },
    {
      "arxiv_id": "2408.04388v1",
      "title": "MM-Forecast: A Multimodal Approach to Temporal Event Forecasting with Large Language Models",
      "title_zh": "MM-Forecast：一种利用大型语言模型的多模态时间事件预测方法",
      "authors": [
        "Haoxuan Li",
        "Zhengmao Yang",
        "Yunshan Ma",
        "Yi Bin",
        "Yang Yang",
        "Tat-Seng Chua"
      ],
      "abstract": "We study an emerging and intriguing problem of multimodal temporal event\nforecasting with large language models. Compared to using text or graph\nmodalities, the investigation of utilizing images for temporal event\nforecasting has not been fully explored, especially in the era of large\nlanguage models (LLMs). To bridge this gap, we are particularly interested in\ntwo key questions of: 1) why images will help in temporal event forecasting,\nand 2) how to integrate images into the LLM-based forecasting framework. To\nanswer these research questions, we propose to identify two essential functions\nthat images play in the scenario of temporal event forecasting, i.e.,\nhighlighting and complementary. Then, we develop a novel framework, named\nMM-Forecast. It employs an Image Function Identification module to recognize\nthese functions as verbal descriptions using multimodal large language models\n(MLLMs), and subsequently incorporates these function descriptions into\nLLM-based forecasting models. To evaluate our approach, we construct a new\nmultimodal dataset, MidEast-TE-mm, by extending an existing event dataset\nMidEast-TE-mini with images. Empirical studies demonstrate that our MM-Forecast\ncan correctly identify the image functions, and further more, incorporating\nthese verbal function descriptions significantly improves the forecasting\nperformance. The dataset, code, and prompts are available at\nhttps://github.com/LuminosityX/MM-Forecast.",
      "tldr_zh": "本研究探讨了利用多模态数据进行时间事件预测的问题，特别是如何整合图像来提升基于Large Language Models (LLMs) 的预测框架。研究者识别出图像在预测中的两个关键功能：highlighting（突出）和complementary（补充），并提出MM-Forecast框架，该框架使用Multimodal Large Language Models (MLLMs) 的Image Function Identification模块生成这些功能的文字描述，然后将其融入LLM-based模型中。为验证方法，他们构建了新数据集MidEast-TE-mm，通过添加图像扩展现有数据集。实验结果显示，MM-Forecast能准确识别图像功能，并显著提高预测性能，为多模态事件预测提供了新途径。",
      "categories": [
        "cs.MM",
        "cs.AI",
        "cs.IR",
        "H.3.3"
      ],
      "primary_category": "cs.MM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.04388v1",
      "published_date": "2024-08-08 11:44:57 UTC",
      "updated_date": "2024-08-08 11:44:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:52:36.293864"
    },
    {
      "arxiv_id": "2408.04385v2",
      "title": "Non-maximizing policies that fulfill multi-criterion aspirations in expectation",
      "title_zh": "翻译失败",
      "authors": [
        "Simon Dima",
        "Simon Fischer",
        "Jobst Heitzig",
        "Joss Oliver"
      ],
      "abstract": "In dynamic programming and reinforcement learning, the policy for the\nsequential decision making of an agent in a stochastic environment is usually\ndetermined by expressing the goal as a scalar reward function and seeking a\npolicy that maximizes the expected total reward. However, many goals that\nhumans care about naturally concern multiple aspects of the world, and it may\nnot be obvious how to condense those into a single reward function.\nFurthermore, maximization suffers from specification gaming, where the obtained\npolicy achieves a high expected total reward in an unintended way, often taking\nextreme or nonsensical actions.\n  Here we consider finite acyclic Markov Decision Processes with multiple\ndistinct evaluation metrics, which do not necessarily represent quantities that\nthe user wants to be maximized. We assume the task of the agent is to ensure\nthat the vector of expected totals of the evaluation metrics falls into some\ngiven convex set, called the aspiration set. Our algorithm guarantees that this\ntask is fulfilled by using simplices to approximate feasibility sets and\npropagate aspirations forward while ensuring they remain feasible. It has\ncomplexity linear in the number of possible state-action-successor triples and\npolynomial in the number of evaluation metrics. Moreover, the explicitly\nnon-maximizing nature of the chosen policy and goals yields additional degrees\nof freedom, which can be used to apply heuristic safety criteria to the choice\nof actions. We discuss several such safety criteria that aim to steer the agent\ntowards more conservative behavior.",
      "tldr_zh": "本文研究了动态规划和强化学习中的策略问题，传统方法依赖最大化期望总奖励，但这可能无法处理人类的多方面目标（如多个评估指标），并易导致规格游戏（specification gaming）。作者提出了一种非最大化策略，针对有限无环 Markov Decision Processes，确保多个评估指标的期望向量落入预定义的凸集（aspiration set），通过使用 simplices 近似可行集并向前传播期望来实现。算法复杂度线性于状态-动作-后继三元组数量，且多项式于评估指标数量，同时利用额外自由度应用启发式安全标准，以引导代理行为更保守。",
      "categories": [
        "cs.AI",
        "econ.TH",
        "math.OC",
        "68T20, 90C40, 91B06",
        "I.2.8; F.2.2"
      ],
      "primary_category": "cs.AI",
      "comment": "15 pages main text + 4 pages supplement. Slightly corrected version\n  (corrections in blue in Eq. 11)",
      "pdf_url": "http://arxiv.org/pdf/2408.04385v2",
      "published_date": "2024-08-08 11:41:04 UTC",
      "updated_date": "2025-02-25 14:03:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:52:50.002637"
    },
    {
      "arxiv_id": "2408.04382v1",
      "title": "Judgment2vec: Apply Graph Analytics to Searching and Recommendation of Similar Judgments",
      "title_zh": "翻译失败",
      "authors": [
        "Hsuan-Lei Shao"
      ],
      "abstract": "In court practice, legal professionals rely on their training to provide\nopinions that resolve cases, one of the most crucial aspects being the ability\nto identify similar judgments from previous courts efficiently. However,\nfinding a similar case is challenging and often depends on experience, legal\ndomain knowledge, and extensive labor hours, making veteran lawyers or judges\nindispensable. This research aims to automate the analysis of judgment text\nsimilarity. We utilized a judgment dataset labeled as the \"golden standard\" by\nexperts, which includes human-verified features that can be converted into an\n\"expert similarity score.\" We then constructed a knowledge graph based on\n\"case-article\" relationships, ranking each case using natural language\nprocessing to derive a \"Node2vec similarity score.\" By evaluating these two\nsimilarity scores, we identified their discrepancies and relationships. The\nresults can significantly reduce the labor hours required for legal searches\nand recommendations, with potential applications extending to various fields of\ninformation retrieval.",
      "tldr_zh": "这篇论文提出了 Judgment2vec 方法，利用 Graph Analytics 技术来自动化法律判决的搜索和推荐，旨在解决传统依赖经验和大量人力来识别类似判决的挑战。研究团队使用一个由专家标记的“黄金标准”数据集，构建基于“case-article”关系的 Knowledge Graph，并结合 Natural Language Processing 和 Node2vec 算法计算“Node2vec similarity score”，并与“expert similarity score”进行比较分析。结果显示，这种方法能显著减少法律搜索和推荐所需的工作时间，并具有扩展到其他信息检索领域的潜力。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "68T30 (Primary), 68T50 (Secondary)",
        "I.2.7; I.2.4"
      ],
      "primary_category": "cs.IR",
      "comment": "5 pages, 7 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2408.04382v1",
      "published_date": "2024-08-08 11:37:32 UTC",
      "updated_date": "2024-08-08 11:37:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:53:00.278167"
    },
    {
      "arxiv_id": "2408.04377v3",
      "title": "Anomaly Prediction: A Novel Approach with Explicit Delay and Horizon",
      "title_zh": "翻译失败",
      "authors": [
        "Jiang You",
        "Arben Cela",
        "René Natowicz",
        "Jacob Ouanounou",
        "Patrick Siarry"
      ],
      "abstract": "Anomaly detection in time series data is a critical challenge across various\ndomains. Traditional methods typically focus on identifying anomalies in\nimmediate subsequent steps, often underestimating the significance of temporal\ndynamics such as delay time and horizons of anomalies, which generally require\nextensive post-analysis. This paper introduces a novel approach for time series\nanomaly prediction, incorporating temporal information directly into the\nprediction results. We propose a new dataset specifically designed to evaluate\nthis approach and conduct comprehensive experiments using several\nstate-of-the-art methods. Our results demonstrate the efficacy of our approach\nin providing timely and accurate anomaly predictions, setting a new benchmark\nfor future research in this field.",
      "tldr_zh": "这篇论文提出了一种新型时间序列异常预测方法，通过显式整合延迟(delay)和地平线(horizon)，直接将时间动态信息纳入预测结果，以解决传统方法忽略这些因素的问题。研究者创建了一个专用数据集，并使用多种最先进的方法进行了全面实验。结果表明，该方法显著提高了异常预测的及时性和准确性，为该领域设定了新基准。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.04377v3",
      "published_date": "2024-08-08 11:22:52 UTC",
      "updated_date": "2024-10-23 14:29:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:53:11.257657"
    },
    {
      "arxiv_id": "2408.04349v1",
      "title": "Optimal Layout-Aware CNOT Circuit Synthesis with Qubit Permutation",
      "title_zh": "翻译失败",
      "authors": [
        "Irfansha Shaik",
        "Jaco van de Pol"
      ],
      "abstract": "CNOT optimization plays a significant role in noise reduction for Quantum\nCircuits. Several heuristic and exact approaches exist for CNOT optimization.\nIn this paper, we investigate more complicated variations of optimal synthesis\nby allowing qubit permutations and handling layout restrictions. We encode such\nproblems into Planning, SAT, and QBF. We provide optimization for both CNOT\ngate count and circuit depth. For experimental evaluation, we consider standard\nT-gate optimized benchmarks and optimize CNOT sub-circuits. We show that\nallowing qubit permutations can further reduce up to 56% in CNOT count and 46%\nin circuit depth. In the case of optimally mapped circuits under layout\nrestrictions, we observe a reduction up to 17% CNOT count and 19% CNOT depth.",
      "tldr_zh": "这篇论文探讨了量子电路中CNOT优化的复杂变体，通过允许qubit permutations和处理layout restrictions来进一步减少噪声。研究团队将这些问题编码成Planning、SAT和QBF形式，并针对CNOT gate count和circuit depth进行优化。实验结果显示，引入qubit permutations可将CNOT计数减少高达56%且电路深度减少46%；在布局限制下，最优映射也能实现高达17%的CNOT计数减少和19%的深度减少。",
      "categories": [
        "quant-ph",
        "cs.AI"
      ],
      "primary_category": "quant-ph",
      "comment": "9 pages, 12 tables",
      "pdf_url": "http://arxiv.org/pdf/2408.04349v1",
      "published_date": "2024-08-08 10:20:13 UTC",
      "updated_date": "2024-08-08 10:20:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:53:23.807099"
    },
    {
      "arxiv_id": "2408.04342v1",
      "title": "Towards Explainable Network Intrusion Detection using Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Paul R. B. Houssel",
        "Priyanka Singh",
        "Siamak Layeghy",
        "Marius Portmann"
      ],
      "abstract": "Large Language Models (LLMs) have revolutionised natural language processing\ntasks, particularly as chat agents. However, their applicability to threat\ndetection problems remains unclear. This paper examines the feasibility of\nemploying LLMs as a Network Intrusion Detection System (NIDS), despite their\nhigh computational requirements, primarily for the sake of explainability.\nFurthermore, considerable resources have been invested in developing LLMs, and\nthey may offer utility for NIDS. Current state-of-the-art NIDS rely on\nartificial benchmarking datasets, resulting in skewed performance when applied\nto real-world networking environments. Therefore, we compare the GPT-4 and\nLLama3 models against traditional architectures and transformer-based models to\nassess their ability to detect malicious NetFlows without depending on\nartificially skewed datasets, but solely on their vast pre-trained acquired\nknowledge. Our results reveal that, although LLMs struggle with precise attack\ndetection, they hold significant potential for a path towards explainable NIDS.\nOur preliminary exploration shows that LLMs are unfit for the detection of\nMalicious NetFlows. Most promisingly, however, these exhibit significant\npotential as complementary agents in NIDS, particularly in providing\nexplanations and aiding in threat response when integrated with Retrieval\nAugmented Generation (RAG) and function calling capabilities.",
      "tldr_zh": "本研究探讨了使用大型语言模型 (LLMs) 来实现可解释的网络入侵检测系统 (NIDS)，旨在解决传统模型依赖人工数据集导致的性能偏差问题。通过比较 GPT-4 和 Llama3 与传统架构和 Transformer 模型，评估了 LLMs 在检测恶意 NetFlows 的能力。结果表明，LLMs 在精确攻击检测上表现不佳，但具有显著潜力作为补充工具，提供解释并辅助威胁响应，尤其是结合检索增强生成 (RAG) 和函数调用功能。总的来说，这为开发可解释 NIDS 提供了新路径。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.NI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.04342v1",
      "published_date": "2024-08-08 09:59:30 UTC",
      "updated_date": "2024-08-08 09:59:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:53:37.718703"
    },
    {
      "arxiv_id": "2408.04336v1",
      "title": "KnowPC: Knowledge-Driven Programmatic Reinforcement Learning for Zero-shot Coordination",
      "title_zh": "KnowPC：知识驱动的程序化强化学习用于零样本协调",
      "authors": [
        "Yin Gu",
        "Qi Liu",
        "Zhi Li",
        "Kai Zhang"
      ],
      "abstract": "Zero-shot coordination (ZSC) remains a major challenge in the cooperative AI\nfield, which aims to learn an agent to cooperate with an unseen partner in\ntraining environments or even novel environments. In recent years, a popular\nZSC solution paradigm has been deep reinforcement learning (DRL) combined with\nadvanced self-play or population-based methods to enhance the neural policy's\nability to handle unseen partners. Despite some success, these approaches\nusually rely on black-box neural networks as the policy function. However,\nneural networks typically lack interpretability and logic, making the learned\npolicies difficult for partners (e.g., humans) to understand and limiting their\ngeneralization ability. These shortcomings hinder the application of\nreinforcement learning methods in diverse cooperative scenarios.We suggest to\nrepresent the agent's policy with an interpretable program. Unlike neural\nnetworks, programs contain stable logic, but they are non-differentiable and\ndifficult to optimize.To automatically learn such programs, we introduce\nKnowledge-driven Programmatic reinforcement learning for zero-shot Coordination\n(KnowPC). We first define a foundational Domain-Specific Language (DSL),\nincluding program structures, conditional primitives, and action primitives. A\nsignificant challenge is the vast program search space, making it difficult to\nfind high-performing programs efficiently. To address this, KnowPC integrates\nan extractor and an reasoner. The extractor discovers environmental transition\nknowledge from multi-agent interaction trajectories, while the reasoner deduces\nthe preconditions of each action primitive based on the transition knowledge.",
      "tldr_zh": "这篇论文针对 Zero-shot Coordination (ZSC) 挑战，提出 KnowPC 框架——一种知识驱动的程序化强化学习方法，以可解释的程序代替传统黑盒神经网络，提升代理与未见伙伴的合作能力。KnowPC 定义了一个 Domain-Specific Language (DSL)，包括程序结构、条件原语和动作原语，并通过提取器从多代理交互轨迹中发现环境转换知识，以及推理器基于这些知识推断动作原语的前提条件。相比深度强化学习 (DRL) 的局限性，该方法提高了政策的逻辑性和泛化性，为多样化合作场景的应用提供了新途径。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.04336v1",
      "published_date": "2024-08-08 09:43:54 UTC",
      "updated_date": "2024-08-08 09:43:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:53:58.784608"
    },
    {
      "arxiv_id": "2408.04686v1",
      "title": "Multi-Turn Context Jailbreak Attack on Large Language Models From First Principles",
      "title_zh": "翻译失败",
      "authors": [
        "Xiongtao Sun",
        "Deyue Zhang",
        "Dongdong Yang",
        "Quanchen Zou",
        "Hui Li"
      ],
      "abstract": "Large language models (LLMs) have significantly enhanced the performance of\nnumerous applications, from intelligent conversations to text generation.\nHowever, their inherent security vulnerabilities have become an increasingly\nsignificant challenge, especially with respect to jailbreak attacks. Attackers\ncan circumvent the security mechanisms of these LLMs, breaching security\nconstraints and causing harmful outputs. Focusing on multi-turn semantic\njailbreak attacks, we observe that existing methods lack specific\nconsiderations for the role of multiturn dialogues in attack strategies,\nleading to semantic deviations during continuous interactions. Therefore, in\nthis paper, we establish a theoretical foundation for multi-turn attacks by\nconsidering their support in jailbreak attacks, and based on this, propose a\ncontext-based contextual fusion black-box jailbreak attack method, named\nContext Fusion Attack (CFA). This method approach involves filtering and\nextracting key terms from the target, constructing contextual scenarios around\nthese terms, dynamically integrating the target into the scenarios, replacing\nmalicious key terms within the target, and thereby concealing the direct\nmalicious intent. Through comparisons on various mainstream LLMs and red team\ndatasets, we have demonstrated CFA's superior success rate, divergence, and\nharmfulness compared to other multi-turn attack strategies, particularly\nshowcasing significant advantages on Llama3 and GPT-4.",
      "tldr_zh": "这篇论文探讨了大型语言模型(LLMs)面对多轮语义jailbreak attacks的安全漏洞，强调现有攻击方法忽略了多轮对话的语义偏差问题。作者从理论基础出发，建立了多轮攻击的支持框架，并提出了一种黑盒攻击方法Context Fusion Attack (CFA)，该方法通过过滤提取目标关键术语、构建上下文场景、动态整合目标以及替换恶意关键术语来隐藏直接恶意意图。实验结果显示，CFA在主流LLMs（如Llama3和GPT-4）以及红队数据集上，比其他多轮攻击策略具有更高的成功率、发散性和有害性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.04686v1",
      "published_date": "2024-08-08 09:18:47 UTC",
      "updated_date": "2024-08-08 09:18:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:54:00.057913"
    },
    {
      "arxiv_id": "2408.04304v1",
      "title": "Learning with Digital Agents: An Analysis based on the Activity Theory",
      "title_zh": "翻译失败",
      "authors": [
        "Mateusz Dolata",
        "Dzmitry Katsiuba",
        "Natalie Wellnhammer",
        "Gerhard Schwabe"
      ],
      "abstract": "Digital agents are considered a general-purpose technology. They spread\nquickly in private and organizational contexts, including education. Yet,\nresearch lacks a conceptual framing to describe interaction with such agents in\na holistic manner. While focusing on the interaction with a pedagogical agent,\ni.e., a digital agent capable of natural-language interaction with a learner,\nwe propose a model of learning activity based on activity theory. We use this\nmodel and a review of prior research on digital agents in education to analyze\nhow various characteristics of the activity, including features of a\npedagogical agent or learner, influence learning outcomes. The analysis leads\nto identification of IS research directions and guidance for developers of\npedagogical agents and digital agents in general. We conclude by extending the\nactivity theory-based model beyond the context of education and show how it\nhelps designers and researchers ask the right questions when creating a digital\nagent.",
      "tldr_zh": "这篇论文基于Activity Theory提出一个学习活动模型，用于整体分析与数字代理的互动，特别聚焦于Pedagogical Agent（教学代理），即能进行自然语言互动的数字代理。研究通过文献综述和模型分析，探讨代理特性、学习者特征等因素如何影响学习成果，并识别了信息系统（IS）研究方向和开发指导。最终，该模型扩展到教育以外的领域，帮助设计师和研究者提出关键问题以优化数字代理的设计。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "Authors manuscript accepted for publication in Journal of Management\n  Information Systems",
      "pdf_url": "http://arxiv.org/pdf/2408.04304v1",
      "published_date": "2024-08-08 08:38:02 UTC",
      "updated_date": "2024-08-08 08:38:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:54:11.344745"
    },
    {
      "arxiv_id": "2408.05246v1",
      "title": "Differentially Private Data Release on Graphs: Inefficiencies and Unfairness",
      "title_zh": "基于图的差分隐私数据发布：低效性和不公平性",
      "authors": [
        "Ferdinando Fioretto",
        "Diptangshu Sen",
        "Juba Ziani"
      ],
      "abstract": "Networks are crucial components of many sectors, including\ntelecommunications, healthcare, finance, energy, and transportation.The\ninformation carried in such networks often contains sensitive user data, like\nlocation data for commuters and packet data for online users. Therefore, when\nconsidering data release for networks, one must ensure that data release\nmechanisms do not leak information about individuals, quantified in a precise\nmathematical sense. Differential Privacy (DP) is the widely accepted, formal,\nstate-of-the-art technique, which has found use in a variety of real-life\nsettings including the 2020 U.S. Census, Apple users' device data, or Google's\nlocation data. Yet, the use of DP comes with new challenges, as the noise added\nfor privacy introduces inaccuracies or biases and further, DP techniques can\nalso distribute these biases disproportionately across different populations,\ninducing fairness issues. The goal of this paper is to characterize the impact\nof DP on bias and unfairness in the context of releasing information about\nnetworks, taking a departure from previous work which has studied these effects\nin the context of private population counts release (such as in the U.S.\nCensus). To this end, we consider a network release problem where the network\nstructure is known to all, but the weights on edges must be released privately.\nWe consider the impact of this private release on a simple downstream\ndecision-making task run by a third-party, which is to find the shortest path\nbetween any two pairs of nodes and recommend the best route to users. This\nsetting is of highly practical relevance, mirroring scenarios in transportation\nnetworks, where preserving privacy while providing accurate routing information\nis crucial. Our work provides theoretical foundations and empirical evidence\ninto the bias and unfairness arising due to privacy in these networked decision\nproblems.",
      "tldr_zh": "这篇论文探讨了在图数据发布中应用 Differential Privacy (DP) 所引发的效率低下和不公平问题，特别是针对网络中敏感信息的保护。研究聚焦于一种场景，其中网络结构公开，但边权重需通过 DP 私密发布，并分析其对下游决策任务（如计算最短路径并推荐路由）的影响。作者通过理论分析和实证证据，展示了 DP 引入的噪声如何导致偏差和不均等分布，强调了在交通等实际网络应用中隐私保护的潜在挑战，并为优化此类问题提供了基础。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "32 pages",
      "pdf_url": "http://arxiv.org/pdf/2408.05246v1",
      "published_date": "2024-08-08 08:37:37 UTC",
      "updated_date": "2024-08-08 08:37:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:54:23.932944"
    },
    {
      "arxiv_id": "2408.04301v1",
      "title": "Tackling Noisy Clients in Federated Learning with End-to-end Label Correction",
      "title_zh": "翻译失败",
      "authors": [
        "Xuefeng Jiang",
        "Sheng Sun",
        "Jia Li",
        "Jingjing Xue",
        "Runhan Li",
        "Zhiyuan Wu",
        "Gang Xu",
        "Yuwei Wang",
        "Min Liu"
      ],
      "abstract": "Recently, federated learning (FL) has achieved wide successes for diverse\nprivacy-sensitive applications without sacrificing the sensitive private\ninformation of clients. However, the data quality of client datasets can not be\nguaranteed since corresponding annotations of different clients often contain\ncomplex label noise of varying degrees, which inevitably causes the performance\ndegradation. Intuitively, the performance degradation is dominated by clients\nwith higher noise rates since their trained models contain more misinformation\nfrom data, thus it is necessary to devise an effective optimization scheme to\nmitigate the negative impacts of these noisy clients. In this work, we propose\na two-stage framework FedELC to tackle this complicated label noise issue. The\nfirst stage aims to guide the detection of noisy clients with higher label\nnoise, while the second stage aims to correct the labels of noisy clients' data\nvia an end-to-end label correction framework which is achieved by learning\npossible ground-truth labels of noisy clients' datasets via back propagation.\nWe implement sixteen related methods and evaluate five datasets with three\ntypes of complicated label noise scenarios for a comprehensive comparison.\nExtensive experimental results demonstrate our proposed framework achieves\nsuperior performance than its counterparts for different scenarios.\nAdditionally, we effectively improve the data quality of detected noisy\nclients' local datasets with our label correction framework. The code is\navailable at https://github.com/Sprinter1999/FedELC.",
      "tldr_zh": "该研究针对联邦学习（Federated Learning, FL）中客户端数据标签噪声问题，提出了一种两阶段框架 FedELC，以缓解噪声导致的性能下降。第一阶段通过检测机制识别标签噪声较高的客户端，第二阶段则采用端到端标签修正框架，通过反向传播学习可能的真实标签来修正这些客户端的数据。实验在五个数据集和三种复杂噪声场景下评估了 FedELC 与其他十六种方法的性能，结果显示该框架在不同场景下表现出色，并显著提升了噪声客户端的数据质量。代码已开源，可从指定仓库获取。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "To appear in ACM CIKM'24 full research paper track",
      "pdf_url": "http://arxiv.org/pdf/2408.04301v1",
      "published_date": "2024-08-08 08:35:32 UTC",
      "updated_date": "2024-08-08 08:35:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:54:35.950113"
    },
    {
      "arxiv_id": "2408.12609v1",
      "title": "Enhanced Prediction of Multi-Agent Trajectories via Control Inference and State-Space Dynamics",
      "title_zh": "基于控制推理和状态空间动力学的多智能体轨迹增强预测",
      "authors": [
        "Yu Zhang",
        "Yongxiang Zou",
        "Haoyu Zhang",
        "Zeyu Liu",
        "Houcheng Li",
        "Long Cheng"
      ],
      "abstract": "In the field of autonomous systems, accurately predicting the trajectories of\nnearby vehicles and pedestrians is crucial for ensuring both safety and\noperational efficiency. This paper introduces a novel methodology for\ntrajectory forecasting based on state-space dynamic system modeling, which\nendows agents with models that have tangible physical implications. To enhance\nthe precision of state estimations within the dynamic system, the paper also\npresents a novel modeling technique for control variables. This technique\nutilizes a newly introduced model, termed \"Mixed Mamba,\" to derive initial\ncontrol states, thereby improving the predictive accuracy of these variables.\nMoverover, the proposed approach ingeniously integrates graph neural networks\nwith state-space models, effectively capturing the complexities of multi-agent\ninteractions. This combination provides a robust and scalable framework for\nforecasting multi-agent trajectories across a range of scenarios. Comprehensive\nevaluations demonstrate that this model outperforms several established\nbenchmarks across various metrics and datasets, highlighting its significant\npotential to advance trajectory forecasting in autonomous systems.",
      "tldr_zh": "本论文提出了一种增强多智能体轨迹预测的方法，通过状态-space dynamic system建模赋予代理物理含义，并引入Mixed Mamba模型来优化控制变量的估计，从而提高预测精度。该方法巧妙整合graph neural networks与状态-space模型，捕捉多智能体交互的复杂性，提供一个鲁棒且可扩展的框架。实验评估表明，该模型在多种指标和数据集上优于现有基准，提升了自主系统的安全性和效率。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12609v1",
      "published_date": "2024-08-08 08:33:02 UTC",
      "updated_date": "2024-08-08 08:33:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:54:47.893212"
    },
    {
      "arxiv_id": "2408.04683v2",
      "title": "Eliminating Backdoors in Neural Code Models for Secure Code Understanding",
      "title_zh": "消除神经代码模型中的后门以实现安全的代码理解",
      "authors": [
        "Weisong Sun",
        "Yuchen Chen",
        "Chunrong Fang",
        "Yebo Feng",
        "Yuan Xiao",
        "An Guo",
        "Quanjun Zhang",
        "Yang Liu",
        "Baowen Xu",
        "Zhenyu Chen"
      ],
      "abstract": "Neural code models (NCMs) have been widely used to address various code\nunderstanding tasks, such as defect detection. However, numerous recent studies\nreveal that such models are vulnerable to backdoor attacks. Backdoored NCMs\nfunction normally on normal/clean code snippets, but exhibit adversary-expected\nbehavior on poisoned code snippets injected with the adversary-crafted trigger.\nIt poses a significant security threat. Therefore, there is an urgent need for\neffective techniques to detect and eliminate backdoors stealthily implanted in\nNCMs.\n  To address this issue, in this paper, we innovatively propose a backdoor\nelimination technique for secure code understanding, called EliBadCode.\nEliBadCode eliminates backdoors in NCMs by inverting/reverse-engineering and\nunlearning backdoor triggers. Specifically, EliBadCode first filters the model\nvocabulary for trigger tokens based on the naming conventions of specific\nprogramming languages to reduce the trigger search space and cost. Then,\nEliBadCode introduces a sample-specific trigger position identification method,\nwhich can reduce the interference of non-backdoor (adversarial) perturbations\nfor subsequent trigger inversion, thereby producing effective inverted backdoor\ntriggers efficiently. Backdoor triggers can be viewed as backdoor (adversarial)\nperturbations. Subsequently, EliBadCode employs a Greedy Coordinate Gradient\nalgorithm to optimize the inverted trigger and designs a trigger anchoring\nmethod to purify the inverted trigger. Finally, EliBadCode eliminates backdoors\nthrough model unlearning. We evaluate the effectiveness of EliBadCode in\neliminating backdoors implanted in multiple NCMs used for three safety-critical\ncode understanding tasks. The results demonstrate that EliBadCode can\neffectively eliminate backdoors while having minimal adverse effects on the\nnormal functionality of the model.",
      "tldr_zh": "这篇论文针对 Neural Code Models (NCMs) 在代码理解任务（如缺陷检测）中的后门攻击问题，提出了一种名为 EliBadCode 的消除技术，以提升代码理解的安全性。EliBadCode 通过过滤模型词汇以缩小触发器搜索空间、识别触发器位置、使用 Greedy Coordinate Gradient 算法优化和净化触发器，并通过模型取消学习来反转和消除后门。实验结果表明，该方法在多个 NCMs 和三个安全关键任务上有效消除了后门，同时对模型的正常功能影响最小。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.SE",
        "68-06",
        "D.2.3; I.2.2"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted to the 33rd ACM International Conference on the Foundations\n  of Software Engineering (FSE 2025)",
      "pdf_url": "http://arxiv.org/pdf/2408.04683v2",
      "published_date": "2024-08-08 08:23:03 UTC",
      "updated_date": "2025-02-20 06:07:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:55:00.836772"
    },
    {
      "arxiv_id": "2408.04295v3",
      "title": "Assigning Credit with Partial Reward Decoupling in Multi-Agent Proximal Policy Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Aditya Kapoor",
        "Benjamin Freed",
        "Howie Choset",
        "Jeff Schneider"
      ],
      "abstract": "Multi-agent proximal policy optimization (MAPPO) has recently demonstrated\nstate-of-the-art performance on challenging multi-agent reinforcement learning\ntasks. However, MAPPO still struggles with the credit assignment problem,\nwherein the sheer difficulty in ascribing credit to individual agents' actions\nscales poorly with team size. In this paper, we propose a multi-agent\nreinforcement learning algorithm that adapts recent developments in credit\nassignment to improve upon MAPPO. Our approach leverages partial reward\ndecoupling (PRD), which uses a learned attention mechanism to estimate which of\na particular agent's teammates are relevant to its learning updates. We use\nthis estimate to dynamically decompose large groups of agents into smaller,\nmore manageable subgroups. We empirically demonstrate that our approach,\nPRD-MAPPO, decouples agents from teammates that do not influence their expected\nfuture reward, thereby streamlining credit assignment. We additionally show\nthat PRD-MAPPO yields significantly higher data efficiency and asymptotic\nperformance compared to both MAPPO and other state-of-the-art methods across\nseveral multi-agent tasks, including StarCraft II. Finally, we propose a\nversion of PRD-MAPPO that is applicable to \\textit{shared} reward settings,\nwhere PRD was previously not applicable, and empirically show that this also\nleads to performance improvements over MAPPO.",
      "tldr_zh": "这篇论文针对多智能体近端策略优化（MAPPO）中的信用分配问题，提出了一种改进算法，通过Partial Reward Decoupling (PRD)利用学习注意力机制来估计代理与其队友的相关性，从而动态将大代理组分解成更易管理的子组。实验结果显示，PRD-MAPPO显著提高了数据效率和渐进性能，在多个多智能体任务（如StarCraft II）上比MAPPO和其他基准方法表现更优。论文还扩展了PRD-MAPPO，使其适用于共享奖励设置，并证明了其性能提升。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.MA",
      "comment": "20 pages, 5 figures, 12 tables, Reinforcement Learning Journal and\n  Reinforcement Learning Conference 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.04295v3",
      "published_date": "2024-08-08 08:18:05 UTC",
      "updated_date": "2025-02-07 10:48:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:55:12.215842"
    },
    {
      "arxiv_id": "2408.12608v1",
      "title": "A frugal Spiking Neural Network for unsupervised classification of continuous multivariate temporal data",
      "title_zh": "一种高效的脉冲神经网络，用于连续多变量时间数据的无监督分类",
      "authors": [
        "Sai Deepesh Pokala",
        "Marie Bernert",
        "Takuya Nanami",
        "Takashi Kohno",
        "Timothée Lévi",
        "Blaise Yvert"
      ],
      "abstract": "As neural interfaces become more advanced, there has been an increase in the\nvolume and complexity of neural data recordings. These interfaces capture rich\ninformation about neural dynamics that call for efficient, real-time processing\nalgorithms to spontaneously extract and interpret patterns of neural dynamics.\nMoreover, being able to do so in a fully unsupervised manner is critical as\npatterns in vast streams of neural data might not be easily identifiable by the\nhuman eye. Formal Deep Neural Networks (DNNs) have come a long way in\nperforming pattern recognition tasks for various static and sequential pattern\nrecognition applications. However, these networks usually require large labeled\ndatasets for training and have high power consumption preventing their future\nembedding in active brain implants. An alternative aimed at addressing these\nissues are Spiking Neural Networks (SNNs) which are neuromorphic and use more\nbiologically plausible neurons with evolving membrane potentials. In this\ncontext, we introduce here a frugal single-layer SNN designed for fully\nunsupervised identification and classification of multivariate temporal\npatterns in continuous data with a sequential approach. We show that, with only\na handful number of neurons, this strategy is efficient to recognize highly\noverlapping multivariate temporal patterns, first on simulated data, and then\non Mel Cepstral representations of speech sounds and finally on multichannel\nneural data. This approach relies on several biologically inspired plasticity\nrules, including Spike-timing-dependent plasticity (STDP), Short-term\nplasticity (STP) and intrinsic plasticity (IP). These results pave the way\ntowards highly frugal SNNs for fully unsupervised and online-compatible\nlearning of complex multivariate temporal patterns for future embedding in\ndedicated very-low power hardware.",
      "tldr_zh": "本文提出一个简约的单层 Spiking Neural Networks (SNNs)，用于完全无监督地识别和分类连续多变量时间数据，以应对神经接口数据量的增加和实时处理需求。该网络结合了生物启发的可塑性规则，如 Spike-timing-dependent plasticity (STDP)、Short-term plasticity (STP) 和 intrinsic plasticity (IP)，仅需少量神经元即可高效处理高度重叠的模式。在模拟数据、语音的 Mel Cepstral 表示以及多通道神经数据上进行的实验显示，该方法表现出色，准确率高且功耗低。该研究为嵌入低功耗硬件的在线无监督学习奠定了基础。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12608v1",
      "published_date": "2024-08-08 08:15:51 UTC",
      "updated_date": "2024-08-08 08:15:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:55:27.182755"
    },
    {
      "arxiv_id": "2408.04281v1",
      "title": "AI-Driven Chatbot for Intrusion Detection in Edge Networks: Enhancing Cybersecurity with Ethical User Consent",
      "title_zh": "翻译失败",
      "authors": [
        "Mugheez Asif",
        "Abdul Manan",
        "Abdul Moiz ur Rehman",
        "Mamoona Naveed Asghar",
        "Muhammad Umair"
      ],
      "abstract": "In today's contemporary digital landscape, chatbots have become indispensable\ntools across various sectors, streamlining customer service, providing personal\nassistance, automating routine tasks, and offering health advice. However,\ntheir potential remains underexplored in the realm of network security,\nparticularly for intrusion detection. To bridge this gap, we propose an\narchitecture chatbot specifically designed to enhance security within edge\nnetworks specifically for intrusion detection. Leveraging advanced machine\nlearning algorithms, this chatbot will monitor network traffic to identify and\nmitigate potential intrusions. By securing the network environment using an\nedge network managed by a Raspberry Pi module and ensuring ethical user consent\npromoting transparency and trust, this innovative solution aims to safeguard\nsensitive data and maintain a secure workplace, thereby addressing the growing\nneed for robust network security measures in the digital age.",
      "tldr_zh": "该研究提出了一种AI驱动的聊天机器人，用于增强边际网络（edge networks）的入侵检测（intrusion detection），以应对数字时代的安全挑战。该机器人利用高级机器学习算法（machine learning algorithms）监控网络流量，识别并缓解潜在入侵，同时通过Raspberry Pi管理的边际网络确保系统安全。该框架强调道德用户同意（ethical user consent），提升透明度和信任，从而保护敏感数据并为网络安全提供创新解决方案。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.04281v1",
      "published_date": "2024-08-08 07:39:23 UTC",
      "updated_date": "2024-08-08 07:39:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:55:35.841314"
    },
    {
      "arxiv_id": "2408.04268v2",
      "title": "Evaluating Modern Approaches in 3D Scene Reconstruction: NeRF vs Gaussian-Based Methods",
      "title_zh": "翻译失败",
      "authors": [
        "Yiming Zhou",
        "Zixuan Zeng",
        "Andi Chen",
        "Xiaofan Zhou",
        "Haowei Ni",
        "Shiyao Zhang",
        "Panfeng Li",
        "Liangxi Liu",
        "Mengyao Zheng",
        "Xupeng Chen"
      ],
      "abstract": "Exploring the capabilities of Neural Radiance Fields (NeRF) and\nGaussian-based methods in the context of 3D scene reconstruction, this study\ncontrasts these modern approaches with traditional Simultaneous Localization\nand Mapping (SLAM) systems. Utilizing datasets such as Replica and ScanNet, we\nassess performance based on tracking accuracy, mapping fidelity, and view\nsynthesis. Findings reveal that NeRF excels in view synthesis, offering unique\ncapabilities in generating new perspectives from existing data, albeit at\nslower processing speeds. Conversely, Gaussian-based methods provide rapid\nprocessing and significant expressiveness but lack comprehensive scene\ncompletion. Enhanced by global optimization and loop closure techniques, newer\nmethods like NICE-SLAM and SplaTAM not only surpass older frameworks such as\nORB-SLAM2 in terms of robustness but also demonstrate superior performance in\ndynamic and complex environments. This comparative analysis bridges theoretical\nresearch with practical implications, shedding light on future developments in\nrobust 3D scene reconstruction across various real-world applications.",
      "tldr_zh": "这篇论文评估了NeRF和Gaussian-based methods在3D场景重建中的性能，并与传统SLAM系统进行对比。研究利用Replica和ScanNet数据集，基于跟踪准确性、映射保真度和视图合成等指标进行评估。结果显示，NeRF在视图合成方面表现出色，能够从现有数据生成新视角，但处理速度较慢；Gaussian-based methods则提供快速处理和高表达性，却缺乏全面的场景完成。新方法如NICE-SLAM和SplaTAM，通过全局优化和循环闭合技术，在动态和复杂环境中超越了ORB-SLAM2，为3D场景重建的实际应用提供了重要见解。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by 2024 6th International Conference on Data-driven\n  Optimization of Complex Systems",
      "pdf_url": "http://arxiv.org/pdf/2408.04268v2",
      "published_date": "2024-08-08 07:11:57 UTC",
      "updated_date": "2024-11-14 23:46:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:55:50.856761"
    },
    {
      "arxiv_id": "2408.04261v1",
      "title": "Unveiling Hidden Visual Information: A Reconstruction Attack Against Adversarial Visual Information Hiding",
      "title_zh": "揭示隐藏的视觉信息：针对对抗性视觉信息隐藏的重构攻击",
      "authors": [
        "Jonggyu Jang",
        "Hyeonsu Lyu",
        "Seongjin Hwang",
        "Hyun Jong Yang"
      ],
      "abstract": "This paper investigates the security vulnerabilities of\nadversarial-example-based image encryption by executing data reconstruction\n(DR) attacks on encrypted images. A representative image encryption method is\nthe adversarial visual information hiding (AVIH), which uses type-I adversarial\nexample training to protect gallery datasets used in image recognition tasks.\nIn the AVIH method, the type-I adversarial example approach creates images that\nappear completely different but are still recognized by machines as the\noriginal ones. Additionally, the AVIH method can restore encrypted images to\ntheir original forms using a predefined private key generative model. For the\nbest security, assigning a unique key to each image is recommended; however,\nstorage limitations may necessitate some images sharing the same key model.\nThis raises a crucial security question for AVIH: How many images can safely\nshare the same key model without being compromised by a DR attack? To address\nthis question, we introduce a dual-strategy DR attack against the AVIH\nencryption method by incorporating (1) generative-adversarial loss and (2)\naugmented identity loss, which prevent DR from overfitting -- an issue akin to\nthat in machine learning. Our numerical results validate this approach through\nimage recognition and re-identification benchmarks, demonstrating that our\nstrategy can significantly enhance the quality of reconstructed images, thereby\nrequiring fewer key-sharing encrypted images. Our source code to reproduce our\nresults will be available soon.",
      "tldr_zh": "本论文揭示了基于对抗样本的图像加密方法（如 Adversarial Visual Information Hiding, AVIH）的安全漏洞，通过执行数据重建（DR）攻击来重建加密图像。研究者提出了一种双策略 DR 攻击，结合生成对抗损失（generative-adversarial loss）和增强身份损失（augmented identity loss），以避免攻击模型过拟合，并评估图像在共享密钥模型下的安全边界。实验结果显示，该攻击显著提高了重建图像的质量，在图像识别和重新识别基准上表现突出，从而证明了 AVIH 方法在密钥共享场景下的易受损性，为提升加密安全提供了重要启示。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.CV",
      "comment": "12 pages",
      "pdf_url": "http://arxiv.org/pdf/2408.04261v1",
      "published_date": "2024-08-08 06:58:48 UTC",
      "updated_date": "2024-08-08 06:58:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:56:01.949955"
    },
    {
      "arxiv_id": "2408.04259v2",
      "title": "EfficientRAG: Efficient Retriever for Multi-Hop Question Answering",
      "title_zh": "翻译失败",
      "authors": [
        "Ziyuan Zhuang",
        "Zhiyang Zhang",
        "Sitao Cheng",
        "Fangkai Yang",
        "Jia Liu",
        "Shujian Huang",
        "Qingwei Lin",
        "Saravan Rajmohan",
        "Dongmei Zhang",
        "Qi Zhang"
      ],
      "abstract": "Retrieval-augmented generation (RAG) methods encounter difficulties when\naddressing complex questions like multi-hop queries. While iterative retrieval\nmethods improve performance by gathering additional information, current\napproaches often rely on multiple calls of large language models (LLMs). In\nthis paper, we introduce EfficientRAG, an efficient retriever for multi-hop\nquestion answering. EfficientRAG iteratively generates new queries without the\nneed for LLM calls at each iteration and filters out irrelevant information.\nExperimental results demonstrate that EfficientRAG surpasses existing RAG\nmethods on three open-domain multi-hop question-answering datasets.",
      "tldr_zh": "这篇论文提出了 EfficientRAG，一种高效的检索器，旨在解决 Retrieval-augmented generation (RAG) 方法在处理多跳问答(multi-hop question answering)时的挑战。EfficientRAG 通过迭代生成新查询，而无需每次迭代都调用 Large Language Models (LLMs)，并过滤无关信息，从而提升了整体效率。实验结果显示，在三个开放域多跳问答数据集上，EfficientRAG 超过了现有 RAG 方法的表现。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "20 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.04259v2",
      "published_date": "2024-08-08 06:57:49 UTC",
      "updated_date": "2024-09-26 11:42:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:56:13.299633"
    },
    {
      "arxiv_id": "2408.04245v1",
      "title": "Scalable Transformer for High Dimensional Multivariate Time Series Forecasting",
      "title_zh": "高维多变量时间序列预测的可扩展 Transformer",
      "authors": [
        "Xin Zhou",
        "Weiqing Wang",
        "Wray Buntine",
        "Shilin Qu",
        "Abishek Sriramulu",
        "Weicong Tan",
        "Christoph Bergmeir"
      ],
      "abstract": "Deep models for Multivariate Time Series (MTS) forecasting have recently\ndemonstrated significant success. Channel-dependent models capture complex\ndependencies that channel-independent models cannot capture. However, the\nnumber of channels in real-world applications outpaces the capabilities of\nexisting channel-dependent models, and contrary to common expectations, some\nmodels underperform the channel-independent models in handling high-dimensional\ndata, which raises questions about the performance of channel-dependent models.\nTo address this, our study first investigates the reasons behind the suboptimal\nperformance of these channel-dependent models on high-dimensional MTS data. Our\nanalysis reveals that two primary issues lie in the introduced noise from\nunrelated series that increases the difficulty of capturing the crucial\ninter-channel dependencies, and challenges in training strategies due to\nhigh-dimensional data. To address these issues, we propose STHD, the Scalable\nTransformer for High-Dimensional Multivariate Time Series Forecasting. STHD has\nthree components: a) Relation Matrix Sparsity that limits the noise introduced\nand alleviates the memory issue; b) ReIndex applied as a training strategy to\nenable a more flexible batch size setting and increase the diversity of\ntraining data; and c) Transformer that handles 2-D inputs and captures channel\ndependencies. These components jointly enable STHD to manage the\nhigh-dimensional MTS while maintaining computational feasibility. Furthermore,\nexperimental results show STHD's considerable improvement on three\nhigh-dimensional datasets: Crime-Chicago, Wiki-People, and Traffic. The source\ncode and dataset are publicly available\nhttps://github.com/xinzzzhou/ScalableTransformer4HighDimensionMTSF.git.",
      "tldr_zh": "本研究探讨了多变量时间序列 (MTS) 预测中，通道依赖模型在高维数据上的表现不佳问题，主要归因于无关序列引入的噪声和训练策略挑战。作者提出 STHD（Scalable Transformer for High Dimensional Multivariate Time Series Forecasting）模型，包括三个关键组件：Relation Matrix Sparsity 用于限制噪声并缓解内存问题、ReIndex 作为训练策略提升批量大小灵活性和数据多样性，以及 Transformer 处理 2-D 输入并捕获通道依赖。这些组件共同使 STHD 能够高效处理高维 MTS 数据。实验结果显示，STHD 在 Crime-Chicago、Wiki-People 和 Traffic 等数据集上显著优于基线模型，并公开了源代码以供进一步验证。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IR",
        "H.3"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.04245v1",
      "published_date": "2024-08-08 06:17:13 UTC",
      "updated_date": "2024-08-08 06:17:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:56:24.597098"
    },
    {
      "arxiv_id": "2408.04242v1",
      "title": "The Ungrounded Alignment Problem",
      "title_zh": "翻译失败",
      "authors": [
        "Marc Pickett",
        "Aakash Kumar Nain",
        "Joseph Modayil",
        "Llion Jones"
      ],
      "abstract": "Modern machine learning systems have demonstrated substantial abilities with\nmethods that either embrace or ignore human-provided knowledge, but combining\nbenefits of both styles remains a challenge. One particular challenge involves\ndesigning learning systems that exhibit built-in responses to specific abstract\nstimulus patterns, yet are still plastic enough to be agnostic about the\nmodality and exact form of their inputs. In this paper, we investigate what we\ncall The Ungrounded Alignment Problem, which asks How can we build in\npredefined knowledge in a system where we don't know how a given stimulus will\nbe grounded? This paper examines a simplified version of the general problem,\nwhere an unsupervised learner is presented with a sequence of images for the\ncharacters in a text corpus, and this learner is later evaluated on its ability\nto recognize specific (possibly rare) sequential patterns. Importantly, the\nlearner is given no labels during learning or evaluation, but must map images\nfrom an unknown font or permutation to its correct class label. That is, at no\npoint is our learner given labeled images, where an image vector is explicitly\nassociated with a class label. Despite ample work in unsupervised and\nself-supervised loss functions, all current methods require a labeled\nfine-tuning phase to map the learned representations to correct classes.\nFinding this mapping in the absence of labels may seem a fool's errand, but our\nmain result resolves this seeming paradox. We show that leveraging only letter\nbigram frequencies is sufficient for an unsupervised learner both to reliably\nassociate images to class labels and to reliably identify trigger words in the\nsequence of inputs. More generally, this method suggests an approach for\nencoding specific desired innate behaviour in modality-agnostic models.",
      "tldr_zh": "本论文探讨了“Ungrounded Alignment Problem”，即如何在未知刺激 grounded 方式的情况下，为机器学习系统内置特定抽象模式响应，同时保持输入模态和形式的灵活性。研究者简化了这个问题，通过一个无监督学习器处理文本语料的图像序列，仅利用字母 bigram frequencies 来关联图像到类别标签，而无需任何标签训练或评估。结果显示，该方法能可靠地识别序列模式和触发词，证明了在模态无关模型中编码固有行为的可能性，为整合人类知识和自主学习提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "7 pages, plus references and appendix",
      "pdf_url": "http://arxiv.org/pdf/2408.04242v1",
      "published_date": "2024-08-08 06:08:04 UTC",
      "updated_date": "2024-08-08 06:08:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:56:36.651139"
    },
    {
      "arxiv_id": "2408.04682v2",
      "title": "ToolSandbox: A Stateful, Conversational, Interactive Evaluation Benchmark for LLM Tool Use Capabilities",
      "title_zh": "ToolSandbox：一种状态化",
      "authors": [
        "Jiarui Lu",
        "Thomas Holleis",
        "Yizhe Zhang",
        "Bernhard Aumayer",
        "Feng Nan",
        "Felix Bai",
        "Shuang Ma",
        "Shen Ma",
        "Mengyu Li",
        "Guoli Yin",
        "Zirui Wang",
        "Ruoming Pang"
      ],
      "abstract": "Recent large language models (LLMs) advancements sparked a growing research\ninterest in tool assisted LLMs solving real-world challenges, which calls for\ncomprehensive evaluation of tool-use capabilities. While previous works focused\non either evaluating over stateless web services (RESTful API), based on a\nsingle turn user prompt, or an off-policy dialog trajectory, ToolSandbox\nincludes stateful tool execution, implicit state dependencies between tools, a\nbuilt-in user simulator supporting on-policy conversational evaluation and a\ndynamic evaluation strategy for intermediate and final milestones over an\narbitrary trajectory. We show that open source and proprietary models have a\nsignificant performance gap, and complex tasks like State Dependency,\nCanonicalization and Insufficient Information defined in ToolSandbox are\nchallenging even the most capable SOTA LLMs, providing brand-new insights into\ntool-use LLM capabilities. ToolSandbox evaluation framework is released at\nhttps://github.com/apple/ToolSandbox",
      "tldr_zh": "该论文提出 ToolSandbox，一种状态化（stateful）、对话式交互的基准，用于全面评估大型语言模型（LLM）的工具使用能力。ToolSandbox 创新性地整合了 stateful tool execution、implicit state dependencies、内置用户模拟器（built-in user simulator）和动态评估策略，支持多轮对话和中间里程碑评估。实验结果显示，开源模型与专有模型存在显著性能差距，而复杂任务如 State Dependency、Canonicalization 和 Insufficient Information 即使对最先进的 SOTA LLM 也构成挑战，为工具辅助 LLM 的能力研究提供了新见解。工具框架已开源在 GitHub（https://github.com/apple/ToolSandbox）。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.04682v2",
      "published_date": "2024-08-08 05:45:42 UTC",
      "updated_date": "2025-04-16 22:20:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:56:49.037243"
    },
    {
      "arxiv_id": "2408.04236v1",
      "title": "Cluster-Wide Task Slowdown Detection in Cloud System",
      "title_zh": "翻译失败",
      "authors": [
        "Feiyi Chen",
        "Yingying Zhang",
        "Lunting Fan",
        "Yuxuan Liang",
        "Guansong Pang",
        "Qingsong Wen",
        "Shuiguang Deng"
      ],
      "abstract": "Slow task detection is a critical problem in cloud operation and maintenance\nsince it is highly related to user experience and can bring substantial\nliquidated damages. Most anomaly detection methods detect it from a single-task\naspect. However, considering millions of concurrent tasks in large-scale cloud\ncomputing clusters, it becomes impractical and inefficient. Moreover,\nsingle-task slowdowns are very common and do not necessarily indicate a\nmalfunction of a cluster due to its violent fluctuation nature in a virtual\nenvironment. Thus, we shift our attention to cluster-wide task slowdowns by\nutilizing the duration time distribution of tasks across a cluster, so that the\ncomputation complexity is not relevant to the number of tasks.\n  The task duration time distribution often exhibits compound periodicity and\nlocal exceptional fluctuations over time. Though transformer-based methods are\none of the most powerful methods to capture these time series normal variation\npatterns, we empirically find and theoretically explain the flaw of the\nstandard attention mechanism in reconstructing subperiods with low amplitude\nwhen dealing with compound periodicity.\n  To tackle these challenges, we propose SORN (i.e., Skimming Off subperiods in\ndescending amplitude order and Reconstructing Non-slowing fluctuation), which\nconsists of a Skimming Attention mechanism to reconstruct the compound\nperiodicity and a Neural Optimal Transport module to distinguish cluster-wide\nslowdowns from other exceptional fluctuations. Furthermore, since anomalies in\nthe training set are inevitable in a practical scenario, we propose a picky\nloss function, which adaptively assigns higher weights to reliable time slots\nin the training set. Extensive experiments demonstrate that SORN outperforms\nstate-of-the-art methods on multiple real-world industrial datasets.",
      "tldr_zh": "该论文针对云系统中集群整体任务延缓（Cluster-Wide Task Slowdown）检测问题，提出一种新方法，以任务持续时间分布为基础，避免了传统单任务检测的低效性。作者开发了SORN框架，包括Skimming Attention机制用于重建复合周期性，以及Neural Optimal Transport模块来区分整体延缓与其他异常波动；此外，还引入了picky loss function，以适应训练集中不可避免的异常数据。实验结果显示，SORN在多个真实工业数据集上优于现有方法，显著提升了检测准确性和效率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "This paper has been accepted by KDD2024",
      "pdf_url": "http://arxiv.org/pdf/2408.04236v1",
      "published_date": "2024-08-08 05:43:20 UTC",
      "updated_date": "2024-08-08 05:43:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:57:11.290621"
    },
    {
      "arxiv_id": "2409.07457v1",
      "title": "LSST: Learned Single-Shot Trajectory and Reconstruction Network for MR Imaging",
      "title_zh": "翻译失败",
      "authors": [
        "Hemant Kumar Aggarwal",
        "Sudhanya Chatterjee",
        "Dattesh Shanbhag",
        "Uday Patil",
        "K. V. S. Hari"
      ],
      "abstract": "Single-shot magnetic resonance (MR) imaging acquires the entire k-space data\nin a single shot and it has various applications in whole-body imaging.\nHowever, the long acquisition time for the entire k-space in single-shot fast\nspin echo (SSFSE) MR imaging poses a challenge, as it introduces T2-blur in the\nacquired images. This study aims to enhance the reconstruction quality of SSFSE\nMR images by (a) optimizing the trajectory for measuring the k-space, (b)\nacquiring fewer samples to speed up the acquisition process, and (c) reducing\nthe impact of T2-blur. The proposed method adheres to physics constraints due\nto maximum gradient strength and slew-rate available while optimizing the\ntrajectory within an end-to-end learning framework. Experiments were conducted\non publicly available fastMRI multichannel dataset with 8-fold and 16-fold\nacceleration factors. An experienced radiologist's evaluation on a five-point\nLikert scale indicates improvements in the reconstruction quality as the ACL\nfibers are sharper than comparative methods.",
      "tldr_zh": "本研究提出LSST（Learned Single-Shot Trajectory and Reconstruction Network），一种端到端学习框架，用于提升单次射频磁共振（MR）成像的图像重建质量。方法通过优化k-space测量轨迹、减少样本采集并减轻T2-blur的影响，同时遵守物理约束如最大梯度强度和斜率。实验在fastMRI多通道数据集上以8倍和16倍加速因子进行，结果显示重建图像质量显著改善，ACL fibers比比较方法更清晰，经经验放射科医生五点Likert量表评估得到正面反馈。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.07457v1",
      "published_date": "2024-08-08 05:41:54 UTC",
      "updated_date": "2024-08-08 05:41:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:57:16.158001"
    },
    {
      "arxiv_id": "2408.04229v1",
      "title": "Probabilistic Circuits for Cumulative Distribution Functions",
      "title_zh": "翻译失败",
      "authors": [
        "Oliver Broadrick",
        "William Cao",
        "Benjie Wang",
        "Martin Trapp",
        "Guy Van den Broeck"
      ],
      "abstract": "A probabilistic circuit (PC) succinctly expresses a function that represents\na multivariate probability distribution and, given sufficient structural\nproperties of the circuit, supports efficient probabilistic inference.\nTypically a PC computes the probability mass (or density) function (PMF or PDF)\nof the distribution. We consider PCs instead computing the cumulative\ndistribution function (CDF). We show that for distributions over binary random\nvariables these representations (PMF and CDF) are essentially equivalent, in\nthe sense that one can be transformed to the other in polynomial time. We then\nshow how a similar equivalence holds for distributions over finite discrete\nvariables using a modification of the standard encoding with binary variables\nthat aligns with the CDF semantics. Finally we show that for continuous\nvariables, smooth, decomposable PCs computing PDFs and CDFs can be efficiently\ntransformed to each other by modifying only the leaves of the circuit.",
      "tldr_zh": "这篇论文探讨了概率电路 (PC) 用于计算累积分布函数 (CDF) 的方法，而非传统的概率质量函数 (PMF) 或概率密度函数 (PDF)。研究证明，对于二元随机变量，PMF 和 CDF 表示本质等价，可在多项式时间内相互转换；对于有限离散变量，通过修改标准二元编码实现类似等价性；对于连续变量，光滑可分解的 PC 则可通过仅修改电路叶子节点高效转换 PDF 和 CDF。这种方法扩展了 PC 在概率推理中的灵活性，提供更全面的分布表示工具。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.04229v1",
      "published_date": "2024-08-08 05:33:21 UTC",
      "updated_date": "2024-08-08 05:33:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:57:28.840591"
    },
    {
      "arxiv_id": "2408.04223v1",
      "title": "VideoQA in the Era of LLMs: An Empirical Study",
      "title_zh": "VideoQA 在 LLMs 时代：一项实证研究",
      "authors": [
        "Junbin Xiao",
        "Nanxin Huang",
        "Hangyu Qin",
        "Dongyang Li",
        "Yicong Li",
        "Fengbin Zhu",
        "Zhulin Tao",
        "Jianxing Yu",
        "Liang Lin",
        "Tat-Seng Chua",
        "Angela Yao"
      ],
      "abstract": "Video Large Language Models (Video-LLMs) are flourishing and has advanced\nmany video-language tasks. As a golden testbed, Video Question Answering\n(VideoQA) plays pivotal role in Video-LLM developing. This work conducts a\ntimely and comprehensive study of Video-LLMs' behavior in VideoQA, aiming to\nelucidate their success and failure modes, and provide insights towards more\nhuman-like video understanding and question answering. Our analyses demonstrate\nthat Video-LLMs excel in VideoQA; they can correlate contextual cues and\ngenerate plausible responses to questions about varied video contents. However,\nmodels falter in handling video temporality, both in reasoning about temporal\ncontent ordering and grounding QA-relevant temporal moments. Moreover, the\nmodels behave unintuitively - they are unresponsive to adversarial video\nperturbations while being sensitive to simple variations of candidate answers\nand questions. Also, they do not necessarily generalize better. The findings\ndemonstrate Video-LLMs' QA capability in standard condition yet highlight their\nsevere deficiency in robustness and interpretability, suggesting the urgent\nneed on rationales in Video-LLM developing.",
      "tldr_zh": "这篇论文通过实证研究探讨了大型语言模型（LLMs）时代下 Video-LLMs 在 Video Question Answering（VideoQA）中的表现，旨在揭示其成功与失败模式，并提供更人性化的视频理解见解。研究发现，Video-LLMs 擅长关联视频上下文线索并生成合理的回答，但明显弱于处理视频的时序性，包括推理时间内容顺序和定位相关时刻。模型还表现出不直观的行为：对对抗性视频扰动不敏感，却对候选答案和问题的简单变化高度敏感，且泛化能力不一定优于其他模型。这些发现突显了 Video-LLMs 在标准条件下的高效性，但也暴露了其稳健性和可解释性的严重不足，呼吁在 Video-LLM 开发中加强理性设计。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Preprint. Under Review",
      "pdf_url": "http://arxiv.org/pdf/2408.04223v1",
      "published_date": "2024-08-08 05:14:07 UTC",
      "updated_date": "2024-08-08 05:14:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:57:41.866189"
    },
    {
      "arxiv_id": "2408.04221v1",
      "title": "Connective Viewpoints of Signal-to-Noise Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Khanh Doan",
        "Long Tung Vuong",
        "Tuan Nguyen",
        "Anh Tuan Bui",
        "Quyen Tran",
        "Thanh-Toan Do",
        "Dinh Phung",
        "Trung Le"
      ],
      "abstract": "Diffusion models (DM) have become fundamental components of generative\nmodels, excelling across various domains such as image creation, audio\ngeneration, and complex data interpolation. Signal-to-Noise diffusion models\nconstitute a diverse family covering most state-of-the-art diffusion models.\nWhile there have been several attempts to study Signal-to-Noise (S2N) diffusion\nmodels from various perspectives, there remains a need for a comprehensive\nstudy connecting different viewpoints and exploring new perspectives. In this\nstudy, we offer a comprehensive perspective on noise schedulers, examining\ntheir role through the lens of the signal-to-noise ratio (SNR) and its\nconnections to information theory. Building upon this framework, we have\ndeveloped a generalized backward equation to enhance the performance of the\ninference process.",
      "tldr_zh": "本研究探讨了 Signal-to-Noise (S2N) 扩散模型的连接视角，这些模型是生成模型的核心组成部分，在图像创建、音频生成和复杂数据插值等领域表现出色。作者通过 Signal-to-Noise Ratio (SNR) 和信息理论的框架，系统地分析了噪声调度器的作用，并揭示了其与其他视角的联系。最终，他们开发了一个泛化后的后向方程，提升了扩散模型的推理过程性能，为 S2N 模型的全面理解和优化提供了新见解。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.NE"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.04221v1",
      "published_date": "2024-08-08 05:09:02 UTC",
      "updated_date": "2024-08-08 05:09:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:57:53.338882"
    },
    {
      "arxiv_id": "2408.12606v3",
      "title": "A Large Model for Non-invasive and Personalized Management of Breast Cancer from Multiparametric MRI",
      "title_zh": "翻译失败",
      "authors": [
        "Luyang Luo",
        "Mingxiang Wu",
        "Mei Li",
        "Yi Xin",
        "Qiong Wang",
        "Varut Vardhanabhuti",
        "Winnie CW Chu",
        "Zhenhui Li",
        "Juan Zhou",
        "Pranav Rajpurkar",
        "Hao Chen"
      ],
      "abstract": "Breast Magnetic Resonance Imaging (MRI) demonstrates the highest sensitivity\nfor breast cancer detection among imaging modalities and is standard practice\nfor high-risk women. Interpreting the multi-sequence MRI is time-consuming and\nprone to subjective variation. We develop a large mixture-of-modality-experts\nmodel (MOME) that integrates multiparametric MRI information within a unified\nstructure, leveraging breast MRI scans from 5,205 female patients in China for\nmodel development and validation. MOME matches four senior radiologists'\nperformance in identifying breast cancer and outperforms a junior radiologist.\nThe model is able to reduce unnecessary biopsies in Breast Imaging-Reporting\nand Data System (BI-RADS) 4 patients, classify triple-negative breast cancer,\nand predict pathological complete response to neoadjuvant chemotherapy. MOME\nfurther supports inference with missing modalities and provides decision\nexplanations by highlighting lesions and measuring modality contributions. To\nsummarize, MOME exemplifies an accurate and robust multimodal model for\nnoninvasive, personalized management of breast cancer patients via\nmultiparametric MRI. Code is available at\nhttps://github.com/LLYXC/MOME/tree/main.",
      "tldr_zh": "本研究开发了MOME（一种大型混合模态专家模型），通过整合多参数MRI信息，实现乳腺癌的非侵入性和个性化管理，利用来自5205名中国女性患者的MRI扫描进行训练和验证。MOME在识别乳腺癌方面与四位资深放射科医生表现相当，并优于初级医生，同时能减少BI-RADS 4患者的不必要活检。模型还能分类三阴性乳腺癌、预测新辅助化疗的病理完全反应，并支持缺失模态下的推理。总之，MOME提供决策解释（如突出病变和测量模态贡献），提升了乳腺癌管理的准确性和稳健性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Nature Communications 2025",
      "pdf_url": "http://arxiv.org/pdf/2408.12606v3",
      "published_date": "2024-08-08 05:04:13 UTC",
      "updated_date": "2025-04-04 19:14:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:58:07.165815"
    },
    {
      "arxiv_id": "2408.04681v1",
      "title": "Conversational AI Powered by Large Language Models Amplifies False Memories in Witness Interviews",
      "title_zh": "翻译失败",
      "authors": [
        "Samantha Chan",
        "Pat Pataranutaporn",
        "Aditya Suri",
        "Wazeer Zulfikar",
        "Pattie Maes",
        "Elizabeth F. Loftus"
      ],
      "abstract": "This study examines the impact of AI on human false memories -- recollections\nof events that did not occur or deviate from actual occurrences. It explores\nfalse memory induction through suggestive questioning in Human-AI interactions,\nsimulating crime witness interviews. Four conditions were tested: control,\nsurvey-based, pre-scripted chatbot, and generative chatbot using a large\nlanguage model (LLM). Participants (N=200) watched a crime video, then\ninteracted with their assigned AI interviewer or survey, answering questions\nincluding five misleading ones. False memories were assessed immediately and\nafter one week. Results show the generative chatbot condition significantly\nincreased false memory formation, inducing over 3 times more immediate false\nmemories than the control and 1.7 times more than the survey method. 36.4% of\nusers' responses to the generative chatbot were misled through the interaction.\nAfter one week, the number of false memories induced by generative chatbots\nremained constant. However, confidence in these false memories remained higher\nthan the control after one week. Moderating factors were explored: users who\nwere less familiar with chatbots but more familiar with AI technology, and more\ninterested in crime investigations, were more susceptible to false memories.\nThese findings highlight the potential risks of using advanced AI in sensitive\ncontexts, like police interviews, emphasizing the need for ethical\nconsiderations.",
      "tldr_zh": "这篇研究探讨了大型语言模型(LLM)驱动的对话AI在犯罪目击者访谈中诱导虚假记忆的影响，通过模拟实验比较了控制组、调查-based组、预脚本聊天机器人和生成式聊天机器人四种条件。结果显示，生成式聊天机器人显著放大虚假记忆，立刻诱导的虚假记忆是控制组的3倍多，且36.4%的用户响应被误导；一周后，虚假记忆数量保持不变，而信心水平仍高于控制组。影响因素包括用户对聊天机器人不熟悉但对AI技术更熟悉，以及对犯罪调查更感兴趣的人群更容易受影响，这些发现突出了在敏感情境如警察访谈中使用AI的潜在风险，并呼吁加强伦理考虑。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.04681v1",
      "published_date": "2024-08-08 04:55:03 UTC",
      "updated_date": "2024-08-08 04:55:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:58:17.771738"
    },
    {
      "arxiv_id": "2408.04216v3",
      "title": "Attention Mechanism and Context Modeling System for Text Mining Machine Translation",
      "title_zh": "文本挖掘机器翻译中的注意力机制和上下文建模系统",
      "authors": [
        "Yuwei Zhang",
        "Junming Huang",
        "Sitong Liu",
        "Zexi Chen",
        "Zizheng Li"
      ],
      "abstract": "This paper advances a novel architectural schema anchored upon the\nTransformer paradigm and innovatively amalgamates the K-means categorization\nalgorithm to augment the contextual apprehension capabilities of the schema.\nThe transformer model performs well in machine translation tasks due to its\nparallel computing power and multi-head attention mechanism. However, it may\nencounter contextual ambiguity or ignore local features when dealing with\nhighly complex language structures. To circumvent this constraint, this\nexposition incorporates the K-Means algorithm, which is used to stratify the\nlexis and idioms of the input textual matter, thereby facilitating superior\nidentification and preservation of the local structure and contextual\nintelligence of the language. The advantage of this combination is that K-Means\ncan automatically discover the topic or concept regions in the text, which may\nbe directly related to translation quality. Consequently, the schema contrived\nherein enlists K-Means as a preparatory phase antecedent to the Transformer and\nrecalibrates the multi-head attention weights to assist in the discrimination\nof lexis and idioms bearing analogous semantics or functionalities. This\nensures the schema accords heightened regard to the contextual intelligence\nembodied by these clusters during the training phase, rather than merely\nfocusing on locational intelligence.",
      "tldr_zh": "本论文提出了一种新型架构，基于Transformer模型并整合K-means算法，以提升机器翻译中的上下文理解能力。Transformer模型虽凭借其并行计算和multi-head attention机制在翻译任务中表现出色，但可能在处理复杂语言结构时出现上下文模糊或忽略局部特征。为解决这一问题，论文采用K-means算法对输入文本的词汇和短语进行分层预处理，从而自动发现文本中的主题或概念区域，并调整multi-head attention权重，以更好地识别语义相似的元素。最终，这种结合方法增强了模型对上下文的关注，提高了翻译质量，避免了单纯依赖位置信息的局限。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.04216v3",
      "published_date": "2024-08-08 04:52:10 UTC",
      "updated_date": "2025-01-18 00:29:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:58:28.717634"
    },
    {
      "arxiv_id": "2408.04680v2",
      "title": "Dynamic Fog Computing for Enhanced LLM Execution in Medical Applications",
      "title_zh": "动态雾计算用于增强医疗应用中的LLM",
      "authors": [
        "Philipp Zagar",
        "Vishnu Ravi",
        "Lauren Aalami",
        "Stephan Krusche",
        "Oliver Aalami",
        "Paul Schmiedmayer"
      ],
      "abstract": "The ability of large language models (LLMs) to transform, interpret, and\ncomprehend vast quantities of heterogeneous data presents a significant\nopportunity to enhance data-driven care delivery. However, the sensitive nature\nof protected health information (PHI) raises valid concerns about data privacy\nand trust in remote LLM platforms. In addition, the cost associated with\ncloud-based artificial intelligence (AI) services continues to impede\nwidespread adoption. To address these challenges, we propose a shift in the LLM\nexecution environment from opaque, centralized cloud providers to a\ndecentralized and dynamic fog computing architecture. By executing open-weight\nLLMs in more trusted environments, such as the user's edge device or a fog\nlayer within a local network, we aim to mitigate the privacy, trust, and\nfinancial challenges associated with cloud-based LLMs. We further present\nSpeziLLM, an open-source framework designed to facilitate rapid and seamless\nleveraging of different LLM execution layers and lowering barriers to LLM\nintegration in digital health applications. We demonstrate SpeziLLM's broad\napplicability across six digital health applications, showcasing its\nversatility in various healthcare settings.",
      "tldr_zh": "本研究针对大型语言模型（LLMs）在医疗应用中面临的隐私、信任和成本挑战（如PHI数据保护），提出采用动态雾计算（Dynamic Fog Computing）架构，将LLMs执行从集中式云转移到去中心化的本地环境（如边缘设备或雾层），从而缓解这些问题。论文引入了开源框架SpeziLLM，用于快速无缝地整合不同LLM执行层，并降低LLMs在数字健康应用中的门槛。实验结果显示，SpeziLLM在六个数字健康应用中展现出广泛适用性，提升了LLMs的隐私和可信度。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.04680v2",
      "published_date": "2024-08-08 04:49:21 UTC",
      "updated_date": "2024-12-13 08:44:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:58:41.487259"
    },
    {
      "arxiv_id": "2408.07084v3",
      "title": "Dynamic Hypergraph-Enhanced Prediction of Sequential Medical Visits",
      "title_zh": "动态超图增强的顺序医疗就诊预测",
      "authors": [
        "Wangying Yang",
        "Zitao Zheng",
        "Zhizhong Wu",
        "Bo Zhang",
        "Yuanfang Yang"
      ],
      "abstract": "This study introduces a pioneering Dynamic Hypergraph Networks (DHCE) model\ndesigned to predict future medical diagnoses from electronic health records\nwith enhanced accuracy. The DHCE model innovates by identifying and\ndifferentiating acute and chronic diseases within a patient's visit history,\nconstructing dynamic hypergraphs that capture the complex, high-order\ninteractions between diseases. It surpasses traditional recurrent neural\nnetworks and graph neural networks by effectively integrating clinical event\ndata, reflected through medical language model-assisted encoding, into a robust\npatient representation. Through extensive experiments on two benchmark\ndatasets, MIMIC-III and MIMIC-IV, the DHCE model exhibits superior performance,\nsignificantly outpacing established baseline models in the precision of\nsequential diagnosis prediction.",
      "tldr_zh": "这篇论文提出了 Dynamic Hypergraph Networks (DHCE) 模型，用于从电子健康记录中预测未来的医疗诊断，提高预测准确性。DHCE 创新性地识别急性和慢性疾病，并构建动态超图来捕捉疾病之间的复杂高阶交互，同时整合医疗语言模型辅助编码的临床事件数据，形成鲁棒的患者表示。实验在 MIMIC-III 和 MIMIC-IV 数据集上显示，该模型在顺序诊断预测的精确性上显著优于传统 recurrent neural networks 和 graph neural networks。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.07084v3",
      "published_date": "2024-08-08 04:19:20 UTC",
      "updated_date": "2025-01-06 02:51:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:58:52.292447"
    },
    {
      "arxiv_id": "2408.04203v2",
      "title": "MMRole: A Comprehensive Framework for Developing and Evaluating Multimodal Role-Playing Agents",
      "title_zh": "MMRole：一个全面框架，用于开发和评估多模态角色扮演代理",
      "authors": [
        "Yanqi Dai",
        "Huanran Hu",
        "Lei Wang",
        "Shengjie Jin",
        "Xu Chen",
        "Zhiwu Lu"
      ],
      "abstract": "Recently, Role-Playing Agents (RPAs) have garnered increasing attention for\ntheir potential to deliver emotional value and facilitate sociological\nresearch. However, existing studies are primarily confined to the textual\nmodality, unable to simulate humans' multimodal perceptual capabilities. To\nbridge this gap, we introduce the concept of Multimodal Role-Playing Agents\n(MRPAs), and propose a comprehensive framework, MMRole, for their development\nand evaluation, which comprises a personalized multimodal dataset and a robust\nevaluation approach. Specifically, we construct a large-scale, high-quality\ndataset, MMRole-Data, consisting of 85 characters, 11K images, and 14K single\nor multi-turn dialogues. Additionally, we present a robust evaluation approach,\nMMRole-Eval, encompassing eight metrics across three dimensions, where a reward\nmodel is designed to score MRPAs with the constructed ground-truth data for\ncomparison. Moreover, we develop the first specialized MRPA, MMRole-Agent.\nExtensive evaluation results demonstrate the improved performance of\nMMRole-Agent and highlight the primary challenges in developing MRPAs,\nemphasizing the need for enhanced multimodal understanding and role-playing\nconsistency. The data, code, and models are all available at\nhttps://github.com/YanqiDai/MMRole.",
      "tldr_zh": "该论文引入了Multimodal Role-Playing Agents (MRPAs)，旨在扩展传统Role-Playing Agents (RPAs)至多模态感知，以更好地模拟人类的感知能力和支持社会学研究。研究提出MMRole框架，包括一个大规模个性化数据集MMRole-Data（包含85个角色、11K图像和14K对话），以及一个鲁棒评估方法MMRole-Eval（涵盖八个指标的三个维度，使用奖励模型进行评分）。此外，论文开发了首个专门MRPA——MMRole-Agent，并通过广泛实验证明其性能提升，但突出了多模态理解和角色扮演一致性等主要挑战。数据、代码和模型已在https://github.com/YanqiDai/MMRole上公开。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted for the 13th International Conference on Learning\n  Representations (ICLR 2025)",
      "pdf_url": "http://arxiv.org/pdf/2408.04203v2",
      "published_date": "2024-08-08 03:57:20 UTC",
      "updated_date": "2025-02-17 08:40:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:59:15.902860"
    },
    {
      "arxiv_id": "2408.07083v1",
      "title": "Masked EEG Modeling for Driving Intention Prediction",
      "title_zh": "掩码脑电图建",
      "authors": [
        "Jinzhao Zhou",
        "Justin Sia",
        "Yiqun Duan",
        "Yu-Cheng Chang",
        "Yu-Kai Wang",
        "Chin-Teng Lin"
      ],
      "abstract": "Driving under drowsy conditions significantly escalates the risk of vehicular\naccidents. Although recent efforts have focused on using electroencephalography\nto detect drowsiness, helping prevent accidents caused by driving in such\nstates, seamless human-machine interaction in driving scenarios requires a more\nversatile EEG-based system. This system should be capable of understanding a\ndriver's intention while demonstrating resilience to artifacts induced by\nsudden movements. This paper pioneers a novel research direction in\nBCI-assisted driving, studying the neural patterns related to driving\nintentions and presenting a novel method for driving intention prediction. In\nparticular, our preliminary analysis of the EEG signal using independent\ncomponent analysis suggests a close relation between the intention of driving\nmaneuvers and the neural activities in central-frontal and parietal areas.\nPower spectral density analysis at a group level also reveals a notable\ndistinction among various driving intentions in the frequency domain. To\nexploit these brain dynamics, we propose a novel Masked EEG Modeling framework\nfor predicting human driving intentions, including the intention for left\nturning, right turning, and straight proceeding. Extensive experiments,\nencompassing comprehensive quantitative and qualitative assessments on public\ndataset, demonstrate the proposed method is proficient in predicting driving\nintentions across various vigilance states. Specifically, our model attains an\naccuracy of 85.19% when predicting driving intentions for drowsy subjects,\nwhich shows its promising potential for mitigating traffic accidents related to\ndrowsy driving. Notably, our method maintains over 75% accuracy when more than\nhalf of the channels are missing or corrupted, underscoring its adaptability in\nreal-life driving.",
      "tldr_zh": "本研究针对困倦驾驶导致的事故风险，提出一种基于脑电图(EEG)的驾驶意图预测方法，旨在实现更鲁棒的人机交互。研究者通过独立成分分析(ICA)分析EEG信号，发现驾驶意图（如左转、右转和直行）与中-额叶和顶叶的神经活动密切相关，并利用功率谱密度分析揭示意图在频率域的差异。为此，他们开发了Masked EEG Modeling框架，能够预测驾驶意图并抵抗运动伪像。实验结果显示，该方法在公共数据集上准确率达85.19%，即使在困倦状态或超过一半通道缺失时，准确率仍保持在75%以上，展示了其在缓解困倦驾驶事故方面的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.07083v1",
      "published_date": "2024-08-08 03:49:05 UTC",
      "updated_date": "2024-08-08 03:49:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:59:17.725698"
    },
    {
      "arxiv_id": "2408.04679v1",
      "title": "Towards Linguistic Neural Representation Learning and Sentence Retrieval from Electroencephalogram Recordings",
      "title_zh": "翻译失败",
      "authors": [
        "Jinzhao Zhou",
        "Yiqun Duan",
        "Ziyi Zhao",
        "Yu-Cheng Chang",
        "Yu-Kai Wang",
        "Thomas Do",
        "Chin-Teng Lin"
      ],
      "abstract": "Decoding linguistic information from non-invasive brain signals using EEG has\ngained increasing research attention due to its vast applicational potential.\nRecently, a number of works have adopted a generative-based framework to decode\nelectroencephalogram (EEG) signals into sentences by utilizing the power\ngenerative capacity of pretrained large language models (LLMs). However, this\napproach has several drawbacks that hinder the further development of\nlinguistic applications for brain-computer interfaces (BCIs). Specifically, the\nability of the EEG encoder to learn semantic information from EEG data remains\nquestionable, and the LLM decoder's tendency to generate sentences based on its\ntraining memory can be hard to avoid. These issues necessitate a novel approach\nfor converting EEG signals into sentences. In this paper, we propose a novel\ntwo-step pipeline that addresses these limitations and enhances the validity of\nlinguistic EEG decoding research. We first confirm that word-level semantic\ninformation can be learned from EEG data recorded during natural reading by\ntraining a Conformer encoder via a masked contrastive objective for word-level\nclassification. To achieve sentence decoding results, we employ a training-free\nretrieval method to retrieve sentences based on the predictions from the EEG\nencoder. Extensive experiments and ablation studies were conducted in this\npaper for a comprehensive evaluation of the proposed approach. Visualization of\nthe top prediction candidates reveals that our model effectively groups EEG\nsegments into semantic categories with similar meanings, thereby validating its\nability to learn patterns from unspoken EEG recordings. Despite the exploratory\nnature of this work, these results suggest that our method holds promise for\nproviding more reliable solutions for converting EEG signals into text.",
      "tldr_zh": "本研究针对从EEG信号中解码语言信息的问题，指出现有基于生成式框架（利用LLMs）的EEG解码方法存在EEG编码器学习语义信息不足和LLM生成偏差等问题。作者提出一个新颖的两步管道：首先，使用Conformer编码器通过masked contrastive objective训练进行词级分类，以验证EEG数据中可学习语义信息；其次，采用无训练的retrieval method基于编码器预测检索句子。实验结果显示，该模型能有效将EEG段分组到语义相似的类别中，提升了EEG解码的可靠性和准确性。该方法为脑机接口（BCIs）中的语言应用提供了更可信的解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.04679v1",
      "published_date": "2024-08-08 03:40:25 UTC",
      "updated_date": "2024-08-08 03:40:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:59:30.977949"
    },
    {
      "arxiv_id": "2408.04678v1",
      "title": "CREST: Effectively Compacting a Datastore For Retrieval-Based Speculative Decoding",
      "title_zh": "翻译失败",
      "authors": [
        "Sophia Ho",
        "Jinsol Park",
        "Patrick Wang"
      ],
      "abstract": "We present CREST (Compact Retrieval-Based Speculative Decoding), a redesign\nof REST that allows it to be effectively \"compacted\". REST is a drafting\ntechnique for speculative decoding based on retrieving exact n-gram matches of\nthe most recent n tokens generated by the target LLM from a datastore. The key\nidea of CREST is to only store a subset of the smallest and most common n-grams\nin the datastore with the hope of achieving comparable performance with less\nstorage space. We found that storing a subset of n-grams both reduces storage\nspace and improves performance. CREST matches REST's accepted token length with\n10.6-13.5x less storage space and achieves a 16.5-17.1% higher acceptance\nlength than REST using the same storage space on the HumanEval and MT Bench\nbenchmarks.",
      "tldr_zh": "论文提出了 CREST，一种针对基于检索的推测解码（Retrieval-Based Speculative Decoding）的优化框架，用于有效压缩数据存储以改进 REST 方法。CREST 的关键创新是仅存储子集的最小和最常见 n-grams，这不仅减少了存储空间，还意外提升了整体性能。在 HumanEval 和 MT Bench 基准测试中，CREST 使用 10.6-13.5 倍更少的存储空间即可匹配 REST 的接受 token 长度，并在相同存储空间下实现了 16.5-17.1% 更高的接受长度。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.04678v1",
      "published_date": "2024-08-08 03:38:49 UTC",
      "updated_date": "2024-08-08 03:38:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:59:43.398042"
    },
    {
      "arxiv_id": "2408.04197v3",
      "title": "Pairwise Judgment Formulation for Semantic Embedding Model in Web Search",
      "title_zh": "翻译失败",
      "authors": [
        "Mengze Hong",
        "Di Jiang",
        "Wailing Ng",
        "Zichang Guo",
        "Chen Jason Zhang"
      ],
      "abstract": "Semantic Embedding Model (SEM), a neural network-based Siamese architecture,\nis gaining momentum in information retrieval and natural language processing.\nIn order to train SEM in a supervised fashion for Web search, the search engine\nquery log is typically utilized to automatically formulate pairwise judgments\nas training data. Despite the growing application of semantic embeddings in the\nsearch engine industry, little work has been done on formulating effective\npairwise judgments for training SEM. In this paper, we make the first in-depth\ninvestigation of a wide range of strategies for generating pairwise judgments\nfor SEM. An interesting (perhaps surprising) discovery reveals that the\nconventional pairwise judgment formulation strategy wildly used in the field of\npairwise Learning-to-Rank (LTR) is not necessarily effective for training SEM.\nThrough a large-scale empirical study based on query logs and click-through\nactivities from a major commercial search engine, we demonstrate the effective\nstrategies for SEM and highlight the advantages of a hybrid heuristic (i.e.,\nClicked > Non-Clicked) in comparison to the atomic heuristics (e.g., Clicked >\nSkipped) in LTR. We conclude with best practices for training SEM and offer\npromising insights for future research.",
      "tldr_zh": "该研究探讨了如何为 Semantic Embedding Model (SEM) 生成有效的 pairwise judgments，以提升其在 Web 搜索中的监督训练性能。论文通过分析搜索引擎查询日志和点击数据，进行大规模实证研究，比较了多种生成 pairwise judgments 的策略，并发现传统的 pairwise Learning-to-Rank (LTR) 方法（如 Clicked > Skipped）并不适合 SEM。相反，混合启发式策略（如 Clicked > Non-Clicked）显示出显著优势。最终，论文总结了训练 SEM 的最佳实践，并为未来研究提供了宝贵见解。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.04197v3",
      "published_date": "2024-08-08 03:35:35 UTC",
      "updated_date": "2025-02-02 05:54:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T13:59:54.396672"
    },
    {
      "arxiv_id": "2408.05245v1",
      "title": "Improved Adaboost Algorithm for Web Advertisement Click Prediction Based on Long Short-Term Memory Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Qixuan Yu",
        "Xirui Tang",
        "Feiyang Li",
        "Zinan Cao"
      ],
      "abstract": "This paper explores an improved Adaboost algorithm based on Long Short-Term\nMemory Networks (LSTMs), which aims to improve the prediction accuracy of user\nclicks on web page advertisements. By comparing it with several common machine\nlearning algorithms, the paper analyses the advantages of the new model in ad\nclick prediction. It is shown that the improved algorithm proposed in this\npaper performs well in user ad click prediction with an accuracy of 92%, which\nis an improvement of 13.6% compared to the highest of 78.4% among the other\nthree base models. This significant improvement indicates that the algorithm is\nmore capable of capturing user behavioural characteristics and time series\npatterns. In addition, this paper evaluates the model's performance on other\nperformance metrics, including accuracy, recall, and F1 score. The results show\nthat the improved Adaboost algorithm based on LSTM is significantly ahead of\nthe traditional model in all these metrics, which further validates its\neffectiveness and superiority. Especially when facing complex and dynamically\nchanging user behaviours, the model is able to better adapt and make accurate\npredictions. In order to ensure the practicality and reliability of the model,\nthis study also focuses on the accuracy difference between the training set and\nthe test set. After validation, the accuracy of the proposed model on these two\ndatasets only differs by 1.7%, which is a small difference indicating that the\nmodel has good generalisation ability and can be effectively applied to\nreal-world scenarios.",
      "tldr_zh": "本论文提出了一种基于 Long Short-Term Memory Networks (LSTMs) 的改进 Adaboost 算法，旨在提升网页广告点击预测的准确性，通过更好地捕捉用户行为特征和时间序列模式。相比传统机器学习算法，该模型的准确率达到92%，较最高基线模型提高13.6%。实验结果显示，该算法在准确率、召回率和 F1 分数等指标上均显著优于其他模型，且训练集与测试集的准确率差异仅1.7%，证明其良好的泛化能力和实际应用潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IR",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.05245v1",
      "published_date": "2024-08-08 03:27:02 UTC",
      "updated_date": "2024-08-08 03:27:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:00:06.782896"
    },
    {
      "arxiv_id": "2408.04193v1",
      "title": "Uncertainty-Aware Crime Prediction With Spatial Temporal Multivariate Graph Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Zepu Wang",
        "Xiaobo Ma",
        "Huajie Yang",
        "Weimin Lvu",
        "Peng Sun",
        "Sharath Chandra Guntuku"
      ],
      "abstract": "Crime forecasting is a critical component of urban analysis and essential for\nstabilizing society today. Unlike other time series forecasting problems, crime\nincidents are sparse, particularly in small regions and within specific time\nperiods. Traditional spatial-temporal deep learning models often struggle with\nthis sparsity, as they typically cannot effectively handle the non-Gaussian\nnature of crime data, which is characterized by numerous zeros and\nover-dispersed patterns. To address these challenges, we introduce a novel\napproach termed Spatial Temporal Multivariate Zero-Inflated Negative Binomial\nGraph Neural Networks (STMGNN-ZINB). This framework leverages diffusion and\nconvolution networks to analyze spatial, temporal, and multivariate\ncorrelations, enabling the parameterization of probabilistic distributions of\ncrime incidents. By incorporating a Zero-Inflated Negative Binomial model,\nSTMGNN-ZINB effectively manages the sparse nature of crime data, enhancing\nprediction accuracy and the precision of confidence intervals. Our evaluation\non real-world datasets confirms that STMGNN-ZINB outperforms existing models,\nproviding a more reliable tool for predicting and understanding crime dynamics.",
      "tldr_zh": "该研究针对犯罪预测中的数据稀疏性和非高斯分布问题（如大量零值和过分散），提出了一种Uncertainty-Aware的创新框架：Spatial Temporal Multivariate Zero-Inflated Negative Binomial Graph Neural Networks (STMGNN-ZINB)。该框架利用扩散和卷积网络来分析空间、时间和多变量相关性，并通过Zero-Inflated Negative Binomial模型参数化犯罪事件的概率分布，从而提升预测准确性和置信区间精度。在真实世界数据集上的评估显示，STMGNN-ZINB优于现有模型，提供了一个更可靠的工具，用于理解和预测犯罪动态。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.04193v1",
      "published_date": "2024-08-08 03:25:41 UTC",
      "updated_date": "2024-08-08 03:25:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:00:18.816886"
    },
    {
      "arxiv_id": "2408.04190v1",
      "title": "Listwise Reward Estimation for Offline Preference-based Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Heewoong Choi",
        "Sangwon Jung",
        "Hongjoon Ahn",
        "Taesup Moon"
      ],
      "abstract": "In Reinforcement Learning (RL), designing precise reward functions remains to\nbe a challenge, particularly when aligning with human intent. Preference-based\nRL (PbRL) was introduced to address this problem by learning reward models from\nhuman feedback. However, existing PbRL methods have limitations as they often\noverlook the second-order preference that indicates the relative strength of\npreference. In this paper, we propose Listwise Reward Estimation (LiRE), a\nnovel approach for offline PbRL that leverages second-order preference\ninformation by constructing a Ranked List of Trajectories (RLT), which can be\nefficiently built by using the same ternary feedback type as traditional\nmethods. To validate the effectiveness of LiRE, we propose a new offline PbRL\ndataset that objectively reflects the effect of the estimated rewards. Our\nextensive experiments on the dataset demonstrate the superiority of LiRE, i.e.,\noutperforming state-of-the-art baselines even with modest feedback budgets and\nenjoying robustness with respect to the number of feedbacks and feedback noise.\nOur code is available at https://github.com/chwoong/LiRE",
      "tldr_zh": "在强化学习(RL)中，设计与人类意图对齐的奖励函数是一大挑战，而偏好-based RL (PbRL) 通过人类反馈学习奖励模型，但现有方法往往忽略了表示偏好强度的第二阶偏好。论文提出 Listwise Reward Estimation (LiRE)，一种离线 PbRL 方法，通过构建 Ranked List of Trajectories (RLT) 来利用第二阶偏好信息，并使用传统三元反馈高效实现。实验在新创建的数据集上验证了 LiRE 的优越性，其在反馈预算有限的情况下 outperform 了最先进基线，并对反馈数量和噪声表现出鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "21 pages, ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.04190v1",
      "published_date": "2024-08-08 03:18:42 UTC",
      "updated_date": "2024-08-08 03:18:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:00:32.186111"
    },
    {
      "arxiv_id": "2408.04181v1",
      "title": "EdgeShield: A Universal and Efficient Edge Computing Framework for Robust AI",
      "title_zh": "EdgeShield：一个通用且高效的边缘计算框架，用于鲁",
      "authors": [
        "Duo Zhong",
        "Bojing Li",
        "Xiang Chen",
        "Chenchen Liu"
      ],
      "abstract": "The increasing prevalence of adversarial attacks on Artificial Intelligence\n(AI) systems has created a need for innovative security measures. However, the\ncurrent methods of defending against these attacks often come with a high\ncomputing cost and require back-end processing, making real-time defense\nchallenging. Fortunately, there have been remarkable advancements in\nedge-computing, which make it easier to deploy neural networks on edge devices.\nBuilding upon these advancements, we propose an edge framework design to enable\nuniversal and efficient detection of adversarial attacks. This framework\nincorporates an attention-based adversarial detection methodology and a\nlightweight detection network formation, making it suitable for a wide range of\nneural networks and can be deployed on edge devices. To assess the\neffectiveness of our proposed framework, we conducted evaluations on five\nneural networks. The results indicate an impressive 97.43% F-score can be\nachieved, demonstrating the framework's proficiency in detecting adversarial\nattacks. Moreover, our proposed framework also exhibits significantly reduced\ncomputing complexity and cost in comparison to previous detection methods. This\naspect is particularly beneficial as it ensures that the defense mechanism can\nbe efficiently implemented in real-time on-edge devices.",
      "tldr_zh": "该研究提出EdgeShield框架，这是一个通用且高效的边缘计算框架，旨在增强AI系统对adversarial attacks的鲁棒性，解决现有防御方法的高计算成本和实时性挑战。该框架整合基于注意力的检测方法和轻量级检测网络设计，使其适用于多种神经网络并易于部署在边缘设备上。通过在五个神经网络上的实验评估，EdgeShield实现了97.43%的F-score，同时显著降低了计算复杂度和成本，支持实时防御应用。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.04181v1",
      "published_date": "2024-08-08 02:57:55 UTC",
      "updated_date": "2024-08-08 02:57:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:00:42.908042"
    },
    {
      "arxiv_id": "2408.04174v1",
      "title": "wav2graph: A Framework for Supervised Learning Knowledge Graph from Speech",
      "title_zh": "wav2graph：一个用于从语音中监督学习知识图谱的框架",
      "authors": [
        "Khai Le-Duc",
        "Quy-Anh Dang",
        "Tan-Hanh Pham",
        "Truong-Son Hy"
      ],
      "abstract": "Knowledge graphs (KGs) enhance the performance of large language models\n(LLMs) and search engines by providing structured, interconnected data that\nimproves reasoning and context-awareness. However, KGs only focus on text data,\nthereby neglecting other modalities such as speech. In this work, we introduce\nwav2graph, the first framework for supervised learning knowledge graph from\nspeech data. Our pipeline are straightforward: (1) constructing a KG based on\ntranscribed spoken utterances and a named entity database, (2) converting KG\ninto embedding vectors, and (3) training graph neural networks (GNNs) for node\nclassification and link prediction tasks. Through extensive experiments\nconducted in inductive and transductive learning contexts using\nstate-of-the-art GNN models, we provide baseline results and error analysis for\nnode classification and link prediction tasks on human transcripts and\nautomatic speech recognition (ASR) transcripts, including evaluations using\nboth encoder-based and decoder-based node embeddings, as well as monolingual\nand multilingual acoustic pre-trained models. All related code, data, and\nmodels are published online.",
      "tldr_zh": "该论文提出 wav2graph 框架，这是首个从语音数据中监督学习 Knowledge Graphs (KGs) 的方法，以扩展 KGs 的应用至语音模态，并提升 Large Language Models (LLMs) 和搜索引擎的性能。框架的流程包括：基于转录的语音和命名实体数据库构建 KG、将 KG 转换为嵌入向量，以及训练 Graph Neural Networks (GNNs) 用于节点分类和链接预测任务。通过广泛实验，在归纳和传递学习场景下，对人类转录和 Automatic Speech Recognition (ASR) 转录进行了基线评估和错误分析，展示了框架的有效性。所有相关代码、数据和模型已公开在线。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "Preprint, 32 pages",
      "pdf_url": "http://arxiv.org/pdf/2408.04174v1",
      "published_date": "2024-08-08 02:36:04 UTC",
      "updated_date": "2024-08-08 02:36:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:00:56.180655"
    },
    {
      "arxiv_id": "2408.04168v3",
      "title": "Perceive, Reflect, and Plan: Designing LLM Agent for Goal-Directed City Navigation without Instructions",
      "title_zh": "翻译失败",
      "authors": [
        "Qingbin Zeng",
        "Qinglong Yang",
        "Shunan Dong",
        "Heming Du",
        "Liang Zheng",
        "Fengli Xu",
        "Yong Li"
      ],
      "abstract": "This paper considers a scenario in city navigation: an AI agent is provided\nwith language descriptions of the goal location with respect to some well-known\nlandmarks; By only observing the scene around, including recognizing landmarks\nand road network connections, the agent has to make decisions to navigate to\nthe goal location without instructions. This problem is very challenging,\nbecause it requires agent to establish self-position and acquire spatial\nrepresentation of complex urban environment, where landmarks are often\ninvisible. In the absence of navigation instructions, such abilities are vital\nfor the agent to make high-quality decisions in long-range city navigation.\nWith the emergent reasoning ability of large language models (LLMs), a tempting\nbaseline is to prompt LLMs to \"react\" on each observation and make decisions\naccordingly. However, this baseline has very poor performance that the agent\noften repeatedly visits same locations and make short-sighted, inconsistent\ndecisions. To address these issues, this paper introduces a novel agentic\nworkflow featured by its abilities to perceive, reflect and plan. Specifically,\nwe find LLaVA-7B can be fine-tuned to perceive the direction and distance of\nlandmarks with sufficient accuracy for city navigation. Moreover, reflection is\nachieved through a memory mechanism, where past experiences are stored and can\nbe retrieved with current perception for effective decision argumentation.\nPlanning uses reflection results to produce long-term plans, which can avoid\nshort-sighted decisions in long-range navigation. We show the designed workflow\nsignificantly improves navigation ability of the LLM agent compared with the\nstate-of-the-art baselines.",
      "tldr_zh": "这篇论文探讨了在无指令指导下设计LLM代理进行目标导向的城市导航问题，代理需通过观察场景（如识别地标和道路网络）来定位自身并规划路径，以应对复杂城市环境的挑战。作者提出了一种新型代理工作流，包括Perceive（通过微调LLaVA-7B准确感知地标的方向和距离）、Reflect（利用记忆机制存储并检索过去经验以支持决策论证）以及Plan（基于反思结果制定长期计划，避免短视决策）。实验结果显示，该工作流显著提升了LLM代理的导航性能，优于现有基线方法。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.04168v3",
      "published_date": "2024-08-08 02:28:43 UTC",
      "updated_date": "2024-10-17 06:43:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:01:17.968713"
    },
    {
      "arxiv_id": "2408.12605v1",
      "title": "Convolutional Neural Networks for Predictive Modeling of Lung Disease",
      "title_zh": "翻译失败",
      "authors": [
        "Yingbin Liang",
        "Xiqing Liu",
        "Haohao Xia",
        "Yiru Cang",
        "Zitao Zheng",
        "Yuanfang Yang"
      ],
      "abstract": "In this paper, Pro-HRnet-CNN, an innovative model combining HRNet and\nvoid-convolution techniques, is proposed for disease prediction under lung\nimaging. Through the experimental comparison on the authoritative LIDC-IDRI\ndataset, we found that compared with the traditional ResNet-50, Pro-HRnet-CNN\nshowed better performance in the feature extraction and recognition of\nsmall-size nodules, significantly improving the detection accuracy.\nParticularly within the domain of detecting smaller targets, the model has\nexhibited a remarkable enhancement in accuracy, thereby pioneering an\ninnovative avenue for the early identification and prognostication of pulmonary\nconditions.",
      "tldr_zh": "本研究提出了一种创新模型 Pro-HRnet-CNN，通过结合 HRNet 和 void-convolution 技术，用于肺部影像的疾病预测。实验在权威的 LIDC-IDRI 数据集上与传统 ResNet-50 进行比较，结果显示 Pro-HRnet-CNN 在小尺寸结节的特征提取和识别方面表现出色，显著提高了检测准确率。特别是在检测较小目标时，该模型的准确性有显著提升，为肺部疾病的早期识别和预后开辟了新途径。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "7 pages",
      "pdf_url": "http://arxiv.org/pdf/2408.12605v1",
      "published_date": "2024-08-08 01:58:46 UTC",
      "updated_date": "2024-08-08 01:58:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:01:18.793553"
    },
    {
      "arxiv_id": "2408.04154v1",
      "title": "The Data Addition Dilemma",
      "title_zh": "数据添加困境",
      "authors": [
        "Judy Hanwen Shen",
        "Inioluwa Deborah Raji",
        "Irene Y. Chen"
      ],
      "abstract": "In many machine learning for healthcare tasks, standard datasets are\nconstructed by amassing data across many, often fundamentally dissimilar,\nsources. But when does adding more data help, and when does it hinder progress\non desired model outcomes in real-world settings? We identify this situation as\nthe \\textit{Data Addition Dilemma}, demonstrating that adding training data in\nthis multi-source scaling context can at times result in reduced overall\naccuracy, uncertain fairness outcomes, and reduced worst-subgroup performance.\nWe find that this possibly arises from an empirically observed trade-off\nbetween model performance improvements due to data scaling and model\ndeterioration from distribution shift. We thus establish baseline strategies\nfor navigating this dilemma, introducing distribution shift heuristics to guide\ndecision-making on which data sources to add in data scaling, in order to yield\nthe expected model performance improvements. We conclude with a discussion of\nthe required considerations for data collection and suggestions for studying\ndata composition and scale in the age of increasingly larger models.",
      "tldr_zh": "这篇论文探讨了机器学习在医疗任务中的“Data Addition Dilemma”，即从多个不同来源添加数据可能导致整体准确率下降、不确定的公平性结果以及最差子群体性能降低。研究发现，这种现象源于数据规模带来的性能提升与distribution shift导致的模型退化之间的权衡。作者引入了distribution shift启发式方法作为基线策略，以指导数据来源的选择，确保添加数据能实现预期的模型改进。最后，论文讨论了数据收集的必要考虑，以及在大数据时代研究数据组成和规模的重要性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Machine Learning For Health Care 2024 (MLHC)",
      "pdf_url": "http://arxiv.org/pdf/2408.04154v1",
      "published_date": "2024-08-08 01:42:31 UTC",
      "updated_date": "2024-08-08 01:42:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:01:32.082701"
    },
    {
      "arxiv_id": "2408.12604v1",
      "title": "Generational Computation Reduction in Informal Counterexample-Driven Genetic Programming",
      "title_zh": "翻译失败",
      "authors": [
        "Thomas Helmuth",
        "Edward Pantridge",
        "James Gunder Frazier",
        "Lee Spector"
      ],
      "abstract": "Counterexample-driven genetic programming (CDGP) uses specifications provided\nas formal constraints to generate the training cases used to evaluate evolving\nprograms. It has also been extended to combine formal constraints and\nuser-provided training data to solve symbolic regression problems. Here we show\nhow the ideas underlying CDGP can also be applied using only user-provided\ntraining data, without formal specifications. We demonstrate the application of\nthis method, called ``informal CDGP,'' to software synthesis problems. Our\nresults show that informal CDGP finds solutions faster (i.e. with fewer program\nexecutions) than standard GP. Additionally, we propose two new variants to\ninformal CDGP, and find that one produces significantly more successful runs on\nabout half of the tested problems. Finally, we study whether the addition of\ncounterexample training cases to the training set is useful by comparing\ninformal CDGP to using a static subsample of the training set, and find that\nthe addition of counterexamples significantly improves performance.",
      "tldr_zh": "本研究提出了一种名为 informal Counterexample-Driven Genetic Programming (informal CDGP) 的方法，该方法仅使用用户提供的训练数据，而不依赖正式规范，应用于软件合成问题。结果显示，informal CDGP 比标准 Genetic Programming (GP) 需要更少的程序执行来找到解决方案，从而减少了计算量。此外，研究引入了两个新变体，其中一个在约一半测试问题上显著提高了成功率；同时，通过比较发现，添加反例训练案例显著提升了性能。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12604v1",
      "published_date": "2024-08-08 01:06:28 UTC",
      "updated_date": "2024-08-08 01:06:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:01:42.895975"
    },
    {
      "arxiv_id": "2408.04140v1",
      "title": "UNLEARN Efficient Removal of Knowledge in Large Language Models",
      "title_zh": "UNLEARN：大语言模型中知识的高效移除",
      "authors": [
        "Tyler Lizzo",
        "Larry Heck"
      ],
      "abstract": "Given the prevalence of large language models (LLMs) and the prohibitive cost\nof training these models from scratch, dynamically forgetting specific\nknowledge e.g., private or proprietary, without retraining the model has become\nan important capability. This paper proposes a novel method to achieve this\nobjective called UNLEARN. The approach builds upon subspace methods to identify\nand specifically target the removal of knowledge without adversely affecting\nother knowledge in the LLM. Results demonstrate 96% of targeted knowledge can\nbe forgotten while maintaining performance on other knowledge within 2.5% of\nthe original model, significantly outperforming the discriminatory abilities of\nthe previous state-of-the-art. A dual method called LEARN is also proposed for\ntargeted knowledge addition. Results show LEARN can match the fine-tuning\naccuracy of Low-Rank Adaptation (LoRA) without adversely affecting similar\ntasks.",
      "tldr_zh": "本论文提出 UNLEARN 方法，用于从大语言模型 (LLMs) 中高效移除特定知识（如私有或专有信息），而无需重新训练模型。UNLEARN 基于子空间方法，精确识别并针对性地删除目标知识，同时确保其他知识的性能仅下降 2.5%。实验结果显示，该方法可忘记 96% 的目标知识，比之前的最先进技术表现出色；此外，论文还引入 LEARN 方法，用于针对性添加知识，能匹配 Low-Rank Adaptation (LoRA) 的微调准确性，而不影响类似任务。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "11 pages, 2 Figures",
      "pdf_url": "http://arxiv.org/pdf/2408.04140v1",
      "published_date": "2024-08-08 00:53:31 UTC",
      "updated_date": "2024-08-08 00:53:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:01:55.588882"
    },
    {
      "arxiv_id": "2408.04138v1",
      "title": "Enhancing Healthcare through Large Language Models: A Study on Medical Question Answering",
      "title_zh": "通过大型语言模型增强医疗保健：医疗问答研究",
      "authors": [
        "Haoran Yu",
        "Chang Yu",
        "Zihan Wang",
        "Dongxian Zou",
        "Hao Qin"
      ],
      "abstract": "In recent years, the application of Large Language Models (LLMs) in\nhealthcare has shown significant promise in improving the accessibility and\ndissemination of medical knowledge. This paper presents a detailed study of\nvarious LLMs trained on the MedQuAD medical question-answering dataset, with a\nfocus on identifying the most effective model for providing accurate medical\ninformation. Among the models tested, the Sentence-t5 combined with Mistral 7B\ndemonstrated superior performance, achieving a precision score of 0.762. This\nmodel's enhanced capabilities are attributed to its advanced pretraining\ntechniques, robust architecture, and effective prompt construction\nmethodologies. By leveraging these strengths, the Sentence-t5 + Mistral 7B\nmodel excels in understanding and generating precise medical answers. Our\nfindings highlight the potential of integrating sophisticated LLMs in medical\ncontexts to facilitate efficient and accurate medical knowledge retrieval, thus\nsignificantly enhancing patient education and support.",
      "tldr_zh": "本研究探讨了Large Language Models (LLMs)在医疗领域的应用，特别针对医疗问答任务，使用MedQuAD数据集训练并测试多种模型。结果表明，Sentence-t5结合Mistral 7B模型表现出色，精确度达到0.762，这归功于其高级预训练技术、稳健架构和有效的提示构建方法。该模型的优异性能突显了LLMs在提升医疗知识检索、患者教育和支持方面的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "received by IEEE ICPICS",
      "pdf_url": "http://arxiv.org/pdf/2408.04138v1",
      "published_date": "2024-08-08 00:35:39 UTC",
      "updated_date": "2024-08-08 00:35:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:02:07.720656"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 94,
  "processed_papers_count": 94,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-19T14:02:31.536290"
}