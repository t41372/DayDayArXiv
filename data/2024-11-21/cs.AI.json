{
  "date": "2024-11-21",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-11-21 的 arXiv 中文 TLDR 快报！今天 arXiv 更新了 96 篇论文，主要聚焦 AI 模型优化、LLM 安全与鲁棒性、多模态生成和强化学习等领域，其中令人印象深刻的包括 LLM 在公平性与准确性权衡上的探索（如 Martha Lewis 和 Melanie Mitchell 的工作）和多代理系统的创新应用（如 Yingxuan Yang 等人的研究），这些论文突出了 LLM 在实际部署中的挑战与潜力。\n\n下面，我挑选并简要讨论了部分重要或话题度高的论文，先从 AI 和 LLM 核心领域入手，再快速触及相关交叉主题。其他论文（如一些特定领域的生物或物理研究）仅列出标题并略过，以控制篇幅。\n\n### AI 和 LLM 核心领域\n- **Generative AI for Music and Audio（生成式 AI 用于音乐和音频）**  \n  作者：Hao-Wen Dong（PhD Dissertation）。这篇论文探讨了生成式 AI 在音乐生成、多模态学习等方面的应用，主要贡献是通过三方面研究（多轨音乐生成、辅助工具和多模态学习）降低音乐创作门槛，实现 AI 与人类学习方式的相似性，潜在影响音乐 AI 的民主化。\n\n- **Exploring Accuracy-Fairness Trade-off in Large Language Models（探索大型语言模型的准确性与公平性权衡）**  \n  作者：Qingquan Zhang 等。该研究通过多目标进化学习分析 LLM 在准确性和公平性间的冲突，核心发现是优化框架能生成 Pareto 最优模型，提高了 LLM 在伦理应用中的鲁棒性，强调了实际部署中的平衡挑战。\n\n- **LLM-based Multi-Agent Systems: Techniques and Business Perspectives（基于 LLM 的多代理系统：技术与商业视角）**  \n  作者：Yingxuan Yang 等。论文提出多代理框架，结合 LLM 实现动态任务分解和知识共享，主要贡献是提升系统灵活性和商业可行性，如隐私保护和实体货币化，适用于复杂协作场景。\n\n- **Do I Know This Entity? Knowledge Awareness and Hallucinations in Language Models（我认识这个实体吗？语言模型的知识感知与幻觉问题）**  \n  作者：Javier Ferrando 等。研究使用稀疏自编码器发现 LLM 的实体识别机制，核心发现是这些机制能检测模型知识盲区，并通过因果干预减少幻觉，提供可解释性提升。\n\n- **GenBFA: An Evolutionary Optimization Approach to Bit-Flip Attacks on LLMs（GenBFA：针对 LLM 的进化优化位翻转攻击方法）**  \n  作者：Sanjay Das 等。该工作首次展示少数位翻转即可破坏 LLM 性能，核心贡献是提出 AttentionBreaker 框架和进化优化策略，揭示了 LLM 在硬件攻击下的脆弱性。\n\n- **Evaluation-Driven Development of LLM Agents: A Process Model and Reference Architecture（评估驱动的 LLM 代理开发：过程模型与参考架构）**  \n  作者：Boming Xia 等。论文引入评估驱动方法应对 LLM 代理的动态性，核心发现是通过在线和离线评估实现持续优化，提高了代理的安全性和适应性。\n\n### 图像生成和视觉语言模型\n- **PIORS: Personalized Intelligent Outpatient Reception based on Large Language Model with Multi-Agents Medical Scenario Simulation（PIORS：基于多代理医疗场景模拟的个性化智能门诊系统）**  \n  作者：Zhijie Bao 等。该研究构建多代理 LLM 系统用于医疗门诊，核心贡献是生成框架提升了系统效率和准确性，如在真实场景中实现个性化服务。\n\n- **Global Challenge for Safe and Secure LLMs Track 1（全球 LLM 安全挑战赛 Track 1）**  \n  作者：Xiaojun Jia 等。这是一场针对 LLM 安全性的挑战，核心发现是自动攻击方法暴露了模型漏洞，推动了防御机制的开发。\n\n- **Tiny-Align: Bridging Automatic Speech Recognition and Large Language Model on the Edge（Tiny-Align：在边缘设备桥接自动语音识别与大型语言模型）**  \n  作者：Ruiyang Qin 等。论文提出高效对齐框架，核心贡献是减少计算资源，实现边缘设备的跨模态集成，提高了音频处理性能。\n\n- **FuseGPT: Learnable Layers Fusion of Generative Pre-trained Transformers（FuseGPT：生成式预训练 Transformer 的可学习层融合）**  \n  作者：Zehua Pei 等。该工作优化了 LLM 层融合，核心发现是通过迭代融合减少参数冗余，提升了模型在视觉和语言任务中的效率。\n\n### 其他快速掠过\n以下论文主题较 nich 或交叉领域，仅简要概述核心贡献：\n- **Stain-Invariant Representation for Tissue Classification in Histology Images（染色不变表示用于组织学图像分类）**  \n  贡献：提出框架生成染色增强图像，提高病理图像分类鲁棒性。\n- **Beneath the Surface: The Role of Underwater Image Enhancement in Object Detection（水下图像增强在物体检测中的作用）**  \n  贡献：评估图像增强对水下检测的影响，发现选择性增强可提升性能。\n- **Adaptive Intelligence: leveraging insights from adaptive behavior in animals to build flexible AI systems（适应性智能：利用动物适应行为构建灵活 AI 系统）**  \n  贡献：从神经科学视角提出脑启发算法，提升 AI 的在线学习能力。\n- **When Online Algorithms Influence the Environment: A Dynamical Systems Analysis（在线算法影响环境：动态系统分析）**  \n  贡献：分析算法与环境耦合效应，揭示推荐系统可能导致用户偏好同质化。\n- **Logic Augmented Generation（逻辑增强生成）**  \n  贡献：结合知识图谱和 LLM 减少生成式幻觉，提高输出可靠性。\n\n今天的论文整体上强调了 AI 系统的鲁棒性和实际应用潜力，但也暴露了安全隐患。感兴趣的读者可关注 LLM 代理和对抗攻击领域的发展！",
  "papers": [
    {
      "arxiv_id": "2411.14633v1",
      "title": "Evaluating Representational Similarity Measures from the Lens of Functional Correspondence",
      "title_zh": "从功能对应视角评估表示相似性度量",
      "authors": [
        "Yiqing Bo",
        "Ansh Soni",
        "Sudhanshu Srivastava",
        "Meenakshi Khosla"
      ],
      "abstract": "Neuroscience and artificial intelligence (AI) both face the challenge of\ninterpreting high-dimensional neural data, where the comparative analysis of\nsuch data is crucial for revealing shared mechanisms and differences between\nthese complex systems. Despite the widespread use of representational\ncomparisons and the abundance classes of comparison methods, a critical\nquestion remains: which metrics are most suitable for these comparisons? While\nsome studies evaluate metrics based on their ability to differentiate models of\ndifferent origins or constructions (e.g., various architectures), another\napproach is to assess how well they distinguish models that exhibit distinct\nbehaviors. To investigate this, we examine the degree of alignment between\nvarious representational similarity measures and behavioral outcomes, employing\ngroup statistics and a comprehensive suite of behavioral metrics for\ncomparison. In our evaluation of eight commonly used representational\nsimilarity metrics in the visual domain -- spanning alignment-based, Canonical\nCorrelation Analysis (CCA)-based, inner product kernel-based, and\nnearest-neighbor methods -- we found that metrics like linear Centered Kernel\nAlignment (CKA) and Procrustes distance, which emphasize the overall geometric\nstructure or shape of representations, excelled in differentiating trained from\nuntrained models and aligning with behavioral measures, whereas metrics such as\nlinear predictivity, commonly used in neuroscience, demonstrated only moderate\nalignment with behavior. These insights are crucial for selecting metrics that\nemphasize behaviorally meaningful comparisons in NeuroAI research.",
      "tldr_zh": "这篇论文从功能对应性的角度评估了各种表示相似性 measures，用于神经科学和 AI 中高维神经数据的比较，旨在确定哪些 metrics 最适合揭示系统间的共享机制和行为差异。研究者通过群统计和行为指标，比较了八种常用 metrics，包括基于对齐、Canonical Correlation Analysis (CCA)-based、内积核-based 和最近邻方法。结果发现，linear Centered Kernel Alignment (CKA) 和 Procrustes distance 等强调表示几何结构的 metrics，在区分训练与未训练模型以及与行为结果的关联性上表现出色，而 linear predictivity 等 metrics 仅显示中等一致性。这些见解为 NeuroAI 研究提供了指导，帮助选择更注重行为意义的比较方法。",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "q-bio.NC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.14633v1",
      "published_date": "2024-11-21 23:53:58 UTC",
      "updated_date": "2024-11-21 23:53:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:43:43.628800"
    },
    {
      "arxiv_id": "2411.15237v1",
      "title": "Stain-Invariant Representation for Tissue Classification in Histology Images",
      "title_zh": "翻译失败",
      "authors": [
        "Manahil Raza",
        "Saad Bashir",
        "Talha Qaiser",
        "Nasir Rajpoot"
      ],
      "abstract": "The process of digitising histology slides involves multiple factors that can\naffect a whole slide image's (WSI) final appearance, including the staining\nprotocol, scanner, and tissue type. This variability constitutes a domain shift\nand results in significant problems when training and testing deep learning\n(DL) algorithms in multi-cohort settings. As such, developing robust and\ngeneralisable DL models in computational pathology (CPath) remains an open\nchallenge. In this regard, we propose a framework that generates\nstain-augmented versions of the training images using stain matrix\nperturbation. Thereafter, we employed a stain regularisation loss to enforce\nconsistency between the feature representations of the source and augmented\nimages. Doing so encourages the model to learn stain-invariant and,\nconsequently, domain-invariant feature representations. We evaluate the\nperformance of the proposed model on cross-domain multi-class tissue type\nclassification of colorectal cancer images and have achieved improved\nperformance compared to other state-of-the-art methods.",
      "tldr_zh": "该研究针对组织学图像（histology images）中染色协议、扫描仪等因素导致的领域偏移（domain shift）问题，提出了一种框架，以提高深度学习（DL）模型在多队列设置下的鲁棒性和泛化性。框架通过染色矩阵扰动（stain matrix perturbation）生成训练图像的染色增强版本，并引入染色正则化损失（stain regularisation loss），强制模型在源图像和增强图像之间学习一致的特征表示，从而实现染色不变（stain-invariant）和领域不变（domain-invariant）的表示。实验结果显示，该模型在结直肠癌图像的跨领域多类组织类型分类任务上，性能超过了现有最先进方法。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.15237v1",
      "published_date": "2024-11-21 23:50:30 UTC",
      "updated_date": "2024-11-21 23:50:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:43:55.010824"
    },
    {
      "arxiv_id": "2411.14627v1",
      "title": "Generative AI for Music and Audio",
      "title_zh": "翻译失败",
      "authors": [
        "Hao-Wen Dong"
      ],
      "abstract": "Generative AI has been transforming the way we interact with technology and\nconsume content. In the next decade, AI technology will reshape how we create\naudio content in various media, including music, theater, films, games,\npodcasts, and short videos. In this dissertation, I introduce the three main\ndirections of my research centered around generative AI for music and audio: 1)\nmultitrack music generation, 2) assistive music creation tools, and 3)\nmultimodal learning for audio and music. Through my research, I aim to answer\nthe following two fundamental questions: 1) How can AI help professionals or\namateurs create music and audio content? 2) Can AI learn to create music in a\nway similar to how humans learn music? My long-term goal is to lower the\nbarrier of entry for music composition and democratize audio content creation",
      "tldr_zh": "这篇论文探讨了 Generative AI 在音乐和音频领域的应用，介绍了三个主要研究方向：1) multitrack music generation，2) assistive music creation tools，以及3) multimodal learning for audio and music。作者旨在回答两个核心问题：AI 如何帮助专业人士或业余爱好者创建音乐和音频内容，以及 AI 是否能像人类学习音乐那样进行创作。最终，该研究的目标是降低音乐创作门槛，实现音频内容制作的民主化。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG",
        "cs.MM",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "PhD Dissertation",
      "pdf_url": "http://arxiv.org/pdf/2411.14627v1",
      "published_date": "2024-11-21 23:02:12 UTC",
      "updated_date": "2024-11-21 23:02:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:44:06.154559"
    },
    {
      "arxiv_id": "2411.14626v3",
      "title": "Beneath the Surface: The Role of Underwater Image Enhancement in Object Detection",
      "title_zh": "水面之下：水下图像增强在物体检测中的作用",
      "authors": [
        "Ali Awad",
        "Ashraf Saleem",
        "Sidike Paheding",
        "Evan Lucas",
        "Serein Al-Ratrout",
        "Timothy C. Havens"
      ],
      "abstract": "Underwater imagery often suffers from severe degradation resulting in low\nvisual quality and reduced object detection performance. This work aims to\nevaluate state-of-the-art image enhancement models, investigate their effects\non underwater object detection, and explore their potential to improve\ndetection performance. To this end, we apply nine recent underwater image\nenhancement models, covering physical, non-physical and learning-based\ncategories, to two recent underwater image datasets. Following this, we conduct\njoint qualitative and quantitative analyses on the original and enhanced\nimages, revealing the discrepancy between the two analyses, and analyzing\nchanges in the quality distribution of the images after enhancement. We then\ntrain three recent object detection models on the original datasets, selecting\nthe best-performing detector for further analysis. This detector is\nsubsequently re-trained on the enhanced datasets to evaluate changes in\ndetection performance, highlighting the adverse effect of enhancement on\ndetection performance at the dataset level. Next, we perform a correlation\nstudy to examine the relationship between various enhancement metrics and the\nmean Average Precision (mAP). Finally, we conduct an image-level analysis that\nreveals images of improved detection performance after enhancement. The\nfindings of this study demonstrate the potential of image enhancement to\nimprove detection performance and provide valuable insights for researchers to\nfurther explore the effects of enhancement on detection at the individual image\nlevel, rather than at the dataset level. This could enable the selective\napplication of enhancement for improved detection. The data generated, code\ndeveloped, and supplementary materials are publicly available at:\nhttps://github.com/RSSL-MTU/Enhancement-Detection-Analysis.",
      "tldr_zh": "这篇论文探讨了水下图像增强在物体检测中的作用，针对水下图像的严重退化问题（如低视觉质量和检测性能下降）进行了评估。研究者应用了九种最新的增强模型（涵盖物理、非物理和基于学习的类别）到两个水下图像数据集，并通过定性和定量分析比较了原始和增强图像的效果。结果显示，虽然在数据集级别上图像增强可能对物体检测性能（如mAP）产生负面影响，但图像级分析表明某些图像的检测性能有所改善。该研究提供了宝贵见解，建议未来在图像级别优化增强策略，并公开了相关数据、代码和补充材料以促进进一步研究。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.14626v3",
      "published_date": "2024-11-21 22:59:15 UTC",
      "updated_date": "2025-04-18 01:11:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:44:18.963951"
    },
    {
      "arxiv_id": "2411.14625v1",
      "title": "Predictive Analytics of Air Alerts in the Russian-Ukrainian War",
      "title_zh": "翻译失败",
      "authors": [
        "Demian Pavlyshenko",
        "Bohdan Pavlyshenko"
      ],
      "abstract": "The paper considers exploratory data analysis and approaches in predictive\nanalytics for air alerts during the Russian-Ukrainian war which broke out on\nFeb 24, 2022. The results illustrate that alerts in regions correlate with one\nanother and have geospatial patterns which make it feasible to build a\npredictive model which predicts alerts that are expected to take place in a\ncertain region within a specified time period. The obtained results show that\nthe alert status in a particular region is highly dependable on the features of\nits adjacent regions. Seasonality features like hours, days of a week and\nmonths are also crucial in predicting the target variable. Some regions highly\nrely on the time feature which equals to a number of days from the initial date\nof the dataset. From this, we can deduce that the air alert pattern changes\nthroughout the time.",
      "tldr_zh": "这篇论文探讨了俄罗斯-乌克兰战争（从2022年2月24日开始）中空袭警报的探索性数据分析和predictive analytics方法。研究发现，警报在不同地区之间存在相关性和geospatial patterns，这使得构建预测模型成为可能，用于预测特定地区在指定时间段内的警报发生。结果显示，一个地区的警报状态高度依赖于相邻地区的特征，以及seasonality features如小时、星期几和月份；此外，警报模式会随着时间（如从数据集起始日期算起的天数）而变化。总的来说，该工作突出了这些因素在提升预测准确性方面的作用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.14625v1",
      "published_date": "2024-11-21 22:58:39 UTC",
      "updated_date": "2024-11-21 22:58:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:44:31.207441"
    },
    {
      "arxiv_id": "2411.15235v2",
      "title": "CODE-CL: Conceptor-Based Gradient Projection for Deep Continual Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Marco Paul E. Apolinario",
        "Sakshi Choudhary",
        "Kaushik Roy"
      ],
      "abstract": "Continual learning (CL) - the ability to progressively acquire and integrate\nnew concepts - is essential to intelligent systems to adapt to dynamic\nenvironments. However, deep neural networks struggle with catastrophic\nforgetting (CF) when learning tasks sequentially, as training for new tasks\noften overwrites previously learned knowledge. To address this, recent\napproaches constrain updates to orthogonal subspaces using gradient projection,\neffectively preserving important gradient directions for previous tasks. While\neffective in reducing forgetting, these approaches inadvertently hinder forward\nknowledge transfer (FWT), particularly when tasks are highly correlated. In\nthis work, we propose Conceptor-based gradient projection for Deep Continual\nLearning (CODE-CL), a novel method that leverages conceptor matrix\nrepresentations, a form of regularized reconstruction, to adaptively handle\nhighly correlated tasks. CODE-CL mitigates CF by projecting gradients onto\npseudo-orthogonal subspaces of previous task feature spaces while\nsimultaneously promoting FWT. It achieves this by learning a linear combination\nof shared basis directions, allowing efficient balance between stability and\nplasticity and transfer of knowledge between overlapping input feature\nrepresentations. Extensive experiments on continual learning benchmarks\nvalidate CODE-CL's efficacy, demonstrating superior performance, reduced\nforgetting, and improved FWT as compared to state-of-the-art methods.",
      "tldr_zh": "该研究针对深度神经网络在Continual Learning（CL）中的Catastrophic Forgetting（CF）问题，提出了一种新方法CODE-CL，利用Conceptor matrix表示来实现梯度投影。该方法通过将梯度投影到previous task feature spaces的伪正交子空间，平衡了稳定性（stability）和可塑性（plasticity），从而减少CF并促进Forward Knowledge Transfer（FWT）。实验结果显示，CODE-CL在Continual Learning基准上比现有方法表现出色，显著降低了遗忘并提升了知识转移性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "12 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.15235v2",
      "published_date": "2024-11-21 22:31:06 UTC",
      "updated_date": "2025-03-07 22:46:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:44:43.192783"
    },
    {
      "arxiv_id": "2411.14612v2",
      "title": "Exploiting Boosting in Hyperdimensional Computing for Enhanced Reliability in Healthcare",
      "title_zh": "翻译失败",
      "authors": [
        "SungHeon Jeong",
        "Hamza Errahmouni Barkam",
        "Sanggeon Yun",
        "Yeseong Kim",
        "Shaahin Angizi",
        "Mohsen Imani"
      ],
      "abstract": "Hyperdimensional computing (HDC) enables efficient data encoding and\nprocessing in high-dimensional space, benefiting machine learning and data\nanalysis. However, underutilization of these spaces can lead to overfitting and\nreduced model reliability, especially in data-limited systems a critical issue\nin sectors like healthcare that demand robustness and consistent performance.\nWe introduce BoostHD, an approach that applies boosting algorithms to partition\nthe hyperdimensional space into subspaces, creating an ensemble of weak\nlearners. By integrating boosting with HDC, BoostHD enhances performance and\nreliability beyond existing HDC methods. Our analysis highlights the importance\nof efficient utilization of hyperdimensional spaces for improved model\nperformance. Experiments on healthcare datasets show that BoostHD outperforms\nstate-of-the-art methods. On the WESAD dataset, it achieved an accuracy of\n98.37%, surpassing Random Forest, XGBoost, and OnlineHD. BoostHD also\ndemonstrated superior inference efficiency and stability, maintaining high\naccuracy under data imbalance and noise. In person-specific evaluations, it\nachieved an average accuracy of 96.19%, outperforming other models. By\naddressing the limitations of both boosting and HDC, BoostHD expands the\napplicability of HDC in critical domains where reliability and precision are\nparamount.",
      "tldr_zh": "该论文提出 BoostHD，一种将 boosting 算法整合到 Hyperdimensional Computing (HDC) 中的方法，通过分区高维空间创建弱学习器的集合，以解决 HDC 在数据有限系统中的过拟合和可靠性问题，尤其适用于医疗领域。BoostHD 提升了模型的性能和稳定性，实验结果显示在 WESAD 数据集上其准确率达到 98.37%，优于 Random Forest、XGBoost 和 OnlineHD，并在数据不平衡及噪声条件下保持高准确率（平均 96.19%）。这一创新扩展了 HDC 在可靠性要求高的关键领域的应用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to DATE 2025",
      "pdf_url": "http://arxiv.org/pdf/2411.14612v2",
      "published_date": "2024-11-21 22:28:45 UTC",
      "updated_date": "2025-01-14 00:20:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:46:48.400882"
    },
    {
      "arxiv_id": "2411.14593v2",
      "title": "A Systematic Study of Multi-Agent Deep Reinforcement Learning for Safe and Robust Autonomous Highway Ramp Entry",
      "title_zh": "翻译失败",
      "authors": [
        "Larry Schester",
        "Luis E. Ortiz"
      ],
      "abstract": "Vehicles today can drive themselves on highways and driverless robotaxis\noperate in major cities, with more sophisticated levels of autonomous driving\nexpected to be available and become more common in the future. Yet, technically\nspeaking, so-called \"Level 5\" (L5) operation, corresponding to full autonomy,\nhas not been achieved. For that to happen, functions such as fully autonomous\nhighway ramp entry must be available, and provide provably safe, and reliably\nrobust behavior to enable full autonomy. We present a systematic study of a\nhighway ramp function that controls the vehicles forward-moving actions to\nminimize collisions with the stream of highway traffic into which a merging\n(ego) vehicle enters. We take a game-theoretic multi-agent (MA) approach to\nthis problem and study the use of controllers based on deep reinforcement\nlearning (DRL). The virtual environment of the MA DRL uses self-play with\nsimulated data where merging vehicles safely learn to control longitudinal\nposition during a taper-type merge. The work presented in this paper extends\nexisting work by studying the interaction of more than two vehicles (agents)\nand does so by systematically expanding the road scene with additional traffic\nand ego vehicles. While previous work on the two-vehicle setting established\nthat collision-free controllers are theoretically impossible in fully\ndecentralized, non-coordinated environments, we empirically show that\ncontrollers learned using our approach are nearly ideal when measured against\nidealized optimal controllers.",
      "tldr_zh": "该研究系统探讨了多智能体深度强化学习（Multi-Agent Deep Reinforcement Learning）在实现安全、鲁棒的自动驾驶高速公路坡道入口方面的应用，旨在解决全自治（Level 5）驾驶面临的挑战。研究采用游戏理论方法，通过自博弈（self-play）和模拟环境训练控制器，使合并车辆（ego vehicle）安全控制纵向位置并最小化与车流碰撞的风险。相比现有仅限于两车辆互动的工作，本文扩展到多个车辆场景，并通过系统增加交通车辆进行验证。实验结果显示，学得的DRL控制器在实际表现上几乎与理想化最优控制器相当，尽管在完全去中心化环境中理论上存在碰撞风险。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG",
        "cs.MA",
        "cs.SY",
        "eess.SY",
        "I.2.9; I.2.11; I.2.6; I.2.8"
      ],
      "primary_category": "cs.RO",
      "comment": "9 pages, 9 figures; added support ack",
      "pdf_url": "http://arxiv.org/pdf/2411.14593v2",
      "published_date": "2024-11-21 21:23:46 UTC",
      "updated_date": "2025-01-17 01:00:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:45:07.369885"
    },
    {
      "arxiv_id": "2411.14592v2",
      "title": "G-RAG: Knowledge Expansion in Material Science",
      "title_zh": "翻译失败",
      "authors": [
        "Radeen Mostafa",
        "Mirza Nihal Baig",
        "Mashaekh Tausif Ehsan",
        "Jakir Hasan"
      ],
      "abstract": "In the field of Material Science, effective information retrieval systems are\nessential for facilitating research. Traditional Retrieval-Augmented Generation\n(RAG) approaches in Large Language Models (LLMs) often encounter challenges\nsuch as outdated information, hallucinations, limited interpretability due to\ncontext constraints, and inaccurate retrieval. To address these issues, Graph\nRAG integrates graph databases to enhance the retrieval process. Our proposed\nmethod processes Material Science documents by extracting key entities\n(referred to as MatIDs) from sentences, which are then utilized to query\nexternal Wikipedia knowledge bases (KBs) for additional relevant information.\nWe implement an agent-based parsing technique to achieve a more detailed\nrepresentation of the documents. Our improved version of Graph RAG called G-RAG\nfurther leverages a graph database to capture relationships between these\nentities, improving both retrieval accuracy and contextual understanding. This\nenhanced approach demonstrates significant improvements in performance for\ndomains that require precise information retrieval, such as Material Science.",
      "tldr_zh": "该论文针对材料科学领域的传统Retrieval-Augmented Generation (RAG) 系统存在的过时信息、幻觉、有限可解释性和检索不准确等问题，提出了G-RAG框架，通过整合图数据库来提升知识扩展。G-RAG方法从文档中提取关键实体(MatIDs)，利用代理-based parsing技术查询外部Wikipedia知识库(KBs)，并捕获实体间关系以提高检索准确性和上下文理解。在材料科学等需要精确信息检索的领域，实验显示G-RAG显著提升了整体性能。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.14592v2",
      "published_date": "2024-11-21 21:22:58 UTC",
      "updated_date": "2024-12-01 01:21:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:45:18.588831"
    },
    {
      "arxiv_id": "2411.14574v1",
      "title": "SRSA: A Cost-Efficient Strategy-Router Search Agent for Real-world Human-Machine Interactions",
      "title_zh": "SRSA：一种成本高效的策略路由搜索代理，用于真实世界的人机交互",
      "authors": [
        "Yaqi Wang",
        "Haipei Xu"
      ],
      "abstract": "Recently, as Large Language Models (LLMs) have shown impressive emerging\ncapabilities and gained widespread popularity, research on LLM-based search\nagents has proliferated. In real-world situations, users often input contextual\nand highly personalized queries to chatbots, challenging LLMs to capture\ncontext and generate appropriate answers. However, much of the prior research\nhas not focused specifically on authentic human-machine dialogue scenarios. It\nalso ignores the important balance between response quality and computational\ncost by forcing all queries to follow the same agent process. To address these\ngaps, we propose a Strategy-Router Search Agent (SRSA), routing different\nqueries to appropriate search strategies and enabling fine-grained serial\nsearches to obtain high-quality results at a relatively low cost. To evaluate\nour work, we introduce a new dataset, Contextual Query Enhancement Dataset\n(CQED), comprising contextual queries to simulate authentic and daily\ninteractions between humans and chatbots. Using LLM-based automatic evaluation\nmetrics, we assessed SRSA's performance in terms of informativeness,\ncompleteness, novelty, and actionability. To conclude, SRSA provides an\napproach that resolves the issue of simple serial searches leading to\ndegenerate answers for lengthy and contextual queries, effectively and\nefficiently parses complex user queries, and generates more comprehensive and\ninformative responses without fine-tuning an LLM.",
      "tldr_zh": "本文提出SRSA（Strategy-Router Search Agent），一种成本高效的搜索代理，旨在解决大型语言模型(LLMs)在真实世界人机交互中处理上下文化查询时的响应质量和计算成本平衡问题。SRSA通过路由不同查询到合适的搜索策略并启用细粒度的串行搜索，实现高效生成高质量响应，而无需微调LLM。为此，研究引入了新数据集Contextual Query Enhancement Dataset (CQED) 进行评估，结果显示SRSA在信息性、完整性、新颖性和可操作性方面显著提升，解决了简单串行搜索导致的答案退化问题。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.14574v1",
      "published_date": "2024-11-21 20:41:55 UTC",
      "updated_date": "2024-11-21 20:41:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:45:32.182127"
    },
    {
      "arxiv_id": "2411.14571v1",
      "title": "Assessment of LLM Responses to End-user Security Questions",
      "title_zh": "LLM 对最终用户安全",
      "authors": [
        "Vijay Prakash",
        "Kevin Lee",
        "Arkaprabha Bhattacharya",
        "Danny Yuxing Huang",
        "Jessica Staddon"
      ],
      "abstract": "Answering end user security questions is challenging. While large language\nmodels (LLMs) like GPT, LLAMA, and Gemini are far from error-free, they have\nshown promise in answering a variety of questions outside of security. We\nstudied LLM performance in the area of end user security by qualitatively\nevaluating 3 popular LLMs on 900 systematically collected end user security\nquestions.\n  While LLMs demonstrate broad generalist ``knowledge'' of end user security\ninformation, there are patterns of errors and limitations across LLMs\nconsisting of stale and inaccurate answers, and indirect or unresponsive\ncommunication styles, all of which impacts the quality of information received.\nBased on these patterns, we suggest directions for model improvement and\nrecommend user strategies for interacting with LLMs when seeking assistance\nwith security.",
      "tldr_zh": "本研究评估了大型语言模型（LLMs）如 GPT、LLaMA 和 Gemini 在回答终端用户安全问题方面的表现，通过对 900 个系统收集的安全问题进行定性评估。结果显示，LLMs 虽具备广泛的通用安全知识，但存在错误模式，包括过时的答案、不准确的信息以及间接或不响应的沟通风格，这些问题降低了信息质量。基于这些发现，论文提出改进 LLMs 的方向，并推荐用户在寻求安全帮助时采用特定互动策略，以提升可靠性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL",
        "cs.HC"
      ],
      "primary_category": "cs.CR",
      "comment": "18 pages, 1 figure, 8 tables",
      "pdf_url": "http://arxiv.org/pdf/2411.14571v1",
      "published_date": "2024-11-21 20:36:36 UTC",
      "updated_date": "2024-11-21 20:36:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:46:59.329060"
    },
    {
      "arxiv_id": "2411.15234v3",
      "title": "Adaptive Intelligence: leveraging insights from adaptive behavior in animals to build flexible AI systems",
      "title_zh": "适应性智能：利用动物适应性行为的洞见来构建灵活的AI系统",
      "authors": [
        "Mackenzie Weygandt Mathis"
      ],
      "abstract": "Biological intelligence is inherently adaptive -- animals continually adjust\ntheir actions based on environmental feedback. However, creating adaptive\nartificial intelligence (AI) remains a major challenge. The next frontier is to\ngo beyond traditional AI to develop \"adaptive intelligence,\" defined here as\nharnessing insights from biological intelligence to build agents that can learn\nonline, generalize, and rapidly adapt to changes in their environment. Recent\nadvances in neuroscience offer inspiration through studies that increasingly\nfocus on how animals naturally learn and adapt their world models. In this\nPerspective, I will review the behavioral and neural foundations of adaptive\nbiological intelligence, the parallel progress in AI, and explore\nbrain-inspired approaches for building more adaptive algorithms.",
      "tldr_zh": "该论文提出“adaptive intelligence”概念，即通过借鉴动物适应性行为的洞见，构建能够在线学习、泛化和快速响应环境变化的灵活AI系统。作者回顾了生物智能的行为和神经基础，以及AI领域的并行进展，强调神经科学研究（如动物世界模型的适应机制）对AI的启发作用。作为一篇Perspective文章，它探讨了脑启发方法，以推动开发更具适应性的算法，为未来AI设计提供新方向。",
      "categories": [
        "q-bio.NC",
        "cs.AI"
      ],
      "primary_category": "q-bio.NC",
      "comment": "10 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.15234v3",
      "published_date": "2024-11-21 20:26:29 UTC",
      "updated_date": "2025-03-23 16:59:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:47:12.506258"
    },
    {
      "arxiv_id": "2411.14550v2",
      "title": "The importance of the clustering model to detect new types of intrusion in data traffic",
      "title_zh": "聚类模型在检测数据流量中新类型入侵的重要性",
      "authors": [
        "Noor Saud Abd",
        "Noor Walid Khalid",
        "Basim Hussein Ali"
      ],
      "abstract": "In the current digital age, the volume of data generated by various cyber\nactivities has become enormous and is constantly increasing. The data may\ncontain valuable insights that can be harnessed to improve cyber security\nmeasures. However, much of this data is unclassified and qualitative, which\nposes significant challenges to traditional analysis methods. Clustering\nfacilitates the identification of hidden patterns and structures in data\nthrough grouping similar data points, which makes it simpler to identify and\naddress threats. Clustering can be defined as a data mining (DM) approach,\nwhich uses similarity calculations for dividing a data set into several\ncategories. Hierarchical, density-based, along with partitioning clustering\nalgorithms are typical. The presented work use K-means algorithm, which is a\npopular clustering technique. Utilizing K-means algorithm, we worked with two\ndifferent types of data: first, we gathered data with the use of XG-boost\nalgorithm following completing the aggregation with K-means algorithm. Data was\ngathered utilizing Kali Linux environment, cicflowmeter traffic, and Putty\nSoftware tools with the use of diverse and simple attacks. The concept could\nassist in identifying new attack types, which are distinct from the known\nattacks, and labeling them based on the characteristics they will exhibit, as\nthe dynamic nature regarding cyber threats means that new attack types often\nemerge, for which labeled data might not yet exist. The model counted the\nattacks and assigned numbers to each one of them. Secondly, We tried the same\nwork on the ready data inside the Kaggle repository called (Intrusion Detection\nin Internet of Things Network), and the clustering model worked well and\ndetected the number of attacks correctly as shown in the results section.",
      "tldr_zh": "本文讨论了聚类（Clustering）模型在检测数据流量中新型入侵的重要性，通过识别隐藏模式来提升网络安全。研究采用 K-means 算法结合 XG-boost 进行数据收集和分析，实验使用 Kali Linux、cicflowmeter 和 Putty 工具生成攻击数据，并在 Kaggle 的“Intrusion Detection in Internet of Things Network”数据集上验证。结果表明，该模型能有效识别未知攻击类型、基于特征进行标记，并准确计数攻击，提升了对动态网络威胁的应对能力。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "18 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.14550v2",
      "published_date": "2024-11-21 19:40:31 UTC",
      "updated_date": "2025-03-26 14:42:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:47:24.077655"
    },
    {
      "arxiv_id": "2411.15231v2",
      "title": "IterIS: Iterative Inference-Solving Alignment for LoRA Merging",
      "title_zh": "IterIS：用于 Lo",
      "authors": [
        "Hongxu Chen",
        "Runshi Li",
        "Bowei Zhu",
        "Zhen Wang",
        "Long Chen"
      ],
      "abstract": "Low-rank adaptations (LoRA) are widely used to fine-tune large models across\nvarious domains for specific downstream tasks. While task-specific LoRAs are\noften available, concerns about data privacy and intellectual property can\nrestrict access to training data, limiting the acquisition of a multi-task\nmodel through gradient-based training. In response, LoRA merging presents an\neffective solution by combining multiple LoRAs into a unified adapter while\nmaintaining data privacy. Prior works on LoRA merging primarily frame it as an\noptimization problem, yet these approaches face several limitations, including\nthe rough assumption about input features utilized in optimization, massive\nsample requirements, and the unbalanced optimization objective. These\nlimitations can significantly degrade performance. To address these, we propose\na novel optimization-based method, named IterIS: 1) We formulate LoRA merging\nas an advanced optimization problem to mitigate the rough assumption.\nAdditionally, we employ an iterative inference-solving framework in our\nalgorithm. It can progressively refine the optimization objective for improved\nperformance. 2) We introduce an efficient regularization term to reduce the\nneed for massive sample requirements (requiring only 1-5% of the unlabeled\nsamples compared to prior methods). 3) We utilize adaptive weights in the\noptimization objective to mitigate potential unbalances in LoRA merging\nprocess. Our method demonstrates significant improvements over multiple\nbaselines and state-of-the-art methods in composing tasks for text-to-image\ndiffusion, vision-language models, and large language models. Furthermore, our\nlayer-wise algorithm can achieve convergence with minimal steps, ensuring\nefficiency in both memory and computation.",
      "tldr_zh": "本论文针对 Low-rank adaptations (LoRA) 合并中的问题，如粗糙假设、大量样本需求和优化不平衡，提出了一种新型优化方法 IterIS。IterIS 通过将 LoRA 合并制定为高级优化问题，并采用迭代推理求解框架、效率正则化项（只需1-5%的无标签样本）和自适应权重，来逐步改进优化目标并提升性能。实验结果显示，该方法在文本到图像扩散、视觉语言模型和大型语言模型的任务组合上，比基线和最先进方法有显著改进，并实现了高效的层级收敛，减少了内存和计算开销。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.15231v2",
      "published_date": "2024-11-21 19:04:02 UTC",
      "updated_date": "2025-04-15 01:42:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:47:36.913858"
    },
    {
      "arxiv_id": "2411.16707v3",
      "title": "Enhancing LLMs for Power System Simulations: A Feedback-driven Multi-agent Framework",
      "title_zh": "增强大语言模型用于电力系统模拟：一个反馈驱动的多智能体框架",
      "authors": [
        "Mengshuo Jia",
        "Zeyu Cui",
        "Gabriela Hug"
      ],
      "abstract": "The integration of experimental technologies with large language models\n(LLMs) is transforming scientific research. It positions AI as a versatile\nresearch assistant rather than a mere problem-solving tool. In the field of\npower systems, however, managing simulations -- one of the essential\nexperimental technologies -- remains a challenge for LLMs due to their limited\ndomain-specific knowledge, restricted reasoning capabilities, and imprecise\nhandling of simulation parameters. To address these limitations, this paper\nproposes a feedback-driven, multi-agent framework. It incorporates three\nproposed modules: an enhanced retrieval-augmented generation (RAG) module, an\nimproved reasoning module, and a dynamic environmental acting module with an\nerror-feedback mechanism. Validated on 69 diverse tasks from Daline and\nMATPOWER, this framework achieves success rates of 93.13% and 96.85%,\nrespectively. It significantly outperforms ChatGPT 4o, o1-preview, and the\nfine-tuned GPT-4o, which all achieved a success rate lower than 30% on complex\ntasks. Additionally, the proposed framework also supports rapid, cost-effective\ntask execution, completing each simulation in approximately 30 seconds at an\naverage cost of 0.014 USD for tokens. Overall, this adaptable framework lays a\nfoundation for developing intelligent LLM-based assistants for human\nresearchers, facilitating power system research and beyond.",
      "tldr_zh": "这篇论文针对大型语言模型(LLMs)在电力系统模拟中的局限性（如领域知识不足、推理能力受限和参数处理不精确），提出了一种反馈驱动的多智能体框架。该框架整合了增强的检索增强生成(RAG)模块、改进的推理模块以及带有错误反馈机制的动态环境行动模块，以提升模拟任务的准确性和效率。在Daline和MATPOWER的69个任务上验证，该框架分别实现了93.13%和96.85%的成功率，大幅超越ChatGPT 4o、o1-preview和微调的GPT-4o（后者在复杂任务上成功率低于30%），并以约30秒和0.014 USD的成本完成每次模拟。该框架为开发智能LLM-based研究助手奠定了基础，促进电力系统及其他领域的科研进展。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.MA",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.CL",
      "comment": "16 pages",
      "pdf_url": "http://arxiv.org/pdf/2411.16707v3",
      "published_date": "2024-11-21 19:01:07 UTC",
      "updated_date": "2025-05-19 15:51:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:47:49.049511"
    },
    {
      "arxiv_id": "2411.14429v1",
      "title": "Revisiting the Integration of Convolution and Attention for Vision Backbone",
      "title_zh": "翻译失败",
      "authors": [
        "Lei Zhu",
        "Xinjiang Wang",
        "Wayne Zhang",
        "Rynson W. H. Lau"
      ],
      "abstract": "Convolutions (Convs) and multi-head self-attentions (MHSAs) are typically\nconsidered alternatives to each other for building vision backbones. Although\nsome works try to integrate both, they apply the two operators simultaneously\nat the finest pixel granularity. With Convs responsible for per-pixel feature\nextraction already, the question is whether we still need to include the heavy\nMHSAs at such a fine-grained level. In fact, this is the root cause of the\nscalability issue w.r.t. the input resolution for vision transformers. To\naddress this important problem, we propose in this work to use MSHAs and Convs\nin parallel \\textbf{at different granularity levels} instead. Specifically, in\neach layer, we use two different ways to represent an image: a fine-grained\nregular grid and a coarse-grained set of semantic slots. We apply different\noperations to these two representations: Convs to the grid for local features,\nand MHSAs to the slots for global features. A pair of fully differentiable soft\nclustering and dispatching modules is introduced to bridge the grid and set\nrepresentations, thus enabling local-global fusion. Through extensive\nexperiments on various vision tasks, we empirically verify the potential of the\nproposed integration scheme, named \\textit{GLMix}: by offloading the burden of\nfine-grained features to light-weight Convs, it is sufficient to use MHSAs in a\nfew (e.g., 64) semantic slots to match the performance of recent\nstate-of-the-art backbones, while being more efficient. Our visualization\nresults also demonstrate that the soft clustering module produces a meaningful\nsemantic grouping effect with only IN1k classification supervision, which may\ninduce better interpretability and inspire new weakly-supervised semantic\nsegmentation approaches. Code will be available at\n\\url{https://github.com/rayleizhu/GLMix}.",
      "tldr_zh": "本研究重新审视了卷积（Convs）和多头自注意力（MHSAs）在视觉骨干网络中的整合问题，指出现有方法在像素级别同时应用两者会导致可扩展性挑战。论文提出GLMix框架，在不同粒度级别并行使用Convs和MHSAs：将Convs应用于细粒度网格提取局部特征，将MHSAs应用于粗粒度语义槽提取全局特征，并通过完全可微的软聚类和分发模块桥接局部-全局融合。实验结果显示，GLMix在各种视觉任务上匹配了最先进骨干网络的性能，同时更高效，且软聚类模块在仅使用ImageNet-1k分类监督下实现了有意义的语义分组，可能启发新的弱监督语义分割方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.14429v1",
      "published_date": "2024-11-21 18:59:08 UTC",
      "updated_date": "2024-11-21 18:59:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:48:00.892877"
    },
    {
      "arxiv_id": "2411.14425v1",
      "title": "Whack-a-Chip: The Futility of Hardware-Centric Export Controls",
      "title_zh": "翻译失败",
      "authors": [
        "Ritwik Gupta",
        "Leah Walker",
        "Andrew W. Reddie"
      ],
      "abstract": "U.S. export controls on semiconductors are widely known to be permeable, with\nthe People's Republic of China (PRC) steadily creating state-of-the-art\nartificial intelligence (AI) models with exfiltrated chips. This paper presents\nthe first concrete, public evidence of how leading PRC AI labs evade and\ncircumvent U.S. export controls. We examine how Chinese companies, notably\nTencent, are not only using chips that are restricted under U.S. export\ncontrols but are also finding ways to circumvent these regulations by using\nsoftware and modeling techniques that maximize less capable hardware.\nSpecifically, we argue that Tencent's ability to power its Hunyuan-Large model\nwith non-export controlled NVIDIA H20s exemplifies broader gains in efficiency\nin machine learning that have eroded the moat that the United States initially\nbuilt via its existing export controls. Finally, we examine the implications of\nthis finding for the future of the United States' export control strategy.",
      "tldr_zh": "本文研究了美国对半导体硬件的出口管制无效性，提供了首个公开证据，展示中国领先AI实验室（如Tencent）如何规避这些管制。论文分析了这些公司不仅使用受限芯片，还通过软件和建模技巧最大化较弱硬件（如NVIDIA H20s）的效能，以驱动先进AI模型如Hunyuan-Large。研究发现，这种机器学习效率的提升已侵蚀了美国的出口控制优势，并讨论了其对未来美国策略的潜在启示。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.14425v1",
      "published_date": "2024-11-21 18:57:17 UTC",
      "updated_date": "2024-11-21 18:57:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:50:12.189993"
    },
    {
      "arxiv_id": "2411.15230v1",
      "title": "A No Free Lunch Theorem for Human-AI Collaboration",
      "title_zh": "人类-AI 协作的无免费午餐定理",
      "authors": [
        "Kenny Peng",
        "Nikhil Garg",
        "Jon Kleinberg"
      ],
      "abstract": "The gold standard in human-AI collaboration is complementarity -- when\ncombined performance exceeds both the human and algorithm alone. We investigate\nthis challenge in binary classification settings where the goal is to maximize\n0-1 accuracy. Given two or more agents who can make calibrated probabilistic\npredictions, we show a \"No Free Lunch\"-style result. Any deterministic\ncollaboration strategy (a function mapping calibrated probabilities into binary\nclassifications) that does not essentially always defer to the same agent will\nsometimes perform worse than the least accurate agent. In other words,\ncomplementarity cannot be achieved \"for free.\" The result does suggest one\nmodel of collaboration with guarantees, where one agent identifies \"obvious\"\nerrors of the other agent. We also use the result to understand the necessary\nconditions enabling the success of other collaboration techniques, providing\nguidance to human-AI collaboration.",
      "tldr_zh": "这篇论文证明了一个\"No Free Lunch\"定理：在人类-AI协作的二元分类任务中，任何不总是依赖同一代理的deterministic collaboration strategy（确定性协作策略），基于calibrated probabilistic predictions（校准概率预测），有时会比最不准确的代理表现更差，从而表明complementarity（互补性）无法“免费”实现。研究通过分析多个代理的协作，揭示了实现组合性能优于单独代理的挑战。论文建议了一种协作模型，其中一个代理识别另一个代理的“obvious”错误，并为其他协作技术提供了必要条件和指导，以提升人类-AI协作的可靠性。",
      "categories": [
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.15230v1",
      "published_date": "2024-11-21 18:46:03 UTC",
      "updated_date": "2024-11-21 18:46:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:48:24.459903"
    },
    {
      "arxiv_id": "2411.14404v1",
      "title": "Resolving Multiple-Dynamic Model Uncertainty in Hypothesis-Driven Belief-MDPs",
      "title_zh": "翻译失败",
      "authors": [
        "Ofer Dagan",
        "Tyler Becker",
        "Zachary N. Sunberg"
      ],
      "abstract": "When human operators of cyber-physical systems encounter surprising behavior,\nthey often consider multiple hypotheses that might explain it. In some cases,\ntaking information-gathering actions such as additional measurements or control\ninputs given to the system can help resolve uncertainty and determine the most\naccurate hypothesis. The task of optimizing these actions can be formulated as\na belief-space Markov decision process that we call a hypothesis-driven belief\nMDP. Unfortunately, this problem suffers from the curse of history similar to a\npartially observable Markov decision process (POMDP). To plan in continuous\ndomains, an agent needs to reason over countlessly many possible\naction-observation histories, each resulting in a different belief over the\nunknown state. The problem is exacerbated in the hypothesis-driven context\nbecause each action-observation pair spawns a different belief for each\nhypothesis, leading to additional branching. This paper considers the case in\nwhich each hypothesis corresponds to a different dynamic model in an underlying\nPOMDP. We present a new belief MDP formulation that: (i) enables reasoning over\nmultiple hypotheses, (ii) balances the goals of determining the (most likely)\ncorrect hypothesis and performing well in the underlying POMDP, and (iii) can\nbe solved with sparse tree search.",
      "tldr_zh": "这篇论文解决了在假设驱动的 Belief-MDPs 中处理多个动态模型不确定性的问题，特别是在面对类似 POMDP 的 curse of history 时，需要应对无数可能的行动-观察历史。作者提出了一种新的 Belief-MDP 表述，能够同时（i）推理多个假设、（ii）平衡确定最可能正确假设的目标与在底层 POMDP 中优化表现，以及（iii）通过稀疏树搜索进行高效求解。该方法有助于人类操作员在cyber-physical系统中通过信息收集行动（如额外测量）来化解不确定性，并提升决策的准确性。",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages, 4 figures, submitted to AAMAS 2025",
      "pdf_url": "http://arxiv.org/pdf/2411.14404v1",
      "published_date": "2024-11-21 18:36:19 UTC",
      "updated_date": "2024-11-21 18:36:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:48:36.063473"
    },
    {
      "arxiv_id": "2411.14403v1",
      "title": "Landing Trajectory Prediction for UAS Based on Generative Adversarial Network",
      "title_zh": "翻译失败",
      "authors": [
        "Jun Xiang",
        "Drake Essick",
        "Luiz Gonzalez Bautista",
        "Junfei Xie",
        "Jun Chen"
      ],
      "abstract": "Models for trajectory prediction are an essential component of many advanced\nair mobility studies. These models help aircraft detect conflict and plan\navoidance maneuvers, which is especially important in Unmanned Aircraft systems\n(UAS) landing management due to the congested airspace near vertiports. In this\npaper, we propose a landing trajectory prediction model for UAS based on\nGenerative Adversarial Network (GAN). The GAN is a prestigious neural network\nthat has been developed for many years. In previous research, GAN has achieved\nmany state-of-the-art results in many generation tasks. The GAN consists of one\nneural network generator and a neural network discriminator. Because of the\nlearning capacity of the neural networks, the generator is capable to\nunderstand the features of the sample trajectory. The generator takes the\nprevious trajectory as input and outputs some random status of a flight.\nAccording to the results of the experiences, the proposed model can output more\naccurate predictions than the baseline method(GMR) in various datasets. To\nevaluate the proposed model, we also create a real UAV landing dataset that\nincludes more than 2600 trajectories of drone control manually by real pilots.",
      "tldr_zh": "本文提出了一种基于 Generative Adversarial Network (GAN) 的无人驾驶航空系统 (UAS) 着陆轨迹预测模型，用于检测冲突并规划避让 maneuvers，尤其适用于 vertiports 附近拥挤空域的着陆管理。GAN 由生成器和判别器组成，生成器通过学习样本轨迹特征，从输入的先前轨迹生成预测的飞行状态，从而提升预测准确性。实验结果显示，该模型在各种数据集上比基线方法 GMR 更准确，并基于一个新创建的真实 UAV 着陆数据集（包含超过2600个由飞行员手动控制的轨迹）进行了评估。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "9 pages, AIAA SCITECH 2023",
      "pdf_url": "http://arxiv.org/pdf/2411.14403v1",
      "published_date": "2024-11-21 18:34:33 UTC",
      "updated_date": "2024-11-21 18:34:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:48:48.431301"
    },
    {
      "arxiv_id": "2411.14520v1",
      "title": "Open Challenges in the Formal Verification of Autonomous Driving",
      "title_zh": "自动驾驶形式验证的开放挑战",
      "authors": [
        "Paolo Burgio",
        "Angelo Ferrando",
        "Marco Villani"
      ],
      "abstract": "In the realm of autonomous driving, the development and integration of highly\ncomplex and heterogeneous systems are standard practice. Modern vehicles are\nnot monolithic systems; instead, they are composed of diverse hardware\ncomponents, each running its own software systems. An autonomous vehicle\ncomprises numerous independent components, often developed by different and\npotentially competing companies. This diversity poses significant challenges\nfor the certification process, as it necessitates certifying components that\nmay not disclose their internal behaviour (black-boxes). In this paper, we\npresent a real-world case study of an autonomous driving system, identify key\nopen challenges associated with its development and integration, and explore\nhow formal verification techniques can address these challenges to ensure\nsystem reliability and safety.",
      "tldr_zh": "该论文探讨了自动驾驶系统在形式验证（formal verification）方面的开放挑战，强调了系统的高度复杂性和异构性，例如由不同公司开发的独立硬件和软件组件，这些组件往往是黑盒（不公开内部行为），导致认证过程困难重重。通过一个真实案例研究，作者识别了关键开发和集成挑战，并探讨了如何应用形式验证技术来解决这些问题，以提升系统的可靠性和安全性。该研究为未来自动驾驶系统的安全验证提供了重要见解。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.DC",
        "cs.RO"
      ],
      "primary_category": "cs.SE",
      "comment": "In Proceedings FMAS2024, arXiv:2411.13215",
      "pdf_url": "http://arxiv.org/pdf/2411.14520v1",
      "published_date": "2024-11-21 18:09:35 UTC",
      "updated_date": "2024-11-21 18:09:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:50:23.002995"
    },
    {
      "arxiv_id": "2411.14374v1",
      "title": "Using Formal Models, Safety Shields and Certified Control to Validate AI-Based Train Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Jan Gruteser",
        "Jan Roßbach",
        "Fabian Vu",
        "Michael Leuschel"
      ],
      "abstract": "The certification of autonomous systems is an important concern in science\nand industry. The KI-LOK project explores new methods for certifying and safely\nintegrating AI components into autonomous trains. We pursued a two-layered\napproach: (1) ensuring the safety of the steering system by formal analysis\nusing the B method, and (2) improving the reliability of the perception system\nwith a runtime certificate checker. This work links both strategies within a\ndemonstrator that runs simulations on the formal model, controlled by the real\nAI output and the real certificate checker. The demonstrator is integrated into\nthe validation tool ProB. This enables runtime monitoring, runtime\nverification, and statistical validation of formal safety properties using a\nformal B model. Consequently, one can detect and analyse potential\nvulnerabilities and weaknesses of the AI and the certificate checker. We apply\nthese techniques to a signal detection case study and present our findings.",
      "tldr_zh": "该研究探讨了使用正式模型、安全屏蔽和认证控制来验证基于 AI 的火车系统的认证方法，旨在安全集成 AI 组件到自治火车中。研究采用两层方法：（1）利用 B method 进行正式分析，确保转向系统的安全；（2）通过运行时证书检查器提升感知系统的可靠性。作者构建了一个演示器，将这些策略集成到 ProB 验证工具中，进行模拟、运行时监控和统计验证，以检测 AI 和证书检查器的潜在漏洞。在信号检测案例研究中，该方法成功识别了系统弱点，为 AI 组件的可靠认证提供了新途径。",
      "categories": [
        "cs.LO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LO",
      "comment": "In Proceedings FMAS2024, arXiv:2411.13215",
      "pdf_url": "http://arxiv.org/pdf/2411.14374v1",
      "published_date": "2024-11-21 18:09:04 UTC",
      "updated_date": "2024-11-21 18:09:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:50:35.787673"
    },
    {
      "arxiv_id": "2411.14371v1",
      "title": "Synthesising Robust Controllers for Robot Collectives with Recurrent Tasks: A Case Study",
      "title_zh": "针对具有循环任务的机器人集体的鲁棒控制器合成：一个案例研究",
      "authors": [
        "Till Schnittka",
        "Mario Gleirscher"
      ],
      "abstract": "When designing correct-by-construction controllers for autonomous\ncollectives, three key challenges are the task specification, the modelling,\nand its use at practical scale. In this paper, we focus on a simple yet useful\nabstraction for high-level controller synthesis for robot collectives with\noptimisation goals (e.g., maximum cleanliness, minimum energy consumption) and\nrecurrence (e.g., re-establish contamination and charge thresholds) and safety\n(e.g., avoid full discharge, mutually exclusive room occupation) constraints.\nDue to technical limitations (related to scalability and using constraints in\nthe synthesis), we simplify our graph-based setting from a stochastic\ntwo-player game into a single-player game on a partially observable Markov\ndecision process (POMDP). Robustness against environmental uncertainty is\nencoded via partial observability. Linear-time correctness properties are\nverified separately after synthesising the POMDP strategy. We contribute\nat-scale guidance on POMDP modelling and controller synthesis for tasked robot\ncollectives exemplified by the scenario of battery-driven robots responsible\nfor cleaning public buildings with utilisation constraints.",
      "tldr_zh": "这篇论文探讨了为具有循环任务的机器人集体设计鲁棒控制器的挑战，包括任务规范、建模和实际规模应用。研究团队通过将随机双人游戏简化成部分可观测Markov决策过程（POMDP）的单人游戏模型，编码环境不确定性并在合成策略后单独验证线性时间正确性属性，从而提升了控制器的可扩展性和鲁棒性。论文以电池驱动机器人清洁公共建筑的案例研究为例，提供针对优化目标（如最小能源消耗）和安全约束（如避免完全放电）的POMDP建模和控制器合成指导。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.MA",
      "comment": "In Proceedings FMAS2024, arXiv:2411.13215",
      "pdf_url": "http://arxiv.org/pdf/2411.14371v1",
      "published_date": "2024-11-21 18:08:18 UTC",
      "updated_date": "2024-11-21 18:08:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:50:47.823784"
    },
    {
      "arxiv_id": "2411.14368v1",
      "title": "RV4Chatbot: Are Chatbots Allowed to Dream of Electric Sheep?",
      "title_zh": "翻译失败",
      "authors": [
        "Andrea Gatti",
        "Viviana Mascardi",
        "Angelo Ferrando"
      ],
      "abstract": "Chatbots have become integral to various application domains, including those\nwith safety-critical considerations. As a result, there is a pressing need for\nmethods that ensure chatbots consistently adhere to expected, safe behaviours.\nIn this paper, we introduce RV4Chatbot, a Runtime Verification framework\ndesigned to monitor deviations in chatbot behaviour. We formalise expected\nbehaviours as interaction protocols between the user and the chatbot. We\npresent the RV4Chatbot design and describe two implementations that instantiate\nit: RV4Rasa, for monitoring chatbots created with the Rasa framework, and\nRV4Dialogflow, for monitoring Dialogflow chatbots. Additionally, we detail\nexperiments conducted in a factory automation scenario using both RV4Rasa and\nRV4Dialogflow.",
      "tldr_zh": "本论文探讨了聊天机器人（chatbots）在安全关键领域的行为一致性问题，引入了 RV4Chatbot 框架，这是一种 Runtime Verification 方法，用于实时监控聊天机器人的行为偏差，并将预期行为形式化为用户与聊天机器人之间的交互协议。RV4Chatbot 的设计包括两个具体实现：RV4Rasa（针对 Rasa 框架）和 RV4Dialogflow（针对 Dialogflow 框架）。实验在工厂自动化场景中进行，证明了该框架的有效性。",
      "categories": [
        "cs.AI",
        "cs.HC",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "In Proceedings FMAS2024, arXiv:2411.13215",
      "pdf_url": "http://arxiv.org/pdf/2411.14368v1",
      "published_date": "2024-11-21 18:07:46 UTC",
      "updated_date": "2024-11-21 18:07:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:50:59.074896"
    },
    {
      "arxiv_id": "2411.14367v1",
      "title": "ROSMonitoring 2.0: Extending ROS Runtime Verification to Services and Ordered Topics",
      "title_zh": "翻译失败",
      "authors": [
        "Maryam Ghaffari Saadat",
        "Angelo Ferrando",
        "Louise A. Dennis",
        "Michael Fisher"
      ],
      "abstract": "Formal verification of robotic applications presents challenges due to their\nhybrid nature and distributed architecture. This paper introduces ROSMonitoring\n2.0, an extension of ROSMonitoring designed to facilitate the monitoring of\nboth topics and services while considering the order in which messages are\npublished and received. The framework has been enhanced to support these novel\nfeatures for ROS1 -- and partially ROS2 environments -- offering improved\nreal-time support, security, scalability, and interoperability. We discuss the\nmodifications made to accommodate these advancements and present results\nobtained from a case study involving the runtime monitoring of specific\ncomponents of a fire-fighting Uncrewed Aerial Vehicle (UAV).",
      "tldr_zh": "该论文介绍了 ROSMonitoring 2.0，这是一种扩展框架，用于增强 ROS 运行时验证功能，支持监控 topics 和 services，同时考虑消息的发布和接收顺序。针对 ROS1 和部分 ROS2 环境，该框架通过修改实现了更好的实时支持、安全性、可扩展性和互操作性。研究团队通过一个灭火 Uncrewed Aerial Vehicle (UAV) 组件的案例研究，验证了这些改进的效果。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.SE",
      "comment": "In Proceedings FMAS2024, arXiv:2411.13215",
      "pdf_url": "http://arxiv.org/pdf/2411.14367v1",
      "published_date": "2024-11-21 18:07:31 UTC",
      "updated_date": "2024-11-21 18:07:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:51:10.947821"
    },
    {
      "arxiv_id": "2411.14354v1",
      "title": "Contrasting local and global modeling with machine learning and satellite data: A case study estimating tree canopy height in African savannas",
      "title_zh": "翻译失败",
      "authors": [
        "Esther Rolf",
        "Lucia Gordon",
        "Milind Tambe",
        "Andrew Davies"
      ],
      "abstract": "While advances in machine learning with satellite imagery (SatML) are\nfacilitating environmental monitoring at a global scale, developing SatML\nmodels that are accurate and useful for local regions remains critical to\nunderstanding and acting on an ever-changing planet. As increasing attention\nand resources are being devoted to training SatML models with global data, it\nis important to understand when improvements in global models will make it\neasier to train or fine-tune models that are accurate in specific regions. To\nexplore this question, we contrast local and global training paradigms for\nSatML through a case study of tree canopy height (TCH) mapping in the Karingani\nGame Reserve, Mozambique. We find that recent advances in global TCH mapping do\nnot necessarily translate to better local modeling abilities in our study\nregion. Specifically, small models trained only with locally-collected data\noutperform published global TCH maps, and even outperform globally pretrained\nmodels that we fine-tune using local data. Analyzing these results further, we\nidentify specific points of conflict and synergy between local and global\nmodeling paradigms that can inform future research toward aligning local and\nglobal performance objectives in geospatial machine learning.",
      "tldr_zh": "该研究对比了本地和全球机器学习与卫星图像（SatML）建模方法，通过在莫桑比克Karingani Game Reserve的树冠高度（TCH）映射案例，探讨全球模型改进是否能提升本地建模准确性。结果显示，使用本地数据的中小模型在TCH估计上优于已发布的全球地图，甚至优于使用本地数据微调的全局预训练模型。作者进一步分析了本地和全球范式之间的冲突与协同点，为未来地理空间机器学习研究提供指导，以更好地平衡局部和全局性能目标。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "31 pages; 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.14354v1",
      "published_date": "2024-11-21 17:53:27 UTC",
      "updated_date": "2024-11-21 17:53:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:51:23.447980"
    },
    {
      "arxiv_id": "2411.14343v1",
      "title": "UnifiedCrawl: Aggregated Common Crawl for Affordable Adaptation of LLMs on Low-Resource Languages",
      "title_zh": "翻译失败",
      "authors": [
        "Bethel Melesse Tessema",
        "Akhil Kedia",
        "Tae-Sun Chung"
      ],
      "abstract": "Large language models (LLMs) under-perform on low-resource languages due to\nlimited training data. We present a method to efficiently collect text data for\nlow-resource languages from the entire Common Crawl corpus. Our approach,\nUnifiedCrawl, filters and extracts common crawl using minimal compute\nresources, yielding mono-lingual datasets much larger than previously available\nsources. We demonstrate that leveraging this data to fine-tuning multilingual\nLLMs via efficient adapter methods (QLoRA) significantly boosts performance on\nthe low-resource language, while minimizing VRAM usage. Our experiments show\nlarge improvements in language modeling perplexity and an increase in few-shot\nprompting scores. Our work and released source code provide an affordable\napproach to improve LLMs for low-resource languages using consumer hardware.\nOur source code is available here at\nhttps://github.com/bethelmelesse/unifiedcrawl.",
      "tldr_zh": "该研究提出UnifiedCrawl方法，通过从Common Crawl语料库中高效过滤和提取数据，创建更大规模的单语数据集，以解决LLMs在低资源语言上的性能不足问题。该方法使用最小计算资源生成这些数据集，并通过QLoRA高效适配器微调多语言LLMs，显著提升了低资源语言的语言建模困惑度和少样本提示分数，同时减少VRAM使用。实验结果显示性能改善明显，为在消费级硬件上经济地适应LLMs提供了可行途径。源代码已开源，可从指定仓库获取。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "68T50",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.14343v1",
      "published_date": "2024-11-21 17:41:08 UTC",
      "updated_date": "2024-11-21 17:41:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:51:36.323672"
    },
    {
      "arxiv_id": "2412.00036v3",
      "title": "Beyond Monte Carlo: Harnessing Diffusion Models to Simulate Financial Market Dynamics",
      "title_zh": "超越 Monte Carlo：利用扩散模型模拟金融市场动态",
      "authors": [
        "Andrew Lesniewski",
        "Giulio Trigila"
      ],
      "abstract": "We propose a highly efficient and accurate methodology for generating\nsynthetic financial market data using a diffusion model approach. The synthetic\ndata produced by our methodology align closely with observed market data in\nseveral key aspects: (i) they pass the two-sample Cramer - von Mises test for\nportfolios of assets, and (ii) Q - Q plots demonstrate consistency across\nquantiles, including in the tails, between observed and generated market data.\nMoreover, the covariance matrices derived from a large set of synthetic market\ndata exhibit significantly lower condition numbers compared to the estimated\ncovariance matrices of the observed data. This property makes them suitable for\nuse as regularized versions of the latter. For model training, we develop an\nefficient and fast algorithm based on numerical integration rather than Monte\nCarlo simulations. The methodology is tested on a large set of equity data.",
      "tldr_zh": "本研究提出了一种高效准确的方法，使用 diffusion models 生成合成金融市场数据，以替代传统的 Monte Carlo 模拟。生成的合成数据在关键方面与实际数据高度一致，通过 two-sample Cramer-von Mises test 和 Q-Q plots 验证了其在分位数（包括尾部）上的可靠性；此外，合成数据的 covariance matrices 具有显著较低的 condition numbers，使其适合作为实际数据的正则化版本。该方法采用基于 numerical integration 的快速训练算法，并在大量股票数据上进行了测试，展示了其实际应用潜力。",
      "categories": [
        "q-fin.CP",
        "cs.AI",
        "cs.CE",
        "q-fin.PM"
      ],
      "primary_category": "q-fin.CP",
      "comment": "27 pages",
      "pdf_url": "http://arxiv.org/pdf/2412.00036v3",
      "published_date": "2024-11-21 17:39:23 UTC",
      "updated_date": "2025-02-02 20:31:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:51:48.530876"
    },
    {
      "arxiv_id": "2411.14303v2",
      "title": "BugSpotter: Automated Generation of Code Debugging Exercises",
      "title_zh": "BugSpotter: 代码调试练习的自动化生成",
      "authors": [
        "Victor-Alexandru Pădurean",
        "Paul Denny",
        "Adish Singla"
      ],
      "abstract": "Debugging is an essential skill when learning to program, yet its instruction\nand emphasis often vary widely across introductory courses. In the era of\ncode-generating large language models (LLMs), the ability for students to\nreason about code and identify errors is increasingly important. However,\nstudents frequently resort to trial-and-error methods to resolve bugs without\nfully understanding the underlying issues. Developing the ability to identify\nand hypothesize the cause of bugs is crucial but can be time-consuming to teach\neffectively through traditional means. This paper introduces BugSpotter, an\ninnovative tool that leverages an LLM to generate buggy code from a problem\ndescription and verify the synthesized bugs via a test suite. Students interact\nwith BugSpotter by designing failing test cases, where the buggy code's output\ndiffers from the expected result as defined by the problem specification. This\nnot only provides opportunities for students to enhance their debugging skills,\nbut also to practice reading and understanding problem specifications. We\ndeployed BugSpotter in a large classroom setting and compared the debugging\nexercises it generated to exercises hand-crafted by an instructor for the same\nproblems. We found that the LLM-generated exercises produced by BugSpotter\nvaried in difficulty and were well-matched to the problem specifications.\nImportantly, the LLM-generated exercises were comparable to those manually\ncreated by instructors with respect to student performance, suggesting that\nBugSpotter could be an effective and efficient aid for learning debugging.",
      "tldr_zh": "这篇论文介绍了 BugSpotter，一种利用 LLM (Large Language Models) 自动生成代码调试练习的创新工具，旨在帮助学生提升调试技能并更好地理解代码错误。BugSpotter 通过从问题描述生成带 bug 的代码，并使用测试套件验证，然后让学生设计失败测试用例来互动，从而强化学生的代码阅读和问题分析能力。在实际课堂部署中，LLM 生成的练习与教师手工创建的练习在难度和学生表现上相当，证明了 BugSpotter 作为高效学习辅助工具的有效性。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "Preprint of the SIGCSE'25 paper",
      "pdf_url": "http://arxiv.org/pdf/2411.14303v2",
      "published_date": "2024-11-21 16:56:33 UTC",
      "updated_date": "2024-11-25 08:31:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:51:59.083997"
    },
    {
      "arxiv_id": "2411.14277v1",
      "title": "Neuro-Symbolic Query Optimization in Knowledge Graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Maribel Acosta",
        "Chang Qin",
        "Tim Schwabe"
      ],
      "abstract": "This chapter delves into the emerging field of neuro-symbolic query\noptimization for knowledge graphs (KGs), presenting a comprehensive exploration\nof how neural and symbolic techniques can be integrated to enhance query\nprocessing. Traditional query optimizers in knowledge graphs rely heavily on\nsymbolic methods, utilizing dataset summaries, statistics, and cost models to\nselect efficient execution plans. However, these approaches often suffer from\nmisestimations and inaccuracies, particularly when dealing with complex queries\nor large-scale datasets. Recent advancements have introduced neural models,\nwhich capture non-linear aspects of query optimization, offering promising\nalternatives to purely symbolic methods. In this chapter, we introduce\nneuro-symbolic query optimizers, a novel approach that combines the strengths\nof symbolic reasoning with the adaptability of neural computation. We discuss\nthe architecture of these hybrid systems, highlighting the interplay between\nneural and symbolic components to improve the optimizer's ability to navigate\nthe search space and produce efficient execution plans. Additionally, the\nchapter reviews existing neural components tailored for optimizing queries over\nknowledge graphs and examines the limitations and challenges in deploying\nneuro-symbolic query optimizers in real-world environments.",
      "tldr_zh": "本章探讨了神经符号查询优化（Neuro-Symbolic Query Optimization）在知识图谱（Knowledge Graphs）中的应用，通过整合神经和符号技术来提升查询处理效率。传统符号方法依赖数据集总结、统计和成本模型，但常因处理复杂查询或大规模数据集而出现误估和不准确问题。论文引入神经符号查询优化器，这种混合系统结合符号推理的精确性和神经计算的适应性，优化执行计划并改善搜索空间导航。最终，该方法回顾了现有的神经组件，并分析了在实际环境中部署的挑战，为知识图谱查询优化提供了更高效的框架。",
      "categories": [
        "cs.DB",
        "cs.AI",
        "H.2; I.2"
      ],
      "primary_category": "cs.DB",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.14277v1",
      "published_date": "2024-11-21 16:31:27 UTC",
      "updated_date": "2024-11-21 16:31:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:52:11.203123"
    },
    {
      "arxiv_id": "2411.14263v1",
      "title": "Generating Realistic Adversarial Examples for Business Processes using Variational Autoencoders",
      "title_zh": "使用变分自编码器生成商业流程的真实对抗示例",
      "authors": [
        "Alexander Stevens",
        "Jari Peeperkorn",
        "Johannes De Smedt",
        "Jochen De Weerdt"
      ],
      "abstract": "In predictive process monitoring, predictive models are vulnerable to\nadversarial attacks, where input perturbations can lead to incorrect\npredictions. Unlike in computer vision, where these perturbations are designed\nto be imperceptible to the human eye, the generation of adversarial examples in\npredictive process monitoring poses unique challenges. Minor changes to the\nactivity sequences can create improbable or even impossible scenarios to occur\ndue to underlying constraints such as regulatory rules or process constraints.\nTo address this, we focus on generating realistic adversarial examples tailored\nto the business process context, in contrast to the imperceptible, pixel-level\nchanges commonly seen in computer vision adversarial attacks. This paper\nintroduces two novel latent space attacks, which generate adversaries by adding\nnoise to the latent space representation of the input data, rather than\ndirectly modifying the input attributes. These latent space methods are\ndomain-agnostic and do not rely on process-specific knowledge, as we restrict\nthe generation of adversarial examples to the learned class-specific data\ndistributions by directly perturbing the latent space representation of the\nbusiness process executions. We evaluate these two latent space methods with\nsix other adversarial attacking methods on eleven real-life event logs and four\npredictive models. The first three attacking methods directly permute the\nactivities of the historically observed business process executions. The fourth\nmethod constrains the adversarial examples to lie within the same data\ndistribution as the original instances, by projecting the adversarial examples\nto the original data distribution.",
      "tldr_zh": "这篇论文针对预测过程监控中的对抗攻击问题，提出使用 Variational Autoencoders 生成现实的 adversarial examples，以避免传统方法（如计算机视觉中的像素级扰动）导致的不可行场景。作者引入两种新型 latent space attacks，通过在输入数据的潜在空间添加噪声来生成对抗样本，这些方法是 domain-agnostic，不依赖特定过程知识，并确保样本符合学到的数据分布。实验结果显示，在11个真实事件日志和4个预测模型上，与6种其他攻击方法相比，新方法显著提高了对抗样本的现实性和有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.14263v1",
      "published_date": "2024-11-21 16:18:52 UTC",
      "updated_date": "2024-11-21 16:18:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:52:24.146220"
    },
    {
      "arxiv_id": "2411.14258v1",
      "title": "Knowledge Graphs, Large Language Models, and Hallucinations: An NLP Perspective",
      "title_zh": "翻译失败",
      "authors": [
        "Ernests Lavrinovics",
        "Russa Biswas",
        "Johannes Bjerva",
        "Katja Hose"
      ],
      "abstract": "Large Language Models (LLMs) have revolutionized Natural Language Processing\n(NLP) based applications including automated text generation, question\nanswering, chatbots, and others. However, they face a significant challenge:\nhallucinations, where models produce plausible-sounding but factually incorrect\nresponses. This undermines trust and limits the applicability of LLMs in\ndifferent domains. Knowledge Graphs (KGs), on the other hand, provide a\nstructured collection of interconnected facts represented as entities (nodes)\nand their relationships (edges). In recent research, KGs have been leveraged to\nprovide context that can fill gaps in an LLM understanding of certain topics\noffering a promising approach to mitigate hallucinations in LLMs, enhancing\ntheir reliability and accuracy while benefiting from their wide applicability.\nNonetheless, it is still a very active area of research with various unresolved\nopen problems. In this paper, we discuss these open challenges covering\nstate-of-the-art datasets and benchmarks as well as methods for knowledge\nintegration and evaluating hallucinations. In our discussion, we consider the\ncurrent use of KGs in LLM systems and identify future directions within each of\nthese challenges.",
      "tldr_zh": "该论文从 NLP 视角探讨了 Knowledge Graphs (KGs) 如何缓解 Large Language Models (LLMs) 的 hallucinations 问题，即 LLMs 生成看似合理但事实错误的响应。作者强调 KGs 通过提供结构化的实体和关系知识，能填补 LLMs 的理解缺口，从而提升其可靠性和准确性。论文总结了当前数据集、基准测试、知识整合方法以及评估技术，并指出了未来研究方向，如未解决的开放挑战和潜在改进路径。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "68-02",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "7 pages, 2 Figures, 1 Table",
      "pdf_url": "http://arxiv.org/pdf/2411.14258v1",
      "published_date": "2024-11-21 16:09:05 UTC",
      "updated_date": "2024-11-21 16:09:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:52:35.832748"
    },
    {
      "arxiv_id": "2411.14257v2",
      "title": "Do I Know This Entity? Knowledge Awareness and Hallucinations in Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Javier Ferrando",
        "Oscar Obeso",
        "Senthooran Rajamanoharan",
        "Neel Nanda"
      ],
      "abstract": "Hallucinations in large language models are a widespread problem, yet the\nmechanisms behind whether models will hallucinate are poorly understood,\nlimiting our ability to solve this problem. Using sparse autoencoders as an\ninterpretability tool, we discover that a key part of these mechanisms is\nentity recognition, where the model detects if an entity is one it can recall\nfacts about. Sparse autoencoders uncover meaningful directions in the\nrepresentation space, these detect whether the model recognizes an entity, e.g.\ndetecting it doesn't know about an athlete or a movie. This suggests that\nmodels can have self-knowledge: internal representations about their own\ncapabilities. These directions are causally relevant: capable of steering the\nmodel to refuse to answer questions about known entities, or to hallucinate\nattributes of unknown entities when it would otherwise refuse. We demonstrate\nthat despite the sparse autoencoders being trained on the base model, these\ndirections have a causal effect on the chat model's refusal behavior,\nsuggesting that chat finetuning has repurposed this existing mechanism.\nFurthermore, we provide an initial exploration into the mechanistic role of\nthese directions in the model, finding that they disrupt the attention of\ndownstream heads that typically move entity attributes to the final token.",
      "tldr_zh": "本文研究了大型语言模型中的 hallucinations 问题，使用 sparse autoencoders 作为解释工具，发现实体识别机制是关键，即模型能检测自身是否了解某个实体（如运动员或电影）。这些机制揭示了模型的自我知识，通过表示空间中的有意义方向，影响模型的响应行为，例如引导模型拒绝回答已知实体的问题或为未知实体编造属性。实验证明，这些方向在基模型上训练后，对聊天微调模型的拒绝行为有因果作用，并干扰下游注意力头部的实体属性处理，从而为缓解 hallucinations 提供新见解。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2411.14257v2",
      "published_date": "2024-11-21 16:05:58 UTC",
      "updated_date": "2025-02-08 12:50:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:52:48.464466"
    },
    {
      "arxiv_id": "2411.14254v1",
      "title": "BERT-Based Approach for Automating Course Articulation Matrix Construction with Explainable AI",
      "title_zh": "基于BERT的方法用于自动化课程衔接矩阵构建，结合可解释AI",
      "authors": [
        "Natenaile Asmamaw Shiferaw",
        "Simpenzwe Honore Leandre",
        "Aman Sinha",
        "Dillip Rout"
      ],
      "abstract": "Course Outcome (CO) and Program Outcome (PO)/Program-Specific Outcome (PSO)\nalignment is a crucial task for ensuring curriculum coherence and assessing\neducational effectiveness. The construction of a Course Articulation Matrix\n(CAM), which quantifies the relationship between COs and POs/PSOs, typically\ninvolves assigning numerical values (0, 1, 2, 3) to represent the degree of\nalignment. In this study, We experiment with four models from the BERT family:\nBERT Base, DistilBERT, ALBERT, and RoBERTa, and use multiclass classification\nto assess the alignment between CO and PO/PSO pairs. We first evaluate\ntraditional machine learning classifiers, such as Decision Tree, Random Forest,\nand XGBoost, and then apply transfer learning to evaluate the performance of\nthe pretrained BERT models. To enhance model interpretability, we apply\nExplainable AI technique, specifically Local Interpretable Model-agnostic\nExplanations (LIME), to provide transparency into the decision-making process.\nOur system achieves accuracy, precision, recall, and F1-score values of 98.66%,\n98.67%, 98.66%, and 98.66%, respectively. This work demonstrates the potential\nof utilizing transfer learning with BERT-based models for the automated\ngeneration of CAMs, offering high performance and interpretability in\neducational outcome assessment.",
      "tldr_zh": "本研究提出了一种基于BERT的自动化方法，用于构建课程关联矩阵（CAM），以量化课程成果（CO）和程序成果（PO/PSO）之间的对齐关系。该方法实验了BERT家族模型（如BERT Base、DistilBERT、ALBERT和RoBERTa）进行多类分类，并与传统机器学习分类器（如Decision Tree、Random Forest和XGBoost）比较，同时应用Explainable AI技术（特别是LIME）提升模型决策的透明度。实验结果显示，该系统在准确率、精确率、召回率和F1分数上均达到98.66%。这项工作展示了利用转移学习和BERT-based模型自动生成CAM的潜力，为教育成果评估提供高性能和可解释性支持。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "26 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.14254v1",
      "published_date": "2024-11-21 16:02:39 UTC",
      "updated_date": "2024-11-21 16:02:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:53:00.188684"
    },
    {
      "arxiv_id": "2411.14252v1",
      "title": "Intent-Aware Dialogue Generation and Multi-Task Contrastive Learning for Multi-Turn Intent Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Junhua Liu",
        "Yong Keat Tan",
        "Bin Fu",
        "Kwan Hui Lim"
      ],
      "abstract": "Generating large-scale, domain-specific, multilingual multi-turn dialogue\ndatasets remains a significant hurdle for training effective Multi-Turn Intent\nClassification models in chatbot systems. In this paper, we introduce\nChain-of-Intent, a novel mechanism that combines Hidden Markov Models with\nLarge Language Models (LLMs) to generate contextually aware, intent-driven\nconversations through self-play. By extracting domain-specific knowledge from\ne-commerce chat logs, we estimate conversation turns and intent transitions,\nwhich guide the generation of coherent dialogues. Leveraging LLMs to enhance\nemission probabilities, our approach produces natural and contextually\nconsistent questions and answers. We also propose MINT-CL, a framework for\nmulti-turn intent classification using multi-task contrastive learning,\nimproving classification accuracy without the need for extensive annotated\ndata. Evaluations show that our methods outperform baselines in dialogue\nquality and intent classification accuracy, especially in multilingual\nsettings, while significantly reducing data generation efforts. Furthermore, we\nrelease MINT-E, a multilingual, intent-aware multi-turn e-commerce dialogue\ncorpus to support future research in this area.",
      "tldr_zh": "本论文提出Chain-of-Intent机制，将Hidden Markov Models (HMM)与Large Language Models (LLMs)结合，通过自玩(self-play)从电子商务聊天日志中提取知识，生成上下文感知的意图驱动多轮对话数据集，从而解决大规模领域特定多语言对话生成难题。论文还引入MINT-CL框架，利用multi-task contrastive learning改进多轮意图分类准确性，减少对标注数据的依赖。实验结果显示，该方法在对话质量和意图分类上优于基线模型，尤其在多语言场景中，并发布了MINT-E数据集以支持未来研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.14252v1",
      "published_date": "2024-11-21 15:59:29 UTC",
      "updated_date": "2024-11-21 15:59:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:53:12.488149"
    },
    {
      "arxiv_id": "2411.14251v2",
      "title": "Natural Language Reinforcement Learning",
      "title_zh": "自然语言强化学习",
      "authors": [
        "Xidong Feng",
        "Bo Liu",
        "Ziyu Wan",
        "Haotian Fu",
        "Girish A. Koushik",
        "Zhiyuan Hu",
        "Mengyue Yang",
        "Ying Wen",
        "Jun Wang"
      ],
      "abstract": "Reinforcement Learning (RL) mathematically formulates decision-making with\nMarkov Decision Process (MDP). With MDPs, researchers have achieved remarkable\nbreakthroughs across various domains, including games, robotics, and language\nmodels. This paper seeks a new possibility, Natural Language Reinforcement\nLearning (NLRL), by extending traditional MDP to natural language-based\nrepresentation space. Specifically, NLRL innovatively redefines RL principles,\nincluding task objectives, policy, value function, Bellman equation, and policy\niteration, into their language counterparts. With recent advancements in large\nlanguage models (LLMs), NLRL can be practically implemented to achieve RL-like\npolicy and value improvement by either pure prompting or gradient-based\ntraining. Experiments over Maze, Breakthrough, and Tic-Tac-Toe games\ndemonstrate the effectiveness, efficiency, and interpretability of the NLRL\nframework among diverse use cases.",
      "tldr_zh": "这篇论文引入了 Natural Language Reinforcement Learning (NLRL)，一种将传统 Reinforcement Learning (RL) 扩展到自然语言表示空间的框架，基于 Markov Decision Process (MDP) 的决策原理。NLRL 创新性地重新定义了 RL 的核心元素，包括任务目标、policy、value function、Bellman equation 和 policy iteration，使其适应语言环境，并利用 Large Language Models (LLMs) 通过纯提示或梯度训练实现策略和价值优化。实验在 Maze、Breakthrough 和 Tic-Tac-Toe 游戏上证明了 NLRL 的有效性、效率和可解释性，展示了其在多样化应用中的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at ICLR 2025 Workshop SSI-FM",
      "pdf_url": "http://arxiv.org/pdf/2411.14251v2",
      "published_date": "2024-11-21 15:57:02 UTC",
      "updated_date": "2025-05-15 03:35:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:53:23.993945"
    },
    {
      "arxiv_id": "2411.14243v2",
      "title": "AnywhereDoor: Multi-Target Backdoor Attacks on Object Detection",
      "title_zh": "AnywhereDoor: 针对目标检测的多目标后门攻击",
      "authors": [
        "Jialin Lu",
        "Junjie Shan",
        "Ziqi Zhao",
        "Ka-Ho Chow"
      ],
      "abstract": "As object detection becomes integral to many safety-critical applications,\nunderstanding its vulnerabilities is essential. Backdoor attacks, in\nparticular, pose a serious threat by implanting hidden triggers in victim\nmodels, which adversaries can later exploit to induce malicious behaviors\nduring inference. However, current understanding is limited to single-target\nattacks, where adversaries must define a fixed malicious behavior (target)\nbefore training, making inference-time adaptability impossible. Given the large\noutput space of object detection (including object existence prediction,\nbounding box estimation, and classification), the feasibility of flexible,\ninference-time model control remains unexplored. This paper introduces\nAnywhereDoor, a multi-target backdoor attack for object detection. Once\nimplanted, AnywhereDoor allows adversaries to make objects disappear, fabricate\nnew ones, or mislabel them, either across all object classes or specific ones,\noffering an unprecedented degree of control. This flexibility is enabled by\nthree key innovations: (i) objective disentanglement to scale the number of\nsupported targets; (ii) trigger mosaicking to ensure robustness even against\nregion-based detectors; and (iii) strategic batching to address object-level\ndata imbalances that hinder manipulation. Extensive experiments demonstrate\nthat AnywhereDoor grants attackers a high degree of control, improving attack\nsuccess rates by 26% compared to adaptations of existing methods for such\nflexible control.",
      "tldr_zh": "这篇论文提出了 AnywhereDoor，一种针对对象检测的多目标后门攻击框架，允许攻击者在推理时灵活控制模型行为，例如让对象消失、伪造新对象或错误标记它们，针对所有类或特定类，从而克服了传统单目标攻击的局限性。关键创新包括目标分离(objective disentanglement)来扩展支持的目标数量、触发拼接(trigger mosaicking)确保对基于区域检测器的鲁棒性，以及战略批处理(strategic batching)处理对象级数据不平衡问题。实验结果显示，AnywhereDoor 比现有方法的适应版本提高了 26% 的攻击成功率，突显了对象检测系统在安全关键应用中的潜在脆弱性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CR",
      "comment": "15 pages; This update was mistakenly uploaded as a new manuscript on\n  arXiv (2503.06529). The wrong submission has now been withdrawn, and we\n  replace the old one here",
      "pdf_url": "http://arxiv.org/pdf/2411.14243v2",
      "published_date": "2024-11-21 15:50:59 UTC",
      "updated_date": "2025-03-14 04:12:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:53:36.153064"
    },
    {
      "arxiv_id": "2411.14219v1",
      "title": "Towards Context-Rich Automated Biodiversity Assessments: Deriving AI-Powered Insights from Camera Trap Data",
      "title_zh": "翻译失败",
      "authors": [
        "Paul Fergus",
        "Carl Chalmers",
        "Naomi Matthews",
        "Stuart Nixon",
        "Andre Burger",
        "Oliver Hartley",
        "Chris Sutherland",
        "Xavier Lambin",
        "Steven Longmore",
        "Serge Wich"
      ],
      "abstract": "Camera traps offer enormous new opportunities in ecological studies, but\ncurrent automated image analysis methods often lack the contextual richness\nneeded to support impactful conservation outcomes. Here we present an\nintegrated approach that combines deep learning-based vision and language\nmodels to improve ecological reporting using data from camera traps. We\nintroduce a two-stage system: YOLOv10-X to localise and classify species\n(mammals and birds) within images, and a Phi-3.5-vision-instruct model to read\nYOLOv10-X binding box labels to identify species, overcoming its limitation\nwith hard to classify objects in images. Additionally, Phi-3.5 detects broader\nvariables, such as vegetation type, and time of day, providing rich ecological\nand environmental context to YOLO's species detection output. When combined,\nthis output is processed by the model's natural language system to answer\ncomplex queries, and retrieval-augmented generation (RAG) is employed to enrich\nresponses with external information, like species weight and IUCN status\n(information that cannot be obtained through direct visual analysis). This\ninformation is used to automatically generate structured reports, providing\nbiodiversity stakeholders with deeper insights into, for example, species\nabundance, distribution, animal behaviour, and habitat selection. Our approach\ndelivers contextually rich narratives that aid in wildlife management\ndecisions. By providing contextually rich insights, our approach not only\nreduces manual effort but also supports timely decision-making in conservation,\npotentially shifting efforts from reactive to proactive management.",
      "tldr_zh": "这篇论文提出了一种集成方法，利用深度学习视觉模型 YOLOv10-X 和语言模型 Phi-3.5-vision-instruct 来分析相机陷阱数据，从而提升生态报告的上下文丰富性。该系统采用两阶段流程：YOLOv10-X 负责定位和分类图像中的物种（如哺乳动物和鸟类），而 Phi-3.5-vision-instruct 则处理检测结果、识别难分类对象，并额外检测变量如植被类型和时间。结合检索增强生成 (RAG) 技术，该方法生成结构化的报告，提供物种丰度、分布、行为和栖息地选择的洞见，并通过外部信息（如 IUCN 状态）支持主动的野生动物管理决策。总的来说，这种方法减少了手动分析工作，有助于从反应式转向及时的保护行动。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "32 Pages, 22 images",
      "pdf_url": "http://arxiv.org/pdf/2411.14219v1",
      "published_date": "2024-11-21 15:28:52 UTC",
      "updated_date": "2024-11-21 15:28:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:55:49.017114"
    },
    {
      "arxiv_id": "2411.14215v1",
      "title": "Evaluating the Robustness of Analogical Reasoning in Large Language Models",
      "title_zh": "评估大语言模型中类比推理的鲁棒性",
      "authors": [
        "Martha Lewis",
        "Melanie Mitchell"
      ],
      "abstract": "LLMs have performed well on several reasoning benchmarks, including ones that\ntest analogical reasoning abilities. However, there is debate on the extent to\nwhich they are performing general abstract reasoning versus employing\nnon-robust processes, e.g., that overly rely on similarity to pre-training\ndata. Here we investigate the robustness of analogy-making abilities previously\nclaimed for LLMs on three of four domains studied by Webb, Holyoak, and Lu\n(2023): letter-string analogies, digit matrices, and story analogies. For each\ndomain we test humans and GPT models on robustness to variants of the original\nanalogy problems that test the same abstract reasoning abilities but are likely\ndissimilar from tasks in the pre-training data. The performance of a system\nthat uses robust abstract reasoning should not decline substantially on these\nvariants.\n  On simple letter-string analogies, we find that while the performance of\nhumans remains high for two types of variants we tested, the GPT models'\nperformance declines sharply. This pattern is less pronounced as the complexity\nof these problems is increased, as both humans and GPT models perform poorly on\nboth the original and variant problems requiring more complex analogies. On\ndigit-matrix problems, we find a similar pattern but only on one out of the two\ntypes of variants we tested. On story-based analogy problems, we find that,\nunlike humans, the performance of GPT models are susceptible to answer-order\neffects, and that GPT models also may be more sensitive than humans to\nparaphrasing.\n  This work provides evidence that LLMs often lack the robustness of zero-shot\nhuman analogy-making, exhibiting brittleness on most of the variations we\ntested. More generally, this work points to the importance of carefully\nevaluating AI systems not only for accuracy but also robustness when testing\ntheir cognitive capabilities.",
      "tldr_zh": "这篇论文评估了大型语言模型(LLMs)在类比推理方面的稳健性，通过测试人类和 GPT 模型在字母字符串、数字矩阵和故事类比等三个领域的原始问题及其变体。研究发现，在简单变体问题上，LLMs 的性能急剧下降，而人类保持较高水平；在复杂问题或特定变体（如故事类比中的答案顺序和改述）上，LLMs 表现出更大的脆弱性。总体而言，这表明 LLMs 缺乏人类零样本类比推理的稳健性，并强调在评估 AI 认知能力时需同时关注准确性和 robustness。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "31 pages, 13 figures. arXiv admin note: text overlap with\n  arXiv:2402.08955",
      "pdf_url": "http://arxiv.org/pdf/2411.14215v1",
      "published_date": "2024-11-21 15:25:08 UTC",
      "updated_date": "2024-11-21 15:25:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:54:00.182037"
    },
    {
      "arxiv_id": "2411.14214v1",
      "title": "Physics-Informed LLM-Agent for Automated Modulation Design in Power Electronics Systems",
      "title_zh": "物理信息驱动的 LLM 代理用于电力电子系统的自动调制设计",
      "authors": [
        "Junhua Liu",
        "Fanfan Lin",
        "Xinze Li",
        "Kwan Hui Lim",
        "Shuai Zhao"
      ],
      "abstract": "LLM-based autonomous agents have demonstrated outstanding performance in\nsolving complex industrial tasks. However, in the pursuit of carbon neutrality\nand high-performance renewable energy systems, existing AI-assisted design\nautomation faces significant limitations in explainability, scalability, and\nusability. To address these challenges, we propose LP-COMDA, an LLM-based,\nphysics-informed autonomous agent that automates the modulation design of power\nconverters in Power Electronics Systems with minimal human supervision. Unlike\ntraditional AI-assisted approaches, LP-COMDA contains an LLM-based planner that\ngathers and validates design specifications through a user-friendly chat\ninterface. The planner then coordinates with physics-informed design and\noptimization tools to iteratively generate and refine modulation designs\nautonomously. Through the chat interface, LP-COMDA provides an explainable\ndesign process, presenting explanations and charts. Experiments show that\nLP-COMDA outperforms all baseline methods, achieving a 63.2% reduction in error\ncompared to the second-best benchmark method in terms of standard mean absolute\nerror. Furthermore, empirical studies with 20 experts conclude that design time\nwith LP-COMDA is over 33 times faster than conventional methods, showing its\nsignificant improvement on design efficiency over the current processes.",
      "tldr_zh": "本研究提出了一种基于LLM的物理信息自主代理LP-COMDA，用于自动化电力电子系统的调制设计，旨在解决传统AI方法在可解释性、可扩展性和可用性方面的局限性。该代理包括一个LLM-based planner，通过用户友好的聊天界面收集并验证设计规格，并与物理信息设计和优化工具协作，进行迭代生成和完善设计过程，同时提供可解释的解释和图表。实验结果显示，LP-COMDA比基准方法减少63.2%的平均绝对误差，并使设计时间比传统方法快33倍以上，显著提升了电力电子系统的设计效率。",
      "categories": [
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.14214v1",
      "published_date": "2024-11-21 15:24:41 UTC",
      "updated_date": "2024-11-21 15:24:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:54:10.986218"
    },
    {
      "arxiv_id": "2411.14207v2",
      "title": "HARP: A Large-Scale Higher-Order Ambisonic Room Impulse Response Dataset",
      "title_zh": "翻译失败",
      "authors": [
        "Shivam Saini",
        "Jürgen Peissig"
      ],
      "abstract": "This contribution introduces a dataset of 7th-order Ambisonic Room Impulse\nResponses (HOA-RIRs), created using the Image Source Method. By employing\nhigher-order Ambisonics, our dataset enables precise spatial audio\nreproduction, a critical requirement for realistic immersive audio\napplications. Leveraging the virtual simulation, we present a unique microphone\nconfiguration, based on the superposition principle, designed to optimize sound\nfield coverage while addressing the limitations of traditional microphone\narrays. The presented 64-microphone configuration allows us to capture RIRs\ndirectly in the Spherical Harmonics domain. The dataset features a wide range\nof room configurations, encompassing variations in room geometry, acoustic\nabsorption materials, and source-receiver distances. A detailed description of\nthe simulation setup is provided alongside for an accurate reproduction. The\ndataset serves as a vital resource for researchers working on spatial audio,\nparticularly in applications involving machine learning to improve room\nacoustics modeling and sound field synthesis. It further provides a very high\nlevel of spatial resolution and realism crucial for tasks such as source\nlocalization, reverberation prediction, and immersive sound reproduction.",
      "tldr_zh": "本研究引入了HARP数据集，这是一个大规模的7th-order Ambisonic Room Impulse Responses (HOA-RIRs)数据集，通过Image Source Method进行创建，以实现精确的spatial audio reproduction。数据集采用基于superposition principle的独特64-microphone配置，直接在Spherical Harmonics域捕获RIRs，并覆盖了多种room configurations，包括room geometry、acoustic absorption materials和source-receiver distances。HARP为spatial audio研究提供宝贵资源，尤其适用于machine learning应用，如提升room acoustics modeling、sound field synthesis、source localization、reverberation prediction和immersive sound reproduction等领域。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.MM",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted at ICASSP 2025 Workshop. Code to generate uploaded at:\n  https://github.com/whojavumusic/HARP",
      "pdf_url": "http://arxiv.org/pdf/2411.14207v2",
      "published_date": "2024-11-21 15:16:48 UTC",
      "updated_date": "2025-01-19 11:15:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:55:59.945014"
    },
    {
      "arxiv_id": "2411.14205v1",
      "title": "Is this Generated Person Existed in Real-world? Fine-grained Detecting and Calibrating Abnormal Human-body",
      "title_zh": "翻译失败",
      "authors": [
        "Zeqing Wang",
        "Qingyang Ma",
        "Wentao Wan",
        "Haojie Li",
        "Keze Wang",
        "Yonghong Tian"
      ],
      "abstract": "Recent improvements in visual synthesis have significantly enhanced the\ndepiction of generated human photos, which are pivotal due to their wide\napplicability and demand. Nonetheless, the existing text-to-image or\ntext-to-video models often generate low-quality human photos that might differ\nconsiderably from real-world body structures, referred to as \"abnormal human\nbodies\". Such abnormalities, typically deemed unacceptable, pose considerable\nchallenges in the detection and repair of them within human photos. These\nchallenges require precise abnormality recognition capabilities, which entail\npinpointing both the location and the abnormality type. Intuitively, Visual\nLanguage Models (VLMs) that have obtained remarkable performance on various\nvisual tasks are quite suitable for this task. However, their performance on\nabnormality detection in human photos is quite poor. Hence, it is quite\nimportant to highlight this task for the research community. In this paper, we\nfirst introduce a simple yet challenging task, i.e., \\textbf{F}ine-grained\n\\textbf{H}uman-body \\textbf{A}bnormality \\textbf{D}etection \\textbf{(FHAD)},\nand construct two high-quality datasets for evaluation. Then, we propose a\nmeticulous framework, named HumanCalibrator, which identifies and repairs\nabnormalities in human body structures while preserving the other content.\nExperiments indicate that our HumanCalibrator achieves high accuracy in\nabnormality detection and accomplishes an increase in visual comparisons while\npreserving the other visual content.",
      "tldr_zh": "本研究关注视觉合成技术生成的图像中“abnormal human bodies”问题，即人体结构与现实不符的现象，并指出现有Visual Language Models (VLMs)在此任务上的性能较差。论文引入了新的Fine-grained Human-body Abnormality Detection (FHAD)任务，并构建了两个高质量数据集，用于评估细粒度人体异常检测。作者提出了HumanCalibrator框架，该框架能够精确识别和修复人体结构异常，同时保留其他视觉内容。实验结果表明，HumanCalibrator在异常检测中实现了高准确率，并提升了整体视觉比较效果。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "16 pages, 14 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.14205v1",
      "published_date": "2024-11-21 15:13:38 UTC",
      "updated_date": "2024-11-21 15:13:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:56:12.418835"
    },
    {
      "arxiv_id": "2411.14199v1",
      "title": "OpenScholar: Synthesizing Scientific Literature with Retrieval-augmented LMs",
      "title_zh": "OpenScholar：使用检索增强 LMs 合成科学文献",
      "authors": [
        "Akari Asai",
        "Jacqueline He",
        "Rulin Shao",
        "Weijia Shi",
        "Amanpreet Singh",
        "Joseph Chee Chang",
        "Kyle Lo",
        "Luca Soldaini",
        "Sergey Feldman",
        "Mike D'arcy",
        "David Wadden",
        "Matt Latzke",
        "Minyang Tian",
        "Pan Ji",
        "Shengyan Liu",
        "Hao Tong",
        "Bohao Wu",
        "Yanyu Xiong",
        "Luke Zettlemoyer",
        "Graham Neubig",
        "Dan Weld",
        "Doug Downey",
        "Wen-tau Yih",
        "Pang Wei Koh",
        "Hannaneh Hajishirzi"
      ],
      "abstract": "Scientific progress depends on researchers' ability to synthesize the growing\nbody of literature. Can large language models (LMs) assist scientists in this\ntask? We introduce OpenScholar, a specialized retrieval-augmented LM that\nanswers scientific queries by identifying relevant passages from 45 million\nopen-access papers and synthesizing citation-backed responses. To evaluate\nOpenScholar, we develop ScholarQABench, the first large-scale multi-domain\nbenchmark for literature search, comprising 2,967 expert-written queries and\n208 long-form answers across computer science, physics, neuroscience, and\nbiomedicine. On ScholarQABench, OpenScholar-8B outperforms GPT-4o by 5% and\nPaperQA2 by 7% in correctness, despite being a smaller, open model. While GPT4o\nhallucinates citations 78 to 90% of the time, OpenScholar achieves citation\naccuracy on par with human experts. OpenScholar's datastore, retriever, and\nself-feedback inference loop also improves off-the-shelf LMs: for instance,\nOpenScholar-GPT4o improves GPT-4o's correctness by 12%. In human evaluations,\nexperts preferred OpenScholar-8B and OpenScholar-GPT4o responses over\nexpert-written ones 51% and 70% of the time, respectively, compared to GPT4o's\n32%. We open-source all of our code, models, datastore, data and a public demo.",
      "tldr_zh": "本研究引入了 OpenScholar，一种基于 Retrieval-augmented LMs 的系统，能够从 4500 万篇开源论文中检索相关段落，并合成带有准确引文的科学响应，以辅助研究者文献合成。\n为了评估，研究团队开发了 ScholarQABench，这是一个大型多领域基准，包含 2967 个专家编写的查询和 208 个长形式答案，覆盖计算机科学、物理学、神经科学和生物医学。\n在 ScholarQABench 测试中，OpenScholar-8B 模型的正确率比 GPT-4o 高 5%、比 PaperQA2 高 7%，并在引文准确性上达到人类专家水平，同时显著减少了幻觉引文。\n此外，OpenScholar 的数据存储、检索器和自反馈推理循环能提升其他 LMs 的性能，如将 GPT-4o 的正确率提高 12%，并在人类评估中被专家偏好率高达 51% 到 70%。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DL",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.14199v1",
      "published_date": "2024-11-21 15:07:42 UTC",
      "updated_date": "2024-11-21 15:07:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:56:26.387020"
    },
    {
      "arxiv_id": "2411.14193v1",
      "title": "ComfyGI: Automatic Improvement of Image Generation Workflows",
      "title_zh": "翻译失败",
      "authors": [
        "Dominik Sobania",
        "Martin Briesch",
        "Franz Rothlauf"
      ],
      "abstract": "Automatic image generation is no longer just of interest to researchers, but\nalso to practitioners. However, current models are sensitive to the settings\nused and automatic optimization methods often require human involvement. To\nbridge this gap, we introduce ComfyGI, a novel approach to automatically\nimprove workflows for image generation without the need for human intervention\ndriven by techniques from genetic improvement. This enables image generation\nwith significantly higher quality in terms of the alignment with the given\ndescription and the perceived aesthetics. On the performance side, we find that\noverall, the images generated with an optimized workflow are about 50% better\ncompared to the initial workflow in terms of the median ImageReward score.\nThese already good results are even surpassed in our human evaluation, as the\nparticipants preferred the images improved by ComfyGI in around 90% of the\ncases.",
      "tldr_zh": "该研究引入了 ComfyGI，一种基于 genetic improvement 技术的创新方法，用于自动优化图像生成工作流，无需人为干预。ComfyGI 通过自动调整设置来提升图像与描述的匹配度以及感知美学质量。实验结果显示，优化后的图像在 ImageReward 分数中位数上比初始工作流提高约 50%，而在人类评估中，参与者更偏好 ComfyGI 改进的图像，达 90% 的情况下。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.NE"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.14193v1",
      "published_date": "2024-11-21 15:02:41 UTC",
      "updated_date": "2024-11-21 15:02:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:56:35.876908"
    },
    {
      "arxiv_id": "2411.14164v1",
      "title": "FoPru: Focal Pruning for Efficient Large Vision-Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Lei Jiang",
        "Weizhe Huang",
        "Tongxuan Liu",
        "Yuting Zeng",
        "Jing Li",
        "Lechao Cheng",
        "Xiaohua Xu"
      ],
      "abstract": "Large Vision-Language Models (LVLMs) represent a significant advancement\ntoward achieving superior multimodal capabilities by enabling powerful Large\nLanguage Models (LLMs) to understand visual input. Typically, LVLMs utilize\nvisual encoders, such as CLIP, to transform images into visual tokens, which\nare then aligned with textual tokens through projection layers before being\ninput into the LLM for inference. Although existing LVLMs have achieved\nsignificant success, their inference efficiency is still limited by the\nsubstantial number of visual tokens and the potential redundancy among them. To\nmitigate this issue, we propose Focal Pruning (FoPru), a training-free method\nthat prunes visual tokens based on the attention-based token significance\nderived from the vision encoder. Specifically, we introduce two alternative\npruning strategies: 1) the rank strategy, which leverages all token\nsignificance scores to retain more critical tokens in a global view; 2) the row\nstrategy, which focuses on preserving continuous key information in images from\na local perspective. Finally, the selected tokens are reordered to maintain\ntheir original positional relationships. Extensive experiments across various\nLVLMs and multimodal datasets demonstrate that our method can prune a large\nnumber of redundant tokens while maintaining high accuracy, leading to\nsignificant improvements in inference efficiency.",
      "tldr_zh": "本文提出 FoPru，一种无需训练的修剪方法，针对 Large Vision-Language Models (LVLMs) 中的视觉标记冗余问题，通过基于注意力机制的标记重要性来优化模型效率。具体而言，FoPru 包括两种策略：rank strategy 使用全局视角保留关键标记，以及 row strategy 从局部视角保持图像的连续信息，并对选定标记进行重新排序以维持原位置关系。实验在多种 LVLMs 和多模态数据集上证明，该方法能修剪大量冗余标记，同时保持高准确率，从而显著提升推理效率。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "11 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.14164v1",
      "published_date": "2024-11-21 14:22:38 UTC",
      "updated_date": "2024-11-21 14:22:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:56:49.154095"
    },
    {
      "arxiv_id": "2411.14515v1",
      "title": "Are Anomaly Scores Telling the Whole Story? A Benchmark for Multilevel Anomaly Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Tri Cao",
        "Minh-Huy Trinh",
        "Ailin Deng",
        "Quoc-Nam Nguyen",
        "Khoa Duong",
        "Ngai-Man Cheung",
        "Bryan Hooi"
      ],
      "abstract": "Anomaly detection (AD) is a machine learning task that identifies anomalies\nby learning patterns from normal training data. In many real-world scenarios,\nanomalies vary in severity, from minor anomalies with little risk to severe\nabnormalities requiring immediate attention. However, existing models primarily\noperate in a binary setting, and the anomaly scores they produce are usually\nbased on the deviation of data points from normal data, which may not\naccurately reflect practical severity. In this paper, we address this gap by\nmaking three key contributions. First, we propose a novel setting, Multilevel\nAD (MAD), in which the anomaly score represents the severity of anomalies in\nreal-world applications, and we highlight its diverse applications across\nvarious domains. Second, we introduce a novel benchmark, MAD-Bench, that\nevaluates models not only on their ability to detect anomalies, but also on how\neffectively their anomaly scores reflect severity. This benchmark incorporates\nmultiple types of baselines and real-world applications involving severity.\nFinally, we conduct a comprehensive performance analysis on MAD-Bench. We\nevaluate models on their ability to assign severity-aligned scores, investigate\nthe correspondence between their performance on binary and multilevel\ndetection, and study their robustness. This analysis offers key insights into\nimproving AD models for practical severity alignment. The code framework and\ndatasets used for the benchmark will be made publicly available.",
      "tldr_zh": "该论文指出，现有的异常检测(Anomaly Detection, AD)模型通常仅进行二元分类，无法准确反映异常的实际严重程度，从而忽略了从轻微风险到紧急异常的差异。为解决这一问题，研究者提出Multilevel Anomaly Detection (MAD)的新设置，并引入MAD-Bench基准，用于评估模型不仅在检测异常方面的能力，还在异常分数是否有效对齐严重程度。实验分析显示，通过MAD-Bench的全面性能评估，模型在严重度对齐、从二元到多级检测的对应关系以及鲁棒性上获得了关键见解，为改进AD模型在实际应用中的实用性提供了指导。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Under review",
      "pdf_url": "http://arxiv.org/pdf/2411.14515v1",
      "published_date": "2024-11-21 14:18:37 UTC",
      "updated_date": "2024-11-21 14:18:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:57:00.783933"
    },
    {
      "arxiv_id": "2411.14141v1",
      "title": "Differentiable SVD based on Moore-Penrose Pseudoinverse for Inverse Imaging Problems",
      "title_zh": "基于 Moore-Penrose Pseudoinverse 的可微 SVD 用于逆成像问题",
      "authors": [
        "Yinghao Zhang",
        "Yue Hu"
      ],
      "abstract": "Low-rank regularization-based deep unrolling networks have achieved\nremarkable success in various inverse imaging problems (IIPs). However, the\nsingular value decomposition (SVD) is non-differentiable when duplicated\nsingular values occur, leading to severe numerical instability during training.\nIn this paper, we propose a differentiable SVD based on the Moore-Penrose\npseudoinverse to address this issue. To the best of our knowledge, this is the\nfirst work to provide a comprehensive analysis of the differentiability of the\ntrivial SVD. Specifically, we show that the non-differentiability of SVD is\nessentially due to an underdetermined system of linear equations arising in the\nderivation process. We utilize the Moore-Penrose pseudoinverse to solve the\nsystem, thereby proposing a differentiable SVD. A numerical stability analysis\nin the context of IIPs is provided. Experimental results in color image\ncompressed sensing and dynamic MRI reconstruction show that our proposed\ndifferentiable SVD can effectively address the numerical instability issue\nwhile ensuring computational precision. Code is available at\nhttps://github.com/yhao-z/SVD-inv.",
      "tldr_zh": "该论文针对逆向成像问题（IIPs）中，低秩正则化深度展开网络的训练不稳定性问题，分析了奇异值分解（SVD）在重复奇异值时的非微分性。作者提出了一种基于Moore-Penrose Pseudoinverse的微分SVD方法，通过解决求导过程中出现的欠定线性方程系统来实现数值稳定。实验结果显示，该方法在彩色图像压缩感知和动态MRI重建任务上有效缓解了不稳定性问题，同时保持了计算精度，为IIPs的优化提供了可靠工具。",
      "categories": [
        "math.NA",
        "cs.AI",
        "cs.CV",
        "cs.NA",
        "G.1.4; I.2.0; I.4.4; I.4.5"
      ],
      "primary_category": "math.NA",
      "comment": "11 pages",
      "pdf_url": "http://arxiv.org/pdf/2411.14141v1",
      "published_date": "2024-11-21 14:04:38 UTC",
      "updated_date": "2024-11-21 14:04:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:57:12.039177"
    },
    {
      "arxiv_id": "2411.14133v1",
      "title": "GASP: Efficient Black-Box Generation of Adversarial Suffixes for Jailbreaking LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Advik Raj Basani",
        "Xiao Zhang"
      ],
      "abstract": "Large Language Models (LLMs) have shown impressive proficiency across a range\nof natural language processing tasks yet remain vulnerable to adversarial\nprompts, known as jailbreak attacks, carefully designed to elicit harmful\nresponses from LLMs. Traditional methods rely on manual heuristics, which\nsuffer from limited generalizability. While being automatic, optimization-based\nattacks often produce unnatural jailbreak prompts that are easy to detect by\nsafety filters or require high computational overhead due to discrete token\noptimization. Witnessing the limitations of existing jailbreak methods, we\nintroduce Generative Adversarial Suffix Prompter (GASP), a novel framework that\ncombines human-readable prompt generation with Latent Bayesian Optimization\n(LBO) to improve adversarial suffix creation in a fully black-box setting. GASP\nleverages LBO to craft adversarial suffixes by efficiently exploring continuous\nembedding spaces, gradually optimizing the model to improve attack efficacy\nwhile balancing prompt coherence through a targeted iterative refinement\nprocedure. Our experiments show that GASP can generate natural jailbreak\nprompts, significantly improving attack success rates, reducing training times,\nand accelerating inference speed, thus making it an efficient and scalable\nsolution for red-teaming LLMs.",
      "tldr_zh": "该研究提出GASP框架，一种高效的黑盒方法，用于生成对抗性后缀以实现对大语言模型(LLMs)的jailbreak attacks。GASP结合人类可读提示生成和Latent Bayesian Optimization (LBO)，通过在连续嵌入空间中探索和迭代优化，来创建自然的对抗性后缀，同时平衡提示连贯性和攻击效率。实验结果表明，GASP显著提高了jailbreak成功率，减少了训练时间并加速了推理速度，使其成为red-teaming LLMs的可靠解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "28 pages, 9 tables, 13 figures; under review at CVPR '25",
      "pdf_url": "http://arxiv.org/pdf/2411.14133v1",
      "published_date": "2024-11-21 14:00:01 UTC",
      "updated_date": "2024-11-21 14:00:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:57:24.698844"
    },
    {
      "arxiv_id": "2411.14117v1",
      "title": "Umbrella Reinforcement Learning -- computationally efficient tool for hard non-linear problems",
      "title_zh": "翻译失败",
      "authors": [
        "Egor E. Nuzhin",
        "Nikolai V. Brilliantov"
      ],
      "abstract": "We report a novel, computationally efficient approach for solving hard\nnonlinear problems of reinforcement learning (RL). Here we combine umbrella\nsampling, from computational physics/chemistry, with optimal control methods.\nThe approach is realized on the basis of neural networks, with the use of\npolicy gradient. It outperforms, by computational efficiency and implementation\nuniversality, all available state-of-the-art algorithms, in application to hard\nRL problems with sparse reward, state traps and lack of terminal states. The\nproposed approach uses an ensemble of simultaneously acting agents, with a\nmodified reward which includes the ensemble entropy, yielding an optimal\nexploration-exploitation balance.",
      "tldr_zh": "这篇论文提出了一种名为 Umbrella Reinforcement Learning 的新方法，用于高效解决强化学习 (RL) 中的困难非线性问题。该方法结合 umbrella sampling 和 optimal control 技术，通过 neural networks 和 policy gradient 实现计算上的高效性，并使用一个 ensemble of agents 和修改的 reward（包括 ensemble entropy）来实现最佳的 exploration-exploitation 平衡。与现有 state-of-the-art 算法相比，该方法在处理稀疏奖励、状态陷阱和无终止状态的硬 RL 问题时，表现出更高的计算效率和实现通用性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "I.2.6; I.2.8"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.14117v1",
      "published_date": "2024-11-21 13:34:36 UTC",
      "updated_date": "2024-11-21 13:34:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:57:36.670861"
    },
    {
      "arxiv_id": "2411.14092v1",
      "title": "MetaCropFollow: Few-Shot Adaptation with Meta-Learning for Under-Canopy Navigation",
      "title_zh": "翻译失败",
      "authors": [
        "Thomas Woehrle",
        "Arun N. Sivakumar",
        "Naveen Uppalapati",
        "Girish Chowdhary"
      ],
      "abstract": "Autonomous under-canopy navigation faces additional challenges compared to\nover-canopy settings - for example the tight spacing between the crop rows,\ndegraded GPS accuracy and excessive clutter. Keypoint-based visual navigation\nhas been shown to perform well in these conditions, however the differences\nbetween agricultural environments in terms of lighting, season, soil and crop\ntype mean that a domain shift will likely be encountered at some point of the\nrobot deployment. In this paper, we explore the use of Meta-Learning to\novercome this domain shift using a minimal amount of data. We train a\nbase-learner that can quickly adapt to new conditions, enabling more robust\nnavigation in low-data regimes.",
      "tldr_zh": "该论文针对树冠下导航的挑战（如作物行间距狭窄、GPS 精度降低和杂物过多），提出了一种基于 Meta-Learning 的 Few-Shot Adaptation 方法，以应对农业环境差异（如照明、季节和作物类型）引发的领域偏移。研究训练了一个 base-learner 模型，能够使用极少数据快速适应新条件，从而提升导航的鲁棒性。实验结果表明，这种方法在低数据环境下显著改善了关键点-based 视觉导航的表现，为自主农业机器人部署提供了更可靠的解决方案。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.14092v1",
      "published_date": "2024-11-21 12:58:09 UTC",
      "updated_date": "2024-11-21 12:58:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:57:47.561487"
    },
    {
      "arxiv_id": "2411.14064v1",
      "title": "Multi LoRA Meets Vision: Merging multiple adapters to create a multi task model",
      "title_zh": "翻译失败",
      "authors": [
        "Ege Kesim",
        "Selahattin Serdar Helli"
      ],
      "abstract": "Parameter efficient finetuning (PEFT) methods are widely used in LLMs and\ngenerative models in computer vision. Especially one can use multiple of these\nduring inference to change the behavior of the base model. In this paper we\ninvestigated whether multiple LoRA adapters trained on computer vision tasks\ncan be merged together and used during inference without loss in performance.\nBy achieving this, multitask models can be created just by merging different\nLoRAs. Merging these will reduce inference time and it will not require any\nadditional retraining. We have trained adapters on six different tasks and\nevaluated their performance when they are merged together. For comparison we\nused a model with a frozen backbone and finetuned its head. Our results show\nthat even with simple merging techniques creating a multitask model by merging\nadapters is achievable by slightly loosing performance in some cases. In our\nexperiments we merged up to three adapters together. Depending on the task and\nthe similarity of the data adapters were trained on, merges can outperform head\nfinetuning. We have observed that LoRAs trained with dissimilar datasets tend\nto perform better compared to model trained on similar datasets.",
      "tldr_zh": "本研究探讨了在计算机视觉任务中，将多个LoRA适配器合并以创建多任务模型的可行性，从而实现参数高效微调(PEFT)并减少推理时间，而无需额外重新训练。研究者训练了六个不同任务的适配器，并通过简单合并技术评估性能，与冻结主干并微调头的基线模型比较，结果显示合并后模型在某些情况下仅略微损失性能，甚至在数据集不相似时表现出优越性。总体而言，此方法证明了LoRA适配器合并的有效性，有助于构建高效的多任务视觉模型。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.14064v1",
      "published_date": "2024-11-21 12:26:33 UTC",
      "updated_date": "2024-11-21 12:26:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:58:01.069002"
    },
    {
      "arxiv_id": "2411.14511v1",
      "title": "Variational Autoencoders for Efficient Simulation-Based Inference",
      "title_zh": "翻译失败",
      "authors": [
        "Mayank Nautiyal",
        "Andrey Shternshis",
        "Andreas Hellander",
        "Prashant Singh"
      ],
      "abstract": "We present a generative modeling approach based on the variational inference\nframework for likelihood-free simulation-based inference. The method leverages\nlatent variables within variational autoencoders to efficiently estimate\ncomplex posterior distributions arising from stochastic simulations. We explore\ntwo variations of this approach distinguished by their treatment of the prior\ndistribution. The first model adapts the prior based on observed data using a\nmultivariate prior network, enhancing generalization across various posterior\nqueries. In contrast, the second model utilizes a standard Gaussian prior,\noffering simplicity while still effectively capturing complex posterior\ndistributions. We demonstrate the efficacy of these models on well-established\nbenchmark problems, achieving results comparable to flow-based approaches while\nmaintaining computational efficiency and scalability.",
      "tldr_zh": "本文提出了一种基于变分推理(variational inference)的生成建模方法，用于高效处理无需似然函数的模拟-based inference，通过变分自编码器(Variational Autoencoders)的潜在变量来估计复杂后验分布(posterior distributions)。该方法探索了两种变体：第一种使用多变量先验网络(multivariate prior network)基于观察数据适应先验分布，以提升在不同后验查询中的泛化能力；第二种则采用标准高斯先验(Gaussian prior)，提供简单有效的后验捕捉。实验结果显示，该方法在基准问题上取得了与基于流的(flow-based)方法相当的表现，同时显著提高了计算效率和可扩展性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.14511v1",
      "published_date": "2024-11-21 12:24:13 UTC",
      "updated_date": "2024-11-21 12:24:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:58:14.337602"
    },
    {
      "arxiv_id": "2411.19793v1",
      "title": "Voice Communication Analysis in Esports",
      "title_zh": "翻译失败",
      "authors": [
        "Aymeric Vinot",
        "Nicolas Perez"
      ],
      "abstract": "In most team-based esports, voice communications are prominent in the team\nefficiency and synergy. In fact it has been observed that not only the skill\naspect of the team but also the team effective voice communication comes into\nplay when trying to have good performance in official matches. With the recent\nemergence of LLM (Large Language Models) tools regarding NLP (Natural Language\nProcessing) (Vaswani et. al.), we decided to try applying them in order to have\na better understanding on how to improve the effectiveness of the voice\ncommunications. In this paper the study has been made through the prism of\nLeague of Legends esport. However the main concepts and ideas can be easily\napplicable in any other team related esports.",
      "tldr_zh": "本文研究了电子竞技中语音通信对团队效率和协同作用的影响，强调除了玩家技能外，有效的语音通信同样是提升比赛表现的关键。研究利用LLM（Large Language Models）和NLP（Natural Language Processing）工具，对League of Legends的语音通信进行分析，以探索改进其有效性的方法。该方法的核心概念可轻松应用于其他团队电子竞技，帮助优化团队协作。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CL",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "17 pages, 11 figures. Independent research",
      "pdf_url": "http://arxiv.org/pdf/2411.19793v1",
      "published_date": "2024-11-21 12:21:11 UTC",
      "updated_date": "2024-11-21 12:21:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:58:24.223117"
    },
    {
      "arxiv_id": "2411.14062v2",
      "title": "MMGenBench: Fully Automatically Evaluating LMMs from the Text-to-Image Generation Perspective",
      "title_zh": "翻译失败",
      "authors": [
        "Hailang Huang",
        "Yong Wang",
        "Zixuan Huang",
        "Huaqiu Li",
        "Tongwen Huang",
        "Xiangxiang Chu",
        "Richong Zhang"
      ],
      "abstract": "Large Multimodal Models (LMMs) demonstrate impressive capabilities. However,\ncurrent benchmarks predominantly focus on image comprehension in specific\ndomains, and these benchmarks are labor-intensive to construct. Moreover, their\nanswers tend to be brief, making it difficult to assess the ability of LMMs to\ngenerate detailed descriptions of images. To address these limitations, we\npropose the MMGenBench-Pipeline, a straightforward and fully automated\nevaluation pipeline. This involves generating textual descriptions from input\nimages, using these descriptions to create auxiliary images via text-to-image\ngenerative models, and then comparing the original and generated images.\nFurthermore, to ensure the effectiveness of MMGenBench-Pipeline, we design\nMMGenBench-Test, evaluating LMMs across 13 distinct image patterns, and\nMMGenBench-Domain, focusing on generative image performance. A thorough\nevaluation involving over 50 popular LMMs demonstrates the effectiveness and\nreliability of both the pipeline and benchmark. Our observations indicate that\nnumerous LMMs excelling in existing benchmarks fail to adequately complete the\nbasic tasks related to image understanding and description. This finding\nhighlights the substantial potential for performance improvement in current\nLMMs and suggests avenues for future model optimization. Concurrently,\nMMGenBench-Pipeline can efficiently assess the performance of LMMs across\ndiverse domains using only image inputs.",
      "tldr_zh": "该研究提出 MMGenBench-Pipeline，一种简单且完全自动化的评估框架，用于从文本到图像生成角度评估 Large Multimodal Models (LMMs)，以解决现有基准测试在图像理解领域耗时且评估深度不足的问题。该管道通过从输入图像生成文本描述、利用文本-to-image 生成模型创建辅助图像，然后比较原始和生成图像，来全面评估 LMMs 的图像描述能力。为验证其有效性，论文设计了 MMGenBench-Test（覆盖 13 种图像模式）和 MMGenBench-Domain（聚焦生成性能），并对 50 多个流行 LMMs 进行评估，结果显示许多在现有基准中表现优秀的 LMMs 在基本图像理解和描述任务上失败，揭示了当前模型的改进潜力，并为未来优化提供了方向。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "This project is available at: https://github.com/lerogo/MMGenBench",
      "pdf_url": "http://arxiv.org/pdf/2411.14062v2",
      "published_date": "2024-11-21 12:16:16 UTC",
      "updated_date": "2025-03-08 10:27:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:58:36.936726"
    },
    {
      "arxiv_id": "2411.14054v1",
      "title": "FunctionChat-Bench: Comprehensive Evaluation of Language Models' Generative Capabilities in Korean Tool-use Dialogs",
      "title_zh": "FunctionChat-Bench：针对韩语工具使用对话中语言模型生成能力的全面评估",
      "authors": [
        "Shinbok Lee",
        "Gaeun Seo",
        "Daniel Lee",
        "Byeongil Ko",
        "Sunghee Jung",
        "Myeongcheol Shin"
      ],
      "abstract": "This study investigates language models' generative capabilities in tool-use\ndialogs. We categorize the models' outputs in tool-use dialogs into four\ndistinct types: Tool Call, Answer Completion, Slot Question, and Relevance\nDetection, which serve as aspects for evaluation. We introduce\nFunctionChat-Bench, comprising 700 evaluation items and automated assessment\nprograms. Using this benchmark, we evaluate several language models that\nsupport function calling. Our findings indicate that while language models may\nexhibit high accuracy in single-turn Tool Call scenarios, this does not\nnecessarily translate to superior generative performance in multi-turn\nenvironments. We argue that the capabilities required for function calling\nextend beyond generating tool call messages; they must also effectively\ngenerate conversational messages that engage the user.",
      "tldr_zh": "该研究评估了语言模型在韩语工具使用对话中的生成能力，将模型输出分类为四个方面：Tool Call、Answer Completion、Slot Question 和 Relevance Detection。研究者引入了 FunctionChat-Bench 基准，该基准包含700个评估项目和自动化评估程序，用于测试支持函数调用的语言模型。结果表明，虽然模型在单轮 Tool Call 场景中表现出高准确率，但这并不直接转化为多轮对话环境的优异性能，强调语言模型需具备生成用户互动消息的更全面能力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages",
      "pdf_url": "http://arxiv.org/pdf/2411.14054v1",
      "published_date": "2024-11-21 11:59:13 UTC",
      "updated_date": "2024-11-21 11:59:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:58:48.279576"
    },
    {
      "arxiv_id": "2411.14042v1",
      "title": "Forecasting Future International Events: A Reliable Dataset for Text-Based Event Modeling",
      "title_zh": "翻译失败",
      "authors": [
        "Daehoon Gwak",
        "Junwoo Park",
        "Minho Park",
        "Chaehun Park",
        "Hyunchan Lee",
        "Edward Choi",
        "Jaegul Choo"
      ],
      "abstract": "Predicting future international events from textual information, such as news\narticles, has tremendous potential for applications in global policy, strategic\ndecision-making, and geopolitics. However, existing datasets available for this\ntask are often limited in quality, hindering the progress of related research.\nIn this paper, we introduce WORLDREP (WORLD Relationship and Event Prediction),\na novel dataset designed to address these limitations by leveraging the\nadvanced reasoning capabilities of large-language models (LLMs). Our dataset\nfeatures high-quality scoring labels generated through advanced prompt modeling\nand rigorously validated by domain experts in political science. We showcase\nthe quality and utility of WORLDREP for real-world event prediction tasks,\ndemonstrating its effectiveness through extensive experiments and analysis.\nFurthermore, we publicly release our dataset along with the full automation\nsource code for data collection, labeling, and benchmarking, aiming to support\nand advance research in text-based event prediction.",
      "tldr_zh": "本论文引入了 WORLDREP，这是一个高质量数据集，用于基于文本（如新闻文章）预测未来国际事件，旨在解决现有数据集质量不足的问题。WORLDREP 利用大型语言模型 (LLMs) 的高级推理能力，通过高级提示建模生成评分标签，并由政治科学领域的专家进行严格验证。实验结果展示了该数据集在真实事件预测任务中的有效性，并公开了数据集及其自动化源代码，以推动文本-based事件建模的研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "EMNLP 2024 Findings",
      "pdf_url": "http://arxiv.org/pdf/2411.14042v1",
      "published_date": "2024-11-21 11:44:23 UTC",
      "updated_date": "2024-11-21 11:44:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:59:00.092780"
    },
    {
      "arxiv_id": "2411.14039v1",
      "title": "Uterine Ultrasound Image Captioning Using Deep Learning Techniques",
      "title_zh": "使用深度学习技术的子宫超声图像描述生成",
      "authors": [
        "Abdennour Boulesnane",
        "Boutheina Mokhtari",
        "Oumnia Rana Segueni",
        "Slimane Segueni"
      ],
      "abstract": "Medical imaging has significantly revolutionized medical diagnostics and\ntreatment planning, progressing from early X-ray usage to sophisticated methods\nlike MRIs, CT scans, and ultrasounds. This paper investigates the use of deep\nlearning for medical image captioning, with a particular focus on uterine\nultrasound images. These images are vital in obstetrics and gynecology for\ndiagnosing and monitoring various conditions across different age groups.\nHowever, their interpretation is often challenging due to their complexity and\nvariability. To address this, a deep learning-based medical image captioning\nsystem was developed, integrating Convolutional Neural Networks with a\nBidirectional Gated Recurrent Unit network. This hybrid model processes both\nimage and text features to generate descriptive captions for uterine ultrasound\nimages. Our experimental results demonstrate the effectiveness of this approach\nover baseline methods, with the proposed model achieving superior performance\nin generating accurate and informative captions, as indicated by higher BLEU\nand ROUGE scores. By enhancing the interpretation of uterine ultrasound images,\nour research aims to assist medical professionals in making timely and accurate\ndiagnoses, ultimately contributing to improved patient care.",
      "tldr_zh": "这篇论文探讨了使用深度学习技术对子宫超声图像进行图像描述，以解决其复杂性和变异性带来的解释挑战。研究开发了一个混合模型，结合了Convolutional Neural Networks (CNN) 和Bidirectional Gated Recurrent Unit (BiGRU)网络，来处理图像和文本特征并生成准确的描述性标题。实验结果显示，该模型在BLEU和ROUGE分数上超过了基线方法，提升了诊断准确性，最终有助于医疗专业人士实现及时诊断和改善患者护理。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.14039v1",
      "published_date": "2024-11-21 11:41:42 UTC",
      "updated_date": "2024-11-21 11:41:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:59:11.939577"
    },
    {
      "arxiv_id": "2412.04488v1",
      "title": "Optimizing Student Ability Assessment: A Hierarchy Constraint-Aware Cognitive Diagnosis Framework for Educational Contexts",
      "title_zh": "翻译失败",
      "authors": [
        "Xinjie Sun",
        "Qi Liu",
        "Kai Zhang",
        "Shuanghong Shen",
        "Fei Wang",
        "Yan Zhuang",
        "Zheng Zhang",
        "Weiyin Gong",
        "Shijin Wang",
        "Lina Yang",
        "Xingying Huo"
      ],
      "abstract": "Cognitive diagnosis (CD) aims to reveal students' proficiency in specific\nknowledge concepts. With the increasing adoption of intelligent education\napplications, accurately assessing students' knowledge mastery has become an\nurgent challenge. Although existing cognitive diagnosis frameworks enhance\ndiagnostic accuracy by analyzing students' explicit response records, they\nprimarily focus on individual knowledge state, failing to adequately reflect\nthe relative ability performance of students within hierarchies. To address\nthis, we propose the Hierarchy Constraint-Aware Cognitive Diagnosis Framework\n(HCD), designed to more accurately represent student ability performance within\nreal educational contexts. Specifically, the framework introduces a hierarchy\nmapping layer to identify students' levels. It then employs a hierarchy\nconvolution-enhanced attention layer for in-depth analysis of knowledge\nconcepts performance among students at the same level, uncovering nuanced\ndifferences. A hierarchy inter-sampling attention layer captures performance\ndifferences across hierarchies, offering a comprehensive understanding of the\nrelationships among students' knowledge state. Finally, through personalized\ndiagnostic enhancement, the framework integrates hierarchy constraint\nperception features with existing models, improving the representation of both\nindividual and group characteristics. This approach enables precise inference\nof students' knowledge state. Research shows that this framework not only\nreasonably constrains changes in students' knowledge states to align with real\neducational settings, but also supports the scientific rigor and fairness of\neducational assessments, thereby advancing the field of cognitive diagnosis.",
      "tldr_zh": "这篇论文针对认知诊断（CD）中现有框架忽略学生在知识层级中的相对能力表现问题，提出了一种层次约束感知认知诊断框架（HCD），旨在更准确地评估学生能力。HCD 框架包括层次映射层用于识别学生层级、层次卷积增强注意力层分析同层知识差异，以及层次间采样注意力层捕捉跨层性能关系，从而实现个性化诊断增强。实验结果显示，该框架能合理约束学生知识状态变化，符合实际教育场景，并提升教育评估的科学性和公平性。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "Cognitive Diagnosis",
      "pdf_url": "http://arxiv.org/pdf/2412.04488v1",
      "published_date": "2024-11-21 11:37:36 UTC",
      "updated_date": "2024-11-21 11:37:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:59:24.315088"
    },
    {
      "arxiv_id": "2412.00033v1",
      "title": "Can an AI Agent Safely Run a Government? Existence of Probably Approximately Aligned Policies",
      "title_zh": "翻译失败",
      "authors": [
        "Frédéric Berdoz",
        "Roger Wattenhofer"
      ],
      "abstract": "While autonomous agents often surpass humans in their ability to handle vast\nand complex data, their potential misalignment (i.e., lack of transparency\nregarding their true objective) has thus far hindered their use in critical\napplications such as social decision processes. More importantly, existing\nalignment methods provide no formal guarantees on the safety of such models.\nDrawing from utility and social choice theory, we provide a novel quantitative\ndefinition of alignment in the context of social decision-making. Building on\nthis definition, we introduce probably approximately aligned (i.e.,\nnear-optimal) policies, and we derive a sufficient condition for their\nexistence. Lastly, recognizing the practical difficulty of satisfying this\ncondition, we introduce the relaxed concept of safe (i.e., nondestructive)\npolicies, and we propose a simple yet robust method to safeguard the black-box\npolicy of any autonomous agent, ensuring all its actions are verifiably safe\nfor the society.",
      "tldr_zh": "该研究探讨了AI代理在社会决策中的安全性和对齐问题，指出现有自主代理可能因目标不透明而无法应用于关键领域，并缺乏正式的安全保证。作者基于效用和社会选择理论，提出了一种新的定量对齐定义，并引入了probably approximately aligned policies及其存在的充分条件，以量化代理行为的近似最优性。为应对实际挑战，该研究进一步定义了safe (i.e., nondestructive) policies，并提出了一种简单鲁棒的方法来保护黑箱代理，确保其行为对社会是可验证安全的，从而为AI在政府等场景中的应用提供潜在框架。",
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2412.00033v1",
      "published_date": "2024-11-21 11:36:45 UTC",
      "updated_date": "2024-11-21 11:36:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:59:36.193926"
    },
    {
      "arxiv_id": "2411.14033v2",
      "title": "LLM-based Multi-Agent Systems: Techniques and Business Perspectives",
      "title_zh": "基于LLM的多智能体系统：技术与商业视角",
      "authors": [
        "Yingxuan Yang",
        "Qiuying Peng",
        "Jun Wang",
        "Ying Wen",
        "Weinan Zhang"
      ],
      "abstract": "In the era of (multi-modal) large language models, most operational processes\ncan be reformulated and reproduced using LLM agents. The LLM agents can\nperceive, control, and get feedback from the environment so as to accomplish\nthe given tasks in an autonomous manner. Besides the environment-interaction\nproperty, the LLM agents can call various external tools to ease the task\ncompletion process. The tools can be regarded as a predefined operational\nprocess with private or real-time knowledge that does not exist in the\nparameters of LLMs. As a natural trend of development, the tools for calling\nare becoming autonomous agents, thus the full intelligent system turns out to\nbe a LLM-based Multi-Agent System (LaMAS). Compared to the previous\nsingle-LLM-agent system, LaMAS has the advantages of i) dynamic task\ndecomposition and organic specialization, ii) higher flexibility for system\nchanging, iii) proprietary data preserving for each participating entity, and\niv) feasibility of monetization for each entity. This paper discusses the\ntechnical and business landscapes of LaMAS. To support the ecosystem of LaMAS,\nwe provide a preliminary version of such LaMAS protocol considering technical\nrequirements, data privacy, and business incentives. As such, LaMAS would be a\npractical solution to achieve artificial collective intelligence in the near\nfuture.",
      "tldr_zh": "该论文探讨了基于大型语言模型(LLM)的多代理系统(LaMAS)，强调这些系统能通过代理感知环境、调用外部工具并自主完成任务，从而实现动态任务分解和有机专业化。相比单一LLM代理，LaMAS的优势包括更高的系统灵活性、私有数据保护以及每个实体的货币化潜力。论文分析了LaMAS的技术和商业景观，并提出一个初步协议，考虑数据隐私和商业激励，以推动人工集体智能的实际应用。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.14033v2",
      "published_date": "2024-11-21 11:36:29 UTC",
      "updated_date": "2024-12-28 12:48:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T02:59:48.271688"
    },
    {
      "arxiv_id": "2411.14014v2",
      "title": "Trajectory Representation Learning on Road Networks and Grids with Spatio-Temporal Dynamics",
      "title_zh": "翻译失败",
      "authors": [
        "Stefan Schestakov",
        "Simon Gottschalk"
      ],
      "abstract": "Trajectory representation learning is a fundamental task for applications in\nfields including smart city, and urban planning, as it facilitates the\nutilization of trajectory data (e.g., vehicle movements) for various downstream\napplications, such as trajectory similarity computation or travel time\nestimation. This is achieved by learning low-dimensional representations from\nhigh-dimensional and raw trajectory data. However, existing methods for\ntrajectory representation learning either rely on grid-based or road-based\nrepresentations, which are inherently different and thus, could lose\ninformation contained in the other modality. Moreover, these methods overlook\nthe dynamic nature of urban traffic, relying on static road network features\nrather than time varying traffic patterns. In this paper, we propose TIGR, a\nnovel model designed to integrate grid and road network modalities while\nincorporating spatio-temporal dynamics to learn rich, general-purpose\nrepresentations of trajectories. We evaluate TIGR on two realworld datasets and\ndemonstrate the effectiveness of combining both modalities by substantially\noutperforming state-of-the-art methods, i.e., up to 43.22% for trajectory\nsimilarity, up to 16.65% for travel time estimation, and up to 10.16% for\ndestination prediction.",
      "tldr_zh": "该论文探讨了轨迹表示学习（Trajectory Representation Learning）在智能城市和城市规划中的应用，旨在从高维轨迹数据（如车辆运动）中学习低维表示，以支持下游任务如轨迹相似性计算和旅行时间估计。现有方法要么依赖网格（grid-based）或道路网络（road-based）表示，导致信息丢失，且忽略了城市交通的时空动态（spatio-temporal dynamics）。为此，作者提出了一种新模型 TIGR，它整合网格和道路网络模态，并纳入时空动态特征，以生成更丰富的轨迹表示。在两个真实数据集上的实验中，TIGR 显著优于现有方法，在轨迹相似性上提升至 43.22%、旅行时间估计上提升至 16.65%、以及目的地预测上提升至 10.16%。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.14014v2",
      "published_date": "2024-11-21 10:56:02 UTC",
      "updated_date": "2025-01-02 10:59:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T03:00:01.204773"
    },
    {
      "arxiv_id": "2411.14012v2",
      "title": "Logic Augmented Generation",
      "title_zh": "逻辑增强生成",
      "authors": [
        "Aldo Gangemi",
        "Andrea Giovanni Nuzzolese"
      ],
      "abstract": "Semantic Knowledge Graphs (SKG) face challenges with scalability,\nflexibility, contextual understanding, and handling unstructured or ambiguous\ninformation. However, they offer formal and structured knowledge enabling\nhighly interpretable and reliable results by means of reasoning and querying.\nLarge Language Models (LLMs) overcome those limitations making them suitable in\nopen-ended tasks and unstructured environments. Nevertheless, LLMs are neither\ninterpretable nor reliable. To solve the dichotomy between LLMs and SKGs we\nenvision Logic Augmented Generation (LAG) that combines the benefits of the two\nworlds. LAG uses LLMs as Reactive Continuous Knowledge Graphs that can generate\npotentially infinite relations and tacit knowledge on-demand. SKGs are key for\ninjecting a discrete heuristic dimension with clear logical and factual\nboundaries. We exemplify LAG in two tasks of collective intelligence, i.e.,\nmedical diagnostics and climate projections. Understanding the properties and\nlimitations of LAG, which are still mostly unknown, is of utmost importance for\nenabling a variety of tasks involving tacit knowledge in order to provide\ninterpretable and effective results.",
      "tldr_zh": "这篇论文探讨了语义知识图 (SKG) 和大型语言模型 (LLMs) 的优缺点：SKG 提供结构化、可解释的知识，但面临可扩展性和处理非结构化信息的问题，而 LLMs 适合开放任务但缺乏可解释性和可靠性。论文提出 Logic Augmented Generation (LAG) 框架，将 LLMs 作为 Reactive Continuous Knowledge Graphs 生成无限关系和隐性知识，并利用 SKG 注入离散的逻辑边界，以实现可解释且可靠的结果。通过医疗诊断和气候预测等集体智能任务的示例，LAG 展示了其在处理隐性知识方面的潜力，并强调了理解其属性和限制的重要性。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.14012v2",
      "published_date": "2024-11-21 10:54:35 UTC",
      "updated_date": "2025-01-14 15:58:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T03:00:49.672541"
    },
    {
      "arxiv_id": "2411.13997v1",
      "title": "Mirror Target YOLO: An Improved YOLOv8 Method with Indirect Vision for Heritage Buildings Fire Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Jian Liang",
        "JunSheng Cheng"
      ],
      "abstract": "Fires can cause severe damage to heritage buildings, making timely fire\ndetection essential. Traditional dense cabling and drilling can harm these\nstructures, so reducing the number of cameras to minimize such impact is\nchallenging. Additionally, avoiding false alarms due to noise sensitivity and\npreserving the expertise of managers in fire-prone areas is crucial. To address\nthese needs, we propose a fire detection method based on indirect vision,\ncalled Mirror Target YOLO (MITA-YOLO). MITA-YOLO integrates indirect vision\ndeployment and an enhanced detection module. It uses mirror angles to achieve\nindirect views, solving issues with limited visibility in irregular spaces and\naligning each indirect view with the target monitoring area. The Target-Mask\nmodule is designed to automatically identify and isolate the indirect vision\nareas in each image, filtering out non-target areas. This enables the model to\ninherit managers' expertise in assessing fire-risk zones, improving focus and\nresistance to interference in fire detection.In our experiments, we created an\n800-image fire dataset with indirect vision. Results show that MITA-YOLO\nsignificantly reduces camera requirements while achieving superior detection\nperformance compared to other mainstream models.",
      "tldr_zh": "本文提出 Mirror Target YOLO (MITA-YOLO)，一种基于 YOLOv8 的改进火检测方法，针对遗产建筑火灾检测问题，通过间接视觉技术减少摄像头数量并避免对建筑的损害。方法整合镜子角度实现间接视图，以及 Target-Mask 模块自动识别和隔离目标区域，从而提升检测的焦点、抗干扰能力和对管理专家知识的继承。实验结果显示，在自制的 800 张间接视觉火图像数据集上，MITA-YOLO 比主流模型表现出色，显著降低了设备需求并提高了检测性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.13997v1",
      "published_date": "2024-11-21 10:23:00 UTC",
      "updated_date": "2024-11-21 10:23:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T03:00:25.341346"
    },
    {
      "arxiv_id": "2411.14507v1",
      "title": "FuseGPT: Learnable Layers Fusion of Generative Pre-trained Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Zehua Pei",
        "Hui-Ling Zhen",
        "Xianzhi Yu",
        "Sinno Jialin Pan",
        "Mingxuan Yuan",
        "Bei Yu"
      ],
      "abstract": "Generative Pre-trained Transformers (GPTs) have demonstrated remarkable\nperformance across diverse domains through the extensive scaling of model\nparameters. Recent works observe the redundancy across the transformer blocks\nand develop compression methods by structured pruning of the unimportant\nblocks. However, such straightforward elimination will always provide\nirreversible performance degradation. In this paper, we propose FuseGPT, a\nnovel methodology to recycle the pruned transformer blocks to further recover\nthe model performance. Firstly we introduce a new importance detection metric,\nMacro Influence (MI), to detect the long-term influence of each transformer\nblock by calculating their loss of information after removal. Then we propose\ngroup-level layers fusion, which adopts the parameters in layers of the\nunimportant blocks and injects them into the corresponding layers inside the\nneighboring blocks. The fusion is not one-off but through iterative parameter\nupdates by lightweight group-level fine-tuning. Specifically, these injected\nparameters are frozen but weighted with learnable rank decomposition matrices\nto reduce the overhead during fine-tuning. Our approach not only works well on\nlarge language models but also on large multimodal models. The experiments have\nshown that, by using modest amounts of data, FuseGPT can outperform previous\nworks in both perplexity and zero-shot task performance.",
      "tldr_zh": "该研究提出 FuseGPT，一种创新方法，用于优化 Generative Pre-trained Transformers (GPTs) 模型，通过回收被修剪的 Transformer 块来恢复性能。具体而言，FuseGPT 引入 Macro Influence (MI) 指标来评估每个块的长期信息损失，并采用 group-level layers fusion 将不重要块的参数注入相邻块中，同时通过轻量级 fine-tuning 和 learnable rank decomposition matrices 加权更新以降低开销。实验结果显示，该方法适用于大型语言模型和多模态模型，仅需少量数据即可在 perplexity 和 zero-shot 任务性能上超越现有工作。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.14507v1",
      "published_date": "2024-11-21 09:49:28 UTC",
      "updated_date": "2024-11-21 09:49:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T03:00:36.454718"
    },
    {
      "arxiv_id": "2411.13982v2",
      "title": "Safety Without Semantic Disruptions: Editing-free Safe Image Generation via Context-preserving Dual Latent Reconstruction",
      "title_zh": "翻译失败",
      "authors": [
        "Jordan Vice",
        "Naveed Akhtar",
        "Mubarak Shah",
        "Richard Hartley",
        "Ajmal Mian"
      ],
      "abstract": "Training multimodal generative models on large, uncurated datasets can result\nin users being exposed to harmful, unsafe and controversial or\nculturally-inappropriate outputs. While model editing has been proposed to\nremove or filter undesirable concepts in embedding and latent spaces, it can\ninadvertently damage learned manifolds, distorting concepts in close semantic\nproximity. We identify limitations in current model editing techniques, showing\nthat even benign, proximal concepts may become misaligned. To address the need\nfor safe content generation, we leverage safe embeddings and a modified\ndiffusion process with tunable weighted summation in the latent space to\ngenerate safer images. Our method preserves global context without compromising\nthe structural integrity of the learned manifolds. We achieve state-of-the-art\nresults on safe image generation benchmarks and offer intuitive control over\nthe level of model safety. We identify trade-offs between safety and\ncensorship, which presents a necessary perspective in the development of\nethical AI models. We will release our code.\n  Keywords: Text-to-Image Models, Generative AI, Safety, Reliability, Model\nEditing",
      "tldr_zh": "本文提出了一种无需模型编辑的图像生成方法，名为“Safety Without Semantic Disruptions”，通过上下文保留的双潜空间重构（Context-preserving Dual Latent Reconstruction）来避免语义失真问题，确保生成图像的安全性。该方法利用安全的嵌入和修改的扩散过程，在潜在空间中进行可调权重的求和，保留全局上下文和学习流形的结构完整性，从而防止语义相邻概念的误-align。实验结果显示，该方法在Text-to-Image Models的安全生成基准上达到最先进水平，提供对安全程度的直观控制，并探讨了安全与审查之间的权衡，为道德AI开发提供了重要视角。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "This research is supported by the NISDRG project #20100007, funded by\n  the Australian Government",
      "pdf_url": "http://arxiv.org/pdf/2411.13982v2",
      "published_date": "2024-11-21 09:47:13 UTC",
      "updated_date": "2025-03-05 14:45:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T03:00:49.624798"
    },
    {
      "arxiv_id": "2411.13981v1",
      "title": "On the Fairness, Diversity and Reliability of Text-to-Image Generative Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jordan Vice",
        "Naveed Akhtar",
        "Richard Hartley",
        "Ajmal Mian"
      ],
      "abstract": "The widespread availability of multimodal generative models has sparked\ncritical discussions on their fairness, reliability, and potential for misuse.\nWhile text-to-image models can produce high-fidelity, user-guided images, they\nalso exhibit unpredictable behavior and vulnerabilities, which can be exploited\nto manipulate class or concept representations. To address this, we propose an\nevaluation framework designed to assess model reliability through their\nresponses to globally- and locally-applied `semantic' perturbations in the\nembedding space, pinpointing inputs that trigger unreliable behavior. Our\napproach offers deeper insights into two essential aspects: (i) generative\ndiversity, evaluating the breadth of visual representations for learned\nconcepts, and (ii) generative fairness, examining how removing concepts from\ninput prompts affects semantic guidance. Beyond these evaluations, our method\nlays the groundwork for detecting unreliable, bias-injected models and\nretrieval of bias provenance. We will release our code.\n  Keywords: Fairness, Reliability, AI Ethics, Bias, Text-to-Image Models",
      "tldr_zh": "该研究探讨了文本到图像生成模型（Text-to-Image Generative Models）的公平性（Fairness）、多样性（Diversity）和可靠性（Reliability），并强调了这些模型可能存在的不可预测行为和偏见风险。作者提出一个评估框架，通过在嵌入空间中应用全局和局部“语义”扰动（semantic perturbations）来识别触发不可靠行为的输入，并评估生成多样性（generative diversity）和生成公平性（generative fairness）。该方法不仅能检测偏见注入模型并追踪偏见来源，还为AI伦理（AI Ethics）和模型改进奠定基础，作者计划发布相关代码。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "This research is supported by the NISDRG project #20100007, funded by\n  the Australian Government",
      "pdf_url": "http://arxiv.org/pdf/2411.13981v1",
      "published_date": "2024-11-21 09:46:55 UTC",
      "updated_date": "2024-11-21 09:46:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T03:01:00.010582"
    },
    {
      "arxiv_id": "2411.13979v1",
      "title": "FedRAV: Hierarchically Federated Region-Learning for Traffic Object Classification of Autonomous Vehicles",
      "title_zh": "FedRAV：用于自动驾驶车辆交通物体分类的层次化联邦区域学习",
      "authors": [
        "Yijun Zhai",
        "Pengzhan Zhou",
        "Yuepeng He",
        "Fang Qu",
        "Zhida Qin",
        "Xianlong Jiao",
        "Guiyan Liu",
        "Songtao Guo"
      ],
      "abstract": "The emerging federated learning enables distributed autonomous vehicles to\ntrain equipped deep learning models collaboratively without exposing their raw\ndata, providing great potential for utilizing explosively growing autonomous\ndriving data. However, considering the complicated traffic environments and\ndriving scenarios, deploying federated learning for autonomous vehicles is\ninevitably challenged by non-independent and identically distributed (Non-IID)\ndata of vehicles, which may lead to failed convergence and low training\naccuracy. In this paper, we propose a novel hierarchically Federated\nRegion-learning framework of Autonomous Vehicles (FedRAV), a two-stage\nframework, which adaptively divides a large area containing vehicles into\nsub-regions based on the defined region-wise distance, and achieves\npersonalized vehicular models and regional models. This approach ensures that\nthe personalized vehicular model adopts the beneficial models while discarding\nthe unprofitable ones. We validate our FedRAV framework against existing\nfederated learning algorithms on three real-world autonomous driving datasets\nin various heterogeneous settings. The experiment results demonstrate that our\nframework outperforms those known algorithms, and improves the accuracy by at\nleast 3.69%. The source code of FedRAV is available at:\nhttps://github.com/yjzhai-cs/FedRAV.",
      "tldr_zh": "该研究提出FedRAV框架，一种层次化联邦学习方法，用于解决自动驾驶车辆在交通物体分类任务中因Non-IID数据导致的训练收敛失败和准确率低等问题。FedRAV采用两阶段策略，首先基于区域距离将大区域划分为子区域，然后训练个性化的车辆模型和区域模型，以选择有益模型并排除无益部分。在三个真实世界自动驾驶数据集上的实验表明，该框架比现有算法至少提高3.69%的准确率，为分布式车辆协作学习提供了高效解决方案。",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "8 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.13979v1",
      "published_date": "2024-11-21 09:45:55 UTC",
      "updated_date": "2024-11-21 09:45:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T03:01:12.150481"
    },
    {
      "arxiv_id": "2411.13951v4",
      "title": "PATH: A Discrete-sequence Dataset for Evaluating Online Unsupervised Anomaly Detection Approaches for Multivariate Time Series",
      "title_zh": "翻译失败",
      "authors": [
        "Lucas Correia",
        "Jan-Christoph Goos",
        "Thomas Bäck",
        "Anna V. Kononova"
      ],
      "abstract": "Benchmarking anomaly detection approaches for multivariate time series is a\nchallenging task due to a lack of high-quality datasets. Current publicly\navailable datasets are too small, not diverse and feature trivial anomalies,\nwhich hinders measurable progress in this research area. We propose a solution:\na diverse, extensive, and non-trivial dataset generated via state-of-the-art\nsimulation tools that reflects realistic behaviour of an automotive powertrain,\nincluding its multivariate, dynamic and variable-state properties.\nAdditionally, our dataset represents a discrete-sequence problem, which remains\nunaddressed by previously-proposed solutions in literature. To cater for both\nunsupervised and semi-supervised anomaly detection settings, as well as time\nseries generation and forecasting, we make different versions of the dataset\navailable, where training and test subsets are offered in contaminated and\nclean versions, depending on the task. We also provide baseline results from a\nselection of approaches based on deterministic and variational autoencoders, as\nwell as a non-parametric approach. As expected, the baseline experimentation\nshows that the approaches trained on the semi-supervised version of the dataset\noutperform their unsupervised counterparts, highlighting a need for approaches\nmore robust to contaminated training data. Furthermore, results show that the\nthreshold used can have a large influence on detection performance, hence more\nwork needs to be invested in methods to find a suitable threshold without the\nneed for labelled data.",
      "tldr_zh": "本研究针对多变量时间序列（multivariate time series）的在线无监督异常检测（unsupervised anomaly detection）基准数据集问题，提出一个名为PATH的离散序列（discrete-sequence）数据集，通过先进的模拟工具生成，模拟汽车动力系统的真实行为，包括多变量、动态和可变状态特性，以解决现有数据集规模小、缺乏多样性和异常过于简单的问题。数据集提供不同版本，支持无监督和半监督设置、时间序列生成和预测，训练和测试子集包括污染（contaminated）和干净（clean）选项。基线实验使用确定性自编码器（deterministic autoencoders）、变分自编码器（variational autoencoders）和非参数方法，结果显示半监督方法优于无监督方法，并强调需要开发更robust to contaminated training data的算法，以及改进阈值选择机制以减少对标签数据的依赖。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "Submitted to the Big Data Research journal",
      "pdf_url": "http://arxiv.org/pdf/2411.13951v4",
      "published_date": "2024-11-21 09:03:12 UTC",
      "updated_date": "2025-04-08 15:26:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T03:01:25.581574"
    },
    {
      "arxiv_id": "2411.13949v1",
      "title": "Separable Mixture of Low-Rank Adaptation for Continual Visual Instruction Tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Ziqi Wang",
        "Chang Che",
        "Qi Wang",
        "Yangyang Li",
        "Zenglin Shi",
        "Meng Wang"
      ],
      "abstract": "Visual instruction tuning (VIT) enables multimodal large language models\n(MLLMs) to effectively handle a wide range of vision tasks by framing them as\nlanguage-based instructions. Building on this, continual visual instruction\ntuning (CVIT) extends the capability of MLLMs to incrementally learn new tasks,\naccommodating evolving functionalities. While prior work has advanced CVIT\nthrough the development of new benchmarks and approaches to mitigate\ncatastrophic forgetting, these efforts largely follow traditional continual\nlearning paradigms, neglecting the unique challenges specific to CVIT. We\nidentify a dual form of catastrophic forgetting in CVIT, where MLLMs not only\nforget previously learned visual understanding but also experience a decline in\ninstruction following abilities as they acquire new tasks. To address this, we\nintroduce the Separable Mixture of Low-Rank Adaptation (SMoLoRA) framework,\nwhich employs separable routing through two distinct modules - one for visual\nunderstanding and another for instruction following. This dual-routing design\nenables specialized adaptation in both domains, preventing forgetting while\nimproving performance. Furthermore, we propose a novel CVIT benchmark that goes\nbeyond existing benchmarks by additionally evaluating a model's ability to\ngeneralize to unseen tasks and handle diverse instructions across various\ntasks. Extensive experiments demonstrate that SMoLoRA outperforms existing\nmethods in mitigating dual forgetting, improving generalization to unseen\ntasks, and ensuring robustness in following diverse instructions.",
      "tldr_zh": "本研究针对持续视觉指令微调 (CVIT) 中的双重灾难性遗忘问题，即多模态大语言模型 (MLLMs) 不仅遗忘先前视觉理解，还会降低指令遵循能力，提出 Separable Mixture of Low-Rank Adaptation (SMoLoRA) 框架。该框架通过可分离路由设计，分别使用两个模块处理视觉理解和指令遵循，实现领域专用适应，从而缓解遗忘并提升性能。同时，论文引入一个新颖的 CVIT 基准，评估模型对未见任务的泛化能力和处理多样指令的鲁棒性。实验结果表明，SMoLoRA 在减轻双重遗忘、改善泛化和指令遵循方面优于现有方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.13949v1",
      "published_date": "2024-11-21 09:00:15 UTC",
      "updated_date": "2024-11-21 09:00:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T03:01:37.116712"
    },
    {
      "arxiv_id": "2411.13941v1",
      "title": "LLMs as Continuous Learners: Improving the Reproduction of Defective Code in Software Issues",
      "title_zh": "翻译失败",
      "authors": [
        "Yalan Lin",
        "Yingwei Ma",
        "Rongyu Cao",
        "Binhua Li",
        "Fei Huang",
        "Xiaodong Gu",
        "Yongbin Li"
      ],
      "abstract": "Reproducing buggy code is the first and crucially important step in issue\nresolving, as it aids in identifying the underlying problems and validating\nthat generated patches resolve the problem. While numerous approaches have been\nproposed for this task, they primarily address common, widespread errors and\nstruggle to adapt to unique, evolving errors specific to individual code\nrepositories. To fill this gap, we propose EvoCoder, a multi-agent continuous\nlearning framework for issue code reproduction. EvoCoder adopts a reflection\nmechanism that allows the LLM to continuously learn from previously resolved\nproblems and dynamically refine its strategies to new emerging challenges. To\nprevent experience bloating, EvoCoder introduces a novel hierarchical\nexperience pool that enables the model to adaptively update common and\nrepo-specific experiences. Our experimental results show a 20\\% improvement in\nissue reproduction rates over existing SOTA methods. Furthermore, integrating\nour reproduction mechanism significantly boosts the overall accuracy of the\nexisting issue-resolving pipeline.",
      "tldr_zh": "该研究针对软件问题中缺陷代码再现的挑战，提出EvoCoder，一个多智能体连续学习框架，以帮助LLMs适应独特且不断演变的错误。EvoCoder引入反射机制，让模型从之前解决的问题中学习，并动态优化策略，同时采用层次化经验池来适应性地更新通用和仓库特定经验，防止经验膨胀。实验结果显示，EvoCoder比现有SOTA方法提高了20%的再现率，并显著提升了整体问题解决管道的准确性。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.13941v1",
      "published_date": "2024-11-21 08:49:23 UTC",
      "updated_date": "2024-11-21 08:49:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T03:01:48.370015"
    },
    {
      "arxiv_id": "2411.13934v1",
      "title": "Learning to Cooperate with Humans using Generative Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Yancheng Liang",
        "Daphne Chen",
        "Abhishek Gupta",
        "Simon S. Du",
        "Natasha Jaques"
      ],
      "abstract": "Training agents that can coordinate zero-shot with humans is a key mission in\nmulti-agent reinforcement learning (MARL). Current algorithms focus on training\nsimulated human partner policies which are then used to train a Cooperator\nagent. The simulated human is produced either through behavior cloning over a\ndataset of human cooperation behavior, or by using MARL to create a population\nof simulated agents. However, these approaches often struggle to produce a\nCooperator that can coordinate well with real humans, since the simulated\nhumans fail to cover the diverse strategies and styles employed by people in\nthe real world. We show \\emph{learning a generative model of human partners}\ncan effectively address this issue. Our model learns a latent variable\nrepresentation of the human that can be regarded as encoding the human's unique\nstrategy, intention, experience, or style. This generative model can be\nflexibly trained from any (human or neural policy) agent interaction data. By\nsampling from the latent space, we can use the generative model to produce\ndifferent partners to train Cooperator agents. We evaluate our method --\n\\textbf{G}enerative \\textbf{A}gent \\textbf{M}odeling for \\textbf{M}ulti-agent\n\\textbf{A}daptation (GAMMA) -- on Overcooked, a challenging cooperative cooking\ngame that has become a standard benchmark for zero-shot coordination. We\nconduct an evaluation with real human teammates, and the results show that\nGAMMA consistently improves performance, whether the generative model is\ntrained on simulated populations or human datasets. Further, we propose a\nmethod for posterior sampling from the generative model that is biased towards\nthe human data, enabling us to efficiently improve performance with only a\nsmall amount of expensive human interaction data.",
      "tldr_zh": "本研究旨在训练代理在多智能体强化学习(MARL)中实现与人类的零样本协调(zero-shot coordination)，通过学习一个生成模型(generative model)来模拟人类伙伴策略，从而解决传统方法无法覆盖真实人类多样性的问题。该生成模型学习人类策略的潜在变量表示(latent variable representation)，编码人类的独特策略、意图、经验或风格，并可从任何代理互动数据中训练。研究提出GAMMA框架(Generative Agent Modeling for Multi-agent Adaptation)，通过从潜在空间采样生成多样伙伴来训练Cooperator代理，并在Overcooked合作游戏上实验验证，与真实人类队友合作时，GAMMA显著提升了性能，即使仅使用少量人类数据也能高效优化。实验结果显示，GAMMA无论基于模拟数据还是人类数据集训练，都能改善协调效果，为真实世界多智能体合作提供新途径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.13934v1",
      "published_date": "2024-11-21 08:36:17 UTC",
      "updated_date": "2024-11-21 08:36:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T03:02:00.905815"
    },
    {
      "arxiv_id": "2411.14503v2",
      "title": "Planning-Driven Programming: A Large Language Model Programming Workflow",
      "title_zh": "翻译失败",
      "authors": [
        "Chao Lei",
        "Yanchuan Chang",
        "Nir Lipovetzky",
        "Krista A. Ehinger"
      ],
      "abstract": "The strong performance of large language models (LLMs) raises extensive\ndiscussion on their application to code generation. Recent research suggests\ncontinuous program refinements through visible tests to improve code generation\naccuracy in LLMs. However, these methods suffer from LLMs' inefficiency and\nlimited reasoning capacity. In this work, we propose an LLM programming\nworkflow (LPW) designed to improve both initial code generation and subsequent\nrefinements within a structured two-phase workflow. Specifically, the solution\ngeneration phase formulates a solution plan, which is then verified through\nvisible tests to specify the intended natural language solution. Subsequently,\nthe code implementation phase drafts an initial code according to the solution\nplan and its verification. If the generated code fails the visible tests, the\nplan verification serves as the intended solution to consistently inform the\nrefinement process for correcting bugs. Compared to state-of-the-art methods\nacross various existing LLMs, LPW significantly improves the Pass@1 accuracy by\nup to 16.4% on well-established text-to-code generation benchmarks. LPW also\nsets new state-of-the-art Pass@1 accuracy, achieving 98.2% on HumanEval, 84.8%\non MBPP, 59.3% on LiveCode, 62.6% on APPS, and 34.7% on CodeContest, using\nGPT-4o as the backbone.",
      "tldr_zh": "该研究提出了一种规划驱动的编程工作流（LPW），旨在提升大型语言模型（LLMs）在代码生成的初始生成和后续优化效率，解决现有方法中LLMs的低效性和有限推理能力问题。LPW分为两个阶段：首先，在解决方案生成阶段制定解决方案计划并通过可见测试验证自然语言描述；其次，在代码实现阶段根据验证后的计划起草代码，并使用计划验证指导错误修正。实验结果显示，LPW在使用GPT-4o作为基础模型时，在多个基准上显著提升Pass@1准确率，包括HumanEval达到98.2%、MBPP达到84.8%、LiveCode达到59.3%、APPS达到62.6%和CodeContest达到34.7%。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.14503v2",
      "published_date": "2024-11-21 08:31:06 UTC",
      "updated_date": "2025-01-09 08:55:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T03:02:12.615912"
    },
    {
      "arxiv_id": "2411.13932v1",
      "title": "XAgents: A Framework for Interpretable Rule-Based Multi-Agents Cooperation",
      "title_zh": "XAgents：一种可解释的基于规则的多智能体合作框架",
      "authors": [
        "Hailong Yang",
        "Mingxian Gu",
        "Renhuo Zhao",
        "Fuping Hu",
        "Zhaohong Deng",
        "Yitang Chen"
      ],
      "abstract": "Extracting implicit knowledge and logical reasoning abilities from large\nlanguage models (LLMs) has consistently been a significant challenge. The\nadvancement of multi-agent systems has further en-hanced the capabilities of\nLLMs. Inspired by the structure of multi-polar neurons (MNs), we propose the\nXAgents framework, an in-terpretable multi-agent cooperative framework based on\nthe IF-THEN rule-based system. The IF-Parts of the rules are responsible for\nlogical reasoning and domain membership calculation, while the THEN-Parts are\ncomprised of domain expert agents that generate domain-specific contents.\nFollowing the calculation of the member-ship, XAgetns transmits the task to the\ndisparate domain rules, which subsequently generate the various responses.\nThese re-sponses are analogous to the answers provided by different experts to\nthe same question. The final response is reached at by eliminat-ing the\nhallucinations and erroneous knowledge of the LLM through membership\ncomputation and semantic adversarial genera-tion of the various domain rules.\nThe incorporation of rule-based interpretability serves to bolster user\nconfidence in the XAgents framework. We evaluate the efficacy of XAgents\nthrough a com-parative analysis with the latest AutoAgents, in which XAgents\ndemonstrated superior performance across three distinct datasets. We perform\npost-hoc interpretable studies with SHAP algorithm and case studies, proving\nthe interpretability of XAgent in terms of input-output feature correlation and\nrule-based semantics.",
      "tldr_zh": "该研究提出 XAgents 框架，一种基于 IF-THEN 规则系统的可解释多智能体合作框架，受多极神经元（MNs）结构启发，用于从大型语言模型（LLMs）中提取隐性知识和逻辑推理能力。框架的 IF-Parts 负责逻辑推理和领域成员计算，而 THEN-Parts 则由领域专家智能体生成特定内容，通过成员计算和语义对抗生成机制消除 LLMs 的幻觉和错误知识，最终合成可靠响应。实验对比显示，XAgents 在三个数据集上优于 AutoAgents，并在可解释性方面通过 SHAP 算法和案例研究验证了输入输出特征相关性和规则语义。",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.13932v1",
      "published_date": "2024-11-21 08:28:27 UTC",
      "updated_date": "2024-11-21 08:28:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T03:02:25.579613"
    },
    {
      "arxiv_id": "2411.14502v1",
      "title": "Global Challenge for Safe and Secure LLMs Track 1",
      "title_zh": "全球安全可靠大型语言模型挑战 Track 1",
      "authors": [
        "Xiaojun Jia",
        "Yihao Huang",
        "Yang Liu",
        "Peng Yan Tan",
        "Weng Kuan Yau",
        "Mun-Thye Mak",
        "Xin Ming Sim",
        "Wee Siong Ng",
        "See Kiong Ng",
        "Hanqing Liu",
        "Lifeng Zhou",
        "Huanqian Yan",
        "Xiaobing Sun",
        "Wei Liu",
        "Long Wang",
        "Yiming Qian",
        "Yong Liu",
        "Junxiao Yang",
        "Zhexin Zhang",
        "Leqi Lei",
        "Renmiao Chen",
        "Yida Lu",
        "Shiyao Cui",
        "Zizhou Wang",
        "Shaohua Li",
        "Yan Wang",
        "Rick Siow Mong Goh",
        "Liangli Zhen",
        "Yingjie Zhang",
        "Zhe Zhao"
      ],
      "abstract": "This paper introduces the Global Challenge for Safe and Secure Large Language\nModels (LLMs), a pioneering initiative organized by AI Singapore (AISG) and the\nCyberSG R&D Programme Office (CRPO) to foster the development of advanced\ndefense mechanisms against automated jailbreaking attacks. With the increasing\nintegration of LLMs in critical sectors such as healthcare, finance, and public\nadministration, ensuring these models are resilient to adversarial attacks is\nvital for preventing misuse and upholding ethical standards. This competition\nfocused on two distinct tracks designed to evaluate and enhance the robustness\nof LLM security frameworks. Track 1 tasked participants with developing\nautomated methods to probe LLM vulnerabilities by eliciting undesirable\nresponses, effectively testing the limits of existing safety protocols within\nLLMs. Participants were challenged to devise techniques that could bypass\ncontent safeguards across a diverse array of scenarios, from offensive language\nto misinformation and illegal activities. Through this process, Track 1 aimed\nto deepen the understanding of LLM vulnerabilities and provide insights for\ncreating more resilient models.",
      "tldr_zh": "本论文介绍了由 AI Singapore (AISG) 和 CyberSG R&D Programme Office (CRPO) 组织的“Global Challenge for Safe and Secure LLMs”，这是一个旨在提升大型语言模型(LLMs) 安全性的全球竞赛，重点开发防御自动越狱攻击的机制，以防止 LLMs 在医疗、金融和公共管理等领域被滥用。Track 1 要求参与者创建自动化方法来探测 LLMs 的漏洞，通过诱导不期望的响应（如攻击性语言、误信息或非法活动）来测试现有安全协议的极限。该竞赛通过加深对 LLMs 弱点的理解，提供宝贵见解，帮助构建更坚固的模型并维护伦理标准。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.14502v1",
      "published_date": "2024-11-21 08:20:31 UTC",
      "updated_date": "2024-11-21 08:20:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T03:02:36.217724"
    },
    {
      "arxiv_id": "2411.13907v1",
      "title": "Split Federated Learning Over Heterogeneous Edge Devices: Algorithm and Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Yunrui Sun",
        "Gang Hu",
        "Yinglei Teng",
        "Dunbo Cai"
      ],
      "abstract": "Split Learning (SL) is a promising collaborative machine learning approach,\nenabling resource-constrained devices to train models without sharing raw data,\nwhile reducing computational load and preserving privacy simultaneously.\nHowever, current SL algorithms face limitations in training efficiency and\nsuffer from prolonged latency, particularly in sequential settings, where the\nslowest device can bottleneck the entire process due to heterogeneous resources\nand frequent data exchanges between clients and servers. To address these\nchallenges, we propose the Heterogeneous Split Federated Learning (HSFL)\nframework, which allows resource-constrained clients to train their\npersonalized client-side models in parallel, utilizing different cut layers.\nAiming to mitigate the impact of heterogeneous environments and accelerate the\ntraining process, we formulate a latency minimization problem that optimizes\ncomputational and transmission resources jointly. Additionally, we design a\nresource allocation algorithm that combines the Sample Average Approximation\n(SAA), Genetic Algorithm (GA), Lagrangian relaxation and Branch and Bound\n(B\\&B) methods to efficiently solve this problem. Simulation results\ndemonstrate that HSFL outperforms other frameworks in terms of both convergence\nrate and model accuracy on heterogeneous devices with non-iid data, while the\noptimization algorithm is better than other baseline methods in reducing\nlatency.",
      "tldr_zh": "该论文提出 Heterogeneous Split Federated Learning (HSFL) 框架，以解决 Split Learning (SL) 在异构边缘设备上的训练效率和延迟问题，特别是避免 slowest device 成为瓶颈。HSFL 允许资源受限客户端并行训练个性化模型，使用不同的 cut layers，并通过联合优化计算和传输资源来最小化延迟问题。研究设计了一种资源分配算法，结合 Sample Average Approximation (SAA)、Genetic Algorithm (GA)、Lagrangian relaxation 和 Branch and Bound (B&B) 方法来高效求解该优化问题。模拟结果表明，HSFL 在非-iid 数据下的收敛率和模型准确性上优于其他框架，且该算法显著降低了训练延迟。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.13907v1",
      "published_date": "2024-11-21 07:46:01 UTC",
      "updated_date": "2024-11-21 07:46:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T03:02:49.647923"
    },
    {
      "arxiv_id": "2411.13903v1",
      "title": "AmpliNetECG12: A lightweight SoftMax-based relativistic amplitude amplification architecture for 12 lead ECG classification",
      "title_zh": "翻译失败",
      "authors": [
        "Shreya Srivastava"
      ],
      "abstract": "The urgent need to promptly detect cardiac disorders from 12-lead\nElectrocardiograms using limited computations is motivated by the heart's fast\nand complex electrical activity and restricted computational power of portable\ndevices. Timely and precise diagnoses are crucial since delays might\nsignificantly impact patient health outcomes. This research presents a novel\ndeep-learning architecture that aims to diagnose heart abnormalities quickly\nand accurately. We devised a new activation function called aSoftMax, designed\nto improve the visibility of ECG deflections. The proposed activation function\nis used with Convolutional Neural Network architecture to includes kernel\nweight sharing across the ECG's various leads. This innovative method\nthoroughly generalizes the global 12-lead ECG features and minimizes the\nmodel's complexity by decreasing the trainable parameters. aSoftMax, combined\nwith enhanced CNN architecture yielded AmpliNetECG12, we obtain exceptional\naccuracy of 84% in diagnosing cardiac disorders. AmpliNetECG12 shows\noutstanding prediction ability when used with the CPSC2018 dataset for\narrhythmia classification. The model attains an F1-score of 80.71% and a\nROC-AUC score of 96.00%, with 280,000 trainable parameters which signifies the\nlightweight yet efficient nature of AmpliNetECG12. The stochastic\ncharacteristics of aSoftMax, a fundamental element of AmpliNetECG12, improve\nprediction accuracy and also increasse the model's interpretability. This\nfeature enhances comprehension of important ECG segments in different forms of\narrhythmias, establishing a new standard of explainable architecture for\ncardiac disorder classification.",
      "tldr_zh": "本研究针对计算资源有限的便携设备上12-lead ECG的心脏疾病快速诊断，提出了一种轻量级架构AmpliNetECG12。核心创新包括设计新的激活函数aSoftMax，以增强ECG偏转的可见性，并与增强的CNN架构结合，实现跨ECG leads的内核权重共享，从而减少可训练参数至280,000个。实验结果显示，AmpliNetECG12在CPSC2018数据集上达到84%的准确率、80.71%的F1-score和96.00%的ROC-AUC分数，同时通过aSoftMax的随机特性提升了模型的预测准确性和解释性，为高效的可解释心脏疾病分类设定了新标准。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.13903v1",
      "published_date": "2024-11-21 07:28:24 UTC",
      "updated_date": "2024-11-21 07:28:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T03:03:01.000884"
    },
    {
      "arxiv_id": "2411.13902v1",
      "title": "PIORS: Personalized Intelligent Outpatient Reception based on Large Language Model with Multi-Agents Medical Scenario Simulation",
      "title_zh": "翻译失败",
      "authors": [
        "Zhijie Bao",
        "Qingyun Liu",
        "Ying Guo",
        "Zhengqiang Ye",
        "Jun Shen",
        "Shirong Xie",
        "Jiajie Peng",
        "Xuanjing Huang",
        "Zhongyu Wei"
      ],
      "abstract": "In China, receptionist nurses face overwhelming workloads in outpatient\nsettings, limiting their time and attention for each patient and ultimately\nreducing service quality. In this paper, we present the Personalized\nIntelligent Outpatient Reception System (PIORS). This system integrates an\nLLM-based reception nurse and a collaboration between LLM and hospital\ninformation system (HIS) into real outpatient reception setting, aiming to\ndeliver personalized, high-quality, and efficient reception services.\nAdditionally, to enhance the performance of LLMs in real-world healthcare\nscenarios, we propose a medical conversational data generation framework named\nService Flow aware Medical Scenario Simulation (SFMSS), aiming to adapt the LLM\nto the real-world environments and PIORS settings. We evaluate the\neffectiveness of PIORS and SFMSS through automatic and human assessments\ninvolving 15 users and 15 clinical experts. The results demonstrate that\nPIORS-Nurse outperforms all baselines, including the current state-of-the-art\nmodel GPT-4o, and aligns with human preferences and clinical needs. Further\ndetails and demo can be found at https://github.com/FudanDISC/PIORS",
      "tldr_zh": "本研究针对中国门诊护士工作负担过重导致服务质量下降的问题，提出 Personalized Intelligent Outpatient Reception System (PIORS)，该系统整合基于 Large Language Model (LLM) 的接待护士与 Hospital Information System (HIS) 的协作，提供个性化的、高效的门诊服务。针对 LLM 在真实医疗场景的适应性，作者开发了 Service Flow aware Medical Scenario Simulation (SFMSS) 框架，通过模拟医疗对话数据来提升模型性能。评估结果显示，PIORS-Nurse 优于基线模型包括 GPT-4o，并在涉及 15 名用户和 15 名临床专家的自动及人工评估中，展现出与人类偏好和临床需求的高度一致性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.13902v1",
      "published_date": "2024-11-21 07:28:07 UTC",
      "updated_date": "2024-11-21 07:28:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T03:03:11.994085"
    },
    {
      "arxiv_id": "2411.13883v1",
      "title": "When Online Algorithms Influence the Environment: A Dynamical Systems Analysis of the Unintended Consequences",
      "title_zh": "在线算法影响环境时：对意外后果的动态系统分析",
      "authors": [
        "Prabhat Lankireddy",
        "Jayakrishnan Nair",
        "D Manjunath"
      ],
      "abstract": "We analyze the effect that online algorithms have on the environment that\nthey are learning. As a motivation, consider recommendation systems that use\nonline algorithms to learn optimal product recommendations based on user and\nproduct attributes. It is well known that the sequence of recommendations\naffects user preferences. However, typical learning algorithms treat the user\nattributes as static and disregard the impact of their recommendations on user\npreferences. Our interest is to analyze the effect of this mismatch between the\nmodel assumption of a static environment, and the reality of an evolving\nenvironment affected by the recommendations. To perform this analysis, we first\nintroduce a model for a generic coupled evolution of the parameters that are\nbeing learned, and the environment that is affected by it. We then frame a\nlinear bandit recommendation system (RS) into this generic model where the\nusers are characterized by a state variable that evolves based on the sequence\nof recommendations. The learning algorithm of the RS does not explicitly\naccount for this evolution and assumes that the users are static. A dynamical\nsystem model that captures the coupled evolution of the population state and\nthe learning algorithm is described, and its equilibrium behavior is analyzed.\nWe show that when the recommendation algorithm is able to learn the population\npreferences in the presence of this mismatch, the algorithm induces similarity\nin the preferences of the user population. In particular, we present results on\nhow different properties of the recommendation algorithm, namely the user\nattribute space and the exploration-exploitation tradeoff, effect the\npopulation preferences when they are learned by the algorithm. We demonstrate\nthese results using model simulations.",
      "tldr_zh": "该研究分析在线算法对环境的动态影响，特别是推荐系统如何通过推荐序列改变用户偏好，而传统算法却假设用户属性静态。论文引入一个通用耦合演化模型，并将线性 bandit 推荐系统框架到其中，使用动力系统模型捕捉用户状态和算法的交互演化。结果显示，当算法学习用户偏好时，会诱导用户群体偏好趋于相似，且算法属性如用户属性空间和探索-利用权衡会显著影响这一过程；通过模拟实验验证了这些发现。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "13 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.13883v1",
      "published_date": "2024-11-21 06:47:53 UTC",
      "updated_date": "2024-11-21 06:47:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T03:04:38.877017"
    },
    {
      "arxiv_id": "2411.13874v1",
      "title": "Next-Generation Phishing: How LLM Agents Empower Cyber Attackers",
      "title_zh": "下一代网络钓鱼：大型语言模型代理如何增强网络攻击者",
      "authors": [
        "Khalifa Afane",
        "Wenqi Wei",
        "Ying Mao",
        "Junaid Farooq",
        "Juntao Chen"
      ],
      "abstract": "The escalating threat of phishing emails has become increasingly\nsophisticated with the rise of Large Language Models (LLMs). As attackers\nexploit LLMs to craft more convincing and evasive phishing emails, it is\ncrucial to assess the resilience of current phishing defenses. In this study we\nconduct a comprehensive evaluation of traditional phishing detectors, such as\nGmail Spam Filter, Apache SpamAssassin, and Proofpoint, as well as machine\nlearning models like SVM, Logistic Regression, and Naive Bayes, in identifying\nboth traditional and LLM-rephrased phishing emails. We also explore the\nemerging role of LLMs as phishing detection tools, a method already adopted by\ncompanies like NTT Security Holdings and JPMorgan Chase. Our results reveal\nnotable declines in detection accuracy for rephrased emails across all\ndetectors, highlighting critical weaknesses in current phishing defenses. As\nthe threat landscape evolves, our findings underscore the need for stronger\nsecurity controls and regulatory oversight on LLM-generated content to prevent\nits misuse in creating advanced phishing attacks. This study contributes to the\ndevelopment of more effective Cyber Threat Intelligence (CTI) by leveraging\nLLMs to generate diverse phishing variants that can be used for data\naugmentation, harnessing the power of LLMs to enhance phishing detection, and\npaving the way for more robust and adaptable threat detection systems.",
      "tldr_zh": "本研究探讨了大型语言模型（LLMs）如何提升网络钓鱼攻击的复杂性和有效性，通过评估传统检测器（如Gmail Spam Filter、Apache SpamAssassin和Proofpoint）以及机器学习模型（如SVM、Logistic Regression和Naive Bayes）对传统和LLM改写钓鱼邮件的识别能力。结果显示，这些检测器的准确率在面对改写邮件时显著下降，暴露了现有防御的脆弱性，并突出了对LLM生成内容的监管需求。研究贡献包括利用LLMs生成多样化的钓鱼变体进行数据增强，从而提升Cyber Threat Intelligence (CTI)系统的鲁棒性和适应性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.13874v1",
      "published_date": "2024-11-21 06:20:29 UTC",
      "updated_date": "2024-11-21 06:20:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T03:03:37.043887"
    },
    {
      "arxiv_id": "2411.13867v1",
      "title": "Generative Fuzzy System for Sequence Generation",
      "title_zh": "用于序列生成的生成模糊系统",
      "authors": [
        "Hailong Yang",
        "Zhaohong Deng",
        "Wei Zhang",
        "Zhuangzhuang Zhao",
        "Guanjin Wang",
        "Kup-sze Choi"
      ],
      "abstract": "Generative Models (GMs), particularly Large Language Models (LLMs), have\ngarnered significant attention in machine learning and artificial intelligence\nfor their ability to generate new data by learning the statistical properties\nof training data and creating data that resemble the original. This capability\noffers a wide range of applications across various domains. However, the\ncomplex structures and numerous model parameters of GMs make the input-output\nprocesses opaque, complicating the understanding and control of outputs.\nMoreover, the purely data-driven learning mechanism limits GM's ability to\nacquire broader knowledge. There remains substantial potential for enhancing\nthe robustness and generalization capabilities of GMs. In this work, we\nintroduce the fuzzy system, a classical modeling method that combines data and\nknowledge-driven mechanisms, to generative tasks. We propose a novel Generative\nFuzzy System framework, named GenFS, which integrates the deep learning\ncapabilities of GM with the interpretability and dual-driven mechanisms of\nfuzzy systems. Specifically, we propose an end-to-end GenFS-based model for\nsequence generation, called FuzzyS2S. A series of experimental studies were\nconducted on 12 datasets, covering three distinct categories of generative\ntasks: machine translation, code generation, and summary generation. The\nresults demonstrate that FuzzyS2S outperforms the Transformer in terms of\naccuracy and fluency. Furthermore, it exhibits better performance on some\ndatasets compared to state-of-the-art models T5 and CodeT5.",
      "tldr_zh": "该论文针对生成模型（Generative Models，如LLMs）的复杂结构和数据驱动局限性，提出了一种结合数据和知识驱动机制的Generative Fuzzy System (GenFS)框架，以提升模型的鲁棒性和泛化能力。具体而言，作者开发了基于GenFS的端到端模型FuzzyS2S，用于序列生成任务，通过整合模糊系统的可解释性来优化生成过程。在12个数据集上的实验，包括机器翻译、代码生成和摘要生成，显示FuzzyS2S在准确性和流畅性上优于Transformer，并在某些数据集上超越了T5和CodeT5模型。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "12 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.13867v1",
      "published_date": "2024-11-21 06:03:25 UTC",
      "updated_date": "2024-11-21 06:03:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T03:05:48.459374"
    },
    {
      "arxiv_id": "2411.13865v2",
      "title": "Breaking Information Cocoons: A Hyperbolic Graph-LLM Framework for Exploration and Exploitation in Recommender Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Qiyao Ma",
        "Menglin Yang",
        "Mingxuan Ju",
        "Tong Zhao",
        "Neil Shah",
        "Rex Ying"
      ],
      "abstract": "Modern recommender systems often create information cocoons, restricting\nusers' exposure to diverse content. A key challenge lies in balancing content\nexploration and exploitation while allowing users to adjust their\nrecommendation preferences. Intuitively, this balance can be modeled as a\ntree-structured representation, where depth search facilitates exploitation and\nbreadth search enables exploration. However, existing approaches face two\nfundamental limitations: Euclidean methods struggle to capture hierarchical\nstructures, while hyperbolic methods, despite their superior hierarchical\nmodeling, lack semantic understanding of user and item profiles and fail to\nprovide a principled mechanism for balancing exploration and exploitation. To\naddress these challenges, we propose HERec, a hyperbolic graph-LLM framework\nthat effectively balances exploration and exploitation in recommender systems.\nOur framework introduces two key innovations: (1) a hierarchical-aware\ngraph-LLM mechanism that jointly aligns textual descriptions with user-item\ncollaborative information in hyperbolic space, and (2) a hierarchical\nrepresentation structure that enables user-adjustable exploration-exploitation\ntrade-offs. Extensive experiments demonstrate that HERec consistently\noutperforms both Euclidean and hyperbolic baselines, achieving up to 5.49%\nimprovement in utility metrics and 11.39% increase in diversity metrics,\neffectively mitigating information cocoons. We open-source our model\nimplementation at https://github.com/Martin-qyma/HERec.",
      "tldr_zh": "本文研究了推荐系统中的信息茧房问题，即用户接触多样内容受限，并提出 HERec 框架——一个 Hyperbolic Graph-LLM 机制，用于平衡 Exploration 和 Exploitation。HERec 的关键创新包括：在 Hyperbolic 空间中联合对齐文本描述与用户-物品协作信息，以及提供层次表示结构以允许用户调整探索-利用权衡。实验结果显示，该框架比 Euclidean 和 Hyperbolic 基线提升 utility metrics 至多 5.49% 和 diversity metrics 至多 11.39%，有效缓解信息茧房问题，并开源了模型实现。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.13865v2",
      "published_date": "2024-11-21 06:01:47 UTC",
      "updated_date": "2025-02-01 13:05:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T03:06:00.840275"
    },
    {
      "arxiv_id": "2411.13846v1",
      "title": "Exploratory Study Of Human-AI Interaction For Hindustani Music",
      "title_zh": "翻译失败",
      "authors": [
        "Nithya Shikarpur",
        "Cheng-Zhi Anna Huang"
      ],
      "abstract": "This paper presents a study of participants interacting with and using\nGaMaDHaNi, a novel hierarchical generative model for Hindustani vocal contours.\nTo explore possible use cases in human-AI interaction, we conducted a user\nstudy with three participants, each engaging with the model through three\npredefined interaction modes. Although this study was conducted \"in the wild\"-\nwith the model unadapted for the shift from the training data to real-world\ninteraction - we use it as a pilot to better understand the expectations,\nreactions, and preferences of practicing musicians when engaging with such a\nmodel. We note their challenges as (1) the lack of restrictions in model\noutput, and (2) the incoherence of model output. We situate these challenges in\nthe context of Hindustani music and aim to suggest future directions for the\nmodel design to address these gaps.",
      "tldr_zh": "这篇论文探索了在 Hindustani Music 中的 Human-AI Interaction，通过用户研究评估新型分层生成模型 GaMaDHaNi 的实际应用。研究涉及三名参与者，通过三种预定义互动模式进行测试，尽管模型未适应从训练数据到真实场景的转变，但揭示了音乐家对模型输出的期望和偏好。关键挑战包括模型输出缺乏限制和不连贯性，论文将这些问题置于 Hindustani Music 的语境中，并建议未来模型设计应针对这些缺陷进行优化，以提升互动体验。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "Accepted at NeurIPS Creative AI Track 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.13846v1",
      "published_date": "2024-11-21 05:06:37 UTC",
      "updated_date": "2024-11-21 05:06:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T03:06:11.840852"
    },
    {
      "arxiv_id": "2411.15224v3",
      "title": "Parameter Efficient Mamba Tuning via Projector-targeted Diagonal-centric Linear Transformation",
      "title_zh": "翻译失败",
      "authors": [
        "Seokil Ham",
        "Hee-Seon Kim",
        "Sangmin Woo",
        "Changick Kim"
      ],
      "abstract": "Despite the growing interest in Mamba architecture as a potential replacement\nfor Transformer architecture, parameter-efficient fine-tuning (PEFT) approaches\nfor Mamba remain largely unexplored. In our study, we introduce two key\ninsights-driven strategies for PEFT in Mamba architecture: (1) While\nstate-space models (SSMs) have been regarded as the cornerstone of Mamba\narchitecture, then expected to play a primary role in transfer learning, our\nfindings reveal that Projectors -- not SSMs -- are the predominant contributors\nto transfer learning. (2) Based on our observation, we propose a novel PEFT\nmethod specialized to Mamba architecture: Projector-targeted Diagonal-centric\nLinear Transformation (ProDiaL). ProDiaL focuses on optimizing only the\npretrained Projectors for new tasks through diagonal-centric linear\ntransformation matrices, without directly fine-tuning the Projector weights.\nThis targeted approach allows efficient task adaptation, utilizing less than 1%\nof the total parameters, and exhibits strong performance across both vision and\nlanguage Mamba models, highlighting its versatility and effectiveness.",
      "tldr_zh": "该研究发现，在Mamba架构中，Projectors 比状态空间模型(SSMs) 在迁移学习中发挥更主要作用，从而为参数高效微调(PEFT) 提供了新见解。作者提出了一种新方法 ProDiaL（Projector-targeted Diagonal-centric Linear Transformation），该方法仅通过对角线中心线性变换矩阵优化预训练的 Projectors，而不直接微调其权重，从而实现高效任务适应。实验结果显示，ProDiaL 使用不到1%的参数，即可在视觉和语言 Mamba 模型上表现出色，证明了其通用性和有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "accepted in CVPR 2025",
      "pdf_url": "http://arxiv.org/pdf/2411.15224v3",
      "published_date": "2024-11-21 04:58:20 UTC",
      "updated_date": "2025-03-24 04:59:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T03:06:23.350963"
    },
    {
      "arxiv_id": "2411.14500v1",
      "title": "Exploring Accuracy-Fairness Trade-off in Large Language Models",
      "title_zh": "探索大型语言模型中的准确性-公平性权衡",
      "authors": [
        "Qingquan Zhang",
        "Qiqi Duan",
        "Bo Yuan",
        "Yuhui Shi",
        "Jialin Liu"
      ],
      "abstract": "Large Language Models (LLMs) have made significant strides in the field of\nartificial intelligence, showcasing their ability to interact with humans and\ninfluence human cognition through information dissemination. However, recent\nstudies have brought to light instances of bias inherent within these LLMs,\npresenting a critical issue that demands attention. In our research, we delve\ndeeper into the intricate challenge of harmonising accuracy and fairness in the\nenhancement of LLMs. While improving accuracy can indeed enhance overall LLM\nperformance, it often occurs at the expense of fairness. Overemphasising\noptimisation of one metric invariably leads to a significant degradation of the\nother. This underscores the necessity of taking into account multiple\nconsiderations during the design and optimisation phases of LLMs. Therefore, we\nadvocate for reformulating the LLM training process as a multi-objective\nlearning task. Our investigation reveals that multi-objective evolutionary\nlearning (MOEL) methodologies offer promising avenues for tackling this\nchallenge. Our MOEL framework enables the simultaneous optimisation of both\naccuracy and fairness metrics, resulting in a Pareto-optimal set of LLMs. In\nsummary, our study sheds valuable lights on the delicate equilibrium between\naccuracy and fairness within LLMs, which is increasingly significant for their\nreal-world applications. By harnessing MOEL, we present a promising pathway\ntowards fairer and more efficacious AI technologies.",
      "tldr_zh": "这篇论文探讨了 Large Language Models (LLMs) 在优化准确性时可能牺牲公平性的 trade-off 问题，强调了二者之间难以协调的挑战。研究发现，过度优化单一指标会导致另一指标显著下降，因此建议将 LLM 训练过程重构为多目标学习任务。作者引入 multi-objective evolutionary learning (MOEL) 框架，能够同时优化准确性和公平性指标，生成 Pareto-optimal 的 LLM 模型集。总体而言，这为实现更公平且高效的 AI 技术提供了有价值的路径。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "9 pages",
      "pdf_url": "http://arxiv.org/pdf/2411.14500v1",
      "published_date": "2024-11-21 04:40:35 UTC",
      "updated_date": "2024-11-21 04:40:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T03:06:35.462248"
    },
    {
      "arxiv_id": "2411.13821v2",
      "title": "Heterophilic Graph Neural Networks Optimization with Causal Message-passing",
      "title_zh": "翻译失败",
      "authors": [
        "Botao Wang",
        "Jia Li",
        "Heng Chang",
        "Keli Zhang",
        "Fugee Tsung"
      ],
      "abstract": "In this work, we discover that causal inference provides a promising approach\nto capture heterophilic message-passing in Graph Neural Network (GNN). By\nleveraging cause-effect analysis, we can discern heterophilic edges based on\nasymmetric node dependency. The learned causal structure offers more accurate\nrelationships among nodes. To reduce the computational complexity, we introduce\nintervention-based causal inference in graph learning. We first simplify causal\nanalysis on graphs by formulating it as a structural learning model and define\nthe optimization problem within the Bayesian scheme. We then present an\nanalysis of decomposing the optimization target into a consistency penalty and\na structure modification based on cause-effect relations. We then estimate this\ntarget by conditional entropy and present insights into how conditional entropy\nquantifies the heterophily. Accordingly, we propose CausalMP, a causal\nmessage-passing discovery network for heterophilic graph learning, that\niteratively learns the explicit causal structure of input graphs. We conduct\nextensive experiments in both heterophilic and homophilic graph settings. The\nresult demonstrates that the our model achieves superior link prediction\nperformance. Training on causal structure can also enhance node representation\nin classification task across different base models.",
      "tldr_zh": "本研究发现，因果推理可以有效捕捉图神经网络（GNN）中的异质性消息传递（heterophilic message-passing），通过分析不对称节点依赖来识别异质性边（heterophilic edges）并学习更准确的节点关系。为降低计算复杂度，论文引入基于干预的因果推理，将因果分析简化为贝叶斯框架下的结构学习模型，并使用条件熵量化异质性。最终，提出 CausalMP 框架，该框架迭代学习图的显式因果结构，并在实验中显示出在异质性和同质性图设置中，链接预测性能优于基线模型，同时提升了节点表示在分类任务中的效果。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.13821v2",
      "published_date": "2024-11-21 03:59:07 UTC",
      "updated_date": "2024-11-27 06:12:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T03:06:49.463997"
    },
    {
      "arxiv_id": "2411.14499v1",
      "title": "Understanding World or Predicting Future? A Comprehensive Survey of World Models",
      "title_zh": "理解世界还是预测未来？世界模型的全面综述",
      "authors": [
        "Jingtao Ding",
        "Yunke Zhang",
        "Yu Shang",
        "Yuheng Zhang",
        "Zefang Zong",
        "Jie Feng",
        "Yuan Yuan",
        "Hongyuan Su",
        "Nian Li",
        "Nicholas Sukiennik",
        "Fengli Xu",
        "Yong Li"
      ],
      "abstract": "The concept of world models has garnered significant attention due to\nadvancements in multimodal large language models such as GPT-4 and video\ngeneration models such as Sora, which are central to the pursuit of artificial\ngeneral intelligence. This survey offers a comprehensive review of the\nliterature on world models. Generally, world models are regarded as tools for\neither understanding the present state of the world or predicting its future\ndynamics. This review presents a systematic categorization of world models,\nemphasizing two primary functions: (1) constructing internal representations to\nunderstand the mechanisms of the world, and (2) predicting future states to\nsimulate and guide decision-making. Initially, we examine the current progress\nin these two categories. We then explore the application of world models in key\ndomains, including autonomous driving, robotics, and social simulacra, with a\nfocus on how each domain utilizes these aspects. Finally, we outline key\nchallenges and provide insights into potential future research directions.",
      "tldr_zh": "这篇论文对世界模型进行了全面调查，探讨其在理解当前世界状态和预测未来动态方面的核心作用，尤其在多模态大语言模型如 GPT-4 和视频生成模型如 Sora 的背景下。论文将世界模型分类为两大功能：（1）构建内部表示来理解世界机制，（2）预测未来状态以模拟和指导决策，并回顾了这些方面的最新进展。调查还涵盖了世界模型在自动驾驶、机器人和社会模拟等领域的应用，突出了其实用价值。最后，论文指出了关键挑战，如模型准确性和泛化性，并提供了未来研究方向的见解。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.14499v1",
      "published_date": "2024-11-21 03:58:50 UTC",
      "updated_date": "2024-11-21 03:58:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T03:07:00.951832"
    },
    {
      "arxiv_id": "2411.13814v1",
      "title": "AutoMixQ: Self-Adjusting Quantization for High Performance Memory-Efficient Fine-Tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Changhai Zhou",
        "Shiyang Zhang",
        "Yuhua Zhou",
        "Zekai Liu",
        "Shichao Weng"
      ],
      "abstract": "Fine-tuning large language models (LLMs) under resource constraints is a\nsignificant challenge in deep learning. Low-Rank Adaptation (LoRA), pruning,\nand quantization are all effective methods for improving resource efficiency.\nHowever, combining them directly often results in suboptimal performance,\nespecially with uniform quantization across all model layers. This is due to\nthe complex, uneven interlayer relationships introduced by pruning,\nnecessitating more refined quantization strategies. To address this, we propose\nAutoMixQ, an end-to-end optimization framework that selects optimal\nquantization configurations for each LLM layer. AutoMixQ leverages lightweight\nperformance models to guide the selection process, significantly reducing time\nand computational resources compared to exhaustive search methods. By\nincorporating Pareto optimality, AutoMixQ balances memory usage and\nperformance, approaching the upper bounds of model capability under strict\nresource constraints. Our experiments on widely used benchmarks show that\nAutoMixQ reduces memory consumption while achieving superior performance. For\nexample, at a 30\\% pruning rate in LLaMA-7B, AutoMixQ achieved 66.21\\% on BoolQ\ncompared to 62.45\\% for LoRA and 58.96\\% for LoftQ, while reducing memory\nconsumption by 35.5\\% compared to LoRA and 27.5\\% compared to LoftQ.",
      "tldr_zh": "本文提出AutoMixQ，一种自调整量化框架，用于在资源受限下实现高性能且内存高效的LLM微调。它通过为每个模型层选择最佳量化配置，利用轻量级性能模型和Pareto最优性来平衡内存消耗和性能，避免了统一量化带来的次优问题。在实验中，AutoMixQ在LLaMA-7B模型上以30%修剪率达到66.21%的BoolQ基准准确率，比LoRA的62.45%和LoftQ的58.96%更优，同时减少了35.5%的内存消耗。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.13814v1",
      "published_date": "2024-11-21 03:35:07 UTC",
      "updated_date": "2024-11-21 03:35:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T03:07:12.408898"
    },
    {
      "arxiv_id": "2411.15222v1",
      "title": "Rethinking the Intermediate Features in Adversarial Attacks: Misleading Robotic Models via Adversarial Distillation",
      "title_zh": "翻译失败",
      "authors": [
        "Ke Zhao",
        "Huayang Huang",
        "Miao Li",
        "Yu Wu"
      ],
      "abstract": "Language-conditioned robotic learning has significantly enhanced robot\nadaptability by enabling a single model to execute diverse tasks in response to\nverbal commands. Despite these advancements, security vulnerabilities within\nthis domain remain largely unexplored. This paper addresses this gap by\nproposing a novel adversarial prompt attack tailored to language-conditioned\nrobotic models. Our approach involves crafting a universal adversarial prefix\nthat induces the model to perform unintended actions when added to any original\nprompt. We demonstrate that existing adversarial techniques exhibit limited\neffectiveness when directly transferred to the robotic domain due to the\ninherent robustness of discretized robotic action spaces. To overcome this\nchallenge, we propose to optimize adversarial prefixes based on continuous\naction representations, circumventing the discretization process. Additionally,\nwe identify the beneficial impact of intermediate features on adversarial\nattacks and leverage the negative gradient of intermediate self-attention\nfeatures to further enhance attack efficacy. Extensive experiments on VIMA\nmodels across 13 robot manipulation tasks validate the superiority of our\nmethod over existing approaches and demonstrate its transferability across\ndifferent model variants.",
      "tldr_zh": "本文重新审视了对抗攻击中的中间特征（intermediate features），提出了一种针对语言条件机器人模型的对抗提示攻击（adversarial prompt attack）方法，通过创建通用对抗前缀（universal adversarial prefix）来诱导模型执行非预期动作。针对机器人动作空间的离散化（discretized robotic action spaces）导致的现有技术局限，该方法基于连续动作表示（continuous action representations）优化前缀，并利用中间自注意力特征（intermediate self-attention features）的负梯度来提升攻击效率。在 VIMA 模型的 13 个机器人操作任务上进行的广泛实验证明，该方法比现有方法更优越，并展示了良好的模型转移性（transferability）。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.15222v1",
      "published_date": "2024-11-21 02:46:04 UTC",
      "updated_date": "2024-11-21 02:46:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T03:07:24.782713"
    },
    {
      "arxiv_id": "2411.14497v1",
      "title": "Star-Agents: Automatic Data Optimization with LLM Agents for Instruction Tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Hang Zhou",
        "Yehui Tang",
        "Haochen Qin",
        "Yujie Yang",
        "Renren Jin",
        "Deyi Xiong",
        "Kai Han",
        "Yunhe Wang"
      ],
      "abstract": "The efficacy of large language models (LLMs) on downstream tasks usually\nhinges on instruction tuning, which relies critically on the quality of\ntraining data. Unfortunately, collecting high-quality and diverse data is both\nexpensive and time-consuming. To mitigate this issue, we propose a novel\nStar-Agents framework, which automates the enhancement of data quality across\ndatasets through multi-agent collaboration and assessment. The framework adopts\na three-pronged strategy. It initially generates diverse instruction data with\nmultiple LLM agents through a bespoke sampling method. Subsequently, the\ngenerated data undergo a rigorous evaluation using a dual-model method that\nassesses both difficulty and quality. Finaly, the above process evolves in a\ndynamic refinement phase, where more effective LLMs are prioritized, enhancing\nthe overall data quality. Our empirical studies, including instruction tuning\nexperiments with models such as Pythia and LLaMA, demonstrate the effectiveness\nof the proposed framework. Optimized datasets have achieved substantial\nimprovements, with an average increase of 12% and notable gains in specific\nmetrics, such as a 40% improvement in Fermi, as evidenced by benchmarks like\nMT-bench, Vicuna bench, and WizardLM testset.",
      "tldr_zh": "该研究提出 Star-Agents 框架，利用多智能体协作自动优化指令微调数据，以解决大型语言模型(LLMs)训练中高质量数据收集的成本和时间问题。框架采用三步策略：首先通过定制采样方法由多个 LLM 代理生成多样指令数据；其次，使用双模型评估方法检查数据的难度和质量；最后，通过动态精炼阶段优先使用更有效的 LLM，进一步提升数据整体质量。实验结果显示，在 Pythia 和 LLaMA 等模型上进行指令微调后，优化数据集平均提升 12%，特定指标如 Fermi 提升 40%，并在 MT-bench、Vicuna bench 和 WizardLM 测试集上表现出显著改进。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.14497v1",
      "published_date": "2024-11-21 02:30:53 UTC",
      "updated_date": "2024-11-21 02:30:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T03:07:35.776931"
    },
    {
      "arxiv_id": "2412.04486v1",
      "title": "The Global AI Vibrancy Tool",
      "title_zh": "翻译失败",
      "authors": [
        "Loredana Fattorini",
        "Nestor Maslej",
        "Raymond Perrault",
        "Vanessa Parli",
        "John Etchemendy",
        "Yoav Shoham",
        "Katrina Ligett"
      ],
      "abstract": "This paper presents the latest version of the Global AI Vibrancy Tool (GVT),\nan interactive suite of visualizations designed to facilitate the comparison of\nAI vibrancy across 36 countries, using 42 indicators organized into 8 pillars.\nThe tool offers customizable features that allow users to conduct in-depth\ncountry-level comparisons and longitudinal analyses of AI-related metrics, all\nbased on publicly available data. By providing a transparent assessment of\nnational progress in AI, it serves the diverse needs of policymakers, industry\nleaders, researchers, and the general public. Using weights for indicators and\npillars developed by AI Index's panel of experts and combined into an index,\nthe Global AI Vibrancy Ranking for 2023 places the United States first by a\nsignificant margin, followed by China and the United Kingdom. The ranking also\nhighlights the rise of smaller nations such as Singapore when evaluated on both\nabsolute and per capita bases. The tool offers three sub-indices for evaluating\nGlobal AI Vibrancy along different dimensions: the Innovation Index, the\nEconomic Competitiveness Index, and the Policy, Governance, and Public\nEngagement Index.",
      "tldr_zh": "本论文介绍了Global AI Vibrancy Tool (GVT)的最新版本，这是一个交互式可视化工具，用于比较36个国家的AI活力，基于42个指标组织成8个支柱。GVT允许用户通过公开数据进行国家级和纵向分析，提供透明评估以服务政策制定者、行业领袖和研究人员等群体。利用AI Index专家的指标权重，2023年全球AI活力排名显示美国领先，其次是中国和英国，同时突出了新加坡等小国在绝对和人均指标上的崛起；工具还包括三个子指数：Innovation Index、经济竞争力指数和Policy, Governance, and Public Engagement Index，以评估AI的不同维度。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.04486v1",
      "published_date": "2024-11-21 01:41:17 UTC",
      "updated_date": "2024-11-21 01:41:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T03:07:47.506832"
    },
    {
      "arxiv_id": "2411.13779v1",
      "title": "NewsInterview: a Dataset and a Playground to Evaluate LLMs' Ground Gap via Informational Interviews",
      "title_zh": "翻译失败",
      "authors": [
        "Michael Lu",
        "Hyundong Justin Cho",
        "Weiyan Shi",
        "Jonathan May",
        "Alexander Spangher"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated impressive capabilities in\ngenerating coherent text but often struggle with grounding language and\nstrategic dialogue. To address this gap, we focus on journalistic interviews, a\ndomain rich in grounding communication and abundant in data. We curate a\ndataset of 40,000 two-person informational interviews from NPR and CNN, and\nreveal that LLMs are significantly less likely than human interviewers to use\nacknowledgements and to pivot to higher-level questions. Realizing that a\nfundamental deficit exists in multi-turn planning and strategic thinking, we\ndevelop a realistic simulated environment, incorporating source personas and\npersuasive elements, in order to facilitate the development of agents with\nlonger-horizon rewards. Our experiments show that while source LLMs mimic human\nbehavior in information sharing, interviewer LLMs struggle with recognizing\nwhen questions are answered and engaging persuasively, leading to suboptimal\ninformation extraction across model size and capability. These findings\nunderscore the need for enhancing LLMs' strategic dialogue capabilities.",
      "tldr_zh": "该研究构建了NewsInterview数据集，包含40,000个来自NPR和CNN的信息采访样本，用于评估Large Language Models (LLMs)在语言接地和战略对话方面的不足。论文发现，LLMs比人类采访者更少使用acknowledgements和转向更高层次的问题，暴露了其在多轮规划和战略思考上的根本缺陷。为此，研究开发了一个模拟环境，融入source personas和说服元素，以促进代理的长期奖励优化。实验结果显示，interviewer LLMs在识别问题回答和进行说服性互动上表现不佳，导致信息提取效率低下，从而强调了提升LLMs战略对话能力的必要性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.13779v1",
      "published_date": "2024-11-21 01:37:38 UTC",
      "updated_date": "2024-11-21 01:37:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T03:08:00.231745"
    },
    {
      "arxiv_id": "2411.13778v1",
      "title": "A Survey on Adversarial Robustness of LiDAR-based Machine Learning Perception in Autonomous Vehicles",
      "title_zh": "翻译失败",
      "authors": [
        "Junae Kim",
        "Amardeep Kaur"
      ],
      "abstract": "In autonomous driving, the combination of AI and vehicular technology offers\ngreat potential. However, this amalgamation comes with vulnerabilities to\nadversarial attacks. This survey focuses on the intersection of Adversarial\nMachine Learning (AML) and autonomous systems, with a specific focus on\nLiDAR-based systems. We comprehensively explore the threat landscape,\nencompassing cyber-attacks on sensors and adversarial perturbations.\nAdditionally, we investigate defensive strategies employed in countering these\nthreats. This paper endeavors to present a concise overview of the challenges\nand advances in securing autonomous driving systems against adversarial\nthreats, emphasizing the need for robust defenses to ensure safety and\nsecurity.",
      "tldr_zh": "本调查探讨了自动驾驶系统中 LiDAR 基于机器学习感知的对抗鲁棒性，聚焦于 Adversarial Machine Learning (AML) 与这些系统的交叉点。论文全面分析了威胁景观，包括对传感器的网络攻击和对抗扰动，并考察了相应的防御策略，以提升系统安全性。最终，该研究概述了当前挑战和进展，强调了开发鲁棒防御措施的必要性，以确保自动驾驶的安全和可靠性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "20 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.13778v1",
      "published_date": "2024-11-21 01:26:52 UTC",
      "updated_date": "2024-11-21 01:26:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T03:08:12.056898"
    },
    {
      "arxiv_id": "2411.13775v1",
      "title": "Benchmarking GPT-4 against Human Translators: A Comprehensive Evaluation Across Languages, Domains, and Expertise Levels",
      "title_zh": "翻译失败",
      "authors": [
        "Jianhao Yan",
        "Pingchuan Yan",
        "Yulong Chen",
        "Jing Li",
        "Xianchao Zhu",
        "Yue Zhang"
      ],
      "abstract": "This study presents a comprehensive evaluation of GPT-4's translation\ncapabilities compared to human translators of varying expertise levels. Through\nsystematic human evaluation using the MQM schema, we assess translations across\nthree language pairs (Chinese$\\longleftrightarrow$English,\nRussian$\\longleftrightarrow$English, and Chinese$\\longleftrightarrow$Hindi) and\nthree domains (News, Technology, and Biomedical). Our findings reveal that\nGPT-4 achieves performance comparable to junior-level translators in terms of\ntotal errors, while still lagging behind senior translators. Unlike traditional\nNeural Machine Translation systems, which show significant performance\ndegradation in resource-poor language directions, GPT-4 maintains consistent\ntranslation quality across all evaluated language pairs. Through qualitative\nanalysis, we identify distinctive patterns in translation approaches: GPT-4\ntends toward overly literal translations and exhibits lexical inconsistency,\nwhile human translators sometimes over-interpret context and introduce\nhallucinations. This study represents the first systematic comparison between\nLLM and human translators across different proficiency levels, providing\nvaluable insights into the current capabilities and limitations of LLM-based\ntranslation systems.",
      "tldr_zh": "本研究对 GPT-4 的翻译能力进行了全面评估，与不同经验水平的人类翻译者进行比较，使用 MQM schema 进行系统化人类评估，涵盖三个语言对（Chinese ↔ English、Russian ↔ English 和 Chinese ↔ Hindi）以及三个领域（News、Technology 和 Biomedical）。结果显示，GPT-4 在总错误方面与初级翻译者相当，但仍落后于高级翻译者，且与传统 Neural Machine Translation 系统不同，它在资源匮乏的语言方向上保持一致的质量。定性分析揭示，GPT-4 倾向于过于字面翻译和词汇不一致，而人类翻译者可能过度解释上下文并引入幻觉；此研究首次系统比较 LLM 和人类翻译者，提供宝贵洞见以揭示 LLM 翻译系统的能力和局限性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Work in progress",
      "pdf_url": "http://arxiv.org/pdf/2411.13775v1",
      "published_date": "2024-11-21 01:12:46 UTC",
      "updated_date": "2024-11-21 01:12:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T03:08:23.956232"
    },
    {
      "arxiv_id": "2411.13773v1",
      "title": "FastRAG: Retrieval Augmented Generation for Semi-structured Data",
      "title_zh": "FastRAG：针对半结构化数据的检索增强生成",
      "authors": [
        "Amar Abane",
        "Anis Bekri",
        "Abdella Battou"
      ],
      "abstract": "Efficiently processing and interpreting network data is critical for the\noperation of increasingly complex networks. Recent advances in Large Language\nModels (LLM) and Retrieval-Augmented Generation (RAG) techniques have improved\ndata processing in network management. However, existing RAG methods like\nVectorRAG and GraphRAG struggle with the complexity and implicit nature of\nsemi-structured technical data, leading to inefficiencies in time, cost, and\nretrieval. This paper introduces FastRAG, a novel RAG approach designed for\nsemi-structured data. FastRAG employs schema learning and script learning to\nextract and structure data without needing to submit entire data sources to an\nLLM. It integrates text search with knowledge graph (KG) querying to improve\naccuracy in retrieving context-rich information. Evaluation results demonstrate\nthat FastRAG provides accurate question answering, while improving up to 90% in\ntime and 85% in cost compared to GraphRAG.",
      "tldr_zh": "该论文提出FastRAG，一种针对半结构化数据的Retrieval-Augmented Generation (RAG) 方法，旨在解决现有RAG技术如VectorRAG和GraphRAG在处理复杂网络数据时的时间、成本和检索效率问题。FastRAG通过schema learning和script learning来提取并结构化数据，避免将整个数据源提交给Large Language Models (LLM)。它整合文本搜索与knowledge graph (KG) 查询，提升了上下文丰富的检索准确性。评估结果显示，FastRAG在问答准确性上表现优异，同时比GraphRAG节省90%的时间和85%的成本。",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.13773v1",
      "published_date": "2024-11-21 01:00:25 UTC",
      "updated_date": "2024-11-21 01:00:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T03:08:35.666690"
    },
    {
      "arxiv_id": "2501.00004v1",
      "title": "NewsHomepages: Homepage Layouts Capture Information Prioritization Decisions",
      "title_zh": "翻译失败",
      "authors": [
        "Ben Welsh",
        "Naitian Zhou",
        "Arda Kaz",
        "Michael Vu",
        "Alexander Spangher"
      ],
      "abstract": "Information prioritization plays an important role in how humans perceive and\nunderstand the world. Homepage layouts serve as a tangible proxy for this\nprioritization. In this work, we present NewsHomepages, a large dataset of over\n3,000 new website homepages (including local, national and topic-specific\noutlets) captured twice daily over a three-year period. We develop models to\nperform pairwise comparisons between news items to infer their relative\nsignificance. To illustrate that modeling organizational hierarchies has\nbroader implications, we applied our models to rank-order a collection of local\ncity council policies passed over a ten-year period in San Francisco, assessing\ntheir \"newsworthiness\". Our findings lay the groundwork for leveraging implicit\norganizational cues to deepen our understanding of information prioritization.",
      "tldr_zh": "本文提出NewsHomepages数据集，该数据集包含超过3000个新闻网站主页（包括本地、国家和主题特定来源）的布局数据，每天捕捉两次，持续三年，用于捕捉信息优先化决策。研究者开发了模型，通过pairwise comparisons对新闻项目进行配对比较，以推断其相对重要性。模型还应用于排名旧金山过去十年的市议会政策，评估其newsworthiness，为利用隐含组织线索加深信息优先化理解奠定了基础。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.00004v1",
      "published_date": "2024-11-21 00:46:42 UTC",
      "updated_date": "2024-11-21 00:46:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T03:08:47.673620"
    },
    {
      "arxiv_id": "2412.04485v1",
      "title": "EDA-Aware RTL Generation with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Mubashir ul Islam",
        "Humza Sami",
        "Pierre-Emmanuel Gaillardon",
        "Valerio Tenace"
      ],
      "abstract": "Large Language Models (LLMs) have become increasingly popular for generating\nRTL code. However, producing error-free RTL code in a zero-shot setting remains\nhighly challenging for even state-of-the-art LLMs, often leading to issues that\nrequire manual, iterative refinement. This additional debugging process can\ndramatically increase the verification workload, underscoring the need for\nrobust, automated correction mechanisms to ensure code correctness from the\nstart.\n  In this work, we introduce AIvril2, a self-verifying, LLM-agnostic agentic\nframework aimed at enhancing RTL code generation through iterative corrections\nof both syntax and functional errors. Our approach leverages a collaborative\nmulti-agent system that incorporates feedback from error logs generated by EDA\ntools to automatically identify and resolve design flaws. Experimental results,\nconducted on the VerilogEval-Human benchmark suite, demonstrate that our\nframework significantly improves code quality, achieving nearly a 3.4$\\times$\nenhancement over prior methods. In the best-case scenario, functional pass\nrates of 77% for Verilog and 66% for VHDL were obtained, thus substantially\nimproving the reliability of LLM-driven RTL code generation.",
      "tldr_zh": "该研究针对大型语言模型(LLMs)在零-shot 设置下生成 RTL 代码时存在的语法和功能错误问题，提出了一种自验证的框架 AIvril2，以提升代码生成质量。该框架采用协作多代理系统，利用 EDA 工具的错误日志反馈进行自动迭代修正，从而识别和解决设计缺陷。在 VerilogEval-Human 基准测试中，AIvril2 比先前方法提高了约 3.4 倍的代码质量，最佳情况下实现了 Verilog 的 77% 和 VHDL 的 66% 功能通过率。",
      "categories": [
        "cs.AR",
        "cs.AI"
      ],
      "primary_category": "cs.AR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.04485v1",
      "published_date": "2024-11-21 00:37:51 UTC",
      "updated_date": "2024-11-21 00:37:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T03:08:59.316309"
    },
    {
      "arxiv_id": "2411.13768v2",
      "title": "Evaluation-Driven Development of LLM Agents: A Process Model and Reference Architecture",
      "title_zh": "LLM 代理的评估驱动开发：一个过程模型和参考架构",
      "authors": [
        "Boming Xia",
        "Qinghua Lu",
        "Liming Zhu",
        "Zhenchang Xing",
        "Dehai Zhao",
        "Hao Zhang"
      ],
      "abstract": "Large Language Models (LLMs) have enabled the emergence of LLM agents:\nautonomous systems capable of achieving under-specified goals and adapting\npost-deployment, often without explicit code or model changes. Evaluating these\nagents is critical to ensuring their performance and safety, especially given\ntheir dynamic, probabilistic, and evolving nature. However, traditional\napproaches such as predefined test cases and standard redevelopment pipelines\nstruggle to address the unique challenges of LLM agent evaluation. These\nchallenges include capturing open-ended behaviors, handling emergent outcomes,\nand enabling continuous adaptation over the agent's lifecycle. To address these\nissues, we propose an evaluation-driven development approach, inspired by\ntest-driven and behavior-driven development but reimagined for the unique\ncharacteristics of LLM agents. Through a multivocal literature review (MLR), we\nsynthesize the limitations of existing LLM evaluation methods and introduce a\nnovel process model and reference architecture tailored for evaluation-driven\ndevelopment of LLM agents. Our approach integrates online (runtime) and offline\n(redevelopment) evaluations, enabling adaptive runtime adjustments and\nsystematic iterative refinement of pipelines, artifacts, system architecture,\nand LLMs themselves. By continuously incorporating evaluation results,\nincluding fine-grained feedback from human and AI evaluators, into each stage\nof development and operation, this framework ensures that LLM agents remain\naligned with evolving goals, user needs, and governance standards.",
      "tldr_zh": "该论文探讨了Large Language Models (LLM) 代理的开发挑战，特别是评估其动态、概率性和演化特性以确保性能和安全。作者提出了一种评估驱动开发方法，受test-driven development和behavior-driven development启发，通过multivocal literature review (MLR) 分析现有方法的局限性，并引入新型过程模型和reference architecture。 该框架整合在线（运行时）和离线（重新开发）评估，允许持续反馈从人类和AI评估者中获取，从而实现对管道、架构和LLM的迭代优化，确保代理适应演变目标、用户需求及治理标准。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.13768v2",
      "published_date": "2024-11-21 00:34:30 UTC",
      "updated_date": "2025-03-27 02:02:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T03:09:11.891164"
    },
    {
      "arxiv_id": "2411.13766v2",
      "title": "Tiny-Align: Bridging Automatic Speech Recognition and Large Language Model on the Edge",
      "title_zh": "Tiny-Align：桥接自动语音识别和大语言模型于边缘",
      "authors": [
        "Ruiyang Qin",
        "Dancheng Liu",
        "Gelei Xu",
        "Zheyu Yan",
        "Chenhui Xu",
        "Yuting Hu",
        "X. Sharon Hu",
        "Jinjun Xiong",
        "Yiyu Shi"
      ],
      "abstract": "The combination of Large Language Models (LLM) and Automatic Speech\nRecognition (ASR), when deployed on edge devices (called edge ASR-LLM), can\nserve as a powerful personalized assistant to enable audio-based interaction\nfor users. Compared to text-based interaction, edge ASR-LLM allows accessible\nand natural audio interactions. Unfortunately, existing ASR-LLM models are\nmainly trained in high-performance computing environments and produce\nsubstantial model weights, making them difficult to deploy on edge devices.\nMore importantly, to better serve users' personalized needs, the ASR-LLM must\nbe able to learn from each distinct user, given that audio input often contains\nhighly personalized characteristics that necessitate personalized on-device\ntraining. Since individually fine-tuning the ASR or LLM often leads to\nsuboptimal results due to modality-specific limitations, end-to-end training\nensures seamless integration of audio features and language understanding\n(cross-modal alignment), ultimately enabling a more personalized and efficient\nadaptation on edge devices. However, due to the complex training requirements\nand substantial computational demands of existing approaches, cross-modal\nalignment between ASR audio and LLM can be challenging on edge devices. In this\nwork, we propose a resource-efficient cross-modal alignment framework that\nbridges ASR and LLMs on edge devices to handle personalized audio input. Our\nframework enables efficient ASR-LLM alignment on resource-constrained devices\nlike NVIDIA Jetson Orin (8GB RAM), achieving 50x training time speedup while\nimproving the alignment quality by more than 50\\%. To the best of our\nknowledge, this is the first work to study efficient ASR-LLM alignment on\nresource-constrained edge devices.",
      "tldr_zh": "这篇论文提出 Tiny-Align 框架，用于在边缘设备上桥接 Automatic Speech Recognition (ASR) 和 Large Language Model (LLM)，以实现高效的跨模态对齐和个性化音频交互。框架通过资源高效的端到端训练方法，解决现有 ASR-LLM 模型体积大、计算需求高的部署挑战，确保无缝整合音频特征和语言理解。实验结果显示，在 NVIDIA Jetson Orin 等资源受限设备上，该框架实现了 50 倍的训练时间加速，同时提升超过 50% 的对齐质量，这是首个针对边缘设备高效 ASR-LLM 对齐的研究。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "7 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.13766v2",
      "published_date": "2024-11-21 00:29:58 UTC",
      "updated_date": "2024-11-26 05:12:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T03:09:24.811729"
    },
    {
      "arxiv_id": "2411.13757v2",
      "title": "GenBFA: An Evolutionary Optimization Approach to Bit-Flip Attacks on LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Sanjay Das",
        "Swastik Bhattacharya",
        "Souvik Kundu",
        "Shamik Kundu",
        "Anand Menon",
        "Arnab Raha",
        "Kanad Basu"
      ],
      "abstract": "Large Language Models (LLMs) have revolutionized natural language processing\n(NLP), excelling in tasks like text generation and summarization. However,\ntheir increasing adoption in mission-critical applications raises concerns\nabout hardware-based threats, particularly bit-flip attacks (BFAs). BFAs,\nenabled by fault injection methods such as Rowhammer, target model parameters\nin memory, compromising both integrity and performance. Identifying critical\nparameters for BFAs in the vast parameter space of LLMs poses significant\nchallenges. While prior research suggests transformer-based architectures are\ninherently more robust to BFAs compared to traditional deep neural networks, we\nchallenge this assumption. For the first time, we demonstrate that as few as\nthree bit-flips can cause catastrophic performance degradation in an LLM with\nbillions of parameters. Current BFA techniques are inadequate for exploiting\nthis vulnerability due to the difficulty of efficiently identifying critical\nparameters within the immense parameter space. To address this, we propose\nAttentionBreaker, a novel framework tailored for LLMs that enables efficient\ntraversal of the parameter space to identify critical parameters. Additionally,\nwe introduce GenBFA, an evolutionary optimization strategy designed to refine\nthe search further, isolating the most critical bits for an efficient and\neffective attack. Empirical results reveal the profound vulnerability of LLMs\nto AttentionBreaker. For example, merely three bit-flips (4.129 x 10^-9% of\ntotal parameters) in the LLaMA3-8B-Instruct 8-bit quantized (W8) model result\nin a complete performance collapse: accuracy on MMLU tasks drops from 67.3% to\n0%, and Wikitext perplexity skyrockets from 12.6 to 4.72 x 10^5. These findings\nunderscore the effectiveness of AttentionBreaker in uncovering and exploiting\ncritical vulnerabilities within LLM architectures.",
      "tldr_zh": "这篇论文探讨了Bit-Flip Attacks (BFAs)对Large Language Models (LLMs)的威胁，挑战了现有观点，认为LLMs比传统神经网络更鲁棒。研究者首次证明，仅三个位翻转即可导致LLMs性能灾难性下降，并引入AttentionBreaker框架来高效遍历参数空间识别关键参数。接着，他们提出GenBFA，一种基于evolutionary optimization的策略，进一步优化搜索以实现高效攻击。实验结果显示，在LLaMA3-8B-Instruct 8-bit量化模型上，仅占总参数4.129 x 10^-9%的三个位翻转，使MMLU任务准确率从67.3%降至0%，并显著增加Wikitext困惑度至4.72 x 10^5，这突显了LLMs的潜在漏洞。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.13757v2",
      "published_date": "2024-11-21 00:01:51 UTC",
      "updated_date": "2025-02-07 16:24:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T03:09:37.988644"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 99,
  "processed_papers_count": 99,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-21T03:09:57.117273"
}