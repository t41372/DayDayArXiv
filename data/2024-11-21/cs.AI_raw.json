[
  {
    "arxiv_id": "2411.14633v1",
    "title": "Evaluating Representational Similarity Measures from the Lens of Functional Correspondence",
    "authors": [
      "Yiqing Bo",
      "Ansh Soni",
      "Sudhanshu Srivastava",
      "Meenakshi Khosla"
    ],
    "abstract": "Neuroscience and artificial intelligence (AI) both face the challenge of\ninterpreting high-dimensional neural data, where the comparative analysis of\nsuch data is crucial for revealing shared mechanisms and differences between\nthese complex systems. Despite the widespread use of representational\ncomparisons and the abundance classes of comparison methods, a critical\nquestion remains: which metrics are most suitable for these comparisons? While\nsome studies evaluate metrics based on their ability to differentiate models of\ndifferent origins or constructions (e.g., various architectures), another\napproach is to assess how well they distinguish models that exhibit distinct\nbehaviors. To investigate this, we examine the degree of alignment between\nvarious representational similarity measures and behavioral outcomes, employing\ngroup statistics and a comprehensive suite of behavioral metrics for\ncomparison. In our evaluation of eight commonly used representational\nsimilarity metrics in the visual domain -- spanning alignment-based, Canonical\nCorrelation Analysis (CCA)-based, inner product kernel-based, and\nnearest-neighbor methods -- we found that metrics like linear Centered Kernel\nAlignment (CKA) and Procrustes distance, which emphasize the overall geometric\nstructure or shape of representations, excelled in differentiating trained from\nuntrained models and aligning with behavioral measures, whereas metrics such as\nlinear predictivity, commonly used in neuroscience, demonstrated only moderate\nalignment with behavior. These insights are crucial for selecting metrics that\nemphasize behaviorally meaningful comparisons in NeuroAI research.",
    "categories": [
      "q-bio.NC",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "q-bio.NC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.14633v1",
    "published_date": "2024-11-21 23:53:58 UTC",
    "updated_date": "2024-11-21 23:53:58 UTC"
  },
  {
    "arxiv_id": "2411.15237v1",
    "title": "Stain-Invariant Representation for Tissue Classification in Histology Images",
    "authors": [
      "Manahil Raza",
      "Saad Bashir",
      "Talha Qaiser",
      "Nasir Rajpoot"
    ],
    "abstract": "The process of digitising histology slides involves multiple factors that can\naffect a whole slide image's (WSI) final appearance, including the staining\nprotocol, scanner, and tissue type. This variability constitutes a domain shift\nand results in significant problems when training and testing deep learning\n(DL) algorithms in multi-cohort settings. As such, developing robust and\ngeneralisable DL models in computational pathology (CPath) remains an open\nchallenge. In this regard, we propose a framework that generates\nstain-augmented versions of the training images using stain matrix\nperturbation. Thereafter, we employed a stain regularisation loss to enforce\nconsistency between the feature representations of the source and augmented\nimages. Doing so encourages the model to learn stain-invariant and,\nconsequently, domain-invariant feature representations. We evaluate the\nperformance of the proposed model on cross-domain multi-class tissue type\nclassification of colorectal cancer images and have achieved improved\nperformance compared to other state-of-the-art methods.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.15237v1",
    "published_date": "2024-11-21 23:50:30 UTC",
    "updated_date": "2024-11-21 23:50:30 UTC"
  },
  {
    "arxiv_id": "2411.14627v1",
    "title": "Generative AI for Music and Audio",
    "authors": [
      "Hao-Wen Dong"
    ],
    "abstract": "Generative AI has been transforming the way we interact with technology and\nconsume content. In the next decade, AI technology will reshape how we create\naudio content in various media, including music, theater, films, games,\npodcasts, and short videos. In this dissertation, I introduce the three main\ndirections of my research centered around generative AI for music and audio: 1)\nmultitrack music generation, 2) assistive music creation tools, and 3)\nmultimodal learning for audio and music. Through my research, I aim to answer\nthe following two fundamental questions: 1) How can AI help professionals or\namateurs create music and audio content? 2) Can AI learn to create music in a\nway similar to how humans learn music? My long-term goal is to lower the\nbarrier of entry for music composition and democratize audio content creation",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "cs.MM",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "PhD Dissertation",
    "pdf_url": "http://arxiv.org/pdf/2411.14627v1",
    "published_date": "2024-11-21 23:02:12 UTC",
    "updated_date": "2024-11-21 23:02:12 UTC"
  },
  {
    "arxiv_id": "2411.14626v3",
    "title": "Beneath the Surface: The Role of Underwater Image Enhancement in Object Detection",
    "authors": [
      "Ali Awad",
      "Ashraf Saleem",
      "Sidike Paheding",
      "Evan Lucas",
      "Serein Al-Ratrout",
      "Timothy C. Havens"
    ],
    "abstract": "Underwater imagery often suffers from severe degradation resulting in low\nvisual quality and reduced object detection performance. This work aims to\nevaluate state-of-the-art image enhancement models, investigate their effects\non underwater object detection, and explore their potential to improve\ndetection performance. To this end, we apply nine recent underwater image\nenhancement models, covering physical, non-physical and learning-based\ncategories, to two recent underwater image datasets. Following this, we conduct\njoint qualitative and quantitative analyses on the original and enhanced\nimages, revealing the discrepancy between the two analyses, and analyzing\nchanges in the quality distribution of the images after enhancement. We then\ntrain three recent object detection models on the original datasets, selecting\nthe best-performing detector for further analysis. This detector is\nsubsequently re-trained on the enhanced datasets to evaluate changes in\ndetection performance, highlighting the adverse effect of enhancement on\ndetection performance at the dataset level. Next, we perform a correlation\nstudy to examine the relationship between various enhancement metrics and the\nmean Average Precision (mAP). Finally, we conduct an image-level analysis that\nreveals images of improved detection performance after enhancement. The\nfindings of this study demonstrate the potential of image enhancement to\nimprove detection performance and provide valuable insights for researchers to\nfurther explore the effects of enhancement on detection at the individual image\nlevel, rather than at the dataset level. This could enable the selective\napplication of enhancement for improved detection. The data generated, code\ndeveloped, and supplementary materials are publicly available at:\nhttps://github.com/RSSL-MTU/Enhancement-Detection-Analysis.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.14626v3",
    "published_date": "2024-11-21 22:59:15 UTC",
    "updated_date": "2025-04-18 01:11:28 UTC"
  },
  {
    "arxiv_id": "2411.14625v1",
    "title": "Predictive Analytics of Air Alerts in the Russian-Ukrainian War",
    "authors": [
      "Demian Pavlyshenko",
      "Bohdan Pavlyshenko"
    ],
    "abstract": "The paper considers exploratory data analysis and approaches in predictive\nanalytics for air alerts during the Russian-Ukrainian war which broke out on\nFeb 24, 2022. The results illustrate that alerts in regions correlate with one\nanother and have geospatial patterns which make it feasible to build a\npredictive model which predicts alerts that are expected to take place in a\ncertain region within a specified time period. The obtained results show that\nthe alert status in a particular region is highly dependable on the features of\nits adjacent regions. Seasonality features like hours, days of a week and\nmonths are also crucial in predicting the target variable. Some regions highly\nrely on the time feature which equals to a number of days from the initial date\nof the dataset. From this, we can deduce that the air alert pattern changes\nthroughout the time.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.14625v1",
    "published_date": "2024-11-21 22:58:39 UTC",
    "updated_date": "2024-11-21 22:58:39 UTC"
  },
  {
    "arxiv_id": "2411.15235v2",
    "title": "CODE-CL: Conceptor-Based Gradient Projection for Deep Continual Learning",
    "authors": [
      "Marco Paul E. Apolinario",
      "Sakshi Choudhary",
      "Kaushik Roy"
    ],
    "abstract": "Continual learning (CL) - the ability to progressively acquire and integrate\nnew concepts - is essential to intelligent systems to adapt to dynamic\nenvironments. However, deep neural networks struggle with catastrophic\nforgetting (CF) when learning tasks sequentially, as training for new tasks\noften overwrites previously learned knowledge. To address this, recent\napproaches constrain updates to orthogonal subspaces using gradient projection,\neffectively preserving important gradient directions for previous tasks. While\neffective in reducing forgetting, these approaches inadvertently hinder forward\nknowledge transfer (FWT), particularly when tasks are highly correlated. In\nthis work, we propose Conceptor-based gradient projection for Deep Continual\nLearning (CODE-CL), a novel method that leverages conceptor matrix\nrepresentations, a form of regularized reconstruction, to adaptively handle\nhighly correlated tasks. CODE-CL mitigates CF by projecting gradients onto\npseudo-orthogonal subspaces of previous task feature spaces while\nsimultaneously promoting FWT. It achieves this by learning a linear combination\nof shared basis directions, allowing efficient balance between stability and\nplasticity and transfer of knowledge between overlapping input feature\nrepresentations. Extensive experiments on continual learning benchmarks\nvalidate CODE-CL's efficacy, demonstrating superior performance, reduced\nforgetting, and improved FWT as compared to state-of-the-art methods.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "12 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.15235v2",
    "published_date": "2024-11-21 22:31:06 UTC",
    "updated_date": "2025-03-07 22:46:12 UTC"
  },
  {
    "arxiv_id": "2411.14612v2",
    "title": "Exploiting Boosting in Hyperdimensional Computing for Enhanced Reliability in Healthcare",
    "authors": [
      "SungHeon Jeong",
      "Hamza Errahmouni Barkam",
      "Sanggeon Yun",
      "Yeseong Kim",
      "Shaahin Angizi",
      "Mohsen Imani"
    ],
    "abstract": "Hyperdimensional computing (HDC) enables efficient data encoding and\nprocessing in high-dimensional space, benefiting machine learning and data\nanalysis. However, underutilization of these spaces can lead to overfitting and\nreduced model reliability, especially in data-limited systems a critical issue\nin sectors like healthcare that demand robustness and consistent performance.\nWe introduce BoostHD, an approach that applies boosting algorithms to partition\nthe hyperdimensional space into subspaces, creating an ensemble of weak\nlearners. By integrating boosting with HDC, BoostHD enhances performance and\nreliability beyond existing HDC methods. Our analysis highlights the importance\nof efficient utilization of hyperdimensional spaces for improved model\nperformance. Experiments on healthcare datasets show that BoostHD outperforms\nstate-of-the-art methods. On the WESAD dataset, it achieved an accuracy of\n98.37%, surpassing Random Forest, XGBoost, and OnlineHD. BoostHD also\ndemonstrated superior inference efficiency and stability, maintaining high\naccuracy under data imbalance and noise. In person-specific evaluations, it\nachieved an average accuracy of 96.19%, outperforming other models. By\naddressing the limitations of both boosting and HDC, BoostHD expands the\napplicability of HDC in critical domains where reliability and precision are\nparamount.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to DATE 2025",
    "pdf_url": "http://arxiv.org/pdf/2411.14612v2",
    "published_date": "2024-11-21 22:28:45 UTC",
    "updated_date": "2025-01-14 00:20:32 UTC"
  },
  {
    "arxiv_id": "2411.14593v2",
    "title": "A Systematic Study of Multi-Agent Deep Reinforcement Learning for Safe and Robust Autonomous Highway Ramp Entry",
    "authors": [
      "Larry Schester",
      "Luis E. Ortiz"
    ],
    "abstract": "Vehicles today can drive themselves on highways and driverless robotaxis\noperate in major cities, with more sophisticated levels of autonomous driving\nexpected to be available and become more common in the future. Yet, technically\nspeaking, so-called \"Level 5\" (L5) operation, corresponding to full autonomy,\nhas not been achieved. For that to happen, functions such as fully autonomous\nhighway ramp entry must be available, and provide provably safe, and reliably\nrobust behavior to enable full autonomy. We present a systematic study of a\nhighway ramp function that controls the vehicles forward-moving actions to\nminimize collisions with the stream of highway traffic into which a merging\n(ego) vehicle enters. We take a game-theoretic multi-agent (MA) approach to\nthis problem and study the use of controllers based on deep reinforcement\nlearning (DRL). The virtual environment of the MA DRL uses self-play with\nsimulated data where merging vehicles safely learn to control longitudinal\nposition during a taper-type merge. The work presented in this paper extends\nexisting work by studying the interaction of more than two vehicles (agents)\nand does so by systematically expanding the road scene with additional traffic\nand ego vehicles. While previous work on the two-vehicle setting established\nthat collision-free controllers are theoretically impossible in fully\ndecentralized, non-coordinated environments, we empirically show that\ncontrollers learned using our approach are nearly ideal when measured against\nidealized optimal controllers.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG",
      "cs.MA",
      "cs.SY",
      "eess.SY",
      "I.2.9; I.2.11; I.2.6; I.2.8"
    ],
    "primary_category": "cs.RO",
    "comment": "9 pages, 9 figures; added support ack",
    "pdf_url": "http://arxiv.org/pdf/2411.14593v2",
    "published_date": "2024-11-21 21:23:46 UTC",
    "updated_date": "2025-01-17 01:00:13 UTC"
  },
  {
    "arxiv_id": "2411.14592v2",
    "title": "G-RAG: Knowledge Expansion in Material Science",
    "authors": [
      "Radeen Mostafa",
      "Mirza Nihal Baig",
      "Mashaekh Tausif Ehsan",
      "Jakir Hasan"
    ],
    "abstract": "In the field of Material Science, effective information retrieval systems are\nessential for facilitating research. Traditional Retrieval-Augmented Generation\n(RAG) approaches in Large Language Models (LLMs) often encounter challenges\nsuch as outdated information, hallucinations, limited interpretability due to\ncontext constraints, and inaccurate retrieval. To address these issues, Graph\nRAG integrates graph databases to enhance the retrieval process. Our proposed\nmethod processes Material Science documents by extracting key entities\n(referred to as MatIDs) from sentences, which are then utilized to query\nexternal Wikipedia knowledge bases (KBs) for additional relevant information.\nWe implement an agent-based parsing technique to achieve a more detailed\nrepresentation of the documents. Our improved version of Graph RAG called G-RAG\nfurther leverages a graph database to capture relationships between these\nentities, improving both retrieval accuracy and contextual understanding. This\nenhanced approach demonstrates significant improvements in performance for\ndomains that require precise information retrieval, such as Material Science.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.14592v2",
    "published_date": "2024-11-21 21:22:58 UTC",
    "updated_date": "2024-12-01 01:21:24 UTC"
  },
  {
    "arxiv_id": "2411.14574v1",
    "title": "SRSA: A Cost-Efficient Strategy-Router Search Agent for Real-world Human-Machine Interactions",
    "authors": [
      "Yaqi Wang",
      "Haipei Xu"
    ],
    "abstract": "Recently, as Large Language Models (LLMs) have shown impressive emerging\ncapabilities and gained widespread popularity, research on LLM-based search\nagents has proliferated. In real-world situations, users often input contextual\nand highly personalized queries to chatbots, challenging LLMs to capture\ncontext and generate appropriate answers. However, much of the prior research\nhas not focused specifically on authentic human-machine dialogue scenarios. It\nalso ignores the important balance between response quality and computational\ncost by forcing all queries to follow the same agent process. To address these\ngaps, we propose a Strategy-Router Search Agent (SRSA), routing different\nqueries to appropriate search strategies and enabling fine-grained serial\nsearches to obtain high-quality results at a relatively low cost. To evaluate\nour work, we introduce a new dataset, Contextual Query Enhancement Dataset\n(CQED), comprising contextual queries to simulate authentic and daily\ninteractions between humans and chatbots. Using LLM-based automatic evaluation\nmetrics, we assessed SRSA's performance in terms of informativeness,\ncompleteness, novelty, and actionability. To conclude, SRSA provides an\napproach that resolves the issue of simple serial searches leading to\ndegenerate answers for lengthy and contextual queries, effectively and\nefficiently parses complex user queries, and generates more comprehensive and\ninformative responses without fine-tuning an LLM.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.14574v1",
    "published_date": "2024-11-21 20:41:55 UTC",
    "updated_date": "2024-11-21 20:41:55 UTC"
  },
  {
    "arxiv_id": "2411.14571v1",
    "title": "Assessment of LLM Responses to End-user Security Questions",
    "authors": [
      "Vijay Prakash",
      "Kevin Lee",
      "Arkaprabha Bhattacharya",
      "Danny Yuxing Huang",
      "Jessica Staddon"
    ],
    "abstract": "Answering end user security questions is challenging. While large language\nmodels (LLMs) like GPT, LLAMA, and Gemini are far from error-free, they have\nshown promise in answering a variety of questions outside of security. We\nstudied LLM performance in the area of end user security by qualitatively\nevaluating 3 popular LLMs on 900 systematically collected end user security\nquestions.\n  While LLMs demonstrate broad generalist ``knowledge'' of end user security\ninformation, there are patterns of errors and limitations across LLMs\nconsisting of stale and inaccurate answers, and indirect or unresponsive\ncommunication styles, all of which impacts the quality of information received.\nBased on these patterns, we suggest directions for model improvement and\nrecommend user strategies for interacting with LLMs when seeking assistance\nwith security.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL",
      "cs.HC"
    ],
    "primary_category": "cs.CR",
    "comment": "18 pages, 1 figure, 8 tables",
    "pdf_url": "http://arxiv.org/pdf/2411.14571v1",
    "published_date": "2024-11-21 20:36:36 UTC",
    "updated_date": "2024-11-21 20:36:36 UTC"
  },
  {
    "arxiv_id": "2411.15234v3",
    "title": "Adaptive Intelligence: leveraging insights from adaptive behavior in animals to build flexible AI systems",
    "authors": [
      "Mackenzie Weygandt Mathis"
    ],
    "abstract": "Biological intelligence is inherently adaptive -- animals continually adjust\ntheir actions based on environmental feedback. However, creating adaptive\nartificial intelligence (AI) remains a major challenge. The next frontier is to\ngo beyond traditional AI to develop \"adaptive intelligence,\" defined here as\nharnessing insights from biological intelligence to build agents that can learn\nonline, generalize, and rapidly adapt to changes in their environment. Recent\nadvances in neuroscience offer inspiration through studies that increasingly\nfocus on how animals naturally learn and adapt their world models. In this\nPerspective, I will review the behavioral and neural foundations of adaptive\nbiological intelligence, the parallel progress in AI, and explore\nbrain-inspired approaches for building more adaptive algorithms.",
    "categories": [
      "q-bio.NC",
      "cs.AI"
    ],
    "primary_category": "q-bio.NC",
    "comment": "10 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.15234v3",
    "published_date": "2024-11-21 20:26:29 UTC",
    "updated_date": "2025-03-23 16:59:23 UTC"
  },
  {
    "arxiv_id": "2411.14550v2",
    "title": "The importance of the clustering model to detect new types of intrusion in data traffic",
    "authors": [
      "Noor Saud Abd",
      "Noor Walid Khalid",
      "Basim Hussein Ali"
    ],
    "abstract": "In the current digital age, the volume of data generated by various cyber\nactivities has become enormous and is constantly increasing. The data may\ncontain valuable insights that can be harnessed to improve cyber security\nmeasures. However, much of this data is unclassified and qualitative, which\nposes significant challenges to traditional analysis methods. Clustering\nfacilitates the identification of hidden patterns and structures in data\nthrough grouping similar data points, which makes it simpler to identify and\naddress threats. Clustering can be defined as a data mining (DM) approach,\nwhich uses similarity calculations for dividing a data set into several\ncategories. Hierarchical, density-based, along with partitioning clustering\nalgorithms are typical. The presented work use K-means algorithm, which is a\npopular clustering technique. Utilizing K-means algorithm, we worked with two\ndifferent types of data: first, we gathered data with the use of XG-boost\nalgorithm following completing the aggregation with K-means algorithm. Data was\ngathered utilizing Kali Linux environment, cicflowmeter traffic, and Putty\nSoftware tools with the use of diverse and simple attacks. The concept could\nassist in identifying new attack types, which are distinct from the known\nattacks, and labeling them based on the characteristics they will exhibit, as\nthe dynamic nature regarding cyber threats means that new attack types often\nemerge, for which labeled data might not yet exist. The model counted the\nattacks and assigned numbers to each one of them. Secondly, We tried the same\nwork on the ready data inside the Kaggle repository called (Intrusion Detection\nin Internet of Things Network), and the clustering model worked well and\ndetected the number of attacks correctly as shown in the results section.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "18 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.14550v2",
    "published_date": "2024-11-21 19:40:31 UTC",
    "updated_date": "2025-03-26 14:42:39 UTC"
  },
  {
    "arxiv_id": "2411.15231v2",
    "title": "IterIS: Iterative Inference-Solving Alignment for LoRA Merging",
    "authors": [
      "Hongxu Chen",
      "Runshi Li",
      "Bowei Zhu",
      "Zhen Wang",
      "Long Chen"
    ],
    "abstract": "Low-rank adaptations (LoRA) are widely used to fine-tune large models across\nvarious domains for specific downstream tasks. While task-specific LoRAs are\noften available, concerns about data privacy and intellectual property can\nrestrict access to training data, limiting the acquisition of a multi-task\nmodel through gradient-based training. In response, LoRA merging presents an\neffective solution by combining multiple LoRAs into a unified adapter while\nmaintaining data privacy. Prior works on LoRA merging primarily frame it as an\noptimization problem, yet these approaches face several limitations, including\nthe rough assumption about input features utilized in optimization, massive\nsample requirements, and the unbalanced optimization objective. These\nlimitations can significantly degrade performance. To address these, we propose\na novel optimization-based method, named IterIS: 1) We formulate LoRA merging\nas an advanced optimization problem to mitigate the rough assumption.\nAdditionally, we employ an iterative inference-solving framework in our\nalgorithm. It can progressively refine the optimization objective for improved\nperformance. 2) We introduce an efficient regularization term to reduce the\nneed for massive sample requirements (requiring only 1-5% of the unlabeled\nsamples compared to prior methods). 3) We utilize adaptive weights in the\noptimization objective to mitigate potential unbalances in LoRA merging\nprocess. Our method demonstrates significant improvements over multiple\nbaselines and state-of-the-art methods in composing tasks for text-to-image\ndiffusion, vision-language models, and large language models. Furthermore, our\nlayer-wise algorithm can achieve convergence with minimal steps, ensuring\nefficiency in both memory and computation.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.15231v2",
    "published_date": "2024-11-21 19:04:02 UTC",
    "updated_date": "2025-04-15 01:42:54 UTC"
  },
  {
    "arxiv_id": "2411.16707v3",
    "title": "Enhancing LLMs for Power System Simulations: A Feedback-driven Multi-agent Framework",
    "authors": [
      "Mengshuo Jia",
      "Zeyu Cui",
      "Gabriela Hug"
    ],
    "abstract": "The integration of experimental technologies with large language models\n(LLMs) is transforming scientific research. It positions AI as a versatile\nresearch assistant rather than a mere problem-solving tool. In the field of\npower systems, however, managing simulations -- one of the essential\nexperimental technologies -- remains a challenge for LLMs due to their limited\ndomain-specific knowledge, restricted reasoning capabilities, and imprecise\nhandling of simulation parameters. To address these limitations, this paper\nproposes a feedback-driven, multi-agent framework. It incorporates three\nproposed modules: an enhanced retrieval-augmented generation (RAG) module, an\nimproved reasoning module, and a dynamic environmental acting module with an\nerror-feedback mechanism. Validated on 69 diverse tasks from Daline and\nMATPOWER, this framework achieves success rates of 93.13% and 96.85%,\nrespectively. It significantly outperforms ChatGPT 4o, o1-preview, and the\nfine-tuned GPT-4o, which all achieved a success rate lower than 30% on complex\ntasks. Additionally, the proposed framework also supports rapid, cost-effective\ntask execution, completing each simulation in approximately 30 seconds at an\naverage cost of 0.014 USD for tokens. Overall, this adaptable framework lays a\nfoundation for developing intelligent LLM-based assistants for human\nresearchers, facilitating power system research and beyond.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.MA",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.CL",
    "comment": "16 pages",
    "pdf_url": "http://arxiv.org/pdf/2411.16707v3",
    "published_date": "2024-11-21 19:01:07 UTC",
    "updated_date": "2025-05-19 15:51:40 UTC"
  },
  {
    "arxiv_id": "2411.14429v1",
    "title": "Revisiting the Integration of Convolution and Attention for Vision Backbone",
    "authors": [
      "Lei Zhu",
      "Xinjiang Wang",
      "Wayne Zhang",
      "Rynson W. H. Lau"
    ],
    "abstract": "Convolutions (Convs) and multi-head self-attentions (MHSAs) are typically\nconsidered alternatives to each other for building vision backbones. Although\nsome works try to integrate both, they apply the two operators simultaneously\nat the finest pixel granularity. With Convs responsible for per-pixel feature\nextraction already, the question is whether we still need to include the heavy\nMHSAs at such a fine-grained level. In fact, this is the root cause of the\nscalability issue w.r.t. the input resolution for vision transformers. To\naddress this important problem, we propose in this work to use MSHAs and Convs\nin parallel \\textbf{at different granularity levels} instead. Specifically, in\neach layer, we use two different ways to represent an image: a fine-grained\nregular grid and a coarse-grained set of semantic slots. We apply different\noperations to these two representations: Convs to the grid for local features,\nand MHSAs to the slots for global features. A pair of fully differentiable soft\nclustering and dispatching modules is introduced to bridge the grid and set\nrepresentations, thus enabling local-global fusion. Through extensive\nexperiments on various vision tasks, we empirically verify the potential of the\nproposed integration scheme, named \\textit{GLMix}: by offloading the burden of\nfine-grained features to light-weight Convs, it is sufficient to use MHSAs in a\nfew (e.g., 64) semantic slots to match the performance of recent\nstate-of-the-art backbones, while being more efficient. Our visualization\nresults also demonstrate that the soft clustering module produces a meaningful\nsemantic grouping effect with only IN1k classification supervision, which may\ninduce better interpretability and inspire new weakly-supervised semantic\nsegmentation approaches. Code will be available at\n\\url{https://github.com/rayleizhu/GLMix}.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2411.14429v1",
    "published_date": "2024-11-21 18:59:08 UTC",
    "updated_date": "2024-11-21 18:59:08 UTC"
  },
  {
    "arxiv_id": "2411.14425v1",
    "title": "Whack-a-Chip: The Futility of Hardware-Centric Export Controls",
    "authors": [
      "Ritwik Gupta",
      "Leah Walker",
      "Andrew W. Reddie"
    ],
    "abstract": "U.S. export controls on semiconductors are widely known to be permeable, with\nthe People's Republic of China (PRC) steadily creating state-of-the-art\nartificial intelligence (AI) models with exfiltrated chips. This paper presents\nthe first concrete, public evidence of how leading PRC AI labs evade and\ncircumvent U.S. export controls. We examine how Chinese companies, notably\nTencent, are not only using chips that are restricted under U.S. export\ncontrols but are also finding ways to circumvent these regulations by using\nsoftware and modeling techniques that maximize less capable hardware.\nSpecifically, we argue that Tencent's ability to power its Hunyuan-Large model\nwith non-export controlled NVIDIA H20s exemplifies broader gains in efficiency\nin machine learning that have eroded the moat that the United States initially\nbuilt via its existing export controls. Finally, we examine the implications of\nthis finding for the future of the United States' export control strategy.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.14425v1",
    "published_date": "2024-11-21 18:57:17 UTC",
    "updated_date": "2024-11-21 18:57:17 UTC"
  },
  {
    "arxiv_id": "2411.15230v1",
    "title": "A No Free Lunch Theorem for Human-AI Collaboration",
    "authors": [
      "Kenny Peng",
      "Nikhil Garg",
      "Jon Kleinberg"
    ],
    "abstract": "The gold standard in human-AI collaboration is complementarity -- when\ncombined performance exceeds both the human and algorithm alone. We investigate\nthis challenge in binary classification settings where the goal is to maximize\n0-1 accuracy. Given two or more agents who can make calibrated probabilistic\npredictions, we show a \"No Free Lunch\"-style result. Any deterministic\ncollaboration strategy (a function mapping calibrated probabilities into binary\nclassifications) that does not essentially always defer to the same agent will\nsometimes perform worse than the least accurate agent. In other words,\ncomplementarity cannot be achieved \"for free.\" The result does suggest one\nmodel of collaboration with guarantees, where one agent identifies \"obvious\"\nerrors of the other agent. We also use the result to understand the necessary\nconditions enabling the success of other collaboration techniques, providing\nguidance to human-AI collaboration.",
    "categories": [
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.15230v1",
    "published_date": "2024-11-21 18:46:03 UTC",
    "updated_date": "2024-11-21 18:46:03 UTC"
  },
  {
    "arxiv_id": "2411.14404v1",
    "title": "Resolving Multiple-Dynamic Model Uncertainty in Hypothesis-Driven Belief-MDPs",
    "authors": [
      "Ofer Dagan",
      "Tyler Becker",
      "Zachary N. Sunberg"
    ],
    "abstract": "When human operators of cyber-physical systems encounter surprising behavior,\nthey often consider multiple hypotheses that might explain it. In some cases,\ntaking information-gathering actions such as additional measurements or control\ninputs given to the system can help resolve uncertainty and determine the most\naccurate hypothesis. The task of optimizing these actions can be formulated as\na belief-space Markov decision process that we call a hypothesis-driven belief\nMDP. Unfortunately, this problem suffers from the curse of history similar to a\npartially observable Markov decision process (POMDP). To plan in continuous\ndomains, an agent needs to reason over countlessly many possible\naction-observation histories, each resulting in a different belief over the\nunknown state. The problem is exacerbated in the hypothesis-driven context\nbecause each action-observation pair spawns a different belief for each\nhypothesis, leading to additional branching. This paper considers the case in\nwhich each hypothesis corresponds to a different dynamic model in an underlying\nPOMDP. We present a new belief MDP formulation that: (i) enables reasoning over\nmultiple hypotheses, (ii) balances the goals of determining the (most likely)\ncorrect hypothesis and performing well in the underlying POMDP, and (iii) can\nbe solved with sparse tree search.",
    "categories": [
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "8 pages, 4 figures, submitted to AAMAS 2025",
    "pdf_url": "http://arxiv.org/pdf/2411.14404v1",
    "published_date": "2024-11-21 18:36:19 UTC",
    "updated_date": "2024-11-21 18:36:19 UTC"
  },
  {
    "arxiv_id": "2411.14403v1",
    "title": "Landing Trajectory Prediction for UAS Based on Generative Adversarial Network",
    "authors": [
      "Jun Xiang",
      "Drake Essick",
      "Luiz Gonzalez Bautista",
      "Junfei Xie",
      "Jun Chen"
    ],
    "abstract": "Models for trajectory prediction are an essential component of many advanced\nair mobility studies. These models help aircraft detect conflict and plan\navoidance maneuvers, which is especially important in Unmanned Aircraft systems\n(UAS) landing management due to the congested airspace near vertiports. In this\npaper, we propose a landing trajectory prediction model for UAS based on\nGenerative Adversarial Network (GAN). The GAN is a prestigious neural network\nthat has been developed for many years. In previous research, GAN has achieved\nmany state-of-the-art results in many generation tasks. The GAN consists of one\nneural network generator and a neural network discriminator. Because of the\nlearning capacity of the neural networks, the generator is capable to\nunderstand the features of the sample trajectory. The generator takes the\nprevious trajectory as input and outputs some random status of a flight.\nAccording to the results of the experiences, the proposed model can output more\naccurate predictions than the baseline method(GMR) in various datasets. To\nevaluate the proposed model, we also create a real UAV landing dataset that\nincludes more than 2600 trajectories of drone control manually by real pilots.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "9 pages, AIAA SCITECH 2023",
    "pdf_url": "http://arxiv.org/pdf/2411.14403v1",
    "published_date": "2024-11-21 18:34:33 UTC",
    "updated_date": "2024-11-21 18:34:33 UTC"
  },
  {
    "arxiv_id": "2411.14520v1",
    "title": "Open Challenges in the Formal Verification of Autonomous Driving",
    "authors": [
      "Paolo Burgio",
      "Angelo Ferrando",
      "Marco Villani"
    ],
    "abstract": "In the realm of autonomous driving, the development and integration of highly\ncomplex and heterogeneous systems are standard practice. Modern vehicles are\nnot monolithic systems; instead, they are composed of diverse hardware\ncomponents, each running its own software systems. An autonomous vehicle\ncomprises numerous independent components, often developed by different and\npotentially competing companies. This diversity poses significant challenges\nfor the certification process, as it necessitates certifying components that\nmay not disclose their internal behaviour (black-boxes). In this paper, we\npresent a real-world case study of an autonomous driving system, identify key\nopen challenges associated with its development and integration, and explore\nhow formal verification techniques can address these challenges to ensure\nsystem reliability and safety.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.DC",
      "cs.RO"
    ],
    "primary_category": "cs.SE",
    "comment": "In Proceedings FMAS2024, arXiv:2411.13215",
    "pdf_url": "http://arxiv.org/pdf/2411.14520v1",
    "published_date": "2024-11-21 18:09:35 UTC",
    "updated_date": "2024-11-21 18:09:35 UTC"
  },
  {
    "arxiv_id": "2411.14374v1",
    "title": "Using Formal Models, Safety Shields and Certified Control to Validate AI-Based Train Systems",
    "authors": [
      "Jan Gruteser",
      "Jan Roßbach",
      "Fabian Vu",
      "Michael Leuschel"
    ],
    "abstract": "The certification of autonomous systems is an important concern in science\nand industry. The KI-LOK project explores new methods for certifying and safely\nintegrating AI components into autonomous trains. We pursued a two-layered\napproach: (1) ensuring the safety of the steering system by formal analysis\nusing the B method, and (2) improving the reliability of the perception system\nwith a runtime certificate checker. This work links both strategies within a\ndemonstrator that runs simulations on the formal model, controlled by the real\nAI output and the real certificate checker. The demonstrator is integrated into\nthe validation tool ProB. This enables runtime monitoring, runtime\nverification, and statistical validation of formal safety properties using a\nformal B model. Consequently, one can detect and analyse potential\nvulnerabilities and weaknesses of the AI and the certificate checker. We apply\nthese techniques to a signal detection case study and present our findings.",
    "categories": [
      "cs.LO",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LO",
    "comment": "In Proceedings FMAS2024, arXiv:2411.13215",
    "pdf_url": "http://arxiv.org/pdf/2411.14374v1",
    "published_date": "2024-11-21 18:09:04 UTC",
    "updated_date": "2024-11-21 18:09:04 UTC"
  },
  {
    "arxiv_id": "2411.14371v1",
    "title": "Synthesising Robust Controllers for Robot Collectives with Recurrent Tasks: A Case Study",
    "authors": [
      "Till Schnittka",
      "Mario Gleirscher"
    ],
    "abstract": "When designing correct-by-construction controllers for autonomous\ncollectives, three key challenges are the task specification, the modelling,\nand its use at practical scale. In this paper, we focus on a simple yet useful\nabstraction for high-level controller synthesis for robot collectives with\noptimisation goals (e.g., maximum cleanliness, minimum energy consumption) and\nrecurrence (e.g., re-establish contamination and charge thresholds) and safety\n(e.g., avoid full discharge, mutually exclusive room occupation) constraints.\nDue to technical limitations (related to scalability and using constraints in\nthe synthesis), we simplify our graph-based setting from a stochastic\ntwo-player game into a single-player game on a partially observable Markov\ndecision process (POMDP). Robustness against environmental uncertainty is\nencoded via partial observability. Linear-time correctness properties are\nverified separately after synthesising the POMDP strategy. We contribute\nat-scale guidance on POMDP modelling and controller synthesis for tasked robot\ncollectives exemplified by the scenario of battery-driven robots responsible\nfor cleaning public buildings with utilisation constraints.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.MA",
    "comment": "In Proceedings FMAS2024, arXiv:2411.13215",
    "pdf_url": "http://arxiv.org/pdf/2411.14371v1",
    "published_date": "2024-11-21 18:08:18 UTC",
    "updated_date": "2024-11-21 18:08:18 UTC"
  },
  {
    "arxiv_id": "2411.14368v1",
    "title": "RV4Chatbot: Are Chatbots Allowed to Dream of Electric Sheep?",
    "authors": [
      "Andrea Gatti",
      "Viviana Mascardi",
      "Angelo Ferrando"
    ],
    "abstract": "Chatbots have become integral to various application domains, including those\nwith safety-critical considerations. As a result, there is a pressing need for\nmethods that ensure chatbots consistently adhere to expected, safe behaviours.\nIn this paper, we introduce RV4Chatbot, a Runtime Verification framework\ndesigned to monitor deviations in chatbot behaviour. We formalise expected\nbehaviours as interaction protocols between the user and the chatbot. We\npresent the RV4Chatbot design and describe two implementations that instantiate\nit: RV4Rasa, for monitoring chatbots created with the Rasa framework, and\nRV4Dialogflow, for monitoring Dialogflow chatbots. Additionally, we detail\nexperiments conducted in a factory automation scenario using both RV4Rasa and\nRV4Dialogflow.",
    "categories": [
      "cs.AI",
      "cs.HC",
      "cs.SE"
    ],
    "primary_category": "cs.AI",
    "comment": "In Proceedings FMAS2024, arXiv:2411.13215",
    "pdf_url": "http://arxiv.org/pdf/2411.14368v1",
    "published_date": "2024-11-21 18:07:46 UTC",
    "updated_date": "2024-11-21 18:07:46 UTC"
  },
  {
    "arxiv_id": "2411.14367v1",
    "title": "ROSMonitoring 2.0: Extending ROS Runtime Verification to Services and Ordered Topics",
    "authors": [
      "Maryam Ghaffari Saadat",
      "Angelo Ferrando",
      "Louise A. Dennis",
      "Michael Fisher"
    ],
    "abstract": "Formal verification of robotic applications presents challenges due to their\nhybrid nature and distributed architecture. This paper introduces ROSMonitoring\n2.0, an extension of ROSMonitoring designed to facilitate the monitoring of\nboth topics and services while considering the order in which messages are\npublished and received. The framework has been enhanced to support these novel\nfeatures for ROS1 -- and partially ROS2 environments -- offering improved\nreal-time support, security, scalability, and interoperability. We discuss the\nmodifications made to accommodate these advancements and present results\nobtained from a case study involving the runtime monitoring of specific\ncomponents of a fire-fighting Uncrewed Aerial Vehicle (UAV).",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.SE",
    "comment": "In Proceedings FMAS2024, arXiv:2411.13215",
    "pdf_url": "http://arxiv.org/pdf/2411.14367v1",
    "published_date": "2024-11-21 18:07:31 UTC",
    "updated_date": "2024-11-21 18:07:31 UTC"
  },
  {
    "arxiv_id": "2411.14354v1",
    "title": "Contrasting local and global modeling with machine learning and satellite data: A case study estimating tree canopy height in African savannas",
    "authors": [
      "Esther Rolf",
      "Lucia Gordon",
      "Milind Tambe",
      "Andrew Davies"
    ],
    "abstract": "While advances in machine learning with satellite imagery (SatML) are\nfacilitating environmental monitoring at a global scale, developing SatML\nmodels that are accurate and useful for local regions remains critical to\nunderstanding and acting on an ever-changing planet. As increasing attention\nand resources are being devoted to training SatML models with global data, it\nis important to understand when improvements in global models will make it\neasier to train or fine-tune models that are accurate in specific regions. To\nexplore this question, we contrast local and global training paradigms for\nSatML through a case study of tree canopy height (TCH) mapping in the Karingani\nGame Reserve, Mozambique. We find that recent advances in global TCH mapping do\nnot necessarily translate to better local modeling abilities in our study\nregion. Specifically, small models trained only with locally-collected data\noutperform published global TCH maps, and even outperform globally pretrained\nmodels that we fine-tune using local data. Analyzing these results further, we\nidentify specific points of conflict and synergy between local and global\nmodeling paradigms that can inform future research toward aligning local and\nglobal performance objectives in geospatial machine learning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "31 pages; 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.14354v1",
    "published_date": "2024-11-21 17:53:27 UTC",
    "updated_date": "2024-11-21 17:53:27 UTC"
  },
  {
    "arxiv_id": "2411.14343v1",
    "title": "UnifiedCrawl: Aggregated Common Crawl for Affordable Adaptation of LLMs on Low-Resource Languages",
    "authors": [
      "Bethel Melesse Tessema",
      "Akhil Kedia",
      "Tae-Sun Chung"
    ],
    "abstract": "Large language models (LLMs) under-perform on low-resource languages due to\nlimited training data. We present a method to efficiently collect text data for\nlow-resource languages from the entire Common Crawl corpus. Our approach,\nUnifiedCrawl, filters and extracts common crawl using minimal compute\nresources, yielding mono-lingual datasets much larger than previously available\nsources. We demonstrate that leveraging this data to fine-tuning multilingual\nLLMs via efficient adapter methods (QLoRA) significantly boosts performance on\nthe low-resource language, while minimizing VRAM usage. Our experiments show\nlarge improvements in language modeling perplexity and an increase in few-shot\nprompting scores. Our work and released source code provide an affordable\napproach to improve LLMs for low-resource languages using consumer hardware.\nOur source code is available here at\nhttps://github.com/bethelmelesse/unifiedcrawl.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "68T50",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.14343v1",
    "published_date": "2024-11-21 17:41:08 UTC",
    "updated_date": "2024-11-21 17:41:08 UTC"
  },
  {
    "arxiv_id": "2412.00036v3",
    "title": "Beyond Monte Carlo: Harnessing Diffusion Models to Simulate Financial Market Dynamics",
    "authors": [
      "Andrew Lesniewski",
      "Giulio Trigila"
    ],
    "abstract": "We propose a highly efficient and accurate methodology for generating\nsynthetic financial market data using a diffusion model approach. The synthetic\ndata produced by our methodology align closely with observed market data in\nseveral key aspects: (i) they pass the two-sample Cramer - von Mises test for\nportfolios of assets, and (ii) Q - Q plots demonstrate consistency across\nquantiles, including in the tails, between observed and generated market data.\nMoreover, the covariance matrices derived from a large set of synthetic market\ndata exhibit significantly lower condition numbers compared to the estimated\ncovariance matrices of the observed data. This property makes them suitable for\nuse as regularized versions of the latter. For model training, we develop an\nefficient and fast algorithm based on numerical integration rather than Monte\nCarlo simulations. The methodology is tested on a large set of equity data.",
    "categories": [
      "q-fin.CP",
      "cs.AI",
      "cs.CE",
      "q-fin.PM"
    ],
    "primary_category": "q-fin.CP",
    "comment": "27 pages",
    "pdf_url": "http://arxiv.org/pdf/2412.00036v3",
    "published_date": "2024-11-21 17:39:23 UTC",
    "updated_date": "2025-02-02 20:31:25 UTC"
  },
  {
    "arxiv_id": "2411.14303v2",
    "title": "BugSpotter: Automated Generation of Code Debugging Exercises",
    "authors": [
      "Victor-Alexandru Pădurean",
      "Paul Denny",
      "Adish Singla"
    ],
    "abstract": "Debugging is an essential skill when learning to program, yet its instruction\nand emphasis often vary widely across introductory courses. In the era of\ncode-generating large language models (LLMs), the ability for students to\nreason about code and identify errors is increasingly important. However,\nstudents frequently resort to trial-and-error methods to resolve bugs without\nfully understanding the underlying issues. Developing the ability to identify\nand hypothesize the cause of bugs is crucial but can be time-consuming to teach\neffectively through traditional means. This paper introduces BugSpotter, an\ninnovative tool that leverages an LLM to generate buggy code from a problem\ndescription and verify the synthesized bugs via a test suite. Students interact\nwith BugSpotter by designing failing test cases, where the buggy code's output\ndiffers from the expected result as defined by the problem specification. This\nnot only provides opportunities for students to enhance their debugging skills,\nbut also to practice reading and understanding problem specifications. We\ndeployed BugSpotter in a large classroom setting and compared the debugging\nexercises it generated to exercises hand-crafted by an instructor for the same\nproblems. We found that the LLM-generated exercises produced by BugSpotter\nvaried in difficulty and were well-matched to the problem specifications.\nImportantly, the LLM-generated exercises were comparable to those manually\ncreated by instructors with respect to student performance, suggesting that\nBugSpotter could be an effective and efficient aid for learning debugging.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "Preprint of the SIGCSE'25 paper",
    "pdf_url": "http://arxiv.org/pdf/2411.14303v2",
    "published_date": "2024-11-21 16:56:33 UTC",
    "updated_date": "2024-11-25 08:31:00 UTC"
  },
  {
    "arxiv_id": "2411.14277v1",
    "title": "Neuro-Symbolic Query Optimization in Knowledge Graphs",
    "authors": [
      "Maribel Acosta",
      "Chang Qin",
      "Tim Schwabe"
    ],
    "abstract": "This chapter delves into the emerging field of neuro-symbolic query\noptimization for knowledge graphs (KGs), presenting a comprehensive exploration\nof how neural and symbolic techniques can be integrated to enhance query\nprocessing. Traditional query optimizers in knowledge graphs rely heavily on\nsymbolic methods, utilizing dataset summaries, statistics, and cost models to\nselect efficient execution plans. However, these approaches often suffer from\nmisestimations and inaccuracies, particularly when dealing with complex queries\nor large-scale datasets. Recent advancements have introduced neural models,\nwhich capture non-linear aspects of query optimization, offering promising\nalternatives to purely symbolic methods. In this chapter, we introduce\nneuro-symbolic query optimizers, a novel approach that combines the strengths\nof symbolic reasoning with the adaptability of neural computation. We discuss\nthe architecture of these hybrid systems, highlighting the interplay between\nneural and symbolic components to improve the optimizer's ability to navigate\nthe search space and produce efficient execution plans. Additionally, the\nchapter reviews existing neural components tailored for optimizing queries over\nknowledge graphs and examines the limitations and challenges in deploying\nneuro-symbolic query optimizers in real-world environments.",
    "categories": [
      "cs.DB",
      "cs.AI",
      "H.2; I.2"
    ],
    "primary_category": "cs.DB",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.14277v1",
    "published_date": "2024-11-21 16:31:27 UTC",
    "updated_date": "2024-11-21 16:31:27 UTC"
  },
  {
    "arxiv_id": "2411.14263v1",
    "title": "Generating Realistic Adversarial Examples for Business Processes using Variational Autoencoders",
    "authors": [
      "Alexander Stevens",
      "Jari Peeperkorn",
      "Johannes De Smedt",
      "Jochen De Weerdt"
    ],
    "abstract": "In predictive process monitoring, predictive models are vulnerable to\nadversarial attacks, where input perturbations can lead to incorrect\npredictions. Unlike in computer vision, where these perturbations are designed\nto be imperceptible to the human eye, the generation of adversarial examples in\npredictive process monitoring poses unique challenges. Minor changes to the\nactivity sequences can create improbable or even impossible scenarios to occur\ndue to underlying constraints such as regulatory rules or process constraints.\nTo address this, we focus on generating realistic adversarial examples tailored\nto the business process context, in contrast to the imperceptible, pixel-level\nchanges commonly seen in computer vision adversarial attacks. This paper\nintroduces two novel latent space attacks, which generate adversaries by adding\nnoise to the latent space representation of the input data, rather than\ndirectly modifying the input attributes. These latent space methods are\ndomain-agnostic and do not rely on process-specific knowledge, as we restrict\nthe generation of adversarial examples to the learned class-specific data\ndistributions by directly perturbing the latent space representation of the\nbusiness process executions. We evaluate these two latent space methods with\nsix other adversarial attacking methods on eleven real-life event logs and four\npredictive models. The first three attacking methods directly permute the\nactivities of the historically observed business process executions. The fourth\nmethod constrains the adversarial examples to lie within the same data\ndistribution as the original instances, by projecting the adversarial examples\nto the original data distribution.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.14263v1",
    "published_date": "2024-11-21 16:18:52 UTC",
    "updated_date": "2024-11-21 16:18:52 UTC"
  },
  {
    "arxiv_id": "2411.14258v1",
    "title": "Knowledge Graphs, Large Language Models, and Hallucinations: An NLP Perspective",
    "authors": [
      "Ernests Lavrinovics",
      "Russa Biswas",
      "Johannes Bjerva",
      "Katja Hose"
    ],
    "abstract": "Large Language Models (LLMs) have revolutionized Natural Language Processing\n(NLP) based applications including automated text generation, question\nanswering, chatbots, and others. However, they face a significant challenge:\nhallucinations, where models produce plausible-sounding but factually incorrect\nresponses. This undermines trust and limits the applicability of LLMs in\ndifferent domains. Knowledge Graphs (KGs), on the other hand, provide a\nstructured collection of interconnected facts represented as entities (nodes)\nand their relationships (edges). In recent research, KGs have been leveraged to\nprovide context that can fill gaps in an LLM understanding of certain topics\noffering a promising approach to mitigate hallucinations in LLMs, enhancing\ntheir reliability and accuracy while benefiting from their wide applicability.\nNonetheless, it is still a very active area of research with various unresolved\nopen problems. In this paper, we discuss these open challenges covering\nstate-of-the-art datasets and benchmarks as well as methods for knowledge\nintegration and evaluating hallucinations. In our discussion, we consider the\ncurrent use of KGs in LLM systems and identify future directions within each of\nthese challenges.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "68-02",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "7 pages, 2 Figures, 1 Table",
    "pdf_url": "http://arxiv.org/pdf/2411.14258v1",
    "published_date": "2024-11-21 16:09:05 UTC",
    "updated_date": "2024-11-21 16:09:05 UTC"
  },
  {
    "arxiv_id": "2411.14257v2",
    "title": "Do I Know This Entity? Knowledge Awareness and Hallucinations in Language Models",
    "authors": [
      "Javier Ferrando",
      "Oscar Obeso",
      "Senthooran Rajamanoharan",
      "Neel Nanda"
    ],
    "abstract": "Hallucinations in large language models are a widespread problem, yet the\nmechanisms behind whether models will hallucinate are poorly understood,\nlimiting our ability to solve this problem. Using sparse autoencoders as an\ninterpretability tool, we discover that a key part of these mechanisms is\nentity recognition, where the model detects if an entity is one it can recall\nfacts about. Sparse autoencoders uncover meaningful directions in the\nrepresentation space, these detect whether the model recognizes an entity, e.g.\ndetecting it doesn't know about an athlete or a movie. This suggests that\nmodels can have self-knowledge: internal representations about their own\ncapabilities. These directions are causally relevant: capable of steering the\nmodel to refuse to answer questions about known entities, or to hallucinate\nattributes of unknown entities when it would otherwise refuse. We demonstrate\nthat despite the sparse autoencoders being trained on the base model, these\ndirections have a causal effect on the chat model's refusal behavior,\nsuggesting that chat finetuning has repurposed this existing mechanism.\nFurthermore, we provide an initial exploration into the mechanistic role of\nthese directions in the model, finding that they disrupt the attention of\ndownstream heads that typically move entity attributes to the final token.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2411.14257v2",
    "published_date": "2024-11-21 16:05:58 UTC",
    "updated_date": "2025-02-08 12:50:42 UTC"
  },
  {
    "arxiv_id": "2411.14254v1",
    "title": "BERT-Based Approach for Automating Course Articulation Matrix Construction with Explainable AI",
    "authors": [
      "Natenaile Asmamaw Shiferaw",
      "Simpenzwe Honore Leandre",
      "Aman Sinha",
      "Dillip Rout"
    ],
    "abstract": "Course Outcome (CO) and Program Outcome (PO)/Program-Specific Outcome (PSO)\nalignment is a crucial task for ensuring curriculum coherence and assessing\neducational effectiveness. The construction of a Course Articulation Matrix\n(CAM), which quantifies the relationship between COs and POs/PSOs, typically\ninvolves assigning numerical values (0, 1, 2, 3) to represent the degree of\nalignment. In this study, We experiment with four models from the BERT family:\nBERT Base, DistilBERT, ALBERT, and RoBERTa, and use multiclass classification\nto assess the alignment between CO and PO/PSO pairs. We first evaluate\ntraditional machine learning classifiers, such as Decision Tree, Random Forest,\nand XGBoost, and then apply transfer learning to evaluate the performance of\nthe pretrained BERT models. To enhance model interpretability, we apply\nExplainable AI technique, specifically Local Interpretable Model-agnostic\nExplanations (LIME), to provide transparency into the decision-making process.\nOur system achieves accuracy, precision, recall, and F1-score values of 98.66%,\n98.67%, 98.66%, and 98.66%, respectively. This work demonstrates the potential\nof utilizing transfer learning with BERT-based models for the automated\ngeneration of CAMs, offering high performance and interpretability in\neducational outcome assessment.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "26 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.14254v1",
    "published_date": "2024-11-21 16:02:39 UTC",
    "updated_date": "2024-11-21 16:02:39 UTC"
  },
  {
    "arxiv_id": "2411.14252v1",
    "title": "Intent-Aware Dialogue Generation and Multi-Task Contrastive Learning for Multi-Turn Intent Classification",
    "authors": [
      "Junhua Liu",
      "Yong Keat Tan",
      "Bin Fu",
      "Kwan Hui Lim"
    ],
    "abstract": "Generating large-scale, domain-specific, multilingual multi-turn dialogue\ndatasets remains a significant hurdle for training effective Multi-Turn Intent\nClassification models in chatbot systems. In this paper, we introduce\nChain-of-Intent, a novel mechanism that combines Hidden Markov Models with\nLarge Language Models (LLMs) to generate contextually aware, intent-driven\nconversations through self-play. By extracting domain-specific knowledge from\ne-commerce chat logs, we estimate conversation turns and intent transitions,\nwhich guide the generation of coherent dialogues. Leveraging LLMs to enhance\nemission probabilities, our approach produces natural and contextually\nconsistent questions and answers. We also propose MINT-CL, a framework for\nmulti-turn intent classification using multi-task contrastive learning,\nimproving classification accuracy without the need for extensive annotated\ndata. Evaluations show that our methods outperform baselines in dialogue\nquality and intent classification accuracy, especially in multilingual\nsettings, while significantly reducing data generation efforts. Furthermore, we\nrelease MINT-E, a multilingual, intent-aware multi-turn e-commerce dialogue\ncorpus to support future research in this area.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.14252v1",
    "published_date": "2024-11-21 15:59:29 UTC",
    "updated_date": "2024-11-21 15:59:29 UTC"
  },
  {
    "arxiv_id": "2411.14251v2",
    "title": "Natural Language Reinforcement Learning",
    "authors": [
      "Xidong Feng",
      "Bo Liu",
      "Ziyu Wan",
      "Haotian Fu",
      "Girish A. Koushik",
      "Zhiyuan Hu",
      "Mengyue Yang",
      "Ying Wen",
      "Jun Wang"
    ],
    "abstract": "Reinforcement Learning (RL) mathematically formulates decision-making with\nMarkov Decision Process (MDP). With MDPs, researchers have achieved remarkable\nbreakthroughs across various domains, including games, robotics, and language\nmodels. This paper seeks a new possibility, Natural Language Reinforcement\nLearning (NLRL), by extending traditional MDP to natural language-based\nrepresentation space. Specifically, NLRL innovatively redefines RL principles,\nincluding task objectives, policy, value function, Bellman equation, and policy\niteration, into their language counterparts. With recent advancements in large\nlanguage models (LLMs), NLRL can be practically implemented to achieve RL-like\npolicy and value improvement by either pure prompting or gradient-based\ntraining. Experiments over Maze, Breakthrough, and Tic-Tac-Toe games\ndemonstrate the effectiveness, efficiency, and interpretability of the NLRL\nframework among diverse use cases.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at ICLR 2025 Workshop SSI-FM",
    "pdf_url": "http://arxiv.org/pdf/2411.14251v2",
    "published_date": "2024-11-21 15:57:02 UTC",
    "updated_date": "2025-05-15 03:35:25 UTC"
  },
  {
    "arxiv_id": "2411.14243v2",
    "title": "AnywhereDoor: Multi-Target Backdoor Attacks on Object Detection",
    "authors": [
      "Jialin Lu",
      "Junjie Shan",
      "Ziqi Zhao",
      "Ka-Ho Chow"
    ],
    "abstract": "As object detection becomes integral to many safety-critical applications,\nunderstanding its vulnerabilities is essential. Backdoor attacks, in\nparticular, pose a serious threat by implanting hidden triggers in victim\nmodels, which adversaries can later exploit to induce malicious behaviors\nduring inference. However, current understanding is limited to single-target\nattacks, where adversaries must define a fixed malicious behavior (target)\nbefore training, making inference-time adaptability impossible. Given the large\noutput space of object detection (including object existence prediction,\nbounding box estimation, and classification), the feasibility of flexible,\ninference-time model control remains unexplored. This paper introduces\nAnywhereDoor, a multi-target backdoor attack for object detection. Once\nimplanted, AnywhereDoor allows adversaries to make objects disappear, fabricate\nnew ones, or mislabel them, either across all object classes or specific ones,\noffering an unprecedented degree of control. This flexibility is enabled by\nthree key innovations: (i) objective disentanglement to scale the number of\nsupported targets; (ii) trigger mosaicking to ensure robustness even against\nregion-based detectors; and (iii) strategic batching to address object-level\ndata imbalances that hinder manipulation. Extensive experiments demonstrate\nthat AnywhereDoor grants attackers a high degree of control, improving attack\nsuccess rates by 26% compared to adaptations of existing methods for such\nflexible control.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CR",
    "comment": "15 pages; This update was mistakenly uploaded as a new manuscript on\n  arXiv (2503.06529). The wrong submission has now been withdrawn, and we\n  replace the old one here",
    "pdf_url": "http://arxiv.org/pdf/2411.14243v2",
    "published_date": "2024-11-21 15:50:59 UTC",
    "updated_date": "2025-03-14 04:12:52 UTC"
  },
  {
    "arxiv_id": "2411.14219v1",
    "title": "Towards Context-Rich Automated Biodiversity Assessments: Deriving AI-Powered Insights from Camera Trap Data",
    "authors": [
      "Paul Fergus",
      "Carl Chalmers",
      "Naomi Matthews",
      "Stuart Nixon",
      "Andre Burger",
      "Oliver Hartley",
      "Chris Sutherland",
      "Xavier Lambin",
      "Steven Longmore",
      "Serge Wich"
    ],
    "abstract": "Camera traps offer enormous new opportunities in ecological studies, but\ncurrent automated image analysis methods often lack the contextual richness\nneeded to support impactful conservation outcomes. Here we present an\nintegrated approach that combines deep learning-based vision and language\nmodels to improve ecological reporting using data from camera traps. We\nintroduce a two-stage system: YOLOv10-X to localise and classify species\n(mammals and birds) within images, and a Phi-3.5-vision-instruct model to read\nYOLOv10-X binding box labels to identify species, overcoming its limitation\nwith hard to classify objects in images. Additionally, Phi-3.5 detects broader\nvariables, such as vegetation type, and time of day, providing rich ecological\nand environmental context to YOLO's species detection output. When combined,\nthis output is processed by the model's natural language system to answer\ncomplex queries, and retrieval-augmented generation (RAG) is employed to enrich\nresponses with external information, like species weight and IUCN status\n(information that cannot be obtained through direct visual analysis). This\ninformation is used to automatically generate structured reports, providing\nbiodiversity stakeholders with deeper insights into, for example, species\nabundance, distribution, animal behaviour, and habitat selection. Our approach\ndelivers contextually rich narratives that aid in wildlife management\ndecisions. By providing contextually rich insights, our approach not only\nreduces manual effort but also supports timely decision-making in conservation,\npotentially shifting efforts from reactive to proactive management.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "32 Pages, 22 images",
    "pdf_url": "http://arxiv.org/pdf/2411.14219v1",
    "published_date": "2024-11-21 15:28:52 UTC",
    "updated_date": "2024-11-21 15:28:52 UTC"
  },
  {
    "arxiv_id": "2411.14215v1",
    "title": "Evaluating the Robustness of Analogical Reasoning in Large Language Models",
    "authors": [
      "Martha Lewis",
      "Melanie Mitchell"
    ],
    "abstract": "LLMs have performed well on several reasoning benchmarks, including ones that\ntest analogical reasoning abilities. However, there is debate on the extent to\nwhich they are performing general abstract reasoning versus employing\nnon-robust processes, e.g., that overly rely on similarity to pre-training\ndata. Here we investigate the robustness of analogy-making abilities previously\nclaimed for LLMs on three of four domains studied by Webb, Holyoak, and Lu\n(2023): letter-string analogies, digit matrices, and story analogies. For each\ndomain we test humans and GPT models on robustness to variants of the original\nanalogy problems that test the same abstract reasoning abilities but are likely\ndissimilar from tasks in the pre-training data. The performance of a system\nthat uses robust abstract reasoning should not decline substantially on these\nvariants.\n  On simple letter-string analogies, we find that while the performance of\nhumans remains high for two types of variants we tested, the GPT models'\nperformance declines sharply. This pattern is less pronounced as the complexity\nof these problems is increased, as both humans and GPT models perform poorly on\nboth the original and variant problems requiring more complex analogies. On\ndigit-matrix problems, we find a similar pattern but only on one out of the two\ntypes of variants we tested. On story-based analogy problems, we find that,\nunlike humans, the performance of GPT models are susceptible to answer-order\neffects, and that GPT models also may be more sensitive than humans to\nparaphrasing.\n  This work provides evidence that LLMs often lack the robustness of zero-shot\nhuman analogy-making, exhibiting brittleness on most of the variations we\ntested. More generally, this work points to the importance of carefully\nevaluating AI systems not only for accuracy but also robustness when testing\ntheir cognitive capabilities.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "31 pages, 13 figures. arXiv admin note: text overlap with\n  arXiv:2402.08955",
    "pdf_url": "http://arxiv.org/pdf/2411.14215v1",
    "published_date": "2024-11-21 15:25:08 UTC",
    "updated_date": "2024-11-21 15:25:08 UTC"
  },
  {
    "arxiv_id": "2411.14214v1",
    "title": "Physics-Informed LLM-Agent for Automated Modulation Design in Power Electronics Systems",
    "authors": [
      "Junhua Liu",
      "Fanfan Lin",
      "Xinze Li",
      "Kwan Hui Lim",
      "Shuai Zhao"
    ],
    "abstract": "LLM-based autonomous agents have demonstrated outstanding performance in\nsolving complex industrial tasks. However, in the pursuit of carbon neutrality\nand high-performance renewable energy systems, existing AI-assisted design\nautomation faces significant limitations in explainability, scalability, and\nusability. To address these challenges, we propose LP-COMDA, an LLM-based,\nphysics-informed autonomous agent that automates the modulation design of power\nconverters in Power Electronics Systems with minimal human supervision. Unlike\ntraditional AI-assisted approaches, LP-COMDA contains an LLM-based planner that\ngathers and validates design specifications through a user-friendly chat\ninterface. The planner then coordinates with physics-informed design and\noptimization tools to iteratively generate and refine modulation designs\nautonomously. Through the chat interface, LP-COMDA provides an explainable\ndesign process, presenting explanations and charts. Experiments show that\nLP-COMDA outperforms all baseline methods, achieving a 63.2% reduction in error\ncompared to the second-best benchmark method in terms of standard mean absolute\nerror. Furthermore, empirical studies with 20 experts conclude that design time\nwith LP-COMDA is over 33 times faster than conventional methods, showing its\nsignificant improvement on design efficiency over the current processes.",
    "categories": [
      "cs.AI",
      "cs.ET"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.14214v1",
    "published_date": "2024-11-21 15:24:41 UTC",
    "updated_date": "2024-11-21 15:24:41 UTC"
  },
  {
    "arxiv_id": "2411.14207v2",
    "title": "HARP: A Large-Scale Higher-Order Ambisonic Room Impulse Response Dataset",
    "authors": [
      "Shivam Saini",
      "Jürgen Peissig"
    ],
    "abstract": "This contribution introduces a dataset of 7th-order Ambisonic Room Impulse\nResponses (HOA-RIRs), created using the Image Source Method. By employing\nhigher-order Ambisonics, our dataset enables precise spatial audio\nreproduction, a critical requirement for realistic immersive audio\napplications. Leveraging the virtual simulation, we present a unique microphone\nconfiguration, based on the superposition principle, designed to optimize sound\nfield coverage while addressing the limitations of traditional microphone\narrays. The presented 64-microphone configuration allows us to capture RIRs\ndirectly in the Spherical Harmonics domain. The dataset features a wide range\nof room configurations, encompassing variations in room geometry, acoustic\nabsorption materials, and source-receiver distances. A detailed description of\nthe simulation setup is provided alongside for an accurate reproduction. The\ndataset serves as a vital resource for researchers working on spatial audio,\nparticularly in applications involving machine learning to improve room\nacoustics modeling and sound field synthesis. It further provides a very high\nlevel of spatial resolution and realism crucial for tasks such as source\nlocalization, reverberation prediction, and immersive sound reproduction.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.MM",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Accepted at ICASSP 2025 Workshop. Code to generate uploaded at:\n  https://github.com/whojavumusic/HARP",
    "pdf_url": "http://arxiv.org/pdf/2411.14207v2",
    "published_date": "2024-11-21 15:16:48 UTC",
    "updated_date": "2025-01-19 11:15:34 UTC"
  },
  {
    "arxiv_id": "2411.14205v1",
    "title": "Is this Generated Person Existed in Real-world? Fine-grained Detecting and Calibrating Abnormal Human-body",
    "authors": [
      "Zeqing Wang",
      "Qingyang Ma",
      "Wentao Wan",
      "Haojie Li",
      "Keze Wang",
      "Yonghong Tian"
    ],
    "abstract": "Recent improvements in visual synthesis have significantly enhanced the\ndepiction of generated human photos, which are pivotal due to their wide\napplicability and demand. Nonetheless, the existing text-to-image or\ntext-to-video models often generate low-quality human photos that might differ\nconsiderably from real-world body structures, referred to as \"abnormal human\nbodies\". Such abnormalities, typically deemed unacceptable, pose considerable\nchallenges in the detection and repair of them within human photos. These\nchallenges require precise abnormality recognition capabilities, which entail\npinpointing both the location and the abnormality type. Intuitively, Visual\nLanguage Models (VLMs) that have obtained remarkable performance on various\nvisual tasks are quite suitable for this task. However, their performance on\nabnormality detection in human photos is quite poor. Hence, it is quite\nimportant to highlight this task for the research community. In this paper, we\nfirst introduce a simple yet challenging task, i.e., \\textbf{F}ine-grained\n\\textbf{H}uman-body \\textbf{A}bnormality \\textbf{D}etection \\textbf{(FHAD)},\nand construct two high-quality datasets for evaluation. Then, we propose a\nmeticulous framework, named HumanCalibrator, which identifies and repairs\nabnormalities in human body structures while preserving the other content.\nExperiments indicate that our HumanCalibrator achieves high accuracy in\nabnormality detection and accomplishes an increase in visual comparisons while\npreserving the other visual content.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "16 pages, 14 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.14205v1",
    "published_date": "2024-11-21 15:13:38 UTC",
    "updated_date": "2024-11-21 15:13:38 UTC"
  },
  {
    "arxiv_id": "2411.14199v1",
    "title": "OpenScholar: Synthesizing Scientific Literature with Retrieval-augmented LMs",
    "authors": [
      "Akari Asai",
      "Jacqueline He",
      "Rulin Shao",
      "Weijia Shi",
      "Amanpreet Singh",
      "Joseph Chee Chang",
      "Kyle Lo",
      "Luca Soldaini",
      "Sergey Feldman",
      "Mike D'arcy",
      "David Wadden",
      "Matt Latzke",
      "Minyang Tian",
      "Pan Ji",
      "Shengyan Liu",
      "Hao Tong",
      "Bohao Wu",
      "Yanyu Xiong",
      "Luke Zettlemoyer",
      "Graham Neubig",
      "Dan Weld",
      "Doug Downey",
      "Wen-tau Yih",
      "Pang Wei Koh",
      "Hannaneh Hajishirzi"
    ],
    "abstract": "Scientific progress depends on researchers' ability to synthesize the growing\nbody of literature. Can large language models (LMs) assist scientists in this\ntask? We introduce OpenScholar, a specialized retrieval-augmented LM that\nanswers scientific queries by identifying relevant passages from 45 million\nopen-access papers and synthesizing citation-backed responses. To evaluate\nOpenScholar, we develop ScholarQABench, the first large-scale multi-domain\nbenchmark for literature search, comprising 2,967 expert-written queries and\n208 long-form answers across computer science, physics, neuroscience, and\nbiomedicine. On ScholarQABench, OpenScholar-8B outperforms GPT-4o by 5% and\nPaperQA2 by 7% in correctness, despite being a smaller, open model. While GPT4o\nhallucinates citations 78 to 90% of the time, OpenScholar achieves citation\naccuracy on par with human experts. OpenScholar's datastore, retriever, and\nself-feedback inference loop also improves off-the-shelf LMs: for instance,\nOpenScholar-GPT4o improves GPT-4o's correctness by 12%. In human evaluations,\nexperts preferred OpenScholar-8B and OpenScholar-GPT4o responses over\nexpert-written ones 51% and 70% of the time, respectively, compared to GPT4o's\n32%. We open-source all of our code, models, datastore, data and a public demo.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.DL",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.14199v1",
    "published_date": "2024-11-21 15:07:42 UTC",
    "updated_date": "2024-11-21 15:07:42 UTC"
  },
  {
    "arxiv_id": "2411.14193v1",
    "title": "ComfyGI: Automatic Improvement of Image Generation Workflows",
    "authors": [
      "Dominik Sobania",
      "Martin Briesch",
      "Franz Rothlauf"
    ],
    "abstract": "Automatic image generation is no longer just of interest to researchers, but\nalso to practitioners. However, current models are sensitive to the settings\nused and automatic optimization methods often require human involvement. To\nbridge this gap, we introduce ComfyGI, a novel approach to automatically\nimprove workflows for image generation without the need for human intervention\ndriven by techniques from genetic improvement. This enables image generation\nwith significantly higher quality in terms of the alignment with the given\ndescription and the perceived aesthetics. On the performance side, we find that\noverall, the images generated with an optimized workflow are about 50% better\ncompared to the initial workflow in terms of the median ImageReward score.\nThese already good results are even surpassed in our human evaluation, as the\nparticipants preferred the images improved by ComfyGI in around 90% of the\ncases.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.NE"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.14193v1",
    "published_date": "2024-11-21 15:02:41 UTC",
    "updated_date": "2024-11-21 15:02:41 UTC"
  },
  {
    "arxiv_id": "2411.14164v1",
    "title": "FoPru: Focal Pruning for Efficient Large Vision-Language Models",
    "authors": [
      "Lei Jiang",
      "Weizhe Huang",
      "Tongxuan Liu",
      "Yuting Zeng",
      "Jing Li",
      "Lechao Cheng",
      "Xiaohua Xu"
    ],
    "abstract": "Large Vision-Language Models (LVLMs) represent a significant advancement\ntoward achieving superior multimodal capabilities by enabling powerful Large\nLanguage Models (LLMs) to understand visual input. Typically, LVLMs utilize\nvisual encoders, such as CLIP, to transform images into visual tokens, which\nare then aligned with textual tokens through projection layers before being\ninput into the LLM for inference. Although existing LVLMs have achieved\nsignificant success, their inference efficiency is still limited by the\nsubstantial number of visual tokens and the potential redundancy among them. To\nmitigate this issue, we propose Focal Pruning (FoPru), a training-free method\nthat prunes visual tokens based on the attention-based token significance\nderived from the vision encoder. Specifically, we introduce two alternative\npruning strategies: 1) the rank strategy, which leverages all token\nsignificance scores to retain more critical tokens in a global view; 2) the row\nstrategy, which focuses on preserving continuous key information in images from\na local perspective. Finally, the selected tokens are reordered to maintain\ntheir original positional relationships. Extensive experiments across various\nLVLMs and multimodal datasets demonstrate that our method can prune a large\nnumber of redundant tokens while maintaining high accuracy, leading to\nsignificant improvements in inference efficiency.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "11 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.14164v1",
    "published_date": "2024-11-21 14:22:38 UTC",
    "updated_date": "2024-11-21 14:22:38 UTC"
  },
  {
    "arxiv_id": "2411.14515v1",
    "title": "Are Anomaly Scores Telling the Whole Story? A Benchmark for Multilevel Anomaly Detection",
    "authors": [
      "Tri Cao",
      "Minh-Huy Trinh",
      "Ailin Deng",
      "Quoc-Nam Nguyen",
      "Khoa Duong",
      "Ngai-Man Cheung",
      "Bryan Hooi"
    ],
    "abstract": "Anomaly detection (AD) is a machine learning task that identifies anomalies\nby learning patterns from normal training data. In many real-world scenarios,\nanomalies vary in severity, from minor anomalies with little risk to severe\nabnormalities requiring immediate attention. However, existing models primarily\noperate in a binary setting, and the anomaly scores they produce are usually\nbased on the deviation of data points from normal data, which may not\naccurately reflect practical severity. In this paper, we address this gap by\nmaking three key contributions. First, we propose a novel setting, Multilevel\nAD (MAD), in which the anomaly score represents the severity of anomalies in\nreal-world applications, and we highlight its diverse applications across\nvarious domains. Second, we introduce a novel benchmark, MAD-Bench, that\nevaluates models not only on their ability to detect anomalies, but also on how\neffectively their anomaly scores reflect severity. This benchmark incorporates\nmultiple types of baselines and real-world applications involving severity.\nFinally, we conduct a comprehensive performance analysis on MAD-Bench. We\nevaluate models on their ability to assign severity-aligned scores, investigate\nthe correspondence between their performance on binary and multilevel\ndetection, and study their robustness. This analysis offers key insights into\nimproving AD models for practical severity alignment. The code framework and\ndatasets used for the benchmark will be made publicly available.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "Under review",
    "pdf_url": "http://arxiv.org/pdf/2411.14515v1",
    "published_date": "2024-11-21 14:18:37 UTC",
    "updated_date": "2024-11-21 14:18:37 UTC"
  },
  {
    "arxiv_id": "2411.14141v1",
    "title": "Differentiable SVD based on Moore-Penrose Pseudoinverse for Inverse Imaging Problems",
    "authors": [
      "Yinghao Zhang",
      "Yue Hu"
    ],
    "abstract": "Low-rank regularization-based deep unrolling networks have achieved\nremarkable success in various inverse imaging problems (IIPs). However, the\nsingular value decomposition (SVD) is non-differentiable when duplicated\nsingular values occur, leading to severe numerical instability during training.\nIn this paper, we propose a differentiable SVD based on the Moore-Penrose\npseudoinverse to address this issue. To the best of our knowledge, this is the\nfirst work to provide a comprehensive analysis of the differentiability of the\ntrivial SVD. Specifically, we show that the non-differentiability of SVD is\nessentially due to an underdetermined system of linear equations arising in the\nderivation process. We utilize the Moore-Penrose pseudoinverse to solve the\nsystem, thereby proposing a differentiable SVD. A numerical stability analysis\nin the context of IIPs is provided. Experimental results in color image\ncompressed sensing and dynamic MRI reconstruction show that our proposed\ndifferentiable SVD can effectively address the numerical instability issue\nwhile ensuring computational precision. Code is available at\nhttps://github.com/yhao-z/SVD-inv.",
    "categories": [
      "math.NA",
      "cs.AI",
      "cs.CV",
      "cs.NA",
      "G.1.4; I.2.0; I.4.4; I.4.5"
    ],
    "primary_category": "math.NA",
    "comment": "11 pages",
    "pdf_url": "http://arxiv.org/pdf/2411.14141v1",
    "published_date": "2024-11-21 14:04:38 UTC",
    "updated_date": "2024-11-21 14:04:38 UTC"
  },
  {
    "arxiv_id": "2411.14133v1",
    "title": "GASP: Efficient Black-Box Generation of Adversarial Suffixes for Jailbreaking LLMs",
    "authors": [
      "Advik Raj Basani",
      "Xiao Zhang"
    ],
    "abstract": "Large Language Models (LLMs) have shown impressive proficiency across a range\nof natural language processing tasks yet remain vulnerable to adversarial\nprompts, known as jailbreak attacks, carefully designed to elicit harmful\nresponses from LLMs. Traditional methods rely on manual heuristics, which\nsuffer from limited generalizability. While being automatic, optimization-based\nattacks often produce unnatural jailbreak prompts that are easy to detect by\nsafety filters or require high computational overhead due to discrete token\noptimization. Witnessing the limitations of existing jailbreak methods, we\nintroduce Generative Adversarial Suffix Prompter (GASP), a novel framework that\ncombines human-readable prompt generation with Latent Bayesian Optimization\n(LBO) to improve adversarial suffix creation in a fully black-box setting. GASP\nleverages LBO to craft adversarial suffixes by efficiently exploring continuous\nembedding spaces, gradually optimizing the model to improve attack efficacy\nwhile balancing prompt coherence through a targeted iterative refinement\nprocedure. Our experiments show that GASP can generate natural jailbreak\nprompts, significantly improving attack success rates, reducing training times,\nand accelerating inference speed, thus making it an efficient and scalable\nsolution for red-teaming LLMs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "28 pages, 9 tables, 13 figures; under review at CVPR '25",
    "pdf_url": "http://arxiv.org/pdf/2411.14133v1",
    "published_date": "2024-11-21 14:00:01 UTC",
    "updated_date": "2024-11-21 14:00:01 UTC"
  },
  {
    "arxiv_id": "2411.14117v1",
    "title": "Umbrella Reinforcement Learning -- computationally efficient tool for hard non-linear problems",
    "authors": [
      "Egor E. Nuzhin",
      "Nikolai V. Brilliantov"
    ],
    "abstract": "We report a novel, computationally efficient approach for solving hard\nnonlinear problems of reinforcement learning (RL). Here we combine umbrella\nsampling, from computational physics/chemistry, with optimal control methods.\nThe approach is realized on the basis of neural networks, with the use of\npolicy gradient. It outperforms, by computational efficiency and implementation\nuniversality, all available state-of-the-art algorithms, in application to hard\nRL problems with sparse reward, state traps and lack of terminal states. The\nproposed approach uses an ensemble of simultaneously acting agents, with a\nmodified reward which includes the ensemble entropy, yielding an optimal\nexploration-exploitation balance.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "I.2.6; I.2.8"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.14117v1",
    "published_date": "2024-11-21 13:34:36 UTC",
    "updated_date": "2024-11-21 13:34:36 UTC"
  },
  {
    "arxiv_id": "2411.14092v1",
    "title": "MetaCropFollow: Few-Shot Adaptation with Meta-Learning for Under-Canopy Navigation",
    "authors": [
      "Thomas Woehrle",
      "Arun N. Sivakumar",
      "Naveen Uppalapati",
      "Girish Chowdhary"
    ],
    "abstract": "Autonomous under-canopy navigation faces additional challenges compared to\nover-canopy settings - for example the tight spacing between the crop rows,\ndegraded GPS accuracy and excessive clutter. Keypoint-based visual navigation\nhas been shown to perform well in these conditions, however the differences\nbetween agricultural environments in terms of lighting, season, soil and crop\ntype mean that a domain shift will likely be encountered at some point of the\nrobot deployment. In this paper, we explore the use of Meta-Learning to\novercome this domain shift using a minimal amount of data. We train a\nbase-learner that can quickly adapt to new conditions, enabling more robust\nnavigation in low-data regimes.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.14092v1",
    "published_date": "2024-11-21 12:58:09 UTC",
    "updated_date": "2024-11-21 12:58:09 UTC"
  },
  {
    "arxiv_id": "2411.14064v1",
    "title": "Multi LoRA Meets Vision: Merging multiple adapters to create a multi task model",
    "authors": [
      "Ege Kesim",
      "Selahattin Serdar Helli"
    ],
    "abstract": "Parameter efficient finetuning (PEFT) methods are widely used in LLMs and\ngenerative models in computer vision. Especially one can use multiple of these\nduring inference to change the behavior of the base model. In this paper we\ninvestigated whether multiple LoRA adapters trained on computer vision tasks\ncan be merged together and used during inference without loss in performance.\nBy achieving this, multitask models can be created just by merging different\nLoRAs. Merging these will reduce inference time and it will not require any\nadditional retraining. We have trained adapters on six different tasks and\nevaluated their performance when they are merged together. For comparison we\nused a model with a frozen backbone and finetuned its head. Our results show\nthat even with simple merging techniques creating a multitask model by merging\nadapters is achievable by slightly loosing performance in some cases. In our\nexperiments we merged up to three adapters together. Depending on the task and\nthe similarity of the data adapters were trained on, merges can outperform head\nfinetuning. We have observed that LoRAs trained with dissimilar datasets tend\nto perform better compared to model trained on similar datasets.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.14064v1",
    "published_date": "2024-11-21 12:26:33 UTC",
    "updated_date": "2024-11-21 12:26:33 UTC"
  },
  {
    "arxiv_id": "2411.14511v1",
    "title": "Variational Autoencoders for Efficient Simulation-Based Inference",
    "authors": [
      "Mayank Nautiyal",
      "Andrey Shternshis",
      "Andreas Hellander",
      "Prashant Singh"
    ],
    "abstract": "We present a generative modeling approach based on the variational inference\nframework for likelihood-free simulation-based inference. The method leverages\nlatent variables within variational autoencoders to efficiently estimate\ncomplex posterior distributions arising from stochastic simulations. We explore\ntwo variations of this approach distinguished by their treatment of the prior\ndistribution. The first model adapts the prior based on observed data using a\nmultivariate prior network, enhancing generalization across various posterior\nqueries. In contrast, the second model utilizes a standard Gaussian prior,\noffering simplicity while still effectively capturing complex posterior\ndistributions. We demonstrate the efficacy of these models on well-established\nbenchmark problems, achieving results comparable to flow-based approaches while\nmaintaining computational efficiency and scalability.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.14511v1",
    "published_date": "2024-11-21 12:24:13 UTC",
    "updated_date": "2024-11-21 12:24:13 UTC"
  },
  {
    "arxiv_id": "2411.19793v1",
    "title": "Voice Communication Analysis in Esports",
    "authors": [
      "Aymeric Vinot",
      "Nicolas Perez"
    ],
    "abstract": "In most team-based esports, voice communications are prominent in the team\nefficiency and synergy. In fact it has been observed that not only the skill\naspect of the team but also the team effective voice communication comes into\nplay when trying to have good performance in official matches. With the recent\nemergence of LLM (Large Language Models) tools regarding NLP (Natural Language\nProcessing) (Vaswani et. al.), we decided to try applying them in order to have\na better understanding on how to improve the effectiveness of the voice\ncommunications. In this paper the study has been made through the prism of\nLeague of Legends esport. However the main concepts and ideas can be easily\napplicable in any other team related esports.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CL",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "17 pages, 11 figures. Independent research",
    "pdf_url": "http://arxiv.org/pdf/2411.19793v1",
    "published_date": "2024-11-21 12:21:11 UTC",
    "updated_date": "2024-11-21 12:21:11 UTC"
  },
  {
    "arxiv_id": "2411.14062v2",
    "title": "MMGenBench: Fully Automatically Evaluating LMMs from the Text-to-Image Generation Perspective",
    "authors": [
      "Hailang Huang",
      "Yong Wang",
      "Zixuan Huang",
      "Huaqiu Li",
      "Tongwen Huang",
      "Xiangxiang Chu",
      "Richong Zhang"
    ],
    "abstract": "Large Multimodal Models (LMMs) demonstrate impressive capabilities. However,\ncurrent benchmarks predominantly focus on image comprehension in specific\ndomains, and these benchmarks are labor-intensive to construct. Moreover, their\nanswers tend to be brief, making it difficult to assess the ability of LMMs to\ngenerate detailed descriptions of images. To address these limitations, we\npropose the MMGenBench-Pipeline, a straightforward and fully automated\nevaluation pipeline. This involves generating textual descriptions from input\nimages, using these descriptions to create auxiliary images via text-to-image\ngenerative models, and then comparing the original and generated images.\nFurthermore, to ensure the effectiveness of MMGenBench-Pipeline, we design\nMMGenBench-Test, evaluating LMMs across 13 distinct image patterns, and\nMMGenBench-Domain, focusing on generative image performance. A thorough\nevaluation involving over 50 popular LMMs demonstrates the effectiveness and\nreliability of both the pipeline and benchmark. Our observations indicate that\nnumerous LMMs excelling in existing benchmarks fail to adequately complete the\nbasic tasks related to image understanding and description. This finding\nhighlights the substantial potential for performance improvement in current\nLMMs and suggests avenues for future model optimization. Concurrently,\nMMGenBench-Pipeline can efficiently assess the performance of LMMs across\ndiverse domains using only image inputs.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "This project is available at: https://github.com/lerogo/MMGenBench",
    "pdf_url": "http://arxiv.org/pdf/2411.14062v2",
    "published_date": "2024-11-21 12:16:16 UTC",
    "updated_date": "2025-03-08 10:27:55 UTC"
  },
  {
    "arxiv_id": "2411.14054v1",
    "title": "FunctionChat-Bench: Comprehensive Evaluation of Language Models' Generative Capabilities in Korean Tool-use Dialogs",
    "authors": [
      "Shinbok Lee",
      "Gaeun Seo",
      "Daniel Lee",
      "Byeongil Ko",
      "Sunghee Jung",
      "Myeongcheol Shin"
    ],
    "abstract": "This study investigates language models' generative capabilities in tool-use\ndialogs. We categorize the models' outputs in tool-use dialogs into four\ndistinct types: Tool Call, Answer Completion, Slot Question, and Relevance\nDetection, which serve as aspects for evaluation. We introduce\nFunctionChat-Bench, comprising 700 evaluation items and automated assessment\nprograms. Using this benchmark, we evaluate several language models that\nsupport function calling. Our findings indicate that while language models may\nexhibit high accuracy in single-turn Tool Call scenarios, this does not\nnecessarily translate to superior generative performance in multi-turn\nenvironments. We argue that the capabilities required for function calling\nextend beyond generating tool call messages; they must also effectively\ngenerate conversational messages that engage the user.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "8 pages",
    "pdf_url": "http://arxiv.org/pdf/2411.14054v1",
    "published_date": "2024-11-21 11:59:13 UTC",
    "updated_date": "2024-11-21 11:59:13 UTC"
  },
  {
    "arxiv_id": "2411.14042v1",
    "title": "Forecasting Future International Events: A Reliable Dataset for Text-Based Event Modeling",
    "authors": [
      "Daehoon Gwak",
      "Junwoo Park",
      "Minho Park",
      "Chaehun Park",
      "Hyunchan Lee",
      "Edward Choi",
      "Jaegul Choo"
    ],
    "abstract": "Predicting future international events from textual information, such as news\narticles, has tremendous potential for applications in global policy, strategic\ndecision-making, and geopolitics. However, existing datasets available for this\ntask are often limited in quality, hindering the progress of related research.\nIn this paper, we introduce WORLDREP (WORLD Relationship and Event Prediction),\na novel dataset designed to address these limitations by leveraging the\nadvanced reasoning capabilities of large-language models (LLMs). Our dataset\nfeatures high-quality scoring labels generated through advanced prompt modeling\nand rigorously validated by domain experts in political science. We showcase\nthe quality and utility of WORLDREP for real-world event prediction tasks,\ndemonstrating its effectiveness through extensive experiments and analysis.\nFurthermore, we publicly release our dataset along with the full automation\nsource code for data collection, labeling, and benchmarking, aiming to support\nand advance research in text-based event prediction.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "EMNLP 2024 Findings",
    "pdf_url": "http://arxiv.org/pdf/2411.14042v1",
    "published_date": "2024-11-21 11:44:23 UTC",
    "updated_date": "2024-11-21 11:44:23 UTC"
  },
  {
    "arxiv_id": "2411.14039v1",
    "title": "Uterine Ultrasound Image Captioning Using Deep Learning Techniques",
    "authors": [
      "Abdennour Boulesnane",
      "Boutheina Mokhtari",
      "Oumnia Rana Segueni",
      "Slimane Segueni"
    ],
    "abstract": "Medical imaging has significantly revolutionized medical diagnostics and\ntreatment planning, progressing from early X-ray usage to sophisticated methods\nlike MRIs, CT scans, and ultrasounds. This paper investigates the use of deep\nlearning for medical image captioning, with a particular focus on uterine\nultrasound images. These images are vital in obstetrics and gynecology for\ndiagnosing and monitoring various conditions across different age groups.\nHowever, their interpretation is often challenging due to their complexity and\nvariability. To address this, a deep learning-based medical image captioning\nsystem was developed, integrating Convolutional Neural Networks with a\nBidirectional Gated Recurrent Unit network. This hybrid model processes both\nimage and text features to generate descriptive captions for uterine ultrasound\nimages. Our experimental results demonstrate the effectiveness of this approach\nover baseline methods, with the proposed model achieving superior performance\nin generating accurate and informative captions, as indicated by higher BLEU\nand ROUGE scores. By enhancing the interpretation of uterine ultrasound images,\nour research aims to assist medical professionals in making timely and accurate\ndiagnoses, ultimately contributing to improved patient care.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.14039v1",
    "published_date": "2024-11-21 11:41:42 UTC",
    "updated_date": "2024-11-21 11:41:42 UTC"
  },
  {
    "arxiv_id": "2412.04488v1",
    "title": "Optimizing Student Ability Assessment: A Hierarchy Constraint-Aware Cognitive Diagnosis Framework for Educational Contexts",
    "authors": [
      "Xinjie Sun",
      "Qi Liu",
      "Kai Zhang",
      "Shuanghong Shen",
      "Fei Wang",
      "Yan Zhuang",
      "Zheng Zhang",
      "Weiyin Gong",
      "Shijin Wang",
      "Lina Yang",
      "Xingying Huo"
    ],
    "abstract": "Cognitive diagnosis (CD) aims to reveal students' proficiency in specific\nknowledge concepts. With the increasing adoption of intelligent education\napplications, accurately assessing students' knowledge mastery has become an\nurgent challenge. Although existing cognitive diagnosis frameworks enhance\ndiagnostic accuracy by analyzing students' explicit response records, they\nprimarily focus on individual knowledge state, failing to adequately reflect\nthe relative ability performance of students within hierarchies. To address\nthis, we propose the Hierarchy Constraint-Aware Cognitive Diagnosis Framework\n(HCD), designed to more accurately represent student ability performance within\nreal educational contexts. Specifically, the framework introduces a hierarchy\nmapping layer to identify students' levels. It then employs a hierarchy\nconvolution-enhanced attention layer for in-depth analysis of knowledge\nconcepts performance among students at the same level, uncovering nuanced\ndifferences. A hierarchy inter-sampling attention layer captures performance\ndifferences across hierarchies, offering a comprehensive understanding of the\nrelationships among students' knowledge state. Finally, through personalized\ndiagnostic enhancement, the framework integrates hierarchy constraint\nperception features with existing models, improving the representation of both\nindividual and group characteristics. This approach enables precise inference\nof students' knowledge state. Research shows that this framework not only\nreasonably constrains changes in students' knowledge states to align with real\neducational settings, but also supports the scientific rigor and fairness of\neducational assessments, thereby advancing the field of cognitive diagnosis.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "Cognitive Diagnosis",
    "pdf_url": "http://arxiv.org/pdf/2412.04488v1",
    "published_date": "2024-11-21 11:37:36 UTC",
    "updated_date": "2024-11-21 11:37:36 UTC"
  },
  {
    "arxiv_id": "2412.00033v1",
    "title": "Can an AI Agent Safely Run a Government? Existence of Probably Approximately Aligned Policies",
    "authors": [
      "Frédéric Berdoz",
      "Roger Wattenhofer"
    ],
    "abstract": "While autonomous agents often surpass humans in their ability to handle vast\nand complex data, their potential misalignment (i.e., lack of transparency\nregarding their true objective) has thus far hindered their use in critical\napplications such as social decision processes. More importantly, existing\nalignment methods provide no formal guarantees on the safety of such models.\nDrawing from utility and social choice theory, we provide a novel quantitative\ndefinition of alignment in the context of social decision-making. Building on\nthis definition, we introduce probably approximately aligned (i.e.,\nnear-optimal) policies, and we derive a sufficient condition for their\nexistence. Lastly, recognizing the practical difficulty of satisfying this\ncondition, we introduce the relaxed concept of safe (i.e., nondestructive)\npolicies, and we propose a simple yet robust method to safeguard the black-box\npolicy of any autonomous agent, ensuring all its actions are verifiably safe\nfor the society.",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted at NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2412.00033v1",
    "published_date": "2024-11-21 11:36:45 UTC",
    "updated_date": "2024-11-21 11:36:45 UTC"
  },
  {
    "arxiv_id": "2411.14033v2",
    "title": "LLM-based Multi-Agent Systems: Techniques and Business Perspectives",
    "authors": [
      "Yingxuan Yang",
      "Qiuying Peng",
      "Jun Wang",
      "Ying Wen",
      "Weinan Zhang"
    ],
    "abstract": "In the era of (multi-modal) large language models, most operational processes\ncan be reformulated and reproduced using LLM agents. The LLM agents can\nperceive, control, and get feedback from the environment so as to accomplish\nthe given tasks in an autonomous manner. Besides the environment-interaction\nproperty, the LLM agents can call various external tools to ease the task\ncompletion process. The tools can be regarded as a predefined operational\nprocess with private or real-time knowledge that does not exist in the\nparameters of LLMs. As a natural trend of development, the tools for calling\nare becoming autonomous agents, thus the full intelligent system turns out to\nbe a LLM-based Multi-Agent System (LaMAS). Compared to the previous\nsingle-LLM-agent system, LaMAS has the advantages of i) dynamic task\ndecomposition and organic specialization, ii) higher flexibility for system\nchanging, iii) proprietary data preserving for each participating entity, and\niv) feasibility of monetization for each entity. This paper discusses the\ntechnical and business landscapes of LaMAS. To support the ecosystem of LaMAS,\nwe provide a preliminary version of such LaMAS protocol considering technical\nrequirements, data privacy, and business incentives. As such, LaMAS would be a\npractical solution to achieve artificial collective intelligence in the near\nfuture.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.14033v2",
    "published_date": "2024-11-21 11:36:29 UTC",
    "updated_date": "2024-12-28 12:48:11 UTC"
  },
  {
    "arxiv_id": "2411.14014v2",
    "title": "Trajectory Representation Learning on Road Networks and Grids with Spatio-Temporal Dynamics",
    "authors": [
      "Stefan Schestakov",
      "Simon Gottschalk"
    ],
    "abstract": "Trajectory representation learning is a fundamental task for applications in\nfields including smart city, and urban planning, as it facilitates the\nutilization of trajectory data (e.g., vehicle movements) for various downstream\napplications, such as trajectory similarity computation or travel time\nestimation. This is achieved by learning low-dimensional representations from\nhigh-dimensional and raw trajectory data. However, existing methods for\ntrajectory representation learning either rely on grid-based or road-based\nrepresentations, which are inherently different and thus, could lose\ninformation contained in the other modality. Moreover, these methods overlook\nthe dynamic nature of urban traffic, relying on static road network features\nrather than time varying traffic patterns. In this paper, we propose TIGR, a\nnovel model designed to integrate grid and road network modalities while\nincorporating spatio-temporal dynamics to learn rich, general-purpose\nrepresentations of trajectories. We evaluate TIGR on two realworld datasets and\ndemonstrate the effectiveness of combining both modalities by substantially\noutperforming state-of-the-art methods, i.e., up to 43.22% for trajectory\nsimilarity, up to 16.65% for travel time estimation, and up to 10.16% for\ndestination prediction.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.14014v2",
    "published_date": "2024-11-21 10:56:02 UTC",
    "updated_date": "2025-01-02 10:59:50 UTC"
  },
  {
    "arxiv_id": "2411.14012v2",
    "title": "Logic Augmented Generation",
    "authors": [
      "Aldo Gangemi",
      "Andrea Giovanni Nuzzolese"
    ],
    "abstract": "Semantic Knowledge Graphs (SKG) face challenges with scalability,\nflexibility, contextual understanding, and handling unstructured or ambiguous\ninformation. However, they offer formal and structured knowledge enabling\nhighly interpretable and reliable results by means of reasoning and querying.\nLarge Language Models (LLMs) overcome those limitations making them suitable in\nopen-ended tasks and unstructured environments. Nevertheless, LLMs are neither\ninterpretable nor reliable. To solve the dichotomy between LLMs and SKGs we\nenvision Logic Augmented Generation (LAG) that combines the benefits of the two\nworlds. LAG uses LLMs as Reactive Continuous Knowledge Graphs that can generate\npotentially infinite relations and tacit knowledge on-demand. SKGs are key for\ninjecting a discrete heuristic dimension with clear logical and factual\nboundaries. We exemplify LAG in two tasks of collective intelligence, i.e.,\nmedical diagnostics and climate projections. Understanding the properties and\nlimitations of LAG, which are still mostly unknown, is of utmost importance for\nenabling a variety of tasks involving tacit knowledge in order to provide\ninterpretable and effective results.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "10 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.14012v2",
    "published_date": "2024-11-21 10:54:35 UTC",
    "updated_date": "2025-01-14 15:58:02 UTC"
  },
  {
    "arxiv_id": "2411.13997v1",
    "title": "Mirror Target YOLO: An Improved YOLOv8 Method with Indirect Vision for Heritage Buildings Fire Detection",
    "authors": [
      "Jian Liang",
      "JunSheng Cheng"
    ],
    "abstract": "Fires can cause severe damage to heritage buildings, making timely fire\ndetection essential. Traditional dense cabling and drilling can harm these\nstructures, so reducing the number of cameras to minimize such impact is\nchallenging. Additionally, avoiding false alarms due to noise sensitivity and\npreserving the expertise of managers in fire-prone areas is crucial. To address\nthese needs, we propose a fire detection method based on indirect vision,\ncalled Mirror Target YOLO (MITA-YOLO). MITA-YOLO integrates indirect vision\ndeployment and an enhanced detection module. It uses mirror angles to achieve\nindirect views, solving issues with limited visibility in irregular spaces and\naligning each indirect view with the target monitoring area. The Target-Mask\nmodule is designed to automatically identify and isolate the indirect vision\nareas in each image, filtering out non-target areas. This enables the model to\ninherit managers' expertise in assessing fire-risk zones, improving focus and\nresistance to interference in fire detection.In our experiments, we created an\n800-image fire dataset with indirect vision. Results show that MITA-YOLO\nsignificantly reduces camera requirements while achieving superior detection\nperformance compared to other mainstream models.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.13997v1",
    "published_date": "2024-11-21 10:23:00 UTC",
    "updated_date": "2024-11-21 10:23:00 UTC"
  },
  {
    "arxiv_id": "2411.14507v1",
    "title": "FuseGPT: Learnable Layers Fusion of Generative Pre-trained Transformers",
    "authors": [
      "Zehua Pei",
      "Hui-Ling Zhen",
      "Xianzhi Yu",
      "Sinno Jialin Pan",
      "Mingxuan Yuan",
      "Bei Yu"
    ],
    "abstract": "Generative Pre-trained Transformers (GPTs) have demonstrated remarkable\nperformance across diverse domains through the extensive scaling of model\nparameters. Recent works observe the redundancy across the transformer blocks\nand develop compression methods by structured pruning of the unimportant\nblocks. However, such straightforward elimination will always provide\nirreversible performance degradation. In this paper, we propose FuseGPT, a\nnovel methodology to recycle the pruned transformer blocks to further recover\nthe model performance. Firstly we introduce a new importance detection metric,\nMacro Influence (MI), to detect the long-term influence of each transformer\nblock by calculating their loss of information after removal. Then we propose\ngroup-level layers fusion, which adopts the parameters in layers of the\nunimportant blocks and injects them into the corresponding layers inside the\nneighboring blocks. The fusion is not one-off but through iterative parameter\nupdates by lightweight group-level fine-tuning. Specifically, these injected\nparameters are frozen but weighted with learnable rank decomposition matrices\nto reduce the overhead during fine-tuning. Our approach not only works well on\nlarge language models but also on large multimodal models. The experiments have\nshown that, by using modest amounts of data, FuseGPT can outperform previous\nworks in both perplexity and zero-shot task performance.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.14507v1",
    "published_date": "2024-11-21 09:49:28 UTC",
    "updated_date": "2024-11-21 09:49:28 UTC"
  },
  {
    "arxiv_id": "2411.13982v2",
    "title": "Safety Without Semantic Disruptions: Editing-free Safe Image Generation via Context-preserving Dual Latent Reconstruction",
    "authors": [
      "Jordan Vice",
      "Naveed Akhtar",
      "Mubarak Shah",
      "Richard Hartley",
      "Ajmal Mian"
    ],
    "abstract": "Training multimodal generative models on large, uncurated datasets can result\nin users being exposed to harmful, unsafe and controversial or\nculturally-inappropriate outputs. While model editing has been proposed to\nremove or filter undesirable concepts in embedding and latent spaces, it can\ninadvertently damage learned manifolds, distorting concepts in close semantic\nproximity. We identify limitations in current model editing techniques, showing\nthat even benign, proximal concepts may become misaligned. To address the need\nfor safe content generation, we leverage safe embeddings and a modified\ndiffusion process with tunable weighted summation in the latent space to\ngenerate safer images. Our method preserves global context without compromising\nthe structural integrity of the learned manifolds. We achieve state-of-the-art\nresults on safe image generation benchmarks and offer intuitive control over\nthe level of model safety. We identify trade-offs between safety and\ncensorship, which presents a necessary perspective in the development of\nethical AI models. We will release our code.\n  Keywords: Text-to-Image Models, Generative AI, Safety, Reliability, Model\nEditing",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "This research is supported by the NISDRG project #20100007, funded by\n  the Australian Government",
    "pdf_url": "http://arxiv.org/pdf/2411.13982v2",
    "published_date": "2024-11-21 09:47:13 UTC",
    "updated_date": "2025-03-05 14:45:55 UTC"
  },
  {
    "arxiv_id": "2411.13981v1",
    "title": "On the Fairness, Diversity and Reliability of Text-to-Image Generative Models",
    "authors": [
      "Jordan Vice",
      "Naveed Akhtar",
      "Richard Hartley",
      "Ajmal Mian"
    ],
    "abstract": "The widespread availability of multimodal generative models has sparked\ncritical discussions on their fairness, reliability, and potential for misuse.\nWhile text-to-image models can produce high-fidelity, user-guided images, they\nalso exhibit unpredictable behavior and vulnerabilities, which can be exploited\nto manipulate class or concept representations. To address this, we propose an\nevaluation framework designed to assess model reliability through their\nresponses to globally- and locally-applied `semantic' perturbations in the\nembedding space, pinpointing inputs that trigger unreliable behavior. Our\napproach offers deeper insights into two essential aspects: (i) generative\ndiversity, evaluating the breadth of visual representations for learned\nconcepts, and (ii) generative fairness, examining how removing concepts from\ninput prompts affects semantic guidance. Beyond these evaluations, our method\nlays the groundwork for detecting unreliable, bias-injected models and\nretrieval of bias provenance. We will release our code.\n  Keywords: Fairness, Reliability, AI Ethics, Bias, Text-to-Image Models",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "This research is supported by the NISDRG project #20100007, funded by\n  the Australian Government",
    "pdf_url": "http://arxiv.org/pdf/2411.13981v1",
    "published_date": "2024-11-21 09:46:55 UTC",
    "updated_date": "2024-11-21 09:46:55 UTC"
  },
  {
    "arxiv_id": "2411.13979v1",
    "title": "FedRAV: Hierarchically Federated Region-Learning for Traffic Object Classification of Autonomous Vehicles",
    "authors": [
      "Yijun Zhai",
      "Pengzhan Zhou",
      "Yuepeng He",
      "Fang Qu",
      "Zhida Qin",
      "Xianlong Jiao",
      "Guiyan Liu",
      "Songtao Guo"
    ],
    "abstract": "The emerging federated learning enables distributed autonomous vehicles to\ntrain equipped deep learning models collaboratively without exposing their raw\ndata, providing great potential for utilizing explosively growing autonomous\ndriving data. However, considering the complicated traffic environments and\ndriving scenarios, deploying federated learning for autonomous vehicles is\ninevitably challenged by non-independent and identically distributed (Non-IID)\ndata of vehicles, which may lead to failed convergence and low training\naccuracy. In this paper, we propose a novel hierarchically Federated\nRegion-learning framework of Autonomous Vehicles (FedRAV), a two-stage\nframework, which adaptively divides a large area containing vehicles into\nsub-regions based on the defined region-wise distance, and achieves\npersonalized vehicular models and regional models. This approach ensures that\nthe personalized vehicular model adopts the beneficial models while discarding\nthe unprofitable ones. We validate our FedRAV framework against existing\nfederated learning algorithms on three real-world autonomous driving datasets\nin various heterogeneous settings. The experiment results demonstrate that our\nframework outperforms those known algorithms, and improves the accuracy by at\nleast 3.69%. The source code of FedRAV is available at:\nhttps://github.com/yjzhai-cs/FedRAV.",
    "categories": [
      "cs.DC",
      "cs.AI"
    ],
    "primary_category": "cs.DC",
    "comment": "8 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.13979v1",
    "published_date": "2024-11-21 09:45:55 UTC",
    "updated_date": "2024-11-21 09:45:55 UTC"
  },
  {
    "arxiv_id": "2411.13951v4",
    "title": "PATH: A Discrete-sequence Dataset for Evaluating Online Unsupervised Anomaly Detection Approaches for Multivariate Time Series",
    "authors": [
      "Lucas Correia",
      "Jan-Christoph Goos",
      "Thomas Bäck",
      "Anna V. Kononova"
    ],
    "abstract": "Benchmarking anomaly detection approaches for multivariate time series is a\nchallenging task due to a lack of high-quality datasets. Current publicly\navailable datasets are too small, not diverse and feature trivial anomalies,\nwhich hinders measurable progress in this research area. We propose a solution:\na diverse, extensive, and non-trivial dataset generated via state-of-the-art\nsimulation tools that reflects realistic behaviour of an automotive powertrain,\nincluding its multivariate, dynamic and variable-state properties.\nAdditionally, our dataset represents a discrete-sequence problem, which remains\nunaddressed by previously-proposed solutions in literature. To cater for both\nunsupervised and semi-supervised anomaly detection settings, as well as time\nseries generation and forecasting, we make different versions of the dataset\navailable, where training and test subsets are offered in contaminated and\nclean versions, depending on the task. We also provide baseline results from a\nselection of approaches based on deterministic and variational autoencoders, as\nwell as a non-parametric approach. As expected, the baseline experimentation\nshows that the approaches trained on the semi-supervised version of the dataset\noutperform their unsupervised counterparts, highlighting a need for approaches\nmore robust to contaminated training data. Furthermore, results show that the\nthreshold used can have a large influence on detection performance, hence more\nwork needs to be invested in methods to find a suitable threshold without the\nneed for labelled data.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CE",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.LG",
    "comment": "Submitted to the Big Data Research journal",
    "pdf_url": "http://arxiv.org/pdf/2411.13951v4",
    "published_date": "2024-11-21 09:03:12 UTC",
    "updated_date": "2025-04-08 15:26:49 UTC"
  },
  {
    "arxiv_id": "2411.13949v1",
    "title": "Separable Mixture of Low-Rank Adaptation for Continual Visual Instruction Tuning",
    "authors": [
      "Ziqi Wang",
      "Chang Che",
      "Qi Wang",
      "Yangyang Li",
      "Zenglin Shi",
      "Meng Wang"
    ],
    "abstract": "Visual instruction tuning (VIT) enables multimodal large language models\n(MLLMs) to effectively handle a wide range of vision tasks by framing them as\nlanguage-based instructions. Building on this, continual visual instruction\ntuning (CVIT) extends the capability of MLLMs to incrementally learn new tasks,\naccommodating evolving functionalities. While prior work has advanced CVIT\nthrough the development of new benchmarks and approaches to mitigate\ncatastrophic forgetting, these efforts largely follow traditional continual\nlearning paradigms, neglecting the unique challenges specific to CVIT. We\nidentify a dual form of catastrophic forgetting in CVIT, where MLLMs not only\nforget previously learned visual understanding but also experience a decline in\ninstruction following abilities as they acquire new tasks. To address this, we\nintroduce the Separable Mixture of Low-Rank Adaptation (SMoLoRA) framework,\nwhich employs separable routing through two distinct modules - one for visual\nunderstanding and another for instruction following. This dual-routing design\nenables specialized adaptation in both domains, preventing forgetting while\nimproving performance. Furthermore, we propose a novel CVIT benchmark that goes\nbeyond existing benchmarks by additionally evaluating a model's ability to\ngeneralize to unseen tasks and handle diverse instructions across various\ntasks. Extensive experiments demonstrate that SMoLoRA outperforms existing\nmethods in mitigating dual forgetting, improving generalization to unseen\ntasks, and ensuring robustness in following diverse instructions.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.13949v1",
    "published_date": "2024-11-21 09:00:15 UTC",
    "updated_date": "2024-11-21 09:00:15 UTC"
  },
  {
    "arxiv_id": "2411.13941v1",
    "title": "LLMs as Continuous Learners: Improving the Reproduction of Defective Code in Software Issues",
    "authors": [
      "Yalan Lin",
      "Yingwei Ma",
      "Rongyu Cao",
      "Binhua Li",
      "Fei Huang",
      "Xiaodong Gu",
      "Yongbin Li"
    ],
    "abstract": "Reproducing buggy code is the first and crucially important step in issue\nresolving, as it aids in identifying the underlying problems and validating\nthat generated patches resolve the problem. While numerous approaches have been\nproposed for this task, they primarily address common, widespread errors and\nstruggle to adapt to unique, evolving errors specific to individual code\nrepositories. To fill this gap, we propose EvoCoder, a multi-agent continuous\nlearning framework for issue code reproduction. EvoCoder adopts a reflection\nmechanism that allows the LLM to continuously learn from previously resolved\nproblems and dynamically refine its strategies to new emerging challenges. To\nprevent experience bloating, EvoCoder introduces a novel hierarchical\nexperience pool that enables the model to adaptively update common and\nrepo-specific experiences. Our experimental results show a 20\\% improvement in\nissue reproduction rates over existing SOTA methods. Furthermore, integrating\nour reproduction mechanism significantly boosts the overall accuracy of the\nexisting issue-resolving pipeline.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.13941v1",
    "published_date": "2024-11-21 08:49:23 UTC",
    "updated_date": "2024-11-21 08:49:23 UTC"
  },
  {
    "arxiv_id": "2411.13934v1",
    "title": "Learning to Cooperate with Humans using Generative Agents",
    "authors": [
      "Yancheng Liang",
      "Daphne Chen",
      "Abhishek Gupta",
      "Simon S. Du",
      "Natasha Jaques"
    ],
    "abstract": "Training agents that can coordinate zero-shot with humans is a key mission in\nmulti-agent reinforcement learning (MARL). Current algorithms focus on training\nsimulated human partner policies which are then used to train a Cooperator\nagent. The simulated human is produced either through behavior cloning over a\ndataset of human cooperation behavior, or by using MARL to create a population\nof simulated agents. However, these approaches often struggle to produce a\nCooperator that can coordinate well with real humans, since the simulated\nhumans fail to cover the diverse strategies and styles employed by people in\nthe real world. We show \\emph{learning a generative model of human partners}\ncan effectively address this issue. Our model learns a latent variable\nrepresentation of the human that can be regarded as encoding the human's unique\nstrategy, intention, experience, or style. This generative model can be\nflexibly trained from any (human or neural policy) agent interaction data. By\nsampling from the latent space, we can use the generative model to produce\ndifferent partners to train Cooperator agents. We evaluate our method --\n\\textbf{G}enerative \\textbf{A}gent \\textbf{M}odeling for \\textbf{M}ulti-agent\n\\textbf{A}daptation (GAMMA) -- on Overcooked, a challenging cooperative cooking\ngame that has become a standard benchmark for zero-shot coordination. We\nconduct an evaluation with real human teammates, and the results show that\nGAMMA consistently improves performance, whether the generative model is\ntrained on simulated populations or human datasets. Further, we propose a\nmethod for posterior sampling from the generative model that is biased towards\nthe human data, enabling us to efficiently improve performance with only a\nsmall amount of expensive human interaction data.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.13934v1",
    "published_date": "2024-11-21 08:36:17 UTC",
    "updated_date": "2024-11-21 08:36:17 UTC"
  },
  {
    "arxiv_id": "2411.14503v2",
    "title": "Planning-Driven Programming: A Large Language Model Programming Workflow",
    "authors": [
      "Chao Lei",
      "Yanchuan Chang",
      "Nir Lipovetzky",
      "Krista A. Ehinger"
    ],
    "abstract": "The strong performance of large language models (LLMs) raises extensive\ndiscussion on their application to code generation. Recent research suggests\ncontinuous program refinements through visible tests to improve code generation\naccuracy in LLMs. However, these methods suffer from LLMs' inefficiency and\nlimited reasoning capacity. In this work, we propose an LLM programming\nworkflow (LPW) designed to improve both initial code generation and subsequent\nrefinements within a structured two-phase workflow. Specifically, the solution\ngeneration phase formulates a solution plan, which is then verified through\nvisible tests to specify the intended natural language solution. Subsequently,\nthe code implementation phase drafts an initial code according to the solution\nplan and its verification. If the generated code fails the visible tests, the\nplan verification serves as the intended solution to consistently inform the\nrefinement process for correcting bugs. Compared to state-of-the-art methods\nacross various existing LLMs, LPW significantly improves the Pass@1 accuracy by\nup to 16.4% on well-established text-to-code generation benchmarks. LPW also\nsets new state-of-the-art Pass@1 accuracy, achieving 98.2% on HumanEval, 84.8%\non MBPP, 59.3% on LiveCode, 62.6% on APPS, and 34.7% on CodeContest, using\nGPT-4o as the backbone.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.14503v2",
    "published_date": "2024-11-21 08:31:06 UTC",
    "updated_date": "2025-01-09 08:55:07 UTC"
  },
  {
    "arxiv_id": "2411.13932v1",
    "title": "XAgents: A Framework for Interpretable Rule-Based Multi-Agents Cooperation",
    "authors": [
      "Hailong Yang",
      "Mingxian Gu",
      "Renhuo Zhao",
      "Fuping Hu",
      "Zhaohong Deng",
      "Yitang Chen"
    ],
    "abstract": "Extracting implicit knowledge and logical reasoning abilities from large\nlanguage models (LLMs) has consistently been a significant challenge. The\nadvancement of multi-agent systems has further en-hanced the capabilities of\nLLMs. Inspired by the structure of multi-polar neurons (MNs), we propose the\nXAgents framework, an in-terpretable multi-agent cooperative framework based on\nthe IF-THEN rule-based system. The IF-Parts of the rules are responsible for\nlogical reasoning and domain membership calculation, while the THEN-Parts are\ncomprised of domain expert agents that generate domain-specific contents.\nFollowing the calculation of the member-ship, XAgetns transmits the task to the\ndisparate domain rules, which subsequently generate the various responses.\nThese re-sponses are analogous to the answers provided by different experts to\nthe same question. The final response is reached at by eliminat-ing the\nhallucinations and erroneous knowledge of the LLM through membership\ncomputation and semantic adversarial genera-tion of the various domain rules.\nThe incorporation of rule-based interpretability serves to bolster user\nconfidence in the XAgents framework. We evaluate the efficacy of XAgents\nthrough a com-parative analysis with the latest AutoAgents, in which XAgents\ndemonstrated superior performance across three distinct datasets. We perform\npost-hoc interpretable studies with SHAP algorithm and case studies, proving\nthe interpretability of XAgent in terms of input-output feature correlation and\nrule-based semantics.",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.13932v1",
    "published_date": "2024-11-21 08:28:27 UTC",
    "updated_date": "2024-11-21 08:28:27 UTC"
  },
  {
    "arxiv_id": "2411.14502v1",
    "title": "Global Challenge for Safe and Secure LLMs Track 1",
    "authors": [
      "Xiaojun Jia",
      "Yihao Huang",
      "Yang Liu",
      "Peng Yan Tan",
      "Weng Kuan Yau",
      "Mun-Thye Mak",
      "Xin Ming Sim",
      "Wee Siong Ng",
      "See Kiong Ng",
      "Hanqing Liu",
      "Lifeng Zhou",
      "Huanqian Yan",
      "Xiaobing Sun",
      "Wei Liu",
      "Long Wang",
      "Yiming Qian",
      "Yong Liu",
      "Junxiao Yang",
      "Zhexin Zhang",
      "Leqi Lei",
      "Renmiao Chen",
      "Yida Lu",
      "Shiyao Cui",
      "Zizhou Wang",
      "Shaohua Li",
      "Yan Wang",
      "Rick Siow Mong Goh",
      "Liangli Zhen",
      "Yingjie Zhang",
      "Zhe Zhao"
    ],
    "abstract": "This paper introduces the Global Challenge for Safe and Secure Large Language\nModels (LLMs), a pioneering initiative organized by AI Singapore (AISG) and the\nCyberSG R&D Programme Office (CRPO) to foster the development of advanced\ndefense mechanisms against automated jailbreaking attacks. With the increasing\nintegration of LLMs in critical sectors such as healthcare, finance, and public\nadministration, ensuring these models are resilient to adversarial attacks is\nvital for preventing misuse and upholding ethical standards. This competition\nfocused on two distinct tracks designed to evaluate and enhance the robustness\nof LLM security frameworks. Track 1 tasked participants with developing\nautomated methods to probe LLM vulnerabilities by eliciting undesirable\nresponses, effectively testing the limits of existing safety protocols within\nLLMs. Participants were challenged to devise techniques that could bypass\ncontent safeguards across a diverse array of scenarios, from offensive language\nto misinformation and illegal activities. Through this process, Track 1 aimed\nto deepen the understanding of LLM vulnerabilities and provide insights for\ncreating more resilient models.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.14502v1",
    "published_date": "2024-11-21 08:20:31 UTC",
    "updated_date": "2024-11-21 08:20:31 UTC"
  },
  {
    "arxiv_id": "2411.13907v1",
    "title": "Split Federated Learning Over Heterogeneous Edge Devices: Algorithm and Optimization",
    "authors": [
      "Yunrui Sun",
      "Gang Hu",
      "Yinglei Teng",
      "Dunbo Cai"
    ],
    "abstract": "Split Learning (SL) is a promising collaborative machine learning approach,\nenabling resource-constrained devices to train models without sharing raw data,\nwhile reducing computational load and preserving privacy simultaneously.\nHowever, current SL algorithms face limitations in training efficiency and\nsuffer from prolonged latency, particularly in sequential settings, where the\nslowest device can bottleneck the entire process due to heterogeneous resources\nand frequent data exchanges between clients and servers. To address these\nchallenges, we propose the Heterogeneous Split Federated Learning (HSFL)\nframework, which allows resource-constrained clients to train their\npersonalized client-side models in parallel, utilizing different cut layers.\nAiming to mitigate the impact of heterogeneous environments and accelerate the\ntraining process, we formulate a latency minimization problem that optimizes\ncomputational and transmission resources jointly. Additionally, we design a\nresource allocation algorithm that combines the Sample Average Approximation\n(SAA), Genetic Algorithm (GA), Lagrangian relaxation and Branch and Bound\n(B\\&B) methods to efficiently solve this problem. Simulation results\ndemonstrate that HSFL outperforms other frameworks in terms of both convergence\nrate and model accuracy on heterogeneous devices with non-iid data, while the\noptimization algorithm is better than other baseline methods in reducing\nlatency.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.13907v1",
    "published_date": "2024-11-21 07:46:01 UTC",
    "updated_date": "2024-11-21 07:46:01 UTC"
  },
  {
    "arxiv_id": "2411.13903v1",
    "title": "AmpliNetECG12: A lightweight SoftMax-based relativistic amplitude amplification architecture for 12 lead ECG classification",
    "authors": [
      "Shreya Srivastava"
    ],
    "abstract": "The urgent need to promptly detect cardiac disorders from 12-lead\nElectrocardiograms using limited computations is motivated by the heart's fast\nand complex electrical activity and restricted computational power of portable\ndevices. Timely and precise diagnoses are crucial since delays might\nsignificantly impact patient health outcomes. This research presents a novel\ndeep-learning architecture that aims to diagnose heart abnormalities quickly\nand accurately. We devised a new activation function called aSoftMax, designed\nto improve the visibility of ECG deflections. The proposed activation function\nis used with Convolutional Neural Network architecture to includes kernel\nweight sharing across the ECG's various leads. This innovative method\nthoroughly generalizes the global 12-lead ECG features and minimizes the\nmodel's complexity by decreasing the trainable parameters. aSoftMax, combined\nwith enhanced CNN architecture yielded AmpliNetECG12, we obtain exceptional\naccuracy of 84% in diagnosing cardiac disorders. AmpliNetECG12 shows\noutstanding prediction ability when used with the CPSC2018 dataset for\narrhythmia classification. The model attains an F1-score of 80.71% and a\nROC-AUC score of 96.00%, with 280,000 trainable parameters which signifies the\nlightweight yet efficient nature of AmpliNetECG12. The stochastic\ncharacteristics of aSoftMax, a fundamental element of AmpliNetECG12, improve\nprediction accuracy and also increasse the model's interpretability. This\nfeature enhances comprehension of important ECG segments in different forms of\narrhythmias, establishing a new standard of explainable architecture for\ncardiac disorder classification.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.13903v1",
    "published_date": "2024-11-21 07:28:24 UTC",
    "updated_date": "2024-11-21 07:28:24 UTC"
  },
  {
    "arxiv_id": "2411.13902v1",
    "title": "PIORS: Personalized Intelligent Outpatient Reception based on Large Language Model with Multi-Agents Medical Scenario Simulation",
    "authors": [
      "Zhijie Bao",
      "Qingyun Liu",
      "Ying Guo",
      "Zhengqiang Ye",
      "Jun Shen",
      "Shirong Xie",
      "Jiajie Peng",
      "Xuanjing Huang",
      "Zhongyu Wei"
    ],
    "abstract": "In China, receptionist nurses face overwhelming workloads in outpatient\nsettings, limiting their time and attention for each patient and ultimately\nreducing service quality. In this paper, we present the Personalized\nIntelligent Outpatient Reception System (PIORS). This system integrates an\nLLM-based reception nurse and a collaboration between LLM and hospital\ninformation system (HIS) into real outpatient reception setting, aiming to\ndeliver personalized, high-quality, and efficient reception services.\nAdditionally, to enhance the performance of LLMs in real-world healthcare\nscenarios, we propose a medical conversational data generation framework named\nService Flow aware Medical Scenario Simulation (SFMSS), aiming to adapt the LLM\nto the real-world environments and PIORS settings. We evaluate the\neffectiveness of PIORS and SFMSS through automatic and human assessments\ninvolving 15 users and 15 clinical experts. The results demonstrate that\nPIORS-Nurse outperforms all baselines, including the current state-of-the-art\nmodel GPT-4o, and aligns with human preferences and clinical needs. Further\ndetails and demo can be found at https://github.com/FudanDISC/PIORS",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.13902v1",
    "published_date": "2024-11-21 07:28:07 UTC",
    "updated_date": "2024-11-21 07:28:07 UTC"
  },
  {
    "arxiv_id": "2411.13883v1",
    "title": "When Online Algorithms Influence the Environment: A Dynamical Systems Analysis of the Unintended Consequences",
    "authors": [
      "Prabhat Lankireddy",
      "Jayakrishnan Nair",
      "D Manjunath"
    ],
    "abstract": "We analyze the effect that online algorithms have on the environment that\nthey are learning. As a motivation, consider recommendation systems that use\nonline algorithms to learn optimal product recommendations based on user and\nproduct attributes. It is well known that the sequence of recommendations\naffects user preferences. However, typical learning algorithms treat the user\nattributes as static and disregard the impact of their recommendations on user\npreferences. Our interest is to analyze the effect of this mismatch between the\nmodel assumption of a static environment, and the reality of an evolving\nenvironment affected by the recommendations. To perform this analysis, we first\nintroduce a model for a generic coupled evolution of the parameters that are\nbeing learned, and the environment that is affected by it. We then frame a\nlinear bandit recommendation system (RS) into this generic model where the\nusers are characterized by a state variable that evolves based on the sequence\nof recommendations. The learning algorithm of the RS does not explicitly\naccount for this evolution and assumes that the users are static. A dynamical\nsystem model that captures the coupled evolution of the population state and\nthe learning algorithm is described, and its equilibrium behavior is analyzed.\nWe show that when the recommendation algorithm is able to learn the population\npreferences in the presence of this mismatch, the algorithm induces similarity\nin the preferences of the user population. In particular, we present results on\nhow different properties of the recommendation algorithm, namely the user\nattribute space and the exploration-exploitation tradeoff, effect the\npopulation preferences when they are learned by the algorithm. We demonstrate\nthese results using model simulations.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "13 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.13883v1",
    "published_date": "2024-11-21 06:47:53 UTC",
    "updated_date": "2024-11-21 06:47:53 UTC"
  },
  {
    "arxiv_id": "2411.13874v1",
    "title": "Next-Generation Phishing: How LLM Agents Empower Cyber Attackers",
    "authors": [
      "Khalifa Afane",
      "Wenqi Wei",
      "Ying Mao",
      "Junaid Farooq",
      "Juntao Chen"
    ],
    "abstract": "The escalating threat of phishing emails has become increasingly\nsophisticated with the rise of Large Language Models (LLMs). As attackers\nexploit LLMs to craft more convincing and evasive phishing emails, it is\ncrucial to assess the resilience of current phishing defenses. In this study we\nconduct a comprehensive evaluation of traditional phishing detectors, such as\nGmail Spam Filter, Apache SpamAssassin, and Proofpoint, as well as machine\nlearning models like SVM, Logistic Regression, and Naive Bayes, in identifying\nboth traditional and LLM-rephrased phishing emails. We also explore the\nemerging role of LLMs as phishing detection tools, a method already adopted by\ncompanies like NTT Security Holdings and JPMorgan Chase. Our results reveal\nnotable declines in detection accuracy for rephrased emails across all\ndetectors, highlighting critical weaknesses in current phishing defenses. As\nthe threat landscape evolves, our findings underscore the need for stronger\nsecurity controls and regulatory oversight on LLM-generated content to prevent\nits misuse in creating advanced phishing attacks. This study contributes to the\ndevelopment of more effective Cyber Threat Intelligence (CTI) by leveraging\nLLMs to generate diverse phishing variants that can be used for data\naugmentation, harnessing the power of LLMs to enhance phishing detection, and\npaving the way for more robust and adaptable threat detection systems.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.13874v1",
    "published_date": "2024-11-21 06:20:29 UTC",
    "updated_date": "2024-11-21 06:20:29 UTC"
  },
  {
    "arxiv_id": "2411.13867v1",
    "title": "Generative Fuzzy System for Sequence Generation",
    "authors": [
      "Hailong Yang",
      "Zhaohong Deng",
      "Wei Zhang",
      "Zhuangzhuang Zhao",
      "Guanjin Wang",
      "Kup-sze Choi"
    ],
    "abstract": "Generative Models (GMs), particularly Large Language Models (LLMs), have\ngarnered significant attention in machine learning and artificial intelligence\nfor their ability to generate new data by learning the statistical properties\nof training data and creating data that resemble the original. This capability\noffers a wide range of applications across various domains. However, the\ncomplex structures and numerous model parameters of GMs make the input-output\nprocesses opaque, complicating the understanding and control of outputs.\nMoreover, the purely data-driven learning mechanism limits GM's ability to\nacquire broader knowledge. There remains substantial potential for enhancing\nthe robustness and generalization capabilities of GMs. In this work, we\nintroduce the fuzzy system, a classical modeling method that combines data and\nknowledge-driven mechanisms, to generative tasks. We propose a novel Generative\nFuzzy System framework, named GenFS, which integrates the deep learning\ncapabilities of GM with the interpretability and dual-driven mechanisms of\nfuzzy systems. Specifically, we propose an end-to-end GenFS-based model for\nsequence generation, called FuzzyS2S. A series of experimental studies were\nconducted on 12 datasets, covering three distinct categories of generative\ntasks: machine translation, code generation, and summary generation. The\nresults demonstrate that FuzzyS2S outperforms the Transformer in terms of\naccuracy and fluency. Furthermore, it exhibits better performance on some\ndatasets compared to state-of-the-art models T5 and CodeT5.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "12 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.13867v1",
    "published_date": "2024-11-21 06:03:25 UTC",
    "updated_date": "2024-11-21 06:03:25 UTC"
  },
  {
    "arxiv_id": "2411.13865v2",
    "title": "Breaking Information Cocoons: A Hyperbolic Graph-LLM Framework for Exploration and Exploitation in Recommender Systems",
    "authors": [
      "Qiyao Ma",
      "Menglin Yang",
      "Mingxuan Ju",
      "Tong Zhao",
      "Neil Shah",
      "Rex Ying"
    ],
    "abstract": "Modern recommender systems often create information cocoons, restricting\nusers' exposure to diverse content. A key challenge lies in balancing content\nexploration and exploitation while allowing users to adjust their\nrecommendation preferences. Intuitively, this balance can be modeled as a\ntree-structured representation, where depth search facilitates exploitation and\nbreadth search enables exploration. However, existing approaches face two\nfundamental limitations: Euclidean methods struggle to capture hierarchical\nstructures, while hyperbolic methods, despite their superior hierarchical\nmodeling, lack semantic understanding of user and item profiles and fail to\nprovide a principled mechanism for balancing exploration and exploitation. To\naddress these challenges, we propose HERec, a hyperbolic graph-LLM framework\nthat effectively balances exploration and exploitation in recommender systems.\nOur framework introduces two key innovations: (1) a hierarchical-aware\ngraph-LLM mechanism that jointly aligns textual descriptions with user-item\ncollaborative information in hyperbolic space, and (2) a hierarchical\nrepresentation structure that enables user-adjustable exploration-exploitation\ntrade-offs. Extensive experiments demonstrate that HERec consistently\noutperforms both Euclidean and hyperbolic baselines, achieving up to 5.49%\nimprovement in utility metrics and 11.39% increase in diversity metrics,\neffectively mitigating information cocoons. We open-source our model\nimplementation at https://github.com/Martin-qyma/HERec.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.13865v2",
    "published_date": "2024-11-21 06:01:47 UTC",
    "updated_date": "2025-02-01 13:05:17 UTC"
  },
  {
    "arxiv_id": "2411.13846v1",
    "title": "Exploratory Study Of Human-AI Interaction For Hindustani Music",
    "authors": [
      "Nithya Shikarpur",
      "Cheng-Zhi Anna Huang"
    ],
    "abstract": "This paper presents a study of participants interacting with and using\nGaMaDHaNi, a novel hierarchical generative model for Hindustani vocal contours.\nTo explore possible use cases in human-AI interaction, we conducted a user\nstudy with three participants, each engaging with the model through three\npredefined interaction modes. Although this study was conducted \"in the wild\"-\nwith the model unadapted for the shift from the training data to real-world\ninteraction - we use it as a pilot to better understand the expectations,\nreactions, and preferences of practicing musicians when engaging with such a\nmodel. We note their challenges as (1) the lack of restrictions in model\noutput, and (2) the incoherence of model output. We situate these challenges in\nthe context of Hindustani music and aim to suggest future directions for the\nmodel design to address these gaps.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "Accepted at NeurIPS Creative AI Track 2024",
    "pdf_url": "http://arxiv.org/pdf/2411.13846v1",
    "published_date": "2024-11-21 05:06:37 UTC",
    "updated_date": "2024-11-21 05:06:37 UTC"
  },
  {
    "arxiv_id": "2411.15224v3",
    "title": "Parameter Efficient Mamba Tuning via Projector-targeted Diagonal-centric Linear Transformation",
    "authors": [
      "Seokil Ham",
      "Hee-Seon Kim",
      "Sangmin Woo",
      "Changick Kim"
    ],
    "abstract": "Despite the growing interest in Mamba architecture as a potential replacement\nfor Transformer architecture, parameter-efficient fine-tuning (PEFT) approaches\nfor Mamba remain largely unexplored. In our study, we introduce two key\ninsights-driven strategies for PEFT in Mamba architecture: (1) While\nstate-space models (SSMs) have been regarded as the cornerstone of Mamba\narchitecture, then expected to play a primary role in transfer learning, our\nfindings reveal that Projectors -- not SSMs -- are the predominant contributors\nto transfer learning. (2) Based on our observation, we propose a novel PEFT\nmethod specialized to Mamba architecture: Projector-targeted Diagonal-centric\nLinear Transformation (ProDiaL). ProDiaL focuses on optimizing only the\npretrained Projectors for new tasks through diagonal-centric linear\ntransformation matrices, without directly fine-tuning the Projector weights.\nThis targeted approach allows efficient task adaptation, utilizing less than 1%\nof the total parameters, and exhibits strong performance across both vision and\nlanguage Mamba models, highlighting its versatility and effectiveness.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "accepted in CVPR 2025",
    "pdf_url": "http://arxiv.org/pdf/2411.15224v3",
    "published_date": "2024-11-21 04:58:20 UTC",
    "updated_date": "2025-03-24 04:59:31 UTC"
  },
  {
    "arxiv_id": "2411.14500v1",
    "title": "Exploring Accuracy-Fairness Trade-off in Large Language Models",
    "authors": [
      "Qingquan Zhang",
      "Qiqi Duan",
      "Bo Yuan",
      "Yuhui Shi",
      "Jialin Liu"
    ],
    "abstract": "Large Language Models (LLMs) have made significant strides in the field of\nartificial intelligence, showcasing their ability to interact with humans and\ninfluence human cognition through information dissemination. However, recent\nstudies have brought to light instances of bias inherent within these LLMs,\npresenting a critical issue that demands attention. In our research, we delve\ndeeper into the intricate challenge of harmonising accuracy and fairness in the\nenhancement of LLMs. While improving accuracy can indeed enhance overall LLM\nperformance, it often occurs at the expense of fairness. Overemphasising\noptimisation of one metric invariably leads to a significant degradation of the\nother. This underscores the necessity of taking into account multiple\nconsiderations during the design and optimisation phases of LLMs. Therefore, we\nadvocate for reformulating the LLM training process as a multi-objective\nlearning task. Our investigation reveals that multi-objective evolutionary\nlearning (MOEL) methodologies offer promising avenues for tackling this\nchallenge. Our MOEL framework enables the simultaneous optimisation of both\naccuracy and fairness metrics, resulting in a Pareto-optimal set of LLMs. In\nsummary, our study sheds valuable lights on the delicate equilibrium between\naccuracy and fairness within LLMs, which is increasingly significant for their\nreal-world applications. By harnessing MOEL, we present a promising pathway\ntowards fairer and more efficacious AI technologies.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "9 pages",
    "pdf_url": "http://arxiv.org/pdf/2411.14500v1",
    "published_date": "2024-11-21 04:40:35 UTC",
    "updated_date": "2024-11-21 04:40:35 UTC"
  },
  {
    "arxiv_id": "2411.13821v2",
    "title": "Heterophilic Graph Neural Networks Optimization with Causal Message-passing",
    "authors": [
      "Botao Wang",
      "Jia Li",
      "Heng Chang",
      "Keli Zhang",
      "Fugee Tsung"
    ],
    "abstract": "In this work, we discover that causal inference provides a promising approach\nto capture heterophilic message-passing in Graph Neural Network (GNN). By\nleveraging cause-effect analysis, we can discern heterophilic edges based on\nasymmetric node dependency. The learned causal structure offers more accurate\nrelationships among nodes. To reduce the computational complexity, we introduce\nintervention-based causal inference in graph learning. We first simplify causal\nanalysis on graphs by formulating it as a structural learning model and define\nthe optimization problem within the Bayesian scheme. We then present an\nanalysis of decomposing the optimization target into a consistency penalty and\na structure modification based on cause-effect relations. We then estimate this\ntarget by conditional entropy and present insights into how conditional entropy\nquantifies the heterophily. Accordingly, we propose CausalMP, a causal\nmessage-passing discovery network for heterophilic graph learning, that\niteratively learns the explicit causal structure of input graphs. We conduct\nextensive experiments in both heterophilic and homophilic graph settings. The\nresult demonstrates that the our model achieves superior link prediction\nperformance. Training on causal structure can also enhance node representation\nin classification task across different base models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.13821v2",
    "published_date": "2024-11-21 03:59:07 UTC",
    "updated_date": "2024-11-27 06:12:01 UTC"
  },
  {
    "arxiv_id": "2411.14499v1",
    "title": "Understanding World or Predicting Future? A Comprehensive Survey of World Models",
    "authors": [
      "Jingtao Ding",
      "Yunke Zhang",
      "Yu Shang",
      "Yuheng Zhang",
      "Zefang Zong",
      "Jie Feng",
      "Yuan Yuan",
      "Hongyuan Su",
      "Nian Li",
      "Nicholas Sukiennik",
      "Fengli Xu",
      "Yong Li"
    ],
    "abstract": "The concept of world models has garnered significant attention due to\nadvancements in multimodal large language models such as GPT-4 and video\ngeneration models such as Sora, which are central to the pursuit of artificial\ngeneral intelligence. This survey offers a comprehensive review of the\nliterature on world models. Generally, world models are regarded as tools for\neither understanding the present state of the world or predicting its future\ndynamics. This review presents a systematic categorization of world models,\nemphasizing two primary functions: (1) constructing internal representations to\nunderstand the mechanisms of the world, and (2) predicting future states to\nsimulate and guide decision-making. Initially, we examine the current progress\nin these two categories. We then explore the application of world models in key\ndomains, including autonomous driving, robotics, and social simulacra, with a\nfocus on how each domain utilizes these aspects. Finally, we outline key\nchallenges and provide insights into potential future research directions.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.14499v1",
    "published_date": "2024-11-21 03:58:50 UTC",
    "updated_date": "2024-11-21 03:58:50 UTC"
  },
  {
    "arxiv_id": "2411.13814v1",
    "title": "AutoMixQ: Self-Adjusting Quantization for High Performance Memory-Efficient Fine-Tuning",
    "authors": [
      "Changhai Zhou",
      "Shiyang Zhang",
      "Yuhua Zhou",
      "Zekai Liu",
      "Shichao Weng"
    ],
    "abstract": "Fine-tuning large language models (LLMs) under resource constraints is a\nsignificant challenge in deep learning. Low-Rank Adaptation (LoRA), pruning,\nand quantization are all effective methods for improving resource efficiency.\nHowever, combining them directly often results in suboptimal performance,\nespecially with uniform quantization across all model layers. This is due to\nthe complex, uneven interlayer relationships introduced by pruning,\nnecessitating more refined quantization strategies. To address this, we propose\nAutoMixQ, an end-to-end optimization framework that selects optimal\nquantization configurations for each LLM layer. AutoMixQ leverages lightweight\nperformance models to guide the selection process, significantly reducing time\nand computational resources compared to exhaustive search methods. By\nincorporating Pareto optimality, AutoMixQ balances memory usage and\nperformance, approaching the upper bounds of model capability under strict\nresource constraints. Our experiments on widely used benchmarks show that\nAutoMixQ reduces memory consumption while achieving superior performance. For\nexample, at a 30\\% pruning rate in LLaMA-7B, AutoMixQ achieved 66.21\\% on BoolQ\ncompared to 62.45\\% for LoRA and 58.96\\% for LoftQ, while reducing memory\nconsumption by 35.5\\% compared to LoRA and 27.5\\% compared to LoftQ.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.13814v1",
    "published_date": "2024-11-21 03:35:07 UTC",
    "updated_date": "2024-11-21 03:35:07 UTC"
  },
  {
    "arxiv_id": "2411.15222v1",
    "title": "Rethinking the Intermediate Features in Adversarial Attacks: Misleading Robotic Models via Adversarial Distillation",
    "authors": [
      "Ke Zhao",
      "Huayang Huang",
      "Miao Li",
      "Yu Wu"
    ],
    "abstract": "Language-conditioned robotic learning has significantly enhanced robot\nadaptability by enabling a single model to execute diverse tasks in response to\nverbal commands. Despite these advancements, security vulnerabilities within\nthis domain remain largely unexplored. This paper addresses this gap by\nproposing a novel adversarial prompt attack tailored to language-conditioned\nrobotic models. Our approach involves crafting a universal adversarial prefix\nthat induces the model to perform unintended actions when added to any original\nprompt. We demonstrate that existing adversarial techniques exhibit limited\neffectiveness when directly transferred to the robotic domain due to the\ninherent robustness of discretized robotic action spaces. To overcome this\nchallenge, we propose to optimize adversarial prefixes based on continuous\naction representations, circumventing the discretization process. Additionally,\nwe identify the beneficial impact of intermediate features on adversarial\nattacks and leverage the negative gradient of intermediate self-attention\nfeatures to further enhance attack efficacy. Extensive experiments on VIMA\nmodels across 13 robot manipulation tasks validate the superiority of our\nmethod over existing approaches and demonstrate its transferability across\ndifferent model variants.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.15222v1",
    "published_date": "2024-11-21 02:46:04 UTC",
    "updated_date": "2024-11-21 02:46:04 UTC"
  },
  {
    "arxiv_id": "2411.14497v1",
    "title": "Star-Agents: Automatic Data Optimization with LLM Agents for Instruction Tuning",
    "authors": [
      "Hang Zhou",
      "Yehui Tang",
      "Haochen Qin",
      "Yujie Yang",
      "Renren Jin",
      "Deyi Xiong",
      "Kai Han",
      "Yunhe Wang"
    ],
    "abstract": "The efficacy of large language models (LLMs) on downstream tasks usually\nhinges on instruction tuning, which relies critically on the quality of\ntraining data. Unfortunately, collecting high-quality and diverse data is both\nexpensive and time-consuming. To mitigate this issue, we propose a novel\nStar-Agents framework, which automates the enhancement of data quality across\ndatasets through multi-agent collaboration and assessment. The framework adopts\na three-pronged strategy. It initially generates diverse instruction data with\nmultiple LLM agents through a bespoke sampling method. Subsequently, the\ngenerated data undergo a rigorous evaluation using a dual-model method that\nassesses both difficulty and quality. Finaly, the above process evolves in a\ndynamic refinement phase, where more effective LLMs are prioritized, enhancing\nthe overall data quality. Our empirical studies, including instruction tuning\nexperiments with models such as Pythia and LLaMA, demonstrate the effectiveness\nof the proposed framework. Optimized datasets have achieved substantial\nimprovements, with an average increase of 12% and notable gains in specific\nmetrics, such as a 40% improvement in Fermi, as evidenced by benchmarks like\nMT-bench, Vicuna bench, and WizardLM testset.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.14497v1",
    "published_date": "2024-11-21 02:30:53 UTC",
    "updated_date": "2024-11-21 02:30:53 UTC"
  },
  {
    "arxiv_id": "2412.04486v1",
    "title": "The Global AI Vibrancy Tool",
    "authors": [
      "Loredana Fattorini",
      "Nestor Maslej",
      "Raymond Perrault",
      "Vanessa Parli",
      "John Etchemendy",
      "Yoav Shoham",
      "Katrina Ligett"
    ],
    "abstract": "This paper presents the latest version of the Global AI Vibrancy Tool (GVT),\nan interactive suite of visualizations designed to facilitate the comparison of\nAI vibrancy across 36 countries, using 42 indicators organized into 8 pillars.\nThe tool offers customizable features that allow users to conduct in-depth\ncountry-level comparisons and longitudinal analyses of AI-related metrics, all\nbased on publicly available data. By providing a transparent assessment of\nnational progress in AI, it serves the diverse needs of policymakers, industry\nleaders, researchers, and the general public. Using weights for indicators and\npillars developed by AI Index's panel of experts and combined into an index,\nthe Global AI Vibrancy Ranking for 2023 places the United States first by a\nsignificant margin, followed by China and the United Kingdom. The ranking also\nhighlights the rise of smaller nations such as Singapore when evaluated on both\nabsolute and per capita bases. The tool offers three sub-indices for evaluating\nGlobal AI Vibrancy along different dimensions: the Innovation Index, the\nEconomic Competitiveness Index, and the Policy, Governance, and Public\nEngagement Index.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.04486v1",
    "published_date": "2024-11-21 01:41:17 UTC",
    "updated_date": "2024-11-21 01:41:17 UTC"
  },
  {
    "arxiv_id": "2411.13779v1",
    "title": "NewsInterview: a Dataset and a Playground to Evaluate LLMs' Ground Gap via Informational Interviews",
    "authors": [
      "Michael Lu",
      "Hyundong Justin Cho",
      "Weiyan Shi",
      "Jonathan May",
      "Alexander Spangher"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated impressive capabilities in\ngenerating coherent text but often struggle with grounding language and\nstrategic dialogue. To address this gap, we focus on journalistic interviews, a\ndomain rich in grounding communication and abundant in data. We curate a\ndataset of 40,000 two-person informational interviews from NPR and CNN, and\nreveal that LLMs are significantly less likely than human interviewers to use\nacknowledgements and to pivot to higher-level questions. Realizing that a\nfundamental deficit exists in multi-turn planning and strategic thinking, we\ndevelop a realistic simulated environment, incorporating source personas and\npersuasive elements, in order to facilitate the development of agents with\nlonger-horizon rewards. Our experiments show that while source LLMs mimic human\nbehavior in information sharing, interviewer LLMs struggle with recognizing\nwhen questions are answered and engaging persuasively, leading to suboptimal\ninformation extraction across model size and capability. These findings\nunderscore the need for enhancing LLMs' strategic dialogue capabilities.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.13779v1",
    "published_date": "2024-11-21 01:37:38 UTC",
    "updated_date": "2024-11-21 01:37:38 UTC"
  },
  {
    "arxiv_id": "2411.13778v1",
    "title": "A Survey on Adversarial Robustness of LiDAR-based Machine Learning Perception in Autonomous Vehicles",
    "authors": [
      "Junae Kim",
      "Amardeep Kaur"
    ],
    "abstract": "In autonomous driving, the combination of AI and vehicular technology offers\ngreat potential. However, this amalgamation comes with vulnerabilities to\nadversarial attacks. This survey focuses on the intersection of Adversarial\nMachine Learning (AML) and autonomous systems, with a specific focus on\nLiDAR-based systems. We comprehensively explore the threat landscape,\nencompassing cyber-attacks on sensors and adversarial perturbations.\nAdditionally, we investigate defensive strategies employed in countering these\nthreats. This paper endeavors to present a concise overview of the challenges\nand advances in securing autonomous driving systems against adversarial\nthreats, emphasizing the need for robust defenses to ensure safety and\nsecurity.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "20 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.13778v1",
    "published_date": "2024-11-21 01:26:52 UTC",
    "updated_date": "2024-11-21 01:26:52 UTC"
  },
  {
    "arxiv_id": "2411.13775v1",
    "title": "Benchmarking GPT-4 against Human Translators: A Comprehensive Evaluation Across Languages, Domains, and Expertise Levels",
    "authors": [
      "Jianhao Yan",
      "Pingchuan Yan",
      "Yulong Chen",
      "Jing Li",
      "Xianchao Zhu",
      "Yue Zhang"
    ],
    "abstract": "This study presents a comprehensive evaluation of GPT-4's translation\ncapabilities compared to human translators of varying expertise levels. Through\nsystematic human evaluation using the MQM schema, we assess translations across\nthree language pairs (Chinese$\\longleftrightarrow$English,\nRussian$\\longleftrightarrow$English, and Chinese$\\longleftrightarrow$Hindi) and\nthree domains (News, Technology, and Biomedical). Our findings reveal that\nGPT-4 achieves performance comparable to junior-level translators in terms of\ntotal errors, while still lagging behind senior translators. Unlike traditional\nNeural Machine Translation systems, which show significant performance\ndegradation in resource-poor language directions, GPT-4 maintains consistent\ntranslation quality across all evaluated language pairs. Through qualitative\nanalysis, we identify distinctive patterns in translation approaches: GPT-4\ntends toward overly literal translations and exhibits lexical inconsistency,\nwhile human translators sometimes over-interpret context and introduce\nhallucinations. This study represents the first systematic comparison between\nLLM and human translators across different proficiency levels, providing\nvaluable insights into the current capabilities and limitations of LLM-based\ntranslation systems.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Work in progress",
    "pdf_url": "http://arxiv.org/pdf/2411.13775v1",
    "published_date": "2024-11-21 01:12:46 UTC",
    "updated_date": "2024-11-21 01:12:46 UTC"
  },
  {
    "arxiv_id": "2411.13773v1",
    "title": "FastRAG: Retrieval Augmented Generation for Semi-structured Data",
    "authors": [
      "Amar Abane",
      "Anis Bekri",
      "Abdella Battou"
    ],
    "abstract": "Efficiently processing and interpreting network data is critical for the\noperation of increasingly complex networks. Recent advances in Large Language\nModels (LLM) and Retrieval-Augmented Generation (RAG) techniques have improved\ndata processing in network management. However, existing RAG methods like\nVectorRAG and GraphRAG struggle with the complexity and implicit nature of\nsemi-structured technical data, leading to inefficiencies in time, cost, and\nretrieval. This paper introduces FastRAG, a novel RAG approach designed for\nsemi-structured data. FastRAG employs schema learning and script learning to\nextract and structure data without needing to submit entire data sources to an\nLLM. It integrates text search with knowledge graph (KG) querying to improve\naccuracy in retrieving context-rich information. Evaluation results demonstrate\nthat FastRAG provides accurate question answering, while improving up to 90% in\ntime and 85% in cost compared to GraphRAG.",
    "categories": [
      "cs.NI",
      "cs.AI"
    ],
    "primary_category": "cs.NI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.13773v1",
    "published_date": "2024-11-21 01:00:25 UTC",
    "updated_date": "2024-11-21 01:00:25 UTC"
  },
  {
    "arxiv_id": "2501.00004v1",
    "title": "NewsHomepages: Homepage Layouts Capture Information Prioritization Decisions",
    "authors": [
      "Ben Welsh",
      "Naitian Zhou",
      "Arda Kaz",
      "Michael Vu",
      "Alexander Spangher"
    ],
    "abstract": "Information prioritization plays an important role in how humans perceive and\nunderstand the world. Homepage layouts serve as a tangible proxy for this\nprioritization. In this work, we present NewsHomepages, a large dataset of over\n3,000 new website homepages (including local, national and topic-specific\noutlets) captured twice daily over a three-year period. We develop models to\nperform pairwise comparisons between news items to infer their relative\nsignificance. To illustrate that modeling organizational hierarchies has\nbroader implications, we applied our models to rank-order a collection of local\ncity council policies passed over a ten-year period in San Francisco, assessing\ntheir \"newsworthiness\". Our findings lay the groundwork for leveraging implicit\norganizational cues to deepen our understanding of information prioritization.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.00004v1",
    "published_date": "2024-11-21 00:46:42 UTC",
    "updated_date": "2024-11-21 00:46:42 UTC"
  },
  {
    "arxiv_id": "2412.04485v1",
    "title": "EDA-Aware RTL Generation with Large Language Models",
    "authors": [
      "Mubashir ul Islam",
      "Humza Sami",
      "Pierre-Emmanuel Gaillardon",
      "Valerio Tenace"
    ],
    "abstract": "Large Language Models (LLMs) have become increasingly popular for generating\nRTL code. However, producing error-free RTL code in a zero-shot setting remains\nhighly challenging for even state-of-the-art LLMs, often leading to issues that\nrequire manual, iterative refinement. This additional debugging process can\ndramatically increase the verification workload, underscoring the need for\nrobust, automated correction mechanisms to ensure code correctness from the\nstart.\n  In this work, we introduce AIvril2, a self-verifying, LLM-agnostic agentic\nframework aimed at enhancing RTL code generation through iterative corrections\nof both syntax and functional errors. Our approach leverages a collaborative\nmulti-agent system that incorporates feedback from error logs generated by EDA\ntools to automatically identify and resolve design flaws. Experimental results,\nconducted on the VerilogEval-Human benchmark suite, demonstrate that our\nframework significantly improves code quality, achieving nearly a 3.4$\\times$\nenhancement over prior methods. In the best-case scenario, functional pass\nrates of 77% for Verilog and 66% for VHDL were obtained, thus substantially\nimproving the reliability of LLM-driven RTL code generation.",
    "categories": [
      "cs.AR",
      "cs.AI"
    ],
    "primary_category": "cs.AR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.04485v1",
    "published_date": "2024-11-21 00:37:51 UTC",
    "updated_date": "2024-11-21 00:37:51 UTC"
  },
  {
    "arxiv_id": "2411.13768v2",
    "title": "Evaluation-Driven Development of LLM Agents: A Process Model and Reference Architecture",
    "authors": [
      "Boming Xia",
      "Qinghua Lu",
      "Liming Zhu",
      "Zhenchang Xing",
      "Dehai Zhao",
      "Hao Zhang"
    ],
    "abstract": "Large Language Models (LLMs) have enabled the emergence of LLM agents:\nautonomous systems capable of achieving under-specified goals and adapting\npost-deployment, often without explicit code or model changes. Evaluating these\nagents is critical to ensuring their performance and safety, especially given\ntheir dynamic, probabilistic, and evolving nature. However, traditional\napproaches such as predefined test cases and standard redevelopment pipelines\nstruggle to address the unique challenges of LLM agent evaluation. These\nchallenges include capturing open-ended behaviors, handling emergent outcomes,\nand enabling continuous adaptation over the agent's lifecycle. To address these\nissues, we propose an evaluation-driven development approach, inspired by\ntest-driven and behavior-driven development but reimagined for the unique\ncharacteristics of LLM agents. Through a multivocal literature review (MLR), we\nsynthesize the limitations of existing LLM evaluation methods and introduce a\nnovel process model and reference architecture tailored for evaluation-driven\ndevelopment of LLM agents. Our approach integrates online (runtime) and offline\n(redevelopment) evaluations, enabling adaptive runtime adjustments and\nsystematic iterative refinement of pipelines, artifacts, system architecture,\nand LLMs themselves. By continuously incorporating evaluation results,\nincluding fine-grained feedback from human and AI evaluators, into each stage\nof development and operation, this framework ensures that LLM agents remain\naligned with evolving goals, user needs, and governance standards.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.13768v2",
    "published_date": "2024-11-21 00:34:30 UTC",
    "updated_date": "2025-03-27 02:02:18 UTC"
  },
  {
    "arxiv_id": "2411.13766v2",
    "title": "Tiny-Align: Bridging Automatic Speech Recognition and Large Language Model on the Edge",
    "authors": [
      "Ruiyang Qin",
      "Dancheng Liu",
      "Gelei Xu",
      "Zheyu Yan",
      "Chenhui Xu",
      "Yuting Hu",
      "X. Sharon Hu",
      "Jinjun Xiong",
      "Yiyu Shi"
    ],
    "abstract": "The combination of Large Language Models (LLM) and Automatic Speech\nRecognition (ASR), when deployed on edge devices (called edge ASR-LLM), can\nserve as a powerful personalized assistant to enable audio-based interaction\nfor users. Compared to text-based interaction, edge ASR-LLM allows accessible\nand natural audio interactions. Unfortunately, existing ASR-LLM models are\nmainly trained in high-performance computing environments and produce\nsubstantial model weights, making them difficult to deploy on edge devices.\nMore importantly, to better serve users' personalized needs, the ASR-LLM must\nbe able to learn from each distinct user, given that audio input often contains\nhighly personalized characteristics that necessitate personalized on-device\ntraining. Since individually fine-tuning the ASR or LLM often leads to\nsuboptimal results due to modality-specific limitations, end-to-end training\nensures seamless integration of audio features and language understanding\n(cross-modal alignment), ultimately enabling a more personalized and efficient\nadaptation on edge devices. However, due to the complex training requirements\nand substantial computational demands of existing approaches, cross-modal\nalignment between ASR audio and LLM can be challenging on edge devices. In this\nwork, we propose a resource-efficient cross-modal alignment framework that\nbridges ASR and LLMs on edge devices to handle personalized audio input. Our\nframework enables efficient ASR-LLM alignment on resource-constrained devices\nlike NVIDIA Jetson Orin (8GB RAM), achieving 50x training time speedup while\nimproving the alignment quality by more than 50\\%. To the best of our\nknowledge, this is the first work to study efficient ASR-LLM alignment on\nresource-constrained edge devices.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "7 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.13766v2",
    "published_date": "2024-11-21 00:29:58 UTC",
    "updated_date": "2024-11-26 05:12:26 UTC"
  },
  {
    "arxiv_id": "2411.13757v2",
    "title": "GenBFA: An Evolutionary Optimization Approach to Bit-Flip Attacks on LLMs",
    "authors": [
      "Sanjay Das",
      "Swastik Bhattacharya",
      "Souvik Kundu",
      "Shamik Kundu",
      "Anand Menon",
      "Arnab Raha",
      "Kanad Basu"
    ],
    "abstract": "Large Language Models (LLMs) have revolutionized natural language processing\n(NLP), excelling in tasks like text generation and summarization. However,\ntheir increasing adoption in mission-critical applications raises concerns\nabout hardware-based threats, particularly bit-flip attacks (BFAs). BFAs,\nenabled by fault injection methods such as Rowhammer, target model parameters\nin memory, compromising both integrity and performance. Identifying critical\nparameters for BFAs in the vast parameter space of LLMs poses significant\nchallenges. While prior research suggests transformer-based architectures are\ninherently more robust to BFAs compared to traditional deep neural networks, we\nchallenge this assumption. For the first time, we demonstrate that as few as\nthree bit-flips can cause catastrophic performance degradation in an LLM with\nbillions of parameters. Current BFA techniques are inadequate for exploiting\nthis vulnerability due to the difficulty of efficiently identifying critical\nparameters within the immense parameter space. To address this, we propose\nAttentionBreaker, a novel framework tailored for LLMs that enables efficient\ntraversal of the parameter space to identify critical parameters. Additionally,\nwe introduce GenBFA, an evolutionary optimization strategy designed to refine\nthe search further, isolating the most critical bits for an efficient and\neffective attack. Empirical results reveal the profound vulnerability of LLMs\nto AttentionBreaker. For example, merely three bit-flips (4.129 x 10^-9% of\ntotal parameters) in the LLaMA3-8B-Instruct 8-bit quantized (W8) model result\nin a complete performance collapse: accuracy on MMLU tasks drops from 67.3% to\n0%, and Wikitext perplexity skyrockets from 12.6 to 4.72 x 10^5. These findings\nunderscore the effectiveness of AttentionBreaker in uncovering and exploiting\ncritical vulnerabilities within LLM architectures.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.13757v2",
    "published_date": "2024-11-21 00:01:51 UTC",
    "updated_date": "2025-02-07 16:24:17 UTC"
  }
]