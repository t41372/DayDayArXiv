[
  {
    "arxiv_id": "2412.10450v2",
    "title": "Regional Weather Variable Predictions by Machine Learning with Near-Surface Observational and Atmospheric Numerical Data",
    "authors": [
      "Yihe Zhang",
      "Bryce Turney",
      "Purushottam Sigdel",
      "Xu Yuan",
      "Eric Rappin",
      "Adrian Lago",
      "Sytske Kimball",
      "Li Chen",
      "Paul Darby",
      "Lu Peng",
      "Sercan Aygun",
      "Yazhou Tu",
      "M. Hassan Najafi",
      "Nian-Feng Tzeng"
    ],
    "abstract": "Accurate and timely regional weather prediction is vital for sectors\ndependent on weather-related decisions. Traditional prediction methods, based\non atmospheric equations, often struggle with coarse temporal resolutions and\ninaccuracies. This paper presents a novel machine learning (ML) model, called\nMiMa (short for Micro-Macro), that integrates both near-surface observational\ndata from Kentucky Mesonet stations (collected every five minutes, known as\nMicro data) and hourly atmospheric numerical outputs (termed as Macro data) for\nfine-resolution weather forecasting. The MiMa model employs an encoder-decoder\ntransformer structure, with two encoders for processing multivariate data from\nboth datasets and a decoder for forecasting weather variables over short time\nhorizons. Each instance of the MiMa model, called a modelet, predicts the\nvalues of a specific weather parameter at an individual Mesonet station. The\napproach is extended with Re-MiMa modelets, which are designed to predict\nweather variables at ungauged locations by training on multivariate data from a\nfew representative stations in a region, tagged with their elevations. Re-MiMa\n(short for Regional-MiMa) can provide highly accurate predictions across an\nentire region, even in areas without observational stations. Experimental\nresults show that MiMa significantly outperforms current models, with Re-MiMa\noffering precise short-term forecasts for ungauged locations, marking a\nsignificant advancement in weather forecasting accuracy and applicability.",
    "categories": [
      "physics.ao-ph",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "physics.ao-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.10450v2",
    "published_date": "2024-12-11 23:55:38 UTC",
    "updated_date": "2025-02-10 22:39:17 UTC"
  },
  {
    "arxiv_id": "2412.08810v1",
    "title": "Efficient Dynamic Attributed Graph Generation",
    "authors": [
      "Fan Li",
      "Xiaoyang Wang",
      "Dawei Cheng",
      "Cong Chen",
      "Ying Zhang",
      "Xuemin Lin"
    ],
    "abstract": "Data generation is a fundamental research problem in data management due to\nits diverse use cases, ranging from testing database engines to data-specific\napplications. However, real-world entities often involve complex interactions\nthat cannot be effectively modeled by traditional tabular data. Therefore,\ngraph data generation has attracted increasing attention recently. Although\nvarious graph generators have been proposed in the literature, there are three\nlimitations: i) They cannot capture the co-evolution pattern of graph structure\nand node attributes. ii) Few of them consider edge direction, leading to\nsubstantial information loss. iii) Current state-of-the-art dynamic graph\ngenerators are based on the temporal random walk, making the simulation process\ntime-consuming. To fill the research gap, we introduce VRDAG, a novel\nvariational recurrent framework for efficient dynamic attributed graph\ngeneration. Specifically, we design a bidirectional message-passing mechanism\nto encode both directed structural knowledge and attribute information of a\nsnapshot. Then, the temporal dependency in the graph sequence is captured by a\nrecurrence state updater, generating embeddings that can preserve the evolution\npattern of early graphs. Based on the hidden node embeddings, a conditional\nvariational Bayesian method is developed to sample latent random variables at\nthe neighboring timestep for new snapshot generation. The proposed generation\nparadigm avoids the time-consuming path sampling and merging process in\nexisting random walk-based methods, significantly reducing the synthesis time.\nFinally, comprehensive experiments on real-world datasets are conducted to\ndemonstrate the effectiveness and efficiency of the proposed model.",
    "categories": [
      "cs.DB",
      "cs.AI"
    ],
    "primary_category": "cs.DB",
    "comment": "14 pages,10 figures. Accepted by IEEE ICDE2025",
    "pdf_url": "http://arxiv.org/pdf/2412.08810v1",
    "published_date": "2024-12-11 22:53:27 UTC",
    "updated_date": "2024-12-11 22:53:27 UTC"
  },
  {
    "arxiv_id": "2412.08805v2",
    "title": "GAMA: Generative Agents for Multi-Agent Autoformalization",
    "authors": [
      "Agnieszka Mensfelt",
      "Kostas Stathis",
      "Vince Trencsenyi"
    ],
    "abstract": "Multi-agent simulations facilitate the exploration of interactions among both\nnatural and artificial agents. However, modelling real-world scenarios and\ndeveloping simulations often requires substantial expertise and effort. To\nstreamline this process, we present a framework that enables the\nautoformalization of interaction scenarios using agents augmented by large\nlanguage models (LLMs) utilising game-theoretic formalisms. The agents\ntranslate natural language descriptions of interactions into executable logic\nprograms that define the rules of each game, ensuring syntactic correctness\nthrough validation by a solver. A tournament simulation then tests the\nfunctionality of the generated game rules and strategies. After the tournament,\nif a ground truth payoff matrix is available, an exact semantic validation is\nperformed. We evaluate our approach on a diverse set of 110 natural language\ndescriptions exemplifying five $2\\times2$ simultaneous-move games, achieving\n100% syntactic and 76.5% semantic correctness in the generated game rules for\nClaude 3.5 Sonnet, and 99.82% syntactic and 77% semantic correctness for\nGPT-4o. Additionally, we demonstrate high semantic correctness in\nautoformalizing gameplay strategies. Overall, the results highlight the\npotential of autoformalization to leverage LLMs in generating formal reasoning\nmodules for decision-making agents.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "This is a revised version of the paper that incorporates feedback\n  from the reviewers of the first version. It includes an improved\n  presentation, enhanced experiments, and additional validation. This version\n  also uses the latest version of the framework, now available at:\n  https://github.com/dicelab-rhul/GAMA",
    "pdf_url": "http://arxiv.org/pdf/2412.08805v2",
    "published_date": "2024-12-11 22:37:45 UTC",
    "updated_date": "2025-02-18 12:06:39 UTC"
  },
  {
    "arxiv_id": "2412.12167v1",
    "title": "Greek2MathTex: A Greek Speech-to-Text Framework for LaTeX Equations Generation",
    "authors": [
      "Evangelia Gkritzali",
      "Panagiotis Kaliosis",
      "Sofia Galanaki",
      "Elisavet Palogiannidi",
      "Theodoros Giannakopoulos"
    ],
    "abstract": "In the vast majority of the academic and scientific domains, LaTeX has\nestablished itself as the de facto standard for typesetting complex\nmathematical equations and formulae. However, LaTeX's complex syntax and\ncode-like appearance present accessibility barriers for individuals with\ndisabilities, as well as those unfamiliar with coding conventions. In this\npaper, we present a novel solution to this challenge through the development of\na novel speech-to-LaTeX equations system specifically designed for the Greek\nlanguage. We propose an end-to-end system that harnesses the power of Automatic\nSpeech Recognition (ASR) and Natural Language Processing (NLP) techniques to\nenable users to verbally dictate mathematical expressions and equations in\nnatural language, which are subsequently converted into LaTeX format. We\npresent the architecture and design principles of our system, highlighting key\ncomponents such as the ASR engine, the LLM-based prompt-driven equations\ngeneration mechanism, as well as the application of a custom evaluation metric\nemployed throughout the development process. We have made our system open\nsource and available at https://github.com/magcil/greek-speech-to-math.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.CL",
    "comment": "4 pages, 2 figures, SETN2024: 13th EETN Conference on Artificial\n  Intelligence",
    "pdf_url": "http://arxiv.org/pdf/2412.12167v1",
    "published_date": "2024-12-11 22:29:44 UTC",
    "updated_date": "2024-12-11 22:29:44 UTC"
  },
  {
    "arxiv_id": "2501.06189v1",
    "title": "A Multimodal Social Agent",
    "authors": [
      "Athina Bikaki",
      "Ioannis A. Kakadiaris"
    ],
    "abstract": "In recent years, large language models (LLMs) have demonstrated remarkable\nprogress in common-sense reasoning tasks. This ability is fundamental to\nunderstanding social dynamics, interactions, and communication. However, the\npotential of integrating computers with these social capabilities is still\nrelatively unexplored. However, the potential of integrating computers with\nthese social capabilities is still relatively unexplored. This paper introduces\nMuSA, a multimodal LLM-based agent that analyzes text-rich social content\ntailored to address selected human-centric content analysis tasks, such as\nquestion answering, visual question answering, title generation, and\ncategorization. It uses planning, reasoning, acting, optimizing, criticizing,\nand refining strategies to complete a task. Our approach demonstrates that MuSA\ncan automate and improve social content analysis, helping decision-making\nprocesses across various applications. We have evaluated our agent's\ncapabilities in question answering, title generation, and content\ncategorization tasks. MuSA performs substantially better than our baselines.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "9 pages",
    "pdf_url": "http://arxiv.org/pdf/2501.06189v1",
    "published_date": "2024-12-11 22:04:27 UTC",
    "updated_date": "2024-12-11 22:04:27 UTC"
  },
  {
    "arxiv_id": "2412.08795v2",
    "title": "Coverage-based Fairness in Multi-document Summarization",
    "authors": [
      "Haoyuan Li",
      "Yusen Zhang",
      "Rui Zhang",
      "Snigdha Chaturvedi"
    ],
    "abstract": "Fairness in multi-document summarization (MDS) measures whether a system can\ngenerate a summary fairly representing information from documents with\ndifferent social attribute values. Fairness in MDS is crucial since a fair\nsummary can offer readers a comprehensive view. Previous works focus on\nquantifying summary-level fairness using Proportional Representation, a\nfairness measure based on Statistical Parity. However, Proportional\nRepresentation does not consider redundancy in input documents and overlooks\ncorpus-level unfairness. In this work, we propose a new summary-level fairness\nmeasure, Equal Coverage, which is based on coverage of documents with different\nsocial attribute values and considers the redundancy within documents. To\ndetect the corpus-level unfairness, we propose a new corpus-level measure,\nCoverage Parity. Our human evaluations show that our measures align more with\nour definition of fairness. Using our measures, we evaluate the fairness of\nthirteen different LLMs. We find that Claude3-sonnet is the fairest among all\nevaluated LLMs. We also find that almost all LLMs overrepresent different\nsocial attribute values. The code is available at\nhttps://github.com/leehaoyuan/coverage_fairness.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "accepted to NAACL 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.08795v2",
    "published_date": "2024-12-11 22:01:30 UTC",
    "updated_date": "2025-03-25 03:19:51 UTC"
  },
  {
    "arxiv_id": "2412.08771v1",
    "title": "LLaVA-Zip: Adaptive Visual Token Compression with Intrinsic Image Information",
    "authors": [
      "Ke Wang",
      "Hong Xuan"
    ],
    "abstract": "Multi-modal large language models (MLLMs) utilizing instruction-following\ndata, such as LLaVA, have achieved great progress in the industry. A major\nlimitation in these models is that visual tokens consume a substantial portion\nof the maximum token limit in large language models (LLMs), leading to\nincreased computational demands and decreased performance when prompts include\nmultiple images or videos. Industry solutions often mitigate this issue by\nincreasing computational power, but this approach is less feasible in academic\nenvironments with limited resources. In this study, we propose Dynamic Feature\nMap Reduction (DFMR) based on LLaVA-1.5 to address the challenge of visual\ntoken overload. DFMR dynamically compresses the visual tokens, freeing up token\ncapacity. Our experimental results demonstrate that integrating DFMR into\nLLaVA-1.5 significantly improves the performance of LLaVA in varied visual\ntoken lengths, offering a promising solution for extending LLaVA to handle\nmulti-image and video scenarios in resource-constrained academic environments\nand it can also be applied in industry settings for data augmentation to help\nmitigate the scarcity of open-domain image-text pair datasets in the continued\npretraining stage.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.08771v1",
    "published_date": "2024-12-11 20:46:06 UTC",
    "updated_date": "2024-12-11 20:46:06 UTC"
  },
  {
    "arxiv_id": "2412.12166v1",
    "title": "Performance of a large language model-Artificial Intelligence based chatbot for counseling patients with sexually transmitted infections and genital diseases",
    "authors": [
      "Nikhil Mehta",
      "Sithira Ambepitiya",
      "Thanveer Ahamad",
      "Dinuka Wijesundara",
      "Yudara Kularathne"
    ],
    "abstract": "Introduction: Global burden of sexually transmitted infections (STIs) is\nrising out of proportion to specialists. Current chatbots like ChatGPT are not\ntailored for handling STI-related concerns out of the box. We developed Otiz,\nan Artificial Intelligence-based (AI-based) chatbot platform designed\nspecifically for STI detection and counseling, and assessed its performance.\nMethods: Otiz employs a multi-agent system architecture based on GPT4-0613,\nleveraging large language model (LLM) and Deterministic Finite Automaton\nprinciples to provide contextually relevant, medically accurate, and empathetic\nresponses. Its components include modules for general STI information,\nemotional recognition, Acute Stress Disorder detection, and psychotherapy. A\nquestion suggestion agent operates in parallel. Four STIs (anogenital warts,\nherpes, syphilis, urethritis/cervicitis) and 2 non-STIs (candidiasis, penile\ncancer) were evaluated using prompts mimicking patient language. Each prompt\nwas independently graded by two venereologists conversing with Otiz as patient\nactors on 6 criteria using Numerical Rating Scale ranging from 0 (poor) to 5\n(excellent). Results: Twenty-three venereologists did 60 evaluations of 30\nprompts. Across STIs, Otiz scored highly on diagnostic accuracy (4.1-4.7),\noverall accuracy (4.3-4.6), correctness of information (5.0), comprehensibility\n(4.2-4.4), and empathy (4.5-4.8). However, relevance scores were lower\n(2.9-3.6), suggesting some redundancy. Diagnostic scores for non-STIs were\nlower (p=0.038). Inter-observer agreement was strong, with differences greater\nthan 1 point occurring in only 12.7% of paired evaluations. Conclusions: AI\nconversational agents like Otiz can provide accurate, correct, discrete,\nnon-judgmental, readily accessible and easily understandable STI-related\ninformation in an empathetic manner, and can alleviate the burden on healthcare\nsystems.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "18 pages, 1 table",
    "pdf_url": "http://arxiv.org/pdf/2412.12166v1",
    "published_date": "2024-12-11 20:36:32 UTC",
    "updated_date": "2024-12-11 20:36:32 UTC"
  },
  {
    "arxiv_id": "2412.08761v1",
    "title": "Integrating Optimization Theory with Deep Learning for Wireless Network Design",
    "authors": [
      "Sinem Coleri",
      "Aysun Gurur Onalan",
      "Marco di Renzo"
    ],
    "abstract": "Traditional wireless network design relies on optimization algorithms derived\nfrom domain-specific mathematical models, which are often inefficient and\nunsuitable for dynamic, real-time applications due to high complexity. Deep\nlearning has emerged as a promising alternative to overcome complexity and\nadaptability concerns, but it faces challenges such as accuracy issues, delays,\nand limited interpretability due to its inherent black-box nature. This paper\nintroduces a novel approach that integrates optimization theory with deep\nlearning methodologies to address these issues. The methodology starts by\nconstructing the block diagram of the optimization theory-based solution,\nidentifying key building blocks corresponding to optimality conditions and\niterative solutions. Selected building blocks are then replaced with deep\nneural networks, enhancing the adaptability and interpretability of the system.\nExtensive simulations show that this hybrid approach not only reduces runtime\ncompared to optimization theory based approaches but also significantly\nimproves accuracy and convergence rates, outperforming pure deep learning\nmodels.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted for publication in IEEE Communications Magazine",
    "pdf_url": "http://arxiv.org/pdf/2412.08761v1",
    "published_date": "2024-12-11 20:27:48 UTC",
    "updated_date": "2024-12-11 20:27:48 UTC"
  },
  {
    "arxiv_id": "2412.10448v1",
    "title": "Unlocking Visual Secrets: Inverting Features with Diffusion Priors for Image Reconstruction",
    "authors": [
      "Sai Qian Zhang",
      "Ziyun Li",
      "Chuan Guo",
      "Saeed Mahloujifar",
      "Deeksha Dangwal",
      "Edward Suh",
      "Barbara De Salvo",
      "Chiao Liu"
    ],
    "abstract": "Inverting visual representations within deep neural networks (DNNs) presents\na challenging and important problem in the field of security and privacy for\ndeep learning. The main goal is to invert the features of an unidentified\ntarget image generated by a pre-trained DNN, aiming to reconstruct the original\nimage. Feature inversion holds particular significance in understanding the\nprivacy leakage inherent in contemporary split DNN execution techniques, as\nwell as in various applications based on the extracted DNN features.\n  In this paper, we explore the use of diffusion models, a promising technique\nfor image synthesis, to enhance feature inversion quality. We also investigate\nthe potential of incorporating alternative forms of prior knowledge, such as\ntextual prompts and cross-frame temporal correlations, to further improve the\nquality of inverted features. Our findings reveal that diffusion models can\neffectively leverage hidden information from the DNN features, resulting in\nsuperior reconstruction performance compared to previous methods. This research\noffers valuable insights into how diffusion models can enhance privacy and\nsecurity within applications that are reliant on DNN features.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.10448v1",
    "published_date": "2024-12-11 20:24:15 UTC",
    "updated_date": "2024-12-11 20:24:15 UTC"
  },
  {
    "arxiv_id": "2412.12165v1",
    "title": "Multimodal Approaches to Fair Image Classification: An Ethical Perspective",
    "authors": [
      "Javon Hickmon"
    ],
    "abstract": "In the rapidly advancing field of artificial intelligence, machine perception\nis becoming paramount to achieving increased performance. Image classification\nsystems are becoming increasingly integral to various applications, ranging\nfrom medical diagnostics to image generation; however, these systems often\nexhibit harmful biases that can lead to unfair and discriminatory outcomes.\nMachine Learning systems that depend on a single data modality, i.e. only\nimages or only text, can exaggerate hidden biases present in the training data,\nif the data is not carefully balanced and filtered. Even so, these models can\nstill harm underrepresented populations when used in improper contexts, such as\nwhen government agencies reinforce racial bias using predictive policing. This\nthesis explores the intersection of technology and ethics in the development of\nfair image classification models. Specifically, I focus on improving fairness\nand methods of using multiple modalities to combat harmful demographic bias.\nIntegrating multimodal approaches, which combine visual data with additional\nmodalities such as text and metadata, allows this work to enhance the fairness\nand accuracy of image classification systems. The study critically examines\nexisting biases in image datasets and classification algorithms, proposes\ninnovative methods for mitigating these biases, and evaluates the ethical\nimplications of deploying such systems in real-world scenarios. Through\ncomprehensive experimentation and analysis, the thesis demonstrates how\nmultimodal techniques can contribute to more equitable and ethical AI\nsolutions, ultimately advocating for responsible AI practices that prioritize\nfairness.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Bachelor's thesis",
    "pdf_url": "http://arxiv.org/pdf/2412.12165v1",
    "published_date": "2024-12-11 19:58:31 UTC",
    "updated_date": "2024-12-11 19:58:31 UTC"
  },
  {
    "arxiv_id": "2412.08755v4",
    "title": "Proactive Adversarial Defense: Harnessing Prompt Tuning in Vision-Language Models to Detect Unseen Backdoored Images",
    "authors": [
      "Kyle Stein",
      "Andrew Arash Mahyari",
      "Guillermo Francia",
      "Eman El-Sheikh"
    ],
    "abstract": "Backdoor attacks pose a critical threat by embedding hidden triggers into\ninputs, causing models to misclassify them into target labels. While extensive\nresearch has focused on mitigating these attacks in object recognition models\nthrough weight fine-tuning, much less attention has been given to detecting\nbackdoored samples directly. Given the vast datasets used in training, manual\ninspection for backdoor triggers is impractical, and even state-of-the-art\ndefense mechanisms fail to fully neutralize their impact. To address this gap,\nwe introduce a groundbreaking method to detect unseen backdoored images during\nboth training and inference. Leveraging the transformative success of prompt\ntuning in Vision Language Models (VLMs), our approach trains learnable text\nprompts to differentiate clean images from those with hidden backdoor triggers.\nExperiments demonstrate the exceptional efficacy of this method, achieving an\nimpressive average accuracy of 86% across two renowned datasets for detecting\nunseen backdoor triggers, establishing a new standard in backdoor defense.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.08755v4",
    "published_date": "2024-12-11 19:54:14 UTC",
    "updated_date": "2025-04-07 18:01:26 UTC"
  },
  {
    "arxiv_id": "2412.08751v1",
    "title": "Sampling-based Continuous Optimization with Coupled Variables for RNA Design",
    "authors": [
      "Wei Yu Tang",
      "Ning Dai",
      "Tianshuo Zhou",
      "David H. Mathews",
      "Liang Huang"
    ],
    "abstract": "The task of RNA design given a target structure aims to find a sequence that\ncan fold into that structure. It is a computationally hard problem where some\nversion(s) have been proven to be NP-hard. As a result, heuristic methods such\nas local search have been popular for this task, but by only exploring a fixed\nnumber of candidates. They can not keep up with the exponential growth of the\ndesign space, and often perform poorly on longer and harder-to-design\nstructures. We instead formulate these discrete problems as continuous\noptimization, which starts with a distribution over all possible candidate\nsequences, and uses gradient descent to improve the expectation of an objective\nfunction. We define novel distributions based on coupled variables to rule out\ninvalid sequences given the target structure and to model the correlation\nbetween nucleotides. To make it universally applicable to any objective\nfunction, we use sampling to approximate the expected objective function, to\nestimate the gradient, and to select the final candidate. Compared to the\nstate-of-the-art methods, our work consistently outperforms them in key metrics\nsuch as Boltzmann probability, ensemble defect, and energy gap, especially on\nlong and hard-to-design puzzles in the Eterna100 benchmark. Our code is\navailable at: http://github.com/weiyutang1010/ncrna_design.",
    "categories": [
      "q-bio.BM",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.BM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.08751v1",
    "published_date": "2024-12-11 19:46:54 UTC",
    "updated_date": "2024-12-11 19:46:54 UTC"
  },
  {
    "arxiv_id": "2412.08742v1",
    "title": "In-Context Learning with Topological Information for Knowledge Graph Completion",
    "authors": [
      "Udari Madhushani Sehwag",
      "Kassiani Papasotiriou",
      "Jared Vann",
      "Sumitra Ganesh"
    ],
    "abstract": "Knowledge graphs (KGs) are crucial for representing and reasoning over\nstructured information, supporting a wide range of applications such as\ninformation retrieval, question answering, and decision-making. However, their\neffectiveness is often hindered by incompleteness, limiting their potential for\nreal-world impact. While knowledge graph completion (KGC) has been extensively\nstudied in the literature, recent advances in generative AI models,\nparticularly large language models (LLMs), have introduced new opportunities\nfor innovation. In-context learning has recently emerged as a promising\napproach for leveraging pretrained knowledge of LLMs across a range of natural\nlanguage processing tasks and has been widely adopted in both academia and\nindustry. However, how to utilize in-context learning for effective KGC remains\nrelatively underexplored. We develop a novel method that incorporates\ntopological information through in-context learning to enhance KGC performance.\nBy integrating ontological knowledge and graph structure into the context of\nLLMs, our approach achieves strong performance in the transductive setting\ni.e., nodes in the test graph dataset are present in the training graph\ndataset. Furthermore, we apply our approach to KGC in the more challenging\ninductive setting, i.e., nodes in the training graph dataset and test graph\ndataset are disjoint, leveraging the ontology to infer useful information about\nmissing nodes which serve as contextual cues for the LLM during inference. Our\nmethod demonstrates superior performance compared to baselines on the\nILPC-small and ILPC-large datasets.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "68T37 (Primary), 68T05, 68P20 (Secondary)"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.08742v1",
    "published_date": "2024-12-11 19:29:36 UTC",
    "updated_date": "2024-12-11 19:29:36 UTC"
  },
  {
    "arxiv_id": "2412.08739v1",
    "title": "VEL: A Formally Verified Reasoner for OWL2 EL Profile",
    "authors": [
      "Atalay Mert Ileri",
      "Nalen Rangarajan",
      "Jack Cannell",
      "Hande McGinty"
    ],
    "abstract": "Over the past two decades, the Web Ontology Language (OWL) has been\ninstrumental in advancing the development of ontologies and knowledge graphs,\nproviding a structured framework that enhances the semantic integration of\ndata. However, the reliability of deductive reasoning within these systems\nremains challenging, as evidenced by inconsistencies among popular reasoners in\nrecent competitions. This evidence underscores the limitations of current\ntesting-based methodologies, particularly in high-stakes domains such as\nhealthcare. To mitigate these issues, in this paper, we have developed VEL, a\nformally verified EL++ reasoner equipped with machine-checkable correctness\nproofs that ensure the validity of outputs across all possible inputs. This\nformalization, based on the algorithm of Baader et al., has been transformed\ninto executable OCaml code using the Coq proof assistant's extraction\ncapabilities. Our formalization revealed several errors in the original\ncompleteness proofs, which led to changes to the algorithm to ensure its\ncompleteness. Our work demonstrates the necessity of mechanization of reasoning\nalgorithms to ensure their correctness at theoretical and implementation\nlevels.",
    "categories": [
      "cs.LO",
      "cs.AI",
      "cs.PL"
    ],
    "primary_category": "cs.LO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.08739v1",
    "published_date": "2024-12-11 19:17:28 UTC",
    "updated_date": "2024-12-11 19:17:28 UTC"
  },
  {
    "arxiv_id": "2412.12164v2",
    "title": "GAMED: Knowledge Adaptive Multi-Experts Decoupling for Multimodal Fake News Detection",
    "authors": [
      "Lingzhi Shen",
      "Yunfei Long",
      "Xiaohao Cai",
      "Imran Razzak",
      "Guanming Chen",
      "Kang Liu",
      "Shoaib Jameel"
    ],
    "abstract": "Multimodal fake news detection often involves modelling heterogeneous data\nsources, such as vision and language. Existing detection methods typically rely\non fusion effectiveness and cross-modal consistency to model the content,\ncomplicating understanding how each modality affects prediction accuracy.\nAdditionally, these methods are primarily based on static feature modelling,\nmaking it difficult to adapt to the dynamic changes and relationships between\ndifferent data modalities. This paper develops a significantly novel approach,\nGAMED, for multimodal modelling, which focuses on generating distinctive and\ndiscriminative features through modal decoupling to enhance cross-modal\nsynergies, thereby optimizing overall performance in the detection process.\nGAMED leverages multiple parallel expert networks to refine features and\npre-embed semantic knowledge to improve the experts' ability in information\nselection and viewpoint sharing. Subsequently, the feature distribution of each\nmodality is adaptively adjusted based on the respective experts' opinions.\nGAMED also introduces a novel classification technique to dynamically manage\ncontributions from different modalities, while improving the explainability of\ndecisions. Experimental results on the Fakeddit and Yang datasets demonstrate\nthat GAMED performs better than recently developed state-of-the-art models. The\nsource code can be accessed at https://github.com/slz0925/GAMED.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.12164v2",
    "published_date": "2024-12-11 19:12:22 UTC",
    "updated_date": "2025-03-02 15:12:38 UTC"
  },
  {
    "arxiv_id": "2412.08737v1",
    "title": "Euclid: Supercharging Multimodal LLMs with Synthetic High-Fidelity Visual Descriptions",
    "authors": [
      "Jiarui Zhang",
      "Ollie Liu",
      "Tianyu Yu",
      "Jinyi Hu",
      "Willie Neiswanger"
    ],
    "abstract": "Multimodal large language models (MLLMs) have made rapid progress in recent\nyears, yet continue to struggle with low-level visual perception (LLVP) --\nparticularly the ability to accurately describe the geometric details of an\nimage. This capability is crucial for applications in areas such as robotics,\nmedical image analysis, and manufacturing. In this paper, we first introduce\nGeoperception, a benchmark designed to evaluate an MLLM's ability to accurately\ntranscribe 2D geometric information from an image. Using this benchmark, we\ndemonstrate the limitations of leading MLLMs, and then conduct a comprehensive\nempirical study to explore strategies for improving their performance on\ngeometric tasks. Our findings highlight the benefits of certain model\narchitectures, training techniques, and data strategies, including the use of\nhigh-fidelity synthetic data and multi-stage training with a data curriculum.\nNotably, we find that a data curriculum enables models to learn challenging\ngeometry understanding tasks which they fail to learn from scratch. Leveraging\nthese insights, we develop Euclid, a family of models specifically optimized\nfor strong low-level geometric perception. Although purely trained on synthetic\nmultimodal data, Euclid shows strong generalization ability to novel geometry\nshapes. For instance, Euclid outperforms the best closed-source model,\nGemini-1.5-Pro, by up to 58.56% on certain Geoperception benchmark tasks and\n10.65% on average across all tasks.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "33 pages, 22 figures, 5 tables, 7 algorithms",
    "pdf_url": "http://arxiv.org/pdf/2412.08737v1",
    "published_date": "2024-12-11 19:12:13 UTC",
    "updated_date": "2024-12-11 19:12:13 UTC"
  },
  {
    "arxiv_id": "2412.08731v1",
    "title": "From MLP to NeoMLP: Leveraging Self-Attention for Neural Fields",
    "authors": [
      "Miltiadis Kofinas",
      "Samuele Papa",
      "Efstratios Gavves"
    ],
    "abstract": "Neural fields (NeFs) have recently emerged as a state-of-the-art method for\nencoding spatio-temporal signals of various modalities. Despite the success of\nNeFs in reconstructing individual signals, their use as representations in\ndownstream tasks, such as classification or segmentation, is hindered by the\ncomplexity of the parameter space and its underlying symmetries, in addition to\nthe lack of powerful and scalable conditioning mechanisms. In this work, we\ndraw inspiration from the principles of connectionism to design a new\narchitecture based on MLPs, which we term NeoMLP. We start from an MLP, viewed\nas a graph, and transform it from a multi-partite graph to a complete graph of\ninput, hidden, and output nodes, equipped with high-dimensional features. We\nperform message passing on this graph and employ weight-sharing via\nself-attention among all the nodes. NeoMLP has a built-in mechanism for\nconditioning through the hidden and output nodes, which function as a set of\nlatent codes, and as such, NeoMLP can be used straightforwardly as a\nconditional neural field. We demonstrate the effectiveness of our method by\nfitting high-resolution signals, including multi-modal audio-visual data.\nFurthermore, we fit datasets of neural representations, by learning\ninstance-specific sets of latent codes using a single backbone architecture,\nand then use them for downstream tasks, outperforming recent state-of-the-art\nmethods. The source code is open-sourced at https://github.com/mkofinas/neomlp.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Preprint. Source code: https://github.com/mkofinas/neomlp",
    "pdf_url": "http://arxiv.org/pdf/2412.08731v1",
    "published_date": "2024-12-11 19:01:38 UTC",
    "updated_date": "2024-12-11 19:01:38 UTC"
  },
  {
    "arxiv_id": "2412.08725v1",
    "title": "A quantum-classical reinforcement learning model to play Atari games",
    "authors": [
      "Dominik Freinberger",
      "Julian Lemmel",
      "Radu Grosu",
      "Sofiene Jerbi"
    ],
    "abstract": "Recent advances in reinforcement learning have demonstrated the potential of\nquantum learning models based on parametrized quantum circuits as an\nalternative to deep learning models. On the one hand, these findings have shown\nthe ultimate exponential speed-ups in learning that full-blown quantum models\ncan offer in certain -- artificially constructed -- environments. On the other\nhand, they have demonstrated the ability of experimentally accessible PQCs to\nsolve OpenAI Gym benchmarking tasks. However, it remains an open question\nwhether these near-term QRL techniques can be successfully applied to more\ncomplex problems exhibiting high-dimensional observation spaces. In this work,\nwe bridge this gap and present a hybrid model combining a PQC with classical\nfeature encoding and post-processing layers that is capable of tackling Atari\ngames. A classical model, subjected to architectural restrictions similar to\nthose present in the hybrid model is constructed to serve as a reference. Our\nnumerical investigation demonstrates that the proposed hybrid model is capable\nof solving the Pong environment and achieving scores comparable to the\nclassical reference in Breakout. Furthermore, our findings shed light on\nimportant hyperparameter settings and design choices that impact the interplay\nof the quantum and classical components. This work contributes to the\nunderstanding of near-term quantum learning models and makes an important step\ntowards their deployment in real-world RL scenarios.",
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "quant-ph",
    "comment": "10 + 13 pages",
    "pdf_url": "http://arxiv.org/pdf/2412.08725v1",
    "published_date": "2024-12-11 19:00:09 UTC",
    "updated_date": "2024-12-11 19:00:09 UTC"
  },
  {
    "arxiv_id": "2412.08643v1",
    "title": "GPD-1: Generative Pre-training for Driving",
    "authors": [
      "Zixun Xie",
      "Sicheng Zuo",
      "Wenzhao Zheng",
      "Yunpeng Zhang",
      "Dalong Du",
      "Jie Zhou",
      "Jiwen Lu",
      "Shanghang Zhang"
    ],
    "abstract": "Modeling the evolutions of driving scenarios is important for the evaluation\nand decision-making of autonomous driving systems. Most existing methods focus\non one aspect of scene evolution such as map generation, motion prediction, and\ntrajectory planning. In this paper, we propose a unified Generative\nPre-training for Driving (GPD-1) model to accomplish all these tasks altogether\nwithout additional fine-tuning. We represent each scene with ego, agent, and\nmap tokens and formulate autonomous driving as a unified token generation\nproblem. We adopt the autoregressive transformer architecture and use a\nscene-level attention mask to enable intra-scene bi-directional interactions.\nFor the ego and agent tokens, we propose a hierarchical positional tokenizer to\neffectively encode both 2D positions and headings. For the map tokens, we train\na map vector-quantized autoencoder to efficiently compress ego-centric semantic\nmaps into discrete tokens. We pre-train our GPD-1 on the large-scale nuPlan\ndataset and conduct extensive experiments to evaluate its effectiveness. With\ndifferent prompts, our GPD-1 successfully generalizes to various tasks without\nfinetuning, including scene generation, traffic simulation, closed-loop\nsimulation, map prediction, and motion planning. Code:\nhttps://github.com/wzzheng/GPD.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "Code is available at: https://github.com/wzzheng/GPD",
    "pdf_url": "http://arxiv.org/pdf/2412.08643v1",
    "published_date": "2024-12-11 18:59:51 UTC",
    "updated_date": "2024-12-11 18:59:51 UTC"
  },
  {
    "arxiv_id": "2412.08637v3",
    "title": "DMin: Scalable Training Data Influence Estimation for Diffusion Models",
    "authors": [
      "Huawei Lin",
      "Yingjie Lao",
      "Weijie Zhao"
    ],
    "abstract": "Identifying the training data samples that most influence a generated image\nis a critical task in understanding diffusion models (DMs), yet existing\ninfluence estimation methods are constrained to small-scale or LoRA-tuned\nmodels due to computational limitations. To address this challenge, we propose\nDMin (Diffusion Model influence), a scalable framework for estimating the\ninfluence of each training data sample on a given generated image. To the best\nof our knowledge, it is the first method capable of influence estimation for\nDMs with billions of parameters. Leveraging efficient gradient compression,\nDMin reduces storage requirements from hundreds of TBs to mere MBs or even KBs,\nand retrieves the top-k most influential training samples in under 1 second,\nall while maintaining performance. Our empirical results demonstrate DMin is\nboth effective in identifying influential training samples and efficient in\nterms of computational and storage requirements.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "14 pages, 6 figures, 8 tables. Under Review",
    "pdf_url": "http://arxiv.org/pdf/2412.08637v3",
    "published_date": "2024-12-11 18:58:40 UTC",
    "updated_date": "2025-03-11 03:10:09 UTC"
  },
  {
    "arxiv_id": "2412.10447v1",
    "title": "TidyBot++: An Open-Source Holonomic Mobile Manipulator for Robot Learning",
    "authors": [
      "Jimmy Wu",
      "William Chong",
      "Robert Holmberg",
      "Aaditya Prasad",
      "Yihuai Gao",
      "Oussama Khatib",
      "Shuran Song",
      "Szymon Rusinkiewicz",
      "Jeannette Bohg"
    ],
    "abstract": "Exploiting the promise of recent advances in imitation learning for mobile\nmanipulation will require the collection of large numbers of human-guided\ndemonstrations. This paper proposes an open-source design for an inexpensive,\nrobust, and flexible mobile manipulator that can support arbitrary arms,\nenabling a wide range of real-world household mobile manipulation tasks.\nCrucially, our design uses powered casters to enable the mobile base to be\nfully holonomic, able to control all planar degrees of freedom independently\nand simultaneously. This feature makes the base more maneuverable and\nsimplifies many mobile manipulation tasks, eliminating the kinematic\nconstraints that create complex and time-consuming motions in nonholonomic\nbases. We equip our robot with an intuitive mobile phone teleoperation\ninterface to enable easy data acquisition for imitation learning. In our\nexperiments, we use this interface to collect data and show that the resulting\nlearned policies can successfully perform a variety of common household mobile\nmanipulation tasks.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "Conference on Robot Learning (CoRL), 2024. Project page:\n  https://tidybot2.github.io",
    "pdf_url": "http://arxiv.org/pdf/2412.10447v1",
    "published_date": "2024-12-11 18:54:22 UTC",
    "updated_date": "2024-12-11 18:54:22 UTC"
  },
  {
    "arxiv_id": "2412.12163v1",
    "title": "Towards LLM-based optimization compilers. Can LLMs learn how to apply a single peephole optimization? Reasoning is all LLMs need!",
    "authors": [
      "Xiangxin Fang",
      "Lev Mukhanov"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated great potential in various\nlanguage processing tasks, and recent studies have explored their application\nin compiler optimizations. However, all these studies focus on the conventional\nopen-source LLMs, such as Llama2, which lack enhanced reasoning mechanisms. In\nthis study, we investigate the errors produced by the fine-tuned 7B-parameter\nLlama2 model as it attempts to learn and apply a simple peephole optimization\nfor the AArch64 assembly code. We provide an analysis of the errors produced by\nthe LLM and compare it with state-of-the-art OpenAI models which implement\nadvanced reasoning logic, including GPT-4o and GPT-o1 (preview). We demonstrate\nthat OpenAI GPT-o1, despite not being fine-tuned, outperforms the fine-tuned\nLlama2 and GPT-4o. Our findings indicate that this advantage is largely due to\nthe chain-of-thought reasoning implemented in GPT-o1. We hope our work will\ninspire further research on using LLMs with enhanced reasoning mechanisms and\nchain-of-thought for code generation and optimization.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.PL"
    ],
    "primary_category": "cs.LG",
    "comment": "13 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.12163v1",
    "published_date": "2024-12-11 18:44:31 UTC",
    "updated_date": "2024-12-11 18:44:31 UTC"
  },
  {
    "arxiv_id": "2412.08619v2",
    "title": "Physics Context Builders: A Modular Framework for Physical Reasoning in Vision-Language Models",
    "authors": [
      "Vahid Balazadeh",
      "Mohammadmehdi Ataei",
      "Hyunmin Cheong",
      "Amir Hosein Khasahmadi",
      "Rahul G. Krishnan"
    ],
    "abstract": "Physical reasoning, which involves interpreting object behaviors within\ndynamic environments, remains a significant challenge for Vision-Language\nModels (VLMs). The limitations in physical reasoning arise from an inability to\ntranslate learned knowledge into predictions about physical behavior. We\nperform a careful study to show how continual fine-tuning can mitigate this\nissue. However, fine-tuning is expensive for large models and impractical to\nrepeatedly perform for every task. This necessitates the creation of modular\nand scalable ways to teach VLMs about physical reasoning. To that end, we\nintroduce Physics Context Builders (PCBs), a novel modular framework where\nspecialized VLMs are fine-tuned to generate detailed physical scene\ndescriptions. These can be used as physical contexts for larger VLMs to enhance\ntheir reasoning capabilities. PCBs enable the separation of visual perception\nfrom reasoning, allowing us to analyze their relative contributions to physical\nunderstanding. We perform careful experiments on CLEVRER and on Falling Tower,\na stability detection dataset with both simulated and real-world scenes, to\ndemonstrate that PCBs provide substantial performance improvements, increasing\naverage accuracy by up to 13.8% on complex physical reasoning tasks. Notably,\nPCBs show strong Sim2Real transfer, successfully generalizing from simulated\ntraining data to real-world scenes. Our work demonstrates that enhancing visual\nperception through modular, simulation-trained components offers a practical\napproach to improving physical reasoning in VLMs, while providing insights into\nthe factors affecting physical understanding in these models.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.08619v2",
    "published_date": "2024-12-11 18:40:16 UTC",
    "updated_date": "2025-03-10 17:01:51 UTC"
  },
  {
    "arxiv_id": "2412.08618v1",
    "title": "Image Retrieval Methods in the Dissimilarity Space",
    "authors": [
      "Madhu Kiran",
      "Kartikey Vishnu",
      "Rafael M. O. Cruz",
      "Eric Granger"
    ],
    "abstract": "Image retrieval methods rely on metric learning to train backbone feature\nextraction models that can extract discriminant queries and reference (gallery)\nfeature representations for similarity matching. Although state-of-the-art\naccuracy has improved considerably with the advent of deep learning (DL) models\ntrained on large datasets, image retrieval remains challenging in many\nreal-world video analytics and surveillance applications, e.g., person\nre-identification. Using the Euclidean space for matching limits the\nperformance in real-world applications due to the curse of dimensionality,\noverfitting, and sensitivity to noisy data.\n  We argue that the feature dissimilarity space is more suitable for similarity\nmatching, and propose a dichotomy transformation to project query and reference\nembeddings into a single embedding in the dissimilarity space.\n  We also advocate for end-to-end training of a backbone and binary\nclassification models for pair-wise matching. As opposed to comparing the\ndistance between queries and reference embeddings, we show the benefits of\nclassifying the single dissimilarity space embedding (as similar or\ndissimilar), especially when trained end-to-end. We propose a method to train\nthe max-margin classifier together with the backbone feature extractor by\napplying constraints to the L2 norm of the classifier weights along with the\nhinge loss.\n  Our extensive experiments on challenging image retrieval datasets and using\ndiverse feature extraction backbones highlight the benefits of similarity\nmatching in the dissimilarity space. In particular, when jointly training the\nfeature extraction backbone and regularised classifier for matching, the\ndissimilarity space provides a higher level of accuracy.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "7 pages",
    "pdf_url": "http://arxiv.org/pdf/2412.08618v1",
    "published_date": "2024-12-11 18:39:32 UTC",
    "updated_date": "2024-12-11 18:39:32 UTC"
  },
  {
    "arxiv_id": "2412.08610v1",
    "title": "Competition and Diversity in Generative AI",
    "authors": [
      "Manish Raghavan"
    ],
    "abstract": "Recent evidence suggests that the use of generative artificial intelligence\nreduces the diversity of content produced. In this work, we develop a\ngame-theoretic model to explore the downstream consequences of content\nhomogeneity when producers use generative AI to compete with one another. At\nequilibrium, players indeed produce content that is less diverse than optimal.\nHowever, stronger competition mitigates homogeneity and induces more diverse\nproduction. Perhaps more surprisingly, we show that a generative AI model that\nperforms well in isolation (i.e., according to a benchmark) may fail to do so\nwhen faced with competition, and vice versa. We validate our results\nempirically by using language models to play Scattergories, a word game in\nwhich players are rewarded for producing answers that are both correct and\nunique. We discuss how the interplay between competition and homogeneity has\nimplications for the development, evaluation, and use of generative AI.",
    "categories": [
      "cs.GT",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.GT",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.08610v1",
    "published_date": "2024-12-11 18:34:31 UTC",
    "updated_date": "2024-12-11 18:34:31 UTC"
  },
  {
    "arxiv_id": "2412.08608v1",
    "title": "AdvWave: Stealthy Adversarial Jailbreak Attack against Large Audio-Language Models",
    "authors": [
      "Mintong Kang",
      "Chejian Xu",
      "Bo Li"
    ],
    "abstract": "Recent advancements in large audio-language models (LALMs) have enabled\nspeech-based user interactions, significantly enhancing user experience and\naccelerating the deployment of LALMs in real-world applications. However,\nensuring the safety of LALMs is crucial to prevent risky outputs that may raise\nsocietal concerns or violate AI regulations. Despite the importance of this\nissue, research on jailbreaking LALMs remains limited due to their recent\nemergence and the additional technical challenges they present compared to\nattacks on DNN-based audio models. Specifically, the audio encoders in LALMs,\nwhich involve discretization operations, often lead to gradient shattering,\nhindering the effectiveness of attacks relying on gradient-based optimizations.\nThe behavioral variability of LALMs further complicates the identification of\neffective (adversarial) optimization targets. Moreover, enforcing stealthiness\nconstraints on adversarial audio waveforms introduces a reduced, non-convex\nfeasible solution space, further intensifying the challenges of the\noptimization process. To overcome these challenges, we develop AdvWave, the\nfirst jailbreak framework against LALMs. We propose a dual-phase optimization\nmethod that addresses gradient shattering, enabling effective end-to-end\ngradient-based optimization. Additionally, we develop an adaptive adversarial\ntarget search algorithm that dynamically adjusts the adversarial optimization\ntarget based on the response patterns of LALMs for specific queries. To ensure\nthat adversarial audio remains perceptually natural to human listeners, we\ndesign a classifier-guided optimization approach that generates adversarial\nnoise resembling common urban sounds. Extensive evaluations on multiple\nadvanced LALMs demonstrate that AdvWave outperforms baseline methods, achieving\na 40% higher average jailbreak attack success rate.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CR",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.08608v1",
    "published_date": "2024-12-11 18:30:57 UTC",
    "updated_date": "2024-12-11 18:30:57 UTC"
  },
  {
    "arxiv_id": "2412.08604v1",
    "title": "Preference Discerning with LLM-Enhanced Generative Retrieval",
    "authors": [
      "Fabian Paischer",
      "Liu Yang",
      "Linfeng Liu",
      "Shuai Shao",
      "Kaveh Hassani",
      "Jiacheng Li",
      "Ricky Chen",
      "Zhang Gabriel Li",
      "Xialo Gao",
      "Wei Shao",
      "Xue Feng",
      "Nima Noorshams",
      "Sem Park",
      "Bo Long",
      "Hamid Eghbalzadeh"
    ],
    "abstract": "Sequential recommendation systems aim to provide personalized recommendations\nfor users based on their interaction history. To achieve this, they often\nincorporate auxiliary information, such as textual descriptions of items and\nauxiliary tasks, like predicting user preferences and intent. Despite numerous\nefforts to enhance these models, they still suffer from limited\npersonalization. To address this issue, we propose a new paradigm, which we\nterm preference discerning. In preference dscerning, we explicitly condition a\ngenerative sequential recommendation system on user preferences within its\ncontext. To this end, we generate user preferences using Large Language Models\n(LLMs) based on user reviews and item-specific data. To evaluate preference\ndiscerning capabilities of sequential recommendation systems, we introduce a\nnovel benchmark that provides a holistic evaluation across various scenarios,\nincluding preference steering and sentiment following. We assess current\nstate-of-the-art methods using our benchmark and show that they struggle to\naccurately discern user preferences. Therefore, we propose a new method named\nMender ($\\textbf{M}$ultimodal Prefer$\\textbf{en}$ce\n$\\textbf{d}$iscern$\\textbf{er}$), which improves upon existing methods and\nachieves state-of-the-art performance on our benchmark. Our results show that\nMender can be effectively guided by human preferences even though they have not\nbeen observed during training, paving the way toward more personalized\nsequential recommendation systems. We will open-source the code and benchmarks\nupon publication.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.IR",
    "comment": "11 pages + references and appendix",
    "pdf_url": "http://arxiv.org/pdf/2412.08604v1",
    "published_date": "2024-12-11 18:26:55 UTC",
    "updated_date": "2024-12-11 18:26:55 UTC"
  },
  {
    "arxiv_id": "2412.10446v1",
    "title": "Disentanglement and Compositionality of Letter Identity and Letter Position in Variational Auto-Encoder Vision Models",
    "authors": [
      "Bruno Bianchi",
      "Aakash Agrawal",
      "Stanislas Dehaene",
      "Emmanuel Chemla",
      "Yair Lakretz"
    ],
    "abstract": "Human readers can accurately count how many letters are in a word (e.g., 7 in\n``buffalo''), remove a letter from a given position (e.g., ``bufflo'') or add a\nnew one. The human brain of readers must have therefore learned to disentangle\ninformation related to the position of a letter and its identity. Such\ndisentanglement is necessary for the compositional, unbounded, ability of\nhumans to create and parse new strings, with any combination of letters\nappearing in any positions. Do modern deep neural models also possess this\ncrucial compositional ability? Here, we tested whether neural models that\nachieve state-of-the-art on disentanglement of features in visual input can\nalso disentangle letter position and letter identity when trained on images of\nwritten words. Specifically, we trained beta variational autoencoder\n($\\beta$-VAE) to reconstruct images of letter strings and evaluated their\ndisentanglement performance using CompOrth - a new benchmark that we created\nfor studying compositional learning and zero-shot generalization in visual\nmodels for orthography. The benchmark suggests a set of tests, of increasing\ncomplexity, to evaluate the degree of disentanglement between orthographic\nfeatures of written words in deep neural models. Using CompOrth, we conducted a\nset of experiments to analyze the generalization ability of these models, in\nparticular, to unseen word length and to unseen combinations of letter\nidentities and letter positions. We found that while models effectively\ndisentangle surface features, such as horizontal and vertical `retinal'\nlocations of words within an image, they dramatically fail to disentangle\nletter position and letter identity and lack any notion of word length.\nTogether, this study demonstrates the shortcomings of state-of-the-art\n$\\beta$-VAE models compared to humans and proposes a new challenge and a\ncorresponding benchmark to evaluate neural models.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.10446v1",
    "published_date": "2024-12-11 18:20:53 UTC",
    "updated_date": "2024-12-11 18:20:53 UTC"
  },
  {
    "arxiv_id": "2412.08681v1",
    "title": "Learning Physics Informed Neural ODEs With Partial Measurements",
    "authors": [
      "Paul Ghanem",
      "Ahmet Demirkaya",
      "Tales Imbiriba",
      "Alireza Ramezani",
      "Zachary Danziger",
      "Deniz Erdogmus"
    ],
    "abstract": "Learning dynamics governing physical and spatiotemporal processes is a\nchallenging problem, especially in scenarios where states are partially\nmeasured. In this work, we tackle the problem of learning dynamics governing\nthese systems when parts of the system's states are not measured, specifically\nwhen the dynamics generating the non-measured states are unknown. Inspired by\nstate estimation theory and Physics Informed Neural ODEs, we present a\nsequential optimization framework in which dynamics governing unmeasured\nprocesses can be learned. We demonstrate the performance of the proposed\napproach leveraging numerical simulations and a real dataset extracted from an\nelectro-mechanical positioning system. We show how the underlying equations fit\ninto our formalism and demonstrate the improved performance of the proposed\nmethod when compared with baselines.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.08681v1",
    "published_date": "2024-12-11 18:17:34 UTC",
    "updated_date": "2024-12-11 18:17:34 UTC"
  },
  {
    "arxiv_id": "2412.08591v2",
    "title": "RoomTour3D: Geometry-Aware Video-Instruction Tuning for Embodied Navigation",
    "authors": [
      "Mingfei Han",
      "Liang Ma",
      "Kamila Zhumakhanova",
      "Ekaterina Radionova",
      "Jingyi Zhang",
      "Xiaojun Chang",
      "Xiaodan Liang",
      "Ivan Laptev"
    ],
    "abstract": "Vision-and-Language Navigation (VLN) suffers from the limited diversity and\nscale of training data, primarily constrained by the manual curation of\nexisting simulators. To address this, we introduce RoomTour3D, a\nvideo-instruction dataset derived from web-based room tour videos that capture\nreal-world indoor spaces and human walking demonstrations. Unlike existing VLN\ndatasets, RoomTour3D leverages the scale and diversity of online videos to\ngenerate open-ended human walking trajectories and open-world navigable\ninstructions. To compensate for the lack of navigation data in online videos,\nwe perform 3D reconstruction and obtain 3D trajectories of walking paths\naugmented with additional information on the room types, object locations and\n3D shape of surrounding scenes. Our dataset includes $\\sim$100K open-ended\ndescription-enriched trajectories with $\\sim$200K instructions, and 17K\naction-enriched trajectories from 1847 room tour environments. We demonstrate\nexperimentally that RoomTour3D enables significant improvements across multiple\nVLN tasks including CVDN, SOON, R2R, and REVERIE. Moreover, RoomTour3D\nfacilitates the development of trainable zero-shot VLN agents, showcasing the\npotential and challenges of advancing towards open-world navigation.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "CVPR2025",
    "pdf_url": "http://arxiv.org/pdf/2412.08591v2",
    "published_date": "2024-12-11 18:10:21 UTC",
    "updated_date": "2025-03-19 10:05:05 UTC"
  },
  {
    "arxiv_id": "2412.08680v1",
    "title": "Distinguishing Scams and Fraud with Ensemble Learning",
    "authors": [
      "Isha Chadalavada",
      "Tianhui Huang",
      "Jessica Staddon"
    ],
    "abstract": "Users increasingly query LLM-enabled web chatbots for help with scam defense.\nThe Consumer Financial Protection Bureau's complaints database is a rich data\nsource for evaluating LLM performance on user scam queries, but currently the\ncorpus does not distinguish between scam and non-scam fraud. We developed an\nLLM ensemble approach to distinguishing scam and fraud CFPB complaints and\ndescribe initial findings regarding the strengths and weaknesses of LLMs in the\nscam defense context.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.08680v1",
    "published_date": "2024-12-11 18:07:18 UTC",
    "updated_date": "2024-12-11 18:07:18 UTC"
  },
  {
    "arxiv_id": "2412.08587v2",
    "title": "Advancing Single and Multi-task Text Classification through Large Language Model Fine-tuning",
    "authors": [
      "Hang Zhao",
      "Qile P. Chen",
      "Yijing Barry Zhang",
      "Gang Yang"
    ],
    "abstract": "Both encoder-only models (e.g., BERT, RoBERTa) and large language models\n(LLMs, e.g., Llama3) have been widely used for text classification tasks.\nHowever, there is a lack of systematic studies comparing the performance of\nencoder-based models and LLMs in text classification, particularly when\nfine-tuning is involved. This study employed a diverse range of models and\nmethods, varying in size and architecture, and including both fine-tuned and\npre-trained approaches. We first assessed the performances of these LLMs on the\n20 Newsgroups (20NG) and MASSIVE datasets, comparing them to encoder-only\nRoBERTa models. Additionally, we explored the multi-task capabilities of both\nmodel types by combining multiple classification tasks, including intent\ndetection and slot-filling, into a single model using data from both datasets.\nOur results indicate that fully fine-tuned Llama3-70B models outperform\nRoBERTa-large and other decoder LLMs across various classification tasks and\ndatasets. Moreover, the consolidated multi-task fine-tuned LLMs matched the\nperformance of dual-model setups in both tasks across both datasets. Overall,\nour study provides a comprehensive benchmark of encoder-only and LLM models on\ntext classification tasks and demonstrates a method to combine two or more\nfully fine-tuned decoder LLMs for reduced latency and equivalent performance.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "9 pages, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2412.08587v2",
    "published_date": "2024-12-11 18:06:44 UTC",
    "updated_date": "2025-05-11 04:59:46 UTC"
  },
  {
    "arxiv_id": "2412.08585v3",
    "title": "TurboAttention: Efficient Attention Approximation For High Throughputs LLMs",
    "authors": [
      "Hao Kang",
      "Srikant Bharadwaj",
      "James Hensman",
      "Tushar Krishna",
      "Victor Ruhle",
      "Saravan Rajmohan"
    ],
    "abstract": "Large language model (LLM) inference demands significant amount of\ncomputation and memory, especially in the key attention mechanism. While\ntechniques, such as quantization and acceleration algorithms, like\nFlashAttention, have improved efficiency of the overall inference, they address\ndifferent aspects of the problem: quantization focuses on weight-activation\noperations, while FlashAttention improves execution but requires high-precision\nformats. Recent Key-value (KV) cache quantization reduces memory bandwidth but\nstill needs floating-point dequantization for attention operation.\n  We present TurboAttention, a comprehensive approach to enable quantized\nexecution of attention that simultaneously addresses both memory and\ncomputational efficiency. Our solution introduces two key innovations: FlashQ,\na headwise attention quantization technique that enables both compression of KV\ncache and quantized execution of activation-activation multiplication, and\nSparsity-based Softmax Approximation (SAS), which eliminates the need for\ndequantization to FP32 during exponentiation operation in attention.\nExperimental results demonstrate that TurboAttention achieves 1.2-1.8x speedup\nin attention, reduces the KV cache size by over 4.4x, and enables up to 2.37x\nmaximum throughput over the FP16 baseline while outperforming state-of-the-art\nquantization and compression techniques across various datasets and models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.AR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.08585v3",
    "published_date": "2024-12-11 18:03:05 UTC",
    "updated_date": "2024-12-17 05:40:09 UTC"
  },
  {
    "arxiv_id": "2412.08574v1",
    "title": "Learning Sketch Decompositions in Planning via Deep Reinforcement Learning",
    "authors": [
      "Michael Aichmüller",
      "Hector Geffner"
    ],
    "abstract": "In planning and reinforcement learning, the identification of common subgoal\nstructures across problems is important when goals are to be achieved over long\nhorizons. Recently, it has been shown that such structures can be expressed as\nfeature-based rules, called sketches, over a number of classical planning\ndomains. These sketches split problems into subproblems which then become\nsolvable in low polynomial time by a greedy sequence of IW$(k)$ searches.\nMethods for learning sketches using feature pools and min-SAT solvers have been\ndeveloped, yet they face two key limitations: scalability and expressivity. In\nthis work, we address these limitations by formulating the problem of learning\nsketch decompositions as a deep reinforcement learning (DRL) task, where\ngeneral policies are sought in a modified planning problem where the successor\nstates of a state s are defined as those reachable from s through an IW$(k)$\nsearch. The sketch decompositions obtained through this method are\nexperimentally evaluated across various domains, and problems are regarded as\nsolved by the decomposition when the goal is reached through a greedy sequence\nof IW$(k)$ searches. While our DRL approach for learning sketch decompositions\ndoes not yield interpretable sketches in the form of rules, we demonstrate that\nthe resulting decompositions can often be understood in a crisp manner.",
    "categories": [
      "cs.AI",
      "I.2.6; I.2.8"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.08574v1",
    "published_date": "2024-12-11 17:45:31 UTC",
    "updated_date": "2024-12-11 17:45:31 UTC"
  },
  {
    "arxiv_id": "2412.08565v2",
    "title": "GenPlan: Generative Sequence Models as Adaptive Planners",
    "authors": [
      "Akash Karthikeyan",
      "Yash Vardhan Pant"
    ],
    "abstract": "Sequence models have demonstrated remarkable success in behavioral planning\nby leveraging previously collected demonstrations. However, solving multi-task\nmissions remains a significant challenge, particularly when the planner must\nadapt to unseen constraints and tasks, such as discovering goals and unlocking\ndoors. Such behavioral planning problems are challenging to solve due to: a)\nagents failing to adapt beyond the single task learned through their reward\nfunction, and b) inability to generalize to new environments, e.g., those with\nwalls and locked doors, when trained only in planar environments. Consequently,\nstate-of-the-art decision-making methods are limited to missions where the\nrequired tasks are well-represented in the training demonstrations and can be\nsolved within a short (temporal) planning horizon. To address this, we propose\nGenPlan: a stochastic and adaptive planner that leverages discrete-flow models\nfor generative sequence modeling, enabling sample-efficient exploration and\nexploitation. This framework relies on an iterative denoising procedure to\ngenerate a sequence of goals and actions. This approach captures multi-modal\naction distributions and facilitates goal and task discovery, thereby\ngeneralizing to out-of-distribution tasks and environments, i.e., missions not\npart of the training data. We demonstrate the effectiveness of our method\nthrough multiple simulation environments. Notably, GenPlan outperforms\nstate-of-the-art methods by over 10% on adaptive planning tasks, where the\nagent adapts to multi-task missions while leveraging demonstrations from\nsingle-goal-reaching tasks. Our code is available at\nhttps://github.com/CL2-UWaterloo/GenPlan.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted in AAAI 2025. Project page:\n  https://aku02.github.io/projects/genplan/",
    "pdf_url": "http://arxiv.org/pdf/2412.08565v2",
    "published_date": "2024-12-11 17:32:33 UTC",
    "updated_date": "2024-12-25 19:45:43 UTC"
  },
  {
    "arxiv_id": "2412.08556v2",
    "title": "Exact Algorithms for Multiagent Path Finding with Communication Constraints on Tree-Like Structures",
    "authors": [
      "Foivos Fioravantes",
      "Dušan Knop",
      "Jan Matyáš Křišťan",
      "Nikolaos Melissinos",
      "Michal Opler"
    ],
    "abstract": "Consider the scenario where multiple agents have to move in an optimal way\nthrough a network, each one towards their ending position while avoiding\ncollisions. By optimal, we mean as fast as possible, which is evaluated by a\nmeasure known as the makespan of the proposed solution. This is the setting\nstudied in the Multiagent Path Finding problem. In this work, we additionally\nprovide the agents with a way to communicate with each other. Due to size\nconstraints, it is reasonable to assume that the range of communication of each\nagent will be limited. What should be the trajectories of the agents to,\nadditionally, maintain a backbone of communication? In this work, we study the\nMultiagent Path Finding with Communication Constraint problem under the\nparameterized complexity framework.\n  Our main contribution is three exact algorithms that are efficient when\nconsidering particular structures for the input network. We provide such\nalgorithms for the case when the communication range and the number of agents\n(the makespan resp.) are provided in the input and the network has a tree\ntopology, or bounded maximum degree (has a tree-like topology, i.e., bounded\ntreewidth resp.). We complement these results by showing that it is highly\nunlikely to construct efficient algorithms when considering the number of\nagents as part of the input, even if the makespan is $3$ and the communication\nrange is $1$.",
    "categories": [
      "cs.CC",
      "cs.AI"
    ],
    "primary_category": "cs.CC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.08556v2",
    "published_date": "2024-12-11 17:17:31 UTC",
    "updated_date": "2024-12-12 09:51:26 UTC"
  },
  {
    "arxiv_id": "2412.16184v1",
    "title": "More complex environments may be required to discover benefits of lifetime learning in evolving robots",
    "authors": [
      "Ege de Bruin",
      "Kyrre Glette",
      "Kai Olav Ellefsen"
    ],
    "abstract": "It is well known that intra-life learning, defined as an additional\ncontroller optimization loop, is beneficial for evolving robot morphologies for\nlocomotion. In this work, we investigate this further by comparing it in two\ndifferent environments: an easy flat environment and a more challenging hills\nenvironment. We show that learning is significantly more beneficial in a hilly\nenvironment than in a flat environment and that it might be needed to evaluate\nrobots in a more challenging environment to see the benefits of learning.",
    "categories": [
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.16184v1",
    "published_date": "2024-12-11 17:15:45 UTC",
    "updated_date": "2024-12-11 17:15:45 UTC"
  },
  {
    "arxiv_id": "2412.08542v1",
    "title": "MaestroMotif: Skill Design from Artificial Intelligence Feedback",
    "authors": [
      "Martin Klissarov",
      "Mikael Henaff",
      "Roberta Raileanu",
      "Shagun Sodhani",
      "Pascal Vincent",
      "Amy Zhang",
      "Pierre-Luc Bacon",
      "Doina Precup",
      "Marlos C. Machado",
      "Pierluca D'Oro"
    ],
    "abstract": "Describing skills in natural language has the potential to provide an\naccessible way to inject human knowledge about decision-making into an AI\nsystem. We present MaestroMotif, a method for AI-assisted skill design, which\nyields high-performing and adaptable agents. MaestroMotif leverages the\ncapabilities of Large Language Models (LLMs) to effectively create and reuse\nskills. It first uses an LLM's feedback to automatically design rewards\ncorresponding to each skill, starting from their natural language description.\nThen, it employs an LLM's code generation abilities, together with\nreinforcement learning, for training the skills and combining them to implement\ncomplex behaviors specified in language. We evaluate MaestroMotif using a suite\nof complex tasks in the NetHack Learning Environment (NLE), demonstrating that\nit surpasses existing approaches in both performance and usability.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.08542v1",
    "published_date": "2024-12-11 16:59:31 UTC",
    "updated_date": "2024-12-11 16:59:31 UTC"
  },
  {
    "arxiv_id": "2412.08520v1",
    "title": "GR-NLP-TOOLKIT: An Open-Source NLP Toolkit for Modern Greek",
    "authors": [
      "Lefteris Loukas",
      "Nikolaos Smyrnioudis",
      "Chrysa Dikonomaki",
      "Spyros Barbakos",
      "Anastasios Toumazatos",
      "John Koutsikakis",
      "Manolis Kyriakakis",
      "Mary Georgiou",
      "Stavros Vassos",
      "John Pavlopoulos",
      "Ion Androutsopoulos"
    ],
    "abstract": "We present GR-NLP-TOOLKIT, an open-source natural language processing (NLP)\ntoolkit developed specifically for modern Greek. The toolkit provides\nstate-of-the-art performance in five core NLP tasks, namely part-of-speech\ntagging, morphological tagging, dependency parsing, named entity recognition,\nand Greeklishto-Greek transliteration. The toolkit is based on pre-trained\nTransformers, it is freely available, and can be easily installed in Python\n(pip install gr-nlp-toolkit). It is also accessible through a demonstration\nplatform on HuggingFace, along with a publicly available API for non-commercial\nuse. We discuss the functionality provided for each task, the underlying\nmethods, experiments against comparable open-source toolkits, and future\npossible enhancements. The toolkit is available at:\nhttps://github.com/nlpaueb/gr-nlp-toolkit",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted Demo Paper @ COLING 2025 (Github:\n  https://github.com/nlpaueb/gr-nlp-toolkit/, Demo:\n  https://huggingface.co/spaces/AUEB-NLP/greek-nlp-toolkit-demo, API:\n  https://huggingface.co/spaces/AUEB-NLP/The-Greek-NLP-API)",
    "pdf_url": "http://arxiv.org/pdf/2412.08520v1",
    "published_date": "2024-12-11 16:34:23 UTC",
    "updated_date": "2024-12-11 16:34:23 UTC"
  },
  {
    "arxiv_id": "2412.08515v1",
    "title": "Enhancing Interpretability Through Loss-Defined Classification Objective in Structured Latent Spaces",
    "authors": [
      "Daniel Geissler",
      "Bo Zhou",
      "Mengxi Liu",
      "Paul Lukowicz"
    ],
    "abstract": "Supervised machine learning often operates on the data-driven paradigm,\nwherein internal model parameters are autonomously optimized to converge\npredicted outputs with the ground truth, devoid of explicitly programming rules\nor a priori assumptions. Although data-driven methods have yielded notable\nsuccesses across various benchmark datasets, they inherently treat models as\nopaque entities, thereby limiting their interpretability and yielding a lack of\nexplanatory insights into their decision-making processes. In this work, we\nintroduce Latent Boost, a novel approach that integrates advanced distance\nmetric learning into supervised classification tasks, enhancing both\ninterpretability and training efficiency. Thus during training, the model is\nnot only optimized for classification metrics of the discrete data points but\nalso adheres to the rule that the collective representation zones of each class\nshould be sharply clustered. By leveraging the rich structural insights of\nintermediate model layer latent representations, Latent Boost improves\nclassification interpretability, as demonstrated by higher Silhouette scores,\nwhile accelerating training convergence. These performance and latent\nstructural benefits are achieved with minimum additional cost, making it\nbroadly applicable across various datasets without requiring data-specific\nadjustments. Furthermore, Latent Boost introduces a new paradigm for aligning\nclassification performance with improved model transparency to address the\nchallenges of black-box models.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.08515v1",
    "published_date": "2024-12-11 16:25:17 UTC",
    "updated_date": "2024-12-11 16:25:17 UTC"
  },
  {
    "arxiv_id": "2412.08513v1",
    "title": "REPEAT: Improving Uncertainty Estimation in Representation Learning Explainability",
    "authors": [
      "Kristoffer K. Wickstrøm",
      "Thea Brüsch",
      "Michael C. Kampffmeyer",
      "Robert Jenssen"
    ],
    "abstract": "Incorporating uncertainty is crucial to provide trustworthy explanations of\ndeep learning models. Recent works have demonstrated how uncertainty modeling\ncan be particularly important in the unsupervised field of representation\nlearning explainable artificial intelligence (R-XAI). Current R-XAI methods\nprovide uncertainty by measuring variability in the importance score. However,\nthey fail to provide meaningful estimates of whether a pixel is certainly\nimportant or not. In this work, we propose a new R-XAI method called REPEAT\nthat addresses the key question of whether or not a pixel is \\textit{certainly}\nimportant. REPEAT leverages the stochasticity of current R-XAI methods to\nproduce multiple estimates of importance, thus considering each pixel in an\nimage as a Bernoulli random variable that is either important or unimportant.\nFrom these Bernoulli random variables we can directly estimate the importance\nof a pixel and its associated certainty, thus enabling users to determine\ncertainty in pixel importance. Our extensive evaluation shows that REPEAT gives\ncertainty estimates that are more intuitive, better at detecting\nout-of-distribution data, and more concise.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at AAAI 2025. Code available at:\n  https://github.com/Wickstrom/REPEAT",
    "pdf_url": "http://arxiv.org/pdf/2412.08513v1",
    "published_date": "2024-12-11 16:24:31 UTC",
    "updated_date": "2024-12-11 16:24:31 UTC"
  },
  {
    "arxiv_id": "2412.08504v1",
    "title": "PointTalk: Audio-Driven Dynamic Lip Point Cloud for 3D Gaussian-based Talking Head Synthesis",
    "authors": [
      "Yifan Xie",
      "Tao Feng",
      "Xin Zhang",
      "Xiangyang Luo",
      "Zixuan Guo",
      "Weijiang Yu",
      "Heng Chang",
      "Fei Ma",
      "Fei Richard Yu"
    ],
    "abstract": "Talking head synthesis with arbitrary speech audio is a crucial challenge in\nthe field of digital humans. Recently, methods based on radiance fields have\nreceived increasing attention due to their ability to synthesize high-fidelity\nand identity-consistent talking heads from just a few minutes of training\nvideo. However, due to the limited scale of the training data, these methods\noften exhibit poor performance in audio-lip synchronization and visual quality.\nIn this paper, we propose a novel 3D Gaussian-based method called PointTalk,\nwhich constructs a static 3D Gaussian field of the head and deforms it in sync\nwith the audio. It also incorporates an audio-driven dynamic lip point cloud as\na critical component of the conditional information, thereby facilitating the\neffective synthesis of talking heads. Specifically, the initial step involves\ngenerating the corresponding lip point cloud from the audio signal and\ncapturing its topological structure. The design of the dynamic difference\nencoder aims to capture the subtle nuances inherent in dynamic lip movements\nmore effectively. Furthermore, we integrate the audio-point enhancement module,\nwhich not only ensures the synchronization of the audio signal with the\ncorresponding lip point cloud within the feature space, but also facilitates a\ndeeper understanding of the interrelations among cross-modal conditional\nfeatures. Extensive experiments demonstrate that our method achieves superior\nhigh-fidelity and audio-lip synchronization in talking head synthesis compared\nto previous methods.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.GR",
      "cs.MM",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "9 pages, accepted by AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.08504v1",
    "published_date": "2024-12-11 16:15:14 UTC",
    "updated_date": "2024-12-11 16:15:14 UTC"
  },
  {
    "arxiv_id": "2412.09651v2",
    "title": "Assisted morbidity coding: the SISCO.web use case for identifying the main diagnosis in Hospital Discharge Records",
    "authors": [
      "Elena Cardillo",
      "Lucilla Frattura"
    ],
    "abstract": "Coding morbidity data using international standard diagnostic classifications\nis increasingly important and still challenging. Clinical coders and physicians\nassign codes to patient episodes based on their interpretation of case notes or\nelectronic patient records. Therefore, accurate coding relies on the legibility\nof case notes and the coders' understanding of medical terminology. During the\nlast ten years, many studies have shown poor reproducibility of clinical\ncoding, even recently, with the application of Artificial Intelligence-based\nmodels. Given this context, the paper aims to present the SISCO.web approach\ndesigned to support physicians in filling in Hospital Discharge Records with\nproper diagnoses and procedures codes using the International Classification of\nDiseases (9th and 10th), and, above all, in identifying the main pathological\ncondition. The web service leverages NLP algorithms, specific coding rules, as\nwell as ad hoc decision trees to identify the main condition, showing promising\nresults in providing accurate ICD coding suggestions.",
    "categories": [
      "cs.OH",
      "cs.AI",
      "H.4.2; H.3.3; H.3.5; H.3.1; I.2.1; I.2.4; J.3"
    ],
    "primary_category": "cs.OH",
    "comment": "18 pages",
    "pdf_url": "http://arxiv.org/pdf/2412.09651v2",
    "published_date": "2024-12-11 16:08:25 UTC",
    "updated_date": "2025-03-07 09:32:03 UTC"
  },
  {
    "arxiv_id": "2412.08490v1",
    "title": "SuperCode: Sustainability PER AI-driven CO-DEsign",
    "authors": [
      "P. Chris Broekema",
      "Rob V. van Nieuwpoort"
    ],
    "abstract": "Currently, data-intensive scientific applications require vast amounts of\ncompute resources to deliver world-leading science. The climate emergency has\nmade it clear that unlimited use of resources (e.g., energy) for scientific\ndiscovery is no longer acceptable. Future computing hardware promises to be\nmuch more energy efficient, but without better optimized software this cannot\nreach its full potential. In this vision paper, we propose a generic AI-driven\nco-design methodology, using specialized Large Language Models (like ChatGPT),\nto effectively generate efficient code for emerging computing hardware. We\ndescribe how we will validate our methodology with two radio astronomy\napplications, with sustainability as the key performance indicator. This paper\nis a modified version of our accepted SuperCode project proposal. We present it\nhere in this form to introduce the vision behind this project and to\ndisseminate the work in the spirit of Open Science and transparency. An\nadditional aim is to collect feedback, invite potential collaboration partners\nand use-cases to join the project.",
    "categories": [
      "astro-ph.IM",
      "cs.AI"
    ],
    "primary_category": "astro-ph.IM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.08490v1",
    "published_date": "2024-12-11 15:54:33 UTC",
    "updated_date": "2024-12-11 15:54:33 UTC"
  },
  {
    "arxiv_id": "2412.08477v2",
    "title": "Accurate Water Level Monitoring in AWD Rice Cultivation Using Convolutional Neural Networks",
    "authors": [
      "Ahmed Rafi Hasan",
      "Niloy Kumar Kundu",
      "Saad Hasan",
      "Mohammad Rashedul Hoque",
      "Swakkhar Shatabda"
    ],
    "abstract": "The Alternate Wetting and Drying (AWD) method is a rice-growing water\nmanagement technique promoted as a sustainable alternative to Continuous\nFlooding (CF). Climate change has placed the agricultural sector in a\nchallenging position, particularly as global water resources become\nincreasingly scarce, affecting rice production on irrigated lowlands. Rice, a\nstaple food for over half of the world's population, demands significantly more\nwater than other major crops. In Bangladesh, Boro rice, in particular, requires\nconsiderable water inputs during its cultivation. Traditionally, farmers\nmanually measure water levels, a process that is both time-consuming and prone\nto errors. While ultrasonic sensors offer improvements in water height\nmeasurement, they still face limitations, such as susceptibility to weather\nconditions and environmental factors. To address these issues, we propose a\nnovel approach that automates water height measurement using computer vision,\nspecifically through a convolutional neural network (CNN). Our attention-based\narchitecture achieved an $R^2$ score of 0.9885 and a Mean Squared Error (MSE)\nof 0.2766, providing a more accurate and efficient solution for managing AWD\nsystems.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "15 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.08477v2",
    "published_date": "2024-12-11 15:44:08 UTC",
    "updated_date": "2024-12-12 05:45:10 UTC"
  },
  {
    "arxiv_id": "2412.08467v2",
    "title": "Bootstrapping Language-Guided Navigation Learning with Self-Refining Data Flywheel",
    "authors": [
      "Zun Wang",
      "Jialu Li",
      "Yicong Hong",
      "Songze Li",
      "Kunchang Li",
      "Shoubin Yu",
      "Yi Wang",
      "Yu Qiao",
      "Yali Wang",
      "Mohit Bansal",
      "Limin Wang"
    ],
    "abstract": "Creating high-quality data for training robust language-instructed agents is\na long-lasting challenge in embodied AI. In this paper, we introduce a\nSelf-Refining Data Flywheel (SRDF) that generates high-quality and large-scale\nnavigational instruction-trajectory pairs by iteratively refining the data pool\nthrough the collaboration between two models, the instruction generator and the\nnavigator, without any human-in-the-loop annotation. Specifically, SRDF starts\nwith using a base generator to create an initial data pool for training a base\nnavigator, followed by applying the trained navigator to filter the data pool.\nThis leads to higher-fidelity data to train a better generator, which can, in\nturn, produce higher-quality data for training the next-round navigator. Such a\nflywheel establishes a data self-refining process, yielding a continuously\nimproved and highly effective dataset for large-scale language-guided\nnavigation learning. Our experiments demonstrate that after several flywheel\nrounds, the navigator elevates the performance boundary from 70% to 78% SPL on\nthe classic R2R test set, surpassing human performance (76%) for the first\ntime. Meanwhile, this process results in a superior generator, evidenced by a\nSPICE increase from 23.5 to 26.2, better than all previous VLN instruction\ngeneration methods. Finally, we demonstrate the scalability of our method\nthrough increasing environment and instruction diversity, and the\ngeneralization ability of our pre-trained navigator across various downstream\nnavigation tasks, surpassing state-of-the-art methods by a large margin in all\ncases.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "28 pages, Code and data are available at\n  https://github.com/wz0919/VLN-SRDF",
    "pdf_url": "http://arxiv.org/pdf/2412.08467v2",
    "published_date": "2024-12-11 15:32:24 UTC",
    "updated_date": "2025-02-28 08:06:39 UTC"
  },
  {
    "arxiv_id": "2412.12161v2",
    "title": "Discover physical concepts and equations with machine learning",
    "authors": [
      "Bao-Bing Li",
      "Yi Gu",
      "Shao-Feng Wu"
    ],
    "abstract": "Machine learning can uncover physical concepts or physical equations when\nprior knowledge from the other is available. However, these two aspects are\noften intertwined and cannot be discovered independently. We extend SciNet,\nwhich is a neural network architecture that simulates the human physical\nreasoning process for physics discovery, by proposing a model that combines\nVariational Autoencoders (VAE) with Neural Ordinary Differential Equations\n(Neural ODEs). This allows us to simultaneously discover physical concepts and\ngoverning equations from simulated experimental data across various physical\nsystems. We apply the model to several examples inspired by the history of\nphysics, including Copernicus' heliocentrism, Newton's law of gravity,\nSchr\\\"odinger's wave mechanics, and Pauli's spin-magnetic formulation. The\nresults demonstrate that the correct physical theories can emerge in the neural\nnetwork.",
    "categories": [
      "cs.LG",
      "cond-mat.dis-nn",
      "cs.AI",
      "physics.comp-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.12161v2",
    "published_date": "2024-12-11 15:30:21 UTC",
    "updated_date": "2025-04-22 22:11:42 UTC"
  },
  {
    "arxiv_id": "2412.08463v1",
    "title": "IRL for Restless Multi-Armed Bandits with Applications in Maternal and Child Health",
    "authors": [
      "Gauri Jain",
      "Pradeep Varakantham",
      "Haifeng Xu",
      "Aparna Taneja",
      "Prashant Doshi",
      "Milind Tambe"
    ],
    "abstract": "Public health practitioners often have the goal of monitoring patients and\nmaximizing patients' time spent in \"favorable\" or healthy states while being\nconstrained to using limited resources. Restless multi-armed bandits (RMAB) are\nan effective model to solve this problem as they are helpful to allocate\nlimited resources among many agents under resource constraints, where patients\nbehave differently depending on whether they are intervened on or not. However,\nRMABs assume the reward function is known. This is unrealistic in many public\nhealth settings because patients face unique challenges and it is impossible\nfor a human to know who is most deserving of any intervention at such a large\nscale. To address this shortcoming, this paper is the first to present the use\nof inverse reinforcement learning (IRL) to learn desired rewards for RMABs, and\nwe demonstrate improved outcomes in a maternal and child health telehealth\nprogram. First we allow public health experts to specify their goals at an\naggregate or population level and propose an algorithm to design expert\ntrajectories at scale based on those goals. Second, our algorithm WHIRL uses\ngradient updates to optimize the objective, allowing for efficient and accurate\nlearning of RMAB rewards. Third, we compare with existing baselines and\noutperform those in terms of run-time and accuracy. Finally, we evaluate and\nshow the usefulness of WHIRL on thousands on beneficiaries from a real-world\nmaternal and child health setting in India. We publicly release our code here:\nhttps://github.com/Gjain234/WHIRL.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.08463v1",
    "published_date": "2024-12-11 15:28:04 UTC",
    "updated_date": "2024-12-11 15:28:04 UTC"
  },
  {
    "arxiv_id": "2412.08460v2",
    "title": "Federated Learning for Traffic Flow Prediction with Synthetic Data Augmentation",
    "authors": [
      "Fermin Orozco",
      "Pedro Porto Buarque de Gusmão",
      "Hongkai Wen",
      "Johan Wahlström",
      "Man Luo"
    ],
    "abstract": "Deep-learning based traffic prediction models require vast amounts of data to\nlearn embedded spatial and temporal dependencies. The inherent privacy and\ncommercial sensitivity of such data has encouraged a shift towards\ndecentralised data-driven methods, such as Federated Learning (FL). Under a\ntraditional Machine Learning paradigm, traffic flow prediction models can\ncapture spatial and temporal relationships within centralised data. In reality,\ntraffic data is likely distributed across separate data silos owned by multiple\nstakeholders. In this work, a cross-silo FL setting is motivated to facilitate\nstakeholder collaboration for optimal traffic flow prediction applications.\nThis work introduces an FL framework, referred to as FedTPS, to generate\nsynthetic data to augment each client's local dataset by training a\ndiffusion-based trajectory generation model through FL. The proposed framework\nis evaluated on a large-scale real world ride-sharing dataset using various FL\nmethods and Traffic Flow Prediction models, including a novel prediction model\nwe introduce, which leverages Temporal and Graph Attention mechanisms to learn\nthe Spatio-Temporal dependencies embedded within regional traffic flow data.\nExperimental results show that FedTPS outperforms multiple other FL baselines\nwith respect to global model performance.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC",
      "I.2.1; I.2.11"
    ],
    "primary_category": "cs.LG",
    "comment": "11 pages, 7 figures, 6 tables, ACM format",
    "pdf_url": "http://arxiv.org/pdf/2412.08460v2",
    "published_date": "2024-12-11 15:25:38 UTC",
    "updated_date": "2025-03-20 13:29:36 UTC"
  },
  {
    "arxiv_id": "2412.08457v2",
    "title": "Efficient Rectification of Neuro-Symbolic Reasoning Inconsistencies by Abductive Reflection",
    "authors": [
      "Wen-Chao Hu",
      "Wang-Zhou Dai",
      "Yuan Jiang",
      "Zhi-Hua Zhou"
    ],
    "abstract": "Neuro-Symbolic (NeSy) AI could be regarded as an analogy to human\ndual-process cognition, modeling the intuitive System 1 with neural networks\nand the algorithmic System 2 with symbolic reasoning. However, for complex\nlearning targets, NeSy systems often generate outputs inconsistent with domain\nknowledge and it is challenging to rectify them. Inspired by the human\nCognitive Reflection, which promptly detects errors in our intuitive response\nand revises them by invoking the System 2 reasoning, we propose to improve NeSy\nsystems by introducing Abductive Reflection (ABL-Refl) based on the Abductive\nLearning (ABL) framework. ABL-Refl leverages domain knowledge to abduce a\nreflection vector during training, which can then flag potential errors in the\nneural network outputs and invoke abduction to rectify them and generate\nconsistent outputs during inference. ABL-Refl is highly efficient in contrast\nto previous ABL implementations. Experiments show that ABL-Refl outperforms\nstate-of-the-art NeSy methods, achieving excellent accuracy with fewer training\nresources and enhanced efficiency.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted by AAAI 2025, Oral",
    "pdf_url": "http://arxiv.org/pdf/2412.08457v2",
    "published_date": "2024-12-11 15:24:07 UTC",
    "updated_date": "2025-02-08 01:31:44 UTC"
  },
  {
    "arxiv_id": "2412.08445v1",
    "title": "TapeAgents: a Holistic Framework for Agent Development and Optimization",
    "authors": [
      "Dzmitry Bahdanau",
      "Nicolas Gontier",
      "Gabriel Huang",
      "Ehsan Kamalloo",
      "Rafael Pardinas",
      "Alex Piché",
      "Torsten Scholak",
      "Oleh Shliazhko",
      "Jordan Prince Tremblay",
      "Karam Ghanem",
      "Soham Parikh",
      "Mitul Tiwari",
      "Quaizar Vohra"
    ],
    "abstract": "We present TapeAgents, an agent framework built around a granular, structured\nlog tape of the agent session that also plays the role of the session's\nresumable state. In TapeAgents we leverage tapes to facilitate all stages of\nthe LLM Agent development lifecycle. The agent reasons by processing the tape\nand the LLM output to produce new thought and action steps and append them to\nthe tape. The environment then reacts to the agent's actions by likewise\nappending observation steps to the tape. By virtue of this tape-centred design,\nTapeAgents can provide AI practitioners with holistic end-to-end support. At\nthe development stage, tapes facilitate session persistence, agent auditing,\nand step-by-step debugging. Post-deployment, one can reuse tapes for\nevaluation, fine-tuning, and prompt-tuning; crucially, one can adapt tapes from\nother agents or use revised historical tapes. In this report, we explain the\nTapeAgents design in detail. We demonstrate possible applications of TapeAgents\nwith several concrete examples of building monolithic agents and multi-agent\nteams, of optimizing agent prompts and finetuning the agent's LLM. We present\ntooling prototypes and report a case study where we use TapeAgents to finetune\na Llama-3.1-8B form-filling assistant to perform as well as GPT-4o while being\norders of magnitude cheaper. Lastly, our comparative analysis shows that\nTapeAgents's advantages over prior frameworks stem from our novel design of the\nLLM agent as a resumable, modular state machine with a structured\nconfiguration, that generates granular, structured logs and that can transform\nthese logs into training text -- a unique combination of features absent in\nprevious work.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.08445v1",
    "published_date": "2024-12-11 15:09:54 UTC",
    "updated_date": "2024-12-11 15:09:54 UTC"
  },
  {
    "arxiv_id": "2412.08435v3",
    "title": "Proactive Model Adaptation Against Concept Drift for Online Time Series Forecasting",
    "authors": [
      "Lifan Zhao",
      "Yanyan Shen"
    ],
    "abstract": "Time series forecasting always faces the challenge of concept drift, where\ndata distributions evolve over time, leading to a decline in forecast model\nperformance. Existing solutions are based on online learning, which continually\norganize recent time series observations as new training samples and update\nmodel parameters according to the forecasting feedback on recent data. However,\nthey overlook a critical issue: obtaining ground-truth future values of each\nsample should be delayed until after the forecast horizon. This delay creates a\ntemporal gap between the training samples and the test sample. Our empirical\nanalysis reveals that the gap can introduce concept drift, causing forecast\nmodels to adapt to outdated concepts. In this paper, we present Proceed, a\nnovel proactive model adaptation framework for online time series forecasting.\nProceed first estimates the concept drift between the recently used training\nsamples and the current test sample. It then employs an adaptation generator to\nefficiently translate the estimated drift into parameter adjustments,\nproactively adapting the model to the test sample. To enhance the\ngeneralization capability of the framework, Proceed is trained on synthetic\ndiverse concept drifts. Extensive experiments on five real-world datasets\nacross various forecast models demonstrate that Proceed brings more performance\nimprovements than the state-of-the-art online learning methods, significantly\nfacilitating forecast models' resilience against concept drifts. Code is\navailable at https://github.com/SJTU-DMTai/OnlineTSF.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CE",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by KDD 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.08435v3",
    "published_date": "2024-12-11 14:57:10 UTC",
    "updated_date": "2025-02-07 13:54:59 UTC"
  },
  {
    "arxiv_id": "2412.08434v2",
    "title": "Mitigating Out-of-Entity Errors in Named Entity Recognition: A Sentence-Level Strategy",
    "authors": [
      "Guochao Jiang",
      "Ziqin Luo",
      "Chengwei Hu",
      "Zepeng Ding",
      "Deqing Yang"
    ],
    "abstract": "Many previous models of named entity recognition (NER) suffer from the\nproblem of Out-of-Entity (OOE), i.e., the tokens in the entity mentions of the\ntest samples have not appeared in the training samples, which hinders the\nachievement of satisfactory performance. To improve OOE-NER performance, in\nthis paper, we propose a new framework, namely S+NER, which fully leverages\nsentence-level information. Our S+NER achieves better OOE-NER performance\nmainly due to the following two particular designs. 1) It first exploits the\npre-trained language model's capability of understanding the target entity's\nsentence-level context with a template set. 2) Then, it refines the\nsentence-level representation based on the positive and negative templates,\nthrough a contrastive learning strategy and template pooling method, to obtain\nbetter NER results. Our extensive experiments on five benchmark datasets have\ndemonstrated that, our S+NER outperforms some state-of-the-art OOE-NER models.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by COLING 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.08434v2",
    "published_date": "2024-12-11 14:55:48 UTC",
    "updated_date": "2025-01-13 14:13:38 UTC"
  },
  {
    "arxiv_id": "2412.08430v1",
    "title": "Assessing Personalized AI Mentoring with Large Language Models in the Computing Field",
    "authors": [
      "Xiao Luo",
      "Sean O'Connell",
      "Shamima Mithun"
    ],
    "abstract": "This paper provides an in-depth evaluation of three state-of-the-art Large\nLanguage Models (LLMs) for personalized career mentoring in the computing\nfield, using three distinct student profiles that consider gender, race, and\nprofessional levels. We evaluated the performance of GPT-4, LLaMA 3, and Palm 2\nusing a zero-shot learning approach without human intervention. A quantitative\nevaluation was conducted through a custom natural language processing analytics\npipeline to highlight the uniqueness of the responses and to identify words\nreflecting each student's profile, including race, gender, or professional\nlevel. The analysis of frequently used words in the responses indicates that\nGPT-4 offers more personalized mentoring compared to the other two LLMs.\nAdditionally, a qualitative evaluation was performed to see if human experts\nreached similar conclusions. The analysis of survey responses shows that GPT-4\noutperformed the other two LLMs in delivering more accurate and useful\nmentoring while addressing specific challenges with encouragement languages.\nOur work establishes a foundation for developing personalized mentoring tools\nbased on LLMs, incorporating human mentors in the process to deliver a more\nimpactful and tailored mentoring experience.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.08430v1",
    "published_date": "2024-12-11 14:51:13 UTC",
    "updated_date": "2024-12-11 14:51:13 UTC"
  },
  {
    "arxiv_id": "2412.08428v1",
    "title": "SwarmGPT-Primitive: A Language-Driven Choreographer for Drone Swarms Using Safe Motion Primitive Composition",
    "authors": [
      "Vedant Vyas",
      "Martin Schuck",
      "Dinushka O. Dahanaggamaarachchi",
      "Siqi Zhou",
      "Angela P. Schoellig"
    ],
    "abstract": "Catalyzed by advancements in hardware and software, drone performances are\nincreasingly making their mark in the entertainment industry. However,\ndesigning smooth and safe choreographies for drone swarms is complex and often\nrequires expert domain knowledge. In this work, we introduce\nSwarmGPT-Primitive, a language-based choreographer that integrates the\nreasoning capabilities of large language models (LLMs) with safe motion\nplanning to facilitate deployable drone swarm choreographies. The LLM composes\nchoreographies for a given piece of music by utilizing a library of motion\nprimitives; the language-based choreographer is augmented with an\noptimization-based safety filter, which certifies the choreography for\nreal-world deployment by making minimal adjustments when feasibility and safety\nconstraints are violated. The overall SwarmGPT-Primitive framework decouples\nchoreographic design from safe motion planning, which allows non-expert users\nto re-prompt and refine compositions without concerns about compliance with\nconstraints such as avoiding collisions or downwash effects or satisfying\nactuation limits. We demonstrate our approach through simulations and\nexperiments with swarms of up to 20 drones performing choreographies designed\nbased on various songs, highlighting the system's ability to generate effective\nand synchronized drone choreographies for real-world deployment.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO",
    "comment": "Submitted to ICRA 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.08428v1",
    "published_date": "2024-12-11 14:48:19 UTC",
    "updated_date": "2024-12-11 14:48:19 UTC"
  },
  {
    "arxiv_id": "2412.12160v1",
    "title": "Climate Aware Deep Neural Networks (CADNN) for Wind Power Simulation",
    "authors": [
      "Ali Forootani",
      "Danial Esmaeili Aliabadi",
      "Daniela Thraen"
    ],
    "abstract": "Wind power forecasting plays a critical role in modern energy systems,\nfacilitating the integration of renewable energy sources into the power grid.\nAccurate prediction of wind energy output is essential for managing the\ninherent intermittency of wind power, optimizing energy dispatch, and ensuring\ngrid stability. This paper proposes the use of Deep Neural Network (DNN)-based\npredictive models that leverage climate datasets, including wind speed,\natmospheric pressure, temperature, and other meteorological variables, to\nimprove the accuracy of wind power simulations. In particular, we focus on the\nCoupled Model Intercomparison Project (CMIP) datasets, which provide climate\nprojections, as inputs for training the DNN models. These models aim to capture\nthe complex nonlinear relationships between the CMIP-based climate data and\nactual wind power generation at wind farms located in Germany. Our study\ncompares various DNN architectures, specifically Multilayer Perceptron (MLP),\nLong Short-Term Memory (LSTM) networks, and Transformer-enhanced LSTM models,\nto identify the best configuration among these architectures for climate-aware\nwind power simulation. The implementation of this framework involves the\ndevelopment of a Python package (CADNN) designed to support multiple tasks,\nincluding statistical analysis of the climate data, data visualization,\npreprocessing, DNN training, and performance evaluation. We demonstrate that\nthe DNN models, when integrated with climate data, significantly enhance\nforecasting accuracy. This climate-aware approach offers a deeper understanding\nof the time-dependent climate patterns that influence wind power generation,\nproviding more accurate predictions and making it adaptable to other\ngeographical regions.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.12160v1",
    "published_date": "2024-12-11 14:22:52 UTC",
    "updated_date": "2024-12-11 14:22:52 UTC"
  },
  {
    "arxiv_id": "2412.08392v1",
    "title": "The Roles of English in Evaluating Multilingual Language Models",
    "authors": [
      "Wessel Poelman",
      "Miryam de Lhoneux"
    ],
    "abstract": "Multilingual natural language processing is getting increased attention, with\nnumerous models, benchmarks, and methods being released for many languages.\nEnglish is often used in multilingual evaluation to prompt language models\n(LMs), mainly to overcome the lack of instruction tuning data in other\nlanguages. In this position paper, we lay out two roles of English in\nmultilingual LM evaluations: as an interface and as a natural language. We\nargue that these roles have different goals: task performance versus language\nunderstanding. This discrepancy is highlighted with examples from datasets and\nevaluation setups. Numerous works explicitly use English as an interface to\nboost task performance. We recommend to move away from this imprecise method\nand instead focus on furthering language understanding.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "NoDaLiDa 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.08392v1",
    "published_date": "2024-12-11 14:02:55 UTC",
    "updated_date": "2024-12-11 14:02:55 UTC"
  },
  {
    "arxiv_id": "2412.08385v1",
    "title": "NyayaAnumana & INLegalLlama: The Largest Indian Legal Judgment Prediction Dataset and Specialized Language Model for Enhanced Decision Analysis",
    "authors": [
      "Shubham Kumar Nigam",
      "Balaramamahanthi Deepak Patnaik",
      "Shivam Mishra",
      "Noel Shallum",
      "Kripabandhu Ghosh",
      "Arnab Bhattacharya"
    ],
    "abstract": "The integration of artificial intelligence (AI) in legal judgment prediction\n(LJP) has the potential to transform the legal landscape, particularly in\njurisdictions like India, where a significant backlog of cases burdens the\nlegal system. This paper introduces NyayaAnumana, the largest and most diverse\ncorpus of Indian legal cases compiled for LJP, encompassing a total of 7,02,945\npreprocessed cases. NyayaAnumana, which combines the words \"Nyay\" (judgment)\nand \"Anuman\" (prediction or inference) respectively for most major Indian\nlanguages, includes a wide range of cases from the Supreme Court, High Courts,\nTribunal Courts, District Courts, and Daily Orders and, thus, provides\nunparalleled diversity and coverage. Our dataset surpasses existing datasets\nlike PredEx and ILDC, offering a comprehensive foundation for advanced AI\nresearch in the legal domain.\n  In addition to the dataset, we present INLegalLlama, a domain-specific\ngenerative large language model (LLM) tailored to the intricacies of the Indian\nlegal system. It is developed through a two-phase training approach over a base\nLLaMa model. First, Indian legal documents are injected using continual\npretraining. Second, task-specific supervised finetuning is done. This method\nallows the model to achieve a deeper understanding of legal contexts.\n  Our experiments demonstrate that incorporating diverse court data\nsignificantly boosts model accuracy, achieving approximately 90% F1-score in\nprediction tasks. INLegalLlama not only improves prediction accuracy but also\noffers comprehensible explanations, addressing the need for explainability in\nAI-assisted legal decisions.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted on COLING 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.08385v1",
    "published_date": "2024-12-11 13:50:17 UTC",
    "updated_date": "2024-12-11 13:50:17 UTC"
  },
  {
    "arxiv_id": "2412.10443v3",
    "title": "SweetTok: Semantic-Aware Spatial-Temporal Tokenizer for Compact Video Discretization",
    "authors": [
      "Zhentao Tan",
      "Ben Xue",
      "Jian Jia",
      "Junhao Wang",
      "Wencai Ye",
      "Shaoyun Shi",
      "Mingjie Sun",
      "Wenjin Wu",
      "Quan Chen",
      "Peng Jiang"
    ],
    "abstract": "This paper presents the \\textbf{S}emantic-a\\textbf{W}ar\\textbf{E}\nspatial-t\\textbf{E}mporal \\textbf{T}okenizer (SweetTok), a novel video\ntokenizer to overcome the limitations in current video tokenization methods for\ncompacted yet effective discretization. Unlike previous approaches that process\nflattened local visual patches via direct discretization or adaptive query\ntokenization, SweetTok proposes a decoupling framework, compressing visual\ninputs through distinct spatial and temporal queries via \\textbf{D}ecoupled\n\\textbf{Q}uery \\textbf{A}uto\\textbf{E}ncoder (DQAE). This design allows\nSweetTok to efficiently compress video token count while achieving superior\nfidelity by capturing essential information across spatial and temporal\ndimensions. Furthermore, we design a \\textbf{M}otion-enhanced \\textbf{L}anguage\n\\textbf{C}odebook (MLC) tailored for spatial and temporal compression to\naddress the differences in semantic representation between appearance and\nmotion information. SweetTok significantly improves video reconstruction\nresults by \\textbf{42.8\\%} w.r.t rFVD on UCF-101 dataset. With a better token\ncompression strategy, it also boosts downstream video generation results by\n\\textbf{15.1\\%} w.r.t gFVD. Additionally, the compressed decoupled tokens are\nimbued with semantic information, enabling few-shot recognition capabilities\npowered by LLMs in downstream applications.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.10443v3",
    "published_date": "2024-12-11 13:48:06 UTC",
    "updated_date": "2025-03-11 03:19:42 UTC"
  },
  {
    "arxiv_id": "2412.08378v3",
    "title": "FILA: Fine-Grained Vision Language Models",
    "authors": [
      "Shiding Zhu",
      "Wenhui Dong",
      "Jun Song",
      "Yingbo Wang",
      "Yanan Guo",
      "Bo Zheng"
    ],
    "abstract": "Recently, there has been growing interest in the capability of multimodal\nlarge language models (MLLMs) to process high-resolution images. A common\napproach currently involves dynamically cropping the original high-resolution\nimage into smaller sub-images, which are then fed into a vision encoder that\nwas pre-trained on lower-resolution images. However, this cropping approach\noften truncates objects and connected areas in the original image, causing\nsemantic breaks. To address this limitation, we introduce HyViLM, designed to\nprocess images of any resolution while retaining the overall context during\nencoding. Specifically, we: (i) Design a new visual encoder called Hybrid\nEncoder that not only encodes individual sub-images but also interacts with\ndetailed global visual features, significantly improving the model's ability to\nencode high-resolution images. (ii) Propose an optimal feature fusion strategy\nfor the dynamic cropping approach, effectively leveraging information from\ndifferent layers of the vision encoder. Compared with the state-of-the-art\nMLLMs under the same setting, our HyViLM outperforms existing MLLMs in nine out\nof ten tasks. Specifically, HyViLM achieves a 9.6% improvement in performance\non the TextVQA task and a 6.9% enhancement on the DocVQA task.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "9 pages, 4 figures, accepted to ICLR 2025 workshop",
    "pdf_url": "http://arxiv.org/pdf/2412.08378v3",
    "published_date": "2024-12-11 13:41:21 UTC",
    "updated_date": "2025-04-30 08:49:56 UTC"
  },
  {
    "arxiv_id": "2412.08360v1",
    "title": "Agency and Morality as part of Text Entry AI Assistant Personas",
    "authors": [
      "Andreas Komninos"
    ],
    "abstract": "This paper discusses the need to move away from an instrumental view of text\ncomposition AI assistants under direct control of the user, towards a more\nagentic approach that is based on a value rationale. Based on an analysis of\nmoral dimensions of AI assistance in computer mediated communication, the paper\nproposes basic guidelines for designing the agent's persona.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.08360v1",
    "published_date": "2024-12-11 13:06:24 UTC",
    "updated_date": "2024-12-11 13:06:24 UTC"
  },
  {
    "arxiv_id": "2412.12159v1",
    "title": "Personalized Sleep Staging Leveraging Source-free Unsupervised Domain Adaptation",
    "authors": [
      "Yangxuan Zhou",
      "Sha Zhao",
      "Jiquan Wang",
      "Haiteng Jiang",
      "hijian Li",
      "Benyan Luo",
      "Tao Li",
      "Gang Pan"
    ],
    "abstract": "Sleep staging is crucial for assessing sleep quality and diagnosing related\ndisorders. Recent deep learning models for automatic sleep staging using\npolysomnography often suffer from poor generalization to new subjects because\nthey are trained and tested on the same labeled datasets, overlooking\nindividual differences. To tackle this issue, we propose a novel Source-Free\nUnsupervised Individual Domain Adaptation (SF-UIDA) framework. This two-step\nadaptation scheme allows the model to effectively adjust to new unlabeled\nindividuals without needing source data, facilitating personalized\ncustomization in clinical settings. Our framework has been applied to three\nestablished sleep staging models and tested on three public datasets, achieving\nstate-of-the-art performance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "9 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.12159v1",
    "published_date": "2024-12-11 12:59:36 UTC",
    "updated_date": "2024-12-11 12:59:36 UTC"
  },
  {
    "arxiv_id": "2412.08347v1",
    "title": "SmolTulu: Higher Learning Rate to Batch Size Ratios Can Lead to Better Reasoning in SLMs",
    "authors": [
      "Sultan Alrashed"
    ],
    "abstract": "We present SmolTulu-1.7b-Instruct, referenced in this report as\nSmolTulu-DPO-1130, an instruction-tuned language model that adapts AllenAI's\nTulu 3 post-training pipeline to enhance Huggingface's SmolLM2-1.7B base model.\nThrough comprehensive empirical analysis using a 135M parameter model, we\ndemonstrate that the relationship between learning rate and batch size\nsignificantly impacts model performance in a task-dependent manner. Our\nfindings reveal a clear split: reasoning tasks like ARC and GSM8K benefit from\nhigher learning rate to batch size ratios, while pattern recognition tasks such\nas HellaSwag and IFEval show optimal performance with lower ratios. These\ninsights informed the development of SmolTulu, which achieves state-of-the-art\nperformance among sub-2B parameter models on instruction following, scoring\n67.7% on IFEval ($\\Delta$11%), and mathematical reasoning with 51.6% on GSM8K\n($\\Delta$3.4%), with an alternate version achieving scoring 57.1% on ARC\n($\\Delta5.4%$). We release our model, training recipes, and ablation studies to\nfacilitate further research in efficient model alignment, demonstrating that\ncareful adaptation of optimization dynamics can help bridge the capability gap\nbetween small and large language models.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "10 pages, 4 figures, and 13 tables. For the SmolTulu-1.7b-instruct\n  model, see: https://huggingface.co/SultanR/SmolTulu-1.7b-Instruct",
    "pdf_url": "http://arxiv.org/pdf/2412.08347v1",
    "published_date": "2024-12-11 12:41:36 UTC",
    "updated_date": "2024-12-11 12:41:36 UTC"
  },
  {
    "arxiv_id": "2412.12158v1",
    "title": "Hyperbolic Hypergraph Neural Networks for Multi-Relational Knowledge Hypergraph Representation",
    "authors": [
      "Mengfan Li",
      "Xuanhua Shi",
      "Chenqi Qiao",
      "Teng Zhang",
      "Hai Jin"
    ],
    "abstract": "Knowledge hypergraphs generalize knowledge graphs using hyperedges to connect\nmultiple entities and depict complicated relations. Existing methods either\ntransform hyperedges into an easier-to-handle set of binary relations or view\nhyperedges as isolated and ignore their adjacencies. Both approaches have\ninformation loss and may potentially lead to the creation of sub-optimal\nmodels. To fix these issues, we propose the Hyperbolic Hypergraph Neural\nNetwork (H2GNN), whose essential component is the hyper-star message passing, a\nnovel scheme motivated by a lossless expansion of hyperedges into hierarchies.\nIt implements a direct embedding that consciously incorporates adjacent\nentities, hyper-relations, and entity position-aware information. As the name\nsuggests, H2GNN operates in the hyperbolic space, which is more adept at\ncapturing the tree-like hierarchy. We compare H2GNN with 15 baselines on\nknowledge hypergraphs, and it outperforms state-of-the-art approaches in both\nnode classification and link prediction tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.12158v1",
    "published_date": "2024-12-11 12:03:33 UTC",
    "updated_date": "2024-12-11 12:03:33 UTC"
  },
  {
    "arxiv_id": "2412.10442v2",
    "title": "Steganography in Game Actions",
    "authors": [
      "Ching-Chun Chang",
      "Isao Echizen"
    ],
    "abstract": "The exchange of messages has always carried with it the timeless challenge of\nsecrecy. From whispers in shadows to the enigmatic notes written in the margins\nof history, humanity has long sought ways to convey thoughts that remain\nimperceptible to all but the chosen few. The challenge of subliminal\ncommunication has been addressed in various forms of steganography. However,\nthe field faces a fundamental paradox: as the art of concealment advances, so\ntoo does the science of revelation, leading to an ongoing evolutionary\ninterplay. This study seeks to extend the boundaries of what is considered a\nviable steganographic medium. We explore a steganographic paradigm, in which\nhidden information is communicated through the episodes of multiple agents\ninteracting with an environment. Each agent, acting as an encoder, learns a\npolicy to disguise the very existence of hidden messages within actions\nseemingly directed toward innocent objectives. Meanwhile, an observer, serving\nas a decoder, learns to associate behavioural patterns with their respective\nagents despite their dynamic nature, thereby unveiling the hidden messages. The\ninteractions of agents are governed by the framework of multi-agent\nreinforcement learning and shaped by feedback from the observer. This framework\nencapsulates a game-theoretic dilemma, wherein agents face decisions between\ncooperating to create distinguishable behavioural patterns or defecting to\npursue individually optimal yet potentially overlapping episodic actions. As a\nproof of concept, we exemplify action steganography through the game of\nlabyrinth, a navigation task where subliminal communication is concealed within\nthe act of steering toward a destination, and systematically validate the\nstego-system in terms of distortion, capacity, secrecy and robustness when\nsubjected to simulated passive and active adversaries.",
    "categories": [
      "cs.AI",
      "cs.CR",
      "cs.MM"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.10442v2",
    "published_date": "2024-12-11 12:02:36 UTC",
    "updated_date": "2025-04-20 02:17:12 UTC"
  },
  {
    "arxiv_id": "2412.12157v1",
    "title": "What Makes In-context Learning Effective for Mathematical Reasoning: A Theoretical Analysis",
    "authors": [
      "Jiayu Liu",
      "Zhenya Huang",
      "Chaokun Wang",
      "Xunpeng Huang",
      "Chengxiang Zhai",
      "Enhong Chen"
    ],
    "abstract": "Owing to the capability of in-context learning, large language models (LLMs)\nhave shown impressive performance across diverse mathematical reasoning\nbenchmarks. However, we find that few-shot demonstrations can sometimes bring\nnegative performance and their effectiveness on LLMs' reasoning abilities\nremains unreliable. To this end, in this paper, we aim to theoretically analyze\nthe impact of in-context demonstrations on LLMs' reasoning performance. We\nprove that the reasoning efficacy (measured by empirical prediction loss) can\nbe bounded by a LLM-oriented semantic similarity and an inference stability of\ndemonstrations, which is general for both one-shot and few-shot scenarios.\nBased on this finding, we propose a straightforward, generalizable, and\nlow-complexity demonstration selection method named LMS3. It can adaptively\nfacilitate to select the most pertinent samples for different LLMs and includes\na novel demonstration rejection mechanism to automatically filter out samples\nthat are unsuitable for few-shot learning. Through experiments on three\nrepresentative benchmarks, two LLM backbones, and multiple few-shot settings,\nwe verify that our LMS3 has superiority and achieves consistent improvements on\nall datasets, which existing methods have been unable to accomplish.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.12157v1",
    "published_date": "2024-12-11 11:38:11 UTC",
    "updated_date": "2024-12-11 11:38:11 UTC"
  },
  {
    "arxiv_id": "2412.10441v1",
    "title": "Novel 3D Binary Indexed Tree for Volume Computation of 3D Reconstructed Models from Volumetric Data",
    "authors": [
      "Quoc-Bao Nguyen-Le",
      "Tuan-Hy Le",
      "Anh-Triet Do"
    ],
    "abstract": "In the burgeoning field of medical imaging, precise computation of 3D volume\nholds a significant importance for subsequent qualitative analysis of 3D\nreconstructed objects. Combining multivariate calculus, marching cube\nalgorithm, and binary indexed tree data structure, we developed an algorithm\nfor efficient computation of intrinsic volume of any volumetric data recovered\nfrom computed tomography (CT) or magnetic resonance (MR). We proposed the 30\nconfigurations of volume values based on the polygonal mesh generation method.\nOur algorithm processes the data in scan-line order simultaneously with\nreconstruction algorithm to create a Fenwick tree, ensuring query time much\nfaster and assisting users' edition of slicing or transforming model. We tested\nthe algorithm's accuracy on simple 3D objects (e.g., sphere, cylinder) to\ncomplicated structures (e.g., lungs, cardiac chambers). The result deviated\nwithin $\\pm 0.004 \\text{cm}^3$ and there is still room for further improvement.",
    "categories": [
      "cs.GR",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.GR",
    "comment": "8 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.10441v1",
    "published_date": "2024-12-11 11:29:53 UTC",
    "updated_date": "2024-12-11 11:29:53 UTC"
  },
  {
    "arxiv_id": "2412.08292v1",
    "title": "Self-Refining Diffusion Samplers: Enabling Parallelization via Parareal Iterations",
    "authors": [
      "Nikil Roashan Selvam",
      "Amil Merchant",
      "Stefano Ermon"
    ],
    "abstract": "In diffusion models, samples are generated through an iterative refinement\nprocess, requiring hundreds of sequential model evaluations. Several recent\nmethods have introduced approximations (fewer discretization steps or\ndistillation) to trade off speed at the cost of sample quality. In contrast, we\nintroduce Self-Refining Diffusion Samplers (SRDS) that retain sample quality\nand can improve latency at the cost of additional parallel compute. We take\ninspiration from the Parareal algorithm, a popular numerical method for\nparallel-in-time integration of differential equations. In SRDS, a quick but\nrough estimate of a sample is first created and then iteratively refined in\nparallel through Parareal iterations. SRDS is not only guaranteed to accurately\nsolve the ODE and converge to the serial solution but also benefits from\nparallelization across the diffusion trajectory, enabling batched inference and\npipelining. As we demonstrate for pre-trained diffusion models, the early\nconvergence of this refinement procedure drastically reduces the number of\nsteps required to produce a sample, speeding up generation for instance by up\nto 1.7x on a 25-step StableDiffusion-v2 benchmark and up to 4.3x on longer\ntrajectories.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2412.08292v1",
    "published_date": "2024-12-11 11:08:09 UTC",
    "updated_date": "2024-12-11 11:08:09 UTC"
  },
  {
    "arxiv_id": "2412.08282v2",
    "title": "How Does the Smoothness Approximation Method Facilitate Generalization for Federated Adversarial Learning?",
    "authors": [
      "Wenjun Ding",
      "Ying An",
      "Lixing Chen",
      "Shichao Kan",
      "Fan Wu",
      "Zhe Qu"
    ],
    "abstract": "Federated Adversarial Learning (FAL) is a robust framework for resisting\nadversarial attacks on federated learning. Although some FAL studies have\ndeveloped efficient algorithms, they primarily focus on convergence performance\nand overlook generalization. Generalization is crucial for evaluating algorithm\nperformance on unseen data. However, generalization analysis is more\nchallenging due to non-smooth adversarial loss functions. A common approach to\naddressing this issue is to leverage smoothness approximation. In this paper,\nwe develop algorithm stability measures to evaluate the generalization\nperformance of two popular FAL algorithms: \\textit{Vanilla FAL (VFAL)} and {\\it\nSlack FAL (SFAL)}, using three different smooth approximation methods: 1)\n\\textit{Surrogate Smoothness Approximation (SSA)}, (2) \\textit{Randomized\nSmoothness Approximation (RSA)}, and (3) \\textit{Over-Parameterized Smoothness\nApproximation (OPSA)}. Based on our in-depth analysis, we answer the question\nof how to properly set the smoothness approximation method to mitigate\ngeneralization error in FAL. Moreover, we identify RSA as the most effective\nmethod for reducing generalization error. In highly data-heterogeneous\nscenarios, we also recommend employing SFAL to mitigate the deterioration of\ngeneralization performance caused by heterogeneity. Based on our theoretical\nresults, we provide insights to help develop more efficient FAL algorithms,\nsuch as designing new metrics and dynamic aggregation rules to mitigate\nheterogeneity.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.08282v2",
    "published_date": "2024-12-11 10:57:16 UTC",
    "updated_date": "2024-12-19 06:35:21 UTC"
  },
  {
    "arxiv_id": "2412.08273v1",
    "title": "Can transformative AI shape a new age for our civilization?: Navigating between speculation and reality",
    "authors": [
      "Jesus L. Lobo",
      "Javier Del Ser"
    ],
    "abstract": "Artificial Intelligence is widely regarded as a transformative force with the\npotential to redefine numerous sectors of human civilization. While Artificial\nIntelligence has evolved from speculative fiction to a pivotal element of\ntechnological progress, its role as a truly transformative agent, or\ntransformative Artificial Intelligence, remains a subject of debate. This work\nexplores the historical precedents of technological breakthroughs, examining\nwhether Artificial Intelligence can achieve a comparable impact, and it delves\ninto various ethical frameworks that shape the perception and development of\nArtificial Intelligence. Additionally, it considers the societal, technical,\nand regulatory challenges that must be addressed for Artificial Intelligence to\nbecome a catalyst for global change. We also examine not only the strategies\nand methodologies that could lead to transformative Artificial Intelligence but\nalso the barriers that could ultimately make these goals unattainable. We end\nwith a critical inquiry into whether reaching a transformative Artificial\nIntelligence might compel humanity to adopt an entirely new ethical approach,\ntailored to the complexities of advanced Artificial Intelligence. By addressing\nthe ethical, social, and scientific dimensions of Artificial Intelligence's\ndevelopment, this work contributes to the broader discourse on the long-term\nimplications of Artificial Intelligence and its capacity to drive civilization\ntoward a new era of progress or, conversely, exacerbate existing inequalities\nand risks.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "100 pages, 6 Figures, 2 Tables",
    "pdf_url": "http://arxiv.org/pdf/2412.08273v1",
    "published_date": "2024-12-11 10:44:47 UTC",
    "updated_date": "2024-12-11 10:44:47 UTC"
  },
  {
    "arxiv_id": "2412.08271v1",
    "title": "Position-aware Guided Point Cloud Completion with CLIP Model",
    "authors": [
      "Feng Zhou",
      "Qi Zhang",
      "Ju Dai",
      "Lei Li",
      "Qing Fan",
      "Junliang Xing"
    ],
    "abstract": "Point cloud completion aims to recover partial geometric and topological\nshapes caused by equipment defects or limited viewpoints. Current methods\neither solely rely on the 3D coordinates of the point cloud to complete it or\nincorporate additional images with well-calibrated intrinsic parameters to\nguide the geometric estimation of the missing parts. Although these methods\nhave achieved excellent performance by directly predicting the location of\ncomplete points, the extracted features lack fine-grained information regarding\nthe location of the missing area. To address this issue, we propose a rapid and\nefficient method to expand an unimodal framework into a multimodal framework.\nThis approach incorporates a position-aware module designed to enhance the\nspatial information of the missing parts through a weighted map learning\nmechanism. In addition, we establish a Point-Text-Image triplet corpus PCI-TI\nand MVP-TI based on the existing unimodal point cloud completion dataset and\nuse the pre-trained vision-language model CLIP to provide richer detail\ninformation for 3D shapes, thereby enhancing performance. Extensive\nquantitative and qualitative experiments demonstrate that our method\noutperforms state-of-the-art point cloud completion methods.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by AAAI25",
    "pdf_url": "http://arxiv.org/pdf/2412.08271v1",
    "published_date": "2024-12-11 10:43:11 UTC",
    "updated_date": "2024-12-11 10:43:11 UTC"
  },
  {
    "arxiv_id": "2412.10440v1",
    "title": "Multi-level Matching Network for Multimodal Entity Linking",
    "authors": [
      "Zhiwei Hu",
      "Víctor Gutiérrez-Basulto",
      "Ru Li",
      "Jeff Z. Pan"
    ],
    "abstract": "Multimodal entity linking (MEL) aims to link ambiguous mentions within\nmultimodal contexts to corresponding entities in a multimodal knowledge base.\nMost existing approaches to MEL are based on representation learning or\nvision-and-language pre-training mechanisms for exploring the complementary\neffect among multiple modalities. However, these methods suffer from two\nlimitations. On the one hand, they overlook the possibility of considering\nnegative samples from the same modality. On the other hand, they lack\nmechanisms to capture bidirectional cross-modal interaction. To address these\nissues, we propose a Multi-level Matching network for Multimodal Entity Linking\n(M3EL). Specifically, M3EL is composed of three different modules: (i) a\nMultimodal Feature Extraction module, which extracts modality-specific\nrepresentations with a multimodal encoder and introduces an intra-modal\ncontrastive learning sub-module to obtain better discriminative embeddings\nbased on uni-modal differences; (ii) an Intra-modal Matching Network module,\nwhich contains two levels of matching granularity: Coarse-grained\nGlobal-to-Global and Fine-grained Global-to-Local, to achieve local and global\nlevel intra-modal interaction; (iii) a Cross-modal Matching Network module,\nwhich applies bidirectional strategies, Textual-to-Visual and Visual-to-Textual\nmatching, to implement bidirectional cross-modal interaction. Extensive\nexperiments conducted on WikiMEL, RichpediaMEL, and WikiDiverse datasets\ndemonstrate the outstanding performance of M3EL when compared to the\nstate-of-the-art baselines.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at KDD'25",
    "pdf_url": "http://arxiv.org/pdf/2412.10440v1",
    "published_date": "2024-12-11 10:26:17 UTC",
    "updated_date": "2024-12-11 10:26:17 UTC"
  },
  {
    "arxiv_id": "2412.08261v2",
    "title": "FLIP: Flow-Centric Generative Planning as General-Purpose Manipulation World Model",
    "authors": [
      "Chongkai Gao",
      "Haozhuo Zhang",
      "Zhixuan Xu",
      "Zhehao Cai",
      "Lin Shao"
    ],
    "abstract": "We aim to develop a model-based planning framework for world models that can\nbe scaled with increasing model and data budgets for general-purpose\nmanipulation tasks with only language and vision inputs. To this end, we\npresent FLow-centric generative Planning (FLIP), a model-based planning\nalgorithm on visual space that features three key modules: 1. a multi-modal\nflow generation model as the general-purpose action proposal module; 2. a\nflow-conditioned video generation model as the dynamics module; and 3. a\nvision-language representation learning model as the value module. Given an\ninitial image and language instruction as the goal, FLIP can progressively\nsearch for long-horizon flow and video plans that maximize the discounted\nreturn to accomplish the task. FLIP is able to synthesize long-horizon plans\nacross objects, robots, and tasks with image flows as the general action\nrepresentation, and the dense flow information also provides rich guidance for\nlong-horizon video generation. In addition, the synthesized flow and video\nplans can guide the training of low-level control policies for robot execution.\nExperiments on diverse benchmarks demonstrate that FLIP can improve both the\nsuccess rates and quality of long-horizon video plan synthesis and has the\ninteractive world model property, opening up wider applications for future\nworks.Video demos are on our website: https://nus-lins-lab.github.io/flipweb/.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.08261v2",
    "published_date": "2024-12-11 10:17:00 UTC",
    "updated_date": "2025-02-16 03:13:51 UTC"
  },
  {
    "arxiv_id": "2412.08258v1",
    "title": "Large Language Models for Scholarly Ontology Generation: An Extensive Analysis in the Engineering Field",
    "authors": [
      "Tanay Aggarwal",
      "Angelo Salatino",
      "Francesco Osborne",
      "Enrico Motta"
    ],
    "abstract": "Ontologies of research topics are crucial for structuring scientific\nknowledge, enabling scientists to navigate vast amounts of research, and\nforming the backbone of intelligent systems such as search engines and\nrecommendation systems. However, manual creation of these ontologies is\nexpensive, slow, and often results in outdated and overly general\nrepresentations. As a solution, researchers have been investigating ways to\nautomate or semi-automate the process of generating these ontologies. This\npaper offers a comprehensive analysis of the ability of large language models\n(LLMs) to identify semantic relationships between different research topics,\nwhich is a critical step in the development of such ontologies. To this end, we\ndeveloped a gold standard based on the IEEE Thesaurus to evaluate the task of\nidentifying four types of relationships between pairs of topics: broader,\nnarrower, same-as, and other. Our study evaluates the performance of seventeen\nLLMs, which differ in scale, accessibility (open vs. proprietary), and model\ntype (full vs. quantised), while also assessing four zero-shot reasoning\nstrategies. Several models have achieved outstanding results, including\nMixtral-8x7B, Dolphin-Mistral-7B, and Claude 3 Sonnet, with F1-scores of 0.847,\n0.920, and 0.967, respectively. Furthermore, our findings demonstrate that\nsmaller, quantised models, when optimised through prompt engineering, can\ndeliver performance comparable to much larger proprietary models, while\nrequiring significantly fewer computational resources.",
    "categories": [
      "cs.DL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.DL",
    "comment": "submitted to Information Processing & Management",
    "pdf_url": "http://arxiv.org/pdf/2412.08258v1",
    "published_date": "2024-12-11 10:11:41 UTC",
    "updated_date": "2024-12-11 10:11:41 UTC"
  },
  {
    "arxiv_id": "2412.08231v1",
    "title": "Dynamic Modality-Camera Invariant Clustering for Unsupervised Visible-Infrared Person Re-identification",
    "authors": [
      "Yiming Yang",
      "Weipeng Hu",
      "Haifeng Hu"
    ],
    "abstract": "Unsupervised learning visible-infrared person re-identification (USL-VI-ReID)\noffers a more flexible and cost-effective alternative compared to supervised\nmethods. This field has gained increasing attention due to its promising\npotential. Existing methods simply cluster modality-specific samples and employ\nstrong association techniques to achieve instance-to-cluster or\ncluster-to-cluster cross-modality associations. However, they ignore\ncross-camera differences, leading to noticeable issues with excessive splitting\nof identities. Consequently, this undermines the accuracy and reliability of\ncross-modal associations. To address these issues, we propose a novel Dynamic\nModality-Camera Invariant Clustering (DMIC) framework for USL-VI-ReID.\nSpecifically, our DMIC naturally integrates Modality-Camera Invariant Expansion\n(MIE), Dynamic Neighborhood Clustering (DNC) and Hybrid Modality Contrastive\nLearning (HMCL) into a unified framework, which eliminates both the\ncross-modality and cross-camera discrepancies in clustering. MIE fuses\ninter-modal and inter-camera distance coding to bridge the gaps between\nmodalities and cameras at the clustering level. DNC employs two dynamic search\nstrategies to refine the network's optimization objective, transitioning from\nimproving discriminability to enhancing cross-modal and cross-camera\ngeneralizability. Moreover, HMCL is designed to optimize instance-level and\ncluster-level distributions. Memories for intra-modality and inter-modality\ntraining are updated using randomly selected samples, facilitating real-time\nexploration of modality-invariant representations. Extensive experiments have\ndemonstrated that our DMIC addresses the limitations present in current\nclustering approaches and achieve competitive performance, which significantly\nreduces the performance gap with supervised methods.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.08231v1",
    "published_date": "2024-12-11 09:31:03 UTC",
    "updated_date": "2024-12-11 09:31:03 UTC"
  },
  {
    "arxiv_id": "2412.08228v1",
    "title": "Hierarchical Classification for Automated Image Annotation of Coral Reef Benthic Structures",
    "authors": [
      "Célia Blondin",
      "Joris Guérin",
      "Kelly Inagaki",
      "Guilherme Longo",
      "Laure Berti-Équille"
    ],
    "abstract": "Automated benthic image annotation is crucial to efficiently monitor and\nprotect coral reefs against climate change. Current machine learning approaches\nfail to capture the hierarchical nature of benthic organisms covering reef\nsubstrata, i.e., coral taxonomic levels and health condition. To address this\nlimitation, we propose to annotate benthic images using hierarchical\nclassification. Experiments on a custom dataset from a Northeast Brazilian\ncoral reef show that our approach outperforms flat classifiers, improving both\nF1 and hierarchical F1 scores by approximately 2\\% across varying amounts of\ntraining data. In addition, this hierarchical method aligns more closely with\necological objectives.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Poster at Tackling Climate Change with Machine Learning: workshop at\n  NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2412.08228v1",
    "published_date": "2024-12-11 09:28:30 UTC",
    "updated_date": "2024-12-11 09:28:30 UTC"
  },
  {
    "arxiv_id": "2412.12155v1",
    "title": "Adapting Unsigned Graph Neural Networks for Signed Graphs: A Few-Shot Prompt Tuning Approach",
    "authors": [
      "Zian Zhai",
      "Sima Qing",
      "Xiaoyang Wang",
      "Wenjie Zhang"
    ],
    "abstract": "Signed Graph Neural Networks (SGNNs) are powerful tools for signed graph\nrepresentation learning but struggle with limited generalization and heavy\ndependence on labeled data. While recent advancements in \"graph pre-training\nand prompt tuning\" have reduced label dependence in Graph Neural Networks\n(GNNs) and improved their generalization abilities by leveraging pre-training\nknowledge, these efforts have focused exclusively on unsigned graphs. The\nscarcity of publicly available signed graph datasets makes it essential to\ntransfer knowledge from unsigned graphs to signed graph tasks. However, this\ntransfer introduces significant challenges due to the graph-level and\ntask-level divergences between the pre-training and downstream phases. To\naddress these challenges, we propose Signed Graph Prompt Tuning (SGPT) in this\npaper. Specifically, SGPT employs a graph template and a semantic prompt to\nsegregate mixed link semantics in the signed graph and then adaptively\nintegrate the distinctive semantic information according to the needs of\ndownstream tasks, thereby unifying the pre-training and downstream graphs.\nAdditionally, SGPT utilizes a task template and a feature prompt to reformulate\nthe downstream signed graph tasks, aligning them with pre-training tasks to\nensure a unified optimization objective and consistent feature space across\ntasks. Finally, extensive experiments are conducted on popular signed graph\ndatasets, demonstrating the superiority of SGPT over state-of-the-art methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.12155v1",
    "published_date": "2024-12-11 09:22:46 UTC",
    "updated_date": "2024-12-11 09:22:46 UTC"
  },
  {
    "arxiv_id": "2412.08221v2",
    "title": "Generate Any Scene: Evaluating and Improving Text-to-Vision Generation with Scene Graph Programming",
    "authors": [
      "Ziqi Gao",
      "Weikai Huang",
      "Jieyu Zhang",
      "Aniruddha Kembhavi",
      "Ranjay Krishna"
    ],
    "abstract": "DALL-E and Sora have gained attention by producing implausible images, such\nas \"astronauts riding a horse in space.\" Despite the proliferation of\ntext-to-vision models that have inundated the internet with synthetic visuals,\nfrom images to 3D assets, current benchmarks predominantly evaluate these\nmodels on real-world scenes paired with captions. We introduce Generate Any\nScene, a framework that systematically enumerates scene graphs representing a\nvast array of visual scenes, spanning realistic to imaginative compositions.\nGenerate Any Scene leverages 'scene graph programming', a method for\ndynamically constructing scene graphs of varying complexity from a structured\ntaxonomy of visual elements. This taxonomy includes numerous objects,\nattributes, and relations, enabling the synthesis of an almost infinite variety\nof scene graphs. Using these structured representations, Generate Any Scene\ntranslates each scene graph into a caption, enabling scalable evaluation of\ntext-to-vision models through standard metrics. We conduct extensive\nevaluations across multiple text-to-image, text-to-video, and text-to-3D\nmodels, presenting key findings on model performance. We find that DiT-backbone\ntext-to-image models align more closely with input captions than UNet-backbone\nmodels. Text-to-video models struggle with balancing dynamics and consistency,\nwhile both text-to-video and text-to-3D models show notable gaps in human\npreference alignment. We demonstrate the effectiveness of Generate Any Scene by\nconducting three practical applications leveraging captions generated by\nGenerate Any Scene: 1) a self-improving framework where models iteratively\nenhance their performance using generated data, 2) a distillation process to\ntransfer specific strengths from proprietary models to open-source\ncounterparts, and 3) improvements in content moderation by identifying and\ngenerating challenging synthetic data.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.08221v2",
    "published_date": "2024-12-11 09:17:39 UTC",
    "updated_date": "2024-12-16 09:54:46 UTC"
  },
  {
    "arxiv_id": "2412.10438v1",
    "title": "Automatic Image Annotation for Mapped Features Detection",
    "authors": [
      "Maxime Noizet",
      "Philippe Xu",
      "Philippe Bonnifait"
    ],
    "abstract": "Detecting road features is a key enabler for autonomous driving and\nlocalization. For instance, a reliable detection of poles which are widespread\nin road environments can improve localization. Modern deep learning-based\nperception systems need a significant amount of annotated data. Automatic\nannotation avoids time-consuming and costly manual annotation. Because\nautomatic methods are prone to errors, managing annotation uncertainty is\ncrucial to ensure a proper learning process. Fusing multiple annotation sources\non the same dataset can be an efficient way to reduce the errors. This not only\nimproves the quality of annotations, but also improves the learning of\nperception models. In this paper, we consider the fusion of three automatic\nannotation methods in images: feature projection from a high accuracy vector\nmap combined with a lidar, image segmentation and lidar segmentation. Our\nexperimental results demonstrate the significant benefits of multi-modal\nautomatic annotation for pole detection through a comparative evaluation on\nmanually annotated images. Finally, the resulting multi-modal fusion is used to\nfine-tune an object detection model for pole base detection using unlabeled\ndata, showing overall improvements achieved by enhancing network\nspecialization. The dataset is publicly available.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.10438v1",
    "published_date": "2024-12-11 09:06:52 UTC",
    "updated_date": "2024-12-11 09:06:52 UTC"
  },
  {
    "arxiv_id": "2412.08197v1",
    "title": "SAFIRE: Segment Any Forged Image Region",
    "authors": [
      "Myung-Joon Kwon",
      "Wonjun Lee",
      "Seung-Hun Nam",
      "Minji Son",
      "Changick Kim"
    ],
    "abstract": "Most techniques approach the problem of image forgery localization as a\nbinary segmentation task, training neural networks to label original areas as 0\nand forged areas as 1. In contrast, we tackle this issue from a more\nfundamental perspective by partitioning images according to their originating\nsources. To this end, we propose Segment Any Forged Image Region (SAFIRE),\nwhich solves forgery localization using point prompting. Each point on an image\nis used to segment the source region containing itself. This allows us to\npartition images into multiple source regions, a capability achieved for the\nfirst time. Additionally, rather than memorizing certain forgery traces, SAFIRE\nnaturally focuses on uniform characteristics within each source region. This\napproach leads to more stable and effective learning, achieving superior\nperformance in both the new task and the traditional binary forgery\nlocalization.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at AAAI 2025. Code is available at:\n  https://github.com/mjkwon2021/SAFIRE",
    "pdf_url": "http://arxiv.org/pdf/2412.08197v1",
    "published_date": "2024-12-11 08:40:37 UTC",
    "updated_date": "2024-12-11 08:40:37 UTC"
  },
  {
    "arxiv_id": "2412.08195v1",
    "title": "Semantic Scene Completion Based 3D Traversability Estimation for Off-Road Terrains",
    "authors": [
      "Zitong Chen",
      "Chao Sun",
      "Shida Nie",
      "Chen Min",
      "Changjiu Ning",
      "Haoyu Li",
      "Bo Wang"
    ],
    "abstract": "Off-road environments present significant challenges for autonomous ground\nvehicles due to the absence of structured roads and the presence of complex\nobstacles, such as uneven terrain, vegetation, and occlusions. Traditional\nperception algorithms, designed primarily for structured environments, often\nfail under these conditions, leading to inaccurate traversability estimations.\nIn this paper, ORDformer, a novel multimodal method that combines LiDAR point\nclouds with monocular images, is proposed to generate dense traversable\noccupancy predictions from a forward-facing perspective. By integrating\nmultimodal data, environmental feature extraction is enhanced, which is crucial\nfor accurate occupancy estimation in complex terrains. Furthermore, RELLIS-OCC,\na dataset with 3D traversable occupancy annotations, is introduced,\nincorporating geometric features such as step height, slope, and unevenness.\nThrough a comprehensive analysis of vehicle obstacle-crossing conditions and\nthe incorporation of vehicle body structure constraints, four traversability\ncost labels are generated: lethal, medium-cost, low-cost, and free.\nExperimental results demonstrate that ORDformer outperforms existing approaches\nin 3D traversable area recognition, particularly in off-road environments with\nirregular geometries and partial occlusions. Specifically, ORDformer achieves\nover a 20\\% improvement in scene completion IoU compared to other models. The\nproposed framework is scalable and adaptable to various vehicle platforms,\nallowing for adjustments to occupancy grid parameters and the integration of\nadvanced dynamic models for traversability cost estimation.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.RO",
    "comment": "12 pages,14 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.08195v1",
    "published_date": "2024-12-11 08:36:36 UTC",
    "updated_date": "2024-12-11 08:36:36 UTC"
  },
  {
    "arxiv_id": "2412.08187v1",
    "title": "From communities to interpretable network and word embedding: an unified approach",
    "authors": [
      "Thibault Prouteau",
      "Nicolas Dugué",
      "Simon Guillot"
    ],
    "abstract": "Modelling information from complex systems such as humans social interaction\nor words co-occurrences in our languages can help to understand how these\nsystems are organized and function. Such systems can be modelled by networks,\nand network theory provides a useful set of methods to analyze them. Among\nthese methods, graph embedding is a powerful tool to summarize the interactions\nand topology of a network in a vectorized feature space. When used in input of\nmachine learning algorithms, embedding vectors help with common graph problems\nsuch as link prediction, graph matching, etc. Word embedding has the goal of\nrepresenting the sense of words, extracting it from large text corpora. Despite\ndifferences in the structure of information in input of embedding algorithms,\nmany graph embedding approaches are adapted and inspired from methods in NLP.\nLimits of these methods are observed in both domains. Most of these methods\nrequire long and resource greedy training. Another downside to most methods is\nthat they are black-box, from which understanding how the information is\nstructured is rather complex. Interpretability of a model allows understanding\nhow the vector space is structured without the need for external information,\nand thus can be audited more easily. With both these limitations in mind, we\npropose a novel framework to efficiently embed network vertices in an\ninterpretable vector space. Our Lower Dimension Bipartite Framework (LDBGF)\nleverages the bipartite projection of a network using cliques to reduce\ndimensionality. Along with LDBGF, we introduce two implementations of this\nframework that rely on communities instead of cliques: SINr-NR and SINr-MF. We\nshow that SINr-MF can perform well on classical graphs and SINr-NR can produce\nhigh-quality graph and word embeddings that are interpretable and stable across\nruns.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.08187v1",
    "published_date": "2024-12-11 08:27:25 UTC",
    "updated_date": "2024-12-11 08:27:25 UTC"
  },
  {
    "arxiv_id": "2412.08186v1",
    "title": "Towards Automated Algebraic Multigrid Preconditioner Design Using Genetic Programming for Large-Scale Laser Beam Welding Simulations",
    "authors": [
      "Dinesh Parthasarathy",
      "Tommaso Bevilacqua",
      "Martin Lanser",
      "Axel Klawonn",
      "Harald Köstler"
    ],
    "abstract": "Multigrid methods are asymptotically optimal algorithms ideal for large-scale\nsimulations. But, they require making numerous algorithmic choices that\nsignificantly influence their efficiency. Unlike recent approaches that learn\noptimal multigrid components using machine learning techniques, we adopt a\ncomplementary strategy here, employing evolutionary algorithms to construct\nefficient multigrid cycles from available individual components. This\ntechnology is applied to finite element simulations of the laser beam welding\nprocess. The thermo-elastic behavior is described by a coupled system of\ntime-dependent thermo-elasticity equations, leading to nonlinear and\nill-conditioned systems. The nonlinearity is addressed using Newton's method,\nand iterative solvers are accelerated with an algebraic multigrid (AMG)\npreconditioner using hypre BoomerAMG interfaced via PETSc. This is applied as a\nmonolithic solver for the coupled equations. To further enhance solver\nefficiency, flexible AMG cycles are introduced, extending traditional cycle\ntypes with level-specific smoothing sequences and non-recursive cycling\npatterns. These are automatically generated using genetic programming, guided\nby a context-free grammar containing AMG rules. Numerical experiments\ndemonstrate the potential of these approaches to improve solver performance in\nlarge-scale laser beam welding simulations.",
    "categories": [
      "cs.CE",
      "cs.AI",
      "cs.NA",
      "math.NA",
      "65M55 (Primary) 74F05, 65M60 (Secondary)",
      "I.2.2; G.1.8; J.2"
    ],
    "primary_category": "cs.CE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.08186v1",
    "published_date": "2024-12-11 08:24:38 UTC",
    "updated_date": "2024-12-11 08:24:38 UTC"
  },
  {
    "arxiv_id": "2412.10435v1",
    "title": "COEF-VQ: Cost-Efficient Video Quality Understanding through a Cascaded Multimodal LLM Framework",
    "authors": [
      "Xin Dong",
      "Sen Jia",
      "Hongyu Xiong"
    ],
    "abstract": "Recently, with the emergence of recent Multimodal Large Language Model (MLLM)\ntechnology, it has become possible to exploit its video understanding\ncapability on different classification tasks. In practice, we face the\ndifficulty of huge requirements for GPU resource if we need to deploy MLLMs\nonline. In this paper, we propose COEF-VQ, a novel cascaded MLLM framework for\nbetter video quality understanding on TikTok. To this end, we first propose a\nMLLM fusing all visual, textual and audio signals, and then develop a cascade\nframework with a lightweight model as pre-filtering stage and MLLM as\nfine-consideration stage, significantly reducing the need for GPU resource,\nwhile retaining the performance demonstrated solely by MLLM. To demonstrate the\neffectiveness of COEF-VQ, we deployed this new framework onto the video\nmanagement platform (VMP) at TikTok, and performed a series of detailed\nexperiments on two in-house tasks related to video quality understanding. We\nshow that COEF-VQ leads to substantial performance gains with limit resource\nconsumption in these two tasks.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.10435v1",
    "published_date": "2024-12-11 08:10:32 UTC",
    "updated_date": "2024-12-11 08:10:32 UTC"
  },
  {
    "arxiv_id": "2412.08179v1",
    "title": "Auto-Generating Earnings Report Analysis via a Financial-Augmented LLM",
    "authors": [
      "Van-Duc Le"
    ],
    "abstract": "Financial analysis heavily relies on the evaluation of earnings reports to\ngain insights into company performance. Traditional generation of these reports\nrequires extensive financial expertise and is time-consuming. With the\nimpressive progress in Large Language Models (LLMs), a wide variety of\nfinancially focused LLMs has emerged, addressing tasks like sentiment analysis\nand entity recognition in the financial domain. This paper presents a novel\nchallenge: developing an LLM specifically for automating the generation of\nearnings reports analysis. Our methodology involves an in-depth analysis of\nexisting earnings reports followed by a unique approach to fine-tune an LLM for\nthis purpose. This approach combines retrieval augmentation and the generation\nof instruction-based data, specifically tailored for the financial sector, to\nenhance the LLM's performance. With extensive financial documents, we construct\nfinancial instruction data, enabling the refined adaptation of our LLM to\nfinancial contexts. Preliminary results indicate that our augmented LLM\noutperforms general open-source models and rivals commercial counterparts like\nGPT-3.5 in financial applications. Our research paves the way for streamlined\nand insightful automation in financial report generation, marking a significant\nstride in the field of financial analysis.",
    "categories": [
      "q-fin.ST",
      "cs.AI"
    ],
    "primary_category": "q-fin.ST",
    "comment": "8 pages, 1 figure, 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2412.08179v1",
    "published_date": "2024-12-11 08:09:42 UTC",
    "updated_date": "2024-12-11 08:09:42 UTC"
  },
  {
    "arxiv_id": "2412.08174v2",
    "title": "Can Graph Neural Networks Learn Language with Extremely Weak Text Supervision?",
    "authors": [
      "Zihao Li",
      "Lecheng Zheng",
      "Bowen Jin",
      "Dongqi Fu",
      "Baoyu Jing",
      "Yikun Ban",
      "Jingrui He",
      "Jiawei Han"
    ],
    "abstract": "While great success has been achieved in building vision models with\nContrastive Language-Image Pre-training (CLIP) over Internet-scale image-text\npairs, building transferable Graph Neural Networks (GNNs) with CLIP pipeline is\nchallenging because of three fundamental issues: the scarcity of labeled data\nand text supervision, different levels of downstream tasks, and the conceptual\ngaps between domains. In this work, to address these issues, we leverage\nmulti-modal prompt learning to effectively adapt pre-trained GNN to downstream\ntasks and data, given only a few semantically labeled samples, each with\nextremely weak text supervision. Our new paradigm embeds the graphs directly in\nthe same space as the Large Language Models (LLMs) by learning both graph\nprompts and text prompts simultaneously. To accomplish this, we improve\nstate-of-the-art graph prompt method, and then propose the first graph-language\nmulti-modal prompt learning approach for exploiting the knowledge in\npre-trained models. Notably, due to the insufficient supervision for\nfine-tuning, in our paradigm, the pre-trained GNN and the LLM are kept frozen,\nso the learnable parameters are much fewer than fine-tuning any pre-trained\nmodel. Through extensive experiments on real-world datasets, we demonstrate the\nsuperior performance of our paradigm in few-shot, multi-task-level, and\ncross-domain settings. Moreover, we build the first CLIP-style zero-shot\nclassification prototype that can generalize GNNs to unseen classes with\nextremely weak text supervision.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SI"
    ],
    "primary_category": "cs.LG",
    "comment": "Preprint, 25 pages",
    "pdf_url": "http://arxiv.org/pdf/2412.08174v2",
    "published_date": "2024-12-11 08:03:35 UTC",
    "updated_date": "2024-12-15 20:54:47 UTC"
  },
  {
    "arxiv_id": "2501.14737v1",
    "title": "EvalSVA: Multi-Agent Evaluators for Next-Gen Software Vulnerability Assessment",
    "authors": [
      "Xin-Cheng Wen",
      "Jiaxin Ye",
      "Cuiyun Gao",
      "Lianwei Wu",
      "Qing Liao"
    ],
    "abstract": "Software Vulnerability (SV) assessment is a crucial process of determining\ndifferent aspects of SVs (e.g., attack vectors and scope) for developers to\neffectively prioritize efforts in vulnerability mitigation. It presents a\nchallenging and laborious process due to the complexity of SVs and the scarcity\nof labeled data. To mitigate the above challenges, we introduce EvalSVA, a\nmulti-agent evaluators team to autonomously deliberate and evaluate various\naspects of SV assessment. Specifically, we propose a multi-agent-based\nframework to simulate vulnerability assessment strategies in real-world\nscenarios, which employs multiple Large Language Models (LLMs) into an\nintegrated group to enhance the effectiveness of SV assessment in the limited\ndata. We also design diverse communication strategies to autonomously discuss\nand assess different aspects of SV. Furthermore, we construct a multi-lingual\nSV assessment dataset based on the new standard of CVSS, comprising 699, 888,\nand 1,310 vulnerability-related commits in C++, Python, and Java, respectively.\nOur experimental results demonstrate that EvalSVA averagely outperforms the\n44.12\\% accuracy and 43.29\\% F1 for SV assessment compared with the previous\nmethods. It shows that EvalSVA offers a human-like process and generates both\nreason and answer for SV assessment. EvalSVA can also aid human experts in SV\nassessment, which provides more explanation and details for SV assessment.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "11 pages",
    "pdf_url": "http://arxiv.org/pdf/2501.14737v1",
    "published_date": "2024-12-11 08:00:50 UTC",
    "updated_date": "2024-12-11 08:00:50 UTC"
  },
  {
    "arxiv_id": "2412.12154v1",
    "title": "PyOD 2: A Python Library for Outlier Detection with LLM-powered Model Selection",
    "authors": [
      "Sihan Chen",
      "Zhuangzhuang Qian",
      "Wingchun Siu",
      "Xingcan Hu",
      "Jiaqi Li",
      "Shawn Li",
      "Yuehan Qin",
      "Tiankai Yang",
      "Zhuo Xiao",
      "Wanghao Ye",
      "Yichi Zhang",
      "Yushun Dong",
      "Yue Zhao"
    ],
    "abstract": "Outlier detection (OD), also known as anomaly detection, is a critical\nmachine learning (ML) task with applications in fraud detection, network\nintrusion detection, clickstream analysis, recommendation systems, and social\nnetwork moderation. Among open-source libraries for outlier detection, the\nPython Outlier Detection (PyOD) library is the most widely adopted, with over\n8,500 GitHub stars, 25 million downloads, and diverse industry usage. However,\nPyOD currently faces three limitations: (1) insufficient coverage of modern\ndeep learning algorithms, (2) fragmented implementations across PyTorch and\nTensorFlow, and (3) no automated model selection, making it hard for\nnon-experts.\n  To address these issues, we present PyOD Version 2 (PyOD 2), which integrates\n12 state-of-the-art deep learning models into a unified PyTorch framework and\nintroduces a large language model (LLM)-based pipeline for automated OD model\nselection. These improvements simplify OD workflows, provide access to 45\nalgorithms, and deliver robust performance on various datasets. In this paper,\nwe demonstrate how PyOD 2 streamlines the deployment and automation of OD\nmodels and sets a new standard in both research and industry. PyOD 2 is\naccessible at\n[https://github.com/yzhao062/pyod](https://github.com/yzhao062/pyod). This\nstudy aligns with the Web Mining and Content Analysis track, addressing topics\nsuch as the robustness of Web mining methods and the quality of\nalgorithmically-generated Web data.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.12154v1",
    "published_date": "2024-12-11 07:53:20 UTC",
    "updated_date": "2024-12-11 07:53:20 UTC"
  },
  {
    "arxiv_id": "2412.08156v1",
    "title": "Antelope: Potent and Concealed Jailbreak Attack Strategy",
    "authors": [
      "Xin Zhao",
      "Xiaojun Chen",
      "Haoyu Gao"
    ],
    "abstract": "Due to the remarkable generative potential of diffusion-based models,\nnumerous researches have investigated jailbreak attacks targeting these\nframeworks. A particularly concerning threat within image models is the\ngeneration of Not-Safe-for-Work (NSFW) content. Despite the implementation of\nsecurity filters, numerous efforts continue to explore ways to circumvent these\nsafeguards. Current attack methodologies primarily encompass adversarial prompt\nengineering or concept obfuscation, yet they frequently suffer from slow search\nefficiency, conspicuous attack characteristics and poor alignment with targets.\nTo overcome these challenges, we propose Antelope, a more robust and covert\njailbreak attack strategy designed to expose security vulnerabilities inherent\nin generative models. Specifically, Antelope leverages the confusion of\nsensitive concepts with similar ones, facilitates searches in the semantically\nadjacent space of these related concepts and aligns them with the target\nimagery, thereby generating sensitive images that are consistent with the\ntarget and capable of evading detection. Besides, we successfully exploit the\ntransferability of model-based attacks to penetrate online black-box services.\nExperimental evaluations demonstrate that Antelope outperforms existing\nbaselines across multiple defensive mechanisms, underscoring its efficacy and\nversatility.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.08156v1",
    "published_date": "2024-12-11 07:22:51 UTC",
    "updated_date": "2024-12-11 07:22:51 UTC"
  },
  {
    "arxiv_id": "2412.08148v1",
    "title": "A Review of Intelligent Device Fault Diagnosis Technologies Based on Machine Vision",
    "authors": [
      "Guiran Liu",
      "Binrong Zhu"
    ],
    "abstract": "This paper provides a comprehensive review of mechanical equipment fault\ndiagnosis methods, focusing on the advancements brought by Transformer-based\nmodels. It details the structure, working principles, and benefits of\nTransformers, particularly their self-attention mechanism and parallel\ncomputation capabilities, which have propelled their widespread application in\nnatural language processing and computer vision. The discussion highlights key\nTransformer model variants, such as Vision Transformers (ViT) and their\nextensions, which leverage self-attention to improve accuracy and efficiency in\nvisual tasks. Furthermore, the paper examines the application of\nTransformer-based approaches in intelligent fault diagnosis for mechanical\nsystems, showcasing their superior ability to extract and recognize patterns\nfrom complex sensor data for precise fault identification. Despite these\nadvancements, challenges remain, including the reliance on extensive labeled\ndatasets, significant computational demands, and difficulties in deploying\nmodels on resource-limited devices. To address these limitations, the paper\nproposes future research directions, such as developing lightweight Transformer\narchitectures, integrating multimodal data sources, and enhancing adaptability\nto diverse operational conditions. These efforts aim to further expand the\napplication of Transformer-based methods in mechanical fault diagnosis, making\nthem more robust, efficient, and suitable for real-world industrial\nenvironments.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "9 pages, This paper has been accepted for publication at RICAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2412.08148v1",
    "published_date": "2024-12-11 07:06:53 UTC",
    "updated_date": "2024-12-11 07:06:53 UTC"
  },
  {
    "arxiv_id": "2412.08147v1",
    "title": "How to Weight Multitask Finetuning? Fast Previews via Bayesian Model-Merging",
    "authors": [
      "Hugo Monzón Maldonado",
      "Thomas Möllenhoff",
      "Nico Daheim",
      "Iryna Gurevych",
      "Mohammad Emtiyaz Khan"
    ],
    "abstract": "When finetuning multiple tasks altogether, it is important to carefully weigh\nthem to get a good performance, but searching for good weights can be difficult\nand costly. Here, we propose to aid the search with fast previews to quickly\nget a rough idea of different reweighting options. We use model merging to\ncreate previews by simply reusing and averaging parameters of models trained on\neach task separately (no retraining required). To improve the quality of\npreviews, we propose a Bayesian approach to design new merging strategies by\nusing more flexible posteriors. We validate our findings on vision and\nnatural-language transformers. Our work shows the benefits of model merging via\nBayes to improve multitask finetuning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.08147v1",
    "published_date": "2024-12-11 07:06:36 UTC",
    "updated_date": "2024-12-11 07:06:36 UTC"
  },
  {
    "arxiv_id": "2412.08145v1",
    "title": "A Survey on Private Transformer Inference",
    "authors": [
      "Yang Li",
      "Xinyu Zhou",
      "Yitong Wang",
      "Liangxin Qian",
      "Jun Zhao"
    ],
    "abstract": "Transformer models have revolutionized AI, enabling applications like content\ngeneration and sentiment analysis. However, their use in Machine Learning as a\nService (MLaaS) raises significant privacy concerns, as centralized servers\nprocess sensitive user data. Private Transformer Inference (PTI) addresses\nthese issues using cryptographic techniques such as Secure Multi-Party\nComputation (MPC) and Homomorphic Encryption (HE), enabling secure model\ninference without exposing inputs or models. This paper reviews recent\nadvancements in PTI, analyzing state-of-the-art solutions, their challenges,\nand potential improvements. We also propose evaluation guidelines to assess\nresource efficiency and privacy guarantees, aiming to bridge the gap between\nhigh-performance inference and data privacy.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "The manuscript is still being revised and will be continuously\n  updated in the future",
    "pdf_url": "http://arxiv.org/pdf/2412.08145v1",
    "published_date": "2024-12-11 07:05:24 UTC",
    "updated_date": "2024-12-11 07:05:24 UTC"
  },
  {
    "arxiv_id": "2412.08144v1",
    "title": "AGMixup: Adaptive Graph Mixup for Semi-supervised Node Classification",
    "authors": [
      "Weigang Lu",
      "Ziyu Guan",
      "Wei Zhao",
      "Yaming Yang",
      "Yibing Zhan",
      "Yiheng Lu",
      "Dapeng Tao"
    ],
    "abstract": "Mixup is a data augmentation technique that enhances model generalization by\ninterpolating between data points using a mixing ratio $\\lambda$ in the image\ndomain. Recently, the concept of mixup has been adapted to the graph domain\nthrough node-centric interpolations. However, these approaches often fail to\naddress the complexity of interconnected relationships, potentially damaging\nthe graph's natural topology and undermining node interactions. Furthermore,\ncurrent graph mixup methods employ a one-size-fits-all strategy with a randomly\nsampled $\\lambda$ for all mixup pairs, ignoring the diverse needs of different\npairs. This paper proposes an Adaptive Graph Mixup (AGMixup) framework for\nsemi-supervised node classification. AGMixup introduces a subgraph-centric\napproach, which treats each subgraph similarly to how images are handled in\nEuclidean domains, thus facilitating a more natural integration of mixup into\ngraph-based learning. We also propose an adaptive mechanism to tune the mixing\nratio $\\lambda$ for diverse mixup pairs, guided by the contextual similarity\nand uncertainty of the involved subgraphs. Extensive experiments across seven\ndatasets on semi-supervised node classification benchmarks demonstrate\nAGMixup's superiority over state-of-the-art graph mixup methods. Source codes\nare available at \\url{https://github.com/WeigangLu/AGMixup}.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.08144v1",
    "published_date": "2024-12-11 07:04:35 UTC",
    "updated_date": "2024-12-11 07:04:35 UTC"
  },
  {
    "arxiv_id": "2412.08139v1",
    "title": "Wasserstein Distance Rivals Kullback-Leibler Divergence for Knowledge Distillation",
    "authors": [
      "Jiaming Lv",
      "Haoyuan Yang",
      "Peihua Li"
    ],
    "abstract": "Since pioneering work of Hinton et al., knowledge distillation based on\nKullback-Leibler Divergence (KL-Div) has been predominant, and recently its\nvariants have achieved compelling performance. However, KL-Div only compares\nprobabilities of the corresponding category between the teacher and student\nwhile lacking a mechanism for cross-category comparison. Besides, KL-Div is\nproblematic when applied to intermediate layers, as it cannot handle\nnon-overlapping distributions and is unaware of geometry of the underlying\nmanifold. To address these downsides, we propose a methodology of Wasserstein\nDistance (WD) based knowledge distillation. Specifically, we propose a logit\ndistillation method called WKD-L based on discrete WD, which performs\ncross-category comparison of probabilities and thus can explicitly leverage\nrich interrelations among categories. Moreover, we introduce a feature\ndistillation method called WKD-F, which uses a parametric method for modeling\nfeature distributions and adopts continuous WD for transferring knowledge from\nintermediate layers. Comprehensive evaluations on image classification and\nobject detection have shown (1) for logit distillation WKD-L outperforms very\nstrong KL-Div variants; (2) for feature distillation WKD-F is superior to the\nKL-Div counterparts and state-of-the-art competitors. The source code is\navailable at https://peihuali.org/WKD",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to NeurIPS 2024. Equal contribution from first two authors",
    "pdf_url": "http://arxiv.org/pdf/2412.08139v1",
    "published_date": "2024-12-11 06:54:39 UTC",
    "updated_date": "2024-12-11 06:54:39 UTC"
  },
  {
    "arxiv_id": "2412.08138v2",
    "title": "Learn How to Query from Unlabeled Data Streams in Federated Learning",
    "authors": [
      "Yuchang Sun",
      "Xinran Li",
      "Tao Lin",
      "Jun Zhang"
    ],
    "abstract": "Federated learning (FL) enables collaborative learning among decentralized\nclients while safeguarding the privacy of their local data. Existing studies on\nFL typically assume offline labeled data available at each client when the\ntraining starts. Nevertheless, the training data in practice often arrive at\nclients in a streaming fashion without ground-truth labels. Given the expensive\nannotation cost, it is critical to identify a subset of informative samples for\nlabeling on clients. However, selecting samples locally while accommodating the\nglobal training objective presents a challenge unique to FL. In this work, we\ntackle this conundrum by framing the data querying process in FL as a\ncollaborative decentralized decision-making problem and proposing an effective\nsolution named LeaDQ, which leverages multi-agent reinforcement learning\nalgorithms. In particular, under the implicit guidance from global information,\nLeaDQ effectively learns the local policies for distributed clients and steers\nthem towards selecting samples that can enhance the global model's accuracy.\nExtensive simulations on image and text tasks show that LeaDQ advances the\nmodel performance in various FL scenarios, outperforming the benchmarking\nalgorithms.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.08138v2",
    "published_date": "2024-12-11 06:51:45 UTC",
    "updated_date": "2024-12-12 01:47:20 UTC"
  },
  {
    "arxiv_id": "2412.16182v1",
    "title": "Decoding Poultry Vocalizations -- Natural Language Processing and Transformer Models for Semantic and Emotional Analysis",
    "authors": [
      "Venkatraman Manikandan",
      "Suresh Neethirajan"
    ],
    "abstract": "Deciphering the acoustic language of chickens offers new opportunities in\nanimal welfare and ecological informatics. Their subtle vocal signals encode\nhealth conditions, emotional states, and dynamic interactions within\necosystems. Understanding the semantics of these calls provides a valuable tool\nfor interpreting their functional vocabulary and clarifying how each sound\nserves a specific purpose in social and environmental contexts. We apply\nadvanced Natural Language Processing and transformer based models to translate\nbioacoustic data into meaningful insights. Our method integrates Wave2Vec 2.0\nfor raw audio feature extraction with a fine tuned Bidirectional Encoder\nRepresentations from Transformers model, pretrained on a broad corpus of animal\nsounds and adapted to poultry tasks. This pipeline decodes poultry\nvocalizations into interpretable categories including distress calls, feeding\nsignals, and mating vocalizations, revealing emotional nuances often overlooked\nby conventional analyses. Achieving 92 percent accuracy in classifying key\nvocalization types, our approach demonstrates the feasibility of real time\nautomated monitoring of flock health and stress. By tracking this functional\nvocabulary, farmers can respond proactively to environmental or behavioral\nchanges, improving poultry welfare, reducing stress related productivity\nlosses, and supporting more sustainable farm management. Beyond agriculture,\nthis research enhances our understanding of computational ecology. Accessing\nthe semantic foundation of animal calls may indicate biodiversity,\nenvironmental stressors, and species interactions, informing integrative\necosystem level decision making.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "28 Pages, 14 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.16182v1",
    "published_date": "2024-12-11 06:44:32 UTC",
    "updated_date": "2024-12-11 06:44:32 UTC"
  },
  {
    "arxiv_id": "2412.08133v1",
    "title": "Intelligent Electric Power Steering: Artificial Intelligence Integration Enhances Vehicle Safety and Performance",
    "authors": [
      "Vikas Vyas",
      "Sneha Sudhir Shetiya"
    ],
    "abstract": "Electric Power Steering (EPS) systems utilize electric motors to aid users in\nsteering their vehicles, which provide additional precise control and reduced\nenergy consumption compared to traditional hydraulic systems. EPS technology\nprovides safety,control and efficiency.. This paper explains the integration of\nArtificial Intelligence (AI) into Electric Power Steering (EPS) systems,\nfocusing on its role in enhancing the safety, and adaptability across diverse\ndriving conditions. We explore significant development in AI-driven EPS,\nincluding predictive control algorithms, adaptive torque management systems,\nand data-driven diagnostics. The paper presents case studies of AI applications\nin EPS, such as Lane centering control (LCC), Automated Parking Systems, and\nAutonomous Vehicle Steering, while considering the challenges, limitations, and\nfuture prospects of this technology. This article discusses current\ndevelopments in AI-driven EPS, emphasizing on the benefits of improved safety,\nadaptive control, and predictive maintenance. Challenges in integrating AI in\nEPS systems. This paper addresses cybersecurity risks, ethical concerns, and\ntechnical limitations,, along with next steps for research and implementation\nin autonomous, and connected vehicles.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO",
    "comment": "IEEE Summit on Reliability, Availability and Serviceability, 2024",
    "pdf_url": "http://arxiv.org/pdf/2412.08133v1",
    "published_date": "2024-12-11 06:41:51 UTC",
    "updated_date": "2024-12-11 06:41:51 UTC"
  },
  {
    "arxiv_id": "2412.08131v1",
    "title": "DiffRaman: A Conditional Latent Denoising Diffusion Probabilistic Model for Bacterial Raman Spectroscopy Identification Under Limited Data Conditions",
    "authors": [
      "Haiming Yao",
      "Wei Luo",
      "Ang Gao",
      "Tao Zhou",
      "Xue Wang"
    ],
    "abstract": "Raman spectroscopy has attracted significant attention in various biochemical\ndetection fields, especially in the rapid identification of pathogenic\nbacteria. The integration of this technology with deep learning to facilitate\nautomated bacterial Raman spectroscopy diagnosis has emerged as a key focus in\nrecent research. However, the diagnostic performance of existing deep learning\nmethods largely depends on a sufficient dataset, and in scenarios where there\nis a limited availability of Raman spectroscopy data, it is inadequate to fully\noptimize the numerous parameters of deep neural networks. To address these\nchallenges, this paper proposes a data generation method utilizing deep\ngenerative models to expand the data volume and enhance the recognition\naccuracy of bacterial Raman spectra. Specifically, we introduce DiffRaman, a\nconditional latent denoising diffusion probability model for Raman spectra\ngeneration. Experimental results demonstrate that synthetic bacterial Raman\nspectra generated by DiffRaman can effectively emulate real experimental\nspectra, thereby enhancing the performance of diagnostic models, especially\nunder conditions of limited data. Furthermore, compared to existing generative\nmodels, the proposed DiffRaman offers improvements in both generation quality\nand computational efficiency. Our DiffRaman approach offers a well-suited\nsolution for automated bacteria Raman spectroscopy diagnosis in data-scarce\nscenarios, offering new insights into alleviating the labor of spectroscopic\nmeasurements and enhancing rare bacteria identification.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.08131v1",
    "published_date": "2024-12-11 06:36:55 UTC",
    "updated_date": "2024-12-11 06:36:55 UTC"
  },
  {
    "arxiv_id": "2412.12153v2",
    "title": "Revisiting Weight Averaging for Model Merging",
    "authors": [
      "Jiho Choi",
      "Donggyun Kim",
      "Chanhyuk Lee",
      "Seunghoon Hong"
    ],
    "abstract": "Model merging aims to build a multi-task learner by combining the parameters\nof individually fine-tuned models without additional training. While a\nstraightforward approach is to average model parameters across tasks, this\noften results in suboptimal performance due to interference among parameters\nacross tasks. In this paper, we present intriguing results that weight\naveraging implicitly induces task vectors centered around the weight averaging\nitself and that applying a low-rank approximation to these centered task\nvectors significantly improves merging performance. Our analysis shows that\ncentering the task vectors effectively reduces task interference and most of\ntask-specific knowledge is concentrated in the top singular vectors. Our method\ndemonstrates robust and scalable performance on vision benchmarks across\nvarying numbers of tasks and model sizes. Furthermore, we observe that our\napproach is applicable to natural language processing tasks with competitive\nperformance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Additional experiment results are included",
    "pdf_url": "http://arxiv.org/pdf/2412.12153v2",
    "published_date": "2024-12-11 06:29:20 UTC",
    "updated_date": "2025-04-03 11:46:20 UTC"
  },
  {
    "arxiv_id": "2412.08127v3",
    "title": "Evil twins are not that evil: Qualitative insights into machine-generated prompts",
    "authors": [
      "Nathanaël Carraz Rakotonirina",
      "Corentin Kervadec",
      "Francesca Franzon",
      "Marco Baroni"
    ],
    "abstract": "It has been widely observed that language models (LMs) respond in predictable\nways to algorithmically generated prompts that are seemingly unintelligible.\nThis is both a sign that we lack a full understanding of how LMs work, and a\npractical challenge, because opaqueness can be exploited for harmful uses of\nLMs, such as jailbreaking. We present the first thorough analysis of opaque\nmachine-generated prompts, or autoprompts, pertaining to 6 LMs of different\nsizes and families. We find that machine-generated prompts are characterized by\na last token that is often intelligible and strongly affects the generation. A\nsmall but consistent proportion of the previous tokens are prunable, probably\nappearing in the prompt as a by-product of the fact that the optimization\nprocess fixes the number of tokens. The remaining tokens fall into two\ncategories: filler tokens, which can be replaced with semantically unrelated\nsubstitutes, and keywords, that tend to have at least a loose semantic relation\nwith the generation, although they do not engage in well-formed syntactic\nrelations with it. Additionally, human experts can reliably identify the most\ninfluential tokens in an autoprompt a posteriori, suggesting these prompts are\nnot entirely opaque. Finally, some of the ablations we applied to autoprompts\nyield similar effects in natural language inputs, suggesting that autoprompts\nemerge naturally from the way LMs process linguistic inputs in general.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.08127v3",
    "published_date": "2024-12-11 06:22:44 UTC",
    "updated_date": "2025-03-31 16:33:26 UTC"
  },
  {
    "arxiv_id": "2412.08120v1",
    "title": "Dense Depth from Event Focal Stack",
    "authors": [
      "Kenta Horikawa",
      "Mariko Isogawa",
      "Hideo Saito",
      "Shohei Mori"
    ],
    "abstract": "We propose a method for dense depth estimation from an event stream generated\nwhen sweeping the focal plane of the driving lens attached to an event camera.\nIn this method, a depth map is inferred from an ``event focal stack'' composed\nof the event stream using a convolutional neural network trained with\nsynthesized event focal stacks. The synthesized event stream is created from a\nfocal stack generated by Blender for any arbitrary 3D scene. This allows for\ntraining on scenes with diverse structures. Additionally, we explored methods\nto eliminate the domain gap between real event streams and synthetic event\nstreams. Our method demonstrates superior performance over a depth-from-defocus\nmethod in the image domain on synthetic and real datasets.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at WACV2025",
    "pdf_url": "http://arxiv.org/pdf/2412.08120v1",
    "published_date": "2024-12-11 06:13:38 UTC",
    "updated_date": "2024-12-11 06:13:38 UTC"
  },
  {
    "arxiv_id": "2412.12152v1",
    "title": "GraphTool-Instruction: Revolutionizing Graph Reasoning in LLMs through Decomposed Subtask Instruction",
    "authors": [
      "Rongzheng Wang",
      "Shuang Liang",
      "Qizhi Chen",
      "Jiasheng Zhang",
      "Ke Qin"
    ],
    "abstract": "Large language models (LLMs) have been demonstrated to possess the\ncapabilities to understand fundamental graph properties and address various\ngraph reasoning tasks. Existing methods fine-tune LLMs to understand and\nexecute graph reasoning tasks by specially designed task instructions. However,\nthese Text-Instruction methods generally exhibit poor performance. Inspired by\ntool learning, researchers propose Tool-Instruction methods to solve various\ngraph problems by special tool calling (e.g., function, API and model),\nachieving significant improvements in graph reasoning tasks. Nevertheless,\ncurrent Tool-Instruction approaches focus on the tool information and ignore\nthe graph structure information, which leads to significantly inferior\nperformance on small-scale LLMs (less than 13B). To tackle this issue, we\npropose GraphTool-Instruction, an innovative Instruction-tuning approach that\ndecomposes the graph reasoning task into three distinct subtasks (i.e., graph\nextraction, tool name identification and tool parameter extraction), and design\nspecialized instructions for each subtask. Our GraphTool-Instruction can be\nused as a plug-and-play prompt for different LLMs without fine-tuning.\nMoreover, building on GraphTool-Instruction, we develop GTools, a dataset that\nincludes twenty graph reasoning tasks, and create a graph reasoning LLM called\nGraphForge based on Llama3-8B. We conduct extensive experiments on twenty graph\nreasoning tasks with different graph types (e.g., graph size or graph\ndirection), and we find that GraphTool-Instruction achieves SOTA compared to\nText-Instruction and Tool-Instruction methods. Fine-tuned on GTools, GraphForge\ngets further improvement of over 30% compared to the Tool-Instruction enhanced\nGPT-3.5-turbo, and it performs comparably to the high-cost GPT-4o. Our codes\nand data are available at\nhttps://anonymous.4open.science/r/GraphTool-Instruction.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "22 pages, have been accepted by KDD 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.12152v1",
    "published_date": "2024-12-11 06:12:52 UTC",
    "updated_date": "2024-12-11 06:12:52 UTC"
  },
  {
    "arxiv_id": "2412.12151v1",
    "title": "SMARTCAL: An Approach to Self-Aware Tool-Use Evaluation and Calibration",
    "authors": [
      "Yuanhao Shen",
      "Xiaodan Zhu",
      "Lei Chen"
    ],
    "abstract": "The tool-use ability of Large Language Models (LLMs) has a profound impact on\na wide range of industrial applications. However, LLMs' self-control and\ncalibration capability in appropriately using tools remains understudied. The\nproblem is consequential as it raises potential risks of degraded performance\nand poses a threat to the trustworthiness of the models. In this paper, we\nconduct a study on a family of state-of-the-art LLMs on three datasets with two\nmainstream tool-use frameworks. Our study reveals the tool-abuse behavior of\nLLMs, a tendency for models to misuse tools with overconfidence. We also find\nthat this is a common issue regardless of model capability. Accordingly, we\npropose a novel approach, \\textit{SMARTCAL}, to mitigate the observed issues,\nand our results show an average of 8.6 percent increase in the QA performance\nand a 21.6 percent decrease in Expected Calibration Error (ECE) compared to\nbaseline models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.12151v1",
    "published_date": "2024-12-11 06:09:12 UTC",
    "updated_date": "2024-12-11 06:09:12 UTC"
  },
  {
    "arxiv_id": "2412.08117v1",
    "title": "LatentSpeech: Latent Diffusion for Text-To-Speech Generation",
    "authors": [
      "Haowei Lou",
      "Helen Paik",
      "Pari Delir Haghighi",
      "Wen Hu",
      "Lina Yao"
    ],
    "abstract": "Diffusion-based Generative AI gains significant attention for its superior\nperformance over other generative techniques like Generative Adversarial\nNetworks and Variational Autoencoders. While it has achieved notable\nadvancements in fields such as computer vision and natural language processing,\ntheir application in speech generation remains under-explored. Mainstream\nText-to-Speech systems primarily map outputs to Mel-Spectrograms in the\nspectral space, leading to high computational loads due to the sparsity of\nMelSpecs. To address these limitations, we propose LatentSpeech, a novel TTS\ngeneration approach utilizing latent diffusion models. By using latent\nembeddings as the intermediate representation, LatentSpeech reduces the target\ndimension to 5% of what is required for MelSpecs, simplifying the processing\nfor the TTS encoder and vocoder and enabling efficient high-quality speech\ngeneration. This study marks the first integration of latent diffusion models\nin TTS, enhancing the accuracy and naturalness of generated speech.\nExperimental results on benchmark datasets demonstrate that LatentSpeech\nachieves a 25% improvement in Word Error Rate and a 24% improvement in Mel\nCepstral Distortion compared to existing models, with further improvements\nrising to 49.5% and 26%, respectively, with additional training data. These\nfindings highlight the potential of LatentSpeech to advance the\nstate-of-the-art in TTS technology",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.MM",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.08117v1",
    "published_date": "2024-12-11 05:55:06 UTC",
    "updated_date": "2024-12-11 05:55:06 UTC"
  },
  {
    "arxiv_id": "2501.09021v1",
    "title": "Navigating Ethical Challenges in Generative AI-Enhanced Research: The ETHICAL Framework for Responsible Generative AI Use",
    "authors": [
      "Douglas Eacersall",
      "Lynette Pretorius",
      "Ivan Smirnov",
      "Erika Spray",
      "Sam Illingworth",
      "Ritesh Chugh",
      "Sonja Strydom",
      "Dianne Stratton-Maher",
      "Jonathan Simmons",
      "Isaac Jennings",
      "Rian Roux",
      "Ruth Kamrowski",
      "Abigail Downie",
      "Chee Ling Thong",
      "Katharine A. Howell"
    ],
    "abstract": "The rapid adoption of generative artificial intelligence (GenAI) in research\npresents both opportunities and ethical challenges that should be carefully\nnavigated. Although GenAI tools can enhance research efficiency through\nautomation of tasks such as literature review and data analysis, their use\nraises concerns about aspects such as data accuracy, privacy, bias, and\nresearch integrity. This paper develops the ETHICAL framework, which is a\npractical guide for responsible GenAI use in research. Employing a\nconstructivist case study examining multiple GenAI tools in real research\ncontexts, the framework consists of seven key principles: Examine policies and\nguidelines, Think about social impacts, Harness understanding of the\ntechnology, Indicate use, Critically engage with outputs, Access secure\nversions, and Look at user agreements. Applying these principles will enable\nresearchers to uphold research integrity while leveraging GenAI benefits. The\nframework addresses a critical gap between awareness of ethical issues and\npractical action steps, providing researchers with concrete guidance for\nethical GenAI integration. This work has implications for research practice,\ninstitutional policy development, and the broader academic community while\nadapting to an AI-enhanced research landscape. The ETHICAL framework can serve\nas a foundation for developing AI literacy in academic settings and promoting\nresponsible innovation in research methodologies.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "I.2.0"
    ],
    "primary_category": "cs.CY",
    "comment": "28 pages, 1 figure",
    "pdf_url": "http://arxiv.org/pdf/2501.09021v1",
    "published_date": "2024-12-11 05:49:11 UTC",
    "updated_date": "2024-12-11 05:49:11 UTC"
  },
  {
    "arxiv_id": "2412.08112v1",
    "title": "Aligner-Guided Training Paradigm: Advancing Text-to-Speech Models with Aligner Guided Duration",
    "authors": [
      "Haowei Lou",
      "Helen Paik",
      "Wen Hu",
      "Lina Yao"
    ],
    "abstract": "Recent advancements in text-to-speech (TTS) systems, such as FastSpeech and\nStyleSpeech, have significantly improved speech generation quality. However,\nthese models often rely on duration generated by external tools like the\nMontreal Forced Aligner, which can be time-consuming and lack flexibility. The\nimportance of accurate duration is often underestimated, despite their crucial\nrole in achieving natural prosody and intelligibility. To address these\nlimitations, we propose a novel Aligner-Guided Training Paradigm that\nprioritizes accurate duration labelling by training an aligner before the TTS\nmodel. This approach reduces dependence on external tools and enhances\nalignment accuracy. We further explore the impact of different acoustic\nfeatures, including Mel-Spectrograms, MFCCs, and latent features, on TTS model\nperformance. Our experimental results show that aligner-guided duration\nlabelling can achieve up to a 16\\% improvement in word error rate and\nsignificantly enhance phoneme and tone alignment. These findings highlight the\neffectiveness of our approach in optimizing TTS systems for more natural and\nintelligible speech generation.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.08112v1",
    "published_date": "2024-12-11 05:39:12 UTC",
    "updated_date": "2024-12-11 05:39:12 UTC"
  },
  {
    "arxiv_id": "2412.08109v2",
    "title": "Unseen Horizons: Unveiling the Real Capability of LLM Code Generation Beyond the Familiar",
    "authors": [
      "Yuanliang Zhang",
      "Yifan Xie",
      "Shanshan Li",
      "Ke Liu",
      "Chong Wang",
      "Zhouyang Jia",
      "Xiangbing Huang",
      "Jie Song",
      "Chaopeng Luo",
      "Zhizheng Zheng",
      "Rulin Xu",
      "Yitong Liu",
      "Si Zheng",
      "Xiangke Liao"
    ],
    "abstract": "Recently, large language models (LLMs) have shown strong potential in code\ngeneration tasks. However, there are still gaps before they can be fully\napplied in actual software development processes. Accurately assessing the code\ngeneration capabilities of large language models has become an important basis\nfor evaluating and improving the models. Some existing works have constructed\ndatasets to evaluate the capabilities of these models. However, the current\nevaluation process may encounter the illusion of \"Specialist in Familiarity\",\nprimarily due to three gaps: the exposure of target code, case timeliness, and\ndependency availability. The fundamental reason for these gaps is that the code\nin current datasets may have been extensively exposed and exercised during the\ntraining phase, and due to the continuous training and development of LLM,\ntheir timeliness has been severely compromised. The key to solve the problem is\nto, as much as possible, evaluate the LLMs using code that they have not\nencountered before. Thus, the fundamental idea in this paper is to draw on the\nconcept of code obfuscation, changing code at different levels while ensuring\nthe functionality and output. To this end, we build a code-obfuscation based\nbenchmark OBFUSEVAL. We first collect 1,354 raw cases from five real-world\nprojects, including function description and code. Then we use three-level\nstrategy (symbol, structure and semantic) to obfuscate descriptions, code and\ncontext dependencies. We evaluate four LLMs on OBFU- SEVAL and compared the\neffectiveness of different obfuscation strategy. We use official test suites of\nthese projects to evaluate the generated code. The results show that after\nobfuscation, the average decrease ratio of test pass rate can up to 62.5%.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "Accepted by the 47th International Conference on Software Engineering\n  (ICSE 2025)",
    "pdf_url": "http://arxiv.org/pdf/2412.08109v2",
    "published_date": "2024-12-11 05:31:39 UTC",
    "updated_date": "2025-01-15 11:57:34 UTC"
  },
  {
    "arxiv_id": "2412.08099v4",
    "title": "Adversarial Vulnerabilities in Large Language Models for Time Series Forecasting",
    "authors": [
      "Fuqiang Liu",
      "Sicong Jiang",
      "Luis Miranda-Moreno",
      "Seongjin Choi",
      "Lijun Sun"
    ],
    "abstract": "Large Language Models (LLMs) have recently demonstrated significant potential\nin time series forecasting, offering impressive capabilities in handling\ncomplex temporal data. However, their robustness and reliability in real-world\napplications remain under-explored, particularly concerning their\nsusceptibility to adversarial attacks. In this paper, we introduce a targeted\nadversarial attack framework for LLM-based time series forecasting. By\nemploying both gradient-free and black-box optimization methods, we generate\nminimal yet highly effective perturbations that significantly degrade the\nforecasting accuracy across multiple datasets and LLM architectures. Our\nexperiments, which include models like LLMTime with GPT-3.5, GPT-4, LLaMa, and\nMistral, TimeGPT, and TimeLLM show that adversarial attacks lead to much more\nsevere performance degradation than random noise, and demonstrate the broad\neffectiveness of our attacks across different LLMs. The results underscore the\ncritical vulnerabilities of LLMs in time series forecasting, highlighting the\nneed for robust defense mechanisms to ensure their reliable deployment in\npractical applications. The code repository can be found at\nhttps://github.com/JohnsonJiang1996/AdvAttack_LLM4TS.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "AISTATS 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.08099v4",
    "published_date": "2024-12-11 04:53:15 UTC",
    "updated_date": "2025-03-12 21:35:52 UTC"
  },
  {
    "arxiv_id": "2412.08098v2",
    "title": "What You See Is Not Always What You Get: An Empirical Study of Code Comprehension by Large Language Models",
    "authors": [
      "Bangshuo Zhu",
      "Jiawen Wen",
      "Huaming Chen"
    ],
    "abstract": "Recent studies have demonstrated outstanding capabilities of large language\nmodels (LLMs) in software engineering tasks, including code generation and\ncomprehension. While LLMs have shown significant potential in assisting with\ncoding, it is perceived that LLMs are vulnerable to adversarial attacks. In\nthis paper, we investigate the vulnerability of LLMs to imperceptible attacks,\nwhere hidden character manipulation in source code misleads LLMs' behaviour\nwhile remaining undetectable to human reviewers. We devise these attacks into\nfour distinct categories and analyse their impacts on code analysis and\ncomprehension tasks. These four types of imperceptible coding character attacks\ninclude coding reordering, invisible coding characters, code deletions, and\ncode homoglyphs. To comprehensively benchmark the robustness of current LLMs\nsolutions against the attacks, we present a systematic experimental evaluation\non multiple state-of-the-art LLMs. Our experimental design introduces two key\nperformance metrics, namely model confidence using log probabilities of\nresponse, and the response correctness. A set of controlled experiments are\nconducted using a large-scale perturbed and unperturbed code snippets as the\nprimary prompt input. Our findings confirm the susceptibility of LLMs to\nimperceptible coding character attacks, while different LLMs present different\nnegative correlations between perturbation magnitude and performance. These\nresults highlight the urgent need for robust LLMs capable of manoeuvring\nbehaviours under imperceptible adversarial conditions. We anticipate this work\nprovides valuable insights for enhancing the security and trustworthiness of\nLLMs in software engineering applications.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.08098v2",
    "published_date": "2024-12-11 04:52:41 UTC",
    "updated_date": "2025-02-14 05:21:37 UTC"
  },
  {
    "arxiv_id": "2412.08090v2",
    "title": "Multilingual LLMs Inherently Reward In-Language Time-Sensitive Semantic Alignment for Low-Resource Languages",
    "authors": [
      "Ashutosh Bajpai",
      "Tanmoy Chakraborty"
    ],
    "abstract": "The unwavering disparity in labeled resources between resource-rich languages\nand those considered low-resource remains a significant impediment for Large\nLanguage Models (LLMs). Recent strides in cross-lingual in-context learning\n(X-ICL), mainly through semantically aligned examples retrieved from\nmultilingual pre-trained transformers, have shown promise in mitigating this\nissue. However, our investigation reveals that LLMs intrinsically reward\nin-language semantically aligned cross-lingual instances over direct\ncross-lingual semantic alignments, with a pronounced disparity in handling\ntime-sensitive queries in the X-ICL setup. Such queries demand sound temporal\nreasoning ability from LLMs, yet the advancements have predominantly focused on\nEnglish. This study aims to bridge this gap by improving temporal reasoning\ncapabilities in low-resource languages. To this end, we introduce mTEMPREASON,\na temporal reasoning dataset aimed at the varied degrees of low-resource\nlanguages and propose Cross-Lingual Time-Sensitive Semantic Alignment\n(CLiTSSA), a novel method to improve temporal reasoning in these contexts. To\nfacilitate this, we construct an extension of mTEMPREASON comprising pairs of\nparallel cross-language temporal queries along with their anticipated\nin-language semantic similarity scores. Our empirical evidence underscores the\nsuperior performance of CLiTSSA compared to established baselines across three\nlanguages -- Romanian, German, and French, encompassing three temporal tasks\nand including a diverse set of four contemporaneous LLMs. This marks a\nsignificant step forward in addressing resource disparity in the context of\ntemporal reasoning across languages.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.08090v2",
    "published_date": "2024-12-11 04:16:39 UTC",
    "updated_date": "2025-02-24 13:44:37 UTC"
  },
  {
    "arxiv_id": "2412.10434v1",
    "title": "NAT-NL2GQL: A Novel Multi-Agent Framework for Translating Natural Language to Graph Query Language",
    "authors": [
      "Yuanyuan Liang",
      "Tingyu Xie",
      "Gan Peng",
      "Zihao Huang",
      "Yunshi Lan",
      "Weining Qian"
    ],
    "abstract": "The emergence of Large Language Models (LLMs) has revolutionized many fields,\nnot only traditional natural language processing (NLP) tasks. Recently,\nresearch on applying LLMs to the database field has been booming, and as a\ntypical non-relational database, the use of LLMs in graph database research has\nnaturally gained significant attention. Recent efforts have increasingly\nfocused on leveraging LLMs to translate natural language into graph query\nlanguage (NL2GQL). Although some progress has been made, these methods have\nclear limitations, such as their reliance on streamlined processes that often\noverlook the potential of LLMs to autonomously plan and collaborate with other\nLLMs in tackling complex NL2GQL challenges. To address this gap, we propose\nNAT-NL2GQL, a novel multi-agent framework for translating natural language to\ngraph query language. Specifically, our framework consists of three synergistic\nagents: the Preprocessor agent, the Generator agent, and the Refiner agent. The\nPreprocessor agent manages data processing as context, including tasks such as\nname entity recognition, query rewriting, path linking, and the extraction of\nquery-related schemas. The Generator agent is a fine-tuned LLM trained on\nNL-GQL data, responsible for generating corresponding GQL statements based on\nqueries and their related schemas. The Refiner agent is tasked with refining\nthe GQL or context using error information obtained from the GQL execution\nresults. Given the scarcity of high-quality open-source NL2GQL datasets based\non nGQL syntax, we developed StockGQL, a dataset constructed from a financial\nmarket graph database. It is available at:\nhttps://github.com/leonyuancode/StockGQL. Experimental results on the StockGQL\nand SpCQL datasets reveal that our method significantly outperforms baseline\napproaches, highlighting its potential for advancing NL2GQL research.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.DB"
    ],
    "primary_category": "cs.CL",
    "comment": "12 pages,6 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.10434v1",
    "published_date": "2024-12-11 04:14:09 UTC",
    "updated_date": "2024-12-11 04:14:09 UTC"
  },
  {
    "arxiv_id": "2412.08085v2",
    "title": "Non-Myopic Multi-Objective Bayesian Optimization",
    "authors": [
      "Syrine Belakaria",
      "Alaleh Ahmadianshalchi",
      "Barbara Engelhardt",
      "Stefano Ermon",
      "Janardhan Rao Doppa"
    ],
    "abstract": "We consider the problem of finite-horizon sequential experimental design to\nsolve multi-objective optimization (MOO) of expensive black-box objective\nfunctions. This problem arises in many real-world applications, including\nmaterials design, where we have a small resource budget to make and evaluate\ncandidate materials in the lab. We solve this problem using the framework of\nBayesian optimization (BO) and propose the first set of non-myopic methods for\nMOO problems. Prior work on non-myopic BO for single-objective problems relies\non the Bellman optimality principle to handle the lookahead reasoning process.\nHowever, this principle does not hold for most MOO problems because the reward\nfunction needs to satisfy some conditions: scalar variable, monotonicity, and\nadditivity. We address this challenge by using hypervolume improvement (HVI) as\nour scalarization approach, which allows us to use a lower-bound on the Bellman\nequation to approximate the finite-horizon using a batch expected hypervolume\nimprovement (EHVI) acquisition function (AF) for MOO. Our formulation naturally\nallows us to use other improvement-based scalarizations and compare their\nefficacy to HVI. We derive three non-myopic AFs for MOBO: 1) the Nested AF,\nwhich is based on the exact computation of the lower bound, 2) the Joint AF,\nwhich is a lower bound on the nested AF, and 3) the BINOM AF, which is a fast\nand approximate variant based on batch multi-objective acquisition functions.\nOur experiments on multiple diverse real-world MO problems demonstrate that our\nnon-myopic AFs substantially improve performance over the existing myopic AFs\nfor MOBO.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Published in Transactions on Machine Learning Research (TMLR)",
    "pdf_url": "http://arxiv.org/pdf/2412.08085v2",
    "published_date": "2024-12-11 04:05:29 UTC",
    "updated_date": "2025-05-01 05:07:33 UTC"
  },
  {
    "arxiv_id": "2412.08081v2",
    "title": "How to select slices for annotation to train best-performing deep learning segmentation models for cross-sectional medical images?",
    "authors": [
      "Yixin Zhang",
      "Kevin Kramer",
      "Maciej A. Mazurowski"
    ],
    "abstract": "Automated segmentation of medical images heavily relies on the availability\nof precise manual annotations. However, generating these annotations is often\ntime-consuming, expensive, and sometimes requires specialized expertise\n(especially for cross-sectional medical images). Therefore, it is essential to\noptimize the use of annotation resources to ensure efficiency and\neffectiveness. In this paper, we systematically address the question: \"in a\nnon-interactive annotation pipeline, how should slices from cross-sectional\nmedical images be selected for annotation to maximize the performance of the\nresulting deep learning segmentation models?\" We conducted experiments on 4\nmedical imaging segmentation tasks with varying annotation budgets, numbers of\nannotated cases, numbers of annotated slices per volume, slice selection\ntechniques, and mask interpolations. We found that:\n  1) It is almost always preferable to annotate fewer slices per volume and\nmore volumes given an annotation budget. 2) Selecting slices for annotation by\nunsupervised active learning (UAL) is not superior to selecting slices randomly\nor at fixed intervals, provided that each volume is allocated the same number\nof annotated slices. 3) Interpolating masks between annotated slices rarely\nenhances model performance, with exceptions of some specific configuration for\n3D models.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "9 main pages, 21 total pages, MIDL 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.08081v2",
    "published_date": "2024-12-11 03:59:05 UTC",
    "updated_date": "2025-04-05 07:44:13 UTC"
  },
  {
    "arxiv_id": "2412.08072v1",
    "title": "Using Large Language Models for Parametric Shape Optimization",
    "authors": [
      "Xinxin Zhang",
      "Zhuoqun Xu",
      "Guangpu Zhu",
      "Chien Ming Jonathan Tay",
      "Yongdong Cui",
      "Boo Cheong Khoo",
      "Lailai Zhu"
    ],
    "abstract": "Recent advanced large language models (LLMs) have showcased their emergent\ncapability of in-context learning, facilitating intelligent decision-making\nthrough natural language prompts without retraining. This new machine learning\nparadigm has shown promise in various fields, including general control and\noptimization problems. Inspired by these advancements, we explore the potential\nof LLMs for a specific and essential engineering task: parametric shape\noptimization (PSO). We develop an optimization framework, LLM-PSO, that\nleverages an LLM to determine the optimal shape of parameterized engineering\ndesigns in the spirit of evolutionary strategies. Utilizing the ``Claude 3.5\nSonnet'' LLM, we evaluate LLM-PSO on two benchmark flow optimization problems,\nspecifically aiming to identify drag-minimizing profiles for 1) a\ntwo-dimensional airfoil in laminar flow, and 2) a three-dimensional\naxisymmetric body in Stokes flow. In both cases, LLM-PSO successfully\nidentifies optimal shapes in agreement with benchmark solutions. Besides, it\ngenerally converges faster than other classical optimization algorithms. Our\npreliminary exploration may inspire further investigations into harnessing LLMs\nfor shape optimization and engineering design more broadly.",
    "categories": [
      "cs.CE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.08072v1",
    "published_date": "2024-12-11 03:35:38 UTC",
    "updated_date": "2024-12-11 03:35:38 UTC"
  },
  {
    "arxiv_id": "2412.08069v1",
    "title": "DialogAgent: An Auto-engagement Agent for Code Question Answering Data Production",
    "authors": [
      "Xiaoyun Liang",
      "Jingyi Ren",
      "Jiayi Qi",
      "Chao Peng",
      "Bo Jiang"
    ],
    "abstract": "Large Language Models (LLMs) have become increasingly integral to enhancing\ndeveloper productivity, particularly in code generation, comprehension, and\nrepair tasks. However, fine-tuning these models with high-quality, real-world\ndata is challenging due to privacy concerns and the lack of accessible, labeled\ndatasets. In this paper, we present DialogAgent, an automated tool for\ngenerating synthetic training data that closely mimics real developer\ninteractions within Integrated Development Environments (IDEs). DialogAgent\nenables the production of diverse, high-fidelity query-response pairs by\nsimulating multi-turn dialogues and contextual behaviors observed in real-world\nprogramming scenarios. The tool significantly reduces the reliance on manual\ndata generation, increasing efficiency by 4.8 times compared to traditional\nmethods. Our experiments and online deployment demonstrate substantial\nimprovements in model performance for code-related question-answering tasks:\nthe acceptance rate of responses generated by our in-house model is improved by\n33%, after training on synthesized data generated by DialogAgent.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.08069v1",
    "published_date": "2024-12-11 03:31:36 UTC",
    "updated_date": "2024-12-11 03:31:36 UTC"
  },
  {
    "arxiv_id": "2412.08068v1",
    "title": "Repository-Level Graph Representation Learning for Enhanced Security Patch Detection",
    "authors": [
      "Xin-Cheng Wen",
      "Zirui Lin",
      "Cuiyun Gao",
      "Hongyu Zhang",
      "Yong Wang",
      "Qing Liao"
    ],
    "abstract": "Software vendors often silently release security patches without providing\nsufficient advisories (e.g., Common Vulnerabilities and Exposures) or delayed\nupdates via resources (e.g., National Vulnerability Database). Therefore, it\nhas become crucial to detect these security patches to ensure secure software\nmaintenance. However, existing methods face the following challenges: (1) They\nprimarily focus on the information within the patches themselves, overlooking\nthe complex dependencies in the repository. (2) Security patches typically\ninvolve multiple functions and files, increasing the difficulty in well\nlearning the representations. To alleviate the above challenges, this paper\nproposes a Repository-level Security Patch Detection framework named RepoSPD,\nwhich comprises three key components: 1) a repository-level graph construction,\nRepoCPG, which represents software patches by merging pre-patch and post-patch\nsource code at the repository level; 2) a structure-aware patch representation,\nwhich fuses the graph and sequence branch and aims at comprehending the\nrelationship among multiple code changes; 3) progressive learning, which\nfacilitates the model in balancing semantic and structural information. To\nevaluate RepoSPD, we employ two widely-used datasets in security patch\ndetection: SPI-DB and PatchDB. We further extend these datasets to the\nrepository level, incorporating a total of 20,238 and 28,781 versions of\nrepository in C/C++ programming languages, respectively, denoted as SPI-DB* and\nPatchDB*. We compare RepoSPD with six existing security patch detection methods\nand five static tools. Our experimental results demonstrate that RepoSPD\noutperforms the state-of-the-art baseline, with improvements of 11.90%, and\n3.10% in terms of accuracy on the two datasets, respectively.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.SE",
    "comment": "13 pages. This paper is accepted by ICSE 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.08068v1",
    "published_date": "2024-12-11 03:29:56 UTC",
    "updated_date": "2024-12-11 03:29:56 UTC"
  },
  {
    "arxiv_id": "2412.10432v2",
    "title": "Imitate Before Detect: Aligning Machine Stylistic Preference for Machine-Revised Text Detection",
    "authors": [
      "Jiaqi Chen",
      "Xiaoye Zhu",
      "Tianyang Liu",
      "Ying Chen",
      "Xinhui Chen",
      "Yiwen Yuan",
      "Chak Tou Leong",
      "Zuchao Li",
      "Tang Long",
      "Lei Zhang",
      "Chenyu Yan",
      "Guanghao Mei",
      "Jie Zhang",
      "Lefei Zhang"
    ],
    "abstract": "Large Language Models (LLMs) have revolutionized text generation, making\ndetecting machine-generated text increasingly challenging. Although past\nmethods have achieved good performance on detecting pure machine-generated\ntext, those detectors have poor performance on distinguishing machine-revised\ntext (rewriting, expansion, and polishing), which can have only minor changes\nfrom its original human prompt. As the content of text may originate from human\nprompts, detecting machine-revised text often involves identifying distinctive\nmachine styles, e.g., worded favored by LLMs. However, existing methods\nstruggle to detect machine-style phrasing hidden within the content contributed\nby humans. We propose the \"Imitate Before Detect\" (ImBD) approach, which first\nimitates the machine-style token distribution, and then compares the\ndistribution of the text to be tested with the machine-style distribution to\ndetermine whether the text has been machine-revised. To this end, we introduce\nstyle preference optimization (SPO), which aligns a scoring LLM model to the\npreference of text styles generated by machines. The aligned scoring model is\nthen used to calculate the style-conditional probability curvature (Style-CPC),\nquantifying the log probability difference between the original and\nconditionally sampled texts for effective detection. We conduct extensive\ncomparisons across various scenarios, encompassing text revisions by six LLMs,\nfour distinct text domains, and three machine revision types. Compared to\nexisting state-of-the-art methods, our method yields a 13% increase in AUC for\ndetecting text revised by open-source LLMs, and improves performance by 5% and\n19% for detecting GPT-3.5 and GPT-4o revised text, respectively. Notably, our\nmethod surpasses the commercially trained GPT-Zero with just $1,000$ samples\nand five minutes of SPO, demonstrating its efficiency and effectiveness.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.CL",
    "comment": "To appear at AAAI 2025. 14 pages, 6 figure",
    "pdf_url": "http://arxiv.org/pdf/2412.10432v2",
    "published_date": "2024-12-11 03:17:14 UTC",
    "updated_date": "2024-12-22 15:47:50 UTC"
  },
  {
    "arxiv_id": "2412.08063v1",
    "title": "ContextModule: Improving Code Completion via Repository-level Contextual Information",
    "authors": [
      "Zhanming Guan",
      "Junlin Liu",
      "Jierui Liu",
      "Chao Peng",
      "Dexin Liu",
      "Ningyuan Sun",
      "Bo Jiang",
      "Wenchao Li",
      "Jie Liu",
      "Hang Zhu"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated impressive capabilities in\ncode completion tasks, where they assist developers by predicting and\ngenerating new code in real-time. However, existing LLM-based code completion\nsystems primarily rely on the immediate context of the file being edited, often\nmissing valuable repository-level information, user behaviour and edit history\nthat could improve suggestion accuracy. Additionally, challenges such as\nefficiently retrieving relevant code snippets from large repositories,\nincorporating user behavior, and balancing accuracy with low-latency\nrequirements in production environments remain unresolved. In this paper, we\npropose ContextModule, a framework designed to enhance LLM-based code\ncompletion by retrieving and integrating three types of contextual information\nfrom the repository: user behavior-based code, similar code snippets, and\ncritical symbol definitions. By capturing user interactions across files and\nleveraging repository-wide static analysis, ContextModule improves the\nrelevance and precision of generated code. We implement performance\noptimizations, such as index caching, to ensure the system meets the latency\nconstraints of real-world coding environments. Experimental results and\nindustrial practise demonstrate that ContextModule significantly improves code\ncompletion accuracy and user acceptance rates.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.08063v1",
    "published_date": "2024-12-11 03:15:49 UTC",
    "updated_date": "2024-12-11 03:15:49 UTC"
  },
  {
    "arxiv_id": "2412.08061v1",
    "title": "Go-Oracle: Automated Test Oracle for Go Concurrency Bugs",
    "authors": [
      "Foivos Tsimpourlas",
      "Chao Peng",
      "Carlos Rosuero",
      "Ping Yang",
      "Ajitha Rajan"
    ],
    "abstract": "The Go programming language has gained significant traction for developing\nsoftware, especially in various infrastructure systems. Nonetheless,\nconcurrency bugs have become a prevalent issue within Go, presenting a unique\nchallenge due to the language's dual concurrency mechanisms-communicating\nsequential processes and shared memory. Detecting concurrency bugs and\naccurately classifying program executions as pass or fail presents an immense\nchallenge, even for domain experts. We conducted a survey with expert\ndevelopers at Bytedance that confirmed this challenge. Our work seeks to\naddress the test oracle problem for Go programs, to automatically classify test\nexecutions as pass or fail. This problem has not been investigated in the\nliterature for Go programs owing to its distinctive programming model.\n  Our approach involves collecting both passing and failing execution traces\nfrom various subject Go programs. We capture a comprehensive array of execution\nevents using the native Go execution tracer. Subsequently, we preprocess and\nencode these traces before training a transformer-based neural network to\neffectively classify the traces as either passing or failing. The evaluation of\nour approach encompasses 8 subject programs sourced from the GoBench\nrepository. These subject programs are routinely used as benchmarks in an\nindustry setting. Encouragingly, our test oracle, Go-Oracle, demonstrates high\naccuracies even when operating with a limited dataset, showcasing the efficacy\nand potential of our methodology. Developers at Bytedance strongly agreed that\nthey would use the Go-Oracle tool over the current practice of manual\ninspections to classify tests for Go programs as pass or fail.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.08061v1",
    "published_date": "2024-12-11 03:07:56 UTC",
    "updated_date": "2024-12-11 03:07:56 UTC"
  },
  {
    "arxiv_id": "2412.08054v1",
    "title": "Federated In-Context LLM Agent Learning",
    "authors": [
      "Panlong Wu",
      "Kangshuo Li",
      "Junbao Nan",
      "Fangxin Wang"
    ],
    "abstract": "Large Language Models (LLMs) have revolutionized intelligent services by\nenabling logical reasoning, tool use, and interaction with external systems as\nagents. The advancement of LLMs is frequently hindered by the scarcity of\nhigh-quality data, much of which is inherently sensitive. Federated learning\n(FL) offers a potential solution by facilitating the collaborative training of\ndistributed LLMs while safeguarding private data. However, FL frameworks face\nsignificant bandwidth and computational demands, along with challenges from\nheterogeneous data distributions. The emerging in-context learning capability\nof LLMs offers a promising approach by aggregating natural language rather than\nbulky model parameters. Yet, this method risks privacy leakage, as it\nnecessitates the collection and presentation of data samples from various\nclients during aggregation. In this paper, we propose a novel\nprivacy-preserving Federated In-Context LLM Agent Learning (FICAL) algorithm,\nwhich to our best knowledge for the first work unleashes the power of\nin-context learning to train diverse LLM agents through FL. In our design,\nknowledge compendiums generated by a novel LLM-enhanced Knowledge Compendiums\nGeneration (KCG) module are transmitted between clients and the server instead\nof model parameters in previous FL methods. Apart from that, an incredible\nRetrieval Augmented Generation (RAG) based Tool Learning and Utilizing (TLU)\nmodule is designed and we incorporate the aggregated global knowledge\ncompendium as a teacher to teach LLM agents the usage of tools. We conducted\nextensive experiments and the results show that FICAL has competitive\nperformance compared to other SOTA baselines with a significant communication\ncost decrease of $\\mathbf{3.33\\times10^5}$ times.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.08054v1",
    "published_date": "2024-12-11 03:00:24 UTC",
    "updated_date": "2024-12-11 03:00:24 UTC"
  },
  {
    "arxiv_id": "2412.08053v2",
    "title": "DynamicPAE: Generating Scene-Aware Physical Adversarial Examples in Real-Time",
    "authors": [
      "Jin Hu",
      "Xianglong Liu",
      "Jiakai Wang",
      "Junkai Zhang",
      "Xianqi Yang",
      "Haotong Qin",
      "Yuqing Ma",
      "Ke Xu"
    ],
    "abstract": "Physical adversarial examples (PAEs) are regarded as \"whistle-blowers\" of\nreal-world risks in deep-learning applications. However, current PAE generation\nstudies show limited adaptive attacking ability to diverse and varying scenes.\nThe key challenges in generating dynamic PAEs are exploring their patterns\nunder noisy gradient feedback and adapting the attack to agnostic scenario\nnatures. To address the problems, we present DynamicPAE, the first generative\nframework that enables scene-aware real-time physical attacks beyond static\nattacks. Specifically, to train the dynamic PAE generator under noisy gradient\nfeedback, we introduce the residual-driven sample trajectory guidance\ntechnique, which redefines the training task to break the limited feedback\ninformation restriction that leads to the degeneracy problem. Intuitively, it\nallows the gradient feedback to be passed to the generator through a low-noise\nauxiliary task, thereby guiding the optimization away from degenerate solutions\nand facilitating a more comprehensive and stable exploration of feasible PAEs.\nTo adapt the generator to agnostic scenario natures, we introduce the\ncontext-aligned scene expectation simulation process, consisting of the\nconditional-uncertainty-aligned data module and the skewness-aligned objective\nre-weighting module. The former enhances robustness in the context of\nincomplete observation by employing a conditional probabilistic model for\ndomain randomization, while the latter facilitates consistent stealth control\nacross different attack targets by automatically reweighting losses based on\nthe skewness indicator. Extensive digital and physical evaluations demonstrate\nthe superior attack performance of DynamicPAE, attaining a 1.95 $\\times$ boost\n(65.55% average AP drop under attack) on representative object detectors (e.g.,\nYolo-v8) over state-of-the-art static PAE generating methods.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "This work has been submitted to the IEEE for possible publication",
    "pdf_url": "http://arxiv.org/pdf/2412.08053v2",
    "published_date": "2024-12-11 03:00:15 UTC",
    "updated_date": "2024-12-23 02:53:13 UTC"
  },
  {
    "arxiv_id": "2412.12149v2",
    "title": "MHSA: A Multi-scale Hypergraph Network for Mild Cognitive Impairment Detection via Synchronous and Attentive Fusion",
    "authors": [
      "Manman Yuan",
      "Weiming Jia",
      "Xiong Luo",
      "Jiazhen Ye",
      "Peican Zhu",
      "Junlin Li"
    ],
    "abstract": "The precise detection of mild cognitive impairment (MCI) is of significant\nimportance in preventing the deterioration of patients in a timely manner.\nAlthough hypergraphs have enhanced performance by learning and analyzing brain\nnetworks, they often only depend on vector distances between features at a\nsingle scale to infer interactions. In this paper, we deal with a more arduous\nchallenge, hypergraph modelling with synchronization between brain regions, and\ndesign a novel framework, i.e., A Multi-scale Hypergraph Network for MCI\nDetection via Synchronous and Attentive Fusion (MHSA), to tackle this\nchallenge. Specifically, our approach employs the Phase-Locking Value (PLV) to\ncalculate the phase synchronization relationship in the spectrum domain of\nregions of interest (ROIs) and designs a multi-scale feature fusion mechanism\nto integrate dynamic connectivity features of functional magnetic resonance\nimaging (fMRI) from both the temporal and spectrum domains. To evaluate and\noptimize the direct contribution of each ROI to phase synchronization in the\ntemporal domain, we structure the PLV coefficients dynamically adjust strategy,\nand the dynamic hypergraph is modelled based on a comprehensive\ntemporal-spectrum fusion matrix. Experiments on the real-world dataset indicate\nthe effectiveness of our strategy. The code is available at\nhttps://github.com/Jia-Weiming/MHSA.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "The submission was made prematurely and will be resubmitted after\n  further development",
    "pdf_url": "http://arxiv.org/pdf/2412.12149v2",
    "published_date": "2024-12-11 02:59:57 UTC",
    "updated_date": "2025-01-12 02:48:52 UTC"
  },
  {
    "arxiv_id": "2412.08029v1",
    "title": "NeRF-NQA: No-Reference Quality Assessment for Scenes Generated by NeRF and Neural View Synthesis Methods",
    "authors": [
      "Qiang Qu",
      "Hanxue Liang",
      "Xiaoming Chen",
      "Yuk Ying Chung",
      "Yiran Shen"
    ],
    "abstract": "Neural View Synthesis (NVS) has demonstrated efficacy in generating\nhigh-fidelity dense viewpoint videos using a image set with sparse views.\nHowever, existing quality assessment methods like PSNR, SSIM, and LPIPS are not\ntailored for the scenes with dense viewpoints synthesized by NVS and NeRF\nvariants, thus, they often fall short in capturing the perceptual quality,\nincluding spatial and angular aspects of NVS-synthesized scenes. Furthermore,\nthe lack of dense ground truth views makes the full reference quality\nassessment on NVS-synthesized scenes challenging. For instance, datasets such\nas LLFF provide only sparse images, insufficient for complete full-reference\nassessments. To address the issues above, we propose NeRF-NQA, the first\nno-reference quality assessment method for densely-observed scenes synthesized\nfrom the NVS and NeRF variants. NeRF-NQA employs a joint quality assessment\nstrategy, integrating both viewwise and pointwise approaches, to evaluate the\nquality of NVS-generated scenes. The viewwise approach assesses the spatial\nquality of each individual synthesized view and the overall inter-views\nconsistency, while the pointwise approach focuses on the angular qualities of\nscene surface points and their compound inter-point quality. Extensive\nevaluations are conducted to compare NeRF-NQA with 23 mainstream visual quality\nassessment methods (from fields of image, video, and light-field assessment).\nThe results demonstrate NeRF-NQA outperforms the existing assessment methods\nsignificantly and it shows substantial superiority on assessing NVS-synthesized\nscenes without references. An implementation of this paper are available at\nhttps://github.com/VincentQQu/NeRF-NQA.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.HC",
      "cs.MM",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.08029v1",
    "published_date": "2024-12-11 02:17:33 UTC",
    "updated_date": "2024-12-11 02:17:33 UTC"
  },
  {
    "arxiv_id": "2412.08021v2",
    "title": "Can a MISL Fly? Analysis and Ingredients for Mutual Information Skill Learning",
    "authors": [
      "Chongyi Zheng",
      "Jens Tuyls",
      "Joanne Peng",
      "Benjamin Eysenbach"
    ],
    "abstract": "Self-supervised learning has the potential of lifting several of the key\nchallenges in reinforcement learning today, such as exploration, representation\nlearning, and reward design. Recent work (METRA) has effectively argued that\nmoving away from mutual information and instead optimizing a certain\nWasserstein distance is important for good performance. In this paper, we argue\nthat the benefits seen in that paper can largely be explained within the\nexisting framework of mutual information skill learning (MISL). Our analysis\nsuggests a new MISL method (contrastive successor features) that retains the\nexcellent performance of METRA with fewer moving parts, and highlights\nconnections between skill learning, contrastive representation learning, and\nsuccessor features. Finally, through careful ablation studies, we provide\nfurther insight into some of the key ingredients for both our method and METRA.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Code and videos are available on the website:\n  https://princeton-rl.github.io/contrastive-successor-features/",
    "pdf_url": "http://arxiv.org/pdf/2412.08021v2",
    "published_date": "2024-12-11 02:00:39 UTC",
    "updated_date": "2025-03-20 01:53:24 UTC"
  },
  {
    "arxiv_id": "2412.08020v1",
    "title": "Intelligent Control of Robotic X-ray Devices using a Language-promptable Digital Twin",
    "authors": [
      "Benjamin D. Killeen",
      "Anushri Suresh",
      "Catalina Gomez",
      "Blanca Inigo",
      "Christopher Bailey",
      "Mathias Unberath"
    ],
    "abstract": "Natural language offers a convenient, flexible interface for controlling\nrobotic C-arm X-ray systems, making advanced functionality and controls\naccessible. However, enabling language interfaces requires specialized AI\nmodels that interpret X-ray images to create a semantic representation for\nreasoning. The fixed outputs of such AI models limit the functionality of\nlanguage controls. Incorporating flexible, language-aligned AI models prompted\nthrough language enables more versatile interfaces for diverse tasks and\nprocedures. Using a language-aligned foundation model for X-ray image\nsegmentation, our system continually updates a patient digital twin based on\nsparse reconstructions of desired anatomical structures. This supports\nautonomous capabilities such as visualization, patient-specific viewfinding,\nand automatic collimation from novel viewpoints, enabling commands 'Focus in on\nthe lower lumbar vertebrae.' In a cadaver study, users visualized, localized,\nand collimated structures across the torso using verbal commands, achieving 84%\nend-to-end success. Post hoc analysis of randomly oriented images showed our\npatient digital twin could localize 35 commonly requested structures to within\n51.68 mm, enabling localization and isolation from arbitrary orientations. Our\nresults demonstrate how intelligent robotic X-ray systems can incorporate\nphysicians' expressed intent directly. While existing foundation models for\nintra-operative X-ray analysis exhibit failure modes, as they improve, they can\nfacilitate highly flexible, intelligent robotic C-arms.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.08020v1",
    "published_date": "2024-12-11 02:00:25 UTC",
    "updated_date": "2024-12-11 02:00:25 UTC"
  },
  {
    "arxiv_id": "2412.08014v2",
    "title": "MAGIC: Mastering Physical Adversarial Generation in Context through Collaborative LLM Agents",
    "authors": [
      "Yun Xing",
      "Nhat Chung",
      "Jie Zhang",
      "Yue Cao",
      "Ivor Tsang",
      "Yang Liu",
      "Lei Ma",
      "Qing Guo"
    ],
    "abstract": "Physical adversarial attacks in driving scenarios can expose critical\nvulnerabilities in visual perception models. However, developing such attacks\nremains challenging due to diverse real-world environments and the requirement\nfor maintaining visual naturality. Building upon this challenge, we reformulate\nphysical adversarial attacks as a one-shot patch generation problem. Our\napproach generates adversarial patches through a deep generative model that\nconsiders the specific scene context, enabling direct physical deployment in\nmatching environments. The primary challenge lies in simultaneously achieving\ntwo objectives: generating adversarial patches that effectively mislead object\ndetection systems while determining contextually appropriate deployment within\nthe scene. We propose MAGIC (Mastering Physical Adversarial Generation In\nContext), a novel framework powered by multi-modal LLM agents to address these\nchallenges. MAGIC automatically understands scene context and generates\nadversarial patch through the synergistic interaction of language and vision\ncapabilities. In particular, MAGIC orchestrates three specialized LLM agents:\nThe adv-patch generation agent (GAgent) masters the creation of deceptive\npatches through strategic prompt engineering for text-to-image models. The\nadv-patch deployment agent (DAgent) ensures contextual coherence by determining\noptimal deployment strategies based on scene understanding. The\nself-examination agent (EAgent) completes this trilogy by providing critical\noversight and iterative refinement of both processes. We validate our method on\nboth digital and physical levels, i.e., nuImage and manually captured\nreal-world scenes, where both statistical and visual results prove that our\nMAGIC is powerful and effective for attacking widely applied object detection\nsystems, i.e., YOLO and DETR series.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.08014v2",
    "published_date": "2024-12-11 01:41:19 UTC",
    "updated_date": "2025-03-11 07:15:54 UTC"
  },
  {
    "arxiv_id": "2412.10429v1",
    "title": "GPTDrawer: Enhancing Visual Synthesis through ChatGPT",
    "authors": [
      "Kun Li",
      "Xinwei Chen",
      "Tianyou Song",
      "Hansong Zhang",
      "Wenzhe Zhang",
      "Qing Shan"
    ],
    "abstract": "In the burgeoning field of AI-driven image generation, the quest for\nprecision and relevance in response to textual prompts remains paramount. This\npaper introduces GPTDrawer, an innovative pipeline that leverages the\ngenerative prowess of GPT-based models to enhance the visual synthesis process.\nOur methodology employs a novel algorithm that iteratively refines input\nprompts using keyword extraction, semantic analysis, and image-text congruence\nevaluation. By integrating ChatGPT for natural language processing and Stable\nDiffusion for image generation, GPTDrawer produces a batch of images that\nundergo successive refinement cycles, guided by cosine similarity metrics until\na threshold of semantic alignment is attained. The results demonstrate a marked\nimprovement in the fidelity of images generated in accordance with user-defined\nprompts, showcasing the system's ability to interpret and visualize complex\nsemantic constructs. The implications of this work extend to various\napplications, from creative arts to design automation, setting a new benchmark\nfor AI-assisted creative processes.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.10429v1",
    "published_date": "2024-12-11 00:42:44 UTC",
    "updated_date": "2024-12-11 00:42:44 UTC"
  },
  {
    "arxiv_id": "2412.19814v1",
    "title": "Predicting Human Brain States with Transformer",
    "authors": [
      "Yifei Sun",
      "Mariano Cabezas",
      "Jiah Lee",
      "Chenyu Wang",
      "Wei Zhang",
      "Fernando Calamante",
      "Jinglei Lv"
    ],
    "abstract": "The human brain is a complex and highly dynamic system, and our current\nknowledge of its functional mechanism is still very limited. Fortunately, with\nfunctional magnetic resonance imaging (fMRI), we can observe blood oxygen\nlevel-dependent (BOLD) changes, reflecting neural activity, to infer brain\nstates and dynamics. In this paper, we ask the question of whether the brain\nstates rep-resented by the regional brain fMRI can be predicted. Due to the\nsuccess of self-attention and the transformer architecture in sequential\nauto-regression problems (e.g., language modelling or music generation), we\nexplore the possi-bility of the use of transformers to predict human brain\nresting states based on the large-scale high-quality fMRI data from the human\nconnectome project (HCP). Current results have shown that our model can\naccurately predict the brain states up to 5.04s with the previous 21.6s.\nFurthermore, even though the prediction error accumulates for the prediction of\na longer time period, the gen-erated fMRI brain states reflect the architecture\nof functional connectome. These promising initial results demonstrate the\npossibility of developing gen-erative models for fMRI data using self-attention\nthat learns the functional or-ganization of the human brain. Our code is\navailable at: https://github.com/syf0122/brain_state_pred.",
    "categories": [
      "q-bio.NC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.NC",
    "comment": "11 pages, 4 figures, MICCAI MMMI workshop in press",
    "pdf_url": "http://arxiv.org/pdf/2412.19814v1",
    "published_date": "2024-12-11 00:18:39 UTC",
    "updated_date": "2024-12-11 00:18:39 UTC"
  },
  {
    "arxiv_id": "2412.07990v1",
    "title": "Adaptive Querying for Reward Learning from Human Feedback",
    "authors": [
      "Yashwanthi Anand",
      "Sandhya Saisubramanian"
    ],
    "abstract": "Learning from human feedback is a popular approach to train robots to adapt\nto user preferences and improve safety. Existing approaches typically consider\na single querying (interaction) format when seeking human feedback and do not\nleverage multiple modes of user interaction with a robot. We examine how to\nlearn a penalty function associated with unsafe behaviors, such as side\neffects, using multiple forms of human feedback, by optimizing the query state\nand feedback format. Our framework for adaptive feedback selection enables\nquerying for feedback in critical states in the most informative format, while\naccounting for the cost and probability of receiving feedback in a certain\nformat. We employ an iterative, two-phase approach which first selects critical\nstates for querying, and then uses information gain to select a feedback format\nfor querying across the sampled critical states. Our evaluation in simulation\ndemonstrates the sample efficiency of our approach.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.07990v1",
    "published_date": "2024-12-11 00:02:48 UTC",
    "updated_date": "2024-12-11 00:02:48 UTC"
  }
]