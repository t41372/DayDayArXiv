{
  "date": "2024-12-11",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-12-11 的 arXiv 中文 TLDR 快报！今天 arXiv 的论文主要聚焦 AI 领域，包括大型语言模型（LLM）的代码生成、多模态模型的应用、图神经网络（GNNs）和机器人学习等关键话题，令人印象深刻的文章有 Euclid 的多模态视觉描述提升，以及 GPD-1 的自动驾驶预训练；知名学者如 Agnieszka Mensfelt 和 Marco di Renzo 的作品也值得关注，这些论文展示了 AI 在实际应用中的潜力。\n\n下面，我将挑选并简要讨论今天更重要的论文，先从高影响力或热门主题入手（如 LLM、扩散模型和机器人），然后快速掠过其他次要论文。每个条目会列出论文标题（中文 + 英文），并清晰描述主要贡献和发现，保留核心学术术语。\n\n### 重点论文讨论\n\n**1. Efficient Dynamic Attributed Graph Generation（高效动态属性图生成）**  \n这篇论文提出 VRDAG，一种基于变分循环框架的动态属性图生成方法，解决了现有方法在捕获图结构与节点属性共进化、处理有向边和计算效率上的局限。主要贡献：通过双向消息传递和条件变分贝叶斯采样，提高了图生成的速度和准确性，在真实数据集上显著提升了生成质量。IEEE ICDE 2025 接受，作者包括 Fan Li 和 Xuemin Lin，展示了图神经网络在数据管理中的潜力。\n\n**2. GAMA: Generative Agents for Multi-Agent Autoformalization（GAMA：用于多代理自动形式化的生成代理）**  \n作者 Agnieszka Mensfelt 等人开发了一个框架，使用 LLM 和博弈论形式化来自动生成代理交互规则。主要发现：在 110 个自然语言描述上，Claude 3.5 Sonnet 达到 100% 语法正确性和 76.5% 语义正确性，显著提升了多代理模拟的效率和准确性。该论文修订版公开了 GitHub 代码，强调 LLM 在形式化推理中的应用。\n\n**3. Euclid: Supercharging Multimodal LLMs with Synthetic High-Fidelity Visual Descriptions（Euclid：使用合成高保真视觉描述增强多模态 LLM）**  \n这篇论文引入 Geoperception 基准，评估和优化多模态 LLM 在几何感知任务上的性能。主要贡献：通过数据课程和合成数据训练，Euclid 模型在几何任务上比 Gemini-1.5-Pro 高出 58.56%，展示了 LLM 在机器人和医疗图像分析中的潜力。\n\n**4. LLaVA-Zip: Adaptive Visual Token Compression with Intrinsic Image Information（LLaVA-Zip：基于内在图像信息的自适应视觉标记压缩）**  \n论文提出 DFMR 框架，用于压缩视觉标记以处理多图像场景。主要发现：集成到 LLaVA-1.5 中后，提升了模型在资源受限环境下的性能，适用于学术和工业的多模态任务。\n\n**5. GPD-1: Generative Pre-training for Driving（GPD-1：用于自动驾驶的生成预训练）**  \n作者 Shanghang Zhang 等人开发了 GPD-1 模型，用于统一处理地图生成、运动预测和轨迹规划。主要贡献：通过自回归 Transformer 和分层位置编码，实现了多任务自动驾驶预训练，在 nuPlan 数据集上表现出色，代码开源。\n\n**6. Integrating Optimization Theory with Deep Learning for Wireless Network Design（将优化理论与深度学习集成用于无线网络设计）**  \n作者 Marco di Renzo 等人提出了一种混合方法，将优化理论的块图与深度神经网络结合。主要发现：显著降低了运行时间，同时提高了无线网络设计的准确性和收敛率，IEEE Communications Magazine 接受。\n\n**7. Regional Weather Variable Predictions by Machine Learning with Near-Surface Observational and Atmospheric Numerical Data（使用机器学习结合近地表观测和大气数值数据的区域天气变量预测）**  \n论文引入 MiMa 模型，用于精细分辨率天气预测。主要贡献：整合微观和宏观数据，显著提高了预测准确性，尤其在无观测站区域。\n\n**8. Performance of a large language model-Artificial Intelligence based chatbot for counseling patients with sexually transmitted infections and genital diseases（基于 LLM 的 AI 聊天机器人用于性传播感染咨询的性能）**  \n研究 Otiz 聊天机器人，提供准确的 STI 咨询。主要发现：在真实评估中，诊断准确性和移情得分高，但相关性需改进，展示了 LLM 在医疗咨询中的应用潜力。\n\n**9. Unlocking Visual Secrets: Inverting Features with Diffusion Priors for Image Reconstruction（解锁视觉秘密：使用扩散先验反转特征进行图像重建）**  \n论文探索扩散模型在特征反转中的应用，主要贡献：改进了深度神经网络特征的逆向重建，增强了隐私和安全分析。\n\n**10. Proactive Adversarial Defense: Harnessing Prompt Tuning in Vision-Language Models to Detect Unseen Backdoored Images（主动对抗防御：利用提示调整检测 Vision-Language 模型中的未知后门图像）**  \n论文提出一种提示调整方法检测后门图像。主要发现：平均准确率达 86%，在后门防御中树立新标准。\n\n其他论文较多，我会快速掠过不那么核心的：\n- **点云补全和生成（如 PointTalk、Sampling-based Continuous Optimization）**：这些论文改进点云补全算法，但影响较局部，仅提贡献：PointTalk 使用事件数据生成动态唇部点云，提升 3D 高斯建模。\n- **知识图谱和推理（如 In-Context Learning with Topological Information、VEL）**：VEL 开发了形式化 OWL2 EL 推理器，确保输出正确性；其他论文提升了图谱完成，但非主流。\n- **机器人和强化学习（如 TidyBot++、A quantum-classical reinforcement learning model）**：TidyBot++ 设计开源移动机械臂，提升模仿学习；这些工作实用但不革命性。\n- **其他领域（如 Greek2MathTex 的语音到 LaTeX 转换、Coverage-based Fairness 的多文档摘要公平性）**：Greek2MathTex 提供希腊语语音转公式系统；公平性论文评估 LLM 的摘要偏见，但较专业化。\n\n总之，今天的论文突出了 AI 在多领域应用的创新潜力，但也暴露出模型鲁棒性和泛化挑战。更多细节可查阅 arXiv！",
  "papers": [
    {
      "arxiv_id": "2412.10450v2",
      "title": "Regional Weather Variable Predictions by Machine Learning with Near-Surface Observational and Atmospheric Numerical Data",
      "title_zh": "基于机器学习结合近地表观测数据和大气数值数据的区域天气变量预测",
      "authors": [
        "Yihe Zhang",
        "Bryce Turney",
        "Purushottam Sigdel",
        "Xu Yuan",
        "Eric Rappin",
        "Adrian Lago",
        "Sytske Kimball",
        "Li Chen",
        "Paul Darby",
        "Lu Peng",
        "Sercan Aygun",
        "Yazhou Tu",
        "M. Hassan Najafi",
        "Nian-Feng Tzeng"
      ],
      "abstract": "Accurate and timely regional weather prediction is vital for sectors\ndependent on weather-related decisions. Traditional prediction methods, based\non atmospheric equations, often struggle with coarse temporal resolutions and\ninaccuracies. This paper presents a novel machine learning (ML) model, called\nMiMa (short for Micro-Macro), that integrates both near-surface observational\ndata from Kentucky Mesonet stations (collected every five minutes, known as\nMicro data) and hourly atmospheric numerical outputs (termed as Macro data) for\nfine-resolution weather forecasting. The MiMa model employs an encoder-decoder\ntransformer structure, with two encoders for processing multivariate data from\nboth datasets and a decoder for forecasting weather variables over short time\nhorizons. Each instance of the MiMa model, called a modelet, predicts the\nvalues of a specific weather parameter at an individual Mesonet station. The\napproach is extended with Re-MiMa modelets, which are designed to predict\nweather variables at ungauged locations by training on multivariate data from a\nfew representative stations in a region, tagged with their elevations. Re-MiMa\n(short for Regional-MiMa) can provide highly accurate predictions across an\nentire region, even in areas without observational stations. Experimental\nresults show that MiMa significantly outperforms current models, with Re-MiMa\noffering precise short-term forecasts for ungauged locations, marking a\nsignificant advancement in weather forecasting accuracy and applicability.",
      "tldr_zh": "这篇论文提出了一种名为 MiMa 的机器学习模型，用于精确的区域天气预测，通过整合 Kentucky Mesonet 站的近地表观测数据 (Micro data) 和大气数值输出 (Macro data)，采用编码器-解码器 Transformer 结构进行短期天气变量预报。每个 MiMa 实例（modelet）针对特定参数和站点进行预测，而扩展版本 Re-MiMa 则利用少量代表性站点的多变量数据和海拔标签，实现对无观测站区域的高精度预测。实验结果表明，MiMa 显著优于现有模型，Re-MiMa 为区域天气预报的准确性和适用性带来了重大进步。",
      "categories": [
        "physics.ao-ph",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "physics.ao-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.10450v2",
      "published_date": "2024-12-11 23:55:38 UTC",
      "updated_date": "2025-02-10 22:39:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:00:16.262655"
    },
    {
      "arxiv_id": "2412.08810v1",
      "title": "Efficient Dynamic Attributed Graph Generation",
      "title_zh": "高效动态属性图生成",
      "authors": [
        "Fan Li",
        "Xiaoyang Wang",
        "Dawei Cheng",
        "Cong Chen",
        "Ying Zhang",
        "Xuemin Lin"
      ],
      "abstract": "Data generation is a fundamental research problem in data management due to\nits diverse use cases, ranging from testing database engines to data-specific\napplications. However, real-world entities often involve complex interactions\nthat cannot be effectively modeled by traditional tabular data. Therefore,\ngraph data generation has attracted increasing attention recently. Although\nvarious graph generators have been proposed in the literature, there are three\nlimitations: i) They cannot capture the co-evolution pattern of graph structure\nand node attributes. ii) Few of them consider edge direction, leading to\nsubstantial information loss. iii) Current state-of-the-art dynamic graph\ngenerators are based on the temporal random walk, making the simulation process\ntime-consuming. To fill the research gap, we introduce VRDAG, a novel\nvariational recurrent framework for efficient dynamic attributed graph\ngeneration. Specifically, we design a bidirectional message-passing mechanism\nto encode both directed structural knowledge and attribute information of a\nsnapshot. Then, the temporal dependency in the graph sequence is captured by a\nrecurrence state updater, generating embeddings that can preserve the evolution\npattern of early graphs. Based on the hidden node embeddings, a conditional\nvariational Bayesian method is developed to sample latent random variables at\nthe neighboring timestep for new snapshot generation. The proposed generation\nparadigm avoids the time-consuming path sampling and merging process in\nexisting random walk-based methods, significantly reducing the synthesis time.\nFinally, comprehensive experiments on real-world datasets are conducted to\ndemonstrate the effectiveness and efficiency of the proposed model.",
      "tldr_zh": "本研究针对现有图生成方法的局限性（如无法捕获图结构和节点属性的共同演化、忽略边方向以及基于随机游走的低效率），提出了一种新型框架VRDAG（variational recurrent framework），用于高效生成动态属性图。具体来说，VRDAG采用双向消息-passing机制编码有向结构和属性信息，通过循环状态更新器捕获时间依赖性，并利用条件变分贝叶斯方法采样新图快照，从而避免了传统随机游走方法的耗时过程。实验在真实数据集上验证了VRDAG的有效性和效率，显著提升了动态图生成性能。",
      "categories": [
        "cs.DB",
        "cs.AI"
      ],
      "primary_category": "cs.DB",
      "comment": "14 pages,10 figures. Accepted by IEEE ICDE2025",
      "pdf_url": "http://arxiv.org/pdf/2412.08810v1",
      "published_date": "2024-12-11 22:53:27 UTC",
      "updated_date": "2024-12-11 22:53:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:00:28.372019"
    },
    {
      "arxiv_id": "2412.08805v2",
      "title": "GAMA: Generative Agents for Multi-Agent Autoformalization",
      "title_zh": "GAMA：用于多智能体自动形式化的生成代理",
      "authors": [
        "Agnieszka Mensfelt",
        "Kostas Stathis",
        "Vince Trencsenyi"
      ],
      "abstract": "Multi-agent simulations facilitate the exploration of interactions among both\nnatural and artificial agents. However, modelling real-world scenarios and\ndeveloping simulations often requires substantial expertise and effort. To\nstreamline this process, we present a framework that enables the\nautoformalization of interaction scenarios using agents augmented by large\nlanguage models (LLMs) utilising game-theoretic formalisms. The agents\ntranslate natural language descriptions of interactions into executable logic\nprograms that define the rules of each game, ensuring syntactic correctness\nthrough validation by a solver. A tournament simulation then tests the\nfunctionality of the generated game rules and strategies. After the tournament,\nif a ground truth payoff matrix is available, an exact semantic validation is\nperformed. We evaluate our approach on a diverse set of 110 natural language\ndescriptions exemplifying five $2\\times2$ simultaneous-move games, achieving\n100% syntactic and 76.5% semantic correctness in the generated game rules for\nClaude 3.5 Sonnet, and 99.82% syntactic and 77% semantic correctness for\nGPT-4o. Additionally, we demonstrate high semantic correctness in\nautoformalizing gameplay strategies. Overall, the results highlight the\npotential of autoformalization to leverage LLMs in generating formal reasoning\nmodules for decision-making agents.",
      "tldr_zh": "本研究提出 GAMA 框架，利用大型语言模型 (LLMs) 增强的生成代理，实现多代理自动形式化，从而简化真实场景交互的建模过程。框架通过将自然语言描述转化为基于游戏理论形式主义的可执行逻辑程序，并结合语法验证、锦标赛模拟和语义验证，确保生成的游戏规则和策略的准确性。在对 110 个 $2\\times2$ 同时移动游戏描述的评估中，Claude 3.5 Sonnet 达到 100% 语法正确性和 76.5% 语义正确性，而 GPT-4o 达到 99.82% 语法和 77% 语义正确性，突显了 LLMs 在决策代理正式推理模块生成方面的潜力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "This is a revised version of the paper that incorporates feedback\n  from the reviewers of the first version. It includes an improved\n  presentation, enhanced experiments, and additional validation. This version\n  also uses the latest version of the framework, now available at:\n  https://github.com/dicelab-rhul/GAMA",
      "pdf_url": "http://arxiv.org/pdf/2412.08805v2",
      "published_date": "2024-12-11 22:37:45 UTC",
      "updated_date": "2025-02-18 12:06:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:00:41.377848"
    },
    {
      "arxiv_id": "2412.12167v1",
      "title": "Greek2MathTex: A Greek Speech-to-Text Framework for LaTeX Equations Generation",
      "title_zh": "Greek2MathTex：希腊语语音到文本框架，用于 LaTeX",
      "authors": [
        "Evangelia Gkritzali",
        "Panagiotis Kaliosis",
        "Sofia Galanaki",
        "Elisavet Palogiannidi",
        "Theodoros Giannakopoulos"
      ],
      "abstract": "In the vast majority of the academic and scientific domains, LaTeX has\nestablished itself as the de facto standard for typesetting complex\nmathematical equations and formulae. However, LaTeX's complex syntax and\ncode-like appearance present accessibility barriers for individuals with\ndisabilities, as well as those unfamiliar with coding conventions. In this\npaper, we present a novel solution to this challenge through the development of\na novel speech-to-LaTeX equations system specifically designed for the Greek\nlanguage. We propose an end-to-end system that harnesses the power of Automatic\nSpeech Recognition (ASR) and Natural Language Processing (NLP) techniques to\nenable users to verbally dictate mathematical expressions and equations in\nnatural language, which are subsequently converted into LaTeX format. We\npresent the architecture and design principles of our system, highlighting key\ncomponents such as the ASR engine, the LLM-based prompt-driven equations\ngeneration mechanism, as well as the application of a custom evaluation metric\nemployed throughout the development process. We have made our system open\nsource and available at https://github.com/magcil/greek-speech-to-math.",
      "tldr_zh": "该论文提出Greek2MathTex，一种针对希腊语的语音到LaTeX方程生成框架，旨在解决LaTeX复杂语法对残疾人和其他用户造成的访问障碍。系统采用端到端设计，结合Automatic Speech Recognition (ASR)和Natural Language Processing (NLP)技术，让用户用自然语言口述数学表达式，并通过LLM-based提示驱动机制将其转换为LaTeX格式。论文详细描述了系统架构、关键组件（如ASR引擎和自定义评估指标），并开源了代码，供进一步开发和应用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "4 pages, 2 figures, SETN2024: 13th EETN Conference on Artificial\n  Intelligence",
      "pdf_url": "http://arxiv.org/pdf/2412.12167v1",
      "published_date": "2024-12-11 22:29:44 UTC",
      "updated_date": "2024-12-11 22:29:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:00:51.427086"
    },
    {
      "arxiv_id": "2501.06189v1",
      "title": "A Multimodal Social Agent",
      "title_zh": "翻译失败",
      "authors": [
        "Athina Bikaki",
        "Ioannis A. Kakadiaris"
      ],
      "abstract": "In recent years, large language models (LLMs) have demonstrated remarkable\nprogress in common-sense reasoning tasks. This ability is fundamental to\nunderstanding social dynamics, interactions, and communication. However, the\npotential of integrating computers with these social capabilities is still\nrelatively unexplored. However, the potential of integrating computers with\nthese social capabilities is still relatively unexplored. This paper introduces\nMuSA, a multimodal LLM-based agent that analyzes text-rich social content\ntailored to address selected human-centric content analysis tasks, such as\nquestion answering, visual question answering, title generation, and\ncategorization. It uses planning, reasoning, acting, optimizing, criticizing,\nand refining strategies to complete a task. Our approach demonstrates that MuSA\ncan automate and improve social content analysis, helping decision-making\nprocesses across various applications. We have evaluated our agent's\ncapabilities in question answering, title generation, and content\ncategorization tasks. MuSA performs substantially better than our baselines.",
      "tldr_zh": "这篇论文引入了 MuSA，一种基于大型语言模型 (LLMs) 的多模态社会代理，用于分析文本丰富的社交内容，针对任务如问答、视觉问答、标题生成和分类。MuSA 采用规划、推理、行动、优化、批评和精炼策略来完成任务，从而实现自动化社交内容分析。实验结果表明，MuSA 在问答、标题生成和内容分类任务上显著优于基线模型，为决策过程提供更好的支持。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "9 pages",
      "pdf_url": "http://arxiv.org/pdf/2501.06189v1",
      "published_date": "2024-12-11 22:04:27 UTC",
      "updated_date": "2024-12-11 22:04:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:01:03.090291"
    },
    {
      "arxiv_id": "2412.08795v2",
      "title": "Coverage-based Fairness in Multi-document Summarization",
      "title_zh": "翻译失败",
      "authors": [
        "Haoyuan Li",
        "Yusen Zhang",
        "Rui Zhang",
        "Snigdha Chaturvedi"
      ],
      "abstract": "Fairness in multi-document summarization (MDS) measures whether a system can\ngenerate a summary fairly representing information from documents with\ndifferent social attribute values. Fairness in MDS is crucial since a fair\nsummary can offer readers a comprehensive view. Previous works focus on\nquantifying summary-level fairness using Proportional Representation, a\nfairness measure based on Statistical Parity. However, Proportional\nRepresentation does not consider redundancy in input documents and overlooks\ncorpus-level unfairness. In this work, we propose a new summary-level fairness\nmeasure, Equal Coverage, which is based on coverage of documents with different\nsocial attribute values and considers the redundancy within documents. To\ndetect the corpus-level unfairness, we propose a new corpus-level measure,\nCoverage Parity. Our human evaluations show that our measures align more with\nour definition of fairness. Using our measures, we evaluate the fairness of\nthirteen different LLMs. We find that Claude3-sonnet is the fairest among all\nevaluated LLMs. We also find that almost all LLMs overrepresent different\nsocial attribute values. The code is available at\nhttps://github.com/leehaoyuan/coverage_fairness.",
      "tldr_zh": "本研究探讨了多文档摘要（Multi-document Summarization）中的公平性问题，强调摘要应公平代表不同社会属性值的文档，以提供全面视角。论文提出两种新公平度量：摘要级的Equal Coverage（基于不同属性文档的覆盖率，并考虑文档冗余）和语料级的Coverage Parity（用于检测整体不公平）。通过人性化评估，发现这些度量更符合公平定义；评估13个大语言模型（LLMs）后，Claude3-sonnet表现最公平，但几乎所有LLMs都存在过度代表不同社会属性值的现象。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "accepted to NAACL 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.08795v2",
      "published_date": "2024-12-11 22:01:30 UTC",
      "updated_date": "2025-03-25 03:19:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:01:15.827394"
    },
    {
      "arxiv_id": "2412.08771v1",
      "title": "LLaVA-Zip: Adaptive Visual Token Compression with Intrinsic Image Information",
      "title_zh": "翻译失败",
      "authors": [
        "Ke Wang",
        "Hong Xuan"
      ],
      "abstract": "Multi-modal large language models (MLLMs) utilizing instruction-following\ndata, such as LLaVA, have achieved great progress in the industry. A major\nlimitation in these models is that visual tokens consume a substantial portion\nof the maximum token limit in large language models (LLMs), leading to\nincreased computational demands and decreased performance when prompts include\nmultiple images or videos. Industry solutions often mitigate this issue by\nincreasing computational power, but this approach is less feasible in academic\nenvironments with limited resources. In this study, we propose Dynamic Feature\nMap Reduction (DFMR) based on LLaVA-1.5 to address the challenge of visual\ntoken overload. DFMR dynamically compresses the visual tokens, freeing up token\ncapacity. Our experimental results demonstrate that integrating DFMR into\nLLaVA-1.5 significantly improves the performance of LLaVA in varied visual\ntoken lengths, offering a promising solution for extending LLaVA to handle\nmulti-image and video scenarios in resource-constrained academic environments\nand it can also be applied in industry settings for data augmentation to help\nmitigate the scarcity of open-domain image-text pair datasets in the continued\npretraining stage.",
      "tldr_zh": "本研究针对多模态大语言模型 (MLLMs) 如 LLaVA 在处理多个图像或视频时，视觉标记占用大量令牌限制导致的计算需求问题，提出了一种自适应视觉标记压缩方法 LLaVA-Zip。核心机制是 Dynamic Feature Map Reduction (DFMR)，基于 LLaVA-1.5 动态压缩视觉标记，释放令牌容量，从而提升模型在资源受限环境下的性能。实验结果表明，DFMR 显著提高了 LLaVA 处理多图像和视频场景的能力，并可应用于工业设置的数据增强，帮助缓解开源领域图像-文本对数据集的稀缺性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.08771v1",
      "published_date": "2024-12-11 20:46:06 UTC",
      "updated_date": "2024-12-11 20:46:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:01:28.549969"
    },
    {
      "arxiv_id": "2412.12166v1",
      "title": "Performance of a large language model-Artificial Intelligence based chatbot for counseling patients with sexually transmitted infections and genital diseases",
      "title_zh": "翻译失败",
      "authors": [
        "Nikhil Mehta",
        "Sithira Ambepitiya",
        "Thanveer Ahamad",
        "Dinuka Wijesundara",
        "Yudara Kularathne"
      ],
      "abstract": "Introduction: Global burden of sexually transmitted infections (STIs) is\nrising out of proportion to specialists. Current chatbots like ChatGPT are not\ntailored for handling STI-related concerns out of the box. We developed Otiz,\nan Artificial Intelligence-based (AI-based) chatbot platform designed\nspecifically for STI detection and counseling, and assessed its performance.\nMethods: Otiz employs a multi-agent system architecture based on GPT4-0613,\nleveraging large language model (LLM) and Deterministic Finite Automaton\nprinciples to provide contextually relevant, medically accurate, and empathetic\nresponses. Its components include modules for general STI information,\nemotional recognition, Acute Stress Disorder detection, and psychotherapy. A\nquestion suggestion agent operates in parallel. Four STIs (anogenital warts,\nherpes, syphilis, urethritis/cervicitis) and 2 non-STIs (candidiasis, penile\ncancer) were evaluated using prompts mimicking patient language. Each prompt\nwas independently graded by two venereologists conversing with Otiz as patient\nactors on 6 criteria using Numerical Rating Scale ranging from 0 (poor) to 5\n(excellent). Results: Twenty-three venereologists did 60 evaluations of 30\nprompts. Across STIs, Otiz scored highly on diagnostic accuracy (4.1-4.7),\noverall accuracy (4.3-4.6), correctness of information (5.0), comprehensibility\n(4.2-4.4), and empathy (4.5-4.8). However, relevance scores were lower\n(2.9-3.6), suggesting some redundancy. Diagnostic scores for non-STIs were\nlower (p=0.038). Inter-observer agreement was strong, with differences greater\nthan 1 point occurring in only 12.7% of paired evaluations. Conclusions: AI\nconversational agents like Otiz can provide accurate, correct, discrete,\nnon-judgmental, readily accessible and easily understandable STI-related\ninformation in an empathetic manner, and can alleviate the burden on healthcare\nsystems.",
      "tldr_zh": "这篇论文评估了 Otiz，一种基于 Large Language Model (LLM) 和多智能体系统的 AI 聊天机器人，用于为性传播感染 (STIs) 和生殖器疾病患者提供咨询和支持。Otiz 采用 GPT4-0613 架构，结合 Deterministic Finite Automaton 原理，提供准确的诊断信息、情感识别、急性应激障碍检测以及心理治疗模块，并包括一个并行问题建议代理。实验结果显示，Otiz 在诊断准确性（4.1-4.7 分）、信息正确性（5.0 分）和同情心（4.5-4.8 分）上表现优秀，但相关性较低（2.9-3.6 分），且在非 STIs 病例上得分较差（p=0.038）。结论是，AI 聊天机器人如 Otiz 可以以非判断性和易懂的方式缓解医疗系统的负担，提供可访问的 STI 相关信息。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "18 pages, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2412.12166v1",
      "published_date": "2024-12-11 20:36:32 UTC",
      "updated_date": "2024-12-11 20:36:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:01:43.811874"
    },
    {
      "arxiv_id": "2412.08761v1",
      "title": "Integrating Optimization Theory with Deep Learning for Wireless Network Design",
      "title_zh": "将优化理论与深度学习整合用于无线网络设计",
      "authors": [
        "Sinem Coleri",
        "Aysun Gurur Onalan",
        "Marco di Renzo"
      ],
      "abstract": "Traditional wireless network design relies on optimization algorithms derived\nfrom domain-specific mathematical models, which are often inefficient and\nunsuitable for dynamic, real-time applications due to high complexity. Deep\nlearning has emerged as a promising alternative to overcome complexity and\nadaptability concerns, but it faces challenges such as accuracy issues, delays,\nand limited interpretability due to its inherent black-box nature. This paper\nintroduces a novel approach that integrates optimization theory with deep\nlearning methodologies to address these issues. The methodology starts by\nconstructing the block diagram of the optimization theory-based solution,\nidentifying key building blocks corresponding to optimality conditions and\niterative solutions. Selected building blocks are then replaced with deep\nneural networks, enhancing the adaptability and interpretability of the system.\nExtensive simulations show that this hybrid approach not only reduces runtime\ncompared to optimization theory based approaches but also significantly\nimproves accuracy and convergence rates, outperforming pure deep learning\nmodels.",
      "tldr_zh": "这篇论文针对传统无线网络设计的优化算法效率低下且不适于动态实时应用的问题，提出了一种将优化理论与深度学习相结合的创新方法。该方法首先构建优化理论解决方案的块图，识别关键构建块（如最优条件和迭代解决方案），然后用深度神经网络替换选定的构建块，以提升系统的适应性和可解释性。实验结果显示，这种混合方法比纯优化理论方法减少了运行时间，并显著提高了准确性和收敛率，优于纯深度学习模型。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted for publication in IEEE Communications Magazine",
      "pdf_url": "http://arxiv.org/pdf/2412.08761v1",
      "published_date": "2024-12-11 20:27:48 UTC",
      "updated_date": "2024-12-11 20:27:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:01:54.812675"
    },
    {
      "arxiv_id": "2412.10448v1",
      "title": "Unlocking Visual Secrets: Inverting Features with Diffusion Priors for Image Reconstruction",
      "title_zh": "解锁视觉秘密：利用扩散先验反转特征以实现图像重建",
      "authors": [
        "Sai Qian Zhang",
        "Ziyun Li",
        "Chuan Guo",
        "Saeed Mahloujifar",
        "Deeksha Dangwal",
        "Edward Suh",
        "Barbara De Salvo",
        "Chiao Liu"
      ],
      "abstract": "Inverting visual representations within deep neural networks (DNNs) presents\na challenging and important problem in the field of security and privacy for\ndeep learning. The main goal is to invert the features of an unidentified\ntarget image generated by a pre-trained DNN, aiming to reconstruct the original\nimage. Feature inversion holds particular significance in understanding the\nprivacy leakage inherent in contemporary split DNN execution techniques, as\nwell as in various applications based on the extracted DNN features.\n  In this paper, we explore the use of diffusion models, a promising technique\nfor image synthesis, to enhance feature inversion quality. We also investigate\nthe potential of incorporating alternative forms of prior knowledge, such as\ntextual prompts and cross-frame temporal correlations, to further improve the\nquality of inverted features. Our findings reveal that diffusion models can\neffectively leverage hidden information from the DNN features, resulting in\nsuperior reconstruction performance compared to previous methods. This research\noffers valuable insights into how diffusion models can enhance privacy and\nsecurity within applications that are reliant on DNN features.",
      "tldr_zh": "这篇论文探讨了在深度神经网络(DNNs)中反转视觉特征以重建原始图像的问题，旨在解决安全和隐私挑战，特别是针对分割DNN执行中的隐私泄露。作者提出了一种使用扩散模型(diffusion models)的方法，通过整合文本提示(textual prompts)和跨帧时间相关性(cross-frame temporal correlations)等先验知识，提升特征反转的质量。实验结果表明，该方法比现有技术实现了更优的图像重建性能，并为依赖DNN特征的应用提供了增强隐私和安全的宝贵洞见。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.10448v1",
      "published_date": "2024-12-11 20:24:15 UTC",
      "updated_date": "2024-12-11 20:24:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:02:03.656877"
    },
    {
      "arxiv_id": "2412.12165v1",
      "title": "Multimodal Approaches to Fair Image Classification: An Ethical Perspective",
      "title_zh": "翻译失败",
      "authors": [
        "Javon Hickmon"
      ],
      "abstract": "In the rapidly advancing field of artificial intelligence, machine perception\nis becoming paramount to achieving increased performance. Image classification\nsystems are becoming increasingly integral to various applications, ranging\nfrom medical diagnostics to image generation; however, these systems often\nexhibit harmful biases that can lead to unfair and discriminatory outcomes.\nMachine Learning systems that depend on a single data modality, i.e. only\nimages or only text, can exaggerate hidden biases present in the training data,\nif the data is not carefully balanced and filtered. Even so, these models can\nstill harm underrepresented populations when used in improper contexts, such as\nwhen government agencies reinforce racial bias using predictive policing. This\nthesis explores the intersection of technology and ethics in the development of\nfair image classification models. Specifically, I focus on improving fairness\nand methods of using multiple modalities to combat harmful demographic bias.\nIntegrating multimodal approaches, which combine visual data with additional\nmodalities such as text and metadata, allows this work to enhance the fairness\nand accuracy of image classification systems. The study critically examines\nexisting biases in image datasets and classification algorithms, proposes\ninnovative methods for mitigating these biases, and evaluates the ethical\nimplications of deploying such systems in real-world scenarios. Through\ncomprehensive experimentation and analysis, the thesis demonstrates how\nmultimodal techniques can contribute to more equitable and ethical AI\nsolutions, ultimately advocating for responsible AI practices that prioritize\nfairness.",
      "tldr_zh": "本论文从伦理角度探讨多模态方法在图像分类中的应用，旨在解决传统单模态系统（如仅使用图像或文本）可能放大的偏见问题，从而避免在医疗诊断或执法等场景中对弱势群体造成不公。研究提出创新方法，通过整合视觉数据与文本和元数据等模态，提升图像分类的公平性和准确性，并评估这些方法的伦理影响。实验结果表明，多模态技术能有效缓解数据集和算法中的偏见，促进更公正的 AI 实践。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Bachelor's thesis",
      "pdf_url": "http://arxiv.org/pdf/2412.12165v1",
      "published_date": "2024-12-11 19:58:31 UTC",
      "updated_date": "2024-12-11 19:58:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:02:15.679238"
    },
    {
      "arxiv_id": "2412.08755v4",
      "title": "Proactive Adversarial Defense: Harnessing Prompt Tuning in Vision-Language Models to Detect Unseen Backdoored Images",
      "title_zh": "翻译失败",
      "authors": [
        "Kyle Stein",
        "Andrew Arash Mahyari",
        "Guillermo Francia",
        "Eman El-Sheikh"
      ],
      "abstract": "Backdoor attacks pose a critical threat by embedding hidden triggers into\ninputs, causing models to misclassify them into target labels. While extensive\nresearch has focused on mitigating these attacks in object recognition models\nthrough weight fine-tuning, much less attention has been given to detecting\nbackdoored samples directly. Given the vast datasets used in training, manual\ninspection for backdoor triggers is impractical, and even state-of-the-art\ndefense mechanisms fail to fully neutralize their impact. To address this gap,\nwe introduce a groundbreaking method to detect unseen backdoored images during\nboth training and inference. Leveraging the transformative success of prompt\ntuning in Vision Language Models (VLMs), our approach trains learnable text\nprompts to differentiate clean images from those with hidden backdoor triggers.\nExperiments demonstrate the exceptional efficacy of this method, achieving an\nimpressive average accuracy of 86% across two renowned datasets for detecting\nunseen backdoor triggers, establishing a new standard in backdoor defense.",
      "tldr_zh": "该研究针对后门攻击（backdoor attacks）提出了一种主动防御方法，利用 Vision-Language Models (VLMs) 中的提示微调（prompt tuning）来训练可学习的文本提示，从而在训练和推理阶段检测未见过的后门图像。不同于传统的权重微调方法，该方法专注于区分干净图像与带有隐藏触发器的图像，避免了手动检查的低效。实验结果显示，在两个知名数据集上，该方法平均准确率达到86%，为后门防御领域设定了新标准。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CR",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.08755v4",
      "published_date": "2024-12-11 19:54:14 UTC",
      "updated_date": "2025-04-07 18:01:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:03:34.759717"
    },
    {
      "arxiv_id": "2412.08751v1",
      "title": "Sampling-based Continuous Optimization with Coupled Variables for RNA Design",
      "title_zh": "翻译失败",
      "authors": [
        "Wei Yu Tang",
        "Ning Dai",
        "Tianshuo Zhou",
        "David H. Mathews",
        "Liang Huang"
      ],
      "abstract": "The task of RNA design given a target structure aims to find a sequence that\ncan fold into that structure. It is a computationally hard problem where some\nversion(s) have been proven to be NP-hard. As a result, heuristic methods such\nas local search have been popular for this task, but by only exploring a fixed\nnumber of candidates. They can not keep up with the exponential growth of the\ndesign space, and often perform poorly on longer and harder-to-design\nstructures. We instead formulate these discrete problems as continuous\noptimization, which starts with a distribution over all possible candidate\nsequences, and uses gradient descent to improve the expectation of an objective\nfunction. We define novel distributions based on coupled variables to rule out\ninvalid sequences given the target structure and to model the correlation\nbetween nucleotides. To make it universally applicable to any objective\nfunction, we use sampling to approximate the expected objective function, to\nestimate the gradient, and to select the final candidate. Compared to the\nstate-of-the-art methods, our work consistently outperforms them in key metrics\nsuch as Boltzmann probability, ensemble defect, and energy gap, especially on\nlong and hard-to-design puzzles in the Eterna100 benchmark. Our code is\navailable at: http://github.com/weiyutang1010/ncrna_design.",
      "tldr_zh": "该论文针对RNA设计问题（给定目标结构寻找能折叠成该结构的序列），提出了一种基于采样(sampling-based)的连续优化方法，以解决传统启发式方法（如局部搜索）在长序列上的表现不足问题。作者将离散问题转化为连续优化框架，通过定义基于coupled variables的新分布来排除无效序列并建模核苷酸之间的相关性，并使用gradient descent和sampling来近似期望目标函数、估计梯度并选择最佳候选。实验结果显示，该方法在Eterna100基准测试中，尤其在长且难设计的谜题上，在Boltzmann probability、ensemble defect和energy gap等关键指标上 consistently outperform 现有最先进方法。",
      "categories": [
        "q-bio.BM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.BM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.08751v1",
      "published_date": "2024-12-11 19:46:54 UTC",
      "updated_date": "2024-12-11 19:46:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:02:40.408361"
    },
    {
      "arxiv_id": "2412.08742v1",
      "title": "In-Context Learning with Topological Information for Knowledge Graph Completion",
      "title_zh": "翻译失败",
      "authors": [
        "Udari Madhushani Sehwag",
        "Kassiani Papasotiriou",
        "Jared Vann",
        "Sumitra Ganesh"
      ],
      "abstract": "Knowledge graphs (KGs) are crucial for representing and reasoning over\nstructured information, supporting a wide range of applications such as\ninformation retrieval, question answering, and decision-making. However, their\neffectiveness is often hindered by incompleteness, limiting their potential for\nreal-world impact. While knowledge graph completion (KGC) has been extensively\nstudied in the literature, recent advances in generative AI models,\nparticularly large language models (LLMs), have introduced new opportunities\nfor innovation. In-context learning has recently emerged as a promising\napproach for leveraging pretrained knowledge of LLMs across a range of natural\nlanguage processing tasks and has been widely adopted in both academia and\nindustry. However, how to utilize in-context learning for effective KGC remains\nrelatively underexplored. We develop a novel method that incorporates\ntopological information through in-context learning to enhance KGC performance.\nBy integrating ontological knowledge and graph structure into the context of\nLLMs, our approach achieves strong performance in the transductive setting\ni.e., nodes in the test graph dataset are present in the training graph\ndataset. Furthermore, we apply our approach to KGC in the more challenging\ninductive setting, i.e., nodes in the training graph dataset and test graph\ndataset are disjoint, leveraging the ontology to infer useful information about\nmissing nodes which serve as contextual cues for the LLM during inference. Our\nmethod demonstrates superior performance compared to baselines on the\nILPC-small and ILPC-large datasets.",
      "tldr_zh": "本文提出了一种结合拓扑信息（Topological Information）的 In-Context Learning 方法，用于提升知识图谱补全（KGC）的性能。该方法通过将本体知识（Ontological Knowledge）和图结构整合到大语言模型（LLMs）的上下文中，实现对训练和测试图节点的有效处理，在 Transductive Setting（测试节点在训练集中存在）中表现出色，并在更具挑战性的 Inductive Setting（训练和测试节点不相交）中利用本体推断缺失信息作为上下文提示。在 ILPC-small 和 ILPC-large 数据集上，该方法比基线模型取得了优越的性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "68T37 (Primary), 68T05, 68P20 (Secondary)"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.08742v1",
      "published_date": "2024-12-11 19:29:36 UTC",
      "updated_date": "2024-12-11 19:29:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:02:53.100311"
    },
    {
      "arxiv_id": "2412.08739v1",
      "title": "VEL: A Formally Verified Reasoner for OWL2 EL Profile",
      "title_zh": "翻译失败",
      "authors": [
        "Atalay Mert Ileri",
        "Nalen Rangarajan",
        "Jack Cannell",
        "Hande McGinty"
      ],
      "abstract": "Over the past two decades, the Web Ontology Language (OWL) has been\ninstrumental in advancing the development of ontologies and knowledge graphs,\nproviding a structured framework that enhances the semantic integration of\ndata. However, the reliability of deductive reasoning within these systems\nremains challenging, as evidenced by inconsistencies among popular reasoners in\nrecent competitions. This evidence underscores the limitations of current\ntesting-based methodologies, particularly in high-stakes domains such as\nhealthcare. To mitigate these issues, in this paper, we have developed VEL, a\nformally verified EL++ reasoner equipped with machine-checkable correctness\nproofs that ensure the validity of outputs across all possible inputs. This\nformalization, based on the algorithm of Baader et al., has been transformed\ninto executable OCaml code using the Coq proof assistant's extraction\ncapabilities. Our formalization revealed several errors in the original\ncompleteness proofs, which led to changes to the algorithm to ensure its\ncompleteness. Our work demonstrates the necessity of mechanization of reasoning\nalgorithms to ensure their correctness at theoretical and implementation\nlevels.",
      "tldr_zh": "本文开发了VEL，一种针对OWL2 EL Profile的正式验证推理器，使用Coq证明助手对基于Baader et al.算法的形式化进行机器可检查的正确性证明，并提取到可执行的OCaml代码中。研究过程中发现并修正了原算法完整性证明中的错误，确保推理器在所有输入下输出有效。该工作突显了机械化推理算法的必要性，尤其在高风险领域如医疗中，提升了OWL系统的可靠性和一致性。",
      "categories": [
        "cs.LO",
        "cs.AI",
        "cs.PL"
      ],
      "primary_category": "cs.LO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.08739v1",
      "published_date": "2024-12-11 19:17:28 UTC",
      "updated_date": "2024-12-11 19:17:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:03:04.476846"
    },
    {
      "arxiv_id": "2412.12164v2",
      "title": "GAMED: Knowledge Adaptive Multi-Experts Decoupling for Multimodal Fake News Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Lingzhi Shen",
        "Yunfei Long",
        "Xiaohao Cai",
        "Imran Razzak",
        "Guanming Chen",
        "Kang Liu",
        "Shoaib Jameel"
      ],
      "abstract": "Multimodal fake news detection often involves modelling heterogeneous data\nsources, such as vision and language. Existing detection methods typically rely\non fusion effectiveness and cross-modal consistency to model the content,\ncomplicating understanding how each modality affects prediction accuracy.\nAdditionally, these methods are primarily based on static feature modelling,\nmaking it difficult to adapt to the dynamic changes and relationships between\ndifferent data modalities. This paper develops a significantly novel approach,\nGAMED, for multimodal modelling, which focuses on generating distinctive and\ndiscriminative features through modal decoupling to enhance cross-modal\nsynergies, thereby optimizing overall performance in the detection process.\nGAMED leverages multiple parallel expert networks to refine features and\npre-embed semantic knowledge to improve the experts' ability in information\nselection and viewpoint sharing. Subsequently, the feature distribution of each\nmodality is adaptively adjusted based on the respective experts' opinions.\nGAMED also introduces a novel classification technique to dynamically manage\ncontributions from different modalities, while improving the explainability of\ndecisions. Experimental results on the Fakeddit and Yang datasets demonstrate\nthat GAMED performs better than recently developed state-of-the-art models. The\nsource code can be accessed at https://github.com/slz0925/GAMED.",
      "tldr_zh": "该论文提出了一种名为 GAMED 的新方法，用于多模态假新闻检测，通过知识自适应多专家解耦（Knowledge Adaptive Multi-Experts Decoupling）来处理视觉和语言等异构数据源的问题。GAMED 通过模态解耦生成独特且区分性的特征，增强跨模态协同，并利用多个并行专家网络结合预嵌入语义知识，提高信息选择和观点共享的能力，同时自适应调整每个模态的特征分布。论文还引入了一种动态分类技术来管理不同模态的贡献，提升决策的可解释性。实验结果显示，在 Fakeddit 和 Yang 数据集上，GAMED 优于现有的最先进模型，证明了其有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.12164v2",
      "published_date": "2024-12-11 19:12:22 UTC",
      "updated_date": "2025-03-02 15:12:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:03:16.419130"
    },
    {
      "arxiv_id": "2412.08737v1",
      "title": "Euclid: Supercharging Multimodal LLMs with Synthetic High-Fidelity Visual Descriptions",
      "title_zh": "翻译失败",
      "authors": [
        "Jiarui Zhang",
        "Ollie Liu",
        "Tianyu Yu",
        "Jinyi Hu",
        "Willie Neiswanger"
      ],
      "abstract": "Multimodal large language models (MLLMs) have made rapid progress in recent\nyears, yet continue to struggle with low-level visual perception (LLVP) --\nparticularly the ability to accurately describe the geometric details of an\nimage. This capability is crucial for applications in areas such as robotics,\nmedical image analysis, and manufacturing. In this paper, we first introduce\nGeoperception, a benchmark designed to evaluate an MLLM's ability to accurately\ntranscribe 2D geometric information from an image. Using this benchmark, we\ndemonstrate the limitations of leading MLLMs, and then conduct a comprehensive\nempirical study to explore strategies for improving their performance on\ngeometric tasks. Our findings highlight the benefits of certain model\narchitectures, training techniques, and data strategies, including the use of\nhigh-fidelity synthetic data and multi-stage training with a data curriculum.\nNotably, we find that a data curriculum enables models to learn challenging\ngeometry understanding tasks which they fail to learn from scratch. Leveraging\nthese insights, we develop Euclid, a family of models specifically optimized\nfor strong low-level geometric perception. Although purely trained on synthetic\nmultimodal data, Euclid shows strong generalization ability to novel geometry\nshapes. For instance, Euclid outperforms the best closed-source model,\nGemini-1.5-Pro, by up to 58.56% on certain Geoperception benchmark tasks and\n10.65% on average across all tasks.",
      "tldr_zh": "这项研究针对Multimodal large language models (MLLMs)在低级视觉感知(LLVP)方面的不足，特别是准确描述图像几何细节的问题，引入了Geoperception基准来评估MLLMs转录2D几何信息的能力。研究通过实证分析探索了改进策略，包括优化模型架构、训练技巧和数据方法，如使用高保真合成数据以及多阶段训练和数据课程，以帮助模型掌握复杂几何任务。最终，开发的Euclid模型系列虽仅基于合成多模态数据训练，却展现出强大的泛化能力，在Geoperception基准上平均超出顶尖闭源模型Gemini-1.5-Pro 10.65%，某些任务甚至高出58.56%。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "33 pages, 22 figures, 5 tables, 7 algorithms",
      "pdf_url": "http://arxiv.org/pdf/2412.08737v1",
      "published_date": "2024-12-11 19:12:13 UTC",
      "updated_date": "2024-12-11 19:12:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:03:29.054919"
    },
    {
      "arxiv_id": "2412.08731v1",
      "title": "From MLP to NeoMLP: Leveraging Self-Attention for Neural Fields",
      "title_zh": "翻译失败",
      "authors": [
        "Miltiadis Kofinas",
        "Samuele Papa",
        "Efstratios Gavves"
      ],
      "abstract": "Neural fields (NeFs) have recently emerged as a state-of-the-art method for\nencoding spatio-temporal signals of various modalities. Despite the success of\nNeFs in reconstructing individual signals, their use as representations in\ndownstream tasks, such as classification or segmentation, is hindered by the\ncomplexity of the parameter space and its underlying symmetries, in addition to\nthe lack of powerful and scalable conditioning mechanisms. In this work, we\ndraw inspiration from the principles of connectionism to design a new\narchitecture based on MLPs, which we term NeoMLP. We start from an MLP, viewed\nas a graph, and transform it from a multi-partite graph to a complete graph of\ninput, hidden, and output nodes, equipped with high-dimensional features. We\nperform message passing on this graph and employ weight-sharing via\nself-attention among all the nodes. NeoMLP has a built-in mechanism for\nconditioning through the hidden and output nodes, which function as a set of\nlatent codes, and as such, NeoMLP can be used straightforwardly as a\nconditional neural field. We demonstrate the effectiveness of our method by\nfitting high-resolution signals, including multi-modal audio-visual data.\nFurthermore, we fit datasets of neural representations, by learning\ninstance-specific sets of latent codes using a single backbone architecture,\nand then use them for downstream tasks, outperforming recent state-of-the-art\nmethods. The source code is open-sourced at https://github.com/mkofinas/neomlp.",
      "tldr_zh": "神经场 (NeFs) 在编码时空信号方面表现出色，但应用于下游任务如分类或分割时，面临参数空间复杂性、对称性问题以及缺乏可扩展的条件机制。作者提出 NeoMLP 架构，将传统的 MLP 视为图结构，从多部分图转换为完全图，并在输入、隐藏和输出节点上进行消息传递 (Message Passing)，并通过自注意力 (Self-Attention) 实现权重共享。NeoMLP 内置条件机制，使用隐藏和输出节点作为潜在代码，支持条件神经场应用，并在实验中成功拟合高分辨率多模态音频-视觉数据，并优于现有方法在下游任务中的表现。开源代码可从指定仓库获取。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Preprint. Source code: https://github.com/mkofinas/neomlp",
      "pdf_url": "http://arxiv.org/pdf/2412.08731v1",
      "published_date": "2024-12-11 19:01:38 UTC",
      "updated_date": "2024-12-11 19:01:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:03:42.291953"
    },
    {
      "arxiv_id": "2412.08725v1",
      "title": "A quantum-classical reinforcement learning model to play Atari games",
      "title_zh": "翻译失败",
      "authors": [
        "Dominik Freinberger",
        "Julian Lemmel",
        "Radu Grosu",
        "Sofiene Jerbi"
      ],
      "abstract": "Recent advances in reinforcement learning have demonstrated the potential of\nquantum learning models based on parametrized quantum circuits as an\nalternative to deep learning models. On the one hand, these findings have shown\nthe ultimate exponential speed-ups in learning that full-blown quantum models\ncan offer in certain -- artificially constructed -- environments. On the other\nhand, they have demonstrated the ability of experimentally accessible PQCs to\nsolve OpenAI Gym benchmarking tasks. However, it remains an open question\nwhether these near-term QRL techniques can be successfully applied to more\ncomplex problems exhibiting high-dimensional observation spaces. In this work,\nwe bridge this gap and present a hybrid model combining a PQC with classical\nfeature encoding and post-processing layers that is capable of tackling Atari\ngames. A classical model, subjected to architectural restrictions similar to\nthose present in the hybrid model is constructed to serve as a reference. Our\nnumerical investigation demonstrates that the proposed hybrid model is capable\nof solving the Pong environment and achieving scores comparable to the\nclassical reference in Breakout. Furthermore, our findings shed light on\nimportant hyperparameter settings and design choices that impact the interplay\nof the quantum and classical components. This work contributes to the\nunderstanding of near-term quantum learning models and makes an important step\ntowards their deployment in real-world RL scenarios.",
      "tldr_zh": "本文提出了一种量子-经典混合强化学习模型，结合参数化量子电路（PQCs）与经典特征编码和后处理层，用于处理高维观察空间的Atari游戏任务。相比传统模型，该方法在Pong环境中表现出色，并在Breakout游戏中达到与类似架构的经典参考模型相当的分数。研究还探讨了关键超参数设置和设计选择，以优化量子和经典组件的互动。总体而言，此工作增强了对近中期量子学习模型的理解，并为其在真实世界强化学习（RL）场景中的部署铺平道路。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "quant-ph",
      "comment": "10 + 13 pages",
      "pdf_url": "http://arxiv.org/pdf/2412.08725v1",
      "published_date": "2024-12-11 19:00:09 UTC",
      "updated_date": "2024-12-11 19:00:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:03:54.054539"
    },
    {
      "arxiv_id": "2412.08643v1",
      "title": "GPD-1: Generative Pre-training for Driving",
      "title_zh": "翻译失败",
      "authors": [
        "Zixun Xie",
        "Sicheng Zuo",
        "Wenzhao Zheng",
        "Yunpeng Zhang",
        "Dalong Du",
        "Jie Zhou",
        "Jiwen Lu",
        "Shanghang Zhang"
      ],
      "abstract": "Modeling the evolutions of driving scenarios is important for the evaluation\nand decision-making of autonomous driving systems. Most existing methods focus\non one aspect of scene evolution such as map generation, motion prediction, and\ntrajectory planning. In this paper, we propose a unified Generative\nPre-training for Driving (GPD-1) model to accomplish all these tasks altogether\nwithout additional fine-tuning. We represent each scene with ego, agent, and\nmap tokens and formulate autonomous driving as a unified token generation\nproblem. We adopt the autoregressive transformer architecture and use a\nscene-level attention mask to enable intra-scene bi-directional interactions.\nFor the ego and agent tokens, we propose a hierarchical positional tokenizer to\neffectively encode both 2D positions and headings. For the map tokens, we train\na map vector-quantized autoencoder to efficiently compress ego-centric semantic\nmaps into discrete tokens. We pre-train our GPD-1 on the large-scale nuPlan\ndataset and conduct extensive experiments to evaluate its effectiveness. With\ndifferent prompts, our GPD-1 successfully generalizes to various tasks without\nfinetuning, including scene generation, traffic simulation, closed-loop\nsimulation, map prediction, and motion planning. Code:\nhttps://github.com/wzzheng/GPD.",
      "tldr_zh": "本文提出GPD-1模型，一个统一的生成式预训练框架，用于自动驾驶场景的演化建模，能够同时处理地图生成、运动预测和轨迹规划等任务，而无需额外微调。模型通过ego、agent和map tokens表示场景，采用自回归Transformer架构、场景级注意力掩码、分层位置标记化器（用于编码2D位置和航向）以及地图向量量化自编码器（用于压缩语义地图成离散tokens）。在nuPlan数据集上预训练后，实验显示GPD-1成功泛化到场景生成、交通模拟、闭环模拟、地图预测和运动规划任务，展示了其高效性和通用性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "Code is available at: https://github.com/wzzheng/GPD",
      "pdf_url": "http://arxiv.org/pdf/2412.08643v1",
      "published_date": "2024-12-11 18:59:51 UTC",
      "updated_date": "2024-12-11 18:59:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:04:06.389995"
    },
    {
      "arxiv_id": "2412.08637v3",
      "title": "DMin: Scalable Training Data Influence Estimation for Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Huawei Lin",
        "Yingjie Lao",
        "Weijie Zhao"
      ],
      "abstract": "Identifying the training data samples that most influence a generated image\nis a critical task in understanding diffusion models (DMs), yet existing\ninfluence estimation methods are constrained to small-scale or LoRA-tuned\nmodels due to computational limitations. To address this challenge, we propose\nDMin (Diffusion Model influence), a scalable framework for estimating the\ninfluence of each training data sample on a given generated image. To the best\nof our knowledge, it is the first method capable of influence estimation for\nDMs with billions of parameters. Leveraging efficient gradient compression,\nDMin reduces storage requirements from hundreds of TBs to mere MBs or even KBs,\nand retrieves the top-k most influential training samples in under 1 second,\nall while maintaining performance. Our empirical results demonstrate DMin is\nboth effective in identifying influential training samples and efficient in\nterms of computational and storage requirements.",
      "tldr_zh": "这篇论文提出了 DMin，一种可扩展的框架，用于估计扩散模型（DMs）中每个训练数据样本对生成图像的影响，解决了现有方法受限于小规模或 LoRA-tuned 模型的计算限制问题。DMin 通过高效梯度压缩技术，将存储需求从数百 TB 减少到 MB 或 KB，并在不到 1 秒内检索 top-k 最有影响的训练样本，同时保持性能。实验结果证明，DMin 在识别影响样本方面有效，且显著提升了计算和存储效率。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "14 pages, 6 figures, 8 tables. Under Review",
      "pdf_url": "http://arxiv.org/pdf/2412.08637v3",
      "published_date": "2024-12-11 18:58:40 UTC",
      "updated_date": "2025-03-11 03:10:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:04:18.931218"
    },
    {
      "arxiv_id": "2412.10447v1",
      "title": "TidyBot++: An Open-Source Holonomic Mobile Manipulator for Robot Learning",
      "title_zh": "Tidy",
      "authors": [
        "Jimmy Wu",
        "William Chong",
        "Robert Holmberg",
        "Aaditya Prasad",
        "Yihuai Gao",
        "Oussama Khatib",
        "Shuran Song",
        "Szymon Rusinkiewicz",
        "Jeannette Bohg"
      ],
      "abstract": "Exploiting the promise of recent advances in imitation learning for mobile\nmanipulation will require the collection of large numbers of human-guided\ndemonstrations. This paper proposes an open-source design for an inexpensive,\nrobust, and flexible mobile manipulator that can support arbitrary arms,\nenabling a wide range of real-world household mobile manipulation tasks.\nCrucially, our design uses powered casters to enable the mobile base to be\nfully holonomic, able to control all planar degrees of freedom independently\nand simultaneously. This feature makes the base more maneuverable and\nsimplifies many mobile manipulation tasks, eliminating the kinematic\nconstraints that create complex and time-consuming motions in nonholonomic\nbases. We equip our robot with an intuitive mobile phone teleoperation\ninterface to enable easy data acquisition for imitation learning. In our\nexperiments, we use this interface to collect data and show that the resulting\nlearned policies can successfully perform a variety of common household mobile\nmanipulation tasks.",
      "tldr_zh": "该论文介绍了TidyBot++，一个开源的holonomic mobile manipulator，用于支持机器人学习中的imitation learning数据收集。该设计采用动力脚轮，使移动底盘能够独立同时控制所有平面自由度，从而提高机动性和简化复杂任务。机器人配备直观的手机遥控界面，便于人类指导演示数据的获取；实验结果显示，基于收集的数据，机器人成功执行了各种家庭移动操作任务。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Conference on Robot Learning (CoRL), 2024. Project page:\n  https://tidybot2.github.io",
      "pdf_url": "http://arxiv.org/pdf/2412.10447v1",
      "published_date": "2024-12-11 18:54:22 UTC",
      "updated_date": "2024-12-11 18:54:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:04:34.190690"
    },
    {
      "arxiv_id": "2412.12163v1",
      "title": "Towards LLM-based optimization compilers. Can LLMs learn how to apply a single peephole optimization? Reasoning is all LLMs need!",
      "title_zh": "翻译失败",
      "authors": [
        "Xiangxin Fang",
        "Lev Mukhanov"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated great potential in various\nlanguage processing tasks, and recent studies have explored their application\nin compiler optimizations. However, all these studies focus on the conventional\nopen-source LLMs, such as Llama2, which lack enhanced reasoning mechanisms. In\nthis study, we investigate the errors produced by the fine-tuned 7B-parameter\nLlama2 model as it attempts to learn and apply a simple peephole optimization\nfor the AArch64 assembly code. We provide an analysis of the errors produced by\nthe LLM and compare it with state-of-the-art OpenAI models which implement\nadvanced reasoning logic, including GPT-4o and GPT-o1 (preview). We demonstrate\nthat OpenAI GPT-o1, despite not being fine-tuned, outperforms the fine-tuned\nLlama2 and GPT-4o. Our findings indicate that this advantage is largely due to\nthe chain-of-thought reasoning implemented in GPT-o1. We hope our work will\ninspire further research on using LLMs with enhanced reasoning mechanisms and\nchain-of-thought for code generation and optimization.",
      "tldr_zh": "本研究探讨大型语言模型（LLMs）在编译器优化中的应用，焦点是LLMs是否能学习并应用一个简单的peephole optimization。研究者分析了fine-tuned的7B-parameter Llama2模型的错误，并与OpenAI的GPT-4o和GPT-o1进行比较，结果显示GPT-o1在未fine-tune的情况下表现出色，主要得益于其chain-of-thought reasoning机制。总体发现表明，增强推理能力是LLMs在代码生成和优化中取得进展的关键，希望此工作激发更多相关研究。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.PL"
      ],
      "primary_category": "cs.LG",
      "comment": "13 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.12163v1",
      "published_date": "2024-12-11 18:44:31 UTC",
      "updated_date": "2024-12-11 18:44:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:04:43.608625"
    },
    {
      "arxiv_id": "2412.08619v2",
      "title": "Physics Context Builders: A Modular Framework for Physical Reasoning in Vision-Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Vahid Balazadeh",
        "Mohammadmehdi Ataei",
        "Hyunmin Cheong",
        "Amir Hosein Khasahmadi",
        "Rahul G. Krishnan"
      ],
      "abstract": "Physical reasoning, which involves interpreting object behaviors within\ndynamic environments, remains a significant challenge for Vision-Language\nModels (VLMs). The limitations in physical reasoning arise from an inability to\ntranslate learned knowledge into predictions about physical behavior. We\nperform a careful study to show how continual fine-tuning can mitigate this\nissue. However, fine-tuning is expensive for large models and impractical to\nrepeatedly perform for every task. This necessitates the creation of modular\nand scalable ways to teach VLMs about physical reasoning. To that end, we\nintroduce Physics Context Builders (PCBs), a novel modular framework where\nspecialized VLMs are fine-tuned to generate detailed physical scene\ndescriptions. These can be used as physical contexts for larger VLMs to enhance\ntheir reasoning capabilities. PCBs enable the separation of visual perception\nfrom reasoning, allowing us to analyze their relative contributions to physical\nunderstanding. We perform careful experiments on CLEVRER and on Falling Tower,\na stability detection dataset with both simulated and real-world scenes, to\ndemonstrate that PCBs provide substantial performance improvements, increasing\naverage accuracy by up to 13.8% on complex physical reasoning tasks. Notably,\nPCBs show strong Sim2Real transfer, successfully generalizing from simulated\ntraining data to real-world scenes. Our work demonstrates that enhancing visual\nperception through modular, simulation-trained components offers a practical\napproach to improving physical reasoning in VLMs, while providing insights into\nthe factors affecting physical understanding in these models.",
      "tldr_zh": "本文研究了 Vision-Language Models (VLMs) 在物理推理中的挑战，即难以将学到的知识转化为对动态环境物体行为的预测，并提出 Physics Context Builders (PCBs) 作为一种模块化框架。PCBs 通过微调专门的 VLMs 生成详细的物理场景描述，作为增强更大 VLMs 推理能力的上下文，同时分离视觉感知和推理过程以分析其贡献。在 CLEVRER 和 Falling Tower 数据集上的实验显示，PCBs 显著提高了性能，平均准确率提升多达 13.8%，并展示了从模拟到真实场景的 Sim2Real 转移能力。该框架为提升 VLMs 的物理理解提供了实用、可扩展的方法，并揭示了影响物理推理的关键因素。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.08619v2",
      "published_date": "2024-12-11 18:40:16 UTC",
      "updated_date": "2025-03-10 17:01:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:04:57.320141"
    },
    {
      "arxiv_id": "2412.08618v1",
      "title": "Image Retrieval Methods in the Dissimilarity Space",
      "title_zh": "差异空间中的图像检索方法",
      "authors": [
        "Madhu Kiran",
        "Kartikey Vishnu",
        "Rafael M. O. Cruz",
        "Eric Granger"
      ],
      "abstract": "Image retrieval methods rely on metric learning to train backbone feature\nextraction models that can extract discriminant queries and reference (gallery)\nfeature representations for similarity matching. Although state-of-the-art\naccuracy has improved considerably with the advent of deep learning (DL) models\ntrained on large datasets, image retrieval remains challenging in many\nreal-world video analytics and surveillance applications, e.g., person\nre-identification. Using the Euclidean space for matching limits the\nperformance in real-world applications due to the curse of dimensionality,\noverfitting, and sensitivity to noisy data.\n  We argue that the feature dissimilarity space is more suitable for similarity\nmatching, and propose a dichotomy transformation to project query and reference\nembeddings into a single embedding in the dissimilarity space.\n  We also advocate for end-to-end training of a backbone and binary\nclassification models for pair-wise matching. As opposed to comparing the\ndistance between queries and reference embeddings, we show the benefits of\nclassifying the single dissimilarity space embedding (as similar or\ndissimilar), especially when trained end-to-end. We propose a method to train\nthe max-margin classifier together with the backbone feature extractor by\napplying constraints to the L2 norm of the classifier weights along with the\nhinge loss.\n  Our extensive experiments on challenging image retrieval datasets and using\ndiverse feature extraction backbones highlight the benefits of similarity\nmatching in the dissimilarity space. In particular, when jointly training the\nfeature extraction backbone and regularised classifier for matching, the\ndissimilarity space provides a higher level of accuracy.",
      "tldr_zh": "该论文探讨了图像检索方法，指出传统依赖欧氏空间的相似性匹配面临维数灾难、过拟合和噪声敏感等问题，导致在真实应用如人脸再识别中的性能受限。作者提出一种基于差异空间(dissimilarity space)的框架，包括二分变换(dichotomy transformation)来将查询和参考嵌入投影到一个单一嵌入，并倡导端到端(end-to-end)训练主干特征提取模型与二元分类模型，通过最大边距分类器(max-margin classifier)结合L2范数约束和铰链损失进行配对匹配。实验结果显示，在多种挑战性数据集上，该方法显著提升了准确率，尤其是在联合训练特征提取器和正则化分类器时，证明了差异空间在相似性匹配中的优势。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "7 pages",
      "pdf_url": "http://arxiv.org/pdf/2412.08618v1",
      "published_date": "2024-12-11 18:39:32 UTC",
      "updated_date": "2024-12-11 18:39:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:05:46.167875"
    },
    {
      "arxiv_id": "2412.08610v1",
      "title": "Competition and Diversity in Generative AI",
      "title_zh": "生成式人工智能中的竞争与多样性",
      "authors": [
        "Manish Raghavan"
      ],
      "abstract": "Recent evidence suggests that the use of generative artificial intelligence\nreduces the diversity of content produced. In this work, we develop a\ngame-theoretic model to explore the downstream consequences of content\nhomogeneity when producers use generative AI to compete with one another. At\nequilibrium, players indeed produce content that is less diverse than optimal.\nHowever, stronger competition mitigates homogeneity and induces more diverse\nproduction. Perhaps more surprisingly, we show that a generative AI model that\nperforms well in isolation (i.e., according to a benchmark) may fail to do so\nwhen faced with competition, and vice versa. We validate our results\nempirically by using language models to play Scattergories, a word game in\nwhich players are rewarded for producing answers that are both correct and\nunique. We discuss how the interplay between competition and homogeneity has\nimplications for the development, evaluation, and use of generative AI.",
      "tldr_zh": "本研究使用博弈论模型(game-theoretic model)探讨生成式人工智能(generative AI)导致内容多样性减少的后果，分析竞争环境下生产者之间的互动。结果显示，在均衡状态下(equilibrium)，参与者生产的内容多样性低于最优水平，但更强的竞争可以缓解同质化并促进更多样化输出。令人意外的是，一个在隔离基准测试中表现良好的generative AI模型，可能在竞争中失败，反之亦然。研究通过语言模型玩Scattergories游戏进行实证验证，并强调竞争与同质化(interplay between competition and homogeneity)的相互作用对generative AI的开发、评估和应用具有重要启示。",
      "categories": [
        "cs.GT",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.GT",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.08610v1",
      "published_date": "2024-12-11 18:34:31 UTC",
      "updated_date": "2024-12-11 18:34:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:05:19.894266"
    },
    {
      "arxiv_id": "2412.08608v1",
      "title": "AdvWave: Stealthy Adversarial Jailbreak Attack against Large Audio-Language Models",
      "title_zh": "AdvWave：针对大型音频语言模型的隐蔽",
      "authors": [
        "Mintong Kang",
        "Chejian Xu",
        "Bo Li"
      ],
      "abstract": "Recent advancements in large audio-language models (LALMs) have enabled\nspeech-based user interactions, significantly enhancing user experience and\naccelerating the deployment of LALMs in real-world applications. However,\nensuring the safety of LALMs is crucial to prevent risky outputs that may raise\nsocietal concerns or violate AI regulations. Despite the importance of this\nissue, research on jailbreaking LALMs remains limited due to their recent\nemergence and the additional technical challenges they present compared to\nattacks on DNN-based audio models. Specifically, the audio encoders in LALMs,\nwhich involve discretization operations, often lead to gradient shattering,\nhindering the effectiveness of attacks relying on gradient-based optimizations.\nThe behavioral variability of LALMs further complicates the identification of\neffective (adversarial) optimization targets. Moreover, enforcing stealthiness\nconstraints on adversarial audio waveforms introduces a reduced, non-convex\nfeasible solution space, further intensifying the challenges of the\noptimization process. To overcome these challenges, we develop AdvWave, the\nfirst jailbreak framework against LALMs. We propose a dual-phase optimization\nmethod that addresses gradient shattering, enabling effective end-to-end\ngradient-based optimization. Additionally, we develop an adaptive adversarial\ntarget search algorithm that dynamically adjusts the adversarial optimization\ntarget based on the response patterns of LALMs for specific queries. To ensure\nthat adversarial audio remains perceptually natural to human listeners, we\ndesign a classifier-guided optimization approach that generates adversarial\nnoise resembling common urban sounds. Extensive evaluations on multiple\nadvanced LALMs demonstrate that AdvWave outperforms baseline methods, achieving\na 40% higher average jailbreak attack success rate.",
      "tldr_zh": "本研究提出 AdvWave，一种针对大型音频语言模型 (LALMs) 的隐秘对抗越狱攻击框架，旨在解决 LALMs 安全问题，如梯度粉碎、行为变异和隐秘性约束带来的挑战。AdvWave 采用双阶段优化方法处理梯度粉碎，自适应对抗目标搜索算法动态调整优化目标，以及分类器引导优化生成类似于城市声音的对抗噪声，以确保音频对人类听众保持感知自然。实验结果显示，在多个高级 LALMs 上，AdvWave 的平均越狱攻击成功率比基线方法提高 40%，证明了其有效性。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CR",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.08608v1",
      "published_date": "2024-12-11 18:30:57 UTC",
      "updated_date": "2024-12-11 18:30:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:05:31.110401"
    },
    {
      "arxiv_id": "2412.08604v1",
      "title": "Preference Discerning with LLM-Enhanced Generative Retrieval",
      "title_zh": "翻译失败",
      "authors": [
        "Fabian Paischer",
        "Liu Yang",
        "Linfeng Liu",
        "Shuai Shao",
        "Kaveh Hassani",
        "Jiacheng Li",
        "Ricky Chen",
        "Zhang Gabriel Li",
        "Xialo Gao",
        "Wei Shao",
        "Xue Feng",
        "Nima Noorshams",
        "Sem Park",
        "Bo Long",
        "Hamid Eghbalzadeh"
      ],
      "abstract": "Sequential recommendation systems aim to provide personalized recommendations\nfor users based on their interaction history. To achieve this, they often\nincorporate auxiliary information, such as textual descriptions of items and\nauxiliary tasks, like predicting user preferences and intent. Despite numerous\nefforts to enhance these models, they still suffer from limited\npersonalization. To address this issue, we propose a new paradigm, which we\nterm preference discerning. In preference dscerning, we explicitly condition a\ngenerative sequential recommendation system on user preferences within its\ncontext. To this end, we generate user preferences using Large Language Models\n(LLMs) based on user reviews and item-specific data. To evaluate preference\ndiscerning capabilities of sequential recommendation systems, we introduce a\nnovel benchmark that provides a holistic evaluation across various scenarios,\nincluding preference steering and sentiment following. We assess current\nstate-of-the-art methods using our benchmark and show that they struggle to\naccurately discern user preferences. Therefore, we propose a new method named\nMender ($\\textbf{M}$ultimodal Prefer$\\textbf{en}$ce\n$\\textbf{d}$iscern$\\textbf{er}$), which improves upon existing methods and\nachieves state-of-the-art performance on our benchmark. Our results show that\nMender can be effectively guided by human preferences even though they have not\nbeen observed during training, paving the way toward more personalized\nsequential recommendation systems. We will open-source the code and benchmarks\nupon publication.",
      "tldr_zh": "该论文针对顺序推荐系统（Sequential recommendation systems）的个性化不足，提出一种新的范式——preference discerning，通过在上下文中显式整合用户偏好来提升推荐效果。具体方法利用 Large Language Models (LLMs) 基于用户评论和物品数据生成偏好，并引入一个新基准来评估系统在偏好引导（preference steering）和情感遵循（sentiment following）等场景下的性能。实验结果显示，现有的最先进方法难以准确识别用户偏好，而提出的 Mender（Multimodal Preference Discerners）方法显著改进，实现了基准上的最先进性能，并能有效处理训练中未观察到的用户偏好。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "cs.IR",
      "comment": "11 pages + references and appendix",
      "pdf_url": "http://arxiv.org/pdf/2412.08604v1",
      "published_date": "2024-12-11 18:26:55 UTC",
      "updated_date": "2024-12-11 18:26:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:05:45.242089"
    },
    {
      "arxiv_id": "2412.10446v1",
      "title": "Disentanglement and Compositionality of Letter Identity and Letter Position in Variational Auto-Encoder Vision Models",
      "title_zh": "字母身份和字母位置在变分自编码器视觉模型中的解",
      "authors": [
        "Bruno Bianchi",
        "Aakash Agrawal",
        "Stanislas Dehaene",
        "Emmanuel Chemla",
        "Yair Lakretz"
      ],
      "abstract": "Human readers can accurately count how many letters are in a word (e.g., 7 in\n``buffalo''), remove a letter from a given position (e.g., ``bufflo'') or add a\nnew one. The human brain of readers must have therefore learned to disentangle\ninformation related to the position of a letter and its identity. Such\ndisentanglement is necessary for the compositional, unbounded, ability of\nhumans to create and parse new strings, with any combination of letters\nappearing in any positions. Do modern deep neural models also possess this\ncrucial compositional ability? Here, we tested whether neural models that\nachieve state-of-the-art on disentanglement of features in visual input can\nalso disentangle letter position and letter identity when trained on images of\nwritten words. Specifically, we trained beta variational autoencoder\n($\\beta$-VAE) to reconstruct images of letter strings and evaluated their\ndisentanglement performance using CompOrth - a new benchmark that we created\nfor studying compositional learning and zero-shot generalization in visual\nmodels for orthography. The benchmark suggests a set of tests, of increasing\ncomplexity, to evaluate the degree of disentanglement between orthographic\nfeatures of written words in deep neural models. Using CompOrth, we conducted a\nset of experiments to analyze the generalization ability of these models, in\nparticular, to unseen word length and to unseen combinations of letter\nidentities and letter positions. We found that while models effectively\ndisentangle surface features, such as horizontal and vertical `retinal'\nlocations of words within an image, they dramatically fail to disentangle\nletter position and letter identity and lack any notion of word length.\nTogether, this study demonstrates the shortcomings of state-of-the-art\n$\\beta$-VAE models compared to humans and proposes a new challenge and a\ncorresponding benchmark to evaluate neural models.",
      "tldr_zh": "本研究探讨了变分自编码器(β-VAE)视觉模型在处理字母身份和位置的分离(disentanglement)与组合性(compositionality)方面的能力，旨在与人类阅读能力进行比较。研究者训练β-VAE模型来重建字母字符串图像，并引入了一个新基准CompOrth，用于评估模型在正字法方面的组合学习和零样本泛化，包括对未见词长和字母组合的测试。结果显示，虽然模型能有效分离图像中的表面特征（如水平和垂直位置），但在分离字母身份和位置以及理解词长方面严重失败，与人类相比存在显著缺陷。该研究突显了当前神经模型的局限性，并提出CompOrth作为评估和改进这些模型的新挑战。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.10446v1",
      "published_date": "2024-12-11 18:20:53 UTC",
      "updated_date": "2024-12-11 18:20:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:05:55.361579"
    },
    {
      "arxiv_id": "2412.08681v1",
      "title": "Learning Physics Informed Neural ODEs With Partial Measurements",
      "title_zh": "翻译失败",
      "authors": [
        "Paul Ghanem",
        "Ahmet Demirkaya",
        "Tales Imbiriba",
        "Alireza Ramezani",
        "Zachary Danziger",
        "Deniz Erdogmus"
      ],
      "abstract": "Learning dynamics governing physical and spatiotemporal processes is a\nchallenging problem, especially in scenarios where states are partially\nmeasured. In this work, we tackle the problem of learning dynamics governing\nthese systems when parts of the system's states are not measured, specifically\nwhen the dynamics generating the non-measured states are unknown. Inspired by\nstate estimation theory and Physics Informed Neural ODEs, we present a\nsequential optimization framework in which dynamics governing unmeasured\nprocesses can be learned. We demonstrate the performance of the proposed\napproach leveraging numerical simulations and a real dataset extracted from an\nelectro-mechanical positioning system. We show how the underlying equations fit\ninto our formalism and demonstrate the improved performance of the proposed\nmethod when compared with baselines.",
      "tldr_zh": "本文提出了一种学习部分测量状态下物理和时空过程动态的方法，针对未测量状态的未知动态问题。受状态估计理论和 Physics Informed Neural ODEs 启发，该方法采用顺序优化框架来学习这些动态。通过数值模拟和来自机电定位系统的真实数据集进行验证，结果显示该方法在性能上优于基线模型，并展示了底层方程的有效拟合。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.08681v1",
      "published_date": "2024-12-11 18:17:34 UTC",
      "updated_date": "2024-12-11 18:17:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:06:08.185001"
    },
    {
      "arxiv_id": "2412.08591v2",
      "title": "RoomTour3D: Geometry-Aware Video-Instruction Tuning for Embodied Navigation",
      "title_zh": "翻译失败",
      "authors": [
        "Mingfei Han",
        "Liang Ma",
        "Kamila Zhumakhanova",
        "Ekaterina Radionova",
        "Jingyi Zhang",
        "Xiaojun Chang",
        "Xiaodan Liang",
        "Ivan Laptev"
      ],
      "abstract": "Vision-and-Language Navigation (VLN) suffers from the limited diversity and\nscale of training data, primarily constrained by the manual curation of\nexisting simulators. To address this, we introduce RoomTour3D, a\nvideo-instruction dataset derived from web-based room tour videos that capture\nreal-world indoor spaces and human walking demonstrations. Unlike existing VLN\ndatasets, RoomTour3D leverages the scale and diversity of online videos to\ngenerate open-ended human walking trajectories and open-world navigable\ninstructions. To compensate for the lack of navigation data in online videos,\nwe perform 3D reconstruction and obtain 3D trajectories of walking paths\naugmented with additional information on the room types, object locations and\n3D shape of surrounding scenes. Our dataset includes $\\sim$100K open-ended\ndescription-enriched trajectories with $\\sim$200K instructions, and 17K\naction-enriched trajectories from 1847 room tour environments. We demonstrate\nexperimentally that RoomTour3D enables significant improvements across multiple\nVLN tasks including CVDN, SOON, R2R, and REVERIE. Moreover, RoomTour3D\nfacilitates the development of trainable zero-shot VLN agents, showcasing the\npotential and challenges of advancing towards open-world navigation.",
      "tldr_zh": "该论文提出了 RoomTour3D，一个基于网络房间游览视频的几何感知视频指令数据集，旨在解决 Vision-and-Language Navigation (VLN) 训练数据多样性和规模不足的问题。通过 3D 重建技术，该数据集生成开放式的人类行走轨迹，并增强了房间类型、物体位置和场景形状的信息，总共包括约 100K 描述增强轨迹、200K 指令和 17K 动作增强轨迹，覆盖 1847 个环境。实验结果显示，RoomTour3D 在 CVDN、SOON、R2R 和 REVERIE 等 VLN 任务中显著提升性能，并支持训练零样本 VLN 代理，推动了开放世界导航的潜力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR2025",
      "pdf_url": "http://arxiv.org/pdf/2412.08591v2",
      "published_date": "2024-12-11 18:10:21 UTC",
      "updated_date": "2025-03-19 10:05:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:06:23.263783"
    },
    {
      "arxiv_id": "2412.08680v1",
      "title": "Distinguishing Scams and Fraud with Ensemble Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Isha Chadalavada",
        "Tianhui Huang",
        "Jessica Staddon"
      ],
      "abstract": "Users increasingly query LLM-enabled web chatbots for help with scam defense.\nThe Consumer Financial Protection Bureau's complaints database is a rich data\nsource for evaluating LLM performance on user scam queries, but currently the\ncorpus does not distinguish between scam and non-scam fraud. We developed an\nLLM ensemble approach to distinguishing scam and fraud CFPB complaints and\ndescribe initial findings regarding the strengths and weaknesses of LLMs in the\nscam defense context.",
      "tldr_zh": "本研究针对用户使用LLM-enabled网络聊天机器人进行诈骗防御的场景，分析了消费者金融保护局(CFPB)投诉数据库中诈骗和非诈骗欺诈的区分问题。研究开发了一种LLM ensemble approach，即LLM集成学习方法，来自动分类CFPB投诉。初步结果显示，该方法突显了LLM在诈骗防御背景下的优势，如高效处理查询，但也暴露了其弱点，包括潜在的分类错误和领域知识限制。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.08680v1",
      "published_date": "2024-12-11 18:07:18 UTC",
      "updated_date": "2024-12-11 18:07:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:06:32.236159"
    },
    {
      "arxiv_id": "2412.08587v2",
      "title": "Advancing Single and Multi-task Text Classification through Large Language Model Fine-tuning",
      "title_zh": "通过大型语言模型微调推进单任务和多任务文本分类",
      "authors": [
        "Hang Zhao",
        "Qile P. Chen",
        "Yijing Barry Zhang",
        "Gang Yang"
      ],
      "abstract": "Both encoder-only models (e.g., BERT, RoBERTa) and large language models\n(LLMs, e.g., Llama3) have been widely used for text classification tasks.\nHowever, there is a lack of systematic studies comparing the performance of\nencoder-based models and LLMs in text classification, particularly when\nfine-tuning is involved. This study employed a diverse range of models and\nmethods, varying in size and architecture, and including both fine-tuned and\npre-trained approaches. We first assessed the performances of these LLMs on the\n20 Newsgroups (20NG) and MASSIVE datasets, comparing them to encoder-only\nRoBERTa models. Additionally, we explored the multi-task capabilities of both\nmodel types by combining multiple classification tasks, including intent\ndetection and slot-filling, into a single model using data from both datasets.\nOur results indicate that fully fine-tuned Llama3-70B models outperform\nRoBERTa-large and other decoder LLMs across various classification tasks and\ndatasets. Moreover, the consolidated multi-task fine-tuned LLMs matched the\nperformance of dual-model setups in both tasks across both datasets. Overall,\nour study provides a comprehensive benchmark of encoder-only and LLM models on\ntext classification tasks and demonstrates a method to combine two or more\nfully fine-tuned decoder LLMs for reduced latency and equivalent performance.",
      "tldr_zh": "这篇论文比较了编码器模型（如 BERT 和 RoBERTa）和大型语言模型（LLMs，如 Llama3）在文本分类任务中的性能，特别关注微调的影响。研究使用多种模型和方法，在 20 Newsgroups (20NG) 和 MASSIVE 数据集上进行评估，并扩展到多任务场景，如意图检测和槽填充。结果显示，完全微调的 Llama3-70B 模型在单任务和多任务上超过了 RoBERTa-large 等基线模型，且多任务微调 LLMs 能与双模型设置匹配性能，同时降低延迟。该研究提供了全面的文本分类基准，并展示了结合微调解码器 LLMs 的优化方法。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "9 pages, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2412.08587v2",
      "published_date": "2024-12-11 18:06:44 UTC",
      "updated_date": "2025-05-11 04:59:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:06:46.224193"
    },
    {
      "arxiv_id": "2412.08585v3",
      "title": "TurboAttention: Efficient Attention Approximation For High Throughputs LLMs",
      "title_zh": "TurboAttention：用于高吞吐量 LLMs 的高效注意力近似",
      "authors": [
        "Hao Kang",
        "Srikant Bharadwaj",
        "James Hensman",
        "Tushar Krishna",
        "Victor Ruhle",
        "Saravan Rajmohan"
      ],
      "abstract": "Large language model (LLM) inference demands significant amount of\ncomputation and memory, especially in the key attention mechanism. While\ntechniques, such as quantization and acceleration algorithms, like\nFlashAttention, have improved efficiency of the overall inference, they address\ndifferent aspects of the problem: quantization focuses on weight-activation\noperations, while FlashAttention improves execution but requires high-precision\nformats. Recent Key-value (KV) cache quantization reduces memory bandwidth but\nstill needs floating-point dequantization for attention operation.\n  We present TurboAttention, a comprehensive approach to enable quantized\nexecution of attention that simultaneously addresses both memory and\ncomputational efficiency. Our solution introduces two key innovations: FlashQ,\na headwise attention quantization technique that enables both compression of KV\ncache and quantized execution of activation-activation multiplication, and\nSparsity-based Softmax Approximation (SAS), which eliminates the need for\ndequantization to FP32 during exponentiation operation in attention.\nExperimental results demonstrate that TurboAttention achieves 1.2-1.8x speedup\nin attention, reduces the KV cache size by over 4.4x, and enables up to 2.37x\nmaximum throughput over the FP16 baseline while outperforming state-of-the-art\nquantization and compression techniques across various datasets and models.",
      "tldr_zh": "该论文提出了 TurboAttention，一种高效的注意力机制近似方法，旨在优化大型语言模型（LLMs）的计算和内存效率，同时解决注意力操作中的量化挑战。TurboAttention 引入了两个关键创新：FlashQ 技术，用于头级别的注意力量化，以压缩 KV cache 并实现激活-激活乘法的量化执行；以及 SAS (Sparsity-based Softmax Approximation)，通过稀疏性近似消除注意力计算中对 FP32 去量化的需求。实验结果显示，该方法在各种数据集和模型上实现了 1.2-1.8x 的注意力加速、超过 4.4x 的 KV cache 压缩，以及高达 2.37x 的最大吞吐量，优于现有量化与压缩技术。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.AR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.08585v3",
      "published_date": "2024-12-11 18:03:05 UTC",
      "updated_date": "2024-12-17 05:40:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:06:56.946102"
    },
    {
      "arxiv_id": "2412.08574v1",
      "title": "Learning Sketch Decompositions in Planning via Deep Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Michael Aichmüller",
        "Hector Geffner"
      ],
      "abstract": "In planning and reinforcement learning, the identification of common subgoal\nstructures across problems is important when goals are to be achieved over long\nhorizons. Recently, it has been shown that such structures can be expressed as\nfeature-based rules, called sketches, over a number of classical planning\ndomains. These sketches split problems into subproblems which then become\nsolvable in low polynomial time by a greedy sequence of IW$(k)$ searches.\nMethods for learning sketches using feature pools and min-SAT solvers have been\ndeveloped, yet they face two key limitations: scalability and expressivity. In\nthis work, we address these limitations by formulating the problem of learning\nsketch decompositions as a deep reinforcement learning (DRL) task, where\ngeneral policies are sought in a modified planning problem where the successor\nstates of a state s are defined as those reachable from s through an IW$(k)$\nsearch. The sketch decompositions obtained through this method are\nexperimentally evaluated across various domains, and problems are regarded as\nsolved by the decomposition when the goal is reached through a greedy sequence\nof IW$(k)$ searches. While our DRL approach for learning sketch decompositions\ndoes not yield interpretable sketches in the form of rules, we demonstrate that\nthe resulting decompositions can often be understood in a crisp manner.",
      "tldr_zh": "本文提出了一种使用深度强化学习(DRL)来学习sketch decompositions的方法，旨在解决规划和强化学习中识别子目标结构的问题，从而提高任务在长时域下的可解决性。该方法将学习过程转化为一个修改后的规划任务，其中状态s的后继状态通过IW(k)搜索定义，克服了传统基于特征池和min-SAT求解器的可伸缩性和表达性局限。在实验中，该DRL方法在多个领域成功生成有效的分解，并证明这些分解虽非直接可解释的规则形式，但通常清晰可理解，能通过贪婪序列的IW(k)搜索达到目标。",
      "categories": [
        "cs.AI",
        "I.2.6; I.2.8"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.08574v1",
      "published_date": "2024-12-11 17:45:31 UTC",
      "updated_date": "2024-12-11 17:45:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:07:09.335968"
    },
    {
      "arxiv_id": "2412.08565v2",
      "title": "GenPlan: Generative Sequence Models as Adaptive Planners",
      "title_zh": "GenPlan：生成式序列模型作为适应性规划器",
      "authors": [
        "Akash Karthikeyan",
        "Yash Vardhan Pant"
      ],
      "abstract": "Sequence models have demonstrated remarkable success in behavioral planning\nby leveraging previously collected demonstrations. However, solving multi-task\nmissions remains a significant challenge, particularly when the planner must\nadapt to unseen constraints and tasks, such as discovering goals and unlocking\ndoors. Such behavioral planning problems are challenging to solve due to: a)\nagents failing to adapt beyond the single task learned through their reward\nfunction, and b) inability to generalize to new environments, e.g., those with\nwalls and locked doors, when trained only in planar environments. Consequently,\nstate-of-the-art decision-making methods are limited to missions where the\nrequired tasks are well-represented in the training demonstrations and can be\nsolved within a short (temporal) planning horizon. To address this, we propose\nGenPlan: a stochastic and adaptive planner that leverages discrete-flow models\nfor generative sequence modeling, enabling sample-efficient exploration and\nexploitation. This framework relies on an iterative denoising procedure to\ngenerate a sequence of goals and actions. This approach captures multi-modal\naction distributions and facilitates goal and task discovery, thereby\ngeneralizing to out-of-distribution tasks and environments, i.e., missions not\npart of the training data. We demonstrate the effectiveness of our method\nthrough multiple simulation environments. Notably, GenPlan outperforms\nstate-of-the-art methods by over 10% on adaptive planning tasks, where the\nagent adapts to multi-task missions while leveraging demonstrations from\nsingle-goal-reaching tasks. Our code is available at\nhttps://github.com/CL2-UWaterloo/GenPlan.",
      "tldr_zh": "该论文提出GenPlan，一种基于生成序列模型的适应性规划框架，旨在解决序列模型在多任务行为规划中的挑战，如无法适应新约束（如发现目标和解锁门）或泛化到新环境。GenPlan利用离散-flow models进行生成序列建模，通过迭代去噪过程生成目标和动作序列，支持样本高效的探索、利用多模态动作分布，并实现任务发现和泛化。实验在多个模拟环境中证明，GenPlan在适应性规划任务中比最先进方法提高10%以上，展示了其在处理分布外任务时的优越性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted in AAAI 2025. Project page:\n  https://aku02.github.io/projects/genplan/",
      "pdf_url": "http://arxiv.org/pdf/2412.08565v2",
      "published_date": "2024-12-11 17:32:33 UTC",
      "updated_date": "2024-12-25 19:45:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:07:20.773467"
    },
    {
      "arxiv_id": "2412.08556v2",
      "title": "Exact Algorithms for Multiagent Path Finding with Communication Constraints on Tree-Like Structures",
      "title_zh": "翻译失败",
      "authors": [
        "Foivos Fioravantes",
        "Dušan Knop",
        "Jan Matyáš Křišťan",
        "Nikolaos Melissinos",
        "Michal Opler"
      ],
      "abstract": "Consider the scenario where multiple agents have to move in an optimal way\nthrough a network, each one towards their ending position while avoiding\ncollisions. By optimal, we mean as fast as possible, which is evaluated by a\nmeasure known as the makespan of the proposed solution. This is the setting\nstudied in the Multiagent Path Finding problem. In this work, we additionally\nprovide the agents with a way to communicate with each other. Due to size\nconstraints, it is reasonable to assume that the range of communication of each\nagent will be limited. What should be the trajectories of the agents to,\nadditionally, maintain a backbone of communication? In this work, we study the\nMultiagent Path Finding with Communication Constraint problem under the\nparameterized complexity framework.\n  Our main contribution is three exact algorithms that are efficient when\nconsidering particular structures for the input network. We provide such\nalgorithms for the case when the communication range and the number of agents\n(the makespan resp.) are provided in the input and the network has a tree\ntopology, or bounded maximum degree (has a tree-like topology, i.e., bounded\ntreewidth resp.). We complement these results by showing that it is highly\nunlikely to construct efficient algorithms when considering the number of\nagents as part of the input, even if the makespan is $3$ and the communication\nrange is $1$.",
      "tldr_zh": "该论文研究了多智能体路径寻找（Multiagent Path Finding）问题，在代理需保持通信约束的前提下，优化代理在网络中的移动路径，以最小化 makespan（完成时间）。作者提出了三个精确算法，利用参数化复杂性框架，在网络为树状拓扑（tree topology）或具有边界最大度（bounded maximum degree）/边界树宽（bounded treewidth）时，根据通信范围和代理数量实现高效计算。实验结果证明，这些算法在特定输入条件下表现出色，但当代理数量作为输入时，即使 makespan 为 3 和通信范围为 1，构建高效算法也极度困难。",
      "categories": [
        "cs.CC",
        "cs.AI"
      ],
      "primary_category": "cs.CC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.08556v2",
      "published_date": "2024-12-11 17:17:31 UTC",
      "updated_date": "2024-12-12 09:51:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:07:31.834975"
    },
    {
      "arxiv_id": "2412.16184v1",
      "title": "More complex environments may be required to discover benefits of lifetime learning in evolving robots",
      "title_zh": "翻译失败",
      "authors": [
        "Ege de Bruin",
        "Kyrre Glette",
        "Kai Olav Ellefsen"
      ],
      "abstract": "It is well known that intra-life learning, defined as an additional\ncontroller optimization loop, is beneficial for evolving robot morphologies for\nlocomotion. In this work, we investigate this further by comparing it in two\ndifferent environments: an easy flat environment and a more challenging hills\nenvironment. We show that learning is significantly more beneficial in a hilly\nenvironment than in a flat environment and that it might be needed to evaluate\nrobots in a more challenging environment to see the benefits of learning.",
      "tldr_zh": "本研究探讨了 intra-life learning（一种额外的控制器优化循环）在演化机器人形态用于运动时的益处，通过比较简单平坦环境和复杂丘陵环境。结果显示，在丘陵环境中，intra-life learning 的优势更为显著，因为它能显著提升机器人的适应性。作者强调，为了发现这种学习的好处，可能需要使用更具挑战性的环境来评估 evolving robots。",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.16184v1",
      "published_date": "2024-12-11 17:15:45 UTC",
      "updated_date": "2024-12-11 17:15:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:07:43.400551"
    },
    {
      "arxiv_id": "2412.08542v1",
      "title": "MaestroMotif: Skill Design from Artificial Intelligence Feedback",
      "title_zh": "MaestroMotif：基于人工智能反馈的技能设计",
      "authors": [
        "Martin Klissarov",
        "Mikael Henaff",
        "Roberta Raileanu",
        "Shagun Sodhani",
        "Pascal Vincent",
        "Amy Zhang",
        "Pierre-Luc Bacon",
        "Doina Precup",
        "Marlos C. Machado",
        "Pierluca D'Oro"
      ],
      "abstract": "Describing skills in natural language has the potential to provide an\naccessible way to inject human knowledge about decision-making into an AI\nsystem. We present MaestroMotif, a method for AI-assisted skill design, which\nyields high-performing and adaptable agents. MaestroMotif leverages the\ncapabilities of Large Language Models (LLMs) to effectively create and reuse\nskills. It first uses an LLM's feedback to automatically design rewards\ncorresponding to each skill, starting from their natural language description.\nThen, it employs an LLM's code generation abilities, together with\nreinforcement learning, for training the skills and combining them to implement\ncomplex behaviors specified in language. We evaluate MaestroMotif using a suite\nof complex tasks in the NetHack Learning Environment (NLE), demonstrating that\nit surpasses existing approaches in both performance and usability.",
      "tldr_zh": "该研究提出MaestroMotif，一种AI辅助技能设计方法，利用Large Language Models (LLMs)从自然语言描述中自动生成技能对应的奖励，并结合LLMs的代码生成能力与reinforcement learning训练技能，以实现复杂行为的组合。MaestroMotif通过这种方式创建高性能且可适应的AI代理，允许人类知识轻松注入决策系统中。在NetHack Learning Environment (NLE)的复杂任务测试中，该方法在性能和可用性上超过了现有方法。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.08542v1",
      "published_date": "2024-12-11 16:59:31 UTC",
      "updated_date": "2024-12-11 16:59:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:07:56.011918"
    },
    {
      "arxiv_id": "2412.08520v1",
      "title": "GR-NLP-TOOLKIT: An Open-Source NLP Toolkit for Modern Greek",
      "title_zh": "GR-NLP-TOOLKIT：一个开源的 NLP 工具包，用于现代希腊语",
      "authors": [
        "Lefteris Loukas",
        "Nikolaos Smyrnioudis",
        "Chrysa Dikonomaki",
        "Spyros Barbakos",
        "Anastasios Toumazatos",
        "John Koutsikakis",
        "Manolis Kyriakakis",
        "Mary Georgiou",
        "Stavros Vassos",
        "John Pavlopoulos",
        "Ion Androutsopoulos"
      ],
      "abstract": "We present GR-NLP-TOOLKIT, an open-source natural language processing (NLP)\ntoolkit developed specifically for modern Greek. The toolkit provides\nstate-of-the-art performance in five core NLP tasks, namely part-of-speech\ntagging, morphological tagging, dependency parsing, named entity recognition,\nand Greeklishto-Greek transliteration. The toolkit is based on pre-trained\nTransformers, it is freely available, and can be easily installed in Python\n(pip install gr-nlp-toolkit). It is also accessible through a demonstration\nplatform on HuggingFace, along with a publicly available API for non-commercial\nuse. We discuss the functionality provided for each task, the underlying\nmethods, experiments against comparable open-source toolkits, and future\npossible enhancements. The toolkit is available at:\nhttps://github.com/nlpaueb/gr-nlp-toolkit",
      "tldr_zh": "本研究介绍了 GR-NLP-TOOLKIT，一个开源的自然语言处理（NLP）工具包，专门针对现代希腊语设计。该工具包基于预训练 Transformers，提供五项核心任务的 state-of-the-art 性能，包括 part-of-speech tagging、morphological tagging、dependency parsing、named entity recognition 和 Greeklish-to-Greek transliteration。通过实验对比，它优于可比较的开源工具包，并易于在 Python 中安装（pip install gr-nlp-toolkit）。此外，该工具包在 HuggingFace 上提供演示平台和公开 API，支持非商业使用，并讨论了未来的潜在增强。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted Demo Paper @ COLING 2025 (Github:\n  https://github.com/nlpaueb/gr-nlp-toolkit/, Demo:\n  https://huggingface.co/spaces/AUEB-NLP/greek-nlp-toolkit-demo, API:\n  https://huggingface.co/spaces/AUEB-NLP/The-Greek-NLP-API)",
      "pdf_url": "http://arxiv.org/pdf/2412.08520v1",
      "published_date": "2024-12-11 16:34:23 UTC",
      "updated_date": "2024-12-11 16:34:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:08:07.966944"
    },
    {
      "arxiv_id": "2412.08515v1",
      "title": "Enhancing Interpretability Through Loss-Defined Classification Objective in Structured Latent Spaces",
      "title_zh": "翻译失败",
      "authors": [
        "Daniel Geissler",
        "Bo Zhou",
        "Mengxi Liu",
        "Paul Lukowicz"
      ],
      "abstract": "Supervised machine learning often operates on the data-driven paradigm,\nwherein internal model parameters are autonomously optimized to converge\npredicted outputs with the ground truth, devoid of explicitly programming rules\nor a priori assumptions. Although data-driven methods have yielded notable\nsuccesses across various benchmark datasets, they inherently treat models as\nopaque entities, thereby limiting their interpretability and yielding a lack of\nexplanatory insights into their decision-making processes. In this work, we\nintroduce Latent Boost, a novel approach that integrates advanced distance\nmetric learning into supervised classification tasks, enhancing both\ninterpretability and training efficiency. Thus during training, the model is\nnot only optimized for classification metrics of the discrete data points but\nalso adheres to the rule that the collective representation zones of each class\nshould be sharply clustered. By leveraging the rich structural insights of\nintermediate model layer latent representations, Latent Boost improves\nclassification interpretability, as demonstrated by higher Silhouette scores,\nwhile accelerating training convergence. These performance and latent\nstructural benefits are achieved with minimum additional cost, making it\nbroadly applicable across various datasets without requiring data-specific\nadjustments. Furthermore, Latent Boost introduces a new paradigm for aligning\nclassification performance with improved model transparency to address the\nchallenges of black-box models.",
      "tldr_zh": "这篇论文针对监督机器学习模型的不透明性问题，提出了一种名为Latent Boost的新方法，将advanced distance metric learning整合到分类任务中，以优化潜在空间的结构化聚类。该方法不仅提升了分类性能，还确保每个类的表示在latent spaces中紧密聚类，从而提高了模型的可解释性，如通过更高的Silhouette scores来衡量。实验结果显示，Latent Boost加速了训练收敛，并以最低额外成本适用于多种数据集。总体上，它引入了一个新范式，将classification performance与模型透明度对齐，解决黑箱模型的挑战。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.08515v1",
      "published_date": "2024-12-11 16:25:17 UTC",
      "updated_date": "2024-12-11 16:25:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:08:19.952009"
    },
    {
      "arxiv_id": "2412.08513v1",
      "title": "REPEAT: Improving Uncertainty Estimation in Representation Learning Explainability",
      "title_zh": "REPEAT：改进表示学习可解释性中的不确定性估计",
      "authors": [
        "Kristoffer K. Wickstrøm",
        "Thea Brüsch",
        "Michael C. Kampffmeyer",
        "Robert Jenssen"
      ],
      "abstract": "Incorporating uncertainty is crucial to provide trustworthy explanations of\ndeep learning models. Recent works have demonstrated how uncertainty modeling\ncan be particularly important in the unsupervised field of representation\nlearning explainable artificial intelligence (R-XAI). Current R-XAI methods\nprovide uncertainty by measuring variability in the importance score. However,\nthey fail to provide meaningful estimates of whether a pixel is certainly\nimportant or not. In this work, we propose a new R-XAI method called REPEAT\nthat addresses the key question of whether or not a pixel is \\textit{certainly}\nimportant. REPEAT leverages the stochasticity of current R-XAI methods to\nproduce multiple estimates of importance, thus considering each pixel in an\nimage as a Bernoulli random variable that is either important or unimportant.\nFrom these Bernoulli random variables we can directly estimate the importance\nof a pixel and its associated certainty, thus enabling users to determine\ncertainty in pixel importance. Our extensive evaluation shows that REPEAT gives\ncertainty estimates that are more intuitive, better at detecting\nout-of-distribution data, and more concise.",
      "tldr_zh": "该论文针对表示学习可解释性 (R-XAI) 中的不确定性估计问题，提出了一种新方法 REPEAT，以解决现有方法无法准确判断像素是否“一定”重要的问题。REPEAT 利用现有 R-XAI 方法的随机性生成多个重要性估计，将每个像素视为 Bernoulli random variable，从而直接评估像素的重要性和其相关确定性。实验评估显示，REPEAT 提供更直观、更有效的确定性估计，能够更好地检测 out-of-distribution 数据，并实现更简洁的输出。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at AAAI 2025. Code available at:\n  https://github.com/Wickstrom/REPEAT",
      "pdf_url": "http://arxiv.org/pdf/2412.08513v1",
      "published_date": "2024-12-11 16:24:31 UTC",
      "updated_date": "2024-12-11 16:24:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:08:31.859306"
    },
    {
      "arxiv_id": "2412.08504v1",
      "title": "PointTalk: Audio-Driven Dynamic Lip Point Cloud for 3D Gaussian-based Talking Head Synthesis",
      "title_zh": "翻译失败",
      "authors": [
        "Yifan Xie",
        "Tao Feng",
        "Xin Zhang",
        "Xiangyang Luo",
        "Zixuan Guo",
        "Weijiang Yu",
        "Heng Chang",
        "Fei Ma",
        "Fei Richard Yu"
      ],
      "abstract": "Talking head synthesis with arbitrary speech audio is a crucial challenge in\nthe field of digital humans. Recently, methods based on radiance fields have\nreceived increasing attention due to their ability to synthesize high-fidelity\nand identity-consistent talking heads from just a few minutes of training\nvideo. However, due to the limited scale of the training data, these methods\noften exhibit poor performance in audio-lip synchronization and visual quality.\nIn this paper, we propose a novel 3D Gaussian-based method called PointTalk,\nwhich constructs a static 3D Gaussian field of the head and deforms it in sync\nwith the audio. It also incorporates an audio-driven dynamic lip point cloud as\na critical component of the conditional information, thereby facilitating the\neffective synthesis of talking heads. Specifically, the initial step involves\ngenerating the corresponding lip point cloud from the audio signal and\ncapturing its topological structure. The design of the dynamic difference\nencoder aims to capture the subtle nuances inherent in dynamic lip movements\nmore effectively. Furthermore, we integrate the audio-point enhancement module,\nwhich not only ensures the synchronization of the audio signal with the\ncorresponding lip point cloud within the feature space, but also facilitates a\ndeeper understanding of the interrelations among cross-modal conditional\nfeatures. Extensive experiments demonstrate that our method achieves superior\nhigh-fidelity and audio-lip synchronization in talking head synthesis compared\nto previous methods.",
      "tldr_zh": "本文提出 PointTalk，一种基于 3D Gaussian 的新方法，用于从任意语音音频合成高保真度的 talking head。方法通过构建静态头部 3D Gaussian 场，并结合音频驱动的 dynamic lip point cloud 来同步唇部运动，同时引入动态差异编码器和音频-点云增强模块，以捕捉唇部细微变化并提升跨模态特征的关联。实验结果显示，PointTalk 在 audio-lip synchronization 和视觉质量方面显著优于现有基于辐射场的方法，为数字人类领域提供更可靠的合成技术。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.GR",
        "cs.MM",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "9 pages, accepted by AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.08504v1",
      "published_date": "2024-12-11 16:15:14 UTC",
      "updated_date": "2024-12-11 16:15:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:08:44.037679"
    },
    {
      "arxiv_id": "2412.09651v2",
      "title": "Assisted morbidity coding: the SISCO.web use case for identifying the main diagnosis in Hospital Discharge Records",
      "title_zh": "辅助疾病编码：SISCO.web 用例，用于识别医院出院记录中的主要",
      "authors": [
        "Elena Cardillo",
        "Lucilla Frattura"
      ],
      "abstract": "Coding morbidity data using international standard diagnostic classifications\nis increasingly important and still challenging. Clinical coders and physicians\nassign codes to patient episodes based on their interpretation of case notes or\nelectronic patient records. Therefore, accurate coding relies on the legibility\nof case notes and the coders' understanding of medical terminology. During the\nlast ten years, many studies have shown poor reproducibility of clinical\ncoding, even recently, with the application of Artificial Intelligence-based\nmodels. Given this context, the paper aims to present the SISCO.web approach\ndesigned to support physicians in filling in Hospital Discharge Records with\nproper diagnoses and procedures codes using the International Classification of\nDiseases (9th and 10th), and, above all, in identifying the main pathological\ncondition. The web service leverages NLP algorithms, specific coding rules, as\nwell as ad hoc decision trees to identify the main condition, showing promising\nresults in providing accurate ICD coding suggestions.",
      "tldr_zh": "该论文讨论了使用国际标准诊断分类（如 ICD）编码疾病数据的挑战，包括临床编码的可再现性问题和对医疗术语的理解依赖。研究引入了 SISCO.web 一种网络服务，利用 NLP 算法、特定编码规则和专属决策树，帮助医生在 Hospital Discharge Records 中准确识别主要病况并提供 ICD 编码建议。实验结果显示，该方法在提高编码准确性和可靠性方面表现出色，有望解决传统临床编码的不足。",
      "categories": [
        "cs.OH",
        "cs.AI",
        "H.4.2; H.3.3; H.3.5; H.3.1; I.2.1; I.2.4; J.3"
      ],
      "primary_category": "cs.OH",
      "comment": "18 pages",
      "pdf_url": "http://arxiv.org/pdf/2412.09651v2",
      "published_date": "2024-12-11 16:08:25 UTC",
      "updated_date": "2025-03-07 09:32:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:08:54.695698"
    },
    {
      "arxiv_id": "2412.08490v1",
      "title": "SuperCode: Sustainability PER AI-driven CO-DEsign",
      "title_zh": "翻译失败",
      "authors": [
        "P. Chris Broekema",
        "Rob V. van Nieuwpoort"
      ],
      "abstract": "Currently, data-intensive scientific applications require vast amounts of\ncompute resources to deliver world-leading science. The climate emergency has\nmade it clear that unlimited use of resources (e.g., energy) for scientific\ndiscovery is no longer acceptable. Future computing hardware promises to be\nmuch more energy efficient, but without better optimized software this cannot\nreach its full potential. In this vision paper, we propose a generic AI-driven\nco-design methodology, using specialized Large Language Models (like ChatGPT),\nto effectively generate efficient code for emerging computing hardware. We\ndescribe how we will validate our methodology with two radio astronomy\napplications, with sustainability as the key performance indicator. This paper\nis a modified version of our accepted SuperCode project proposal. We present it\nhere in this form to introduce the vision behind this project and to\ndisseminate the work in the spirit of Open Science and transparency. An\nadditional aim is to collect feedback, invite potential collaboration partners\nand use-cases to join the project.",
      "tldr_zh": "本论文提出SuperCode框架，一种AI驱动的共同设计方法，利用专用Large Language Models（如ChatGPT），旨在为新兴计算硬件生成高效代码，以提升软件优化并减少能源消耗。该方法针对数据密集型科学应用中的可持续性问题，提供通用解决方案，确保资源利用更环保。作者计划通过两个射电天文学应用进行验证，以可持续性作为关键绩效指标，并通过此愿景论文邀请合作和反馈，促进开放科学发展。",
      "categories": [
        "astro-ph.IM",
        "cs.AI"
      ],
      "primary_category": "astro-ph.IM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.08490v1",
      "published_date": "2024-12-11 15:54:33 UTC",
      "updated_date": "2024-12-11 15:54:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:09:07.143998"
    },
    {
      "arxiv_id": "2412.08477v2",
      "title": "Accurate Water Level Monitoring in AWD Rice Cultivation Using Convolutional Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Ahmed Rafi Hasan",
        "Niloy Kumar Kundu",
        "Saad Hasan",
        "Mohammad Rashedul Hoque",
        "Swakkhar Shatabda"
      ],
      "abstract": "The Alternate Wetting and Drying (AWD) method is a rice-growing water\nmanagement technique promoted as a sustainable alternative to Continuous\nFlooding (CF). Climate change has placed the agricultural sector in a\nchallenging position, particularly as global water resources become\nincreasingly scarce, affecting rice production on irrigated lowlands. Rice, a\nstaple food for over half of the world's population, demands significantly more\nwater than other major crops. In Bangladesh, Boro rice, in particular, requires\nconsiderable water inputs during its cultivation. Traditionally, farmers\nmanually measure water levels, a process that is both time-consuming and prone\nto errors. While ultrasonic sensors offer improvements in water height\nmeasurement, they still face limitations, such as susceptibility to weather\nconditions and environmental factors. To address these issues, we propose a\nnovel approach that automates water height measurement using computer vision,\nspecifically through a convolutional neural network (CNN). Our attention-based\narchitecture achieved an $R^2$ score of 0.9885 and a Mean Squared Error (MSE)\nof 0.2766, providing a more accurate and efficient solution for managing AWD\nsystems.",
      "tldr_zh": "本研究针对水稻种植中Alternate Wetting and Drying (AWD)方法的用水管理问题，提出一种基于Convolutional Neural Networks (CNN)的计算机视觉技术，以解决传统手动测量和超声波传感器受天气影响的局限性。研究设计了一个注意力机制的CNN架构，用于自动化水位监测，在实验中实现了R²分数0.9885和Mean Squared Error (MSE) 0.2766的优异性能。相比传统方法，该方法为AWD系统提供了更准确、高效的解决方案，有助于缓解气候变化下水资源短缺对水稻生产的冲击。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "15 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.08477v2",
      "published_date": "2024-12-11 15:44:08 UTC",
      "updated_date": "2024-12-12 05:45:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:09:19.420938"
    },
    {
      "arxiv_id": "2412.08467v2",
      "title": "Bootstrapping Language-Guided Navigation Learning with Self-Refining Data Flywheel",
      "title_zh": "翻译失败",
      "authors": [
        "Zun Wang",
        "Jialu Li",
        "Yicong Hong",
        "Songze Li",
        "Kunchang Li",
        "Shoubin Yu",
        "Yi Wang",
        "Yu Qiao",
        "Yali Wang",
        "Mohit Bansal",
        "Limin Wang"
      ],
      "abstract": "Creating high-quality data for training robust language-instructed agents is\na long-lasting challenge in embodied AI. In this paper, we introduce a\nSelf-Refining Data Flywheel (SRDF) that generates high-quality and large-scale\nnavigational instruction-trajectory pairs by iteratively refining the data pool\nthrough the collaboration between two models, the instruction generator and the\nnavigator, without any human-in-the-loop annotation. Specifically, SRDF starts\nwith using a base generator to create an initial data pool for training a base\nnavigator, followed by applying the trained navigator to filter the data pool.\nThis leads to higher-fidelity data to train a better generator, which can, in\nturn, produce higher-quality data for training the next-round navigator. Such a\nflywheel establishes a data self-refining process, yielding a continuously\nimproved and highly effective dataset for large-scale language-guided\nnavigation learning. Our experiments demonstrate that after several flywheel\nrounds, the navigator elevates the performance boundary from 70% to 78% SPL on\nthe classic R2R test set, surpassing human performance (76%) for the first\ntime. Meanwhile, this process results in a superior generator, evidenced by a\nSPICE increase from 23.5 to 26.2, better than all previous VLN instruction\ngeneration methods. Finally, we demonstrate the scalability of our method\nthrough increasing environment and instruction diversity, and the\ngeneralization ability of our pre-trained navigator across various downstream\nnavigation tasks, surpassing state-of-the-art methods by a large margin in all\ncases.",
      "tldr_zh": "本文提出 Self-Refining Data Flywheel (SRDF)，一种无需人为干预的迭代框架，用于自动生成和精炼高质量的语言引导导航指令-轨迹对。SRDF 通过指令生成器和导航器的协作，不断优化数据池：从初始数据训练基础导航器，再用改进的导航器过滤数据，反向提升生成器性能。实验结果显示，该方法使导航器在 R2R 测试集上的 SPL 性能从 70% 提升到 78%，首次超过人类水平 (76%)，同时生成器的 SPICE 指标从 23.5 提高到 26.2。SRDF 还展示了优秀的扩展性和泛化能力，在多种下游导航任务上大幅超越现有最先进方法。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "28 pages, Code and data are available at\n  https://github.com/wz0919/VLN-SRDF",
      "pdf_url": "http://arxiv.org/pdf/2412.08467v2",
      "published_date": "2024-12-11 15:32:24 UTC",
      "updated_date": "2025-02-28 08:06:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:09:32.347767"
    },
    {
      "arxiv_id": "2412.12161v2",
      "title": "Discover physical concepts and equations with machine learning",
      "title_zh": "通过机器学习发现物理概念和方程",
      "authors": [
        "Bao-Bing Li",
        "Yi Gu",
        "Shao-Feng Wu"
      ],
      "abstract": "Machine learning can uncover physical concepts or physical equations when\nprior knowledge from the other is available. However, these two aspects are\noften intertwined and cannot be discovered independently. We extend SciNet,\nwhich is a neural network architecture that simulates the human physical\nreasoning process for physics discovery, by proposing a model that combines\nVariational Autoencoders (VAE) with Neural Ordinary Differential Equations\n(Neural ODEs). This allows us to simultaneously discover physical concepts and\ngoverning equations from simulated experimental data across various physical\nsystems. We apply the model to several examples inspired by the history of\nphysics, including Copernicus' heliocentrism, Newton's law of gravity,\nSchr\\\"odinger's wave mechanics, and Pauli's spin-magnetic formulation. The\nresults demonstrate that the correct physical theories can emerge in the neural\nnetwork.",
      "tldr_zh": "本研究提出了一种扩展 SciNet 架构的模型，通过结合 Variational Autoencoders (VAE) 和 Neural Ordinary Differential Equations (Neural ODEs)，从模拟实验数据中同时发现物理概念和 governing equations，从而解决两者相互依赖的挑战。  \n该模型应用于历史物理案例，包括 Copernicus 的 heliocentrism、Newton 的 law of gravity、Schrödinger's wave mechanics 和 Pauli's spin-magnetic formulation。  \n实验结果表明，神经网络能够从数据中浮现正确的物理理论，为机器学习在物理发现中的应用提供了新途径。",
      "categories": [
        "cs.LG",
        "cond-mat.dis-nn",
        "cs.AI",
        "physics.comp-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.12161v2",
      "published_date": "2024-12-11 15:30:21 UTC",
      "updated_date": "2025-04-22 22:11:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:09:43.365201"
    },
    {
      "arxiv_id": "2412.08463v1",
      "title": "IRL for Restless Multi-Armed Bandits with Applications in Maternal and Child Health",
      "title_zh": "翻译失败",
      "authors": [
        "Gauri Jain",
        "Pradeep Varakantham",
        "Haifeng Xu",
        "Aparna Taneja",
        "Prashant Doshi",
        "Milind Tambe"
      ],
      "abstract": "Public health practitioners often have the goal of monitoring patients and\nmaximizing patients' time spent in \"favorable\" or healthy states while being\nconstrained to using limited resources. Restless multi-armed bandits (RMAB) are\nan effective model to solve this problem as they are helpful to allocate\nlimited resources among many agents under resource constraints, where patients\nbehave differently depending on whether they are intervened on or not. However,\nRMABs assume the reward function is known. This is unrealistic in many public\nhealth settings because patients face unique challenges and it is impossible\nfor a human to know who is most deserving of any intervention at such a large\nscale. To address this shortcoming, this paper is the first to present the use\nof inverse reinforcement learning (IRL) to learn desired rewards for RMABs, and\nwe demonstrate improved outcomes in a maternal and child health telehealth\nprogram. First we allow public health experts to specify their goals at an\naggregate or population level and propose an algorithm to design expert\ntrajectories at scale based on those goals. Second, our algorithm WHIRL uses\ngradient updates to optimize the objective, allowing for efficient and accurate\nlearning of RMAB rewards. Third, we compare with existing baselines and\noutperform those in terms of run-time and accuracy. Finally, we evaluate and\nshow the usefulness of WHIRL on thousands on beneficiaries from a real-world\nmaternal and child health setting in India. We publicly release our code here:\nhttps://github.com/Gjain234/WHIRL.",
      "tldr_zh": "该研究针对公共卫生领域的资源有限问题，提出使用Inverse Reinforcement Learning (IRL)来学习Restless Multi-Armed Bandits (RMAB)的奖励函数，以优化患者健康状态管理。研究者开发了WHIRL算法，允许专家在总体水平指定目标，通过梯度更新高效优化RMAB奖励，并生成大规模专家轨迹。实验结果显示，WHIRL在运行时间和准确性上优于现有基准，并在印度的真实母婴健康项目中实现了更好的干预效果，并公开了代码以供进一步应用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.08463v1",
      "published_date": "2024-12-11 15:28:04 UTC",
      "updated_date": "2024-12-11 15:28:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:09:55.139557"
    },
    {
      "arxiv_id": "2412.08460v2",
      "title": "Federated Learning for Traffic Flow Prediction with Synthetic Data Augmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Fermin Orozco",
        "Pedro Porto Buarque de Gusmão",
        "Hongkai Wen",
        "Johan Wahlström",
        "Man Luo"
      ],
      "abstract": "Deep-learning based traffic prediction models require vast amounts of data to\nlearn embedded spatial and temporal dependencies. The inherent privacy and\ncommercial sensitivity of such data has encouraged a shift towards\ndecentralised data-driven methods, such as Federated Learning (FL). Under a\ntraditional Machine Learning paradigm, traffic flow prediction models can\ncapture spatial and temporal relationships within centralised data. In reality,\ntraffic data is likely distributed across separate data silos owned by multiple\nstakeholders. In this work, a cross-silo FL setting is motivated to facilitate\nstakeholder collaboration for optimal traffic flow prediction applications.\nThis work introduces an FL framework, referred to as FedTPS, to generate\nsynthetic data to augment each client's local dataset by training a\ndiffusion-based trajectory generation model through FL. The proposed framework\nis evaluated on a large-scale real world ride-sharing dataset using various FL\nmethods and Traffic Flow Prediction models, including a novel prediction model\nwe introduce, which leverages Temporal and Graph Attention mechanisms to learn\nthe Spatio-Temporal dependencies embedded within regional traffic flow data.\nExperimental results show that FedTPS outperforms multiple other FL baselines\nwith respect to global model performance.",
      "tldr_zh": "该研究针对交通流量预测模型对大量数据的依赖及其隐私敏感性，提出了一种基于 Federated Learning (FL) 的框架 FedTPS。该框架通过训练一个 diffusion-based trajectory generation model 来生成合成数据，从而增强每个客户端的本地数据集，并捕捉时空依赖性。FedTPS 引入了一个新颖的预测模型，利用 Temporal and Graph Attention 机制学习区域交通数据的时空关系。实验结果显示，在大规模真实世界乘车共享数据集上，FedTPS 在全局模型性能上优于其他 FL 基准。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC",
        "I.2.1; I.2.11"
      ],
      "primary_category": "cs.LG",
      "comment": "11 pages, 7 figures, 6 tables, ACM format",
      "pdf_url": "http://arxiv.org/pdf/2412.08460v2",
      "published_date": "2024-12-11 15:25:38 UTC",
      "updated_date": "2025-03-20 13:29:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:10:07.557708"
    },
    {
      "arxiv_id": "2412.08457v2",
      "title": "Efficient Rectification of Neuro-Symbolic Reasoning Inconsistencies by Abductive Reflection",
      "title_zh": "翻译失败",
      "authors": [
        "Wen-Chao Hu",
        "Wang-Zhou Dai",
        "Yuan Jiang",
        "Zhi-Hua Zhou"
      ],
      "abstract": "Neuro-Symbolic (NeSy) AI could be regarded as an analogy to human\ndual-process cognition, modeling the intuitive System 1 with neural networks\nand the algorithmic System 2 with symbolic reasoning. However, for complex\nlearning targets, NeSy systems often generate outputs inconsistent with domain\nknowledge and it is challenging to rectify them. Inspired by the human\nCognitive Reflection, which promptly detects errors in our intuitive response\nand revises them by invoking the System 2 reasoning, we propose to improve NeSy\nsystems by introducing Abductive Reflection (ABL-Refl) based on the Abductive\nLearning (ABL) framework. ABL-Refl leverages domain knowledge to abduce a\nreflection vector during training, which can then flag potential errors in the\nneural network outputs and invoke abduction to rectify them and generate\nconsistent outputs during inference. ABL-Refl is highly efficient in contrast\nto previous ABL implementations. Experiments show that ABL-Refl outperforms\nstate-of-the-art NeSy methods, achieving excellent accuracy with fewer training\nresources and enhanced efficiency.",
      "tldr_zh": "该论文探讨了 Neuro-Symbolic (NeSy) AI 系统在复杂任务中输出与领域知识不一致的问题，并提出 Abductive Reflection (ABL-Refl) 方法，受人类认知反射启发，基于 Abductive Learning (ABL) 框架来高效修正这些不一致。ABL-Refl 在训练过程中利用领域知识推断反射向量，以标记神经网络输出的潜在错误，并在推理阶段通过诱导修正生成一致的输出。实验结果表明，该方法超越了现有 NeSy 方法，实现了更高的准确率，同时显著减少了训练资源和提高了整体效率。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by AAAI 2025, Oral",
      "pdf_url": "http://arxiv.org/pdf/2412.08457v2",
      "published_date": "2024-12-11 15:24:07 UTC",
      "updated_date": "2025-02-08 01:31:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:10:20.599350"
    },
    {
      "arxiv_id": "2412.08445v1",
      "title": "TapeAgents: a Holistic Framework for Agent Development and Optimization",
      "title_zh": "TapeAgents",
      "authors": [
        "Dzmitry Bahdanau",
        "Nicolas Gontier",
        "Gabriel Huang",
        "Ehsan Kamalloo",
        "Rafael Pardinas",
        "Alex Piché",
        "Torsten Scholak",
        "Oleh Shliazhko",
        "Jordan Prince Tremblay",
        "Karam Ghanem",
        "Soham Parikh",
        "Mitul Tiwari",
        "Quaizar Vohra"
      ],
      "abstract": "We present TapeAgents, an agent framework built around a granular, structured\nlog tape of the agent session that also plays the role of the session's\nresumable state. In TapeAgents we leverage tapes to facilitate all stages of\nthe LLM Agent development lifecycle. The agent reasons by processing the tape\nand the LLM output to produce new thought and action steps and append them to\nthe tape. The environment then reacts to the agent's actions by likewise\nappending observation steps to the tape. By virtue of this tape-centred design,\nTapeAgents can provide AI practitioners with holistic end-to-end support. At\nthe development stage, tapes facilitate session persistence, agent auditing,\nand step-by-step debugging. Post-deployment, one can reuse tapes for\nevaluation, fine-tuning, and prompt-tuning; crucially, one can adapt tapes from\nother agents or use revised historical tapes. In this report, we explain the\nTapeAgents design in detail. We demonstrate possible applications of TapeAgents\nwith several concrete examples of building monolithic agents and multi-agent\nteams, of optimizing agent prompts and finetuning the agent's LLM. We present\ntooling prototypes and report a case study where we use TapeAgents to finetune\na Llama-3.1-8B form-filling assistant to perform as well as GPT-4o while being\norders of magnitude cheaper. Lastly, our comparative analysis shows that\nTapeAgents's advantages over prior frameworks stem from our novel design of the\nLLM agent as a resumable, modular state machine with a structured\nconfiguration, that generates granular, structured logs and that can transform\nthese logs into training text -- a unique combination of features absent in\nprevious work.",
      "tldr_zh": "我们介绍了TapeAgents，一种基于结构化日志磁带（log tape）的整体框架，用于LLM代理的开发和优化，该框架将磁带作为会话状态，实现代理推理、环境交互以及生命周期各阶段的支持，如调试、评估和微调。TapeAgents允许重用或修改历史磁带来构建单体代理或多代理团队，并优化代理提示。实验案例显示，通过TapeAgents微调Llama-3.1-8B模型，其在表单填写任务上的性能可媲美GPT-4o，但成本低几个数量级；相比现有框架，该设计突出了代理作为可恢复模块化状态机的优势，提供粒度化日志和训练文本转换功能。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.08445v1",
      "published_date": "2024-12-11 15:09:54 UTC",
      "updated_date": "2024-12-11 15:09:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:10:32.758859"
    },
    {
      "arxiv_id": "2412.08435v3",
      "title": "Proactive Model Adaptation Against Concept Drift for Online Time Series Forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Lifan Zhao",
        "Yanyan Shen"
      ],
      "abstract": "Time series forecasting always faces the challenge of concept drift, where\ndata distributions evolve over time, leading to a decline in forecast model\nperformance. Existing solutions are based on online learning, which continually\norganize recent time series observations as new training samples and update\nmodel parameters according to the forecasting feedback on recent data. However,\nthey overlook a critical issue: obtaining ground-truth future values of each\nsample should be delayed until after the forecast horizon. This delay creates a\ntemporal gap between the training samples and the test sample. Our empirical\nanalysis reveals that the gap can introduce concept drift, causing forecast\nmodels to adapt to outdated concepts. In this paper, we present Proceed, a\nnovel proactive model adaptation framework for online time series forecasting.\nProceed first estimates the concept drift between the recently used training\nsamples and the current test sample. It then employs an adaptation generator to\nefficiently translate the estimated drift into parameter adjustments,\nproactively adapting the model to the test sample. To enhance the\ngeneralization capability of the framework, Proceed is trained on synthetic\ndiverse concept drifts. Extensive experiments on five real-world datasets\nacross various forecast models demonstrate that Proceed brings more performance\nimprovements than the state-of-the-art online learning methods, significantly\nfacilitating forecast models' resilience against concept drifts. Code is\navailable at https://github.com/SJTU-DMTai/OnlineTSF.",
      "tldr_zh": "该研究针对时间序列预测中的concept drift问题，提出了一种主动模型适应框架Proceed，以解决现有在线学习方法忽略的训练样本延迟问题，导致模型适应过时概念。Proceed框架首先估计最近训练样本与当前测试样本之间的concept drift，然后通过适应生成器高效地将漂移转化为模型参数调整，并在合成多样concept drifts上训练以提升泛化能力。在五个真实数据集上的实验显示，Proceed显著优于现有在线学习方法，提高了预测模型对concept drift的抵抗力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by KDD 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.08435v3",
      "published_date": "2024-12-11 14:57:10 UTC",
      "updated_date": "2025-02-07 13:54:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:10:43.681005"
    },
    {
      "arxiv_id": "2412.08434v2",
      "title": "Mitigating Out-of-Entity Errors in Named Entity Recognition: A Sentence-Level Strategy",
      "title_zh": "缓解命名实体识别中的实体外错误：一种句子级策略",
      "authors": [
        "Guochao Jiang",
        "Ziqin Luo",
        "Chengwei Hu",
        "Zepeng Ding",
        "Deqing Yang"
      ],
      "abstract": "Many previous models of named entity recognition (NER) suffer from the\nproblem of Out-of-Entity (OOE), i.e., the tokens in the entity mentions of the\ntest samples have not appeared in the training samples, which hinders the\nachievement of satisfactory performance. To improve OOE-NER performance, in\nthis paper, we propose a new framework, namely S+NER, which fully leverages\nsentence-level information. Our S+NER achieves better OOE-NER performance\nmainly due to the following two particular designs. 1) It first exploits the\npre-trained language model's capability of understanding the target entity's\nsentence-level context with a template set. 2) Then, it refines the\nsentence-level representation based on the positive and negative templates,\nthrough a contrastive learning strategy and template pooling method, to obtain\nbetter NER results. Our extensive experiments on five benchmark datasets have\ndemonstrated that, our S+NER outperforms some state-of-the-art OOE-NER models.",
      "tldr_zh": "本论文针对命名实体识别(NER)中的Out-of-Entity (OOE)问题——即测试样本实体标记在训练样本中未出现导致性能下降——提出了一种新的框架S+NER，该框架充分利用句子级信息来提升OOE-NER效果。S+NER的关键设计包括：利用预训练语言模型理解目标实体的句子级上下文，通过一组模板进行处理；并通过对比学习策略和模板池化方法，基于正负模板精炼句子级表示，以获得更准确的NER结果。在五个基准数据集上的广泛实验表明，S+NER超过了现有的最先进OOE-NER模型，证明了其有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by COLING 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.08434v2",
      "published_date": "2024-12-11 14:55:48 UTC",
      "updated_date": "2025-01-13 14:13:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:10:54.998026"
    },
    {
      "arxiv_id": "2412.08430v1",
      "title": "Assessing Personalized AI Mentoring with Large Language Models in the Computing Field",
      "title_zh": "翻译失败",
      "authors": [
        "Xiao Luo",
        "Sean O'Connell",
        "Shamima Mithun"
      ],
      "abstract": "This paper provides an in-depth evaluation of three state-of-the-art Large\nLanguage Models (LLMs) for personalized career mentoring in the computing\nfield, using three distinct student profiles that consider gender, race, and\nprofessional levels. We evaluated the performance of GPT-4, LLaMA 3, and Palm 2\nusing a zero-shot learning approach without human intervention. A quantitative\nevaluation was conducted through a custom natural language processing analytics\npipeline to highlight the uniqueness of the responses and to identify words\nreflecting each student's profile, including race, gender, or professional\nlevel. The analysis of frequently used words in the responses indicates that\nGPT-4 offers more personalized mentoring compared to the other two LLMs.\nAdditionally, a qualitative evaluation was performed to see if human experts\nreached similar conclusions. The analysis of survey responses shows that GPT-4\noutperformed the other two LLMs in delivering more accurate and useful\nmentoring while addressing specific challenges with encouragement languages.\nOur work establishes a foundation for developing personalized mentoring tools\nbased on LLMs, incorporating human mentors in the process to deliver a more\nimpactful and tailored mentoring experience.",
      "tldr_zh": "本研究评估了GPT-4、LLaMA 3和Palm 2等Large Language Models (LLMs)在计算机领域个性化职业指导中的表现，针对三种学生配置文件（考虑性别、种族和专业水平）进行零-shot learning评估。研究采用定量分析（如自然语言处理管道识别个性化词汇）和定性评估（如人类专家调查），结果显示GPT-4在响应独特性、准确性和鼓励语言上优于其他模型。总体而言，该工作为开发基于LLMs的个性化指导工具奠定了基础，并建议结合人类导师以提供更具影响力的指导体验。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.08430v1",
      "published_date": "2024-12-11 14:51:13 UTC",
      "updated_date": "2024-12-11 14:51:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:11:07.326111"
    },
    {
      "arxiv_id": "2412.08428v1",
      "title": "SwarmGPT-Primitive: A Language-Driven Choreographer for Drone Swarms Using Safe Motion Primitive Composition",
      "title_zh": "翻译失败",
      "authors": [
        "Vedant Vyas",
        "Martin Schuck",
        "Dinushka O. Dahanaggamaarachchi",
        "Siqi Zhou",
        "Angela P. Schoellig"
      ],
      "abstract": "Catalyzed by advancements in hardware and software, drone performances are\nincreasingly making their mark in the entertainment industry. However,\ndesigning smooth and safe choreographies for drone swarms is complex and often\nrequires expert domain knowledge. In this work, we introduce\nSwarmGPT-Primitive, a language-based choreographer that integrates the\nreasoning capabilities of large language models (LLMs) with safe motion\nplanning to facilitate deployable drone swarm choreographies. The LLM composes\nchoreographies for a given piece of music by utilizing a library of motion\nprimitives; the language-based choreographer is augmented with an\noptimization-based safety filter, which certifies the choreography for\nreal-world deployment by making minimal adjustments when feasibility and safety\nconstraints are violated. The overall SwarmGPT-Primitive framework decouples\nchoreographic design from safe motion planning, which allows non-expert users\nto re-prompt and refine compositions without concerns about compliance with\nconstraints such as avoiding collisions or downwash effects or satisfying\nactuation limits. We demonstrate our approach through simulations and\nexperiments with swarms of up to 20 drones performing choreographies designed\nbased on various songs, highlighting the system's ability to generate effective\nand synchronized drone choreographies for real-world deployment.",
      "tldr_zh": "本论文提出SwarmGPT-Primitive，一种基于语言驱动的编舞系统，用于无人机群（drone swarms）的安全编排设计。系统整合大型语言模型（LLMs）的推理能力与运动基元（motion primitives）库，由LLMs根据给定音乐创作编舞，并通过优化-based safety filter进行最小调整，以确保满足可行性和安全约束，如避免碰撞或满足执行限制。该框架将编舞设计与安全运动规划（safe motion planning）解耦，允许非专家用户轻松重新提示和优化编舞。实验在模拟和真实环境中证明，该系统能为多达20架无人机生成有效且同步的编舞，支持实际部署。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "Submitted to ICRA 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.08428v1",
      "published_date": "2024-12-11 14:48:19 UTC",
      "updated_date": "2024-12-11 14:48:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:11:19.220944"
    },
    {
      "arxiv_id": "2412.12160v1",
      "title": "Climate Aware Deep Neural Networks (CADNN) for Wind Power Simulation",
      "title_zh": "气候感知深度神经网络 (CADNN) 用于风力发电模拟",
      "authors": [
        "Ali Forootani",
        "Danial Esmaeili Aliabadi",
        "Daniela Thraen"
      ],
      "abstract": "Wind power forecasting plays a critical role in modern energy systems,\nfacilitating the integration of renewable energy sources into the power grid.\nAccurate prediction of wind energy output is essential for managing the\ninherent intermittency of wind power, optimizing energy dispatch, and ensuring\ngrid stability. This paper proposes the use of Deep Neural Network (DNN)-based\npredictive models that leverage climate datasets, including wind speed,\natmospheric pressure, temperature, and other meteorological variables, to\nimprove the accuracy of wind power simulations. In particular, we focus on the\nCoupled Model Intercomparison Project (CMIP) datasets, which provide climate\nprojections, as inputs for training the DNN models. These models aim to capture\nthe complex nonlinear relationships between the CMIP-based climate data and\nactual wind power generation at wind farms located in Germany. Our study\ncompares various DNN architectures, specifically Multilayer Perceptron (MLP),\nLong Short-Term Memory (LSTM) networks, and Transformer-enhanced LSTM models,\nto identify the best configuration among these architectures for climate-aware\nwind power simulation. The implementation of this framework involves the\ndevelopment of a Python package (CADNN) designed to support multiple tasks,\nincluding statistical analysis of the climate data, data visualization,\npreprocessing, DNN training, and performance evaluation. We demonstrate that\nthe DNN models, when integrated with climate data, significantly enhance\nforecasting accuracy. This climate-aware approach offers a deeper understanding\nof the time-dependent climate patterns that influence wind power generation,\nproviding more accurate predictions and making it adaptable to other\ngeographical regions.",
      "tldr_zh": "本论文提出 Climate Aware Deep Neural Networks (CADNN)，一种利用气候数据集（如风速、气压和温度等）来提升风力发电模拟准确性的 DNN 框架，旨在解决风能间歇性问题并优化电网稳定性。研究使用 Coupled Model Intercomparison Project (CMIP) 数据作为输入，比较了 Multilayer Perceptron (MLP)、Long Short-Term Memory (LSTM) 和 Transformer-enhanced LSTM 等架构，捕捉气候数据与德国风电场发电之间的复杂非线性关系。结果显示，CADNN 显著提高了预测准确性，提供对时间依赖气候模式更深入的理解，并通过开发的 Python 包支持数据处理、训练和评估，可扩展至其他地区。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.12160v1",
      "published_date": "2024-12-11 14:22:52 UTC",
      "updated_date": "2024-12-11 14:22:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:11:32.896557"
    },
    {
      "arxiv_id": "2412.08392v1",
      "title": "The Roles of English in Evaluating Multilingual Language Models",
      "title_zh": "English 在评估多语言语言模型中的角色",
      "authors": [
        "Wessel Poelman",
        "Miryam de Lhoneux"
      ],
      "abstract": "Multilingual natural language processing is getting increased attention, with\nnumerous models, benchmarks, and methods being released for many languages.\nEnglish is often used in multilingual evaluation to prompt language models\n(LMs), mainly to overcome the lack of instruction tuning data in other\nlanguages. In this position paper, we lay out two roles of English in\nmultilingual LM evaluations: as an interface and as a natural language. We\nargue that these roles have different goals: task performance versus language\nunderstanding. This discrepancy is highlighted with examples from datasets and\nevaluation setups. Numerous works explicitly use English as an interface to\nboost task performance. We recommend to move away from this imprecise method\nand instead focus on furthering language understanding.",
      "tldr_zh": "这篇论文探讨了英语在评估多语言语言模型(Multilingual Language Models)中的两个角色：作为接口和作为自然语言。作者指出，这些角色存在目标差异，前者旨在提升任务性能，而后者则侧重于语言理解，通过数据集和评估设置的例子来突出这一问题。论文建议放弃使用英语作为接口来提升任务性能，转而专注于推进多语言的语言理解，以实现更精确的模型评估。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "NoDaLiDa 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.08392v1",
      "published_date": "2024-12-11 14:02:55 UTC",
      "updated_date": "2024-12-11 14:02:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:11:42.510864"
    },
    {
      "arxiv_id": "2412.08385v1",
      "title": "NyayaAnumana & INLegalLlama: The Largest Indian Legal Judgment Prediction Dataset and Specialized Language Model for Enhanced Decision Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Shubham Kumar Nigam",
        "Balaramamahanthi Deepak Patnaik",
        "Shivam Mishra",
        "Noel Shallum",
        "Kripabandhu Ghosh",
        "Arnab Bhattacharya"
      ],
      "abstract": "The integration of artificial intelligence (AI) in legal judgment prediction\n(LJP) has the potential to transform the legal landscape, particularly in\njurisdictions like India, where a significant backlog of cases burdens the\nlegal system. This paper introduces NyayaAnumana, the largest and most diverse\ncorpus of Indian legal cases compiled for LJP, encompassing a total of 7,02,945\npreprocessed cases. NyayaAnumana, which combines the words \"Nyay\" (judgment)\nand \"Anuman\" (prediction or inference) respectively for most major Indian\nlanguages, includes a wide range of cases from the Supreme Court, High Courts,\nTribunal Courts, District Courts, and Daily Orders and, thus, provides\nunparalleled diversity and coverage. Our dataset surpasses existing datasets\nlike PredEx and ILDC, offering a comprehensive foundation for advanced AI\nresearch in the legal domain.\n  In addition to the dataset, we present INLegalLlama, a domain-specific\ngenerative large language model (LLM) tailored to the intricacies of the Indian\nlegal system. It is developed through a two-phase training approach over a base\nLLaMa model. First, Indian legal documents are injected using continual\npretraining. Second, task-specific supervised finetuning is done. This method\nallows the model to achieve a deeper understanding of legal contexts.\n  Our experiments demonstrate that incorporating diverse court data\nsignificantly boosts model accuracy, achieving approximately 90% F1-score in\nprediction tasks. INLegalLlama not only improves prediction accuracy but also\noffers comprehensible explanations, addressing the need for explainability in\nAI-assisted legal decisions.",
      "tldr_zh": "本文介绍了 NyayaAnumana，这是最大的印度法律判断预测 (LJP) 数据集，包含 702,945 个预处理案件，覆盖从最高法院到地区法院的多样化来源，并超越了现有数据集如 PredEx 和 ILDC，提供更全面的 AI 研究基础。作者同时提出了 INLegalLlama，一个针对印度法律系统的专用大语言模型 (LLM)，通过两阶段训练（持续预训练注入法律文档和任务特定监督微调）来提升模型对法律语境的理解。实验结果显示，该模型在预测任务中达到约 90% F1-score，不仅提高了准确性，还提供了可解释的解释，支持 AI 在法律决策中的可信应用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted on COLING 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.08385v1",
      "published_date": "2024-12-11 13:50:17 UTC",
      "updated_date": "2024-12-11 13:50:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:11:56.912032"
    },
    {
      "arxiv_id": "2412.10443v3",
      "title": "SweetTok: Semantic-Aware Spatial-Temporal Tokenizer for Compact Video Discretization",
      "title_zh": "翻译失败",
      "authors": [
        "Zhentao Tan",
        "Ben Xue",
        "Jian Jia",
        "Junhao Wang",
        "Wencai Ye",
        "Shaoyun Shi",
        "Mingjie Sun",
        "Wenjin Wu",
        "Quan Chen",
        "Peng Jiang"
      ],
      "abstract": "This paper presents the \\textbf{S}emantic-a\\textbf{W}ar\\textbf{E}\nspatial-t\\textbf{E}mporal \\textbf{T}okenizer (SweetTok), a novel video\ntokenizer to overcome the limitations in current video tokenization methods for\ncompacted yet effective discretization. Unlike previous approaches that process\nflattened local visual patches via direct discretization or adaptive query\ntokenization, SweetTok proposes a decoupling framework, compressing visual\ninputs through distinct spatial and temporal queries via \\textbf{D}ecoupled\n\\textbf{Q}uery \\textbf{A}uto\\textbf{E}ncoder (DQAE). This design allows\nSweetTok to efficiently compress video token count while achieving superior\nfidelity by capturing essential information across spatial and temporal\ndimensions. Furthermore, we design a \\textbf{M}otion-enhanced \\textbf{L}anguage\n\\textbf{C}odebook (MLC) tailored for spatial and temporal compression to\naddress the differences in semantic representation between appearance and\nmotion information. SweetTok significantly improves video reconstruction\nresults by \\textbf{42.8\\%} w.r.t rFVD on UCF-101 dataset. With a better token\ncompression strategy, it also boosts downstream video generation results by\n\\textbf{15.1\\%} w.r.t gFVD. Additionally, the compressed decoupled tokens are\nimbued with semantic information, enabling few-shot recognition capabilities\npowered by LLMs in downstream applications.",
      "tldr_zh": "本论文提出 SweetTok，一种语义感知的空间-时间分词器，用于实现紧凑且有效的视频离散化。它采用解耦框架，通过 Decoupled Query AutoEncoder (DQAE) 分别处理空间和时间查询，并引入 Motion-enhanced Language Codebook (MLC) 来优化外观和运动信息的语义表示，从而显著减少 token 数量同时保持高保真度。在 UCF-101 数据集上，SweetTok 使视频重建性能提升 42.8% (rFVD)，视频生成性能提升 15.1% (gFVD)，并赋予压缩 token 以语义信息，支持 LLMs 在下游应用的少样本识别任务。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.10443v3",
      "published_date": "2024-12-11 13:48:06 UTC",
      "updated_date": "2025-03-11 03:19:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:12:08.481585"
    },
    {
      "arxiv_id": "2412.08378v3",
      "title": "FILA: Fine-Grained Vision Language Models",
      "title_zh": "FILA: 细粒度视觉语言模型",
      "authors": [
        "Shiding Zhu",
        "Wenhui Dong",
        "Jun Song",
        "Yingbo Wang",
        "Yanan Guo",
        "Bo Zheng"
      ],
      "abstract": "Recently, there has been growing interest in the capability of multimodal\nlarge language models (MLLMs) to process high-resolution images. A common\napproach currently involves dynamically cropping the original high-resolution\nimage into smaller sub-images, which are then fed into a vision encoder that\nwas pre-trained on lower-resolution images. However, this cropping approach\noften truncates objects and connected areas in the original image, causing\nsemantic breaks. To address this limitation, we introduce HyViLM, designed to\nprocess images of any resolution while retaining the overall context during\nencoding. Specifically, we: (i) Design a new visual encoder called Hybrid\nEncoder that not only encodes individual sub-images but also interacts with\ndetailed global visual features, significantly improving the model's ability to\nencode high-resolution images. (ii) Propose an optimal feature fusion strategy\nfor the dynamic cropping approach, effectively leveraging information from\ndifferent layers of the vision encoder. Compared with the state-of-the-art\nMLLMs under the same setting, our HyViLM outperforms existing MLLMs in nine out\nof ten tasks. Specifically, HyViLM achieves a 9.6% improvement in performance\non the TextVQA task and a 6.9% enhancement on the DocVQA task.",
      "tldr_zh": "本文提出 FILA（Fine-Grained Vision Language Models），一种改进多模态大型语言模型 (MLLMs) 处理高分辨率图像的方法，以解决动态裁剪导致的对象截断和语义中断问题。核心创新包括设计 Hybrid Encoder 视觉编码器，该编码器不仅处理单个子图像，还与详细的全局视觉特征交互，并提出一个最佳特征融合策略来利用视觉编码器不同层的信息。实验结果显示，FILA 在相同设置下优于现有 MLLMs，在十个任务中胜出九个，具体在 TextVQA 任务上提升 9.6%、DocVQA 任务上提升 6.9%。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "9 pages, 4 figures, accepted to ICLR 2025 workshop",
      "pdf_url": "http://arxiv.org/pdf/2412.08378v3",
      "published_date": "2024-12-11 13:41:21 UTC",
      "updated_date": "2025-04-30 08:49:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:12:22.342048"
    },
    {
      "arxiv_id": "2412.08360v1",
      "title": "Agency and Morality as part of Text Entry AI Assistant Personas",
      "title_zh": "翻译失败",
      "authors": [
        "Andreas Komninos"
      ],
      "abstract": "This paper discusses the need to move away from an instrumental view of text\ncomposition AI assistants under direct control of the user, towards a more\nagentic approach that is based on a value rationale. Based on an analysis of\nmoral dimensions of AI assistance in computer mediated communication, the paper\nproposes basic guidelines for designing the agent's persona.",
      "tldr_zh": "这篇论文主张从用户直接控制的工具性视角，转向基于价值理性的代理性（agency）方法，以提升文本输入AI助手的自主性。通过分析AI在计算机中介通信中的道德（morality）维度，论文揭示了AI助手设计中的潜在伦理挑战。最终，论文提出了设计AI助手人格的基本指南，以促进更负责任和有效的AI应用。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.08360v1",
      "published_date": "2024-12-11 13:06:24 UTC",
      "updated_date": "2024-12-11 13:06:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:12:31.649180"
    },
    {
      "arxiv_id": "2412.12159v1",
      "title": "Personalized Sleep Staging Leveraging Source-free Unsupervised Domain Adaptation",
      "title_zh": "翻译失败",
      "authors": [
        "Yangxuan Zhou",
        "Sha Zhao",
        "Jiquan Wang",
        "Haiteng Jiang",
        "hijian Li",
        "Benyan Luo",
        "Tao Li",
        "Gang Pan"
      ],
      "abstract": "Sleep staging is crucial for assessing sleep quality and diagnosing related\ndisorders. Recent deep learning models for automatic sleep staging using\npolysomnography often suffer from poor generalization to new subjects because\nthey are trained and tested on the same labeled datasets, overlooking\nindividual differences. To tackle this issue, we propose a novel Source-Free\nUnsupervised Individual Domain Adaptation (SF-UIDA) framework. This two-step\nadaptation scheme allows the model to effectively adjust to new unlabeled\nindividuals without needing source data, facilitating personalized\ncustomization in clinical settings. Our framework has been applied to three\nestablished sleep staging models and tested on three public datasets, achieving\nstate-of-the-art performance.",
      "tldr_zh": "该研究针对睡眠分期（sleep staging）中深度学习模型的泛化问题，提出了一种创新的 Source-Free Unsupervised Individual Domain Adaptation (SF-UIDA) 框架，以应对模型在新个体上的适应性不足。SF-UIDA 采用两步适应方案，在无需源数据的情况下，通过无监督方式实现模型对未标记新个体的个性化定制，便于临床应用。该框架已应用于三个已建立的睡眠分期模型，并在三个公共数据集上测试，取得了最先进性能，显著提升了个性化睡眠评估的准确性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.12159v1",
      "published_date": "2024-12-11 12:59:36 UTC",
      "updated_date": "2024-12-11 12:59:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:12:43.376863"
    },
    {
      "arxiv_id": "2412.08347v1",
      "title": "SmolTulu: Higher Learning Rate to Batch Size Ratios Can Lead to Better Reasoning in SLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Sultan Alrashed"
      ],
      "abstract": "We present SmolTulu-1.7b-Instruct, referenced in this report as\nSmolTulu-DPO-1130, an instruction-tuned language model that adapts AllenAI's\nTulu 3 post-training pipeline to enhance Huggingface's SmolLM2-1.7B base model.\nThrough comprehensive empirical analysis using a 135M parameter model, we\ndemonstrate that the relationship between learning rate and batch size\nsignificantly impacts model performance in a task-dependent manner. Our\nfindings reveal a clear split: reasoning tasks like ARC and GSM8K benefit from\nhigher learning rate to batch size ratios, while pattern recognition tasks such\nas HellaSwag and IFEval show optimal performance with lower ratios. These\ninsights informed the development of SmolTulu, which achieves state-of-the-art\nperformance among sub-2B parameter models on instruction following, scoring\n67.7% on IFEval ($\\Delta$11%), and mathematical reasoning with 51.6% on GSM8K\n($\\Delta$3.4%), with an alternate version achieving scoring 57.1% on ARC\n($\\Delta5.4%$). We release our model, training recipes, and ablation studies to\nfacilitate further research in efficient model alignment, demonstrating that\ncareful adaptation of optimization dynamics can help bridge the capability gap\nbetween small and large language models.",
      "tldr_zh": "本研究介绍了 SmolTulu-1.7b-Instruct（简称 SmolTulu-DPO-1130），一种基于 AllenAI 的 Tulu 3 后训练管道，对 Huggingface 的 SmolLM2-1.7B 基础模型进行指令微调的语言模型。研究通过对 135M 参数模型的实证分析，发现学习率到批量大小比例对任务性能有显著影响：推理任务如 ARC 和 GSM8K 受益于更高比例，而模式识别任务如 HellaSwag 和 IFEval 则在较低比例下表现最佳。SmolTulu 实现了子2B 参数模型的领先性能，在 IFEval 上得分 67.7%（提升 11%）、GSM8K 上 51.6%（提升 3.4%），并在 ARC 上达到 57.1%（提升 5.4%），证明优化动态能缩小小型语言模型 (SLMs) 与大型模型的能力差距，并发布了模型、训练配方和消融研究以支持进一步探索。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages, 4 figures, and 13 tables. For the SmolTulu-1.7b-instruct\n  model, see: https://huggingface.co/SultanR/SmolTulu-1.7b-Instruct",
      "pdf_url": "http://arxiv.org/pdf/2412.08347v1",
      "published_date": "2024-12-11 12:41:36 UTC",
      "updated_date": "2024-12-11 12:41:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:12:58.728785"
    },
    {
      "arxiv_id": "2412.12158v1",
      "title": "Hyperbolic Hypergraph Neural Networks for Multi-Relational Knowledge Hypergraph Representation",
      "title_zh": "翻译失败",
      "authors": [
        "Mengfan Li",
        "Xuanhua Shi",
        "Chenqi Qiao",
        "Teng Zhang",
        "Hai Jin"
      ],
      "abstract": "Knowledge hypergraphs generalize knowledge graphs using hyperedges to connect\nmultiple entities and depict complicated relations. Existing methods either\ntransform hyperedges into an easier-to-handle set of binary relations or view\nhyperedges as isolated and ignore their adjacencies. Both approaches have\ninformation loss and may potentially lead to the creation of sub-optimal\nmodels. To fix these issues, we propose the Hyperbolic Hypergraph Neural\nNetwork (H2GNN), whose essential component is the hyper-star message passing, a\nnovel scheme motivated by a lossless expansion of hyperedges into hierarchies.\nIt implements a direct embedding that consciously incorporates adjacent\nentities, hyper-relations, and entity position-aware information. As the name\nsuggests, H2GNN operates in the hyperbolic space, which is more adept at\ncapturing the tree-like hierarchy. We compare H2GNN with 15 baselines on\nknowledge hypergraphs, and it outperforms state-of-the-art approaches in both\nnode classification and link prediction tasks.",
      "tldr_zh": "该研究针对知识超图（knowledge hypergraphs）的复杂关系建模问题，指出现有方法在处理超边（hyperedges）时存在信息损失，如将超边转化为二元关系或忽略邻接关系。作者提出Hyperbolic Hypergraph Neural Network (H2GNN)，其核心是hyper-star message passing机制，通过无损扩展超边为层次结构，直接嵌入相邻实体、超关系和实体位置信息，并在hyperbolic space中操作，以更好地捕捉树状层次结构。在节点分类和链接预测任务上，H2GNN与15个基线模型比较，表现出色，实现了最先进性能的提升。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.12158v1",
      "published_date": "2024-12-11 12:03:33 UTC",
      "updated_date": "2024-12-11 12:03:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:13:08.735594"
    },
    {
      "arxiv_id": "2412.10442v2",
      "title": "Steganography in Game Actions",
      "title_zh": "游戏动作中的隐写术",
      "authors": [
        "Ching-Chun Chang",
        "Isao Echizen"
      ],
      "abstract": "The exchange of messages has always carried with it the timeless challenge of\nsecrecy. From whispers in shadows to the enigmatic notes written in the margins\nof history, humanity has long sought ways to convey thoughts that remain\nimperceptible to all but the chosen few. The challenge of subliminal\ncommunication has been addressed in various forms of steganography. However,\nthe field faces a fundamental paradox: as the art of concealment advances, so\ntoo does the science of revelation, leading to an ongoing evolutionary\ninterplay. This study seeks to extend the boundaries of what is considered a\nviable steganographic medium. We explore a steganographic paradigm, in which\nhidden information is communicated through the episodes of multiple agents\ninteracting with an environment. Each agent, acting as an encoder, learns a\npolicy to disguise the very existence of hidden messages within actions\nseemingly directed toward innocent objectives. Meanwhile, an observer, serving\nas a decoder, learns to associate behavioural patterns with their respective\nagents despite their dynamic nature, thereby unveiling the hidden messages. The\ninteractions of agents are governed by the framework of multi-agent\nreinforcement learning and shaped by feedback from the observer. This framework\nencapsulates a game-theoretic dilemma, wherein agents face decisions between\ncooperating to create distinguishable behavioural patterns or defecting to\npursue individually optimal yet potentially overlapping episodic actions. As a\nproof of concept, we exemplify action steganography through the game of\nlabyrinth, a navigation task where subliminal communication is concealed within\nthe act of steering toward a destination, and systematically validate the\nstego-system in terms of distortion, capacity, secrecy and robustness when\nsubjected to simulated passive and active adversaries.",
      "tldr_zh": "本研究扩展了隐写术（steganography）的应用领域，提出一种通过多代理互动在游戏动作中隐藏信息的新范式。代理作为编码器，通过多代理强化学习（multi-agent reinforcement learning）框架学习策略，将隐藏消息伪装在看似无害的行为中，同时观察者作为解码器识别行为模式以解码信息。论文引入游戏理论困境，探讨代理在合作与缺陷间的决策权衡，并以“labyrinth”导航游戏为例，验证了系统的失真、容量、保密性和对被动及主动对手的鲁棒性。总体而言，此框架为隐秘通信提供了创新途径，提升了在动态环境中的实用性。",
      "categories": [
        "cs.AI",
        "cs.CR",
        "cs.MM"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.10442v2",
      "published_date": "2024-12-11 12:02:36 UTC",
      "updated_date": "2025-04-20 02:17:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:13:19.222578"
    },
    {
      "arxiv_id": "2412.12157v1",
      "title": "What Makes In-context Learning Effective for Mathematical Reasoning: A Theoretical Analysis",
      "title_zh": "是什么使上下文学习在",
      "authors": [
        "Jiayu Liu",
        "Zhenya Huang",
        "Chaokun Wang",
        "Xunpeng Huang",
        "Chengxiang Zhai",
        "Enhong Chen"
      ],
      "abstract": "Owing to the capability of in-context learning, large language models (LLMs)\nhave shown impressive performance across diverse mathematical reasoning\nbenchmarks. However, we find that few-shot demonstrations can sometimes bring\nnegative performance and their effectiveness on LLMs' reasoning abilities\nremains unreliable. To this end, in this paper, we aim to theoretically analyze\nthe impact of in-context demonstrations on LLMs' reasoning performance. We\nprove that the reasoning efficacy (measured by empirical prediction loss) can\nbe bounded by a LLM-oriented semantic similarity and an inference stability of\ndemonstrations, which is general for both one-shot and few-shot scenarios.\nBased on this finding, we propose a straightforward, generalizable, and\nlow-complexity demonstration selection method named LMS3. It can adaptively\nfacilitate to select the most pertinent samples for different LLMs and includes\na novel demonstration rejection mechanism to automatically filter out samples\nthat are unsuitable for few-shot learning. Through experiments on three\nrepresentative benchmarks, two LLM backbones, and multiple few-shot settings,\nwe verify that our LMS3 has superiority and achieves consistent improvements on\nall datasets, which existing methods have been unable to accomplish.",
      "tldr_zh": "本研究理论分析了 in-context learning 如何影响大型语言模型 (LLMs) 在数学推理中的有效性，发现 few-shot demonstrations 可能导致负面性能，导致推理能力不可靠。论文证明，推理效能（以经验预测损失衡量）可以由 LLM-oriented semantic similarity 和 inference stability 界定，这适用于 one-shot 和 few-shot 场景。基于此，作者提出了一种简单、通用的 LMS3 演示选择方法，包括自适应样本选择和演示拒绝机制；实验在三个代表性基准、两个 LLM 骨干和多种 few-shot 设置上验证，LMS3 实现了持续性能提升，而现有方法无法达到此效果。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.12157v1",
      "published_date": "2024-12-11 11:38:11 UTC",
      "updated_date": "2024-12-11 11:38:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:13:31.598246"
    },
    {
      "arxiv_id": "2412.10441v1",
      "title": "Novel 3D Binary Indexed Tree for Volume Computation of 3D Reconstructed Models from Volumetric Data",
      "title_zh": "翻译失败",
      "authors": [
        "Quoc-Bao Nguyen-Le",
        "Tuan-Hy Le",
        "Anh-Triet Do"
      ],
      "abstract": "In the burgeoning field of medical imaging, precise computation of 3D volume\nholds a significant importance for subsequent qualitative analysis of 3D\nreconstructed objects. Combining multivariate calculus, marching cube\nalgorithm, and binary indexed tree data structure, we developed an algorithm\nfor efficient computation of intrinsic volume of any volumetric data recovered\nfrom computed tomography (CT) or magnetic resonance (MR). We proposed the 30\nconfigurations of volume values based on the polygonal mesh generation method.\nOur algorithm processes the data in scan-line order simultaneously with\nreconstruction algorithm to create a Fenwick tree, ensuring query time much\nfaster and assisting users' edition of slicing or transforming model. We tested\nthe algorithm's accuracy on simple 3D objects (e.g., sphere, cylinder) to\ncomplicated structures (e.g., lungs, cardiac chambers). The result deviated\nwithin $\\pm 0.004 \\text{cm}^3$ and there is still room for further improvement.",
      "tldr_zh": "本文提出了一种新型的3D Binary Indexed Tree 算法，用于高效计算从 CT 或 MR 扫描中重建的3D 模型体积，从而支持医疗成像中的定性分析。该算法整合多元微积分、Marching Cube 算法和 Binary Indexed Tree 数据结构，并在扫描线顺序中与重建过程同步创建 Fenwick Tree，以显著加快查询速度并便于模型切片或转换编辑。测试结果显示，该算法在简单物体（如球体、圆柱体）和复杂结构（如肺部、心脏腔室）上准确性高，体积计算偏差控制在 ±0.004 cm³ 之内，并具有进一步优化的潜力。",
      "categories": [
        "cs.GR",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.GR",
      "comment": "8 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.10441v1",
      "published_date": "2024-12-11 11:29:53 UTC",
      "updated_date": "2024-12-11 11:29:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:13:44.615936"
    },
    {
      "arxiv_id": "2412.08292v1",
      "title": "Self-Refining Diffusion Samplers: Enabling Parallelization via Parareal Iterations",
      "title_zh": "翻译失败",
      "authors": [
        "Nikil Roashan Selvam",
        "Amil Merchant",
        "Stefano Ermon"
      ],
      "abstract": "In diffusion models, samples are generated through an iterative refinement\nprocess, requiring hundreds of sequential model evaluations. Several recent\nmethods have introduced approximations (fewer discretization steps or\ndistillation) to trade off speed at the cost of sample quality. In contrast, we\nintroduce Self-Refining Diffusion Samplers (SRDS) that retain sample quality\nand can improve latency at the cost of additional parallel compute. We take\ninspiration from the Parareal algorithm, a popular numerical method for\nparallel-in-time integration of differential equations. In SRDS, a quick but\nrough estimate of a sample is first created and then iteratively refined in\nparallel through Parareal iterations. SRDS is not only guaranteed to accurately\nsolve the ODE and converge to the serial solution but also benefits from\nparallelization across the diffusion trajectory, enabling batched inference and\npipelining. As we demonstrate for pre-trained diffusion models, the early\nconvergence of this refinement procedure drastically reduces the number of\nsteps required to produce a sample, speeding up generation for instance by up\nto 1.7x on a 25-step StableDiffusion-v2 benchmark and up to 4.3x on longer\ntrajectories.",
      "tldr_zh": "本研究提出Self-Refining Diffusion Samplers (SRDS)，一种基于Parareal算法的创新方法，用于加速扩散模型(diffusion models)的样本生成过程，同时保持样本质量。SRDS首先快速生成一个粗略样本，然后通过并行迭代精炼扩散轨迹，从而实现ODE的准确求解和高效并行化，支持批量推理和流水线处理。与传统方法不同，该方法无需牺牲质量即可减少迭代步骤。实验结果显示，在预训练模型上，SRDS可将生成速度提升至原有的1.7倍（如25步StableDiffusion-v2基准），并在更长轨迹上达到4.3倍加速。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2412.08292v1",
      "published_date": "2024-12-11 11:08:09 UTC",
      "updated_date": "2024-12-11 11:08:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:13:56.428955"
    },
    {
      "arxiv_id": "2412.08282v2",
      "title": "How Does the Smoothness Approximation Method Facilitate Generalization for Federated Adversarial Learning?",
      "title_zh": "光滑度逼近方法如何促进联邦对抗学习的泛化？",
      "authors": [
        "Wenjun Ding",
        "Ying An",
        "Lixing Chen",
        "Shichao Kan",
        "Fan Wu",
        "Zhe Qu"
      ],
      "abstract": "Federated Adversarial Learning (FAL) is a robust framework for resisting\nadversarial attacks on federated learning. Although some FAL studies have\ndeveloped efficient algorithms, they primarily focus on convergence performance\nand overlook generalization. Generalization is crucial for evaluating algorithm\nperformance on unseen data. However, generalization analysis is more\nchallenging due to non-smooth adversarial loss functions. A common approach to\naddressing this issue is to leverage smoothness approximation. In this paper,\nwe develop algorithm stability measures to evaluate the generalization\nperformance of two popular FAL algorithms: \\textit{Vanilla FAL (VFAL)} and {\\it\nSlack FAL (SFAL)}, using three different smooth approximation methods: 1)\n\\textit{Surrogate Smoothness Approximation (SSA)}, (2) \\textit{Randomized\nSmoothness Approximation (RSA)}, and (3) \\textit{Over-Parameterized Smoothness\nApproximation (OPSA)}. Based on our in-depth analysis, we answer the question\nof how to properly set the smoothness approximation method to mitigate\ngeneralization error in FAL. Moreover, we identify RSA as the most effective\nmethod for reducing generalization error. In highly data-heterogeneous\nscenarios, we also recommend employing SFAL to mitigate the deterioration of\ngeneralization performance caused by heterogeneity. Based on our theoretical\nresults, we provide insights to help develop more efficient FAL algorithms,\nsuch as designing new metrics and dynamic aggregation rules to mitigate\nheterogeneity.",
      "tldr_zh": "这篇论文探讨了平滑近似方法如何提升 Federated Adversarial Learning (FAL) 的泛化性能，针对其非平滑损失函数带来的挑战。作者开发了算法稳定性度量，分析了 Vanilla FAL (VFAL) 和 Slack FAL (SFAL) 两种算法，使用 Surrogate Smoothness Approximation (SSA)、Randomized Smoothness Approximation (RSA) 和 Over-Parameterized Smoothness Approximation (OPSA) 三种方法进行评估。研究发现，RSA 是最有效的减少泛化错误的方法，并在数据高度异构场景中推荐使用 SFAL 以缓解性能下降。论文还提供了理论见解，帮助设计新指标和动态聚合规则，开发更高效的 FAL 算法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.08282v2",
      "published_date": "2024-12-11 10:57:16 UTC",
      "updated_date": "2024-12-19 06:35:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:14:09.764885"
    },
    {
      "arxiv_id": "2412.08273v1",
      "title": "Can transformative AI shape a new age for our civilization?: Navigating between speculation and reality",
      "title_zh": "翻译失败",
      "authors": [
        "Jesus L. Lobo",
        "Javier Del Ser"
      ],
      "abstract": "Artificial Intelligence is widely regarded as a transformative force with the\npotential to redefine numerous sectors of human civilization. While Artificial\nIntelligence has evolved from speculative fiction to a pivotal element of\ntechnological progress, its role as a truly transformative agent, or\ntransformative Artificial Intelligence, remains a subject of debate. This work\nexplores the historical precedents of technological breakthroughs, examining\nwhether Artificial Intelligence can achieve a comparable impact, and it delves\ninto various ethical frameworks that shape the perception and development of\nArtificial Intelligence. Additionally, it considers the societal, technical,\nand regulatory challenges that must be addressed for Artificial Intelligence to\nbecome a catalyst for global change. We also examine not only the strategies\nand methodologies that could lead to transformative Artificial Intelligence but\nalso the barriers that could ultimately make these goals unattainable. We end\nwith a critical inquiry into whether reaching a transformative Artificial\nIntelligence might compel humanity to adopt an entirely new ethical approach,\ntailored to the complexities of advanced Artificial Intelligence. By addressing\nthe ethical, social, and scientific dimensions of Artificial Intelligence's\ndevelopment, this work contributes to the broader discourse on the long-term\nimplications of Artificial Intelligence and its capacity to drive civilization\ntoward a new era of progress or, conversely, exacerbate existing inequalities\nand risks.",
      "tldr_zh": "这篇论文探讨了 transformative AI 是否能重塑人类文明的新时代，分析了 AI 从科幻到现实的技术演变，并与历史技术突破进行对比。作者考察了影响 AI 发展的伦理框架、社会挑战、技术障碍和监管问题，同时评估了实现 transformative AI 的策略和潜在风险。最终，论文强调 AI 可能推动全球进步，但也可能加剧不平等和风险，并呼吁采用新的伦理方法来应对其复杂性，从而为 AI 的长期影响提供重要 discourse。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "100 pages, 6 Figures, 2 Tables",
      "pdf_url": "http://arxiv.org/pdf/2412.08273v1",
      "published_date": "2024-12-11 10:44:47 UTC",
      "updated_date": "2024-12-11 10:44:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:14:19.797893"
    },
    {
      "arxiv_id": "2412.08271v1",
      "title": "Position-aware Guided Point Cloud Completion with CLIP Model",
      "title_zh": "翻译失败",
      "authors": [
        "Feng Zhou",
        "Qi Zhang",
        "Ju Dai",
        "Lei Li",
        "Qing Fan",
        "Junliang Xing"
      ],
      "abstract": "Point cloud completion aims to recover partial geometric and topological\nshapes caused by equipment defects or limited viewpoints. Current methods\neither solely rely on the 3D coordinates of the point cloud to complete it or\nincorporate additional images with well-calibrated intrinsic parameters to\nguide the geometric estimation of the missing parts. Although these methods\nhave achieved excellent performance by directly predicting the location of\ncomplete points, the extracted features lack fine-grained information regarding\nthe location of the missing area. To address this issue, we propose a rapid and\nefficient method to expand an unimodal framework into a multimodal framework.\nThis approach incorporates a position-aware module designed to enhance the\nspatial information of the missing parts through a weighted map learning\nmechanism. In addition, we establish a Point-Text-Image triplet corpus PCI-TI\nand MVP-TI based on the existing unimodal point cloud completion dataset and\nuse the pre-trained vision-language model CLIP to provide richer detail\ninformation for 3D shapes, thereby enhancing performance. Extensive\nquantitative and qualitative experiments demonstrate that our method\noutperforms state-of-the-art point cloud completion methods.",
      "tldr_zh": "该论文针对点云完成（Point cloud completion）问题，提出了一种位置感知引导方法，以解决现有方法在提取缺失区域细粒度位置信息方面的不足。该方法将单模态框架扩展为多模态框架，引入了position-aware module，通过加权映射学习机制增强缺失部分的空问信息，并构建了Point-Text-Image三元组语料库（PCI-TI和MVP-TI），利用预训练的CLIP模型为3D形状提供更丰富的细节支持。实验结果显示，该方法在定量和定性评估中优于现有最先进的技术。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by AAAI25",
      "pdf_url": "http://arxiv.org/pdf/2412.08271v1",
      "published_date": "2024-12-11 10:43:11 UTC",
      "updated_date": "2024-12-11 10:43:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:14:33.386834"
    },
    {
      "arxiv_id": "2412.10440v1",
      "title": "Multi-level Matching Network for Multimodal Entity Linking",
      "title_zh": "翻译失败",
      "authors": [
        "Zhiwei Hu",
        "Víctor Gutiérrez-Basulto",
        "Ru Li",
        "Jeff Z. Pan"
      ],
      "abstract": "Multimodal entity linking (MEL) aims to link ambiguous mentions within\nmultimodal contexts to corresponding entities in a multimodal knowledge base.\nMost existing approaches to MEL are based on representation learning or\nvision-and-language pre-training mechanisms for exploring the complementary\neffect among multiple modalities. However, these methods suffer from two\nlimitations. On the one hand, they overlook the possibility of considering\nnegative samples from the same modality. On the other hand, they lack\nmechanisms to capture bidirectional cross-modal interaction. To address these\nissues, we propose a Multi-level Matching network for Multimodal Entity Linking\n(M3EL). Specifically, M3EL is composed of three different modules: (i) a\nMultimodal Feature Extraction module, which extracts modality-specific\nrepresentations with a multimodal encoder and introduces an intra-modal\ncontrastive learning sub-module to obtain better discriminative embeddings\nbased on uni-modal differences; (ii) an Intra-modal Matching Network module,\nwhich contains two levels of matching granularity: Coarse-grained\nGlobal-to-Global and Fine-grained Global-to-Local, to achieve local and global\nlevel intra-modal interaction; (iii) a Cross-modal Matching Network module,\nwhich applies bidirectional strategies, Textual-to-Visual and Visual-to-Textual\nmatching, to implement bidirectional cross-modal interaction. Extensive\nexperiments conducted on WikiMEL, RichpediaMEL, and WikiDiverse datasets\ndemonstrate the outstanding performance of M3EL when compared to the\nstate-of-the-art baselines.",
      "tldr_zh": "本研究针对多模态实体链接(Multimodal Entity Linking, MEL)的问题，提出了一种多层次匹配网络(Multi-level Matching Network for Multimodal Entity Linking, M3EL)，以解决现有方法忽略同一模态负面样本和缺乏双向跨模态交互的局限性。M3EL包括三个模块：Multimodal Feature Extraction模块使用多模态编码器和intra-modal contrastive learning提取更具区分性的模态表示；Intra-modal Matching Network模块通过Coarse-grained Global-to-Global和Fine-grained Global-to-Local匹配实现模态内部的全局和局部交互；Cross-modal Matching Network模块采用Textual-to-Visual和Visual-to-Textual双向策略进行跨模态交互。在WikiMEL、RichpediaMEL和WikiDiverse数据集上的广泛实验表明，M3EL在性能上超过了最先进基线模型。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at KDD'25",
      "pdf_url": "http://arxiv.org/pdf/2412.10440v1",
      "published_date": "2024-12-11 10:26:17 UTC",
      "updated_date": "2024-12-11 10:26:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:14:45.895809"
    },
    {
      "arxiv_id": "2412.08261v2",
      "title": "FLIP: Flow-Centric Generative Planning as General-Purpose Manipulation World Model",
      "title_zh": "翻译失败",
      "authors": [
        "Chongkai Gao",
        "Haozhuo Zhang",
        "Zhixuan Xu",
        "Zhehao Cai",
        "Lin Shao"
      ],
      "abstract": "We aim to develop a model-based planning framework for world models that can\nbe scaled with increasing model and data budgets for general-purpose\nmanipulation tasks with only language and vision inputs. To this end, we\npresent FLow-centric generative Planning (FLIP), a model-based planning\nalgorithm on visual space that features three key modules: 1. a multi-modal\nflow generation model as the general-purpose action proposal module; 2. a\nflow-conditioned video generation model as the dynamics module; and 3. a\nvision-language representation learning model as the value module. Given an\ninitial image and language instruction as the goal, FLIP can progressively\nsearch for long-horizon flow and video plans that maximize the discounted\nreturn to accomplish the task. FLIP is able to synthesize long-horizon plans\nacross objects, robots, and tasks with image flows as the general action\nrepresentation, and the dense flow information also provides rich guidance for\nlong-horizon video generation. In addition, the synthesized flow and video\nplans can guide the training of low-level control policies for robot execution.\nExperiments on diverse benchmarks demonstrate that FLIP can improve both the\nsuccess rates and quality of long-horizon video plan synthesis and has the\ninteractive world model property, opening up wider applications for future\nworks.Video demos are on our website: https://nus-lins-lab.github.io/flipweb/.",
      "tldr_zh": "本文提出 FLIP，一种基于流中心的生成式规划框架，作为通用目的的操纵世界模型，用于处理仅依赖语言和视觉输入的长期任务。FLIP 包括三个关键模块：多模态流生成模型作为动作提案模块、流条件视频生成模型作为动态模块，以及视觉-语言表示学习模型作为价值模块。该框架能从初始图像和语言指令出发，通过搜索最大化折扣回报的长期流和视频计划，提高任务规划的成功率和质量。实验结果显示，FLIP 在多样基准上提升了视频计划合成的性能，并支持交互式世界模型应用。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.08261v2",
      "published_date": "2024-12-11 10:17:00 UTC",
      "updated_date": "2025-02-16 03:13:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:14:57.685880"
    },
    {
      "arxiv_id": "2412.08258v1",
      "title": "Large Language Models for Scholarly Ontology Generation: An Extensive Analysis in the Engineering Field",
      "title_zh": "大语言模型用于学术本体生成：工程领域的广泛分析",
      "authors": [
        "Tanay Aggarwal",
        "Angelo Salatino",
        "Francesco Osborne",
        "Enrico Motta"
      ],
      "abstract": "Ontologies of research topics are crucial for structuring scientific\nknowledge, enabling scientists to navigate vast amounts of research, and\nforming the backbone of intelligent systems such as search engines and\nrecommendation systems. However, manual creation of these ontologies is\nexpensive, slow, and often results in outdated and overly general\nrepresentations. As a solution, researchers have been investigating ways to\nautomate or semi-automate the process of generating these ontologies. This\npaper offers a comprehensive analysis of the ability of large language models\n(LLMs) to identify semantic relationships between different research topics,\nwhich is a critical step in the development of such ontologies. To this end, we\ndeveloped a gold standard based on the IEEE Thesaurus to evaluate the task of\nidentifying four types of relationships between pairs of topics: broader,\nnarrower, same-as, and other. Our study evaluates the performance of seventeen\nLLMs, which differ in scale, accessibility (open vs. proprietary), and model\ntype (full vs. quantised), while also assessing four zero-shot reasoning\nstrategies. Several models have achieved outstanding results, including\nMixtral-8x7B, Dolphin-Mistral-7B, and Claude 3 Sonnet, with F1-scores of 0.847,\n0.920, and 0.967, respectively. Furthermore, our findings demonstrate that\nsmaller, quantised models, when optimised through prompt engineering, can\ndeliver performance comparable to much larger proprietary models, while\nrequiring significantly fewer computational resources.",
      "tldr_zh": "这篇论文分析了大型语言模型 (LLMs) 在工程领域生成学术本体的潜力，旨在解决手动创建本体耗时昂贵且易过时的难题。研究团队基于 IEEE Thesaurus 开发了金标准，评估了 17 个不同规模（全模型 vs. 量化模型）和类型（开放 vs. 专有）的 LLMs，在识别研究主题间四种语义关系（broader, narrower, same-as, and other）时采用了四种 zero-shot reasoning 策略。结果显示，Claude 3 Sonnet 等模型取得了高达 0.967 的 F1-score，而较小的量化模型通过 prompt engineering 优化，能实现与大型专有模型相当的性能，但所需计算资源显著降低。",
      "categories": [
        "cs.DL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.DL",
      "comment": "submitted to Information Processing & Management",
      "pdf_url": "http://arxiv.org/pdf/2412.08258v1",
      "published_date": "2024-12-11 10:11:41 UTC",
      "updated_date": "2024-12-11 10:11:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:15:11.397759"
    },
    {
      "arxiv_id": "2412.08231v1",
      "title": "Dynamic Modality-Camera Invariant Clustering for Unsupervised Visible-Infrared Person Re-identification",
      "title_zh": "翻译失败",
      "authors": [
        "Yiming Yang",
        "Weipeng Hu",
        "Haifeng Hu"
      ],
      "abstract": "Unsupervised learning visible-infrared person re-identification (USL-VI-ReID)\noffers a more flexible and cost-effective alternative compared to supervised\nmethods. This field has gained increasing attention due to its promising\npotential. Existing methods simply cluster modality-specific samples and employ\nstrong association techniques to achieve instance-to-cluster or\ncluster-to-cluster cross-modality associations. However, they ignore\ncross-camera differences, leading to noticeable issues with excessive splitting\nof identities. Consequently, this undermines the accuracy and reliability of\ncross-modal associations. To address these issues, we propose a novel Dynamic\nModality-Camera Invariant Clustering (DMIC) framework for USL-VI-ReID.\nSpecifically, our DMIC naturally integrates Modality-Camera Invariant Expansion\n(MIE), Dynamic Neighborhood Clustering (DNC) and Hybrid Modality Contrastive\nLearning (HMCL) into a unified framework, which eliminates both the\ncross-modality and cross-camera discrepancies in clustering. MIE fuses\ninter-modal and inter-camera distance coding to bridge the gaps between\nmodalities and cameras at the clustering level. DNC employs two dynamic search\nstrategies to refine the network's optimization objective, transitioning from\nimproving discriminability to enhancing cross-modal and cross-camera\ngeneralizability. Moreover, HMCL is designed to optimize instance-level and\ncluster-level distributions. Memories for intra-modality and inter-modality\ntraining are updated using randomly selected samples, facilitating real-time\nexploration of modality-invariant representations. Extensive experiments have\ndemonstrated that our DMIC addresses the limitations present in current\nclustering approaches and achieve competitive performance, which significantly\nreduces the performance gap with supervised methods.",
      "tldr_zh": "本研究针对无监督可见-红外人重新识别（USL-VI-ReID）的问题，提出了一种新型框架 Dynamic Modality-Camera Invariant Clustering (DMIC)，以解决现有方法忽略跨摄像头差异导致的身份过度分割和跨模态关联不准确问题。DMIC 整合了 Modality-Camera Invariant Expansion (MIE) 用于桥接模态和摄像头间的距离编码、Dynamic Neighborhood Clustering (DNC) 通过动态搜索策略提升判别性和泛化能力，以及 Hybrid Modality Contrastive Learning (HMCL) 来优化实例级和聚类级分布，并使用随机样本更新记忆以探索模态不变表示。实验结果表明，DMIC 显著改善了聚类性能，缩小了与监督方法的差距，并在多个基准上实现了竞争性成果。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.08231v1",
      "published_date": "2024-12-11 09:31:03 UTC",
      "updated_date": "2024-12-11 09:31:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:15:23.205010"
    },
    {
      "arxiv_id": "2412.08228v1",
      "title": "Hierarchical Classification for Automated Image Annotation of Coral Reef Benthic Structures",
      "title_zh": "翻译失败",
      "authors": [
        "Célia Blondin",
        "Joris Guérin",
        "Kelly Inagaki",
        "Guilherme Longo",
        "Laure Berti-Équille"
      ],
      "abstract": "Automated benthic image annotation is crucial to efficiently monitor and\nprotect coral reefs against climate change. Current machine learning approaches\nfail to capture the hierarchical nature of benthic organisms covering reef\nsubstrata, i.e., coral taxonomic levels and health condition. To address this\nlimitation, we propose to annotate benthic images using hierarchical\nclassification. Experiments on a custom dataset from a Northeast Brazilian\ncoral reef show that our approach outperforms flat classifiers, improving both\nF1 and hierarchical F1 scores by approximately 2\\% across varying amounts of\ntraining data. In addition, this hierarchical method aligns more closely with\necological objectives.",
      "tldr_zh": "这篇论文针对珊瑚礁底栖结构图像的自动标注问题，提出使用层次分类（hierarchical classification）方法，以捕捉珊瑚的分类水平和健康状况，从而解决当前机器学习方法忽略层次性质的局限性。在一个来自巴西东北部珊瑚礁的自定义数据集上进行实验，该方法比平坦分类器（flat classifiers）提高了约2%的F1分数和层次F1分数（hierarchical F1 scores），并在不同训练数据量下保持优势。这种层次化方法更符合生态目标，有助于更有效地监测和保护珊瑚礁免受气候变化影响。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Poster at Tackling Climate Change with Machine Learning: workshop at\n  NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2412.08228v1",
      "published_date": "2024-12-11 09:28:30 UTC",
      "updated_date": "2024-12-11 09:28:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:15:33.782858"
    },
    {
      "arxiv_id": "2412.12155v1",
      "title": "Adapting Unsigned Graph Neural Networks for Signed Graphs: A Few-Shot Prompt Tuning Approach",
      "title_zh": "将无符号图神经网络适应于有符号图：一种少样本提示调优方法",
      "authors": [
        "Zian Zhai",
        "Sima Qing",
        "Xiaoyang Wang",
        "Wenjie Zhang"
      ],
      "abstract": "Signed Graph Neural Networks (SGNNs) are powerful tools for signed graph\nrepresentation learning but struggle with limited generalization and heavy\ndependence on labeled data. While recent advancements in \"graph pre-training\nand prompt tuning\" have reduced label dependence in Graph Neural Networks\n(GNNs) and improved their generalization abilities by leveraging pre-training\nknowledge, these efforts have focused exclusively on unsigned graphs. The\nscarcity of publicly available signed graph datasets makes it essential to\ntransfer knowledge from unsigned graphs to signed graph tasks. However, this\ntransfer introduces significant challenges due to the graph-level and\ntask-level divergences between the pre-training and downstream phases. To\naddress these challenges, we propose Signed Graph Prompt Tuning (SGPT) in this\npaper. Specifically, SGPT employs a graph template and a semantic prompt to\nsegregate mixed link semantics in the signed graph and then adaptively\nintegrate the distinctive semantic information according to the needs of\ndownstream tasks, thereby unifying the pre-training and downstream graphs.\nAdditionally, SGPT utilizes a task template and a feature prompt to reformulate\nthe downstream signed graph tasks, aligning them with pre-training tasks to\nensure a unified optimization objective and consistent feature space across\ntasks. Finally, extensive experiments are conducted on popular signed graph\ndatasets, demonstrating the superiority of SGPT over state-of-the-art methods.",
      "tldr_zh": "这篇论文针对 Signed Graph Neural Networks (SGNNs) 在泛化能力和标签依赖上的不足，提出了一种从无符号图转移知识的 Few-Shot Prompt Tuning 方法，以解决有符号图任务的挑战。作者开发了 Signed Graph Prompt Tuning (SGPT)，通过图模板和语义提示分离并整合有符号图的链接语义，以及任务模板和特征提示重构下游任务，从而统一预训练和下游任务的优化目标和特征空间。实验在流行有符号图数据集上表明，SGPT 优于现有最先进方法，提高了模型的泛化和性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.12155v1",
      "published_date": "2024-12-11 09:22:46 UTC",
      "updated_date": "2024-12-11 09:22:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:15:45.916913"
    },
    {
      "arxiv_id": "2412.08221v2",
      "title": "Generate Any Scene: Evaluating and Improving Text-to-Vision Generation with Scene Graph Programming",
      "title_zh": "生成任意场景：使用场景图编程评估和改进文本到视觉生成",
      "authors": [
        "Ziqi Gao",
        "Weikai Huang",
        "Jieyu Zhang",
        "Aniruddha Kembhavi",
        "Ranjay Krishna"
      ],
      "abstract": "DALL-E and Sora have gained attention by producing implausible images, such\nas \"astronauts riding a horse in space.\" Despite the proliferation of\ntext-to-vision models that have inundated the internet with synthetic visuals,\nfrom images to 3D assets, current benchmarks predominantly evaluate these\nmodels on real-world scenes paired with captions. We introduce Generate Any\nScene, a framework that systematically enumerates scene graphs representing a\nvast array of visual scenes, spanning realistic to imaginative compositions.\nGenerate Any Scene leverages 'scene graph programming', a method for\ndynamically constructing scene graphs of varying complexity from a structured\ntaxonomy of visual elements. This taxonomy includes numerous objects,\nattributes, and relations, enabling the synthesis of an almost infinite variety\nof scene graphs. Using these structured representations, Generate Any Scene\ntranslates each scene graph into a caption, enabling scalable evaluation of\ntext-to-vision models through standard metrics. We conduct extensive\nevaluations across multiple text-to-image, text-to-video, and text-to-3D\nmodels, presenting key findings on model performance. We find that DiT-backbone\ntext-to-image models align more closely with input captions than UNet-backbone\nmodels. Text-to-video models struggle with balancing dynamics and consistency,\nwhile both text-to-video and text-to-3D models show notable gaps in human\npreference alignment. We demonstrate the effectiveness of Generate Any Scene by\nconducting three practical applications leveraging captions generated by\nGenerate Any Scene: 1) a self-improving framework where models iteratively\nenhance their performance using generated data, 2) a distillation process to\ntransfer specific strengths from proprietary models to open-source\ncounterparts, and 3) improvements in content moderation by identifying and\ngenerating challenging synthetic data.",
      "tldr_zh": "本论文提出 Generate Any Scene 框架，通过 scene graph programming 系统地枚举场景图，以评估和改进文本到视觉生成模型的性能。该框架利用结构化的视觉元素分类法动态构建各种复杂度的场景图，包括对象、属性和关系，然后将这些场景图转化为标题，实现对文本到图像、文本到视频和文本到3D 模型的可扩展评估。实验结果显示，DiT-backbone 文本到图像模型比 UNet-backbone 模型更接近输入标题，而文本到视频模型在动态与一致性之间存在平衡难题，且文本到视频及文本到3D 模型在人类偏好上仍有显著差距。该框架还应用于三个实际场景：模型的自提升机制、从专有模型向开源模型的知识蒸馏，以及通过生成挑战性数据改进内容审核。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.08221v2",
      "published_date": "2024-12-11 09:17:39 UTC",
      "updated_date": "2024-12-16 09:54:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:15:58.896739"
    },
    {
      "arxiv_id": "2412.10438v1",
      "title": "Automatic Image Annotation for Mapped Features Detection",
      "title_zh": "针对映射特征检测的自动图像",
      "authors": [
        "Maxime Noizet",
        "Philippe Xu",
        "Philippe Bonnifait"
      ],
      "abstract": "Detecting road features is a key enabler for autonomous driving and\nlocalization. For instance, a reliable detection of poles which are widespread\nin road environments can improve localization. Modern deep learning-based\nperception systems need a significant amount of annotated data. Automatic\nannotation avoids time-consuming and costly manual annotation. Because\nautomatic methods are prone to errors, managing annotation uncertainty is\ncrucial to ensure a proper learning process. Fusing multiple annotation sources\non the same dataset can be an efficient way to reduce the errors. This not only\nimproves the quality of annotations, but also improves the learning of\nperception models. In this paper, we consider the fusion of three automatic\nannotation methods in images: feature projection from a high accuracy vector\nmap combined with a lidar, image segmentation and lidar segmentation. Our\nexperimental results demonstrate the significant benefits of multi-modal\nautomatic annotation for pole detection through a comparative evaluation on\nmanually annotated images. Finally, the resulting multi-modal fusion is used to\nfine-tune an object detection model for pole base detection using unlabeled\ndata, showing overall improvements achieved by enhancing network\nspecialization. The dataset is publicly available.",
      "tldr_zh": "这篇论文针对自动驾驶和定位中的道路特征检测（如电线杆），提出了一种自动图像标注方法，以避免耗时费力的手动标注。方法通过融合三种来源的自动标注：从高精度矢量地图结合激光雷达(lidar)的特征投影、图像分割(image segmentation)和激光雷达分割(lidar segmentation)，从而管理标注不确定性和提高标注质量。实验结果显示，这种多模态融合在手动标注图像上的比较评估中显著提升了电线杆检测的准确性，并用于微调物体检测模型(object detection model)，增强了网络的专业性。该数据集已公开可用，为深度学习-based perception systems 的应用提供了宝贵资源。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.10438v1",
      "published_date": "2024-12-11 09:06:52 UTC",
      "updated_date": "2024-12-11 09:06:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:16:09.648511"
    },
    {
      "arxiv_id": "2412.08197v1",
      "title": "SAFIRE: Segment Any Forged Image Region",
      "title_zh": "翻译失败",
      "authors": [
        "Myung-Joon Kwon",
        "Wonjun Lee",
        "Seung-Hun Nam",
        "Minji Son",
        "Changick Kim"
      ],
      "abstract": "Most techniques approach the problem of image forgery localization as a\nbinary segmentation task, training neural networks to label original areas as 0\nand forged areas as 1. In contrast, we tackle this issue from a more\nfundamental perspective by partitioning images according to their originating\nsources. To this end, we propose Segment Any Forged Image Region (SAFIRE),\nwhich solves forgery localization using point prompting. Each point on an image\nis used to segment the source region containing itself. This allows us to\npartition images into multiple source regions, a capability achieved for the\nfirst time. Additionally, rather than memorizing certain forgery traces, SAFIRE\nnaturally focuses on uniform characteristics within each source region. This\napproach leads to more stable and effective learning, achieving superior\nperformance in both the new task and the traditional binary forgery\nlocalization.",
      "tldr_zh": "这篇论文提出了 SAFIRE 方法，用于图像伪造定位，通过点提示（point prompting）将图像分区成多个来源区域，每个点用于分割包含自身的来源区域，这是首次实现这种功能。与传统的二元分割任务不同，SAFIRE 关注每个来源区域的统一特性，而不是记忆特定伪造痕迹，从而实现更稳定有效的学习。在实验中，该方法在新任务和传统二元伪造定位上均表现出优越性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at AAAI 2025. Code is available at:\n  https://github.com/mjkwon2021/SAFIRE",
      "pdf_url": "http://arxiv.org/pdf/2412.08197v1",
      "published_date": "2024-12-11 08:40:37 UTC",
      "updated_date": "2024-12-11 08:40:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:16:21.011257"
    },
    {
      "arxiv_id": "2412.08195v1",
      "title": "Semantic Scene Completion Based 3D Traversability Estimation for Off-Road Terrains",
      "title_zh": "基于语义场景完成的非道路地形3D可穿越性估计",
      "authors": [
        "Zitong Chen",
        "Chao Sun",
        "Shida Nie",
        "Chen Min",
        "Changjiu Ning",
        "Haoyu Li",
        "Bo Wang"
      ],
      "abstract": "Off-road environments present significant challenges for autonomous ground\nvehicles due to the absence of structured roads and the presence of complex\nobstacles, such as uneven terrain, vegetation, and occlusions. Traditional\nperception algorithms, designed primarily for structured environments, often\nfail under these conditions, leading to inaccurate traversability estimations.\nIn this paper, ORDformer, a novel multimodal method that combines LiDAR point\nclouds with monocular images, is proposed to generate dense traversable\noccupancy predictions from a forward-facing perspective. By integrating\nmultimodal data, environmental feature extraction is enhanced, which is crucial\nfor accurate occupancy estimation in complex terrains. Furthermore, RELLIS-OCC,\na dataset with 3D traversable occupancy annotations, is introduced,\nincorporating geometric features such as step height, slope, and unevenness.\nThrough a comprehensive analysis of vehicle obstacle-crossing conditions and\nthe incorporation of vehicle body structure constraints, four traversability\ncost labels are generated: lethal, medium-cost, low-cost, and free.\nExperimental results demonstrate that ORDformer outperforms existing approaches\nin 3D traversable area recognition, particularly in off-road environments with\nirregular geometries and partial occlusions. Specifically, ORDformer achieves\nover a 20\\% improvement in scene completion IoU compared to other models. The\nproposed framework is scalable and adaptable to various vehicle platforms,\nallowing for adjustments to occupancy grid parameters and the integration of\nadvanced dynamic models for traversability cost estimation.",
      "tldr_zh": "本研究针对非道路环境的复杂挑战（如不平整地形、植被和遮挡），提出了一种新型多模态方法 ORDformer，通过结合 LiDAR 点云和单目图像，从前方视角生成密集的 3D traversability 估计，从而提升环境特征提取和可穿越区域预测的准确性。研究还引入了 RELLIS-OCC 数据集，该数据集包含 3D traversable occupancy 注解，如步高、坡度和不平整度，并基于车辆障碍跨越条件生成四种 traversability cost 标签：lethal、medium-cost、low-cost 和 free。实验结果显示，ORDformer 在非道路场景中显著优于现有方法，场景完成 IoU 改善超过 20%，并具备可扩展性，可适应不同车辆平台并整合高级动态模型。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "12 pages,14 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.08195v1",
      "published_date": "2024-12-11 08:36:36 UTC",
      "updated_date": "2024-12-11 08:36:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:16:34.151887"
    },
    {
      "arxiv_id": "2412.08187v1",
      "title": "From communities to interpretable network and word embedding: an unified approach",
      "title_zh": "翻译失败",
      "authors": [
        "Thibault Prouteau",
        "Nicolas Dugué",
        "Simon Guillot"
      ],
      "abstract": "Modelling information from complex systems such as humans social interaction\nor words co-occurrences in our languages can help to understand how these\nsystems are organized and function. Such systems can be modelled by networks,\nand network theory provides a useful set of methods to analyze them. Among\nthese methods, graph embedding is a powerful tool to summarize the interactions\nand topology of a network in a vectorized feature space. When used in input of\nmachine learning algorithms, embedding vectors help with common graph problems\nsuch as link prediction, graph matching, etc. Word embedding has the goal of\nrepresenting the sense of words, extracting it from large text corpora. Despite\ndifferences in the structure of information in input of embedding algorithms,\nmany graph embedding approaches are adapted and inspired from methods in NLP.\nLimits of these methods are observed in both domains. Most of these methods\nrequire long and resource greedy training. Another downside to most methods is\nthat they are black-box, from which understanding how the information is\nstructured is rather complex. Interpretability of a model allows understanding\nhow the vector space is structured without the need for external information,\nand thus can be audited more easily. With both these limitations in mind, we\npropose a novel framework to efficiently embed network vertices in an\ninterpretable vector space. Our Lower Dimension Bipartite Framework (LDBGF)\nleverages the bipartite projection of a network using cliques to reduce\ndimensionality. Along with LDBGF, we introduce two implementations of this\nframework that rely on communities instead of cliques: SINr-NR and SINr-MF. We\nshow that SINr-MF can perform well on classical graphs and SINr-NR can produce\nhigh-quality graph and word embeddings that are interpretable and stable across\nruns.",
      "tldr_zh": "这篇论文提出了一种统一方法，用于从社区结构生成可解释的网络嵌入（graph embedding）和单词嵌入（word embedding），以解决现有方法在资源消耗和黑盒问题上的局限。作者引入了 Lower Dimension Bipartite Framework (LDBGF)，通过二分图投影和基于社区的团（cliques）处理来降低嵌入维度，并开发了两个实现版本：SINr-NR 和 SINr-MF。实验结果显示，SINr-MF 在经典图上表现良好，而 SINr-NR 能产生高质量、可解释且稳定的嵌入向量，适用于链接预测等任务。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.08187v1",
      "published_date": "2024-12-11 08:27:25 UTC",
      "updated_date": "2024-12-11 08:27:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:16:45.172055"
    },
    {
      "arxiv_id": "2412.08186v1",
      "title": "Towards Automated Algebraic Multigrid Preconditioner Design Using Genetic Programming for Large-Scale Laser Beam Welding Simulations",
      "title_zh": "翻译失败",
      "authors": [
        "Dinesh Parthasarathy",
        "Tommaso Bevilacqua",
        "Martin Lanser",
        "Axel Klawonn",
        "Harald Köstler"
      ],
      "abstract": "Multigrid methods are asymptotically optimal algorithms ideal for large-scale\nsimulations. But, they require making numerous algorithmic choices that\nsignificantly influence their efficiency. Unlike recent approaches that learn\noptimal multigrid components using machine learning techniques, we adopt a\ncomplementary strategy here, employing evolutionary algorithms to construct\nefficient multigrid cycles from available individual components. This\ntechnology is applied to finite element simulations of the laser beam welding\nprocess. The thermo-elastic behavior is described by a coupled system of\ntime-dependent thermo-elasticity equations, leading to nonlinear and\nill-conditioned systems. The nonlinearity is addressed using Newton's method,\nand iterative solvers are accelerated with an algebraic multigrid (AMG)\npreconditioner using hypre BoomerAMG interfaced via PETSc. This is applied as a\nmonolithic solver for the coupled equations. To further enhance solver\nefficiency, flexible AMG cycles are introduced, extending traditional cycle\ntypes with level-specific smoothing sequences and non-recursive cycling\npatterns. These are automatically generated using genetic programming, guided\nby a context-free grammar containing AMG rules. Numerical experiments\ndemonstrate the potential of these approaches to improve solver performance in\nlarge-scale laser beam welding simulations.",
      "tldr_zh": "本文提出一种使用遗传编程(Genetic Programming)自动设计代数多网格(AMG)预处理器的方法，旨在优化多网格方法在大型激光束焊接模拟中的效率，解决算法选择带来的挑战。该方法通过进化算法构建高效的多网格循环，应用于热弹性方程的有限元模拟中，并结合牛顿方法处理非线性问题，同时引入灵活的AMG循环以支持自定义平滑序列和非递归模式。实验结果表明，这种自动生成策略显著提升了求解器性能，为大规模模拟提供了更有效的预处理解决方案。",
      "categories": [
        "cs.CE",
        "cs.AI",
        "cs.NA",
        "math.NA",
        "65M55 (Primary) 74F05, 65M60 (Secondary)",
        "I.2.2; G.1.8; J.2"
      ],
      "primary_category": "cs.CE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.08186v1",
      "published_date": "2024-12-11 08:24:38 UTC",
      "updated_date": "2024-12-11 08:24:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:16:57.870709"
    },
    {
      "arxiv_id": "2412.10435v1",
      "title": "COEF-VQ: Cost-Efficient Video Quality Understanding through a Cascaded Multimodal LLM Framework",
      "title_zh": "翻译失败",
      "authors": [
        "Xin Dong",
        "Sen Jia",
        "Hongyu Xiong"
      ],
      "abstract": "Recently, with the emergence of recent Multimodal Large Language Model (MLLM)\ntechnology, it has become possible to exploit its video understanding\ncapability on different classification tasks. In practice, we face the\ndifficulty of huge requirements for GPU resource if we need to deploy MLLMs\nonline. In this paper, we propose COEF-VQ, a novel cascaded MLLM framework for\nbetter video quality understanding on TikTok. To this end, we first propose a\nMLLM fusing all visual, textual and audio signals, and then develop a cascade\nframework with a lightweight model as pre-filtering stage and MLLM as\nfine-consideration stage, significantly reducing the need for GPU resource,\nwhile retaining the performance demonstrated solely by MLLM. To demonstrate the\neffectiveness of COEF-VQ, we deployed this new framework onto the video\nmanagement platform (VMP) at TikTok, and performed a series of detailed\nexperiments on two in-house tasks related to video quality understanding. We\nshow that COEF-VQ leads to substantial performance gains with limit resource\nconsumption in these two tasks.",
      "tldr_zh": "本论文提出 COEF-VQ，一种级联的多模态大语言模型(MLLM)框架，旨在高效处理视频质量理解任务，同时解决部署 MLLM 时的高 GPU 资源需求问题。\n该框架首先融合视觉、文本和音频信号构建 MLLM，然后采用级联结构，将轻量级模型作为预过滤阶段和 MLLM 作为精细处理阶段，从而显著降低资源消耗。\n实验结果显示，在 TikTok 视频管理平台上的两个内部任务中，COEF-VQ 实现了性能的大幅提升，同时保持了有限的资源使用。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.10435v1",
      "published_date": "2024-12-11 08:10:32 UTC",
      "updated_date": "2024-12-11 08:10:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:17:09.110026"
    },
    {
      "arxiv_id": "2412.08179v1",
      "title": "Auto-Generating Earnings Report Analysis via a Financial-Augmented LLM",
      "title_zh": "翻译失败",
      "authors": [
        "Van-Duc Le"
      ],
      "abstract": "Financial analysis heavily relies on the evaluation of earnings reports to\ngain insights into company performance. Traditional generation of these reports\nrequires extensive financial expertise and is time-consuming. With the\nimpressive progress in Large Language Models (LLMs), a wide variety of\nfinancially focused LLMs has emerged, addressing tasks like sentiment analysis\nand entity recognition in the financial domain. This paper presents a novel\nchallenge: developing an LLM specifically for automating the generation of\nearnings reports analysis. Our methodology involves an in-depth analysis of\nexisting earnings reports followed by a unique approach to fine-tune an LLM for\nthis purpose. This approach combines retrieval augmentation and the generation\nof instruction-based data, specifically tailored for the financial sector, to\nenhance the LLM's performance. With extensive financial documents, we construct\nfinancial instruction data, enabling the refined adaptation of our LLM to\nfinancial contexts. Preliminary results indicate that our augmented LLM\noutperforms general open-source models and rivals commercial counterparts like\nGPT-3.5 in financial applications. Our research paves the way for streamlined\nand insightful automation in financial report generation, marking a significant\nstride in the field of financial analysis.",
      "tldr_zh": "这篇论文提出了一种通过金融增强的 LLM（Large Language Models）自动生成收益报告分析的方法，以解决传统金融分析耗时且依赖专业知识的问题。研究方法包括对现有收益报告进行深入分析，并结合 retrieval augmentation 和生成指令数据来微调 LLM，使其适应金融领域上下文。初步结果显示，该增强 LLM 在金融应用中优于通用开源模型，并与 GPT-3.5 相当，为金融报告生成的自动化和洞察力提升开辟了新路径。",
      "categories": [
        "q-fin.ST",
        "cs.AI"
      ],
      "primary_category": "q-fin.ST",
      "comment": "8 pages, 1 figure, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2412.08179v1",
      "published_date": "2024-12-11 08:09:42 UTC",
      "updated_date": "2024-12-11 08:09:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:17:20.794609"
    },
    {
      "arxiv_id": "2412.08174v2",
      "title": "Can Graph Neural Networks Learn Language with Extremely Weak Text Supervision?",
      "title_zh": "图神经网络能否在极弱文本监督下学习语言？",
      "authors": [
        "Zihao Li",
        "Lecheng Zheng",
        "Bowen Jin",
        "Dongqi Fu",
        "Baoyu Jing",
        "Yikun Ban",
        "Jingrui He",
        "Jiawei Han"
      ],
      "abstract": "While great success has been achieved in building vision models with\nContrastive Language-Image Pre-training (CLIP) over Internet-scale image-text\npairs, building transferable Graph Neural Networks (GNNs) with CLIP pipeline is\nchallenging because of three fundamental issues: the scarcity of labeled data\nand text supervision, different levels of downstream tasks, and the conceptual\ngaps between domains. In this work, to address these issues, we leverage\nmulti-modal prompt learning to effectively adapt pre-trained GNN to downstream\ntasks and data, given only a few semantically labeled samples, each with\nextremely weak text supervision. Our new paradigm embeds the graphs directly in\nthe same space as the Large Language Models (LLMs) by learning both graph\nprompts and text prompts simultaneously. To accomplish this, we improve\nstate-of-the-art graph prompt method, and then propose the first graph-language\nmulti-modal prompt learning approach for exploiting the knowledge in\npre-trained models. Notably, due to the insufficient supervision for\nfine-tuning, in our paradigm, the pre-trained GNN and the LLM are kept frozen,\nso the learnable parameters are much fewer than fine-tuning any pre-trained\nmodel. Through extensive experiments on real-world datasets, we demonstrate the\nsuperior performance of our paradigm in few-shot, multi-task-level, and\ncross-domain settings. Moreover, we build the first CLIP-style zero-shot\nclassification prototype that can generalize GNNs to unseen classes with\nextremely weak text supervision.",
      "tldr_zh": "本文探讨了在极弱文本监督下，Graph Neural Networks (GNNs) 是否能有效学习语言的问题，针对数据稀缺、任务级别差异和领域间差距等挑战，提出了一种多模态提示学习方法。 该方法通过同时学习图提示和文本提示，将图直接嵌入到 Large Language Models (LLMs) 的空间中，同时保持预训练的 GNN 和 LLM 冻结，仅优化少量参数。 实验结果显示，该范式在少样本、多任务和跨域设置中显著优于基线，并在真实数据集上构建了第一个 CLIP 风格的零样本分类原型，实现 GNNs 对未见类的泛化。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "Preprint, 25 pages",
      "pdf_url": "http://arxiv.org/pdf/2412.08174v2",
      "published_date": "2024-12-11 08:03:35 UTC",
      "updated_date": "2024-12-15 20:54:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:17:33.510888"
    },
    {
      "arxiv_id": "2501.14737v1",
      "title": "EvalSVA: Multi-Agent Evaluators for Next-Gen Software Vulnerability Assessment",
      "title_zh": "EvalSVA：多智能体评估器用于下一代软件漏洞评估",
      "authors": [
        "Xin-Cheng Wen",
        "Jiaxin Ye",
        "Cuiyun Gao",
        "Lianwei Wu",
        "Qing Liao"
      ],
      "abstract": "Software Vulnerability (SV) assessment is a crucial process of determining\ndifferent aspects of SVs (e.g., attack vectors and scope) for developers to\neffectively prioritize efforts in vulnerability mitigation. It presents a\nchallenging and laborious process due to the complexity of SVs and the scarcity\nof labeled data. To mitigate the above challenges, we introduce EvalSVA, a\nmulti-agent evaluators team to autonomously deliberate and evaluate various\naspects of SV assessment. Specifically, we propose a multi-agent-based\nframework to simulate vulnerability assessment strategies in real-world\nscenarios, which employs multiple Large Language Models (LLMs) into an\nintegrated group to enhance the effectiveness of SV assessment in the limited\ndata. We also design diverse communication strategies to autonomously discuss\nand assess different aspects of SV. Furthermore, we construct a multi-lingual\nSV assessment dataset based on the new standard of CVSS, comprising 699, 888,\nand 1,310 vulnerability-related commits in C++, Python, and Java, respectively.\nOur experimental results demonstrate that EvalSVA averagely outperforms the\n44.12\\% accuracy and 43.29\\% F1 for SV assessment compared with the previous\nmethods. It shows that EvalSVA offers a human-like process and generates both\nreason and answer for SV assessment. EvalSVA can also aid human experts in SV\nassessment, which provides more explanation and details for SV assessment.",
      "tldr_zh": "该研究引入了EvalSVA，一种基于多智能体评估器的框架，旨在解决软件漏洞（SV）评估中的复杂性和数据稀缺问题，通过模拟真实场景来评估SV的各方面，如攻击向量和范围。框架利用多个Large Language Models (LLMs) 构建集成团队，并设计多样化通信策略，实现自主讨论和评估，同时构建了一个基于CVSS标准的多语言数据集，涵盖C++、Python和Java的699至1,310个漏洞提交。实验结果显示，EvalSVA在SV评估中平均准确率和F1分数分别超过44.12%和43.29%，提供类似人类的推理过程，并能辅助专家生成详细解释和答案。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "11 pages",
      "pdf_url": "http://arxiv.org/pdf/2501.14737v1",
      "published_date": "2024-12-11 08:00:50 UTC",
      "updated_date": "2024-12-11 08:00:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:17:45.386119"
    },
    {
      "arxiv_id": "2412.12154v1",
      "title": "PyOD 2: A Python Library for Outlier Detection with LLM-powered Model Selection",
      "title_zh": "翻译失败",
      "authors": [
        "Sihan Chen",
        "Zhuangzhuang Qian",
        "Wingchun Siu",
        "Xingcan Hu",
        "Jiaqi Li",
        "Shawn Li",
        "Yuehan Qin",
        "Tiankai Yang",
        "Zhuo Xiao",
        "Wanghao Ye",
        "Yichi Zhang",
        "Yushun Dong",
        "Yue Zhao"
      ],
      "abstract": "Outlier detection (OD), also known as anomaly detection, is a critical\nmachine learning (ML) task with applications in fraud detection, network\nintrusion detection, clickstream analysis, recommendation systems, and social\nnetwork moderation. Among open-source libraries for outlier detection, the\nPython Outlier Detection (PyOD) library is the most widely adopted, with over\n8,500 GitHub stars, 25 million downloads, and diverse industry usage. However,\nPyOD currently faces three limitations: (1) insufficient coverage of modern\ndeep learning algorithms, (2) fragmented implementations across PyTorch and\nTensorFlow, and (3) no automated model selection, making it hard for\nnon-experts.\n  To address these issues, we present PyOD Version 2 (PyOD 2), which integrates\n12 state-of-the-art deep learning models into a unified PyTorch framework and\nintroduces a large language model (LLM)-based pipeline for automated OD model\nselection. These improvements simplify OD workflows, provide access to 45\nalgorithms, and deliver robust performance on various datasets. In this paper,\nwe demonstrate how PyOD 2 streamlines the deployment and automation of OD\nmodels and sets a new standard in both research and industry. PyOD 2 is\naccessible at\n[https://github.com/yzhao062/pyod](https://github.com/yzhao062/pyod). This\nstudy aligns with the Web Mining and Content Analysis track, addressing topics\nsuch as the robustness of Web mining methods and the quality of\nalgorithmically-generated Web data.",
      "tldr_zh": "PyOD 2 是一个用于 Outlier Detection (OD) 的 Python 库，通过引入 Large Language Model (LLM) 驱动的模型选择管道，解决了原版库的三大问题：深度学习算法覆盖不足、框架碎片化（PyTorch 和 TensorFlow 实现）和缺乏自动化模型选择。 该库将 12 个最先进的深度学习模型整合到一个统一的 PyTorch 框架中，提供总计 45 个算法，并简化了 OD 工作流程。 实验结果显示，PyOD 2 在各种数据集上表现出色，提升了部署效率，并在研究和行业中树立了新标准，可在 GitHub 上获取。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.12154v1",
      "published_date": "2024-12-11 07:53:20 UTC",
      "updated_date": "2024-12-11 07:53:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:17:57.490193"
    },
    {
      "arxiv_id": "2412.08156v1",
      "title": "Antelope: Potent and Concealed Jailbreak Attack Strategy",
      "title_zh": "Antelope: 强大且隐蔽的越狱攻击策略",
      "authors": [
        "Xin Zhao",
        "Xiaojun Chen",
        "Haoyu Gao"
      ],
      "abstract": "Due to the remarkable generative potential of diffusion-based models,\nnumerous researches have investigated jailbreak attacks targeting these\nframeworks. A particularly concerning threat within image models is the\ngeneration of Not-Safe-for-Work (NSFW) content. Despite the implementation of\nsecurity filters, numerous efforts continue to explore ways to circumvent these\nsafeguards. Current attack methodologies primarily encompass adversarial prompt\nengineering or concept obfuscation, yet they frequently suffer from slow search\nefficiency, conspicuous attack characteristics and poor alignment with targets.\nTo overcome these challenges, we propose Antelope, a more robust and covert\njailbreak attack strategy designed to expose security vulnerabilities inherent\nin generative models. Specifically, Antelope leverages the confusion of\nsensitive concepts with similar ones, facilitates searches in the semantically\nadjacent space of these related concepts and aligns them with the target\nimagery, thereby generating sensitive images that are consistent with the\ntarget and capable of evading detection. Besides, we successfully exploit the\ntransferability of model-based attacks to penetrate online black-box services.\nExperimental evaluations demonstrate that Antelope outperforms existing\nbaselines across multiple defensive mechanisms, underscoring its efficacy and\nversatility.",
      "tldr_zh": "该论文提出Antelope，一种强大且隐蔽的jailbreak attack策略，旨在针对扩散模型生成Not-Safe-for-Work (NSFW)内容的安全漏洞。Antelope通过利用敏感概念与类似概念的混淆、在语义相邻空间进行搜索并与目标图像对齐，从而生成符合目标的敏感图像，同时规避检测机制。实验结果显示，Antelope在多种防御机制下优于现有基准，证明了其高效性和可转移性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.08156v1",
      "published_date": "2024-12-11 07:22:51 UTC",
      "updated_date": "2024-12-11 07:22:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:18:08.056581"
    },
    {
      "arxiv_id": "2412.08148v1",
      "title": "A Review of Intelligent Device Fault Diagnosis Technologies Based on Machine Vision",
      "title_zh": "基于机器视觉的智能设备故障诊断技术综述",
      "authors": [
        "Guiran Liu",
        "Binrong Zhu"
      ],
      "abstract": "This paper provides a comprehensive review of mechanical equipment fault\ndiagnosis methods, focusing on the advancements brought by Transformer-based\nmodels. It details the structure, working principles, and benefits of\nTransformers, particularly their self-attention mechanism and parallel\ncomputation capabilities, which have propelled their widespread application in\nnatural language processing and computer vision. The discussion highlights key\nTransformer model variants, such as Vision Transformers (ViT) and their\nextensions, which leverage self-attention to improve accuracy and efficiency in\nvisual tasks. Furthermore, the paper examines the application of\nTransformer-based approaches in intelligent fault diagnosis for mechanical\nsystems, showcasing their superior ability to extract and recognize patterns\nfrom complex sensor data for precise fault identification. Despite these\nadvancements, challenges remain, including the reliance on extensive labeled\ndatasets, significant computational demands, and difficulties in deploying\nmodels on resource-limited devices. To address these limitations, the paper\nproposes future research directions, such as developing lightweight Transformer\narchitectures, integrating multimodal data sources, and enhancing adaptability\nto diverse operational conditions. These efforts aim to further expand the\napplication of Transformer-based methods in mechanical fault diagnosis, making\nthem more robust, efficient, and suitable for real-world industrial\nenvironments.",
      "tldr_zh": "这篇论文对基于机器视觉的智能设备故障诊断技术进行了全面综述，重点探讨了 Transformer-based 模型的进展及其在机械设备故障诊断中的应用。论文详细阐述了 Transformer's 结构、工作原理（如自注意力机制和并行计算能力），以及关键变体如 Vision Transformers (ViT)，这些模型在处理复杂传感器数据和模式提取方面显著提高了诊断准确性和效率。尽管存在对大量标注数据集的依赖、高计算需求和部署挑战，论文提出未来研究方向，包括开发轻量级 Transformer 架构、整合多模态数据源以及提升模型对多样化操作环境的适应性，以推动其在实际工业环境中的应用。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "9 pages, This paper has been accepted for publication at RICAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2412.08148v1",
      "published_date": "2024-12-11 07:06:53 UTC",
      "updated_date": "2024-12-11 07:06:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:18:21.767807"
    },
    {
      "arxiv_id": "2412.08147v1",
      "title": "How to Weight Multitask Finetuning? Fast Previews via Bayesian Model-Merging",
      "title_zh": "翻译失败",
      "authors": [
        "Hugo Monzón Maldonado",
        "Thomas Möllenhoff",
        "Nico Daheim",
        "Iryna Gurevych",
        "Mohammad Emtiyaz Khan"
      ],
      "abstract": "When finetuning multiple tasks altogether, it is important to carefully weigh\nthem to get a good performance, but searching for good weights can be difficult\nand costly. Here, we propose to aid the search with fast previews to quickly\nget a rough idea of different reweighting options. We use model merging to\ncreate previews by simply reusing and averaging parameters of models trained on\neach task separately (no retraining required). To improve the quality of\npreviews, we propose a Bayesian approach to design new merging strategies by\nusing more flexible posteriors. We validate our findings on vision and\nnatural-language transformers. Our work shows the benefits of model merging via\nBayes to improve multitask finetuning.",
      "tldr_zh": "该论文探讨了在多任务微调（multitask finetuning）中如何权衡任务权重以优化性能的问题，并提出使用快速预览（fast previews）来加速权重搜索过程。方法通过模型合并（model merging）重用和平均每个任务单独训练的模型参数，避免了重新训练；同时，引入 Bayesian 方法设计更灵活的后验分布，以提升预览质量。在视觉和自然语言 transformer 上进行的验证显示，这种 Bayesian 模型合并策略显著改善了多任务微调的效果。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.08147v1",
      "published_date": "2024-12-11 07:06:36 UTC",
      "updated_date": "2024-12-11 07:06:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:18:35.167551"
    },
    {
      "arxiv_id": "2412.08145v1",
      "title": "A Survey on Private Transformer Inference",
      "title_zh": "翻译失败",
      "authors": [
        "Yang Li",
        "Xinyu Zhou",
        "Yitong Wang",
        "Liangxin Qian",
        "Jun Zhao"
      ],
      "abstract": "Transformer models have revolutionized AI, enabling applications like content\ngeneration and sentiment analysis. However, their use in Machine Learning as a\nService (MLaaS) raises significant privacy concerns, as centralized servers\nprocess sensitive user data. Private Transformer Inference (PTI) addresses\nthese issues using cryptographic techniques such as Secure Multi-Party\nComputation (MPC) and Homomorphic Encryption (HE), enabling secure model\ninference without exposing inputs or models. This paper reviews recent\nadvancements in PTI, analyzing state-of-the-art solutions, their challenges,\nand potential improvements. We also propose evaluation guidelines to assess\nresource efficiency and privacy guarantees, aiming to bridge the gap between\nhigh-performance inference and data privacy.",
      "tldr_zh": "这篇论文调查了Private Transformer Inference (PTI)，旨在解决Transformer模型在Machine Learning as a Service (MLaaS)中的隐私问题，这些问题源于服务器处理敏感用户数据。论文回顾了最近的进展，包括使用Secure Multi-Party Computation (MPC)和Homomorphic Encryption (HE)等加密技术，实现安全的模型推理而不暴露输入或模型。作者分析了现有解决方案的挑战和潜在改进，并提出评估指南，以平衡资源效率和隐私保障，从而桥接高性能推理与数据隐私保护的差距。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "The manuscript is still being revised and will be continuously\n  updated in the future",
      "pdf_url": "http://arxiv.org/pdf/2412.08145v1",
      "published_date": "2024-12-11 07:05:24 UTC",
      "updated_date": "2024-12-11 07:05:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:18:44.141145"
    },
    {
      "arxiv_id": "2412.08144v1",
      "title": "AGMixup: Adaptive Graph Mixup for Semi-supervised Node Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Weigang Lu",
        "Ziyu Guan",
        "Wei Zhao",
        "Yaming Yang",
        "Yibing Zhan",
        "Yiheng Lu",
        "Dapeng Tao"
      ],
      "abstract": "Mixup is a data augmentation technique that enhances model generalization by\ninterpolating between data points using a mixing ratio $\\lambda$ in the image\ndomain. Recently, the concept of mixup has been adapted to the graph domain\nthrough node-centric interpolations. However, these approaches often fail to\naddress the complexity of interconnected relationships, potentially damaging\nthe graph's natural topology and undermining node interactions. Furthermore,\ncurrent graph mixup methods employ a one-size-fits-all strategy with a randomly\nsampled $\\lambda$ for all mixup pairs, ignoring the diverse needs of different\npairs. This paper proposes an Adaptive Graph Mixup (AGMixup) framework for\nsemi-supervised node classification. AGMixup introduces a subgraph-centric\napproach, which treats each subgraph similarly to how images are handled in\nEuclidean domains, thus facilitating a more natural integration of mixup into\ngraph-based learning. We also propose an adaptive mechanism to tune the mixing\nratio $\\lambda$ for diverse mixup pairs, guided by the contextual similarity\nand uncertainty of the involved subgraphs. Extensive experiments across seven\ndatasets on semi-supervised node classification benchmarks demonstrate\nAGMixup's superiority over state-of-the-art graph mixup methods. Source codes\nare available at \\url{https://github.com/WeigangLu/AGMixup}.",
      "tldr_zh": "本文提出 AGMixup，一种自适应图混合作用框架，用于半监督节点分类，以解决现有方法忽略图拓扑复杂性和统一混合比例 λ 的问题。AGMixup 采用子图中心方法，将子图视为欧氏空间中的图像进行插值，实现更自然的图数据增强。同时，该框架引入自适应机制，根据子图的上下文相似性和不确定性动态调整 λ，以优化不同混合作用的效果。在七个数据集上的实验表明，AGMixup 优于最先进的方法，提升了节点分类性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.08144v1",
      "published_date": "2024-12-11 07:04:35 UTC",
      "updated_date": "2024-12-11 07:04:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:18:56.503703"
    },
    {
      "arxiv_id": "2412.08139v1",
      "title": "Wasserstein Distance Rivals Kullback-Leibler Divergence for Knowledge Distillation",
      "title_zh": "翻译失败",
      "authors": [
        "Jiaming Lv",
        "Haoyuan Yang",
        "Peihua Li"
      ],
      "abstract": "Since pioneering work of Hinton et al., knowledge distillation based on\nKullback-Leibler Divergence (KL-Div) has been predominant, and recently its\nvariants have achieved compelling performance. However, KL-Div only compares\nprobabilities of the corresponding category between the teacher and student\nwhile lacking a mechanism for cross-category comparison. Besides, KL-Div is\nproblematic when applied to intermediate layers, as it cannot handle\nnon-overlapping distributions and is unaware of geometry of the underlying\nmanifold. To address these downsides, we propose a methodology of Wasserstein\nDistance (WD) based knowledge distillation. Specifically, we propose a logit\ndistillation method called WKD-L based on discrete WD, which performs\ncross-category comparison of probabilities and thus can explicitly leverage\nrich interrelations among categories. Moreover, we introduce a feature\ndistillation method called WKD-F, which uses a parametric method for modeling\nfeature distributions and adopts continuous WD for transferring knowledge from\nintermediate layers. Comprehensive evaluations on image classification and\nobject detection have shown (1) for logit distillation WKD-L outperforms very\nstrong KL-Div variants; (2) for feature distillation WKD-F is superior to the\nKL-Div counterparts and state-of-the-art competitors. The source code is\navailable at https://peihuali.org/WKD",
      "tldr_zh": "本文指出，传统的基于 Kullback-Leibler Divergence (KL-Div) 的知识蒸馏方法存在局限性，仅比较对应类别的概率，无法进行跨类别比较，且在中间层处理非重叠分布时忽略了底层流形几何。针对这些问题，论文提出了一种基于 Wasserstein Distance (WD) 的方法，包括 WKD-L 用于 logit 蒸馏（通过离散 WD 实现跨类别概率比较）和 WKD-F 用于特征蒸馏（通过参数化建模和连续 WD 转移中间层知识）。在图像分类和物体检测任务的全面评估中，WKD-L 优于 KL-Div 的强力变体，而 WKD-F 超越了现有竞争者，证明了 WD 的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to NeurIPS 2024. Equal contribution from first two authors",
      "pdf_url": "http://arxiv.org/pdf/2412.08139v1",
      "published_date": "2024-12-11 06:54:39 UTC",
      "updated_date": "2024-12-11 06:54:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:19:10.052877"
    },
    {
      "arxiv_id": "2412.08138v2",
      "title": "Learn How to Query from Unlabeled Data Streams in Federated Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Yuchang Sun",
        "Xinran Li",
        "Tao Lin",
        "Jun Zhang"
      ],
      "abstract": "Federated learning (FL) enables collaborative learning among decentralized\nclients while safeguarding the privacy of their local data. Existing studies on\nFL typically assume offline labeled data available at each client when the\ntraining starts. Nevertheless, the training data in practice often arrive at\nclients in a streaming fashion without ground-truth labels. Given the expensive\nannotation cost, it is critical to identify a subset of informative samples for\nlabeling on clients. However, selecting samples locally while accommodating the\nglobal training objective presents a challenge unique to FL. In this work, we\ntackle this conundrum by framing the data querying process in FL as a\ncollaborative decentralized decision-making problem and proposing an effective\nsolution named LeaDQ, which leverages multi-agent reinforcement learning\nalgorithms. In particular, under the implicit guidance from global information,\nLeaDQ effectively learns the local policies for distributed clients and steers\nthem towards selecting samples that can enhance the global model's accuracy.\nExtensive simulations on image and text tasks show that LeaDQ advances the\nmodel performance in various FL scenarios, outperforming the benchmarking\nalgorithms.",
      "tldr_zh": "该论文解决了Federated Learning (FL) 中数据以流式方式到达且无标签的挑战，提出了一种协作式去中心化决策方法。作者引入LeaDQ框架，利用multi-agent reinforcement learning 算法，让客户端在全球信息的隐式指导下学习本地查询策略，从而选择信息丰富的样本进行标注以提升全局模型准确性。在图像和文本任务的广泛实验中，LeaDQ在各种FL场景下优于基准算法，显著提高了模型性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.08138v2",
      "published_date": "2024-12-11 06:51:45 UTC",
      "updated_date": "2024-12-12 01:47:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:19:21.148516"
    },
    {
      "arxiv_id": "2412.16182v1",
      "title": "Decoding Poultry Vocalizations -- Natural Language Processing and Transformer Models for Semantic and Emotional Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Venkatraman Manikandan",
        "Suresh Neethirajan"
      ],
      "abstract": "Deciphering the acoustic language of chickens offers new opportunities in\nanimal welfare and ecological informatics. Their subtle vocal signals encode\nhealth conditions, emotional states, and dynamic interactions within\necosystems. Understanding the semantics of these calls provides a valuable tool\nfor interpreting their functional vocabulary and clarifying how each sound\nserves a specific purpose in social and environmental contexts. We apply\nadvanced Natural Language Processing and transformer based models to translate\nbioacoustic data into meaningful insights. Our method integrates Wave2Vec 2.0\nfor raw audio feature extraction with a fine tuned Bidirectional Encoder\nRepresentations from Transformers model, pretrained on a broad corpus of animal\nsounds and adapted to poultry tasks. This pipeline decodes poultry\nvocalizations into interpretable categories including distress calls, feeding\nsignals, and mating vocalizations, revealing emotional nuances often overlooked\nby conventional analyses. Achieving 92 percent accuracy in classifying key\nvocalization types, our approach demonstrates the feasibility of real time\nautomated monitoring of flock health and stress. By tracking this functional\nvocabulary, farmers can respond proactively to environmental or behavioral\nchanges, improving poultry welfare, reducing stress related productivity\nlosses, and supporting more sustainable farm management. Beyond agriculture,\nthis research enhances our understanding of computational ecology. Accessing\nthe semantic foundation of animal calls may indicate biodiversity,\nenvironmental stressors, and species interactions, informing integrative\necosystem level decision making.",
      "tldr_zh": "本研究利用自然语言处理（NLP）和Transformer模型，分析鸡的叫声语义和情绪，以提升动物福利和生态信息学。方法结合Wave2Vec 2.0提取音频特征，并微调Bidirectional Encoder Representations from Transformers（BERT）模型，预训练于动物声音数据并适应家禽任务，从而将叫声分类为求救、喂食或交配信号，并揭示情绪细微差别。实验结果显示，该方法在关键叫声分类中达到92%的准确率，支持实时监控鸡群健康和压力，帮助农民主动改善福利、减少生产损失，并扩展到生态学领域以评估生物多样性和环境应激。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "28 Pages, 14 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.16182v1",
      "published_date": "2024-12-11 06:44:32 UTC",
      "updated_date": "2024-12-11 06:44:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:19:32.829857"
    },
    {
      "arxiv_id": "2412.08133v1",
      "title": "Intelligent Electric Power Steering: Artificial Intelligence Integration Enhances Vehicle Safety and Performance",
      "title_zh": "智能电动助力转向：人工智能整合提升车辆安全和性能",
      "authors": [
        "Vikas Vyas",
        "Sneha Sudhir Shetiya"
      ],
      "abstract": "Electric Power Steering (EPS) systems utilize electric motors to aid users in\nsteering their vehicles, which provide additional precise control and reduced\nenergy consumption compared to traditional hydraulic systems. EPS technology\nprovides safety,control and efficiency.. This paper explains the integration of\nArtificial Intelligence (AI) into Electric Power Steering (EPS) systems,\nfocusing on its role in enhancing the safety, and adaptability across diverse\ndriving conditions. We explore significant development in AI-driven EPS,\nincluding predictive control algorithms, adaptive torque management systems,\nand data-driven diagnostics. The paper presents case studies of AI applications\nin EPS, such as Lane centering control (LCC), Automated Parking Systems, and\nAutonomous Vehicle Steering, while considering the challenges, limitations, and\nfuture prospects of this technology. This article discusses current\ndevelopments in AI-driven EPS, emphasizing on the benefits of improved safety,\nadaptive control, and predictive maintenance. Challenges in integrating AI in\nEPS systems. This paper addresses cybersecurity risks, ethical concerns, and\ntechnical limitations,, along with next steps for research and implementation\nin autonomous, and connected vehicles.",
      "tldr_zh": "本论文探讨了 Artificial Intelligence (AI) 与 Electric Power Steering (EPS) 系统的整合，旨在提升车辆安全、性能和适应性。研究重点介绍了 AI 在 EPS 中的应用，包括预测控制算法、适应性扭矩管理系统以及数据驱动诊断，这些方法帮助实现更精确的转向控制。论文通过案例研究，如 Lane Centering Control (LCC)、Automated Parking Systems 和 Autonomous Vehicle Steering，展示了 AI 带来的益处，包括改善安全、适应不同驾驶条件以及预测维护。同时，讨论了整合挑战，如网络安全风险、伦理问题和技术限制，并展望了 AI 在自主和连接车辆中的未来研究方向。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "IEEE Summit on Reliability, Availability and Serviceability, 2024",
      "pdf_url": "http://arxiv.org/pdf/2412.08133v1",
      "published_date": "2024-12-11 06:41:51 UTC",
      "updated_date": "2024-12-11 06:41:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:19:44.346639"
    },
    {
      "arxiv_id": "2412.08131v1",
      "title": "DiffRaman: A Conditional Latent Denoising Diffusion Probabilistic Model for Bacterial Raman Spectroscopy Identification Under Limited Data Conditions",
      "title_zh": "翻译失败",
      "authors": [
        "Haiming Yao",
        "Wei Luo",
        "Ang Gao",
        "Tao Zhou",
        "Xue Wang"
      ],
      "abstract": "Raman spectroscopy has attracted significant attention in various biochemical\ndetection fields, especially in the rapid identification of pathogenic\nbacteria. The integration of this technology with deep learning to facilitate\nautomated bacterial Raman spectroscopy diagnosis has emerged as a key focus in\nrecent research. However, the diagnostic performance of existing deep learning\nmethods largely depends on a sufficient dataset, and in scenarios where there\nis a limited availability of Raman spectroscopy data, it is inadequate to fully\noptimize the numerous parameters of deep neural networks. To address these\nchallenges, this paper proposes a data generation method utilizing deep\ngenerative models to expand the data volume and enhance the recognition\naccuracy of bacterial Raman spectra. Specifically, we introduce DiffRaman, a\nconditional latent denoising diffusion probability model for Raman spectra\ngeneration. Experimental results demonstrate that synthetic bacterial Raman\nspectra generated by DiffRaman can effectively emulate real experimental\nspectra, thereby enhancing the performance of diagnostic models, especially\nunder conditions of limited data. Furthermore, compared to existing generative\nmodels, the proposed DiffRaman offers improvements in both generation quality\nand computational efficiency. Our DiffRaman approach offers a well-suited\nsolution for automated bacteria Raman spectroscopy diagnosis in data-scarce\nscenarios, offering new insights into alleviating the labor of spectroscopic\nmeasurements and enhancing rare bacteria identification.",
      "tldr_zh": "本文针对 Raman spectroscopy 在细菌识别中的数据有限问题，提出 DiffRaman，一种条件潜在去噪扩散概率模型，用于生成合成光谱数据以扩展数据集。DiffRaman 通过结合深度生成技术，提高了诊断模型的识别准确率，尤其在数据稀缺场景下。实验结果显示，该模型生成的合成光谱能有效模拟真实光谱，并在生成质量和计算效率上优于现有生成模型。总体上，DiffRaman 为自动化细菌 Raman spectroscopy 诊断提供了高效解决方案，减少光谱测量劳动并增强稀有细菌识别。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.08131v1",
      "published_date": "2024-12-11 06:36:55 UTC",
      "updated_date": "2024-12-11 06:36:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:19:57.841024"
    },
    {
      "arxiv_id": "2412.12153v2",
      "title": "Revisiting Weight Averaging for Model Merging",
      "title_zh": "翻译失败",
      "authors": [
        "Jiho Choi",
        "Donggyun Kim",
        "Chanhyuk Lee",
        "Seunghoon Hong"
      ],
      "abstract": "Model merging aims to build a multi-task learner by combining the parameters\nof individually fine-tuned models without additional training. While a\nstraightforward approach is to average model parameters across tasks, this\noften results in suboptimal performance due to interference among parameters\nacross tasks. In this paper, we present intriguing results that weight\naveraging implicitly induces task vectors centered around the weight averaging\nitself and that applying a low-rank approximation to these centered task\nvectors significantly improves merging performance. Our analysis shows that\ncentering the task vectors effectively reduces task interference and most of\ntask-specific knowledge is concentrated in the top singular vectors. Our method\ndemonstrates robust and scalable performance on vision benchmarks across\nvarying numbers of tasks and model sizes. Furthermore, we observe that our\napproach is applicable to natural language processing tasks with competitive\nperformance.",
      "tldr_zh": "该论文重新审视了模型合并(Model Merging)中的权重平均(Weight Averaging)方法，指出直接平均参数会导致任务间干扰和性能不佳。研究发现，权重平均隐式诱导了以其为中心的任务向量，通过对这些向量进行低秩逼近(Low-Rank Approximation)可以有效减少干扰，并将大部分任务特定知识集中在顶层奇异向量(Top Singular Vectors)。实验结果显示，该方法在视觉基准上表现出稳健和可扩展的性能，适用于不同任务数量和模型大小，并扩展到自然语言处理(Natural Language Processing)任务中。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Additional experiment results are included",
      "pdf_url": "http://arxiv.org/pdf/2412.12153v2",
      "published_date": "2024-12-11 06:29:20 UTC",
      "updated_date": "2025-04-03 11:46:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:20:08.986056"
    },
    {
      "arxiv_id": "2412.08127v3",
      "title": "Evil twins are not that evil: Qualitative insights into machine-generated prompts",
      "title_zh": "翻译失败",
      "authors": [
        "Nathanaël Carraz Rakotonirina",
        "Corentin Kervadec",
        "Francesca Franzon",
        "Marco Baroni"
      ],
      "abstract": "It has been widely observed that language models (LMs) respond in predictable\nways to algorithmically generated prompts that are seemingly unintelligible.\nThis is both a sign that we lack a full understanding of how LMs work, and a\npractical challenge, because opaqueness can be exploited for harmful uses of\nLMs, such as jailbreaking. We present the first thorough analysis of opaque\nmachine-generated prompts, or autoprompts, pertaining to 6 LMs of different\nsizes and families. We find that machine-generated prompts are characterized by\na last token that is often intelligible and strongly affects the generation. A\nsmall but consistent proportion of the previous tokens are prunable, probably\nappearing in the prompt as a by-product of the fact that the optimization\nprocess fixes the number of tokens. The remaining tokens fall into two\ncategories: filler tokens, which can be replaced with semantically unrelated\nsubstitutes, and keywords, that tend to have at least a loose semantic relation\nwith the generation, although they do not engage in well-formed syntactic\nrelations with it. Additionally, human experts can reliably identify the most\ninfluential tokens in an autoprompt a posteriori, suggesting these prompts are\nnot entirely opaque. Finally, some of the ablations we applied to autoprompts\nyield similar effects in natural language inputs, suggesting that autoprompts\nemerge naturally from the way LMs process linguistic inputs in general.",
      "tldr_zh": "这篇论文对 machine-generated prompts（简称 autoprompts）进行了首次定性分析，探讨了语言模型（LMs）对这些看似不透明的算法生成提示的响应机制。研究发现，autoprompts 的最后一个 token 通常可理解且对生成影响重大，而其他 token 包括可修剪的标记、filler tokens（可替换为语义无关的替代品）和 keywords（与生成有松散语义关系但无良好句法连接）。此外，人类专家能可靠识别关键 token，且对 autoprompts 的某些消融操作在自然语言输入中产生类似效果，表明这些提示并非完全不透明，并为理解 LMs 的处理方式提供了新见解。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.08127v3",
      "published_date": "2024-12-11 06:22:44 UTC",
      "updated_date": "2025-03-31 16:33:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:20:22.074833"
    },
    {
      "arxiv_id": "2412.08120v1",
      "title": "Dense Depth from Event Focal Stack",
      "title_zh": "翻译失败",
      "authors": [
        "Kenta Horikawa",
        "Mariko Isogawa",
        "Hideo Saito",
        "Shohei Mori"
      ],
      "abstract": "We propose a method for dense depth estimation from an event stream generated\nwhen sweeping the focal plane of the driving lens attached to an event camera.\nIn this method, a depth map is inferred from an ``event focal stack'' composed\nof the event stream using a convolutional neural network trained with\nsynthesized event focal stacks. The synthesized event stream is created from a\nfocal stack generated by Blender for any arbitrary 3D scene. This allows for\ntraining on scenes with diverse structures. Additionally, we explored methods\nto eliminate the domain gap between real event streams and synthetic event\nstreams. Our method demonstrates superior performance over a depth-from-defocus\nmethod in the image domain on synthetic and real datasets.",
      "tldr_zh": "我们提出了一种从事件流中估计密集深度（Dense Depth）的全新方法，该方法利用事件相机扫过焦平面生成“事件焦堆栈”（Event Focal Stack）。通过训练一个卷积神经网络（Convolutional Neural Network, CNN）来处理这些焦堆栈，我们使用Blender生成的合成事件流作为训练数据，以覆盖多样化的3D场景。研究还探讨了减少真实事件流与合成事件流之间领域差距（Domain Gap）的技术。实验结果显示，该方法在合成和真实数据集上优于传统的深度从模糊（Depth-from-Defocus）方法。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at WACV2025",
      "pdf_url": "http://arxiv.org/pdf/2412.08120v1",
      "published_date": "2024-12-11 06:13:38 UTC",
      "updated_date": "2024-12-11 06:13:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:20:33.292307"
    },
    {
      "arxiv_id": "2412.12152v1",
      "title": "GraphTool-Instruction: Revolutionizing Graph Reasoning in LLMs through Decomposed Subtask Instruction",
      "title_zh": "翻译失败",
      "authors": [
        "Rongzheng Wang",
        "Shuang Liang",
        "Qizhi Chen",
        "Jiasheng Zhang",
        "Ke Qin"
      ],
      "abstract": "Large language models (LLMs) have been demonstrated to possess the\ncapabilities to understand fundamental graph properties and address various\ngraph reasoning tasks. Existing methods fine-tune LLMs to understand and\nexecute graph reasoning tasks by specially designed task instructions. However,\nthese Text-Instruction methods generally exhibit poor performance. Inspired by\ntool learning, researchers propose Tool-Instruction methods to solve various\ngraph problems by special tool calling (e.g., function, API and model),\nachieving significant improvements in graph reasoning tasks. Nevertheless,\ncurrent Tool-Instruction approaches focus on the tool information and ignore\nthe graph structure information, which leads to significantly inferior\nperformance on small-scale LLMs (less than 13B). To tackle this issue, we\npropose GraphTool-Instruction, an innovative Instruction-tuning approach that\ndecomposes the graph reasoning task into three distinct subtasks (i.e., graph\nextraction, tool name identification and tool parameter extraction), and design\nspecialized instructions for each subtask. Our GraphTool-Instruction can be\nused as a plug-and-play prompt for different LLMs without fine-tuning.\nMoreover, building on GraphTool-Instruction, we develop GTools, a dataset that\nincludes twenty graph reasoning tasks, and create a graph reasoning LLM called\nGraphForge based on Llama3-8B. We conduct extensive experiments on twenty graph\nreasoning tasks with different graph types (e.g., graph size or graph\ndirection), and we find that GraphTool-Instruction achieves SOTA compared to\nText-Instruction and Tool-Instruction methods. Fine-tuned on GTools, GraphForge\ngets further improvement of over 30% compared to the Tool-Instruction enhanced\nGPT-3.5-turbo, and it performs comparably to the high-cost GPT-4o. Our codes\nand data are available at\nhttps://anonymous.4open.science/r/GraphTool-Instruction.",
      "tldr_zh": "本文提出 GraphTool-Instruction，一种创新的 Instruction-tuning 方法，将图推理任务分解为三个子任务（graph extraction、tool name identification 和 tool parameter extraction），并为每个子任务设计专用指令，以解决现有 Tool-Instruction 方法忽略图结构信息的问题。该方法作为 plug-and-play prompt，可直接应用于不同 LLMs，无需 fine-tuning。实验结果显示，GraphTool-Instruction 在二十个图推理任务上超越 Text-Instruction 和 Tool-Instruction 方法，达到 SOTA 水平；基于 Llama3-8B 构建的 GraphForge 模型在 fine-tuning 后比 GPT-3.5-turbo 提升超过30%，并与 GPT-4o 相当。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "22 pages, have been accepted by KDD 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.12152v1",
      "published_date": "2024-12-11 06:12:52 UTC",
      "updated_date": "2024-12-11 06:12:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:20:45.985835"
    },
    {
      "arxiv_id": "2412.12151v1",
      "title": "SMARTCAL: An Approach to Self-Aware Tool-Use Evaluation and Calibration",
      "title_zh": "SMARTCAL：一种自感知工具使用评估和校准方法",
      "authors": [
        "Yuanhao Shen",
        "Xiaodan Zhu",
        "Lei Chen"
      ],
      "abstract": "The tool-use ability of Large Language Models (LLMs) has a profound impact on\na wide range of industrial applications. However, LLMs' self-control and\ncalibration capability in appropriately using tools remains understudied. The\nproblem is consequential as it raises potential risks of degraded performance\nand poses a threat to the trustworthiness of the models. In this paper, we\nconduct a study on a family of state-of-the-art LLMs on three datasets with two\nmainstream tool-use frameworks. Our study reveals the tool-abuse behavior of\nLLMs, a tendency for models to misuse tools with overconfidence. We also find\nthat this is a common issue regardless of model capability. Accordingly, we\npropose a novel approach, \\textit{SMARTCAL}, to mitigate the observed issues,\nand our results show an average of 8.6 percent increase in the QA performance\nand a 21.6 percent decrease in Expected Calibration Error (ECE) compared to\nbaseline models.",
      "tldr_zh": "该研究探讨了大型语言模型（LLMs）在使用工具时的自我控制和校准能力问题，发现LLMs存在工具滥用行为，即过度自信地误用工具，且此问题独立于模型能力。作者通过在三个数据集和两种主流工具框架上测试一系列最先进LLMs，提出了SMARTCAL方法，该方法通过自我感知评估和校准来缓解这些问题。实验结果显示，SMARTCAL使QA性能平均提高了8.6%，并将Expected Calibration Error (ECE)降低了21.6%，从而提升了模型的可信度和性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.12151v1",
      "published_date": "2024-12-11 06:09:12 UTC",
      "updated_date": "2024-12-11 06:09:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:20:56.651876"
    },
    {
      "arxiv_id": "2412.08117v1",
      "title": "LatentSpeech: Latent Diffusion for Text-To-Speech Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Haowei Lou",
        "Helen Paik",
        "Pari Delir Haghighi",
        "Wen Hu",
        "Lina Yao"
      ],
      "abstract": "Diffusion-based Generative AI gains significant attention for its superior\nperformance over other generative techniques like Generative Adversarial\nNetworks and Variational Autoencoders. While it has achieved notable\nadvancements in fields such as computer vision and natural language processing,\ntheir application in speech generation remains under-explored. Mainstream\nText-to-Speech systems primarily map outputs to Mel-Spectrograms in the\nspectral space, leading to high computational loads due to the sparsity of\nMelSpecs. To address these limitations, we propose LatentSpeech, a novel TTS\ngeneration approach utilizing latent diffusion models. By using latent\nembeddings as the intermediate representation, LatentSpeech reduces the target\ndimension to 5% of what is required for MelSpecs, simplifying the processing\nfor the TTS encoder and vocoder and enabling efficient high-quality speech\ngeneration. This study marks the first integration of latent diffusion models\nin TTS, enhancing the accuracy and naturalness of generated speech.\nExperimental results on benchmark datasets demonstrate that LatentSpeech\nachieves a 25% improvement in Word Error Rate and a 24% improvement in Mel\nCepstral Distortion compared to existing models, with further improvements\nrising to 49.5% and 26%, respectively, with additional training data. These\nfindings highlight the potential of LatentSpeech to advance the\nstate-of-the-art in TTS technology",
      "tldr_zh": "这篇论文提出了LatentSpeech，一种基于潜在扩散模型的文本到语音(TTS)生成方法，旨在解决主流TTS系统依赖Mel-Spectrograms导致的计算负荷高和效率低的问题。LatentSpeech使用latent embeddings作为中间表示，将目标维度减少到Mel-Spectrograms的5%，从而简化编码器和声码器的处理过程，并提升生成语音的准确性和自然性。实验结果显示，在基准数据集上，该方法比现有模型改善了25%的Word Error Rate和24%的Mel Cepstral Distortion；在增加训练数据后，进一步提升至49.5%和26%。这项研究首次将latent diffusion models整合到TTS领域，展示了其在推进语音生成技术方面的潜力。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.MM",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.08117v1",
      "published_date": "2024-12-11 05:55:06 UTC",
      "updated_date": "2024-12-11 05:55:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:21:10.341809"
    },
    {
      "arxiv_id": "2501.09021v1",
      "title": "Navigating Ethical Challenges in Generative AI-Enhanced Research: The ETHICAL Framework for Responsible Generative AI Use",
      "title_zh": "在",
      "authors": [
        "Douglas Eacersall",
        "Lynette Pretorius",
        "Ivan Smirnov",
        "Erika Spray",
        "Sam Illingworth",
        "Ritesh Chugh",
        "Sonja Strydom",
        "Dianne Stratton-Maher",
        "Jonathan Simmons",
        "Isaac Jennings",
        "Rian Roux",
        "Ruth Kamrowski",
        "Abigail Downie",
        "Chee Ling Thong",
        "Katharine A. Howell"
      ],
      "abstract": "The rapid adoption of generative artificial intelligence (GenAI) in research\npresents both opportunities and ethical challenges that should be carefully\nnavigated. Although GenAI tools can enhance research efficiency through\nautomation of tasks such as literature review and data analysis, their use\nraises concerns about aspects such as data accuracy, privacy, bias, and\nresearch integrity. This paper develops the ETHICAL framework, which is a\npractical guide for responsible GenAI use in research. Employing a\nconstructivist case study examining multiple GenAI tools in real research\ncontexts, the framework consists of seven key principles: Examine policies and\nguidelines, Think about social impacts, Harness understanding of the\ntechnology, Indicate use, Critically engage with outputs, Access secure\nversions, and Look at user agreements. Applying these principles will enable\nresearchers to uphold research integrity while leveraging GenAI benefits. The\nframework addresses a critical gap between awareness of ethical issues and\npractical action steps, providing researchers with concrete guidance for\nethical GenAI integration. This work has implications for research practice,\ninstitutional policy development, and the broader academic community while\nadapting to an AI-enhanced research landscape. The ETHICAL framework can serve\nas a foundation for developing AI literacy in academic settings and promoting\nresponsible innovation in research methodologies.",
      "tldr_zh": "这篇论文探讨了生成式AI（GenAI）在研究中的伦理挑战，包括数据准确性、隐私、偏见和研究完整性等问题，并提出ETHICAL框架作为负责任使用GenAI的实用指南。框架基于建构主义案例研究，包含七个关键原则：Examine policies and guidelines、Think about social impacts、Harness understanding of the technology、Indicate use、Critically engage with outputs、Access secure versions和Look at user agreements。应用该框架能帮助研究人员维护研究完整性，同时利用GenAI的效率优势，并为机构政策、AI literacy和学术创新提供基础。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "I.2.0"
      ],
      "primary_category": "cs.CY",
      "comment": "28 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2501.09021v1",
      "published_date": "2024-12-11 05:49:11 UTC",
      "updated_date": "2024-12-11 05:49:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:21:22.070464"
    },
    {
      "arxiv_id": "2412.08112v1",
      "title": "Aligner-Guided Training Paradigm: Advancing Text-to-Speech Models with Aligner Guided Duration",
      "title_zh": "翻译失败",
      "authors": [
        "Haowei Lou",
        "Helen Paik",
        "Wen Hu",
        "Lina Yao"
      ],
      "abstract": "Recent advancements in text-to-speech (TTS) systems, such as FastSpeech and\nStyleSpeech, have significantly improved speech generation quality. However,\nthese models often rely on duration generated by external tools like the\nMontreal Forced Aligner, which can be time-consuming and lack flexibility. The\nimportance of accurate duration is often underestimated, despite their crucial\nrole in achieving natural prosody and intelligibility. To address these\nlimitations, we propose a novel Aligner-Guided Training Paradigm that\nprioritizes accurate duration labelling by training an aligner before the TTS\nmodel. This approach reduces dependence on external tools and enhances\nalignment accuracy. We further explore the impact of different acoustic\nfeatures, including Mel-Spectrograms, MFCCs, and latent features, on TTS model\nperformance. Our experimental results show that aligner-guided duration\nlabelling can achieve up to a 16\\% improvement in word error rate and\nsignificantly enhance phoneme and tone alignment. These findings highlight the\neffectiveness of our approach in optimizing TTS systems for more natural and\nintelligible speech generation.",
      "tldr_zh": "本文提出 Aligner-Guided Training Paradigm，一种新颖的训练框架，用于提升 Text-to-Speech (TTS) 模型的性能，通过先训练一个 aligner 来生成更准确的 duration 标注，从而减少对外部工具如 Montreal Forced Aligner 的依赖，并改善语音的自然 prosody 和 intelligibility。研究探索了不同声学特征（如 Mel-Spectrograms、MFCCs 和 latent features）对 TTS 模型的影响。实验结果显示，该方法可将 word error rate 降低最多 16%，并显著提升 phoneme 和 tone alignment，最终优化 TTS 系统实现更自然和易懂的语音生成。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.08112v1",
      "published_date": "2024-12-11 05:39:12 UTC",
      "updated_date": "2024-12-11 05:39:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:21:34.180523"
    },
    {
      "arxiv_id": "2412.08109v2",
      "title": "Unseen Horizons: Unveiling the Real Capability of LLM Code Generation Beyond the Familiar",
      "title_zh": "翻译失败",
      "authors": [
        "Yuanliang Zhang",
        "Yifan Xie",
        "Shanshan Li",
        "Ke Liu",
        "Chong Wang",
        "Zhouyang Jia",
        "Xiangbing Huang",
        "Jie Song",
        "Chaopeng Luo",
        "Zhizheng Zheng",
        "Rulin Xu",
        "Yitong Liu",
        "Si Zheng",
        "Xiangke Liao"
      ],
      "abstract": "Recently, large language models (LLMs) have shown strong potential in code\ngeneration tasks. However, there are still gaps before they can be fully\napplied in actual software development processes. Accurately assessing the code\ngeneration capabilities of large language models has become an important basis\nfor evaluating and improving the models. Some existing works have constructed\ndatasets to evaluate the capabilities of these models. However, the current\nevaluation process may encounter the illusion of \"Specialist in Familiarity\",\nprimarily due to three gaps: the exposure of target code, case timeliness, and\ndependency availability. The fundamental reason for these gaps is that the code\nin current datasets may have been extensively exposed and exercised during the\ntraining phase, and due to the continuous training and development of LLM,\ntheir timeliness has been severely compromised. The key to solve the problem is\nto, as much as possible, evaluate the LLMs using code that they have not\nencountered before. Thus, the fundamental idea in this paper is to draw on the\nconcept of code obfuscation, changing code at different levels while ensuring\nthe functionality and output. To this end, we build a code-obfuscation based\nbenchmark OBFUSEVAL. We first collect 1,354 raw cases from five real-world\nprojects, including function description and code. Then we use three-level\nstrategy (symbol, structure and semantic) to obfuscate descriptions, code and\ncontext dependencies. We evaluate four LLMs on OBFU- SEVAL and compared the\neffectiveness of different obfuscation strategy. We use official test suites of\nthese projects to evaluate the generated code. The results show that after\nobfuscation, the average decrease ratio of test pass rate can up to 62.5%.",
      "tldr_zh": "本研究揭示了大型语言模型 (LLMs) 在代码生成任务中的真实能力，指出现有评估因目标代码暴露、案例时效性和依赖可用性等问题而产生“Familiarity Specialist”幻觉。论文提出构建基于代码混淆 (code obfuscation) 的基准 OBFUSEVAL，通过从五个真实项目收集1354个案例，并采用符号、结构和语义三层策略对描述、代码和上下文依赖进行混淆，以评估 LLMs 对未见过代码的生成性能。实验结果显示，在 OBFUSEVAL 上，四种 LLMs 的测试通过率平均下降62.5%，强调了改进模型泛化能力的必要性。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted by the 47th International Conference on Software Engineering\n  (ICSE 2025)",
      "pdf_url": "http://arxiv.org/pdf/2412.08109v2",
      "published_date": "2024-12-11 05:31:39 UTC",
      "updated_date": "2025-01-15 11:57:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:21:46.307548"
    },
    {
      "arxiv_id": "2412.08099v4",
      "title": "Adversarial Vulnerabilities in Large Language Models for Time Series Forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Fuqiang Liu",
        "Sicong Jiang",
        "Luis Miranda-Moreno",
        "Seongjin Choi",
        "Lijun Sun"
      ],
      "abstract": "Large Language Models (LLMs) have recently demonstrated significant potential\nin time series forecasting, offering impressive capabilities in handling\ncomplex temporal data. However, their robustness and reliability in real-world\napplications remain under-explored, particularly concerning their\nsusceptibility to adversarial attacks. In this paper, we introduce a targeted\nadversarial attack framework for LLM-based time series forecasting. By\nemploying both gradient-free and black-box optimization methods, we generate\nminimal yet highly effective perturbations that significantly degrade the\nforecasting accuracy across multiple datasets and LLM architectures. Our\nexperiments, which include models like LLMTime with GPT-3.5, GPT-4, LLaMa, and\nMistral, TimeGPT, and TimeLLM show that adversarial attacks lead to much more\nsevere performance degradation than random noise, and demonstrate the broad\neffectiveness of our attacks across different LLMs. The results underscore the\ncritical vulnerabilities of LLMs in time series forecasting, highlighting the\nneed for robust defense mechanisms to ensure their reliable deployment in\npractical applications. The code repository can be found at\nhttps://github.com/JohnsonJiang1996/AdvAttack_LLM4TS.",
      "tldr_zh": "本论文探讨了大语言模型（LLMs）在时间序列预测中的对抗性漏洞，揭示了这些模型在实际应用中对攻击的易感性。研究者提出了一种针对LLM-based预测的攻击框架，使用梯度-free和黑箱优化方法生成最小扰动，从而显著降低多个数据集和模型（如GPT-3.5、GPT-4、LLaMa、Mistral、TimeGPT和TimeLLM）的预测准确性。实验结果显示，对抗攻击导致的性能下降远超随机噪声，并证明了其在不同LLM中的广泛有效性，强调了开发robust防御机制的紧迫性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "AISTATS 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.08099v4",
      "published_date": "2024-12-11 04:53:15 UTC",
      "updated_date": "2025-03-12 21:35:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:23:57.413288"
    },
    {
      "arxiv_id": "2412.08098v2",
      "title": "What You See Is Not Always What You Get: An Empirical Study of Code Comprehension by Large Language Models",
      "title_zh": "眼见不一定为实：大型语言模型代码理解的实证研究",
      "authors": [
        "Bangshuo Zhu",
        "Jiawen Wen",
        "Huaming Chen"
      ],
      "abstract": "Recent studies have demonstrated outstanding capabilities of large language\nmodels (LLMs) in software engineering tasks, including code generation and\ncomprehension. While LLMs have shown significant potential in assisting with\ncoding, it is perceived that LLMs are vulnerable to adversarial attacks. In\nthis paper, we investigate the vulnerability of LLMs to imperceptible attacks,\nwhere hidden character manipulation in source code misleads LLMs' behaviour\nwhile remaining undetectable to human reviewers. We devise these attacks into\nfour distinct categories and analyse their impacts on code analysis and\ncomprehension tasks. These four types of imperceptible coding character attacks\ninclude coding reordering, invisible coding characters, code deletions, and\ncode homoglyphs. To comprehensively benchmark the robustness of current LLMs\nsolutions against the attacks, we present a systematic experimental evaluation\non multiple state-of-the-art LLMs. Our experimental design introduces two key\nperformance metrics, namely model confidence using log probabilities of\nresponse, and the response correctness. A set of controlled experiments are\nconducted using a large-scale perturbed and unperturbed code snippets as the\nprimary prompt input. Our findings confirm the susceptibility of LLMs to\nimperceptible coding character attacks, while different LLMs present different\nnegative correlations between perturbation magnitude and performance. These\nresults highlight the urgent need for robust LLMs capable of manoeuvring\nbehaviours under imperceptible adversarial conditions. We anticipate this work\nprovides valuable insights for enhancing the security and trustworthiness of\nLLMs in software engineering applications.",
      "tldr_zh": "该研究通过实证分析探讨了大型语言模型 (LLMs) 在代码理解任务中的脆弱性，特别是对隐蔽攻击的敏感性，这些攻击包括代码重排序、不可见字符、代码删除和代码同形字符。研究者设计了系统实验，使用模型置信度（log probabilities）和响应正确性作为指标，对多个最先进 LLMs 进行了评估。结果显示，LLMs 容易受到这些攻击影响，导致性能下降，且不同模型的鲁棒性存在差异，突显了提升 LLMs 在软件工程应用中的安全性和可信度的迫切需求。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.08098v2",
      "published_date": "2024-12-11 04:52:41 UTC",
      "updated_date": "2025-02-14 05:21:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:22:10.662881"
    },
    {
      "arxiv_id": "2412.08090v2",
      "title": "Multilingual LLMs Inherently Reward In-Language Time-Sensitive Semantic Alignment for Low-Resource Languages",
      "title_zh": "多语言 LLMs 固有地奖励针对低资源语言的语言内时间敏感语义对齐",
      "authors": [
        "Ashutosh Bajpai",
        "Tanmoy Chakraborty"
      ],
      "abstract": "The unwavering disparity in labeled resources between resource-rich languages\nand those considered low-resource remains a significant impediment for Large\nLanguage Models (LLMs). Recent strides in cross-lingual in-context learning\n(X-ICL), mainly through semantically aligned examples retrieved from\nmultilingual pre-trained transformers, have shown promise in mitigating this\nissue. However, our investigation reveals that LLMs intrinsically reward\nin-language semantically aligned cross-lingual instances over direct\ncross-lingual semantic alignments, with a pronounced disparity in handling\ntime-sensitive queries in the X-ICL setup. Such queries demand sound temporal\nreasoning ability from LLMs, yet the advancements have predominantly focused on\nEnglish. This study aims to bridge this gap by improving temporal reasoning\ncapabilities in low-resource languages. To this end, we introduce mTEMPREASON,\na temporal reasoning dataset aimed at the varied degrees of low-resource\nlanguages and propose Cross-Lingual Time-Sensitive Semantic Alignment\n(CLiTSSA), a novel method to improve temporal reasoning in these contexts. To\nfacilitate this, we construct an extension of mTEMPREASON comprising pairs of\nparallel cross-language temporal queries along with their anticipated\nin-language semantic similarity scores. Our empirical evidence underscores the\nsuperior performance of CLiTSSA compared to established baselines across three\nlanguages -- Romanian, German, and French, encompassing three temporal tasks\nand including a diverse set of four contemporaneous LLMs. This marks a\nsignificant step forward in addressing resource disparity in the context of\ntemporal reasoning across languages.",
      "tldr_zh": "本文研究发现，多语言 Large Language Models (LLMs) 在处理低资源语言时，内在更倾向于奖励使用相同语言的语义对齐实例，尤其在时间敏感查询的跨语言 in-context learning (X-ICL) 中存在显著差距。论文引入了 mTEMPREASON 数据集——一个针对低资源语言的时间推理数据集，并提出 Cross-Lingual Time-Sensitive Semantic Alignment (CLiTSSA) 方法，通过构建平行跨语言查询及其语义相似性分数来提升这些语言的 temporal reasoning 能力。实验结果显示，CLiTSSA 在罗马尼亚语、德语和法语的三个时间任务上，优于现有基线模型，并验证了其在缓解资源不均衡方面的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.08090v2",
      "published_date": "2024-12-11 04:16:39 UTC",
      "updated_date": "2025-02-24 13:44:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:24:10.162955"
    },
    {
      "arxiv_id": "2412.10434v1",
      "title": "NAT-NL2GQL: A Novel Multi-Agent Framework for Translating Natural Language to Graph Query Language",
      "title_zh": "NAT-NL2GQL：一个新颖的多智能体框架，用于将自然语言翻译成图查询语言",
      "authors": [
        "Yuanyuan Liang",
        "Tingyu Xie",
        "Gan Peng",
        "Zihao Huang",
        "Yunshi Lan",
        "Weining Qian"
      ],
      "abstract": "The emergence of Large Language Models (LLMs) has revolutionized many fields,\nnot only traditional natural language processing (NLP) tasks. Recently,\nresearch on applying LLMs to the database field has been booming, and as a\ntypical non-relational database, the use of LLMs in graph database research has\nnaturally gained significant attention. Recent efforts have increasingly\nfocused on leveraging LLMs to translate natural language into graph query\nlanguage (NL2GQL). Although some progress has been made, these methods have\nclear limitations, such as their reliance on streamlined processes that often\noverlook the potential of LLMs to autonomously plan and collaborate with other\nLLMs in tackling complex NL2GQL challenges. To address this gap, we propose\nNAT-NL2GQL, a novel multi-agent framework for translating natural language to\ngraph query language. Specifically, our framework consists of three synergistic\nagents: the Preprocessor agent, the Generator agent, and the Refiner agent. The\nPreprocessor agent manages data processing as context, including tasks such as\nname entity recognition, query rewriting, path linking, and the extraction of\nquery-related schemas. The Generator agent is a fine-tuned LLM trained on\nNL-GQL data, responsible for generating corresponding GQL statements based on\nqueries and their related schemas. The Refiner agent is tasked with refining\nthe GQL or context using error information obtained from the GQL execution\nresults. Given the scarcity of high-quality open-source NL2GQL datasets based\non nGQL syntax, we developed StockGQL, a dataset constructed from a financial\nmarket graph database. It is available at:\nhttps://github.com/leonyuancode/StockGQL. Experimental results on the StockGQL\nand SpCQL datasets reveal that our method significantly outperforms baseline\napproaches, highlighting its potential for advancing NL2GQL research.",
      "tldr_zh": "该论文提出 NAT-NL2GQL，一种新型多智能体框架，用于将自然语言翻译成图查询语言 (NL2GQL)，以解决现有方法在 Large Language Models (LLMs) 自主规划和协作方面的局限性。框架由三个协同代理组成：Preprocessor agent 负责数据处理（如命名实体识别、查询重写和模式提取）、Generator agent（一个在 NL-GQL 数据上微调的 LLM）生成对应的 GQL 语句，以及 Refiner agent 使用执行错误信息优化输出。为了支持研究，他们构建了 StockGQL 数据集（基于 nGQL 语法）。实验结果显示，该框架在 StockGQL 和 SpCQL 数据集上显著优于基线方法，展示了其在 NL2GQL 研究中的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.CL",
      "comment": "12 pages,6 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.10434v1",
      "published_date": "2024-12-11 04:14:09 UTC",
      "updated_date": "2024-12-11 04:14:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:24:22.157749"
    },
    {
      "arxiv_id": "2412.08085v2",
      "title": "Non-Myopic Multi-Objective Bayesian Optimization",
      "title_zh": "非短视多目标贝叶斯优化",
      "authors": [
        "Syrine Belakaria",
        "Alaleh Ahmadianshalchi",
        "Barbara Engelhardt",
        "Stefano Ermon",
        "Janardhan Rao Doppa"
      ],
      "abstract": "We consider the problem of finite-horizon sequential experimental design to\nsolve multi-objective optimization (MOO) of expensive black-box objective\nfunctions. This problem arises in many real-world applications, including\nmaterials design, where we have a small resource budget to make and evaluate\ncandidate materials in the lab. We solve this problem using the framework of\nBayesian optimization (BO) and propose the first set of non-myopic methods for\nMOO problems. Prior work on non-myopic BO for single-objective problems relies\non the Bellman optimality principle to handle the lookahead reasoning process.\nHowever, this principle does not hold for most MOO problems because the reward\nfunction needs to satisfy some conditions: scalar variable, monotonicity, and\nadditivity. We address this challenge by using hypervolume improvement (HVI) as\nour scalarization approach, which allows us to use a lower-bound on the Bellman\nequation to approximate the finite-horizon using a batch expected hypervolume\nimprovement (EHVI) acquisition function (AF) for MOO. Our formulation naturally\nallows us to use other improvement-based scalarizations and compare their\nefficacy to HVI. We derive three non-myopic AFs for MOBO: 1) the Nested AF,\nwhich is based on the exact computation of the lower bound, 2) the Joint AF,\nwhich is a lower bound on the nested AF, and 3) the BINOM AF, which is a fast\nand approximate variant based on batch multi-objective acquisition functions.\nOur experiments on multiple diverse real-world MO problems demonstrate that our\nnon-myopic AFs substantially improve performance over the existing myopic AFs\nfor MOBO.",
      "tldr_zh": "本研究针对多目标优化（Multi-Objective Optimization, MOO）问题，提出了一种非短视（Non-Myopic）Bayesian Optimization (BO) 方法，用于有限资源预算下的实验设计，以优化昂贵的黑箱目标函数。论文通过使用 hypervolume improvement (HVI) 作为标量化策略，并基于对 Bellman 方程的下界近似，开发了 batch expected hypervolume improvement (EHVI) 采集函数（AF），以处理 MOO 的非短视推理挑战。作者提出了三种新采集函数：Nested AF（基于精确下界计算）、Joint AF（Nested AF 的下界）和 BINOM AF（快速近似变体）。实验结果显示，这些非短视方法在多个真实世界 MOO 问题上显著优于现有的短视 AFs，实现了性能的实质性提升。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Published in Transactions on Machine Learning Research (TMLR)",
      "pdf_url": "http://arxiv.org/pdf/2412.08085v2",
      "published_date": "2024-12-11 04:05:29 UTC",
      "updated_date": "2025-05-01 05:07:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:24:33.250715"
    },
    {
      "arxiv_id": "2412.08081v2",
      "title": "How to select slices for annotation to train best-performing deep learning segmentation models for cross-sectional medical images?",
      "title_zh": "如何选择切片进行标注，以训练表现最好的深度学习分割模型，用于横截面医学图像？",
      "authors": [
        "Yixin Zhang",
        "Kevin Kramer",
        "Maciej A. Mazurowski"
      ],
      "abstract": "Automated segmentation of medical images heavily relies on the availability\nof precise manual annotations. However, generating these annotations is often\ntime-consuming, expensive, and sometimes requires specialized expertise\n(especially for cross-sectional medical images). Therefore, it is essential to\noptimize the use of annotation resources to ensure efficiency and\neffectiveness. In this paper, we systematically address the question: \"in a\nnon-interactive annotation pipeline, how should slices from cross-sectional\nmedical images be selected for annotation to maximize the performance of the\nresulting deep learning segmentation models?\" We conducted experiments on 4\nmedical imaging segmentation tasks with varying annotation budgets, numbers of\nannotated cases, numbers of annotated slices per volume, slice selection\ntechniques, and mask interpolations. We found that:\n  1) It is almost always preferable to annotate fewer slices per volume and\nmore volumes given an annotation budget. 2) Selecting slices for annotation by\nunsupervised active learning (UAL) is not superior to selecting slices randomly\nor at fixed intervals, provided that each volume is allocated the same number\nof annotated slices. 3) Interpolating masks between annotated slices rarely\nenhances model performance, with exceptions of some specific configuration for\n3D models.",
      "tldr_zh": "这篇论文探讨了如何在非交互式标注管道中选择横截面医疗图像的切片，以最大化深度学习 segmentation models 的性能，同时优化标注资源的效率。研究通过在4个医疗图像分割任务上的实验，考察了不同标注预算、标注病例数、每卷标注切片数、切片选择技术和mask interpolations的影响。关键发现包括：给定标注预算，最好标注更多卷而非每个卷更多切片；unsupervised active learning (UAL)选择切片并不优于随机或固定间隔选择；mask interpolations 很少提升模型性能，仅在某些3D模型特定配置中有效。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "9 main pages, 21 total pages, MIDL 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.08081v2",
      "published_date": "2024-12-11 03:59:05 UTC",
      "updated_date": "2025-04-05 07:44:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:24:45.141840"
    },
    {
      "arxiv_id": "2412.08072v1",
      "title": "Using Large Language Models for Parametric Shape Optimization",
      "title_zh": "利用大型语言模型进行参数化形状优化",
      "authors": [
        "Xinxin Zhang",
        "Zhuoqun Xu",
        "Guangpu Zhu",
        "Chien Ming Jonathan Tay",
        "Yongdong Cui",
        "Boo Cheong Khoo",
        "Lailai Zhu"
      ],
      "abstract": "Recent advanced large language models (LLMs) have showcased their emergent\ncapability of in-context learning, facilitating intelligent decision-making\nthrough natural language prompts without retraining. This new machine learning\nparadigm has shown promise in various fields, including general control and\noptimization problems. Inspired by these advancements, we explore the potential\nof LLMs for a specific and essential engineering task: parametric shape\noptimization (PSO). We develop an optimization framework, LLM-PSO, that\nleverages an LLM to determine the optimal shape of parameterized engineering\ndesigns in the spirit of evolutionary strategies. Utilizing the ``Claude 3.5\nSonnet'' LLM, we evaluate LLM-PSO on two benchmark flow optimization problems,\nspecifically aiming to identify drag-minimizing profiles for 1) a\ntwo-dimensional airfoil in laminar flow, and 2) a three-dimensional\naxisymmetric body in Stokes flow. In both cases, LLM-PSO successfully\nidentifies optimal shapes in agreement with benchmark solutions. Besides, it\ngenerally converges faster than other classical optimization algorithms. Our\npreliminary exploration may inspire further investigations into harnessing LLMs\nfor shape optimization and engineering design more broadly.",
      "tldr_zh": "本研究探索了大型语言模型（LLMs）在参数形状优化（PSO）中的应用，利用LLMs的in-context学习能力，通过自然语言提示进行智能决策，而无需重新训练。研究开发了LLM-PSO框架，基于进化策略原理，使用Claude 3.5 Sonnet模型对两个基准流体优化问题进行测试，包括二维翼型在层流中的阻力最小化和三维轴对称体在Stokes流中的优化。结果显示，LLM-PSO成功识别出与基准解决方案一致的最优形状，且收敛速度比传统优化算法更快，为未来利用LLMs扩展工程设计和形状优化提供了新思路。",
      "categories": [
        "cs.CE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.08072v1",
      "published_date": "2024-12-11 03:35:38 UTC",
      "updated_date": "2024-12-11 03:35:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:24:57.694346"
    },
    {
      "arxiv_id": "2412.08069v1",
      "title": "DialogAgent: An Auto-engagement Agent for Code Question Answering Data Production",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaoyun Liang",
        "Jingyi Ren",
        "Jiayi Qi",
        "Chao Peng",
        "Bo Jiang"
      ],
      "abstract": "Large Language Models (LLMs) have become increasingly integral to enhancing\ndeveloper productivity, particularly in code generation, comprehension, and\nrepair tasks. However, fine-tuning these models with high-quality, real-world\ndata is challenging due to privacy concerns and the lack of accessible, labeled\ndatasets. In this paper, we present DialogAgent, an automated tool for\ngenerating synthetic training data that closely mimics real developer\ninteractions within Integrated Development Environments (IDEs). DialogAgent\nenables the production of diverse, high-fidelity query-response pairs by\nsimulating multi-turn dialogues and contextual behaviors observed in real-world\nprogramming scenarios. The tool significantly reduces the reliance on manual\ndata generation, increasing efficiency by 4.8 times compared to traditional\nmethods. Our experiments and online deployment demonstrate substantial\nimprovements in model performance for code-related question-answering tasks:\nthe acceptance rate of responses generated by our in-house model is improved by\n33%, after training on synthesized data generated by DialogAgent.",
      "tldr_zh": "该研究提出 DialogAgent，一种自动化代理，用于生成合成训练数据，以解决 Large Language Models (LLMs) 在代码生成、理解和修复任务中因隐私问题和数据缺乏而面临的挑战。DialogAgent 通过模拟多轮对话和真实 Integrated Development Environments (IDEs) 中的上下文行为，高效生产多样、高保真的查询-响应对，从而将数据生成效率提高 4.8 倍。实验结果显示，使用该工具生成的合成数据训练模型后，代码相关问答任务的响应接受率提升了 33%。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.08069v1",
      "published_date": "2024-12-11 03:31:36 UTC",
      "updated_date": "2024-12-11 03:31:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:25:09.306921"
    },
    {
      "arxiv_id": "2412.08068v1",
      "title": "Repository-Level Graph Representation Learning for Enhanced Security Patch Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Xin-Cheng Wen",
        "Zirui Lin",
        "Cuiyun Gao",
        "Hongyu Zhang",
        "Yong Wang",
        "Qing Liao"
      ],
      "abstract": "Software vendors often silently release security patches without providing\nsufficient advisories (e.g., Common Vulnerabilities and Exposures) or delayed\nupdates via resources (e.g., National Vulnerability Database). Therefore, it\nhas become crucial to detect these security patches to ensure secure software\nmaintenance. However, existing methods face the following challenges: (1) They\nprimarily focus on the information within the patches themselves, overlooking\nthe complex dependencies in the repository. (2) Security patches typically\ninvolve multiple functions and files, increasing the difficulty in well\nlearning the representations. To alleviate the above challenges, this paper\nproposes a Repository-level Security Patch Detection framework named RepoSPD,\nwhich comprises three key components: 1) a repository-level graph construction,\nRepoCPG, which represents software patches by merging pre-patch and post-patch\nsource code at the repository level; 2) a structure-aware patch representation,\nwhich fuses the graph and sequence branch and aims at comprehending the\nrelationship among multiple code changes; 3) progressive learning, which\nfacilitates the model in balancing semantic and structural information. To\nevaluate RepoSPD, we employ two widely-used datasets in security patch\ndetection: SPI-DB and PatchDB. We further extend these datasets to the\nrepository level, incorporating a total of 20,238 and 28,781 versions of\nrepository in C/C++ programming languages, respectively, denoted as SPI-DB* and\nPatchDB*. We compare RepoSPD with six existing security patch detection methods\nand five static tools. Our experimental results demonstrate that RepoSPD\noutperforms the state-of-the-art baseline, with improvements of 11.90%, and\n3.10% in terms of accuracy on the two datasets, respectively.",
      "tldr_zh": "该论文针对软件供应商在发布安全补丁时缺乏足够通知的问题，提出了一种仓库级别的安全补丁检测框架RepoSPD，以解决现有方法忽略仓库依赖和多函数文件复杂性的挑战。RepoSPD包括三个关键组件：仓库级图构建(RepoCPG)用于合并补丁前后源代码、结构感知补丁表示融合图和序列信息以理解代码变化关系，以及渐进式学习平衡语义和结构信息。实验在扩展后的数据集SPI-DB*和PatchDB*上进行，结果显示RepoSPD比最先进基线方法在准确率上分别提高了11.90%和3.10%。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.SE",
      "comment": "13 pages. This paper is accepted by ICSE 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.08068v1",
      "published_date": "2024-12-11 03:29:56 UTC",
      "updated_date": "2024-12-11 03:29:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:25:20.588315"
    },
    {
      "arxiv_id": "2412.10432v2",
      "title": "Imitate Before Detect: Aligning Machine Stylistic Preference for Machine-Revised Text Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Jiaqi Chen",
        "Xiaoye Zhu",
        "Tianyang Liu",
        "Ying Chen",
        "Xinhui Chen",
        "Yiwen Yuan",
        "Chak Tou Leong",
        "Zuchao Li",
        "Tang Long",
        "Lei Zhang",
        "Chenyu Yan",
        "Guanghao Mei",
        "Jie Zhang",
        "Lefei Zhang"
      ],
      "abstract": "Large Language Models (LLMs) have revolutionized text generation, making\ndetecting machine-generated text increasingly challenging. Although past\nmethods have achieved good performance on detecting pure machine-generated\ntext, those detectors have poor performance on distinguishing machine-revised\ntext (rewriting, expansion, and polishing), which can have only minor changes\nfrom its original human prompt. As the content of text may originate from human\nprompts, detecting machine-revised text often involves identifying distinctive\nmachine styles, e.g., worded favored by LLMs. However, existing methods\nstruggle to detect machine-style phrasing hidden within the content contributed\nby humans. We propose the \"Imitate Before Detect\" (ImBD) approach, which first\nimitates the machine-style token distribution, and then compares the\ndistribution of the text to be tested with the machine-style distribution to\ndetermine whether the text has been machine-revised. To this end, we introduce\nstyle preference optimization (SPO), which aligns a scoring LLM model to the\npreference of text styles generated by machines. The aligned scoring model is\nthen used to calculate the style-conditional probability curvature (Style-CPC),\nquantifying the log probability difference between the original and\nconditionally sampled texts for effective detection. We conduct extensive\ncomparisons across various scenarios, encompassing text revisions by six LLMs,\nfour distinct text domains, and three machine revision types. Compared to\nexisting state-of-the-art methods, our method yields a 13% increase in AUC for\ndetecting text revised by open-source LLMs, and improves performance by 5% and\n19% for detecting GPT-3.5 and GPT-4o revised text, respectively. Notably, our\nmethod surpasses the commercially trained GPT-Zero with just $1,000$ samples\nand five minutes of SPO, demonstrating its efficiency and effectiveness.",
      "tldr_zh": "这篇论文针对检测机器修改文本（machine-revised text，如 rewriting、expansion 和 polishing）的挑战，提出了“Imitate Before Detect (ImBD)”方法，以更好地识别隐藏在人类内容中的机器风格。ImBD 通过 style preference optimization (SPO) 调整评分模型来模仿机器的 token 分布，并使用 style-conditional probability curvature (Style-CPC) 计算原文本与条件采样文本的概率差异，从而实现精确检测。实验结果显示，该方法在多种场景下提升了性能，与现有方法相比，AUC 提高了 13% 对于开源 LLMs，5% 对于 GPT-3.5 和 19% 对于 GPT-4o，仅需 1,000 个样本和五分钟的 SPO 训练就超过了商业模型如 GPT-Zero。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.CL",
      "comment": "To appear at AAAI 2025. 14 pages, 6 figure",
      "pdf_url": "http://arxiv.org/pdf/2412.10432v2",
      "published_date": "2024-12-11 03:17:14 UTC",
      "updated_date": "2024-12-22 15:47:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:25:34.470958"
    },
    {
      "arxiv_id": "2412.08063v1",
      "title": "ContextModule: Improving Code Completion via Repository-level Contextual Information",
      "title_zh": "ContextModule：通过仓库级上下文信息改进代码补全",
      "authors": [
        "Zhanming Guan",
        "Junlin Liu",
        "Jierui Liu",
        "Chao Peng",
        "Dexin Liu",
        "Ningyuan Sun",
        "Bo Jiang",
        "Wenchao Li",
        "Jie Liu",
        "Hang Zhu"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated impressive capabilities in\ncode completion tasks, where they assist developers by predicting and\ngenerating new code in real-time. However, existing LLM-based code completion\nsystems primarily rely on the immediate context of the file being edited, often\nmissing valuable repository-level information, user behaviour and edit history\nthat could improve suggestion accuracy. Additionally, challenges such as\nefficiently retrieving relevant code snippets from large repositories,\nincorporating user behavior, and balancing accuracy with low-latency\nrequirements in production environments remain unresolved. In this paper, we\npropose ContextModule, a framework designed to enhance LLM-based code\ncompletion by retrieving and integrating three types of contextual information\nfrom the repository: user behavior-based code, similar code snippets, and\ncritical symbol definitions. By capturing user interactions across files and\nleveraging repository-wide static analysis, ContextModule improves the\nrelevance and precision of generated code. We implement performance\noptimizations, such as index caching, to ensure the system meets the latency\nconstraints of real-world coding environments. Experimental results and\nindustrial practise demonstrate that ContextModule significantly improves code\ncompletion accuracy and user acceptance rates.",
      "tldr_zh": "现有LLM-based代码补全系统主要依赖当前文件上下文，忽略了仓库级信息、用户行为和编辑历史，导致建议准确性不足。论文提出ContextModule框架，通过检索和整合三种仓库级上下文信息——用户行为-based代码、类似代码片段以及关键符号定义——来提升LLMs的代码生成相关性和精确性。该框架还通过索引缓存等性能优化，确保在低延迟的实际环境中运行顺畅，实验结果和工业实践显示其显著提高了代码补全准确性和用户接受率。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.08063v1",
      "published_date": "2024-12-11 03:15:49 UTC",
      "updated_date": "2024-12-11 03:15:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:27:44.912032"
    },
    {
      "arxiv_id": "2412.08061v1",
      "title": "Go-Oracle: Automated Test Oracle for Go Concurrency Bugs",
      "title_zh": "翻译失败",
      "authors": [
        "Foivos Tsimpourlas",
        "Chao Peng",
        "Carlos Rosuero",
        "Ping Yang",
        "Ajitha Rajan"
      ],
      "abstract": "The Go programming language has gained significant traction for developing\nsoftware, especially in various infrastructure systems. Nonetheless,\nconcurrency bugs have become a prevalent issue within Go, presenting a unique\nchallenge due to the language's dual concurrency mechanisms-communicating\nsequential processes and shared memory. Detecting concurrency bugs and\naccurately classifying program executions as pass or fail presents an immense\nchallenge, even for domain experts. We conducted a survey with expert\ndevelopers at Bytedance that confirmed this challenge. Our work seeks to\naddress the test oracle problem for Go programs, to automatically classify test\nexecutions as pass or fail. This problem has not been investigated in the\nliterature for Go programs owing to its distinctive programming model.\n  Our approach involves collecting both passing and failing execution traces\nfrom various subject Go programs. We capture a comprehensive array of execution\nevents using the native Go execution tracer. Subsequently, we preprocess and\nencode these traces before training a transformer-based neural network to\neffectively classify the traces as either passing or failing. The evaluation of\nour approach encompasses 8 subject programs sourced from the GoBench\nrepository. These subject programs are routinely used as benchmarks in an\nindustry setting. Encouragingly, our test oracle, Go-Oracle, demonstrates high\naccuracies even when operating with a limited dataset, showcasing the efficacy\nand potential of our methodology. Developers at Bytedance strongly agreed that\nthey would use the Go-Oracle tool over the current practice of manual\ninspections to classify tests for Go programs as pass or fail.",
      "tldr_zh": "这篇论文介绍了 Go-Oracle，一种自动化测试预言机（test oracle），旨在检测和分类 Go 语言中并发 bugs（concurrency bugs），解决其独特并发机制（communicating sequential processes 和 shared memory）带来的挑战。研究方法包括收集 passing 和 failing 执行 traces，使用 Go 的原生执行 tracer 捕获事件，然后预处理、编码这些 traces 并训练一个 transformer-based neural network 来自动分类测试执行。实验在 8 个 GoBench 仓库的主题程序上进行，结果显示 Go-Oracle 即使在数据有限的情况下也取得了高准确率，并获得 Bytedance 开发者们的认可，认为它优于手动检查。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.08061v1",
      "published_date": "2024-12-11 03:07:56 UTC",
      "updated_date": "2024-12-11 03:07:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:25:57.447071"
    },
    {
      "arxiv_id": "2412.08054v1",
      "title": "Federated In-Context LLM Agent Learning",
      "title_zh": "联邦式上下文内 LLM 代理学习",
      "authors": [
        "Panlong Wu",
        "Kangshuo Li",
        "Junbao Nan",
        "Fangxin Wang"
      ],
      "abstract": "Large Language Models (LLMs) have revolutionized intelligent services by\nenabling logical reasoning, tool use, and interaction with external systems as\nagents. The advancement of LLMs is frequently hindered by the scarcity of\nhigh-quality data, much of which is inherently sensitive. Federated learning\n(FL) offers a potential solution by facilitating the collaborative training of\ndistributed LLMs while safeguarding private data. However, FL frameworks face\nsignificant bandwidth and computational demands, along with challenges from\nheterogeneous data distributions. The emerging in-context learning capability\nof LLMs offers a promising approach by aggregating natural language rather than\nbulky model parameters. Yet, this method risks privacy leakage, as it\nnecessitates the collection and presentation of data samples from various\nclients during aggregation. In this paper, we propose a novel\nprivacy-preserving Federated In-Context LLM Agent Learning (FICAL) algorithm,\nwhich to our best knowledge for the first work unleashes the power of\nin-context learning to train diverse LLM agents through FL. In our design,\nknowledge compendiums generated by a novel LLM-enhanced Knowledge Compendiums\nGeneration (KCG) module are transmitted between clients and the server instead\nof model parameters in previous FL methods. Apart from that, an incredible\nRetrieval Augmented Generation (RAG) based Tool Learning and Utilizing (TLU)\nmodule is designed and we incorporate the aggregated global knowledge\ncompendium as a teacher to teach LLM agents the usage of tools. We conducted\nextensive experiments and the results show that FICAL has competitive\nperformance compared to other SOTA baselines with a significant communication\ncost decrease of $\\mathbf{3.33\\times10^5}$ times.",
      "tldr_zh": "这篇论文提出了一种新型的 Federated In-Context LLM Agent Learning (FICAL) 算法，这是首个将 In-Context Learning 应用于联邦学习 (FL) 的方法，用于在保护隐私的前提下训练分布式 LLM 代理。FICAL 通过 LLM-enhanced Knowledge Compendiums Generation (KCG) 模块生成知识摘要来替代传统模型参数传输，并引入 Retrieval Augmented Generation (RAG) based Tool Learning and Utilizing (TLU) 模块，利用聚合的全局知识作为教师指导 LLM 代理工具的使用。实验结果显示，FICAL 与现有最先进基线相比性能具有竞争力，同时将通信成本降低了 3.33×10^5 倍，显著缓解了 FL 的带宽和计算挑战。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.08054v1",
      "published_date": "2024-12-11 03:00:24 UTC",
      "updated_date": "2024-12-11 03:00:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:27:56.937170"
    },
    {
      "arxiv_id": "2412.08053v2",
      "title": "DynamicPAE: Generating Scene-Aware Physical Adversarial Examples in Real-Time",
      "title_zh": "DynamicPAE：实时生成场景感知的物理对抗样本",
      "authors": [
        "Jin Hu",
        "Xianglong Liu",
        "Jiakai Wang",
        "Junkai Zhang",
        "Xianqi Yang",
        "Haotong Qin",
        "Yuqing Ma",
        "Ke Xu"
      ],
      "abstract": "Physical adversarial examples (PAEs) are regarded as \"whistle-blowers\" of\nreal-world risks in deep-learning applications. However, current PAE generation\nstudies show limited adaptive attacking ability to diverse and varying scenes.\nThe key challenges in generating dynamic PAEs are exploring their patterns\nunder noisy gradient feedback and adapting the attack to agnostic scenario\nnatures. To address the problems, we present DynamicPAE, the first generative\nframework that enables scene-aware real-time physical attacks beyond static\nattacks. Specifically, to train the dynamic PAE generator under noisy gradient\nfeedback, we introduce the residual-driven sample trajectory guidance\ntechnique, which redefines the training task to break the limited feedback\ninformation restriction that leads to the degeneracy problem. Intuitively, it\nallows the gradient feedback to be passed to the generator through a low-noise\nauxiliary task, thereby guiding the optimization away from degenerate solutions\nand facilitating a more comprehensive and stable exploration of feasible PAEs.\nTo adapt the generator to agnostic scenario natures, we introduce the\ncontext-aligned scene expectation simulation process, consisting of the\nconditional-uncertainty-aligned data module and the skewness-aligned objective\nre-weighting module. The former enhances robustness in the context of\nincomplete observation by employing a conditional probabilistic model for\ndomain randomization, while the latter facilitates consistent stealth control\nacross different attack targets by automatically reweighting losses based on\nthe skewness indicator. Extensive digital and physical evaluations demonstrate\nthe superior attack performance of DynamicPAE, attaining a 1.95 $\\times$ boost\n(65.55% average AP drop under attack) on representative object detectors (e.g.,\nYolo-v8) over state-of-the-art static PAE generating methods.",
      "tldr_zh": "该研究提出DynamicPAE框架，这是首个支持场景感知实时物理对抗样本（PAEs）生成的系统，旨在解决现有方法在多样化场景下的适应性不足问题。框架通过residual-driven sample trajectory guidance技术处理噪声梯度反馈，避免训练退化，并引入context-aligned scene expectation simulation过程，包括conditional-uncertainty-aligned data module和skewness-aligned objective re-weighting module，以适应未知场景并增强鲁棒性。实验结果显示，DynamicPAE在物体检测器如Yolo-v8上比最先进静态方法提升1.95倍，平均AP下降65.55%，证明了其在数字和物理评估中的优越攻击性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "This work has been submitted to the IEEE for possible publication",
      "pdf_url": "http://arxiv.org/pdf/2412.08053v2",
      "published_date": "2024-12-11 03:00:15 UTC",
      "updated_date": "2024-12-23 02:53:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:28:07.887299"
    },
    {
      "arxiv_id": "2412.12149v2",
      "title": "MHSA: A Multi-scale Hypergraph Network for Mild Cognitive Impairment Detection via Synchronous and Attentive Fusion",
      "title_zh": "翻译失败",
      "authors": [
        "Manman Yuan",
        "Weiming Jia",
        "Xiong Luo",
        "Jiazhen Ye",
        "Peican Zhu",
        "Junlin Li"
      ],
      "abstract": "The precise detection of mild cognitive impairment (MCI) is of significant\nimportance in preventing the deterioration of patients in a timely manner.\nAlthough hypergraphs have enhanced performance by learning and analyzing brain\nnetworks, they often only depend on vector distances between features at a\nsingle scale to infer interactions. In this paper, we deal with a more arduous\nchallenge, hypergraph modelling with synchronization between brain regions, and\ndesign a novel framework, i.e., A Multi-scale Hypergraph Network for MCI\nDetection via Synchronous and Attentive Fusion (MHSA), to tackle this\nchallenge. Specifically, our approach employs the Phase-Locking Value (PLV) to\ncalculate the phase synchronization relationship in the spectrum domain of\nregions of interest (ROIs) and designs a multi-scale feature fusion mechanism\nto integrate dynamic connectivity features of functional magnetic resonance\nimaging (fMRI) from both the temporal and spectrum domains. To evaluate and\noptimize the direct contribution of each ROI to phase synchronization in the\ntemporal domain, we structure the PLV coefficients dynamically adjust strategy,\nand the dynamic hypergraph is modelled based on a comprehensive\ntemporal-spectrum fusion matrix. Experiments on the real-world dataset indicate\nthe effectiveness of our strategy. The code is available at\nhttps://github.com/Jia-Weiming/MHSA.",
      "tldr_zh": "该研究提出 MHSA 框架，一种多尺度超图网络，用于精确检测 Mild Cognitive Impairment (MCI)，以及时预防患者病情恶化。\nMHSA 通过 Phase-Locking Value (PLV) 计算感兴趣区域 (ROIs) 在频谱域的相位同步关系，并设计多尺度特征融合机制整合 fMRI 的时域和频谱动态连接特征。\n此外，该框架动态调整 PLV 系数并基于时谱融合矩阵构建动态超图，优化脑区互动建模。\n实验结果表明，该方法在真实数据集上表现出色，有效提升了 MCI 检测性能，相关代码已在 GitHub 上开源。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "The submission was made prematurely and will be resubmitted after\n  further development",
      "pdf_url": "http://arxiv.org/pdf/2412.12149v2",
      "published_date": "2024-12-11 02:59:57 UTC",
      "updated_date": "2025-01-12 02:48:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:28:20.314453"
    },
    {
      "arxiv_id": "2412.08029v1",
      "title": "NeRF-NQA: No-Reference Quality Assessment for Scenes Generated by NeRF and Neural View Synthesis Methods",
      "title_zh": "NeRF-NQA：NeRF 及神经视图合成方法生成",
      "authors": [
        "Qiang Qu",
        "Hanxue Liang",
        "Xiaoming Chen",
        "Yuk Ying Chung",
        "Yiran Shen"
      ],
      "abstract": "Neural View Synthesis (NVS) has demonstrated efficacy in generating\nhigh-fidelity dense viewpoint videos using a image set with sparse views.\nHowever, existing quality assessment methods like PSNR, SSIM, and LPIPS are not\ntailored for the scenes with dense viewpoints synthesized by NVS and NeRF\nvariants, thus, they often fall short in capturing the perceptual quality,\nincluding spatial and angular aspects of NVS-synthesized scenes. Furthermore,\nthe lack of dense ground truth views makes the full reference quality\nassessment on NVS-synthesized scenes challenging. For instance, datasets such\nas LLFF provide only sparse images, insufficient for complete full-reference\nassessments. To address the issues above, we propose NeRF-NQA, the first\nno-reference quality assessment method for densely-observed scenes synthesized\nfrom the NVS and NeRF variants. NeRF-NQA employs a joint quality assessment\nstrategy, integrating both viewwise and pointwise approaches, to evaluate the\nquality of NVS-generated scenes. The viewwise approach assesses the spatial\nquality of each individual synthesized view and the overall inter-views\nconsistency, while the pointwise approach focuses on the angular qualities of\nscene surface points and their compound inter-point quality. Extensive\nevaluations are conducted to compare NeRF-NQA with 23 mainstream visual quality\nassessment methods (from fields of image, video, and light-field assessment).\nThe results demonstrate NeRF-NQA outperforms the existing assessment methods\nsignificantly and it shows substantial superiority on assessing NVS-synthesized\nscenes without references. An implementation of this paper are available at\nhttps://github.com/VincentQQu/NeRF-NQA.",
      "tldr_zh": "该研究针对Neural View Synthesis (NVS) 和 NeRF 生成的密集视点场景，提出NeRF-NQA，这是一种无参考（No-Reference）质量评估方法，以解决现有方法如PSNR、SSIM 和 LPIPS 在捕捉空间和角度感知质量方面的不足。NeRF-NQA 采用联合评估策略，包括viewwise 方法（评估单个视图的空间质量和视图间一致性）和pointwise 方法（评估场景表面点的角度质量及点间复合质量）。实验结果显示，NeRF-NQA 在与23种主流视觉质量评估方法比较中表现出显著优势，尤其适用于无参考评估NVS合成场景，提供了一个高效的评估框架。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.HC",
        "cs.MM",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.08029v1",
      "published_date": "2024-12-11 02:17:33 UTC",
      "updated_date": "2024-12-11 02:17:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:28:32.221013"
    },
    {
      "arxiv_id": "2412.08021v2",
      "title": "Can a MISL Fly? Analysis and Ingredients for Mutual Information Skill Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Chongyi Zheng",
        "Jens Tuyls",
        "Joanne Peng",
        "Benjamin Eysenbach"
      ],
      "abstract": "Self-supervised learning has the potential of lifting several of the key\nchallenges in reinforcement learning today, such as exploration, representation\nlearning, and reward design. Recent work (METRA) has effectively argued that\nmoving away from mutual information and instead optimizing a certain\nWasserstein distance is important for good performance. In this paper, we argue\nthat the benefits seen in that paper can largely be explained within the\nexisting framework of mutual information skill learning (MISL). Our analysis\nsuggests a new MISL method (contrastive successor features) that retains the\nexcellent performance of METRA with fewer moving parts, and highlights\nconnections between skill learning, contrastive representation learning, and\nsuccessor features. Finally, through careful ablation studies, we provide\nfurther insight into some of the key ingredients for both our method and METRA.",
      "tldr_zh": "本论文分析了在强化学习中，互信息技能学习（MISL）框架如何解释 METRA 方法的性能优势，METRA 强调优化 Wasserstein 距离而非互信息。作者提出了一种新的 MISL 方法——对比性后继特征（contrastive successor features），它保留了 METRA 的出色性能，同时简化了组件，并揭示了技能学习、对比性表示学习和后继特征之间的联系。通过仔细的消融研究，论文提供了对关键成分的深入洞见，从而提升了自监督学习在探索、表示学习和奖励设计方面的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Code and videos are available on the website:\n  https://princeton-rl.github.io/contrastive-successor-features/",
      "pdf_url": "http://arxiv.org/pdf/2412.08021v2",
      "published_date": "2024-12-11 02:00:39 UTC",
      "updated_date": "2025-03-20 01:53:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:28:44.759809"
    },
    {
      "arxiv_id": "2412.08020v1",
      "title": "Intelligent Control of Robotic X-ray Devices using a Language-promptable Digital Twin",
      "title_zh": "翻译失败",
      "authors": [
        "Benjamin D. Killeen",
        "Anushri Suresh",
        "Catalina Gomez",
        "Blanca Inigo",
        "Christopher Bailey",
        "Mathias Unberath"
      ],
      "abstract": "Natural language offers a convenient, flexible interface for controlling\nrobotic C-arm X-ray systems, making advanced functionality and controls\naccessible. However, enabling language interfaces requires specialized AI\nmodels that interpret X-ray images to create a semantic representation for\nreasoning. The fixed outputs of such AI models limit the functionality of\nlanguage controls. Incorporating flexible, language-aligned AI models prompted\nthrough language enables more versatile interfaces for diverse tasks and\nprocedures. Using a language-aligned foundation model for X-ray image\nsegmentation, our system continually updates a patient digital twin based on\nsparse reconstructions of desired anatomical structures. This supports\nautonomous capabilities such as visualization, patient-specific viewfinding,\nand automatic collimation from novel viewpoints, enabling commands 'Focus in on\nthe lower lumbar vertebrae.' In a cadaver study, users visualized, localized,\nand collimated structures across the torso using verbal commands, achieving 84%\nend-to-end success. Post hoc analysis of randomly oriented images showed our\npatient digital twin could localize 35 commonly requested structures to within\n51.68 mm, enabling localization and isolation from arbitrary orientations. Our\nresults demonstrate how intelligent robotic X-ray systems can incorporate\nphysicians' expressed intent directly. While existing foundation models for\nintra-operative X-ray analysis exhibit failure modes, as they improve, they can\nfacilitate highly flexible, intelligent robotic C-arms.",
      "tldr_zh": "该论文提出了一种智能控制机器人X-ray设备的方法，利用语言可提示的数字孪生体（digital twin）来处理自然语言命令，实现更灵活的系统操作。系统通过语言对齐的AI模型（language-aligned foundation model）进行X-ray图像分割，并持续更新患者数字孪生体，支持自主功能如可视化、患者特定视图查找和自动准直（automatic collimation）。在尸体研究中，该系统实现了84%的端到端成功率，并能将35种常见结构定位在51.68 mm以内，展示了如何直接整合医生的意图并提升机器人C-arm X-ray systems的智能性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.08020v1",
      "published_date": "2024-12-11 02:00:25 UTC",
      "updated_date": "2024-12-11 02:00:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:28:57.190187"
    },
    {
      "arxiv_id": "2412.08014v2",
      "title": "MAGIC: Mastering Physical Adversarial Generation in Context through Collaborative LLM Agents",
      "title_zh": "MAGIC：在上下文中通过协作LLM代理掌握物理对抗生成",
      "authors": [
        "Yun Xing",
        "Nhat Chung",
        "Jie Zhang",
        "Yue Cao",
        "Ivor Tsang",
        "Yang Liu",
        "Lei Ma",
        "Qing Guo"
      ],
      "abstract": "Physical adversarial attacks in driving scenarios can expose critical\nvulnerabilities in visual perception models. However, developing such attacks\nremains challenging due to diverse real-world environments and the requirement\nfor maintaining visual naturality. Building upon this challenge, we reformulate\nphysical adversarial attacks as a one-shot patch generation problem. Our\napproach generates adversarial patches through a deep generative model that\nconsiders the specific scene context, enabling direct physical deployment in\nmatching environments. The primary challenge lies in simultaneously achieving\ntwo objectives: generating adversarial patches that effectively mislead object\ndetection systems while determining contextually appropriate deployment within\nthe scene. We propose MAGIC (Mastering Physical Adversarial Generation In\nContext), a novel framework powered by multi-modal LLM agents to address these\nchallenges. MAGIC automatically understands scene context and generates\nadversarial patch through the synergistic interaction of language and vision\ncapabilities. In particular, MAGIC orchestrates three specialized LLM agents:\nThe adv-patch generation agent (GAgent) masters the creation of deceptive\npatches through strategic prompt engineering for text-to-image models. The\nadv-patch deployment agent (DAgent) ensures contextual coherence by determining\noptimal deployment strategies based on scene understanding. The\nself-examination agent (EAgent) completes this trilogy by providing critical\noversight and iterative refinement of both processes. We validate our method on\nboth digital and physical levels, i.e., nuImage and manually captured\nreal-world scenes, where both statistical and visual results prove that our\nMAGIC is powerful and effective for attacking widely applied object detection\nsystems, i.e., YOLO and DETR series.",
      "tldr_zh": "本文提出 MAGIC 框架，利用协作的多模态 LLM 代理来解决物理对抗攻击在驾驶场景中的挑战，该框架通过深度生成模型生成上下文相关的单次对抗补丁，同时确保视觉自然性和部署策略优化。MAGIC 包括三个专门代理：GAgent 负责通过提示工程生成欺骗性补丁、DAgent 基于场景理解确定最佳部署位置，以及 EAgent 提供自我检查和迭代改进。实验在 nuImage 和真实世界场景中验证，证明 MAGIC 对 YOLO 和 DETR 等物体检测系统有效，提高了攻击成功率。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.08014v2",
      "published_date": "2024-12-11 01:41:19 UTC",
      "updated_date": "2025-03-11 07:15:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:29:08.762801"
    },
    {
      "arxiv_id": "2412.10429v1",
      "title": "GPTDrawer: Enhancing Visual Synthesis through ChatGPT",
      "title_zh": "GPTDrawer：通过 ChatGPT 增强视觉合成",
      "authors": [
        "Kun Li",
        "Xinwei Chen",
        "Tianyou Song",
        "Hansong Zhang",
        "Wenzhe Zhang",
        "Qing Shan"
      ],
      "abstract": "In the burgeoning field of AI-driven image generation, the quest for\nprecision and relevance in response to textual prompts remains paramount. This\npaper introduces GPTDrawer, an innovative pipeline that leverages the\ngenerative prowess of GPT-based models to enhance the visual synthesis process.\nOur methodology employs a novel algorithm that iteratively refines input\nprompts using keyword extraction, semantic analysis, and image-text congruence\nevaluation. By integrating ChatGPT for natural language processing and Stable\nDiffusion for image generation, GPTDrawer produces a batch of images that\nundergo successive refinement cycles, guided by cosine similarity metrics until\na threshold of semantic alignment is attained. The results demonstrate a marked\nimprovement in the fidelity of images generated in accordance with user-defined\nprompts, showcasing the system's ability to interpret and visualize complex\nsemantic constructs. The implications of this work extend to various\napplications, from creative arts to design automation, setting a new benchmark\nfor AI-assisted creative processes.",
      "tldr_zh": "本文提出GPTDrawer，一种创新管道，利用ChatGPT增强AI驱动的图像生成过程，以提高文本提示的精确性和相关性。该方法采用一个新算法，通过关键词提取、语义分析和图像-文本一致性评估来迭代优化输入提示，并结合Stable Diffusion生成图像批次，随后使用余弦相似度指标进行连续精炼，直至达到语义对齐阈值。实验结果显示，GPTDrawer显著提升了图像生成的保真度，使其能够更好地解释和可视化复杂语义结构，并为创意艺术、设计自动化等领域设定新的AI辅助基准。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.10429v1",
      "published_date": "2024-12-11 00:42:44 UTC",
      "updated_date": "2024-12-11 00:42:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:29:19.744171"
    },
    {
      "arxiv_id": "2412.19814v1",
      "title": "Predicting Human Brain States with Transformer",
      "title_zh": "使用 Transformer 预测人类大脑状态",
      "authors": [
        "Yifei Sun",
        "Mariano Cabezas",
        "Jiah Lee",
        "Chenyu Wang",
        "Wei Zhang",
        "Fernando Calamante",
        "Jinglei Lv"
      ],
      "abstract": "The human brain is a complex and highly dynamic system, and our current\nknowledge of its functional mechanism is still very limited. Fortunately, with\nfunctional magnetic resonance imaging (fMRI), we can observe blood oxygen\nlevel-dependent (BOLD) changes, reflecting neural activity, to infer brain\nstates and dynamics. In this paper, we ask the question of whether the brain\nstates rep-resented by the regional brain fMRI can be predicted. Due to the\nsuccess of self-attention and the transformer architecture in sequential\nauto-regression problems (e.g., language modelling or music generation), we\nexplore the possi-bility of the use of transformers to predict human brain\nresting states based on the large-scale high-quality fMRI data from the human\nconnectome project (HCP). Current results have shown that our model can\naccurately predict the brain states up to 5.04s with the previous 21.6s.\nFurthermore, even though the prediction error accumulates for the prediction of\na longer time period, the gen-erated fMRI brain states reflect the architecture\nof functional connectome. These promising initial results demonstrate the\npossibility of developing gen-erative models for fMRI data using self-attention\nthat learns the functional or-ganization of the human brain. Our code is\navailable at: https://github.com/syf0122/brain_state_pred.",
      "tldr_zh": "本研究探讨了使用Transformer模型预测人类脑状态的问题，基于fMRI（functional magnetic resonance imaging）数据观察BOLD（blood oxygen level-dependent）变化来推断大脑动态。研究利用HCP（Human Connectome Project）的大规模高品质fMRI数据，开发了一个Transformer架构模型，能够准确预测未来5.04秒的脑状态，依赖于之前的21.6秒数据。结果显示，即使预测时间延长，生成的fMRI脑状态仍能反映功能连接组的结构，这为开发基于自注意力机制的学习大脑功能组织的生成模型提供了可能性。",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.NC",
      "comment": "11 pages, 4 figures, MICCAI MMMI workshop in press",
      "pdf_url": "http://arxiv.org/pdf/2412.19814v1",
      "published_date": "2024-12-11 00:18:39 UTC",
      "updated_date": "2024-12-11 00:18:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:29:31.311932"
    },
    {
      "arxiv_id": "2412.07990v1",
      "title": "Adaptive Querying for Reward Learning from Human Feedback",
      "title_zh": "翻译失败",
      "authors": [
        "Yashwanthi Anand",
        "Sandhya Saisubramanian"
      ],
      "abstract": "Learning from human feedback is a popular approach to train robots to adapt\nto user preferences and improve safety. Existing approaches typically consider\na single querying (interaction) format when seeking human feedback and do not\nleverage multiple modes of user interaction with a robot. We examine how to\nlearn a penalty function associated with unsafe behaviors, such as side\neffects, using multiple forms of human feedback, by optimizing the query state\nand feedback format. Our framework for adaptive feedback selection enables\nquerying for feedback in critical states in the most informative format, while\naccounting for the cost and probability of receiving feedback in a certain\nformat. We employ an iterative, two-phase approach which first selects critical\nstates for querying, and then uses information gain to select a feedback format\nfor querying across the sampled critical states. Our evaluation in simulation\ndemonstrates the sample efficiency of our approach.",
      "tldr_zh": "本论文提出了一种自适应查询框架，用于从人类反馈(Human Feedback)中学习奖励函数，帮助机器人适应用户偏好并提升安全性，特别是针对不安全行为的惩罚函数。该框架通过优化查询状态和反馈格式，结合多种互动模式（如不同反馈形式），采用迭代的两阶段方法：首先选择关键状态进行查询，然后基于信息增益(Information Gain)选择最有效的反馈格式。实验结果在模拟环境中证明了该方法的样本效率(Sample Efficiency)，展示了其在减少反馈需求的同时提升学习效果。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.07990v1",
      "published_date": "2024-12-11 00:02:48 UTC",
      "updated_date": "2024-12-11 00:02:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T11:29:43.538858"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 130,
  "processed_papers_count": 130,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-21T11:30:03.001142"
}