{
  "date": "2024-01-01",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-01-01 的 arXiv 中文 TLDR 快报！今天的 arXiv 更新聚焦于人工智能生成模型和大型语言模型 (LLMs) 的应用，涵盖金融数据分析、图像处理和医疗诊断等领域，其中 LLMs 在金融领域的基准测试和图像偏见评估最为引人注目，同时有著名学者如 Leonidas J. Guibas 参与的论文，强调了模型的鲁棒性和实际应用潜力。\n\n### LLMs 和 AI 生成模型：焦点话题\n这些论文探讨了 LLMs 在金融、教育和一般任务中的优化与评估，突显了模型的潜力与挑战。\n- **论文 9: Astraios: Parameter-Efficient Instruction Tuning Code Large Language Models（Astraios: 参数高效指令微调代码大型语言模型）**  \n  该研究比较了多种参数高效微调 (PEFT) 方法，发现 LoRA 在不同模型规模下提供最佳性价比；实验显示，PEFT 可提升代码任务性能，但模型规模增大可能降低鲁棒性和安全性，为实际应用提供实用指导。\n  \n- **论文 10: FinDABench: Benchmarking Financial Data Analysis Ability of Large Language Models（FinDABench: 基准测试大型语言模型的金融数据分析能力）**  \n  引入 FinDABench 基准，评估 LLMs 在金融数值计算、报告分析和图表可视化中的能力；发现特定模型在基础能力（如情感风险评估）和技术技能上表现突出，但需改进泛化性，为金融 AI 应用提供全面评估框架。\n\n- **论文 16: Taking the Next Step with Generative Artificial Intelligence: The Transformative Role of Multimodal Large Language Models in Science Education（利用生成式人工智能迈向下一步：多模态大型语言模型在科学教育中的变革作用）**  \n  探讨多模态 LLMs（如 GPT-4V）在科学教育中的应用，包括内容创建和个性化反馈；主要发现是这些模型能提升学习效果，但需关注数据隐私和伦理问题，强调技术应辅助而非取代教师。\n\n其他 LLMs 相关论文（如 7、19、27、28）涉及心理健康分析和工具学习评估，但这些更侧重特定场景优化，贡献较局部，因此简要提及：它们展示了 LLMs 在医疗和任务评估中的准确性提升，但面临数据可靠性和泛化挑战。\n\n### 图像处理和生成：技术创新亮点\n这一领域论文强调生成模型的改进和应用，特别在偏见检测和视频分割上。\n- **论文 14: New Job, New Gender? Measuring the Social Bias in Image Generation Models（新工作，新性别？测量图像生成模型中的社会偏见）**  \n  提出 BiasPainter 框架，自动检测图像生成模型（如 Stable Diffusion）的性别、种族偏见；发现模型在职业场景中易产生偏差，准确率达 90.8%，为公平 AI 提供量化评估工具。\n\n- **论文 20: DiffMorph: Text-less Image Morphing with Diffusion Models（DiffMorph: 使用扩散模型的无文本图像变形）**  \n  开发 DiffMorph 方法，实现无文本提示的图像变形，通过扩散模型融合草图和图像；主要贡献是提升图像生成灵活性，无需文本输入，适用于艺术设计。\n\n其他图像论文（如 2、3、23）聚焦 WiFi CSI 人体活动识别和深度图增强，但这些技术细节较多，快速掠过：它们改善了长距离感知和噪声处理，精度可达 92%，但对实际部署的计算需求较高。\n\n### 医疗和生物应用：实用导向\n这些论文将 AI 应用于医疗诊断和脑网络预测，关注实际效果。\n- **论文 8: Accurate Leukocyte Detection Based on Deformable-DETR and Multi-Level Feature Fusion for Aiding Diagnosis of Blood Diseases（基于 Deformable-DETR 和多级特征融合的精确白细胞检测，用于辅助血液疾病诊断）**  \n  提出 MFDS-DETR 模型，通过多级特征融合提升白细胞检测准确性；实验在数据集上表现优异，帮助减少诊断错误，为自动化血液分析提供高效工具。\n\n- **论文 24: Predicting Infant Brain Connectivity with Federated Multi-Trajectory GNNs using Scarce Data（使用稀疏数据和联邦多轨迹 GNNs 预测婴儿脑连接）**  \n  引入 FedGmTE-Net++ 框架，利用联邦学习预测婴儿脑网络轨迹；主要发现是它在数据稀缺环境下提升预测准确性，并通过辅助正则化最大化数据利用。\n\n其他医疗论文（如 7、12、18）探讨 LLMs 在心理健康和患者表示中的作用，但这些更侧重综述和框架，简要掠过：它们强调了模型在诊断中的潜力，但需解决数据隐私和泛化问题。\n\n### 其他领域：快速概述\n剩余论文涉及卫星通信、金融工具和图神经网络等（如 29、4、17），但影响力较小，仅快速提及：论文 29 的 NomaFedHAP 优化了卫星 FL 通信效率，论文 4 的自动化模型选择框架提升了表格数据预测，但这些在当下话题度不如 AI 生成模型高，故不展开讨论。\n\n总之，今天的 arXiv 更新展示了 AI 模型在实际应用中的进展与挑战，LLMs 领域的创新尤为值得关注，读者可优先探索金融和图像相关论文以把握前沿趋势。保持关注，下一天见！",
  "papers": [
    {
      "arxiv_id": "2401.00974v1",
      "title": "Downstream Task-Oriented Generative Model Selections on Synthetic Data Training for Fraud Detection Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yinan Cheng",
        "Chi-Hua Wang",
        "Vamsi K. Potluru",
        "Tucker Balch",
        "Guang Cheng"
      ],
      "abstract": "Devising procedures for downstream task-oriented generative model selections\nis an unresolved problem of practical importance. Existing studies focused on\nthe utility of a single family of generative models. They provided limited\ninsights on how synthetic data practitioners select the best family generative\nmodels for synthetic training tasks given a specific combination of machine\nlearning model class and performance metric. In this paper, we approach the\ndownstream task-oriented generative model selections problem in the case of\ntraining fraud detection models and investigate the best practice given\ndifferent combinations of model interpretability and model performance\nconstraints. Our investigation supports that, while both Neural\nNetwork(NN)-based and Bayesian Network(BN)-based generative models are both\ngood to complete synthetic training task under loose model interpretability\nconstrain, the BN-based generative models is better than NN-based when\nsynthetic training fraud detection model under strict model interpretability\nconstrain. Our results provides practical guidance for machine learning\npractitioner who is interested in replacing their training dataset from real to\nsynthetic, and shed lights on more general downstream task-oriented generative\nmodel selection problems.",
      "tldr_zh": "本论文探讨了针对欺诈检测模型的合成数据训练中，如何进行下游任务导向的生成模型选择问题，调查了不同模型可解释性和性能约束下的最佳实践。研究比较了 Neural Network (NN)-based 和 Bayesian Network (BN)-based 生成模型，发现二者在宽松模型可解释性约束下均能有效完成合成训练任务，但BN-based 生成模型在严格可解释性约束下表现更优。论文为机器学习从业者提供实用指导，帮助从真实数据转向合成数据训练，并为更广泛的下游任务导向生成模型选择问题带来启发。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "The following article has been accepted by ICAIF22, Synthetic Data\n  for AI in Finance; see\n  https://sites.google.com/view/icaif-synthetic-2022/program",
      "pdf_url": "http://arxiv.org/pdf/2401.00974v1",
      "published_date": "2024-01-01 23:33:56 UTC",
      "updated_date": "2024-01-01 23:33:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:07:36.271981"
    },
    {
      "arxiv_id": "2401.01388v1",
      "title": "Directional Antenna Systems for Long-Range Through-Wall Human Activity Recognition",
      "title_zh": "用于长距离穿墙人体活动识别的定向天线系统",
      "authors": [
        "Julian Strohmayer",
        "Martin Kampel"
      ],
      "abstract": "WiFi Channel State Information (CSI)-based human activity recognition (HAR)\nenables contactless, long-range sensing in spatially constrained environments\nwhile preserving visual privacy. However, despite the presence of numerous\nWiFi-enabled devices around us, few expose CSI to users, resulting in a lack of\nsensing hardware options. Variants of the Espressif ESP32 have emerged as\npotential low-cost and easy-to-deploy solutions for WiFi CSI-based HAR. In this\nwork, four ESP32-S3-based 2.4GHz directional antenna systems are evaluated for\ntheir ability to facilitate long-range through-wall HAR. Two promising systems\nare proposed, one of which combines the ESP32-S3 with a directional biquad\nantenna. This combination represents, to the best of our knowledge, the first\ndemonstration of such a system in WiFi-based HAR. The second system relies on\nthe built-in printed inverted-F antenna (PIFA) of the ESP32-S3 and achieves\ndirectionality through a plane reflector. In a comprehensive evaluation of\nline-of-sight (LOS) and non-line-of-sight (NLOS) HAR performance, both systems\nare deployed in an office environment spanning a distance of 18 meters across\nfive rooms. In this experimental setup, the Wallhack1.8k dataset, comprising\n1806 CSI amplitude spectrograms of human activities, is collected and made\npublicly available. Based on Wallhack1.8k, we train activity recognition models\nusing the EfficientNetV2 architecture to assess system performance in LOS and\nNLOS scenarios. For the core NLOS activity recognition problem, the biquad\nantenna and PIFA-based systems achieve accuracies of 92.0$\\pm$3.5 and\n86.8$\\pm$4.7, respectively, demonstrating the feasibility of long-range\nthrough-wall HAR with the proposed systems.",
      "tldr_zh": "这篇论文探讨了基于 WiFi Channel State Information (CSI) 的长距离穿墙人类活动识别 (HAR)，以解决现有硬件选项不足的问题，通过评估四个基于 ESP32-S3 的 2.4GHz 定向天线系统。研究提出了两种创新系统：一种是将 ESP32-S3 与定向 biquad antenna 结合，另一款则利用 ESP32-S3 的内置 printed inverted-F antenna (PIFA) 和平面反射器实现方向性。在办公室环境中进行的实验跨越 18 米，包括 line-of-sight (LOS) 和 non-line-of-sight (NLOS) 场景，收集了 Wallhack1.8k 数据集（包含 1806 个 CSI 幅度谱图）。使用 EfficientNetV2 架构训练的模型在 NLOS 场景中，biquad antenna 系统达到 92.0±3.5% 的准确率，PIFA 系统达到 86.8±4.7%，证明了这些系统的长距离穿墙 HAR 可行性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "arXiv admin note: text overlap with arXiv:2401.00964",
      "pdf_url": "http://arxiv.org/pdf/2401.01388v1",
      "published_date": "2024-01-01 22:35:22 UTC",
      "updated_date": "2024-01-01 22:35:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:07:50.042586"
    },
    {
      "arxiv_id": "2401.00964v1",
      "title": "Data Augmentation Techniques for Cross-Domain WiFi CSI-based Human Activity Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Julian Strohmayer",
        "Martin Kampel"
      ],
      "abstract": "The recognition of human activities based on WiFi Channel State Information\n(CSI) enables contactless and visual privacy-preserving sensing in indoor\nenvironments. However, poor model generalization, due to varying environmental\nconditions and sensing hardware, is a well-known problem in this space. To\naddress this issue, in this work, data augmentation techniques commonly used in\nimage-based learning are applied to WiFi CSI to investigate their effects on\nmodel generalization performance in cross-scenario and cross-system settings.\nIn particular, we focus on the generalization between line-of-sight (LOS) and\nnon-line-of-sight (NLOS) through-wall scenarios, as well as on the\ngeneralization between different antenna systems, which remains under-explored.\nWe collect and make publicly available a dataset of CSI amplitude spectrograms\nof human activities. Utilizing this data, an ablation study is conducted in\nwhich activity recognition models based on the EfficientNetV2 architecture are\ntrained, allowing us to assess the effects of each augmentation on model\ngeneralization performance. The gathered results show that specific\ncombinations of simple data augmentation techniques applied to CSI amplitude\ndata can significantly improve cross-scenario and cross-system generalization.",
      "tldr_zh": "本研究探讨了数据增强(data augmentation)技术在跨域 WiFi Channel State Information (CSI) 基于的人类活动识别中的应用，以解决模型在不同环境条件和硬件系统下的泛化性能问题。研究者专注于 line-of-sight (LOS) 与 non-line-of-sight (NLOS) 通过墙场景，以及不同天线系统之间的泛化，收集并公开了一个 CSI 幅度谱图数据集，并使用 EfficientNetV2 架构进行消融研究评估各增强技术的效果。结果显示，特定组合的简单数据增强技术能显著提升跨场景和跨系统模型的泛化性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.00964v1",
      "published_date": "2024-01-01 22:27:59 UTC",
      "updated_date": "2024-01-01 22:27:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:07:59.851680"
    },
    {
      "arxiv_id": "2401.00961v2",
      "title": "Automated Model Selection for Tabular Data",
      "title_zh": "自动化表格数据模型选择",
      "authors": [
        "Avinash Amballa",
        "Gayathri Akkinapalli",
        "Manas Madine",
        "Naga Pavana Priya Yarrabolu",
        "Przemyslaw A. Grabowicz"
      ],
      "abstract": "Structured data in the form of tabular datasets contain features that are\ndistinct and discrete, with varying individual and relative importances to the\ntarget. Combinations of one or more features may be more predictive and\nmeaningful than simple individual feature contributions. R's mixed effect\nlinear models library allows users to provide such interactive feature\ncombinations in the model design. However, given many features and possible\ninteractions to select from, model selection becomes an exponentially difficult\ntask. We aim to automate the model selection process for predictions on tabular\ndatasets incorporating feature interactions while keeping computational costs\nsmall. The framework includes two distinct approaches for feature selection: a\nPriority-based Random Grid Search and a Greedy Search method. The\nPriority-based approach efficiently explores feature combinations using prior\nprobabilities to guide the search. The Greedy method builds the solution\niteratively by adding or removing features based on their impact. Experiments\non synthetic demonstrate the ability to effectively capture predictive feature\ncombinations.",
      "tldr_zh": "本研究针对表格数据的模型选择问题，提出了一种自动化框架，以处理特征交互带来的指数级复杂度，同时保持计算成本较低。该框架包括两种特征选择方法：Priority-based Random Grid Search，利用先验概率引导高效探索特征组合；以及Greedy Search，通过迭代添加或移除特征基于其影响来构建模型。在合成数据实验中，该框架成功捕获了预测性特征组合，证明了其有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages",
      "pdf_url": "http://arxiv.org/pdf/2401.00961v2",
      "published_date": "2024-01-01 21:41:20 UTC",
      "updated_date": "2024-05-29 01:03:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:08:10.147924"
    },
    {
      "arxiv_id": "2401.00850v2",
      "title": "Refining Pre-Trained Motion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Xinglong Sun",
        "Adam W. Harley",
        "Leonidas J. Guibas"
      ],
      "abstract": "Given the difficulty of manually annotating motion in video, the current best\nmotion estimation methods are trained with synthetic data, and therefore\nstruggle somewhat due to a train/test gap. Self-supervised methods hold the\npromise of training directly on real video, but typically perform worse. These\ninclude methods trained with warp error (i.e., color constancy) combined with\nsmoothness terms, and methods that encourage cycle-consistency in the estimates\n(i.e., tracking backwards should yield the opposite trajectory as tracking\nforwards). In this work, we take on the challenge of improving state-of-the-art\nsupervised models with self-supervised training. We find that when the\ninitialization is supervised weights, most existing self-supervision techniques\nactually make performance worse instead of better, which suggests that the\nbenefit of seeing the new data is overshadowed by the noise in the training\nsignal. Focusing on obtaining a \"clean\" training signal from real-world\nunlabelled video, we propose to separate label-making and training into two\ndistinct stages. In the first stage, we use the pre-trained model to estimate\nmotion in a video, and then select the subset of motion estimates which we can\nverify with cycle-consistency. This produces a sparse but accurate\npseudo-labelling of the video. In the second stage, we fine-tune the model to\nreproduce these outputs, while also applying augmentations on the input. We\ncomplement this boot-strapping method with simple techniques that densify and\nre-balance the pseudo-labels, ensuring that we do not merely train on \"easy\"\ntracks. We show that our method yields reliable gains over fully-supervised\nmethods in real videos, for both short-term (flow-based) and long-range\n(multi-frame) pixel tracking.",
      "tldr_zh": "该论文探讨了如何通过自监督训练改进预训练的运动模型，以解决现有监督方法在真实视频上因训练/测试差距而导致的性能问题。作者提出一个两阶段方法：首先，使用预训练模型估计视频运动并通过cycle-consistency验证生成稀疏但准确的pseudo-labelling；其次，对模型进行微调以重现这些伪标签，同时应用输入增强和技术来稠密化及重新平衡标签。实验结果显示，该方法在真实视频的短期（基于光流的）和长期（多帧）像素跟踪任务上，比完全监督方法实现了可靠的性能提升。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at ICRA 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.00850v2",
      "published_date": "2024-01-01 18:59:33 UTC",
      "updated_date": "2024-02-17 03:09:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:08:23.372458"
    },
    {
      "arxiv_id": "2401.00832v3",
      "title": "Taking the Next Step with Generative Artificial Intelligence: The Transformative Role of Multimodal Large Language Models in Science Education",
      "title_zh": "翻译失败",
      "authors": [
        "Arne Bewersdorff",
        "Christian Hartmann",
        "Marie Hornberger",
        "Kathrin Seßler",
        "Maria Bannert",
        "Enkelejda Kasneci",
        "Gjergji Kasneci",
        "Xiaoming Zhai",
        "Claudia Nerdel"
      ],
      "abstract": "The integration of Artificial Intelligence (AI), particularly Large Language\nModel (LLM)-based systems, in education has shown promise in enhancing teaching\nand learning experiences. However, the advent of Multimodal Large Language\nModels (MLLMs) like GPT-4 with vision (GPT-4V), capable of processing\nmultimodal data including text, sound, and visual inputs, opens a new era of\nenriched, personalized, and interactive learning landscapes in education.\nGrounded in theory of multimedia learning, this paper explores the\ntransformative role of MLLMs in central aspects of science education by\npresenting exemplary innovative learning scenarios. Possible applications for\nMLLMs could range from content creation to tailored support for learning,\nfostering competencies in scientific practices, and providing assessment and\nfeedback. These scenarios are not limited to text-based and uni-modal formats\nbut can be multimodal, increasing thus personalization, accessibility, and\npotential learning effectiveness. Besides many opportunities, challenges such\nas data protection and ethical considerations become more salient, calling for\nrobust frameworks to ensure responsible integration. This paper underscores the\nnecessity for a balanced approach in implementing MLLMs, where the technology\ncomplements rather than supplants the educator's role, ensuring thus an\neffective and ethical use of AI in science education. It calls for further\nresearch to explore the nuanced implications of MLLMs on the evolving role of\neducators and to extend the discourse beyond science education to other\ndisciplines. Through the exploration of potentials, challenges, and future\nimplications, we aim to contribute to a preliminary understanding of the\ntransformative trajectory of MLLMs in science education and beyond.",
      "tldr_zh": "本论文探讨了多模态大型语言模型（MLLMs，如 GPT-4V）在科学教育中的变革性作用，这些模型能处理文本、声音和视觉等多模态数据，从而提升教学和学习体验。基于多媒体学习理论，论文呈现了创新学习场景，包括内容创建、个性化支持、培养科学实践能力和提供评估反馈，这些应用通过多模态方式提高了学习个性化、可访问性和有效性。尽管MLLMs带来诸多机遇，但论文强调了数据保护和伦理挑战的紧迫性，呼吁采用稳健框架确保负责任整合，并建议MLLMs补充而非取代教师角色。最终，论文呼吁进一步研究MLLMs对教育者角色的影响，并扩展到其他学科领域，以推动AI在教育中的平衡发展。",
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "revised version 2. September 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.00832v3",
      "published_date": "2024-01-01 18:11:43 UTC",
      "updated_date": "2024-09-19 08:07:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:08:35.848205"
    },
    {
      "arxiv_id": "2401.02984v2",
      "title": "Large Language Models in Mental Health Care: a Scoping Review",
      "title_zh": "翻译失败",
      "authors": [
        "Yining Hua",
        "Fenglin Liu",
        "Kailai Yang",
        "Zehan Li",
        "Hongbin Na",
        "Yi-han Sheu",
        "Peilin Zhou",
        "Lauren V. Moran",
        "Sophia Ananiadou",
        "Andrew Beam",
        "John Torous"
      ],
      "abstract": "The integration of large language models (LLMs) in mental health care is an\nemerging field. There is a need to systematically review the application\noutcomes and delineate the advantages and limitations in clinical settings.\nThis review aims to provide a comprehensive overview of the use of LLMs in\nmental health care, assessing their efficacy, challenges, and potential for\nfuture applications. A systematic search was conducted across multiple\ndatabases including PubMed, Web of Science, Google Scholar, arXiv, medRxiv, and\nPsyArXiv in November 2023. All forms of original research, peer-reviewed or\nnot, published or disseminated between October 1, 2019, and December 2, 2023,\nare included without language restrictions if they used LLMs developed after T5\nand directly addressed research questions in mental health care settings. From\nan initial pool of 313 articles, 34 met the inclusion criteria based on their\nrelevance to LLM application in mental health care and the robustness of\nreported outcomes. Diverse applications of LLMs in mental health care are\nidentified, including diagnosis, therapy, patient engagement enhancement, etc.\nKey challenges include data availability and reliability, nuanced handling of\nmental states, and effective evaluation methods. Despite successes in accuracy\nand accessibility improvement, gaps in clinical applicability and ethical\nconsiderations were evident, pointing to the need for robust data, standardized\nevaluations, and interdisciplinary collaboration. LLMs hold substantial promise\nfor enhancing mental health care. For their full potential to be realized,\nemphasis must be placed on developing robust datasets, development and\nevaluation frameworks, ethical guidelines, and interdisciplinary collaborations\nto address current limitations.",
      "tldr_zh": "这篇综述系统审查了 Large Language Models (LLMs) 在心理健康护理中的应用，通过搜索多个数据库筛选出 34 篇相关文章，评估了其功效、挑战和未来潜力。研究发现，LLMs 在诊断、治疗和患者参与等方面显示出显著优势，如提升准确性和可访问性，但面临数据可靠性和处理心理状态的细微性等关键挑战。尽管存在这些限制，LLMs 具有巨大潜力，通过开发稳健数据集、标准化评估框架以及加强伦理指南和跨学科合作来实现更广泛的临床应用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.02984v2",
      "published_date": "2024-01-01 17:35:52 UTC",
      "updated_date": "2024-08-21 13:55:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:08:47.704929"
    },
    {
      "arxiv_id": "2401.00926v4",
      "title": "Accurate Leukocyte Detection Based on Deformable-DETR and Multi-Level Feature Fusion for Aiding Diagnosis of Blood Diseases",
      "title_zh": "基于 Deformable-DETR 和多级特征融合的准确白细胞检测，用于辅助血液疾病诊断",
      "authors": [
        "Yifei Chen",
        "Chenyan Zhang",
        "Ben Chen",
        "Yiyu Huang",
        "Yifei Sun",
        "Changmiao Wang",
        "Xianjun Fu",
        "Yuxing Dai",
        "Feiwei Qin",
        "Yong Peng",
        "Yu Gao"
      ],
      "abstract": "In standard hospital blood tests, the traditional process requires doctors to\nmanually isolate leukocytes from microscopic images of patients' blood using\nmicroscopes. These isolated leukocytes are then categorized via automatic\nleukocyte classifiers to determine the proportion and volume of different types\nof leukocytes present in the blood samples, aiding disease diagnosis. This\nmethodology is not only time-consuming and labor-intensive, but it also has a\nhigh propensity for errors due to factors such as image quality and\nenvironmental conditions, which could potentially lead to incorrect subsequent\nclassifications and misdiagnosis. To address these issues, this paper proposes\nan innovative method of leukocyte detection: the Multi-level Feature Fusion and\nDeformable Self-attention DETR (MFDS-DETR). To tackle the issue of leukocyte\nscale disparity, we designed the High-level Screening-feature Fusion Pyramid\n(HS-FPN), enabling multi-level fusion. This model uses high-level features as\nweights to filter low-level feature information via a channel attention module\nand then merges the screened information with the high-level features, thus\nenhancing the model's feature expression capability. Further, we address the\nissue of leukocyte feature scarcity by incorporating a multi-scale deformable\nself-attention module in the encoder and using the self-attention and\ncross-deformable attention mechanisms in the decoder, which aids in the\nextraction of the global features of the leukocyte feature maps. The\neffectiveness, superiority, and generalizability of the proposed MFDS-DETR\nmethod are confirmed through comparisons with other cutting-edge leukocyte\ndetection models using the private WBCDD, public LISC and BCCD datasets. Our\nsource code and private WBCCD dataset are available at\nhttps://github.com/JustlfC03/MFDS-DETR.",
      "tldr_zh": "该论文针对传统医院血检中手动隔离白血球的耗时、费力和易出错问题，提出了一种创新的白血球检测方法：Multi-level Feature Fusion and Deformable Self-attention DETR (MFDS-DETR)。该方法通过设计 High-level Screening-feature Fusion Pyramid (HS-FPN) 来融合多级特征，利用通道注意力模块筛选和增强特征表达，并结合多尺度可变形自注意力机制在编码器和解码器中提取白血球的全局特征。实验结果显示，MFDS-DETR 在私有 WBCDD 及公开 LISC 和 BCCD 数据集上优于现有模型，证明了其在准确性和泛化能力方面的优势，有助于辅助血病诊断。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "15 pages, 11 figures, accept Computers in Biology and Medicine 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.00926v4",
      "published_date": "2024-01-01 16:28:30 UTC",
      "updated_date": "2024-01-10 08:26:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:09:02.521163"
    },
    {
      "arxiv_id": "2401.00788v1",
      "title": "Astraios: Parameter-Efficient Instruction Tuning Code Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Terry Yue Zhuo",
        "Armel Zebaze",
        "Nitchakarn Suppattarachai",
        "Leandro von Werra",
        "Harm de Vries",
        "Qian Liu",
        "Niklas Muennighoff"
      ],
      "abstract": "The high cost of full-parameter fine-tuning (FFT) of Large Language Models\n(LLMs) has led to a series of parameter-efficient fine-tuning (PEFT) methods.\nHowever, it remains unclear which methods provide the best cost-performance\ntrade-off at different model scales. We introduce Astraios, a suite of 28\ninstruction-tuned OctoCoder models using 7 tuning methods and 4 model sizes up\nto 16 billion parameters. Through investigations across 5 tasks and 8 different\ndatasets encompassing both code comprehension and code generation tasks, we\nfind that FFT generally leads to the best downstream performance across all\nscales, and PEFT methods differ significantly in their efficacy based on the\nmodel scale. LoRA usually offers the most favorable trade-off between cost and\nperformance. Further investigation into the effects of these methods on both\nmodel robustness and code security reveals that larger models tend to\ndemonstrate reduced robustness and less security. At last, we explore the\nrelationships among updated parameters, cross-entropy loss, and task\nperformance. We find that the tuning effectiveness observed in small models\ngeneralizes well to larger models, and the validation loss in instruction\ntuning can be a reliable indicator of overall downstream performance.",
      "tldr_zh": "本研究引入了Astraios，这是一个包含28个指令调整的OctoCoder模型套件，使用7种微调方法和4种模型规模（最大16B参数），旨在评估参数高效微调(PEFT)方法的成本-性能权衡。实验通过5个任务和8个数据集（涵盖代码理解和生成）发现，全参数微调(FFT)通常提供最佳下游性能，而PEFT方法的效果因模型规模而异，LoRA往往在成本和性能间提供最佳平衡。进一步分析显示，较大模型的鲁棒性和代码安全性降低，且指令调优中的验证损失可作为下游性能的可靠指标。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.CL",
      "comment": "25 pages (12 main), 19 figures, 8 tables",
      "pdf_url": "http://arxiv.org/pdf/2401.00788v1",
      "published_date": "2024-01-01 15:30:19 UTC",
      "updated_date": "2024-01-01 15:30:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:09:12.456430"
    },
    {
      "arxiv_id": "2401.02982v4",
      "title": "FinDABench: Benchmarking Financial Data Analysis Ability of Large Language Models",
      "title_zh": "FinDABench：大型语言模型的金融数据分析能力基准测试",
      "authors": [
        "Shu Liu",
        "Shangqing Zhao",
        "Chenghao Jia",
        "Xinlin Zhuang",
        "Zhaoguang Long",
        "Jie Zhou",
        "Aimin Zhou",
        "Man Lan",
        "Qingquan Wu",
        "Chong Yang"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated impressive capabilities across\na wide range of tasks. However, their proficiency and reliability in the\nspecialized domain of financial data analysis, particularly focusing on\ndata-driven thinking, remain uncertain. To bridge this gap, we introduce\n\\texttt{FinDABench}, a comprehensive benchmark designed to evaluate the\nfinancial data analysis capabilities of LLMs within this context.\n\\texttt{FinDABench} assesses LLMs across three dimensions: 1)\n\\textbf{Foundational Ability}, evaluating the models' ability to perform\nfinancial numerical calculation and corporate sentiment risk assessment; 2)\n\\textbf{Reasoning Ability}, determining the models' ability to quickly\ncomprehend textual information and analyze abnormal financial reports; and 3)\n\\textbf{Technical Skill}, examining the models' use of technical knowledge to\naddress real-world data analysis challenges involving analysis generation and\ncharts visualization from multiple perspectives. We will release\n\\texttt{FinDABench}, and the evaluation scripts at\n\\url{https://github.com/cubenlp/BIBench}. \\texttt{FinDABench} aims to provide a\nmeasure for in-depth analysis of LLM abilities and foster the advancement of\nLLMs in the field of financial data analysis.",
      "tldr_zh": "该研究引入了 FinDABench，这是一个全面基准测试，用于评估大型语言模型 (LLMs) 在金融数据分析领域的能力，特别是数据驱动思维的熟练度和可靠性。FinDABench 涵盖三个维度：1) **Foundational Ability**，评估模型在金融数值计算和公司情绪风险评估方面的基础能力；2) **Reasoning Ability**，测试模型快速理解文本信息和分析异常财务报告的能力；以及3) **Technical Skill**，考察模型使用技术知识处理真实世界挑战，如分析生成和图表可视化。研究将 FinDABench 和评估脚本发布在 GitHub 上，旨在为深入分析 LLMs 的能力提供标准，并推动其在金融数据分析领域的进步。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.02982v4",
      "published_date": "2024-01-01 15:26:23 UTC",
      "updated_date": "2024-06-14 10:17:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:09:23.006882"
    },
    {
      "arxiv_id": "2401.00779v1",
      "title": "Temporal Validity Change Prediction",
      "title_zh": "时间有效性变化预测",
      "authors": [
        "Georg Wenzel",
        "Adam Jatowt"
      ],
      "abstract": "Temporal validity is an important property of text that is useful for many\ndownstream applications, such as recommender systems, conversational AI, or\nstory understanding. Existing benchmarking tasks often require models to\nidentify the temporal validity duration of a single statement. However, in many\ncases, additional contextual information, such as sentences in a story or posts\non a social media profile, can be collected from the available text stream.\nThis contextual information may greatly alter the duration for which a\nstatement is expected to be valid. We propose Temporal Validity Change\nPrediction, a natural language processing task benchmarking the capability of\nmachine learning models to detect contextual statements that induce such\nchange. We create a dataset consisting of temporal target statements sourced\nfrom Twitter and crowdsource sample context statements. We then benchmark a set\nof transformer-based language models on our dataset. Finally, we experiment\nwith temporal validity duration prediction as an auxiliary task to improve the\nperformance of the state-of-the-art model.",
      "tldr_zh": "这篇论文提出 Temporal Validity Change Prediction 任务，用于评估机器学习模型检测上下文语句是否会改变文本的时间有效性（temporal validity）持续时间的能力，尤其在推荐系统、对话 AI 或故事理解等应用中。研究者创建了一个数据集，从 Twitter 采集目标语句并众包上下文样本，然后基准测试了基于 transformer 的语言模型。实验结果表明，将时间有效性持续时间预测作为辅助任务，能提升最先进模型的性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "68T50",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "9 pages, 9 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2401.00779v1",
      "published_date": "2024-01-01 14:58:53 UTC",
      "updated_date": "2024-01-01 14:58:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:09:35.626633"
    },
    {
      "arxiv_id": "2401.00776v1",
      "title": "Edge Computing based Human-Robot Cognitive Fusion: A Medical Case Study in the Autism Spectrum Disorder Therapy",
      "title_zh": "翻译失败",
      "authors": [
        "Qin Yang"
      ],
      "abstract": "In recent years, edge computing has served as a paradigm that enables many\nfuture technologies like AI, Robotics, IoT, and high-speed wireless sensor\nnetworks (like 5G) by connecting cloud computing facilities and services to the\nend users. Especially in medical and healthcare applications, it provides\nremote patient monitoring and increases voluminous multimedia. From the\nrobotics angle, robot-assisted therapy (RAT) is an active-assistive robotic\ntechnology in rehabilitation robotics, attracting many researchers to study and\nbenefit people with disability like autism spectrum disorder (ASD) children.\nHowever, the main challenge of RAT is that the model capable of detecting the\naffective states of ASD people exists and can recall individual preferences.\nMoreover, involving expert diagnosis and recommendations to guide robots in\nupdating the therapy approach to adapt to different statuses and scenarios is a\ncrucial part of the ASD therapy process. This paper proposes the architecture\nof edge cognitive computing by combining human experts and assisted robots\ncollaborating in the same framework to help ASD patients with long-term\nsupport. By integrating the real-time computing and analysis of a new cognitive\nrobotic model for ASD therapy, the proposed architecture can achieve a seamless\nremote diagnosis, round-the-clock symptom monitoring, emergency warning,\ntherapy alteration, and advanced assistance.",
      "tldr_zh": "本论文探讨了基于边缘计算（edge computing）的Human-Robot Cognitive Fusion架构，针对自闭症谱系障碍（Autism Spectrum Disorder, ASD）疗法的应用案例。论文提出将人类专家与辅助机器人整合到一个框架中，利用实时计算和新的认知机器人模型（cognitive robotic model），以解决Robot-Assisted Therapy (RAT)中检测情感状态、回忆个人偏好以及动态调整疗法的挑战。该架构实现了无缝远程诊断、24/7症状监测、紧急警告、疗法调整和高级辅助，支持ASD患者的长效治疗。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.DC",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.RO",
      "comment": "This paper was accepted by the 38th AAAI 2024 workshop: \"Cooperative\n  Multi-Agent Systems Decision-Making and Learning: From Individual Needs to\n  Swarm Intelligence\"",
      "pdf_url": "http://arxiv.org/pdf/2401.00776v1",
      "published_date": "2024-01-01 14:45:19 UTC",
      "updated_date": "2024-01-01 14:45:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:09:46.719268"
    },
    {
      "arxiv_id": "2401.00773v3",
      "title": "Unsupervised Outlier Detection using Random Subspace and Subsampling Ensembles of Dirichlet Process Mixtures",
      "title_zh": "翻译失败",
      "authors": [
        "Dongwook Kim",
        "Juyeon Park",
        "Hee Cheol Chung",
        "Seonghyun Jeong"
      ],
      "abstract": "Probabilistic mixture models are recognized as effective tools for\nunsupervised outlier detection owing to their interpretability and global\ncharacteristics. Among these, Dirichlet process mixture models stand out as a\nstrong alternative to conventional finite mixture models for both clustering\nand outlier detection tasks. Unlike finite mixture models, Dirichlet process\nmixtures are infinite mixture models that automatically determine the number of\nmixture components based on the data. Despite their advantages, the adoption of\nDirichlet process mixture models for unsupervised outlier detection has been\nlimited by challenges related to computational inefficiency and sensitivity to\noutliers in the construction of outlier detectors. Additionally, Dirichlet\nprocess Gaussian mixtures struggle to effectively model non-Gaussian data with\ndiscrete or binary features. To address these challenges, we propose a novel\noutlier detection method that utilizes ensembles of Dirichlet process Gaussian\nmixtures. This unsupervised algorithm employs random subspace and subsampling\nensembles to ensure efficient computation and improve the robustness of the\noutlier detector. The ensemble approach further improves the suitability of the\nproposed method for detecting outliers in non-Gaussian data. Furthermore, our\nmethod uses variational inference for Dirichlet process mixtures, which ensures\nboth efficient and rapid computation. Empirical analyses using benchmark\ndatasets demonstrate that our method outperforms existing approaches in\nunsupervised outlier detection.",
      "tldr_zh": "这篇论文提出了一种新的无监督异常检测方法，使用Dirichlet process mixtures的集成（包括random subspace和subsampling ensembles）来解决传统模型的计算效率低和对异常敏感的问题。该方法通过Dirichlet process Gaussian mixtures自动确定混合组件数量，并采用variational inference进行高效计算，提高了对非高斯数据的鲁棒性。实验结果表明，该方法在基准数据集上优于现有方法，在异常检测性能上表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.00773v3",
      "published_date": "2024-01-01 14:34:11 UTC",
      "updated_date": "2024-07-25 08:13:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:09:58.534001"
    },
    {
      "arxiv_id": "2401.00763v3",
      "title": "New Job, New Gender? Measuring the Social Bias in Image Generation Models",
      "title_zh": "新工作，新性别？ 测量图像生成模型中的社会偏见",
      "authors": [
        "Wenxuan Wang",
        "Haonan Bai",
        "Jen-tse Huang",
        "Yuxuan Wan",
        "Youliang Yuan",
        "Haoyi Qiu",
        "Nanyun Peng",
        "Michael R. Lyu"
      ],
      "abstract": "Image generation models can generate or edit images from a given text. Recent\nadvancements in image generation technology, exemplified by DALL-E and\nMidjourney, have been groundbreaking. These advanced models, despite their\nimpressive capabilities, are often trained on massive Internet datasets, making\nthem susceptible to generating content that perpetuates social stereotypes and\nbiases, which can lead to severe consequences. Prior research on assessing bias\nwithin image generation models suffers from several shortcomings, including\nlimited accuracy, reliance on extensive human labor, and lack of comprehensive\nanalysis. In this paper, we propose BiasPainter, a novel evaluation framework\nthat can accurately, automatically and comprehensively trigger social bias in\nimage generation models. BiasPainter uses a diverse range of seed images of\nindividuals and prompts the image generation models to edit these images using\ngender, race, and age-neutral queries. These queries span 62 professions, 39\nactivities, 57 types of objects, and 70 personality traits. The framework then\ncompares the edited images to the original seed images, focusing on the\nsignificant changes related to gender, race, and age. BiasPainter adopts a key\ninsight that these characteristics should not be modified when subjected to\nneutral prompts. Built upon this design, BiasPainter can trigger the social\nbias and evaluate the fairness of image generation models. We use BiasPainter\nto evaluate six widely-used image generation models, such as stable diffusion\nand Midjourney. Experimental results show that BiasPainter can successfully\ntrigger social bias in image generation models. According to our human\nevaluation, BiasPainter can achieve 90.8% accuracy on automatic bias detection,\nwhich is significantly higher than the results reported in previous work.",
      "tldr_zh": "本研究探讨了图像生成模型（如 DALL-E 和 Midjourney）在生成内容时可能强化社会刻板印象的问题，特别是在性别、种族和年龄方面。论文提出了一种新型评估框架 BiasPainter，通过使用多样化的种子图像和中性查询（如涉及62个职业、39个活动等），自动编辑图像并比较前后变化，以准确触发和评估模型中的社会偏见。实验结果显示，BiasPainter 在评估 Stable Diffusion 和 Midjourney 等六种模型时，人评准确率达90.8%，远超现有方法，并证明了其在全面检测偏见方面的有效性。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.MM"
      ],
      "primary_category": "cs.SE",
      "comment": "ACM MM 2024 Oral",
      "pdf_url": "http://arxiv.org/pdf/2401.00763v3",
      "published_date": "2024-01-01 14:06:55 UTC",
      "updated_date": "2024-08-20 04:11:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:10:11.030649"
    },
    {
      "arxiv_id": "2401.00761v1",
      "title": "The Earth is Flat? Unveiling Factual Errors in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Wenxuan Wang",
        "Juluan Shi",
        "Zhaopeng Tu",
        "Youliang Yuan",
        "Jen-tse Huang",
        "Wenxiang Jiao",
        "Michael R. Lyu"
      ],
      "abstract": "Large Language Models (LLMs) like ChatGPT are foundational in various\napplications due to their extensive knowledge from pre-training and\nfine-tuning. Despite this, they are prone to generating factual and commonsense\nerrors, raising concerns in critical areas like healthcare, journalism, and\neducation to mislead users. Current methods for evaluating LLMs' veracity are\nlimited by test data leakage or the need for extensive human labor, hindering\nefficient and accurate error detection. To tackle this problem, we introduce a\nnovel, automatic testing framework, FactChecker, aimed at uncovering factual\ninaccuracies in LLMs. This framework involves three main steps: First, it\nconstructs a factual knowledge graph by retrieving fact triplets from a\nlarge-scale knowledge database. Then, leveraging the knowledge graph,\nFactChecker employs a rule-based approach to generates three types of questions\n(Yes-No, Multiple-Choice, and WH questions) that involve single-hop and\nmulti-hop relations, along with correct answers. Lastly, it assesses the LLMs'\nresponses for accuracy using tailored matching strategies for each question\ntype. Our extensive tests on six prominent LLMs, including text-davinci-002,\ntext-davinci-003, ChatGPT~(gpt-3.5-turbo, gpt-4), Vicuna, and LLaMA-2, reveal\nthat FactChecker can trigger factual errors in up to 45\\% of questions in these\nmodels. Moreover, we demonstrate that FactChecker's test cases can improve\nLLMs' factual accuracy through in-context learning and fine-tuning (e.g.,\nllama-2-13b-chat's accuracy increase from 35.3\\% to 68.5\\%). We are making all\ncode, data, and results available for future research endeavors.",
      "tldr_zh": "本研究揭示了大型语言模型（Large Language Models, LLMs）如 ChatGPT 在生成事实和常识错误方面的不足，这些错误可能在医疗、教育和新闻等领域误导用户。作者提出了一种自动测试框架 FactChecker，通过构建事实知识图、生成 Yes-No、Multiple-Choice 和 WH 问题（涉及单跳和多跳关系），并使用针对性匹配策略评估模型响应，来检测 LLMs 的事实不准确性。在对六种 LLMs 的测试中，FactChecker 引发了高达 45% 的错误率，并证明其测试案例可通过 in-context learning 和 fine-tuning 显著提升模型准确性（如 llama-2-13b-chat 从 35.3% 提高到 68.5%），所有代码、数据和结果已公开以支持进一步研究。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.00761v1",
      "published_date": "2024-01-01 14:02:27 UTC",
      "updated_date": "2024-01-01 14:02:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:10:25.200921"
    },
    {
      "arxiv_id": "2401.00757v3",
      "title": "LogicAsker: Evaluating and Improving the Logical Reasoning Ability of Large Language Models",
      "title_zh": "LogicAsker: 评估和改进大型语言模型的逻辑推理能力",
      "authors": [
        "Yuxuan Wan",
        "Wenxuan Wang",
        "Yiliu Yang",
        "Youliang Yuan",
        "Jen-tse Huang",
        "Pinjia He",
        "Wenxiang Jiao",
        "Michael R. Lyu"
      ],
      "abstract": "We introduce LogicAsker, a novel approach for evaluating and enhancing the\nlogical reasoning capabilities of large language models (LLMs) such as ChatGPT\nand GPT-4. Despite LLMs' prowess in tasks like writing assistance, code\ngeneration, and machine translation, assessing their ability to reason has been\nchallenging. Traditional evaluations often prioritize accuracy on downstream\ntasks over direct assessments of reasoning processes. LogicAsker addresses this\ngap by employing a set of atomic reasoning skills grounded in propositional and\npredicate logic to systematically examine and improve the reasoning prowess of\nLLMs. Our methodology reveals significant gaps in LLMs' learning of logical\nrules, with identified reasoning failures ranging from 29\\% to 90\\% across\ndifferent models. Moreover, we leverage these findings to construct targeted\ndemonstration examples and fine-tune data, notably enhancing logical reasoning\nin models like GPT-4o by up to 5\\%. To our knowledge, this is the first effort\nto utilize test case outcomes to effectively refine LLMs' formal reasoning\ncapabilities. We make our code, data, and results publicly available\n(https://github.com/yxwan123/LogicAsker) to facilitate further research and\nreplication of our findings.",
      "tldr_zh": "本研究引入了LogicAsker，一种新颖方法，用于评估和提升大型语言模型(LLMs)如ChatGPT和GPT-4的逻辑推理能力，解决传统评估偏重下游任务准确率而忽略推理过程的问题。LogicAsker通过基于命题逻辑和谓词逻辑的原子推理技能，对LLMs进行系统性检查，发现不同模型的推理失败率从29%到90%不等。研究进一步利用这些评估结果创建针对性演示示例和微调数据，成功提升了如GPT-4o的逻辑推理能力高达5%，这是首次利用测试结果来有效改进LLMs的正式推理能力。代码、数据和结果已开源（https://github.com/yxwan123/LogicAsker），以促进进一步研究。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL",
        "cs.LO"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted by EMNLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.00757v3",
      "published_date": "2024-01-01 13:53:53 UTC",
      "updated_date": "2024-10-08 14:34:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:10:36.025041"
    },
    {
      "arxiv_id": "2401.01384v1",
      "title": "Strong Transitivity Relations and Graph Neural Networks",
      "title_zh": "强传递关系与图神经网络",
      "authors": [
        "Yassin Mohamadi",
        "Mostafa Haghir Chehreghani"
      ],
      "abstract": "Local neighborhoods play a crucial role in embedding generation in\ngraph-based learning. It is commonly believed that nodes ought to have\nembeddings that resemble those of their neighbors. In this research, we try to\ncarefully expand the concept of similarity from nearby neighborhoods to the\nentire graph. We provide an extension of similarity that is based on\ntransitivity relations, which enables Graph Neural Networks (GNNs) to capture\nboth global similarities and local similarities over the whole graph. We\nintroduce Transitivity Graph Neural Network (TransGNN), which more than local\nnode similarities, takes into account global similarities by distinguishing\nstrong transitivity relations from weak ones and exploiting them. We evaluate\nour model over several real-world datasets and showed that it considerably\nimproves the performance of several well-known GNN models, for tasks such as\nnode classification.",
      "tldr_zh": "本研究扩展了图神经网络(GNNs)中节点嵌入的相似性概念，从局部邻域到整个图，通过引入基于 transitivity relations 的全局相似性框架。提出 Transitivity Graph Neural Network (TransGNN) 模型，该模型区分强和弱 transitivity relations，并利用它们同时捕获全局和局部相似性。实验在多个真实数据集上显示，TransGNN 显著提升了现有 GNN 模型在节点分类等任务中的性能。",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.01384v1",
      "published_date": "2024-01-01 13:53:50 UTC",
      "updated_date": "2024-01-01 13:53:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:10:47.085842"
    },
    {
      "arxiv_id": "2401.00756v1",
      "title": "MPRE: Multi-perspective Patient Representation Extractor for Disease Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Ziyue Yu",
        "Jiayi Wang",
        "Wuman Luo",
        "Rita Tse",
        "Giovanni Pau"
      ],
      "abstract": "Patient representation learning based on electronic health records (EHR) is a\ncritical task for disease prediction. This task aims to effectively extract\nuseful information on dynamic features. Although various existing works have\nachieved remarkable progress, the model performance can be further improved by\nfully extracting the trends, variations, and the correlation between the trends\nand variations in dynamic features. In addition, sparse visit records limit the\nperformance of deep learning models. To address these issues, we propose the\nMulti-perspective Patient Representation Extractor (MPRE) for disease\nprediction. Specifically, we propose Frequency Transformation Module (FTM) to\nextract the trend and variation information of dynamic features in the\ntime-frequency domain, which can enhance the feature representation. In the 2D\nMulti-Extraction Network (2D MEN), we form the 2D temporal tensor based on\ntrend and variation. Then, the correlations between trend and variation are\ncaptured by the proposed dilated operation. Moreover, we propose the\nFirst-Order Difference Attention Mechanism (FODAM) to calculate the\ncontributions of differences in adjacent variations to the disease diagnosis\nadaptively. To evaluate the performance of MPRE and baseline methods, we\nconduct extensive experiments on two real-world public datasets. The experiment\nresults show that MPRE outperforms state-of-the-art baseline methods in terms\nof AUROC and AUPRC.",
      "tldr_zh": "本研究针对基于电子健康记录 (EHR) 的患者表示学习问题，提出了一种多视角患者表示提取器 (MPRE)，旨在更全面地提取动态特征的趋势、变化及其相关性，以提升疾病预测性能。MPRE 包括 Frequency Transformation Module (FTM) 用于在时频域提取趋势和变化信息、2D Multi-Extraction Network (2D MEN) 通过 dilated operation 捕获趋势与变化的相关性，以及 First-Order Difference Attention Mechanism (FODAM) 来自适应评估相邻变化对诊断的贡献。在两个真实公共数据集上的实验表明，MPRE 在 AUROC 和 AUPRC 指标上优于现有最先进方法，证明了其有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by ICDM 2023",
      "pdf_url": "http://arxiv.org/pdf/2401.00756v1",
      "published_date": "2024-01-01 13:52:05 UTC",
      "updated_date": "2024-01-01 13:52:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:10:59.655807"
    },
    {
      "arxiv_id": "2401.00741v3",
      "title": "ToolEyes: Fine-Grained Evaluation for Tool Learning Capabilities of Large Language Models in Real-world Scenarios",
      "title_zh": "翻译失败",
      "authors": [
        "Junjie Ye",
        "Guanyu Li",
        "Songyang Gao",
        "Caishuang Huang",
        "Yilong Wu",
        "Sixian Li",
        "Xiaoran Fan",
        "Shihan Dou",
        "Tao Ji",
        "Qi Zhang",
        "Tao Gui",
        "Xuanjing Huang"
      ],
      "abstract": "Existing evaluations of tool learning primarily focus on validating the\nalignment of selected tools for large language models (LLMs) with expected\noutcomes. However, these approaches rely on a limited set of scenarios where\nanswers can be pre-determined, diverging from genuine needs. Furthermore, a\nsole emphasis on outcomes disregards the complex capabilities required for LLMs\nto effectively use tools. To tackle this issue, we propose ToolEyes, a\nfine-grained system tailored for the evaluation of the LLMs' tool learning\ncapabilities in authentic scenarios. The system meticulously examines seven\nreal-world scenarios, analyzing five dimensions crucial to LLMs in tool\nlearning: format alignment, intent comprehension, behavior planning, tool\nselection, and answer organization. Additionally, ToolEyes incorporates a tool\nlibrary boasting approximately 600 tools, serving as an intermediary between\nLLMs and the physical world. Evaluations involving ten LLMs across three\ncategories reveal a preference for specific scenarios and limited cognitive\nabilities in tool learning. Intriguingly, expanding the model size even\nexacerbates the hindrance to tool learning. The code and data are available at\nhttps://github.com/Junjie-Ye/ToolEyes.",
      "tldr_zh": "本文提出ToolEyes，一种细粒度评估系统，用于评估大型语言模型(LLMs)在真实场景中的工具学习能力，以弥补现有评估方法局限于预定答案和忽略复杂能力的不足。ToolEyes考察七个真实世界场景，分析五个关键维度：格式对齐、意图理解、行为规划、工具选择和答案组织，并整合约600个工具的库作为LLMs与物理世界的接口。实验结果显示，十个跨三类LLMs表现出对特定场景的偏好，且工具学习认知能力有限；有趣的是，模型规模增大反而会加剧这一阻碍。代码和数据可从https://github.com/Junjie-Ye/ToolEyes获取。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by COLING 2025 conference",
      "pdf_url": "http://arxiv.org/pdf/2401.00741v3",
      "published_date": "2024-01-01 12:49:36 UTC",
      "updated_date": "2024-12-05 07:05:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:11:12.764885"
    },
    {
      "arxiv_id": "2401.00739v1",
      "title": "DiffMorph: Text-less Image Morphing with Diffusion Models",
      "title_zh": "DiffMorph：基于扩散模型的无文本图像变形",
      "authors": [
        "Shounak Chatterjee"
      ],
      "abstract": "Text-conditioned image generation models are a prevalent use of AI image\nsynthesis, yet intuitively controlling output guided by an artist remains\nchallenging. Current methods require multiple images and textual prompts for\neach object to specify them as concepts to generate a single customized image.\n  On the other hand, our work, \\verb|DiffMorph|, introduces a novel approach\nthat synthesizes images that mix concepts without the use of textual prompts.\nOur work integrates a sketch-to-image module to incorporate user sketches as\ninput. \\verb|DiffMorph| takes an initial image with conditioning artist-drawn\nsketches to generate a morphed image.\n  We employ a pre-trained text-to-image diffusion model and fine-tune it to\nreconstruct each image faithfully. We seamlessly merge images and concepts from\nsketches into a cohesive composition. The image generation capability of our\nwork is demonstrated through our results and a comparison of these with\nprompt-based image generation.",
      "tldr_zh": "该论文提出DiffMorph，一种无需文本提示的图像变形方法，利用Diffusion Models合成混合概念的图像。DiffMorph整合sketch-to-image模块，允许用户通过初始图像和艺术家绘制的草图作为输入，生成忠实重建的变形图像。研究基于预训练的text-to-image扩散模型进行微调，并通过结果比较证明其在图像生成能力上优于基于提示的方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.00739v1",
      "published_date": "2024-01-01 12:42:32 UTC",
      "updated_date": "2024-01-01 12:42:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:11:22.996124"
    },
    {
      "arxiv_id": "2401.00737v1",
      "title": "Searching, fast and slow, through product catalogs",
      "title_zh": "翻译失败",
      "authors": [
        "Dayananda Ubrangala",
        "Juhi Sharma",
        "Sharath Kumar Rangappa",
        "Kiran R",
        "Ravi Prasad Kondapalli",
        "Laurent Boué"
      ],
      "abstract": "String matching algorithms in the presence of abbreviations, such as in Stock\nKeeping Unit (SKU) product catalogs, remains a relatively unexplored topic. In\nthis paper, we present a unified architecture for SKU search that provides both\na real-time suggestion system (based on a Trie data structure) as well as a\nlower latency search system (making use of character level TF-IDF in\ncombination with language model vector embeddings) where users initiate the\nsearch process explicitly. We carry out ablation studies that justify designing\na complex search system composed of multiple components to address the delicate\ntrade-off between speed and accuracy. Using SKU search in the Dynamics CRM as\nan example, we show how our system vastly outperforms, in all aspects, the\nresults provided by the default search engine. Finally, we show how SKU\ndescriptions may be enhanced via generative text models (using gpt-3.5-turbo)\nso that the consumers of the search results may get more context and a\ngenerally better experience when presented with the results of their SKU\nsearch.",
      "tldr_zh": "本文提出了一种统一的架构，用于处理缩写环境下如 Stock Keeping Unit (SKU) 产品目录的字符串匹配问题。该架构结合了基于 Trie 数据结构的实时建议系统，以及使用字符级 TF-IDF 与语言模型向量嵌入的低延迟搜索系统，通过多组件设计平衡速度与准确性。研究通过消融实验证明了这种复杂系统的必要性，并在 Dynamics CRM 的 SKU 搜索中显著优于默认搜索引擎。最终，该系统利用生成文本模型如 gpt-3.5-turbo 增强 SKU 描述，提供更丰富的上下文并提升用户体验。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG",
        "cs.SE"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.00737v1",
      "published_date": "2024-01-01 12:30:46 UTC",
      "updated_date": "2024-01-01 12:30:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:11:36.577415"
    },
    {
      "arxiv_id": "2401.00736v3",
      "title": "Diffusion Models, Image Super-Resolution And Everything: A Survey",
      "title_zh": "扩散模型、图像超分辨率以及一切：一个综述",
      "authors": [
        "Brian B. Moser",
        "Arundhati S. Shanbhag",
        "Federico Raue",
        "Stanislav Frolov",
        "Sebastian Palacio",
        "Andreas Dengel"
      ],
      "abstract": "Diffusion Models (DMs) have disrupted the image Super-Resolution (SR) field\nand further closed the gap between image quality and human perceptual\npreferences. They are easy to train and can produce very high-quality samples\nthat exceed the realism of those produced by previous generative methods.\nDespite their promising results, they also come with new challenges that need\nfurther research: high computational demands, comparability, lack of\nexplainability, color shifts, and more. Unfortunately, entry into this field is\noverwhelming because of the abundance of publications. To address this, we\nprovide a unified recount of the theoretical foundations underlying DMs applied\nto image SR and offer a detailed analysis that underscores the unique\ncharacteristics and methodologies within this domain, distinct from broader\nexisting reviews in the field. This survey articulates a cohesive understanding\nof DM principles and explores current research avenues, including alternative\ninput domains, conditioning techniques, guidance mechanisms, corruption spaces,\nand zero-shot learning approaches. By offering a detailed examination of the\nevolution and current trends in image SR through the lens of DMs, this survey\nsheds light on the existing challenges and charts potential future directions,\naiming to inspire further innovation in this rapidly advancing area.",
      "tldr_zh": "这篇调查论文回顾了Diffusion Models (DMs)在Image Super-Resolution (SR)领域的应用，强调DMs易于训练且能生成超越以往生成方法的真实高质图像，从而缩小了图像质量与人类感知偏好的差距。论文分析了DMs面临的挑战，包括高计算需求、可比性不足、缺乏解释性和颜色偏移等问题，并提供了一个统一的理论基础回顾。论文进一步探讨了当前研究方向，如替代输入域、条件技术、引导机制、腐败空间和零样本学习方法，并指出未来挑战与创新路径，以推动该领域的快速发展。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.00736v3",
      "published_date": "2024-01-01 12:25:57 UTC",
      "updated_date": "2024-06-23 19:32:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:11:48.062852"
    },
    {
      "arxiv_id": "2401.00719v1",
      "title": "Depth Map Denoising Network and Lightweight Fusion Network for Enhanced 3D Face Recognition",
      "title_zh": "深度图去噪网络和",
      "authors": [
        "Ruizhuo Xu",
        "Ke Wang",
        "Chao Deng",
        "Mei Wang",
        "Xi Chen",
        "Wenhui Huang",
        "Junlan Feng",
        "Weihong Deng"
      ],
      "abstract": "With the increasing availability of consumer depth sensors, 3D face\nrecognition (FR) has attracted more and more attention. However, the data\nacquired by these sensors are often coarse and noisy, making them impractical\nto use directly. In this paper, we introduce an innovative Depth map denoising\nnetwork (DMDNet) based on the Denoising Implicit Image Function (DIIF) to\nreduce noise and enhance the quality of facial depth images for low-quality 3D\nFR. After generating clean depth faces using DMDNet, we further design a\npowerful recognition network called Lightweight Depth and Normal Fusion network\n(LDNFNet), which incorporates a multi-branch fusion block to learn unique and\ncomplementary features between different modalities such as depth and normal\nimages. Comprehensive experiments conducted on four distinct low-quality\ndatabases demonstrate the effectiveness and robustness of our proposed methods.\nFurthermore, when combining DMDNet and LDNFNet, we achieve state-of-the-art\nresults on the Lock3DFace database.",
      "tldr_zh": "本研究针对消费级深度传感器获取的粗糙噪声数据问题，提出了一种基于 Denoising Implicit Image Function (DIIF) 的 Depth map denoising network (DMDNet)，用于减少深度图像噪声并提升低质量 3D Face Recognition 的图像质量。接着，设计了 Lightweight Depth and Normal Fusion network (LDNFNet)，该网络通过多分支融合块学习深度和法线图像等不同模态的独特互补特征，从而提高识别性能。在四个低质量数据库上的全面实验证明了这些方法的有效性和鲁棒性，最终结合 DMDNet 和 LDNFNet 在 Lock3DFace 数据库上达到了 state-of-the-art 结果。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by Pattern Recognition",
      "pdf_url": "http://arxiv.org/pdf/2401.00719v1",
      "published_date": "2024-01-01 10:46:42 UTC",
      "updated_date": "2024-01-01 10:46:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:11:59.922672"
    },
    {
      "arxiv_id": "2401.01383v2",
      "title": "Predicting Infant Brain Connectivity with Federated Multi-Trajectory GNNs using Scarce Data",
      "title_zh": "利用联邦多轨迹 GNNs",
      "authors": [
        "Michalis Pistos",
        "Gang Li",
        "Weili Lin",
        "Dinggang Shen",
        "Islem Rekik"
      ],
      "abstract": "The understanding of the convoluted evolution of infant brain networks during\nthe first postnatal year is pivotal for identifying the dynamics of early brain\nconnectivity development. Existing deep learning solutions suffer from three\nmajor limitations. First, they cannot generalize to multi-trajectory prediction\ntasks, where each graph trajectory corresponds to a particular imaging modality\nor connectivity type (e.g., T1-w MRI). Second, existing models require\nextensive training datasets to achieve satisfactory performance which are often\nchallenging to obtain. Third, they do not efficiently utilize incomplete time\nseries data. To address these limitations, we introduce FedGmTE-Net++, a\nfederated graph-based multi-trajectory evolution network. Using the power of\nfederation, we aggregate local learnings among diverse hospitals with limited\ndatasets. As a result, we enhance the performance of each hospital's local\ngenerative model, while preserving data privacy. The three key innovations of\nFedGmTE-Net++ are: (i) presenting the first federated learning framework\nspecifically designed for brain multi-trajectory evolution prediction in a\ndata-scarce environment, (ii) incorporating an auxiliary regularizer in the\nlocal objective function to exploit all the longitudinal brain connectivity\nwithin the evolution trajectory and maximize data utilization, (iii)\nintroducing a two-step imputation process, comprising a preliminary KNN-based\nprecompletion followed by an imputation refinement step that employs regressors\nto improve similarity scores and refine imputations. Our comprehensive\nexperimental results showed the outperformance of FedGmTE-Net++ in brain\nmulti-trajectory prediction from a single baseline graph in comparison with\nbenchmark methods.",
      "tldr_zh": "本文提出 FedGmTE-Net++，一个基于联邦学习的图神经网络 (GNNs) 框架，用于在数据稀缺环境下预测婴儿大脑连接的多轨迹演化，从而解决现有模型的泛化性差、数据需求大和处理不完整时间序列数据的问题。关键创新包括：设计首个专为脑多轨迹预测的联邦学习框架、加入辅助正则化器以最大化纵向脑连接利用、以及引入两步插值过程（结合 KNN 和回归器）来提升数据处理效率。同时，通过聚合不同医院的本地学习，FedGmTE-Net++ 在实验中显著优于基准方法，在从单一基线图预测脑多轨迹方面表现出色。",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "q-bio.NC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.01383v2",
      "published_date": "2024-01-01 10:20:01 UTC",
      "updated_date": "2024-01-08 09:46:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:12:12.330772"
    },
    {
      "arxiv_id": "2401.00711v1",
      "title": "Text2Avatar: Text to 3D Human Avatar Generation with Codebook-Driven Body Controllable Attribute",
      "title_zh": "翻译失败",
      "authors": [
        "Chaoqun Gong",
        "Yuqin Dai",
        "Ronghui Li",
        "Achun Bao",
        "Jun Li",
        "Jian Yang",
        "Yachao Zhang",
        "Xiu Li"
      ],
      "abstract": "Generating 3D human models directly from text helps reduce the cost and time\nof character modeling. However, achieving multi-attribute controllable and\nrealistic 3D human avatar generation is still challenging due to feature\ncoupling and the scarcity of realistic 3D human avatar datasets. To address\nthese issues, we propose Text2Avatar, which can generate realistic-style 3D\navatars based on the coupled text prompts. Text2Avatar leverages a discrete\ncodebook as an intermediate feature to establish a connection between text and\navatars, enabling the disentanglement of features. Furthermore, to alleviate\nthe scarcity of realistic style 3D human avatar data, we utilize a pre-trained\nunconditional 3D human avatar generation model to obtain a large amount of 3D\navatar pseudo data, which allows Text2Avatar to achieve realistic style\ngeneration. Experimental results demonstrate that our method can generate\nrealistic 3D avatars from coupled textual data, which is challenging for other\nexisting methods in this field.",
      "tldr_zh": "本文提出Text2Avatar框架，用于从文本提示生成多属性可控的真实3D human avatar，解决特征耦合和真实3D human avatar数据集稀缺的问题。Text2Avatar利用离散codebook作为中间特征，实现文本与avatars之间的特征解耦，并通过预训练的无条件3D human avatar生成模型创建大量伪数据来提升生成质量。实验结果表明，该方法能有效处理耦合文本数据，生成真实风格的3D avatars，在该领域表现出色。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.00711v1",
      "published_date": "2024-01-01 09:39:57 UTC",
      "updated_date": "2024-01-01 09:39:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:12:23.387797"
    },
    {
      "arxiv_id": "2401.00700v1",
      "title": "An attempt to generate new bridge types from latent space of generative adversarial network",
      "title_zh": "从生成对抗网络的潜在空间生成新桥型的尝试",
      "authors": [
        "Hongjun Zhang"
      ],
      "abstract": "Try to generate new bridge types using generative artificial intelligence\ntechnology. Symmetric structured image dataset of three-span beam bridge, arch\nbridge, cable-stayed bridge and suspension bridge are used . Based on Python\nprogramming language, TensorFlow and Keras deep learning platform framework ,\nas well as Wasserstein loss function and Lipschitz constraints, generative\nadversarial network is constructed and trained. From the obtained low\ndimensional bridge-type latent space sampling, new bridge types with asymmetric\nstructures can be generated. Generative adversarial network can create new\nbridge types by organically combining different structural components on the\nbasis of human original bridge types. It has a certain degree of human original\nability. Generative artificial intelligence technology can open up imagination\nspace and inspire humanity.",
      "tldr_zh": "这篇论文尝试使用生成对抗网络(GAN)从潜在空间生成新的桥梁类型，以扩展传统桥梁设计的想象空间。研究者利用对称结构图像数据集，包括三跨梁桥、拱桥、斜拉桥和悬索桥，通过Python、TensorFlow和Keras框架构建并训练GAN，采用Wasserstein损失函数和Lipschitz约束进行优化。从低维潜在空间采样，成功生成了具有不对称结构的新桥梁类型，展示了GAN将不同结构组件有机结合的原创能力，并强调生成式人工智能技术在激发人类创新方面的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2401.00700v1",
      "published_date": "2024-01-01 08:46:29 UTC",
      "updated_date": "2024-01-01 08:46:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:12:36.127161"
    },
    {
      "arxiv_id": "2401.00698v1",
      "title": "Large Language Models aren't all that you need",
      "title_zh": "大型语言模型并不是你需要的一切",
      "authors": [
        "Kiran Voderhobli Holla",
        "Chaithanya Kumar",
        "Aryan Singh"
      ],
      "abstract": "This paper describes the architecture and systems built towards solving the\nSemEval 2023 Task 2: MultiCoNER II (Multilingual Complex Named Entity\nRecognition) [1]. We evaluate two approaches (a) a traditional Conditional\nRandom Fields model and (b) a Large Language Model (LLM) fine-tuned with a\ncustomized head and compare the two approaches. The novel ideas explored are:\n1) Decaying auxiliary loss (with residual) - where we train the model on an\nauxiliary task of Coarse-Grained NER and include this task as a part of the\nloss function 2) Triplet token blending - where we explore ways of blending the\nembeddings of neighboring tokens in the final NER layer prior to prediction 3)\nTask-optimal heads - where we explore a variety of custom heads and learning\nrates for the final layer of the LLM. We also explore multiple LLMs including\nGPT-3 and experiment with a variety of dropout and other hyperparameter\nsettings before arriving at our final model which achieves micro & macro f1 of\n0.85/0.84 (on dev) and 0.67/0.61 on the test data . We show that while\npre-trained LLMs, by themselves, bring about a large improvement in scores as\ncompared to traditional models, we also demonstrate that tangible improvements\nto the Macro-F1 score can be made by augmenting the LLM with additional\nfeature/loss/model engineering techniques described above.",
      "tldr_zh": "这篇论文探讨了大型语言模型 (LLM) 在 SemEval 2023 Task 2: MultiCoNER II（多语言复杂命名实体识别）任务中的局限性，通过比较传统的条件随机场 (CRF) 模型与微调 LLM 的方法。\n他们引入了新颖技术，包括衰减辅助损失 (Decaying auxiliary loss with residual) 用于粗粒度 NER 辅助训练、三元组令牌混合 (Triplet token blending) 来混合相邻令牌嵌入，以及任务最优头 (Task-optimal heads) 来优化最终层和学习率。\n实验结果显示，最终模型在开发集上达到微观和宏观 F1 分数为 0.85/0.84，在测试集上为 0.67/0.61，证明预训练 LLM 本身已优于传统模型，但通过额外特征、损失和模型工程技术可进一步提升宏观 F1 性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.00698v1",
      "published_date": "2024-01-01 08:32:50 UTC",
      "updated_date": "2024-01-01 08:32:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:12:50.916563"
    },
    {
      "arxiv_id": "2401.00689v1",
      "title": "Large language model for Bible sentiment analysis: Sermon on the Mount",
      "title_zh": "翻译失败",
      "authors": [
        "Mahek Vora",
        "Tom Blau",
        "Vansh Kachhwal",
        "Ashu M. G. Solo",
        "Rohitash Chandra"
      ],
      "abstract": "The revolution of natural language processing via large language models has\nmotivated its use in multidisciplinary areas that include social sciences and\nhumanities and more specifically, comparative religion. Sentiment analysis\nprovides a mechanism to study the emotions expressed in text. Recently,\nsentiment analysis has been used to study and compare translations of the\nBhagavad Gita, which is a fundamental and sacred Hindu text. In this study, we\nuse sentiment analysis for studying selected chapters of the Bible. These\nchapters are known as the Sermon on the Mount. We utilize a pre-trained\nlanguage model for sentiment analysis by reviewing five translations of the\nSermon on the Mount, which include the King James version, the New\nInternational Version, the New Revised Standard Version, the Lamsa Version, and\nthe Basic English Version. We provide a chapter-by-chapter and verse-by-verse\ncomparison using sentiment and semantic analysis and review the major\nsentiments expressed. Our results highlight the varying sentiments across the\nchapters and verses. We found that the vocabulary of the respective\ntranslations is significantly different. We detected different levels of\nhumour, optimism, and empathy in the respective chapters that were used by\nJesus to deliver his message.",
      "tldr_zh": "这篇论文利用大型语言模型（Large Language Model）对圣经《山上宝训》（Sermon on the Mount）的五个翻译版本（包括 King James version、New International Version 等）进行情感分析（Sentiment Analysis），旨在比较不同翻译中的情感和语义差异。研究方法包括章节和诗句级别的分析，审视了词汇变异以及表达的幽默、乐观和移情水平。结果显示，这些翻译在情感表达上存在显著差异，突出了耶稣信息传递方式的多面性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.00689v1",
      "published_date": "2024-01-01 07:35:29 UTC",
      "updated_date": "2024-01-01 07:35:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:13:00.017286"
    },
    {
      "arxiv_id": "2401.00685v2",
      "title": "Communication-Efficient Federated Learning for LEO Satellite Networks Integrated with HAPs Using Hybrid NOMA-OFDM",
      "title_zh": "翻译失败",
      "authors": [
        "Mohamed Elmahallawy",
        "Tie Luo",
        "Khaled Ramadan"
      ],
      "abstract": "Space AI has become increasingly important and sometimes even necessary for\ngovernment, businesses, and society. An active research topic under this\nmission is integrating federated learning (FL) with satellite communications\n(SatCom) so that numerous low Earth orbit (LEO) satellites can collaboratively\ntrain a machine learning model. However, the special communication environment\nof SatCom leads to a very slow FL training process up to days and weeks. This\npaper proposes NomaFedHAP, a novel FL-SatCom approach tailored to LEO\nsatellites, that (1) utilizes high-altitude platforms (HAPs) as distributed\nparameter servers (PS) to enhance satellite visibility, and (2) introduces\nnon-orthogonal multiple access (NOMA) into LEO to enable fast and\nbandwidth-efficient model transmissions. In addition, NomaFedHAP includes (3) a\nnew communication topology that exploits HAPs to bridge satellites among\ndifferent orbits to mitigate the Doppler shift, and (4) a new FL model\naggregation scheme that optimally balances models between different orbits and\nshells. Moreover, we (5) derive a closed-form expression of the outage\nprobability for satellites in near and far shells, as well as for the entire\nsystem. Our extensive simulations have validated the mathematical analysis and\ndemonstrated the superior performance of NomaFedHAP in achieving fast and\nefficient FL model convergence with high accuracy as compared to the\nstate-of-the-art.",
      "tldr_zh": "该论文提出了一种通信高效的联邦学习（Federated Learning, FL）方法，名为 NomaFedHAP，针对低地球轨道（LEO）卫星网络与高空平台（HAPs）的整合，使用混合非正交多址接入（NOMA）和正交频分复用（OFDM）技术，以解决卫星通信（SatCom）环境中 FL 训练缓慢的问题。关键创新包括利用 HAPs 作为分布式参数服务器提升卫星可见性、引入 NOMA 实现快速带宽高效的模型传输、设计新通信拓扑缓解 Doppler shift，以及优化 FL 模型聚合方案以平衡不同轨道和壳层。实验模拟验证了该方法的数学分析，并证明 NomaFedHAP 在 FL 模型收敛速度、效率和准确性方面显著优于现有基准。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.00685v2",
      "published_date": "2024-01-01 07:07:27 UTC",
      "updated_date": "2024-02-16 09:21:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:13:12.775780"
    },
    {
      "arxiv_id": "2401.00916v1",
      "title": "Data Assimilation in Chaotic Systems Using Deep Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Mohamad Abed El Rahman Hammoud",
        "Naila Raboudi",
        "Edriss S. Titi",
        "Omar Knio",
        "Ibrahim Hoteit"
      ],
      "abstract": "Data assimilation (DA) plays a pivotal role in diverse applications, ranging\nfrom climate predictions and weather forecasts to trajectory planning for\nautonomous vehicles. A prime example is the widely used ensemble Kalman filter\n(EnKF), which relies on linear updates to minimize variance among the ensemble\nof forecast states. Recent advancements have seen the emergence of deep\nlearning approaches in this domain, primarily within a supervised learning\nframework. However, the adaptability of such models to untrained scenarios\nremains a challenge. In this study, we introduce a novel DA strategy that\nutilizes reinforcement learning (RL) to apply state corrections using full or\npartial observations of the state variables. Our investigation focuses on\ndemonstrating this approach to the chaotic Lorenz '63 system, where the agent's\nobjective is to minimize the root-mean-squared error between the observations\nand corresponding forecast states. Consequently, the agent develops a\ncorrection strategy, enhancing model forecasts based on available system state\nobservations. Our strategy employs a stochastic action policy, enabling a Monte\nCarlo-based DA framework that relies on randomly sampling the policy to\ngenerate an ensemble of assimilated realizations. Results demonstrate that the\ndeveloped RL algorithm performs favorably when compared to the EnKF.\nAdditionally, we illustrate the agent's capability to assimilate non-Gaussian\ndata, addressing a significant limitation of the EnKF.",
      "tldr_zh": "本研究提出了一种新型数据同化（DA）策略，使用深度强化学习（RL）来对混沌系统（如 Lorenz '63 系统）的状态进行修正，目标是最小化观察与预测状态之间的根均方误差（RMSE）。该方法通过 RL 代理基于全或部分观察开发修正策略，并采用随机动作策略构建 Monte Carlo 基于的 DA 框架，从而生成同化集合。实验结果显示，该 RL 算法在性能上优于传统 ensemble Kalman filter (EnKF)，并能有效处理非高斯数据，解决了 EnKF 的关键局限性。",
      "categories": [
        "math.DS",
        "cs.AI",
        "cs.LG",
        "physics.ao-ph"
      ],
      "primary_category": "math.DS",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.00916v1",
      "published_date": "2024-01-01 06:53:36 UTC",
      "updated_date": "2024-01-01 06:53:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:13:24.188112"
    },
    {
      "arxiv_id": "2401.02981v2",
      "title": "Fine-tuning and Utilization Methods of Domain-specific LLMs",
      "title_zh": "领域特定大语言模型的微调与利用方法",
      "authors": [
        "Cheonsu Jeong"
      ],
      "abstract": "Recent releases of pre-trained Large Language Models (LLMs) have gained\nconsiderable traction, yet research on fine-tuning and employing\ndomain-specific LLMs remains scarce. This study investigates approaches for\nfine-tuning and leveraging domain-specific LLMs, highlighting trends in LLMs,\nfoundational models, and methods for domain-specific pre-training. Focusing on\nthe financial sector, it details dataset selection, preprocessing, model\nchoice, and considerations crucial for LLM fine-tuning in finance. Addressing\nthe unique characteristics of financial data, the study explores the\nconstruction of domain-specific vocabularies and considerations for security\nand regulatory compliance. In the practical application of LLM fine-tuning, the\nstudy outlines the procedure and implementation for generating domain-specific\nLLMs in finance. Various financial cases, including stock price prediction,\nsentiment analysis of financial news, automated document processing, research,\ninformation extraction, and customer service enhancement, are exemplified. The\nstudy explores the potential of LLMs in the financial domain, identifies\nlimitations, and proposes directions for improvement, contributing valuable\ninsights for future research. Ultimately, it advances natural language\nprocessing technology in business, suggesting proactive LLM utilization in\nfinancial services across industries.",
      "tldr_zh": "本研究探讨了针对特定领域的LLM（Large Language Models）的微调和利用方法，强调了LLM趋势、基础模型以及领域特定预训练的策略。聚焦于金融领域，该论文详细阐述了数据集选择、预处理、模型选择、构建领域词汇表以及安全和合规考虑，以应对金融数据的独特特性。研究通过实际案例如股票价格预测、情感分析和自动化文档处理，展示了LLM在金融服务中的应用潜力，同时识别了现有限制并提出改进方向，为NLP在商业领域的推进提供宝贵见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.02981v2",
      "published_date": "2024-01-01 06:22:04 UTC",
      "updated_date": "2024-01-24 18:16:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:13:37.980295"
    },
    {
      "arxiv_id": "2401.00663v1",
      "title": "1st Place Solution for 5th LSVOS Challenge: Referring Video Object Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Zhuoyan Luo",
        "Yicheng Xiao",
        "Yong Liu",
        "Yitong Wang",
        "Yansong Tang",
        "Xiu Li",
        "Yujiu Yang"
      ],
      "abstract": "The recent transformer-based models have dominated the Referring Video Object\nSegmentation (RVOS) task due to the superior performance. Most prior works\nadopt unified DETR framework to generate segmentation masks in\nquery-to-instance manner. In this work, we integrate strengths of that leading\nRVOS models to build up an effective paradigm. We first obtain binary mask\nsequences from the RVOS models. To improve the consistency and quality of\nmasks, we propose Two-Stage Multi-Model Fusion strategy. Each stage rationally\nensembles RVOS models based on framework design as well as training strategy,\nand leverages different video object segmentation (VOS) models to enhance mask\ncoherence by object propagation mechanism. Our method achieves 75.7% J&F on\nRef-Youtube-VOS validation set and 70% J&F on test set, which ranks 1st place\non 5th Large-scale Video Object Segmentation Challenge (ICCV 2023) track 3.\nCode is available at https://github.com/RobertLuo1/iccv2023_RVOS_Challenge.",
      "tldr_zh": "该论文提出了一种针对 Referring Video Object Segmentation (RVOS) 任务的解决方案，通过整合 transformer-based 模型的优势，构建了一个高效的范式。研究团队首先从 RVOS 模型获取二进制掩码序列，然后采用 Two-Stage Multi-Model Fusion 策略：在每个阶段基于框架设计和训练策略融合模型，并利用视频对象分割 (VOS) 模型的物体传播机制提升掩码的一致性和质量。该方法在 Ref-Youtube-VOS 验证集上达到 75.7% J&F，在测试集上达到 70% J&F，最终在 5th Large-scale Video Object Segmentation Challenge (ICCV 2023) 的 track 3 中获得第一名。代码已在 GitHub 上开源。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.00663v1",
      "published_date": "2024-01-01 04:24:48 UTC",
      "updated_date": "2024-01-01 04:24:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:13:50.148756"
    },
    {
      "arxiv_id": "2401.10262v1",
      "title": "Null Space Properties of Neural Networks with Applications to Image Steganography",
      "title_zh": "神经网络的零空间属性及其在图像隐写中的应用",
      "authors": [
        "Xiang Li",
        "Kevin M. Short"
      ],
      "abstract": "This paper explores the null space properties of neural networks. We extend\nthe null space definition from linear to nonlinear maps and discuss the\npresence of a null space in neural networks. The null space of a given neural\nnetwork can tell us the part of the input data that makes no contribution to\nthe final prediction so that we can use it to trick the neural network. This\nreveals an inherent weakness in neural networks that can be exploited. One\napplication described here leads to a method of image steganography. Through\nexperiments on image datasets such as MNIST, we show that we can use null space\ncomponents to force the neural network to choose a selected hidden image class,\neven though the overall image can be made to look like a completely different\nimage. We conclude by showing comparisons between what a human viewer would\nsee, and the part of the image that the neural network is actually using to\nmake predictions and, hence, show that what the neural network ``sees'' is\ncompletely different than what we would expect.",
      "tldr_zh": "这篇论文扩展了神经网络的零空间（null space）概念，从线性映射到非线性映射，探讨了其在神经网络中的存在及其含义，即零空间允许输入数据中某些部分不影响最终预测，从而可用于欺骗模型。研究揭示了神经网络的固有弱点，并将其应用于图像隐写术（image steganography），通过在 MNIST 数据集上的实验，展示了如何利用零空间组件强制神经网络选择指定的隐藏图像类别，同时使图像外观完全不同。最终，论文比较了人类视觉与神经网络的预测机制，证明神经网络“看到”的内容与人类预期截然不同，这突显了模型的潜在风险。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CR",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.10262v1",
      "published_date": "2024-01-01 03:32:28 UTC",
      "updated_date": "2024-01-01 03:32:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:14:03.940929"
    },
    {
      "arxiv_id": "2401.00631v2",
      "title": "Edge AI as a Service with Coordinated Deep Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Alireza Maleki",
        "Hamed Shah-Mansouri",
        "Babak H. Khalaj"
      ],
      "abstract": "As artificial intelligence (AI) applications continue to expand in\nnext-generation networks, there is a growing need for deep neural network (DNN)\nmodels. Although DNN models deployed at the edge are promising for providing AI\nas a service with low latency, their cooperation is yet to be explored. In this\npaper, we consider that DNN service providers share their computing resources\nas well as their models' parameters and allow other DNNs to offload their\ncomputations without mirroring. We propose a novel algorithm called coordinated\nDNNs on edge (\\textbf{CoDE}) that facilitates coordination among DNN services\nby establishing new inference paths. CoDE aims to find the optimal path, which\nis the path with the highest possible reward, by creating multi-task DNNs from\nindividual models. The reward reflects the inference throughput and model\naccuracy. With CoDE, DNN models can make new paths for inference by using their\nown or other models' parameters. We then evaluate the performance of CoDE\nthrough numerical experiments. The results demonstrate a $40\\%$ increase in the\ninference throughput while degrading the average accuracy by only $2.3\\%$.\nExperiments show that CoDE enhances the inference throughput and, achieves\nhigher precision compared to a state-of-the-art existing method.",
      "tldr_zh": "该论文探讨了在下一代网络中部署深度神经网络 (DNNs) 以提供低延迟的 Edge AI as a Service 的需求，但强调了DNN模型之间合作的需求。作者提出了一种名为 CoDE (Coordinated DNNs on Edge) 的新算法，该算法允许DNN服务提供者共享计算资源和模型参数，通过建立新的推理路径并创建多任务DNN来优化推理吞吐量和模型准确性。实验结果显示，CoDE 使推理吞吐量提升了40%，平均准确性仅下降2.3%，并在精度上优于现有方法。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.00631v2",
      "published_date": "2024-01-01 01:54:53 UTC",
      "updated_date": "2024-08-21 17:47:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:14:14.442645"
    },
    {
      "arxiv_id": "2401.04122v3",
      "title": "From Prompt Engineering to Prompt Science With Human in the Loop",
      "title_zh": "翻译失败",
      "authors": [
        "Chirag Shah"
      ],
      "abstract": "As LLMs make their way into many aspects of our lives, one place that\nwarrants increased scrutiny with LLM usage is scientific research. Using LLMs\nfor generating or analyzing data for research purposes is gaining popularity.\nBut when such application is marred with ad-hoc decisions and engineering\nsolutions, we need to be concerned about how it may affect that research, its\nfindings, or any future works based on that research. We need a more scientific\napproach to using LLMs in our research. While there are several active efforts\nto support more systematic construction of prompts, they are often focused more\non achieving desirable outcomes rather than producing replicable and\ngeneralizable knowledge with sufficient transparency, objectivity, or rigor.\nThis article presents a new methodology inspired by codebook construction\nthrough qualitative methods to address that. Using humans in the loop and a\nmulti-phase verification processes, this methodology lays a foundation for more\nsystematic, objective, and trustworthy way of applying LLMs for analyzing data.\nSpecifically, we show how a set of researchers can work through a rigorous\nprocess of labeling, deliberating, and documenting to remove subjectivity and\nbring transparency and replicability to prompt generation process. A set of\nexperiments are presented to show how this methodology can be put in practice.",
      "tldr_zh": "这篇论文探讨了在科学研究中使用大型语言模型（LLMs）的问题，指出当前的提示工程（Prompt Engineering）方法往往依赖临时决策，可能影响研究的可靠性、可重复性和客观性。\n作者提出一种新方法论，将提示工程转变为提示科学（Prompt Science），通过 Human in the Loop 的多阶段验证过程（如标记、审议和记录），受代码本构建启发，确保提示生成更系统化、透明和可信。\n该方法强调人类参与来减少主观性，并通过实验展示其在数据分析中的实际应用，提高了 LLMs 研究的整体严谨性。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.04122v3",
      "published_date": "2024-01-01 01:37:36 UTC",
      "updated_date": "2024-05-10 03:50:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T19:14:26.454732"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 35,
  "processed_papers_count": 35,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-16T19:14:48.098983"
}