{
  "date": "2024-10-19",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-10-19 的 arXiv 中文 TLDR 快报！\n\n今天的 arXiv 论文主要聚焦于 AI 模型优化（如 LLM 的偏见放大和强化学习框架）、医疗诊断应用（如癌症分类和图像重建）、以及科学模拟领域（如分子和材料建模）的创新，其中 LLM 在偏见处理和强化学习中的研究最为突出，Yoshua Bengio 等著名学者的作品令人印象深刻。\n\n下面，我将挑选并简要讨论部分关键论文，先优先聊那些重要、话题度高或涉及著名学者的文章（如强化学习和 LLM 相关），其他次要论文快速掠过。每个条目包括论文标题（中文 + 英文）和核心贡献。\n\n### 1. **偏见放大：大型语言模型作为日益偏见的媒体 (Bias Amplification: Large Language Models as Increasingly Biased Media)**  \n   这篇论文由 Ze Wang 等作者（包括知名学者）发布，探讨了 LLM 在使用合成数据时如何放大社会偏见。通过统计模拟和实验，证明偏见在无采样错误的情况下仍会加剧，并评估了缓解策略，揭示偏见放大与模型崩溃源于不同机制，为 LLM 公平性提供新见解。\n\n### 2. **动作抽象用于摊销采样 (Action abstractions for amortized sampling)**  \n   Yoshua Bengio 参与的这篇强化学习论文提出了一种将动作序列抽象为高阶动作的框架，通过迭代提取高回报轨迹来优化探索。关键发现是这种方法在复杂环境中提升了样本效率，并在合成和真实任务中表现出色，推动了强化学习在分层规划中的应用。\n\n### 3. **AutoFLUKA：基于大型语言模型的框架，用于自动化 FLUKA 中的蒙特卡罗模拟 (AutoFLUKA: A Large Language Model Based Framework for Automating Monte Carlo Simulations in FLUKA)**  \n   作者 Zavier Ndum Ndum 等开发了 AutoFLUKA，使用 LLM 和 AI 代理简化科学模拟工作流。论文的主要贡献是减少手动干预，提高模拟效率，并通过案例验证其在高能物理等领域的可扩展性，展示了 LLM 在科学计算中的潜力。\n\n### 4. **IntersectionZoo：用于基准多代理上下文强化学习的合作式生态驾驶 (IntersectionZoo: Eco-driving for Benchmarking Multi-Agent Contextual Reinforcement Learning)**  \n   这篇论文引入了一个基于真实交通场景的基准数据集，评估多代理强化学习在城市驾驶中的泛化能力。发现流行算法在处理部分可观察性和竞争目标时表现不佳，为多代理 RL 的实际应用提供了新基准和改进方向。\n\n### 5. **Medical-GAT：利用基于图形的残差网络在数据有限场景下进行癌症文献分类 (Medical-GAT: Cancer Document Classification Leveraging Graph-Based Residual Network for Scenarios with Limited Data)**  \n   作者 Elias Hossain 等提出 R-GAT 模型，通过图注意力机制捕获文档语义关系，在数据稀缺的癌症分类任务中实现高精度（F1 分数达 0.98）。这为医疗 AI 在小样本场景下的应用提供了实用框架，强调了图神经网络的优势。\n\n### 6. **LLM-HDR：桥接 LLM 感知与自监督，用于无配对 LDR 到 HDR 图像重建 (LLM-HDR: Bridging LLM-based Perception and Self-Supervision for Unpaired LDR-to-HDR Image Reconstruction)**  \n   这篇论文使用 LLM 和自监督方法处理图像动态范围重建，实现了高鲁棒性的无配对数据转换。贡献在于提升图像质量并减少配对数据需求，实验显示在基准数据集上显著改善重建效果。\n\n### 7. **PanDerm：临床皮肤科的多模态视觉基础模型 (PanDerm: A Multimodal Vision Foundation Model for Clinical Dermatology)**  \n   作者 Siyuan Yan 等开发了 PanDerm 模型，通过自监督学习处理多模态皮肤图像数据。论文发现该模型在癌症筛查和诊断任务中超越了临床医生，提供更准确的预测，并展示了多模态 AI 在医疗领域的潜力。\n\n其他论文，如 Chasing Random（指令选择策略的泛化失败）、BrainECHO（脑信号解码）和 Adversarial Training（对抗训练调查），也涉及 AI 优化，但相对次要，我仅快速提及：这些工作分别探讨了数据选择泛化问题、脑信号到文本的语义重建，以及对抗训练的全面综述，提供了一些实用见解，但未有突破性创新。\n\n总之，今天的论文强调了 AI 在实际应用中的鲁棒性和泛化挑战，LLM 和强化学习领域进展显著。如果你对特定主题感兴趣，建议查看上述优先论文。明天的快报见！",
  "papers": [
    {
      "arxiv_id": "2410.15234v2",
      "title": "Bias Amplification: Large Language Models as Increasingly Biased Media",
      "title_zh": "偏见放大：大语言模型作为越来越有偏见的媒体",
      "authors": [
        "Ze Wang",
        "Zekun Wu",
        "Jeremy Zhang",
        "Xin Guan",
        "Navya Jain",
        "Skylar Lu",
        "Saloni Gupta",
        "Adriano Koshiyama"
      ],
      "abstract": "Model collapse, a phenomenon where models degrade in performance due to\nindiscriminate use of synthetic data is well studied. However, its role in bias\namplification, the progressive reinforcement of preexisting social biases in\nLarge Language Models (LLMs) remains underexplored. In this paper, we formally\ndefine the conditions for bias amplification and demonstrate through\nstatistical simulations that bias can intensify even in the absence of sampling\nerrors, the primary driver of model collapse. Empirically, we investigate\npolitical bias amplification in GPT2 using a custom built benchmark for\nsentence continuation tasks. Our findings reveal a progressively increasing\nright-leaning bias. Furthermore, we evaluate three mitigation strategies,\nOverfitting, Preservation, and Accumulation, and show that bias amplification\npersists even when model collapse is mitigated. Finally, a mechanistic\ninterpretation identifies distinct sets of neurons responsible for model\ncollapse and bias amplification, suggesting they arise from different\nunderlying mechanisms.",
      "tldr_zh": "本文研究了大型语言模型 (LLMs) 中的 bias amplification 现象，即预存社会偏见在模型迭代过程中逐步强化，并将其与 model collapse 分离。作者通过统计模拟和实证实验（如在 GPT2 上使用自定义基准测试句子续写任务）证明，bias amplification 即使在 absence of sampling errors 的情况下也能加剧，导致右倾政治偏见 progressively increasing。评估了 Overfitting, Preservation 和 Accumulation 等缓解策略后，发现 bias amplification 持续存在，且通过神经元分析揭示了其与 model collapse 的不同底层机制，为理解和减轻 LLMs 偏见提供了新见解。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15234v2",
      "published_date": "2024-10-19 22:53:27 UTC",
      "updated_date": "2025-02-17 07:49:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:40:54.280010"
    },
    {
      "arxiv_id": "2410.15225v1",
      "title": "Chasing Random: Instruction Selection Strategies Fail to Generalize",
      "title_zh": "追逐随机：指令选择策略无法泛化",
      "authors": [
        "Harshita Diddee",
        "Daphne Ippolito"
      ],
      "abstract": "Prior work has shown that language models can be tuned to follow user\ninstructions using only a small set of high-quality instructions. This has\naccelerated the development of methods that filter a large, noisy\ninstruction-tuning datasets down to high-quality subset which works just as\nwell. However, typically, the performance of these methods is not demonstrated\nacross a uniform experimental setup and thus their generalization capabilities\nare not well established. In this work, we analyze popular selection strategies\nacross different source datasets, selection budgets and evaluation benchmarks:\nOur results indicate that selection strategies generalize poorly, often failing\nto consistently outperform even random baselines. We also analyze the\ncost-performance trade-offs of using data selection. Our findings reveal that\ndata selection can often exceed the cost of fine-tuning on the full dataset,\nyielding only marginal and sometimes no gains compared to tuning on the full\ndataset or a random subset.",
      "tldr_zh": "本文研究了指令选择策略(instruction selection strategies)在语言模型微调中的泛化能力，通过分析不同来源数据集、选择预算和评估基准，发现这些策略往往无法稳定超越随机基线(random baselines)。结果显示，选择策略的性能不一致，泛化能力较差。作者还评估了数据选择的成本-性能权衡，指出其通常会增加微调成本，却仅带来微不足道的收益，甚至不如直接在完整数据集或随机子集上进行微调。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15225v1",
      "published_date": "2024-10-19 22:10:49 UTC",
      "updated_date": "2024-10-19 22:10:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:41:05.305748"
    },
    {
      "arxiv_id": "2410.15222v1",
      "title": "AutoFLUKA: A Large Language Model Based Framework for Automating Monte Carlo Simulations in FLUKA",
      "title_zh": "AutoFLUKA：一种基于大型语言模型的",
      "authors": [
        "Zavier Ndum Ndum",
        "Jian Tao",
        "John Ford",
        "Yang Liu"
      ],
      "abstract": "Monte Carlo (MC) simulations, particularly using FLUKA, are essential for\nreplicating real-world scenarios across scientific and engineering fields.\nDespite the robustness and versatility, FLUKA faces significant limitations in\nautomation and integration with external post-processing tools, leading to\nworkflows with a steep learning curve, which are time-consuming and prone to\nhuman errors. Traditional methods involving the use of shell and Python\nscripts, MATLAB, and Microsoft Excel require extensive manual intervention and\nlack flexibility, adding complexity to evolving scenarios. This study explores\nthe potential of Large Language Models (LLMs) and AI agents to address these\nlimitations. AI agents, integrate natural language processing with autonomous\nreasoning for decision-making and adaptive planning, making them ideal for\nautomation. We introduce AutoFLUKA, an AI agent application developed using the\nLangChain Python Framework to automate typical MC simulation workflows in\nFLUKA. AutoFLUKA can modify FLUKA input files, execute simulations, and\nefficiently process results for visualization, significantly reducing human\nlabor and error. Our case studies demonstrate that AutoFLUKA can handle both\ngeneralized and domain-specific cases, such as Microdosimetry, with an\nstreamlined automated workflow, showcasing its scalability and flexibility. The\nstudy also highlights the potential of Retrieval Augmentation Generation (RAG)\ntools to act as virtual assistants for FLUKA, further improving user\nexperience, time and efficiency. In conclusion, AutoFLUKA represents a\nsignificant advancement in automating MC simulation workflows, offering a\nrobust solution to the inherent limitations. This innovation not only saves\ntime and resources but also opens new paradigms for research and development in\nhigh energy physics, medical physics, nuclear engineering space and\nenvironmental science.",
      "tldr_zh": "这篇论文针对 Monte Carlo (MC) 模拟中 FLUKA 的自动化和集成限制问题，提出使用 Large Language Models (LLMs) 和 AI 代理来简化复杂、易出错的工作流程。研究开发了 AutoFLUKA 框架，基于 LangChain Python Framework，能自动修改 FLUKA 输入文件、执行模拟、处理结果并进行可视化，从而大幅减少手动干预和错误。案例研究证明，AutoFLUKA 在一般和特定场景（如 Microdosimetry）中表现出色，并结合 Retrieval Augmentation Generation (RAG) 工具作为虚拟助手，提升了效率和用户体验，为高能物理、医疗物理等领域的研究带来创新。",
      "categories": [
        "cs.AI",
        "hep-ex",
        "nucl-ex",
        "physics.comp-ph",
        "physics.med-ph"
      ],
      "primary_category": "cs.AI",
      "comment": "58 pages including text, figures, references and appendices",
      "pdf_url": "http://arxiv.org/pdf/2410.15222v1",
      "published_date": "2024-10-19 21:50:11 UTC",
      "updated_date": "2024-10-19 21:50:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:41:17.788969"
    },
    {
      "arxiv_id": "2410.15221v1",
      "title": "IntersectionZoo: Eco-driving for Benchmarking Multi-Agent Contextual Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Vindula Jayawardana",
        "Baptiste Freydt",
        "Ao Qu",
        "Cameron Hickert",
        "Zhongxia Yan",
        "Cathy Wu"
      ],
      "abstract": "Despite the popularity of multi-agent reinforcement learning (RL) in\nsimulated and two-player applications, its success in messy real-world\napplications has been limited. A key challenge lies in its generalizability\nacross problem variations, a common necessity for many real-world problems.\nContextual reinforcement learning (CRL) formalizes learning policies that\ngeneralize across problem variations. However, the lack of standardized\nbenchmarks for multi-agent CRL has hindered progress in the field. Such\nbenchmarks are desired to be based on real-world applications to naturally\ncapture the many open challenges of real-world problems that affect\ngeneralization. To bridge this gap, we propose IntersectionZoo, a comprehensive\nbenchmark suite for multi-agent CRL through the real-world application of\ncooperative eco-driving in urban road networks. The task of cooperative\neco-driving is to control a fleet of vehicles to reduce fleet-level vehicular\nemissions. By grounding IntersectionZoo in a real-world application, we\nnaturally capture real-world problem characteristics, such as partial\nobservability and multiple competing objectives. IntersectionZoo is built on\ndata-informed simulations of 16,334 signalized intersections derived from 10\nmajor US cities, modeled in an open-source industry-grade microscopic traffic\nsimulator. By modeling factors affecting vehicular exhaust emissions (e.g.,\ntemperature, road conditions, travel demand), IntersectionZoo provides one\nmillion data-driven traffic scenarios. Using these traffic scenarios, we\nbenchmark popular multi-agent RL and human-like driving algorithms and\ndemonstrate that the popular multi-agent RL algorithms struggle to generalize\nin CRL settings.",
      "tldr_zh": "该研究提出IntersectionZoo，一种基于真实世界应用的基准测试套件，用于评估多智能体上下文强化学习（Contextual Reinforcement Learning, CRL）。IntersectionZoo聚焦于合作式环保驾驶（cooperative eco-driving）任务，通过控制车队减少车辆排放，并自然捕捉真实问题特征如部分可观察性和多个竞争目标。基于10个主要美国城市的16,334个信号灯路口数据，该基准在开源行业级微观交通模拟器上构建了超过一百万个数据驱动的交通场景。实验结果显示，流行多智能体强化学习（Multi-Agent RL）算法在CRL设置中泛化能力较差，突显了该领域的挑战。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "In review",
      "pdf_url": "http://arxiv.org/pdf/2410.15221v1",
      "published_date": "2024-10-19 21:34:24 UTC",
      "updated_date": "2024-10-19 21:34:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:41:29.428993"
    },
    {
      "arxiv_id": "2410.15208v1",
      "title": "Low-cost Robust Night-time Aerial Material Segmentation through Hyperspectral Data and Sparse Spatio-Temporal Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Chandrajit Bajaj",
        "Minh Nguyen",
        "Shubham Bhardwaj"
      ],
      "abstract": "Material segmentation is a complex task, particularly when dealing with\naerial data in poor lighting and atmospheric conditions. To address this,\nhyperspectral data from specialized cameras can be very useful in addition to\nRGB images. However, due to hardware constraints, high spectral data often come\nwith lower spatial resolution. Additionally, incorporating such data into a\nlearning-based segmentation framework is challenging due to the numerous data\nchannels involved. To overcome these difficulties, we propose an innovative\nSiamese framework that uses time series-based compression to effectively and\nscalably integrate the additional spectral data into the segmentation task. We\ndemonstrate our model's effectiveness through competitive benchmarks on aerial\ndatasets in various environmental conditions.",
      "tldr_zh": "这篇论文针对夜晚航空数据的材料分割任务提出了一种低成本鲁棒方法，利用 hyperspectral data 辅助 RGB 图像，以应对照明和大气条件差的挑战。作者设计了一个创新的 Siamese framework，通过基于时间序列的压缩和 sparse spatio-temporal learning 来有效整合多通道光谱数据，实现可扩展的分割处理。实验结果显示，该框架在各种环境条件下的航空数据集上达到了竞争性的基准表现，提升了分割的准确性和鲁棒性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to the International Conference on Neural Information\n  Processing (ICONIP) 2024. To be published in Springer-Nature Communications\n  in Computer and Information Science (CCIS) Series",
      "pdf_url": "http://arxiv.org/pdf/2410.15208v1",
      "published_date": "2024-10-19 20:48:41 UTC",
      "updated_date": "2024-10-19 20:48:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:41:40.539740"
    },
    {
      "arxiv_id": "2410.19835v1",
      "title": "Multidimensional Knowledge Graph Embeddings for International Trade Flow Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Durgesh Nandini",
        "Simon Bloethner",
        "Mirco Schoenfeld",
        "Mario Larch"
      ],
      "abstract": "Understanding the complex dynamics of high-dimensional, contingent, and\nstrongly nonlinear economic data, often shaped by multiplicative processes,\nposes significant challenges for traditional regression methods as such methods\noffer limited capacity to capture the structural changes they feature. To\naddress this, we propose leveraging the potential of knowledge graph embeddings\nfor economic trade data, in particular, to predict international trade\nrelationships. We implement KonecoKG, a knowledge graph representation of\neconomic trade data with multidimensional relationships using SDM-RDFizer, and\ntransform the relationships into a knowledge graph embedding using AmpliGraph.",
      "tldr_zh": "该论文针对传统回归方法在处理高维、非线性经济数据（如乘法过程引起的结构变化）时的局限性，提出使用知识 graph embeddings 来分析国际贸易流。研究者构建了 KonecoKG，这是一个多维关系的知识图表示，利用 SDM-RDFizer 处理经济贸易数据，并通过 AmpliGraph 进行知识图嵌入转换。最终，该方法旨在更准确地预测国际贸易关系，提供一种更有效的工具来捕捉复杂经济动态。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IR",
        "econ.GN",
        "q-fin.EC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.19835v1",
      "published_date": "2024-10-19 20:28:20 UTC",
      "updated_date": "2024-10-19 20:28:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:41:52.643582"
    },
    {
      "arxiv_id": "2410.15198v4",
      "title": "Medical-GAT: Cancer Document Classification Leveraging Graph-Based Residual Network for Scenarios with Limited Data",
      "title_zh": "Medical-GAT：利用基于图形的残差网络进行癌症文档分类，以应对数据有限场景",
      "authors": [
        "Elias Hossain",
        "Tasfia Nuzhat",
        "Shamsul Masum",
        "Shahram Rahimi",
        "Noorbakhsh Amiri Golilarz"
      ],
      "abstract": "Accurate classification of cancer-related medical abstracts is crucial for\nhealthcare management and research. However, obtaining large, labeled datasets\nin the medical domain is challenging due to privacy concerns and the complexity\nof clinical data. This scarcity of annotated data impedes the development of\neffective machine learning models for cancer document classification. To\naddress this challenge, we present a curated dataset of 1,874 biomedical\nabstracts, categorized into thyroid cancer, colon cancer, lung cancer, and\ngeneric topics. Our research focuses on leveraging this dataset to improve\nclassification performance, particularly in data-scarce scenarios. We introduce\na Residual Graph Attention Network (R-GAT) with multiple graph attention layers\nthat capture the semantic information and structural relationships within\ncancer-related documents. Our R-GAT model is compared with various techniques,\nincluding transformer-based models such as Bidirectional Encoder\nRepresentations from Transformers (BERT), RoBERTa, and domain-specific models\nlike BioBERT and Bio+ClinicalBERT. We also evaluated deep learning models\n(CNNs, LSTMs) and traditional machine learning models (Logistic Regression,\nSVM). Additionally, we explore ensemble approaches that combine deep learning\nmodels to enhance classification. Various feature extraction methods are\nassessed, including Term Frequency-Inverse Document Frequency (TF-IDF) with\nunigrams and bigrams, Word2Vec, and tokenizers from BERT and RoBERTa. The R-GAT\nmodel outperforms other techniques, achieving precision, recall, and F1 scores\nof 0.99, 0.97, and 0.98 for thyroid cancer; 0.96, 0.94, and 0.95 for colon\ncancer; 0.96, 0.99, and 0.97 for lung cancer; and 0.95, 0.96, and 0.95 for\ngeneric topics.",
      "tldr_zh": "这篇论文针对癌症相关医疗摘要分类的挑战，构建了一个包含1,874个生物医学摘要的数据集，涵盖甲状腺癌、结肠癌、肺癌和通用主题，以应对数据稀缺问题。研究引入了Residual Graph Attention Network (R-GAT)模型，通过多个图注意力层捕捉文档的语义信息和结构关系，并与其他方法如BERT、RoBERTa、BioBERT、CNNs、LSTMs和传统机器学习模型（如SVM）进行了比较。结果显示，R-GAT在分类性能上表现出色，例如甲状腺癌的精确率、召回率和F1分数分别达到0.99、0.97和0.98。该方法为数据有限场景下的癌症文档分类提供了高效且可靠的解决方案。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15198v4",
      "published_date": "2024-10-19 20:07:40 UTC",
      "updated_date": "2025-04-08 22:53:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:42:06.021175"
    },
    {
      "arxiv_id": "2410.15188v1",
      "title": "Augmented Lagrangian-Based Safe Reinforcement Learning Approach for Distribution System Volt/VAR Control",
      "title_zh": "基于增强拉格朗日的安全强化学习方法，用于配电系统电压/无功功率控制",
      "authors": [
        "Guibin Chen"
      ],
      "abstract": "This paper proposes a data-driven solution for Volt-VAR control problem in\nactive distribution system. As distribution system models are always inaccurate\nand incomplete, it is quite difficult to solve the problem. To handle with this\ndilemma, this paper formulates the Volt-VAR control problem as a constrained\nMarkov decision process (CMDP). By synergistically combining the augmented\nLagrangian method and soft actor critic algorithm, a novel safe off-policy\nreinforcement learning (RL) approach is proposed in this paper to solve the\nCMDP. The actor network is updated in a policy gradient manner with the\nLagrangian value function. A double-critics network is adopted to synchronously\nestimate the action-value function to avoid overestimation bias. The proposed\nalgorithm does not require strong convexity guarantee of examined problems and\nis sample efficient. A two-stage strategy is adopted for offline training and\nonline execution, so the accurate distribution system model is no longer\nneeded. To achieve scalability, a centralized training distributed execution\nstrategy is adopted for a multi-agent framework, which enables a decentralized\nVolt-VAR control for large-scale distribution system. Comprehensive numerical\nexperiments with real-world electricity data demonstrate that our proposed\nalgorithm can achieve high solution optimality and constraints compliance.",
      "tldr_zh": "本论文针对主动配电系统的 Volt-VAR 控制问题提出了一种数据驱动的解决方案，以应对模型不准确和不完整带来的挑战。将问题表述为约束马尔科夫决策过程 (CMDP)，并结合 Augmented Lagrangian 方法和 Soft Actor-Critic 算法，开发了一种新的安全离策略强化学习 (RL) 方法。算法采用策略梯度更新演员网络、双评论家网络避免过估计偏差，并通过两阶段策略（离线训练和在线执行）实现无需准确系统模型的多智能体框架。实验结果显示，该方法在真实电力数据上实现了高解决方案最优性和约束遵守性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "arXiv admin note: substantial text overlap with arXiv:2209.09772",
      "pdf_url": "http://arxiv.org/pdf/2410.15188v1",
      "published_date": "2024-10-19 19:45:09 UTC",
      "updated_date": "2024-10-19 19:45:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:42:17.553024"
    },
    {
      "arxiv_id": "2410.15186v1",
      "title": "Fine-tuning foundational models to code diagnoses from veterinary health records",
      "title_zh": "翻译失败",
      "authors": [
        "Mayla R. Boguslav",
        "Adam Kiehl",
        "David Kott",
        "G. Joseph Strecker",
        "Tracy Webb",
        "Nadia Saklou",
        "Terri Ward",
        "Michael Kirby"
      ],
      "abstract": "Veterinary medical records represent a large data resource for application to\nveterinary and One Health clinical research efforts. Use of the data is limited\nby interoperability challenges including inconsistent data formats and data\nsiloing. Clinical coding using standardized medical terminologies enhances the\nquality of medical records and facilitates their interoperability with\nveterinary and human health records from other sites. Previous studies, such as\nDeepTag and VetTag, evaluated the application of Natural Language Processing\n(NLP) to automate veterinary diagnosis coding, employing long short-term memory\n(LSTM) and transformer models to infer a subset of Systemized Nomenclature of\nMedicine - Clinical Terms (SNOMED-CT) diagnosis codes from free-text clinical\nnotes. This study expands on these efforts by incorporating all 7,739 distinct\nSNOMED-CT diagnosis codes recognized by the Colorado State University (CSU)\nVeterinary Teaching Hospital (VTH) and by leveraging the increasing\navailability of pre-trained large language models (LLMs). Ten freely-available\npre-trained LLMs were fine-tuned on the free-text notes from 246,473\nmanually-coded veterinary patient visits included in the CSU VTH's electronic\nhealth records (EHRs), which resulted in superior performance relative to\nprevious efforts. The most accurate results were obtained when expansive\nlabeled data were used to fine-tune relatively large clinical LLMs, but the\nstudy also showed that comparable results can be obtained using more limited\nresources and non-clinical LLMs. The results of this study contribute to the\nimprovement of the quality of veterinary EHRs by investigating accessible\nmethods for automated coding and support both animal and human health research\nby paving the way for more integrated and comprehensive health databases that\nspan species and institutions.",
      "tldr_zh": "本文研究了通过微调预训练的大型语言模型(LLMs)来自动编码兽医健康记录中的诊断代码，扩展了SNOMED-CT术语集至7,739个代码。研究利用246,473个手动编码的兽医电子健康记录(EHRs)对十个自由可用LLMs进行微调，相比之前的NLP方法如LSTM和transformer，取得了更高的性能。结果显示，使用大量标记数据微调大型临床LLMs能获得最佳准确率，而资源有限时，非临床LLMs也能提供类似效果，从而提升兽医EHRs质量并促进跨物种和机构的One Health研究。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "26 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.15186v1",
      "published_date": "2024-10-19 19:30:29 UTC",
      "updated_date": "2024-10-19 19:30:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:42:29.607920"
    },
    {
      "arxiv_id": "2410.15184v1",
      "title": "Action abstractions for amortized sampling",
      "title_zh": "翻译失败",
      "authors": [
        "Oussama Boussif",
        "Léna Néhale Ezzine",
        "Joseph D Viviano",
        "Michał Koziarski",
        "Moksh Jain",
        "Nikolay Malkin",
        "Emmanuel Bengio",
        "Rim Assouel",
        "Yoshua Bengio"
      ],
      "abstract": "As trajectories sampled by policies used by reinforcement learning (RL) and\ngenerative flow networks (GFlowNets) grow longer, credit assignment and\nexploration become more challenging, and the long planning horizon hinders mode\ndiscovery and generalization. The challenge is particularly pronounced in\nentropy-seeking RL methods, such as generative flow networks, where the agent\nmust learn to sample from a structured distribution and discover multiple\nhigh-reward states, each of which take many steps to reach. To tackle this\nchallenge, we propose an approach to incorporate the discovery of action\nabstractions, or high-level actions, into the policy optimization process. Our\napproach involves iteratively extracting action subsequences commonly used\nacross many high-reward trajectories and `chunking' them into a single action\nthat is added to the action space. In empirical evaluation on synthetic and\nreal-world environments, our approach demonstrates improved sample efficiency\nperformance in discovering diverse high-reward objects, especially on harder\nexploration problems. We also observe that the abstracted high-order actions\nare interpretable, capturing the latent structure of the reward landscape of\nthe action space. This work provides a cognitively motivated approach to action\nabstraction in RL and is the first demonstration of hierarchical planning in\namortized sequential sampling.",
      "tldr_zh": "这篇论文针对强化学习（RL）和生成流网络（GFlowNets）中长轨迹带来的信用分配、探索困难和模式发现问题，提出了一种整合行动抽象（action abstractions）的策略优化方法。该方法通过迭代提取高奖励轨迹中的常见行动子序列，并将其“chunking”成单一高阶行动添加到行动空间中，从而提升探索效率和分层规划能力。在合成和真实环境中实验表明，该方法显著提高了样本效率，尤其在困难探索任务中发现多样高奖励对象，并展示了可解释的潜在结构，这是RL中认知动机行动抽象的首次摊销顺序采样应用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15184v1",
      "published_date": "2024-10-19 19:22:50 UTC",
      "updated_date": "2024-10-19 19:22:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:42:41.432868"
    },
    {
      "arxiv_id": "2410.15178v3",
      "title": "GUIDEd Agents: Enhancing Navigation Policies through Task-Specific Uncertainty Abstraction in Localization-Limited Environments",
      "title_zh": "翻译失败",
      "authors": [
        "Gokul Puthumanaillam",
        "Paulo Padrao",
        "Jose Fuentes",
        "Leonardo Bobadilla",
        "Melkior Ornik"
      ],
      "abstract": "Autonomous vehicles performing navigation tasks in complex environments face\nsignificant challenges due to uncertainty in state estimation. In many\nscenarios, such as stealth operations or resource-constrained settings,\naccessing high-precision localization comes at a significant cost, forcing\nrobots to rely primarily on less precise state estimates. Our key observation\nis that different tasks require varying levels of precision in different\nregions: a robot navigating a crowded space might need precise localization\nnear obstacles but can operate effectively with less precision elsewhere. In\nthis paper, we present a planning method for integrating task-specific\nuncertainty requirements directly into navigation policies. We introduce\nTask-Specific Uncertainty Maps (TSUMs), which abstract the acceptable levels of\nstate estimation uncertainty across different regions. TSUMs align task\nrequirements and environmental features using a shared representation space,\ngenerated via a domain-adapted encoder. Using TSUMs, we propose Generalized\nUncertainty Integration for Decision-Making and Execution (GUIDE), a policy\nconditioning framework that incorporates these uncertainty requirements into\nrobot decision-making. We find that TSUMs provide an effective way to abstract\ntask-specific uncertainty requirements, and conditioning policies on TSUMs\nenables the robot to reason about the context-dependent value of certainty and\nadapt its behavior accordingly. We show how integrating GUIDE into\nreinforcement learning frameworks allows the agent to learn navigation policies\nthat effectively balance task completion and uncertainty management without\nexplicit reward engineering. We evaluate GUIDE on various real-world robotic\nnavigation tasks and find that it demonstrates significant improvement in task\ncompletion rates compared to baseline methods that do not explicitly consider\ntask-specific uncertainty.",
      "tldr_zh": "本研究针对自主车辆在定位受限环境（如隐秘操作）中的导航挑战，观察到不同任务对区域定位精度的需求不一，例如靠近障碍物时需高精度。论文提出 Task-Specific Uncertainty Maps (TSUMs)，一种通过域适应编码器生成的任务特定不确定性地图，用于抽象环境区域的可接受不确定性水平。随后，引入 Generalized Uncertainty Integration for Decision-Making and Execution (GUIDE) 框架，将这些不确定性要求整合到机器人决策政策中，使代理能根据上下文动态调整行为。GUIDE 整合到 reinforcement learning 框架中，允许代理学习平衡任务完成和不确定性管理的策略，而无需显式奖励工程。实验结果显示，在各种真实世界导航任务中，GUIDE 相较基线方法显著提高了任务完成率。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15178v3",
      "published_date": "2024-10-19 18:46:17 UTC",
      "updated_date": "2025-02-03 04:57:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:42:54.095582"
    },
    {
      "arxiv_id": "2410.15175v1",
      "title": "Implicit neural representation for free-breathing MR fingerprinting (INR-MRF): co-registered 3D whole-liver water T1, water T2, proton density fat fraction, and R2* mapping",
      "title_zh": "翻译失败",
      "authors": [
        "Chao Li",
        "Jiahao Li",
        "Jinwei Zhang",
        "Eddy Solomon",
        "Alexey V. Dimov",
        "Pascal Spincemaille",
        "Thanh D. Nguyen",
        "Martin R. Prince",
        "Yi Wang"
      ],
      "abstract": "Purpose: To develop an MRI technique for free-breathing 3D whole-liver\nquantification of water T1, water T2, proton density fat fraction (PDFF), R2*.\nMethods: An Eight-echo spoiled gradient echo pulse sequence with spiral readout\nwas developed by interleaving inversion recovery and T2 magnetization\npreparation. We propose a neural network based on a 4D and a 3D implicit neural\nrepresentation (INR) which simultaneously learns the motion deformation fields\nand the static reference frame MRI subspace images respectively. Water and fat\nsingular images were separated during network training, with no need of\nperforming retrospective water-fat separation. T1, T2, R2* and proton density\nfat fraction (PDFF) produced by the proposed method were validated in vivo on\n10 healthy subjects, using quantitative maps generated from conventional scans\nas reference. Results: Our results showed minimal bias and narrow 95% limits of\nagreement on T1, T2, R2* and PDFF values in the liver compared to conventional\nbreath-holding scans. Conclusions: INR-MRF enabled co-registered 3D whole liver\nT1, T2, R2* and PDFF mapping in a single free-breathing scan.",
      "tldr_zh": "本研究开发了INR-MRF技术，利用隐式神经表示(INR)网络，实现自由呼吸下的3D全肝量化映射，包括water T1, water T2, PDFF和R2*。该方法基于一个八回波spoiled gradient echo脉冲序列，结合4D和3D INR网络，同时学习运动变形场和静态MRI子空间图像，并在训练过程中分离水和脂肪图像，无需事后处理。实验在10名健康受试者上验证，结果显示与传统屏息扫描相比，INR-MRF提供最小偏差和窄的95%置信区间，为高效的肝脏定量成像提供了可靠方案。",
      "categories": [
        "physics.med-ph",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "physics.med-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15175v1",
      "published_date": "2024-10-19 18:35:36 UTC",
      "updated_date": "2024-10-19 18:35:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:43:05.807412"
    },
    {
      "arxiv_id": "2410.15173v1",
      "title": "Uncovering Autoregressive LLM Knowledge of Thematic Fit in Event Representation",
      "title_zh": "翻译失败",
      "authors": [
        "Safeyah Khaled Alshemali",
        "Daniel Bauer",
        "Yuval Marton"
      ],
      "abstract": "The thematic fit estimation task measures the compatibility between a\npredicate (typically a verb), an argument (typically a noun phrase), and a\nspecific semantic role assigned to the argument. Previous state-of-the-art work\nhas focused on modeling thematic fit through distributional or neural models of\nevent representation, trained in a supervised fashion with indirect labels. In\nthis work, we assess whether pre-trained autoregressive LLMs possess\nconsistent, expressible knowledge about thematic fit. We evaluate both closed\nand open state-of-the-art LLMs on several psycholinguistic datasets, along\nthree axes: (1) Reasoning Form: multi-step logical reasoning (chain-of-thought\nprompting) vs. simple prompting. (2) Input Form: providing context (generated\nsentences) vs. raw tuples <predicate, argument, role>. (3) Output Form:\ncategorical vs. numeric. Our results show that chain-of-thought reasoning is\nmore effective on datasets with self-explanatory semantic role labels,\nespecially Location. Generated sentences helped only in few settings, and\nlowered results in many others. Predefined categorical (compared to numeric)\noutput raised GPT's results across the board with few exceptions, but lowered\nLlama's. We saw that semantically incoherent generated sentences, which the\nmodels lack the ability to consistently filter out, hurt reasoning and overall\nperformance too. Our GPT-powered methods set new state-of-the-art on all tested\ndatasets.",
      "tldr_zh": "本文研究了预训练的自回归LLMs（如GPT和Llama）在事件表示中对主题适合度(thematic fit)的内在知识，主题适合度任务涉及谓词、论元和语义角色的兼容性。作者通过三轴评估（Reasoning Form: chain-of-thought推理 vs. 简单提示；Input Form: 生成句子上下文 vs. 原始元组；Output Form: 分类 vs. 数字）在多个心理语言学数据集上测试了这些模型。结果表明，chain-of-thought推理在自解释语义角色（如Location）上更有效，但生成的语义不连贯句子可能降低性能，且GPT驱动的方法在所有数据集上设定了新的state-of-the-art。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "15 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.15173v1",
      "published_date": "2024-10-19 18:25:30 UTC",
      "updated_date": "2024-10-19 18:25:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:43:18.575205"
    },
    {
      "arxiv_id": "2410.15171v1",
      "title": "Linguistic Fuzzy Information Evolution with Random Leader Election Mechanism for Decision-Making Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Qianlei Jia",
        "Witold Pedrycz"
      ],
      "abstract": "Linguistic fuzzy information evolution is crucial in understanding\ninformation exchange among agents. However, different agent weights may lead to\ndifferent convergence results in the classic DeGroot model. Similarly, in the\nHegselmann-Krause bounded confidence model (HK model), changing the confidence\nthreshold values of agents can lead to differences in the final results. To\naddress these limitations, this paper proposes three new models of linguistic\nfuzzy information dynamics: the per-round random leader election\nmechanism-based DeGroot model (PRRLEM-DeGroot), the PRRLEM-based homogeneous HK\nmodel (PRRLEM-HOHK), and the PRRLEM-based heterogeneous HK model (PRRLEM-HEHK).\nIn these models, after each round of fuzzy information updates, an agent is\nrandomly selected to act as a temporary leader with more significant influence,\nwith the leadership structure being reset after each update. This strategy\nincreases the information sharing and enhances decision-making by integrating\nmultiple agents' evaluation information, which is also in line with real life\n(\\emph{Leader is not unchanged}). The Monte Carlo method is then employed to\nsimulate the behavior of complex systems through repeated random tests,\nobtaining confidence intervals for different fuzzy information. Subsequently,\nan improved golden rule representative value (GRRV) in fuzzy theory is proposed\nto rank these confidence intervals. Simulation examples and a real-world\nscenario about space situational awareness validate the effectiveness of the\nproposed models. Comparative analysis with the other models demonstrate our\nability to address the echo chamber and improve the robustness.",
      "tldr_zh": "本论文针对经典DeGroot模型和Hegselmann-Krause (HK)模型中代理权重或置信阈值变化导致的收敛差异问题，提出了三种新模型：PRRLEM-DeGroot、PRRLEM-HOHK 和 PRRLEM-HEHK，这些模型通过每轮随机选举临时领导者机制来增强信息共享和决策鲁棒性。机制涉及在模糊信息更新后随机选择代理作为领导者，以更大影响整合多代理评估信息，并重置领导结构，以模拟现实场景。论文采用Monte Carlo方法模拟复杂系统，计算模糊信息的置信区间，并引入改进的黄金规则代表值 (GRRV) 来对这些区间进行排序。模拟例子和空间态势感知的真实应用验证了这些模型的有效性，与其他模型相比，它们显著解决了回声室问题并提升了系统鲁棒性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15171v1",
      "published_date": "2024-10-19 18:15:24 UTC",
      "updated_date": "2024-10-19 18:15:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:43:29.937248"
    },
    {
      "arxiv_id": "2410.15164v3",
      "title": "SPA-Bench: A Comprehensive Benchmark for SmartPhone Agent Evaluation",
      "title_zh": "翻译失败",
      "authors": [
        "Jingxuan Chen",
        "Derek Yuen",
        "Bin Xie",
        "Yuhao Yang",
        "Gongwei Chen",
        "Zhihao Wu",
        "Li Yixing",
        "Xurui Zhou",
        "Weiwen Liu",
        "Shuai Wang",
        "Kaiwen Zhou",
        "Rui Shao",
        "Liqiang Nie",
        "Yasheng Wang",
        "Jianye Hao",
        "Jun Wang",
        "Kun Shao"
      ],
      "abstract": "Smartphone agents are increasingly important for helping users control\ndevices efficiently, with (Multimodal) Large Language Model (MLLM)-based\napproaches emerging as key contenders. Fairly comparing these agents is\nessential but challenging, requiring a varied task scope, the integration of\nagents with different implementations, and a generalisable evaluation pipeline\nto assess their strengths and weaknesses. In this paper, we present SPA-Bench,\na comprehensive SmartPhone Agent Benchmark designed to evaluate (M)LLM-based\nagents in an interactive environment that simulates real-world conditions.\nSPA-Bench offers three key contributions: (1) A diverse set of tasks covering\nsystem and third-party apps in both English and Chinese, focusing on features\ncommonly used in daily routines; (2) A plug-and-play framework enabling\nreal-time agent interaction with Android devices, integrating over ten agents\nwith the flexibility to add more; (3) A novel evaluation pipeline that\nautomatically assesses agent performance across multiple dimensions,\nencompassing seven metrics related to task completion and resource consumption.\nOur extensive experiments across tasks and agents reveal challenges like\ninterpreting mobile user interfaces, action grounding, memory retention, and\nexecution costs. We propose future research directions to ease these\ndifficulties, moving closer to real-world smartphone agent applications.\nSPA-Bench is available at https://ai-agents-2030.github.io/SPA-Bench/.",
      "tldr_zh": "本文介绍了SPA-Bench，一种全面的智能手机代理评估基准，针对基于(Multimodal) Large Language Model ((M)LLM)的代理在真实交互环境中进行评估。该基准的主要贡献包括：一个多样化的任务集，覆盖英语和中文的系统及第三方应用；一个即插即用的框架，支持实时与Android设备的交互并集成十多个代理；以及一个新颖的自动评估管道，涵盖七个指标，如任务完成率和资源消耗。实验揭示了代理在解释移动用户界面、行动定位、记忆保留和执行成本等方面的挑战，并提出未来研究方向以推动实际应用。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "ICLR 2025 Spotlight",
      "pdf_url": "http://arxiv.org/pdf/2410.15164v3",
      "published_date": "2024-10-19 17:28:48 UTC",
      "updated_date": "2025-03-31 20:39:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:43:40.933009"
    },
    {
      "arxiv_id": "2410.15163v2",
      "title": "Optimizing Large Language Models for Dynamic Constraints through Human-in-the-Loop Discriminators",
      "title_zh": "翻译失败",
      "authors": [
        "Timothy Wei",
        "Annabelle Miin",
        "Anastasia Miin"
      ],
      "abstract": "Large Language Models (LLMs) have recently demonstrated impressive\ncapabilities across various real-world applications. However, due to the\ncurrent text-in-text-out paradigm, it remains challenging for LLMs to handle\ndynamic and complex application constraints, let alone devise general solutions\nthat meet predefined system goals. Current common practices like model\nfinetuning and reflection-based reasoning often address these issues\ncase-by-case, limiting their generalizability. To address this issue, we\npropose a flexible framework that enables LLMs to interact with system\ninterfaces, summarize constraint concepts, and continually optimize performance\nmetrics by collaborating with human experts. As a case in point, we initialized\na travel planner agent by establishing constraints from evaluation interfaces.\nThen, we employed both LLM-based and human discriminators to identify critical\ncases and continuously improve agent performance until the desired outcomes\nwere achieved. After just one iteration, our framework achieved a $7.78\\%$ pass\nrate with the human discriminator (a $40.2\\%$ improvement over baseline) and a\n$6.11\\%$ pass rate with the LLM-based discriminator. Given the adaptability of\nour proposal, we believe this framework can be applied to a wide range of\nconstraint-based applications and lay a solid foundation for model finetuning\nwith performance-sensitive data samples.",
      "tldr_zh": "这篇论文提出了一种灵活框架，通过 Human-in-the-Loop Discriminators 优化 Large Language Models (LLMs)，以更好地处理动态和复杂应用约束，实现与系统接口交互、约束概念总结以及与人类专家的持续协作。框架的核心在于使用 LLM-based 和人类鉴别器识别关键案例，并迭代优化代理性能，例如在旅行规划代理的初始化中，通过评估接口建立约束后，仅需一次迭代即提升了通过率。实验结果显示，与基线相比，人类鉴别器的通过率提高了 40.2%（达到 7.78%），而 LLM-based 鉴别器达到 6.11%。该方法提升了 LLMs 的通用性，并为基于约束的应用提供坚实的基础。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15163v2",
      "published_date": "2024-10-19 17:27:38 UTC",
      "updated_date": "2024-10-24 04:46:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:43:53.823770"
    },
    {
      "arxiv_id": "2410.15156v1",
      "title": "Simulation-Based Optimistic Policy Iteration For Multi-Agent MDPs with Kullback-Leibler Control Cost",
      "title_zh": "翻译失败",
      "authors": [
        "Khaled Nakhleh",
        "Ceyhun Eksin",
        "Sabit Ekin"
      ],
      "abstract": "This paper proposes an agent-based optimistic policy iteration (OPI) scheme\nfor learning stationary optimal stochastic policies in multi-agent Markov\nDecision Processes (MDPs), in which agents incur a Kullback-Leibler (KL)\ndivergence cost for their control efforts and an additional cost for the joint\nstate. The proposed scheme consists of a greedy policy improvement step\nfollowed by an m-step temporal difference (TD) policy evaluation step. We use\nthe separable structure of the instantaneous cost to show that the policy\nimprovement step follows a Boltzmann distribution that depends on the current\nvalue function estimate and the uncontrolled transition probabilities. This\nallows agents to compute the improved joint policy independently. We show that\nboth the synchronous (entire state space evaluation) and asynchronous (a\nuniformly sampled set of substates) versions of the OPI scheme with finite\npolicy evaluation rollout converge to the optimal value function and an optimal\njoint policy asymptotically. Simulation results on a multi-agent MDP with KL\ncontrol cost variant of the Stag-Hare game validates our scheme's performance\nin terms of minimizing the cost return.",
      "tldr_zh": "本论文提出了一种基于模拟的乐观策略迭代(OPI)方案，用于在多代理Markov Decision Processes (MDPs)中学习平稳最优随机策略，其中代理需承担Kullback-Leibler (KL) 散度控制成本以及联合状态的额外成本。方案包括贪婪策略改进步骤和m-step Temporal Difference (TD) 策略评估步骤，利用即时成本的可分离结构，使代理能够通过依赖当前价值函数估计和无控制转移概率的Boltzmann分布独立计算改进的联合策略。研究证明，OPI方案的同步和异步版本在有限策略评估回滚下会渐进收敛到最优价值函数和最优联合策略；模拟实验在Stag-Hare游戏的KL控制成本变体上验证了该方案在最小化成本回报方面的优越性能。",
      "categories": [
        "cs.AI",
        "cs.MA",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15156v1",
      "published_date": "2024-10-19 17:00:23 UTC",
      "updated_date": "2024-10-19 17:00:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:44:06.049201"
    },
    {
      "arxiv_id": "2410.15154v2",
      "title": "MCCoder: Streamlining Motion Control with LLM-Assisted Code Generation and Rigorous Verification",
      "title_zh": "翻译失败",
      "authors": [
        "Yin Li",
        "Liangwei Wang",
        "Shiyuan Piao",
        "Boo-Ho Yang",
        "Ziyue Li",
        "Wei Zeng",
        "Fugee Tsung"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated significant potential in code\ngeneration. However, in the factory automation sector, particularly motion\ncontrol, manual programming, alongside inefficient and unsafe debugging\npractices, remains prevalent. This stems from the complex interplay of\nmechanical and electrical systems and stringent safety requirements. Moreover,\nmost current AI-assisted motion control programming efforts focus on PLCs, with\nlittle attention given to high-level languages and function libraries. To\naddress these challenges, we introduce MCCoder, an LLM-powered system tailored\nfor generating motion control code, integrated with a soft-motion controller.\nMCCoder improves code generation through a structured workflow that combines\nmultitask decomposition, hybrid retrieval-augmented generation (RAG), and\niterative self-correction, utilizing a well-established motion library.\nAdditionally, it integrates a 3D simulator for intuitive motion validation and\nlogs of full motion trajectories for data verification, significantly enhancing\naccuracy and safety. In the absence of benchmark datasets and metrics tailored\nfor evaluating motion control code generation, we propose MCEVAL, a dataset\nspanning motion tasks of varying complexity. Experiments show that MCCoder\noutperforms baseline models using Advanced RAG, achieving an overall\nperformance gain of 33.09% and a 131.77% improvement on complex tasks in the\nMCEVAL dataset.",
      "tldr_zh": "本文提出 MCCoder，一种基于 LLM 的系统，用于简化工厂自动化中的运动控制代码生成，并通过严格验证提升准确性和安全。该系统采用多任务分解、hybrid RAG 和迭代自校正的工作流程，结合成熟的运动库以及 3D 模拟器进行直观验证和轨迹数据分析，以应对机械电气系统的复杂性。为评估运动控制代码，论文引入 MCEVAL 数据集，实验结果显示 MCCoder 相较基线模型整体性能提升 33.09%，在复杂任务上提升 131.77%。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15154v2",
      "published_date": "2024-10-19 16:46:21 UTC",
      "updated_date": "2025-03-16 06:03:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:44:17.460888"
    },
    {
      "arxiv_id": "2410.15143v2",
      "title": "Budgeted Online Continual Learning by Adaptive Layer Freezing and Frequency-based Sampling",
      "title_zh": "预算限制的在线持续学习：通过自适应层冻结和基于频率的采样",
      "authors": [
        "Minhyuk Seo",
        "Hyunseo Koh",
        "Jonghyun Choi"
      ],
      "abstract": "The majority of online continual learning (CL) advocates single-epoch\ntraining and imposes restrictions on the size of replay memory. However,\nsingle-epoch training would incur a different amount of computations per CL\nalgorithm, and the additional storage cost to store logit or model in addition\nto replay memory is largely ignored in calculating the storage budget. Arguing\ndifferent computational and storage budgets hinder fair comparison among CL\nalgorithms in practice, we propose to use floating point operations (FLOPs) and\ntotal memory size in Byte as a metric for computational and memory budgets,\nrespectively, to compare and develop CL algorithms in the same 'total resource\nbudget.' To improve a CL method in a limited total budget, we propose adaptive\nlayer freezing that does not update the layers for less informative batches to\nreduce computational costs with a negligible loss of accuracy. In addition, we\npropose a memory retrieval method that allows the model to learn the same\namount of knowledge as using random retrieval in fewer iterations. Empirical\nvalidations on the CIFAR-10/100, CLEAR-10/100, and ImageNet-1K datasets\ndemonstrate that the proposed approach outperforms the state-of-the-art methods\nwithin the same total budget",
      "tldr_zh": "这篇论文针对在线持续学习（Online Continual Learning）中的计算和存储预算问题，提出使用浮点运算（FLOPs）和总内存大小作为公平比较指标，以确保不同算法在相同总资源预算下进行评估。主要贡献包括引入自适应层冻结（Adaptive Layer Freezing），该方法不对信息量小的批次更新层，从而减少计算成本而几乎不损失准确性；以及基于频率的采样（Frequency-based Sampling）内存检索技术，使模型在更少迭代中学习等量知识。在CIFAR-10/100、CLEAR-10/100和ImageNet-1K数据集上的实验验证表明，该方法在相同预算下优于现有最先进方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "ICLR 2025 Spotlight",
      "pdf_url": "http://arxiv.org/pdf/2410.15143v2",
      "published_date": "2024-10-19 16:00:00 UTC",
      "updated_date": "2025-03-16 20:18:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:44:29.731492"
    },
    {
      "arxiv_id": "2410.15128v1",
      "title": "Generalized Flow Matching for Transition Dynamics Modeling",
      "title_zh": "用于过渡动力学建模的广义流匹配",
      "authors": [
        "Haibo Wang",
        "Yuxuan Qiu",
        "Yanze Wang",
        "Rob Brekelmans",
        "Yuanqi Du"
      ],
      "abstract": "Simulating transition dynamics between metastable states is a fundamental\nchallenge in dynamical systems and stochastic processes with wide real-world\napplications in understanding protein folding, chemical reactions and neural\nactivities. However, the computational challenge often lies on sampling\nexponentially many paths in which only a small fraction ends in the target\nmetastable state due to existence of high energy barriers. To amortize the\ncost, we propose a data-driven approach to warm-up the simulation by learning\nnonlinear interpolations from local dynamics. Specifically, we infer a\npotential energy function from local dynamics data. To find plausible paths\nbetween two metastable states, we formulate a generalized flow matching\nframework that learns a vector field to sample propable paths between the two\nmarginal densities under the learned energy function. Furthermore, we\niteratively refine the model by assigning importance weights to the sampled\npaths and buffering more likely paths for training. We validate the\neffectiveness of the proposed method to sample probable paths on both synthetic\nand real-world molecular systems.",
      "tldr_zh": "该研究针对动态系统和随机过程的过渡动力学建模问题提出了一种数据驱动方法，旨在解决模拟稳定态之间路径采样的高计算挑战，例如在蛋白质折叠、化学反应和神经活动中的应用。方法首先从局部动态数据中推断势能函数（potential energy function），然后通过广义流匹配框架（Generalized Flow Matching）学习一个矢量场，以采样两个边际密度之间可能的路径，并通过迭代分配重要性权重和缓冲更可能路径来精炼模型。实验结果显示，该方法在合成和真实分子系统中有效提高了路径采样的准确性和效率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.bio-ph",
        "physics.chem-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15128v1",
      "published_date": "2024-10-19 15:03:39 UTC",
      "updated_date": "2024-10-19 15:03:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:44:41.149847"
    },
    {
      "arxiv_id": "2410.15127v2",
      "title": "Reinfier and Reintrainer: Verification and Interpretation-Driven Safe Deep Reinforcement Learning Frameworks",
      "title_zh": "Reinfier and Reintrainer：验证和解释驱动的安全深度强化学习框架",
      "authors": [
        "Zixuan Yang",
        "Jiaqi Zheng",
        "Guihai Chen"
      ],
      "abstract": "Ensuring verifiable and interpretable safety of deep reinforcement learning\n(DRL) is crucial for its deployment in real-world applications. Existing\napproaches like verification-in-the-loop training, however, face challenges\nsuch as difficulty in deployment, inefficient training, lack of\ninterpretability, and suboptimal performance in property satisfaction and\nreward performance. In this work, we propose a novel verification-driven\ninterpretation-in-the-loop framework Reintrainer to develop trustworthy DRL\nmodels, which are guaranteed to meet the expected constraint properties.\nSpecifically, in each iteration, this framework measures the gap between the\non-training model and predefined properties using formal verification,\ninterprets the contribution of each input feature to the model's output, and\nthen generates the training strategy derived from the on-the-fly measure\nresults, until all predefined properties are proven. Additionally, the low\nreusability of existing verifiers and interpreters motivates us to develop\nReinfier, a general and fundamental tool within Reintrainer for DRL\nverification and interpretation. Reinfier features breakpoints searching and\nverification-driven interpretation, associated with a concise\nconstraint-encoding language DRLP. Evaluations demonstrate that Reintrainer\noutperforms the state-of-the-art on six public benchmarks in both performance\nand property guarantees. Our framework can be accessed at\nhttps://github.com/Kurayuri/Reinfier.",
      "tldr_zh": "本研究提出Reintrainer框架和Reinfier工具，以验证和解释驱动的方式提升Deep Reinforcement Learning (DRL) 的安全性和可信赖性，解决现有方法在部署、训练效率、可解释性和性能方面的挑战。Reintrainer通过迭代过程使用formal verification测量模型与预定义属性的差距，解释输入特征对输出的贡献，并据此生成训练策略，直至所有属性被证明。Reinfier作为通用工具，集成了断点搜索、验证驱动解释和简洁约束编码语言DRLP，提升了验证和解释的复用性。实验结果显示，Reintrainer在六个公共基准上超越最先进方法，在性能和属性保证方面表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15127v2",
      "published_date": "2024-10-19 15:03:26 UTC",
      "updated_date": "2025-02-04 14:01:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:44:53.062111"
    },
    {
      "arxiv_id": "2410.15126v1",
      "title": "MELT: Materials-aware Continued Pre-training for Language Model Adaptation to Materials Science",
      "title_zh": "翻译失败",
      "authors": [
        "Junho Kim",
        "Yeachan Kim",
        "Jun-Hyung Park",
        "Yerim Oh",
        "Suho Kim",
        "SangKeun Lee"
      ],
      "abstract": "We introduce a novel continued pre-training method, MELT (MatEriaLs-aware\ncontinued pre-Training), specifically designed to efficiently adapt the\npre-trained language models (PLMs) for materials science. Unlike previous\nadaptation strategies that solely focus on constructing domain-specific corpus,\nMELT comprehensively considers both the corpus and the training strategy, given\nthat materials science corpus has distinct characteristics from other domains.\nTo this end, we first construct a comprehensive materials knowledge base from\nthe scientific corpus by building semantic graphs. Leveraging this extracted\nknowledge, we integrate a curriculum into the adaptation process that begins\nwith familiar and generalized concepts and progressively moves toward more\nspecialized terms. We conduct extensive experiments across diverse benchmarks\nto verify the effectiveness and generality of MELT. A comprehensive evaluation\nconvincingly supports the strength of MELT, demonstrating superior performance\ncompared to existing continued pre-training methods. The in-depth analysis also\nshows that MELT enables PLMs to effectively represent materials entities\ncompared to the existing adaptation methods, thereby highlighting its broad\napplicability across a wide spectrum of materials science.",
      "tldr_zh": "本研究提出了一种名为 MELT 的材料感知持续预训练方法，用于高效适应预训练语言模型 (PLMs) 到材料科学领域。不同于以往仅关注领域特定语料库的策略，MELT 通过构建语义图从科学语料中创建全面的材料知识库，并整合课程学习策略，从熟悉的通用概念逐步过渡到专业术语，从而优化训练过程。实验结果显示，MELT 在多种基准上表现出色，比现有持续预训练方法性能更优，并在材料实体表示方面显著提升，证明了其在材料科学领域的广泛适用性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at EMNLP 2024 (Findings)",
      "pdf_url": "http://arxiv.org/pdf/2410.15126v1",
      "published_date": "2024-10-19 14:49:03 UTC",
      "updated_date": "2024-10-19 14:49:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:45:04.286436"
    },
    {
      "arxiv_id": "2410.15116v1",
      "title": "Coarse-to-Fine Highlighting: Reducing Knowledge Hallucination in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Qitan Lv",
        "Jie Wang",
        "Hanzhu Chen",
        "Bin Li",
        "Yongdong Zhang",
        "Feng Wu"
      ],
      "abstract": "Generation of plausible but incorrect factual information, often termed\nhallucination, has attracted significant research interest. Retrieval-augmented\nlanguage model (RALM) -- which enhances models with up-to-date knowledge --\nemerges as a promising method to reduce hallucination. However, existing RALMs\nmay instead exacerbate hallucination when retrieving lengthy contexts. To\naddress this challenge, we propose COFT, a novel\n\\textbf{CO}arse-to-\\textbf{F}ine highligh\\textbf{T}ing method to focus on\ndifferent granularity-level key texts, thereby avoiding getting lost in lengthy\ncontexts. Specifically, COFT consists of three components: \\textit{recaller},\n\\textit{scorer}, and \\textit{selector}. First, \\textit{recaller} applies a\nknowledge graph to extract potential key entities in a given context. Second,\n\\textit{scorer} measures the importance of each entity by calculating its\ncontextual weight. Finally, \\textit{selector} selects high contextual weight\nentities with a dynamic threshold algorithm and highlights the corresponding\nparagraphs, sentences, or words in a coarse-to-fine manner. Extensive\nexperiments on the knowledge hallucination benchmark demonstrate the\neffectiveness of COFT, leading to a superior performance over $30\\%$ in the F1\nscore metric. Moreover, COFT also exhibits remarkable versatility across\nvarious long-form tasks, such as reading comprehension and question answering.",
      "tldr_zh": "该论文针对大型语言模型（Large Language Models）中的知识幻觉（hallucination）问题，提出了一种创新方法COFT（COarse-to-Fine Highlighting），通过粗到细的文本突出技术来减少模型在长上下文中的错误生成。COFT包括三个组件：recaller使用知识图谱提取关键实体、scorer计算实体的上下文权重，以及selector通过动态阈值算法选择并突出高权重文本，从而聚焦于不同粒度的关键信息。实验结果显示，COFT在知识幻觉基准测试中使F1分数提升超过30%，并在阅读理解和问答等长文本任务中表现出色。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15116v1",
      "published_date": "2024-10-19 13:59:48 UTC",
      "updated_date": "2024-10-19 13:59:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:45:16.926795"
    },
    {
      "arxiv_id": "2410.15115v3",
      "title": "On Designing Effective RL Reward at Training Time for LLM Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Jiaxuan Gao",
        "Shusheng Xu",
        "Wenjie Ye",
        "Weilin Liu",
        "Chuyi He",
        "Wei Fu",
        "Zhiyu Mei",
        "Guangju Wang",
        "Yi Wu"
      ],
      "abstract": "Reward models have been increasingly critical for improving the reasoning\ncapability of LLMs. Existing research has shown that a well-trained reward\nmodel can substantially improve model performances at inference time via\nsearch. However, the potential of reward models during RL training time still\nremains largely under-explored. It is currently unclear whether these reward\nmodels can provide additional training signals to enhance the reasoning\ncapabilities of LLMs in RL training that uses sparse success rewards, which\nverify the correctness of solutions. In this work, we evaluate popular reward\nmodels for RL training, including the Outcome-supervised Reward Model (ORM) and\nthe Process-supervised Reward Model (PRM), and train a collection of LLMs for\nmath problems using RL by combining these learned rewards with success rewards.\nSurprisingly, even though these learned reward models have strong\ninference-time performances, they may NOT help or even hurt RL training,\nproducing worse performances than LLMs trained with the success reward only.\nOur analysis reveals that an LLM can receive high rewards from some of these\nreward models by repeating correct but unnecessary reasoning steps, leading to\na severe reward hacking issue. Therefore, we introduce two novel reward\nrefinement techniques, including Clipping and Delta. The key idea is to ensure\nthe accumulative reward of any reasoning trajectory is upper-bounded to keep a\nlearned reward model effective without being exploited. We evaluate our\ntechniques with multiple reward models over a set of 1.5B and 7B LLMs on MATH\nand GSM8K benchmarks and demonstrate that with a carefully designed reward\nfunction, RL training without any additional supervised tuning can improve all\nthe evaluated LLMs, including the state-of-the-art 7B LLM\nQwen2.5-Math-7B-Instruct on MATH and GSM8K benchmarks.",
      "tldr_zh": "该研究探讨了在强化学习（RL）训练期间设计有效奖励函数，以提升大型语言模型（LLMs）的推理能力。作者评估了流行奖励模型如 Outcome-supervised Reward Model (ORM) 和 Process-supervised Reward Model (PRM)，发现这些模型在结合稀疏成功奖励的 RL 训练中，可能导致奖励操纵（reward hacking），从而损害模型性能。针对这一问题，论文引入了两种新技巧：Clipping 和 Delta，用于限制推理轨迹的累积奖励，确保奖励模型不被滥用。实验结果显示，在 MATH 和 GSM8K 基准上，这些优化后的奖励函数使多种 LLMs，包括 Qwen2.5-Math-7B-Instruct，提升了性能，且无需额外监督微调。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15115v3",
      "published_date": "2024-10-19 13:53:50 UTC",
      "updated_date": "2024-11-27 11:58:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:45:29.967952"
    },
    {
      "arxiv_id": "2410.15111v1",
      "title": "A Prompt Refinement-based Large Language Model for Metro Passenger Flow Forecasting under Delay Conditions",
      "title_zh": "基于提示精炼的大型语言模型，用于延误条件下地铁客流预测",
      "authors": [
        "Ping Huang",
        "Yuxin He",
        "Hao Wang",
        "Jingjing Chen",
        "Qin Luo"
      ],
      "abstract": "Accurate short-term forecasts of passenger flow in metro systems under delay\nconditions are crucial for emergency response and service recovery, which pose\nsignificant challenges and are currently under-researched. Due to the rare\noccurrence of delay events, the limited sample size under delay condictions\nmake it difficult for conventional models to effectively capture the complex\nimpacts of delays on passenger flow, resulting in low forecasting accuracy.\nRecognizing the strengths of large language models (LLMs) in few-shot learning\ndue to their powerful pre-training, contextual understanding, ability to\nperform zero-shot and few-shot reasoning, to address the issues that\neffectively generalize and adapt with minimal data, we propose a passenger flow\nforecasting framework under delay conditions that synthesizes an LLM with\ncarefully designed prompt engineering. By Refining prompt design, we enable the\nLLM to understand delay event information and the pattern from historical\npassenger flow data, thus overcoming the challenges of passenger flow\nforecasting under delay conditions. The propmpt engineering in the framework\nconsists of two main stages: systematic prompt generation and prompt\nrefinement. In the prompt generation stage, multi-source data is transformed\ninto descriptive texts understandable by the LLM and stored. In the prompt\nrefinement stage, we employ the multidimensional Chain of Thought (CoT) method\nto refine the prompts. We verify the proposed framework by conducting\nexperiments using real-world datasets specifically targeting passenger flow\nforecasting under delay conditions of Shenzhen metro in China. The experimental\nresults demonstrate that the proposed model performs particularly well in\nforecasting passenger flow under delay conditions.",
      "tldr_zh": "该研究针对地铁系统延误条件下客流预测的准确性问题，提出了一种基于 Large Language Model (LLMs) 的框架，利用精心设计的提示工程来应对样本稀少带来的挑战。该框架包括两个阶段：系统提示生成，将多源数据转化为 LLM 可理解的描述性文本；以及提示精炼，通过多维度的 Chain of Thought (CoT) 方法优化提示，使模型更好地理解延误事件和历史客流模式。实验使用中国深圳地铁的真实数据集进行验证，结果显示该模型在延误条件下表现出色，显著提升了预测准确率。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "14 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.15111v1",
      "published_date": "2024-10-19 13:46:46 UTC",
      "updated_date": "2024-10-19 13:46:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:45:40.509645"
    },
    {
      "arxiv_id": "2410.19834v1",
      "title": "GNNRL-Smoothing: A Prior-Free Reinforcement Learning Model for Mesh Smoothing",
      "title_zh": "翻译失败",
      "authors": [
        "Zhichao Wang",
        "Xinhai Chen",
        "Chunye Gong",
        "Bo Yang",
        "Liang Deng",
        "Yufei Sun",
        "Yufei Pang",
        "Jie Liu"
      ],
      "abstract": "Mesh smoothing methods can enhance mesh quality by eliminating distorted\nelements, leading to improved convergence in simulations. To balance the\nefficiency and robustness of traditional mesh smoothing process, previous\napproaches have employed supervised learning and reinforcement learning to\ntrain intelligent smoothing models. However, these methods heavily rely on\nlabeled dataset or prior knowledge to guide the models' learning. Furthermore,\ntheir limited capacity to enhance mesh connectivity often restricts the\neffectiveness of smoothing. In this paper, we first systematically analyze the\nlearning mechanisms of recent intelligent smoothing methods and propose a\nprior-free reinforcement learning model for intelligent mesh smoothing. Our\nproposed model integrates graph neural networks with reinforcement learning to\nimplement an intelligent node smoothing agent and introduces, for the first\ntime, a mesh connectivity improvement agent. We formalize mesh optimization as\na Markov Decision Process and successfully train both agents using Twin Delayed\nDeep Deterministic Policy Gradient and Double Dueling Deep Q-Network in the\nabsence of any prior data or knowledge. We verified the proposed model on both\n2D and 3D meshes. Experimental results demonstrate that our model achieves\nfeature-preserving smoothing on complex 3D surface meshes. It also achieves\nstate-of-the-art results among intelligent smoothing methods on 2D meshes and\nis 7.16 times faster than traditional optimization-based smoothing methods.\nMoreover, the connectivity improvement agent can effectively enhance the\nquality distribution of the mesh.",
      "tldr_zh": "该论文分析了现有网格平滑方法依赖标记数据集或先验知识的局限性，并提出 GNNRL-Smoothing，一种无先验知识的强化学习模型，用于智能网格平滑。模型整合图神经网络 (GNN) 和强化学习 (RL)，包括智能节点平滑代理和首次引入的网格连接性改善代理，并将网格优化形式化为 Markov Decision Process (MDP)，使用 Twin Delayed Deep Deterministic Policy Gradient (TD3) 和 Double Dueling Deep Q-Network (D3QN) 进行训练。实验结果显示，该模型在 2D 和 3D 网格上实现特征保留平滑，在 2D 网格中达到最先进性能，比传统优化方法快 7.16 倍，且连接性改善代理能有效提升网格质量分布。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.19834v1",
      "published_date": "2024-10-19 13:26:52 UTC",
      "updated_date": "2024-10-19 13:26:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:45:54.740724"
    },
    {
      "arxiv_id": "2410.15098v1",
      "title": "Incorporating Group Prior into Variational Inference for Tail-User Behavior Modeling in CTR Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Han Xu",
        "Taoxing Pan",
        "Zhiqiang Liu",
        "Xiaoxiao Xu",
        "Lantao Hu"
      ],
      "abstract": "User behavior modeling -- which aims to extract user interests from\nbehavioral data -- has shown great power in Click-through rate (CTR)\nprediction, a key component in recommendation systems. Recently,\nattention-based algorithms have become a promising direction, as attention\nmechanisms emphasize the relevant interactions from rich behaviors. However,\nthe methods struggle to capture the preferences of tail users with sparse\ninteraction histories. To address the problem, we propose a novel variational\ninference approach, namely Group Prior Sampler Variational Inference (GPSVI),\nwhich introduces group preferences as priors to refine latent user interests\nfor tail users. In GPSVI, the extent of adjustments depends on the estimated\nuncertainty of individual preference modeling. In addition, We further enhance\nthe expressive power of variational inference by a volume-preserving flow. An\nappealing property of the GPSVI method is its ability to revert to traditional\nattention for head users with rich behavioral data while consistently enhancing\nperformance for long-tail users with sparse behaviors. Rigorous analysis and\nextensive experiments demonstrate that GPSVI consistently improves the\nperformance of tail users. Moreover, online A/B testing on a large-scale\nreal-world recommender system further confirms the effectiveness of our\nproposed approach.",
      "tldr_zh": "这篇论文针对点击率 (CTR) 预测中的用户行为建模问题，提出了一种新方法 Group Prior Sampler Variational Inference (GPSVI)，通过引入群组偏好作为先验来优化尾部用户（行为数据稀疏）的潜在兴趣建模。GPSVI 的调整程度基于个体偏好建模的不确定性，并通过体积保持流 (volume-preserving flow) 增强变分推理的表达能力，其关键优势是为头部用户退化回传统注意力机制，同时提升尾部用户的性能。实验分析和大型推荐系统的在线 A/B 测试均证明了 GPSVI 在改善尾用户表现方面的有效性。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15098v1",
      "published_date": "2024-10-19 13:15:36 UTC",
      "updated_date": "2024-10-19 13:15:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:46:06.378807"
    },
    {
      "arxiv_id": "2410.15096v1",
      "title": "GDPO: Learning to Directly Align Language Models with Diversity Using GFlowNets",
      "title_zh": "翻译失败",
      "authors": [
        "Oh Joon Kwon",
        "Daiki E. Matsunaga",
        "Kee-Eung Kim"
      ],
      "abstract": "A critical component of the current generation of language models is\npreference alignment, which aims to precisely control the model's behavior to\nmeet human needs and values. The most notable among such methods is\nReinforcement Learning with Human Feedback (RLHF) and its offline variant\nDirect Preference Optimization (DPO), both of which seek to maximize a reward\nmodel based on human preferences. In particular, DPO derives reward signals\ndirectly from the offline preference data, but in doing so overfits the reward\nsignals and generates suboptimal responses that may contain human biases in the\ndataset. In this work, we propose a practical application of a\ndiversity-seeking RL algorithm called GFlowNet-DPO (GDPO) in an offline\npreference alignment setting to curtail such challenges. Empirical results show\nGDPO can generate far more diverse responses than the baseline methods that are\nstill relatively aligned with human values in dialog generation and\nsummarization tasks.",
      "tldr_zh": "本论文提出 GDPO，一种基于 GFlowNets 的多样性求解强化学习算法，用于直接对齐语言模型（Language Models），以解决现有方法如 Direct Preference Optimization (DPO) 的过拟合问题和潜在人类偏见。GDPO 在离线偏好对齐（Offline Preference Alignment）设置中，通过多样性导向的训练生成更丰富的响应，同时保持与人类价值观的兼容。实验结果显示，在对话生成和总结任务上，GDPO 比基线方法（如 DPO）提升了响应的多样性，同时维持了较高的对齐性能。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15096v1",
      "published_date": "2024-10-19 13:07:52 UTC",
      "updated_date": "2024-10-19 13:07:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:46:18.311899"
    },
    {
      "arxiv_id": "2410.15093v1",
      "title": "DPVS-Shapley:Faster and Universal Contribution Evaluation Component in Federated Learning",
      "title_zh": "DPVS-Shapley：联邦学习中更快且通用的贡献评估组件",
      "authors": [
        "Ketin Yin",
        "Zonghao Guo",
        "ZhengHan Qin"
      ],
      "abstract": "In the current era of artificial intelligence, federated learning has emerged\nas a novel approach to addressing data privacy concerns inherent in centralized\nlearning paradigms. This decentralized learning model not only mitigates the\nrisk of data breaches but also enhances the system's scalability and\nrobustness. However, this approach introduces a new challenge: how to fairly\nand accurately assess the contribution of each participant. Developing an\neffective contribution evaluation mechanism is crucial for federated learning.\nSuch a mechanism incentivizes participants to actively contribute their data\nand computational resources, thereby improving the overall performance of the\nfederated learning system. By allocating resources and rewards based on the\nsize of the contributions, it ensures that each participant receives fair\ntreatment, fostering sustained engagement.Currently, Shapley value-based\nmethods are widely used to evaluate participants' contributions, with many\nresearchers proposing modifications to adapt these methods to real-world\nscenarios. In this paper, we introduce a component called Dynamic Pruning\nValidation Set Shapley (DPVS-Shapley). This method accelerates the contribution\nassessment process by dynamically pruning the original dataset without\ncompromising the evaluation's accuracy. Furthermore, this component can assign\ndifferent weights to various samples, thereby allowing clients capable of\ndistinguishing difficult examples to receive higher contribution scores.",
      "tldr_zh": "本论文针对联邦学习中公平评估参与者贡献的挑战，提出了一种更高效的组件DPVS-Shapley，以Shapley value为基础动态修剪数据集，从而加速贡献评估过程，同时保持评估准确性。DPVS-Shapley允许为不同样本分配权重，让能有效处理困难样本的客户端获得更高贡献分数，从而激励参与者更积极贡献数据和资源。该方法提升了联邦学习的整体性能和可扩展性，为资源分配和奖励机制提供了更通用且公平的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "cs.GT"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15093v1",
      "published_date": "2024-10-19 13:01:44 UTC",
      "updated_date": "2024-10-19 13:01:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:46:28.370520"
    },
    {
      "arxiv_id": "2410.15086v1",
      "title": "Towards Safer Heuristics With XPlain",
      "title_zh": "翻译失败",
      "authors": [
        "Pantea Karimi",
        "Solal Pirelli",
        "Siva Kesava Reddy Kakarla",
        "Ryan Beckett",
        "Santiago Segarra",
        "Beibin Li",
        "Pooria Namyar",
        "Behnaz Arzani"
      ],
      "abstract": "Many problems that cloud operators solve are computationally expensive, and\noperators often use heuristic algorithms (that are faster and scale better than\noptimal) to solve them more efficiently. Heuristic analyzers enable operators\nto find when and by how much their heuristics underperform. However, these\ntools do not provide enough detail for operators to mitigate the heuristic's\nimpact in practice: they only discover a single input instance that causes the\nheuristic to underperform (and not the full set), and they do not explain why.\n  We propose XPlain, a tool that extends these analyzers and helps operators\nunderstand when and why their heuristics underperform. We present promising\ninitial results that show such an extension is viable.",
      "tldr_zh": "云操作员经常使用启发式算法(heuristics)来高效解决计算昂贵的难题，但这些算法可能在某些情况下表现不佳，而现有分析器仅能识别单一问题实例且不提供原因解释。作者提出XPlain工具，通过扩展这些分析器，帮助操作员全面理解启发式算法何时和为什么underperform。初步实验结果显示，这种扩展方法是可行的，为改进算法安全性提供了潜在途径。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.DC",
        "cs.NI",
        "cs.PF"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15086v1",
      "published_date": "2024-10-19 12:21:42 UTC",
      "updated_date": "2024-10-19 12:21:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:46:40.953209"
    },
    {
      "arxiv_id": "2410.15081v4",
      "title": "A Distribution Semantics for Probabilistic Term Rewriting",
      "title_zh": "翻译失败",
      "authors": [
        "Germán Vidal"
      ],
      "abstract": "Probabilistic programming is becoming increasingly popular thanks to its\nability to specify problems with a certain degree of uncertainty. In this work,\nwe focus on term rewriting, a well-known computational formalism. In\nparticular, we consider systems that combine traditional rewriting rules with\nprobabilities. Then, we define a novel \"distribution semantics\" for such\nsystems that can be used to model the probability of reducing a term to some\nvalue. We also show how to compute a set of \"explanations\" for a given\nreduction, which can be used to compute its probability in a more efficient\nway. Finally, we illustrate our approach with several examples and outline a\ncouple of extensions that may prove useful to improve the expressive power of\nprobabilistic rewrite systems.",
      "tldr_zh": "本论文探讨了概率编程在处理不确定性问题中的应用，特别针对术语重写（term rewriting）系统，提出了一种结合传统重写规则和概率的框架。核心贡献是定义了新型的distribution semantics，用于建模术语减少到特定值的概率，并引入计算“explanations”集的方法，以更高效地计算该概率。该方法通过几个例子进行说明，并概述了可能的扩展，以提升probabilistic term rewriting系统的表达能力。",
      "categories": [
        "cs.PL",
        "cs.AI"
      ],
      "primary_category": "cs.PL",
      "comment": "Submitted for publication",
      "pdf_url": "http://arxiv.org/pdf/2410.15081v4",
      "published_date": "2024-10-19 12:00:13 UTC",
      "updated_date": "2025-03-19 11:03:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:46:52.668211"
    },
    {
      "arxiv_id": "2410.15076v2",
      "title": "EPT-1.5 Technical Report",
      "title_zh": "EPT-1.5 技术报告",
      "authors": [
        "Roberto Molinaro",
        "Jordan Dane Daubinet",
        "Alexander Jakob Dautel",
        "Andreas Schlueter",
        "Alex Grigoryev",
        "Nikoo Ekhtiari",
        "Bas Steunebrink",
        "Kevin Thiart",
        "Roan John Song",
        "Henry Martin",
        "Leonie Wagner",
        "Andrea Giussani",
        "Marvin Vincent Gabler"
      ],
      "abstract": "We announce the release of EPT-1.5, the latest iteration in our Earth Physics\nTransformer (EPT) family of foundation AI earth system models. EPT-1.5\ndemonstrates substantial improvements over its predecessor, EPT-1. Built\nspecifically for the European energy industry, EPT-1.5 shows remarkable\nperformance in predicting energy-relevant variables, particularly 10m & 100m\nwind speed and solar radiation. Especially in wind prediction, it outperforms\nexisting AI weather models like GraphCast, FuXi, and Pangu-Weather, as well as\nthe leading numerical weather model, IFS HRES by the European Centre for\nMedium-Range Weather Forecasts (ECMWF), setting a new state of the art.",
      "tldr_zh": "我们发布 EPT-1.5，这是 Earth Physics Transformer (EPT) 系列的最新模型，在其前身 EPT-1 的基础上实现了显著改进，专为欧洲能源行业设计。EPT-1.5 在预测10m 和100m 风速以及太阳辐射等关键变量方面表现出色，尤其在风速预测上超越了现有 AI 天气模型如 GraphCast、FuXi 和 Pangu-Weather。相比领先的数值天气模型 IFS HRES，EPT-1.5 设立了新的行业标准，为能源相关应用提供了更准确的预测工具。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15076v2",
      "published_date": "2024-10-19 11:44:04 UTC",
      "updated_date": "2024-11-03 18:11:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:47:05.281774"
    },
    {
      "arxiv_id": "2410.15075v1",
      "title": "SLIC: Secure Learned Image Codec through Compressed Domain Watermarking to Defend Image Manipulation",
      "title_zh": "翻译失败",
      "authors": [
        "Chen-Hsiu Huang",
        "Ja-Ling Wu"
      ],
      "abstract": "The digital image manipulation and advancements in Generative AI, such as\nDeepfake, has raised significant concerns regarding the authenticity of images\nshared on social media. Traditional image forensic techniques, while helpful,\nare often passive and insufficient against sophisticated tampering methods.\nThis paper introduces the Secure Learned Image Codec (SLIC), a novel active\napproach to ensuring image authenticity through watermark embedding in the\ncompressed domain. SLIC leverages neural network-based compression to embed\nwatermarks as adversarial perturbations in the latent space, creating images\nthat degrade in quality upon re-compression if tampered with. This degradation\nacts as a defense mechanism against unauthorized modifications. Our method\ninvolves fine-tuning a neural encoder/decoder to balance watermark invisibility\nwith robustness, ensuring minimal quality loss for non-watermarked images.\nExperimental results demonstrate SLIC's effectiveness in generating visible\nartifacts in tampered images, thereby preventing their redistribution. This\nwork represents a significant step toward developing secure image codecs that\ncan be widely adopted to safeguard digital image integrity.",
      "tldr_zh": "该论文提出SLIC（Secure Learned Image Codec），一种主动方法，通过在压缩域嵌入watermark来防御图像操纵和Deepfake等生成AI威胁，确保图像真实性。SLIC利用神经网络压缩，将watermark作为adversarial perturbations嵌入潜空间，从而使篡改图像在重压缩时质量显著下降，生成可见伪影作为防御机制。实验结果显示，该方法在篡改图像上有效防止重新分发，并平衡了watermark的隐形性和鲁棒性，为保护数字图像完整性提供了重要进展。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "accepted by ACM Multimedia Asia 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.15075v1",
      "published_date": "2024-10-19 11:42:36 UTC",
      "updated_date": "2024-10-19 11:42:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:47:17.234031"
    },
    {
      "arxiv_id": "2410.15074v1",
      "title": "LLaVA-Ultra: Large Chinese Language and Vision Assistant for Ultrasound",
      "title_zh": "翻译失败",
      "authors": [
        "Xuechen Guo",
        "Wenhao Chai",
        "Shi-Yan Li",
        "Gaoang Wang"
      ],
      "abstract": "Multimodal Large Language Model (MLLM) has recently garnered attention as a\nprominent research focus. By harnessing powerful LLM, it facilitates a\ntransition of conversational generative AI from unimodal text to performing\nmultimodal tasks. This boom begins to significantly impact medical field.\nHowever, general visual language model (VLM) lacks sophisticated comprehension\nfor medical visual question answering (Med-VQA). Even models specifically\ntailored for medical domain tend to produce vague answers with weak visual\nrelevance. In this paper, we propose a fine-grained adaptive VLM architecture\nfor Chinese medical visual conversations through parameter-efficient tuning.\nSpecifically, we devise a fusion module with fine-grained vision encoders to\nachieve enhancement for subtle medical visual semantics. Then we note data\nredundancy common to medical scenes is ignored in most prior works. In cases of\na single text paired with multiple figures, we utilize weighted scoring with\nknowledge distillation to adaptively screen valid images mirroring text\ndescriptions. For execution, we leverage a large-scale multimodal Chinese\nultrasound dataset obtained from the hospital. We create instruction-following\ndata based on text from professional doctors, which ensures effective tuning.\nWith enhanced model and quality data, our Large Chinese Language and Vision\nAssistant for Ultrasound (LLaVA-Ultra) shows strong capability and robustness\nto medical scenarios. On three Med-VQA datasets, LLaVA-Ultra surpasses previous\nstate-of-the-art models on various metrics.",
      "tldr_zh": "本文提出 LLaVA-Ultra，一种针对中文超声图像的 Multimodal Large Language Model (MLLM)，旨在解决现有 Visual Language Model (VLM) 在医疗视觉问答 (Med-VQA) 中的问题，如答案模糊和视觉相关性弱。模型采用细粒度视觉编码器融合模块增强医疗语义，并通过加权评分和知识蒸馏筛选有效图像，同时利用大规模中文超声数据集和参数高效调优进行训练。实验结果显示，LLaVA-Ultra 在三个 Med-VQA 数据集上超越了先前最先进模型，在各种指标上表现出色。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15074v1",
      "published_date": "2024-10-19 11:38:31 UTC",
      "updated_date": "2024-10-19 11:38:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:47:30.222461"
    },
    {
      "arxiv_id": "2410.15073v1",
      "title": "Personalized Federated Learning with Adaptive Feature Aggregation and Knowledge Transfer",
      "title_zh": "基于自适应特征聚合和知识转移的个性化联邦学习",
      "authors": [
        "Keting Yin",
        "Jiayi Mao"
      ],
      "abstract": "Federated Learning(FL) is popular as a privacy-preserving machine learning\nparadigm for generating a single model on decentralized data. However,\nstatistical heterogeneity poses a significant challenge for FL. As a subfield\nof FL, personalized FL (pFL) has attracted attention for its ability to achieve\npersonalized models that perform well on non-independent and identically\ndistributed (Non-IID) data. However, existing pFL methods are limited in terms\nof leveraging the global model's knowledge to enhance generalization while\nachieving personalization on local data. To address this, we proposed a new\nmethod personalized Federated learning with Adaptive Feature Aggregation and\nKnowledge Transfer (FedAFK), to train better feature extractors while balancing\ngeneralization and personalization for participating clients, which improves\nthe performance of personalized models on Non-IID data. We conduct extensive\nexperiments on three datasets in two widely-used heterogeneous settings and\nshow the superior performance of our proposed method over thirteen\nstate-of-the-art baselines.",
      "tldr_zh": "本研究针对 Federated Learning (FL) 中统计异质性（statistical heterogeneity）的挑战，提出了一种新的 personalized FL (pFL) 方法 FedAFK，以提升在 Non-IID 数据上的模型性能。FedAFK 通过 Adaptive Feature Aggregation 和 Knowledge Transfer 技术，训练更有效的特征提取器，同时平衡全局泛化和本地个性化。实验结果显示，该方法在三个数据集和两种异质设置下，比 13 个最先进基线表现出色，提高了个性化模型的整体表现。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15073v1",
      "published_date": "2024-10-19 11:32:39 UTC",
      "updated_date": "2024-10-19 11:32:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:47:41.158590"
    },
    {
      "arxiv_id": "2410.15068v2",
      "title": "LLM-HDR: Bridging LLM-based Perception and Self-Supervision for Unpaired LDR-to-HDR Image Reconstruction",
      "title_zh": "翻译失败",
      "authors": [
        "Hrishav Bakul Barua",
        "Kalin Stefanov",
        "Lemuel Lai En Che",
        "Abhinav Dhall",
        "KokSheik Wong",
        "Ganesh Krishnasamy"
      ],
      "abstract": "The translation of Low Dynamic Range (LDR) to High Dynamic Range (HDR) images\nis an important computer vision task. There is a significant amount of research\nutilizing both conventional non-learning methods and modern data-driven\napproaches, focusing on using both single-exposed and multi-exposed LDR for HDR\nimage reconstruction. However, most current state-of-the-art methods require\nhigh-quality paired {LDR,HDR} datasets for model training. In addition, there\nis limited literature on using unpaired datasets for this task, that is, the\nmodel learns a mapping between domains, i.e., {LDR,HDR}. This paper proposes\nLLM-HDR, a method that integrates the perception of Large Language Models (LLM)\ninto a modified semantic- and cycle-consistent adversarial architecture that\nutilizes unpaired {LDR,HDR} datasets for training. The method introduces novel\nartifact- and exposure-aware generators to address visual artifact removal and\nan encoder and loss to address semantic consistency, another under-explored\ntopic. LLM-HDR is the first to use an LLM for the {LDR,HDR} translation task in\na self-supervised setup. The method achieves state-of-the-art performance\nacross several benchmark datasets and reconstructs high-quality HDR images. The\nofficial website of this work is available at:\nhttps://github.com/HrishavBakulBarua/LLM-HDR",
      "tldr_zh": "这篇论文提出 LLM-HDR 方法，将 Large Language Models (LLM) 的感知能力整合到自监督的语义和循环一致对抗架构中，用于处理 unpaired LDR 和 HDR 数据集的图像重建问题。该方法引入了 artifact- and exposure-aware generators 来去除视觉伪影并优化曝光，同时添加编码器和损失函数以确保语义一致性，这是该领域的首次尝试。实验结果表明，LLM-HDR 在多个基准数据集上达到了最先进性能，并成功重构高质量的 HDR 图像。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "cs.LG",
        "cs.RO",
        "Artificial intelligence, Computer vision, Machine learning, Deep\n  learning",
        "I.3.3; I.4.5"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15068v2",
      "published_date": "2024-10-19 11:11:58 UTC",
      "updated_date": "2025-03-11 06:46:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:47:54.293923"
    },
    {
      "arxiv_id": "2410.15064v1",
      "title": "A Prompt Engineering Approach and a Knowledge Graph based Framework for Tackling Legal Implications of Large Language Model Answers",
      "title_zh": "翻译失败",
      "authors": [
        "George Hannah",
        "Rita T. Sousa",
        "Ioannis Dasoulas",
        "Claudia d'Amato"
      ],
      "abstract": "With the recent surge in popularity of Large Language Models (LLMs), there is\nthe rising risk of users blindly trusting the information in the response, even\nin cases where the LLM recommends actions that have potential legal\nimplications and this may put the user in danger. We provide an empirical\nanalysis on multiple existing LLMs showing the urgency of the problem. Hence,\nwe propose a short-term solution consisting in an approach for isolating these\nlegal issues through prompt re-engineering. We further analyse the outcomes but\nalso the limitations of the prompt engineering based approach and we highlight\nthe need of additional resources for fully solving the problem We also propose\na framework powered by a legal knowledge graph (KG) to generate legal citations\nfor these legal issues, enriching the response of the LLM.",
      "tldr_zh": "本研究探讨了Large Language Models (LLMs) 回应中潜在法律风险的问题，用户可能盲目信任这些回应而面临危险。通过实证分析，论文证实了这一问题的紧迫性，并提出一种prompt engineering approach，通过重新设计提示来隔离法律问题。作者进一步分析了该方法的优势和局限性，强调需要额外资源来全面解决。随后，论文引入了一个基于legal knowledge graph (KG) 的框架，用于生成法律引用，从而丰富LLM的回应。该框架为提升LLM响应的可靠性和可信度提供了重要基础。",
      "categories": [
        "cs.AI",
        "I.2.1"
      ],
      "primary_category": "cs.AI",
      "comment": "27 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.15064v1",
      "published_date": "2024-10-19 10:59:50 UTC",
      "updated_date": "2024-10-19 10:59:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:48:05.279595"
    },
    {
      "arxiv_id": "2410.15054v1",
      "title": "A Dual-Fusion Cognitive Diagnosis Framework for Open Student Learning Environments",
      "title_zh": "翻译失败",
      "authors": [
        "Yuanhao Liu",
        "Shuo Liu",
        "Yimeng Liu",
        "Jingwen Yang",
        "Hong Qian"
      ],
      "abstract": "Cognitive diagnosis model (CDM) is a fundamental and upstream component in\nintelligent education. It aims to infer students' mastery levels based on\nhistorical response logs. However, existing CDMs usually follow the ID-based\nembedding paradigm, which could often diminish the effectiveness of CDMs in\nopen student learning environments. This is mainly because they can hardly\ndirectly infer new students' mastery levels or utilize new exercises or\nknowledge without retraining. Textual semantic information, due to its unified\nfeature space and easy accessibility, can help alleviate this issue.\nUnfortunately, directly incorporating semantic information may not benefit\nCDMs, since it does not capture response-relevant features and thus discards\nthe individual characteristics of each student. To this end, this paper\nproposes a dual-fusion cognitive diagnosis framework (DFCD) to address the\nchallenge of aligning two different modalities, i.e., textual semantic features\nand response-relevant features. Specifically, in DFCD, we first propose the\nexercise-refiner and concept-refiner to make the exercises and knowledge\nconcepts more coherent and reasonable via large language models. Then, DFCD\nencodes the refined features using text embedding models to obtain the semantic\ninformation. For response-related features, we propose a novel response matrix\nto fully incorporate the information within the response logs. Finally, DFCD\ndesigns a dual-fusion module to merge the two modal features. The ultimate\nrepresentations possess the capability of inference in open student learning\nenvironments and can be also plugged in existing CDMs. Extensive experiments\nacross real-world datasets show that DFCD achieves superior performance by\nintegrating different modalities and strong adaptability in open student\nlearning environments.",
      "tldr_zh": "本论文提出了一种双融合认知诊断框架 (DFCD)，旨在解决现有 Cognitive Diagnosis Models (CDMs) 在开放学生学习环境中的局限性，这些模型依赖 ID-based 嵌入范式，无法直接处理新学生或新练习而不需重新训练。DFCD 通过 exercise-refiner 和 concept-refiner 利用 large language models 提炼练习和知识概念的语义特征，并引入响应矩阵 (response matrix) 来整合学生响应日志中的相关信息。框架的核心是 dual-fusion module，它将文本语义特征与响应相关特征进行模态对齐融合，从而生成适用于开放环境的表示，并可无缝集成到现有 CDMs 中。实验在真实数据集上证明，DFCD 显著提升了性能和适应性，展示了其在智能教育中的潜力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15054v1",
      "published_date": "2024-10-19 10:12:02 UTC",
      "updated_date": "2024-10-19 10:12:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:48:19.499720"
    },
    {
      "arxiv_id": "2410.15052v4",
      "title": "GlitchMiner: Mining Glitch Tokens in Large Language Models via Gradient-based Discrete Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Zihui Wu",
        "Haichang Gao",
        "Ping Wang",
        "Shudong Zhang",
        "Zhaoxiang Liu",
        "Shiguo Lian"
      ],
      "abstract": "Glitch tokens in Large Language Models (LLMs) can trigger unpredictable\nbehaviors, threatening model reliability and safety. Existing detection methods\nrely on predefined patterns, limiting their adaptability across diverse LLM\narchitectures. We propose GlitchMiner, a gradient-based discrete optimization\nframework that efficiently identifies glitch tokens by introducing entropy as a\nmeasure of prediction uncertainty and employing a local search strategy to\nexplore the token space. Experiments across multiple LLM architectures\ndemonstrate that GlitchMiner outperforms existing methods in detection accuracy\nand adaptability, achieving over 10% average efficiency improvement. This\nmethod enhances vulnerability assessment in LLMs, contributing to the\ndevelopment of more robust and reliable applications. Code is available at\nhttps://github.com/wooozihui/GlitchMiner.",
      "tldr_zh": "本研究针对Large Language Models (LLMs)中的Glitch tokens可能引发的不可预测行为及其对模型可靠性和安全性的威胁，提出了一种名为GlitchMiner的框架。GlitchMiner采用gradient-based discrete optimization，通过引入entropy作为预测不确定性的度量，并结合local search strategy来高效探索token空间，从而提升检测的准确性和适应性。实验在多个LLM架构上验证，该方法比现有方法平均效率提升超过10%，有助于加强LLMs的vulnerability assessment并推动更robust和reliable的应用开发。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15052v4",
      "published_date": "2024-10-19 09:49:12 UTC",
      "updated_date": "2024-11-09 06:25:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:48:30.032773"
    },
    {
      "arxiv_id": "2410.15048v1",
      "title": "MorphAgent: Empowering Agents through Self-Evolving Profiles and Decentralized Collaboration",
      "title_zh": "翻译失败",
      "authors": [
        "Siyuan Lu",
        "Jiaqi Shao",
        "Bing Luo",
        "Tao Lin"
      ],
      "abstract": "Large Language Model (LLM) based multi-agent systems (MAS) have shown promise\nin tackling complex tasks, but often rely on predefined roles and centralized\ncoordination, limiting their adaptability to evolving challenges. This paper\nintroduces MorphAgent, a novel framework for decentralized multi-agent\ncollaboration that enables agents to dynamically evolve their roles and\ncapabilities. Our approach employs self-evolving agent profiles, optimized\nthrough three key metrics, guiding agents in refining their individual\nexpertise while maintaining complementary team dynamics. MorphAgent implements\na two-phase process: a warm-up phase for initial profile optimization, followed\nby a task execution phase where agents continuously adapt their roles based on\ntask feedback. Our experimental results show that MorphAgent outperforms\ntraditional static-role MAS in terms of task performance and adaptability to\nchanging requirements, paving the way for more robust and versatile multi-agent\ncollaborative systems. Our code will be publicly available at\n\\url{https://github.com/LINs-lab/learn2collaborate}.",
      "tldr_zh": "本文提出MorphAgent框架，用于提升多智能体系统（MAS）的适应性，通过自演化代理配置文件（self-evolving agent profiles）和分散式协作（decentralized collaboration），让代理动态调整角色和能力。框架基于三个关键指标优化代理的专业性，同时维护团队互补关系，采用两阶段过程：预热阶段（warm-up phase）进行初始优化，以及任务执行阶段根据反馈持续适应。实验结果表明，MorphAgent在任务性能和对变化要求的适应性上优于传统静态角色MAS，为更鲁棒的协作系统提供了新途径。代码将在GitHub上公开。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15048v1",
      "published_date": "2024-10-19 09:10:49 UTC",
      "updated_date": "2024-10-19 09:10:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:48:41.609853"
    },
    {
      "arxiv_id": "2410.15045v2",
      "title": "Distribution-Aware Compensation Design for Sustainable Data Rights in Machine Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Jiaqi Shao",
        "Tao Lin",
        "Bing Luo"
      ],
      "abstract": "Modern distributed learning systems face a critical challenge when clients\nrequest the removal of their data influence from trained models, as this\nprocess can significantly destabilize system performance and affect remaining\nparticipants. We propose an innovative mechanism that views this challenge\nthrough the lens of game theory, establishing a leader-follower framework where\na central coordinator provides strategic incentives to maintain system\nstability during data removal operations. Our approach quantifies the ripple\neffects of data removal through a comprehensive analytical model that captures\nboth system-wide and participant-specific impacts. We establish mathematical\nfoundations for measuring participant utility and system outcomes, revealing\ncritical insights into how data diversity influences both individual decisions\nand overall system stability. The framework incorporates a computationally\nefficient solution method that addresses the inherent complexity of optimizing\nparticipant interactions and resource allocation.",
      "tldr_zh": "本研究针对分布式学习系统中客户端数据移除请求可能导致系统性能不稳定和影响其他参与者的问题，提出了一种基于 game theory 的补偿设计机制，采用 leader-follower 框架，由中央协调器提供战略激励来维持系统稳定性。  \n该机制通过一个全面的分析模型量化数据移除的连锁效应，测量参与者 utility 和系统结果，并揭示数据多样性对个体决策和整体系统稳定的关键影响。  \n最终，该框架提供了一个计算高效的解决方案，优化参与者交互和资源分配，从而支持机器学习中可持续的数据权利管理。",
      "categories": [
        "cs.GT",
        "cs.AI"
      ],
      "primary_category": "cs.GT",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15045v2",
      "published_date": "2024-10-19 09:04:13 UTC",
      "updated_date": "2024-10-24 01:25:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:48:53.695993"
    },
    {
      "arxiv_id": "2410.15042v1",
      "title": "Adversarial Training: A Survey",
      "title_zh": "对抗训练：综述",
      "authors": [
        "Mengnan Zhao",
        "Lihe Zhang",
        "Jingwen Ye",
        "Huchuan Lu",
        "Baocai Yin",
        "Xinchao Wang"
      ],
      "abstract": "Adversarial training (AT) refers to integrating adversarial examples --\ninputs altered with imperceptible perturbations that can significantly impact\nmodel predictions -- into the training process. Recent studies have\ndemonstrated the effectiveness of AT in improving the robustness of deep neural\nnetworks against diverse adversarial attacks. However, a comprehensive overview\nof these developments is still missing. This survey addresses this gap by\nreviewing a broad range of recent and representative studies. Specifically, we\nfirst describe the implementation procedures and practical applications of AT,\nfollowed by a comprehensive review of AT techniques from three perspectives:\ndata enhancement, network design, and training configurations. Lastly, we\ndiscuss common challenges in AT and propose several promising directions for\nfuture research.",
      "tldr_zh": "这篇论文对 Adversarial Training (AT) 进行了全面调查，旨在填补现有概述的空白，通过整合对抗样本（inputs altered with imperceptible perturbations）来提升深度神经网络对各种攻击的鲁棒性。论文首先描述了 AT 的实施程序和实际应用，然后从数据增强、网络设计和训练配置三个角度审视了相关技术。最终，它讨论了 AT 的常见挑战，并提出了未来研究的潜在方向。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15042v1",
      "published_date": "2024-10-19 08:57:35 UTC",
      "updated_date": "2024-10-19 08:57:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:49:04.620199"
    },
    {
      "arxiv_id": "2410.15040v1",
      "title": "Retrieval Augmented Diffusion Model for Structure-informed Antibody Design and Optimization",
      "title_zh": "检索增强扩散模型用于结构指导的抗体设计和优化",
      "authors": [
        "Zichen Wang",
        "Yaokun Ji",
        "Jianing Tian",
        "Shuangjia Zheng"
      ],
      "abstract": "Antibodies are essential proteins responsible for immune responses in\norganisms, capable of specifically recognizing antigen molecules of pathogens.\nRecent advances in generative models have significantly enhanced rational\nantibody design. However, existing methods mainly create antibodies from\nscratch without template constraints, leading to model optimization challenges\nand unnatural sequences. To address these issues, we propose a\nretrieval-augmented diffusion framework, termed RADAb, for efficient antibody\ndesign. Our method leverages a set of structural homologous motifs that align\nwith query structural constraints to guide the generative model in inversely\noptimizing antibodies according to desired design criteria. Specifically, we\nintroduce a structure-informed retrieval mechanism that integrates these\nexemplar motifs with the input backbone through a novel dual-branch denoising\nmodule, utilizing both structural and evolutionary information. Additionally,\nwe develop a conditional diffusion model that iteratively refines the\noptimization process by incorporating both global context and local\nevolutionary conditions. Our approach is agnostic to the choice of generative\nmodels. Empirical experiments demonstrate that our method achieves\nstate-of-the-art performance in multiple antibody inverse folding and\noptimization tasks, offering a new perspective on biomolecular generative\nmodels.",
      "tldr_zh": "本文提出了一种检索增强扩散框架RADAb，用于基于结构的抗体设计和优化，以解决现有生成模型从零创建抗体导致的优化挑战和不自然序列问题。该框架通过结构信息检索机制和双分支去噪模块，整合结构同源基序（structural homologous motifs）与输入主链，利用结构和进化信息指导条件扩散模型的迭代精炼过程。该方法在多个抗体逆折叠和优化任务中实现最先进性能，为生物分子生成模型提供了新视角。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15040v1",
      "published_date": "2024-10-19 08:53:01 UTC",
      "updated_date": "2024-10-19 08:53:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:49:17.164132"
    },
    {
      "arxiv_id": "2410.15038v3",
      "title": "A Multimodal Vision Foundation Model for Clinical Dermatology",
      "title_zh": "一种用于临床皮肤科的多模态视觉基础模型",
      "authors": [
        "Siyuan Yan",
        "Zhen Yu",
        "Clare Primiero",
        "Cristina Vico-Alonso",
        "Zhonghua Wang",
        "Litao Yang",
        "Philipp Tschandl",
        "Ming Hu",
        "Lie Ju",
        "Gin Tan",
        "Vincent Tang",
        "Aik Beng Ng",
        "David Powell",
        "Paul Bonnington",
        "Simon See",
        "Elisabetta Magnaterra",
        "Peter Ferguson",
        "Jennifer Nguyen",
        "Pascale Guitera",
        "Jose Banuls",
        "Monika Janda",
        "Victoria Mar",
        "Harald Kittler",
        "H. Peter Soyer",
        "Zongyuan Ge"
      ],
      "abstract": "Diagnosing and treating skin diseases require advanced visual skills across\ndomains and the ability to synthesize information from multiple imaging\nmodalities. While current deep learning models excel at specific tasks like\nskin cancer diagnosis from dermoscopic images, they struggle to meet the\ncomplex, multimodal requirements of clinical practice. Here, we introduce\nPanDerm, a multimodal dermatology foundation model pretrained through\nself-supervised learning on over 2 million real-world skin disease images from\n11 clinical institutions across 4 imaging modalities. We evaluated PanDerm on\n28 diverse benchmarks, including skin cancer screening, risk stratification,\ndifferential diagnosis of common and rare skin conditions, lesion segmentation,\nlongitudinal monitoring, and metastasis prediction and prognosis. PanDerm\nachieved state-of-the-art performance across all evaluated tasks, often\noutperforming existing models when using only 10% of labeled data. We conducted\nthree reader studies to assess PanDerm's potential clinical utility. PanDerm\noutperformed clinicians by 10.2% in early-stage melanoma detection through\nlongitudinal analysis, improved clinicians' skin cancer diagnostic accuracy by\n11% on dermoscopy images, and enhanced non-dermatologist healthcare providers'\ndifferential diagnosis by 16.5% across 128 skin conditions on clinical\nphotographs. These results demonstrate PanDerm's potential to improve patient\ncare across diverse clinical scenarios and serve as a model for developing\nmultimodal foundation models in other medical specialties, potentially\naccelerating the integration of AI support in healthcare. The code can be found\nat https://github.com/SiyuanYan1/PanDerm.",
      "tldr_zh": "本文提出PanDerm，一种多模态视觉基础模型，通过自监督学习(self-supervised learning)在超过200万张真实世界皮肤病图像上预训练，旨在解决临床皮肤病诊断中跨领域视觉技能和多模态信息合成的挑战。PanDerm在28个多样化基准上，包括皮肤癌筛查、鉴别诊断和病变分割等方面，达到了最先进性能，往往只需10%的标注数据就优于现有模型。在临床读者研究中，PanDerm提升了医生的诊断准确率，例如在早期黑色素瘤检测上比临床医生高10.2%，并在皮肤镜图像和临床照片上显著改善非皮肤科医生的鉴别诊断。这些结果证明了PanDerm在提升患者护理和推动医疗AI应用方面的潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "74 pages; Preprint; The code can be found at\n  https://github.com/SiyuanYan1/PanDerm",
      "pdf_url": "http://arxiv.org/pdf/2410.15038v3",
      "published_date": "2024-10-19 08:48:01 UTC",
      "updated_date": "2025-04-13 05:58:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:49:30.373647"
    },
    {
      "arxiv_id": "2410.15029v2",
      "title": "Enhancing Multimodal Sentiment Analysis for Missing Modality through Self-Distillation and Unified Modality Cross-Attention",
      "title_zh": "通过自蒸馏和统一模态交叉注意力增强缺失模态的多模态情感分析",
      "authors": [
        "Yuzhe Weng",
        "Haotian Wang",
        "Tian Gao",
        "Kewei Li",
        "Shutong Niu",
        "Jun Du"
      ],
      "abstract": "In multimodal sentiment analysis, collecting text data is often more\nchallenging than video or audio due to higher annotation costs and inconsistent\nautomatic speech recognition (ASR) quality. To address this challenge, our\nstudy has developed a robust model that effectively integrates multimodal\nsentiment information, even in the absence of text modality. Specifically, we\nhave developed a Double-Flow Self-Distillation Framework, including Unified\nModality Cross-Attention (UMCA) and Modality Imagination Autoencoder (MIA),\nwhich excels at processing both scenarios with complete modalities and those\nwith missing text modality. In detail, when the text modality is missing, our\nframework uses the LLM-based model to simulate the text representation from the\naudio modality, while the MIA module supplements information from the other two\nmodalities to make the simulated text representation similar to the real text\nrepresentation. To further align the simulated and real representations, and to\nenable the model to capture the continuous nature of sample orders in sentiment\nvalence regression tasks, we have also introduced the Rank-N Contrast (RNC)\nloss function. When testing on the CMU-MOSEI, our model achieved outstanding\nperformance on MAE and significantly outperformed other models when text\nmodality is missing. The code is available at:\nhttps://github.com/WarmCongee/SDUMC",
      "tldr_zh": "本研究针对多模态情感分析中文本模态缺失的问题，提出了一种基于自蒸馏的鲁棒模型，包括Unified Modality Cross-Attention (UMCA)和Modality Imagination Autoencoder (MIA)的Double-Flow Self-Distillation Framework。该框架在文本缺失时，利用LLM-based模型从音频模态模拟文本表示，并通过MIA模块补充其他模态信息，同时引入Rank-N Contrast (RNC)损失函数来对齐模拟与真实表示，并处理情感值回归任务的连续性。在CMU-MOSEI数据集上，模型在MAE指标上表现出色，尤其在缺少文本模态时，显著优于其他基线模型。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15029v2",
      "published_date": "2024-10-19 07:59:41 UTC",
      "updated_date": "2025-03-24 08:50:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:49:41.607817"
    },
    {
      "arxiv_id": "2410.15028v3",
      "title": "A Novel Reinforcement Learning Model for Post-Incident Malware Investigations",
      "title_zh": "翻译失败",
      "authors": [
        "Dipo Dunsin",
        "Mohamed Chahine Ghanem",
        "Karim Ouazzane",
        "Vassil Vassilev"
      ],
      "abstract": "This Research proposes a Novel Reinforcement Learning (RL) model to optimise\nmalware forensics investigation during cyber incident response. It aims to\nimprove forensic investigation efficiency by reducing false negatives and\nadapting current practices to evolving malware signatures. The proposed RL\nframework leverages techniques such as Q-learning and the Markov Decision\nProcess (MDP) to train the system to identify malware patterns in live memory\ndumps, thereby automating forensic tasks. The RL model is based on a detailed\nmalware workflow diagram that guides the analysis of malware artefacts using\nstatic and behavioural techniques as well as machine learning algorithms.\nFurthermore, it seeks to address challenges in the UK justice system by\nensuring the accuracy of forensic evidence. We conduct testing and evaluation\nin controlled environments, using datasets created with Windows operating\nsystems to simulate malware infections. The experimental results demonstrate\nthat RL improves malware detection rates compared to conventional methods, with\nthe RL model's performance varying depending on the complexity and learning\nrate of the environment. The study concludes that while RL offers promising\npotential for automating malware forensics, its efficacy across diverse malware\ntypes requires ongoing refinement of reward systems and feature extraction\nmethods.",
      "tldr_zh": "这篇论文提出了一种新型强化学习 (RL) 模型，用于优化网络事件响应中的恶意软件取证调查，旨在提高效率、减少假阴性并适应演变的恶意软件签名。模型基于 Q-learning 和 Markov Decision Process (MDP) 等技术，结合静态和行为分析以及机器学习算法，来自动识别实时内存转储中的恶意软件模式，并通过详细的恶意软件工作流图指导分析过程。实验结果显示，该 RL 框架在模拟 Windows 环境的数据集上显著提升了检测率，但其性能受环境复杂性和学习率影响，需要进一步完善奖励系统和特征提取方法，以适应多样化的恶意软件类型。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "v3, 8 pages. arXiv admin note: substantial text overlap with\n  arXiv:2408.01999",
      "pdf_url": "http://arxiv.org/pdf/2410.15028v3",
      "published_date": "2024-10-19 07:59:10 UTC",
      "updated_date": "2025-01-12 12:24:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:49:53.780972"
    },
    {
      "arxiv_id": "2410.15026v1",
      "title": "A Recommendation Model Utilizing Separation Embedding and Self-Attention for Feature Mining",
      "title_zh": "翻译失败",
      "authors": [
        "Wenyi Liu",
        "Rui Wang",
        "Yuanshuai Luo",
        "Jianjun Wei",
        "Zihao Zhao",
        "Junming Huang"
      ],
      "abstract": "With the explosive growth of Internet data, users are facing the problem of\ninformation overload, which makes it a challenge to efficiently obtain the\nrequired resources. Recommendation systems have emerged in this context. By\nfiltering massive amounts of information, they provide users with content that\nmeets their needs, playing a key role in scenarios such as advertising\nrecommendation and product recommendation. However, traditional click-through\nrate prediction and TOP-K recommendation mechanisms are gradually unable to\nmeet the recommendations needs in modern life scenarios due to high\ncomputational complexity, large memory consumption, long feature selection\ntime, and insufficient feature interaction. This paper proposes a\nrecommendations system model based on a separation embedding cross-network. The\nmodel uses an embedding neural network layer to transform sparse feature\nvectors into dense embedding vectors, and can independently perform feature\ncross operations on different dimensions, thereby improving the accuracy and\ndepth of feature mining. Experimental results show that the model shows\nstronger adaptability and higher prediction accuracy in processing complex data\nsets, effectively solving the problems existing in existing models.",
      "tldr_zh": "该论文针对互联网信息过载问题，提出了一种基于分离嵌入(separation embedding)和自注意力(self-attention)的推荐系统模型，用于提升特征挖掘效率。模型通过嵌入神经网络层(embedding neural network)将稀疏特征向量转化为密集嵌入向量，并在不同维度上独立进行特征交叉操作，从而解决传统点击率预测和TOP-K推荐机制的计算复杂度高、内存消耗大等问题。实验结果表明，该模型在处理复杂数据集时表现出更强的适应性和更高的预测准确率。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15026v1",
      "published_date": "2024-10-19 07:49:21 UTC",
      "updated_date": "2024-10-19 07:49:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:50:04.706899"
    },
    {
      "arxiv_id": "2410.15025v1",
      "title": "LLM-Driven Learning Analytics Dashboard for Teachers in EFL Writing Education",
      "title_zh": "LLM 驱动的学习分析仪表板，针对 EFL 写作教育的教师",
      "authors": [
        "Minsun Kim",
        "SeonGyeom Kim",
        "Suyoun Lee",
        "Yoosang Yoon",
        "Junho Myung",
        "Haneul Yoo",
        "Hyunseung Lim",
        "Jieun Han",
        "Yoonsu Kim",
        "So-Yeon Ahn",
        "Juho Kim",
        "Alice Oh",
        "Hwajung Hong",
        "Tak Yeon Lee"
      ],
      "abstract": "This paper presents the development of a dashboard designed specifically for\nteachers in English as a Foreign Language (EFL) writing education. Leveraging\nLLMs, the dashboard facilitates the analysis of student interactions with an\nessay writing system, which integrates ChatGPT for real-time feedback. The\ndashboard aids teachers in monitoring student behavior, identifying\nnoneducational interaction with ChatGPT, and aligning instructional strategies\nwith learning objectives. By combining insights from NLP and Human-Computer\nInteraction (HCI), this study demonstrates how a human-centered approach can\nenhance the effectiveness of teacher dashboards, particularly in\nChatGPT-integrated learning.",
      "tldr_zh": "本研究开发了一个基于 LLM（Large Language Models）的学习分析仪表板，专门针对 EFL（English as a Foreign Language）写作教育的教师。该仪表板利用 ChatGPT 提供的实时反馈分析学生与作文写作系统的互动，帮助教师监控学生行为、识别非教育性 ChatGPT 使用，并优化教学策略以符合学习目标。通过整合 NLP（Natural Language Processing）和 HCI（Human-Computer Interaction）的见解，该研究证明了人性化方法能显著提升仪表板在 ChatGPT 整合学习环境中的有效性。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "EMNLP 2024 Workshop CustomNLP4U. arXiv admin note: text overlap with\n  arXiv:2405.19691",
      "pdf_url": "http://arxiv.org/pdf/2410.15025v1",
      "published_date": "2024-10-19 07:46:11 UTC",
      "updated_date": "2024-10-19 07:46:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:50:16.814998"
    },
    {
      "arxiv_id": "2410.15017v1",
      "title": "DM-Codec: Distilling Multimodal Representations for Speech Tokenization",
      "title_zh": "DM-Codec：用于语音标记化的多模态表示蒸馏",
      "authors": [
        "Md Mubtasim Ahasan",
        "Md Fahim",
        "Tasnim Mohiuddin",
        "A K M Mahbubur Rahman",
        "Aman Chadha",
        "Tariq Iqbal",
        "M Ashraful Amin",
        "Md Mofijul Islam",
        "Amin Ahsan Ali"
      ],
      "abstract": "Recent advancements in speech-language models have yielded significant\nimprovements in speech tokenization and synthesis. However, effectively mapping\nthe complex, multidimensional attributes of speech into discrete tokens remains\nchallenging. This process demands acoustic, semantic, and contextual\ninformation for precise speech representations. Existing speech representations\ngenerally fall into two categories: acoustic tokens from audio codecs and\nsemantic tokens from speech self-supervised learning models. Although recent\nefforts have unified acoustic and semantic tokens for improved performance,\nthey overlook the crucial role of contextual representation in comprehensive\nspeech modeling. Our empirical investigations reveal that the absence of\ncontextual representations results in elevated Word Error Rate (WER) and Word\nInformation Lost (WIL) scores in speech transcriptions. To address these\nlimitations, we propose two novel distillation approaches: (1) a language model\n(LM)-guided distillation method that incorporates contextual information, and\n(2) a combined LM and self-supervised speech model (SM)-guided distillation\ntechnique that effectively distills multimodal representations (acoustic,\nsemantic, and contextual) into a comprehensive speech tokenizer, termed\nDM-Codec. The DM-Codec architecture adopts a streamlined encoder-decoder\nframework with a Residual Vector Quantizer (RVQ) and incorporates the LM and SM\nduring the training process. Experiments show DM-Codec significantly\noutperforms state-of-the-art speech tokenization models, reducing WER by up to\n13.46%, WIL by 9.82%, and improving speech quality by 5.84% and intelligibility\nby 1.85% on the LibriSpeech benchmark dataset. The code, samples, and model\ncheckpoints are available at https://github.com/mubtasimahasan/DM-Codec.",
      "tldr_zh": "本研究针对语音标记化的挑战，提出 DM-Codec 框架，通过蒸馏多模态表示（包括声学、语义和上下文信息）来解决现有方法忽略上下文表示的问题，从而降低 Word Error Rate (WER) 和 Word Information Lost (WIL)。该框架采用两种新颖的蒸馏方法：(1) 语言模型 (LM) 引导的蒸馏，(2) 结合 LM 和自监督语音模型 (SM) 的联合蒸馏，并使用简化的编码器-解码器架构及 Residual Vector Quantizer (RVQ) 进行训练。实验结果显示，DM-Codec 在 LibriSpeech 数据集上比最先进模型减少 WER 13.46%、WIL 9.82%、并提升语音质量 5.84% 和可懂度 1.85%，显著提高了语音标记化和合成的整体性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15017v1",
      "published_date": "2024-10-19 07:14:14 UTC",
      "updated_date": "2024-10-19 07:14:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:50:30.988217"
    },
    {
      "arxiv_id": "2410.15016v1",
      "title": "Transit Pulse: Utilizing Social Media as a Source for Customer Feedback and Information Extraction with Large Language Model",
      "title_zh": "翻译失败",
      "authors": [
        "Jiahao Wang",
        "Amer Shalaby"
      ],
      "abstract": "Users of the transit system flood social networks daily with messages that\ncontain valuable insights crucial for improving service quality. These posts\nhelp transit agencies quickly identify emerging issues. Parsing topics and\nsentiments is key to gaining comprehensive insights to foster service\nexcellence. However, the volume of messages makes manual analysis impractical,\nand standard NLP techniques like Term Frequency-Inverse Document Frequency\n(TF-IDF) fall short in nuanced interpretation. Traditional sentiment analysis\nseparates topics and sentiments before integrating them, often missing the\ninteraction between them. This incremental approach complicates classification\nand reduces analytical productivity. To address these challenges, we propose a\nnovel approach to extracting and analyzing transit-related information,\nincluding sentiment and sarcasm detection, identification of unusual system\nproblems, and location data from social media. Our method employs Large\nLanguage Models (LLM), specifically Llama 3, for a streamlined analysis free\nfrom pre-established topic labels. To enhance the model's domain-specific\nknowledge, we utilize Retrieval-Augmented Generation (RAG), integrating\nexternal knowledge sources into the information extraction pipeline. We\nvalidated our method through extensive experiments comparing its performance\nwith traditional NLP approaches on user tweet data from the real world transit\nsystem. Our results demonstrate the potential of LLMs to transform social media\ndata analysis in the public transit domain, providing actionable insights and\nenhancing transit agencies' responsiveness by extracting a broader range of\ninformation.",
      "tldr_zh": "该研究提出“Transit Pulse”方法，利用Large Language Models (LLM)，特别是Llama 3，从社交媒体中提取交通用户反馈，包括情感分析、讽刺检测、异常问题识别和位置数据，以解决传统NLP技术如TF-IDF在处理主题与情感互动时的局限性。方法采用Retrieval-Augmented Generation (RAG)来增强模型的领域知识，实现无预设主题标签的流畅分析。实验结果显示，该方法在真实交通系统推文数据上优于传统NLP方法，提供更全面的可操作见解，并提升交通机构的响应效率。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.IR",
        "cs.LG",
        "cs.SI"
      ],
      "primary_category": "cs.CL",
      "comment": "17 pages, 21 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.15016v1",
      "published_date": "2024-10-19 07:08:40 UTC",
      "updated_date": "2024-10-19 07:08:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:50:41.253027"
    },
    {
      "arxiv_id": "2410.15013v1",
      "title": "DST-TransitNet: A Dynamic Spatio-Temporal Deep Learning Model for Scalable and Efficient Network-Wide Prediction of Station-Level Transit Ridership",
      "title_zh": "翻译失败",
      "authors": [
        "Jiahao Wang",
        "Amer Shalaby"
      ],
      "abstract": "Accurate prediction of public transit ridership is vital for efficient\nplanning and management of transit in rapidly growing urban areas in Canada.\nUnexpected increases in passengers can cause overcrowded vehicles, longer\nboarding times, and service disruptions. Traditional time series models like\nARIMA and SARIMA face limitations, particularly in short-term predictions and\nintegration of spatial and temporal features. These models struggle with the\ndynamic nature of ridership patterns and often ignore spatial correlations\nbetween nearby stops. Deep Learning (DL) models present a promising\nalternative, demonstrating superior performance in short-term prediction tasks\nby effectively capturing both spatial and temporal features. However,\nchallenges such as dynamic spatial feature extraction, balancing accuracy with\ncomputational efficiency, and ensuring scalability remain.\n  This paper introduces DST-TransitNet, a hybrid DL model for system-wide\nstation-level ridership prediction. This proposed model uses graph neural\nnetworks (GNN) and recurrent neural networks (RNN) to dynamically integrate the\nchanging temporal and spatial correlations within the stations. The model also\nemploys a precise time series decomposition framework to enhance accuracy and\ninterpretability. Tested on Bogota's BRT system data, with three distinct\nsocial scenarios, DST-TransitNet outperformed state-of-the-art models in\nprecision, efficiency and robustness. Meanwhile, it maintains stability over\nlong prediction intervals, demonstrating practical applicability.",
      "tldr_zh": "本研究针对公共交通客流预测的挑战，提出了一种动态时空深度学习模型DST-TransitNet，以提升城市交通系统的规划和管理。DST-TransitNet结合Graph Neural Networks (GNN)和Recurrent Neural Networks (RNN)，动态整合站点间的空间相关性和时间变化，同时采用精确的时间序列分解框架，提高预测的准确性和可解释性。实验在波哥大的BRT系统数据上进行，该模型在三种社会场景下，超越了传统模型如ARIMA和SARIMA，在精度、效率、鲁棒性和可扩展性方面表现出色，并保持长期预测的稳定性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "16 pages, 22 figures. Accepted by TRB 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.15013v1",
      "published_date": "2024-10-19 06:59:39 UTC",
      "updated_date": "2024-10-19 06:59:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:50:53.418956"
    },
    {
      "arxiv_id": "2410.15012v1",
      "title": "Pathologist-like explainable AI for interpretable Gleason grading in prostate cancer",
      "title_zh": "类似于病理学家的可解释人工智能，用于前列腺癌的可解释格里森分级",
      "authors": [
        "Gesa Mittmann",
        "Sara Laiouar-Pedari",
        "Hendrik A. Mehrtens",
        "Sarah Haggenmüller",
        "Tabea-Clara Bucher",
        "Tirtha Chanda",
        "Nadine T. Gaisa",
        "Mathias Wagner",
        "Gilbert Georg Klamminger",
        "Tilman T. Rau",
        "Christina Neppl",
        "Eva Maria Compérat",
        "Andreas Gocht",
        "Monika Hämmerle",
        "Niels J. Rupp",
        "Jula Westhoff",
        "Irene Krücken",
        "Maximillian Seidl",
        "Christian M. Schürch",
        "Marcus Bauer",
        "Wiebke Solass",
        "Yu Chun Tam",
        "Florian Weber",
        "Rainer Grobholz",
        "Jaroslaw Augustyniak",
        "Thomas Kalinski",
        "Christian Hörner",
        "Kirsten D. Mertz",
        "Constanze Döring",
        "Andreas Erbersdobler",
        "Gabriele Deubler",
        "Felix Bremmer",
        "Ulrich Sommer",
        "Michael Brodhun",
        "Jon Griffin",
        "Maria Sarah L. Lenon",
        "Kiril Trpkov",
        "Liang Cheng",
        "Fei Chen",
        "Angelique Levi",
        "Guoping Cai",
        "Tri Q. Nguyen",
        "Ali Amin",
        "Alessia Cimadamore",
        "Ahmed Shabaik",
        "Varsha Manucha",
        "Nazeel Ahmad",
        "Nidia Messias",
        "Francesca Sanguedolce",
        "Diana Taheri",
        "Ezra Baraban",
        "Liwei Jia",
        "Rajal B. Shah",
        "Farshid Siadat",
        "Nicole Swarbrick",
        "Kyung Park",
        "Oudai Hassan",
        "Siamak Sakhaie",
        "Michelle R. Downes",
        "Hiroshi Miyamoto",
        "Sean R. Williamson",
        "Tim Holland-Letz",
        "Carolin V. Schneider",
        "Jakob Nikolas Kather",
        "Yuri Tolkach",
        "Titus J. Brinker"
      ],
      "abstract": "The aggressiveness of prostate cancer, the most common cancer in men\nworldwide, is primarily assessed based on histopathological data using the\nGleason scoring system. While artificial intelligence (AI) has shown promise in\naccurately predicting Gleason scores, these predictions often lack inherent\nexplainability, potentially leading to distrust in human-machine interactions.\nTo address this issue, we introduce a novel dataset of 1,015 tissue microarray\ncore images, annotated by an international group of 54 pathologists. The\nannotations provide detailed localized pattern descriptions for Gleason grading\nin line with international guidelines. Utilizing this dataset, we develop an\ninherently explainable AI system based on a U-Net architecture that provides\npredictions leveraging pathologists' terminology. This approach circumvents\npost-hoc explainability methods while maintaining or exceeding the performance\nof methods trained directly for Gleason pattern segmentation (Dice score: 0.713\n$\\pm$ 0.003 trained on explanations vs. 0.691 $\\pm$ 0.010 trained on Gleason\npatterns). By employing soft labels during training, we capture the intrinsic\nuncertainty in the data, yielding strong results in Gleason pattern\nsegmentation even in the context of high interobserver variability. With the\nrelease of this dataset, we aim to encourage further research into segmentation\nin medical tasks with high levels of subjectivity and to advance the\nunderstanding of pathologists' reasoning processes.",
      "tldr_zh": "本研究针对前列腺癌的Gleason评分系统，开发了一种类似病理学家的可解释AI系统，以解决传统AI预测缺乏内在解释性的问题。该系统利用一个新数据集，包含1,015张组织微阵列核心图像，由54位国际病理学家标注，提供详细的本地化模式描述。基于U-Net架构，该AI采用病理学家的术语进行预测，并通过软标签捕获数据不确定性，实现Gleason模式分割的Dice分数为0.713 ± 0.003，优于直接训练的基线方法（0.691 ± 0.010）。通过发布此数据集，该研究旨在推动对主观性强医疗任务的分割研究，并加深对病理学家推理过程的理解。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "58 pages, 15 figures (incl. supplementary)",
      "pdf_url": "http://arxiv.org/pdf/2410.15012v1",
      "published_date": "2024-10-19 06:58:26 UTC",
      "updated_date": "2024-10-19 06:58:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:51:06.277861"
    },
    {
      "arxiv_id": "2410.15010v1",
      "title": "FlexMol: A Flexible Toolkit for Benchmarking Molecular Relational Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Sizhe Liu",
        "Jun Xia",
        "Lecheng Zhang",
        "Yuchen Liu",
        "Yue Liu",
        "Wenjie Du",
        "Zhangyang Gao",
        "Bozhen Hu",
        "Cheng Tan",
        "Hongxin Xiang",
        "Stan Z. Li"
      ],
      "abstract": "Molecular relational learning (MRL) is crucial for understanding the\ninteraction behaviors between molecular pairs, a critical aspect of drug\ndiscovery and development. However, the large feasible model space of MRL poses\nsignificant challenges to benchmarking, and existing MRL frameworks face\nlimitations in flexibility and scope. To address these challenges, avoid\nrepetitive coding efforts, and ensure fair comparison of models, we introduce\nFlexMol, a comprehensive toolkit designed to facilitate the construction and\nevaluation of diverse model architectures across various datasets and\nperformance metrics. FlexMol offers a robust suite of preset model components,\nincluding 16 drug encoders, 13 protein sequence encoders, 9 protein structure\nencoders, and 7 interaction layers. With its easy-to-use API and flexibility,\nFlexMol supports the dynamic construction of over 70, 000 distinct combinations\nof model architectures. Additionally, we provide detailed benchmark results and\ncode examples to demonstrate FlexMol's effectiveness in simplifying and\nstandardizing MRL model development and comparison.",
      "tldr_zh": "该研究介绍了 FlexMol，一种灵活的工具包，用于基准测试 Molecular Relational Learning (MRL)，以解决分子对交互行为建模在药物发现中的挑战，如模型空间庞大和现有框架的灵活性不足。FlexMol 提供了一系列预设组件，包括 16 个药物编码器、13 个蛋白质序列编码器、9 个蛋白质结构编码器和 7 个交互层，支持动态构建超过 70,000 种模型架构组合，并通过易用 API 简化模型建设和评估。实验基准结果和代码示例展示了 FlexMol 在标准化 MRL 模型开发和公平比较方面的有效性，从而减少了重复编码工作。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15010v1",
      "published_date": "2024-10-19 06:53:11 UTC",
      "updated_date": "2024-10-19 06:53:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:51:16.485052"
    },
    {
      "arxiv_id": "2410.14998v1",
      "title": "A comparative study of NeuralODE and Universal ODE approaches to solving Chandrasekhar White Dwarf equation",
      "title_zh": "翻译失败",
      "authors": [
        "Raymundo Vazquez Martinez",
        "Raj Abhijit Dandekar",
        "Rajat Dandekar",
        "Sreedath Panat"
      ],
      "abstract": "In this study, we apply two pillars of Scientific Machine Learning: Neural\nOrdinary Differential Equations (Neural ODEs) and Universal Differential\nEquations (UDEs) to the Chandrasekhar White Dwarf Equation (CWDE). The CWDE is\nfundamental for understanding the life cycle of a star, and describes the\nrelationship between the density of the white dwarf and its distance from the\ncenter. Despite the rise in Scientific Machine Learning frameworks, very less\nattention has been paid to the systematic applications of the above SciML\npillars on astronomy based ODEs. Through robust modeling in the Julia\nprogramming language, we show that both Neural ODEs and UDEs can be used\neffectively for both prediction as well as forecasting of the CWDE. More\nimportantly, we introduce the forecasting breakdown point - the time at which\nforecasting fails for both Neural ODEs and UDEs. Through a robust\nhyperparameter optimization testing, we provide insights on the neural network\narchitecture, activation functions and optimizers which provide the best\nresults. This study provides opens a door to investigate the applicability of\nScientific Machine Learning frameworks in forecasting tasks for a wide range of\nscientific domains.",
      "tldr_zh": "这篇论文比较了 Neural ODEs 和 Universal ODEs 这两种 Scientific Machine Learning 框架在解决 Chandrasekhar White Dwarf Equation (CWDE) 上的应用，CWDE 用于描述白矮星密度与中心距离的关系。研究利用 Julia 编程语言进行建模，证明了这些方法在 CWDE 的预测和预测任务中均有效，并引入了 forecasting breakdown point 来标识预测失败的时间点。通过超参数优化，论文提供了关于神经网络架构、激活函数和优化器的最佳见解，为 Scientific Machine Learning 在天文学及其他科学领域的预测应用开辟了新路径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.14998v1",
      "published_date": "2024-10-19 06:13:32 UTC",
      "updated_date": "2024-10-19 06:13:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:51:29.844771"
    },
    {
      "arxiv_id": "2410.14997v2",
      "title": "Improving Pronunciation and Accent Conversion through Knowledge Distillation And Synthetic Ground-Truth from Native TTS",
      "title_zh": "翻译失败",
      "authors": [
        "Tuan Nam Nguyen",
        "Seymanur Akti",
        "Ngoc Quan Pham",
        "Alexander Waibel"
      ],
      "abstract": "Previous approaches on accent conversion (AC) mainly aimed at making\nnon-native speech sound more native while maintaining the original content and\nspeaker identity. However, non-native speakers sometimes have pronunciation\nissues, which can make it difficult for listeners to understand them. Hence, we\ndeveloped a new AC approach that not only focuses on accent conversion but also\nimproves pronunciation of non-native accented speaker. By providing the\nnon-native audio and the corresponding transcript, we generate the ideal\nground-truth audio with native-like pronunciation with original duration and\nprosody. This ground-truth data aids the model in learning a direct mapping\nbetween accented and native speech. We utilize the end-to-end VITS framework to\nachieve high-quality waveform reconstruction for the AC task. As a result, our\nsystem not only produces audio that closely resembles native accents and while\nretaining the original speaker's identity but also improve pronunciation, as\ndemonstrated by evaluation results.",
      "tldr_zh": "本文提出了一种改进口音转换（AC）的方法，通过 Knowledge Distillation 和从 Native TTS 生成的 Synthetic Ground-Truth，来同时实现非母语者口音转换和发音改善。方法包括提供非母语音频及对应文本，生成保持原时长和韵律的理想母语-like 音频，作为 ground-truth 数据辅助模型学习直接映射。利用端到端的 VITS 框架进行高质量波形重建，结果显示，该系统不仅产生更接近母语口音的音频，同时保留原说话者身份，并显著提升了发音清晰度，如评测结果所示。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "accepted at ICASSP 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.14997v2",
      "published_date": "2024-10-19 06:12:31 UTC",
      "updated_date": "2025-03-04 13:17:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:51:41.834003"
    },
    {
      "arxiv_id": "2410.14989v1",
      "title": "AutoFPDesigner: Automated Flight Procedure Design Based on Multi-Agent Large Language Model",
      "title_zh": "翻译失败",
      "authors": [
        "Longtao Zhu",
        "Hongyu Yang",
        "Ge Song",
        "Xin Ma",
        "Yanxin Zhang",
        "Yulong Ji"
      ],
      "abstract": "Current flight procedure design methods heavily rely on human-led design\nprocess, which is not only low auto-mation but also suffer from complex\nalgorithm modelling and poor generalization. To address these challenges, this\npaper proposes an agent-driven flight procedure design method based on large\nlanguage model, named Au-toFPDesigner, which utilizes multi-agent collaboration\nto complete procedure design. The method enables end-to-end automated design of\nperformance-based navigation (PBN) procedures. In this process, the user input\nthe design requirements in natural language, AutoFPDesigner models the flight\nprocedure design by loading the design speci-fications and utilizing tool\nlibraries complete the design. AutoFPDesigner allows users to oversee and\nseamlessly participate in the design process. Experimental results show that\nAutoFPDesigner ensures nearly 100% safety in the designed flight procedures and\nachieves 75% task completion rate, with good adaptability across different\ndesign tasks. AutoFPDesigner introduces a new paradigm for flight procedure\ndesign and represents a key step towards the automation of this process.\nKeywords: Flight Procedure Design; Large Language Model; Performance-Based\nNavigation (PBN); Multi Agent;",
      "tldr_zh": "本研究针对传统飞行程序设计依赖人工、自动化低且泛化差的问题，提出AutoFPDesigner框架，该框架基于多智能体Large Language Model，实现飞行程序的端到端自动化设计。用户通过自然语言输入设计需求，系统加载设计规范并利用工具库进行多智能体协作，完成Performance-Based Navigation (PBN)程序的建模和优化，同时允许用户监督和参与过程。实验结果显示，AutoFPDesigner设计的飞行程序安全率接近100%，任务完成率达75%，并在不同设计任务中表现出良好适应性。该框架引入飞行程序设计的新范式，推动该领域的自动化发展。",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "21 pages, 18 figures, 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2410.14989v1",
      "published_date": "2024-10-19 05:41:11 UTC",
      "updated_date": "2024-10-19 05:41:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:51:52.946384"
    },
    {
      "arxiv_id": "2410.14986v1",
      "title": "NeuralMAG: Fast and Generalizable Micromagnetic Simulation with Deep Neural Nets",
      "title_zh": "NeuralMAG: 基于深度神经网络的快速且泛化微磁模拟",
      "authors": [
        "Yunqi Cai",
        "Jiangnan Li",
        "Dong Wang"
      ],
      "abstract": "Micromagnetics has made significant strides, particularly due to its\nwide-ranging applications in magnetic storage design. Numerical simulation is a\ncornerstone of micromagnetics research, relying on first-principle rules to\ncompute the dynamic evolution of micromagnetic systems based on the renowned\nLLG equation, named after Landau, Lifshitz, and Gilbert. However, simulations\nare often hindered by their slow speed. Although Fast-Fourier transformation\n(FFT) calculations reduce the computational complexity to O(NlogN), it remains\nimpractical for large-scale simulations. In this paper, we introduce NeuralMAG,\na deep learning approach to micromagnetic simulation. Our approach follows the\nLLG iterative framework but accelerates demagnetizing field computation through\nthe employment of a U-shaped neural network (Unet). The Unet architecture\ncomprises an encoder that extracts aggregated spins at various scales and\nlearns the local interaction at each scale, followed by a decoder that\naccumulates the local interactions at different scales to approximate the\nglobal convolution. This divide-and-accumulate scheme achieves a time\ncomplexity of O(N), significantly enhancing the speed and feasibility of\nlarge-scale simulations. Unlike existing neural methods, NeuralMAG concentrates\non the core computation rather than an end-to-end approximation for a specific\ntask, making it inherently generalizable. To validate the new approach, we\ntrained a single model and evaluated it on two micromagnetics tasks with\nvarious sample sizes, shapes, and material settings.",
      "tldr_zh": "本文提出NeuralMAG，一种基于深度神经网络的微磁模拟方法，旨在解决传统基于LLG equation的数值模拟速度慢的问题，通过Unet架构加速去磁场计算，实现O(N)的计算复杂度，而非O(NlogN)。Unet的编码器提取多尺度自旋特征并学习局部交互，解码器则累积这些交互来近似全局卷积，从而显著提升大规模模拟的可行性。与现有神经方法不同，NeuralMAG专注于核心计算而非特定任务，使其更具泛化性；实验验证显示，一个单一模型即可在各种样本大小、形状和材料设置的微磁任务上表现出色。",
      "categories": [
        "cs.LG",
        "cond-mat.mes-hall",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.14986v1",
      "published_date": "2024-10-19 05:25:08 UTC",
      "updated_date": "2024-10-19 05:25:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:52:05.918900"
    },
    {
      "arxiv_id": "2410.14979v5",
      "title": "Do Large Language Models Truly Grasp Mathematics? An Empirical Exploration From Cognitive Psychology",
      "title_zh": "大语言模型是否真正掌握数学？基于认知心理学的实证探索",
      "authors": [
        "Wei Xie",
        "Shuoyoucheng Ma",
        "Zhenhua Wang",
        "Enze Wang",
        "Kai Chen",
        "Xiaobing Sun",
        "Baosheng Wang"
      ],
      "abstract": "The cognitive mechanism by which Large Language Models (LLMs) solve\nmathematical problems remains a widely debated and unresolved issue. Currently,\nthere is little interpretable experimental evidence that connects LLMs'\nproblem-solving with human cognitive psychology.To determine if LLMs possess\nhuman-like mathematical reasoning, we modified the problems used in the human\nCognitive Reflection Test (CRT). Our results show that, even with the use of\nChains of Thought (CoT) prompts, mainstream LLMs, including the latest o1 model\n(noted for its reasoning capabilities), have a high error rate when solving\nthese modified CRT problems. Specifically, the average accuracy rate dropped by\nup to 50% compared to the original questions.Further analysis of LLMs'\nincorrect answers suggests that they primarily rely on pattern matching from\ntheir training data, which aligns more with human intuition (System 1 thinking)\nrather than with human-like reasoning (System 2 thinking). This finding\nchallenges the belief that LLMs have genuine mathematical reasoning abilities\ncomparable to humans. As a result, this work may adjust overly optimistic views\non LLMs' progress towards artificial general intelligence.",
      "tldr_zh": "本研究通过修改人类认知反射测试（Cognitive Reflection Test, CRT）的问题，评估大型语言模型（Large Language Models, LLMs）是否具备人类般的数学推理能力。结果显示，即使使用链式思维提示（Chains of Thought, CoT），主流 LLMs 的准确率比原问题下降了 50%，错误率居高不下。进一步分析表明，LLMs 主要依赖训练数据的模式匹配，类似于人类的直觉思维（System 1），而非推理思维（System 2）。这项发现质疑了 LLMs 拥有真正人类级数学推理能力的观点，并可能调整对人工智能通用智能进展的乐观预期。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.14979v5",
      "published_date": "2024-10-19 05:01:56 UTC",
      "updated_date": "2024-11-15 12:46:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:52:17.267103"
    },
    {
      "arxiv_id": "2410.14975v2",
      "title": "Reflexive Guidance: Improving OoDD in Vision-Language Models via Self-Guided Image-Adaptive Concept Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Jihyo Kim",
        "Seulbi Lee",
        "Sangheum Hwang"
      ],
      "abstract": "With the recent emergence of foundation models trained on internet-scale data\nand demonstrating remarkable generalization capabilities, such foundation\nmodels have become more widely adopted, leading to an expanding range of\napplication domains. Despite this rapid proliferation, the trustworthiness of\nfoundation models remains underexplored. Specifically, the out-of-distribution\ndetection (OoDD) capabilities of large vision-language models (LVLMs), such as\nGPT-4o, which are trained on massive multi-modal data, have not been\nsufficiently addressed. The disparity between their demonstrated potential and\npractical reliability raises concerns regarding the safe and trustworthy\ndeployment of foundation models. To address this gap, we evaluate and analyze\nthe OoDD capabilities of various proprietary and open-source LVLMs. Our\ninvestigation contributes to a better understanding of how these foundation\nmodels represent confidence scores through their generated natural language\nresponses. Furthermore, we propose a self-guided prompting approach, termed\nReflexive Guidance (ReGuide), aimed at enhancing the OoDD capability of LVLMs\nby leveraging self-generated image-adaptive concept suggestions. Experimental\nresults demonstrate that our ReGuide enhances the performance of current LVLMs\nin both image classification and OoDD tasks. The lists of sampled images, along\nwith the prompts and responses for each sample are available at\nhttps://github.com/daintlab/ReGuide.",
      "tldr_zh": "该研究评估了大型视觉语言模型 (LVLMs) 的 Out-of-Distribution Detection (OoDD) 能力，发现这些模型在处理分布外数据时存在可信度问题，并分析了它们通过自然语言响应表示置信度的机制。针对这一问题，作者提出了一种自引导提示方法 Reflexive Guidance (ReGuide)，通过自生成的图像自适应概念建议来提升 LVLMs 的 OoDD 性能。实验结果显示，ReGuide 显著改善了 LVLMs 在图像分类和 OoDD 任务中的表现，为更可靠的视觉语言模型应用提供了新途径。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at ICLR 2025. The first two authors contributed equally",
      "pdf_url": "http://arxiv.org/pdf/2410.14975v2",
      "published_date": "2024-10-19 04:46:51 UTC",
      "updated_date": "2025-02-08 20:38:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:52:29.496904"
    },
    {
      "arxiv_id": "2410.14971v2",
      "title": "BrainECHO: Semantic Brain Signal Decoding through Vector-Quantized Spectrogram Reconstruction for Whisper-Enhanced Text Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Jilong Li",
        "Zhenxi Song",
        "Jiaqi Wang",
        "Meishan Zhang",
        "Honghai Liu",
        "Min Zhang",
        "Zhiguo Zhang"
      ],
      "abstract": "Current EEG/MEG-to-text decoding systems suffer from three key limitations:\n(1) reliance on teacher-forcing methods, which compromises robustness during\ninference, (2) sensitivity to session-specific noise, hindering generalization\nacross subjects, and (3) misalignment between brain signals and linguistic\nrepresentations due to pre-trained language model over-dominance. To overcome\nthese challenges, we propose BrainECHO (Brain signal decoding via\nvEctor-quantized speCtrogram reconstruction for WHisper-enhanced text\ngeneratiOn), a multi-stage framework that employs decoupled representation\nlearning to achieve state-of-the-art performance on both EEG and MEG datasets.\nSpecifically, BrainECHO consists of three stages: (1) Discrete autoencoding,\nwhich transforms continuous Mel spectrograms into a finite set of high-quality\ndiscrete representations for subsequent stages. (2) Frozen alignment, where\nbrain signal embeddings are mapped to corresponding Mel spectrogram embeddings\nin a frozen latent space, effectively filtering session-specific noise through\nvector-quantized reconstruction, yielding a 3.65% improvement in BLEU-4 score.\n(3) Constrained decoding fine-tuning, which leverages the pre-trained Whisper\nmodel for audio-to-text translation, balancing signal adaptation with knowledge\npreservation, and achieving 74%-89% decoding BLEU scores without excessive\nreliance on teacher forcing. BrainECHO demonstrates robustness across sentence,\nsession, and subject-independent conditions, passing Gaussian noise tests and\nshowcasing its potential for enhancing language-based brain-computer\ninterfaces.",
      "tldr_zh": "本研究提出 BrainECHO 框架，通过向量量化谱图重建和解耦表示学习，解决 EEG/MEG-to-text 解码系统的三大问题：依赖 teacher-forcing 方法导致的鲁棒性不足、对 session-specific 噪声的敏感性，以及脑信号与语言表示的失配。框架包括三个阶段：（1）Discrete autoencoding，将连续 Mel spectrograms 转换为高质量离散表示；（2）Frozen alignment，将脑信号嵌入映射到冻结的 Mel spectrogram 嵌入空间，过滤噪声并提高 BLEU-4 得分 3.65%；（3）Constrained decoding fine-tuning，利用预训练 Whisper 模型进行音频到文本翻译，平衡信号适应和知识保留，实现 74%-89% 的解码 BLEU 得分，同时减少对 teacher-forcing 的依赖。BrainECHO 在 EEG 和 MEG 数据集上达到最先进性能，并展示出在句子、session 和主体无关条件下的高鲁棒性，有望提升语言基于脑机接口的应用潜力。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.14971v2",
      "published_date": "2024-10-19 04:29:03 UTC",
      "updated_date": "2025-05-19 08:17:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:52:43.626759"
    },
    {
      "arxiv_id": "2410.14970v4",
      "title": "Taming the Long Tail in Human Mobility Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaohang Xu",
        "Renhe Jiang",
        "Chuang Yang",
        "Zipei Fan",
        "Kaoru Sezaki"
      ],
      "abstract": "With the popularity of location-based services, human mobility prediction\nplays a key role in enhancing personalized navigation, optimizing\nrecommendation systems, and facilitating urban mobility and planning. This\ninvolves predicting a user's next POI (point-of-interest) visit using their\npast visit history. However, the uneven distribution of visitations over time\nand space, namely the long-tail problem in spatial distribution, makes it\ndifficult for AI models to predict those POIs that are less visited by humans.\nIn light of this issue, we propose the Long-Tail Adjusted Next POI Prediction\n(LoTNext) framework for mobility prediction, combining a Long-Tailed Graph\nAdjustment module to reduce the impact of the long-tailed nodes in the user-POI\ninteraction graph and a novel Long-Tailed Loss Adjustment module to adjust loss\nby logit score and sample weight adjustment strategy. Also, we employ the\nauxiliary prediction task to enhance generalization and accuracy. Our\nexperiments with two real-world trajectory datasets demonstrate that LoTNext\nsignificantly surpasses existing state-of-the-art works.",
      "tldr_zh": "该研究针对人类移动性预测中的长尾问题（long-tail problem），即POI（point-of-interest）访问分布不均导致模型难以预测低频访问点，提出了一种名为LoTNext的框架。LoTNext框架包括Long-Tailed Graph Adjustment模块，用于减少用户-POI交互图中长尾节点的冲击，以及Long-Tailed Loss Adjustment模块，通过logit分数和样本权重调整策略优化损失函数；此外，还引入辅助预测任务以提升模型的泛化和准确性。在两个真实轨迹数据集上的实验表明，LoTNext显著超越了现有最先进的方法。",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.SI",
      "comment": "Accepted by NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.14970v4",
      "published_date": "2024-10-19 04:28:44 UTC",
      "updated_date": "2025-01-15 15:35:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:52:54.763790"
    },
    {
      "arxiv_id": "2410.17094v1",
      "title": "Team Ryu's Submission to SIGMORPHON 2024 Shared Task on Subword Tokenization",
      "title_zh": "翻译失败",
      "authors": [
        "Zilong Li"
      ],
      "abstract": "This papers presents the submission of team Ryu to the canceled SIGMORPHON\n2024 shared task on subword tokenization. My submission explores whether\nmorphological segmentation methods can be used as a part of subword tokenizers.\nI adopt two approaches: the statistical segmentation method Morfessor and a\ntransformer based sequence-to-sequence (seq2seq) segmentation model in\ntokenizers. The prediction results show that morphological segmentation could\nbe as effective as commonly used subword tokenizers. Additionally, I\ninvestigate how a tokenizer's vocabulary influences the performance of language\nmodels. A tokenizer with a balanced token frequency distribution tends to work\nbetter. A balanced token vocabulary can be achieved by keeping frequent words\nas unique tokens.",
      "tldr_zh": "这篇论文介绍了团队 Ryu 针对 SIGMORPHON 2024 子词分词共享任务的提交，尽管任务已取消，主要探索了形态学分割方法在 subword tokenization 中的应用。作者采用了两种方法：统计分割工具 Morfessor 和基于 Transformer 的 seq2seq 模型，用于构建分词器。实验结果表明，形态学分割的性能可与常见子词分词器相当，且通过保持词汇表中令牌频率分布平衡（如将频繁单词作为唯一令牌），可以提升语言模型的整体表现。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.17094v1",
      "published_date": "2024-10-19 04:06:09 UTC",
      "updated_date": "2024-10-19 04:06:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:53:09.016725"
    },
    {
      "arxiv_id": "2410.14961v1",
      "title": "LangGFM: A Large Language Model Alone Can be a Powerful Graph Foundation Model",
      "title_zh": "LangGFM：仅凭一个大型语言模型即可成为强大的图基础模型",
      "authors": [
        "Tianqianjin Lin",
        "Pengwei Yan",
        "Kaisong Song",
        "Zhuoren Jiang",
        "Yangyang Kang",
        "Jun Lin",
        "Weikang Yuan",
        "Junjie Cao",
        "Changlong Sun",
        "Xiaozhong Liu"
      ],
      "abstract": "Graph foundation models (GFMs) have recently gained significant attention.\nHowever, the unique data processing and evaluation setups employed by different\nstudies hinder a deeper understanding of their progress. Additionally, current\nresearch tends to focus on specific subsets of graph learning tasks, such as\nstructural tasks, node-level tasks, or classification tasks. As a result, they\noften incorporate specialized modules tailored to particular task types, losing\ntheir applicability to other graph learning tasks and contradicting the\noriginal intent of foundation models to be universal. Therefore, to enhance\nconsistency, coverage, and diversity across domains, tasks, and research\ninterests within the graph learning community in the evaluation of GFMs, we\npropose GFMBench-a systematic and comprehensive benchmark comprising 26\ndatasets. Moreover, we introduce LangGFM, a novel GFM that relies entirely on\nlarge language models. By revisiting and exploring the effective graph\ntextualization principles, as well as repurposing successful techniques from\ngraph augmentation and graph self-supervised learning within the language\nspace, LangGFM achieves performance on par with or exceeding the state of the\nart across GFMBench, which can offer us new perspectives, experiences, and\nbaselines to drive forward the evolution of GFMs.",
      "tldr_zh": "本研究指出，现有的Graph Foundation Models (GFMs) 存在评估不一致和任务专化问题，导致其通用性不足。为此，作者提出GFMBench，一个包含26个数据集的系统性基准测试，以提升图学习领域的评估一致性、覆盖性和多样性。同时，引入LangGFM，一种完全基于Large Language Models (LLMs)的创新GFM，通过重新审视图文本化原则并应用图增强和自监督学习技术，在语言空间中实现性能。实验结果显示，LangGFM在GFMBench上达到或超过最先进水平，为GFMs的发展提供新视角和基准。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "under review",
      "pdf_url": "http://arxiv.org/pdf/2410.14961v1",
      "published_date": "2024-10-19 03:27:19 UTC",
      "updated_date": "2024-10-19 03:27:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:53:19.467316"
    },
    {
      "arxiv_id": "2410.14957v2",
      "title": "Offline-to-online Reinforcement Learning for Image-based Grasping with Scarce Demonstrations",
      "title_zh": "翻译失败",
      "authors": [
        "Bryan Chan",
        "Anson Leung",
        "James Bergstra"
      ],
      "abstract": "Offline-to-online reinforcement learning (O2O RL) aims to obtain a\ncontinually improving policy as it interacts with the environment, while\nensuring the initial policy behaviour is satisficing. This satisficing\nbehaviour is necessary for robotic manipulation where random exploration can be\ncostly due to catastrophic failures and time. O2O RL is especially compelling\nwhen we can only obtain a scarce amount of (potentially suboptimal)\ndemonstrations$\\unicode{x2014}$a scenario where behavioural cloning (BC) is\nknown to suffer from distribution shift. Previous works have outlined the\nchallenges in applying O2O RL algorithms under the image-based environments. In\nthis work, we propose a novel O2O RL algorithm that can learn in a real-life\nimage-based robotic vacuum grasping task with a small number of demonstrations\nwhere BC fails majority of the time. The proposed algorithm replaces the target\nnetwork in off-policy actor-critic algorithms with a regularization technique\ninspired by neural tangent kernel. We demonstrate that the proposed algorithm\ncan reach above 90\\% success rate in under two hours of interaction time, with\nonly 50 human demonstrations, while BC and existing commonly-used RL algorithms\nfail to achieve similar performance.",
      "tldr_zh": "该论文提出了一种新的 Offline-to-online Reinforcement Learning (O2O RL) 算法，旨在在图像-based 机器人抓取任务中，利用稀少演示快速学习策略，同时避免初始行为的灾难性失败。算法创新性地将 off-policy actor-critic 方法中的目标网络替换为受 neural tangent kernel 启发的正则化技术，以解决行为克隆 (BC) 因分布偏移而导致的性能问题。实验结果显示，该算法在真实机器人真空抓取任务中，仅用 50 个演示即可在两小时内达到 90% 以上的成功率，而 BC 和现有 RL 算法则无法实现类似表现。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "In CoRL Workshop on Mastering Robot Manipulation in a World of\n  Abundant Data 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.14957v2",
      "published_date": "2024-10-19 03:08:10 UTC",
      "updated_date": "2025-01-22 22:15:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:53:31.864776"
    },
    {
      "arxiv_id": "2410.14951v1",
      "title": "LSS-SKAN: Efficient Kolmogorov-Arnold Networks based on Single-Parameterized Function",
      "title_zh": "翻译失败",
      "authors": [
        "Zhijie Chen",
        "Xinglin Zhang"
      ],
      "abstract": "The recently proposed Kolmogorov-Arnold Networks (KAN) networks have\nattracted increasing attention due to their advantage of high visualizability\ncompared to MLP. In this paper, based on a series of small-scale experiments,\nwe proposed the Efficient KAN Expansion Principle (EKE Principle): allocating\nparameters to expand network scale, rather than employing more complex basis\nfunctions, leads to more efficient performance improvements in KANs. Based on\nthis principle, we proposed a superior KAN termed SKAN, where the basis\nfunction utilizes only a single learnable parameter. We then evaluated various\nsingle-parameterized functions for constructing SKANs, with LShifted\nSoftplus-based SKANs (LSS-SKANs) demonstrating superior accuracy. Subsequently,\nextensive experiments were performed, comparing LSS-SKAN with other KAN\nvariants on the MNIST dataset. In the final accuracy tests, LSS-SKAN exhibited\nsuperior performance on the MNIST dataset compared to all tested pure KAN\nvariants. Regarding execution speed, LSS-SKAN outperformed all compared popular\nKAN variants. Our experimental codes are available at\nhttps://github.com/chikkkit/LSS-SKAN and SKAN's Python library (for quick\nconstruction of SKAN in python) codes are available at\nhttps://github.com/chikkkit/SKAN .",
      "tldr_zh": "本研究基于小规模实验提出了Efficient KAN Expansion Principle (EKE Principle)，强调通过分配参数扩展网络规模而非使用更复杂的基函数，能更高效提升Kolmogorov-Arnold Networks (KAN)的性能。作者开发了SKAN，使用单一可学习参数作为基函数，并在多种单参数函数中评估后，发现LShifted Softplus-based SKANs (LSS-SKANs)表现出优越的准确性。在MNIST数据集的实验中，LSS-SKAN比其他KAN变体实现了更高的准确率和更快执行速度，并提供了开源代码以便复现和应用。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "25 pages, 14 figures, experiment codes are available at\n  https://github.com/chikkkit/LSS-SKAN , and SKAN's Python library code are\n  available at https://github.com/chikkkit/SKAN",
      "pdf_url": "http://arxiv.org/pdf/2410.14951v1",
      "published_date": "2024-10-19 02:44:35 UTC",
      "updated_date": "2024-10-19 02:44:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:53:43.035819"
    },
    {
      "arxiv_id": "2410.14947v1",
      "title": "Optimally Solving Colored Generalized Sliding-Tile Puzzles: Complexity and Bounds",
      "title_zh": "翻译失败",
      "authors": [
        "Marcus Gozon",
        "Jingjin Yu"
      ],
      "abstract": "The Generalized Sliding-Tile Puzzle (GSTP), allowing many square tiles on a\nboard to move in parallel while enforcing natural geometric collision\nconstraints on the movement of neighboring tiles, provide a high-fidelity\nmathematical model for many high-utility existing and future multi-robot\napplications, e.g., at mobile robot-based warehouses or autonomous garages.\nMotivated by practical relevance, this work examines a further generalization\nof GSTP called the Colored Generalized Sliding-Tile Puzzle (CGSP), where tiles\ncan now assume varying degrees of distinguishability, a common occurrence in\nthe aforementioned applications. Our study establishes the computational\ncomplexity of CGSP and its key sub-problems under a broad spectrum of possible\nconditions and characterizes solution makespan lower and upper bounds that\ndiffer by at most a logarithmic factor. These results are further extended to\nhigher-dimensional versions of the puzzle game.",
      "tldr_zh": "这篇论文研究了Colored Generalized Sliding-Tile Puzzle (CGSP)，这是Generalized Sliding-Tile Puzzle (GSTP)的扩展，允许方块具有不同区分度，以更好地模拟多机器人应用，如仓库或自动车库。作者分析了CGSP及其子问题的计算复杂性，在多种条件下建立了解决方案的makespan（完成时间）下界和上界，这些界限相差最多一个对数因子。这些结果进一步扩展到更高维度的谜题版本，为优化实际机器人系统提供了理论基础。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.RO",
      "comment": "WAFR 2024 Conference Version",
      "pdf_url": "http://arxiv.org/pdf/2410.14947v1",
      "published_date": "2024-10-19 02:34:13 UTC",
      "updated_date": "2024-10-19 02:34:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:53:54.567940"
    },
    {
      "arxiv_id": "2410.14946v2",
      "title": "DEL-Ranking: Ranking-Correction Denoising Framework for Elucidating Molecular Affinities in DNA-Encoded Libraries",
      "title_zh": "翻译失败",
      "authors": [
        "Hanqun Cao",
        "Mutian He",
        "Ning Ma",
        "Chang-yu Hsieh",
        "Chunbin Gu",
        "Pheng-Ann Heng"
      ],
      "abstract": "DNA-encoded library (DEL) screening has revolutionized the detection of\nprotein-ligand interactions through read counts, enabling rapid exploration of\nvast chemical spaces. However, noise in read counts, stemming from nonspecific\ninteractions, can mislead this exploration process. We present DEL-Ranking, a\nnovel distribution-correction denoising framework that addresses these\nchallenges. Our approach introduces two key innovations: (1) a novel ranking\nloss that rectifies relative magnitude relationships between read counts,\nenabling the learning of causal features determining activity levels, and (2)\nan iterative algorithm employing self-training and consistency loss to\nestablish model coherence between activity label and read count predictions.\nFurthermore, we contribute three new DEL screening datasets, the first to\ncomprehensively include multi-dimensional molecular representations,\nprotein-ligand enrichment values, and their activity labels. These datasets\nmitigate data scarcity issues in AI-driven DEL screening research. Rigorous\nevaluation on diverse DEL datasets demonstrates DEL-Ranking's superior\nperformance across multiple correlation metrics, with significant improvements\nin binding affinity prediction accuracy. Our model exhibits zero-shot\ngeneralization ability across different protein targets and successfully\nidentifies potential motifs determining compound binding affinity. This work\nadvances DEL screening analysis and provides valuable resources for future\nresearch in this area.",
      "tldr_zh": "本研究针对 DNA-encoded library (DEL) 筛选中读数噪声（如非特异性交互）导致的探索偏差，提出 DEL-Ranking 框架，这是一种分布修正去噪方法。框架的关键创新包括：一个新的 ranking loss 函数，用于修正读数之间的相对关系并学习决定活性水平的因果特征，以及一个迭代算法结合自训练和一致性损失，以确保模型在活性标签和读数预测间的连贯性。该框架还贡献了三个新的 DEL 筛选数据集，涵盖多维分子表示、蛋白-配体富集值和活性标签，缓解了 AI 驱动 DEL 研究的数据稀缺问题。实验结果显示，DEL-Ranking 在多种相关指标上表现出色，提高了结合亲和力预测的准确性，并实现了零样本泛化能力，能够识别潜在的化合物结合基序，从而推进 DEL 筛选分析。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.BM"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.14946v2",
      "published_date": "2024-10-19 02:32:09 UTC",
      "updated_date": "2024-12-04 07:58:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:54:08.945159"
    },
    {
      "arxiv_id": "2410.14929v1",
      "title": "Water quality polluted by total suspended solids classified within an Artificial Neural Network approach",
      "title_zh": "翻译失败",
      "authors": [
        "I. Luviano Soto",
        "Y. Concha Sánchez",
        "A. Raya"
      ],
      "abstract": "This study investigates the application of an artificial neural network\nframework for analysing water pollution caused by solids. Water pollution by\nsuspended solids poses significant environmental and health risks. Traditional\nmethods for assessing and predicting pollution levels are often time-consuming\nand resource-intensive. To address these challenges, we developed a model that\nleverages a comprehensive dataset of water quality from total suspended solids.\nA convolutional neural network was trained under a transfer learning approach\nusing data corresponding to different total suspended solids concentrations,\nwith the goal of accurately predicting low, medium and high pollution levels\nbased on various input variables. Our model demonstrated high predictive\naccuracy, outperforming conventional statistical methods in terms of both speed\nand reliability. The results suggest that the artificial neural network\nframework can serve as an effective tool for real-time monitoring and\nmanagement of water pollution, facilitating proactive decision-making and\npolicy formulation. This approach not only enhances our understanding of\npollution dynamics but also underscores the potential of machine learning\ntechniques in environmental science.",
      "tldr_zh": "本研究探讨了使用 Artificial Neural Network 框架分析由 total suspended solids 引起的水污染问题，以克服传统评估方法的耗时和资源密集问题。研究团队开发了一个基于 Convolutional Neural Network 和 transfer learning 的模型，利用全面水质数据集训练，以准确预测污染水平（低、中、高）。实验结果显示，该模型在预测准确性、速度和可靠性上明显优于传统统计方法。总之，这一方法为实时监测和管理水污染提供了高效工具，并突显了机器学习在环境科学中的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "Machine Learning"
      ],
      "primary_category": "cs.LG",
      "comment": "42 pages, 8 figures and 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2410.14929v1",
      "published_date": "2024-10-19 01:33:08 UTC",
      "updated_date": "2024-10-19 01:33:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:54:18.579568"
    },
    {
      "arxiv_id": "2410.14916v1",
      "title": "Cooperation and Fairness in Multi-Agent Reinforcement Learning",
      "title_zh": "多智能体强化学习中的合作与公平性",
      "authors": [
        "Jasmine Jerry Aloor",
        "Siddharth Nayak",
        "Sydney Dolan",
        "Hamsa Balakrishnan"
      ],
      "abstract": "Multi-agent systems are trained to maximize shared cost objectives, which\ntypically reflect system-level efficiency. However, in the resource-constrained\nenvironments of mobility and transportation systems, efficiency may be achieved\nat the expense of fairness -- certain agents may incur significantly greater\ncosts or lower rewards compared to others. Tasks could be distributed\ninequitably, leading to some agents receiving an unfair advantage while others\nincur disproportionately high costs. It is important to consider the tradeoffs\nbetween efficiency and fairness. We consider the problem of fair multi-agent\nnavigation for a group of decentralized agents using multi-agent reinforcement\nlearning (MARL). We consider the reciprocal of the coefficient of variation of\nthe distances traveled by different agents as a measure of fairness and\ninvestigate whether agents can learn to be fair without significantly\nsacrificing efficiency (i.e., increasing the total distance traveled). We find\nthat by training agents using min-max fair distance goal assignments along with\na reward term that incentivizes fairness as they move towards their goals, the\nagents (1) learn a fair assignment of goals and (2) achieve almost perfect goal\ncoverage in navigation scenarios using only local observations. For goal\ncoverage scenarios, we find that, on average, our model yields a 14%\nimprovement in efficiency and a 5% improvement in fairness over a baseline\ntrained using random assignments. Furthermore, an average of 21% improvement in\nfairness can be achieved compared to a model trained on optimally efficient\nassignments; this increase in fairness comes at the expense of only a 7%\ndecrease in efficiency. Finally, we extend our method to environments in which\nagents must complete coverage tasks in prescribed formations and show that it\nis possible to do so without tailoring the models to specific formation shapes.",
      "tldr_zh": "这篇论文探讨了在多智能体强化学习(MARL)中实现合作和公平性的问题，针对资源受限环境（如交通系统）中可能出现的效率与公平性权衡。研究提出了一种方法，通过最小-最大公平距离目标分配(min-max fair distance goal assignments)并添加奖励激励公平性，训练智能体学习公平分配目标，同时保持高效导航。实验结果显示，在目标覆盖场景中，该方法比随机分配基线提高了14%的效率和5%的公平性；与最优效率分配相比，公平性提升21%，但效率仅下降7%。此外，该方法扩展到智能体在指定队形下完成任务时，展示了良好的适应性，而无需针对特定形状进行调整。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.MA",
      "comment": "Manuscript accepted in ACM Journal on Autonomous Transportation\n  Systems",
      "pdf_url": "http://arxiv.org/pdf/2410.14916v1",
      "published_date": "2024-10-19 00:10:52 UTC",
      "updated_date": "2024-10-19 00:10:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:54:31.865105"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 69,
  "processed_papers_count": 69,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-20T13:54:50.833876"
}